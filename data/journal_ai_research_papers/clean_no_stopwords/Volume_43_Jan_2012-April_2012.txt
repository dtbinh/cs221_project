Journal Artificial Intelligence Research 43 (2012) 523-570

Submitted 01/12; published 04/12

Avoiding Escaping Depressions
Real-Time Heuristic Search
Carlos Hernandez

chernan@ucsc.cl

Departamento de Ingeniera Informatica
Universidad Catolica de la Santsima Concepcion
Caupolican 491, Concepcion, Chile

Jorge A. Baier

jabaier@ing.puc.cl

Departamento de Ciencia de la Computacion
Pontificia Universidad Catolica de Chile
Vicuna Mackenna 4860, Santiago, Chile

Abstract
Heuristics used solving hard real-time search problems regions depressions.
regions bounded areas search space heuristic function inaccurate compared actual cost reach solution. Early real-time search algorithms,
like LRTA , easily become trapped regions since heuristic values states
may need updated multiple times, results costly solutions. State-of-the-art
real-time search algorithms, like LSS-LRTA LRTA (k), improve LRTA mechanism
update heuristic, resulting improved performance. algorithms, however,
guide search towards avoiding depressed regions. paper presents depression
avoidance, simple real-time search principle guide search towards avoiding states
marked part heuristic depression. propose two ways depression avoidance implemented: mark-and-avoid move-to-border. implement
strategies top LSS-LRTA RTAA , producing 4 new real-time heuristic
search algorithms: aLSS-LRTA , daLSS-LRTA , aRTAA , daRTAA . objective find single solution running real-time search algorithm once, show
daLSS-LRTA daRTAA outperform predecessors sometimes one order
magnitude. four new algorithms, daRTAA produces best solutions given
fixed deadline average time allowed per planning episode. prove algorithms good theoretical properties: finite search spaces, find solution one
exists, converge optimal number trials.

1. Introduction
Many real-world applications require agents act quickly possibly unknown environment. case, example, autonomous robots vehicles moving quickly
initially unknown terrain (Koenig, 2001). also case virtual agents
games (e.g., Warcraft, Starcraft), time dedicated game software
perform tasks path-finding virtual agents limited. Actually, companies impose limits order 1 millisecond perform tasks (Bulitko, Bjornsson,
Sturtevant, & Lawrence, 2011). Therefore, usually time plan full trajectories advance; rather, path-finding carried real-time fashion.
Real-time search (e.g., Korf, 1990; Weiss, 1999; Edelkamp & Schrodl, 2011) standard
paradigm solving search problems environment fully known advance
c
2012
AI Access Foundation. rights reserved.

fiHernandez & Baier

agents act quickly. Instead running computationally expensive procedure
generate conditional plan outset, real-time algorithms interleave planning
execution. such, usually run computationally inexpensive lookahead-update-act
cycle, search carried select next move (lookahead phase), learning
carried (update phase), finally action executed may involve observing
environment (act phase). Like standard search (Hart, Nilsson, & Raphael, 1968),
use heuristic function guide action selection. environment unveiled,
algorithm updates internal belief structure search space, updating (i.e.
learning) heuristic value states. lookahead-update-act cycle executed
solution found.
Early heuristic real-time algorithms like Learning Real-Time (LRTA ) RealTime (RTA ) (Korf, 1990) amenable settings environment initially
unknown. algorithms perform poorly presence heuristic depressions
(Ishida, 1992). Intuitively, heuristic depression bounded region search space
heuristic inaccurate respect heuristic values states
border region. agent controlled LRTA RTA enters region
search space conforms heuristic depression usually become trapped.
order leave heuristically depressed region, agent need visit update
many states region, potentially several times. Furthermore, many applications,
games, behavior agent depression may look irrational thus
undesirable.
State-of-the-art heuristic real-time search algorithms suitable applications
initially unknown environments capable escaping heuristic depressions
quickly LRTA RTA . performing lookahead search,
learning, combination both. search involves selecting action looking
farther away search space. learning usually involves updating heuristic
several states single iteration. many algorithms use one combination
techniques (e.g., Hernandez & Meseguer, 2005; Bulitko & Lee, 2006; Koenig &
Likhachev, 2006b; Hernandez & Meseguer, 2007; Rayner, Davison, Bulitko, Anderson, &
Lu, 2007; Bjornsson, Bulitko, & Sturtevant, 2009; Koenig & Sun, 2009). result,
algorithms perform better LRTA , spending fewer moves trapped depressions.
Two algorithms representative state art real-time search initially
unknown environments LSS-LRTA (Koenig & Sun, 2009) RTAA (Koenig &
Likhachev, 2006a). algorithms generalize LRTA performing search
learning episode. algorithms shown perform well
practice. However, despite use elaborate techniques, may still perform
poorly presence heuristic depressions. may sometimes rely
increasing heuristic value states inside depressions mechanism exit them.
paper study techniques allow us improve performance real-time
search algorithms making explicitly aware heuristic depressions,
guiding search order avoid and, therefore, escape depressions. Specifically,
contributions paper follows.
provide new empirical evidence shows RTAA outperforms LSS-LRTA
game map benchmarks first trial, means whenever
single chance run one real-time heuristic search algorithms solve search
524

fiAvoiding Escaping Depressions Real-Time Heuristic Search

problem, RTAA finds better solutions LSS-LRTA making search
effort. Before, Koenig Likhachev (2006b) shown similar performance results
mazes. important since LSS-LRTA , RTAA , algorithm
received attention real-time heuristic search community.
paper consider incorporating techniques LSS-LRTA RTAA .
propose definition cost-sensitive heuristic depressions, general
notion Ishidas (1992) notion heuristic depression since incorporates action
costs. illustrate depressions better describe regions search
space real-time search algorithms get trapped.
propose simple principle actively guide search towards avoiding cost-sensitive
heuristic depressions call depression avoidance, together two strategies
implement depression avoidance incorporated state-of-the-art
real-time heuristic search algorithms: mark-and-avoid move-to-border.
propose four new real-time search algorithms; two based mark-and-avoid, aLSSLRTA , aRTAA , two based move-to-border: daLSS-LRTA , daRTAA .
algorithms result implementing depression avoidance top RTAA
LSS-LRTA .
prove algorithms desirable properties: heuristic consistency
preserved, terminate solution exists, eventually converge
optimal solution running sufficiently large, finite number trials.
carry extensive empirical evaluation algorithms deployed game
benchmarks mazes. evaluation shows algorithms outperform existing algorithms game maps mazes. little time allowed
lookahead phase, two algorithms, daLSS-LRTA daRTAA , outperform
existing ones order magnitude.
contributions paper published conference papers
(Hernandez & Baier, 2011d, 2011c). article includes new material
presented before. particular:
describe evaluate daLSS-LRTA , algorithm presented article
first time.
include full proofs termination results (Theorem 6), new theoretical
result (Theorem 7) convergence algorithms.
extend previously published empirical results including maze benchmarks,
previously considered, including game domains
problems.
Finally, discuss detail scenarios techniques may perform
particularly good.
525

fiHernandez & Baier

rest paper organized follows. Section 2 explain basic concepts
real-time search. continue presenting LSS-LRTA RTAA , extend results
available literature comparing game maps. continue elaborating
concept heuristic depression. describe strategies implementing
depression avoidance algorithms result applying LSSLRTA RTAA . continue detailed theoretical experimental analysis.
Then, present discussion approach evaluation. finish summary.

2. Preliminaries
search problem P tuple (S, A, c, s0 , G), (S, A) digraph represents
search space. set represents states arcs represent available actions.
contain elements form (x, x). addition, cost function c : 7 R+
associates cost available actions. Finally, s0 start state,
G set goal states. paper assume search spaces undirected; i.e.,
whenever (u, v) A, (v, u). Furthermore, c(u, v) = c(v, u), (u, v) A.
successors state u defined Succ(u) = {v | (u, v) A}. Two states
neighbors successors other.
heuristic function h : 7 [0, ) associates state approximation h(s)
cost path goal state. denote h (s) cost optimal path
reach solution s.
heuristic h consistent h(g) = 0 g G h(s) c(s, s0 ) + h(s0 )
states s0 Succ(s). h consistent C(s, s0 ) cost path
two states s0 , h(s) C(s, s0 ) + h(s0 ). Furthermore, h consistent easy
prove also admissible; i.e., h(s) underestimates h (s). details
definitions, refer reader book authored Pearl (1984).
refer h(s) h-value assume familiarity algorithm (Hart
et al., 1968): g(s) denotes cost path start state s, f (s) defined
g(s) + h(s). f -value g-value refer f (s) g(s) respectively.
2.1 Real-Time Search
objective real-time search algorithm make agent travel initial
state goal state performing, moves, amount computation bounded
constant. example situation path-finding priori unknown grid-like environments.
agent sufficient memory store current belief structure
search space. addition, free-space assumption (Zelinsky, 1992; Koenig, Tovey, &
Smirnov, 2003) taken: environment initially assumed obstacle-free. agent
capable limited form sensing: obstacles neighbor states detected.
obstacles detected, agent updates map accordingly.
Many state-of-the-art real-time heuristic search algorithms described
pseudo-code Algorithm 1. algorithm iteratively executes lookahead-update-act
cycle goal reached. lookahead phase (Line 46) determines next state
move to, update phase (Line 7) updates heuristic, act phase (Line 8)
moves agent next position. lookahead-update part cycle (Lines 47)
referred planning episode throughout paper.
526

fiAvoiding Escaping Depressions Real-Time Heuristic Search

Algorithm 1: generic real-time heuristic search algorithm

1
2
3
4
5
6
7
8
9
10

Input: search problem P , heuristic function h.
Side Effect: agent moved initial state goal state trajectory exists
h0 h
scurrent s0
scurrent 6 G
LookAhead ()
Open = return no-solution
snext Extract-Best-State()
Update ()
move agent scurrent snext path identified LookAhead. Stop
action cost along path updated.
scurrent current agent position
update action costs (if increased)

generic algorithm three local variables: scurrent stores current position
agent, c(s, s0 ) contains cost moving state successor s0 , h
h(s) contains heuristic value s. three variables may change time.
path-finding tasks, environment initially unknown, initial value c
obstacles assumed; i.e., c(s, s0 ) < two neighbor states s, s0 . initial
value h(s), every s, given parameter.
generic algorithm receives input search problem P , starts initializing
useful variables (Lines 12). h0 records initial value h, states P ,
scurrent stores initial position agent, s0 . assume cost arc
cannot decrease. particular, arc costs increase infinity obstacle discovered.
lookahead phase (Lines 46), algorithm determines proceed next.
Lookahead() procedure Line 4 implements bounded search procedure expands
states current state scurrent . set states generated call referred
local search space. Different choices made implement procedure. RealTime (RTA ) Learning Real-Time (LRTA )two early algorithms proposed
Korf (1990) modern real-time search algorithms run search
current state fixed depth (e.g., Bulitko & Lee, 2006). Another common option
run bounded search; choice taken Local Search Space LRTA (LSSLRTA ) (Koenig & Sun, 2009), Real-Time Adaptive (RTAA ) (Koenig & Likhachev,
2006b). Algorithm 2 shows pseudo-code bounded . Note k states
expanded, k parameter algorithm usually referred lookahead
parameter. pseudo code generic real-time search algorithm assumes call
Lookahead() stores frontier local search space Open, and, moreover,
goal state found search, state removed frontier (in
bounded pseudo-code guaranteed condition Line 7).
last step lookahead phase (Line 6, Algorithm 1), variable containing
next state move to, snext , assigned. Here, algorithms select state
search frontier estimated closest goal state. lookahead used,
state usually corresponds state minimum f -value Open. Thus -based
lookahead algorithms use Algorithm 3 implement Extract-Best-State() function.

527

fiHernandez & Baier

Algorithm 2: Bounded lookahead
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16

procedure ()
g(s)
g(scurrent ) 0
Open
Insert scurrent Open
expansions 0
s0 Open minimum f -value s0 6 G expansions < k
Remove state smallest f -value Open
Insert Closed
s0 Succ(s)
g(s0 ) > g(s) + c(s, s0 )
g(s0 ) g(s) + c(s, s0 )
s0 .back =
s0 Open remove s0 Open
Insert s0 Open
expansions expansions + 1

Algorithm 3: Selection Best State used LSS-LRTA , RTAA ,
algorithms.
1
2

procedure Extract-Best-State ()
return argmins0 Open g(s0 ) + h(s0 )

update phase (Line 7, Algorithm 1), heuristic states search
space updated value better estimate true cost reach solution,
staying consistent. exploring states vicinity scurrent , algorithm
gains information heuristic value number states. Using information,
h-value scurrent potentially states search spacecan
updated way reflect better estimation cost reach solution.
Since update heuristic states updated value closer true
cost, phase also referred learning phase.
literature describes several ways one implement update
heuristic, e.g., mini-min (e.g., Korf, 1990), max mins (Bulitko, 2004), heuristic
bounded propagation (Hernandez & Meseguer, 2005). learning rules
relevant paper, however, implemented LSS-LRTA RTAA .
described detail following subsections.
Finally, learning, agent attempts move state selected
Extract-Best-State() function, snext . implementations, path selected
state computed already Lookahead() procedure (in case Algorithm 2,
path reconstructed using back pointer set Line 13). environment known advance, agent always move destination. However,
environment known advance, process fail (in path-finding,
occur due discovery obstacle). obstacle found, assume
agent stops moving soon detected obstacle. cases, algorithm
528

fiAvoiding Escaping Depressions Real-Time Heuristic Search

update memory regarding environment, typically involves updating cost
function. pseudo-code, reflected Line 10.

3. LSS-LRTA RTAA
describe LSS-LRTA RTAA , two state-of-the-art real-time heuristic search
algorithms relevant paper. make two small contributions understanding two algorithms. First, experimental comparison
benchmarks considered before. Second, prove two theoretical results
aim understanding differences update mechanisms (Propositions 1
2). knowledge, none results appear literature.
3.1 LSS-LRTA
Local search space LRTA (LSS-LRTA ) first introduced Koenig (2004), later
presented detail Koenig Sun (2009). instance Algorithm 1. lookahead procedure bounded search (Algorithm 2). next state move corresponds state Open lowest f -value; i.e., uses Algorithm 3 implement
Extract-Best-State().
LSS-LRTA updates values state local search space way
h(s) assigned maximum possible value guarantees consistency
states Open. implementing Update() procedure modified Dijkstras algorithm (Algorithm 4). Since value h raised maximum, update
mechanism LSS-LRTA makes h informed get given current knowledge
search space, maintaining consistency.
Algorithm 4: LSS-LRTA Modified Dijkstras Procedure. assume Open list
queue ordered h-value.
1
2
3
4
5
6
7
8
9

procedure ModifiedDijkstra ()
state Closed h(s)
Closed 6=
Extract minimum h-value Open
Closed delete Closed
s0 Succ(s0 )
s0 Closed h(s0 ) > c(s0 , s) + h(s)
h(s0 ) c(s0 , s) + h(s)
s0 6 Open Insert s0 Open

Algorithm 5: RTAA Update Procedure
1
2
3
4

procedure Update ()
f minsOpen g(s) + h(s)
Closed
h(s) f g(s)

529

fiHernandez & Baier

3.2 RTAA
Real-Time Adaptive (RTAA ) proposed Koenig Likhachev (2006b).
instance Algorithm 1. lookahead phase identical LSS-LRTA :
bounded followed selecting state lowest f -value Open next state
move to. However uses simpler learning mechanism based update rule
incremental search algorithm Adaptive (Koenig & Likhachev, 2006a). Thus,
updates heuristic value states interior local search space (i.e.,
stored variable Closed) using f -value best state Open. procedure
shown Algorithm 5.
RTAA update procedure considerably faster practice LSS-LRTA .
Obtaining lowest f -value state Open done constant time
implemented binary heaps. that, algorithm simply iterates
states Closed. worst-case performance O(|Closed|). hand,
LSS-LRTA update procedure first needs convert Open priority queue ordered
h may, worst case, need extract |Open| + |Closed| elements
binary heap. addition, expands node ever extracted priority
queue. time complete operations, worst case Texp N + Tb N log N ,
N = |Open| + |Closed|, Texp time taken per expansion, Tb constant
factor associated extraction binary heap. worst-case asymptotic complexity
extraction thus O(N log N ). However, since usually deal small N may
case term Texp N dominates expression time.
prove heuristic values RTAA learns may less accurate
LSS-LRTA . state formally, introduce notation. Let hn ,
n > 0, denote value h variable start iteration n main algorithm,
or, equivalently, right update phase iteration n 1. also denote
heuristic function given input h0 . Let kn (s, s0 ) denote cost optimal path
s0 traverses states Closed ending s0 .
Proposition 1 Let state Closed right call returned n-th
iteration LSS-LRTA . Then,
hn+1 (s) = min kn (s, sb ) + hn (sb ).
sb Open

(1)

Proof: show value h(s) computed modified Dijkstra algorithm
state corresponds minimum cost reaching node certain state
particular graph G. modified Dijkstra procedure seen run standard
Dijkstra algorithm (e.g., Cormen, Leiserson, Rivest, & Stein, 2001) graph.
First observe procedure differs standard Dijkstra algorithm
non-singleton set states, namely Open, initialized finite value h.
standard Dijkstra algorithm, hand, source node initialized
cumulative cost 0 whereas remaining nodes initialized .
facts mind, straightforward see run modified Dijkstra
interpreted run standard Dijkstra algorithm node sstart directed graph
G that:
nodes exactly Open Closed plus distinguished node sstart .
530

fiAvoiding Escaping Depressions Real-Time Heuristic Search

contains arc (u, v) cost c arc (v, u) cost c search
graph P one v u Open.
contains arc form (sstart , s) cost h(s) Open.
contains arcs.
running Dijkstra algorithm sstart G, obtain, node G
cost optimal path sstart s. interpret cost h(s), s,
Equation 1 holds, finishes proof.

RTAA prove sightly different result.
Proposition 2 Right call returns n-th iteration RTAA , let
state lowest f -value Open, let state Closed. Then,
hn+1 (s) min kn (s, sb ) + hn (sb ).
sb Open

(2)

However, hn consistent path found scurrent ,
hn+1 (s) = min kn (s, sb ) + hn (sb ).
sb Open

(3)

Proof: (2), use fact heuristic consistent, remains consistent
RTAA iteration (a fact proven Koenig & Likhachev, 2006a), write
inequality hn+1 (s) minsb Open kn (s, sb ) + hn+1 (sb ). note every state sb
Open holds hn (s) = hn+1 (s), since heuristic values states Open
updated. Substituting hn+1 (s) inequality, obtain required result.
(3), use fact proven Hart et al. (1968) : consistent heuristics
used, g(s) contains cost cheapest path start state right
extracted Open (Line 8 Algorithm 2).
run consistent heuristic, state s0 along (optimal) path
found scurrent ,
g(s0 ) = kn (scurrent , s0 ),


0

(4)
0



g(s ) = kn (scurrent , ) + kn (s , ).

(5)

RTAA update rule states that:
hn+1 (s0 ) = f (s ) g(s0 ) = hn (s ) + g(s ) g(s0 )

(6)

Substituting (4) (5) (6), obtain hn+1 (s0 ) = kn (s0 , ) + hn (s ). Finally,
observe
kn (s0 , ) + h(s ) = min kn (s0 , sb ) + hn (sb ).
sb Open

Indeed, Open kn (s0 , ) + h(s ) > kn (s0 , ) + hn (s ),
adding g(s0 ) sides inequality, would f (s ) > f (s ),
contradicts fact state lowest f -value Open. conclude
henceforth hn+1 (s0 ) = minsb Open kn (s0 , sb ) + hn (sb ). finishes proof.

531

fiHernandez & Baier

Proposition 2 implies that, using consistent heuristics, RTAA update may yield
less informed h-values LSS-LRTA . However, least states
local search space, final h-values equal LSS-LRTA , hence
informed given current knowledge search space.
Koenig Likhachev (2006a) show fixed value lookahead parameter, quality solutions obtained LSS-LRTA better average
obtained RTAA path-finding tasks mazes. due fact LSSLRTA heuristic informed time RTAA . However, also
showed given fixed time deadline per planning episode, RTAA yields better solutions LSS-LRTA . essentially due fact RTAA update mechanism
faster: fixed deadline, higher lookahead parameter used RTAA
LSS-LRTA .
extend Koenig Likhachevs experimental analysis running comparison
two algorithms game maps. Table 1 shows average results LSS-LRTA
RTAA ran 12 different game maps. map, generated 500 random test cases.
Observe, example, deadline 0.0364 milliseconds imposed per planning
episode choose run RTAA lookahead k = 128, whereas choose
run LSS-LRTA lookahead k = 64. parameters, RTAA obtains
solution 36% cheaper LSS-LRTA does. Figure 1 shows average solution cost
versus time per episode. slopes curves suggest rate RTAA
improves solutions better LSS-LRTA , time per episode given.
conclusion RTAA seems superior LSS-LRTA time actually important.
thus confirm wider range tasks that, time per episode matters, RTAA
better LSS-LRTA . findings important mazes (for previous
evaluations existed) problems particular structure, results
necessarily generalize types problems.
Although conclude RTAA algorithm superior LSS-LRTA
comes finding good solution quickly, interesting note recent research
real-time heuristic search focused mainly extending using LSS-LRTA (see e.g.,
Bulitko, Bjornsson, & Lawrence, 2010; Bond, Widger, Ruml, & Sun, 2010; Hernandez &
Baier, 2011d; Sturtevant & Bulitko, 2011), RTAA rarely considered. Since LSSLRTA seems algorithm active study community, paper
apply techniques algorithms.

4. Heuristic Depressions
real-time search problems heuristics usually contain depressions. identification
depressions central algorithm. Intuitively, heuristic depression bounded
region search space containing states whose heuristic value low respect
heuristic values states border depression. Depressions exist naturally
heuristics used along real-time heuristic search algorithms. seen above,
real-time heuristic algorithms build solutions incrementally, updating heuristic values
associated certain states information gathered environment.
Ishida (1992) gave constructive definition heuristic depressions. construction
starts node heuristic value equal less
532

fiAvoiding Escaping Depressions Real-Time Heuristic Search

RTAA*
LSS-LRTA*
k Avg. Cost Time/ep Exp/ep Per/ep Time Avg. Cost Time/ep Exp/ep Per/ep Time
1 1,146,014 0.0004
1.0
6.1 447.9 1,146,014 0.0012
8.7
14.8 1,259.6
2
919,410 0.0006
2.0
9.4 475.4
625,693 0.0020
13.7
29.3 979.4
4
626,623 0.0011
4.0
17.3 468.8
372,456 0.0034
21.3
54.3 818.1
8
363,109 0.0021
8.0
34.1 383.7
227,526 0.0058
33.8
102.4 653.6
16
188,346 0.0040
16.0
70.1 269.1
127,753 0.0102
56.1
193.5 459.9
32
95,494 0.0078
32.0 152.9 192.8
72,044 0.0187
98.7
397.7 345.3
64
48,268 0.0159
63.9 361.3 145.7
40,359 0.0364 184.9
903.4 279.6
128
25,682 0.0326 126.4 932.3 125.8
22,471 0.0750 370.1 2,338.1 258.2
256
13,962 0.0647 236.8 2,351.8 125.6
12,264 0.1534 733.6 6,003.8 272.2
512
7,704 0.1078 377.6 4,616.7 131.6
7,275 0.2620 1,207.5 11,548.9 312.4

Table 1: Average results 12 game maps. lookahead value k, report
solution cost per test case (Avg. Cost), four measures efficiency: runtime
per planning episode (Time/ep) milliseconds, number cell expansions per
planning episode (Exp/ep), number heap percolations per planning episode
(Per/ep) runtime per test case (Time) milliseconds. results
obtained using Linux machine Intel Xeon CPU running 2GHz 12
GB RAM.

Cost vs Time per Episode (Games)

Average Solution Cost (log-scale)

1,000,000

RTAA*
LSS-LRTA*

500,000

100,000

10,000

0

0.05

0.1

0.15

0.2

0.25

0.3

Time per Planning Episode msec

Figure 1: Average solution cost obtained LSS-LRTA RTAA versus planning time
per episode 12 game maps.

533

fiHernandez & Baier

surrounding states. region extended adding state border states
resulting region heuristic value lower equal states
border. result, heuristic depression maximal connected component states
states boundary heuristic value greater equal
heuristic value state D.
known algorithms like LRTA behave poorly presence heuristic
depressions (Ishida, 1992). see this, assume LRTA run lookahead depth
equal 1, expands current state, leaving immediate successors
search frontier. Assume visits state depression
solution node lies outside depression. exit depressed region agent must follow
path interior depressed region, say, s1 . . . sn , finally choosing state
border region, say se . visiting sn , agent chooses se next move,
means se minimizes estimated cost reach solution among neighbors
sn . problems uniform action costs, happen h(se ) lower equal
heuristic value neighbors sn . fact actually means
depression region search space longer exists, happen
heuristic values states originally depressed region updated (increased).
LRTA , update process may quite costly: worst case states
depression may need updated state may need updated several times.
Ishidas definition is, nonetheless, restrictive. fact, take account
costs actions needed move interior depression exterior.
closed region states may unrealistically low heuristic values even though heuristic
values interior greater ones border. propose intuitive
notion depression costs taken account. formal definition follows.
Definition 1 (Cost-sensitive heuristic depression) connected component states
cost-sensitive heuristic depression heuristic h iff state every
state s0 6 neighbor state D, h(s) < k(s, s0 ) + h(s0 ), k(s, s0 ) denotes
cost cheapest path starts s, traverses states D, ends s0 .
Cost-sensitive heuristic depressions better reflect regions agent controlled
algorithms LRTA get trapped. illustrate this, consider two 4-connected
grid-world problems Figure 2. Gray cells conform Ishida depression. union
yellow gray cells conform cost-sensitive heuristic depression. Suppose agents
initial position lower-right corner Ishida depression (C4 Figure 2(a),
C7 Figure 2(b)). Assume ties broken priorities, given
higher lower, are: down, left, up, right. initial state,
situation (a) situation (b), agent controlled LRTA visit every state
cost-sensitive heuristic depression reaching goal. Indeed, cells costsensitive depression adjacent obstacle visited exactly 3 times,
cells adjacent obstacle visited 2 times, agent escapes depression,
thus performance LRTA described linear function size
cost-sensitive depression.
interesting note problems like ones shown Figure 2, size
Ishida depression remains width grid varies. Thus, size
534

fiAvoiding Escaping Depressions Real-Time Heuristic Search

1

B
C

2

3

4

5
3

1

6

7

6

5

4

2

6

5

4

3

1

5

4

3

2

0 G


B
C

2

3

4

5

6

7

8

10

9

8

7

6

5

4

9

8

7

6

5

4

3

1

8

7

6

5

4

3

2

0 G

(a)

3

9
2

(b)

Figure 2: 4-connected grid-like search space unitary costs. Black cells obstacles.
cell G goal cell. Cells show h-value (Manhattan distance).
Ties broken giving priority movement, left, up,
right. initial position agent situation (a) C4, cells
visited agent controlled LRTA are: C3, C2, C1, B1, B2, B3, B4, C4,
C3, B3, C3, C2, B2, C2, C1, B1, C1, B1, B2, B3, B4, A4, A5, A6, B6, C6.
solution found (b) analogous.

Ishida depression correlated performance LRTA . hand,
size cost-sensitive heuristic depression predictor cost solution

5. Depression Avoidance
major issue solving real-time search problems presence heuristic depressions.
State-of-the-art algorithms able deal problem essentially extensive
learning and/or extensive lookahead. lookahead, chances state
outside depression eventually selected move to. hand, learning
heuristic values several states time, fewer movements might needed order
raise heuristic values states interior depression high enough make
disappear. such, LSS-LRTA , run high value lookahead parameter
exits depressions quickly LRTA run search depth equal 1 two
reasons: (1) heuristic function increases states quickly (2)
high value lookahead parameter sometimes possible escape
depression one step.
Besides already discussed LSS-LRTA RTAA , many algorithms described literature capable extensive lookahead learning. lookahead
ability LRTS (Bulitko & Lee, 2006), TBA (Bjornsson et al., 2009) parametrized.
using algorithms LRTA (k) (Hernandez & Meseguer, 2005), PLRTA (Rayner
et al., 2007) LRTALS (k) (Hernandez & Meseguer, 2007) one increase number
states updated based parameter. None algorithms however aware depressions; design simply allows escape ability lookahead,
learning, combination both. Later, Section 9, give detailed overview
related work.
improve search performance algorithms avoid depressions, principle call
depression avoidance. Depression avoidance simple principle dictates search
535

fiHernandez & Baier

guided away states identified heuristic depression.
many ways one could conceive implementation principle real-time
heuristic search algorithm. present two alternative realizations principle
within state-of-the-art RTAA LSS-LRTA algorithms. result, propose
four new real-time search algorithms, good theoretical properties.
5.1 Depression Avoidance via Mark-and-Avoid
subsection presents first possible realization depression avoidance call
mark-and-avoid. strategy, extend update phase mark states
prove belong heuristic depression. modify selection best state
(i.e., Extract-Best-State() function) select states marked; i.e., states
yet proven part depression.
aLSS-LRTA version LSS-LRTA avoids depressions via mark-and-avoid.
obtained implementing Update() function using Algorithm 6 implementing
Extract-Best() function Algorithm 7. two differences
update procedure LSS-LRTA s. first initialization updated flag
Lines 23. second Line 7, sets s.updated true heuristic value h
changes result update process. following section, formally prove
means inside cost-sensitive heuristic depression (Theorem 5).
Algorithm 6: Modified Dijkstra Procedure used aLSS-LRTA .
1
2
3
4
5
6
7
8
9
10
11
12

procedure ModifiedDijkstra ()
first run
s.updated f alse
/* initialization update flag */
Closed h(s)
Closed 6=
Extract minimum h-value Open
h(s) > h0 (s) s.updated = true
Closed delete Closed
s0 Succ(s0 )
s0 Closed h(s0 ) > c(s0 , s) + h(s)
h(s0 ) c(s0 , s) + h(s)
s0 6 Open Insert s0 Open

select next state snext , aLSS-LRTA chooses state lowest f -value
Open marked depression. state exist,
algorithm selects state lowest f -value Open, like LSS-LRTA would do.
Depending implementation, worst-case complexity new selection mechanism may different Algorithm 3. Indeed, Open list implemented
binary heap (as case), worst-case complexity Algorithm 7 O(N log N )
N size Open. heap ordered f -value.
hand worst-case complexity Algorithm 3 using binary heaps O(1).
experimental results observe, however, significant degradation performance
due factor.
536

fiAvoiding Escaping Depressions Real-Time Heuristic Search

Algorithm 7: Selection next state used aLSS-LRTA aRTAA
1
2
3
4
5
6

function Extract-Best-State ()
Open contains s.updated = f alse
argmins0 Opens0 .updated=f alse g(s0 ) + h(s0 )
else
argmins0 Open g(s0 ) + h(s0 )
return ;

Example Figure 3 shows example illustrates difference LSS-LRTA
aLSS-LRTA lookahead parameter equal two. 4 search episodes,
observe aLSS-LRTA avoids depression, leading agent position 2
steps closer goal LSS-LRTA .
Algorithm 8: aRTAA Update Procedure
1
2
3
4
5
6
7

procedure Update ()
first run
s.updated f alse
f f -value best state Open
Closed
h(s) f g(s)
h(s) > h0 (s) s.updated true

/* initialization update flag */

aLSS-LRTA reference, straightforward implement mark-and-avoid
strategy RTAA . update phase resulting algorithm, aRTAA , like
RTAA extended mark states depression (Algorithm 8). selection
best state move done way aLSS-LRTA , i.e., Algorithm
7. result aRTAA version RTAA aims avoiding depressions using
mark-and-avoid.
5.2 Depression Avoidance via Move-to-Border
Move-to-border finely grained implementation depression avoidance. illustrate differences, consider that, lookahead, state frontier
local search space s.updated false. Intuitively, situation
agent trapped heuristic depression. case, aLSS-LRTA behaves exactly
LRTA since states search frontier marked. Nevertheless, cases,
would like movement agent still guided away depression.
situations states frontier local search space already
proven members depression, move-to-border strategy attempts move
state seems closer border depression. next state, strategy chooses
state best f -value among states whose heuristic changed least.
intuition behind behavior follows: assume (s) difference actual
cost reach solution state initial heuristic value state s. Then,
s1 state close border depression s2 state farther away
border deep interior D, (s2 ) (s1 ), heuristic s2
537

fiHernandez & Baier

LSS-LRTA
1

2

3

4

1



Iteration 1



2

G

3

1

C


2

1 5 0
3
2 7 1
5
4

4

3
5
5
6

C 4
G

3



4

1

6

2

G

3

4

1 6

B 5

4 1 6
6 5 7
6 2 8
6

2

0 4 1 6

C 4 6 5 7

3

1 6 2 8
6

G

5

G

1
6
0
5
1
6
2
5

4

1





B

B
1 7 2 9
7
0 5 1 7
5 7 6 8

C 6


3


1
5
0
4
1
5

1

Iteration 4

2

G

B
1 5 0 3
4
3 5
2 7 1 5
5
4 6


B





1

Iteration 3

2 6 1 4
3
1 4 0 2
3 5 2 4

4

B



4

C 4



C

3

B
2 6 1 4
4
3
1 4 0 2
3 5 2 4

1

Iteration 2

2



B
C

aLSS-LRTA

C


2

G

3

4

7
5
7
7 2 9
7
7
6

G

Figure 3: First 4 iterations LSS-LRTA (left) aLSS-LRTA (right) lookahead
equal 2 4-connected grid world unitary action costs, initial
state D2, goal D4. Numbers cell corners denote g-value (upper
left), f -value (upper right), h-value (lower left), new h-value expanded
cell update (lower right). cells closed list show
four numbers. Cells generated expanded (i.e., Open) show three
numbers, since h-values updated. Triangles (N) denote states
updated flag set true search episode. heuristic used
Manhattan distance. assume ties broken choosing first right
bottom left top adjacent cell. position agent
given dot. grid cell shaded (gray) blocked cell agent
sensed yet. grid cell black blocked cell agent
already sensed. best state chosen move agent lookahead search
pointed arrow.

538

fiAvoiding Escaping Depressions Real-Time Heuristic Search

aLSS-LRTA
1
5

Iteration 1

2

3

4

B

C

C




E

G

5

2

3

4

4 6 5 7 6 8

B

4 6 5 7

C

3 7 4 8



5

2

3

4 6 5 7

C

3 7 4 8



3

4

B
C

2
8
2
7
4
8

G

1

2

3

4

2
2
4 6 5 7 6
2
4 6 5
4
3 7 4

5
B
C

2
8
2
7
4
8



E

E

G

1
5

2

3

4

4 6 5 7 6 8

B

4 8 5 7

C

3 7 4 8



G

1

2

3

4

2
2
4 6 5 7 6
4
4 8 5
4
3 7 4

5
B
C

2
8
2
7
4
8



E

E

G

1

2

3

4

4 6 5 7 6 8

B

4 8 5 9

C

3 7 4 8


E

2

2
2
4 6 5 7 6
2
4 6 5
4
3 7 4

5

4

4 6 5 7 6 8

B

Iteration 18

4

G

1

E

G

1

5

3



E

Iteration 17

2
2
4 6 5

5

4 6 5

1

Iteration 16

1

B

E

Iteration 15

daLSS-LRTA

G

1
5
B
C

2

3

2
2
4 6 5 7 6
4
4 8 5
4
3 7 4

4
2
8
4
9
4
8


E

G

G

Figure 4: Iterations 1 1518 aLSS-LRTA (left) daLSS-LRTA (right)
lookahead equal 1 4-connected grid, analogous previous example,
objective cell E2. iterations 1 14 algorithms execute
way. Numbers cells correspond initial h-value (lower-left), current
h-value (lower-right), difference two amounts (upper-right).
Triangles (N) denote states whose heuristic value updated.

539

fiHernandez & Baier

imprecise s1 . execution time, h estimate actual cost
reach solution.
daLSS-LRTA daRTAA differ, respectively, LSS-LRTA RTAA
selection next state move (i.e., function Extract-Best()) implemented
via Algorithm 9. Note worst case complexity algorithm O(N log N ),
N size Open binary heaps used.
Algorithm 9: Selection next state daRTAA daLSS-LRTA .
1
2
3
4
5
6
7
8

function Extract-Best-State ()
min
Open 6= min 6= 0
Remove state sb smallest f -value Open
h(sb ) h0 (sb ) < min
sb
min h(sb ) h0 (sb )
return

Figure 4 illustrates differences aLSS-LRTA daLSS-LRTA . algorithms execute way if, lookahead phase, state Open whose
heuristic value updated. However, case (i.e.,
algorithm trapped depression), daLSS-LRTA move seems closer
border depression. example Figure 4, iteration 15, algorithm
chooses B4 instead C3 since B4 state h-value changed least.
iteration 18, daLSS-LRTA move cells less learning carried
thus exit depression quickly.
new algorithms presented section closely related. Table 2 shows
schematic view different components algorithm, complexity
involved algorithms.

6. Theoretical Analysis
section analyze theoretical properties algorithms propose.
prove algorithms also satisfy desirable properties hold
ancestors. start presenting theoretical results proven using existing
proofs available literature; among them, show consistency
heuristic maintained algorithms run time. continue results
need different proofs; particular, termination convergence optimal solution.
before, use hn refer value variable h start iteration n (h0 ,
thus, denotes heuristic function given parameter algorithm). Similarly,
cn (s, s0 ) cost arc s0 . Finally, kn (s, s0 ) denotes cost
optimal path s0 traverses nodes Closed ending s0
respect cost function cn .
first establish h initially consistent, h non-decreasing time.
important property since means heuristic becomes accurate
time.

540

fiAvoiding Escaping Depressions Real-Time Heuristic Search

Algorithm
LSS-LRTA
aLSS-LRTA
daLSS-LRTA
RTAA
aRTAA

daRTAA

Update Phase
Algorithm
Time (heaps)
Modified Dijkstra
(Algorithm 4)
Modified Dijkstra
Marking (Algorithm 6)
Modified Dijkstra
(Algorithm 4)

O(M log )

Update

best
f -value
(Algorithm 5)
Update

best
f -value
plus
marking
(Algorithm 8)
Update

best
f -value
(Algorithm 5)

O(N )

O(M log )
O(M log )

Next State Selection
Algorithm
Time (heaps)
Best state Open
(Algorithm 3)
Best
unmarked
state

Open
(Algorithm 7)
State Open
changed
least (Algorithm 9)
Best state Open
(Algorithm 3)

(1)
O(L log L)
O(L log L)
(1)

O(N )

Best
unmarked
state

Open
(Algorithm 7)

O(L log L)

O(N )

State Open
changed
least (Algorithm 9)

O(L log L)

Table 2: Procedures used update phase selection next state
algorithms discussed paper. Worst-case time complexity
procedure included assuming Open list implemented binary heap.
corresponds |Open| + |Closed|, N equal |Closed|, L |Open|.

541

fiHernandez & Baier

Theorem 1 hn consistent respect cost function cn , hn+1 (s) hn (s)
n along execution aLSS-LRTA daLSS-LRTA .
Proof: Assume contrary, i.e., state hn (s) > hn+1 (s). State
must Closed, since states whose h-value may updated. such,
Proposition 1, hn+1 (s) = kn (s, sb ) + hn (sb ), state sb Open.
However, since hn (s) > hn+1 (s), conclude that:
hn (s) > kn (s, sb ) + hn (sb ),
contradicts fact hn consistent. thus conclude h-value
cannot decrease.

Theorem 2 hn consistent respect cost function cn , hn+1 (s) hn (s)
n along execution aRTAA daRTAA .
Proof: Assume contrary, i.e., state hn (s) > hn+1 (s). State
must Closed, since states whose h-value may updated.
update rule set value hn+1 (s) f (s0 ) g(s) s0 Open, i.e.,
hn+1 (s) = f (s0 ) g(s) = g(s0 ) + hn (s0 ) g(s).
since hn (s) > hn+1 (s), that:
hn (s) > g(s0 ) + hn (s0 ) g(s).
Reordering terms, obtain that:
hn (s) + g(s) > g(s0 ) + hn (s0 ),
means f -value greater f -value s0 . known however
, run consistent heuristic, expand nodes non-decreasing f -values.
conclude, thus, s0 must expanded s. Since s0 Open,
cannot Closed, contradicts initial assumption. thus conclude
h-value cannot decrease.

Theorem 3 hn consistent respect cost function cn , hn+1 consistent
respect cost function cn+1 along execution aLSS-LRTA daLSS-LRTA .
Proof: Since update procedure used aLSS-LRTA , daLSS-LRTA LSS-LRTA
update variable h exactly way, proof Koenig Sun (2009)
reused here. However, provide rather simpler proof Section B.1.

Theorem 4 hn consistent respect cost function cn , hn+1 consistent
respect cost function cn+1 along execution aRTAA daRTAA .
542

fiAvoiding Escaping Depressions Real-Time Heuristic Search

Proof: Since update procedure used aRTAA , daRTAA RTAA update variable
h exactly way, re-use proof Theorem 1 Koenig Likhachev
(2006b) establish result. provide however complete proof Section B.2

objective mark-and-avoid strategy stay away depressions.
following theorems establish that, indeed, state marked aLSS-LRTA
aRTAA state heuristic depression current heuristic.
Theorem 5 Let state s.updated switches false true iterations n n + 1 execution aLSS-LRTA aRTAA h initially
consistent. cost-sensitive heuristic depression hn .
Proof: first prove result case aLSS-LRTA . proof aRTAA
similar found Section B.3.
Let maximal connected component states connected that:
1. states Closed call iteration n,
2. state sd hn+1 (sd ) > hn (sd ).
Let s0 state boundary D. first show hn (s0 ) = hn+1 (s0 ).
definition s0 either Closed Open. s0 Closed then, since s0 6 D, must
case s0 satisfy condition 2 definition D, hence hn+1 (s0 ) hn (s0 ).
However, since heuristic non-decreasing (Theorems 2 1), must hn (s0 ) =
hn+1 (s0 ). hand, s0 Open, heuristic value changed thus
also hn (s0 ) = hn+1 (s0 ). established, hence, hn (s0 ) = hn+1 (s0 ).
ready establish result: cost-sensitive heuristic depression
hn .
Let sd state D. distinguish two cases.
Case 1: s0 Closed. Then, Proposition 1,
hn (s0 ) = kn (s0 , sb ) + hn (sb ),

(7)

sb Open. hand, since heuristic value increased
sd , hn (sd ) < hn+1 (sd ) = mins0b Open kn (sd , s0b ) + h(s0b ); particular, hn (sd ) <
kn (sd , sb ) + hn (sb ). Since kn (sd , sb ) optimal cost go sd sb , kn (sd , sb )
kn (sd , s0 ) + kn (s0 , sb ). Substituting kn (sd , sb ) previous inequality have:
hn (sd ) < kn (sd , s0 ) + kn (s0 , sb ) + hn (sb ).

(8)

substitute right-hand side (8) using (7), obtain
hn (sd ) < kn (sd , s0 ) + hn (s0 ).
Case 2: s0 Open. Proposition 1 hn+1 (sd ) kn (sd , s0 ) + hn (s0 ).
Moreover, definition D, hn+1 (sd ) > hn (sd ). Combining two
inequalities, obtain:
hn (sd ) < kn (sd , s0 ) + hn (s0 ).
543

fiHernandez & Baier

cases, proved hn (sd ) < kn (sd , s0 ) + hn (s0 ), sd s0
boundary D. conclude cost-sensitive heuristic depression hn , finishes
proof.

turn attention termination. prove solution exists,
found algorithms. prove result, need two intermediate
lemmas. first establishes algorithm moves best state Open,
h-value state changed h-value current state.
Formally,
Lemma 1 Let s0 state smallest f -value Open lookahead phase
aLSS-LRTA , daLSS-LRTA , aRTAA , daRTAA , initialized consistent
heuristic h. Then,
hn+1 (scurrent ) h0 (scurrent ) hn (s0 ) h0 (s0 ).
Proof: Indeed, Propositions 1 2:
hn+1 (scurrent ) = kn (scurrent , s0 ) + hn (s0 )

(9)

Let optimal path found connecting scurrent s0 . Let K0 denote cost
path respect cost function c0 . Given heuristic h0 consistent
respect graph cost function c0 , h0 (scurrent ) K0 + h0 (s0 )
re-written as:
h0 (scurrent ) K0 h0 (s0 ).
(10)
Adding (10) (9), obtain:
hn+1 (scurrent ) h0 (s) kn (scurrent , s0 ) K0 + hn (s0 ) h0 (s0 ).

(11)

Now, cn increase, cost iteration n, kn (scurrent , s0 ), strictly
greater cost iteration 0, K0 . words, amount kn (scurrent , s0 )K0
positive removed right-hand side (11) produce:
hn+1 (scurrent ) h0 (s) hn (s0 ) h0 (s0 ),
desired result.



second intermediate result prove termination following lemma.
Lemma 2 Let n iteration aLSS-LRTA , daLSS-LRTA , aRTAA ,
daRTAA , initialized consistent heuristic h. snext set equal
state s0 least f -value Open, then:
hn (s0 ) h0 (s0 ) > hn (snext ) h0 (snext ).
Proof: Indeed, aRTAA aLSS-LRTA run, means snext snext
marked updated, means hn (snext ) = h0 (snext ), equivalently,
hn (snext ) h0 (snext ) = 0. Moreover, best state Open, s0 , chosen hence
544

fiAvoiding Escaping Depressions Real-Time Heuristic Search

must s0 .updated = true, means h(s0 ) h0 (s0 ) > 0. obtain
hn (s0 ) h0 (s0 ) > hn (snext ) h0 (snext ).
case daRTAA daLSS-LRTA direct condition Line 5 Algorithm 9. Hence, also true hn (s0 ) h0 (s0 ) > hn (snext ) h0 (snext ).

ready prove main termination result.
Theorem 6 Let P undirected finite real-time search problem solution
exists. Let h consistent heuristic P . Then, aLSS-LRTA , daLSS-LRTA ,
aRTAA , daRTAA , used h, find solution P .
Proof: Let us assume contrary. two cases algorithms
return solution: (a) return solution Line 5 (Algorithm 1), (b)
agent traverses infinite path never hits solution node.
(a) assume algorithms state call . reaches
Line 5 (Algorithm 1), open list empty, means agent exhausted
search space states reachable without finding solution; contradiction
fact solution node reachable fact search problem
undirected.
(b) assume agent follows infinite path . Observe
infinite execution, iterationsay, Rthe value variable c increase
anymore. states around states observed past.
consequence, iteration R agent traverses complete path identified
lookahead procedure (Line 8 Algorithm 1).
second important observation that, iteration R, value h states
finite cannot increase anymore. Indeed, Theorems 4 3, h remains consistent
hence admissible, means h(s) bounded actual cost reach
solution s, . Moreover, since c change anymore, call
update function change value h(s), every .
ready finish proof. Consider algorithm executes past iteration
R. Since path infinite state space finite, iteration R
algorithm decides go back previously visited state. such, going assume
agent visits state t0 selects move trough states t1 t2 tr1 tr t0 . Since
heuristic change anymore, simply denote h, regardless iteration
number. distinguish two cases.
Case 1 agent always decides move best state Open, s0 , hence
depending algorithm usedby Proposition 1 2, h(s) = k(s, s0 )+h(s0 ),
implies h(s) > h(s0 ), since action costs positive. implies that:
h(t0 ) > h(t1 ) > h(t2 ) > . . . > h(tn ) > h(t0 ),
contradiction; cannot case h(t0 ) > h(t0 ).
Case 2 least once, agent move best state Open. Without loss
generality, assume happens once, state ti < r. Let
state smallest f -value Open lookahead carried ti .
545

fiHernandez & Baier

Lemma 1, write following inequalities.
h(t0 ) h0 (t0 ) h(t1 ) h0 (t1 ),
..
.
h(ti1 ) h0 (ti1 ) h(ti ) h0 (ti ),
h(ti ) h0 (ti ) h(t ) h0 (t ),
h(ti+1 ) h0 (ti+1 ) h(ti+2 ) h0 (ti+2 ),
..
.
h(tr ) h0 (tr ) h(t0 ) h0 (t0 ).
Let set containing inequalities. since state ti algorithm
decides move ti+1 instead , use Lemma 2 write:
hn (t ) h0 (t ) > hn (ti+1 ) h0 (ti+1 ).

(12)

inequalities together (12) entail h(t0 ) h0 (t0 ) > h(t0 ) h0 (t0 ),
contradiction.
cases derive contradictions hence conclude algorithm cannot enter
infinite loop thus finds solution.

turn attention convergence. literature often analyzes properties
real-time heuristic search run sequence trials (e.g., Shimbo &
Ishida, 2003). trial characterized running algorithm start state
problem solved. heuristic function h resulting trial n used feed
algorithms h variable trial n + 1.
stating convergence theorem prove result related h increases
successive iterations trials. Indeed, iteration search algorithms
potentially increases h, making informed. following result implies
improvement cannot infinitesimal.
Lemma 3 Let P finite undirected search problem, let Sol set states P
solution reached. Let n iteration aLSS-LRTA , daLSSLRTA , aRTAA , daRTAA . hn (s) take finite number values,
every P .
Proof: Given Proposition 1, along execution algorithms LSS-LRTA
family, simple prove induction n that:
hn (s) = K + h0 (s000 ),
n, K sum costs 0 arcs P cost function cn .
hand, given update rule algorithms RTAA family
(e.g., Line 6 Algorithm 8),
hn (s) = K K 0 + h0 (s000 ),
546

fiAvoiding Escaping Depressions Real-Time Heuristic Search

n, K K 0 correspond sum costs arcs P cost
function cn .
Since finite problems finite number arcs, quantities referred K
K 0 take finite number values. implies hn (s), P ,
take finite number values, concludes proof.

show h converges sequence trials, solution found h
optimal.
Theorem 7 Let P undirected finite real-time search problem solution
exists. Let h consistent heuristic P . initialized h, sequence trials
aLSS-LRTA , daLSS-LRTA , aRTAA , daRTAA , converges optimal
solution.
Proof: First, observe since heuristic admissible, remains admissible
number trials run. consequence Theorems 3 4. Hence, every
state goal state reached, h(s) bounded (finite
amount) h (s).
hand, Lemma 3, h-values states solution reachable
increase finite number times. sequence trials value h thus
converges; i.e., least one complete trial, h(s) changed, every P .
also assume trial, value c change either, since h
converges, path states always followed thus new cost increases
made.
Let us focus run algorithms h c change.
Observe means hn (s) = h0 (s) n (recall h0 heuristic given
input algorithm). Independent algorithm used, implies algorithm
always moves best state Open. Let s1 . . . sm sequence states
assigned snext execution (sm thus goal state). Observe since c
change along execution, states s1 . . . sm actually visited agent. Depending
algorithm used, Proposition 1 2, know:
h(si ) = k(si , si+1 ) + h(si+1 ),

{0, . . . , 1},

(13)

k(si , si+1 ) cost optimal path si si+1 . Since heuristic
consistent
Ph(sm ) = 0, thus family equations (13) conclude h(s0 )
equal m1
i=0 k(si , si+1 ), corresponds cost path traversed agent.
know h also admissible, so:
h(s0 ) =

m1
X

k(si , si+1 ) h (s0 ).

i=0

Since h (s0 ) cost optimal solution, conclude path found optimal
cost.

547

fiHernandez & Baier

Figure 5: Upper row: four maze maps used test approach; 512512 cells.
Lower row: 4 12 game maps used. first two come Dragon
Age: Origins; remaining 2 StarCraft.

7. Empirical Evaluation
evaluated algorithms solving real-time navigation problems unknown environments. LSS-LRTA RTAA used baseline comparisons. fairness,
used comparable implementations use underlying codebase. example,
search algorithms use implementation binary heaps priority queues
break ties among cells f -values favor cells larger g-values,
known good tie-breaking strategy.
carried experiments two sets benchmarks: deployed game maps
mazes. used twelve maps deployed video games carry experiments.
first six taken game Dragon Age, remaining six taken game
StarCraft. maps retrieved Nathan Sturtevants pathfinding repository.1
addition, used four maze maps taken HOG2 repository.2 shown
Figure 5. results obtained using Linux machine Intel Xeon CPU running
2GHz 12 GB RAM.
maps regarded undirected, eight-neighbor grids.
Horizontal vertical movements cost 1, whereas diagonal movements cost 2. used octile distance
(Sturtevant & Buro, 2005) heuristic.
1. http://www.movingai.com/ http://hog2.googlecode.com/svn/trunk/maps/. Dragon
Age used maps brc202d, orz702d, orz900d, ost000a, ost000t ost100d size 481530, 939718,
656 1491 969 487, 971 487, 1025 1024 cells respectively. StarCraft, used maps
ArcticStation, Enigma, Inferno JungleSiege, Ramparts WheelofWar size 768 768, 768 768,
768 768, 768 768, 512 512 768 768 cells respectively.
2. http://hog2.googlecode.com/svn/trunk/maps/

548

fiAvoiding Escaping Depressions Real-Time Heuristic Search

LSS-LRTA* Variants: Cost vs Time per Episode (Games)
LSS-LRTA*
aLSS-LRTA*

500,000

daLSS-LRTA*

100,000

10,000

0

0.05

0.1

0.15

0.2

0.25

LSS-LRTA* Variants: Cost vs Time per Episode (Mazes)
5,500,000
Average Solution Cost (log-scale)

Average Solution Cost (log-scale)

1,000,000

LSS-LRTA*
aLSS-LRTA*

2,000,000

0.3

Time per Planning Episode msec

daLSS-LRTA*

500,000

100,000

0

0.05

0.1

0.15

0.2

0.25

Time per Planning Episode msec

(a)

(b)

Figure 6: Plots showing average solution cost found LSS-LRTA variants versus
average planning time per episode, measured milliseconds. (a) shows stats
game-map benchmarks, (b) mazes benchmarks. Times shown
milliseconds. Costs shown log-scale.

evaluation ran algorithms 10 different lookahead values. map,
generate 500 test cases. test case choose start goal cells randomly.
presentation results sometimes use concept improvement factor.
say improvement factor algorithm respect B terms
average solution cost n, means average produces solutions n times
cheaper ones found B.
Next describe different views experimental data shown plots
tables. continue draw experimental conclusions.
7.1 Analysis LSS-LRTA Variants
section analyzes performance LSS-LRTA , aLSS-LRTA daLSS-LRTA .
Figure 6 shows two plots average solution costs versus average planning time
per episode three algorithms games mazes benchmarks. Planning time per
planning episode accurate measure effort carried algorithms.
Thus plots illustrate solution quality varies depending effort
algorithm carries out.
Regardless search effort, observe aLSS-LRTA slightly consistently outperforms LSS-LRTA solution cost. games benchmarks observe equal
search effort, aLSS-LRTA produces average improvement factors 1.08 1.20
terms solution cost. mazes, hand, improvement factors 1.04
1.25. games, largest improvements observed lookahead parameter
(and hence search time per episode) rather small. Thus aLSS-LRTA advantage
LSS-LRTA clearly observed tighter time constraints imposed
planning episodes.
549

fiHernandez & Baier

Often times results real-time search literature presented form tables,
search performance statistics reported per lookahead value. provide
tables appendix paper (Tables 5 6). important observation
drawn tables time per planning episode LSS-LRTA aLSS-LRTA
similar fixed lookahead value; indeed, time per planning episode aLSSLRTA slightly larger LSS-LRTA . interesting since shows
worst-case asymptotic complexity seem achieved aLSS-LRTA
(cf. Table 2).
experimental results show daLSS-LRTA refined mechanism escaping depressions better aLSS-LRTA . given value search effort,
daLSS-LRTA consistently outperforms aLSS-LRTA significant margin solution
cost games mazes. daLSS-LRTA also outperforms aLSS-LRTA total search
time, i.e., overall time spent searching solution found. Details found
Tables 5 6. search effort algorithm small, daLSS-LRTA average
solution quality substantially better aLSS-LRTA s; improvements actually
close order magnitude.
daLSS-LRTA consistently outperforms LSS-LRTA significant margin total
search time solution quality, independent search effort employed. terms
solution cost daLSS-LRTA produces average improvement factors respect LSSLRTA 1.66 order magnitude game benchmarks, produces
average improvement factors 1.49 order magnitude mazes benchmarks. fixed lookahead (see Tables 5 6 specific numbers), time spent
per planning episode daLSS-LRTA larger time spent per planning episode
LSS-LRTA daLSS-LRTA makes heap percolations LSS-LRTA . However, small values lookahead parameter, daLSS-LRTA obtains better solutions
using less time per planning episode LSS-LRTA used much larger lookahead.
example, game maps, lookahead parameter equal 32, daLSS-LRTA obtains
better solutions LSS-LRTA lookahead parameter equal 128, requiring,
average, 2.6 times less time per planning episode. mazes, lookahead parameter
equal 16, daLSS-LRTA obtains better solutions LSS-LRTA lookahead
parameter equal 64, requiring, average, 2.4 times less time per planning episode.
low values lookahead parameter (i.e. limited search effort) daLSS-LRTA
obtains better solutions less time per planning episode aLSS-LRTA used
much larger lookahead. example, game maps, lookahead parameter equal
1, daLSS-LRTA obtains better solutions aLSS-LRTA lookahead parameter
equal 16, requiring, average, 14.1 times less time per planning episode.
hand, mazes lookahead parameter equal 1, daLSS-LRTA obtains better solutions aLSS-LRTA lookahead parameter equal 16, requiring, average,
11.6 times less time per planning episode.
fixed lookahead (see Tables 5 6), time taken daLSS-LRTA per planning
episode larger time taken aLSS-LRTA per planning episode. increase
explained because, average, daLSS-LRTA open list grows larger
aLSS-LRTA . due fact that, benchmarks tried, daLSS-LRTA
tends expand cells less obstacles around aLSS-LRTA does. result,
550

fiAvoiding Escaping Depressions Real-Time Heuristic Search

RTAA* Variants: Cost vs Time per Episode (Games)
RTAA*
aRTAA*

500,000

daRTAA*

100,000

10,000
0

0.02

0.04

0.06

0.08

RTAA* Variants: Cost vs Time per Episode (Mazes)
5,500,000
Average Solution Cost (log-scale)

Average Solution Cost (log-scale)

1,000,000

0.1

0.12

Time per Planning Episode msec

RTAA*
aRTAA*

2,000,000

daRTAA*

500,000

100,000

0

0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.1
Time per Planning Episode msec

(a)

(b)

Figure 7: Plots showing average solution cost found RTAA variants versus average planning time per episode. (a) shows stats game-maps benchmarks,
(b) mazes benchmarks. Costs shown log-scale.

daLSS-LRTA expands cells learning phase makes heap percolations
lookahead phase aLSS-LRTA .
Results show that, among LSS-LRTA variants, daLSS-LRTA algorithm
best performance. fact daLSS-LRTA clearly superior LSS-LRTA .
60,000 runs (12 maps 500 test cases 10 lookahead-values) game benchmarks,
daLSS-LRTA obtains better solution quality LSS-LRTA 69.9% cases,
tie 20.9% cases, LSS-LRTA obtains better-quality solution 9.2%
cases.
20,000 (4 maps 500 test cases 10 lookahead-values) runs mazes benchmarks, daLSS-LRTA obtains better solution quality LSS-LRTA 75.1%
cases, tie 3.3% cases, LSS-LRTA obtains better-quality solution
21.7% cases.
7.2 Analysis RTAA Variants
section analyze relative performance RTAA , aRTAA , daRTAA .
Figure 7 shows two plots average solution costs versus average effort carried
per search episode.
search effort, observe significant improvements aRTAA
RTAA . Indeed, small values average time per search episode aRTAA
improve solution quality upon RTAA . general, however, algorithms
seem similar performance.
hand, results show daRTAA mechanism escaping depressions
substantially better aRTAA . small values lookahead parameter (and hence reduced search effort), daRTAA obtains better solutions
variants used much larger lookahead. Indeed, limited search effort, daRTAA
551

fiHernandez & Baier

approximately order magnitude better two algorithms. example,
game maps, lookahead parameter equal 1, daRTAA obtains better solutions
aRTAA lookahead parameter equal 16, requiring, average, 10.4 times
less time per planning episode.
daRTAA substantially improves RTAA , among best real-time heuristic
search algorithms known date. game maps, daRTAA needs lookahead parameter 16 obtain solutions better RTAA lookahead parameter 64.
values, daRTAA requires 2.3 times less time per planning episode
RTAA .
results show daRTAA best-performing algorithm RTAA family.
60,000 runs game-map benchmarks, daRTAA obtains better solution quality
RTAA 71.2% cases, tie 20.5% cases, RTAA obtains
better-quality solution 8.3% cases. 20,000 runs mazes, daRTAA
obtains better solution quality RTAA 78.0% cases, tie 2.7%
cases, RTAA obtains better-quality solution 19.4% cases.
7.3 daLSS-LRTA Versus daRTAA
daRTAA , best performing algorithm among RTAA variants, also superior
daLSS-LRTA , best-performing algorithm LSS-LRTA variants. Figure 8 shows
average solution costs versus search effort, game maps mazes.
seen figure, lookahead parameter small (i.e., search effort
little), performance daRTAA daLSS-LRTA fairly similar. However,
search allowed per planning episode, daRTAA outperforms daLSS-LRTA .
example, games benchmarks, daRTAA , allowed spend 0.08 milliseconds per
episode, obtain solutions comparable daLSS-LRTA allowed
spend 0.18 millisecconds per episode.
Furthermore, slopes curves significantly favorable daRTAA
daLSS-LRTA . verified types benchmarks important since
speaks inherent superiority RTAA framework time per planning episode
relevant factor.
7.4 Analysis Disaggregated Data
performance real-time algorithms usually varies depending map used. illustrate algorithms perform different maps, Figure 9 shows improvement
solution cost daLSS-LRTA LSS-LRTA 4 game 4 maze benchmarks.
confirm improvements observed domains thus showing average values
representative daLSS-LRTA behavior individual benchmarks. Although aLSSLRTA daLSS-LRTA outperform LSS-LRTA average, specific cases
situation hold. notably, observe one maze benchmarks daLSS-LRTA improve significantly respect LSS-LRTA large
values lookahead parameter. discuss next section. Figure 10
shows also improvement factors daRTAA RTAA . plot, different
algorithms show similar relative performance relation LSS-LRTA variants.
552

fiAvoiding Escaping Depressions Real-Time Heuristic Search

Cost vs Time per Episode (Games)

Cost vs Time per Episode (Mazes)
1e+06
Average Solution Cost (log-scale)

Average Solution Cost (log-scale)

daRTAA*
daLSS-LRTA*

100,000

10,000

0

0.05

0.1

0.15

0.2

0.25

daRTAA*
daLSS-LRTA*

100000

0.3

0

0.05

Time per Planning Episode msec

0.1

0.15

0.2

0.25

Time per Planning Episode msec

(a)

(b)

Figure 8: Plots showing average solution cost found daRTAA daLSS-LRTA
versus average planning time per episode. (a) shows stats game-maps
benchmarks, (b) mazes benchmarks. Costs shown log-scale.

orz702d

10

maze512-16

orz900d

8
7
6
5

maze512-32

ArticStation

Cost Improvement Factor

Cost Improvement Factor

8

Enigma

7
6
5
4
3

maze512-4
maze512-8

4
3
2

1

2
0.01

0.03

0.06

0.09

0.12

0.15

Time Deadline per Planning Episode

0.01

0.03

0.06

0.09

0.12

0.15

Time Deadline per Planning Episode

Figure 9: Cost improvement factor daLSS-LRTA LSS-LRTA , game maps (left)
maze benchmarks (right). improvement factor equal n indicates
solution found algorithm n times cheaper one found
original algorithm.

553

fiHernandez & Baier

5
orz702d

maze512-16
8

ArticStation

Cost Improvement Factor

Cost Improvement Factor

orz900d
Enigma

4

3

2

maze512-32
maze512-4
maze512-8

6
5
4
3
2
1

0.01

0.03

0.06

0.09

0.12

0.15

Time Deadline per Planning Episode

0.01

0.03

0.06

0.09

0.12

0.15

Time Deadline per Planning Episode

Figure 10: Cost improvement factor daRTAA RTAA , game maps (left)
maze (right) benchmarks. improvement factor equal n indicates
solution found algorithm n times cheaper one found
original algorithm.

7.5 Worst-Case Experimental Analysis
Although algorithms perform resource-bounded computation per planning episode,
hard tune lookahead parameter way LRTA daLSSLRTA incur worst-case planning effort. time spent
extracting best state open list depends structure search space
expanded lookahead phase.
section set carry experimental worst-case analysis based
theoretical worst-case bound. bound obtained worst-case effort per planning
step follows. RTAA performs k expansions per planning episode, open list
could contain 8k states. state 8 neighbors.
worst case, effort spent adding states open list would 8k log 8k.
hand, daRTAA would make effort insert states open
list, would incur additional cost 8k log 8k, worst-case, remove states
open list. Therefore, worst-case scenario, given lookahead parameter equal
k, daRTAA make double effort RTAA makes parameter.
Based worst-case estimation, Figure 11 presents performance RTAA
variants, displacing RTAA curve lookahead factor 2. conclude
worst-case scenario daRTAA still clearly outperforms RTAA . Gains vary one order
magnitude, low values lookahead parameter, similar performance
lookahead parameter high.
remark, however, never observed worst-case practice. example,
game benchmarks, RTAA , used lookahead parameter 2k spends,
average 50% time per planning episode daRTAA used lookahead parameter
k.
554

fiAvoiding Escaping Depressions Real-Time Heuristic Search

0.1

1e+06

0.08

RTAA*(Lookahead * 2)

aRTAA*

aRTAA*

daRTAA*

daRTAA*
Average Cost (log-scale)

Average Time per Planning Episode

RTAA*(Lookahead * 2)

0.06

0.04

0.02

100000

10000
0

0

50

100

150

200

250

300

Lookahead

0

50

100

150

200

250

300

Lookahead

(a)

(b)

Figure 11: Plots showing average time per planning episode average solution cost
per lookahead parameter, adjusting performance RTAA using theoretical worst-case bound 2. such, RTAA , average cost reported
lookahead k actually corresponds cost obtained lookahead
2k. Costs shown log-scale.

8. Discussion
number aspects work deserve discussion. focus two
them. First, discuss setting evaluated work, focused
showing performance improvements first trial search priori unknown
domain, without considering settings. Second, discuss scenarios
algorithms may exhibit average performance improvements shown
previous section.
8.1 Experimental Setting: Unknown Environments, First Trial
algorithm tailored solving quickly search problem environment
initially unknown. setting several applications, including goal-directed navigation
unknown terrain (Koenig et al., 2003; Bulitko & Lee, 2006). also widely
used evaluate real-time heuristic search algorithms (e.g., Koenig, 1998; Hernandez &
Meseguer, 2005; Bulitko & Lee, 2006; Hernandez & Meseguer, 2007; Koenig & Sun, 2009).
hand, present evaluation algorithm environments
known priori. previous paper (Hernandez & Baier, 2011d), however,
showed aLSS-LRTA obtains similar improvements LSS-LRTA environment known. However, omit results known environments since RTAA
LSS-LRTA representative state art scenarios. Indeed, algorithms like TBA* (Bjornsson et al., 2009) outperform LSS-LRTA significantly.
immediately obvious incorporate techniques algorithms like TBA*.
present experimental results regarding convergence several successive
search trials. Recall setting, agent teleported initial location
555

fiHernandez & Baier

new search trial carried out. real-time search algorithmsours includedare
guaranteed eventually find optimal solution. algorithms particularly excel
setting. heuristic value fewer states updated, hence
heuristic values states search space converges slowly correct value.
such, generally trials needed converge.
Convergence performance important problems solved offline
real-time approaches may adequate computing approximation optimal
solution. case problem computing optimal policy MDPs using
Real-Time Dynamic Programming (Barto, Bradtke, & Singh, 1995). aware,
however, application deterministic search searching offline using realtime search would yield better performance using suboptimal search algorithms
(e.g., Richter, Thayer, & Ruml, 2010; Thayer, Dionne, & Ruml, 2011). Indeed, Wilt,
Thayer, Ruml (2010) concluded real-time algorithms, though applicable,
used solving shortest path problems unless need real-time action.
8.2 Bad Performance Scenarios
Although algorithms clearly outperform originators LSS-LRTA RTAA
average, possible contrive families increasingly difficult path-finding tasks
algorithms perform worse respective predecessors.
Consider example 4-connected grid-world scenario size 7n shown Figure 12.
goal agent reach state labeled G, starting S. Assume
furthermore solve problem run aRTAA aLSS-LRTA , lookahead
parameter equal 1, ties broken movement priority
movement. initial state algorithms determine initial
state (cell E3) heuristic depression thus update heuristic cell E3. Cell
E3 marked depression. Since cells D3 F3 heuristic
value ties broken favor upper cells, agent moved cell D3.
later iterations, algorithm prefer move cells updated
therefore agent go back state E3 unless currently D3 (at least) C3
also marked. However, agent go back D3 quickly. Indeed, visit
states right Wall 1 Wall 2 coming back E3. happens because,
algorithm executes, update mark visited states, never prefer
go back previously marked position unless current neighbors also marked.
situation, RTAA LSS-LRTA , run lookahead parameter 1
behave differently depending tie-breaking rules. Indeed, priority given
(highest), down, right, left (lowest), RTAA LSS-LRTA find
goal fairly quickly visit states right walls. Indeed,
since tie-breaking rules prefer move up, agent reaches cell A3 4 moves,
proceeds straight goal. situations, performance aRTAA
aLSS-LRTA made arbitrarily worse RTAA LSS-LRTA , n
increased.
quite different situation produced tie-breaking follows priorities given
(highest), right, down, left (lowest). case four algorithms visit
states right walls. Indeed, A3 reached, tie
556

fiAvoiding Escaping Depressions Real-Time Heuristic Search

1

2

3

4

5

6

7

8

n2 n1 n
...

B

...
Wall 1




E
F

G

...
...


...

Wall 2

C

...
...

G

Figure 12: situation relative performance LSS-LRTA aLSSLRTA changes depending value n. start state, G
goal. Ties broken favor upper cells.

h-value B3 A4. agent prefers moving A4, continues
moving right grid zig-zag fashion.
investigating executions da- algorithms maze512-4-0 benchmark
(performance shown Figures 9 10), believe lack improvement
particular benchmark explained situation described. benchmark
512 512 maze corridors 4-cell width. low lookahead values,
number updates high enough block corridors. such, low values
lookahead parameter increase performance still reasonably good.
lookahead increases, algorithm updates states one single iteration, and,
result, chances good paths may become blocked.
Interestingly, however, observe phenomenon mazes wider corridors
game maps. necessary condition block corridor leads solution
agent sufficient knowledge borders corridor. mazes
narrow corridors may happen relative ease, agent needs moves
travel opposite walls. grids corridors wide however, knowledge
existence obstacles (walls) hard obtain agent, and, thus, chances
updating blocking, corridor leads solution lower.
believe possible prove algorithms always better always
worse specific search space topologies. think, nevertheless, analysis
may hard carry out, practical significance may limited. Therefore
decided exclude scope work. hand, think
impressive performance exhibited algorithms many benchmarks sufficiently
strong favor using algorithms domains contain narrow corridors.

9. Related Work
Besides LSS-LRTA RTAA , number real-time search algorithms
used priori unknown environments. LRTA (k) LRTALS (k) (Hernandez &
Meseguer, 2005, 2007) two algorithms competitive LSS-LRTA capable
557

fiHernandez & Baier

learning heuristic several states time; states heuristic
learned independent expanded lookahead phase. may escape
heuristic depressions quickly LRTA , action selection mechanism
aware heuristic depressions. eLSS-LRTA preliminary version aLSS-LRTA
presented extended abstract (Hernandez & Baier, 2011a). outperformed
aLSS-LRTA average, usually becomes focused avoiding depressions.
algorithms designed order find good-quality solutions first
search trial. algorithms described literature designed different
objectives mind. example, RIBS (Sturtevant, Bulitko, & Bjornsson, 2010) realtime algorithm specifically designed converge quickly optimal solution. move
agent iterative-deepening search carried out. first solution
finds optimal. consequence, RIBS potentially requires time find one solution
LSS-LRTA does, optimal solution required RIBS likely outperform
LSS-LRTA run convergence. f -LRTA* (Sturtevant & Bulitko, 2011) another recent
real-time search algorithm builds upon ideas introduced RIBS, gcost states learned successive trials. good convergence performance,
needs computation per planning step LSS-LRTA .
Incremental methods, like D* (Stentz, 1995), D*Lite (Koenig & Likhachev, 2002),
Adaptive A* (Koenig & Likhachev, 2006a), Tree Adaptive A* (Hernandez, Sun, Koenig,
& Meseguer, 2011), search methods also allow solving goal-directed navigation
problems unknown environments. first-move delay required short, incremental A* methods cannot used since require compute complete solution
starting move. Real-time search remains applicable strategy task
limited time allowed per planning episode.
Less related work algorithms abide real-time search constraints
assume environment known advance sufficient time given prior
solving problem, allowing preprocessing. Examples LRTA (Bulitko, Lustrek,
Schaeffer, Bjornsson, & Sigmundarson, 2008) kNN-LRTA (Bulitko et al., 2010), tree
subgoaling (Hernandez & Baier, 2011b), real-time search via compressed path databases
(Botea, 2011).
Finally, concept cost-sensitive depression real-time search could linked
concepts used describe poor performance planning algorithms. example,
Hoffmann (2005, 2011) analyzed existence plateaus h+ , effective admissible
domain-independent planning heuristic, negatively affects performance
otherwise fast planning algorithms. Cushing, Benton, Kambhampati (2011) introduced
concept -traps related poor performance best-first search problems
action costs high variance. -traps areas search space connected
actions least cost. such, h-values states -traps considered
analysis. Although think existence cost-sensitive heuristic depressions
affect performance , exact relation performance
heuristic depressions seem obvious.
558

fiAvoiding Escaping Depressions Real-Time Heuristic Search

10. Summary Future Work
presented simple principle guiding real-time search algorithms away
heuristic depressions. proposed two alternative approaches implementing principle: mark-and-avoid move-to-border. first approach, states proven
depression marked update phase, avoided, possible,
deciding next move. second approach, algorithm selects next move
state seems closer border depression.
approaches implemented efficiently. Mark-and-avoid requires little
overhead, results almost negligible increment time per planning episode.
Move-to-border, hand, requires overhead per planning episode, but,
given time deadline per planning episode, able obtain best-quality solutions.
Experimentally, shown goal-directed navigation tasks unknown terrain, algorithms outperform predecessors RTAA LSS-LRTA . Indeed,
algorithms based move-to-borderdaLSS-LRTA daRTAA significantly
efficient LSS-LRTA RTAA , especially lookahead parameter small
value.
four algorithms proposed good properties: undirected, finite search spaces,
guaranteed find solution solution exists. Moreover, converge
optimal solution running number search trials.
Depression avoidance principle applicable real-time heuristic search algorithms. Indeed, think could easily incorporated LRTA (k), LRTALS (k),
P-LRTA* (Rayner et al., 2007). algorithms specialized mechanisms updating heuristic, mechanism select next state like LSS-LRTA
run lookahead parameter equal 1. think significant improvements could
achieved procedure select next movement changed daLSS-LRTA s.
also believe depression avoidance could incorporated multi-agent real-time search
algorithms (e.g., Knight, 1993; Yokoo & Kitamura, 1996; Kitamura, Teranishi, & Tatsumi,
1996).

11. Acknowledgments
thank JAIR reviewers provided extensive feedback helped improve
article significantly. also thank IJCAI-11, SoCS-11, AIIDE-11 anonymous
reviewers thoughtful insights earlier versions work. grateful
Cristhian Aguilera, helped running experiments. Carlos Hernandez
partly funded Fondecyt project #11080063. Jorge Baier partly funded
VRI-38-2010 grant Pontificia Universidad Catolica de Chile Fondecyt grant
number 11110321.

Appendix A. Additional Experimental Data
Tables 36 show average statistics LSS-LRTA , RTAA , 4 algorithms.
559

fiHernandez & Baier

LookAhead
parameter
1
2
4
8
16
32
64
128
256
512

Avg.
Cost
5,731,135
4,805,384
3,217,283
1,905,895
1,004,971
513,692
262,760
137,403
71,939
41,089

LookAhead
parameter
1
2
4
8
16
32
64
128
256
512

Avg.
Cost
5,165,062
4,038,347
2,746,638
1,504,379
859,669
455,023
239,484
129,765
67,346
38,939

k
1
2
4
8
16
32
64
128
256
512

Avg.
Cost
443,773
804,990
419,616
374,684
257,126
155,573
108,337
75,158
49,065
31,265

RTAA
# Planning
Total
Episodes
Time
5,307,571
2,174
3,885,684
2,410
2,147,060
2,321
954,571
1,912
353,707
1,338
127,555
927
46,777
661
18,787
521
9,012
475
5,973
530
aRTAA
# Planning
Total
Episodes
Time
4,785,257
2,798
3,260,134
2,981
1,832,375
2,829
755,334
2,034
305,372
1,458
114,089
992
43,497
699
18,478
559
9,108
506
6,172
567

daRTAA
# Planning
Total
Episodes
Time
415,327
208
689,014
575
321,418
502
260,163
801
148,616
864
66,818
697
34,119
626
17,686
568
10,370
590
6,954
652

Time per
Episode
0.0004
0.0006
0.0011
0.0020
0.0038
0.0073
0.0141
0.0277
0.0527
0.0888

Exp.
per ep.
1.0
2.0
4.0
8.0
16.0
32.0
63.9
126.3
237.8
397.4

Perc.
per ep.
5.9
9.1
16.8
33.2
67.8
145.6
331.8
816.5
2,016.6
4,101.6

Time
per ep.
0.0006
0.0009
0.0015
0.0027
0.0048
0.0087
0.0161
0.0303
0.0555
0.0918

Exp.
per ep.
1.0
2.0
4.0
8.0
16.0
32.0
63.9
126.3
237.5
399.4

Perc.
per ep.
10.6
18.9
34.0
61.5
113.3
216.0
440.6
988.9
2,272.5
4,394.9

Time
per ep.
0.0005
0.0008
0.0016
0.0031
0.0058
0.0104
0.0183
0.0321
0.0569
0.0937

Exp.
per ep.
1.0
2.0
4.0
8.0
16.0
32.0
63.8
126.2
239.3
408.9

Perc.
per ep.
10.5
27.3
58.5
129.4
261.1
476.7
854.8
1,536.7
2,920.9
5,074.1

Table 3: Average results RTAA variants mazes. given lookahead parameter value,
report average solution cost (Avg. Cost), average number planning episodes
(# Planning Episodes), total runtime (Total Time), average runtime per search episode
(Time per Episode), average number expansions per episode (Exp. per ep.), average
number percolations per planning episode (Perc. per ep.). times reported
milliseconds.

560

fiAvoiding Escaping Depressions Real-Time Heuristic Search

LookAhead
parameter
1
2
4
8
16
32
64
128
256
512

Avg.
Cost
1,146,014
919,410
626,623
363,109
188,346
95,494
48,268
25,682
13,962
7,704

LookAhead
parameter
1
2
4
8
16
32
64
128
256
512

Avg.
Cost
958,795
763,367
516,545
299,786
151,737
81,695
42,883
23,217
12,510
6,892

k
1
2
4
8
16
32
64
128
256
512

Avg.
Cost
109,337
88,947
74,869
62,400
41,145
29,469
18,405
11,924
7,921
5,205

RTAA
# Planning
Total
Episodes
Time
1,058,265
448
747,824
475
422,389
469
184,753
384
67,652
269
24,609
193
9,138
146
3,854
126
1,941
126
1,220
132

aRTAA
# Planning
Total
Episodes
Time
885,506
549
621,438
598
348,785
569
154,037
445
55,706
290
21,533
210
8,357
157
3,631
134
1,845
129
1,178
133
daRTAA
# Planning
Total
Episodes
Time
102,616
53
79,951
66
62,664
102
48,838
165
28,453
199
16,857
229
8,152
196
3,908
158
2,116
149
1,311
145

Time per
Episode
0.0004
0.0006
0.0011
0.0021
0.0040
0.0078
0.0159
0.0326
0.0647
0.1078

Exp.
per ep.
1.0
2.0
4.0
8.0
16.0
32.0
63.9
126.4
236.8
377.6

Perc.
per ep.
6.1
9.4
17.3
34.1
70.1
152.9
361.3
932.3
2,351.8
4,616.7

Time
per ep.
0.0006
0.0010
0.0016
0.0029
0.0052
0.0098
0.0187
0.0368
0.0700
0.1132

Exp.
per ep.
1.0
2.0
4.0
8.0
16.0
32.0
63.9
126.3
235.8
372.7

Perc.
per ep.
11.1
19.9
36.0
66.1
122.5
235.0
485.5
1,114.1
2,586.7
4,826.3

Time
per ep.
0.0005
0.0008
0.0016
0.0034
0.0070
0.0136
0.0241
0.0406
0.0702
0.1107

Exp.
per ep.
1.0
2.0
4.0
8.0
16.0
32.0
63.9
126.4
238.3
385.1

Perc.
per ep.
11.6
29.6
68.0
153.7
327.4
654.9
1,167.4
1,958.9
3,491.5
5,654.4

Table 4: Average results RTAA variants game maps. given lookahead parameter value, report average solution cost (Avg. Cost), average number
planning episodes (# Planning Episodes), total runtime (Total Time), average
runtime per search episode (Time per Episode), average number expansions per
episode (Exp. per ep.), average number percolations per planning episode (Perc.
per ep.). times reported milliseconds.

561

fiHernandez & Baier

LookAhead
parameter
1
2
4
8
16
32
64
128
256
512

Avg.
Cost
5,731,135
3,346,675
1,931,251
1,195,330
674,872
391,120
218,303
119,177
64,861
38,182

LookAhead
parameter
1
2
4
8
16
32
64
128
256
512

Avg.
Cost
5,165,062
2,561,769
1,670,535
1,027,134
617,302
354,691
205,214
112,288
61,031
36,524

LookAhead
parameter
1
2
4
8
16
32
64
128
256
512

Avg.
Cost
443,773
433,576
527,638
317,508
197,066
125,511
85,373
65,009
39,777
28,937

LSS-LRTA
# Planning
Total
Episodes
Time
5,307,571
6,036
2,594,738
4,967
1,247,205
4,009
586,084
3,187
233,400
2,189
96,163
1,613
39,002
1,215
16,649
1,010
8,420
991
5,805
1,143
aLSS-LRTA
# Planning
Total
Episodes
Time
4,785,257
6,174
1,981,509
4,321
1,078,512
3,923
504,696
3,069
213,959
2,217
87,700
1,603
37,106
1,240
16,069
1,028
8,300
1,010
5,879
1,185
daLSS-LRTA
# Planning
Total
Episodes
Time
415,327
357
353,087
603
393,222
1,374
205,868
1,412
100,984
1,293
45,682
1,023
22,725
888
13,772
977
8,201
1,056
6,330
1,310

Time per
Episode
0.0011
0.0019
0.0032
0.0054
0.0094
0.0168
0.0312
0.0607
0.1177
0.1968

Exp.
per ep.
8.5
13.4
20.7
32.9
54.5
95.2
175.6
341.3
655.0
1,079.2

Perc.
per ep.
14.3
28.0
52.1
97.6
182.9
367.4
799.4
1,939.0
4,704.4
8,961.1

Time
per ep.
0.0013
0.0022
0.0036
0.0061
0.0104
0.0183
0.0334
0.0640
0.1217
0.2016

Exp.
per ep.
8.5
13.3
20.7
33.0
54.6
95.8
176.9
344.4
659.1
1,082.0

Perc.
per ep.
19.0
37.7
69.5
126.6
228.3
441.1
918.4
2,134.7
4,997.9
9,283.8

Time
per ep.
0.0009
0.0017
0.0035
0.0069
0.0128
0.0224
0.0391
0.0709
0.1288
0.2070

Exp.
per ep.
6.2
11.7
21.9
40.0
70.7
119.7
209.7
384.7
698.4
1,115.8

Perc.
per ep.
18.9
43.3
96.6
225.8
459.9
816.1
1,477.1
2,936.7
5,972.6
10,136.2

Table 5: Average results LSS-LRTA variants mazes. given lookahead parameter value,
report average solution cost (Avg. Cost), average number planning episodes (#
Planning Episodes), total runtime (Total Time), average runtime per search episode (Time
per Episode), average number expansions per episode (Exp. per ep.), average number
percolations per planning episode (Perc. per ep.). times reported milliseconds.
Results obtained Linux PC Pentium QuadCore 2.33 GHz CPU 8 GB
RAM.

562

fiAvoiding Escaping Depressions Real-Time Heuristic Search

LookAhead
parameter
1
2
4
8
16
32
64
128
256
512

Avg.
Cost
1,146,014
625,693
372,456
227,526
127,753
72,044
40,359
22,471
12,264
7,275

LookAhead
parameter
1
2
4
8
16
32
64
128
256
512

Avg.
Cost
958,795
506,745
313,789
184,632
111,633
66,911
37,215
20,524
11,053
6,460

k
1
2
4
8
16
32
64
128
256
512

Avg.
Cost
109,337
79,417
72,028
51,753
33,351
21,622
13,581
8,693
6,464
4,830

LSS-LRTA
# Planning
Total
Episodes
Time
1,058,265
1,260
488,096
979
242,171
818
113,236
654
45,242
460
18,445
345
7,687
280
3,444
258
1,774
272
1,192
312
aLSS-LRTA
# Planning
Total
Episodes
Time
885,506
1,185
395,546
903
204,478
786
92,594
602
39,857
449
17,271
351
7,217
278
3,234
251
1,677
261
1,137
295
daLSS-LRTA
# Planning
Total
Episodes
Time
102,616
86
69,976
116
58,931
214
38,862
300
20,792
322
10,177
293
4,715
233
2,424
220
1,604
267
1,195
317

Time per
Episode
0.0012
0.0020
0.0034
0.0058
0.0102
0.0187
0.0364
0.0750
0.1534
0.2620

Exp.
per ep.
8.7
13.7
21.3
33.8
56.1
98.7
184.9
370.1
733.6
1,207.5

Perc.
per ep.
14.8
29.3
54.3
102.4
193.5
397.7
903.4
2,338.1
6,003.8
11,548.9

Time
per ep.
0.0013
0.0023
0.0038
0.0065
0.0113
0.0203
0.0386
0.0776
0.1556
0.2592

Exp.
per ep.
8.7
13.7
21.3
34.1
56.6
99.5
186.8
374.5
741.4
1,204.5

Perc.
per ep.
19.8
40.1
73.7
135.6
246.0
479.6
1,036.2
2,553.8
6,339.3
11,823.7

Time
per ep.
0.0008
0.0017
0.0036
0.0077
0.0155
0.0288
0.0494
0.0905
0.1667
0.2651

Exp.
per ep.
6.1
12.1
23.3
44.1
80.3
139.6
236.9
435.4
791.5
1,237.3

Perc.
per ep.
20.8
49.9
118.2
274.0
586.2
1,122.4
1,911.2
3,725.4
7,538.1
12,697.3

Table 6: Average results LSS-LRTA variants game maps. given lookahead parameter value, report average solution cost (Avg. Cost), average number planning
episodes (# Planning Episodes), total runtime (Total Time), average runtime per search
episode (Time per Episode), average number expansions per episode (Exp. per ep.), average number percolations per planning episode (Perc. per ep.). times reported
milliseconds. Results obtained Linux PC Pentium QuadCore 2.33 GHz
CPU 8 GB RAM.

563

fiHernandez & Baier

Appendix B. Additional Proofs Theorems
B.1 Proof Theorem 3
establish that, pair neighbor states, s0 , hn+1 (s) cn+1 (s, s0 ) + hn+1 (s0 ).
divide rest argument three cases.
Case 1. s0 Closed. Then, Proposition 1,
hn+1 (s0 ) = kn (s0 , s00 ) + hn (s00 ),

(14)

s00 Open. hand, Proposition 1,
hn+1 (s) = min kn (s, sb ) + hn (sb ),
sb Open

thus
hn+1 (s) kn (s, s00 ) + hn (s00 ),

(15)

since s00 element Open. However, kn (s, s00 ) cost shortest path
s00 , know
kn (s, s00 ) cn (s, s0 ) + kn (s0 , s00 )

(16)

Adding (15) (16), obtain
hn+1 (s) cn (s, s0 ) + kn (s0 , s00 ) + hn (s00 )

(17)

Using Equation 14 substitute kn (s0 , s00 ) + hn (s00 ) Inequality 17, obtaining:
hn+1 (s) cn (s, s0 ) + hn (s0 ).

(18)

Since cost function increase, cn (s, s0 ) cn+1 (s, s0 ), hence:
hn+1 (s) cn+1 (s, s0 ) + hn (s0 ),

(19)

Finally, since h non-decreasing (Theorem 1), hn (s0 ) hn+1 (s0 ), allows us
write
hn+1 (s) cn+1 (s, s0 ) + hn+1 (s0 ),
(20)
finishes proof case.
Case 2. One state among s0 Closed, state Closed.
Without loss generality, assume Closed. Since s0 Closed, must
Open, expanded s0 neighbor s. Proposition 1 know:
hn+1 (s) = min kn (s, sb ) + hn (sb ),
sb Open

since s0 particular state Open, have:
hn+1 (s) cn (s, s0 ) + hn (s0 ).
Since cn cn+1 , obtain:
hn+1 (s) cn+1 (s, s0 ) + hn (s0 ),
564

fiAvoiding Escaping Depressions Real-Time Heuristic Search

concludes proof case.
Case 3. s0 Closed. Since hn consistent:
hn (s) cn (s, s0 ) + hn (s0 )

(21)

use h-value s0 updated (hn (s) = hn+1 (s) hn (s0 ) =
hn+1 (s0 )), fact cost function increases write:
hn+1 (s) cn+1 (s, s0 ) + hn+1 (s0 ),

(22)

finishes proof case.
three cases proved desired inequality therefore conclude heuristic
hn+1 consistent respect cost function cn+1 .
B.2 Proof Theorem 4
establish that, pair neighbor states, s0 , hn+1 (s) cn+1 (s, s0 ) + hn+1 (s0 ).
divide rest argument three cases.
Case 1. s0 Closed.
hn+1 (s) = f (s ) g(s),
0



0

hn+1 (s ) = f (s ) g(s ),

(23)
(24)

Open. Subtracting (24) (23), obtain:
hn+1 (s) hn+1 (s0 ) = g(s0 ) g(s).

(25)

Since hn consistent g(s) g(s0 ) correspond cost shortest path
scurrent and, respectively, s0 . Thus g(s0 ) = kn (scurrent , s0 ) g(s) = kn (scurrent , s),
therefore:
hn+1 (s) hn+1 (s0 ) = kn (scurrent , s0 ) kn (scurrent , s).
(26)
Let us consider path scurrent s0 goes optimally s, goes
s0 . cost path must least kn (scurrent , s0 ). words:
kn (scurrent , s0 ) kn (scurrent , s) + cn (s, s0 ),
directly implies:
kn (scurrent , s0 ) kn (scurrent , s) cn (s, s0 ).

(27)

combine (27) (26) obtain:
hn+1 (s) cn (s, s0 ) + hn+1 (s0 ).

(28)

And, finally, since cn cn+1 conclude that:
hn+1 (s) cn+1 (s, s0 ) + hn+1 (s0 ),
finishes proof case.
565

(29)

fiHernandez & Baier

Case 2. One state among s0 Closed, state Closed.
Without loss generality, assume Closed. Since s0 Closed, must
Open, expanded s0 neighbor s.
state Open,
hn+1 (s) = f (s ) g(s)

(30)

use fact that, consistent heuristic hn , expands nodes increasing f -values. Note state would expanded next ,
s0 would expanded later on. Moreover, soon s0 would
expanded g-value s0 optimal cost path scurrent s0 , kn (scurrent , s0 ).
Therefore, write:
f (s ) kn (scurrent , s0 ) + hn (s0 ),
(31)
kn (scurrent , s0 ) + hn (s0 ) f -value s0 upon expansion. Adding (30) (31),
obtain:
hn+1 (s) kn (scurrent , s0 ) g(s) + hn (s0 )
However, since Closed, g(s) cost optimal path scurrent s,
thus:
hn+1 (s) kn (scurrent , s0 ) kn (scurrent , s) + hn (s0 )
(32)
use argument previous case conclude that:
kn (scurrent , s0 ) kn (scurrent , s) cn (s, s0 ).

(33)

Combining (31) (33) obtain:
hn+1 (s) cn (s, s0 ) + hn (s0 )

(34)

Since s0 closed, hn+1 (s0 ) = hn (s). Furthermore, know cn cn+1 . Substituting (34), obtain:
hn+1 (s) cn+1 (s, s0 ) + hn+1 (s0 ),

(35)

allows us conclude proof case.
Case 3. s0 Closed. proof Case 3
Theorem 3.
three cases proved desired inequality therefore conclude heuristic
hn+1 consistent respect cost function cn+1 .
B.3 Appendix Proof Theorem 5
section describes proof Theorem 5 specific case aRTAA .
Let maximal connected component states connected (1)
states Closed call iteration n, (2) state sd
hn+1 (sd ) > hn (sd ). prove cost-sensitive heuristic depression hn .
Let s0 state boundary D; argued case aLSS-LRTA ,
show hn (s0 ) = hn+1 (s0 ). Now, let sd state D. continue proof showing
566

fiAvoiding Escaping Depressions Real-Time Heuristic Search

hn (sd ) low respect hn (s0 ), means heuristic depression
hn . final part proof, distinguish two cases: (Case 1) s0 Closed,
(Case 2) s0 Open.
Case 1, given hn+1 (s0 ) = hn (s0 ), know hn (s0 ) = f g(s0 ), f
lowest f -value open list algorithm run, hence:
f = hn (s0 ) + g(s0 )

(36)

hand, since definition heuristic value increased sd ,
hn (sd ) < hn+1 (sd ) = f g(sd ).

(37)

Substituting f Eq. 37 right-hand-side Eq. 36, get:
hn (sd ) < hn (s0 ) + g(s0 ) g(sd ).

(38)

heuristic consistent s0 sd Closed, g(s0 ) g(sd ) actually
correspond cost cheapest path reach, respectively, s0 sd s; i.e.,
g(s0 ) = k(s, s0 ) g(sd ) = kn (s, sd ). addition, triangular inequality kn (s, sd ) +
kn (sd , s0 ) kn (s, s0 ), re-written as:
g(s0 ) g(sd ) kn (sd , s0 ).

(39)

Inequalities 38 39 imply hn (sd ) < kn (sd , s0 ) + hn (s0 ).
Finally, Case 2, s0 Open, Proposition 2 fact hn+1 (sd ) > hn (sd ),
also hn (sd ) < kn (sd , s0 ) + hn (s0 ).
cases, proved hn (sd ) < kn (sd , s0 ) + hn (s0 ), sd s0
boundary D. conclude cost-sensitive heuristic depression hn .

References
Barto, A. G., Bradtke, S. J., & Singh, S. P. (1995). Learning act using real-time dynamic
programming. Artificial Intelligence, 72 (1-2), 81138.
Bjornsson, Y., Bulitko, V., & Sturtevant, N. R. (2009). TBA*: Time-bounded A*. Proceedings 21st International Joint Conference Artificial Intelligence (IJCAI),
pp. 431436.
Bond, D. M., Widger, N. A., Ruml, W., & Sun, X. (2010). Real-time search dynamic
worlds. Proceedings 3rd Symposium Combinatorial Search (SoCS), Atlanta, Georgia.
Botea, A. (2011). Ultra-fast Optimal Pathfinding without Runtime Search. Proceedings
7th Annual International AIIDE Conference (AIIDE), Palo Alto, California.
Bulitko, V., & Lee, G. (2006). Learning real time search: unifying framework. Journal
Artificial Intelligence Research, 25, 119157.
Bulitko, V. (2004). Learning adaptive real-time search. Computing Research Repository,
cs.AI/0407016.
567

fiHernandez & Baier

Bulitko, V., Bjornsson, Y., & Lawrence, R. (2010). Case-based subgoaling real-time
heuristic search video game pathfinding. Journal Artificial Intelligence Research,
38, 268300.
Bulitko, V., Bjornsson, Y., Sturtevant, N., & Lawrence, R. (2011). Real-time Heuristic
Search Game Pathfinding. Applied Research Artificial Intelligence Computer
Games. Springer.
Bulitko, V., Lustrek, M., Schaeffer, J., Bjornsson, Y., & Sigmundarson, S. (2008). Dynamic
control real-time heuristic search. Journal Artificial Intelligence Research, 32,
419452.
Cormen, T. H., Leiserson, C. E., Rivest, R. L., & Stein, C. (2001). Introduction Algorithms, Second Edition. MIT Press McGraw-Hill Book Company.
Cushing, W., Benton, J., & Kambhampati, S. (2011). Cost based satisficing search considered harmful. CoRR, abs/1103.3687.
Edelkamp, S., & Schrodl, S. (2011). Heuristic Search: Theory Applications. Morgan
Kaufmann.
Hart, P. E., Nilsson, N., & Raphael, B. (1968). formal basis heuristic determination
minimal cost paths. IEEE Transactions Systems Science Cybernetics, 4 (2).
Hernandez, C., & Meseguer, P. (2005). LRTA*(k). Proceedings 19th International
Joint Conference Artificial Intelligence (IJCAI), pp. 12381243.
Hernandez, C., & Meseguer, P. (2007). Improving LRTA*(k). Proceedings 20th
International Joint Conference Artificial Intelligence (IJCAI), pp. 23122317.
Hernandez, C., & Baier, J. A. (2011a). Escaping heuristic depressions real-time heuristic
search (extended abstract). Proceedings 10th International Joint Conference
Autonomous Agents Multi Agent Systems (AAMAS), Taipei, Taiwan.
Hernandez, C., & Baier, J. A. (2011b). Fast subgoaling pathfinding via real-time
search. Proceedings 21th International Conference Automated Planning
Scheduling (ICAPS), Freiburg, Germany.
Hernandez, C., & Baier, J. A. (2011c). Real-time adaptive A* depression avoidance.
Proceedings 7th Annual International AIIDE Conference (AIIDE), Palo Alto,
California.
Hernandez, C., & Baier, J. A. (2011d). Real-time heuristic search depression avoidance.
Proceedings 22nd International Joint Conference Artificial Intelligence
(IJCAI), Barcelona, Spain.
Hernandez, C., Sun, X., Koenig, S., & Meseguer, P. (2011). Tree adaptive A*. Proceedings
10th International Joint Conference Autonomous Agents Multi Agent
Systems (AAMAS), Taipei, Taiwan.
Hoffmann, J. (2011). ignoring delete lists works, part II: Causal graphs. Proceedings 21th International Conference Automated Planning Scheduling
(ICAPS), pp. 98105.
Hoffmann, J. (2005). ignoring delete lists works: Local search topology planning
benchmarks. Journal Artificial Intelligence Research, 24, 685758.
568

fiAvoiding Escaping Depressions Real-Time Heuristic Search

Ishida, T. (1992). Moving target search intelligence. Proceedings 10th National
Conference Artificial Intelligence (AAAI), pp. 525532.
Kitamura, Y., Teranishi, K.-i., & Tatsumi, S. (1996). Organizational strategies multiagent real-time search. Proceedings 2nd International Conference Multiagent Systems (ICMAS), pp. 150156, Kyoto, Japan.
Knight, K. (1993). many reactive agents better deliberative ones?. Proceedings 13th International Joint Conference Artificial Intelligence (IJCAI),
pp. 432437.
Koenig, S. (1998). Exploring unknown environments real-time search reinforcement
learning. Proceedings 11th Conference Advances Neural Information
Processing Systems (NIPS), pp. 10031009.
Koenig, S. (2001). Agent-centered search. Artificial Intelligence Magazine, 22 (4), 109131.
Koenig, S. (2004). comparison fast search methods real-time situated agents.
Proceedings 3rd International Joint Conference Autonomous Agents
Multi Agent Systems (AAMAS), pp. 864871.
Koenig, S., & Likhachev, M. (2002). D* lite. Proceedings 18th National Conference
Artificial Intelligence (AAAI), pp. 476483.
Koenig, S., & Likhachev, M. (2006a). new principle incremental heuristic search:
Theoretical results. Proceedings 16th International Conference Automated
Planning Scheduling (ICAPS), pp. 402405, Lake District, UK.
Koenig, S., & Likhachev, M. (2006b). Real-time adaptive A*. Proceedings 5th
International Joint Conference Autonomous Agents Multi Agent Systems (AAMAS), pp. 281288.
Koenig, S., & Sun, X. (2009). Comparing real-time incremental heuristic search
real-time situated agents. Autonomous Agents Multi-Agent Systems, 18 (3), 313
341.
Koenig, S., Tovey, C. A., & Smirnov, Y. V. (2003). Performance bounds planning
unknown terrain. Artificial Intelligence, 147 (1-2), 253279.
Korf, R. E. (1990). Real-time heuristic search. Artificial Intelligence, 42 (2-3), 189211.
Pearl, J. (1984). Heuristics: preintelligent search strategies computer problem solving.
Addison-Wesley Longman Publishing Co., Inc., Boston, MA, USA.
Rayner, D. C., Davison, K., Bulitko, V., Anderson, K., & Lu, J. (2007). Real-time heuristic
search priority queue. Proceedings 20th International Joint Conference
Artificial Intelligence (IJCAI), pp. 23722377.
Richter, S., Thayer, J. T., & Ruml, W. (2010). joy forgetting: Faster anytime search
via restarting. Proceedings 20th International Conference Automated
Planning Scheduling (ICAPS), pp. 137144.
Shimbo, M., & Ishida, T. (2003). Controlling learning process real-time heuristic
search. Artificial Intelligence, 146 (1), 141.
569

fiHernandez & Baier

Stentz, A. (1995). focussed D* algorithm real-time replanning. Proceedings
14th International Joint Conference Artificial Intelligence (IJCAI), pp. 16521659.
Sturtevant, N. R., & Bulitko, V. (2011). Learning going whence
came: h- g-cost learning real-time heuristic search. Proceedings
22nd International Joint Conference Artificial Intelligence (IJCAI), pp. 365370,
Barcelona, Spain.
Sturtevant, N. R., Bulitko, V., & Bjornsson, Y. (2010). learning agent-centered search.
Proceedings 9th International Joint Conference Autonomous Agents
Multi Agent Systems (AAMAS), pp. 333340, Toronto, Ontario.
Sturtevant, N. R., & Buro, M. (2005). Partial pathfinding using map abstraction
refinement. Proceedings 20th National Conference Artificial Intelligence
(AAAI), pp. 13921397.
Thayer, J. T., Dionne, A. J., & Ruml, W. (2011). Learning inadmissible heuristics
search. Proceedings 21th International Conference Automated Planning
Scheduling (ICAPS), pp. 250257, Freinurg, Germany.
Weiss, G. (Ed.). (1999). Multiagent Systems: Modern Approach Distributed Artificial
Intelligence. MIT Press, Cambridge, MA.
Wilt, C. M., Thayer, J. T., & Ruml, W. (2010). comparison greedy search algorithms.
Proceedings 3rd Symposium Combinatorial Search (SoCS).
Yokoo, M., & Kitamura, Y. (1996). Multiagent real-time A* selection: Introducing
competition cooperative search. Proceedings 2nd International Conference
Multiagent Systems (ICMAS), pp. 409416, Kyoto, Japan.
Zelinsky, A. (1992). mobile robot exploration algorithm. IEEE Transactions Robotics
Automation, 8 (6), 707717.

570

fiJournal Artificial Intelligence Research 43 (2012) 661-704

Submitted 09/11; published 04/12

Learning Win Reading Manuals
Monte-Carlo Framework
S.R.K. Branavan

branavan@csail.mit.edu

Computer Science Artificial Intelligence Laboratory
Massachusetts Institute Technology

David Silver

d.silver@cs.ucl.ac.uk

Department Computer Science
University College London

Regina Barzilay

regina@csail.mit.edu

Computer Science Artificial Intelligence Laboratory
Massachusetts Institute Technology

Abstract
Domain knowledge crucial effective performance autonomous control systems.
Typically, human effort required encode knowledge control algorithm.
paper, present approach language grounding automatically interprets
text context complex control application, game, uses domain
knowledge extracted text improve control performance. text analysis
control strategies learned jointly using feedback signal inherent application.
effectively leverage textual information, method automatically extracts text
segment relevant current game state, labels task-centric predicate
structure. labeled text used bias action selection policy game,
guiding towards promising regions action space. encode model text
analysis game playing multi-layer neural network, representing linguistic decisions
via latent variables hidden layers, game action quality via output layer.
Operating within Monte-Carlo Search framework, estimate model parameters using
feedback simulated games. apply approach complex strategy game
Civilization II using official game manual text guide. results show
linguistically-informed game-playing agent significantly outperforms language-unaware
counterpart, yielding 34% absolute improvement winning 65% games
playing built-in AI Civilization.

1. Introduction
paper, study task grounding document content control applications
computer games. applications, agent attempts optimize utility
function (e.g., game score) learning select situation-appropriate actions. complex
domains, finding winning strategy challenging even humans. Therefore, human
players typically rely manuals guides describe promising tactics provide
general advice underlying task. Surprisingly, textual information never
utilized control algorithms despite potential greatly improve performance.
goal, therefore, develop methods achieve automatic fashion.
c
2012
AI Access Foundation. rights reserved.

fiBranavan, Silver, & Barzilay

natural resources available population settles aects ability produce food
goods. Cities built near water sources irrigate increase crop yields,
cities near mineral resources mine raw materials. Build city plains grassland
square river running possible.

Figure 1: excerpt user manual game Civilization II.
explore question context strategy games, challenging class large scale
adversarial planning problems.
Consider instance text shown Figure 1. excerpt user
manual game Civilization II.1 text describes game locations action
build-city effectively applied. stochastic player access
text would gain knowledge hard way: would repeatedly attempt
action myriad states, thereby learning characterization promising state-action
pairs based observed game outcomes. games large state spaces, long planning
horizons, high-branching factors, approach prohibitively slow ineffective.
algorithm access text, however, could learn correlations words
text game attributes e.g., word river places rivers game
thus leveraging strategies described text select better actions.
improve performance control applications using domain knowledge automatically extracted text, need address following challenges:
Grounding Text State-Action Space Control Application Text
guides provide wealth information effective control strategies, including
situation-specific advice well general background knowledge. benefit
information, algorithm learn mapping text
guide, states actions control application. mapping allows
algorithm find state-specific advice matching state attributes verbal
descriptions. Furthermore, relevant sentence found, mapping biases
algorithm select action proposed guide document. mapping
modeled word-level, ideally would also use information encoded
structure sentence predicate argument structure. instance,
algorithm explicitly identify predicates state attribute descriptions,
map directly structures inherent control application.
Annotation-free Parameter Estimation text analysis tasks relate
well-known methods information extraction, prior work primarily focused
supervised methods. setup, text analysis state dependent, therefore annotations need representative entire state space. Given enormous state
space continually changes game progresses, collecting annotations
impractical. Instead, propose learn text analysis based feedback signal
inherent control application, e.g., game score. feedback computed
automatically step game, thereby allowing algorithm continuously
adapt local, observed game context.
1. http://en.wikipedia.org/wiki/Civilization II

662

fiLearning Win Reading Manuals Monte-Carlo Framework

Effective Integration Extracted Text Information Control Application text guides provide complete, step-by-step advice situations player may encounter. Even advice available, learned
mapping may noisy, resulting suboptimal choices. Therefore, need design method achieve effective control absence textual advice,
robustly integrating automatically extracted information available.
address challenge incorporating language analysis Monte-Carlo Search,
state-of-the-art framework playing complex games. Traditionally framework
operates state action features. extending Monte-Carlo search
include textual features, integrate two sources information principled
fashion.
1.1 Summary Approach
address challenges unified framework based Markov Decision Processes
(MDP), formulation commonly used game playing algorithms. setup consists
game stochastic environment, goal player maximize given
utility function R(s) state s. players behavior determined action-value
function Q(s, a) assesses goodness action state based attributes
a.
incorporate linguistic information MDP formulation, expand action
value function include linguistic features. state action features known
point computation, relevant words semantic roles observed.
Therefore, model text relevance hidden variable. Similarly, use hidden variables
discriminate words describe actions describe state attributes
rest sentence. incorporate hidden variables action-value function,
model Q(s, a) non-linear function approximation using multi-layer neural network.
Despite added complexity, parameters non-linear model effectively learned Monte-Carlo Search framework. Monte-Carlo Search, actionvalue function estimated playing multiple simulated games starting current
game state. use observed reward simulations update parameters
neural network via backpropagation. focuses learning current game state,
allowing method learn language analysis game-play appropriate observed
game context.
1.2 Evaluation
test method strategy game Civilization II, notoriously challenging game
immense action space.2 source knowledge guiding model, use
official game manual. baseline, employ similar Monte-Carlo search based player
access textual information. demonstrate linguisticallyinformed player significantly outperforms baseline terms number games
won. Moreover, show modeling deeper linguistic structure sentences improves performance. full-length games, algorithm yields 34% improve2. Civilization II #3 IGNs 2007 list top video games time.
(http://top100.ign.com/2007/ign top game 3.html)

663

fiBranavan, Silver, & Barzilay

ment language unaware baseline wins 65% games built-in,
hand-crafted AI Civilization II. video method playing game available
http://groups.csail.mit.edu/rbg/code/civ/video. code data work, along
complete experimental setup preconfigured environment virtual machine
available http://groups.csail.mit.edu/rbg/code/civ.
1.3 Roadmap
Section 2, provide intuition benefits integrating textual information
learning algorithms control. Section 3 describes prior work language grounding, emphasizing unique challenges opportunities setup. section also positions
work large body research Monte-Carlo based players. Section 4 presents
background Monte-Carlo Search applied game playing. Section 5 present
multi-layer neural network formulation action-value function combines information text control application. Next, present Monte-Carlo method
estimating parameters non-linear function. Sections 6 7 focus application algorithm game Civilization II. Section 8 compare method
range competitive game-playing baselines, empirically analyze properties algorithm. Finally, Section 9 discuss implications research,
conclude.

2. Learning Game Play Text
section, provide intuitive explanation textual information help improve action selection complex game. clarity, first discuss benefits textual
information supervised scenario, thereby decoupling questions concerning modeling
representation related parameter estimation. Assume every state
represented set n features [s1 , s2 , . . . , sn ]. Given state s, goal select
best possible action aj fixed set A. model task multiclass classification, choice aj represented feature vector [(s1 , aj ), (s2 , aj ), . . . , (sn , aj )].
Here, (si , aj ), [1, n] represents feature created taking Cartesian product [s1 , s2 , . . . , sn ] aj . learn classifier effectively, need training set
sufficiently covers possible combinations state features actions. However, domains complex state spaces large number possible actions, many instances
state-action feature values unobserved training.
show generalization power classifier improved using textual information. Assume training example, addition state-action pair,
contains sentence may describe action taken given state attributes. Intuitively, want enrich basic classifier features capture correspondence
states actions, words describe them. Given sentence w composed
word types w1 , w2 , . . . , wm , features form (si , wk ) (aj , wk )
every [1, n], k [1, m] aj A. Assuming action described using similar words throughout guide, expect text-enriched classifier would able
learn correspondence via features (aj , wk ). similar intuition holds learning
correspondence state-attributes descriptions represented features
(si , wk ). features, classifier connect state action aj based
664

fiLearning Win Reading Manuals Monte-Carlo Framework

evidence provided guiding sentence occurrences contexts
throughout training data. text-free classifier may support association
action appear similar state context training set.
benefits textual information extend models trained using control
feedback rather supervised data. training scenario, algorithm assesses
goodness given state-action combination simulating limited number game turns
action taken observing control feedback provided underlying
application. algorithm built-in mechanism (see Section 4) employs
observed feedback learn feature weights, intelligently samples space search
promising state-action pairs. algorithm access collection sentences,
similar feedback-based mechanism used find sentences match given stateaction pair (Section 5.1). state- action-description features (si , wk )
(aj , wk ), algorithm jointly learns identify relevant sentences map actions
states descriptions. Note used classification basis
discussion section, reality methods learn regression function.

3. Related Work
section, first discuss prior work field grounded language acquisition.
Subsequently look two areas specific application domain i.e., natural language
analysis context games, Monte-Carlo Search applied game playing.
3.1 Grounded Language Acquisition
work fits broad area research grounded language acquisition
goal learn linguistic analysis non-linguistic situated context (Oates, 2001;
Barnard & Forsyth, 2001; Siskind, 2001; Roy & Pentland, 2002; Yu & Ballard, 2004; Chen
& Mooney, 2008; Zettlemoyer & Collins, 2009; Liang, Jordan, & Klein, 2009; Branavan,
Chen, Zettlemoyer, & Barzilay, 2009; Branavan, Zettlemoyer, & Barzilay, 2010; Vogel & Jurafsky, 2010; Clarke, Goldwasser, Chang, & Roth, 2010; Tellex, Kollar, Dickerson, Walter,
Banerjee, Teller, & Roy, 2011; Chen & Mooney, 2011; Liang, Jordan, & Klein, 2011; Goldwasser, Reichart, Clarke, & Roth, 2011). appeal formulation lies reducing
need manual annotations, non-linguistic signals provide powerful, albeit
noisy, source supervision learning. traditional grounding setup assumed
non-linguistic signals parallel content input text, motivating machine
translation view grounding task. alternative approach models grounding
control framework learner actively acquires feedback non-linguistic environment uses drive language interpretation. summarize approaches,
emphasizing similarity differences work.
3.1.1 Learning Grounding Parallel Data
many applications, linguistic content tightly linked perceptual observations, providing rich source information learning language grounding. Examples parallel
data include images captions (Barnard & Forsyth, 2001), Robocup game events paired
text commentary (Chen & Mooney, 2008), sequences robot motor actions de665

fiBranavan, Silver, & Barzilay

scribed natural language (Tellex et al., 2011). large diversity properties
parallel data resulted development algorithms tailored specific grounding
contexts, instead application-independent grounding approach. Nevertheless, existing
grounding approaches characterized along several dimensions illuminate
connection algorithms:
Representation Non-Linguistic Input first step grounding words
perceptual data discretize non-linguistic signal (e.g., image) representation facilitates alignment. instance, Barnard Forsyth (2001) segment images regions subsequently mapped words. approaches
intertwine alignment segmentation single step (Roy & Pentland, 2002),
two tasks clearly interrelated. application, segmentation required
state-action representation nature discrete.
Many approaches move beyond discretization, aiming induce rich hierarchical structures non-linguistic input (Fleischman & Roy, 2005; Chen & Mooney, 2008,
2011). instance, Fleischman Roy (2005) parse action sequences using
context-free grammar subsequently mapped semantic frames. Chen
Mooney (2008) represent action sequences using first order logic. contrast,
algorithm capitalizes structure readily available data state-action
transitions. inducing richer structure state-action space may benefit mapping, difficult problem right field hierarchical
planning (Barto & Mahadevan, 2003).
Representation Linguistic Input Early grounding approaches used bagof-words approach represent input documents (Yu & Ballard, 2004; Barnard &
Forsyth, 2001; Fleischman & Roy, 2005). recent methods relied richer
representation linguistic data, syntactic trees (Chen & Mooney, 2008)
semantic templates (Tellex et al., 2011). method incorporates linguistic information multiple levels, using feature-based representation encodes words
well syntactic information extracted dependency trees. shown
results, richer linguistic representations significantly improve model performance.
Alignment Another common feature existing grounding models training
procedure crucially depends well words aligned non-linguistic structures.
reason, models assume alignment provided part training
data (Fleischman & Roy, 2005; Tellex et al., 2011). grounding algorithms,
alignment induced part training procedure. Examples approaches
methods Barnard Forsyth (2001), Liang et al. (2009).
models jointly generate text attributes grounding context, treating
alignment unobserved variable.
contrast, explicitly model alignment model due lack
parallel data. Instead, aim extract relevant information text infuse
control application.
666

fiLearning Win Reading Manuals Monte-Carlo Framework

3.1.2 Learning Grounding Control Feedback
recent work moved away reliance parallel corpora, using control feedback primary source supervision. assumption behind setup
textual information used drive control application, applications performance
correlate quality language analysis. also assumed performance measurement obtained automatically. setup conducive reinforcement learning
approaches estimate model parameters feedback signal, even noisy
delayed.
One line prior work focused task mapping textual instructions
policy control application, assuming text fully specifies actions executed environment. example, previous work (Branavan et al., 2009, 2010),
approach applied task translating instructions computer manual
executable GUI actions. Vogel Jurafsky (2010) demonstrate grounding
framework effectively map navigational directions corresponding path map.
second line prior work focused full semantic parsing converting given text
formal meaning representation first order logic (Clarke et al., 2010).
methods applied domains correctness output accurately evaluated based control feedback example, output database
query executed provides clean, oracle feedback signal learning. line
work also assumes text fully specifies required output.
method also driven control feedback, language interpretation task
fundamentally different. assume given text document provides highlevel advice without directly describing correct actions every potential game state.
Furthermore, textual advice necessarily translate single strategy fact,
text may describe several strategies, contingent specific game states.
reason, strategy text cannot simply interpreted directly policy. Therefore,
goal bias learned policy using information extracted text. end,
aim achieve complete semantic interpretation, rather use partial text analysis
compute features relevant control application.
3.2 Language Analysis Games
Even though games provide rich domain situated text analysis,
prior attempts leveraging opportunity (Gorniak & Roy, 2005; Eisenstein,
Clarke, Goldwasser, & Roth, 2009).
Eisenstein et al. (2009) aim automatically extract information collection
documents help identify rules game. information, represented predicate logic formulae, estimated unsupervised fashion via generative model.
extracted formulae, along observed traces game play subsequently fed Inductive Logic Program, attempts reconstruct rules game.
high-level, goal similar, i.e., extract information text useful external
task, several key differences. Firstly, Eisenstein et al. (2009) analyze
text game two disjoint steps, model tasks integrated fashion.
allows model learn text analysis pertinent game play, time
using text guide game play. Secondly, method learns text analysis game
667

fiBranavan, Silver, & Barzilay

play feedback signal inherent game, avoiding need pre-compiled game
traces. enables method operate effectively complex games collecting
sufficiently representative set game traces impractical.
Gorniak Roy (2005) develop machine controlled game character responds
spoken natural language commands. Given traces game actions manually annotated
transcribed speech, method learns structured representation text
aligned action sequences. learned model used interpret spoken instructions
grounding actions human player current game state.
method learn play game, enables human control additional game
character via speech. contrast Gorniak Roy (2005), aim develop algorithms
fully autonomously control actions one player game. Furthermore,
method operates games user manual rather human provided, contextually
relevant instructions. requires model identify text contains information
useful current game state, addition mapping text productive actions.
Finally, method learns game feedback collected via active interaction without
relying manual annotations. allows us effectively operate complex games
collecting traditional labeled traces would prohibitively expensive.
3.3 Monte-Carlo Search Game AI
Monte-Carlo Search (MCS) state-of-the-art framework successfully
applied, prior work, playing complex games Go, Poker, Scrabble, real-time
strategy games (Gelly, Wang, Munos, & Teytaud, 2006; Tesauro & Galperin, 1996; Billings,
Castillo, Schaeffer, & Szafron, 1999; Sheppard, 2002; Schafer, 2008; Sturtevant, 2008; Balla
& Fern, 2009). framework operates playing simulated games estimate goodness value different candidate actions. games state action spaces
complex, number simulations needed effective play become prohibitively large.
Previous application MCS addressed issue using two orthogonal techniques: (1)
leverage domain knowledge either guide prune action selection, (2) estimate
value untried actions based observed outcomes simulated games. estimate used bias action selection. MCS based algorithm games relies
techniques. describe differences application
techniques prior work.
3.3.1 Leveraging Domain Knowledge
Domain knowledge shown critically important achieving good performance MCS complex games. prior work achieved manually
encoding relevant domain knowledge game playing algorithm example, via
manually specified heuristics action selection (Billings et al., 1999; Gelly et al., 2006),
hand crafted features (Tesauro & Galperin, 1996), value functions encoding expert
knowledge (Sturtevant, 2008). contrast approaches, goal automatically extract use domain knowledge relevant natural language documents, thus
bypassing need manual specification. method learns text interpretation
game action selection based outcomes simulated games MCS. allows
identify leverage textual domain knowledge relevant observed game context.
668

fiLearning Win Reading Manuals Monte-Carlo Framework

Action selection
according
policy function

Stochastic state
transition according
distribution

Figure 2: Markov Decision Process. Actions selected according policy function (s, a)
given current state s. execution selected action ai (e.g., a1 ), causes
MDP transition new state s0 according stochastic state transition
distribution (s0 | s, a).

3.3.2 Estimating Value Untried Actions
Previous approaches estimating value untried actions relied two techniques.
first, Upper Confidence bounds Tree (UCT) heuristic used concert
Monte-Carlo Tree Search variant MCS. augments actions value exploration
bonus rarely visited state-action pairs, resulting better action selection better
overall game performance (Gelly et al., 2006; Sturtevant, 2008; Balla & Fern, 2009).
second technique learn linear function approximation action values current
state s, based game feedback (Tesauro & Galperin, 1996; Silver, Sutton, & Muller, 2008).
Even though method follows latter approach, model action-value Q(s, a) via
non-linear function approximation. Given complexity application domain,
non-linear approximation generalizes better linear one, shown results
significantly improves performance. importantly, non-linear model enables
method represent text analysis latent variables, allowing use textual information
estimate value untried actions.

4. Monte-Carlo Search
task leverage textual information help us win turn-based strategy game
given opponent. section, first describe Monte-Carlo Search framework
within method operates. details linguistically informed Monte-Carlo
Search algorithm given Section 5.
4.1 Game Representation
Formally, represent given turn-based stochastic game Markov Decision Process
(MDP). MDP defined 4-tuple hS, A, T, Ri,
State space, S, set possible states. state represents complete
configuration game in-between player turns.
Action space, A, set possible actions. turn-based strategy game,
player controls multiple game units turn. Thus, action represents
joint assignment unit actions executed current player turn.
669

fiBranavan, Silver, & Barzilay

Transition distribution, (s0 | s, a), probability executing action state
result state s0 next game turn. distribution encodes way
game state changes due game rules, opposing players actions.
reason, (s0 | s, a) stochastic shown Figure 2, executing
action given state result different outcomes s0 .
Reward function, R(s) R, immediate reward received transitioning
state s. value reward correlates goodness actions executed
now, higher reward indicating better actions.
aspects MDP representation game i.e., S, A, () R()
defined implicitly game rules. step game, game-playing
agent observe current game state s, select best possible action a.
agent executes action a, game state changes according state transition
distribution. (s0 | s, a) known priori, state transitions sampled
distribution invoking game code black-box simulator i.e., playing
game. action, agent receives reward according reward function R(s).
game playing setup, value reward indication chances winning
game state s. Crucially, reward signal may delayed i.e., R(s) may
non-zero value game ending states win, loss, tie.
game playing agent selects actions according stochastic policy (s, a),
specifies probability selecting action state s. expected total reward
executing action state s, following policy termed action-value function
Q (s, a). goal find optimal policy (s, a) maximizes expected
total reward i.e., maximizes chances winning game. optimal action-value

function Q (s, a) known, optimal game-playing behavior would select action

highest Q (s, a). may computationally hard find optimal policy

(s, a) Q (s, a), many well studied algorithms available estimating effective
approximation (Sutton & Barto, 1998).
4.2 Monte-Carlo Framework Computer Games
Monte-Carlo Search algorithm, shown Figure 3, simulation-based search paradigm
dynamically estimating action-values Q (s, a) given state st (see Algorithm 1
pseudo code). estimate based rewards observed multiple roll-outs,
simulated game starting state st .3 Specifically, roll-out,
algorithm starts state st , repeatedly selects executes actions according
simulation policy (s, a), sampling state transitions (s0 | s, a). game completion
time , final reward R(s ) measured, action-value function updated
accordingly.4 Monte-Carlo control (Sutton & Barto, 1998), updated action-value
3. Monte-Carlo Search assumes possible play simulated games. simulations may
played heuristic AI player. experiments, built-in AI game used
opponent.
4. general, roll-outs run game completion. simulations expensive, case
domain, roll-outs truncated fixed number steps. however depends availability
approximate reward signal truncation point. experiments, use built-in score
game reward. reward noisy, available every stage game.

670

fiLearning Win Reading Manuals Monte-Carlo Framework

Game

Copy game
state
simulator

Apply action
best simulation
outcome game
Single
simulation
rollout

Update rollout
policy
game feedback
rollout

Simulation

Simulation

Figure 3: Overview Monte-Carlo Search algorithm. game state st , independent set simulated games roll-outs done find best possible game
action . roll-out starts state st , actions selected according
simulation policy (s, a). policy learned roll-outs
roll-outs improving policy, turn improves roll-out action selection. process repeated every actual game state, simulation
policy relearned scratch time.

function Q (s, a) used define improved simulation policy, thereby directing subsequent roll-outs towards higher scoring regions game state space. fixed number
roll-outs performed, action highest average final reward
simulations selected played actual game state st . process repeated
state encountered actual game, action-value function
relearned scratch new game state.5 simulation policy usually selects
actions maximize action-value function. However, sometimes valid actions
also randomly explored case valuable predicted current es5. conceivable sharing action-value function across roll-outs different game states
would beneficial, empirically case experiments. One possible reason
domain, game dynamics change radically many points game e.g.,
new technology becomes available. change occurs, may actually detrimental play
according action-value function previous game step. Note however, action-value
function indeed shared across roll-outs single game state st , parameters updated
successive roll-outs. learned model helps improve roll-out action selection, thereby
improves game play. setup relearning scratch game state shown
beneficial even stationary environments (Sutton, Koop, & Silver, 2007).

671

fiBranavan, Silver, & Barzilay

timate Q (s, a). accuracy Q (s, a) improves, quality action selection
improves vice versa, cycle continual improvement (Sutton & Barto, 1998).
success Monte-Carlo Search depends ability make fast, local estimate
action-value function roll-outs collected via simulated play. However games
large branching factors, may feasible collect sufficient roll-outs, especially
game simulation computationally expensive. Thus crucial learned
action-value function generalizes well small number roll-outs i.e., observed
states, actions rewards. One way achieve model action-value function
linear combination state action attributes:
Q (s, a) = w
~ f~(s, a).
f~(s, a) Rn real-valued feature function, w
~ weight vector. Prior work
shown linear value function approximations effective Monte-Carlo Search
framework (Silver et al., 2008).
Note learning action-value function Q(s, a) Monte-Carlo Search related
Reinforcement Learning (RL) (Sutton & Barto, 1998). fact, approach, use
standard gradient descent updates RL estimate parameters Q(s, a). is,
however, one crucial difference two techniques: general, goal RL
find Q(s, a) applicable state agent may observe existence.
Monte-Carlo Search framework, aim learn Q(s, a) specialized current state
s. essence, Q(s, a) relearned every observed state actual game, using
states, actions feedback simulations. relearning may seem suboptimal,
two distinct advantages: first, since Q(s, a) needs model current state,
representationally much simpler global action-value function. Second, due
simpler representation, learned fewer observations global actionvalue function (Sutton et al., 2007). properties important state
space extremely large, case domain.

5. Adding Linguistic Knowledge Monte-Carlo Framework
goal work improve performance Monte-Carlo Search framework
described above, using information automatically extracted text. section,
describe achieve terms model structure parameter estimation.
5.1 Model Structure
achieve aim leveraging textual information improve game-play, method
needs perform three tasks: (1) identify sentences relevant current game state, (2)
label sentences predicate structure, (3) predict good game actions combining
game features text features extracted via language analysis steps. first describe
tasks modeled separately showing integrate
single coherent model.
672

fiLearning Win Reading Manuals Monte-Carlo Framework

procedure PlayGame ()
Initialize game state fixed starting state
s1 s0
= 1 . . .
Run N simulated games
= 1 . . . N
(ai , ri ) SimulateGame (st )
end
Compute average observed utility action
1 X
arg max
ri
Na

i:ai =a

Execute selected action game
st+1 (s0 | st , )
end

procedure SimulateGame (st )
u = . . .
Compute Q function approximation
Q (su , a) = w
~ f~(su , a)
Sample action action-value function -greedy fashion:

uniform (a A)
probability
au (su , a) =

arg max Q (su , a) otherwise


Execute selected action game:
su+1 (s0 | su , au )
game lost
break
end
Update parameters w
~ Q (st , a)
Return action observed utility:
return , R(s )
Algorithm 1: general Monte-Carlo algorithm.
673

fiBranavan, Silver, & Barzilay

5.1.1 Modeling Sentence Relevance
discussed Section 1, small fraction strategy document likely provide
guidance relevant current game context. Therefore, effectively use information
given document d, first need identify sentence yi relevant
current game state action a.6 model decision log-linear distribution,
defining probability yi relevant sentence as:
~

p(y = yi |s, a, d) e~u(yi ,s,a,d) .

(1)

~ , s, a, d) Rn feature function, ~u parameters need estimate.
(y
~
function ()
encodes features combine attributes sentence yi
attributes game state action. features allow model learn correlations
game attributes attributes relevant sentences.
5.1.2 Modeling Predicate Structure
using text guide action selection, addition using word-level correspondences,
would also like leverage information encoded structure sentence.
example, verbs sentence might likely describe suggested game actions.
aim access information inducing task-centric predicate structure
sentences. is, label words sentence either action-description, statedescription background. Given sentence precomputed dependency parse q,
model word-by-word labeling decision log-linear fashion i.e., distribution
predicate labeling z sentence given by:
p(z |y, q) = p(~e |y, q)

=
p(ej |j, y, q),

(2)

j
~

p(ej |j, y, q) e~v(ej ,j,y,q) ,
~ j , j, y, q) Rn ,
ej predicate label j th word. feature function (e
addition encoding word type part-of-speech tag, also includes dependency parse
information word. features allow predicate labeling decision condition
syntactic structure sentence.
5.1.3 Modeling Action-Value Function
relevant sentence identified labeled predicate structure,
algorithm needs use information along attributes current game state
select best possible game action a. end, redefine action-value function
Q(s, a) weighted linear combination features game text information:
Q(s0 , a0 ) = w
~ f~(s, a, yi , zi ).

(3)

6. use approximation selecting single relevant sentence alternative combining
features sentences text, weighted relevance probability p(y = yi |s, a, d).
setup computationally expensive one used here.

674

fiLearning Win Reading Manuals Monte-Carlo Framework

Input layer:

Deterministic feature
layer:

Output layer

Hidden layer encoding
sentence relevance
Hidden layer encoding
predicate labeling

Figure 4: structure neural network model. rectangle represents collection
units layer, shaded trapezoids show connections layers.
fixed, real-valued feature function ~x(s, a, d) transforms game state s, action
a, strategy document input vector ~x. second layer contains
two disjoint sets hidden units ~y ~z, ~y encodes sentence relevance
decisions, ~z predicate labeling. softmax layers, one
unit active time. units third layer f~(s, a, yi , zi ) set
fixed real valued feature functions s, a, active units yi zi ~y
~z respectively.

s0 = hs, di, a0 = ha, yi , zi i, w
~ weight vector, f~(s, a, yi , zi ) Rn feature
function state s, action a, relevant sentence yi , predicate labeling zi .
structure action-value function allows explicitly learn correlations
textual information, game states actions. action maximizes Q(s, a)
selected best action state s: 7
= arg max Q(s, a).


5.1.4 Complete Joint Model
two text analysis models, action-value function described form three
primary components text-aware game playing algorithm. construct single
principled model components representing via different layers
multi-layer neural network shown Figure 4. Essentially, text analysis decisions
modeled latent variables second, hidden layer network, final
output layer models action-value function.
7. Note select action based Q(s, a), depends relevant sentence yi . sentence
selected conditioned action a. may look like cyclic dependency actions
sentence relevance. However, case since Q(s, a), therefore sentence relevance
p(y|s, a, d), computed every candidate action A. actual game action selected
estimate Q(s, a).

675

fiBranavan, Silver, & Barzilay

input layer ~x neural network encodes inputs model i.e.,
current state s, candidate action a, document d. second layer consists two
disjoint sets hidden units ~y ~z, set operates stochastic 1-of-n softmax
selection layer (Bridle, 1990). activation function units layer standard
softmax function:
.X
p(yi = 1|~x) = e~ui ~x
e~uk ~x ,
k

ith

yi
hidden unit ~y , ~ui weight vector corresponding yi , k
number units layer. Given activation function mathematically
equivalent log-linear distribution, layers ~y ~z operate like log-linear models.
Node activation softmax layer simulates sampling log-linear distribution.
use layer ~y replicate log-linear model sentence relevance Equation (1),
node yi representing single sentence. Similarly, unit zi layer ~z represents
complete predicate labeling sentence, Equation (2).8
third feature layer f~ neural network deterministically computed given
active units yi zi softmax layers, values input layer. unit
layer corresponds fixed feature function fk (s, a, yi , zi ) R. Finally output layer
encodes action-value function Q(s, a) weighted linear combination units
feature layer, thereby replicating Equation (3) completing joint model.
example kind correlations learned model, consider Figure 5.
Here, relevant sentence already selected given game state. predicate
labeling sentence identified words irrigate settler describing
action take. game roll-outs return higher rewards irrigate action
settler unit, model learn association action words
describe it. Similarly, learn association state description words
feature values current game state e.g., word city binary feature nearcity. allows method leverage automatically extracted textual information
improve game play.
5.2 Parameter Estimation
Learning method performed online fashion: game state st ,
algorithm performs simulated game roll-out, observes outcome simulation,
updates parameters ~u, ~v w
~ action-value function Q(st , ). shown
Figure 3, three steps repeated fixed number times actual game state.
information roll-outs used select actual game action.
algorithm relearns parameters action-value function every new game state
st . specializes action-value function subgame starting st . Learning
specialized Q(st , ) game state common useful games complex
state spaces dynamics, learning single global function approximation
particularly difficult (Sutton et al., 2007). consequence function specialization
need online learning since cannot predict games states seen
8. intention incorporate, action-value function, information relevant
sentence. Therefore, practice, perform predicate labeling sentence selected
relevance component model.

676

fiLearning Win Reading Manuals Monte-Carlo Framework

Settlers unit, candidate action 1:
plains

Features:
action = irrigate action-word = "irrigate"
action = irrigate state-word = "land"
action = irrigate terrain = plains
action = irrigate unit-type = settler
state-word = "city" near-city = true

city

Settlers unit, candidate action 2:

settler unit

Relevant text: "Use settlers irrigate land near city"
Predicted action words:

"irrigate", "settler"

Predicted state words:

"land", "near", "city"

irrigate

Features:
action = build-city
action = build-city
action = build-city
action = build-city
state-word = "city"







build-city

action-word = "irrigate"
state-word = "land"
terrain = plains
unit-type = settler
near-city = true

Figure 5: example text game attributes, resulting candidate action features.
left portion game state arrows indicating game attributes.
Also left sentence relevant game state along action
state words identified predicate labeling. right two candidate
actions settler unit along corresponding features. mentioned
relevant sentence, irrigate better two actions executing
lead future higher game scores. feedback features shown
allow model learn effective mappings actionword irrigate action irrigate, state-word city game
attribute near-city.

testing, function specialization states cannot done priori, ruling
traditional training/test separation.
Since model non-linear approximation underlying action-value function
game, learn model parameters applying non-linear regression observed final
utilities simulated roll-outs. Specifically, adjust parameters stochastic
gradient descent, minimize mean-squared error action-value Q(s, a)
final utility R(s ) observed game state action a. resulting update
model parameters form:

= [R(s ) Q(s, a)]2
2
= [R(s ) Q(s, a)] Q(s, a; ),
learning rate parameter. minimization performed via standard error
backpropagation (Bryson & Ho, 1969; Rumelhart, Hinton, & Williams, 1986), resulting
following online parameter updates:
w
~ w
~ + w [Q R(s )] f~(s, a, yi , zj ),
~ui ~ui + u [Q R(s )] Q ~x [1 p(yi |)],
~vi ~vi + v [Q R(s )] Q ~x [1 p(zi |)].
677

fiBranavan, Silver, & Barzilay

w learning rate, Q = Q(s, a), w,
~ ~ui ~vi parameters
final layer, sentence relevance layer predicate labeling layer respectively.
derivations update equations given Appendix

6. Applying Model
game test model on, Civilization II, multi-player strategy game set either
Earth randomly generated world. player acts ruler one civilization,
starts game units i.e., two Settlers, two Workers one Explorer.
goal expand civilization developing new technologies, building cities new
units, win game either controlling entire world, successfully sending
spaceship another world. map game world divided grid typically
4000 squares, grid location represents tile either land sea. Figure 6 shows
portion world map particular instance game, along game
units one player. experiments, consider two-player game Civilization II
map 1000 squares smallest map allowed Freeciv. map size used
novice human players looking easier game, well advanced players wanting
game shorter duration. test algorithms built-in AI player
game, difficulty level default Normal setting.9
6.1 Game States Actions
define game state Monte-Carlo search, map game world, along
attributes map tile, location attributes players cities
units. examples attributes shown Figure 7. space possible
actions city unit defined game rules given current game state.
example, cities construct buildings harbors banks, create new units
various types; individual units move around grid, perform unit
specific actions irrigation Settlers, military defense Archers. Since
player controls multiple cities units, players action space turn defined
combination possible actions cities units. experiments,
average, player controls approximately 18 units unit 15 possible actions.
resulting action space player large i.e., 1021 . effectively deal
large action space, assume given state, actions individual city
unit independent actions cities units player.10
time, maximize parameter sharing using single action-value function
cities units player.

9. Freeciv five difficulty settings: Novice, Easy, Normal, Hard Cheating. evidenced discussions games online forum (http://freeciv.wikia.com/index.php?title=Forum:Playing Freeciv),
human players new game find even Novice setting hard.
10. Since player executes game actions turn, i.e. opposing units fixed individual players
turn, opponents moves enlarge players action space.

678

fiLearning Win Reading Manuals Monte-Carlo Framework

Figure 6: portion game map one instance Civilization II game. Three
cities, several units single player visible map. Also visible
different terrain attributes map tiles, grassland, hills, mountains
deserts.

Nation attributes:
-

City attributes:
-

Amount gold treasury
% world controlled
Number cities
Population
Known technologies

Map tile attributes:
-

City population
Surrounding terrain resources
Amount food & resources produced
Number units supported city
Number & type units present

Unit attributes:

Terrain type (e.g. grassland, mountain, etc)
Tile resources (e.g. wheat, coal, wildlife, etc)
Tile river
Construction tile (city, road, rail, etc)
Types units (own enemy) present

-

Unit type (e.g., worker, explorer, archer, etc)
Unit health & hit points
Unit experience
unit city?
unit fortied?

Figure 7: Example attributes game state.

679

fiBranavan, Silver, & Barzilay

6.2 Utility Function
Critically important Monte-Carlo search algorithm, availability utility
function evaluate outcomes simulated game roll-outs. typical application algorithm, final game outcome terms victory loss used
utility function (Tesauro & Galperin, 1996). Unfortunately, complexity Civilization
II, length typical game, precludes possibility running simulation roll-outs
game completion. game, however, provides player real valued game
score, noisy indicator strength civilization. Since playing
two-player game, players score relative opponents used utility
function. Specifically, use ratio game score two players.11
6.3 Features
components method operate features computed basic set text
game attributes. text attributes include words sentence along
parts-of-speech dependency parse information dependency types parent
words. basic game attributes encode game information available human players
via games graphical user interface. examples attributes shown
Figure 7.
identify sentence relevant current game state candidate action,
sentence relevance component computes features combined basic attributes
~ two types first
game sentence text. features ,
computes Cartesian product attributes game attributes
candidate sentence. second type consists binary features test overlap
words candidate sentence, text labels current game state
candidate action. Given 3.2% word tokens manual overlap
labels game, similarity features highly sparse. However, serve
signposts guide learner shown results, method able operate
effectively even absence features, performs better present.
Predicate labeling, unlike sentence relevance, purely language task
~ compute
operates basic text attributes. features component, ,
Cartesian product candidate predicate label words type, part-of-speech
tag, dependency parse information. final component model, action-value
approximation, operates attributes game state, candidate action,
sentence selected relevant, predicate labeling sentence. features
layer, f~, compute three way Cartesian product attributes candidate
action, attributes game state, predicate labeled words relevant
~
~ f~ compute approximately 158,500, 7,900, 306,800 features
sentence. Overall, ,
respectively resulting total 473,200 features full model. Figure 8 shows
examples features.

11. difference players scores also used utility function. However, practice
score ratio produced better empirical performance across algorithms baselines.

680

fiLearning Win Reading Manuals Monte-Carlo Framework

Sentence relevance features:
1 action = build-city
& tile-has-river = true
& word = "build"

1 action = irrigate
& tile-is-next-to-city = true
& word = "irrigate"

0 otherwise

0 otherwise

Predicate labeling features:
1 label = action
& word = "city"
& parent-word = "build"

1 label = state
& word = "city"
& parent-label = "near"

0 otherwise

0 otherwise

Action-value features:
1 action = build-city
& tile-has-river = true
& action-word = "build"
& state-word = "river"

1 action = irrigate
& tile-terrain = plains
& action-word = "irrigate"
& state-word = "city"

0 otherwise

0 otherwise

Figure 8: examples features used model. feature, conditions
test game attributes highlighted blue, test words
game manual highlighted red.

7. Experimental Setup
section, describe datasets, evaluation metrics, experimental framework
used test performance method various baselines.
7.1 Datasets
use official game manual Civilization II strategy guide document.12
text manual uses vocabulary 3638 word types, composed 2083 sentences,
average 16.9 words long. manual contains information rules
game, game user interface, basic strategy advice different aspects
game. use Stanford parser (de Marneffe, MacCartney, & Manning, 2006),
default settings, generate dependency parse information sentences game
manual.
7.2 Experimental Framework
apply method Civilization II game, use games open source reimplementation Freeciv.13 instrumented FreeCiv allow method programmatically
12. www.civfanatics.com/content/civ2/reference/Civ2manual.zip
13. http://freeciv.wikia.com. Game version 2.2

681

fiBranavan, Silver, & Barzilay

Primary Game
Monte-Carlo
Player

Game
Server

Modied Game
GUI Client

In-memory
File System

Game Simulation 1

Game
Strategy Guide

Game
Server

Modied Game
GUI Client

Game State

Game Simulation 2
Game
Server

Modied Game
GUI Client

Game Simulation 8
Game
Server

Modied Game
GUI Client

Figure 9: diagram experimental framework, showing Monte-Carlo player,
server primary game playing aims win, multiple game
servers simulated play. Communications multiple processes comprising framework via UNIX sockets in-memory file system.

control game i.e., measure current game state, execute game actions,
save/load current game state, start end games.14
Across experiments, start game initial state run 100
steps. step, perform 500 Monte-Carlo roll-outs. roll-out run 20
simulated game steps halting simulation evaluating outcome. Note
simulated game step, algorithm needs select action game unit.
Given average number units per player 18, results 180,000 decisions
500 roll-outs. pairing decisions corresponding roll-out
outcome used datapoint update model parameters. use fixed learning rate
0.0001 experiments. method, baselines, run 200
independent games manner, evaluations averaged across 200 runs.
use experimental settings across methods, model parameters
initialized zero.
experimental setup consists Monte-Carlo player, primary game
aim play win, set simulation games. primary game simula14. addition instrumentation, code FreeCiv (both server client) changed increase
simulation speed several orders magnitude, remove bugs caused game crash.
best knowledge, game rules functionality identical unmodified Freeciv
version 2.2

682

fiLearning Win Reading Manuals Monte-Carlo Framework

tions simply separate instances Freeciv game. instance Freeciv game
made one server process, runs actual game, one client process,
controlled Monte-Carlo player. start roll-out, simulations
initialized current state primary game via game save/reload functionality
Freeciv. Figure 9 shows diagram experimental framework.
experiments run typical desktop PCs single Intel Core i7 CPUs (4
hyper-threaded cores per CPU). algorithms implemented execute 8 simulation
roll-outs parallel connecting 8 independent simulation games. computational
setup, approximately 5 simulation roll-outs executed per second full model,
single game 100 steps runs 3 hours. Since treat Freeciv game code
black box, special care taken ensure consistency across experiments: code
compiled one specific machine, single fixed build environment (gcc 4.3.2);
experiments run identical settings fixed set machines running fixed
OS configuration (Linux kernel 2.6.35-25, libc 2.12.1).

7.3 Evaluation Metrics

wish evaluate two aspects method: well improves game play leveraging textual information, accurately analyzes text learning game feedback.
evaluate first aspect comparing method various baselines terms
percentage games built-in AI Freeciv. AI fixed heuristic
algorithm designed using extensive knowledge game, intention challenging human players.15 such, provides good open-reference baseline. evaluate
method measuring percentage games won, averaged 100 independent runs.
However, full games sometimes last multiple days, making difficult extensive analysis model performance contributing factors. reason, primary
evaluation measures percentage games within first 100 game steps, averaged
200 independent runs. evaluation underestimate model performance
game player gaining control entire game map within
100 steps considered loss. Since games remain tied 100 steps, two equally
matched average players, playing other, likely win rate close
zero evaluation.

8. Results

adequately characterize performance method, evaluate respect
several different aspects. section, first describe game playing performance
analyze impact textual information. Then, investigate quality text
analysis produced model terms sentence relevance predicate labeling.
683

fiBranavan, Silver, & Barzilay

Method
Random
Built-in AI
Game
Latent variable
Full model
Randomized text

% Win
0
0
17.3
26.1
53.7
40.3

% Loss
100
0
5.3
3.7
5.9
4.3

Std. Err.


2.7
3.1
3.5
3.4

Table 1: Win rate method several baselines within first 100 game steps,
playing built-in game AI. Games neither lost still
ongoing. models win rate statistically significant baselines.
results averaged across 200 independent game runs. standard errors shown
percentage wins.

Method
Game
Latent variable
Full model

% Wins
24.8
31.5
65.4

Standard Error
4.3
4.6
4.8

Table 2: Win rate method two text-unaware baselines built-in AI.
results averaged across 100 independent game runs.

8.1 Game Performance
Table 1 shows performance method several baselines primary 100-step
evaluation. scenario, language-aware Monte-Carlo algorithm wins average
53.7% games, substantially outperforming baselines, best non-languageaware method win rate 26.1%. dismal performance Random baseline
games Built-in AI, playing itself, indications difficulty
winning games within first 100 steps. shown Table 2, evaluated full length
games, method win rate 65.4% compared 31.5% best text-unaware
baseline.16

15. AI constrained follow rules game, access information typically
available human players, information technology, cities units opponents.
methods hand restricted actions information available human players.
16. Note performance methods full games different listed previous
publications (Branavan, Silver, & Barzilay, 2011a, 2011b). previous numbers biased
code flaw FreeCiv caused game sporadically crash middle game play.
originally believed crash random, subsequently discovered happen often losing
games, thereby biasing win rates methods upwards. numbers presented
game bug fixed, crashes observed experiments.

684

fiObserved game score

Learning Win Reading Manuals Monte-Carlo Framework

Monte-Carlo rollouts

Figure 10: Observed game score function Monte-Carlo roll-outs text-aware
full model, text-unaware latent-variable model. Model parameters
updated roll-out, thus performance improves roll-outs.
seen, full models performance improves dramatically small number
roll-outs, demonstrating benefit derives textual information.

8.1.1 Textual Advice Game Performance
verify characterize impact textual advice models performance,
compare several baselines access textual information.
simplest methods, Game only, models action-value function Q(s, a) linear
approximation games state action attributes. non-text-aware method wins
17.3% games (see Table 1). confirm methods improved performance
simply due inherently richer non-linear approximation, also evaluate two
ablative non-linear baselines. first these, Latent variable extends linear actionvalue function Game set latent variables. essence four layer
neural network, similar full model, second layers units activated
based game information. baseline wins 26.1% games (Table 1), significantly
improving linear Game baseline, still trailing text-aware method
27%. second ablative baseline, Randomized text, identical model,
except given randomly generated document input. generate document
randomly permuting locations words game manual, thereby maintaining
documents statistical properties terms type frequencies. ensures
number latent variables baseline equal full model. Thus,
baseline model capacity equal text-aware method access
textual information. performance baseline, wins 40.3% games,
confirms information extracted text indeed instrumental performance
method.
685

fiBranavan, Silver, & Barzilay

Figure 10 provides insight textual information helps improve game performance
shows observed game score Monte-Carlo roll-outs full model
latent-variable baseline. seen figure, textual information guides
model high-score region search space far quicker non-text aware
method, thus resulting better overall performance. evaluate performance
method varies amount available textual-information, conduct
experiment random portions text given algorithm. shown
Figure 11, methods performance varies linearly function amount text,
Randomized text experiment corresponding point information
available text.
8.1.2 Impact Seed Vocabulary Performance
sentence relevance component model uses features compute similarity
words sentence, text labels game state action. assumes
availability seed vocabulary names game attributes. domain, 256
unique text labels present game, 135 occur vocabulary game manual.
results sparse seed vocabulary 135 words, covering 3.7% word types
3.2% word tokens manual. Despite sparsity, seed vocabulary
potentially large impact model performance since provides initial set word
groundings. evaluate importance initial grounding, test method
empty seed vocabulary. setup, full model wins 49.0% games, showing
seed words important, method also operate effectively
absence.
8.1.3 Linguistic Representation Game Performance
characterize contribution language game performance, conduct series
evaluations vary type complexity linguistic analysis performed
method. results evaluation shown Table 3. first these, Sentence
relevance, highlights contributions two language components model.
algorithm, identical full model lacks predicate labeling component,
wins 46.7% games, showing essential identify textual advice relevant
current game state, deeper syntactic analysis extracted text substantially
improves performance.
evaluate importance dependency parse information language analysis,
vary type features available predicate labeling component model.
first ablative experiments, dependency information, removes dependency
features leaving predicate labeling operate word type features. performance
baseline, win rate 39.6%, clearly shows dependency features crucial
model performance. remaining three methods dependency label, dependency
parent POS tag dependency parent word drop dependency feature
named after. contribution features model performance seen
Table 3.
686

fiWin rate

Learning Win Reading Manuals Monte-Carlo Framework

Random
text

Percentage document text given model

Figure 11: performance text-aware model function amount text
available it. construct partial documents randomly sub-sampling sentences full game manual. x-axis shows amount sentences
given method ratio full text. leftmost extreme
performance Randomized Text baseline, showing fits
performance trend point useful textual information.
Method
Full model
Sentence relevance
dependency information
dependency label
depend. parent POS tag
depend. parent word

% Win
53.7
46.7
39.6
50.1
42.6
33.0

% Loss
5.9
2.8
3.0
3.0
4.0
4.0

Std. Err.
3.5
3.5
3.4
3.5
3.5
3.3

Table 3: Win rates several ablated versions model, showing contribution
different aspects textual information game performance. Sentence relevance
identical Full model, except lacks predicate labeling component.
four methods bottom table ablate specific dependency features
(as indicated methods name) predicate labeling component
full model.

8.1.4 Model Complexity vs Computation Time Trade-off
One inherent disadvantage non-linear models, compared simpler linear models,
increase computation time required parameter estimation. Monte-Carlo
Search setup, model parameters re-estimated simulated roll-out. Therefore,
given fixed amount time, roll-outs done simpler faster model.
nature, performance Monte-Carlo Search improves number rollouts. trade-off model complexity roll-outs important since simpler
687

fiBranavan, Silver, & Barzilay

60%
Full model
Latent variable
Game
ro
llo

ut



50%

0



ts

20

0

50

ut

0r
oll
-ou

30%

10

Win rate

40%


llro

20%

10%

0%

0

20

40

60

80

100

120

140

Computation time per game step (seconds)

Figure 12: Win rate function computation time per game step. MonteCarlo search method, win rate computation time measured 100,
200 500 roll-outs per game step, respectively.

model could compensate using roll-outs, thereby outperform complex
ones. scenario particularly relevant games players limited amount
time turn.
explore trade-off, vary number simulation roll-outs allowed
method game step, recording win-rate average computation time per
game. Figure 12 shows results evaluation 100, 200 500 roll-outs.
complex methods higher computational demands, results clearly show
even given fixed amount computation time per game step, text-aware
model still produces best performance wide margin.
8.1.5 Learned Game Strategy
Qualitatively, methods described learn basic rush strategy. Essentially,
attempt develop basic technologies, build army, take opposing cities
quickly possible. performance difference different models essentially
due well learn strategy.
two basic reasons algorithms learn rush strategy. First, since
attempting maximize game score, methods implicitly biased towards finding
fastest way win happens rush strategy playing
built-in AI Civilization 2. Second, complex strategies typically require
coordination multiple game units. Since models assume game units independent,
688

fiLearning Win Reading Manuals Monte-Carlo Framework

Phalanxes twice eective defending cities warriors.
Build city plains grassland river running it.




rename city like, we'll refer washington.
many dierent strategies dictating order
advances researched

road built, use settlers start improving terrain.
















settlers becomes active, chose build road.












Use settlers engineers improve terrain square within city radius
























Figure 13: Examples methods sentence relevance predicate labeling decisions.
box shows two sentences (identified green check marks)
predicted relevant, two not. box shows
predicted predicate structure three sentences, indicating state
description,A action description background words unmarked. Mistakes
identified crosses.

cannot explicitly learn coordination putting many complex strategies beyond
capabilities algorithms.
8.2 Accuracy Linguistic Analysis
described Section 5, text analysis method tightly coupled game playing
terms modeling, terms learning game feedback. seen
results thus far, text analysis indeed help game play. section
focus game-driven text analysis itself, investigate well conforms
common notions linguistic correctness. comparing model predictions
sentence relevance predicate labeling manual annotations.
8.2.1 Sentence Relevance
Figure 13 shows examples sentence relevance decisions produced method.
evaluate accuracy decisions, would ideally like use ground-truth
relevance annotation games user manual. however, impractical since
relevance decision dependent game context, hence specific time step
game instance. Therefore, evaluate sentence relevance accuracy using synthetic
document. create document combining original game manual equal
689

fiSentence relevance accuracy

Branavan, Silver, & Barzilay

1.0
0.8
0.6
0.4
Sentence relevance
Moving average

0.2
0

20

40

60

80

100

Game step

Figure 14: Accuracy methods sentence relevance predictions, averaged 100 independent runs.

number sentences known irrelevant game. sentences
collected randomly sampling Wall Street Journal corpus (Marcus, Santorini,
& Marcinkiewicz, 1993).17 evaluate sentence relevance synthetic document
measuring accuracy game manual sentences picked relevant.
evaluation, method achieves average accuracy 71.8%. Given
model differentiate game manual text Wall Street Journal,
number may seem disappointing. Furthermore, seen Figure 14,
sentence relevance accuracy varies widely game progresses, high average
94.2% initial 25 game steps. reality, pattern high initial accuracy followed lower average entirely surprising: official game manual Civilization
II written first time players. such, focuses initial portion game,
providing little strategy advice relevant subsequent game play.18 reason
observed sentence relevance trend, would also expect final layer neural
network emphasize game features text features first 25 steps game.
indeed case, seen Figure 15.
test hypothesis, perform experiment first n steps
game played using full model, subsequent 100 n steps played without
using textual information. results evaluation several values n
given Figure 16, showing initial phase game indeed information
game manual useful. fact, hybrid method performs well
full model n = 50, achieving 53.3% win rate. shows method
17. Note sentences WSJ corpus contain words city potentially confuse
algorithm, causing select sentences relevant game play.
18. reminiscent opening books games like Chess Go, aim guide player
playable middle game, without providing much information subsequent game play.

690

fiLearning Win Reading Manuals Monte-Carlo Framework

0.5

Game features dominate

1.0

Text features dominate

Text feature importance

1.5

0
20

40

60

80

100

Game step

Figure 15: Difference norms text features game features
output layer neural network. Beyond initial 25 steps game,
method relies increasingly game features.

Win rate

60%

40%

20%

0%
20

40

60

80

100

# initial game steps text information used

Figure 16: Graph showing availability textual information initial steps
game affects performance full model. Textual information
given model first n steps (the x axis), beyond point
algorithm access text, becomes equivalent Latent Variable
model i.e., best non-text model.

able accurately identify relevant sentences information contain
pertinent game play, likely produce better game performance.
691

fiBranavan, Silver, & Barzilay

Method
Random labeling
Model, first 100 steps
Model, first 25 steps

S/A/B
33.3%
45.1%
48.0%

S/A
50.0%
78.9%
92.7%

Table 4: Predicate labeling accuracy method random baseline. Column
S/A/B shows performance three-way labeling words state, action
background, column S/A shows accuracy task differentiating
state action words.
game attribute

word

state: grassland

"city"

state: grassland

"build"

state: hills

"build"

action: settlers_build_city

"city"

action: set_research

"discovery"

action: settlers_build_city

"settler"

action: settlers_goto_location

"build"

action: city_build_barracks

"construct"

action: research_alphabet

"develop"

action: set_research

"discovery"

Figure 17: Examples word game attribute associations learned via feature
weights model.
8.2.2 Predicate Labeling
Figure 13 shows examples predicate structure output model. evaluate
accuracy labeling comparing gold-standard annotation game
manual.19 Table 4 shows performance method terms accurately labels
words state, action background, also accurately differentiates state
action words. addition showing performance improvement random
baseline, results display clear trend: evaluations, labeling accuracy
higher initial stages game. expected since model relies
heavily textual features beginning game (see Figure 15).
verify usefulness methods predicate labeling, perform final set
experiments predicate labels selected uniformly random within full model.
random labeling results win rate 44% performance similar sentence
relevance model uses predicate information. confirms method
able identify predicate structure which, noisy, provides information relevant
game play. Figure 17 shows examples textual information grounded
game, way associations learned words game attributes final
layer full model. example, model learns strong association
19. Note ground truth labeling words either action-description, state-description, background
based purely semantics sentence, independent game state. reason,
manual annotation feasible, unlike case sentence relevance.

692

fiLearning Win Reading Manuals Monte-Carlo Framework

game-state attribute grassland words city build, indicating textual
information building cities maybe useful players unit near grassland.

9. Conclusions
paper presented novel approach improving performance control
applications leveraging information automatically extracted text documents,
time learning language analysis based control feedback. model biases
learned strategy enriching policy function text features, thereby modeling
mapping words manual state-specific action selection. effectively learn
grounding, model identifies text relevant current game state, induces
predicate structure text. linguistic decisions modeled jointly using
non-linear policy function trained Monte-Carlo Search framework.
Empirical results show model able significantly improve game win rate
leveraging textual information compared strong language-agnostic baselines.
also demonstrate despite increased complexity model, knowledge
acquires enables sustain good performance even number simulations
reduced. Moreover, deeper linguistic analysis, form predicate labeling text,
improves game play. show information syntactic structure
text crucial analysis, ignoring information large impact
model performance. Finally, experiments demonstrate tightly coupling control
linguistic features, model able deliver robust performance presence
noise inherent automatic language analysis.

Bibliographical Note
Portions work previously presented two conference publications (Branavan
et al., 2011a, 2011b). article significantly extends previous work, notably
providing analysis model properties impact linguistic representation
model performance, dependence model bootstrapping conditions, tradeoff models representational power empirical complexity (Section 8).
paper also significantly increases volume experiments base
conclusions. addition, provide comprehensive description model, providing
full mathematical derivations supporting algorithm (Section 5.1 Appendix A).

Acknowledgments
authors acknowledge support NSF (CAREER grant IIS-0448168, grant IIS0835652), DARPA BOLT Program (HR0011-11-2-0008), DARPA Machine Reading
Program (FA8750-09-C-0172, PO#4910018860), Batelle (PO#300662) Microsoft
Research New Faculty Fellowship. Thanks anonymous reviewers, Michael Collins,
Tommi Jaakkola, Leslie Kaelbling, Nate Kushman, Sasha Rush, Luke Zettlemoyer,
MIT NLP group suggestions comments. opinions, findings, conclusions,
recommendations expressed paper authors, necessarily
reflect views funding organizations.
693

fiBranavan, Silver, & Barzilay

Appendix A. Parameter Estimation
parameter model estimated via standard error backpropagation (Bryson &
Ho, 1969; Rumelhart et al., 1986). derive parameter updates, consider slightly
simplified neural network shown below. network identical model,
sake clarity, single second layer ~y instead two parallel second layers
~y ~z. parameter updates parallel layers ~y ~z similar, therefore
show derivation ~y addition updates final layer.

model, nodes yi network activated via softmax function;
third layer, f~, computed deterministically active nodes second layer
via function ~g (yi , ~x); output Q linear combination f~ weighted w:
~
p(yi = 1 | ~x; ~ui ) =

e~ui ~x
X
,
e~uk ~x
k

f~ =

X

~g (~x, yi ) p(yi | ~x; ~ui ),



Q = w
~ f~.
goal minimize mean-squared error e gradient descent. achieve
updating model parameters along gradient e respect parameter. Using
general term indicate models parameters, update takes form:
1
(Q R)2 ,
2
e
=

Q
= (Q R)
.


e =


Equation (4), updates final layer parameters given by:
Q
wi

= (Q R)
w
~ f~
wi
= (Q R) fi .

wi = (Q R)

694

(4)

fiLearning Win Reading Manuals Monte-Carlo Framework

Since model samples one relevant sentence yi , best predicate labeling
zi , resulting online updates output layer parameters w
~ are:
w
~ w
~ + w [Q R(s )] f~(s, a, yi , zj ),
w learning rate, Q = Q(s, a). updates second layers parameters similar, somewhat involved. Again, Equation (4),
ui,j

Q
ui,j

= (Q R)
w
~ f~
ui,j
X

w
~
~g (~x, yk ) p(yi | ~x; ~uk )
= (Q R)
ui,j
= (Q R)

k

= (Q R) w
~ ~g (~x, yi )


p(yi | ~x; ~ui ).
ui,j

(5)

Considering final term equation separately,

p(yi | ~x; ~ui ) =
ui,j

e~ui ~x
,
ui,j Z


=

Z =

X

e~uk ~x

k

eu~ ~x
e~ui ~x ui,j Z
u~ ~x
e
Z
Z

=
=
=
=
=
=

e~ui ~x

~ui ~x

e
log
Z
ui,j
Z
~ui ~x

e

xj
log Z
Z
ui,j
~ui ~x

e
1 Z
xj
Z
Z ui,j
"
#
~ui ~x
e
1 X ~uk ~x
xj
e
Z
Z ui,j
k
~ui ~x

e
1
~
uk ~
x
xj xj e
Z
Z
~ui ~x

e
e~ui ~x
xj 1
.
Z
Z




695

fiBranavan, Silver, & Barzilay

Therefore, Equation (5),
ui,j


p(yi | ~x; ~ui )
ui,j
~ui ~x


e
e~ui ~x
= (Q R) w
~ ~g (~x, yi )
xj 1
Z
Z
= (Q R) xj w
~ ~g (~x, yi ) p(yi | ~x; ~ui ) [1 p(yi | ~x; ~ui )]
= (Q R) w
~ ~g (~x, yi )

= (Q R) xj Q [1 p(yi | ~x; ~ui )] ,
Q = w
~ ~g (~x, yi ) p(yi | ~x; ~ui ).

resulting online updates sentence relevance predicate labeling parameters
~u ~v are:
~ui ~ui + u [Q R(s )] Q ~x [1 p(yi |)],
~vi ~vi + v [Q R(s )] Q ~x [1 p(zi |)].

696

fiLearning Win Reading Manuals Monte-Carlo Framework

Appendix B. Example Sentence Relevance Predictions
Shown portion strategy guide Civilization II. Sentences
identified relevant text-aware model highlighted green.

Choosing location.
building new city, carefully plan place it. Citizens
work terrain surrounding city square x-shaped pattern (see
city radius diagram showing exact dimensions). area called
city radius (the terrain square settlers standing
becomes city square). natural resources available
population settles affect ability produce food goods. Cities built
near water sources irrigate increase crop yields, cities
near mineral outcroppings mine raw materials. hand,
cities surrounded desert always handicapped aridness
terrain, cities encircled mountains find arable cropland
premium. addition economic potential within city's radius,
need consider proximity cities strategic value
location. Ideally, want locate cities areas offer combination
benefits : food population growth, raw materials production,
river coastal areas trade. possible, take advantage
presence special resources terrain squares (see terrain & movement
details benefits).
Strategic value.
strategic value city site final consideration. city square's
underlying terrain increase defender's strength city
comes attack. circumstances, defensive value
particular city's terrain might important economic value;
consider case continent narrows bottleneck rival
holds side. Good defensive terrain (hills, mountains, jungle)
generally poor food production inhibits early growth city.
need compromise growth defense, build city
plains grassland square river running possible.
yields decent trade production gains 50 percent defense bonus.
Regardless city built, city square easier defend
unimproved terrain. city build city walls
improvement, triples defense factors military units stationed
there. Also, units defending city square destroyed one time
lose. Outside cities, units stacked together destroyed
military unit stack defeated (units fortresses
exception; see fortresses). Placing cities seacoast gives
access ocean. launch ship units explore world
transport units overseas. coastal cities, sea power
inhibited.

697

fiBranavan, Silver, & Barzilay

Appendix C. Examples Predicate Labeling Predictions
Listed predicate labellings computed text-aware method example
sentences game manual. predicted labels indicated words
letters A, S, B action-description, state-description background respectively.
Incorrect labels indicated red check mark, along correct label brackets.
road built, use settlers start improving terrain.
















settlers becomes active, chose build road.












Use settlers engineers improve terrain square within city radius

(A)







(S)











Bronze working allows build phalanx units


B (S)









order expand civilization , need build cities

(S)





B

B (A)



order protect city , phalanx must remain inside

B(S)

B(S)



S(A)





B(A)

soon you've found decent site , want settlers build

B(S)

B(S)



B (A)

(B)





permanent settlement - city

(A)



city build city walls improvement

(S)

B (A)







city undefended , move friendly army city capture


B (S)











B

build city terrain square except ocean.


(A)

B (S)



(S)



launch ship units explore world transport units overseas


(A)





B (S)

B (S)



B

city disorder, disband distant military units, return home cities,

(S)







(A)



(A)



change home cities






build wonder discovered advance makes possible


(A)



698







fiLearning Win Reading Manuals Monte-Carlo Framework

Appendix D. Examples Learned Text Game Attribute Mappings
Shown examples word game-attribute associations learned
model. top ten game attributes strongest association feature weight
listed three example words attack, build grassland. fourth
word, settler, seven attributes non-zero weights experiments used collect
statistics.

attack

build

phalanx (unit)

worker_goto (action)

warriors (unit)

settler_autosettle (action)

colossus (wonder)

worker_autosettle (action)

city walls (city improvement)

pheasant (terrain attribute)

archers (unit)

settler_irrigate (action)

catapult (unit)

worker_mine (action)

palace (city improvement)

build_city_walls (action)

coinage (city production)

build_catapult (action)

city_build_warriors (action)

swamp (terrain attribute)

city_build_phalanx (action)

grassland (terrain attribute)

grassland

settler

settler_build_city (action)

settlers (state attribute)

worker_continue_action (action)

settler_build_city (action)

pheasant (terrain attribute)

city (state_attribute)

city_build_improvement (action)

grassland (terrain_attribute)

city_max_production (action)

plains (terrain_attribute)

settlers (state attribute)

road (terrain_attribute)

city_max_food (action)

workers (state attribute)

settler_goto (action)
worker_build_road (action)
pyramids (city attribute)

699

fiBranavan, Silver, & Barzilay

Appendix E. Features Used Model
Features used predict sentence relevance
following templates used compute features sentence relevance:
Word W present sentence.
Number words match text label current unit, attribute
immediate neighborhood unit, action consideration.
units type U, (e.g., worker) word W present sentence.
action type A, (e.g., irrigate) word W present sentence.
Features used predict predicate structure
following templates used compute features predicate labeling words.
label considered word (i.e., action, state background) denoted
L.
Label L word type W.
Label L part-of-speech tag word T.
Label L parent word dependency tree W.
Label L dependency type dependency parent word D.
Label L part-of-speech dependency parent word T.
Label L word leaf node dependency tree.
Label L word leaf node dependency tree.
Label L word matches state attribute name.
Label L word matches unit type name.
Label L word matches action name.
Features used model action-value function
following templates used compute features action-value approximation.
Unless otherwise mentioned, features look attributes player controlled
model.
Percentage world controlled.
Percentage world explored.
Players game score.
Opponents game score.
Number cities.
Average size cities.
Total size cities.
700

fiLearning Win Reading Manuals Monte-Carlo Framework

Number units.
Number veteran units.
Wealth gold.
Excess food produced.
Excess shield produced.
Excess trade produced.
Excess science produced.
Excess gold produced.
Excess luxury produced.
Name technology currently researched.
Percentage completion current research.
Percentage remaining current research.
Number game turns current research completed.
following feature templates applied city controlled player:
Current size city.
Number turns city grows size.
Amount food stored city.
Amount shield stored city (shields used construct new buildings
units city).
Turns remaining current construction completed.
Surplus food production city.
Surplus shield production city.
Surplus trade production city.
Surplus science production city.
Surplus gold production city.
Surplus luxury production city.
Distance closest friendly city.
Average distance friendly cities.
City governance type.
Type building unit currently construction.
Types buildings already constructed city.
Type terrain surrounding city.
Type resources available citys neighborhood.
701

fiBranavan, Silver, & Barzilay

another city neighborhood.
enemy unit neighborhood.
enemy city neighborhood.
following feature templates applied unit controlled player:
Type unit.
Moves left unit current game turn.
Current health unit.
Hit-points unit.
unit veteran.
Distance closest friendly city.
Average distance friendly cities.
Type terrain surrounding unit.
Type resources available units neighborhood.
enemy unit neighborhood.
enemy city neighborhood.
following feature templates applied predicate-labeled word sentence
selected relevant, combined current state action attributes:
Word W present sentence, action considered A.
Word W predicate label P present sentence, action considered
A.
Word W present sentence, current units type U, action
considered A.
Word W predicate label P present sentence, current units type U,
action considered A.
Word W present sentence, current units type U.
Word W predicate label P present sentence, current units type
U.
Word W present sentence, attribute text label present
current units neighborhood.
Word W predicate label P present sentence, attribute text label
present current units neighborhood.

702

fiLearning Win Reading Manuals Monte-Carlo Framework

References
Balla, R., & Fern, A. (2009). UCT tactical assault planning real-time strategy games.
Proceedings IJCAI, pp. 4045.
Barnard, K., & Forsyth, D. A. (2001). Learning semantics words pictures.
Proceedings ICCV, pp. 408415.
Barto, A. G., & Mahadevan, S. (2003). Recent advances hierarchical reinforcement
learning. Discrete Event Dynamic Systems, 13, 341379.
Billings, D., Castillo, L. P., Schaeffer, J., & Szafron, D. (1999). Using probabilistic knowledge
simulation play poker. Proceedings AAAI/IAAI, pp. 697703.
Branavan, S., Chen, H., Zettlemoyer, L., & Barzilay, R. (2009). Reinforcement learning
mapping instructions actions. Proceedings ACL, pp. 8290.
Branavan, S., Silver, D., & Barzilay, R. (2011a). Learning win reading manuals
monte-carlo framework. Proceedings ACL, pp. 268277.
Branavan, S., Silver, D., & Barzilay, R. (2011b). Non-linear monte-carlo search civilization
II. Proceedings IJCAI, pp. 24042410.
Branavan, S., Zettlemoyer, L., & Barzilay, R. (2010). Reading lines: Learning
map high-level instructions commands. Proceedings ACL, pp. 12681277.
Bridle, J. S. (1990). Training stochastic model recognition algorithms networks lead
maximum mutual information estimation parameters. Advances NIPS, pp.
211217.
Bryson, A. E., & Ho, Y.-C. (1969). Applied optimal control: optimization, estimation,
control. Blaisdell Publishing Company.
Chen, D. L., & Mooney, R. J. (2008). Learning sportscast: test grounded language
acquisition. Proceedings ICML, pp. 128135.
Chen, D. L., & Mooney, R. J. (2011). Learning interpret natural language navigation
instructions observations. Proceedings AAAI, pp. 859865.
Clarke, J., Goldwasser, D., Chang, M.-W., & Roth, D. (2010). Driving semantic parsing
worlds response. Proceedings CoNNL, pp. 1827.
de Marneffe, M.-C., MacCartney, B., & Manning, C. D. (2006). Generating typed dependency parses phrase structure parses. Proceedings LREC, pp. 449454.
Eisenstein, J., Clarke, J., Goldwasser, D., & Roth, D. (2009). Reading learn: Constructing
features semantic abstracts. Proceedings EMNLP, pp. 958967.
Fleischman, M., & Roy, D. (2005). Intentional context situated natural language learning.
Proceedings CoNLL, pp. 104111.
Gelly, S., Wang, Y., Munos, R., & Teytaud, O. (2006). Modification UCT patterns
Monte-Carlo Go. Tech. rep. 6062, INRIA.
Goldwasser, D., Reichart, R., Clarke, J., & Roth, D. (2011). Confidence driven unsupervised
semantic parsing. Proceedings ACL, pp. 14861495.

703

fiBranavan, Silver, & Barzilay

Gorniak, P., & Roy, D. (2005). Speaking sidekick: Understanding situated speech
computer role playing games. Proceedings AIIDE, pp. 5762.
Liang, P., Jordan, M. I., & Klein, D. (2009). Learning semantic correspondences less
supervision. Proceedings ACL, pp. 9199.
Liang, P., Jordan, M. I., & Klein, D. (2011). Learning dependency-based compositional
semantics. Proceedings ACL, pp. 590599.
Marcus, M. P., Santorini, B., & Marcinkiewicz, M. A. (1993). Building large annotated
corpus english: penn treebank. Computational Linguistics, 19 (2), 313330.
Oates, J. T. (2001). Grounding knowledge sensors: Unsupervised learning language
planning. Ph.D. thesis, University Massachusetts Amherst.
Roy, D. K., & Pentland, A. P. (2002). Learning words sights sounds: computational model. Cognitive Science 26, 113146.
Rumelhart, D. E., Hinton, G. E., & Williams, R. J. (1986). Learning representations
back-propagating errors. Nature, 323, 533536.
Schafer, J. (2008). UCT algorithm applied games imperfect information.
Diploma Thesis. Otto-von-Guericke-Universitat Magdeburg.
Sheppard, B. (2002). World-championship-caliber Scrabble. Artificial Intelligence, 134 (1-2),
241275.
Silver, D., Sutton, R., & Muller, M. (2008). Sample-based learning search permanent transient memories. Proceedings ICML, pp. 968975.
Siskind, J. M. (2001). Grounding lexical semantics verbs visual perception using
force dynamics event logic. Journal Artificial Intelligence Research, 15, 3190.
Sturtevant, N. (2008). analysis UCT multi-player games. Proceedings ICCG,
pp. 3749.
Sutton, R. S., & Barto, A. G. (1998). Reinforcement Learning: Introduction. MIT
Press.
Sutton, R. S., Koop, A., & Silver, D. (2007). role tracking stationary environments. Proceedings ICML, pp. 871878.
Tellex, S., Kollar, T., Dickerson, S., Walter, M. R., Banerjee, A. G., Teller, S., & Roy, N.
(2011). Understanding natural language commands robotic navigation mobile
manipulation. Proceedings AAAI, pp. 15071514.
Tesauro, G., & Galperin, G. (1996). On-line policy improvement using Monte-Carlo search.
Advances NIPS, pp. 10681074.
Vogel, A., & Jurafsky, D. (2010). Learning follow navigational directions. Proceedings
ACL, pp. 806814.
Yu, C., & Ballard, D. H. (2004). integration grounding language learning
objects. Proceedings AAAI, pp. 488493.
Zettlemoyer, L., & Collins, M. (2009). Learning context-dependent mappings sentences
logical form. Proceedings ACL, pp. 976984.

704

fiJournal Artificial Intelligence Research 43 (2012) 173210

Submitted 08/11; published 02/12

Counting-Based Search:
Branching Heuristics Constraint Satisfaction Problems
Gilles Pesant

gilles.pesant@polymtl.ca

Ecole polytechnique de Montreal, Montreal, Canada

Claude-Guy Quimper

claude-guy.quimper@ift.ulaval.ca

Universite Laval, Quebec, Canada

Alessandro Zanarini

alessandro.zanarini@dynadec.com

Dynadec Europe, Belgium

Abstract
Designing search heuristic constraint programming reliable across problem
domains important research topic recent years. paper concentrates
one family candidates: counting-based search. heuristics seek make branching
decisions preserve solutions determining proportion solutions
individual constraint agree decision. Whereas generic search heuristics
constraint programming rely local information level individual variable,
search heuristics based global information constraint level.
design several algorithms used count number solutions specific families
constraints propose search heuristics exploiting information. experimental part paper considers eight problem domains ranging well-established
benchmark puzzles rostering sport scheduling. initial empirical analysis identifies
heuristic maxSD robust candidate among proposals. evaluate latter
state art, including latest generic search heuristics, restarts,
discrepancy-based tree traversals. Experimental results show counting-based search
generally outperforms generic heuristics.

1. Introduction
Constraint Programming (cp) powerful technique solve combinatorial problems.
applies sophisticated inference reduce search space combination variableand value-selection heuristics guide exploration search space.
inference encapsulated constraint appearing model problem, users may
consider black box. contrast, search cp programmable, mixed
blessing. allows one easily tailor search problem, adding expertise domain
knowledge, may also discourage average user would prefer generic
fairly robust default search heuristic works well time. generic search
heuristics indeed available cp robustness remains issue.
Whereas generic search heuristics constraint programming rely information
level individual variable (e.g. domain size degree constraint
network), investigate search heuristics based global information. Global
constraints cp successful encapsulate powerful dedicated inference algorithms foremost bring underlying structure combinatorial
problems. exposed structure also exploited search. Search heuristics
c
2012
AI Access Foundation. rights reserved.

fiPesant, Quimper, & Zanarini

following fail-first principle (detect failure early possible) centered constraints guided count number solutions left constraint.
might example focus search constraint currently smallest number
solutions, recognizing failure necessarily occurs constraint admitting
solution. also count number solutions featuring given variable-value
assignment individual constraint, favoring assignments appearing high proportion
solutions hope choice generally brings us closer satisfying
whole csp.
concept counting-based search heuristics already introduced, recently Zanarini Pesant (2009). specific contributions paper are: additional counting algorithms, including families constraints, thus broadening
applicability heuristics; experiments include effect common features
search heuristics search tree traversal order, restarts learning; considerable
empirical evidence counting-based search outperforms generic heuristics.
rest paper: Section 2 provides background reviews related work; Sections 3 5 present counting algorithms several usual constraints; Section 6
introduces counting-based search heuristics exploit algorithms previous sections; Section 7 reports extensive experimental study comparing proposed
heuristics state-of-the-art generic heuristics many problem domains; finally Section 8
concludes paper.

2. Background Related Work
start usual general representation formalism cp.
Definition 1 (constraint satisfaction problem (csp)). Given finite set variables X =
{x1 , x2 , . . .}, finite domain possible values variables, = {D1 , . . . , D|X| },
xi Di (1 |X|), finite set constraints (relations) subsets X,
C = {c1 , c2 , . . .}, constraint satisfaction problem (X, D, C) asks assignment
value Di variable xi X satisfies (belongs to) cj C.
recall definitions notation Pesant (2005) Zanarini Pesant
(2009).
Definition 2 (solution count). Given constraint c(x1 , . . . , xn ) respective finite domains Di 1in, let #c(x1 , . . . , xn ) denote number n-tuples corresponding
relation, called solution count.
Definition 3 (solution density). Given constraint c(x1 , . . . , xn ), respective finite domains
Di 1in, variable xi scope c, value Di , call
(xi , d, c) =

#c(x1 , . . . , xi1 , d, xi+1 , . . . , xn )
#c(x1 , . . . , xn )

solution density pair (xi , d) c. measures often certain assignment part
solution c.
174

fiCounting-Based Search

Heuristics usually classified two main categories: static variable ordering heuristics
(SVOs) dynamic variable ordering heuristics (DVOs). former order variables
prior search revise ordering search. Common SVOs lexicographic order, lexico, decreasing degree (i.e. number constraints variable
involved), deg. DVOs generally considered effective exploit information
gathered search. often follow fail-first principle originally introduced
Haralick Elliott (1980, p. 263) i.e. succeed, try first likely
fail. authors proposed widely-used heuristic dom branches
variables smallest domain; aim heuristic minimize branch depth.
similar heuristic, proposed Brelaz (1979), selects variable smallest remaining domain breaks ties choosing one highest dynamic degree ddeg 1 (that is, one constraining largest number unbound variables). Bessiere
Regin (1996) Smith Grant (1998) combined domain degree information
minimizing ratio dom/deg dom/ddeg.

2.1 Impact-Based Heuristics
Refalo (2004) proposed Impact Based Search (IBS), heuristic chooses variable
whose instantiation triggers largest search space reduction (highest impact)
approximated reduction product variable domain cardinalities.
formally impact variable-value pair is:
I(xi = d) = 1

Paf ter
Pbef ore

Paf ter Pbef ore products domain cardinalities respectively
branching xi = (and propagating decision). impact either computed
exactly given node search (the exact computation provides better information
time consuming) approximated average reduction observed
search (hence automatically collected on-the-go almost additional cost), is:
P
k
= d) = kK (xi = d)
I(x
|K|
K index set impact observed far assignment xi = d.
variable impact defined Refalo (2004)
X
= d)
I(xi ) =
1 I(x
dDi0

Di0 current domain variable xi . Impact initialization fundamental
obtain good performance even root search tree; therefore, Refalo proposed
initialize impacts probing variable-value pair root node (note
subsumes reduced form singleton consistency root node quite
computationally costly). IBS selects variable largest impact (hence trying
1. also referred future degree forward degree literature.

175

fiPesant, Quimper, & Zanarini

maximize propagation effects reduction search space) selects
value smallest impact (hence leaving choices future variables).
interesting connection impact-based heuristics, Szymanek OSullivan
(2006) proposed query model constraints approximate number filtered
values constraint individually. information exploited design variable and/or value selection heuristic. Nonetheless, differs impact-based search
take consideration constraint separately, counting-based heuristics
(Zanarini & Pesant, 2009) information provided coarse-grained actual
solution counts.
2.2 Conflict-Driven Heuristics
Boussemart, Hemery, Lecoutre, Sais (2004) proposed conflict-driven variable ordering
heuristic: extended concept variable degree integrating simple effective
learning technique takes failures account. Basically constraint associated weight increased one time constraint leads failure (i.e.
domain wipe-out). variable weighted degree wdeg sum weights
constraints involved. Formally, weighted degree variable is:
X
wdeg (xi ) =
weight[c] | V ars(c) 3 xi |F utV ars(c)| > 1
cC

F utV ars(c) denotes uninstantiated variables constraint c, weight[c]
weight V ars(c) variables involved c. heuristics proposed simply choose
variable maximizes wdeg minimizes dom/wdeg. heuristics offer general
method deal global constraints: natural extension increase weight
every variable failed constraint may anything
failure, dilutes conflict information. also particularly sensitive
revision orderings (i.e. ordering propagation queue) hence leading varying
performance. Grimes Wallace (2006, 2007) proposed adaptations dom/wdeg
combined restarts updating weights value deletions well. Balafoutis
Stergiou (2008b) proposed, among improvements original dom/wdeg,
weight aging, constraint weights periodically reduced. limits inertia
constraints got significant weight early search critical
anymore later on.
Nowadays heuristics dom/wdeg IBS considered state art
generic heuristics clear dominance one (Balafoutis & Stergiou,
2008a). Finally note rely hypothesis learned early
search tend remain true throughout search tree: impacts change much
one search tree node other; constraints lead domain wipe-outs
different parts search tree.
2.3 Approximated Counting-Based Heuristics
idea using approximation number solutions problem heuristic
new. Kask, Dechter, Gogate (2004) approximate total number solutions
extending partial solution csp use value selection heuristic, choosing
176

fiCounting-Based Search

value whose assignment current variable gives largest approximate solution
count. implementation optimized binary constraints performs well compared
popular strategies. Hsu, Kitching, Bacchus, McIlraith (2007) later Bras,
Zanarini, Pesant (2009) apply Belief Propagation algorithm within Expectation
Maximization framework (EMBP) order approximate variable biases (or marginals)
i.e. probability variable takes given value solution. resulting heuristics tend
effective quite time-consuming. One way differentiate work
focus fine-grained information individual constraints whereas work
coarser information whole problem.

3. Counting Alldifferent Constraints
alldifferent constraint restricts set variables pairwise different (Regin,
1994).
Definition 4 (Alldifferent Constraint). Given set variables X = {x1 , . . . , xn }
respective domains D1 , . . . , Dn , set tuples allowed alldifferent(X) are:
{(d1 , d2 , . . . , dn ) | di Di , di 6= dj 6= j}

define associated (0-1) square matrix = (aid ) | i=1,...,n Di | rows
columns aid = 1 iff Di 2 . distinct values domains
variables, say p more, add p rows filled 1s matrix A. equivalent
representation given bipartite value graph vertex variable value
edges corresponding 1 entries A.
discussed Zanarini Pesant (2009), counting number solutions
alldifferent constraint equivalent computing permanent (or number
maximum matchings value graph), formally defined
perm(A) =

n
X

a1,d perm(A1,d )

(1)

d=1

A1,d denotes submatrix obtained removing row 1 column (the
permanent empty matrix equal 1). p extra rows added, result must
divided p! shown Zanarini Pesant (2010).
computing permanent well-known #P -complete (Valiant, 1979),
Zanarini Pesant (2009) developed approach based sampling gave close
approximations led effective heuristics hard instances. However
competitive easy medium difficulty instances additional computational
effort. next section describes approach based upper bounds, trading approximation accuracy significant speedup counting procedure.3
2. notational convenience without loss generality, identify domain values consecutive
natural numbers.
3. originally introduced Zanarini Pesant (2010).

177

fiPesant, Quimper, & Zanarini

3.1 Upper Bounds
following assume notational convenience matrix n rows
P columns
denote ri sum elements ith row (i.e. ri = nd=1 aid ).
first upper bound permanent conjectured Minc (1963) later proved
Bregman (1973):
n

perm(A)
(ri !)1/ri .
(2)
i=1

Recently Liang Bai (2004) proposed second upper bound (with qi = min{d ri2+1 e, 2i e}):
perm(A)2

n


qi (ri qi + 1).

(3)

i=1

Neither two upper bounds strictly dominates other. following
denote U B BM (A) Bregman-Minc upper bound U B LB (A) Liang-Bai
upper bound. Jurkat Ryser (1966) proposed another bound:
perm(A)

n


min(ri , i).

i=1

However considered generally weaker U B BM (A) (see Soules, 2005 comprehensive literature review).
3.1.1 Algorithm
decided adapt U B BM U B LB order compute approximation solution
densities alldifferent constraint. Assigning variable xi translates replacing
ith row unit vector e(d) (i.e. setting ith row matrix 0 except
element column d). write Axi =d denote matrix except xi fixed d.
call local probe assignment xi = performed compute Axi =d i.e. temporary
assignment propagate constraint except one processed.
upper bound number solutions alldifferent(x1 , . . . , xn ) constraint
related adjacency matrix simply
#alldifferent(x1 , . . . , xn ) min{U B BM (A), U B LB (A)}
Note Formulas 2 3, ri equal |Di |; since |Di | ranges 0 n,
factors precomputed stored: vector BM f actors[r] = (r!)1/r , r = 0, . . . , n
first bound similarly second one (with factors depending |Di |
i). Assuming |Di | returned O(1), computing formulas takes O(n) time.
Solution densities approximated
min{U B BM (Axi =d ), U B LB (Axi =d )}

P
normalizing constant dDi (xi , d, alldifferent) = 1.
(xi , d, alldifferent)

178

fiCounting-Based Search

local probe xi = may trigger local propagation according level
consistency want achieve; therefore Axi =d subject filtering performed
constraint processed. Since two bounds Formulas 2 3 depend |Di |,
stronger form consistency would likely lead changes domains
bounds, presumably accurate solution densities.
want compute (xi , d, alldifferent) = 1, . . . , n Di
trivial implementation would compute Axi =d variable-value pair; total time
complexity would O(mP + mn) (where sum cardinalities variable
domains P time complexity filtering).
Although unable improve worst case complexity, following propose algorithm performs definitely better practice. introduce
additional notation: write Dk0 variable domains enforcing -consistency4
constraint alone Ixi =d set indices variables subject
domain change due local probe ensuing filtering, is, k Ixi =d iff
|Dk0 | 6= |Dk |. describe algorithm Bregman-Minc bound easily
adapted Liang-Bai bound.
basic idea compute bound matrix reuse speed
computation bounds Axi =d = 1, . . . , n Di . Let

BM f actors[|D0 |]

BM f actors[|Dkk |] k Ixi =d
k =


1
otherwise

U B BM (Axi =d ) =

n


BM f actors[|Dk0 |] =

k BM f actors[|Dk |]

k=1

k=1

= U B BM (A)

n


n


k

k=1

Note k k = (i.e. computing U B BM (Axi =d )) depend d;
however Ixi =d depend domain filtering.
Algorithm 1 shows pseudo code computing U B BM (Axi =d ) = 1, . . . , n
Di . Initially, computes bound matrix (line 1); then, given i,
computes upper bound modified accordingly (line 3). Afterwards,
Di , -consistency enforced (line 7) iterates set modified variables
(line 9-10) compute k different 1. store upper bound
variable value structure V arV alU B[i][d]. computing bound
variables-values assignment xi = needs undone (line 12). Finally,
normalize upper bounds order correctly return solution densities (line 13-14). Let
equal maxi,d |Ixi =d |, time complexity O(mP + mI).
matrix dense expect ' n. Therefore k different 1
need computed. soon matrix becomes sparse enough n
small fraction k need computed, Algorithm 1 advantage.
4. Stands form consistency

179

fiPesant, Quimper, & Zanarini

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15

UB = U B BM (A);
= 1, . . . , n
varUB = UB * BMfactors[1] / BMfactors[|Di |];
total = 0;
forall Di
set xi = d;
enforce -consistency;
VarValUB[i][d] = varUB;
forall k Ixi =d \ {i}
VarValUB[i][d] = VarValUB[i][d] * BMfactors[|Dk0 |] / BMfactors[|Dk |];
total = total + VarValUB[i][d];
rollback xi = d;
forall Di
SD[i][d] = VarValUB[i][d]/total;
return SD;
Algorithm 1: Solution Densities

sampling algorithm introduced Zanarini Pesant (2009) performed well
approximating solution count solution densities, case
upper bounds. latter fact produce weak approximations solution count
offer good trade-off performance accuracy solution densities:
taking ratio two solution counts appears cancel weakness original
approximations (see Zanarini & Pesant, 2010 details).
3.2 Symmetric Alldifferent
Regin (1999) proposed symmetric alldifferent constraint special case
alldifferent variables values defined set.
equivalent traditional alldifferent additional set constraints stating
variable assigned value j iff variable j assigned value i. constraint useful
many real world problems set entities need paired up; particularly,
sport scheduling problems teams need form set pairs define games.
symmetric alldifferent achieving domain consistency provides pruning power
equivalent decomposition given alldifferent constraint set
xi = j xj = constraints (Regin, 1999). filtering algorithm inspired
one alldifferent difference matching computed graph
(not necessarily bipartite) called contracted value graph vertices values representing entity collapsed single vertex (i.e. vertex xi vertex
merged single vertex representing variable value). Regin
proved bijection matching contracted value graph
solution symmetric alldifferent constraint. Therefore, counting number
matchings contracted value graph corresponds counting number solutions
constraint.

180

fiCounting-Based Search

Friedland (2008) Alon Friedland (2008) extended Bregman-Minc upper
bound consider number matchings general undirected graphs. Therefore,
exploit bound previous section order provide upper bound
solution count solution densities symmetric alldifferent constraint.
upper bound number matchings graph G = (V, E) representing contracted
value graph following:

1
#matchings(G)
(deg(v))! 2deg(v)
(4)
vV

deg(v) degree vertex v #matchings(G) denotes number
matchings graph G. Note case bipartite graph, bound equivalent
Bregman-Minc upper bound.
algorithm counting number solutions computing solution densities
easily derived proposed alldifferent.
Example 1. Consider symmetric alldifferent defined six variables x1 , . . . , x6
one domain equal {1, . . . , 6}. Figure 1 associated contracted value graph
depicted (together possible solution constraint). case, number
solutions symmetric alldifferent computed 5 3 = 15. contracted
value graph vertex connected vertex, forming clique size 6, therefore
vertices degree equal 5. upper bound proposed Friedland equal to:

1
#matchings(G)
(deg(v))! 2deg(v) = (5!1/10 )6 17.68
vV

alldifferent formulation, related value graph variable vertices connected
values (from 1 6) thus ri equal 6. consider rule
edges causing degenerated assignments (xi = i) end value graph
ri equal 5. Bregman-Minc upper bound would give:
perm(A)

n


(ri !)1/ri = (5!(1/5) )6 312.62.

i=1

result obviously far upper bound given Formula 4 well
exact value.

4. Counting Global Cardinality Constraints
present section extend results obtained Section 3 Global
Cardinality Constraint (gcc), generalization alldifferent constraint.
Definition 5 (Global Cardinality Constraint). set solutions constraint gcc(X, l, u)
X set k variables, l u respectively lower upper bounds
value, defined as:
[
(gcc(X, l, u)) = {(d1 , . . . , dk ) | di Di , ld |{di |di = d}| ud DX =
Dj }
xj X

181

fiPesant, Quimper, & Zanarini

1
3

2

5

4
6

Figure 1: Contracted Value Graph constraint symmetric alldifferent Example
1. Edges bold represent possible solution.

consider gcc fixed variables removed lower
upper bounds adjusted accordingly (the semantics constraint unchanged).
refer new set variables X 0 = {x X | x bound}; lower bounds l0
ld0 = ld |{x X | x = d}| upper bounds u0 defined similarly; assume
constraint maintains -consistency ld0 0 u0d 0 DX .
Inspired Quimper, Lopez-Ortiz, van Beek, Golynski (2004) Zanarini, Milano,
Pesant (2006), define Gl lower bound graph.
Definition 6. Let Gl (X 0 Dl , El ) undirected bipartite graph X 0 set
unbounded variables Dl extended value set, DX graph ld0
vertices d1 , d2 , . . . representing (ld0 possibly equal zero). edge (xi , dj ) El
Di .
Note maximum matching Gl corresponds partial assignment variables X satisfies gcc lower bound restriction number occurrences
value. partial assignment may may completed full assignment
satisfies upper bound lower bound restrictions (here take
consideration augmenting paths Zanarini et al., 2006 instead fix variables
values represented matching Gl ).
Example 2. Suppose gcc defined X = {x1 , . . . , x6 } domains D1 = D4 =
{1, 2, 3}, D2 = {2}, D3 = D5 = {1, 2} D6 = {1, 3}; lower upper bounds
values respectively l1 = 1, l2 = 3, l3 = 0 u1 = 2, u2 = 3, u3 = 2. Considering
x2 = 2, lower upper bounds value 2 respectively l20 = 2 u02 = 2.
lower bound graph shown Figure 2a: variable x2 bounded thus appear
graph, value vertex 2 represented two vertices l20 = 2 (although
l2 = 3); finally value vertex 3 appear lower bound equal zero.
matching shown figure (bold edges) maximum. However fix assignments
represented (x1 = 2, x4 = 2, x6 = 1) possible consistent solution
since x3 x5 assigned either 1 2 hence exceeding upper bound
restriction. compute permanent two additional fake value vertices would added
graph connected variable vertices (not shown figure).
182

fiCounting-Based Search

x1

1

x1

x3

2

x3

x4

20

x4

1

x5

x5

3

x6

x6

30

(a)

(b)

Figure 2: Lower Bound Graph (a) Residual Upper Bound Graph (b) Example 2
Every partial assignment satisfies lower bound restriction might correspond
several maximum matchings Gl due duplicated vertices.
Q partial
assignment satisfying lower bound restriction exactly dDX ld0 ! maximum
matchings corresponding particular partial assignment. take consideration
Example 2 shown Figure 2a, variables x1 x4 may matched respectively
permutation vertices 2 20 , however matter permutation, set
matchings represents always assignment x2 x4 value 2.
Let Ml 5 set maximum matchings Gl . define f : Ml N, function
counts number possible ways maximum matching extended full gcc
solution. shown Example 2, f possibly equal zero. Note number
remaining variables
need assigned starting matching Ml equal
P
0
0
K = |X | dDX ld .
total number solutions satisfying gcc is:
P
|Ml | maxmMl (f (m))
U B(Gl ) maxmMl (f (m))
mM f (m)
Q
Q
#gcc(X, l, u) = Q l 0


(5)
0
0
dDX ld !
dDX ld !
dDX ld !
U B(Gl ) represents upper bound permanent 0 1 matrix corresponding graph Gl .
Note computing f (m) hard computing permanent. fact l u
respectively equal 0 1 value, result alldifferent constraint
equation 5 simplifies #gcc(X, l, u) = f (m) = {} f (m) corresponds
permanent.
computing f (m) #P-complete problem own, focus upper bounding f (m). order that, introduce upper bound residual graph. Intuitively,
similar lower bound graph considers upper bound restriction.
Definition 7. Let Gu (X 0 Du , Eu ) undirected bipartite graph X 0 set
unbounded variables Du extended value set, DX graph
5. DX , ld0 = 0 Ml = {} |Ml | = 1

183

fiPesant, Quimper, & Zanarini

u0d ld0 vertices d1 , d2 , . . . representing (if u0d ld0 equal zero vertex
representing d). edge (xi , dj ) Eu Di u0d ld0 > 0.
Similarly lower bound matching, matching Gu covers K variables may
may completed full assignment satisfying complete gcc. Figure 2b shows
residual upper bound graph Example 1: value 2 disappears graph since
u02 = l20 i.e. starting matching lower bound graph, constraints
value 2 already satisfied.

graphs comIn order compute maxmMl (f (m)), build |X|
K
bination K variables, choose one maximizes permanent.
practically, given nature U B B U B LB , suffices choose K variables
contribute highest factor computation upper bounds;
easily done O(n log K) iterating n variables maintaining heap
K entries highest factor. write Gu Gu graphs
K variables maximize respectively U B B U B LB present; note Gu might
different Gu .
recall although K variables chosen, graphs Gu Gu
completed fake vertices way equal number vertices two
vertex partitions. AsQin lower bound graph, given upper bound scaled
factor dDX (u0d ld0 )!. Equation 5, number gcc solutions
bounded by:

#gcc(X, l, u)

U B(Gl ) min(U B B (Gu ), U B LB (Gu ))
Q
0
0
0
dDX (ld !(ud ld )!)

(6)

Scaling also fake vertices used permanent bounds factors degrade
quality upper bound. Nonetheless, solution densities computed ratio
two upper bounds therefore scaling factors often attenuated.
Example 3. refer gcc described Example 2. exact number solutions
19. U B B U B LB lower bound graph Figure 2a 35 (the scaling
two fake value vertices already considered). upper bound 2 variables
need assigned one maximizing bounds x1 x4 (or possibly x6 ):
resulting permanent upper bound 6. upper bound total number gcc solutions
0
0
b 356
4 c = 52 division 4 due l2 ! = 2! u3 ! = 2!.
Figure 3 shows lower bound residual upper bound graph constraint
x1 = 1 domain consistency achieved. Vertex x1 removed l10 = 0
u01 = 1. graph Gl permanent upper bound 6. number unassigned
variables Gu 2 ones maximizing upper bounds x4 x6 , giving
upper bound 6. total number gcc solutions x1 = 1 bounded
b 66
4 c = 9; approximate solution density normalizing thus 9/52. Note
normalization, turns 0.18 whereas exact computation
5/19 0.26.

184

fiCounting-Based Search

x3

x3

x4

2

x4

x5

20

x5

x6

1

x6

3
30

(a)

(b)

Figure 3: Lower Bound Graph (a) Residual Upper Bound Graph (b) assuming x1 = 1

5. Counting Regular Knapsack Constraints
regular constraint useful express patterns must exhibited sequences
variables.
Definition 8 (Regular Language Membership Constraint). regular(X, ) constraint
holds values taken sequence finite domain variables X = hx1 , x2 , . . . , xk spell
word belonging regular language defined deterministic finite automaton
= (Q, , , q0 , F ) Q finite set states, alphabet, : Q Q
partial transition function, q0 Q initial state, F Q set final (or
accepting) states.
Linear equalities inequalities expressed knapsack constraints.
Definition 9 (Knapsack Constraint). knapsack(x, c, `, u) constraint holds
` cx u
c = (c1 , c2 , . . . , ck ) integer row vector, x column vector finite domain
variables (x1 , x2 , . . . , xk )T xi Di , ` u integers.
assume l u finite always set smallest largest
value cx take. Strictly speaking interpreted knapsack, integer values
involved (including finite domains) nonnegative algorithms
proposed section easily adapted lift restriction nonnegative coefficients domain values, expense larger graph case algorithm
Section 5.1. dealing general linear constraints.
filtering algorithms regular constraint knapsack constraint (when
domain consistency enforced) based computation paths layered
acyclic directed graph (Pesant, 2004; Trick, 2003). graph property paths
first layer last one-to-one correspondence solutions constraint. exact counting algorithm former constraint derived Zanarini
185

fiPesant, Quimper, & Zanarini

Pesant (2009) next section describe exact counting algorithm knapsack
constraints similar spirit, Section 5.2 present approximate counting algorithm attuned bounds consistency. 6
5.1 Domain Consistent Knapsacks
start reduced graph described Trick (2003), layered directed
graph G(V, A) special vertex v0,0 vertex vi,b V 1 k 0 b u
whenever

X
j [1, i], dj Dj
cj dj = b
j=1


j (i, n], dj Dj ` b

k
X

cj dj u b,

j=i+1

arc (vi,b , vi+1,b0 ) whenever
Di+1 ci+1 = b0 b.
define following two recursions represent number incoming outgoing
paths node.
every vertex vi,b V , let #ip(i, b) denote number paths vertex v0,0
vi,b :
#ip(0, 0) = 1
#ip(i + 1, b0 ) =

X

#ip(i, b),

0i<n

(vi,b ,vi+1,b0 )A

Let #op(i, b) denote number paths vertex vi,b vertex vk,b0 ` b0 u.
#op(n, b) = 1
#op(i, b) =

X

#op(i + 1, b0 ),

0i<k

(vi,b ,vi+1,b0 )A

total number paths (i.e. solution count) given
#knapsack(x, c, `, u) = #op(0, 0)
time linear size graph even though may exponentially many
them. solution density variable-value pair (xi , d) given
P
(vi1,b ,vi,b+ci )A #ip(i 1, b) #op(i, b + ci d)
.
(xi , d, knapsack) =
#op(0, 0)
6. originally introduced Pesant Quimper (2008).

186

fiCounting-Based Search

b

8

6;1

7
6

1;3

1;1

3;1

6;1

2;2

3;2

5;1

3;2

5;1

5
4
3

1;10

1;4

2;2

2;4

3;1

2
1
0

1;3

1;22

1;9

1;2

0

1

2

3

4



Figure 4: Reduced graph knapsack constraint 5 3x1 + x2 + 2x3 + x4 8 D1 =
{0, 1, 2}, D2 = {0, 1, 3}, D3 = {0, 1, 2}, D4 = {1, 2}. Vertex labels represent
number incoming outgoing paths.

value
0
1
2
3

x1
9/22
10/22
3/22


variable
x2
x3
8/22 9/22
8/22 7/22

6/22
6/22


x4

11/22
11/22


Table 1: Solution densities example Fig. 4.
Figure 4, left right labels inside vertex give number incoming
outgoing paths vertex, respectively. Table 1 reports solution densities every
variable-value pair.
time required compute recursions #ip() #op() related number
arcs, O(ku max1ik {|Di |}). solution density computes summation
subset arcs arc graph involved one summation,
overall time complexity computing every solution density O(ku max1ik {|Di |})
well.
5.2 Bounds Consistent Knapsacks
Knapsack constraints, indeed arithmetic constraints, traditionally handled
enforcing bounds consistency, much cheaper form inference. situations,
187

fiPesant, Quimper, & Zanarini

may afford enforce domain consistency order get solution counting
information need guide search heuristic. still retrieve information,
perhaps accurately, weaker bounds consistency?
Consider variable x domain = [a, b]. value equiprobable.
associate x discrete random variable X follows discrete uniform distribution
probability mass function f (v), mean = E[X], variance 2 = V ar[X].

f (v) =
=
2 =

1
ba+1

v b
0
otherwise
a+b
2
(b + 1)2 1
12

(7)
(8)
(9)

find distribution variable subject knapsack constraint, one needs
find distribution linear combination uniformly distributed random variables.
Lyapunovs central limit theorem allows us approximate distribution linear
combination.
Theorem 1 (Lyapunovs central limit theorem). Consider independent random variables X1 , . . . , Xn . Let mean Xi , i2 variance, ri3 = E[|Xi |3 ]
third central moment.
P
1
( n r3 ) 3
lim Pni=1 1 = 0,
2 2
n (
i=1 )
Pn

SP=
i=1 Xi follows normal distribution mean =
Pn random variable
n
2.
2 =



variance

i=1
i=1

probability mass function normal distribution mean variance 2
Gaussian function:
(x)2

(x) =

e 22

2

(10)

Note Lyapunovs central limit theorem assume variables taken
identical distributions. necessary since variables different domains
different distributions.
Lemma 1 defines upper bound third central moment expression kX
k positive coefficient X uniformly distributed random variable.
Lemma 1. Let discrete random variable equal kX k positive
coefficient X discrete random variable uniformly distributed interval [a, b].
third central moment r3 = E[|Y E[Y ]|3 ] greater k 3 (b a)3 .
Proof. case = b trivial. prove b > 0. proof involves simple
algebraic manipulations definition expectation.
188

fiCounting-Based Search

r

3

=

=

kb
X

|i E[Y ]|3 f (i)

(11)

|kj kE[X]|3 f (j)

(12)

i=ka
b
X
j=a

fi3
b fi
X
fi
fi

+
b
1
fij
fi
= k
since k > 0
fi
fi
2
ba+1
j=a


a+b




b
2
3
3
X
k3
a+b
X + b
=
j +
j


ba+1
2
2
a+b
3

j=a

=

k3
ba+1

j=

ba

ba
2
2
X
X

j3 +
j3
j=0

(13)

(14)

2

(15)

j=0

ba



2
2k 3 X
j 3 since b > 0
ba

j=0

189

(16)

fiPesant, Quimper, & Zanarini

Let =

ba
2 .

r

3








k3 X 3
j

j=0


k3 1
1
1
4
3
2
(m + 1) (m + 1) + (m + 1)
4
2
4
4

3
3
2
k



+
+

4
2
4
4

3
k

4
4
+m +m
since 12

4
9 3 3
k
4

confirms r3

9 3
32 k (b

(17)
(18)
(19)
(20)
(21)

a)3 k 3 (b a)3 .

Lemma 2 defines distribution linear combination uniformly distributed random variables.
P
Lemma 2. Let = ni=1 ci Xi random variable Xi discrete random variable
uniformly chosen interval [ai , bi ] ci non-negative coefficient.
P n itends
infinity, distribution tends normal distribution mean ni=1 ci ai +b

2
Pn 2 (bi ai +1)2 1
variance i=1 ci
.
12
Proof. Let Yi = ci Xi random variable. want characterize distribution
P
n
bi ai
i=1 Yi . Let mi =
2 . variance uniform distribution interval [ai , bi ]
2

(m + 1 )2

+1) 1
1
i2 = (bi ai12
= 3 2 12
. V ar[Yi ] = c2i V ar[Xi ] = c2i i2 . Let ri3
third central moment Yi . Lemma 1, ri3 c3i (bi ai )3 . Let L term
mentioned condition Lyapunovs central limit theorem:

Pn
L =

lim

3
i=1 ri

n

Pn

1

2 2
i=1 ci

3

1

(22)

2

Note numerator denominator fraction non-negative.
implies L non-negative. prove L 0 n tends infinity.
190

fiCounting-Based Search

Approximation Combination Uniformly Distributed Random Variables
0.045
0.04
0.035

density

0.03
0.025
0.02
0.015
0.01
0.005
0
0

5

10

15

20

25
x

30

35

40

45

50

Figure 5: histogram actual distribution expression 3x+4y +2z x, y, z
[0, 5]. curve approximation given Gaussian curve mean
= 22.5 variance 2 = 84.583.

Pn
L

3 3
i=1 8ci mi

lim
n P
n

2
i=1 ci



lim

n

8
1
3



(mi + 12 )2
3

Pn

1
3

Pn

1
2

3
i=1 ci mi

2
i=1 ci mi

1
3



1
12

12

(23)

3

(24)

2

v
u Pn 3 3 2
u
i=1 ci mi
6
lim 2 3
Pn 2 2 3
n
i=1 ci mi

Pn Pn
3
6
j=1 (ci cj mi mj )
i=1
lim 2 3 Pn Pn Pn
2
n
i=1
j=1
k=1 (ci cj ck mi mj mk )

(25)

(26)

Note last inequality, terms (ci cj mi mj )3 (ci cj ck mi mj mk )2
order. However, n times terms denominator numerator.
Therefore, n tends infinity, fraction tends zero proves L = 0
n tends zero.
Pn
Lyapunovs central limit theorem, n tends

infinity,

expression

=
i=1 Yi
Pn
Pn
ai +bi
tends normal distribution mean E[Y ] = i=1 ci E[Xi ] = i=1 ci 2 variance
P
P
+1)2 1
V ar[Y ] = ni=1 c2i V ar[Xi ] = ni=1 c2i (bi ai12
.
P
Consider knapsack constraint ` ni=1 ci xi u. Let xn+1 variable domain
P
Pn
Dn+1 = [`, u]. obtain xj = c1j (xn+1 j1
i=j+1 ci xi ). coefficients
i=1 ci xi
expression might negative. made positive setting c0i = ci
Di0 = [ max(Di ), min(Di )]. n grows infinity, distribution xj tends
normal distribution stated Lemma 2. practice, normal distribution
191

fiPesant, Quimper, & Zanarini

good estimation even small values n. Figure 5.2 shows actual distribution
expression 3x + 4y + 2z x, y, z [0, 5] approximation normal distribution.
Given variable xi subject knapsack constraint, Algorithm 2 returns assignment
xi = ki highest solution density. loop computes average mean j
variance j2 uniform distribution associated variable
Pn xj . Lines 4 5
compute mean variance distribution xn+1 j=1 cj xj Lines 6
P
Pn
7 compute mean variance xi = c1i (xn+1 i1
j=1 cj xj
j=i+1 cj xj ).
Since normal distribution symmetric unimodal, likely value ki
domain Di one closest mean . algorithm finds returns value
well density di . density di computed using normal distribution. Since
variable xi must assigned value domain, algorithm normalizes Line 9
distribution values interval [min(Di ), max(Di )].
1
2
3
4
5
6
7
8
9

j [1, n]
min(Dj )+max(Dj )
j
;
2

(max(D )min(D )+1)2 1

j
j
;
j2
12
Pn
l+u
2 j=1 cj j ;
2 1
P
V (ul+1)
+ nj=1 c2j j2 ;
12

+c
;
ci

v

V c2i i2
;
c2i

ki arg minkDi |k m|;
(ki m)2
(km)2
Pmax(Di )
2v
di e 2v / k=min(D
e
;
i)

return hxi = ki , di
Algorithm 2: P
xi = ki highest density well density di knapsack
constraint ` ni=1 ci xi u.

10

Lines 1 5 take O(n) time execute. Line 8 depends data structure
used solver encode domain. assume line takes O(log |Di |) time
execute. summation Line 9 computed constant time approximating
summation m,v (max(Di ) + 12 ) m,v (min(Di ) + 12 ) m,v normal
cumulative distribution function average variance v. constant 12 added
continuity correction. lines constant running time. total complexity
Algorithm 2 therefore O(n + log |Di |). Note Line 1 Line 5 depend
value i. computation therefore cached subsequent calls
function knapsack constraint. Using technique, finding theP
variable xi
{x1 , . . . , xn } assignment xi = ki maximum density takes O( ni=1 log |Di |)
time.
source alteration distribution values interval absent
actual domain. Bounds consistency approximates domain variable
smallest covering interval. order reduce error introduced approximation,
one compute actual mean actual variance domain Di Lines 2 3
192

fiCounting-Based Search

instead
P using mean variance covering interval, revised overall cost
O( ni=1 |Di |).

6. Generic Constraint-Centered Counting-based Heuristics
previous sections provided algorithms retrieve solution counting information
many frequently used constraints. information must exploited
guide search. solving process alternates propagating constraints filter
domains branching fixing variable value domain. crucial choice
variable value made search heuristic. considered many search heuristics
based counting information, describe briefly next paragraph.
experiment extensively one successful ones Section 7, present
detail. following, denote C(xi ) set constraints whose scope
contains variable xi . heuristics proposed assume lexicographical ordering
tie breaking. Counting information gathered search tree node propagation
fixed point reached: recomputed constraints change occurred
domain variable within scope, otherwise cached information reused.
cached counting information stored trailing data structures (also known reversible
data structures) retrieved upon backtracking. heuristics considered
fall four broad categories:
Combined choice variable value select directly variable-value pair
without explicit differentiation variable value ordering, based aggregation,
simple functions, counting information coming different constraints.
heuristics iterate variable-value pair, aggregating solution densities
relevant constraints selecting pair exhibiting maximum aggregated score.
type aggregation used e.g. maximum, minimum, sum, average. instance:
maxSD: maxcC(xi ) ((xi , d, c)) selects maximum solution densities.
maxRelSD: maxcC(xi ) ((xi , d, c) (1/|Di |)) selects maximum solution
densities subtracting average solution density given variable (i.e. 1/|Di |).
smoothes inherent solution densities differences due domain cardinalities
(as also following aggregation function).
,d,c)
maxRelRatio: maxcC(xi ) ( (x
(1/|Di |) ) selects maximum ratio
solution density average solution density given variable.

P

aAvgSD:

(xi ,d,c)
|C(xi )|

cC(xi )

P

wSCAvg:

(#c(xi ,d,c))
cC(x ) #c

cC(xi )

P

computes arithmetic average solution densities.
computes average solution densities weighted



constraints solution count. weights tend favor branchings variablevalue pairs keep high percentage solutions constraints high solution
count.
193

fiPesant, Quimper, & Zanarini

Choice constraint first focus first specific constraint (e.g. based
solution count) select variable-value pair (as before) among variables
preselected constraints scope. instance, minSCMaxSD first selects constraint
lowest number solutions restricts choice variable involved
constraint, choosing variable-value pair highest solution density.
rationale behind heuristic constraint fewest solutions probably
among hardest satisfy.
Restriction variables preselect subset variables minimum domain size choose among one best variable-value pair according
counting information.
Choice value using generic heuristic variable selection
solution densities value selection.
Heuristic maxSD heuristic maxSD (Algorithm 3) simply iterates variablevalue pairs chooses one highest density; assuming (xi , d, c)
precomputed, complexity algorithm O(qm) q number
constraints sum cardinalities variables domains. Interestingly,
heuristic likely selects variable small domain, keeping fail-first
principle, since values average higher density compared variable
many values (consider average density value (xi , d, c) = |D1i | ). Note
constraint considered individually.
1
2
3
4
5
6
7
8

max = 0;
constraint c(x1 , . . . , xk )
unbound variable xi {x1 , . . . , xk }
value Di
(xi , d, c) > max
(x? , d? ) = (xi , d);
max = (xi , d, c);
return branching decision x? = d? ;
Algorithm 3: Maximum Solution Density search heuristic (maxSD)

7. Experimental Analysis
performed thorough experimental analysis order evaluate performance
proposed heuristics eight different problems.7 problems expose sub-structures
encapsulated global constraints counting algorithms known.
Counting-based heuristics use random problems class problems
expose structure; nonetheless real-life problems usually present structure therefore
performance heuristics proposed may positive impact quest
provide generic efficient heuristics structured problems. problems
experimented different structures different constraints possibly different
7. instances used available www.crt.umontreal.ca/quosseca/fichiers/20-JAIRbenchs.tar.gz.

194

fiCounting-Based Search

arities interconnected different ways; thus, considered good representatives
variety problems may arise real life.
7.1 Quasigroup Completion Problem Holes (QWH)
Also referred Latin Square problem, QWH defined n n grid whose
squares contain integer 1 n integer appears exactly per
row column (problem 3 CSPLib maintained Gent, Walsh, Hnich, & Miguel,
2009). common model uses matrix integer variables alldifferent
constraint row column. constraint defined n variables
type; variable involved two constraints domain
(disregarding clues). homogeneous problem. tested 40 hard
instances used Zanarini Pesant (2009) n = 30 42% holes (corresponding
phase transition), generated following Gomes Shmoys (2002).
7.2 Magic Square Completion Problem
magic square completion problem (problem 19 CSPLib) defined n n grid
asks fill square numbers 1 n2 row, column
main diagonal sums value. order make harder, problem
instances partially prefilled (half instances 10% variables
set half, 50% variables set). 40 instances (9 9) taken
work Pesant Quimper (2008). problem modeled matrix
integer variables, single alldifferent constraint spanning variables
knapsack constraint row, column main diagonal. problem involves
different constraints although majority equality knapsack arity.
7.3 Nonograms
Nonogram (problem 12 CSPLib) built rectangular nm grid requires filling
squares unique feasible way according clues given row
column. reward, one gets pretty monochromatic picture. individual clue
indicates many sequences consecutive filled-in squares row (column),
respective size order appearance. example, 2 1 5 indicates
two consecutive filled-in squares, isolated one, finally five consecutive ones.
sequence separated others least one blank square know little
actual position row (column). clues modeled regular
constraints. homogeneous problem, constraints identical type defined
n variables, (binary) variable involved two constraints.
puzzles typically require amount search, despite fact domain consistency
maintained clue. experimented 180 instances8 sizes ranging
16 16 32 32.

8. Instances taken http://www.blindchicken.com/ali/games/puzzles.html

195

fiPesant, Quimper, & Zanarini

7.4 Multi Dimensional Knapsack Problem
Multi dimensional knapsack problem originally proposed optimization problem community. followed approach Refalo (2004) transforming
optimization problem feasibility problem fixing objective function optimal value, thereby introducing 0-1 equality knapsack constraint. constraints
upper bounded knapsack constraints variables. tested three different set instances total 25 instances: first set corresponds six instances
used Refalo, second set third set come OR-Library (Weish[1-13]
Shi, 1979; PB[1,2,4] HP[1,2] Freville & Plateau, 1990). first instance set
n, number variables, ranging 6 50 m, number
constraints, 5 10; second third instance set n varies 27 60
2 5. problem involves one kind constraint and, differently
previous problem classes, constraints posted set variables.
7.5 Market Split Problem
market split problem originally introduced Cornuejols Dawande (1999)
challenge LP-based branch-and-bound approaches. exists feasibility
optimization version. feasibility problem consists 0-1 equality knapsack
constraints defined set 10(m1) variables. Even small instances (4 6)
surprisingly hard solve standard means. used 10 instances tested Pesant
Quimper (2008) generated Wassermann (2007). Market Split Problem
shares characteristics Multi Dimensional Knapsack problem: constraints
type posted set variables.
7.6 Rostering Problem
rostering problem inspired rostering context. objective schedule
n employees span n time periods. time period, n 1 tasks need
accomplished one employee n break. tasks fully ordered 1
n 1; employee schedule respect following rules: two consecutive
time periods assigned either two consecutive tasks (in matter order
i.e. (t, + 1) (t + 1, t)) task (i.e. (t, t)); employee break
matter task; break employee cannot perform task precedes
task prior break (i.e. (t, break, t1) allowed). problem modeled one
regular constraint per row one alldifferent constraint per column. generated 2
sets 30 instances n = 10 5% preset assignments respectively 0%
2.5% values removed.
7.7 Cost-Constrained Rostering Problem
cost-constrained rostering problem borrowed Pesant Quimper (2008)
10 instances well. inspired rostering problem employees
(m = 4) accomplish set tasks n-day schedule (n = 25). employee
perform task another employee day (alldifferent constraint
day). Moreover, hourly cost making someone work, varies
196

fiCounting-Based Search

across employees days. employee, total cost must equal randomly
generated value (equality knapsack constraint employee). Finally, instance
10 forbidden shifts i.e. days employee cannot perform
given task. following, refer problem also KPRostering. problem
presents constraints different types largely different arities.
7.8 Traveling Tournament Problem Predefined Venues (TTPPV)
TTPPV introduced Melo, Urrutia, Ribeiro (2009) consists finding
optimal single round robin schedule sport event. Given set n teams,
team play every team. game, team supposed play
either home away, however team play three consecutive times
home away. particularity problem resides venue game
predefined, i.e. team plays b already known whether game going
held home bs home. TTPPV instance said balanced
number home games number away games differ one team;
otherwise referred non-balanced random. problem modeled one
alldifferent one regular constraint per row one alldifferent constraint per
column. TTPPV originally introduced optimization problem sum
traveling distance team minimized, however Melo et al. (2009)
show particularly difficult find single feasible solution employing traditional
integer linear programming methods. Balanced instances size 18 20 (the number
teams denotes instance size) taking roughly 20 60 seconds find first
feasible solution Integer Linear Programming; non-balanced instances could take
5 minutes (or even time 2 hours computation). Furthermore six non-balanced
instances infeasible ILP approach proposed Melo et al. unable prove
it. Hence, feasibility version problem already represents challenge.
every problem (unless specified otherwise): domain consistency maintained
search9 , counting algorithm alldifferent constraint UB-FC (upper bounds
forward checking consistency level enforced), search tree binary (i.e.
xi = j xi 6= j), traversed depth-first. tests performed AMD Opteron
2.2GHz 1GB Ilog Solver 6.6; heuristics involve sort randomization
(either heuristic counting algorithms employed) run 10 times
average results taken account. set timeout 20 minutes
problems heuristics. present results plotting percentage solved
instances time backtracks.
7.9 Comparing Counting-Based Search Heuristics
first compare several proposed search heuristics based counting respect
well guide search, measured number backtracks required find
solution. important issue overall runtime addressed following sections.
9. Even knapsack constraints, comparative experimental results benchmark instances,
originally reported Pesant Quimper (2008), indicated maxSD performed better domain
consistency associated counting algorithm.

197

fiPesant, Quimper, & Zanarini

Figure 6: Percentage solved instances respect number backtracks
eight benchmark problems. search heuristics compared based
solution counting.

198

fiCounting-Based Search

Figure 6 plots number solved instances backtracks eight benchmark problems. Nonogram, Multi-Knapsack, Market Split problems, maxSD,
maxRelSD, maxRelRatio correspond heuristics domains binary.
Restricting use solution densities choice value variable selected popular domain size dynamic degree heuristic (domDeg;maxSD) generally
achieves poor performance compared others. One disappointment came
surprise selecting first constraint fewest solutions left (minSCMaxSD)
often behaves poorly well. Multi-Knapsack Problem aAvgSD, takes
arithmetic average solution densities, performs one order magnitude better
others. believe might explained fact constraints
share variables (in Latin Square Nonogram problems constraints overlap
one variable): therefore branching considering constraint information
pays off. maxSD maxRelSD search heuristics stand robust
benchmarks. quite similar performs significantly better
one problem domain. slightly simpler, restrict
former remaining experiments.
7.10 Comparing Generic Search Heuristics
experimental results previous section suggest relatively simple maxSD
heuristic guides search least well others. compare
following ones (see Section 2 reference) good representatives state
art generic search heuristics:
dom - selects among variables smallest remaining domain uniformly
random chooses value uniformly random;
domWDeg - selects variable according dom/wdeg heuristic
first value lexicographic order;
IBS - Impact-based Search full initialization impacts; chooses subset
5 variables best approximated impact breaks ties based
node impacts ties broken randomly; (ILOG, 2005)
Figure 7 8 plot number solved instances backtracks time
eight benchmark problems. moment ignore curves heuristics
restarts.
maxSD heuristic significantly outperforms heuristics Latin Square,
Magic Square, Multi Dimensional Knapsack, Cost-Constrained Rostering (KPRostering
figure), TTPPV problems (5 8 problems), terms number
backtracks computation time. Nonogram Problem slightly worse
domWDeg eventually outperformed IBS. sharp improvement latter
around 1000 backtracks suggests singleton consistency powerful problem
time consuming since domains binary. Indeed IBSs full initialization
impacts root node achieves singleton consistency preprocessing step.
behavior even pronounced Rostering Problem (see IBS curves).
problem maxSDs performance easily compared domWDeg, dominates it.
199

fiPesant, Quimper, & Zanarini

Figure 7: Percentage solved instances respect number backtracks
time (in seconds) first four benchmark problems. search heuristics
compared maxSD, dom, IBS, domWDeg, without restarts.

200

fiCounting-Based Search

Figure 8: Percentage solved instances respect number backtracks
time (in seconds) last four benchmark problems. search heuristics
compared maxSD, dom, IBS, domWDeg, without restarts.

201

fiPesant, Quimper, & Zanarini

Market Split Problem differences performance striking: maxSD
slightly better terms backtracks enough outperform domWDeg
terms runtime.
Magic Square plot time, notable bend 50% mark
curves explained fact half instances
10% cells prefilled present bigger challenge. Interestingly, simpler
dom heuristics performs better IBS domWDeg, latter unable solve
half instances allotted time. contrast Nonogram Problem,
full impact initialization heavy procedure due high number variable-value
pairs probe ( n4 instances 94 = 6561). also worth noting
Cost-Constrained Rostering Problem, maxSD solves seven ten instances
backtrack-free heuristic solving every instance. Similarly TTPPV
Problem, almost 90% instances solved backtrack-free heuristic. Moreover
six instances happen infeasible maxSD exhibits short proof trees five them,
every heuristic timing them.
7.11 Adding Randomized Restarts
remarked combinatorial search strictly positive probability
reach subtree requires exponentially time subtrees encountered
far (so called heavy-tail behavior). Nonetheless, heavy tails largely avoided
adding randomized restarts top search procedure (Gomes, Selman, & Kautz,
1998). technique orthogonal search heuristic employed systematically
restarts search every time limit (typically bound number backtracks)
reached; obviously, order effective, randomized restarts must employed along
heuristic presents sort randomization learning
restart different parts search tree explored. tested heuristics
assess performance randomized restarts. maxSD IBS heuristics
randomized: particularly, one variable-value pair chosen random equal
probability best two provided heuristic. Note that, pointed
Refalo (2004), impact information carried different runs improve quality
impact approximation. domWDeg, learned weights kept restarts.
implemented slow geometric restart policy (Walsh, 1999) (that 1, r, r2 , . . . r = 2)
scale parameter optimized experimentally separately problem type
search heuristic.
turn Figure 7 8 time also consider curves
heuristics restarts. Restarts generally help less informed heuristic dom,
sometimes spectacularly Rostering Problem, always indicated
results Market Split Problem. heuristics usefulness mixed:
makes little difference maxSD except Market Split degrades performance
Rostering improves performance significantly, solving every instance
easily; IBS helps difficult instances half problems
three others degrades performance; domWDeg generally positive never
spectacular. Note heavy-tail behavior runtime distribution conjectured depend
problem structure search heuristic employed (Hulubei & OSullivan,
202

fiCounting-Based Search

2006). Market Split Problem stands one randomized restarts hurt every
search heuristic considered.
7.12 Using Limited Discrepancy Search
Another way avoid heavy tails change order search tree traversed,
undoing decisions made top search tree earlier traversal. popular
way applying limited discrepancy search (LDS) visits branches
increasing order number discrepancies, correspond branching decisions
going search heuristic (Harvey & Ginsberg, 1995). restarts,
combined search heuristic may cause dramatic improvements cases
less natural traversal comes price. Figure 9 illustrates impact LDS
two benchmark problems, using maxSD search heuristic. Either usual
depth-first search traversal used (maxSD curve) limited discrepancy search, grouping
branches exactly number discrepancies (LDS 1), skips 2 (LDS
2), skips 4 (LDS 4) discrepancies. rostering problem LDS undoes bad
early decisions made heuristic allows us solve every instance quickly.
However Magic Square problem impact LDS number backtracks
low actually significantly slows resolution LDS must revisit internal
nodes, thus repeating propagation steps: smaller skip, larger computational
penalty.
behavior could observed search heuristics problems. LDS necessarily add robustness search.
7.13 Analyzing Variable Value Selection Separately
One may wonder whether success counting-based search heuristics mostly depends
informed value selection, accompanying variable selection accessory. order
investigate this, introduce hybrid heuristics:
maxSD; random - selects variable maxSD selects value domain
uniformly random;
IBS; maxSD - selects variable IBS selects value domain
according solution densities;
domWDeg; maxSD - selects variable domWDeg selects value
domain according solution densities;
Figure 10 11 plot number solved instances backtracks time
eight benchmark problems. Comparing maxSD maxSD; random indicates
time value selection according solution densities crucial, Rostering Problem
exception. Interestingly value selection solution density improves overall
performance IBS; domWDeg improves Latin Square Magic Square
problems rest, often decreasing performance. However improvements
really tip balance favor heuristics maxSD, thus indicating
variable selection according solution densities also important success.
203

fiPesant, Quimper, & Zanarini

Figure 9: Percentage solved instances respect number backtracks
time (in seconds) two benchmark problems. maxSD search heuristic
used every curve search tree traversal order different.

204

fiCounting-Based Search

Figure 10: Percentage solved instances respect number backtracks
time (in seconds) first four benchmark problems. search heuristics
compared use solution densities either variable value selection.

205

fiPesant, Quimper, & Zanarini

Figure 11: Percentage solved instances respect number backtracks
time (in seconds) last four benchmark problems. search heuristics
compared use solution densities either variable value selection.

206

fiCounting-Based Search

8. Conclusion
paper described evaluated counting-based search solve constraint satisfaction
problems. presented algorithms necessary extract counting information
several main families constraints cp. proposed variety heuristics based
counting information evaluated them. compared one outstanding
representative, maxSD, state art eight different problems literature
obtained encouraging results. next logical steps research include
designing counting algorithms common constraints strengthening
empirical evaluation considering new problems comparing applicationspecific heuristics. next two paragraphs describe less obvious steps.
Users often need introduce auxiliary variables different views models
linked together channeling constraints. important provide counting
information available level branching variables least level
direct comparison solution densities meaningful. example case TTPPV
earlier model, two sets variables received solution densities different
constraints, perform nearly well. Channeling constraints express one-tomany relation (such one present TTPPV) dealt considering value
multiplicity counting algorithms (Pesant & Zanarini, 2011). complex channeling
constraints represent however limitation current framework.
Combinatorial optimization problems discussed paper
important operations research. Heuristics strong emphasis feasibility (such
counting-based heuristics) might well suited problems strong optimization
component, yet may useful dealing optimization problems involve
hard combinatorics. Ideally, counting algorithms blind cost reasoning.
One possibility started investigating counts number solutions
involve particular variable-value pair also returns average cost solutions
featuring particular variable-value pair. Another shown promise cost
linear decomposable decision variables (Pesant & Zanarini, 2011).
conclude, believe counting-based search brings us closer robust automated
search cp also offers efficient building blocks application-specific heuristics.

Acknowledgments
Financial support research provided part Natural Sciences Engineering Research Council Canada Fonds quebecois de la recherche sur la nature
et les technologies. wish thank Tyrel Russell participated implementation
experimentation work. also thank anonymous referees constructive
comments allowed us improve paper.

References
Alon, N., & Friedland, S. (2008). Maximum Number Perfect Matchings Graphs
Given Degree Sequence. Electronic Journal Combinatorics, 15 (1), N13.
207

fiPesant, Quimper, & Zanarini

Balafoutis, T., & Stergiou, K. (2008a). Experimental evaluation modern variable selection
strategies Constraint Satisfaction Problems. Proceedings Fifteenth Knowledge Representation Automated Reasoning Workshop Experimental Evaluation
Algorithms Solving Problems Combinatorial Explosion, RCRA-08.
Balafoutis, T., & Stergiou, K. (2008b). Conflict-driven variable ordering heuristics.
Proceedings Thirteenth Annual ERCIM International Workshop Constraint
Solving Constraint Logic Programming, CSCLP-08.
Bessiere, C., & Regin, J.-C. (1996). MAC Combined Heuristics: Two Reasons Forsake FC (and CBJ?) Hard Problems. Proceedings Second International
Conference Principles Practice Constraint Programming, CP-96, Vol. 1118
LNCS, pp. 6175. Springer Berlin / Heidelberg.
Boussemart, F., Hemery, F., Lecoutre, C., & Sais, L. (2004). Boosting Systematic Search
Weighting Constraints. Proceedings Sixteenth Eureopean Conference
Artificial Intelligence, ECAI-04, pp. 146150. IOS Press.
Bras, R. L., Zanarini, A., & Pesant, G. (2009). Efficient Generic Search Heuristics within
EMBP framework. Proceedings Fifteenth International Conference
Principles Practice Constraint Programming, CP-04, Vol. 5732 LNCS, pp.
539553. Springer.
Bregman, L. M. (1973). Properties Nonnegative Matrices Permanents.
Soviet Mathematics Doklady, 14 (4), 945949.
Brelaz, D. (1979). New Methods Color Vertices Graph. Communications
ACM, 22 (4), 251256.
Cornuejols, G., & Dawande, M. (1999). Class Hard Small 0-1 Programs. INFORMS
Journal Computing, 11, 205210.
Freville, A., & Plateau, G. (1990). Branch Bound Method Multiconstraint
Zero One Knapsack Problem.. Investigation Operativa, 1, 251270.
Friedland, S. (2008). Upper Bound Number Perfect Matchings Graphs.
http://arxiv.org/abs/0803.0864.
Gent, I. P., Walsh, T., Hnich, B., & Miguel, I. (2009). Problem Library Constraints.
http://www.csplib.org. last consulted 2009-08.
Gomes, C., Selman, B., & Kautz, H. (1998). Boosting Combinatorial Search
Randomization. Proceedings fifteenth national/tenth conference Artificial
intelligence/Innovative applications artificial intelligence, AAAI-98/IAAI-98, pp.
431437. AAAI Press.
Gomes, C., & Shmoys, D. (2002). Completing Quasigroups Latin Squares: Structured
Graph Coloring Problem.. Proceedings Computational Symposium Graph
Coloring Generalizations, COLOR-02, pp. 2239.
Grimes, D., & Wallace, R. J. (2006). Learning Identify Global Bottlenecks Constraint
Satisfaction Search. Learning Search: Papers AAAI-06 Workshop, Vol.
Tech. Rep. WS-06-11, pp. 2431.
208

fiCounting-Based Search

Grimes, D., & Wallace, R. J. (2007). Sampling Strategies Variable Selection Weighted
Degree Heuristics. Proceedings Thirteenth International Conference Principles Practice Constraint Programming, CP-07, Vol. 4741 LNCS, pp. 831
838. Springer.
Haralick, R. M., & Elliott, G. L. (1980). Increasing Tree Seach Efficiency Constraint
Satisfaction Problems. Artificial Intelligence, 14, 263313.
Harvey, W. D., & Ginsberg, M. L. (1995). Limited Discrepancy Search. Proceedings
Fourteenth International Joint Conference Artificial Intelligence, IJCAI-95,
pp. 607615. Morgan Kaufmann.
Hsu, E. I., Kitching, M., Bacchus, F., & McIlraith, S. A. (2007). Using Expectation Maximization Find Likely Assignments Solving CSPs. Proceedings TwentySecond AAAI Conference Artificial Intelligence, pp. 224230. AAAI Press.
Hulubei, T., & OSullivan, B. (2006). Impact Search Heuristics Heavy-Tailed
Behaviour. Constraints, 11 (2-3), 159178.
ILOG (2005). ILOG Solver 6.1 Users Manual. page 378.
Jurkat, W., & Ryser, H. J. (1966). Matrix Factorizations Determinants Permanents.
Journal Algebra, 3, 127.
Kask, K., Dechter, R., & Gogate, W. (2004). Counting-Based Look-Ahead Schemes
Constraint Satisfaction. Springer-Verlag (Ed.), Proceedings Tenth International Conference Principles Practice Constraint Programming, CP-04, Vol.
LNCS 3258, pp. 317331.
Liang, H., & Bai, F. (2004). Upper Bound Permanent (0,1)-Matrices. Linear
Algebra Applications, 377, 291295.
Melo, R., Urrutia, S., & Ribeiro, C. (2009). traveling tournament problem predefined venues. Journal Scheduling, 12 (6), 607622.
Minc, H. (1963). Upper Bounds Permanents (0, 1)-matrices. Bulletin American
Mathematical Society, 69, 789791.
Pesant, G. (2004). Regular Language Membership Constraint Finite Sequences Variables. Proceedings Tenth International Conference Principles Practice
Constraint Programming, CP-04, Vol. 3258 LNCS, pp. 482495. Springer.
Pesant, G. (2005). Counting solutions csps: structural approach. Proceedings
Nineteenth International Joint Conference Artificial Intelligence, IJCAI-05, pp.
260265.
Pesant, G., & Quimper, C.-G. (2008). Counting solutions knapsack constraints. Proceedings Fifth International Conference Integration AI Techniques
Constraint Programming Combinatorial Optimization Problems, CPAIOR-08,
pp. 203217.
Pesant, G., & Zanarini, A. (2011). Recovering indirect solution densities counting-based
branching heuristics. Achterberg, T., & Beck, J. C. (Eds.), CPAIOR, Vol. 6697
Lecture Notes Computer Science, pp. 170175. Springer.
209

fiPesant, Quimper, & Zanarini

Quimper, C., Lopez-Ortiz, A., van Beek, P., & Golynski, A. (2004). Improved algorithms
global cardinality constraint. Proceedings Tenth International Conference
Principles Practice Constraint Programming, CP-04, Vol. LNCS 3258, pp.
542556. Springer.
Refalo, P. (2004). Impact-Based Search Strategies Constraint Programming. Proceedings Tenth International Conference Principles Practice Constraint
Programming, CP-04, Vol. LNCS 3258, pp. 557571. Springer.
Regin, J.-C. (1994). Filtering Algorithm Constraints Difference CSPs.
Proceedings Twelfth National Conference Artificial Intelligence, AAAI-94,
Vol. 1, pp. 362367. American Association Artificial Intelligence.
Regin, J. (1999). Symmetric Alldiff Constraint. Proceedings Sixteenth International Joint Conference Artificial Intelligence, IJCAI-99, pp. 420425. Morgan
Kaufmann Publishers Inc.
Shi, W. (1979). Branch Bound Method Multiconstraint Zero One Knapsack
Problem.. Journal Operational Research Society, 30, 369378.
Smith, B. M., & Grant, S. A. (1998). Trying Harder Fail First. Thirteenth European
Conference Artificial Intelligence, ECAI-98, pp. 249253. John Wiley & Sons.
Soules, G. W. (2005). Permanental Bounds Nonnegative Matrices via Decomposition.
Linear Algebra Applications, 394, 7389.
Szymanek, R., & OSullivan, B. (2006). Guiding Search using Constraint-Level Advice.
Proceeding Seventeenth European Conference Artificial Intelligence, ECAI06, Vol. 141 Frontiers Artificial Intelligence Applications, pp. 158162. IOS
Press.
Trick, M. A. (2003). dynamic programming approach consistency propagation
knapsack constraints. Annals Operations Research, 118, 7384.
Valiant, L. (1979). Complexity Computing Permanent. Theoretical Computer
Science, 8 (2), 189201.
Walsh, T. (1999). Search Small World. Proceedings Sixteenth International
Joint Conference Artificial Intelligence, IJCAI-99, pp. 11721177.
Wassermann, A. (2007).
feasibility version market split problem.
http://did.mat.uni-bayreuth.de/ alfred/marketsplit.html. last consulted 2007-11.
Zanarini, A., Milano, M., & Pesant, G. (2006). Improved algorithm soft global cardinality constraint. Proceedings Third International Conference Integration
AI Techniques Constraint Programming Combinatorial Optimization
Problems, CPAIOR-06, Vol. LNCS 3990, pp. 288299. Springer.
Zanarini, A., & Pesant, G. (2009). Solution Counting Algorithms Constraint-Centered
Search Heuristics. Constraints, 14, 392413.
Zanarini, A., & Pesant, G. (2010). robust counting-based search heuristics
alldifferent constraints. Lodi, A., Milano, M., & Toth, P. (Eds.), CPAIOR, Vol.
6140 Lecture Notes Computer Science, pp. 354368. Springer.

210

fiJournal Artificial Intelligence Research 43 (2012) 389418

Submitted 10/11; published 03/12

Generalized Biwords Bitext Compression
Translation Spotting
Felipe Sanchez-Martnez
Rafael C. Carrasco

fsanchez@dlsi.ua.es
carrasco@dlsi.ua.es

Departament de Llenguatges Sistemes Informatics
Universitat dAlacant, E-03071, Alacant, Spain

Miguel A. Martnez-Prieto
Joaqun Adiego

migumar2@infor.uva.es
jadiego@infor.uva.es

Departamento de Informatica
Universidad de Valladolid, E-47011, Valladolid, Spain

Abstract
Large bilingual parallel texts (also known bitexts) usually stored compressed
form, previous work shown efficiently compressed
fact two texts mutual translations exploited. example, bitext
seen sequence biwords pairs parallel words high probability cooccurrence used intermediate representation compression process.
However, simple biword approach described literature exploit one-toone word alignments cannot tackle reordering words. therefore introduce
generalization biwords describe multi-word expressions reorderings.
also describe methods binary compression generalized biword sequences,
compare performance different schemes applied extraction
biword sequence. addition, show generalization biwords allows
implementation efficient algorithm look compressed bitext words
text segments one texts retrieve counterpart translations
text application usually referred translation spotting minor
modifications compression algorithm.

1. Introduction
increasing availability large collections multilingual texts fostered development natural-language processing applications address multilingual tasks
corpus-based machine translation (Arnold, Balkan, Meijer, Humphreys, & Sadler, 1994;
Lopez, 2008; Koehn, 2010; Carl & Way, 2003), cross-language information retrieval (Grossman & Frieder, 2004, Ch. 4), automatic extraction bilingual lexicons (Tufis, Barbu,
& Ion, 2004), translation spotting (Simard, 2003; Veronis & Langlais, 2000).
applications, monolingual nature e.g., syntactic parsing (Carroll, 2003),
word sense disambiguation (Ide & Veronis, 1998) also exploit multilingual texts
projecting linguistic knowledge available one language languages (Mihalcea
& Simard, 2005).
bilingual parallel corpus, bitext, textual collection contains pairs documents translations one another. documents pair nature
c
2012
AI Access Foundation. rights reserved.

fiSanchez-Martnez, Carrasco, Martnez-Prieto & Adiego

sometimes called source text target text, respectively. However, whenever
information document created unknown irrelevant, documents
simply called left text right text. words Melamed (2001, p. 1), bitexts
one richest sources linguistic knowledge translation text
another language viewed detailed annotation text means.
Bitexts usually available compressed form order reduce storage requirements, improve access times (Ziviani, Moura, Navarro, & Baeza-Yates, 2000),
increase efficiency transmissions. However, independent compression two
texts bitext clearly far efficient information contained texts
redundant: theory, one texts might sufficient generate translated version reliable machine translation systems already available (Nevill-Manning & Bell,
1992). improvement compression performance obtained taking advantage
fact two texts bitext mutual translations may regarded indication quality word alignments (Och & Ney, 2003). indicator, bounds
mutual information (Cover & Thomas, 1991) two texts bitext, require
manually-annotated corpus evaluate automatic alignment.
first article dealing compression bitexts published Nevill-Manning
Bell (1992). approach compressed one texts isolation,
compressed general prediction partial matching (PPM; Cleary & Witten, 1984)
encoder based model used automatic translation left text predict
words right text. model exploited two types relations exact word
matches synonymy relationships provided thesaurus relative weight
predictions depended number letters word processed.
approach obtained better compression ratios standard PPM coder operating
concatenated texts.
contrast, Conley Klein (2008) proposed text alignment is, pairings
words phrases one text other, basis multilingual text compression. algorithm extends ideas delta-encoding (Suel &
Memon, 2003) case right text R translated, automatically aligned,
version source text L: L compressed first, block R encoded
reference parallel block L. method requires computation wordand phrase-level alignments, together lemmatized forms L R. translated text retrieved references, using bilingual glossary together
linguistic resources: lemmata dictionary words L, dictionary possible
morphological variants word R, bilingual glossary. authors report
slight improvements compression right text R comparison classical compression algorithms bzip21 word-based Huffman (Moffat, 1989) (approximately
1% 6%, respectively). However, authors take consideration size
auxiliary files needed retrieval right text.
contrast PPM, text-compression methods use words rather characters
input tokens (Moffat, 1989; Moffat & Isal, 2005). Analogously, Martnez-Prieto, Adiego,
Sanchez-Martnez, de la Fuente, Carrasco (2009), Adiego colleagues (2009,
2010) propose use biwords pairs words, one different text, high
1. http://www.bzip.org

390

fiGeneralized Biwords Bitext Compression Translation Spotting

Figure 1: Processing pipeline biword-based bitext compression approach.

probability co-occurrence input units compression bitexts. means
biword-based intermediate representation bitext obtained exploiting
alignments, encoding unaligned words pairs one component empty
string. Significant spatial savings achieved technique (Martnez-Prieto et al.,
2009), although compression biword sequences requires larger dictionaries
traditional text compression methods.
biword-based compression approach works simple processing pipeline consisting
two stages (see Figure 1). text alignment obtained without pre-existing
linguistic resources, first stage transforms bitext biword sequence.
second stage compresses sequence. Decompression works reverse order:
biword sequence representing bitext first generated compressed file,
original texts restored sequence.
variation PPM algorithm takes words rather characters input
tokens bytes rather bits minimal output units (Adiego & de la Fuente, 2006)
directly applied order compress biword sequences. bitext thus compressed
using single probabilistic model texts rather independent models used
older bitext-compression approaches (Nevill-Manning & Bell, 1992; Conley & Klein,
2008). improvement general-purpose compressors obtained approach
depends language pair: instance, reduction output size almost 11%
obtained SpanishPortuguese, 2.5% EnglishFrench (Martnez-Prieto
et al., 2009).
different biword-based scheme called 2lcab recently proposed (Adiego et al.,
2009) creates two-level dictionary store biwords compresses biword
sequence End-Tagged Dense Code (ETDC; Brisaboa, Farina, Navarro, & Parama,
2007). usage ETDC permits Boyer-Moore-type searching (Boyer & Moore,
1977), random access compressed file. 2lcab used compression booster
standard PPM coder, improvements compression obtained,
longer possible directly search compressed files (Adiego et al., 2010).
biword sequences obtained former biword-based compression methods
contain large fraction 10% 60%, depending language pair
unpaired words, is, biwords one words pair empty word .
unpaired words generated three different cases:
391

fiSanchez-Martnez, Carrasco, Martnez-Prieto & Adiego

Figure 2: Example SpanishEnglish pair sentences one-to-many word alignments.
aligner unable connect word words parallel text
because, example, infrequent idiomatic expressions free translations
found.
aligner generates one-to-many alignment word translated
multiword expression. instance, Spanish word volver translated
English go back, biword extractor select one links, build
pair words link, leave words unpaired.
aligner generates crossing alignments result word reordering
translation. instance, Figure 2, either pair (verde, green) pair
(casa, house) must ignored biword extractor, thus leaving two unpaired
words; otherwise, information provided sequence sufficient
retrieve texts original order.
last two sources unpaired words responsible different spatial savings
reported Martnez-Prieto et al. (2009) bitexts consisting closely-related languages
(e.g., Spanish Portuguese) involving divergent language pairs (e.g., French
English), word reorderings multiword translations frequent.
paper, describe evaluate simple biword extraction approach, compare schemes used generate generalized biword sequences maintain
part structural information provided aligner. biword essentially becomes
left word connected variable number right words plus additional information
concerning relative position right word regard preceding one.
fraction unpaired words thus reduced, better compression ratios obtained.
also show generalization biwords allows implementation
efficient translation spotting (Simard, 2003; Veronis & Langlais, 2000) algorithm
compressed bitext; task consists identifying words (or text segments)
text translation words query. Indeed, generalized biword
sequences contain information needed order retrieve connected passages.
Generalized biwords also used ingredient bilingual language model
employed statistical machine translation systems (Koehn, 2010). instance,
Marino et al. (2006) use bilingual n-grams consider translation bilingual decoding process. Casacuberta Vidal (2004) also exploit bilingual n-grams apply
stochastic finite-state transducers task. cases, local reordering words
addressed considering multiword segments source target words fundamental translation units. alternative approaches (Niehues, Herrmann, Vogel, & Waibel,
2011; Matusov, Zens, Vilar, Mauser, Popovic, Hasan, & Ney, 2006; Hasan, Ganitkevitch,
392

fiGeneralized Biwords Bitext Compression Translation Spotting

Ney, & Andres-Ferrer, 2008) integrate bilingual language models additional feature
decoding function drives statistical translation process. However, none
approaches mentioned includes structural information provided aligners part
bilingual language model.
remainder paper organized follows. following section shows
generalized biword sequence represent bitext. Section 3 describes two different methods applied compress biword sequence. Section 4 introduces resources
used evaluate different generalizations biwords, whereas Section 5 discusses
compression results obtained. Section 6 describes modifications one
compression techniques order allow compressed bitext searched presents
efficient search translation spotting algorithms. Finally, concluding remarks
presented Section 7.

2. Extraction Biword Sequences
extracting sequence biwords representing bitext, alignments
words left text L = l1 l2 lM words right text R = r1 r2 rN must
established word aligner. Word aligners usually work sentence aligner
identified pairs sentences bitext parallel, is, plausible mutual
translation. Sentence alignment algorithms often based simple statistical models
correlation sentence lengths (Brown, Lai, & Mercer, 1991; Gale & Church,
1993).
Current word aligners use word-based statistical machine translation models (Brown,
Cocke, Pietra, Pietra, Jelinek, Lafferty, Mercer, & Roossin, 1990; Brown, Pietra, Pietra,
& Mercer, 1993) compute likely alignment words two parallel
sentences (Koehn, 2010, Ch. 4). case, word alignments computed opensource Giza++ toolkit2 (Och & Ney, 2003) implements set methods, including
standard word-based statistical machine translation models (Brown et al., 1993)
hidden-Markov-model-based alignment model (Vogel, Ney, & Tillmann, 1996). Giza++
produces alignments depicted Figure 2, source word (here, left
word) aligned many target words (here, right words), whereas target word
aligned with, most, one source word.
result word alignment bigraph G = {L, R, A} edge {li , rj }
word li L word rj R signifies mutual translations according
translation model used aligner. complex structures processed
splitting bigraph connected components: connected component either
unpaired (right left) word, left word aligned sequence (one more) right
words. shown later, connected component including structural information
needed place words original positions bitext term
generalized biword.
order build sequence B generalized biwords, biwords sorted primarily
according left component and, secondarily, head right component
. precisely, left() right() denote left word sequence right
2. http://code.google.com/p/giza-pp/

393

fiSanchez-Martnez, Carrasco, Martnez-Prieto & Adiego

words respectively biword , represents empty left right component
unpaired words, precedes if:
left() 6= , left() 6= left() precedes left() L.
Either left() = left() = , right() 6= , right() 6= , initial word
right() precedes, R, initial word right().
left() = , left() 6= biword precedes precedes
.
Every generalized biword = (, , ) sequence B consists of:
string L ,
array strings R ,
integer array containing one offset every string .
Here, L denotes set different words L enhanced empty word , R
denotes set subsequences R includes empty subsequence, represented
(). array offsets stores structural information needed place word
original position.
offset non-negative integer specifies, every word
first one, number words R located word preceding one ,
thus allowing generation stage decompression keep track gaps
subsequence filled word posterior biword B. offset
first word w 6= () defined number words R located w
first available gap, is, first word R belongs biword
precede = (, , ).
combination types offsets permits encoding translations
word reordering. Indeed, seen Figure 3, offset biword (casa,
(house),(1)) signifies one-word gap house occupied word green offset 0 (verde,(green),(0)). offsets (vivimos,
(we,live), (0,0)) indicate comes directly word house live comes
immediately we. pseudo-code procedure extracts sequence
generalized biwords details implementation found Appendix A.
Henceforth, shall call biwords shifts biwords least one non-null
offset (biwords without shifts, otherwise). shall differentiate biwords
simple shifts, first offset non-null, biwords complex shifts,
non-consecutive words R.
Generalized biwords clearly expressive, bitexts therefore mapped
onto shorter sequences. However, enhanced variety biwords implies compression algorithms must use larger dictionaries. global effect compression
ratio must therefore explored. also worth measuring effect ignoring certain infrequent alignments order avoid biwords complex shifts. example,
generalized biword sequence Figure 3 contains one biword complex shifts,
(prefiero,(i,like),(0,1)) split smaller components, (,(i),
394

fiGeneralized Biwords Bitext Compression Translation Spotting

(prefiero,(i,like),(0,1))
(,(would),(0))
(volver,(to,go,back),(0,0,0))
(a,(to),(0))
(la,(the),(0))
(casa,(house),(1))
(verde, (green),(0))
(en,(in),(2))
(que,(),())
(vivimos,(we,live),(0,0))
Figure 3: Generalized biword sequence word-aligned sentence shown Figure 2.
(0)) (prefiero,(like),(0)), sequence includes biwords simple
shifts. simple shifts allowed, compression algorithm needs encode, most,
one non-null offset per biword.
experiments shall compare results obtained algorithms described
next section (Tre 2lcab) used combination four different methods
extract sequence biwords:
1:N Complex: one-to-many word alignments generated Giza++ used
generate sequence generalized biwords.
1:N Simple: biwords complex shifts generated one-to-many alignments provided Giza++ split biwords simple shifts plus unpaired
words; result sequence biwords simple shifts without shifts. Biwords complex shifts split ignoring least frequent alignments
resulting biwords contain simple shifts.
1:1 Non-monotonic: one-to-one word alignments obtained computing intersection alignments produced Giza++ left right text
exchanged; result sequence biwords whose right component contains,
most, one word (and biwords cannot, therefore, complex shifts).
1:1 Monotonic: 1:1 non-monotonic sequence transformed sequence
biwords without shifts splitting biwords shifts unpaired words.
last method, 1:1 Monotonic, use enhancement provided generalization biwords (i.e., structural information), therefore equivalent basic
procedures described earlier (Martnez-Prieto et al., 2009; Adiego et al., 2009, 2010).

3. Compression Biword Sequences
clearly possible compress intermediate representation introduced previous
section via application wide range approaches. Here, describe evaluate
two different encoding methods, namely Tre (Subsection 3.2) 2lcab (Subsection 3.3),
apply word-based implementation Huffman coding (Moffat & Turpin, 1997; Turpin
395

fiSanchez-Martnez, Carrasco, Martnez-Prieto & Adiego

& Moffat, 2000) input strings mapped onto integers compressed
Huffman codewords (Huffman, 1952). methods encode offsets described
(Subsection 3.1) differ encode lexical components biword
sequence.
use Huffman codewords allows two methods described achieve large
spatial savings, makes inefficient search compressed bitext retrieve
matches. Section 6 shall describe variant 2lcab compression algorithm
(searchable 2lcab) allows sequence words retrieved left text
addition parallel sequences (and context) right text.
3.1 Structural Encoding
Preliminary tests showed biword extraction algorithm capable generating
sequences high number (usually 70%) biwords without shifts, array
null values thus considered default offset sequence. offsets therefore
encoded two streams integer values:
positions P = (p1 , p2 , . . . , pN ) biwords shifts sequence B.
positions expressed relation previous biword shifts B;
example, biwords shifts Figure 3 P = (1, 5, 2).
offset values biwords shifts. example, offsets =
(0, 1, 1, 2); first two offsets belong first biword shifts whereas
following ones belong second third biword shifts, respectively.
streams therefore encoded using two independent sets Huffman codewords.
3.2 TRE Compressor
Translation Relationship-based Encoder (Tre) assigns codewords left word
sequences right words biword use two independent methods.
left text encoded using word-based Huffman coding (Moffat, 1989). contrast,
right text encoded using left text context. this, Tre uses three
dictionaries: one, L , left words, second one, R , sequences right
words, third one, translation dictionary B , maps word L onto
subset entries R :
B () = { R : N : (, , ) B}.
every L sequences B () sorted frequency assigned integer
range [1, |B ()|], thus signifying frequent translations lowest
values.
compression stage, text every biword (, , ) mapped onto pair
integers reference left word integer value assigned sequence
right words B (), sequences integers compressed using
independent Huffman codewords. compression efficiency improved
frequent translations assigned low (and thus recurrent) integer values. Finally,
compressed file includes header with:
396

fiGeneralized Biwords Bitext Compression Translation Spotting

dictionaries L R , independently encoded using PPM compression. special character used separate consecutive entries dictionaries
white-space serves delimiter word sequences.
translation dictionary B , is, Huffman-compressed sequence integers
(Moffat & Turpin, 1997) containing, every entry L , size B ()
references entries R store every sequence B ().
independent Huffman codewords used compress integer sequences references, B () values.
3.3 2LCAB Compressor
contrast Tre, 2-Level Compressor Aligned Bitexts (2lcab; Adiego et al., 2009)
encodes every biword single codeword based two-level dictionary. first level
consists two dictionaries, L R , containing left words sequences right
words, respectively, appear biword sequence B. second level dictionary B
stores different biwords B integer sequence alternating references
entries L R . text sequence B mapped onto sequence
references entries B .
header includes L R compressed, Tre, PPM algorithm (Cleary & Witten, 1984). also contains codewords (selected according
Huffman compression procedure) integers sequence describing dictionary
B , encoded dictionary B , second list Huffman codewords used encode
biword sequence B. implementation 2lcab employs (bit-oriented) Huffman coding, original work (Adiego et al., 2009), application described Section 6
implement byte-oriented ETDC (Brisaboa et al., 2007). bit-oriented approach
effective, ETDC permits faster searches compressed bitext.

4. Resources Settings
order evaluate performance bitext compressors based generalized biwords
made use following bitext collections:
100 MB SpanishCatalan (es-ca) bitext obtained El Periodico de Catalunya,3
daily newspaper published Catalan Spanish.
100 MB WelshEnglish (cy-en) bitext Proceedings National Assembly Wales (Jones & Eisele, 2006).4
Bitexts (100 MB each) European Parliament Proceedings Parallel Corpus
(Europarl; Koehn, 2005) seven different language pairs: GermanEnglish (de-en),
SpanishEnglish (es-en), SpanishFrench (es-fr), SpanishItalian (es-it), Spanish
Portuguese (es-pt), FrenchEnglish (fr-en), FinnishEnglish (fi-en).
3. Available on-line http://www.elperiodico.com.
4. Available on-line http://xixona.dlsi.ua.es/corpora/UAGT-PNAW/.

397

fiSanchez-Martnez, Carrasco, Martnez-Prieto & Adiego

Lang.
pair
en-de
es-en
fr-es
it-es
pt-es
fr-en
es-ca
en-fi
cy-en

bzip2

gzip

p7zip

ppmdi

wh

22.19%
22.01%
21.51%
21.88%
21.94%
21.65%
27.21%
22.17%
21.83%

31.59%
31.38%
30.80%
31.00%
31.10%
31.10%
37.09%
31.32%
31.11%

21.61%
21.39%
20.75%
21.15%
21.11%
21.06%
24.41%
20.78%
20.33%

20.35%
20.12%
19.57%
19.98%
20.02%
19.76%
25.43%
20.33%
20.07%

23.28%
23.95%
24.04%
23.57%
23.11%
24.57%
27.66%
22.97%
25.18%

Table 1: Compression ratios obtained four general-purpose compressors wordbased text compressor (wh).
common information retrieval applications, texts tokenized converted lowercase (Manning & Schutze, 1999, Ch. 4). tokenization placed blank
spaces every punctuation mark, word thus defined
sequence alphanumeric characters delimited blank spaces.
Word alignments computed Giza++ toolkit, parameters set
default values, exception fertility set 5 (the default
9). fertility maximum number words word aligned,
low value moderates number right sequences one single occurrence bitext.

5. Results Discussion
reference, Table 1 shows compression ratio defined quotient
lengths output input texts (Ziv & Lempel, 1977) achieved aforementioned bitexts compressed variety general-purpose compressors
word-based compressor operating concatenation two texts L
R. approaches quoted introduction could compared either
code linguistic resources required publicly available. compressors
used reference are:
bzip2 compressor,5 splits text blocks (100-900 KB), then, applies
Burrows-Wheeler Transform (BWT; Burrows & Wheeler, 1994) followed moveto-front transformation and, finally, encodes result Huffman encoder.
Two dictionary-based compressors built different variants Ziv-Lempels
LZ77 (Ziv & Lempel, 1977) algorithm. First, gzip,6 classical compressor
combines LZ77-based modeling Huffman coding (Huffman, 1952). Second,
modern p7zip7 compressor based Lempel-Ziv-Markov chain algorithm (Sa5. http://www.bzip.org. Experiments run version 1.0.5.
6. http://www.gzip.org. Experiments carried version 1.3.12-6.
7. http://www.7zip.com. Experiments carried using version 4.58dfsg1.1.

398

fiGeneralized Biwords Bitext Compression Translation Spotting

Lang.
pair
en-de
es-en
fr-es
it-es
pt-es
fr-en
es-ca
en-fi
cy-en

1:1
Monotonic
20.38%
19.63%
19.07%
19.21%
18.44%
20.20%
17.02%
21.50%
20.06%

1:1
Non-monotonic
20.06%
18.85%
18.60%
18.86%
18.06%
19.30%
16.95%
20.82%
18.69%

1:N
Simple
20.26%
18.69%
18.78%
19.11%
18.17%
19.31%
16.78%
21.70%
18.05%

1:N
Complex
21.22%
19.33%
19.51%
20.00%
18.79%
20.06%
16.86%
22.24%
18.22%

Table 2: Compression ratios obtained Tre compressor different biword
extraction methods.
lomon, 2007, Sec. 3.24), algorithm improves LZ77 large dictionary
(up 4 GB) range encoding (Martin, 1979).
ppmdi (Shkarin, 2002) representative Prediction Partial Matching
(PPM; Cleary & Witten, 1984) family compressors. ppmdi uses high-order
context model method (Howard & Vitter, 1992) handle escape codes.
implementation available Pizza&Chili website8 default configuration
(sixth-order context model) used.
word-based Huffman compressor (Moffat, 1989) maps input strings
integers encoding values Huffman codewords (Moffat & Turpin, 1997;
Turpin & Moffat, 2000). method originally designed compress text,
also works well types sources. dictionary maps words integers
encoding ppmdi compressor part output.
seen Table 1, lowest compression ratios obtained ppmdi,
except es-ca pair. fact compression ratios depend moderately
languages involved suggests compressors benefit (variable)
cross-language information provided translations.
ratios must compared performance two compressors described
section presented Tables 2 3. Note although bitexts
aligned translation directions, results obtained direction producing
best compression reported here, since effect choice compression
ratio proved small (an average difference 0.2 percentage points).
comparison shows Tre 2lcab outperform general-purpose compressors cases en-fi pair. best results obtained
cases one-to-one alignments used techniques. 2lcab achieves
slightly better results Tre language pairs exception it-es
pt-es, although two cases difference performance small considered relevant. low performance en-fi consequence larger translation
8. http://pizzachili.dcc.uchile.cl/utils/ppmdi.tar.gz

399

fiSanchez-Martnez, Carrasco, Martnez-Prieto & Adiego

Lang.
pair
en-de
es-en
fr-es
it-es
pt-es
fr-en
es-ca
en-fi
cy-en

1:1
Monotonic
19.98%
19.29%
18.89%
19.18%
18.46%
19.75%
16.69%
21.29%
19.43%

1:1
Non-monotonic
19.83%
18.68%
18.50%
18.87%
18.09%
19.03%
16.61%
20.62%
18.30%

1:N
Simple
20.77%
19.08%
19.27%
19.77%
18.75%
19.65%
16.59%
22.46%
17.98%

1:N
Complex
22.12%
19.99%
20.25%
20.96%
19.60%
20.71%
16.70%
23.31%
18.25%

Table 3: Compression ratios obtained 2lcab compressor different biword
extraction methods.
Lang.
pair
en-de
es-en
fr-es
it-es
pt-es
fr-en
es-ca
en-fi
cy-en

General
purpose
20.35%
20.12%
19.57%
19.98%
20.02%
19.76%
24.41%
20.33%
20.07%

2lcab 1:1
Monotonic
19.98%
19.29%
18.89%
19.18%
18.46%
19.75%
16.69%
21.29%
19.43%

2lcab
(best)
19.83%
18.68%
18.50%
18.87%
18.09%
19.03%
16.59%
20.62%
17.98%

Gain
(Best/Gen.)
2.56%
7.16%
5.47%
5.56%
9.64%
3.69%
32.04%
-1.43%
10.41%

Gain
(Best/Mono.)
0.75%
3.16%
2.06%
1.62%
2.00%
3.65%
0.60%
3.15%
7.46%

Table 4: Summary best compression results obtained with: i) general-purpose
word-based compressors; ii) 2lcab compressor structural information (1:1
Monotonic); iii) best 2lcab compressor. columns right show relative improvement best 2lcab general purpose monotonic compressors,
respectively.

dictionaries used Tre, larger bilingual dictionary used 2lcab, comparison
language pairs. Furthermore, percentage unpaired words also higher
language pairs seen below.
Table 4 summarizes results obtained general-purpose compressors
2lcab, relative gains compression performance regard generalpurpose compressors performing best, regard 2lcab compressing
1:1 Monotonic biword sequence. greatest improvement, comparison results obtained general-purpose compressors, achieved language pair es-ca:
instead 24.4% compression ratio obtained p7zip, 2lcab achieves compression
ratio 16.6% represents substantial spatial saving (32.04% relative improvement).
suggests Tre 2lcab take advantage fact texts contain
400

fiGeneralized Biwords Bitext Compression Translation Spotting

Lang.
pair
en-de
es-en
fr-es
it-es
pt-es
fr-en
es-ca
en-fi
cy-en

1:1
Monotonic
0.600
0.506
0.463
0.465
0.421
0.540
0.128
0.684
0.530

1:1
Non-monotonic
0.483
0.395
0.398
0.408
0.363
0.425
0.122
0.610
0.387

1:N
Simple
0.352
0.984
0.290
0.279
0.249
0.316
0.077
0.492
0.286

1:N
Complex
0.319
0.258
0.266
0.247
0.225
0.292
0.072
0.467
0.276

Table 5: Fraction biwords extracted sequence one empty component.
information encoded different languages, particularly case highly
parallel bitexts (en-cy) languages high syntactic correlation (es-ca).
generalization biwords generates shorter biword sequences, essentially
sequence extracted contains lower fraction unpaired words. Table 5 shows
fraction biwords one component empty word (the unpaired
word). number obviously considerably reduced offsets used encode
structural information implicit alignments. course, case 1:N Complex
approach, fraction coincides bigraph produced aligner.
expected, effect generalization percentage biwords empty
component depends languages involved, reduction smaller pairs
closely-related languages (es-ca, pt-es, it-es) pairs languages strong
grammatical divergences (en-de, es-en, fr-en) since, latter case, word reorderings multiword expressions commonly appear translations.
order gain insight performance Tre 2lcab compressors,
interesting make separate examination contribution output size
headers, dictionaries codewords. respect, worth noting that:
1. number entries left dictionary L depend method used
extract biword sequence.
2. number entries right dictionary R identical two extraction
methods based one-to-one alignments consists words found
right text plus empty word.
Tables 6 7 show fraction output corresponds encoded biword
sequence (columns B), translation dictionary biword dictionary (columns D),
depending compressor used. numbers reveal general biwords used are, compact encoded sequences compared headers
dictionaries. particular, translation dictionary size (analogously, biword dictionary size) differ much non-monotonic alignments used instead basic
method. However, usage one-to-many alignments causes size dictionary
grow considerably, particularly case biword dictionary B used 2lcab.
401

fiSanchez-Martnez, Carrasco, Martnez-Prieto & Adiego

Lang.
pair
en-de
es-en
fr-es
it-es
pt-es
fr-en
es-ca
en-fi
cy-en

1:1
Monotonic
B

0.933 0.031
0.942 0.035
0.934 0.041
0.928 0.045
0.923 0.047
0.951 0.029
0.892 0.039
0.884 0.059
0.960 0.021

1:1
Non-monotonic
B

0.930
0.034
0.940
0.037
0.932
0.042
0.927
0.046
0.922
0.048
0.948
0.031
0.893
0.039
0.884
0.058
0.958
0.023

1:N
Simple
B

0.857 0.070
0.894 0.058
0.884 0.065
0.870 0.073
0.870 0.072
0.903 0.054
0.870 0.045
0.785 0.093
0.933 0.034

1:N
Complex
B

0.787 0.078
0.839 0.069
0.826 0.074
0.805 0.081
0.819 0.078
0.845 0.066
0.862 0.046
0.724 0.089
0.916 0.038

Table 6: Fraction file compressed Tre encoding bitext (B) translation dictionary (D).

Lang.
pair
en-de
es-en
fr-es
it-es
pt-es
fr-en
es-ca
en-fi
cy-en

1:1
Monotonic
B

0.896 0.065
0.911 0.063
0.894 0.077
0.886 0.083
0.880 0.087
0.920 0.057
0.859 0.071
0.845 0.094
0.939 0.039

1:1
Non-monotonic
B

0.893
0.067
0.908
0.065
0.892
0.079
0.884
0.084
0.880
0.088
0.916
0.060
0.860
0.070
0.844
0.093
0.935
0.042

1:N
Simple
B

0.808 0.116
0.844 0.105
0.831 0.115
0.812 0.128
0.814 0.126
0.856 0.098
0.832 0.080
0.725 0.151
0.903 0.061

1:N
Complex
B

0.733 0.130
0.788 0.119
0.772 0.126
0.745 0.140
0.762 0.133
0.796 0.114
0.824 0.082
0.666 0.147
0.884 0.066

Table 7: Fraction file compressed 2lcab encoding bitext (B)
biword dictionary (D).

402

fiGeneralized Biwords Bitext Compression Translation Spotting

Lang.
pair
en-de
es-en
fr-es
it-es
pt-es
fr-en
es-ca
en-fi
cy-en

Comp.
Ratio
19.82%
18.51%
18.58%
18.82%
17.98%
19.10%
16.78%
21.01%
18.05%

1:N Simple
Biword
B
reduc. weight
0.514
0.033
0.495
0.024
0.472
0.028
0.458
0.029
0.483
0.030
0.479
0.022
1.000
0.045
0.539
0.049
1.000
0.034

1:N Complex
Comp. Biword
B
Ratio reduc. weight
19.93%
0.465
0.033
18.56%
0.441
0.024
18.64%
0.434
0.027
18.91%
0.418
0.029
18.05%
0.456
0.030
19.17%
0.416
0.022
16.86%
1.000
0.046
21.09%
0.559
0.048
18.08%
0.631
0.019

Table 8: Compression ratios Tre infrequent biwords split smaller
biwords, remaining fraction original biword dictionary, relative size translation dictionary compressed file.

Lang.
pair
en-de
es-en
fr-es
it-es
pt-es
fr-en
es-ca
en-fi
cy-en

1:N Simple
Comp. Biword
B
Ratio reduc. weight
19.42%
0.435
0.043
18.16%
0.406
0.036
18.21%
0.385
0.038
18.47%
0.334
0.035
17.67%
0.361
0.037
18.71%
0.386
0.033
16.59%
1.000
0.080
20.50%
0.445
0.056
17.68%
0.573
0.029

1:N Complex
Comp. Biword
B
Ratio reduc. weight
19.51%
0.393
0.043
18.22%
0.326
0.031
18.27%
0.354
0.037
18.55%
0.306
0.035
17.73%
0.341
0.036
18.77%
0.334
0.032
16.70%
1.000
0.082
20.55%
0.464
0.055
17.71%
0.542
0.029

Table 9: Compression ratios 2lcab infrequent biwords split smaller
biwords, remaining fraction original biword dictionary, relative size biword
dictionary compressed file.

This, cases, causes 2lcab perform worse Tre one-to-many
word alignments.
observation one-to-many alignment leads larger dictionaries makes worth
exploring effect compression ratio infrequent biwords discarded.
Tables 8 9 therefore show compression ratios obtained Tre 2lcab, respectively, infrequent biwords split smaller, frequent, biwords.
split proceeds iteratively removing least frequent alignment biword (which
produces new unpaired word) biword frequencies threshold
biwords contain unpaired words. threshold determined means ternary
search optimizes compression ratio. tables also show fraction biwords
403

fiSanchez-Martnez, Carrasco, Martnez-Prieto & Adiego

remain dictionary pruning, along new fraction output
corresponds translation biword dictionary.
seen tables, discarding infrequent biwords (about two thirds
them) usually leads improvement compression ratios, except case
similar languages, Catalan Spanish, translation highly
parallel. effect important case 2lcab pruning leads
large reduction size biword dictionary compensates small
increment total number biwords needed represent bitext (between 5%
10% increment depending method used generation). filtering,
2lcab Tre obtain best results extracting biword sequence method
1:N Simple.

6. Translation Spotting Compressed Bitexts
exploitation bitexts computer-aided translation tools evolved simple
bilingual concordancers (Barlow, 2004; Bowker & Barlow, 2004) advanced translation
search engines (Callison-Burch, Bannard, & Schroeder, 2005a; Bourdaillet, Huet, Langlais,
& Lapalme, 2010). standard translation unit processed bilingual concordancers
sentences, concordancers thus provide whole sentence result
translation search. contrast, translation search engines translation spotting
capabilities, i.e. retrieve parallel text segments bitexts.
would seem existing translation search engines (Callison-Burch et al., 2005a;
Bourdaillet et al., 2010) access bitexts compressed forms storing
correspondences translated segments requires additional data structures
word indexes suffix arrays (Lopez, 2007; Callison-Burch, Bannard, & Schroeder,
2005b); suffix arrays typically require four times size text (Manber & Myers,
1993). contrast, generalized biwords require much less space, integrate
alignment information compressed bitext, information exploited
retrieve translation examples. section describe minor modifications
need done 2lcab compression algorithm applied task.
also describe search algorithm compressed bitexts evaluate compression
performance new 2lcab implementation (searchable 2lcab).
application 2lcab compression technique direct search compressed
bitexts leads certain challenges present decompression process
because:
Huffman PPM compression hinder direct searching random access
compressed text (Bell, Cleary, & Witten, 1990).
multilevel scheme 2lcab, whenever matching string found
instance, biword dictionary B necessary know strings codeword
order search encoded string higher level example, sequence
biwords B.
differences induced 2lcab described follows, summarized Table 10.

404

fiGeneralized Biwords Bitext Compression Translation Spotting

Data
L
R
B
B
P


Content
lword0, lword1, . . .
rword0, rword1, . . .
lpos0, rpos0, lpos1, rpos1, . . .
bpos0, bpos1, . . .
delta0, delta1, . . .
offset0, offset1, . . .

2lcab
PPM
PPM
Huffman
Huffman
Huffman
Huffman

Searchable 2lcab
PPM
PPM
ETDC
ETDC
RRR
DAC & RG

Table 10: Summary compression methods applied. marked sort
items compression. RG used DAC case biwords complex
shifts present.
6.1 Searchable 2LCAB Compression
several alternative compression methods, ETDC, allow direct
searches compressed text. contrast output Huffman compression,
ETDC header stores words, codeword derived word position henceforth, rank words sorted according relative frequencies
document compressed. means always mapping,
denoted code(n), provides ETDC codeword n-th frequent word,
along corresponding reverse mapping.
instance, b-th byte compressed bilingual dictionary B matches leftword code, rank B determines codeword must looked B.9 course,
rank obtained keeping record number n words B scanned
far, standard pattern matching algorithms BM (Boyer & Moore, 1977)
KMP (Knuth, Morris, & Pratt, 1977) well suited tracking. therefore
use finite sequence bits = b1 , b2 , , b|S| retrieve rank n-th byte n
encoded B . sequence bn = 1 every n n final byte
codeword built fly B read compressed file.
Succinct data structures (Navarro & Makinen, 2007, Sec. 6), RG (Gonzalez,
Grabowski, Makinen, & Navarro, 2005) RRR (Raman, Raman, & Rao, 2002), provide
effective way represent sequence bits recover rank associated
every matching sequence, support number operations sequence
bits time independent length (Clark, 1996):
number bits rankS (i) whose value one b1 bi .
position selectS (i) i-th bit whose value one;
value i-th bit S, denoted accessS (i) = bi .
Moreover, structural information P describing biwords shifts
also needs randomly accessed, succinct data structure RRR provides compact
alternative Huffman-based method used 2lcab compress P, sequence
position increments. Indeed, RRR encoding especially compact information
9. rank also used discard false matches originated coincidence right word B
because, cases, rank even number.

405

fiSanchez-Martnez, Carrasco, Martnez-Prieto & Adiego

unbalanced instance, 80% bits show identical value, case
number biwords shifts small. Therefore, integer sequence P
instead stored binary sequence P = p1 , p2 , . . . , pm pi = 1 n-th byte
B final byte codeword biword shifts.
Finally, offsets stored compressed directly addressable variablelength codes (DAC, Brisaboa, Ladra, & Navarro, 2009) which, contrast Huffman
compression, provide direct access n-th encoded element. Information associated
n-th biword thus retrieved immediately, since DAC encoding
require preceding sequence decompressed beginning. biwords
complex shifts contain one offset, access cases indirect
provided auxiliary RG data structure. structure builds sequence
bits Q = q1 , q2 , , q|Q| |Q| total number offsets stored O. sequence
Q qi = 1 Oi first offset array biword (, , ), qi = 0 otherwise.
seen Table 10, searchable 2lcab method replaces Huffman compression ETDC sorts contents higher-level ETDC compression
need store codewords header.
6.2 Translation Spotting
searchable 2lcab described complemented search algorithm which,
given single word w left text, proceeds follows:
1. word w looked L whose relatively small size permits uncompressed
copy stored memory identifier n, given word position
L , used obtain ETDC codeword c = code(n).
2. exact pattern-matching algorithm (Knuth et al., 1977) identifies occurrences
codeword c biword dictionary B . match found b-th byte
r = rankS (b) odd (indicating match L -codeword, is, biword
left component w), then, biword codeword code(r/2) added
search set Z.
3. multi-pattern matching algorithm Set-Horspool (Horspool, 1980; Navarro &
Raffinot, 2002) locates codewords sequence biwords B match one
contained Z, matching positions added new set .
4. every match , adjacent right component read B and, whenever
pm = 1 P , offsets recovered used place right words
original order. case biwords complex shifts, interval Oi Oj
containing offsets starts = selectQ (r) ends j = selectQ (r + 1) 1,
r = rankP (m).
case query consists sequence words (w1 , w2 , wK ) K > 1,
Set-Horspool algorithm executed word wk sequence generating
smallest set codewords locate Zk , remaining words used filter
results biword context retrieved.
Table 11 shows actual example output obtained multiple word query
compressed biword sequence obtained 1:N Complex method. Note
406

fiGeneralized Biwords Bitext Compression Translation Spotting

Left text:

Right text:

Left text:

Right text:

Left text:

Right text:

Left text:
Right text:

democratic citizens able exercise influence , goes without saying entitled
information need order perform civic duties
society .
un componente de la democracia es que los ciudadanos puedan influir
, obviamente , que tengan derecho acceder la informacion necesaria
para actuar como ciudadanos en sus sociedades .
concerned , , protection criminal law
europol units receive information intelligence
need order perform tasks .
se trata , por tanto , de proteccion penal de que las unidades de
europol deben obtener la informacion los datos que necesiten para
poder realizar su trabajo .
co-decision procedure must used order perform
legislative work conditions guarantee genuine debate ,
involving society citizens .
para que ese trabajo legislativo se realice en condiciones que garanticen un verdadero debate , social ciudadano , hace falta recurrir al
procedimiento de codecision .
tools , procedures , need order
perform ?
cuales son las herramientas , los procedimientos que necesitamos para
ejecutarlas ?

Table 11: Output obtained query order perform bitext compressed
1:N Complex method. query terms translations spotted
boldface.

third match shows non-contiguous translation, case cannot retrieved
original 2lcab implementation (Adiego et al., 2009).
6.3 Experimental Evaluation
compression ratios obtained searchable 2lcab shown Table 12. algorithm clearly effective 2lcab described Section 3, leading compression
ratios slightly worse obtained general purpose word-based
compressors. However, worth mentioning compressed files include information concerning alignments words, information included
files compressed standard compressors necessary perform translation
spotting.
Table 12 also shows 1:1 Monotonic method case effective
1:1 Non-monotonic method latter needs additional data structure
(the RRR bit sequence) order access structural information. Moreover, byte
orientation ETDC reduces gain obtained encoding lower number biwords.
407

fiSanchez-Martnez, Carrasco, Martnez-Prieto & Adiego

Lang.
pair
en-de
es-en
fr-es
it-es
pt-es
fr-en
es-ca
en-fi
cy-en

1:1
Monotonic
22.66%
21.86%
21.30%
21.69%
20.87%
22.37%
19.22%
24.14%
22.30%

1:1
Non-monotonic
23.20%
21.81%
21.47%
21.93%
21.07%
22.19%
19.67%
24.01%
21.86%

1:N
Simple
24.10%
22.26%
22.33%
22.93%
21.78%
22.83%
19.70%
25.91%
21.39%

1:N
Complex
26.02%
23.68%
23.70%
24.57%
23.00%
24.36%
19.87%
27.29%
21.98%

Table 12: Compression ratios obtained searchable 2lcab compressor.
studied time needed process query depends language pair
also number frequencies words query. average times
100 different sequences 10 runs reported Figures 4 5, process times
measured AMD Athlon Dual Core 2 GHz 2GB RAM.
Figure 4 presents times two different language pairs. first one, en-fr, displays typical behavior Europarl bitexts (Koehn, 2005), second one,
en-fi, requires particularly longer times, especially large queries. divergent behavior seems originate poor quality alignments words
pair languages. often makes words participate large number different biwords
degrades performance Set-Horspool algorithm. language pair
consistently leads worst compression ratios.
Finally, Figure 5 shows processing times two language pairs (en-cy es-ca)
whose bitexts obtained totally different source. processing times
considerably lower required Europarl corpus manual inspection
bitexts revealed highly parallel structure. implies words
participate small number biwords and, surprisingly, 2lcab achieves
lowest compression ratios language pairs.

7. Concluding Remarks
introduced concept generalized biwords applied compression
bitexts. Generalized biwords integrate information concerning word reordering
multiword expressions translated text. described procedure transforms
bitext sequence generalized biwords used intermediate
representation compression process. extended binary compression
algorithm 2lcab proposed new one, called Tre, encoding generalized
biword sequences. also designed variant 2lcab compression technique,
companion algorithm facilitates efficient searching translation spotting
compressed bitext.
compression performance 2lcab Tre tested four different
schemes extract biword sequence, uses biwords different structural
408

fiGeneralized Biwords Bitext Compression Translation Spotting

Low-frequency sequences

Medium-frequency sequences

1:1 Monotonic
1:1 Non-monotonic
1:N Simple
1:N Complex

350
300

1:1 Monotonic
1:1 Non-monotonic
1:N Simple
1:N Complex

350
300

High-frequency sequences

300

250

250

250

200

200

200

150

150

150

100

100

100

50

50

50

0

0
1

2

3 4 5 6
Query length

7

8

1:1 Monotonic
1:1 Non-monotonic
1:N Simple
1:N Complex

350

0
1

2

3 4 5 6
Query length

7

8

1

2

3 4 5 6
Query length

7

8

(a) EnglishFrench (en-fr) bitext
Low-frequency sequences

Medium-frequency sequences

High-frequency sequences

350

350

350

300

300

300

250

250

250

200

200

200

150

150

150

100

100
1:1 Monotonic
1:1 Non-monotonic
1:N Simple
1:N Complex

50
0
1

2

3 4 5 6
Query length

100
1:1 Monotonic
1:1 Non-monotonic
1:N Simple
1:N Complex

50
0
7

8

1

2

3 4 5 6
Query length

1:1 Monotonic
1:1 Non-monotonic
1:N Simple
1:N Complex

50
0
7

8

1

2

3 4 5 6
Query length

7

8

(b) EnglishFinnish (en-fi) bitext

Figure 4: Average time (milliseconds) needed process query containing words
low, medium high frequency, function query length. Times shown
two different language pairs four encoding methods.

409

fiSanchez-Martnez, Carrasco, Martnez-Prieto & Adiego

Low-frequency sequences

Medium-frequency sequences

1:1 Monotonic
1:1 Non-monotonic
1:N Simple
1:N Complex

350
300

1:1 Monotonic
1:1 Non-monotonic
1:N Simple
1:N Complex

350
300

High-frequency sequences

300

250

250

250

200

200

200

150

150

150

100

100

100

50

50

50

0

0
1

2

3 4 5 6
Query length

7

8

1:1 Monotonic
1:1 Non-monotonic
1:N Simple
1:N Complex

350

0
1

2

3 4 5 6
Query length

7

8

1

2

3 4 5 6
Query length

7

8

(a) EnglishWelsh (en-cy) bitext
Low-frequency sequences

Medium-frequency sequences

1:1 Monotonic
1:1 Non-monotonic
1:N Simple
1:N Complex

350
300

1:1 Monotonic
1:1 Non-monotonic
1:N Simple
1:N Complex

350
300

High-frequency sequences

300

250

250

250

200

200

200

150

150

150

100

100

100

50

50

50

0

0
1

2

3 4 5 6
Query length

7

8

1:1 Monotonic
1:1 Non-monotonic
1:N Simple
1:N Complex

350

0
1

2

3 4 5 6
Query length

7

8

1

2

3 4 5 6
Query length

7

8

(b) SpanishCatalan (es-ca) bitext

Figure 5: Average time (milliseconds) needed process query two different language
pairs (en-cy es-ca).

410

fiGeneralized Biwords Bitext Compression Translation Spotting

complexities. simplest method uses biwords without shifts therefore equivalent
approaches biwords simple pairs include structural information.
methods include offsets integrate structural information alignments.
experiments show generalized biwords lead better compression ratios
reduction sequences encoding bitext compensates larger dictionaries
needed. largest reduction compression ratios obtained pairs divergent
languages because, cases, biwords without shifts cannot tackle frequent word
reorderings multiword translations.
Since enhanced variability generalized biwords requires larger dictionaries
increase header included compressed files, tested effect splitting
infrequent biwords smaller, frequent biwords. reduces number different
biwords allows 2lcab compressor obtain lower compression ratios.
pruning, 2lcab provides best results biwords obtained one-to-many word
alignments simple shifts allowed, is, target text split
segments contiguous words. algorithms, Tre 2lcab, provide better
compression ratios general purpose compressors, particularly case pairs
languages share common language family (es-ca) bitexts highly parallel
(en-cy). compression ratio therefore used indirectly measure quality
word alignment degree parallelism bitext.
modifications made 2lcab compressors allow compressed bitext
searched efficiently, although adaptation leads slightly worse compression ratios.
However, new compressed file includes alignments words bitext
additional information needed order implement translation spotting.
relatively small difference time needed process query 1:1 Monotonic
method (the fastest one) 1:N Complex method (the one conveying information) makes latter preferable choice translation spotting identifies
larger variety translations bitext provides richer examples.
future work plan study effect translation performance integration generalized, biword-based bilingual language models current state-of-the-art
statistical machine translation systems.

Appendix A. Biword Extraction Algorithm
Algorithm 1 shows procedure used obtain sequence generalized biwords B
bitext one-to-many word alignments. main loop (lines 325) iterates
words left right texts still words sides considered.
Variables n point next left right words, respectively, processed.
Inside main loop, set
positions right words aligned left

word lm , set positions left words aligned right word
rn first computed. word alignments one-to-many,
n contains, most, one
element.
every iteration, single biword produced.
empty, i.e., lm aligned,
next biword consists left word lm , empty sequence right words empty

sequence offsets (line 7).
empty is, biword consists empty
word, sequence right words containing rn sequence offsets containing
411

fiSanchez-Martnez, Carrasco, Martnez-Prieto & Adiego

Algorithm 1 GetBiwords extracts biword sequence one-to-many word alignment two texts.
Input: Two word sequences L R, one-to-many bigraph G = {L, R, A}
Output: sequence B 3-tuples (word, sequence words, sequence offsets)
1: B ()
. Create empty sequence 3-tuples
2: 1; n 1
3: (m ) (n N )
4:

{j : (lm , rj ) A}
5:

n {i : (li , rn ) A}
6:

=
7:
add (lm , (), ()) B
8:
mm+1
9:
else
n =
10:
add (, (rn ), (0)) B
11:
n NextRight(m, n, G)
12:
else
13:
(); ()
. Create empty sequences words offsets
14:
kn
15:
j
ascending order
16:
add rj ; add j k
17:
k j+1
18:
n = j
19:
n NextRight(m, n, A)
20:
end
21:
end
22:
add (lm , , ) B
23:
mm+1
24:
end
25: end
26:
27:
add (lm , (), ()) B
28:
mm+1
29: end
30: n N
31:

n {i : (li , rn ) A}
32:

n =
33:
add (, (rn ), (0)) B
34:
end
35:
nn+1
36: end
37: return B

412

fiGeneralized Biwords Bitext Compression Translation Spotting

Algorithm 2 NextRight
Input: Integers n, one-to-many bigraph G = (L, R, A)
Output: Index next right word paired , lm posterior word L
1: repeat
2:
nn+1
3:

n {i : (li , rn ) A}

4: (n > N ) (A
n = ) (min(An ) m)
5: return n

null offset (line 10). Otherwise, biword consists lm , sequence containing
right words aligned lm , sequence containing one offset right word.
first offset relative n, whereas following ones relative previous word
sequence (see lines 1521).
Index simply incremented every time biword containing left word produced.
update n subtle since words positions greater n may
already processed aligned left word preceding lm . n therefore
assigned value returned function NextRight (depicted Algorithm 2) which, given
current values n, looks next n rm paired either
empty word left word preceding lm .
Finally, two loops take care words remain unprocessed main loop.

Appendix B. Bitext Restoration Algorithm
Algorithm 3 provides pseudo-code restore right text bitext
biword representation obtained Algorithm 1. Restoring left text straightforward since biwords sorted left component.
main loop Algorithm 3 (lines 315) iterates sequence biwords representing bitext. Variables n point next biword processed,
next gap R filled word, respectively. iterates array
offsets = (w1 , . . . , w|| ) (lines 710) places word j sequence right
words = (1 , . . . , || ) right place. biword processed,
updated point next biword, n point next gap R filled
(lines 1214).

Acknowledgments
work supported Spanish Government projects TIN2009-14009C02-01 TIN2009-14009-C02-02, Millennium Institute Cell Dynamics
Biotechnology (grant ICM P05-001-F). development work reported
paper, Miguel A. Martnez-Prieto Department Computer Science (University
Chile) post-doctoral stay. authors thanks Nieves R. Brisaboa ideas
cooperation development initial version 2lcab, Gonzalo Navarro
inspiration Tre compression approach, anonymous referees suggesting
significant improvements paper Francis M. Tyers proof-reading it.
413

fiSanchez-Martnez, Carrasco, Martnez-Prieto & Adiego

Algorithm 3 GetRightText retrieves right text biword representation
bitext.
Input: sequence biwords B = (1 , . . . , )
Output: right text R = r1 r2 rN contained sequence B.
1: 1
2: n 1
3:
4:
k =n1
5:
offset(m )
6:
right(m )
7:
j = 1, . . . , ||
8:
k k + j + 1
9:
rk j
10:
end
11:
mm+1
12:
rn undefined
13:
nn+1
14:
end
15: end
16: return R

References
Adiego, J., Brisaboa, N. R., Martnez-Prieto, M. A., & Sanchez-Martnez, F. (2009).
two-level structure compressing aligned bitexts. Proceedings 16th String
Processing Information Retrieval Symposium, Vol. 5721 Lecture Notes Computer Science, pp. 114121, Saariselka, Finland. Springer.
Adiego, J., & de la Fuente, P. (2006). Mapping words codewords PPM. Proceedings
13th String Processing Information Retrieval Symposium, Vol. 4209
Lecture Notes Computer Science, pp. 181192, Glasgow, UK. Springer.
Adiego, J., Martnez-Prieto, M. A., Hoyos-Torio, J. E., & Sanchez-Martnez, F. (2010).
Modelling parallel texts boosting compression. Proceedings 2010 Data
Compression Conference, p. 517, Snowbird, USA.
Arnold, D., Balkan, L., Meijer, S., Humphreys, R., & Sadler, L. (1994). Machine translation:
introductory guide. NCC Blackwell, Oxford.
Barlow, M. (2004). Parallel concordancing translation. Proceedings ASLIB Translating Computer 26, London, UK.
Bell, T. C., Cleary, J. G., & Witten, I. H. (1990). Text compression. Prentice Hall.
Bourdaillet, J., Huet, S., Langlais, P., & Lapalme, G. (2010). TransSearch: bilingual concordancer translation finder. Machine Translation, 23 (34), 241271.
Published 2011.
Bowker, L., & Barlow, M. (2004). Bilingual concordancers translation memories:
comparative evaluation. Proceedings Second International Workshop
414

fiGeneralized Biwords Bitext Compression Translation Spotting

Language Resources Translation Work, Research Training Coling 2004, pp.
7079, Geneva, Switzerland.
Boyer, R., & Moore, J. S. (1977). fast string searching algorithm. Communications
ACM, 20 (10), 762772.
Brisaboa, N., Ladra, S., & Navarro, G. (2009). Directly addressable variable-length codes.
Proceedings 16th String Processing Information Retrieval Symposium,
Vol. 5721 Lecture Notes Computer Science, pp. 122130, Saariselka, Finland.
Springer.
Brisaboa, N. R., Farina, A., Navarro, G., & Parama, J. R. (2007). Lightweight natural
language text compression. Information Retrieval, 10 (1), 133.
Brown, P., Lai, J., & Mercer, R. (1991). Aligning sentences parallel corpora. Proceedings 29th Annual Meeting Association Computational Linguistics, pp.
169176, Berkeley, CA, USA.
Brown, P. F., Cocke, J., Pietra, S. A. D., Pietra, V. J. D., Jelinek, F., Lafferty, J. D.,
Mercer, R. L., & Roossin, P. S. (1990). statistical approach machine translation.
Computational Linguistics, 16 (2), 7685.
Brown, P. F., Pietra, S. A. D., Pietra, V. J. D., & Mercer, R. L. (1993). mathematics
statistical machine translation: Parameter estimation. Computational Linguistics,
19 (2), 263311.
Burrows, M., & Wheeler, D. (1994). block sorting lossless data compression algorithm.
Tech. rep. 124, Digital Systems Research Center, Palo Alto, CA, USA.
Callison-Burch, C., Bannard, C., & Schroeder, J. (2005a). compact data structure
searchable translation memories. Proceedings 10th European Association
Machine Translation Conference, pp. 5965, Budapest, Hungary.
Callison-Burch, C., Bannard, C., & Schroeder, J. (2005b). Scaling phrase-based statistical
machine translation larger corpora longer phrases. Proceedings 43rd
Annual Meeting Association Computational Linguistics, pp. 255262, Ann
Arbor, USA.
Carl, M., & Way, A. (Eds.). (2003). Recent Advances Example-Based Machine Translation, Vol. 21 Text, Speech Language Technology. Springer.
Carroll, J. (2003). Oxford Handbook Computational Linguistics, chap. 12 Parsing,
pp. 233248. Oxford University Press.
Casacuberta, F., & Vidal, E. (2004). Machine translation inferred stochastic finite-state
transducers. Computational Linguistics, 30 (2), 205225.
Clark, D. (1996). Compact PAT trees. Ph.D. thesis, University Waterloo, Warteloo, ON,
Canada.
Cleary, J. G., & Witten, I. H. (1984). Data compression using adaptive coding partial
string matching. IEEE Transactions Communications, 32 (4), 396402.
Conley, E., & Klein, S. (2008). Using alignment multilingual text compression. International Journal Foundations Computer Science, 19 (1), 89101.
415

fiSanchez-Martnez, Carrasco, Martnez-Prieto & Adiego

Cover, T. M., & Thomas, J. A. (1991). Elements Information Theory. Wiley.
Gale, W. A., & Church, K. W. (1993). program aligning sentences bilingual corpora.
Computational Linguistics, 19 (1), 75102.
Gonzalez, R., Grabowski, S., Makinen, V., & Navarro, G. (2005). Practical implementation
rank select queries. Proceedings 4th International Workshop
Efficient Experimental Algorithms, pp. 2738, Santorini Island, Greece.
Grossman, D. A., & Frieder, O. (2004). Information Retrieval: Algorithms Heuristics
(2nd edition)., Vol. 15 Information Retrieval Series. Springer.
Hasan, S., Ganitkevitch, J., Ney, H., & Andres-Ferrer, J. (2008). Triplet lexicon models
statistical machine translation. Proceedings 2008 Conference Empirical
Methods Natural Language Processing, pp. 372381, Honolulu, USA.
Horspool, R. N. (1980). Practical fast searching strings. Software: Practice Experience, 10 (6), 501506.
Howard, P., & Vitter, J. (1992). Practical implementations arithmetic coding. Storer,
J. (Ed.), Image Text Compression, pp. 85112. Kluwer Academic.
Huffman, D. (1952). method construction minimum-redundancy codes. Proceedings Institute Radio Engineers, 40 (9), 10981101.
Ide, N., & Veronis, J. (1998). Word sense disambiguation: state art. Computational Linguistics, 24 (1), 141.
Jones, D., & Eisele, A. (2006). Phrase-based statistical machine translation English
Welsh. Proceedings 5th SALTMIL Workshop Minority Languages
5th International Conference Language Resources Evaluation, pp. 7577,
Genoa, Italy.
Knuth, D. E., Morris, J. H., & Pratt, V. (1977). Fast pattern matching strings. SIAM
Journal Computing, 6 (2), 323350.
Koehn, P. (2005). Europarl: parallel corpus statistical machine translation. Proceedings Tenth Machine Translation Summit, pp. 7986, Phuket, Thailand.
Koehn, P. (2010). Statistical Machine Translation. Cambridge University Press.
Lopez, A. (2007). Hierarchical phrase-based translation suffix arrays. Proceedings
2007 Joint Conference Empirical Methods Natural Language Processing
Computational Natural Language Learning, pp. 976985, Prague, Czech Republic.
Lopez, A. (2008). Statistical machine translation. ACM Computing Surveys, 40 (3), 149.
Manber, U., & Myers, G. (1993). Suffix arrays: new method on-line string searches.
SIAM Journal Computing, 22 (5), 935948.
Manning, C. D., & Schutze, H. (1999). Foundations statistical natural language processing.
MIT Press.
Marino, J., Banchs, R. E., Crego, J. M., de Gispert, A., Lambert, P., Fonollosa, J. A. R.,
& Costa-Jussa, M. R. (2006). N-gram-based machine translation. Computational
Linguistics, 32 (4), 527549.
416

fiGeneralized Biwords Bitext Compression Translation Spotting

Martin, G. (1979). Range encoding: algorithm removing redundancy digitized
message. Proceedings Video Data Recording Conference, Southampton, UK.
Martnez-Prieto, M. A., Adiego, J., Sanchez-Martnez, F., de la Fuente, P., & Carrasco,
R. C. (2009). use word alignments enhance bitext compression.
Proceedings 2009 Data Compression Conference, p. 459, Snowbird, USA.
Matusov, E., Zens, R., Vilar, D., Mauser, A., Popovic, M., Hasan, S., & Ney, H. (2006).
RWTH machine translation system. Proceedings TC-STAR Workshop
Speech-to-Speech Translation, pp. 3136, Barcelona, Spain.
Melamed, I. D. (2001). Emplirical methods exploting parallel texts. MIT Press.
Mihalcea, R., & Simard, M. (2005). Parallel texts. Natural Language Engineering, 11 (3),
239246.
Moffat, A. (1989). Word-based text compression. Software: Practice Experience, 19 (2),
185198.
Moffat, A., & Isal, R. Y. K. (2005). Word-based text compression using Burrows-Wheeler
transform. Information Processing Management, 41 (5), 11751192.
Moffat, A., & Turpin, A. (1997). implementation minimum redundancy prefix
codes. IEEE Transactions Communications, 45 (10), 12001207.
Navarro, G., & Makinen, V. (2007). Compressed full-text indexes. ACM Computing Surveys,
39 (1). Article 2.
Navarro, G., & Raffinot, M. (2002). Flexible Pattern Matching String: Practical on-line
search algorithms texts biological sequences. Cambridge University Press.
Nevill-Manning, C., & Bell, T. (1992). Compression parallel texts. Information Processing
& Management, 28 (6), 781794.
Niehues, J., Herrmann, T., Vogel, S., & Waibel, A. (2011). Wider context using bilingual language models machine translation. Proceedings 6th Workshop
Statistical Machine Translation, pp. 198206, Edinburgh, UK.
Och, F. J., & Ney, H. (2003). systematic comparison various statistical alignment
models. Computational Linguistics, 29 (1), 1951.
Raman, R., Raman, V., & Rao, S. (2002). Succinct indexable dictionaries applications
encoding k-ary trees multisets. Proceedings 22nd Annual ACM-SIAM
Symposium Discrete Algorithms, pp. 233242, San Francisco, CA, USA.
Salomon, D. (2007). Data compression. complete reference (Fourth edition). Springer.
Shkarin, D. (2002). PPM: One step practicality. Proceeding 2002 Data Compression Conference, pp. 202211, Snowbird, USA.
Simard, M. (2003). Translation spotting translation memories. Proceedings NAACL
2003 Workshop Building Using Parallel Texts: Data Driven Machine Translation Beyond, pp. 6572, Edmonton, AB, Canada.
Suel, T., & Memon, N. (2003). Algorithms delta compression remote file synchronization. Sayood, K. (Ed.), Lossless Compression Handbook, pp. 269290. Academic
Press.
417

fiSanchez-Martnez, Carrasco, Martnez-Prieto & Adiego

Tufis, D., Barbu, A.-M., & Ion, R. (2004). Extracting multilingual lexicons parallel
corpora. Computers Humanities, 38 (2), 163189.
Turpin, A., & Moffat, A. (2000). Housekeeping prefix coding. IEEE Transactions
Communications, 48 (4), 622628.
Veronis, J., & Langlais, P. (2000). Parallel text processing. Alignment use translation corpora, chap. Evaluation Parallel Text Alignment Systems ARCADE
Project. Kluwer Academic Publishers.
Vogel, S., Ney, H., & Tillmann, C. (1996). HMM-based word alignment statistical translation. Proceedings 16th International Conference Computational Linguistics, pp. 836841, Copenhagen, Denmark.
Ziv, J., & Lempel, A. (1977). universal algorithm sequential data compression. IEEE
Transactions Information Theory, 23 (3), 337343.
Ziviani, N., Moura, E., Navarro, G., & Baeza-Yates, R. (2000). Compression: key
next-generation text retrieval systems. IEEE Computer, 33 (11), 3744.

418

fiJournal Artificial Intelligence Research 43 (2012) 571-620

Submitted 09/11; published 04/12

Reformulating Situation Calculus Event
Calculus General Theory Stable Models
Answer Set Programming

Joohyung Lee
Ravi Palla

joolee@asu.edu
Ravi.Palla@asu.edu

School Computing, Informatics,
Decision Systems Engineering
Arizona State University
Tempe, AZ 85287, USA

Abstract
Circumscription logic programs stable model semantics two wellknown nonmonotonic formalisms. former served basis classical logic based
action formalisms, situation calculus, event calculus temporal action
logics; latter served basis family action languages, language
several descendants. Based discovery circumscription stable
model semantics coincide class canonical formulas, reformulate situation
calculus event calculus general theory stable models. also present
translation turns reformulations answer set programs, efficient
answer set solvers applied compute situation calculus event calculus.

1. Introduction
Circumscription (McCarthy, 1980, 1986) logic programs stable model semantics (Gelfond & Lifschitz, 1988) two well-known nonmonotonic formalisms. one
oldest nonmonotonic formalisms, circumscription found many applications commonsense reasoning model-based diagnoses (e.g., McCarthy, 1986; Shanahan, 1995; Besnard
& Cordier, 1994). stable model semantics mathematical basis Answer Set Programming (ASP) (Marek & Truszczynski, 1999; Niemela, 1999; Lifschitz, 2008),
widely applied thanks availability several efficient implementations, known
answer set solvers.
two nonmonotonic formalisms applied overlapping classes
problems, minimal model reasoning ensured circumscription coincide stable
model reasoning. Moreover, formalisms different roots. circumscription
defined terms translation classical (second-order) logic, stable models proposed
Gelfond Lifschitz (1988) defined terms grounding fixpoints
style Reiters default logic (Reiter, 1980). differences part account fact
two formalisms formed rather disparate traditions knowledge representation
research. particular, area temporal reasoning, former served basis
classical logic based action calculi, situation calculus (McCarthy & Hayes, 1969;
Reiter, 2001), event calculus (Shanahan, 1995) temporal action logics (Doherty,
c
2012
AI Access Foundation. rights reserved.

fiLee & Palla

Gustafsson, Karlsson, & Kvarnstrom, 1998), whereas latter served basis
family action languages, language (Gelfond & Lifschitz, 1998) several
descendants translated logic programs stable model semantics.
However, recent generalization stable model semantics shed new light
relationship circumscription stable models. first-order stable model semantics defined Ferraris, Lee Lifschitz (2007, 2011) characterizes stable models
first-order sentence models (in sense first-order logic) sentence
satisfy stability condition, expressed second-order formula similar
one used define circumscription. Since logic programs viewed special
class first-order sentences stable model semantics, definition extends
stable model semantics Gelfond Lifschitz (1988) full first-order level without
limiting attention Herbrand models. Essentially characterization independently given Lin Zhou (2011), via logic knowledge justified assumption (Lin
& Shoham, 1992). definitions also equivalent definition Quantified Equilibrium Logic given Pearce Valverde (2005), defined terms logic
Here-and-There (Heyting, 1930).
new definition stable model motivates us investigate relationship
stable model reasoning minimal model reasoning. particular, focus
relationship area temporal reasoning. show situation calculus
event calculus reformulated first-order stable model semantics,
ASP. theoretically interesting, also practically useful allows us
leverage efficient answer set solvers computing circumscriptive action theories.
this, develop two technical results. First, show circumscription
first-order stable model semantics coincide class canonical formulas.
largest syntactic class identified far two semantics coincide, general
enough cover several circumscriptive action formalisms, situation calculus,
event calculus, temporal action logics. result allows us reformulate
action formalisms first-order stable model semantics. minimal model reasoning
sometimes leads unintuitive results, circumscriptive action formalisms carefully
designed avoid cases, result implies minimal model reasoning
action formalisms also viewed stable model reasoning.
Second, identify class almost universal formulas, turned
syntax logic program preserving stable models. turns reformulations situation calculus event calculus first-order stable model
semantics fall class formulas. introduce system f2lp turns formulas
class logic programs, and, conjunction result canonical formulas, use
combination f2lp answer set solvers compute situation calculus
event calculus.
work makes explicit relationship classical logic logic program traditions temporal reasoning. Interestingly, development event calculus
spanned traditions. original version event calculus (Kowalski & Sergot, 1986) formulated logic programs, stable model semantics (that
time invention stable model semantics). extensive developments later carried classical logic foundation via circumscription (e.g.,
Shanahan, 1995, 1997, 1999; Miller & Shanahan, 1999; Mueller, 2004), relation
572

fiReformulating Situation Calculus Event Calculus

logic program formulation remained implicit. Based reduction circumscription completion, SAT-based event calculus systems implemented, one Shanahan
Witkowski (2004) another Mueller (2004). latter system called dec
reasoner,1 outperforms former thanks efficient general compilation
method propositional logic. system handles large fragment event
calculus, still cannot handle recursive disjunctive axioms since completion cannot
applied axioms. ASP-based approach hand handle
full version event calculus assumption domain given finite.
Thanks efficiency ASP solvers, experiments indicate ASP-based event
calculus reasoner significantly faster dec reasoner (Appendix B).
Similar logic programming tradition event calculus, situation calculus (McCarthy & Hayes, 1969; Reiter, 2001) implemented Prolog, based
fact Clarks completion semantics accounts definitional axioms. unlike
event calculus, best knowledge, efficient propositional solvers
applied directly compute models situation calculus theories. paper,
reformulate Lins causal action theories (1995) Reiters basic action theories (2001)
first-order stable model semantics ASP. basic action theories, also provide
ASP-based encoding method obtains Reiters successor state axioms effect
axioms generic inertia axioms adopted ASP, idea close Reiters
frame default (1980).
paper organized follows. next section reviews definitions circumscription first-order stable model semantics, presents definition
canonical formula. Based this, Sections 3 4 reformulate event calculus
situation calculus first-order stable model semantics. Section 5 shows translation
turns almost universal formulas logic programs accepted ASP
solvers. Sections 6 7 use result turn reformulations event calculus
situation calculus given Sections 3 4 input language ASP solvers.
Complete proofs given Appendix C.

2. Circumscription First-Order Stable Model Semantics
assume following set primitive propositional connectives quantifiers:
(falsity), , , , , .
understand F abbreviation F ; symbol > stands , F G
stands (F G) (G F ).
2.1 Review: Circumscription
Let p list distinct predicate constants p1 , . . . , pn , let u list distinct
predicate variables u1 , . . . , un . u p denote conjunction formulas
x(ui (x) pi (x)) = 1, . . . n, x list distinct object variables whose
length arity pi . Expression u < p stands (u p) (p u).
1. http://decreasoner.sourceforge.net

573

fiLee & Palla

instance, p q unary predicate constants (u, v) < (p, q)


x(u(x) p(x)) x(v(x) q(x)) x(p(x) u(x)) x(q(x) v(x)) .
Circumscription defined terms CIRC operator minimized predicates.
first-order formula F , expression CIRC[F ; p] stands second-order formula
F u((u < p) F (u)),
F (u) formula obtained F substituting ui pi . F sentence
(i.e., formula free variables), intuitively, models CIRC[F ; p] models
F minimal p.
definition straightforwardly extended case F many-sorted firstorder formula (Lifschitz, 1994, Section 2.4), language event calculus
situation calculus based on.
2.2 Review: First-Order Stable Model Semantics
review follows definition Ferraris et al. (2011). There, stable models
defined terms SM operator, whose definition similar CIRC operator
previous section. first-order formula F finite list predicate constants
p = (p1 , . . . , pn ), formula SM[F ; p] defined
F u((u < p) F (u)),
u defined CIRC[F ; p], F (u) defined recursively follows:
pi (t) = ui (t) list terms;
F = F atomic formula F (including equality) contain
members p;
(F G) = F G ;
(F G) = F G ;
(F G) = (F G ) (F G);
(xF ) = xF ;
(xF ) = xF .
predicates p called intensional: predicates intend
characterize F terms non-intensional predicates.2 F sentence, models
second-order sentence SM[F ; p] called p-stable models F :
models F stable p. often simply write SM[F ] place SM[F ; p]
p list predicate constants occurring F . According Lee, Lifschitz,
2. Intensional predicates analogous output predicates Datalog, non-intensional predicates
analogous input predicates Datalog (Lifschitz, 2011).

574

fiReformulating Situation Calculus Event Calculus

Palla (2008), answer sets defined special class stable models follows. (F )
denote signature consisting object, function predicate constants occurring
F . F contains least one object constant, Herbrand interpretation (F )
satisfies SM[F ] called answer set F . answer sets logic program defined
answer sets FOL-representation (i.e., conjunction universal
closures implications corresponding rules). example, FOL-representation
program
p(a)
q(b)
r(x) p(x), q(x)

p(a) q(b) x(p(x) q(x) r(x))

(1)

SM[F ]
p(a) q(b) x(p(x) q(x) r(x))
uvw(((u, v, w) < (p, q, r)) u(a) v(b)
x((u(x) (v(x) q(x)) w(x)) (p(x) q(x) r(x)))),
equivalent first-order sentence
x(p(x) x = a) x(q(x) x = b) x(r(x) (p(x) q(x)))

(2)

(Ferraris et al., 2007, Example 3). stable models F first-order models (2).
answer set F Herbrand model {p(a), q(b), r(a)}.
According Ferraris et al. (2011), definition answer set, applied
syntax logic programs, equivalent traditional definition answer set
based grounding fixpoints (Gelfond & Lifschitz, 1988).
Note definition stable model general definition
answer set following ways: stable models restricted Herbrand models,
underlying signature arbitrary, intensional predicates fixed
list predicate constants occurring formula. last fact essential view
following proposition. pr (F ) denote list predicate constants occurring
F ; Choice(p) denote conjunction choice formulas x(p(x) p(x))
predicate constants p p, x list distinct object variables; False(p)
denote conjunction xp(x) predicate constants p p. sometimes identify
list corresponding set confusion.
Proposition 1 Formula
SM[F ; p] SM[F Choice(pr (F )\p) False(p\pr (F ))]

(3)

logically valid.
Notice (implicit) intensional predicates right-hand side (3)
(pr (F ) p). Choice formula makes predicates (pr (F ) \ p) exempt
stability checking. hand, False formula makes predicates
(p \ pr (F )) stabilized (i.e., empty extents), though occur F .
575

fiLee & Palla

Ferraris et al. (2011) incorporate strong negation stable model semantics
distinguishing intensional predicates two kinds, positive negative.
negative intensional predicate form p, p positive intensional predicate
symbol strong negation. Syntactically logical connective,
appear part predicate constant. interpretation underlying
signature coherent satisfies formula
x(p(x) p(x)),

(4)

x list distinct object variables, negative predicate p. usually
consider coherent interpretations only. Intuitively, p(t) represents p(t) false.
different p(t) represents known p(t) true. Similarly,
p(t) represents known p(t) false, p(t) represents
known p(t) known true. Note that, unlike first-order logic, p(t)
different p(t). instance, formula p(a) one answer set {p(a)} p(a)
answer sets.
Like extension circumscription many-sorted first-order sentences, definition
stable model straightforwardly extended many-sorted first-order sentences.
2.3 Equivalence Stable Model Semantics Circumscription
Canonical Formulas
Neither stable model semantics circumscription stronger other.
example,
CIRC[x(p(x) p(x)); p]
(5)
equivalent xp(x),
SM[x(p(x) p(x)); p]

(6)

equivalent >, (5) stronger (6). hand,
CIRC[x(p(x) q(x)); p, q]

(7)

equivalent x(p(x) q(x)),
SM[x(p(x) q(x)); p, q]

(8)

equivalent x(p(x) q(x)), (8) stronger (7).
section, show two semantics coincide class formulas called
canonical formulas, define below. first review notions positive, negative,
strictly positive occurrences.
Definition 1 say occurrence predicate constant, subexpression, formula F positive number implications containing occurrence
antecedent even, negative otherwise. (Recall treat G shorthand
G .) say occurrence strictly positive number implications F
containing occurrence antecedent 0.
576

fiReformulating Situation Calculus Event Calculus

example, (1), occurrences q positive, first one strictly
positive.
Definition 2 say formula F canonical relative list p predicate constants

occurrence predicate constant p antecedents one
implication F ,
every occurrence predicate constant p scope strictly positive
occurrence F strictly positive F .
Example 1 formula
x(p(x) q(x))

(9)

shown canonical relative {p, q} since satisfy first clause
definition (p occurs antecedents two implications p(x) shorthand
p(x) ). hand, formula canonical relative {q}. formula
x(p(x) p(x))

(10)

canonical relative {p} since satisfy second clause (the second occurrence p scope strictly positive occurrence , strictly positive
(10)); formula
p(a) (x p(x) x q(x))
(11)
canonical relative {p, q},
p(a, a) x(p(x, a) p(b, x))

(12)

canonical relative {p, q} since satisfy second clause (the second
occurrence p scope strictly positive occurrence , strictly
positive formula (12)).
following theorem states that, canonical formula, circumscription coincides
stable model semantics.
Theorem 1 canonical formula F relative p,
CIRC[F ; p] SM[F ; p]

(13)

logically valid.
instance, formula (11), canonical relative {p, q}, formulas CIRC[(11); p, q]
SM[(11); p, q] equivalent other. Also, sentence F clearly canonical
relative , CIRC[F ; ] equivalent SM[F ; ], turn equivalent F .
hand, equivalence may necessarily hold non-canonical formulas.
instance, observed that, formula (10) canonical relative {p}, formulas (5) (6) equivalent other. formula (9) canonical
577

fiLee & Palla

relative {p, q}, formulas (7) (8) equivalent other. also observe
formula (12) canonical relative {p, q}, CIRC[(12); p, q] equivalent
SM[(12); p, q]: Herbrand interpretation {p(a, a), p(b, a)} satisfies SM[(12); p, q],
satisfy CIRC[(12); p, q].
Note non-canonical formulas often equivalently rewritten canonical formulas. Since equivalent transformation preserves models circumscription, Theorem 1 applied non-canonical formulas, first rewriting canonical
formulas. example, formula (9) equivalent
x(p(x) q(x)),

(14)

canonical relative {p, q}, CIRC[(9); p, q] equivalent SM[(14); p, q].
another example, formula (10) equivalent
x(p(x) p(x)),

(15)

canonical relative {p}, CIRC[(10); p] equivalent SM[(15); p].
clear treatment applied quantifier-free formula (including
propositional formula) quantifier-free formula equivalently rewritten
canonical formula first rewriting clausal normal form turning
clause form C D, C conjunction atoms disjunction
atoms.3
Sections 3 4 use Theorem 1 reformulate event calculus situation
calculus first-order stable model semantics.

3. Reformulating Event Calculus General Theory Stable
Models
section, review syntax circumscriptive event calculus described Chapter 2
book Mueller (2006). Based observation syntax conforms
condition canonicality, present reformulations event calculus general
theory stable models.
3.1 Review: Circumscriptive Event Calculus
assume many-sorted first-order language, contains event sort, fluent sort,
timepoint sort. fluent term term whose sort fluent; event term
timepoint term defined similarly.
Definition 3 condition defined recursively follows:
1 2 terms, comparisons 1 < 2 , 1 2 , 1 2 , 1 > 2 , 1 = 2 ,
1 6= 2 conditions;
3. appears unlikely knowledge encoded non-canonical formula (12)
cannot easily turned equivalent canonical formula. c.f. Guide Axiomatizing Domains
First-Order Logic (http://cs.nyu.edu/faculty/davise/guide.html). surprise
circumscriptive action theories mentioned paper satisfy canonicality assumption.

578

fiReformulating Situation Calculus Event Calculus

f fluent term timepoint term, HoldsAt(f, t) HoldsAt(f, t)
conditions;
1 2 conditions, 1 2 1 2 conditions;
v variable condition, v condition.
use e ei denote event terms, f fi denote fluent terms, ti
denote timepoint terms, denote conditions.
event calculus, circumscribe Initiates, Terminates, Releases minimize
unexpected effects events, circumscribe Happens minimize unexpected events,
circumscribe Ab (abnormality predicates) minimize abnormalities. Formally, event
calculus description circumscriptive theory defined
CIRC[ ; Initiates, Terminates, Releases] CIRC[ ; Happens]
CIRC[ ; Ab 1 , . . . , Ab n ] ,

(16)


conjunction universal closures axioms form
Initiates(e, f, t)
Terminates(e, f, t)
Releases(e, f, t)
1 (e, f1 , t) 2 (e, f2 , t)
(effect constraint)
[]Happens(e1 , t) []Happens(en , t) Initiates(e, f, t)
[]Happens(e1 , t) []Happens(en , t) Terminates(e, f, t),
1 2 either Initiates Terminates ([] means
optional);
conjunction universal closures temporal ordering formulas (comparisons
timepoint terms) axioms form
Happens(e, t)
(f, t) 1 (f1 , t) n (fn , t) Happens(e, t)
(causal constraints)
Happens(e, t) Happens(e1 , t) Happens(en , t) (disjunctive event axiom),
Started Stopped j (1 j n) either Initiated
Terminated ;
conjunction universal closures cancellation axioms form
Abi (..., t) ;
conjunction first-order sentences (outside scope CIRC) including unique
name axioms, state constraints, event occurrence constraints, set domainindependent axioms event calculus, EC (for continuous event calculus) DEC (for discrete event calculus) (Mueller, 2006, Chapter 2). also
579

fiLee & Palla

includes following definitions predicates used causal constraints :
def

Started (f, t) (HoldsAt(f, t) e(Happens(e, t) Initiates(e, f, t)))

(CC1 )

def

Stopped (f, t) (HoldsAt(f, t) e(Happens(e, t) Terminates(e, f, t)))
def

Initiated (f, t) (Started (f, t) e(Happens(e, t) Terminates(e, f, t)))
def

Terminated (f, t) (Stopped (f, t) e(Happens(e, t) Initiates(e, f, t)))

(CC2 )
(CC3 )
(CC4 ).

Remark 1 following facts easy check:
canonical relative {Initiates, Terminates, Releases};
canonical relative {Happens};
canonical relative {Ab 1 , . . . , Ab n }.
facts used next section reformulate event calculus general
theory stable models.
3.2 Reformulating Event Calculus General Theory Stable Models
Following Ferraris, Lee, Lifschitz, Palla (2009), formula F say
negative list p predicate constants members p strictly positive
occurrences F .4 example, formula (9) negative {p}, negative {p, q}.
formula form F (shorthand F ) negative list predicates.
assume already equivalently rewritten negative {Initiates,
Terminates, Releases, Happens, Ab 1 , . . . , Ab n }. easily done prepending
strictly positive occurrences predicates. following theorem shows
equivalent reformulations circumscriptive event calculus general theory stable
models.
Theorem 2 event calculus description (16), following theories equivalent
other:5
(a) CIRC[; I, T, R] CIRC[; H] CIRC[; Ab 1 , . . . , Ab n ] ;
(b) SM[; I, T, R] SM[; H] SM[; Ab 1 , . . . , Ab n ] ;
(c) SM[ ; I, T, R, H, Ab 1 , . . . , Ab n ] ;
(d) SM[ Choice(pr ( ) \ {I, T, R, H, Ab 1 , . . . , Ab n })] .
equivalence (a) (b) immediate Theorem 1. equivalence
(b) (c) shown using splitting theorem Ferraris et al. (2009).
assumption negative intensional predicates essential showing
4. Note distinguish formula negative (on p) occurrence negative
(Section 2.3).
5. brevity, abbreviate names circumscribed predicates.

580

fiReformulating Situation Calculus Event Calculus

equivalence (For details, see proof Appendix C.4.). equivalence
(c) (d) follows Proposition 1 since
{I, T, R, H, Ab 1 , . . . , Ab n } \ pr ( )
empty set.6

4. Reformulating Situation Calculus General Theory Stable
Models
section, review reformulate two versions situation calculusLins
causal action theories (1995) Reiters basic action theories (2001).
4.1 Review: Lins Causal Action Theories
assume many-sorted first-order language contains situation sort, action
sort, fluent sort, truth value sort object sort. understand expression P (x, s),
P fluent name, shorthand Holds(P (x), s). consider functional
fluents simplicity.
According Lin (1995), formula (s) called simple state formula (s)
mention Poss, Caused situation term possibly variable s.
assume causal action theory consists finite number following
sets axioms. often identify conjunction universal closures
axioms D. following, F , Fi fluent names, action name, V , Vi truth
values, s, s0 situation variables, (s) simple state formula s, symbols a, a0
action variables, f variable sort fluent, v variable sort truth value, x,
xi , y, yi lists variables.
Dcaused conjunction axioms form
Poss(A(x), s) ((s) Caused (F (y), V, do(A(x), s))
(direct effect axioms),
(s) Caused (F1 (x1 ), V1 , s) Caused (Fn (xn ), Vn , s) Caused (F (x), V, s)
(indirect effect axioms).
Dposs conjunction precondition axioms form
Poss(A(x), s) (s).

(17)

Drest conjunction following axioms:
basic axioms:
Caused (f, true, s) Holds(f, s),
Caused (f, false, s) Holds(f, s),
true 6= false v(v = true v = false).
6. I, , R, H occur domain independent axioms part .

581

(18)

fiLee & Palla

unique name assumptions fluent names:
Fi (x) 6= Fj (y), (i 6= j)
Fi (x) = Fi (y) x = y.

(19)

Similarly action names.
foundational axioms discrete situation calculus:

7

6= do(a, s),
0

0

0

0

do(a, s) = do(a , ) (a = = ),



p p(S0 ) a, p(s) p(do(a, s)) p(s) .

(20)
(21)
(22)

frame axiom:
Poss(a, s) (vCaused (f, v, do(a, s))
(Holds(f, do(a, s)) Holds(f, s))).
Axioms domain knowledge: (s).
causal action theory defined
CIRC[Dcaused ; Caused ] Dposs Drest .

(23)

Remark 2 easy check Dcaused canonical relative Caused .
fact used next section reformulate causal action theories general
theory stable models.
4.2 Reformulating Causal Action Theories General Theory Stable
Models
Let Dposs conjunction axioms (s) Poss(A(x), s) axiom (17) Dposs .
Instead second-order axiom (22), consider following first-order formula Dsit ,
introduces new intensional predicate constant Sit whose argument sort situation.8
Sit(S0 ) a, s(Sit(s) Sit(do(a, s))) sSit(s).

(24)


following, Drest
theory obtained Drest dropping (22).

Theorem 3 Given causal action theory (23), following theories equivalent
disregard auxiliary predicate Sit:
(a) CIRC[Dcaused ; Caused ] Dposs Drest ;

(b) SM[Dcaused ; Caused ] Dposs Drest
SM[Dsit ; Sit] ;

(c) SM[Dcaused ; Caused ] SM[Dposs ; Poss] Drest
SM[Dsit ; Sit] ;

(d) SM[Dcaused Dposs Drest
Dsit ; Caused , Poss, Sit] .

7. simplicity omit two axioms regarding partial-order among situations.
8. Suggested Vladimir Lifschitz (personal communication).

582

fiReformulating Situation Calculus Event Calculus

4.3 Review: Reiters Basic Action Theories
causal action theories, understand P (x, s), P fluent name, shorthand
Holds(P (x), s), consider functional fluents.
basic action theory (BAT) form
Dss Dap Duna DS0 ,

(25)


conjunction foundational axioms (Section 4.1);
Dss conjunction successor state axioms form
F (x, do(a, s)) F (x, a, s),
F (x, a, s) formula uniform
among x, a, s;

9

whose free variables

Dap conjunction action precondition axioms form
Poss(A(x), s) (x, s),
(x, s) formula uniform whose free variables among x, s;
Duna conjunction unique name axioms fluents actions;
DS0 conjunction first-order formulas uniform S0 .
4.4 Reformulating Basic Action Theories General Theory Stable
Models
Note BAT theory first-order logic.10 view fact first-order
logic sentence F equivalent SM[F ; ], trivial view BAT first-order theory
stable model semantics list intensional predicates empty.
rest section, consider alternative encoding BAT ASP,
need provide explicit successor state axioms Dss . Instead, successor state
axioms entailed effect axioms generic inertia axioms adopted ASP
making intensional positive predicate Holds negative predicate Holds
(Recall definitions positive negative predicates Section 2.2). following
assume underlying signature contains predicates.
ASP-style BAT form
Deffect Dprecond Dinertia Dexogenous0 Duna DS0 ,

, Duna DS0 defined before;
9. refer reader book Reiter (2001) definition uniform formula.
10. simplicity disregard second-order axiom (22).

583

(26)

fiLee & Palla

Deffect conjunction axioms form
+
R
(x, a, s) Holds(R(x), do(a, s))

(27)


R
(x, a, s) Holds(R(x), do(a, s)),

(28)


+
R
(x, a, s)


R
(x, a, s)



variables among x, s;

formulas uniform whose free

Dprecond conjunction axioms form
(x, s) Poss(A(x), s),

(29)

(x, s) formula uniform whose free variables among x, s;
Dinertia conjunction axioms
Holds(R(x), s) Holds(R(x), do(a, s)) Holds(R(x), do(a, s)),
Holds(R(x), s) Holds(R(x), do(a, s)) Holds(R(x), do(a, s))
fluent names R;
Dexogenous0 conjunction
Holds(R(x), S0 ) Holds(R(x), S0 )
fluent names R.
Note axioms Dinertia typically used answer set programming represent
common sense law inertia (Lifschitz & Turner, 1999). Similarly, Dexogenous0 used
represent initial value fluent arbitrary.11
show ASP-style BAT related Reiters BAT. First, since use
strong negation, convenient define following notions. Given signature
BAT, Holds signature obtained adding Holds . say
interpretation Holds complete Holds satisfies
y(Holds(y) Holds(y)),
list distinct variables. Given interpretation Holds , expression I|
denotes projection .
Let Dss conjunction successor state axioms

Holds(R(x), do(a, s)) +
R (x, a, s) (Holds(R(x), s) R (x, a, s)),
+

+
R (x, a, s) disjunction R (x, a, s) axioms (27) Deffect , R (x, a, s)

disjunction R (x, a, s) axioms (28) Deffect . Dap denote conjunction axioms Poss(A(x), s) (x, s), (x, s) disjunction (x, s)
axioms (29) Dprecond .

11. axioms Dinertia Dexogenous0 also closely related translation C+ nonmonotonic
causal logic (Giunchiglia, Lee, Lifschitz, McCain, & Turner, 2004).

584

fiReformulating Situation Calculus Event Calculus

Theorem 4 Let theory (26) signature Holds , coherent interpretation
Holds complete Holds. satisfies

x s(+
R (x, a, s) R (x, a, s))

every fluent name R, satisfies
SM[T ; Poss, Holds, Holds]
iff I| satisfies BAT
Dss Dap Duna DS0 .

5. Translating Almost Universal Sentences Logic Programs
Theorems 24 present reformulations situation calculus event calculus
general theory stable models, may contain nested quantifiers connectives.
hand, input languages ASP solvers limited simple rule forms,
analogous clausal normal form classical logic. Although first-order formula
rewritten clausal normal form preserving satisfiability, transformations
necessarily preserve stable models. due fact notion equivalence
stronger stable model semantics (Lifschitz, Pearce, & Valverde, 2001).
Definition 4 (Ferraris et al., 2011) formula F strongly equivalent formula G if,
formula H containing F subformula (and possibly containing object, function
predicate constants occur F , G), list p distinct predicate
constants, SM[H; p] equivalent SM[H 0 ; p], H 0 obtained H replacing
occurrence F G.
words, replacing subformula another strongly equivalent subformula
change stable models whole formula. strongly equivalent theories
classically equivalent (i.e., equivalent classical logic), converse hold.
Consequently, classically equivalent transformations necessarily preserve stable models. instance, consider p p. p intensional, former stable models
latter not.
known every propositional formula rewritten logic program (Cabalar
& Ferraris, 2007; Cabalar, Pearce, & Valverde, 2005; Lee & Palla, 2007), translations extended quantifier-free formulas straightforward way (Section 5.1).
However, method work presence arbitrary quantifiers,
target formalism (logic programs), variables implicitly universally quantified.
section, present translation turns certain class sentences called
almost universal sentences logic programs preserving stable models. turns
reformulations situation calculus event calculus Sections 3
4 belong class almost universal sentences, use ASP solvers
computing them.
585

fiLee & Palla

5.1 Translating Quantifier-Free Formulas Logic Programs
Cabalar et al. (2005) define following transformation turns propositional formula stable model semantics logic program.
Left side rules:
>F G

7

{F G}

(L1)

F G

7



(L2)

F G H

7

(L3)

(F G) H K

7

(F G) H K

7

{G F H}


F H K
GH K



F H K
GH K


H F G K

F G

7

{F G}

(R1)

F >G

7



(R2)

F G H

7

(R3)

F (G H) K

7

F (G H) K

7

{G F H}


F GK
F H K


GF H K
H F G K

(L4)

(L5)

Right side rules:

(R4)
(R5)

applying transformation formula lefthand side, assume
formula already written negation normal form, negation applied
literals only, using following transformation:
Negation normal form conversion:
>

F
(F G)
(F G)
(F G)

7
7

7

7

7

7



>
F
F G
F G
F G

According Cabalar et al. (2005), successive application rewriting rules
turn propositional formula disjunctive logic program. result simply
extended turn quantifier-free formula logic program.
noted Cabalar et al. (2005), translation may involve exponential blowup
size, Theorem 1 paper shows indeed vocabulary-preserving
polynomial time algorithm convert general propositional theories stable model
semantics disjunctive logic programs. Alternatively, one use another translation
paper, linear size involves auxiliary atoms
complex.
586

fiReformulating Situation Calculus Event Calculus

5.2 Quantifier Elimination
introduce quantifier elimination method distinguishes two kinds occurrences quantifiers: singular non-singular. non-singular occurrence
quantifier easy eliminate, singular occurrence eliminated certain
syntactic condition.
Definition 5 say occurrence QxG F singular
Q , occurrence QxG positive F ,
Q , occurrence QxG negative F .
example, occurrence x q(x) singular (11), occurrence x p(x)
not.
Non-singular occurrences quantifiers eliminated view fact every
first-order sentence rewritten prenex form. prenex form conversion rules given
Section 6.3.1 Pearce Valverde (2005) preserve strong equivalence, leads
following theorem.12
Theorem 5 (Lee & Palla, 2007, Proposition 5) Every first-order formula strongly
equivalent formula prenex form.
prenex form conversion turns non-singular occurrence quantifier
outermost preserving strong equivalence. Consequently, sentence contains
singular occurrence quantifier, results used turn sentence
universal sentence set ASP rules. However, presence
singular occurrence quantifier, prenex form conversion turns occurrence
outermost , allowed logic programs. consider handle
occurrences.
Obviously, Herbrand universe finite, interested Herbrand stable
models (i.e., answer sets) only, quantified formulas rewritten multiple disjunctions
conjunctions. even need consider turning formula prenex form.
example, formula
r x(p(x) q(x))

(30)

occurring theory whose signature contains {1, . . . , n} object constants (and
function constants), replace x(p(x) q(x)) multiple disjunctions
turn resulting program nested expressions usual disjunctive program
(Lifschitz, Tang, & Turner, 1999), 2n rules generated. instance, n = 3,
12. Pearce Valverde (2005) show sentence QNc5 , monotonic basis Quantified Equilibrium
Logic, turned prenex form, result follows.

587

fiLee & Palla

resulting logic program
r,
r,
r,
r,
r,
r,
r,
r,

p(1),
p(1),
p(1),
p(1),
q(1),
q(1),
q(1),
q(1),

p(2),
p(2),
q(2),
q(2),
p(2),
p(2),
q(2),
q(2),

p(3)
q(3)
p(3)
q(3)
p(3)
q(3)
p(3)
q(3).

Also, translation modular depends underlying domain; multiple
disjunctions conjunctions need updated domain changes. importantly, method applicable theory contains function constants positive
arity, Herbrand universe infinite.
One may also consider introducing Skolem constants first-order logic, presuming
that, sentence F Skolem form F 0 , SM[F ; p] satisfiable iff SM[F 0 ; p]
satisfiable. However, idea work.13
Example 2 formula
F = (x p(x) q) x(q p(x)),
SM[F ; q] equivalent first-order sentence
(q x p(x)) x(q p(x)),
unsatisfiable (the equivalence established using Theorems 3 11 Ferraris et al., 2011). Formula F strongly equivalent prenex form

xy (p(x) q) (q p(y)) ,

(31)

However, introduce new object constants b replace existentially quantified
variables
F 0 = (p(a) q) (q p(b)),
formula SM[F 0 ; q] equivalent
(q p(a)) (q p(b)),
satisfiable.
present method eliminating singular occurrences quantifiers introducing auxiliary predicates. idea generalization practice logic programming
13. Pearce Valverde (2005) show Skolemization works QNc5 , monotonic basis Quantified Equilibrium Logic, example shows, imply Skolemization works
Quantified Equilibrium Logic.

588

fiReformulating Situation Calculus Event Calculus

simulates negated existential quantification body rule introducing auxiliary predicates. instance, order eliminate (30), introduce new
predicate constant p0 , turn (30)
(r p0 s) x(p(x) q(x) p0 ),

(32)

corresponds logic program
r, p0
p0 p(x), q(x).

(33)

models SM[(30); p, q, r, s] stable models (33) disregard
p0 . method involve grounding, translation depend
domain restricted Herbrand models. method formally justified
following proposition.
Recall formula H negative p members p strictly positive
occurrences H. Given formula F , say occurrence subformula G
p-negated F contained subformula H F negative p.
Proposition 2 Let F sentence, let p finite list distinct predicate constants,
let q new predicate constant occur F . Consider non-strictly
positive, p-negated occurrence yG(y, x) F , x list free variables
yG(y, x). Let F 0 formula obtained F replacing occurrence yG(y, x)
q(x).
SM[F ; p] x(q(x) yG(y, x))
equivalent
SM[F 0 xy(G(y, x) q(x)); p, q].
Proposition 2 tells us SM[F ; p] SM[F 0 xy(G(y, x) q(x); p, q]
models disregard new predicate constant q. Notice F 0 retain
occurrence y.
Example 3 formula (30), x(p(x) q(x)) contained negative formula (relative
set intensional predicates). accordance Proposition 2, SM[(30); p, q, r, s]
models SM[(32); p, q, r, s, p0 ] disregard p0 .
singular, p-negated occurrence subformula yG(y, x) also eliminated
using Proposition 2 first rewriting yG(y, x) yG(y, x). Note yG(y, x)
strongly equivalent yG(y, x), general classically equivalent transformation may necessarily preserve stable models. However, Theorem Double
Negations (Ferraris et al., 2009, also reviewed Appendix C) tells us transformation ensured preserve p-stable models replaced occurrence p-negated
given formula.
ready present quantifier elimination method, applies
class almost universal formulas.
589

fiLee & Palla

Definition 6 say formula F almost universal relative p every singular
occurrence QxG F p-negated F .
example, formula (30) almost universal relative set predicates
singular occurrence x(p(x) q(x)) (30) contained x(p(x) q(x)),
negative list predicates. Formula F Example 2 almost universal relative
{q} singular occurrence x p(x) contained formula itself,
negative {q}, singular occurrence x(q p(x)) contained x(q p(x)),
also negative {q}.
following procedure used eliminate (possibly nested) quantifiers
almost universal sentence.
Definition 7 (Translation elim-quantifiers) Given formula F , first prepend
every maximal strictly positive occurrence formula form yH(y, x),14
repeat following process occurrences quantifiers remaining: Select
maximal occurrence formula form QyG(y, x) F , Q , x
list free variables QyG(y, x).
(a) occurrence QyG(y, x) F non-singular F , set F formula
obtained F replacing occurrence QyG(y, x) G(z, x), z
new variable.
(b) Otherwise, Q occurrence QyG(y, x) F positive, set F

F 0 (G(y, x) pG (x)),
pG new predicate constant F 0 formula obtained F replacing occurrence QyG(y, x) pG (x).
(c) Otherwise, Q occurrence QyG(y, x) F negative, set F
formula obtained F replacing occurrence QyG(y, x)
yG(y, x).
assume new predicate constants introduced translation belong
signature input formula F . clear process terminates, yields
formula quantifier-free. Since number times step (b) applied
number quantifiers input formula, new formulas added
size polynomial input formula, follows size resulting quantifier-free
formula polynomial size input formula.
following theorem tells us almost universal sentence F turned
form xG, G quantifier-free formula. (second-order) sentences F
G signature subset signature, say F -equivalent
G, denoted F G, class models F restricted identical class
models G restricted .
14. maximality understood terms subformula relation. is, select strictly positive
occurrence subformula F form yH(y, x) contained subformula
F form.

590

fiReformulating Situation Calculus Event Calculus

Theorem 6 Let F sentence signature , let F 0 universal closure
formula obtained F applying translation elim-quantifiers, let q list
new predicate constants introduced translation. F almost universal relative
p, SM[F ; p] -equivalent SM[F 0 ; p, q].
statement theorem becomes incorrect require F almost
universal relative p. instance, elim-quantifiers applied x p(x), results
q (p(x) q). However, SM[x p(x); p] {p}-equivalent
SM[x(q (p(x) q)); p, q]. former equivalent saying p singleton.
latter equivalent q xp(x) (q xp(x)), inconsistent.
5.3 f2lp: Computing Answer Sets First-Order Formulas
Using translation elim-quantifiers defined previous section, introduce translation f2lp turns almost universal formula logic program. assume
underlying signature contains finitely many predicate constants.
Definition 8 (Translation f2lp)
1. Given formula F list intensional predicates p, apply translation elim-quantifiers (Definition 7) F ;
2. Add choice formulas (q(x) q(x)) non-intensional predicates q.
3. Turn resulting quantifier-free formula logic program applying translation Section 3 paper Cabalar et al. (2005), also reviewed
Section 5.1.
explained Section 5.1, due third step, transformation may involve
exponential blowup size. One obtain polynomial translation replacing Step 3
alternative translation given Section 4 paper Cabalar et al.
following theorem asserts correctness translation.
Theorem 7 Let F sentence signature , let p list intensional predicates,
let F 0 FOL representation program obtained F applying translation
f2lp p intensional predicates. F almost universal relative p, SM[F ; p]
-equivalent
SM[F 0 False(p \ pr (F 0 ))].
Example 4 Consider one domain independent axioms discrete event calculus
(DEC5 axiom):
HoldsAt(f, t) ReleasedAt(f, t+1)
e(Happens(e, t) Terminates(e, f, t)) HoldsAt(f, t+1).
Step 1 translation f2lp introduces formula
Happens(e, t) Terminates(e, f, t) q(f, t),
replaces (34)
HoldsAt(f, t) ReleasedAt(f, t+1) q(f, t) HoldsAt(f, t+1).
591

(34)

fiLee & Palla

Step 3 turns formulas rules
q(f, t) Happens(e, t), Terminates(e, f, t)
HoldsAt(f, t+1) HoldsAt(f, t), ReleasedAt(f, t+1), q(f, t).
Turning program obtained applying translation f2lp input languages
lparse 15 gringo 16 requires minor rewriting, moving equality negated
atoms head body 17 adding domain predicates body variables
occurring rule order reduce many-sorted signature non-sorted one.18
System f2lp implementation translation f2lp, turns first-order formula
languages lparse gringo. system downloaded home
page
http://reasoning.eas.asu.edu/f2lp .
First-order formulas encoded f2lp using extended rule form F G,
F G first-order formulas contain . ASCII representation
quantifiers connectives shown following table.
Symbol
ASCII





-


&


|


<-


false

>
true

xyz
![X,Y,Z]:

xyz
?[X,Y,Z]:

example, formula (34) encoded input language f2lp
holdsAt(F,T+1) <- holdsAt(F,T) & releasedAt(F,T+1) &
?[E]:(happens(E,T) & terminates(E,F,T)).

usual lparse gringo rules (which rule arrow :-) also allowed
f2lp. rules simply copied output. program returned f2lp
passed ASP grounders solvers accept lparse gringo languages.

6. Computing Event Calculus Using ASP Solvers
Using translation f2lp, turn event calculus reformulation Section 3.2
answer set programs. following procedure describes process.
Definition 9 (Translation ec2asp)
1. Given event calculus description (16), rewrite
definitional axioms form
def

x(p(x) G)

(35)

x(G p(x)), G obtained G prepending
occurrences intensional predicates Initiates, Terminates, Releases, Happens,
Ab 1 , . . . , Ab n . Also prepend strictly positive occurrences intensional
predicates remaining axioms . Let 0 resulting formula obtained
.
15.
16.
17.
18.

http://www.tcs.hut.fi/Software/smodels
http://potassco.sourceforge.net
instance, (X=Y) | -q(X,Y) :- p(X,Y) turned :- X!=Y, {not q(X,Y)}0, p(X,Y).
Alternatively done declaring variables using #domain directive lparse gringo
languages.

592

fiReformulating Situation Calculus Event Calculus

2. Apply translation f2lp 0 intensional predicates
{Initiates, Terminates, Releases, Happens, Ab 1 , . . . , Ab n } p,
p set predicate constants p (35) considered Step 1.
following theorem states correctness translation.
Theorem 8 Let event calculus description (16) signature contains finitely
many predicate constants, let F FOL representation program obtained
applying translation ec2asp. -equivalent SM[F ].
view theorem, system f2lp used compute event calculus descriptions
simple rewriting stated translation ec2asp.19 system used place
dec reasoner many existing applications event calculus, robotics,
security, video games, web service composition, listed
http://decreasoner.sourceforge.net/csr/decapps.html .
computational mechanism dec reasoner similar method
based reduction event calculus reasoning propositional satisfiability uses
efficient SAT solvers computation. However, method advantages.
First, significantly faster due efficient grounding mechanisms implemented
ASP systems. evidenced experiments reported Appendix B.
Second, f2lp allows us compute full version event calculus, assuming
domain given finite. hand, reduction implemented dec
reasoner based completion, weaker circumscription. makes
system unable handle recursive axioms disjunctive axioms, effect constraints
disjunctive event axioms (Section 3.1). example, dec reasoner allow
following effect constraints describe indirect effects agents walking
objects holding:
HoldsAt(Holding(a, o), t) Initiates(e, InRoom(a, r), t)
Initiates(e, InRoom(o, r), t)
HoldsAt(Holding(a, o), t) Terminates(e, InRoom(a, r), t)
Terminates(e, InRoom(o, r), t).

(36)

Third, enhance event calculus reasoning combining ASP rules
event calculus description. words, event calculus viewed high
level action formalism top ASP. illustrate using example work
Dogandag, Ferraris, Lifschitz (2004). 9 rooms 12 doors shown
Figure 1. Initially robot Robby middle room doors closed.
goal robot make rooms accessible other. Figure 2 (File robby)
shows encoding problem language f2lp. Atom door(x, y) denotes
door rooms x y; open(x, y) denotes event Robby opening door
19. Kim, Lee, Palla (2009) presented prototype f2lp called ecasp tailored event
calculus computation.

593

fiLee & Palla

Figure 1: Robbys apartment 3 3 grid
rooms x y; goto(x) denotes event Robby going room x; opened(x, y)
denotes door x opened; inRoom(x) denotes Robby
room x; accessible(x, y) denotes accessible x. Note rules
defining relation accessible part event calculus axioms (Section 3.1).
example illustrates advantage allowing ASP rules event calculus descriptions.
minimal number steps solve given problem 11. find
plan using combination f2lp, gringo (grounder) claspD (solver disjunctive
programs) following way. 20
$ f2lp dec robby | gringo -c maxstep=11 | claspD
File dec f2lp encoding domain independent axioms Discrete Event
Calculus (The file listed Appendix A).21 following one plans found:
happens(open(5,8),0) happens(open(5,2),1) happens(open(5,4),2)
happens(goto(4),3) happens(open(4,1),4) happens(open(4,7),5)
happens(goto(5),6) happens(open(5,6),7) happens(goto(6),8)
happens(open(6,9),9) happens(open(6,3),10)

7. Computing Situation Calculus Using ASP Solvers
Using translation f2lp, turn situation calculus reformulations Sections 4.2
4.4 answer set programs.
7.1 Representing Causal Action Theories Answer Set Programs
following theorem shows turn causal action theories answer set programs.
Theorem 9 Let finite causal action theory (23) signature contains finitely
many predicate constants, let F FOL representation program obtained
applying translation f2lp

Dcaused Dposs Drest
Dsit

(37)

intensional predicates {Caused , Poss, Sit}. -equivalent SM[F ].
20. One use clingo instead gringo claspD output f2lp nondisjunctive program.
21. file also available http://reasoning.eas.asu.edu/f2lp, along f2lp encodings
domain independent axioms versions event calculus.

594

fiReformulating Situation Calculus Event Calculus

% File robby
% objects
step(0..maxstep).
astep(0..maxstep-1) :- maxstep > 0.
room(1..9).
% variables
#domain step(T).
#domain room(R).
#domain room(R1).
#domain room(R2).
% position
door(R1,R2) <- R1
door(R1,R2) <- R1
door(R1,R2) <- R1
door(R1,R2) <- R2

doors
>= 1 &
>= 4 &
>= 7 &
< 10 &

R2
R2
R2
R2

>=1 & R1 < 4 & R2 < 4 & R2 = R1+1.
>= 4 & R1 < 7 & R2 < 7 & R2 = R1+1.
>= 7 & R1 < 10 & R2 < 10 & R2 = R1+1.
= R1+3.

door(R1,R2) <- door(R2,R1).
% fluents
fluent(opened(R,R1)) <- door(R1,R2).
fluent(inRoom(R)).
% F ranges fluents
#domain fluent(F).
% events
event(open(R,R1)) <- door(R,R1).
event(goto(R)).
% E E1 range events
#domain event(E).
#domain event(E1).
% effect axioms
initiates(open(R,R1),opened(R,R1),T).
initiates(open(R,R1),opened(R1,R),T).
initiates(goto(R2),inRoom(R2),T)
<- holdsAt(opened(R1,R2),T) & holdsAt(inRoom(R1),T).
terminates(E,inRoom(R1),T)
<- holdsAt(inRoom(R1),T) & initiates(E,inRoom(R2),T).
% action precondition axioms
holdsAt(inRoom(R1),T) <- happens(open(R1,R2),T).

595

fiLee & Palla

% event occurrence constraint
happens(E1,T) <- happens(E,T) & E != E1.
% state constraint
holdsAt(inRoom(R2),T) <- holdsAt(inRoom(R1),T) & R1 != R2.
% accessibility
accessible(R,R1,T) <- holdsAt(opened(R,R1),T).
accessible(R,R2,T) <- accessible(R,R1,T) & accessible(R1,R2,T).
% initial state
holdsAt(opened(R1,R2),0).
holdsAt(inRoom(5),0).
% goal state
accessible(R,R1,maxstep).
% happens exempt minimization order find plan.
{happens(E,T)} <- < maxstep.
% fluents inertial
releasedAt(F,0).

Figure 2: Robby f2lp

Similar computation event calculus Section 6, Herbrand stable
models (37) computed using f2lp answer set solvers. input f2lp
simplified limit attention Herbrand models. drop axioms (18)(21)
ensured Herbrand models. Also, order ensure finite grounding, instead
Dsit , include following set rules situation input f2lp.
nesting(0,s0).
nesting(L+1,do(A,S)) <- nesting(L,S) & action(A) & L < maxdepth.
situation(S) <- nesting(L,S).
final(S) <- nesting(maxdepth,S).

situation used generate finitely many situation terms whose depth maxdepth,
value given option invoking gringo. Using splitting theorem
(Section C.1), difficult check program containing rules
occurrence predicate nesting rules occurrence predicate situation head rules, every answer set contains
atoms situation(do(am , do(am1 , do(. . . , do(a1 , s0))))) possible sequences actions
a1 , . . . , = 0, . . . , maxdepth. Though program satisfy syntactic conditions, -restricted (Gebser, Schaub, & Thiele, 2007), -restricted (Syrjanen, 2004),
finite domain programs (Calimeri, Cozza, Ianni, & Leone, 2008), answer set solvers
usually impose order ensure finite grounding, rules still finitely grounded
596

fiReformulating Situation Calculus Event Calculus

% File: suitcase
value(t).
value(f).

lock(l1).

lock(l2).

#domain value(V).
#domain lock(X).
fluent(up(X)).
fluent(open).
#domain fluent(F).
action(flip(X)).
#domain action(A).
depth(0..maxdepth).
#domain depth(L).
% defining situation domain
nesting(0,s0).
nesting(L+1,do(A,S)) <- nesting(L,S) & L < maxdepth.
situation(S) <- nesting(L,S).
final(S) <- nesting(maxdepth,S).
% basic axioms
h(F,S) <- situation(S) & caused(F,t,S).
h(F,S) <- situation(S) & caused(F,f,S).
% D_caused
caused(up(X),f,do(flip(X),S)) <situation(S) & final(S) & poss(flip(X),S) & h(up(X),S).
caused(up(X),t,do(flip(X),S)) <situation(S) & final(S) & poss(flip(X),S) & h(up(X),S).
caused(open,t,S) <- situation(S) & h(up(l1),S) & h(up(l2),S).
% D_poss
poss(flip(X),S) <- situation(S).
% frame axioms
h(F,do(A,S)) <h(F,S) & situation(S) & final(S) & poss(A,S)
& ?[V]:caused(F,V,do(A,S)).
h(F,do(A,S)) <not h(F,S) & situation(S) & final(S) & poss(A,S)
& ?[V]:caused(F,V,do(A,S)).
% h non-intensional.
{h(F,S)} <- situation(S).

Figure 3: Lins Suitcase language f2lp
597

fiLee & Palla

gringo Version 3.x, check syntactic conditions.22 difficult
see program leads finite grounding since provide explicit upper
limit nesting depth function do.
addition situation , use following program executable order represent
set executable situations (Reiter, 2001):
executable(s0).
executable(do(A,S)) <- executable(S) & poss(A,S) & final(S)
& situation(S) & action(A).

Figure 3 shows encoding Lins suitcase example (1995) language f2lp
(h used represent Holds), describes suitcase two locks spring
loaded mechanism open suitcase locks up. example
illustrates ramification problem handled causal action theories. Since fix
domain situations finite, require actions effective final
situations. done introducing atom final(S).
Consider simple temporal projection problem Lin (1995). Initially first lock
second lock up. happen first lock flipped? Intuitively,
expect locks suitcase open. automate reasoning
using combination f2lp, gringo claspD. First, add executable
following rules theory Figure 3. order check theory entails flipping
first lock executable, suitcase open action, encode
negation facts last rule.
% initial situation
<- h(up(l1),s0).
h(up(l2),s0).
% query
<- executable(do(flip(l1),s0)) & h(open,do(flip(l1),s0)).

check answer temporal projection problem running command:
$ f2lp suitcase | gringo -c maxdepth=1 | claspD

claspD returns answer set expected.
Now, consider simple planning problem opening suitcase locks
initially down. add executable following rules theory Figure 3.
last rule encodes goal.
% initial situation
<- h(up(l1),s0).
<- h(up(l2),s0).
<- h(open,s0).
% goal
<- ?[S]: (executable(S) & h(open,S)).

maxdepth 1, combined use f2lp, gringo claspD results
answer sets, maxdepth 2, finds unique answer set contains
22. Similarly, system dlv-complex allows us turn finite domain checking (option -nofdcheck).
system used conference paper (Lee & Palla, 2010) article based on.

598

fiReformulating Situation Calculus Event Calculus

h(open, do(flip(l2), do(flip(l1), s0))) h(open, do(flip(l1), do(flip(l2), s0))),
encodes plan. words, single answer set encodes multiple plans
different branches situation tree, allows us combine information
different branches one model. instance hypothetical reasoning
elegantly handled situation calculus due branching time structure. Belleghem,
Denecker, Schreye (1997) note linear time structure event calculus
limited handle hypothetical reasoning allowed situation calculus.
7.2 Representing Basic Action Theories Answer Set Programs
Since BAT (not including second-order axiom (22)) viewed first-order
theory stable model semantics list intensional predicates empty,
follows f2lp used turn logic program. before, focus
ASP-style BAT.
Theorem 10 Let ASP-style BAT (26) signature contains finitely many
predicate constants, let F FOL representation program obtained applying translation f2lp intensional predicates {Holds, Holds, Poss}.
SM[T ; Holds, Holds, Poss] -equivalent SM[F ; (F ) {Poss}].
Figure 4 shows encoding broken object example discussed Reiter (1991).
Consider simple projection problem determining object o, next
bomb b, broken bomb explodes. add executable following rules
theory Figure 4.
% initial situation
h(broken(o),s0) & h(fragile(o),s0) & h(nexto(b,o),s0).
h(holding(p,o),s0) & h(exploded(b),s0).
% query
<- executable(do(explode(b),s0)) & h(broken(o),do(explode(b),s0)).

command
$ f2lp broken | gringo -c maxdepth=1 | claspD

returns answer set expected.

8. Related Work
Identifying syntactic class theories different semantics coincide important
understanding relationship them. known that, tight logic programs
tight first-order formulas, stable model semantics coincides completion
semantics (Fages, 1994; Erdem & Lifschitz, 2003; Ferraris et al., 2011). fact helps us
understand relationship two semantics, led design answer
set solver cmodels-1 23 computes answer sets using completion. Likewise class
canonical formulas introduced helps us understand relationship
stable model semantics circumscription. class canonical formulas largest
23. http://www.cs.utexas.edu/users/tag/cmodels

599

fiLee & Palla

% File: broken
% domains situations
person(p).
object(o).
bomb(b).
#domain person(R).
#domain object(Y).
#domain bomb(B).
fluent(holding(R,Y)).
fluent(broken(Y)).

fluent(nexto(B,Y)).
fluent(exploded(B)).

fluent(fragile(Y)).

action(drop(R,Y)).

action(explode(B)).

action(repair(R,Y)).

#domain fluent(F).
#domain action(A).
depth(0..maxdepth).
#domain depth(L).
% defining situation domain
nesting(0,s0).
nesting(L+1,do(A,S)) <- nesting(L,S) & L < maxdepth.
situation(S) <- nesting(L,S).
final(S) <- nesting(maxdepth,S).
% Effect Axioms
h(broken(Y),do(drop(R,Y),S)) <- situation(S) & h(fragile(Y),S) & final(S).
h(broken(Y),do(explode(B),S)) <- situation(S) & h(nexto(B,Y),S) & final(S).
h(exploded(B),do(explode(B),S)) <- situation(S) & final(S).
-h(broken(Y),do(repair(R,Y),S)) <- situation(S) & final(S).
-h(holding(R,Y),do(drop(R,Y),S)) <- situation(S) & final(S).
% Action precondition axioms
poss(drop(R,Y),S) <- h(holding(R,Y),S) & situation(S).
poss(explode(B),S) <- situation(S) & h(exploded(B),S).
poss(repair(R,Y),S) <- situation(S) & h(broken(Y),S).
% inertial axioms
h(F,do(A,S)) <- h(F,S) & -h(F,do(A,S)) & situation(S) & final(S).
-h(F,do(A,S)) <- -h(F,S) & h(F,do(A,S)) & situation(S) & final(S).
% D_exogeneous_0
h(F,s0) | -h(F,s0).
% Consider interpretations complete Holds
<- h(F,S) & -h(F,S) & situation(S).

Figure 4: Broken object example language f2lp

600

fiReformulating Situation Calculus Event Calculus

syntactic class first-order formulas identified far stable models coincide
models circumscription. words, minimal model reasoning stable
model reasoning indistinguishable canonical formulas.
Proposition 8 work Lee Lin (2006) shows embedding propositional circumscription logic programs stable model semantics. theorem
canonical formulas generalization result first-order case. Janhunen
Oikarinen (2004) showed another embedding propositional circumscription logic
programs, implemented system circ2dlp,24 translation appears quite
different one Lee Lin.
Zhang, Zhang, Ying, Zhou (2011) show embedding first-order circumscription
first-order stable model semantics. Theorem 3 paper reproduced follows.25
Theorem 11 (Zhang et al., 2011, Thm. 3) Let F formula negation normal form
let p finite list predicate constants. Let F formula obtained F
replacing every p(t) p(t), let F c formula obtained F replacing
every p(t) p(t) Choice(p), p p list terms. CIRC[F ; p]
equivalent SM[F F c ; p].
comparison Theorem 1, theorem applied characterize circumscription arbitrary formulas terms stable models first rewriting formulas
negation normal form. Theorem 1 applicable canonical formulas only,
require transformation, characterization bidirectional sense
also viewed characterization stable models terms circumscription.
Zhang et al. (2011) also introduce translation turns arbitrary first-order formulas
logic programs, work limited finite structures only. hand,
translation f2lp (Definition 8) works almost universal formulas only,
limited finite structures.
situation calculus event calculus widely studied action formalisms,
several papers compare relate (e.g., Belleghem, Denecker, &
Schreye, 1995; Provetti, 1996; Belleghem et al., 1997; Kowalski & Sadri, 1997).
Prolog provides natural implementation basic action theories since definitional
axioms represented Prolog rules according Clarks theorem (Reiter, 2001,
Chapter 5). Lloyd-Topor transformation used turn formulas Prolog rules
similar translation f2lp, difference former preserves completion
semantics latter preserves stable model semantics.
Lin Wang (1999) describe language used represent syntactically
restricted form Lins causal situation calculus, called clausal causal theories,
allow quantifiers. show translate language answer set programs
strong negation, answer sets used obtain fully instantiated
successor state axioms action precondition axioms. quite different
approach, computes propositional models full situation calculus theories
directly.
Kautz Selman (1992) introduce linear encodings similar propositionalized version situation calculus (McCarthy & Hayes, 1969). Lin (2003) introduces
24. http://www.tcs.hut.fi/Software/circ2dlp
25. bit simpler original statement redundancy dropped.

601

fiLee & Palla

action description language describes procedure compile action domain
language complete set successor state axioms, STRIPS-like
description extracted. soundness procedure shown respect
translation action domain descriptions Lins causal action theories. However,
procedure based completion cannot handle recursive axioms unlike
approach.
Denecker Ternovska (2007) present inductive variant situation calculus
represented ID-logic (Denecker & Ternovska, 2008)classical logic extended inductive definitions. ID-logic first-order stable model semantics appear closely
related, precise relationship yet shown.

9. Conclusion
first-order stable model semantics defined similar circumscription. paper
takes advantage definition identify class formulas minimal model
reasoning stable model reasoning coincide, uses idea reformulate situation calculus event calculus first-order stable model semantics. Together
translation turns almost universal sentence logic program, show
reasoning situation calculus event calculus reduced computing
answer sets. implemented system f2lp, front-end ASP solvers allows us
compute circumscriptive action theories. mathematical tool sets system presented paper may also useful relating circumscriptive theories
logic programs. Also, advances ASP solvers may improve computation
circumscriptive theories.

Acknowledgments
grateful Yuliya Lierler, Vladimir Lifschitz, Erik Mueller, Heng Zhang, Yan Zhang,
anonymous referees useful comments discussions. authors
partially supported National Science Foundation Grant IIS-0916116.

Appendix A. File dec Language f2lp
File dec encodes domain independent axioms discrete event calculus. file
used together event calculus domain descriptions shown Section 6.
% File dec
#domain
#domain
#domain
#domain
#domain
#domain
#domain

fluent(F).
fluent(F1).
fluent(F2).
event(E).
time(T).
time(T1).
time(T2).

time(0..maxstep).
602

fiReformulating Situation Calculus Event Calculus

% DEC 1
stoppedIn(T1,F,T2) <- happens(E,T) & T1<T & T<T2 & terminates(E,F,T).
% DEC 2
startedIn(T1,F,T2) <- happens(E,T) & T1<T & T<T2 & initiates(E,F,T).
% DEC 3
holdsAt(F2,T1+T2) <- happens(E,T1) & initiates(E,F1,T1) & T2>0 &
trajectory(F1,T1,F2,T2) & stoppedIn(T1,F1,T1+T2) & T1+T2<=maxstep.
% DEC 4
holdsAt(F2,T1+T2) <- happens(E,T1) & terminates(E,F1,T1) & 0<T2 &
antiTrajectory(F1,T1,F2,T2) & startedIn(T1,F1,T1+T2) &
T1+T2<=maxstep.
% DEC 5
holdsAt(F,T+1) <- holdsAt(F,T) & releasedAt(F,T+1) &
?[E]:(happens(E,T) & terminates(E,F,T)) & T<maxstep.
% DEC 6
holdsAt(F,T+1) <- holdsAt(F,T) & releasedAt(F,T+1) &
?[E]:(happens(E,T) & initiates(E,F,T)) & T<maxstep.
% DEC 7
releasedAt(F,T+1) <releasedAt(F,T) & ?[E]:(happens(E,T) &
(initiates(E,F,T) | terminates(E,F,T))) & T<maxstep.
% DEC 8
releasedAt(F,T+1) <- releasedAt(F,T) &
?[E]: (happens(E,T) & releases(E,F,T)) & T<maxstep.
% DEC 9
holdsAt(F,T+1) <- happens(E,T) & initiates(E,F,T) & T<maxstep.
% DEC 10
holdsAt(F,T+1) <- happens(E,T) & terminates(E,F,T) & T<maxstep.
% DEC 11
releasedAt(F,T+1) <- happens(E,T) & releases(E,F,T) & T<maxstep.
% DEC 12
releasedAt(F,T+1) <- happens(E,T) &
(initiates(E,F,T) | terminates(E,F,T)) & T<maxstep.
{holdsAt(F,T)}.
{releasedAt(F,T)}.

603

fiLee & Palla

Problem
(max. step)

dec
reasoner

dec
reasoner (minisat)

f2lp
lparse + cmodels

f2lp
gringo + cmodels

f2lp
gringo + clasp(D)

f2lp
clingo

BusRide
(15)











0.2s
(0.07s + 0.13s)
A:13174/R:24687

0.14s

Kitchen
Sink (25)

39.0s
(38.9s + 0.1s)
A:1014/C:12109

38.9s
(38.9s + 0.00s)
A:1014/C:12109

0.24s
(0.18s + 0.06s)
A:11970/R:61932

0.20s

Thielscher
Circuit (40)

6.5s
(6.3s + 0.2s)
A:1394/C:42454

6.3s
(6.3s + 0.0s)
A:1394/C:42454

0.12s
(0.09s + 0.03s)
A:4899/R:35545

0.1s

Walking
Turkey (15)





0.00s
(0.00s + 0.00s)
A:316/R:456

0.00s

Falling w/
AntiTraj (15)

141.8s
(141.4s + 0.4s)
A:416/C:3056

141.7s
(141.7s + 0.00s)
A:416/C:3056

0.03s
(0.03s + 0.00s)
A:3702/R:7414

0.03s

Falling w/
Events (25)

59.5s
(59.5s + 0.0s)
A:1092/C:12351

59.4s
(59.4s + 0.0s)
A:1092/C:12351

0.28s
(0.20s + 0.08s)
A:13829/R:71266

0.22s

HotAir
Baloon (15)

32.2s
(32.2s + 0.0s)
A:288/C:1163

32.3s
(32.3s + 0.0s)
A:288/C:1163

0.0s
(0.0s + 0.0s)
A:1063/R:1835

0.01s

Telephone1
(40)

9.3s
(9.2s + 0.1s)
A:5419/C:41590

9.1s
(9.1s + 0.0s)
A:5419/C:41590

0.00s
(0.00s + 0.00s)
A:355/R:555
C:0
0.15s
(0.07s + 0.08s)
A:5269/R:24687
C:5308
0.44s
(0.19s + 0.25s)
A:11970/R:61932
C:0
0.19s
(0.09s + 0.1s)
A:4899/R:35545
C:0
0.00s
(0.00s + 0.00s)
A:316/R:456
C:0
0.04s
(0.02s + 0.02s)
A:3702/R:7414
C:0
0.46s
(0.20s + 0.26s)
A:1219/R:71266
C:1415
0.0s
(0.0s + 0.0s)
A:492/R:1835
C:681
0.11s
(0.08s + 0.03s)
A:9455/R:13140
C:0

0.01s
(0.00s + 0.01s)
A:448/R:647

Commuter
(15)

0.04s
(0.03s + 0.01s)
A:902/R:7779
C:0
77.29s
(45.74s + 31.55s)
A:32861/R:8734019
C:0
6.19s
(2.99s + 3.20s)
A:121621/R:480187
C:0
0.42s
(0.27s + 0.15s)
A:9292/R:53719
C:0
0.00s
(0.00s + 0.00s)
A:370/R:518
C:0
0.08s
(0.05s + 0.03s)
A:4994/R:9717
C:0
4.95s
(2.57s + 2.38s)
A:1240/R:388282
C:1436
0.01s
(0.01s + 0.00s)
A:494/R:2451
C:689
0.22s
(0.13s + 0.09s)
A:21414/R:27277
C:0

0.07s
(0.06s + 0.01s)
A:9455/R:13140

0.07s

A: number atoms, C: number clauses, R: number ground rules
Figure 5: Comparing dec reasoner f2lp answer set solvers

Appendix B. Comparing dec Reasoner ASP-based Event
Calculus Reasoner
compared performance dec reasoner (v 1.0) running relsat (v 2.2)
minisat (v 2.2) following:
f2lp (v 1.11) lparse (v 1.0.17)+cmodels (v 3.79) running minisat (v 2.0
beta),
f2lp (v 1.11) gringo (v 3.0.3)+cmodels (v 3.79) running minisat (v 2.0 beta),
f2lp (v 1.11) gringo (v 3.0.3) +clasp (v 2.0.2) (claspD (v 1.1.2) used instead
disjunctive programs),
f2lp (v 1.11) clingo (v 3.0.3 (clasp v 1.3.5)).
f2lp turns input theory languages lparse gringo, lparse
gringo turn result ground ASP program. cmodels turns ground program
set clauses invokes SAT solver compute answer sets, clasp
computes answer sets using techniques similar used SAT solvers. clingo
system combines gringo clasp monolithic way.
first five examples Figure 5 part benchmark problems work
Shanahan (1997, 1999). next four Mueller (2006). (We increased timepoints
604

fiReformulating Situation Calculus Event Calculus

Problem
(max. step)
ZooTest1
(16)

f2lp
gringo + cmodels
50.48s
(6.66s + 43.82s)
A:930483/R:2272288
C:3615955
ZooTest2
> 2h
159.51s
(22)
(12.36s + 147.15s)
A:2241512/R:4153670
C:8864228
ZooTest3
> 2h
142.68s
(23)
(13.55s + 129.13s)
A:2505940/R:4556928
C:9914568
A: number atoms, C: number clauses, R: number
dec
reasoner (minisat)
> 2h

f2lp
gringo + clasp
29.01s
(6.66s + 22.35s)
A:153432/R:2271175
210.55s
(12.36s + 198.19s)
A:219220/R:4152137
196.63s
(13.55s + 183.08s)
A:230731/R:4555325
ground rules

Figure 6: Zoo World dec reasoner ASP

see notable differences.) examples found f2lp homepage.
experiments done Pentium machine 3.06 GHz CPU 4GB RAM running
64 bit Linux. reported run times seconds obtained using Linux
time command (user time + sys time), except dec reasoner recorded
times reported system. fair comparisons order avoid including
time spent dec reasoner producing output neat format, sometimes
takes non-negligible time. dec reasoner, times parentheses (SAT encoding time + SAT solving time). others, times spent
grounder solver. cmodels time includes time spent converting ground
program generated lparse/gringo set clauses, calling SAT solver.
time spent f2lp translating event calculus description answer set
program (retaining variables) negligible problems. denotes system
cannot solve example due limited expressivity. instance, BusRide includes
disjunctive event axioms, results disjunctive program cannot handled
clingo. Similarly, dec reasoner cannot handle BusRide (disjunctive event axioms),
Commuter (compound events) Walking Turkey (effect constraints). evident
experiments, main reason efficiency ASP-based approach efficient grounding mechanisms implemented ASP grounders. Though dec reasoner
cmodels call SAT solver minisat, number atoms processed dec
reasoner general much smaller. dec reasoner adopts optimized
encoding method (that based predicate completion) avoids large number
ground instances atoms Initiates(e, f, t), Terminates(e, f, t), Releases(e, f, t)
(Mueller, 2004, Section 4.4). hand, several examples, number clauses
generated cmodels 0, means answer sets found without calling
SAT solver. examples unique answer set coincides
well-founded model, efficiently computed cmodels preprocessing step
calling SAT solvers. 14 benchmark examples Shanahan (1997, 1999),
10 belong case lparse used grounding.
605

fiLee & Palla

experiments Figure 5, solving times negligible problems. also experimented computationally hard problems, solving takes
time grounding. Figure 6 shows runs medium-size action domain, Zoo
World (Akman, Erdogan, Lee, Lifschitz, & Turner, 2004). tests shown table
planning problems max. step length minimal plan. cut-off time
2 hours dec reasoner terminate within time problems. fact, entire time spent SAT encoding SAT solver never
called. hand, ASP grounder gringo took seconds ground
domain and, unlike Figure 5, solvers took much time grounder.
see, cmodels minisat performed better clasp two problems.
check time taken minisat encoding generated dec reasoner,
ran ZooTest1 completion. dec reasoner terminated 116578.1 seconds (32.38
hours).

Appendix C. Proofs
C.1 Review Useful Theorems
review theorems Ferraris et al. (2011) Ferraris et al. (2009)
used prove main results. fact, provide version splitting theorem
slightly general one given Ferraris et al. (2009), order
facilitate proof efforts.
Lemma 1 Formula
u p ((F ) (u) F )
logically valid.
Theorem 12 (Ferraris et al., 2011, Thm. 2) first-order formula F
disjoint lists p, q distinct predicate constants,
SM[F ; p] SM[F Choice(q); p q]
logically valid.
Let F first-order formula. rule F implication occurs strictly positively
F . predicate dependency graph F (relative p) directed graph
members p vertices,
edge p q if, rule G H F ,
p strictly positive occurrence H,
q positive occurrence G belong subformula G
negative p.
Theorem 13 (Ferraris et al., 2009, Splitting Thm.) Let F , G first-order sentences,
let p, q finite disjoint lists distinct predicate constants.
606

fiReformulating Situation Calculus Event Calculus

(a) strongly connected component predicate dependency graph F G relative
p, q either subset p subset q,
(b) F negative q,
(c) G negative p

SM[F G; p q] SM[F ; p] SM[G; q]
logically valid.
theorem slightly general one Ferraris et al. (2009)
notion dependency graph yields less edges one given Ferraris et al.
Instead
q positive occurrence G belong subformula G
negative p,
Ferraris et al.s definition
q positive occurrence G belong subformula
form K.
instance, according Ferraris et al., dependency graph
((p q) r) p

(38)

relative p two edges (from p r, p p), dependency graph
according definition edges.
hand, generalization essential view following theorem.
Theorem 14 (Ferraris et al., 2009, Thm. Double Negations) Let H sentence, F
subformula H, H sentence obtained H inserting front F .
occurrence F p-negated H, SM[H; p] equivalent SM[H ; p].
instance, SM[(38); p] equivalent SM[((p q) r) p; p]. dependency
graph ((p q) r) p relative p according definition Ferraris et al.
identical dependency graph (38) relative p according definition.
Next, say formula F Clark normal form (relative list p intensional
predicates) conjunction sentences form
x(G p(x)),

(39)

one intensional predicate p, x list distinct object variables, G
free variables x. completion (relative p) formula F
Clark normal form obtained replacing conjunctive term (39)
x(p(x) G).
following theorem relates SM completion. say F tight p
predicate dependency graph F relative p acyclic.
Theorem 15 (Ferraris et al., 2011) formula F Clark normal form tight
p, formula SM[F ; p] equivalent completion F relative p.
607

fiLee & Palla

C.2 Proof Proposition 1
Using Theorem 12 Theorem 13,
SM[F ; p] SM[F ; p pr (F )] SM[>; p\pr (F )]
SM[F ; p pr (F )] False(p\pr (F ))
SM[F Choice(pr (F )\p)] False(p\pr (F ))
SM[F Choice(pr (F )\p) False(p\pr (F ))].

C.3 Proof Theorem 1
following, F formula, p list distinct predicate constants p1 , . . . , pn , u
list distinct predicate variables u1 , . . . , un length p.
Lemma 2 (Ferraris et al., 2011, Lemma 5) Formula
u p (F (u) F )
logically valid.
Lemma 3 every occurrence every predicate constant p strictly positive F ,
(u p) (F (u) F (u))
logically valid.
Proof. induction. show case F G H. cases
straightforward. Consider
F (u) = (G (u) H (u)) (G H).
Since every occurrence predicate constants p F strictly positive, G contains
predicate constants p, G (u) equivalent G(u),
G. Also, I.H., H (u) H(u) logically valid. Therefore sufficient prove
assumption u p,
(G H(u)) (G H) (G H(u))
logically valid. left right clear. Assume (u p), G H(u), G. get
H(u), equivalent H (u) I.H. Lemma 2, conclude H.

proof Theorem 1 immediate following lemma, proved
induction.
Lemma 4 F canonical relative p, formula
(u p) F (F (u) F (u))
logically valid.
608

fiReformulating Situation Calculus Event Calculus

Proof.
F atomic formula. Trivial.
F = G H. Follows I.H.
F = G H. Assume (u p) (G H). Since G H canonical relative p,
every occurrence every predicate constant p strictly positive G H,
that, Lemma 3, G (u) equivalent G(u), H (u) equivalent H(u).
F = G H. Assume (u p) (G H). sufficient show
(G (u) H (u)) (G(u) H(u)).

(40)

Since G H canonical relative p, every occurrence every predicate constant
p G strictly positive G, that, Lemma 3, G (u) equivalent
G(u).
Case 1: G. Lemma 2, G (u). claim follows since G (u) equivalent
G(u).
Case 2: H. I.H. H (u) equivalent H(u). claim follows since G (u)
equivalent G(u).
F = xG. Follows I.H.
F = xG. Since every occurrence every predicate constant p G strictly
positive G, claim follows Lemma 3.

C.4 Proof Theorem 2
Proof. (a) (b):
(b) (c):

Follows immediately Theorem 1.

Note first equivalent SM[; ]. Since

every strongly connected component dependency graph relative
{I, T, R, H} either belongs {I, T, R} {H},
negative {H},
negative {I, T, R},
follows Theorem 13 (b) equivalent
SM[ ; I, T, R, H] SM[; Ab1 , . . . , Abn ] SM[; ]
Similarly, applying Theorem 13 repeatedly, show formula
equivalent (c).
(c) (d):

Proposition 1.



609

fiLee & Palla

C.5 Proof Theorem 3
Since Dcaused canonical relative Caused , Theorem 1, (a)

(a) (b):
equivalent


SM[Dcaused ; Caused ] Dposs Drest
(22).

(41)

Consequently, sufficient prove claim that, assumption Sit(s),
formula (22) equivalent SM[Dsit ; Sit].
First note assumption, (22) equivalently rewritten

p p(S0 ) a, s(p(s) p(do(a, s))) p = Sit .
(42)
hand, Sit(s), SM[Dsit ; Sit] equivalent
Sit(S0 ) a, s(Sit(s) Sit(do(a, s)))

p p < Sit (p(S0 ) a, s(p(s) p(do(a, s))) a, s(Sit(s) Sit(do(a, s)))) ,
which, assumption Sit(s), equivalent
p p(S0 ) a, s(p(s) p(do(a, s))) (p < Sit)



furthermore (42).
(b) (c): Since (s) contain Poss, equivalence follows
equivalence completion stable model semantics.
(c) (d): Since Dcaused contains strictly positive occurrence Poss
Dposs contains occurrence Caused , every strongly connected component
predicate dependency graph Dcaused Dposs relative {Caused , Poss} either belongs
{Caused } belongs {Poss}. Theorem 13, follows (b) equivalent

SM[Dcaused Dposs ; Caused , Poss] Drest
SM[Dsit ; Sit].

Similarly, applying Theorem 13 two times, get formula equivalent
(c).

C.6 Proof Theorem 4
Theory
Deffect Dprecond DS0 Duna Dinertia Dexogenous0 ,
corresponding BAT
Dss Dap DS0 Duna .
Without loss generality, assume already equivalently rewritten
exactly one positive effect axiom exactly one negative effect axiom fluent R,
exactly one action precondition axiom action A.
610

fiReformulating Situation Calculus Event Calculus

Consider
SM[ Deffect Dprecond DS0 Duna Dinertia Dexogenous0 ; Poss, Holds, Holds].
Since Duna negative intensional predicates, formula equivalent
SM[Deffect Dprecond DS0 Dinertia Dexogenous0 ; P oss, Holds, Holds] Duna .
(43)
Since P oss occur
Deffect DS0 Dinertia Dexogenous0 ,
since Dprecond negative {Holds, Holds}, Theorem 13, (43) equivalent
SM[Deffect DS0 Dinertia Dexogenous0 ; Holds, Holds]
SM[Dprecond ; P oss] Duna ,

(44)

equivalent
SM[Deffect DS0 Dinertia Dexogenous0 ; Holds, Holds]
Dap Duna .
Therefore statement theorem proven showing following:

|= x s(+
R (x, a, s) R (x, a, s))

(45)

|=

(46)

SM[DS0 Dexogenous0 Deffect Dinertia ; Holds, Holds]

(47)

every fluent R,
satisfies

iff I| satisfies
DS0 Dss .
Dexogenous0 , follows (47) equivalent
SM[DS
Dexogenous0 Deffect Dinertia ; Holds, Holds],
0

(48)

DS
formula obtained DS0 prepending occurrences Holds.
0
assumption (46),
DS
Dexogenous0 Deffect Dinertia
0
{Holds}-atomic-tight w.r.t. I, 26 relationship completion SM
stated Corollary 11 (Lee & Meng, 2011), |= (48) iff satisfies
DS0 , and, fluent R,
26. See Section 7 work Lee Meng (2011) definition.

611

fiLee & Palla

Holds(R(x), do(a, s)) +
R (x, a, s) (Holds(R(x, s) Holds(R(x), do(a, s)))

(49)


Holds(R(x), do(a, s))
R (x, a, s) (Holds(R(x), s) Holds(R(x), do(a, s))), (50)
x, a, (lists of) object names corresponding sorts.
remains show that, assumption (45), satisfies (49) (50) iff I| satisfies

Holds(R(x), do(a, s)) +
R (x, a, s) (Holds(R(x), s) R (x, a, s)).

(51)

following use following facts.
|=Holds(R(x), s) iff I| 6|= Holds(R(x), s).
F ground formula contain , |= F iff I| |= F .
Left Right: Assume |= (49) (50).
Case 1: I| |= Holds(R(x), do(a, s)). Clearly, |= Holds(R(x), do(a, s)), that,
(49), two subcases consider.
Subcase 1: |= +
R (x, a, s). Clearly, I| satisfies LHS RHS (51).
Subcase 2: |= Holds(R(x), s). (50), follows 6|=
R (x, a, s),
(x,
a,
s).
Clearly,
I|
satisfies

LHS

RHS (51).
consequently, I| 6|=

R
Case 2: I| 6|= Holds(R(x), do(a, s)). follows (49) 6|= +
R (x, a, s),
(x,
a,
s).
Also
since

|=Holds(R(x),
do(a, s)),
equivalent saying I| 6|= +
R
(50), two subcases consider.
Subcase 1: |=
R (x, a, s). Clearly, I| satisfies neither LHS RHS (51).
Subcase 2: |= Holds(R(x), s). equivalent saying I| 6|=
Holds(R(x), s). Clearly, I| satisfies neither LHS RHS (51).
Right Left: Assume I| |= (51).
Case 1: |= Holds(R(x), do(a, s)). follows (51) I| satisfies RHS (51),
two subcases consider.
Subcase 1: I| |= +
R (x, a, s). Clearly, satisfies LHS RHS (49).
Also (45), follows 6|=
R (x, a, s). Consequently, satisfies neither
LHS RHS (50).
Subcase 2: I| |= Holds(R(x), s)
R (x, a, s). Clearly, satisfies LHS
RHS (49). Since 6|=
(x,
a,
s),

satisfies neither LHS RHS (50).
R
Case 2: |=Holds(R(x), do(a, s)). follows (51) I| 6|= +
R (x, a, s),
I| 6|= (Holds(R(x), s)
(x,
a,
s)).


latter,
consider

two
subcases.
R
612

fiReformulating Situation Calculus Event Calculus

Subcase 1: I| 6|= Holds(R(x), s). Clearly, satisfies neither LHS RHS
(49), satisfies LHS RHS (50).
Subcase 2: I| 6|=
R (x, a, s). Clearly, satisfies neither LHS RHS (49),
satisfies LHS RHS (50).

C.7 Proof Proposition 2
Lemma 5 Let F formula, let p list distinct predicate constants, let G
subformula F let G0 formula classically equivalent G. Let F 0
formula obtained F substituting G0 G. occurrence G subformula
F negative p occurrence G0 subformula F 0 negative
p,
SM[F ; p] SM[F 0 ; p]
logically valid.
Proof. Let F formula obtained F prepending G, let (F 0 )
formula obtained F 0 prepending G0 . Theorem Double
Negations (Theorem 14), following formulas logically valid.
SM[F ; p] SM[F ; p],
SM[F 0 ; p] SM[(F 0 ) ; p].
Lemma 1, follows
(u p (G G0 )) ((F ) (u) ((F 0 ) ) (u))
logically valid, u list predicate variables corresponding p. Consequently,
SM[F ; p] SM[(F 0 ) ; p]
logically valid.



Proof Proposition 2. formula
SM[F 0 xy(G(y, x) q(x)); p, q],

(52)

clearly, F 0 negative q xy(G(y, x) q(x)) negative p. Let H
subformula F negative p contains occurrence yG(y, x). Consider
two cases.
Case 1: occurrence yG(y, x) H strictly positive. Thus dependency
graph F 0 xy(G(y, x) q(x)) relative {p, q} incoming edges q.
Case 2: occurrence yG(y, x) H strictly positive. Since H negative p, yG(y, x) negative p well, dependency graph
F 0 xy(G(y, x) q(x)) relative {p, q} outgoing edges q.
613

fiLee & Palla

Therefore, every strongly connected component dependency graph belongs either
p {q}. Consequently, Theorem 13, (52) equivalent
SM[F 0 ; p] SM[xy(G(y, x) q(x)); q]

(53)

Since yG(y, x) negative q, formula xy(G(y, x) q(x)) tight {q}. Theorem 15, (53) equivalent
SM[F 0 ; p] x(yG(y, x) q(x)).

(54)

Lemma 5, follows (54) equivalent
SM[F ; p] x(yG(y, x) q(x)).
Consequently, claim follows.



C.8 Proof Theorem 6
clear algorithm terminates yields quantifier-free formula K.
prove SM[F ; p] SM[xK; p q], x list (free) variables K.
Let F formula obtained initial formula F prepending double
negations front every maximal strictly positive occurrence formulas form
yG(x, y). Since F almost universal relative p, occurrence subformula
F negative p. Thus Theorem Double Negations (Theorem 14),
SM[F ; p] equivalent SM[F ; p]. Note F contains strictly positive occurrence
formulas form yG(x, y).
iteration, let us assume formula iteration
H0 Hn ,
H0 transformed F previous iterations, Hi (i > 0)
formula form G(x, y) pG (x) introduced Step (b). Initially H0 F
n = 0. Let r0 p, let ri pG Hi (i > 0). induction prove

(i) every positive occurrence formulas form yG(x, y) Hi strictly positive, subformula Hi negative ri ;
(ii) every negative occurrence formulas form yG(x, y) Hi subformula
Hi negative ri .
prove Step (a) Step (c) applied turn Hk Hk0 ,
SM[x0 H0 ; r0 ] SM[xn Hn ; rn ]

(55)

SM[x00 H00 ; r0 ] SM[x0n Hn0 ; rn ],

(56)

equivalent
Hj0 = Hj j different k, xi (i 0) list free variables
Hi , x0i (i 0) list free variables Hi0 .
614

fiReformulating Situation Calculus Event Calculus

Indeed, Step (a) part prenex form conversion, preserves strong equivalence
(Theorem 5). clear (55) equivalent (56).
Step (c) applied turn (55) (56), since yH(x, y) subformula
Hk negative rk , equivalence (55) (56) follows Lemma 5.
Step (b) applied turn Hk Hk0 introduces new conjunctive term
0
Hn+1 , formula (55) (, r1 , . . . , rn )-equivalent
0
SM[x00 H00 ; r0 ] SM[x0n Hn0 ; rn ] SM[x0n+1 Hn+1
; rn+1 ]

(57)

Proposition 2 due condition (i).
Let
00
H000 Hm

(58)

final quantifier-free formula, H000 transformed F . induction,
follows SM[F ; p] -equivalent
00
SM[x000 H000 ; r0 ] SM[x00m Hm
; rm ],

(59)

x00i (0 m) list free variables Hi00 .
Since every non-strictly positive occurrence new predicate ri (i > 0) Hj00 (0
j m) positive, incoming edge ri dependency graph (58) relative
r0 , r1 , . . . , rm . Consequently, every strongly connected component dependency
graph belongs one ri (i 0). Moreover, clear Hi00 (i 0) negative
every rj j 6= i. (In case H000 , recall occurrence rj j > 0
strictly positive since F , H000 obtained, contains strictly positive
occurrence formulas form yG(x, y).) Thus splitting theorem (Theorem 13),
formula (59) equivalent
00
SM[x000 H000 x00m Hm
; r0 rm ].

(60)


C.9 Proof Theorem 7
use notations introduced proof Theorem 6. Theorem 6, SM[F ; p]
-equivalent (60) and, Theorem 12, (60) equivalent
00
SM[x000 H000 x00m Hm
Choice( pred \ p); pred r1 rm ]

(61)

(r0 p), pred set predicate constants signature . follows
Proposition 3 (Cabalar et al., 2005) (61) equivalent
000
SM[x000 H0000 x00m Hm
Choice( pred \ p); pred r1 rm ],

(62)

Hi000 obtained Hi00 applying translation (Cabalar et al., 2005,
Section 3) turns quantifier-free formula set rules. easy see F 0
formula
000
x000 H0000 x00m Hm
Choice( pred \ p)

615

fiLee & Palla

pred r1 rm p pr (F 0 ), (62) written
SM[F 0 ; p pr (F 0 )],
equivalent
SM[F 0 False(p \ pr (F 0 ))].
Proposition 1.



C.10 Proof Theorem 8
Assume
CIRC[; Initiates, Terminates, Releases] CIRC[; Happens]
CIRC[; Ab 1 , . . . , Ab n ] ,
equivalent
SM[; Initiates, Terminates, Releases] SM[; Happens]
SM[; Ab 1 , . . . , Ab n ]

(63)

Theorem 2.
Let def set definitions (35) , let 0 formula obtained
applying Step 1. Theorem 15, follows formula (35) def equivalent

SM[x(G0 p(x)); p],
G0 described Step 1. Consequently, (63) equivalent
SM[; Initiates, Terminates,
V Releases] SM[; Happens]
SM[; Ab 1 , . . . , Ab n ] (35)def SM[x(G0 p(x)); p] 00 ,

(64)

00 conjunction axioms 0 ones obtained
definitional axioms (35).
Applying Theorem 13 repeatedly, follows (64) equivalent
V
SM[ 00 (35)def x(G0 p(x));
Initiates, Terminates, Releases, Happens, Ab 1 , . . . , Ab n , p] .

(65)

According syntax event calculus reviewed Section 3.1,
every positive occurrence formula form yG(y) (65) contained
subformula negative
{Initiates, Terminates, Releases, Happens, Ab 1 , . . . , Ab n , p},
negative occurrences formula form yG(y) (65).
Consequently, statement theorem follows Theorem 7.

616



fiReformulating Situation Calculus Event Calculus

C.11 Proof Theorem 9
Since (37) almost universal relative {Caused , Poss, Sit}, result follows Theorems 7 3.

C.12 Proof Theorem 10
Dexogenous0 , follows SM[T ; Holds, Holds, Poss] equivalent
SM[T ; Holds, Holds, Poss], obtained prepending
occurrences Holds DS0 . definition uniform formula (Reiter, 2001),
follows almost universal relative {Holds, Holds, Poss}. result follows
Theorem 7.


References
Akman, V., Erdogan, S., Lee, J., Lifschitz, V., & Turner, H. (2004). Representing Zoo
World Traffic World language Causal Calculator. Artificial
Intelligence, 153(12), 105140.
Belleghem, K. V., Denecker, M., & Schreye, D. D. (1995). Combining situation calculus
event calculus. Proceedings International Conference Logic Programming
(ICLP), pp. 8397.
Belleghem, K. V., Denecker, M., & Schreye, D. D. (1997). relation situation
calculus event calculus. Journal Logic Programming, 31 (1-3), 337.
Besnard, P., & Cordier, M.-O. (1994). Explanatory diagnoses characterization
circumscription. Annals Mathematics Artificial Intelligence, 11 (1-4), 7596.
Cabalar, P., & Ferraris, P. (2007). Propositional theories strongly equivalent logic
programs. Theory Practice Logic Programming, 7 (6), 745759.
Cabalar, P., Pearce, D., & Valverde, A. (2005). Reducing propositional theories equilibrium logic logic programs. Proceedings Portuguese Conference Artificial
Intelligence (EPIA), pp. 417.
Calimeri, F., Cozza, S., Ianni, G., & Leone, N. (2008). Computable functions ASP: theory
implementation. Proceedings International Conference Logic Programming (ICLP), pp. 407424.
Denecker, M., & Ternovska, E. (2007). Inductive situation calculus. Artificial Intelligence,
171 (5-6), 332360.
Denecker, M., & Ternovska, E. (2008). logic nonmonotone inductive definitions. ACM
Transactions Computational Logic, 9 (2).
Doherty, P., Gustafsson, J., Karlsson, L., & Kvarnstrom, J. (1998). TAL: Temporal action
logics language specification tutorial. Linkoping Electronic Articles Computer
Information Science ISSN 1401-9841, 3 (015). http://www.ep.liu.se/ea/cis/
1998/015/.
617

fiLee & Palla

Dogandag, S., Ferraris, P., & Lifschitz, V. (2004). Almost definite causal theories..
Proceedings International Conference Logic Programming Nonmonotonic
Reasoning (LPNMR), pp. 7486.
Erdem, E., & Lifschitz, V. (2003). Tight logic programs. Theory Practice Logic
Programming, 3, 499518.
Fages, F. (1994). Consistency Clarks completion existence stable models. Journal
Methods Logic Computer Science, 1, 5160.
Ferraris, P., Lee, J., & Lifschitz, V. (2007). new perspective stable models. Proceedings International Joint Conference Artificial Intelligence (IJCAI), pp. 372379.
Ferraris, P., Lee, J., & Lifschitz, V. (2011). Stable models circumscription. Artificial
Intelligence, 175, 236263.
Ferraris, P., Lee, J., Lifschitz, V., & Palla, R. (2009). Symmetric splitting general
theory stable models. Proceedings International Joint Conference Artificial
Intelligence (IJCAI), pp. 797803.
Gebser, M., Schaub, T., & Thiele, S. (2007). Gringo : new grounder answer set
programming. Proceedings International Conference Logic Programming
Nonmonotonic Reasoning (LPNMR), pp. 266271.
Gelfond, M., & Lifschitz, V. (1988). stable model semantics logic programming.
Kowalski, R., & Bowen, K. (Eds.), Proceedings International Logic Programming
Conference Symposium, pp. 10701080. MIT Press.
Gelfond, M., & Lifschitz, V. (1998). Action languages. Electronic Transactions Artificial
Intelligence, 3, 195210. http://www.ep.liu.se/ea/cis/1998/016/.
Giunchiglia, E., Lee, J., Lifschitz, V., McCain, N., & Turner, H. (2004). Nonmonotonic
causal theories. Artificial Intelligence, 153(12), 49104.
Heyting, A. (1930). Die formalen Regeln der intuitionistischen Logik. Sitzungsberichte
der Preussischen Akademie von Wissenschaften. Physikalisch-mathematische Klasse,
4256.
Janhunen, T., & Oikarinen, E. (2004). Capturing parallel circumscription disjunctive
logic programs. Proc. 9th European Conference Logics Artificial Intelligence
(JELIA-04), pp. 134146.
Kautz, H., & Selman, B. (1992). Planning satisfiability. Proceedings European
Conference Artificial Intelligence (ECAI), pp. 359363.
Kim, T.-W., Lee, J., & Palla, R. (2009). Circumscriptive event calculus answer set programming. Proceedings International Joint Conference Artificial Intelligence
(IJCAI), pp. 823829.
Kowalski, R., & Sergot, M. (1986). logic-based calculus events. New Generation
Computing, 4, 6795.
Kowalski, R. A., & Sadri, F. (1997). Reconciling event calculus situation
calculus. Journal Logic Programming, 31 (1-3), 3958.
618

fiReformulating Situation Calculus Event Calculus

Lee, J., Lifschitz, V., & Palla, R. (2008). reductive semantics counting choice
answer set programming. Proceedings AAAI Conference Artificial
Intelligence (AAAI), pp. 472479.
Lee, J., & Lin, F. (2006). Loop formulas circumscription. Artificial Intelligence, 170 (2),
160185.
Lee, J., & Meng, Y. (2011). First-order stable model semantics first-order loop formulas.
Journal Artificial Inteligence Research (JAIR), 42, 125180.
Lee, J., & Palla, R. (2007). Yet another proof strong equivalence propositional
theories logic programs. Working Notes Workshop Correspondence
Equivalence Nonmonotonic Theories.
Lee, J., & Palla, R. (2010). Situation calculus answer set programming. Proceedings
AAAI Conference Artificial Intelligence (AAAI), pp. 309314.
Lifschitz, V. (1994). Circumscription. Gabbay, D., Hogger, C., & Robinson, J. (Eds.),
Handbook Logic AI Logic Programming, Vol. 3, pp. 298352. Oxford University Press.
Lifschitz, V. (2008). answer set programming?. Proceedings AAAI Conference Artificial Intelligence, pp. 15941597. MIT Press.
Lifschitz, V. (2011). Datalog programs stable models. de Moor, O., Gottlob,
G., Furche, T., & Sellers, A. (Eds.), Datalog Reloaded: First International Workshop,
Datalog 2010, Oxford, UK, March 16-19, 2010. Revised Selected Papers. Springer.
Lifschitz, V., Pearce, D., & Valverde, A. (2001). Strongly equivalent logic programs. ACM
Transactions Computational Logic, 2, 526541.
Lifschitz, V., Tang, L. R., & Turner, H. (1999). Nested expressions logic programs. Annals
Mathematics Artificial Intelligence, 25, 369389.
Lifschitz, V., & Turner, H. (1999). Representing transition systems logic programs.
Proceedings International Conference Logic Programming Nonmonotonic
Reasoning (LPNMR), pp. 92106.
Lin, F. (1995). Embracing causality specifying indirect effects actions. Proceedings International Joint Conference Artificial Intelligence (IJCAI), pp. 1985
1991.
Lin, F. (2003). Compiling causal theories successor state axioms STRIPS-like systems. Journal Artificial Intelligence Research, 19, 279314.
Lin, F., & Shoham, Y. (1992). logic knowledge justified assumptions. Artificial
Intelligence, 57, 271289.
Lin, F., & Wang, K. (1999). causal theories logic programs (sometimes).
Proceedings International Conference Logic Programming Nonmonotonic
Reasoning (LPNMR), pp. 117131.
Lin, F., & Zhou, Y. (2011). answer set logic programming circumscription via logic
GK. Artificial Intelligence, 175, 264277.
619

fiLee & Palla

Marek, V., & Truszczynski, M. (1999). Stable models alternative logic programming
paradigm. Logic Programming Paradigm: 25-Year Perspective, pp. 375398.
Springer Verlag.
McCarthy, J. (1980). Circumscriptiona form non-monotonic reasoning. Artificial Intelligence, 13, 2739,171172.
McCarthy, J. (1986). Applications circumscription formalizing common sense knowledge. Artificial Intelligence, 26 (3), 89116.
McCarthy, J., & Hayes, P. (1969). philosophical problems standpoint
artificial intelligence. Meltzer, B., & Michie, D. (Eds.), Machine Intelligence, Vol. 4,
pp. 463502. Edinburgh University Press, Edinburgh.
Miller, R., & Shanahan, M. (1999). event calculus classical logic - alternative axiomatisations. Electronic Transactions Artificial Intelligence, 3 (A), 77105.
Mueller, E. (2006). Commonsense reasoning. Morgan Kaufmann.
Mueller, E. T. (2004). Event calculus reasoning satisfiability. Journal Logic
Computation, 14 (5), 703730.
Niemela, I. (1999). Logic programs stable model semantics constraint programming
paradigm. Annals Mathematics Artificial Intelligence, 25, 241273.
Pearce, D., & Valverde, A. (2005). first order nonmonotonic extension constructive
logic. Studia Logica, 80, 323348.
Provetti, A. (1996). Hypothetical reasoning actions: situation calculus event
calculus. Computational Intelligence, 12, 478498.
Reiter, R. (1980). logic default reasoning. Artificial Intelligence, 13, 81132.
Reiter, R. (1991). frame problem situation calculus: simple solution (sometimes) completeness result goal regression. Lifschitz, V. (Ed.), Artificial
Intelligence Mathematical Theory Computation: Papers Honor John McCarthy, pp. 359380. Academic Press.
Reiter, R. (2001). Knowledge Action: Logical Foundations Specifying Implementing Dynamical Systems. MIT Press.
Shanahan, M. (1995). circumscriptive calculus events. Artif. Intell., 77 (2), 249284.
Shanahan, M. (1997). Solving Frame Problem: Mathematical Investigation
Common Sense Law Inertia. MIT Press.
Shanahan, M. (1999). event calculus explained. Artificial Intelligence Today, LNCS
1600, pp. 409430. Springer.
Shanahan, M., & Witkowski, M. (2004). Event calculus planning satisfiability.
Journal Logic Computation, 14 (5), 731745.
Syrjanen, T. (2004). Cardinality constraint programs.. Proceedings European Conference Logics Artificial Intelligence (JELIA), pp. 187199.
Zhang, H., Zhang, Y., Ying, M., & Zhou, Y. (2011). Translating first-order theories logic
programs. Proceedings International Joint Conference Artificial Intelligence
(IJCAI), pp. 11261131.

620

fiJournal Artificial Intelligence Research 43 (2012) 353388

Submitted 10/11; published 03/12

Computing All-Pairs Shortest Paths
Leveraging Low Treewidth
Leon Planken
Mathijs de Weerdt

l.r.planken@tudelft.nl
m.m.deweerdt@tudelft.nl

Faculty EEMCS, Delft University Technology,
Delft, Netherlands

Roman van der Krogt

roman@4c.ucc.ie

Cork Constraint Computation Centre,
University College Cork, Cork, Ireland

Abstract
present two new efficient algorithms computing all-pairs shortest paths.
algorithms operate directed graphs real (possibly negative) weights. make use
directed path consistency along vertex ordering d. algorithms run n2 wd
time, wd graph width induced vertex ordering. graphs constant
treewidth, yields n2 time, optimal. chordal graphs, algorithms
run (nm) time. addition, present
variant exploits graph separators

arrive run time nwd2 + n2 sd general graphs, sd wd size
largest minimal separator induced vertex ordering d. show empirically
constructed realistic benchmarks, many cases algorithms outperform
FloydWarshalls well Johnsons
algorithm,
represent current state


art run time n3 nm + n2 log n , respectively. algorithms
used spatial temporal reasoning, Simple Temporal Problem,
underlines relevance planning scheduling community.

1. Introduction
Finding shortest paths important fundamental problem communication
transportation networks, circuit design, bioinformatics, Internet node traffic, social networking, graph analysis generale.g. computing betweenness (Girvan & Newman, 2002)and sub-problem many combinatorial problems,
represented network flow problem. particular, context planning
scheduling, finding shortest paths important solve set binary linear constraints
events, i.e. Simple Temporal Problem (STP; Dechter, Meiri, & Pearl, 1991).
STP turn appears sub-problem NP-hard Temporal Constraint Satisfaction
Problem (TCSP; Dechter et al., 1991) Disjunctive Temporal Problem (DTP; Stergiou
& Koubarakis, 2000), powerful enough model e.g. job-shop scheduling problems. shortest path computations applications account significant
part total run time solver. Thus, hardly surprising topics received substantial interest planning scheduling community (Satish Kumar, 2005;
Bresina, Jonsson, Morris, & Rajan, 2005; Rossi, Venable, & Yorke-Smith, 2006; Shah &
Williams, 2008; Conrad, Shah, & Williams, 2009).
c
2012
AI Access Foundation. rights reserved.

fiPlanken, De Weerdt, & Van der Krogt

Instances STP, called Simple Temporal Networks (STNs), natural representation directed graphs real edge weights. Recently, specific interest
STNs stemming hierarchical task networks (HTNs; Castillo, Fernandez-Olivares,
& Gonzalez, 2006; Bui & Yorke-Smith, 2010). graphs sibling-restricted
property: task, represented pair vertices, connected sibling tasks,
parent children. graphs number children task restricted
constant branching factor, therefore resulting STNs also tree-like structure.
canonical way solving STP instance (Dechter et al., 1991) computing
all-pairs shortest paths (APSP) STN, thus achieving full path consistency.
graphs n vertices edges, done n3 time FloydWarshall
algorithm (Floyd, 1962), based Warshalls (1962) formulation efficiently computing
transitive closure Boolean matrices. However, state art computing APSP
sparse graphs algorithm based technique originally proposed Johnson
(1977), preprocessing allow n runs Dijkstras (1959) algorithm. Using
Fibonacci heap (Fredman & Tarjan, 1987), algorithm runs n2 log n + nm time.
remainder paper, refer algorithm Johnson.
paper present two new algorithms APSP real edge weights (in Section 3). One algorithm, dubbed ChleqAPSP, based point-to-point shortest path
algorithm Chleq (1995); other, named Snowball, similar Planken, de Weerdt,
van der Krogts (2008) algorithm enforcing partial (instead full) path consistency (P3 C). new algorithms advance state art computing APSP.
graphs constant treewidth, sibling-restricted STNs based HTNs
con
2
stant branching factor, run time
algorithms bounded n ,
optimal since output n2 . addition STNs, examples graphs
constant treewidth outerplanar graphs, graphs bounded bandwidth, graphs
bounded cutwidth, series-parallel graphs (Bodlaender, 1986).
ChleqAPSP Snowball applied chordal graphs, run time
(nm), strict improvement
state art (Chaudhuri & Zaroliagis,

2000, run time nmwd2 ; wd defined below). Chordal graphs important
subset general sparse graphs: interval graphs, trees, k-trees split graphs special
cases chordal graphs (Golumbic, 2004). Moreover, graph made chordal using
so-called triangulation algorithm. algorithm operates eliminating vertices one
one, connecting neighbours eliminated vertex thereby inducing cliques
graph.
induced width wd vertex ordering defined equal cardinality
largest set neighbours encountered. upper
bound run time
proposed algorithms general graphs, n2 wd , depends induced
width. Finding vertex ordering minimum induced width, however, NP-hard
problem (Arnborg, Corneil, & Proskurowski, 1987). minimum induced width
tree-likeness property graph mentioned above, i.e. treewidth, denoted w .
contrast, induced width direct measure input (graph), bound
n2 wd quite proper. Still, better bound Johnson wd (log n).1
1. prefer write x (f (n)) instead common x = (f (n)). Formally, right-hand
side represents set functions grow strictly slower f (n), traditional equality
fact works one direction (see also Graham, Knuth, & Patashnik, 1989, Section 9.2).

354

fiComputing APSP Leveraging Low Treewidth


see this, note bound Johnson never better n2 log n , regardless
value m.
paper, also present variant Snowball exploits graph separators
attains upper bound run time nwd2 + n2 sd . upper bound even
better one two new algorithms, since sd wd size largest
minimal separator induced vertex ordering d. theoretical bounds run
time usually give good indication performance algorithms, see especially
last variant always predict algorithm best settings.
Section 4, therefore, experimentally establish computational efficiency
proposed algorithms wide range graphs, varying random scale-free networks
parts road network New York City, STNs generated HTNs job-shop
scheduling problems.
Below, first give detailed introduction required concepts,
induced width, chordal graphs triangulation, present new algorithms
analysis.

2. Preliminaries
section, briefly introduce algorithm enforces directed path consistency (DPC) find vertex ordering required algorithm.
present algorithms all-pairs shortest paths, require enforcing DPC (or
stronger property) first step. treatment, assume weights edges
graph real possibly negative.
2.1 Directed Path Consistency
Dechter et al. (1991) presented DPC, included Algorithm 1, way check whether
STP instance consistent.2 equivalent checking graph
contain negative cycle (a closed path negative total weight). algorithm takes
input weighted directed graph G = hV, Ei vertex ordering d, bijection
V natural numbers {1, . . . , n}. paper, simply represent ith
vertex ordering natural number i. (possibly negative) weight
arc j represented wij R. shorthand existence arc
vertices, either direction, {i, j} E. Finally, denote Gk graph
induced vertices {1, . . . , k}; likewise, set vertices V 0 V , GV 0 denotes graph
induced V 0 . So, particular, GV = Gn = G.
iteration k, algorithm adds edges (in line 5) pairs lower-numbered
neighbours i, j k, thus triangulating graph. Moreover, lines 3 4, updates
edge j weight paths k j j k i, shorter.
Consequently, < j, defining property DPC ensures wij higher
total weight path j consists vertices outside Gj (except
j themselves). implies particular running DPC, w12 w21
labelled shortest paths vertices 1 2.
2. Note algorithmssuch BellmanFordcan used purpose well, usually
perform better practice.

355

fiPlanken, De Weerdt, & Van der Krogt

Algorithm 1: DPC (Dechter et al., 1991)
Input: Weighted directed graph G = hV, Ei; vertex ordering : V {1, . . . , n}
Output: DPC version G, inconsistent G contains negative cycle

10

k n 1
forall < j < k {i, k} , {j, k} E
wij min {wij , wik + wkj }
wji min {wji , wjk + wki }
E E {{i, j}}
wij + wji < 0
return inconsistent
end
end
end

11

return G = hV, Ei

1
2
3
4
5
6
7
8
9

run time DPC depends measure wd called induced width relative
ordering vertices. Dechter et al. (1991) define induced width vertex
ordering procedurally exactly highest number neighbours j k j < k
encountered DPC algorithm. includes neighbours original graph (i.e.
{j, k} E) well vertices became neighbours edges added
earlier iteration algorithm. However, definition based original
graph vertex ordering, making use following result.
Proposition 1. Suppose G = hV, Ei undirected graph : V {1, . . . , n}
(where bijection) vertex ordering. Suppose given n sets
edges Ek0 1 k n, defined follows:


Ek0 = {j, k} V | j < k path k j G{j}{k,k+1,...,n}
Then, Ek0 exactly set edges visited iteration k DPC.
Proof. Note definition, set Ek0 superset original edges
vertex k lower-numbered neighbours. use fact prove equivalence
induction.
equivalence holds first iteration k = n, En0 exactly set
original edges vertex n lower-numbered neighbours, earlier
iterations DPC may added edges {j, k} j < k. Now, assuming
equivalence holds sets E`0 ` > k, show also holds Ek0 .
inductive case, prove inclusion relations separately.
() reach contradiction, assume exists edge {j, k} 6 Ek0 , j < k,
visited DPC iteration k. Ek0 includes original edges
k lower-numbered neighbours, must new edge added earlier
iteration ` > k, must exist edges {j, `} , {k, `} E`0 . induction hypothesis,
j k therefore connected induced subgraph G{j,k}{`,`+1,...,n} .
356

fiComputing APSP Leveraging Low Treewidth

must also connected larger subgraph G{j}{k,k+1,...n} thus definition
included Ek0 : contradiction.
() Assume, reaching contradiction, exists edge {j, k} Ek0
part E iteration k DPC therefore visited algorithm. Clearly,
{j, k} cannot one original edges. definition Ek0 must therefore
exist path least one intermediate vertex j k induced subgraph
G{j}{k,k+1,...n} . Let ` lowest-numbered vertex j k path;
` > k > j. Then, induction hypothesis, must exist edges
{j, `} , {k, `} E`0 , visited DPC iteration `. more,
reach contradiction, since DPC must added {j, k} E iteration ` > k.
formally define induced width follows, conclude Proposition 1
equivalent original procedural definition.
Definition 1. Given undirected graph G = hV, Ei, vertex ordering d, n sets
edges Ek0 Proposition 1, induced width wd G (relative d) following
measure:
fi fi
wd = max fiEk0 fi
kV

follows run time DPC property graph per se; rather,
dependent graphand vertex ordering used. careful implementation,
DPCs time bound nwd2 ordering known beforehand.
edges added DPC called fill edges make graph chordal (sometimes
also called triangulated). Indeed, DPC differs triangulation procedure
manipulation arc weights. chordal graph, every cycle length four
edge joining two vertices adjacent cycle. Definition 1, number
edges chordal graph, denoted mc m, (nwd ). give formal
definitions concepts.


Definition 2. Given graph G = hV, Ei set v 1 , v 2 , . . . , v k V vertices
form cycle G, chord
cycle edge non-adjacent vertices
cycle, i.e. edge v , v j E 1 < j < k 1. graph G = hV, Ei called chordal
cycles size larger 3 chord.
Definition 3. Given graph G = hV, Ei, triangulation G, E = ,
set edges G0 = hV, E chordal. edges called fill edges.
minimal triangulation G exists proper subset 0 0
triangulation G.
2.2 Finding Vertex Ordering
principle, DPC use vertex ordering make graph chordal directionally path-consistent. However, since vertex ordering defines induced width,
directly influences run time number edges mc resulting graph. mentioned introduction, finding ordering minimum induced width wd = w ,
even determining treewidth w , NP-hard problem general. Still,
class constant-treewidth graphs recognised, optimally triangulated, (n)
357

fiPlanken, De Weerdt, & Van der Krogt

time (Bodlaender, 1996). G already chordal, find perfect ordering (resulting fill edges) (m) time, using e.g. maximal cardinality search (MCS; Tarjan &
Yannakakis, 1984). perfect ordering also called simplicial ordering, every vertex k together lower-numbered neighbours ordering induces clique
(simplex) subgraph Gk . implies following (known) result, relating induced
width treewidth size largest clique G.
Proposition 2. graph G chordal, size largest clique exactly w + 1.
non-chordal graph G triangulated along vertex ordering d, yielding chordal graph G0 ,
size largest clique G0 exactly wd + 1. treewidth G0 equals wd
upper bound treewidth original graph G: w wd .
general graphs, various heuristics exist often produce good results. mention
minimum degree heuristic (Rose, 1972), iteration chooses vertex
lowest degree. Since ordering produced heuristic fully known
DPC starts depends fill edges added, adjacency-list-based implementation
require another (log n) factor DPCs time bound. However, purposes
article, afford
comfort maintaining adjacency matrix, yields bounds

n2 + nwd2 time n2 space.

3. All-Pairs Shortest Paths
Even though, best knowledge, DPC-based APSP algorithm yet
proposed, algorithms computing single-source shortest paths (SSSP) based DPC
obtained known results relatively straightforward manner. Chleq (1995)
proposed point-to-point shortest path algorithm trivial adaptation computes
SSSP; Planken, de Weerdt, Yorke-Smith (2010) implicitly also compute SSSP part
IPPC algorithm. algorithms run (mc ) time thus
simply run
2
vertex yield APSP algorithm (nmc ) n wd time complexity.
Below, first show adapt Chleqs algorithm compute APSP; then, present
new, efficient algorithm named Snowball relates Planken et al.s (2008) P3 C.
3.1 Chleqs Approach
Chleqs (1995) point-to-point shortest path algorithm simply called Minpath computes shortest path two arbitrary vertices s, V directionally pathconsistent graph G. reproduced Algorithm 2 seen run (mc )
time edge considered twice. shortest distance source
vertex maintained array D; algorithm iterates downward 1
upward 1 t, updating distance array shorter path found.
Since sink vertex used bound second loop, clear
actually contains shortest distances pairs (s, t0 ) t0 t. Therefore,
easily adapt algorithm compute SSSP within (mc ) time bound setting
= n returning entire array instead D[t]. call result ChleqAPSP,
included Algorithm 3, calls SSSP algorithm (referred Minpaths) n times
compute all-pairs shortest paths (nmc ) nwd2 time.
358

fiComputing APSP Leveraging Low Treewidth

Algorithm 2: Minpath (Chleq, 1995)
Input: Weighted directed DPC graph G = hV, Ei;
(arbitrary) source vertex destination vertex
Output: Distance t, inconsistent G contains negative cycle

12

V : D[i]
D[s] 0
k 1
forall j < k {j, k} E
D[j] min {D[j], D[k] + wkj }
end
end
k 1
forall j > k {j, k} E
D[j] min {D[j], D[k] + wkj }
end
end

13

return D[t]

1
2
3
4
5
6
7
8
9
10
11

Algorithm 3: ChleqAPSP
Input: Weighted directed graph G = hV, Ei; vertex ordering : V {1, . . . , n}
Output: Distance matrix D, inconsistent G contains negative cycle
1
2

G DPC(G, d)
return inconsistent DPC

5

1 n
D[i][] Minpaths(G, i)
end

6

return

3
4

359

fiPlanken, De Weerdt, & Van der Krogt

Algorithm 4: Snowball
Input: Weighted directed graph G = hV, Ei; vertex ordering : V {1, . . . , n}
Output: Distance matrix D, inconsistent G contains negative cycle
1
2

G DPC(G, d)
return inconsistent DPC

12

i, j V : D[i][j]
V : D[i][i] 0
k 1 n
forall j < k {j, k} E
forall {1, . . . , k 1}
D[i][k] min {D[i][k], D[i][j] + wjk }
D[k][i] min {D[k][i], wkj + D[j][i]}
end
end
end

13

return

3
4
5
6
7
8
9
10
11

3.2 Snowball Algorithm
section, present algorithm computes APSP (or full path-consistency),
dubbed Snowball included Algorithm 4, asymptotic worst-case time
bounds ChleqAPSP requires strictly less computational work.
Like ChleqAPSP, algorithm first ensures input graph directionally pathconsistent. idea behind algorithm grow, execution
outermost loop, clique {1, . . . , k} computed (shortest) distances, one vertex
time, starting trivial clique consisting vertex 1; DPC performed
backward sweep along d, Snowball iterates direction. adding vertex k
clique, two inner loops ensure compute distances k
vertices < k. works know DPC pair (i, k),
must exist shortest path k form j k (and vice versa),
{j, k} E j < k edge chordal graph. means algorithm
needs look vertices i, j < k, follows inductively D[i][j]
D[j][i] guaranteed correct earlier iteration.
name algorithm derives snowball effect: clique computed
distances grows quadratically course operation. small example
operation Snowball given Figure 1. Originally, graph contained shortest path
4762513. Dashed edges added DPC, path 4213 also
shortest path; particular, w42 holds correct value. snapshot taken
k = 4; shaded vertices 13 already visited shortest distances D[i][j]
computed i, j 3. Then, iteration k = 4, j = 2 = 3,
algorithm sets correct weight D[4][3] taking sum w42 + D[2][3].
Theorem
3. Algorithm 4 ( Snowball) correctly computes all-pairs shortest paths (nmc )
n2 wd time.
360

fiComputing APSP Leveraging Low Treewidth

7
6
5
4
3
2
1

Figure 1: Snapshot (k = 4) graph operation Snowball.

Proof. proof induction. enforcing DPC, w12 w21 labelled
shortest distances vertices 1 2. k = 2 = j = 1, algorithm
sets D[1][2] D[2][1] correct values.
Now, assume D[i][j] set correctly vertices i, j < k. Let : = v0
v1 v`1 v` = k shortest path k, let hmax =
arg maxh{0,1,...,`} {vh }. DPC, 0 < hmax < `, exists path
weight shortcut vhmax 1 vhmax +1 taken. argument repeated
conclude must exist shortest path 0 k lies completely Gk and,
except last arc, Gk1 . Thus, induction hypothesis observation
algorithm considers arcs subgraph Gk1 k, D[i][k] set correct
value. analogous argument holds D[k][i].
regard algorithms time complexity, note two outermost loops
together result mc edges chordal graph visited exactly once.
inner loop always fewer n iterations, yielding run time (nmc ) time.

2
observation mc nwd , also state looser time bound n wd .
briefly discuss consequences two special cases: graphs constant
treewidth chordal graphs. chordal graphs, recognised (m) time,
substitute mc run-time complexity; further, described above,
perfect ordering exists found (m) time. gives total run-time
complexity (nm). Likewise, stated given constant ,
determined (n) time whether graph treewidth w , so, vertex ordering wd = w found within time bound. Then, omitting
constant factor wd , algorithm runs n2 time. also follows algorithms pseudocode noting every vertex k constant number (at w )
neighbours j < k.
note similarity Snowball P3 C algorithm (Planken et al.,
2008), presented below. Like Snowball, P3 C operates enforcing DPC, followed
single

backward sweep along vertex ordering. P3 C computes, nwd2 time, shortest
361

fiPlanken, De Weerdt, & Van der Krogt

Algorithm 5: P 3 C (Planken et al., 2008)
Input: Weighted directed graph G = hV, Ei; vertex ordering : V {1, . . . , n}
Output: PPC version G, inconsistent G contains negative cycle
1
2

G DPC(G, d)
return inconsistent DPC

8

k 1 n
forall i, j < k {i, k} , {j, k} E
wik min {wik , wij + wjk }
wkj min {wkj , wki + wij }
end
end

9

return G

3
4
5
6
7

paths arcs present chordal graph. similarity property chordal
graphs fact prompt us present version Snowball improved time complexity.
3.3 Improving Run-Time Complexity Using Separators

section, present improvement Snowball nwd2 + n2 sd run time,
sd size largest minimal separator chordal graph obtained
triangulation along d.
Definition 4. Given connected graph G = hV, Ei, separator set V 0 V
GV \V 0 longer connected. separator V 0 minimal proper subset V 0
separator.
bound better because, seen below, always holds sd wd . improvement hinges property chordal graphs called partial path consistency (PPC).
partially path-consistent graph, arc labelled length shortest path
endpoints.3 P3 C, presented Algorithm 5, depends DPC computes PPC
nwd2 time, current state art. Then, use clique tree
PPC graph compute shortest path vertices. Figure 2 shows example
chordal graph associated clique tree. clique tree following useful
properties (Heggernes, 2006, Section 3.2).
Property 1. Every chordal graph G = hV, Ei associated clique tree = hC, Si,
constructed linear time (mc ).
Property 2. clique tree node c C associated subset Vc V induces
maximal clique G. Conversely, every maximal clique G associated clique tree
node c C.
Property 3. coherent: vertex v V , clique tree nodes whose associated
cliques contain v induce subtree .
3. Full path-consistency (FPC) achieved arc exists pairs vertices u, v V .

362

fiComputing APSP Leveraging Low Treewidth

(a) Chordal graph

(b) Clique tree

Figure 2: chordal graph clique tree. shaded shape represents maximal
clique graph, containing vertices corners.
Property 4. two clique tree nodes ci , cj C connected edge {ci , cj } S,
Vci Vcj minimal separator G. Conversely, minimal separator V 0 G,
clique tree edge {ci , cj } V 0 = Vci Vcj .
Property
5. vertices appear least one clique associated node , so:

V
=
V
.
cC c
Since Proposition 2 page 358 size largest clique chordal
graph exactly wd + 1, follows Properties 2 4 sd wd .

Now, idea behind SnowballSeparators first compute PPC nwd2 time using
P3 C, traverse clique tree. PPC ensures shortest paths within clique
computed. Then, traversing clique tree arbitrary root node
out, grow set Vvisited vertices cliques whose nodes already traversed.
clique node c C visited traversal, shortest paths vertices
clique Vc vertices Vvisited must run separator Vsep c cs
parent. sd size largest minimal separator G,
pair vertices
2
suffices consider sd alternative routesfor total n sd routes, yielding
stated overall time complexity nwd2 + n2 sd . formally present algorithm based
idea Algorithm 6 associated recursive procedure Processcliquetreenode
(on following page).
Note visit nodes parent visiting node itself, always
holds Vcparent Vvisited . note that, simplicity presentation, assume
graph connected. not, simply find connected components linear
time construct clique tree them.
improved algorithm edge original algorithm separators
small treewidth not. HTN-based sibling-restricted STNs (which described
part experimental validation Section 4.3.5), instance, many separators

size 2. every task many ( n) subtasks every task subtasks

induces clique,
wd ( n) sd = 2, implying SnowballSeparators still

2
optimal n time complexity instances.4
proceed prove algorithm correct meets stated run-time
bounds, introduce following definition.
4. However, since general every task subtasks form clique, low value sd usually
attained practice.

363

fiPlanken, De Weerdt, & Van der Krogt

Algorithm 6: Snowballseparators
Input: Weighted directed graph G = hV, Ei; vertex ordering : V {1, . . . , n}
Output: Distance matrix D, inconsistent G contains negative cycle
1
2
3
4
5
6
7
8
9
10

G P3 C(G, d)
return inconsistent P3 C
i, j V : D[i][j]
V : D[i][i] 0
{i, j} E : D[i][j] wij
{i, j} E : D[j][i] wji
build clique tree = hC, Si G
select arbitrary root node croot C
(D, Vvisited ) Processcliquetreenode(croot , nil, D, )
return

Procedure Processcliquetreenode(c, cparent , D, Vvisited )
Input: Current clique tree node c, cs parent cparent , distance matrix D, set
visited vertices Vvisited
Output: Updated matrix set Vvisited

13

cparent 6= nil
Vnew Vc \ Vcparent
Vsep Vc Vcparent
Vother Vvisited \ Vc
forall (i, j, k) Vnew Vsep Vother
D[i][k] min {D[i][k], D[i][j] + D[j][k]}
D[k][i] min {D[k][i], D[k][j] + D[j][i]}
end
end
Vvisited Vvisited Vc
forall children c0 c
(D, Vvisited ) Processcliquetreenode(c0 , c, D, Vvisited )
end

14

return (D, Vvisited )

1
2
3
4
5
6
7
8
9
10
11
12

364

// recursive call

fiComputing APSP Leveraging Low Treewidth

Definition 5. define distance matrix valid set U vertices, (D, U )
valid pair, pairs vertices (i, j) U U , D[i][j] holds shortest distance
G j.
split correctness proof algorithm three parts: Lemmas 4 5
culminate Theorem 6. first step show Processcliquetreenode called
valid pair (D, U ) clique node c, procedure extends validity
U Vc .
Lemma 4. Consider call procedure Processcliquetreenode with, arguments, clique
node c, cs parent cparent , distance matrix D, set visited vertices Vvisited .
valid Vvisited upon calling, becomes valid Vc Vvisited running lines
18 Processcliquetreenode.
Proof. First, note Property 2, Vc induces clique G. Therefore, edges exist
pair (i, k) vertices Vc , since graph PPC, wik labelled
shortest distance k. Due lines 5 6 main algorithm, also
contains shortest distances, valid Vc .
Now, remains shown pair vertices (i, k) Vc Vvisited
shortest distances D[i][k] D[k][i] set correctly. show case D[i][k];
case analogous.
desired result follows trivially cparent = nil, since procedure called
Vvisited = . Otherwise, let Vnew = Vc \ Vcparent , Vsep = Vc Vcparent Vother = Vvisited \ Vc
set procedure lines 24. either k lies Vsep , correctness D[i][k]s
value already proven, need consider pairs vertices (i, k) Vnew Vother .
pair (i, k), Vsep separator k Property 4,
shortest path k necessarily concatenation shortest paths j
j k, j Vsep . Since follows definitions Vnew , Vsep Vother
(i, j) Vnew Vsep (j, k) Vsep Vother , D[i][j] D[j][k] correctly
set (by validity Vc Vvisited , respectively), loop lines 58 yields
desired result.
next step prove recursive calls, validity fact extended
entire subtree rooted c.
Lemma 5. Consider call procedure Processcliquetreenode with, arguments,
clique node c, cs parent Vcparent , distance matrix D, set visited vertices Vvisited .
0
valid Vvisited upon calling, returned, updated pair (D0 , Vvisited
) also
valid.
Proof. First, note Lemma 4, valid Vvisited update line 10.
Assume clique tree depth d; proof reverse induction
depth clique tree node. c clique tree node depth (i.e. leaf), loop
lines 1113 no-op, immediately obtain desired result.
assume lemma holds nodes depth k let c clique tree
node depth k 1. first call (if any) made child node c0 loop
lines 1113, lemma applied. consequence, returned updated
365

fiPlanken, De Weerdt, & Van der Krogt

pair valid. argument repeated loop ends procedure
returns valid pair.
results disposal, state prove main theorem
section.
Theorem 6. Algorithm
6 ( SnowballSeparators) correctly computes all-pairs shortest paths

nwd2 + n2 sd time.
Proof. Note Vvisited = call Processcliquetreenode line 9 Snowball
Separators; therefore, pair (D, Vvisited ) trivially valid. Lemma 5, call thus
returns valid updated pair (D, Vvisited ). Since Processcliquetreenode recursively traS
versed entire clique tree, Vvisited contains union cC Vc cliques clique
tree = hC, Si, Property 5 equals set vertices G. Therefore,
contains correct shortest paths pairs vertices graph.

time complexity, note initialisations lines 3 4 carried
2
n time, whereas lines 5 6 require (mc ) time. Property 1,
clique tree built linear time (mc ). Since clique tree contains
n nodes,

Processcliquetreenode called (n) times. Line 1 requires wd2 time. implement
lines 24 10 Processcliquetreenode, represent characteristic function
Vvisited array size n; using Vvisited instead Vcparent everywhere, simply
iterate (wd ) members Vc perform required computations.
Now, complexity loop lines 58 remains shown. Note
|Vsep | sd definition, |Vother | < n always. using observation
n vertices graph appears Vnew exactly one invocation Processcliquetree
node (after
becomes staunch member Vvisited ), obtain total time bound
2
n sd loop invocations.
recursive description perhaps easier grasp satisfies claimed
time bounds, found efficiency benefited practice iterative implementation.
also turns good heuristic first visit child nodes connected already
visited subtree large separator, postponing processing children connected
small separator, set visited vertices still small. way, sum
terms |Vsep Vvisited | kept low. implementation, therefore used priority queue
clique nodes ordered separator sizes. Future research must point whether
feasible determine optimal traversal clique tree within given time bounds.
presented new algorithms proven correctness formal complexity, move empirical evaluation performance.

4. Experiments
evaluate two algorithms together efficient implementations FloydWarshall
Johnson Fibonacci heap5 across six different benchmark sets.6
5. Johnson used corrected Fibonacci heap implementation Fiedler (2008), since widely
used pseudocode Cormen, Leiserson, Rivest, Stein (2001) contains mistakes.
6. Available
http://dx.doi.org/10.4121/uuid:49388c35-c7fb-464f-9293-cca1406edccf

366

fiComputing APSP Leveraging Low Treewidth

Table 1: Properties benchmark sets
type
Chordal
Figure 3
Figure 4
Scale-free
Figure 5
Figure 6
New York
Diamonds
Job-shop
HTN

#cases

n



wd

sd

250
130

1,000
2143,125

75,840499,490
22,788637,009

79995
211

79995
211

130
160
170
130
400
121

1,000
2501,000
1083,906
1112,751
171,321
500625

1,99667,360
2,1763,330
1136,422
1112,751
32110,220
7481,599

88864
150200
251
2
3331
2128

80854
138190
240
2
3311
2127

properties test cases summarised Table 1. table lists number
test cases, range number vertices n, edges m, induced width wd produced
minimum degree heuristic, well size largest minimal separators sd
graphs. details different sets found below, one thing
stands immediately sd often equal marginally smaller wd .
However, median size minimum separator less 10 instances except
constructed chordal graphs.
algorithms implemented Java went intensive profiling phase.7
experiments run using Java 1.6 (OpenJDK-1.6.0.b09) server mode, Intel
Xeon E5430 CPUs running 64-bit Linux. Java processes allowed maximum
heap size 4 GB, used default stack size. report measured CPU times,
including time spent running triangulation heuristic ChleqAPSP
Snowball. reported run times averaged 10 runs unique problem instance.
Moreover, generated 10 unique instances parameter setting, obtained using
different random seeds. Thus, reported statistic represents average 100 runs,
unless otherwise indicated. Finally, graph instance ensured contain cycles
negative weight.
4.1 Triangulation
discussed Section 2.2, finding optimal vertex ordering (with minimum induced
width) NP-hard, several efficient triangulation heuristics problem exist.
ran experiments six different heuristics: minimum fill minimum degree
heuristics, static variants (taking account original graph), ordering
produced running maximum cardinality search (MCS) original graph,
random ordering. these, except minimum fill, time complexities within bound
run time ChleqAPSP Snowball. found minimum degree heuristic
gave average induced widths less 1.5% higher found minimum fill,
7. implementations available binary form
http://dx.doi.org/10.4121/uuid:776a266e-81c6-41ee-9d23-8c89d90b6992

367

fiPlanken, De Weerdt, & Van der Krogt

Table 2: summed induced width, triangulation, total run time Snowball
experiments general (non-chordal) graphs show minimum degree heuristic
best choice.
heuristic
min-fill
min-degree
MCS
static min-fill
static min-degree
random

P

wd
321,492
326,222
365,662
388,569
388,707
505,844

triangulation (s)
1,204,384
498
1,520
1,387
1,317
2,436

Snowball (s)

2,047
3,166
3,348
2,746
2,748
5,179

total (s)
1,206,431
3,664
4,868
4,133
4,064
7,615

drastically lower run time. exorbitant time consumption minimum
fill heuristic partially explained fact used LibTW package8
compute ordering, whose implementation probably improved. However,
also known literature theoretical bound minimum fill heuristic
worse minimum degree (Kjrulff, 1990). heuristics
slower minimum degree, also yield induced width least 12% higher, resulting
longer total triangulation time longer total run time Snowball (see summary
results benchmarks given Table 2). Again, confirms Kjrulffs earlier
work. experimental results included therefore show results based
minimum degree heuristic.
4.2 Chordal Graphs
evaluate performance new algorithms chordal graphs, construct chordal
graphs fixed size 1,000 vertices treewidth ranging 79 less
number vertices, thus yielding nearly complete graph high end.
results experiment depicted Figure 3. this, figures, error
bars represent standard deviations measured run time instances
size. graphs induced width three quarters number vertices,
Snowball significantly outperforms FloydWarshall (which yields expected horizontal line),
overall run time new algorithms well Johnson across
entire range. Figure 4 shows run times chordal graphs constant treewidth
increasing number vertices. Here, two new algorithms outperform Johnson
nearly order magnitude (a factor 9.3 Snowball around n = 1300), even
regarding FloydWarshall, confirming expectations based theoretical upper bounds.
4.3 General Graphs

general, non-chordal graphs, expect theoretical analysis nwd2 time ChleqAPSP Snowball algorithms faster Johnson nm + n2 log n
8. Available http://treewidth.com/.

368

fiComputing APSP Leveraging Low Treewidth

100000

time solve (ms, log scale)

F-W
Johnson
Chleq
Snowball

10000

1000

100
100

1000
induced width (log scale)

Figure 3: Run times generated chordal graphs fixed number 1000 vertices
varying treewidth.

1e+06

F-W
Johnson
Chleq
Snowball

time solve (ms, log scale)

100000

10000

1000

100
300

1000
number vertices (log scale)

3000

Figure 4: Run times generated chordal graphs fixed treewidth 211.

369

fiPlanken, De Weerdt, & Van der Krogt

100000
F-W
Johnson
Chleq
Snowball

time solve (ms, log scale)

10000

1000

100

10
100

200

300

400

500
induced width

600

700

800

900

Figure 5: Run times scale-free benchmarks graphs 1,000 vertices varying
induced width.
time bound wd low, Johnson faster sparse graphs (where low)
large induced width wd . main question induced width changeover
occurs. Regarding FloydWarshall n3 bound, expect larger n
always outperformed algorithms.
4.3.1 Scale-Free Graphs
Scale-free networks networks whose degree distribution follows power law. is,
large values k, fraction P (k) vertices network k connections
vertices tends P (k) ck , constant c parameter . words,
vertices many connections many vertices connections.
property found many real-world graphs, social networks
Internet. instances randomly generated Albert Barabasis (2002)
preferential attachment method, iteration new vertex added graph,
attached number existing vertices; higher degree existing
vertex, likely connected newly added vertex. see
induced width Johnson faster, compare run times generated graphs
1,000 vertices. varying number attachments new vertex 2
n/2, obtain graphs induced width ranging 88 866. graphs,
induced width already quite large small attachment values: example,
value 11, induced width already 500.
results experiment found Figure 5. see
induced width 350 (attachment value 5), Snowball efficient. higher
induced widths, Johnson becomes efficient; wd around 800, even FloydWarshall
becomes faster Snowball. consistent observation different angle
made Figure 6, induced width 150 200, number edges
370

fiComputing APSP Leveraging Low Treewidth

time solve (ms, log scale)

10000

F-W
Johnson
Chleq
Snowball

1000

100

300

400

500

600
700
number vertices

800

900

1000

Figure 6: Run times scale-free benchmarks graphs induced widths 150 200
varying vertex count.
2,176 3,330 number vertices varied 250 1,000.
see small graphs 350 vertices, Johnson fastest; Snowball overtakes
it, around 750 vertices ChleqAPSP also faster Johnson (this holds results
sparse graph 1,000 vertices).
Around mark 750 vertices, results show decrease run time
Snowball ChleqAPSP. artifact (preferential attachment) benchmark
generator. Since cannot generate scale-free graphs specific induced width,
modify attachment value instead. turns out, graphs size one
attachment value yields induced width within desired range; graph size
750, width high end interval, whereas graph size 800 near
low end. explains reduced run time larger graph.
scale-free networks, conclude Snowball fastest four algorithms induced width large (at one third number vertices
benchmark set). However, also observe structure scale-free networks
particularly high induced width relatively sparse graphs, exactly
vertices connections. Therefore, Snowball efficient
relatively small attachment values.
4.3.2 Selections New York Road Network
interesting artificially constructed graphs graphs based real networks,
shortest path calculations relevant. first series based road
network New York City, obtained DIMACS challenge website.9
network large (with 264,346 vertices 733,846 edges) decided compute
9. http://www.dis.uniroma1.it/~challenge9/

371

fiPlanken, De Weerdt, & Van der Krogt

Figure 7: Coordinates vertices New York City input graph, examples
extent subgraphs respectively 250, 1000, 5000 vertices.

1e+07
F-W
Johnson
Chleq
Snowball

time solve (ms, log scale)

1e+06

100000

10000

1000

100

10
100

1000
number vertices (log scale)

Figure 8: Run times New York benchmarks subgraphs varying vertex count.

372

fiComputing APSP Leveraging Low Treewidth

shortest paths (induced) subgraphs varying sizes. obtained running
simple breadth-first search random starting location desired number
vertices visited. extent subnetworks thus obtained illustrated
three different sizes Figure 7. results algorithms subgraphs
found Figure 8. observe ranking algorithms chordal
graphs fixed treewidth diamonds: FloydWarshall slowest n3
run time, Johnson, ChleqAPSP, Snowball significantly faster
predecessor. explained considering induced width graphs. Even
largest graphs induced width around 30, considerably smaller
number vertices.
4.3.3 STNs Diamonds
benchmark set based problem instances difference logic proposed Strichman,
Seshia, Bryant (2002) also appearing smt-lib (Ranise & Tinelli, 2003),
constraint graph instance takes form circular chain diamonds.
diamond consists two parallel paths equal length starting single vertex
ending another single vertex. latter vertex, two paths start again, converge
third vertex. pattern repeated diamond chain; final vertex
connected first one. sizes diamond total number
diamonds varied benchmarks.
Problems class actually instances NP-complete Disjunctive Temporal
Problem (DTP): constraints take form disjunction inequalities. DTP
instance, obtain STP instance (i.e. graph) randomly selecting one inequality
disjunction. STP probably inconsistent, constraint graph
contains negative cycle; remedy modifying weights constraint edges.
idea behind procedure structure graph still conforms type
networks one might encounter solving corresponding DTP instance,
run time algorithms mostly depends structure. Moreover, reduce
influence randomized extraction procedure, repeat 10 different seeds.
benchmark set, considered problem instances size
diamonds fixed 5 number varying. interesting property set
graphs generated sparse. ran experiments 130 graphs,
ranging size 111 2751 vertices, induced width 2. induced width
clearly extremely small, translates ChleqAPSP Snowball considerably
faster Johnson FloydWarshall, evidenced Figure 9.
4.3.4 STNs Job-Shop Scheduling
generated 400 graphs job-shop set instance real jobshop problem. instances type available smt-lib (Ranise & Tinelli,
2003), larger range included benchmark collection. obtain
graphs job-shop instances, used extraction procedure described
previous section. striking observation taken Figure 10
difference Johnson two new algorithms quite pronounced,
though Snowball consistently fastest three small margin. fact
373

fiPlanken, De Weerdt, & Van der Krogt

100000
F-W
Johnson
Chleq
Snowball

time solve (ms, log scale)

10000

1000

100

10

1
100

1000
number vertices (log scale)

Figure 9: Run times diamonds benchmarks graphs varying vertex count.

10000

F-W
Johnson
Chleq
Snowball

time solve (ms, log scale)

1000

100

10

1
100
number vertices (log scale)

1000

Figure 10: Run times job-shop benchmarks graphs varying vertex count.

374

fiComputing APSP Leveraging Low Treewidth

margin small likely due structure graphs, also reflected
relatively high induced width. Note also run times FloydWarshall
better graphs 160 vertices, larger graphs algorithms
significantly faster.
4.3.5 STNs HTNs
Finally, consider benchmark set whose instances imitate so-called sibling-restricted
STNs originating Hierarchical Task Networks. set therefore particularly interesting planning point view. graphs, constraints may occur
parent tasks children, sibling tasks (Bui & Yorke-Smith, 2010).
consider extension includes landmark variables (Castillo, Fernandez-Olivares, &
Gonzalez, 2002) mimic synchronisation tasks different parts network, thereby cause deviation tree-like HTN structure. generate
HTNs using following parameters: (i) number tasks initial HTN tree (fixed
250; note tasks start end point), (ii) branching factor, determining
number children task (between 4 7), (iii) depth HTN tree
(between 3 7), (iv) ratio landmark time points number tasks
HTN, varying 0 0.5 step size 0.05, (v) probability constraints
siblings, varying 0 0.5 step size 0.05.
settings result graphs 500 625 vertices, induced widths
varying 2 128. Though induced width seems high light claim
constant, verified wd 2 branching factor + #landmarks + 1
instances. Filling maximal values 7 125 respectively, find upper
bound wd 140, well actual maximum encountered.
Figure 11 shows results experiments function induced widths
graphs. see larger induced widths, Johnson ChleqAPSP
come close. large induced widths found high landmark ratios 0.5.
results indicate majority STNs stemming HTNs, Snowball significantly
efficient Johnson.
4.4 SnowballSeparators
Section 3.3 presented version Snowball improved worst-case run time
vanilla Snowball taking advantage separators graph. section,
discuss results experiments comparing two variants. First, turn
attention benchmark problems regular graphs. results summarised
Figure 12. one see, SnowballSeparators actually performs strictly worse sets
terms run-time performance compared original Snowball.
However, seen Table 1, largest minimal separator often equal
marginally smaller induced width. Even though may
separators large, many may substantially smaller (as noted above,
instances median separator size 10), prompts us run experiments
instances separator sizes artificially kept small. Indeed, found
cases SnowballSeparators shows improvement vanilla Snowball comparing
number update operations performedi.e. lines 8 9 Snowball lines 6 7
375

fiPlanken, De Weerdt, & Van der Krogt

F-W
Johnson
Chleq
Snowball

time solve (ms, log scale)

1000

100

10
0

20

40

60
induced width

80

100

120

Figure 11: Run times HTN benchmarks graphs 500 625 vertices
varying induced width. point average instances induced width within
range [5k, 5k + 4], k. results 5 11 instances per data point.

100000
Snowball
Snowball-Sep

time solve (ms, log scale)

10000

chordal

1000
scale-free

ny
diamonds

100
htn

10
job shop

1
100

1000
number vertices (log scale)

Figure 12: Run times Snowball algorithms benchmark problem sets listed
Table 1.

376

fiComputing APSP Leveraging Low Treewidth

100000

number updates (x1000, log scale)

Snowball
Snowball-Sep
DPC
P3C

10000

1000

100
50

100

150

200

250
300
induced width

350

400

450

Figure 13: Number distance matrix updates chordal instances 512 vertices,
largest minimal separator size 2 varying treewidth. point represents 5
10 instances.
Processcliquetreenode, along lines 3 4 DPC lines 5 6 P3 C. One
case presented Figure 13. describes results collection chordal
graphs 512 vertices, largest minimal separator fixed size 2,
treewidth varied 16 448. figure also includes results DPC P3 C,
respective subroutines Snowball SnowballSeparators. graphs,
SnowballSeparators performs strictly fewer update operations Snowball instances,
although difference becomes smaller induced width increases. number
updates shows distinct improvement Snowball, run times SnowballSeparators
algorithms show improvement. Instead, seen Figure 14,
run times Snowball strictly better SnowballSeparators instances.
Snowball even seen outperform P3 C better theoretical bound;
reason adjacency matrix data structure used Snowball fast,
adjacency list used P3 C, though staying within theoretical bound, inflicts larger
constant factor run time.
experiments, conclude graphs sizes, additional
bookkeeping required SnowballSeparators outweighs potential improvement
number distance matrix updates.
4.5 Proper Upper Bound Run Time
general graphs, run time proposed algorithms depends induced width wd
ordering produced triangulation heuristic. induced width direct
measure input (graph), given upper bound run time quite proper.
arrive proper bound, section aim relate run time treewidth,
denoted w , property input. However, determining treewidth,
377

fiPlanken, De Weerdt, & Van der Krogt

10000

time solve (ms, log scale)

Snowball
Snowball-Sep
DPC
P3C

1000

100

10
50

100

150

200

250
induced width

300

350

400

450

Figure 14: Run times chordal instances 512 vertices, largest minimal separator
size 2 varying treewidth. point represents 5 10 instances.

NP-hard problem, intractable task benchmark problems used. therefore

compare measured induced width wd w , upper bound treewidth, lower
bound x w .10 unaware guarantee quality relative treewidth
either minimum degree triangulation heuristic lower bound used. However,
calculate ratio wd /x get upper bound ratio wd /w .
measure obtain upper bound run time expressed treewidth,
least benchmark problems paper.
results computations found Figure 15, plot ratios
New York, HTN, scale-free job-shop benchmarks function lower
bound x. Using least-squares approach, fitted functions wd (x) = cxk (showing
straight line log-log plot) plotted data points. functions found
fitting, get k = 4.6 New York, k = 2.3 HTN, k = 0.98 job-shop,
small multiplicative constants 0.012 < c < 1.62. one see plotted data
points scale-free instances, amenable fit therefore omit
figure.
decreasing trend job-shop data indicates quality triangulation
(i.e. upper bound represented induced width) gradually increases: lower
upper bound always less factor 2 apart. Indeed, plot line representing
function wd0 (x) = 2x (yielding horizontal line figure), find describes
comfortable upper bound data points benchmark set.
HTN data prompts us plot function wd00 (x) = 25 x2.5 , exponent slightly
higher one found least-squares fit, tweaked slightly
10. lower bound computed LibTW package; see http://treewidth.com/. used
MMD + Least-c heuristic.

378

firelative induced width (vs. lower bound)

Computing APSP Leveraging Low Treewidth

New York
HTN
scale-free
job shop
2x
2
/5x2.5

8

4

2

1
10

100
lower bound treewidth

Figure 15: upper bound induced width relative treewidth determined experimentally comparing lower bound treewidth.
multiplicative coefficient bring view. function plotted represents ample
upper bound HTN benchmarks (as well job-shop ones).
fit data points New York benchmark good trend
points clear, lower bound spans interval
1 4. Therefore, cannot give upper bound set benchmarks
acceptable level confidence.
However, scale-free data points plotted, could fitted function
yielding straight line, mostly follow clear curving trend. hypothesis
behaviour quality upper lower bound deteriorates mostly middle
sizes benchmarks; smaller larger scale-free graphs easier triangulate well.11
give upper bound, could plot line outer hull data points; e.g.
horizontal line represented wd (x) = 8x would work. pessimistic assumption
would choose function highest slope, find upper bound
wd00 (x) = 25 x2.5 , found HTN benchmarks, also works here.
discussion,
may conclude
benchmarks ran except New
Snowball
York, wd (x) x2.5 turn w 2.5 ; run time algorithms

ChleqAPSP instances therefore bounded n2 w 2.5 .
conclude section, remark alternative triangulation heuristic
would use approximation algorithm bound induced width
theoretically determined. example, Bouchitte, Kratsch, Muller, Todinca (2004)
give (log w ) approximation treewidth w . Using approximation
would

give upper bound run time Snowball n2 w log w . However, run
11. mirrors earlier observations authors.

379

fiPlanken, De Weerdt, & Van der Krogt


time obtaining approximate induced width n3 log4 nw 5 log w high
constant well, work isfor nowmainly theoretical value.

5. Related Work
dense, directed
graphs real weights, state-of-the-art APSP algorithms run

3
n / logn time (Chan, 2005; Han, 2008). represent serious improvement
n3 bound FloydWarshall profit fact graphs
occur practice, number edges significantly lower n2 .
profit exactly algorithms sparse graphs aim achieve. Recently,
improvement published nm + n2 log n algorithm based Johnsons (1977)
Fredman Tarjans
(1987) work: algorithm sparse directed graphs running

nm + n2 log log n time (Pettie, 2004). theory, algorithm thus faster
Johnson (in worst cases, large graphs) (n log n).12 However, currently
implementation exists (as confirmed
personal communication Pettie, June

2011). upper bound n2 wd run time Snowball smaller
established upper bound induced width small (i.e. wd (log log n)),
and, course, chordal graphs graphs constant treewidth.
familiar one earlier work compute shortest paths leveraging low
treewidth. Chaudhuri Zaroliagis (2000) present
algorithm answering (point-to

wd3 .
point) shortest path queries wd3 n log n preprocessing time query time

direct extension results APSP would imply run time n2 wd3 general
graphs andO nmwd2 chordal graphs. result computing APSP general graphs
n2 wd (nm) chordal graphs thus strict improvement.
large part state-of-the-art point-to-point shortest paths focused road
networks (with positive edge weights). studies strong focus heuristics, ranging goal-directed search bi-directional search using creating hierarchical
structure, see example (Geisberger, Sanders, Schultes, & Delling, 2008; Bauer, Delling,
Sanders, Schieferdecker, Schultes, & Wagner, 2008). One hierarchical heuristics
similarities idea using chordal graphs. heuristic called contraction.
idea distinguish important (core) vertices, may possible end points,
vertices never used start end point. latter vertices
removed (bypassed) one-by-one, connecting neighbours directly.
restrictions input graphs shortest paths computed also
assumed, sometimes lead algorithms tighter bounds.
example,

unweighted chordal graphs, APSP lengths determined n2 time (Balachandhran
& Rangan, 1996; Han, Sekharan, & Sridhar, 1997) pairs distance two known.
See (Dragan, 2005) overview unification approaches. Considering
planar graphs, recent work shows APSP found n2 log2 n (Klein, Mozes,
&
2
Weimann, 2010), improvement Johnson cases n log n .
context planning scheduling, number similar APSP problems need
computed sequentially, potentially allowing efficient approach using dynamic algorithms. Even Gazit (1985) provide method addition single edge
require n2 steps, deletion n4 /m average. Thorup (2004) Deme12. explain use notation x (f (n)) Footnote 1 page 354.

380

fiComputing APSP Leveraging Low Treewidth

trescu Italiano (2006)
later give alternative approach amortized run time
n2 (log n + log2 n+m
)
. Especially context planning scheduling, esn
sential shortest paths time points maintained. Often, sufficient
shortest paths selection pairs maintained. Above, already mentioned
P3 C algorithm Planken et al. (2008) single-shot case; Planken et al. (2010)
describe algorithm incrementally maintains property partial path consistency
chordal graphs time linear number edges.

6. Conclusions Future Work
paper give three algorithms computing all-pairs shortest paths, run
time bounded (i) n2 graphs constant treewidth, matching earlier results
also required n2 (Chaudhuri & Zaroliagis, 2000);
(ii) (nm) chordal graphs, improving earlier nmwd2 ; (iii) n2 wd general
graphs, showing
2
3
improvement previously known tightest bound n wd . bounds, wd
induced width ordering used; experimentally determined bounded
treewidth power 2.5 benchmarks.
contributions obtained applying directed path consistency combined
known graph-theoretic techniques, vertex elimination tree decomposition,
computing shortest paths. supports general idea techniques may help
solving graphically-representable combinatorial problems, main contribution
article narrow, focusing improving state art single,
important problem computing APSP.
results extensive experiments make recommendations
algorithm best suited type problems. small instances,
FloydWarshall used; probably mostly thanks simplicity, yielding
straightforward implementation low overhead. Snowball exploit fact
perfect elimination ordering efficiently found chordal graphs, makes
efficient algorithm class graphs. experiments different
types general graphs, conclude Snowball consistently outperforms Johnson (and
FloydWarshall), except induced width high. experiments also show
Snowball always outperforms ChleqAPSP SnowballSeparators. Although
latter better bound run time, surprisingly actual performance worse
Snowball instances benchmark sets. holds even instances
SnowballSeparators performs significantly fewer updates. Thus, conclude
additional bookkeeping required SnowballSeparators pay off.
Regarding experiments, must noted that, although utmost
obtain fair comparison, constant factor measurements depends significant
way exact implementation details (e.g. whether lookup-table heap used),
also put forward earlier work experimentally comparing shortest path algorithms (Mondou, Crainic, & Nguyen, 1991; Cherkassky, Goldberg, & Radzik, 1996).
implementation higher constant factor Snowball algorithms may caused
adhering object-oriented paradigm, i.e. inheriting DPC P3 C superclasses,
choosing reuse code rather inlining method calls. Nonetheless, confident
general trends identified hold independently details.
381

fiPlanken, De Weerdt, & Van der Krogt

Note strictly speaking, algorithms introduced paper compute all-pairs
shortest distances. one wants actually trace shortest paths, algorithms
extended keep track midpoint whenever distance matrix updated, like
one FloydWarshall. Then, pair vertices, actual shortest path
graph traced (n) time.
current implementation SnowballSeparators, used priority queue decide
heuristically clique tree node visit next, giving precedence nodes connected
large separator part clique tree already visited. noted before, defer
answering question whether optimal ordering found efficiently future work.
remark using minimum-degree heuristic triangulation provides Snowball
natural edge, delaying processing vertices number iterations
middle loop small k grows large.
Cherkassky Goldberg (1999) compared several innovative algorithms singlesource shortest paths gave better efficiency standard BellmanFord algorithm
practice, worst-case bound (nm) run time. future
work, investigate clever improvements also exploited Snowball.
SnowballSeparators improved way influence theoretical complexity may yield better performance practice. Iterating Vother
seen reverse traversal part clique tree visited before, starting cs parent.
Then, instead always using separator current clique node (containing k)
parent previously visited vertices Vother , keep track smallest
separator encountered backwards traversal extra asymptotic cost. Since
shown Table 1 largest minimal separator often hardly smaller
induced width, might well pay search smaller separators. plan implement
improvement near future.
Another possible improvement suggested following observation DPC.
variant DPC proposed edge directionality taken account:
iteration k, neighbours i, j < k considered directed path
k j, resulting addition arc j. set added arcs would often
much smaller twice number edges added standard DPC algorithm,
graph produced directed variant would chordal, correctness
Snowball would impacted.
Furthermore, would like also experimentally compare algorithms recent
algorithms Pettie (2004) algorithms graphs constant treewidth Chaudhuri Zaroliagis (2000) future work. addition, interested efficient
triangulation heuristics, triangulation heuristics guaranteed quality, able
give guaranteed theoretical bound general graphs. Another direction, especially
interesting context planning scheduling, use ideas presented
design faster algorithm dynamic all-pairs shortest paths: maintaining shortest paths
edge deletions (or relaxations) additions (or tightenings).

Acknowledgments
Roman van der Krogt supported Science Foundation Ireland Grant number
08/RFP/CMS1711.
382

fiComputing APSP Leveraging Low Treewidth

offer sincere gratitude reviewers comments, helped us
improve clarity article strengthen empirical results.
article based conference paper title, received
honourable mention best student paper International Conference Automated
Planning Scheduling (Planken, de Weerdt, & van der Krogt, 2011).

Appendix A. Johnsons Heap
experiments paper, presented results Johnson
using Fibonacci
2
heap, theoretical bound nm + n log n time attained.
practice, using binary heap theoretical bound (nm log n) time turns
efficient occasions, show results section.
Figure 16 shows run times Johnson binary heap Fibonacci
heap benchmark sets listed Table 1. diamonds, HTN, New
York benchmarks binary heap percent faster Fibonacci heap,
slope lines doubly logarithmic scale same, conclude
average-case run time similar asymptotic behavior. However, larger job-shop
problems, binary heap factor 2 slower Fibonacci heap, chordal
graph benchmark problems even factor 10. benchmark problems scale-free graphs
fixed number vertices help explaining difference.
Figure 17, run time variants Johnson found scale-free graphs
1,000 vertices, number edges varying 2,000 almost 80,000.
Here, see sparsest scale-free graphs 2, 000 edges, binary
heap slightly faster, edges considered, using Fibonacci heap
significantly outperforms using binary heap. particular, run time Fibonacci
heap implementation increases slowly number edges, run time
binary heap increases much significantly. explained fact
running Dijkstras algorithm subroutine Johnson, update (candidate)
shortest path done amortized constant time Fibonacci heap,
binary heap worst-case cost (log n) time per update. number updates
bounded run Dijkstras algorithm, yielding bound (nm) updates
Johnson. binary heap (nm log n) bound accounts significant part
run time, Fibonacci heap operations (such extracting minimum
element heap) bigger relative contribution run time.
Based results benchmark sets, conclude although Johnson
binary heap help reducing actual run time sparse graphs, Johnson Fibonacci
heap overall better choice large.

383

fiPlanken, De Weerdt, & Van der Krogt

1e+07
Binary
Fibonacci

time solve (ms, log scale)

1e+06

chordal

100000

10000

ny

1000

diamonds
scale-free

100

htn
job shop

10

10

100
number vertices (log scale)

1000

Figure 16: Run times Johnson binary heap Fibonacci heap
benchmark problem sets listed Table 1.

1e+07
Binary
Fibonacci

time solve (ms, log scale)

1e+06

100000

10000

1000

100

10

2000

4000

8000
16000
number edges (log scale)

32000

64000

Figure 17: Run times Johnson binary heap Fibonacci heap scale-free
graphs 1,000 vertices increasing number edges.

384

fiComputing APSP Leveraging Low Treewidth

References
Albert, R., & Barabasi, A.-L. (2002). Statistical Mechanics Complex Networks. Reviews
Modern Physics, 74 (1), 4797.
Arnborg, S., Corneil, D. G., & Proskurowski, A. (1987). Complexity Finding Embeddings
k -Tree. SIAM Journal Algebraic Discrete Methods, 8 (2), 277284.
Balachandhran, V., & Rangan, C. P. (1996). All-pairs-shortest-length strongly chordal
graphs. Discrete applied mathematics, 69 (1-2), 169182.
Bauer, R., Delling, D., Sanders, P., Schieferdecker, D., Schultes, D., & Wagner, D. (2008).
Combining hierarchical goal-directed speed-up techniques Dijkstras algorithm. Experimental Algorithms (WEA 2008), Vol. 5038 LNCS, pp. 303318.
Springer.
Bodlaender, H. L. (1986). Classes graphs bounded tree-width. Tech. rep. RUU-CS86-22, Utrecht University.
Bodlaender, H. L. (1996). Linear-Time Algorithm Finding Tree-Decompositions
Small Treewidth. SIAM Journal Computing, 25 (6), 13051317.
Bouchitte, V., Kratsch, D., Muller, H., & Todinca, I. (2004). Treewidth Approximations.
Discrete Applied Mathematics, 136 (2-3), 183196.
Bresina, J. L., Jonsson, A. K., Morris, P. H., & Rajan, K. (2005). Activity Planning
Mars Exploration Rovers. Proc. 15th Int. Conf. Automated Planning
Scheduling, pp. 4049.
Bui, H. H., & Yorke-Smith, N. (2010). Efficient Variable Elimination Semi-Structured
Simple Temporal Networks Continuous Domains. Knowledge Engineering Review, 25 (3), 337351.
Castillo, L., Fernandez-Olivares, J., & Gonzalez, A. (2002). Temporal Constraint Network
Based Temporal Planner. Proc. 21st Workshop UK Planning
Scheduling Special Interest Group, pp. 99109, Delft, Netherlands.
Castillo, L., Fernandez-Olivares, J., & Gonzalez, A. (2006). Efficiently Handling Temporal
Knowledge HTN planner. Proc. 16th Int. Conf. Automated Planning
Scheduling, pp. 6372.

Chan, T. (2005). All-Pairs Shortest Paths Real Weights n3 / log n Time.
Algorithms Datastructures, LNCS, pp. 318324. Springer.
Chaudhuri, S., & Zaroliagis, C. D. (2000). Shortest Paths Digraphs Small Treewidth.
Part I: Sequential Algorithms. Algorithmica, 27 (3), 212226.
Cherkassky, B. V., Goldberg, A. V., & Radzik, T. (1996). Shortest paths algorithms: theory
experimental evaluation. Mathematical programming, 73 (2), 129174.
Cherkassky, B. V., & Goldberg, A. V. (1999). Negative-cycle detection algorithms. Mathematical Programming, 85, 277311.
Chleq, N. (1995). Efficient Algorithms Networks Quantitative Temporal Constraints.
Proc. 1st Int. Workshop Constraint Based Reasoning, pp. 4045.
385

fiPlanken, De Weerdt, & Van der Krogt

Conrad, P. R., Shah, J. A., & Williams, B. C. (2009). Flexible execution plans
choice. Proc. 19th Int. Conf. Automated Planning Scheduling.
Cormen, T. H., Leiserson, C. E., Rivest, R. L., & Stein, C. (2001). Introduction Algorithms, 2nd edition. MIT Press.
Dechter, R., Meiri, I., & Pearl, J. (1991). Temporal Constraint Networks. Artificial Intelligence, 49 (13), 6195.
Demetrescu, C., & Italiano, G. F. (2006). Fully Dynamic All-Pairs Shortest Paths
Real Edge Weights. Journal Computer System Sciences, 72 (5), 813837.
Dijkstra, E. W. (1959). note two problems connexion graphs.. Numerische
Mathematik, 1, 269271.
Dragan, F. F. (2005). Estimating pairs shortest paths restricted graph families:
unified approach. Journal Algorithms, 57 (1), 121.
Even, S., & Gazit, H. (1985). Updating Distances Dynamic Graphs. Methods Operations Research, 49, 371387.
Fiedler, N. (2008). Analysis Java implementations Fibonacci Heap. http://tinyurl.
com/fibo-heap.
Floyd, R. W. (1962). Algorithm 97: Shortest path. Communications ACM, 5 (6),
345.
Fredman, M., & Tarjan, R. E. (1987). Fibonacci Heaps Uses Improved Network
Optimization Algorithms. Journal ACM, 34 (3), 596615.
Geisberger, R., Sanders, P., Schultes, D., & Delling, D. (2008). Contraction hierarchies:
Faster simpler hierarchical routing road networks. Proc. Int. Workshop
Experimental Algorithms, pp. 319333. Springer.
Girvan, M., & Newman, M. E. J. (2002). Community Structure Social Biological
Networks. Proc. National Academy Sciences USA, 99 (12), 78217826.
Golumbic, M. (2004). Algorithmic Graph Theory Perfect Graphs. Elsevier.
Graham, R. L., Knuth, D. E., & Patashnik, O. (1989). Concrete Mathematics: Foundation
Computer Science (1st edition). Addison-Wesley.
Han, K., Sekharan, C. N., & Sridhar, R. (1997). Unified All-Pairs Shortest Path Algorithms
Chordal Hierarchy. Discrete Applied Mathematics, 77 (1), 5971.

Han, Y. (2008). Note n3 / log n -time Algorithm All-Pairs Shortest Paths.
Information Processing Letters, 105 (3), 114116.
Heggernes, P. (2006). Minimal triangulations graphs: survey. Discrete Mathematics,
306 (3), 297317. Minimal Separation Minimal Triangulation.
Johnson, D. B. (1977). Efficient Algorithms Shortest Paths Sparse Networks. Journal
ACM, 24 (1), 113.
Kjrulff, U. (1990). Triangulation Graphs - Algorithms Giving Small Total State Space.
Tech. rep., Aalborg University.
386

fiComputing APSP Leveraging Low Treewidth

Klein, P. N., Mozes, S., & Weimann, O. (2010). ShortestPaths Directed Planar Graphs
Negative Lengths: Linear-space n log2 n -time Algorithm. ACM Transactions Algorithms, 6 (2), 118.
Mondou, J. F., Crainic, T. G., & Nguyen, S. (1991). Shortest path algorithms: computational study C programming language. Computers & Operations Research,
18 (8), 767786.
Pettie, S. (2004). New Approach All-pairs Shortest Paths Real-weighted Graphs.
Theoretical Computer Science, 312 (1), 4774.
Planken, L. R., de Weerdt, M. M., & van der Krogt, R. P. J. (2008). P3 C: New Algorithm
Simple Temporal Problem. Proc. 18th Int. Conf. Automated
Planning Scheduling, pp. 256263.
Planken, L. R., de Weerdt, M. M., & van der Krogt, R. P. J. (2011). Computing allpairs shortest paths leveraging low treewidth. Proc. 21st Int. Conf.
Automated Planning Scheduling, pp. 170177.
Planken, L. R., de Weerdt, M. M., & Yorke-Smith, N. (2010). Incrementally Solving STNs
Enforcing Partial Path Consistency. Proc. 20th Int. Conf. Automated
Planning Scheduling, pp. 129136.
Ranise, S., & Tinelli, C. (2003). SMT-LIB Format: Initial Proposal. Proc.
Pragmatics Decision Procedures Automated Reasoning.
Rose, D. J. (1972). Graph-Theoretic Study Numerical Solution Sparse Positive
Definite Systems Linear Equations. Read, R. (Ed.), Graph theory computing,
pp. 183217. Academic Press.
Rossi, F., Venable, K. B., & Yorke-Smith, N. (2006). Uncertainty soft temporal constraint problems: general framework controllability algorithms fuzzy
case. Journal AI Research, 27, 617674.
Satish Kumar, T. K. (2005). Tractability Restricted Disjunctive Temporal Problems. Proc. 15th Int. Conf. Automated Planning Scheduling, pp.
110119.
Shah, J. A., & Williams, B. C. (2008). Fast Dynamic Scheduling Disjunctive Temporal
Constraint Networks Incremental Compilation. Proc. 18th Int. Conf.
Automated Planning Scheduling, pp. 322329.
Stergiou, K., & Koubarakis, M. (2000). Backtracking algorithms disjunctions temporal
constraints. Artificial Intelligence, 120 (1), 81117.
Strichman, O., Seshia, S. A., & Bryant, R. E. (2002). Deciding Separation Formulas
SAT. Proc. 14th Int. Conf. Computer Aided Verification, Vol. 2404
LNCS, pp. 209222. Springer.
Tarjan, R. E., & Yannakakis, M. (1984). Simple Linear-time Algorithms Test Chordality
Graphs, Test Acyclicity Hypergraphs, Selectively Reduce Acyclic Hypergraphs. SIAM Journal Computing, 13 (3), 566579.
387

fiPlanken, De Weerdt, & Van der Krogt

Thorup, M. (2004). Fully-dynamic All-Pairs Shortest Paths: Faster Allowing Negative
Cycles. Algorithm Theory, Vol. 3111 LNCS, pp. 384396. Springer.
Warshall, S. (1962). Theorem Boolean Matrices. Journal ACM, 9 (1), 1112.

388

fiJournal Artificial Intelligence Research 43 (2012) 257-292

Submitted 09/11; published 02/12

Consistency Techniques Flow-Based Projection-Safe Global Cost
Functions Weighted Constraint Satisfaction
J.H.M. Lee
K.L. Leung

JLEE @ CSE . CUHK . EDU . HK
KLLEUNG @ CSE . CUHK . EDU . HK

Department Computer Science Engineering
Chinese University Hong Kong
Shatin, N.T., Hong Kong

Abstract
Many combinatorial problems deal preferences violations, goal find
solutions minimum cost. Weighted constraint satisfaction framework modeling
problems, consists set cost functions measure degree violation preferences different combinations variable assignments. Typical solution methods weighted
constraint satisfaction problems (WCSPs) based branch-and-bound search, made
practical use powerful consistency techniques AC*, FDAC*, EDAC*
deduce hidden cost information value pruning search. techniques, however,
designed efficient binary ternary cost functions represented table
form. tackling many real-life problems, high arity (or global) cost functions required.
investigate efficient representation scheme algorithms bring benefits consistency
techniques also high arity cost functions, often derived hard global constraints
classical constraint satisfaction.
literature suggests global cost functions represented flow networks,
minimum cost flow algorithm used compute minimum costs networks
polynomial time. show naive adoption flow-based algorithmic method global
cost functions result stronger form -inverse consistency. show
method modified handle cost projections extensions maintain generalized versions
AC* FDAC* cost functions two variables. Similar generalization
stronger EDAC* less straightforward. reveal oscillation problem enforcing
EDAC* cost functions sharing one variable. avoid oscillation, propose weak
version EDAC* generalize weak EDGAC* non-binary cost functions. Using various
benchmarks involving soft variants hard global constraints IFFERENT, GCC, SAME,
REGULAR, empirical results demonstrate proposal gives improvements
order magnitude compared traditional constraint optimization approach,
terms time pruning.

1. Introduction
Constraint satisfaction problems (CSPs) occur walks industrial applications computer
science, scheduling, bin packing, transport routing, type checking, diagram layout,
name few. Constraints CSPs functions returning true false. constraints
hard sense must satisfied. over-constrained optimization scenarios, hard
constraints relaxed softened. weighted constraint satisfaction framework adopt
soft constraints cost functions returning non-negative integer upper bound . Solution techniques solving weighted constraint satisfaction problems (WCSPs) made practic
2012
AI Access Foundation. rights reserved.

fiL EE & L EUNG

cal enforcing various consistency notions branch-and-bound search, NC*, AC*,
FDAC* (Larrosa & Schiex, 2004, 2003) EDAC* (de Givry, Heras, Zytnicki, & Larrosa, 2005).
enforcement techniques, however, designed efficient binary ternary cost
functions represented table form. hand, many real-life problems
modelled naturally global cost functions high arities. investigate efficient representation
scheme algorithms bring benefits existing consistency techniques binary
ternary cost functions also high arity cost functions, often derived hard global
constraints classical constraint satisfaction.
existing WCSP solvers, high arity cost functions delayed become binary
ternary search. size tables also concern. lack efficient handling
high arity global cost functions WCSP systems greatly restricts applicability WCSP
techniques complex real-life problems. overcome difficulty, incorporate van Hoeve, Pesant, Rousseaus (2006) flow-based algorithmic method WCSPs, amounts
representing global cost functions flow networks computing minimum costs
networks using minimum cost flow algorithm. show naive incorporation global cost
functions WCSPs would result strong form -inverse consistency (Zytnicki, Gaspin,
& Schiex, 2009), still relatively weak terms lower bound estimation pruning.
question whether achieve stronger consistencies GAC* FDGAC*,
generalized versions AC* FDAC* respectively, non-binary cost functions efficiently.
Consistency algorithms (G)AC* FD(G)AC* involve three main operations: (a) computing
minimum cost cost functions variable x fixed value v, (b) projecting
minimum cost cost function unary cost functions x value v, (c) extending
unary costs related high arity cost functions. operations allow cost movements among
cost functions shifting costs increase global lower bound problem, implies opportunities domain value prunings. Part (a) readily handled using minimum
cost flow (MCF) algorithm proposed van Hoeve et al.s method. However, parts (b) (c)
modify cost functions, possibly destroy required flow-based structure cost
functions required van Hoeve et al.s method. overcome difficulty, propose give
sufficient conditions flow-based projection-safety property. global cost function flowbased projection-safe, flow-based property cost function guaranteed retained
matter many times parts (b) (c) performed. Thus, MCF algorithm applied
throughout enforcements GAC* FDGAC* increase search efficiency.
natural next step generalize also stronger consistency EDAC* (de Givry et al., 2005)
EDGAC*, turns non-trivial. identify analyze inherent limitation
EDAC* similar case Full AC* (de Givry et al., 2005). ED(G)AC* enforcement
go oscillation two cost functions share one variable, common
problem involves high arity cost functions. Sanchez, de Givry, Schiex (2008) mention
oscillation problem method enforcing EDAC* special case ternary cost
functions would avoid oscillation problem. paper, give weak form EDAC*,
generalized weak EDGAC* cost functions arity. importantly, weak
EDAC* reduced EDAC* two cost functions share one variable. Weak
EDGAC* stronger FDGAC* GAC*, weaker VAC (Cooper, de Givry, Sanchez,
Schiex, Zytnicki, & Werner, 2010). also give efficient algorithm enforce weak EDGAC*.
Based theoretical results, prove soft variants IFFERENT,
GCC, SAME, REGULAR constraints flow-based projection-safe, give polynomial time
258

fiC ONSISTENCY ECHNIQUES



OFT G LOBAL C OST F UNCTIONS



WCSP

algorithms enforce GAC*, FDGAC* also weak EDGAC* cost functions. Experiments carried different benchmarks featuring proposed global cost functions. Empirical results coincide theoretical prediction relative strengths various consistency notions complexities enforcement algorithms. experimental results also
confirm stronger consistencies GAC*, FDGAC* weak EDGAC* worthwhile
essential making global cost functions WCSP practical. addition, reified approach
(Petit, Regin, & Bessiere, 2000) strong IC weak estimating useful lower bounds
pruning search space branch-and-bound search.
rest paper organized follows. Section 2 gives necessary definitions
background, Section 3 gives related work. Generalized versions existing consistency techniques global cost functions presented compared Section 4. Enforcement algorithms
consistencies exponential general. introduce notion flow-based projectionsafety, describe polynomial time consistency enforcement algorithms global cost functions
enjoying flow-based projection-safety property. Section 5, prove softened form
common hard global constraints flow-based projection-safe give experimental results
demonstrating feasibility efficiency proposal terms runtime search
space pruning. Section 6 summarizes contributions shed light possible directions
future research.

2. Background
give preliminaries weighted constraint satisfaction problems, global cost functions
network flows.
2.1 Weighted Constraint Satisfaction
weighted constraint satisfaction problem (WCSP) special case valued constraint satisfaction (Schiex, Fargier, & Verfaillie, 1995) cost structure ([0, . . . , ], , ). structure
contains set integers 0 ordered standard ordering . Addition defined
b = min(, + b), subtraction defined b, b = b 6=
= a. Formally,
Definition 1 (Schiex et al., 1995) WCSP tuple (X , D, C, ), where:
X set variables {x1 , x2 , . . . , xn } ordered indices;
set domains D(xi ) xi X , one value assigned xi ;
C set cost functions WS different scope = {xs1 , . . . , xsn } X maps
tuple L(S), L(S) = D(xs1 ) . . . D(xsn ), [0, . . . , ].
assignment set variables X , written {xs1 7 vs1 , . . . , xsn 7 vsn },
assign variable xsi value vsi D(xsi ). context clear assuming
ordering variable indices, abuse notations considering assignment also tuple
= (vs1 , . . . , vsn ) L(S), L(S) = D(xs1 ) D(xs2 ) . . . D(xsn ). notation [xsi ]
denotes value vsi assigned xsi S, [S ] denotes tuple formed projecting onto
S.
Without loss generality, assume C = {W } {Wi | xi X } C + . W constant
nullary cost function. Wi unary cost function associated xi X . C + set cost
259

fiL EE & L EUNG

functions WS scope containing two variables. W {Wi } defined,
assume Wi (v) = 0 v D(xi ) W = 0. simplify notation, denote Ws1 ,s2 ,...,sn
cost function variables {xs1 , xs2 , . . . , xsn } context clear.
Definition
L 2 Given WCSPL(X , D, C, ). cost tuple L(X ) defined cost() =
W xi X Wi ([xi ]) WS C + WS ([S]). tuple L(X ) feasible cost() < ,
solution WCSP cost() minimum among tuples L(X ).
WCSPs usually solved basic branch-and-bound search augmented consistency
techniques prune infeasible values variable domains push costs W
preserving equivalence problems, i.e. cost tuple L(X ) unchanged.
Different consistency notions defined NC*, AC*, FDAC* (Larrosa & Schiex,
2004, 2003), EDAC* (de Givry et al., 2005).
Definition 3 variable xi node consistent (NC*) value v D(xi ) satisfies Wi (v)
W < exists value v D(xi ) Wi (v ) = 0. WCSP NC* iff
variables NC*.
Procedure enforceNC*() Algorithm 1 enforces NC*, unaryProject() moves unary
costs towards W keeping solution unchanged, pruneVal() removes infeasible
values. variables Q, R, global propagation queues used consistency
enforcements explained later sections. initially empty specified.

1
2

3
4
5

6
7
8
9
10
11

12
13
14

Procedure enforceNC*()
foreach xi X unaryProject (xi );
pruneVal ();
Procedure unaryProject(xi)
:= min{Wi (v) | v D(xi )};
W := W ;
foreach v D(xi ) Wi (v) := Wi (v) ;
Procedure pruneVal()
foreach xi X
flag := false;
foreach v D(xi ) s.t. Wi (v) W =
D(xi ) := D(xi ) \ {v};
flag := true;
flag
// consistency enforcement.
empty specified
Q := Q {xi };
:= {xi };
R := R {xi };

Algorithm 1: Enforce NC*
260

Assume initially

fiC ONSISTENCY ECHNIQUES



OFT G LOBAL C OST F UNCTIONS



WCSP

Based NC*, AC* FDAC* developed binary (Larrosa & Schiex, 2004,
2003) ternary cost functions (Sanchez et al., 2008). Enforcing consistency notions requires two equivalence preserving transformations besides NC* enforcement, namely projection
extension (Cooper & Schiex, 2004).
projection, written Project(WS ,Wi ,v,), transforms (WS , Wi ) (WS , Wi )
respect value v D(xi ) cost , min{WS () | [xi ] = v L(S)},
that:

Wi (u) u = v,
Wi (u) =
Wi (u)
otherwise.

WS () [xi ] = v,
WS () =
WS ()
otherwise.
extension, written Extend(WS ,Wi ,v,), transforms (WS , Wi ) (WS , Wi )
respect value v D(xi ) cost , Wi (v), that:

Wi (u) u = v,

Wi (u) =
Wi (u)
otherwise.

WS () [xi ] = v,
WS () =
WS ()
otherwise.
2.2 Global Constraints Global Cost Functions
global constraint constraint special semantics. usually high arity, thus
cannot propagated efficiently standard consistency algorithms. special semantics,
special propagation algorithms designed achieve efficiency.
global cost function soft variant hard global constraint. cost tuple
indicates much tuple violates corresponding global constraint. One global constraint
give rise different global cost functions using different violation measures. global cost
function returns 0 tuple satisfies corresponding global constraint. notation SOFT GC
denotes global cost function derived global constraint GC using violation measure .
instance, IFFERENT constraint two soft variants.
Definition 4 (Petit, Regin, & Bessiere, 2001) cost function SOFT IFFERENTvar returns
minimum number variable assignments needed changed tuple contains
distinct values; SOFT IFFERENTdec returns number pairs variables
assigned value.
2.3 Flow Theory
Definition 5 flow network G = (V, E, w, c, d) connected directed graph (V, E),
edge e E weight , capacity ce , demand de ce .
(s, t)-flow f source V sink V value G defined mapping
E real numbers that:
P
P

(s,u)E f(s,u) =
(u,t)E f(u,t) = ;
P
P

(u,v)E f(u,v) =
(v,u)E f(v,u) v V \ {s, t};
261

fiL EE & L EUNG

de fe ce e E.
simplicity, call (s, t)-flow flow specified.
P
Definition 6 cost flow f defined cost(f ) =
eE fe . minimum cost flow
problem value find flow whose value cost minimum.
given, assumed maximum value among flows.
solve minimum cost flow problems, various approaches developed. Two
successive shortest path cycle-cancelling algorithms (Lawler, 1976). algorithms
focus computation residual network corresponding flow network.
Definition 7 Given flow f network G = (V, E, w, c, d). residual network Gres =
(V, E res , wres , cres , dres ) defined as:
E res = {(u, v) e | f(u,v) < c(u,v) } {(v, u) e | f(u,v) > d(u,v) };

,if f(u,v) < c(u,v)
w(u,v)
res
w(u,v) =
w(u,v) ,if f(v,u) > d(v,u)

c(u,v) f(u,v) ,if f(u,v) < c(u,v)
cres
(u,v) =
f(u,v) d(u,v) ,if f(v,u) > d(v,u)
dres
e = 0, e E;
successive shortest path algorithm successively increases flow values edges along
shortest paths residual network value flow reaches
paths found. cycle-cancelling algorithm reduces cost given flow minimum
removing negative cycles induced residual network.
consistency enforcement flow, usually deal following problem: consider
(s, t)-flow f network G = (V, E, w, c, d) minimum cost, edge e E. problem
determine whether increasing (or decreasing) fe one unit keeps flow value unchanged,
compute minimal cost new resultant flow possible. Again, problem
solved using residual network Gres (Regin, 2002; van Hoeve et al., 2006): compute
shortest path P v u Gres , e = (u , v ) E. P exists, value flow
unchanged fe increased one unit. new minimum cost computed following
theorem.
flow increasing fe
Theorem 1 (Regin, 2002; van Hoeve et al., 2006) Suppose f resultant
P
one unit. minimum value cost(f ) cost(f ) + weres + eP weres .

Theorem 1 reduces problem finding shortest path v u , made
incremental consistency enforcement. want reduce unit flow edge,
apply similar methods used Theorem 1.

3. Related Work
Global cost functions handled using constraint optimization, focuses efficient
computation min{WS () | L(S)} enforcing GAC hard constraint forms
WS () zS , zS variable storing costs (Petit et al., 2001). Van Hoeve et al. (2006)
262

fiC ONSISTENCY ECHNIQUES



OFT G LOBAL C OST F UNCTIONS



WCSP

develop framework global cost functions representable flow networks, whose computation
polynomial size networks. Beldiceanu (2000) Beldiceanu, Carlsson Petit (2004)
develop representation scheme global cost functions using graph-based approach
automaton approach. framework, computation global cost functions
reduced considering fixed set global cost functions, e.g. SOFT REGULAR functions.
hand, efficiently remove search space WCSPs solving, various
consistency notions developed. Examples NC* (Larrosa & Schiex, 2004), BAC
(Zytnicki et al., 2009), AC* (Larrosa & Schiex, 2004), FDAC* (Larrosa & Schiex, 2003),
EDAC* (de Givry et al., 2005). Stronger consistency notions, namely OSAC VAC (Cooper
et al., 2010), also defined, enforcement requires relaxation cost valuation structure
V () rational numbers, current implementations efficient binary WCSPs.
ternary cost functions, AC, FDAC EDAC introduced (Sanchez et al., 2008). Cooper (2005)
incorporates concept k-consistency WCSPs form complete k-consistency. However,
time space complexities increase exponentially problem size increases, making complete k-consistency impractical enforce general WCSPs.

4. Consistency Notions Global Cost Functions
section, discuss four consistency notions high-arity cost functions: (1) strong inverse consistency (strong IC), (2) generalized arc consistency (GAC*), (3) full directional generalized arc consistency(FDGAC*), (4) generalized EDAC*. consistency notions require
exponential time enforce general, flow-based global cost functions (van Hoeve et al., 2006)
enjoy polynomial time enforcement.
4.1 Strong -Inverse Consistency
Strong -inverse consistency based -inverse consistency (IC) (Zytnicki et al., 2009).
Definition 8 (Zytnicki et al., 2009) Given WCSP P = (X , D, C, ). cost function WS C
-inverse consistent (IC) exists tuple L(S) WS () = 0. WCSP IC
iff cost functions IC.
procedure enforceIC() Algorithm 2 enforces IC. cost function WS made
IC lines 3 6, move costs WS W simple arithmetic operations.
1
2
3
4
5
6
7

Function enforceIC()
flag := false;
foreach WS C
:= min{WS () | L(S)};
W := W ;
foreach L(S) WS () := WS () ;
> 0 flag := true;
return flag;

Algorithm 2: Enforcing IC WCSP
time complexity enforceIC() Algorithm 2 depends time complexities
lines 3 5. Line 3 computes minimum cost line 5 modifies cost tuple
263

fiL EE & L EUNG

maintain equivalence. general, two operations exponential arity cost
function. However, first operation reduced polynomial time global cost function.
One example flow-based global cost functions (van Hoeve et al., 2006).
Definition 9 (van Hoeve et al., 2006) global cost function WS flow-based WS represented flow network G = (V, E, w, c, d)
min{cost(f ) | f max. {s, t}-flow G} = min{WS () | L(S)},
V fixed source V fixed destination.
examples, cost function SOFT IFFERENTdec (S) returns number pairs
variables share value, shown flow-based (van Hoeve et al., 2006).
example corresponding flow network, = {x1 , x2 , x3 , x4 }, shown Figure 1.
edges capacity 1. numbers edges represent weight edges. edge
number, edge zero weight. thick lines show flow corresponding tuple
= (a, c, b, b) cost 1.
x1

x2


b



1
2

x3
c

1

x4

Figure 1: example flow network SOFT

IFFERENTdec

flow-based cost functions, first operation (computing minimum cost) reduced time polynomial network size constraints. second operation
reduced constant time using data structure suggested Zytnicki et al. (2009). Instead
deducting projected value tuple WS , simply store projected value .
want know actual value WS , compute WS .
Enforcing IC increases W help reduce domain size. Consider WCSP
Figure 2. IC, value c D(x1 ) cannot part feasible tuple. tuples
associated assignment {x1 7 c} must cost least 4: 1 W , 2 W1 ,
1 W1,2 . allow domain reduction, extra conditions added IC form strong IC.
x1

b
c

W1
0
2
2

x2

b

= 4, W = 1
x1 x2 W1,2
W2


0
1
b

0
0
c

1

x1

b
c

Figure 2: WCSP IC

264

x2
b
b
b

W1,2
0
0
1

fiC ONSISTENCY ECHNIQUES



OFT G LOBAL C OST F UNCTIONS



WCSP

Definition 10 Given WCSP P = (X , D, C, ). Consider non-unary cost function WS C +
variable xi S. tuple L(S) -support value v D(xi ) respect WS
iff [xi ] = v W Wi (v) WS () < . cost function WS strong IC iff IC,
value variable -support respect WS . WCSP strong IC
IC non-unary cost functions strong IC.
instance, WCSP Figure 2 strong IC. value c D(x1 ) support, since W W1 (c) min{W1,2 () | [x1 ] = c L({x1 , x2 })} = = 4. Removal
c D(x1 ) makes so.
Strong IC collapses GAC classical CSPs WCSPs collapse CSPs. Although
definition similar BAC (Zytnicki et al., 2009), strengths incomparable. BAC
gathers cost information cost functions boundary values, consider
information one non-unary cost function individual values.
procedure enforceSIC() Algorithm 3 enforces strong IC, based W-AC*3()
Algorithm (Larrosa & Schiex, 2004). algorithm maintains propagation queue Q variables.
Cost functions involving variables Q potentially strong IC. iteration, arbitrary variable xj removed Q function pop() constant time. algorithm enforces
strong IC cost functions involving xj lines 4 6. existence -support
enforced findSupport(). domain reduction occurs (findSupport() returns true),
W increases (enforceIC() returns true), variables pushed onto Q lines 6 7 respectively, indicating IC potentially broken. algorithm terminates, i.e. Q = ,
variables pushed Q line 6, Q set X line 7. implies variables strong
IC WCSP IC. Thus WCSP strong IC execution.

1
2
3
4
5
6
7

8
9
10
11
12
13
14

Procedure enforceSIC()
Q := X ;
Q 6=
xj := pop (Q);
foreach WS C + s.t. xj
foreach xi \ {xj }
findSupport (WS , xi ) Q := Q {xi };
enforceIC () Q := X ;
Function findSupport(WS , xi )
flag := false;
foreach v D(xi )
:= min{WS () | [xi ] = v};
W Wi (v) =
D(xi ) := D(xi ) \ {v};
flag := true;
return flag;

Algorithm 3: Enforcing strong IC WCSP
procedure enforceSIC() correct must terminate. complexity analyzed
abstracting worst-case time complexities findSupport() enforceIC()
265

fiL EE & L EUNG

fstrong fIC respectively. Using augment similar proof Larrosa Schiexs
(2004) Theorems 12 21, complexity stated follows.
Theorem 2 procedure enforceSIC() time complexity O(r 2 edfstrong +ndfIC ),
r maximum arity cost functions, maximum domain size, e = |C + | n = |X |.
Proof: loop line 2 iterates O(nd) times. iteration, line 6 executes
O(r |N (j)|) times, N (j) set soft constraints restricting
xj . Since line 7 exeP
cutes O(nd) times, overall time complexity O(rdfstrong nj=1 |N (j)| + ndfIC ) =
Pn
O(r 2 edfstrong
Pn + ndfIC ). O( j=1 |N (j)|) = O(re) holds since cost function counts
r times j=1 |N (j)|. Thus, must terminate.

Corollary 1 procedure enforceSIC() must terminate. resultant WCSP strong IC,
equivalent original WCSP.
general, due enforceIC() findSupport(), enforcing strong IC exponential r. discussed before, enforceIC() reduced polynomial time flow-based
global cost functions. Similarly, findSupport() executed efficiently incrementally
flow-based global cost functions since line 10 computed polynomial time using minimum cost flow.
Another property interested confluence. consistency confluent enforcing
always transforms problem P unique problem P . AC* confluent (Larrosa
& Schiex, 2004). different variable and/or cost function orderings, AC* enforcement lead
different equivalent WCSPs different values W . BAC confluent (Zytnicki et al.,
2009). Following proofs Propositions 3.3 4.3 Zytnicki et al., shown
strong IC also confluent.
Theorem 3 (Confluence) Given WCSP P = (X , D, C, ), exists unique WCSP P =
(X , , C , ) strong IC equivalent P .
concludes theoretical analysis strong IC. following, compare
strength strong IC classical consistency notions used constraint optimization. Following Petit et al. (2000), define reified form WCSP follows:
Definition 11 (Petit et al., 2000) Given WCSP P = (X , D, C, ). reified form, reified(P ),
P constraint optimization problem (COP) (X h , h , C h , obj), where:
X h = X Z, Z = {zS | WS C \ {W }} cost variables.
h (xi ) = D(xi ) xi X , h (zS ) = {0, . . . , W 1} zS Z.
W < 1, h (zS ) = .
h
C h contains reified constraints CS{z
, hard constraints associated
S}
h
h
WS C \ {W
L } defined WS () zS tuple L(S). C also contains CZ
defined W zS Z zS < .
L
objective minimize obj, obj = W zS Z zS .

266

fiC ONSISTENCY ECHNIQUES



OFT G LOBAL C OST F UNCTIONS



WCSP

Finding optimal solution reified(P ) equivalent solving P . However, enforcing GAC
reified(P ) cannot remove values enforcing strong IC P . strong
IC P implies GAC reified(P ) vice versa.
general, define strength comparison follows.
Definition 12 Given problem P representable two models (P ) (P ). consistency
(P ) strictly stronger another consistency (P ), written (P ) > (P ),
> (P ) = (P ), iff (P ) whenever (P ) , vice versa.
Zytnicki et al. (2009) also define consistency strength comparison terms unsatisfiability detection, subsumed new definition. (P ) implies (P ), enforcing
(P ) detects unsatisfiability, enforcing (P ) detect unsatisfiability well.
Given WCSP P = (X , D, C, ). show strong IC P stronger GAC
reified(P ) following theorem.
Theorem 4 Strong IC P > GAC reified(P ).
Proof: Figure 2 given example WCSP whose reified COP GAC may strong
IC. show strong IC P implies GAC reified(P ).
First, CZh GAC. |C| 1, constraint obviously GAC. |C| > 1, vSi D(zSi ),
satisfy constraint, let cost variables take value 0, i.e. supports
vSi D(zSi ) exist.
h
Besides, CS{z
GAC. definition IC, exists tuple L(S)
S}
h
WS ( ) = 0. tuple form support vS D(zS ) respect CS{z
. Besides,
S}
-support v D(xi ), together vS = WS ( ), forms support v D(xi ).

detailed comparison strong IC WCSPs GAC reified approach,
readers refer work Leung (2009).
cost functions binary, strong IC cannot stronger AC*. next section,
show fact proving GAC*, generalized version AC*, stronger strong IC.
4.2 Generalized Arc Consistency
Definition 13 (Cooper & Schiex, 2004) Given WCSP P = (X , D, C, ). Consider cost function
WS C + variable xi S. tuple L(S) simple support v D(xi ) respect
WS xi iff [xi ] = v WS () = 0. variable xi star generalized arc consistent
(GAC*) respect WS iff xi NC*, value vi D(xi ) simple support
respect WS . WCSP GAC* iff variables GAC* respect related non-unary
cost functions.
definition designed practical considerations, slightly weakerL
Definition 4.2
work Cooper et al. (2010), also requires WS () = W xi Wi ([xi ])
WS () = .
GAC* collapses AC* binary cost functions (Larrosa & Schiex, 2004) AC ternary
cost functions (Sanchez et al., 2008). GAC* stronger strong IC, WCSP GAC*
also strong IC, vice versa. state without proof follows.
Theorem 5 GAC* > strong IC.
267

fiL EE & L EUNG

procedure enforceGAC*() Algorithm 4 enforces GAC* WCSP (X , D, C, ),
based W-AC*3() Algorithm (Larrosa & Schiex, 2004). propagation queue Q stores set
variables xj . xj Q, variables involved cost functions xj potentially
GAC*. Initially, variables Q. variable xj pushed Q values
removed D(xj ). iteration, arbitrary variable xj removed queue
function pop() line 4. function findSupport() line 7 enforces GAC* xi
respect WS finding simple supports. infeasible values removed function
pruneVal() line 10. value removed D(xi ), simple supports related
variables may destroyed. Thus, xi pushed back Q procedure pruneVal().
GAC*() terminates, values variable domain must simple support. WCSP
GAC*.

1
2

3
4
5
6
7

8
9
10

11
12
13
14
15
16
17
18

Procedure enforceGAC*()
Q := X ;
GAC* ();
Procedure GAC*()
Q 6=
xj := pop (Q);
foreach WS C + s.t. xj
foreach xi \ {xj }
findSupport (WS , xi )
// consistency enforcement.
initially empty specified
:= {xi };
R := R {xi };

Assume

pruneVal ();
Function findSupport(WS , xi )
flag := false;
foreach v D(xi )
:= min{WS () | [xi ] = v};
Wi (v) = 0 > 0 flag := true;
Wi (v) := Wi (v) ;
foreach L(S) s.t. [xi ] = WS () := WS () ;
unaryProject (xi );
return flag;

Algorithm 4: Enforcing GAC* WCSP
procedure enforceGAC*() Algorithm 4 correct must terminate. proof
similar Theorem 2. replacing fstrong fGAC (the worst-case time complexities
findSupport()) fIC O(nd) (the complexity pruneVal()), complexity
Algorithm 4 stated follows.
Theorem 6 procedure enforceGAC*() time complexity O(r 2 edfGAC +n2 d2 ),
n, d, e, r defined Theorem 2.
268

fiC ONSISTENCY ECHNIQUES



OFT G LOBAL C OST F UNCTIONS



WCSP

Corollary 2 procedure enforceGAC*() must terminate. resultant WCSP GAC*,
equivalent original WCSP.
general, procedure enforceGAC*() exponential maximum arity cost
function due findSupport(). function findSupport() consists two operations: (1)
finding minimum cost tuple associated {xi 7 v} line 13, (2) performing
projection lines 15 16. time complexity first operation polynomial flowbased global cost function WS . method introduced van Hoeve et al. (2006) applied
first operation discussed Section 4.1. However, second operation modifies WS WS ,
requires changing costs exponential number tuples. Cooper Schiex (2004)
use similar technique one Zytnicki et al. (2009) (similar technique described
Section 4.1) make modification constant time. However, resulting WS may flowbased, affecting time complexity subsequent procedure calls. resolve issue,
introduce flow-based projection-safety. WS flow-based projection-safe, flow property
maintained throughout enforcement.
Definition 14 Given property . global cost function WS projection-safe iff WS satisfies
property , WS derived WS series projections extensions, WS also
satisfies .
words, projection-safe cost function WS still satisfies numbers projections extensions. facilitates use derive efficient consistency enforcement
algorithms. following, consider special form projection-safety,
flow-based property.
following, first define FB, show FB sufficient condition flow-based
projection-safety.
Definition 15 global cost function satisfies FB if:
1. WS flow-based, corresponding network G = (V, E, w, c, d) fixed source
V fixed destination V ;
2. exists subjective function mapping maximum flow f G tuple f
L(S), and;
3. exists injection mapping assignment {xi
7 v} aP
subset edges E E
allP
maximum flow f corresponding tuple f , eE fe = 1 whenever
f [xi ] = v, eE fe = 0 whenever f [xi ] 6= v
Lemma 1 Given WS satisfying FB. Suppose WS obtained Project(WS ,Wi ,v,)
Extend(WS ,Wi ,v,). WS also satisfies FB.
Proof: prove part projection, since proof extension similar. first show
WS flow-based (condition 1). Assume G = (V, E, w, c, d) corresponding flow network
WS . projection, G modified G = (V, E, w , c, d), w (e) = w(e)
e E edge corresponding {xi 7 v} w (e) = w(e) otherwise. resulting G
269

fiL EE & L EUNG

corresponding flow network WS , since maximum flow f G minimum cost:
X

fe =

eE

X

fe

eE

X

fe

eE

= min{WS () | L(S)}

X

fe

eE

= min{WS () | L(S)}.
Moreover, since topology G = (V, E, w , c, d) G = (V, E, w, c, d),
WS also satisfies conditions 2 3.

Theorem 7 global cost function WS satisfies FB, WS flow-based projection-safe.
Proof: Initially, projection extension performed, directly Definition 15, WS
flow-based. Assume WS cost function formed WS series projections and/or
extensions. Lemma 1, WS still satisfies FB thus flow-based. Result follows.

shown Theorem 7, global cost function flow-based projection-safe, always
flow-based projections and/or extensions. Besides, checking conditions Definition
15, determine whether global cost function flow-based projection-safe.
Note computation proof performed standard integer set instead
V () practical considerations. investigation required computation restricted V ().
using Theorem 7, apply results van Hoeve et al. (2006) compute value
min{WS () | [xi ] = v L(S)} polynomial time throughout GAC* enforcement. Besides,
proof gives efficient algorithm perform projection polynomial time simply modifying
weights corresponding edges.
Again, use SOFT IFFERENTdec example. Van Hoeve et al. (2006) shown
SOFT IFFERENTdec (S) satisfies conditions 1 2 Definition 15. Besides,
network structure shown Figure 1, taking E = {(xi , v)} assignment {xi 7 v},
condition 3 satisfied. Thus, SOFT IFFERENTdec flow-based projection-safe.
x1

1


x2


b



1
2

x3
c

1

x4

Figure 3: flow network SOFT

IFFERENT dec ()

projection

Consider flow network SOFT IFFERENTdec Figure 1. Suppose perform
Project(SOFT IFFERENTdec (S),W1 ,a,1). network modified one Figure 3, weight edge (x1 , a) decreased 0 1. flow cost 0,
cost tuple (a, c, b, b) projection.
270

fiC ONSISTENCY ECHNIQUES



OFT G LOBAL C OST F UNCTIONS



WCSP

global cost function flow-based projection-safe, findSupport() time complexity
depending time complexity computing minimum cost flow shortest path
two nodes network. result stated following theorem.
Theorem 8 Given time complexities computing minimum cost flow shortest path
K SP respectively. WS flow-based projection-safe, findSupport() time
complexity O(K + SP), = max{|D(xi )| | xi S} maximum size E.
Proof: Theorem 1, finding first flow O(K), minimum cost line 13 found
augmenting existing flow, requires O(SP). Line 15 done constant time,
line 16 done follows: (a) decrease weights edges corresponding xi 7 v
, (b) augment current flow one new minimum cost changing flow
values edges whose weights modified first step. first step requires O(),
second step requires O( SP). edges required change flow values
maintain minimality flow cost. Since unaryProject() requires O(d), overall time
O(K + d(SP + SP) + d) = O(K + SP).

time complexity finding shortest path graph SP varies applying different
algorithms. general, SP = O(|V ||E|), negative weights introduced graph. However,
reduced applying potential value vertices, Johnsons (1977) algorithm.
example, Figure 3, increase potential value vertices 1, weight
edges (b, t) (c, t) 1. increases cost paths 1, makes
weights edges non-negative. Dijkstras (1959) algorithm thus applied, reducing
time complexity O(|E| + |V |log(|V |)).
Although GAC* enforced polynomial time flow-based projection-safe global cost
functions, findSupport() function still requires runtime much higher binary
ternary table cost functions general. optimize performance solver, delay
consistency enforcement global cost functions binary ternary table cost functions
processed line 5.
FDAC* binary cost functions (Larrosa & Schiex, 2003) suggests stronger consistency
deduced using extension operator. discuss generalized version FDAC*
non-binary cost functions next section.
4.3 Full Directional Generalized Arc Consistency
Definition 16 Given WCSP P = (X , D, C, ). Consider cost function WS C + variable
xi S. tuple full support value v D(x
L ) respect WS subset
variables U \ {xi } iff [xi ] = v WS () xj U Wj ([xj ]) = 0. variable xi
directional star generalized arc consistent (DGAC*) respect WS NC* value
v D(xi ) full support respect {xu | xu u > i}. WCSP full directional star
generalized arc consistent (FDGAC*) GAC* variable DGAC* respect
related non-unary cost functions.
FDGAC* collapses GAC WCSPs collapse CSPs. Moreover, FDGAC* collapses
FDAC* (Larrosa & Schiex, 2003) arity cost functions two. However, FDGAC*
incomparable FDAC ternary cost functions (Sanchez et al., 2008). FDAC requires full
supports zero unary also zero binary costs next variable only,
require variables full supports zero unary costs.
271

fiL EE & L EUNG

definition, FDGAC* stronger GAC* also strong IC.
Theorem 9 FDGAC* > GAC* > strong IC.
procedure enforceFDGAC*() enforces FDGAC* WCSP, based FDAC*() Algorithm (Larrosa & Schiex, 2003). propagation queues Q R store set variables.
xj Q, variables involved cost functions xj potentially GAC*; xj R,
variables xi involved cost functions xj potentially DGAC*. values
removed domain variable xj , xj pushed onto Q R; unary costs
values D(xj ) increased, xj pushed R. iteration, GAC* maintained
procedure GAC*(). DGAC* enforced DGAC*(). Enforcing DGAC* follows ordering
largest index smallest index full supports values domains
variables smaller indices destroyed DGAC*-enforcement larger
indices. variable largest index R removed R function popMax().
implementing R heap, popMax() requires constant time. DGAC* enforcement performed line 10 findFullSupport(). last step, NC* re-enforced pruneVal().
iteration continues propagation queues empty, implies values
variable domain simple full support, variables NC*. resultant WCSP
FDGAC*.

1
2
3
4
5

6
7
8
9
10
11
12

13
14
15
16
17
18
19
20

Procedure enforceFDGAC*()
R := Q := X ;
R 6= Q 6=
GAC* ();
DGAC* ();
pruneVal ();
Procedure DGAC*()
R 6=
xu := popMax (R);
foreach WS C + s.t. xu
= n DownTo 1 s.t. xi \ {xu }
findFullSupport (WS , xi , {xj | j > i}) R := R {xi };
:= {xi } ;
// consistency enforcement.

Function findFullSupport(WS , xi , U )
foreach xj U
foreach vj D(xj )
foreach L(S) s.t. [xj ] = vj WS () := WS () Wj (vj );
Wj (vj ) := 0;
flag := findSupport (WS , xi );
foreach xj U findSupport (WS , xj );
unaryProject (xi );
return flag;

Algorithm 5: Enforcing FDGAC* WCSP
272

fiC ONSISTENCY ECHNIQUES



OFT G LOBAL C OST F UNCTIONS



WCSP

procedure enforceFDGAC*() Algorithm 5 correct must terminate, proof
similar Theorems 3 4 Larrosa Schiex (2003). worst-case
time complexity enforceFDGAC*() stated terms findFullSupport()
(fDGAC ) findSupport() (fGAC ) follows.
Theorem 10 procedure enforceFDGAC*() time complexity O(r 2 ed(nfDGAC +
fGAC ) + n2 d2 ), n, d, e, r defined Theorem 2.
Proof: First analyze time complexity enforcing DGAC*. Consider procedure
DGAC*() line 6. while-loop iterates O(n) times. Since value removed
line 10, > j, pushed back R line
while-loop, xi processed P
11. Thus, line 10 executes O(r nj=0 |N (j)|) = O(r 2 e) times, N (j) set
cost functions restricting xj . Therefore, time complexity DGAC*() O(r 2 efDGAC ). Since
DGAC*() executes O(nd) times throughout global enforcement iteration. Thus time
spent enforcing DGAC* O(nr 2 edfDGAC )
Although GAC*() called O(nd) times, nothing values removed variable
domains. Thus count number times calling findSupport(). Since variables
pushed Q value removed, findSupport() executes O(nd) times
throughout global enforcement iteration. Similar arguments apply pruneVal() line 10
inside GAC*() defined Algorithm 4. proof similar Theorem 6, time spent
enforcing GAC* O(r 2 edfGAC + n2 d2 ).
pruneVal line 5 executes O(nd) times, time requires time complexity
O(nd). Therefore, overall time complexity O(r 2 ed(nfDGAC + fGAC ) + n2 d2 ).

Corollary 3 procedure enforceFDGAC*() must terminate. resultant WCSP FDGAC*
equivalent original WCSP.
Again, complexity exponential maximum arity due function findSupport()
findFullSupport(). following, focus discussion findFullSupport().
first part (lines 15 16) performs extensions push unary costs back WS .
time execute line 17, unary costs Wj , xj U , 0, enforcing GAC* xi
achieves second requirement DGAC* (each v D(xi ) full support). Line 18 re-instates
GAC* variables xj U . Note success line 17 guarantees Wj (vj ) = 0
value vj appearing tuple makes WS () = 0.
Again, flow-based projection-safety helps reduce time complexity findFullSupport()
throughout enforcement. proof Theorem 7 gives polynomial time algorithm perform
extension maintain efficient computation min{WS () | L(S)}. Flow-based projectionsafety guaranteed Theorem 7, requires checking conditions 1, 2, 3
definition flow-based projection-safety. complexity result follows Theorems 2 8.
Theorem 11 WS flow-based projection-safe global cost function, findFullSupport()
time complexity O(K + rd SP), r, , d, K SP defined Theorems 2
8.
Proof: Similarly Theorem 8, lines 13 16 performed follows: (a) xj U
value vj D(xj ), increase weights edges corresponding {xj 7 vj }
Wj (vj ), reduce Wj (vj ) 0, (b) find flow new minimum cost new
273

fiL EE & L EUNG

flow network. first step done O(rd), size U bounded arity
cost function r. second step done O(K), also acts preprocessing
findSupport() lines 17 18. Theorem 8, lines 17 18 done O(rd SP).
Thus, overall complexity O(r + K + rd SP) = O(K + rd SP).

Similarly GAC*, DGAC* enforcement global cost functions delayed
binary ternary table cost functions processed.
4.4 Generalizing Existential Directional Arc Consistency
EDAC* (de Givry et al., 2005) generalized EDGAC* using full support definition
FDGAC*. However, find naively generalizing EDAC* always enforceable, due
limitation EDAC*. following, explain provide solution limitation.
4.4.1 N NHERENT L IMITATION



EDAC*

Definition 17 (de Givry et al., 2005) Consider binary WCSP P = (X , D, C, ). variable
xi X existential arc consistent (EAC*) NC* exists value v D(xi ) zero
unary cost full supports respect binary cost functions Wi,j {xi , xj }
{xj }. P existential directional arc consistent (EDAC*) FDAC* variables
EAC* .
Enforcing EAC* variable xi requires two main operations: (1) compute

= min {Wi (a)
min {Wi,j (a, b) Wj (b)}},
aD(xi )

Wi,j C

bD(xj )

determines whether enforcing full supports breaks NC* requirement, (2) > 0, enforce full supports respect cost functions Wi,j C invoking findFullSupport (xi ,
Wi,j , {xj }), implying NC* longer satisfied hence W increased enforcing
NC*. EDAC* enforcement oscillate constraints share one variable. situation
similar Example 3 de Givry et al. (2005). demonstrate example Figure 4(a),
1 W 2 . FDAC* EDAC*.
shows WCSP two cost functions W1,2
1,2
1
x2 takes value a, W1,2 (v, a) W1 (v) 1 values v D(x1 ); x2 takes value b,
2 (v, b) C (v) 1 values v D(x ). Thus, enforcing full supports value
W1,2
1
1
D(x2 ) respect cost functions {x1 }, NC* broken W increased.
1 , resulting Figincrease W , enforce full supports: cost 1 W1 (a) extended W1,2
2
1 W results
ure 4(b). costs W1 extended W1,2 . Performing projection W1,2
2
Figure 4(c). WCSP EAC* FDAC*. Enforcing FDAC* converts problem
state back Figure 4(a).
problem caused first step, tell unary costs separated
extension increase W . Although increment predicted, unary cost W1 (a)
1 W 2 . computation, information obtained
choice moving W1,2
1,2
unary costs moved. shown, wrong movement breaks DAC* without incrementing W ,
resulting oscillation.
problem occur existing solvers handle ternary cost functions.
solvers allow one binary cost functions every pair variables. indeed
two cost functions two variables, cost functions merged one,
274

fiC ONSISTENCY ECHNIQUES

= 4, W
x1
W1

1

0
b
b

x1

b

x2

b

x1


b
b

W2
0
0

=0
1
x2 W1,2

0
b
2

1
b
0
x2

b

b

2
W1,2
1
0
0
2



x1

b

x2

b

(a) Original WCSP

OFT G LOBAL C OST F UNCTIONS

= 4, W
x1
W1

0

0
b
b
W2
0
0

x1


b
b

=0
1
x2 W12

1
b
3

1
b
0
x2

b

b

2
W12
1
0
0
2

(b) Extension

x1

b



WCSP

= 4, W
x1
W1

0

0
b
b

x2

b

W2
1
0

x1


b
b

=0
1
x2 W12

0
b
3

0
b
0
x2

b

b

2
W12
1
0
0
2

(c) Projection

Figure 4: Oscillation EDAC* enforcement
cost tuple merged function sum costs tuple two original
functions. However, allow high arity global cost functions, sharing one variable
would common necessary many scenarios. straightforward generalization EDAC*
non-binary cost functions would inherit oscillation problem. case ternary cost
functions, Sanchez et al. (2008) cleverly avoid oscillation problem re-defining full supports
include unary also binary cost functions. EDAC enforcement, unary costs
distributed extension binary cost functions. However, method designed
ternary cost functions. following, define weak version EDAC*, based
notion cost-providing partitions.
4.4.2 C OST-P ROVIDING PARTITIONS



W EAK EDGAC*

Definition 18 cost-providing partition Bxi variable xi X set sets {Bxi ,WS | xi S}
that:
|Bxi | number constraints scope includes xi ;
Bxi ,WS S;
Bxi ,WSj Bxi ,WSk = two different constraints WSk , WSj C + , and;


Bx ,W Bx Bxi ,WS = ( WS C + xi S) \ {xi }.






Essentially, Bxi forms partition set containing variables constrained xi . xj
Bxi ,WS , unary costs Wj extended WS enforcing EAC* xi .
avoids problem determining unary costs xj distributed exists
one constraint {xi , xj }.
Based cost-providing partitions, define weak EDAC*.
Definition 19 Consider binary WCSP P = (X , D, C, ) cost-providing partitions {Bxi |
xi X }. weak fully supported value v D(xi ) variable xi X value zero unary
, exists value b D(x )
cost variable xj binary cost function Wi,j
j


= {}, W
= {xj }. variable xi
Wi,j (v, b) = 0 Bxi ,Wi,j
(v,
b)

W
(b)
=
0

B
j
x
,W

i,j
i,j
weak existential arc consistent (weak EAC*) NC* exists least one weak fully
supported value domain. P weak existential directional arc consistent (weak EDAC*)
FDAC* variable weak EAC*.
275

fiL EE & L EUNG

Weak EDAC* collapses AC WCSPs collapse CSPs cost-providing partition.
Moreover, weak EDAC* reduced EDAC* (de Givry et al., 2005) binary cost functions
share one variable.
generalize weak EDAC* weak EDGAC* n-ary cost functions.
Definition 20 Given WCSP P = (X , D, C, ) cost-providing partitions {Bxi | xi X }.
weak fully supported value v D(xi ) variable xi value zero unary cost full
supports respect cost functions WS C + xi Bxi ,WS . variable xi weak
existential generalized arc consistent (weak EGAC*) NC* exists least one weak
fully supported value domain. P weak existential directional generalized arc consistent
(weak EDGAC*) FDGAC* variable weak EGAC*.
Weak EDAC* weak EDGAC* achieved using cost-providing partitions. Weak
EDGAC* reduced GAC WCSPs collapse CSPs.
Compared consistency notions, weak EDGAC* strictly stronger FDGAC*
consistency notions described. deduced directly definition.
Theorem 12 cost-providing partitions, weak EDGAC* > FDGAC* > GAC* > strong IC
VAC stronger weak EDGAC*, stated theorem below.
Theorem 13 VAC strictly stronger weak EDGAC* cost-providing partition.
Proof: WCSP VAC must weak EDGAC* cost-providing partition. Otherwise, must exist sequence projections extensions increase W , violates
Theorem 7.3 Cooper et al. (2010). another hand, Cooper et al. (2010) give example
EDAC* VAC. Results follow.

However, weak EDGAC* incomparable complete k-consistency (Cooper, 2005), k >
2, cost-providing partition. EDAC* already incomparable complete kconsistency (Sanchez et al., 2008).
compute cost-providing partition Bxi variable xi , could apply Algorithm 6,
greedy approach partition set containing variables related xi defined line 1,
hoping gathering costs gathering variables one cost function, increasing
chance removing infeasible values raising W .

1
2
3
4
5

ProcedureSfindCostProvidingPartition(xi)
= ( WS C + xi S) \ {xi };
Sort C + decreasing order |S|;
foreach WS C + s.t. xi
Bxi ,WS = S;
= \ S;

Algorithm 6: Finding Bxi
procedure enforceWeakEDGAC*() Algorithm 7 enforces weak EDGAC* WCSP.
cost-providing partitions first computed line 1. procedure makes use four propagation queues P, Q, R S. xi P, variable xi potentially weak EGAC* due
276

fiC ONSISTENCY ECHNIQUES

1
2
3
4
5
6
7
8
9

10
11
12
13
14

15
16



OFT G LOBAL C OST F UNCTIONS



WCSP

Procedure enforceWeakEDGAC*()
foreach xi X findCostProvidingPartition (xi );
R := Q := := X ;
6=
SR 6= Q 6=
P := xi S,WS C + (S \ {xi });
weakEGAC* ();
:= ;
DGAC* ();
GAC* ();
pruneVal ();
Procedure weakEGAC*()
P 6=
xi := pop(P);
findExistentialSupport (xi )
R := R {xi };
P := P {xj | xi , xj WS , WS C + };
Function findExistentialSupport(xi)
flag := false;
L
L
:= minaD(xi ) {Wi (a) xi S,WS C + min[xi ]=a {WS () xj Bx

,WS

Wj ([xj ])}};

19

> 0
flag := true;
foreach WS C + s.t. xi findFullSupport (WS , xi , Bxi ,WS );

20

return flag;

17
18

Algorithm 7: Enforcing weak EDGAC*

change unary costs removal values variables. xj R, variables xi involved cost functions xj potentially DGAC*. xj Q, variables
cost functions xj potentially GAC*. propagation queue helps build P
efficiently. procedure weakEGAC*() enforces weak EGAC* variable procedure
findExistentialSupport() line 12. findExistentialSupport() returns true,
projection performed cost functions. weak fully supported values
variables may destroyed. Thus, variables constrained xi pushed back onto P revision line 14. DGAC* GAC* enforced procedures DGAC*() GAC*().
change unary cost requires re-examining DGAC* weak EGAC*, done pushing
variables corresponding queues lines 13 14, lines 11 12 Algorithm 5.
last step, NC* enforced pruneVal(). Again, value D(xi ) removed, GAC*,
DGAC* weak EGAC* may destroyed, xi pushed corresponding queues
re-examination pruneVal() Algorithm 1. propagation queues empty, variables
GAC*, DGAC*, weak EGAC*, i.e. WCSP weak EDGAC*.
algorithm correct must terminate. analyze time complexity abstracting
worst-case time complexities findSupport(), findFullSupport()
277

fiL EE & L EUNG

findExistentialSupport() fGAC , fDGAC , fEGAC respectively. overall time
complexity stated follows.
Theorem 14 procedure enforceWeakEDGAC*() requires O((nd+)(fEGAC +r 2 efDGAC +
nd) + r 2 edfGAC ), n, d, e, r defined Theorem 2.
Proof: line 1 requires O(nr), analyze overall time complexity spent
sub-procedure compute overall time complexity.
variable pushed value removed weak EGAC* violated. former
happens O(nd) times, latter occurs O() times (each time weak EGAC* violated, W
increased). Since P built S, findExistentialSupport() executed
O(nd + ) times throughout global enforcement. Thus, time complexity spent enforcing
weak EGAC* O((nd + )fEGAC ).
variable pushed R either value removed, unary costs moved GAC*
weak EGAC* enforcement. Thus, DGAC*() called O(nd + ) times. time DGAC*()
called, Theorem 10, requires O(r 2 efDGAC ) DGAC* enforcement. Thus, time complexity enforcing DGAC* O((nd + )r 2 efDGAC ).
variable pushed Q value removed. Thus, findSupport() inside
procedure GAC*() called O(nd) times throughout global enforcement. Using
proof similar Theorem 6, overall time spent enforcing GAC* O(r 2 edfGAC + n2 d2 ).
main while-loop line 3 terminates propagation queues empty. Thus, main
while-loop iterates O(nd + ) times. time complexity re-enforcing NC* pruneVal()
line 9 O((nd + )nd).
summing time complexity results, overall time complexity O((nd+)(fEGAC +

r 2 efDGAC + nd) + r 2 edfGAC ).
Corollary 4 procedure enforceWeakEDGAC*() must terminate. resultant WCSP
weak EDGAC*, equivalent original WCSP.
procedure enforceWeakEDGAC*() exponential due findSupport(),
findFullSupport() findExistentialSupport(). following, focus
last procedure. first checks whether weak fully supported value exists computing ,
determines whether NC* still holds perform findFullSupport() line 19. equals
0, weak fully supported value exists nothing done; otherwise, value made
weak fully supported for-loop line 19. time complexity depends two operations:
(1) computing value line 16, and; (2) finding full supports line 19. two
operations exponential |S| general. However, global cost functions flow-based
projection-safe, time complexity operations reduced polynomial time.
next section, put theory practice. demonstrate framework different
benchmarks compare results current approach.

5. Towards Library Efficient Global Cost Functions
previous section, show SOFT IFFERENTdec flow-based projection-safe.
following, show range common global cost functions also flow-based
projection-safe. give experimental results various benchmarks different consistency
notions different global cost functions.
278

fiC ONSISTENCY ECHNIQUES



OFT G LOBAL C OST F UNCTIONS



WCSP

5.1 List Flow-Based Projection-Safe Global Cost Functions
section, show number common global cost functions flow-based projectionsafe. include soft variants IFFERENT, GCC, SAME, REGULAR constraints.
5.1.1 OFT VARIANTS



IFFERENT

IFFERENT() constraint restricts variables take distinct values (Lauriere, 1978).
two possible soft variants, namely SOFT IFFERENTdec () IFFERENTvar ().
former returns number pairs variables share value, latter returns
least number variables must changed variables take distinct values.
cost function SOFT IFFERENTdec () shown flow-based projection-safe Section 4.2.
fact, also implies another cost function
SOFT IFFERENTvar () flow-based projection-safe. SOFT IFFERENT var () function
also corresponds flow network structure similar SOFT IFFERENTdec ()
different weights edges connecting (van Hoeve et al., 2006). state results
follows.
Theorem 15 cost functions SOFT
flow-based projection-safe.

IFFERENT var (S) SOFT IFFERENTdec (S)

5.1.2 OFT VARIANTS GCC

Given set values = xi D(xi ) functions lb ub maps non-negative
integers. value v associated upper bound ubv lower bound lbv .
GCC(S, ub, lb) constraint satisfied tuple L(S) number occurrences value
v (denoted #(, v)) ubv times least lbv times (Regin, 1996).
two soft variants GCC constraints, namely SOFT GCCvar () SOFT GCCval () (van Hoeve
et al., 2006).
Definition 21 (van Hoeve et al., 2006) Define two functions s(, v) e(, v): s(, v) returns
lbv #(, v) #(, v) lbv , 0 otherwise; e(, v) returns #(, v) ubv #(, v) ubv ,
0 otherwise.
P
P
global
SOFT GCC var (S) returns max{ v s(, v),
v e(, v)}, proP cost functions P
P
vided v lbv |S| v ubv ; SOFT GCCval (S) returns v (s(, v) + e(, v)).
Van Hoeve et al. (2006) show SOFT GCCvar SOFT GCCdec flow-based,
flow networks structures similar SOFT IFFERENT cost functions. proof
similar Theorem 15, show following theorem.

Theorem 16 cost functions SOFT GCCvar (S) SOFT GCCval (S) flow-based projectionsafe.
5.1.3 OFT VARIANTS



AME

Given two sets variables S1 S2 |S1 | = |S2 | S1 S2 = . SAME(S1 ,S2 )
constraint satisfied tuple L(S1 S2 ) [S1 ] permutation [S2 ] (Beldiceanu,
Katriel, & Thiel, 2004). hard SAME() constraint softened global cost function
SOFT SAMEvar () (van Hoeve et al., 2006):
279

fiL EE & L EUNG

Definition 22 (van Hoeve et al., 2006) Given union operation multi-set union,
1 2 returns symmetric difference two multi-sets 1 2 , i.e.1 2 = (1 \
2 ) (2 \ 1 ).


global cost function SOFT SAMEvar (S1 , S2 ) returns |( xi S1 {[xi ]})( yi S2 {[yi ]})|/2.
Theorem 17 cost function

SOFT SAMEvar (S1 ,

S2 ) flow-based projection-safe.

Proof: Van Hoeve et al. (2006) shown SOFT SAMEvar satisfies conditions 1 2
Definition 15. instance, consider S1 = {x1 , x2 , x3 } S2 = {x4 , x5 , x6 } D(x1 ) = {a},
D(x2 ) = {a, b}, D(x3 ) = {b}, D(x4 ) = {a, b} ,and D(x5 ) = D(x6 ) = {a}. flow network
corresponding SOFT SAMEvar (S1 , S2 ) shown Fig. 5. Solid edges zero weight unit
capacity. Dotted edges unit weight capacity 3. thick edges show (s, t)-flow
corresponding tuple = (a, b, b, b, a, a).
x1



x4



x2

x5



b
x6

x3

Figure 5: flow network corresponding SOFT

SAMEvar (S1 ,

S2 ) constraint

Moreover, network structure, taking E = {(xi , v)} xi S1 v D(xi ),
E = {(v, yi )} yi S2 v D(yi ), cost function satisfies condition 3. Thus,
flow-based projection-safe.

5.1.4 OFT VARIANTS



R EGULAR

R EGULAR constraint defined based regular languages. regular language L(M )
represented finite state automaton = (Q, , , q0 , F ). Q set states. set
characters. symbol q0 Q denotes initial state F Q set final states.
transition function defined : Q 7 Q. automaton represented graphically
shown Figure 6, final states denoted double circles.
Given D(xi ) xi S. REGULAR(S, ) constraint accepts tuple
L(S) corresponding string belongs regular language L(M ) represented finite state
automaton = (Q, , , q0 , F ) (Pesant, 2004).
b
q0



q1
b


q2

Figure 6: graphical representation automaton.
280

fiC ONSISTENCY ECHNIQUES



OFT G LOBAL C OST F UNCTIONS

Two soft variants defined REGULAR constraint, namely
SOFT REGULAR edit () (van Hoeve et al., 2006):



WCSP

SOFT REGULAR var ()



Definition 23 (van Hoeve et al., 2006) Define string formed tuple L(S).
cost functions SOFT REGULARvar (S) returns min{H( , ) | L(M )}, H( 1 , 2 )
returns number positions two strings 1 2 differ; SOFT REGULARedit (S)
returns min{E( , ) | L(M )}, E( 1 , 2 ) returns minimum number insertions,
deletions substitutions transform 1 2 .
Theorem 18 cost functions SOFT
projection-safe.

REGULAR var (S) SOFT REGULAR edit (S) flow-based

Proof: Van Hoeve et al. (2006) show conditions 1 2 satisfied. example, consider
automaton shown Figure 6 = {x1 , x2 , x3 } D(x1 ) = {a} D(x2 ) = D(x3 ) =
{a, b}. flow networks corresponding SOFT REGULARvar (S) SOFT REGULARedit (S)
functions shown Figure 7(a) 7(b) respectively. solid edges zero weight
dotted edges unit weight. thick edges show flow corresponding tuple (a, b, a).
graphs constructed follows (van Hoeve et al., 2006): vertices separated
n + 1 layers, n = |X |, layer contains |Q| nodes. source connected q0,0
first layer, sink connected {qn+1,i | qi F } last layer. ith
(i + 1)th layers, zero weighted edge representing v D(xi ) connects qi,h ith layer
qi+1,k (i + 1)th layer (qk , v) = qh . SOFT REGULARvar (S), set unit-weighted
edges Esub added graph, Esub = {(qi,k , qi+1,h )u | xi X u D(xi ) v 6=
u s.t. (qk , v) = qh }. SOFT REGULARedit (S), set unit-weighted edges Eedit added
graph, Eedit = Esub {(qi,k , qi,h ) | xi X v s.t. (qk , v) = qh } {(qi,k , qi,k )u |
xi X u D(xi )}.
Moreover, assignment {xi 7 v} maps set edges E labelled v layer xi
networks. example, {x1 7 a} maps edges labeled layer x1 shown Fig. 7(a).
Thus, SOFT REGULAR cost functions satisfy condition 3 flow-based projection-safe.
SOFT REGULAR cost functions, instead general flow computation algorithms,
dynamic programming approach applied compute minimum cost (van Hoeve et al.,
2006; Demassey, Pesant, & Rousseau, 2006).
5.2 Experimental Results
section, series experiments different benchmarks conducted demonstrate
efficiency practicality different consistencies different global cost functions. implemented strong IC, GAC*, FDGAC* weak EDGAC* enforcement algorithms
global cost functions ToulBar2 version 0.51 . compare performance using five benchmarks different natures. case reified COP models, instances solved using ILOG
Solver 6.0.
benchmarks crisp nature, softened follows. variable xi introduced, random unary cost 0 9 assigned value D(xi ). Soft variants global
constraints implemented proposed. target benchmarks find optimal value
within 1 hour.
1. http://carlit.toulouse.inra.fr/cgi-bin/awki.cgi/ToolBarIntro

281

fiL EE & L EUNG

x2

x1


q0

x3

q0

q0









q1





q2

q0
b

b

q1

q1

b



q0

q2

x1

x2



a,b





()
x3
a,b

q0

b

b





q1

q2

var

q0






q1

q2

q1

b

b

b

b

q1






q2

SOFT REGULAR

q2



b

b

(b)



b

SOFT REGULAR

q0



q2
b

(a)

q1

b





q2

b

b

edit

()

Figure 7: flow network corresponding soft REGULAR constraints
experiments, variables assigned lexicographical order. Value assignment starts
value minimum unary cost. test conducted Sun Blade 2500 (2 1.6GHz
USIIIi) machine 2GB memory. average runtime number nodes five instances
measured value n initial upper bound. Entries marked *
average runtime exceeds limit 1 hour. best results marked using symbol.
5.2.1 B ENCHMARKS BASED



OFT IFFERENT

IFFERENT() constraint various applications. following, focus two:
all-interval series Latin Square problem.
NTERVAL ERIES
all-interval series problem (prob007 CSPLib) modelled WCSP two sets variables {si } {di } domains {0, . . . n 1} denote elements adjacent difference
respectively. Random unary costs ranging 0 9 placed variable. apply two
soft IFFERENT cost functions {si } {di } respectively, set hard arithmetic
constraints di = |si si+1 | = 1, . . . , n 1.
experiment divided two parts. first compare results enforcing different consistencies using global cost functions derived IFFERENT() . compare result
using different approaches modelling SOFT IFFERENTdec () functions.
result first experiment shown Table 1, agrees theoretical strength
consistency notions shown number nodes. FDGAC* GAC* always outperforms strong IC reified modelling, FDGAC* requires time GAC*. One
explanation phenomenon problem structure. xi xi+1 assigned, di
282

fiC ONSISTENCY ECHNIQUES



OFT G LOBAL C OST F UNCTIONS



WCSP

automatically assigned due hard constraint di = |xi xi+1 |. Thus, enforcing FDGAC*
variables {di } every search node worthwhile.
(a)
n
8
9
10
11
12

Reified Approach
Time(s) Nodes
1.3
571.0
3.9
1445.0
52.0 15860.6
59.6 13286.2
180.1 31015.2

Strong IC
Time(s) Nodes
0.2
296.4
1.0
542.2
20.2
5706.6
31.8
7536.4
77.8 12886.4

(b)
n
8
9
10
11
12

Reified Approach
Time(s) Nodes
1.6
777.0
3.9
1480.4
56.8 17753.8
70.1 16149.6
214.9 38438.6

SOFT IFFERENT

var

GAC*
Time(s) Nodes
0.1
181.0
0.6
300.2
10.8 2589.4
16.4 3273.6
37.6 5204.6

SOFT IFFERENT

Strong IC
Time(s) Nodes
0.2
396.8
1.0
553.2
21.2
5999.2
38.4
9113.2
96.4 16355.2

()
FDGAC*
Time(s) Nodes
0.1
86.4
1.2
197.2
15.2 1612.4
21.0 1715.4
46.8 2259.0

Weak EDGAC*
Time(s) Nodes
0.1
15.4
0.1
20.2
0.2
47.4
0.1
33.6
0.8
47.6

dec

GAC*
Time(s) Nodes
0.2
219.6
0.6
301.8
11.6 2654.6
18.6 3551.8
46.8 6405.0

()
FDGAC*
Time(s) Nodes
0.1
93.8
1.2
195.0
16.0 1604.2
23.0 1812.6
52.6 2451.6

Weak EDGAC*
Time(s) Nodes
0.1
16.0
0.1
28.8
0.8
70.4
1.0
68.6
1.8
71.2

Table 1: time (in seconds) number nodes solving all-interval series instances
second experiment based following fact. SOFT IFFERENTdec (S) flowbased projection-safe. modelled flow network consistency enforcement efficiently.
Another way model global cost functions apply decomposition directly. cost
returned SOFT IFFERENTdec (S) equal sum costs returned set soft
binary cost functions {Wi,j | > j xi , xj S}, Wi,j (a, b) returns 0 6= b 1
otherwise. Thus, binary consistency notions, AC* FDAC* applied directly.
compare performance solving interval series problem different modelling
methods SOFT IFFERENTdec (). results shown Table 2. level
consistency, global cost functions remove order magnitude 10 100 times nodes
binary decomposition. However, time required binary cost functions much smaller
global cost functions AC* FDAC*. enforcing consistency notions binary
cost functions faster global cost functions, removal nodes great enough
compensate extra time consistency enforcement global cost functions. runtime
weak EDGAC*, however, fastest among (2 times EDAC* counterpart) since
able utilize global information prune drastically search space binary
decomposition approaches.
L ATIN QUARES
Latin Square problem (prob003 CSPLib) order n fill initially empty n n table
using numbers {0, . . . , n 1} number occurs every row every
column. model relax problem WCSP set variables {xij } denoting
value placed cell ith row j th column random unary costs. costs
essentially restrictions/preferences value taken cell. Thus, formulation
model different variants Latin Square problem, including Latin Square Completion
problem. One SOFT IFFERENT() cost function posted variables row
283

fiL EE & L EUNG

n
8
9
10
11
12

AC*
Time(s) Nodes
0.1
317.2
0.1
596.0
1.4
9113.8
1.6
7672.2
4.6 15897.2

Binary Decomposition
FDAC*
EDAC*
Time(s) Nodes Time(s) Nodes
0.1
0.1
231.6
161.8
0.1
0.1
358.2
333.0
1.0
5957.4
1.0 5483.2
1.2
4578.4
1.2 4318.6
3.2 10534.8
2.6 7414.4

GAC*
Time(s) Nodes
0.2
219.6
0.6
301.8
11.6 2654.6
18.6 3551.8
46.8 6405.0

Global Cost Functions
FDGAC*
Weak EDGAC*
Time(s) Nodes Time(s) Nodes
0.1
0.1
16.0
93.8
0.1
28.8
1.2
195.0
0.8
70.4
16.0 1604.2
1.0
68.6
23.0 1812.6
1.8
71.2
52.6 2451.6

Table 2: time (in seconds) number nodes solving all-interval series instances
different modelling

column, denoting elements rows columns allowed violation
costs resultant cost optimal. result shown Table 3, similar Table
1. Besides, runtime also agrees theoretical strength consistency notions.

n
4
5
6
7
8

n
4
5
6
7
8

Reified Approach
Time(s)
Nodes
69.0 129958.0
*
*
*
*
*
*
*
*

(a) SOFT IFFERENT var()
Strong IC
GAC*
FDGAC*
Time(s)
Nodes
Time(s) Nodes Time(s) Nodes
0.1
0.1
1.8
3511.0
188.0
21.8
0.1
490.2 348790.4
26.0 12368.0
66.2
*
*
*
*
3.4
244.4
*
*
*
*
43.2 1429.4
*
*
*
*
*
*

Weak EDGAC*
Time(s) Nodes
0.1
16.6
0.1
41.2
1.4
93.6
16.2
425.2
148.2
2066.5

Reified Approach
Time(s)
Nodes
62.7 121319.0
*
*
*
*
*
*
*
*

(b) SOFT IFFERENT dec()
Strong IC
GAC*
FDGAC*
Time(s)
Nodes
Time(s) Nodes Time(s) Nodes
0.1
0.1
2.6
3859.8
187.6
21.8
0.1
531.4 376526.2
25.2 12254.0
66.2
*
*
*
*
3.4
244.4
*
*
*
*
43.4 1429.6
*
*
*
*
*
*

Weak EDGAC*
Time(s) Nodes
0.1
16.6
0.1
41.2
1.4
93.6
15.8
425.2
147.2
2066.5

Table 3: time (in seconds) number nodes solving Latin Square instances using
SOFT IFFERENT cost functions

SOFT IFFERENTdec () cost functions also decomposed binary disequality
cost functions. also perform experiments compare binary decomposition approach
global cost function approach. result shown Table 4. result confirms enforcing
stronger consistency global cost functions efficient terms number nodes explored
also problem size grows large.
5.2.2 B ENCHMARKS BASED



OFT GCC

GCC() constraint various applications. following, focus Latin Square
problem round robin tournament problem.
284

fiC ONSISTENCY ECHNIQUES

n
4
5
6
7
8

AC*
Time(s)
Nodes
0.1
264.0
3.0
17955.8
639.2 2188035.4
*
*
*
*

Binary Decomposition
FDAC*
Time(s)
Nodes
0.1
71.8
0.4
3059.6
167.8 346797.6
*
*
*
*



OFT G LOBAL C OST F UNCTIONS

EDAC*
Time(s) Nodes
0.1
39.4
0.1
828.2
28.2 45817.8
*
*
*
*



WCSP

Global Constraint Approaches
GAC*
FDGAC*
Weak EDGAC*
Time(s) Nodes Time(s) Nodes Time(s) Nodes
0.1
0.1
0.1
16.6
187.6
21.8
0.1
0.1
41.2
25.2 12254.0
66.2
1.4
93.6
*
*
3.4
244.4
15.8
425.2
*
*
43.4 1429.6
147.2
2066.5
*
*
*
*

Table 4: time (in seconds) number nodes solving Latin Square instances
different modelling
(a)
n
4
5
6
7
8

Reified Approach
Time(s)
Nodes
3.8
4865.6
653.7 460989.2
*
*
*
*
*
*

Strong IC
Time(s)
Nodes
2.8
3859.8
621.2 376526.2
*
*
*
*
*
*

(b)
n
4
5
6
7
8

Reified Approach
Time(s)
Nodes
2.2
2815.8
165.2 122840.0
*
*
*
*
*
*

Strong IC
Time(s)
Nodes
1.4
2326.6
153.4 102493.6
*
*
*
*
*
*

GCCvar
GAC*
Time(s) Nodes
0.1
220.8
38.6 14482.8
*
*
*
*
*
*

SOFT

SOFT

FDGAC*
Time(s) Nodes
0.1
22
0.1
66.2
4.8
244.6
58.4 1431.2
*
*

Weak EDGAC*
Time(s) Nodes
0.1
17.0
0.1
48.2
1.2
87.0
16.4
331.8
459.6
4730.8

FDGAC*
Time(s) Nodes
0.1
20.4
0.1
61.2
3.6
211.0
40.4 1243.6
*
*

Weak EDGAC*
Time(s) Nodes
0.1
17.0
0.1
45.2
1.0
82.2
13.4
318.4
285.2
3700.4

GCCval

GAC*
Time(s)
Nodes
0.1
131.8
10.0
4818.2
1407.4 357529.8
*
*
*
*

Table 5: time (in seconds) number nodes solving Latin Square instances using
soft GCC constraints

L ATIN QUARES
first focus Latin Square problem, described Section 5.2.1. use
soft version replace SOFT IFFERENT either SOFT GCCvar () SOFT GCCval ()
cost functions measure violation differently. results shown Table 5,
shows similar result Table 3. Weak EDGAC* always performs best terms time
reduction search space.
ROUND ROBIN OURNAMENT
round robin problem problem (prob026 CSPLib) order n schedule tournament n
teams n 1 weeks. week divided n/2 periods, period divided two
slots. tournament must satisfy following three constraints: (1) every team plays least
week, (2) every team plays twice period tournament, (3) every team
plays every team. Van Hentenryck, Michel, Perron, Regin (1999) give CSP model
based GCC constraints: triple variables (sij , tij , mij ) represents match played ith
week j th period. assignment {sij 7 a, tij 7 b, mij 7 ab} represents team played
team b. Ternary constraints link sij , tij mij together sij takes value
285

fiL EE & L EUNG

(a)
(N, P, )
(4,3,2)
(5,4,2)
(6,5,3)
(7,5,3)

Reified Approach
Time(s) Nodes
1.7 1119.2
4.5 2016.6
*
*
*
*

Strong IC
Time(s) Nodes
0.6
827.4
2.2 1242.0
*
*
*
*

(b)
(N, P, )
(4,3,2)
(5,4,2)
(6,5,3)
(7,5,3)

Reified Approach
Time(s) Nodes
1.5 1046.8
3.5 1821.4
*
*
*
*

SOFT

GAC*
Time(s) Nodes
0.4 470.2
1.8 836.2
*
*
*
*

SOFT

Strong IC
Time(s) Nodes
0.4 794.6
0.6 171.0
*
*
*
*

GCCvar
FDGAC*
Time(s) Nodes
0.2 142.2
0.6 171.6
*
*
*
*

Weak EDGAC*
Time(s) Nodes
0.1
33.4
0.1
44.6
583.4
6508.8
1283.4
7476.6

FDGAC*
Time(s) Nodes
0.2 141.0
0.6 171.0
*
*
*
*

Weak EDGAC*
Time(s) Nodes
0.1
33.0
0.1
42.8
438.2
6499.6
765.0
7413.6

GCCval

GAC*
Time(s) Nodes
0.4 464.6
1.4 824.6
*
*
*
*

Table 6: time (in seconds) number nodes solving round robin tournament
problems using SOFT GCC cost functions

tij takes value b iff mij takes value ab ba. first second requirements
represented GCC constraints {sij , tij | = w} wth week {sij , tij | j = p}
pth period. third requirement represented GCC constraint {mij }.
problem generalized three parameters (N, P, ): scheduling tournament
N teams weeks, week divided P periods. Besides placing random unary
costs, also replace GCC constraints soft variants. try different combinations
N , P , . results shown Table 6, agrees theoretical strength
consistency. also shows although enforcing stronger consistency expensive, helps
reduce search space more. Thus, stronger consistency helps solve larger instances.
5.2.3 B ENCHMARKS BASED



OFT AME

SAME() constraint used model following two problems: (1) fair scheduling,
(2) people-mission scheduling.
FAIR CHEDULING
problem suggested Global Constraint Catalog2 . goal schedule n persons
shifts days schedule fair, i.e. person assigned
number ith shift. example, schedule Figure 8(a) fair. person p1
assigned shift two times p2 assigned shift only. Figure 8(b) shows
schedule fair everyone: p1 p2 assigned shift Overnight shift
once, PM shift twice.
model soften problem set variables {xij }, denote shift assigned
ith person j th day random unary costs. SOFT SAMEvar ({xp1 j }, {xp2 j }) cost
functions placed pair persons p1 p2 , allowing violation fairness
schedule obtain minimum cost. fix = 4 = 5 vary n. results shown
Table 7. Similarly Table 5, weak EDGAC* produces smallest number nodes. However,
2. http://www.emn.fr/x-info/sdemasse/gccat/

286

fiC ONSISTENCY ECHNIQUES

Day 1



p1
p2

Day 2
PM
PM

Day 3
PM
Overnight



OFT G LOBAL C OST F UNCTIONS

Day 4

PM

p1
p2

Day 1



(a) Unfair Schedule

Day 2
PM
PM



WCSP

Day 3
PM
Overnight

Day 4
Overnight
PM

(b) Fair Schedule

Figure 8: Examples Fair Scheduling
n
5
6
7
8
9
10
11

Reified Approach
Time(s)
Nodes
1983.9 1457812.6
*
*
*
*
*
*
*
*
*
*
*
*

Strong IC
Time(s)
Nodes
74.2
20610.4
1884.0 1038613.2
*
*
*
*
*
*
*
*
*
*

GAC*
Time(s)
Nodes
16.6
3511.8
78.8
11031.8
377.0
36063.0
1630.0 124920.8
*
*
*
*
*
*

FDGAC*
Time(s) Nodes
0.1
27.4
0.4
40.4
1.0
45.0
2.0
45.4
2.6
49.0
4.0
58.0
5.8
67.2

Weak EDGAC*
Time(s) Nodes
0.1
25.4
34.0
1.0
40.6
1.2
45.0
2.2
49.0
3.2
56.8
4.6
61.6
6.4

Table 7: time (in seconds) number nodes solving fair scheduling problem
enforcing different consistency notions.

weak EDGAC* requires time solve FDGAC*. look execution discover
FDGAC* strong first lower bound computed already close, identical,
objective value optimal solution. Therefore, enforcing weak EDGAC* gives little
improvement reducing search space.
P EOPLE -M ISSION CHEDULING
problem extends doctor-nurse rostering problem described Beldiceanu, Katriel
Thiel (2004). Given three groups n persons, missions must assigned team containing exactly one person group. also given set constraints restricting combination team one mission. problem schedule people teams
missions restriction violated. model problem {xij } denoting mission
assigned ith person j th group random unary costs. combination restriction
softened ternary cost functions. Two global cost functions SOFT SAMEvar ({xi1 }, {xi2 })
SOFT SAMEvar ({xi2 }, {xi3 }) posted ensure team exactly contains one person
group. fix = 6 vary n. results shown Table 8. Similarly Table 7, weak
EDGAC* produces smallest number nodes, requires time FDGAC*.
5.2.4 B ENCHMARKS BASED



OFT R EGULAR

REGULAR() constraint many applications. following, focus two: (1) nurse
rostering problem, and; (2) STRETCH() constraint modelling.
N URSE ROSTERING P ROBLEM
nurse rostering problem (Cheng, Lee, & Wu, 1997) schedule group n nurses four
shifts, PM shift, shift, Overnight, Day-Off, period requirements satisfied.
287

fiL EE & L EUNG

n
4
5
6
7

Reified Approach
Time(s)
Nodes
17.5
16992.0
427.8 283950.2
*
*
*
*

Strong IC
Time(s)
Nodes
4.0
5931.6
45.2
51029.8
666.6 553001.2
*
*

GAC*
Time(s) Nodes
1.6
1517.4
11.2
7073.8
156.6 75481.6
*
*

FDGAC*
Time(s)
Nodes
0.2
247.8
3.4
831.2
55.6
11065.2
1348.0
333937.6

weak EDGAC*
Time(s)
Nodes
238.8
0.4
3.4
693.4
10957.8
69.2
1714.0 296019.2

Table 8: time (in seconds) number nodes solving people-mission scheduling
problem enforcing different consistency notions.

(a)
n
3
4
5
6
7
8

Reified Approach
Time(s) Nodes
260.66 118562
*
*
*
*
*
*
*
*
*
*

Strong IC
Time(s) Nodes
152.6 91661.4
*
*
*
*
*
*
*
*
*
*

(b)
n
3
4
5

Reified Approach
Time(s)
Nodes
286.6 122542.4
*
*
*
*

Strong IC
Time(s) Nodes
178.4 91933.8
*
*
*
*

SOFT REGULAR

var

()

GAC*
Time(s) Nodes
2.0
956.2
25.4 6983.4
*
*
*
*
*
*
*
*
SOFT REGULAR

edit

GAC*
Time(s) Nodes
9.2
2850.4
126.2 27267.6
*
*

FDGAC*
Time(s) Nodes
0.1
28.6
0.1
32.6
4.0
379.0
63.4
4017.6
207.6 12242.0
821.2 44414.0

weak EDGAC*
Time(s)
Nodes
0.1
22.8
0.1
28.0
3.6
273.6
37.8
1927.2
42.8
2167.6
229.2
10437.0

()
FDGAC*
Time(s) Nodes
5.6
841.4
25.4
2568.8
535.6
47091.2

weak EDGAC*
Time(s)
Nodes
803.2
6.2

27.6
2424.0
546.8 40244.0

Table 9: time (in seconds) number nodes solving nurse scheduling problem
enforcing different consistency notions.

experiment, nurses scheduled four days (1) nurse must
three shifts, least two PM shifts, least one Overnight, least one day-off; (2)
shift must two nurses, PM shift Overnight must one nurse, and; (3) AMshifts preferred packed together, preference also posted Day-Offs.
model problem set variables {xij } denote shift assigned ith nurse j th
day random unary costs. Restrictions (1) (2) modeled SOFT GCCval cost functions,
(3) modeled either SOFT REGULARvar SOFT REGULARedit cost functions. restrictions allowed violated. results shown Table 9. SOFT REGULARedit ()
used, FDGAC* wins term runtime. However, SOFT REGULARvar () used, weak EDGAC*
requires least time least number nodes solve.
ODELLING



TRETCH () C ONSTRAINT

Another application REGULAR() constraint model constraints describe patterns. One
example STRETCH() constraint.
288

fiC ONSISTENCY ECHNIQUES

n
30
35
40
45
50
55

Reified Approach
Time(s) Nodes
183.5
7346.2
419.4 13845.2
842.4 23485.0
2318.2 55976.0
*
*
*
*



(a) SOFT REGULARvar()
Strong IC
GAC*
Time(s)
Nodes
Time(s) Nodes
68.2
5203.2
36.4
573.0
162.2
10297.8
80.6
971.6
335.6
18067.2
148.4
1423.2
900.4
42007.0
378.2
3042.0
1142.2
88616.8
165.8 10762.2
2231.4 146901.6
306.0 17130.0
(b)

n
30
35
40
45
50
55

Reified Approach
Time(s) Nodes
216.2
6038.6
561.6 12487.6
1128.1 20585.8
*
*
*
*
*
*

OFT G LOBAL C OST F UNCTIONS

SOFT REGULAR

Strong IC
Time(s) Nodes
83.2
3861.6
204.2
7626.0
413.0 12789.6
1151.8 30480.6
2122.8 62225.2
*
*

edit



WCSP

FDGAC*
Time(s) Nodes
30.0
171.4
57.6
239.8
92.2
328.6
240.6
651.8
130.2 1660.6
208.0 2291.8

weak EDGAC*
Time(s) Nodes
162.6
35.2
233.4
69.0
316.0
108.2
570.6
246.4
118.2
1316.0
193.8
1856.8

FDGAC*
Time(s) Nodes
34.2
123.8
60.6
164.0
90.8
208.4
239.6 371.0
204.8 967.6
264.2 972.8

weak EDGAC*
Time(s) Nodes
39.6 122.4
70.8 162.8
101.6 194.0
207.8
299.6
185.0
823.2
234.6
777.6

()

GAC*
Time(s) Nodes
40.6
447.4
86.8
706.0
165.8
1080.0
446.4
2346.2
348.6
9189.0
623.8 13496.8

Table 10: time (in seconds) number nodes solving sliding problem enforcing different consistency notions.

Definition 24 (Pesant, 2001) Given value v tuple L(S). v-stretch maximal
subsequence identical values v . STRETCH(S, ub, lb) constraint satisfied
length v-stretch ubv least lbv .
simplicity, omit case STRETCH() constraint circular. However,
handled variable duplication (Pesant, 2004).
STRETCH() constraint described automaton thus modelled using
REGULAR () constraint (Pesant, 2004). SOFT REGULAR var () SOFT REGULAR edit () cost
functions directly applied define two soft variants STRETCH() constraint, namely
SOFT STRETCH var () SOFT STRETCH edit (). flow-based projection-safe inheriting
property SOFT REGULARvar () SOFT REGULARedit () respectively.
demonstrate idea, conduct experiments using following sliding problem.
sliding problem order n consists set variables {x1 , . . . , xn } domains D(xi ) = {a, b}
random unary costs. subsequence {xi , . . . , xn5+i }, 1 5, required
contain a-stretches length 2 b-stretches length 2 3. restriction enforced
STRETCH constraints. allow violations modeling constraints using either
SOFT REGULAR var SOFT REGULAR edit cost functions. results shown Table 10. Weak
EDGAC* needs time FDGAC* instances small, weak EDGAC* pays
large instances. experiment also shows STRETCH constraint, important
constraint modeling patterns, efficiently propagated WCSP framework.
5.2.5 ISCUSSIONS
control comparison conducted examine efficiency ToulBar2
global cost functions encoded explicitly tables well. cannot done meaningful
manner since tables prohibitively large. Consider simple cost function 10 variables,
289

fiL EE & L EUNG

domain size 10. table already requires storage order 1010 integers
tens gigabytes.
Based experiments, two conclusions made. First, experiments show
reified approach strong IC weak terms search space pruning runtime
reduction compared GAC*, FDGAC*, weak EDGAC*. Second, stronger consistency
notions, weak EDGAC*, FDGAC* GAC*, worthwhile although expensive
enforce. shown experiments, GAC* reduces number search nodes least
3 times reified approach 1.5 times strong IC. GAC* runtime
least 4 times less reified approach 1.5 times less strong IC. Weak EDGAC*
FDGAC* reduce search space much greater extent. additional pruning usually
compensate extra effort. Although Table 7 Table 8 shown cases weak
EDGAC* results slower runtime, FDGAC* wins small margin. general, weak
EDGAC* still worthwhile enforce. Table 10 confirms stronger consistency
desirable problem becomes large.

6. Conclusion Remarks
section, summarize contributions shed light possible future directions
research.
contributions five-fold. First, introduce strong IC based IC (Zytnicki et al.,
2009) give algorithm enforce strong IC. Besides, prove strong IC confluent.
also show enforcing strong IC WCSP stronger GAC reified approach.
Second, give algorithm enforce GAC* WCSP, enforcement exponential. efficient enforcement, introduce flow-based projection-safety, preserves basic structure
global cost functions. give sufficient conditions global cost function flow-based
projection-safe. also show part proof projection extension done
flow property preserved. Third, generalize FDAC* (Larrosa & Schiex, 2003)
FDGAC* give enforcement algorithm. Again, flow-based projection-safety helps FDGAC*
enforcement. Fourth, attempt generalize EDAC* using similar methods, find nontrivial. discover give example limitation EDAC*. cost functions share
one variable, oscillation similar one demonstrated Full AC* (de Givry et al.,
2005) occur. solve problem, introduce cost-providing partitions, restrict
distribution costs enforcing EDAC*. Based cost-providing partitions, define weak
EDGAC*, enforced polynomial time flow-based projection-safe global cost
functions. Last least, show soft versions IFFERENT(), GCC(), SAME()
REGULAR () flow-based projection-safe. also prove practicality framework
empirical results various benchmarks involving global cost functions. empirical results
agree theoretical strength consistencies terms search tree pruning. results
also show stronger consistency notions like weak EDGAC* FDGAC* worthwhile
enforce, especially solving large problems.
Three directions future work possible. first one investigate even stronger
consistency notions, VAC (Cooper et al., 2010), also benefit projection-safety
make enforcement practical global cost functions. Second, current sufficient conditions
flow-based projection-safety might still overly restrictive. example, global cost function SOFT SEQUENCE (Maher, Narodytska, Quimper, & Walsh, 2008) satisfy three
290

fiC ONSISTENCY ECHNIQUES



OFT G LOBAL C OST F UNCTIONS



WCSP

conditions. interesting find possible definition flow-based projection-safety,
allow efficient projection extension operations. Third, consider minimum
cost flow computation finding minimum cost global cost function. interesting
check approaches, mathematical programming, used achieve
results.

Acknowledgments
Work described paper generously supported grants CUHK413808 CUHK413710
Research Grants Council Hong Kong SAR.

References
Beldiceanu, N. (2000). Global Constraints Graph Properties Structured Network Elementary Constraints Type. Proceedings CP00, pp. 5267.
Beldiceanu, N., Carlsson, M., & Petit, T. (2004). Deriving Filtering Algorithms Constraint
Checkers. Proceedings CP04, pp. 107122.
Beldiceanu, N., Katriel, I., & Thiel, S. (2004). Filtering Algorithms Constraints.
Proceedings CPAIOR04, pp. 6579.
Cheng, B., Lee, J. H. M., & Wu, J. (1997). Nurse Rostering System Using Constraint Programming Redundant Modeling. IEEE Transactions Information Technology
Biomedicine, 1, 4454.
Cooper, M., de Givry, S., Sanchez, M., Schiex, T., Zytnicki, M., & Werner, T. (2010). Soft Arc
Consistency Revisited. Artificial Intelligence, 174, 449478.
Cooper, M., & Schiex, T. (2004). Arc Consistency Soft Constraints. Artifical Intelligence, 154,
199227.
Cooper, M. C. (2005). High-Order Consistency Valued Constraint Satisfaction. Constraints,
10(3), 283305.
de Givry, S., Heras, F., Zytnicki, M., & Larrosa, J. (2005). Existential Arc Consistency: Getting
Closer Full Arc Consistency Weighted CSPs. Proceedings IJCAI05, pp. 8489.
Demassey, S., Pesant, G., & Rousseau, L.-M. (2006). Cost-Regular Based Hybrid Column Generation Approach. Constraints, 11, 315333.
Dijkstra, E. W. (1959). Note Two Problems Connexion Graphs. Numerische Mathematik, 1, 269271.
Johnson, D. (1977). Efficient Algorithms Shortest Paths Sparse Networks. Journal
ACM, 24(1), 113.
Larrosa, J., & Schiex, T. (2003). Quest Best Form Local Consistency Weighted
CSP. Proceedings IJCAI03, pp. 239244.
Larrosa, J., & Schiex, T. (2004). Solving Weighted CSP Maintaining Arc Consistency. Artificial
Intelligence, 159(1-2), 126.
Lauriere, J.-L. (1978). Language Program Stating Solving Combinatorial Problems.
Artificial Intelligence, 10, 29127.
291

fiL EE & L EUNG

Lawler, E. (1976). Combinatorial Optimization: Networks Matroids. Holt, Rinehart Winston.
Leung, K. L. (2009). Soft Global Constraints Constraint Optimization Weighted Constraint
Satisfaction. Masters thesis, Chinese University Hong Kong.
Maher, M., Narodytska, N., Quimper, C.-G., & Walsh, T. (2008). Flow-Based Propagators
SEQUENCE Related Global Constraints. Proceedings CP08, pp. 159174.
Pesant, G. (2001). Filtering Algorithm Stretch Constraint. Proceedings CP01, pp.
183195.
Pesant, G. (2004). Regular Language Membership Constraint Finite Sequences Variables.
Proceedings CP04, pp. 482495.
Petit, T., Regin, J.-C., & Bessiere, C. (2000). Meta-constraints Violations Constrained
Problems. Proceedings ICTAI00, pp. 358365.
Petit, T., Regin, J.-C., & Bessiere, C. (2001). Specific Filtering Algorithm Over-Constrained
Problems. Proceedings CP01, pp. 451463.
Regin, J.-C. (1996). Generalized Arc Consistency Global Cardinality Constraints. Proceedings AAAI96, pp. 209215.
Regin, J.-C. (2002). Cost-Based Arc Consistency Global Cardinality Constraints. Constraints,
7, 387405.
Sanchez, M., de Givry, S., & Schiex, T. (2008). Mendelian Error Detection Complex Pedigrees
using Weighted Constraint Satisfaction Techniques. Constraints, 13(1), 130154.
Schiex, T., Fargier, H., & Verfaillie, G. (1995). Valued Constraint Satisfaction Problems: Hard
Easy Problems. Proceedings IJCAI95, pp. 631637.
Van Hentenryck, P., Michel, L., Perron, L., & Regin, J.-C. (1999). Constraint Programming OPL.
Proceedings International Conference Principles Practice Declarative
Programming, pp. 98116.
van Hoeve, W.-J., Pesant, G., & Rousseau, L.-M. (2006). Global Warming: Flow-based Soft
Global Constraints. J. Heuristics, 12(4-5), 347373.
Zytnicki, M., Gaspin, C., & Schiex, T. (2009). Bounds Arc Consistency Weighted CSPs. Journal
Artificial Intelligence Research, 35, 593621.

292

fiJournal Artificial Intelligence Research 43 (2012) 477522

Submitted 12/11; published 03/12

Proximity-Based Non-uniform Abstractions
Approximate Planning
Jir Baum
Ann E. Nicholson
Trevor I. Dix

Jiri@baum.com.au
Ann.Nicholson@monash.edu
Trevor.Dix@monash.edu

Faculty Information Technology
Monash University, Clayton, Victoria, Australia

Abstract
deterministic world, planning agent certain consequences
planned sequence actions. so, however, dynamic, stochastic domains
Markov decision processes commonly used. Unfortunately suffer curse
dimensionality: state space Cartesian product many small sets (dimensions),
planning exponential number dimensions.
new technique exploits intuitive strategy selectively ignoring various dimensions different parts state space. resulting non-uniformity strong
implications, since approximation longer Markovian, requiring use modified planner. also use spatial temporal proximity measure, responds
continued planning well movement agent state space, dynamically adapt abstraction planning progresses.
present qualitative quantitative results across range experimental domains
showing agent exploiting novel approximation method successfully finds solutions planning problem using much less full state space. assess
analyse features domains method exploit.

1. Introduction
deterministic world planning agent certain consequences
actions, plan sequence actions, knowing execution necessarily
achieve goals. assumption appropriate flexible, multi-purpose robots
intelligent software agents need able plan dynamic, stochastic
domains operate, outcome taking action uncertain.
small medium-sized stochastic domains, theory Markov decision processes
provides algorithms generating optimal plan (Bellman, 1957; Howard, 1960; Puterman & Shin, 1978). plan takes account uncertainty outcome taking
action, specified distribution possible outcomes. flexibility,
reward function rather simple goal, relative desirability
otherwise situation specified.
However, domain becomes larger, algorithms become intractable approximate solutions become necessary (for instance Drummond & Bresina, 1990; Dean,
Kaelbling, Kirman, & Nicholson, 1995; Kim, 2001; Steinkraus, 2005). particular
state space expressed terms dimensions, Cartesian product sets,
size resulting computational cost exponential number dimensions.
c
2012
AI Access Foundation. rights reserved.

fiBaum, Nicholson & Dix

hand, fortunately, results fairly structured state-space effective
approximations often possible.
solution based selectively ignoring dimensions, parts
state space, time. words, obtain approximate solutions
dynamically varying level abstraction different parts state space.
two aspects approach. Firstly, varying level abstraction introduces
artefacts, planning algorithm must somewhat modified eliminate these.
Secondly, interestingly, appropriate abstraction must selected later modified
planning action progress.
work extension synthesis two existing approaches approximate planning: locality-based approximation envelope methods (Dean et al., 1995)
structure-based approximation uniform abstraction (Nicholson & Kaelbling, 1994; Dearden & Boutilier, 1997). work extends exploiting structure
locality, broadening scope problems contemplated. Baum Nicholson
(1998) introduced main concepts full details algorithms experimental
results presented Baums (2006) thesis. studies arbitrary
abstraction, instance Bertsekas Tsitsiklis (1996). However, generally
theoretical case tended treat approximation Markovian,
would resulted unacceptable performance practice. improve extending planning algorithm deal non-Markovian aspects approximation.
Finally, use measure locality, introduced Baum Nicholson (1998),
similar flexible influence measure Munos Moore (1999).
assume agent continues improve plan acting
planning failures generally fatal. also deal control error exclusively. Sensor
error considered assumed agent accurately discern current
world state (fully observable), accurately knows state space, goal
reward function, distribution effect actions (no learning).
remainder paper organised follows. Section 2 reviews background,
introduces abstraction provides framework. Section 3 discusses planning
static non-uniform abstraction, Section 4 presents method initially selecting
non-uniform abstraction based problem description. Section 5 presents method
changing abstraction based policy planned, Sections 6 7 introduce
proximity measure method varying abstraction based measure,
respectively. Section 8 presents results based direct evaluation calculated
policy simulation. Finally, Section 9 discusses results Section 10 gives
conclusions outlines possible directions future work.

2. Planning Non-uniform Abstractions
non-deterministic world planning agent cannot certain consequences
actions except probabilities, cannot plan simple sequence actions achieve
goals. able plan dynamic, stochastic domains, must use
sophisticated approach. Markov decision processes appropriate commonly used
representation sort planning problem.
478

fiProximity-Based Non-uniform Abstractions Planning

2.1 Illustrative Problems
aid exposition, present two example problems here. full set experimental
domains presented Section 8.1.
two illustrative problems grid navigation domain, shown Figure 1.
integer x coordinates 0 9, three doors either
open closed damage indication either yes no. agent
move one four cardinal directions, open door next it, nothing.
doors fairly difficult open, probability success 10% per time step,
moving 80% chance success, effect case failure. Running
wall closed door causes damage, cannot repaired. transitions
shown Table 1. agent starts location marked s0 Figure 1 doors
closed damage, goal reach location marked damage.
x=0
y=0

1

2

3

4

5

6

7



s0

8

9

k3

1

x=0
y=0

2

3

4

5

6

7

s0

8

9

k3

1



2

d1

d2

k1

4

4

5

5

6

6



8





d1
3

7



2

3

9

1



d2



k1





7
8

k2

d3

9

(a)

k2

d3
(b)

Figure 1: layout grid navigation domain. blue arrows show optimal
path (a) suboptimal path (b) 3Keys problem. 3Doors
problem grid layout (walls doors) keys.

3Keys problem also contains keys, required open doors. agent
may one time. additional action allows agent
pick key location shown figure, open action requires
corresponding key effective (there separate unlock action). 3Doors problem
contains keys doors unlocked closed therefore corresponding
keys pickup action.
optimal policy obtained exact planning 3Doors problem simply takes
shortest path door 2. 3Keys problem, optimal plan collect
keys 3 1, pass south door 1 east door 3, shown Figure 1(a).
suboptimal plan shown Figure 1(b).
479

fiBaum, Nicholson & Dix

x
Stay




pre-state
d1
d2
d3

post-state
d1
d2

dmg



x















3
3


y+1



















South
2
7




2
2
2
9


open






open






















80%
80%

North
2
7




3
3
0
3


open






open






















80%
80%

East
4
4
4
4
4
9
x

0
1
2
9























open




















80%
80%
80%
80%

West
5
5
5
5
5
0
x

0
1
2
9























open




















Open
2
2
7
7
4
5


2
3
2
3
9
9










































80%

80%

80%
80%
80%
80%
80%

80%
10%
10%
10%
10%
10%
10%

d3

dmg



























yes
yes


2
2


y1





















yes
yes


5
5
5
5


x+1





































yes
yes


4
4
4
4


x1





































yes
yes


















open
open








open
open








open
open








yes

Table 1: Transitions 3Doors problem, showing important changed dimensions
only. First matching transition used. percentage shown, given
post-state occur probability, otherwise state unchanged. Transitions without percentages deterministic.

480

fiProximity-Based Non-uniform Abstractions Planning

2.2 Exact Planning
One approach exact planning stochastic
domains
involves using Markov Decision


ff
0
Processes (MDPs). MDP tuple S, A, T, R, , state space,
set available actions, transition function, R reward function s0
initial state. agent begins state s0 . time step, agent selects
action A, which, together current state, applies obtain distribution
S. current state next time-step random according distribution
write PrT (s, a, ) probability action taken state result state
next time-step. agent also given reward time step, calculated
R current state (and possibly also action selected). aim agent
maximise cumulative function rewards, typically expected discounted1
sum discounting factor . fully-observable MDP, agent full knowledge.
particular, agent aware , R current state selecting action.
well-known fully-observable MDP, optimal solution expressed
policy : mapping current state optimum action. planning
problem, then, calculation . side-effect calculation, standard
algorithms also calculate value function V : R, expected discounted sum
rewards starting state. Table 2 summarises notation used paper.
well known iterative algorithms, Bellmans (1957) value iteration, Howards
(1960) policy iteration, modified policy iteration Puterman Shin (1978)
computing optimal policy . However, becomes larger, calculation
becomes computationally expensive. particularly state space structured
Cartesian product dimensions, = S1 S2 SD , |S| exponential
D. Since algorithms explicitly store V usually , functions S,
space complexity therefore also exponential D. Since iterate arrays,
time complexity also least exponential D, even consideration
fast iterative algorithms converge. Typically, grows, planning
quickly becomes intractable. Since practice amount computation allowed
agent limited, necessitates approximations process.
3Doors problem, six dimensions (two x coordinates, three
doors one damage), = {0 . . . 9} {0 . . . 9} {open, closed}
{open, closed} {open, closed} {damage, damage} |S| = 12 800. action space
set five actions, = {north, south, east, west, open}. transition function
specifies outcomes taking action state. reward function R 0
agent h7, 7i location (marked diagram) damage, 1
location damage, 2 damage. Finally, s0 state
agent h0, 0i location, doors closed, damage.
Exact planning listed results |S| V (s0 ) comparison.
approximation, planner must consider whole state space S. |S| therefore
measure cost planning directly terms space indirectly terms
time. hand, since planning exact, optimal value function V
1. illustrative problems simple goals achievement, use time discounting order
remain general mathematical convenience.

481

fiBaum, Nicholson & Dix

symbol
original

Sd

meaning

abstract
W P(S)


state space (specific state space / worldview, resp.)
dimension state space
N
number dimensions
sS
wW
state
0


initial state
scur

current state (in on-line planning)
sd Sd
wd Sd
dimension state w, resp.

set actions (action space)
a0
default action


transition function (formal)
PrT :SAS[0, 1] PrT :WAW[0, 1] transition function (in use)
R:S R
R:WR
reward function (one-step reward)
V :SR
V :W R
value function (expected discounted sum rewards)
[0, 1)
discount factor reward
:SA
:WA
policy
:

optimal policy
V :S R

optimal value function (exact value function )
, :
, : W
approximate policy, ith approximate policy

exact value function (note: may abstract)
V : R
V : R
V : W R
approximate value function (approx. V )
Table 2: Summary notation. first column notation original MDP,
second notation non-uniform abstraction applied.

obtained, along optimal policy ensuring agent expect obtain
value. figures approximations must measure.
2.3 Uniform Abstraction
One method approximation take advantage dimensions ignoring
irrelevant marginally relevant order obtain
approximate solution. uniform sense dimensions ignored
throughout state space. Since approach attacks curse dimensionality
originates, dimensions, effective counteracting it.
Dearden Boutilier use obtain exact solution (Boutilier, 1997) approximate one (Boutilier & Dearden, 1996; Dearden & Boutilier, 1997). However, abstractions fixed throughout execution, dimensions also deleted problem
pre-determined sequence. makes approach somewhat inflexible. Similarly,
Nicholson Kaelbling (1994) propose technique approximate planning.
delete dimensions problem based sensitivity analysis, refine abstraction execution time permits, still uniform. Dietterich (2000) uses kind
abstraction combination hierarchical planning good effect: subtask,
Navigate location t, ignore irrelevant dimensions, location items
482

fiProximity-Based Non-uniform Abstractions Planning

picked even ultimate destination agent. Generally, time problem
description derived general source rather specified particular
problem, uniform abstraction help. Gardiol Kaelbling (2008) use dimensions relevant, marginally, ignoring results approximate
solution improved planning progresses.
Unfortunately, however, least human-specified problems, one would generally
expect mentioned dimensions way relevant. Irrelevant dimensions
eliminated human designer natural course specifying problem.
Depending domain situation marginally relevant dimensions might
included, often, nearly enough effective approximation.
list comparisons uniform abstraction results reason
sample domains, makes little sense. almost dimensions
important solving problem. case methods exist
effective uniform abstraction, integrated approach easily.
2.4 Non-uniform Abstraction
approximation, non-uniform abstraction, replaces state space W, particular type partition S, originally introduced Baum Nicholson (1998). call
W worldview, members W worldview states members specific
states.2 Non-uniform abstraction based intuitive idea ignoring dimensions
parts state space. example, door interest agent
walk it, ignored parts state space
distant door. particular member worldview wi W, dimension
either taken account
(concrete, refined in), ignored altogether (abstract,
Q completely
w singleton subset corresponding
w
coarsened out). wi =

d=1

concrete dimensions equal Sd abstract dimensions.3 worldview
selection modification methods ensure W remains partition times.
give example, 3Doors problem one possible worldview location
damage dimensions concrete every state, door dimensions concrete
states within two steps respective door.
Note domain still fully-observable. question lack knowledge
dimensions question, wilful conditional ignorance planning
matter computational expediency. approximation also subsumes exact
planning uniform abstraction. exact planning, dimensions set uniformly
concrete, |W| = |S| worldview state corresponds one specific state.
uniform abstraction, combination abstract concrete dimensions fixed
entire worldview. treated special cases general approach.4
2. Previously, used word envelope concept (Baum & Nicholson, 1998), however,
worldview better describes approximation used envelope.
3. allow dimension partially considered, abstract level dimensions,
within them. dimension x coordinate either particular value, fully
abstract, never 59, instance.
4. modified calculation reduces standard algorithm uniform fully concrete worldviews,
planner obtains standard results cases.

483

fiBaum, Nicholson & Dix

hand, approximation longer Markovian. dimension
abstracted away indeterminate. notation Markov Decision Processes,
represented distribution concrete states, dimension
stochastic specific (but ignored) value. distinction important
truly stochastic outcome, quite valid plan retry action
succeeds (for instance, opening door 3Doors problem). dimension
merely ignored, agent obtain outcome (door closed) time moves
region dimension ignored, within worldview, previous
states appear matter. discuss Section 3.
2.5 Comparison Approaches
Non-uniform abstractions began appear literature first usually side-effect
structured method, state space represented decision tree based
individual dimensions, Boutilier, Dearden, Goldszmidt (1995, 2000). Note,
however, decision tree structure imposes restriction kinds non-uniform
abstraction represented: dimension root tree considered
throughout state space, on. significant restriction results
representation much limited representation. similar restriction affects
de Alfaro Roys (2007) magnifying-lens abstraction, refinement multivalued dimensions taken bit-by-bit bits interleaved, level
decision tree halves space along different dimension pre-determined order.
note, would work well dimensions correspond more-or-less connected
space, gridworld, would less well features like doors
grid navigation domain. Magnifying-lens abstraction calculates upper lower bounds
value function, rather single approximation, advantage guiding
abstraction selection allows definite termination condition (which lack).
hand, always considers fully-concrete states part algorithm, limiting
space savings square root state space, whereas algorithm work
mixture variously abstract states necessarily including fully concrete
ones. Another related approach variable grids used discretisation,
indirectly used discrete domains, Boutilier, Goldszmidt, Sabata (1999) do,
dimensions reasonably approximated continuous (for instance money). Unlike
approach, variable grids completely inapplicable predicates binary
enumerated dimensions. Some, Reyes, Sucar, Morales (2009), use techniques
ways quite similar continuous MDPs, though quite different
ways: consider refinement only, coarsening; use sampling, rather
directly dealing domain model; use different refinement method,
refinement evaluated fact either committed rolled back.
Perhaps similar approach one modules Steinkraus (2005),
ignore-state-variables module. However, module appears completely manual,
requiring input variables (dimensions) ignored parts state
space. also uses values dimensions current state scur , rather
distribution, obviously restricts situations may used (for instance,
3Doors problem, doors could ignored starting state). Finally, since
484

fiProximity-Based Non-uniform Abstractions Planning

Steinkraus (2005) analyse report relative contributions modules
solution, meta-planning problem selecting arranging modules,
difficult know extent particular module useful.
approaches take advantage different features different domains. instance,
factored MDP approach (used, instance, Boutilier et al., 2000, Guestrin,
Koller, Parr, & Venkataraman, 2003) suitable domains parts state
action spaces grouped together within group actions action
dimensions affect corresponding states state dimensions interaction
groups weak. St-Aubin, Hoey, Boutilier (2000) iterate symbolic representation
form algebraic decision diagrams produce approximate solutions, Sanner
Boutilier (2009) iterate symbolic representation whole class problems
domain, using symbolic dynamic programming, first-order algebraic decision diagrams
linear value approximation, pre-compute generic solution used
quickly solve specific problems class. focus state space, others approximate action space, typically grouping actions (possibly hierarchically)
macro actions, Korf (1985). instance Hauskrecht, Meuleau, Kaelbling, Dean,
Boutilier (1998) Botea, Enzenberger, Muller, Schaeffer (2005) take approach,
Parr (1998) uses finite state automata macro actions Srivastava, Immerman, Zilberstein (2009) take using algorithm-like plans branches
loops. Goldman, Musliner, Boddy, Durfee, Wu (2007) reduce state space generating (limited-horizon, undiscounted) MDP different, non-MDP representation
including reachable states, pruning detected clearly
immediately poor, inferior equivalent already-generated states. Naturally, many
approaches combined. instance, Gardiol Kaelbling (2004, 2008) combine state space abstraction envelope work Dean et al. (1995), Steinkraus
(2005) uses modular planner view combining many approaches may
appropriate given problem. details approaches variants
refer reader recent survey field Daoui, Abbad, Tkiouat (2010).
2.6 Dynamic Approximate Planning
top-level algorithm shown Algorithm 1. initialisation, consisting
selecting initial abstraction setting policy, value proximity a0 , 0
proportionally size worldview state, respectively,5 planner enters
infinite loop stochastically alternates among five possible calculations,
described following sections. elsewhere algorithm, use
stochastic choice default absence directed method.
agent assumed processing power available acting,
continually improve policy, modify approximation updates focus
planning based current state. means agent need plan
well unlikely possibilities, therefore expend planning effort
likely paths closer future, expecting reaches parts
state space, improve approximation appropriate.
5. Initialising approximate policy action a0 constitutes domain-specific heuristic namely,
known default action a0 reasonably safe states, nothing action.

485

fiBaum, Nicholson & Dix

Algorithm 1 High-level algorithm Approximate Planning Dynamic Non-uniform
Abstractions
select initial abstraction /* Algorithm 3 */
worldview states w
(w) a0 ; V (w) 0; P(w) |w|
|S|
policy value calculation /* Algorithm 2 */
loop
choose stochastically
policy value calculation /* Algorithm 2 */

policy-based refinement /* Algorithm 4 */

proximity calculation /* Algorithm 5 */

proximity-based refinement /* Algorithm 6 */

proximity-based coarsening /* Algorithm 7 */
input latest current state; output policy

Actual execution policy assumed separate thread (executive),
planner concern timeliness requirements
domain: whenever action needs taken, executive simply uses policy
recently received planner.
Dean et al. (1995) call recurrent deliberation, use locality-based
approximation. similar architecture used CIRCA system (Musliner, Durfee, &
Shin, 1995; Goldman, Musliner, Krebsbach, & Boddy, 1997) guarantee hard deadlines.
CIRCA terminology, planner AIS (AI subsystem), executive
RTS (real-time subsystem).
alternative recurrent deliberation pre-cursor deliberation, agent first
plans, finished planning begin act, making
adjustments plan policy. Effectively, planner, current state constant
equal initial state throughout planning. work pre-cursor mode used
measurements, involves fewer potentially confounding variables.
Conceptually, approach divided two broad parts: open-ended problem selecting good abstraction relatively closed problem planning within
abstraction. Since latter part closed, deal first, next
section, covering Algorithm 2. explore open-ended part Sections 57,
covering Algorithms 37.

3. Solving Non-uniformly Abstracted MDPs
Given non-uniform abstraction, simplest way use planning take one
standard MDP algorithms, modified policy iteration Puterman
Shin (1978), adapt non-uniform abstraction minimally. formulae translate
486

fiProximity-Based Non-uniform Abstractions Planning

directly obvious fashion. becomes function worldview states instead concrete
states, on, shown Algorithm 2 (using simple variant update policy
w procedure). Probabilities transition one worldview state another
approximated using uniform distribution concrete states (or possibly
distribution, information available).
Algorithm 2 policy value calculation
repeat n times
worldview states w
update value w
worldview states w
update policy w
update value w
procedure update value w
PrT (w, (w), w) = 1
/* optimisation V (w) calculated directly case */
V (w) R(w)
1
else
P
V (w) R(w) + w PrT (w, (w), w )V (w )

procedure update policy
P w variant simple
(w) min arg maxa w PrT (w, a, w )V (w )

procedure update policy w variant Locally Uniform Abstraction
/* see Section 3.1 discussion Locally Uniform Abstraction */
absdims {d :
w . PrT (w, a, w ) > 0 w abstract d}
w abstract
absdims
LUA w . w :
dimension w = dimension w
/ absdims
P
|w w |


V w . w W |w | V (w )
P
(w) min arg maxa w PrT (w, a, w )V (LUA(w ))

Note Algorithm 2, considered ordered set a0 smallest element
minimum used arg max gives one possibility.
two aspects: (a) domain-specific heuristic, instance, breaking ties favour
default action possible, (b) avoid policy-basedP
refinement (see Section 5)
based actions equal value. Secondly, efficiency, w calculated
states w PrT (w, a, w ) > 0, since states make contribution
sum. Finally, number n tuning parameter particularly critical (we use
n = 10).
course, replacing state space worldview W way not, general,
preserve Markov property, since actual dynamics may depend aspects state
space abstracted worldview. simple variant ignore assume
Markov property anyway, grounds is, all, approximation.
Unfortunately, resulting performance unacceptably large error, including
outright non-attainment goals.
487

fiBaum, Nicholson & Dix

instance, 3Doors problem, situation occur three
doors whenever abstract s0 concrete near door question.
doors relatively difficult open, 10% probability success per try.
hand, moving area abstract area
concrete, assumed probability door already open 50%.
calculations performed, turns preferable plan loop, repeatedly trying
illusory 50% chance success rather attempting open door
10% chance success. agent never reach goal. Worse still, ways,
estimate quality solution quite good, V (s0 ) 19.0,
fact better even optimal solutions V (s0 ) 27.5, true quality
solution poor, V (s0 ) = 100 000, corresponding never reaching goal (but
incurring damage, either; figures discounting factor = 0.999 99).
Regions take account particularly bad piece information may seem unattractive, described above, vice versa. call problem Ostrich effect,
agent refusing accept unpleasant fact, like mythical ostrich buries
head sand. solution, Locally Uniform Abstraction, described next section.
abstracted approximation simply treated MDP agent
know state reach (near closed door near open door), correspond
underlying process, might reach particular state deterministically (as
here). problem especially obvious example, planner plans loop.
reminiscent problem noted Cassandra, Kaelbling, Kurien (1996),
plan derived POMDP failed actual robot got loop particular
situation sensor completely reliable contrary model.
3.1 Locally Uniform Abstraction
ostrich effect occurs states different abstraction considered, instance
one door abstract one door concrete closed.
solution make abstraction locally uniform, therefore locally Markovian
duration policy generation iterative step. making abstraction locally,
temporarily uniform, iterative step policy generation algorithm never work
across edge abstract region, and, since information available
states considered point, impetus favoured
avoided basis (for instance, avoiding state door concrete closed
favour one door abstract). action chosen chosen based
information presence absence.
modification update policy w procedure Algorithm 2:
states considered one one, region around state accessed
function returns locally uniform version. States concrete state
considered averaged ignore distinctions. different states
considered, sometimes states taken themselves, sometimes estimated
values V averaged adjacent states. means dimensions
partially considered states cases, mean
concrete region must extend one step beyond region dimension
488

fiProximity-Based Non-uniform Abstractions Planning

immediately relevant. dimension fully considered state, possible
outcomes actions state must also concrete dimension.
modified procedure proceeds follows: first dimensions abstract
possible outcome state updated w collected variable absdims.
function LUA constructed takes worldview states w returns potential
worldview states w like w abstract dimensions absdims.
core modification, named LUA Locally Uniform Abstraction. Since
potential states returned LUA not, general, members W, therefore
necessarily value stored V , function V constructed calculates
weighted
averages value function V potential states. sum,
P

calculated states w w w 6= efficiency. Finally,

w
update step carried using two functions LUA V .
Unfortunately, modification applied, algorithm may may converge depending worldview. Failure converge occurs concrete region
small cases, algorithm cycle two policies (or conceivably
more) instead converging. One must careful, therefore, worldview, avoid
situations, else detect modify worldview accordingly. policybased worldview refinement algorithm described Section 5 ensures convergence
practice.

4. Initial Abstraction
beginning planning, planner must select initial abstraction. Since
worldview never completely discarded planner, infelicity stage may
impair entire planning process, worldview-improvement algorithms
make amount weakness here.
different ways select initial abstraction. propose one heuristic
method selecting initial worldview based problem description,
variants. Consider example door 3Doors problem associated
two locations, is, immediately either side. makes sense, then, consider
status door two locations. association read problem
specification. Intuitively, structure solution likely resemble structure
problem. incorporates structure transition function initial
worldview. reward function also incorporated, reflecting assumption
dimensions reward based important.
use two-step method derive initial worldview, shown Algorithm 3.
Firstly, reward function specified based particular dimensions. make
dimensions concrete throughout worldview, leave dimensions abstract.
3Doors problem, x dmg dimensions, step
10 10 2 = 200 states worldview.
Secondly, transition function specified decision trees, one per action. use
find nexuses dimensions, is, linking points, points
dimensions interact. nexus corresponds one path root
tree leaf. example, 3Doors problem, decision tree open action
contains leaf whose ancestors x, y, d1 stochastic node, choices leading
489

fiBaum, Nicholson & Dix

Algorithm 3 select initial abstraction
/* set worldview completely abstract */
W {S}
/* reward step */
reward step enabled
dimensions mentioned reward tree
refine whole worldview dimension
/* nexus step */
nexus step enabled
leaf nodes action trees
worldview states w matching pre-state
refine w dimensions mentioned pre-state

leaf labelled respectively 4, 2, closed 10%. corresponds nexus
sx = 4, sy = 2 sd1 = closed (the stochastic node ignored determining nexus).
total, four nexuses side door, two locations immediately
adjacent, shown Figure 2(a), connecting relevant door dimension x
coordinates. initial worldview shown Figure 2(b), x, dmg concrete
everywhere doors abstract except concrete one location directly
side door, corresponding location nexuses Figure 2(a).
steps, |W| = 212, compared |S| = 1 600 specific states.

x=0

1

2

3

4

5

6

7

8

9

x=0

y=0

y=0

1

1

1

2

3

4

5

6

7

2





2

d1

d2

3





3

d1

d2

4

4

5

5

6

6

7

7

8

8

9



9

(a)

8

9

d3 d3
(b)

Figure 2: Nexus step initial abstraction, showing (a) location nexuses
3Doors problem (there four nexuses ) (b) locations
door dimensions concrete initial worldview.

490

fiProximity-Based Non-uniform Abstractions Planning

3Keys problem, location nexuses Figure 2(a), except
nexuses location also involve corresponding
key dimensions. Thus, initial worldview, locations shown Figure 2(b)
concrete corresponding door dimension, also, closed,
corresponding key dimension. states doors open, key dimension
remains abstract. initial worldview size 3Keys |W| = 224.
Due locally-uniform abstraction, concrete door dimensions taken
account minimal degree. worldview used without
refinement, expected resulting policies would poor.
results6 bear expectation. worldview initialization methods therefore
intended used own, rather basis refinement. Thus,
real test methods well work coupled worldview
modification methods, described below.

5. Policy-Based Refinement
section presents first worldview modification methods, policy-based refinement. method modifies worldview based directly current approximate
policy . particular, refines states based differences actions planned
adjacent, differently-abstract states. differences indicate dimension may
important, adjacent states abstract dimension refined (i.e.
dimension made concrete states).
method previously introduced Baum Nicholson (1998), showed,
using small navigation domain example (the 3Doors problem paper),
refinement method resulted good policy, though optimal. present quantitative results consider complex domains.
5.1 Motivation
motivation method twofold. Firstly, already indicated, method detects
areas particular dimension important, affects action planned,
ensures concrete adjacent states. Thus regions dimension taken
account expand long dimension matters, stop. Secondly,
method fulfils requirements choosing worldview avoid non-convergence
policy calculation, mentioned Section 3.1 above.
Dimensions important affect policy, since policy planners
output. less important parts state space affect
policy. Thus, dimensions need concrete remain abstract
gleaned part state space comparing optimal actions
various states. optimal actions equal, states abstract,
differ, states concrete. However, optimal policy .
approximate policy worldview, difficult. However, planner compare
policies areas dimension concrete, found important there,
expand area concrete. policy-based refinement policy calculation
6. Omitted uninteresting, presented Baum (2006).

491

fiBaum, Nicholson & Dix

alternate, refinement continue area dimension concrete covers
whole region important.
Section 3.1 noted planning algorithm requires worldview chosen
care. algorithm described section detects situations potentially problematic locally-uniform abstraction modifies worldview preclude them.
Intuitively, incorrect behaviour occurs edge concrete region intersects
place two fairly-similarly valued courses action, corresponding
two different paths goal.
5.2 Method
method uses transition function definition adjacent states, worldview states w w considered adjacent . PrT (w, a, w ) > 0. definition
symmetrical general, since transition function not, problem
method, seen below. algorithm shown Algorithm 4.
Algorithm 4 policy-based refinement
candidates
worldview states w
actions
w : P r(w, a, w ) > 0

dimensions
: w abstract w concrete
w

abstract


construct w :
dimension w = dimension w 6=

b

w , w . (w ) 6= (wb ) wa w 6= wb w 6=
/* policy throughout w */
candidates candidates {(w, d)}
(w, d) candidates
w W
/* replace w
group states concrete */
anew
w
concrete

wnew :
dimension wnew = dimension w 6=
W W {wnew }
new
(wnew ) (w); V (wnew ) V (w); P(wnew ) |w|w| | P(w)
W W \ {w} /* discarding also stored (w), V (w) P(w) */

Example 3Doors problem, instance, applying method planning
increases number worldview states initial 212 220231, depending
stochastic choices (recall |S| = 1 600 comparison). produces concrete regions
nice tight around doors, shown Figure 3, allowing algorithm
converge reasonable solution. solution fact optimal given initial
state s0 , though simply coincidence, since s0 taken account
algorithm states somewhat suboptimal actions (the agent would reach
goal states, shortest route).
492

fiProximity-Based Non-uniform Abstractions Planning

x=0

1

2

3

4

5

6

7

8

9

x=0

y=0

1

2

3

4

5

6

7

8

9

y=0


1

d1

d2

1

k2

2

d1 d1 d1

d2 d2 d2

2

3

d1 d1 d1 d1

d2

3

d1 k1 d1 d1

4

d1 d1

4

d1 d1 d1 d1 d1

5

5

d1 d1 d1

6

6

d1

7

7





k1






k2



8

d3

8

k3

9

d3 d3 d3

9

k3 k3 k3

(a)



k2 k2 k2







(b)

Figure 3: Example non-uniform abstraction (a) 3Doors (b) 3Keys problems
policy-based refinement. x, dmg dimensions concrete everyd
where; d1, d2 d3 indicate corresponding door concrete; k1,


k2 k3 indicate corresponding door concrete corresponding
key also concrete door closed.

worldview obtained method often quite compact. instance, rather
refining simple 2 3 rectangular region side door 3Doors, human
might, algorithm makes 4 locations concrete approach side door,
enough obtain good solution. seen north sides doors
d1 d2, well west side door d3 (3 concrete locations, due edge).
departure side doors d2 d3, even better makes refinement all:
south door d2 east door d3, action move toward goal, regardless
status door actions equal, refinement takes place.
south side door d1 seems rather less compact. concrete area fact
big 6 locations 3Doors seems excessive compared compact
concrete areas elsewhere. occur nexus close region
best action take genuinely depends status dimension nexus,
difference small. somehow agent found h4, 3i policy-based
refinement independent scur optimal path genuinely would depend whether
door d1 open, path slightly suboptimal case. theory
region could arbitrarily large extent, seems relatively minor effect
practice. Here, instance, adds couple states, 1% |W|,
found real problem domains (or domains used Baum,
2006).
493

fiBaum, Nicholson & Dix

5.3 Limitations
Policy-based refinement deal cases single dimension makes difference. two dimensions needed combination, often miss them.
instance, 3Keys problem key quite distant corresponding door
policy-based refinement therefore never find relationship two.
key, appears reason pick up, door appears
means unlocking it.
Obviously, fixed ad hoc rewarding picking keys sake.
Indeed, domain formulations literature exactly that, rewarding agent
partial achievement goal. However, clean solution. effect,
domain specifications cheat providing hints.
Another problem policy-based refinement provide coarsening
worldview, modifying ways, instance execution progresses
planner needs update plan. Indeed, policy-based refinement ignores initial state
s0 altogether, current state scur recurrent planning. Thus produces
solution regardless part problem agent actually asked solve.
waste computation solving parts agent unlikely actually
visit, perhaps importantly carries penalty corresponding loss
quality relevant parts.
following sections describe proximity-based worldview modification, needed
solve domains combinations dimensions important also makes
use s0 scur , appropriate.

6. Proximity Measure
general, worldview mostly concrete near agent planned path
goal, allow detailed planning, mostly abstract elsewhere, conserve computational resources. section describe measure (originally Baum & Nicholson,
1998) realises concept, proximity P, decreases state
future less probable.7 section extends brief description Baum
Nicholson (1998). following section present new worldview modification
methods based directly measure.
6.1 Motivation
proximity P realisation intuitive concept states near agent
likely visited, opposed distant agent unlikely. naturally
takes account current state scur recurrent planning, initial state s0
pre-cursor planning, unlike policy-based refinement ignores altogether. Thus
planner selecting worldviews based proximity measure produce solutions tailored
particular scur s0 ignore parts MDP irrelevant nearirrelevant performance state. Thus saves computation would otherwise
7. Baum Nicholson (1998) used word likelihood measure. prefer proximity
avoid confusion meanings word likelihood. Munos Moore (1999) use word
influence somewhat similar measure continuous domains.

494

fiProximity-Based Non-uniform Abstractions Planning

wasted solving parts agent unlikely actually visit, perhaps
importantly carries advantage corresponding gain quality
relevant parts. allows agent deal problems 3Keys beyond
reach policy-based refinement.
Implicitly, agent plans reaches mostly-abstract parts
state space, improve approximation appropriate. planner thus continually
improves policy, modifies approximation updates focus planning based
current state scur . means refining regions agent finds
likely visit, coarsening away details regions longer likely
visit already traversed.
three aspects proximity: temporal, spatial probabilistic. Firstly,
temporal aspect indicates states may encountered near future, exponentially decaying scale. second aspect spatial nearness states (in terms
state space) agent planned path. spatial aspect somewhat indirect,
spatial structure domain represented implicitly transition
matrix, proximity measure reflect it. two aspects combined
proximity give single real number 0 1 state, denoted P P
proximity, spatial aspect temporal aspect. number
interpreted probability namely probability encountering state P
interpreted probability distribution states, giving final, probabilistic
aspect proximity.
6.2 Calculation
formula proximity P similar formula value function.
three differences. Firstly, instead beginning reward function based
current state function, cur. Secondly, transition probabilities time-reversed
(that is, matrix transposed). value calculation based
reward function, occurs future (after taking actions), current state
function based present, taking actions. Since order taking actions
function upon formula based reversed time, similar reversal must
b used
applied transition probabilities. Thirdly, estimated future policy
b
b
instead . estimate, stochastic policy defined making (s) distribution
actions assigns constant probability current (s) distributes
remaining probability mass among actions equally. distributed probability
mass corresponds probability policy change sometime future,
or, alternately, probability currently-selected action yet correct.
formula therefore:
X

b ), s)P(s )
Pr(s , (s
(1)
P(s) cur(s) + P







P proximity discounting factor (0 P < 1)

1 P scur =
cur(s) =
0
otherwise
495

(2)

fiBaum, Nicholson & Dix

P
constant 1P chosen current-state function P(s) converges
1, words P probability distribution. checked near future,
agent probability P(s) state s, assuming follow policy
near future defined probability checking time proportional
Pt (that is, P interpreted stopping probability). value calculation,
one instead solve set linear equations
X

b ), s)P(s )
Pr(s , (s
(3)
P(s) = cur(s) + P




or, matrix notation,
(I P TbT )P = cur

(4)

b identity
Tb transition matrix induced stochastic policy
matrix. implementation uses matrix form, shown Algorithm 5. proximity
measure needs little adjustment work non-uniformly abstract worldview:
simply replaced w (1) (2), scur = becoming scur w.
Algorithm 5 proximity calculation
solve matrix equation P linear system:
(I P TbT )P = cur
measure two tuning parameters, replanning probability discounting
factor P . replanning probability controls spatial aspect: trades focus
likely path planning less likely eventualities nearby. Similarly, P controls
temporal aspect: smaller P is, short sighted greedy planning
be. Conversely, P close 1, planner spend time planning future
might better spent planning here-and-now. set depending
reward discounting factor , mode planner. use P = 0.95,
replanning probability 10%.
Example Proximities 3Doors problem shown Figure 4 initial situation (agent h0, 0i, doors closed) possible situation later execution
(agent h4, 2i, doors closed). Larger symbols correspond higher proximity. One
immediately see agents planned path goal, large symbols correspond
states agent expects visit. Conversely small proximities show locations
agents planned path goal. example, agent expect visit
states south-western room, especially already passed door
1. Similarly, proximities around initial state much lower agent
h4, 2i, expect need return.
6.3 Discussion
One interesting feature resulting numbers emphasise absorbing nearabsorbing states somewhat might intuitively expected. However, considering
496

fiProximity-Based Non-uniform Abstractions Planning

x=0

1

2

3

4

5

6

7

8

9

x=0

y=0

y=0

1

1

2

2

3

3

4

4

5

5

6

6

7

7

8

8

9

9

hx = 0, = 0i

1

2

3

4

5

6

7

8

9

hx = 4, = 2i

Figure 4: Proximities 3Doors problem s0 possible later scur ; symbol size
logarithmic, proximities range 237 21.4 ; P = 0.95, replanning probability 10%.

absorbing states general important, good feature, especially since
normally planner try minimise probability entering absorbing state
(unless goal). feature help ensure absorbing states kept
mind long chance falling them. Dean et al. (1995), instance,
note algorithm undesirable absorbing states along path goal
tend come candidates removal consideration (due low probability
reaching current policy), make special accommodation
removed consideration. proximity measure emphasising
states, special handling necessary.
contrast approach, Kirman (1994) uses probabilities Es steps,
Es (an estimate of) number steps agent take switching
previous policy policy currently calculated. assumes Es
estimated well, current policy policy executive, oneplanning-cycle probability appropriate measure. fact one would prefer least
two-planning-cycle look-ahead, agent begins within area focus
new policy, also remains throughout validity policy, probably
longer, since planners foresight extend beyond next thinking cycle.
philosophically, reliance planning cycle length desirable,
artefact planner rather intrinsic domain.
somewhat related approach prioritised sweeping (see instance Barto, Bradtke,
& Singh, 1995). Like present approach, defines measure states
way interesting. Unlike approach, applies measure determine
497

fiBaum, Nicholson & Dix

order formulae V calculation applied,
applied preferentially interesting states less frequently uninteresting
unimportant states. well-known order calculation MDP planning
algorithms varied greatly without forfeiting convergence optimal policy,
prioritised sweeping takes advantage this. Often done measure change
V previous calculations, approaches use look-ahead current state,
ways simple version proximity (in fact, corresponds
threshold P replanning probability set 1). proximity measure P might well
good candidate approach: apply V calculation states chosen directly
according P distribution.8
Munos Moore (1999) use influence measure deterministic continuous
domains, similar P. fact, main difference measure
two parameters re-uses replanning probability
(effectively zero). means cannot take account replanning, neither
difference horizon entails, possibility policy may change
acted upon. Absorbing states, instance, would emphasised
proximities.

7. Proximity-Based Dynamic Abstraction
proximity measure described previous section used focus planners attention areas likely useful near future. Firstly, means worldview
made match proximities, refining coarsening appropriate. Secondly, since proximity measure takes account current state, method
automatically update worldview agents circumstances change recurrent
mode, is, planning execution concurrent.
7.1 Refinement
High proximity indicates states agent likely visit near future.
planner therefore plan states carefully. abstract, reason
refine allow detailed planning. states high proximity
therefore considered candidates refinement.
High proximity defined simple threshold, shown Algorithm 6.
refinement occurs, anomaly sometimes appears. Like anomaly led
policy-based refinement method, arises different levels abstraction, here,
adjacent abstract state causes problem, rather recentlyrefined one. state refined, values V new states initially estimated
states previous value V . However, typically, means
overestimated others underestimated. policy re-calculated,
state overestimated value attractive.
Since problem directly follows moment refinement, self-correcting.
iterations, planner converges correct policy values. However,
8. retaining theoretical guarantee convergence desired, care would taken since

P zero states reachable current state. practice, course, optimality
otherwise unreachable states immaterial.

498

fiProximity-Based Non-uniform Abstractions Planning

Algorithm 6 proximity-based refinement
stochastically choose dimension
worldview states w
P(w) > threshold w abstract
/* replace w
group states concrete */
anew
w
concrete
new
w
:

dimension wnew = dimension w 6=
W W {wnew }
new
(wnew ) (w); V (wnew ) V (w); P(wnew ) |w|w| | P(w)
W W \ {w} /* discarding also stored (w), V (w) P(w) */

so, transient anomalies appear policy, worst case,
planner may replan path, refine states re-trigger
anomaly. Rather large parts state space spuriously refined way.
occurs combined V calculation phase, may update
V chance converge. solution create variant phase, V
calculation only, replaces V calculation phase values stabilise.
two iterations, appears sufficient. alternative solution would
copy difference values adjacent, concrete states
possible, thus obtaining better estimated values newly-refined states. However, since
simpler solution V -only calculation works satisfactorily, complex possibility
explored.
7.2 Coarsening
Low proximity indicates states agent unlikely visit near future.
planner therefore need plan states carefully. Usually, already
abstract, never refined first place. However, concrete
previously refined reason coarsen free memory
CPU time detailed planning elsewhere. states low proximity
therefore considered candidates coarsening.
Proximity-based coarsening useful primarily on-line planning scenario recurrent planning. agent moves state space current state
scur changes, states likely visited near future. especially useful agent finds unexpected part state space, instance
due low-probability outcomes, agent planned path leading part way
goal (perhaps partial reward). case, however, parts state
space already traversed coarsened favour refinement front agent.9
One might also imagine planning progresses, planner may wish concentrate
different parts state space coarsening might useful cull abandoned
explorations switch focus. However, observed domains
9. States already traversed cannot discarded, even agent never visit again, since
worldview partition since agent necessarily know whether need revisit (or
end revisiting) states.

499

fiBaum, Nicholson & Dix

found pre-cursor mode, coarsening generally worsens quality policies
positive contribution.
Coarsening proceeds three steps, shown Algorithm 7. first step
similar proximity-based refinement: time proximity-based coarsening phase
invoked, worldview scanned states low proximity (below threshold),
put list candidates. second step tricky. Coarsening needs join
several states one. However, representation allow arbitrary partitions
worldviews therefore allow coarsening-together arbitrary set
worldview states. planner must therefore find group states among lowproximity candidates coarsened valid worldview state. groups
detected fact differ one dimension size
dimension, therefore covering completely. Finally, groups found
replaced single abstract state.
Algorithm 7 proximity-based coarsening
/* collect candidates coarsening */
candidates {w : P < threshold}
/* find groups candidates coarsened together */
/* partition candidates according pattern abstract concrete dimensions */
patterns candidates / {(wa , wb ) : . wa concrete wb concrete d}
groups
p patterns
dimensions
states p concrete
/* partition p dimensions except d, giving potential groups */
potgroups p / {(wa , wb ) : 6= . dimension wa = dimension wb }
/* add potential groups size dimension groups */
groups groups {g potgroups : |g| = |Sd |}
/* replace group states single, abstract state */
g groups
g W
stochastically choose
wa g
new
w
abstract
construct wnew :
dimension wnew = dimension wa 6=
W W {wnew }
P
1 P
new )


(wnew ) (wa ); V (wnew ) |g|
wg V (w); P(w
wg P(w)

W W \ g /* discarding also stored (w), V (w) P(w) w g */

cases, may impossible coarsen section worldview despite low
proximity, due situation somewhat akin grid-lock. Probably simplest example
one Figure 5, shows worldview five states three-dimensional binary
specific state space, three states ignoring different dimension each,
remaining two take account three. situation, group states
500

fiProximity-Based Non-uniform Abstractions Planning

S1

0

0

0

0

1

1

1

1

S2

0

0

1

1

1

1

0

0

S3

0

1

1

0

0

1

1

0

w1

w2

w3

w4

w5

Figure 5: non-uniform worldview cannot immediately coarsened. state space
three binary dimensions (eight states). worldview two concrete states,
w1 w4 , three abstract states, w2 , w3 w5 , abstract different
dimension.

coarsened single dimension. coarsening possible, one states must
first refined, low P candidates proximity-based
refinement. this, integration uniform abstraction method coarsening
would also straightforward selecting initial worldview refinement,
unless worldview kept uniform. However, even non-uniform worldview would
difficult. instance, dimension could simply removed possible
rather everywhere.

8. Results
run algorithm range different domains demonstrate approach.
domains divide two broad groups. first group consists grid navigation
domain only. domain intuition gathered preliminary runs
done, however, problems domain show well approach performs,
cannot show generality. second group consists domains literature,
demonstrating well approach generalises.
8.1 Experimental Domains
introduce domains section. first five problems grid navigation
domain, two already described Section 2.1, shown Figure 1, three additional
problems. remaining domains based domains literature, particular
used Kim (2001) Barry (2009).
described Section 2.1, problems grid navigation domain shown Figure 1
x dimensions size 10, three door dimensions (binary: open/closed)
damage dimension (also binary). far 3Doors problem, 3Keys
problem, keys agent must pick keys open corresponding doors.
three remaining problems 1Key, shuttlebot 1010. 1Key problem
similar 3Keys, except agent capable holding one key time,
instead three binary dimensions keys, one four-valued dimension
indicating key agent holds (or none). shuttlebot problem introduces
cyclic goal (with extra loaded dimension damage dimension tri-valued)
501

fiBaum, Nicholson & Dix

(a) grid navigation domain
keys world
Problem
3Doors
0
1Key
3
3
3Keys
0
shuttlebot
1010
0

keys held time

1
1, 2 3



note

cyclic
tiled

dimensions
6
7
9
7
8

|S|
1 600
6 400
12 800
4 800
160 000

(b) robot4 -k domain
Problem
robot4 -10
robot4 -15
robot4 -20
robot4 -25

dimensions
11
16
21
26

|S|
10 240
491 520
20 971 520
838 860 800

(c) factory domain
Problem
s-factory
s-factory1
s-factory3
(d) tireworld domain
locations
Problem
tire-small
5
8
tire-medium
tire-large
19
19
tire-large-n0

initial
n1
n0
n12
n0

dimensions
17
21
25

goal
n4
n3
n3
n3

|S|
131 072
2 097 152
33 554 432

route length
3
4
1
3

dimensions
12
18
40
40

|S|
4 096
262 144
1 099 511 627 776
1 099 511 627 776

Table 3: Experimental domains problems, dimensionality state
space size.

1010 variant increases size problem tiling grid 10
direction (by two extra dimensions, xx yy, size 10). Table 3(a) summarises
problems domain.
next two domains based Kim (2001). Firstly, robot4 -k domain,
based Kims (2001) ROBOT-k domain reducing number actions
four. robot4 -k domain problems consist cycle k rooms shown Figure 6,
room light, analogous doors 3Doors problem
enable agent move. four actions variant go forward, turn light
current room off, nothing. original formulation allowed agent
combination toggling lights going forward, total 2k+1 actions,
reduced approach intended approximate action space.
goal move first room last. k + 1 dimensions state space
k2k states, listed Table 3(b).
502

fiProximity-Based Non-uniform Abstractions Planning

4
k-1

3

0

2
1

Figure 6: robot4 -k domain.
drill B
part B:

shape B

drilled

polish B

polish B

shaped

dip B
polished

spray B
handpaint B

painted
glue

connected

bolt
drill
part A:

shape

shaped

drilled
polish

polish

dip
polished

spray

painted

handpaint

Figure 7: factory domain.
Kims (2001) factory domain10 series variants simple manufacturing problem, represented purely predicates (that is, dimensions size 2). agent make
product two parts must drilled, painted finally joined together.
Figure 7 shows simplified diagram, omitting interactions options
instance, achieve painted predicate, agent may spray, dip handpaint
object; connect two objects, may use glue bolt (and latter requires
drilled); on. Unlike domains, partial rewards available
agent achieving certain subgoals. problems used listed Table 3(c).
final domain tireworld domain 2006 ICAPS IPC competition
(Littman, Weissman, & Bonet, 2006) used Barry (2009). domain, robotic
car trying drive point point B. car room carry one spare tire
locations additional spare tires them. locations, car
carrying spare, pick one up. n locations car,
2n + 2 binary dimensions problem, follows: n dimensions used represent
location car. valid states states one location dimension
true, explicitly stated anywhere domain.11 Another n dimensions
used represent locations spare tire not. final two
dimensions represent whether car carrying spare whether flat tire.
10. domain previously used Hoey, St.-Aubin, Hu, Boutilier (1999) based
builder domain Dearden Boutilier (1997) adapted standard job-shop scheduling
problems used test partial-order planners.
11. touch aspect discussion Section 9, case include domain without
change order facilitate comparison literature.

503

fiBaum, Nicholson & Dix

n0

n15
n10
n8

n4

n0
n12

n17

n6

n3

n9

n8
n18
n2

n6

n14

n4

n10

n16
n2

n1

n1
n1

n13

n3

n12
n3
n7

n0

tire-small

n7

n11

tire-medium

n5

tire-large

goal ( )
locations.
Figure 8: tireworld domain problems, indicating initial ( )

Barry (2009) uses two tireworld problems, labelled small large.
small tireworld problem 5 locations 12 variables 14 actions, large
one 19 locations 40 variables 100 actions. Curiously, large problem,
direct road initial goal locations, takes single action
solve problem. makes difficult assess whether Barrys method has, fact,
scaled up. addition two, created medium-sized tireworld, 8 locations
18 variables, removing locations large tireworld moving initial
location n0, goal. variants listed Table 3(d) shown
Figure 8. final variant, tire-large-n0, shown, identical large tireworld
except initial location moved n0.
8.2 Direct Evaluation Policies Pre-cursor Deliberation
smaller problems 3Doors, 1Key, 3Keys, directly evaluate
approximate policies produced planner running pre-cursor deliberation.
problems small enough use exact algorithm calculate actual value
function corresponding approximate policies. noted Section 2.6,
useful involves fewer potentially confounding variables, exploit full
potential approach.12
Table 4(a) shows results policy-based refinement is,
proximity-based methods (Algorithms 5, 6 7) disabled. problem, table
lists size problem |S| value optimal solution initial state
12. Proximity-based coarsening (Algorithm 7) primarily aimed regions state space agent
already traversed, pre-cursor deliberation traversal. Coarsening would therefore
expected bring limited benefit pre-cursor deliberation direct evaluation would
meaningful evaluate performance. therefore evaluated recurrent deliberation.

504

fiProximity-Based Non-uniform Abstractions Planning

olu
tio
nv
alu
wo
e
rld
vie
w
siz
e
rel
ati

wo
rld
vie
w
siz
pla
e
nn
er

esti
sol
uti te

val
ue
act
ua
ls
olu
tio
nv
alu
e

ize

op
tim
al


sta
te
sp
ce


dis

cou
nti
ng

fac
tor

V (s0 ), representing costs results exact planning. followed
size worldview |W| absolute number percentage |S|, planners
estimate value solution initial state V (s0 ), actual value
solution initial state V (s0 ). first half part table discounting
factor = 0.999 99, second half = 0.95. Averages 10 runs
shown planner run 1000 . 1000 chosen approximation
assumed 1 000 phases sufficient planner converge. practice,
convergence generally took place much earlier. detected, however,
overall assumption planner continues plan forever, responding changing
inputs, makes convergence somewhat irrelevant.


problem
|S|
V (s0 )
|W|
(a) policy-based refinement
226.4
0.999 99 3Doors
1 600 27.50
326.8
1Key
6 400 79.47
3Keys
12 800 61.98
262.0
222.6
0.95
3Doors
1 600 14.63
1Key
6 400 19.59
296.8
245.7
3Keys
12 800 18.99
(b) proximity-based refinement
0.999 99 3Doors
1 600 27.50 1 381.7
1Key
6 400 79.47 4 166.7
3Keys
12 800 61.98 4 262.8
0.95
3Doors
1 600 14.63 1 363.2
1Key
6 400 19.59 2 828.2
3Keys
12 800 18.99 4 230.6
(c) policy- proximity-based refinement
0.999 99 3Doors
1 600 27.50 1 361.7
1Key
6 400 79.47 4 635.5
3Keys
12 800 61.98 5 948.2
0.95
3Doors
1 600 14.63 1 359.5
1Key
6 400 19.59 4 036.1
3Keys
12 800 18.99 3 748.8

|W|
|S|

V (s0 )

V (s0 )

14%
5.1%
2.0%
14%
5.6%
1.9%

22.50
37 512.20
25 015.60
13.22
15.23
14.56

27.50
100 000.00
100 000.00
14.63
20.00
20.00

86%
65%
33%
85%
44%
33%

27.50
60 031.79
70 018.59
14.63
19.92
19.70

27.50
60 031.79
70 018.59
14.63
19.92
19.70

85%
72%
46%
85%
63%
29%

27.50
20 063.57
30 043.39
14.63
19.67
20.00

27.50
20 063.57
30 043.39
14.63
19.67
20.00

Table 4: Results direct evaluation policies pre-cursor deliberation three
different refinement methods, evaluated 1 000 phases.

505

fiBaum, Nicholson & Dix

results part (a) table divide neatly two types: without keys (3Doors
problem), planner succeeds ten runs, getting perfect policies given starting
state. two problems, 1Key 3Keys, planning invariably fails. two
problems, agent must pick key far door opens, version
planner simply cannot think ahead extent. three these, planner
somewhat optimistic, estimating better value obtains cases even
better optimum. instance, 3Doors problem = 0.999 99, planners
estimate value V (s0 ) 22.50, better true value
optimum, V (s0 ) = V (s0 ) = 27.50. fractional |W| table due
averaged ten runs. final size worldview sometimes depends extent
order dimensions states refined, order randomised
runs. instance, 3Doors problem = 0.999 99, W various
sizes ranging 220 231 states end ten runs, average
226.4.
results part (a) similar two values . main difference
smaller leads smaller numbers. instance, value indicating failure 100 000
1
,
= 0.999 99 20 = 0.95. values tend multiples 1
1
smaller value here, 1 20 rather 100 000. cases,
smaller range make differences less obvious: instance, estimated value
1
column (V (s0 )), clear whether numbers approximations 1 1
1
(and failure reach goal) 0 1
minus small number (representing success).
1
represent rewards costs
units represent once-off rewards costs, multiples 1
obtained perpetuity. However, expected desired behaviour. smaller
represents disinterest distant future, reward cost perpetuity
much important once-off reward cost.
Table 4(b) shows results ten runs pre-cursor mode 1000 proximitybased refinement (no policy-based refinement coarsening) problem
. seen, 3Doors problem solved optimally cases.
surprising, complex problem.
1Key 3Keys problems interesting. figures Table 4(b) arise
average 31 successful runs, values close equal optimal values
V (s0 ), 23 unsuccessful runs values 100 000. = 0.999 99,
planner found successful policy 4 10 runs 1Key problem 3 times
10 3Keys problem. Similarly = 0.95 case (2 times 3 times,
1
respectively), since optimal path quite long compared 1
, success
means reward 19.59 (or 18.99) failure punished 20, effect
difficult discern.
Table 4(c) shows results proximity-based refinement policy-based refinement combined (no coarsening). Naturally, 3Doors problem either refinement
method alone already obtained optimal policy shows improvement. worldview size |W| differs slightly Table 4(b), policy-based refinement sometimes
directed, |W| tend slightly smaller exploratory proximitybased refinement alone, larger policy-based refinement alone.
506

fiProximity-Based Non-uniform Abstractions Planning

two problems, 1Key 3Keys, show improvement compared either
refinement methods alone. solved 43 runs = 0.999 99
values 20 063.57 30 043.39 represent averages 2 3 unsuccessful runs
8 7 successful ones, compared 4 3 successful runs proximity-based
refinement successful runs policy-based refinement only. = 0.95,
1Key problem solved 8 runs, due discounting length
path, goal near horizon. Again, success meaning reward
19.59 failure receives 20, distinction great. 3Keys problem
= 0.95 find solution parameters, receives uniform
20 runs, suboptimality one unit.
behaviour runs generally quite straightforward. Typically,
initially calculating agent cannot reach goal initial worldview,
worldview size gradually increases, plateaus coarsening here, movement agent, behaviour really possible. successful runs,
planner plans route goal point increase, worldview becomes sufficient, V (s0 ) quickly reaches final value. Rarely, V (s0 ) may oscillate
twice first. omit graphs here, presented Baum (2006).
8.3 Evaluation Simulation Recurrent Deliberation
larger problems, performance evaluated simulation, running agent
simulated world observing reward collects. problems, direct
evaluation possible calculating actual value function using exact
algorithm longer tractable. Simulation recurrent delibertion also context
coarsening evaluated. comparison, section presents results
3Keys problem evaluated simulation, without coarsening.
Figure 9 shows representative sample results simulation 3Keys problem
refinement methods coarsening, combination options
shown Table 4(c) previous section, evaluated simulation rather directly.
small graph shows different individual run. seen, agent behaves
reasonably working recurrent planning mode simulation.
left vertical axes graphs represent reward R, plotted thick red lines.
run 1 Figure 9, instance, agent starts receiving reward 1
step, meaning goal, damage domain. 180 onwards, receives
reward 0 per step, meaning goal, damage. right vertical axes
worldview size |W|, thin blue lines. shown details throughout section,
is, scaled actual worldview sizes rather full 1|S| ranges. Taking run 1
Figure 9 again, see |W| grows relatively quickly 80, continues
grow slowly eventually levels little 5 000. full state space,
comparison, 12 800. run 2, agent received reward similarly, state space
grew longer, eventually levelling somewhat 7000. runs 3 4, agent
failed reach goal continued receiving reward 1 throughout. run 3,
worldview size levelled little 3000, run 4 steadily grew 5000.
horizontal axes simulated world time, corresponding discrete time-steps
MDP. two time-scales simulation: wall clock time, indicating
507

fiBaum, Nicholson & Dix

1:

|W|

R

2:

7000
6000

0

7000
6000

0

5000

5000

4000

4000

3000

3000

2000

-1

|W|

R

2000

-1

1000
0

50

100

150

200

1000

0
250

0

|W|

R

50

100

time

3:

150

200

time

R

4:

7000
6000

0

|W|

7000
6000

0

5000

5000

4000

4000

3000

3000

2000

-1

2000

-1

1000
0

50

100

0
250

150

200

1000

0
250

0

time

50

100

150

200

0
250

time

Figure 9: Simulation results, 3Keys problem, policy-based proximity-based refinement,
coarsening (four runs). Reward (left axes, thick red lines) worldview size
|W| (right axes, thin blue lines; detail) world time (horizontal axes).

passage real time, number phases planner performed. simulation configured take 1 time step per 10s wall clock time. number phases
R
controlled simply given speed (1.5GHz Intel
) CPU implementation coded flexibility rather efficiency. Ideally, agent gradually
move general direction goal planning, simplifies problem,
fast agent runs far ahead abstraction planner.
planner algorithm terminate, since planner assumed keep planning
(and agent keep acting) indefinitely. goal-oriented domains,
examples paper, one might consider achieving goal termination
condition, (a) example domains assume agent continue
goal goal maintenance, albeit trivial, (b) apply non-goal-oriented
domains (c) even goal-oriented domains clear apply condition
case agent fails reach goal. simulation, therefore, runs either
terminated manually, succeeded appeared progress
508

fiProximity-Based Non-uniform Abstractions Planning

1:

|W|

R

0

-1

0

2:

9000
8000
7000
6000
5000
4000
3000
2000
1000
0
50 100 150 200 250 300 350 400

0

-1

0

time

|W|

R

9000
8000
7000
6000
5000
4000
3000
2000
1000
0
50 100 150 200 250 300 350 400
time

Figure 10: Simulation results illustrating effect coarsening worldview size, 3Keys
problem, policy-based refinement, proximity-based refinement coarsening
(two runs).

likely made, run fixed number world time steps, selected based
manually-terminated runs allowance variation.
coarsening Figure 9, worldview sizes monotonic increasing.
Different runs refined differently domain algorithm stochastic.
beginning planning, agent receiving reward 1 per step,
yet goal. worldview size increases, planner eventually finds policy
leads goal runs 1 2, seen better reward 0 obtained
runs. simple relationship worldview size performance: runs
worked worldview 5 000 larger generally succeeded, smaller
worldviews generally not. vast majority runs (> 90%), agent reached
goal.
coarsening (Algorithm 7) activated, compared situation turned
off, reward gathered agent declines slightly, still reaches goal
vast majority runs (> 90%). Figure 10 shows two runs, one successful one
unsuccessful, 3Keys problem proximity-based coarsening well two
refinement methods, contrast Figure 9 two refinement methods
used. Note effect interleaving refinement coarsening: worldview
size |W| (thin blue line) longer monotonic, instead alternately increased
decreased, shows jagged line graph. Slightly fewer runs reach
goal. decline solution quality expected, however, since goal coarsening
reduce size worldview.
completeness, also tested agent proximity-based methods
(Algorithms 6 7) active policy-based refinement (Algorithm 4) deactivated.
configuration, agent collects reward generally takes steps toward
goal, without directed policy-based refinement, largely exploratory
proximity-based methods discover keys consequently cannot reach goal.
509

fiBaum, Nicholson & Dix

8.4 Effect Discounting Factor
shuttlebot problem similar 3Doors problem requires agent move
back forth two locations repeatedly. interesting preliminary
runs pre-cursor mode solved = 0.999 99 solved optimally
= 0.95. considered whether = 0.999 99 case might behave better
simulation, agent took advantage possibility planning nearest
reward replanning reward obtained. all, agent could function
well even none policies good solution itself. However, illustrated
Figure 11, agents behaviour similar pre-cursor case: = 0.999 99,
(a) refinement only, run 1, (b) coarsening, run 2, would pick reward
immediately adjacent s0 , that. Again, setting planners discounting
factor 0.95, (c) coarsening, runs 3 4, provided much better performance.13
Note effect balance refinement coarsening (b) (c):
worldview size |W| nice steady throughout runs (though admittedly fair
fraction |S| = 4 800).
8.5 Initial Worldview
problems, standard initial worldviews large planner. Even
modified, smaller initial worldviews obtained enabling nexus step Algorithm 3
disabling reward step large. Disabling reward nexus steps
results singleton initial worldview, W = {S}, treats entire state space
single (very) abstract worldview state. Unfortunately, means planner
starts little way hints direction refine and, least
initially, information base crucial decision. upshot
collects reward. cases remains initial state s0 , others moves around
state space sometimes distance, times small loop
reach goal subgoals.14
situation factory domain problems Kim (2001), fact
agent collected reward simulated runs, even though quite runs
substantial actions taken. similar result occurs 10x10 problem (in grid
navigation domain). reward obtained agent problem,
standard initial worldview somewhat large planner and, again, singleton
initial worldview badly. best, runs, agent took limited steps
general direction goal.
interesting case tireworld domain. Again, tire-large large
standard initial worldview fails obtain solution reward step initial
worldview only. However, manually-chosen initial worldview refines locations
along path start state goal planning begins, planner solves
tire-large, also tire-large-n0 40% runs (in one less
one minute, although atypical).
13. rewards appear two horizontal lines runs 3 4, one solid one broken, task
cyclic, agent collects reward 1 twice cycle reward 0 steps.
14. details unsuccessful runs, including |W| behaviour, given Baum (2006).

510

fiProximity-Based Non-uniform Abstractions Planning

(a) = 0.999 99, coarsening (one run)
R
|W|
1:
4500

(b) = 0.999 99, coarsening (one run)
R
|W|
2:
4500

4000

4000

3500

1

3500

1

3000

3000

2500

2500

2000

2000

1500
0

1500
0

1000

1000

500
0

1000

2000

3000

500

0
4000

0

200

time

400

600

800

(c) = 0.95, coarsening (two runs)
R
|W|
3:
4500

4:

|W|

R

4000

3500

1

3000

3000

2500

2500

2000

2000

1500
0

1500
0

1000

1000

500
1000

2000

3000

4500
4000

3500

1

0

0
1000

time

500

0
4000

0

time

1000

2000

3000

4000

0
5000

time

Figure 11: Simulation results illustrating effect discounting factor, shuttlebot
problem, policy-based proximity-based refinement.

8.6 Worldview Size Quality
Finally, consider effect worldview size quality robot4 domain,
agent moves series rooms lights. domain excellent example
simulated agent works well. runs robot4 -10 robot4 -15 problems
agent thought small amount time, quickly moved goal stayed
there, small worldviews, seen Figure 12 robot4 -15
problem. Four representative runs shown, two two refinement methods
(runs 1 2) two three methods (runs 3 4). four runs, worldview
sizes |W| reasonable consider full state space contains almost half million
states, 1 000-state worldview represents fifth percent. Despite small
worldview size, however, planner effective. dozen phases, agent
reached goal. planner works well robot4 -10 robot4 -15.
comparison, Kims (2001) largest ROBOT-k problem ROBOT-16, though since
ROBOT-16 216+1 = 131 072 actions robot4 -k domain problems 4,
511

fiBaum, Nicholson & Dix

(a) coarsening (two runs)
R
1:

|W|

2:

1200

|W|

R

1000

1200
1000

1

1
800

800

600

600

400

400

0

0
200

200

0
0 10 20 30 40 50 60 70 80 90 100

0
0 10 20 30 40 50 60 70 80 90 100

time

time

(b) proximity-based coarsening (two runs)
R
|W|
3:
4:
1200

|W|

R

1000

1200
1000

1

1
800

800

600

600

400

400

0

0
200

200

0
0 10 20 30 40 50 60 70 80 90 100

0
0 10 20 30 40 50 60 70 80 90 100

time

time

Figure 12: Simulation results, robot4 -15 problem, = 0.999 99, policy-based proximity-based refinement, without proximity-based coarsening.

direct comparison would valid. hand, values k (10, 15
on) necessarily powers 2, since, unlike Kim, domain specification
always considers room numbers atomic rather binary numbers, particular
advantage powers 2.
results robot4 -20 problem beginning interesting
robot4 -10 robot4 -15. Figure 13(a), showing two runs coarsening
(runs 1 2), agent succeeds reasonably promptly reasonable worldview
sizes. However, illustrated Figure 13(b), coarsening active planner fails
reach goal runs (about 40%, example, run 3) succeeds others
(about 60%, example, run 4). state space contains almost 21 million states,
successful worldviews Figure 13 order 0.01% full state space size.
Figure 14 shows four representative runs robot4 -25 problem, (a) two without coarsening (runs 1 2) (b) two three methods (runs 3 4). problem state space 25 225 839 million states, effect noted robot4 -20
512

fiProximity-Based Non-uniform Abstractions Planning

(a) coarsening (two runs)
R
1:

|W|

2:

8000

|W|

R

7000
1

7000

6000

0

1

6000

5000

5000

4000

4000

3000

3000

2000

0

2000

1000
0

50

100

150

200

1000

0
250

0

50

100

time

150

200

|W|

R

7000
1

0

1

6000

5000

5000

4000

4000

3000

3000

2000

0

2000

1000
100

150

200

8000
7000

6000

50

0
250

time

(b) proximity-based coarsening (two runs)
R
|W|
4:
3:
8000

0

8000

1000

0
250

0

time

50

100

150

200

0
250

time

Figure 13: Simulation results, robot4 -20 problem, = 0.999 99, policy-based proximity-based refinement, without proximity-based coarsening.

much pronounced here: without coarsening, planner tends much larger worldviews15 large worldviews cause planner run slowly. noted Section 8.3
above, horizontal axes world time, planning time. relation two
varies quite significantly runs two policies per time step
smaller worldviews less one ten time steps worldviews grew
large.
far reaching goal concerned, two cases similar. Again, successful
runs maintain reasonably-sized worldview, runs 2 4. Runs
worldview size grows big invariably fail (runs 1 3). difference
time, smallest successful worldview, run 4 Figure 14, used around 2 000 well-chosen
worldview states, 0.000 24% full state space. worldview grows
beyond miniscule fraction state space even 19 243-state worldview
15. Note run 1 plotted different scale worldview size |W| axis compared runs 2, 3
4. makes details behaviour easier see, makes size run 1 less obvious.

513

fiBaum, Nicholson & Dix

(a) coarsening (two runs)
R
1:

0

0

|W|

2:

20000
18000
16000
14000
12000
10000
8000
6000
4000
2000
0
50 100 150 200 250 300 350 400

|W|

R

8000
7000

1

6000
5000
4000
3000

0

2000
1000
0

time

0
50 100 150 200 250 300 350 400
time

(b) proximity-based coarsening (two runs)
R
|W|
4:
3:

|W|

R

8000

8000

7000
1

7000
1

6000

0

6000

5000

5000

4000

4000

3000

3000
0

2000

2000

1000
0

250

500

750

1000

0
1000

0

time

0
20 40 60 80 100 120 140 160
time

Figure 14: Simulation results, robot4 -25 problem, = 0.999 99, policy-based proximity-based refinement, without proximity-based coarsening. Note
different scales worldview size |W| axis run (a)1.

run 1 Figure 14 0.002 3% planner stall progress
possible. Even challenging environment, agent reaches goal almost half
runs.

9. Discussion
Section 8 presented results across range experimental domains showing method
successfully finds solutions planning problem using much less full state space,
well limitations. section discuss results analyse
features domains method exploit give difficulty.
smaller problems, could directly evaluate policies produced method
pre-cursor mode, allowing us better isolate behaviour planner. Without
proximity-based methods, worldviews quite small planner could solve
514

fiProximity-Based Non-uniform Abstractions Planning

3Doors problem. However, even better uniform abstraction, could
little here. Even oracle could best remove one door key 3Keys
two doors 3Doors, giving 25% relative worldview size however, planner
used uniform distribution removed dimension, agent would fail anyway, since
opening doors left worldview would harder hoping best
assumed-50%-open door actually closed. succeed, would also
deduce abstracted doors considered closed, considerable feat.
function sample domains. circumstances, uniform abstraction could
effective, either pre-processing step approach integrated W selection
methods.
expected turning proximity-based refinement (Algorithms 5 6) would
lead larger worldviews. general, one would expect larger worldviews yield better
solutions smaller worldviews yield worse solutions, lower computational cost.
means proximity-based refinement should, general, improve solution quality.
results corresponded expectation. worldviews indeed larger
solution quality higher.
larger problems, performance could evaluated simulation, running
agent simulated world observing reward collects. problems,
direct evaluation possible calculating actual value function using
exact algorithm longer tractable. Section 8.3 therefore presented results
3Keys problem comparison obtained direct evaluation policies
pre-cursor deliberation discussed above. seen, results correspond, crossconfirming evaluation methods.
addition, simulation recurrent delibertion context coarsening
could evaluated. proximity-based coarsening activated, compared
situation turned off, reward gathered agent declines slightly.
impression worse performance somewhat misleading. due fact first
comparison takes place one small problems, planner able solve
without coarsening, fact without abstraction all. Thus, disadvantages
(lower reward collected) much apparent advantages (lower computational
cost).
larger problems, working without abstractions option, balance
reversed. fact, somewhat counterintuitively, larger problems
coarsening active, successful runs smaller worldviews unsuccessful
runs. Clearly, size worldview determines success, quality.
good worldview enabled efficient calculation policies progress toward goal
remaining small. poor worldview simply grew larger. smaller problems, growing
worldview may eventually covered state space detail, thus masking
effect. planner would find good policy effectively without real approximation.
larger problems, finding good policy without approximation feasible,
similarly growing worldview simply slowed planner progress
made. situation, worldview-reducing action proximity-based coarsening
became crucial, ensuring least worldview remained tractably small
thereby enabled planner deal problem.
515

fiBaum, Nicholson & Dix

seen results, coarsening successful task
time. agent paused replan part-way goal, reduces size
worldview keep relevant changing circumstances. runs, however,
worldview size grew beyond capabilities planner. cases,
10x10 problem, settled higher balance. others, appears simply
continued growing. latter case, would appear simple question
tuning parameters: find balance, appropriate worldview size.
appears factor, quality worldview determining
success failure runs whether find balance reach goal grow
big fail.
number problems solved poorly due initial abstraction
selection algorithm (Algorithm 3). problems, algorithm produced either large
worldview exceeded available memory (either immediately shortly afterwards),
planning possible, small worldview planning ineffective.
could set produce medium-sized worldview, none four combinations
options produced one. problems, singleton worldview possible
is, steps initial abstraction selection disabled, resulting worldview aggregating
states single, maximally abstract worldview state leading typically reward
collected agent. best, would take actions general direction
goal(s). considerably worse previous work. instance, Kim (2001)
obtains approximate solutions problems larger variants, others
use domain variant, including Hoey et al. (1999) originators, Dearden
Boutilier (1997).
necessity using singleton initial worldview understandably greatly
hurt performance. infelicity worldview initialisation stage could impair
entire planning process, since worldview never completely discarded planner.
worldview-improvement algorithms could made amount weakness
initial worldview, singleton worldview poor starting point indeed.
similar observation made Dean et al. (1995) work using reduced envelope
states (that is, subset state space). high level algorithms, like here,
work regardless initial envelope (worldview). practice, however, better
initial envelope chosen intelligence, instance contain least
possible path goal (for goal-oriented domains). find path using simple
depth first search, directly applicable worldviews
gradations abstraction, overall concept remains: reasonable initial worldview
crucial.
tireworld results confirm this. initial worldview reward step
enabled small, since domain rewards single dimension, planning
ineffective. planner given better initial worldview one could
plausibly calculated became quite effective, even modified tire-large-n0
initial state deliberately moved goal. seems, then,
basic approach general, worldview selection modification methods
less so. good worldview selection less fundamental apect approach
easily supplemented additional methods even tuning. domains like
516

fiProximity-Based Non-uniform Abstractions Planning

tireworld, seems modified predicate solver generate plausible trajectories
current state goal would well part worldview selection.
interesting compare results Sanner Boutilier (2009)
tireworld, describe passing extremely poorly approximated
going manually tweak domain planner, adding information
locations mutually exclusive. makes planning much easier largely invalidates
comparison approaches.16 fair question, however, extent
weakness planner extent artefact domain. combination
representation narrative seems rather unfortunate, narrative obvious
1-of-n intuition tend obscure real features (and real applicability)
propositional representation hinder rather help intuition. would occur
tighter fit representation narrative.
Others, course, solve tireworld domain well. Some, Barry, Kaelbling,
Lozano-Prez (2010), generate full policy, others take advantage initial state,
planner would do. difficult know extent planners adapted
domain extent flexible. seems recent years
become common planners tested domains researchers
access development, ICAPS IPC domains, rather
greater lesser degree hand-tuned, usually unconsciously, particulars one
another domain, undoubtedly unconsciously tuned grid navigation
domain.
interesting side point provided shuttlebot problem, solved
= 0.999 99 (other collecting trivial reward immediately adjacent
s0 ) solved optimally = 0.95. Since simulator
intrinsic discounting factor reports reward collected one see
even though planner working discounting factor = 0.95, provided
better solution = 0.999 99 case worked = 0.999 99 first
place.
ways better behaviour smaller planner discounting factor reasonable, agents horizon represented world discounting factor,
horizon particular policy therefore planner effectively much shorter,
policy supplanted new one relatively soon. Thus, may useful
occasion set planners discounting factor lower true world discounting factor order facilitate planning. However, may lead suboptimal, short-sighted
policies.

10. Conclusions
theory Markov decision processes provides algorithms optimal planning. However,
larger domains algorithms intractable approximate solutions necessary.
state space expressed terms dimensions, size resulting computational cost exponential number dimensions. Fortunately, also results
structured state-space effective approximations possible.
16. Similarly, Kolobov, Mausam, Weld (2008) report results variant tireworld rather
tireworld itself, without providing explanation.

517

fiBaum, Nicholson & Dix

approach based selectively ignoring dimensions parts
state space order obtain approximate solutions lower computational
cost. non-uniform abstraction dynamically adjusted planning (in on-line
situations) execution progress, different dimensions may ignored different parts
state space. strong implications, since resulting approximation longer
Markovian. However, approach intuitive practical. synthesis
two existing approaches: structure-based approximation uniform abstraction
dynamic locality-based approximation envelope methods. Like envelope methods,
limited reliance initial worldview (or envelope): poor,
tend perform poorly overall. approach subsumes uniform abstraction completely
treated special case general method.
paper extends preliminary work Baum Nicholson (1998) modifying
worldview based proximity measure, enlarging reducing size,
evaluating behaviour simulation. allows us test approach larger
problems, importantly demonstrates full strength approach
limits terms domain features exploit exploit
adjustment all. abstraction becomes truly dynamic, reacting changes
agents current state enabling planning tailored agents situation
changes. shown qualitative quantitative results presented
Baum (2006), approach effective efficient calculating approximate
policies guide agent simulated worlds.
10.1 Future Work
One possible direction future research would find worldview initialisation
modification methods result smaller yet still useful worldviews, probably domainspecific, extend method domains, either larger different features.
example, factory tireworld domains goal-oriented based predicates,
worldview selection modification method based predicate-oriented solver could
find possible paths goal ensure relevant preconditions concrete along
path.
Interestingly, 10x10 problem, proximity-based methods keep
worldview size small, seem find balance larger stil moderate
size. Thus another possibility might tune proximity-based methods develop
self-tuning variants.
number points, instance phase selection, algorithm uses stochastic choice
default. could replaced heuristics, learning, directed methods.
One could adapt method work types MDPs, undiscounted
finite-horizon ones, combine approaches approximate different aspects domains planning problem, described Section 2.5. example,
mentioned section, Gardiol Kaelbling (2004, 2008) combine hierarchical state
space abstraction somewhat similar envelope work Dean et al. (1995).
Many combinations would likely fruitful planning domains features relevant multiple methods. Similarly, additional refinement coarsening methods
518

fiProximity-Based Non-uniform Abstractions Planning

could added, instance one based after-the-fact refinement criterion
roll-back Reyes et al. (2009).
theoretical side, one could look situations optimality
guaranteed, Hansen Zilberstein (2001) LAO* algorithm work
Dean et al. (1995), observing admissible heuristic used evaluate fringe states,
rather pragmatically chosen V (out), algorithm related heuristic search
acquires stopping criterion guaranteed optimality (or -optimality). Perhaps
similar condition could developed approach, rather different heuristic.
two basic directions work extended
fundamental way, relaxing one MDP assumptions, perfect observability knowledge
transition probabilities. Partially Observable Markov Decision Process (POMDP)
gives agent observation instead current state, observation partly
random partly determined preceding action current state.
optimal solution known principle, quite computationally expensive, since transforms POMDP larger, continuous, many-dimensional MDP agents beliefs.
such, non-uniform abstraction approach could applied two different ways: either original POMDP, fairly direct translation, transformed MDP.
extension would apply technique agent learn transition
probabilities. particular, application technique exploration17 would
interesting agent would somehow learn distinctions within single abstract states, distinguish refined remain
abstract.

References
de Alfaro, L., & Roy, P. (2007). Magnifying-lens abstraction Markov decision processes.
Proceedings 19th International Conference Computer Aided Verification,
CAV07, pp. 325338.
Barry, J., Kaelbling, L. P., & Lozano-Prez, T. (2010). Hierarchical solution large Markov
decision processes. Proceedings ICAPS Workshop Planning Scheduling
Uncertain Domains.
Barry, J. L. (2009). Fast approximate hierarchical solution MDPs. Masters thesis,
Massachusetts Institute Technology.
Barto, A. G., Bradtke, S. J., & Singh, S. P. (1995). Learning act using real-time dynamic programming. Artificial Intelligence, Special Volume: Computational Research
Interaction Agency, 72 (12), 81138.
Baum, J. (2006). Dynamic Non-uniform Abstractions Approximate Planning Large
Structured Stochastic Domains. Ph.D. thesis, Clayton School Information Technology, Monash University. Available www.baum.com.au/jiri/baum-phd.ps.gz
17. learning problem could also transformed MDP agents beliefs experiences,
would computationally prohibitive. standard approaches instead explicitly distinguish exploration, agent learns domain (but ignores goals) exploitation, achieves
goals (but ignores opportunities learn).

519

fiBaum, Nicholson & Dix

Baum, J., & Nicholson, A. E. (1998). Dynamic non-uniform abstractions approximate
planning large structured stochastic domains. Lee, H.-Y., & Motoda, H. (Eds.),
Topics Artificial Intelligence, Proceedings 5th Pacific Rim International Conference Artificial Intelligence (PRICAI-98), pp. 587598.
Bellman, R. E. (1957). Dynamic Programming. Princeton University Press.
Bertsekas, D. P., & Tsitsiklis, J. N. (1996). Neuro-Dynamic Programming. Athena Scientific.
Botea, A., Enzenberger, M., Muller, M., & Schaeffer, J. (2005). Macro-FF: Improving AI
planning automatically learned macro-operators. Journal Articial Intelligence
Research, 24, 581621.
Boutilier, C. (1997). Correlated action effects decision theoretic regression. Geiger, D.,
& Shenoy, P. (Eds.), Proceedings 13th Conference Uncertainty Artificial
Intelligence (UAI-97), pp. 3037.
Boutilier, C., & Dearden, R. (1996). Approximating value trees structured dynamic programming. Proceedings 13th International Conference Machine Learning,
pp. 5462.
Boutilier, C., Dearden, R., & Goldszmidt, M. (1995). Exploiting structure policy construction. Mellish, C. S. (Ed.), Proceedings 14th International Joint Conference
Artificial Intelligence (IJCAI-95), Vol. 2, pp. 11041111.
Boutilier, C., Dearden, R., & Goldszmidt, M. (2000). Stochastic dynamic programming
factored representations. Artificial Intelligence, 121 (1-2), 49107.
Boutilier, C., Goldszmidt, M., & Sabata, B. (1999). Continuous value function approximation sequential bidding policies. Laskey, K., & Prade, H. (Eds.), Proceedings
15th Conference Uncertainty Artificial Intelligence (UAI-99), pp. 8190.
Cassandra, A. R., Kaelbling, L. P., & Kurien, J. A. (1996). Acting uncertainty: Discrete Bayesian models mobile-robot navigation. Tech. rep. TR CS-96-17, Computer
Science, Brown University.
Daoui, C., Abbad, M., & Tkiouat, M. (2010). Exact decomposition approaches Markov
decision processes: survey. Advances Operations Research, 2010, 120.
Dean, T., Kaelbling, L. P., Kirman, J., & Nicholson, A. E. (1995). Planning time
constraints stochastic domains. Artificial Intelligence, 76 (1-2), 3574.
Dearden, R., & Boutilier, C. (1997). Abstraction approximate decision theoretic planning. Artificial Intelligence, 89 (1), 219283.
Dietterich, T. G. (2000). Hierarchical reinforcement learning MAXQ value function
decomposition. Journal Artificial Intelligence Research, 13, 227303.
Drummond, M., & Bresina, J. (1990). Anytime synthetic projection: Maximizing probability goal satisfaction. Dietterich, T., & Swartout, W. (Eds.), Proceedings
8th National Conference Artificial Intelligence (AAAI-90), pp. 138144.
Gardiol, N. H., & Kaelbling, L. P. (2004). Envelope-based planning relational MDPs.
Advances Neural Information Processing Systems 16 NIPS-03.
520

fiProximity-Based Non-uniform Abstractions Planning

Gardiol, N. H., & Kaelbling, L. P. (2008). Adaptive envelope MDPs relational equivalence-based planning. Tech. rep. MIT-CSAIL-TR-2008-050, Computer Science
Artificial Intelligence Laboratory, Massachusetts Institute Technology.
Goldman, R. P., Musliner, D. J., Boddy, M. S., Durfee, E. H., & Wu, J. (2007). Unrolling
complex task models MDPs. Proceedings 2007 AAAI Spring Symposium
Game Theoretic Decision Theoretic Agents.
Goldman, R. P., Musliner, D. J., Krebsbach, K. D., & Boddy, M. S. (1997). Dynamic
abstraction planning. Kuipers, B., & Webber, B. (Eds.), Proceedings 14th
National Conference Artificial Intelligence 9th Innovative Applications Artificial Intelligence Conference (AAAI/IAAI-97), pp. 680686.
Guestrin, C., Koller, D., Parr, R., & Venkataraman, S. (2003). Efficient solution algorithms
factored MDPs. Journal Artificial Intelligence Research, 19, 399468.
Hansen, E. A., & Zilberstein, S. (2001). LAO*: heuristic search algorithm finds
solutions loops. Artificial Intelligence, 129 (12), 3562.
Hauskrecht, M., Meuleau, N., Kaelbling, L. P., Dean, T., & Boutilier, C. (1998). Hierarchical
solution Markov decision processes using macro-actions. Cooper, G., & Moral,
S. (Eds.), Proceedings 14th Annual Conference Uncertainty Artificial
Intelligence (UAI-98), pp. 220229.
Hoey, J., St.-Aubin, R., Hu, A., & Boutilier, C. (1999). SPUDD: Stochastic planning using
decision diagrams. Proceedings 15th Annual Conference Uncertainty
Artificial Intelligence (UAI-99), pp. 279288.
Howard, R. A. (1960). Dynamic Programming Markov Processes. MIT Press.
Kim, K.-E. (2001). Representations Algorithms Large Stochastic Planning Problems.
Ph.D. thesis, Deptartment Computer Science, Brown University.
Kirman, J. (1994). Predicting Real-time Planner Performance Domain Characterization.
Ph.D. thesis, Department Computer Science, Brown University.
Kolobov, A., Mausam, & Weld, D. S. (2008). Regressing deterministic plans MDP
function approximation. Workshop Reality Check Planning Scheduling
Uncertainty ICAPS.
Korf, R. (1985). Macro-operators: weak method learning. Artificial Intelligence, 26 (1),
3577.
Littman, M., Weissman, D., & Bonet, B. (2006). Tireworld domain. Fifth International
Planning Competition (IPC-5) hosted International Conference Automated
Planning Scheduling (ICAPS 2006).
Munos, R., & Moore, A. (1999). Variable resolution discretization high-accuracy solutions optimal control problems. Dean, T. (Ed.), Proceedings 16th International Joint Conference Artificial Intelligence (IJCAI-99), pp. 13481355.
Musliner, D. J., Durfee, E. H., & Shin, K. G. (1995). World modeling dynamic
construction real-time plans. Artificial Intelligence, 74, 83127.
521

fiBaum, Nicholson & Dix

Nicholson, A. E., & Kaelbling, L. P. (1994). Toward approximate planning large
stochastic domains. Proceedings AAAI Spring Symposium Decision Theoretic Planning, pp. 190196.
Parr, R. (1998). unifying framework temporal abstraction stochastic processes.
Proceedings Symposium Abstraction Reformulation Approximation
(SARA-98), pp. 95102.
Puterman, M. L., & Shin, M. C. (1978). Modified policy iteration algorithms discounted
Markov decision processes. Management Science, 24, 11271137.
Reyes, A., Sucar, L. E., & Morales, E. F. (2009). AsistO: qualitative MDP-based recommender system power plant operation. Computacion Sistemas, 13 (1), 520.
Sanner, S., & Boutilier, C. (2009). Practical solution techniques first-order MDPs.
Artificial Intelligence, 173 (56), 748788. Advances Automated Plan Generation.
Srivastava, S., Immerman, N., & Zilberstein, S. (2009). Abstract planning unknown
object quantities properties. Proceedings Eighth Symposium Abstraction, Reformulation Approximation (SARA-09), pp. 143150.
St-Aubin, R., Hoey, J., & Boutilier, C. (2000). APRICODD: Approximate policy construction using decision diagrams. Proceedings Conference Neural Information
Processing Systems, pp. 10891095.
Steinkraus, K. A. (2005). Solving Large Stochastic Planning Problems using Multiple Dynamic Abstractions. Ph.D. thesis, Department Electrical Engineering Computer
Science, Massachusetts Institute Technology.

522

fiJournal Artificial Intelligence Research 43 (2012) 1-42

Submitted 08/11; published 01/12

Learning Reasoning Action-Related Places
Robust Mobile Manipulation
Freek Stulp

stulp@clmc.usc.edu

Computational Learning Motor Control Lab
University Southern California
3710 S. McClintock Avenue, Los Angeles, CA 90089, USA

Andreas Fedrizzi
Lorenz Mosenlechner
Michael Beetz

fedrizza@cs.tum.edu
moesenle@cs.tum.edu
beetz@cs.tum.edu

Intelligent Autonomous Systems Group
Technische Universitat Munchen
Boltzmannstrae 3, D-85747 Garching bei Munchen, Germany

Abstract
propose concept Action-Related Place (ARPlace) powerful flexible representation task-related place context mobile manipulation. ARPlace
represents robot base locations single position, rather collection positions, associated probability manipulation action succeed
located there. ARPlaces generated using predictive model acquired
experience-based learning, take account uncertainty robot
location location object manipulated.
executing task, rather choosing one specific goal position based
initial knowledge task context, robot instantiates ARPlace,
bases decisions ARPlace, updated new information
task becomes available. show advantages least-commitment approach,
present transformational planner reasons ARPlaces order optimize
symbolic plans. empirical evaluation demonstrates using ARPlaces leads
robust efficient mobile manipulation face state estimation uncertainty
simulated robot.

1. Introduction
Recent advances design robot hardware software enabling robots solve
increasingly complex everyday tasks. performing tasks, robot must continually decide course action, decision commitment plan
action parameterization based evidence expected costs benefits associated
outcome. (Resulaj, Kiani, Wolpert, & Shadlen, 2009). definition highlights
complexity decision making. involves choosing appropriate action action
parameterization, costs minimized benefits maximized. robot
must therefore able predict costs benefits arise executing
action. Furthermore, due stochasticity hidden state, exact outcome action
known advance. robot must therefore reason expected outcomes,
able predict probability different outcomes given action action paramec
2012
AI Access Foundation. rights reserved.

fiStulp, Fedrizzi, Mosenlechner, & Beetz

terization. Finally, robot commits decisions based current observable evidence,
represented belief state. evidence changes, rationale committing
decision may longer valid. robot therefore needs methods efficiently reconsider decisions belief state changes action execution, possibly commit
another plan necessary.
Mobile manipulation good case point. Even basic mobile manipulation
tasks, picking object table, require complex decision making. pick
object robot must decide stand order pick object,
hand(s) use, reach it, grasp type apply, grasp, much
grasp force apply, lift object, much force apply lift it,
hold object, hold it. decision problems complex depend
specific task context, consists many task-relevant parameters. Furthermore,
decisions must continually updated verified, task context, robots
knowledge context, often changes task execution.
Consequently, tasks complexity require robust hardware low-level
controllers, also least-commitment approach making decisions, abstract planning
capabilities, probabilistic representations, principled ways updating beliefs
task execution. article, demonstrate implementing core AI topics
contributes robustness flexibility mobile manipulation platform.
task-relevant decision consider article base position robot
navigate order perform manipulation action. decision alone presents
several challenges, 1) successfully executing reaching manipulation action
critically depends position base; 2) due imperfect state-estimation,
uncertainty position robot target object. positions
known exactly, fundamental successfully grasping object, possible
determine single-best base position manipulation; 3) complete knowledge required
determine appropriate base position often available initially, rather acquired
on-line task execution.
solution idea address challenges concept Action-Related Places
(ARPlace), powerful flexible representation task-related place context
mobile manipulation. ARPlace represented probability mapping, specifies
expected probability target object successfully grasped, given positions
target object robot

ARPlace : { P (Success|fkrob , hf obj , obj i) }K
k=1

(1)

Here, estimated position target object represented multi-variate Gaussian
distribution mean f obj covariance matrix obj 1 . discrete set robot positions
{fkrob }K
k=1 thought possible base positions robot considers grasping,
i.e. potential positions navigate to. Typically, set positions arranged grid,
exemplary ARPlace depicted Figure 1.
1. feature vectors f rob f obj contain poses robot object relative tables
edge. Details given Section 3.1. Positions without uncertainty denoted f , estimated
positions uncertainty hf , i.

2

fiLearning Reasoning Action-Related Places Robust Mobile Manipulation

Figure 1: ARPlace: probability successful manipulation, given current estiobj
rob K
, obj
mated object position hfcur
cur i. set potential robot positions {fk }k=1
arranged grid along x y-axis, whereby position leads
obj
, obj
different probability successful grasping P (Success|fkrob , hfcur
cur i).
black isolines represent grasp success probability levels 0.2 0.8.

ARPlace three important properties: 1) models base places single
position f rob , rather set positions {fkrob }K
k=1 , different expectation
success manipulation action; 2) depends upon estimated target object
position, updating f obj obj task execution thus leads different probabilities
ARPlace; 3) using probabilistic representation takes account uncertainty
target object position leads robust grasping.
1.1 Example Scenario
Figure 2, present example scenario demonstrates properties
ARPlace address challenges stated above, supports decision-making
mobile manipulation. images top row show current situation robot
outside view, images lower visualize robots internal ARPlace
representation. ARPlace visualized colors red, white green,
represent low, medium high grasp success probabilities respectively. Grasp success
probability levels 0.2 0.8 depicted isolines, Figure 1.
scenario robots task clean table. Scene 1 robot enters
kitchen vision system detects cup. robot far away cup,
uncertainty arising vision-based pose estimation cup high, indicated
large circle around cup lower left image. exact position cup
known, possible determine single-best base position grasping
cup. ARPlace representation takes uncertainty account modeling
base position probability mapping.
3

fiStulp, Fedrizzi, Mosenlechner, & Beetz

Scene 1

Scene 2

Scene 3

Scene 4

Figure 2: Example scenario.
Scene 1 ARPlace distribution low probabilities overall, maximum
probability grasp success 0.52. Note although initial uncertainty
cups position precludes robot determining specific base position
reliably grasp cup, robot know general area navigate.
navigation, robot able determine position cup accurately,
depicted Scene 2. new sensor data comes in, robot refines ARPlace
therefore ARPlace Scene 2 much higher probabilities overall, maximum
0.96.
Scene 3 robot detected second cup. grasping cups
single position much efficient approaching two locations, robot
merges two ARPlaces cup one ARPlace representing probability
successfully grasping cups single position2 . Scene 4 measurements
helped reduce pose estimation uncertainties cups. maximum grasp success
probability ARPlace reaches 0.97; sufficient robot commit
goal position attempt grasp cups once.
scenario illustrates real-world tasks often planned start
finish, initial knowledge often complete accurate enough determine
optimal goal position. rather committing particular base position early
based robots initial knowledge task context, robot instantiates
ARPlace particular task context, bases decisions ARPlace.
place concept instantiation represented explicitly course action
enables robot reconsider reevaluate decisions on-line whenever new
information task context comes in. instance, decision grasp
cups one position Scene 3 would possible robot would
committed plan given initial knowledge one cup detected. Even
environment completely observable, dynamic properties make pre-planned
optimal position suboptimal unaccessible. least-commitment implementation,
2. Section 4.4.1 explains ARPlaces merged compute ARPlace joint tasks.

4

fiLearning Reasoning Action-Related Places Robust Mobile Manipulation

decisions delayed must taken flexible, leads robust
efficient mobile manipulation. demonstrated empirical evaluation.
1.2 Contributions, System Overview Outline
system overview learning, computing, reasoning ARPlaces depicted
Figure 3. also serves outline rest article.

Figure 3: System Overview. Numbers refer sections article. Green ovals represent
algorithms procedures, blue rectangles models result them.
Procedures models briefly described contributions section;
detail given throughout article. Yellow rectangles cluster conceptually
related procedures, also delineate different sections article.

main contributions article are:
Representing ARPlace Section 1. propose ARPlace flexible representation
place least-commitment decision making mobile manipulation.
Model Learning Section 3. generate ARPlace, robot must able
predict outcome action given action parameterization. propose
generic, off-line learning approach acquiring compact prediction model two
steps: 1) learn predict whether action succeed given task parameterization. supervised classification problem implement Support
Vector Machines (Sonnenburg, Raetsch, Schaefer, & Schoelkopf, 2006); 2) generalize
several task parameterizations generalizing learned SVM classifiers,
5

fiStulp, Fedrizzi, Mosenlechner, & Beetz

implement Point Distribution Models (Cootes, Taylor, Cooper, & Graham, 1995). resulting success prediction model enables robot predict
whether manipulation action given object position succeed given
base position 3 .
Generating ARPlace Section 4. demonstrate ARPlaces generated online, take object position uncertainty account Monte-Carlo simulation. Furthermore, ARPlace conditioned robot position uncertainty,
thus also taken account.
Reasoning ARPlace Section 5. show ARPlace integrated symbolic transformational planner, automate decision-making ARPlaces.
particular, consider scenario shows ARPlaces merged joint
manipulation tasks.
Empirical Evaluation Section 6. demonstrate reasoning ARPlaces
leads robust efficient behavior simulated mobile manipulation platform.
turning contributions, first compare approach related work
Section 2.

2. Related Work
state-of-the-art mobile manipulation platforms use sampling-based motion planners
solve manipulation problems (LaValle, 2006). advantages using symbolic
planning general, ARPlaces particular, are: 1. Abstraction. Representing planning abstract symbolic actions reduces complexity planning
problem. Although computational power ever increasing, still intractable solve
extended tasks, preparing meal (Beetz et al., 2008), state-space search alone.
2. Least-commitment. Friedman Weld (1996) show setting open conditions
abstract actions later refining choice particular concrete action lead exponential savings. Note principle also used reduce number collision
checks building Probabilistic Roadmaps (Bohlin & Kavraki, 2000). 3. Modular replanning. symbolic planning, causal links actions explicitly represented.
robot navigates table order perform grasping motion represented
plan generated sampling-based motion planner. Therefore, execution, motion
planners cannot reconsider appropriate base position decision right,
must rather inefficiently replan entire trajectory belief state changes. 4. Reflection. explicit symbolic representation causality also allows robot reason
reflect plans monitor execution, instance report reasons
3. using experience-based learning, approach applied variety robots environments.
model learned however, obviously specific environment experience
generated. instance, one table height considered data collection, learned
prediction model specific table height. different table heights used experience
collection, table height included task-relevant parameter, model able
generalize table heights well. refer Section 3.5 full discussion.

6

fiLearning Reasoning Action-Related Places Robust Mobile Manipulation

plan failure: could find cup. could determine position cup
sufficient accuracy robustly perform grasp. obstacle blocking
path.. obvious achieve introspection motion planning methods.
Also, contrast sampling based motion-planning, ARPlace generate trajectories motion itself, rather representation supports decisions,
decision robot move order manipulate. goal position
given motion planner order find trajectory gets robot
goal position. system instance, navigation trajectory determined
Wavefront planner. Also, ARPlace Reinforcement Learning policy (Sutton
& Barto, 1998). policy maps states actions, whereas ARPlace maps (uncertain)
states expected probabilities successfully executing certain action. ARPlaces
thus models actions, executable actions right. distinction
become apparent Section 5, ARPlaces used transformational
planner detect repair performance flaws symbolic plans.
perspective, similar work aSyMov (Cambon, Gravot, &
Alami, 2004) RL-TOPs (Ryan, 2002), use symbolic planners generate
sequences motion plans/reinforcement learning policies respectively. specific contributions article enable robot learn grounded, probabilistic models
actions support symbolic decision making, well using flexible transformational
planners reason models. focus thus grounding improving
representations enable symbolic planning, rather underlying actions
generate trajectories and/or actual motion.
Okada, Kojima, Sagawa, Ichino, Sato, Inaba (2006) also develop representations
place enable symbolic planning, denote good base placement grasping
spot. Different spots hand-coded different tasks, manipulating faucet,
cupboard, trashcan. symbolic representations place used
LISP-based motion planner perform tool manipulation behavior. ARPlace extends
concept spot learning autonomously, grounding observed behavior,
providing probabilistic representation place. Berenson, Choset, Kuffner (2008)
address issue finding optimal start goal configurations manipulating objects
pick-and-place operations. explicitly take placement mobile base
account. interested optimal start goal configurations, instead
probabilistic representation, approach enable least-commitment planning.
Diankov, Ratliff, Ferguson, Srinivasa, Kuffner (2008) use model reachable
workspace robot arm decide robot may stand grasp object
focus search. However, uncertainties robots base position objects position
considered, thus cannot compensated for. recent work Berenson,
Srinivasa, Kuffner (2009) addresses issues, still relies accurate model
environment, high computational cost. hand, ARPlace
compact representation computed negligible computational load, allowing
continuous updating.
Recently, similar methods ones presented article used determine successful grasps, rather base positions grasping. instance, Detry et al.
(2009) determine probability density function represents graspability specific
objects. function learned samples successful robot grasps, biased
7

fiStulp, Fedrizzi, Mosenlechner, & Beetz

observed human grasps. However, approach take examples failed grasps
account. shall see Section 4, distance failed successful
grasp quite small, determined taking failed grasps account.
classification boundaries Section 3.2 similar Workspace Goal Regions, except
boundaries refer base positions, whereas Workspace Goal Regions refer grasp
positions (Berenson, Srinivasa, Ferguson, Romea, & Kuffner, 2009). Also, generalize
boundaries Point Distribution Model, use generate probabilistic
concept successful grasp positions.
Kuipers, Beeson, Modayil, Provost (2006) present bootstrapping approach
enables robots develop high-level ontologies low-level sensor data including distinctive states, places, objects, actions. high level states used choose
trajectory-following control laws move one distinctive state another. approach exactly way around: given manipulation navigation skills
robot (which far high-dimensional learn trajectory-following control laws),
learn places skills (e.g. grasping) executed successfully. focus
action affordance, recognition localization. us, place means cluster
locations execute (grasping) skill successfully, whereas Kuipers
et al. refers location perceptually distinct others, therefore
well-recognized. Furthermore, work yet considered physical manipulation
objects, relates place.
Learning success models considered probabilistic pre-condition learning.
research field far focussed learning symbolic predicates symbolic
examples (Clement, Durfee, & Barrett, 2007; Chang & Amir, 2006; Amir & Chang, 2008).
approaches applied robots, representations
learned able encapsulate complex conditions arise robot dynamics
action parameterization. robotics, focus pre-condition learning therefore
rather grounding pre-conditions robot experience. realistic domain considered Zettlemoyer, Pasula, Kaelbling (2005), simulated gripper stacks objects
blocks world. Here, focus predicting possible outcomes actions completely observable, unambiguous description current state; emphasis rather
taking state estimation uncertainty account. Dexter learns sequences manipulation
skills searching grasping object (Hart, Ou, Sweeney, & Grupen, 2006).
Declarative knowledge length arm learned experience. Learning
success models also done context robotic soccer, instance learning
success rate passing (Buck & Riedmiller, 2000), approaching ball (Stulp & Beetz,
2008). system extends approaches explicitly representing regions
successful instances observed, computing Generalized Success Model
regions.
interesting line research shares paradigms ARPlaces,
learning relation objects actions building prediction models, ObjectAction Complexes (OACs). Geib, Mourao, Petrick, Pugeault, Steedman, Kruger,
Worgotter (2006) Pastor, Hoffmann, Asfour, Schaal (2009) present OACs
used integrate high-level artificial intelligence planning technology continuous low-level robot control. work stresses that, cognitive agent, objects
actions inseparably intertwined therefore paired single interface.
8

fiLearning Reasoning Action-Related Places Robust Mobile Manipulation

physically interacting world applying machine learning techniques, OACs allow
acquisition high-level action representations low-level control representations.
OACs meant generalize principle affordances (Gibson, 1977).

3. Learning Generalized Success Model ARPlace
section, describe implementation off-line phase depicted Figure 3,
Generalized Success Model (GSM) learned. goal acquire function g
P (Success|f rob , f obj )

=

g(f rob , f obj ) 7 {0, 1}

(2)

predicts chance successful manipulation action, given relative positions
robot object, stored feature vectors f rob f obj respectively.
Note off-line learning phase, known positions. Uncertainty
positions taken account on-line phase, described Section 4.
Performing mobile manipulation complex task involves many hardware
software modules. overview modules platform described Appendix A.
overview demonstrates large number modules required implement mobile
manipulation platform. Many modules results years
decades research development within companies, research groups, open-source
projects. global behavior robot, e.g. whether grasp cup certain
base position, depends modules, interactions them.
cases, analytic models certain modules available (such Capability Map
arms workspace, Section 3.1). However, general way composing models
acquire global model systems behavior task execution. Therefore,
rather learn model observed experience.
However, component computes ARPlaces requires exactly global model
predict circumstances manipulation action fail succeed. attempting theoretical analysis model foreseeable events uncertainties world
best tedious error-prone, worst infeasible, therefore use experience-based
learning acquire global models behavior. so, model grounded
observation actual robot behavior.
off-line learning phase consists three steps: 1) repeatedly execute action
sequence observe result N different target object positions; 2) learn N Support
Vector Machines classifiers N specific cup positions 3) generalize N classifiers
Point Distribution Model.
3.1 Data Acquisition
robot acquires experience executing following action sequence: 1) navigate
specified base position table; 2) reach cup; 3) close gripper; 4) lift
cup (Stulp, Fedrizzi, & Beetz, 2009a). action sequence, task context
determined following parameters 1) pose robot navigates to4 ; 2)
4. Note navigation planner parameterized robot always directly facing table.
limitation planner, rather constraint added make behavior

9

fiStulp, Fedrizzi, Mosenlechner, & Beetz

pose target object table. execution, robot logs whether object
successfully grasped not. efficiently acquire sufficient data, perform training
experiments Gazebo simulator (Gerkey, Vaughan, & Howard, 2003). robot
modeled accurately, thus simulator provides training data also valid
real robot. Examples failed successful grasp depicted Figure 4.

Figure 4: Two experiment runs different samples robot position. navigatereach-grasp sequence upper row succeeds, fails lower sequence.

vector field controller use perform reaching movement proven
robust wide range robots workspace (Beetz et al., 2010). also
low computational load, easy debug, quickly adapted novel objects.
disadvantage occasionally gets stuck local minima, motion
must restarted. probabilistic motion planner arm suffer local
minima, plan generation fails border workspace; even though vector
field controller able grasp there. Every planner controller advantages
disadvantages, always sources failure real world, especially
complex embodied agents. article aims modelling failures experiencebased learning, basing decisions models.
feature space data collected depicted Figure 5. coordinate
system relative tables edge, position cup table.
enable us apply model learned data different tables
different locations kitchen, contrast previous work (Stulp, Fedrizzi, &
Beetz, 2009b). on, refer f obj = [xobj obj ] observable taskrelevant parameters, robot observes cannot influence directly. xobj
distance object table edge, obj angle object
orientation normal goes table edge object, depicted
physical robot predictable; makes robot safe, required operate
robot human environments (cf. Figure 20). principle, methods paper could take
orientation account.

10

fiLearning Reasoning Action-Related Places Robust Mobile Manipulation

Figure 5. f rob = [xrob rob ] controllable action parameters, robot
use navigation system change them.

Figure 5: Relative feature space used rest paper.
robot gathers data 16 target object poses, depicted Figure 6. target
object poses listed matrix Fobj . given target object position, determine
rectangular area generous estimation upper bound
robot grasp object. rectangle 16 object poses. Within
rectangle uniform grid almost 200 positions, stored matrix Frob ,
defined. Figure 6 depicts results data gathering positions. Here,
markers represent position robot base table. three types
markers, represent following classes:
3.1.1 Theoretically Unreachable (Light Round Markers)
cup cannot grasped many positions bounding rectangle simply
arm long enough. formally, base positions, kinematics
arm inverse kinematic solution exists end-effector
position required grasp target object. exploit analytic models arm
kinematics filter base positions bounding rectangle cup theoretically unreachable. analytic model use capability map, compiled
representation robots kinematic workspace (Zacharias, Borst, & Hirzinger, 2007).
Capability maps usually used answer question: given position base,
positions reach end-effector? article, use capability map
answer inverse question: given position target object (and therefore
desired position end-effector), base positions reach end-effector
position? Figure 7, answer question visualized specific target object
position. depicted area theoretical kinematic upper bound base positions
robot reach target.
example base position bounding box, use capability map
determine target object theoretically reachable. not, corresponding base
position labeled failure without executing navigate-reach-grasp action sequence.
saves time gathering data. Another obvious theoretical bound implemented
robots distance table least big robots radius.
Otherwise robot would bump table. Again, labeled base positions
failures without executing order save time.
11

fiStulp, Fedrizzi, Mosenlechner, & Beetz

Figure 6: Results data acquisition 16 target object poses, listed matrix Fobj .
Markers correspond center robot base. Green squares red
circles represent successful failed grasps respectively. Bright circles
executed successful grasp deemed theoretically impossible capability
maps. dark green hulls classification boundaries (Section 3.2).

3.1.2 Practically Unreachable (Red Filled Round Markers)
capability map considers theoretical reachability position, given kinematics robots arm. take self-collisions account, constraints
imposed vector-field controller reaching, specific hardware gripper,
way gripper interacts target object. Red markers Figure 6 represent
base positions capability map deems possible, lead failure performing reaching motion. causes failure are: 1) bumping table due
imprecision navigation routine 2) bumping cup grasping it; 3) closing
gripper without cup handle it; 4) cup slipping gripper 5)
vector field controller getting caught local minimum.
One aim article demonstrate practical problems, arise
interaction many hard- software modules, properly addressed experiencebased learning. approach use analytic models available, use
experience-based learning necessary. interacting world, robot observes
12

fiLearning Reasoning Action-Related Places Robust Mobile Manipulation

Figure 7: Inverse capability map right arm specific object position.
global behavior, learns difference possible theory
works practice.
3.1.3 Reachable (Green Square Markers)
base positions robot able successfully grasp cup.
task execution deemed successful cup 10cm table
action sequence completed, case robot holding
it. prefer empirical measure instance force-closure measure,
latter requires accurate models object, always have. Furthermore,
argued theoretical grounds (Zheng & Qian, 2005), well demonstrated
empirically (Morales, Chinellato, Fagg, & del Pobil, 2004), force-closure grasps may
always lead successful grasps practice. course, force-closure may well
used measure successful grasping; methods described article
depend upon design choice.
data acquisition yields set discrete robot object positions, associated
resulting outcome manipulation action, success failure:
obj N
P (Success|{f rob }M
}j=1 ) = bi,j , bi,j {0, 1}
i=1 , {f

(3)

article, number sampled object positions N = 4 4 = 16 (i.e. number
graphs Figure 6), number sampled robot positions = 11 17 = 187 (i.e.
number data points per graph Figure 6).
remainder section, first generalize discrete robot positions
training Support Vector Machines (Section 3.2), generalize N cup
positions Point Distribution Models (Section 3.3)
3.2 Generalization Robot Positions
step, generalize discrete robot positions, acquire compact boolean
classifier efficiently predicts whether manipulation succeed:
13

fiStulp, Fedrizzi, Mosenlechner, & Beetz

P (Success|f rob , {f obj }N
j=1 )

=

gj=1...N (f rob ) 7 {0, 1}

(4)

generalization implemented follows. separate classifier gi=1...N learned
N = 16 object poses, i.e. one classifier 16 data sets depicted
Figure 4. acquire prediction models, compute classification boundary around
successful samples Support Vector Machines (SVM), using implementation
Sonnenburg et al. (2006), Gaussian kernel =0.1 cost parameter C=40.0.
successful grasps rarer, weight twice much failed grasp attempts.
Figure 6 depicts resulting classification boundaries different configurations taskrelevant parameters dark-green boundaries. Manipulation predicted succeed
robots base position lies within boundary given target object pose Fobj .
accuracy learned classifiers listed Section 6.1.
3.3 Generalization Object Positions
next step, generalize discrete object positions:
P (Success|f rob , f obj )

=

g(f rob , f obj ) 7 {0, 1}

(5)

determining low-dimensional set parameters allows us interpolate
individual classification boundaries Support Vector Machines generate. done Point Distribution Model (PDM), established method
modelling variations medical images faces (Cootes et al., 1995; Wimmer, Stulp,
Pietzsch, & Radig, 2008). result one compact model incorporates individual boundaries, able interpolate make predictions target object poses
observed training.
input PDM requires n points distributed contour.
landmarks distributed described Appendix B. Given landmarks classification boundaries, compute PDM. Although PDMs well-known
use computer vision (Cootes et al., 1995; Wimmer et al., 2008), use notation
Roduit, Martinoli, Jacot (2007), focus robotic applications. First, 16
boundaries 20 2D points merged one 40x16 matrix H, columns
concatenation xrob rob coordinates 20 landmarks along classification boundary. column thus represents one boundary. next step compute
P, matrix eigenvectors covariance matrix H. P represents
principal modes variation. Given H P, decompose boundary h1..16
set mean boundary linear combination columns P follows
hk = H + P bk . Here, bk so-called deformation mode k th boundary.
Point Distribution Model. get intuition PDM represents,
first three deformation modes depicted Figure 8, values first, second
third deformation modes (columns 1, 2, 3 B) varied maximal
minimal value, whilst deformation modes set 0.
eigenvalues covariance matrix H indicate first 2 components already contain 96% deformation energy. reasons compactness achieve
14

fiLearning Reasoning Action-Related Places Robust Mobile Manipulation

Figure 8: first 3 deformation modes Point Distribution Model (in B).

better generalization, use first 2 deformation modes, without losing much accuracy.

{fjobj , gj (f rob ) = inboundary(f rob , hj )}N
j=1
{fjobj , gj (f rob ) = inboundary(f rob , H + P bj )}N
j=1
g(f

rob

,f

obj

) = inboundary(f

rob

, H + P b(f

obj

))

N Support Vector Machines

(6)

Point Distribution Model

(7)

Regression

fjobj

bj

(8)

PDM several advantages: 1) instead store N = 16 classification
boundaries hj 20 2D points capture variation classification hulls due
different target object positions, store N = 16 deformation modes 2 degrees
freedom each. greatly reduces dimensionality; 2) 2 degrees freedom b
used interpolate principled way computed classification boundaries
hj , generate boundaries object positions observed learning; 3)
simple regression two degrees freedom PDM b position f obj
feasible, object position related directly shape classification
boundary. regression explained next section.
3.4 Relation Task-Relevant Parameters
step, acquire function b, computes appropriate deformation modes b
given object position f obj . so, compute regression matrix
deformation modes specific object positions B, 16 object positions
Fobj , depicted Figure 6. found simple second order polynomial regression
model suffices compute regression, yields high coefficients determination
R2 = 0.99 R2 = 0.96 first second deformation modes respectively.
coefficients polynomial model stored two 3x3 upper triangular matrices W1
W2 , B [ diag([T 1] W1 [Fobj 1]T ) diag([T 1] W2 [T 1]T ]
Generalized Success Model consists 1) H, mean classification
boundaries computed SVM; 2) P, principal modes variation clas15

fiStulp, Fedrizzi, Mosenlechner, & Beetz

sification boundaries; 3) W1,2 , mapping task-relevant parameters deformation
modes.
Let us summarize Generalized Success Model used predict successful
manipulation behavior:
1. Generalized Success Model takes (observed) relative position object
obj
obj
table fcur
= [xobj
cur cur ] input (Figure 5).
2. appropriate deformation values given object position computed
obj
obj
obj
bcur = b(fcur
) = [ q W1 qT q W2 qT ], q = [fcur
1] = [xobj
cur cur 1]
(Section 3.4).
3. boundary computed hcur = H + P bcur (Section 3.3).
4. relative robot base center f rob = [xrob rob ] within boundary hcur ,
model predicts robot able successfully grasp object position
obj
obj
= [xobj
fcur
cur cur ].
Note steps involve simple multiplications additions small matrices,
thus performed efficiently5 . reason efficiency lies fact
directly relate task-relevant parameters, position cup table,
predictions global behavior robot, whether manipulation action
succeed not. on-line efficiency made possible experience-based learning,
wealth information observation global behavior compiled
compact model off-line. approach adheres proposed strategy learning taskrelevant features map actions, instead attempting reconstruct detailed model
world plan actions (Kemp, Edsinger, & Torres-Jara, 2007).
summary, observed behavior outcomes, learned mapping Equation 2 (which repeat Equation 9), maps continuous robot target object
positions boolean prediction success action:
P (Success|f rob , f obj ) = g(f rob , f obj ) 7 {0, 1}

(9)

mapping used predict current base position robot lead
successful manipulation, also determine appropriate base positions navigate to.
Equation 9 assumes true values robot target object positions
known robot. Section 4, discuss uncertainties estimates
positions taken account task execution.
3.5 Generality Generalized Success Model
explaining Generalized Success Model used generate ARPlaces online task-execution Section 4, discuss generalization properties
limitations Generalized Success Model. so, must distinguish
5. indication, model described paper four steps take 0.2ms 2.2GHz
machine Matlab implementation.

16

fiLearning Reasoning Action-Related Places Robust Mobile Manipulation

general applicability approach different robots, objects domains,
specificity model factors learned. essentially holds
data-driven approach: model principle learned data, independent
robot system generates data, learned, specific
data generated robot system, thus specific robot system itself.
practical purposes, assume domain robot hardware remain fixed, learning
domain- robot-specific model grave limitation.
3.5.1 Generalization Object Poses
learned model generalizes different object poses, relative object pose
table f obj = [xobj obj ] part feature space Generalized Success
Model parameterized (see step 1. calling GSM Section 3.4). Generalized
actually refers capability generalizing Success Models specific object poses.
3.5.2 Grasp-Specific ARPlaces
specific object, lot data would required learn ARPlace
object robot manipulate. practice however, found
grasps suffice grasp everyday objects kitchen environments real robot
platform (Maldonado, Klank, & Beetz, 2010). particular, approach required
2 grasps (one top one side) achieve 47 successful grasps
51 attempts 14 everyday kitchen objects. Therefore, propose use grasp-specific
ARPlaces, rather object-specific ARPlaces. learned Generalized Success
Models grasps, depicted Figure 9.

Figure 9: two Point Distribution Models side top grasp. Examples
objects manipulated grasps depicted.

two deformation modes Point Distribution Model depicted Figure 9
already contain 99% deformation energy, even side grasps.
success side grasp relatively independent orientation
object, robot need reach around object. also leads
symmetric classification boundaries top grasp, seen Figure 9.
summary, two Generalized Success Models must learned two different
grasps, two grasps suffice grasp 14 everyday kitchen objects tested
17

fiStulp, Fedrizzi, Mosenlechner, & Beetz

real robot Maldonado et al. (2010). rest article, focus
side grasp; ARPlaces top grasps presented Fedrizzi (2010).

4. Computing Action-Related Places
previous section, demonstrated Generalized Success Model learned
observed experience variety task parameterizations. resulting function
maps known robot object positions prediction whether action execution
succeed feel.
section, describe ARPlaces manipulation computed on-line
specific task contexts. depicted Figure 3, module takes Generalized
Success Model estimated robot pose target object pose input, returns
ARPlace depicted Figure 1.
4.1 Taking Object Position Uncertainty Account
Equation 9, prediction whether manipulation action succeeds fails based
known robot target object positions. However, task execution, robot
estimates positions, varying levels uncertainty. uncertainties
must taken account predicting outcome, manipulation action
predicted succeed might well fail target object position
robot expects be. Given Generalized Success Model Equation 9, goal
section therefore compute mapping

Generalized Success Model

P (Succ|f

rob

,f

obj

ARPlace (with object uncertainty)

) 7 {0, 1} Monte Carlo { P (Succ|fkrob , hf obj , obj i) }K
k=1 7 [0, 1]
(10)

takes estimates target object position, returns continuous probability
value, rather discrete {0, 1} probability value Equation 9. belief state,
uncertainties object positions modelled Gaussian distribution mean f obj
covariance matrix obj .
robot platform described Appendix A, f obj obj obtained
vision-based object localization module (Klank, Zia, & Beetz, 2009). Typical values along
2
2
2
diagonal 6x6 covariance matrix are: x,x
= 0.05, y,y
= 0.03, z,z
= 0.07,
2
2
2
yaw,yaw = 0.8, pitch,pitch = 0.06, roll,roll = 0.06. uncertainties position specified
meters angular uncertainties specified radians. estimation object
position quite accurate, vision system problems detect handle,
important estimating orientation (yaw) cup. Due constraints enforced
assumption cup standing upright table, uncertainty z, pitch
roll set 0. remaining 3x3 covariance matrix mapped relative feature
space, yields obj .
end Section 3.4, demonstrated classification boundary hnew reobj
obj
constructed, given known task relevant parameters fnew
= [ xobj
new new ].
obj
uncertainty fnew , suffice compute one classification boundary given
18

fiLearning Reasoning Action-Related Places Robust Mobile Manipulation

probable position cup ARPlace grasp. might
lead failure cup position expected. Therefore, use
Monte-Carlo simulation generate whole set classification boundaries. done
taking 100 samples Gaussian distribution object position, given mean
position associated covariance matrix. yields matrix task-relevant parameters
obj obj ]. corresponding classification boundaries computed
Fobj


s=1...100 = [x
samples hs = H + P b(fsobj )) Equation 8. Figure 10(a), 20
100 boundaries depicted.
task-relevant
parameters
h
2 generated

obj obj
2 obj obj
2
x

0.03
0
=
.
f obj = [ xobj obj ] = [ 0.2 1.5 ] obj = 2x x
2
2
0 0.30

obj xobj

obj obj

(a) Sampled classification boundaries (b) Discretized relative sum (c) Final distribution, condi(hs=1..20 ).
boundaries.
tioning robot pose uncertainty.

Figure 10: Monte-Carlo simulation classification boundaries compute ARPlace.
described Appendix C, 0 definition, FGSM defined relative
cups position along tables edge. uncertainty y, described
2 , leads uncertainty origin F
y,y
GSM . Therefore, sampling
task-relevant parameters, also sample values y, translate FGSM accordingly. Uncertainty influence shape classification boundary PDM,
simply translates classification boundary along tables edge. sampling
actually already done Figure 10(a), yobj yobj = 0.03. fact,
2

obj obj
2 obj obj
2 obj obj


x
x
x

x

0.032 0
0
2
2
2
obj





2
=
=
0 0.03
0
obj xobj
obj obj
obj obj
2

obj xobj

2

obj obj

0

2

obj obj

0

0.302

computed sampled classification boundaries, generate discrete
grid 2.52.5cm cells, represent discrete robot positions {fkrob }K
k=1 Equation 1.
cell, number classification boundaries classify cell success
counted. thus computing histogram predicted successful grasps. Dividing
result overall number boundaries yields probability grasping cup
succeed position. corresponding distribution, takes uncertainty
cup position account, depicted Figure 10(b).
interesting note steep decline right side distribution near
table, probability successful grasp drops 0.8 0.2 5cm.
intuitive, table located right side, robot bumps table
moving sampled initial position, leading unsuccessful navigate-reach19

fiStulp, Fedrizzi, Mosenlechner, & Beetz

grasp sequence. Therefore, none 16 boundaries contain area close
table, variation P right side PDM low. Variations B
large effect boundary, seen Figure 10(b). summing
sampled boundaries, leads steep decline success probability.
Note ARPlace normalized probability distribution (which sums 1),
rather probability mapping, element (discrete grid cell) probability
distribution itself. Thus sum probabilities grid cell 1, i.e. P (Succ) +
P (Succ) = 1.
4.2 Taking Robot Position Uncertainty Account
robot uncertainty position target object, also
position. uncertainty must also taken account ARPlace. instance,
although position near left steep incline Figure 10(b) predicted
successful, might still fail robot actually right expected.
Therefore, condition probabilities Figure 10(b) robot actually
rob ,
rob )6 , acquire
certain grid cell (xrob , rob ) given position estimate (x
final ARPlace mapping as:
ARPlace prob. mapping, Figure 10(c).
P (Success|hf rob , rob i, hf obj , obj i) =
P (Success|f rob , hf obj , obj i)

P (f rob |hf rob , rob i)
(11)

Prob. mapping Equation 10, Figure 10(b).

Prob. distribution robot uncertainty (Gaussian).

equation, hf rob , rob interpreted two ways. First all, represent
actual estimate robots position current time. case, P (Success| . . . )
predicts probability success manipulation current position. However,
also interpreted possible goal positions robot could navigate order
rob , rob i, throughout paper. so,
perform navigation, i.e. hfgoal
goal
rob
make assumption future position uncertainty rob
goal goal position fgoal
rob . believe fair assumption because;
currently, i.e. rob
goal =
1) realistic assuming rob
goal = 0; 2) robot approaches navigation
rob
goal, continually updating , thus P (Success| . . . ). reached
rob .
goal, rob
goal equivalent
4.3 Refining ARPlace On-line
summary, ARPlaces computed on-line learned Generalized Success Model,
given task-relevant parameters current task context, includes uncertainties
6. Since navigation planner parameterized robot always faces table (cf. Section 3.1),
ignored orientation robot computing GSM. Note therefore also ignore
uncertainty parameter here, ARPlaces take account. expect
improved robustness (evaluated Section 6.2) could improved taking (the uncertainty)
parameter account.

20

fiLearning Reasoning Action-Related Places Robust Mobile Manipulation

poses robot target object. yields probability mapping maps
robot base positions probability grasping target object succeed.
Learning Generalized Success Model costly step involves extensive data
collection, thus performed off-line. learned, model compact,
used efficiently compute ARPlaces on-line7 Therefore, ARPlaces updated
execution task progresses, incorporate new knowledge taskrelevant parameters changes environment. Figure 11 depicts ARPlace
probability mapping affected new knowledge task-relevant parameters comes
in. first row demonstrates accurate knowledge target objects
position (lower uncertainty, e.g. lower xobj xobj ) leads focussed ARPlace
higher overall probabilities, higher mode. second third row depict
similar effects estimates target objects position orientation change.
figure serves two purposes: gives reader visual intuition effects several taskrelevant parameters shape ARPlace, demonstrates robots
internal ARPlace representation might change new (more accurate) information
target object pose comes in.
Decreasing uncertainty cup position perpendicular table edge
xobj =

0.28

xobj =

0.38

obj =

0.60

0.19

0.10

0.01

Decreasing distance cup table edge
0.33

0.23

0.13

Changing orientation cup table
1.30

1.95

2.65

Figure 11: images demonstrate varying certain task-relevant parameters affects
shape ARPlace distribution.
decision whether certain probability success suffices execute manipulation
action critically depends domain task. Failing grasp full glass wine
7. indication, takes average 110ms 2.2GHz machine Matlab implementation
perform steps Section 4.1 4.2.

21

fiStulp, Fedrizzi, Mosenlechner, & Beetz

grave consequences failing grasp tennis ball. general, ARPlace provides
representation enables high-level planners make rational decisions
scenarios, specify decisions made, minimal
success probability order perform task. Section 5 present use
ARPlace concrete scenario.
4.4 Generality ARPlaces
Section 3.5, discussed generality learning Generalized Success Model,
specificity model respect robot skills, model
learned off-line. section, demonstrate generality flexibility
ARPlace representation, generated on-line using Generalized Success Model.
also present various ways ARPlaces extended, lay groundwork Section 5, explains ARPlaces used context high-level
transformational planner.
4.4.1 Merging ARPlaces Multiple Actions
ARPlaces multiple actions composed intersecting them. Assume
computed ARPlaces two different actions (a1 a2 ). success probabilities
ARPlaces independent, compute ARPlace executing actions
parallel multiplying probabilities ARPlaces action a1 a2 .
first two graphs Figure 12 instance, ARPlaces grasping cup
left right gripper depicted. piecewise multiplication probabilities,
acquire merged ARPlace, depicted right graph. robot use
merged ARPlace determine probability use left right gripper
grasp cups one base position (Fedrizzi, Moesenlechner, Stulp, & Beetz, 2009).
Another similar application merging ARPlaces two cup positions, grasped
gripper. ARPlace represents probability able grasp
cup one position, placing position, without moving base.
compositions would impossible robot commits specific positions advance.

Figure 12: Left distribution: grasp cup left gripper. Center distribution: grasp cup
right gripper. Right distribution (element-wise product two
distributions): Grasp cups left/right gripper one base position.

22

fiLearning Reasoning Action-Related Places Robust Mobile Manipulation

navigating one position grasp two cups much efficient navigating two positions, implemented decision transformation rule
Reactive Planning Language (McDermott, 1991), described detail Section 5.
4.4.2 Different Supporting Planes
Defining feature space Generalized Success Model relative tables edge
allows robot compute ARPlaces general table shapes one presented far. done determining ARPlace straight edges
table, computing union individual ARPlaces. example depicted
Figure 13.

Figure 13: ARPlace complex table shape.

4.4.3 Different Uncertainty Distributions
article, uncertainty position robot target objects modelled
multi-variate Gaussian distribution. approach expects
distribution, state estimation systems represent uncertainty.
Section 4.1, described specific target object positions sampled
distribution Monte Carlo simulation. general, method applies distribution
sampling done. distributions need Gaussian,
might well multi-modal even non-parametric. particle filter instance,
particle could directly used sample compute classification boundaries
Figure 10(a).
4.4.4 Applicability Domains
demonstrate generality ARPlaces briefly showing ARPlace able
represent task-relevant place different task domain: approaching ball
robotic soccer. task frequently fails robot bumps ball
achieving desired position ball. Figure 14(a), examples successful (S)
failed (F) attempt depicted. Here, robot approach ball
top. goal acquire ARPlace maps robots position field
predicted probability successfully approach ball.
23

fiStulp, Fedrizzi, Mosenlechner, & Beetz

procedure learning ARPlace equivalent mobile manipulation
domain: 1) gather data log successful failed episodes (Figure 14(a)); 2) learn classification boundaries generalized success model data; 3) generate ARPlaces
specific task contexts (Figure 14(b)). example demonstrates ARPlace
approach limited mobile manipulation, generalizes actions domains.

(a) Successful failed
attempts approaching
ball.
Data taken
(Stulp & Beetz,
2008).

(b) robots ARPlace approaching ball. Green
plateau: high probability robot succeed approaching ball orientation indicated thick
black arrow.

Figure 14: ARPlace robot soccer domain.
Note two bumps left right ball. intuitively clear
robot succeed approaching ball locations, surrounding
ones. assume depends particular morphology robot,
controller used approach ball; described Stulp Beetz (2008). One
main advantages using approach based learning assumptions
intuitions play role acquiring model. Whatever reason may be,
successful approaches obvious observed data (Figure 14(a)), hence
ARPlace represents them.
4.4.5 Using General Cost Functions
article, probability success considered utility relevant determining
appropriate base position. principle, ARPlace able represent kind
utility cost, example given Figure 15. Here, task robot
collect one two cups table. probabilistic ARPlaces two cups
depicted left graph. Given parameters, chance success 0.99
cups, reason prefer fetching one other. However, cup B much
closer robot, therefore would efficient collect cup B. preference
expressed ARPlace. First, compute distance robot
24

fiLearning Reasoning Action-Related Places Robust Mobile Manipulation

grid cells probabilistic ARPlace, depicted center graph. Finally,
merge probability P distance one cost u, u = (1 P )5 + d/0.3.
expresses takes average 5 seconds reposition robot another grasp
attempt case failure, average navigation speed 0.3m/s. cost
thus expresses expected time overall task take8
depicted Figure 15, mode ARPlace cup closer
robot higher, reflecting fact prefer robot fetch cups closer.
in-depth discussion utility-based ARPlaces, affect behavior
robot, refer Fedrizzi (2010).
Probability: P

Distance:

Cost: u = (1 P )5 + d/0.3

Figure 15: Example general cost-based ARPlace (right), including
probability success (left) distance robot (center). including
distance part cost, mode cost-based ARPlace closer
cup higher distant cup.

5. Transformational Planning ARPlace
far, described ARPlaces generated on-line using learned Generalized Success Model. ability predict (probability an) outcome action
makes ARPlaces powerful tool combined high level planning system.
section, demonstrate ARPlace used context symbolic transformational planner. Reasoning ARPlace enables planner generate robust
efficient plans, demonstrates flexibility least-commitment ARPlace
representation.
particular, consider task retrieving two cups table. One action
sequence solves task is: Plan A: navigate location near cup1, pick cup1
left gripper, navigate location near cup2, pick cup2 right gripper,
depicted Figure 16. However, cups sufficiently close (as
Figure 12, right), much efficient replace plan Plan B: navigate
location near cup1 cup2, pick cup1 left gripper, pick cup2
right gripper, saves entire navigation action.
8. cost chosen simplicity, illustrate generality ARPlace representation.
realistic, complex cost functions used.

25

fiStulp, Fedrizzi, Mosenlechner, & Beetz

Figure 16: Improving performance transformational planning (merged)
ARPlace. Plan A: navigate two separate poses grasping object,
using ARPlaces objects. Plan B: navigate one pose grasping
objects, using merged ARPlace.

Deciding whether use two base locations (Plan A) one (Plan B) difficult solve
control program without sacrificing generality. keep solution general,
want write two separate control programs options, choose
if-then-else statement. would mean provide control programs
choice points every option robot has. space choices prohibitively large
everyday tasks allow approach. Instead, use transformational planner
takes general program (Plan A) and, appropriate, applies generic transformation rules
change program locally (to yield Plan B). transformational planner consists
following components:
Plan projection. projection mechanism predicting outcome plan. ARPlace
compact representation projection mechanism, able predict
probability success action, given parameters.
Flaw detection. mechanism detecting behavior flaws within predicted plan outcome. Flaws errors hinder robot completing task,
may also performance flaws, suboptimal efficiency. Using two navigation actions approach cups close (Plan A) flawed,
much efficient navigate one position close cups.
Plan transformation. mechanism fix detected flaws applying transformation
rules plan code. problem consider, local transformation rule
applied Plan yield efficient Plan B.
next sections, describe mechanisms detail,
explain implemented exploit ARPlace representation. Note
article, use transformational planner exemplify ARPlace used
context larger planning system. information transformational
planning framework, examples behavior flaws transformation rules,
refer work Mosenlechner Beetz (2009).
26

fiLearning Reasoning Action-Related Places Robust Mobile Manipulation

5.1 Plan Design
detect flaws apply transformation rules repair, transformational planner
must able reason intention code parts, infer goal achieved
not, deduce reason possible failure was. so, control programs
written rpl (McDermott, 1991), provides functionality annotating code
parts indicate purpose make transparent transformational planner.
purpose article, important rpl instructions semantic annotation
context pick-and-place tasks achieve, perceive at-location. formal
definition semantics instructions given Mosenlechner Beetz (2009);
describe informally.
(achieve ?expression) achieve statement executes successfully, logical expression passed argument asserted true. instance, successful
execution (achieve (entity-picked-up ?cup)), object referenced variable ?cup
must robots gripper9 .
(perceive ?object) manipulating objects, robot must find objects
instantiate belief state. successful execution, statement (perceive ?cup)
asserts object referenced ?cup found, reference internal
representation returned.
(at-location ?location ?expression) Manipulation implies execution actions
specific locations. Therefore, must assured pick-up actions executed
robot specific location. (at-location ?location ...) asserts code within
context either executed specified location fails. Please note transformations affect location actions performed directly modify ?location
parameter at-location expressions. Therefore, at-location important
declarative plan expression optimizing ARPlaces. specify locations at-location,
use so-called designators, symbolic descriptions entities locations, objects
actions. instance, designator location stand picking cup
specified follows: (a location (to pick-up) (the object (type cup))). symbolic
description resolved reasoning mechanisms ARPlaces Prolog
actual pose generated needed. general, infinite number poses provide
valid solution pose. ARPlace gives us way evaluate utility select
best pose.
declarative expressions explained combined form tree. Every
achieve statement contain several achieve, perceive at-location statements
sub-plans. example plan tree sketched Figure 17. tree, goal (achieve
(entity-at-location ?object ?location)) first perceives object, picks achieving
entity-picked-up, executes pick-up action within at-location block, puts
object achieving entity-put-down, also contains at-location block.
shall see Section 5.4, behavior flaws repaired applying transformation rules
replace sub-trees within plan tree new code.

9. Please note lisp syntax, variables prefixed ?, example ?cup, predicates
functions pure symbols.

27

fiStulp, Fedrizzi, Mosenlechner, & Beetz

(entity-at-location ?o ?l)

(perceive ?o)

(achieve (entity-put-down ?o ?l))

(achieve (entity-picked-up ?o)
..
.
..
.

.. (at-location ?obj-l)
.

(at-location ?obj-l)
..
.
..
.

..
.

..
.

Figure 17: example plan tree created executing pick-up plan
5.2 Plan Projection
central component transformational planner plan projection, simulates
behavior robot arises executing plan. approach, plan projection generates temporally ordered set events based plan code presented
previous section. use Gazebo based mechanism projection
used generating training data learning ARPlaces. particular, use information collisions, perception events locations objects robot.
executing plan simulation, generate extensive execution trace
used reasoning engine infers behavior flaws fixed transformation rules (Mosenlechner & Beetz, 2009). execution trace contains low-level data
representing position objects robot, well collisions objects,
visibility objects robot, information reconstruct state program
throughout execution.
ARPlaces efficient way performing plan projection, predict
probability successful outcome without requiring on-line generation execution traces.
reason execution trace sampling required on-line, task
already executed frequently off-line data acquisition (cf. Section 3.1).
results task executions compiled ARPlaces learning
GSM, yields compact representation experience acquired. Therefore,
experience must generated anew plan generation.
5.3 Behavior Flaws Reasoning Plan Execution
Plan projection simulates robot behavior executing plan. second component transformational planner reasoning engine finds pre-defined flaws
projected robot behavior. Examples flaws collisions, e.g. caused underparameterized goal locations, blocked goals, e.g. chair standing location
robot wants navigate to. examples behavior flaws lead critical
errors plan execution (i.e. plan fails), also consider behavior inefficient
flawed (i.e. plan succeeds, unnecessarily inefficient). task consider
paper example performance flaw, performing two navigation actions one required highly inefficient. Behavior flaws specified using
28

fiLearning Reasoning Action-Related Places Robust Mobile Manipulation

Prolog-like reasoning engine implemented Common Lisp (Mosenlechner & Beetz,
2009).
execution trace generated plan projection transparently integrated
reasoning engine, i.e. execution trace queried using Prolog predicates. information recorded execution trace valuable information order find behavior flaws.
Additional information used find behavior flaws set facts model semantics declarative expressions achieve at-location concepts world,
instance objects placed supporting planes (table, cup-board, ...). find
behavior flaws, Prolog specifications matched logical representation
execution trace solutions found, corresponding flaw present plan
fixed.
instance, code match two locations perform actions merged
one ARPlace looks follows:
Listing 1: Flaw definition match two different pick-up tasks.
1
2
3
4
5

(
( k g l ? k 1 ( c h e v e ( e n p c k e ? b j e c 1)))
( k g l ? k 2 ( c h e v e ( e n p c k e ? b j e c 2))) ( h n
(== ? k 1 ? k 2)) ( p z e c n l c n ? b j e c 1
? b j e c 2 ? p z e l c n ) )

code first matches two different pick-up tasks. predicate optimizedaction-location holds ?optimized-location ARPlace two objects
picked up. bind variable, predicate implemented calculate
ARPlace.
Another example flaw definition failed navigation, i.e. robot
standing location supposed drive to:

Listing 2: Flaw definition find locations reached robot although
told reach them.
1
2
3
4
5

(
( k g l ? k ( c h e v e ( l c Robot ? g l l c ) ) )
( k u ? k Done ? )
( h l ( l c Robot ? r b l c ) ( ? ) )
( (== ? g l l c ? r b l c ) ) )

code first matches code navigating robot location ?goalloc. infers actual location robot navigation task terminated
binds variable ?robot-loc finally asserts two locations
equal. Prolog expression proven execution trace, found
flaw indicating unachieved goal location.
5.4 Plan Transformations Transformation Rules
behavior flaw detected, last step planner iteration application
transformation rule fix behavior flaw. Transformation rules applied parts
plan tree cause substantial changes structure corresponding robot
behavior.
29

fiStulp, Fedrizzi, Mosenlechner, & Beetz

transformation rule consists three parts. input schema matched
plan part transformed binds required code parts variables order
reassemble output part. transformation part performs transformations
matched parts, output plan describes new code respective
plan part reassembled.
input schema
transformation
output plan
Besides integration ARPlace robot control program at-location
statements, ARPlace also integrated reasoning engine transformational
planner. Using two locations grasping considered performance flaw one location
would suffice. Informally, investigate execution trace occurrence two different pick-up actions, one executed location L1 , one executed
location L2 . request location L3 perform actions corresponding success probability. L3 computed merging ARPlace Figure 12.
probability success merged ARPlace sufficiently high, apply plan
transformation, replace locations L1 L2 location L3 .
transformation rule optimizing ARPlaces shown Listing 3. Please note
variables bound matching flaw definition still bound
used transformation rule.
Listing 3: Transformation rule fixing flaw.
1
2
3
4
5
6
7
8
9
10
11

( e f r r u l e f x unoptimized l c n
: n p u schema
( ( ( k g l ? l c n k 1
( atl c n ( ? l c n 1) . ? code 1))
( subt k ? l c n k 1 ? k 1))
( ( k g l ? l c n k 2
( atl c n ( ? l c n 2) . ? code ) )
( subt k ? l c n k 2 ? k 2)))
: outputp l n
( ( atl c n ( ? p z e l c n ) . ? code 1)
( atl c n ( ? p z e l c n ) . ? code 2)))

input schema code consists two similar patterns, matching
at-location sub-plan pick-up goals matched flaw. planner replaces
matching code parts corresponding entries output plan. transformation
rule, location passed at-location replaced optimized location
calculated flaw definition.
behavior flaw defined match two different pick-up executions.
ARPlace query performed find probability successfully grasping
objects one location. probability sufficiently high (> 0.85) Prolog query
succeeds, i.e. flaw detected sufficiently good location grasping
objects found. Note sufficiently high depends much scenario
context. robotic soccer beneficial choose fast risky moves, whereas
safe human-robot interaction, certainty successful execution important
mere speed. article focusses principled ways integrating thresholds
transformational planner, relating grounded models robots behavior.
30

fiLearning Reasoning Action-Related Places Robust Mobile Manipulation

thresholds be, determined, depends application
domain users.

6. Empirical Evaluation
section 1) determine many samples needed learn accurate SVM
classifier; 2) compare robustness default strategy determining base positions
strategy uses ARPlaces; 3) compare efficiency plans without
fixing performance flaws transformational planner; 4) present preliminary results
physical robot platform.
6.1 Classification Accuracy Training Set Size
Figure 18 depicts accuracy SVM classifier predicting base positions
lead successful grasps one particular cup position, evaluated separate test set
150 samples. Without using capability map filter kinematically impossible
base positions, graph levels 300 examples10 . filtering theoretically
impossible base positions capability map, classifier achieves accuracy
within 173 examples (Stulp et al., 2009).

Figure 18: Accuracy dependent training set size one cup position.
effect dramatic entire dataset containing data 16 different cup
positions. applying capability map, number trials need executed
reduces 2992 (all markers Figure 6) 666 (only red/green filled markers Figure 6).
capability map reduces unsuccessful attempts, influence final
classification accuracy, 94%.
10. graph applies another dataset described Stulp, Fedrizzi, Zacharias, Tenorth, Bandouch,
Beetz (2009), similar one used rest article.

31

fiStulp, Fedrizzi, Mosenlechner, & Beetz

6.2 Results Simulated Robot
compare robustness navigation based probabilistic ARPlaces
strategy based deterministic navigation goals. evaluation, position
robot navigates position ARPlace returns highest probability
grasping target object succeed. compare strategy previous
hand-coded implementation Fixed, always navigates location
relative offset target object, whilst time taking care bump
table.
experiments, vary position cup (xobj , obj ), well
uncertainties robot position position cup, varying
diagonal elements covariance matrices associated position robot
(xrob xrob ,yrob yrob ) cup (xobj xobj ,obj obj ). combination
variables, robot performs navigate-reach-grasp-lift sequence. result
recorded, data acquisition learning Generalized Success Model.
simulate uncertainty, sample specific perceived robot cup position
distribution defined means covariance matrices. result action
determined true simulated state world, robot bases decisions
perceived samples.
results evaluation summarized three bar plots Figure 19,
depict success ratios ARPlace-based Fixed strategies. ratio
number successful executions, divided number examples, 100. pvalue pair bars computed 2 test them, tests whether
number successful failed attempts sampled distribution
ARPlace Fixed.
first graph depicts success ratios increasing uncertainty object
position (i.e. xobj xobj = [ 0.00 0.05 0.10 0.15 0.20 ]), fixed robot position uncertainty xrob = 0.05. cases, ARPlace strategy significantly outperforms
Fixed strategy. Furthermore, performance ARPlace much robust towards
increasing object position uncertainty, ARPlace takes explicitly account.
trend seen increasing uncertainty robot position (i.e.
xrob xrob = yrob yrob = [ 0.00 0.05 0.10 0.15 0.20 ]), fixed object position uncertainty
xobj = 0.05. However, xrob xrob > 0.1 difference ARPlace
Fixed longer significant.
Finally, last graph depicts success ratios increasing robot object
uncertainty. Again, ARPlace significantly outperforms Fixed ( < 0.15).
robot quite uncertain objects position ( > 0.15), grasp success
probabilities drop 50% strategies.
Summarizing, ARPlace robust towards state-estimation uncertainties
previous default strategy. effect pronounced object positions robot
positions.
6.3 Transformational Planning Merged ARPlaces
evaluated merging ARPlaces joint grasping, application transformation rules rpl planner, discussed Section 4.4.1. Two cups placed
32

fiLearning Reasoning Action-Related Places Robust Mobile Manipulation

Figure 19: Success ratios ARPlace Fixed approaches changing object
and/or robot pose uncertainties.

table, distance varied 20 60cm, increments
5cm. evaluation shows grasping two cups separate base positions requires
average 48 seconds, independent relative distance cups other.
applying transformation rules, default plan optimized 32 seconds, significant (t-test: p < 0.001) substantial performance gain 50% (Fedrizzi et al., 2009).
45cm, two cups cannot grasped one position, plan transformation
applied.
6.4 Integration ARPlace Physical Robot System
day open house, B21 mobile manipulation platform continually performed
application scenario, locates, grasps, lifts cup table moves
kitchen oven. Figure 20 shows two images taken demonstration. robot
performed scenario 50 times approximately 6 hours, convinced us
robot hardware software robust enough deployed amongst general public.
open day, ran experiment, time determined goal
location navigating table mode ARPlace computed
executing navigation action. Since main focus experiment
error-recovery system described Beetz et al. (2010), improved robot performance
observed cannot quantitatively attributed use ARPlace error-recovery
system. However, major qualitative improvement certainly attribute using
ARPlace cup grasped much larger area table.
Without ARPlaces, cup always placed position table
enable successful grasping.

7. Conclusion
article, present system enables robots learn action-related places
observed experience, reason places generate robust, flexible, least33

fiStulp, Fedrizzi, Mosenlechner, & Beetz

1. robot navigates table

2. robot reaches cup

Figure 20: reach grasp trajectory performed public demonstration. (Note
operator holding camera, remote control!)

commitment plans mobile manipulation. ARPlace modeled probability distribution maps locations predicted outcome action.
believe system several advantages. First all, learned model
compact, 2 (deformation) parameters, directly related task-relevant
parameters. Querying model on-line therefore efficient. advantage
compiling experience compact models, rather running novel search
situation.
hand, model acquired experience-based learning,
model grounded observed experience, takes account robot hardware,
control programs, interactions environment. applied mobile
manipulation platform, independent manipulators, navigation base, algorithms
run them.
output model set positions associated success probabilities,
instead one specific position. Rather constraining specific position prematurely, robot efficiently update ARPlace new sensor data comes in. enables
least-commitment planning. ARPlace representation also enables optimization
secondary criteria, execution duration, determining best position grasping two objects simultaneously. previous work, proposed subgoal refinement (Stulp
& Beetz, 2008) optimizing secondary criteria respect subgoals.
Finally, using ARPlaces determine appropriate base positions, difficult positions
grasping avoided, leads robust behavior face state estimation
uncertainty, demonstrated empirical evaluation.
currently extending approach several directions. process
including ARPlace general utility-based framework, probability
success one aspects task needs optimized. New utilities,
34

fiLearning Reasoning Action-Related Places Robust Mobile Manipulation

execution duration power consumption, easily included framework,
enables robot trade efficiency robustness on-line task execution.
also applying approach complex scenarios different domains.
instance, learning higher-dimensional ARPlace concepts, take aspects
scenario account, i.e. different object sizes objects require different
types grasps. Instead mapping specific objects places, map object grasp
properties deformation modes. also investigating extensions machine
learning algorithms enable methods generalize larger space. Objects
require different grasps, using two hands manipulate them, require
sophisticated methods acquiring reasoning place. Generalization
place concept respect situations task contexts research challenge
mid-term research agenda.

Acknowledgments
grateful Pierre Roduit providing us Matlab code described Roduit
et al. (2007). also thank Ingo Kresse, Alexis Maldonado, Federico Ruiz assistance
robotic platform, robot system overview. grateful Franziska
Zacharias providing capability map (Zacharias et al., 2007) robot. thank
Dominik Jain Franziska Meier fruitful discussions Section 4.2.
work partly funded DFG project ActAR (Action Awareness Autonomous Robots) CoTeSys cluster excellence (Cognition Technical Systems, http://www.cotesys.org), part Excellence Initiative German Research
Foundation (DFG). Freek Stulp also supported post-doctoral Research Fellowship
(STU-514/1-1) DFG, well Japanese Society Promotion
Science (PE08571). Freek Stulps contributions work made Intelligent
Autonomous Systems Group (Technische Universitat Munchen, Munich, Germany),
Computational Neuroscience Laboratories (Advanced Telecommunications Research Institute International, Kyoto, Japan), Computational Learning Motor Control Lab
(University Southern California, Los Angeles, USA),

Appendix A. Robot Platform
action sequence consider article is: 1) navigate specified base position
near table; 2) reach object; 3) close gripper; 4) lift object.
sequentially describe various hard- software components involved executing
actions. overview components data communicated
depicted Figure 21.
main hardware component B21r mobile robot Real World Interfaces
(RWI), frontal 180 degrees Sick LMS 200 laser range scanner. task execution,
robot acquires map (kitchen) environment using pmap map building.
navigate specified base position, robot uses Adaptive Monte Carlo Localization
algorithm localization, AMCL Wavefront Planner global path planning.
three software modules (map building, localization planning), use
implementations Player project (Gerkey et al., 2003).
35

fiStulp, Fedrizzi, Mosenlechner, & Beetz

Figure 21: Overview mobile manipulation hardware software modules.

robot close table, detects tracks target object using
approach proposed Klank et al. (2009). stereo-vision hardware consists two
high dynamic range cameras mounted PTU-46 pan-tilt unit Directed
Perception resolution 1390x1038 pixels.
manipulation, robot equipped two 6-DOF Powercube lightweight arms
Amtec Robotics. control arms reach target cup, use Kinematics Dynamics Library (Orocos-KDL) (Smits, ) Vector Field approach. Within
vector field, handle cup attractor, cup itself, table
obstacles repellors. Details position shape attractors
repellors given Beetz et al. (2010). On-line every control cycle, task space velocity end-effector computed given attractors repellors, velocity
mapped joint space velocities using damped least squares inverse kinematics algorithm.
reaching desired end-effector pose, 1-DOF slide gripper closes.
High-level decision making, monitoring error-recovery done planning module written Reactive Planning Language (McDermott, 1991). requests ARPlaces
module described article, reasons them, performs navigation
manipulation requests based them.
Communication modules described done middleware layer
consisting Player (Gerkey et al., 2003) YARP (Metta, Fitzpatrick, & Natale, 2006).
overview simplification actual system. instance, role RFID tags
Belief State omitted. complete detailed description
mobile manipulation platform, refer work Beetz et al. (2010, Section 1.2).
36

fiLearning Reasoning Action-Related Places Robust Mobile Manipulation

Appendix B. Landmark Distribution Point Distribution Model
Point Distribution Model (PDM) takes set landmarks n contours input,
represented n matrix H, returns matrices H (mean contours), P
(deformation modes), B (deformation mode weighting per contour), original
contours reconstructed.
application PDMs, free choose locations landmarks. Therefore, goal procedure described determine landmark locations leads
compact PDM accurately reconstructs original contours, i.e. classification
boundaries. explicitly optimizing two measures: 1) model compactness:
amount energy e stored first degrees freedom PDM, 0 e 1;
2) reconstruction accuracy: mean distance l landmarks original
contours reconstructed contours. measures combined cost function
(2 e)l2 , expressing want low error high energy given number degrees
freedom d.
Given number landmarks number degrees freedom d, explicitly
optimize cost function search. varying position
landmark, one landmark time, greedily selecting position leads
lowest cost. optimization first done = 1, number degrees freedom
incremented optimization leads energy lies 95%. ensures
number degrees freedom distance l landmarks remains
low, whilst energy e high. Therefore, resulting PDM model compact yet
accurate.
optimization step far computationally intensive step off-line
learning phase. currently investigating use alignment methods computer
vision (Huang, Paragios, & Metaxas, 2006), replace iterative optimization approach.

Appendix C. Robot Coordinate Systems Relative Feature
Space
robot uses variety coordinate systems. goal compute matrix GSM ,
describes objects position relative feature space Generalized Success
Model. GSM used reconstruct classification boundaries successfully
grasping object, described Section 3.4. present required coordinate
systems, transformed yield Generalized Success Model required
feature space depicted Figure 5.
coordinate frames involved transformation depicted Figure 22:
world frame FW , table frame FT centered middle top table,
robot frame FR centered robots base center floor, camera frame
FC centered cameras sensor chip, frame pan-tilt unit
camera mounted FP , relative feature space FGSM .
acquire position target object relative FGSM , compute GSM
follows:
GSM

= (W TGSM )1
37

W



(12)

fiStulp, Fedrizzi, Mosenlechner, & Beetz

Figure 22: Relevant coordinate frames

global position object
W

=

W

WT


TR

computed follows:
R

TP

PT

TC

C



(13)

Here, W TR location robots base frame relative world frame.
robot uses AMCL particle filter estimating position. R TP pose pan
tilt unit relative robots base frame. transformation matrix R TP constant
specified manually measuring distances angular offsets B21
robot base pan tilt unit. careful measurement, assume maximum
errors 1mm distance measurements along x-, y-, z-axis, 2
yaw angle measurement. P TC pose cameras sensor relative pan tilt
unit. P TC changes according current pan tilt angles, read
pan tilt units driver high accuracy. C position target object relative
camera frame. estimated vision-based object localization module
described Klank et al. (2009).
order compute W TGSM need know global position object W ,
already computed above, global position table W TT . Currently,
get world coordinates tables position map, also possible
estimate position vision-based object localization module. compute
normal object table edge closest robot, seen
Figure 5. origin FGSM therefore W TGSM table edge object
normal intersect.
critical parts computations angular estimations
robots localization vision system. First, estimation uncertainty rather big.
Second, error localization angle significant impact estimated object
pose, follows Equation 13.
pose cup frame FGSM 6D vector [x, y, z, yaw, pitch, roll]. However,
since assume cup standing upright table, set z tables height,
roll pitch 0 . Since origin FGSM perpendicular tables edge
passes y, also 0 definition. remaining parameters x yaw
correspond features xobj obj respectively.
38

fiLearning Reasoning Action-Related Places Robust Mobile Manipulation

References
Amir, E., & Chang, A. (2008). Learning partially observable deterministic action models.
Journal Artificial Intelligence Research (JAIR), 33, 349402.
Beetz, M., Stulp, F., Esden-Tempski, P., Fedrizzi, A., Klank, U., Kresse, I., Maldonado,
A., & Ruiz, F. (2010). Generality legibility mobile manipulation. Autonomous
Robots Journal (Special Issue Mobile Manipulation), 28 (1), 2144.
Beetz, M., Stulp, F., Radig, B., Bandouch, J., Blodow, N., Dolha, M., Fedrizzi, A., Jain,
D., Klank, U., Kresse, I., Maldonado, A., Marton, Z., Mosenlechner, L., Ruiz, F.,
Rusu, R. B., & Tenorth, M. (2008). assistive kitchen demonstration scenario
cognitive technical systems. IEEE 17th International Symposium Robot
Human Interactive Communication (RO-MAN), Muenchen, Germany. Invited paper.
Berenson, D., Choset, H., & Kuffner, J. (2008). optimization approach planning
mobile manipulation. Proceedings IEEE International Conference
Robotics Automation (ICRA) 2008, pp. 11871192.
Berenson, D., Srinivasa, S., Ferguson, D., Romea, A. C., & Kuffner, J. (2009a). Manipulation planning workspace goal regions. Proceedings IEEE International
Conference Robotics Automation (ICRA), pp. 13971403.
Berenson, D., Srinivasa, S. S., & Kuffner, J. J. (2009b). Addressing pose uncertainty
manipulation planning using task space regions. Proceedings IEEE/RSJ
International Conference Intelligent Robots Systems (IROS, pp. 14191425.
Bohlin, R., & Kavraki, L. E. (2000). Path planning using lazy prm. IEEE International
Conference Robototics Automation, pp. 521528.
Buck, S., & Riedmiller, M. (2000). Learning situation dependent success rates actions
RoboCup scenario. Pacific Rim International Conference Artificial Intelligence,
p. 809.
Cambon, S., Gravot, F., & Alami, R. (2004). robot task planner merges symbolic
geometric reasoning.. Proceedings 16th European Conference Artificial
Intelligence (ECAI), pp. 895899.
Chang, A., & Amir, E. (2006). Goal achievement partially known, partially observable domains. International Conference Automated Planning Scheduling
(ICAPS), pp. 203211.
Clement, B. J., Durfee, E. H., & Barrett, A. C. (2007). Abstract reasoning planning
coordination. Journal Artificial Intelligence Research, 28, 453515.
Cootes, T. F., Taylor, C. J., Cooper, D., & Graham, J. (1995). Active shape models -
training application. Computer Vision Image Understanding, 61 (1), 3859.
Detry, R., Baseski, E., Popovic, M., Touati, Y., Krueger, N., Kroemer, O., Peters, J., &
Piater, J. (2009). Learning object-specific grasp affordance densities. Proceedings
International Conference Development Learning (ICDL), pp. 17.
Diankov, R., Ratliff, N., Ferguson, D., Srinivasa, S., & Kuffner, J. (2008). Bispace planning:
Concurrent multi-space exploration. Proc. Int. Conf. Robotics: Science
Systems.
39

fiStulp, Fedrizzi, Mosenlechner, & Beetz

Fedrizzi, A. (2010). Action-Related Places Mobile Manipulation. Ph.D. thesis, Technische
Universiat Munchen.
Fedrizzi, A., Moesenlechner, L., Stulp, F., & Beetz, M. (2009). Transformational planning mobile manipulation based action-related places. Proceedings
International Conference Advanced Robotics (ICAR)., pp. 18.
Friedman, M., & Weld, D. S. (1996). Least-commitment action selection. Proceedings
3rd International Conference A.I. Planning Systems, pp. 8693. AAAI Press.
Geib, C., Mourao, K., Petrick, R., Pugeault, M., Steedman, M., Kruger, N., & Worgotter,
F. (2006). Object action complexes interface planning robot control.
Proceedings 2006 IEEE RAS International Conference Humanoid Robots,
Genova.
Gerkey, B., Vaughan, R. T., & Howard, A. (2003). Player/Stage Project: Tools
multi-robot distributed sensor systems. Proceedings 11th International
Conference Advanced Robotics (ICAR), pp. 317323.
Gibson, J. J. (1977). Theory Affordances. John Wiley & Sons.
Hart, S., Ou, S., Sweeney, J., & Grupen, R. (2006). framework learning declarative
structure. RSS-06 Workshop: Manipulation Human Environments.
Huang, X., Paragios, N., & Metaxas, D. N. (2006). Shape registration implicit spaces
using information theory free form deformations. IEEE Trans. Pattern Analysis
Machine Intelligence (TPAMI), 28, 13031318.
Kemp, C., Edsinger, A., & Torres-Jara, E. (2007). Challenges robot manipulation
human environments. IEEE Robotics Automation Magazine, 14 (1), 2029.
Klank, U., Zia, M. Z., & Beetz, M. (2009). 3D Model Selection Internet Database
Robotic Vision. International Conference Robotics Automation (ICRA),
pp. 24062411.
Kuipers, B., Beeson, P., Modayil, J., & Provost, J. (2006). Bootstrap learning foundational representations. Connection Science, 18, 145158.
LaValle, S. M. (2006). Planning Algorithms, chap. Chapter 5: Sampling-Based Motion
Planning. Cambridge University Press.
Maldonado, A., Klank, U., & Beetz, M. (2010). Robotic grasping unmodeled objects
using time-of-flight range data finger torque information. 2010 IEEE/RSJ
International Conference Intelligent Robots Systems (IROS), pp. 25862591,
Taipei, Taiwan.
McDermott, D. (1991). Reactive Plan Language. Research Report YALEU/DCS/RR864, Yale University.
Metta, G., Fitzpatrick, P., & Natale, L. (2006). YARP: Yet Another Robot Platform. International Journal Advanced Robotics Systems, special issue Software Development
Integration Robotics, 3 (1), 4348.
Morales, A., Chinellato, E., Fagg, A. H., & del Pobil, A. P. (2004). Using experience
assessing grasp reliability. International Journal Humanoid Robotics, 1 (4), 671691.
40

fiLearning Reasoning Action-Related Places Robust Mobile Manipulation

Mosenlechner, L., & Beetz, M. (2009). Using physics- sensor-based simulation
high-fidelity temporal projection realistic robot behavior. 19th International
Conference Automated Planning Scheduling (ICAPS09).
Okada, K., Kojima, M., Sagawa, Y., Ichino, T., Sato, K., & Inaba, M. (2006). Vision
based behavior verification system humanoid robot daily environment tasks.
Proceedings 6th IEEE-RAS International Conference Humanoid Robots
(Humanoids), pp. 712.
Pastor, P., Hoffmann, H., Asfour, T., & Schaal, S. (2009). Learning generalization
motor skills learning demonstration. Proceedings International
Conference Robotics Automation (ICRA), pp. 12931298.
Resulaj, A., Kiani, R., Wolpert, D. M., & Shadlen, M. N. (2009). Changes mind
decision-making. Nature, 461 (7261), 263266.
Roduit, P., Martinoli, A., & Jacot, J. (2007). quantitative method comparing trajectories mobile robots using point distribution models. Proceedings IEEE/RSJ
International Conference Intelligent Robots Systems (IROS), pp. 24412448.
Ryan, M. R. K. (2002). Using abstract models behaviours automatically generate reinforcement learning hierarchies. Proceedings 19th International Conference
Machine Learning, Sydney, Australia, pp. 522529.
Smits, R. KDL: Kinematics Dynamics Library. http://www.orocos.org/kdl.
Sonnenburg, S., Raetsch, G., Schaefer, C., & Schoelkopf, B. (2006). Large scale multiple
kernel learning. Journal Machine Learning Research, 7, 15311565.
Stulp, F., & Beetz, M. (2008). Refining execution abstract actions learned action
models. Journal Artificial Intelligence Research (JAIR), 32.
Stulp, F., Fedrizzi, A., & Beetz, M. (2009a). Action-related place-based mobile manipulation. Proceedings International Conference Intelligent Robots Systems
(IROS), pp. 31153120.
Stulp, F., Fedrizzi, A., & Beetz, M. (2009b). Learning performing place-based mobile
manipulation. Proceedings 8th International Conference Development
Learning (ICDL)., pp. 17.
Stulp, F., Fedrizzi, A., Zacharias, F., Tenorth, M., Bandouch, J., & Beetz, M. (2009c).
Combining analysis, imitation, experience-based learning acquire concept
reachability. 9th IEEE-RAS International Conference Humanoid Robots, pp.
161167.
Sutton, R., & Barto, A. (1998). Reinforcement Learning: Introduction. MIT Press.
Wimmer, M., Stulp, F., Pietzsch, S., & Radig, B. (2008). Learning local objective functions
robust face model fitting. IEEE Transactions Pattern Analysis Machine
Intelligence (PAMI), 30 (8), 13571370.
Zacharias, F., Borst, C., & Hirzinger, G. (2007). Capturing robot workspace structure: representing robot capabilities. Proceedings IEEE/RSJ International Conference
Intelligent Robots Systems (IROS), pp. 32293236.
41

fiStulp, Fedrizzi, Mosenlechner, & Beetz

Zettlemoyer, L. S., Pasula, H. M., & Kaelbling, L. P. (2005). Learning planning rules noisy
stochastic worlds. Proceedings Twentieth National Conference Artificial
Intelligence (AAAI), pp. 911918.
Zheng, Y., & Qian, W.-H. (2005). Coping grasping uncertainties force-closure
analysis. International Journal Robotics Research, 24 (4), 311327.

42

fiJournal Artificial Intelligence Research 43 (2012) 621-659

Submitted 11/11; published 04/12

Market-Inspired Approach Intersection Management
Urban Road Traffic Networks
Matteo Vasirani
Sascha Ossowski

matteo.vasirani@urjc.es
sascha.ossowski@urjc.es

Centre Intelligent Information Technology
University Rey Juan Carlos
C/ Tulipan s/n
Madrid, 28933, Spain

Abstract
Traffic congestion urban road networks costly problem affects major
cities developed countries. tackle problem, possible (i) act supply
side, increasing number roads lanes network, (ii) reduce demand, restricting access urban areas specific hours specific vehicles, (iii) improve
efficiency existing network, means widespread use so-called Intelligent
Transportation Systems (ITS). line recent advances smart transportation
management infrastructures, turned promising field application
artificial intelligence techniques. particular, multiagent systems seem ideal
candidates design implementation ITS. fact, drivers naturally
modelled autonomous agents interact transportation management infrastructure, thereby generating large-scale, open, agent-based system. regulate
system maintain smooth efficient flow traffic, decentralised mechanisms
management transportation infrastructure needed.
article propose distributed, market-inspired, mechanism management future urban road network, intelligent autonomous vehicles, operated
software agents behalf human owners, interact infrastructure order
travel safely efficiently road network. Building reservationbased intersection control model proposed Dresner Stone, consider two different
scenarios: one single intersection one network intersections.
former, analyse performance novel policy based combinatorial auctions
allocation reservations. latter, analyse impact traffic assignment strategy inspired competitive markets drivers route choices. Finally
propose adaptive management mechanism integrates auction-based traffic
control policy competitive traffic assignment strategy.

1. Introduction
Removing human driver control loop use autonomous vehicles integrated intelligent road infrastructure considered ultimate,
long-term goal set systems technologies grouped name Intelligent
Transportation Systems (ITS). Autonomous vehicles already reality. instance,
three DARPA Grand Challenges 1 held far. teams participating
latest event, DARPA Urban Challenge, competed build best autonomous vehi1. http://archive.darpa.mil/grandchallenge/
c
!2012
AI Access Foundation. rights reserved.

fiVasirani & Ossowski

cles, capable driving traffic, performing complex manoeuvres merging, passing,
parking negotiating intersections. results shown first time
autonomous vehicles successfully interact manned unmanned vehicular
traffic urban environment. Several car-makers expect technology affordable
(and less obtrusive) decade2 . Another initiative fosters vision Connected Vehicle 3 , promotes research development technologies link road
vehicles directly physical surroundings, i.e., vehicle-to-infrastructure wireless
communications. advantages integration span improved road safety
efficient operational use transportation network. instance, vehicles
exchange critical safety information infrastructure, recognise high-risk
situations advance therefore alert drivers. Furthermore, traffic signal systems
communicate signal phase timing information vehicles enhance use
transportation network.
regard, authors recently paid attention potential tighter
integration autonomous vehicles road infrastructure future urban traffic management. reservation-based control system (Dresner & Stone, 2008), intersection
regulated software agent, called intersection manager agent, assigns reservations space time autonomous vehicle intending cross intersection.
vehicle operated another software agent, called driver agent. vehicle
approaching intersection, driver requests intersection manager reserve
necessary space-time slots safely cross intersection. intersection manager,
provided data vehicle ID, vehicle size, arrival time, arrival speed, type turn,
etc., simulates vehicles trajectory inside intersection informs driver whether
request conflict already confirmed reservations. conflict
exist, driver stores reservation details tries meet them; otherwise may try
later time. authors show simulations situations balanced
traffic, vehicles autonomous, delays intersection drastically reduced
compared traditional traffic lights.
article explore different lines research artificial intelligence agent
technology improve effectiveness applicability Dresner Stones
approach, assuming vehicles autonomous capable interacting
regulating traffic infrastructure. extend reservation-based model intersection
control two different levels.
1.1 Single Intersection
single intersection, objective elaborate new policy allocation
reservations vehicles takes account drivers different attitudes regarding
travel times. Instead granting disputed resources (intersection space time)
first agent requests them, intend allocate agents value
most, maintaining adequate level efficiency fairness system.
main contribution regard definition auction-based allocation policy
2. See example Alan Taub, General Motors Vice President Global R&D, 18th World Congress
Intelligent Transport Systems, October 17th, 2011.
3. http://www.its.dot.gov/connected vehicle/connected vehicle.htm

622

fiA Market-Inspired Approach Intersection Management

assigning reservations. policy models incoming requests bids intersections
available space-time slots tries maximise overall value accepted bids. Due
combinatorial nature auction restrictions scenario (mainly realtime execution safety), define specific auction protocol, adapt algorithm
winner determination purposes, evaluate behaviour approach.
1.2 Network Intersections.
extend Dresner Stones approach network intersections, focus
problem traffic assignment, conceived distributed choice problem intersection
managers try affect decision making driver agents. particular, use markets
mediators distributed choice allocation problem (Gerding, McBurney, &
Yao, 2010). contribution attainment objective twofold. First,
build computational market drivers must acquire right pass
intersections urban road network, implementing intersection managers
competitive suppliers reservations selfishly adapt prices match actual
demand. Second, combine competitive strategy traffic assignment
auction-based control policy intersection level adaptive, market-inspired,
mechanism traffic management reservation-based intersections.
article structured follows. Section 2 provides overview use artificial
intelligence agent technology field ITS. Section 3 briefly review key
elements reservation-based intersection control model work sets from.
Section 4 present policy allocation reservations single intersection,
inspired combinatorial auction theory. Section 5 extend reservation-based
model network intersections. Finally, conclude Section 6.

2. Related Work
achieve goals pursued vision increasing need understand,
model, govern systems individual (micro) societal (macro)
level. Transportation systems may contain thousands autonomous entities need
governed, raises significant technical problems concerning efficiency
scalability. inherent distribution traffic management control problems,
high degree complexity, fact actors traffic transportation systems
(driver, pedestrians, infrastructure managers, etc.) fit concept autonomous agent
well, allow modelling terms agents interact achieve
goals, selfishly well cooperatively. Therefore, traffic transportation scenarios
extraordinarily appealing multiagent technology (Bazzan & Klugl, 2008). section,
outline key dimensions briefly review relevant literature use
artificial intelligence multiagent techniques field.
2.1 Traffic Control Traffic Assignment
Traffic control refers regulation access disputed road transport resource.
Traffic control systems manage traffic along arterial roadways, employing traffic detectors,
traffic signals, various means communicating information drivers. Freeway control
623

fiVasirani & Ossowski

systems manage traffic along highways, employing traffic surveillance systems, traffic control
measures freeway entrance ramps (ramp metering), lane management.
Traffic control intersections, based traffic lights, major control measure
urban road networks. type control typically applies off-line optimisation basis
historical data. TRANSYT (Robertson, 1969) well-known frequently applied
signal control strategy, cannot adapt dynamically changing demand patterns.
control techniques, SCOOT (Hunt, Robertson, Bretherton, & Winton, 1981),
use real-time traffic volume rather historical data run optimisation algorithms
compute optimal signal plan.
Traffic assignment refers problem distribution traffic network, considering demands several locations, capacity network. general,
demand may change non-predictable way, due changing environmental conditions,
exceptional events, accidents. This, turn, leads under-utilisation overall network capacity, whereby links heavily congested capacity reserves available
alternative routes. address problem, different traffic management techniques, involving information broadcast well control optimisation, employed.
example, route guidance driver information systems (RGDIS) may employed improve network efficiency via direct indirect recommendation alternative routes (Papageorgiou, Diakaki, Dinopoulou, Kotsialos, & Wang, 2003). communication devices
may consulted potential road user make rational decision regarding whether
carry (or postpone) intended trip, choice transport mode (car, bus,
underground, etc.), departure time selection route choice.
Traffic control assignment different focuses therefore combined
single management policy takes explicitly account mutual interactions
signal control policies user route choices (Meneguzzer, 1997).
2.2 Isolated Coordinated Traffic Control
traffic control strategies use control devices (e.g., traffic lights, variable message signs,
ramp meters) surveillance devices (e.g., loop detectors, cameras) manage physical
traffic network. isolated control, small portion network (e.g. single
intersection) modelled, techniques control theory employed determine
signal cycles minimise vehicles total delay. instance, da Silva et al. proposed
reinforcement learning system traffic lights copes dynamism
environment incrementally building new models environmental state transitions
rewards (da Silva, Basso, Bazzan, & Engel, 2006). traffic pattern changes,
additional model created new traffic signal plan learned. creation new
models controlled continuous evaluation prediction errors generated
partial model.
coordinated control, settings several control devices adapted other,
achieve smooth traffic flow network level (i.e., green waves) rather
single intersection. allowing individual devices coordinate actions
based information receive sensors other, coherent traffic
control plans often generated faster accurately compared human traffic
operator (van Katwijk, Schutter, & Hellendoorn, 2009). instance, distributed constraint
624

fiA Market-Inspired Approach Intersection Management

optimisation (DCOP) techniques recently applied coordination control
devices (Junges & Bazzan, 2008). traffic signal agent assigned one several
variables DCOP, inter-dependencies conflicts (e.g., two neighbouring
intersections giving preference different directions traffic.). mediator agent
charge resolving conflicts occur, recommending values variables
associated agents involved mediation.
2.3 Time Perspective
time perspective refers stage decision-making process
application takes place. Operational decision-making refers short term issues,
controlling traffic intersection. Tactical decision-making deals medium-term
issues, anticipating congestion diverting traffic different routes influencing
demand patterns. Finally, strategic decision-making typically involves long-term decisions,
e.g. planning construction new roads, highways parking hubs.
Many AI-based partially automate operational part road traffic control tasks.
Tactical strategic decision-making still mainly human activity (e.g., carried
city planners). recent decision-support systems address tactical questions
well. InT RY (Hernandez, Ossowski, & Garca-Serrano, 2002), instance, multiagent
system aimed assisting operators traffic control centre manage urban motorway
network. system capable engaging dialogues operators, e.g. diagnose
causes detected traffic problems, construct coherent sets driver information
messages, simulate expected effects control plans.
2.4 Information Drivers
Cooperative systems improve dynamic routing traffic management (Adler, Satapathy, Manikonda, Bowles, & Blue, 2005), using information services aimed giving advice
drivers efficiently assigning traffic among network. difficult problem collective route choice performed selfish agents often leads equilibrium strategies
far social welfare optima (Roughgarden, 2003). Providing information congestion links sharing partial views vehicle choices, context-aware routing (Zutt,
van Gemund, de Weerdt, & Witteveen, 2010), may improve systems efficiency.
2.5 Domain Knowledge
Domain topological knowledge exploited structure architecture
reasoning models ITS. instance, Choy et al. propose cooperative, hierarchical, multiagent system real-time traffic signal control (Choy, Srinivasan, & Cheu,
2003). control problem divided various sub-problems, handled
intelligent agent applies fuzzy neural decision-making. multiagent system
hierarchical, since decisions made lower-level agents mediated respective
higher-level agents. InT RY system (Hernandez et al., 2002) conceives traffic
dynamics terms so-called problem areas, defined based expertise
traffic engineers. problem area controlled separate traffic control (software)
agent. Knowledge modelling reasoning techniques applied integrate local control
625

fiVasirani & Ossowski

strategies (proposed different traffic control agents) coherent global plan
whole traffic network.
2.6 Learning Adaptation
often rely learning techniques adapt changing unknown traffic conditions.
instance, traffic light agents may use reinforcement learning minimise overall
waiting time vehicles (Steingrover, Schouten, Peelen, Nijhuis, & Bakker, 2005; Wiering,
2000). control objective global, although actions local agents. state
learning task represented aggregation waiting times individual vehicles
intersection. Traffic light agents learn value function estimates expected
waiting times vehicles given different settings traffic lights.
Several authors focus self-organising self-adapting mechanisms traffic control (Gershenson, 2005; Lammer & Helbing, 2008), traffic lights self-organise
direct communication them. local interactions neighbouring traffic lights lead emergent coordination patterns green waves. way,
efficient, decentralised traffic light control achieved, combination two rules, one
aims optimising flow one aims stabilising it. RY SA2
system (Hernandez et al., 2002), traffic agents use mechanism called structural cooperation (Ossowski & Garca-Serrano, 1999) locally coordinate signal plan proposals
without need rely dedicated domain (coordination) knowledge.
2.7 Market-Based Coordination
complex system, traffic well suited application market-based coordination mechanisms different levels. mechanisms replicate functioning real
markets (i.e., auctions, bargaining, etc.) order coordinate activities goals
pursued set agents. agents regulate infrastructure built
act team, i.e., may share global objective function represents system
designers preferences possible solutions, occurs multi-robot domains (Dias,
Zlot, Kalra, & Stentz, 2006). line perspective, Vasirani Ossowski (2009b)
proposed market-based policy traffic assignment. authors put forward cooperative learning model coordinate prices several intersections. experimental
results showed that, general, increase profit raised team intersections
aligned reduced average travel times. limitation work number interactions environment required order price vector maximises
overall profit learned.
extend focus include selfish driver agents interaction
infrastructure agents, non-cooperative scenario arises. instance, auction-based
policy intersection control proposed work Schepperle Bohm (2007).
work, intersection controlled intelligent agent starts auction earliest
time slot among vehicles approaching intersection lane. authors
assume agent controls intersection detect approaching vehicle
another vehicle front it. case, former allowed participate
auction (i.e., bids processed), ensure vehicles
physical impediments cross intersection allowed participate auction.
626

fiA Market-Inspired Approach Intersection Management

Furthermore, since non-combinatorial auction run allocate earliest time-slot,
one bidder (i.e., driver) entitled get specific time-slot, lead inefficiencies
assignments.
field transport economics also studies allocation resources used move
road users place place (Small & Verhoef, 2007). However, follows static
analytical approach requires extensive knowledge supply demand functions.
information often hard obtain extract, usually findings field
hard transfer directly ITS.
2.8 Discussion
work, mainly focus operational time perspective, since aim
manage advanced traffic infrastructure regulates route choices autonomous
vehicles, tactical strategic decisions left human users. order make
proposed mechanisms broadly adoptable, minimise domain knowledge necessary
set models. software agents reside traffic management
infrastructure need aware remaining infrastructure agents, require
expert knowledge related underlying traffic system. focus local adaptation
mechanisms, rather learning techniques, enforce emergent coordination among
software agents reside traffic management infrastructure. Furthermore,
put forward market-based coordination framework involves infrastructure
drivers. infrastructure agents coordinate actions indirect way
competitive market participants aim match supply demand. driver
agents participate allocation road network capacity auction-based
mechanism regulates assignment right cross intersection. Finally,
recognise importance providing information drivers order influence
decision making. particular, assume existence propagation mechanisms,
market price information available drivers, thus potentially influencing
collective behaviour4 .

3. Reservation-Based Intersection Control
applications AI techniques multiagent technology traffic domains
detailed previous section conceive lies infrastructure components (traffic lights, message signs, sensors, etc.), vehicles usually treated
particles traffic flow control policy cannot individually address. Nevertheless,
continuous advances software hardware technologies make tighter integration
vehicles infrastructure possible. Even today, vehicles equipped
features cruise control (Ioannou & Chien, 1993) autonomous steering (Krogh
& Thorpe, 1986). Small-scale systems autonomous guided vehicles (AGV) already exist,
example factory transport systems. trend continues, one day fully autonomous
vehicles populate road networks. case, given system comprise
variable (and possibly huge) number vehicles, open infrastructure needed control
4. Setting price index boards technically feasible already today: instance, NYSE indexes
approximately 8500 stocks, whose price variations spread worldwide almost immediately.

627

fiVasirani & Ossowski

Driver agent
(2)
Send REQUEST

Intersection manager

Reservation distance
lter

(5)

> reservation
distance di ?

Calculate
distance d(r)



Get driver
agent's ID

(3)

(1)

yes
Send
REJECTION

(6)

(4)


reservation ?



yes

(11)

(10)

Send
REJECTION

Update di

Remove
agent's
reservation

min(di,d(r))

yes

(9)

(7)

(8)
Simulate
trajectory


conicts ?


(13)

(12)

Send
CONFIRMATION

Update di

Figure 1: Reservation-based protocol FCFS policy
schedule transit AGVs. fact, nowadays centralised AGV control systems know
number vehicles, origins destinations, route planning takes
place. case urban road traffic scenario, approach certainly unfeasible.
section present details reservation-based system intersection
control (Dresner & Stone, 2008) relevant work5 . particular outline
policy executed intersection managers process reservations requests (Section 3.1)
analyse impact distance reservation sent performance
control mechanism (Section 3.2).
3.1 Protocol
reservation-based control system proposed Dresner Stone assumes existence
two different kinds software agents: intersection manager agents driver agents.
intersection manager agent controls space intersection schedules crossing
vehicle. driver agent entity autonomously operates vehicle (in
following use terms intersection manager driver short, refer
software agents control intersection vehicle respectively). protocol,
using first-come-first-served policy (FCFS), summarised Figure 1. driver,
5. remark work engineered basic aspects reservation-based system.
consider advanced features, acceleration within intersections, safety buffers edge
tiles. basic functioning reservation-based intersection assume work
every experimental scenario compare. way fair comparison different policies
allocation reservations guaranteed.

628

fiA Market-Inspired Approach Intersection Management

(request reservation
:sender
:receiver
:content(

D-3548
IM-05629
:arrival time
:arrival speed
:lane
:type turn

08:03:15
23km/h
2
LEFT

)
)
Figure 2: Example REQUEST message
approaching intersection, contacts intersection manager sending REQUEST
message (1). message contains vehicles ID, arrival time, arrival speed,
lane occupied vehicle road segment approaches intersection
intended type turn (see Figure 2 example REQUEST message). intersection
manager calculates distance d(r) driver sending reservation request
r (2). distance greater maximum reservation distance di lane
driver occupying (3), request rejected without processing (4). Otherwise,
intersection manager proceeds evaluate whether accommodated not.
First, drivers ID parsed (5), driver already prior reservation (6),
reservation removed (7). Then, information contained REQUEST message,
intersection manager simulates vehicle trajectory, calculating space needed
vehicle time order check potential conflicts (8). (9),
intersection manager updates maximum reservation distance di (10) replies
REJECTION message (11). Otherwise, maximum reservation distance di updated
infinite (12) intersection manager replies CONFIRMATION message (13),
implies drivers request accepted.
FCFS policy implies two drivers send requests require spacetime slots inside intersection, driver sends request first obtain
reservation. extreme cases policy clearly inefficient. Consider case set
n vehicles, v1 , v2 , . . . , vn , v1 request conflicts every vehicle,
v2 , . . . , vn conflicts one another. v1 sends request first,
granted vehicles requests rejected. hand, sends
request last, n 1 vehicles requests confirmed, whilst v1
wait. Nevertheless, FCFS advantage simple policy,
needs minimum amount information necessary implement reservation-based
intersection control.
3.2 Reservation Distance
protocol detailed would prone deadlock situations, make use
reservation distance filter. Consider two vehicles, B, moving front
B (see Figure 3). Suppose also B cannot safely overtake A. B send request
629

fiVasirani & Ossowski

B sends request
rst gets
reservation

B

A's request
rejected, thus
must stop
intersection


Given cannot
cross, also B must
stop
intersection

Figure 3: Potential deadlock situation.

space-time slots inside intersection, first request intersection
manager receives accepted, second one rejected. vehicle B,
behind vehicle A, obtains reservation, result vehicle able
cross hold confirmed reservation. turn prevents vehicle B
making use reservation. vehicle B always sends request first, deadlock
situation arises, vehicle physically blocking vehicle B, vehicle B blocking vehicle
getting disputed reservation.
avoid occurrence deadlock situations, Dresner Stone proposed
use reservation distance heuristic criterion filtering reservation requests
could generate deadlock situations. Since drivers communicate time
plan arrive intersection, well speed get
(quantities drivers incentive misrepresent), possible
approximate vehicles distance intersection, given reservation request
vehicle. heuristic approximation, called reservation distance d(r), calculated
d(r) = va (ta t), va proposed arrival speed vehicle, ta proposed
arrival time vehicle, current time.
approximation assumes vehicle maintaining constant speed.
reservation processing policy uses follows. lane i, policy variable di ,
initialised infinity, represents maximum distance driver send
reservation request. reservation request r lane i, policy computes
reservation distance, d(r). d(r) > di , r rejected. If, hand, d(r) di , r
processed normal. r rejected processed normal, di min(di , d(r)).
Otherwise, di . use reservation distance guarantee
630

fiA Market-Inspired Approach Intersection Management

mutually blocking situations never occur, prevent situations degenerating
deadlocks.

4. Single Intersection
single reservation-based intersection, problem intersection manager
solve allocating reservations among set drivers way specific objective
maximised. objective be, instance, minimising average delay caused
presence regulated intersection. case, simplest policy adopt allocating
reservation first agent requests it, occurs FCFS policy proposed
Dresner Stone original work. Another work line objective takes
inspiration adversarial queuing theory definition several alternative control
policies aim minimising average delay (Vasirani & Ossowski, 2009a)
However, policies ignore fact real world, depending context
personal situation, people value importance travel times delays quite
differently. Since processing incoming requests grant associated reservations
considered process assigning resources agents request them, one may
interested intersection manager aims allocate disputed resources
agents value most. line approaches mechanism design,
assume human driver willing pay desired set space-time slots,
value good. Therefore, rely combinatorial auction theory (Krishna,
2002) definition auction-based policy allocation resources.
4.1 Auction-Based Policy
formalise auction-based policy processing incoming reservation requests,
necessary specify auction design space. includes definition disputed
resources, rules regulate bidding clearing policy.
4.1.1 Auctioned Resources
first step design auction definition resources (or items)
allocated. nature items determines type auction employed
allocate them. scenario, auctioned good use space inside
intersection given time. model intersection discrete matrix space slots.
Let set intersection space slots, = {s1 , s2 , . . . , sm }. Let tnow current
time, = {tnow + , N} set future time-steps. set items
bidder bid set = . Due nature problem, bidder
interested bundles items set I. absence acceleration
intersection, reservation request (Figure 4) implicitly defines space slots
time driver needs order pass intersection6 . Thus, items must
necessarily allocated combinatorial auction.
6. computation easily done intersection manager, knows geometry intersection. vehicles calculate trajectory, would need know geometry every
intersection pass through.

631

fiVasirani & Ossowski

t4

t4

t3

t3

t2

t2

t4

t4

t3

t3

t2

t2

t1

t1

t1

t1

t0

t0

t0

t0

Figure 4: Bundle items defined reservation request.

4.1.2 Bidding Rules
bidding rules define form valid bid accepted auctioneer (Wurman,
Wellman, & Walsh, 2001). scenario, bid bundle items implicitly defined
reservation request. Given parameters arrival time, arrival speed, lane type
turn, auctioneer (i.e., intersection manager) able determine space slots
needed time. Thus, additional parameter driver must include
reservation request value bid, i.e., amount money willing pay
requested reservation.
bidder allowed withdraw bid submit new one. may happen,
instance, driver submitted bid b, estimating intersection
time t, realises that, due changing traffic conditions, likely
intersection time + t, thus making submitted bid b useless driver.
case driver guarantees safety regarding crossing intersection. Thus,
rational thing case, driver would want risk involved
car accident, resubmitting bid updated arrival time. However, new bid
must greater equal value previous one. constraint avoids
situation whereby bidder blocks one several slots itself, acquiring early
overpriced bids. Even though would oblige others try reserve alternative
slots, thus make desired slot less disputed, bidder cannot take advantage
this, cannot withdraw initial bid resubmit lower bids order obtain
reservation lower price.
632

fiA Market-Inspired Approach Intersection Management

new bids

winners


bid set

Send
CONFIRMATION

Solve
WDP



Collect
incoming
bids

losers

Collect
incoming
bids

Send
REJECTION

new bids

Figure 5: Auction policy

4.1.3 Auction Policy
auction policy (see Figure 5) starts auctioneer waiting bids certain amount time t. new bids collected, constitute bid set.
Then, auctioneer executes algorithm winner determination problem (WDP),
winner set built, containing bids whose reservation requests accepted. WDP algorithm execution, auctioneer still accepts incoming bids,
included bid set next round. auctioneer sends
CONFIRMATION message bidders submitted bids contained winner set,
REJECTION message sent bidders submitted remaining bids.
new round begins, auctioneer collects new incoming bids certain amount
time7 .
4.1.4 Winner Determination Algorithm
Since auction must performed real-time, bid collection winner
determination phase must time-bounded, is, must occur within specific time
window. implies optimal complete algorithms WDP (Leyton-Brown,
Shoham, & Tennenholtz, 2000; Sandholm, 2002) suited kind auction.
algorithm anytime properties needed (Hoos & Boutilier, 2000), longer
algorithm keeps executing, better solution finds.
7. safety reasons auctioneer cannot spend much time collecting bids, deallocate
previously granted reservations. Therefore possible low-valued bid, winner set round
k, impedes allocation disputed reservation high-valued bids, submitted round k + n.
case, second bidder slow resubmit new (possibly winning) bid. Although
theory bid-delay relation (Figure 7) could worsened unrelated sequence auctions,
practice effect negligible.

633

fiVasirani & Ossowski

Algorithm 1 Winner determination algorithm
B allBids
W
start currentT ime
currentT ime start < 1 sec

step = 1 |B|
step step + 1
random drawU nif ormDistribution(0, 1)
random < wp
b selectRandomlyF rom(B \ A)
else
highest selectHighestF rom(B \ A)
secondHighest selectSecondHighestF rom(B \ A)
highest.age secondHighest.age
b highest
else
random drawU nif ormDistribution(0, 1)
random < np
b secondHighest
else
b highest
end
end
end !
AA
{b} \ N (b)
A.value > W.value
WA
end
end
end
Algorithm 1 sketches winner determination problem solved. algorithm
starts initialising set B containing bids received far. winner set W
initialised empty set. initialisation concluded, algorithm
executes main loop 1 second. Within main loop, stochastic search performed
number steps equal number bids B. Set contains candidate bids
winner set. Then, probability wp (walk probability8 ), random bid selected
set bids actually candidate winner set (B \ A), while,
probability 1 wp, highest second highest bids evaluated. highest bid
selected age (i.e., number steps since bid last selected added
candidate solution) greater equal age second highest bid. Otherwise,
8. probability adding random, previously allocated bid candidate winner set.

634

fiA Market-Inspired Approach Intersection Management

Figure 6: Simulator single intersection
probability np (novelty probability9 ) second highest, probability 1 np
highest bid selected. Finally bid b added candidate solution
neighbours N (b), is, set bids bundles share b least one item,
removed A. Finally, value (i.e., sum bids A) greater
value best-so-far winner set, W, best solution found far updated.
4.2 Simulation Environment
simulator use evaluation auction-based policy custom, microscopic,
time-and-space-discrete simulator, simple rules acceleration deceleration.
simulated area modelled grid, subdivided lanes (see Figure 6). lane
3m wide, subdivided 12 squared tiles 0.25m each. vehicle modelled
rectangle 816 tiles, equivalently, rectangle 2m4m, preferred speed
interval [30, 50]km/h. simulation environment generates origin-destination
pair randomly. vehicle spawned inside simulation, inserted
beginning one 4 incoming links, randomly selected, destination randomly
assigned it. destination implies type turn (left, right straight)
vehicle perform intersection well lane use travel (the leftmost lane case left turn, right-most lane case right turn, lane going
straight). preferred speed assigned using normal distribution mean 40km/h
variance 5km/h, limited interval [30, 50].
9. probability adding candidate winner set second highest bid rather greedy
bid, i.e., highest value.

635

fiVasirani & Ossowski

Since link used approach intersection relatively short, assume
vehicle travel pre-assigned lane, without changing it. Therefore, need
car-following model simulate vehicle dynamics, lane-changing model
needed. car-following model use Intelligent Driver Model (Treiber, Hennecke,
& Helbing, 2000). model, decision driver accelerate brake depends
speed, speed vehicle immediately ahead it. Specifically,
acceleration dv/dt given vehicle depends speed v, distance
front vehicle, speed difference v (positive approaching) :
"
# $ # $2 %
dv
v

= 1

dt
vp


(1)




= s0 +

#

v v
vT +

2 ag

$

(2)

acceleration, g deceleration10 , v actual speed, vp preferred
speed, s0 minimum gap, time headway.
acceleration divided acceleration towards preferred speed free
road, braking decelerations induced front vehicle. acceleration free
road decreases initial acceleration 0 approaching preferred speed vp .
braking term based comparison preferred distance ,
current gap respect front vehicle. current gap approximately
equal , braking deceleration essentially compensates free acceleration
part, resulting acceleration nearly zero. means corresponds
gap following vehicles steady traffic conditions. addition, increases
dynamically approaching slower vehicles decreases front vehicle faster.
consequence, imposed deceleration increases decreasing distance front
vehicle, increasing speed, increasing speed difference front vehicle.
aforementioned parameters set vp = 50km/h, = 1.5s, s0 = 2m, = 0.3m/s2 ,
b = 3m/s2 . speed vehicle updated every second, position, since space
discrete, updated tile closest new position continuous space.
4.3 Experimental Results
create different traffic demands varying expected number vehicles () that,
every O-D pair, spawned interval 60 seconds, using Poisson distribution.
spawned vehicles total time 30 minutes. Table 1 shows number vehicles
generated different values .
main goal set experiments test whether policy based combinatorial auction (CA) enforces inverse relation money spent bidders
delay. delay measures increase travel time due presence
intersection. computed difference travel time intersection
10. g different parameters different values, since usually vehicle decelerates (i.e., brakes)
strongly accelerates.

636

fiA Market-Inspired Approach Intersection Management


# vehicles

1
29

5
136

10
285

15
438

20
633

25
716

30
832

Table 1: Traffic demands single intersection
regulated intersection manager, travel time would arise vehicle
could travel unhindered intersection. bid driver willing submit
drawn normal distribution mean 100 cents variance 25 cents, since
willingness human drivers pay usually normally (or log-normally) distributed (Hensher & Sullivan, 2003). Thus, agents homogeneous sense amount
money offering differs one another. population, track
delay subset drivers, endowed 10, 50, 100, 150, 200, 1000, 1500,
2000 10000 cents. endowment entirely allocated bid. also evaluate
auction-based policy respect average delay entire population drivers.
WDP algorithm, set walk probability wp = 0.15 novelty probability np = 0.5, values produced best results auctions similar type
size (Hoos & Boutilier, 2000). experiments, give intersection manager one
second execute WDP algorithm return solution. give time bidders submit bids, starting another auction, intersection manager waits
another second collect incoming bids11 . determine one second enough
winner determination algorithm produce acceptable results, performed following experimental analysis. According results reported Hoos Boutilier, given
auction 100 bids, winner determination algorithm able find optimal
solution probability 0.6, tends 1 algorithm allowed run
10 seconds. encouraging, order justify adequacy
stochastic algorithm particular problem, need show that, context
auction-based policy reservation-based intersection control, produces results
reasonably close optimum, despite relatively short time (1 second experiments) algorithm return solution. Given average number
submitted bids single auction 3 low traffic demand ( = 1) 80
high traffic demand ( = 30), performed several experiments compare solution
provided algorithm 1 second run-time solution provided algorithm 100 seconds. solution provided second execution algorithm
assumed best approximation optimal solution. result
winner determination algorithm able find solution whose value least 95%
optimal solution value probability 96.1% high traffic demand ( = 30)
99.2% low traffic demand ( = 1).
Figure 7 plots (in logarithmic scale) relation travel time bid value
different values . error bars denote 95% confidence intervals.
sensible decrease delay experienced drivers bid 100 150 cents,
represent 49.8% drivers whose bid greater mean bid. Still, delay
reduction tends settle drivers bid 1000 cents.
11. Nevertheless, intersection manager runs separate thread receives incoming bids also
WDP algorithm execution.

637

fiVasirani & Ossowski

500

90

80

70

60

10

100

1000

Bid (cents)
(a) = 10

10000

900

450

Avg delay (sec)

Avg delay (sec)

Avg delay (sec)

100

400

350

300

250

800

700

600

500
10

100

1000

Bid (cents)
(b) = 20

10000

10

100

1000

10000

Bid (cents)
(c) = 30

Figure 7: Bid-delay relation various values normally distributed endowments

remark auction-based policy also uses reservation distance preprocessing step, guarantees drivers bid cannot rejected indefinitely.
fact, vehicle allowed approach intersection slow reaches
intersection edge. point, request rejected another driver submitted
higher value bid, reservation distance updated stopped vehicles distance.
Therefore, following time step, driver allowed submit bid
preferred value. result is, course, driver suffer greater delays compared
drivers willing pay more12 .
auction-based allocation policy proven effective regarding main goal,
is, rewarding lower delays drivers value disputed reservations
most. However, worth analysing impact policy intersections
average delay. Figure 8a plots average delay different traffic demands ( [1, 30]).
Again, error bars denote 95% confidence intervals. traffic demand low, performance CA policy FCFS approximately same. However, traffic
demand increases, noticeable increase average delay intersection
manager applies CA. somewhat expected, CA policy aims grant
reservation driver values most, rather maximising number
granted requests. Thus, bid b, whose value greater sum n bids share
items b, likely selected winner set. so, 1 vehicle
allowed transit, n vehicles slow try again. fact
highlighted also average rejected requests (Figure 8b). Since non-winning
bids rejected, number rejected requests CA policy four times
greater FCFS policy.
12. Although focus technical problems social political ones, one may wonder whether
fair rich drivers travel faster poor drivers using road-infrastructure public
good. Nevertheless, could argue money raised auction-based policy rich
drivers contribute much maintenance extension public road infrastructure
poor drivers.

638

fiA Market-Inspired Approach Intersection Management

FCFS
CA

600

Avg delay (sec)

Avg rejected requests (%)

700

500
400
300
200
100
0
5

10

15

20

25

30

FCFS
CA

20

15

10

5

5

10

15



20

25

30



(a)

(b)

Figure 8: Average delay (a) average rejected requests (b)
4.4 Discussion
principle optimising use available resources unique guiding
principle traffic controller. real world, depending context
personal situation, drivers value importance travel times delays quite differently.
Thus, makes sense elaborate control policies aware different valuations
reward drivers value disputed resources most. respect,
evaluated control policy reservation-based intersections relies auction
mechanism. policy, drivers submit high-value bids usually experience
significant reductions individual delays (about 30% less compared drivers
submit low-value bids).
However, since objective policy maximising number granted
reservations, pays social cost, form greater average travel times. fact
might limit applicability CA policy high load situations. case, additional
mechanisms reduce number vehicles approach single intersection needed.
also worth noting possible driver, even theoretically infinite
amount money, cannot experience zero delay approaching intersection.
auction carried realistic traffic scenario quite different
synthetic auction set-up benchmarking purposes (Hoos & Boutilier, 2000).
auctions arise traffic scenario affected high level dynamism,
uncertainty noise, intrinsic domain. example, high load situations,
reservation distance plays important role, since filters many potentially winning
bids coming greater distance13 . Figure 9 plots reservation distance decreases
time different traffic demands. high load situations, reservation distance
tends small, therefore wealthy driver must reach reservation distance order
participate auction acquire reservation, thus increasing travel time.
estimation arrival time also greatly affects performance auction. fact,
13. outlined Section 3.2, reservation distance maximum distance driver allowed
request reservation.

639

fiReservation distance (m)

Vasirani & Ossowski

350

300

250

200






150

0

=1
= 10
= 20
= 30
5

10

15

20

25

Time (min)

Figure 9: Reservation distance

high load situations, estimation much noisy uncertain, likely
driver must resubmit reservation request updated arrival time.
way, possible agent wins auction time then, due new estimation
arrival time, must resubmit bid time + t. bidders participate
auction time + obviously different participated time t,
guarantee agent might win auction again.
Furthermore, real-world scenario urban traffic limits auction design space
applicable solution methods winner determination payments calculation.
fact, gave priority winner determination problem, adapting local search algorithm needs, payments calculation adopt sophisticated
method, i.e., winner pays price exactly bid submitted. This,
first-price payment mechanism, could principle lead malicious behaviours,
drivers try acquire reservations submitting bids lower
real valuations have. single item auctions computationally easy set
incentive compatible payment mechanism, second-price (Vickrey) mechanism.
Unfortunately, extending mechanism combinatorial auctions (computationally) straightforward, since equivalent truth-revealing mechanism combinatorial
world, Vickrey-Clarke-Groves (VCG) payment mechanism (Clarke, 1971; Groves, 1973;
Vickrey, 1961), NP-complete. Therefore, although driver agent could potentially acquire
reservation submitting bid &b lower real valuation b, practical
point view exclusively affects revenues auctioneer gain every
bidder truth-telling, primary concern. Another possible weakness
fact bidder could start bidding lower real valuation raising bid able acquire it, thus leading communication overhead
bidders auctioneer. Nevertheless, bidders within reservation distance able submit bid, thus number bids intersection manager may
receive simultaneously necessarily bounded.
640

fiA Market-Inspired Approach Intersection Management

5. Network Intersections
single intersection scenario analysed performance auction-based policy
allocation reservations. context, driver modelled simple agent
selects preferred value bid submitted auctioneer.
focus urban road network multiple intersections, interesting notice
decision space driver much broader. fact, drivers involved complex
mutually dependent decisions route choice departure time selection.
time, scenario opens new possibilities intersection managers affect behaviour
drivers. example, intersection manager may interested influencing
collective route choice performed drivers, using variable message signs, information
broadcast, individual route guidance systems, evenly distribute traffic
network. problem called traffic assignment.
Section 5.1 evaluate market-inspired methods (Gerding et al., 2010)
applied traffic assignment strategies networks reservation-based intersections.
idea that, market drivers acquire necessary reservations pass
intersections urban network, market, intersection managers
operate supply side, designed work traffic assignment
system. particular, model intersection managers apply competitive
pricing strategy compete among supply reservations
traded. Finally, Section 5.2 combine traffic assignment strategy auctionbased control policy integrated mechanism traffic management urban road
networks.
5.1 Competitive Traffic Assignment (CTA)
Traffic assignment strategies aim influencing collective route choice drivers order
use road network capacity efficiently. Therefore, see traffic assignment
problem distributed choice allocation problem, since set resources (i.e.,
links capacity) must allocated set agents (i.e., drivers). regard,
markets mediators distributed resource allocation problems applied
several socio-technical systems (Gerding et al., 2010).
Setting approach outlined work Vasirani Ossowski (2011),
follow metaphor model intersection manager provider resources,
case, reservations intersection manages. Thus, intersection manager
free establish price reservations provides. side market,
driver modelled buyer resources. Provided current prices
reservations, chooses route, according personal preferences travel
times monetary costs. intersection manager modelled compete
others supply reservations traded. Therefore, goal market
designers making intersection managers adapt prices towards price vector
accounts efficient allocation resources.
641

fiVasirani & Ossowski

5.1.1 CTA Pricing Strategy
Let L set incoming links generic intersection. incoming link l L,
intersection manager defines following variables:
Current price pt (l): price applied intersection manager reservations
sold drivers come incoming link l.
Total demand dt (l | pt (l)): represents total demand reservations
incoming link l intersection manager observes time t, given current
price pt (l). given number vehicles want cross intersection
coming link l time t.
Supply s(l): defines reservations supplied intersection manager
incoming link l. constant represents number vehicles cross
intersection coming link l intersection manager willing serve.
Excess demand z (l | pt (l)): difference total demand time
supply, z (l | pt (l)) = dt (l | pt (l)) s(l).
Given set intersection managers operating market, J ,
define price vector pt vector prices applied intersection manager
controlled links:
pt = [ pt1 (l1 ) pt1 (l2 ) . . . pt|J | (lh ) ]

(3)

p1 (l1 ) price applied intersection manager 1 controlled link l1 , p1 (l2 )
price applied intersection manager another link l2 intersection,
p|J | (lh ) price applied |J |th intersection manager last controlled link
lh .
particular, say price vector pt maps supply demand excess
demand z (l | pt (l)) 0 links network. price vector, corresponds
market equilibrium price, computed Walrasian auction (Codenotti,
Pemmaraju, & Varadarajan, 2004), buyer (i.e., driver) communicates
suppliers (i.e., intersection managers) route willing choose, given current
price vector pt . information, intersection manager computes demand
dt (l | pt (l)) well excess demand z (l | pt (l)) controlled links. Then,
intersection manager adjusts prices pt (l) incoming links, lowering
excess supply ( z (l | pt (l)) < 0 ) raising excess demand
( z (l | pt (l)) > 0 ). new price vector pt+1 communicated drivers
iteratively choose new desired route, basis new price vector pt+1 .
equilibrium price computed, trading transactions take place driver buys
required reservations intersections lay route.
Walrasian auction relies quite strict assumptions, make direct implementation traffic domain hard. instance, set buyers assumed fixed
auction, means traffic domain new drivers may join
auction terminates. Also fact transactions take place disequilibrium prices strict assumption traffic domain. unreasonable
642

fiA Market-Inspired Approach Intersection Management

Algorithm 2 Intersection manager price update
t0
l L
pt (l)
s(l) 0.5 opt $(l)
end
true
l L
dt (l) evaluateDemand
z (l) dt (l) s(l)
z (l)
pt (l) pt (l) + pt (l)
s(l)
end
tt+1
end
drivers wait reach equilibrium point choosing desired route starting
travel. Finally, driver probably willing transfer money intersection manager
spatially close it, is, already travelling along desired route.
Thus, implement pricing strategy aims reach equilibrium price -
Walrasian auction - works continuous basis, drivers leave
join market dynamically, transactions take place continuously. reach
general equilibrium, intersection manager applies price update strategy sketched
Algorithm 2. time t, intersection manager independently computes excess
demand z (l | pt (l)) updates price pt (l) using formula (Codenotti et al., 2004):
'
(
z (l | pt (l))
t+1


p (l) max , p (l) + p (l)
(4)
s(l)



minimum price intersection manager charges reservations
sells.
s(l) supply intersection manager, is, number vehicles
intersection manager considers excess demand starts raise
prices.
claim drivers travel road network links low demand shall
incur costs. reason, choose = 0. define supply s(l), rely
fundamental diagram traffic flow (Gerlough & Huber, 1975). Let opt density
maximises traffic flow link l (see Figure 10). choose s(l) = 0.5 opt $(l),
$(l) length link l. words, intersection manager considers
excess demand density reaches 50% optimal density. way
intersection manager aims avoid exceeding opt raising prices diverting drivers
different routes reaching opt .
643

fiVasirani & Ossowski

Trafc ow (veh/h)

opt

opt
Density (veh/km)

Figure 10: Fundamental diagram traffic flow
5.1.2 Driver Model
Unlike single intersection scenario, case need reasonable driver model
route choice. route choice problem modelled multi-attribute utility-functionmaximisation problem. Given traffic system regulated market mechanism,
driver must take consideration different aspects route determine utility
value. route modelled ordered list links, = [l1 . . . lN ]. generic link
lk characterised two attributes: estimated travel time E[T (lk )] price
reservations K(lk ). sake simplicity, estimation based travel time
free flow, consider real-time information traffic conditions (see Equation 5,
$(lk ) length link lk , vmax (lk ) maximum allowed speed link lk ).
price reservations link lk always 0, unless link lk one incoming link
intersection (lk = l), case price pt (l) (Equation 6).
E[T (lk )] =

K(l ) =
k

)

$(lk )
vmax (lk )

pt (l)
0

lk = l L
otherwise

(5)

(6)

summatory estimated travel time links gives estimated travel
time entire route :
E[T ()] =

N
*

E[T (lk )]

(7)

k=1

Similarly, summatory price reservations links gives price
entire route :
K() =

N
*
k=1

644

K(lk )

(8)

fiA Market-Inspired Approach Intersection Management

Let C = {1 , . . . , } choice set, is, set routes available driver.
set C built using k-shortest paths algorithm (Yen, 1971), k = 10. Let uT ()
normalised utility route estimated travel time attribute (Equation 9),
MT = max E[T (i )] mT = min E[T (i )].
C

C

uT () =

MT E[T ()]
MT mT

(9)

Let uK () normalised utility route reservations cost attribute (Equation 10), MK = max K(i ) mK = min K(i ).
C

C

uK () =

MK K()
MK mK

(10)

driver multi-attribute utility route defined as:
U () = wT uT () + wK uK ()

(11)

wT weight estimated travel time attribute wK weight
cost reservations attribute. Basically, wT = 1 driver utility considers
attribute related estimated travel time (i.e., prefers shortest route, matter
price reservations), wK = 1 driver utility considers attribute
related cost reservations (i.e., prefers cheapest route, matter travel
time), every combination weights wT wK driver considers
trade-off estimated travel time cost reservations. experiments
draw wT uniform distribution interval [0, 1], set wK = 1 wT .
utility routes form choice set C computed, driver
must choose one alternatives. work, model driver deterministic
utility maximiser always selects route highest utility value. Since
price incoming links intersection changing dynamically, term uK ()
Eq. 11 may change journey. reason, driver continuously evaluates
utility route following and, case different route becomes
attractive, may react change on-the-fly reach destination, selecting route
different original one.
5.1.3 Simulation Environment
experimental evaluation performed hybrid mesoscopic-microscopic simulator,
traffic flow roads modelled mesoscopic level (Schwerdtfeger, 1984),
traffic flow inside intersections modelled microscopic level (Nagel &
Schreckenberg, 1992).
mesoscopic model vehicle dynamics governed average traffic density
link traverses rather behaviour vehicles immediate neighbourhood
microscopic models. road network modelled graph, nodes represent
intersections edges represent lanes road. edge, also called stretch,
subdivided sections (of typically 500m length) constant traffic condition
assumed. vehicle time driving link lk characterised position
645

fiVasirani & Ossowski

xti [0, $(lk )], speed vit . time step, new target speed vehicle
computed, using formula:
v&it+t = (1

xti
xti
k
)

y(l
)
+
y(lk+1 )
$(lk )
$(lk )

(12)

y(lk ) reference speed link lk y(lk+1 ) reference speed link lk+1 .
reference speeds calculated taking consideration mean speed link
vehicles desired speed. mean speed link calculated speed-density
function given links density (lk ) returns links mean speed (Schwerdtfeger,
1984).
equation takes consideration fact closer vehicle
next link lk+1 , higher effect link reference speed vehicle target
speed. new target speed v&it+t higher (lower) current speed vit , vehicle
accelerates (decelerates) vehicle-type specific maximum acceleration (deceleration).
new speed denoted vit+t . Finally, vehicle position updated using
formula:
1
(vit + vit+t )
(13)
2
xt+t
$(lk ), vehicle placed next link route, densities link lk

lk+1 updated accordingly, position reset xt+t
$(lk ).

mesoscopic model described offer necessary level detail
model reservation-based intersection. reason, vehicle enters intersection, dynamics switches microscopic, cellular-based, simulator (Nagel & Schreckenberg, 1992), similar simulation environment used Section 4.2. Still, cells
compose intersections area coarse grained (5 meters), simplicity
assume vehicles cross intersection constant speed, additional
tuning parameters, slowdown probability acceleration/deceleration factors,
necessary.
xt+t
= xti +


5.1.4 Experimental Results
Although work depend underlying road network, chose (simplified)
topology entire urban road network city Madrid empirical evaluation
(see Figure 11). network characterised several freeways connect city
centre surroundings ring road. large dark vertex Figure 11 -
connects three links - modelled reservation-based intersection. aim
recreate typical high load situation (i.e., central, worst part morning peak),
11,000 vehicles departing within time window 50 minutes (see Table 2).
vehicles travel 7 destinations outside city (marked O1 O7
Figure 11) form traffic evaluation.
market-inspired traffic assignment strategy compared network FCFS
reservation-based intersections. latter, drivers route choice takes consideration expected travel time free flow, since notion price.
focus two different types metrics, one related vehicles one related
network. network-related metric density variation time 7 critical
646

fiA Market-Inspired Approach Intersection Management

Figure 11: Urban road network

Origin
O1
O2
O3
O4
O5
O6
O7

O1

O2

Destination
O3
O4
O5

O6

O7

223
300
208
199
290
224

323
364
233
228
316
231

355
221
229
261
398
214

349
214
368
199
238
253

271
229
362
204
209
337
-

336
248
343
216
386
235

311
191
358
218
374
219

Table 2: OD Matrix (# vehicles)
intersections (marked c1 . . . c7 Figure 11), connect freeways going toward
city centre ring road. vehicle-related metric average travel time,
grouped origin-destination (O-D) pair. given O-D pair, compute average
travel time vehicles go D. measurement averaged 30
runs. Furthermore, O-D pair compute improvement % CTA FCFS
based average travel times. Table 3 shows average travel time drivers,
according origin-destination pairs, reservations allocated
647

fiVasirani & Ossowski

competitive traffic assignment (CTA) granted usual FCFS
policy. Using CTA observe net reduction average travel time 30 42 origindestination pairs. reduction generally noteworthy busiest14 routes,
O6 -O2 , O6 -O3 O7 -O3 . Along less demanded O-D pairs, FCFS
best performing policy. happens preferred route
traffic density already low enough assure free flow, exist alternative routes
even lower demand, CTA keeps diverting traffic along potentially longer
thus slower routes.
evaluate effects trading activity drivers intersection managers
worth observing density variation time critical intersections c1 c7 ,
plotted Figure 12. general, density tends lower CTA compared
system regulated FCFS intersection managers. least demanded intersections c1 ,
c2 c7 , is, intersections whose density density maximises
traffic flow (see Figure 10), substantial difference CTA FCFS.
critical intersections less demanded due topology network. fact, fewer
origins located northern part (O1 , O2 O7 ).
critical intersections c3 , c4 c6 , vehicle density CTA always
density results use FCFS, especially case intersections c4
c6 CTA density exceeds optimal one small extent
limited period time.
intersection c5 , density higher peak around 9:30, density starts
exceed optimal density later begins fall optimal density earlier.
calculated integral density curves, measured interval curve
optimal density (Eq. 14)
+ t2
+ t2
CTA (t)dt
FCFS (t)dt
(14)
t1

t1

CTA FCFS density functions, t1 = min( | CTA (t) > opt , | FCFS (t) >
opt ) t2 = max( | CTA (t) < opt , | FCFS (t) > opt ). metric lower
reservations allocated competitive market (70.24 veh h/km versus
105.07 veh h/km).
result application market-inspired traffic assignment strategy
balanced urban network, since price fluctuations force demand change towards
less expensive intersections. fluctuations contribute creating system dynamic
equilibrium, unused intersections became cheaper congested ones became
expensive. effect average travel time decreases, although guarantees
drivers pay rewarded lower travel times.

14. empirically noticed experiments southern part network tends
congested simulation. due fact 4 7 origins/destinations (O3 , O4 , O5 ,
O6 ) located southern part.

648

fiA Market-Inspired Approach Intersection Management

Origin
CTA
O1 FCFS
%
CTA
O2 FCFS
%
CTA
O3 FCFS
%
CTA
O4 FCFS
%
CTA
O5 FCFS
%
CTA
O6 FCFS
%
CTA
O7 FCFS
%

Destination
O4
O5

O1

O2

O3

-

12.09
0.27
11.98
0.31
-0.8%

19.58
0.80
22.89
1.17
14.4%
14.17
0.72
16.50
1.06
14.1%

11.26
0.17
10.15
0.06
-11.0%
15.57
0.33
13.35
0.09
-16.7%
24.79
0.77
26.94
1.31
8.0%
26.80
0.84
32.17
1.83
16.7%
23.17
0.50
22.51
0.40
-2.9%
15.05
0.22
14.31
0.10
-5.2%

10.79
0.14
9.76
0.03
-10.6%
20.39
0.60
22.58
1.06
9.7%
22.83
0.71
30.61
1.70
25.4%
27.31
0.55
57.01
3.13
52.1%
23.52
0.33
23.26
0.40
-1.1%

11.62
0.41
13.92
0.82
16.5%
16.30
0.67
21.54
1.39
24.3%
25.30
0.89
41.05
2.59
38.4%
31.67
0.82
56.42
3.01
43.9%

26.70
1.04
35.13
1.80
24.0%
19.02
0.66
25.87
1.51
26.5%
9.18
0.08
12.21
0.62
24.8%
7.47
0.20
8.83
0.31
15.4%
16.40
0.73
24.68
1.62
33.6%
24.44
0.97
34.99
2.15
30.2%

30.75
0.83
43.57
1.89
29.4%
23.72
0.83
31.05
2.03
23.6%
13.99
0.37
17.64
0.92
20.7%
8.21
0.27
10.05
0.48
18.3%
12.12
0.46
19.02
1.50
36.3%
19.12
0.69
31.24
2.06
38.8%

O6

O7

21.17
0.20
21.35
0.40
0.8%
24.00
0.40
38.09
1.82
37.0%
18.54
0.32
23.69
6.34
21.7%
14.35
0.48
15.74
0.73
8.8%
11.11
0.24
10.77
0.26
-3.1%

14.13
0.12
13.83
0.09
-2.2%
20.88
0.23
19.51
0.15
-7.0%
24.95
0.42
31.73
1.36
21.4%
21.66
0.75
22.74
0.99
4.8%
19.47
0.63
17.66
0.52
-10.3%
16.58
0.89
13.73
0.32
-20.8%

11.69
0.11
12.00
0.20
2.5%

-

Table 3: Average travel time minutes ( 95%CI): CTA vs. FCFS

649

fiVasirani & Ossowski

FCFS
CTA
Optimum

14
12
10
8
6
4
2

FCFS
CTA
Optimum

20

Density (veh/km)

Density (veh/km)

16

0

15

10

5

0

08:00:00

09:00:00

10:00:00

11:00:00

08:00:00

FCFS
CTA
Optimum

40

10:00:00

30

20

10

50

0

11:00:00

FCFS
CTA
Optimum

40

30

20

10

0
08:00

09:00

10:00

11:00

08:00:00

Time
(c) Intersection c3

09:00:00

10:00:00

11:00:00

Time
(d) Intersection c4

40
30
20
10

FCFS
CTA
Optimum

40

Density (veh/km)

FCFS
CTA
Optimum

50

Density (veh/km)

09:00:00

Time
(b) Intersection c2

Density (veh/km)

Density (veh/km)

Time
(a) Intersection c1

0

30

20

10

0
08:00

09:00

10:00

11:00

08:00

Time
(e) Intersection c5

10:00

11:00

Time
(f) Intersection c6

16

Density (veh/km)

09:00

FCFS
CTA
Optimum

14
12
10
8
6
4
2
0
08:00

09:00

10:00

11:00

Time
(g) Intersection c7

Figure 12: Density variation time critical intersections evaluation
650

fiA Market-Inspired Approach Intersection Management

5.2 Integrated Mechanism Traffic Management (CA-CTA)
Section 4.1, introduced auction-based policy control single intersection.
experimental results showed policy quite effective allocating reservations drivers value most. Drivers bid high usually experience
great reduction delay (about 30%), compared drivers submit low-value
bids. However, policy showed couple drawbacks. First, fosters
attainment user optimum rather global one. therefore pays social price,
form greater average delay entire population drivers. Furthermore,
possible even wealthy drivers, high-load situations, could get reservation,
example due decreasing reservation distance.
hand, one results experimental evaluation Section 5.1
traffic assignment strategy make task traffic controllers easier, enforcing
better distribution traffic demand. Therefore, seems reasonable combine
auction-based policy competitive traffic assignment strategy integrated,
market-inspired, mechanism traffic management.
5.2.1 CA-CTA Mechanism
adapt competitive traffic assignment strategy (CTA) combine auctionbased policy (CA) integrated mechanism traffic management (CA-CTA). Since
intersection manager supplier reservations allocated
combinatorial auction, may control reserve price auctioned reservations, i.e.,
minimum price intersection manager willing sell. model
intersection managers way compete provision reservations
drivers, raising reserve price case increasing demand lowering case
decreasing demand. reservations allocated CA policy defined
Section 4.1. However, bids whose value reserve price accepted
bid set.
incoming link l generic intersection, intersection manager independently
computes excess demand z (l | ptr (l)) updates reserve price ptr (l) using
formula:
'
(
z (l | ptr (l))
t+1


pr (l) max r , pr (l) + pr (l)
(15)
s(l)

r minimum reserve price, s(l) number vehicles intersection
manager willing serve. Section 5.1, choose r = 0 s(l) = 0.5 opt $(l),
$(l) length link l, opt density maximises traffic flow
link l (see Figure 10).
5.2.2 Driver Model

empirically evaluate CA-CTA need define driver route choice model takes
consideration fact reservations allocated combinatorial
auction reserve price. assume driver holds private valuation
bids willing submit pass intersections chosen route, defined
variable b. Given monetary constraint, driver selects preferred route
651

fiVasirani & Ossowski

, taking consideration estimated travel time associated route. route
modelled ordered list links, = [l1 . . . lN ], characterised
two attributes, namely estimated travel time reserve price.
travel time estimation based, before, travel time free flow (Equation 5). reserve price link defined as:
)
pr (l)
lk = l L
(16)
K(lk ) =
0
otherwise
price link lk always 0, unless link lk one incoming link intersection
(lk = l), case price equal reserve price ptr (l) established
intersection manager. summatory travel time links gives
estimated travel time free flow entire route :
E[T ()] =

N
*

E[T (lk )]

(17)

k=1

Given b, driver builds choice-set C set routes whose intersections
reserve price lower desired bid b:
,
C = 1 , . . . , | K(lk ) b lk

choice-set built, driver selects shortest route = argmin E[T (i )].
C

5.2.3 Experimental Results
recreate typical high load situation, using network topology OD
matrix Figure 11 Table 2. interested two different types properties.
one side must evaluate whether integrated management mechanism (traffic
control+traffic assignment) guarantees lower delays drivers submit higher bids
(user optimum). purpose, calculate average (percentage) increase
travel times D, calculated according Equation 18, (i ) observed travel
time vehicle origin destination along route , mT travel time
origin destination along shortest route vehicle could
cross intersection unhindered15 . simplicity, refer percentage increase
travel time normalised delay.
D=

(i ) mT
mT

(18)

hand, would like set system fair entire population
drivers, guaranteeing lower average delays (global optimum). Thus, compare
integrated mechanism network intersections governed intersection managers
apply FCFS control policy. assume case drivers choose
shortest route origin destination, since incentives
15. ratio enables us aggregate results drivers even though different origins and/or
destinations.

652

fiA Market-Inspired Approach Intersection Management

140%

Moving avg (min)

Normalised delay

25
114.30%

110%

80%

67.12%

73.31%

50%

58.10%

20%

0-50

50-100

100-150

150-200

FCFS
CA-CTA
CTA

20

15

10

5

0%

Bid (cents)

20%

40%

60%

80%

100%

Percentage completed trips

(a)

(b)

Figure 13: Relation normalised delay bid (a) moving average travel
time (b)
diverge route. aim evaluate global performance (in terms average
travel time) integrated mechanism compared straightforward application
FCFS policy network intersections, detect potential social cost similar
reported Section 4.3. metrics use assess performance
average delay every O-D pair, moving average travel time. latter
intended measure average travel time evolves simulation.
metric initialised 0 calculated follows: driver concludes trip,
travel time (i ) computed moving average travel time updated according
Equation 19, n number drivers completed trips far.
(i )
(19)
n+1
following tables figures refer two configurations abbreviations
CA-CTA (which stands combinatorial auction-competitive traffic assignment)
FCFS.
Figure 13a plots relation bid value normalised delay population
drivers16 . still possible appreciate inverse relation two quantities: drivers submit bids 150 200 cents reduce delay
50% compared bid less 50 cents. Also network level, granting
reservations combinatorial auction (the CA component CA-CTA policy)
ensures drivers submit higher bids experience lower delays (user optimum).
assess social cost incurred CA-CTA global level, measure moving
average travel time, is, average travel time entire population
drivers, computed O-D pairs, evolves simulation. compare CACTA FCFS and, completeness, CTA17 . results, 95% confidence
=T +

16. error bars denote 95% confidence intervals.
17. order evaluate CA-CTA CTA experimental conditions ran new set
experiments using CTA combination driver model detailed Section 5.2.2.

653

fiVasirani & Ossowski

Origin
CA-CTA
O1 FCFS
%
CA-CTA
O2 FCFS
%
CA-CTA
O3 FCFS
%
CA-CTA
O4 FCFS
%
CA-CTA
O5 FCFS
%
CA-CTA
O6 FCFS
%
CA-CTA
O7 FCFS
%

Destination
O4
O5

O1

O2

O3

-

12.22
0.26
11.98
0.31
-2.0%
-

13.65
0.31
22.89
1.17
40.3%
10.51
0.14
16.50
1.06
36.4%
-

12.16
0.21
10.15
0.06
-19.8%
15.05
0.69
13.35
0.09
-12.7%
20.79
1.23
26.94
1.31
22.8%
24.59
1.10
32.17
1.83
23.6%
25.08
1.53
22.51
0.40
-11.4%
15.73
0.32
14.31
0.10
-9.9%

12.51
0.62
9.76
0.03
-28.2%
18.45
0.93
22.58
1.06
18.3%
20.82
1.26
30.61
1.70
32.0%
26.72
0.40
57.01
3.13
53.1%
24.18
0.52
23.26
0.40
-3.9%

10.52
0.41
13.92
0.82
24.4%
12.62
0.63
21.54
1.39
41.4%
18.12
1.26
41.05
2.59
55.8%
22.12
2.28
56.42
3.01
60.8%

25.12
3.40
35.13
1.80
28.5%
19.58
1.38
25.87
1.51
24.3%
9.01
0.22
12.21
0.62
26.2%
7.91
0.48
8.83
0.31
10.4%
15.78
1.35
24.68
1.62
36.1%
26.86
2.59
34.99
2.15
23.2%

27.13
2.03
43.57
1.89
37.7%
24.17
1.74
31.05
2.03
22.1%
13.27
0.46
17.64
0.92
24.8%
7.32
0.15
10.05
0.48
27.2%
10.85
0.28
19.02
1.50
42.9%
16.81
0.99
31.24
2.06
46.2%

O6

O7

23.13
0.34
21.35
0.40
-8.3%
26.54
0.67
38.09
1.82
30.3%
18.72
0.68
23.69
6.34
21%
13.02
1.02
15.74
0.73
17.3%
10.01
0.28
10.77
0.26
7.0%
-

13.75
0.11
13.83
0.09
0.5%
22.21
0.37
19.51
0.15
-13.8%
26.76
1.02
31.73
1.36
15.7%
23.12
1.53
22.74
0.99
-1.7%
21.88
1.41
17.66
0.52
-23.9%
14.55
0.69
13.73
0.32
-6.0%
-

11.43
0.29
12.00
0.20
4.7%

-

Table 4: Average travel time minutes ( 95%CI): CA-CTA vs. FCFS
interval error bars, plotted Figure 13b. beginning, average travel time
similar scenarios, number drivers populate network
(i.e., load) increases, grows significantly faster FCFS CA-CTA
policy. terms average travel times CTA best performing policy. CA-CTA
slightly inferior performance, enforce inverse relationship bid value
delay (see Figure 13a). fact CA-CTA CTA outperforms FCFS
indication that, general, traffic assignment strategy (the CTA component
policies) improves travel time. fact, FCFS drivers always select shortest
654

fiA Market-Inspired Approach Intersection Management

route, cases best route choice. Furthermore, granting reservations
auction (the CA component CA-CTA policy) ensures bid value
delay reduction correlated.
Table 4 shows average travel time drivers, according O-D pairs,
intersection managers use CA-CTA mechanism, compared FCFS policy.
CA-CTA, net reduction average travel time 70%
O-D pairs compared FCFS. Furthermore, 30 intersections CA-CTA
outperforms FCFS, relative improvement (%) usually substantial
relative losses remaining 12 intersections. travel time reduction particularly
noteworthy busy routes O6 -O2 , O6 -O3 O7 -O3 gains exceed 50%.
O-D pairs CA-CTA performs worst (especially O5 -O7 O3 -O2 , losses
20%) assignment strategy able sufficiently reduce demand
intersection, thus considerably increasing travel time due social cost
combinatorial auction.

6. Conclusions
article studied distributed mechanism control management
future urban road network, intelligent autonomous vehicles, controlled drivers,
interact infrastructure order travel links network. last
section summarise discuss main contributions, propose future lines
work.
first objective extension reservation-based intersection control system (Dresner & Stone, 2008). focused modelling policy relied theory
combinatorial auctions (Krishna, 2002) allocate reservations drivers. empirical experimentation, discovered combinatorial auction-based policy guarantees
reduced delay drivers value time most, i.e., submit higher
bids. However, new policy showed paid social cost, term greater average
delays, especially traffic demand high.
second objective work go beyond single intersection setting,
extending reservation-based model network intersections. Building findings
reported Vasirani Ossowski (2011), realised traffic assignment strategy
could make task traffic control policy easier, better distributing traffic flow
network. studied market-inspired traffic assignment strategy tackled
problem adaptation perspective. model, intersection managers behaved
selfishly, competing others supply reservations intersections.
experimental evaluation showed way available resources efficiently
allocated drivers, generating balanced network.
Finally, combined competitive strategy traffic assignment auctionbased policy traffic control, order develop adaptive, market-inspired, mechanism
traffic management. demand-response pricing policy acted distribution
vehicles network, adapting reserve price (i.e., minimum price
intersection manager willing sell) generating system dynamic equilibrium,
unused intersections became cheaper highly demanded ones became expensive. demand particularly disputed intersections lowered reserve price
655

fiVasirani & Ossowski

fluctuations, social cost auction-based control policy lowered (at intersection level). Therefore, homogeneous distribution vehicles network led
better use network resources, thus lower average travel times. way,
entire population drivers rewarded lower average travel times and,
time, traffic control policy enforced inverse relation bid value delay,
rewarding drivers valued reservations reduced delays.
future work, economic models implemented, continuous double
auctions. Furthermore, work assumed driver decision making model exclusively
took consideration route choice, modelled utility maximisation
problem. order capture inherent complexity urban traffic systems, important
extend enrich driver behavioural model. example, driver could
implemented two layer decision maker, reactive, rule-based layer provides
short-term decisions car-following lane-changing, cognitive, BDI-style,
layer charge making complex decisions route choice departure
time selection (Rossetti, Bampi, Liu, Vliet, & Cybis, 2000).
Finally, article interactions vehicles infrastructure take
place. Thus, collaboration possible vehicles. Nevertheless, vehicle-tovehicle communication receiving great attention scientific engineering community (Biswas, Tatchikou, & Dion, 2006). particular, vehicle-to-vehicle communication
could used enrich action space driver, e.g. option dynamically
joining abandoning coalitions vehicles, based idea platoons (Varaiya, 1993).

Acknowledgments
research partially supported Spanish Ministry Science Innovation
project (CONSOLIDER CSD2007-0022, INGENIO 2010) OVAMAH
(TIN2009-13839-C03-02, Plan E).

References
Adler, J. L., Satapathy, G., Manikonda, V., Bowles, B., & Blue, V. J. (2005). multiagent approach cooperative traffic management route guidance. Transportation
Research Part B - Methodological, 39, 297318.
Bazzan, A. L. C., & Klugl, F. (Eds.). (2008). Multi-agent Architectures Traffic
Transportation Engineering. IGI-Global.
Biswas, S., Tatchikou, R., & Dion, F. (2006). Vehicle-to-vehicle wireless communication protocols enhancing highway traffic safety. IEEE Communications Magazine, 44 (1),
7482.
Choy, M. C., Srinivasan, D., & Cheu, R. L. (2003). Cooperative, hybrid agent architecture
real-time traffic control. IEEE Transactions Systems, Man, Cybernetics Part A, 33 (5), 597607.
Clarke, E. H. (1971). Multipart pricing public goods. Public Choice, 11 (1), 1733.
656

fiA Market-Inspired Approach Intersection Management

Codenotti, B., Pemmaraju, S., & Varadarajan, K. (2004). computation market
equilibria. SIGACT News, 35 (4), 2337.
da Silva, B. C., Basso, E. W., Bazzan, A. L. C., & Engel, P. M. (2006). Dealing
non-stationary environments using context detection. Proceedings 23rd International Conference Machine Learning, pp. 217224. ACM.
Dias, M. B., Zlot, R. M., Kalra, N., & Stentz, A. (2006). Market-based multirobot coordination: survey analysis. Proceedings IEEE, 94 (7), 12571270.
Dresner, K., & Stone, P. (2008). multiagent approach autonomous intersection management. Journal Artificial Intelligence Research, 31, 591656.
Gerding, E., McBurney, P., & Yao, X. (2010). Market-based control computational
systems: Introduction special issue. Journal Autonomous Agents MultiAgent Systems, 21, 109114.
Gerlough, D. L., & Huber, M. J. (1975). Traffic-flow theory. Transportation Research
Board.
Gershenson, C. (2005). Self-organizing traffic lights. Complex Systems, 16, 2953.
Groves, T. (1973). Incentives teams. Econometrica, 41 (4), 617631.
Hensher, D. A., & Sullivan, C. (2003). Willingness pay road curviness road type.
Transportation Research Part - Transport Environment, 8, 139155.
Hernandez, J. Z., Ossowski, S., & Garca-Serrano, A. (2002). Multiagent architectures
intelligent traffic management systems. Transportation Research Part C - Emerging
Technologies, 10 (5), 473506.
Hoos, H. H., & Boutilier, C. (2000). Solving combinatorial auctions using stochastic local
search. Proceedings 17th National Conference Artificial Intelligence, pp.
2229. AAAI Press.
Hunt, P. B., Robertson, D. I., Bretherton, R. D., & Winton, R. I. (1981). Scoot-a traffic responsive method coordinating signals. Tech. rep., TRRL Lab. Report 1014,
Transport Road Research Laboratory, Berkshire.
Ioannou, P., & Chien, C. C. (1993). Autonomous intelligent cruise control. IEEE Transactions Vehicular Technology, 42 (4), 657672.
Junges, R., & Bazzan, A. L. C. (2008). Evaluating performance dcop algorithms
real world, dynamic problem. Proceedings 7th International Joint Conference Autonomous Agents Multi-Agent Systems, pp. 599606. International
Foundation Autonomous Agents Multiagent Systems.
Krishna, V. (2002). Auction Theory. Academic Press.
Krogh, B., & Thorpe, C. (1986). Integrated path planning dynamic steering control
autonomous vehicles. Proceedings IEEE International Conference
Robotics Automation, pp. 16641669.
Lammer, S., & Helbing, D. (2008). Self-control traffic lights vehicle flows urban
road networks. Journal Statistical Mechanics: Theory Experiment, 2008 (04).
657

fiVasirani & Ossowski

Leyton-Brown, K., Shoham, Y., & Tennenholtz, M. (2000). algorithm multi-unit
combinatorial auctions. Proceedings 17th National Conference Artificial
Intelligence, pp. 5661. AAAI Press.
Meneguzzer, C. (1997). Review models combining traffic assignment signal control.
Transportation Engineering, 123 (2), 148155.
Nagel, K., & Schreckenberg, M. (1992). cellular automaton model freeway traffic.
Journal de Physique I, 2 (12), 22212229.
Ossowski, S., & Garca-Serrano, A. (1999). Social structure computational co-ordination
mechanism societies autonomous problem-solving agents. Intelligent Agents
V: Agents Theories, Architectures, Languages, Vol. 1555 Lecture Notes Computer Science, pp. 133148. Springer.
Papageorgiou, M., Diakaki, C., Dinopoulou, V., Kotsialos, A., & Wang, Y. (2003). Review
road traffic control strategies. Proceedings IEEE, Vol. 91, pp. 20432067.
IEEE.
Robertson, D. I. (1969). Transyt: traffic network study tool. Tech. rep., Rep. LR 253,
Road Res. Lab., London.
Rossetti, R. J. F., Bampi, S., Liu, R., Vliet, D. V., & Cybis, H. B. B. (2000). agent-based
framework assessment drivers decision making. Proceedings 3rd
IEEE Conference Intelligent Transportation Systems, pp. 387392.
Roughgarden, T. (2003). price anarchy independent network topology.
Journal Computer System Sciences, 67 (2), 341364.
Sandholm, T. (2002). Algorithm optimal winner determination combinatorial auctions. Artificial Intelligence, 135 (1-2), 154.
Schepperle, H., & Bohm, K. (2007). Agent-based traffic control using auctions. Cooperative Information Agents XI, Vol. 4676 Lecture Notes Computer Science, pp.
119133. Springer.
Schwerdtfeger, T. (1984). Dynemo: model simulation traffic flow motorway
networks. Proceedings 9th International Symposium Transportation
Traffic Theory, pp. 6587. VNU Science Press.
Small, K., & Verhoef, E. (2007). Economics Urban Transportation. Routledge.
Steingrover, M., Schouten, R., Peelen, S., Nijhuis, E., & Bakker, B. (2005). Reinforcement
learning traffic light controllers adapting traffic congestion. Proceedings
17th Belgium-Netherlands Conference Artificial Intelligence, pp. 216223.
Treiber, M., Hennecke, A., & Helbing, D. (2000). Congested traffic states empirical
observations microscopic simulations. Physical Review E, 62 (2), 18051824.
van Katwijk, R. T., Schutter, B. D., & Hellendoorn, J. (2009). Multi-agent control traffic
networks: Algorithm case study. Proceedings 12th International IEEE
Conference Intelligent Transportation Systems, pp. 316321.
Varaiya, P. (1993). Smart cars smart roads: Problems control. IEEE Transactions
Automatic Control, 38, 195207.
658

fiA Market-Inspired Approach Intersection Management

Vasirani, M., & Ossowski, S. (2009a). Evaluating policies reservation-based intersection
control. Proceedings 14th Portuguese Conference Artificial Intelligence,
pp. 3950.
Vasirani, M., & Ossowski, S. (2009b). market-inspired approach reservation-based urban road traffic management. Proceedings 8th International Joint Conference
Autonomous Agents Multiagent Systems, pp. 617624.
Vasirani, M., & Ossowski, S. (2011). computational market distributed control
urban road traffic systems. IEEE Transactions Intelligent Transportation Systems,
12, 313321.
Vickrey, W. (1961). Counterspeculation, auctions, competitive sealed tenders. Journal
Finance, 16, 837.
Wiering, M. (2000). Multi-agent reinforcement learning traffic light control. Proceedings 17th European Conference Machine Learning, pp. 11511158.
Wurman, P. R., Wellman, M. P., & Walsh, W. E. (2001). parametrization auction
design space. Games Economic Behavior, 35 (1-2), 304338.
Yen, J. Y. (1971). Finding k shortest loopless paths network. Management Science,
17 (11), 712716.
Zutt, J., van Gemund, A., de Weerdt, M., & Witteveen, C. (2010). Dealing uncertainty operational transport planning. Intelligent Infrastructures, pp. 349375.
Springer.

659

fiJournal Artificial Intelligence Research 43 (2012) 329-351

Submitted 11/11; published 03/12

Local Consistency SAT-Solvers
Peter Jeavons
Justyna Petke

Peter.Jeavons@cs.ox.ac.uk
Justyna.Petke@cs.ox.ac.uk

Department Computer Science, University Oxford
Wolfson Building, Parks Road, Oxford, OX1 3QD, UK

Abstract
Local consistency techniques k-consistency key component specialised
solvers constraint satisfaction problems. paper show power
using k-consistency techniques constraint satisfaction problem precisely captured
using particular inference rule, call negative-hyper-resolution, standard
direct encoding problem Boolean clauses. also show current clauselearning SAT-solvers discover expected polynomial time inconsistency
deduced given set clauses using negative-hyper-resolvents fixed size.
combine two results show that, without explicitly designed so, current
clause-learning SAT-solvers efficiently simulate k-consistency techniques, fixed values
k. give experimental results show feature allows clause-learning
SAT-solvers efficiently solve certain families constraint problems challenging
conventional constraint-programming solvers.

1. Introduction
One oldest central ideas constraint programming, going right back
Montanaris original paper 1974, idea using local consistency techniques prune
search space (Bessiere, 2006). idea arc-consistency introduced Mackworth
(1977), generalised k-consistency Freuder (1978). Modern constraint solvers
generally employ specialised propagators prune domains variables achieve
form generalised arc-consistency, typically attempt enforce higher levels
consistency, path-consistency.
contrast, software tools developed solve propositional satisfiability problems,
known SAT-solvers, generally use logical inference techniques, unit propagation
clause-learning, prune search space.
One surprising empirical findings last years remarkably good performance general SAT-solvers solving constraint satisfaction problems.
apply tools constraint satisfaction problem one first translate instance set clauses using form Boolean encoding (Tamura, Taga, Kitagawa,
& Banbara, 2009; Walsh, 2000). encoding techniques tend obscure structure original problem, may introduce large number Boolean variables
clauses encode quite easily-stated constraints. Nevertheless, quite cases,
approaches out-performed traditional constraint-solving tools (van Dongen,
Lecoutre, & Roussel, 2008, 2009; Petke & Jeavons, 2009).
c
2012
AI Access Foundation. rights reserved.

fiJeavons & Petke

paper draw number recent analytical approaches try account
good performance general SAT-solvers many forms constraint problems.
Building results Atserias, Bulatov, Dalmau (2007), Atserias Dalmau
(2008), Hwang Mitchell (2005), show power using k-consistency
techniques constraint problem precisely captured using single inference rule
standard Boolean encoding problem. refer inference rule negativehyper-resolution, show conclusions deduced enforcing k-consistency
deduced sequence negative-hyper-resolution inferences involving Boolean clauses
original instance negative-hyper-resolvents k literals. Furthermore,
using approach Atserias, Fichte, Thurley (2011), Pipatsrisawat
Darwiche (2009), show current clause-learning SAT-solvers mimic effect
deductions polynomial expected time, even random branching strategy. Hence
show that, although explicitly designed so, running clause-learning
SAT-solver straightforward encoding constraint problem efficiently simulates
effects enforcing k-consistency values k.

2. Preliminaries
section give background definitions used throughout
rest paper.
2.1 Constraint Satisfaction Problems k-Consistency
Definition 1 instance Constraint Satisfaction Problem (CSP) specified
triple (V, D, C),
V finite set variables;
= {Dv | v V } set Dv set possible values variable v,
called domain v;
C finite set constraints. constraint C pair (Ri , Si )
Si ordered list mi variables, called constraint scope;
Ri relation arity mi , called constraint relation.
Given CSP instance (V, D, C), partial assignment mapping f

subset W V Dv f (v) Dv v W . partial assignment satisfies
constraints instance if, (R, (v1 , v2 , . . . , vm )) C vj W
j = 1, 2, . . . , m, (f (v1 ), f (v2 ) . . . , f (vm )) R. partial assignment satisfies
constraints instance called partial solution1 instance. set
variables partial assignment f defined called domain f , denoted
Dom(f ). partial solution g extends partial solution f Dom(g) Dom(f )
g(v) = f (v) v Dom(f ). partial solution domain V called solution.
One way derive new information CSP instance, may help determine
whether solution, use form constraint propagation enforce
1. Note partial solutions extend solutions.

330

fiLocal Consistency SAT-Solvers

level local consistency (Bessiere, 2006). example, possible use notion
k-consistency, defined below. note several different equivalent ways
define enforce k-consistency described literature (Bessiere, 2006; Cooper, 1989;
Freuder, 1978). presentation follows Atserias et al. (2007), inspired
notion existential k-pebble games introduced Kolaitis Vardi (2000).
Definition 2 (Atserias et al., 2007) CSP instance P , k-consistency closure
P set H partial assignments obtained following algorithm:
1. Let H collection partial solutions f P |Dom(f )| k + 1;
2. every f H |Dom(f )| k every variable v P , g H
g extends f v Dom(g), remove f extensions H;
3. Repeat step 2 H unchanged.
Note computing k-consistency closure according definition corresponds
precisely enforcing strong (k+1)-consistency according definitions given Bessiere
(2006), Cooper (1989), Freuder (1978).
Throughout paper, shall assume domain possible values
variable CSP instance finite. straightforward show fixed k,
fixed maximum domain size, k-consistency closure instance P
computed polynomial time (Atserias et al., 2007; Cooper, 1989).
Note solution P must extend element k-consistency closure
P . Hence, k-consistency closure P empty, k, P solutions.
converse true general, holds certain special cases, class
instances whose structure tree-width bounded k (Atserias et al., 2007), class
instances whose constraint relations 0/1/all relations, defined Cooper, Cohen,
Jeavons (1994), connected row-convex relations, defined Deville, Barette,
Hentenryck (1997). special kinds instances possible determine
polynomial time whether solution exists simply computing k-consistency
closure, appropriate choice k. Moreover, solution exists,
constructed polynomial time selecting variable turn, assigning possible
value, re-computing k-consistency closure, retaining assignment gives
non-empty result.
following result gives useful condition determining whether k-consistency
closure CSP instance empty.
Lemma 1 (Kolaitis & Vardi, 2000) k-consistency closure CSP instance P
non-empty exists non-empty family H partial solutions P
that:
1. f H, |Dom(f )| k + 1;
2. f H f extends g, g H;
3. f H, |Dom(f )| k, v
/ Dom(f ) variable P ,
g H g extends f v Dom(g).
set partial solutions H satisfying conditions described Lemma 1 sometimes
called strategy instance P (Barto & Kozik, 2009; Kolaitis & Vardi, 2000).
331

fiJeavons & Petke

2.2 Encoding CSP Instance Propositional Formula
One possible approach solving CSP instance encode propositional formula
suitable set Boolean variables, use program decide satisfiability
formula. Many programs, known SAT-solvers, available
often efficiently handle problems thousands, sometimes even millions, Boolean
variables (Zhang & Malik, 2002).
Several different ways encoding CSP instance propositional formula
proposed (Prestwich, 2009; Tamura et al., 2009; Walsh, 2000).
consider one common family encodings, known sparse encodings (this term
introduced Hoos, 1999). CSP instance P = (V, D, C), sparse encoding
introduces set Boolean variables form xvi v V Dv .
Boolean variable xvi assigned True original variable v assigned
value i. say partial assignment f falsifies clause C C consists entirely
literals form xvf (v) , variables v Dom(f ). Otherwise, say partial
assignment f satisfies clause C.
Example 1 Let P CSP instance V = {u, v, w}, Du = Dv = {0, 1}, Dw =
{0, 1, 2} C contains single ternary constraint scope (u, v, w) specifying
u v < w. sparse encoding P introduce seven Boolean variables:
xu0 , xu1 , xv0 , xv1 , xw0 , xw1 , xw2 .
Sparse encodings usually contain certain clauses known at-least-one at-most-one
clauses, ensure variable v assigned value, say i, value,
W
j 6= i, assigned v. at-least-one clauses form iDv xvi variable
v. at-most-one clauses represented set binary clauses xvi xvj
i, j Dv 6= j.
Example 2 case CSP instance Example 1 at-least-one clauses are:
xu0 xu1 , xv0 xv1 , xw0 xw1 xw2
at-most-one clauses are:
xu0 xu1 , xv0 xv1 , xw0 xw1 , xw0 xw2 , xw1 xw2
various different sparse encodings differ way encode constraints
CSP instance. Two methods commonly used. first one encodes disallowed
variable assignments - so-called conflicts no-goods. direct encoding (Prestwich,
W
2009), instance, generates clause vS xvf (v) partial assignment f
satisfy constraint (R, S) C. Using direct encoding, ternary constraint
Example 1 would encoded following clauses:
xu0 xv0 xw0 ,
xu0 xv1 xw0 ,
xu0 xv1 xw1 ,
xu1 xv0 xw0 ,
332

fiLocal Consistency SAT-Solvers

xu1 xv0 xw1 ,
xu1 xv0 xw2 ,
xu1 xv1 xw0 ,
xu1 xv1 xw1 .
Another way translating constraints clauses encode allowed variable
assignments - so-called supports. used basis encoding
binary CSP instances, known support encoding (Gent, 2002), defined follows.
pair variables v, w scope constraint, value Dv ,
W
support encoding contain clause xvi jA xwj , Dw set
values variable w compatible assignment v = i, according
constraint.
Note support encoding defined binary CSP instances only. However,
non-binary constraints decomposed binary ones without introducing new
variables. instance, ternary constraint Example 1 decomposed two
binary constraints specifying u v v < w. Using support encoding,
binary constraints would represented following clauses:
xu0 xv0 xv1 , xu1 xv1 , xv0 xu0 , xv1 xu0 xu1 ,
xv0 xw1 xw2 , xv1 xw2 , xw0 , xw1 xv0 , xw2 xv0 xv1 .
2.3 Inference Rules
Given set clauses often deduce clauses applying certain inference
rules. example, two clauses form C1 x C2 x, (possibly
empty) clauses C1 , C2 , variable x, deduce clause C1 C2 .
form inference known propositional resolution; resultant clause called
resolvent (Robinson, 1965).
next section, shall establish close connection k-consistency
algorithm form inference called negative-hyper-resolution (Buning & Lettmann,
1999), define follows:
Definition 3 collection clauses form Ci xi , = 1, 2, . . . , r,
clause C0 x1 x2 xr , xi Boolean variable, C0
Ci (possibly empty) disjunction negative literals, deduce clause
C0 C1 Cr .
call form inference negative-hyper-resolution resultant clause
C0 C1 Cr negative-hyper-resolvent.
case C0 empty, negative-hyper-resolution rule equivalent
nogood resolution rule described Hwang Mitchell (2005) well H5-k rule
introduced de Kleer (1989) nogood recording scheme described Schiex
Verfaillie (1993).
Note inference obtained negative-hyper-resolution also obtained
sequence standard resolution steps. However, reason introducing negative-hyperresolution allows us deduce clauses need single step without needing
introduce intermediate clauses (which may contain r 1 literals
333

fiJeavons & Petke

negative-hyper-resolvent). restricting size clauses use way
able obtain better performance bounds SAT-solvers results below.
Example 3 Assume collection clauses form Ci xi , = 1, 2, . . . , r,
clause C0 x1 x2 xr , specified Definition 3, Ci = C0 .
negative-hyper-resolvent set clauses C0 .
clause C0 also obtained sequence standard resolution steps, follows.
First resolve C0 x1 x2 xr C0 xr obtain C0 x1 x2 xr1 .
resolve next clause, C0 xr1 , clauses, finally
obtain C0 . However, case intermediate clause C0 x1 x2 xr1 contains
r 1 literals negative-hyper-resolvent.
Example 4 Note no-good clauses direct encoding binary CSP instance
obtained single negative-hyper-resolution step appropriate support
clause support encoding together appropriate collection at-most-one clauses.
Let Dw set values variable w compatible assignment
W
v = i, support encoding contain clause C = xvi jA xwj .
values k Dw incompatible assignment v = i, form
negative-hyper-resolvent C at-most-one clauses xwk xwj j A,
obtain corresponding no-good clause, xvi xwk .
negative-hyper-resolution derivation clause C set initial clauses
sequence clauses C1 , C2 , . . . , Cm , Cm = C Ci follows negativehyper-resolution rule collection clauses, either contained
else occurs earlier sequence. width derivation defined
maximum size clauses Ci . Cm empty clause, say
derivation negative-hyper-resolution refutation .

3. k-Consistency Negative-Hyper-Resolution
pointed many authors enforcing local consistency form
inference relations analogous use resolution rule clauses (Bacchus, 2007;
Bessiere, 2006; Hwang & Mitchell, 2005; Rish & Dechter, 2000). precise strength
standard resolution inference rule direct encoding CSP instance considered
work Walsh (2000), shown unit resolution (where one
clauses resolved consists single literal), corresponds enforcing weak form
local consistency known forward checking. Hwang Mitchell (2005) pointed
standard resolution rule restriction clause length able simulate
inferences made k-consistency algorithm. Atserias Dalmau (2008) showed
standard resolution rule restricted clauses k literals, known kresolution rule, characterised terms Boolean existential (k +1)-pebble game.
follows CSP instances Boolean domains form inference corresponds
enforcing k-consistency. alternative proof k-resolution achieves k-consistency
instances Boolean domains given book Hooker (2006, Thm. 3.22).
extend results little, show CSP instances arbitrary
finite domains, applying negative-hyper-resolution rule direct encoding obtain
334

fiLocal Consistency SAT-Solvers

clauses k literals corresponds precisely enforcing k-consistency. similar
relationship stated work de Kleer (1989), complete proof given.
Note bound, k, impose size negative-hyper-resolvents,
independent domain size. words, using inference rule need
consider inferred clauses size k, even though make use clauses
encoding whose size equal domain size, may arbitrarily large.
Theorem 1 k-consistency closure CSP instance P empty direct
encoding set clauses negative-hyper-resolution refutation width k.
proof broken two lemmas inspired Lemmas 2 3 work
Atserias Dalmau (2008).
Lemma 2 Let P CSP instance, let direct encoding set clauses.
negative-hyper-resolution refutation width k less, k-consistency
closure P non-empty.
Proof. Let V set variables P , v V domain Dv , let
X = {xvi | v V, Dv } corresponding set Boolean variables . Let
set clauses negative-hyper-resolution derivation width k.
definition negative-hyper-resolution, every non-empty clause consists entirely
negative literals.
let H set partial assignments P domain size k + 1
falsify clause direct encoding.
Consider element f H. definition H, f falsify clause
, definition direct encoding, every element H partial solution
P . Furthermore, f extends g, g also element H, g makes fewer
assignments f hence cannot falsify additional clauses f .
negative-hyper-resolution refutation width k,
contain empty clause, H contains (at least) partial solution empty domain,
hence H empty.
let f element H |Dom(f )| k let v variable P
Dom(f ). partial assignment g extends f Dom(g) =
Dom(f ) {v} either g H else exists clause
falsified g. Since g partial assignment, clause C falsified g,
must consist entirely negative literals. Hence literals C must either form
xwf (w) w Dom(f ), else xvg(v) . Moreover, clause must contain
literal xvg(v) , else would already falsified f .
Assume, contradiction, H contain assignment g extends f
Dom(g) = Dom(f ) {v}. case, that, Dv , contains
clause Ci consisting negative literals form xwf (w) w Dom(f ), together
literal xvi . consider clause, C, negative-hyper-resolvent
W
clauses Ci at-least-one clause iDv xvi . clause C consists entirely
negative literals form xwf (w) w Dom(f ), width
|Dom(f )| k, hence element . However C falsified f , contradicts
choice f . Hence shown f H |Dom(f )| k,
335

fiJeavons & Petke

variables v v 6 Dom(f ), g H g extends f
v Dom(g).
shown H satisfies conditions required Lemma 1, conclude
k-consistency closure P non-empty.
2

Lemma 3 Let P CSP instance, let direct encoding set clauses.
k-consistency closure P non-empty, negative-hyper-resolution
refutation width k less.
Proof. Let V set variables P , v V domain Dv , let
X = {xvi | v V, Dv } corresponding set Boolean variables .
Lemma 1, k-consistency closure P non-empty, exists nonempty set H partial solutions P satisfies three properties described
Lemma 1.
consider negative-hyper-resolution derivation width k.
show induction length derivation elements H falsify
clause derivation. First note elements H partial solutions,
satisfy constraints P , hence falsify clause . establishes
base case. Assume, induction, clauses derivation earlier
clause C falsified element H.
Note that, apart at-least-one clauses, clauses consist entirely
negative literals. Hence may assume, without loss generality, C negativehyper-resolvent set clauses = {Ci xvi | Dv } at-least-one clause
W
iDv xvi , fixed variable v.
f H falsifies C, literals C must form xwf (w) ,
w Dom(f ). Since width derivation k, C contains k literals,
hence may assume |Dom(f )| k. then, choice H, must
exist extension g f H v Dom(g). g falsify
clause , contradicts inductive hypothesis. Hence f H falsifies C, and,
particular, C cannot empty.
follows negative-hyper-resolution derivation width k contain
empty clause.
2
Note proof Theorem 1 applies sparse encoding contains
at-least-one clauses variable, clauses purely negative.
call encoding negative sparse encoding. well direct encoding,
negative sparse encodings exist. example, may use negative clauses involve
subset variables scope constraints (to forbid tuples possible
extensions complete scope disallowed constraint). Another example
negative sparse encoding well-known variant direct encoding
at-most-one clauses omitted.
Corollary 1 k-consistency closure CSP instance P empty
negative sparse encoding P negative-hyper-resolution refutation width k.
336

fiLocal Consistency SAT-Solvers

4. Negative-Hyper-Resolution SAT-Solvers
section adapt machinery Atserias et al. (2011), Pipatsrisawat
Darwiche (2009) show fixed k, existence negative-hyper-resolution
refutation width k likely discovered SAT-solver polynomial-time using
standard clause learning restart techniques, even totally random branching
strategy.
Note previous results power clause-learning SAT-solvers generally
assumed optimal branching strategy (Beame, Kautz, & Sabharwal, 2004; Pipatsrisawat
& Darwiche, 2009) - shown solvers potentially capable doing, rather
likely achieve practice. important exception paper
Atserias et al. (2011), gives analysis likely behaviour, relies
existence standard resolution proof bounded width. show results
Atserias et al. extended hyper-resolution proofs, shorter
narrower associated standard resolution proofs.
make use following terminology Atserias et al. (2011). clause
C, Boolean variable x, truth value {0, 1}, restriction C assignment
x = a, denoted C|x=a , defined constant 1, assignment satisfies clause,
else clause obtained deleting C literals involving variable x.
sequence assignments form (x1 = a1 , x2 = a2 , . . . , xr = ar ) write C|S
denote result computing restriction C assignment turn. C|S
empty, say assignments falsify clause C. set clauses ,
write |S denote set {C|S | C } \ {1}.
current SAT-solvers operate following way (Atserias et al., 2011; Pipatsrisawat & Darwiche, 2009). maintain database clauses current state
S, partial assignment truth values Boolean variables clauses
. high-level description algorithms used update clause database
state, derived description given Atserias et al., shown Algorithm 1 (a similar framework, using slightly different terminology, given Pipatsrisawat & Darwiche,
2009).
consider run algorithm shown Algorithm 1, started initial
database , empty state S0 , either halts discovers conflict (i.e., |S ).
run called complete round started , represent sequence
states S0 , . . . , Sm , algorithm maintains. Note state Si extends
state Si1 single assignment Boolean variable, may either decision
assignment implied assignment.
generally, round initial segment S0 , S1 , . . . , Sr complete round started
, state Sr either |Sr contains empty clause, |Sr
contain unit clause. clause C, say round S0 , S1 , . . . , Sr satisfies C
C|Sr = 1, say round falsifies C C|Sr empty.
S0 , S1 , . . . , Sr round started , |Sr contains empty clause,
algorithm either reports unsatisfiability learns new clause: round called
conclusive. round conclusive call inconclusive 2 . Note S0 , S1 , . . . , Sr
inconclusive round started , |Sr contain empty clause,
2. Note complete round assigns variables reports satisfiability called inconclusive.

337

fiJeavons & Petke

contain unit clauses. Hence, clause C , Sr falsifies
literals C except one, must satisfy remaining literal, hence satisfy C.
property clauses captured following definition.
Definition 4 (Atserias et al., 2011) Let set clauses, C non-empty clause,
l literal C. say absorbs C l every inconclusive round started
falsifies C \ {l} satisfies C.
absorbs C literal l C, simply say absorbs C.
Note closely related notion introduced Pipatsrisawat Darwiche (2009)
clauses absorbed set clauses ; referred 1-empowering
respect . (The exact relationship 1-empowering absorption discussed
Atserias et al., 2011.)
explore relationship absorption negative-hyper-resolution.
Example 5 Let direct encoding CSP instance P = (V, D, C), V =
{u, v, w}, Du = Dv = Dw = {1, 2} C contains two binary constraints: one forbids
assignment value 1 u v simultaneously, forbids simultaneous
assignment value 2 u 1 w. Let C also contain ternary constraint
forbids assignment value 2 three variables simultaneously.
= { xu1 xu2 , xv1 xv2 , xw1 xw2 ,
xu1 xu2 , xv1 xv2 , xw1 xw2 ,
xu1 xv1 , xu2 xw1 , xu2 xv2 xw2 }.
clause xv1 xw1 contained , obtained negative-hyperresolution clauses xu1 xu2 , xu1 xv1 , xu2 xw1 .
clause absorbed , since every inconclusive round sets xv1 = true must
set xw1 = f alse unit propagation, every inconclusive round sets xw1 = true
must set xv1 = f alse also unit propagation.
Example 5 indicates clauses obtained negative hyper-resolution
set clauses sometimes absorbed . next result clarifies situation
holds.
Lemma 4 negative-hyper-resolvent set disjoint clauses absorbed set
clauses.
Proof. Let C negative-hyper-resolvent set clauses = {Ci xi | =
1, 2, . . . , r} clause C 0 = C0 x1 x2 xr , Ci (possibly empty)
disjunction negative literals, 0 r. C = C0 C1 Cr Definition 3.
Definition 4, must show C 0 absorbs C literals. Assume
one literals C falsified. Since set clauses C 0 assumed
disjoint, remaining literal l must belong exactly one clauses set.
two cases consider.
1. l belongs clause C 0 , clauses one literals falsified,
remaining literal xi clauses set true, unit propagation.
Hence literals C 0 falsified, except l, l set true, unit propagation.
338

fiLocal Consistency SAT-Solvers

2. l belongs one clauses Ci xi , remaining clauses
one literals falsified, corresponding literals xj set true, unit
propagation. Hence literals C 0 falsified, except xi , xi set true,
unit propagation. literals Ci xi falsified, except l, l set
true unit propagation.
2
next example shows negative-hyper-resolvent set clauses
disjoint necessarily absorbed clauses.
Example 6 Recall set clauses given Example 5, direct encoding
CSP instance three variables {u, v, w}, domain {1, 2}.
clause xu2 xv2 contained , obtained negative-hyperresolution clauses xw1 xw2 , xu2 xv2 xw2 , xu2 xw1 .
clause absorbed , since inconclusive round sets xv2 = true
necessarily ensure xu2 = f alse unit propagation.
basic approach shall use establish main results show
clauses obtained bounded width negative-hyper-resolution given set
clauses, immediately absorbed (such one Example 6) likely
become absorbed quite quickly additional clauses added
process clause learning. Hence clause-learning SAT-solver likely fairly rapidly
absorb clauses derived original database clauses negativehyper-resolution. particular, empty clause derived negative-hyperresolution, solver fairly rapidly absorb literal complement,
hence report unsatisfiability (see proof Theorem 2 details).
following key properties absorption established Atserias et al. (2011).
Lemma 5 (Atserias et al., 2011) Let 0 sets clauses, let C C 0
non-empty clauses.
1. C belongs , absorbs C;
2. C C 0 absorbs C, absorbs C 0 ;
3. 0 absorbs C, 0 absorbs C.
allow analysis, need make assumptions learning scheme,
restart policy branching strategy used SAT-solver.
learning scheme rule creates adds new clause database
whenever conflict. clause called conflict clause, literals
falsified assignment current state. literal falsified i-th decision
assignment, later implied assignment (i + 1)-th decision assignment,
said falsified level i. conflict clause contains exactly one literal falsified
maximum possible level, called asserting clause (Pipatsrisawat & Darwiche,
2009; Zhang, Madigan, Moskewicz, & Malik, 2001).
Assumption 1 learning scheme chooses asserting clause.
339

fiJeavons & Petke

Algorithm 1 Framework typical clause-learning SAT-solver
Input: : set clauses;
: partial assignment truth values variables.
1.
2.
3.
4.
5.
6.
7.
8.
9.
10.
11.
12.
13.
14.
15.
16.
17.
18.
19.
20.
21.

|S 6=
|S
Conflict
contains decision assignments
print UNSATISFIABLE halt
else
apply learning scheme add new clause
restart policy says restart
set =
else
select recent conflict-causing unreversed decision assignment
reverse decision, remove later assignments
end
end
else {l} |S literal l
Unit Propagation
add implied assignment x = satisfies l
else
Decision
apply branching strategy choose decision assignment x =
add decision assignment
end
end
print SATISFIABLE output

learning schemes current use satisfy assumption (Pipatsrisawat & Darwiche, 2009; Zhang et al., 2001), including learning schemes called 1UIP Decision (Zhang et al., 2001).
make particular assumption restart policy. However, main result
phrased terms bound expected number restarts. algorithm restarts
r conflicts, bound expected number restarts simply multiplied
r get bound expected number conflicts. means results
strongest algorithm restarts immediately conflict. case,
r = 1 bound also bound expected number conflicts. Existing SATsolvers typically employ aggressive restart policy, note remark
work Pipatsrisawat Darwiche (2009, p.666) clear trend
towards frequent restarts modern SAT solvers.
branching strategy determines decision assignment chosen inconclusive round complete. current SAT solvers strategy based
heuristic measure variable activity, related occurrence variable
conflict clauses (Moskewicz, Madigan, Zhao, Zhang, & Malik, 2001). However, simplify
probabilistic analysis, make following assumption.

340

fiLocal Consistency SAT-Solvers

Assumption 2 branching strategy chooses variable uniformly random amongst
unassigned variables, assigns value TRUE.
noted Atserias et al. (2011), analysis give also applied
branching strategy randomly chooses making heuristic-based
decision randomly-based decision. precisely, allow, say, c > 1 rounds nonrandom decisions random ones, number required restarts conflicts
would appear multiplied factor c.
algorithm behaves according description Algorithm 1, satisfies
assumptions above, called standard randomised SAT-solver.
Theorem 2 set non-empty clauses n Boolean variables negativehyper-resolution refutation width k length m, expected number restarts
requiredby standard randomised SAT-solver discover unsatisfiable less
mnk 2 nk .
Proof. Let C1 , C2 , . . . , Cm negative-hyper-resolution refutation width k ,
Cm first occurrence empty clause. Since clause non-empty,
Cm must derived negative-hyper-resolution collection negative literals
x1 , x2 , . . . xd purely positive clause x1 x2 xd .
consider standard randomised SAT-solver started database .
unit clauses xi absorbed current database, then, Definition 4,
inconclusive round algorithm must assign variables xi false, hence falsify
clause x1 x2 xd . Since happens even decision assignments made,
SAT-solver report unsatisfiability.
remains bound expected number restarts required clause
Ci absorbed, 1 < m. Let Ci negative-hyper-resolvent clauses
0 x , together clause C = C x x x
Ci1 , Ci2 , . . . , Cir , form Cij
j
i0
0
1
2
r
, C0 (possibly empty) disjunction negative literals. Assume also
clause Cij absorbed j = 0, 1, . . . , r.
absorbs Ci , learning restarts needed, assume
absorb Ci . Definition 4, means exists literal l
inconclusive round R started falsifies Ci \ {l} satisfy Ci . Note
R must leave literal l unassigned, one assignment would satisfy Ci
0 , hence force literals x used
would falsify C0 Cij
j
negative-hyper-resolution step satisfied, Cij absorbed , Ci0
would falsified, contradicting fact R inconclusive.
Hence, branching strategy chooses falsify literals Ci \ {l} whenever
choice, construct inconclusive round R0 l unassigned (since
decision assignments R0 also assigned values R, implied assignments
R0 must also assigned values3 R, shown R leaves l
unassigned). branching strategy chooses falsify remaining literal l Ci ,
algorithm would construct conclusive round R00 Ci0 falsified,
3. See Lemmas 5, 8 10 work Atserias et al. (2011) formal statement proof
assertion.

341

fiJeavons & Petke

decision assignments falsify literals Ci . Hence, Assumption 1, algorithm would
learn asserting clause C 0 add obtain new set 0 .
Since C 0 asserting clause, contains exactly one literal, l0 , falsified
highest level R00 . Hence, inconclusive round R started 0 falsifies Ci \ {l}
falsify one literal C 0 , hence force remaining literal l0 satisfied,
unit propagation. new implied assignment l0 propagates force l true,
R satisfies Ci , hence 0 absorbs Ci l. not, branching strategy
choose falsify remaining literal l Ci , cause new asserting
clause learned added . Since new asserting clause forces new literal
satisfied falsifying Ci \ {l} process repeated fewer n times
certain 0 absorbs Ci l.
consider sequence k random branching choices. first k 1
falsify literal Ci \ {l}, final choice falsifies l, shown
associated round reach conflict, add asserting clause . random
branching strategy, described Assumption 2, probability happens
least probability first k 1 random choices consist fixed set variables
(in order), final choice variable associated l. number
random choices fall fixed set follows hypergeometric distribution, overall
1
probability n1 (nk+1)
= 1/(k nk ).
(k1)
obtain upper bound expected number restarts, consider worst case
require n asserting clauses added absorb clause Ci k
literals l. Since require upper bound,
treat round independent
n
trial success probability p = 1/(k k ), consider worst case
achieve (m 1)nk successes ensure Ci 1 < absorbed. case
total number restarts follow negative binomial distribution, expected value
(m 1)nk/p. Hence cases expected number restarts less mnk 2 nk . 2
tighter bound number restarts obtained focus Decision
learning scheme (Atserias et al., 2011; Zhang et al., 2001), next result indicates.
Theorem 3 set non-empty clauses n Boolean variables negative-hyperresolution refutation width k length m, expected number restarts required
standard randomised SAT-solver
using Decision learning scheme discover

unsatisfiable less nk .
Proof. proof similar proof Theorem 2, except Decision learning scheme additional feature literals chosen conflict clause falsify
subset current decision assignments. Hence situation consider,
decision assignments falsify literals clause Ci , learning scheme learn
subset Ci , hence immediately absorb Ci , Lemma 5 (1,2). Hence maximum
number learnt clausesrequired
reduced (m 1)nk (m 1), probability

increased 1/(k nk ) 1/ nk , giving tighter bound.
2
Note similar argument shows standard deviation number restarts
less standard deviation negative binomial distribution parameters
342

fiLocal Consistency SAT-Solvers




1/ nk , less nk . Hence, Chebyshevs inequality (one-tailed version),
probability standard randomised SAT-solver using decision learning scheme

discover unsatisfiable (m + m) nk restarts greater 1/2.

5. k-Consistency SAT-Solvers
combining Theorem 1 Theorem 3 obtain following result linking k-consistency
SAT-solvers.
Theorem 4 k-consistency closure CSP instance P empty, expected
number restarts required standard randomised SAT-solver using Decision learning scheme discover direct encoding P unsatisfiable O(n2k d2k ), n
number variables P maximum domain size.
Proof. length negative-hyper-resolution refutation width k bounded
Pk
n
number possible no-goods length
k

P
,


i=1 . Hence,



Theorem 1 Theorem 3 obtain bound


n
i=1

Pk

nd
k ,

O(n2k d2k ). 2

Hence standard randomised SAT-solver suitable learning strategy decide
satisfiability CSP instance tree-width k O(n2k d2k ) expected restarts,
even set restart immediately conflict. particular, satisfiability
tree-structured binary CSP instance (i.e., tree-width 1) decided
solver O(n2 d2 ) expected conflicts, comparable growth rate
optimal arc-consistency algorithm binary constraints. Note result cannot
obtained directly work Atserias et al. (2011), direct encoding
instance tree-width k set clauses whose tree-width may high dk.
Moreover, standard randomised SAT-solver decide satisfiability CSP
instance, structure, within polynomial bounds, constraint relations
satisfy certain algebraic properties ensure bounded width (Barto & Kozik, 2009).
Examples constraint types include 0/1/all relations, defined Cooper et al.
(1994), connected row-convex relations, defined Deville et al. (1997),
decided 2-consistency.
shown Gent (2002) support encoding binary CSP instance
made arc-consistent (that is, 1-consistent) applying unit propagation alone. Hence,
standard SAT-solver mimic effect enforcing arc-consistency encoding
making decisions restarts. combining Theorem 4 observation
Example 4 direct encoding obtained support encoding negativehyper-resolution, obtain following corollary concerning support encoding
higher levels consistency.
Corollary 2 k 2, k-consistency closure binary CSP instance P
empty, expected number restarts required standard randomised SATsolver using Decision learning scheme discover support encoding P
unsatisfiable O(n2k d2k ), n number variables P maximum
domain size.
343

fiJeavons & Petke

CSP literature describes many variations notion consistency.
paper considered k-consistency only. note results generalised
types consistency singleton arc-consistency (Bessiere, 2006).
extension singleton arc-consistency follows recent discovery family
CSP instances solvable enforcing singleton arc-consistency, instances
bounded width (Chen, Dalmau, & Gruien, 2011). words, instances
solved enforcing k-consistency, fixed k. Hence, Theorem 4,
solved polynomial expected time standard randomised SAT-solver.

6. Experimental Results
polynomial upper bounds obtain paper asymptotic, apply
values n, k. However, conservative, likely met
easily practice.
investigate existing SAT-solver actually performs, measured runtime
MiniSAT solver (Een & Sorensson, 2003), version 2.2.0, family CSP instances
decided fixed level consistency. comparison, also ran experiments two state-of-the-art constraint solvers: used Minion (Gent, Jefferson, &
Miguel, 2006), version 0.12, G12 finite domain solver (Nethercote et al., 2007),
version 1.4.
match simplified assumptions analysis closely, ran
set experiments core version MiniSAT order get solver uses
unit propagation conflict-directed learning restarts. also modified solver
follow random branching strategy described above. solver delete learnt
clauses uses extreme restart policy makes restart whenever encounters
conflict. uses learning scheme MiniSAT. refer modified solver
simple-MiniSAT.
characteristic feature instances tested relatively low tree-width,
also used Toulbar2 solver (Sanchez et al., 2008). solver implements BTD
(Backtracking Tree-Decomposition) technique shown efficient
practice, contrast earlier methods proposed attempt exploit
tree-decompositions input problem (Jegou & Terrioux, 2003). problem
finding tree-decomposition minimal width (i.e., tree-width) NP-hard, BTD
technique uses approximations (described Jegou & Terrioux, 2003). note
Toulbar2 designed solving optimization problems, namely weighted CSPs,
WCSPs. WCSP instance, certain partial assignments associated cost. However,
Toulbar2 solver used solve standard CSPs simply setting costs 0.
results, times given elapsed times Lenovo 3000 N200 laptop
Intel Core 2 Duo processor running 1.66GHz 2GB RAM. generated
instance run five times mean times mean number restarts shown4 .
Example 7 consider family instances specified two parameters, w d.
((d1)w+2)w variables arranged groups size w, domain {0, ..., d1}.
4. MiniSAT simple-MiniSAT run different seeds five runs instance.
Instances marked * run only. runtime simple-MiniSAT instances
exceeded 6 hours. Moreover, Toulbar2 run parameter B = 1 enables BTD.

344

fiLocal Consistency SAT-Solvers

impose constraint arity 2w pair successive groups, requiring
sum values assigned first two groups strictly smaller
sum values assigned second. ensures instances generated
unsatisfiable. instance w = 2 = 2 shown diagrammatically defined
using specification language MiniZinc (Nethercote et al., 2007) Figure 1 (a) (b)
respectively5 . similar format used Toulbar2 6 instance encoded
format shown Figure 1 (c) (note hard constraint cost 0).

(a) Graphical representation.

chain
x1 0 1
x2 0 1
x3 0 1
x4 0 1
x5 0 1
x6 0 1
x7 0 1
x8 0 1
hard( x1 + x2 < x3 + x4 )
hard( x3 + x4 < x5 + x6 )
hard( x5 + x6 < x7 + x8 )

array[1..4] var 0..1 : X1;
array[1..4] var 0..1 : X2;
constraint
forall(i 1..3)(
X1[i] + X2[i] < X1[i + 1] + X2[i + 1]);
solve satisfy;
(b) Specification MiniZinc.

(c) Specification cp format.

Figure 1: example CSP instance w = 2, = 2 tree-width = 3.

structure instances described Example 7 simple tree-decomposition
path nodes, node corresponding constraint scope. Hence tree-width
instances 2w 1 shown unsatisfiable enforcing (2w 1)consistency (Atserias et al., 2007). However, instances cannot solved efficiently
using standard propagation algorithms prune individual domain values.
structure direct encoding instances also tree-decomposition
node corresponding constraint scope original CSP instance. However,
direct encoding introduces Boolean variables represent variable
5. order run instance CP solver one must usually use translator convert original
model. MiniZinc distribution provides mzn2fzn translator Minion one use Tailor
(available http://www.cs.st-andrews.ac.uk/andrea/tailor/).
6. cp2wcsp translator description cp wcsp formats available
http://carlit.toulouse.inra.fr/cgi-bin/awki.cgi/SoftCSP.

345

fiJeavons & Petke

original instance, tree-width encoded SAT instances larger approximately
factor d; fact 2wd 1 (see Figure 2).

(a) Tree-decomposition original instance.

(b) Tree-decomposition direct
encoding.

Figure 2: Tree-decompositions CSP instance Figure 1.
Table 1 shows runtimes simple-MiniSAT original MiniSAT solver
family instances, along times two state-of-the-art CP solvers
WCSP solver Toulbar2. far best solver set instances Toulbar2,
explicitly designed exploit low tree-width constructing tree-decomposition.
class instances considering, widths tree-decompositions found
Toulbar2 matched tree-widths instances tested (i.e., 2w 1).
However, also note MiniSAT remarkably effective solving chains
inequalities, compared Minion G12, even though use MiniSAT requires
encoding instance large number clauses much larger tree-width
original. Although simplified version MiniSAT solver takes little longer
current highly optimised version, still performs well instances
comparison conventional CP solvers. Moreover, number restarts (and hence
number conflicts) appears grow polynomially size instance
(see Figure 3). cases actual number restarts much lower polynomial
upper bound expected number restarts given Theorem 4.
best theoretical upper bounds expected run-time obtained
Decision learning scheme (Theorem 4), standard version MiniSAT uses
1UIP learning scheme conflict clause minimization. allow direct comparison
theoretical upper bounds, implemented Decision scheme simpleMiniSAT. 1UIP learning scheme generally found efficient
practice (Zhang et al., 2001), switched conflict clause minimization simpleMiniSAT order compare two standard learning schemes ran set
experiments. counted number restarts two modified solvers instances
form described Example 7 - see Table 2.
346

fiLocal Consistency SAT-Solvers

group
size
(w)
2
2
2
2
2
2
2
2
2
3
3
3
3
3
4
4
4

domain
size
(d)
2
3
4
5
6
7
8
9
10
2
3
4
5
6
2
3
4

CSP
variables
(n)
8
12
16
20
24
28
32
36
40
15
24
33
42
51
24
40
56

Minion

G12

(sec)
0.055
0.053
0.057
0.084
1.048
47.295
> 20 min
> 20 min
> 20 min
0.055
0.412
> 20 min
> 20 min
> 20 min
0.060
> 20 min
> 20 min

(sec)
0.010
0.011
0.013
0.047
0.959
122.468
> 20 min
> 20 min
> 20 min
0.010
0.034
7.147
> 20 min
> 20 min
0.015
11.523
> 20 min

Toulbar2

MiniSAT

(sec)
0.021
0.023
0.040
0.091
0.199
0.549
1.214
2.523
4.930
0.024
0.103
0.860
5.646
28.663
0.046
1.246
20.700

(sec)
0.003
0.005
0.015
0.043
0.126
0.362
0.895
2.407
5.656
0.004
0.066
1.334
20.984
383.564
0.012
4.631
1,160.873

simpleMiniSAT
(sec)
0.002
0.007
0.034
0.188
0.789
2.884
9.878
34.352
111.912
0.008
0.503
20.054
817.779
> 20 min
0.118
260.656
> 20 min

simpleMiniSAT
restarts
19
157
820
3 039
7 797
17 599
36 108
65 318
114 827
167
5 039
41 478
210 298
731 860
1 617
108 113
1 322 784*

Table 1: Average performance solvers instances Example 7.
group
size
(w)

domain
size
(d)

CSP
variables
(n)

no. clauses
direct
encoding

2
2
2
2
2
2
2
2
2
3
3
3
3
3
4
4

2
3
4
5
6
7
8
9
10
2
3
4
5
6
2
3

8
12
16
20
24
28
32
36
40
15
24
33
42
51
24
40

49
298
1 162
3 415
8 315
17 724
34 228
61 257
103 205
198
3 141
23 611
113 406
408 720
863
34 666

simpleMiniSAT
1UIP
(sec)
0.002
0.008
0.048
0.272
1.399
5.780
24.417
95.278
309.980
0.009
0.643
53.067
2,266.627
> 6 hours
0.141
603.241

simpleMiniSAT
1UIP
restarts
21
203
1 026
4 068
12 029
27 356
56 193
109 862
199 399
192
5 952
63 952
375 849
1 584 012*
1 937
155 842

simpleMiniSAT
Decision
(sec)
0.002
0.010
0.057
0.323
1.526
6.035
20.436
69.144
207.342
0.012
0.750
71.778
2,036.456
> 6 hours
0.192
938.836

simpleMiniSAT
Decision
restarts
23
267
1 424
5 283
14 104
33 621
64 262
113 460
190 063
287
7 308
91 283
391,664
1 365 481*
2 592
253 153

Table 2: Average performance simple-MiniSAT 1UIP Decision learning schemes instances Example 7.

347

fiJeavons & Petke

Figure 3: Log-log plot number restarts/conflicts used simple-MiniSAT

instances Example 7. solid lines show growth function d2w2 nd/w
,
3
n number CSP variables. empirically derived polynomial
function appears fit experimental data well, much lower
upper bound expected number restarts calculated Theorem 4
O(d4w2 n4w2 ).

348

fiLocal Consistency SAT-Solvers

Although performance simple-MiniSAT Decision learning scheme
1UIP scheme significantly worse performance original simpleMiniSAT solver, twice many restarts required instance. Hence,
theoretical upper bounds still easily met standard learning schemes.

7. Conclusions
shown notion k-consistency precisely captured single
inference rule direct encoding CSP instance, restricted deriving clauses
k literals. used show clause-learning SAT-solver purely
random branching strategy simulate effect enforcing k-consistency expected
polynomial time, fixed k. sufficient ensure solvers able
solve certain problem families much efficiently conventional CP solvers relying
GAC-propagation.
principle clause-learning SAT-solvers also much more. known that,
appropriate branching strategy restart policy, able p-simulate general
resolution (Beame et al., 2004; Pipatsrisawat & Darwiche, 2009), general resolution
proofs exponentially shorter negative-hyper-resolution proofs considered (Hwang & Mitchell, 2005). practice, seems current clause-learning
SAT-solvers highly-tuned learning schemes, branching strategies restart policies
often able exploit structure Boolean encoding CSP instance even
effectively local consistency techniques. Hence considerable work remains done
understanding relevant features instances able exploit, order
predict effectiveness solving different kinds CSP instances.

Acknowledgments
would like thank Albert Atserias Marc Thurley comments conference
version paper, well anonymous referees. provision EPSRC
Doctoral Training Award Justyna Petke also gratefully acknowledged.
preliminary version paper appeared Proceedings 16th International
Conference Principles Practice Constraint Programming - CP2010.

References
Atserias, A., Bulatov, A. A., & Dalmau, V. (2007). power k-consistency.
International Colloquium Automata, Languages Programming - ICALP07,
pp. 279290.
Atserias, A., & Dalmau, V. (2008). combinatorial characterization resolution width.
Journal Computer System Sciences, 74 (3), 323334.
Atserias, A., Fichte, J. K., & Thurley, M. (2011). Clause-learning algorithms many
restarts bounded-width resolution. Journal Artificial Intelligence Research
(JAIR), 40, 353373.
Bacchus, F. (2007). GAC via unit propagation. Principles Practice Constraint
Programming - CP07, pp. 133147.
349

fiJeavons & Petke

Barto, L., & Kozik, M. (2009). Constraint satisfaction problems bounded width.
Symposium Foundations Computer Science - FOCS09, pp. 595603.
Beame, P., Kautz, H. A., & Sabharwal, A. (2004). Towards understanding harnessing
potential clause learning. Journal Artificial Intelligence Research (JAIR),
22, 319351.
Bessiere, C. (2006). Constraint propagation. Rossi, F., van Beek, P., & Walsh, T. (Eds.),
Handbook Constraint Programming, chap. 3. Elsevier.
Buning, H., & Lettmann, T. (1999). Propositional logic: deduction algorithms. Cambridge tracts theoretical computer science. Cambridge University Press.
Chen, H., Dalmau, V., & Gruien, B. (2011). Arc consistency friends. Computing
Research Repository - CoRR, abs/1104.4993.
Cooper, M. C. (1989). optimal k-consistency algorithm. Artificial Intelligence, 41 (1),
8995.
Cooper, M. C., Cohen, D. A., & Jeavons, P. (1994). Characterising tractable constraints.
Artificial Intelligence, 65 (2), 347361.
de Kleer, J. (1989). comparison ATMS CSP techniques. International Joint
Conference Artificial Intelligence - IJCAI89, pp. 290296.
Deville, Y., Barette, O., & Hentenryck, P. V. (1997). Constraint satisfaction connected
row convex constraints. International Joint Conference Artificial Intelligence IJCAI97 (1), pp. 405411.
Een, N., & Sorensson, N. (2003). extensible SAT-solver. Theory Applications
Satisfiability Testing - SAT03, pp. 502518.
Freuder, E. C. (1978). Synthesizing constraint expressions. Communications ACM,
21 (11), 958966.
Gent, I. P. (2002). Arc consistency SAT. European Conference Artificial Intelligence
- ECAI02, pp. 121125.
Gent, I. P., Jefferson, C., & Miguel, I. (2006). Minion: fast scalable constraint solver.
European Conference Artificial Intelligence - ECAI06, pp. 98102.
Hooker, J. N. (2006). Integrated Methods Optimization (International Series Operations Research & Management Science). Springer-Verlag New York, Inc., Secaucus,
NJ, USA.
Hoos, H. H. (1999). SAT-encodings, search space structure, local search performance.
International Joint Conference Artificial Intelligence - IJCAI99, pp. 296303.
Hwang, J., & Mitchell, D. G. (2005). 2-way vs. d-way branching CSP. Principles
Practice Constraint Programming - CP05, pp. 343357.
Jegou, P., & Terrioux, C. (2003). Hybrid backtracking bounded tree-decomposition
constraint networks. Artificial Intelligence, 146 (1), 4375.
Kolaitis, P. G., & Vardi, M. Y. (2000). game-theoretic approach constraint satisfaction. Conference Artificial Intelligence - AAAI00 / Innovative Applications
Artificial Intelligence Conference - IAAI00, pp. 175181.
350

fiLocal Consistency SAT-Solvers

Mackworth, A. K. (1977). Consistency networks relations. Artificial Intelligence, 8 (1),
99118.
Montanari, U. (1974). Networks constraints: Fundamental properties applications
picture processing. Information Sciences, 7, 95132.
Moskewicz, M. W., Madigan, C. F., Zhao, Y., Zhang, L., & Malik, S. (2001). Chaff: Engineering efficient SAT solver. Design Automation Conference - DAC01, pp.
530535.
Nethercote, N., Stuckey, P. J., Becket, R., Brand, S., Duck, G. J., & Tack, G. (2007).
MiniZinc: Towards standard CP modelling language. Principles Practice
Constraint Programming - CP07, pp. 529543.
Petke, J., & Jeavons, P. (2009). Tractable benchmarks constraint programming. Technical Report RR-09-07, Department Computer Science, University Oxford.
Pipatsrisawat, K., & Darwiche, A. (2009). power clause-learning SAT solvers
restarts. Principles Practice Constraint Programming - CP09, pp. 654668.
Prestwich, S. D. (2009). CNF encodings. Biere, A., Heule, M., van Maaren, H., & Walsh,
T. (Eds.), Handbook Satisfiability, pp. 7597. IOS Press.
Rish, I., & Dechter, R. (2000). Resolution versus search: Two strategies SAT. Journal
Automated Reasoning, 24 (1/2), 225275.
Robinson, J. A. (1965). machine-oriented logic based resolution principle. Journal
ACM, 12 (1), 2341.
Sanchez, M., Bouveret, S., de Givry, S., Heras, F., Jegou, P., Larrosa, J., Ndiaye, S., Rollon,
E., Schiex, T., Terrioux, C., Verfaillie, G., & Zytnicki, M. (2008). Max-CSP competition 2008: Toulbar2 solver description. Proceedings Third International
CSP Solver Competition.
Schiex, T., & Verfaillie, G. (1993). Nogood recording static dynamic constraint
satisfaction problems. International Conference Tools Artificial Intelligence
- ICTAI93, pp. 4855.
Tamura, N., Taga, A., Kitagawa, S., & Banbara, M. (2009). Compiling finite linear CSP
SAT. Constraints, 14 (2), 254272.
van Dongen, M., Lecoutre, C., & Roussel, O. (2008). 3rd international CSP solver competition. Instances results available http://www.cril.univ-artois.fr/CPAI08/.
van Dongen, M., Lecoutre, C., & Roussel, O. (2009). 4th international CSP solver competition. Instances results available http://www.cril.univ-artois.fr/CPAI09/.
Walsh, T. (2000). SAT v CSP. Principles Practice Constraint Programming CP00, pp. 441456.
Zhang, L., Madigan, C. F., Moskewicz, M. W., & Malik, S. (2001). Efficient conflict driven
learning Boolean satisfiability solver. International Conference ComputerAided Design - ICCAD01, pp. 279285.
Zhang, L., & Malik, S. (2002). quest efficient Boolean satisfiability solvers.
Computer Aided Verification - CAV02, pp. 1736.

351

fiJournal Artificial Intelligence Research 43 (2012) 87-133

Submitted 07/11; published 01/12

Location-Based Reasoning Complex Multi-Agent Behavior
Adam Sadilek
Henry Kautz

SADILEK @ CS . ROCHESTER . EDU
KAUTZ @ CS . ROCHESTER . EDU

Department Computer Science, University Rochester
Rochester, NY 14627, USA

Abstract
Recent research shown surprisingly rich models human activity learned
GPS (positional) data. However, effort date concentrated modeling single individuals statistical properties groups people. Moreover, prior work focused solely modeling
actual successful executions (and failed attempted executions) activities interest.
We, contrast, take task understanding human interactions, attempted interactions,
intentions noisy sensor data fully relational multi-agent setting. use real-world
game capture flag illustrate approach well-defined domain involves many
distinct cooperative competitive joint activities. model domain using Markov logic,
statistical-relational language, learn theory jointly denoises data infers occurrences high-level activities, player capturing enemy. unified model combines
constraints imposed geometry game area, motion model players,
rules dynamics game probabilistically logically sound fashion. show
may impossible directly detect multi-agent activity due sensor noise malfunction, occurrence activity still inferred considering impact
future behaviors people involved well events could preceded it. Further,
show given model successfully performed multi-agent activities, along set
examples failed attempts activities, system automatically learns augmented
model capable recognizing success failure, well goals peoples actions
high accuracy. compare approach alternatives show unified model,
takes account relationships among individual players, also relationships
among activities entire length game, although computationally costly, significantly accurate. Finally, demonstrate explicitly modeling unsuccessful attempts
boosts performance important recognition tasks.

1. Introduction
society founded interplay human relationships interactions. Since every person tightly embedded social structure, vast majority human behavior fully
understood context actions others. Thus, surprisingly, evidence shows want model behavior person, single best predictor often
behavior people social network. instance, behavioral patterns people taking taxis,
rating movies, choosing cell phone provider, sharing music best explained predicted
habits related people, rather single person attributes age, race,
education (Bell, Koren, & Volinsky, 2007; Pentland, 2008).
contrast observations, research effort activity recognition date concentrated modeling single individuals (Bui, 2003; Liao, Fox, & Kautz, 2004, 2005), statistical
properties aggregate groups individuals (Abowd, Atkeson, Hong, Long, Kooper, & Pinkerton,
1997; Horvitz, Apacible, Sarin, & Liao, 2005), combinations (Eagle & Pentland, 2006).
c
2012
AI Access Foundation. rights reserved.

fiS ADILEK & K AUTZ

Notable exceptions isolated individuals approach includes work Kamar Horvitz
(2009) Gupta, Srinivasan, Shi, Davis (2009), simple relationships among people
starting explicitly considered leveraged. instance, Eagle Pentland (2006)
elegantly model location individuals multi-modal sensory data, approach
oblivious explicit effects ones friends, relatives, etc. ones behavior. isolated individuals approximations often made sake tractability representational convenience.
considering individuals independently sufficient constrained tasks,
many interesting domains discards wealth important information results inefficient unnatural data representation. hand, decomposing domain set
entities (representing instance people, objects environment, activities) linked
various relationships (e.g., is-a, has-a, is-involved-in) natural clear way representing
data.
address shortcomings nonrelational behavior modeling, introduce capture
flag domain (described below), argue statistical-relational approach learning models
multi-agent behavior raw GPS data. CTF dataset one hand quite complex
recorded real-world sensors, time well-defined (as per rules game),
thereby allowing unambiguous evaluation results.
able recognize peoples activities reason behavior necessary precondition intelligent helpful machines aware going
human-machine well human-human relationships. many exciting practical applications activity recognition potential fundamentally change peoples lives.
example, cognitive assistants help people teams productive, provide support
(groups of) disabled individuals, efficiently summarize long complex event busy person
without leaving essential information. important applications include intelligent navigation, security (physical well digital), human-computer interaction, crowdsourcing.
applications myriad others build top multi-agent activity recognition therefore require necessary stepping stone. Furthermore, consequence anthropocentrism
technology, modeling human behavior playsperhaps surprisinglya significant role even
applications directly involve people (e.g., unmanned space probes).
Furthermore, reasoning human intentions essential element activity recognition,
since recognize person (or group people) wants do, proactively
try help (orin adversarial situationshinder them). Intent notoriously problematic
quantify (e.g., Baldwin & Baird, 2001), show capture flag domain, notion
naturally captured process learning structure failed activities. know perhaps
well successful action often precededand unfortunately sometimes also followedby
multiple failed attempts. Therefore, reasoning attempts typically entails high practical utility,
relatively high frequency. Consider, example, task real-time analysis
security video system. There, detecting person group people (again, relations)
intend steal something much important useful recognizing theft taken
(or even taking) place, certainly late entirely prevent incident,
may also late harder merely stop it. believe recognition attempts peoples
activities severely underrepresented topic artificial intelligence needs explored
since opens new realm interesting possibilities.
delve details approach Sections 5 6, briefly introduce
CTF dataset (Section 2), highlight main contributions work (Section 3), review
88

fiL OCATION -BASED R EASONING C OMPLEX ULTI -AGENT B EHAVIOR

background material (Section 4). discuss related work, conclude, outline future work
Sections 7, 8 9 respectively.
paper incorporates extends previous work (Sadilek & Kautz, 2010a, 2010b).

2. Capture Flag Domain
Imagine two teamsseven players eachplaying capture flag (CTF) university campus,
player carries consumer-grade global positioning system (GPS) logs location
(plus noise) every second (see Figure 1). primary goal enter opponents flag area.
Players captured enemy territory tagged enemy. Upon
captured, must remain place freed (tagged teammate) game ends.
games involve many competitive cooperative activities, focus (both successful
attempted) capturing freeing. Visualization games available first authors
website.
collected four games CTF portion University Rochester campus (about
23 acres) Columbus V-900 GPS loggers (one per player) 1 GB memory card
set sampling rate 1 Hz. durations games ranged approximately 4 15
minutes.
work primarily motivated problem annotating strategy games, although
obvious applications results sports combat situations. are, generally, exploring relational learning inference methods recognizing multi-agent activities
location data. accept fact GPS data disposal inherently unreliable
ambiguous one individual. therefore focus methods jointly simultaneously
localize recognize high-level activities groups individuals.
Although CTF domain doesnt capture intricacies life, contains many complex, interesting, yet well-defined (multi-agent) activities. Moreover, based extensive
real-world GPS data (total 40,000+ data points). Thus problems addressing clearly direct analogs everyday-life situations ubiquitous computing needs
addressimagine people going daily lives city instead CTF players,
smart phones instead GPS loggers.
One main challenges overcome successfully model CTF
severe noise present data. Accuracy GPS data varies 1 10 meters.
open areas, readings typically 3 meters, discrepancy much higher locations
tall buildings (which present within game area) obstructions. Compare
scale error granularity activities concern with: capturing
freeing involves players within reaching distance (less 1 meter) apart. Therefore,
signal noise ratio domain daunting.
error systematic component well significant stochastic component. Errors
devices poorly correlated, subtle differences players, angle
device sits players pocket, dramatically affect accuracy. Moreover, since
consider multi-agent scenarios, errors individual players readings add up, thereby
creating large discrepancy reality recorded dataset. players
move freely open areas, cannot reduce data error assuming players move
along road walkways, done much work GPS-based activity recognition (e.g., Liao
et al., 2004). Finally, traditional techniques denoising GPS data, Kalman filtering,

89

fiS ADILEK & K AUTZ

Figure 1: snapshot game capture flag shows game area. Players
represented pins letters. version CTF, two flags stationary
shown white circles near top bottom figure. horizontal road middle image territory boundary. data shown prior
denoising corrections map errors. Videos games available
http://www.cs.rochester.edu/u/sadilek/
90

fiL OCATION -BASED R EASONING C OMPLEX ULTI -AGENT B EHAVIOR

little help, due low data rate (1 sample per second) relative small amount time
required player completely change speed direction.
reliably recognize events happen games presence severe
noise, need consider player, also relationships among
actions extended periods time (possibly whole length game). Consider concrete
task inferring individual joint activities intentions CTF players GPS
traces. example, suppose GPS data shows player running toward stationary teammate
B, moving away. occurred? Possibly player freed player B, GPS error
hidden fact player actually reached B. Another possibility player
intention freeing player B, scared opponent last second. Yet another possibility freeing occurred even intended, player B previously
captured.
Understanding game thus consists inferring complex set interactions among various
players well players intentions. conclusions drawn occurs one point
time affect affected inferences past future events. example given,
recognizing player B moving future reinforces conclusion player freeing
player B, failing recognize past event player B captured decreases confidence
conclusion. game CTF also illustrates understanding situation much
recognizing attempts intentions recognizing successfully executed actions.
example, course 15 minute game, handful capture freeing events occur. However,
dozens cases one player unsuccessfully tries capture opponent free
teammate. description game restricted actually occurred would
pale reflection original.

Figure 2: Three snapshots game situation successful failed capturing occur.
example also illustrates need approach exploits relational
far reaching temporal structure domain. (See text explanation.)

concrete example, consider real game situation illustrated Figure 2. see three
snapshots game projected map campus modification GPS data.
game time shown snapshot. Players D, F, G allies currently
home territory near flag, whereas players L enemies. first snapshot,
players L head opponents flag thenin second framethey intercepted
G. point unclear happening substantial error GPS data

91

fiS ADILEK & K AUTZ

three players appear close other, actuality could 20
meters apart. However, see third snapshot (note tens seconds passed)
realize player G actually captured player didnt capture L since G evidently
still chasing L. fact player remains stationary coupled fact neither F
attempt capture suggests indeed captured. show possible infer
occurrences capturing events even complex situations like whereas limited approaches
largely fail. However, need able recognize individual events, also need
discover new activities, identify respective goals, distinguish events based
whether outcomes favorable negative. instance, second frame, player G tries
capture L M. Although succeeded former case, failed latter.
Many different kinds cooperative competitive multi-agent activities occur games.
lowest-level joint activities based location movement, include approaching
location. Note, noise GPS data often makes difficult impossible
directly detect simple activities. next level come competitive multi-agent activities
including capturing attacking; cooperative activities include freeing; activities,
chasing guarding, may belong either category categories.
also abstract tactical activities, making sacrifice, overall strategies,
playing defensively. paper, concentrate activities first two levels.

3. Contributions
main contributions paper follows. first present novel method simultaneously denoises positional data learns model multi-agent activities occur there.
subsequently evaluate model CTF dataset show achieves high accuracy
recognizing complex game events.
However, creating model manually writing new rules editing existing axioms
laborious prone introduction errors unnecessarily complex theories. Thus, would
like automate process learning (or inducing) new axioms training data. people,
much easier provide validate concrete examples directly modify model.
leads us second contribution: show automatically augment preexisting model
(joint) activities capable recognizing successful actions, also identifies
failed attempts types activities. line work also demonstrates explicitly
modeling attempted interactions unified way improves overall model performance.
third contribution, demonstrate difference (discussed below)
newly learned definitions failed activity original definition corresponding successful activity directly corresponds goal given activity. instance, per rules
capture flag game, captured player cannot move freed. system induces
definition failed capture, new theory contain constraint movement
almost-captured player, thereby allowing move freely.

4. Background
cores models described implemented Markov logic (ML), statisticalrelational language. section, provide brief overview ML, extends finite firstorder logic (FOL) probabilistic setting. detailed (and excellent) treatment FOL,

92

fiL OCATION -BASED R EASONING C OMPLEX ULTI -AGENT B EHAVIOR

ML, inductive logic programming see work Shoenfield (1967), Domingos, Kok, Lowd,
Poon, Richardson, Singla (2008), De Raedt Kersting (2008), respectively.
order compare Markov logic based models alternative approaches, consider
dynamic Bayesian network (DBN) model experiments one baselines.
therefore review relevant aspects DBNs section well.
4.1 Markov Logic
Given inherent uncertainty involved reasoning real-world activities observed
noisy sensor readings, looked methodology would provide elegant combination
probabilistic reasoning expressive, relatively natural, compact unfortunately strictly
true false formulas first-order logic. exactly Markov logic provides thus
allows us elegantly model complex finite relational non-i.i.d. domains. Markov logic network
(MLN) consists set constants C set pairs hFi , wi FOL formula
Fi weight wi R associated it. Optionally, weight scaled
real-valued function subset variables appear corresponding formula. Markov
logic networks contain functions called hybrid MLNs (Wang & Domingos, 2008).
MLN viewed template Markov network (MN) follows: MN contains
one node possible ground atom MLN. value node 0 corresponding
atom false 1 otherwise. Two nodes connected edge corresponding atoms
appear formula. Thus, MN distinct clique corresponding grounding
g
formula. Fi j denote j-th grounding formula Fi . MN feature value fi,j
gj
Fi
(
g
1 Fi j true
fi,j =
0 otherwise
weight wi intuitively represents relative importance satisfying (or violating,
weight negative) corresponding formula Fi . formally, weight scales difference
log-probability world satisfies n groundings corresponding formula one
results true groundings formula, else equal (cf. Equation 1). Thus
problem satisfiability relaxed MLNs. longer search satisfying truth assignment
traditional FOL. Instead, looking truth assignment maximizes sum
weights satisfied formulas.
weights either specified knowledge base engineer or, approach,
learned training data. is, provide learning algorithm labeled capture instances pairs raw corresponding denoised trajectories along labeled instances
game events finds optimal set weights maximize likelihood training
data. Weight learning done either generative discriminative fashion. Generative training maximizes joint probability observed (evidence) well hidden (query) predicates,
whereas discriminative learning directly maximizes conditional likelihood hidden predicates given observed predicates. Since prior work demonstrated Markov network models
learned discriminatively consistently outperform generatively trained counterparts (Singla &
Domingos, 2005), focus discriminative learning activity recognition domain.
knowledge base weights specified, ask questions state
hidden atoms given state observed atoms. Let X vector random variables
(one random variable possible ground atom MN) let set possible
93

fiS ADILEK & K AUTZ

instantiations X. Then, x represents possible world. (x )[Pr(X = x) > 0]
holds, probability distribution worlds defined
!
X

1
Pr(X = x) = exp
wi ni x{i}
(1)
Z


ni (x{i} ) number true groundings i-th formula wi weight world x

!
X
X

Z=
exp
wi ni x{i}
(2)
x



Equation 1 viewed assigning score possible world dividing score
sum scores possible worlds (the constant Z) order normalize.
Maximum posteriori (MAP) inference Markov logic given state observed atoms
reduces finding truth assignment hidden atoms weighed sum satisfied
clauses maximal. Even though problem general #P-complete, achieve reasonable
run times applying Cutting Plane MAP Inference (CPI) (Riedel, 2008). CPI thought
meta solver incrementally grounds Markov logic network, step creating Markov
network subsequently solved applicable methodsuch MaxWalkSAT via
reduction integer linear program. CPI refines current solution searching additional
groundings could contribute objective function.
point, focused first-order Markov logic. first-order ML, variable
ranges objects present domain (e.g., apples, players, cars). hand, finite
second-order Markov logic, variabilize objects also predicates (relations) (Kok & Domingos, 2007). CTF model contains predicate variable type activity. example, one variable captureType whose domain {capturing, failedCapturing}
analogously freeing events. grounding second-order ML, ground predicate
variables well object variables. also preliminary work generalizing ML
well-defined infinite domains, would indeed give full power FOL (Singla &
Domingos, 2007).
Implementations Markov logic include Alchemy1 theBeast2 . experiments used
modified version theBeast.
4.2 Dynamic Bayesian Networks
Bayesian network (BN) directed probabilistic graphical model (Jordan, 1998). Nodes
graph represent random variables edges represent conditional dependencies (cf. Figure 4).
BN n nodes, joint probability distribution given
Pr(X1 , . . . , Xn ) =

n

i=1

1. http://alchemy.cs.washington.edu/
2. http://code.google.com/p/theBeast/

94


Pr Xi |Pa(Xi ) ,

(3)

fiL OCATION -BASED R EASONING C OMPLEX ULTI -AGENT B EHAVIOR

Pa(Xi ) denotes parents node Xi . typical setting, subset random variables
observed (we know actual values), others hidden values need
inferred.
dynamic Bayesian network (DBN) BN models sequential data. DBN composed
slicesin case slice represents one second time interval. order specify DBN,
either write learn intra- inter-slice conditional probability distributions (CPDs).
intra-slice CPDs typically constitute observation model inter-slice CPDs model
transitions hidden states. extensive treatment DBNs, see work Murphy
(2002).
number parameter learning inference techniques DBNs. match
Markov logic-based framework, experiments DBN model presented below, focus
supervised learning scenario, hidden labels known training time therefore
maximum likelihood estimate calculated directly.
find set parameters (discrete probability distributions) maximize log-likelihood
training data. achieved optimizing following objective function.

? = argmax log Pr x1:t , y1:t |) ,

(4)



x1:t y1:t represent sequence observed hidden values, respectively,
times 1 t, ? set optimal model parameters. implementation, represent
probabilities likelihoods log-counterparts avoid arithmetic underflow.
testing time, interested likely explanation observed data. is,
want calculate likely assignment states hidden nodes (i.e., Viterbi decoding
DBN) given

?
(5)
y1:t
= argmax log Pr(y1:t |x1:t ) ,
y1:t

Pr(y1:t |x1:t ) conditional probability sequence hidden states y1:t given concrete
sequence observations x1:t times 1 t. calculate Viterbi decoding efficiently
using dynamic programming (Jordan, 1998).

5. Methodology
section, describe three major components approach. short, first manually
construct model captures freeings CTF optimize parameters supervised
learning framework (Section 5.1). constitutes seed theory used denoising raw
location data recognition successful multi-agent activities. show, Section 5.2,
automatically extend seed theory inducing structure learning importance
failed captures freeings well relationships successful counterparts. Finally,
Section 5.3, use augmented theory recognize richer set multi-agent activitiesboth
successful failed attemptsand extract goals activities.
Specifically, investigate following four research questions:
Q1. reliably recognize complex multi-agent activities CTF dataset even presence severe noise?
Q2. models attempted activities automatically learned leveraging existing models
successfully performed actions?
95

fiS ADILEK & K AUTZ

Q3. modeling success failure allow us infer respective goals activities?
Q4. modeling failed attempts activities improve performance recognizing activities themselves?
elaborate three components system turn, subsequently
discuss, light experimental results lessons learned, answers research
questions.
5.1 Recognition Successful Activities
section, present unified framework intelligent relational denoising raw GPS
data simultaneously labeling instances player captured enemy freed
ally. denoising labeling cast learning inference problem Markov
logic. denoising, mean modifying raw GPS trajectories players final
trajectories satisfy constraints imposed geometry game area, motion model
players, well rules dynamics game. paper, refer trajectory
modification snapping since tile game area 3 3 meter cells snap raw
GPS reading appropriate cell. creating cells unobstructed space, ensure final
trajectory consistent map area.
begin modeling domain via Markov logic theory, write logical formulas express structure model hand, learn optimal set weights
formulas training data supervised discriminative fashion (details experimental setup Section 6). following two subsections, show augment seed
Markov logic theory recognize richer set events extract goals players multi-agent
activities.
order perform data denoising recognition successful capturing freeing,
model game weighted formulas Markov logic. formulas hard,
sense interested solutions satisfy them. Hard formulas capture basic
physical constraints (e.g., player one location time) inviolable rules game
(e.g., captured player must stand still freed game ends).3 rest formulas
soft, meaning finite weight associated one. soft constraints
correspond traditional low-level data filter, expressing preferences smooth trajectories
close raw GPS readings. soft constraints capture high-level constraints concerning
individual multi-agent activities likely occur. example, soft constraint states
player encounters enemy enemys territory, player likely captured.
exact weights soft constraints learned labeled data, described below.
distinguish two types atoms models: observed (e.g., GPS(P1 , 4, 43.13 , 77.71 )
hidden (e.g., freeing(P1 , P8 , 6)). observed predicates CTF domain are: GPS, enemies, adjacent, onHomeTer, onEnemyTer;4 whereas capturing, freeing, isCaptured, isFree,
samePlace, snap hidden. Additionally, set hidden predicates expanded structure learning algorithm described (see Table 1 predicate semantics). training phase,
3. Cheating occur CTF games, principle could accommodated making rules highlyweighted soft constraints rather hard constraints.
4. noise GPS data introduces ambiguity last two observed predicates, still reliably
generate since road marks boundary territories constitutes neutral zone.

96

fiL OCATION -BASED R EASONING C OMPLEX ULTI -AGENT B EHAVIOR

Hard Rules:
H1. raw GPS reading snapped exactly one cell.
H2.

(a) player frees player b, involved players must snapped common cell
time.
(b) player freed free ally.
(c) player freed currently captured.
(d) Immediately freeing event, freed player transitions free state.
(e) player freed enemy territory.

H3.

(a) player captures player b, involved players must snapped common cell
time.
(b) player captured free enemy.
(c) player captured currently free.
(d) Immediately capture event, captured player transitions captured state.
(e) player captured standing enemy territory.

H4. players free beginning game.
H5. given time, player either captured free both.
H6. player transitions captured state free state via freeing event.
H7. player transitions free state captured state via capture event.
H8. player captured must remain location.

Soft Rules:
S1. Minimize distance raw GPS reading snapped-to cell.
S2. Minimize projection variance, i.e., two consecutive snappings generally correlated.
S3. Maximize smoothness (both terms space time) final player trajectories.
S4. players b enemies, enemy territory b not, b captured already,
close other, probably captures b.
S5. players b allies, enemy territory, b currently captured not,
close other, probably frees b.
S6. Capture events generally rare, i.e., typically captures within game.
S7. Freeing events also generally rare.

Figure 3: Descriptions hard soft rules capture flag.
learning algorithm access known truth assignment atoms. testing phase,
still access state observed atoms, infer assignment hidden
atoms.
Figure 3 gives English description hard soft rules low-level movement
player interactions within capture flag. Corresponding formulas language ML
shown Figures 5 6.
97

fiS ADILEK & K AUTZ

Predicate
capturing(a, b, t)
enemies(a, b)
adjacent(c1 , c2 )
failedCapturing(a, b, t)
failedFreeing(a, b, t)
freeing(a, b, t)
isCaptured(a, t)
isFailedCaptured(a, t)

Type
hidden
observed
observed
hidden
hidden
hidden
hidden
hidden

isFailedFree(a, t)

hidden

isFree(a, t)

hidden

onEnemyTer(a, t)
onHomeTer(a, t)
samePlace(a, b, t)

observed
observed
hidden

snap(a, c, t)

hidden

Meaning
Player capturing b time t.
Players b enemies.
Cells c1 c2 mutually adjacent, c1 = c2 .
Player unsuccessfully capturing b time t.
Player unsuccessfully freeing b time t.
Player freeing b time t.
Player captured state time t.
time t, player state follows
unsuccessful attempt capturing a.
state capabilities free.
time t, player state follows
unsuccessful attempt freeing a.
state capabilities captured.
Player free state time
(isFree(a, t) isCaptured(a, t)).
Player enemy territory time t.
Player home territory time t.
Players b either snapped common cell
two adjacent cells time t.
Player snapped cell c time t.

Table 1: Summary logical predicates models use. Predicate names containing word
failed introduced Markov logic theory augmentation method described
Section 5.2.1.

compare unified approach four alternative models. first two models (baseline
baseline states) purely deterministic separate denoising GPS data
labeling game events. implemented Perl. involve
training phase. third alternative model dynamic Bayesian network shown Figure 4.
Finally, two models cast Markov logic: two-step ML model unified ML
model itself. unified model handles denoising labeling joint fashion, whereas
two-step approach first performs snapping given geometric constraints subsequently labels
instances capturing freeing. latter three models evaluated using four-fold crossvalidation order test given game, first train model three games.
models access following observed data: raw GPS position player
time indication whether enemy home territory, location 3 3 meter
cell, cell adjacency, list pairs players enemies. tested five models
observed data. following describes model detail.
Baseline Model (B)
model two separate stages. First snap reading nearest cell afterward label instances player capturing player b. labeling rule simple:
98

fiL OCATION -BASED R EASONING C OMPLEX ULTI -AGENT B EHAVIOR

loop whole discretized (via snapping) data set output capturing(a, b, t) every
time encounter pair players b snapped (in first step)
either cell two mutually adjacent cells time t, enemies,
home territory b not. Freeing recognition considered simple model
since need notion persisting player states (captured free) order model
freeing meaningful way.
Baseline Model States (B+S)
second model builds top previous one introducing notion players states. player captures player b time t, b enters captured state (in logic,
isCaptured(b, + 1)). b remains captured state moves (is snapped different cell later time) game ends. per rules CTF, player captured
state cannot captured again.
Thus, model works like previous one except whenever label
capturing event, checks states involved players outputs capturing(a, b, t)
b captured state.
Freeing recognition implemented analogous way capturing recognition. Namely,
every time captured player b transition free state, check b
free teammate nearby (again, within adjacent cells). case, output
freeing(a, b, t).
Dynamic Bayesian Network Model (DBN)
dynamic Bayesian network model viewed probabilistic generalization
baseline model states. structure DBN model one player shown
Figure 4. time slice, one hidden node four observed nodes,
represent binary random variables. want infer likely state
player given time course game. state either free captured
hidden testing time. four observed random variables per time step model
players motion (M ), presence absence least one enemy (EN ) ally (AN ) player
nearby, finally players location either home enemy territory (ET ). player
modeled separate DBN. Therefore, fourteen instantiated DBNs game,
within one game, DBNs share set parameters.
Note DBN model perform GPS trajectory denoising itself. make fair
comparison Markov logic models, use denoising component Markov
logic theory using constraints H1 S1S3 (in Figure 3). produces denoised
discretization data subsequently fed DBN model. random variables
within DBN capture notion player movement players nearby one
another defined occupancy grid game area, like two deterministic
baseline models. Namely, player said moving time + 1
snapped two different nonadjacent cells times. Similarly, two players
nearby snapped either cell two adjacent cells.
Two-Step ML Model (2SML)
two-step approach, two separate theories Markov logic. first theory
used perform preliminary snapping player trajectories individually us99

fiS ADILEK & K AUTZ

ETt

...

ENt

ANt

ETt+1

ENt+1

St

St+1

Mt

Mt+1

ANt+1

...

Figure 4: Two consecutive time slices dynamic Bayesian network modeling state
individual player P observations. Shaded nodes represent observed random
variables, unfilled denote hidden variables. random variables binary. (ETt = 1
P enemy territory time t, ENt = 1 enemy nearby time
t, ANt = 1 ally nearby time t, finally Mt = 1 P moved
time 1 t. value hidden state St 1 P captured time
0 P free.)

ing constraints H1 S1S3 (in Figure 3). theory identical one used
discretization step DBN model above.
second theory takes preliminary denoising list observed atoms
form preliminarySnap(a, c, t) (meaning player snapped cell c time t) uses
remaining constraints label instances capturing freeing, considering cell adjacency manner previous three models. two-step model constitutes
decomposition unified model (see below) overall contains virtually formulas, except 2SML operates observed preliminarySnap predicate, whereas unified
model contains hidden snap predicate instead. Thus omit elaborating here.
Unified ML Model (UML)
unified approach, express hard constraints H1H8 soft constraints S1
S7 (Figure 3) Markov logic single theory jointly denoises data labels game
events. Selected interesting formulas shown Figure 6their labels correspond
listing Figure 3. Note formulas S1S3 contain real-valued functions d1 , d2 , d3
respectively. d1 returns distance agent cell c time t. Similarly, d2 returns
dissimilarity two consecutive snapping vectors5 given agent position time
+ 1 location centers two cells c1 c2 . Finally, since people prefer
move straight lines, function d3 quantifies lack smoothness three consecutive
segments trajectory. Since wp , ws , wt assigned negative values
training, formulas S1S3 effectively softly enforce corresponding geometric constraints.
5. initial point snapping (projection) vector raw GPS reading terminal point center
cell snap reading to.

100

fiL OCATION -BASED R EASONING C OMPLEX ULTI -AGENT B EHAVIOR

presence functions d1 d3 renders formulas S1S3 hybrid formulas. means
inference time, instantiated logical part formula evaluates either 1 (true)
0 (false), turn multiplied product corresponding function value
formula weight.
see train, test, evaluate four models, perform
multi-agent activity recognition task Section 6. Next, turn supervised learning method
augmenting unified ML model order recognize successful failed attempts
multi-agent activities.
Hard formulas:
a, c : snap(a, c, t)
0

(H1)
0

0

a, c, c , : (snap(a, c, t) c 6= c ) snap(a, c , t)
a1 , a2 , : freeing(a1 , a2 , t) samePlace(a1 , a2 , t) isFree(a1 , t)

(H2)

enemies(a1 , a2 ) isCaptured(a2 , t) isFree(a2 , + 1)

onEnemyTer(a1 , t) onEnemyTer(a2 , t)

a1 , a2 , : capturing(a1 , a2 , t) samePlace(a1 , a2 , t) isFree(a1 , t)

(H3)

enemies(a1 , a2 ) isFree(a2 , t) isCaptured(a2 , + 1)

onHomeTer(a1 , t) onEnemyTer(a2 , t)

a1 , a2 , : samePlace(a1 , a2 , t) c1 , c2 : snap(a1 , c1 , t) snap(a2 , c2 , t) adjacent(c1 , c2 )



a, : (t = 0) isFree(a, t)

(H4)

a, : isCaptured(a, t) isFree(a, t)

(H5)

a, : (isFree(a, t) isCaptured(a, + 1)) (=1 a1 : capturing(a1 , a, t))

(H6)

a, : (isCaptured(a, t) isFree(a, + 1)) (=1 a1 : freeing(a1 , a, t))

(H7)

a, t, c : (isCaptured(a, t) isCaptured(a, + 1) snap(a, c, t)) snap(a, c, + 1)

(H8)

Figure 5: hard formulas Markov logic. See corresponding rules Figure 3 English
description Table 1 explanation predicates. implementation,
actual rules written syntax used theBeast, Markov logic toolkit. (=1
denotes unique existential quantification, designates exclusive or.)

5.2 Learning Models Failed Attempts
work described above, manually designed structure Markov logic network
models capture flag domain allows us jointly denoise raw GPS data recognize
101

fiS ADILEK & K AUTZ

Soft formulas:


a, c, : snap(a, c, t) d1 (a, c, t) wp

(S1)



a,c1 , c2 , : snap(a, c1 , t) snap(a, c2 , + 1) d2 (a, c1 , c2 , t) ws

(S2)



a,c1 , c2 , c3 , : snap(a, c1 , t) snap(a, c2 , + 1) snap(a, c3 , + 2) d3 (a, c1 , c2 , c3 , t) wt
a1 , a2 , : [(enemies(a1 , a2 ) onHomeTer(a1 , t)

(S3)
(S4)

onEnemyTer(a2 , t) isFree(a2 , t)
samePlace(a1 , a2 , t)) capturing(a1 , a2 , t)] wc
a1 , a2 , : [(enemies(a1 , a2 ) onEnemyTer(a1 , t)

(S5)

onEnemyTer(a2 , t) samePlace(a1 , a2 , t) isFree(a1 , t)
isCaptured(a2 , t)) freeing(a1 , a2 , t)] wf


a, c, : capturing(a, c, t) wcb

(S6)

a, c, : [freeing(a, c, t)] wf b

(S7)

Figure 6: Soft formulas Markov logic. See corresponding rules Figure 3 English description. soft formula
written

traditional quantified finite first-order logic
formula (e.g., a, c, : snap(a, c, t) ), followed optional function (e.g., d1 (a, c, t)),
followed weight formula (e.g., wp ). syntax denotes inference
time, instantiated logical part formula evaluates either 1 (true) 0 (false),
effectively multiplied product corresponding function value
formula weight.

instances actual capturing freeing. show automaticallyin supervised
learning settingextend theory encompass correctly label successful actions,
also failed attempts interactions. is, given raw GPS data represent
CTF games, want new model label instances player captures (or frees) player
b successful captures (successful frees) instances player almost captures (or frees)
player b failed captures (failed frees). example, failed capturing mean instance
players interactions whereup pointit appeared capturing b, carefully
consider events (potentially) preceded well impacts supposed capture
future unfolding game, conclude false alarm capture actually
occurred. words, conditions capture right, later on, pivotal
moment foiled capturing agents attempt.
activities (capturing freeing), model jointly finds optimal separation success failure. Note since cast model second-order Markov logic,
learn, e.g., isolated rule separates successful freeing failed attempt freeing.
Rathersince capturing freeing events (both actual failed) related thus labeling
activity as, say, successful capturing far-reaching impact past, present, future
102

fiL OCATION -BASED R EASONING C OMPLEX ULTI -AGENT B EHAVIOR

labelingwe learn separations joint unified way. Namely, structure (logical
form) importance (weight) formula theory considered consequences
influence axioms theory. system thus finds optimal balance success failure capturing freeing activities respect training data.
5.2.1 HEORY AUGMENTATION LGORITHM
follows, describe Markov logic theory augmentation algorithm (Algorithm 1).
clarity, explain works concrete context ML models capture flag
discussed previous sections. However, underlying assumption successful actions
many ways similar failed counterparts, minorbut crucialdeviations cause
failure occur, often hold beyond capture flag. Therefore, algorithm applicable
domains different activities, long modeled Markov logic.
Algorithm 1 : Extend ML theory model successful well failed activities.
Input: A: set activities
MS : ML theory models successful instances activities
S: set examples successful activities
F : set examples failed activities
Output: MS+F : augmented ML model learned weights models successful
attempted activities
I: intended goals activities
1:
2:
3:
4:
5:
6:
7:

M2S liftToSecondOrderML(MS , A)
M0S instantiate(M2S , A)
findIncompatibleFormulas(F , M0S )
MS+F M0S \I
MS+F learnWeights(S, F , MS+F )
MS+F removeZeroWeightedFormulas(MS+F )
return MS+F ,

high-level, augmentation algorithm belongs family structure learning methods. Starting seed model successful actions, searches new formulas
added seed theory order jointly model successfully unsuccessfully carried
actions. declarative language biasessentially rules exploring hypothesis space candidate structuresis defined implicitly notion given activity, structure
unsuccessful attempts similar successful attempts. Therefore, augmentation algoritm
goes inflation stage, formulas seed theory generalized, followed
refinement stage, superfluous incompatible formulas inflated model pruned
away. refinement step also optimizes weights within newly induced theory.
discuss process detail.
input theory augmentation algorithm consists initial first-order ML theory MS
models successful capturing freeing (such unified ML model defined Section 5.1
contains formulas shown Figures 5 6), set activities interest A, set
examples successful (S) well failed (F ) captures frees. MS need
weights soft formulas specified. case missing, learn scratch

103

fiS ADILEK & K AUTZ

final steps augmentation algorithm. weights specified, final weight learning
step MS+F leverage estimate initial weight values. specified
set predicate names, e.g., {capturing, freeing}. example sets F describes game
segment constitutes truth assignment appropriate literals instantiated MS . Table 2
shows two toy examples sets F three time steps. Since goal learn model
failed (and successful) attempts supervised way, example game segment F contain
activities labeled predicates failedCapturing() failedFreeing().
MS contains hybrid formulas (such formulas S1S3 Figure 6), appropriate function
definitions provided part F well. definition consists implicit mapping
input arguments function values. instance, function d1 formula S1 quantifies L2
distance
agent cell c time projected Mercator space: d1 (a, c, t) =
p
(a.gpsXt c.gpsX)2 + (a.gpsYt c.gpsY )2 .
system goes following process order induce new theory MS+F
augments MS definition failed attempts activity already defined MS .
First lift MS second-order Markov logic variabilizing predicates correspond
activities interest (step 1 Algorithm 1). yields lifted theory M2S . concretely, order apply technique domain, introduce new predicate variables captureType (whose domain {capturing, failedCapturing}), freeType (over {freeing, failedFreeing}),
stateType (over {isCaptured, isFailedCaptured, isFree, isFailedFree}). instance, variabilizing first-order ML formula freeing(a, b, t) enemies(a, b) yields second-order ML formula
freeType(a, b, t) enemies(a, b) (note freeType variable). Instantiating back
first-order yields two formulas: freeing(a, b, t) enemies(a, b) failedFreeing(a, b, t)
enemies(a, b).
far agents behavior concerned, CTF domain, isCaptured equivalent isFailedFree, isFree equivalent isFailedCaptured. soon see, theory augmentation
process learns equivalence classes relationships states training examples expanding subsequently refining formula H5 Figure 5. could work
isCaptured predicate negation represent agents states, feel explicit failure states makes discussion clearer. Furthermore, future work need address
hierarchies activities, including failures. context, representation explicit failure
states may convenient, may necessary.
Next, instantiate predicate variables M2S produce new first-order ML theory M0S
contains original theory MS entirety plus new formulas correspond failed captures frees (step 2). Since events are, e.g., near-captures appear similar actual successful
captures, hypothesis need drastically modify original successful formulas order model failed activities well. practice, process lifting
instantiating indeed results good seed theory. could emulate lifting grounding
steps scheme copying formulas renaming predicates duplicates appropriately,
cast approach principled second-order Markov logic, ties work closely
previous research results extensible framework. Specifically, second-order Markov
logic successfully used deep transfer learning (Davis & Domingos, 2009) predicate invention (Kok & Domingos, 2007). Therefore, interesting direction future work
combine theory augmentation refinement transfer inductive learningoperating
second-order MLto jointly induce models failed attempts different activities different
domains, starting single model successful activities source domain.
104

fiL OCATION -BASED R EASONING C OMPLEX ULTI -AGENT B EHAVIOR

Set S: Successful Capture
enemies(P1 , P2 )
enemies(P2 , P1 )
onEnemyTer(P2 , 2)
onEnemyTer(P2 , 3)
capturing(P1 , P2 , 2)
isFree(P1 , 1)
isFree(P1 , 2)
isFree(P1 , 3)
isFree(P2 , 1)
isFree(P2 , 2)
isCaptured(P2 , 3)
snap(P1 , C5, 1)
snap(P1 , C10, 2)
snap(P1 , C10, 3)
snap(P2 , C9, 1)
snap(P2 , C10, 2)
snap(P2 , C10, 3)
samePlace(P1 , P2 , 2)
samePlace(P2 , P1 , 2)
samePlace(P1 , P2 , 3)
samePlace(P2 , P1 , 3)

Set F: Failed Capture
enemies(P4 , P5 )
enemies(P5 , P4 )
onEnemyTer(P5 , 1)
onEnemyTer(P5 , 2)
onEnemyTer(P5 , 3)
failedCapturing(P4 , P5 , 2)
isFree(P4 , 1)
isFailedCaptured(P4 , 1)
isFree(P4 , 2)
isFailedCaptured(P4 , 2)
isFree(P4 , 3)
isFailedCaptured(P4 , 3)
isFree(P5 , 1)
isFailedCaptured(P5 , 1)
isFree(P5 , 2)
isFailedCaptured(P5 , 2)
isFree(P5 , 3)
isFailedCaptured(P5 , 3)
snap(P4 , C17, 1)
snap(P4 , C34, 2)
snap(P4 , C0, 3)
snap(P5 , C6, 1)
snap(P5 , C34, 2)
snap(P5 , C7, 3)
samePlace(P4 , P5 , 2)
samePlace(P5 , P4 , 2)

Table 2: Two examples logical representation successful (S) well failed (F ) capture
events input Algorithm 1. closed-world assumption applied, therefore
atoms listed assumed false. clarity, omit listing adjacent()
predicate.

Typical structure learning inductive logic programming techniques start initial (perhaps empty) theory iteratively grow refine order find form fits training data
well. order avoid searching generally huge space hypotheses, declarative bias either
specified hand mined data. declarative bias restricts set possible refinements formulas search algorithm apply. Common restrictions include limiting
formula length, adding new predicate formula shares least one variable
predicate already present formula. hand, approach, first
generate seed theory instantiating activity-related predicate variables. put
105

fiS ADILEK & K AUTZ

context structure learning, expand input model order generate large seed theory,
apply bottom-up (data-driven) learning prune seed theory, whereby training data
guides search formulas remove well optimal set weights remaining
formulas. conjecture failed attempt activity always violates least one constraint
holds successful executions activity. experiments support conjecture.
pruning done steps 3 4 Algorithm 1. function findIncompatibleFormulas(F ,
M0S ) returns set hard formulas M0S incompatible set examples failed
interactions F . say formula c compatible respect set examples F F
logically entails c (F |= c). Conversely, F entail c, say c incompatible w.r.t.
F . explain find incompatible formulas next section.
step 4 Algorithm 1, simply remove incompatible formulas (I) theory.
point, MS+F model, hard formulas guaranteed logically consistent
examples failed activities (because removed incompatible hard formulas), well
successful activities (because logically consistent start with). However,
soft formulas MS+F missing properly updated weights (in Markov logic, weight
hard formula simply set +). Therefore, run Markov logic weight learning using theBeast
package (step 5).
Recall theBeast implements cutting plane meta solving scheme inference Markov
logic, ground ML network reduced integer linear program subsequently
solved LpSolve ILP solver. chose approach opposed to, e.g., MaxWalkSAT
may find solution merely locally optimal, since resulting run times still relatively
short (under hour even training testing even complex model). Weights
learned discriminatively, directly model posterior conditional probability hidden predicates given observed predicates. set theBeast optimize weights soft
formulas via supervised on-line learning using margin infused relaxed algorithm (MIRA) weight
updates loss function computed number false positives false negatives
hidden atoms. Note soft formulas truly irrelevant respect
training examples, picked findIncompatibleFormulas() function,
weights set zero (or close zero) weight learning step (line 5 Algorithm 1).
zero-weighted formulas subsequently removed following step. Note weight
learning process need experience cold start, initial setting weights
inherited input theory MS .
Finally, return learned theory MS+F , whose formulas optimally weighted respect training examples. Experiments Results section below, use MS+F
recognize successful failed activities. Algorithm 1 also returns incompatible hard formulas I. see used extract intended goal activities Section 5.3,
first, let us discuss step 3 Algorithm 1 detail.
5.2.2 C ONSISTENCY C HECK : F INDING NCOMPATIBLE F ORMULAS
turn method finding incompatible formulas (summarized Algorithm 2). Since
method leverages satisfiability testing determine consistency candidate theories
possible worlds (examples),6 Algorithm 2 viewed instance learning
interpretationsa learning setting inductive logic programming literature (De Raedt, 2008).
6. often referred covers relation inductive logic programming.

106

fiL OCATION -BASED R EASONING C OMPLEX ULTI -AGENT B EHAVIOR

Algorithm 2 (findIncompatibleFormulas). Find formulas ML theory logically inconsistent examples execution failed activities.
Input: F : set examples failed activities
: unrefined ML theory successful failed activities
Output: smallest set formulas appear unsatisfiable worlds F
1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:

extractObjects(F )
Thard \ Tsoft
integer n 0
boolean result false
result == false
c Thard
remove new n-tuple formulas c
current n, n-tuples tested
nn+1
end
result testSAT(F , c , O)
end
return Thard \ c

input, take set examples failed activities F seed theory (e.g., produced
step 2 Algorithm 1). output smallest set hard formulas appear
logically inconsistent F . algorithm first extracts set objects appear
F (step 1 Algorithm 2), keeping track type object. example, suppose two example worlds F shown Table 3. extractObjects(F ) returns
{P1 , P2 , P7 , P8 , C3 , C5 , 1, 2}.
Example 1
snap(P1 , C5 , 1)
snap(P2 , C5 , 1)
failedCapturing(P1 , P2 , 1)

Example 2
snap(P7 , C3 , 2)
snap(P8 , C3 , 2)
failedFreeing(P2 , P5 , 2)

Table 3: Two simple examples logical representation failed capture event.

step 2, limit hard formulas testing compatibility. since
prove incompatibility hard formulas. Soft constraints violated many times
data yet may want eliminate them. Instead, want merely adjust
weights, exactly approach. Therefore, Thard contains hard formulas
appear . Next, lines 5 12, check entire unmodified Thard compatible
(since n = 0, remove formulas). compatible, return empty set
indicating hard formulas original seed theory compatible examples.
detect incompatibility, need remove some, perhaps even all, hard formulas
order arrive logically consistent theory. Therefore, incrementally start removing n-tuples
formulas. is, subsequent |Thard | iterations loop, determine
107

fiS ADILEK & K AUTZ

restore consistency removing one hard formulas Thard . can, return
set Thard \ fi , fi identified removed incompatible formula. consistency cannot
restored removing single formula, turn begin considering pairs formulas (n = 2),
triples (n = 3), etc. find pruned theory c consistent examples.
general, need consider n-tuples formulas, rather testing formula
isolation. due disjunctive formulas conjunction possibly incomplete truth
assignment training data. Consider following theory propositional logic:
f1 = b
f2 = b c
Data: c
(Following closed-world assumption, negated atom c would actually appear training data, explicitly include example clarity.) f1 f2 individually consistent data, f1 f2 inconsistent data. complicated examples
constructed, every group k formulas inconsistent data, even though
individual formulas are. special case truth values atoms training examples known, formulas tested consistency individually, reduces original
exponential number iterations Algorithm 2 executes, worst case, linear complexity.
interesting direction future work explore applications logical methods lower
computational cost general case partially observed data.
also note hard formulas model physical constraints inviolable rules capture
flag, therefore hold universally. Appropriately, formulas eliminated Algorithm 2. example, consider formula H1 Figure 5, asserts player occupies
exactly one cell given time. formula satisfied games include successful failed activities. hand, consider formula H8 figure. contains
captured player cell captured (following captured players cannot move rule
CTF). holds successful capturing events, necessarily hold failed
attempts capturing. Therefore, rule H8 expanded via second-order ML,
derived formulas going consistent observations.
Specifically, candidate formula Equation 6 pruned away, inconsistent
training examples, i.e., players nearly captured continue free move about.
However, remaining three variants formula H8 pruned away. Equation 7
always evaluate true, since someone attempts re-capture already captured player a,
indeed remain stationary. Similarly, Equation 8 also consistent example CTF games
failed attempt capture immediately followed successful capture,
captured player remain place time onward. Finally, Equation 9 compatible well,
since original formula H8 consistent observations.

a, t, c : isFailedCaptured(a, t) isFailedCaptured(a, + 1) snap(a, c, t) snap(a, c, + 1)
(6)

a, t, c : isCaptured(a, t) isFailedCaptured(a, + 1) snap(a, c, t) snap(a, c, + 1) (7)

108

fiL OCATION -BASED R EASONING C OMPLEX ULTI -AGENT B EHAVIOR


a, t, c : isFailedCaptured(a, t) isCaptured(a, + 1) snap(a, c, t) snap(a, c, + 1) (8)


a, t, c : isCaptured(a, t) isCaptured(a, + 1) snap(a, c, t) snap(a, c, + 1)

(9)

function testSAT() (line 11 Algorithm 2) checks whether given candidate theory c
compatible examples F following process. First, ground c using objects
O, thereby creating ground theory G. example, c = {p(x) q(x)} = {B, W },
grounding would G = {p(B) q(B), p(W ) q(W )}. check G Fhidden
satisfiable using miniSAT solver, Fhidden simply set hidden atoms appear
F . Intuitively, corresponds testing whether plug worlds F c
satisfying hard constraints. Though satisfiability NP-complete problem, practice
testSAT() completes within tenths second even largest problems CTF domain.
instance, suppose Fhidden = {p(B), q(B)}. test satisfiability formula



p(B) q(B) p(W ) q(W ) p(B) q(B).
case cannot satisfy since forced set p(B) true q(B) false,
renders first clauseand therefore whole formulafalse.
alternative approach pruning formulas via satisfiability testing, described,
would treat types formulas (hard soft) inflated theory M0S strictly soft
formulas learning weight formula examples successful failed game
events. However, introduces several complications negatively impact systems performance well model clarity. First, number formulas inflated theory
exponentially larger seed theory. instantiation second-order ML representation quantified limit expansion, still worst-case exponential blow-up.
treating formulas soft ones, need potentially learn many weights.
especially problematic activities occur rarely, may enough training data
properly learn weights. Eliminating hard candidate formulas proving inconsistent
dramatically reduces number parameters model. satisfiability testing
NP-complete, weight learning Markov logic entails running inference multiple times,
#P-complete problem.
second reason distinguishing soft hard formulas resulting clarity
elegance final learned model MS+F . Even situations enough training data
properly learn large number weights, run overfitting problems, neither
structure parameters model represent domain natural way. experiments
shown skip pruning stage (steps 3 4 Algorithm 1), models recognition
performance differ pruned model significant way (p-value 0.45).
However, end large number soft formulas mixture positive negative
weights learning algorithm carefully tuned balanced fit training data.
however bear little relationship concepts underlying domain. make
hard human expert analyze model, makes even harder modify
model.
109

fiS ADILEK & K AUTZ

reasons, softening hard formulas is, general, infeasible. interesting direction
future work identify small amount key inconsistent hard formulas soften,
eliminating rest inconsistent hard formulas. however entails searching large
space candidate subsets softened formulas, iteration requires expensive re-learning
weights.
Note Algorithm 2 terminates soon finds compatible theory requires smallest
number formula-removals. also experimented active learning component
system, modify Algorithms 1 2 present several possible refinements
theory user selects one looks best. proposed modifications
shown ML theory level modified sections (formulas) highlighted well
data level program shows inferred consequences modifications.
candidate modification, corresponding consequences displayed collection animations
animation shows results activity recognition would committed
particular candidate theory. Note even people background ML
interact system since visualization easy understand. Interestingly, case
captures frees, least modified theory off-line version algorithm finds
also best one therefore need query user. One view differential
variant Occams razor. However, different activities domains, active learning
approach may worth revisiting leave exploration future work.
Finally, general structure learning techniques statistical-relational AI inductive
logic programming applicable substitute theory augmentation algorithm
several reasons. main reason that, efficiency reasons, existing techniques literature
typically operate restricted set formula templates. is, consider Horn
clauses, formulas without existential quantifier, formulas k literals
l variables, on. set restrictions part language bias given
approach. principle, structure learning possible without language bias, one often
carefully define one sake tractability (see Section 7 details). approach,
language bias defined implicitly discussed Section 5.2.1.
5.3 Extracting Goal Success Failure
Recall applying theory augmentation process (Algorithm 1) CTF seed theory
successful interactions (shown Figures 5 6) induces new set formulas capture
structure failed activities ties together existing formulas seed theory.
logically inconsistent formulas Algorithm 2 returns ones satisfiable
worlds failed activities. time, variants formulas consistent
examples successful actions occurring games. Therefore, represents difference
theory models successful activities augmented theory successful
failed actions, derived it. Intuitively, difference success
failure viewed intended purpose given activity rational agent executes,
consequently goal agent mind engages particular activity.
next section, explore goals extracted CTF domain fashion.
concludes discussion models methodology, turn experimental
evaluation framework presented above.

110

fiL OCATION -BASED R EASONING C OMPLEX ULTI -AGENT B EHAVIOR

6. Experiments Results
evaluate approach along three major directions outlined Section 5 (Methodology),
focusing answering four research questions formulated ibidem. structure
section closely follows Methodology section.
nutshell, first interested Markov logic models perform standard
multi-agent activity recognition tasklabeling successful activitiesand performance
compares alternative models. Second, examine augmented model captures
successful failed attempts activities. model MS+F induced Algorithm 1,
also lets us extract intended goal activities question. Third, compare performance
MS+F task jointly recognizing four activities alternative model.
Finally, investigate extent reasoning failed attempts help recognition
successfully executed activities.
experiments performed capture flag dataset consisting four separate games.
dataset summarized Table 4, game list number raw GPS readings
number instances activity interest. evaluate models via four-fold crossvalidation, always training three games (if training required model) testing
fourth. experimental condition below, report precision, recall, F1 scores attained
respective model four cross-validation runs. purposefully chosen
split data cross-validation fold directly corresponds separate game CTF
conceptual convenience clarity. discussed above, events occurring games often
far-reaching consequences. example, captured players never freed allies.
Therefore, capture beginning game typically profoundly influences entire rest
game. reason, splitting games randomly even manually would introduce unnecessary
complications, segments would dependencies segments. enforcing
fold exactly corresponds different game, make fold self-contained.
quantify statistical significance pair-wise differences models, use
generalized probabilistic interpretation F1 score (Goutte & Gaussier, 2005). Namely, express
F1 scores terms gamma variates derived models true positives, false positives, false
negatives ( = 0.5, h = 1.0, cf., Goutte & Gaussier, 2005). approach makes possible
compare results future work may apply alternative models similar, identical,
datasets. future comparison may, instance, include additional games introduce random
splits data. note standard statistical significance tests cannot applied situations. p-values reported one sided, interested models performance significantly
improves level sophistication increases.
6.1 Recognition Successful Activities
Recall two-step (2SML) unified (UML) Markov logic models, specify
Markov logic formulas hand optimize weights soft formulas via supervised online learning. run modified version theBeast software package perform weight learning
MAP inference. theBeast implements cutting plane meta solving scheme inference
Markov logic, ground ML network reduced integer linear program subsequently solved LpSolve ILP solver. chose approach opposed to, e.g., MaxWalkSAT
get stuck local optimum, since resulting run times still relatively short (under
hour even training testing even complex model).
111

fiS ADILEK & K AUTZ

Game 1
Game 2
Game 3
Game 4
Total

#GPS
13,412
14,420
3,472
10,850
42,154

#AC
2
2
6
3
13

#FC
15
34
12
4
65

#AF
2
2
0
1
5

#FF
1
1
2
0
4

Table 4: CTF dataset overview: #GPS total number raw GPS readings, #AC #FC
number actual (successful) failed captures respectively, analogously freeings
(#AF #FF).

weight learning time, use margin infused relaxed algorithm (MIRA) weight updates loss function computed number false positives false negatives
hidden atoms, described Methodology section. discretization step
dynamic Bayesian network model (DBN) implemented Markov logic also executed
fashion. DBN model trained via maximum likelihood described Section 4.2.
two deterministic baselines (B B+S) require training phase.
inference time, interested likely explanation data. Markov logic,
maximum posteriori inference reduces finding complete truth assignment satisfies
hard constraints maximizing sum weights satisfied soft formulas. testing
time, theBeast Markov logic solver finds likely truth assignment hidden atoms
described above, section specifically interested values capturing
freeing atoms.
DBNs, likely explanation observations equivalent Viterbi decoding.
DBN model assigns either free captured state player every time step. label
transitions free captured state capturing transitions captured free
freeing. Note DBN model capable determining player freed captured,
model player freeing capturing. evaluation, give
benefit doubt assume always outputs correct actor.
models, inference done simultaneously entire game (on average, 10
minutes worth data). Note restrict inference (small) sliding time window.
experiments described show, many events domain definitely recognized
long occur. example, GPS noise may make impossible determine whether player
captured moment encounter enemy, player thereafter remains
place long time, possibility capture becomes certain.
Figures 7 8 summarize performance models successful capturing freeing
terms precision, recall, F1 score calculated four cross-validation runs. clarity,
present results two separate plots, model jointly labeling capturing
freeing activities. consider baseline model freeing recognition activity
makes little sense without notion player state (captured free).
see unified approach yields best results activities. Let us focus
capturing first (Figure 7). Overall, unified model labels 11 13 captures correctlythere

112

fiL OCATION -BASED R EASONING C OMPLEX ULTI -AGENT B EHAVIOR

Capturing Recogni/on
1.00

1.00
0.80

0.69

0.69

0.77

0.87
0.77

1.00

0.92
0.85

0.60

Precision

0.40
0.20
0.00

Recall

0.26
0.16
0.01 0.02

0.03 0.06

B

B+S

F1

DBN

2SML

UML

Figure 7: Comparison performance five models capturing recognition joint
inference capturing freeing events. See Table 5 statistical significance
analysis pairwise differences models. (B = baseline model, B+S = baseline
model states, 2SML = two-step Markov logic model, UML = unified Markov logic
model)

two false negatives. fact, two capture events missed models
involve two enemies appear unusually far apart (about 12 meters) raw data. Even
unified approach fails instance since cost adjusting players trajectoriesthereby
losing score due violation geometry-based constraintsis compensated
potential gain labeling additional capture.
Note even two-step approach recognizes 10 13 captures. compared
unified model, misses one additional instance involved players, moderately
far apart, snapped mutually nonadjacent cells. hand, unified model
fail situation limited prior nonrelational snapping nearby cells.
However, difference performance dataset statistically significant even
0.05 level (p-value 0.32).
deterministic baseline models (B B+S) perform poorly. Although yield
respectable recall, produce overwhelming amount false positives. shows even
relatively comprehensive pattern matching work domain. Interestingly,
performance DBN model leaves much desired well, especially terms precision.
DBN model significantly better baselines (p-value less 5.9 105 ),
also achieves significantly worse performance Markov logic models (p-value less
0.0002; see Table 5).
Table 5 summarizes p-values pairwise differences models actual (i.e., successful)
capturing. difference Markov logic-based models (2SML UML)

113

fiS ADILEK & K AUTZ

Freeing Recogni+on
1.00

1.00

1.00

0.80

0.75
0.57

0.60
0.40

0.40
0.20

0.20
0.15
0.13

0.22

0.60

Precision

0.40

Recall

0.29

F1

0.00
B+S

DBN

2-SML

UML

Figure 8: Comparison performance three models freeing recognition joint
inference capturing freeing events. See Table 6 statistical significance
analysis pairwise differences models. (B+S = baseline model states,
2SML = two-step Markov logic model, UML = unified Markov logic model)

B
B+S
DBN
2SML

B+S
0.0192
-

DBN
3.6 106
5.9 105
-

2SML
5.1 107
9.4 106
0.0002
-

UML
2.9 107
1.4 106
8.0 105
0.3230

Table 5: Summary statistical significance (one sided p-values) pairwise differences F1 scores models actual capturing. (B = baseline model, B+S = baseline
model states, DBN = dynamic Bayesian network model, 2SML = two-step Markov
logic model, UML = unified Markov logic model)

statistically significant (p-value 0.32), pairwise differences F1 scores models
significant 0.02 level, often even much lower p-values.
Though unified model still outperforms alternatives case freeing recognition
well, performance ideal compared capture recognition case (Figure 8).
correctly identifies 3 5 freeing events games, produce false
positives. partly due dependency freeing capturing. failure model
recognize capture precludes recognition future freeing. Another reason extreme
sparseness freeing events (there five 40,000+ datapoints). Finally,

114

fiL OCATION -BASED R EASONING C OMPLEX ULTI -AGENT B EHAVIOR

B+S
DBN
2SML

DBN
0.2739
-

2SML
0.0733
0.1672
-

UML
0.0162
0.0497
0.2743

Table 6: Summary statistical significance (one sided p-values) pairwise differences F1 scores models actual freeing. (B+S = baseline model states, DBN =
dynamic Bayesian network model, 2SML = two-step Markov logic model, UML = unified
Markov logic model)

instances players barely move freed. may occur number reasons
ranging already occupying strategic spot simply tired. freeing instances
challenging automated system, even people familiar game recognize
(several situations would extremely hard disambiguate didnt access
notes data collection).
two-step ML model slightly worse job unified model freeing recognition.
correctly identifies 2 5 freeings reasons capturing recognition
case. Similarly models actual captures, difference unified two-step freeing
models statistically significant (p-value 0.27).
Table 6 summarizes p-values pairwise differences models actual (i.e., successful) freeing. see difference B+S UML models statistically
significant (p-value 0.01), whereas differences rest model pairs
statistically significant. Since five instances successful freeing, 2SML model
perform significantly better B+S model 0.05 significance level (p-value
0.07). However, UML model achieves better recognition results even DBN model
high confidence (p-value less 0.05). Therefore, see although 2SML model strictly
dominates non-Markov logic models evaluated capturing recognition, need full
power unified ML model strictly outperform nonrelational alternatives freeing.
suggests move complex interdependent activities, relational unified
modeling approaches winning larger larger margins.
Even though statistical significance tests suggest 2SML likely give similar results
UML, important note 2SML, design, precludes recognition activities question
certain situations. Namely, experiments demonstrate, players snapped cells
far apart, two-step model even consider instances candidates
labeling, inevitably fails recognizing them. Therefore, one needs look beyond p-values
obtained comparing fully unified models various alternatives.
expected experiments capturing recognition, deterministic baseline models perform poorly freeing recognition well. produce overwhelming
amount false positives, also fail recognize freeing events.
Thus, see models cast Markov logic perform significantly better
deterministic baseline models, also better probabilistic, nonrelational, DBN model.
note DBN model potential quite powerful similar DBNs
applied great success previous work activity recognition location data (Eagle &
115

fiS ADILEK & K AUTZ

Pentland, 2006; Liao, Patterson, Fox, & Kautz, 2007). also many similarities twostep ML model. share denoising discretization step, operate
observed data. key difference DBN model considers players individually,
whereas two-step ML model performs joint reasoning.
Looking actual CTF game data, see several concrete examples hurts DBNs
labeling accuracy. instance, consider situation two allies captured near
other. Performing inference individual players isolation allows DBN model infer
two players effectively free other, even though reality captured cannot
so. occurs DBN model oblivious explicit states ones teammates
well opponents. Since capturing freeing interdependent, obliviousness DBN
model state actors negatively impacts recognition performance activities.
example gave illustrates one type freeing false positives. hallucinated freeings
create opportunities often lead false positives captures, creating vicious cycle. False
negatives freeing (capturing) events often occur players model incorrectly believes
already freed (captured) prior time.
Since Markov logic based models significantly betterwith high level confidence
alternatives fully relational, experiments validate hypothesis
need exploit rich relational temporal structure domain probabilistic way
time affirmatively answer research question Q1 (Can reliably recognize complex
multi-agent activities CTF dataset even presence severe noise?). Namely, show
although relatively powerful probabilistic models sufficient achieve high labeling
accuracy, gain significant improvements formulating recognition problem learning
inference Markov logic networks.
turn evaluation method learning models success failure
peoples activities.
6.2 Learned Formulas Intentions
Applying theory augmentation process (Algorithm 1) CTF seed theory (shown Figures 5 6) induces new set formulas capture structure failed activities ties
together existing formulas theory. call model MS+F . Figure 9 shows
examples new weighted formulas modeling failed freeing capturing attempts appear
MS+F .
First, note system correctly carries basic preconditions activity (contrast
formulas S4 S40 S5 S50 Figures 6 9 respectively). allows reliably
recognize successful failed actions instead of, e.g., merely labeling events
point time appear resemble capture near-capture. re-use preconditions directly
follows language bias theory augmentation algorithm.
Turning attention learned hard formulas, observe system correctly induced
equivalence classes states, also derived mutual exclusion relationships (H50 ).
furthermore tied new failure states corresponding instantaneous interactions (H60
H70 ).
Finally, algorithm correctly discovers rule player captured
must remain location (H8, Figure 5) key distinction successful
failed capture (since players actually captured still move). Therefore, introduces

116

fiL OCATION -BASED R EASONING C OMPLEX ULTI -AGENT B EHAVIOR

appropriate rule failed captures (H80 , Figure 9) explicitly stating failed capturing
confine near-captured player remain stationary. analogous process yields fitting
separation failed successful freeings. Namely, model learns unsuccessfully
freed player remains stationary. learned difference success failure players
actions directly corresponds goal activity consequently intent rational actors. difference system outputs intended goal capturing activity (and
analogously freeing).
experimental results provide evidence resounding yes Q2 (Can models
attempted activities automatically learned leveraging existing models successfully performed actions?) Q3 (Does modeling success failure allow us infer respective
goals activities?) within CTF domain.
note instead applying automated theory augmentation method, person could,
principle, manually formulate Markov logic theory successful well failed activities
observing games. all, designed initial seed model successful
events. However, process extremely time consuming, one tends omit encoding facts
us, humans, seem self-evident need explicitly articulated machine (e.g.,
single person cannot ten different places once, player either free captured
both). also surprisingly easy introduce errors theory, difficult debug,
mostly complex weight learning techniques involved. Therefore, believe
theory augmentation method significant step forward enhancing models capabilities
requiring small amounts human effort. complexity domains models increases,
advantage gain larger larger importance.
6.3 Recognition Successful Failed Activities
compare performance model MS+F alternative (baseline) method
labels four activities following way. Similarly baseline states model successful interactions defined Section 5.1, two separate stages. First snap GPS
reading nearest cell applying geometric constraints (H1 S1S3) theory, afterward label instances activities. following labeling rule applied.
loop whole discretized (via snapping) data set look instances pair
players b snapped (in first step) either cell two adjacent cells
time t, enemies, b captured already, home territory b not.
b moves (is snapped different cell later time) without ally nearby, output
failedCapturing(a,b,t), otherwise output capturing(a,b,t). labeling rule freeing defined analogously four events tied together. also tested variant DBN model
introduced Section 5.1 two additional hidden state values node St : isFailedFree
isFailedCaptured. However, difference results obtained model statistically significant (p-value 0.38), therefore focus conceptually straightforward
baseline model described above.
Model MS+F evaluated using four-fold cross-validation (always training three games
testing fourth). Figure 10 compares models terms precision, recall, F1
score. Note four activities modeled jointly models. F1 score augmented
model significantly better baseline four target activities (p-value less
1.3 104 ).

117

fiS ADILEK & K AUTZ

a1 , a2 , : [(enemies(a1 , a2 ) onHomeTer(a1 , t)

(S40 )

onEnemyTer(a2 , t) samePlace(a1 , a2 , t) isFree(a1 , t)
isFree(a2 , t)) failedCapturing(a1 , a2 , t)] 11.206
a1 , a2 , : [(enemies(a1 , a2 ) onEnemyTer(a1 , t)

(S50 )

onEnemyTer(a2 , t) samePlace(a1 , a2 , t) isFree(a1 , t)
isCaptured(a2 , t)) failedFreeing(a1 , a2 , t)] 1.483
a1 , a2 , : [failedCapturing(a1 , a2 , t)] (0.0001)

(S60 )

a1 , a2 , : [failedFreeing(a1 , a2 , t)] (0.002)

(S70 )

a, : isFailedCaptured(a, t) isFree(a, t)

(H50 )

a, : isCaptured(a, t) isFailedFree(a, t)
a, : isFailedCaptured(a, t) isFree(a, t)
a, : isCaptured(a, t) isFailedFree(a, t)
a, : (isFree(a, t) isFailedCaptured(a, + 1)) (=1 a1 : failedCapturing(a1 , a, t))
a, : (isCaptured(a, t) isFailedFree(a, + 1)) (=1 a1 : failedFreeing(a1 , a, t))

(H60 )
(H70 )

a, t, c : (isFailedCaptured(a, t) isFailedCaptured(a, + 1) snap(a, c, t)) snap(a, c, + 1)
(H80 )

Figure 9: Example formulas, learned Algorithm 1, model unsuccessful capturing freeing events. crucial intent recognition formula (H80 ) highlighted bold. Formulas
eliminated Algorithm 2 preceded symbol, included
induced model MS+F . identity isCaptured(a, t) = isFree(a, t) applied throughout refining show formulas intuitive fashion. concreteness sake,
values learned weights come one cross-validation run (and similar
runs).

see baseline model has, general, respectable recall produces large
number false positives activities. false positives stem fact algorithm
greedy typically labels situation several players appear close
certain period time sequence many captures subsequent frees even though none
actually occurred. Model MS+F gives significantly better results takes full
advantage structure game probabilistic fashion. similar labeling
tendency case failed captures, single capture attempt often labeled
several consecutive attempts. hurts precision score, significant deficiency,

118

fiL OCATION -BASED R EASONING C OMPLEX ULTI -AGENT B EHAVIOR

0.15

Baseline

AC (13)

0.23

FC (65)

0.97

0.13
0.04

AF (5)

0.40

0.02
0.06

FF (4)
Augmented ML Model

0.46

0.09

F1

0.75

0.03

Recall
0.96
0.92
1.00

AC (13)
0.86

FC (65)

0.78

AF (5)

0.80

FF (4)

0.75

0

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

Precision

0.97

0.89
1.00
0.86
1.00

0.9

1

Figure 10: Performance baseline augmented (MS+F ) models joint recognition
successful failed capturing freeing. F1 score augmented model
significantly better baseline four target activities (p-value less
1.3 104 ). AC = actual (successful) capturing, FC = failed capturing, AF =
actual freeing, FF = failed freeing.

practice, small number short game segments labeled possible near-captures
useful well.
also note even though original model (UML) contain information
failed capturing failed freeing, performance MS+F respectable even two
newly introduced activities. provided examples game situations attempts
occur system augmented subsequently labeled four activities. Thus, see
indeed extend preexisting models automated fashion unified model
capable recognizing individual activities, also success failure peoples
behavior.
6.4 Effect Modeling Failed Attempts Recognition Successful Activities
address research question Q4 (Does modeling failed attempts activities improve performance recognizing activities themselves?), want see much recognition
attempted activities help modeling successful actions (the latter standard activity

119

fiS ADILEK & K AUTZ

Capturing

F1

0.92

Recall

0.85

Precision

+0.08

1.00

F1
Freeing

+0.04

0.75

Recall

+0.14

0.60

+0.20

Precision

1.00

0

0.1

0.2

0.3

0.4

Without Modeling Failure

0.5

0.6

0.7

0.8

0.9

1

Modeling Failure

Figure 11: Considering unsuccessfully attempted activities strictly improves performance standard activity recognition. Blue bars show scores obtained unified Markov logic
model considers successful activities (MS ). red bars indicate additive improvement provided augmented model considers successful
failed activities (MS+F , output Algorithm 1). model labels target activities jointly, separate capturing freeing plot clarity. Precision value
1 models. F1 scores obtained explicitly modeling failed attempts
statistically different F1 scores obtained without modeling attempts high
confidence level (p-value 0.20). However, results still show importance
reasoning peoples attempts recognizing activities; see text details.

recognition problem). Toward end, compare Markov logic model MS jointly labels
successful capturing freeing model MS+F jointly labels successful
failed attempts capturing freeing (see Section 5.2.1 detailed description two
models). However, evaluate terms precision, recall, F1 score successful
interactions, four types activities.
Figure 11 summarizes results. see evaluated actual capturing, MS+F
performs better MS , similarly freeing. However, difference F1 scores
model captures attempted successful activities (MS+F ) model successful activities (MS ) statistically significant (p-value 0.20). partly MS
already produces solid results, leaving little room improvement. Additionally, CTF
dataset contains relatively events interest. terms labeling performance testing time,
difference two models 11% (MS MS+F recognize, respectively,
120

fiL OCATION -BASED R EASONING C OMPLEX ULTI -AGENT B EHAVIOR

14 16 18 successful activities correctly). Thus, believe trends shown Figure 11
promising modeling attempted actions improve recognition performance capturing freeing, evaluation dataset larger number events needed show
difference statistically significant higher confidence level. However, mean
recognizing attempts unimportant. show above, induced augmented model
recognize failed (as well successful) activities complex CTF domain high accuracy,
argue significant contribution.
Finally, comparison MS MS+F shows applying learning algorithm augments model recognition capabilities hurt model labeling performance.
fact binary classification problems typically easier solve multi-class counterparts well reported machine learning literature (Allwein, Schapire, & Singer, 2001).
Therefore, introducing new activities model, especially automated way, likely degrade performance. Contrary intuition, experiments show MS+F worse
MS successful activity recognition (i.e., intersection) high confidence, even though
MS+F clearly richer useful.

7. Related Work
world single-agent location-based reasoning, work Bui (2003) presents evaluates system probabilistic plan recognition cast abstract hidden Markov memory model.
Subsequently, work Liao et al. (2004) implements system denoising raw GPS traces
simultaneously inferring individuals mode transportation (car, bus, etc.) goal destination. cast problem learning inference dynamic Bayesian network achieve
encouraging results. follow-up work, Liao et al. (2005) introduce framework locationbased activity recognition, implemented efficient learning inference relational
Markov network.
work Ashbrook Starner (2003) focuses inferring significant locations raw
GPS logs via clustering. transition probabilities important places subsequently
used number user modeling tasks, including location prediction. work Eagle
Pentland (2006) explores harnessing data collected regular smart phones modeling human
behavior. Specifically, infer individuals general location nearby cell towers Bluetooth devices various times day. Applying hidden Markov model (HMM), show
predicting person home, work, someplace else achieved 90% accuracy. Similarly, work Eagle Pentland (2009) extracts significant patterns signatures
peoples movement applying eigenanalysis smart phone logs.
work Hu, Pan, Zheng, Liu, Yang (2008) concentrates recognition interleaving
overlapping activities. show publicly available academic datasets contain significant
number instances activities, formulate conditional random field (CRF) model
capable detecting high (more 80%) accuracy. However, focus solely
single-agent household activities.
Peoples conversation primary focus multi-agent modeling effort (Barbuceanu
& Fox, 1995). fields multi-agent activity recognition studies human behavior, researchers either modeled conversation explicitly (e.g., Busetta, Serafini, Singh, & Zini, 2001),
leveraged peoples communication implicitly via call location logs mobile phones.
data successfully used infer social networks, user mobility patterns, model socially

121

fiS ADILEK & K AUTZ

significant locations dynamics, others (Eagle & Pentland, 2006; Eagle, Pentland,
& Lazer, 2009). arguably excellent stepping stone full-fledged multi-agent activity
recognition since location is, times, practically synonymous ones activity (e.g.,
store often implies shopping) (Tang, Lin, Hong, Siewiorek, & Sadeh, 2010), social networks
tremendous influence behavior (Pentland, 2008).
Additionally, number researchers machine vision worked problem recognizing events videos sporting events, impressive recent work learning models
baseball plays (Gupta et al., 2009). work area focused recognizing individual
actions (e.g., catching throwing), state art beginning consider relational
actions (e.g., ball thrown player player B). computational challenges dealing
video data make necessary limit time windows seconds. contrast,
demonstrate work many events capture flag data disambiguated
considering arbitrarily long temporal sequences. general, however, work
machine vision rely upon similar probabilistic models, already evidence
statistical-relational techniques similar Markov logic used activity recognition
video (Biswas, Thrun, & Fujimura, 2007; Tran & Davis, 2008).
Looking beyond activity recognition, recent work relational spacial reasoning includes
attempt locateusing spacial abductioncaches weapons Iraq based information
attacks area (Shakarian, Subrahmanian, & Spaino, 2009). Additionally, work Abowd
et al. (1997) presents location- context-aware system, Cyberguide, helps people explore
fully experience foreign locations. researchers explore intelligent nonintrusive
navigation system takes advantage predictions traffic conditions along model
users knowledge competence (Horvitz et al., 2005). Finally, work Kamar Horvitz
(2009) explore automatic generation synergistic plans regarding sharing vehicles across multiple
commuters.
interesting line work cognitive science focuses intent goal recognition probabilistic framework (Baker, Tenenbaum, & Saxe, 2006, 2007). Specifically, cast goal inference
inverse planning problem Markov decision processes, Bayesian inversion used estimate posterior distribution possible goals. Recent extensions work begin consider
simulated multi-agent domains (Baker, Goodman, & Tenenbaum, 2008; Ullman, Baker, Macindoe,
Evans, Goodman, & Tenenbaum, 2010; Baker, Saxe, & Tenenbaum, 2011). Comparison
computational models human judgement synthetic domains shows strong correlation
peoples predicted actual behavior. However, computational challenges involved
dealing underlying partially observable Markov decision processes prohibitive
complex domains large state spaces, ours.
focus work different aspect reasoning peoples goals. Rather
inferring distribution possible, priori known goals, automatically induce goals
complex multi-agent activities themselves.
researchers concentrated modeling behavior people general agents reinforcement learning problems single-agent multi-agent settings. work (2008)
proposes system household activity recognition cast single-agent Markov decision process
problem subsequently solved using probabilistic model checker. Wilson colleagues address problem learning agents roles multi-agent domain derived real-time strategy
computer game (Wilson, Fern, Ray, & Tadepalli, 2008; Wilson, Fern, & Tadepalli, 2010). Experiments synthetic domain show strongly encouraging results. perform role
122

fiL OCATION -BASED R EASONING C OMPLEX ULTI -AGENT B EHAVIOR

learning ourselves, anticipate work Wilson et al. going play important role
learning hierarchies peoples activities. capture flag domain, one imagine automatically identifying particular player as, example, defender subsequently leveraging
information model behavior personalized way.
work Hong (2001) concentrates recognizing goal agent course
activities deterministic, relational setting. Interesting work goal recognition
also applied computer-aided monitoring complex multi-agent systems, relationships
agents leveraged compensate noise sparse data (Kaminka, Tambe, Pynadath,
& Tambe, 2002). contrast, work focus learning respective goals given set
multi-agent activities probabilistic setting. knowledge turn leveraged achieve
stronger robustness recognition tasks. Similarly approach Hong, system
need supplied plan library either.
work also touches anomaly detection since system reasons failed attempts
players. Anomaly detection concerns revealing segments data
way violate expectations. excellent survey subject, refer reader
results Chandola, Banerjee, Kumar (2009). realm anomaly detection within peoples
activities, work Moore Essa (2001) addresses problem error detection recovery
card games involve two players recorded video. system models domain
stochastic context-free grammar achieves excellent results.
note recognizing failed attempt activity fine-grained problem
anomaly detection. failed event anomalous general.7 Rather, specific
distinction success failure human activities interested in. distinction lies fact unsuccessful attempt yield certain desired state whereas
successful action does. desired state exactly approach extracts activity
question. knowledge, exists prior work explicit modeling recognition
attempted activities learning intended purpose activity multi-agent setting.
One components contribution focuses joint learning inference across multiple tasks (capturing, freeing, respective attempted counterparts). contrast
traditional pipeline learning architecture, system decomposed series modules module performs partial computation passes result next stage.
main benefits set-up reduced computational complexity often higher modularity.
However, since stage myopic, may take full advantage dependencies broader
patterns within data. Additionally, even though errors introduced module may small,
accumulate beyond tolerable levels data passes pipeline.
extensive body work shown joint reasoning improves model performance
number natural language processing data mining tasks including information extraction (i.e.,
text segmentation coupled entity resolution) (Poon & Domingos, 2007), co-reference resolution (Poon & Domingos, 2008), information extraction coupled co-reference resolution (Wellner, McCallum, Peng, & Hay, 2004), temporal relation identification (Yoshikawa, Riedel, Asahara,
& Matsumoto, 2009; Ling & Weld, 2010), record de-duplication (Domingos, 2004; Culotta
& McCallum, 2005). Similarly work, models cast Markov logic.
However, prior work uses sampling techniques perform learning inference, whereas apply
7. situation player CTF moves campus speed 100 mph way passes enemy
player certainly anomalous (and probably caused GPS sensor noise), want say failed
attempt capturing.

123

fiS ADILEK & K AUTZ

reduction integer linear programming. Interestingly, work Denis Baldridge (2007)
jointly addresses problems anaphoricity co-reference via manual formulation
integer linear program.
Joint activity modeling also shown yield better recognition accuracy, compared
pipeline baselines well baselines make strong inter-activity independence assumptions.
work Wu, Lian, Hsu (2007) performs joint learning inference concurrent singleagent activities using factorial conditional random field model. Similarly, work Helaoui,
Niepert, Stuckenschmidt (2010) models interleaved activities Markov logic. distinguish
foreground background activities infer time window activity takes
place RFID sensory data. contrast, focus joint reasoning multi-agent activities
attempts fully relationaland arguably significantly noisysetting.
work Manfredotti, Hamilton, Zilles (2010) propose hierarchical activity recognition
system formulated learning inference relational dynamic Bayesian networks. model
jointly leverages observed interactions individual objects domain relationships
objects. Since method outperforms hidden Markov model significant margin,
contributes additional experimental evidence relational decomposition domain improves
model quality.
work Landwehr, Gutmann, Thon, Philipose, De Raedt (2007) casts single-agent
activity recognition relational transformation learning problem, building transformationbased tagging natural language processing. system induces set transformation rules
used infer activities sensory data. Since transformation rules applied
adaptively, step, system leverages observed data, also currently assigned
labels (inferred activities). However, transformation rules learned greedy fashion
experiments show model perform significantly better simple HMM.
hand, representation quite general, intuitive, extensible. see,
Markov logic model similar level representational convenience performing global
instead greedyoptimization significantly complex domain.
denoising component model formulated tracking problem. Prior work
proposed relational dynamic Bayesian network model multi-agent tracking (Manfredotti &
Messina, 2009). evaluation shows considering relationships tracked entities
significantly improves model performance, compared nonrelational particle filter baseline.
contrast, work explores joint tracking activity recognition. However, GPS reading
annotated identity corresponding agent. work Manfredotti Messina
suggests model generalized, associations GPS agent
identities inferred need observed.
Markov logic theory viewed template conditional random field (Lafferty,
2001), undirected graphical model captures conditional probability hidden labels
given observations, rather joint probability labels observations, one would
typically directed graphical model. relational world, directed formalisms include
relational Bayesian networks (Jaeger, 1997) dynamic counterparts (Manfredotti, 2009),
probabilistic relational models (Koller, 1999; Friedman, Getoor, Koller, & Pfeffer, 1999), Bayesian
logic programs (Kersting & De Raedt, 2000), first-order conditional influence language (Natarajan, Tadepalli, Altendorf, Dietterich, Fern, & Restificar, 2005). Conditional random fields
extensively applied activity recognition, superior labeling performance generative
models demonstrated number single-agent multi-agent domains (Liao
124

fiL OCATION -BASED R EASONING C OMPLEX ULTI -AGENT B EHAVIOR

et al., 2005; Limketkai, Fox, & Liao, 2007; Vail, 2008; Vail & Veloso, 2008; Hu et al., 2008).
Since MLNs often solved propositionalized CRFs, directed alternatives compiled Bayesian network, expected discriminative relational models generally
outperform generative counterparts labeling tasks. However, work needs done
answer question entirety.
Since Markov logic based on, fact subsumes, finite first-order logic, immediately
gain access number techniques developed rich field traditional logic. Current Markov
logic solvers take advantage underlying logical structure perform powerful optimizations, Alchemys lifted inference belief propagation MC-SAT (Poon & Domingos,
2006). Additionally, domain pruning, one uses hard constraints infer reduced domains
predicates, shown lead significant speed-ups (Papai, Singla, & Kautz, 2011).
also leverage relationship Markov first-order logic inducing augmented model. Furthermore, presence dependency cycles introduces additional problems
directed graphical (relational) models. Thus, fact that, Markov logic, knowledge
expressed weighted first-order formulas combined factors make powerful
framework best suited multi-agent reasoning tasks considered work.
Traditional hidden Markov models operate alphabet unstructured (i.e., flat) symbols. makes relational reasoning difficult, one either propositionalize domain,
thereby incurring combinatorial increase number symbols model parameters, ignore
relational structure sacrifice information. Logical hidden Markov models (LHMMs)
proposed address problem (Kersting, De Raedt, & Raiko, 2006). LHMMs generalization standard HMMs compactly represents probability distributions sequences
logical atoms rather flat symbols. LHMMs proven strictly powerful
propositional counterparts (HMMs). applying techniques logic-based reasoning,
unification, leveraging logical structure component model, Kersting et al. show
LHMMs often require fewer parameters achieve higher accuracy HMMs.
LHMMs recently applied activity recognition. context intelligent user interfaces, work Shen (2009) designs evaluates LHMM model recognition peoples
activities workflows carried desktop computer. researchers proposed hierarchical extension LHMMs along efficient particle filter-based inference technique,
apply activity recognition problems synthetic domains (Natarajan, Bui, Tadepalli, Kersting,
& Wong, 2008). lines work show LHMMs learned applied efficiently,
perform better plain HMMs.
However, LHMMs generative model therefore ideal pure labeling
recognition tasks, typically want make strong independence assumptions
observations, want explicitly model dependencies input space. TildeCRFa
relational extension traditional conditional random fieldshas introduced address
issue (Gutmann & Kersting, 2006). TildeCRF allows discriminative learning inference CRFs
encode sequences logical atoms, opposed sequences unstructured symbols. TildeCRF
specifically focuses efficient learning models sequential data via boosting, subsumed
Markov logic, produce discriminative generative models. cast model
latter framework make general, extensible, interpretable.
PRISM, probabilistic extension Prolog, shown subsume wide variety generative models, including Bayesian networks, probabilistic context-free grammars, HMMs (along
logical extension) (Sato & Kameya, 2001, 2008). However, since focus PRISM
125

fiS ADILEK & K AUTZ

representational elegance generality, rather scalability, sheer size state space
complexity CTF domain precludes application here.
Finally, Markov logic theory augmentation process related structure learning, transfer learning, inductive logic programming. fact, Algorithm 1 implements special case
structure learning, search target theory explains training data well,
declarative bias forces target theory differ source theory much necessary.
Again, intuition failed attempts similar failed counterparts. number
researchers focused structure learning specifically Markov logic networks. includes
early work top-down structure learning, clauses knowledge base greedily modified adding, flipping, deleting logical literals (Kok & Domingos, 2005). search guided
likelihood training data current model. work Mihalkova Mooney
(2007) exploit patterns ground Markov logic networks introduce bottom-up declarative
bias makes algorithm less susceptible finding local optima, compared alternative greedy methods. Similarly, work Kok Domingos (2009) introduce bottom-up
declarative bias based lifted hypergraph representation relational database. bias
guides search clauses fit data. Since hypergraph lifted, relational path finding
tractable. Interesting work predicate invention applies relational clustering technique formulated
second-order Markov logic discover new predicates relational databases (Kok & Domingos, 2007). systems capable modeling relatively rich family logical formulas.
approaches perform discriminative structure learning achieve excellent results, focus
restricted set types formulas (e.g., Horn clauses) (Huynh & Mooney, 2008; Biba, Ferilli, &
Esposito, 2008). work Davis Domingos (2009) successfully uses second-order Markov
logic deep transfer learning. lift model source domain second-order ML
identify high-level structural patterns. subsequently serve declarative bias structure
learning target domain.
nature, inductive logic programming discipline extensively studied structure
learning deterministic, well probabilistic settings (e.g., Muggleton, 2002; De Raedt, 2008;
De Raedt, Frasconi, Kersting, & Muggleton, 2008). fact, theory augmentation algorithm
viewed efficient Markov logic based version theory refinement, well-established ILP
technique aims improve quality theory terms simplicity, fit newly acquired
data, efficiency factors (Wrobel, 1996).
approach differs work three main points. First, declarative bias defined
implicitly seed theory successful activities. Therefore, theory augmentation algorithm
limited hard-wired set formula types consider. Rather, search space
defined run time extracting motifs seed theory. second distinction lies computational tractability exactness results. distinguishing soft hard formulas,
able search candidate formulas systematic, rather greedy manner. Consequently, final learned model requires fewer parameters, especially important
amount training data relatively small. Additionally, weight learning experience cold starts, leverage seed theory. final difference that, knowledge,
first explore structure learning context interplay success failure,
relationship intended goals peoples actions.

126

fiL OCATION -BASED R EASONING C OMPLEX ULTI -AGENT B EHAVIOR

8. Conclusions
paper took task understanding game capture flag GPS data
exemplar general problem inferring human interactions intentions sensor data.
presented novel methodologycast Markov logicfor effectively combining data
denoising higher-level relational reasoning complex multi-agent domain. Specifically,
demonstrated given raw noisy data, automatically reliably detect
recognize successful failed interactions adversarial well cooperative settings.
Additionally, shown success, failure, goal activity intimately tied
together model successful events allows us naturally learn models
two important aspects life. Specifically, demonstrated intentions rational
agents automatically discovered process resolving inconsistencies theory
models successful instances set activities examples failed attempts activities.
formulated four research questions designed experiments within CTF domain
empirically answer them. Compared alternative approaches solving multi-agent activity recognition problem, augmented Markov logic model, takes account
relationships among individual players, also relationships among activities entire length
game, although computationally costly, significantly accurate real-world data.
Furthermore, illustrated explicitly modeling unsuccessful attempts boosts performance
important recognition tasks.

9. Future Work
Multi-agent activity recognition especially interesting context current unprecedented
growth on-line social networksin terms size, popularity, impact offline lives. paper, show location information alone allows rich models peoples
interactions, case on-line social networks, additionally access content
users posts explicit implicit network interactions. instance, recent
study shows that, interestingly, 30% Twitter status updates reveal authors location
(Sadilek, Kautz, & Bigham, 2012). data sources available machines massive
volumes ever-increasing real-time streaming rate. note substantial fraction posts
services Facebook Twitter talk everyday activities users (Naaman, Boase,
& Lai, 2010), information channel become available research community
recently. Thus, able reason human behavior interactions automated
way, tap colossal amounts knowledge isat presentdistributed across whole
population.
currently extending model handle explicit GPS traces, also able
infer location people broadcast GPS coordinates. basic idea is, again,
leverage structure relationships among people. vast majority us participate on-line
social networks typically friends publish location. thus view
GPS-enabled people noisy location sensors use network interactions dynamics
estimate location rest users. present, testing approach public
tweets.

127

fiS ADILEK & K AUTZ

Acknowledgments
thank anonymous reviewers constructive feedback. thank Sebastian Riedel
help theBeast, Radka Sadlkova Wendy Beatty helpful comments.
work supported ARO grant #W911NF-08-1-0242, DARPA SBIR Contract #W31P4Q08-C-0170, gift Kodak.

References
Abowd, G. D., Atkeson, C. G., Hong, J., Long, S., Kooper, R., & Pinkerton, M. (1997). Cyberguide:
mobile context-aware tour guide. Wirel. Netw., 3(5), 421433.
Allwein, E., Schapire, R., & Singer, Y. (2001). Reducing multiclass binary: unifying approach
margin classifiers. Journal Machine Learning Research, 1, 113141.
Ashbrook, D., & Starner, T. (2003). Using GPS learn significant locations predict movement
across multiple users. Personal Ubiquitous Comput., 7, 275286.
Baker, C., Tenenbaum, J., & Saxe, R. (2006). Bayesian models human action understanding.
Advances Neural Information Processing Systems, 18, 99.
Baker, C., Goodman, N., & Tenenbaum, J. (2008). Theory-based social goal inference. Proceedings thirtieth annual conference cognitive science society, pp. 14471452.
Baker, C., Saxe, R., & Tenenbaum, J. (2011). Bayesian theory mind: Modeling joint belief-desire
attribution. Proceedings Thirty-Second Annual Conference Cognitive Science
Society.
Baker, C., Tenenbaum, J., & Saxe, R. (2007). Goal inference inverse planning. Proceedings
29th annual meeting cognitive science society.
Baldwin, D. A., & Baird, J. A. (2001). Discerning intentions dynamic human action. Trends
Cognitive Sciences, 5(4), 171 178.
Barbuceanu, M., & Fox, M. (1995). COOL: language describing coordination multi
agent systems. Proceedings First International Conference Multi-Agent Systems
(ICMAS-95), pp. 1724.
Bell, R., Koren, Y., & Volinsky, C. (2007). Modeling relationships multiple scales improve
accuracy large recommender systems. KDD, pp. 95104, New York, NY, USA. ACM.
Biba, M., Ferilli, S., & Esposito, F. (2008). Discriminative structure learning Markov logic
networks.. pp. 5976. Springer.
Biswas, R., Thrun, S., & Fujimura, K. (2007). Recognizing activities multiple cues. Workshop Human Motion, pp. 255270.
Bui, H. H. (2003). general model online probabilistic plan recognition. Eighteenth International Joint Conference Artificial Intelligence (IJCAI-2003).
Busetta, P., Serafini, L., Singh, D., & Zini, F. (2001). Extending multi-agent cooperation overhearing. Cooperative Information Systems, pp. 4052. Springer.
Chandola, V., Banerjee, A., & Kumar, V. (2009). Anomaly detection: survey. ACM Comput.
Surv., 41, 15:115:58.
128

fiL OCATION -BASED R EASONING C OMPLEX ULTI -AGENT B EHAVIOR

Culotta, A., & McCallum, A. (2005). Joint deduplication multiple record types relational data.
Proceedings 14th ACM international conference Information knowledge
management, pp. 257258. ACM.
Davis, J., & Domingos, P. (2009). Deep transfer via second-order Markov logic. Proceedings
26th Annual International Conference Machine Learning, pp. 217224. ACM.
De Raedt, L. (2008). Logical relational learning. Springer-Verlag New York Inc.
De Raedt, L., Frasconi, P., Kersting, K., & Muggleton, S. (Eds.). (2008). Probabilistic Inductive
Logic Programming - Theory Applications, Vol. 4911 Lecture Notes Computer
Science. Springer.
De Raedt, L., & Kersting, K. (2008). Probabilistic inductive logic programming. (De Raedt et al.,
2008), pp. 127.
Denis, P., & Baldridge, J. (2007). Joint determination anaphoricity coreference resolution
using integer programming. Proceedings NAACL HLT, pp. 236243.
Domingos, P. (2004). Multi-relational record linkage. Proceedings KDD-2004 Workshop
Multi-Relational Data Mining.
Domingos, P., Kok, S., Lowd, D., Poon, H., Richardson, M., & Singla, P. (2008). Markov logic.
(De Raedt et al., 2008), pp. 92117.
Eagle, N., & Pentland, A. (2006). Reality mining: sensing complex social systems. Personal
Ubiquitous Computing, 10(4), 255268.
Eagle, N., & Pentland, A. (2009). Eigenbehaviors: Identifying structure routine. Behavioral
Ecology Sociobiology, 63(7), 10571066.
Eagle, N., Pentland, A., & Lazer, D. (2009). Inferring social network structure using mobile phone
data. Proceedings National Academy Sciences.
Friedman, N., Getoor, L., Koller, D., & Pfeffer, A. (1999). Learning probabilistic relational models.
International Joint Conference Artificial Intelligence, Vol. 16, pp. 13001309.
Goutte, C., & Gaussier, E. (2005). probabilistic interpretation precision, recall f-score,
implication evaluation.. pp. 345359. Springer.
Gupta, A., Srinivasan, P., Shi, J., & Davis, L. S. (2009). Understanding videos, constructing plots:
Learning visually grounded storyline model annotated videos. CVPR.
Gutmann, B., & Kersting, K. (2006). TildeCRF: conditional random fields logical sequences.
Machine Learning: ECML 2006, pp. 174185. Springer.
Helaoui, R., Niepert, M., & Stuckenschmidt, H. (2010). statistical-relational activity recognition
framework ambient assisted living systems. Ambient Intelligence Future TrendsInternational Symposium Ambient Intelligence (ISAmI 2010), pp. 247254. Springer.
Hong, J. (2001). Goal recognition goal graph analysis. Journal Artificial Intelligence
Research, 15, 130.
Horvitz, E., Apacible, J., Sarin, R., & Liao, L. (2005). Prediction, expectation, surprise: Methods, designs, study deployed traffic forecasting service. Twenty-First Conference
Uncertainty Artificial Intelligence.

129

fiS ADILEK & K AUTZ

Hu, D., Pan, S., Zheng, V., Liu, N., & Yang, Q. (2008). Real world activity recognition multiple
goals. UbiComp, Vol. 8, pp. 3039.
Huynh, T., & Mooney, R. (2008). Discriminative structure parameter learning Markov
logic networks. Proceedings 25th international conference Machine learning,
pp. 416423. ACM.
Jaeger, M. (1997). Relational Bayesian networks. Proceedings 13th Conference Uncertainty Artificial Intelligence, pp. 266273.
Jordan, M. (1998). Learning graphical models. Kluwer Academic Publishers.
Kamar, E., & Horvitz, E. (2009). Collaboration shared plans open world: Studies
ridesharing. IJCAI.
Kaminka, G. A., Tambe, D. V. P. M., Pynadath, D. V., & Tambe, M. (2002). Monitoring teams
overhearing: multi-agent plan-recognition approach. Journal Artificial Intelligence
Research, 17, 2002.
Kersting, K., & De Raedt, L. (2000). Bayesian logic programs. Proceedings Work-inProgress Track 10th International Conference Inductive Logic Programming.
Kersting, K., De Raedt, L., & Raiko, T. (2006). Logical hidden Markov models. Journal Artificial
Intelligence Research, 25(1), 425456.
Kok, S., & Domingos, P. (2005). Learning structure Markov logic networks. Proceedings
22nd international conference Machine learning, pp. 441448. ACM.
Kok, S., & Domingos, P. (2007). Statistical predicate invention. Proceedings 24th international conference Machine learning, pp. 433440. ACM.
Kok, S., & Domingos, P. (2009). Learning Markov logic network structure via hypergraph lifting.
Proceedings 26th Annual International Conference Machine Learning, pp. 505512.
ACM.
Kok, S., & Domingos, P. (2007). Statistical predicate invention. ICML 07: Proceedings
24th international conference Machine learning, pp. 433440, New York, NY, USA.
ACM.
Koller, D. (1999). Probabilistic relational models. Inductive Logic Programming, pp. 313.
Springer.
Lafferty, J. (2001). Conditional random fields: Probabilistic models segmenting labeling
sequence data. International Conference Machine Learning (ICML), pp. 282289.
Morgan Kaufmann.
Landwehr, N., Gutmann, B., Thon, I., Philipose, M., & De Raedt, L. (2007). Relational
transformation-based tagging human activity recognition. Proceedings 6th International Workshop Multi-relational Data Mining (MRDM07), pp. 8192.
Liao, L., Patterson, D., Fox, D., & Kautz, H. (2007). Learning inferring transportation routines.
Artificial Intelligence, 171(5-6), 311331.
Liao, L., Fox, D., & Kautz, H. (2004). Learning inferring transportation routines. Proceedings Nineteenth National Conference Artificial Intelligence.

130

fiL OCATION -BASED R EASONING C OMPLEX ULTI -AGENT B EHAVIOR

Liao, L., Fox, D., & Kautz, H. (2005). Location-based activity recognition using relational Markov
networks. IJCAI.
Limketkai, B., Fox, D., & Liao, L. (2007). CRF-filters: Discriminative particle filters sequential
state estimation. Robotics Automation, 2007 IEEE International Conference on, pp.
31423147.
Ling, X., & Weld, D. (2010). Temporal information extraction. Proceedings Twenty Fifth
National Conference Artificial Intelligence.
Ma, Z. (2008). Modelling PRISM intelligent system. MSc. Thesis, Linacre College, University Oxford.
Manfredotti, C. (2009). Modeling inference relational dynamic Bayesian networks.
Advances Artificial Intelligence, pp. 287290. Springer.
Manfredotti, C., & Messina, E. (2009). Relational dynamic Bayesian networks improve multitarget tracking. Advanced Concepts Intelligent Vision Systems, pp. 528539. Springer.
Manfredotti, C., Hamilton, H., & Zilles, S. (2010). Learning RDBNs activity recognition.
Neural Information Processing Systems.
Mihalkova, L., & Mooney, R. (2007). Bottom-up learning Markov logic network structure.
Proceedings 24th international conference Machine learning, pp. 625632. ACM.
Moore, D., & Essa, I. (2001). Recognizing multitasked activities using stochastic context-free grammar. Proceedings AAAI Conference.
Muggleton, S. (2002). Learning structure parameters stochastic logic programs. Proceedings 12th international conference Inductive logic programming, pp. 198206.
Springer-Verlag.
Murphy, K. P. (2002). Dynamic bayesian networks: representation, inference learning. Ph.D.
thesis, University California, Berkeley.
Naaman, M., Boase, J., & Lai, C.-H. (2010). really me?: message content social
awareness streams. CSCW 10: Proceedings 2010 ACM conference Computer
supported cooperative work, pp. 189192, New York, NY, USA. ACM.
Natarajan, S., Tadepalli, P., Altendorf, E., Dietterich, T., Fern, A., & Restificar, A. (2005). Learning
first-order probabilistic models combining rules. Proceedings 22nd international conference Machine learning, pp. 609616. ACM.
Natarajan, S., Bui, H. H., Tadepalli, P., Kersting, K., & Wong, W. (2008). Logical hierarchical
hidden Markov models modeling user activities. Proc. ILP-08.
Papai, T., Singla, P., & Kautz, H. (2011). Constraint propagation efficient inference Markov
logic. Seventeenth International Conference Principles Practice Constraint
Programming.
Pentland, A. S. (2008). Honest Signals: Shape World. MIT Press.
Poon, H., & Domingos, P. (2006). Sound efficient inference probabilistic deterministic
dependencies. Proceedings National Conference Artificial Intelligence, Vol. 21,
p. 458. Menlo Park, CA; Cambridge, MA; London; AAAI Press; MIT Press; 1999.

131

fiS ADILEK & K AUTZ

Poon, H., & Domingos, P. (2007). Joint inference information extraction. Proceedings
22nd national conference Artificial intelligence-Volume 1, pp. 913918. AAAI Press.
Poon, H., & Domingos, P. (2008). Joint unsupervised coreference resolution Markov logic.
Proceedings Conference Empirical Methods Natural Language Processing, pp.
650659. Association Computational Linguistics.
Riedel, S. (2008). Improving accuracy efficiency map inference Markov logic.
Proceedings Proceedings Twenty-Fourth Conference Annual Conference Uncertainty Artificial Intelligence (UAI-08), pp. 468475, Corvallis, Oregon. AUAI Press.
Sadilek, A., & Kautz, H. (2010a). Modeling reasoning success, failure, intent
multi-agent activities. Mobile Context-Awareness Workshop, Twelfth ACM International
Conference Ubiquitous Computing.
Sadilek, A., & Kautz, H. (2010b). Recognizing multi-agent activities GPS data. TwentyFourth AAAI Conference Artificial Intelligence.
Sadilek, A., Kautz, H., & Bigham, J. P. (2012). Finding friends following
are. Fifth ACM International Conference Web Search Data Mining (WSDM).
Sato, T., & Kameya, Y. (2001). Parameter learning logic programs symbolic-statistical modeling. Journal Artificial Intelligence Research.
Sato, T., & Kameya, Y. (2008). New advances logic-based probabilistic modeling PRISM.
Probabilistic inductive logic programming, pp. 118155. Springer.
Shakarian, P., Subrahmanian, V., & Spaino, M. L. (2009). SCARE: Case Study Baghdad.
Proceedings Third International Conference Computational Cultural Dynamics.
AAAI.
Shen, J. (2009). Activity recognition desktop environments. Ph.D. Thesis, Oregon State University.
Shoenfield, J. R. (1967). Mathematical Logic. Addison-Wesley.
Singla, P., & Domingos, P. (2005). Discriminative training Markov logic networks. Proceedings National Conference Artificial Intelligence, Vol. 20, p. 868. Menlo Park, CA;
Cambridge, MA; London; AAAI Press; MIT Press; 1999.
Singla, P., & Domingos, P. (2007). Markov logic infinite domains. UAI-07.
Tang, K., Lin, J., Hong, J., Siewiorek, D., & Sadeh, N. (2010). Rethinking location sharing: exploring implications social-driven vs. purpose-driven location sharing. Proceedings
12th ACM international conference Ubiquitous computing, pp. 8594. ACM.
Tran, S., & Davis, L. (2008). Visual event modeling recognition using Markov logic networks.
Proceedings 10th European Conference Computer Vision.
Ullman, T., Baker, C., Macindoe, O., Evans, O., Goodman, N., & Tenenbaum, J. (2010). Help
hinder: Bayesian models social goal inference. Advances Neural Information
Processing Systems (NIPS), Vol. 22.
Vail, D. (2008). Conditional random fields activity recognition. Ph.D. Thesis, Carnegie Mellon
University.

132

fiL OCATION -BASED R EASONING C OMPLEX ULTI -AGENT B EHAVIOR

Vail, D., & Veloso, M. (2008). Feature selection activity recognition multi-robot domains.
Proceedings AAAI, Vol. 2008.
Wang, J., & Domingos, P. (2008). Hybrid Markov logic networks. Proceedings 23rd
national conference Artificial intelligence - Volume 2, pp. 11061111. AAAI Press.
Wellner, B., McCallum, A., Peng, F., & Hay, M. (2004). integrated, conditional model information extraction coreference application citation matching. Proceedings
20th conference Uncertainty artificial intelligence, pp. 593601. AUAI Press.
Wilson, A., Fern, A., Ray, S., & Tadepalli, P. (2008). Learning transferring roles multi-agent
mdps. Proceedings AAAI.
Wilson, A., Fern, A., & Tadepalli, P. (2010). Bayesian role discovery multi-agent reinforcement learning. Proceedings 9th International Conference Autonomous Agents
Multiagent Systems: volume 1-Volume 1, pp. 15871588. International Foundation
Autonomous Agents Multiagent Systems.
Wrobel, S. (1996). First order theory refinement. Advances inductive logic programming, pp.
1433. IOS Press, Amsterdam.
Wu, T., Lian, C., & Hsu, J. (2007). Joint recognition multiple concurrent activities using factorial
conditional random fields. Proc. 22nd Conf. Artificial Intelligence (AAAI-2007).
Yoshikawa, K., Riedel, S., Asahara, M., & Matsumoto, Y. (2009). Jointly identifying temporal relations Markov logic. Proceedings Joint Conference 47th Annual Meeting
ACL 4th International Joint Conference Natural Language Processing
AFNLP: Volume 1-Volume 1, pp. 405413. Association Computational Linguistics.

133

fiJournal Artificial Intelligence Research 43 (2012) 211-255

Submitted 8/11; published 02/12

Exploiting Model Equivalences Solving Interactive Dynamic
Influence Diagrams
Yifeng Zeng

YFZENG @ CS . AAU . DK

Dept. Computer Science
Aalborg University
DK-9220 Aalborg, Denmark

Prashant Doshi

PDOSHI @ CS . UGA . EDU

Dept. Computer Science
University Georgia
Athens, GA 30602, U.S.A.

Abstract
focus problem sequential decision making partially observable environments
shared agents uncertain types similar conflicting objectives. problem
previously formalized multiple frameworks one interactive dynamic
influence diagram (I-DID), generalizes well-known influence diagram multiagent
setting. I-DIDs graphical models may used compute policy agent given
belief physical state others models, changes agent acts observes
multiagent setting.
may expect, solving I-DIDs computationally hard. predominantly due
large space candidate models ascribed agents exponential growth time.
present two methods reducing size model space stemming exponential
growth. methods involve aggregating individual models equivalence classes.
first method groups together behaviorally equivalent models selects models updating result predictive behaviors distinct others updated model
space. second method compacts model space focusing portions behavioral predictions. Specifically, cluster actionally equivalent models prescribe identical
actions single time step. Exactly identifying equivalences would require us solve
models initial set. avoid selectively solving models, thereby introducing approximation. discuss error introduced approximation, empirically
demonstrate improved efficiency solving I-DIDs due equivalences.

1. Introduction
Sequential decision making (planning) key tenet agent autonomy. Decision making becomes
complicated due actions nondeterministic physical environment often
partially observable. complexity increases exponentially presence agents
acting observing, whose actions impact subject agent. Multiple related
frameworks formalize general problem decision making uncertain settings shared
sophisticated agents may similar conflicting objectives. One frameworks interactive partially observable Markov decision process (I-POMDP) (Gmytrasiewicz
& Doshi, 2005), generalizes POMDPs (Smallwood & Sondik, 1973; Kaelbling, Littman,
& Cassandra, 1998) multiagent settings; another framework interactive dynamic influc
2012
AI Access Foundation. rights reserved.

fiZ ENG & OSHI

Ri

Ri

Ait

Ait+1
Ajt

Ajt+1

St

St+1

Mj,l-1t

Mj,l-1t+1

Oit

Oit+1

Figure 1: two time-slice I-DID agent modeling another agent j. I-DIDs allow representing
models model node (hexagon) update time using dotted model
update link. Predictions agents behavior models represented
using dashed policy link.

ence diagram (I-DID) (Doshi, Zeng, & Chen, 2009). cooperative settings, decentralized
POMDP (Bernstein, Givan, Immerman, & Zilberstein, 2002) framework models multiagent decision making.
I-DIDs graphical models sequential decision making uncertain multiagent settings.
concisely represent problem agent act uncertain environment shared
others may act simultaneously sophisticated ways. I-DIDs may viewed graphical
counterparts I-POMDPs adopt enumerative representation decision-making problem. I-DIDs generalize dynamic influence diagrams (DID) (Tatman & Shachter, 1990) multiagent
settings analogously way I-POMDPs generalize POMDPs. Importantly, I-DIDs
advantage representation explicates embedded domain structure decomposing
state space variables relationships variables. representation
intuitive use, translates computational benefits compared enumerative
representation used I-POMDPs (Doshi et al., 2009).
Following paradigm graphical models, I-DIDs compactly represent decision problem
mapping various variables chance, decision utility nodes, denoting dependencies
variables using directed arcs corresponding nodes. extend DIDs
introducing special model node whose values possible models agent.
models may represented using I-DIDs leading nested modeling. agents
models original agents beliefs models updated time using special
model update link connects model nodes time steps. Solution I-DID
policy prescribes agent time, given beliefs physical state
others models. Consequently, I-DIDs may used compute policy agent online
given initial belief agent agent acts observes setting populated
interacting agents. show generic I-DID Fig. 1 provide details Section 3.
may expect, solving I-DIDs computationally hard. particular, acutely
suffer curses dimensionality history (Pineau, Gordon, & Thrun, 2006).
state space I-DIDs includes models agents addition traditional
212

fiE XPLOITING ODEL E QUIVALENCES OLVING NTERACTIVE DYNAMIC NFLUENCE IAGRAMS

physical states. agents act, observe update beliefs, I-DIDs must track evolution
models time. Theoretically, number candidate models grows exponentially time.
Thus, I-DIDs suffer curse history afflicts modeling agent, also
exhibited modeled agents. complicated nested nature state
space.
Consequently, exact solutions I-DIDs infeasible simple problems ways
mitigating computational intractability critically needed. complexity predominantly due candidate models, focus principled reductions model space
avoiding significant losses optimality decision maker. first approach builds
upon idea grouping together behaviorally equivalent (BE) models (Rathnasabapathy, Doshi,
& Gmytrasiewicz, 2006; Pynadath & Marsella, 2007). models whose behavioral predictions modeled agent(s) identical. solution subject agents I-DID
affected predicted behavior agent regardless description
ascribed model, may consider single representative class without affecting
optimality solution. Identifying models requires solving individual models. reduce exponential growth model space discriminatively updating models. Specifically,
time step, select models updating result predictive behaviors
distinct others updated model space. words, models update
would result predictions identical existing models selected updating. models, simply transfer revised probability masses existing
models. Thus, avoid generating possible updated models subsequently reducing them.
Rather, generate minimal set models time step.
Restricting updated models exact minimal set would require solving models
considered initially. Exploiting notion models whose beliefs spatially close tend
BE, solve models whose beliefs -close representative. theoretically analyze error introduced approach optimality solution. Importantly,
experimentally evaluate approach I-DIDs formulated multiple problem domains two agents, show approximately order magnitude improvement performance
comparison previous clustering approach (Zeng, Doshi, & Chen, 2007), comparable
loss optimality. One problem domains Georgia testbed autonomous control
vehicles (GaTAC) (Doshi & Sonu, 2010), facilitates scalable realistic problem domains
pertaining autonomous control unmanned agents uninhabited aerial vehicles (UAV).
GaTAC provides low-cost, open-source flexible environment realistically simulating
problem domains evaluating solutions produced multiagent decision-making algorithms.
compact space models model node observing behaviorally
distinct models may prescribe identical actions single time step. may group together
models single equivalence class. comparison BE, definition equivalence
class different: includes models whose prescribed action particular time step
same, call action equivalence (AE). Since typically additional models
ones prescribe identical actions time step, AE class often includes many
models. Consequently, model space partitioned lesser number classes previously
bounded number actions agent.
Unlike update classes, given action observation AE classes update
deterministically. show may compute probability equivalence class
updated another class next time step. Although, general, grouping AE models introduces
213

fiZ ENG & OSHI

approximation, derive conditions AE model grouping preserves optimality
solution. demonstrate performance approach multiple two-agent problem domains
including GaTAC show significant time savings comparison previous approaches.
summarize, main contributions article new approaches group equivalent
models efficiently leading improved scalability solving I-DIDs. first method reduces
exponential growth model space discriminatively updating models thereby generating
behaviorally minimal set next time step characterized absence models.
second method adopts relaxed grouping models prescribe identical actions
particular time step. Grouping AE models leads equivalence classes often include many
models addition BE. augment methods approximation
avoids solving initial models, demonstrate much improved scalability experiments.
remainder article structured follows. Section 2, discuss previous work
related article. Section 3, briefly review graphical model I-DID well
solution based BE. Section 4, show may discriminatively update models order
facilitate behaviorally-distinct models subsequent time steps. introduce approximation,
discuss associated computational savings error. introduce approach
grouping models based actions, Section 5. approaches solving I-DIDs empirically
evaluated along different dimensions Section 6. conclude article discussion
framework solution approaches including extensions N > 2 agent interactions,
limitations, Section 7. Appendices contain proofs propositions mentioned elsewhere,
detailed descriptions I-DID representations problem domains used evaluation.

2. Related Work
Suryadi Gmytrasiewicz (1999) early piece related work, proposed modeling
agents using IDs. approach proposed ways modify IDs better reflect observed
behavior. However, unlike I-DIDs, agents model original agent distribution
models updated based actions observations.
detailed Doshi et al. (2009), I-DIDs contribute emerging promising line
research graphical models multiagent decision making. includes multiagent influence
diagrams (MAID) (Koller & Milch, 2001), network influence diagrams (NID) (Gal & Pfeffer,
2008), recently, limited memory influence diagram based players (Madsen & Jensen,
2008). MAIDs adopt external perspective interaction, exploiting conditional
independence effects actions compute Nash equilibrium strategy agents
involved interaction, I-DIDs offer subjective perspective interaction, computing
best-response policy opposed policy equilibrium. latter may account
agents behaviors outside equilibrium multiple equilibria may exist. Furthermore,
MAID NID formalisms focus static, single-shot interaction. contrast, I-DIDs offer
solutions extended time interactions, agents act update beliefs others
models dynamic.
I-DIDs closely relate previously mentioned ID-based graphical models, another
significant class graphical models compactly represents joint behavior graphical game
(Kearns, Littman, & Singh, 2001). models agents graph vertices interaction payoff
two agents using edge, objective finding joint distribution agents
actions possibly equilibrium. recently, graphical multiagent models (Duong, Wellman,
214

fiE XPLOITING ODEL E QUIVALENCES OLVING NTERACTIVE DYNAMIC NFLUENCE IAGRAMS

& Singh, 2008) enhance graphical games allowing beliefs agent behaviors formed
different knowledge sources, conditioning agent behaviors abstracted history game
dynamic (Duong, Wellman, Singh, & Vorobeychik, 2010).
mentioned previously, dominating cause complexity I-DIDs exponential
growth candidate models time. Using insight models (with identical capabilities
preferences) whose beliefs spatially close likely BE, Zeng Doshi (2007) utilized k-means approach cluster models together select K models closest means
clusters model node time step. approach facilitates consideration fixed
number models time. However, approach first generates possible models
reducing model space time step, thereby reducing memory required. Further,
utilizes iterative often time-consuming k-means clustering method.
concept models proposed initially used solving I-POMDPs (Rathnasabapathy et al., 2006), discussed generally Pynadath Marsella (2007). contextualize within framework I-DIDs seek extensions. somewhat related notion
state equivalence introduced Givan et al. (2003) equivalence concept exploited factorize MDPs gain computational benefit. Along direction, another type
equivalence probabilistic frameworks MDPs POMDPs, sometimes also called BE,
bisimulation (Milner, 1980; Givan et al., 2003; Castro, Panangaden, & Precup, 2009). Two states
bisimilar action states leads identical immediate reward states transition probability equivalence classes states. bisimulation test within
model given definition, multiagent systems defined used differently: way
comparing models using solutions. Interestingly, concepts ultimately
useful model minimization.
frameworks modeling multiagent decision-making problem exist. notable
among decentralized POMDP (Bernstein et al., 2002). framework suitable
cooperative settings focuses computing joint solution agents team.
Seuken Zilberstein (2008) provide comprehensive survey approaches related decentralized POMDPs; emphasize exploit clustering. Emery-Montemerlo et al. (2005) propose
iteratively merging action-observation histories agents lead small worst-case expected
loss. clustering could lossy, Oliehoek et al. (2009) losslessly cluster histories
exhibit probabilistic equivalence. histories generate identical distribution histories
agents lead joint belief state. utilize losslessly cluster
models agent, note models combined subject agents policy induce identical distributions subject agents action-observation history. recently,
Witwicki Durfee (2010) use influence-based abstraction order limit agents belief
agents relevant information focusing mutually-modeled features only.
agent models analogous types game theory (Harsanyi, 1967), defined
attribute vectors encompass agents private information. context, Dekel et
al. (2006) define strategic topology universal type spaces (Mertens & Zamir, 1985; Brandenburger & Dekel, 1993) two types close strategic behavior similar
strategic situations. Dekel et al. focus theoretical analysis topology use
rationalizability solution concept, focus operationalizing within computational
framework. Furthermore, solution concept best response ones beliefs.
215

fiZ ENG & OSHI

3. Background
briefly review interactive influence diagrams (I-ID) two-agent interactions followed
extension dynamic settings, I-DIDs (Doshi et al., 2009). formalisms allow modeling
agent use information decision making subject agent.
illustrate formalisms approaches context multiagent tiger problem (Gmytrasiewicz & Doshi, 2005) two-agent generalization well-known single agent
tiger problem (Kaelbling et al., 1998). problem, two agents, j, face two closed doors
one hides tiger hides pot gold. agent gets rewarded opening
door hides gold gets penalized opening door leading tiger. agent
may open left door (action denoted OL), open right door (OR), listen (L). listening,
agent may hear tiger growling either left (observation denoted GL)
right (GR). Additionally, agent hears creaks emanating direction door
possibly opened agent creak left (CL) creak right (CR) silence
(S) door opened. observations assumed noisy. door opened
agent, tiger appears behind two doors randomly next time step.
actions agent directly affect reward agent, may potentially change
location tiger. formulation problem differs Nair et al. (2003)
presence door creaks cooperative.
3.1 Interactive Dynamic Influence Diagrams
Influence diagrams (Tatman & Shachter, 1990) typically contain chance nodes represent
random variables modeling physical state, S, agents observations, Oi , among
aspects problem; decision nodes model agents actions, Ai ; utility nodes
model agents reward function, Ri . addition nodes, I-IDs agent include
new type node called model node. hexagonal node, Mj,l1 , Fig. 2, j
denotes agent l 1 strategy level, allows nested modeling
agent j. Agent js level one less i, consistent previous
hierarchical modeling game theory (Aumann, 1999a; Brandenburger & Dekel, 1993) decision
theory (Gmytrasiewicz & Doshi, 2005). Additionally, level 0 model ID flat probability
distribution. note probability distribution chance node, S, model node
together represents agent belief interactive state space. addition model node,
I-IDs differ IDs chance node, Aj , represents distribution
agents actions, dashed link, called policy link.
model node contains values alternative computational models ascribed
agent. policy link denotes distribution Aj contingent models
model node. denote set models Mj,l1 , individual model j as,
mj,l1 = hbj,l1 , j i, bj,l1 level l 1 belief, j agents frame encompassing
decision, observation utility nodes. model model node may I-ID ID,
recursion terminates model ID flat probability distribution actions.
observe model node dashed policy link connects chance node,
Aj , could represented shown Fig. 3(a) leading flat ID shown Fig. 3(b). decision
node level l 1 I-ID transformed chance node. Specifically, OPT(m1j,l1 )
set optimal actions obtained solving I-ID (or ID) denoted m1j,l1 , P r(aj
216

fiE XPLOITING ODEL E QUIVALENCES OLVING NTERACTIVE DYNAMIC NFLUENCE IAGRAMS

Ri

Ai



Aj

Mj.l-1

Oi

Figure 2: generic level l > 0 I-ID agent situated one agent j. shaded hexagon
model node (Mj,l1 ) dashed arrow policy link.

Mj,l-1


Aj
Ri

Ai

Mod[Mj]

mj,l-11

mj,l-12



j1
j2

Aj

Mod[Mj]

Oi

Aj1

Aj2

(b)

(a)

Figure 3: (a) Representing model node policy link using chance nodes dependencies
them. decision nodes lower-level I-IDs IDs (m1j,l1 , m2j,l1 ; superscript numbers serve distinguish models) mapped corresponding chance
nodes (A1j , A2j ) respectively, indicated dotted arrows. Depending
value node, od[Mj ], distribution chance nodes assigned node Aj
probability. (b) transformed flat ID model node policy link
replaced (a).

A1j ) =

1
|OPT(m1j,l1 )|

aj OPT(m1j,l1 ), 0 otherwise. different chance nodes (A1j , A2j )

one model additionally, chance node labeled od[Mj ] form parents
chance node, Aj . many action nodes number models support agent
beliefs. conditional probability table (CPT) chance node, Aj , multiplexer
assumes distribution action nodes (A1j , A2j ) depending value od[Mj ].
words, od[Mj ] value m1j,l1 , chance node Aj assumes distribution
node A1j , Aj assumes distribution A2j od[Mj ] value m2j,l1 .
distribution od[Mj ] belief js models given state.
two agents, add model node chance node representing distribution
agents action linked together using policy link, agent. Interactions among
others coordination team work could considered utilizing models, predict
217

fiZ ENG & OSHI

joint behavior others, distinct model node possibly updating models. example,
joint behavioral models could graphical analogs decentralized POMDPs. settings
involving agents acting independently cooperative others adversarial
may represented well, topic research study. aside, Doshi et al. (2009)
show I-IDs relate NIDs (Gal & Pfeffer, 2008).

Ri

Ait

Tiger
Locationt

Ajt

Mod[Mjt]
Growl&
Creakit

Ajt,1

Ajt,2

mj,01

mj,02

Rj

Tiger
Locationt,1

Aj

Ajt,2

t,1

Rj

Tiger
Locationt,2

Growljt

Growljt

Figure 4: Level 1 I-ID multiagent tiger problem. Solutions two level 0 models (IDs)
t,2
j map chance nodes, At,1
j Aj , respectively (illustrated using dotted arrows),
transforming I-ID flat ID. two models differ distribution
chance node, TigerLocationt .

setup I-ID multiagent tiger problem described previously, Fig. 4. discuss
CPTs various nodes Appendix B.1. I-ID contains two models j,
would many action nodes j models.

Ri

Ri

Ait

Ait+1
Ajt

Ajt+1

St

St+1

Mj,l-1t

Mj,l-1t+1

Oit

Oit+1

Figure 5: generic two time-slice level l I-DID agent i. Notice dotted model update link
denotes update models j distribution models,
time.

218

fiE XPLOITING ODEL E QUIVALENCES OLVING NTERACTIVE DYNAMIC NFLUENCE IAGRAMS

I-DIDs extend I-IDs allow sequential decision making multiple time steps. depict
general, two time-slice I-DID Fig. 5. addition model nodes dashed policy link,
differentiates I-DID model update link shown dotted arrow Fig. 5.
briefly explain semantics model update next.

St

Ajt

Mj,l-1t

Ajt+1

Mj,l-1t+1
St+1

Mod[Mjt+1]



Mod[Mj ]

Ojt+1

Ait
mj,l-1t,1

mj,l-1t,2

Aj

1

Oj

j2

Oj2

mj,l-1t+1,1

1

mj,l-1t+1,2
mj,l-1t+1,3
mj,l-1t+1,4

j1

j2

j3

j4

Figure 6: semantics model update link. Notice growth number models
model node + 1 shown bold (superscript numbers distinguish different models).
Models + 1 reflect updated beliefs j solutions provide probability
distributions action nodes.
Agents multiagent setting may act make observations, changes beliefs.
Therefore, update model node time involves two steps: First, given models
time t, identify updated set models reside model node time + 1.
agents act receive observations, models updated reflect changed beliefs. Since
set optimal actions model could include actions, agent may receive
one |j | possible observations j set js observations, updated set time step
t+1 |Mtj,l1 ||Aj ||j | models. Here, |Mtj,l1 | number models time step t,
|Aj | |j | largest spaces actions observations respectively, among models.
t+1
t+1
CPT chance node od[Mj,l1
] encodes indicator function, (btj,l1 , atj , ot+1
j , bj,l1 ),
updates
1 belief btj,l1 model mtj,l1 using action atj observation ot+1
j
t+1
t+1
bj,l1 model mj,l1 ; otherwise 0. Second, compute new distribution
updated models given original distribution probability agent performing action
receiving observation led updated model. dotted model update link
I-DID may implemented using standard dependency links chance nodes, shown Fig. 6
transforming I-DID flat DID.
Fig. 7, show two time-slice flat model nodes model update link
replaced chance nodes relationships them. Chance nodes dependency
links bold standard, usually found single agent DIDs.
Continuing illustration, show two time-slice I-DID multiagent tiger
problem Fig. 8. model update link updates number js candidate models due
action observations growl, also updates probability distribution models.
model update link I-DID implemented using standard dependency links shown
Fig. 9. sake clarity, illustrate update single model j contained model
node time t.
219

fiZ ENG & OSHI

Ri

Ri

Ait

Ait+1

St

St+1

Oit

Oit+1

Ajt

Ajt+1
t+1

Mod[Mj ]

Mod[Mjt]

Ojt+1
Aj1
Aj

1

Oj

1

j2

Aj
Oj2

4

j2
j3

Figure 7: flat obtained replacing model nodes model update link I-DID
Fig. 5 chance nodes relationships (in bold) shown Fig. 6.
lower-level models solved obtain distributions chance action nodes.

Ri

Ri

Ait

Ait+1
Ajt

Ajt+1

Tiger
Locationt

Tiger
Locationt+1

Mj,l-1t

Mj,l-1t+1

Growl&
Creakt

Growl&
Creakt+1

Figure 8: Two time-slice level l I-DID multiagent tiger problem. Shaded model nodes
contain different models j.

3.2 Behavioral Equivalence Model Solution
Although space possible models large, models need considered agent
model node. mentioned previously, models (Rathnasabapathy et al., 2006;
Pynadath & Marsella, 2007) could pruned single representative model considered.
solution subject agents I-DID affected predicted behavior
agent; thus need distinguish behaviorally equivalent models. define
formally below:
Definition 1 (Behavioral equivalence). Two models, mj,l1 mj,l1 , agent, j,
behaviorally equivalent if, OPT(mj,l1 ) = OPT(mj,l1 ), OPT() denotes solution
model forms argument.
Thus, models whose behavioral predictions agent identical.
220

fiE XPLOITING ODEL E QUIVALENCES OLVING NTERACTIVE DYNAMIC NFLUENCE IAGRAMS

Tiger
Locationt

Ajt

Mj,l-1t

Ajt+1

Mj,l-1t+1
Tiger
Locationt+1

Mod[Mjt+1]

Mod[Mjt]

mj,l-1t+1,1
Growljt+1

Ait
mj,l-1t,1

j1

mj,l-1t+1,3

Growlj1

mj,l-1t+1,4
mj,l-1t+1,5
mj,l-1t+1,6

mj,l-1t+1,2

Aj

j1
2

j3

j4

Aj5

Aj6

Figure 9: agent j tiger problem may receive one six possible observations
given action prescribed model, single model model node time could
lead six distinct models time + 1.

solution I-DID (and I-ID) implemented recursively levels shown
Fig. 10. order solve level 1 I-DID horizon , start solving level 0 models,
may traditional DIDs horizon . solutions provide probability distributions
agents actions, entered corresponding action nodes found model node
level 1 I-DID corresponding time step (lines 3-5). Subsequently, set js models
minimized excluding models (line 6).
solution method uses standard look-ahead technique, projecting agents action
observation sequences forward current belief state, finding possible beliefs
could next time step (Russell & Norvig, 2010). agent belief
js models well, look-ahead includes finding possible models j could
future. Consequently, js level 0 models represented using standard must
solved first time step horizon obtain optimal set actions. actions
combined set possible observations j could make model, resulting
updated set candidate models (that include updated beliefs) could describe behavior
j. SE(btj , aj , oj ) abbreviation belief update (lines 8-13). Beliefs updated
set candidate models calculated using standard inference methods dependency
links model nodes shown Fig. 6 (lines 15-18). Agent I-DID expanded across
time steps manner. point algorithm Fig. 10 may realized help
standard implementations DIDs H UGIN E XPERT (Andersen & Jensen, 1989).
solution policy tree prescribes optimal action(s) perform agent initially given
belief, actions thereafter conditional observations.

4. Discriminative Model Updates
Solving I-DIDs computationally intractable due large space complexity
models ascribed j, also due exponential growth candidate models j time.
growth leads disproportionate increase interactive state space time. begin
introducing set models minimal sense describe method generating set.
minimal set analogous one notions minimal mental model space described
221

fiZ ENG & OSHI

I-DID E XACT (level l 1 I-DID level 0 DID, horizon )
Expansion Phase
1. 0 1
2.
l 1

Minimize Mj,l1
3.
mtj Mtj,l1
4.
Recursively call algorithm l 1 I-DID (or DID)
represents mtj horizon,
5.
Map decision node solved I-DID (or DID), OPT(mtj ),
corresponding chance node Aj
6.
Mtj,l1 PruneBEModels(Mtj,l1 )
7.
< 1
t+1
Populate Mj,l1
8.
mtj Mtj,l1
9.
aj OPT(mtj )
10.
oj Oj (part mtj )
11.
Update js belief, bt+1
SE(btj , aj , oj )
j
t+1
12.
mj New I-DID (or DID) bt+1
initial belief
j

t+1

{m
}
13.
Mt+1
j
j,l1
t+1
14.
Add model node, Mj,l1
, model update link
t+1

Mj,l1
Mj,l1
15.
Add chance, decision, utility nodes + 1 time slice
dependency links
16.
Establish CPTs chance node utility node
Solution Phase
17. l 1
18. Represent model nodes, policy links model update links
Fig. 6 obtain
19. Apply standard look-ahead backup method solve expanded
(other solution approaches may also used)

Figure 10: Algorithm exactly solving level l 1 I-DID level 0 expanded time
steps.

Pynadath Marsella (2007). assume models agent differ beliefs
agents frame known. later discuss Section 7 impact frame
unknown well. clarity, continue focus two-agent interactions, discuss
extensions techniques presented Section 7 well.
4.1 Behaviorally Minimal Model Set
Given set models, Mj,l1 , agent, j, model node define corresponding
behaviorally minimal set models:
222

fiE XPLOITING ODEL E QUIVALENCES OLVING NTERACTIVE DYNAMIC NFLUENCE IAGRAMS

Definition 2 (Behaviorally minimal set). Define minimal set models, Mj,l1 , largest
subset Mj,l1 , model, mj,l1 Mj,l1 , exists model Mj,l1
mj,l1 .
Here, defined Def. 1. say Mj,l1 (behaviorally) minimizes Mj,l1 .
illustrate Fig. 11 using tiger problem (Kaelbling et al., 1998), set Mj,l1 minimizes
Mj,l1 comprises behaviorally distinct representatives models Mj,l1
models. model group models may selected representative
Mj,l1 , minimal set corresponding Mj,l1 unique, although cardinality remains
fixed.
0.075 0.1 0.025

0.05

0.2 0.25

0.05 0.05

0.15 0.05

Pri(Mj,0t|s)

Prj(TL)
0.2

0.6

0.2

Pri(j,0t|s)

Prj(TL)

Figure 11: Illustration minimal set using tiger problem. Black vertical lines denote
beliefs contained different models agent j included model node, Mj,0 . Decimals
top indicate probability distribution js models, P ri (Mtj,0 |s). order
form behaviorally minimal set, Mtj,0 , select representative model
group models (models differently shaded regions). Agent distribution
models Mtj,0 obtained summing probability mass assigned individual
models region. Note Mtj,0 unique one model within
shaded region could selected inclusion it.

Agent probability distribution minimal set, Mj,l1 , conditioned physical
state obtained summing probability mass models Mj,l1 assigning
accumulated probability representative model Mj,l1 . Formally, let mj,l1 Mj,l1 ,
then:
X
bi (mj,l1 |s) =
bi (mj,l1 |s)
(1)
mj,l1 Mj,l1

Mj,l1 Mj,l1 set models representative mj,l1 belongs. Thus,
Mj,l1 minimizes Mj,l1 , Eq. 1 shows may obtain probability distribution
Mj,l1 time step, given belief distribution models model node step
(see Fig. 11).
behaviorally minimal set together probability distribution important
property: Solution I-DID remains unchanged models model node
distribution models replaced corresponding minimal set distribution
it, respectively. words, transforming set models model node
minimal set preserves solution. Proposition 1 states formally:
223

fiZ ENG & OSHI

Proposition 1. Let X : (Mj,l1 ) (Mj,l1 ) mapping defined Eq. 1, Mj,l1
space models model node Mj,l1 minimizes it. Then, applying X preserves
solution I-DID.
Proof Proposition 1 given Appendix A. Proposition 1 allows us show Mj,l1
indeed minimal given Mj,l1 respect solution I-DID.
Corollary 1. Mj,l1 conjunction X sufficient solution-preserving subset models
found Mj,l1 .
Proof corollary follows directly Proposition 1. Notice subset continues
solution preserving additionally augment Mj,l1 models Mj,l1 .
number models minimal set is, course, original set
typically much less, solution I-DID often computationally much less intensive
model set replaced behaviorally minimal counterpart.
4.2 Discrimination Using Policy Graphs
straightforward way obtaining Mj,l1 exactly time step first ascertain
groups models. requires us solve I-DIDs DIDs representing models, select
representative model group include Mj,l1 , prune others
solution representative.
4.2.1 PPROACH
Given set js models, Mj,l1 , time t(=0), present technique generating minimal
sets subsequent time steps I-DID. first observe behaviorally distinct models time
may result updated models + 1 BE. Hence, approach select time step
models updating result predictive behaviors distinct
others updated model space + 1. Models result predictions update
identical existing models + 1 selected updating. Consequently,
resulting model set + 1 minimal.
solving individual I-DIDs DIDs Mtj,l1 . Solutions DIDs I-DIDs
policy trees, may merged bottom obtain policy graph, demonstrate
Fig. 12. Seuken Zilberstein (2007) reuse subtrees smaller horizon linking using
pointers forming policy trees next horizon solution decentralized POMDPs.
net effect formation policy graph similar thereby providing alternative
approach solving individual models first obtain complete policy trees
merge post hoc. adopt latter approach individual models, DIDs,
solved using available implementations produce complete policy trees. following proposition
gives complexity merging policy trees obtain policy graph.
Proposition 2 (Complexity tree merge). worst-case complexity procedure merging
policy trees form policy graph O((|j |T 1 )2 |Mj |2 ), horizon.
Proof. complexity policy tree merge procedure proportional number comparisons made parts policy trees ascertain similarity. procedure
follows bottom-up approach leaf level largest number nodes, maximum
224

fiE XPLOITING ODEL E QUIVALENCES OLVING NTERACTIVE DYNAMIC NFLUENCE IAGRAMS

L
GR

GL

OL
*

time t=0



L

*

L

L

GL GR

*

L

OL

L

GR GL

L

GL GR

L



GR GL GR GL

L

OL

L



L

*

GR GL

L



Merge

(a)

GR

OL

Merge

*

GL

GR

*

GL GR

GR GL

L

L

L

L



L

*

GLGR

GL GR

OL



L

L

GL

GL
GR

*

L



L

(b)

[ 0 0.135) [ 0.135 0.865) [ 0.865 0.955) [ 0.955 1]
Actions (node labels):
L = Listen
OL = Open left door
= Open right door
Observations (edge labels):
GL = Growl left door
GR = Growl right door

L
GR

OL

L

L

GR

GL

L
GR*

OL

GR

GL
L

GL

GR



GL

*



L

* GL *


L

(c)

Figure 12: (a) Example policy trees obtained solving four models j tiger problem.
Beginning bottom up, may merge four L nodes, two nodes two OL
nodes respectively obtain graph (b). two policy trees two steps
rooted L (bold circle) identical, two policy trees rooted L (rightmost), may merge them, respectively, obtain policy graph (c). Nodes
= 0 annotated ranges P rj (T L).

number comparisons made leaf nodes. worst case occurs none leaf
nodes different policy trees merged. Note precludes merger upper parts
policy trees well. policy tree may contain |j |T 1 leaf nodes,
horizon. Hence, O((|j |T 1 )2 |Mj |2 ) comparisons made, O(|Mj |2 ) number pairs model set. 1 case none leaf nodes merge must occur
models behaviorally distinct, form minimal set, Mj . words, Mj = Mj .

1. assume ordering observations (edge labels) thereby ordering tree, two policy trees may sufficiently compared O(|j |T 1 ) time.

225

fiZ ENG & OSHI

node policy graph represents action performed agent edges
represent agents observations. common policy graphs POMDPs, associate
node time = 0, range beliefs corresponding action optimal (see
Fig. 12(c)). range may obtained computing value executing policy tree rooted
node = 0 graph starting physical state. results vector
values policy tree, typically called -vector. Intersecting -vectors projecting
intersections belief simplex provides us boundaries needed belief ranges.
utilize policy graph discriminate model updates. clarity, formally
define policy graph next.
Definition 3 (Policy graph). Define policy graph as:
P G = hV, A, E, , Lv , Le
V set vertices (nodes); set actions form node labels; E set
ordered pairs vertices (edges); set observations form edge labels; Lv :
V assigns vertex action set actions, (node label); Le : E
assigns edge observation set observations, (edge label). Le follows
property two edges whose first elements identical (begin vertex) assigned
observation.
Notice policy graph augments regular graph meaningful node edge labels.
policy graph, P G, also define transition function, Tp : V V, convenience.
Tp (v, o) returns vertex, v , {v, v } E Le ({v, v }) = o.
insight Tp (v, o) root node policy tree represents predictive behavior model updated using action Lv (v) observation o. iterate js models
model node time expansion phase solving I-DID, utilize Tp deciding
whether update model.

first combine policy trees obtained solving models node Mj,l1
obtain
policy graph, P G, shown Fig. 12. Let v vertex P G whose action label, Lv (v), represents rational action mj,l1 Mtj,l1 . ascertain simply checking whether
belief mj,l1 falls within belief range associated node. every observation
Le ({v, }), update model, mj,l1 , using action Lv (v) observation o, v = Tp (v, o)
encountered previously model. illustrate below:
Example 1 (Model update). Consider level 0 models j model node time t, Mtj,0 =
{h0.01, j i, h0.5, j i, h0.05, j i}, multiagent tiger problem. Recall model j,
h0.01, j i, 0.01 js belief (over TL) j frame. PG Fig. 12(c), leftmost
node prescribing action L optimal first third models, second node also
prescribing L optimal second model. Beginning model, h0.01, j i, Tp (v, GL) = v1
(where Lv (v1 ) = L) Tp (v, GR) = v2 (Lv (v2 ) = OL). Since first model consider,
updated using L observations resulting two models Mt+1
j,0 . model,



h0.5, j i, v optimal node (Lv (v ) = L), Tp (v , GR) = v1 , encountered
previously. Hence, model updated using L GR, although updated
using L GL.
226

fiE XPLOITING ODEL E QUIVALENCES OLVING NTERACTIVE DYNAMIC NFLUENCE IAGRAMS

Intuitively, model, mj,l1 , node v1 = Tp (v, o) obtained previously
model action-observation combination, update mj,l1
previously updated model (both policy tree rooted v1 ). Hence, mj,l1 need
updated using observation o. permit updates lead models,
set models obtained + 1 minimal. Applying process analogously models
following time steps lead minimal sets subsequent steps nesting levels.
4.2.2 PPROXIMATION
may gain efficiency avoiding solution models model node first
time step. One way randomly select K models j, K |M0j,l1 |.
Solution models result K policy trees, could combined shown Fig. 12
form policy graph. policy graph utilized discriminate model updates.
Notice approach becomes exact optimal solution model M0j,l1 identical
one K models. K models selected randomly, assumption
implausible approach likely result substantial loss optimality mediated
K.
propose simple effective refinement mitigates loss. Recall models whose
beliefs spatially close likely (Rathnasabapathy et al., 2006). remaining
|M0j,l1 | K models whose belief within 0 belief K models
also solved. additional step makes likely behaviorally distinct solutions
generated included forming policy graph. = 0, models model node
solved leading exact solution, increasing reduces number solved models
beyond K. One measure distance belief points L1 based metric, though
metrics Euclidean distance may also used.
4.3 Transfer Probability Mass
Notice consequence updating models using action-observation combination
probability mass would assigned updated model model node
t+1 lost. Disregarding probability mass may introduce error optimality solution.
perform update model potentially updated model
already exists model node time t+1. could avoid error transfering probability
mass would assigned updated model model.
t+1
t+1
mentioned previously, node od[Mj,l1
] model node Mj,l1
, values
t+1
different models ascribed agent j time + 1. CPT od[Mj,l1 ] implements
t+1
t+1


function (btj,l1 , atj , ot+1
j , bj,l1 ), 1 bj,l1 model mj,l1 updates bj,l1 model




t+1
t+1
mt+1
j,l1 using action-observation combination, otherwise 0. Let mj,l1 = hbj,l1 , j
model mt+1
j,l1 . order transfer probability mass model update


t+1
pruned, modify CPT od[Mj,l1
] indicate mt+1
j,l1 model results
t+1


updating bj,l1 action, aj observation oj . desired effect transfering


probability would assigned updated model (Fig. 6) mt+1
j,l1 model
node time + 1.
227

fiZ ENG & OSHI

4.4 Algorithm
present discriminative update based algorithm solving level l 1 I-DID (as well
level 0 DID) Fig. 13. algorithm differs exact approach (Fig. 10) expansion
phase. addition two time-slice level l I-DID horizon , algorithm takes input
number random models solved initially, K, distance, . Following Section 4.2,
begin randomly selecting K models solve (lines 2-5). remaining models,
identify one K solved model whose belief spatially closest (ties broken randomly).
proximity within , model solved instead, previously computed solution
0
assigned corresponding action node model model node, Mj,l1
(lines 6-12).
Subsequently, models model node associated respective solutions (policy
trees), merged obtain policy graph (line 13), illustrated Fig. 12.
order populate model node next time step, identify node v P G
represents optimal action model time t. model updated using optimal action
aj (= Lv (v)) observation oj node, v = Tp (v, oj ) encountered
previous updates (lines 16-23). Given policy graph, evaluating Tp (v, oj ) constant time
t+1
operation. Otherwise, mentioned Section 4.3, modify CPT node, od[Mj,l1
],
transfer probability mass model (line 25). Consequently, model nodes subsequent
time steps expanded I-DID likely populated minimal sets. Given expanded I-DID,
solution may proceed straightforward manner shown Fig. 10.

4.5 Computational Savings Prediction Error Bound
primary complexity solving I-DIDs due large number models must solved
time steps. time step t, could |M0j,l1 |(|Aj ||j |)t many models
agent j, |M0j,l1 | number models considered initially. nested modeling
contributes complexity since solutions model level l 1 requires solving
lower level l 2 models, recursively level 0. N +1 agent setting,
number models considered level agent bound |M|, solving I-DID
level l requires solutions O((N |M|)l ) many models. Discriminating model updates
reduces number agent models level size behaviorally minimal
set, |Mt |, incurring worst-case complexity O((||T 1 )2 |M|2 ) forming policy
graph (Proposition 2). Consequently, need solve O((N |M |)l ) number models
non-initial time step, largest minimal sets across levels. 2
comparison O((N |M|)l ), grows exponentially time. general, M,
resulting substantial reduction computation. Additionally, reduction number
models model node also reduces size interactive state space, makes solving
I-DID efficient.
0
, order form policy
choose solve models initial model node, Mj,l1
graph, sets models subsequent time steps indeed minimal. Consequently,
loss optimality solution agent level l I-DID.
case select K < |M0j,l1 | models solve, infinitesimally small,
eventually solve models resulting error. increasing values , larger numbers
2. discuss Section 7, may group models across agents well due number models
solved reduces.

228

fiE XPLOITING ODEL E QUIVALENCES OLVING NTERACTIVE DYNAMIC NFLUENCE IAGRAMS

I-DID PPROX (level l 1 I-DID level 0 DID, , K, )
1. l 1
Selectively solve M0j,l1
2. Randomly select K models M0j,l1
3. mkj K models
4.
Recursively call algorithm l 1 I-DID (or DID) represents mkj ,
horizon , K,
5.
Map decision node solved I-DID (or DID), OPT(mkj ), chance node Akj
6. mkj |M0j,l1 | K models
7.
Find model among K whose belief, bkj , closest bkj mkj
8.
||bkj bkj ||1
9.
Map decision node OPT(mkj ) chance node, Akj
10.
else
11.
Recursively call algorithm l 1 I-DID (or DID) represents mkj ,
horizon, , K,
12.
Map decision node solved I-DID (or DID), OPT(mkj ), chance node Akj
13. Combine solutions (policy trees) models bottom obtain policy graph, P G
Expansion Phase
14. 0 2
15.
l 1
t+1
Populate Mj,l1
minimally
16.
mtj Mtj,l1
17.
aj OPT(mtj )
18.
oj j (part mtj )
19.
v vertex P G mtj maps
20.
Tp (v, oj ) encountered previously
SE(btj , aj , oj )
21.
Update js belief, bt+1
j
t+1
22.
mj New I-DID (or DID) bt+1
belief
j

t+1
t+1
23.
Mj,l1 {mj }
24.
else
t+1
25.
Update CPT od[Mj,l1
] s. t. row mtj , aj , oj 1 column
model
t+1
t+1

26.
Add model node, Mj,l1
, model update link Mj,l1
Mj,l1
27.
Add chance, decision, utility nodes + 1 time slice dependency
links
28.
Establish CPTs chance node utility node
solution phase proceeds analogously Fig. 10

Figure 13: Algorithm approximately solving level l 1 I-DID level 0 expanded
time steps using discriminative model updates.

models remain unsolved could erroneously associated existing solutions.
worst case, models may behaviorally distinct K solved models.
Therefore, policy graph subgraph one exact case, leads sets models
229

fiZ ENG & OSHI

subsets minimal sets. Additionally, lower-level models solved approximately
well. seek possibly bound prediction error, impact optimality agent
level l I-DID difficult pinpoint. formally define error discuss bounding including
limitations bound, Appendix A.

5. Grouping Models Using Action Equivalence
Grouping models may significantly reduce given space agents models model
node without loss optimality. may compact space models model node
observing behaviorally distinct models may prescribe identical actions single time step.
may group together models single equivalence class. comparison BE,
equivalence class includes models whose prescribed action particular time step
same, call action equivalence. define formally next.
5.1 Action Equivalence
Notice Fig. 12(c) policy graph contains multiple nodes labeled action
time steps = 0 = 1. associated models prescribing actions identical
particular time step, differ entire behavior. call models actionally equivalent.
general case, define action equivalence (AE) below:
Definition 4 (Action equivalence). Two models, mj,l1 mj,l1 , agent actionally

1
equivalent time step P r(Atj ) = P r(Atj ) P r(atj ) = |OPT(m
atj OPT(mj,l1 ),
j,l1 )|


0 otherwise; P r(atj ) =

1
|OPT(mj,l1 )|



atj OPT(mj,l1 ), 0 otherwise, defined previously.

Since AE may include behaviorally distinct models, partitions model space fewer
classes.
show example aggregation AE models Fig. 14. figure, partition
t=0,2
t=0,1
model set, Mtj,l1 , induced AE time step 0 {Mt=0,1
j,l1 , Mj,l1 }, Mj,l1 class
models model space whose prescribed action = 0 L, Mt=0,2
j,l1 class
models whose prescribed action = 0 OR. Note classes include models
well. Thus, models AE class prescribe identical action time step. Furthermore
= 1, partition consists 3 AE classes and, = 2, partition also consists 3 singleton
classes.
t,p

Mt,p
j,l1 AE class comprising models mj,l1 Mj,l1 , agent conditional belief
obtained summing conditional belief member models:
bi (Mt,p
j,l1 |s) =

X

bi (mtj,l1 |s)

(2)

mtj,l1 Mt,p
j,l1

5.2 Revised CPT Mod Node Markov Blanket

Equation 2 changes CPT node, od[Mj,l1
], due aggregation. Chang Fung
(1991) note coarsening operation type affect distributions

230

fiE XPLOITING ODEL E QUIVALENCES OLVING NTERACTIVE DYNAMIC NFLUENCE IAGRAMS

Mj,l-1t=0,1
0.16

0.23

L
GR

0.32
L

L

GR

GL

OL

L
GR*

OL

GL*

GR

GL

L

GL



GR

0.29
time t=0

L



time t=1

OL

* GL *

GL,0.23 GL,0.32

time t=2

OL

GL



GR,0.45

L

L
GR*



L

L

L

GR,0.23 GR,0.32

L

Mj,l-1t=0,2

GL,0.45 *,1.0



L

GR

L

*GL

*



(b)

(a)

L

GR,0.23

L

L



GR,0.32 GL,0.23 GL,0.32 GR,0.45
GL,0.45 *,1.0

OL

*,1.0

L

L

GL,0.69 GL,0.31

GR,0.22 GR,0.78

OL



L

*,1.0



L

(c)

Figure 14: (a) Annotations example probabilities models associated nodes. (b, c)
may group models prescribe identical actions classes indicated dashed boxes.
Probabilities edges represent probability transition class model given
action observation (ie., CPT next od node).

Ajt

St

Mod[Mjt]

Mod[Mjt+1]

Ojt+1


Figure 15: Markov blanket chance node, od[Mj,l1
], shown bold.

directly involve model space joint probability distribution Markov blanket node,


od[Mj,l1
], remains unchanged. Fig. 15, show Markov blanket od[Mj,l1
]. 3
joint distribution Markov blanket is:
P
t+1
t+1
P r(st , atj , ot+1
, mt+1
) = p P r(st , Mt,p
j
j,l1
j,l1 , aj , oj , mj,l1 )
P
t,p
t,p
t+1
t+1
|Mt,p
= p P r(st )P r(Mj,l1 |st )P r(atj |Mj,l1 )P r(mt+1
j,l1
j,l1 , aj , oj )P r(oj |aj )
P
t,p
t,p
t,p
t+1
t+1
= P r(st )P r(oj |atj ) p P r(Mj,l1 |st )P r(atj |Mj,l1 )P r(mj,l1 |Mj,l1 , atj , ot+1
j )
P P
t)

)P r(at |Mt,p )
t,p
= P r(st )P r(ot+1
|a
P
r(m
|s
j
j
p
j
j,l1
j,l1
mt

j,l1

t,p
t+1
P r(mt+1
j,l1 |Mj,l1 , aj , oj )

(3)

j,l1

(from Eq. 2)


] Ojt+1 thus
3. assume agents frames change, may remove arc od[Mj,l1
simplifying blanket.

231

fiZ ENG & OSHI


joint distribution prior aggregation od[Mj,l1
] is:
t+1
t+1

P r(st , atj , ot+1
j , mj,l1 ) = P r(s )P r(oj |aj )

t+1
P r(mt+1
j,l1 |mj,l1 , aj , oj )

P

mtj,l1 Mtj,l1

P r(mtj,l1 |st )P r(atj |mtj,l1 )

(4)
equate right hand sides Eqs. 3 4 obtain constraint must satisfied
CPTs chance nodes Markov blanket order joint distribution
remain unchanged:
P
t,p
t,p
t+1

t+1
P r(mtj,l1 |st )
p P r(aj |Mj,l1 )P r(mj,l1 |Mj,l1 , aj , oj )
mtj,l1 Mt,p
j,l1
P
t+1





t+1
mtj,l1 Mtj,l1 P r(mj,l1 |s )P r(aj |mj,l1 )P r(mj,l1 |mj,l1 , aj , oj )

P

=

(5)

t+1
Notice Eq. 5 imposes constraint CPTs successor nodes, Atj od[Mj,l1
].
t+1

constraint satisfied setting CPTs nodes, Aj od[Mj,l1 ], found
grouping AE models initial model node exact optimality I-DID
preserved. obvious way satisfy Eq. 5 would meet following intuitive constraint
AE class p:
t,p
t+1
t+1
P r(atj |Mt,p
j,l1 )P r(mj,l1 |Mj,l1 , aj , oj ) =
P

t,p
mt

j,l1
j,l1


t+1 )
P r(mtj,l1 |st )P r(atj |mtj,l1 )P r(mt+1
j,l1 |mj,l1 ,aj ,oj
P
P r(mtj,l1 |st )
t,p


(6)



j,l1
j,l1

t,p
P r(atj |mtj,l1 ) fixed model, mtj,l1 , AE class Mj,l1
equals P r(atj |Mt,p
j,l1 ).
Therefore, Eq. 6 reduces to:

t,p
t+1
P r(mt+1
j,l1 |Mj,l1 , aj , oj )

=

P

t,p
mt

j,l1
j,l1
P


t+1 )
P r(mtj,l1 |st )P r(mt+1
j,l1 |mj,l1 ,aj ,oj

t,p
mt

j,l1
j,l1

P r(mtj,l1 |st )

(7)

Observe Eq. 7 must hold values physical state, st . right hand side
t+1
equation remains unchanged value st , may set CPT od[Mj,l1
]
using it. Typically, trivial often possible find single CPT chance node
t+1
od[Mj,l1
] satisfy constraint st . Chang Fung (1991) demonstrate
close approximation would take average right hand side Eq. 7 possible
values st values close.
t+1
course, may wish aggregate models node, od[Mj,l1
], well (and on).
overall procedure analogous, difference Markov blanket node

aggregated. includes predecessor chance nodes, od[Mj,l1
], Atj , Ojt+1 addition
successors parents successors corresponding Fig. 15.
illustrate application Eq. 7 example policy graph Fig. 14(a) below:
Example 2 (Model update). simplicity, let left AE class, Mt=0,1
j,l1 , comprise three models,
t=0,2
t=0,3
mt=0,1
j,l1 , mj,l1 mj,l1 , prescribe action L. Let belief three models

232

fiE XPLOITING ODEL E QUIVALENCES OLVING NTERACTIVE DYNAMIC NFLUENCE IAGRAMS

0.16, 0.23 0.32 given physical state TL TR, respectively (see Fig. 14(a)). set
probability updating say, Mt=0,1
j,l1 , using different action-observation combinations individual
models time t=1, using Eq. 7. show probabilities Fig. 14(b); form CPT
t=1 ]. P r(mt=0,1 |s) remains given s, constraint Eq. 7 met
node od[Mj,l1
j,l1
AE based partitioning t=0 exact.
Next, group AE models t=1 forming 3 AE classes shown Fig. 14(c). Again, may
set probabilities updating AE class given action-observation combinations individual
models t=2 using right hand side Eq. 7. However, meet constraint
t=0,p t=0 t=1
represented Eq. 7 example, P r(mt=1,1
j,l1 |Mj,l1 , aj , oj ) varies given different
values conditionals. aside, possible meet constraint example.
t=2 ], according average
Consequently, adjust CPT chance node, od[Mj,l1
right hand side Eq. 7 different values conditional variables (see Fig. 14(c)). result,
AE based partitioning t=1 exact.

manifestation approximation agent may think j could initially open
right door, followed listening open left right door again. sequence
actions j possible original policy graph shown Fig. 14(a).
5.3 Algorithm
provide algorithm exploiting AE order solve level l 1 I-DID (as well level
0 DID) Fig. 16. algorithm starts selectively solving lower-level I-DID models
= 0, results set policy trees (line 2). build policy graph merging
policy trees mentioned lines 1-13 Fig 13. algorithm differs Fig. 13
expansion phase. particular, begin grouping together AE models initial model
node. changes value initial od node AE classes (lines 3-9). Subsequently,
updated models AE aggregated time steps, CPTs od nodes
revised reflect constraint involving AE classes (lines 13-24). mentioned Section 5.2,
AE partitioning becomes inexact cannot find CPT successor od node satisfies
Eq. 7. Given expanded I-DID, use standard look-ahead backup method get
solution.
5.4 Computational Savings
mentioned, complexity exactly solving level l I-DID is, part, due solving
lower-level models agent, given solutions, due exponentially growing
space models. particular, time step t, could |M0j,l1 |(|Aj ||j |)t
many models, M0j,l1 set initial models agent. K |M0j,l1 |
models solved, considering AE bounds model space |Aj | distinct classes. Thus,
cardinality interactive state space I-DID bounded |S||Aj | elements
time step. significant reduction size state space. so, additionally
incur computational cost merging policy trees, O((|j |T 1 )2 |M0j,l1 |2 ) (from
Proposition 2). point approach applied recursively solve I-DIDs levels
1, shown algorithm.
233

fiZ ENG & OSHI

I-DID PPROX AE (level l 1 I-DID level 0 DID, , K, )
1. l 1
2. Selectively solve models M0j,l1 Fig. 13 obtain policy graph, P G
Expansion Phase
3. l 1
4. m0j M0j,l1
5.
v vertex P G m0j maps
6.
aj Lv (v) encountered previously
0,aj
7.
Initialize AE class Mj,l1
0,aj
8.
Mj,l1 {m0j }
0
9. Mj,l1 Set AE classes
10. 0 2
11.
l 1
t+1
Populate Mj,l1
using AE classes
12.
13.
14.
15.
16.
17.
18.
19.
20.
21.
22.
23.
24.
25.
26.

t,a

j
Mtj,l1
Mj,l1
t,aj

mtj Mj,l1
aj OP (mtj )
oj j
v vertex P G mtj maps
aj Lv (Tp (v, oj )) encountered previously
t+1,a
Initialize AE class Mj,l1 j
t+1
Update js belief, bj SE(btj , aj , oj )
mt+1
New I-DID (or DID) bt+1
belief
j
j
t+1,aj
}
Mj,l1 {mt+1
j
Mt+1
j,l1 Set AE classes
Update CPT node od[Mt+1
j,l1 ] meet constraint specified Eq. 7
possible, otherwise take average
t+1
t+1

Add model node, Mj,l1
, model update link Mj,l1
Mj,l1
Add chance, decision, utility nodes + 1 time slice dependency
links
Establish CPTs chance node utility node

solution phase proceeds analogously one Fig. 10.

Figure 16: Algorithm possibly inexactly solving level l 1 I-DID using action equivalence.

6. Empirical Results
implemented algorithms Figs. 10, 13 16 refer resulting techniques
Exact-BE, DMU AE, respectively. addition these, utilize previous approximation
technique k-means clustering (Zeng et al., 2007), referred MC, exact approach
without exploiting BE, referred Exact, baselines. MC, models clustered based
spatial closeness beliefs, clusters refined iteratively stabilize.
I-DIDs eventually transform flat DIDs, implemented layer popular ID
234

fiE XPLOITING ODEL E QUIVALENCES OLVING NTERACTIVE DYNAMIC NFLUENCE IAGRAMS

tool, H UGIN E XPERT V 7.0. transformed flat DIDs level 0 DIDs solved using
H UGIN obtain policy trees.
benchmark problem domains, evaluate techniques two well-known toy problems
new scalable multiagent testbed practical implications. One benchmarks
two-agent generalization single agent tiger problem introduced previously Section 3.
mentioned, formulation problem (|S|=2, |Ai |=|Aj |=3, |i |=6, |j |=2) follows
one introduced Gmytrasiewicz Doshi (2005), differs formulation Nair
et al. (2003), cooperative door creaks additional observations.
observations informative, though perfectly, js actions. toy domain generalization Smallwood Sondiks machine maintenance problem (Smallwood & Sondik, 1973)
two-agent domain. problem (|S|=3, |Ai |=|Aj |=4, |i |=|j |=2) fully described
Appendix B.2. I-DIDs problem domains shown Section 3 Appendix B.2,
respectively. Decentralized POMDP solution techniques appropriate baselines cooperative problems machine maintenance absence common initial belief
among agents, I-DIDs take perspective agent interaction instead computing
joint behavior.
physical dimensions problems small, interactive state space includes models agent order magnitude larger. Furthermore, provide advantage facilitating detailed analysis solutions uncovering interesting behaviors previously demonstrated (Doshi et al., 2009). However, beyond increasing horizons, allow
evaluation scalability techniques. context, also evaluate approaches
within Georgia testbed autonomous control vehicles (GaTAC) (Doshi & Sonu, 2010),
computer simulation framework evaluating autonomous control aerial robotic vehicles UAVs. Unmanned agents UAVs used fighting forest fires (Casbeer, Beard,
McLain, Sai-Ming, & Mehra, 2005), law enforcement (Murphy & Cycon, 1998), wartime reconnaissance. operate environments characterized multiple parameters affect
decisions, including agents common antagonistic preferences. task
complicated vehicles may possess noisy sensors unreliable actuators. GaTAC provides
low-cost open-source alternative highly complex expensive simulation infrastructures.
setup execute experiments evaluate following: (a) hypothesize sets
models attributed agent, several BE. lead exact approach
groups models (Exact-BE) significantly efficient plain approach (Exact).
(b) approximation techniques (DMU AE) improve previous approximation
technique k-means clustering (MC). MC generates models time step
clustering furthermore MC may retain models. (c) Finally, DMU AE,
hypothesize AE significantly efficient forms many classes
actions only. However, solution quality resulting DMU AE explored.
6.1 Improved Efficiency Due
report performance exact methods (Exact-BE Exact) used solving
level 1 2 I-DIDs formulated small problem domains. infinitely many
computable models, obtain policy exactly solving I-DID given finite set models
agent initially, 0 . Fig. 17, show average rewards gathered executing
235

fiZ ENG & OSHI

policy trees obtained exactly solving level 1 2 I-DIDs two problem domains,
function time allocated toward solutions.
data point average 200 runs executing policies, true model
agent, j, randomly selected according belief distribution js models. time
consumed function initial number models horizon I-DID,
varied beginning 0 = 50 level.
Multiagent tiger problem
Level = 1

Level = 2
6.5

6.5

6

6

5.5

5.5

Average Reward

Average Reward

7

5
4.5
4
3.5

5
4.5
4
3.5
3

3
Exact-BE
Exact

2.5

Exact-BE
Exact

2.5

2

2
0

5

10

15

20

25

30

40

60

80

100

120

Time(s)

140

160

180

200

220

240

Time(s)

(a)

(b)

Multiagent machine maintenance problem
Level = 2
0.8

0.7

0.7
Average Reward

Average Reward

Level = 1
0.8

0.6
0.5
0.4
0.3
0.2
10

20

30

40
50
Time(s)

60

70

0.5
0.4
0.3
0.2

Exact-BE
Exact
0

0.6

80

90

(c)

0.1
100

Exact-BE
Exact
150

200

250
Time(s)

300

350

400

(d)

Figure 17: Performance profiles exact solutions multiagent tiger (a, b) machine
maintenance problems (c, d). Higher average reward given time better. Exact-BE
significantly improves plain Exact approach levels 1 2. longer times
Exact program runs memory. Vertical bars represent standard deviation
mean.

Fig. 17, observe Exact-BE performs significantly better Exact approach.
Specifically, Exact-BE obtains amount reward Exact less time, subsequently, given allocated time, able obtain larger reward Exact.
able solve better quality solution less time groups together models retains
single representative class, thereby reducing number models held model
node. see significant improvement performances solving I-DIDs levels.
uncover main reason behind improved performance Exact-BE Fig. 18.
may expect, grouping models Exact-BE maintains much fewer classes models (predicting particular behavior agent) number individual models maintained
Exact. occurs horizons problem domains. number models
236

fiE XPLOITING ODEL E QUIVALENCES OLVING NTERACTIVE DYNAMIC NFLUENCE IAGRAMS

Multiagent tiger

Multiagent machine maintenance

50

50
Exact
Exact-BE

Exact
Exact-BE
40
Model Classes

Model Classes

40

30

20

10

30

20

10

0

0
9

8

7

6

5

4

3

2

1

9

8

Horizon

7

6

5

4

3

2

1

Horizon

Figure 18: Exact-BE maintains far fewer classes larger horizons comparison Exact approach. Notice number classes reduces horizon decreases
solutions tend involve fewer distinct behaviors. show increase models time Exact clarity.

increase horizon reduces (but time steps increase) due model updates; however, classes
reduce smaller horizon less distinct behaviors solutions.
increase number levels beyond two model j strategically, expect
Exact-BE (and Exact) result solutions whose average reward possibly improves doesnt
deteriorate. However, number models increases exponentially l, expect substantially computational resources consumed making challenging solve deeper
levels.
6.2 Comparative Performance Approximation Methods
discriminating model updates described Section 4 lead
loss optimality, combined approach solving K (which call KDM U )
models 0 models, solving models -close
KDM U models, form policy graph. Thus, initially examine behavior two
parameters, KDM U , regulate performance DMU-based approximation
technique solving level 1 I-DIDs.
show performance DMU multiagent tiger machine maintenance
problems Fig. 19. also compare performance implementation MC; KM C
represents total number models retained clustering pruning approach.
performance MC shown flat lines play role approach.
data point DMU average 50 runs executing policies true model
agent, j, randomly picked according belief distribution js models, solved
exactly possible. Otherwise, l > 1, solve approximately using DMU large KDM U
small . plot 0 = 100, horizon 10. increase number models
randomly selected, KDM U , reduce distance, , policies improve converge toward
exact. Notice DMU improves performance MC reduce , KDM U = KM C .
behavior remains true multiagent machine maintenance problem well.
evaluate impact AE solving level 1 I-DIDs problem domains compare
MC. experiments run analogously different values KAE .
parameters play roles similar use DMU. observe Fig. 20
237

fiZ ENG & OSHI

Multiagent tiger

Multiagent machine maintenance
0.75

6.5

0.7

6

0.65
Average Reward

Average Reward

7

5.5
5
4.5
KDMU=25
KDMU=50
KMC=25
KMC=50
Exact-BE M0=100

4
3.5
3
0.90

0.70

0.50

0.30

0.10
0.09

0.6
0.55
0.5
0.45

KDMU=25
KDMU=50
KMC=25
KMC=50
Exact-BE M0=100

0.4
0.35
0.3
0.90

0.07

0.70

0.50

0.30



0.10
0.09

0.07



(a)

(b)

Figure 19: Performance profiles DMU horizon =10, level 1 I-DID 0 =100.
given 0 , performance approaches exact method KDM U increases
reduces. comparison MC indicates better performance achieved
DMU-based solutions.
Multiagent tiger

Multiagent machine maintenance
0.75

6.5

0.7

6

0.65
Average Reward

Average Reward

7

5.5
5
4.5
KAE=25
KAE=50
KMC=25
KMC=50
Exact-BE M0=100

4
3.5
3
0.90

0.70

0.50

0.30

0.10
0.09

0.6
0.55
0.5
0.45

KAE=25
KAE=50
KMC=25
KMC=50
Exact-BE M0=100

0.4
0.35
0.07

0.3
0.90

0.70

0.50

0.30



0.10
0.09

0.07



(a)

(b)

Figure 20: Performance profiles AE horizon =10, level 1 I-DID 0 =100. given
0 , performance approaches exact method KAE increases reduces. Comparative performance relation MC indicates AE capable
achieving better quality solutions (although relatively small values ).

reduces models beyond KAE solved, solution generated AE improves
MC case KAE = KM C . course, solve models initially, AE produces
better quality solutions generated policy graph includes parts exact graph.
Additionally, may expect, solution quality approaches exact becomes
significantly close exact (within one standard deviation tiger problem) < 0.1.
previous experiments demonstrated DMU AE capable improving MC, clear many initial models beyond KM C solved obtain
improvements. Furthermore, performance DMU AE compared. Fig. 21,
directly compare performance DMU, AE MC. particular, measure average
rewards obtained corresponding solutions level 2 I-DIDs function time consumed
238

fiE XPLOITING ODEL E QUIVALENCES OLVING NTERACTIVE DYNAMIC NFLUENCE IAGRAMS

Multiagent tiger

Multiagent machine maintenance

6.5

0.65

6
0.6
Average Reward

Average Reward

5.5
5
4.5
4
3.5

0.5

0.45

AE
DMU
MC

3

0.55

2.5

AE
DMU
MC

0.4
40

60

80

100

120

140

160

180

200

220

240

Time(s)

60

80

100

120

140

160

180

200

220

240

Time(s)

Figure 21: Performance comparison approximation techniques solving level 2 I-DIDs. AE
achieves significantly improved efficiency identical quality solutions two
domains.

approaches. DMU AE, time taken dependent parameters (K ), tree
merging horizon I-DID solved. MC, time due iterative clustering
convergence K models picked. problem domains considered, larger
horizon increasing K reducing typically leads better average rewards. observe
DMU AE significantly improve MC produce identical quality solutions
less time MC. Furthermore, DMU AE, latters performance
favorable. because, grouping AE models may result additional approximation,
efficiency made possible fewer AE classes whose number exceed
constant across horizons.
empirically explore reason behind comparative performance approximation
techniques. time (and space) consumed approaches predominantly due
solution models model node, focus models retained approaches
different horizons. Fig. 22 shows models different horizons varying
problem domains. Note = 0, initial models solved case DMU,
results behaviorally minimal set every horizon. Furthermore, mentioned previously,
non-zero , merged policy graph subgraph exact ( = 0) case. show,
resulting sets models subsets minimal set.
horizon, AE maintains model classes number js actions, |Aj |.
see, substantially less number maintained DMU. MC maintains fixed
number, KM C , models horizon I-DID.
6.3 Runtime Comparison
show run times exact approximation techniques solving level 1 2 I-DIDs
scaling horizons, Table 1. Notice plain exact approach exploit
model equivalences scales poorly beyond small horizons. contrast, simply grouping models
reducing exponential growth models leads significantly faster executions better
scaleup. run times reported approaches solving I-DID exactly.
obtaining run times approximations, adjusted corresponding parameters
quality solution approach similar other. DMU AE reported
239

fiZ ENG & OSHI

Multiagent tiger
8

8
Exact-BE
DMU =0.09
DMU =0.5
DMU =0.9

7

6
Model classes

Model Classes

6

Exact-BE
AE =0.09
AE =0.5
AE =0.9

7

5
4
3
2

5
4
3
2

1

1

0

0
9

8

7

6

5

4

3

2

1

9

8

7

6

Horizon

5

4

3

2

1

Horizon

(a)

(b)
Multiagent machine maintenance

6

6
Exact-BE
DMU =0.09
DMU =0.5
DMU =0.9

Exact-BE
AE =0.09
AE =0.5
AE =0.9

5

4

Model classes

Model classes

5

3
2
1

4
3
2
1

0

0
9

8

7

6

5

4

3

2

1

9

Horizon

8

7

6

5

4

3

2

1

Horizon

(c)

(d)

Figure 22: Number models maintained model node different horizon level 1 I-DID
multiagent tiger (a, b) machine maintenance (c, d) problems. DMU,
reduces, model space approaches minimal set. Aggregation using AE
reduces model space.

substantially less execution times better scaleup comparison MC domains.
However, run times DMU AE relatively similar level 1 I-DIDs. Although,
saw previously, difference number models maintained two techniques,
solving js level 0 DIDs quick difference lead significant impact.
differences run times significant level 2 I-DIDs solving js level 1 I-DIDs
computationally intensive. may expect, AE consumes substantially less time comparison
DMU sometimes less half. approaches scale similarly terms horizon.
particular, able solve level 1 2 I-DIDs horizon 10.
scaleup limited predominantly due use software H UGIN solving flat
DIDs, seeks keep entire transformed main memory.
6.4 Scalable Testbed: GaTAC
mentioned, objective behind developing GaTAC provide realistic scalable
testbed algorithms multiagent decision making. GaTAC facilitates providing intuitive easy deploy architecture makes use powerful, open-source software components.
Successful demonstrations algorithms GaTAC would represent tangible gains
potential practical applications toward designing autonomous vehicles UAVs. 4
4. GaTAC available download http://thinc.cs.uga.edu/thinclabwiki/index.php/
GaTAC_:_Georgia_Testbed_for_Autonomous_Control_of_Vehicles

240

fiE XPLOITING ODEL E QUIVALENCES OLVING NTERACTIVE DYNAMIC NFLUENCE IAGRAMS

Level

Domain


4
8
14
4
6
12
3
6
10
4
6
10

Tiger
Level 1
MM

Tiger
Level 2
MM

Exact
5.8s
*
*
6.66s
*
*
3m 24s
*
*
5m12s
*
*

Exact-BE
0.47s
10.5s
2h 4m
0.45s
1.73s
9m 40s
10.97s
22m 6s
2h 48m
1.11s
13.59s
20m 36s

DMU
0.13s
1.27s
15m 6s
0.19s
0.53s
2m 9s
4.63s
6m 54s
27m 36s
0.33s
4.3s
3m 36s

AE
0.42s
1.64s
15m 15s
0.22s
0.58s
2m 12s
3.11s
3m 3s
16m 54s
0.58s
1.48s
2m 15s

MC
2.12s
28.45s
*
3.23s
9.88s
*
1m 46s
*
*
2m 21s
*
*

Table 1: Exploiting model equivalences significant impact execution times. DMU
AE demonstrate improved efficiency. Algorithm involving AE scales significantly
better larger horizons deeper strategy levels. experiments run WinXP
platform dual processor Xeon 2.0GHz 2GB memory. * indicates data
point unavailable program ran memory.

< Socket, port >

Low-level control

High-level control

Communication
Module
(UDP)
Flight Simulator
Instance #1

< Socket, port >

Autonomous
Control Module
High-level state

Flight dynamics

Host 1
Host 2

Flight Simulator
Server

High-level state
Flight Simulator
Instance #2

Communication
Module
< Socket, port >
(UDP)

Flight dynamics

Host 3

manual control

(a)

(b)

Figure 23: (a) Design GaTAC showing two networked instances flight simulator (FlightGear
3D scenery TerraGear), one autonomously manually controlled.
GaTAC extensible instances may added. (b) Snapshot UAV flying
within FlightGear. Different viewpoints including external view shown
cockpit view available.

simplified design GaTAC architecture shown Fig. 23, manually controlled
UAV interacting autonomous one. Briefly, GaTAC employs multiple instances opensource flight simulator, called FlightGear (Perry, 2004), possibly different networked platforms
communicate via external servers, autonomous control module
interacts simulator instances. GaTAC deployed platforms including Linux
241

fiZ ENG & OSHI

Windows moderate hardware requirements, entire source code available
GNU Affero public license version 3.
utilize relatively straightforward setting consisting
another hostile fugitive, target ground reconnaissance (Fig. 24). UAV must track fugitive
flees safe house. problem made complex assuming fugitive unaware precise location though knows location safe house,
may aware fugitives location. problem complicated realistically assume nondeterministic actions observations. simulations

GaTAC include grids sizes 3 3 5 5
actors each. GaTAC may programmed support
complex scenarios comprising team UAVs, multiple
hostile UAVs reconnaissance targets attempting blend Figure 24: Example 5 5 theater
UAV I, perin civilians.
forms low-altitude reconWe summarize formulation UAVs problem
naissance potentially
domain. utilize possible relative positions
hostile theater populated
fugitive states. Hence, possible states would same,
fugitive, J.
north, south, east, west, north-west, on. representation 3 3 theater consists 25 physical states
UAV I. assume fugitive unaware location resulting 9 physical
states it. Extending theater 5 5 grid leads 81 physical states UAV 25
fugitive. factor physical state two variables I-DID model row
column positions, respectively. UAV fugitive may move one four cardinal
directions, may additionally hover current positions listen get informative
observations. Thus actions fugitive {move north, move south, move west,
move east, listen}. may synchronize actions two agents GaTAC allocating
equal time duration performance action. Typically, UAVs infrared camera
sensors whose range limited. Accordingly, assume UAV fugitive
sense whether respective target north (sense north), south (sense south),
west east row (sense level) location (sense found).
target fugitive, fugitives target safe house. assume
fugitive unaware presence, transition function straightforward simply reflects
possible nondeterministic change grid location fugitive moves listens. However,
transitions physical state contingent joint actions agents. Furthermore,
probability distribution next states due nondeterminism actions,
also influenced current relative physical state. provide opportunity UAV
catch fugitive, assume fugitive sense safe house within
distance 1 sector (horizontally vertically) it. hand, UAV observations
fugitive limited constraint. Thus, fugitive location north
(including north-west north-east), receives observation sense north. simulate noise
sensors, assume likelihood correct observation 0.8 others equiprobable. reward function straightforward fugitive receiving reward location
identical safe house, small costs performing actions discourage excessive
242

fiE XPLOITING ODEL E QUIVALENCES OLVING NTERACTIVE DYNAMIC NFLUENCE IAGRAMS

action taking. Analogously, UAV recieves reward performing action receiving
observation sense found, incurs small costs actions lead observations.
Listen

Listen

Move_
North

Sense_
North

Sense_
South

Sense_
Level

Safe

Sense_ Sense_
North
South

*

Move_
North

Listen

Move_
West

Listen

*

*

Move_
North

Listen

Listen
*

Sense_ Sense_
North
South

Move_
North

Listen

Sense_
Level

Move_
West

Safe

Move_
West

Listen

Move_
North

Sense_ Sense_
North
South

Listen

Sense_
Level

Safe

Move_
West

Sense_
Level

Found

Move_
North

Move_
South

Move_
West

Listen

*

*

*

Sense_ Sense_
Found
North
Level

Move_
North

Listen

Move_
East

Move_
North

Listen

Listen

Listen

(b)

(a)

Figure 25: (a) Example policies fugitive modeled UAV. (b) UAV optimal policy
pursuing fugitive obtained solving level 1 I-DID exactly using BE. policy
straightforward, using observations guide actions. policies 3 3
grid.

modeled problem formulation described using level 1 I-DID UAV
level 0 models fugitive. show two example policies fugitive obtained solving
level 0 models, Fig. 25(a). considered several models fugitive differing
initial beliefs, fugitives initial belief likely safe house results left
policy, initial belief likely south east safe house leads policy
right. show UAVs policy reconnaissance Fig. 25(b), obtained solving level 1
I-DID exactly utilizing classes. Thirty models fugitive grouped 16 classes
considered I-DID. Here, UAV initially believes fugitive likely
row south it.
simulate reconnaissance theaters Fig. 24 GaTAC. UAV fugitives
behaviors controlled respective policies provided input autonomous control
module. simulation run, generated UAVs policy solving level 1 I-DID using
either Exact-BE, DMU AE, sampled one fugitives 30 models based UAVs
initial belief. run terminates either fugitive reaches safe house, UAV spots
fugitive entering sector fugitive. case DMU AE, used
parameters, K = 13 = 0.3 3 3 problem size, K = 17, = 0.15 5 5
problem. show average reward gathered UAV across 20 simulation runs
three approaches Fig. 26(a) associated clock time solving I-DIDs Fig. 26(b).
considered several different beliefs UAV, positioning approximately
fugitive safe house yielded fugitive capture rate 65% among simulation runs
escape rate 25%. remaining runs result capture escape.
exactly solving I-DID using Exact-BE continues provide largest reward among
approaches, shown Fig. 26(a), fails scale longer horizon problem size.
DMU AE scale, although AE performs worse DMU context reward domain.
Note longer horizons result overall better quality policies problem domain, may
expect. UAV able plan initial action better. Finally, improved reward
obtained AE relative DMUs horizon increases 6 8 3 3 grid,
243

fiAverage Reward

Z ENG & OSHI

50
40

ExactBE
DMU
AE

Problem size

30

33 grid

20
10
0

3

6

8

3x3

55 grid

6


3
6
8
6
8

Exact-BE
1m 21s
4m 32s
*
*
*

DMU
8.7s
28s
3h 13m
10m 18s
11h 14m

AE
7.13s
19.24s
23m 54s
2m 12s
41m 30s

5x5

Horizon(T)

(a)

(b)

Figure 26: (a) Simulation performance UAV GaTAC level 1 I-DID solved using
different approaches longer horizons. scaled grid size 3 3
5 5. Notice Exact-BE fails scale horizon problem size increase
show reward. (b) Execution times solving level 1 I-DID using
different approaches. Although AE results solutions lower quality compared
DMU, much less time. longer horizon 8, time difference
order magnitude.

slight climb AEs relative reward percentage DMUs 57% 62%
horizon 6 grid size scaled 3 3 5 5 makes us believe AEs performance
necessarily deteriorate compared DMU larger problems. Overall, demonstrate
scalability DMU AE increasing horizon 8 larger problem domain,
scaling size. Larger grid sizes longer horizons resulted DIDs could solved
H UGIN given fixed memory.


SN

SN


SL
SN

SN


SN

(a)

(b)

(c)

Figure 27: UAV flight trajectory dashed blue fugitives dashed red. Trajectories (a, b) eventually lead fugitive spotted (c), fugitive reaches
safe house. latter due incorrect move UAV ambiguity
observations. circle represents hovering UAV fugtive
listening senses labeled observation.

244

fiE XPLOITING ODEL E QUIVALENCES OLVING NTERACTIVE DYNAMIC NFLUENCE IAGRAMS

Finally, handpick three simulations numerous carried show
corresponding trajectories UAV fugitive Fig. 27. show two trajectories
UAV spots fugitive trajectory fugitive successfully escapes safehouse.
Figure 27 shows trajectories UAV get quite complicated fugitive
straightforward due low strategic awareness.

7. Discussion
Graphical models appealing formalism modeling decision making due convenience
representation increased efficiency solution. DIDs key contribution
regard. I-DIDs founded normative paradigm decision theory formalized DIDs
augmented aspects Bayesian games (Harsanyi, 1967) interactive epistemology (Aumann, 1999a, 1999b) make applicable interactions. I-DIDs generalize DIDs multiagent
settings thereby extending advantages DIDs decision making multiagent settings. I-DIDs
adopt subjective approach understanding strategic behavior, rooted decision-theoretic formalism takes decision-makers perspective interaction may cooperative
non-cooperative. broader impact understanding agents decision-making process facilitates planning problem-solving level absence centralized controllers
assumptions agent behaviors. game-theoretic sense, setting modeled I-DIDs
partially observable stochastic game, solving computing Nash equilibria otherwise,
received minimal attention game theory.
presented collection exact approximation algorithms scalably solving I-DIDs.
algorithms improve early techniques providing effective approaches order
reduce exponential growth agents models time step. main idea cluster
models attributed agents BE. models attribute identical behaviors across
time steps agent. select representative models cluster without loss
optimality solution. Instead generating updated models clustering them,
showed may selectively update models existing models
next time step. Nevertheless, ascertaining requires solving initial set models. order
approximate this, proposed solving K randomly picked models followed
-close K models. partially bounded error due approximation
cases. Despite lack proper bound, empirical results reveal error becomes
unwieldy large values only. many problems admit large regions models,
albeit tend reduce horizon increases.
order reduce number equivalence classes, investigated grouping together
models whose prescribed actions particular time step identical. approach appealing
number AE classes upper bounded number distinct actions time.
AE models may grouped without loss optimality, identified conditions
AE leads approximation. experiments indicate considerations
significance grouping AE models leads reduction model space among
different approaches. However, also show gap quality solutions due
grouping grouping AE models become large. difference depends domain
characteristics necessarily worsen problem scaled horizon size.
Due expressiveness modeling ensuing complexity, experimentation
focused settings involving two agents. However, number agents increases, po245

fiZ ENG & OSHI

tential computational savings due exploiting AE assumes greater significance.
space interactive states increases exponentially number agents. Therefore, grouping agent models less numbers classes would substantially reduce state space
consequently size I-DID. may group models separately agent
case computations ascertaining classes grow linearly number agents.
hand, consider tiger problem agent action affected somebody opening
door, without need knowing particular agent opened it. case, may group
together models belonging different agents, leading increased savings.
preliminary experimentation context multiagent tiger problem setting involving
two agents (total three agents) one thought cooperative
adversarial, indicates grouping models agent leads speed 7
3-horizon 5-horizon I-DID. Specifically, computation time reduces 4.8s
Exact 0.6s Exact-BE horizon 3, 72.6s 10.5s Exact-BE
horizon 5.
identifying exact computationally intensive, think improved scalability
may brought investigating approximate models. would allow us form
larger clusters fewer representative models. investigating multiple ways
this, significant challenge storing policy trees grow exponentially horizon
scaled. One promising approach regard compare partial policy trees bounded
depth distance belief vectors leaves trees. allows us define
approximate measure based distance updated belief vectors given
bounded-depth policy trees identical. However, preliminary investigations reveal
deriving depth tree becomes challenging certain types problems.
general limitation utilizing spatial closeness beliefs approximately identifying
models error may larger frames models differ. model
beliefs close still less likely result behavior say, reward functions
different. absence approximation, approaches discriminatively updating
models grouping AE models continue apply frames also uncertain operate
model solutions policy trees actions model specifications. Another impact
considering frame uncertainty Markov blanket shown Fig. 15 changes. general hurdle
scalability ID-based graphical models also limited absence state-ofthe-art techniques solving DIDs within commercial implementations H UGIN E XPERT
predominantly rely solving entire main memory. Although newer versions
H UGIN allow use limited memory IDs (Nilsson & Lauritzen, 2000), recent advances
branch-and-bound approach solving multistage IDs (Yuan, Wu, & Hansen, 2010) would help
drive scalability I-DID solutions.

Acknowledgments
Yifeng Zeng acknowledges support Obel Family Foundation (Denmark) NSFC (#
60974089 # 60975052). Prashant Doshi acknowledges support NSF CAREER grant (#
IIS-0845036) grant U.S. Air Force (# FA9550-08-1-0429). authors also thank Ekhlas
Sonu Yingke Chen help performing GaTAC-based simulations, acknowledge
anonymous reviewers helpful comments.
246

fiE XPLOITING ODEL E QUIVALENCES OLVING NTERACTIVE DYNAMIC NFLUENCE IAGRAMS

Appendix A. Proofs
Proof Proposition 1. prove induction horizon. Let {M1j,l1 , . . . , Mqj,l1 }
collection behaviorally equivalent sets models Mj,l1 . aim show value
actions decision nodes time step remains unchanged application
transformation, X. implies solution I-DID preserved. Let Qn (bi,l , ai ) give
action value horizon n. computation I-DID could modeled using standard dynamic programming approach. Let ERi (s, mj,l1 , ai ) expected immediateP
reward agent
averaged js predicted actions. Then, mq Mq
ERi (s, mqj,l1 , ai ) = aj Ri (s, ai , aj )
j,l1

j,l1

P r(aj |mqj,l1 ) = Ri (s, ai , aqj ), aqj optimal mqj,l1 Mqj,l1 .
P
Basis step: Q1 (bi,l , ai ) = s,mj,l1 bi,l (s, mj,l1 )ERi (s, mj,l1 , ai )
P
P
= s,q bi,l (s) mq Mq
bi,l (mqj,l1 |s)Ri (s, ai , aqj ) (aqj optimal behaviorally equivalent
j,l1
j,l1
models Mqj,l1 )
P
P
= s,q bi,l (s)Ri (s, ai , aqj ) mq Mq
bi,l (mqj,l1 |s)
j,l1
j,l1
P
= s,q bi,l (s)Ri (s, ai , aqj )bi,l (mqj,l1 |s)
(from Eq. 1)
P
q
q
= s,q bi,l (s, mj,l1 )ERi (s, mj,l1 , ai ) (aqj optimal representative mqj,l1 )

= Q1 (bi,l , ai )
Inductive hypothesis: Let, ai ,bi,l Qn (bi,l , ai ) = Qn (bi,l , ai ), bi,l relates bi,l using Eq. 1.
Therefore, U n (bi,l ) = U n (bi,l ) U n (bi,l ) expected utility bi,l horizon n.
P
Inductive proof: Qn+1 (bi,l , ai ) = Q1 (bi,l , ai ) + oi ,s,mj,l1 ,aj P r(oi |s, ai , aj )
P r(aj |mj,l1 )bi,l (s, mj,l1 )U n (bi,l ) (basis step)
P
P
= Q1 (bi,l , ai ) + oi ,s,q P r(oi |s, ai , aqj ) bi,l (s) mq Mq
bi,l (mqj,l1 |s) U n (bi,l ) (aqj optij,l1
j,l1
mal models Mqj,l1 )
P
P
bi,l (mqj,l1 |s) U n (bi,l ) (using
= Q1 (bi,l , ai ) + oi ,s,q P r(oi |s, ai , aqj ) bi,l (s) mq Mq
j,l1
j,l1
inductive hypothesis)
P
= Q1 (bi,l , ai ) + oi ,s,q P r(oi |s, ai , aqj ) bi,l (s) bi,l (mqj,l1 |s) U n (bi,l ) (from Eq. 1)
P
= Q1 (bi,l , ai ) + oi ,s,q P r(oi |s, ai , aqj ) bi,l (s, mqj,l1 ) U n (bi,l )
= Qn+1 (bi,l , ai )

Calculating prediction error Section 4.5. Let mj,l1 model associated solved
model, mj,l1 , resulting worst error. Let exact policy tree obtained solving
mj,l1 optimally policy tree mj,l1 . mj,l1 solved inexactly due
approximate solutions lower level models, let exact policy tree optimal
mj,l1 . bj,l1 belief mj,l1 bj,l1 mj,l1 , error is:
E

= | bj,l1 bj,l1 |
= | bj,l1 bj,l1 + ( bj,l1 bj,l1 )|
(add zero)
= |( bj,l1 bj,l1 ) + ( bj,l1 bj,l1 )|
|( bj,l1 bj,l1 )| + |( bj,l1 bj,l1 )| (triangle inequality)

(8)

first term, | bj,l1 bj,l1 |, denote , error due associating
mj,l1 mj,l1 , solved exactly. analyze error below:
247

fiZ ENG & OSHI

= | bj,l1 bj,l1 |
= | bj,l1 bj,l1 + bj,l1 bj,l1 | (add zero)
| bj,l1 bj,l1 + bj,l1 bj,l1 | ( bj,l1 bj,l1 )
= | (bj,l1 bj,l1 ) (bj,l1 bj,l1 )|
= |( ) (bj,l1 bj,l1 )|
(Holders inequality)
|| || ||bj,l1 bj,l1 ||1
(Rjmax Rjmin )T

(9)

inequality, largest difference bj,l1 bj,l1 , otherwise model,
mj,l1 belief bj,l1 , would solved. Notice error regulated , increases,
solve less models beyond K approximation error worsens.
subsequent time steps, sets models could subsets minimal sets,
updated probabilities could transferred incorrect models. worst case, error incurred
bounded analogously Eq. 9. Hence, cumulative error js predicted behavior steps
, similar previous k-means model clustering approach (Zeng
et al., 2007):
(Rjmax Rjmin )T 2
second term, |( bj,l1 bj,l1 )|, Eq. 8 represents error due approximate
solutions models level (for example, level l 2 models). Since js behavior
depends, part, actions (and value solution), even slight deviation
j exact prediction could lead js behavior worst error. Hence, seems
difficult derive bounds second term tighter usual, (Rjmax Rjmin )T .
Consequently, total error predicting js behavior bounded lower-level models
solved exactly. Otherwise, show Section 6.2, error large large .
many problems admit large regions models thereby overconstraining ,
prediction continues remain exact. However, noticed regions reduce size
horizon increases. summary, although error due associating different models whose
beliefs -close bounded, unable usefully bound overall error prediction due
approximate solutions lower-level models.

Appendix B. Problem Domains
provide detailed descriptions problem domains utilized evaluations, including
I-DID models, below.
B.1 Multiagent Tiger Problem
mentioned previously, multiagent tiger problem non-cooperative generalization
well-known single agent tiger problem (Kaelbling et al., 1998) multiagent setting. differs
multiagent versions problem (Nair et al., 2003) assuming agents
hear creaks well growls reward function promote cooperation. Creaks
indicative door opened agent(s). described problem
Section 3, quantify different uncertainties here. assume accuracy creaks
90%, accuracy growls 85% single agent problem. tiger location
chosen randomly next time step agents opened doors current step.
248

fiE XPLOITING ODEL E QUIVALENCES OLVING NTERACTIVE DYNAMIC NFLUENCE IAGRAMS

Fig. 8 shows I-DID unrolled two time-slices multiagent tiger problem. give
CPTs different nodes below:
hati , atj
hOL,
hOR,
h, OLi
h, ORi
hL, Li
hL, Li

TigerLocationt
*
*
*
*
TL
TR

TL
0.5
0.5
0.5
0.5
1.0
0

TR
0.5
0.5
0.5
0.5
0
1.0

Table 2: CPT chance node igerLocationt+1 I-DID Fig. 8.

assign marginal distribution tigers location agent initial belief
chance node, igerLocationt . CPT igerLocationt+1 next time step conditioned
igerLocationt , Ati , Atj transition function, shown Table 2. CPT
observation node, Growl&Creakt+1 , shown Table 3. CPTs observation nodes level
0 DIDs identical observation function single agent tiger problem.
hati , atj
hL, Li
hL, Li
hL, OLi
hL, OLi
hL, ORi
hL, ORi
hOL,
hOR,

TgrLoct+1
TL
TR
TL
TR
TL
TR



hGL, CLi
0.85*0.05
0.15*0.05
0.85*0.9
0.15*0.9
0.85*0.05
0.15*0.05
1/6
1/6

hGL, CRi
0.85*0.05
0.15*0.05
0.85*0.05
0.15*0.05
0.85*0.9
0.15*0.9
1/6
1/6

hGL, Si
0.85*0.9
0.15*0.9
0.85*0.05
0.15*0.05
0.85*0.05
0.15*0.05
1/6
1/6

hGR, CLi
0.15*0.05
0.85*0.05
0.15*0.9
0.85*0.9
0.15*0.05
0.85*0.05
1/6
1/6

hGR, CRi
0.15*0.05
0.85*0.05
0.15*0.05
0.85*0.05
0.15*0.9
0.85*0.9
1/6
1/6

hGR, Si
0.15*0.9
0.85*0.9
0.15*0.05
0.85*0.05
0.15*0.05
0.85*0.05
1/6
1/6

Table 3: CPT chance node, Growl&Creakt+1 , agent I-DID.
Decision nodes, Ati At+1
, contain possible actions agent L, OL, OR. Model

node, Mj,l1
, contains different models agent j DIDs I-DID level 0,
otherwise I-DIDs themselves. distribution associated od[Mjt ] node (see
Fig. 9) conditional distribution js models given physical state agent initial
t+1
belief. CPT chance node, od[Mjt+1 ], model node, Mj,l1
, reflects prior
model, action observation j results model contained model node.
Finally, utility node, Ri , I-DID relies agents actions, Ati Atj ,
physical states, igerLocationt . utility table shown Table 4. payoffs analogous
single agent version, assigns reward 10 correct door opened, penalty
100 opened door one behind tiger, penalty 1 listening. result
assumption agents actions impact original agents payoffs directly,
rather indirectly resulting states matter original agent. utility tables level
0 models exactly identical reward function single agent tiger problem.
249

fiZ ENG & OSHI

hai , aj
hOR, ORi
hOL, OLi
hOR, OLi
hOL, ORi
hL, Li
hL, ORi
hOR, Li
hL, OLi
hOL, Li

TL
10
-100
10
-100
-1
-1
10
-1
-100

TR
-100
10
-100
10
-1
-1
-100
-1
10

Table 4: Utility table node, Ri , I-DID. Utility table I-DID agent j
column label, hai , aj i, swapped.

B.2 Multiagent Machine Maintenance Problem
extend traditional single agent based machine maintenance (MM) problem (Smallwood &
Sondik, 1973) two-agent cooperative version. Smallwood Sondik (1973) described MM
problem involving machine containing two internal components. Either one components
machine may fail spontaneously production cycle (0-fail: component fails; 1fail: 1 component fails; 2-fail: components fail). internal component failed,
chance operating upon product, cause product defective.
agent may choose manufacture product (M) without examining it, examine product (E),
inspect machine (I), repair (R) next production cycle. examination
product, subject may find defective. course, components failed,
probability product defective greater.

Ri

Ri

Ait

Ait+1
Aj



Ajt+1

Machine
Failuret

Machine
Failuret+1

Mj,l-1t

Mj,l-1t+1

Defectiveit

Defectiveit+1

Figure 28: Level l I-DID agent multiagent MM problem.
level l I-DID multiagent MM problem shown Fig. 28. consider models
agent j lower level differ probability j assigns chance node Machine
Failure. Agent initial belief physical state js models provides marginal distribution achineF ailuret . I-DID, chance node, achineF ailuret+1 , incident
250

fiE XPLOITING ODEL E QUIVALENCES OLVING NTERACTIVE DYNAMIC NFLUENCE IAGRAMS

arcs nodes achineF ailuret , Ati , Atj . Table 5, show CPT chance
node.
hati , atj
hM/E,M/Ei
hM/E,M/Ei
hM/E,M/Ei
hM,I/Ri
hM,I/Ri
hM,I/Ri
hE,I/Ri
hE,I/Ri
hE,I/Ri
hI/R,*i
hI/R,*i
hI/R,*i

Machine Failuret+1
0-fail
1-fail
2-fail
0-fail
1-fail
2-fail
0-fail
1-fail
2-fail
0-fail
1-fail
2-fail

0-fail
0.81
0.0
0.0
1.0
0.95
0.95
1.0
0.95
0.95
1.0
0.95
0.95

1-fail
0.18
0.9
0.0
0.0
0.05
0.0
0.0
0.05
0.0
0.0
0.05
0.0

2-fail
0.01
0.1
1.0
0.0
0.0
0.05
0.0
0.0
0.05
0.0
0.0
0.05

Table 5: CPT chance node, achineF ailuret+1 , level l I-DID agent i. level 0
CPT analogous one original MM problem.

observation chance node, Def ectivet+1
, associate CPT shown Table 6.
Note arcs achineF ailuret+1 nodes, Ati Atj , previous time step
incident node. observation nodes level 0 DIDs CPTs identical
observation function original MM problem.
hati , atj
hM,M/Ei
hM,I/Ri
hE,M/Ei
hE,M/Ei
hE,M/Ei
hE,I/Ri
hI/R,*i

Machine Failuret+1
*
*
0-fail
1-fail
2-fail
*
*

not-defective
0.5
0.95
0.75
0.5
0.25
0.95
0.95

defective
0.5
0.05
0.25
0.5
0.75
0.05
0.05

Table 6: CPT observation node, Def ectivet+1
. Corresponding CPT agent js l 1 I-DID
identical hati , atj swapped.

decision node, Ai , one information arc observation node Def ectiveti indicating knows examination results making choice. utility node Ri associated
utility table Table 7. utility table level 0 agent identical one
original MM problem.
t+1
CPT chance node, od[Mjt+1 ], model node, Mj,l1
, reflects prior
model, action observation j results model contained model node, analogously
tiger problem.
251

fiZ ENG & OSHI

hati , atj
hM,Mi
hM,Ei
hM,Ii
hM,Ri
hE,Mi
hE,Ei
hE,Ii
hE,Ri
hI,Mi
hI,Ei
hI,Ii
hI,Ri
hR,Mi
hR,Ei
hR,Ii
hR,Ri

0-fail
1.805
1.555
0.4025
-1.0975
1.5555
1.305
0.1525
-1.3475
0.4025
0.1525
-1.0
-2.5
-1.0975
-1.3475
-2.5
-4

1-fail
0.95
0.7
-1.025
-1.525
0.7
0.45
-1.275
-1.775
-1.025
-1.275
-3.00
-3.5
-1.525
-1.775
-3.5
-4

2-fail
0.5
0.25
-2.25
-1.75
0.25
0.0
-2.5
-2.0
-2.25
-2.5
-5.00
-4.5
-1.75
-2.0
-4.5
-4

Table 7: Utility table agent i. Agent js utility table l 1 I-DID identical
column label, hati , atj i, swapped.

B.3 UAV Reconnaissance Problem
show level l I-DID multiagent UAV problem Fig 29. Models fugitive (agent
j) lower level differ probability fugitive assigns position grid.
UAVs (agent i) initial beliefs probability distributions assigned relative position
fugitive decomposed chance nodes, F ugRelP osX F ugRelP osY , represent
relative location fugitive along row column, respectively. CPTs assume
action (except listen) moves UAV intended direction probability 0.67,
remaining probability equally divided among neighboring positions. Action listen
keeps UAV position.
observation node, SenF ug, represents UAVs sensing relative position
fugitive grid. CPT assumes UAV good sensing capability (likelihood 0.8
correct relative location fugitive) action listen, otherwise UAV receives
random observations actions.
decision node, Ai , contains five actions UAV, includes moving four
cardinal directions listening. edge incident node indicates UAV ascertains
observation relative position fugitive takes action.
utility node, Ri , reward assigned UAV actions given fugitives relative
position actions. UAV gets rewarded 50 captures fugitive; otherwise, costs -5
performing action.
actual CPT tables large, show here. problem domain
files available upon request.
252

fiE XPLOITING ODEL E QUIVALENCES OLVING NTERACTIVE DYNAMIC NFLUENCE IAGRAMS

Ri

Ri

Ait

Ait+1
Aj



Ajt+1

FugRel
PosXit

FugRel
PosXit+1

FugRel
PosYit

FugRel
PosYit+1

Mj,l-1t

Mj,l-1t+1

SenFugit

SenFugit+1

Figure 29: Level l I-DID agent UAV reconnaissance problem.

References
Andersen, S., & Jensen, F. (1989). Hugin: shell building belief universes expert systems.
International Joint Conference Artificial Intelligence (IJCAI), pp. 332337.
Aumann, R. J. (1999a). Interactive epistemology i: Knowledge. International Journal Game
Theory, 28(3), 263300.
Aumann, R. J. (1999b). Interactive epistemology ii: Probability. International Journal Game
Theory, 28, 301314.
Bernstein, D. S., Givan, R., Immerman, N., & Zilberstein, S. (2002). complexity decentralized control markov decision processes. Mathematics Operations Research, 27(4),
819840.
Brandenburger, A., & Dekel, E. (1993). Hierarchies beliefs common knowledge. Journal
Economic Theory, 59, 189198.
Casbeer, D., Beard, R., McLain, T., Sai-Ming, L., & Mehra, R. (2005). Forest fire monitoring
multiple small uavs. American Control Conference, pp. 35303535.
Castro, P., Panangaden, P., & Precup, D. (2009). Equivalence relations fully partially observable markov decision processes. International Joint Conference Artificial Intelligence
(IJCAI), pp. 16531658.
Chang, K.-C., & Fung, R. (1991). Refinement coarsening bayesian networks. Uncertainty
Artificial Intelligence, pp. 435445.
Dekel, E., Fudenberg, D., & Morris, S. (2006). Topologies types. Theoretical Economics, 1,
275309.
Doshi, P., & Sonu, E. (2010). Gatac: scalable realistic testbed multiagent decision making). Fifth Workshop Multiagent Sequential Decision Making Uncertain Domains
(MSDM), AAMAS, pp. 6266.
253

fiZ ENG & OSHI

Doshi, P., Zeng, Y., & Chen, Q. (2009). Graphical models interactive pomdps: Representations
solutions. Journal Autonomous Agents Multi-Agent Systems (JAAMAS), 18(3),
376416.
Duong, Q., Wellman, M., & Singh, S. (2008). Knowledge combination graphical multiagent
models. Uncertainty Artificial Intelligence (UAI), pp. 153160.
Duong, Q., Wellman, M., Singh, S., & Vorobeychik, Y. (2010). History-dependent graphical multiagent models. International Conference Autonomous Agents Multiagent Systems
(AAMAS), pp. 12151222.
Emery-Montemerlo, R., Gordon, G., Schneider, J., & Thrun, S. (2005). Game theoretic control
robot teams. International Conference Robotics Automation (ICRA), pp. 1163
1169.
Gal, Y., & Pfeffer, A. (2008). Networks influence diagrams: formalism representing agents
beliefs decision-making processes. Journal Artificial Intelligence Research, 33, 109
147.
Givan, R., Dean, T., & Greig, M. (2003). Equivalence notions model minimization markov
decision processes. Artificial Intelligence, 147(1-2), 163223.
Gmytrasiewicz, P., & Doshi, P. (2005). framework sequential planning multiagent settings.
Journal Artificial Intelligence Research (JAIR), 24, 4979.
Harsanyi, J. C. (1967). Games incomplete information played bayesian players. Management Science, 14(3), 159182.
Kaelbling, L., Littman, M., & Cassandra, A. (1998). Planning acting partially observable
stochastic domains. Artificial Intelligence Journal, 101, 99134.
Kearns, M., Littman, M., & Singh, S. (2001). Graphical models game theory. Uncertainty
Artificial Intelligence (UAI), pp. 253260.
Koller, D., & Milch, B. (2001). Multi-agent influence diagrams representing solving games.
International Joint Conference Artificial Intelligence (IJCAI), pp. 10271034.
Madsen, N. S., & Jensen, F. V. (2008). influence diagram framework acting influence
agents unknown goals. Fourth European Workshop Probabilistic Graphical
Models (PGM), pp. 289296.
Mertens, J., & Zamir, S. (1985). Formulation bayesian analysis games incomplete
information. International Journal Game Theory, 14, 129.
Milner, R. (1980). Calculus Communicating Systems. Springer-Verlag.
Murphy, D., & Cycon, J. (1998). Applications mini vtol uav law enforcement. SPIE
3577:Sensors, C3I, Information, Training Technologies Law Enforcement.
Nair, R., Tambe, M., Yokoo, M., Pynadath, D., & Marsella, S. (2003). Taming decentralized pomdps
: Towards efficient policy computation multiagent settings. International Joint Conference Artificial Intelligence (IJCAI), pp. 705711.
Nilsson, D., & Lauritzen, S. (2000). Evaluating influence diagrams using limids. Uncertainty
Artificial Intelligence (UAI), pp. 436445.
254

fiE XPLOITING ODEL E QUIVALENCES OLVING NTERACTIVE DYNAMIC NFLUENCE IAGRAMS

Oliehoek, F. A., Whiteson, S., & Spaan, M. T. J. (2009). Lossless clustering histories decentralized pomdps. International Conference Autonomous Agents Multi-Agent Systems
(AAMAS), pp. 577584.
Perry, A. R. (2004). flightgear flight simulator. UseLinux.
Pineau, J., Gordon, G., & Thrun, S. (2006). Anytime point-based approximations large pomdps.
Journal Artificial Intelligence Research (JAIR), 27, 335380.
Pynadath, D., & Marsella, S. (2007). Minimal mental models. Twenty-Second Conference
Artificial Intelligence (AAAI), pp. 10381044, Vancouver, Canada.
Rathnasabapathy, B., Doshi, P., & Gmytrasiewicz, P. J. (2006). Exact solutions interactive pomdps
using behavioral equivalence. Autonomous Agents Multi-Agents Systems Conference
(AAMAS), pp. 10251032.
Russell, S., & Norvig, P. (2010). Artificial Intelligence: Modern Approach (Third Edition). Prentice Hall.
Seuken, S., & Zilberstein, S. (2007). Memory-bounded dynamic programming dec-pomdps.
International Joint Conference Artificial Intelligence (IJCAI), pp. 20092015.
Seuken, S., & Zilberstein, S. (2008). Formal models algorithms decentralized decision
making uncertainty. Autonomous Agents Multi-Agent Systems, 17(2), 190250.
Smallwood, R., & Sondik, E. (1973). optimal control partially observable markov decision
processes finite horizon. Operations Research (OR), 21, 10711088.
Suryadi, D., & Gmytrasiewicz, P. (1999). Learning models agents using influence diagrams.
International Conference User Modeling, pp. 223232.
Tatman, J. A., & Shachter, R. D. (1990). Dynamic programming influence diagrams. IEEE
Transactions Systems, Man, Cybernetics, 20(2), 365379.
Witwicki, S. J., & Durfee, E. H. (2010). Influence-based policy abstraction weakly-coupled
dec-pomdps. International Conference Automated Planning Scheduling (ICAPS),
pp. 185192.
Yuan, C., Wu, X., & Hansen, E. (2010). Solving multistage influence diagrams using branch-andbound search. Uncertainty Artificial Intelligence (UAI), pp. 691700.
Zeng, Y., Doshi, P., & Chen, Q. (2007). Approximate solutions interactive dynamic influence
diagrams using model clustering. Twenty Second Conference Artificial Intelligence
(AAAI), pp. 782787.

255

fiJournal Artificial Intelligence Research 43 (2012) 419476

Submitted 08/11; published 03/12

Completeness Guarantees Incomplete Ontology
Reasoners: Theory Practice
Bernardo Cuenca Grau
Boris Motik
Giorgos Stoilos
Ian Horrocks

bernardo.cuenca.grau@cs.ox.ac.uk
boris.motik@cs.ox.ac.uk
giorgos.stoilos@cs.ox.ac.uk
ian.horrocks@cs.ox.ac.uk

Department Computer Science, University Oxford
Wolfson Building, Parks Road, OX1 3QD, Oxford

Abstract
achieve scalability query answering, developers Semantic Web applications
often forced use incomplete OWL 2 reasoners, fail derive answers
least one query, ontology, data set. lack completeness guarantees, however,
may unacceptable applications areas health care defence,
missing answers adversely aect applications functionality. Furthermore, even
application tolerate level incompleteness, often advantageous
estimate many kind answers lost.
paper, present novel logic-based framework allows one check whether
reasoner complete given query Q ontology is, whether reasoner
guaranteed compute answers Q w.r.t. arbitrary data set A. Since
ontologies typical queries often fixed application design time, approach allows
application developers check whether reasoner known incomplete general
actually complete kinds input relevant application.
also present technique that, given query Q, ontology , reasoners
R1 R2 satisfy certain assumptions, used determine whether,
data set A, reasoner R1 computes answers Q w.r.t. reasoner R2 .
allows application developers select reasoner provides highest degree
completeness Q compatible applications scalability requirements.
results thus provide theoretical practical foundation design future
ontology-based information systems maximise scalability minimising even
eliminating incompleteness query answers.

1. Introduction
Ecient management querying large amounts data core problem growing
range applications fields diverse biology (Sidhu, Dillon, Chang, & Sidhu, 2005),
medicine (Golbreich, Zhang, & Bodenreider, 2006), geography (Goodwin, 2005), astronomy
(Derriere, Richard, & Preite-Martinez, 2006), agriculture (Soergel, Lauser, Liang, Fisseha,
Keizer, & Katz, 2004), defence (Lacy, Aviles, Fraser, Gerber, Mulvehill, & Gaskill,
2005). order facilitate interoperability, applications often use standard data
models query languages. particular, RDF (Hayes, 2004) provides standard model
semistructured data, SPARQL (Prudhommeaux & Seaborne, 2008) standard query
language RDF, ontology languages OWL (Horrocks, Patel-Schneider, &
van Harmelen, 2003) OWL 2 (Cuenca Grau, Horrocks, Motik, Parsia, Patel-Schneider,
c
2012
AI Access Foundation. rights reserved.

fiCuenca Grau, Motik, Stoilos & Horrocks

& Sattler, 2008b) used describe background knowledge application
domain. Thus, answering SPARQL queries RDF data sets structured using OWL
ontology key service ontology-based information systems.
important question design systems selection appropriate
reasoner. Systems Pellet (Sirin, Parsia, Cuenca Grau, Kalyanpur, & Katz, 2007),
HermiT (Motik, Shearer, & Horrocks, 2009b), RACER (Haarslev & Moller, 2001)
based (hyper)tableau algorithms provably completethat is, guaranteed compute answers query, ontology, data set. Completeness, however,
comes cost scalability, answering queries OWL 2 ontologies high computational complexity (Glimm, Horrocks, Lutz, & Sattler, 2007; Ortiz, Calvanese, & Eiter,
2008; Calvanese, De Giacomo, Lembo, Lenzerini, & Rosati, 2007; Lutz, Toman, & Wolter,
2009). Thus, complete systems often fail meet scalability demands applications
manage data sets consisting hundreds millions even billions assertions.
Scalability query answering ensured restricting expressive power
ontology language level makes provably complete reasoning tractable.
led development three profiles OWL 2 (Motik, Cuenca Grau, Horrocks, Wu,
Fokoue, & Lutz, 2009a): OWL 2 EL, OWL 2 RL, OWL 2 QL. Query answering
three profiles implemented polynomial time w.r.t. size data (and even
logarithmic space case OWL 2 QL). appealing theoretical properties
spurred development specialised reasoners QuONTO (Acciarri, Calvanese,
De Giacomo, Lembo, Lenzerini, Palmieri, & Rosati, 2005) target specific profiles
typically reject ontologies fall outside target profile.
dierent solution scalability problem adopted reasoners Oracles Semantic Data Store (Wu, Eadon, Das, Chong, Kolovski, Annamalai, & Srinivasan,
2008), Sesame (Broekstra, Kampman, & van Harmelen, 2002), Jena (McBride, Brian, 2001),
OWLim (Kiryakov, Ognyanov, & Manov, 2005), Minerva (Ma, Yang, Qiu, Xie, Pan, & Liu,
2006), DLE-Jena (Meditskos & Bassiliades, 2008), Virtuoso (Erling & Mikhailov, 2009).
reasoners accept OWL 2 ontologies inputthat is, never reject inputs.
Furthermore, best knowledge, systems intended sound,
means results query indeed correct answers. Finally, reasoners
typically use scalable reasoning techniques, various (deductive) database algorithms.
consequence, reasoners incomplete: reasoner, least one query, ontology, data set exist reasoner return answers query.
reasoners actually designed complete particular profile
OWL 2 (typically OWL 2 RL due close connection datalog),
often additionally handle certain kinds axiom fall outside target profile.
Since incomplete reasoners handle large data sets, often provide best practical choice developers ontology-based applications. example, OWLim used
reasoning backend BBCs 2010 World Cup website, Oracles reasoner
used University Texas Health Science Center improve large-scale public
health surveillance. order verify selected reasoner meets applications
requirements, developers typically resort empirical testing, check reasoners answers w.r.t. application ontology queries representative data sets.
Although primarily intended testing performance, benchmark suites Lehigh
420

fiCompleteness Guarantees Incomplete Ontology Reasoners

University Benchmark (LUBM) (Guo, Pan, & Heflin, 2005) University Ontology
Benchmark (UOBM) (Ma et al., 2006) used completeness testing.
Empirical completeness testing, however, several important limitations. First, tests
generic, data sets used testing typically fixed and/or repetitive structure, skew test results. Second, test data exhaustive, completeness
tested w.r.t. limited number data sets. Finally, query answers may verifiable: since complete reasoners fail handle large data sets, often cannot compute
control answers needed check answers produced incomplete reasoner.
consequence, empirical completeness tests provide limited assurance reasoners
ability meet requirements given application.
paper, present radically dierent approach solving problems.
observed that, given query Q ontology , even reasoner complete
language , reasoner may able correctly answer Q w.r.t. arbitrary data
set A; case, say reasoner (Q, )-complete. Given ontology-based
applications often use limited set queries fixed ontology (or least queries
ontology evolve relatively slowly), scalable reasoner generally incomplete,
(Q, )-complete relevant combinations Q , may provide solid foundation
ontology-based applications, allowing enjoy best worlds: regardless
data set encountered, applications enjoy completeness guarantees normally
available computationally-intensive complete reasoners, time
exhibiting scalability levels normally available sacrificing completeness. develop
approach testing (Q, )-completeness given reasoner, proceed follows.
Section 3 develop logic-based framework allows us establish formally
provable (Q, )-completeness guarantees. following two notions central
framework. First, order abstract away implementation details concrete
reasoners, introduce notion abstract reasoner idealised reasoner captures intended behaviour salient features (such soundness monotonicity)
class concrete reasoners. Second, introduce notion test suitea finite set
data sets queries. Intuitively, given Q , goal construct test suite
that, reasoner correctly answers queries data sets test suite,
reasoner guaranteed (Q, )-complete.
Unfortunately, show Section 3.4, certain Q , impossible
construct finite test suite provide aforementioned completeness guarantees.
Therefore, investigate assumptions Q, , reasoner testing (Q, )completeness becomes practically feasible.
Section 3.5 consider case Q rewritten union
conjunctive queries Rthat is, answering Q w.r.t data set equivalent
evaluating R A. expressed OWL 2 QL, rewriting R computed
using algorithm Calvanese et al. (2007); additionally, algorithm Perez-Urbina,
Motik, Horrocks (2010) sometimes compute R even syntactically outside
fragment. show R converted test suite ER used
testing (Q, )-completeness reasoner satisfies basic assumptions;
roughly speaking, reasoners answers depend names individuals
occurring data set, answers must increase monotonically new data added.
size test ER polynomial size longest conjunctive query R,
421

fiCuenca Grau, Motik, Stoilos & Horrocks

feasible compute correct answers tests using complete reasoner.
number tests ER , however, exponential size R, may lead
problems practice. remedy, Section 3.6 strengthen assumptions require
reasoner drop answers merging individualsthat is, reasoner returns
given inputs Q, , A, (possibly noninjective) mapping reasoner
returns (a) given inputs Q, , (A)and show (Q, )-completeness
reasoners checked using test suite IR obtained R linear transformation.
Q rewritable union conjunctive queries eectively prevents stating recursive axioms. overcome restriction, Section 3.7 consider first-order reproducible reasonersthat is, reasoners whose behaviour Q, ,
seen computing certain answers Q w.r.t. (possibly unknown) first-order
theory FT A. Since FT datalog program, reasoners based deductive
databases first-order reproducible. addition, require Q rewritable
datalog, extension datalog allows existential quantifiers disjunction rule heads. many cases, transformed datalog, program
using equivalence-preserving transformations; furthermore, algorithm Perez-Urbina
et al. (2010) many cases produce plain datalog rewriting. show
transform datalog, rewriting Q test suite used test
(Q, )-completeness first-order reproducible reasoners.
Section 4 turn attention comparing incomplete reasoners. Roughly speaking, given Q , reasoner R1 complete reasoner R2 if, data set A,
reasoner R1 computes answers Q w.r.t. computed R2 .
show comparing incomplete reasoners infeasible general. Therefore, introduce
notion compact reasonersthat is, reasoners whose behaviour Q, ,
seen first selecting subset using complete reasoner evaluate
Q w.r.t. A. Thus, class compact reasoners captures reasoners reduce
input ontology set axioms match certain parameters, fitting
language fragments. Q rewritten union conjunctive queries
R, show test suite IR used compare compact reasoners.
implemented approaches computing test suites, tested completeness several well-known reasoners (see Section 5). show test suites
eciently computed realistic ontologies. Furthermore, able guarantee
(Q, )-completeness evaluated reasoners many queries ontologies. Finally,
(Q, )-completeness guarantee could provided, able compute
counter-examplea small data set reasoner hand incomplete.

2. Preliminaries
section briefly introduce Description Logics (DLs) (Baader, McGuinness, Nardi, &
Patel-Schneider, 2002)a family knowledge representation formalisms underpin
OWL OWL 2 ontology languages. describe description logics wider
framework first-order logic since many results hold arbitrary first-order theories.
introduce datalog, datalog languages, define syntax
semantics unions conjunctive queries (UCQs). Finally, introduce notions
UCQ, datalog, datalog, rewritings, underpin many techniques.
422

fiCompleteness Guarantees Incomplete Ontology Reasoners

2.1 Description Logics First-Order Logic
results paper hold arbitrary first-order theories, rather description logics. work, however, motivated description logics ontologies, use
DL terminology throughout paper; example, often talk TBoxes
ABoxes instead first-order theories sets facts.
definitions paper implicitly parameterised signature = P , ,
consists countably infinite disjoint sets predicates P individuals (commonly
called constants first-order logic) . predicate associated nonnegative
arity; predicates zero arity commonly called propositional symbols. notions
variables, terms, atoms, first-order formulae, sentences defined usual (Fitting,
1996); consider function symbols article assume formulae
function-free. atom false (true) interpretations written ().
atom fact contain variables. use standard first-order notions
satisfiability, unsatisfiability, entailment (written |=) sets first-order sentences.
assume P contains special equality inequality predicates ,
respectively; atoms form (t1 , t2 ) (t1 , t2 ) commonly written t1 t2
t1 t2 , respectively. make technical assumption distinct predicates
rather than, common first-order logic, t1 t2 abbreviation (t1 t2 );
furthermore, assume theory uses axiomatises semantics
follows, (5) instantiated predicate P arity n 1 n.
x, y.[x x ]

(1)

x, y.[x x]

(3)

x1 , . . . , xi , . . . , xn , yi .[P (x1 , . . . , xi , . . . , xn ) xi yi P (x1 , . . . , yi , . . . , xn )]

(5)

x.[x x]

(2)

x, y, z.[x z x z]

(4)

Note that, according assumption, set facts satisfiable. example,
set atoms {a b, b} satisfiable since b b positive variable-free
atoms semantically independent other; moreover, axiom (1) required
obtain expected contradiction.
individual renaming (often renaming) partial function :
maps individuals individuals. domain range written dom()
rng(); unless otherwise noted, assume dom() finite. object containing
individuals (such formula, set formulae, tuple individuals), ind()
set individuals occurring , () obtained simultaneously replacing
individual ind() dom() (a).
use notion substitutions first-order logic; is, substitution
mapping variables terms. term, atom, formula, result applying
substitution written ().
TBox finite set first-order sentences contains axioms (1)(5) whenever
and/or used. ABox finite set facts. Note definition allows
atoms form b b ABoxes; furthermore, since ABoxes contain
positive atoms, ABox (when considered without TBox) satisfiable.
423

fiCuenca Grau, Motik, Stoilos & Horrocks

DL Name
EL
FL
ALC
+(H)
+(R)
+(S)
+(I)
+(Q)
+(O)

Roles
R
R
R

Concepts
, A, C1 C2 , R.C
, A, C1 C2 , R.C
, , A, C, C1 C2 , C1 C2 , R.C, R.C
R.Self

TBox Axioms
C1 C2
C1 C2
C1 C2
R1 R2
RS
Trans(R)

R
nS.C, nS.C
{a}

Table 1: Syntax standard description logics. Typical extensions EL, ALC, FL
named appending calligraphic letters (H, R, S, I, Q, and/or O).
description logic DL (usually infinite) recursive set TBoxes satisfying
following conditions:
DL renaming , (T ) DL,
DL , DL.

DL, say DL-TBox. Finally, FOL largest description logic
contains finite sets first-order sentences signature question.
next present overview DLs commonly considered literature. Typically, predicates DL signatures required unary binary; former
commonly called atomic concepts latter commonly called atomic roles. DLs
typically use specialised syntax, summarised Table 1, provides set constructors
constructing complex concepts roles simpler ones, well dierent kinds
axioms. Using translation Table 2, concepts translated first-order
formulae one free variable, roles translated first-order formulae two
free variables, axioms translated first-order sentences. Note translation uses counting quantifiers n n , expressed using ordinary
quantifiers equality well-known transformations.
rest paper, commonly write TBoxes ABoxes DL syntax; however,
simplify presentation, identify written DL syntax (T ) (A).
2.2 Datalog,
next introduce fragment first-order logic called datalog, extension
datalog Cal, Gottlob, Lukasiewicz, Marnette, Pieris (2010). datalog, rule
(or commonly rule) r formula form (6), Bj atom dierent
whose free variables contained x,
= 1 1 (x, y1 ) = ,

1 and, 1 m, formula (x, yi ) conjunction atoms dierent
whose free variables contained x yi .
424

fiCompleteness Guarantees Incomplete Ontology Reasoners

Mapping DL roles first-order logic
(R, x, y) = R(x, y)
(R , x, y) = R(y, x)
Mapping DL concepts first-order logic
(, x, y) =
(, x, y) =
(A, x, y) = A(x)
({a}, x, y) = x
(C, x, y) = (C, x, y)
(C D, x, y) = (C, x, y) (D, x, y)
(C D, x, y) = (C, x, y) (D, x, y)
(R.C, x, y) = y.[(R, x, y) (C, y, x)]
(R.Self, x, y) = R(x, x)
(R.C, x, y) = y.[(R, x, y) (C, y, x)]
( nS.C, x, y) = n y.[(S, x, y) (C, y, x)]
( nS.C, x, y) = n y.[(S, x, y) (C, y, x)]
Mapping TBox axioms first-order logic
(C D) = x.[(C, x, y) (D, x, y)]
(R S) = x, y.[(R, x, y) (S, x, y)]
(Trans(R)) = x, y, z.[(R, x, y) (R, y, z) (R, x, z)]
(R ) = x, y, z.[(R, x, y) (S, y, z) (T, x, z)]
Mapping ABox axioms first-order logic
(C(a)) = (C, a, y)
(R(a, b)) = R(a, b)
(a b) = b
(a b) = b
Table 2: Translation DL syntax first-order logic

x.[B1 . . . Bn




i=1

yi .i (x, yi )]

(6)

rule safe variable x also occurs Bj ; unless otherwise noted, rules
assumed safe. brevity, outer quantifier x commonly left implicit.
body r
set atoms body(r) = {B1 , . . . , Bn }, head r formula
head(r) =
yi .i (x, yi ). datalog, program finite set safe datalog, rules.
i=1
Note that, since treated ordinary predicates, occur rules, provided
semantics appropriately axiomatised; furthermore, note latter
achieved using datalog, rules.
Let r datalog, rule. Then, r datalog rule head(r) contains existential
quantifier. Also, r datalog rule = 1. Finally, r datalog rule = 1
head r single atom without existential quantifiers (Ceri, Gottlob, & Tanca, 1989).
several places paper, check whether set first-order sentences entails
datalog, rule, accomplished using following simple result.
425

fiCuenca Grau, Motik, Stoilos & Horrocks

Proposition 2.1. Let F set first-order sentences, let r datalog, rule
form (6). Then, substitution mapping free variables r distinct
individuals occurring F r, F |= r
F {(B1 ), . . . , (Bn )} |=




i=1

yi .i ((x), yi )

Proof. Let x tuple free variables r let arbitrary substitution
mapping variables x distinct individuals occurring F r. claim
proposition follows following equivalences:
F |= x.[B1 . . . Bn




yi .i (x, yi )]

i=1



F {[x.B1 . . . Bn
F {x.[B1 . . . Bn

F {(B1 ) . . . (Bn )
F {(B1 ), . . . , (Bn ),






yi .i (x, yi )]} unsatisfiable

(skolem. x)




i=1

yi .i ((x), yi )} unsatisfiable

yi .i ((x), yi )} unsatisfiable

i=1



F {(B1 ), . . . , (Bn )} |=

yi .i (x, yi )]} unsatisfiable

i=1



i=1

i=1






yi .i ((x), yi ).

2.3 Queries
order achieve high degree generality, define query Q finite set firstorder sentences containing distinct query predicate Q. Intuitively, query predicate Q
determines answers Q. order simplify notation, typically assume
association Q query predicate implicit (e.g., may require query
contain precisely one predicate), assume query predicate occurs
TBox ABox.
tuple constants certain answer query Q query predicate Q
respect TBox ABox arity agrees arity Q
Q |= Q(a). set certain answers Q w.r.t. denoted
cert(Q, , A). query predicate Q propositional (i.e., query Boolean),
cert(Q, , A) either empty contains tuple zero length; cases,
commonly write cert(Q, , A) = f cert(Q, , A) = t, respectively.
use special Boolean query checks first-order theory unsatisfiability.
Thus, cert(, , A) = unsatisfiable.
query Q query predicate Q union conjunctive queries (UCQ)
datalog program rule contains Q head body. UCQ Q
conjunctive query (CQ) contains exactly one rule.
426

fiCompleteness Guarantees Incomplete Ontology Reasoners

union conjunctive queries Q ground if, rule r Q, variable occurring body r also occurs head r. Roughly speaking, computing
cert(Q, , A) ground Q, variables Q matched individuals
A, unnamed objects whose existence guaranteed existential quantifiers.
Many state art reasoners used practice support ground UCQs. Note
Q = {A(x) Q(x), R(x, y) Q(x, y)} ground UCQ; fact, Q even valid
first-order theory since predicate Q unique arity. obtain UCQ, one
pad head first rulethat is, one introduce special fresh individual null
rewrite rules Q = {A(x) Q(x, null ), R(x, y) Q(x, y)}.
properties first-order logic entailment, cert satisfies following properties
query Q, TBoxes , ABoxes .
1. Monotonicity: imply
cert(, , A) = implies cert(, , ) = t,
cert(Q, , A) cert(Q, , ).

2. Invariance renamings: renaming tuple individuals a,
cert(, , A) = implies cert(, (T ), (A)) = t,

cert(Q, , A) implies (a) cert((Q), (T ), (A)).
2.4 Rewritings
Intuitively, rewriting query Q w.r.t. TBox another query captures
information relevant answering Q arbitrary ABox (Calvanese
et al., 2007; Artale, Calvanese, Kontchakov, & Zakharyaschev, 2009; Perez-Urbina et al.,
2010). practice, UCQs (Calvanese et al., 2007) datalog (Perez-Urbina et al., 2010)
widely used target languages query rewriting. sake generality,
however, paper use notion datalog, rewriting.
Definition 2.2. Let Q query let TBox. datalog, rewriting (or simply
rewriting) Q w.r.t. triple R = RD , R , RQ
RD datalog, program containing Q |= RD ,
R datalog program head(r) = r R ,
RQ UCQ whose query predicate Q,
following properties hold ABox A:
cert(, , A) = cert(, RD R , A),
cert(, , A) = f, cert(Q, , A) = cert(RQ , RD R , A).
Rewriting R datalog rewriting RD datalog program. Furthermore, rewriting R
UCQ rewriting RD = ; R usually written R = R , RQ .
427

fiCuenca Grau, Motik, Stoilos & Horrocks

Note Definition 2.2 requires |= RD hold, precludes rewritings consisting
axioms unsound w.r.t. . example, let Q = {A(x) Q(x)} = ;
then, RD = {B(x) A(x)} satisfy definition rewriting since formula
B(x) A(x) logical consequence .
wide range Q, datalog, rewriting Q w.r.t. computed using
straightforward equivalence-preserving transformations ; optimised
eliminating axioms irrelevant answering Q. Furthermore, several
algorithms computing UCQ datalog rewritings proposed literature.
example, Calvanese et al. (2007) showed compute UCQ rewriting cases
expressed logic DL-Lite family, approach extended
OWL 2 QL profile OWL 2 (Motik et al., 2009a). Similarly, Perez-Urbina et al. (2010)
proposed algorithm computing simplest possible datalog rewriting
expressed description logic ELHIO.
Rewritings produced known algorithms often contain predicates occur
Q; predicates sometimes called fresh. example, many rewriting
algorithms normalise TBoxes replacing complex concepts fresh atomic concepts.
rewriting R = RD , R , RQ obtained way unlikely satisfy requirement
|= RD . However, predicates occurring R often eliminated
via unfolding. example, let Q = {A(x) Q(x)} = {R.S.B A}, assume
rewriting algorithm produces
RD = {S(x, y) B(x) C(x), R(x, y) C(y) A(x)}.
satisfy Definition 2.2, predicate C unfolded RD replaced
RD = {R(x, y) S(y, z) B(z) A(x)},
|= RD holds. Unfolding, however, may always possible (e.g., might
case fresh predicates occur recursive axioms), may limit applicability results presented paper.

3. Completeness Guarantees Incomplete Reasoners
section, introduce formal framework allow us establish completeness guarantees incomplete reasoners. results restricted particular
description logic, applicable TBoxes satisfy following criterion.
Definition 3.1. TBox admissible description logic DL exists
DL-TBox, checking TBox satisfiability answering Boolean UCQs w.r.t.
arbitrary ABox decidable DL.
3.1 Concrete Abstract Reasoners
Concrete reasoners complex software systems dier greatly functionality
supported interfaces, use range dierent implementation techniques.
make results general independent specific implementation techniques,
introduce notion abstract reasoner. abstract reasoner thought
428

fiCompleteness Guarantees Incomplete Ontology Reasoners

idealised reasoner captures intended behaviour salient features class
concrete reasoners. concrete reasoner belonging class may use arbitrary algorithms,
long observable behaviour mirrors abstract reasoner.
Definition 3.2. abstract reasoner ans description logic DL computable function takes input arbitrary DL-TBox , arbitrary ABox A, either
special unsatisfiability query arbitrary UCQ Q. return value ans defined
follows:
ans(, , A) either f;
ans(, , A) = t, ans(Q, , A) interest arbitrary;
ans(, , A) = f, ans(Q, , A) finite set tuples individuals,
arity tuple equal arity query predicate Q.
abstract reasoner ans DL said applicable TBox DL-TBox.
Intuitively, ans(, , A) asks abstract reasoner check whether unsatisfiable, ans(Q, , A) asks abstract reasoner evaluate Q w.r.t. A.
unsatisfiable, tuple constants arity query predicate Q
answer Q A; therefore, result ans(Q, , A) interest
ans(, , A) = fthat is, ans identifies satisfiable.
Example 3.3. Consider abstract reasoners rdf, rdfs, rl, classify which, given
input UCQ Q, TBox , ABox A, compute answer Q w.r.t.
described next.
Abstract reasoner rdf ignores evaluates Q w.r.t. A; precisely, rdf(, , A) = f
rdf(Q, , A) = cert(Q, , A). Thus, rdf captures behaviour RDF reasoners.
Abstract reasoner rdfs evaluates Q w.r.t. datalog program Prdfs constructed translating RDFS axiom equivalent datalog rule;
precisely, rdfs(, , A) = f rdfs(Q, , A) = cert(Q, Prdfs , A). Thus, rdfs captures
behaviour RDFS reasoners Sesame.
Abstract reasoner rl evaluates Q w.r.t. datalog program Prl constructed
translating OWL 2 RL axiom equivalent datalog rule; precisely,
rl(, , A) = cert(, Prl , A) rl(Q, , A) = cert(Q, Prl , A). Thus, rl captures behaviour
OWL 2 RL reasoners Jena Oracles Semantic Data Store.
Abstract reasoner classify first classifies using complete OWL 2 DL reasoner; is,
computes TBox containing subclass axiom B |= B,
B atomic concepts occurring . abstract reasoner proceeds rl,
considers instead ; precisely, classify(, , A) = rl(, , )
classify(Q, , A) = rl(Q, , A). way, classify captures behaviour OWL 2
RL reasoners Minerva DLE-Jena try complete materialising
certain consequences .


ideal abstract reasoner one that, arbitrary UCQ Q, TBox ,
ABox A, ans(, , A) = cert(, , A), ans(Q, , A) = cert(Q, , A) whenever
ans(, , A) = f. next introduce discuss several properties abstract reasoners
429

fiCuenca Grau, Motik, Stoilos & Horrocks

likely aect close come ideal may also relevant
applicability results.
following notion soundness describes abstract reasoners return answers
logically follow Q, , A.
Definition 3.4. abstract reasoner ans DL sound following conditions hold
UCQ Q, DL-TBox , ABox A:
ans(, , A) = implies cert(, , A) = t;
ans(, , A) = f implies ans(Q, , A) cert(Q, , A).
following notion monotonicity describes abstract reasoners extending
input TBox ABox never leads dropping answers. also consider weaker
notion (Q, )-monotonicity, input query Q TBox fixed.
Definition 3.5. abstract reasoner ans DL monotonic following conditions
hold UCQ Q, DL-TBoxes , ABoxes
:
ans(, , A) = implies ans(, , ) = t;
ans(, , A) = f ans(, , ) = f imply ans(Q, , A) ans(Q, , ).
Given UCQ Q DL-TBox , ans (Q, )-monotonic following conditions
hold ABoxes :
ans(, , A) = implies ans(, , ) = t;
ans(, , A) = f ans(, , ) = f imply ans(Q, , A) ans(Q, , ).
discussed Section 2.3, logical consequences first-order theory invariant
renaming merging individuals. define analogous properties abstract
reasoners, first introduce notions -stable (Q, )-stable renamingsthat is,
renamings leave individuals occurring (respectively, Q ) unchanged.
Definition 3.6. Let Q query, let TBox, let renaming. Then, stable (a) = individual dom() ind(T ); furthermore, (Q, )-stable
(a) = individual dom() ind(Q ).
following notion weak faithfulness describes abstract reasoners whose answers
invariant replacement individuals fresh individuals. Furthermore, weak
(Q, )-faithfulness relaxes property case Q fixed.
Definition 3.7. abstract reasoner ans DL weakly faithful following conditions hold UCQ Q, DL-TBox , ABox A, injective renaming , tuple a:
ans(, , A) = ind(T A) dom() imply ans(, (T ), (A)) = t;
ans(, , A) = f, ind(Q A) dom(), ans(Q, , A) imply
ans(, (T ), (A)) = f (a) ans((Q), (T ), (A)).
430

fiCompleteness Guarantees Incomplete Ontology Reasoners

Given UCQ Q DL-TBox , ans weakly (Q, )-faithful following conditions
hold ABox A, injective renaming , tuple a:
ans(, , A) = t, ind(T A) dom(), -stable imply ans(, , (A)) = t;

ans(, , A) = f, ind(Q A) dom(), (Q, )-stable, ans(Q, , A)
imply ans(, , (A)) = f (a) ans(Q, , (A)).
following notion strong faithfulness describes abstract reasoners whose answers
invariant merging individuals. Furthermore, strong (Q, )-faithfulness relaxes
property case Q fixed.
Definition 3.8. abstract reasoner ans DL strongly faithful following conditions hold UCQ Q, DL-TBox , ABox A, renaming , tuple a:
ans(, , A) = implies ans(, (T ), (A)) = t;
ans(, , A) = f, ans(Q, , A), ans(, (T ), (A)) = f imply
(a) ans((Q), (T ), (A)).
Given UCQ Q DL-TBox , ans strongly (Q, )-faithful following conditions hold ABox A, renaming , tuple a:
ans(, , A) = -stable imply ans(, , (A)) = t;
ans(, , A) = f, (Q, )-stable, ans(Q, , A), ans(, , (A)) = f imply
(a) ans(Q, , (A)).
results present rest paper applicable abstract
reasoners satisfy various combinations properties; minimum, require
(Q, )-monotonicity weak (Q, )-faithfulness. abstract reasoners described Example 3.3 satisfy properties. Testing case concrete reasoners may,
however, infeasible practice; indeed, aware technique would allow one check whether concrete reasoner satisfies required properties. believe,
however, concrete reasoners commonly used practice intended sound,
monotonic, least weakly faithful, strong faithfulness reasonable assumption cases. concrete reasoner fails satisfy properties
certain inputs, likely due implementation bugs; thus, consequent failure
completeness seen bug, detecting situations viewed
part general problem testing software systems.
next present several examples abstract reasoners satisfy
mentioned properties.
Example 3.9. Consider abstract reasoner behaves rdf whenever number
assertions input ABox smaller certain threshold, returns
empty set answers larger ABoxes. Intuitively, abstract reasoner characterises
concrete RDF reasoner processes inputs certain size. reasoner
(Q, )-monotonic arbitrary Q .

431

fiCuenca Grau, Motik, Stoilos & Horrocks

Example 3.10. Consider abstract reasoner behaves like rdf, that, trust
reasons, removes input ABox assertions whose individuals blacklisted
(e.g., come untrusted source). abstract reasoner weakly (Q, )faithful arbitrary Q .

Example 3.10 suggests that, abstract reasoner weakly faithful,
make decisions depend specific names individuals.
Example 3.11. Consider abstract reasoner rl= that, given input UCQ Q, TBox
, ABox A, proceeds follows. First, rl= computes ABox obtained
evaluating datalog program Prl Example 3.3 A. Second, rl= computes
query Q= obtained Q adding body rule r Q inequality x
pairs distinct variables x occurring r. Third, rl= evaluates Q=
considering databasethat is, finite first-order interpretation
individual mapped (and thus dierent individuals distinct). Thus, rl= characterises concrete reasoners evaluate queries matching dierent variables dierent
individuals. Abstract reasoner rl= sound, monotonic, weakly faithful,
strongly faithful. example, given query Q = {R(x, y) Q(x)}, ABox = {R(a, b)},
renaming = {a c, b c}, rl= (Q, , A) = {a}, rl= (Q, , (A)) = .
Example 3.11 suggests that, abstract reasoner strongly faithful,
allow distinct variables queries axioms mapped individuals.
next identify classes abstract reasoners use throughout paper. Note
soundness required, contributes generality results.
Definition 3.12. Given UCQ Q TBox , CwQ,T (CsQ,T ) class (Q, )monotonic weakly (strongly) (Q, )-faithful abstract reasoners applicable .
Finally, note abstract reasoners introduced Example 3.3 sound, monotonic, strongly (and therefore also weakly) faithful. Consequently, concrete reasoners
based reasoning techniques outlined Example 3.3 considered sound, monotonic,
strongly faithful, modulo implementation bugs.
3.2 Completeness Abstract Reasoners
next define central notion abstract reasoner completeness given query Q
TBox . Intuitively, (Q, )-complete abstract reasoner indistinguishable
complete abstract reasoner applied Q, , arbitrary ABox A.
Definition 3.13. Let DL description logic, let ans abstract reasoner DL.
Then, ans (Q, )-complete UCQ Q DL-TBox following conditions
hold ABox A:
cert(, , A) = t, ans(, , A) = t;
cert(, , A) = f ans(, , A) = f, cert(Q, , A) ans(Q, , A).
Finally, ans complete (Q, )-complete UCQ Q DL-TBox .
432

fiCompleteness Guarantees Incomplete Ontology Reasoners

Example 3.14. Consider EL-TBox consisting following axioms; translation
axioms first-order logic shown symbol.
takesCo.MathCo St



MathSt takesCo.MathCo



CalcCo MathCo



St Prof



x, y.[takesCo(x, y) MathCo(y) St(x)]
x.[CalcCo(x) MathCo(x)]

(7)
(8)

x.[MathSt(x) y.[takesCo(x, y) MathCo(y)]] (9)
x.[St(x) Prof(x) ]

(10)

Axiom (7) states everyone taking maths course student; axiom (8) states
calculus course also maths course; axiom (9) states maths student takes
maths course; axiom (10) states person student
professor. Axiom (8) RDFS axiom, axioms apart (9) OWL
2 RL axioms. Consider also query (11) retrieves students taking maths course.
Q = {St(x) takesCo(x, y) MathCo(y) Q(x)}

(11)

None abstract reasoners rdf, rdfs, rl, classify Example 3.3 complete
general answering UCQs EL-TBoxes. Furthermore, Q previous
paragraph, abstract reasoners rdf, rdfs, rl (Q, )-complete, return
empty set answers ABox = {MathSt(c)}. contrast, following sections
show abstract reasoner classify (Q, )-completethat is, returns
certain answers Q, , arbitrary ABox A.

3.3 Test Suites
Checking (Q, )-completeness concrete reasoner applying reasoner possible
ABoxes comparing reasoners answers complete reasoner clearly
infeasible practice since infinitely many candidate input ABoxes. obtain
practical approach, need finite number tests. formalise idea using
following definition.
Definition 3.15. Let TBox. -test suite pair = , SQ
finite set ABoxes cert(, , A) = ,
SQ finite set pairs A, ABox cert(, , A) = f
UCQ.
abstract reasoner ans applicable passes -test suite ans satisfies
following two conditions:
, ans(, , A) = t,
A, SQ , ans(, , A) = f, cert(Y, , A) ans(Y, , A).
Let Q UCQ, let C class abstract reasoners applicable . Then,
exhaustive C Q ans C passes (Q, )-complete.
-test suite Q-simple Q query occurring SQ ; then, SQ commonly written set ABoxes, A, Q SQ commonly abbreviated SQ .
433

fiCuenca Grau, Motik, Stoilos & Horrocks

Intuitively, -test suite = , SQ determines tests abstract reasoner
subjected to. reasoner pass S, must correctly identify ABox
unsatisfiable, ABoxquery pair A, SQ reasoner must
correctly answer w.r.t. A.
Given Q , goal identify -test suite exhaustive Qthat
is, test suite abstract reasoner passes guaranteed (Q, )complete. Depending properties abstract reasoners, however, dierent test suites
may may achieve goal. Therefore, notion exhaustiveness relative
class abstract reasoners C: exhaustive class abstract reasoners C,
used test arbitrary abstract reasoner C. Note depends
target class abstract reasoners, actual abstract reasoner tested;
order words, construction depends properties one assume hold
target abstract reasoner. Furthermore, abstract reasoner contained C
passes S, general imply (Q, )-completeness guarantee.
Example 3.16. Let Q specified Example 3.14, let A1 A6
following ABoxes.
A1 = {takesCo(c, d), MathCo(d)}
A3 = {takesCo(c, d), CalcCo(d)}
A5 = {MathSt(c)}

A2 = {takesCo(c, c), MathCo(c)}
A4 = {takesCo(c, c), CalcCo(c)}
A6 = {St(c), Prof(c)}

following sections, show Q-simple -test suite = , SQ defined
= {A6 } SQ = {A1 , . . . , A5 } exhaustive class CwQ,T Q; consequently,
used test abstract reasoners Example 3.3.
particular, note abstract reasoners rdf rdfs fail tests SQ ,
abstract reasoner rl fails test A5 SQ ; furthermore, failed tests provide counterexample (Q, )-completeness. contrast, abstract reasoner classify Example
3.14 passes tests S, implies abstract reasoner indeed (Q, )-complete.
Finally, consider variant abstract reasoner classify that, similarly abstract
reasoner described Example 3.9, returns empty set answers input ABox
contains than, say, ten assertions. abstract reasoner (Q, )-monotonic
hence belong CwQ,T . abstract reasoner clearly passes S; however, since
belong CwQ,T , passing (correctly) imply abstract reasoner
(Q, )-complete.

next state following property, proof trivial.

Proposition 3.17. Let Q UCQ, let TBox, let C1 C2 classes
abstract reasoners applicable C1 C2 .
1. -test suite exhaustive C2 Q, also exhaustive C1 Q.
2. -test suite exists exhaustive C1 Q, -test suite exists
exhaustive C2 Q.
Therefore, proving existence -test suite exhaustive Q, general
result one applies largest possible class abstract reasoners. Furthermore,
434

fiCompleteness Guarantees Incomplete Ontology Reasoners

following section identify cases -test suite exhaustive Q
found; Proposition 3.17 suces provide nonexistence results smallest
possible class abstract reasoners.
finish section pointing important practically relevant property
Q-simple -test suites, illustrated Example 3.16.
Proposition 3.18. Let = , SQ Q-simple -test suite let ans abstract
reasoner applicable . ans pass S, ans (Q, )-complete.
Proof. ABox SQ ans satisfy conditions Definition
3.15 counterexample (Q, )-completeness ans.
Thus, Q-simple -test suite exhaustive C Q provides sucient necessary test (Q, )-completeness abstract reasoners C. contrast,
Q-simple, show Section 3.7 provides sucient, also
necessary test (Q, )-completeness abstract reasoners C.
3.4 Negative Results
Sections 3.5 (resp. Section 3.6) identify restrictions UCQ Q TBox
guarantee existence -test suites exhaustive CwQ,T (resp. CsQ,T ) Q.
presenting positive results, first outline limits (Q, )-completeness testing
thus justify restrictions use following sections.
3.4.1 Monotonicity Weak Faithfulness
approaches testing (Q, )-completeness abstract reasoners applicable
reasoners (Q, )-monotonic weakly (Q, )-faithful. section, provide
formal justification requirements form following two theorems.
Theorem 3.19 shows exhaustive test suites exist consider class
abstract reasoners satisfying properties Section 3.1 apart (Q, )monotonicity; includes soundness, strong faithfulness (which implies weak faithfulness), monotonicity w.r.t. TBox only.
Theorem 3.20 shows exhaustive test suites exist consider class
abstract reasoners satisfying properties defined Section 3.1 exception
(Q, )-weak faithfulness; properties include soundness monotonicity.
negative results Theorems 3.19 3.20 strong: hold smallest
classes abstract reasoners define based notions introduced Section 3.1 (by
Proposition 3.17, smaller class abstract reasoners, general negative
result); hold regardless Q considered (modulo minor technicality:
unlike Theorem 3.19, Theorem 3.20 requires satisfiable).
proof Theorem 3.19 intuitively understood follows. first assume
-test suite exhaustive Q class abstract reasoners
theorem applies. Then, specify abstract reasoner ans right thing (i.e.,
returns correct answer) given input query Q, TBox ,
435

fiCuenca Grau, Motik, Stoilos & Horrocks

arbitrary ABox containing many assertions largest test ABox S;
otherwise, ans returns sound, incomplete answer. finally show following
three properties ans.
Abstract reasoner ans belongs relevant class abstract reasoners.
Abstract reasoner ans passes S.
Abstract reasoner ans incomplete least one input ABox.
three properties show exhaustive Q relevant class
abstract reasoners. Intuitively, means class abstract reasoners large,
allowing abstract reasoners treat input erratic way.
Theorem 3.19. Let Q arbitrary UCQ, let arbitrary admissible TBox.
Then, -test suite exists exhaustive Q class sound strongly
faithful abstract reasoners applicable satisfying following conditions TBox
ABox A:
ans(, , A) = implies ans(, , A) = t;
ans(, , A) = f ans(, , A) = f imply ans(Q, , A) ans(Q, , A).
Proof. Consider arbitrary -test suite = , SQ . Let n maximum number
assertions ABox S. Furthermore, let ans abstract reasoner takes
input UCQ Qin , FOL-TBox Tin , ABox . result ans(, Tin , )
determined follows.
1. Try find renaming dom() = ind(T ) (T ) Tin ;
exists, return f.
2. contains n assertions, check satisfiability (T ) using
sound complete reasoner; return (T ) unsatisfiable.
3. Return f.
Furthermore, result ans(Qin , Tin , ) determined follows.
4. Try find renaming dom() = ind(Q ), (T ) Tin , (Q) = Qin ;
exists, return .
5. contains n assertions, compute cert((Q), (T ), ) using sound
complete reasoner return result.
6. Return .
Since admissible, checks steps 2 5 performed finite time; furthermore, step 1 realised enumerating mappings ind(T ) ind(Tin ), step
4 realised analogously; consequently, ans implemented terminates
inputs. see ans sound monotonic w.r.t. TBox, consider arbitrary
input Qin , Tin , Tin , Tin Tin .
436

fiCompleteness Guarantees Incomplete Ontology Reasoners

Assume ans(, Tin , ) = t. Then, Qin , Tin , abstract reasoner
returns step 2 (T ) unsatisfiable; then, since (T ) Tin ,
Tin unsatisfiable well, required soundness. Furthermore,
since (T ) Tin Tin , Qin , Tin , abstract reasoner returns step 2
well, ans(, Tin , ) = t, required monotonicity w.r.t. TBox.
Assume ans(Qin , Tin , ). Then, Qin , Tin , abstract reasoner
returns step 5, therefore cert((Q), (T ), ); then, since
(Q) = Qin (T ) Tin , cert(Qin , Tin , ), required soundness. Furthermore, since (T ) Tin Tin , Qin , Tin , abstract reasoner
returns step 5 well, ans(Qin , Tin , ), required monotonicity w.r.t.
TBox.
see ans strongly faithful, consider arbitrary renaming . renaming
exists (Q) = Qin (T ) Tin , clearly renaming exists
(Q) = (Qin ) (T ) (Tin ). Consequently, ans(, Tin , ) returns step 2,
ans(, (Tin ), (Ain )) returns step 2 well; similarly, ans(Qin , Tin , ) returns step
5, ans((Qin ), (Tin ), (Ain )) returns step 5 well; clearly, ans strongly faithful.
Finally, straightforward see ans passes S.
let ABox containing least n + 1 assertions cert(Q, , A) = ;
clearly exists. unsatisfiable, ans(, , A) = f; furthermore,
satisfiable, ans(Q, , A) = ; consequently, ans (Q, )-complete. Thus,
exhaustive Q class abstract reasoners considered theorem.
next prove Theorem 3.20. proof similar proof Theorem 3.19,
main dierence abstract reasoner ans construct. particular, given test
suite S, take ans return correct answer query Q, TBox ,
ABox contains individuals occurring S; otherwise, abstract reasoner
returns sound, incomplete answer. Again, class abstract reasoners
large, allowing ans treat inputs erratic way.
Unlike Theorem 3.19, following theorem requires satisfiable; understand
why, consider arbitrary unsatisfiable TBox UCQ Q. Let = , SQ
-test suite defined = {} (i.e., contains single empty ABox) SQ = (i.e.,
SQ contains ABoxes), consider arbitrary monotonic abstract reasoner ans
passes . Since ans passes S, ans(, , ) = t; then, since ans monotonic,
arbitrary ABox ans(, , A) = well, turn implies ans
(Q, )-complete. Failure satisfy weak faithfulness thus irrelevant unsatisfiable.
Theorem 3.20. Let arbitrary admissible satisfiable TBox let Q
arbitrary UCQ. Then, -test suite exists exhaustive Q class
sound monotonic abstract reasoners applicable .
Proof. Consider arbitrary -test suite = , SQ . Let set individuals
occurring S, Q, . Furthermore, let ans abstract reasoner takes
input UCQ Qin , FOL-TBox Tin , ABox . result ans(, Tin , )
determined follows.
1. Tin , return f.
437

fiCuenca Grau, Motik, Stoilos & Horrocks

2. Let Ain,I set assertions mention individuals I.
3. Check satisfiability Ain,I using sound complete reasoner; return
Ain,I unsatisfiable, return f otherwise.
Furthermore, given UCQ Qin , result ans(Qin , Tin , ) determined follows:
4. Tin Q =
Qin , return .
5. Let Ain,I set assertions mention individuals I.
6. Compute cert(Q, , Ain,I ) using sound complete reasoner return result.
ans implemented terminates inputs shown
proof Theorem 3.19. Furthermore, soundness ans follows following
two observations.
Assume ans(, Tin , ) = t. Then, abstract reasoner returns step 3 since
Ain,I unsatisfiable; then, since Tin Ain,I ,
Tin unsatisfiable well, required.
Assume ans(Qin , Tin , ). Then, abstract reasoner returns step 6,
therefore cert(Q, , Ain,I ); then, since Q = Qin , Tin ,
Ain,I , cert(Qin , Tin , ), required.
monotonicity, consider arbitrary Tin Tin Tin ;
clearly, Tin Ain,I Ain,I ; then, monotonicity first-order logic,
ans(, Tin , ) = implies ans(, Tin , ) = t, ans(Q, Tin , ) ans(Q, Tin , ). Finally, straightforward see ans passes S.
consider arbitrary ABox ind(A) = cert(Q, , A) = ;
clearly exists. unsatisfiable, since ABox constructed step 2 empty
satisfiable, ans(, , A) = f; furthermore, satisfiable, since
ABox constructed step 5 empty, ans(Q, , A) cannot contain individuals occurring
I; consequently, ans (Q, )-complete. Thus, exhaustive Q
class abstract reasoners considered theorem.
3.4.2 Monotonicity Weak Faithfulness Suffice
Next, show (Q, )-monotonicity (Q, )-faithfulness general guarantee
existence -test suite exhaustive Q. particular, Theorem 3.21 shows that,
contains single recursive axiom, test suite exists exhaustive class
sound, monotonic, strongly faithful abstract reasoners (and Proposition 3.17
CsQ,T CwQ,T well, UCQ Q). Although result applicable
particular Q , straightforward adapt proof TBox recursive
axiom relevant given query. Example 3.22, however, shows concept
relevance rather dicult formalise: even entails recursive axiom, axiom
necessarily relevant answering query. order complicate matters
further, state following result fixed Q , hope proof clearly
illustrates limitations incurred recursive axioms.
438

fiCompleteness Guarantees Incomplete Ontology Reasoners

Theorem 3.21. Q = {A(x) Q(x)} = {R.A A}, -test suite exists
exhaustive Q class sound, monotonic, strongly faithful abstract
reasoners applicable .

Proof. Consider arbitrary -test suite = , SQ . Since -test suite,
contains ABoxes unsatisfiable; clearly, ABox exists
stated theorem, = . Let SQ arbitrary, finite, set pairs A,
ABox UCQ, let n maximum number assertions ABox
SQ . Furthermore, consider following ABox, ai = aj 1 < j n + 1:
An+1 = {R(a0 , a1 ), . . . , R(an , an+1 ), A(an+1 )}
next construct abstract reasoner pEvaln following properties:
(P1) A, SQ , cert(Y, , A) pEvaln (Y, , A);
(P2) a0 pEvaln (Q, , An+1 );
(P3) pEvaln sound, monotonic, strongly faithful.
Note a0 cert(Q, , An+1 ), three properties imply exhaustive
Q class abstract reasoners considered theorem.
Abstract reasoner pEvaln accepts input FOL-TBox Tin ABox .
result pEvaln (, Tin , ) determined follows.
1. Return f.

Furthermore, given UCQ Qin , result pEvaln (Qin , Tin , ) determined follows.
2. Tin Q =
Qin , return .
3. Asat :=
4. Repeat following computation n times:
Asat := Asat {(A(x)) | substitution s.t. {(R(x, y)), (A(y))} Asat }
5. Return cert(Q, , Asat ).

Abstract reasoner pEvaln clearly satisfies Property (P2) deriving assertion A(a0 )
requires n+1 iterations loop step 4. Furthermore, pEvaln also satisfies (P1)
every ABox occurring SQ contains n individuals seen
rule R(x, y) A(y) A(x), pEvaln applies n times input ABox .
finally show (P3). Abstract reasoner pEvaln clearly sound. Furthermore,
renaming (T ) = (Q) = Q, pEvaln clearly strongly faithful.
show pEvaln monotonic, consider arbitrary Tin , Tin , ,
Tin Tin ; since pEvaln (, Tin , ) = f input, following
relevant cases.
pEvaln returns step 2 input Qin , Tin , , case either Tin
Q = Qin . Since Tin Tin , clearly pEvaln also returns step 2 input Qin , Tin ,
, monotonicity holds.
439

fiCuenca Grau, Motik, Stoilos & Horrocks

pEvaln returns step 5 input Qin , Tin , . Then, pEvaln return either
step 2 step 5 input Qin , Tin ; former case, monotonicity holds
trivially, latter case, pEvaln (Qin , Tin , ) pEvaln (Qin , Tin , ) follows
directly fact .
following example shows presence recursive axioms preclude existence -test suite exhaustive Q.
Example 3.22. Consider Q defined follows:
Q = {A(x) B(x) Q(x)}
= {R.A A, B R.A}
Note contains axiom mentioned Theorem 3.21; however, note also
|= B A,
R = , {B(x) Q(x)}

UCQ rewriting Q w.r.t. . Section 3.5 show existence UCQ rewriting Q w.r.t. guarantees existence Q-simple -test suite exhaustive CwQ,T
(and hence also CsQ,T ) Q; example, = , { {B(a)} } one -test suite.
Intuitively, |= B consequence relevant answering Q; hence,
= {B A} Q = {A(x) Q(x)}, cert(Q, , A) = cert(Q , , A)
arbitrary ABox A. Hence, recursive axiom irrelevant answering Q,
therefore presence preclude existence -test suite exhaustive
CwQ,T Q.

3.5 Testing (Q, )-Monotonic Weakly (Q, )-Faithful Abstract Reasoners

section, identify sucient condition guarantees existence Q-simple
-test suite exhaustive CwQ,T Q; Proposition 3.17, result applies CsQ,T
well. Roughly speaking, always computed instantiating rules
UCQ rewriting Q w.r.t. suitable way. requirement Q UCQrewritable w.r.t. invalidates negative result Theorem 3.21 since UCQ rewriting
Q = {A(x) Q(x)} w.r.t. = {R.A A} exists.
result allows one compute Q-simple -test suites exhaustive Q numerous
practically relevant cases. particular, UCQ rewriting guaranteed exist
expressed DLs underpinning QL profile OWL 2 (Motik et al., 2009a; Calvanese
et al., 2007); furthermore, illustrated Example 3.22, UCQ rewriting may exist even
expressed fragments OWL 2 OWL 2 EL (Motik et al., 2009a;
Baader, Brandt, & Lutz, 2005). practice, rewritings computed using systems
QuOnto (Acciarri et al., 2005) REQUIEM (Perez-Urbina et al., 2010).
establish desired result two steps. First, Section 3.5.1 present general
characterisation Q-simple -test suites exhaustive CwQ,T Q. Then, Section
3.5.2 use characterisation establish desired connection rewritings
Q-simple -test suites exhaustive Q.
440

fiCompleteness Guarantees Incomplete Ontology Reasoners

3.5.1 Characterisation Simple Exhaustive Test Suites
next prove Q-simple -test suite = , SQ exhaustive CwQ,T Q
contains isomorphic copy data pattern (i.e., subset ABox)
produce certain answer Q w.r.t. , preserves identity
individuals occurring Q. show sucient, also
necessary condition existence exhaustive -test suite, observe that,
contain one copy data pattern, always find abstract reasoner
CwQ,T passes misses certain answers obtained via missing data pattern
therefore (Q, )-complete.
Theorem 3.23. Let Q UCQ, let admissible TBox, let = , SQ
Q-simple -test suite. Then, exhaustive CwQ,T Q following
properties satisfied ABox A.
1. unsatisfiable, exist ABox injective -stable
renaming dom() = ind(T ) (A ) A.
2. satisfiable, tuple cert(Q, , A) exist ABox
SQ , tuple b cert(Q, , ), injective (Q, )-stable renaming
(b) = a, dom() = ind(Q ), (A ) A.
Proof. () Let arbitrary Q-simple -test suite satisfies Properties 1 2;
next show exhaustive CwQ,T Q. Consider arbitrary abstract reasoner
ans CwQ,T passes Sthat is, ans satisfies following two properties:
(a) ans(, , ) = ,
(b) ans(, , ) = f implies cert(Q, , ) ans(Q, , ) SQ .
next show ans (Q, )-completethat is, ans satisfies two conditions
Definition 3.13 arbitrary ABox A. arbitrary A, following
two possibilities, depending satisfiability A.
Assume unsatisfiable. Since satisfies Property 1, exist ABox
injective -stable renaming s.t. dom() = ind(T ) (A ) A.
Condition (a) ans(, , ) = t. Since ans weakly (Q, )-faithful, injective
-stable, dom() = ind(T ), ans(, , (A )) = t; finally, since ans
(Q, )-monotonic (A ) A, ans(, , A) = t, required Definition 3.13.
Assume satisfiable ans(, , A) = f. Furthermore, consider arbitrary tuple cert(Q, , A). Since satisfies Property 2, exist ABox SQ ,
tuple b cert(Q, , ), injective (Q, )-stable renaming (b) = a,
dom() = ind(Q ), (A ) A. Since (A ) A, ans(, , A) = f, ans
(Q, )-monotonic, ans(, , (A )) = f; furthermore, ind(T ) dom(),
injective (Q, )-stable, ans weakly (Q, )-faithful, ans(, , (A )) = f implies ans(, , ) = f. then, Condition (b) cert(Q, , ) ans(Q, , ),
b ans(Q, , ). Since ans weakly (Q, )-faithful, injective (Q, )-stable,
dom() = ind(Q ), (b) ans(Q, , (A )); since (b) = a,
441

fiCuenca Grau, Motik, Stoilos & Horrocks

ans(Q, , (A )); finally, since ans (Q, )-monotonic (A ) A,
ans(Q, , A), required Definition 3.13.

() Assume exhaustive CwQ,T Q; next show Properties 1 2
satisfied arbitrary ABox A. end, consider particular abstract reasoner
ans prove ans CwQ,T ans passes S; abstract reasoner
help us identify ABox, tuple, renaming required prove Properties 1 2.
Let ans abstract reasoner takes input UCQ Qin , FOL-TBox Tin ,
ABox . result ans(, Tin , ) determined follows.
1. =
Tin , return f.

2. ABox , following.
(a) Check satisfiability using sound, complete, terminating
reasoner.
(b) unsatisfiable, injective -stable renaming exists
dom() = ind(T ) (A ) , return t.
3. Return f.
Furthermore, result ans(Qin , Tin , ) determined follows.
4. =
Tin Q =
Qin , return .
5. := .
6. tuple constants occurring arity equal arity query
predicate Q, SQ following.
(a) Compute C := cert(Q, , ) using sound, complete terminating reasoner.
(b) tuple b C injective (Q, )-stable renaming exist
(b) = a, dom() = ind(Q ), (A ) , add Out.
7. Return Out.
next show ans belongs CwQ,T ; end, prove ans terminates
inputs, (Q, )-monotonic weakly (Q, )-faithful.
Termination. Since admissible, checking satisfiability computation
cert(Q, , ) decidable, relevant sound, complete terminating reasoners
exist. Furthermore, checking whether -stable (resp. (Q, )-stable) injective renaming
exists done enumerating renamings ind(T ) (resp. ind(Q ))
ind(T ) (resp. ind(Q )). Therefore, ans implemented
terminates input.
(Q, )-Monotonicity. Consider arbitrary input Qin , Tin , , .
Assume ans(, Tin , ) = t, Tin abstract reasoner terminates
step 2(b) . then, since (A ) , Tin
abstract reasoner also terminates step 2(b), ans(, Tin , ) = t,
required.
442

fiCompleteness Guarantees Incomplete Ontology Reasoners

Assume ans(, Tin , ) = f ans(, Tin , ) = f, consider arbitrary
tuple ans(Qin , Tin , ). added step 7(b) SQ
. then, since (A ) , Qin , Tin , abstract reasoner
also adds step 7(b), ans(Qin , Tin , ), required.
Weak (Q, )-Faithfulness. Consider arbitrary input Qin , Tin , , arbitrary
injective renaming .
Assume ans(, Tin , ) = t, dom() ind(T A), -stable. Thus,
Tin abstract reasoner terminates step 2(b) . Let
renaming (c) = ((c)) c ind(T ). Clearly,
dom( ) = ind(T ), renaming -stable injective, (A ) (Ain ).
Thus, Tin (Ain ) abstract reasoner terminates step 2(b), therefore
ans(, Tin , (Ain )) = t, required.
Assume ans(, Tin , ) = f, dom() ind(Q A), (Q, )-stable,
consider arbitrary truple ans(Qin , Tin , ). added step
7(b) SQ , , b. Let renaming defined s.t. (c) = ((c))
individual c ind(Q ). Clearly, dom( ) = ind(Q ),
renaming (Q, )-stable injective, (A ) (Ain ), (b) = (a). Thus,
Qin , Tin , (Ain ) abstract reasoner terminates step 7(b) clearly
(a) ans(Qin , Tin , (Ain )), required.
concludes proof ans CwQ,T . Furthermore, ans clearly passes S; then,
since exhaustive CwQ,T Q, abstract reasoner ans (Q, )-complete. next
prove main claim theorem. end, consider arbitrary ABox A;
following possibilities, depending satisfiability A.
Assume unsatisfiable. ans(, , A) = t, abstract reasoner
returns step 2(b) ABox -stable renaming
(A ) dom() = ind(T ). Thus, Property 1 holds required.
Assume satisfiable, consider arbitrary tuple cert(Q, , A).
ans(, , A) = f ans(Q, , A), added step 7(b)
ABox SQ , tuple b cert(Q, , ), injective (Q, )-stable renaming
(b) = a, dom() = ind(Q ), (A ) A. Thus, Property 2
holds required.
following example illustrates Theorem 3.23.
Example 3.24. Let Q specified Example 3.14, let = , SQ
specified Example 3.16. show Section 3.5.2, exhaustive CwQ,T Q.
Consider ABox = {St(a), MathSt(b), takesCo(a, b1 )}. Clearly, satisfiable cert(Q, , A) = {b}. Theorem 3.23, certain answer obtained
evaluating Q w.r.t. ABox SQ . Indeed, note ABox A5 SQ isomorphic
subset = {MathSt(b)} via renaming = {b c}, applying Q
A5 produces c, isomorphic b via .
443

fiCuenca Grau, Motik, Stoilos & Horrocks

Note also that, remove A5 S, longer -test suite
exhaustive Q. example, abstract reasoner rl Example 3.16 would pass
test suite, would return required certain answers applied A5 (and,
consequently, applied either).

3.5.2 Computing Test Suites Exhaustive CwQ,T

Based Theorem 3.23, section show -test suite exhaustive CwQ,T
Q obtained instantiating UCQ rewriting R Q w.r.t. is, replacing
variables R individuals possible ways. Please note instantiation
must full, sense possible replacements must considered.
class CwQ,T contain abstract reasoners rl= Example 3.11
strongly faithful may incorrectly handle case distinct variables bound
individuals.
Definition 3.25. Let set individuals, let r datalog rule, let
substitution. Then, instantiation substitution r w.r.t. (x)
variable x occurring r. latter holds, instantiation r w.r.t. ABox
Ar := {(B) | B body(r)}.
Let Q UCQ, let TBox, let R = R , RQ UCQ rewriting Q w.r.t.
, let maximum number distinct variables occurring rule R, let
set containing individuals occurring R, Q, , well fresh individuals.
R,I
R,I
full instantiation R w.r.t. pair ER,I = ER,I
ER,I
Q
, EQ E
smallest sets ABoxes
Ar ER,I
r R instantiation substitution r w.r.t. I,
Ar ER,I
Q r RQ instantiation substitution r w.r.t.
cert(, R , Ar ) = f.
ER,I clearly unique renaming fresh individuals I, typically left
R
implicit, one talks full instantiation ER = ER
, EQ R.
Example 3.26. Let Q specified Example 3.14, let R = R , RQ
R = {St(x) Prof(x) } RQ consists following datalog rules:
takesCo(x, y) MathCo(y) Q(x)
takesCo(x, y) CalcCo(y) Q(x)
MathSt(x) Q(x)

Then, R UCQ rewriting Q w.r.t. , one see Q-simple -test suite
= , SQ Example 3.16 full instantiation R.


following theorem shows full instantiation UCQ rewriting Q w.r.t.
Q-simple -test suite exhaustive CwQ,T Q. According theorem,
-test suite Example 3.26 exhaustive CwQ,T Q.
444

fiCompleteness Guarantees Incomplete Ontology Reasoners

Theorem 3.27. Let Q UCQ, let admissible TBox, let R = R , RQ
R
UCQ rewriting Q w.r.t. , let ER = ER
, EQ full instantiation R. Then,
ER Q-simple -test suite exhaustive CwQ,T Q.

Proof. Let set individuals ER obtained from. first show ER
Q-simple -test suitethat is, satisfies two properties Definition 3.15.
Consider arbitrary ABox ER
. Then, rule r R instantiation
substitution r exist = Ar ; clearly cert(, {r}, A) = t; since R
UCQ rewriting, unsatisfiable, required.
Consider arbitrary ABox ER
Q . Then, cert(, R , A) = f Definition 3.25;
since R UCQ rewriting, satisfiable, required.
next show ER satisfies Properties 1 2 Theorem 3.23 arbitrary
ABox A.
(Property 1) Assume unsatisfiable. Since R UCQ rewriting,
Definition 2.2 cert(, R , A) = t; then, rule r R substitution
exist Ar cert(, {r}, Ar ) = t. Let injective renaming
individual c occurring R (c) = c, individual
occurring Ar R (d) fresh individual I;
exists since number variables r smaller equal number fresh individuals
I. Let instantiation substitution r (x) = ((x)) variable
R
x occurring r; Ar ER
holds since E full instantiation R w.r.t. I. Let
injective renaming coincides inverse individual occurring
Ar , R, ; exists since injective range contains individual
occurring Ar , R, . Clearly (Ar ) = Ar holds, (Ar ) A. Furthermore,
clearly -stable. Thus, Property (1) satisfied Ar ER
.
(Property 2) Assume satisfiable, consider arbitrarily chosen tuple
cert(Q, , A). Since R UCQ rewriting, Definition 2.2 cert(, R , A) = f
cert(RQ , R , A); then, clearly cert(RQ , , A) well. Then, rule r RQ
substitution exist Ar cert({r}, , Ar ). Let injective
renaming individual c occurring R, Q, (c) = c,
individual occurring Ar R, Q, (d) fresh
individual I; clearly exists since number variables r smaller equal
number fresh individuals I. Let instantiation substitution r
R
(x) = ((x)) variable x occurring r; Ar ER
Q holds since E
full instantiation R w.r.t. I. Let injective renaming coincides
inverse individual occurring Ar , R, Q, ; exists since
injective range contains individual occurring Ar , R, Q, .
Furthermore, clearly tuple b cert({r}, , Ar ) exists (head(r)) = Q(b); since
R UCQ rewriting Ar satisfiable, b cert(Q, , Ar ); furthermore,
since injective, (b) = clearly holds. then, Property (2) satisfied Ar ER
Q,

, b.
445

fiCuenca Grau, Motik, Stoilos & Horrocks

3.5.3 Minimising Exhaustive Test Suites
practice, clearly beneficial compute test suites small possible.
goal achieved applying known techniques minimising UCQ rewritings
(Calvanese et al., 2007; Perez-Urbina, Horrocks, & Motik, 2009). Theorem 3.27,
smallest rewriting instantiated obtain exhaustive test suite.
State art query rewriting systems employ subsumption condensation techniques order reduce size rewriting. datalog rule r subsumes datalog rule
r substitution exists (r) r ; intuitively, r general r .
rewriting contains rules r r , r safely removed rewriting.
Furthermore, rule r contains distinct unifiable body atoms Bi Bj , condensation
r rule (r) general unifier Bi Bj . rewriting contains
rule r (r) subsumes r, rule safely replaced (r). following
example illustrates techniques used obtain small test suites.
Example 3.28. Let Q specified Example 3.14, let R rewriting
Q w.r.t. Example 3.26. R = R , RQ RQ consists following
rules also UCQ rewriting Q w.r.t. .
takesCo(x, y) takesCo(x, z) MathCo(y) Q(x)

(12)

takesCo(x, y) CalcCo(y) Q(x)

(14)

MathSt(x) Q(x)

(16)

takesCo(x, x) CalcCo(x) MathCo(x) Q(x)

(13)

St(x) MathSt(x) Q(x)

(15)

Theorem 3.27, full instantiation R also -test suite exhaustive CwQ,T
Q. rewriting R , however, contains redundancy hence resulting test suite
unnecessarily large. particular, applying condensation query (12), subsumption
queries (13) (14), subsumption queries (15) (16), obtain
simpler rewriting R.

Finally, note test suites obtained via full instantiation contain isomorphic
ABoxes. Clearly, isomorphic copies ABox safely eliminated test
suite without losing exhaustiveness CwQ,T Q.
3.6 Testing (Q, )-Monotonic Strongly (Q, )-Faithful Abstract Reasoners

Due full instantiation, test suites obtained Definition 3.25 exponentially larger
rewriting generated from. result, even rewritings moderate size
yield test suites containing thousands ABoxes. Intuitively, full instantiation required
obtain test suite exhaustive class CwQ,T class contains abstract
reasoners rl= Example 3.11, correctly handle case
distinct variables query matched individual.
section, show test suites exhaustive class CsQ,T obtained
injective instantiation rewritingthat is, replacing variable distinct
fresh individual. Test suites obtained way linear size rewriting,
thus substantially smaller test suites obtained full instantiation.
446

fiCompleteness Guarantees Incomplete Ontology Reasoners

Example 3.29. Let Q specified Example 3.14, let = , SQ
Q-simple -test suite Example 3.16. Furthermore, consider abstract reasoner rl=
Example 3.11 weakly, strongly (Q, )-faithful. easy check
rl= returns complete answers A1 A3 , A2 A4 . Therefore, Theorem
3.27, exhaustive CwQ,T Q, must include SQ ABoxes A2 A4 ,
respectively obtained ABoxes A1 A3 merging individual c.
Strongly (Q, )-faithful abstract reasoners, however, correctly handle inputs obtained
merging individuals. Based observation, section show Q-simple
-test suite = , SQ SQ = {A1 , A3 , A5 }, obtained injectively instantiating
rewriting R Example 3.26, exhaustive CsQ,T Q.



Section 3.5, first develop characterisation Q-simple -test suites
exhaustive CsQ,T Q; result analogous Theorem 3.23.

Theorem 3.30. Let Q UCQ, let admissible TBox, let = , SQ
Q-simple -test suite. Then, exhaustive CsQ,T Q following
properties satisfied ABox A.
1. unsatisfiable, exist ABox -stable renaming
dom() = ind(T ) (A ) A.
2. satisfiable, tuple cert(Q, , A) exist ABox
SQ , tuple b cert(Q, , ), (Q, )-stable renaming (b) = a,
dom() = ind(Q ), (A ) A.
Proof. () Let arbitrary Q-simple -test suite satisfies Properties 1 2;
next show exhaustive CsQ,T Q. Consider arbitrary abstract reasoner
ans CsQ,T passes Sthat is, ans satisfies following two properties:
(a) ans(, , ) = ,
(b) ans(, , ) = f implies cert(Q, , ) ans(Q, , ) SQ .
next show ans (Q, )-completethat is, ans satisfies two conditions
Definition 3.13 arbitrary ABox A. arbitrary A, following
two possibilities, depending satisfiability A.
Assume unsatisfiable. Since satisfies Property 1, exist ABox
-stable renaming dom() = ind(T ) (A ) A.
Condition (a) ans(, , ) = t. Since ans strongly (Q, )-faithful stable, ans(, , (A )) = t; finally, since ans (Q, )-monotonic (A ) A,
ans(, , A) = t, required Definition 3.13.
Assume satisfiable ans(, , A) = f. Furthermore, consider arbitrary tuple cert(Q, , A). Since satisfies Property 2, exist ABox SQ ,
tuple b cert(Q, , ), (Q, )-stable renaming (b) = a, (A ) A,
dom() = ind(Q ). Since (A ) A, ans(, , A) = f, ans (Q, )-monotonic,
ans(, , (A )) = f; furthermore, (Q, )-stable ans strongly faithful, ans(, , (A )) = f implies ans(, , ) = f. then, Condition (b)
cert(Q, , ) ans(Q, , ), b ans(Q, , ). ans strongly (Q, )-faithful
447

fiCuenca Grau, Motik, Stoilos & Horrocks

(Q, )-stable, (b) ans(Q, , (A )); since (b) = a, ans(Q, , (A ));
finally, since ans (Q, )-monotonic (A ) A, ans(Q, , A), required
Definition 3.13.
() Assume exhaustive CsQ,T Q; next show Properties 1 2
satisfied arbitrary ABox A. end, consider particular abstract reasoner
ans prove ans CsQ,T ans passes S; abstract reasoner
help us identify ABox, tuple, renaming required prove Properties 1 2.
Let ans abstract reasoner takes input UCQ Qin , FOL-TBox Tin ,
ABox . result ans(, Tin , ) determined follows.
1. =
Tin , return f.
2. ABox , following.
(a) Check satisfiability using sound, complete, terminating
reasoner.
(b) unsatisfiable, -stable renaming exists
dom() = ind(T ) (A ) , return t.
3. Return f.
Furthermore, result ans(Qin , Tin , ) determined follows.
4. =
Tin Q =
Qin , return .
5. := .
6. tuple constants occurring arity equal arity query
predicate Q, SQ following.
(a) Compute C := cert(Q, , ) using sound, complete terminating reasoner.
(b) tuple b C (Q, )-stable renaming exist (b) = a,
dom() = ind(Q ), (A ) , add Out.

7. Return Out.
next show ans belongs CsQ,T . proofs ans terminates
(Q, )-monotonic analogous proofs Theorem 3.23. show strong (Q, )faithfulness, consider arbitrary Qin , Tin , , arbitrary renaming .
Assume ans(, Tin , ) = -stable. Thus, Tin abstract
reasoner terminates step 2(b) . Let renaming
(c) = ((c)) c ind(T ). Clearly, dom( ) = ind(T ),
renaming -stable, (A ) (Ain ). Thus, Tin (Ain ) abstract
reasoner terminates step 2(b), ans(, Tin , (Ain )) = t, required.
Assume ans(, Tin , ) = f (Q, )-stable, consider arbitrary
tuple ans(Qin , Tin , ). added step 7(b) SQ ,
448

fiCompleteness Guarantees Incomplete Ontology Reasoners

, b. Let renaming defined (c) = ((c)) individual c ind(Q ). Clearly, dom( ) = ind(Q ), mapping
(Q, )-stable, (A ) (Ain ), (b) = (a). Thus, Qin , Tin , (Ain )
abstract reasoner terminates step 7(b), (a) ans(Qin , Tin , (Ain )), required.
concludes proof ans CsQ,T . Furthermore, ans clearly passes S; then,
since exhaustive CsQ,T Q, abstract reasoner ans (Q, )-complete. main
claim theorem shown Theorem 3.23.
next use Theorem 3.30 show Q-simple -test suite exhaustive
Q obtained injective instantiation UCQ rewriting Q w.r.t. .

CsQ,T

Definition 3.31. Let Q UCQ, let TBox, let R = R , RQ UCQ rewriting
Q w.r.t. , let substitution mapping variable occurring R distinct
R,
fresh individual. injective instantiation R w.r.t. pair IR, = IR,
, IQ
IR,
IR,
smallest sets ABoxes
Q

Ar IR,
r R ,

Ar IR,
r RQ cert(, R , Ar ) = f.
Q
IR, clearly unique renaming fresh individuals , typically left
R
implicit, one talks injective instantiation IR = IR
, IQ R.
Theorem 3.32. Let Q UCQ, let admissible TBox, let R = R , RQ
R
UCQ rewriting Q w.r.t. , let IR = IR
, IQ injective instantiation R.
Then, IR Q-simple -test suite exhaustive CsQ,T Q.

Proof. Let substitution IR obtained from. first show IR
Q-simple -test suitethat is, satisfies two properties Definition 3.15.
r
Consider arbitrary IR
. Then, rule r R exist = ; clearly
cert(, {r}, A) = t; since R UCQ rewriting, unsatisfiable, required.

Consider arbitrary IR
Q . Then, cert(, R , A) = f Definition 3.31; since R
UCQ rewriting, satisfiable, required.
next show IR satisfies Properties 1 2 Theorem 3.30 arbitrary
ABox A.
(Property 1) Assume unsatisfiable. Since R UCQ rewriting,
Definition 2.2 cert(, R , A) = t; then, rule r R substitution
exist Ar cert(, {r}, Ar ) = t. Let renaming
individual c occurring R (c) = c, variable x r
((x)) = (x). Clearly, (Ar ) = Ar , (Ar ) A. Furthermore, clear
-stable. Thus, Property (1) holds Ar IR
.
(Property 2) Assume satisfiable, consider arbitrarily chosen tuple
cert(Q, , A). Since R UCQ rewriting, Definition 2.2 cert(, R , A) = f
cert(RQ , R , A); then, clearly cert(RQ , , A) well. Then, rule r RQ
449

fiCuenca Grau, Motik, Stoilos & Horrocks

substitution exist Ar cert({r}, , Ar ). Let renaming
individual c occurring R, Q, (c) = c,
variable x r ((x)) = (x). Clearly, (Ar ) = Ar , (Ar ) A. Furthermore,
clear (Q, )-stable. Finally, clearly tuple b cert({r}, , Ar ) exists
(head(r)) = Q(b); since R UCQ rewriting Ar satisfiable,
b cert(Q, , Ar ); furthermore, (b) = clearly holds. then, Property (2) satisfied

Ar IR
,
,
b.
Q
3.7 Dealing Recursive Axioms
negative result Theorem 3.21 (which applies CwQ,T CsQ,T ) depends
presence recursive axiom TBox; thus, positive results Sections 3.5
3.6 require input UCQ rewritable w.r.t. input TBox, eectively
prohibits recursion TBox axioms. Instead disallowing recursive axioms, section
overcome limitation Theorem 3.21 placing additional requirements
abstract reasoners requiring first-order reproducible. Intuitively, latter
means reasoners behaviour seen complete reasoning unknown
first-order theory. abstract reasoners allowed partially evaluate recursive
axioms, invalidates approach used prove Theorem 3.21.
show -test suite exhaustive Q class first-order reproducible
abstract reasoners obtained instantiating datalog, rewriting Q w.r.t. .
rewritings exist wide range TBoxes queries, turn allows
results applicable range practically interesting cases. contrast test
suites computed UCQ rewriting, however, test suites obtained datalog,
rewriting may Q-simple. fact, show Section 3.7.2 that, certain Q
, -test suite exhaustive Q class first-order reproducible abstract
reasoners exists, test suite Q-simple. important practicallyrelevant consequence: -test suite Q-simple, first-order reproducible abstract
reasoner passes guaranteed (Q, )-complete; however, abstract reasoner
pass S, general cannot conclude reasoner (Q, )-complete.
3.7.1 First-Order Reproducible Abstract Reasoners
State art concrete reasoners Oracles reasoner, Jena, OWLim, Minerva, Virtuoso, DLE-Jena implemented RDF triple stores extended deductive
database features. Given input, reasoners first precompute assertions
follow preprocessing step. practice, step commonly implemented (a technique seen as) evaluating datalog program A.
preprocessing, reasoners answer arbitrary UCQ Q simply evaluating
Q precomputed set assertions.
Motivated observation, next introduce new class first-order reproducible
abstract reasonersthat is, abstract reasoners whose behaviour conceived complete reasoning unknown first-order theory. Note theory required
datalog program; example, contain existential quantifiers, used
capture behaviour concrete reasoners Jena OWLim (Bishop, Kiryakov,
450

fiCompleteness Guarantees Incomplete Ontology Reasoners

Ognyano, Peikov, Tashev, & Velkov, 2011) handle existential quantifiers input
introducing fresh individuals.
Definition 3.33. abstract reasoner ans description logic DL first-order reproducible if, DL-TBox , set first-order sentences FT exists that,
ABox A,
ans(, , A) = cert(, FT , A),

ans(, , A) = f, UCQ Q, ans(Q, , A) = cert(Q, FT , A).

FT contains predicates and/or individuals occurring , assumed
internal ans accessible queries, TBoxes, ABoxes, test suites, on.
Given TBox , CfT class first-order reproducible abstract reasoners applicable
.
Example 3.34. Abstract reasoners rdf, rdfs, rl classify Example 3.3 firstorder reproducible. Indeed, theory FT empty case rdf, precisely Prdfs
Prl cases rdfs rl, respectively. Finally, abstract reasoner classify, theory
FT union Prl program containing axiom x.[A(x) B(x)]
atomic subsumption B entailed input TBox.


Please note first-order reproducible abstract reasoner ans need actually construct FT : matters (possibly unknown) theory FT exists
characterises reasoners behaviour specified Definition 3.33.
Since QFT |= QFT whenever , first-order reproducible abstract
reasoner (Q, )-monotonic arbitrary Q . Furthermore, straightforward
see first-order reproducible abstract reasoner also strongly (Q, )-faithful.
Consequently, CfT CsQ,T UCQ Q TBox .
next show negative result Theorem 3.21 directly apply
class CfT . particular, show abstract reasoner pEvaln used prove
Theorem 3.21 first-order reproducible. Intuitively, pEvaln understood
partial evaluation datalog programthat is, rules program applied
facts fixed number times rather fixpoint reached.
Proposition 3.35. positive integer n, abstract reasoner pEvaln defined
proof Theorem 3.21 first-order reproducible.
Proof. Let = {R.A A}, let Q = {A(x) Q(x)}, consider arbitrary nonnegative integer n. Furthermore, assume pEvaln CfT ; then, finite set first-order
sentences FT exists pEvaln (Q, , A) = cert(Q, FT , A) ABox A.
Let k positive integer; furthermore, let rk datalog rule let Ak
ABox defined follows, a0 , . . . , ak arbitrary distinct fixed individuals occurring
Q FT :
rk = R(x0 , x1 ) . . . R(xk1 , xk ) A(xk ) A(x0 )
Ak = {R(a0 , a1 ), . . . , R(ak1 , ak ), A(ak )}
following condition holds Proposition 2.1:
FT |= rk

FT Ak |= A(a0 )
451

(17)

fiCuenca Grau, Motik, Stoilos & Horrocks

definition pEvaln ,
a0 pEvaln (Q, , Ak ) 1 k n,
a0 pEvaln (Q, , Ak ) k > n.
Since pEvaln (Q, , A) = cert(Q, FT , A),
a0 cert(Q, FT , Ak ) 1 k n,
a0 cert(Q, FT , Ak ) k > n.
Since Q contains atom A(x) body,
FT Ak |= A(a0 ) 1 k n,
FT Ak |= A(a0 ) k > n.
condition (17),
FT |= rk 1 k n
FT |= rk k > n.
This, however, contradicts obvious observation r1 |= rk k 1.
Note proof Proposition 3.35 relies fact theory FT depends
input TBox, input query. shown next, defined first-order
reproducible abstract reasoners allowing FT depend also input query,
negative result Theorem 3.21 would applied.
Definition 3.36. abstract reasoner ans DL first-order q-reproducible if,
UCQ Q DL-TBox , finite set first-order sentences FQ,T exists that,
ABox A,
ans(, , A) = cert(, FQ,T , A),
ans(, , A) = f, ans(Q, , A) = cert(Q, FQ,T , A).
Theorem 3.37. Q = {A(x) Q(x)} = {R.A A}, -test suite exists
exhaustive Q class sound, monotonic, strongly faithful, qreproducible abstract reasoners applicable .
Proof. prove claim, suces show that, nonnegative integer n,
abstract reasoner pEvaln defined proof Theorem 3.21 first-order q-reproducible.
Consider arbitrary nonnegative integer n, arbitrary DL-TBox , arbitrary
UCQ Q . define FQ ,T that, Q = Q, FQ ,T = ; otherwise,
FQ ,T consists following n rules:
A(x0 ) Q(x0 )

R(x0 , x1 ) A(x1 ) Q(x0 )
...

R(x0 , x1 ) R(x1 , x2 ) . . . R(xn1 , xn ) A(xn ) Q(x0 )
452

fiCompleteness Guarantees Incomplete Ontology Reasoners

Clearly, pEvaln (, , ) = cert(, FQ ,T , ) = f UCQ Q , DL-TBox
ABox , required. Furthermore, Q either Q = Q
ABox , pEvaln (Q , , ) = cert(Q , FQ ,T , ) = . Finally,
Q = Q, , ABox , clearly pEvaln (Q , , ) =
cert(Q , FQ ,T , ), required.
3.7.2 Simple vs. Non-Simple Test Suites
Proposition 3.18 Section 3.3 shows Q-simple -test suite exhaustive
Q class abstract reasoners provides sucient necessary test (Q, )completeness. next show analogous result hold contains recursive
axioms, even consider first-order reproducible abstract reasoners. Theorem 3.21, prove claim fixed Q since concept relevant recursive
axioms might dicult formalise; however, proof easily adapted
UCQs TBoxes. result essentially states -test suite exists provides
necessary sucient condition (Q, )-completeness abstract reasoner
CfT ; consequently, Proposition 3.18 -test suite exhaustive CfT Q
Q-simple. Furthermore, Section 3.7.3 show compute -test suite exhaustive
CfT Q, following claim hold vacuously.
Theorem 3.38. Let Q = {A(x) B(x) Q(x)}, let = {R.A A}, let C
class sound, monotonic, strongly faithful, first-order reproducible abstract reasoners applicable . Then, -test suite exists satisfies following two properties:
1. exhaustive C Q;
2. abstract reasoner ans C, ans (Q, )-complete ans passes S.
Proof. Assume -test suite = , SQ exists satisfies properties 1 2
theorem. Let n maximal number assertions occurring ABox S.
next define two abstract reasoners ans1 ans2 ; straightforward check
sound, monotonic, strongly faithful, first-order reproducible.
Given arbitrary FOL-TBox Tin , abstract reasoner ans1 uses datalog program
FT1in defined follows:
Tin , FT1in = .
Tin , FT1in contains following n rules:
r0 =
r1 =
r2 =

B(x0 ) A(x0 ) A(x0 )
B(x0 ) R(x0 , x1 ) A(x1 ) A(x0 )
B(x0 ) R(x0 , x1 ) R(x1 , x2 ) A(x3 ) A(x0 )
...
rn = B(x0 ) R(x0 , x1 ) . . . R(xn1 , xn ) A(xn ) A(x0 )
Given arbitrary FOL-TBox Tin , abstract reasoner ans2 uses datalog program
defined follows, predicate Z private FT2in (and hence aect
soundness abstract reasoner):
FT2in

453

fiCuenca Grau, Motik, Stoilos & Horrocks

Tin , FT2in = .
Tin , FT2in contains FT1in well following rules:
rZ1 = R(x0 , x1 ) . . . R(xn , xn+1 ) A(xn+1 ) Z(x0 )
rZ2 =
R(x0 , x1 ) Z(x1 ) Z(x0 )
rZ3 =
Z(x) B(x) A(x)
let arbitrary ABox containing n assertions. next show
that, assertion containing predicate Z, FT1in |=
FT2in |= . () direction trivial since FT1in FT2in , consider ()
direction. Furthermore, since rZ3 rule FT2in \ FT1in contain
Z head, claim nontrivial form A(a0 ) individual a0 occurring A. Since antecedent rZ3 satisfied a0 , B(a0 )
FT2in |= Z(a0 ). then, latter implied rZ1 rZ2 , individuals
a0 , a1 , . . . , ak 0 k exist R(ai , ai+1 ) 1 < k, A(ak ) A.
Since contains n assertions, w.l.o.g. assume k n. then, since
FT1in contains rule rk , FT1in |= A(a0 ) well, proves claim. consequence claim fact ABoxes contain n assertions,
cert(, FT1in , A) = cert(, FT2in , A) , cert(Y, FT1in , A) = cert(Y, FT2in , A)
A, SQ .
Let = {B(a0 ), R(a0 , a1 ), . . . , R(an , an+1 ), A(an+1 )}. cert(Q, , A) = {a0 }
cert(Q, FT1in , A) = , ans1 (Q, )-complete. Since exhaustive C Q,
abstract reasoner ans1 pass S; claim previous paragraph, abstract
reasoner ans2 pass either. next show ans2 (Q, )-complete,
contradicts assumption satisfies property 2 thus proves claim
theorem.
Consider arbitrary ABox containing assertions. Clearly, a0 cert(Q, , A)
individuals a0 , a1 , . . . , ak 0 k exist B(a0 ) A, R(ai , ai+1 )
1 < k, A(ak ) A. assume k n; since rk FT2in ,
FT2in |= A(a0 ) thus a0 cert(Q, FT2in , A). contrast, assume k > n; since
rZ1 FT2in , FT2in |= Z(akn1 ); since rZ2 FT2in , FT2in |= Z(ai )
0 k n 1; finally, since rZ3 FT2in , FT2in |= A(a0 ); then,
a0 cert(Q, FT2in , A), required.
corollary Theorem 3.38, next show testing abstract reasoners CfT
cannot done general using Q-simple test suites.
Corollary 3.39. Q = {A(x) B(x) Q(x)} = {R.A A}, Q-simple test suite exists exhaustive Q class sound, monotonic, strongly
faithful, first-order reproducible abstract reasoners applicable .
Proof. Q-simple -test suite exhaustive Q class mentioned
Theorem, Proposition 3.18 abstract reasoner ans class
pass (Q, )-complete, contradicts Theorem 3.38.
454

fiCompleteness Guarantees Incomplete Ontology Reasoners

Theorem 3.38 eectively says that, abstract reasoner ans CfT pass test suite S, cannot conclude ans (Q, )-complete. Please note holds
ans fails test form A, Q =
Y: Q = Y, counterexample
(Q, )-completeness ans. Thus, may show ans (Q, )-complete,
guaranteed so. illustrated following example.
Example 3.40. Let Q = {A(x) B(x) Q(x)} let = {R.A A, R.C C}. Furthermore, let = , SQ general test suite defined follows:
SQ = {

{ A(c) },
{ A(x) B(x) Q(x) } ,
{ R(c, d), A(d) }, { A(c) Q } ,
{ R(c, d), C(d) }, { C(c) Q }
}

Let R = RD , , Q RD = {R(x, y) A(y) A(x), R(x, y) C(y) C(x)}; clearly,
R rewriting Q w.r.t. . Section 3.7.3 show compute R using
variant injective instantiation way guarantees exhaustiveness CfT Q.
let ans1 CfT abstract reasoner defined FT1 = {R(x, y) A(y) A(x)}.
reasoner pass since cert({C(c) Q }, FT1 , {R(c, d), C(d)}) = f. Note, however, reasoner (Q, )-complete. Thus, test suite Q-simple, passing
sucient, necessary condition (Q, )-completeness. fact, note
contains TBox Theorem 3.38, theorem cannot reduce
correctly identifies reasoners CfT (Q, )-complete.
practice, however, one try mitigate fundamental theoretical limitation
eliminating irrelevant axioms rewriting R thus increasing likelihood
obtaining -test suite (Q, )-complete abstract reasoner pass. example,
using techniques Cuenca Grau, Horrocks, Kazakov, Sattler (2008a)
extract module R relevant query. example previous paragraph,
would remove rule R(x, y) C(y) C(x) R, injective instantiation
produce test suite = , SQ SQ defined follows:
SQ = {

{ A(c) },
{ A(x) B(x) Q(x) } ,
{ R(c, d), A(d) }, { A(c) Q }
}

Abstract reasoner ans1 previous paragraph passes thus guaranteed
(Q, )-complete.
let ans2 abstract reasoner defined FT2 = {B(x) R(x, y) A(y) A(x)}.
Clearly, abstract reasoner ans2 (Q, )-complete, ans2 pass SQ .
latter, however, cannot immediately conclude (Q, )-complete: test
fails involve original query Q. possible remedy, try unfold
R certain level injectively instantiate result hope obtaining -test
suite identify ans2 (Q, )-complete. particular, first unfolding
R produces following query:
B(x) R(x, y) A(y) Q(x)

Instantiating rewriting produces following test suite, prove
ans2 (Q, )-complete.
SQ = {

{ B(c), R(c, d), A(d) }, { A(x) B(x) Q(x) } }
455

fiCuenca Grau, Motik, Stoilos & Horrocks

Another round unfolding, however, produces following query:
B(x) R(x, y) R(y, z) A(z) Q(x)
Instantiating query produces following test suite:

Q ={

{ B(c), R(c, d), R(d, e), A(e) }, { A(x) B(x) Q(x) } }

ans2 pass
Q , conclude ans2 (Q, )-complete.



better understand Example 3.40, consider first-order reproducible abstract reasoner
ans, arbitrary UCQ Q, TBox R = RD , , RQ datalog rewriting
Q w.r.t. . Datalog program RD RQ equivalent (possibly infinite) UCQ RuQ
obtained RD RQ via exhaustive unfolding. following possibilities.
First, assume ans (Q, )-complete. Since RD RQ equivalent RuQ ,
certain answer Q w.r.t. arbitrary ABox produced r RuQ .
then, injective instantiation Ar r provide us counterexample
(Q, )-completeness ans. Thus, prove ans (Q, )-complete
generating elements RuQ fair manner (i.e., without indefinitely delaying
generation element RuQ ) checking whether cert(Q, , Ar ) ans(Q, , Ar );
guaranteed eventually encounter r RuQ invalidates condition
thus proves ans (Q, )-complete.
Second, assume ans (Q, )-complete. Using approach, determine cert(Q, , Ar ) ans(Q, , Ar ) holds r RuQ . RuQ finite (i.e.,
unfolding RD RQ terminates), RuQ UCQ rewriting Q w.r.t. ,
results Section 3.6 conclude ans indeed (Q, )-complete. If, however, RuQ infinite, never obtain sucient assurance (Q, )-complete
ans. following section show possible remedy problem.
3.7.3 Testing First-Order Reproducible Abstract Reasoners
section, show compute -test suite = , SQ exhaustive CfT
Q datalog, rewriting R = RD , R , RQ Q w.r.t. . Since first-order
reproducible abstract reasoners strongly faithful, need consider injective
instantiations R. Thus, rules R RQ instantiated Section 3.6.
rule r RD , however, instantiated pair A, SQ ABox obtained
instantiating body r Boolean UCQ obtained instantiating head
r. Intuitively, tests allow us check whether (unknown) first-order theory FT
captures behaviour abstract reasoner entails r.
Definition 3.41. Let Q UCQ query predicate Q, let admissible TBox,
let R = RD , R , RQ datalog, rewriting Q w.r.t. , let substitution
mapping variable occurring R distinct fresh individual. injective instanR,
R,
tiation R w.r.t. pair IR, = IR,
smallest set ABoxes
, IQ
IR,
smallest set pairs ABox UCQ
Q
Ar IR,
r R ,

456

fiCompleteness Guarantees Incomplete Ontology Reasoners

Ar , Q IR,
r RQ cert(, RD R , Ar ) = f,
Q
Ar , IR,
r RD form (6) cert(, RD R , Ar ) = f,
Q
UCQ = {i ((x), yi ) Q | 1 m} propositional query
predicate Q .
IR, clearly unique renaming fresh individuals , typically left
R
implicit, one talks injective instantiation IR = IR
, IQ R.
Example 3.42. Consider query Q = {A(x) Q(x)} EL-TBox consisting
following axioms, whose translation first-order logic shown symbol.
R.A B



BC



AD



R.C



C R.D



x, y.[R(x, y) A(y) B(x)]
x, y.[R(x, y) C(y) A(x)]
x.[B(x) C(x)]

x.[C(x) y.[R(x, y) D(y)]]
x.[A(x) D(x) ]

Then, R = RD , R , RQ defined next datalog rewriting Q w.r.t. .
RD = { R(x, y) A(y) B(x), R(x, y) C(y) A(x), B(x) C(x) }
R = { A(x) D(x) }

RQ = { A(x) Q(x) }

R
injective instantiation IR = IR
, IQ R shown below.

IR
= { { A(c), D(c) } }

IR
{ A(x) Q(x) } ,
Q = { { A(c) },
{ R(c, d), A(d) }, { B(c) Q } ,
{ R(c, d), C(d) }, { A(c) Q } ,
{ B(c) },
{ C(c) Q }
}



show injective instantiation datalog, rewriting Q w.r.t.
-test suite exhaustive CfT Q.
Theorem 3.43. Let Q UCQ, let TBox, let R = RD , R , RQ datalog,
R
R
rewriting Q w.r.t. , let IR = IR
, IQ injective instantiation R. Then,
-test suite exhaustive CfT Q.
Proof. Let substitution IR obtained from. first show IR -test
suite.
r
Consider arbitrary IR
. Then, rule r R exist = ; clearly
cert(, {r}, A) = t, cert(, RD R , A) = well; since R datalog, rewriting Q w.r.t. , unsatisfiable, required.

457

fiCuenca Grau, Motik, Stoilos & Horrocks

Consider arbitrary IR
Q . Then, cert(, RD R , A) = f Definition 3.41;
,
since R datalog
rewriting Q w.r.t. , satisfiable,
required.
show IR exhaustive CfT Q, consider arbitrary abstract reasoner
ans CfT passes IR is, ans satisfies following two properties:
(a) ans(, , ) = IR
,
(b) ans(, , ) = f implies cert(Y, , ) ans(Y, , ) Y, IR
Q.
Since ans first-order reproducible, set first-order sentences FT exists that,
ABox A,
ans(, , A) = cert(, FT , A),
ans(, , A) = f, ans(Q, , A) = cert(Q, FT , A).
assumption FT Definition 3.33 fact maps variables fresh
individuals, rng() ind(FT ) = .
Let R1D R2D smallest sets rules satisfying following conditions
rule r RD :
cert(, FT , Ar ) = implies r R1D , r obtained r replacing head
,
cert(, FT , Ar ) = f implies r R2D .
Furthermore, let R1Q R2Q sets rules obtained RQ analogous way.
Since R1D R2D obtained RD replacing head formulae , clearly
R1D R2D |= RD ; analogously, R1Q R2Q |= RQ .

next show FT |= R ; latter holds FT |= r rule r R .
Consider arbitrary rule r R ; note head(r) = . Then, Definition 3.41
r
r
Ar IR
; (a) ans(, , ) = t; Definition 3.33 cert(, FT , ) =
hence FT Ar |= ; finally, since rng() ind(FT ) = , Proposition 2.1
FT |= r, required.
next show FT |= R1D ; latter holds FT |= r rule r R1D .
Consider arbitrary rule r R1D ; note head(r) = . Then, definition R1D
cert(, FT , Ar ) = hence FT Ar |= ; finally, since rng() ind(FT ) = ,
Proposition 2.1 FT |= r, required.
completely analogous way previous paragraph, possible show
FT |= R1Q .
next show FT |= R2D ; latter holds FT |= r rule
r R2D . Consider arbitrary rule r R2D form (6); definition R2D
cert(, FT , Ar ) = f, Definition 3.33 ans(, , Ar ) = f. Then, Definition
3.41 Ar , IR
x), yi ) Q | 1 m}. Note
Q UCQ = {i ((
|= r Definition 2.2, Proposition 2.1 Ar |=
x), yi );
i=1 ((
definition fact Q occur , Ar |= Q ;
458

fiCompleteness Guarantees Incomplete Ontology Reasoners

then, cert(Y, , Ar ) = t. latter observation, ans(, , Ar ) = f, (b) imply
ans(Y, , Ar ) = t, Definition 3.33 cert(Y, FT , Ar ) = t. Since Q occurs

(note predicate occurring
FT private FT , Q cannot
r
occur FT ), FT |= i=1 ((x), yi ). Finally, since rng() ind(FT ) = ,
Proposition 2.1 FT |= r, required.
next show Q FT |= R2Q ; latter holds Q FT |= r
rule r R2Q . Consider arbitrary rule r R2Q ; note head(r) atom predicate
Q, definition R2Q cert(, FT , Ar ) = f, Definition 3.33
ans(, , Ar ) = f. Furthermore, Definition 3.41, cert(, RD R , Ar ) = f.
Let tuple arguments (head(r)). Then, Definition 3.41
Ar , Q IR
cert({r}, , Ar ), cert(RQ , RD R , Ar )
Q ; clearly,
monotonicity first-order logic. Since R rewriting Q w.r.t. , Definition 2.2 cert(Q, , Ar ). latter observation, ans(, , Ar ) = f, (b)
imply ans(Q, , Ar ). Definition 3.33 cert(Q, FT , Ar ); hence,
FT Ar |= Q(a). Finally, since rng() ind(FT ) = , Proposition 2.1
FT |= r, required.
following table summarises entailment relationships various first-order
theories obtained thus far:
FT |= R
Q FT |= R2Q

FT |= R1D
R1Q R2Q |= RQ

FT |= R2D
R1D R2D |= RD

FT |= R1Q

Clearly, implies following entailments:
FT |= RD R

Q FT |= RD R RQ

complete proof theorem show ans (Q, )-complete.
end, consider arbitrary ABox A; following possibilities, depending
satisfiability A.
Assume unsatisfiable. cert(, RD R , A) = Definition
2.2; mentioned entailments, cert(, FT , A) = t; consequently,
ans(, , A) = Definition 3.33, required.
Assume satisfiable ans(, , A) = f, consider arbitrary tuple
cert(Q, , A). Then, cert(, RD R , A) = f cert(RQ , RD R , A)
Definition 2.2. mentioned entailments, cert(Q, FT , A);
hence, ans(Q, , A) Definition 3.33, required.
Note size test suite obtained Theorem 3.43 linear size
rewriting, which, believe, makes approach suitable use practice.
3.7.4 Testing Ground Queries
shown Section 3.7.2, abstract reasoner ans CfT pass -test suite
Q-simple, cannot always conclude ans (Q, )-complete.
practical point view, would highly beneficial identify situations passing
would show ans indeed incomplete Q . Furthermore, applications
459

fiCuenca Grau, Motik, Stoilos & Horrocks

prototypical queries known design time, would like design completeness
tests query-independentthat is, test abstract reasoner completeness
w.r.t. regardless input data query. section, show
achieve two goals focusing ground queries. restriction unreasonable
practice, since SPARQL query equivalently expressed ground UCQ.
first define query-independent notion exhaustiveness test suite.
Definition 3.44. Let TBox, let -test suite, let C class abstract
reasoners applicable . Then, exhaustive C ground UCQs ans C
passes (Q, )-complete ground UCQ Q.
Then, define notion ground rewriting rewriting captures
query answers w.r.t. , regardless input ground query ABoxand show
instantiate ground rewritings.

Definition 3.45. ground rewriting TBox pair R = RD , R that,
ground UCQ Q, triple RD , R , Q datalog rewriting w.r.t. Q.

injective instantiation IR R defined IR = IR R = RD , R , .
Note Definition 3.45 implies variable occurring head rule
R also occurs rule body. Tools REQUIEM KAON2 easily
adapted compute ground rewriting TBox practice. next show
injective instantiation ground rewriting yields -test suite provides us
sucient necessary check completeness w.r.t. ground UCQs.

Theorem 3.46. Let TBox, let R = RD , R ground rewriting .
Then, following two claims hold.
1. IR exhaustive CfT ground UCQs.
2. abstract reasoner ans CfT pass IR (Q, )-complete
ground UCQ Q.

Proof. (Property 1) Consider arbitrary abstract reasoner ans CfT passes IR . Let
FT first-order theory characterises behaviour ans; proof
Theorem 3.43, fact ans passes IR implies FT |= RD R . Furthermore, consider
arbitrary ground UCQ Q arbitrary ABox A. ans (Q, )-complete
shown proof Theorem 3.43, minor dierence cert(Q, , A)
implies cert(Q, RD R , A) Definition 3.45.
(Property 2) Note that, since R ground rewriting , Definition 3.41 UCQs
IR ground. Thus, abstract reasoner ans CfT pass IR , clearly
shows ans (Q, )-complete ground UCQ Q.

4. Comparing Incomplete Abstract Reasoners
section, investigate techniques that, given query Q TBox , allow us
determine whether abstract reasoner ans2 complete abstract reasoner
ans1 is, whether ABoxes A, abstract reasoner ans2 computes answers
Q abstract reasoner ans1 . idea formalised following definition.
460

fiCompleteness Guarantees Incomplete Ontology Reasoners

Definition 4.1. Let Q UCQ, let TBox, let ans1 ans2 abstract
reasoners applicable . Then, ans1 Q,T ans2 following conditions hold
ABox A:
1. cert(, , A) = ans1 (, , A) = imply ans2 (, , A) = t;
2. cert(, , A) = f, ans1 (, , A) = f, ans2 (, , A) = f imply
ans1 (Q, , A) cert(Q, , A) ans2 (Q, , A) cert(Q, , A).
Furthermore, ans1 <Q,T ans2 ans1 Q,T ans2 ABox exists least one
following two conditions holds:
3. cert(, , A) = t, ans1 (, , A) = f, ans2 (, , A) = t;
4. cert(, , A) = f, ans1 (, , A) = f, ans2 (, , A) = f,
ans1 (Q, , A) cert(Q, , A) ans2 (Q, , A) cert(Q, , A).
Example 4.2. Consider abstract reasoners rdf, rdfs, rl, classify introduced Example 3.3 query Q TBox Example 3.14. clearly following:
rdf Q,T rdfs Q,T rl Q,T classify
Furthermore, two abstract reasoners, ABox exists distinguishes
abstracts reasoners w.r.t. Q ; example, ABox = {takesCo(c, d), MathsCo(d)},
rdfs(Q, , ) = rl(Q, , ) = {c}. result, also following:
rdf <Q,T rdfs <Q,T rl <Q,T classify



would like check whether ans1 Q,T ans2 ans1 <Q,T ans2 given pair
abstract reasoners subjecting reasoners finite set tests. Towards goal,
R
next define relations R
Q,T <Q,T compare abstract reasoners w.r.t. given
finite set R ABoxes. Ideally, given Q , would like compute finite R
R
R
Q,T <Q,T coincide Q,T <Q,T abstract reasoners class C
interest. ideas captured following definitions.
Definition 4.3. Let Q UCQ, let TBox, let R finite set ABoxes, let
ans1 ans2 abstract reasoners applicable .
Then, ans1 R
Q,T ans2 Conditions 1 2 Definition 4.1 hold ABox
R
R. Furthermore, ans1 <R
Q,T ans2 ans1 Q,T ans2 either Condition 3 Condition
4 Definition 4.1 holds ABox R.
Definition 4.4. Let Q UCQ, let TBox, let C class abstract reasoners
applicable . finite set R ABoxes (Q, )-representative C following
conditions hold ans1 , ans2 C:
1. ans1 R
Q,T ans2 ans1 Q,T ans2 ;
461

fiCuenca Grau, Motik, Stoilos & Horrocks

2. ans1 <R
Q,T ans2 ans1 <Q,T ans2 .
show next, prove R (Q, )-representative, suces show
implication Condition 1 implication Condition 2 Definition 4.4.
Proposition 4.5. Let Q UCQ, let TBox, let C class abstract reasoners
applicable , let R finite set ABoxes
1. ans1 R
Q,T ans2 implies ans1 Q,T ans2 ,
2. ans1 <Q,T ans2 implies ans1 <R
Q,T ans2 .
Then, R (Q, )-representative C.
Proof. Note ans1 Q,T ans2 trivially implies ans1 R
Q,T ans2 ; thus, Condition 1
proposition clearly implies Condition 1 Definition 4.4. Furthermore, ABox R
satisfies Condition 3 4 Definition 4.1, Condition 1 2 Definition 4.1 holds well;
consequently, Conditions 1 2 proposition imply Condition 2 Definition 4.4.
obvious question whether Q-simple -test suite exhaustive class
C Q also (Q, )-representative C. following example shows
necessarily case.
Example 4.6. Let Q specified Example 3.14, let R = {A1 , . . . , A6 }
ABoxes specified Example 3.16. shown Section 3, Q-simple -test suite
= , SQ = {A6 } SQ = {A1 , . . . , A5 } exhaustive CwQ,T Q.
Let trivial abstract reasoner returns empty set input, consider also RDF-based abstract reasoner rdf Example 3.3, ignores TBox
evaluates query directly ABox. Clearly, trivial Q,T rdf; furthermore,
trivial <Q,T rdf since = {St(c), takesCo(c, d), MathCo(d)} rdf(Q, , A) = {c}
whereas trivial(Q, , A) = . abstract reasoners, however, return empty set
answers ABoxes R thus rdf R
Q,T trivial. Hence, using R cannot
dierentiate two abstract reasoners.

4.1 Negative Result
following strong result shows that, numerous TBoxes , finite set ABoxes
exists dierentiate two arbitrary abstract reasoners class sound,
first-order reproducible, monotonic, strongly faithful reasoners. Note result
stronger negative result Theorem 3.21, applies smaller class abstract
reasoners TBoxes imply least one concept subsumption.
Theorem 4.7. Let arbitrary TBox mentioning atomic role R atomic
concepts B |= B, let Q = {B(x) Q(x)}. Then, finite set
ABoxes exists (Q, )-representative class sound, monotonic, strongly
faithful, first-order reproducible abstract reasoners applicable .
462

fiCompleteness Guarantees Incomplete Ontology Reasoners

Proof. Assume finite set ABoxes R exists (Q, )-representative class
sound, monotonic, strongly faithful, first-order reproducible abstract reasoners
applicable . Let n maximum number assertions ABox R.
arbitrary integer k 1, let ansk first-order reproducible abstract reasoner
that, given FOL-TBox Tin , uses following datalog program FTkin :
FTkin

=




Tin | = B
A(x0 ) R(x0 , x1 ) . . . R(xk1 , xk ) B(x0 ) Tin |= B

Clearly, ansk sound, monotonic, strongly faithful; furthermore, ansk (, , A) = f
ABox A. next show ansn+1 (Q, , A) ansn+2 (Q, , A) ABox
R. Consider arbitrary a0 ansn+1 (Q, , A); then, individuals a0 , a1 , . . . , an+1 exist
R(a1 , ) 1 n + 1. Since contains n assertions
rule FTn+1 contains n + 1 body atoms, ai = aj = jthat is,
contains R-cycle. then, rule FTn+2 matched mapping x0
a0 , a0 ansn+2 (Q, , A). Therefore, ansn+1 R
Q,T ansn+2 .
= {A(a0 ), R(a0 , a1 ), . . . , R(an , an+1 )}, however, a0 ansn+1 (Q, , A)
ansn+2 (Q, , A) = ; thus, ansn+1 Q,T ansn+2 hold, contradicts assumption R exhaustive class abstract reasoners theorem.
4.2 Compact Abstract Reasoners
Theorem 4.7 suggests need make additional assumptions abstract reasoners wish compare using finite set ABoxes. section, show
representative sets ABoxes computed practice restrict
abstract reasoners call (Q, )-compact. Intuitively, abstract reasoner
processes Q, , computing certain answers Q, A, subset
, subset depends Q. words, behaviour compact
abstract reasoners simulated following process: select subset axioms
input TBox processed, compute certain answers w.r.t.
selected fragment TBox. class (Q, )-compact abstract reasoners thus captures properties concrete reasoners Jena Oracles Semantic Data Store
discard axioms input TBox fall outside certain fragment (e.g., existential
restrictions right-hand implications) encode remaining axioms
suitable set rules.
Definition 4.8. Let Q UCQ, let TBox. abstract reasoner ans applicable
(Q, )-compact TBox exists following properties hold
ABox A:
1. cert(, , A) = implies ans(, , A) = t;
2. cert(, , A) = f implies ans(, , A) = f ans(Q, , A) = cert(Q, , A).
Abstract reasoner ans compact (Q, )-compact UCQ Q TBox
ans applicable. Finally, CcQ,T class (Q, )-compact strongly
(Q, )-faithful abstract reasoners applicable .
463

fiCuenca Grau, Motik, Stoilos & Horrocks

Example 4.9. abstract reasoners defined Example 3.3 (Q, )-compact
query Q EL-TBox Example 3.14. Indeed, abstract reasoner rdf subset
given = ; abstract reasoner rdfs = {(8)}; abstract reasoner
rl = {(8), (9), (10)}; abstract reasoner classify = .

abstract reasoners ansk defined proof Theorem 4.7 (Q, )compact query TBoxes Theorem 4.7 applies.

Proposition 4.10. Let Q = {B(x) Q(x)} let = {A B, C R.}. Then,
k 1, abstract reasoner ansk proof Theorem 4.7 (Q, )-compact.
Proof. Let Q stated theorem consider arbitrary k 1. Let A1
A2 ABoxes defined follows:
A1 = {A(a0 )}

A2 = {A(a0 ), R(a0 , a1 ), . . . , R(ak1 , ak )}

Clearly, following:
ansk (Q, , A1 ) =

ansk (Q, , A2 ) = {a0 }

One straightforwardly check, however, following holds :
cert(Q, , A1 ) = cert(Q, , A2 )
Thus, ansk (Q, )-compact.
Thus, negative result Theorem 4.7 immediately apply class
containing compact abstract reasoners.
4.3 Comparing Compact Abstract Reasoners
section, show set ABoxes (Q, )-representative CcQ,T
obtained computing, subset , Q-simple -test suite exhaustive

CsQ,T . minor complication arises due fact contain fewer individuals

. deal cases correctly, ABoxes ST allowed contain

individuals occurring , ABoxes STQ allowed contain
individuals occurring Q . assumption without loss generality:

given (Q, )-test suite ST , one replace individuals Q

fresh individuals; result replacement (Q, )-test suite exhaustive CsQ,T .
Theorem 4.11. Let Q UCQ, let TBox. Furthermore, , let




ST = ST , STQ Q-simple -test suite exhaustive CsQ,T Q


ABox ST contains individual ind(T ) \ ind(T ) ABox STQ contains
individual ind(T ) \ ind(Q ). Then, set R ABoxes defined



R=
ST STQ


(Q, )-representative CcQ,T .
464

fiCompleteness Guarantees Incomplete Ontology Reasoners

Proof. Assume R satisfies conditions theorem, let ans1 ans2
arbitrary abstract reasoners CcQ,T . next show ans1 ans2 satisfy two
properties Proposition 4.5.
Property 1 Proposition 4.5:

ans1 R
Q,T ans2 implies ans1 Q,T ans2

Property 2 Proposition 4.5:

ans1 <Q,T ans2 implies ans1 <R
Q,T ans2

Since ans1 (Q, )-compact, TBox exists satisfies conditions
Definition 4.8. Assume ans1 R
Q,T ans2 ; next show Conditions 1 2
Definition 4.1 satisfied arbitrary ABox A.
(Condition 1) Assume cert(, , A) = ans1 (, , A) = t. contrapositive property 2 Definition 4.8, cert(, , A) = t. Since R contains ABoxes

Q-simple -test suite exhaustive CsQ,T Q, Theorem 3.30
exist ABox R -stable renaming dom() = ind(T )
(A ) A; since contain individuals ind(T ) \ ind(T ), renaming also
-stable. definition -test suite, cert(, , ) = t; furthermore, property 1

Definition 4.8 ans1 (, , ) = t. Since ans1 R
Q,T ans2 ans2 (, , ) = t.

Since ans2 strongly (Q, )-faithful -stable, ans2 (, , (A )) = t. Finally, since (A ) ans2 (Q, )-monotonic, ans2 (, , A) = t, required.
(Condition 2) Assume cert(, , A) = f, ans1 (, , A) = f, ans2 (, , A) = f,
consider arbitrary tuple ans(Q, , A) cert(Q, , A). contrapositive
property 1 Definition 4.8, cert(, , A) = f; then, property 2 Definition 4.8, cert(Q, , A). Since R contains ABoxes Q
simple -test suite exhaustive CsQ,T Q, Theorem 3.30 exist
ABox R, tuple b cert(Q, , ), (Q, )-stable renaming
dom() = ind(Q ), (A ) A, (b) = a; since contain individuals ind(T ) \ ind(Q ), renaming also (Q, )-stable. definition
(Q, )-test suite, cert(, , ) = f; furthermore, property 2 Definition 4.8
b ans1 (Q, , ). Since ans1 R ans2 b ans2 (Q, , ). Since ans2 strongly
Q,T
(Q, )-faithful (Q, )-stable, ans2 (Q, , (A )). Finally, since
(A ) ans2 (Q, )-monotonic, ans2 (Q, , A), required.
Assume ans1 <Q,T ans2 . Definition 4.1, ans1 Q,T ans2 ABox
exists satisfying Conditions 3 4 Definition 4.1. Clearly, ans1 R
Q,T ans2 ; hence,
remains shown R contains ABox satisfies Conditions 3 4
Definition 4.1. Since ans1 (Q, )-compact, TBox exists satisfies
conditions Definition 4.8.
(Condition 3) Assume cert(, , A) = t, assume also ans1 (, , A) =
ans2 (, , A) = f. proof Condition 1, identify ABox R
-stable renaming ans1 (, , ) = (A ) A. Since ans2 (Q, )monotonic ans2 (, , A) = f, ans2 (, , (A )) = f; furthermore, since ans2
strongly (Q, )-faithful -stable, also ans2 (, , ) = f. then,
Condition 3 Definition 4.1 satisfied R.
(Condition 4) Assume cert(, , A) = f ans1 (, , A) = ans2 (, , A) = f,
consider arbitrary tuple [ans1 (Q, , A) cert(Q, , A)] \ ans2 (Q, , A).
proof Condition 2, identify ABox R, (Q, )-stable renaming ,
465

fiCuenca Grau, Motik, Stoilos & Horrocks

tuple b cert(Q, , ) (A ) A, (b) = a, b ans1 (Q, , ). Since ans2
(Q, )-monotonic ans2 (Q, , A), ans2 (Q, , (A )); furthermore, since
ans2 strongly (Q, )-faithful (Q, )-stable, also b ans2 (Q, , ).
then, Condition 4 Definition 4.1 satisfied R.
Theorems 3.32 4.11 immediately suggest approach computing set ABoxes
(Q, )-representative CcQ,T . First, compute UCQ rewriting Q w.r.t.
subset ; then, instantiate rule rewriting using injective
instantiation mapping; finally, compute R union ABoxes test suites.
nave procedure, however, practical since requires computing exponential
number UCQ rewritings. next present practical approach computing
set ABoxes (Q, )-representative CcQ,T . Intuitively, instead computing
exponentially many rewritings, one compute single UCQ rewriting Q w.r.t.
subset-closed is, contains rewriting subset .
Definition 4.12. UCQ rewriting R = R , RQ Q w.r.t. subset-closed
tuple R = R , RQ exists R R , RQ RQ R
UCQ rewriting Q w.r.t. .
following corollary immediate consequence Theorems 3.27, 3.32, 4.11.

Corollary 4.13. Let Q UCQ, let TBox, let R subset-closed UCQ rewriting
R
Q w.r.t. , let IR = IR
, IQ injective instantiation R. Then, set
Q,T
R
ABoxes R = IR
.
IQ (Q, )-representative Cc

Practical query rewriting systems REQUIEM optimised produce small
UCQ rewriting possible, output typically subset-closed. Therefore,
technique requires modification UCQ rewriting algorithms implemented existing systems. illustrated following example, required modification typically
involves disabling (at least partially) subsumption-based optimisations.
Example 4.14. Let Q specified Example 3.14, let = , SQ
-test suite Example 3.16. system REQUIEM compute R
given Q . Note, however, R subset-closed; example, UCQ
rewriting Q w.r.t. = Q, subset RQ . rewriting made
subset-closed extending RQ following rules:
St(x) takesCo(x, y) MathCo(x, y) Q(x)
St(x) takesCo(x, y) CalcCo(x, y) Q(x)
MathSt(x) St(x) Q(x)

Systems REQUIEM, however, typically discard rules applying subsumption
optimisations described Section 3.5.3.

following example shows, subset-closed UCQ rewriting Q w.r.t. can,
worst case, exponentially larger minimal UCQ rewritings Q w.r.t. .
Example 4.15. Let Q = {C(x) Q(x)}, let following TBox:
= {B Ai | 1 n} {A1 . . . C}
466

fiCompleteness Guarantees Incomplete Ontology Reasoners

Furthermore, let R = R , RQ R = RQ contains following rules:
C(x) Q(x)

B(x) Q(x)

A1 (x) . . . (x) Q(x)
Clearly, R UCQ rewriting Q w.r.t. ; however, number rules subset-closed
UCQ rewriting Q w.r.t. exponential n.


5. Evaluation
implemented techniques computing exhaustive test suites comparing incomplete concrete reasoners prototype tool called SyGENiA.1 tool uses REQUIEM
computing UCQ datalog rewritings.2
considered two evaluation scenarios. first one uses well-known Lehigh
University Benchmark (LUBM) (Guo et al., 2005), consists relatively small
TBox academic domain, 14 test queries, data generator. second one
uses small version GALEN (Rector & Rogers, 2006)a complex ontology commonly
used medical applications.
evaluated following concrete reasoners: Sesame v2.3-prl,3 DLE-Jena v2.0,4
OWLim v2.9.1,5 Minerva v1.5,6 Jena v2.6.37 three variants (Micro, Mini,
Max).
5.1 Computing Exhaustive Test Suites
Given UCQ Q TBox , tool uses REQUIEM compute datalog rewriting
R Q . R UCQ rewriting, tool computes simple test suite
either full injective instantiation (see Sections 3.5 3.6, respectively); otherwise,
tool computes non-simple test suite instantiating R described Section 3.7.3.
5.1.1 Simple Test Suites
case LUBM benchmark, 14 test queries leads UCQ rewriting w.r.t. TBox.8 Therefore, computed UCQ rewriting query Q
benchmark using REQUIEM instantiated it, fully injectively, thus obtaining
Q-simple -test suites exhaustive Q CwQ,T CsQ,T , respectively.
times needed compute test suites size test suite shown Table
3, denotes total number ABoxes corresponding test suites.
1.
2.
3.
4.
5.
6.
7.
8.

http://code.google.com/p/sygenia/
http://www.cs.ox.ac.uk/projects/requiem/home.html
http://www.openrdf.org/
http://lpis.csd.auth.gr/systems/DLE-Jena/
http://www.ontotext.com/owlim/
http://www.alphaworks.ibm.com/tech/semanticstk
http://jena.sourceforge.net/
Since REQUIEM currently support individuals queries, replaced individuals
queries distinguished variables.

467

fiCuenca Grau, Motik, Stoilos & Horrocks

Q,T
Cw

CsQ,T

Q1
Time 1.2

2
Time 1.2

1

Q2 Q3 Q4 Q5 Q6 Q7 Q8 Q9 Q10 Q11 Q12 Q13 Q14
0.7 0.2 6.7 0.2 2.1 0.7
7
2.4 7.4 0.07 0.2 0.2 0.05
20 2 2 352 8 1207 345 3 092 5 3 919 7
25 10
1
0.6 0.2 0.6 0.2 1.2 0.4 1.5 2.5 0.6 0.05 0.1 0.1 0.08
4
1
22
4 169 37
36
1 169
2
3
5
1

Table 3: Computation simple test suites LUBM. Times given seconds.

Q,T
Cw

CsQ,T

Time

Time


Q1
14
6 049
2.2
79

Q2
34
12 085
6
151

Q3
67
12 085
40
151

Q4
4.6
79
1.7
25

Table 4: Computation simple test suites GALEN. Times given seconds.
shown table, simple test suites could computed times ranging 0.05
7 seconds, CwQ,T CsQ,T . optimisations implemented REQUIEM ensure
UCQ rewritings relatively small, resulting test suites also consist
relatively small number ABoxes. Notice, however, significant dierence
numbers ABoxes test suites obtained via injective instantiation (which range 1
169 average 32), obtained via full instantiation (which range
1 3, 919 average 702). Furthermore, rule rewriting contains
6 atoms, therefore ABox test suite also contains 6 assertions.
case GALEN, used following sample queries, REQUIEM
compute UCQ rewriting:
Q1
Q2
Q3
Q4

:
:
:
:

HaemoglobinConcentrationProcedure(x) Q(x)
PlateletCountProcedure(x) Q(x)
LymphocyteCountProcedure(x) Q(x)
HollowStructure(x) Q(x)

instantiated UCQ rewriting fully injectively. times needed compute test suites size test suite shown Table 4.
shown table, simple test suites GALEN computed times ranging
1.7 67 seconds average 33 seconds. Thus, computing test suites
GALEN time consuming LUBM. unsurprising since TBox
GALEN significantly complex LUBM. number ABoxes
test suites ranged 25 151 case injective instantiations 79
12, 000 case full instantiations; again, note significant dierence
sizes two kinds test suites. cases, however, individual ABox
small, largest one containing 11 assertions.
5.1.2 Non-Simple Test Suites
also computed non-simple test suites cases UCQ rewriting exists.
already mentioned, LUBM queries UCQ-rewritable. Therefore, manually added
following query, REQUIEM computes recursive datalog rewriting.
468

fiCompleteness Guarantees Incomplete Ontology Reasoners

Time (s)


CfT

LUBM
Q15
1.4
22

Q5
5.2
41

GALEN
Q6 Q7
1.3 2.7
23
31

Q8
1.6
12

Table 5: General test suites computed datalog rewritings LUBM GALEN.
System
Completeness Guarantee Completeness w.r.t. LUBM data set
JenaMax/DLE-Jena
Q1 Q14
Q1 Q14
OWLim
Q1 Q5 , Q7 , Q9 , Q11 Q14
Q1 Q14
Jena Mini/Micro
Q1 Q5 , Q7 , Q9 , Q11 Q14
Q1 Q14
Minerva
Q1 Q4 , Q9 , Q14
Q1 Q14
Sesame
Q1 , Q3 , Q11 , Q14
Q1 Q5 , Q11 , Q14

Table 6: Completeness guarantees UCQ-rewritable queries LUBM
Q15 :

Organization(x) Q(x)

Due complex structure GALEN TBox, test queries UCQ rewritable
easily identified. evaluated following four.
Q5
Q6
Q7
Q8

:
:
:
:

WestergrenESRProcedure(x) Q(x)
ArthroscopicProcedure(x) Q(x)
TrueCavity(x) Q(x)
BacterialCellWall(x) Q(x)

Times needed compute test suites size test suite shown Table 5.
5.2 Completeness Guarantees
already discussed, existing concrete reasoners captured strongly (Q, )-faithful
abstract reasoners. Hence, order establish completeness guarantees concrete
reasoners, restricted tests test suites computed using injective instantiations.
5.2.1 Results Simple Test Suites
results original queries LUBM benchmark shown Table 6.
concrete reasoner, first column table shows queries
able prove completeness using techniques (i.e., queries complete
arbitrary data set), second column table shows queries
concrete reasoner computes answers canonical LUBM data set one university.
results clearly show completeness w.r.t. data set LUBM benchmark
guarantee completeness arbitrary data sets; example, OWLim, Minerva,
Jena Mini/Micro complete queries w.r.t. LUBM data set (and
systems even complete expressive UOBM benchmark); however, certain
queries, systems found incomplete data set test suites.
Jena Max DLE-Jena systems guaranteed complete
14 LUBM queries regardless data setthat is, systems behave exactly like
complete OWL reasoner LUBM queries LUBM TBox. According Jenas
469

fiCuenca Grau, Motik, Stoilos & Horrocks

documentation, Jena Max supports types axioms used LUBM TBox, hence
expected complete LUBM TBox queries. Interestingly, tested
LUBM data sets, Jena Max could compute answers many
queries, used smaller LUBM data sets instead. demonstrates additional
advantage approach: require reasoning w.r.t. large data sets, since
ABoxes test suites typically contain small number assertions. Regarding DLEJena, according technical description (Meditskos & Bassiliades, 2008), system
uses complete DL reasoner materialise certain subsumptions preprocessing step
uses Jena saturate ABox, much like abstract reasoner classify
Example 3.3. Hence, DLE-Jena least complete Jena Mini and, addition,
able draw inferences Jena Mini missing (see below).
OWLim complete LUBM queries involve reasoning existential
quantifiers consequent implications. well known latter supported
system. Jena Mini Micro exhibited exactly behaviour OWLim,
despite fact Jena Mini handle larger fragment OWL OWLim. Clearly,
LUBM TBox queries suciently complex reveal dierences
OWLim, Jena Mini/Micro.
Minerva guaranteed complete six queries. Like DLE-Jena, uses
DL reasoner materialise entailed subsumptions atomic concepts, uses
custom method saturating ABox. investigating several ABoxes test
suites concluded Minerva cannot correctly handle (at-least) inverse role axioms;
example, cannot find entailment { R R , R(a, b) } |= R(b, a).
Finally, Sesame complete four queries. unsurprising since Sesame
RDFS reasoner thus complete small fragment OWL 2 DL.
next discuss results tests based GALEN ontology test queries
Q1 Q4 . could run Jena Max since GALEN heavily uses existential restrictions,
(according Jenas documentation) might cause problems. Minerva
system provided completeness guarantee least one query (Q4 );
Minerva precomputes subsumption relationships atomic concepts depend
existential restrictions right hand side TBox axioms, systems
handle. Also, unlike LUBM, version GALEN used contain
inverse roles, Minerva performed much better ontology. systems
identified incomplete test queries.
5.2.2 Results Non-Simple Test Suites
Results test queries UCQ-rewritable summarised Table 7. Symbol
indicates concrete reasoner found complete given query. Furthermore, whenever concrete reasoner failed test suite, tried prove reasoner
incomplete discussed examples Section 3.7.2; cases successful,
symbol indicates concrete reasoner identified incomplete
given query. Finally, symbol indicates concrete reasoner ran memory.
case LUBM, able establish completeness guarantees w.r.t. query
Q15 OWLim, Jena Micro, DLE-Jena, Jena Max. Note systems
handle recursive TBox statements, completeness Q15 surprising. RDFS,
470

fiCompleteness Guarantees Incomplete Ontology Reasoners

OWLim
Jena Max
Jena Micro
DLE-Jena
Minerva
Sesame

LUBM
Q15







Q5






GALEN
Q6 Q7











Q8






Table 7: Completeness guarantees datalog-rewritable queries

CsQ,T

Q1 Q2 Q3 Q4 Q5 Q6 Q7 Q8 Q9 Q10 Q11 Q12 Q13 Q14
Time 1.4 1.1 0.2 1.8 0.8 1.2 9.5 7.8 - 0.9 0.05 0.5 0.6 0.04
R
1 24 17 130 136 219 925 777 - 219 2
74 185 1

Table 8: Representative sets ABoxes LUBM. Times given seconds.
however, cannot express recursive TBox statements involving roles, Sesamean RDFS
reasonerfails compute certain answers tests.
case GALEN, completeness guaranteed query Q8 OWLim, Jena Micro,
DLE-Jena, Minerva, additionally query Q6 Minerva. already mentioned,
answers queries GALEN depend positive occurrences existential restrictions
axioms, systems cannot handle. could run Jena Max GALEN.
5.3 Comparing Incomplete Concrete Reasoners
also implemented techniques comparing reasoners Section 4.3. end,
modified REQUIEM compute subset-closed rewritings, injectively
instantiated obtain (Q, )-representative sets ABoxes R.
5.3.1 Tests LUBM
shown Table 8, representative sets ABoxes could computed seconds
LUBM queries. exception Q9 , REQUIEM terminate
disabling rule subsumption optimisations. size representative sets ranged
1 777 ABoxes. expected, representative sets contain ABoxes
exhaustive test suites query TBox (see Table 3).
combinations system query tests Section 5.2 identified
system incomplete shown Table 9. table shows proportion certain
answers system returned applied LUBM data set, ABoxes R,
ABoxes test suite used Section 5.2 check systems completeness.
shown table, OWLim Jena Micro exhibited behaviour
almost complete. contrast, Sesame least complete queries. Furthermore,
please note dierence values obtained R S; particular,
Sesame compute certain answer Q5 S, whereas system able
compute certain answers Q5 ABoxes (e.g., LUBM data set).
ABoxes cannot distinguish Sesame trivial reasoner always
returns empty set answers; however, set R make distinction.
471

fiCuenca Grau, Motik, Stoilos & Horrocks

LUBM

R

Q5
1
0.25
0.8

Q6
1
0.86
0.86

LUBM

R

Q2
1
0.75
0.75

Q4
1
0.68
0.06

Minerva
Q8
Q10
Q12
1
1
1
0.98 0.86 0.25
0.81 0.84 0.92
Sesame
Q5
Q6
Q7
Q8
1
0.83 0.87 0.83
0
0.003 0.04 0.04
0.36 0.033 0.01 0.004
Q7
1
0.86
0.86

Q13
1
0.2
0.23

OWLim & JMicro
Q6
Q8
Q10
1
1
1
0.99
0.98
0.99
0.96
0.98
0.97

Q9
0.64
0
-

Q10
0.83
0.001
0.028

Q12
0
0.25
0.017

Q13
0
0.2
0.23

Table 9: Reasoner comparison LUBM

CsQ,T

Time
R

Q1
15
140

Q2
46
266

Q3
70
266

Q4
2
127

Table 10: Representative sets ABoxes GALEN
5.3.2 Tests GALEN
shown Table 10, representative sets ABoxes GALEN could computed
times ranging 2 70 seconds, set contains small number ABoxes.
system query, Table 11 shows proportion certain answers returned
system R test suite Section 5.2. Minerva complete
system. Jena Micro better DLE-Jena (apart query Q4 ), DLE-Jena
OWLim behaved almost way (again apart query Q4 ). expected,
Sesame least complete system.
discrepancies OWLim, Jena Micro, DLE-Jena Minerva rather
surprising. OWLim Jena theoretically support features OWL; furthermore,
DLE-Jena extension Jena (Meditskos & Bassiliades, 2008) DLE-Jena
least complete Jena, case LUBM. order explain discrepancies,
analysed test suites queries Q1 Q4 . precisely, selected ABoxes
OWLim fails return certain answers Jena Micro complete,
identified minimal set TBox axioms entail certain answers. analysis
revealed that, query Q4 , OWLim fails find entailment
{Device(a), HollowTopology(b), hasTopology(a, b)} |= HollowStructure(a),

follows following GALEN axioms:

HollowTopology Topology hasState.Hollow
Device SolidStructure

HollowStructure SolidStructure hasTopology.(Topology hasState.Hollow)

Although existential restrictions appear several axioms, observe reasoning
existential variables actually required, first third axioms imply (by simple
structural transformation) following axiom:
SolidStructure hasTopology.HollowTopology HollowStructure
472

fiCompleteness Guarantees Incomplete Ontology Reasoners

Sesame
OWLim
DLE-Jena
JMicro
Minerva

Q1

R
0.01 0.18
0.54 0.65
0.54 0.65
0.69 0.82
0.84 0.91

Q2

R
0 0.16
0.52 0.63
0.52 0.63
0.68 0.81
0.84 0.90

Q3

R
0 0.16
0.52 0.63
0.52 0.63
0.68 0.81
0.84 0.90

Q4

R
0.04 0.10
0.52 0.48
0.76 0.9
0.76 0.67
1
1

Table 11: Reasoner comparison GALEN
axiom entails required answer, systems deal axioms form;
however, unlike Jena Micro, OWLim appears incapable dealing cases.
Regarding DLE-Jena, according technical description (Meditskos & Bassiliades,
2008), system replaced several inference rules Jena queries DL reasoner, strictly extend Jena. investigation exhaustive test suite
query Q4 revealed DLE-Jena returns many answers based existential
restrictions right hand side TBox axioms Jena misses; however, investigation also revealed DLE-Jena misses several inferences Jenas TBox reasoner
capture, probably due replacement Jenas inference rules. also
explains DLE-Jena performs worse Minerva GALEN.
results clearly show behaviour systems greatly depends given
application scenario. example, DLE-Jena complete LUBM queries,
perform equally well GALEN. contrast, Minerva perform well
LUBM, complete system GALEN. results thus allow application
developers conduct thorough comparison reasoning systems given application.

6. Conclusion
paper proposed theoretical framework practical techniques establishing formally provable algorithmically verifiable completeness guarantees incomplete ontology reasoners. approach radically departs ad hoc evaluation based
well-known benchmarks, provides solid foundation striking balance
scalability completeness practical applications.
approach also opens numerous exciting possibilities future research.
example, work opens door design ontology-based information systems
optimised class ontologies, queries, data relevant particular application. information systems could maximise scalability reasoning still ensuring
completeness query answers, even rich ontologies sophisticated queries.

Acknowledgments
extended version paper Incomplete Semantic Web Reasoner?
Giorgos Stoilos, Bernardo Cuenca Grau, Ian Horrocks published AAAI 2010
paper Completeness Guarantees Incomplete Reasoners authors
published ISWC 2010.
473

fiCuenca Grau, Motik, Stoilos & Horrocks

research supported EU project SEALS (FP7-ICT-238975),
EPSRC projects ExODA (EP/H051511/1) HermiT (EP/F065841/1). B. Cuenca
Grau supported Royal Society University Research Fellowship.

References
Acciarri, A., Calvanese, D., De Giacomo, G., Lembo, D., Lenzerini, M., Palmieri, M., &
Rosati, R. (2005). Quonto: Querying ontologies. Proceedings 20th National
Conference Artificial Intelligence (AAAI-05)., pp. 16701671. AAAI Press /
MIT Press.
Artale, A., Calvanese, D., Kontchakov, R., & Zakharyaschev, M. (2009). DL-Lite family
relations. J. Artificial Intelligence Research (JAIR), 36, 169.
Baader, F., McGuinness, D., Nardi, D., & Patel-Schneider, P. (2002). Description Logic
Handbook: Theory, implementation applications. Cambridge University Press.
Baader, F., Brandt, S., & Lutz, C. (2005). Pushing EL envelope. Proceedings
19th International Joint Conference AI (IJCAI-05), pp. 364369. MorganKaufmann Publishers.
Bishop, B., Kiryakov, A., Ognyano, D., Peikov, I., Tashev, Z., & Velkov, R. (2011).
OWLIM: family scalable semantic repositories. Semantic Web, 2 (1), 3342.
Broekstra, J., Kampman, A., & van Harmelen, F. (2002). Sesame: generic architecture
storing querying RDF RDF Schema. Proceedings 1st International
Semantic Web Conference (ISWC 2002), pp. 5468.
Cal, A., Gottlob, G., Lukasiewicz, T., Marnette, B., & Pieris, A. (2010). Datalog+/-:
family logical knowledge representation query languages new applications.
Proc. 25th Annual IEEE Symposium Logic Computer Science (LICS),
pp. 228242.
Calvanese, D., De Giacomo, G., Lembo, D., Lenzerini, M., & Rosati, R. (2007). Tractable
reasoning ecient query answering description logics: DL-Lite family.
Journal Automated Reasoning, 39 (3), 385429.
Ceri, S., Gottlob, G., & Tanca, L. (1989). always wanted know datalog
(and never dared ask). IEEE Trans. Knowledge Data Engineering, 1 (1), 146166.
Cuenca Grau, B., Horrocks, I., Kazakov, Y., & Sattler, U. (2008a). Modular Reuse
Ontologies: Theory Practice. Journal Artificial Intelligence Research, 31, 273
318.
Cuenca Grau, B., Horrocks, I., Motik, B., Parsia, B., Patel-Schneider, P., & Sattler, U.
(2008b). OWL 2: next step OWL. Journal Web Semantics (JWS), 6 (4),
309322.
Derriere, S., Richard, A., & Preite-Martinez, A. (2006). Ontology Astronomical
Object Types Virtual Observatory. Proc. 26th meeting IAU:
Virtual Observatory Action: New Science, New Technology, Next Generation
Facilities, pp. 1718, Prague, Czech Republic.
474

fiCompleteness Guarantees Incomplete Ontology Reasoners

Erling, O., & Mikhailov, I. (2009). RDF support virtuoso DBMS. Pellegrini, T.,
Auer, S., Tochtermann, K., & Schaert, S. (Eds.), Networked Knowledge - Networked
Media, pp. 724. Springer Berlin / Heidelberg.
Fitting, M. (1996). First-Order Logic Automated Theorem Proving, 2nd Edition. Texts
Computer Science. Springer.
Glimm, B., Horrocks, I., Lutz, C., & Sattler, U. (2007). Conjunctive query answering
description logic SHIQ. Proceedings International Joint Conference
AI (IJCAI), pp. 399404.
Golbreich, C., Zhang, S., & Bodenreider, O. (2006). Foundational Model Anatomy
OWL: Experience Perspectives. Journal Web Semantics, 4 (3), 181195.
Goodwin, J. (2005). Experiences using OWL Ordnance Survey. Proc.
OWL: Experiences Directions Workshop (OWLED 2005), Galway, Ireland.
Guo, Y., Pan, Z., & Heflin, J. (2005). LUBM: Benchmark OWL Knowledge Base
Systems. Journal Web Semantics, 3 (2), 158182.
Haarslev, V., & Moller, R. (2001). RACER System Description. Gore, R., Leitsch, A., &
Nipkow, T. (Eds.), Proc. 1st Int. Joint Conf. Automated Reasoning (IJCAR
2001), Vol. 2083 LNAI, pp. 701706, Siena, Italy. Springer.
Hayes, P. (2004). RDF Semantics. World Wide Web Consortium (W3C) Recommendation.
Horrocks, I., Patel-Schneider, P. F., & van Harmelen, F. (2003). SHIQ RDF
OWL: making web ontology language. Journal Web Semantics, 1 (1), 726.
Kiryakov, A., Ognyanov, D., & Manov, D. (2005). Owlim-a pragmatic semantic repository
owl.. Dean, M., Guo, Y., Jun, W., Kaschek, R., Krishnaswamy, S., Pan, Z., &
Sheng, Q. Z. (Eds.), WISE Workshops, pp. 182192.
Lacy, L., Aviles, G., Fraser, K., Gerber, W., Mulvehill, A., & Gaskill, R. (2005). Experiences
Using OWL Military Applications. Proc. OWL: Experiences Directions
Workshop (OWLED 2005), Galway, Ireland.
Lutz, C., Toman, D., & Wolter, F. (2009). Conjunctive query answering description
logic EL using relational database system. Proceedings 21st International
Joint Conference AI (IJCAI), pp. 20702075.
Ma, L., Yang, Y., Qiu, Z., Xie, G. T., Pan, Y., & Liu, S. (2006). Towards complete OWL
ontology benchmark. Proceedings 3rd European Semantic Web Conference
(ESWC 2006), pp. 125139.
McBride, Brian (2001). Jena: Implementing RDF Model Syntax Specification.
International Workshop Semantic Web 2001.
Meditskos, G., & Bassiliades, N. (2008). Combining DL reasoner rule engine
improving entailment-based OWL reasoning. Proceedings 7th International
Semantic Web Conference (ISWC 2008), pp. 277292.
Motik, B., Cuenca Grau, B., Horrocks, I., Wu, Z., Fokoue, A., & Lutz, C. (2009a). OWL 2
Web Ontology Language Profiles. W3C Recommendation.
475

fiCuenca Grau, Motik, Stoilos & Horrocks

Motik, B., Shearer, R., & Horrocks, I. (2009b). Hypertableau Reasoning Description
Logics. J. Artificial Intelligence Research (JAIR), 173 (14), 12751309.
Ortiz, M., Calvanese, D., & Eiter, T. (2008). Data complexity query answering expressive description logics via tableaux. Journal Automated Reasoning, 41 (1), 6198.
Perez-Urbina, H., Horrocks, I., & Motik, B. (2009). Ecient Query Answering OWL 2.
Proceedings 8th International Semantic Web Conference (ISWC 2009), Vol.
5823 LNCS, pp. 489504. Springer.
Perez-Urbina, H., Motik, B., & Horrocks, I. (2010). Tractable query answering rewriting
description logic constraints. Journal Applied Logic, 8 (2), 186209.
Prudhommeaux, E., & Seaborne, A. (2008). SPARQL query language RDF. World
Wide Web Consortium (W3C). W3C Recommendation.
Rector, A. L., & Rogers, J. (2006). Ontological practical issues using description
logic represent medical concept systems: Experience galen. Barahona,
P., Bry, F., Franconi, E., Henze, N., & Sattler, U. (Eds.), Reasoning Web, Second
International Summer School 2006, pp. 197231.
Sidhu, A., Dillon, T., Chang, E., & Sidhu, B. S. (2005). Protein Ontology Development
using OWL. Proc. OWL: Experiences Directions Workshop (OWLED
2005), Galway, Ireland.
Sirin, E., Parsia, B., Cuenca Grau, B., Kalyanpur, A., & Katz, Y. (2007). Pellet: practical
OWL-DL reasoner. Journal Web Semantics, 5 (2), 5153.
Soergel, D., Lauser, B., Liang, A., Fisseha, F., Keizer, J., & Katz, S. (2004). Reengineering
Thesauri New Applications: AGROVOC Example. J. Digital Information,
4 (4).
Wu, Z., Eadon, G., Das, S., Chong, E. I., Kolovski, V., Annamalai, M., & Srinivasan, J.
(2008). Implementing inference engine rdfs/owl constructs user-defined
rules oracle. Proceedings 2008 IEEE 24th International Conference
Data Engineering (ICDE 08), pp. 12391248. IEEE Computer Society.

476

fiJournal Artificial Intelligence Research 43 (2012) 293-328

Submitted 07/11; published 03/12

SAS+ Planning Satisfiability
Ruoyun Huang
Yixin Chen
Weixiong Zhang

RUOYUN . HUANG @ WUSTL . EDU
CHEN @ CSE . WUSTL . EDU
WEIXIONG . ZHANG @ WUSTL . EDU

Department Computer Science Engineering
Washington University St. Louis
Saint Louis, Missouri, 63130, USA

Abstract
Planning satisfiability principal approach planning many eminent advantages.
existing planning satisfiability techniques usually use encodings compiled STRIPS.
introduce novel SAT encoding scheme (SASE) based SAS+ formalism. new
scheme exploits structural information SAS+, resulting encoding
compact efficient planning. prove correctness new encoding establishing
isomorphism solution plans SASE STRIPS based encodings.
analyze transition variables newly introduced SASE explain accommodates
modern SAT solving algorithms improves performance. give empirical statistical results
support analysis. also develop number techniques reduce encoding size
SASE, conduct experimental studies show strength individual technique. Finally,
report extensive experimental results demonstrate significant improvements SASE
state-of-the-art STRIPS based encoding schemes terms time memory efficiency.

1. Introduction
Planning satisfiability (SAT) one main paradigms planning. Methods using
technique usually compile planning problem sequence SAT instances, increasing
time horizons (Kautz & Selman, 1999). Planning satisfiability number distinct characteristics make efficient widely applicable. makes use extensive advancement
fast SAT solvers. SAT formulae extended accommodate variety complex problems, planning uncertainty (Castellini, Giunchiglia, & Tacchella, 2003), numerical
planning (Hoffmann, Kautz, Gomes, & Selman, 2007) temporally expressive planning (Huang,
Chen, & Zhang, 2009).
key factor performance planning satisfiability approaches SAT encoding
scheme, way planning problem compiled SAT formulae boolean variables
clauses. encoding scheme great impact efficiency SAT-based planning,
developing novel superior SAT encodings active research topic. Extensive research
done make SAT encoding compact. One example compact encoding
lifted action representation (Kautz & Selman, 1996; Ernst, Millstein, & Weld, 1997).
compact encoding scheme, action represented conjunction parameters. result,
method mitigates issue blowing encoding size. original scheme guarantee
optimality makespans. However, improved lifted action representation preserves
optimality proposed (Robinson, Gretton, Pham, & Sattar, 2009). new encoding proposed
c
2012
AI Access Foundation. rights reserved.

fiH UANG , C HEN , & Z HANG

based relaxed parallelism semantic (Rintanen, Heljanko, & Niemel, 2006), also
guarantee optimality.
previous enhancements based conventional STRIPS formalism planning.
Recently, SAS+ formalism (Bckstrm & Nebel, 1996) attracted lot attention
rich structural information. SAS+ formalism represents planning problem using multi-valued
state variables instead propositional facts STRIPS (Bckstrm & Nebel, 1996). SAS+
formalism used derive heuristics (Helmert, 2006; Helmert, Haslum, & Hoffmann, 2008),
landmarks (Richter, Helmert, & Westphal, 2008), new search models (Chen, Huang, & Zhang,
2008), strong mutual exclusion constraints (Chen, Huang, Xing, & Zhang, 2009).
paper, proposed first SAS+ based SAT encoding scheme (SASE) classical
planning. Unlike previous STRIPS based SAT encoding schemes model actions facts,
SASE directly models transitions SAS+ formalism. Transitions viewed highlevel abstraction actions, typically significantly fewer transitions actions
planning task. proposed SASE scheme describes two major classes constraints: first
constraints transitions second constraints match actions transitions.
theoretically empirically studied new SAS+ based SAT encoding compared
traditional STRIPS based SAT encoding. improve performance SASE,
proposed number techniques reduce encoding size recognizing certain structures actions
transitions.
studied relationship solution space SASE STRIPS based
encoding. results showed solution plans found SATPlan06, representative STRIPS
based encoding, SASE isomorphic, meaning bijective mapping
two. Hence, showed equivalence solving STRIPS based encoding SASE.
attempt understand performance gain SASE, studied new encoding
scheme makes SAT solving algorithm behave favorable way. study quantified
widely used VSIDS heuristic (Moskewicz, Madigan, Zhao, Zhang, & Malik, 2001).
transition variables introduced higher frequencies clauses, consequently
higher VSIDS scores. higher VSIDS scores lead branching transition variables
action variables. Since transition variables high scores hence stronger constraint
propagation, branching transition variables leads faster SAT solving. provided
empirical evidence support explanation. Moreover, introduced indicator called
transition index, empirically showed strong correlation transition
index SAT solving speedup.
Finally, evaluated SASE standard benchmarks recent International Planning
Competitions. results show new SASE encoding scheme efficient terms
time memory usage compared STRIPS-based encodings, solves large instances
state-of-the-art STRIPS-based SAT planners fail solve.
paper organized follows. giving basic definitions Section 2, present
SAS+ based SASE encoding Section 3 prove equivalence STRIPS based encoding Section 4. study SASE works better modern SAT solvers Section 5.
techniques reduce encoding size presented Section 6. present experimental results Section 7. Finally, review related works conclude Section 8.
294

fiSAS+ P LANNING ATISFIABILITY

2. Background
section, first briefly introduce STRIPS formalism review representative STRIPS
based SAT encoding. Then, define SAS+ formalism, develop new SAT
encoding scheme.
2.1 STRIPS Formalism
traditional STRIPS planning representation defined binary-valued propositional facts.
STRIPS planning problem tuple = (F, A, , G ), where:
F set propositional facts;
set actions. action triple = (pre(a), add(a), del(a)), pre(a)
F set preconditions, add(a) F del(a) F sets add facts
delete facts, respectively;
state F subset facts assumed true. fact assumed false
state. F initial state, G F specification goal state goal
states.
define three sets actions. use ADD(f ) denote set actions f one
add effects, meaning ADD(f ) = {a | f add(a)}. Similarly, two action sets
DEL(f ) = {a | f del(a)} PRE(f ) = {a | f pre(a)}.
action applicable state pre(a) . use apply(, a) denote state
applying applicable action , variable assignments changed ( \
del(a)) add(a). also write apply(s, P ) denote state applying set actions P
parallel, P A, s. set actions P applicable , 1) P applicable
, 2) exist two actions a1 , a2 P a1 a2 mutually exclusive
(mutex) (Blum & Furst, 1997). Two actions b mutex time step one
following three conditions holds:
Inconsistent effects: del(a) add(b) 6= del(b) add(a) 6= .
Interference: del(a) pre(b) 6= del(b) pre(a) 6= .
Competing needs: exist f1 pre(a) f2 pre(b), f1 f2 mutex
time step 1.
Two facts f1 f2 mutex time step if, actions b f1 add(a), f2
add(b), b mutex previous time step. call mutex defined planning graphs
P-mutex, order distinguish mutex another notion mutex next section.
Definition 1 (Parallel solution plan). STRIPS planning problem = (F, A, , G ),
parallel solution plan sequence P = {P1 , P2 , . . . , PN }, Pt A, = 1, 2, . . . , N ,
set actions executed time step t,
G apply(. . . apply(apply(I , P1 ), P2 ) . . . PN ).
295

fiH UANG , C HEN , & Z HANG

2.2 STRIPS Based SAT Encoding (PE)
SAT instance tuple (V, C), V set variables C set clauses. Given
SAT instance (V, C), assignment sets every variable v V true false, denoted (v) =
(v) =. assignment makes every clause C true, solution (V, C).
encoding scheme SatPlan06 (Kautz, Selman, & Hoffmann, 2006) (denoted PE
following), compiled planning graphs, well known extensively tested
STRIPS based encoding. facilitate encoding, SatPlan06 introduces dummy action dumf
f precondition add-effect. use A+ denote set actions
dummy actions added, {dumf | f F}. Unless otherwise indicated, action set
ADD(f ), DEL(f ), PRE(f ) include corresponding dummy actions.
denote SatPlan06 encoding time step N PE(, N ), given STRIPS task
= (F, A, , G ). SAT instance, PE(, N ) defined (V, C), V = {Wf,t |f
F, [1, N + 1]} {Wa,t |a A+ , [1, N ]}. Wf,t = indicates f true t, otherwise
Wf,t =. clause set C includes following types clauses:




I. Initial state: (f, f ): Wf,1 ;
II. Goal state: (f, f G ): Wf,N +1 ;
III. Add effect: (f F, [1, N ]): Wf,t+1

W

a,f add(a) Wa,t ;

IV. Precondition: (a A+ , f pre(a), [1, N ])): Wa,t Wf,t ;
V. Mutex actions: (a, b A+ , [1, N ], b mutex): W a,t W b,t ;
VI. Mutex facts: (f, g F, [1, N + 1], f g mutex) : W f,t W g,t ;
Clauses class II enforce initial state true first time step,
goal facts need true last time step, respectively. Clauses class III specify fact
f true time step t, least one action A+ time step 1 f
add effect. Clauses class IV specify action true time t, preconditions
true time t. Classes V VI specify mutex actions facts, respectively.
PE one typical SAT encoding schemes STRIPS planning. action
variables fact variables, enforces semantics one defined planning graph.
Later show equivalence new SASE encoding PE.
2.3 SAS+ Formalism
SAS+ formalism (Bckstrm & Nebel, 1996) represents classical planning problem set
multi-valued state variables. planning task SAS+ formalism defined tuple
= {X , O, sI , sG },
X = {x1 , , xN } set state variables, associated finite domain Dom(xi );
set actions action tuple (pre(a), eff(a)), pre(a)
eff(a) sets partial state variable assignments form xi = v, v Dom(xi );
state full assignment (a set assignments assigns value every state variable).
assignment (x = f ) s, write s(x) = f . denote set states.
296

fiSAS+ P LANNING ATISFIABILITY

sI initial state, sG partial assignment state variables define
goal. state goal state sG s.
first define transition is. paper, build constraints recognizing transitions atomic elements state transitions. Actions, cast constraints well case, act
another layer logic flow transitions.
Definition 2 (Transition). SAS+ planning task = {X , O, sI , sG }, given state variable
x X , transition re-assignment x value f g, f, g Dom(x), written fxg ,
x
unknown value g, written g
. may also simplify notation fxg f g
, confusion.
Transitions SAS+ planning task classified three categories.
Transitions form fxg called regular. regular transition fxg applicable
state s, iff s(x) = f . Let = apply(s, fxg ) state applying transition state
s, (x) = g.
Transitions form fxf called prevailing. prevailing transition fxf applicable
state iff s(x) = f , apply(s, fxf ) = s.
x
x

called mechanical. mechanical transition g
Transitions form g
x


applied arbitrary state s, result apply(s, g ) state (x) = g.

transition applicable state three cases. action a, denote
transition set rans(a), includes: regular transitions fxg (x = f )
pre(a) (x = g) eff(a), prevailing transitions fxf (x = f ) pre(a),
x
mechanical transitions g
(x = g) eff(a). Given transition , use A() denote
set actions rans(a). call A() supporting action set .
x
}, f, g Dom(x),
state variable x, introduce (x) = {fxg }{fxf }{g
set transitions affect x. also define union (x), x X .
set transitions. also use R(x) = {fxf | f, f Dom(x)} denote set
prevailing transitions related x, R union R(x) x X .
Definition 3 (Transition Mutex). SAS+ planning task, two different transitions 1 2
mutually exclusive iff exists state variable x X 1 , 2 (x), one
following holds:
1. Neither 1 2 mechanical transition.
2. least one 1 2 mechanical transition, 1 2 transit different values.
set transitions applicable state 1) every transition applicable
s, 2) exist two transitions 1 , 2 1 2 mutually exclusive.
applicable s, write apply(s, ) denote state applying transitions
arbitrary order.
297

fiH UANG , C HEN , & Z HANG

Definition 4 (Transition Plan). transition plan sequence {T1 , T2 , . . . , TN },
Tt , [1, N ], set transitions executed time step t,
sG apply(. . . apply(apply(sI , T1 ), T2 ) . . . TN ).
SAS+ planning task, given state action a, variable assignments
pre(a) match assignments s, applicable state s. use apply(s, a) denote state
applying s, variable assignments changed according eff(a).
Definition 5 (S-Mutex). SAS+ planning task = {X , O, sI , sG }, two actions a1 , a2
S-mutex iff either following holds:
1. exists transition , prevailing ( 6 R), rans(a1 )
rans(a2 ). Actions a1 a2 case deletes others precondition.
2. exist two transitions mutually exclusive
rans(a1 ) rans(a2 ).
named mutex SAS+ planning S-mutex distinguish P-mutex defined
STRIPS planning. show Section 4 two types mutual exclusions
equivalent. Therefore, paper general use single term mutual exclusion (mutex)
both, unless otherwise indicated.
SAS+ planning task, write apply(s, P ) denote state applying set
actions P , P O, s. set actions P applicable 1) P applicable s,
2) two actions a1 , a2 P a1 a2 S-mutex.
Definition 6 (Action Plan). SAS+ task, action plan sequence P = {P1 , . . . , PN },
Pt , [1, N ], set actions executed time step
sG apply(. . . apply(apply(sI , P1 ), P2 ) . . . PN ).
definition action plan SAS+ planning essentially STRIPS
planning (Definition 1). relation transition plan action plan key new
encoding scheme introduced paper. always exists unique transition plan valid
action plan. contrast, given transition plan, may corresponding action plan;
could multiple corresponding action plans.
Definition 7 (Step Optimal Plan). SAS+ planning task, step optimal plan action
plan P = {P1 , . . . , PN } minimum N .
worth noting different optimization metrics classical planning research, including step optimality (Definition 7), number actions total action cost.
criteria used recent IPC competitions (The 6th Intl Planning Competition, 2008; 7th Intl
Planning Competition, 2011) total action cost. step optimality widely used criterion, action cost realistic criterion many domains involving numerical
resources. Nevertheless, action cost assumes plans sequential. words,
consider concurrency actions, limitation many cases.
298

fiSAS+ P LANNING ATISFIABILITY

step optimality introduced GraphPlan (Blum & Furst, 1997), became
popular planning graph analysis used several planning systems (Kautz & Selman,
1999; Hoffmann & Nebel, 2001; & Kambhampati, 2000). Step optimality takes concurrency
actions consideration, although assumes unit duration actions.
planning methods step optimality, particular SAT-based planners, potentially made
useful optimization metrics, topic future work.

3. SAS+ Based SAT Encoding (SASE)
introduce new encoding SAS+ planning tasks, denoted SASE. use
search framework SatPlan: start small number time steps N increase N one
step satisfiable solution found. given N , encode planning task
SAT instance solved SAT solver. SASE instance includes two types binary
variables:
1. Transition variables: U,t , [1, N ], may also written Ux,f,g,t
explicitly fxg ;
2. Action variables: Ua,t , [1, N ].
constraints, SASE eight classes clauses SAS+ planning task. following,
define class every time step [1, N ] unless otherwise indicated.
A. Initial state: x, sI (x) = f ,
B. Goal: x, sG (x) = g,

W

W

f g (x) Ux,f,g,1 ;

f g (x) Ux,f,g,N ;

x
C. Progression: hf
[1, N 1], Ux,h,f,t

D. Regression: fxg [2, N ], Ux,f,g,t

W

W

fxg (x) Ux,f,g,t+1 ;

fx f (x) Ux,f ,f,t1 ;

E. Transition mutex: 1 2 1 2 transition mutex, U 1 ,t U 2 ,t ;
V
F. Composition actions: O, Ua,t rans(a) U,t ;
W
G. Action existence: \ R, U,t a,T rans(a) Ua,t ;

H. Action mutex: a1 a2 , (a1 ) (a2 ) 6 R, U a1 ,t U a2 ,t ;
Clauses classes C specify restrict transitions change time steps. Clauses
class E enforce one related transition true state variable time
step. Clauses classes F G together encode actions composed match transitions.
Clauses class H enforce mutual exclusions actions.
Note essential differences transition variables SASE fact variables
PE. terms semantics, transition variable time step n SASE equivalent
conjunction two fact variables PE, time step n n + 1, respectively. Nevertheless,
fact variables able enforce transition plan transition variables do.
299

fiH UANG , C HEN , & Z HANG

transition variables imply values multi-valued variables, also enforce
values propagate time steps.
addition, transition variables different action variables regarding roles SAT
solving. SASE, action variables exist constraints transition-action
matching, constraints time steps. Transition variables exist both. Thus
transition variables appear frequently SAT instance. inclusion high-frequency
variables help SAT solvers VSIDS rule variable branching. shall discuss
issue provide empirical study, Section 5.
show SASE works using example. Consider planning task two multivalued variables x y, Dom(x) = {f, g, h} Dom(y) = {d, e}. three



x
actions a1 = {fxg , de
}, a2 = {fxg , ed
} a3 = {gh
, ed
}. initial state
{x = f, = d} goal state {x = h, = d}. One solution instance plan two
actions: a1 time step 1 a3 time step 2.
following list constraints transitions actions, namely specified
classes F G. clauses classes self-explanatory. particular, list
variables clauses time step 1, constraints repeat time step 2.
transition variables time step 1 { Ux,f,g,1 , Ux,f,f,1 , Ux,g,h,1 , Ux,g,g,1 , Ux,h,h,1 , Uy,d,d,1 , Uy,e,e,1 ,
Uy,e,d,1 , Uy,d,e,1 }, repeat time step 2. action variables time step 1 { Ua1,1 ,
Ua2,1 , Ua3,1 }, repeat time step 2.
clauses class F are: U a1,1 Ux,f,g,1 , U a1,1 Ux,d,e,1 , U a2,1 Ux,f,g,1 , U a2,1 Uy,e,d,1 ,
U a3,1 Ux,g,h,1 U a3,1 Ux,e,d,1 . clauses class G U x,f,g,1 Ua1,1 Ua2,1 , U x,g,h,1
Ua3,1 , U y,d,e,1 Ua1,1 , U y,e,d,1 Ua2,1 Ua3,1 .


solution, terms actions, action variables Ua1,1 Ua3,2 , action variables . addition, corresponding transition plan following transition variables
: {Ux,f,g,1 , Ux,g,h,2 , Uy,d,e,1 , Uy,e,d,2 }, transition variables false.


mentioned above, although often multiple transition plans, transition plan may
correspond valid action plan. particular example, several different transition
plans satisfy initial goal states, corresponding action
plan. example, suppose transition variables {Ux,f,g,1 , Ux,g,h,2 , Uy,d,d,1 , Uy,d,d,2 } true.
qualifies transition plan, goals achieved. transition plan however
lead valid action plan.

4. Correctness SAS+ Based Encoding
important prove correctness proposed encoding. achieve proving
SASE SAS+ planning solution space PE used STRIPS planning.
specifically, show that, given planning task given time step N , SAT instance
SASE satisfiable SAT instance PE satisfiable. Here, assume
correctness PE encoding, SatPlan06 (Kautz et al., 2006) STRIPS planning.
PE(, N ) denotes PE formula corresponds N-step planning problem. SASE(, N )
gives formula case SASE encoding equivalent SAS+ problem.
300

fiSAS+ P LANNING ATISFIABILITY

4.1 Solution Structure STRIPS Based Encoding
section, study properties solutions STRIPS based encoding. properties provide key insights establishing relationship PE SASE encodings.
Lemma 1 Given STRIPS task = (F, A, , G ), time step N , PE SAT instance
PE(, N ) = (V, C), suppose satisfiable solution denoted , fact f F,
[1, N ] that: 1) (Wdumf ,t ) =, 2) (Wf,t ) = , 3) DEL(f ), (Wa,t ) =,
construct alternative solution PE(, N ) follows:


(v) =

(





, v = Wdumf ,t , v V

(v), v 6= Wdumf ,t , v V

(1)

Proof proved showing satisfies every individual clause C. See Appendix details.

Lemma 2 Given STRIPS task = (F, A, , G ), time step N , PE SAT instance
PE(, N ) = (V, C), suppose satisfiable solution denoted , fact f F,
[1, N ] that: 1) (Wf,t ) =, 2) exists action ADD(f ) (Wa,t1 ) = ,
construct alternative solution PE(, N ) follows:




(v) =

(

, v = Wf,t , v V

(v), v 6= Wf,t , v V

(2)

Proof prove showing makes every individual clause (three types) C
true. See Appendix details.

Lemmas 1 2 show certain conditions, dummy action variables fact
variables PE free variables. set either true false SAT instance
remains satisfied. Although manipulate free variables construct alternative solution given solution , refer STRIPS plan,
change action variable. leads important insight concerning solutions PE:
solution plan STRIPS planning problem may correspond multiple solutions PE(, N ).
Proposition 1 Given STRIPS task = (F, A, , G ), time step N , PE SAT instance
PE(, N ) = (V, C), clauses define competing needs mutex fact mutex inferred
clauses PE(, N ).
mutexes implied PE formula, thus completeness resolution, Proposition 1 true. Proposition 1 implies encoding STRIPS task, necessary encode
fact mutex competing needs action mutex, implied clauses. Therefore,
considering completeness correctness PE, ignore redundant clauses.
Analysis similar conclusion found literature (Sideris & Dimopoulos, 2010),
although different approaches used.
301

fiH UANG , C HEN , & Z HANG

4.2 Equivalence STRIPS SAS+ Based Encodings
classical planning problem represented STRIPS SAS+ formalisms give
rise set solutions. Given STRIPS task = (F, A, , G ) equivalent SAS+
planning task = (X , O, sI , sG ), following isomorphisms (bijective mappings) exist:
Q
f : F X Dom(X) (a binary STRIPS fact corresponds variable assignment
SAS+);
: (a STRIPS action corresponds SAS+ action);
: sI (can derived f );
g : G sG (can derived f ).
Furthermore, since formalisms represent planning task, mappings preserve
relations actions facts. example, f pre(a) f F
STRIPS formalism, f (f ) pre(a (a)) SAS+ formalism.
First, show parallelism semantics enforced S-mutex SAS+ equivalent
P-mutex STRIPS.
Lemma 3 Given SAS+ planning task = (X , O, sI , sG ) equivalent STRIPS task =
(F, A, , G ), suppose actions a, b O, equivalent actions , b (i.e.
= (a ) b = (b )), b S-mutex iff b P-mutex.
Proof prove showing directions given two actions one type
mutex, also mutux type. Details Appendix A.

Lemma 3 connects P-mutex S-mutex. Based construct relations
encodings, used proofs Theorems 1 2, respectively.
Theorem 1 Given STRIPS task SAS+ task equivalent, time step bound
N , PE(, N ) satisfiable, SASE(, N ) also satisfiable.
Proof prove theorem construction. Suppose know solution PE, prove
construct solution SASE accordingly. Details Appendix A.

Theorem 2 Given STRIPS task SAS+ task equivalent, time step bound
N , SASE(, N ) satisfiable, PE(, N ) also satisfiable.
Proof proved using technique used Theorem 1. See Appendix
details.

Theorems 1 2, reach following conclusion.
Theorem 3 classical planning problem solvable PE encoding solvable SASE encoding. Further, solvable problems, solution plans found two
encodings same, optimal makespan.
Theorem 3 reveals planning solution found SASE
found PE. terms SAT solutions, proofs show epimorphism (a surjective
mapping) solutions PE solutions SASE. is, multiple SAT solutions
302

fiSAS+ P LANNING ATISFIABILITY

PE map one SAT solution SASE every SAT solution SASE mapped least one
SAT solution PE. due existence free variables PE encoding. One solution
SASE corresponds group solutions PE assignments real action variables
different assignments free variables.

5. SAT Solving Efficiency Different Encodings
Section 4, showed PE SASE semantically equivalent solution space. section, study makes different regarding SAT solving efficiency.
particular, want understand PE SASE make SAT solver behave differently
planning task. Modern SAT solvers, nowadays employ many sophisticated
techniques, complicated characterized simple models. general, difficult
accurately estimate time SAT solver needs solve SAT instance. section,
provide explanation SAT encodings SASE efficient SAT solvers
solve SAT encodings PE, provide empirical evidence support explanation.
section, first discuss SASEs problem structure Section 5.1 reason
widely used SAT solving heuristic VSIDS (Moskewicz et al., 2001) works better SASE encodings. idea VSIDS select variables appear frequently original
learnt clauses, since lead stronger constraint propagation space pruning. order
variables VSIDS scores, large population top-ranked transition variables introduced SASE higher VSIDS scores top-ranked action variables. result,
top-ranked transition variables selected often provide stronger constraint propagation,
speeding SAT solving.
study significance transition variables, explain make search efficient. Section 5.2, present comparison transition variables versus action variables.
Section 5.3, show often transition variables chosen decision variables,
direct evidence transition variables significance.
Finally, Section 5.4 empirically define significance index transition variables.
index measures significance transition variables within context VSDIS heuristic,
correlates speedup SAT solving. analysis section uses SatPlan06
baseline.
5.1 VSIDS Heuristic SAT Solving
SAT solvers use based Conflict Driven Clause Learning framework. decision
variable refers one selected next variable branching. decision variable
chosen, variables could fixed unit propagation. ordering decision variables
significantly affects problem solving efficiency. existing complete SAT algorithms use
variants VSIDS heuristic (Moskewicz et al., 2001) variable ordering strategy.
VSIDS heuristic essentially evaluates variable using Exponential Moving Average
(EMA) number times (frequency) appears clauses. frequency value
keeps changing learnt clauses. Therefore, VSIDS uses smoothing scheme
periodically scales scores variables constant order reflect importance
recent changes frequencies. variable occurs frequently usually higher value,
thus also higher chance chosen decision variable. random decision made
tie. Thus, variables associated recent conflict clauses higher priorities.
303

fiH UANG , C HEN , & Z HANG

Figure 1: Illustration search spaces two encoding schemes differ other.
first consider frequency original clauses only. investigate taking
periodic update consideration.
Given fact frequency used main measurement, VSIDS effective
difference variables frequencies large variables high
frequencies. variables frequency, picking decision variables purely
random. Further, variables high frequencies desirable since lead stronger constraint
propagation.
major difference SAT instances PE SASE latter encoding,
actions responsible constraint propagation across time steps. Figure 1 illustrates
difference. SASE, SAT instance conceptually reduced following search problem
two hierarchies.
top level, search transition plan defined Definition 4. amounts
finding set transitions time step (corresponding U,t set
), satisfy clauses classes A-E SASE encoding.


lower level, try find action plan satisfies transition plan.
words, given transition plan satisfies clauses classes A-E, try find action
plan satisfying clauses classes F-H.
5.2 Transition Variables versus Action Variables
Let us first formulate frequency variable measured. Given SAT instance (V, C),
variable v V , define function h(v) indicate frequency v. is, h(v)
number clauses v appears in. sort variables V h values descending
order, study variables certain h value.
Definition 8 (High h Value Variable Set). Given SAT instance (V, C), h {h(v) | v
V }, denote V (h ) set variables v V h(v) h .
define percentile top variable set quantify analysis. Instead specific
h() value, use percentage h values make analysis comparable across instances.
304

fiSAS+ P LANNING ATISFIABILITY

Definition 9 (Percentile). Given SAT instance (V, C), percentile hp (0 p 100), h
value variable v V , least p% variables v V h(v ) larger
equal hp .
Definition 10 (Top p Variable Set). Given SAT instance (V, C) percentile hp , call
V (hp ) top p variable set, denoted V p .
use Vo V denote action variables transition variables V , respectively.
also define Vop = Vo V p , similarly Vp = V V p . Table 1 compares h values transition
variables action variables SAT instances. table two parts. first part, list
average standard deviation h values transition variables action variables.
data collected first satisfiable SAT instance largest solvable planning task
every domain consider. average h value, evident domains
transition variables occur frequently action variables. Furthermore, standard deviation
transition variables general larger action variables standard deviation,
also even larger expected value transition variables. high frequencies transition
variables, along large standard deviations, preferred VSIDS heuristic aid
SAT solving, discussed earlier.
second part lists average h values transition variables action variables,
top p variable set different values p: 1%, 2%, 5% 10%. difference Vop
Vp large. domains, transition variables dominate top variable sets, action
variables exist top 10% variable set domains. One exception Airport
domain. However, even domain, although average h value transition variables
smaller average h value action variables, among top 1% variables, average h value
transition variables larger average h value action variables. Since VSIDS picks
variable highest heuristic value, transition variables higher chances picked
decision variables.
5.3 Branching Frequency Transition Variables
Section 5.2, considered difference transition variables action variables,
terms h values. mentioned earlier, however, VSIDS heuristic periodically updates
heuristic values variables. dynamic updating heuristic values captured
analysis. following, present direct empirical evidence show transition
variables indeed chosen frequently action variables branching, especially early
stages SAT solving. is, SAT solver spends time deciding appropriate
transition plan. analysis takes consideration VSIDSs dynamic updating strategy.
empirically test probabilities transition variables action variables chosen
branching variables. measure every k consecutive decision variables, number
transition variables (M ) action variables (Mo ) selected decision variables. variables
selected equally likely,
E(M ) = k

|V |
|Vo |
E(Mo ) = k
,
|V | + |Vo |
|V | + |Vo |

(3)

implies:
E(M )
E(Mo )
=
k|V |
k|Vo |
305

(4)

fiH UANG , C HEN , & Z HANG

Instances

N

Airport-48
Depot-14
Driverlog-16
Elevator-16
Freecell-6
Openstacks-2
Parcprinter-20
Pathways-17
Pegsol-25
Pipe-notankage-49
Pipe-tankage-26
Rovers-18
Satellite-13
Scanalyzer-28
Sokoban-6
Storage-13
TPP-30
Transport-17
Trucks-13
Woodworking-30
Zenotravel-16

68
12
18
15
16
23
19
21
25
12
18
12
13
5
35
18
11
22
24
4
7

V
h

8.6
7.6
10.5
6.0
32.3 11.1
22.2
7.4
42.6 58.0
14.1
5.2
12.0 11.8
5.5
8.5
23.0 15.5
22.9 47.1
58.1 116.7
15.5 14.6
31.8
7.8
113.0 151.4
15.6
4.8
4.7
1.9
12.3 16.1
22.8 19.0
5.1
7.6
6.2
5.1
20.2 25.0

Vo
h

19.6 12.9
6.3 3.3
5.6 3.1
10.2 3.8
33.2 7.0
11.5 4.3
15.5 5.9
12.9 3.6
15.2 6.3
41.3 3.4
50.7 12.8
16.0 6.9
2.0 0.3
8.6 1.1
20.0 4.7
6.3 1.6
4.8 0.7
4.5 1.1
6.4 1.2
10.2 3.5
3.9 0.3

1%
98.5
32.5
43.9
27.0
115.6
17.2
44.3
33.6
30.0
77.1
266.4
175.1
35.0
242.8
16.6
10.4
84.2
99.6
56.7
23.1
51.3

h Vp
h Vop
2% 5 % 10% 1% 2% 5 %
75.5 59.2 23.4 39.6 35.9 34.7
28.6 23.7 20.9
34.6 26.5 23.4
18.9 18.9 18.9
86.0 49.0 34.7
17.2 16.2 15.2
42.8 26.7 17.8 30.0 30.0 30.0
26.9 15.9 14.5
29.8 17.2 15.5
57.5 36.4 25.3
174.0 86.8 56.0
86.0 35.5 35.5
35.0 35.0 35.0
175.8 129.7 129.7
14.1 12.8 11.2
10.4
9.0
8.1
57.8 34.4 24.6
58.1 52.0 41.6
38.2 20.8 16.3
22.1 18.9 17.2
51.3 36.2 28.5
-

10%
32.4
30.0
10.0
9.0
13.1
-

Table 1: h values transition variables versus action variables domains. Column N
optimal makespan. Column h average Column standard deviation. Column
h Vp h Vop refer average h value transition variables action variables
V p , p equals 1, 2, 5 10. - means variable percentile range.

empirically study divide SAT solving process epoches length k = 1000
each, domains IPC-3 IPC-6. present results three representative domains
Figure 2, results domains Figures 9 10 Appendix B. domain,
choose instance least 100,000 decisions. domains (e.g. Woodworking),
even biggest instance thousands decisions. case, choose instance
largest number decisions. every epoch, plot branching frequency,

Mo
k|V | transition variables k|Vo | action variables, respectively. According (4), two
branching frequencies two classes variables chosen equally
likely.
results Openstacks Zenotravel show clear distinctions transition variables
action variables. evidently different, branching frequencies Openstack
higher variance. results Storage domain show completely different pattern,
variables distinguish branching frequencies.
Figures 9 10, evident that, instances except Storage-12 Woodworking20, branching frequencies transition variables higher action variables. fact,
many cases, branching frequencies transition variables 10 times higher
action variables. Transport-26 Zenotravel-15, difference orders magnitude
larger. Hence, empirical study shows SAT solvers branch much frequently
newly introduced transition variables action variables.
306

fiSAS+ P LANNING ATISFIABILITY

0.7

0.3

0.6

0.25

0.05

0.5

Transition Vars
Action Vars

0.06

0.2

0.04

0.15

0.03

0.1

0.02

0.1

0.05

0.01

0

0

0.4
0.3

Transition Vars
Action Vars

0.2

300000

600000

(a) Openstack-5, N = 22, Unsat

Transition Vars
Action Vars

0
30000

60000

(b) Storage-12, N = 9, Satisfiable

0

50000 100000 150000 200000 250000 300000

(c) Zenotravel-15, N = 7, Satisfiable

Figure 2: Comparison variable branching frequency (with k = 1000) transition action variables
solving certain SAT instances instances three representative domains: Openstack, Storage
Zenotravel.
5.4 Transition Index SAT Solving Speedup
behavior transition variables, presented above, suggests correlation
significance transition variables speedup SASE achieves. Nevertheless, study
branching frequency profiles connection showing happens SAT solving.
Another interesting study reveal leads speedup direct way. quantify
analysis, introduce transition index.
mentioned earlier, h value exactly reflect VSIDS works, updates
dynamically throughout SAT solving. Nevertheless, putting together variables studying
h values, statistics population leads following definition transition
index.
Definition 11 (Transition Index). Given planning problems SAT instance (V, C), measure
top p(0 p 100) variable set, calculate transition index p follows:
|Vp |/|V p |
|V |/|V |
Essentially, transition index measures relative density transition variables top
variable set. distribution transition variables homogeneous total ordering
based h, |Vp |/|V p | equal |V |/|V | given p. transition index larger 1
indicates transition variables higher-than-normal density top p% variable set.
larger transition index is, often transition variables occurring top p%
variable set.
Given planning problems SAT instance, correlation transition index
speedup SASE provides. Figures 3 4 measure correlation domains
IPC-3 IPC-6. dot one figures refers individual planning instance.
y-axis speedup SASE SatPlan06. x-axis transition index given p.
Bootstrap aggregating (Breiman, 1996) used regression lines. measurement,
calculate Spearmans rank correlation coefficient (Myers & Well, 2003), assesses well
relationship two variables described using monotonic function.
repeated data values, perfect Spearmans correlation coefficient 1 occurs
variables perfect monotone function other.
307

fiH UANG , C HEN , & Z HANG

25

25

20

Speed

Speed

20

Correlation coefficient: 0.364647

15

10

Correlation coefficient: 0.379701

25

20

15

10

15

10

15

10

5

5

5

5

0
0

0
0

0
0

0
0

1

2

3

4

5

1

2

3

4

5

Correlation coefficient: 0.376107

20

Speed

Correlation coefficient: 0.36747

Speed

25

1

2

3

Transition Index

Transition Index

Transition Index

(a) p = 1

(b) p = 2

(c) p = 5

4

5

1

2

3

4

5

Transition Index

(d) p = 10

Figure 3: correlation SAT solving speedup transition index different p.
problem instances included. see clear cluster outliers bottom-left
graph, Airport Rovers domains.
instances included Figure 3 solved SatPlan06 SASE, Precosat
SAT solver. reduce noise, consider small instances SASE
SatPlan06 spend less 1 second solve. total 186 instances. speedup
instance SASEs SAT solving time divided SatPlan06s SAT solving time, greater
1 cases. observed trend larger transition index leads higher
speedup. result links significance top ranked (high frequency) transition variables
speedup SAT solving.

25

15

Speed

Speed

Correlation coefficient: 0.595048

25

20

10

Correlation coefficient: 0.596698

25

20

15

10

15

10

15

10

5

5

5

5

0

0

0

0

5
0

1

2

3

4

5



5
0

1

2

3

4



5

5
0

Correlation coefficient: 0.598874

20

Speed

Correlation coefficient: 0.594997

Speed

25

20

1

2

3

Transition Index

Transition Index

Transition Index

(a) p = 1

(b) p = 2

(c) p = 5

4

5



5
0

1

2

3

4

5

Transition Index

(d) p = 10

Figure 4: correlation SAT solving speedup transition index different p.
Instances Airport Rovers domains included.
Figure 3 cluster instances small transition indices (to bottom-left
plot Figure 3). instances distinguish much smaller transition indexes.
fact, turns instances either Airport Rovers domain
property: high number action mutual exclusions, contributing
majority clauses. hand, mutual exclusions binary constraints,
contribute significantly SAT problems hardness, trivial unit propagation.
mentioned earlier, transition index merely heuristic indicate significance transition
variables. instances, enormous number action mutual exclusion constraints makes
transition index small. However, make problems harder, two-literal clauses
trivial SAT solving. result, ignore outlier instances correlation
analysis. Figure 4 removed instances Airport Rovers domains, resulting
total 159 instances. analysis, correlation becomes even explicit.
is, however, one caveat study including instances domains.
domains thirty instances solved, domains, solve
308

fiSAS+ P LANNING ATISFIABILITY

Instances
Pipesworld-20
Storage-20
Openstack-10
Airport-20
Driverlog-15

subsumed
count
size
2548
21.72
1449
12.46
221
22.44
1024
6.45
1848
2.82

subsumed
count
size
516
53.66
249
60.22
141
23.4
604
8.49
1848
2.82

Table 2: Statistics action cliques, subsumed action cliques reduced.
count" gives number action cliques, size" average size action cliques.

five. result, study biased toward domains instances solved.
interesting future study see transition index works sophisticated experimental
setting, eliminating certain domain specific factors (Hoffmann, Gomes, & Selman, 2006).

6. Reducing Encoding Size SASE
propose several techniques reduce size SAT instances SASE. first
represent mutual exclusions SASE using compact clique representation.
develop new techniques recognize special structures SASE reduce
encoding size.
6.1 Mutual Exclusion Cliques
Mutual exclusions SASE naturally define cliques transitions actions one
true time step. two types cliques: 1) x X , (x)
clique transitions enforced class E clauses, 2) transition
prevailing, A() clique actions enforced class H clauses.
requires O(n2 ) clauses encode mutexes within clique size n pair-wise manner.
reduce number clauses used, SASE use compact representation (Rintanen, 2006),
uses (n log n) auxiliary variables (n log n) clauses. cliques large n,
reduction number clauses significant. show works, consider simple example.
Suppose clique {x, y, z} one variable true. introduce
auxiliary variables b0 b1 clauses x b0 b1 , b0 b1 z b0 b1 .
6.2 Reduction Techniques
Action variables form majority variables, also lead many clauses represent action
mutual exclusions even clique technique used. Thus, important reduce number
action variables. propose three methods certain structure SAS+ planning task
observed.
6.2.1 R EDUCING UBSUMED ACTION C LIQUES
observe many action cliques share common elements, transition cliques not.
following, discuss case one action clique subset another. Given two transitions
1 2 , A(1 ) A(2 ), say clique A(1 ) subsumed clique A(2 ).
309

fiH UANG , C HEN , & Z HANG

preprocessing, transition 1 , check A(1 ) subsumed another transition 2 action clique. so, encode action clique A(1 ). special case
A(1 ) = A(2 ) two transitions 1 2 , need encode one them.
Table 2 presents number cliques average sizes, reducing action
cliques, representative problems. reduction substantial problem domains,
except Driverlog reduction occurred. Note average sizes cliques
increased since smaller ones subsumed encoded.
6.2.2 U NARY RANSITION R EDUCTION
Given transition |T ()| = 1, say action () reducible. Since
action supporting , logically equivalent. action a, remove
Va,t replace U,t , = 1, , N . effect reduction representative
domains seen Table 3.
6.2.3 U NARY IFFERENCE ET R EDUCTION
Besides unary transition variables, action variable may also eliminated two transition variables. frequent pattern following: given transition , actions A(),
transition sets differ one transition.

Definition 12 Given transition , let = aA() rans(a). every A(),
|T rans(a) \ I| = 1, call action set A() unary difference set.
Consider transition 1 A(1 ) = {a1 , a2 , . . . , }. A(1 ) unary difference set,
transition sets must following form:
rans(a1 ) = {1 , 2 , . . . , k , 1 }
rans(a2 ) = {1 , 2 , . . . , k , 2 }
..
.
rans(an ) = {1 , 2 , . . . , k , n }
case, eliminate action variables a1 , , introducing following
clauses. i, = 1, , n, replace Vai ,t U1 ,t Ui ,t , = 1, , N .
case, action variables eliminated represented two transition variables.
reason reduction done n actions least one action clique.
mutual exclusions actions maintain correctness one shared
transitions reduced.
Table 3 shows number reducible actions several representative problems. Zenotravel,
action variables eliminated two reduction methods used. Openstack
Storage, one type reduction applied.
310

fiSAS+ P LANNING ATISFIABILITY

Instances
Zeno-15
Pathway-15
Trucks-15
Openstack-10
Storage-10

|O|
9420
1174
3168
1660
846

R1
1800
173
36
0
540

R2
7620
810
300
400
0

%
100.00
83.73
10.61
24.10
63.83

Table 3: Number reducible actions representative instances. Columns R1 R2 give
number action variables reduced, unary transition reduction unary difference set reduction,
respectively. Column % percentage actions reduced methods combined.

7. Experimental Analysis Results
experimentally analyzed performance planning using SASE comparison many
state-of-the-art planners. tested problem instances STRIPS domains IPC-3 IPC-6.
PSR Philosophers included derived facts, cannot handled
correctly planners tested. used parser Fast-Downward (Helmert, 2006,
2008) generate SAS+ formalism STRIPS inputs. preprocessing encoding parts
SASE implemented Python2.6. instances based grounded STRIPS.
nearly cases, problem solving took much longer time pre-processing, thus
reported overall running time.
ran experiments PC workstation 2.3 GHz AMD Quad-Core Opteron processor. running time instance set 1800 seconds, memory limited
4GB. planners, running time included parsing, preprocessing problem solving.
memory consumption peak memory usage reported SAT solvers.
7.1 Comparison Results
Precosat (build236) (Biere, 2009), winner application track SAT09 competition,
used SAT solver planners tested compared. Besides Precosat,
also used CryptoMinisat (Soos, Nohl, & Castelluccia, 2009), winner SAT Race 2010,
underlying solver SatPlan06 SASE. nine planners considered listed follows.
1. SP06 SP06-Crypto. original SatPlan06 planner (Kautz et al., 2006),
underlying SAT solver changed Precosat CryptoMinisat, respectively.
2. SASE SASE-Crypto. SASE encoding introduced paper,
optimization methods turned on. underlying SAT solvers Precosat CryptoMinisat,
respectively.
3. SP06L. SatPlan06 (Kautz et al., 2006) long-distance mutual exclusion (londex) (Chen
et al., 2009). compared londex since also derives transition information
SAS+ formalism. used domain transition graphs Fast-Downwards parser derive
londex information.
4. SP06C. SatPlan06 clique technique (Rintanen, 2006) represent mutual
exclusions. clique information obtained via Fast-Downward. Note due
311

fiH UANG , C HEN , & Z HANG

Number Instances Solved

400

450

SatPlan06
nplan
SplitE
SASE
LM-cut

400
Number Instances Solved

450

350

300

250

350

300

SatPlan06
nplan
SplitE
SASE
LM-cut

250

200

200
600

1200

1800

500

1000

Running Time (seconds)

1500

2000

2500

3000

3500

4000

Memory Usage (Megabytes)

420

420

400

400
Number Instances Solved

Number Instances Solved

Figure 5: results different planners. include default version every planner.
figures show number problems solved planner, increasing limits running time
memory consumption.

380
360
340
320
300
280

SatPlan06
SP06L
SP06C
SASE
SP06-Crypto
SASE-Crypto
600
1200
Running Time (seconds)

380
360
340
320
SatPlan06
SP06L
SP06C
SASE
SP06-Crypto
SASE-Crypto

300
280
1800

500

1000

1500
2000
2500
3000
Memory Usage (Megabytes)

3500

4000

Figure 6: results variants SatPlan06 SASE. data presented number
problems solved planner, increasing limits running time memory consumption.
different grounding strategies SatPlan06 Fast-Downward, mutual exclusions defined SatPlan06 could covered cliques.
5. nplan. nplan solver (Rintanen et al., 2006) set use -step generate plans
optimality metric planners. executable recent release
nplans homepage. build-in SAT solver changed Precosat.
6. SplitE. split encoding (Robinson et al., 2009) using Precosat. obtained
source code authors recompiled 64bit Linux workstation.
7. LM-cut. sequential optimal planner, using LM-Cut heuristic (Helmert & Domshlak,
2009) A* search. used implementation Fast-Downward.
present results two sets planners, Figures 5 6, respectively. sets
data, show number instances solvable testing domains, respect
given time limit memory limit.
Figure 5 compares results several different solvers using original version. data
suggests SASE clear advantages. LM-cut least efficient, although comparison
312

fiSAS+ P LANNING ATISFIABILITY

420
Number Instances Solved

Number Instances Solved

420

400

380

360
SatPlan06
SP06L
SP06C
nplan
SplitE
SASE

340

320
0

200000

400000

600000

800000

1e+06

400

380

360
SatPlan06
SP06L
SP06C
nplan
SplitE
SASE

340

320

1.2e+06 1.4e+06

Number Variables

0

5e+06 1e+07 1.5e+07 2e+07 2.5e+07 3e+07 3.5e+07 4e+07 4.5e+07
Number Clauses

Figure 7: Number problems solved planner, increasing limits number variables number clauses.
meaningful uses optimization metric different planners. running time
memory consumption, SASE clearly superior planners. Among planners,
nplan slightly better others smaller instances, larger instances, SatPlan06
becomes competitive.
Figure 6, compare results different variants SatPlan06 SASE.
SP06L SP06C extend SatPlan06 additional techniques. general make little improvements original SatPlan06.
SAT based planners, present Figure 7 number instances solvable
increasing limits number variables number clauses. Note curves slightly
affected given time memory limit, thus efficient planners like SASE stops smaller
number clauses. results show SASE advantage terms number variables
number clauses planners.
Table 4 presents number instances solved planning domain, within given
time memory limit. general, SASE solved instances planners. Due
programming bugs, nplan could find correct solutions optimal makespan
domains Openstacks, Rovers Storage. SplitE parser could handle problems Airport
Pathways. Therefore, evaluate corresponding encoding benchmarks.
Although LM-Cut overall solved fewer instances, domains performed better
SAT based planners. domains seemed allow less concurrencies action.
particular, domains Openstacks Sokoban plans strictly sequential, meaning
actions executed time step. plans instances
often require time steps, making challenging SAT-based planners.
SP06L SP06C used Fast-Downwards parser obtain domain transition graph information. Therefore, SP06C SP06L, took much time pre-process grounded STRIPS
instances twice (one Fast-Downward one original SP06). consequence, efficiency
londex clique representation may compensate pre-processing time, leading slightly
worse performance original SP06 instances. example, londex helpful
TPP, Trucks Scanalyzer. clique representation helpful Airport
domain, 10 instances solved, help much Pegsol Satellite.
313

fiH UANG , C HEN , & Z HANG

Domain
Airport
Depot
Driverlog
Elevator
Freecell
Openstacks
Parcprinter
Pathways
Pegsol
Pipe-notankage
Pipe-tankage
Rovers
Satellite
Scanalyzer
Sokoban
Storage
TPP
Transport
Trucks
Woodworking
Zenotravel
Total

SP06 SP06L SP06C nplan SplitE SASE
35
38
39
20
0
46
17
16
16
19
17
17
16
16
16
17
17
17
30
30
30
30
30
30
5
4
5
6
5
6
5
5
5
0
5
5
29
29
29
30
29
30
11
11
11
12
0
12
21
21
21
21
22
24
38
37
31
40
37
37
16
16
16
22
10
26
13
13
13
0
18
14
17
17
17
18
16
18
15
14
14
18
13
18
5
5
3
11
5
5
15
15
15
0
16
15
27
30
29
28
25
30
19
16
19
22
18
22
7
6
5
10
8
8
30
30
30
30
30
30
15
15
15
15
15
16
386
384
379
369
336
426

SP06c SASEc SASE0
38
42
39
17
15
14
17
17
16
30
30
30
4
6
6
5
5
5
29
30
30
9
10
12
18
19
22
38
35
38
13
23
16
13
17
16
17
17
15
16
17
17
5
5
5
15
15
15
28
29
29
19
21
20
7
8
7
30
30
30
16
16
16
384
407
398

LM
27
7
13
19
5
20
21
5
27
17
11
7
7
7
24
15
6
12
10
16
12
288

Table 4: Number instances solved domain within 1800 seconds. SP06c , SASEc
LM short SP06-Crypto, SASE-Crypto LM-Cut. Column SASE0 result SASE
without reduction optimization.
Comparing nplan, general SASE better, nplan performed better SASE
domains concurrencies. example, Sokoban Trucks one
action nearly every time step. believe reason way nplan encodes mutual
exclusions linear encoding (Rintanen et al., 2006), could used improve SASE.
SplitE general slightly worse SP06. SP06 5 domains SP06
superior SplitE 6 domains. Overall, SplitE competitive nplan SASE. Rovers
however domain SplitE performed better others. Although CryptoMinisat performed better Precosat SAT Race 2010, good planning problems.
SASE SP06, CryptoMinisat solved fewer instances.
7.2 Ablation Study
Figure 8 shows number solvable problems problems IPC-3 IPC-6, increasing limits running time, memory consumption, number variables number clauses.
Precosat used planners. Running time total time including preprocessing
problem solving. Memory usage based status report Precosat. maximum
CPU time (1800s) memory limit (4Gb), clique representation reduction techniques used, SASE solved 398 instances. turning either clique representation
action reduction technique, SASE solved 416 405 instances, respectively. clique
action reduction techniques turned on, SASE solves 426 instances.
314

fi440

420

420

400
380
360
340
clique=on, reduction=on
clique=on, reduction=off
clique=off, reduction=on
clique=off, reduction=off

320
300
10

Number Instances Solved

Number Instances Solved

440

600
1200
Running Time (seconds)

400
380
360
340

300
1800

500

440

440

420

420

400
380
360
340
clique=on, reduction=on
clique=on, reduction=off
clique=off, reduction=on
clique=off, reduction=off

320
300
500000

1e+06

1.5e+06

clique=on, reduction=on
clique=on, reduction=off
clique=off, reduction=on
clique=off, reduction=off

320

Number Instances Solved

Number Instances Solved

SAS+ P LANNING ATISFIABILITY

2e+06

3500

4000

380
360
340
clique=on, reduction=on
clique=on, reduction=off
clique=off, reduction=on
clique=off, reduction=off

300

Number Variables

1500 2000 2500 3000
Memory Usage (Megabytes)

400

320

2.5e+06

1000

0

5e+06 1e+071.5e+072e+072.5e+073e+073.5e+074e+074.5e+07
Number Clauses

Figure 8: results SASE clique reduction methods turned off.
reduction method improved upon problem solving time, well clique representation.
clique representation provided substantial improvement memory consumption, followed
action reduction. numbers clauses, clique technique gave significant reduction. Finally,
techniques helped reduce number variables.

8. Conclusions Future Research
paper, developed novel SAS+ based SAT encoding scheme SASE, showed
improves efficiency STRIPS based SAT encodings terms time memory.
compared state-of-the-art SAT based planners, SASE clear advantages shown
experimental analysis. proved correctness SASE encoding showing
isomorphism solution plans SASE solution plans SatPlan06.
analyzed search space structure SASE, explained efficient. Below,
briefly discuss related work highlight several directions future research.
8.1 Semantics Encodings
Many enhancements developed SAT based planning since introduced (Kautz
& Selman, 1992). split action representation (Kautz & Selman, 1992; Ernst et al., 1997) uses
conjunction multiple variables represent action. optimality is, however, lost. Robinson
et al. (2009) propose new way splitting without sacrificing optimality. results
315

fiH UANG , C HEN , & Z HANG

show method advantages SatPlan06 (Kautz et al., 2006). many published
works thorough analysis, improvements along line research SatPlan family encodings. particular, power mutual exclusion, context planning SAT, attracted
interests (Chen et al., 2009; Sideris & Dimopoulos, 2010). new encoding scheme called SMP
proposed, preserves merits londex shows certain advantages existing
encoding schemes (Sideris & Dimopoulos, 2010).
planner family SatPlan variants step-optimal. step-optimality semantics,
along relaxed parallel semantics, formalized -step -step, respectively (Dimopoulos, Nebel, & Koehler, 1997; Rintanen et al., 2006). -step enforces weaker mutual exclusions
-step, thus may lead reduced running time due fewer calls SAT solver. trade-off,
loses optimality time steps. semantics SatPlan06 SASE -step.
research various kinds semantics orthogonal contribution SASE, idea
SASE migrated new semantics.
Since SAT based planning also applied sequential planning, idea SASE
also extended field. first planner kind MEDIC (Ernst et al., 1997),
extends idea splitted action representation. study shows sequential planning,
splitting yields competitive planners. also proposed utilize advantages
sequential parallel planning (Bttner & Rintanen, 2005).
8.2 Additional Techniques Planning SAT
tremendous amount two-literal clauses (such mutual exclusion clauses case
planning) key challenge approaches based satisfiability tests. proposed mitigate burden encoding recognizing certain structures (Brafman, 2001). traditional
SAT planning systems like SatPlan06, mutual exclusions encoded quadratic manner.
Rintanen proposes log size technique (Rintanen, 2006), called clique representation, mutual exclusion constraints, later linear size one (Rintanen et al., 2006). mutual exclusions
SASE represented clique representation. log size clique representation
supposed less compact linear encoding. results, however, shown
SASE general compact. mainly due compactness SAS+ formalism.
certainly open question whether linear size encoding technique adopted
improve SASE.
also techniques beyond encoding boost SAT-based planning. Rintanen introduces
incorporate symmetry information SAT instances (Rintanen, 2003). MaxPlan (Xing,
Chen, & Zhang, 2006) planning graph analysis find upper bound optimal make
span SAT queries using decreasing time steps, meets unsatisfiable SAT
instance. lemma reusing method proposed (Nabeshima, Soh, Inoue, & Iwanuma, 2006) reuse
learnt clauses across multiple SAT solvings. multiple-step query strategy introduced (Ray &
Ginsberg, 2008), however asks modified SAT procedures. boosting methods
proposed context STRIPS based planning. interesting incorporate techniques
SASE study improve performance.
8.3 Understanding Structure General SAT Instances
SAT intrinsically hard. performance modern SAT solvers improves constantly. therefore interesting important understand SAT solvers work well certain instances,
316

fiSAS+ P LANNING ATISFIABILITY

furthermore, makes SAT instance easy hard. much prior research tries obtain understanding, including backdoor set (Williams, Gomes, & Selman, 2003) backbone (Monasson, Zecchina, Kirkpatrick, Selman, & Troyansky, 1999; Zhang, Rangan, & Looks,
2003; Zhang, 2004). Backdoor set variables set variables, variables
assigned, variables assignments derived polynomial time. Backbone variables
variables assignment valid solutions, exploited improve SAT solving efficiency. recent study context planning reveals
clear correlations SAT solving efficiency goal asymmetry (Hoffmann et al.,
2006).
interesting see connections SASEs problem structure
theories above. example, improvement SASE lead smaller
backdoor set? Second, shown efficiency SASE result transition variables
significance, strong correlation speedup SASE transition
index. interesting investigate similar variable set predictive index automatically
found general SAT solving.
Finally, given efficiency SASE, promising apply SAT-based planning
approaches, complex planning preferences (Giunchiglia & Maratea, 2007)
temporal features (Huang et al., 2009).

9. Acknowledgments
research supported National Science Foundation United States grants
NeTS-1017701, DBI-0743797, IIS-0713109, Microsoft Research New Faculty Fellowship.
thank Joerg Hoffmann, Jussi Rintanen several anonymous reviewers helpful comments. particularly thank Malte Helmert making SAS+ parser available. also thank
computing resource supports engineering group Washington University St.
Louis.

Appendix A. Proofs
Lemma 1 Given STRIPS task = (F, A, , G ), time step N , PE SAT instance
PE(, N ) = (V, C), suppose satisfiable solution denoted , fact f F,
[1, N ] that: 1) (Wdumf ,t ) =, 2) (Wf,t ) = , 3) DEL(f ), (Wa,t ) =,
construct alternative solution PE(, N ) follows:


(v) =

(





, v = Wdumf ,t , v V

(v), v 6= Wdumf ,t , v V

(5)

Proof show satisfies every clause C does. Since variables Wdumf ,t
keep value, need examine clauses Wdumf ,t them. According
definition PE, Wdumf ,t may exist three types clauses:
1. Clauses add effects. case, clauses form Wf,t+1 (Wdumf ,t
Wa1 ,t Wam ,t ), equivalent W f,t+1 Wdumf ,t Wa1 ,t Wam ,t . Since
(Wdumf ,t ) = , clauses still true.


317

fiH UANG , C HEN , & Z HANG

2. Clauses preconditions. case, clauses form Wdumf ,t Wf,t ,
equivalent Wdumf ,t Wf,t . Since (Wf,t ) = , clauses remain true .


3. Clauses mutual exclusion actions. Without loss generality, let us denote
clause Wdumf ,t Wa,t . given f , actions clauses mutex dumf ,
f delete effect. According construction, since (Wa,t ) = (Wa,t ) =,
clauses true.
three cases conclude clauses include Wdumf ,t satisfied . Therefore, also solution PE.

Lemma 2 Given STRIPS task = (F, A, , G ), time step N , PE SAT instance
PE(, N ) = (V, C), suppose satisfiable solution denoted , fact f F,
[1, N ] that: 1) (Wf,t ) =, 2) exists action ADD(f ) (Wa,t1 ) = ,
construct alternative solution PE(, N ) follows:




(v) =

(

, v = Wf,t , v V

(6)

(v), v 6= Wf,t , v V

Proof show makes clause C true. Since variables Wf,t keep
value, need look clauses Wf,t them. According
definition PE, Wf,t may exist three types clauses.
1. Clauses add effects. case, f add effect multiple actions. Let us write
clauses Wf,t (Wa1 ,t1 Wa2 ,t1 Wam ,t1 ), Wf,t Wa1 ,t1 Wa2 ,t1
Wam ,t1 . Since exists action ADD(f ) (Wa,t1 ) = , clause
still true .


2. Clauses preconditions. case, f precondition action b. clause
written Wb,t Wf,t , equivalent Wb,t Wf,t . Since (Wf,t ) = , clause
still true.


3. Clauses fact mutex. Without loss generality, consider fact g mutex f .
corresponding clause Wf,t Wg,t . Since (Wf,t ) = , clause true
(Wg,t ) =.




suppose (Wg,t ) = show leads contradiction. According clauses
class III, must variable Wb,t1 , g add(b) (Wb,t1 ) = .
According definition mutex, two facts mutex every pair actions
add mutex. Thus, Wa,t1 Wb,t1 mutex. Therefore, (Wa,t1 ) =
(Wb,t1 ) = , leading contradiction. result, (Wg,t ) =, consequently
clause satisfied.








three cases conclude clauses include Wf,t satisfied . Therefore,
also solution PE.

318

fiSAS+ P LANNING ATISFIABILITY

Lemma 3 Given SAS+ planning task = (X , O, sI , sG ) equivalent STRIPS task =
(F, A, , G ), suppose actions a, b O, equivalent actions , b (i.e.
= (a ) b = (b )), b S-mutex iff b P-mutex.
Proof construct proof studying directions. Based Proposition 1,
consider inconsistent effects interference mutex P-mutex.
: b P-mutex , b S-mutex .
Since b P-mutex, one either deletes precondition add-effect other. Without
loss generality, suppose deletes f (i.e. f del(a ) pre(b )). Consequently, must
transition 1 = fxh (a) f 6= h 2 = fxg (b). two cases
considered.
1) 1 6= 2 . 1 2 mutex transitions Definition 3, since change value
f . Therefore, b S-mutex, according second condition Definition 5.
2) 1 = 2 . case, b S-mutex first condition Definition 5.
Based two cases, conclude b S-mutex. similar argument applies
case one action deletes others add-effect.
: b S-mutex , b P-mutex .
two actions b S-mutex , two cases.
1) exists transition , (a) (b). Consequently, b deletes
others precondition thus P-mutex.
2) exist two distinct transitions 1 (a), 2 (b) multi-valued variable x X ,
{1 , 2 } (x). Let us denote two transitions vx1 v2 vx3 v4 . case,
suppose vx1 v2 vx3 v4 allowed executed parallel STRIPS plan. obviously
leads contradiction, since v1 , v2 , v3 , v4 Dom(x) values multi-valued variable,
definition SAS+ formalism, one true time. Therefore,
preconditions b must mutex, hence b P-mutex.


Theorem 1 Given STRIPS task SAS+ task equivalent, time step bound
N , PE(, N ) satisfiable, SASE(, N ) also satisfiable.
Proof Since PE(, N ) satisfiable, denote one solutions . first present
construct assignment SASE(, N ) . Next, prove constructed assignment
satisfies every clause SASE(, N ).
Construction. two steps construction. According Lemmas 1 2,
general free variables . first step, construct alternative solution
PE(, N ) changing free variables true according Lemmas 1 2. Let us
denote resulting solution . Then, construct assignment SASE(, N ) .
value variable defined follows.
1. every (which also A)1 , let Ua,t = Wa,t .


Wg,t+1 =



1. simplicity, use denote action instead using (a).

319

, set Ux,f,g,t =



2. every transition f g , Wf,t =
.



fiH UANG , C HEN , & Z HANG

Satisfiability. prove every individual clause SASE satisfied . eight
types clauses.
1. (Forward progression). According construction, need show that,
[1, N 2],
_
x
(Wf,t+1 Wg,t+2 )
(7)
hf
, (Wh,t Wf,t+1 )
g,fxg



(Wf,t+1 ) =, (7) satisfied . (Wf,t+1 ) = , consider action
set = {dumf } DEL(f ), subset rans(fxg ). two possibilities.
every action , (Wa,t+1 ) =. case, Wdumf ,t+1 Wf,t+2
free variables according Lemmas 1 2, respectively. Therefore, according
construction , assigns free variables true, variables Wf,t+1 , Wf,t+2
Wdumf ,t+1 . addition, f f always , meaning Wf,t+2 included
right hand side (7). Therefore, (7) satisfied .




exists action , (Wa,t+1 ) = . case, let us
consider arbitrary fact g add(a). (Wg,t+2 ) = , (7) satisfied .
Otherwise, according Lemma 2, Wg,t+2 free variable Wg,t+2 already set
true construction . Therefore, satisfies (7).


2. (Regression). According construction, need show that, [2, N 1],
_
(Wh,t1 Wf,t )
(8)
fxg , (Wf,t Wg,t+1 )
x
h,hf
(x)

Consider clauses class III (add effect) PE. clauses indicate fact
f F, Wf,t implies disjunction Wa,t1 actions f add(a). Thus,
given f , following clauses included PE, satisfied :
_

Wf,t

Wa,t1 .

(9)

aADD(f )

given f , consider action set



h A(hf ),

Wf,t

_

denoted Z. Since ADD(f ) Z,

Wa,t1

(10)

aZ
x
x
transition hf
, action A(hf
), since h pre(a), satisfies
Wa,t1 Wh,t1 . Therefore, h pre(a),
_
Wa,t1 Wh,t1 .
(11)
x
aA(hf
)

expanding set Z, convert (10) to:
320

fiSAS+ P LANNING ATISFIABILITY

_

Wf,t

_

(

x
h,hf


Wa,t1 ).

(12)

x
aA(hf
)

combining (11) (12), have:
_

Wf,t

Wh,t1 ,

(13)

(Wh,t1 Wf,t ).

(14)

x
h,hf


implies
_

Wf,t

x
h,hf


(14), see clauses regression (8) true.
3. (Initial state). need show variable x X sI (x) = f :
_
Uf,g,1

(15)

g,f g

According construction, (15) becomes:
_

(Wf,1 Wg,2 ),

g,f g

equivalent to:
_

Wf,1 (

Wg,2 )

(16)

g,f g (x)



Since f initial state, (Wf,1 ) = (Wf,1 ) = . Therefore first part
conjunction (16) true. rest part (16) seen true following similar
argument progression case.
4. (Goal). goal clauses shown similar way initial state clauses.
5. V
(Composition actions). clauses
V want prove are, action a, Ua,t
U
,

equivalently,
U

a,t
rans(a) ,t
rans(a) U,t .
Suppose rans(a) = {f1 g1 , f2 g2 , . . . , fm gm }. clause need show becomes:
(Wa,t Wf1 ,t ) (Wa,t Wg1 ,t ) (Wa,t Wf2 ,t ) (Wa,t Wg2 ,t ) . . .
(Wa,t Wfm ,t ) (Wa,t Wgm ,t )

(17)

Let us call two-literal disjunctions (17) sub-clauses. Wa,t Wfi ,t subclauses (17) exactly precondition clause (class IV) PE.
Wa,t Wfi ,t (17) satisfied.
Next, let us consider Wa,t Wgi ,t sub-clauses. g = gi , = 1, , m.
four cases Wa,t Wg,t assigned different values:
321

fiH UANG , C HEN , & Z HANG

(Wa,t =, Wg,t =): Wa,t Wg,t satisfied.


, Wg,t =

): Wa,t Wg,t satisfied.



(Wa,t =



(Wa,t =, Wg,t =

): Wa,t Wg,t satisfied.



(Wa,t = , Wg,t =): According Lemma 2, Wg,t free variable. Therefore, since
(Wg,t ) = , Wa,t Wg,t satisfied , hence satisfied .


6. (Transition mutex). Consider mutex clause two regular transitions 1 = f g
2 = f g . Let f g rans(a) f g rans(b), see b
S-mutex. According Lemma 3, b also P-mutex PE. Therefore,
Wa,t Wb,t .
Vb,t . Then, since composition
V construction, know Ua,t U
actions, Ua,t rans(a) U,t Ub,t rans(b) U,t . simple resolution
clauses yields U1 ,t U2 ,t , equals transition mutex clause U1 ,t U2 ,t .
Therefore, transition mutex clause true . similar argument applies
transitions prevailing mechanical.
W
7. (Action existence). clauses want prove U,t rans(a) Ua,t ,
transitions . construction, clauses become
_
Wa,t .
(18)
Wf,t Wg,t+1
aA(f g )


Let = f g . First, know definition h A(hg ) = ADD(g). Let us denote
ADD(g) Z. According clauses class III PE, clauses:
_
Wa,t .
(19)
Wg,t
aZ

divide Z multiple action sets according different fact {f, h1 , . . . , hm }, denoted Zf , Zh1 , , Zhm . fact, h {f, h1 , . . . , hm }, Zh equivalent
A(hg ). Consider hi , = 1, , m. According clauses class IV, every
action PRE(h), clause Wa,t Whi ,t ,
Wa,t Whi ,t .

(20)

Next, perform resolutions using (19) clauses (20), hi
corresponding actions. consequently have:
Wg,t (Wh1 ,t Wh2 ,t Whm ,t )

_

Wa,t .

(21)

aZf

Further, note h1 , h2 , . . . , fm mutex f , resolution using mutex clauses
PEresults in:
(21), Wh1 ,t Wf,t , Wh2 ,t Wf,t , . . . , Whm ,t Wf,t
W
Wg,t (Wf,t Wf,t Wf,t ) aZf Wa,t

Since Zf = A(f g ), outcome (22) leads (18).
322

(22)

fiSAS+ P LANNING ATISFIABILITY

8. (Action mutex). Action mutex clauses satisfied according Lemma 3.
Combining cases concludes constructed solution satisfies clauses
SASE means SASE satisfiable. Since action a, (Wa,t ) = (Wa,t ) = (Ua,t ),
represent solution plan.


Theorem 2 Given STRIPS task SAS+ task equivalent, time step bound
N , SASE(, N ) satisfiable, PE(, N ) also satisfiable.
Proof Assuming satisfiable solution SASE(, N ), first construct assignment
, show satisfies every clause PE(, N ).
Construction. construct solution follows:
1. every (which also O), let Wa,t = Ua,t ;
2. every dummy action variable dumf , let Wdumf ,t = Uf f ,t ;
, set Wf,t = Wg,t+1 =





3. every transition f g , Ux,f,g,t =

;

4. fact f , Uh,f,t = every transition hf (which implies case 3
assign value f ), set Wf,t .
Satisfiability. Next, prove every clause PE satisfied . clauses initial
goal states obviously satisfied. consider add-effect clauses. clauses
want prove are, every fact f :
Wf,t

_

Wa,t1

(23)

aADD(f )

given fact f , consider facts h 6= f , hf . h,
two cases:


x
exists fact h hf
Ux,h,f,t1 = . satisfiable SASE
instance, action existence clauses class F specify truth non-prevailing
transition indicates disjunction actions A(). Since Ux,h,f,t1 = , follows
x
SASE instance action A(hf
) Ua,t1 = . Then,
construction , see Wh,t1 Wf,t true. Since Wf,t Wa,t1 ,
ADD(f ), true, (23) satisfied .




x
every fact h hf
, Ux,h,f,t1 = , then, according construction,
Wf,t = . Thus, satisfies (23).

two cases conclude satisfies add effect clauses. Next, show
satisfies precondition clauses, Wa,t Wf,t (i.e. Wa,t Wf,t ), actions facts
f pre(a). SASE, clauses class F, Ua,t U,t , actions
x , U
rans(a). Let transition f,g
a,t (Uf,t1 Ug,t1 ), implies
Ua,t Uf,t1 . construction, know Wa,t Wf,t1 true.
Finally, mutex clauses satisfied according Lemma 3. Combining cases
concludes constructed solution satisfies clauses PE means PE satisfiable.

323

fiH UANG , C HEN , & Z HANG

Appendix B. Branching Frequency Domains

0.006

0.06

Transition Vars
Action Vars

0.03

Transition Vars
Action Vars

0.005

0.05

0.025

0.004

0.04

0.02

0.003

0.03

0.015

0.002

0.02

0.01

0.001

0.01

0.005

0

0
0

40000

80000

120000

160000

(a) Airport-44, N = 68, Satisfiable
0.2
0.18

Transition Vars
Action Vars

0
0

50000 100000150000200000250000300000350000

0

10000 20000 30000 40000 50000 60000 70000

(b) Depot-8, N = 14, Satisfiable

(c) Driverlog-16, N = 14, Unsat

0.14

0.045

Transition Vars
Action Vars

0.12

0.16

Transition Vars
Action Vars

0.04
0.035

0.1

0.14
0.12
Transition Vars
Action Vars

0.1

0.03

0.08

0.08

0.06

0.06

0.04

0.025
0.02
0.015
0.01

0.04
0.02

0.02
0

0.005

0
5000

10000

15000

(d) Elevator-30, N = 10, Satisfiable
0.07

Transition Vars
Action Vars

0.06

0
0

5000 10000 15000 20000 25000 30000 35000

(e) Freecell-4, N = 12, Unsat
0.2

Transition Vars
Action Vars

0.18
0.16

0

0.04

0.12
0.1

0.02

0.03

0.08

0.015

0.02

0.06

0.01

0
6000

8000 10000 12000 14000

(g) Pathways-15, N = 18, Satisfiable

3000

0.005

0.02
4000

2500

0.025

0.04

2000

2000

0.03

0.14

0

1500

Transition Vars
Action Vars

0.035

0.04

0

1000

(f) Parcprinter-29, N = 23, Satisfiable

0.05

0.01

500

0
200000

600000

1e+06

(h) Pegsol-18, N = 20, Unsat

0

20000 40000 60000 80000 100000120000140000

(i) Pipe-notankage-29, N = 14, Satisfiable

Figure 9: Comparison variable branching frequency (with k = 1000) transition action variables
solving certain SAT instances twelve benchmark domains encoded SASE. figure corresponds
individual run MiniSAT. x axis corresponds decision epochs SAT solving.
axis denotes branching frequency (defined text) epoch k = 1000.

324

fiSAS+ P LANNING ATISFIABILITY

0.09

0.18

Transition Vars
Action Vars

0.08
0.07

0.14

0.06

0.12

0.05

0.1

0.04

0.08

0.03

0.06

0.02

0.04

0.01

0.02

0

0.025

Transition Vars
Action Vars

0.16

0.015
0.01
0.005

0
0

10000 20000 30000 40000 50000 60000 70000

(a) Pipe-tankage-21, N = 13, Unsat
0.14

0
0

2000 4000 6000 8000 10000 12000 14000 16000

(b) Rovers-15, N = 12, Satisfiable
0.25

Transition Vars
Action Vars

0.12

Transition Vars
Action Vars

0.02

0

0.02

Transition Vars
Action Vars

Transition Vars
Action Vars

0.018

0.2

50000 100000 150000 200000 250000 300000

(c) Satellite-12, N = 13, Unsat

0.016

0.1

0.014

0.08

0.15

0.012

0.06

0.1

0.008

0.01
0.006

0.04
0.05

0.004

0.02

0.002

0

0
100000

200000

300000

0

400000

(d) Scanalyzer-27, N = 12, Satisfiable

300000

0.16
0.14

0.05
Transition Vars
Action Vars

0.06
0.04

0.12

0.04

0.1

0.03

0.08
0.06

0.02
0.02

0.04

0.01

0

0.02

0
50000

100000

150000

(g) Transport-26, N = 12, Satisfiable

Transition Vars
Action Vars

0.18

0.06
0.08

5000 10000 15000 20000 25000 30000 35000 40000

(f) TPP-26, N = 10, Unsat
0.2

Transition Vars
Action Vars

0.07

0.1

0

(e) Sokoban-6, N = 33, Unsat
0.08

0.12

600000

0
100000

200000

300000

400000

(h) Trucks-7, N = 17, Unsat

0

500 1000 1500 2000 2500 3000 3500 4000 4500

(i) Woodworking-20, N = 4, Sat

Figure 10: Comparison variable branching frequency (with k = 1000) transition action variables
solving certain SAT instances nine benchmark domains encoded SASE.

References
Bckstrm, C., & Nebel, B. (1996). Complexity results SAS+ planning. Computational Intelligence, 11, 625655.
Biere, A. (2009). Pr{e,i}coSAT@SC09. SAT09 Competition.
Blum, A., & Furst, M. (1997). Fast Planning Planning Graph Analysis. Artificial Intelligence, 90, 16361642.
Brafman, R. I. (2001). simplifier propositional formulas many binary clauses. Proceedings International Joint Conference Artificial Intelligence.
Breiman, L. (1996). Bagging predictors. Machine Learning, 24, 123140.
325

fiH UANG , C HEN , & Z HANG

Bttner, M., & Rintanen, J. (2005). Satisfiability Planning Constraints Number
Actions. Proceedings International Conference Automated Planning Scheduling.
Castellini, C., Giunchiglia, E., & Tacchella, A. (2003). SAT-based planning complex domains:Concurrency, constraints nondeterminism. Artificial Intelligence, 147, 85117.
Chen, Y., Huang, R., Xing, Z., & Zhang, W. (2009). Long-distance mutual exclusion planning.
Artificial Intelligence, 173, 197412.
Chen, Y., Huang, R., & Zhang, W. (2008). Fast Planning Search Domain Transition Graphs.
Proceedings AAAI Conference Artificial Intelligence.
Dimopoulos, Y., Nebel, B., & Koehler, J. (1997). Encoding planning problems nonmonotonic
logic programs. Proceeding Fourth European Conference Planning, pp. 169
181. Springer-Verlag.
Do, B., & Kambhampati, S. (2000). Solving Planning Graph Compiling CSP.
Proceedings International Conference Automated Planning Scheduling.
Ernst, M., Millstein, T., & Weld, D. (1997). Automatic SAT-compilation planning problems.
Proceedings International Joint Conference Artificial Intelligence.
Giunchiglia, E., & Maratea, M. (2007). Planning satisfiability preferences. Proceedings
AAAI Conference Artificial Intelligence.
Helmert, M. (2006). Fast Downward planning system. Journal Artificial Intelligence Research, 26, 191246.
Helmert, M. (2008). Concise finite-domain representations PDDL planning tasks. Artificial
Intelligence, 173, 503535.
Helmert, M., & Domshlak, C. (2009). Landmarks, Critical paths Abstractions: Whats
difference anyway?. Proceedings International Conference Automated Planning
Scheduling.
Helmert, M., Haslum, P., & Hoffmann, J. (2008). Explicit-State Abstraction: New Method
Generating Heuristic Functions. Proceedings AAAI Conference Artificial Intelligence.
Hoffmann, J., Gomes, C., & Selman, B. (2006). Structure Problem Hardness : Goal Asymmetry
DPLL Proofs SAT-based Planning. Proceedings International Conference
Automated Planning Scheduling.
Hoffmann, J., Kautz, H., Gomes, C., & Selman, B. (2007). SAT encodings state-space reachability problems numeric domains. Proceedings International Joint Conference
Artificial Intelligence.
Hoffmann, J., & Nebel, B. (2001). FF planning system: Fast plan generation heuristic
search. Journal Artificial Intelligence Research, 14, 253302.
Huang, R., Chen, Y., & Zhang, W. (2009). Optimal Temporally Expressive Planner: Initial
Results Application P2P Network Optimization. Proceedings International Conference Automated Planning Scheduling.
Kautz, H., & Selman, B. (1992). Planning satisfiability. Proceedings European Conference
Artificial Intelligence.
326

fiSAS+ P LANNING ATISFIABILITY

Kautz, H., & Selman, B. (1996). Pushing envelope: Planning, propositional logic, stochastic
search. Proceedings AAAI Conference Artificial Intelligence.
Kautz, H., & Selman, B. (1999). Unifying sat-based graph-based planning. Proceedings
International Joint Conference Artificial Intelligence.
Kautz, H., Selman, B., & Hoffmann, J. (2006). SatPlan: Planning Satisfiability. 5th International Planning Competition, International Conference Automated Planning Scheduling.
Monasson, R., Zecchina, R., Kirkpatrick, S., Selman, B., & Troyansky, L. (1999). Determining
computational complexity characteristic phase transitions. Nature, 400(8), 133137.
Moskewicz, M., Madigan, C., Zhao, Y., Zhang, L., & Malik, S. (2001). Chaff: Engineering
Efficient SAT Solver. 39th Design Automation Conference.
Myers, J. L., & Well, A. D. (2003). Research Design Statistical Analysis (2nd edition). Routledge.
Nabeshima, H., Soh, T., Inoue, K., & Iwanuma, K. (2006). Lemma reusing SAT based planning
scheduling. Proceedings International Conference Automated Planning
Scheduling.
Ray, K., & Ginsberg, M. L. (2008). complexity optimal planning efficient method
finding solutions. Proceedings International Conference Automated Planning
Scheduling.
Richter, S., Helmert, M., & Westphal, M. (2008). Landmarks Revisited. Proceedings AAAI
Conference Artificial Intelligence.
Rintanen, J. (2003). Symmetry Reduction SAT Representations Transition System. Proceedings International Conference Automated Planning Scheduling.
Rintanen, J. (2006). Biclique-based representations binary constraints making SAT planning
applicable larger problems. Proceedings European Conference Artificial Intelligence.
Rintanen, J., Heljanko, K., & Niemel, I. (2006). Planning Satisfiability: parallel plans
algorithms plan search. Artificial Intelligence, 12-13, 10311080.
Robinson, N., Gretton, C., Pham, D., & Sattar, A. (2009). SAT-Based Parallel Planning Using
Split Representation Actions. Proceedings International Conference Automated
Planning Scheduling.
Sideris, A., & Dimopoulos, Y. (2010). Constraint propagation propositional planning. Proceedings International Conference Automated Planning Scheduling.
Soos, M., Nohl, K., & Castelluccia, C. (2009). Extending sat solvers cryptographic problems.
International Conference Theory Applications Satisfiability Testing.
6th Intl Planning Competition (2008). http://ipc.informatik.uni-freiburg.de/homepage/..
7th Intl Planning Competition (2011). http://ipc.icaps-conference.org/..
Williams, R., Gomes, C., & Selman, B. (2003). Backdoors typical case complexity. Proceedings International Joint Conference Artificial Intelligence.
327

fiH UANG , C HEN , & Z HANG

Xing, Z., Chen, Y., & Zhang, W. (2006). MaxPlan: Optimal Planning Decomposed Satisfiability Backward Reduction. 5th International Planning Competition, International
Conference Automated Planning Scheduling.
Zhang, W. (2004). Configuration landscape analysis backbone guided local search: Part I:
Satisfiability maximum satisfiability. Artificial Intelligence, 158, 126.
Zhang, W., Rangan, A., & Looks, M. (2003). Backbone Guided Local Search Maximum Satisfiability. Proceedings International Joint Conference Artificial Intelligence.

328

fiJournal Artificial Intelligence Research 43 (2012) 135-171

Submitted 08/11; published 02/12

CQC Algorithm: Cycling Graphs Semantically
Enrich Enhance Bilingual Dictionary
Tiziano Flati
Roberto Navigli

flati@di.uniroma1.it
navigli@di.uniroma1.it

Dipartimento di Informatica, Sapienza University Rome
00198, Rome, Italy.

Abstract
Bilingual machine-readable dictionaries knowledge resources useful many automatic tasks. However, compared monolingual computational lexicons like WordNet,
bilingual dictionaries typically provide lower amount structured information
lexical semantic relations, often cover entire range possible translations word interest. paper present Cycles Quasi-Cycles (CQC),
novel algorithm automated disambiguation ambiguous translations lexical entries bilingual machine-readable dictionary. dictionary represented
graph, cyclic patterns sought graph assign appropriate sense tag
translation lexical entry. Further, use algorithms output improve
quality dictionary itself, suggesting accurate solutions structural problems
misalignments, partial alignments missing entries. Finally, successfully
apply CQC task synonym extraction.

1. Introduction
Lexical knowledge resources, thesauri, machine-readable dictionaries, computational
lexicons encyclopedias, enjoying increasing popularity last
years. Among resources cite Rogets Thesaurus (Roget, 1911), Macquarie Thesaurus (Bernard, 1986), Longman Dictionary Contemporary English (Proctor, 1978,
LDOCE), WordNet (Fellbaum, 1998) Wikipedia. knowledge resources
utilized many applications, including Word Sense Disambiguation (Yarowsky, 1992; Nastase & Szpakowicz, 2001; Martnez, de Lacalle, & Agirre, 2008, cf. Navigli, 2009b, 2012
survey), semantic interpretation text (Gabrilovich & Markovitch, 2009), Semantic Information Retrieval (Krovetz & Croft, 1992; Mandala, Tokunaga, & Tanaka, 1998; Sanderson,
2000), Question Answering (Lita, Hunt, & Nyberg, 2004; Moldovan & Novischi, 2002), Information Extraction (Jacquemin, Brun, & Roux, 2002), knowledge acquisition (Navigli &
Ponzetto, 2010), text summarization (Silber & McCoy, 2003; Nastase, 2008), classification
(Rosso, Molina, Pla, Jimnez, & Vidal, 2004; Wang & Domeniconi, 2008; Navigli, Faralli,
Soroa, de Lacalle, & Agirre, 2011) even simplification (Woodsend & Lapata, 2011).
applications exploit structure provided adopted lexical resources
number different ways. instance, lexical semantic relations encoded
computational lexicons WordNet shown useful graph-based
Word Sense Disambiguation (Mihalcea, 2005; Agirre & Soroa, 2009; Navigli & Lapata, 2010;
Ponzetto & Navigli, 2010) semantic similarity (Pedersen, Banerjee, & Patwardhan,
2005; Agirre, Alfonseca, Hall, Kravalova, Pasca, & Soroa, 2009). Interestingly,
c
2012
AI Access Foundation. rights reserved.

fiFlati & Navigli

reported higher amount structured knowledge, higher disambiguation
performance (Navigli & Lapata, 2010; Cuadros & Rigau, 2006). Unfortunately,
semantics made explicit within lexical resources. Even WordNet (Fellbaum, 1998),
widely-used computational lexicon English, provides explanatory information
unstructured form textual definitions, i.e., strings text explain meaning
concepts using possibly ambiguous words (e.g., motor vehicle four wheels provided
definition common sense car ). Still worse, computational lexicons
like WordNet contain semantically explicit information is-a part-of relations,
machine-readable dictionaries (MRDs) often electronic transcriptions paper
counterparts. Thus, entry mostly provide implicit information form
free text, cannot immediately utilized Natural Language Processing applications.
recent years various approaches disambiguation monolingual dictionary
definitions investigated (Harabagiu, Miller, & Moldovan, 1999; Litkowski, 2004;
Castillo, Real, Asterias, & Rigau, 2004; Navigli & Velardi, 2005; Navigli, 2009a), results
shown can, indeed, boost performance difficult tasks Word
Sense Disambiguation (Cuadros & Rigau, 2008; Agirre & Soroa, 2009). However, little
attention paid disambiguation bilingual dictionaries, would
capable improving popular applications Machine Translation.
article present graph-based algorithm aims disambiguating translations bilingual machine-readable dictionaries. method takes input bilingual
MRD transforms graph whose nodes word senses1 (e.g., car 1n ) whose
edges (s, s0 ) mainly represent potential relations source sense word
w (e.g., car 1n ) various senses s0 translations (e.g., macchina 3n ). Next, introduce novel notion cyclic quasi-cyclic graph paths use select
appropriate sense translation w0 source word w.
contributions paper threefold: first, present novel graph-based algorithm disambiguation bilingual dictionaries; second, exploit disambiguation
results way help lexicographers make considerable improvements
dictionary address issues mistakes various kinds; third, use algorithm
automatically identify synonyms aligned across languages.
paper organized follows: Section 2 introduce reader main
ideas behind algorithm, also help walk-through example. Section 3
provide preliminary definitions needed introduce disambiguation algorithm.
Section 4 present Cycles Quasi-Cycles (CQC) algorithm disambiguation
bilingual dictionaries. Section 5 assess disambiguation performance dictionary
translations. Section 6, show enhance dictionary semi-automatically
means CQC, provide experimental evidence Section 7. Section 8 describe
application monolingual bilingual synonym extraction Section 9 describe
experiments. Related work presented Section 10. give conclusions Section
11.
1. denote wpi i-th sense word w part speech p reference sense inventory (we
use n nouns, v verbs, adjectives r adverbs), senses simply denoted
integers (like 1, 2, 3, etc.), also letters numbers (such A.1, B.4, D.3) indicating different
levels granularity (homonymy, polysemy, etc.).

136

fiCycling Graphs Semantically Enrich Enhance Bilingual Dictionary

2. Brief Overview
section provide brief overview approach disambiguation bilingual
dictionary entries.
2.1 Goal
general form bilingual dictionary entry is:
wpi v1 , v2 , . . . , vk
where:
wpi i-th sense word w part speech p source language (e.g.,
play 2v second sense verb play);
vj translation target language sense wpi (e.g., suonare v translation play 2v ). Note vj implicitly assumed part
speech p wp . Importantly, sense explicitly associated vj .
objective associate target word vj one senses
concepts expressed wp vj match. aim systematic automatic
way. First all, starting bilingual dictionary (see Section 3.1), build noisy
graph associated dictionary (see Section 3.2), whose nodes word senses
edges (mainly) translation relations word senses. translation relations
obtained linking source word sense (wpi above) senses target word
vj . Next, define novel notion graph patterns, called Cycles
Quasi-Cycles (CQC), use support predicting suitable sense
translation vj source word sense wpi (see Section 3.3).
2.2 Walk-Through Example
present walk-through example give insights main goal
present work. Consider following Italian-English dictionary entries:
giocare A.1
v
recitare A.2
v
suonare A.1
v
suonare B.4
v
interpretare 4v







play, toy
act, play
sound, ring, play
ring, echo
play, act





giocare
suonare, riprodurre
interpretare, recitare

following English-Italian entries:
play 1v
play 2v
play 3v

137

fiFlati & Navigli

aim sense tag target terms right-hand side, i.e., would like
obtain following output:
giocare A.1
v
recitare A.2
v
suonare A.1
v
suonare B.4
v
interpretare 4v







play 1v , toy 1v
3
act A.1
v , play v
1.A.1
sound v , ring 2.A.2
, play 2v
v
2.A.4
A.1
ring v , echo v
play 3v , act A.1
v

play 1v
play 2v
play 3v





giocare A.1
v
1
suonare A.2
v , riprodurre v
3
A.2
interpretare v , recitare v

numbers beside right-hand translation correspond suitable senses
dictionary translation (e.g., first sense play v corresponds sense
playing game). instance, order disambiguate first entry (i.e., giocare vA.1
play, toy), determine best sense English verb play given Italian
verb sense giocare A.1
v . humans know since source sense playing
game, right sense playv first one. fact, among 3 senses verb
play v shown above, see first sense one translates back
giocare. words, first sense play v one contained path
starting from, ending in, giocare A.1
v , namely:
giocare A.1
play 1v giocare A.1
v
v
similar paths involving senses playv . hunch
exploiting cyclic paths able predict suitable sense ambiguous
translation. provide scoring function weights paths according length
(with shorter paths providing better clues, thus receiving higher weights) and,
time, favours senses participate paths. also study effect
edge reversal support disambiguating translations. hunch
allowing reversal subsequent edges enable previously-missed meaningful
paths, call quasi-cycles (e.g., recitare A.2
play 3v interpretare 3v act A.1

v
v
A.2
recitare v ). anticipate including quasi-cycles significantly boosts overall disambiguation performance.

3. Preliminaries
provide fundamental definitions used throughout rest
paper.
3.1 Bilingual Dictionary
define bilingual machine-readable dictionary (BiMRD) quadruple =
(L, Senses, , M), L bilingual lexicon (i.e., L includes lexical items
languages), Senses mapping that, given lexical item w L, returns set
138

fiCycling Graphs Semantically Enrich Enhance Bilingual Dictionary

language [lNgwidZ] n.
1 lingua; linguaggio: foreign languages, lingue straniere; technical l., la lingua della
tecnica; l. poetry, il linguaggio poetico; dead languages, le lingue morte l.
laboratory, laboratorio linguistico 2 bad l., linguaggio scorretto (o sboccato) 2 sign l.,
lingua dei segni (usata dai sordomuti) 2 strong l., linguaggio violento (o volgare) 2
use bad l., usare un linguaggio volgare, da trivio.
2 favella: Animals possess l., gli animali non possiedono la favella.
Figure 1: Entry example Ragazzini-Biagi dictionary.
senses w D, translation function which, given word sense Senses(w),
provides set (possibly ambiguous) translations s. Typically, (s) L, is,
translations lexicon. However, might well translations (s)
lexicon. Finally, function which, given word sense Senses(w),
provides set words representing meta-information sense (e.g., M(phoneme 1n )
= {linguistics}).
instance, consider Ragazzini-Biagi English-Italian BiMRD (Ragazzini & Biagi,
2006). dictionary provides Italian translations English word sense, vice
versa. given source lemma (e.g., language n English), dictionary lists translations target language sense expressed lemma. Figure 1 shows
dictionary entry language n . dictionary provides:
lexicon two languages, i.e., set L lemmas dictionary entries
exist (such languagen Figure 1, also lingua n , linguaggio n , etc.);
set senses given lemma, e.g., Senses(language n ) = {language 1n , language 2n }
(the communication sense vs. speaking ability), Senses(lingua n ) = {lingua 1n , lingua 2n } (the muscular organ set words used communication, respectively);
Senses(linguaggio n ) = {linguaggio 1n , linguaggio 2n , linguaggio 3n } (the faculty speaking, means communication machine language, respectively);
translations given sense, e.g., (language 1n ) = {lingua n , linguaggio n };
optionally, meta-information given sense, M(phoneme 1n ) = {linguistics}.
dictionary also provides usage examples compound translations (see Figure 1),
lexical variants (e.g., acknowledgement vs. acknowledgment) references entries
(e.g., motorcar car ).
3.2 Noisy Graph
Given BiMRD D, define noisy dictionary graph G = (V, E) directed graph
where:
1. V set senses dictionary (i.e., V =
139



wL Senses(w));

fiFlati & Navigli

lingua2n
originaleB.3
n

linguaggio1n

parlatoB.1
n

linguaggio3n

language1n

linguaggio2n
tongue1n
lingua1n

speech1n
eloquio1n

favella2n
parlareD.2
n
idioma1n

Figure 2: excerpt Ragazzini-Biagi noisy graph including language 1n neighbours.

2. word w L sense Senses(w), edge (s, s0 ) E s0
sense translation dictionary (i.e., s0 Senses(w0 ) w0 (s)),
s0 sense meta-word definition (i.e., s0 Senses(m)
M(s)).
According definition, given ambiguous word w0 definition s,
add edge sense w0 dictionary. words, noisy graph
G associated dictionary encodes potential meanings word translations
terms edge connections. Figure 2 show excerpt noisy graph associated
Ragazzini-Biagi dictionary. sub-graph three kinds nodes found:
source sense (rectangular box), namely language 1n .
senses translations (thick ellipse-shaped nodes), e.g., three senses
linguaggio n two senses lingua n .
senses (ellipse-shaped nodes), either translations meta-information
senses (e.g., speech 1n translation sense eloquio 1n ).

3.3 Graph Cycles Quasi-Cycles
recall definition graph cycle. cycle graph G sequence edges
G form path v1 v2 vn (vi V {1, . . . , n}) first node
140

fiCycling Graphs Semantically Enrich Enhance Bilingual Dictionary







...
(a) cycle



...
(b)
quasi-cycle
1 (terminal)
reversed edge



(c) quasi-cycle
1 (non terminal) reversed edge



...
(d)
quasi-cycle
2 reversed edges

...

...
(e) quasi-cycle
k reversed edges

...
(f) illegal quasicycle

Figure 3: Legal illegal cycles quasi-cycles.
path corresponds last, i.e., v1 = vn (Cormen, Leiserson, & Rivest, 1990, p. 88).
length cycle given number edges. example, cycle length 3
Figure 2 given path:
language 1n linguaggio 2n lingua 2n language 1n .
provide definition quasi-cycle sequence edges
reversal orientation one consecutive edges creates cycle (Bohman &
Thoma, 2000). instance, quasi-cycle length 4 Figure 2 given path:
language 1n linguaggio 1n speech 1n eloquio 1n language 1n .
seen reversal edge (eloquio1n , speech1n ) creates cycle. Since
direction edge opposite cycle, call reversed edge. Finally,
say path (quasi-)cyclic forms (quasi-)cycle. Note consider
paths going across senses word; language 1n lingua1n tongue 1n lingua2n
language 1n considered legal quasi-cycle.
order provide graphical representation (quasi-)cycles, Figure 3 show
different kinds (quasi-)cycles starting given node s, namely: cycle (a), quasicycle 1 terminal (b) non-terminal (c) reversed edge (a reversed edge terminal
incident s), reversed edges ((d) (e)), illegal quasi-cycle
whose reversed edges consecutive (f).

4. CQC Algorithm
ready introduce Cycles & Quasi-Cycles (CQC) algorithm, whose pseudocode given Table 1. algorithm takes input BiMRD = (L, Senses, , M),
141

fiFlati & Navigli

1
2
3
4
5
6
7
8
9
10
11

CQC(BiMRD = (L, Senses, , M), sense w L)
word w0 (s)
sense s0 Senses(w0 )
paths(s0 ) :=SDFS(s0 , s)
all_paths := s0 Senses(w0 ) paths(s0 )
sense s0 Senses(w0 )
score(s0 ) := 0
path p paths(s0 )
l := length(p)
1
v := (l) N umP aths(all_paths,l)
score(s0 ) := score(s0 ) + v
(w0 ) = argmax score(s0 )

12

return

s0 Senses(w0 )

Table 1: Cycles & Quasi-Cycles (CQC) algorithm pseudocode.
sense word w lexicon (i.e., w L Senses(w)). algorithm
aims disambiguating words ambiguous translations w0 (s), i.e., assign
right sense among listed Senses(w0 ).
algorithm outputs mapping ambiguous word w0 (s)
sense s0 w0 chosen result disambiguation procedure illustrate hereafter.
First, sense s0 target translation w0 (s), algorithm performs
search noisy graph associated collects following kinds paths:
i) Cycles:
s0 s1 sn2 sn1 =
ii) Quasi-cycles:

s0 s1 ... sj ... sk ... sn2 sn1 =

1 j n2, j < k n1
(1)

source sense, s0 candidate sense w0 (s), si sense listed
(i {1, . . . , n 2}), sn1 = s, n length path. Note kinds
path start end node s, algorithm searches quasi-cycles
whose reversed edges connecting sk sj consecutive. avoid redundancy require
(quasi-)cycles simple, is, node repeated path except start/end
node (i.e., si 6= s, si 6= s0 , si 6= si0 i, i0 s. t. 6= i0 ).
first step algorithm (see Table 1, lines 2-3), (quasi-)cyclic paths
sought sense w0 . step performed depth-first search (DFS, cf.
Cormen et al., 1990, pp. 477479) depth .2 DFS whose pseudocode
2. note depth-first search equivalent breadth-first search (BFS) purpose collecting
paths.

142

fiCycling Graphs Semantically Enrich Enhance Bilingual Dictionary

1
2
3
4

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15

DFS(sense s0 , sense s)
paths :=
visited :=
Rec-DFS(s0 , s, s0 )
return paths
Rec-DFS(sense s0 , sense s, path p)
s0 visited length(p) > return
s0 =
paths := paths {p}
return
push(visited, s0 )
// cycles
edge s0 s00
p0 := p s00
Rec-DFS(s00 , s, p0 )
// quasi-cycles
edge s0 s00
p0 := p s00
reversedEdgesNotConsecutive(p0 ) continue
Rec-DFS(s00 , s, p0 )
pop(visited)

Table 2: depth-first search pseudocode algorithm cycle quasi-cycle collection.
shown Table 2 starts sense s0 Senses(w0 ), recursively explores graph;
outgoing edges explored order collect cycles (lines 7-9 Rec-DFS, see Table 2)
incoming edges considered order collect quasi-cycles (lines 11-14);
extending current path p reversed edge, however, necessary check whether
latter consecutive previously reversed edges (if any) present p skip
otherwise (cf. Formula (1)). stack visited contains nodes visited far, order
avoid repetition node path (cf. lines 1, 5 15 Rec-DFS). Finally search
ends maximum path length reached, previously visited node encountered
(line 1 Rec-DFS); otherwise, initial sense found, (quasi-)cycle collected
(lines 2-4 Rec-DFS). sense s0 w0 DFS returns full set paths(s0 )
paths collected. Finally, line 4 Table 1, all_paths set store paths
senses w0 .
second phase CQC algorithm (lines 5-10 Table 1) computes score
sense s0 w0 based paths collected s0 first phase. Let p
path, let l length, i.e., number edges path. contribution
p score s0 given by:
score(p) :=

(l)
N umP aths(all_paths, l)

(2)

where:
143

fiFlati & Navigli

lingua2n
originaleB.3
n
parlatoB.1
n

language1n

linguaggio2n
tongue1n

speech1n
eloquio1n
favella2n
parlareD.2
n
idioma1n

Figure 4: Ragazzini-Biagi graph Figure 2 pruned result CQC algorithm.

(l) monotonically non-increasing function length l; experiments,
tested three different weight functions (l), namely constant, linear
inversely exponential function (see Section 5).
normalization factor N umP aths(all_paths, l) calculates overall number
collected paths length l among target senses.
way score sense s0 amounts to:
X

score(s0 ) :=

ppaths(s0 )

score(p) =


X

(l)

l=2

N umP aths(paths(s0 ), l)
N umP aths(all_paths, l)

(3)

rationale behind scoring formula two-fold: first thanks function
favours shorter paths, intuitively less likely noisy; second, path
length, accounts ratio paths length s0 participates (second
factor right-hand side formula above).
scores sense s0 target translation w0 calculated,
mapping established w0 highest-scoring sense (line 11). Finally,
translations disambiguated, mapping returned (line 12).
result systematic application algorithm sense BiMRD
D, new graph G0 = (V, E 0 ) output, V sense inventory D,
E 0 subset noisy edge set E edge (s, s0 ) E 0 result
disambiguation algorithm run input s. Figure 4 shows clean, unambiguous
dictionary graph executing CQC, compared initial noisy graph Figure
2. pruned graph, sense links one sense translations.
4.1 Example
example, consider following dictionary entry Ragazzini-Biagi dictionary:

144

fiCycling Graphs Semantically Enrich Enhance Bilingual Dictionary

language1n

lingua1n

language1n

lingua1n

favella2n

tongue1n

idioma1n

tongue1n

language1n

lingua2n

language1n

lingua2n

language1n

lingua2n

language1n

lingua2n

favella2n

tongue1n

idioma1n

tongue1n

language1n

lingua2n

language1n

lingua2n

linguaggio2n

linguaggio3n

linguaggio1n

Figure 5: Cycles quasi-cycles collected DFS(lingua 1n , language 1n ) (top)
DFS(lingua 2n , language 1n ) (bottom).

language n. 1 lingua; linguaggio.
order disambiguate Italian translations call CQC algorithm follows:
CQC(D, language1n ). Let us first concentrate disambiguation linguan , ambiguous word two senses Ragazzini-Biagi. First, two calls made, namely
DF S(lingua1n , language1n ) DF S(lingua2n , language1n ). function call performs
DFS starting respective sense target word collect relevant cycles
quasi-cycles according algorithm Table 2. set cycles quasi-cycles
collected two senses noisy graph Figure 2 shown Figure 5.
second phase CQC algorithm, sense linguan ,
contribution path calculated (lines 8-10 algorithm Table 1). Specifically,
following scores calculated two senses lingua n (we assume weight
function (l) = 1/el ):
score(lingua 1n ) =

2

score(lingua 2n ) =
+
+
'

1
3
2
1

1
e4



1
N umP aths(all_paths,4)

' 2 0.018

1
e12 N umP aths(all_paths,2)
+
1
1
e3 N umP aths(all_paths,3) +
1
e14 N umP aths(all_paths,4)
'
1
1
0.135 1 + 3 0.050 3 + 2 0.018

1
4

1
4

= 0.009

= 0.194

N umP aths(all_paths, l) total number paths length l collected
senses linguan . Finally, sense highest score (i.e., lingua2n example)
returned.
Similarly, determine scores various senses linguaggion follows:
145

fiFlati & Navigli

score(linguaggio 1n ) =

2

score(linguaggio 2n ) =
+
+
'

1
2
2
1

score(linguaggio 3n ) =

1

1
e4



1
N umP aths(all_paths,4)

' 2 0.018

1
e12 N umP aths(all_paths,2)
+
1
1
e3 N umP aths(all_paths,3) +
1
e14 N umP aths(all_paths,4)
'
1
1
0.135 2 + 2 0.050 2 + 2 0.018
1
e2



1
N umP aths(all_paths,2)

1
4

' 1 0.135

1
4

= 0.009.

= 0.1265.
1
2

= 0.0675.

result, sense 2 correctly selected.

5. Evaluation: Dictionary Disambiguation
first set experiments aim assess disambiguation quality CQC
algorithm compare existing disambiguation approaches. first describe
experimental setup Section 5.1, introducing bilingual dictionary used throughout
article, providing information dictionary graph, tuning test datasets,
algorithms, parameters baselines used experiments. describe
experimental results Section 5.2.
5.1 Experimental Setup
section discuss experimental setup dictionary disambiguation experiment.
5.1.1 Dictionary
performed dictionary disambiguation experiments Ragazzini-Biagi (Ragazzini
& Biagi, 2006), popular bilingual English-Italian dictionary, contains 90,000
lemmas 150,000 word senses.
5.1.2 Dictionary Graph
order get idea difficulty dictionary disambiguation task determined
ratio wrong edges graph. first calculated ratio correct edges,
i.e., edges link source senses right translation senses. quantity
estimated overall number translations dictionary (i.e., assuming
translation appropriate sense dictionary) divided total number edges:
P
CorrectnessRatio(G) =

|T (s)|

sV

(4)

|E|

ratio wrong edges calculated 1 CorrectnessRatio(G), obtaining
estimate 66.4% incorrect edges noisy graph Ragazzini-Biagi dictionary.
146

fiCycling Graphs Semantically Enrich Enhance Bilingual Dictionary

Dataset

# entries

Tuning Dataset
Test Dataset

50
500

# translations

# polysemous

avg. polysemy

perfect alignments

80
1,069

53
765

4.74
3.95

37
739

Table 3: Statistics tuning test datasets.
5.1.3 Dataset
datasets tuning test consist dictionary entries, containing translations
source sense target language. translation item manually disambiguated
according sense inventory bilingual dictionary. example, given Italian
entry brillante A.2
, translated sparkling , vivacious , associated appropriate English sense English-Italian section sparkling vivacious (senses 3 1,
respectively).
tuning purposes, created dataset 50 entries, totaling 80 translations. also
prepared test dataset 500 entries, randomly sampled Ragazzini-Biagi dictionary
(250 English-Italian section, 250 Italian-English section). Overall,
test dataset included 1,069 translations disambiguated. report statistics
two datasets Table 3, including number polysemous translations average
polysemy translation. note 44 translations test set (i.e., 4.1%
total) none senses listed dictionary appropriate (including monosemous
translations). successful disambiguation system, therefore, disambiguate
items. last column table shows number translations sense exists
translates back source lemma (e.g., car 1n translates macchina macchina 3n
translates car ).
5.1.4 Algorithms
compared following algorithms experimental framework3 , since (with
exception CQC variants thereof) represent widespread graph-based
approaches used many NLP tasks state-of-the-art performance:
CQC: applied CQC algorithm described Section 4;
Cycles, variant CQC algorithm searches cycles (i.e., quasicycles collected);
DFS, applies ordinary DFS algorithm collects paths
s0 (i.e., paths closed completing edge sequences connecting s0
s). setting path s0 discarded, construction found
G sense s0 Senses(w0 );
Random walks, performs large number random walks starting s0
collecting paths lead s. approach successfully used
approximate exhaustive search translation circuits (Mausam, Soderland, Etzioni,
3. order ensure level playing field, provided in-house implementations algorithms
within graph-based framework, except Personalized PageRank, used standard
implementation (http://jung.sourceforge.net).

147

fiFlati & Navigli

Weld, Skinner, & Bilmes, 2009; Mausam, Soderland, Etzioni, Weld, Reiter, Skinner,
Sammer, & Bilmes, 2010). note that, virtue simulation nature,
method merely serves way collecting paths random. fact, given path
ending node v, next edge chosen equiprobably among edges outgoing
v.
Markov chains, calculates probability arriving certain source sense
starting initial translation sense s0 averaged n consecutive steps, is,
P
(m)
(m)
ps0 ,s = n1 nm=1 ps0 ,s , ps0 ,s probability arriving node using exactly
steps starting node s0 . initial Markov chain initialized noisy
(0)
dictionary graph follows: v, v 0 V , (v, v 0 ) E, pv,v0 = 1/out(v),
(0)

out(v) outdegree v noisy graph, otherwise pv,v0 = 0.
Personalized PageRank (PPR): popular variant PageRank algorithm
(Brin & Page, 1998) original Markov chain approach node ranking
modified perturbating initial probability distribution nodes (Haveliwala,
2002, 2003). PPR successfully applied Word Sense Disambiguation (Agirre
& Soroa, 2009) thus represents competitive system compare with.
order disambiguate target translation w0 source word w, translation
sense s0 , concentrate probability mass s0 , apply PPR. select
best translation sense one maximizes PPR value source word
(or, equivalently, translation sense itself).
Lesk algorithm (Lesk, 1986): apply adaptation Lesk algorithm which,
given source sense word w word w0 occurring translation s,
determine right sense w0 basis (normalized) maximum overlap
entries sense s0 w0 s:
|next (s) next (s0 )|
,

0
s0 Senses(w0 ) max{|next (s)|, |next (s )|}
argmax

define next (s) = synonyms(s) next(s), synonyms(s) set lexicalizations sense (i.e., synonyms sense s, e.g., acknowledgement vs acknowledgment) next(s) set nodes s0 connected edge (s, s0 ).
algorithms explicitly collect paths (CQC, Cycles, DFS Random
walks), tried three different functions weighting paths, namely:
constant function (l) = 1 weights paths equally, independently
length l;
linear function (l) = 1/l assigns path score inversely proportional
length l;
exponential function (l) = 1/el assigns score decreases exponentially
path length.
148

fiCycling Graphs Semantically Enrich Enhance Bilingual Dictionary

Algorithm
CQC
Cycles
DFS
Random walks
Markov chains

Best Configuration
Length
Specific parameters
4
2 terminal reversed edges
4
4
4
400 random walks
2
-

Table 4: Parameter tuning path-based algorithms.
5.1.5 Parameters
used tuning dataset fix parameters algorithm maximized
performance. tuned maximum path length path-based algorithms
(CQC, Cycles, DFS, Random walks Markov chains), trying lengths {1, . . . , 6}.
Additionally, CQC, tuned minimum maximum values parameters
j k used quasi-cyclic patterns (cf. Formula 1 Section 4). parameters
determine position number reversed edges quasi-cyclic graph pattern.
best results obtained n 1 k n 1, i.e. k = n 1, n 3 j < n 1,
is, CQC yielded best performance 2 terminal reversed edges sought
(cf. Section 3.3 Figure 3). Random walks, tuned number walks needed
disambiguate item (ranging 50 2,000). best parameters resulting
tuning reported Table 4. Finally, PPR used standard parameters:
performed 30 iterations set damping factor 0.85.
5.1.6 Measures
assess performance algorithms, calculated precision (the number correct
answers number items disambiguated system), recall (the number
correct answers number items dataset), F1 (a harmonic mean
R
precision recall, given P2P+R
). Note precision recall consider
items test set appropriate sense available dictionary. order
account items, also calculated accuracy number correct answers
divided total number items test set.
5.1.7 Baselines
compared performance algorithms three baselines:
First Sense (FS) Baseline, associates first sense listed dictionary
translation disambiguated (e.g., car 1n chosen car independently
disambiguation context). rationale behind baseline derives
tendency lexicographers sort senses according importance perceive
estimate (possibly sense-tagged) corpus;
Random Baseline, selects random sense target translation;
149

fiFlati & Navigli

Degree Baseline, chooses translation sense highest out-degree,
i.e., highest number outgoing edges.
5.2 Results
ready present results dictionary disambiguation experiment.
5.2.1 Results without Backoff Strategy
Table 5 report results algorithms test set. CQC, PPR Cycles
best performing algorithms, achieving around 83%, 81% 75% accuracy respectively.
CQC outperforms systems terms F1 large margin. results show
mere use cyclic patterns lead state-of-the-art performance, is,
instead, obtained quasi-cycles also considered. Including quasi-cycles leads
considerable increase recall, time maintaining high level precision.
DFS even penalizing get backward support happens
cycling patterns. Markov chains consistently outperform Random walks. hypothesize
due higher coverage Markov chains compared number random
walks collected simulated approach. PPR considerably outperforms two
probabilistic approaches (especially terms recall accuracy), lags behind CQC
3 points F1 2 accuracy. result confirms previous findings literature
concerning high performance PPR, also corroborates hunch quasi-cycles
determining factor detection hard-to-find semantic connections within
dictionaries. Finally, Lesk achieves high precision, low recall accuracy, due
lack lookahead mechanism.
choice weighting function impacts performance path-based algorithms, 1/el performing best constant function 1 resulting worst results
(this case DFS, though).
random baseline represents lowerbound much lower results.
Compared first sense baseline, CQC, PPR Cycles obtain better performance.
result consistent previous findings tasks Senseval-3 Gloss Word Sense
Disambiguation (Litkowski, 2004). However, time, contrast results
all-words Word Sense Disambiguation (Navigli, 2009b), first frequent
sense baseline generally outperforms disambiguation systems. Nevertheless, nature
two tasks different, dictionary entries senses tend equally
distributed, whereas open text single predominant meaning determined
context. Degree Baseline, yields results expectations, far worse
FS baseline. reason behind lies fact amount translations
translation senses necessarily correlate mainstream meanings.
attaining highest precision, CQC also outperforms algorithms
terms accuracy. However, accuracy lower F1: due F1 harmonic
mean precision recall, calculating accuracy every item dataset
taken account, even items appropriate sense tag given.
order verify reliability tuning phase (see Section 5.1), studied F1
performance CQC varying depth DFS (cf. Section 4). best results
shown Table 6 obtained test set = 4, confirms
150

fiCycling Graphs Semantically Enrich Enhance Bilingual Dictionary

Algorithm
CQC 1/el
CQC 1/l
CQC 1
Cycles 1/el
Cycles 1/l
Cycles 1
DFS 1/el
DFS 1/l
DFS 1
Random walks 1/el
Random walks 1/l
Random walks 1
Markov chains
PPR
Lesk
First Sense BL
Random BL
Degree BL

P
87.14
87.04
86.33
87.17
86.49
84.56
63.40
63.40
63.56
83.94
83.67
79.38
85.46
83.20
86.05
72.67
28.53
58.39

Performance
R
F1

83.32 85.19 83.35
83.22 85.09 83.26
82.54 84.39 82.60
74.93 80.59 75.58
74.34 79.96 75.02
72.68 78.17 73.43
37.85 47.40 39.85
37.85 47.40 39.85
37.95 47.52 39.94
61.17 70.77 62.49
60.98 70.55 62.30
57.85 66.93 59.31
65.37 74.08 66.70
81.25 82.21 81.27
31.90 46.55 34.52
73.17 72.92 73.53
29.76 29.13 28.53
58.85 58.39 58.62

Table 5: Disambiguation performance Ragazzini-Biagi dataset.

CQC- e1l

=2
76.94

=3
82.85

=4
85.19

=5
84.50

Table 6: Disambiguation performance CQC- e1l based F1.
optimal parameter choice CQC (cf. Table 4). fact, F1 increases higher values
, performance peak 85.19% obtained = 4. higher values
observed performance decay due noise introduced. optimal value
line previous experimental results impact DFS depth Word Sense
Disambiguation (Navigli & Lapata, 2010).
5.2.2 Results Backoff Strategy
mentioned above, experimented path-based approaches allowed return
result; case paths found sense target word.
second set experiments thus let algorithms use first sense baseline
backoff strategy whenever able give result target word.
especially useful disambiguation system cannot make decision
lack knowledge dictionary graph. seen Table 7, scenario changes
151

fiFlati & Navigli

Algorithm
CQC 1/el
CQC 1/l
CQC 1
Cycles 1/el
Cycles 1/l
Cycles 1
DFS 1/el
DFS 1/l
DFS 1
Random walks 1/el
Random walks 1/l
Random walks 1
Markov chains
PPR
Lesk
First Sense BL
Random BL
Degree BL

Performance FS
P
R
F1

86.52 87.02 86.77 86.81
86.42 86.93 86.67 86.72
85.74 86.24 86.00 86.06
85.55 86.05 85.80 85.87
84.97 85.46 85.21 85.31
83.32 83.80 83.56 83.72
68.00 68.39 68.19 68.94
68.00 68.39 68.19 68.94
68.09 68.49 68.29 69.04
82.06 82.54 82.30 82.51
81.86 82.34 82.10 82.32
78.76 79.22 79.00 79.33
82.75 83.32 83.03 83.26
83.12 83.77 83.44 83.12
82.07 82.63 82.35 82.60
72.67 73.17 72.92 73.53
28.53 29.76 29.13 28.53
58.39 58.85 58.39 58.62

Table 7: Disambiguation performance Ragazzini-Biagi dataset using first sense
(FS) backoff strategy.

radically setting. adoption first sense backoff strategy results generally
higher performance; notwithstanding CQC keeps showing best results, achieving
almost 87% F1 accuracy = 1/el .
5.2.3 Directed vs. Undirected Setting
algorithm crucially takes advantage quasi-cyclic pattern therefore relies
heavily directionality edges. Thus, order verify beneficial impact
quasi-cycles, also compared approach undirected setting, i.e., using noisy
graph whose edges unordered pairs. setting similar de Melo
Weikum (2010), aim detecting imprecise wrong interlanguage links Wikipedia.
However, task edges wrong (in fact, remove less 2%
cross-lingual interlanguage links), whereas dictionary graph contains much noise,
estimated involve around 66% edges (see Section 5.1.2).
test whether directionality really matters, compared CQC natural undirected counterpart, namely Undirected Cycles: algorithm collects (undirected)
cycles linking target sense back source sense underlying undirected noisy
graph. implement DFS undirected setting equivalent
Undirected Cycles; neither implement undirected versions Random Walks,
152

fiCycling Graphs Semantically Enrich Enhance Bilingual Dictionary

Algorithm
Undirected Cycles 1/el
Undirected Cycles 1/l
Undirected Cycles 1

P
76.67
76.56
76.12

Performance
R
F1

67.16 66.73 71.60
67.06 66.63 71.50
66.67 66.25 71.08

Table 8: Disambiguation performance Ragazzini-Biagi dataset using undirected
model.

Algorithm
Undirected Cycles 1/el
Undirected Cycles 1/l
Undirected Cycles 1

Performance FS
P
R
F1

77.50 78.10 77.50 77.80
77.40 78.01 77.40 77.70
77.01 77.61 77.01 77.31

Table 9: Disambiguation performance Ragazzini-Biagi dataset using undirected
model (using FS baseline).

Markov Chains PPR, broadly equivalent Degree undirected
setting (Upstill, Craswell, & Hawking, 2003). shown Table 8, Undirected Cycles yields
66% F1 performance 71% accuracy (almost regardless function). Consistently
previous experiments, allowing algorithm resort FS Baseline backoff strategy boosts performance 77-78% (with = 1/el producing best results,
see Table 9). Nonetheless, Undirected Cycles performs significantly worse Cycles
CQC.
reason behaviour lies strong disambiguation evidence provided
directed flow information. fact, accounting directionality leads considerable
loss information, since would treating two different scenarios way: one
another one t.
example, directed setting two senses reciprocally link one
another (s t) create cycle length 2 (s s); undirected setting, instead,
two edges merged (s t) supporting cycles length 2 found.
result considering fact translates back s, precious piece
information! Furthermore undirected cycle likely correspond noisy, illegal
quasi-cycle (cf. Figure 3(f)), i.e., one could contain sequence whatsoever plain
reversed edges. Consequently, undirected setting meaningful nonsensical
paths lumped together.

6. Dictionary Enhancement
present application CQC algorithm problem enhancing
quality bilingual dictionary.
153

fiFlati & Navigli

6.1 Ranking Translation Senses
explained Section 4, application CQC algorithm sense entry determines,
together sense choice, ranking senses chosen translations. instance,
appropriate senses translations language (cf. Section 4.1) chosen
basis following scores: 0.009 (lingua 1n ), 0.194 (lingua 2n ), 0.009 (linguaggio 1n ),
0.1265 (linguaggio 2n ), 0.0675 (linguaggio 3n ). higher score target translation,
higher confidence selecting corresponding sense. fact, high score clear
hint high amount connectivity conveyed target translation back source
sense. result, following senses chosen example: lingua 2n , linguaggio 2n .
hunch confidence information prove useful disambiguating
dictionary translations, also identifying recurring problems dictionaries tend suffer
from.
instance, assume English word w translates Italian word w0 sense
entry w0 bilingual dictionary translates back w. example
shortcoming could fixed following: wood 2n bosco sense bosco translates
back wood (here wood 2n bosco refer forest sense). However, phenomenon
always need solved. might case w relevant (e.g., popular)
translation w0 , w0 frequent term. instance, idioma 1n (idiom n english)
translates language sense language idioma translation. correct
expect language translate uncommon word idioma.
decide whether problem kind needs fixed (like bosco)
(like idioma)? answer question exploit confidence scores output
CQC algorithm. fact, applying CQC algorithm pair wood 2n , bosco 1n
obtain score 0.2 (indicating bosco 1n point back wood )4 , pair
idioma 1n , language 1n get score 0.07 (pointing idioma 1n easy reach
language 1n ).
6.2 Patterns Enhancing Bilingual Dictionary
section, propose methodology enhance bilingual dictionary using
sense rankings provided CQC algorithm. order solve relevant problems raised
Zanichelli lexicographers basis professional experience, identified
following 6 issues, characterized specific graph pattern:
Misalignment. first pattern kind sw sw0 6 sw , sw sense
w source language, sw0 sense w0 target language, denotes
translation dictionary. instance, buy 1n translated compera 1n ,
compera 1n translated buy 1n . high-ranking sense compera 1n implies
issue solved.
Partial alignment. pattern kind sw sw0 sw00 w sw00 w sw0
sw sw sw00 w senses source language, w00 w compound ends
w, sw0 sense target language. instance, repellent 1n translated
insettifugo 1n , turn translates insect repellent 1n .
4. Note practice values greater 0.3 unlikely.

154

fiCycling Graphs Semantically Enrich Enhance Bilingual Dictionary

issue

pattern

misalignment

buy n. 1 (fam.) acquisto; compera.
compera n. 1 purchase; shopping.

sw
sw 0

repellent n. 1 sostanza repellente; insettifugo.
insettifugo n. 2 insect repellent.

sw
sw 0

persistente a. 1 persistent; persisting.
persisting a. (not available dictionary).

w00

sw
sw 0
sw00

pass n. 3 tesserino (di autobus, ecc.).
tesserino n. 1 tessera.
tessera n. 1 card; ticket; pass.

w0 , w00

sw
sw0 , sw00

w0

sw
w00 w

sw

w0

sw

w0

use reference

use variant

sw

sw

example

sw
sw 0

w0

sw

partial alignment

missing lemma

sense
entry

w0

inconsistent spelling
w00

sw
sw00

riscontro n. 6 reply; acknowledgment.
acknowledgement, acknowledgment n.
ferma di ricevuta; riscontro.

3 con-

asciugacapelli n. 1 hair-dryer.
hair dryer n. 1 asciugacapelli.

Table 10: set graph patterns used enhancement suggestions.
Missing lemma. pattern kind sw sw0 sw0 exist
dictionary. example, persistente 1a translated persistent , however latter
lemma exist dictionary lexicon.
Use reference. pattern kind sw sw0 sw00 sw sw0
reference sw00 . example, pass 3n translated tesserino 1n , latter refers
tessera 1n , turn translated pass n . However, claritys sake, double
referencing avoided within dictionaries.
Use variant. pattern kind sw sw0 sw00 sw , w00
variant w0 . example, riscontro 6n translated acknowledgment 1n . However,
variant main form acknowledgement 1n . interests consistency
main form always preferred.
Inconsistent spelling. pattern kind sw sw0 sw00 sw
w w0 differ minimal spelling conventions. example, asciugacapelli 1n
translated hair-dryer 1n , hair dryer 1n translated asciugacapelli 1n .
inconsistency hair-dryer hair dryer must solved favour latter,
lemma defined within dictionary.
Table 10 presents patterns form graphs together examples.
Next, collected pattern occurrences Ragazzini-Biagi bilingual dictionary
ranked CQC scores assigned corresponding translation source
155

fiFlati & Navigli

source sense
still 1.A.1

burrasca 1n
achievement 2n
..
.

target sense
immobile A.2

storm 1n
impresa 2n
..
.

CQC score
0.3300
0.3200
0.3100
..
.

phat 1a
opera 5n

grande A.1

society 2n

0.0001
0.0001

Table 11: Top- bottom-ranking dictionary issues identified using misalignment pattern.

issue
misalignment
partial alignment
missing lemma
use reference
use variant
inconsistent spelling

% accepted
80.0
40.0
21.0
84.5
83.5
98.0

no. absolute
118904
8433
15955
167
1123
12

Table 12: Enhancement suggestions accepted.

entry. excerpt top- bottom-ranking issues misalignment pattern
reported Table 11.

7. Evaluation: Dictionary Enhancement
following two subsections describe experimental setup give results
dictionary enhancement experiment.
7.1 Experimental Setup
aim evaluation show higher confidence score higher
importance issue expert lexicographer. Given issue (e.g., misalignment),
foresee two possible actions taken lexicographer: apply change
dictionary entry ignore issue. order assess quality issues, prepared
dataset 200 randomly-sampled instances kind dictionary issue (i.e., 200
misalignments, 200 uses variants, etc.). Overall dataset included 1,200 issue instances
(i.e., 200 6 issue types). dataset manually annotated expert lexicographers,
decided issue whether change dictionary needed (positive response)
(negative response). Random sampling guarantees dataset distribution
comparable entire set instances issue interest.
156

fiCycling Graphs Semantically Enrich Enhance Bilingual Dictionary

suggestions accepted / suggestions presented
1.0
0.9
0.8
0.7
0.6
0.5
0.4

score
0

0.1

0.2

0.3

Figure 6: Performance trend enhancement suggestions accepted score misalignment issue.

7.2 Results
report results issue type Table 12. observed acceptance percentage
ranging 80.0 84.5% three issues, namely: misalignment, use reference use variant, thus indicating high level reliability degree importance
calculated issues. note however semantics cannot much help
case missing lemmas, partial alignment inconsistent spelling. fact issues
inevitably cause graphs disconnected thus disambiguation scores equal 0.
determine whether score-based ranking impacts degree reliability
enhancement suggestions graphed percentage accepted suggestions score
misalignment issue (Figure 6). expected, higher disambiguation score,
higher percentage suggestions accepted lexicographers, 99% score
> 0.27. observed similar trends issues.

8. Synonym Extraction
previous sections, shown use cycles quasi-cycles extend bilingual
dictionary entries sense information tackle important dictionary issues.
propose third application CQC algorithm enrich bilingual dictionary
synonyms, task referred synonym extraction. task consists automatically
identifying appropriate synonyms given lemma. Many efforts made
develop automated methods collect synonyms. Current approaches typically rely either
statistical methods based large corpora fully-fledged semantic networks
WordNet (a survey literature field given Section 10). approach
closer latter direction, relies bilingual machine readable dictionary (i.e.,
resource explicit semantic relations), rather full computational lexicon.
exploit cross-language connections identify appropriate synonyms given
word using cycles quasi-cycles.
157

fiFlati & Navigli

idea behind synonym extraction approach follows: starting
node(s) graph associated given word, perform cycle quasi-cycle
search (cf. Section 4). words encountered cycles quasi-cycles likely
closely related word sense started tend represent good synonym
candidates two languages. adopted two synonym extraction strategies:
sense-level synonym extraction: aim task find synonyms given
sense word w.
word-level synonym extraction: given word w, collect union synonyms
senses w.
cases apply CQC obtain set paths P (respectively starting
given sense w sense w). Next, rank candidate synonym according
following formula:
score(w0 ) =

X
pP (w0 )

1

(5)

elength(p)

provides score synonym candidate w0 , P (w0 ) set (quasi-)cycles
passing sense w0 . sense-level strategy P (w0 ) contains paths starting
sense source word w, whereas word-level strategy P (w0 ) contains paths
starting sense w. contrast approaches literature, synonym
extraction approach actually produces synonyms, also senses according
dictionary sense inventory. Further, thanks formula, able rank
synonym senses less likely. example, given English sense capable1a ,
system outputs following ordered list senses:
Lang.


en
en

en
en
..
.
en


Word sense
abile 1a
capace 2a
able 1a
skilful 1a
esperto A.1

clever 1a
deft 1a
..
.
crafty 1a
destro A.1


Score
13.34
8.50
4.42
3.21
3.03
2.61
1.00
..
.
0.18
0.17

word-level strategy, instead, synonyms found performing CQC search
starting sense word w, thus collecting union paths
obtained individual visit. result output list words
likely synonym candidates. example, given English word capable,
system outputs following ordered list words:
158

fiCycling Graphs Semantically Enrich Enhance Bilingual Dictionary

Lang.


en
en

en
en
..
.

en

Word
abile
capace
clever
able
esperto
skilful
deft
..
.
sapiente
expert

Score
12.00
10.65
3.45
2.90
2.41
2.30
0.54
..
.
0.18
0.16

9. Evaluation: Synonym Extraction
describe experimental setup discuss results synonym extraction
experiment.
9.1 Experimental Setup
9.1.1 Dataset
compare performance CQC synonym extraction existing approaches,
used Test English Foreign Language (TOEFL) dataset provided ETS via
Thomas Landauer coming originally Educational Testing Service (Landauer
& Dumais, 1997). dataset part well-known TOEFL test used evaluate
ability individual use understand English. dataset includes 80 question
items, presenting:
1. sentence target word w emphasized;
2. 4 words listed possible synonyms w.
examinee asked indicate one, among four presented choices,
likely right synonym given word w. examinees language ability
estimated fraction correct answers. performance automated systems
assessed way.
9.1.2 Algorithms
performed experiments algorithms used Section 5.1.4 compared
results best ones known literature. methods based
sort graph path cycle collection. order select best synonym
target word, used approach described Section 8 methods Markov chains
PPR. latter replaced equation 5 corresponding scoring function
method (cf. Section 5.1.4). also compared best approaches synonym
extraction literature, including:
Product Rule (PR) (Turney, Littman, Bigham, & Shnayder, 2003): method
achieves highest performance combines various different modules.
159

fiFlati & Navigli

module produces probability distribution based word closeness coefficient calculated possible answers system output merge rule applied
integrate four distributions single one.
Singular Value Decomposition (LSA) (Rapp, 2003), automatic Word Sense
Induction method aims finding sense descriptors different senses
ambiguous words. Given word, twenty similar words considered good
candidate descriptors. pairs formed classified according two criteria:
i) two words couple dissimilar possible; ii) cooccurrence
vectors sum ambiguous word cooccurrence vector (scaled 2). Finally,
words highest score selected.
Generalized Latent Semantic Analysis (GLSA) (Matveeva, Levow, Farahat, &
Royer, 2005), corpus-based method builds term-vectors represents
document space terms vectors. means Singular Value Decomposition
Latent Semantic Analysis obtain similarity matrix words
prefixed vocabulary extract related document matrix. Next, synonyms
word selected basis highest cosine-similarity candidate
synonym fixed word.
Positive PMI Cosine (PPMIC) (Bullinaria & Levy, 2007) systematically explores
several possibilities representation word meanings space cooccurrence vectors, studying comparing different information metrics implementation details (such cooccurrence window corpus size).
Context-window overlapping (CWO) (Ruiz-Casado, M., E., & Castells, 2005)
approach based key idea synonymous words replaced
contexts. Given two words, similarity measured number contexts
found replacing word other, context restricted
L-window open-class words Google snippet.
Document Retrieval PMI (PMI-IR) (Terra & Clarke, 2003) integrates many
different word similarity measures cooccurrence estimates. Using large corpus
Web data analyze corpus size influences measure performance
compare window- document-oriented approach.
Rogets Thesaurus system (JS) (Jarmasz & Szpakowicz, 2003), exploits Rogets
thesaurus taxonomy WordNet measure semantic similarity. Given two words
closeness defined minimum distance nodes associated
words. work closest structure knowledge resources
exploited extract synonyms.
9.2 Results
Table 13 14 report performance (precision recall, respectively)
algorithms TOEFL maximum path length varying 2 6. best
results obtained algorithms (except Markov chains) = 6, value
makes easier find near synonyms cannot immediately obtained translations
160

fiCycling Graphs Semantically Enrich Enhance Bilingual Dictionary

Algorithm
CQC
Cycles
DFS
Random walks
Markov chains

Maximum path
2
3
4
100.00 97.56 98.15
100.00 97.50 97.83
97.67 97.78 97.82
97.44 95.12 97.56
94.91 86.76 85.29

length
5
98.36
98.00
98.04
97.62
85.29

6
93.15
96.43
96.36
97.83
85.29

Table 13: Precision graph-based algorithms TOEFL dataset.

Algorithm
CQC
Cycles
DFS
Random walks
Markov chains

2
47.50
47.50
52.50
47.50
70.00

Maximum path length
3
4
5
6
50.00 66.25 75.00 85.00
48.75 56.25 61.25 67.50
55.00 56.25 62.50 66.25
48.75 50.00 51.25 56.25
73.75 72.50 72.50 72.50

Table 14: Recall graph-based algorithms TOEFL dataset.

target word dictionary. attribute higher recall (but lower precision)
Markov chains amount noise accumulated steps. Interestingly,
PPR (which independent parameter , therefore shown Tables 13 14)
obtained comparable performance, i.e., 94.55% precision 65% recall. Thus, CQC
best graph-based approach achieving 93% precision 85% recall. result corroborates
previous findings (cf. Section 5).
Table 15 shows results best systems literature compares
CQC.5 note systems performing better CQC exploit large amount
information: example Rapp (2003) uses corpus 100 million words
everyday written spoken language, Matveeva et al. (2005) draw
1 million New York Times articles history label. Even rely
manually-created lexicon, cope extremely high term-space dimension need adopt method reduce dimensionality (i.e., either using Latent
Semantic Indexing term space reducing vocabulary size according
general strategy selecting top frequent words).
easy see work stands lexicon-based ones, raising performance
78.75% 85% recall. Table 15 also report performance lexiconbased approaches literature (Hirst & St-Onge, 1998; Leacock & Chodorow, 1998;
Jarmasz & Szpakowicz, 2003). note system exploits concise edition
Ragazzini bilingual dictionary omits lots translations (i.e., edges) senses
found complete edition dictionary. graph algorithm could
5. information state art TOEFL test found following web
site: http://aclweb.org/aclwiki/index.php?title=TOEFL_Synonym_Questions_(State_of_the_art)

161

fiFlati & Navigli

Algorithm
PR
LSA
GLSA
CQC
PPMIC
CWO
PMI-IR
JS
HSO
PairClass
DS
Human
Random
LC

Author(s) / Method
Turney et al. (2003)
Rapp (2003)
Matveeva et al. (2005)
Flati Navigli (2012)
Bullinaria Levy (2007)
Ruiz-Casado et al. (2005)
Terra Clarke (2003)
Jarmasz Szpakowicz (2003)
Hirst St-Onge (1998)
Turney (2008)
Pado Lapata (2007)
Average non-English US college applicant
Random guessing
Leacock Chodorow (1998)

Resource type
Hybrid
Corpus-based
Corpus-based
Lexicon-based
Corpus-based
Web-based
Corpus-based
Lexicon-based
Lexicon-based
Corpus-based
Corpus-based
Human
Random
Lexicon-based

Recall (%)
97.50
92.50
86.25
85.00
85.00
82.55
81.25
78.75
77.91
76.25
73.00
64.50
25.00
21.88

Table 15: Recall synonym extraction systems TOEFL dataset.

readily take advantage richer structure complete edition achieve even better
performance.
Another interesting aspect ability CQC rank synonym candidates. better
understand phenomenon, performed second experiment. selected 100 senses
(50 language). applied CQC algorithm also
lemmas. former case sense-tagged list returned; latter list contained
words. determined precision CQC retrieving top ranking K
synonyms (precision@K) according algorithms score. performed evaluation
sense- word-level, explained Section 8. Table 16 report
precision@K calculated levels K = 1, . . . , 10. Note that, K sufficiently
small (K 4), sense-level extraction achieves performance similar word-level
one, semantically precise. However, observe larger values K
performance difference increases considerably.

10. Related Work
review literature three main fields dealt paper,
namely: gloss disambiguation (Section 10.1), dictionary enhancement (Section 10.2)
synonym extraction (Section 10.3).
10.1 Gloss Disambiguation
Since late 1970s much work analysis disambiguation dictionary glosses
done. includes methods automatic extraction taxonomies lexical resources (Litkowski, 1978; Amsler, 1980), identification genus terms (Chodorow, Byrd,
& Heidorn, 1985) and, general, extraction explicit information machine162

fiCycling Graphs Semantically Enrich Enhance Bilingual Dictionary

Level

Sense

Word

K
1
2
3
4
5
6
7
8
9
10
1
2
3
4
5
6
7
8
9
10

Precision
79.00
75.50
70.33
67.01
63.41
60.31
59.24
57.01
55.28
53.06
80.00
74.50
71.67
72.50
71.20
68.83
67.29
65.88
64.22
62.90

Correct/Given
79 / 100
151 / 200
211 / 300
266 / 397
312 / 492
354 / 587
404 / 682
443 / 777
482 / 872
512 / 965
80 / 100
149 / 200
215 / 300
290 / 400
356 / 500
413 / 600
471 / 700
527 / 800
578 / 900
629 /1000

Table 16: Precision@K CQC algorithm sense word synonym extraction
task.

readable dictionaries (see, e.g., Nakamura & Nagao, 1988; Ide & Vronis, 1993), well
construction ambiguous semantic networks glosses (Kozima & Furugori, 1993).
relevant project direction MindNet (Vanderwende, 1996; Richardson, Dolan, &
Vanderwende, 1998), lexical knowledge base obtained automated extraction
lexico-semantic information two machine-readable dictionaries.
recently, set heuristics proposed semantically annotate WordNet
glosses, leading release eXtended WordNet (Harabagiu et al., 1999; Moldovan &
Novischi, 2004). Among heuristics, cross reference heuristic closest technique
notion (quasi-)cyclic patterns. Given pair words w w0 , heuristic
based occurrence w gloss sense s0 w0 and, vice versa, w0
gloss sense w. words, cycle s0 length 2 sought. Recently,
similar consideration put forward proposing probabilistic translation circuits
used evidence automatically acquire multilingual dictionary (Mausam et al.,
2009).
Based eXtended WordNet, gloss disambiguation task organized Senseval3 (Litkowski, 2004). notably, best performing systems, namely TALP system
(Castillo et al., 2004), SSI (Navigli & Velardi, 2005), knowledge-based rely
rich knowledge resources: respectively, Multilingual Central Repository (Atserias, Vil163

fiFlati & Navigli

larejo, Rigau, Agirre, Carroll, Magnini, & Vossen, 2004), proprietary lexical knowledge
base (cf. Navigli & Lapata, 2010).
However, literature field gloss disambiguation focused monolingual dictionaries, WordNet LDOCE. knowledge, CQC first
algorithm aimed disambiguating entries bilingual dictionary: key idea
harvest (quasi-)cyclic paths dictionary viewed noisy graph use
associate meanings target translations. Moreover, contrast many
disambiguation methods literature (Navigli, 2009b), approach works bilingual
machine-readable dictionaries exploit lexical semantic relations,
available computational lexicons like WordNet.
10.2 Dictionary Enhancement
issue improving quality machine-readable dictionaries computational
methods poorly investigated far. Ide Vronis (1993, 1994), among others,
working identification relevant issues transforming machinereadable dictionary computational lexicon. include overgenerality (e.g.,
newspaper defined artifact, rather publication), inconsistent definitions (e.g.,
two concepts defined terms other), meta-information labels sense divisions
(e.g., fine-grained vs. coarse-grained distinctions). little work done
automatic improvement monolingual dictionaries (Navigli, 2008), well bilingual resources, gloss rewriting algorithm proposed (Bond, Nichols, & Breen,
2007). However, knowledge, structure bilingual dictionaries never previously exploited purpose suggesting dictionary enhancements. Moreover,
rank suggestions basis semantic-driven confidence scores, thus submitting
lexicographer pressing issues first.
10.3 Synonym Extraction
Another task aimed improving machine-readable dictionaries synonym extraction. Many efforts made automatically collect set synonyms word
interest. introduced various methods aimed task Section 8.
distinguish greater detail corpus-based (i.e., statistical) lexicon-based (or
knowledge-based) approaches.
Corpus-based approaches typically harvest statistical information word occurrences large corpora, inferring probabilistic clauses word w likely appear
(i.e., cooccur) together word probability p. Thus, word similarity approximated word distance functions. One common goal build cooccurrence matrix;
done directly via corpus analysis indirectly obtaining vector space
representation.
widespread statistical method (Turney et al., 2003; Bullinaria & Levy, 2007;
Ruiz-Casado et al., 2005; Terra & Clarke, 2003) estimate word distance counting
number times two words appear together corpus within fixed k-sized
window, followed convenient normalization. approach suffers well-known
data sparseness problem; furthermore introduces additional window-size parameter k
whose value tuned.
164

fiCycling Graphs Semantically Enrich Enhance Bilingual Dictionary

similar statistical approach consists building vocabulary terms V corpus
C representing document means elements V contained therein.
framework document represented vector, corpus term-document matrix L
well document-term matrix L0 . matrix product LL0 represents cooccurrence
matrix gives measure word closeness.
computational reasons, however, often desirable shrink vocabulary size.
Classical algebraic methods, Singular Value Decomposition (SVD), applied
synonym extraction (Rapp, 2003; Matveeva et al., 2005), able produce
smaller vocabulary V 0 representing concept space. methods take
account relative word position, cooccurrences within document, less
information usually considered. hand, virtue SVD, significant
concept space built documents suitably represented.
Lexicon-based approaches (Jarmasz & Szpakowicz, 2003; Blondel & Senellart, 2002)
alternative purely statistical ones. Graph models employed words
represented nodes relations words edges nodes. setting,
corpus required. Instead two words deemed synonyms linking path, any,
satisfies structural criterion, based length, structure connectivity degree.
application CQC synonym extraction problem follows direction. However,
contrast existing work literature, exploit lexical semantic relation
concepts, WordNet, lexical pattern done Wang
Hirst (2012). Further, view synonym extraction dictionary enrichment task
perform bilingual level.

11. Conclusions
paper presented novel algorithm, called Cycles Quasi-Cycles (CQC),
disambiguation bilingual machine-readable dictionaries. algorithm based
identification (quasi-)cycles noisy dictionary graph, i.e., circular edge sequences
(possibly consecutive edges reversed) relating source word sense target one.
contribution paper threefold:
1. show notion (quasi-)cyclic patterns enables state-of-the-art performance
attained disambiguation dictionary entries, surpassing disambiguation approaches (including popular PPR), well competitive baseline
first sense heuristic. Crucially, introduction reversed edges allows us
find semantic connections, thus substantially increasing recall keeping
precision high.
2. explore novel task dictionary enhancement introducing graph patterns
variety dictionary issues, tackle effectively means CQC
algorithm. use CQC rank issues based disambiguation score
present enhancement suggestions automatically. experiments show higher
score relevant suggestion. result, important idiosyncrasies
missing redundant translations submitted expert lexicographers,
review order improve bilingual dictionary.
165

fiFlati & Navigli

3. successfully apply CQC task synonym extraction. data-intensive
approaches achieve better performance, CQC obtains best result among lexiconbased systems. interesting side effect, algorithm produces sense-tagged
synonyms two languages interest, whereas state-of-the-art approaches
focus single language produce sense annotations synonyms.
strength approach lies weakly supervised nature: CQC algorithm
relies exclusively structure input bilingual dictionary. Unlike research
directions, resource (such labeled corpora knowledge bases) required.
paths output algorithm dataset presented Section 5.1 available
http://lcl.uniroma1.it/cqc. scheduling release software package
allows application CQC algorithm resource standard
interface implemented.
regards future work, foresee several developments CQC algorithm
applications: starting work Budanitsky Hirst (2006), plan experiment
cycles quasi-cycles used semantic similarity measure, compare
successful existing approaches. Moreover, although paper focused
disambiguation dictionary glosses, exactly approach applied
disambiguation collocations using dictionary choice (along lines Navigli,
2005), thus providing way enriching lexical knowledge resources external
knowledge.

Acknowledgments
authors gratefully acknowledge support ERC Starting Grant MultiJEDI No.
259234. authors wish thank Jim McManus, Simon Bartels three anonymous
reviewers useful comments paper, Zanichelli making RagazziniBiagi dictionary available research purposes.

References
Agirre, E., Alfonseca, E., Hall, K., Kravalova, J., Pasca, M., & Soroa, A. (2009). study
similarity relatedness using distributional wordnet-based approaches.
Proceedings Conference North American Chapter Association
Computational Linguistics (HLT-NAACL 2009), pp. 1927, Boulder, Colorado, USA.
Agirre, E., & Soroa, A. (2009). Personalizing PageRank Word Sense Disambiguation.
Proceedings 12th conference European chapter Association
Computational Linguistics (EACL 2009), pp. 3341, Athens, Greece.
Amsler, R. A. (1980). structure Merriam-Webster pocket dictionary, Ph.D. Thesis.
University Texas, Austin, TX, USA.
Atserias, J., Villarejo, L., Rigau, G., Agirre, E., Carroll, J., Magnini, B., & Vossen, P.
(2004). MEANING Multilingual Central Repository. Proceedings International Global WordNet Conference (GWC 2004), pp. 2330, Brno, Czech Republic.
Bernard, J. (Ed.). (1986). Macquarie Thesaurus. Macquarie, Sydney, Australia.
166

fiCycling Graphs Semantically Enrich Enhance Bilingual Dictionary

Blondel, V. D., & Senellart, P. P. (2002). Automatic extraction synonyms dictionary.
Proceedings SIAM Text Mining Workshop, Arlington, VA, USA.
Bohman, T., & Thoma, L. (2000). note sparse random graphs cover graphs.
Electronic Journal Combinatorics, 7 (1), 19.
Bond, F. C., Nichols, E., & Breen, J. W. (2007). Enhancing dictionary transfer rule
acquisition. Linguistic Research, 24 (2), 133151.
Brin, S., & Page, M. (1998). Anatomy large-scale hypertextual web search engine.
Proceedings 7th Conference World Wide Web (WWW), pp. 107117, Brisbane,
Australia.
Budanitsky, A., & Hirst, G. (2006). Evaluating WordNet-based measures semantic distance. Computational Linguistics, 32 (1), 1347.
Bullinaria, J. A., & Levy, J. P. (2007). Extracting semantic representations word
co-occurrence statistics: computational study. Behavior Research Methods, 39 (3),
510526.
Castillo, M., Real, F., Asterias, J., & Rigau, G. (2004). TALP systems disambiguating WordNet glosses. Proceedings ACL 2004 SENSEVAL-3 Workshop, pp. 9396,
Barcelona, Spain.
Chodorow, M., Byrd, R., & Heidorn, G. (1985). Extracting semantic hierarchies large
on-line dictionary. Proceedings Association Computational Linguistics (ACL
1985), pp. 299304, Chicago, IL, USA.
Cormen, T. H., Leiserson, C. E., & Rivest, R. L. (1990). Introduction algorithms. MIT
Press, Cambridge, MA.
Cuadros, M., & Rigau, G. (2006). Quality assessment large scale knowledge resources.
Proceedings Empirical Methods Natural Language Processing (EMNLP 2006),
pp. 534541, Sydney, Australia.
Cuadros, M., & Rigau, G. (2008). KnowNet: Building large net knowledge
web. Proceedings 22nd International Conference Computational Linguistics
(COLING), pp. 161168, Manchester, UK.
de Melo, G., & Weikum, G. (2010). Untangling cross-lingual link structure Wikipedia.
Proceedings 48th Annual Meeting Association Computational Linguistics (ACL 2010), pp. 844853, Uppsala, Sweden. Association Computational
Linguistics.
Fellbaum, C. (Ed.). (1998). WordNet: Electronic Database. MIT Press, Cambridge, MA.
Gabrilovich, E., & Markovitch, S. (2009). Wikipedia-based semantic interpretation natural language processing. Journal Artificial Intelligence Research (JAIR), 34, 443
498.
Harabagiu, S., Miller, G., & Moldovan, D. (1999). WordNet 2 - morphologically semantically enhanced resource. Proceedings Special Interest Group Lexicon
Association Computational Linguistics (SIGLEX 99), pp. 18, Maryland,
USA.
167

fiFlati & Navigli

Haveliwala, T. H. (2002). Topic-sensitive PageRank. Proceedings 11th International
Conference World Wide Web (WWW 2002), pp. 517526.
Haveliwala, T. H. (2003). Topic-sensitive pagerank: context-sensitive ranking algorithm
web search. IEEE Transactions Knowledge Data Engineering, 15 (4), 784796.
Hirst, G., & St-Onge, D. (1998). Lexical chains representations context detection
correction malapropisms. Fellbaum, C. (Ed.), WordNet: electronic lexical
database, pp. 305332. MIT Press.
Ide, N., & Vronis, J. (1993). Extracting knowledge bases machine-readable dictionaries: wasted time?. Proceedings Workshop Knowledge Bases
Knowledge Structures, pp. 257266, Tokyo, Japan.
Ide, N., & Vronis, J. (1994). Machine readable dictionaries: learned,
go?. Proceedings COLING 94 International Workshop Directions
Lexical Research, Beijing, China.
Jacquemin, B., Brun, C., & Roux, C. (2002). Enriching text semantic disambiguation
Information Extraction. Proceedings Workshop Using Semantics
Information Retrieval Filtering 3rd International Conference Language
Resources Evaluations (LREC 2002), Las Palmas, Spain.
Jarmasz, M., & Szpakowicz, S. (2003). Rogets thesaurus semantic similarity. Proceedings International Conference Recent Advances Natural Language Processing (RANLP 2003), pp. 212219, Borovets, Bulgaria.
Kozima, H., & Furugori, T. (1993). Similarity words computed spreading activation english dictionary. Proceedings Association Computational
Linguistics (ACL 1993), pp. 232239, Utrecht, Netherlands.
Krovetz, R., & Croft, W. B. (1992). Lexical ambiguity Information Retrieval. ACM
Transactions Information Systems, 10 (2), 115141.
Landauer, T. K., & Dumais, S. T. (1997). Solution Platos Problem: Latent Semantic Analysis Theory Acquisition, Induction Representation Knowledge.
Psychological Review, 104 (2), 211240.
Leacock, C., & Chodorow, M. (1998). Combining local context WordNet similarity
word sense identification. Fellbaum, C. (Ed.), WordNet: electronic lexical
database, pp. 265283. MIT Press.
Lesk, M. (1986). Automatic sense disambiguation using machine readable dictionaries:
tell pine cone ice cream cone. Proceedings 5th Special Interest
Group Design Communication (SIGDOC), pp. 2426, New York, NY.
Lita, L. V., Hunt, W. A., & Nyberg, E. (2004). Resource analysis Question Answering. Proceedings 42th Annual Meeting Association Computational
Linguistics (ACL 2004), Interactive poster demonstration sessions, pp. 162165,
Barcelona, Spain.
Litkowski, K. C. (1978). Models semantic structure dictionaries. American Journal
Computational Linguistics, 81, 2574.
168

fiCycling Graphs Semantically Enrich Enhance Bilingual Dictionary

Litkowski, K. C. (2004). SENSEVAL-3 task: Word-Sense disambiguation WordNet glosses.
Proceedings ACL 2004 SENSEVAL-3 Workshop, pp. 1316, Barcelona, Spain.
Mandala, R., Tokunaga, T., & Tanaka, H. (1998). use WordNet Information
Retrieval. Proceedings COLING/ACL Workshop Usage WordNet Natural
Language Processing Systems, pp. 3137, Montreal, Canada.
Martnez, D., de Lacalle, O. L., & Agirre, E. (2008). use automatically acquired
examples all-nouns Word Sense Disambiguation. Journal Artificial Intelligence
Research (JAIR), 33, 79107.
Matveeva, I., Levow, G., Farahat, A., & Royer, C. (2005). Generalized latent semantic
analysis term representation. Proceedings International Conference
Recent Advances Natural Language Processing (RANLP 2005), Borovets, Bulgaria.
Mausam, Soderland, S., Etzioni, O., Weld, D., Skinner, M., & Bilmes, J. (2009). Compiling
massive, multilingual dictionary via probabilistic inference. Proceedings Association Computational Linguistics International Joint Conference Natural
Language Processing (ACL-IJCNLP 2009), pp. 262270, Singapore.
Mausam, Soderland, S., Etzioni, O., Weld, D. S., Reiter, K., Skinner, M., Sammer, M., &
Bilmes, J. (2010). Panlingual lexical translation via probabilistic inference. Artificial
Intelligence, 174 (9-10), 619637.
Mihalcea, R. (2005). Unsupervised large-vocabulary word sense disambiguation graphbased algorithms sequence data labeling. Proceedings Human Language
Technology Conference Conference Empirical Methods Natural Language
Processing (HLT/EMNLP), pp. 411418, Vancouver, BC.
Moldovan, D., & Novischi, A. (2002). Lexical chains Question Answering. Proceedings
International Conference Computational Linguistics (COLING), pp. 17, Taipei,
Taiwan.
Moldovan, D., & Novischi, A. (2004). Word Sense Disambiguation WordNet glosses.
Computer Speech & Language, 18 (3), 301317.
Nakamura, J.-I., & Nagao, M. (1988). Extraction semantic information ordinary
English dictionary evaluation. Proceedings 12th International Conference Computational Linguistics (COLING), pp. 459464, Budapest, Hungary.
Nastase, V. (2008). Topic-driven multi-document summarization encyclopedic knowledge spreading activation. Proceedings Conference Empirical Methods
Natural Language Processing (EMNLP 2008), pp. 763772, Honolulu, Hawaii.
Nastase, V., & Szpakowicz, S. (2001). Word Sense Disambiguation Rogets Thesaurus
Using WordNet. Proceedings NAACL WordNet Lexical Resources
workshop, pp. 1722, Pittsburgh, USA.
Navigli, R. (2005). Semi-automatic extension large-scale linguistic knowledge bases.
Proceedings Eighteenth International Florida Artificial Intelligence Research Society Conference (FLAIRS), pp. 548553, Clearwater Beach, Florida.
Navigli, R. (2008). structural approach automatic adjudication word sense
disagreements. Journal Natural Language Engineering, 14 (4), 293310.
169

fiFlati & Navigli

Navigli, R. (2009a). Using Cycles Quasi-Cycles disambiguate dictionary glosses.
Proceedings 12th conference European chapter Association
Computational Linguistics (EACL 2009), pp. 594602.
Navigli, R. (2009b). Word Sense Disambiguation: Survey. ACM Computing Surveys,
41 (2), 169.
Navigli, R. (2012). Quick Tour Word Sense Disambiguation, Induction Related
Approaches. Proceedings 38th International Conference Current Trends
Theory Practice Computer Science (SOFSEM 2012), pindlerv Mln, Czech
Republic.
Navigli, R., Faralli, S., Soroa, A., de Lacalle, O. L., & Agirre, E. (2011). Two birds
one stone: learning semantic models Text Categorization Word Sense Disambiguation. Proceedings 20th ACM Conference Information Knowledge
Management (CIKM 2011), pp. 23172320, Glasgow, United Kingdom.
Navigli, R., & Lapata, M. (2010). experimental study graph connectivity unsupervised Word Sense Disambiguation. IEEE Transactions Pattern Anaylsis
Machine Intelligence (TPAMI), 32 (4), 678692.
Navigli, R., & Ponzetto, S. P. (2010). BabelNet: Building large multilingual semantic
network. Proceedings 48th Annual Meeting Association Computational Linguistics (ACL 2010), pp. 216225, Uppsala, Sweden.
Navigli, R., & Velardi, P. (2005). Structural semantic interconnections: knowledge-based
approach Word Sense Disambiguation. IEEE Transactions Pattern Analysis
Machine Intelligence (TPAMI), 27 (7), 10751088.
Pado, S., & Lapata, M. (2007). Dependency-based construction semantic space models.
Computational Linguistics, 33 (2), 161199.
Pedersen, T., Banerjee, S., & Patwardhan, S. (2005). Maximizing semantic relatedness
perform Word Sense Disambiguation. University Minnesota Supercomputing
Institute Research Report UMSI 2005/25, Minnesota.
Ponzetto, S. P., & Navigli, R. (2010). Knowledge-rich Word Sense Disambiguation rivaling
supervised system. Proceedings 48th Annual Meeting Association
Computational Linguistics (ACL 2010), pp. 15221531, Uppsala, Sweden.
Proctor, P. (Ed.). (1978). Longman Dictionary Contemporary English. Longman Group,
UK.
Ragazzini, G., & Biagi, A. (Eds.). (2006). Il Ragazzini-Biagi, 4th Edition. Zanichelli, Italy.
Rapp, R. (2003). Word sense discovery based sense descriptor dissimilarity. Proceedings
Ninth Machine Translation Summit, pp. 315322, New Orleans, LO, USA.
Richardson, S. D., Dolan, W. B., & Vanderwende, L. (1998). MindNet: acquiring structuring semantic information text. Proceedings International Conference
Computational Linguistics (COLING 1998), pp. 10981102, Montreal, Quebec,
Canada.
Roget, P. M. (1911). Rogets International Thesaurus (1st edition). Cromwell, New York,
USA.
170

fiCycling Graphs Semantically Enrich Enhance Bilingual Dictionary

Rosso, P., Molina, A., Pla, F., Jimnez, D., & Vidal, V. (2004). Information retrieval text
categorization semantic indexing. Proceedings Intelligent Text Processing
Computational Linguistics Conference (CICLing), pp. 596600, Seoul, Korea.
Ruiz-Casado, M., A., E., & Castells, P. (2005). Using context-window overlapping synonym discovery ontology extension. Proceedings International Conference
Recent Advances Natural Language Processing (RANLP 2005), Borovets, Bulgaria.
Sanderson, M. (2000). Retrieving good sense. Information Retrieval, 2 (1), 4969.
Silber, H. G., & McCoy, K. F. (2003). Efficient text summarization using lexical chains.
Proceedings 5th Conference Intelligent User Interfaces (IUI), pp. 252255, New
Orleans, USA.
Terra, E., & Clarke, C. (2003). Frequency estimates statistical word similarity measures.
Proceedings 2003 Human Language Technology North American Chapter Association Computational Linguistics Conference (HLT/NAACL 2003), pp.
244251, Edmonton, Canada.
Turney, P. D. (2008). uniform approach analogies, synonyms, antonyms, associations. Proceedings 22nd International Conference Computational
Linguistics (COLING), pp. 905912, Manchester, UK.
Turney, P. D., Littman, M. L., Bigham, J., & Shnayder, V. (2003). Combining independent modules solve multiple-choice synonym analogy problems. Proceedings
International Conference Recent Advances Natural Language Processing
(RANLP 2003), pp. 101110, Borovets, Bulgaria.
Upstill, T., Craswell, N., & Hawking, D. (2003). Predicting fame fortune: PageRank
Indegree?. Proceedings Australasian Document Computing Symposium, pp.
3140, Canberra, Australia.
Vanderwende, L. (1996). analysis noun sequences using semantic information extracted on-line dictionaries, Ph.D. Thesis. Georgetown University, Washington,
USA.
Wang, P., & Domeniconi, C. (2008). Building semantic kernels text classification using
Wikipedia. Proceedings 14th ACM SIGKDD International Conference
Knowledge Discovery Data Mining (KDD), pp. 713721, Las Vegas, Nevada.
Wang, T., & Hirst, G. (2012). Exploring patterns dictionary definitions synonym
extraction. Journal Natural Language Engineering, 18.
Woodsend, K., & Lapata, M. (2011). WikiSimple: Automatic simplification wikipedia
articles. Proceedings Twenty-Fifth AAAI Conference Artificial Intelligence
(AAAI), pp. 927932, San Francisco, California, USA.
Yarowsky, D. (1992). Word-sense disambiguation using statistical models Rogets
categories trained large corpora. Proceedings 14th International Conference
Computational Linguistics (COLING 1992), pp. 454460, Nantes, France.

171

fiJournal Artificial Intelligence Research 43 (2012) 43-86

Submitted 07/11; published 01/12

Robust Local Search Solving RCPSP/max
Durational Uncertainty
Na Fu
Hoong Chuin Lau
Pradeep Varakantham

na.fu.2007@phdis.smu.edu.sg
hclau@smu.edu.sg
pradeepv@smu.edu.sg

School Information Systems,
Singapore Management University,
80 Stamford Road, 178902 Singapore

Fei Xiao

feixiao@gmail.com

Google Inc.
1600 Amphitheatre Parkway Mountain View,
CA 94043 USA

Abstract
Scheduling problems manufacturing, logistics project management frequently modeled using framework Resource Constrained Project Scheduling
Problems minimum maximum time lags (RCPSP/max). Due importance
problems, providing scalable solution schedules RCPSP/max problems
topic extensive research. However, existing methods solving RCPSP/max assume
durations activities known certainty, assumption hold
real world scheduling problems unexpected external events manpower
availability, weather changes, etc. lead delays advances completion activities.
Thus, paper, focus providing scalable method solving RCPSP/max
problems durational uncertainty. end, introduce robust local search
method consisting three key ideas: (a) Introducing studying properties two
decision rule approximations used compute start times activities respect dynamic realizations durational uncertainty; (b) Deriving expression robust
makespan execution strategy based decision rule approximations; (c) robust
local search mechanism efficiently compute activity execution strategies robust
durational uncertainty. Furthermore, also provide enhancements local search
exploit temporal dependencies activities. experimental results illustrate
robust local search able provide robust execution strategies efficiently.

1. Introduction
Research scheduling typically considered problems deterministic durations.
real-world scheduling problems, unexpected external events manpower availability,
weather changes, etc. lead uncertainty durations activities.
growing interest account data uncertainty (Herroelen & Leus, 2005; Beck &
Wilson, 2007; Rodrguez, Vela, Puente, & Hernandez-Arauzo, 2009) providing optimized schedules. paper also focuses important issue durational uncertainty
scheduling problems. specifically, consider scheduling problems
complex resource constraints temporal dependencies activities.
c
2012
AI Access Foundation. rights reserved.

fiFu, Lau, Varakantham, & Xiao

broadly two approaches tackling scheduling problems durational
uncertainty. One adopt hybrid proactive reactive methods, e.g., work
Vonder, Demeulemeester, Herroelen (2007), initial baseline schedule
computed offline, modified (if required) execution reactively based
occurrence external events. second approach, e.g., paper Mohring
Stork (2000), design schedule policies provide online decision rules
time t, policy decides task(s) may start resource(s) assign.
paper, adopt latter approach focus computation robust schedule
policy.
computational perspective, stochasticity adds great deal complexity
underlying deterministic scheduling problem. example, infinite-resource project
scheduling problem processing times two possible discrete values, problem
computing expected makespan (or point cumulative distribution
optimal makespan), #P-hard (Hagstrom, 1988; Mohring,
2001). also shown
P
scheduling problem 1|stoch pj ; dj = d|E[ wj Uj ], problem computing
policy (i.e., execution strategy) maximizing probability job completes exactly
deadline PSPACE-hard (Dean, Goemans, & Vondrak, 2004). Daniels Carrillo
(1997) consider one-machine scheduling problem probabilistic durations,
objective capture likelihood schedule yields actual performance worse
given target level. shown NP-hard even though underlying
deterministic problem solved polynomial time.
concrete problem interest paper Resource Constrained Project
Scheduling Problem minimum maximum time lags (abbrev. RCPSP/max),
great importance manufacturing, logistics project management. Though
problems shown NP-Hard (Bartusch, Mohring, & Radermacher, 1988),
local search based techniques (Demeulemeester & Herroelen, 2002) achieved great
success solving problems. Taking cue recent advancements
robust optimization, propose robust local search method solving RCPSP/max
problem durational uncertainty risk management perspective. precisely,
(a) employ concepts robust optimization compute robust makespan
proven success probability (or risk failure) execution strategy; (b) use
local search methods computing execution strategy seeks minimize robust
makespan.
recent approach (Beck & Wilson, 2007) provides techniques compute robust
baseline schedule risk management perspective, durations activities
modeled random variables. Given value 0 < 1, interested compute schedule minimal (probabilistic) makespan probability successful
execution least 1 realizations durational uncertainty. main
contribution derive lower bound -makespan given schedule
solving deterministic problem. considered Job-shop Scheduling Problem (JSP)
represents special case RCPSP/max (which problem interest
paper).
Unlike JSPs, complex resource constraints activity dependencies
RCPSP/max problems durational uncertainty. account these, compute
execution strategy (also known commonly schedule policy) called Partial Order Schedule
44

fiRobust Local Search Solving RCPSP/max Durational Uncertainty

(POS) instead schedule. combine techniques robust optimization classical
local search compute POS minimizes robust makespan. robust makespan
value probability realized makespan schedule (derived
POS) exceed greater (1 ), realizations uncertainty. Thus,
compute upper bound makespan values opposed lower bound computation
work Beck Wilson (2007).
specifically, make three key contributions paper. Firstly, introduce
two decision rule approximations define expressions start times activities based
random variables used represent durational uncertainties: (a) Segregated Linear
Approximation(SLA) (b) Generalized Non-Linear Approximation (GNLA). Secondly,
derive expressions upper bound robust makespan employing one sided
Chebyshevs inequality decision rule approximations above. Finally, perform local
search execution strategy using robust makespan upper bound. also provide
enhancements consider feedback robustness execution strategies improve
performance local search.
order demonstrate effectiveness methods, evaluate performance
benchmark problem sets RCPSP/max Job-shop Scheduling Problems (JSPs)
durational uncertainty. Furthermore, make house comparison amongst various
enhancements developed paper. Finally, due absence competing algorithms
solving RCPSP/max problems provide indication performance provided
robust local search, compare existing best solver JSPs durational
uncertainty.
next section, present brief background models solution concepts
referred paper. present decision rule approximations Section 3
computation robust makespan upper bound Section 4. detailed description
robust local search enhancements provided Section 5 Section 6. Finally,
experimental setup results provided Section 7.

2. Preliminaries
section, briefly describe notations along scheduling models
robust optimization concepts relevance paper.
2.1 Definitions Notations
given Ben-Tal Nemirovski (2002), also classify variables stochastic
optimization problem 2 types: Adjustable Non-Adjustable variables.
Definition 1. Non-Adjustable variables priori decisions must made
actual realization uncertainty.
Definition 2. Adjustable variables (also known recourse variables) wait-and-see
variables adjust part uncertain data become known.
example, scheduling problem RCPSP uncertain task durations,
non-adjustable variables represent execution policy, e.g., POS proposed
Policella, Smith, Cesta, Oddi (2004), need constructed priori,
45

fiFu, Lau, Varakantham, & Xiao

adjustable variables associated actual start times tasks,
set respect execution policy dynamic realizations uncertainty.
random variable denoted x bold face lower case letters x
represent vectors.
2.2 RCPSP/max
describe deterministic RCPSP/max scheduling problem along extension handle durational uncertainty. also explain execution policy uncertain
duration extension RCPSP/max.
2.2.1 Deterministic RCPSP/max
RCPSP/max problem (Bartusch et al., 1988) consists N activities {a1 , a2 ..., },
activity aj (j = 1, ...N ) executed certain amount time units
without preemption. activity aj fixed duration processing time dj ,
assumed non-negative real number non-negative integer number. addition,
dummy activities a0 +1 d0 = dN +1 = 0 introduced represent beginning
completion project, respectively.
start time schedule ss assignment start times activities a1 , a2 ..., , i.e.
vector ss = (st(a1 ), st(a2 ), ...st(aN )) st(ai ) represents start time activity ai
st(a0 ) assumed 0. Let et(ai ) end time activity ai . Since durations
deterministic preemption allowed,
st(ai ) + di = et(ai ).

(1)

project makespan also start time final dummy activity st(aN +1 )
equals
st(aN +1 ) = maxi=1,...N et(ai ).
(2)
Schedules subject two kinds constraints, temporal constraints resource
constraints. Temporal constraints restrict time lags activities. minimum
time lag Tijmin start time two different activities ai aj says
st(aj ) st(ai ) Tijmin

(3)

Specially, Tijmin = 0 means activity aj cannot started activity ai begins.
maximum time lag Tijmax start time two different activities ai aj says

st(aj ) st(ai ) Tijmax
(4)
Tijmax = 0 means activity aj cannot started activity ai begins.
definition, time lags connect start times two related activities, known
start-to-start time lags. start-to-end, end-to-end, end-to-start time lags easily transformed general start-to-start time lags deterministic case given Bartusch
et al. (1988). schedule ss = (st(a1 ), st(a2 ), ...st(aN )) time feasible, time lag
constraints satisfied start times st(ai ) (i = 1, ...N ).
resource unit reusable available another activity longer used
current activity. type resource limited capacity, Ck (k = 1, 2..., K)
46

fiRobust Local Search Solving RCPSP/max Durational Uncertainty

units. activity ai requires rik units resource type k k = 1, 2..., K. Let
A(t) = {i {1, 2...N }|st(ai ) et(ai )} set activities processed
time instant t. schedule resource feasible time instant t, total demand
resource k exceed capacity Ck , i.e.
X
rik Ck .
(5)
iA(t)

schedule ss called feasible time resource feasible. objective
deterministic RCPSP/max scheduling problem find feasible schedule
project makespan minimized.

Figure 1: Project Instance.

1

time

Figure 2: Example Schedule.

47

fiFu, Lau, Varakantham, & Xiao

Example 1. Figure 1, show simple example deterministic RCPSP problem
special case RCPSP/max precedence constraints (rather arbitrary time lags) activities expository purposes. circle indicates activity
number inside circle representing activity ID. two numbers top
activity represent duration number units resource required
activity. example, 9 activities one type resource, capacity
resource limited 10. noted activities 0 10 dummy activities introduced source sink dependency graph. Arrows activities
represent temporal dependencies. feasible schedule makespan 13 represented
Figure 2.
2.2.2 RCPSP/max Durational Uncertainty Robust Makespan
paper, consider RCPSP/max problems durational uncertainty. duration
activity specified sum mean value deviation: di = d0i + zi , d0i
mean di zi perturbation part expected value 0 standard
deviation . noted irrespective distribution type, always
represent di di = d0i + zi d0i mean zi perturbation part
E(zi ) = 0. addition, also assume random variables, {zi }, corresponding
durational uncertainty independent other.
Similar deterministic RCPSP/max, start-to-start constraints still deterministic. However, unlike deterministic case, types constraints (end-to-start
etc.) cannot converted deterministic start-to-start constraints . Instead equivalent start-to-start constraint stochastic one shown following expressions
end-to-start constraint. noted even though converted constraints
stochastic, techniques still applicable (with minor modifications) types
time lag constraints. robust local search techniques depend computation
maximum sum random variables even stochastic time lag constraints
remains case. paper, purposes exposition, present techniques
assuming temporal dependencies provided start-to-start constraints.
st(aj ) et(ai ) Tijmax
st(aj ) (st(ai ) + di ) Tijmax
st(aj ) st(ai ) Tijmax + di
deterministic setting, start time schedules computed values makespan
used evaluate performance schedule. However, durational uncertainty involved, project makespan becomes random variable schedule
replaced execution strategy. following sections, introduce Partial
Order Schedule (POS) (Policella et al., 2004), serves execution strategy
scheduling project.
Given level risk 0 < 1, goal problem find strategy minimum value (across strategies) robust makespan. define
robust makespan makespan value probability feasible schedule (i.e.
assignment start times activities) instantiated strategy completed
robust makespan least 1 .
48

fiRobust Local Search Solving RCPSP/max Durational Uncertainty

2.2.3 Partial Order Schedule
Partial Order Schedule (POS) first proposed Policella et al. (2004). defined
set activities, partially ordered schedule total activity order
consistent partial order resource time feasible. Mathematically, POS
represented graph node represents activity edges represent
precedence constraints activities. Within POS, activity retains set
feasible start times, provide flexibility respond unexpected disruptions.
POS constructed given RCPSP instance via chaining algorithm (where
one algorithm described below).
1

Figure 3: Example POS
Example 2. Figure 3 provides POS problem instance introduced Example 1.
10 units resource shown left side figure.
unit represents chain. activity require multiple resource units hence
shown multiple resource units. instance, activity 6 shown resource units
4, 7 8. solid arrow activities represents temporal dependency provided
original problem. Solid arrow activities 1 2 one example.
dotted arrow activities represents temporal dependency introduced since
activities executed resource unit. added remove resource
conflict. example dependency introduced activity 2 activity
6. explanatory purposes consider one resource type example, however
general case, exists multiple resource types dependency diagram
every resource type.
2.2.4 Chaining Algorithm
Chaining procedure dispatching activities different resource units (henceforth
referred chains) based temporal resource feasibility. chaining
process, activity allocated one resource chains based number
resource requirement activity. chaining process, activity
scheduled executed resource unit, additional edge (indicating precedence
49

fiFu, Lau, Varakantham, & Xiao

relationship) added last activity selected chain activity
eliminate possible resource conflicts.
following, describe basic chaining algorithm proposed Policella et al.
(2004). algorithm, feasible schedule first obtained using simple greedy heuristic.
Consequently, POS constructed chaining method follows: First, set
activities sorted according start times given feasible solution; Then,
activities allocated different chains order, chain corresponds
unit certain type resource. chain called available activity end time
last activity allocated chain greater start time activity
feasible schedule. activity allocated chain, precedence constraint
activity last activity chain posted. activities
require one unit one types resources, allocated
number chains number equal overall number resource units required
activity.
Example 3. Take Figure 3 example. Given schedule Figure 2 input,activities
first sorted according starting time sequence activities presented
as: (7,1,2,8,3,5,4,6,9). chaining procedure first picks activity 7 randomly allocates
five chains fulfill resource requirement. available chains belonging
dummy activity 0.Thus, five chains 1 5 created posts precedence
relationship current last activity 0 activity 7. Activity 7 becomes last
activity chains. Activity 1 treated way. available chains
activity 2 belonging activity 1. Activity 2 randomly assigned chain 8
10 edge activity 1 activity 2 indicating precedence relationship
added. procedure continues activities dispatched chains number
equals resource requirement, finally chained POS 3 yielded. However,
randomness chaining procedure, activity 6 allocated chains belong
three different activities: activity 2, activity 1 activity 7. tie together
execution three previously unrelated activities: (activity 2, activity 6),(activity 1, activity
6) (activity 7, activity 6), would decrease flexibility execution.
reduce inter-dependencies activities much possible chaining
procedure, Policella, Cesta, Oddi, Smith (2009) developed two heuristics. One direct
advantage approaches synchronization points solution reduced:
Activities require one resource units allocated subset
chains. achieved scanning list available chains last activity
chain : (a) requires multiple resource units; (b) also previously assigned
another resource unit allocated current activity.
Activities precedence constraint defined original problem allocated
set chains. implemented choosing chain last
activity precedence constraint current activity.
Example 4. Figure 4 provides POS computed using mentioned chaining
algorithm RCPSP problem described Example 1. allocating activity 6,
50

fiRobust Local Search Solving RCPSP/max Durational Uncertainty

1

Figure 4: POS computed Removed Synchronization Point
available chains divided two sets: {chain 10, chain 9} {chain 8, chain7,
chain6}. first set contains chains last activity (i.e. activity 5) already
ordered problem definition respect activity 6. chain (for example, chain 10)
randomly chosen set last activity activity 5. Then, remaining
available chains activity 6 redivided two sets: {chain 9} {chain 8, chain7,
chain6}. first set contains chains activity 5 (i.e. last activity first
picked chain) last activity second set remaining. Activity 6 first
allocated chains belonging first subset satisfy remaining resource requirements.
case, synchronization points caused activities 1 6, activities 7 6
allocated different chains disappeared.
2.3 Job-shop Scheduling Problem (JSP) Durational Uncertainty
classical JSP consists set n jobs set machines. job Ji (i = 1, ...n)
consists sequence ni operations denoted Oij (j = 1, ...ni )
processed given order.
P convenience, enumerate operations jobs Ok ,
k = 1, ...N N = nj=1 nj . operation Ok positive duration denoted
dk must executed dedicated machine denoted Mk . operation
started must executed entire duration. operations require
resource overlap execution. Thus, operations partitioned two sets:
job sets resource sets. Job sets referring operations corresponding job
resource sets referring operations require resource.
solution total ordering operations resource set, conflict
job ordering. path solution sequence operations follows
job ordering ordering various resource sets solution s. length
path equal sum durations operations path. makespan
solution make(s) length longest path. minimum makespan
JSP problem defined minimum value makespans solutions, i.e.
mins make(s). operation Ok associated start time st(Ok ) end time
51

fiFu, Lau, Varakantham, & Xiao

et(Ok ). schedule assignment starting times st(Ok ) (k = 1, ...N ) operations
machines. objective find schedule optimizes total makespan
(makespan completion time last operation): maxN
k=1 et(Ok ), also
minimum value longest path solutions. job shop scheduling problem
special case RCPSP resources unary capacity activity (i.e.
operation) consumes one resource.
propagate notations RCPSP/max durational uncertainty
JSP durational uncertainty, i.e. processing time activity (i.e. operation)
dOk modeled sum expected value d0Ok random part zOk : dOk =
d0Ok + zOk . objective find robust makespan given level risk.
2.4 Segregated Random Variables
primitive random variable zk one zero mean. Examples primitive random
variable include U (a, a) (uniform distribution constants a) N (0, )
(normal distribution mean 0 variance 2 ). mentioned earlier, assume
every uncertain distribution equal sum nominal value (mean)
deviation, represented one (or possibly more) primitive random variable z. straight
forward representation, one primitive random variable zk associated
uncertain variable. recent work Chen, Sim, Sun, Zhang (2008), primitive
random variable zk represented 2 segregated random variables zk+ (read z-plus) zk
(z-minus):
z = z + z

(6)

z = max {z, 0}

(7)

+



z = max {z, 0} .

(8)

following Table 1, give examples respective values mean p ,
variance p 2 , 2 segregated variables z + z .
z
U (a, a)
N (0, )

V ar(z)

p 2 , 2

p ,m

a2

5a2
48
(1) 2
2


4

2

3
2

Table 1: Values mean variance segregated variables Uniform
Normal Distribution
underlying assumption use segregated random variables mean
variance individual segregated variables provided random variables
employed. aware mean variance values segregated variables
distributions normal uniform.
2.5 Decision Rules Optimization Data Uncertainty
optimization problems data uncertainty, decision rule specifies dependence
adjustable variables uncertainty parameters non-adjustable variables. Let z
52

fiRobust Local Search Solving RCPSP/max Durational Uncertainty

x denote set primitive random variables non-adjustable variables respectively.
example linear decision rule framework proposed Ben-Tal Nemirovski
(2002), setting value adjustable decision variable S(x, z) assumed
affinely dependent subset N number primitive random variables:
S(x, z) = c0 +

N
X

ck (x)zk

(9)

k=1

ck (x) (1 k N ) coefficient derived x.
Another example segregated linear decision rule framework proposed Chen
et al. (2008), adjustable decision variable
assumed tobe affinely dependent
+

+
set N segregated random variables z1 , z1 , . . . , zN
, zN . Hence, segregated
linear decision rule following general form:
S(x, z) = c0 +



PN

k=1


+

c+
z
+
c
z
k k
k k .

(10)

show below, segregated linear decision rule allows us easily obtain upper
bound subset random variables (see Eqn 14), possible linear
decision rule framework proposed Ben-Tal Nemirovski (2002).
Given mean variance segregated variable E(zk+ ) = E(zk ) = k ,
2
2
, express expected value variance
V ar(zk ) = mk
V ar(zk+ ) = pk
adjustable variable as:
E[S(x, z)] = c0 +

N
X



c+
k k + ck k



(11)

k=1

N n

X
+ 2
2

V ar[S(x, z)] =
ck pk + ck mk 2c+
.
c

k
k k

(12)

k=1

3. Decision Rules RCPSP/max Durational Uncertainty
RCPSP/max durational uncertainty, decision rule specifies dependence
activity start times durational uncertainty associated activities. make
comparison Equation 9, x represents POS generated; tasks start
time associated adjustable variable S(x, z), c0 represents earliest start
time task POS, ck (x) encodes task k related task
POS.
scheduling context, start time activity dependent start times
preceding activities, i.e. Adjustable variables S(x, z) dependent one another.
activity either start end activity (i.e. series) end
multiple activities occurring simultaneously (i.e. parallel). Thus, adjustable variables
functions adjustable variables addition operator (to model serial
activities) and/or maximum operator (to model parallel activities).
53

fiFu, Lau, Varakantham, & Xiao

Given number adjustable variables, may express sum adjustable
variable form segregated linear decision rule follows:
PM
=

i=1 Si (x, z)
PM 0 PN nPM + +
i=1 ci +
k=1
i=1 ci,k zk

+

PM


i=1 ci,k zk


.

(13)

Similarly, given set C adjustable variables, may also express upper bound
maximum variables adjustable variable form segregated
linear decision rule:
maxiC {Si (x, z)}
n
P
n

P
N


+
+
maxiC {c0i } + N
max
{c
}z
+
max
{c
}z
.
iC
iC
k=1
k=1
i,k k
i,k k

(14)

specifically, output solving RCPSP/max involves POS represented
graph activities vertices precedence constraints activities
edges. Given POS graph, x = (V, E), V set activities E set
temporal dependencies (an edge (u, v) represents temporal dependency states
activity v occur activity u). activity v V , decision rule
computing start time defined recursively follows:
Sv (x, z) = max {d0u + zu + Su (x, z)}.
(u,v)E

(15)

Equation 15 recursive expression defined combination sum maximum set random variables. noted combinations sum maximum random variables cannot computed exactly hence present two operational
decision rule approximations evaluate recursive expression Equation 15: (a) Segregated Linear Approximation(SLA); (b) General Non-Linear Approximation(GNLA).
noted Sv computable long mean variance Su computable
demonstrated approximations.
3.1 Segregated Linear Approximation (SLA)
decision rule, duration activity defined based segregated random
variables introduced Section 2.4. uncertain duration mean processing
time d0 , represent sum three components: mean d0 , lateness z + (i.e.
0}),
max{d d0 , 0}), earliness z (i.e. max{d0 d,
= d0 + z + z .

(16)

normally distributed duration, i.e., z N {0, }, respective values mean
variance segregated variables summarized as:

E[z + ] = E[z ] =
2
( 1) 2
V ar[z + ] = V ar[z ] =
.
2
54

(17)
(18)

fiRobust Local Search Solving RCPSP/max Durational Uncertainty

describe computation Sv (x, z) representing durational uncertainty
activities using segregated random variables. Upper bounds sum maximum
random variables derived linear functions segregated variables illustrated
below:
Sum random variables : case project network involving k activities,
two either precedence constraints competing
resource units, solution form POS requires computation sum
activity durations. start time activity starting k-activity project
expressed as:
P
Sk (x, (z+ , z )) = ki=1 (d0i + zi+ zi ).
(19)
P
Thus, adjustable variable Sk mean ki=1 d0i uncertainty captured
Pk
+
random variable, positive segregated component
i=1 zi
Pk

negative segregated component
i=1 zi . Mean variance segregated
variables known hence mean variance Sk easy compute.
Max random variables: Consider activities executed concurrently,
upper bound start time activity starting parallel k-activity
project network SLA represented linear function positive segregated
components duration perturbations:
P
(20)
Sk (x, (z+ , z )) maxi=1,...k {d0i } + ki=1 zi+ .
Thus, adjustable variable Sk upper bound mean maxi=1,...k {d0i }
uncertainty
P captured random variable positive segregated component given ki=1 zi+ negative segregated component. Mean variance
segregated variables known hence mean variance Sk easy
compute.
Since, cases (sum max) Sk expressed linearly subset random segregated variables, recursive computation straightforward. Compared linear
decision rules (Ben-Tal & Nemirovski, 2002), superiority SLA (Chen et al., 2008) lies
ability linearly express upper bound subset random variables dissecting uncertainty positive negative components. approximation
increases tractability scalability, comes expense losing accuracy.
3.2 General Non Linear Approximation (GNLA)
SLA efficient, typically provide loose upper bounds robust makespan
due linear approximation computing max random variables. section,
describe General Non Linear Approximation (GNLA), restricted
affine dependencies. clarity comparison purposes, use G denote start
time instead used SLA.
Given mean variance values duration uncertainty, describe approximation involved computing mean variance sum max activities
55

fiFu, Lau, Varakantham, & Xiao

used Equation 15. recalled irrespective distribution
always represent = d0 + z, d0 mean
uncertain duration d,
z perturbation part. Thus, E(z) = 0.
3.2.1 Sum Random Variables
compute sum stochastic durations serial k activity project network follows:
Gk (x, z) =

k
X

(d0i + zi ).

(21)

i=1

case, similar representation SLA. Mean variance Gk computed
follows:
Since {zi }i=1,...k random variables zero mean, calculate expected
value as:
k
k
X
X
0
E[ (di + zi )] =
d0i .
i=1

(22)

i=1

{zi } assumed independent other, variance value computed
following expression:
k
k
X
X
0
V ar[ (di + zi )] =
V ar[zi ],
i=1

(23)

i=1

normal distribution zi N (0, ),
k
k
X
X
V ar[ (d0i + zi )] =
i2 .
i=1

(24)

i=1

Note expressions expected value variance case serial activities
identical ones used Wu, Brown, Beck (2009).
3.2.2 Max Random Variables
ease explanation, begin considering two activities executed parallel
extend analysis multiple parallel activities. GNLA, (unlike SLA)
max random variables approximated expected value variance
max approximately calculated.
Expected Value Variance Max Two Variables
decision rule represent starting time activity, begin
completion two parallel activities defined as:
G2 (z) max{d01 , d02 } + max{z1 , z2 }.
Note tighten bound Eqn 20 replacing z1+ + z2+ max{z1 , z2 }.
56

(25)

fiRobust Local Search Solving RCPSP/max Durational Uncertainty

derive expressions expected value variance adjustable variable,
i.e., RHS term Eqn 25. Firstly, focus expected value:
E[max{d01 , d02 } + max{z1 , z2 }] = max{d01 , d02 } + E[max{z1 , z2 }].

(26)

general case, difficult derive exact expression E[max{z1 , z2 }] hence,
provide upper bound.
following Propositions 1 2, compute expected value variance
general case E(z) 0 (note assume E(z) = 0 primitive random variables). calculate general case required computation
expected value variance two random variables (next subsection).
Proposition 1. expected value maximum two general distributions, z1
z2 nonnegativepmeans less
1
1
V ar[z1 ] + V ar[z2 ] + (E[z1 ])2 + (E[z2 ])2 .
2 (E[z1 ] + E[z2 ]) + 2
Proof. begin considering following two equalities:
max{z1 , z2 } + min{z1 , z2 } = z1 + z2
max{z1 , z2 } min{z1 , z2 } = |z1 z2 |.
sum two equalities.
1
max{z1 , z2 } = (z1 + z2 + |z1 z2 |).
2

(27)

Thus, compute expected value maximum using following equation:
1
E[max{z1 , z2 }] = (E[z1 ] + E[z2 ] + E|z1 z2 |).
2

(28)

addition, using definition variance, obtain:
V ar|z1 z2 | = E(z1 z2 )2 (E|z1 z2 |)2 0.
Therefore,
p
E|z1 z2 | p E(z1 z2 )2
= pE(z12 ) + E(z22 ) 2E(z1 )E(z2 )
pE(z12 ) + E(z22 )
= V ar[z1 ] + V ar[z2 ] + E(z1 )2 + E(z2 )2 .
Substituting final expression Eqn 29 Eqn 28 yields bound
p
E[max{z1 , z2 }] 12 (E[z1 ] + E[z2 ]) + 12 V ar[z1 ] + V ar[z2 ] + (E[z1 ])2 + (E[z2 ])2 .

(29)

(30)

Hence proof.
Note paper, assume E(z) = 0, thus, tighter bound obtained
Eqn 30:
p
(31)
E[max{z1 , z2 }] 21 V ar[z1 ] + V ar[z2 ].
57

fiFu, Lau, Varakantham, & Xiao

special case {zi } (i = 1, ...k) normally identically distributed,
i.e. zi N (0, ), know work Clark (1961) closed form
representation expected value maximum k = 2:

E[max{z1 , z2 }] = .

focus deriving expressions variance maximum two general
distributions, i.e., V ar[max(z1 , z2 )].
Proposition 2. variance maximum two general distributions, z1 z2
nonnegative means less V ar(z1 ) + V ar(z2 ) + 21 (E(z1 ))2 + 12 (E(z2 ))2 .
Proof. Eqn 27,
V ar[max(z1 , z2 )] = 41 V ar[z1 + z2 + |z1 z2 |]
= 14 (V ar[z1 + z2 ] + V ar|z1 z2 | + 2COV
p (z1 + z2 , |z1 z2 |))
1
4 (V ar[z1 + z2 ] + V ar|z1 z2 | + 2 V ar[z1 + z2 ]V ar|z1 z2 |)
12 (V ar[z1 + z2 ] + V ar|z1 z2 |).

(32)

Firstly, consider following two equations.
V ar|z1 z2 | = E(z1 z2 )2 (E|z1 z2 |)2
2

(33)

2

V ar(z1 z2 ) = E(z1 z2 ) (E(z1 z2 ))
Subtracting second first yields

V ar|z1 z2 | = V ar(z1 z2 ) + (E(z1 z2 ))2 (E|z1 z2 |)2 .
Now, substitute expression last term Eqn 32 obtain:
V ar[max(z1 , z2 )] V ar(z1 ) + V ar(z2 ) + 12 (E(z1 ) E(z2 ))2 21 (E|z1 z2 |)2 .

(34)

specific distribution duration perturbation known, obtain
bound V ar[max(z1 , z2 )] as:
V ar[max(z1 , z2 )] V ar(z1 ) + V ar(z2 ) + 12 (E(z1 ))2 + 12 (E(z2 ))2 .

(35)

Hence proof.
Note paper, assume E(z) = 0, thus, tighter bound obtained
Eqn 35:
V ar[max(z1 , z2 )] V ar(z1 ) + V ar(z2 ).
(36)
interesting consider special case random variables normally
distributed. first state following lemma1 .
1. found statistics texts, found online http://en.wikipedia.org/wiki/Halfnormal distribution.

58

fiRobust Local Search Solving RCPSP/max Durational Uncertainty

Lemma 3.1. X normally distributed X N (0, ), = |X| half-normally
distributed,
r
2
E(Y ) =
.
(37)

normal distribution zi N (0, ), since z1 z2 also normally distributed,
z1 z2 N (0, 1 + 2 ), conclude Lemma 3.1 |z1 z2 | follows half-normal
distribution
r
2
E|z1 z2 | = (1 + 2 )
.
(38)

Thus, substitute expression Eqn 34, express upper bound
variance value maximum duration perturbation two activities, zi N (0, )
:
V ar[max(z1 , z2 )] (1

2
1
)( 2 + 22 ) 1 2 .
1


(39)

Expected Value Variance Max Multiple Variables
Extending two k (k > 2) parallel activities, completion time upper
bounded by:
Gk (z) max {d0i } + max {zi }.
(40)
i=1,...k
i=1,...k
following, first compute variance value RHS term
use similar procedure compute expected value. basic expression variance
RHS is:
V ar[ max {d0i } + max {zi }] = V ar[ max {zi }].
(41)
i=1,...k

i=1,...k

i=1,...k

obtain value V ar[ max {zi }] general probability distributions, take
i=1,...k

advantage analysis provided two-parallel-activity case above. following
steps outline overall idea:
(a) Firstly, group activity set {a1 , ..., ak } couple set {C1 , ..., Cd k e },
2

element Cj (j = 1, ...d k2 e) contains two different activities Cj = {aj1 , aj2 } chosen
activity set. Note k odd, final element couple set contains
one activity.
(b) couple Cj , apply maximum operator duration perturbations involving activities. Denote cj = max{zj1 , zj2 }, zj1 zj2 duration perturbations
two activities involved Cj , V ar(cj ) calculated based expression
two-parallel-activity case.
(c) max {zi } = max {cj }. (Note one activity contained
i=1,...k

j=1,...d k2 e

Cd k e k odd). Then, build another couple set {C1 , ..., Cd k e },
2
2
method steps (1) (2) used compute V ar[ max {cj }] based
j=1,...d k2 e

Eqn 35 and/or Eqn 36 and/or Eqn 39.
59

fiFu, Lau, Varakantham, & Xiao

numerous ways (exponential k) generating couple set {C1 , ..., Cd k e }
2
k activities parallel. couple sets lead different levels tightness
derived robust makespan. compute grouping provides best robust fitness
random variables generic distributions open problem. Instead, focus
heuristic computes best grouping normal distribution zi N (0, ).
obtained solving following optimization problem:
X
max
j1 j2

(42)
k
j=1,...b 2 c

denotes grouping technique also decision variable; {Cj } couple
set constructed activity set grouping method t; j1 j2 standard
deviations data perturbation durations activities contained Cj . intuition
employing optimization problem obtained Equation 39. noted
computing tighter bound variance implies considering highest possible value
product primitive variances. Hence, reason employing optimization
problem Equation 42.
Proposition 3. solution optimization problem Eqn 42 obtained
ordering k activities non-increasing order variance values grouping
two nearest activities according order, i.e. Cj = {aj1 , aj2 }, j = 1, ...b k2 c
standard deviations following order:
11 12 21 22 , ...b k c1 b k c2 .
2

2

(43)

Proof. Suppose another grouping method t0 , elements couple
set except two couples 2 ordering different, i.e., Cm =
{am1 , an2 } Cn = {am2 , an1 } (m 6= n), Cm = {am1 , am2 } Cn = {an1 , an2 }
. Without loss generality, assume > n Eqn 43,
m1 m2 n1 n2 .

(44)

Since t0 supposed provide solution less ( defined Eqn 42) ,
i.e.
11 12 + ... + m1 n2 + ... + n1 m2 + ... + b k c1 b k c2
2
2

11 12 + ... + m1 m2 + ... + n1 n2 + ... + b k c1 b k c2 .
2
2
Therefore,
m1 n2 + n1 m2 m1 m2 + n1 n2 ,
equivalent to: (m1 n1 )(n2 m2 ) 0.
contradicts Eqn 44 (except case standard deviations equal,
case mixing order affect anything). Thus, exists t0
different least two couples better objective value. general case
2. noted ordering change one couple, method still produces
solution within couple variance computation consider order.

60

fiRobust Local Search Solving RCPSP/max Durational Uncertainty

t0 multiple (more two) couples different easily derived
case (and omitted due space constraints).
Hence proof.
analyzing expected value E[ max {zi }], apply procedure emi=1,...k

ployed calculate variance, i.e., based group solution returned
optimization problem, first calculate expected value couple then, get
final bound following Eqn 30 and/or Eqn 31 and/or Eqn 32.
present, unable show effectivness grouping heuristic (Equation 42) analytically general case. However, show intuition behind
grouping heuristic providing analytical comparison3 example
four activities (normally distributed durations) executed parallel, i.e. zi N (0, ),
assume 1 2 3 4 (no loss generality).
representation makespan grouping heuristic (denoted Mheu )
random grouping (denoted Mran ) are, respectively:
Mheu = max{d01 , d02 , d03 , d04 } + max{max{z1 , z2 }, max{z3 , z4 }}
Mran = max{d01 , d02 , d03 , d04 } + max{max{z1 , z4 }, max{z2 , z3 }}.
Let us first examine mean variance values Mheu . Eqn 31,
p
E(max{z1 , z2 }) 12 p12 + 22
E(max{z3 , z4 }) 12 32 + 42 .

(45)

(46)

Eqn 39,
V ar[max(z1 , z2 )] (1 1 )(12 + 22 ) 2 1 2
V ar[max(z3 , z4 )] (1 1 )(32 + 42 ) 2 3 4 .

(47)

Eqn 30, Eqn 35, Eqn 46 Eqn 47, obtain bounds mean variance
values Mheu 4 :
q
p
p
P
1
1
2
2
2
2
E(Mheu ) const + 4 ( 1 + 2 + 3 + 4 ) + 2 ( 45 1 ) 4i=1 i2 2 (1 2 + 3 4 )
(48)
P
V ar(Mheu ) ( 98 1 ) 4i=1 i2 2 (1 2 + 3 4 ).
Similarly, mean variance values Mran also calculated,
q
p
p
P
E(Mran ) const + 14 ( 12 + 42 + 22 + 32 ) + 12 ( 54 1 ) 4i=1 i2 2 (1 4 + 2 3 )
(49)
P
V ar(Mran ) ( 89 1 ) 4i=1 i2 2 (1 4 + 2 3 ).
Eqn 57, bounds fitness Mheu (denoted F itheu ) Mran (denoted
F itran ) respectively represented function RHS Eqn 48 Eqn 49.
examine difference value two bounds, F itheu F itran . Let us first
compare first term RHS mean values Eqn 48 Eqn 49, since
p
p
p
p
2
2
2
( p
32 + 42 )2 ( 12 + p
22 + 32 )2
1 + 2 +
4 +
(50)
2
2
2
2
2
2
2
2
2
2
= 2 1 3 + 2 4 + 1 4 + 2 3 2 1 3 + 22 42 + 12 22 + 32 42
3. calculation use robust fitness function provided Definition 57 introduced Section 4.
4. Note const Eqn 48 Eqn 49 max{d01 , d02 , d03 , d04 }.

61

fiFu, Lau, Varakantham, & Xiao

Proposition 3,
1 4 + 2 3 1 2 + 3 4 ,

(51)

12 42 + 22 32 (12 22 + 32 42 ) = (1 4 + 2 3 )2 (1 2 + 3 4 )2 0.

(52)

thus,

Eqn 51, Eqn 52, Eqn 48 Eqn 49, bounds mean variance
values Mheu lower Mran . Given robust fitness function Eqn 57,
conclude
F itheu F itran 0

(53)

independent . words, grouping heuristic provide tighter
fitness bound random grouping.

4. Robust Fitness Function
makespan (start time dummy sink activity) RCPSP/max durational uncertainty function non-adjustable variables x random variables representing durational uncertainty z represented using S(x, z) SLA G(x, z)
GNLA. Recall robust optimization problem find minimum value F
following probability bound observed5 :
P (S(x, z) F ) (1 )

(54)

one-sided Chebyshevs Inequality, obtain bound robust objective value F function expected value variance adjustable fitness
function, i.e.:
q
q
(55)
V ar[S(x, z)] F P (S(x, z) F ) (1 )
E[S(x, z)] + 1

Hence, reformulate robust optimization problem follows:
min F
s.t.

E[S(x, z)] +

q

q
1


V ar[S(x, z)] F

(56)

model, derive robust fitness function used
local search framework:
Definition 3. Given 0 < 1 adjustable fitness function S(x, z) defined above,
robust fitness function, f (x, z, ), defined
r
q
1
f (x, z, ) = E[S(x, z)] +
V ar[S(x, z)]
(57)

goal local search mechanism find local minima f . addition, local
search typically requires fitness function computed many times hence
imperative computation fitness function efficient.
5. show computation SLA robust fitness function. substituting G, obtain
fitness function GNLA.

62

fiRobust Local Search Solving RCPSP/max Durational Uncertainty

4.1 Schedule Infeasibility Given POS
noted fitness function, f assumes schedule generated
POS, x always executable. However, due durational uncertainty maximum
time lags, schedule always executable. direct way measure IP r(POS)
probability infeasibility POS (i.e. probability POS lead infeasible schedule) lies computation probability infeasibility activity ai
IP r(ai ), exist feasible start time temporal constraints
respect ai satisfied. IP r(POS) calculated probability
least one activity infeasible. However, due temporal dependencies activities
providing theoretical expression overall probability infeasibility open problem. Therefore, propose simulation approach, simulate POS execution
multiple trials compute probability eciently approximately. illustration,
experimented benchmark J10 instances PSPLib (Kolisch, Schwindt,
& Sprecher, 1998) RCPSP/max additional durational uncertainty follows
normal distribution mean 0 variance 1. generated 1000 sample realizations
POS obtained SLA, check infeasibility respect original temporal
(including maximum time lag) constraints. Examples probability infeasibility
obtained simulation PSP1, PSP4, PSP13 0.18, 0.17 0.001. However,
problems PSP3, PSP5 etc. probability infeasibility 0,
maximal time lags much larger variance durational uncertainty.

5. Robust Local Search Algorithm
section present decision rule approximations introduced SLA, GNLA
integrated robust fitness function local search mechanisms provide
solution problems represented RCPSP/max durational uncertainty.
proposed algorithm outlined follows. Steps 1, 2, 5 6 standard steps local
search algorithm. Steps 3 4 represent departure standard local search deal
uncertainty.
1. Generate initial solution
usually obtained using simple greedy heuristic.
2. Generate neighborhood solutions
Generate pool neighbor solutions current solution.
3. Employ one decision rule approximations (SLA GNLA)
adjustable variables check feasibility
candidate solution x solution pool, derive coefficients Ck (x)
adjustable variable. Subsequently, solution check constraint violation
reject feasible.
4. Evaluate robust fitness function f
feasible solution x, evaluate f obtain robust objective values.
solution lowest robust objective value current best robust solution.
63

fiFu, Lau, Varakantham, & Xiao

5. Apply penalty (optional)
advanced local search strategies may require penalty applied prevent
caught local minima. case tabu-search example,
tabu-list updated tabu move applied. case iterated local search,
perturbation move applied current local minima.
6. Termination criteria
termination criteria met, return solution lowest robust fitness
function value else repeat optimization cycle determining next move.
Algorithm 1 provides robust local search algorithm guided decision rule using
, , G , G , G , obtain local search algoSLA. substituting Snow

min
min
rithm using GNLA. Given RCPSP/max durational uncertainty level risk
(0 < 1), algorithm returns POS (locally) minimal robust makespan,
(or G GNLA). essence, perform robust local search neighborhood set
activity lists. activity list (al) defined precedence-constraint feasible sequence
used heuristics generate earliest start time schedules solving standard
RCPSP problem (Kolisch & Hartmann, 2005).
Different activity lists explored local moves. context, consider
activity list sequence activities satisfy non-negative minimal time lag
constraint. Due existence maximal time lag constraint RCPSP/max, scheduling
activities earliest possible start time based order position activity list
may restrict schedule much may even return feasible schedule. Thus,
schedule activity sequentially based order position activity list,
assign starting time randomly picking time domain feasible start
times.
According experiments, new randomized approach returns feasible
solutions earliest start time one. finding feasible schedule, POS
generated applying chaining procedure proposed Policella et al. (2004). Then,
(or G GNLA) value computed according POS. Intuitively, using
randomized approach may return schedule large baseline scheduled completion
time. However, apply shortest path algorithm resulting POS generate
earliest start time schedule smaller makespan.
mentioned above, may difficult find feasible schedule satisfies minimal
maximal time lag constraints using activity list. fact, believe set
activity lists, many may yield feasible schedule. overcome problem
follows. define set activity lists result feasible (or infeasible) schedules
F (or I). seek design local search algorithm following characteristics:
a) Starting activity list I, local search move activity list F
within short time. b) Starting activity list F , local search move
activity list minimal (or G GNLA)value. c) also diversify
exploration activity lists F allowing local search move activity list
F activity list I, since activity lists F region may reachable
one another simple local moves. flavor strategic oscillation proposed
meta-heuristics research.
64

fiRobust Local Search Solving RCPSP/max Durational Uncertainty

Algorithm 1 Robust Local Search
1: Generate activity list al randomly
2: Find start time schedule, ss randomly according al
3: al F
4:
P OS chaining(ss)

Compute Snow
according P OS
5:


6:
Update Smin Snow
7: else
8:
Record first activity cannot scheduled
9: end
10: 1 Max Iteration
al
11:
12:
Shift activity ahead al randomly al
else
13:
14:
Select two activities b c al randomly
15:
Swap b c al al
16:
end
17:
Find randomized start time schedule ss0 according al
18:
al0 F
P OS 0 chaining(ss0 )
19:
20:
Compute according P OS 0

21:
al Snow



22:
Snow
23:
al al0

24:
Smin



Smin
25:
26:
end
27:
end
28:
else al
29:
al al0
30:
else
31:
p rand(0, 1)
p < 0.01
32:
33:
al al0
34:
Record first activity cannot scheduled
35:
end
36:
end
37: end

65

fiFu, Lau, Varakantham, & Xiao

detailed robust local search procedure given Algorithm 1. procedure starts
randomly generating activity list al, sequence activities satisfy
non-negative minimum time lag constraint (Line 1). Line 2, schedule ss produced
based ordering activities activity list al. first perform domain reduction
distance graph using Floyd-Warshall algorithm, feasible range
start time activity based temporal constraints obtained.
schedule activity sequentially based order position activity list.
activity, first pick start time randomly feasible domain evaluate resource
constraints duration activity (i.e. check current resource capacity exceeds
resource amount used activity). yes, set start time activity,
run shortest path algorithm reduce domains remaining activities, update
current resource capacity due consumption activity. resource constraints
satisfied, try set start time randomly prescribed maximum
numbers retries. start time current activity set, proceed iteratively
next activity according activity list. Line 4, chaining() employed
generate POS baseline schedule (section 2.2.4). ax Iteration refers
maximum number iterations robust local search. apply two different types
local moves. converge quickly activity list F, first local move designed
schedule activity causing temporal resource conflict earlier time.
randomly shift ahead first activity cannot scheduled current
activity list (Line 12). activity list F, second local move randomly
pick two activities swap current activity list, satisfying nonnegative minimal time lag constraints (Line 14-15). move accepted, results
smaller equal value (Line 18-29). explore different activity lists, include
small probability accept move leads infeasible schedule (Line 31-35).
probability move activity list F one set 0.01. minimal
.
value saved Smin

worst-case computational complexity analysis given follows. iteration
local search, three major components: randomized schedule generation, POS
construction fitness calculation. process randomized schedule generation,
perform domain reduction resource checking iteration, thus complexity
O(N (N 3 + H K w)) N number activities, H maximum planning
horizon, K number types resources, w prescribed maximum number
retries activity setting randomized start time. POS construction
process works follows: set activities first sorted according start times
generated deterministic schedule sorting part costs O(N logN );
proceeds allocate activity total units needed type resource. Let
maxcap maximum capacity among resources. cost computing POS
O(N logN + N K maxcap ). determining fitness value generated
POS, examine edge edge check connected parallel serial
respect predecessors costs O(N + e) e number edges POS
(e < N 2 ). Thus, worst-case complexity proposed robust local search algorithm
O(T N (N 3 + H K w + K maxcap )) number iterations local search.
66

fiRobust Local Search Solving RCPSP/max Durational Uncertainty

6. Enhancing Robust Local Search
section, describe two enhancements improve basic local search method
described Section 5. Firstly, describe ordering generation, pre-processing
step used identify precedence ordering activities. precedence ordering
used focus local search activity lists. Secondly, describe new chaining
method generate POS feasible schedule.
6.1 Ordering Generation
Ordering Generation pre-processing step identifies precedence relationships
pairs activities. key idea certain pairs activities, always better
(with respect robust makespan) ordering among activities. goal
identify pairs activities employ ordering focus local search
activity lists chaining method used compute POS feasible schedule.
deciding ordering pair activities, b, two key steps:
(i) Sample set generation: Generate two sets activity lists. first set consists
activity lists occurs b. second set generated swapping activities
b every activity list first set; (ii) Order determination: step, first
compute POS robust makespan activity lists two sets. comparing
robust makespan values corresponding activity lists two sets, determine
ordering activities. explain steps following subsections.
problem n activities, Cn2 pairs activities. decide
orders pairs, ordering computation needs implemented Cn2 times,
computationally expensive. Based observation, first propose PairsSelection heuristic selectively choose certain number activities pairs whose ordering
significant impact robust makespan.
Pairs-Selection heuristic picks activity pair: (a) precedence related
original problem definition; (b) exists least one type resource,
total demand activities exceeds resource capacity. intuition behind
picking activity pair two activities cannot executed parallel
deciding ordering relationship imperative eliminate resource conflict. One main
advantage heuristic number pairs activities need ordered
significantly reduced. Now, describe two steps ordering generation below:
6.1.1 Sample Set Generation
first randomly generate activity lists initial sample set denoted .
element activity list represented ali sequence activities,
= 1, ...m, i.e.
= {ali |ali = (a1 , a2 , ...an ), {1, ...m}}.
pair activities (ak , al ) resulting Pairs-Selection heuristic, define
two sample sets represented ak al al ak . ak al activity lists
, except activity list al ak , activities swapped.
ak al = {aliak al |i {1, ...m}},
67

fiFu, Lau, Varakantham, & Xiao

(
(a1 , a2 , ..., ak , ...al , ...an ) ali = (a1 , a2 , ..., al , ...ak , ...an )
.
aliak al =
ali
ali = (a1 , a2 , ..., ak , ...al , ...an )
Similarly, al ak constructed incrementally selecting activity list
initial set al ak reverse order ak al , i.e.
al ak = {alial ak |i {1, ...m}},
(
(a1 , a2 , ..., al , ...ak , ...an ) ali = (a1 , a2 , ..., ak , ...al , ...an )
alial ak =
.
ali
ali = (a1 , a2 , ..., al , ...ak , ...an )
Thus, activity list sample set ak al share positions activities
except ak al corresponding activity list set al ak , al precedes ak .
6.1.2 Order Determination
determine activity order selected pair activities based sample
sets obtained last phase. pair (ak , al ), construct new instance posting
precedence constraint ak al al ak original instance, based new
instance, determine fitness denoted fiak al fial ak aliak al
alial ak , respectively.
Note aliak al alial ak share elements positions except
order ak al . Thus, order ak al considered reason
fitness aliak al alial ak differs. decide order ak al , define index
variable denoted ivak al measures percentage samples one
order ak proceeds al wins, i.e.
P

ivak al =



min(

al
ak
f k
f l


ak al
ak ,0)
|f
f l
|





.

define Index Parameter activities ak al denoted IPak al
benchmark index variable ivak al determining order ak al . parameter IPak al prescribed users different values (usually larger 50%)
represent different levels confidence order ak al matters causing fitness
variance, thus also represents different controllability ivak al .
value index variable ivak al larger value IPak al , set order
ak al since indicates higher probability b provide better robustness
b a; ivak al less 1 IPak al , set al ak ; cases, order
ak al settled.
6.2 Improved Chaining based Robustness Feedback
noted Preliminaries section, activity a, may exist multiple
choices resource chains assigned. addition, different chaining heuristics lead POSes different robust makespan values. section,
propose new chaining heuristic dispatches activities resource chains predicting
improvement robust makespan generated POS.
68

fiRobust Local Search Solving RCPSP/max Durational Uncertainty

Algorithm 2 Robustness-Feedback Resource Chaining (Activity a, Schedule S, Order G)
1: C Find set available chains, C activity based
2: P Collect chains C last activity chain preceding problem
3: Collect chains C last activity chain ordered G
4: P 6=
5:
k Get first available chain P
6: else 6=
7:
k Get first available chain
8: else
9:
k Get first available chain C
10: end
11: Post constraint last activity chain k (denoted last(k)) activity
12: requires one resource unit
13:
C1 chains C last activity last(k)
14:
C2 C \ C1
15:
resource units required
16:
choose first available chain belonging C1
17:
chain feasible
18:
choose first available chain belonging C2
19:
end
20:
end
21: end
latest chaining method aims increase flexibility described Section 2.2.4, chains first randomly picked superior subset (i.e., chains
last activity already ordered, chains sharing last element). Since objective makespan-related time becomes concern, build work Policella
et al. (2009) pick first available chain wherever available. updated chaining
method called Robustness-Feedback based Resource Chaining.
Example 5. Figure 5 provides POS provided chaining heuristic used
Example 1. seen, compared POS 4, key difference allocation
activity 5 6. new heuristic, seen parallelism
hence reduced robust makespan high probability.
employing Ordering Generation algorithm conjunction chaining
heuristic, also consider information ordered pairs allocating resource
units activity. motivation activity activity b (for example,
b) ordered, high probability precedence relationship result
better solution. Algorithm 2 provides pseudo code Robustness-Feedback
Resource Chaining heuristic Ordering.

7. Experimental Evaluation
section, first evaluate scalability quality execution strategies
provided robust local search various enhancements introduced paper.
69

fiFu, Lau, Varakantham, & Xiao

1

Figure 5: POS Robustness Feedback Chaining
Secondly, establish benchmark performance, compare best known
technique solving JSP problems durational uncertainty. noted
robust local search method developed solve RCPSP/max problems durational
uncertainty hence exploit structure present JSP problems. Furthermore,
described earlier, optimization metrics approaches different.
7.1 Experimental Setup
two sets problems consider described subsections
below. Additionally, also indicate algorithms compared data
sets section.
7.1.1 RCPSP/max Durational Uncertainty
problems considered RCPSP/max durational uncertainty obtained
extending three benchmark sets available RCPSP/max problems, J10, J20
J30 specified PSPLib (Kolisch et al., 1998). set contains 270 problem
instances duration activity ranging 1 10. maximum number
activities J10, J20 J30 10, 20 30, respectively. activity ai , set
expected value d0i stochastic duration corresponding deterministic duration
given benchmarks, assume duration uncertainty normally distributed,
i.e. zi N (0, ). Henceforth, refer J10, J20 J30 RCPSP/max problems
durational uncertainty. run algorithms problems four different duration
variabilities = {0.1, 0.5, 1, 2} four increasing levels risk = {0.01, 0.05, 0.1, 0.2}.
70

fiRobust Local Search Solving RCPSP/max Durational Uncertainty

RCPSP/max problems durational uncertainty, compare robust local
search guided using two decision rule approximations SLA GNLA. Furthermore, also compare different enhancements robust local search RCPSP/max
problems durational uncertainty. compare five different variants robust local
search decision rule approximation: (a) (GNLA) refers basic robust local search
guided GNLA decision rule approximation; (b) (GNLA+RC) robust local search
new Robustness-feedback Chaining heuristic guided GNLA; (c) (GNLA+) refers
basic robust local search additional local search iterations, number
local search iterations determined based problem set (as described later); (d)
(GNLA+OG) Order Generation heuristic top GNLA guided robust local search;
finally (e) (GNLA+OG+RC) Order Generation Robustness-feedback
Chaining heuristics GNLA guided robust local search.
number local search iterations robust local search set 1000. reduce
stochasticity effects robust local search, average 10 random executions
problem instance. code implemented C++ executed Core(TM)2
Duo CPU 2.33GHz processor FedoraCore 11 (Kernel Linux 2.6.29.4-167.fc11.i586).
7.1.2 JSP Durational Uncertainty
JSPs, (GNLA) compared probabilistic makespan results provided
Beck Wilson (2007). benchmark problems, consider instances generated
using existing generator work Watson, Barbulescu, Whitley, Howe (2002)
durations drawn uniformly interval [1,99]. Specifically, focus three
sets probabilistic JSPs size {44,66,1010} (where 44 problems consists 4
jobs consisting 4 activities each) set, three uncertainty levels {0.1,0.5,1}
considered.
7.2 Comparison SLA GNLA
first compare average robust makespan 270 problem instances obtained robust
local search guided decision rule approximations proposed Section 3.1
Section 3.2. refer robust makespan computed using SLA using GNLA
G . Figure 6 provides results three sets RCPSP/max problems
durational uncertainty. results, show robust makespan affected
level risk standard deviation duration uncertainty. X-axis represents
different combinations risk standard deviation durational uncertainty, shown
table Figure 6. runs every instance takes couple seconds hence
report CPU times here. key observations conclusions interest Figure 6
follows:
Irrespective , level risk increases, robust makespan decreases
SLA GNLA. Clearly, lower risk planner willing take,
higher robust value generated execution strategy. method
capable quantifying trade off, help planner decide
desired strategies.
71

fiFu, Lau, Varakantham, & Xiao

105

95

G*

S*

85

75

65

55

45
1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

(a) Results J10
146
136

G*

S*

126
116
106
96
86
76
1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

(b) Results J20
170
160

G*

S*

150
140
130
120
110
100
1

2

3

4

5

6

7

8

9

10

11

12

13

14

(c) Results J30

Figure 6: Comparison Robustness SLA GNLA.
72

15

16

fiRobust Local Search Solving RCPSP/max Durational Uncertainty

Irrespective , degree duration variability increases, robust makespan
increases SLA GNLA, value becomes sensitive
level risk constrained small value (e.g. = 0.01).
lower values , specifically 0.01, provides lower values robust
makespan G . hand, higher values {0.05, 0.1, 0.2}, G
provides superior performance . yet understand reason drop
performance = 0.01, observed consistently across RCPSP/max
benchmark problems.
problem instance, also observe monotonicity absolute
difference robust makespan G risk values. level risk takes
value around 0.02, (SLA) slightly lower value G (GNLA). However,
risk becomes 0.02, superiority GNLA increases higher values risk.
Figure 7 illustrates randomly picked J10 instance = 1 = 2.
pattern observed across problem instances J10, J20 J30.
105

65

95

60

85

55

75

50

65

S*

45

S*

55

G*

40

G*

45

35

35

30

25

25

0.005 0.01 0.02 0.03 0.04 0.05 0.1 0.15 0.2 0.25 0.3

0.005 0.01 0.02 0.03 0.04 0.05 0.1 0.15 0.2 0.25 0.3

(a) Results randomly selected J10 example (b) Results randomly selected J10 example
=1
=2

Figure 7: Comparison Robust Makespan.
Next, Figure 8, compare quality execution strategies obtained using
SLA GNLA. precisely, compare distributions actual makespans
schedules computed using decision rule approximations. purpose, generate
set 100 samples realizations durational uncertainty test 270 instances
benchmark set different levels risk = 0.2, = 0.1 = 0.05 obtain
respective POS, compute actual makespans schedules derived
respective POS given realization samples. difference real makespans
obtained POSs generated two different decision rule approximations observed
across board examples three sets values except 0.01. randomly
select three problem instances benchmark set present results Figure 8.
Figure 8 also compares cumulative frequency distributions actual makespans.
observe GNLA provided far better realized makespans SLA - absolute
terms, well distributionally. J20, except 2 cases, rest actual makespan
73

fiFu, Lau, Varakantham, & Xiao

82

100%
80

80%
78
76

60%

74

40%

72

20%

70

0%

68

69

71

73

75

77

79

81

(a) Results randomly selected J10 example = 0.2

100%

60

80%
55
60%
50
40%
45

20%

40

0%
41

43

45

47

49

51

53

55

57

(b) Results randomly selected J20 example = 0.1
110
100%
105
80%
100

60%

95

40%
20%

90
0%
85

86 88 90 92 94 96 98 100 102 104 106 108

(c) Results randomly selected J30 example = 0.05

Figure 8: Comparison Actual Makespans Gap G .(Lines left pictures top indicating: Computed , Actual Simulation, Computed G , Actual G Simulation.)

74

fiRobust Local Search Solving RCPSP/max Durational Uncertainty

values obtained SLA higher ones obtained GNLA. Similar trends
observed J10 J30.
illustrate difference quality absolute two upper bounds, provide
four lines (computed , actual , computed G actual G ) indicating upper
bounds computed using algorithms simulation 100 samples.
7.3 Comparing Robust Local Search Enhancements
Since, already shown GNLA performs better SLA, show performance enhancements GNLA section. noted enhancements SLA provided similar results conclusions GNLA based enhancements
outperforming SLA based enhancements. Since Ordering Generation heuristic requires
additional rounds robust makespan computation, also include benchmark called
(GNLA+) (which GNLA plus extra iterations local search) make fair comparison.
avoid complexity considering pairs activities, consider pairs
activities ordering would improve performance. proposed Pairs-Selection
heuristic select pairs activities. number extra iterations local search
(GNLA+) benchmark number activity pairs picked Pairs-Selection
heuristic times number samples used Ordering Generation process.
experimental results shows average number activity pairs 270 instances selected Pairs-Selection heuristic J10, J20 J30 5, 14, 28 respectively.
work, set = 100. Thus, extra iterations (GNLA+) benchmark
J10, J20 J30 500, 1400 2800, respectively. performance enhancements shown Figure 9(a), Figure 9(b), Figure 9(c) J10, J20 J30 respectively.
charts, represented X-axis robust makespan Y-axis. So,
lower values better Y-axis.
Given key observations conclusions made results:
Irrespective durational uncertainty, (GNLA+RC) (GNLA+OG) provide
better robust makespan values (GNLA) (GNLA+) J10 J30.
indicates new Robustness Feedback Chaining heuristic Order
Determination able provide robust partial ordered schedules J10
J30. improvement seems increase number activities, i.e.
difference obvious instances J30 J10. Furthermore,
difference consistently observed across problems. However, improvement
consistent J20 cases (GNLA+RC) (GNLA+OG)
perform (GNLA) (GNLA+). instance J20 problems, (GNLA+)
provides better performance (GNLA+RC) (GNLA+OG) = 0.01
= 1.5.
extra iterations local search (GNLA+) improve solution quality
much J10. However, improves solution quality J20 J30. could
optimal solution obtained within 1000 iterations smaller
problems.
cases, (GNLA+RC+OG) provides lowest robust makespan among
enhancements. Thus, OG RC enhancements combination degrade
75

fiFu, Lau, Varakantham, & Xiao

(a) Results J10

76

fiRobust Local Search Solving RCPSP/max Durational Uncertainty

(b) Results J20

77

fiFu, Lau, Varakantham, & Xiao

(c) Results J30

Figure 9: Comparison Robust Local Search Enhancements.

78

fiRobust Local Search Solving RCPSP/max Durational Uncertainty

MNPM
CB
G

Problem Size
44
UL=0.1 UL=0.5 UL=1
1.023
1.046
1.128
1.066
1.123
1.282

Problem Size
66
UL=0.1 UL=0.5 UL=1
1.021
1.073
1.168
1.095
1.190
1.273

Problem Size
1010
UL=0.1 UL=0.5 UL=1
1.024
1.101
1.215
1.210
1.225
1.263

Table 2: Comparison CB solver(UL:Uncertainty Level).
performance improvement obtained individually. cases, difference
significant J10 = 0.1 = 0.01. hand,
cases (GNLA+RC+OG) provide lowest robust makespan,
J20 = 0.5 = 0.01.
7.4 Comparing JSPs Durational Uncertainty
section, compare performance GNLA approach (referred G )
best known solver Job Shop Scheduling Problems proposed Beck Wilson (2007) (referred CB). fair comparison two approaches, employ
Mean Normalized Makespan (MNPM) metric defined Beck Wilson:
N P (a, L) =

1 X D(a, l)
|L|
Dlb (l)

(58)



L set problem instances, D(a, l) probabilistic makespan (i.e., robust
makespan work) instance l algorithm generated Monte Carlo simulation,
Dlb (l) lower bound probabilistic makespan.
denote best MNPM values aross different algorithms reported Beck
Wilson CB. compare MNPM values work obtained
replacing D(a, l) Eqn 58 upper bound robust makespan POS
generated GNLA-guided local search. runs 4 4 6 6 instances took less
minute, 10 10 instances took 15 minutes.
Table 2 provides results. performance solver comparable CB solver
across problem instances. comparison illustrates local search mechanism
generic (different types scheduling problems) also able provide performance
par near optimal approaches. performance comparable, CB provides
better MNPM values approach due following key reasons: (a) approach
exploit structure specific JSPs (jobs consisting sequence operations).
hope improve approach exploit near future. (b) robust local
search reasons upper bounds (due Chebyshev inequality), loose.

8. Related Work
Resource-Constrained Project Scheduling Problem minimum maximum time
lags, RCPSP/max, (or known Resource-Constrained Project Scheduling Problem
Generalized Precedence Relations, RCPSP-GSR) strongly NP-hard combinatorial optimization problem; even decision problem determining whether
79

fiFu, Lau, Varakantham, & Xiao

RCPSP/max instance feasible solution NP-complete (Bartusch et al., 1988).
survey recent developments new applications RCPSP/max given
Neumann, Schwindt, Zimmermann (2006).
However, find much study considers RCPSP/max uncertainty.
One paper dealing variable durations RCPSP/max done Lombardi
Milano (2009), activity durations range given lower upper bounds.
precedence constraint posting approach (Policella, Cesta, Oddi, & Smith, 2007)
adopted. Whereas work, consider RCPSP/max durational uncertainty
activity duration modeled random variable known mean variance
values.
Research scheduling uncertainty received much attention Artificial
Intelligence Operations Research communities. complete survey recent AI
papers robust project scheduling 2004, one may refer work Herroelen
Leus (2005) production scheduling (Aytug, Lawley, McKay, Mohan, & Uzsoy,
2005). Broadly, one may classify techniques tackle scheduling uncertainty
two categories: Proactive Scheduling design priori schedule schedule policy
take account possible uncertainty may occur; Reactive Scheduling modifies
re-optimizes baseline schedule unexpected event occurs. interest
proactive scheduling concerned robust scheduling focuses
obtaining proactive schedules maintain high level performance uncertainty.
main idea proactive techniques build global solution hopefully
need revised execution time. One divide research area three
categories, according information uncertainties taken
account generating robust stable schedules would without using
information (Bidot, Vidal, Laborie, & Beck, 2009): 1. generating one complete generic
schedule proved execute correctly scenarios arising execution;
2. generating flexible solution decisions postponed made
execution; 3. generating conditional solution mutually exclusive decisions
developed,the one chosen dependent observations execution, like
markov decision processes. following, briefly look first two cases since
related work.
8.1 Generating Generic Schedule
first method making generic schedule insensitive online perturbations
produce complete robust schedule taking account possible scenarios, i.e.
schedule strong controllability (Vidal & Fargier, 1999). Rather dealing execution 100% confidence, probabilistic techniques proposed build schedules
probabilistic guarantee threshold value optimization metric
makespan. Another example generic schedule generation fuzzy scheduling (Herroelen & Leus, 2005): instead stochastic variables probabilistic distributions, fuzzy
set scheduling use fuzzy numbers modeling uncertainties based possibility theory;
recent work Rodrguez et al. (2009) modeled uncertain durations fuzzy numbers
improved local search solve Job Shop Scheduling Problem. following,
80

fiRobust Local Search Solving RCPSP/max Durational Uncertainty

provide details work related strong controllability probabilistic
techniques.
8.1.1 Strong Controllable Techniques
Strong Controllability introduced Vidal Fargier (1999) Simple Temporal
Networks Uncertainty (STNU) controllability achievable polynomial
time. existence uncontrollable events controlled exogenous factors, often referred Nature, STNU strongly controllable exists least
one universal schedule suits situation. schedule might computed off-line
beforehand. Strong controllability strictest form STNU. strongly controllable
network means schedule executed without regard contingent events.
useful applications contingent events cannot observed exactly.
8.1.2 Probabilistic Techniques
Instead generating global solution suitable realizations uncertainties, probabilistic techniques build schedule probabilistic guarantee deterministic
optimization measure respect threshold value, e.g., find schedule
highest probability project makespan exceed particular value.
Daniels Carrillo (1997) defined -robust schedule one maximum probability achieving given performance level, e.g., total flow time greater
given threshold. presented branch-and-bound heuristic techniques find robust schedule one-machine manufacturing context performs best within given
confidence level. Job Shop Scheduling Problem, Beck Wilson (2007) consider
activity durations random variables; given level risk 0 1, interested
solution minimal (probabilistic) makespan probability execution
least 1 .
8.2 Generating Flexible Schedule
Another way producing robust schedule taking account uncertainty introduce
flexibility schedule. idea subset decisions made offline
rest postponed made online, decisions made information
becomes precise certain (Bidot et al., 2009). following, discuss three
subcategories works deal generating flexible schedules.
8.2.1 Dynamic Controllable Techniques
STNU Dynamic Controllable (Vidal & Fargier, 1999) exists solution
always instantiated incrementally based outcomes contingent edges past.
execution strategy using dynamic controllability needed produce incremental
solution based subsequent revelation contingent events. Morris Muscettola
(2005) proposed pseudo-polynomial algorithm handle dynamic controllability STNUs
based constraint satisfaction. Techniques proposed Wah Xin (2004)
optimize bounds durations contingent edges resulting STNU
dynamic controllable.
81

fiFu, Lau, Varakantham, & Xiao

8.2.2 Redundancy-based Techniques
Redundancy-based scheduling another proactive technique scheduling. idea
generate schedule includes allocation extra resources and/or time
schedule buffers help absorb impact unexpected events without
rescheduling execution. Davenport, Gefflot, Beck (2001) proposed techniques
generating robust schedules based insertion temporal slacks critical activities allocated possibly breakable resources. Lambrechts, Demeulemeester,
Herroelen (2010) analytically determined expected increase activity duration due
resource breakdown. Based information, simulation-based time buffering used
protect schedule disruptions caused resource availability.
8.2.3 Partial Order Schedule (POS)
Even buffering, baseline schedules may become brittle face unpredictable execution dynamics quickly get invalidated. Instead baseline schedule, another line
work consider design good schedule policies. One example notion
Partial Order Schedules (POS) defined Policella et al. (2004) seeks retain
temporal flexibility whenever problem constraints allow often absorb unexpected deviation predictive assumptions. considered robustness measures
fluidity flexibility. Generating POS another example flexible approaches:
subset sequencing decisions made offline remaining decisions made online
using dispatching rule (Bidot et al., 2009). Different methods generating POS
compared terms robustness resulting schedules work Rasconi, Cesta,
Policella (2010). work, apply concept POS execution policy.
Given RCPSP/max instance, mean variance values segregated variables
data perturbations level risk, objective work determine POS
locally minimal robust value.
8.3 Scenario-based Optimization Scheduling
Another line work deals scheduling uncertainty based use
scenarios (scenario-based optimization). example, Kouvelis, Daniels, Vairaktarakis
(2000) introduced concept robustness scheduling problems. considered uncertain processing times proposed methods generate robust schedule based
maximum absolute deviation robust solution possible scenarios
given scenario set. shortcoming kind approach scenarios assumed
known advance, scenario space usually exponentially large. Noteworthy mention two notions solution robustness quality robustness,
solution robustness (or stability) refers insensitivity actual start times, whereas
quality robustness refers insensitivity solution quality (i.e. makespan) different
scenarios (Herroelen & Leus, 2005). Another pioneering scenario-based optimization work
Mulvey, Vanderbei, Zenios (1995) handles tradeoff solution
robustness (if solution remains close optimal scenarios) model robustness
(if solution remains feasible scenarios).
82

fiRobust Local Search Solving RCPSP/max Durational Uncertainty

8.4 Robust Optimization Scheduling
recent development Operations Research saw potential applying concept
Robust Optimization deal uncertainty. Ben-Tal Nemirovski (2002) Bertsimas Sim (2003) proposed robust optimization models assumptions
underlying probability distribution data needed. idea often approximate
data uncertainty tractable (convex) uncertainty set, optimization performed
set. results robust counterpart formulation conic (such second-order
cone) optimization problem solved polynomial time. However,
works reported literature applying robust optimization scheduling,
due mainly high-degree combinational nature problem. One application
process scheduling problem chemical engineering, works Janak,
Lin, Floudas (2007) Li Ierapetritou (2008). notable recent breakthrough
robust optimization tractable approximation models solve stochastic optimization
problems found Chen et al. (2008). work makes use linear segregated decision rules relevant solving combinatorial scheduling problems durational
uncertainty work exploit mechanism incorporate local search.

9. Conclusion
Given level risk 0 < 1 chosen planner, investigated problem finding
minimum (1 )-guaranteed makespan (i.e. Robust Makespan) proposed methods
find schedule policy (POS) uncertainty dynamically realized,
execution policy result solution whose value good robust makespan.
first put forward new decision rule utilized scheduling help specify start times
activities respect execution policy dynamic realizations data uncertainty.
Based decision rule, new fitness function derived evaluate robustness,
finally integrated local search framework produce solution
robust makespan. Experimental results illustrate improved performance local search
new fitness evaluation, provider tighter bounds robust makespan
better partial order schedules compared existing method.
simplicity adopted upper bound approach assume independence among durational uncertainties. One future work treat correlations
durational uncertainties, since task duration could correlated others real
life. example, correlations occur external event peculiar single
task, universal, weather conditions, seasonal peaks. situations,
durational delays correlated direction. occurs, decision
rules proposed paper break unfortunately, since even covariances
pairs duration variables given, complex analytically model extent
one duration combination (resulting SUM MAX operators)
durations change together. turn complicates analysis variance
makespan variable, hence robust makespan. Extending work handle
covariances interesting future direction.

83

fiFu, Lau, Varakantham, & Xiao

Acknowledgments
paper extends previous research Lau, Ou, Xiao (2007) Fu, Varakantham,
Lau (2010). authors wish thank reviewers insightful comments.

References
Aytug, H., Lawley, M. A., McKay, K., Mohan, S., & Uzsoy, R. (2005). Executing production schedules face uncertainties: review future directions.
European Journal Operational Research, Vol. 165(1), pp. 86110.
Bartusch, M., Mohring, R. H., & Radermacher, F. J. (1988). Scheduling project networks
resource constraints time windows. Annals Operations Research, 16 (1-4),
201240.
Beck, J. C., & Wilson, N. (2007). Proactive algorithms job shop scheduling probabilistic durations. Journal Artificial Intelligence Research, 28 (1), 183232.
Ben-Tal, A., & Nemirovski, A. (2002). Robust optimization - methodology applications.
Mathematical Programming, 92, 453480.
Bertsimas, D., & Sim, M. (2003). Robust discrete optimization network flows. Mathematical Programming, 98, 4971.
Bidot, J., Vidal, T., Laborie, P., & Beck, J. C. (2009). theoretic practical framework
scheduling stochastic environment. Journal Scheduling, 12, 315344.
Chen, X., Sim, M., Sun, P., & Zhang, J. (2008). linear decision-based approximation
approach stochastic programming. Operations Research, 56 (2), 344357.
Clark, C. E. (1961). Greatest Finite Set Random Variables. Operations Research,
9, 145162.
Daniels, R., & Carrillo, J. (1997). Beta-robust scheduling single-machine systems
uncertain processing times. IIE Transactions, 977985.
Davenport, A. J., Gefflot, C., & Beck, J. C. (2001). Slack-based techniques robust
schedules. Proceedings 6th European Conferences Planning (ECP).
Dean, B. C., Goemans, M. X., & Vondrak, J. (2004). Approximating stochastic knapsack
problem: benefit adaptivity. FOCS, pp. 208217.
Demeulemeester, E. L., & Herroelen, W. S. (2002). Project scheduling : research handbook.
Kluwer Academic Publishers, Boston.
Fu, N., Varakantham, P., & Lau, H. C. (2010). Towards finding robust execution strategies
rcpsp/max durational uncertainty. Proceedings International Conference
Automated Planning Scheduling (ICAPS), pp. 7380.
84

fiRobust Local Search Solving RCPSP/max Durational Uncertainty

Hagstrom, J. N. (1988). Computational complexity pert problems. Networks, 18, 139
147.
Herroelen, W., & Leus, R. (2005). Project scheduling uncertainty: Survey
research potentials. European Journal Operational Research, Vol. 165(2), pp.
289306.
Janak, S., Lin, X., & Floudas, C. (2007). new robust optimization approach scheduling
uncertainty :ii. uncertainty known probability distribution. Computers
Chemical Engineering, 31, 171195.
Kolisch, R., & Hartmann, S. (2005). Experimental investigation heuristics resourceconstrained project scheduling: update.. European Journal Operational Research.
Kolisch, R., Schwindt, C., & Sprecher, A. (1998). Benchmark Instances Project Scheduling Problems, pp. 197212. Kluwer Academic Publishers, Boston.
Kouvelis, P., Daniels, R. L., & Vairaktarakis, G. (2000). Robust scheduling two-machine
flow shop uncertain processing times. IIE Transactions, 32, 421432.
Lambrechts, O., Demeulemeester, E., & Herroelen, W. (2010). Time slack-based techniques
robust project scheduling subject resource uncertainty. Open access publications
katholieke universiteit leuven urn:hdl:123456789/272147, Katholieke Universiteit
Leuven.
Lau, H. C., Ou, T., & Xiao, F. (2007). Robust local search application generating
robust schedules. Proceedings International Conference Automated Planning
Scheduling (ICAPS), pp. 208215.
Li, Z., & Ierapetritou, M. G. (2008). Robust optimization process scheduling
uncertainty. Industrial Engineering Chemistry Research, 47 (12), 41484157.
Lombardi, M., & Milano, M. (2009). precedence constraint posting approach
rcpsp time lags variable durations. Proceedings 15th international
conference Principles practice constraint programming, CP09, pp. 569583
Berlin, Heidelberg. Springer-Verlag.
Mohring, R. H. (2001). Scheduling uncertainty: Bounding makespan distribution.
Computational Discrete Mathematics, pp. 7997.
Mohring, R. H., & Stork, F. (2000). Linear preselective policies stochastic project
scheduling. Mathematical Methods Operations Research, 52 (3), 501515.
Morris, P., & Muscettola, N. (2005). Temporal dynamic controllability revisited. Proceedings 20th National Conference Artificial Intelligence, pp. 11931198. AAAI
Press.
Mulvey, J. M., Vanderbei, R. J., & Zenios, S. J. (1995). Robust optimization large-scale
systems. Operations Research, 43.
85

fiFu, Lau, Varakantham, & Xiao

Neumann, K., Schwindt, C., & Zimmermann, J. (2006). Resource-constrained project
scheduling time windows. International Series Operations Research Management Science, 92, 375408.
Policella, N., Cesta, A., Oddi, A., & Smith, S. (2009). Solve-and-robustify. Journal
Scheduling, 12, 299314. 10.1007/s10951-008-0091-7.
Policella, N., Cesta, A., Oddi, A., & Smith, S. F. (2007). precedence constraint posting
partial order schedules: csp approach robust scheduling. AI Communications,
20, 163180.
Policella, N., Smith, S. F., Cesta, A., & Oddi, A. (2004). Generating robust schedules
temporal flexibility.. Proceedings International Conference Automated Planning Scheduling (ICAPS), pp. 209218.
Rasconi, R., Cesta, A., & Policella, N. (2010). Validating scheduling approaches
executional uncertainty. Journal Intelligent Manufacturing, 21 (1), 4964.
Rodrguez, I. G., Vela, C. R., Puente, J., & Hernandez-Arauzo, A. (2009). Improved local
search job shop scheduling uncertain durations. Proceedings International Conference Automated Planning Scheduling (ICAPS).
Vidal, T., & Fargier, H. (1999). Handling contingency temporal constraint networks:
consistency controllabilities. Journal Experimental Theoretical Artificial
Intelligence, 11, 2345.
Vonder, S., Demeulemeester, E., & Herroelen, W. (2007). classification predictivereactive project scheduling procedures. Journal Scheduling, 10 (3), 195207.
Wah, B. W., & Xin, D. (2004). Optimization bounds temporal flexible planning
dynamic controllability. IEEE International Conference Tools Artificial
Intelligence, 0, 4048.
Watson, J.-P., Barbulescu, L., Whitley, L. D., & Howe, A. E. (2002). Contrasting structured
random permutation flow-shop scheduling problems: Search-space topology
algorithm performance. INFORMS Journal Computing, 14, 98123.
Wu, C. W., Brown, K. N., & Beck, J. C. (2009). Scheduling uncertain durations: Modeling beta-robust scheduling constraints.. Computers Operations Research,
36, 23482356.

86

fi
