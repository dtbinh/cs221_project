Journal Artificial Intelligence Research 30 (2007) 525-564

Submitted 1/07; published 12/07

Framework Kernel-Based Multi-Category Classification
Simon I. Hill

sih22@eng.cam.ac.uk

Department Engineering,
University Cambridge,
Cambridge, UK

Arnaud Doucet

arnaud@cs.ubc.ca

Depts. Statistics Computer Science
University British Columbia,
Vancouver, Canada

Abstract
geometric framework understanding multi-category classification introduced,
many existing all-together algorithms understood. structure enables
parsimonious optimisation, direct extension binary methodology.
focus Support Vector Classification, parallels drawn related methods.
ability framework compare algorithms illustrated brief discussion
Fisher consistency. utility improving understanding multi-category analysis
demonstrated derivation improved generalisation bounds.
also described architecture provides insights regarding
improve speed existing multi-category classification algorithms. initial example might achieved developed formulation straightforward
multi-category Sequential Minimal Optimisation algorithm. Proof-of-concept experimental
results shown this, combined mapping pairwise results, comparable
benchmark optimisation speeds.

1. Introduction
problem extending classification methods standard dichotomous framework
general polychotomous arrangement one considered
number authors. Essentially, task learn training data best
assign one possible classes subsequent input data, known beforehand.
key contribution work introduce overarching framework understanding multi-category kernel-based classification methods. particular framework makes assumptions constructions used individual approaches clear.
result enables operation existing multi-category methods transparently compared contrasted intuitive consistent manner. Further, insight
afforded architecture suggests ways developing efficient algorithms
bringing together best existing techniques.
central idea behind approach introduce (M 1)-dimensional space
divided class-specific regions. aim learn (M 1)-dimensional
function f () lies class region corresponding class argument.
shown straightforward generalisation = 2 case, two
c
2007
AI Access Foundation. rights reserved.

fiHill & Doucet

class-specific regions f () 0 f () < 0. Indeed, framework, unlike many
approaches, binary case treated special case.
Discussion done primarily Support Vector Classification (SVC) context
initially, extended methodologies. geometric structure employed
introduced detail Section 2, together derivation optimisation
problem, shown generalisation standard all-together optimisation
problems overviewed Hsu Lin (2002). discussed along review
existing Support Vector (SV) multi-category methods Section 3.
Following consider overall algorithm performance Section 4 discussing
Fisher consistency, Section 5 looking generalisation bounds. Section 6 discusses
methodologies, particular -Support Vector Classification (-SVC), Least Squares
Support Vector Classification (LS-SVC), Lagrangian Support Vector Classification (LSVC),
Proximal Support Vector Classification (PSVC), Bayes Point Machines (BPM).
followed return SVC problem Sequential Minimal Optimisation (SMO)
algorithm derived Section 7. Issues related details best implement
SMO algorithm (e.g. point selection) discussed, options improving
speed convergence. implemented several examples Section 8, initial
experimental exercise.

2. Setting Multi-Category Problem
Section key geometric construction presented, mechanisms
using formulate optimisation problem. Finally, extensions generic structure
described. basic construction described Subsection 2.1. Following this,
Subsection 2.2 describes example empirical SV loss cases, Subsection 2.3 discusses
relative class knowledge incorporated Subsection 2.4 details overview
derivation SV optimisation problem.
2.1 Geometric Construction
binary classification case, class determination input set X often
performed considering sign underlying real-valued function f : X R (Vapnik,
1998, example). progressing -class case, underlying vector-valued func

tion f : X RM 1 found, f = f1 . . . fM 1
. basic idea behind
use (M 1)-dimensional space able introduce equally separable
class-target vectors. class input x determined identifying class-target
vector f (x) closest.
seen effectively takes place binary SV classification,
classes, denoted B, class targets y(A) = 1 y(B) = +1. Consider
third class, C, possibility. one-dimensional numerical label insufficient
classes equidistant, case little known relationship
classes logical arrangement would compare every class every
equivalent way. order class targets must equidistant sense.
526

fiA Framework Kernel-Based Multi-Category Classification

two-dimensional arrangement illustrated Figure 1 allows this. classtarget vectors
y(A) =

h





3
2



21

, y(B) =

h



3
2

21



, y(C) =



0 1



.

(1)

ky()k = 11 classes (with = {A, B, . . . } denoting set possible
classes) improves tractability later. example class-target vectors, however,


Class C

0
1



Class Boundary

1
2



p

3
1

Class Boundary


Class

Class B

1
2



p

3
1



Class Boundary

Figure 1: Possible class labels classification three. class-target vectors corresponding classes A, B C shown. class boundaries given
solid lines.
general important understand optimisation methods described applicable regardless rotation. Indeed, although apparent Cartesian
coordinate asymmetry may appear intuitive, important consideration relative
positioning class-target vectors respect other. optimisation procedure
dependence particular orientation. proven SV methods
part derivation optimisation process Section 2.4.
approach described = 3 taken considering larger values
. typically = 3 used work example case, extensions
higher values follow without consideration. example target vectors
might easily found higher dimensions discussed Hill Doucet (2005).
1. Note work k k denotes 2-norm vector, i.e. kyk =

normalisation imply kyk

527

q

2
y12 + + yM
1 and, further,

fiHill & Doucet

2.2 SV Empirical Multi-Category Loss
setting classification process, class assigned subset (M 1)dimensional output space. particular, straightforward approach, subsets
Voronoi regions associated class targets. result, class boundaries
found forming hyperplanes class regions consist points equidistant
two relevant class targets. input x, classifier output given
function h found observing regions f (x) lies i.e.
h(x) = class associated region f (x) lies.

(2)

describing empirical loss vectors perpendicular hyperplane dividing
region y(A) y(B) typically used2 . Define
vA (B) =

y(B) y(A)
ky(B) y(A)k

(3)

vectors illustrated class C Figure 2 margin introduced
defined = yT ()v () , {A, B, C} 6= . Note
dependency , explicitly noted referring constant. Discussions
might case presented later. definition vectors v used
aim measure distance direction perpendicular class boundaries
done inner product relevant vector v.
margin used cases finding empirical loss. several
different ways combine individual loss components, fundamental starting point
illustrated Figure 2. training point x class
C f (x) falls outside

required region. penalised vB (C)f (x) analogous way binary
SV classification empirical loss (1 yf (x)). Indeed binary case vB (A) = y(A)
vA (B) = y(B) = 1. parallel, region zero loss
binary case f (x) > 1, region zero loss here, dotted
lines.
Consider training data {(xi , ) : {1, . . . , N }} used learn
best classify new input x. Denote indicator function I(); empirical loss
polychotomous classification problem given Allwein, Schapire, Singer (2001),
Crammer Singer (2001a), Lee et al. (2001, 2004) then,
EM P =

N
X

I(h(xi ) 6= ),

(4)

i=1

namely number misclassified training samples. dichotomous SV techniques,
loss used bounds EM P , thus generating straightforward optimisation
problem.
setting multi-category SV classification, approach used many different
authors, however exact empirical loss functions differed. prevalent
understood within framework Figures 1 2, four illustrated
Figure 3 object class C. four loss functions involve either adding together
2. exception case presented Lee, Lin, Wahba (2001, 2004), discussed Hill
Doucet (2005, App. C).

528

fiA Framework Kernel-Based Multi-Category Classification

"

y(C )
vB (C )



vB (C )f (x)

vA (C )

f (x)

Figure 2: Elements involved determining empirical loss associated training sample
class C. Note unlabelled solid lines class boundaries, region
dotted line region zero loss training samples class C.





Contour Linear Summed Error Surface y=[0 1]
2.5

2

2

1.5

1.5
f2(x)

f2(x)

Contour Quadratic Summed Error Surface y=[0 1]
2.5

1
0.5
0
0.5
3

1
0.5
0

2

1

0
f (x)

1

2

0.5
3

3

2

1

1

2

2
1.5
f2(x)

f2(x)

1

2

3

Contour Linear Maximal Error Surface y=[0 1]T
2.5

1.5
1
0.5

1
0.5

0
0.5
3

0
f (x)
1

Contour Quadratic Maximal Error Surface y=[0 1]T
2.5

0
2

1

0
f (x)

1

2

0.5
3

3

1

2

1

0
f (x)

1

2

3

1

Figure 3: Four possible loss functions three class problem (see Figure 1). loss
functions shown respect target vector = [0 1]T . Traditional
additive losses shown top, (see equations (6) (5)), possible variants
following proposals Crammer Singer (2001a) bottom (see equations (8)
(7)). cases class boundary shown dot-dash line.

margin infringements, taking largest infringement. linear quadratic
versions two options illustrated. Algebraically, summed loss training
529

fiHill & Doucet

point expressed,
SL,i =

X

(i )

SQ,i =

X

(i )


f (xi )v (i ) , 0

max


max

2
f (xi )v (i ) , 0

(5)
(6)

SL stands summed linear loss SQ summed quadratic loss.
top two Subfigures Figure 3. Using notation, maximal loss training
point expressed,

max f (xi )v (i ), 0
(i )
n
2
=
max
max f (xi )v (i ), 0

L,i =
Q,i

max



(i )

(7)
(8)

ML stands maximal linear MQ maximal quadratic. bottom
two Subfigures Figure 3. expressions apparent ith summand
empirical loss (equation (4)) bound 12 SQ,i, 12 Q,i, 1 SL,i 1 L,i .
loss arrangements cast transparent way SV framework,
work SL,i initially focussed on, commonly adopted,
albeit implicitly, previous contributions. SQ,i discussed respect LSVC
Subsection 6.3.
terms practioners preferred approach, however, clearly choice must
line underlying probabilistic model data. seems unlikely
one best choice implementations. case practioner particular
idea model wishes use methodology get feel data,
presumably optimal use computationally efficient approach often
approaches converge similar results. end approach outlined
paper interest describes methods potentially used speed
loss cases.
2.3 Relative Class Knowledge
framework developed based assumption classes
treated equally, may desirable cases. may prior
knowledge suggesting classes are, sense, closer other, thus
likely mistaken other. may also reason preferring
err side choosing one class others another cost overall
accuracy.
classical example deeming important choose one class another
comes binary case detection radar. military combat clearly extremely
important detect incoming missiles planes. result understandable
classification algorithm may set return many false positives false
negatives. Hence errors made classing enemy weaponry unimportant far
heavily penalised errors made classifying nonthreatening phenomena weaponry.
530

fiA Framework Kernel-Based Multi-Category Classification

two ways introduce relative class knowledge framework presented.
first traditional method error weighting, introduced alltogether SV framework Lee et al. (2001). solution different type misclassification (e.g. classifying input instead ) error weighted
amount; ().
approach incorporating weights could equivalently viewed varying
length vectors v, i.e. v () ()v (). alternative, possibly complementary, approach allocate class unequal volume (M 1)-dimensional
output space. enabled varying angle class boundaries
hence orientation vectors v, i.e. v () R ()v () R () rotation matrix. may also useful incorporate set variable values
which, class denoted { () : ( )}, () size
margin side (, ) boundary. Clearly greater volume allocated
class diverse input vectors mapped it.
Training Points

Found f(x)

8
Class
Class B
Class C

Class
Class B
Class C
Class Boundary

5

6

0

f2(x)

x

2

4

2

5

0

2
10

4
10

8

6

4

2

0

2

4

6

8

10

8

6

x1

(a) Classes feature space

4

2

0
f1(x)

2

4

6

8

10

(b) Output result

Figure 4: simple example illustrating potential case differently sized class areas.
arrangement target area class could increased.

Unfortunately obvious construct principled approach determining
different volumes. key issue region support class
feature space. instance case illustrated Figure 4 possible find linear
projection feature space separate classes standard class
regions. However, changing class region sizes projection would possible.
may advantage avoiding complicated feature space (possibly
higher dimension).
2.4 Derivation SVC Optimisation Problem
Standard SV mappings inputs higher dimensional feature space, : X F used
order estimate (M 1)-dimensional function f (). mth element f ()
linear function feature space, characterised weight vector wm offset bm .
531

fiHill & Doucet

summarise,





f (x) =







h(x), w1
h(x), w2
..
.
(x), w(M 1)

ff

F





+


b1
b2
..
.
b(M 1)





= (x) + b.


(9)

important realise that, although class separation achieved component,
fm (), accurate classification really accomplished use elements,
together.
optimisation problem follows discussion previous Subsections
written (in standard SV form) as,

N

1
X
X
X
1
(i )i,
kwm k2F + C
Minimise
2
m=1
i=1 (i )
PM 1
m=1 (h(xi ), wm + bm ) v,m (i ) (i ) i, , = 1, ..., N , ( )
Subject
i, 0, = 1, ..., N , ( )
(10)


slack variable i, quantifies empirical loss involved mistaking class
point xi (which ) (6= ). C quantifies trade-off regularisation
(introduced kwm k2F ) empirical loss, v,m () mth element v ().
Framing equation (10) terms Lagrangian gives,
N
1
X
1 X
2
L=
kwm kF + C
2
m=1



N
X

X

(i )i,


1
X

i,

X

ri, i,

i=1 (i )

i=1 (i )

X

N
X

(h(xi ), wm + bm ) v,m (i ) (i ) + i,

m=1

i=1 (i )

!

(11)

{i, , ri, : (1, . . . , N ), ( )} Lagrangian multipliers. standard
SV methodology find optimal solution first finding Wolfe dual,
maximising respect dual variables, namely Lagrangian multipliers
(Cristianini & Shawe-Taylor, 2000; Vapnik, 1998, example). First let V() denote
(M 1) (M 1) matrix columns given vectors v (),
V() =



vA () vB () . . . v6= () . . .

().
represent mth row V() vm



(12)

Lemma 1 dual Lagrangian presented equation (11) is,
N

N

N

X
1 XX
LD =
Ti (i )
V (i )V(j )j K(xi , xj ) +
2
i=1

i=1 j=1

532

(13)

fiA Framework Kernel-Based Multi-Category Classification

where,
=
(i ) =





i,A i,B . . . i,6=i . . .



(i ) B (i ) . . . 6=i (i ) . . .

(14)


(15)

kernel function denoted K(xi , xj ) = h(xi ), (xj )iF . derivation
equation (13) also introduces constraints that,
CD (i ) i, 0, i, ( )

(16)

N
X

(17)

V(i )i = 0.

i=1

derivation presented technical report authors Hill Doucet
(2005, App. A).
also remains confirm optimisation problem unique maximum,
problem unimodal. case shown quadratic
term equation (13) effectively equivalent quadratic expression involving positive
definite matrix. case, shown Hill Doucet (2005, App. B).
final issue consider rotational invariance structuring problem
initially raised Subsection 2.1. Note influence rotational orientation
equation (13) summation term Ti VT (i )V(j )j K(xi , xj ). Consider
chosen orientation rotated way described rotation matrix R,
quadratic term becomes,
Ti VT (i )RT RV(j )j K(xi , xj ) = Ti VT (i )V(j )j K(xi , xj )

(18)

due fact rotation matrices orthonormal. one aspect
considered, namely constraints equation (17), however clear
affected rotation either. Hence optimisation problem rotationally
invariant.
related issue geometric structure implicitly introduces ordinal regression
along (M 1) axes. is, looking example, three-class case illustrated
Figure 1 essentially two real valued outputs i.e. f1 () f2 (). Now, along
horizontal vertical line one held constant, outputing
value, region value falls determines class assignment. gives
impression ordinal regression using ranges single value output determine
two classes essence approach.
raises two questions methodology presented subject problems
ordinal regression? And, looking structure way, fact
potentially arranged quite asymmetrically, appears arbitrary cause concern?
answer questions No. aim structuring ouput space
way avoid situation encountered ordinal regression classes
equivalently compared other. Furthermore, clear
rotational invariance structure, particular orientation chosen going
affect optimisation problem way whatsoever.
533

fiHill & Doucet

Note introduced terminology function f () expressed,
f (x) =

N
X

V(i )i K(x, xi ) + b.

(19)

i=1

clearly natural extension binary framework, comparison previous
similar contributions forms next Section. offset, b determined
realising non-extremal Lagrangian coefficients i, lie edge zero-loss
region analogous finding b two-class case.

3. Discussion Previous SV Approaches
three main methods applying binary classification techniques
generic multi-category problem. one-against-all method, pairwise coupling
method method Error Correcting Output Codes (ECOCs). discussed
here, applied conjunction SV methods. extensive literature review
forms large part work Rifkin Klautau (2004); contrast, Section
various methods discussed respect approach described Section 2.
Essentially, one-against-all pairwise methods made work well,
invariably require heuristic component resolve issues associated combining
results. Many authors tried overcome framing problem single
optimisation, also done Section 2, however approaches substantially slower
converge. key contribution work demonstrate consistent3 result
obtained mapping pairwise results ad hoc way framework Figure 1
fine-tuning result, consistent final optimum. provides combination
fast training consistency.
Contributions Rifkin Klautau (2004) argue one-against-all
pairwise methods made perform practically well methods. may
well case, depending implicit model behind heuristics involved
come surprise. Indeed, many quick black-box implementations approach may
well optimal.
Often however desirable clear understanding optimisation process
significant contribution framework presented within many single optimisation SV methods understood compared directly. Further, framework
multi-category versions algorithms formulated understood
consistent way, discussed Section 6. Finally, fact many
different efforts made find method involving single optimisation
competitive terms speed evidence desire research community
overcome heuristic solutions.
Section one-against-all method reviewed Subsection 3.1, pairwise coupling Subsection 3.2 ECOCs Subsection 3.3. Efforts develop single optimisation
3. Here, subsequent usage, use consistent consistency refer fact
approaches quite ambiguous exactly class output, hence need heuristic
choose, all-together solution suffer i.e. results consistent
other. Fisher consistency discussed Section 4.

534

fiA Framework Kernel-Based Multi-Category Classification

approaches, known all-together methods discussed Subsection 3.4. relate framework presented also clarified therein.
3.1 One-Against-All Method
one-against-all method received attention SV community,
also earliest approach considered. idea generate classifiers. these,
classifier determines whether input belongs class i. obvious stumblingblock case one classifier determines particular input
belong class interest. Hence important place technique
either avoiding resolving problem.
Early implementations (Scholkopf, Burges, & Vapnik, 1995; Blanz, Scholkopf, Bulthoff,
Burges, Vapnik, & Vetter, 1996) used underlying real-valued output, choosing highest output indicate strongest likelihood class membership. variant
introduced Mayoraz Alpaydn (1999) attempt make outputs
reliably comparable; see also Wang, Vuurpijl, Schomaker (2000).
aside, note function f () found framework proposed Section
2 used produce one-against-all classifier. see consider function
f () = yT ()f () y() class-target vector class . new input x would
classed f (x) largest scalar function.
3.2 Pairwise Coupling Method
pairwise coupling method involves finding (M2 1) different classifiers,
compares one class another. Given input, output class decided
vote similar method. One particular problem addressed circular one
which, example, AB classifier chooses class A, AC classifier class C
BC classifier class B.
authors (Hastie & Tibshirani, 1998; Platt, Cristianini, & Shawe-Taylor, 2000;
Furnkranz, 2002) proposed heuristics resolving problems, however
substantive purely SV approach seems Kreel (1999). technique
considers classifier vote and, case tie, real-valued outputs referred to.
downside (M2 1) classifiers found independently,
comparison always meaningful. Nonetheless, shown Kreel supported
Allwein et al. (2001), Hsu Lin (2002) Rifkin Klautau (2004), appears
effective methodology faster all-together methods considerable margin.
alternative approach presented Allwein et al. (2001) work unifying pairwise,
one-against-all class codes discussed Subsection 3.3.
interesting note function f () found framework proposed Section
2 used find classifier two classes B. see consider
(B)f () v (B) defined equation (3). new input x
function fAB () = vA

would classed fAB (x) 0 B otherwise. Results used
Section 7 construct best worlds approach.
535

fiHill & Doucet

3.3 Class Codes
underlying idea behind ECOCs assign class particular binary code
train individual classifiers identify bit code (Sejnowski & Rosenberg,
1987; Dietterich & Bakiri, 1995). Eight classes can, example, assigned 3bit code ([1, 1, 1], [1, 1, +1], etc.). general least log2 bits required.
Dietterich Bakiri (1995) propose using bits order small errors
corrected.
ECOC SV methods described Kindermann, Leopold, Paa (2000)
Rennie Rifkin (2001). Minimum length code methods presented Sebald
(2000), Sebald Bucklew (2001) Suykens Vandewalle (1999). However
implementations often problem classes treated inconsistently. due
fact codes smaller Hamming distances classes
others. approach becomes much like utilising Ordinal Regression (see,
example, Crammer Singer (2001b) Herbrich, Graepel, Obermayer (2000b)
more, SV context) perform classification performance becomes dependent ordering labels (Weston, 1999). Essentially ordinal regression performs
classification based region R scalar output lies. instance,
class may assigned input x f (x) [a, b), class B f (x) [b, c),
on.
see parallel coding approaches consider four-class case
minimum length codes, that,
y(A) =
y(C) =




1 1
+1 1





y(B) =
y(D) =





1 +1
+1 +1





.

Two functions f1 f2 need found corresspond first second elements
codes respectively. However class clearly class classes
B C. Hence comparison classes longer consistent. Although
less extreme ordinal regression main problem classes compared
equivalent way remains. reason, well lack computational
accuracy advantage, methods particularly popular.
Allwein et al. (2001) shown pairwise one-against-all methods viewed
special cases ECOC approaches4 . Indeed code length equals (the
one-against-all case) exceeds inconsistency problem described
made disappear. Even viewing pairwise one-against-all approaches special
cases ECOC Allwein et al. (2001) still must employ heuristic (in case code-based)
find final answer.
3.4 All-Together Methods
consistent result obtained arranging multi-category problem
single optimisation perform. described Hsu Lin (2002)
all-together methods number authors (Bredensteiner & Bennett, 1999; Crammer
4. exception binary nature code formulation case pairwise comparison
code word elements take values {1, 0, 1}.

536

fiA Framework Kernel-Based Multi-Category Classification

& Singer, 2001a; Guermeur, 2000, 2002; Weston & Watkins, 1999; Weston, 1999; Vapnik,
1998) present variety methods. see many relate described
Section 2, note aim find functions {f () : } that, class(x) =
arg max {f (x) : }. Weston Watkins (1999) aim find functions form
f () = h(), w + b
N
X
X
1X

i,
kw k2F + C
2
i=1 (i )

ff



, ( )
(xi ), wi F + bi h(xi ), w + b + 2 i,

Subject

i, 0

Minimising

(20)

shown detail authors (Hill & Doucet, 2005, App. C)
optimisation arrangement identical Section 2 f () = yT ()f () f ()
introduced Section 2. Furthermore, all-together approaches mentioned,
exception Crammer Singer (2001a), shown Guermeur (2002)
converge solution. However key problem algorithms
resulting kernel expressions quite complicated framing optimisation
process leads convoluted expressions.
alternative Crammer Singer (2001a) propose all-together one-against-all
method maximal loss L,i equation (7) (see also Figure 3) give
new optimisation algorithm. comparative work Hsu Lin (2002) find hard
draw definitive conclusions Crammer Singer (2001a) approach comparison
others note variable performance regard optimisation times required.
also suggest algorithmic improvements traditional methods, eventually
conclude that, available techniques, pairwise coupling methods (see Section 3.2) much
faster appear suitable practical use.
standard form methodology introduced Section 2 results optimal
solution equivalent all-together approaches two key points differentiate it.
first increased flexibility incorporate approaches described
Subsection 2.3 without increased computational effort. second easily
take advantage relatively much faster pairwise methods. discussed
Subsection 7.4.
3.4.1 Another All-Together Approach
Lee et al. (2001, 2004) presented unique all-together approach uses -length
target codes. classes = {A, B, . . . } take form

(A) =
(B) =





1

1
1

1
1

1

...
1
1

537

1
1

...



1
1



fiHill & Doucet

on. resulting optimisation problem posed
N
X
X
1X

i,
kw k2F + C
2
i=1 (i )




h(xi ), w + b yi () i,
P



Subject
h(xi ), w + b = 0

i, 0

Minimise

(21)





+ b
+ b
h(), wA
output given f () =
h(),
w
...
=

B F
B
F






W () + b W = wA wB . . . , class membership determined
observing element f () maximal. approach understood
framework Section 2 when, similarly Subsection 3.4 f () = yT ()f () f ()
introduced Section 2. discussed Hill Doucet (2005, App.
C), shown setting vA (B) = y(A) = M11 causes optimisation
problem equation (21) generic approach equation (10).

4. Brief Look Fisher Consistency
Lee et al. (2001, 2004) (Subsubsection 3.4.1) approach key feature
Fisher consistent5 . recently discussed context multicategory
classification Tewari Bartlett (2007), Zhang (2004a, 2004b). Section
simply aim show key results authors understood
framework presented Section 2.
considering Fisher consistency multicategory case first define vector



(22)
= P ( = A|x) P ( = B|x) . . .
p(x) = pA (x) pB (x) . . .

analogous vector p Tewari Bartlett (2007), vector P(|X)
Zhang
(2004b, Eqn.(7)). also express empirical loss function, (, f (x)) =
P

() max v ()f (x) , 0 , cf. equation (5), define vector by,
(f (x)) =



(A, f (x)) (B, f (x)) . . .



.

(23)

notation -risk, terminology Tewari Bartlett (2007)
given by,


EX [ (, f (x))] = EX E|X [ (, f (x))]
(24)


= EX pT (x) (f (x))

optimal classification rule choose class = arg max [p (x)]. Fisher
consistent multicategory classifier g(x) = f (x), cf. Subsection 3.4, that,
= arg max [p (x)] = arg max [g (x)]




(25)

5. referred classification calibrated Tewari Bartlett (2007) infinite-sample consistent
Zhang (2004b).

538

fiA Framework Kernel-Based Multi-Category Classification

Tewari Bartlett (2007) illustrate two class case reference equation
(24), plot (A, f (x)) (B, f (x)) y(A) = 1 y(B) = +1.
Bartlett, Jordan, McAuliffe (2004) shown provided plot differentiable f (x) = 0 consistency attained. case
one tangent plot f (x) = 0. noteworthy particular x,
value f (x) minimises inner product equation (24) determined
point line slope ppBA (x)
(x) tangent. plot differentiable
sample x pA (x) > pB (x), sample x pA (x ) < pB (x ) may
value f (x) = f (x ) = 0 even though f minimises -risk.
Whereas plot straightforward 2D plot, considering three class case
must turn 3D surfaces consider tangent planes normal given p(x) e.g. Tewari
Bartlett (2007, Figs.2&3). illustrated all-together methods
inconsistent including Weston Watkins (1999), Weston (1999)
Crammer Singer (2001a). However, also case approach Lee et al.
(2001, 2004) consistent.
order better understand happening, consider similarities
method introduced Weston Watkins (1999), Weston (1999), Lee et al.
(2001, 2004) (3.4). additive approach forming loss function
(in contrast maximum approach Crammer & Singer, 2001a). key difference
choice vectors v. Weston Watkins (1999), Weston (1999) use,
example vA (B) [y(B) y(A)], Lee et al. (2001, 2004) use e.g. vA (B) = y(A). fact
also consider using vectors either combination these,
extreme versions. Examples resulting loss functions shown Figure 5, cf. Figure 3.
becomes interesting terms Fisher consistency happens
plots loss contours classes overlaid. consider plots
class C Figure 5. particular consider Lee et al. (2001, 2004) (LLW) case.
clearly identify four regions zero loss, loss due class A,
loss due class B combined loss. overlaying contour plots
similarly seek identify regions.
presented Figure 6, regions seperated solid black lines.
seen regions identified Weston Watkins (1999), Weston (1999)
Lee et al. (2001, 2004) plots correspond planes (and edges) Figures 2(b) 3(b)
Tewari Bartlett (2007). Further, keeping discussion becomes clear
potential inconsistency problems occur region boundaries intersect class
boundaries. reason Lee et al. (2001, 2004) case manages avoid
region boundaries coincide particular setting. scenarios illustrated Figure 6
correspond following example vectors v, left right, top bottom;

0.2y(B) y(A)




y(A)



y(B) 5y(A)
vA (B)
y(B) 2y(A)





y(B) y(A)


y(B) 0.5y(A)

539








Excess LLW case.
LLW case.
LLW WW case.
LLW WW B case.
WW case.
Excess WW case.

(26)

fiHill & Doucet

Excess LLW

Lee Lin Wahba

Excess WW

3

3

3

2

2

2

1

1

1

0

0

0

1

1

1

2

2

2

3
3

2

1

0

1

2

3

3
3

2

1

0

1

2

3

3
3

2

1

0

1

2

3

Figure 5: illustration losses respect class C. correspond
changing vectors v. Recall Weston Watkins (1999), Weston (1999)
(WW) case loss contours parallel class boundaries (Figure 3)

clear cases LLW WW onwards Figure 6 inconsistent,
question remains Excess LLW case. investigate created
plots similar Figures 2 3 Tewari Bartlett (2007), shown Figure
7. clear reverse view labelled Point Interest
going pose consistency problem.
results give quick geometric insight Lee et al. (2001, 2004)
approach appears Fisher consistent approach involving summed linear losses.
performed similar investigation effect changing v within context
Crammer Singer (2001a) framework seems clear always
problem central point reasonable choice vectors v, cf. Tewari Bartlett
(2007, Fig. 2a).

5. Generalisation Bounds
important aspect many kernel based algorithms SVC, Structural Risk
Minimisation (SRM) ideas applied order obtain distribution-free bounds
performance. approach underlies initial work SVC particular, results
ideas Vapnik Chervonenkis (VC) dimension.
section build body work concerned bounding
performance multicategory classifiers. originally published Guermeur (2002),
important realise paper draws heavily work Elisseeff,
Guermeur, Paugam-Moisy (1999). insight also found work
Paugam-Moisy, Elisseeff, Guermeur (2000).
540

fiA Framework Kernel-Based Multi-Category Classification

Excess LLW

Lee Lin Wahba

LLW WW

3

3

3

2

2

2

1

1

1

0

0

0

1

1

1

2

2

2

3
3

2

1

0

1

2

3

3
3

2

LLW WW B

1

0

1

2

3

3
3

Weston Watkins
3

3

2

2

2

1

1

1

0

0

0

1

1

1

2

2

2

2

1

0

1

2

3

3
3

2

1

0

1

1

0

1

2

3

2

3

Excess WW

3

3
3

2

2

3

3
3

2

1

0

1

Figure 6: Region Identification six different cases represent rotation vectors v, starting top left progression passes Lee et al. (2001,
2004) case (middle top), bottom left Weston
Watkins (1999), Weston (1999) case (middle bottom).

(a) Front View

(b) Reverse View

Figure 7: Loss surfaces Excess LLW case Figure 6

541

fiHill & Doucet

using geometric approach presented above, becomes possible reduce
multidimensional bounding problem scalar problem, thus fully utilise
traditional approaches bounding. approaches also drawn Elisseeff et al.
(1999), however viewing problem manner proposed becomes possible
adopt virtually unchanged. key references work Bartlett (1998)
Williamson, Smola, Scholkopf (2001).
finalP
result working demonstrate bound derived dependent
1
2
term
i=1 kwi kF , cf. equation (10). keeping results Guermeur
(2002), Elisseeff et al. (1999), well traditional two-class bound analyses (Scholkopf
& Smola, 2002). Note notation Section inconsistent
used elsewhere paper, however difference apparent.
5.1 Basic Definitions
starting reference canonical function Elisseeff et al. (1999), PaugamMoisy et al. (2000), Guermeur (2002), rewritten present notation.
introduce also dimensional vector yc elements,

1 input class
c
=
+1 input class .
introduce function g : X RM ,
g() = f ()

(27)

matrix columns class target vectors y, cf. Section 3.
Definition 1 (The Original Canonical Function) Define R1 (x) index
gR1 (x) (x) = max g (x) R2 (x) index gR2 (x) (x) = max6=R1 (x) g (x).
canonical function g : X RM , given by,
(
1

1

= R1 (x)
2 g gR2 (x) = 2 [y() y(R2 (x))] f (x) = vR2 (x) ()f (x)
g (x) =

1
1

otherwise.
2 g gR1 (x) = 2 [y() y(R1 (x))] f (x) = vR1 (x) ()f (x)
(28)
constant proportionality.

Clearly, example classified correctly, terms vR
()f (x)
1 (x)

negative vR2 (x) (R1 (x))f (x) positive. Paugam-Moisy et al. (2000), Guermeur (2002) define margin = min yc g (x), however, recall vA (B) =
vB (A), gR1 (x) (x) = gR2 (x) (x). Hence, R1 (x) R2 (x) actual class
c
c
x yR
gR1 (x) (x) = yR
gR2 (x) (x). case neither
1 (x)
2 (x)
correct class demonstrated margin going determined
gR1 (x) (x) uniquely, term need ever considered.
case margin simply given min6=R1 (x) vT (R1 (x))f (x).
definition Paugam-Moisy et al. (2000), Guermeur (2002) somewhat nonintuitive, make reference actual class point, merely R1 (x),
may equal class . equivalent defining margin

542

fiA Framework Kernel-Based Multi-Category Classification

two-class classifier absolute value function f (x). something
appears mainstream texts Vapnik (1998, p. 402), Scholkopf Smola (2002, p.
142) Hastie, Tibshirani, Friedman (2001, p. 110), instance. However general
ideas texts, approach Section 2 related Definition
2, Paugam-Moisy et al. (2000, Defn. 6) Guermeur (2002, Defn. 5).
anticipation introduce alternative canonical function f (x, ),
f (x, ) = VT ()f (x)

(29)

V() given equation (12). x correctly classified elements f
positive.
Definition 2 (Empirical Margin Risk) Conceptually, empirical margin risk
fraction training samples whose positioning (M 1) dimensional space lies outside
region zero-loss. Formally expressed fixed margin > 0
training set = {xi , }N
i=1 as,
RS (f ) =

1
|{(xi , ) : ( ) , f (xi , ) < }|
N

(30)

definition used pseudo-metric. definition note
1
P
p denotes norm kxkp = ( |xi |p ) p .
Definition 3 (Pseudo-Metric) Let F : X RM 1 set functions (f , f )
,S
F 2 . set points X , define pseudo-metric dF
,1 by,
,S
dF
,1 (f , f ) = max

(x,)S

X

()

fi
fi
fif (x, ) f (x, )fi .

(31)

define covering number (Vapnik, 1998; Scholkopf & Smola, 2002, example).

Definition 4 (Covering Number) Let F , dF ,S pseudo-metric space, B(f , r)

closed ball F radius r centre f . covering number N , F, dF ,S
set F F smallest cardinality set F that,
[
F
B(f, ).
(32)
f F

sets F satisfying property called covers F: element F
distance less element F. |S| = 2N define also,




,S
Np,q
, F, 2N = sup N
, F, dF
p ,q .
2
2
SX 2N
543

fiHill & Doucet

5.2 Presentation Bounds
use final definition consideration of,


f (x, ) =



sign [min f (x, )] ,
min f (x, ),

| min f (x, )|
otherwise,

(33)

analogous definition g used Elisseeff et al. (1999, 4), Paugam-Moisy
et al. (2000, 6) Guermeur (2002, 2). used define set scalar-valued
functions,
F = {f : f F}
(34)
leading Theorem 1, below. advantage approach presented
function f scalar and, such, lot straightforward use proof
structure outlined Bartlett (1998, Lemma 4) cf. Elisseeff et al. (1999, Cor. 2), PaugamMoisy et al. (2000, Cor. 1), Guermeur (2002, Thm. 1). elaborated on, two
different approaches contrasted Hill (2007, 4.2,A.2)
Theorem 1 probability least (1 ), every value (0, 1], risk R(f )
function f computed numerical class discriminant model F trained set
size N (denoted SN ), bounded
R(f )

RS N (f )

+







2
1
1

, F , 2N
+ log
log 2N,1
+
2N
2

N

(35)

Proof Theorem 1
starting point proof equivalent Elisseeff et al. (1999, Eqn. (5)),
namely, ,
PSN










1
sup R(f ) RS N (f ) 2PSN ,SeN sup RSe (f ) RS N (f )
. (36)
N
N
f F
f F

aim bound right-hand side starting point consider
permutations (X )2N realises transposition two elements
ranking SeN SN . Let U uniform distribution set
permutations so,
PSN ,SeN









1
1




sup U : sup RSe (f ) RSN (f )
.
sup RSe (f ) RSN (f )
N
N
N
N
f F
f F
,Se
N

N





Denote 2 cover set F F , elements f . identical reasoning
Bartlett (1998, proof Lemma 4) defining,
fi ofi


1 fifin fifi
fi
fi

,
f , SN
fi
fi : fif (xi , ) fi
N
2
544

fiA Framework Kernel-Based Multi-Category Classification

inequality leads to,




1
PSN ,SeN sup RSe (f ) RS N (f )
N
N
f F
(
)




1




sup U : sup
f , SeN

f , SN


N
e
f F
SN , SN





fi
1

e
fifi

fi

sup U : f , SN f , SN
F
.


N
f F
fi

fi
definition fiF fi = N,1 2 , F , 2N seen leads




1
PSN ,SeN sup RSe (f ) RS N (f )
N
N
f F
!
(37)


X
1
1

N,1
(ai bi )
, F , 2N sup P
2
N
N
(ai ,bi )


{1, +1}, P (i = 1) = P (i = +1) = 0.5 Independent,
Identically Distributed (IID). Meanwhile
fi
fi


(
fi e
fi
ei , fi 2
1 fif x
ai =
0 otherwise



bi =

(

fi
fi
fi
fi
fif (xi , ) fi
0 otherwise.
1


2

right-hand term equation (37) bounded using Hoeffdings inequality
(Elisseeff et al., 1999, Theorem 5) that,


2 !





1
1
, F , 2N exp 2N
.
PSN ,SeN sup RSe (f ) RS N (f )
N,1
N
N
2
N
f F
(38)

rearranged demonstrate that,









1
1
1




, F , 2N
log 2PSN ,SeN sup R e (f ) RSN (f )
log 2N,1
+
SN
2N
2
N
N
f F

so, equation (36)









1
1

+ .
, F , 2N
log PSN sup R(f ) RSN (f )
log 2N,1

2N
2
N
f F




Now, probability least (1 ) = PSN supf F R(f ) RS N (f ) ,
case R(f ) RS N (f ) . Hence, probability least (1 )
r



1 h
1

R(f ) RSN (f ) +
log 2N,1
, F , 2N
log () + .
(39)
2N
2
N
545

fiHill & Doucet

analogous result Theorem 4 Elisseeff et al. (1999). Using together
Proposition 8 Bartlett (1998) demonstrates that,





2
1
1


R(f ) RsN (f ) +
, F , 2N
+ log
(35)
log 2N,1
+
2N
2

N
concludes proof Theorem 1.
5.2.1 Bounding N,1



2 , F , 2N



using Entropy Numbers

generalised risk Theorem
1 bounded expression involving
covering number, N,1 2 , F , 2N , clear determine number exactly,
standard approach bound it. done following ideas Williamson
et al. (2001). first step define entropy numbers Guermeur (2002, Defns. 7 & 8),
Williamson et al. (2001, eqns. 7-10).
Definition 5 (Entropy Numbers Operator Norm) Given pseudo-metric space
,S
F ,S
(F , dF
,1 ) then, nth entropy number set F F respect ,1 ,


n

,S

n
(40)
n (F) , inf > 0 : N , F, dF
,1

entropy number operator : F follows introduction unit ball
F , denoted UF . nth entropy number defined as,
n (T ) , n (T (UF ))

(41)

kT k = sup kT (f )kM .

(42)

operator norm given by,
f UF

understand entropy number explicitly, denote (UF ) set ,
assume metric dM .
then, keeping


equation (40), entropy

number given n (T ) , inf > 0 : N , M,
n .

Note first
definition clear see n (F) bounded
part
F ,S
, N , F, ,1 n; Guermeur (2002, Thm. 3), Williamson et al. (2001,


, 2N ,
Prop. 12). Note also Definition
4,

order

bound
N
,
F
,1
2

,S
sufficient bound N 2 , F , dF
,1 , discussed following Theorem.


,S
Theorem 2 (Bound log N 2 , F , dF
) log covering number
,1


PM 1
,S
2
N 2 , F , dF
m=1 kwm kF ,
,1 set F F bounded term proportional
i.e.

1


X
,S
kwm k2F
(43)

r
log N
, F , dF
,1
2
m=1

r > 0.

546

fiA Framework Kernel-Based Multi-Category Classification

Proof Theorem 2
proof begins fact, highlighted Williamson et al. (2001, Thm. 10) (see
also Guermeur, 2002, Thm. 4), Maureys Theorem used bound entropy
numbers. Theorem note qp vector space containing vectors dimension
1
P
q norm kf kqp = ( qi=1 |fi |p ) p . Furthermore (F , ) denotes set bounded
operators normed spaces (F , k kF ) (M , k kM ).
Maureys Theorem considers (H , q ) H Hilbert space.
states exists constant c > 0 that, n, q N,
v


u
u log 1 + q

log n+1
.
(44)
n (T ) ckT k
log n + 1
Guermeur (2002) must rely generalisation Maureys Theorem matrix
output spaces, directly applicable vector output spaces. mentioned
Guermeur (2002), claimed problem, extension
derived, although done. current formulation problem however,
theorem used directly bound entropy number, and, stated, also
used bound covering number operator. steps follows,
v


u
u log 1 + N

log n+1

= ckT k
(45)
n (T )
2
log n + 1


,S
N
n
(46)
, (UF ) , dM
,1
2





,S
,S
N
N
.
(47)
, F , dF
, (UF ) , dM


,1
,1
2
2

remains demonstrate third and, particular, aim


(f ) = min f (x1 , 1 ) min f (x2 , 2 ) . . . min f (xN , N ) .
(48)
mapping : F vector space norm
kakM ,S = max |ai |.

(49)

1i|S|

case Maureys Theorem clearly directly applicable, equations (45)
(46). expressions equations (48) (49) far simpler counterparts
Guermeur (2002, 2.3) due scalar form f equation (33).
comparison two approaches, see Hill (2007, 4.2.1,A.2.1). proving equation
(47), consider first,
fi
fi
fi
fi

,S
fi
,1 (f ), (f ) = max fimin f (x, ) min f (x, )fifi
(x,)S





and, meanwhile,

fi
fi




fi
fi
,S

f
(x,
)

f
=
max
(x,
)
f
,
f
dF
fi
fi
,1
(x,)S

547

fiHill & Doucet

clear see that,
fi
fi
fi
fi
fi
fi

fi
fi
fi
max fif (x, ) f (x, )fi max fimin f (x, ) min f (x, )fifi


(x,)S
(x,)S





,S
F ,S
,1 f , f ,1 (f ), (f )

(50)

means that, provided f , f UF , equation (47) correct. extended version
derivation presented Hill (2007, B.2).
remains bound kT k. Now, equation (49),


fi
fi
fi
fi
kT (f )kM ,S = max min v (i )W(xi ) .
(51)
6=i

ii|S|

Cauchy-Schwarz inequality (Guermeur, 2002, A.2) X
radius ball including (X ),



(52)
kT (f )kM ,S X max min kv ()Wk2
6=



means that,


min kvT ()Wk2
6=

kT k X max

v
uM 1
uX
kwm k2F .
X



(53)

m=1

made assumption f UF , however case
straightforward arrive analogous solution. found Williamson
et al. (2001, V.B), Elisseeff et al. (1999, Prop. 4) Guermeur (2002, Prop. 1), example.
Combining result equation (45)
v


v
u
uM 1
N
u
log
1
+
uX

log n+1

kwm k2F
n (TF ) cX
2
log n + 1
m=1
rearranged give,

4c2 2X log(1 + N )
log n
2

PM 1
m=1

kwm k2F

1

n 1, always going case bound covering number.
Equation (46) gives,

4c2 2 log(1 + N ) PM 1 kw k2
F
MF ,S
X
m=1
log N

, TF (UF ) , ,1
1
2
2

so, finally, equation (47)


log N



2

, F



,S
, dF
,1



4c2 2X log(1 + N )

2
548

PM 1
m=1

kwm k2F

1.

fiA Framework Kernel-Based Multi-Category Classification

demonstrates result equation (43) Theorem 2 moreover shows
constant r given by,
4c2 2X log(1 + N )
.
(54)
r=
2
concludes proof Theorem 2
5.3 Summary Generalisation Bounds
Subsection 5.2, Theorem 1 showed risk R(f ) function f bounded
probability least (1 ) by,
R(f )

RS N (f )

+







2
1
1

, F , 2N
+ log
log 2N,1
+ .
2N
2

N

(35)




,S
Where, Definition 4; N,1 2 , F , 2N = supSX 2N N 2 , F , dF
,1 ,
Theorem 2

1


X
,S
kwm k2F
(43)

r
, F , dF
log N
,1
2
m=1
r positive given equation (54). result
v
" 1
u
#
u 1
X
4
1


2
R(f ) RSN (f ) +
kwm kF + log
r
+ .
2N

N
m=1

(55)

mentioned derivation result, methodology employed
keeping two-class derivation bound derived Guermeur (2002).
due use scalar function f , introduced equation (33). use
function logical consequence viewing problem geometric framework
Section 2. allows mapping vector space, two-class case,
rather matrix space, work Guermeur (2002).
use f simplify working, final result
derived bound tighter Guermeur (2002). rederived
present notation Hill (2007, App. A) assumption Maureys Theorem
applicable directly maintained. presenting first define set
(M 1)
/
unique class combinations. class pair (, ) (, )
2
equivalent expression equation (55) is,
v


u

u
X
4
1
u 1
kvT ()Wk2 + log
r
+ .
R(f ) RS N (f ) +
2N

N
(,)


r=

8c2 2 2X (M 1) log(1 + N )
.
2
549

(56)

fiHill & Doucet

6. Kernel-Based Methods
section use framework presented Section 2 described respect
-SVC, LS-SVC, LSVC, PSVC, BPM.
6.1 -Support Vector Classification
case two-class optimisation problem (Scholkopf & Smola, 2002)
!

N
X
1
yi [h(xi ), wiF + b]
2
, Subject
kwkF +
Minimise
0, and, 0
2

(57)

i=1

extension polychotomous case straightforward, namely


N

1
X
X
X X
X
1
Minimise
i,
()
kwm k2F +
2
m=1
i=1 (i )
()
PM 1
m=1 v,m (i ) [h(xi ), wm + bm ] i,
Subject
i, 0, and, 0.

(58)

Following usual Lagrangian dual approach results final aim maximise
LD =

N N 1
1 XX X
V (i )V(j )j K(xi , xj )
2

(59)

i=1 j=1 m=1

subject 0 i, 1, i, ( ),
output given equation (19).

PN

i=1 V(i )i

= 0,

PN P
i=1

(i ) i,

> .

6.2 Least Squares Support Vector Classification
LS-SVC developed length Van Gestel, Suykens, Baesens, Viaene, Vanthienen,
Dedene, De Moor, Vandewalle (2001) much standard SVC, except
empirical loss taken quadratic; see top-left corner Figure 3,
equation (6). Multiclass versions published (Van Gestel, Suykens, Lanckriet,
Lambrechts, De Moor, & Vandewalle, 2002) rely coding schemes discussed
Subsection 3.3. two-class case aims
!
N
X
1
(60)
i2 , Subject yi [h(xi ), wiF + b] = 1
kwk2F + C
Minimise
2
i=1

alternative multi-category extension coding approach exists, i.e.


N

1
X
X
X
1
2
Minimise
i,
kwm k2F + C
2
m=1

Subject


1
X

i=1 (i )

v,m (i ) [h(xi ), wm + bm ] = (i ) i, .

m=1

550

(61)

fiA Framework Kernel-Based Multi-Category Classification

Now, define

Zm =





=

T1

...

TN




( ) . . . (x )vT ( )
(x1 )vm
N
1
N



.
Z = ZT1 . . . ZTM 1



=

V =



(1 ) . . .

(N )

V(1 ) . . .

V(N )





definitions shown (Van Gestel et al., 2001) optimisation
problem becomes equivalent finding b satisfy,


0
V

V

Z Z + CI



b




=



0




.

(62)

classifier found solving linear equations. Note finding Z Z
require reference feature space, kernel evaluations. final output
equation (19).
6.3 Lagrangian Support Vector Classification
introduced Mangasarian Musicant (2001), LSVC algorithm
strength computationally efficient, easy implement. uses
quadratic empirical loss, illustrated top-left corner Figure 3, detailed
equation (6). method two-class classification aims
N

Minimise

X

1
i2
kwk2F + b2 + C
2
i=1

!

, Subject yi [h(xi ), wiF + b] 1 .

(63)

reformulated multi-category problem resulting in,


1
Minimise
2
Subject


1
X


1
X

m=1




kwm k2F + b2m + C

N
X

X

i=1 (i )



2
i,

(64)

v,m (i ) [h(xi ), wm + bm ] (i ) i, .

m=1

dual is,


N
N N
X
1
1 XX

(i )
V (i )V(j )j [K(xi , xj ) + 1] +

LD =
2
2C

(65)

i=1

i=1 j=1

needs maximised subject i, 0 i, ( ).
P
done b = N
i=1 V(i )i . final solution takes form equation
(19).
551

fiHill & Doucet

6.4 Proximal Support Vector Classification
Following LSVC method, PSVC approach developed Fung
Mangasarian (2001b, 2001a). presented multi-category approach
one-against-all algorithm, all-together one. two-class aim
!
N
X

1
2
2
2
, Subject yi [h(xi ), wiF + b] = 1 . (66)
kwkF + b + C
Minimise
2
i=1

is, more, LS-SVC Subsection 6.2 except b2 term.
reformulated multi-category problem resulting in,



1
N
X
X
X


1
2
i,
kwm k2F + b2m + C
Minimise
2
m=1
i=1 (i )
(67)

1
X
v,m (i ) [h(xi ), wm + bm ] = (i ) i, .
Subject
m=1




Now, define v = v1T (1 ) . . . v1T (N ) v2T (1 ) . . . vN
(N ) ,
LS-SVC optimisation problem exact solution,


1

= + Z Z + v v


everything defined Section 6.2 b =
solution takes form equation (19).

PN

i=1 V(i )i .

(68)
before, final

6.5 Bayes Point Machines
BPMs introduced Herbrich, Graepel, Campbell (2000a) ideas
extended multi-category problem. short consider term Version
Space, V. two-class case region weight vector w lie without
inducing classification errors training set.
Within version space uniform distribution assumed possible linear (in feature
space) classifiers, h, outside assumed zero. Bayes point classifier given

h
(69)
hbp = arg min EX EH|{xi ,yi }N [ (h(X), H(X))]
i=1

hH

(, ) loss function (typically zero-one loss function used) inner
expectation classifiers H H. One problem definition usual
knowledge PX evaluation EX impossible.
assumptions form PX (see Herbrich et al., 2000a, more) can, however,
shown centre mass,
wcm =

Ew|{xi ,yi }N [w]
i=1

kEw|{xi ,yi }N [w]k
i=1

552

(70)

fiA Framework Kernel-Based Multi-Category Classification

good approximation wbp . Eventually problem becomes identify V,
contiguous convex space, find wcm given uniform
distribution assumed weight vectors space.
Note version space defined
V = {w : yi h(xi ), wi > 0, kwk = 1, i} ,

(71)

considering multiple classes condition yi h(xi ), wi > 0 becomes VT (i )W(xi ) >


0 0 ... 0
inequality indicates component-wise inequalities, maT

introduced. result version space given
trix W = w1 . . . wM 1

n



V = (w1 , w2 , . . . , wM 1 ) : VT (i )W(xi ) > 0 0 . . . 0
, kwm k = 1 m, ,
(72)
identical form equation (71). Extensions kernel billiards algorithm
described Herbrich et al. (2000a) used find Wcm , analogous wcm
equation (70). method including training errors also seamlessly incorporated.

7. Implementation Sequential Minimal Optimisation
geometric construction introduced Section 2 allows insight multi-category
problem, motivate alternative approaches efficiently solve all-together
optimisation problem. One possibility SVC presented here, based vector-valued
version SMO first introduced binary classification Platt (1999).
several advantages, including fact reasonably straightforward understand,
relatively easy implement, quite efficient flexible, addition well established
known.
SMO optimises respect two points time, denote c d.
notation, Kij = K(xi , xj ), dual Lagrangian equation (13) becomes
1
1
L = Tc (c ) + Td (d ) Tc VT (c )V(c )c Kcc Td VT (d )V(d )d Kdd
2
2
Tc VT (c )V(d )d Kcd Tc VT (c )zc Td VT (d )zd + constant.

(73)

P

zc vector elements zc,m = N
i=1,i6=c,d vm (i )Kic similarly zd,m .
shown Hill Doucet (2005, 6); expressing c terms ,
constraint equation (17), finding minimum setting L(d ) = 0,
SMO update takes form,
= old
new
+




V1 (d )
(xc ) (xd ) + VT (d )(d ) VT (c )(c ) (74)
Kdd + Kcc 2Kdc

where, V1 (d ) exists provided vectors {v (d ) : ( )} linearly independent, nearly always case, although possible conceive pathological
cases. Recall introduced equation (9) cf. (19).
553

fiHill & Doucet

7.1 Clipping
Recall elements c upper lower bounded (equation (16)),
hence clipping may required. best understood Figure 8, relates
Illustration Clipping Considerations
1.2

d,2
1

0.8



0.6
Start point

d,2

old


0.4

new


0.2

End point

0

d,1
0.2
0.2

0

0.2

0.4

0.6

d,1

0.8

1

1.2

1.4

1.6

(a) vector illustration proposed (b) Constraints within update must
update
made

Figure 8: proposed update three-class problem. new point shown Subfigure 8(b) outside allowed regions. correspond overall limits
0 CD1 (d ) (upright box) limits imposed c considerations (tilted
box).

three-class case, however ideas generically applicable. Given update
new new lie outside constraints
equation (74) form new
= old

+ , c

old
new
line traced back along longer case.
Ultimately [0, 1) found
new,clipped
= old
+ .

optimisation surface convex, improvements still made every update.
7.2 Updating Non-Extremal Components
Often, updates form equation (74) involve vectors old
old

c

extremal components (i.e. components constraint-introduced limits).
lead computational bottleneck update suggests components
lie outside allowed region result clipping procedure returning
original vectors.
avoid consider two points update labelled c d,
denote number non-extremal components Pc Pd respectively.
update likely possible6 Pd > 1 Pc and, case, let Pd + Pc + 1
6. Otherwise one solution, current one.

554

fiA Framework Kernel-Based Multi-Category Classification

non-extremal components grouped new vector . remaining elements
c dependent these. Owing linearity relationship
c , introduced constraint equation (17) becomes apparent
e + Ad c =
e c + Ac
=

(75)

e , Ad ,
e c , Ac .
e c
e contain
describe dependencies,
extremal components updated, together zeros, Ac Ad
matrices consisting ones zeros map variable components back
original positions vectors c . shown (Hill & Doucet, 2005, App.
E), SMO update case is,
= old
new

+

(ATd VT (d )V(d )Ad )1 ATd VT (d )
Kdd + Kcc 2Kdc


(xc ) (xd ) + VT (d )(d ) VT (c )(c ) .

(76)

Again, clipping performed Subsection 7.1. Note expression
evaluations () actually change optimisation process. others, especially
matrix-valued numerator may held memory speed procedure, possible.
7.3 Point Selection
remains select points c d. Platt (1999), presents number heuristics, however
improvements suggested Keerthi, Shevade, Bhattacharyya, Murthy (2001) appear
efficient form basis overviewed here. binary case
essential approach identify points requiring highest lowest offsets b
order underlying function f () might expected, i.e. sign
relevant point. considering two classes, B multi-category arrangement
directly analogous approach taken problem reduced two-class
problem across mutual boundary, comparable scalar metric found.
starting point methodology construct Lagrangian governs
dual optimisation problem given equation (13);
N

L=

N

N

i=1

i=1

N

X
X
1 XX
Ti
Ti (i )
V (i )V(j )Tj K(xi , xj )
2
i=1 j=1

+

N
X

X

i, (i, CD (i ))

N
X

Ti VT (i )

i=1

i=1 (i )

{i, , i, : {1, . . . , N }, ( )} {m : {1, . . . , (M 1)}}
Lagrangian multipliers. Differentiating respect setting result equal
zero implies that,
VT (i ) ((xi ) + ) = (i ) +
(77)
and, hence,
= VT (i ) ((i ) + ) (xi ).
555

(78)

fiHill & Doucet

KKT conditions satisfied.
combinations two classes (denoted B).
Perform two-class SMO along direction vB (A)
updates given equation (76) iup , ilow found (79)

Table 1: Algorithm Pseudo-Code

Consider update two points classes B let = A, recall
equality, discussed Keerthi et al. (2001), b. mind becomes
apparent equivalent metric updating difference respective
values across boundary two classes. find perpendicular distance,
take inner product perpendicular boundary, instance vB (A)


vB
(A) = B (A) + i,B i,B vB
(A)(xi ).

(79)

expression directly comparable equivalent key starting point point
selection process directly analogous scalar used Keerthi et al. (2001). Indeed
(A).
parameters bup blow used equivalent extreme values vB
7.4 Multi-Category SMO Summary
Following becomes possible put together complete approach;
1. Select initial two classes consider denoted generically B.
2. two classes determine two points maximum minimum values
(A) equation (79). denoted
vB
ilow respectively
correspond associated bup blow work Keerthi et al. (2001).
3. Perform updates outlined equations (74) (76) convergence
criteria (e.g. updates threshold) achieved. Point selection
made following standard two loop approach loop attempting update
points loop considering non-extremal ones. Updates attempted
respect either iup ilow maximal minimal points updated
iteration.
4. convergence achieved two classes select another two
classes repeat steps 2 3. possible combinations classes
attempted.
5. Repeat entire process updates made. point Karush-KuhnTucker (KKT) conditions nearly satisfied, checked
ensure least within acceptable limit satisfaction.
summarised pseudocode Table 1.
approach clearly closely related structure pairwise coupling algorithm
(Subsection 3.2) however single optimisation problem focus. Clearly
556

fiA Framework Kernel-Based Multi-Category Classification

algorithm may computationally intense Kreel (1999) two reasons.
First, stage updates involves matrix multiplications instead scalar ones. Second,
indicated step 5, one pass may required. hand, might
reduction overall iterations required particular class-class combination
optimisation starting scratch, rather updates previous combinations
may positive impact.
Experimentally however observed traditional pairwise coupling approach computationally efficient, also noted literature (Hsu
& Lin, 2002; Rifkin & Klautau, 2004). alluded Subsection 3.2, combined approach possible, referred combined pairwise, all-together algorithm.
Broadly, follows;
1. Perform pairwise optimisation described Kreel (1999). optimisation
requires implementation (M2 1) standard SV classifiers slight change
instead using standard 2-class value 1, use values corresponding
particular pairwise optimisation.
2. Map results classification spatial arrangement (Figures 1 2 example).
done easily observing product V(i )i equation (19)
element i, multiplies v (i ) recall perpendicular boundary
. result binary classification optimisation
classes used directly provide value i, . Note
constraint equation (17) still satisfied.
3. Finalise all-together single optimisation following steps outlined earlier
Subsection.
short bulk optimisation performed standard pairwise methodology.
geometrical approach detailed Section 2 used manipulate output
unified consistent result obtained little additional computational effort.
clear advantage practitioner sure exactly basis
classification made without resort ad hoc heuristics.

8. Examples
Extensive investigations comparative performance multi-category SVM methods
detailed Hsu Lin (2002), present current benchmark training
times. discussed, work found pairwise coupling approaches far
computationally efficient others. also found case first
SMO algorithm proposed Subsection 7.4 main aim Section investigate
performance combined pairwise, all-together algorithm. standard binary
described multi-category SMO coded straightforward way. dynamic
caching low-level code refinements used initial proof-of-concept investigation
felt detailed optimisations best done together consistent way,
dedicated comparative work Hsu Lin (2002).
datasets used obtained University California repository (Blake &
Merz, 1998). illustrative purposes training test output results DNA
557

fiHill & Doucet

dataset presented Figure 9. clear see pairwise result
Found f(x) Final
4

2

2
f (x)

0

2

2

f (x)

Found f(x), Initial Mapping
4

2

4
4

0

2

2

0
f1(x)

2

4
4

4

2

4

2

2

2

0

2

4
4

2

4

2

4

Found f(x) Final

4

f (x)

2

f (x)

Found f(x), Initial Mapping

0
f1(x)

0

2

2

0
f (x)

2

4

1

4
4

2

0
f (x)
1

Figure 9: DNA data outputs training test data cases. mapped pairwise
optimised all-together results shown. Margins analogous twoclass case clearly visible shown dashed lines. Training data forms
top row, test data bottom. numerous, N case given green
triangles, EI blue circles, IE red squares. stars indicative
class target vectors.

mapped classification plane Figure 1, changes made performing
all-together additional optimisation. short N class appears intermingled little EI class less IE class. well all-together
outputs fill corners margin intersections completely, pairwise
outputs tend cut off. often observed implementations.
training time heavily dependent tolerance within convergence
desired. value, referred Keerthi et al. (2001) indicates variation allowed
bup blow discussed Subsections 7.3 7.4. effect
additionally investigated two values , results tabulated Tables 2
3. experiments Gaussian kernels used appropriate values C
chosen trial error output accuracies (where accuracy refers percentage
classification error rate) all-together implementation comparable
Hsu Lin (2002).
actual accuracies recorded given Table, however recall that, noted
Section 3.1, optimisation problem solved generic all-together one and,
such, judicious choices C mean accuracy rates achievable
algorithms. Clearly implicit model behind pairwise approach slightly
different may indeed able achieve slightly different accuracy results.
mind aim incessantly tweak hyperparameters achieve marginally
superior results, simply look big picture performance.
558

fiA Framework Kernel-Based Multi-Category Classification

Problem
DNA
Vehicle
Satimage
Segment
Vowel
Letter


3
4
6
7
11
26

N
2000
766
4435
2079
891
15000

Pair
0.8
0.4
3.0
2.4
0.7
129.0

= 0.03C

Alone
1.1
1.5
2.7
5.3
10.8
41.8
13.2
47.9
3.5
13.3
129.9
2119.2

Pair
1.1
0.5
3.6
3.2
1.0
142.3

= 0.001C

Alone
3.7
11.7
3.5
3.9
9.0
27.6
16.2
42.0
18.5
22.8
1373.7
5573.4

Table 2: Optimisation times (seconds) various example problems. Columns present results obtained using pairwise algorithm all-together SMO algorithm
discussed. cases Pair refers pairwise optimisation time results, meanwhile denotes additional refinement time i.e. required progress
pairwise result all-together result. Finally Alone identifies time taken
all-together algorithm without initial pairwise optimisation.

Problem
DNA
Vehicle
Satimage
Segment
Vowel
Letter


3
4
6
7
11
26

N
2000
766
4435
2079
891
15000

= 0.03C
ER(Pair) ER(All)
4.4
4.6
15.0
18.8
10.6
10.8
3.0
2.6
3.0
3.0
8.8
8.8

= 0.001C
ER(Pair) ER(All)
4.6
4.5
17.5
20.0
9.7
9.2
3.0
3.0
3.0
3.0
8.9
8.8

Table 3: Optimisation error rates (percentages) various example problems. Columns
present experimentally obtained results using pairwise all-together multicategory SMO algorithms discussed. ER(Pair) refers test error rate
pairwise method ER(All) all-together algorithm.

continuing mindset, class weightings introduced, target vectors set equidistant. Clearly may well case could actually
perturbed, class weights introduced improve performance, additional
computational effort, however initial investigation done.
experiments run 2.8GHz P4 1GB RAM7 . Tables 2 3
following points become apparent,
1. optimisation times presented magnitudes similar Hsu
Lin. Although aim work produce highly refined optimal code, although comparisons always going problematic
terms implementation specifics, result is, itself, positive. Generally,
accurate implementation algorithm presented preceding sections
(when = 0.001C) convergence times similar Hsu Lin
all-together implementation. Briefly, optimisation times were; DNA, 13.5s,
vehicle 88.6s, satimage 48.2s, segment 66.4s, vowel 14.1s, letter
8786.2s. consider advantage obtained extra computational power roughly equivalent effect extra coding.
7. Hsu Lin (2002) 500MHz P3 384MB RAM.

559

fiHill & Doucet

worth noting additional intrinsic value intuitiveness, flexibility
ease implementation presented algorithm, something standard
SMO algorithm well known for. highlighted, additional computational effort
required alter class regions introduce class weights (Subsection 2.3), neither
considered Hsu Lin (2002).
2. possible approximately quantify relative effect combining pairwise
all-together algorithms context. short typically halves them, although
variation quite large. result appears roughly consistent
values .
3. anticipated, error rate results strongly favour pairwise all-together
methods; always going case-by-case issue.

9. Conclusion
geometric framework understanding multi-category classification introduced,
many existing all-together algorithms understood. structure
allows derivation parsimonious optimisation function, direct extension
binary SV classification optimisation function. seen special
case considerations need made order mathematics reduce standard
result number classes, = 2. Further, framework enables considerable
generalisation problem incorporation relative class knowledge without
additional computational complexity. far actual optimisation results concerned,
virtues proposed framework, fact, apply all-together methods
well.
found Hsu Lin (2002) Rifkin Klautau (2004), among others,
pairwise SV method converges substantial speed advantage existing
multi-category methods. However pairwise results require heuristic combine them.
avoided mapping geometric framework described finetuning obtain consistent all-together solution. refining performed
multi-category all-together algorithm.
ability framework compare algorithms illustrated brief
discussion Fisher consistency. shown graphically illustrated different loss
structures compare result Fisher inconsistent optimisation problems.
Generalisation bounds derived aim framework presented
tighter previously presented literature. also benefited
simpler derivation previously presented due fact well-known scalar
methods developed two class case directly applicable. Previously
need extend cumbersome vector methods.
addition providing generic flexible framework, architecture may
well provide insights regarding improve speed existing multicategory SV classification algorithms (whether coupled pairwise optimisation, not).
initial example might achieved developed formulation
straightforward multi-category SMO variant algorithm. proof-of-concept experimental
results shown this, combined mapping pairwise results, already
560

fiA Framework Kernel-Based Multi-Category Classification

comparable optimisation speeds achieved Hsu Lin (2002) benchmark
work, despite fact implementation code highly refined includes features
dynamic caching. Future efforts based geometric framework described
able outperform existing standards.

References
Allwein, E. L., Schapire, R. E., & Singer, Y. (2001). Reducing multiclass binary: unifying approach margin classifiers. Journal Machine Learning Research, 1 (113-141).
Bartlett, P. L. (1998). sample complexity pattern classification neural networks: size weights important size network. IEEE
Transactions Information Theory, 44 (2), 525536.
Bartlett, P. L., Jordan, M. I., & McAuliffe, J. D. (2004). Large margin classifiers: Convex
loss, low noise convergence rates. Advances Neural Information Processing
Systems, 16.
Blake, C. L., & Merz, C. J. (1998). UCI repository machine learning databases..
http://www.ics.uci.edu/mlearn/MLRepository.html.
Blanz, V., Scholkopf, B., Bulthoff, H., Burges, C. J. C., Vapnik, V. N., & Vetter, T. (1996).
Comparison view-based object recognition algorithms using realistic 3D models.
von der Malsburg, C., von Seelen, W., Vorbruggen, J. C., & Sendhoff, B. (Eds.),
Artificial Neural Networks, Vol. 1112 Springer Lecture Notes Computer Science,
pp. 251256, Berlin.
Bredensteiner, E. J., & Bennett, K. P. (1999). Multicategory classification support vector
machines. Computational Optimizations Applications, 12, 5379.
Crammer, K., & Singer, Y. (2001a). algorithmic implementation multiclass
kernel-based vector machines. Journal Machine Learning Research, 2, 265292.
Crammer, K., & Singer, Y. (2001b). Pranking ranking. Advances Neural Information Processing, Vol. 14.
Cristianini, N., & Shawe-Taylor, J. (2000). Introduction Support Vector Machines
Kernel-Based Learning Methods (1st edition). Cambridge University Press.
Dietterich, T., & Bakiri, G. (1995). Solving multiclass learning problems via error-correcting
output codes. Journal Artificial Intelligence Research, 2, 263286.
Elisseeff, A., Guermeur, Y., & Paugam-Moisy, H. (1999). Margin error generalization capabilities multi-class discriminant systems. Tech. rep. NC2-TR-1999-051-R,
NeuroCOLT2.
Fung, G., & Mangasarian, O. L. (2001a). Multicategory proximal support vector machine
classifiers. Tech. rep. 01-06, Data Mining Institute.
Fung, G., & Mangasarian, O. L. (2001b). Proximal support vector machine classifiers.
Proceedings KDD-2001, pp. 7786, San Francisco.
Furnkranz, J. (2002). Round robin classification. Journal Machine Learning, 2, 721747.
561

fiHill & Doucet

Guermeur, Y. (2000). Combining discriminant models new multi-class SVMs. Tech.
rep., NeuroCOLT2.
Guermeur, Y. (2002). Combining discriminant models new multi-class SVMs. Pattern
Analysis Applications, 5, 168179.
Hastie, T., & Tibshirani, R. (1998). Classification pairwise coupling. Michael, M.
J. K., Jordan, I., & Solla, S. A. (Eds.), Advances Neural Information Processing,
Vol. 10, pp. 507513. MIT Press.
Hastie, T., Tibshirani, R., & Friedman, J. (2001). Elements Statistical Learning.
Springer.
Herbrich, R., Graepel, T., & Campbell, C. (2000a). Bayes point machines. Journal
Machine Learning Research, 1, 245279.
Herbrich, R., Graepel, T., & Obermayer, K. (2000b). Large margin rank boundaries
ordinal regression. Advances Large Margin Classifiers, 1, 115132.
Hill, S. I. (2007). Notes generalisation performance Fisher consistency multicategory classifiers. Tech. rep. CUED/F-INFENG/TR.583, Engineering Dept, University Cambridge.
Hill, S. I., & Doucet, A. (2005). framework kernel-based multi-category classification.
Tech. rep. CUED/F-INFENG/TR.508, Engineering Dept., University Cambridge.
Hsu, C.-W., & Lin, C.-J. (2002). comparison methods multi-class support vector
machines. IEEE Transactions Neural Networks, 13, 415425.
Keerthi, S. S., Shevade, S. K., Bhattacharyya, C., & Murthy, K. R. K. (2001). Improvements
Platts SMO algorithm SVM classifier design. Neural Computation, 13, 637649.
Kindermann, J., Leopold, E., & Paa, G. (2000). Multi-class classification error correcting codes. Leopold, E., & Kirsten, M. (Eds.), Treffen der GI-Fachgruppe 1.1.3
Maschinelles Lernen. GMD Report 114.
Kreel, U. H.-G. (1999). Pairwise classification support vector machines. Scholkopf,
B., Burges, C. J. C., & Smola, A. J. (Eds.), Advances Kernel Methods: Support
Vector Learning. MIT Press.
Lee, Y., Lin, Y., & Wahba, G. (2001). Multicategory support vector machines. Tech. rep.
1043, Department Statistics, University Wisconsin.
Lee, Y., Lin, Y., & Wahba, G. (2004). Multicategory support vector machines, theory,
application classification microarray data satellite radiance data.
Journal American Statistical Association, 99, 659672.
Mangasarian, O. L., & Musicant, D. R. (2001). Lagrangian support vector machines. Journal
Machine Learning Research, 1, 161177.
Mayoraz, E., & Alpaydn, E. (1999). Support vector machines multi-class classification. Proceedings International Workshop Artifical Neural Networks
(IWANN99).
Paugam-Moisy, H., Elisseeff, A., & Guermeur, Y. (2000). Generalization performance
multiclass discriminant models..
562

fiA Framework Kernel-Based Multi-Category Classification

Platt, J. C. (1999). Fast training support vector machines using sequential minimal
optimization. Scholkopf, B., Burges, C. J. C., & Smola, A. J. (Eds.), Advances
Kernel Methods - Support Vector Learning, pp. 185208. MIT Press, Cambridge, MA.
Platt, J. C., Cristianini, N., & Shawe-Taylor, J. (2000). Large margin DAGs multiclass
classification. Solla, S. A., Lean, T. K., & Muller, K.-R. (Eds.), Advances Neural
Information Processing, Vol. 12, pp. 547553. MIT Press.
Rennie, J. D. M., & Rifkin, R. (2001). Improving multiclass text classification
support vector machine. Memo AIM-2001-026, Massachusetts Institute Technology
Artificial Intelligence Laboratory.
Rifkin, R., & Klautau, A. (2004). defense one-vs-all classification. Journal Machine
Learning Research, 5, 101141.
Scholkopf, B., Burges, C. J. C., & Vapnik, V. N. (1995). Extracting support data given
task. Fayyad, U. M., & Uthurusamy, R. (Eds.), Proceedings, First International
Conference Knowledge Discovery Data Mining, pp. 252257, Menlo Park, CA.
AAAI Press.
Scholkopf, B., & Smola, A. J. (2002). Learning Kernels. MIT Press.
Sebald, D. J. (2000). Nonlinear Signal Processing Digital Communications using Support
Vector Machines New Form Adaptive Decision Feedback Equalizer. Ph.D.
thesis, University Wisconsin-Madison.
Sebald, D. J., & Bucklew, J. A. (2001). Support vector machines multiple hypothesis
test problem. IEEE Transactions Signal Processing, 49 (11), 28652872.
Sejnowski, T. J., & Rosenberg, C. R. (1987). Parallel networks learn pronounce
English text.. Journal Complex Systems, 1, 145168.
Suykens, J. A. K., & Vandewalle, J. (1999). Multiclass least squares support vector machines. Proceedings International Joint Conference Neural Networks
(IJCNN99), Washington DC, USA.
Tewari, A., & Bartlett, P. L. (2007). consistency multiclass classification methods.
Journal Machine Learning Research, 8, 10071025.
Van Gestel, T., Suykens, J. A. K., Baesens, B., Viaene, S., Vanthienen, J., Dedene, G.,
De Moor, B., & Vandewalle, J. (2001). Benchmarking least squares support vector
machine classifiers. Machine Learning, 54 (1), 532.
Van Gestel, T., Suykens, J. A. K., Lanckriet, G., Lambrechts, A., De Moor, B., & Vandewalle, J. (2002). Multiclass LS-SVMs: Moderated outputs coding-decoding
schemes. Neural Processing Letters, 15, 4558.
Vapnik, V. N. (1998). Statistical Learning Theory. Wiley.
Wang, F., Vuurpijl, L. G., & Schomaker, L. R. B. (2000). Support vector machines
classification western handwritten capitals. Schomaker, L. R. B., & Vuurpijl, L. G. (Eds.), Proceedings 7th International Workshop Frontiers
Handwriting Recognition, pp. 167176.
Weston, J. A. E. (1999). Extensions Support Vector Method. Ph.D. thesis, University
London.
563

fiHill & Doucet

Weston, J. A. E., & Watkins, C. (1999). Support vector machines multi-class pattern recognition. Proceedings 7th European Symposium Artificial Neural
Networks.
Williamson, R. C., Smola, A. J., & Scholkopf, B. (2001). Generalization performance
regularization networks support vector machines via entropy numbers compact
operators. IEEE Transactions Information Theory, 47 (6), 25162532.
Zhang, T. (2004a). infinity-sample theory multi-category large margin classification.
Advances Neural Information Processing, 16.
Zhang, T. (2004b). Statistical analysis multi-category large margin classification.
Journal Machine Learning Research, 5, 12251251.

564

fiJournal Articial Intelligence Research 30 (2007) 659-684

Submitted 06/07; published 12/07

Learning Play Using Low-Complexity Rule-Based Policies:
Illustrations Ms. Pac-Man
Istvn Szita
Andrs Lrincz

szityu@eotvos.elte.hu
andras.lorincz@elte.hu

Dept. Information Systems
Etvs University, Hungary, H-1117

Abstract
article propose method deal certain combinatorial reinforcement learning tasks. demonstrate approach popular Ms. Pac-Man game.
dene set high-level observation action modules, rule-based policies
constructed automatically. policies, actions temporally extended, may
work concurrently. policy agent encoded compact decision list. components list selected large pool rules, either hand-crafted
generated automatically. suitable selection rules learnt cross-entropy
method, recent global optimization algorithm ts framework smoothly. Crossentropy-optimized policies perform better hand-crafted policy, reach score
average human players. argue learning successful mainly (i) policies
may apply concurrent actions thus policy space suciently rich, (ii) search
biased towards low-complexity policies therefore, solutions compact description
found quickly exist.

1. Introduction
last two decades, reinforcement learning (RL) reached mature state,
laid solid foundations. large variety algorithms, including valuefunction-based, direct policy search hybrid methods. reviews subjects,
see, e.g., books Bertsekas Tsitsiklis (1996) Sutton Barto (1998).
basic properties many algorithms relatively well understood, e.g. conditions
convergence, complexity, eect various parameters, although needless say
still lots important open questions. also plenty test problems
(like various maze-navigation tasks, pole-balancing, car hill etc.)
capabilities RL algorithms demonstrated, number large-scale RL
applications also growing steadily. However, current RL algorithms far
out-of-the-box methods, still need demonstrations showing RL
ecient complex tasks.
think games (including diverse set classical board games, card games, modern computer games, etc.) ideal test environments reinforcement learning. Games
intended interesting challenging human intelligence therefore,
ideal means explore articial intelligence still missing. Furthermore,
games well RL paradigm: goal-oriented sequential decision problems,
decision long-term eects. many cases, hidden information, random
events, unknown environment, known unknown players account (part of) diculty
c 2007 AI Access Foundation. rights reserved.


fiSzita & Lrincz

playing game. circumstances focus reinforcement learning. Games
also attractive testing new methods: decision space huge cases,
nding good strategy challenging task.
another great advantage using games test problems: rules games
xed, danger `tailoring task algorithm' i.e., tweak rules
and/or environment meet capabilities proposed RL algorithm
reduced, compared, e.g., various maze navigation tasks.
RL tried many classical games, including checkers (Samuel, 1959), backgammon (Tesauro, 1994), chess (Baxter, Tridgell, & Weaver, 2001). hand,
modern computer games got spotlight recently, many
successful attempts learn AI tools. Notable exceptions are, example, roleplaying game Baldur's Gate (Spronck, Sprinkhuizen-Kuyper, & Postma, 2003), real-time
strategy game Wargus (Ponsen & Spronck, 2004), possibly, Tetris (Szita & Lrincz,
2006). games pose new challenges RL, example, many observations
considered parallel, observation space action space huge.
spirit, decided investigate arcade game Ms. Pac-Man. game
interesting largely unsolved, also imposes several important questions
RL, overview Section 8. provide hand-coded high-level actions
observations, task RL learn combine good policy.
apply rule-based policies, easy interpret enable one include
human domain-knowledge easily. learning, apply cross-entropy method,
recently developed general optimization algorithm. show hybrid approach
successful either tabula rasa learning hand-coded strategy alone.
next section introduce Ms. Pac-Man game briey discuss
formalized reinforcement learning task. sections 3 4, shall shortly describe
cross-entropy optimization method rule-based policies, respectively. section 5,
details learning experiments provided, section 6 present results.
Section 7 provides review related literature, nally, section 8 summarize
discuss approach emphasis implications RL problems.

2. Pac-Man Reinforcement Learning
video-game Pac-Man rst released 1979, reached immense success.
considered one popular video games date (Wikipedia, 2006).
player maneuvers Pac-Man maze (see Fig. 1), Pac-Man eats dots
maze. particular maze 174 dots,1 one worth 10 points. level
nished dots eaten. make things dicult, also four
ghosts maze try catch Pac-Man, succeed, Pac-Man loses life.
Initially, three lives, gets extra life reaching 10,000 points.
four power-up items corners maze, called power dots (worth
40 points). Pac-Man eats power dot, ghosts turn blue short period (15
seconds), slow try escape Pac-Man. time, Pac-Man
1. maze original Pac-Man game slightly dierent. description applies opensource Pac-Man implementation Courtillat (2001). two versions equivalent terms
complexity entertainment value.

660

fiLearning play Ms. Pac-Man

Figure 1: snapshot Pac-Man game
able eat them, worth 200, 400, 800 1600 points, consecutively. point
values reset 200 time another power dot eaten, player would want
eat four ghosts per power dot. ghost eaten, remains hurry back center
maze ghost reborn. certain intervals, fruit appears near center
maze remains while. Eating fruit worth 100 points.
investigations restricted learning optimal policy rst level,
maximum achievable score 174 10 + 4 40 + 4 (200 + 400 + 800 + 1600) = 13900 plus
100 points time fruit eaten.
original version Pac-Man, ghosts move complex deterministic route,
possible learn deterministic action sequence require observations.
Many patterns found enthusiastic players. Pac-Man's sequels,
notably Ms. Pac-Man, randomness added movement ghosts. way,
single optimal action sequence, observations necessary optimal decision
making. respects, game play mostly unchanged.
implementation, ghosts moved randomly 20% time straight towards
Pac-Man remaining 80%, ghosts may turn back (following Koza, 1992, Chapter
12). emphasize presence randomness, shall refer implementation
Ms. Pac-Man-clone.

2.1 Ms. Pac-Man RL Task
Ms. Pac-Man meets criteria reinforcement learning task. agent make
sequence decisions depend observations. environment stochastic
(because paths ghosts unpredictable). also well-dened reward function
(the score eating things), actions inuence rewards collected future.
661

fiSzita & Lrincz

full description state would include (1) whether dots eaten (one
bit dot one power dot), (2) position direction Ms. Pac-Man,
(3) position direction four ghosts, (4) whether ghosts blue (one bit
ghost), so, long remain blue (in range 1 15 seconds) (5)
whether fruit present, time left appears/disappears (6) number
lives left. size resulting state space astronomical, kind function
approximation feature-extraction necessary RL.
action space much smaller, four basic actions: go north/south/east/west. However, typical game consists multiple hundreds steps,
number possible combinations still enormous. indicates need temporally
extended actions.
moderate amount domain knowledge Ms. Pac-Man: one, quite
easy dene high-level observations action modules potentially useful.
hand, constructing well-performing policy seems much dicult. Therefore,
provide mid-level domain knowledge algorithm: use domain knowledge
preprocess state information dene action modules. hand,
role policy search reinforcement learning combine observations modules
rule-based policies nd proper combination.

3. Cross-Entropy Method
goal optimize rule-based policies performing policy search space
legal rule-based policies. search apply cross-entropy method (CEM),
recently published global optimization algorithm (Rubinstein, 1999). aims nd
(approximate) solution global optimization tasks following form

x := arg max f (x).
x

f general objective function (e.g., need assume continuity dierentiability). summarize mechanism method briey (see also section 7.2
overview applications).

3.1 Intuitive Description
optimization algorithms maintain single candidate solution x(t) time
step, CEM maintains distribution possible solutions. distribution, solution
candidates drawn random. essentially random guessing, nice trick
turned highly eective optimization method.
3.1.1 Power Random Guessing

Random guessing overly simple `optimization' method: draw many samples
xed distribution g , select best sample estimation optimum.
limit case innitely many samples, random guessing nds global optimum.
two notes here: (i) shown Wolpert Macready (1997),
general problems, uniform random guessing worse method, (ii)
nonetheless, practical problems, uniform random guessing extremely inecient.
662

fiLearning play Ms. Pac-Man

Thus, random guessing safe start with, one proceeds collection
experience, limited much possible.
eciency random guessing depends greatly distribution g
samples drawn. example, g sharply peaked around x , samples
may sucient get good estimate. case opposite, distribution
sharply peaked around x 6= x : tremendous number examples may needed get
good estimate global optimum. Naturally, nding good distribution least
hard nding x .
3.1.2 Improving Efficiency Random Guessing

drawing moderately many samples distribution g , may able give
acceptable approximation x , may still obtain better sampling distribution.
basic idea CEM selects best samples, modies g
becomes peaked around them. Consider example, x 0-1 vector g
Bernoulli distribution coordinate. Suppose drawn 1000 samples
selected 10 best. see majority selected samples, ith coordinate
1, CEM shifts Bernoulli distribution corresponding component towards 1.
Afterwards, next set samples drawn already modied distribution.
idea seems plausible: majority best-scoring samples ith coordinate
1, structure tness landscape, may hope ith
coordinate x also 1. follows, describe update rule CEM
formal way sketch derivation.

3.2 Formal Description Cross-Entropy Method
pick g family parameterized distributions, denoted G , describe
algorithm iteratively improves parameters distribution g .
Let N number samples drawn, let samples x(1) , . . . , x(N )
drawn independently distribution g . R, set high-valued samples,

L := {x(i) | f (x(i) ) , 1 N },
provides approximation level set

L := {x | f (x) }.
Let U uniform distribution level set L . large values , distribution peaked around x , would suitable random sampling. raises two
potential problems: (i) large values L contain points (possibly none),
making accurate approximation impossible, (ii) level set L usually member
parameterized distribution family.
rst problem easy avoid choosing lower values . However,
make compromise, setting low would inhibit large improvement steps.
compromise achieved follows: CEM chooses ratio [0, 1] adjusts L
set best N samples. corresponds setting := f (x(N ) ), provided
samples arranged decreasing order values. best N samples called
elite samples. practice, typically chosen range [0.02, 0.1].
663

fiSzita & Lrincz

problem solved changing goal approximation: CEM chooses
distribution g distribution family G approximates best empirical distribution L . best g found minimizing distance G uniform
distribution elite samples. measure distance cross-entropy distance
(often called Kullback-Leibler divergence). cross-entropy distance two distributions
g h dened
Z
g(x)
DCE (g||h) = g(x) log
dx
h(x)
general form cross-entropy method summarized Table 1. known
mild regularity conditions, CE method converges probability 1 (Margolin,
2004). Furthermore, suciently large population, global optimum found
high probability.
input: G
input: g0 G
input: N
input:
input:
0 1,
1 N ,
draw x(i) distribution gt
compute fi := f (x(i) )
sort fi -values descending order
t+1 := fN
Et+1 := {x(i) | f (x(i) ) t+1 }
gt+1 := arg mingG DCE (g||Uniform(Et+1 ))
end loop

%
%
%
%
%
%

parameterized distrib. family
initial distribution
population size
selection ratio
number iterations
CEM iteration main loop

% draw N samples
% evaluate
% level set threshold
% get elite samples
% get nearest distrib. G

Table 1: Pseudo-code general cross-entropy method

3.3 Cross-Entropy Method Bernoulli Distribution
many parameterized distribution families, parameters minimum cross-entropy
member computed easily simple statistics elite samples. provide
formulae Bernoulli distributions, needed policy learning procedure
detailed next section. Derivations well list discrete continuous
distributions simple update rules found tutorial de Boer, Kroese,
Mannor, Rubinstein (2004).
Let domain optimization = {0, 1}m , component drawn
independent Bernoulli distributions, i.e., G = Bernoullim . distribution g G parameterized m-dimensional vector p = (p1 , . . . , pm ). using g sampling,
664

fiLearning play Ms. Pac-Man

component j sample x

1, probability pj ;
xj =
0, probability 1 pj .
drawing N samples x(1) , . . . , x(N ) xing threshold value , let E denote set
elite samples, i.e.,
E := {x(i) | f (x(i) ) }
notation, distribution g 0 minimum CE-distance uniform distribution elite set following parameters:

p0 := (p01 , . . . , p0m ),
P
P
(i)
(i)
x(i) E (xj = 1)
x(i) E (xj = 1)
0
P
=
pj :=
N
x(i) E 1

(1)

words, parameters g 0 simply component wise empirical probabilities
1's elite set. derivation rule, see tutorial de Boer et al. (2004).
Changing distribution parameters p p0 coarse, cases,
applying step-size parameter preferable. resulting algorithm summarized
Table 2.
input: p0 = (p0,1 , . . . , p0,m )
input: N
input:
input:
0 1,
1 N ,
draw x(i) Bernoullim (pt )
compute fi := f (x(i) )
sort fi -values descending order
t+1 := fN
Et+1 := {x(i) | f (x(i) ) t+1 }
P

(i)
p0j :=
x(i) E (xj = 1) /( N )
pt+1,j := p0j + (1 ) pt,j
end loop

%
%
%
%
%

initial distribution parameters
population size
selection ratio
number iterations
CEM iteration main loop

% draw N samples
% evaluate
%
%
%
%

level set threshold
get elite samples
get parameters nearest distrib.
update step-size

Table 2: Pseudo-code cross-entropy method Bernoulli distributions
also need optimize functions = {1, 2, . . . , K}m K > 2.
simplest case, distributions domain parameterized
K parameters:
PK
p = (p1,1 , . . . , p1,K ; . . . ; pm,1 , . . . , pm,K ) 0 pj,k 1 k=1 pj,k = 1 j (this
special case multinomial distribution).
update rule parameters essentially Eq. 1 Bernoulli case:
P
P
(i)
(i)
(i) E (xj = k)
x(i) E (xj = k)
x
0
P
=
.
(2)
pj,k :=
N
x(i) E 1
665

fiSzita & Lrincz

Note constraint

PK

0
k=1 pj,k

= 1 satised automatically j .

4. Rule-Based Policies
basic formulation, rule sentence form [Condition] holds,
[Action]. rule-based policy set rules mechanism breaking ties, i.e.,
decide rule executed, multiple rules satised conditions.
Rule-based policies human-readable, easy include domain knowledge,
able represent complex behaviors. reasons, often used many
areas articial intelligence (see section 7.3 short overview related literature).
order apply rule-based policies Ms. Pac-Man, need specify four things:
(1) possible actions (2) possible conditions
constructed observations, (3) make rules conditions actions,
(4) combine rules policies. answers described following
sections.

4.1 Action Modules
dening action modules Ms. Pac-Man, listed modules easy
implement considered potentially useful (see Table 3). way, kept human work minimum, still managed formalize part domain knowledge
problem. consequence, list action modules means optimal: actions could eective appropriate denition, others
may superuous. example, four dierent modules ghost avoidance:
FromGhost escapes nearest ghost, without considering position
ghosts; ToLowerGhostDensity tries take account inuence multiple ghosts;
FromGhostCenter moves geometrical center ghosts, thus, able avoid
surrounded trapped, but, hand, easily bump ghost
so; nally, ToGhostFreeArea considers whole board search safe
location, agent avoid shepherded ghosts. modules
may strengths weaknesses, possibly combination needed
success. also actions, potentially useful, listed
(for example, moving towards fruit).
Note also modules exclusive. example, escaping
ghosts, Ms. Pac-Man may prefer route dots eaten, may want
head towards power dot. Without possibility concurrent actions, performance
Ms. Pac-Man agent may reduced considerably (which investigated experimental
section 5.3).
need mechanism conict resolution, dierent action modules may suggest dierent directions. assigning priorities modules. agent
switches action module, also decides priority. also decision,
learning decision part learning task.2
2. Action priorities learnt indirectly: rule xed priority, action switched
rule, also inherits priority. action switched dierent rules
dierent priorities. mechanism described detail section 4.6.

666

fiLearning play Ms. Pac-Man

Table 3: List action modules used rule construction.
Name

Description

ToDot
ToPowerDot
FromPowerDot

Go towards nearest dot.
Go towards nearest power dot.
Go direction opposite nearest power
dot.
Go towards nearest edible (blue) ghost.
Go direction opposite nearest ghost.
Go towards maximally safe junction.
four directions, safety nearest junction estimated direction. Ms. PacMan n steps away junction
nearest ghost k steps away, safety
value junction n k . negative value
means Ms. Pac-Man possibly cannot reach
junction.
Go direction maximizes Euclidean
distance geometrical center ghosts.
Go current direction, choose
random available action (except turning back)
impossible.
go direction cumulative ghost
density decreases fastest. ghost denes
density cloud (with radius = 10 linear decay), cumulative ghost density
calculated.
Choose location board minimum ghost distance largest, head towards
shortest path.

ToEdGhost
FromGhost
ToSafeJunction

FromGhostCenter
KeepDirection
ToLowerGhostDensity

ToGhostFreeArea

667

fiSzita & Lrincz

Table 4: List observations used rule construction. Distances denote length
shortest path, unless noted otherwise. Distance particular object type +
object exists moment.
Name

Description

Constant
NearestDot
NearestPowerDot
NearestGhost
NearestEdGhost
MaxJunctionSafety

Constant 1 value.
Distance nearest dot.
Distance nearest power dot.
Distance nearest ghost.
Distance nearest edible (blue) ghost.
four directions, safety nearest
junction direction estimated, dened
description action ToSafeJunction.
observation returns value maximally safe junction.
Euclidean distance geometrical center
ghosts.
Euclidean distance geometrical center
uneaten dots.
ghost denes density cloud (with radius
= 10 linear decay). Returns value
cumulative ghost density.
travelling salesman distance ghosts:
length shortest route starts
Ms. Pac-Man reaches four ghosts (not
considering movement).

GhostCenterDist
DotCenterDist
GhostDensity
TotalDistToGhosts

implemented following mechanism: decision agent concerns
action modules: agent either switch or, switch action module. is,
principle, agent able use subset action modules, instead selecting
single one time step. Basically, module highest priority decides direction
Ms. Pac-Man. one equally ranked directions, lower-priority
modules checked. direction cannot decided checking switched-on modules
order decreasing priority (for example, module switched on, two directions
ranked equally switched-on modules), random direction chosen.
Ms. Pac-Man make decisions time advances whole grid cell (the
mechanism ensures never stands still), according 25 game ticks approx. 0.2
seconds simulated game time.

4.2 Observations, Conditions Rules
Similarly actions, easily dene list observations potentially useful
decision making. observations descriptions summarized Table 4.
668

fiLearning play Ms. Pac-Man

Modules could improved many ways, example, checking whether
enough time intercept edible ghosts calculating NearestEdGhost taking
consideration movement ghosts calculating NearestGhost, NearestEdGhost
MaxJunctionSafety. kept implementation modules simple possible.
designed reasonable modules, eort made make module denitions
optimal, complete non-redundant.
necessary tools dening conditions rule. typical condition
true observations given range. note status action module
also important proper decision making. example, agent may decide
ghost close, switches modules except escape module. Therefore
allow conditions check whether action module `on' `o'.
sake simplicity, conditions restricted form [observation]
< [value], [observation] > [value], [action]+, [action]-, conjunction
terms. example,

(NearestDot<5) (NearestGhost>8) (FromGhost+)
valid condition rules.
conditions actions, rules constructed easily. implementation, rule form [Condition], [Action]. example,

(NearestDot<5) (NearestGhost>8) (FromGhost+)
FromGhostCenter+
valid rule.

4.3 Constructing Policies Rules
Decision lists standard forms constructing policies single rules.
approach pursue here, too. Decision lists simply lists rules, together
mechanism decides order rules checked.
rule priority assigned. agent make decision, checks
rule list starting ones highest priority. conditions rule fullled,
corresponding action executed, decision-making process halts.
Note principle, priority rule dierent priority action
modules. However, sake simplicity, make distinction: rule priority
k switches action module, priority action module also taken k .
Intuitively, makes sense: important rule activated, eect also
important. rule priority k switches module, executed, regardless
priority module.
may worth noting many possible alternatives ordering rules
actions:

rule could xed priority, part provided domain knowledge
(Spronck, Ponsen, Sprinkhuizen-Kuyper, & Postma, 2006).
priority rule could free parameter learned CEM
method.
669

fiSzita & Lrincz

Instead absolute priorities, agent could also learn relative ordering rules
(Timuri, Spronck, & van den Herik, 2007).
order rules could determined heuristic decision mechanism.
example, generality rule e.g., rules few/many conditions large/small domains could taken account. heuristics used linear
classier systems (see e.g. work Bull & Kovacs, 2005)
principle, one would like nd interesting solutions using computer minimal
bias `domain knowledge'. regard, eciency simple priority management method satisfactory, experiment priority heuristics.

4.4 Example
Let us consider example shown Table 5. rule-based policy Ms. PacMan agent.
Table 5: hand-coded policy playing Ms. Pac-Man. Bracketed numbers denote
priorities, [1] highest priority.
[1]
[1]
[2]
[2]
[3]
[3]
[3]
[3]










NearestGhost<4 FromGhost+
NearestGhost>7 JunctionSafety>4 FromGhostNearestEdGhost>99 ToEdGhostNearestEdGhost<99 ToEdGhost+
Constant>0 KeepDirection+
FromPowerDot- ToPowerDot+
GhostDensity<1.5 NearestPowerDot<5 FromPowerDot+
NearestPowerDot>10 FromPowerDot-

rst two rules manage ghost avoidance: ghost close, agent
ee, gets safe distance. Ghost avoidance priority
activities. next two rules regulate edible ghost
board, agent chase (the value NearestEdGhost innity (> 99)
edible ghosts, 41 board, are). activity also
relatively high priority, eating ghosts worth lots points, must done
blueness ghosts disappears, must done quickly. fth rule says
agent turn back, directions equally good. rule prevents
unnecessary zigzagging (while dots eaten), surprisingly eective.
remaining rules tweak management power dots. Basically, agent prefers eat
power dot. However, blue ghosts board, power dot resets
score counter 200, bad move. Furthermore, ghost density low around
agent, probably hard collect ghosts, preferable
wait eating power dot.
670

fiLearning play Ms. Pac-Man

4.5 Mechanism Decision Making
mechanism decision making depicted Fig 2. short, (hidden) state-space
world Ms. Pac-Man Ghosts. dynamics (hidden) statespace determines vector observations, checked conditions.
conditions rule satised, corresponding action module switched o.
consequence, multiple actions may eect once. example, decision depicted
Fig. 2 sets two actions work together.

Figure 2: Decision-making mechanism Ms. Pac-Man agent. time step t,
agent receives actual observations state action modules.
checks rules script order, executes rst rule satised
conditions.
Initially, action module switched-o state. module switched
on, remains either explicitly switched another module
priority switched replaces it.

4.6 Learning Rule-Based Policies CEM
apply CEM searching space rule-based policies. Learning composed
three phases: (1) generation random policies drawn according current parameter
set, (2) evaluation policies, consists playing game Ms. Pac-Man
measure score, (3) updating parameter set using CEM update rules.
4.6.1 Drawing Random Scripts Predefined Rule-Base

Suppose predened rule-base containing K rules (for example, one listed
Appendix A). policy rule slots. slot lled K rules,
671

fiSzita & Lrincz

left empty. result, policies could contain rules, possibly much less.
rule slot xed priority, too, set {1, 2, 3}.3 priority rule slot
change learning. Learning can, however, push important rule high-priority
slot low-priority one, vice versa.
1 m, slot lled rule rule-base probability pi ,
left empty probability 1 pi . decided slot
PKbe lled,
particular rule j (1 j K ) selected probability qi,j , j=1 qi,j = 1
slot {1, . . . , m}. result, policies could contain rules, possibly much
less. pi values qi,j values learnt simultaneously cross-entropy
method (Table 2), using update rules (1) (2), respectively. gives total
+ K parameters optimize (although eective number parameters much
less, qi,j values unused slots irrelevant). Initial probabilities set
pi = 1/2 qi,j = 1/K .
4.6.2 Drawing Random Rules without Predefined Rule-Base

studied situations lessened domain knowledge; use predened rulebase. Script generation kept same, rule-base K rules generated
randomly. case generated dierent rule-bases rule slots; low
ratio meaningful rules counteracted increased rule variety.
random rule random pair randomly drawn condition set randomly
drawn action. Random condition sets contained 2 conditions. random action constructed follows: action module selected uniformly set modules listed
Table 3, switched probability 50%. construction random condition starts uniformly random selection module either Table 3 Table
4. selected module action, condition [action]- [action]+
equal probability. selected module observation, condition
[observation]<[value] [observation]>[value] equal probability, [value]
selected uniformly ve-element set. values set determined separately observation module follows: played 100 games using xed policy
recorded histogram values observation. Subsequently, ve-element set
determined would split histogram regions equal area. example,
value set NearestGhost {12, 8, 6, 5, 4}.
design random rule generation procedure contains arbitrary elements (e.g.
number conditions rule, number values observation compared
to). intuition behind procedure generate rules suciently versatile,
ratio meaningless rules (e.g. rules unsatisable conditions) large.
However, optimization form done point.

5. Description Experiments
According assumptions, eectiveness described architecture based
three pillars: (1) human domain knowledge provided modules rules; (2)
3. According preliminary experiments, quality learned policy improve increasing
priority set number slots.

672

fiLearning play Ms. Pac-Man

eectiveness optimization algorithm; (3) possibility concurrent actions.
Below, describe set experiments designed test assumptions.

5.1 Full Architecture
rst experiment, random rules used. construction, use modules
dened sections 4.1 4.2. second experiment, rules generated randomly,
hand-coded. case, role learning determine rules
used.
5.1.1 Learning Random Rule Construction

rst experiment, rule-base generated randomly, described section 4.6.2.
number rule slots xed = 100 (priorities distributed evenly), one
containing K = 100 randomly generated rules. values K selected
coarse search parameter space.
parameters CEM follows: population size N = 1000, selection ratio
= 0.05, step size = 0.6.4 values fairly standard CEM,
tried varying them. step, probabilities using rule slot (that
is, values pi , qi,j ) slightly decreased, using decay rate = 0.98.
larger decay rate, useful rules also annulled often. hand, smaller
decay aect performance, many superuous rules left policies.
score given policy huge variance due random factors game.
Therefore, obtain reliable tness estimations, score policy averaged
3 subsequent games. Learning lasted 50 episodes, sucient tune
probability close either 0 1. performed 10 parallel training runs. experiment
type denoted CE-RandomRB.
5.1.2 Learning Hand-Coded Rules

second experiment constructed rule-base K = 42 hand-coded rules (shown
Appendix A) thought potentially useful. could placed one
= 30 rule slots.5 parameters experiment identical previous
one. experiment type denoted CE-FixedRB.

5.2 Eect Learning Algorithm
following experiment, compared performance CEM simple stochastic
gradient optimization. single comparison sucient measure eciency
CEM; serves provide point reference. comparison relevant,
algorithms similar complexity move gradually towards
best samples found far. dierence SG maintains single solution
4. Note per-episode learning rate. would correspond per-instance learning rate
0 = /( N ) = 0.012 on-line learning algorithm.
5. contrast previous experiment, rules meaningful potentially useful. Therefore
need large pool rules, much lower used. found algorithm
fairly insensitive choice m; signicant changes performance observed parameter
modied factor 3.

673

fiSzita & Lrincz

candidate time, whereas CEM maintains distribution solutions. Thus, CEM
maintains memory solutions becomes less fragile occasional wrong parameter
changes.
particular form stochastic gradient search following: initial policy
drawn random (consisting 6 rules). that, generated 100 random mutation
current solution candidate step, evaluated obtained policies. bestperforming mutation chosen next solution candidate. Mutations generated
using following procedure: (1) rule, condition changed random new
condition probability 0.05; (2) rule, action changed random new
action probability 0.05. listed parameter values (number rules policy, number
mutated policies, probabilities mutation) results coarse parameter-space
optimization.
number episodes set 500. way, evaluated number
dierent policies (50,000) CEM experiments. random rule-base
xed rule-base experiments repeated using stochastic gradient method, executing
10 parallel training runs. resulting policies denoted SG-RandomRB SGFixedRB, respectively.

5.3 Eect Parallel Actions
According assumptions, possibility parallel actions plays crucial role
success architecture. conrm assumption, repeated previous experiments
concurrent actions disabled. agent switches action module,
action modules switched automatically. experiment types denoted
CE-RandomRB-1action, CE-FixedRB-1action, SG-RandomRB-1action SGFixedRB-1action.

5.4 Baseline Experiments
order isolate assess contribution learning, performed two additional
experiments dierent amounts domain knowledge learning. Furthermore,
asked human subjects play game.
5.4.1 Random Policies

rst non-learning experiment, used rule-base 42 hand-coded rules (identical
rule-base CE-FixedRB). Ten rules selected random, random priorities
assigned them. measured performance policies constructed way.
5.4.2 Hand-Coded Policy

second non-learning experiment, hand-coded rules priorities,
is, hand-coded full policy. policy shown Table 5, constructed
trial-and-error. Naturally, policy constructed knowing results
learning experiments.
674

fiLearning play Ms. Pac-Man

Table 6: Ms. Pac-Man results. See text details. Abbreviations: CE: learning
cross-entropy method, SG: learning stochastic gradient, randomRB:
randomly generated rule-base, fixedRB: xed, hand-coded rule-base, 1action:
one action module work time.
Method

Avg. Score

(25%/75% percentiles)

6382
4135
5449

(6147/6451)
(6682/9369)
(3356/5233)
(4843/6090)

CE-randomRB-1action
CE-fixedRB-1action
SG-randomRB-1action
SG-fixedRB-1action

5417
5631
2267
4415

(5319/5914)
(5705/5982)6
(1770/2694)
(3835/5364)

Random policy
Hand-coded policy
Human play

676
7547
8064

(140/940)
(6190/9045)
(5700/10665)

CE-randomRB
CE-fixedRB
SG-randomRB
SG-fixedRB

8186

5.4.3 Human Play

nal experiment, human subjects asked play rst level Ms. PacMan measured performance. subjects played Pac-Man and/or
similar games before, none experienced player.

6. Experimental Results
Human experiments performed rst level open-source Pac-Man clone
Courtillat (2001). experiments applied Delphi re-implementation
code.
learning experiments, 10 parallel learning runs executed, one 50
episodes. training period sucient tune probabilities close either 0
1, learned policy could determined unambiguously cases. obtained
policy tested playing 50 consecutive games, giving total 500 test games per
experiment. non-learning experiments agents played 500 test games, too, using
random policies hand-coded policy, respectively. human subject played 20
games, giving total 100 test games. Results summarized Table 6. provide
25% 75% percentile values instead variances, distribution scores
highly non-Gaussian.
6. fact average smaller 25% percentile caused highly skewed distribution
scores. games, agent reached score range 5800 300, except games
extremely low score. games aect 25% percentile lowered average
signicantly.

675

fiSzita & Lrincz

[1]
[1]
[2]
[2]
[2]
[3]








NearestGhost<3 FromGhost+
MaxJunctionSafety>3 FromGhostNearestEdGhost>99 ToPowerDot+
NearestEdGhost<99 ToEdGhost+
GhostDensity<1.5 NearestPowerDot<5 FromPowerDot+
Constant>0 ToCenterofDots+

Figure 3: Best policy learned CE-fixedRB. Average score 50 games: 9480.
[1]
[1]
[1]
[2]
[2]
[2]
[3]









MaxJunctionSafety>2.5 ToLowerGhostDensity- FromGhostNearestGhost<6 MaxJunctionSafety<1 FromGhost+
NearestGhost>6 FromGhostCenter- ToEdGhost+
ToEdGhost- CenterOfDots>20 ToEdGhost+
ToEdGhost- NearestEdGhost<99 ToEdGhost+
NearestDot>1 GhostCenterDist>0 KeepDirection+
ToGhostFreeArea- ToDot- ToPowerDot+

Figure 4: Best policy learned CE-randomRB. Average score 50 games: 7199.
Note presence always-true (and thus, superuous) conditions like
ToLowerGhostDensity-, FromGhostCenter-, ToGhostFreeArea- ToDot-.

Fig. 3 shows best individual policy learned CE-fixedRB, reaching 9480 points
average. Ghost avoidance given highest priority, turned ghost
close. Otherwise Ms. Pac-Man concentrates eating power dots subsequently
eating blue ghosts. also takes care eat power dot blue
ghosts board, otherwise would miss opportunity eat 1600-point
ghost (and possibly several others, too). lowest priority setting, agent looks
ordinary dots, although rule eect previous rules decide
direction (for example, endgame power dots left ghosts
original form).
Policies learnt CE-randomRB behave similarly ones learnt CE-fixedRB,
although behavior somewhat obscured superuous conditions and/or rules,
demonstrated clearly example policy shown Fig. 4. noise generated
random rules, algorithm often fails learn correct priorities various
activities.
eect enabling/disabling concurrent actions also signicant. instructive
take look best policy learned CE-fixedRB-1action shown Fig. 5:
agent concentrate eating ghosts, major source reward. However,
cannot use modules necessary ghost avoidance long-term survival.
results also show CEM performs signicantly better stochastic gradient
learning. believe, however, dierence could lowered thorough search
parameter space. SG many global optimization methods like evolutionary
methods simulated annealing could reach similar performances CEM. According
de Boer et al. (2004) applications cited section 7.2, advantage CEM
676

fiLearning play Ms. Pac-Man

[2] NearestEdGhost>99 ToPowerDot+
[2] NearestEdGhost<99 ToEdGhost+

Figure 5: Best policy learned CE-fixedRB-1action. Average score 50 games:
6041.

maintains distribution solutions reach robust performance
little eort, requiring little tuning parameters: canonical set
parameters (0.01 0.1, 0.5 0.8, population large possible)
performance method robust. claim coincides experiences
parameter-optimization process.
Finally, interesting analyze dierences tactics human
computer players. One fundamental tactic human players try lure
ghosts close Ms. Pac-Man ghosts close other. way,
eaten fast turn blue. behavior evolved
experiments. Besides, tactics CEM chance discover,
lacking appropriate sensors. example, human player (and does) calculate
time remaining blue period, approximate future position ghosts,
on.

7. Related Literature
section, review literature learning Pac-Man game, various components learning architecture: cross-entropy method, rule-based policies,
concurrent actions.

7.1 Previous Work (Ms.) Pac-Man
Variants Pac-Man used previously several studies. direct comparison
performances possible cases, however, simplied versions
game used studies.
Koza (1992) uses Ms. Pac-Man example application genetic programming.
uses dierent score value fruit (worth 2000 points instead 100 points used
here), shape board (and consequently, number dots) also dierent,
therefore scores cannot directly compared. However, Koza reports (on p. 355)
Pac Man could scored additional 9000 points captured four monsters
four occasions turned blue. score, one reported,
translates approximately 5000 points scoring system.
Lucas (2005) also uses full-scale Ms. Pac-Man game test problem. trains
neural network position evaluator hand-crafted input features. purposes
training, uses evolutionary strategy approach. obtained controller able
reach 4781 116 points, averaged 100 games.
Bonet Stauer (1999) restrict observations 10 10 window centered Ms. PacMan, uses neural network temporal-dierence learning learn reactive con677

fiSzita & Lrincz

troller. series increasingly dicult learning tasks, able teach basic
pellet-collecting ghost-avoidance behaviors greatly simplied versions game:
used simple mazes containing power dots one ghost.
Gallagher Ryan (2003) denes behavior agent parameterized nite
state automata. parameters learnt population-based incremental learning,
evolutionary method similar CEM. run simplied version Pac-Man;
single ghost power dots, takes away complexity game.
Tiong (2002) codes rule-based policies Pac-Man hand, uses learning
improve them. tests, similarly ours, based Pac-Man implementation
Courtillat (2001), limits number ghosts 1. best-performing rule set
reaches 2164 points average maximal 2700. However, results likely
scale well increasing number ghosts: ghost eaten 1.4 times
average (out possible 4 times per game).7

7.2 Cross-Entropy Method
cross-entropy method Rubinstein (1999) general algorithm global optimization
tasks, bearing close resemblance estimation-of-distribution evolutionary methods (see e.g.
paper Muehlenbein, 1998). areas successful application range combinatorial optimization problems like optimal buer allocation problem (Allon, Kroese, Raviv,
& Rubinstein, 2005), DNA sequence alignment (Keith & Kroese, 2002) independent process analysis (Szab, Pczos, & Lrincz, 2006).
cross-entropy method several successful reinforcement learning applications, too:
Dambreville (2006) uses CEM learning input-output hierarchical HMM controls
predator agent partially observable grid world; Menache, Mannor, Shimkin (2005)
use radial basis function approximation value function continuous maze navigation task, use CEM adapt parameters basis functions; nally, Mannor,
Rubinstein, Gat (2003) apply CEM policy search simple grid world maze navigation problem. Recently, cross-entropy method also applied successfully
game Tetris Szita Lrincz (2006).

7.3 Rule-Based Policies
representation policies rule sequences widespread technique complex problems like computer games. example, many Pac-Man-related papers listed
use rule-based representation.
Learning classier systems (Holland, 1986) genetic-algorithm based methods
evolve suitable rules given task. Bull (2004) gives excellent general overview
pointers references. Hayek machine Baum (1996) similar architecture,
agents (corresponding simple rules) dene economical system: make bids
executing tasks hope obtain rewards. Schaul (2005) applies
architecture Sokoban game.
Dynamic scripting (Spronck et al., 2006) another prominent example using
learning rule-based policies. uses hand-coded rule-base reinforcement-learning7. Results cited section 3.6.

678

fiLearning play Ms. Pac-Man

like principle determine rules included policy. Dynamic scripting
successful applications state-of-the-art computer games like role-playing game
Neverwinter Nights (Spronck et al., 2006) real-time strategy game Wargus (Ponsen
& Spronck, 2004).

7.4 Concurrent Actions
traditional formalizations RL tasks, agent select execute single action
time. work known us handles concurrent actions explicitly Rohanimanesh Mahadevan (2001). formalize RL tasks concurrent actions
framework semi-Markov decision processes present simple grid world demonstrations.

8. Summary Closing Remarks
article proposed method learns play Ms. Pac-Man. dened
set high-level observation action modules following properties: (i) actions
temporally extended, (ii) actions exclusive, may work concurrently.
method uncover action combinations together priorities. Thus, agent
pursue multiple goals parallel.
decision agent concerns whether action module turned (if
o) (if on). Furthermore, decisions depend current observations
may depend state action modules. policy agent represented
list if-then rules priorities. policies easy interpret analyze.
also easy incorporate additional human knowledge. cross-entropy method used
learning policies play well. Learning biased towards low-complexity policies,
consequence policy representation applied cross entropy learning
method. CEM, higher complexity solutions harder discover special means
used counteract premature convergence. solutions higher complexities,
noise injection suggested previous work (Szita & Lrincz, 2006). Learned
low complexity policies reached better score hand-coded policy average human
players.
applied architecture potentials handle large, structured observation-
action-spaces, partial observability, temporally extended concurrent actions. Despite
versatility, policy search eective, biased towards low-complexity
policies. properties attractive point view large-scale applications.

8.1 Role Domain Knowledge
demonstrating abilities RL algorithm, desirable learning starts
scratch, contribution learning clearly measurable. However, choices
test problems often misleading: many `abstract' domains contain considerable amount
domain knowledge implicitly. example, consider grid world navigation tasks,
often used class problems tabula rasa learning.
simple version grid world navigation task, state integer uniquely
identies position agent, atomic actions moves grid cells north/south/east/west actual cell. importantly, unique identication
679

fiSzita & Lrincz

position means moves agent change direction agent
task laboratory coordinate framework, sometimes called allocentric coordinates,
egocentric coordinates. concepts north, south, etc. correspond
high-level abstraction, meaning humans only, must considered
part domain knowledge. domain knowledge provided us similar grid
world sense also provide high-level observations allocentric form,
`distance nearest ghost d' `Ms. Pac-Man position (11, 2)'. Similarly, action `go
north' action `go towards nearest power dot' essentially level.
implicit presence high-level concepts becomes even apparent move
abstract MDPs `real world'. Consider robotic implementation maze
task: full state information, i.e. state well state environment
available robot. sees local features may see local features
time. obtain exact position, move one unit's length prescribed direction,
robot integrate information movement sensors, optical/radar sensors etc.
information fusion, although necessary, topic reinforcement learning. Thus,
task, great amount domain knowledge needs provided
CE based policy search method could applied.
opinion, role human knowledge selects set observations
actions suit learning algorithm. extra knowledge typically necessary
applications. Nonetheless, numerous (more-or-less successful) approaches exist obtaining
domain knowledge automatically. According one approach, set observations
chosen rich (and redundant) set observations feature selection method.
cross-entropy method seems promising here, (see paper Szita, 2006,
application feature selection brain fMRI data 2006 Pittsburgh Brain Activity
Interpretation Competition). According dierent approach, successful combinations
lower level rules joined higher level concepts/rules. Machine learning
powerful tools here, e.g. arithmetic coding data compression (Witten, Neal, & Cleary,
1987). applied many areas, including writing tool Dasher developed Ward
MacKay (2002). extensions included framework reinforcement
learning.

8.2 Low-Complexity Policies
space legal policies huge (potentially innite), interesting question
search eective huge space. Direct search formidable. think
implicit bias towards low-complexity policies useful studied here.
low-complexity policy, mean following: policy may consist many
rules, cases, applied concurrently. Unused rules
get rewarded get punished unless limit useful rule, eective length
policies biased towards short policies. implicit bias strengthened explicit
one work: absence explicit reinforcement, probability applying rule
decays, indierent rules get wiped quickly. seems promising use frequent low
complexity rule combinations building blocks continued search powerful
still low-complexity policies.
680

fiLearning play Ms. Pac-Man

bias towards short policies reduces eective search space considerably. Moreover, many real-life problems, low-complexity solutions exist (for excellent analysis
possible reasons, see paper Schmidhuber, 1997). Therefore, search concentrated
relevant part policy space, pays less attention complex policies (which
therefore less likely according Occam's razor arguments.)

Acknowledgments
Please send correspondence Andrs Lrincz. authors would like thank anonymous reviewers detailed comments suggestions improving presentation
paper. material based upon work supported partially European Oce
Aerospace Research Development, Air Force Oce Scientic Research, Air Force
Research Laboratory, Contract No. FA-073029. research also supported
EC FET grant, `New Ties project' contract 003752. opinions, ndings
conclusions recommendations expressed material authors
necessarily reect views European Oce Aerospace Research Development, Air Force Oce Scientic Research, Air Force Research Laboratory, EC,
members EC New Ties project.

Appendix A. Hand-Coded Rule-Base
list rules hand-coded rule-base used experiments.
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25



























Constant>0 ToDot+
Constant>0 ToCenterofDots+
NearestGhost<4 FromGhost+
NearestGhost<3 FromGhost+
NearestGhost<5 FromGhost+
NearestGhost>5 FromGhostNearestGhost>6 FromGhostNearestGhost>7 FromGhostConstant>0 ToSafeJunction+
MaxJunctionSafety<3 ToSafeJunction+
MaxJunctionSafety<1 ToSafeJunction+
MaxJunctionSafety>3 ToSafeJunctionMaxJunctionSafety>3 FromGhostMaxJunctionSafety>5 ToSafeJunctionMaxJunctionSafety>5 FromGhostConstant>0 KeepDirection+
Constant>0 ToEdGhost+
NearestGhost<4 ToPowerDot+
NearestEdGhost<99 ToPowerDotNearestEdGhost<99 NearestPowerDot<5 FromPowerDot+
NearestEdGhost<99 FromPowerDot+
NearestEdGhost>99 FromPowerDotNearestEdGhost>99 ToPowerDot+
GhostDensity>1 ToLowerGhostDensity+
GhostDensity<0.5 ToLowerGhostDensity681

fiSzita & Lrincz

26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42



















NearestPowerDot<2 NearestGhost<5 ToPowerDot+
NearestGhost>7 MaxJunctionSafety>4 FromGhostGhostDensity<1.5 NearestPowerDot<5 FromPowerDot+
NearestPowerDot>10 FromPowerDotTotalDistToGhosts>30 FromPowerDot+
MaxJunctionSafety<3 FromGhost+
MaxJunctionSafety<2 FromGhost+
MaxJunctionSafety<1 FromGhost+
MaxJunctionSafety<0 FromGhost+
Constant>0 FromGhostCenter+
NearestGhost<4 FromGhost+
NearestGhost>7 MaxJunctionSafety>4 FromGhostNearestEdGhost>99 ToEdGhostNearestEdGhost<99 ToEdGhost+
FromPowerDot- ToPowerDot+
GhostDensity<1.5 NearestPowerDot<5 FromPowerDot+
NearestPowerDot>10 FromPowerDot-

References
Allon, G., Kroese, D. P., Raviv, T., & Rubinstein, R. Y. (2005). Application crossentropy method buer allocation problem simulation-based environment.
Annals Operations Research, 134, 137151.
Baum, E. B. (1996). Toward model mind laissez-faire economy idiots.
Proceedings 13rd International Conference Machine Learning, pp. 2836.
Baxter, J., Tridgell, A., & Weaver, L. (2001). Machines learn play games, chap.
Reinforcement learning chess, pp. 91116. Nova Science Publishers, Inc.
Bertsekas, D. P., & Tsitsiklis, J. N. (1996). Neuro-Dynamic Programming. Athena Scientic.
Bonet, J. S. D., & Stauer, C. P. (1999). Learning play Pac-Man using incremental
reinforcement learning.. [Online; accessed 09 October 2006].
Bull, L. (2004). Applications Learning Classier Systems, chap. Learning Classier Systems: Brief Introduction, pp. 313. Springer.
Bull, L., & Kovacs, T. (2005). Foundations Learning Classier Systems, chap. Foundations
Learning Classier Systems: Introduction, pp. 314. Springer.
Courtillat, P. (2001). NoN-SeNS Pacman 1.6 C sourcecode.. [Online; accessed 09
October 2006].
Dambreville, F. (2006). Cross-entropic learning machine decision partially
observable universe. Journal Global Optimization. appear.
de Boer, P.-T., Kroese, D. P., Mannor, S., & Rubinstein, R. Y. (2004). tutorial
cross-entropy method. Annals Operations Research, 134, 1967.
682

fiLearning play Ms. Pac-Man

Gallagher, M., & Ryan, A. (2003). Learning play pac-man: evolutionary, rule-based
approach. et. al., R. S. (Ed.), Proc. Congress Evolutionary Computation, pp.
24622469.
Holland, J. H. (1986). Escaping brittleness: possibilities general-purpose learning
algorithms applied parallel rule-based systems. Mitchell, Michalski, & Carbonell
(Eds.), Machine Learning, Articial Intelligence Approach. Volume II, chap. 20,
pp. 593623. Morgan Kaufmann.
Keith, J., & Kroese, D. P. (2002). Sequence alignment rare event simulation. Proceedings 2002 Winter Simulation Conference, pp. 320327.
Koza, J. (1992). Genetic programming: programming computers means
natural selection. MIT Press.
Lucas, S. M. (2005). Evolving neural network location evaluator play Ms. Pac-Man.
IEEE Symposium Computational Intelligence Games, pp. 203210.
Mannor, S., Rubinstein, R. Y., & Gat, Y. (2003). cross-entropy method fast policy
search. 20th International Conference Machine Learning.
Margolin, L. (2004). convergence cross-entropy method. Annals Operations
Research, 134, 201214.
Menache, I., Mannor, S., & Shimkin, N. (2005). Basis function adaptation temporal
dierence reinforcement learning. Annals Operations Research, 134 (1), 215238.
Muehlenbein, H. (1998). equation response selection use prediction.
Evolutionary Computation, 5, 303346.
Ponsen, M., & Spronck, P. (2004). Improving adaptive game AI evolutionary learning.
Computer Games: Articial Intelligence, Design Education.
Rohanimanesh, K., & Mahadevan, S. (2001). Decision-theoretic planning concurrent
temporally extended actions. Proceedings 17th Conference Uncerainty
Articial Intelligence, pp. 472479.
Rubinstein, R. Y. (1999). cross-entropy method combinatorial continuous
optimization. Methodology Computing Applied Probability, 1, 127190.
Samuel, A. L. (1959). studies machine learning using game checkers. IBM
Journal Research Development, 6, 211229.
Schaul, T. (2005). Evolving compact concept-based Sokoban solver. Master's thesis, cole
Polytechnique Fdrale de Lausanne.
Schmidhuber, J. (1997). computer scientist's view life, universe, everything.
Freksa, C., Jantzen, M., & Valk, R. (Eds.), Foundations Computer Science:
Potential - Theory - Cognition, Vol. 1337 Lecture Notes Computer Science, pp.
201208. Springer, Berlin.
683

fiSzita & Lrincz

Spronck, P., Ponsen, M., Sprinkhuizen-Kuyper, I., & Postma, E. (2006). Adaptive game ai
dynamic scripting. Machine Learning, 63 (3), 217248.
Spronck, P., Sprinkhuizen-Kuyper, I., & Postma, E. (2003). Online adaptation computer
game opponent AI. Proceedings 15th Belgium-Netherlands Conference
Articial Intelligence, pp. 291298.
Sutton, R. S., & Barto, A. G. (1998). Reinforcement Learning: Introduction. MIT Press,
Cambridge.
Szab, Z., Pczos, B., & Lrincz, A. (2006). Cross-entropy optimization independent
process analysis. ICA, pp. 909916.
Szita, I. (2006). select 100 voxels best prediction simplistic
approach. Tech. rep., Etvs Lornd University, Hungary.
Szita, I., & Lrincz, A. (2006). Learning Tetris using noisy cross-entropy method. Neural
Computation, 18 (12), 29362941.
Tesauro, G. (1994). TD-Gammon, self-teaching backgammon program, achieves masterlevel play. Neural Computation, 6 (2), 215219.
Timuri, T., Spronck, P., & van den Herik, J. (2007). Automatic rule ordering dynamic
scripting. Third Articial Intelligence Interactive Digital Entertainment
Conference, pp. 4954.
Tiong, A. L. K. (2002). Rule set representation tness functions articial pac man
playing agent. Bachelor's thesis, Department Information Technology Electrical
Engineering.
Ward, D. J., & MacKay, D. J. C. (2002). Fast hands-free writing gaze direction. Nature,
418, 838540.
Wikipedia (2006). Pac-Man Wikipedia, free encyclopedia. Wikipedia. [Online;
accessed 20 May 2007].
Witten, I. A., Neal, R. M., & Cleary, J. G. (1987). Arithmetic coding data compression.
Communications ACM, 30, 520540.
Wolpert, D. H., & Macready, W. G. (1997). free lunch theorems optimization. IEEE
Transactions Evolutionary Computation, 1, 6782.

684

fiJournal Artificial Intelligence Research 30 (2007) 181-212

Submitted 03/07; published 10/07

Knowledge Derived Wikipedia
Computing Semantic Relatedness
Simone Paolo Ponzetto
Michael Strube

PONZETTO @ EML - RESEARCH . DE
STRUBE @ EML - RESEARCH . DE

EML Research gGmbH, Natural Language Processing Group
Schloss-Wolfsbrunnenweg 33, 69118 Heidelberg, Germany
http://www.eml-research.de/nlp

Abstract
Wikipedia provides semantic network computing semantic relatedness structured
fashion search engine coverage WordNet. present experiments
using Wikipedia computing semantic relatedness compare WordNet various benchmarking datasets. Existing relatedness measures perform better using Wikipedia baseline
given Google counts, show Wikipedia outperforms WordNet datasets.
also address question whether Wikipedia integrated NLP applications
knowledge base. Including Wikipedia improves performance machine learning based
coreference resolution system, indicating represents valuable resource NLP applications. Finally, show method easily used languages English
computing semantic relatedness German dataset.

1. Introduction
advances Natural Language Processing (NLP) made recently investigating data-driven methods, namely statistical techniques, believe advances crucially
depend availability world domain knowledge. essential high-level linguistic tasks require language understanding capabilities question answering (e.g., Hovy,
Gerber, Hermjakob, Junk, & Lin, 2001) recognizing textual entailment (Bos & Markert, 2005;
Tatu, Iles, Slavick, Novischi, & Moldovan, 2006, inter alia). However, many domainindependent knowledge bases available provide large amount information named
entities (the leaves taxonomy) contain continuously updated knowledge processing
current information.
article approach problem novel1 perspective making use wide
coverage online encyclopedia, namely Wikipedia. use encyclopedia anyone edit
compute semantic relatedness taking system categories Wikipedia semantic
network. way overcome well known knowledge acquisition bottleneck deriving
knowledge resource large, collaboratively created encyclopedia. question
whether quality resource high enough used successfully NLP applications.
performing two different evaluations provide answer question.
show Wikipedia derived semantic relatedness correlates well human judgments, also
information used include lexical semantic information NLP application,
namely coreference resolution, world knowledge considered important since early
1. article builds upon extends Ponzetto Strube (2006a) Strube Ponzetto (2006).
c
2007
AI Access Foundation. rights reserved.

fiP ONZETTO & TRUBE

research (Charniak, 1973; Hobbs, 1978), integrated recently means WordNet
(Harabagiu, Bunescu, & Maiorano, 2001; Poesio, Ishikawa, Schulte im Walde, & Vieira, 2002).
begin introducing Wikipedia measures semantic relatedness Section 2.
Section 3 show semantic relatedness measures ported Wikipedia. evaluate approach using datasets designed evaluating measures Section 4.
available datasets small seem assembled rather arbitrarily perform additional
extrinsic evaluation means coreference resolution system Section 5. Section 6 show
relatedness measures computed using Wikipedia easily ported language
English, i.e. German. give details implementation Section 7, present related work
Section 8 conclude future work directions Section 9.

2. Wikipedia Semantic Relatedness Measures
section describe structure Wikipedia present measures use computing
semantic relatedness within categorization network.
2.1 Wikipedia
Wikipedia multilingual web based encyclopedia. collaborative open source medium,
edited volunteers. Wikipedia provides large domain-independent encyclopedic repository. English version, 14 February 2006, contains 971,518 articles 18.4 million
internal hyperlinks2 .
text Wikipedia highly structured. Apart article pages formatted terms
sections paragraphs, various relations exists pages themselves. include:
Redirect pages: pages used redirect query actual article page containing
information entity denoted query. used point alternative expressions
entity article, accordingly models synonymy. Examples include CAR
SICKNESS3 redirecting AUTOMOBILE DISEASE pages respectively, well
U.S.A., U.S., USA, US, ESTADOS UNIDOS YANKEE LAND redirecting
UNITED STATES page.
Disambiguation pages: pages collect links number possible entities original
query could pointed to. models homonymy. instance, page BUSH contains
links pages SHRUB, BUSH LOUISIANA, GEORGE H.W. BUSH GEORGE W.
BUSH.
Internal links: Articles mentioning encyclopedic entries point internal hyperlinks. models article cross-reference. instance, page PATAPHYSICS contains links term inventor, ALFRED JARRY, followers RAYMOND QUENEAU,
well distinctive elements philosophy NONSENSICAL LANGUAGE.
Since May 2004 Wikipedia provides also semantic network means categories: articles assigned one categories, categorized provide so-called
2. Wikipedia downloaded http://download.wikimedia.org. experiments use English
German Wikipedia database dump 19 20 February 2006, except otherwise stated.
3. following use Sans Serif words queries, CAPITALS Wikipedia pages MALL C APS
concepts Wikipedia categories.

182

fiK NOWLEDGE ERIVED F ROM W IKIPEDIA

Categories

Fundamental

Information

Technology

Systems

Information systems

Top 10

Knowledge

Nature

Society

Thought

Science

Organizations

Natural sciences

Interdisciplinary fields

Abstraction

Computer science

Information science

Belief

Mathematics

Philosophy

Applied mathematics

Computational science

Life

Cybernetics

Artificial life

Branches philosophy

Logic

Mathematical logic

Biology

Metaphysics

Neuroscience

Cognitive science

Linguistics

Computational linguistics

Artificial intelligence

Artificial intelligence applications

Cognition

Cognitive architecture

Ontology

Pataphysics

Speech recognition

Natural language processing

Figure 1: Wikipedia category network. top nodes network (C ATEGORIES , F UNDAMEN TAL , OP 10) structurally identical content bearing categories.

category tree. practice, tree designed strict hierarchy, allows multiple categorization schemes coexist simultaneously. category system considered directed acyclic
graph, though encyclopedia editing software prevent users create cycles
graph (which nevertheless avoided according Wikipedia categorization guidelines).
Due flexible nature, refer Wikipedia category tree category network.
February 2006, 94% articles categorized 103,759 categories. illustration
higher regions hierarchy given Figure 1.
strength Wikipedia lies size, could used overcome limited coverage
scalability issues current knowledge bases. large size represents also challenge:
search space Wikipedia category graph large terms depth, branching factor
multiple inheritance relations. Problems arise also finding robust methods retrieving relevant
183

fiP ONZETTO & TRUBE

information. instance, large amount disambiguation pages requires efficient algorithm
disambiguating queries, order able return desired articles.
Since Wikipedia exists since 2001 considered reliable source information even shorter amount time (Giles, 2005), researchers NLP begun recently
work content use resource. Wikipedia used successfully applications question answering (Ahn, Jijkoun, Mishne, Muller, de Rijke, & Schlobach, 2004;
Ahn, Bos, Curran, Kor, Nissim, & Webber, 2005; Lo & Lam, 2006, inter alia), named entity disambiguation (Bunescu & Pasca, 2006), text categorization (Gabrilovich & Markovitch, 2006)
computing document similarity (Gabrilovich & Markovitch, 2007).
2.2 Taxonomy Based Semantic Relatedness Measures
Approaches measuring semantic relatedness use lexical resources transform resource
network graph compute relatedness using paths it. extensive overview lexical
resource-based approaches measuring semantic relatedness presented Budanitsky Hirst
(2006).
2.2.1 ERMINOLOGY
Semantic relatedness indicates much two concepts semantically distant network
taxonomy using relations (i.e. hyponymic/hypernymic, antonymic, meronymic
kind functional relations including is-made-of, is-an-attribute-of, etc.). limited
hyponymy/hyperonymy (i.e. isa) relations, measure quantifies semantic similarity instead
(see Budanitsky & Hirst, 2006, discussion semantic relatedness vs. semantic similarity).
fact, two concepts related necessarily similar (e.g. cars gasoline, see
Resnik, 1999). distinction holds lexical database WordNet,
relations concepts semantically typed, cannot applied computing metrics
Wikipedia. category relations Wikipedia neither typed show uniform
semantics. Wikipedia categorization guidelines state categories mainly used browse
similar articles. Therefore users assign categories rather liberally without make
underlying semantics relations explicit.
following, use generic term semantic relatedness, encompasses
WordNet Wikipedia measures. However, noted applied WordNet,
measures indicate semantic similarity, make use subsumption hierarchy.
2.2.2 PATH BASED EASURES
measures compute relatedness function number edges path two
nodes c1 c2 words w1 w2 mapped to. Rada, Mili, Bicknell, Blettner (1989)
traverse MeSH, term hierarchy indexing articles Medline, compute semantic distance
straightforwardly terms number edges terms hierarchy. Accordingly,
semantic relatedness defined inverse score semantic distance (pl henceforth).
Since edge counting approach relies uniform modeling hierarchy, researchers
started develop measures computing semantic relatedness abstract problem.
Leacock Chodorow (1998) propose normalized path-length measure takes account
depth taxonomy concepts found (lch). Wu Palmer (1994) present
184

fiK NOWLEDGE ERIVED F ROM W IKIPEDIA

instead scaled measure takes account depth nodes together depth
least common subsumer (wup).
2.2.3 NFORMATION C ONTENT BASED EASURES
measure Resnik (1995) computes relatedness concepts function
information content, given probability occurrence corpus (res). Relatedness modeled extent [the concepts] share information, given information
content least common subsumer. Similarly path-length based measures, elaborate measure definitions based information content later developed. includes
measures Jiang Conrath (1997) Lin (1998), hereafter referred respectively
jcn lin, shown correlate better human judgments Resniks
measure.
2.2.4 EXT OVERLAP BASED EASURES
Lesk (1986) defines relatedness two words function text (i.e. gloss) overlap.
extended gloss overlap (lesk) measure Banerjee Pedersen (2003) computes overlap
score extending glosses concepts consideration include glosses related
concepts hierarchy. Given two glosses g1 g2 taken definitions words w1 w2 ,
P
overlap score overlap(g1 , g2 ) computed n m2 n phrasal m-word overlaps (Banerjee
& Pedersen, 2003). overlap score computed using non-linear function, occurrences
words text collection known approximate Zipfian distribution.

3. Computing Semantic Relatedness Wikipedia
Wikipedia based semantic relatedness computation described following Subsections:
1. Retrieve two unambiguous Wikipedia pages pair words, w1 , w2 (e.g. king
rook) refer to, namely pages = {p1 , p2 } (Section 3.1).
2. Connect category network parsing pages extracting two sets categories
C1 = {c1 | c1 category p1 } C2 = {c2 | c2 category p2 } pages assigned
(Section 3.2).
3. Compute set paths pairs categories two pages, namely paths =
{pathc1 ,c2 | c1 C1 , c2 C2 } (Section 3.2).
4. Compute semantic relatedness based two pages extracted (for text overlap based measures) paths found along category network (for path length information content based measures) (Section 3.3).
3.1 Page Retrieval Disambiguation
Given pair words, w1 w2 , page retrieval page p accomplished
1. querying page titled word w,
2. following redirects (e.g. CAR redirecting AUTOMOBILE),
185

fiP ONZETTO & TRUBE

3. resolving ambiguous page queries. due many queries Wikipedia returning
disambiguation page. instance, querying king returns Wikipedia disambiguation page
KING, points pages including MONARCH, KING (CHESS), KING KONG,
KING-FM (a broadcasting station), B.B. KING (the blues guitarist) MARTIN LUTHER
KING.
choose approach disambiguation maximizes relatedness, namely let page
queries disambiguate (see Figure 2). disambiguation page p1 querying word w1
hit, first get hyperlinks page p2 obtained querying word w2 without
disambiguating. bootstrap disambiguation process, since could case
queries ambiguous, e.g. king rook. take word w2 Wikipedia
internal links page p2 lexical association list L2 = {w2 } {l2 | l2 link p2 } used
disambiguation i.e., use term list {rook, rook (chess), rook (bird), rook (rocket),
. . . } disambiguating page KING. Links rook (chess) split extract label
parentheses i.e., rook (chess) splits rook chess. link p1 contains
occurrence disambiguating term l2 L2 (i.e. link KING (CHESS) KING page
containing term chess extracted ROOK page), linked page returned (KING
(CHESS)), else return first article linked disambiguation page (MONARCH).
disambiguation strategy provides less accurate solution following disambiguation
page links. Nevertheless realizes practical solution many pages contain large
number links (e.g. 34 13 KING ROOK pages respectively).
3.2 Category Network Search
Given pages p1 p2 , extract lists categories C1 C2 belong (i.e.
KING (CHESS) ROOK (CHESS) belong C HESS PIECES category). Given category
sets C1 C2 , category pair hc1 , c2 i, c1 C1 , c2 C2 look paths connecting
two categories c1 c2 . perform depth-limited search maximum depth 4
least common subsumer. additionally limit search category level greater
2, i.e. consider levels 0 2 (where level 0 represented top
node C ATEGORIES Figure 1). noticed limiting search improves results.
probably due upper regions Wikipedia category network strongly connected
(see Figure 1). Accordingly, value search depth established system prototyping
finding depth search value maximizes correlation relatedness scores
best performing Wikipedia measure human judgments given datasets Miller
Charles (1991) Rubenstein Goodenough (1965).
3.3 Relatedness Measure Computation
Finally, given set paths found category pairs, compute network based
measures selecting paths satisfying measure definitions, namely shortest path
path-based measures path informative least common subsumer information
content based measures.
order apply Resniks measure Wikipedia couple intrinsic information content measure relying hierarchical structure category network (Seco, Veale, & Hayes,
2004), rather computing information content probabilities occurrence
186

fiK NOWLEDGE ERIVED F ROM W IKIPEDIA

function GET-PAGES(w1 , w2 ) returns pages
1: pages {}
2: pages pages GET-UNAMBIGUOUS-PAGE(w1 , w2 )
3: pages pages GET-UNAMBIGUOUS-PAGE(w2 , w1 )
4: return pages
function GET-UNAMBIGUOUS-PAGE(w1 , w2 ) returns page
1: page getArticleT itled(w1 )
2: page redirection page
3:
page f ollowRedirect(page)
4: end
5: page disambiguation page
6:
l0 first link page
otherP age getArticleT itled(w2 ),
L1 = {l1 | l1 link page}
L2 = {w2 } {l2 | l2 link otherP age}
7:
li L1
8:
lj L2
9:
MATCHES?(li ,lj )
10:
page getArticleT itled(li ), goto (5)
11:
end
12:
end
13:
end
14:
page getArticleT itled(l0 )
15: end
16: return page
function MATCHES?(l1 , l2 ) returns true false
1: T1 SPLIT-BY-PARENTHESIS(l1 )
T2 SPLIT-BY-PARENTHESIS(l2 )
2: ti T1
3:
tj T2
4:
ORTHOGRAPHICALLY-MATCHES(ti , tj )
5:
return true
6:
end
7:
end
8: end
9: return false
Figure 2: Algorithm Wikipedia page retrieval disambiguation

187

fiP ONZETTO & TRUBE

concepts corpus. Seco et al. (2004) show method correlates better human judgments original approach Resnik (1995). intrinsic information content category node n hierarchy given function child nodes, namely
ic(n) = 1

log(hypo(n) + 1)
log(C)

(1)

hypo(n) number hyponyms node n C equals total number conceptual
nodes hierarchy.
Gloss overlap measures computed article pages, since relevant text given
category pages. order adapt Lesk measure Wikipedia (Equation 2), gloss overlap
measures (gloss) computed first paragraph pages. relatedness score given
applying double normalization step overlap score. first normalize sum text
lengths take output value hyperbolic tangent function order minimize
role outliers skewing score distribution.
overlap(t1 , t2 )
lesk wikipedia(t1 , t2 ) = tanh
length(t1 ) + length(t2 )




(2)

4. Experiments
section describes evaluation methodology based experiments word pair lists.
compare performance WordNet Wikipedia based relatedness measures datasets
extensively used literature standard benchmark tests. addition,
evaluate performance relatedness measures derived Wikipedia using different versions online encyclopedia February May 2007.
4.1 Experiments English
evaluate relatedness measures four standard datasets, namely Miller Charles (1991)
list 30 noun pairs (hereafter referred M&C), Rubenstein Goodenoughs (1965) 65 word
pair synonymity list (R&G) M&C subset, WordSimilarity-353 Test Collection
(353-TC) Finkelstein, Gabrilovich, Matias, Rivlin, Solan, Wolfman, Ruppin (2002)4 ,
finally 2,682 pairs nominal subset (KLEB) reader based lexical cohesion
dataset Beigman Klebanov Shamir (2006). 353-TC dataset partitioned
training testing subsets, experiment full list (353 word pairs) test
data subset (153 pairs). Similarly, KLEB dataset contains relatively large amount noun
pairs, split two 50-50% partitions performing machine learning based experiments
learning relatedness words.
4.1.1 E VALUATION
Following literature semantic relatedness, evaluate performance taking Pearson
product-moment correlation coefficient r relatedness measure scores corresponding human judgments. dataset report correlation computed pairs (all).
case word pairs least one words could found lexical resource
4. Available http://www.cs.technion.ac.il/gabr/resources/data/wordsim353/wordsim353.html.

188

fiK NOWLEDGE ERIVED F ROM W IKIPEDIA

Dataset
M&C
R&G
353-TC
full
353-TC
test
KLEB
full
KLEB
test


non-miss

non-miss

non-miss

non-miss

non-miss

non-miss

Google
jaccard
0.33
0.33
0.22
0.22
0.08
0.08
0.10
0.10
0.02
0.02
0.03
0.03

WordNet 2.1
wup
lch
res
0.77
0.82 0.78
0.77
0.82 0.78
0.82
0.86 0.81
0.82
0.86 0.81
0.30
0.34 0.34
0.32
0.36 0.35
0.28
0.35 0.38
0.30
0.38 0.39
0.15
0.15 0.18
0.15
0.15 0.18
0.15
0.14 0.18
0.15
0.14 0.18

pl
0.72
0.72
0.78
0.78
0.28
0.27
0.29
0.28
0.07
0.10
0.06
0.09

lesk
0.37
0.37
0.35
0.35
0.21
0.21
0.21
0.21
0.14
0.14
0.16
0.16

pl
0.47
0.50
0.51
0.53
0.45
0.45
0.50
0.50
0.29
0.30
0.31
0.31

Wikipedia (February 2006)
wup
lch
res
gloss
0.43
0.45
0.23
0.46
0.49
0.49
0.29
0.47
0.50
0.52
0.30
0.46
0.54
0.55
0.34
0.47
0.48
0.49
0.38
0.21
0.48
0.49
0.39
0.21
0.55
0.57
0.46
0.23
0.55
0.57
0.46
0.23
0.28
0.30
0.18
0.13
0.29
0.31
0.19
0.13
0.30
0.32
0.19
0.15
0.31
0.32
0.18
0.15

SVM

0.62

0.38

Table 1: Results correlation human judgments relatedness measures
(i.e. WordNet Wikipedia) relatedness score set 0. addition, report correlation
score obtained disregarding pairs containing missing words (non-miss). baseline,
compute word pair w1 w2 Google correlation coefficient taking Jaccard
similarity coefficient (Salton & McGill, 1983) page hits.
jaccard =

Hits(w1 w2 )
Hits(w1 ) + Hits(w2 ) Hits(w1 w2 )

co-occurrence distributional similarity measure serves baseline. choose Jaccard
similarity coefficient combinatorial measure take account
actual word distributions (Lee, 1999) here, take Google hits.
models also usage similarity coefficients, e.g. van Rijsbergen (1979) shows
Dice Jaccards coefficients monotonic other.
4.1.2 E XPERIMENTAL SETTING
Experiments performed measure datasets. 353-TC KLEB,
experiment integrating different measures performing regression using Support Vector Machine (Vapnik, 1995) estimate functional dependence human relatedness judgments
multiple relatedness scores. learner trained tested using available Google, WordNet
Wikipedia scores. used RBF kernel degree 3. Feature selection performed
find optimal feature space using genetic algorithm (Mierswa, Wurst, Klinkenberg, Scholz,
& Euler, 2006) cross-validation training data. addition, performed model
selection optimal parameter estimation grid search (Hsu, Chang, & Lin, 2006).
4.1.3 ISCUSSION
Table 1 shows correlation coefficients different measures human judgments. Best
performance per dataset highlighted bold5 . WordNet Wikipedia perform better
5. Differences performance statistically significant 95% significance level (p = 0.05). computing statistical significance performed paired t-test dataset pairs corresponding relatedness measures (e.g.
WordNet Wikipedia path measures). Additionally, performed test WordNet
Wikipedia measure Google baseline, SVM combined measure best performing
measure 353-TC KLEB test datasets. statistically non-significant differences performance
found lesk Wikipedia gloss measure M&C dataset.

189

fiP ONZETTO & TRUBE

Google baseline. WordNet performs extremely well M&C R&G datasets,
performance drastically decreases applied 353-TC KLEB datasets. Wikipedia
however perform well M&C R&G datasets outperforms WordNet
353-TC KLEB. case KLEB full dataset, report performance competitive
state-of-the-art WordNet based measure (information content induced taxonomy gloss
information, Beigman Klebanov, 2006). due coverage, 353-TC dataset
2 pairs containing least one word present WordNet, amount
13 Wikipedia. KLEB dataset 114 pairs missing WordNet 150 missing
Wikipedia. problems seem caused rather sense proliferation WordNet. measures
fact computed looking possible sense pairs given words (as word senses
given), taking best scoring (e.g. shortest, informative) path. allows unplausible
paths returned. noted however caused WordNet itself,
provide sense coverage, rather relatedness measures. fact, sense disambiguation
apart one performed measures possible. Using Wikipedia pages
entry points, access page texts hyperlinks, used disambiguate
subsequently limit focus search. example, using fertility disambiguate egg,
correctly return Wikipedia page OVUM, whereas shortest path WordNet makes use
second sense egg, namely oval reproductive body fowl (especially hen) used food.
addition problem sense proliferation, WordNet seems suffer principle
link proliferation problem, e.g., shortest path egg fertility traverses hierarchy
one root nodes (i.e. E NTITY). One could suggest limit search WordNet
Wikipedia, though noted supposed taken care measures
themselves, e.g. scaling depth path nodes.
Besides, Wikipedia performs better WordNet present experimental setting
353-TC KLEB datasets model semantic relatedness, rather similarity. WordNet measures used (all except lesk) instead designed quantify similarity, thus yielding
poor performance. supported 353-TC annotation guidelines, define similarity belonging domain representing features concept, well
Beigman Klebanov (2006) reporting competitive results (Pearson correlation coefficient r =
0.47) WordNet-based relatedness measure. 353-TC contains also highly rated word pairs
cell phone energy crisis closely related, since tend occur frequently together, similar, share properties all. Finally, additional support
given fact competitive results given Wikipedia KLEB dataset,
specifically designed relatedness mind (Beigman Klebanov & Shamir, 2006).
Finkelstein et al. (2002) suggest integrating word-vector based relatedness measure
WordNet based one useful, accounts word co-occurrences helps recovering
cases words cannot found available resources, e.g. dictionary ontology.
Accordingly, 353-TC KLEB test sets report best performance integrating
available measures performing feature selection. 353-TC data, score r =
0.62 outperforms combined WordNetword-vector measure Finkelstein et al. (2002) (r =
0.55), well score r = 0.38 KLEB test data outperforming score r =
0.32 obtained using best performing (Wikipedia-based) relatedness measure (lch). Instead
integrating word-vector based relatedness measure WordNet based one, results indicate
competitive performance achieved also using different knowledge base
Wikipedia.
190

fiK NOWLEDGE ERIVED F ROM W IKIPEDIA

analysis above, one could conclude Wikipedia yields better relatedness scores
WordNet applied datasets designed evaluate relatedness words. practice,
believe extremely difficult perform fair comparison two knowledge sources
limiting application small datasets. addition, always clear linguistic
notion (i.e. similarity vs. relatedness) underlies datasets (cf. 353-TC). reason
perform additional experiments making use datasets synonymity tests
80 TOEFL (Landauer & Dumais, 1997), 50 ESL (Turney, 2001) 300 Readers Digest Word
Power Game (Jarmasz & Szpakowicz, 2003) questions. datasets pose also problem since
contain verbs, unlikely found encyclopedic resource Wikipedia.
reasons evaluate Section 5 approach applying real-world NLP
task, namely coreference resolution, relatedness hundreds thousands word
pairs computed, thus providing reliable evaluation.
4.2 Evaluation Wikipedia Throughout Time
One appealing features Wikipedia provides large coverage knowledge base, also shows quasi-exponential growth respect number articles
(Table 2)6 . evaluated whether growth rate affects methodology computing
relatedness words. experiments word pairs datasets, using Wikipedia English
database dump 19 February 2006, repeated using dumps 25 September 2006
27 May 2007. performance Wikipedia-based relatedness measures M&C,
R&G, 353-TC KLEB datasets presented Tables 3 4. highlighted Figure 3,
notable differences performance different Wikipedia versions M&C
R&G dataset. Nevertheless simple one-tailed paired sample t-test 0.05 level reveals
none variations different Wikipedia versions statistically significant. Qualitative
analysis reveals improvements due queries getting correctly disambiguated i.e.
lad correctly disambiguates BOY September 2006 May 2007 Wikipedia, rather
SECT, February version LAD disambiguation page contains SECT first
link used disambiguation occurring Lad sub-sect Jainist Digambara sect.
differences accidental easily spotted significance test.
WordNet 2.1
#word-sense pairs/#articles
#synsets/#categories

207,016
117,597

English Wikipedia
Feb. 06
Sep. 06
May 07
971,518 1,403,207 1,803,843
103,759
165,744
244,376

Table 2: Statistics WordNet Wikipedia

results show method robust (thus replicable) disregarding Wikipedia version. However, observe improvement despite quasi-exponential growth
Wikipedia, articles added Wikipedia provide crucial information respect experiments.
6. See instance http://en.wikipedia.org/wiki/Wikipedia:Modelling Wikipedias growth.

191

fiP ONZETTO & TRUBE

Dataset
M&C
R&G
353-TC
full
353-TC
test
KLEB
full
KLEB
test


non-miss

non-miss

non-miss

non-miss

non-miss

non-miss

pl
0.59
0.63
0.57
0.60
0.47
0.48
0.52
0.52
0.26
0.28
0.27
0.29

wup
0.54
0.61
0.59
0.65
0.49
0.50
0.57
0.57
0.26
0.28
0.26
0.29

Wikipedia
lch
res
0.58 0.31
0.64 0.41
0.60 0.30
0.66 0.37
0.51 0.35
0.53 0.36
0.60 0.49
0.61 0.49
0.27 0.13
0.29 0.15
0.28 0.14
0.31 0.17

gloss
0.58
0.60
0.52
0.54
0.25
0.26
0.26
0.26
0.11
0.11
0.12
0.13

SVM

0.62

0.37

Table 3: Correlation Wikipedia scores (September 2006) human judgments

Dataset
M&C
R&G
353-TC
full
353-TC
test
KLEB
full
KLEB
test


non-miss

non-miss

non-miss

non-miss

non-miss

non-miss

pl
0.57
0.57
0.58
0.58
0.48
0.48
0.54
0.54
0.31
0.32
0.28
0.29

wup
0.54
0.54
0.58
0.58
0.52
0.52
0.63
0.63
0.31
0.33
0.29
0.30

Wikipedia
lch
res
0.57 0.31
0.57 0.31
0.61 0.38
0.61 0.38
0.53 0.41
0.54 0.41
0.64 0.60
0.64 0.60
0.33 0.19
0.34 0.20
0.30 0.18
0.31 0.18

gloss
0.55
0.55
0.53
0.53
0.20
0.20
0.22
0.22
0.10
0.10
0.11
0.11

SVM

0.66

0.37

Table 4: Correlation Wikipedia scores (May 2007) human judgments

5. Case Study: Coreference Resolution
extend machine learning based coreference resolver features capturing different semantic knowledge sources. features represent relatedness scores mined WordNet
Wikipedia. Coreference resolution provides application evaluate performance relatedness measures previously evaluated using datasets limited size. extrinsic evaluation provides better insight usefulness Wikipedia relatedness measures NLP applications intrinsic evaluation described Section 4.
5.1 Machine Learning Based Coreference Resolution Semantic Knowledge
last years seen boost work devoted development machine learning based
coreference resolution systems (Soon, Ng, & Lim, 2001; Ng & Cardie, 2002; Yang, Zhou, Su,
& Tan, 2003; Luo, Ittycheriah, Jing, Kambhatla, & Roukos, 2004, inter alia). machine
learning proved yield performance rates fully competitive rule based systems, current
coreference resolution systems mostly relying rather shallow features, distance
coreferent expressions, string matching, linguistic form. shallow features
sufficient correctly identifying many coreferential relations expressions
192

fiK NOWLEDGE ERIVED F ROM W IKIPEDIA

Correlation coefficient (Pearson r)

0.7

0.8

M&C
R&G
353-TC full
353-TC test
353-TC SVM
KLEB full
KLEB test
KLEB SVM

0.7

Correlation coefficient (Pearson r)

0.8

0.6

0.5

0.4

0.3

0.2
Jan 06

M&C
R&G
353-TC full
353-TC test
353-TC SVM
KLEB full
KLEB test
KLEB SVM

0.6

0.5

0.4

0.3

Mar 06

May 06

Jul 06

Sep 06

Nov 06

Jan 07

Mar 07

May 07

Jul 07

0.2
Jan 06

Mar 06

May 06

Jul 06

Wikipedia database dump

Sep 06

Nov 06

Jan 07

Mar 07

May 07

Jul 07

Wikipedia database dump

(a) pairs

(b) Non-missing pairs

Figure 3: Performance variation Wikipedia-based relatedness measures throughout time

text. example, consider fragment Automatic Content Extraction (ACE) 2003
data.
frequent visitors say given sheer weight countrys totalitarian ideology
generations mass indoctrination, changing countrys course something akin
turning huge ship sea. Opening North Korea up, even modestly, exposing people
idea Westerners South Koreans devils, alone represents extraordinary
change. [...] people begin get clearer idea deprivation suffered,
especially relative neighbors. society focused
stability, [...].

order correctly resolve coreferent expressions highlighted bold (which annotated
coreferent ACE data), lexical semantic encyclopedic knowledge required, i.e.,
North Korea country, countries consist people societies. resolution
requires knowledge base (e.g. generated Wikipedia) look-up reasoning content
relatedness holding different expressions (e.g. path measure along links
WordNet Wikipedia semantic networks). following explore scenario including
knowledge mined WordNet Wikipedia coreference resolution. start machine
learning based baseline system taken Ponzetto Strube (2006b), includes set
shallow linguistic features Soon et al. (2001) well semantic parsing information terms
semantic role labeling (Gildea & Jurafsky, 2002; Carreras & Marquez, 2005, SRL henceforth),
analyze performance variations given including previously discussed relatedness
measures feature set. overview system present remainder section
given Figure 4.
5.2 Coreference Resolution Using Semantic Knowledge Sources
subsection presents coreference resolution system uses semantic relatedness features
induced WordNet Wikipedia capture information knowledge sources.
193

fiPreprocessing
pipeline

Raw
text

Baseline feature extractor
(Ponzetto Strube, 2006b)

PoS tagger
Semantic feature
Chunker

NER

extractor

MaxEnt
classifier

Text annotated
coreference chains

P ONZETTO & TRUBE

WordNet
Wikipedia

SEMANTICS
Figure 4: Overview coreference resolution system extrinsic evaluation WordNet
Wikipedia relatedness measures. start baseline system Ponzetto
Strube (2006b) includes features Soon et al. (2001) semantic role
information. include different times features WordNet Wikipedia
register performance variations.

5.2.1 C ORPORA U SED
establish competitive coreference resolver, system initially prototyped using MUC6 MUC-7 data sets (Chinchor & Sundheim, 2003; Chinchor, 2001), using standard partitioning 30 texts training 20-30 texts testing. Then, developed tested system
ACE 2003 Training Data corpus (Mitchell, Strassel, Przybocki, Davis, Doddington, Grishman, Meyers, Brunstain, Ferro, & Sundheim, 2003)7 . Newswire (NWIRE) Broadcast News (BNEWS) sections split 60-20-20% document-based partitions training,
development, testing, later per-partition merged (MERGED) system evaluation.
distribution coreference chains referring expressions given Table 5.
5.2.2 L EARNING LGORITHM
learning coreference decisions, used Maximum Entropy (Berger, Della Pietra, & Della Pietra, 1996) model, implemented using MALLET library8 . Coreference resolution viewed
binary classification task: given pair REs, classifier decide whether coreferent not. MaxEnt model produces probability category (coreferent not)
candidate pair, conditioned context x candidate occurs. conditional
probability calculated by:
7. used training data corpus only, availability test data restricted ACE participants. Therefore,
results report cannot compared directly using official test data.
8. http://mallet.cs.umass.edu

194

fiK NOWLEDGE ERIVED F ROM W IKIPEDIA

TRAIN.
DEVEL
TEST
TOTAL
TOTAL (%)

TRAIN.
DEVEL
TEST
TOTAL
TOTAL (%)

#coref chains
587
201
228
1,016

BNEWS (147 docs 33,479 tokens)
#pronouns
#common nouns #proper names
876 (36.1%)
572 (23.6%)
980 (40.3%)
315 (33.4%)
163 (17.3%)
465 (49.3%)
291 (30.7%)
238 (25.1%)
420 (44.2%)
1,482
973
1,865
34.3%
22.5%
43.2%

#coref chains
904
399
354
1,657

NWIRE (105 docs 57,205 tokens)
#pronouns
#common nouns
1037 (24.3%)
1210 (28.3%)
358 (20.3%)
485 (27.5%)
329 (21.6%)
484 (31.7%)
1,724
2,179
22.8%
28.8%

#proper names
2023 (47.4%)
923 (52.2%)
712 ( 46.7%)
3,658
48.4%

Table 5: Partitions ACE 2003 training data corpus

"

#

1 X
fi (x, y)
p(y|x) =
Zx

fi (x, y) value feature outcome context x, weight associated
model. Zx normalization constant. features used model binaryvalued feature functions (or indicator functions), e.g.

fWIKI PL (WIKI PL = 0.1, COREF) =


1 candidate pair coreferent





semantic relatedness lexical


heads 0.1 using pl measure








0 otherwise

use L-BFGS algorithm (Malouf, 2002) estimate parameters Maximum Entropy
model. prevent model overfitting, employ tunable Gaussian prior smoothing
method. Training performed using multi-conditional learning (McCallum, Pal, Druck, & Wang,
2006), state-of-the-art hybrid method combining generative discriminative methods model
parameter estimation.
apply set preprocessing components including POS tagger (Gimenez & Marquez,
2004), NP chunker (Kudoh & Matsumoto, 2000) Alias-I LingPipe Named Entity Recognizer9 text order identify noun phrases, taken referring expressions (REs) used instance generation. Therefore, use automatically extracted noun
phrases, rather assuming perfect NP chunking. contrast related works
coreference resolution (e.g., Luo et al., 2004; Kehler, Appelt, Taylor, & Simma, 2004).
Instances created following Soon et al. (2001). create positive training instance
pair adjacent coreferent REs. Negative instances obtained pairing anaphoric
9. http://alias-i.com/lingpipe

195

fiP ONZETTO & TRUBE

REs occurring anaphor antecedent. testing text
processed left right: paired preceding right left, pair
labeled coreferent output, beginning document reached. classifier imposes
partitioning available REs clustering set expressions labeled coreferent
coreference chain.
5.2.3 BASELINE YSTEM F EATURES
Following Ng Cardie (2002), core baseline system reimplements Soon et al. (2001)
system. system uses twelve features. Given potential antecedent REi potential anaphor
REj features computed follows10 .
(a) Lexical features
1. STRING MATCH REi REj spelling, else F.
2. ALIAS one alias other; else F.
(b) Grammatical features
3. PRONOUN REi pronoun; else F.
4. J PRONOUN REj pronoun; else F.
5. J DEF REj starts the; else F.
6. J DEM REj starts this, that, these, those; else F.
7. NUMBER REi REj agree number; else F.
8. GENDER U either REi REj undefined gender. Else defined
agree T; else F.
9. PROPER NAME REi REj proper names; else F.
10. APPOSITIVE REj apposition REi ; else F.
(c) Semantic features
11. WN CLASS U either REi REj undefined WordNet semantic class. Else
defined one T; else F.
(d) Distance features
12. DISTANCE many sentences REi REj apart.
addition 12 features Soon et al. (2001), employ SRL features taken Ponzetto Strube (2006b). Semantic roles taken output ASSERT parser (Pradhan,
Ward, Hacioglu, Martin, & Jurafsky, 2004), SVM based semantic role tagger uses full
syntactic analysis automatically identify verb predicates sentence together semantic arguments, output PropBank arguments (Palmer, Gildea, & Kingsbury, 2005).
10. Possible values U(nknown), T(rue) F(alse). Note contrast Ng Cardie (2002) interpret ALIAS
lexical feature, solely relies string comparison acronym string matching.

196

fiK NOWLEDGE ERIVED F ROM W IKIPEDIA

often case semantic arguments output parser align previously identified noun phrases. case, pass semantic role label two
phrases share head. Labels form ARG1 pred1 . . . ARGn predn n semantic
roles filled constituent, semantic argument label always defined respect
predicate. Given level semantic information available level, introduce two
new features.
(e) SRL features
13. SEMROLE semantic role argument-predicate pairs REi .
14. J SEMROLE semantic role argument-predicate pairs REj .
ACE 2003 data, 11,406 32,502 automatically extracted noun phrases tagged
2,801 different argument-predicate pairs. baseline feature set obtained starting
features Soon et al. (2001), plus SRL features, removing selected using
backward feature selection (see Subsection 5.3.2).
5.2.4 W ORD N ET F EATURES
WN CLASS feature baseline system noisy, lack coverage,
sense proliferation ambiguity11 . accordingly enrich semantic information available
classifier using semantic similarity measures based WordNet taxonomy (Pedersen,
Patwardhan, & Michelizzi, 2004). measures use include path length based measures (Rada
et al., 1989; Wu & Palmer, 1994; Leacock & Chodorow, 1998), well ones based information
content (Resnik, 1995; Jiang & Conrath, 1997; Lin, 1998).
case, measures obtained computing similarity scores head
lemmata (for common nouns, e.g. house) full NPs (for named entities, e.g. George W. Bush)
potential antecedent-anaphor pair. order deal sense disambiguation problem,
factorize possible sense pairs: given candidate pair, take cross product
antecedent anaphor sense form pairs synsets. measure WN SIMILARITY,
compute similarity score synset pairs, create following features.
15. WN SIMILARITY BEST highest similarity score hSENSEREi ,n , SENSEREj ,m
synset pairs.
16. WN SIMILARITY AVG average similarity score hSENSEREi ,n , SENSEREj ,m
synset pairs.
Pairs containing REs cannot mapped WordNet synsets assumed maximally
dissimilar, i.e. similarity score set 0.
5.2.5 W IKIPEDIA F EATURES
include features derived Wikipedia. Pages paths retrieved following procedure
described Section 3. case WordNet, query head lemmata common nouns
full NPs named entities. Given candidate coreference pair REi/j disambiguated
11. Following Soon et al. (2001) mapped first WordNet sense head noun.

197

fiP ONZETTO & TRUBE

Wikipedia pages pREi/j point to, obtained querying pages titled tREi/j , extract
following features:
17. I/J GLOSS CONTAINS U Wikipedia page titled tREi/j available. Else first
paragraph text pREi/j contains tREj/i ; else F.
18. I/J RELATED CONTAINS U Wikipedia page titled tREi/j available. Else
least one Wikipedia hyperlink pREi/j contains tREj/i ; else F.
19. I/J CATEGORIES CONTAINS U Wikipedia page titled tREi/j available. Else
list categories pREi/j belongs contains tREj/i ; else F.
20. GLOSS OVERLAP overlap score first paragraph text pREi pREj
computed using Equation 2.
Additionally, use Wikipedia category graph. use relatedness measures described
Subsections 2.2.2 2.2.3. Given pREi/j lists categories CREi/j belong to,
factorize possible category pairs. is, take cross product antecedent
anaphor category form pairs Wikipedia synsets. measure WIKI RELATEDNESS,
compute relatedness score category pairs, create following features.
21. WIKI RELATEDNESS BEST highest relatedness score hCREi ,n , CREj ,m category pairs.
22. WIKI RELATEDNESS AVG average relatedness score hCREi ,n , CREj ,m category pairs.
5.3 Experiments
5.3.1 P ERFORMANCE ETRICS
report following tables MUC score (Vilain, Burger, Aberdeen, Connolly, & Hirschman,
1995). Scores Table 6 computed noun phrases appearing either key system
response, whereas Tables 7 8 refer scoring phrases appear key
response. therefore discard responses present key, referring
expressions annotated ACE 2003 data belong categories Person (i.e. humans), Organization (e.g. corporations, agencies), Facility (i.e. buildings), Location (e.g. geographical areas
landmasses) Geo-political entities (i.e. nations, regions, government people, cf.
North Korea example above)12 . makes impossible perform full coreference resolution
including, e.g. identification referential expressions, implies results establish
upper limit improvements given semantic features.
also report accuracy score three types ACE mentions, namely pronouns, common nouns proper names. Accuracy percentage REs given mention type correctly
resolved divided total number REs type direct antecedent given
key. said correctly resolved direct antecedent identify mentions
belong coreference class key.
12. Cf. ACE 2003 Entity Detection Tracking (EDT) Annotation Guidelines available http://projects.
ldc.upenn.edu/ace/docs/EDT-Guidelines-V2-5.pdf: identify mentions animals
inanimate objects time.

198

fiK NOWLEDGE ERIVED F ROM W IKIPEDIA

original
Soon et al.
duplicated
baseline

R
58.6
64.9

MUC-6
P
F1
67.3 62.3
65.6

65.3

R
56.1

MUC-7
P
F1
65.5 60.4

55.1

68.5

61.1

Table 6: Results MUC
5.3.2 F EATURE ELECTION
determining relevant feature sets follow iterative procedure similar wrapper
approach feature selection (Kohavi & John, 1997) using development data. feature
selection algorithm performs hill-climbing search along feature space. case baseline system perform backward feature selection, since interested obtaining minimal
feature set provides competitive baseline13 . start model based
available features (Ponzetto & Strube, 2006b). train models obtained removing one
feature time. choose worst performing feature, namely one whose removal gives
largest improvement based MUC score F-measure development data, remove
model. train classifiers removing remaining features separately
enhanced model. process iteratively run long significant improvement observed.
evaluating WordNet Wikipedia features, perform instead forward greedy feature
selection: start minimal set previously kept baseline features iteratively add
features WordNet Wikipedia give best MUC score F-measure improvement
development data selection step. interested evaluating
additional contribution information, avoid external factors improvements due
removal baseline features. summary features selected backward
forward feature selections given Table 9.
5.3.3 R ESULTS
Table 6 compares results duplicated Soon et al. (2001) baseline original
system MUC data. assume slight improvements system due
use current preprocessing components another classifier. Tables 7 8 show comparison
performance baseline system (Ponzetto & Strube, 2006b) ones incremented semantic features mined WordNet Wikipedia ACE data. Statistically
significant performance improvements highlighted bold14 .
13. assumption adding SRL features core baseline features Soon et al. (2001) could
yield best performance. practice, analysis feature selection development data highlights
Soon et al.s (2001) features J DEM, PROPER NAME WN CLASS (BNEWS), J DEM (NWIRE)
DISTANCE (MERGED) indeed removed baseline feature set SRL information included. None
best performing features Soon et al. (2001) (STRING MATCH, ALIAS APPOSITIVE) removed,
thus supporting feature relevance analysis (pp. 534535).
14. take performance variations different experimental runs statistically significant case changes
MUC F-measure statistically significant 0.05 level higher. follow Soon et al. (2001)
performing simple one-tailed, paired sample t-test baseline systems MUC score F-measure
systems F-measure scores test documents.

199

fiP ONZETTO & TRUBE

baseline
+WordNet
+Wikipedia

R
50.5
59.1
58.3

P
82.0
82.4
81.9

BNEWS
F1
Ap
62.5 44.2
68.8 43.1
68.1 41.2

Acn
17.4
40.9
38.9

Apn
58.0
64.6
62.3

R
56.3
62.4
60.7

P
86.7
81.4
81.8

NWIRE
F1
Ap
68.3 43.8
70.7 45.4
69.7 44.1

Acn
35.0
43.0
40.1

Apn
71.6
68.7
71.6

Table 7: Results ACE 2003 data (BNEWS NWIRE sections)

baseline
+WordNet
+Wikipedia

R
54.5
60.6
59.4

P
85.4
79.4
82.2

F1
66.5
68.7
68.9

Ap
40.5
42.4
38.9

Acn
30.1
43.2
41.4

Apn
73.0
66.0
74.5

Table 8: Results ACE (merged BNEWS/NWIRE)
5.3.4 ISCUSSION
tables show semantic features improve system recall, rather acting semantic filter
improving precision. Semantics therefore seems trigger response cases shallow
features seem suffice. one-tailed, paired sample t-test reveals BNEWS
MERGED sections difference performance WordNet Wikipedia statistically significant (p < 0.05), thus proving Wikipedia indeed competitive WordNet
coreference resolution scenario.
WordNet Wikipedia features tend consistently increase performance common nouns
dataset partitions. WordNet features able improve 23.5%, 8% 13.1% accuracy rate common nouns BNEWS, NWIRE MERGED datasets (+35, +28 +65
correctly resolved common nouns 149 349 498 respectively), whereas employing
Wikipedia yields slightly smaller improvements (+21.5%, +5.1% +11.3% accuracy increase
datasets). accuracy common nouns shows features derived Wikipedia
competitive ones WordNet. performance gap three datasets relatively
small, indicates usefulness using encyclopedic knowledge base replacement
lexical taxonomy.
semantic relatedness clearly helps common nouns, always improve performance proper names, features string matching alias suffice, cf. performance degradation induced WordNet NWIRE MERGED datasets. suggests
semantic information use tends play role mostly common noun resolution,
surface features cannot account complex preferences semantic knowledge required. Nevertheless, Wikipedia exhibits general better performance resolution proper names
WordNet, yields results always least good baseline. surprising, Wikipedia contains larger amount information named entities WordNet.
particular, qualitative analysis development data shows Wikipedia useful instance
identifying cases REs coreferent geo-political discourse entity, e.g. Yemeni
Yemen American United States, thanks feature redirection, i.e. YEMENI
redirects YEMEN. linguistic point view far clear whether cases
represent genuine cases coreference, redirection helps cover meronymy.
200

fiK NOWLEDGE ERIVED F ROM W IKIPEDIA

backward
feature
selection

forward
feature
selection

starting
features
removed
WordNet
features
added
Wikipedia
features
added

BNEWS
WN CLASS
PROPER NAME
J DEM
jcn average
jcn best
pl best
wup average
wup average
pl best
pl average
gloss

NWIRE

MERGED

J DEM

DISTANCE

jcn best
lin average
pl best

lch best
pl best
pl average

wup average
lch best

pl best
pl average

Table 9: Feature selection
Feature selection improves results15 . due fact full feature set extremely redundant: order explore usefulness knowledge sources included overlapping features (i.e. using best average similarity/relatedness measures time),
well features capturing phenomenon different points view (i.e. using multiple
measures time). order yield desired performance improvements, turns
essential filter irrelevant features. instance, case Wikipedia none
I/J GLOSS, RELATED CATEGORIES CONTAINS features survives feature selection process (see Table 9). hand, cases WordNet Wikipedia least one
best one average measure always included among selected features. suggests
including information available senses (in terms average relatedness measures) provides sensible information handle ambiguity. Finally, multiple measures included
selected feature sets, e.g. selected features WordNet BNEWS data include
measure Wu Palmer (1994) one Jiang Conrath (1997), indicating
rather best overall measure, competitive results obtained integrating
different ones.

6. Experiments German
Except Gurevych (2005) ported semantic relatedness measures German using GermaNet
(Lemnitzer & Kunze, 2002), topic semantic relatedness explored almost exclusively
English language using WordNet. Research semantic relatedness languages
English hindered differences structure organization respective
wordnets large variation coverage. instance, Gurevych Niederlich (2005a)
implement API specifically designed GermaNet access. Furthermore, GermaNet much
smaller WordNet even cover word pairs relatively small dataset provided
Rubenstein Goodenough (1965) Gurevych Niederlich (2005b) translated
German. contrast, structure organization Wikipedia across languages,
semantic relatedness measures developed English applied languages
15. experienced system prototyping simply including full feature set without performing feature
selection gave worst significant performance variations all.

201

fiP ONZETTO & TRUBE

GermaNet 4.0
#word-sense pairs/#articles
#synsets/#categories

60,646
41,777

German Wikipedia
Feb. 06
Jun. 06 Sep. 06
387,586 410,586 471,065
25,035
28,656
33,130

Table 10: Statistics GermaNet Wikipedia

without changing methods accessing them. coverage German Wikipedia also
considerably large shown Table 10.
knowledge exist datasets evaluating semantic relatedness measures languages English. Gurevych translated dataset Rubenstein Goodenough
(1965) German supplied judgments native speakers German. Gurevych (2005)
evaluated several semantic relatedness measures R&G dataset using GermaNet knowledge
source. GermaNet cover words 65 word pairs report results
57 word pairs best results obtained res followed lin. Table 11 adopt results
reported Gurevych supply numbers computed 65 word pairs including
ones covered GermaNet. case results given Table 1, word pairs
least one words could found GermaNet assigned relatedness score
016 .
numbers obtain experiments using Wikipedia compare well numbers
reported. contrast results English R&G dataset, Wikipedia performs good
GermaNet considering pairs viz., statistically significant difference using one-tailed
paired sample t-test (p < 0.05) respective best performing measures, GermaNet lin
Wikipedia wup shows performance slightly considering available pairs
only. German R&G dataset one Wikipedia shows best overall performance,
one larger coverage corresponding wordnet (4 missing
pairs versus 8).
previously pointed analysis performance 353-TC English dataset,
Wikipedia able yield competitive performance datasets specifically designed capture
semantic relatedness, rather stricter notion similarity. seems supported
present scenario well, data Gurevych Niederlich (2005b) rated explicitly
semantic relatedness, using definition Budanitsky Hirst (2006) summarized
Section 2.2.1.

7. Implementation Details
Wikipedia freely available download, accessed using robust Open Source applications, e.g. MediaWiki software17 , integrated within Linux, Apache, MySQL PHP (LAMP)
software bundle. briefly present following main components Application Programming Interface (API) developed part present work18 . architecture
WikiRelate! API (Ponzetto & Strube, 2007a) consists following modules:
16. complete list German word pairs corresponding human judgments automatically computed
measures obtained Gurevych Niederlich (2005b).
17. http://www.mediawiki.org
18. WikiRelate! software downloaded http://www.eml-research.de/nlp.

202

fiK NOWLEDGE ERIVED F ROM W IKIPEDIA

Dataset

non-miss

R&G

Google
jaccard
0.26
0.26

GermaNet 4.0
lin
res lesk
0.66 0.64 0.49
0.73 0.76 0.53

Wikipedia (February 2006)
pl
wup lch
res gloss
0.58 0.65 0.64 0.62 0.33
0.62 0.70 0.69 0.67 0.34
Wikipedia (June 2006)
0.65 0.64 0.58 0.33
0.69 0.69 0.62 0.35


non-miss

0.58
0.61


non-miss

Wikipedia (September 2006)
0.59 0.65 0.64 0.50 0.38
0.63 0.70 0.69 0.55 0.40

Table 11: Results German R&G Dataset

1. RDBMS: lowest level, encyclopedia content stored relational database
management system (e.g. MySQL).
2. MediaWiki: suite PHP routines interacting RDBMS.
3. WWW-Wikipedia Perl library19 : responsible querying MediaWiki, parsing structuring returned encyclopedia pages.
4. XML-RPC server: intermediate communication layer Java Perl routines.
5. Java wrapper library: provides simple facade create access encyclopedia page
objects compute relatedness scores.
information flow API summarized sequence diagram Figure 5. higher
input/output layer user interacts provided Java API Wikipedia
queried. API provides factory classes querying Wikipedia, order retrieve encyclopedia entries well relatedness scores word pairs. practice, Java library works
wrapper order provide simple user access terms facade. library responsible
issuing HTTP requests XML-RPC daemon provides layer calling Perl routines
Java API. Perl routines take care bulk querying encyclopedia entries MediaWiki software (which turn queries database) efficiently parsing text responses
structured objects.

8. Related Work
section relate work existing body literature computing semantic relatedness application various NLP tasks.
19. http://search.cpan.org/dist/WWW-Wikipedia/

203

fi204
4. Relatedness score computation

3. Wikipedia pages lookup

loop: foreach word

2. Create category tree Java data structure

1. Retrieve Wikipedia category tree

: XML-RPC daemon

Perl object

Wiki markup text

: HTTP request

: WWW-Wikipedia

: Perl module call

: Category extraction path search

XML-RPC response

: HTTP request

: Create graph category tree query

Result set

: SQL query (categories links)

: Java wrapper library

Result set

: article lookup

: Database

: SQL query (page)

: MediaWiki

PHP Article object

: PHP module call

: Webserver

P ONZETTO & TRUBE

Figure 5: WikiRelate! API processing sequence diagram. Wikipedia pages relatedness measures accessed Java API facade. wrapper communicates Perl
library designed Wikipedia access parsing XML-RPC server. WWWWikipedia turn accesses database encyclopedia stored means
appropriate queries MediaWiki.

fiK NOWLEDGE ERIVED F ROM W IKIPEDIA

8.1 Computing Semantic Relatedness
Research area computing semantic relatedness similarity generally divided
two categories firstly measures distributional similarity using largely unstructured information
text secondly approaches using structured lexical databases WordNet.
Measures distributional similarity (Landauer & Dumais, 1997; Lee, 1999; Dagan, 2000; Turney, 2001; Weeds & Weir, 2005, inter alia) based distributional hypothesis, i.e. hypothesis similar words appear similar contexts hence similar meaning. reasons
discussed detail Budanitsky Hirst (2006, pp.4144), measures distributional similarity
measures semantic relatedness distinct, (1) measures semantic relatedness
cover relations concepts measures distributional similarity capture relations words; (2) semantic relatedness symmetric relation distributional similarity
potentially asymmetric relationship; (3) measures semantic relatedness depend predefined
knowledge source created humans may presumed true, unbiased complete
(Budanitsky & Hirst, 2006, p.43); measures distributional similarity depend entirely corpora
causing problems imbalance data sparseness; problem may overcome using
representative, large corpora; however, computing distributional similarity scale well
(Gorman & Curran, 2006). Budanitsky Hirst (2006) conclude measures distributional
similarity cannot replace measures semantic relatedness similarity.
Approaches using structured lexical databases traced back work Rada et al. (1989)
measured semantic similarity MeSH, term hierarchy indexing articles Medline.
compute semantic similarity straightforwardly terms numbers edges terms
hierarchy. Research area proceeded two directions. Firstly, different knowledge sources
proposed. Early on, WordNet used provide broad coverage lexical database (Resnik,
1993; Wu & Palmer, 1994; Resnik, 1995). Later Jarmasz Szpakowicz (2003) explored use
Rogets Thesaurus computing semantic similarity. Secondly, major advances achieved
developing sophisticated measures semantic similarity relatedness.
article propose new knowledge source computing semantic relatedness, i.e.
Wikipedia associated categorization network. believe many NLP applications
benefit using Wikipedia evaluate hypothesis including Wikipedia based semantic
relatedness measures features state-of-the-art coreference resolution system.
8.2 Using Semantic Relatedness Coreference NLP Applications
Vieira Poesio (2000), Harabagiu et al. (2001), Markert Nissim (2005) explore use
WordNet different coreference resolution subtasks, resolving bridging references, otherand definite NP anaphora, MUC-style coreference resolution. present systems
infer coreference relations set potential antecedents means WordNet search.
approach WordNet cast search results terms semantic similarity measures.
output used features learner. measures specifically developed
coreference resolution simply taken off-the-shelf applied task without specific
tuning e.g. contrast Harabagiu et al. (2001), weight WordNet relations differently
order compute confidence measure path.
Semantic relatedness measures proven useful many applications Natural
Language Processing word sense disambiguation (Kohomban & Lee, 2005; Patwardhan,
Banerjee, & Pedersen, 2005), information retrieval (Finkelstein et al., 2002), information extraction
205

fiP ONZETTO & TRUBE

pattern induction (Stevenson & Greenwood, 2005), interpretation noun compounds (Kim & Baldwin, 2005), paraphrase detection (Mihalcea, Corley, & Strapparava, 2006) spelling correction
(Budanitsky & Hirst, 2006).

9. Conclusions
article investigated use Wikipedia computing semantic relatedness application real-world NLP task, coreference resolution. assumed Wikipedia category
graph represent semantic network modeling relations concepts, computed
relatedness it. Even categorization feature introduced Wikipedia
three years ago, results indicate semantic relatedness computed using Wikipedia category network consistently correlates better human judgments simple baseline based
Google counts. also competitive WordNet datasets specifically modeling semantic
relatedness human judgments. available dataset small seem assembled
rather arbitrarily perform extrinsic evaluation NLP application, i.e. coreference resolution system, register datasets statistically significant differences
improvements given features induced WordNet ones Wikipedia.
Wikipedia provides large amount information encyclopedic entries leaves
category network, e.g. named entities. encyclopedia gets continuously updated derived
knowledge used analyze current information. text category network
provide semi-structured information mined precision unstructured data
gathered web. Unfortunately, Wikipedia categorization still suffers limitations, i.e., cannot considered fully-fledged ontology, relations categories
semantically-typed. near future concentrate making semantic relations
concepts explicit Wikipedia category network (Ponzetto & Strube, 2007b). availability explicit semantic relations allow inducing semantic similarity rather semantic
relatedness measures, may suitable coreference resolution. interesting results indicate collaboratively created folksonomy actually
used NLP applications benefit hand-crafted taxonomies ontologies.
Acknowledgments. work funded Klaus Tschira Foundation, Heidelberg,
Germany. first author supported KTF grant (09.003.2004). thank three
anonymous JAIR reviewers extensive reviews colleague Vivi Nastase useful
feedback.

References
Ahn, D., Jijkoun, V., Mishne, G., Muller, K., de Rijke, M., & Schlobach, S. (2004). Using Wikipedia
TREC QA track. Proceedings Thirteenth Text REtrieval Conference, Gaithersburg, Md., 1619 November 2004.
Ahn, K., Bos, J., Curran, J. R., Kor, D., Nissim, M., & Webber, B. (2005). Question answering
QED TREC-2005. Proceedings Fourteenth Text REtrieval Conference, Gaithersburg, Md., 1518 November 2005.
Banerjee, S., & Pedersen, T. (2003). Extended gloss overlap measure semantic relatedness.
Proceedings 18th International Joint Conference Artificial Intelligence, Acapulco,
206

fiK NOWLEDGE ERIVED F ROM W IKIPEDIA

Mexico, 915 August 2003, pp. 805810.
Beigman Klebanov, B. (2006). Semantic relatedness: Computational investigation human data.
Proceedings 3rd Midwest Computational Linguistics Colloquium, Urbana-Champaign,
Ill., 20-21 May 2006.
Beigman Klebanov, B., & Shamir, E. (2006). Reader-based exploration lexical cohesion. Language Resources Evaluation, 40(2), 109126.
Berger, A., Della Pietra, S. A., & Della Pietra, V. J. (1996). maximum entropy approach natural
language processing. Computational Linguistics, 22(1), 3971.
Bos, J., & Markert, K. (2005). Recognising textual entailment logical inference. Proceedings Human Language Technology Conference 2005 Conference Empirical
Methods Natural Language Processing, Vancouver, B.C., Canada, 68 October 2005, pp.
628635.
Budanitsky, A., & Hirst, G. (2006). Evaluating WordNet-based measures semantic distance.
Computational Linguistics, 32(1), 1347.
Bunescu, R., & Pasca, M. (2006). Using encyclopedic knowledge named entity disambiguation. Proceedings 11th Conference European Chapter Association
Computational Linguistics, Trento, Italy, 37 April 2006, pp. 916.
Carreras, X., & Marquez, L. (2005). Introduction CoNLL-2005 shared task: Semantic role labeling. Proceedings 9th Conference Computational Natural Language Learning,
Ann Arbor, Mich., USA, 2930 June 2005, pp. 152164.
Charniak, E. (1973). Jack Janet search theory knowledge. Advance Papers
Third International Joint Conference Artificial Intelligence, Stanford, Cal., pp. 337343,
Los Altos, Cal. W. Kaufmann.
Chinchor, N. (2001). Message Understanding Conference (MUC) 7. LDC2001T02, Philadelphia,
Penn: Linguistic Data Consortium.
Chinchor, N., & Sundheim, B. (2003).
Message Understanding Conference (MUC) 6.
LDC2003T13, Philadelphia, Penn: Linguistic Data Consortium.
Dagan, I. (2000). Contextual word similarity. Dale, R., Moisl, H., & H., S. (Eds.), Handbook
Natural Language Processing, pp. 459476. New York, N.Y.: Marcel Dekker Inc.
Finkelstein, L., Gabrilovich, E., Matias, Y., Rivlin, E., Solan, Z., Wolfman, G., & Ruppin, E. (2002).
Placing search context: concept revisited. ACM Transactions Information Systems,
20(1), 116131.
Gabrilovich, E., & Markovitch, S. (2006). Overcoming brittleness bottleneck using Wikipedia:
Enhancing text categorization encyclopedic knowledge. Proceedings 21st National Conference Artificial Intelligence, Boston, Mass., 1620 July 2006, pp. 13011306.
Gabrilovich, E., & Markovitch, S. (2007). Computing semantic relatedness using Wikipedia-based
explicit semantic analysis. Proceedings 20th International Joint Conference
Artificial Intelligence, Hyderabad, India, 612 January 2007, pp. 16061611.
Gildea, D., & Jurafsky, D. (2002). Automatic labeling semantic roles. Computational Linguistics,
28(3), 245288.
207

fiP ONZETTO & TRUBE

Giles, J. (2005). Internet encyclopedias go head head. Nature, 438, 900901.
Gimenez, J., & Marquez, L. (2004). SVMTool: general POS tagger generator based support
vector machines. Proceedings 4th International Conference Language Resources
Evaluation, Lisbon, Portugal, 2628 May 2004, pp. 4346.
Gorman, J., & Curran, J. R. (2006). Scaling distributional similarity large corpora. Proceedings
21st International Conference Computational Linguistics 44th Annual Meeting
Association Computational Linguistics, Sydney, Australia, 1721 July 2006, pp.
361368.
Gurevych, I. (2005). Using structure conceptual network computing semantic relatedness.
Proceedings 2nd International Joint Conference Natural Language Processing,
Jeju Island, South Korea, 1113 October 2005, pp. 767778.
Gurevych, I., & Niederlich, H. (2005a). Accessing GermaNet data computing semantic relatedness. Companion Volume Proceedings 43rd Annual Meeting Association
Computational Linguistics, Ann Arbor, Mich., 2530 June 2005, pp. 58.
Gurevych, I., & Niederlich, H. (2005b). Measuring semantic relatedness GermaNet word senses.
Tech. rep., EML Research gGmbH.
Harabagiu, S. M., Bunescu, R. C., & Maiorano, S. J. (2001). Text knowledge mining
coreference resolution. Proceedings 2nd Conference North American Chapter
Association Computational Linguistics, Pittsburgh, Penn., 27 June 2001, pp. 55
62.
Hobbs, J. R. (1978). Resolving pronominal references. Lingua, 44, 311338.
Hovy, E., Gerber, L., Hermjakob, U., Junk, M., & Lin, C.-Y. (2001). Question answering Webclopedia. Proceedings Thirteenth Text REtrieval Conference, Gaithersburg, Md.,
1316 November 2001.
Hsu, C.-W., Chang, C.-C., & Lin, C.-J. (2006). Practical Guide Support Vector Classification.
http://www.csie.ntu.edu.tw/cjlin/papers/guide/guide.pdf.
Jarmasz, M., & Szpakowicz, S. (2003). Rogets Thesaurus semantic similarity. Proceedings International Conference Recent Advances Natural Language Processing,
Borovets, Bulgaria, 1012 September 2003, pp. 212219.
Jiang, J. J., & Conrath, D. W. (1997). Semantic similarity based corpus statistics lexical taxonomy. Proceedings 10th International Conference Research Computational
Linguistics (ROCLING).
Kehler, A., Appelt, D., Taylor, L., & Simma, A. (2004). (non)utility predicate-argument
frequencies pronoun interpretation. Proceedings Human Language Technology
Conference North American Chapter Association Computational Linguistics,
Boston, Mass., 27 May 2004, pp. 289296.
Kim, S. N., & Baldwin, T. (2005). Automatic interpretation noun compounds using WordNet
similarity. Proceedings 2nd International Joint Conference Natural Language
Processing, Jeju Island, South Korea, 1113 October 2005, pp. 945956.
Kohavi, R., & John, G. H. (1997). Wrappers feature subset selection. Artificial Intelligence
Journal, 97(1-2), 273324.
208

fiK NOWLEDGE ERIVED F ROM W IKIPEDIA

Kohomban, U. S., & Lee, W. S. (2005). Learning semantic classes word sense disambiguation.
Proceedings 43rd Annual Meeting Association Computational Linguistics,
Ann Arbor, Mich., 2530 June 2005, pp. 3441.
Kudoh, T., & Matsumoto, Y. (2000). Use Support Vector Machines chunk identification.
Proceedings 4th Conference Computational Natural Language Learning, Lisbon,
Portugal, 1314 September 2000, pp. 142144.
Landauer, T. K., & Dumais, S. T. (1997). solution Platos problem: Latent Semantic
Analysis theory acquisition, induction, representation knowledge. Psychological
Review, 104, 211240.
Leacock, C., & Chodorow, M. (1998). Combining local context WordNet similarity
word sense identification. Fellbaum, C. (Ed.), WordNet. Electronic Lexical Database,
chap. 11, pp. 265283. Cambridge, Mass.: MIT Press.
Lee, L. (1999). Measures distributional similarity. Proceedings 37th Annual Meeting
Association Computational Linguistics, College Park, Md., 2026 June 1999, pp.
2531.
Lemnitzer, L., & Kunze, C. (2002). GermaNet representation, visualization, application.
Proceedings 3rd International Conference Language Resources Evaluation,
Las Palmas, Canary Islands, Spain, 2931 May 2002, pp. 14851491.
Lesk, M. (1986). Automatic sense disambiguation using machine readable dictionaries: tell
pine cone ice cream cone. Proceedings 5th Annual Conference Systems
Documentation, Toronto, Ontario, Canada, pp. 2426.
Lin, D. (1998). information-theoretic definition similarity. Proceedings 15th International Conference Machine Learning, Madison, Wisc., 2427 July 1998, pp. 296304.
Lo, K. K., & Lam, W. (2006). Using semantic relations world knowledge question answering. Proceedings Fifteenth Text REtrieval Conference, Gaithersburg, Md., 1417
November 2006.
Luo, X., Ittycheriah, A., Jing, H., Kambhatla, N., & Roukos, S. (2004). mention-synchronous
coreference resolution algorithm based Bell Tree. Proceedings 42nd Annual
Meeting Association Computational Linguistics, Barcelona, Spain, 2126 July 2004,
pp. 136143.
Malouf, R. (2002). comparison algorithms maximum entropy parameter estimation.
Proceedings 6th Conference Computational Natural Language Learning, Taipei,
Taiwan, 31 August 1 September 2002, pp. 4955.
Markert, K., & Nissim, M. (2005). Comparing knowledge sources nominal anaphora resolution.
Computational Linguistics, 31(3), 367401.
McCallum, A., Pal, C., Druck, G., & Wang, X. (2006). Multi-conditional learning: Generative/discriminative training clustering classification. Proceedings 21st National Conference Artificial Intelligence, Boston, Mass., 1620 July 2006, pp. 433439.
Mierswa, I., Wurst, M., Klinkenberg, R., Scholz, M., & Euler, T. (2006). YALE: Rapid prototyping
complex data mining tasks. Proceedings 12th ACM SIGKDD International
209

fiP ONZETTO & TRUBE

Conference Knowledge Discovery Data Mining, Philadelphia, Penn., 2023 August
2006, pp. 935940.
Mihalcea, R., Corley, C., & Strapparava, C. (2006). Corpus-based knowledge-based measures
text semantic similarity. Proceedings 21st National Conference Artificial
Intelligence, Boston, Mass., 1620 July 2006, pp. 775780.
Miller, G. A., & Charles, W. G. (1991). Contextual correlates semantic similarity. Language
Cognitive Processes, 6(1), 128.
Mitchell, A., Strassel, S., Przybocki, M., Davis, J., Doddington, G., Grishman, R., Meyers, A.,
Brunstain, A., Ferro, L., & Sundheim, B. (2003). TIDES extraction (ACE) 2003 multilingual
training data. LDC2004T09, Philadelphia, Penn.: Linguistic Data Consortium.
Ng, V., & Cardie, C. (2002). Improving machine learning approaches coreference resolution.
Proceedings 40th Annual Meeting Association Computational Linguistics,
Philadelphia, Penn., 712 July 2002, pp. 104111.
Palmer, M., Gildea, D., & Kingsbury, P. (2005). proposition bank: annotated corpus
semantic roles. Computational Linguistics, 31(1), 71105.
Patwardhan, S., Banerjee, S., & Pedersen, T. (2005). SenseRelate::TargetWord generalized
framework word sense disambiguation. Proceedings 20th National Conference
Artificial Intelligence, Pittsburgh, Penn., 913 July 2005.
Pedersen, T., Patwardhan, S., & Michelizzi, J. (2004). WordNet::Similarity Measuring relatedness concepts. Companion Volume Proceedings Human Language
Technology Conference North American Chapter Association Computational
Linguistics, Boston, Mass., 27 May 2004, pp. 267270.
Poesio, M., Ishikawa, T., Schulte im Walde, S., & Vieira, R. (2002). Acquiring lexical knowledge
anaphora resolution. Proceedings 3rd International Conference Language
Resources Evaluation, Las Palmas, Canary Islands, Spain, 2931 May 2002, pp. 1220
1225.
Ponzetto, S. P., & Strube, M. (2006a). Exploiting semantic role labeling, WordNet Wikipedia
coreference resolution. Proceedings Human Language Technology Conference
North American Chapter Association Computational Linguistics, New York,
N.Y., 49 June 2006, pp. 192199.
Ponzetto, S. P., & Strube, M. (2006b). Semantic role labeling coreference resolution. Companion Volume Proceedings 11th Conference European Chapter
Association Computational Linguistics, Trento, Italy, 37 April 2006, pp. 143146.
Ponzetto, S. P., & Strube, M. (2007a). API measuring relatedness words Wikipedia.
Companion Volume Proceedings 45th Annual Meeting Association
Computational Linguistics, Prague, Czech Republic, 2330 June 2007, pp. 4952.
Ponzetto, S. P., & Strube, M. (2007b). Deriving large scale taxonomy Wikipedia. Proceedings 22nd National Conference Artificial Intelligence, Vancouver, B.C., Canada,
2226 July 2007, pp. 14401447.
Pradhan, S., Ward, W., Hacioglu, K., Martin, J. H., & Jurafsky, D. (2004). Shallow semantic parsing using Support Vector Machines. Proceedings Human Language Technology
210

fiK NOWLEDGE ERIVED F ROM W IKIPEDIA

Conference North American Chapter Association Computational Linguistics,
Boston, Mass., 27 May 2004, pp. 233240.
Rada, R., Mili, H., Bicknell, E., & Blettner, M. (1989). Development application metric
semantic nets. IEEE Transactions Systems, Man Cybernetics, 19(1), 1730.
Resnik, P. (1993). Selection Information: Class-based Approach Lexical Relationships.
Ph.D. thesis, Department Computer Information Science, University Pennsylvania,
Philadelphia, Penn.
Resnik, P. (1995). Using information content evaluate semantic similarity taxonomy.
Proceedings 14th International Joint Conference Artificial Intelligence, Montreal,
Canada, 2025 August 1995, Vol. 1, pp. 448453.
Resnik, P. (1999). Semantic similarity taxonomy: information-based measure application problems ambiguity natural language. Journal Artificial Intelligence
Research, 11, 95130.
Rubenstein, H., & Goodenough, J. (1965). Contextual correlates synonymy. Communications
ACM, 8(10), 627633.
Salton, G., & McGill, M. (1983). Introduction Modern Information Retrieval. New York, N.Y.:
McGraw-Hill.
Seco, N., Veale, T., & Hayes, J. (2004). intrinsic information content metric semantic similarity WordNet. Proceedings 16th European Conference Artificial Intelligence,
Valencia, Spain, 2327 August 2004, pp. 10891090.
Soon, W. M., Ng, H. T., & Lim, D. C. Y. (2001). machine learning approach coreference
resolution noun phrases. Computational Linguistics, 27(4), 521544.
Stevenson, M., & Greenwood, M. (2005). semantic approach IE pattern induction. Proceedings 43rd Annual Meeting Association Computational Linguistics, Ann
Arbor, Mich., 2530 June 2005, pp. 379386.
Strube, M., & Ponzetto, S. P. (2006). WikiRelate! Computing semantic relatedness using Wikipedia.
Proceedings 21st National Conference Artificial Intelligence, Boston, Mass., 16
20 July 2006, pp. 14191424.
Tatu, M., Iles, B., Slavick, J., Novischi, A., & Moldovan, D. (2006). COGEX Second Recognizing Textual Entailment Challenge. Proceedings Second PASCAL Recognising
Textual Entailment Challenge Workshop, Venice, Italy, 10 April 2006, pp. 104109.
Turney, P. (2001). Mining web synonyms: PMI-IR versus LSA TOEFL. Proceedings
12th European Conference Machine Learning, Freiburg, Germany, 37 September,
2001, pp. 491502.
van Rijsbergen, C. (1979). Information Retrieval. London, U.K.: Butterworths.
Vapnik, V. (1995). Nature Statistical Learning Theory. Springer-Verlag, Berlin, Germany.
Vieira, R., & Poesio, M. (2000). empirically-based system processing definite descriptions.
Computational Linguistics, 26(4), 539593.
Vilain, M., Burger, J., Aberdeen, J., Connolly, D., & Hirschman, L. (1995). model-theoretic
coreference scoring scheme. Proceedings 6th Message Understanding Conference
(MUC-6), pp. 4552, San Mateo, Cal. Morgan Kaufmann.
211

fiP ONZETTO & TRUBE

Weeds, J., & Weir, D. (2005). Co-occurrence retrieval: flexible framework lexical distributional similarity. Computational Linguistics, 31(4), 439475.
Wu, Z., & Palmer, M. (1994). Verb semantics lexical selection. Proceedings 32nd
Annual Meeting Association Computational Linguistics, Las Cruces, N.M., 2730
June 1994, pp. 133138.
Yang, X., Zhou, G., Su, J., & Tan, C. L. (2003). Coreference resolution using competition learning
approach. Proceedings 41st Annual Meeting Association Computational
Linguistics, Sapporo, Japan, 712 July 2003, pp. 176183.

212

fiJournal Artificial Intelligence Research 30 (2007) 413-456

Submitted 05/2007; published 11/2007

Individual Domain Adaptation
Sentence Planning Dialogue
Marilyn Walker

lynwalker@gmail.com

Department Computer Science, University Sheffield
211 Portobello Street, Sheffield S1 4DP, United Kingdom

Amanda Stent

amanda.stent@gmail.com

Department Computer Science, Stony Brook University
Stony Brook, NY 11794, USA

Francois Mairesse

f.mairesse@sheffield.ac.uk

Department Computer Science, University Sheffield,
211 Portobello Street, Sheffield S1 4DP, United Kingdom

Rashmi Prasad

rjprasad@linc.cis.upenn.edu
Institute Research Cognitive Science, University Pennsylvania,
3401 Walnut Street, Suite 400A, Philadelphia, PA 19104, USA

Abstract
One biggest challenges development deployment spoken dialogue
systems design spoken language generation module. challenge arises
need generator adapt many features dialogue domain, user
population, dialogue context. promising approach trainable generation,
uses general-purpose linguistic knowledge automatically adapted features
interest, application domain, individual user, user group. paper
present evaluate trainable sentence planner providing restaurant information
MATCH dialogue system. show trainable sentence planning produce
complex information presentations whose quality comparable output templatebased generator tuned domain. also show method easily supports
adapting sentence planner individuals, individualized sentence planners
generally perform better models trained tested population individuals.
Previous work documented utilized individual preferences content selection,
knowledge, results provide first demonstration individual preferences
sentence planning operations, affecting content order, discourse structure sentence
structure system responses. Finally, evaluate contribution different feature
sets, show that, application, n-gram features often well features based
higher-level linguistic representations.

1. Introduction
One robust findings studies human-human dialogue people adapt
interactions match conversational partners needs behaviors (Goffman,
1981; Brown & Levinson, 1987; Pennebaker & King, 1999). People adapt content
utterances (Garrod & Anderson, 1987; Luchok & McCroskey, 1978). choose
syntactic structures match partners syntax (Levelt & Kelter, 1982; Branigan,
Pickering, & Cleland, 2000; Reitter, Keller, & Moore, 2006; Stenchikova & Stent, 2007),
c
2007
AI Access Foundation. rights reserved.

fiWalker, Stent, Mairesse, & Prasad

adapt choice words referring expressions (Clark & Wilkes-Gibbs, 1986;
Brennan & Clark, 1996). also adapt speaking rate, amplitude, clarity
pronunciation (Jungers, Palmer, & Speer, 2002; Coulston, Oviatt, & Darves, 2002; Ferguson
& Kewley-Port, 2002).
However, beyond state art reproduce type adaptation
spoken language generation module dialogue system, i.e. components
handle response generation information presentation. standard generation system
includes modules content planning, sentence planning, surface realization (Kittredge,
Korelsky, & Rambow, 1991; Reiter & Dale, 2000). content planner takes input
communicative goal; selects content realize goal organizes content
content plan. sentence planner takes input content plan. decides
content allocated sentences, sentences ordered, discourse cues
use express relationships content elements. outputs sentence plan.
Finally, surface realizer determines words word order sentence
sentence plan. outputs text speech realization original communicative goal.
findings human-human dialogue suggest adaptation could potentially
useful stage generation pipeline. Yet date, work adaptation
individual users utilizes models users knowledge, needs, preferences adapt
content content planning (Jokinen & Kanto, 2004; Rich, 1979; Wahlster & Kobsa,
1989; Zukerman & Litman, 2001; Carenini & Moore, 2006), rather applying models
individual linguistic preferences form output, determined sentence
planning surface realization.
However, consider alternative realizations restaurant recommendation Figure 1. Columns B contain human ratings quality realizations users
B. differences rating feedback suggest user different perceptions quality potential realizations. Data experiment collecting
feedback users B, 20 realizations 30 different recommendation content
plans (600 examples), shows feedback two users easily distinguished:
paired t-test supports hypothesis two samples sampled distinct distributions (t = 17.4, p < 0.001). perceptual differences appear general:
examined user feedback evaluation experiment described Rambow,
Rogati, Walker (2001) 60 users rated output 7 different spoken language
generators 20 content plans, found significant differences user perceptions
utterance quality (F = 1.2, p < 0.002). led us hypothesize individualized
sentence planners dialogue systems might high utility.
addition studies, also find evidence work individual
variation inherent many aspects language generation, including content ordering,
referring expression generation, syntactic choice, lexical choice, prosody generation.
common knowledge individual authors identified linguistic
features written texts (Madigan, Genkin, Lewis, Argamon, Fradkin, & Ye,
2005; Oberlander & Brew, 2000).
examination weather report corpus five weather forecasters showed individual differences lexical choice expressing specific weather-related concepts
(Reiter & Sripada, 2002).
414

fiIndividual Domain Adaptation Dialogue

Alt Realization
6
Chanpen Thai best overall quality among selected restaurants since Thai restaurant, good service, price 24
dollars, good food quality.
7
Chanpen Thai best overall quality among selected restaurants good service, good food quality, Thai
restaurant, price 24 dollars.
4
Chanpen Thai best overall quality among selected restaurants. good food quality, good service, Thai restaurant, price 24 dollars.
9
Chanpen Thai Thai restaurant, good food quality, price
24 dollars, good service. best overall quality
among selected restaurants.
5
Chanpen Thai best overall quality among selected restaurants. good service. good food quality. price 24
dollars, Thai restaurant.
3
Chanpen Thai best overall quality among selected restaurants. price 24 dollars. Thai restaurant, good
service. good food quality.
10 Chanpen Thai best overall quality among selected restaurants. good food quality. price 24 dollars. Thai
restaurant, good service.
2
Chanpen Thai best overall quality among selected restaurants. price 24 dollars, Thai restaurant. good
food quality good service.
1
Chanpen Thai best overall quality among selected restaurants. Thai restaurant good food quality. price 24
dollars, good service.
8
Chanpen Thai Thai restaurant, good food quality.
good service. price 24 dollars. best overall quality
among selected restaurants.


1

B
4

AVG
2.5

2

5

3.5

2

4

3

2

4

3

3

2

2.5

3

3

3

3

3

3

4

4

4

4

3

3.5

4

2

3

Figure 1: alternative realizations content plan Figure 4, feedback
Users B, mean (AVG) feedback (1=worst 5=best).

Rules learned generating nominal referring expressions perform better individual speakers provided feature learning algorithm (Jordan & Walker,
2005), experiment evaluating choice referring expression shows 70%
agreement among native speakers best choice (Yeh & Mellish, 1997). Chai,
Hong, Zhou, Prasov (2004) show also individual differences
gesture generating multimodal references, corpus study accented
pronouns reported Kothari (2007) suggests accentuation also partly determined individual linguistic style.
Automatic evaluation techniques applied human-generated reference outputs
machine translation automatic summarization perform better multiple outputs provided comparison (Papenini, Roukos, Ward, & Zhu, 2002; Nenkova,
Passonneau, & McKeown, 2007): attributed large variation
humans generate given particular content express. also reflected finding human subjects produce many different valid content orderings asked
order specific set content items produce best possible summary (Barzilay,
Elhadad, & McKeown, 2002; Lapata, 2003).
415

fiWalker, Stent, Mairesse, & Prasad

past, linguistic variation among individuals considered problem generation researchers work around, rather potential area study (McKeown, Kukich,
& Shaw, 1994; Reiter, 2002; Reiter, Sripada, & Robertson, 2003). part, due
hand-crafting generation components resources. impossible encode
hand, individual, rules sentence planning realization. Furthermore,
domain experts dont agree best way express domain concept,
generation dictionary encoded? difficult simply get good output respects
interacting domain linguistic constraints even considerable handcrafting
rules (Kittredge, Korelsky, & Rambow, 1991).
Modeling individual differences also problem statistical methods
learning paradigms used assume single correct output (Lapata, 2003;
Jordan & Walker, 2005; Hardt & Rambow, 2001) inter alia. believe simplest
way deal inherent variability possible generation outputs treat generation
ranking problem explain below, techniques overgenerate using user
domain-independent rules, filter rank possibilities using domain userspecific corpora feedback (Langkilde & Knight, 1998; Langkilde-Geary, 2002; Bangalore
& Rambow, 2000; Rambow, Rogati, & Walker, 2001). approach advantage
dialogue systems also affords joint optimization generator textto-speech engine (Bulyko & Ostendorf, 2001; Nakatsu & White, 2006). many
problems generation ranking models individualization could applied,
text planning, cue word selection, referring expression generation (Mellish, ODonnell,
Oberlander, & Knott, 1998; Litman, 1996; Di Eugenio, Moore, & Paolucci, 1997; Marciniak
& Strube, 2004). However, recently work generation acknowledged
individual differences tried model (Guo & Stent, 2005; Mairesse &
Walker, 2005; Belz, 2005; Lin, 2006).
article describes SPaRKy (Sentence Planning Rhetorical Knowledge), sentence planner uses rhetorical relations adapts users individual sentence
planning preferences.1 SPaRKy two components: randomized sentence plan generator (SPG) produces multiple alternative realizations information presentation,
sentence plan ranker (SPR) trained (using human feedback) rank
alternative realizations (See Figure 1). mentioned above, previous work documented
utilized individual preferences content selection, knowledge, results
provide first demonstration individual preferences sentence planning operations,
affecting content ordering, discourse structure, sentence structure, sentence scope
system responses. also show learned preferences domain-specific.
Section 2 compares approach results previous work. Section 3 provides
overview MATCH system architecture, generate dialogue system responses
using either SPaRKy, domain-specific template-based generator described evaluated previous work (Stent, Walker, Whittaker, & Maloor, 2002; Walker et al., 2004).
Sections 4, 5 6 describe SPaRKy detail; describe SPG, automatic
generation features used training SPR, boosting used train SPR.
Sections 7 8 present quantitative qualitative results:
1. Java version SPaRKy downloaded www.dcs.shef.ac.uk/cogsys/sparky.html

416

fiIndividual Domain Adaptation Dialogue

1. First, show SPaRKy learns select sentence plans significantly
better randomly selected sentence plan, average less 10% worse
sentence plan ranked highest human judges. also show that,
experiments, simple n-gram features perform well features based higher-level
linguistic representations.
2. Second, show SPaRKys SPG produce realizations comparable
MATCHs template-based generator, gap
realization SPR selects trained multiple users selected
human.
3. Third, show SPaRKy trained particular individuals, performs
better trained feedback multiple individuals. first
results suggesting individual sentence planning preferences exist,
modeled trainable generation system. also show cases
performance individualized SPRs statistically indistinguishable
MATCHs template-based generator, compare-2, User B prefers SPaRKy,
compare-3, User prefers template-based generator.
4. Fourth, show differences learned models make sense terms
previous rule-based approaches sentence planning. analyze qualitative
differences learned group individual models, show SPaRKy
learns specific rules interaction content items sentence planning
operations, rules model individual differences, would difficult
capture hand-crafted generator.
sum discuss future work Section 9.

2. Related Work
discuss related work adaptation generation using standard generation architecture contains modules content planning (Section 2.1), sentence planning
(Section 2.2) surface realization (Section 2.3) (Kittredge, Korelsky, & Rambow, 1991;
Reiter & Dale, 2000).
2.1 Adaptation Content Planning
significant research use user models discourse context adapt
content information presentations dialogue (Joshi, Webber, & Weischedel, 1984,
1986; Chu-Carroll & Carberry, 1995; Zukerman & Litman, 2001) inter alia,
user models (not information presentation strategies) sensitive particular individuals. Several studies investigated use quantitative models user preferences
selection content recommendations comparisons (Carenini & Moore, 2006; Walker
et al., 2004; Polifroni & Walker, 2006), Moore, Foster, Lemon, White (2004) use
models referring expression generation, sentence planning surface realization. Elhadad, Kan, Klavans, McKeown (2005) applied group models (physician,
lay person) individual user models task summarizing medical information.
417

fiWalker, Stent, Mairesse, & Prasad

McCoy (1989) used context information design helpful system-generated corrections.
work looked use statistical techniques adapting content selection
content ordering methods particular domains (Barzilay, Elhadad, & McKeown, 2002;
Duboue & McKeown, 2003; Lapata, 2003), individual users.
2.2 Adaptation Sentence Planning
first trainable sentence planner SPoT, precursor SPaRKy output information gathering utterances travel domain (Walker, Rambow, & Rogati, 2002).
Evaluations SPoT demonstrated performed well template-based generator
developed travel domain field-tested DARPA Communicator evaluations
(Rambow, Rogati, & Walker, 2001; Walker et al., 2002). Information gathering utterances
considerably simpler information presentations: usually exhibit
complexities rhetorical structure, little interaction domain-specific
content items sentence structures. Thus SPoT generator produce utterances variation rhetorical structure; learned optimize speech-act ordering
sentence structure choices, adapt individuals.
2.3 Adaptation Surface Realization
Work adaptation surface realization mainly focused decisions lexical
syntactic choice, using models target text, individual text models, although
recent research also shown n-gram models trained user-specific corpora
adapt generators reproduce individualized lexical syntactic choices (Lin, 2006; Belz,
2005). Paiva Evans (2004) present technique training generator learning
relationship particular generation decisions text variables measured
output corpus. technique applied generator decisions form
referring expression syntactic structure, used capture stylistic, rather
individual, differences. Gupta Stent (2005) use discourse context speaker
knowledge referring expression generation dialogue.
User models also used adapt surface realization. approach learning
ranking user feedback applied multimedia presentation planning (Stent
& Guo, 2005) joint optimization syntactic realizer text-to-speech
engine (Nakatsu & White, 2006). work look individual differences.
Research also focused factors affect stylistic variation realization
choices reflect personality, politeness, emotion domain specific style (Hovy, 1987; DiMarco
& Foster, 1997; Walker, Cahn, & Whittaker, 1997; Andre, Rist, van Mulken, Klesen, &
Baldes, 2000; Bouayad-Agha, Scott, & Power, 2000; Fleischman & Hovy, 2002; Piwek,
2003; Porayska-Pomsta & Mellish, 2004; Isard, Brockmann, & Oberlander, 2006; Gupta,
Walker, & Romano, 2007; Mairesse & Walker, 2007). None work attempted
reproduce individual stylistic variation.

418

fiIndividual Domain Adaptation Dialogue

3. Overview MATCHs Spoken Language Generator

Dialog Manager
Communicative
goal

SPUR text planner

Content
plan
SPaRKy
Textplan trees
(tptrees)

Sentence plan
generator

Pairs
(sentence plan [sptree],
dependency tree [dtree])

Templatebased
generator

Sentence plan
ranker

Text

Ranked list
(sptree, dtree) pairs

RealPro surface realizer

Text

Figure 2: Architecture MATCHs Spoken Language Generator.

MATCH (Multimodal Access City Help) multimodal dialogue system finding
restaurants entertainment options New York City (Johnston, Bangalore, Vasireddy,
Stent, Ehlen, Walker, Whittaker, & Maloor, 2002). Information presentations MATCH
include route descriptions, well user-tailored recommendations comparisons
restaurants. Figure 2 shows MATCHs architecture spoken language generation (SLG).
content planning module SPUR text planner (Section 3.1) (Walker et al., 2004).
two modules producing text spoken dialogue responses SPURs output: highly engineered domain-specific template-based realizer (Section 3.2);
SPaRKy sentence planner followed RealPro surface realizer (Lavoie & Rambow,
1997) (Section 3.3). Example template-based SPaRKy outputs dialogue strategy Figure 3. SPUR SPaRKy trainable, produce different output
depending user discourse context.
419

fiWalker, Stent, Mairesse, & Prasad

Strategy
recommend

System
Template

recommend

SPaRKy

compare-2

Template

compare-2

SPaRKy

compare-3

Template

compare-3

SPaRKy

Realization
Caffe Cielo best overall value among selected
restaurants. Caffe Cielo good decor good service.
Italian restaurant.
Caffe Cielo, Italian restaurant, good decor
good service, best overall quality among
selected restaurants.
Caffe Buon Gustos Italian restaurant.
hand, Johns Pizzerias Italian, Pizza restaurant.
Caffe Buon Gusto Italian restaurant, Johns
Pizzeria Italian , Pizza restaurant.
Among selected restaurants, following offer exceptional overall value. Uguales price 33 dollars.
good decor good service. French, Italian
restaurant. Da Andreas price 28 dollars. good
decor good service. Italian restaurant.
Johns Pizzerias price 20 dollars. mediocre decor
decent service. Italian, Pizza restaurant.
Da Andrea, Uguale, Johns Pizzeria offer exceptional
value among selected restaurants. Da Andrea Italian restaurant, good service, good decor,
price 28 dollars. Johns Pizzeria Italian ,
Pizza restaurant. decent service. mediocre
decor. price 20 dollars. Uguale French, Italian
restaurant, good service. good decor,
price 33 dollars.

AVG
4

4

2
4
4.5

4

Figure 3: Template outputs sample SPaRKy output dialogue strategy. AVG
= Averaged score two human users.

3.1 SPUR
input SPUR high-level communicative goal MATCH dialogue
manager output content plan recommendation comparison. SPUR
selects organizes content communicated based communicative goal,
conciseness parameter, decision-theoretic user model. produces targeted recommendations comparisons: restaurants mentioned attributes selected
restaurant user model predicts user want know about. Thus
SPUR produce wide variety content plans.
Figure 4 shows sample content plan recommendation. content plan gives rise
alternate realizations recommendations Chanpen Thai Figure 1. Following
bottom-up approach text-planning (Marcu, 1997; Mellish, ODonnell, Oberlander, &
Knott, 1998), content plan consists set assertions must communicated
user set rhetorical relations hold assertions may
communicated well. rhetorical relation designates one facts nuclei
relation, i.e. main point, facts satellites, i.e. supplementary
facts (Mann & Thompson, 1987). Three rhetorical relations (Mann & Thompson, 1987)
used SPUR: justify relation recommendation strategy, contrast
elaboration relations comparison strategies. relations Figure 4 specify
nucleus (1) claim made recommendation, satellites
(assertions 2 5) provide justifying evidence claim.
420

fiIndividual Domain Adaptation Dialogue

relations:justify(nuc:1, sat:2); justify (nuc:1, sat:3 ); justify(nuc:1, sat:4);
justify(nuc:1, sat:5)
content: 1. assert(best (Chanpen Thai))
2. assert(is (Chanpen Tai, cuisine(Thai)))
3. assert(has-att(Chanpen Thai, food-quality(good)))
4. assert(has-att(Chanpen Thai, service(good)))
5. assert(is (Chanpen Thai, price(24 dollars)))
Figure 4: content plan recommendation.

3.2 Template-Based Generator
order produce utterances content plans produced SPUR, first implemented evaluated template-based generator MATCH (Stent, Walker, Whittaker,
& Maloor, 2002; Walker et al., 2004). template-based generator designed
make possible evaluate algorithms user-specific content selection based SPURs
decision-theoretic user model. performs sentence planning, including discourse cue
insertion, clause combining referring expression generation. produces one high quality output content plan three dialogue strategies: recommend, compare-2
compare-3. Recommendations comparisons one form evaluative argument,
realization strategies based guidelines argumentation theory producing
effective evaluative arguments, summarized Carenini Moore (2000).
templates highly tailored domain, template-based generator expected
perform well comparison SPaRKy.
Following argumentation guidelines, template-based generator realizes recommendations nucleus ordered first, followed satellites. satellites
ordered maximize opportunity aggregation. produce concise recommendations given content communicated, phrases identical verbs subjects
grouped, lists coordination used aggregrate assertions
subject. Figure 5 provides examples aggregration number assertions varies
according SPURs conciseness parameter (Z-value).
realization template comparisons focuses communicating elaboration
contrast relations. Figure 6 contains content plan comparisons. nucleus
assertion (1) Carmines exceptional restaurants. satellites
(assertions 2 7 representing selected attributes restaurant) elaborate
claim nucleus (assertion 1). Contrast relations hold assertions 2 3,
4 5, 6 7. One way communicate elaboration relation
structure comparison satellites grouped together, following
nucleus. communicate contrast relation, satellites produced fixed order,
parallel structure maintained across options (Prevost, 1995; Prince, 1985).
satellites initially ordered terms evidential strength, reordered
allow aggregation. Figure 7 illustrates aggregation comparisons varying
numbers assertions.
421

fiWalker, Stent, Mairesse, & Prasad

Z
1.5
0.7
0.3
-0.5
-0.7

-1.5

Output
Komodo best overall value among selected restaurants. Komodos Japanese,
Latin American restaurant.
Komodo best overall value among selected restaurants. Komodos Japanese,
Latin American restaurant.
Komodo best overall value among selected restaurants. Komodos price
$29. Japanese, Latin American restaurant.
Komodo best overall value among selected restaurants. Komodos price
$29 good service. Japanese, Latin American restaurant.
Komodo best overall value among selected restaurants. Komodos price
$29 good service good food quality. Japanese, Latin
American restaurant.
Komodo best overall value among selected restaurants. Komodos price
$29 good service, good food quality good decor. Japanese,
Latin American restaurant.

Figure 5: Recommendations East Village Japanese Task, different settings
conciseness parameter Z.

strategy: compare3
items:
Above, Carmines
relations: elaboration(nuc:1,sat:2);
elaboration(nuc:1,sat:3);
elaboration(nuc:1,sat:4);
elaboration(nuc:1,sat:5);
elaboration(nuc:1,sat:6); elaboration(nuc:1,sat:7); contrast(nuc:2,nuc:3);
contrast(nuc:4,nuc:5); contrast(nuc:6,nuc:7)
content: 1. assert(exceptional(Above,Carmines))
2. assert(has-att(Above, decor(good)))
3. assert(has-att(Carmines, decor(decent)))
4. assert(has-att(Above, service(good)))
5. assert(has-att(Carmines, service(good)))
6. assert(has-att(Above, cuisine(New American)))
7. assert(has-att(Carmines, cuisine(Italian)))
Figure 6: content plan comparison.

3.3 SPaRKy
Like template-based generator, SPaRKy takes input content plans produced SPUR. Figure 2 shows SPaRKy two modules: sentence plan generator (SPG), sentence plan ranker (SPR). SPG uses set clause-combining
operations (Figure 12); produces large set alternative realizations input content
plan (See Figure 1). SPR ranks alternative realizations using model learned
users ratings training set content plans. SPG described Section 4.
features used train SPR described Section 5; procedure training
SPR described Section 6.
SPaRKy trained using user feedback, rather handcrafted,
trained individualized spoken language generator. discussed above,
422

fiIndividual Domain Adaptation Dialogue

Z
1.5
0.7
0.3

-0.5

-0.7

-1.5

Output
Among selected restaurants, following offer exceptional overall value. Komodo
good service.
Among selected restaurants, following offer exceptional overall value. Komodo
good service good decor.
Among selected restaurants, following offer exceptional overall value. Komodos
price $29. good food quality, good service good decor. Takahachis
price $27. good food quality, good service decent decor.
Among selected restaurants, following offer exceptional overall value. Komodos
price $29. good food quality, good service good decor. Takahachis
price $27. good food quality, good service decent decor. Japonicas
price is$37. excellent food quality, good service decent decor
Among selected restaurants, following offer exceptional overall value. Komodos
price $29. good food quality, good service good decor. Takahachis
price $27. good food quality, good service decent decor. Japonicas
price $37. excellent food quality, good service decent decor. Shabu-Tatsus
price $31. good food quality, good service decent decor.
Among selected restaurants, following offer exceptional overall value. Komodos
price $29. good food quality, good service good decor. Takahachis
price $27. good food quality, good service decent decor. Japonicas
price $37. excellent food quality, good service decent decor. Shabu-Tatsus
price $31. good food quality, good service decent decor. Bond Streets
price $51. excellent food quality, good service good decor. Dojos price
$14. decent food quality, mediocre service mediocre decor.

Figure 7: Comparisons East Village Japanese Task, different settings
conciseness parameter Z.

feedback two users Figure 1 suggests user different perceptions
quality potential realizations. significant part Sections 7 8
dedicated examining differences model trained averaged feedback,
shown AVG Figure 1, trained individual feedback users B.

4. Sentence Plan Generation
input SPaRKys SPG content plan SPUR. Content plans
sample recommendation comparison Figure 4 Figure 6. Figure 1 shows
alternative SPaRKy realizations recommendation Figure 4, Figure 8 shows
alternative SPaRKy realizations comparison Figure 6. Content plans specify
assertions include information presentation, rhetorical relations
holding them, order assertions express rhetorical
relations them. task known discourse planning. SPG two stages
processing; first discourse planning, sentence planning.
4.1 Discourse Planning
Discourse planning algorithms characterized as: schema-based (McKeown, 1985;
Kittredge, Korelsky, & Rambow, 1991); top-down algorithms using plan operators (Moore
& Paris, 1993); bottom-up approaches use, example, constraint satisfaction
algorithms (Marcu, 1996, 1997) genetic algorithms (Mellish, ODonnell, Oberlander, &
423

fiWalker, Stent, Mairesse, & Prasad

Alt Realization
11 Carmines offer exceptional value among selected restaurants.
Above, New American restaurant, good decor, good service.
Carmines, Italian restaurant, good service, decent decor.
12 Carmines offer exceptional value among selected restaurants.
good decor, Carmines decent decor. Carmines
good service. New American restaurant. hand,
Carmines Italian restaurant.
13 Carmines offer exceptional value among selected restaurants.
New American restaurant. good decor. good service.
Carmines, Italian restaurant, decent decor good service.
14 Carmines offer exceptional value among selected restaurants.
good decor Carmines decent decor,
Carmines good service. New American restaurant
Carmines Italian restaurant.
20 Carmines offer exceptional value among selected restaurants.
Carmines decent decor good decor, Carmines
good service. Carmines Italian restaurant. Above, however,
New American restaurant.
25 Carmines offer exceptional value among selected restaurants.
good decor. Carmines Italian restaurant. good
service. Carmines decent decor. New American restaurant.
Carmines good service.


2

B
2

AVG
2

3

2

2.5

3

3

3

4

5

4.5

2

3

2.5

NR

NR

NR

Figure 8: alternative realizations compare-3 plan Figure 6, feedback
Users B, mean (AVG) feedback (1=worst 5=best).
NR = generated ranked.
justify

infer

nucleus: <1>
assertreco
best

satellite: <2>
assertreco
cuisine

satellite: <3>
assertreco
foodquality

satellite: <4>
assertreco
service

satellite: <5>
assertreco
price

Figure 9: tp-tree plan Figure 4, used generate Alternatives 1, 3, 4, 5, 6, 7
10 Figure 1.

Knott, 1998). SPaRKy, SPG takes bottom-up approach discourse planning
using principles Centering Theory (Grosz, Joshi, & Weinstein, 1995). Content items
grouped talk thing, linear order
among groupings left unspecified. centering constraints result
Alt-25 Figure 8, repeatedly changes discourse center, never generated.
discourse planning stage produces one text-plan trees (tp-trees). tp-tree
recommend plan Figure 4 Figure 9, tp-trees compare-3 plan
Figure 6 Figure 10. tp-tree, leaf represents single assertion labeled
424

fiIndividual Domain Adaptation Dialogue

elaboration
infer

nucleus:<1>assert-com-list_exceptional

contrast

contrast

nucleus:<4>assert-com-service

nucleus:<2>assert-com-decor

contrast
nucleus:<6>assert-com-cuisine

nucleus:<5>assert-com-service

nucleus:<3>assert-com-decor

nucleus:<7>assert-com-cuisine

elaboration
nucleus:<1>assert-com-list_exceptional

contrast
infer

infer
nucleus:<2>assert-com-decor

nucleus:<3>assert-com-decor
nucleus:<7>assert-com-cuisine
nucleus:<5>assert-com-service

nucleus:<6>assert-com-cuisine

nucleus:<4>assert-com-service

Figure 10: Tp-trees comparisons shown alternatives 12 14 (top) alternatives 11 13 (bottom) Figure 8.

speech act. Interior nodes labeled rhetorical relations. addition
rhetorical relations content plan, SPG uses relation infer combinations
speech acts rhetorical relation expressed content plan (Marcu,
1997). infer relation similar joint relation RST; joins multiple satellites
mononuclear relation nuclei multinuclear relation.
simple assertion, leaf, tp-tree associated one syntactic
realizations (d-trees), using dependency tree representation, called DSyntS (Figure 11)
(Melcuk, 1988; Lavoie & Rambow, 1997). association simple assertions
potential d-trees specifying syntactic realizations specified hand-crafted
generation dictionary. Leaves d-trees generation dictionary variables,
instantiated content plan, e.g. Thai replaces cuisine type variable.
4.2 Sentence Planning
sentence planning, SPG assigns assertions sentences, orders sentences,
inserts discourse cues, performs referring expression generation. uses set clausecombining operations operate tp-trees incrementally transform elementary
d-trees associated leaves single lexico-structural representation. output
process two parallel structures: (1) sentence plan tree (sp-tree), binary tree
leaves labeled assertions input tp-tree, interior nodes labeled
clause-combining operations; (2) one d-trees reflect parallel operations
predicate-argument representations.
clause-combining operations general operations similar aggregation operations used research (Rambow & Korelsky, 1992; Danlos, 2000). operations
425

fiWalker, Stent, Mairesse, & Prasad

assert-com-cuisine

assert-com-food quality

BE3 [class:verb ]
(
Chanpen Thai [number:sg class:proper noun article:no-art person:3rd ]
II restaurant [class:common noun article:indef ]
(
Thai [class:adjective ]
)
)
HAVE1 [class:verb ]
(
Chanpen Thai [number:sg class:proper noun article:no-art person:3rd ]
II quality [class:common noun article:no-art ]
(
ATTR good [class:adjective ]
ATTR food [class:common noun ]
)
)

Figure 11: Example d-trees generation dictionary used SPG.
examples use given Figure 12. applied bottom-up left-to-right
fashion, choice operation constrained rhetorical relation holding
assertions combined (Scott & de Souza, 1990), specified Figure 12.
addition ordering assertions, clause-combining operation may insert cue words
assertions. Figure 13 gives list cue words used SPG. choice
cue-word determined type rhetorical relation2 .
SPG generates random sample possible sp-trees tp-tree, prespecified number sp-trees, randomly selecting among clause-combining operations
according probability distribution favors preferred operations. Table 14 shows
probability distribution used experiments, hand-crafted based assumed
preferences operations merge, relative-clause with-reduction,
one way knowledge injected random process bias
towards producing higher quality sentence plans.3
SPG handles referring expression generation converting proper name pronoun proper name appears previous utterance. Referring expression
generation rules applied locally, across adjacent utterances, rather globally across
entire presentation (Brennan, Friedman, & Pollard, 1987). Referring expressions
manipulated d-trees, either intrasententially incremental creation
sp-tree, intersententially, full sp-tree contains period operations.
2. alternative approach cue-word impose constraint rhetorical relation must
hold (Webber, Knott, Stone, & Joshi, 1999; Forbes, Miltsakaki, Prasad, Sarkar, Joshi, & Webber, 2003).
3. probability distribution could learned corpus (Marcu, 1997; Prasad, Joshi, Dinesh, Lee,
& Miltsakaki, 2005).
4. infer relation holds clauses contain possession predicate, second clause
arbitrarily selected reduction. justify relation holds, satellite RST relation
always undergoes reduction, syntactic constraints satisfied.
5. infer relation holds, clause arbitrarily selected reduction. justify relation holds,
clause undergoes relative clause formation satellite clause. motivated fact
relative clause formation generally seen occur modifying relative clause provides additional
information noun modifies, additional/elaborated information
informational status information main clause.

426

fiIndividual Domain Adaptation Dialogue

Operation

Rel

Description

Merge

infer

contrast

Withreduction

justify
infer

Relativeclause

justify
infer

Two clauses combined
identical matrix verbs
identical arguments adjuncts except one.
nonidentical arguments coordinated.
Two clauses identical subject arguments identified
one clauses havepossession matrix verb.

possession clause undergoes withparticipial clause formation
attached non-reduced
clause.4
Two clauses identical
subject identified. One
clause attached subject
clause relative
clause.5

justify, inCuefer conwordconjunction trast

Cuewordinsertion
(on


hand)

contrast

Period

justify,
contrast,
infer

elaboration

Two clauses conjoined
cue word (coordinating subordinating conjunction). order
arguments connective determined order
nucleus (N) satellite
(S), yielding two distinct operations, cue-word-conjunctionns cue-word-conjunctionsn.
cue-word insertion combines
clauses inserting cue word
start second clause
(Carmines Italian restaurant. HOWEVER,
New American restaurant), resulting two separate sentences.
Two clauses joined period.

Sample 1st
arg
Chanpen
Thai

good service.

Sample
2nd arg
Chanpen
Thai

good
food
quality.

Result

Chanpen
Thai
Thai restaurant.

Chanpen
Thai

good
food
quality.

Chanpen Thai
Thai restaurant,
good food
quality.

Chanpen
Thai


best
overall quality
among
selected
restaurants.
Chanpen
Thai


best
overall quality
among
selected
restaurants.

Chanpen
Thai

located

Midtown
West.

Chanpen
Thai,
located
Midtown West,
best overall
quality among
selected
restaurants.
Chanpen Thai
best overall
quality among
selected
restaurants, since
Thai
restaurant,
good service.

Chanpen
Thai


Thai
restaurant,

good
service.

Chanpen Thai
good service
good food quality.

Penang

good
decor.

Baluchis

mediocre
decor.

Penang
good decor.

hand,
Baluchis

mediocre decor.

Chanpen
Thai
Thai restaurant,

good
food
quality.

Chanpen
Thai

good
service.

Chanpen Thai
Thai restaurant,
good food
quality.

good service.

Figure 12: Clause combining operations examples.

third fourth sentences Alt 13 Figure 8 show conversion named restaurant
(Carmines) pronoun.
sp-trees Alts 6 8 Figure 1 shown Figs. 15 16. Leaf labels
concise names assertions content plan, e.g. assert-reco-best claim (labelled
1) Figure 4. combination operations switch order arguments,
satellite nucleus (SN) nucleus satellite (NS), labels interior
nodes indicate whether occurred, specify rhetorical relation operation
realizes. labels keep track operations substitutions used constructing
tree subsequently used tree feature set described Section 5, one
427

fiWalker, Stent, Mairesse, & Prasad

RST relation
justify
contrast
infer
elaboration

Aggregation operator
with-reduction, relative-clause, cue-word conj. because, cue-word
conj. since, period
merge, cue-word insert. however, cue-word conj. while, cue-word conj.
and, cue-word conj. but, cue-word insert. hand, period
merge, cue-word conj. and, period
period

Figure 13: RST relation constraints aggregation operators.
Aggregation operator
merge, with-reduction, relative-clause
cue-word conj. because, cue-word conj. since, cue-word conj. while,
cue-word conj. and, cue-word conj.
cue-word insert. however, cue-word insert. hand
period

Probability
0.80
0.10
0.09
0.01

Figure 14: Probability distribution aggregation operators. final operation randomly chosen selected set uniform distribution.

feature sets tested training SPR. example, label root tree
Figure 15 (CW-SINCE-NS-justify) specifies cw-conjunction operation
used, since cue word, nucleus first (NS), realize justify relation.
Similarly, bottom left-most interior node (WITH-NS-infer) indicates withreduction operation used, nucleus satellite (NS), realize
infer relation.
Figure 17 shows d-tree content plan Figure 4. d-tree shows
SPG treats period operation part lexico-structural representation
d-tree. d-tree split multiple d-trees nodes sent RealPro
surface realization.
Note tp-tree different realizations, depending operations
SPG. example, tp-tree Figure 9 yields Alt 6 Alt 2 Figure 1. Alt
CWSINCENSjustify

assertreco
best

CWCONJUNCTIONinfer

WITHNSinfer

assertreco
cuisine

CWCONJUNCTIONinfer

assertreco assertreco
service
price

assertreco
foodquality

Figure 15: Sentence Plan Tree (SP-tree) Alternative 6 Figure 1.

428

fiIndividual Domain Adaptation Dialogue

PERIODjustify

assertreco
best

PERIODinfer

WITHNSinfer

assertreco
foodquality

PERIODinfer

assertreco
cuisine

assertreco
service

assertreco
price

Figure 16: Sentence Plan Tree (SP-tree) Alternative 8 Figure 1.
PERIOD_justify

HAVE1
PERIOD_infer
Champen_Thai

PERIOD_infer

Champen_Thai
Champen_Thai

restaurant

best

service



dollar
price

quality

good

restaurant

BE3

good
Thai

overall

AMONG1

selected

HAVE1

BE3

quality

24

Champen_Thais

food

Figure 17: Dependency tree alternative 8 Figure 1.
2 highly rated, average human rating 4. However, Alt 6 poor realization
plan, average human rating 2.5.
summarize, SPaRKys SPG transforms input content plan set alternative
pairs sentence-plan trees d-trees. First, assertions input content plan
grouped using principles centering theory. Second, assertions assigned sentences
discourse cues inserted using clause combining operations. Third, decisions
realization referring expressions made basis recency. rhetorical relations
clause-combining operations domain-independent.
SPaRKy uses two types domain-dependent knowledge: probability distribution
clause-combining operations, d-trees input RealPro surface
realizer. order use SPaRKy new domain, might necessary to:
429

fiWalker, Stent, Mairesse, & Prasad

add new rhetorical relations content planner used additional rhetorical relations;
modify probability distribution clause-combining operations, either hand
learning corpus;
construct new set d-trees capture syntactic structure sentences
domain, unless used surface realizer could take logical forms semantic
representations input.

5. Feature Generation
train use SPR, potential realization generated SPG, along
corresponding sp-tree d-tree, encoded set real-valued features (binary features
modeled values 0 1) three feature types:
N-Gram features simple word n-gram features generated realization
SPG outputs;
Concept features concept n-gram features generated named entities
realization SPG outputs;
Tree features features represent structural configurations sp-trees
d-trees output SPG.
features automatically generated described below.
5.1 N-Gram Features
N-gram features capture information lexical selection lexical ordering realizations output SPaRKy. two-step approach used generate features. First,
domain-specific rule-based named-entity tagger (using MATCHs lexicons restaurant,
cuisine type location names) replaces specific tokens types, e.g. Babbo
restname. Then, unigram, bigram trigram features counts automatically
generated. tokens begin end indicate beginning end realization.
N-gram feature names prefixed n-gram. example, ngram-cuisinenamerestaurant-with counts occurrences cuisine type followed restaurant
(as realization Italian restaurant with); ngram-begin-restname-which
counts occurrences realizations starting restaurants name followed which.
also count words per presentation, per sentence presentation.
5.2 Concept Features
Concept features capture information concepts selected presentation,
linear order realization. two-step approach used generate features.
First, named-entity tagger marks names items restaurant database, e.g.
Uguale. Then, unigram, bigram trigram features counts automatically
generated sequences concepts sentence plan realization.
n-gram features, tokens begin end indicate beginning end realization.
430

fiIndividual Domain Adaptation Dialogue

Concept feature names prefixed conc. example, conc-decor-claim
set 1 claim expressed directly information decor, feature
conc-begin-service characterizes utterances starting information service.
concept n-gram features, use * separate individual features. also count
concepts per presentation, per sentence presentation.
5.3 Tree Features
Tree features capture declaratively way merge, infer cue-word operations applied tp-trees, inspired parsing features used Collins
(2000). count occurrences certain structural linguistic configurations
sp-trees associated d-trees SPG generated. Tree feature names prefixed
r rule (sp-tree) sentence (d-tree).
Several feature templates used generate tree features. Local feature templates
record structural configurations local particular node (its ancestors, daughters etc.);
global feature templates, used sp-tree features, record properties entire sp-tree.
four types local feature template: traversal features, sister features, ancestor
features leaf features. Traversal, sister ancestor features generated nodes
sp-trees d-trees; leaf features generated sp-trees only. value
feature count described configuration tree. discard features
occur fewer 10 times avoid specific particular content plans.
node tree, traversal features record preorder traversal
subtree rooted node, subtrees depths. Feature names concatenation prefix trav-, names nodes (starting current
node) traversal path. * used separate node names. example r-travwith-ns-infer*assert-reco-food-quality*assert-reco-cuisine (with value 1)
bottom-left subtree Figure 16.
Sister features record consecutive sister nodes. Names concatenation
prefix sis-, names sister nodes. example r-sis-assert-recobest*cw-conjunction-infer (with value 1) tree Figure 15.
node tree, ancestor features record initial subpaths path
node root. Feature names concatenation prefix anc-
names nodes (starting current node). example r-anc-assert-recocuisine*with-ns-infer*cw-conjunction-infer (with value 1) tree Figure 15.
Leaf features record initial substrings frontier sp-tree. Names
concatenation prefix leaf-, names frontier nodes (starting
current node). example, sp-tree Figure 15 value 1 leaf-assert-recobest also leaf-assert-reco-best*leaf-assert-reco-cuisine, sp-tree
Figure 16 value 1 leaf-assert-reco-food-quality*assert-reco-cuisine.
Global features apply sp-tree. record, sp-tree
operation labeling non-frontier node, (1) minimal number leaves dominated
node labeled rule tree (MIN); (2) maximal number leaves dominated
node labeled rule (MAX); (3) average number leaves dominated
node labeled rule (AVG). example, sp-tree Figure 15 value
431

fiWalker, Stent, Mairesse, & Prasad

4 cw-conjunction-infer-max, value 2 cw-conjunction-infer-min value 3
cw-conjunction-infer-avg.

6. Training Sentence Plan Ranker
SPR ranks alternative information presentations using model learned user ratings set training data. training procedure follows:
content plan training data, SPG generates set alternative
sentence plans using random selection sentence planning operators (Section 4);
Features automatically generated surface realizations sentence plans
alternative sentence plan represented terms number realvalued features (Section 5);
Feedback perceived quality realization alternative sentence
plan collected one users;
RankBoost boosting method (Freund, Iyer, Schapire, & Singer, 1998) learns
function featural representation realization feedback,
attempts duplicate rankings training examples.
use RankBoost three reasons. First, produces ranking input alternatives rather selection one best alternative. Second, handle many sparse
features. Third, function learns rule-based model showing effect
feature ranking competing examples. models inspected
compared. allows us qualitatively analyze models (Section 8) order
understand preferences individuals, differences SPRs individuals
vs. groups.
section describes training SPR detail. SPUR content planner
produces content plans three dialogue strategies:
recommend: recommend entity set entities
compare-2: compare two entities
compare-3: compare three entities
dialogue strategy, start set 30 representative content plans
SPUR. SPG parameterized produced 20 distinct (sp-tree, d-tree) pairs
content plan. realized RealPro. Separately, also obtained
output content plan template-based generator (Section 3.2).
SPaRKy realizations template-based realizations randomly ordered placed series Web pages. 1830 realizations rated
scale 1 5 first two authors paper, neither implemented
template-based realizer SPG. raters worked rating task sessions one hour time several hours day, period week.
instructed look 21 realizations particular content plan rating
them, try use whole rating scale, indicate spontaneous rating without
432

fiIndividual Domain Adaptation Dialogue

repeatedly re-labelling alternative realizations. discuss ratings
basis ratings time. Given cognitive load long duration
rating task, impossible raters keep track realizations came
SPaRKy template-based generator, likely impossible
generate gestalt evaluation alternative.
(sp-tree, d-tree, realization) triple example input RankBoost; ratings
used feedback. experiments examine two uses ratings. First,
train test SPR average ratings two users, i.e. consider
two users representing single user group. Second, train test individualized
SPRs, one user.
SPR trained using RankBoost algorithm (Freund, Iyer, Schapire, & Singer,
1998), describe briefly here. First, training corpus converted set
ordered pairs examples x, y:
= {(x, y)| x, alternatives plan,
x preferred user ratings}
alternative realization x represented set indicator functions hs (x)
1 m. indicator functions calculated thresholding feature values
(counts) described Section 5. example, one indicator function is:
h100 (x) =



1 leaf-assert-reco-best(x) 1
0 otherwise

h100 (x) = 1 leftmost leaf assertion claim Figure 15. single
parameter associated indicator function, ranking score
example x calculated
X
hs (x)
F (x) =


score used rank competing sp-trees content plan goal
duplicating ranking found training data. Training process setting
parameters minimize following loss function:
RankLoss =

1 X
eval(F (x) F (y))
|T | (x,y)T

eval function returns 1 ranking scores (x, y) pair misordered (so x
ranked higher even though training data ranked higher x), 0
otherwise. words, RankLoss percentage misordered pairs. loss
function minimized, ranking errors (cases ranking scores disagree human
judgments) reduced. Initially parameter values set zero. optimization
method greedily picks single parameter time parameter make
impact loss function updates parameter value minimize
loss.
experiments described below, use two evaluation metrics:
433

fiWalker, Stent, Mairesse, & Prasad

RankLoss: value training methods loss function;
TopRank: difference human rating top realization
content plan human rating realization SPR predicts
top ranked.

7. Quantitative Results
section, describe three experiments SPaRKy:
1. Feature sets trainable sentence planning: examine features (ngram, concept, tree, all) lead best performance sentence planning task,
find n-gram features sometimes perform well features.
2. Comparison template-based generation: show performance
trainable sentence planner using best performing feature set consistent
template-based generator, although overall template-based generator
still performs better.
3. Individualized sentence planners: show people quite specific individual preferences regarding three tasks sentence planning: information ordering, sentence aggregation, use discourse cues; furthermore, trainable
sentence planner model individual preferences. Moreover show
cases individualized sentence planners better than, statistically indistinguishable from, template-based generator.
report results separately comparisons two entities among three
entities. two types comparison generated using different strategies
SPG, produce text different terms length structure.
7.1 Feature Sets Trainable Sentence Planning
Using cross-validation methodology, repeatedly train SPR random 90%
corpus, test remaining 10%. Here, use averaged feedback user
user B feedback. Figure 18 repeats examples Figure 1, showing
user rankings rankings ranking function learned trained
SPRs users B AVG user.
Table 1 shows RankLoss feature set (Section 5). Paired t-tests comparing
ranking loss different feature sets show surprisingly performance differences among
features. Using features (All) always produces best results, differences
always significant.
n-gram features give results comparable features compare-2
recommend. analysis learned models suggests one reason ngram features perform well individual lexical items uniquely
associated many combination operators, lexical item
with-ns operator. means detailed representations content structure
information presentation represented tree features equivalent n-gram
features application domain.
434

fiIndividual Domain Adaptation Dialogue

Alt Realization
6
Chanpen Thai best overall quality among selected restaurants since Thai restaurant, good
service, price 24 dollars, good food quality.
7
Chanpen Thai best overall quality among selected restaurants good service, good
food quality, Thai restaurant, price 24
dollars.
4
Chanpen Thai best overall quality among selected restaurants. good food quality, good
service, Thai restaurant, price 24 dollars.
9
Chanpen Thai Thai restaurant, good food quality,
price 24 dollars, good service.
best overall quality among selected restaurants.
5
Chanpen Thai best overall quality among selected restaurants. good service. good food
quality. price 24 dollars, Thai restaurant.
3
Chanpen Thai best overall quality among selected restaurants. price 24 dollars. Thai
restaurant, good service. good food quality.
10 Chanpen Thai best overall quality among selected restaurants. good food quality. price 24
dollars. Thai restaurant, good service.
2
Chanpen Thai best overall quality among selected restaurants. price 24 dollars, Thai
restaurant. good food quality good service.
1
Chanpen Thai best overall quality among selected restaurants. Thai restaurant good food
quality. price 24 dollars, good service.
8
Chanpen Thai Thai restaurant, good food quality.
good service. price 24 dollars. best
overall quality among selected restaurants.


1

B
4

SPRA
0.16

SPRB
0.65

SPRAV G
0.58

2

5

0.38

0.54

0.42

2

4

0.53

0.62

0.53

2

4

0.47

0.53

0.63

3

2

0.59

0.32

0.46

3

3

0.64

0.40

0.62

3

3

0.67

0.46

0.58

4

4

0.75

0.50

0.74

4

3

0.64

0.52

0.45

4

2

0.81

0.29

0.73

Figure 18: alternative realizations content plan Figure 4, feedback
users B (1=worst 5=best) rankings trained SPRs
users B mean(A,B) ([0, 1]).

concept features always perform worse features, indicating
linear ordering concepts accounts variation rating feedback.
two types comparison, performance using concept features approaches
feature sets. However, recommendations, performance using concept features
much worse using n-gram features features. qualitative analysis
presented Section 8, discuss aspects models recommendations
might account large difference performance.
Table 2 shows results features using TopRank evaluation metric, calculated two-fold cross-validation, comparable previous work (Walker, Rambow,
& Rogati, 2002; Stent, Prasad, & Walker, 2004).6 evaluated SPaRKy test sets
comparing three data points content plan: Human (the score best sentence
plan SPaRKys SPG produce selected human users); SPaRKy (the
score SPRs top-ranked selected sentence); Random (the score sentence plan
6. TopRank metric sensitive distribution ranking feedback SPR scores test set,
means sensitive number cross-validation folds.

435

fiWalker, Stent, Mairesse, & Prasad

Feature set/Strategy
Random Baseline
Concept
N-Gram
Tree


compare-2
0.50
0.16 (p < .000)
0.14 (p < .161)
0.14 (p < .087)
0.13

compare-3
0.50
0.16 (p < .021)
0.15 (p < .035)
0.16 (p < .007)
0.14

recommend
0.50
0.32 (p < .000)
0.21 (p < .197)
0.22 (p < .001)
0.20

Table 1: AVG models ranking error different feature sets, strategies. Results
averaged 10-fold cross-validation, testing mean feedback. p values
parentheses indicate level significance decrease accuracy
compared model using features. Cases different feature sets
perform well features marked bold.

randomly selected alternative sentence plans). three presentation types,
paired t-test comparing SPaRKy Human Random showed SPaRKy significantly better Random (df = 59, p < .001) significantly worse Human
(df = 59, p < .001). difference SPaRKy scores Human scores
indicates much performance could improved SPR perfect replicating
Human ratings.
User
AVG
AVG
AVG

Strategy
recommend
compare-2
compare-3

SPaRKy
3.6 (0.77)
4.0 (0.66)
3.6 (0.68)

Human
3.9 (0.55)
4.4 (0.54)
4.0 (0.49)

Random
2.8 (0.81)
2.8 (1.30)
2.7 (1.20)

Table 2: TopRank scores recommend, compare-2 compare-3 (N = 180), using
features, SPaRKy trained AVG feedback, standard deviations.

7.2 Comparison Template Generation
User
AVG
AVG
AVG

Strategy
recommend
compare-2
compare-3

SPaRKy
3.6 (0.59)
3.9 (0.52)
3.4 (0.38)

Human
4.4 (0.37)
4.6 (0.39)
4.6 (0.35)

Template
4.2 (0.74)
3.6 (0.75)
4.1 (1.23)

Table 3: TopRank scores MATCHs template-based generator, SPaRKy(AVG)
Human. N = 180, standard deviations.

436

fiIndividual Domain Adaptation Dialogue

described above, raters also rated single output template-based generator MATCH content plan training data. Table 3 shows mean
TopRank scores template-based generators output (Template), compared
best plan trained SPR selects (SPaRKy), best plan selected human
oracle (Human). fold, SPaRKy Human oracle select best 10
sentence plans text plan, template-based generator produces single
output single human-rated score. paired t-test comparing Human Template
shows significant differences recommend compare3, Human significantly better compare-2 (df = 29, = 4.8, p < .001).
users evidently like compare-2 template. paired t-test comparing SPaRKy
Template shows template-based generator significantly better recommend compare-3 (df = 29, = 2.1, p < .05), trend SPaRKy
better compare-2 (df = 29, = 2.0, p = .055).
Also, standard deviation Template strategies wider Human SPaRKy,
indicating template-based generator performs well overall, performs poorly
inputs. One reason might SPURs decision-theoretic user model
selects wide range number content items different users, conciseness
settings (See Figures 5 7). means difficult handcraft template-based
generator handle different cases well.
gap Human scores (produced SPG selected human
rather SPR) Template scores shows SPG produces sentence
plans good template-based generator, accuracy SPR needs
improved. Below, Section 7.3 shows SPR trained individuals,
SPaRKys performance indistinguishable template-based generator
cases.
7.3 Comparing Individualized Models Group Models
discussed Section 1 differences rating feedback users B
competing realizations (See Figure 1) suggest user different perceptions
quality potential realizations. quantify utility feasibility training
individualized SPRs, first examine feasibility training models individual users.
results Table 1 based corpus 600 examples, rated user,
may involve much effort users. would like know whether highperforming individualized SPR trained less labelled data. Figure 19 plots
ranking error rates function amount training data. data suggests
error rates around 0.20 could acquired much smaller training set, i.e.
training set around 120 examples, certainly feasible.
recommend
test data
Bs test data
AVGs test data

model
0.17
0.52
0.31

Bs model
0.52
0.17
0.31

AVG model
0.29
0.27
0.20

Table 4: Ranking error various configurations recommend strategy.
437

fiWalker, Stent, Mairesse, & Prasad

0.45
User
User B
0.4

Average test error

0.35

0.3

0.25

0.2

0.15
0

50

100

150

200

250

300

Number sentences training set

Figure 19: Variation testing error users function number
training utterances.

compare-2
test data
Bs test data
AVGs test data

model
0.16
0.23
0.17

Bs model
0.26
0.11
0.16

AVG model
0.20
0.13
0.13

Table 5: Ranking error various configurations compare-2 strategy.

compare-3
test data
Bs test data
AVGs test data

model
0.13
0.26
0.17

Bs model
0.30
0.14
0.20

AVG model
0.18
0.18
0.14

Table 6: Ranking error various configurations compare-3 strategy.
examine trained individualized SPRs accurate. results Tables 4, 5
6 show RankLoss several training testing configurations strategy (using
10-fold cross-validation). compare two individualized models models trained
Bs mean feedback (AVG). model, test test data,
test data models. shows well model might fit customizing
SPR new domain user group. example, train model recommendations
438

fiIndividual Domain Adaptation Dialogue

using feedback group users, deploy system individual user,
might expect model fit differences similar Table 4.
course, may strongly conflicting preferences group users.
example, consider differences ratings users B average ratings
Figure 1. Alt-1 Alt-7 equivalent using average feedback, user dislikes
Alt-7 likes Alt-1 vice versa user B. Column 3 Table 4 shows average
model, used SPR user user B much higher ranking error (.29
.27 respectively) SPR customized user (.17 error) customized
user B (.17 error).
examination Tables 4, 5 6 shows general, striking differences
models trained tested one individuals feedback (RankLoss ranges 0.11
0.17) cross-tested models (RankLoss ranges 0.13 0.52). Also, average
(AVG) models always perform poorly users B individually-tailored
models. baseline comparison, model ranking sentence alternatives randomly
produces error rate 0.5 average; Table 4 shows models trained one users
data tested others perform badly random model baseline.
suggests differences users ratings random noise.
cases, average model also performs significantly worse individual
models even tested feedback average user (the diagonal Tables 4, 5
6). suggests cases harder get good model average
user case, possibly feedback inconsistent. recommendations,
performance individual model significantly better average model (df = 9,
= 2.6, p < .02). compare-2 average model better user (df = 9, = 2.3,
p < .05), user Bs model better average model (df = 9, = 3.1, p < .01).
User



B
B
B

Strategy
recommend
compare-2
compare-3
recommend
compare-2
compare-3

SPaRKy
3.5 (0.87)
3.8 (0.98)
3.1 (1.02)
4.4 (0.70)
4.4 (0.69)
4.4 (0.62)

Human
3.9 (0.61)
4.3 (0.73)
3.6 (0.80)
4.7 (0.46)
4.7 (0.53)
4.8 (0.40)

Template
3.9 (1.05)
4.2 (0.64)
3.9 (1.19)
4.5 (0.76)
3.1 (1.21)
4.2 (1.34)

Table 7: TopRank scores Individualized SPaRKy compared MATCHs
template-based generator rated separately Users B, individual
User User B Human Oracles. Standard Deviations parentheses. N =
180.

also compare template-based generator individualized SPaRKy generators using TopRank metric (See Table 7). comparisons done paired
t-tests using Bonferroni adjustment multiple comparisons.
recommend, significant differences SPaRKy Template
User (df = 59, = 2.3, p = .07), User B (df = 59, = 1.6, p = .3).
439

fiWalker, Stent, Mairesse, & Prasad

also significant differences either user Template Human (df = 59,
< 1.5, p > 0.4).
compare-2, large differences Users B. User appears
like template compare-2 (average rating 4.2) User B (average rating 3.1). User A, significant differences SPaRKy Template
(df = 59, = 2.3, p = .07), Template Human (df = 59, = 0.1, p = .09),
User B strongly prefers SPaRKy Template (df = 59, = 7.7, p < .001).
compare-3, also large differences Users B. User likes
template compare-3 (average rating 3.9), strongly prefers individualized
SPaRKy (average rating 3.1) (df = 59, = 3.4, p < .004). User B also likes template
(average rating 4.2), significant differences SPaRKy (average rating
4.4) (df = 59, = 1.0, p = .95).
users, every strategy, even individually trained SPRs, still
significant gap SPaRKy Human scores, indicating performance
SPR could improved (df = 59, = 3.0, p < .006).
results demonstrate trainable sentence planning produce output comparable better template-based generator, less programming effort
flexibility.

8. Qualitative Analysis
important aspect RankBoost learned models expressed rules: qualitative examination learned models may highlight individual differences linguistic
preferences, help us understand SPaRKys SPG produce sentence plans
better produced template-based generator, individually
trained SPRs usually select sentence plans good templates. qualitatively compare learned ranking models individualized SPRs, assess
linguistic aspects utterance (which features) important individual,
important are. evaluate whether individual oriented towards particular
feature examining features indicator functions hs (x) non-zero values.
evaluate important feature individual examining magnitude
parameters .
two potential problems approach, first problem
feature templates produce thousands features, redundant,
differences models indicator functions spurious. Therefore, allow
meaningful qualitative comparisons models, one pair perfectly correlated
features eliminated.
second problem arises RankBoosts greedy algorithm. selection
parameter set round boosting highly dependent training set,
models derived single episode training highly variable. compare
indicator functions independently training set, adopt bootstrapping method
identify feature set user independent particular training episode.
repeatedly randomly selecting 10 alternatives training 10 testing content
plan, created 50 different training sets user. average values
features selected RankBoost 50 training runs, conduct experiments using
440

fiIndividual Domain Adaptation Dialogue

Model
AVG



B

Strategy
recommend
compare-2
compare-3
recommend
compare-2
compare-3
recommend
compare-2
compare-3

Tree
45
37
63
50
35
47
47
45
47

Feature Type
N-Gram Concept Leaf
36
9
7
46
12
1
29
4
1
29
14
4
51
10
3
37
11
1
34
9
6
36
13
1
34
9
6

Global
3
4
3
3
1
4
4
5
4

Table 8: Features top 100 highest average user model.
100 features user highest average magnitude. Section 8.1
discuss differences types feature selected bootsrapping algorithm
outlined. Section 8.2 discusses differences models produced using tree features
user user B, section 8.3 discusses differences average model
individual models.
8.1 Types Bootstrapped Features
bootstrapping process selects total 100 features strategy
type feedback (individual averaged). found differences features along
dimensions.
Table 8 shows number features type top 100 (averaged
50 training runs). 9 features shared three strategies AVG
model; shared features usually n-gram features. User A, 6 features shared
three strategies (mostly n-gram features). User B, features shared
three strategies.
also found features capture specific interactions domain-specific
content items syntactic structure, difficult model rule-based
template-based generator. example Rule (1) Figure 20 significantly lowers ranking sentence plan neighborhood information (assert-reconbhd) combined subsequent content items via with-ns operation. Among
bootstrapped features average user, 16 features compare-2 count interactions
domain-specific content syntactic structure. compare-3, 22 features count
interactions, bootstrapped features recommend include 39 features.
examine models derived features detail below.
8.2 Differences Individual Models
analyze individual linguistic preferences information presentation strategies, qualitatively compare two models Users B. believe
qualitative analysis provides additional evidence differences users ranking
preferences random noise. identify differences among features selected
441

fiWalker, Stent, Mairesse, & Prasad

N
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28

Condition
r-anc-assert-reco-nbhd*with-ns-infer 1
cw-conjunction-infer-avg-leaves-under 3.1
r-anc-assert-reco*with-ns-infer*cw-conjunction-infer 1
leaf-assert-reco-best*assert-reco-price 1
cw-conjunction-infer-avg-leaves-under 2.8
r-trav-with-ns-infer*assert*assert 1
r-anc-cw-conjunction-infer*cw-conjunction-infer 1
with-ns-infer-min-leaves-under 1
r-anc-assert-reco*with-ns-infer 1
cw-conjunction-infer-max-leaves-under 3.5
r-trav-with-ns-infer*assert-reco*assert-reco 1
r-anc-assert*with-ns-infer 1
r-anc-with-ns-infer*relative-clause-infer 1
r-anc-assert*with-ns-infer*relative-clause-infer 1
cw-conjunction-infer-avg-leaves-under 4.1
r-anc-assert-reco-cuisine*with-ns-infer*period-infer 1
cw-conjunction-infer-avg-leaves-under 2.2
r-anc-assert-reco-food-quality*merge-infer 1
r-anc-assert-reco*merge-infer 2.5
r-anc-assert-reco-decor*merge-infer 1
r-anc-assert*merge-infer 2.5
r-trav-merge-infer 1.5
r-trav-with-ns-infer*assert-reco-service*assert-reco-food-quality
1
leaf-assert-reco-food-quality*assert-reco-cuisine 1
cw-conjunction-infer-avg-leaves-under 3.8
leaf-assert-reco-food-quality 1
s-trav-have1*propernoun-restaurant*II-quality*attr-among1 1
s-anc-attr-with*have1 1


-1.26
-0.58
-0.33
-0.29
-0.27
-0.22
-0.17
-0.13
-0.11
-0.07
-0.07
-0.03
-0.01
-0.01
-0.01
0.10
0.15
0.18
0.20
0.22
0.25
0.27
0.40
0.46
0.46
0.60
0.68
0.71

Figure 20: subset rules corresponding values User model, ordered .
RankBoost, values, using models derived using bootstrapping tree features only, since easier interpret qualitatively. course many different models
possible. User model consists 109 rules; subset Figure 20. User Bs
model consists 90 rules, subset shown Figure 21. first consider
individual models account rating differences Alt-6 Alt-8 Figure 1 (repeated Figure 18 ratings trained SPRs), discuss
differences.
Comparing Alt-6 Alt-8: Alt-6 highly ranked User B User A.
Alt-6 instantiates Rule 21 Figure 21, expressing User Bs preferences linear order
content. (Alt-6s sp-tree Figure 15.) Rule 21 increases rating examples
claim, i.e. assert-reco-best (Chanpen Thai best overall quality),
realized first. Thus, unlike user A, user B prefers claim beginning utterance
(the ordering claim left unspecified argumentation theory (Carenini & Moore,
2000)). Rule 22 increases rating examples initial claim immediately
442

fiIndividual Domain Adaptation Dialogue

N
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24

Condition
r-sis-assert-reco-relative-clause-infer 1
r-sis-period-infer-assert-reco 1
r-anc-assert-reco-nbhd*with-ns-infer 1
r-anc-assert-reco*period-infer*period-infer 1.5
r-anc-assert-reco-food-quality*with-ns-infer*relative-clause-infer 1
r-anc-assert-reco-cuisine*with-ns-infer*relative-clause-infer 1
r-anc-assert-reco*period-infer 1
leaf-assert-reco-price 1
r-anc-assert*period-infer*period-infer 1.5
leaf-assert-reco-decor 1
r-anc-assert*relative-clause-infer*period-infer 1.5
r-trav-relative-clause-infer*assert-reco*with-ns-infer 1
cw-conjunction-infer-avg-leaves-under 3.1
cw-conjunction-infer-avg-leaves-under 3.3
cw-conjunction-infer-avg-leaves-under 2.2
r-anc-assert*relative-clause-infer*period-infer 1
leaf-assert-reco-service 1
s-trav-attr-with 1
r-anc-assert-reco-cuisine*with-ns-infer*cw-conjunction-infer 1
cw-conjunction-infer-avg-leaves-under 3.6
leaf-assert-reco-best 1
leaf-assert-reco-best*assert-reco-cuisine 1
cw-conjunction-infer-avg-leaves-under 2.8
r-trav-with-ns-infer*assert-reco-cuisine*assert-reco-food-quality 1


-1.01
-0.71
-0.50
-0.49
-0.41
-0.39
-0.35
-0.32
-0.26
-0.14
-0.07
-0.05
-0.03
-0.03
-0.01
0.03
0.07
0.18
0.27
0.36
0.47
0.50
0.52
0.76

Figure 21: subset rules corresponding values User Bs model, ordered .
followed type cuisine (assert-reco-cuisine). rules interact Rule 19
Figure 21, specifies preference information following assert-reco-cuisine
combined via with-ns operation, conjoined (cw-conjunction-infer)
additional evidence. Alt-6 also instantiates Rule 23 User Bs model, value
.52 associated multiple uses cw-conjunction-infer operation.
User low rating Alt-6 arises dislike with-ns operation (Rules 3,
8, 9, 11 12) cw-conjunction-infer operation (Rules 3, 5, 7, 10 15)
Figure 20. (Contrast User Bs Rule 23 User Rules 5 17.) Alt-6 also fails
instantiate preference food quality cuisine information occur first (Rules 24
26). Finally, user also prefers claim assert-reco-best realized
sentence (Rule 27).
contrast, Alt-8 rated highly User User B (see Figure 1). Even
though Alt-8 instantiates negatively evaluated with-ns operation (Rules 3, 8, 9 11
Figure 20), instances cw-conjunction-infer (Rules 3, 5, 7, 10 15).
Moreover Alt-8 follows ordering preferences (Rules 24 26) describe sp-trees
assert-reco-food-quality left frontier, trees followed
assert-reco-cuisine. (See Alt-8s sp-tree Figure 16.) Rule 27 also increases rating
Alt-8 large positive reflecting expression claim sentence.
443

fiWalker, Stent, Mairesse, & Prasad

hand, Alt-8 rated poorly User B; violates Bs preferences
linear order (remember Rules 21 22 specify B prefers claim first, followed
cuisine information). Also, Bs model rules radically decrease ranking
examples using period-infer operation (Rules 2, 4, 7 9).
Thus, Alt-6 Alt-8 show users B prefer different combination operators,
different ordering content, e.g. B likes claim first likes recommendations
food quality first followed cuisine. mentioned above, previous work
generation evaluative arguments states claim may appear first last (Carenini
& Moore, 2000). relevant guideline producing effective evaluative arguments states
placing main claim first helps users follow line reasoning, delaying
claim end argument also effective user likely disagree
claim. template-based generator MATCH always placed claim first,
analysis suggests may effective user A.
similarities differences: also individual differences preferences particular operations, specific content operation interactions. example,
User model demotes examples with-ns operation applied (Rules
3, 6 8 Figure 20), User B generally likes examples with-ns
used (Rule 18 Figure 21). However, neither B like with-ns used combine
content neighborhood information. User model value -1.26,
User Bs model value -0.50 (see Rule 1 Figure 20 Rule 3 Figure 21.)
rules capture specific interaction sp-tree domain-specific content
with-ns-infer combination operation. Utterances instantiating rules place
information adjunctival with-clause following clause realizing restaurants
neighborhood. constraint type information with-clause.
utterance (1) below, with-clause realizes restaurants food quality, whereas (2)
contains information restaurants service.
(1) Mont Blanc good service, price 34 dollars, located Midtown
West, good food quality. best overall quality among selected
restaurants.
(2) Mont Blanc located Midtown West, good service, price 34 dollars,
good food quality. best overall quality among selected
restaurants.
Moreover, users like with-ns combines cuisine food-quality information example (3) (Rule 23 Figure 20 Rule 24 Figure 21).
(3) Komodo best overall quality among selected restaurants since
Japanese, Latin American restaurant, good food quality, good
service, price 29 dollars.
User B radically reduces rating cuisine, food-quality combination
combined information using relative-clause-infer operation,
example (5) (Rules 5 6 Figure 21).
444

fiIndividual Domain Adaptation Dialogue

(4) Bond Street good decor. Japanese, Sushi restaurant, excellent
food quality, good service. best overall quality among selected
restaurants.
Example (4) interesting contrast example (3). Example (4) instantiates Rule
24 Figure 21, also instantiates number negatively valued features. discussed
above, User B prefers examples claim expressed first (Rule 21 Figure 21),
User Bs model explicitly reduces rating examples information decor
expressed first (Rule 10 Figure 21).
general, User likes merge-infer operation (Rules 19, 21 22), especially applied assert-reco-food-quality (Rule 18), assert-reco-decor
(Rule 20). User strongly prefers hear food quality first (Rule 26 Figure 20),
followed cuisine information (Rule 24). contrast, User B rules reduce
rating examples price decor first (Rules 8 10 Figure 21). User B also
preferences merge-infer likes cw-conjunction operation (Rule 20
Figure 21). Finally, User B dislikes relative-clause-infer operation general
(Rule 1), combination with-ns operation (Rule 12) period-infer
operation (Rule 11).
addition evidence discussed individual differences language
generation, believe fact model differences interpretable shows
differences user perception quality system utterances true individual
differences, random noise.
8.3 Average Model Differences
Table 22 shows subset rules largest magnitudes example
AVG model using 100 feature bootstrapping process described above. Section 8.2
presented results average model performs statistically worse recommendations
either individual models. may due fact average model
essentially trying learn contradictory feedback two users. see whether
examination models provides support hypothesis, first examine
learned model ranks Alt-6 Alt-8 shown Figure 18 column SPRAV G .
average feedback Alt-6 2.5 average feedback Alt-8 3, trained
SPR ranks Alt-8 second highest Alt-6 fifth 10.
mid-value ranking Alt-6 arises number interacting rules,
similar User Bs similar User As. Alt-6 instantiates Rules
26 27 Figure 22 increase ranking sentence plans claim,
i.e. assert-reco-best realized first, sentence plans claim immediately
followed information type cuisine (assert-reco-cuisine). rules
identical Bs Rules 21 22 Figure 21. Rule 18 additionally increases ranking
sentence plans cuisine information followed service information, applies
Alt-6 increase ranking. However Rule 3 lowers ranking Alt-6, since
combines 3 different assertions single DSyntS tree.
Alt-8 highly ranked SPRAV G , largely result several rules increase
ranking. Rule 31 specifies increase ranking sentence plans claim
sentence, true Alt-8 Alt-6. rule also appears Rule 27
445

fiWalker, Stent, Mairesse, & Prasad

N
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31

Condition
s-anc-attr-with*locate
s-trav-have1*i-restaurant*cuisine-type*ii-quality*attr-good*attrfood
s-trav-propernoun-restaurant 2.5
r-anc-cw-conjunction-infer*cw-conjunction-infer*period-justify
r-sis-assert-reco-relative-clause-infer
r-anc-assert-reco-decor*with-ns-infer*period-infer*period-justify

r-anc-assert-reco-cuisine*with-ns-infer*relative-clause-infer
period-justify-avg-leaves-under 5.5
cw-conjunction-infer-avg-leaves-under 3.1
r-anc-assert-reco-nbhd*with-ns-infer
r-sis-cw-conjunction-infer-relative-clause-infer
period-infer-avg-leaves-under 3.4
r-anc-assert-reco-food-quality*merge-infer
s-trav-propernoun-restaurant 5.5
r-anc-assert-reco-decor*merge-infer
s-anc-attr-with*i-restaurant*have1
r-anc-assert-reco-decor*with-ns-infer
leaf-assert-reco-best*assert-reco-cuisine*assert-reco-service
s-trav-propernoun-restaurant 3.5
r-anc-assert-reco-cuisine*with-ns-infer*period-infer*period-justify

leaf-assert-reco-food-quality
period-infer-avg-leaves-under 3.2
r-sis-merge-infer-assert-reco
period-justify-avg-leaves-under 6.5
s-anc-attr-with*have1
leaf-assert-reco-best*assert-reco-cuisine
leaf-assert-reco-best
merge-infer-max-leaves-under
leaf-assert-reco-food-quality*assert-reco-cuisine
merge-infer-max-leaves-under 2.5
s-trav-have1*propernoun-restaurant*ii-quality*attr-among1


-0.87
-0.81
-0.81
-0.77
-0.74
-0.62
-0.62
-0.60
-0.54
-0.45
-0.40
0.14
0.15
0.19
0.19
0.22
0.26
0.26
0.29
0.29
0.32
0.36
0.42
0.48
0.49
0.50
0.50
0.51
0.77
0.96
0.97

Figure 22: subset rules largest magnitudes learned ranking
recommendations given AVG feedback.

model Figure 20. Alt-8 also instantiates Rules 21 29 identical
user ordering preferences (Rules 24 26 Figure 20) rules describe sptrees assert-reco-food-quality left frontier, trees followed
assert-reco-cuisine. (See Alt-8s sp-tree Figure 16.) Rule 3 also applies Alt-8,
reducing ranking due number content items realizes.
similarities differences: many rules average model
similar either Bs models both, average model retains number
446

fiIndividual Domain Adaptation Dialogue

preferences seen individual models. example, Rules 1 10 reduce
ranking sentence plan neighborhood information combined subsequent
information using with-ns combination operator. Rule 1 expresses terms
lexical items d-tree, whereas Rule 10 expresses terms semantic features
derived sp-tree. Examples 1 2 Section 8.2 illustrate interaction.
rules similar User A. example, Rules 4 9 (like Rules
2 5 Figure 20) reduce rating sentence plans use operation cw-conjinfer. addition, Rules 22, 23, 24, 28 expresses preferences merging information,
similar Rules 19, 21 22. Rule 15 expresses preference
information atmosphere (assert-reco-decor) combined using merge
operation, specified Rule 20. Rule 20 Figure 22 also similar Rule 16
assert-reco-cuisine combined subsequent information with-ns operation.
rules similar Bs model. example, Rule 5 reduces ranking
sentence plans using relative clause operation, also specified User Bs
Rule 1, Rules 16 25 indicate general preference use with-ns operation,
strong preference User Bs model (see Bs Rule 18 Figure 21).
Note cases, learned model tries account Bs preferences, even contradict one another. example, Rule 27 specifies preference
claim come first, Bs Rule 21, whereas Rule 26 24, specifying preference food quality cuisine information expressed first. Thus
model suggest reduction performance may arise trying account
contradictory preferences users B.

9. Conclusions
article describes SPaRKy, two-stage sentence planner generates many alternative realizations input content plans ranks using statistical model
trained human feedback. demonstrate training technique developed
SPoT (Walker, Rambow, & Rogati, 2002), generalizes easily new domains,
extended handle rhetorical structures required complex types
information presentation.
One novel contributions paper show trainable generation
used train sentence planners tailored individual users preferences. Previous work modeling individuals mainly applied content planning. studies
human-human dialogue suggest modeling types individual differences could
valuable spoken language generation, past, linguistic variation among individuals
considered problem generation (McKeown, Kukich, & Shaw, 1994; Reiter, 2002;
Reiter, Sripada, & Robertson, 2003). Here, show users different perceptions
quality alternative realizations content plan, individualized models perform better trained groups users. qualitative analysis indicates
trainable sentence generation sensitive variations domain application, presentation
type, individual human preferences arrangement particular content types.
first results showing individual preferences apply sentence planning.
also compared SPaRKy template-based generator described Section 3.2:
generator highly tuned domain previously shown produce high
447

fiWalker, Stent, Mairesse, & Prasad

quality outputs user evaluation (Stent, Prasad, & Walker, 2004). SPaRKy
trained group users, template-based generation better recommend
compare-3, cases performance individualized SPRs statistically
indistinguishable MATCHs template-based generator: exceptions that,
compare-2, User B prefers SPaRKy, compare-3 User prefers templatebased generator. cases, Human scores (outputs produced SPG selected
human) good better template-based generator, even complex
information presentations extended comparisons.
results show gap performance trained SPR
human performance. suggests might possible improve SPR
different feature sets different ranking algorithm. leave comparison
ranking algorithms future work. Here, report results many different feature sets
(n-gram, concept tree) investigate effect performance. Table 1 shows
combination three feature sets performs significantly better recommend
compare-3 tree features earlier work (Walker, Rambow, & Rogati, 2002;
Stent, Prasad, & Walker, 2004; Mairesse & Walker, 2005). Interestingly, cases,
simple features like n-grams perform well features representing linguistic structure
tree features. might particular lexical items, e.g. with,
often uniquely associated combination operator, e.g. with-ns operator,
shown impact user perceptions utterance quality (Section 8). work
needed determine whether performance similarities simply due fact
variation form generated SPaRKys SPG limited. work also
examined tradeoffs n-gram features linguistically complex features terms
tradeoffs time accuracy (Pantel, Ravichandran, & Hovy, 2004). Although
SPaRKy trained offline, time compute features rank SPG outputs remains
issue using SPaRKy real-time spoken dialogue system.
potential limitation approach time effort required elicit user
feedback training system, described Section 6. Section 7.3 showed
RankLoss error rates around 0.20 could acquired much smaller training set, i.e.
training set around 120 examples. However typical users would probably want
provide ratings 120 examples. Future work explore alternative training regimes
perhaps utilizing ratings several users. example, could identify examples
distinguish existing users, present examples new users.
Also, instead users rating information presentations using MATCH, perhaps
method users rate information presentations using MATCH could developed,
i.e. course dialogue MATCH recommendation comparison
presented user, system could display screen rating form
presentation. Another approach would train different type user feedback
collected automatically monitoring users behavior, e.g. measures cognitive load
reading time.
Another limitation SPaRKys dictionary handcrafted, i.e. associations
simple assertions syntactic realizations (d-trees) specified hand, like
generators. Recent work begun address limitation investigating techniques
learning generation dictionary automatically different types corpora,
448

fiIndividual Domain Adaptation Dialogue

user reviews (Barzilay & Lee, 2002; Higashinaka, Walker, & Prasad, 2007; Snyder &
Barzilay, 2007).
final limitation use two individuals provide proof-of-concept argument value user-tailored trainable sentence planning. argued throughout
paper individual differences document general, particular
users B, result random noise user feedback. Nevertheless,
hope future work test results larger population individuals
order provide support arguments order characterize full
range individual differences preferences language variation dialogue interaction.

Acknowledgments
work partially funded DARPA Communicator Contract MDA972-99-30003, Royal Society Wolfson Research Merit Award M. Walker, Vice
Chancellors studentship F. Mairesse.

References
Andre, E., Rist, T., van Mulken, S., Klesen, M., & Baldes, S. (2000). Embodied Conversational Agents, chap. automated design believable dialogues animated
presentation teams, pp. 220255. MIT Press.
Bangalore, S., & Rambow, O. (2000). Exploiting probabilistic hierarchical model
generation. Proc. International Conference Computational Linguistics.
Barzilay, R., Elhadad, N., & McKeown, K. R. (2002). Inferring strategies sentence
ordering multidocument news summarization. Journal Artificial Intelligence
Research, 17, 3555.
Barzilay, R., & Lee, L. (2002). Bootstrapping lexical choice via multiple-sequence alignment.
Proc. Conference Empirical Methods Natural Language Processing.
Belz, A. (2005). Corpus-driven generation weather forecasts. Proc. 3rd Corpus Linguistics Conference.
Bouayad-Agha, N., Scott, D., & Power, R. (2000). Integrating content style documents: case study patient information leaflets. Information Design Journal, 9 (2),
161176.
Branigan, H., Pickering, M., & Cleland, A. (2000). Syntactic coordination dialogue.
Cognition, 75, B13B25.
Brennan, S. E., & Clark, H. H. (1996). Conceptual pacts lexical choice conversation.
Journal Experimental Psychology: Learning, Memory Cognition, 22 (6), 1482
1493.
449

fiWalker, Stent, Mairesse, & Prasad

Brennan, S. E., Friedman, M. W., & Pollard, C. J. (1987). centering approach pronouns. Proc. Annual Meeting Association Computational Linguistics.
Brown, P., & Levinson, S. (1987). Politeness: Universals Language Usage. Cambridge University Press.
Bulyko, I., & Ostendorf, M. (2001). Joint prosody prediction unit selection concatenative speech synthesis. Proc. International Conference Acoustic Speech
Signal Processing.
Carenini, G., & Moore, J. D. (2000). strategy generating evaluative arguments.
Proc. International Natural Language Generation Conference.
Carenini, G., & Moore, J. D. (2006). Generating evaluating evaluative arguments.
Artificial Intelligence Journal, 170 (11), 925952.
Chai, J., Hong, P., Zhou, M., & Prasov, Z. (2004). Optimization multimodal interpretation. Proc. Annual Meeting Association Computational Linguistics.
Chu-Carroll, J., & Carberry, S. (1995). Response generation collaborative negotiation.
Proc. Annual Meeting Association Computational Linguistics.
Clark, H. H., & Wilkes-Gibbs, D. (1986). Referring collaborative process. Cognition,
22, 139.
Collins, M. (2000). Discriminative reranking natural language parsing. Proc.
International Conference Machine Learning.
Coulston, R., Oviatt, S., & Darves, C. (2002). Amplitude convergence childrens conversational speech animated personas. Proc. International Spoken Language
Processing Conference.
Danlos, L. (2000). G-TAG: lexicalized formalism text generation inspired tree
adjoining grammar. Abeille, A., & Rambow, O. (Eds.), Tree Adjoining Grammars:
Formalisms, Linguistic Analysis, Processing. CSLI Publications.
Di Eugenio, B., Moore, J. D., & Paolucci, M. (1997). Learning features predict cue
usage. Proc. Annual Meeting Association Computational Linguistics.
DiMarco, C., & Foster, M. E. (1997). automated generation Web documents
tailored individual reader. Proc. AAAI Spring Symposium
Natural Language Processing World Wide Web.
Duboue, P. A., & McKeown, K. R. (2003). Statistical acquisition content selection rules
natural language generation. Proc. Conference Empirical Methods
Natural Language Processing.
450

fiIndividual Domain Adaptation Dialogue

Elhadad, N., Kan, M.-Y., Klavans, J., & McKeown, K. (2005). Customization unified
framework summarizing medical literature. Journal Artificial Intelligence
Medicine, 33 (2), 179198.
Ferguson, S. H., & Kewley-Port, D. (2002). Vowel intelligibility clear conversational
speech normal-hearing hearing-impaired listeners. Journal Acoustical
Society America, 112 (1), 259271.
Fleischman, M., & Hovy, E. (2002). Emotional variation speech-based natural language
generation. Proc. International Natural Language Generation Conference.
Forbes, K., Miltsakaki, E., Prasad, R., Sarkar, A., Joshi, A., & Webber, B. (2003). DLTAG system: Discourse parsing lexicalized tree adjoining grammar. Journal
Logic, Language Information, 12 (3), 261279.
Freund, Y., Iyer, R., Schapire, R., & Singer, Y. (1998).
efficient boosting algorithm combining preferences.
Machine Learning: Proceedings
Fifteenth International Conference.
Extended version available
http://www.research.att.com/ schapire.
Garrod, S., & Anderson, A. (1987). Saying mean dialogue: study conceptual semantic coordination. Cognition, 27, 181218.
Goffman, E. (1981). Forms Talk. University Pennsylvania Press, Philadelphia, Pennsylvania, USA.
Grosz, B. J., Joshi, A. K., & Weinstein, S. (1995). Centering: framework modeling
local coherence discourse. Computational Linguistics, 21 (2), 203225.
Guo, H., & Stent, A. (2005). Trainable adapatable multimedia presentation generation.
Proc. International Conference Multimodal Interfaces. Demo paper.
Gupta, S., Walker, M., & Romano, D. (2007). rude you?: Evaluating politeness
affect interaction. Proc. Second International Conference Affective
Computing Intelligent Interaction.
Gupta, S., & Stent, A. (2005). Automatic evaluation referring expression generation using
corpora. Proc. Workshop Using Corpora Natural Language Generation.
Hardt, D., & Rambow, O. (2001). Generation VP ellipsis: corpus-based approach.
Proc. Annual Meeting Association Computational Linguistics.
Higashinaka, R., Walker, M., & Prasad, R. (2007). unsupervised method learning generation lexicons spoken dialogue systems mining user reviews. ACM
Transactions Speech Language Processing, 4 (4).
Hovy, E. (1987). pragmatic decision criteria generation. Kempen, G. (Ed.),
Natural Language Generation, pp. 317. Martinus Nijhoff.
Isard, A., Brockmann, C., & Oberlander, J. (2006). Individuality alignment generated
dialogues. Proc.of International Natural Language Generation Conference.
451

fiWalker, Stent, Mairesse, & Prasad

Johnston, M., Bangalore, S., Vasireddy, G., Stent, A., Ehlen, P., Walker, M., Whittaker,
S., & Maloor, P. (2002). MATCH: architecture multimodal dialogue systems.
Proc. Annual Meeting Association Computational Linguistics.
Jokinen, K., & Kanto, K. (2004). User expertise modelling adaptivity speech-based
e-mail system. Proc. Annual Meeting Association Computational
Linguistics.
Jordan, P., & Walker, M. (2005). Learning content selection rules generating object
descriptions dialogue. Journal Artificial Intelligence Research, 24, 157194.
Joshi, A. K., Webber, B., & Weischedel, R. M. (1986). aspects default reasoning
interactive discourse. Tech. rep. MS-CIS-86-27, University Pennsylvania.
Joshi, A. K., Webber, B. L., & Weischedel, R. M. (1984). Preventing false inferences.
Proc. International Conference Computational Linguistics.
Jungers, M. K., Palmer, C., & Speer, S. R. (2002). Time time: coordinating
influence tempo music speech. Cognitive Processing, 12, 2135.
Kittredge, R., Korelsky, T., & Rambow, O. (1991). need domain communication
knowledge. Computational Intelligence, 7 (4), 305314.
Kothari, A. (2007). Accented pronouns unusual antecedents: corpus study. Proc.
8th SIGdial Workshop Discourse Dialogue.
Langkilde, I., & Knight, K. (1998). Generation exploits corpus-based statistical knowledge. Proc. International Conference Computational Linguistics
Meeting Association Computational Linguistics.
Langkilde-Geary, I. (2002). empirical verification coverage correctness
general-purpose sentence generator. Proc. International Natural Language
Generation Conference.
Lapata, M. (2003). Probabilistic text structuring: Experiments sentence ordering.
Proc. Annual Meeting Association Computational Linguistics.
Lavoie, B., & Rambow, O. (1997). fast portable realizer text generation systems.
Proc. Conference Applied Natural Language Processing.
Levelt, W. J. M., & Kelter, S. (1982). Surface form memory question answering.
Cognitive Psychology, 14, 78106.
Lin, J. (2006). Using distributional similarity identify individual verb choice. Proc.
International Natural Language Generation Conference.
Litman, D. (1996). Cue phrase classification using machine learning. Journal Artificial
Intelligence Research, 5, 5394.
452

fiIndividual Domain Adaptation Dialogue

Luchok, J. A., & McCroskey, J. C. (1978). effect quality evidence attitude
change source credibility. Southern Speech Communication Journal, 43, 371
383.
Madigan, D., Genkin, A., Lewis, D., Argamon, S., Fradkin, D., & Ye, L. (2005). Author
identification large scale. Proc. Meeting Classification Society
North America.
Mairesse, F., & Walker, M. (2007). PERSONAGE: Personality generation dialogue.
Proc. Annual Meeting Association Computational Linguistics.
Mairesse, F., & Walker, M. (2005). Learning personalize spoken generation dialogue
systems. Proc. Interspeech.
Mann, W., & Thompson, S. (1987). Rhetorical structure theory: Description construction text structures. Kempen, G. (Ed.), Natural Language Generation, pp.
8396. Martinus Nijhoff.
Marciniak, T., & Strube, M. (2004). Classification-based generation using TAG. Proc.
International Natural Language Generation Conference.
Marcu, D. (1996). Building rhetorical structure trees. Proc. Conference
Artificial Intelligence Conference Innovative Applications Artificial Intelligence.
Marcu, D. (1997). local global coherence: bottom-up approach text planning.
Proc. Conference Artificial Intelligence.
McCoy, K. F. (1989). Generating context-sensitive responses object related misconceptions. Artificial Intelligence, 41 (2), 157195.
McKeown, K., Kukich, K., & Shaw, J. (1994). Practical issues automatic document
generation. Proc. Conference Applied Natural Language Processing.
McKeown, K. R. (1985). Discourse strategies generating natural language text. Artificial
Intelligence, 27 (1), 142.
Mellish, C., ODonnell, M., Oberlander, J., & Knott, A. (1998). architecture opportunistic text generation. Proc. Ninth International Workshop Natural
Language Generation.
Melcuk, I. A. (1988). Dependency Syntax: Theory Practice. State University New
York Press, Albany, New York.
Moore, J. D., & Paris, C. L. (1993). Planning text advisory dialogues: Capturing
intentional rhetorical information. Computational Linguistics, 19 (4), 651694.
Moore, J. D., Foster, M. E., Lemon, O., & White, M. (2004). Generating tailored, comparative descriptions spoken dialogue. Proc. Seventeenth International
Florida Artificial Intelligence Research Society Conference.
453

fiWalker, Stent, Mairesse, & Prasad

Nakatsu, C., & White, M. (2006). Learning say well: Reranking realizations
predicted synthesis quality. Proc. Annual Meeting Association
Computational Linguistics.
Nenkova, A., Passonneau, R. J., & McKeown, K. (2007). pyramid method: incorporating human content selection variation summarization evaluation. ACM Transactions Speech Language Processing, 4 (2).
Oberlander, J., & Brew, C. (2000). Stochastic text generation. Philosophical Transactions
Royal Society London, Series A, 358, 13731385.
Paiva, D. S., & Evans, R. (2004). framework stylistically controlled generation.
Proc. International Natural Language Generation Conference.
Pantel, P., Ravichandran, D., & Hovy, E. (2004). Towards terascale knowledge acquisition.
Proc. International Conference Computational Linguistics.
Papenini, K., Roukos, S., Ward, T., & Zhu, W.-J. (2002). Bleu: method automatic
evaluation machine translation. Proc. Annual Meeting Association
Computational Linguistics.
Pennebaker, J. W., & King, L. A. (1999). Linguistic styles: Language use individual
difference. Journal Personality Social Psychology, 77, 12961312.
Piwek, P. (2003). flexible pragmatics-driven language generator animated agents.
Proc. European Meeting Association Computational Linguistics.
Polifroni, J., & Walker, M. (2006). analysis automatic content selection algorithms
spoken dialogue system summaries. Proc. IEEE/ACL Conference
Spoken Language Technology.
Porayska-Pomsta, K., & Mellish, C. (2004). Modelling politeness natural language generation. Proc. International Natural Language Generation Conference.
Prasad, R., Joshi, A., Dinesh, N., Lee, A., & Miltsakaki, E. (2005). Penn Discourse
TreeBank resource natural language generation. Proc. Corpus
Linguistics Workshop Using Corpora Natural Language Generation.
Prevost, S. (1995). Semantics Contrast Information Structure Specifying
Intonation Spoken Language Generation. Ph.D. thesis, University Pennsylvania.
Prince, E. F. (1985). Fancy syntax shared knowledge. Journal Pragmatics, 9 (1),
6581.
Rambow, O., Rogati, M., & Walker, M. (2001). Evaluating trainable sentence planner
spoken dialogue travel system. Proc. Annual Meeting Association
Computational Linguistics.
Rambow, O., & Korelsky, T. (1992). Applied text generation. Proc. Conference
Applied Natural Language Processing.
454

fiIndividual Domain Adaptation Dialogue

Reiter, E. (2002). corpora gold standards NLG?. Proc. International
Natural Language Generation Conference.
Reiter, E., & Dale, R. (2000). Building Natural Language Generation Systems. Cambridge
University Press.
Reiter, E., & Sripada, S. (2002). Human variation lexical choice. Computational
Linguistics, 28, 545553.
Reiter, E., Sripada, S., & Robertson, R. (2003). Acquiring correct knowledge natural
language generation. Journal Artificial Intelligence Research, 18, 491516.
Reitter, D., Keller, F., & Moore, J. D. (2006). Computational modeling structural priming dialogue. Proc. Joint Conference Human Language Technologies
Meeting North American Chapter Association Computational
Linguistics.
Rich, E. (1979). User modelling via stereotypes. Cognitive Science, 3, 329354.
Scott, D. R., & de Souza, C. S. (1990). Getting message across RST-based text
generation. Dale, R., Mellish, C., & Zock, M. (Eds.), Current Research Natural
Language Generation, pp. 4773. Academic Press.
Snyder, B., & Barzilay, R. (2007). Database-text alignment via structured multilabel classification. Proc. International Joint Conference Artificial Intelligence.
Stenchikova, S., & Stent, A. (2007). Measuring adaptation dialogs. Proc.
8th SIGdial Workshop Discourse Dialogue.
Stent, A., & Guo, H. (2005). new data-driven approach multimedia presentation
generation. Proc. EuroIMSA.
Stent, A., Prasad, R., & Walker, M. (2004). Trainable sentence planning complex
information presentation spoken dialog systems. Proc. Annual Meeting
Association Computational Linguistics.
Stent, A., Walker, M., Whittaker, S., & Maloor, P. (2002). User-tailored generation
spoken dialogue: experiment. Proc. International Conference Spoken
Language Processing.
Wahlster, W., & Kobsa, A. (1989). User models dialogue systems. User Models
Dialogue Systems, pp. 434. Springer Verlag, Berlin.
Walker, M., Rambow, O., & Rogati, M. (2002). Training sentence planner spoken
dialogue using boosting. Computer Speech Language: Special Issue Spoken
Language Generation, 16 (3-4), 409433.
Walker, M. A., Cahn, J. E., & Whittaker, S. J. (1997). Improvising linguistic style: Social
affective bases agent personality. Proc. First Conference Automous
Agents.
455

fiWalker, Stent, Mairesse, & Prasad

Walker, M. A., et al. (2002). DARPA communicator: Cross-system results 2001
evaluation. Proc. International Spoken Language Processing Conference.
Walker, M. A., et al. (2004). Generation evaluation user tailored responses multimodal dialogue. Cognitive Science, 28 (5), 811840.
Webber, B., Knott, A., Stone, M., & Joshi, A. (1999). little trees made of?:
structural presuppositional account using lexicalized tag. Proc. Annual
Meeting Association Computational Linguistics.
Yeh, C.-L., & Mellish, C. (1997). empirical study generation anaphora
Chinese. Computational Linguistics, 23-1, 169190.
Zukerman, I., & Litman, D. (2001). Natural language processing user modeling: Synergies limitations. User Modeling User-Adapted Interaction, 11 (1-2), 129158.

456

fiJournal Artificial Intelligence Research 30 (2007) 565-620

Submitted 3/07; published 12/07

Probabilistic Planning via Heuristic Forward Search
Weighted Model Counting
Carmel Domshlak

DCARMEL @ IE . TECHNION . AC . IL

Technion - Israel Institute Technology,
Haifa, Israel

Jorg Hoffmann

J OERG .H OFFMANN @ DERI .

University Innsbruck, DERI,
Innsbruck, Austria

Abstract
present new algorithm probabilistic planning observability. algorithm,
called Probabilistic-FF, extends heuristic forward-search machinery Conformant-FF problems probabilistic uncertainty initial state action effects. Specifically,
Probabilistic-FF combines Conformant-FFs techniques powerful machinery weighted
model counting (weighted) CNFs, serving elegantly define search space
heuristic function. evaluation Probabilistic-FF shows fine scalability range probabilistic domains, constituting several orders magnitude improvement previous results
area. use problematic case point main open issue addressed
research.

1. Introduction
paper address problem probabilistic planning observability (Kushmerick,
Hanks, & Weld, 1995), also known AI planning community conditional (Majercik &
Littman, 2003) conformant (Hyafil & Bacchus, 2004) probabilistic planning. problems
given initial belief state form probability distribution world states W ,
set actions (possibly) probabilistic effects, set alternative goal states WG W .
solution problem single sequence actions transforms system one
goal states probability exceeding given threshold . basic assumption
problem system cannot observed time plan execution. setting
useful controlling systems uncertain initial state non-deterministic actions, sensing
expensive unreliable. Non-probabilistic conformant planning may fail due non-existence
plan achieves goals 100% certainty. Even plan, plan
necessarily contain information actions useful achieve requested
threshold .
state-of-the-art performance probabilistic planners advancing much slowly
deterministic planners, scaling 5-10 step plans problems 20 world states
15-20 step plans problems 100 world states (Kushmerick et al., 1995; Majercik &
Littman, 1998; Hyafil & Bacchus, 2004). Since probabilistic planning inherently harder
deterministic counterpart (Littman, Goldsmith, & Mundhenk, 1998), difference evolution
rates surprising. However, recent developments area (Onder, Whelan, & Li,
2006; Bryce, Kambhampati, & Smith, 2006; Huang, 2006), particular work here, show
dramatic improvements probabilistic planning obtained.
c
2007
AI Access Foundation. rights reserved.

fiD OMSHLAK & H OFFMANN

paper introduce Probabilistic-FF, new probabilistic planner based heuristic forward search space implicitly represented probabilistic belief states. planner natural
extension recent (non-probabilistic) conformant planner Conformant-FF (Hoffmann & Brafman, 2006). main trick replace Conformant-FFs SAT-based techniques recent
powerful technique probabilistic reasoning weighted model counting (WMC) propositional CNFs (Sang, Beame, & Kautz, 2005). detail, Conformant-FF forward search
belief space belief state corresponds set world states considered
possible. main trick Conformant-FF use CNF formulas implicit representation belief states. Implicit, context, means formulas (a) encode semantics
executing action sequence initial belief state, propositional variables corresponding
facts time-stamps. actual knowledge belief states (and be) inferred
formulas. particularly, fact p known true belief state
(a) p(m), time endpoint formula. knowledge computed
Conformant-FF belief states known facts, well (symmetrically) facts
known false. suffices STRIPS-style planning, is, determine applicable
actions goal belief states. heuristic function, FFs (Hoffmann & Nebel, 2001) relaxed
planning graph technique enriched approximate SAT reasoning.
basic ideas underlying Probabilistic-FF are:
(i) Define time-stamped Bayesian networks (BNs) describing probabilistic belief states.
(ii) Extend Conformant-FFs belief state CNFs model BNs.
(iii) addition SAT reasoning used Conformant-FF, use weighted model-counting
determine whether probability (unknown) goals belief state high enough.
(iv) Introduce approximate probabilistic reasoning Conformant-FFs heuristic function.
Note synergetic effect: Probabilistic-FF re-uses Conformant-FFs technology recognize
facts true false probability 1. fully serves determine applicable actions,
well detect whether part goal already known. fact, Conformant-FFs CNFbased techniques specifically made suit probabilistic setting: without probabilities
one could imagine successfully replacing CNFs BDDs, probabilities seems much
problematic.
algorithms present cover probabilistic initial belief states given Bayesian networks,
deterministic probabilistic actions, conditional effects, standard action preconditions.
experiments show approach quite effective range domains. contrast
SAT CSP based approaches mentioned (Majercik & Littman, 1998; Hyafil & Bacchus,
2004), Probabilistic-FF find 100-step plans problem instances billions world states.
However, comparison entirely fair due different nature results provided;
SAT CSP based approaches provide guarantees length solution. approach
closely related Probabilistic-FF implemented POND (Bryce et al., 2006): system, like
Probabilistic-FF, conformant probabilistic planning threshold , using non-admissible,
planning-graph based heuristic guide search. Hence comparison Probabilistic-FF
POND fair, experiments perform comparative evaluation Probabilistic-FF
POND. two approaches related, significant differences search
566

fiP ROBABILISTIC -FF

space representation, well definition computation heuristic function.1 run
two approaches range domains partly taken probabilistic planning literature,
partly obtained enriching conformant benchmarks probabilities, partly obtained
enriching classical benchmarks probabilistic uncertainty. almost cases, Conformant-FF
outperforms POND least order magnitude. make interesting observations
regarding behavior two planners; particular identify domain derived
classical Logistics domain approaches fail scale. apparent reason neither
approach good enough detecting many times, early point plan, probabilistic
action must applied order sufficiently support high goal threshold end plan.
Devising methods better regard pressing open issue line work.
paper structured follows. next section provides technical background, formally
defining problem address illustrating running example. Section 3 details
probabilistic belief states represented time-stamped Bayesian networks, Bayesian
networks encoded weighted CNF formulas, necessary reasoning performed
representation. Section 4 explains illustrates extension Conformant-FFs heuristic function probabilistic settings. Section 5 provides empirical results, Section 6
concludes. proofs moved Appendix A.

2. Background
probabilistic planning framework consider adds probabilistic uncertainty subset
classical ADL language, namely (sequential) STRIPS conditional effects. STRIPS
planning tasks described set propositions P triples (A, I, G), corresponding
action set, initial world state, goals. G sets propositions, describes
concrete initial state wI , G describes set goal states w G. Actions pairs
(pre(a), E(a)) precondition (conditional) effects. conditional effect e triple
(con(e), add(e), del(e)) (possibly empty) proposition sets, corresponding effects condition, add, delete lists, respectively. precondition pre(a) also proposition set,
action applicable world state w w pre(a). applicable w,
result applying w undefined. applicable w, conditional effects
e E(a) w con(e) occur. Occurrence conditional effect e w results world
state w add(e) \ del(e).
action applied w, proposition q q add(e) del(e )
(possibly same) occurring e, e E(a), result applying w undefined. Thus,
require actions self-contradictory, is, A, every e, e E(a),
exists world state w con(e) con(e ), add(e) del(e ) = . Finally, action
sequence plan world state results iterative execution actions, starting
wI , leads goal state w G.
2.1 Probabilistic Planning
probabilistic planning setting extends (i) probabilistic uncertainty
initial state, (ii) actions probabilistic effects. general, probabilistic planning
1. POND use implicit belief states, probabilistic part heuristic function uses sampling techniques,
rather probabilistic reasoning techniques employ.

567

fiD OMSHLAK & H OFFMANN

tasks quadruples (A, bI , G, ), corresponding action set, initial belief state, goals,
acceptable goal satisfaction probability. before, G set propositions. initial state
longer assumed known precisely. Instead, given probability distribution
world states, bI , bI (w) describes likelihood w initial world state.
Similarly classical planning, actions pairs (pre(a), E(a)), effect set E(a)
richer structure semantics. e E(a) pair (con(e), (e)) propositional condition set probabilistic outcomes. probabilistic outcome (e)
triplet (P r(), add(), del()), add delete lists before, P r() probability outcome occurs result effect e. Naturally,
P require probabilistic effects
define probability distributions outcomes, is, (e) P r() = 1. special case
deterministic effects e modeled way via (e) = {} P r() = 1. Unconditional actions
modeled single effect e con(e) = . before, applicable w,
result applying w undefined. Otherwise, applicable w, exists
exactly one effect e E(a) con(e) w, (e), applying w results
w add() \ del() probability P r(). likelihood [b, a] (w ) world state w
belief state [b, a], resulting applying probabilistic action b, given
[b, a] (w ) =

X

wpre(a)

b(w)

X

(e)


P r() w = w \ , add(), del() ,

(1)

e effect con(e) w, () Kronecker step function takes
value 1 argument predicate evaluates TRUE, 0 otherwise.
formalism covers problem-description features supported previously proposed
formalisms conformant probabilistic planning (Kushmerick et al., 1995; Majercik & Littman,
1998; Hyafil & Bacchus, 2004; Onder et al., 2006; Bryce et al., 2006; Huang, 2006), corresponds called Unary Nondeterminism (1ND) normal form (Rintanen, 2003). note
succinct forms specifying probabilistic planning problems (Rintanen, 2003),
yet 1ND normal form appears intuitive perspective knowledge engineering.
Example 1 Say robot block physically one two locations.
information captured propositions r1 , r2 robot, b1 , b2 block, respectively. robot either move one location another, carrying block.
robot moves without block, move guaranteed succeed. provides us
pair symmetrically defined deterministic actions {move-right, move-lef t}. action move-right empty precondition, single conditional effect e = ({r1 }, {})
P r() = 1, add() = {r2 }, del() = {r1 }. robot tries move carrying block,
move succeeds probability 0.7, probability 0.2 robot ends moving
without block, probability 0.1 move robot fails completely. provides us
pair (again, symmetrically defined) probabilistic actions {move-b-right, move-b-lef t}.
action move-b-right empty precondition, two conditional effects specified
Table 1.
specified semantics structure components (A, bI , G, ) ,
ready specify actual task probabilistic planning setting. Recall actions
transform probabilistic belief states belief states. action sequence , belief
568

fiP ROBABILISTIC -FF

E(a)

con(e)

e

r1 b 1

e

r1 b1

(e)

P r()

add()

del()

1
2
3
1

0.7
0.2
0.1
1.0

{r2 , b2 }
{r2 }



{r1 , b1 }
{r1 }



Table 1: Possible effects outcomes action move-b-right Example 1.
state b, new belief state [b, a] resulting applying b given


= hi
b,
[b, a] = [b, a] ,
.
= hai,





[[b, a] , ] , = hai , A, 6=

(2)

setting, achieving G certainty typically unrealistic. Hence, specifies required
lower bound probability achieving G. sequence actions called plan
ba (G) belief state ba = [bI , a].
2.2 Specifying Initial Belief State
Considering initial belief state, practical considerations force us limit attention
compactly representable probability distributions bI . numerous alternatives
compact representation structured probability distributions, Bayes networks (BNs) (Pearl, 1988)
date far popular representation model.2 Therefore, Probabilistic-FF
assume initial belief state bI described BN NbI set propositions P.
excellent introductions BNs abound (e.g., see Jensen, 1996), suffices briefly
define notation. BN N = (G, ) represents probability distribution directed acyclic
graph G, set nodes X stands random variables (assumed discrete paper),
, set tables conditional probabilities (CPTs)one table TX node X X .
possible value x Dom(X) (where Dom(X) denotes domain X), table TX
lists probability event X = x given possible value assignment immediate
ancestors (parents) P a(X) G. Thus, table size exponential in-degree X. Usually,
assumed either in-degree small (Pearl, 1988), probabilistic dependence X
P a(X) induces significant local structure allowing compact representation TX (Shimony,
1993, 1995; Boutilier, Friedman, Goldszmidt, & Koller, 1996). (Otherwise, representation
distribution BN would good idea first place.) joint probability complete
assignment variables X given product |X | terms taken respective
CPTs (Pearl, 1988):


P r ([X] | [P a(X)]) =
TX ([X] | [P a(X)]) ,
P r() =
XX

XX

[] stands partial assignment provided corresponding subset X .
2. BNs choice here, framework support models well, e.g. stochastic decision trees.

569

fiD OMSHLAK & H OFFMANN

Probabilistic-FF allow NbI described multi-valued variables underlying
planning problem. significantly simplifies process specifying NbI since STRIPS
3
propositions P
Sknot correspond true random variables underlying problem specification.
Specifically, let i=1 Pi partition P proposition set Pi uniquely corresponds
domain multi-valued variable underlying problem. is, every world state w
every Pi , |Pi | > 1, exactly one proposition q Pi holds w. variables
BN NbI describing initial belief state bI X = {X1 , . . . , Xk }, Dom(Xi ) = Pi
|Pi | > 1, Dom(Xi ) = {q, q} Pi = {q}.
Example 2 illustration NbI , consider running example, say robot
known initially one two possible locations probability P r(r1 ) = 0.9
P r(r2 ) = 0.1. Suppose correlation belief initial locations robot
block. believe that, robot r1 , P r(b1 ) = 0.7 (and P r(b2 ) = 0.3),
robot r2 , P r(b1 ) = 0.2 (and P r(b2 ) = 0.8). initial belief state BN NbI defined
two variables R (robot) B (block) Dom(R) = {r1 , r2 } Dom(B) = {b1 , b2 },
respectively, depicted Figure 1.
r1
0.9

r2
0.1

R

// B

r1
r2

b1
0.7
0.2

b2
0.3
0.8

Figure 1: Bayes network NbI Example 1.
hard see STRIPS-style actions equivalently specified terms
multi-valued variables X . Specifically, |Pi | > 1, action add proposition
q Pi without deleting proposition q Pi , thus, consider setting
Xi = q. |Pi | = 1, adding deleting q Pi standard semantics setting Xi = q
Xi = q, respectively. simplicity presentation, assume actions selfcontradictory level X wellif two conditional effects e, e E(a) possibly occur
world state w, subsets X affected two effects disjoint. Finally,
goal G directly corresponds partial assignment X (unless G self-contradictory,
requiring q q q, q Pi .)

3. Belief States
section, explain representation of, reasoning about, belief states. first explain
probabilistic belief states represented time-stamped BNs, explain
BNs encoded reasoned form weighted CNF formulas. representation
belief states weighted CNFs illustrated belief state running example
Figure 2. finally provide details works Probabilistic-FF.
3. Specifying NbI directly P would require identifying multi-valued variables anyway, followed connecting
propositions corresponding multi-valued variable complete DAG, normalizing CPTs
propositions certain manner.

570

fiP ROBABILISTIC -FF

1 2
r
3 1 1
r2

r1 r2
0.9 0.1
R(0)



B(0)

II
II
II
II
II
$$
::
uu
uu
u
u
uu
uu

b1 b2
r1 0.7 0.3
r2 0.2 0.8

Y(1)

r1
0
1
0

r2
1
0
1

// R
n66 (1)
n
n
nnn
nnn
n
n
1 2 3 1
nn
nnn
r1 b1 0.7 0.2 0.1 0
PPP
PPP
0 0 0 1
PPP othrw
PPP
PPP
P((
// B(1)

b1 b2
1
0 1
b 1 0
1 1
b2 0 1

r1 r2
r1 1 0
r2 1 0
// R(2)

// B(2)

b1 b2
b1 1 0
b2 0 1

Figure 2: Bayes network Nba running Example 1-2 action sequence
= hmove-b-right, move-lef ti.

3.1 Bayesian Networks
Probabilistic-FF performs forward search space belief states. search states belief
states (that is, probability distributions world states w), search restricted belief
states reachable initial belief state bI sequences actions a. key decision
one make actual representation belief states. Let bI initial belief state
captured BN NbI , let ba belief state resulting applying bI sequence
actions a. One well-known problems area decision-theoretic planning
description ba directly state variables X becomes less less structured number
(especially stochastic) actions increases. overcome limitation, represent belief
states ba BN Nba explicitly captures sequential application starting bI , trading
representation size cost inference, compared representing belief states directly
distributions world states. formally specify structure BN Nba , assuming
actions applicable corresponding belief states application, later
showing Probabilistic-FF makes sure indeed case. note belief-state
BNs similar spirit structure proposed AI literature verifying
probabilistic plan achieves goals certain probability (Dean & Kanazawa, 1989; Hanks &
McDermott, 1994; Kushmerick et al., 1995).
Figure 2 illustrates construction Nba running example = hmove-b-right,
move-lef ti. general, let = ha1 , . . . , sequence actions, numbered according
appearance a. 0 m, let X(t) replica state variables X , X(t) X(t)
571

fiD OMSHLAK & H OFFMANN

corresponding X X . variable set Nba union X(0) , . . . , X(m) , plus
additional variables introduce actions a.
First, X(0) X(0) , set parents P a(X(0) ) conditional probability tables
TX(0) simply copy state variable X NbI . Now, consider action a,
let = a. action introduce discrete variable Y(t)
mediates
variable layers X(t1) X(t) . domain Y(t) set Dom(Y(t) ) = eE(a) (e), is,
union probabilistic outcomes possible effects a. parents Y(t) Nba set
P a(Y(t) ) =

[

eE(a)


X(i1) | con(e) Dom(X) 6= ,

(3)

and, Dom(P a(Y(t) )), set
TY (t) (Y(i)

(
P r(),
= | ) =
0,

con (e())
,
otherwise

(4)

e() denotes effect e (e).
refer set variables Y(t) created actions Y. Now, let EX (a)
E(a) probabilistic effects affect variable X X . EX (a) = , set
P a(X(t) ) = {X(t1) },
(
1, x = x ,
.
(5)
TX(t) (X(t) = x | X(t1) = x ) =
0, otherwise
Otherwise, EX (a) 6= , let x Dom(X) value provided X (e), e EX (a).
Recall outcomes effects E(a) mutually exclusive. Hence, set P a(X(t) ) =
{X(t1) , Y(t1) },



TX(i) (X(i) = x | X(i1) = x , Y(i1)



1,
= ) = 1,


0,

e() EX (a) x = x ,
e() 6 EX (a) x = x , ,
otherwise

(6)

e() denotes effect responsible outcome .
hard verify Equations 4-6 capture frame axioms probabilistic semantics ourSactions. principle, accomplishes construction Nba variables
Xba =
t=0 X(t) . note, however, mediating variable Y(t) really needed
truly probabilistic actions. Specifically, deterministic action a, let EX (a) E(a)
conditional effects add and/or delete propositions associated domain variable X X . EX (a) = , set P a(X(t) ) = {X(t1) }, TX(t) according Equation 5.
Otherwise, set

[n

P a(X(t) ) = {X(t1) }
X(t1)
| con(e) Dom(X) 6= ,
(7)
eEX (a)

specify TX(t) follows. Let xe Dom(X) value (the deterministic outcome
of) effect e EX (a) provides X. Dom(P a(X(t) )), exists e EX (a)
572

fiP ROBABILISTIC -FF

con(e) , set
TX(t) (X(t)

(
1,
= x | ) =
0,

x = xe ,
otherwise

(8)

x = [X(t1) ],
otherwise

(9)

Otherwise, set
TX(t) (X(t)

(
1,
= x | ) =
0,

Due self-consistency action, hard verify Equations 8-9 consistent,
and, together Equation 5, capture semantics conditional deterministic actions.
special treatment deterministic actions illustrated Figure 2 direct dependencies
X(2) X(1) .
Proposition 1 Let (A, NbI , G, ) probabilistic planning problem, m-step sequence
actions applicable bI . Let P r joint probability distribution induced Nba
variables Xba . belief state ba corresponds marginal distribution P r X(m) , is:
ba (X ) = P r(X(m) ), G(m) partial assignment provided G X(m) , probability
ba (G) achieves G starting bI equal P r(G(m) ).
already mentioned, belief-state BNs constructed along principles outlined
used Dean Kanazawa (1989), Hanks McDermott (1994), Kushmerick et al.
(1995), thus correctness Proposition 1 immediate previous results.
point, worth bringing attention fact variables X(1) , . . . , X(m) completely
deterministic. Moreover, CPTs variables Nba compactly representable due
either low number parents, local structure induced large amount context-specific
independence, both. compactness CPTs Nba implied compactness
STRIPS-style specification planning actions. exploiting compactness action
specification, size Nba description kept linear size input
number actions a.
Proposition 2 Let (A, NbI , G, ) probabilistic planning problem described k state variables, m-step sequence actions A. Then, |Nba | = O(|NbI |+m(k+1))
largest description size action A.
proof Proposition 2, well proofs formal claims paper, relegated
Appendix A, pp. 613.
3.2 Weighted CNFs
Given representation belief states BNs, next select mechanism reasoning
BNs. general, computing probability query BNs known #Pcomplete (Roth, 1996). addition, hard verify, using analysis similar ones
Darwiche (2001) Brafman Domshlak (2006), networks arising work
typically exhibit large tree-width. numerous exact algorithms inference BNs
proposed literature (Darwiche, 2000; Dechter, 1999; Zhang & Poole, 1994),
classical algorithms scale well large networks exhibiting high tree-width. positive
573

fiD OMSHLAK & H OFFMANN

side, however, observation guides recent advances area probabilistic reasoning
real-world domains typically exhibit significant degree deterministic dependencies
context-specific independencies problem variables. Targeting property practical
BNs already resulted powerful inference techniques (Chavira & Darwiche, 2005; Sang et al.,
2005). general principle underlying techniques
(i) Compile BN N weighted propositional logic formula (N ) CNF,
(ii) Perform efficient weighted model counting (N ) reusing (and adapting) certain
techniques appear powerful enhancing backtracking DPLL-style search SAT.
One observation early stages developing Probabilistic-FF type
networks type queries problems make machinery solving BNs
weighted CNF model counting attractive needs. First, Section 3.1 already
shown BNs representing belief states exhibit large amount deterministic nodes
context-specific independence. Second, queries interest correspond computing
probability evidence G(m) Nba , type query clear interpretation terms
model counting (Sang et al., 2005). Hence, taking route Probabilistic-FF, compile
belief state BNs weighted CNFs following encoding scheme proposed Sang et al. (2005),
answer probabilistic queries using Cachet (Sang, Bacchus, Beame, Kautz, & Pitassi, 2004), one
powerful systems date exact weighted model counting CNFs.
general, weighted CNFs weights formulas specified follows. Let
V = {V1 , . . . , Vn } set propositional variables Dom(Vi ) = {vi , vi }, let :

0+ non-negative, real-valued weight function literals V.
Dom(Vi ) R
partial assignment V,Q
weight () assignment defined product literals
weights, is, () = l (l). Finally, propositional logic formula called weighted
defined weighted set propositional variables. weighted formula V,
weight () defined sum weights complete assignments V satisfying
, is,
X
() =
() ( |= ),
Dom(V)

Dom(V) = Dom(Vi ). instance, variables Vi (vi ) = (vi ) = 1,
() simply stands number complete assignments V satisfy .
Given initial belief state BN NbI , sequence actions = ha1 , . . . , applicable
bI , describe weighted CNF encoding (Nba ) (or (ba ), short) belief state
ba built used Probabilistic-FF. First, formally specify generic scheme introduced
Sang et al. (2005) encoding BN N variables X weighted CNF (N ).
encoding formula (N ) contains two sets variables. First, variable Z X
value z Dom(Z), formula (N ) contains state proposition literals {z, z}, weighted
(z) = (z) = 1. state propositions act (ba ) regular SAT propositions. Now,
variable Z Xba , let Dom(Z) = {z1 , . . . , zk } arbitrary fixed ordering Dom(Z).
Recall row TZ [i] CPT Z corresponds assignment (or set assignments) P a(Z). Thus, number rows TZ upper bounded number different
assignments P a(Z), (as happens case) significantly lower dependence Z P a(Z) induces substantial local structure. Following ordering Dom(Z)
above, entry TZ [i, j] contains conditional probability P r(zj | ). every CPT entry
574

fiP ROBABILISTIC -FF

procedure basic-WMC()
= return 1
empty clause return 0
select variable V
return basic-WMC(|v ) (v) + basic-WMC(|v ) (v)
Figure 3: Basic DPPL-style weighted model counting.
TZ [i, j] last one (i.e., TZ [i, k]), formula (N ) contains chance proposition literals
{hzji i, hzji i}. chance variables aim capturing probabilistic information CPTs
Nba . Specifically, weight literal hzji set P r(zj | , z1 , . . . , zj1 ),
conditional probability entry true, given row true, prior entry row
true:
TZ [i, j]
Pj1
1 k=1 TZ [i, k]



hzj = 1 hzji

hzji =

(10)

Considering clauses (N ), variable Z X , CPT entry TZ [i, j],
formula (N ) contains clause


hz1i hzj1
hzji zj ,
(11)

conjunction literals forming assignment Dom(P a(Z)). clauses
ensure weights complete assignments variables (N ) equal probability corresponding atomic events postulated BN N . illustrate construction
Equations 10-11, let boolean variables B parents ternary variable C (with
Dom(C) = {C1 , C2 , C3 }) BN, let P r(C1 |A, B) = 0.2, P r(C2 |A, B) = 0.4,
P r(C3 |A, B) = 0.4. Let raw corresponding assignment A, B P a(C) i-th
row CPT TC . encoding BN, first two entries raw TC captured
pair respective chance propositions
hC1i i, hC2i i. According
Equation 10, weights


0.4


propositions set hC1 = 0.2, hC1 = 10.2 = 0.5. Then, according
Equation 11, encoding contains three clauses

B hC1i C1

B hC1i hC2i C2

B hC1i hC2i C3

Finally, variable Z X , formula (N ) contains standard set clauses encoding
exactly one relationship state propositions capturing value Z. accomplishes encoding N (N ). next Section 3.3 illustrate encoding
belief state BN running example.
weighted CNF encoding (ba ) belief state BN Nba provides input weighted
model counting procedure. simple recursive DPPL-style procedure basic-WMC underlying Cachet (Sang et al., 2004) depicted Figure 3, formula |v obtained setting
575

fiD OMSHLAK & H OFFMANN

literal v true. Theorem 3 Sang et al. (2005) shows weighted CNF encoding
BN N , P r(Q|E) general query respect N , query Q, evidence E,
have:
basic-WMC( Q E)
P r(Q|E) =
,
(12)
basic-WMC( E)
query Q evidence E fact arbitrary formulas propositional logic. Note that,
special (and relevant us) case empty evidence, Equation 12 reduces P r(Q) =
basic-WMC(Q), is, single call basic-WMC procedure. Corollary 3 immediate
Proposition 1 Theorem 3 Sang et al. (2005).
Corollary 3 Let (A, bI , G, ) probabilistic planning task BN NbI describing bI ,
m-step sequence actions applicable bI . probability ba (G) achieves G starting
bI given by:
ba (G) = WMC ((ba ) G(m)) ,
(13)
G(m) conjunction goal literals time-stamped time endpoint a.
3.3 Example: Weighted CNF Encoding Belief States
illustrate generic BN-to-WCNF encoding scheme Sang et al. (2005) belief
state BN Nba running example Figure 2.
0 2, introduce time-stamped state propositions r1 (i), r2 (i), b1 (i), b2 (i). Likewise,
introduce four state propositions 1 (1), 2 (1), 3 (1), 1 (1) corresponding values
variable Y(1) . first set clauses (ba ) ensure exactly one relationship
state propositions capturing value variable Nba :

1 (1) 2 (1) 3 (1) 1 (1) ,

1i<j4 :

(yi (1) yj (1)) ,
0i2 :

(14)

(r1 (i) r2 (i)) , (r1 (i) r2 (i))
(b1 (i) b2 (i)) , (b1 (i) b2 (i))
proceed encoding CPTs Nba . root nodes one row
CPTs chance propositions identified corresponding state variables (Sang
et al., 2005). Hence, root variable R(0) need neither additional clauses special
chance propositions, state proposition r1 (0) (ba ) treated chance proposition
(r1 (0)) = 0.9.
Encoding variable B(0) bit involved. CPT TB(0) contains two (content-wise
different) rows corresponding given r1 given r2 cases, cases induce
non-deterministic dependence B(0) R(0) . encode content TB(0) introduce
two chance variables hb1 (0)1 hb1 (0)2 (hb1 (0)1 i) = 0.7 (hb1 (0)2 i) = 0.2.
positive literals hb1 (0)1 hb1 (0)2 capture events b1 given r1 b1 given r2 ,
negations hb1 (0)1 hb1 (0)2 capture complementary events b2 given r2 b2
given r2 , respectively. consider given r1 row TB(0) . encode row, need
576

fiP ROBABILISTIC -FF



(ba ) contain r1 (0) hb1 (0)1 b1 (0) r1 (0) hb1 (0)1 b2 (0). Similar encoding
required row given r2 , thus encoding TB 0 introduces four additional clauses:


r1 (0) hb1 (0)1 b1 (0) , r1 (0) hb1 (0)1 b2 (0)


(15)
r2 (0) hb1 (0)2 b1 (0) , r2 (0) hb1 (0)2 b2 (0)

finished NbI part Nba , proceed encoding variable Y(1) corresponding probabilistic action move-b-right. encode first row TY(1) introduce three chance propositions h1 (1)1 i, h2 (1)1 i, h3 (1)1 i; general, chance variables needed last entries CPT rows. weights chance propositions
0.2
= 0.6(6),
set according Equation 10 h1 (1)1 = 0.7, h2 (1)1 = 10.7

0.1
1
h3 (1) = 10.9 = 0.1. Using chance propositions, add (ba ) four clauses
Equation 11, notably first four clauses Equation 16 below.
Proceeding second row TY(1) , observe value R(0) B(0) case fully
determines value Y(1) . deterministic dependence encoded without using
chance propositions using last two clauses Equation 16.

r1 (0) b1 (0) h1 (1)1 1 (1) ,

r1 (0) b1 (0) h1 (1)1 h2 (1)1 2 (1) ,

r1 (0) b1 (0) h1 (1)1 h2 (1)1 h3 (1)1 3 (1) ,
(16)

r1 (0) b1 (0) h1 (1)1 h2 (1)1 h3 (1)1 1 (1) ,


r1 (0) 1 (1) , b1 (0) 1 (1)

Using state/chance variables introduced R0 , B 0 , Y(1) , encode CPTs R(1)
B(1) as:
R(1) : (1 (1) r2 (1)) , (2 (1) r2 (1)) ,

(3 (1) r1 (0) r1 (1)) , 1 (1) r1 (0) r1 (1) ,

(3 (1) r1 (0) r1 (1)) , 1 (1) r2 (0) r2 (1)

B(1) : (1 (1) b2 (1)) ,

(17)

(1 (1) b1 (0) b1 (1)) ,
(1 (1) b2 (0) b2 (1))
Since CPTs R(1) B(1) completely deterministic, encoding well using
chance propositions. Finally, encode (deterministic) CPTs R(2) B(2) as:
R(2) : (r1 (2))
B(2) : (b1 (1) b1 (2))

(18)

(b2 (1) b2 (2))
unary clause (r1 (2)) reduction (r1 (1) r1 (2)) (r2 (1) r1 (2)). accomplishes encoding (ba ).
577

fiD OMSHLAK & H OFFMANN

3.4 Conformant-FF Probabilistic-FF
Besides fact weighted model counting attractive kinds BNs arising context, weighted CNF representation belief states works extremely well ideas underlying Conformant-FF (Hoffmann & Brafman, 2006). outlined introduction already;
give details.
stated, Conformant-FF forward search non-probabilistic belief space
belief state corresponds set world states considered possible. main trick
Conformant-FF use CNF formulas implicit representation belief states,
formulas (a) encode semantics executing action sequence initial belief state. Facts
known true false inferred formulas. computation partial
knowledge constitutes lazy kind belief state representation, comparison approaches
use explicit enumeration (Bonet & Geffner, 2000) BDDs (Bertoli, Cimatti, Pistore, Roveri,
& Traverso, 2001) fully represent belief states. basic ideas underlying Probabilistic-FF are:
(i) Define time-stamped Bayesian Networks (BN) describing probabilistic belief states (Section 3.1 above).
(ii) Extend Conformant-FFs belief state CNFs model BN (Section 3.2 above).
(iii) addition SAT reasoning used Conformant-FF, use weighted model-counting
determine whether probability (unknown) goals belief state high enough
(directly below).
(iv) Introduce approximate probabilistic reasoning Conformant-FFs heuristic function (Section 4 below).
detail, given probabilistic planning task (A, bI , G, ), belief state ba corresponding
applicable bI m-step action sequence a, proposition q P, say q known
ba ba (q) = 1, negatively known ba ba (q) = 0, unknown ba , otherwise. begin
determining whether q known, negatively known, unknown time m. Re-using
Conformant-FF machinery, classification requires two SAT tests (ba ) q(m)
(ba ) q(m), respectively. information provided classification used threefold. First,
subgoal g G negatively known time m, ba (G) = 0. extreme,
subgoals G known time m, ba (G) = 1. Finally, subgoals
G known rest unknown time m, accomplish evaluating belief state ba
testing whether
ba (G) = WMC ((ba ) G(m)) .

(19)

Note also sets (positively/negatively) known propositions time steps
allows us significantly simplify CNF formula (ba ) G(m) inserting
corresponding values known propositions.
evaluating considered action sequence a, get ba (G) , done.
Otherwise, forward search continues, actions applicable ba (and thus used
generate successor belief states) actions whose preconditions known ba .
578

fiP ROBABILISTIC -FF

4. Heuristic Function
key component heuristic search procedure heuristic function. quality (informedness) computational cost function determine performance search.
heuristic function usually obtained solutions relaxation actual problem interest (Pearl, 1984; Russell & Norvig, 2004). classical planning, successful idea
use relaxation ignores delete effects actions (McDermott, 1999; Bonet & Geffner,
2001; Hoffmann & Nebel, 2001). particular, heuristic FF planning system based
notion relaxed plan, plan achieves goals assuming delete
lists actions empty. relaxed plan computed using Graphplan-style (Blum & Furst,
1997) technique combining forward chaining graph construction phase backward chaining
plan extraction phase. heuristic value h(w) FF provides world state w encountered
search length relaxed plan w. Conformant-FF, methodology
extended setting conformant planning initial state uncertainty (without uncertainty
action effects). Herein, extend Conformant-FFs machinery handle probabilistic initial
states effects. Section 4.1 provides background techniques used FF ConformantFF, Sections 4.2 4.4 detail algorithms forward backward chaining phases
Probabilistic-FF, respectively. algorithms two phases Probabilistic-FF heuristic
computation illustrated running example Sections 4.3 4.5, respectively.
4.1 FF Conformant-FF
specify relaxed plans computed FF; provide coarse sketch
computed Conformant-FF. purpose latter slowly prepare reader
come: Conformant-FFs techniques re-used Probabilistic-FF anyway, hence
described full detail part Sections 4.2 4.4.
Formally, relaxed plans classical planning computed follows. Starting w, FF
builds relaxed planning graph sequence alternating proposition layers P (t) action
layers A(t), P (0) w, A(t) set actions whose preconditions
contained P (t), P (t + 1) obtained P (t) including add effects (with fulfilled
conditions) actions A(t). is, P (t) always contains facts true one
would execute (the relaxed versions of) actions earlier layers A(t 1). relaxed
planning graph constructed either reaches propositional layer P (m) contains
goals, construction reaches fixpoint P (t) = P (t + 1) without reaching goals.
latter case corresponds (all) situations relaxed plan exist,
existence relaxed plan necessary condition existence real plan, state w
excluded search space setting h(w) = . former case G P (m), relaxed
plan subset actions A(1), . . . , A(m) suffices achieve goals (under ignoring
delete lists), extracted simple backchaining loop: goal P (m), select
action A(1), . . . , A(m) achieves goal, iterate process considering
actions preconditions respective effect conditions new subgoals. heuristic estimate
h(w) set length extracted relaxed plan, is, number actions selected
backchaining process.
Aiming extending machinery FF conformant planning, Conformant-FF, Hoffmann Brafman (2006) suggested extend relaxed planning graph additional fact layers (t) containing facts unknown time t, reason unknown
579

fiD OMSHLAK & H OFFMANN

facts become known relaxed planning graph. complexity type reasoning
prohibitive, Conformant-FF relaxes planning task ignoring delete lists,
also one unknown conditions action effect. is, action appears
layer A(t), effect e con(e) P (t) (t) con(e) (t) 6= ,
con(e) (t) arbitrarily reduced contain exactly one literal, reasoning done
con(e) reduced form beginning.
V
relaxation converts implications ( ccon(e)uP (t) c(t)) q(t + 1) action effects
induce unknown propositions 2-projections take form binary implications c(t) q(t + 1), arbitrary c con(e) (t). Due layered structure
planning graph, set binary implications c(t) q(t + 1) seen forming
directed acyclic graph Imp. given relaxations, graph captures exactly dependencies truth propositions time. Hence, checking whether proposition q becomes
known time done follows. First, backchain implication edges Imp end
q(t), collect set support(q(t)) leafs4 reached. Then, CNF formula
describing possible initial states, test SAT check whether
_

l
lsupport(q(t))

test succeed least one leafs support(q(t)) true every possible
initial state. given relaxations, case if, applying actions
relaxed planning graph, q always true time t.5
process extracting relaxed plan constructed conformant relaxed planning
graph extension FFs respective process machinery selects actions responsible
relevant paths Imp. overall Conformant-FF heuristic machinery sound complete
relaxed tasks, yields heuristic function highly informative across range challenging
domains (Hoffmann & Brafman, 2006).
work, adopt Conformant-FFs relaxations, ignoring delete lists action effects, well one propositions effects condition. Accordingly, adopt
following notations Conformant-FF. Given set actions A, denote |+
1 function
+
set possible actions, |1 maps action similar
empty delete lists one conditioning propositions effect removed;
+
+
|+
denote action set obtained applying |+
1 (a), write a|
1 . A|1
1 actions

+
+


denote

a|
A, is, A|+
=
a|
|



.


action
sequence
1 sequence
1
1
+
actions obtained applying |1 every action along a, is,
(
hi,
= hi
a|+
.
1 =
+
+

ha|1 |1 , = hai
probabilistic planning task (A, bI , G, ), task (A|+
1 , bI , G, ) called relaxation
+
+
(A, bI , G, ). Finally, a|1 plan (A|1 , bI , G, ), called relaxed plan
(A, bI , G, ).
4. Following Conformant-FF terminology, leafs refer nodes zero in-degree.
5. Note would possible full SAT check, without 2-projection (without relying Imp), see
whether q becomes known t. However, indicated above, full check every unknown proposition
every level relaxed planning graph every search state would likely expensive, computationally.

580

fiP ROBABILISTIC -FF

next two sections describe machinery underlying Probabilistic-FF heuristic
estimation. Due similarity conceptual relaxations used Probabilistic-FF
Conformant-FF, Probabilistic-FF inherits almost Conformant-FFs machinery. course,
new contributions algorithms dealing probabilistic belief states probabilistic
actions.
4.2 Probabilistic Relaxed Planning Graphs
Like FF Conformant-FF, Probabilistic-FF computes heuristic function two steps, first
one chaining forward build relaxed planning graph, second step chaining backward
extract relaxed plan. section, describe detail Probabilistic-FFs forward chaining step,
building probabilistic relaxed planning graph (or PRPG, short). Section 4.4, show
one extract (probabilistic) relaxed plan PRPG. provide detailed illustration
PRPG construction process basis running example; since illustration
lengthy, moved separate Section 4.3.
algorithms building PRPG quite involved; instructive first consider (some
of) key points delving details. main issue is, course, need
extend Conformant-FFs machinery ability determine goal set sufficiently
likely, rather known true sure. achieve that, must introduce
relaxed planning effective reasoning probabilistic initial state, effects
probabilistic actions. turns reasoning obtained certain weighted
extension implication graph. nutshell, want determine likely fact
q true time t, propagate certain weights backwards implication graph,
starting q(t); weight q(t) set 1, weight p(t ) gives estimate
probability achieving q given p holds . Computing probability exactly would,
course, expensive. estimation based assuming independence various
probabilistic events involved. choice made carefully; experimented widely
various options deciding favor technique.
simplifying assumption weight propagation constitutes, course, another relaxation,
top relaxations already inherited Conformant-FF. particularly problematic
aspect assuming independence under-estimating technique. actual weight
node p(t ) probability achieving q given p holds may lower
estimate. effect, PRPG may decide wrongly relaxed plan exists: even execute
relaxed actions contained successful PRPG, probability achieving goal
execution may less required threshold. words, lose soundness (relative
relaxed tasks) relaxed planning process.
experimented alternative weight propagation method, based opposite assumption, relevant probabilistic events always co-occur, hence weights must
propagated according simple maximization operations. propagation method yielded
uninformative heuristic values, hence inacceptable empirical behaviour Probabilistic-FF,
even simple benchmarks. view, seems unlikely under-estimating yet informative efficient weight computation exists. experimented alternative
non under-estimating propagation schemes, particular one based assuming probabilistic events completely disjoint (and hence weights added); schemes gave better
581

fiD OMSHLAK & H OFFMANN

performance maximization, lagged far behind independence assumption
challenging benchmarks.
Let us get actual algorithm building PRPG. coarse outline algorithm
follows. PRPG built layer-wise fashion, iteration extending PRPG, reaching
time t, another layer, reaching time + 1. actions new step whose
preconditions known hold t. Effects conditioned unknown facts (note reduction
effect conditions single fact) constitute new edges implication graph. difference
Conformant-FF, dont obtain single edge condition add effect; instead, obtain edges
condition chance nodes, chance node represents probabilistic outcome
effect; chance nodes, turn, linked edges respective add effects. weights
chance nodes set probabilities respective outcomes, weights
nodes set 1. weights static weights dynamically modified
weight propagation; rather, static weights form input propagation.
implication graph edges inserted layer, algorithm checks whether new
facts become known. check done much like corresponding check Conformant-FF,
testing whether disjunction support leafs proposition p + 1 implied
initial state formula. two differences Conformant-FF are: (1) leafs relevant whose
dynamic weight 1 (otherwise, achieving leaf guaranteed accomplish p + 1). (2)
Another reason p become known may outcomes unconditional effect (or
effect known condition) result achievement p time + 1. elegantly formulate
overall test single implication test support leafs whose dynamic weight equals
weight.
Like FFs Conformant-FFs algorithms, PRPG process two termination criteria.
PRPG terminates positively goal probability high enough time t; PRPG terminates
negatively if, + 1, nothing changed may result higher goal propability
future . goal probability layer computed based weighted model counting
formula derived support leafs goals known true. criteria negative
termination check: whether new facts become known unknown (not negatively known);
whether possibly relevant new support leafs appeared; whether goal probability
increased. neither case, stop safelyif PRPG terminates unsuccessfully
guarantee relaxed plan, corresponding belief hence
dead end.
Let us get details. Figure 4 depicts main routine building PRPG belief
state ba . already specified, sets P (t), (t), A(t) contain propositions
known hold time (hold probability 1), propositions unknown hold
time (hold probability less 1 greater 0), actions known
applicable time t, respectively. layers 0 PRPG capture applying relaxed actions
starting ba . layers 1 PRPG correspond m-step action sequence leading
initial belief state belief state question ba . inherit latter technique
Conformant-FF; sense, PRPG reasons past. may look confusing first
sight, simple reason. Imagine PRPG starts level 0 instead. Then, check whether
proposition becomes known, SAT tests regarding support leafs belief
state formula, (ba ), instead initial state formula (similarly weighted model counting
test whether goal likely enough). Testing (ba ) possible, expensive
582

fiP ROBABILISTIC -FF

procedure build-PRPG(a, A, (NbI ), G, , |+
1 ),
returns Bool saying relaxed plan belief state
given = ham , . . . , a1 i,
builds data structures relaxed plan extracted
:= (NbI ), Imp :=
P (m) := {p | p known }, (m) := {p | p unknown }
:= 1
A(t) := {at |+
1 } N OOP
build-timestep(t, A(t))
endfor
:= 0
get-P(t, G) <
A(t) := {a|+
1 | A, pre(a) P (t)} N OOP
build-timestep(t, A(t))
P (t + 1) = P (t)
(t + 1) = (t)
p (t + 1) : (m) support(p(t + 1)) = (m) support(p(t))
get-P(t + 1, G) = get-P(t, G)
return FALSE
endif
:= + 1
endwhile
:= t, return TRUE

Figure 4: Main routine building probabilistic relaxed planning graph (PRPG).
computationally.6 negative-index layers chain implication graph way back
initial state, hence enable us perform SAT tests typically much smaller initial
state formula.
Returning Figure 4, PRPG initialized empty implication set Imp, P (m)
(m) assigned propositions known unknown initial belief state,
weighted CNF formula initialized (NbI ). formula implication/weighted model checking tests run asking whether proposition becomes known/whether
goal likely enough. PRPG built, incrementally extended clauses
capture behavior different effect outcomes.
loop builds sets P time steps 1 iterative invocation
build-timestep procedure time expands PRPG single time level.
iteration 1, sets P (t + 1) (t + 1) made contain propositions
known/unknown applying relaxed version action (remember
= ha1 , . . . , i). simplify presentation, action set A(t) contains set dummy
actions N OOP simply
transport

propositions time layer time layer t+1.
formally, N OOP = noopp | p P , pre(noopp ) = , E(noopp ) = {({p}, {})},
= (1.0, {p}, )}).
6. Conformant-FF, configuration implemented option; significantly slows search
domains, brings advantages cases.

583

fiD OMSHLAK & H OFFMANN

subsequent loop constructs relaxed planning graph layer 0 onwards by,
again, iterative invocation build-timestep procedure. actions layer 0
relaxations actions whose preconditions known hold time certainty.
iterative construction controlled two termination tests. First, goal estimated hold
layer probability higher , know relaxed plan estimate extracted.
Otherwise, graph reaches fix point, know relaxed (and thus, real) plan
bI exists. postpone discussion two termination criteria, focus
time layer construction procedure build-timestep.
procedure build-timestep(t, A),
builds P (t + 1), (t + 1), implication edges + 1,
induced action set
P (t + 1) := P (t), (t + 1) :=
effects e action A, con(e) P (t) (t)
(e)
(t + 1) := (t + 1) add()
introduce new fact (t) ((t)) = P r()
Imp := Imp {((t), p(t + 1)) | p add()}
endfor
con(e) (t)
Sthen
Imp := Imp (e) {(con(e)(t), (t))}
else
V
:= (e) (t) , (e) ((t) (t))
endif
endfor
p (t + 1)
build-w-impleafs(p(t + 1), Imp)
support(p(t + 1)) := {l | l leafs(Impp(t+1) ) p(t+1) (l) = (l)}
W
lsupport(p(t+1)) l P (t + 1) := P (t + 1) {p} endif
endfor
(t + 1) := (t + 1) \ P (t + 1)

Figure 5: Building time step PRPG.
build-timestep procedure shown Figure 5. first loop build-timestep proceeds
outcomes (relaxed) actions given set may occur time t.
probabilistic outcome introduce new chance proposition weighted conditional likelihood
outcome.7 that, extend Imp binary implications new chance
proposition add list outcome. uncertain condition con(e)
corresponding effect time t, is, con(e) (t), also add implications
con(e) chance propositions created outcomes e. Otherwise, con(e)
known time t, uncertainty ability make effect e hold time
t. case, ground chance propositions created outcomes e
implication graph, simply extend running formula clauses capturing exactly
one relationship chance propositions corresponding alternative outcomes e
7. course, implementation special case treatment deterministic actions, using chance nodes
(rather single chance node static weight 1).

584

fiP ROBABILISTIC -FF

time t. way, probabilistic uncertainty outcome e treated
property initial belief state bI ; type knowledge add knowledge
base formula initializing build-PRPG (NbI ).
Notation
Impvu
Impu
leafs(Imp )
E(Imp )

Description
graph containing exactly paths node v node u Imp.
subgraph Imp formed node u ancestors u Imp.
set zero in-degree nodes subgraph Imp Imp.
set time-stamped action effects responsible implication edges
subgraph Imp Imp.
Table 2: Overview notations around implication graph.

second loop checks whether proposition p, unknown time t, becomes known
time + 1. part build-timestep procedure somewhat involved; Table 2 provides
overview main notations used follows discussing various uses
implication graph Imp.
First thing second loop build-timestep, call build-w-impleafs procedure associates node v(t ) Impp(t+1) estimate p(t+1) (v(t )) probability achieving
p time + 1 effects E(Impv(t )p(t+1) ), given v holds time . words,
dynamic weight (according p(t + 1)) implication graph nodes computed. Note v(t )
either time-stamped proposition q(t ) q P, chance proposition (t )
probabilistic outcome .
discuss build-w-impleafs procedure detail below. proceeding understand
second loop build-timestep, main thing need know following lemma:
Lemma 4 Given node v(t ) Impp(t+1) , p(t+1) (v(t )) = (v(t )) if,
given v time , sequence effects E(Impv(t )p(t+1) ) achieves p + 1 probability 1.
words, v(t ) leads p(t + 1) certainty iff dynamic weight v(t ) equals static
weight. simple consequence weight propagation arranged; hold true
reasonable weight propagation scheme (do mark node certain not). full
proof lemma appears Appendix pp. 613.
Re-consider second loop build-timestep. happens following.
finished build-w-impleafs weight propagation p time + 1,
1. collect leafs support(p(t + 1)) Impp(t) meet criteria Lemma 4,
2. check (by call SAT solver) whether knowledge-base formula implies disjunction leafs.
implication holds, examined fact p time added set facts known time
t. Finally, procedure removes set facts known possibly hold time + 1
facts proven hold time + 1 certainty.
understand above, consider following. Lemma 4, support(p(t + 1)) contains
exactly set leafs achieving lead p(t + 1) certainty. Hence basically
585

fiD OMSHLAK & H OFFMANN

procedure build-w-impleafs (p(t), Imp)
top-down propagation weights p(t) p(t) nodes Impp(t)
p(t) (p(t)) := 1
decreasing time steps := (t 1) . . . (m)
chance nodes (t ) Impp(t)


Q
1 p(t) (r(t + 1))
:= radd(),r(t +1)Imp
p(t)
p(t) ((t )) := ((t )) (1 )
endfor
fact nodes q(t ) Impp(t)
:= 1

A(t
E(a), con(e) = q

h ), eP
p(t) ((t ))
:= 1 (e),(t )Imp
p(t)
endfor
p(t) (q(t )) := 1
endfor
endfor

Figure 6: build-w-impleafs procedure weight back-propagation implication graph.
use implication test Conformant-FF. Note, however, word basically
previous sentence hides subtle important detail. difference situation ConformantFF, support(p(t + 1)) may contain two kinds nodes: (1) proposition nodes start layer
PRPG, i.e., layer corresponding initial belief; (2) chance nodes later layers
PRPG, corresponding outcomes effects unknown conditions. point
discussed updates onWthe formula neededthose keep track alternative
effect outcomes. Hence testing lsupport(p(t+1)) l testing whether either: (1) p
known + 1 always triggered certainty least one proposition true
initial world; (2) p known + 1 triggered outcomes effect
appear certainty. get following result:
Lemma 5 Let (A, NbI , G, ) probabilistic planning task, sequence actions applicable
bI , |+
1 relaxation function A. time step m, proposition p
P, P (t) constructed build-PRPG(a, A, (NbI ), G, , |+
1 ), p time achieved
+
relaxed plan starting a|1
(1) probability > 0 (that is, p negatively known time t) p (t)P (t),

(2) probability 1 (that is, p known time t) p P (t).
consequence arguments outlined above. full proof Lemma 5 given
Appendix pp. 614.
Let us consider weight-propagating8 procedure build-w-impleafs depicted Figure 6.
procedure performs layered, top-down weight propagation given node9 p(t) Imp
8. weight propagation scheme build-w-impleafs procedure similar nature used heuristics
module recent probabilistic temporal planner Prottle Little, Aberdeen, Thiebaux (2005).
9. Note instantiated + 1 called build-timestep.

586

fiP ROBABILISTIC -FF

leafs Impp(t) . order traversal ensures node Impp(t) processed successors Impp(t) . chance nodes (t ), dynamic weight
p(t) ((t )) set
1. probability outcome takes place time given corresponding action
effect e() take place , times
2. estimate probability achieving p time effects E(Imp(t )p(t) ).
first quantity given global, static weight ((t )) assigned (t ) first
loop build-timestep. second quantity derived dynamic weights p(t) (r(t + 1))
r add(), computed previous iteration outermost loop build-w-impleafs.
Making heuristic assumption effect sets E(Impr(t +1)p(t) ) different r add()
pairwise independent, set probability failure achieve p effects
E(Imp(t )p(t) ). computation (t ) decomposed artifacts ,
weight propagation starts taking place. fact nodes q(t ), dynamic weight
p(t) (q(t )) set probability action effect conditioned q time allows
(possibly indirectly) achieving desired fact p time t. Making heuristic assumption
independence various effects conditioned q , computing p(t) (q(t ))
decomposed outcomes effects.
procedure get-P (t, G)
estimates probability achieving G time p.
G 6 P (t) (t) return 0 endif
G P (t) return 1 endif
g G \ P (t)
l leafs(Impg(t) ), introduce chance proposition hlg weight g(t) (l)
W
V
g := ( lleafs(Impg(t) ) l) lleafs(Impg(t) )uP (m) (l hlg i)
endfor
V
return WMC( gG\P (t) g )

Figure 7: Estimating goal likelihood given time step.
remains explained build-PRPG procedure two termination criteria
loop constructing planning graph layer 0 onwards. first test made
call get-P procedure, checks whether PRPG built time layer contains
relaxed plan (A, NbI , G, ). get-P procedure shown Figure 7. First, one
subgoals negatively known time t, then, Lemma 5, overall probability achieving
goal 0. extreme, subgoals known time t, probability
achieving goal 1. correctness latter test implied Lemma 5 non-interference
relaxed actions. leaves us main case uncertain
subgoals. uncertainty either due dependence subgoals actual initial world
state, due achieving subgoals using probabilistic actions, due both. uncertainty
initial state fully captured weighted CNF formula (NbI ) . Likewise,
outcomes chance propositions (t ) introduced implication graph build-timestep
procedure chained Imp propositions add lists outcomes,
587

fiD OMSHLAK & H OFFMANN

chained Imp unknown (relaxed) conditions outcomes, any. Therefore,
action outcome time < relevant achieving subgoal g G time t,
corresponding node (t ) must appear Impg(t) , weight back-propagated
build-w-impleafs(g(t), Imp) leafs Impg(t) . get-P procedure exploits
back-propagated estimates by, again, taking heuristic assumption independence
achieving different subgoals. Namely, probability achieving unknown sub-goals G \ P (t)
estimated weighted model counting formula , conjoined probabilistic theories
g achieving unknown goal g isolation. understand formulas g , consider that,
order make g true t, must achieve least one leafs l Impg(t) ; hence left part
conjunction. hand, make l true, achieves g(t) (estimated)
probability g(t) (l); hence right part conjunction requires us pay price set
l true.10
explained start section, positive PRPG termination test may fire even
real goal probability high enough. is, get-P may return value higher real
goal probability, due approximation (independence assumption) done weight propagation. course, due approximation, may also happen get-P returns value lower
real goal probability.
second PRPPG termination test comes check whether reached point
construction PRPG allows us conclude relaxed plan (A, NbI , G, )
starts given action sequence a. termination criterion asks whether, time step
time step + 1, potentially relevant changes occurred. potentially relevant change
would goal-satisfaction probability estimate get-P grows, known unknown
propositions grow, support leafs latter propositions Imp correspond
initial belief state grow.11 none occurs, would hold future iterations > t,
implying required goal satisfaction probability would never reached. words,
PRPG construction complete.
Theorem 6 Let (A, NbI , G, ) probabilistic planning task, sequence actions appli+
cable bI , |+
1 relaxation function A. build-PRPG(a, A, (NbI ), G, , |1 ) returns
+
FALSE, relaxed plan (A, bI , G, ) starts a|1 .
Note Theorem 6 holds despite approximation done weight propagation, making
assumption probabilistic independence. Theorem 6 hold, requirement
weight propagation this: real weight still grows, estimated weight still grows.
requirement met independence assumption. would met assumption
co-occurence, propagating weights maximization operations, thereby conservatively underestimating weights. propagation, PRPG fails cannot conclude
plan respective belief. another good argument (besides bad quality heuristics
observed empirically) using conservative estimation.
10. introduce extra chance propositions hlg i, instead assign weight g(t) (l) l itself,
outcome correct: pay also setting l false.
11. understand latter, note PRPG always added replicas probabilistic actions
irrelevant achieving goals, effects known conditions. action effects (since
irrelevant) influence estimate goal-satisfaction probability, chance propositions corresponding
outcomes effects may become support leafs unknown proposition p. latter case,
set support leafs support(p(t )) infinitely grow , projection support(p(t ))
initial belief state (that is, support(p(t)) (t)) guaranteed reach fix point.

588

fiP ROBABILISTIC -FF

full proof Theorem 6 given Appendix pp. 615. theorem finalizes
presentation analysis process constructing probabilistic relaxed planning graphs.
4.3 Example: PRPG Construction
illustrate construction PRPG algorithm Figures 4-7, let us consider simplification running Examples 1-2
(i) actions {move-b-right, move-lef t} constitute action set A,
(ii) goal G = {r1 , b2 }, required lower bound probability success = 0.9,
(iii) initial belief state bI given BN NbI Example 2,
(iv) belief state ba evaluated heuristic function corresponds actions sequence
= hmove-b-righti.
effects/outcomes actions considered construction PRPG described
Table 3, embr re-notation effect e Table 1, effect e Table 1 effectively
ignored due emptiness add effects.


E(a)

con(e)

con(e)|+
1

(e)

P r()

add()

0.7
0.2
0.1
1.0

{r2 , b2 }
{r2 }

{r1 }

1.0
1.0
1.0
1.0

{r1 }
{r2 }
{b1 }
{b2 }

embr

{r1 , b1 }

{r1 }

aml (move-lef t)

eml

{r2 }

{r2 }

mbr
1
mbr
2
mbr
3
ml

noopr1
noopr2
noopb1
noopb2

er1

{r1 }
{r2 }
{b1 }
{b2 }

{r1 }
{r2 }
{b1 }
{b2 }

r1
r2
b1
b2

ambr

(move-b-right)

er2
eb1
eb2

Table 3: Actions |+
1 relaxation PRPG construction example.
initialization phase build-PRPG procedure results = (NbI ), Imp := ,
P (1) = , (1) = {r1 , r2 , b1 , b2 }. content (1) depicted first column
nodes Figure 8. first loop build-PRPG (constructing PRPG past layers
corresponding a) makes single iteration, calls build-timestep procedure = 1
A(-1) = {ambr } N OOP S. (In follows, using names actions refer
mbr empty, thus adds
|+
1 relaxations given Table 3.) add list outcome 3
nodes implication graph. that, chance nodes introduced Imp call
build-timestep appear second column Figure 8. first outer loop build-timestep
results Imp given columns 1-3 Figure 8, (0) = (1), extension .
second outer loop build-timestep, weight propagating procedure build-w-impleafs
called unknown fact p(0) (0) = {r1 (0), r2(0) , b1 (0), b2 (0)}, generating p(0)oriented weights Table 4. p(0) (0), set supporting leafs support(p(0)) =
589

fiD OMSHLAK & H OFFMANN


WV



00 ml (0)

54






mbr (-1)
mbr


1 AA

1AA (0)
ML
ML



]\
]\












mbr
mbr (0)

88 2
q88 2 (-1)

;
;;


;;
qqq
rrrr
;;


;;
qq
;;
rrrr
;;
qqq

r
;
r
01;;

;; // r1 (0)
;; // r1 (1)
// 1
// 1 (-1)
r1 (-1)


(0)
;;
;;

;;
;;

;
RS
HI ;
HI ;;




// r2 (0)
// r2 (-1)
// r2 (0)
// r2 (1)
r2 (-1)





b1 (-1)



// b1 (-1)



b2 (-1)



// b2 (-1)



!

// b1 (0)



// b1 (0)



// b2 (0)



// b2 (0)



!



mbr
1 (1)

ML
]\



mbr
2 (1)
;;
;;
;;
;;
;;
;;
;;
HI ;;
r

// 2
// r2 (2)
(1)

// b1 (1)



// b1 (1)



// b2 (1)



// b2 (1)



// b1 (2)
!

// b2 (2)

Figure 8: implication graph Imp. odd columns nodes depict sets unknown propositions (t). even columns nodes depict change propositions introduced
probabilistic outcomes actions A(t).

{p(1)}, none implied = NbI , thus set known facts P (0) remains equal
P (1) = , (1) equal = (1).

r1 (0)
r2 (0)
b1 (0)
b2 (0)

= 0
= 1
mbr
mbr
r
r
r1 r2 b1 b2 1
2
1 2 b1 b2
1
1
1
0.7 0.2
1
1
1
1 0.7
1

r1 r2 b1 b2
1
0.9 1
1
0.7
1

Table 4: columns table correspond nodes implication graph Imp,
row provides weights p(0) p(0) (0). entry row p(0)
empty node associated corresponding column belong
implication subgraph Impp(0) .
finished loop, build-PRPG procedure proceeds loop
builds future layers PRPG. test goal (un)satisficing get-P(0, G) < evaluates
TRUE get get-P(0, G) = 0.63 < 0.9, thus loop proceeds first iteration.
see former, consider implication graph Imp constructed far (columns 1-3 Fig590

fiP ROBABILISTIC -FF

ure 8). goal G = {r1 , b2 } leafs(Impr1 (0) ) = {r1 (1)}, leafs(Impb2 (0) ) =
{r1 (1), b2 (1)}. {r1 (0), b2 (0)} (0) = (NbI ),
get-P(0, G) = WMC ((NbI ) r1 b2 ) ,

r1 = (hr1,r1 i) (r1 hr1,r1 i) ,
b2 = (hr1,b2 hb2,b2 i) (r1 (1) hr1,b2 i) (b2 (1) hb2,b2 i) ,

(20)


(hr1,r1 i) = r1 (0) (r1 (1)) = 1
(hb2,b2 i) = b2 (0) (b2 (1)) = 1

.

(21)

(hr1,b2 i) = b2 (0) (r1 (1)) = 0.7
Observe two models (NbI ) consistent r2 immediately falsify sub-formula
(NbI ) r1 . Hence,

get-P(0, G) = WMC (NbI ) r1 b2 |r1 (1)=1,b1 (1)=1 +

WMC (NbI ) r1 b2 |r1 (1)=1,b2 (1)=1

= bI (r1 , b1 ) (hr1,r1 i) (hr1,b2 i) + bI (r1 , b2 ) (hr1,r1 i) (hr1,b2 i) (hb2,b2 i)

= 0.63 1 0.7 + 0.27 1 0.7 1
= 0.63
first iteration loop, build-PRPG calls build-timestep procedure
= 0 A(0) = {ambr , aml } N OOP S. chance nodes introduced Imp call
build-timestep appear forth column Figure 8. first outer loop build-timestep
results Imp given columns 1-5 Figure 8, (1) = (0), extension .
before, second loop build-timestep, build-w-impleafs procedure called
unknown fact p(1) (1) = {r1 (1), r2(1) , b1 (1), b2 (1)}, generating p(1)-oriented weights.
interesting case case weight propagation build-w-impleafs(r1 (1), Imp), resulting
weights
r1 (1) (r1 (1)) = 1

r1 (1) (r1 (-1)) = 1

ml

r1 (1) ( (0)) = 1
r1

r1 (1) ( (0)) = 1
r1 (1) (r1 (0)) = 1
r1 (1) (r2 (0)) = 1



r1 (1) (r2 (-1)) = 1
r1 (1) (mbr
1 (-1))
mbr
r1 (1) (2 (-1))

= 0.7



r1 (1) (r1 (-1)) = 1
r1 (1) (r2 (-1)) = 1

= 0.2

nodes Impr1 (1) . that, set supporting leafs r1 (1) assigned support(r1 (1)) =
{r1 (1), r2 (1)}, since = (NbI ) implies r1 (1) r2 (1), fact r1 concluded
known time 1, added P (1). nodes p(1) (1) still
support(p(1)) = {p(1)}, thus remain unknown time = 1 well. Putting
things together, call build-w-impleafs procedure results P (1) = {r1 (1)},
591

fiD OMSHLAK & H OFFMANN

(1) = {r2(1) , b1 (1), b2 (1)}. loop build-PRPG procedure proceeds checking fixpoint termination test, immediately fails due P (1) 6= P (0). Hence,
loop proceeds next iteration corresponding = 1.
test goal (un)satisficing get-P(1, G) < still evaluates TRUE
get-P(1, G) = 0.899 < 0.9. Let us follow evaluation get-P(1, G) detail well. Considering implication graph Imp constructed far time = 1 (columns 1-5 Figure 8),
G (1) = {b2 (1)}, leafs(Impb2 (1) ) = {r1 (1), b2 (1)}, (still) = (NbI ),
obtain
get-P(1, G) = WMC ((NbI ) b2 ) ,

b2 = (hr1,b2 hb2,b2 i) (r1 (1) hr1,b2 i) (b2 (1) hb2,b2 i) ,

(22)

structure b2 Equation 22 identical Equation 20, weights associated
auxiliary chance propositions different, notably
(hb2,b2 i) = b2 (1) (b2 (1)) = 1

.

(hr1,b2 i) = b2 (1) (r1 (1)) = 0.91

(23)

difference (hr1,b2 i) Equation 21 Equation 23 stems fact r1 (1)
supports b2 (1) via effect embr time 1 also via different instance
effect time 0. Now, model (NbI ) falsify b2 one sets r1
b2 false. Hence,
get-P(1, G) = bI (r1 , b1 ) (hr1,b2 i) +
bI (r1 , b2 ) (hr1,b2 i) (hb2,b2 i) +
bI (r2 , b2 ) (hb2,b2 i)
= 0.63 0.91 + 0.27 0.91 1 + 0.08 1
= 0.899
verified get-P(1, G) < , loop proceeds construction time = 2,
calls build-timestep procedure = 1 A(1) = {ambr , aml } N OOP S. chance
nodes introduced Imp call build-timestep appear sixth column Figure 8.
first outer loop build-timestep results Imp given columns 1-7 Figure 8,


mbr
mbr
= (NbI ) mbr
(1)


(1)


(1)

1
2
3




mbr
mbr
mbr
mbr
mbr
mbr
(1)


(1)


(1)


(1)


(0)


(0)
1
2
1
3
2
3

(24)

Next, build-w-impleafs procedure called usual unknown fact p(2) (2) =
{r2(2) , b1 (2), b2 (2)}. information worth detailing leafs(Impb2 (2) ) =
mbr
{b2 (1), r1 (1), mbr
1 (1)}, support(b2 (2)) = {b2 (1), 1 (1)}. However, still
W
lsupport(p(2)) l p(2) (2), thus set known facts P (2) remains equal
P (1) = {r1 }.
592

fiP ROBABILISTIC -FF

Returning call build-w-impleafs procedure, build-PRPG proceeds checking
fixpoint termination condition. time, first three equalities condition hold, yet
condition satisfied due get-P(2, G) > get-P(t, G). see latter, notice
get-P(2, G) = WMC ( b2 ) ,
given Equation 24,


b2 = hr1,b2 hb2,b2 mbr
1 (1) (r1 (1) hr1,b2 i) (b2 (1) hb2,b2 i) ,

(25)



(hb2,b2 i) = b2 (1) (b2 (1)) = 1

.

(hr1,b2 i) = b2 (1) (r1 (1)) = 0.91
(mbr
1 (1))

=

b2 (1) (mbr
1 (1))

(26)

= 0.7

hard verify
get-P(2, G) = get-P(1, G) + bI (r2 , b1 ) (mbr
1 (1))
= 0.899 + 0.02 0.7
= 0.913
Note get-P(2, G) , therefore build-PRPG aborts loop
passing goal satisficing test, sets = 2. finalizes construction PRPG, thus,
example.
4.4 Extracting Probabilistic Relaxed Plan
construction PRPG succeeds reaching goals estimated probability success get-P(T, G) exceeding , extract relaxed plan consisting A(0), . . . , A(T
1), use size heuristic value evaluated belief state ba .
get technical details, consider key differences
relaxed (no delete lists) probabilistic planning one hand, relaxed classical relaxed qualitative conformant planning hand. relaxed probabilistic planning, might
make sense execute action numerous times consecutive time steps. fact,
might essential think throwing dice game 6 appears. contrast,
relaxed classical qualitatively uncertain settings needed effect
executed, remains true forever. Another complication probabilistic planning required
goal-achievement probability specified conjunction (or, possibly, complicated
logical combination) different facts. increasing probability achieving individual sub-goal g G relaxed planning always increase overall probability achieving G,
choosing right distribution effort among sub-goals pass required threshold
whole goal G non-trivial problem.
fundamental problem aforementioned lack guarantees weight propagation.
one hand, construction PRPG Lemma 5 imply a|+
1 concatenated
R
arbitrary linearization A(0), . . . , A(T 1) executable bI . hand, due
independence assumption made build-w-impleafs procedure, get-P(T, G)
593

fiD OMSHLAK & H OFFMANN

R
imply probability achieving G a|+
1 concatenated exceeds . real relaxed
plan, sense, might even exist constructed PRPG.
answer difficulties extract relaxed plans correct relative
weight propagation. Namely, use implication graph reduction algorithm computes
minimal subset graph still according weight propagation sufficiently
supports goal. relaxed plan corresponds subset. Obviously, solves
difficulty lack real relaxed plans; relaxed plan extraction according
independence assumption (besides ignoring deletes removing one condition
effect). mechanism also naturally takes care need apply action several times:
corresponds several implication graph edges needed order obtain sufficient
weight. choice effort distributed among sub-goals circumvented sense
sub-goals considered conjunction, is, reduction performed all.
course, remains choice parts implication graph removed.
found useful heuristic make choice based actions already
applied path belief. detail below.
Making another assumption top previous relaxations course bad heuristic
quality. relaxed plans extract guaranteed actually achieve desired goal probability. Since relaxed plans used search guidance, per se theoretical weakness
marginal importance. However, over-estimation goal probability might result bad
heuristic relaxed plan include right actions, apply often
enough. Section 5, discuss example domain Probabilistic-FF fails scale
precisely reason.
Figure 9 shows main routine extract-PRPlan extracting relaxed plan given
PRPG (note index highest PRPG layer, c.f. Figure 4). sub-routines
extract-PRPlan shown Figures 10-11. high level, extract-PRPlan procedure consists
two parts:

1. Reduction implication graph, aiming identifying set time-stamped action effects
ignored without decreasing estimate goal-achievement probability get-P(T, G)
desired threshold ,
2. Extraction valid relaxed plan ar (schematically) constructing PRPG ar instead
full set A(0), . . . , A(T ) would still result get-P(T, G) .
first part accomplished reduce-implication-graph procedure, depicted Figure 10.
first step algorithm, procedure considers parts implication graph
relevant achieving unknown sub-goals. Next, reduce-implication-graph performs
greedy iterative elimination actions future layers 0, . . . , 1 PRPG probability estimate get-P(T, G) reduced set actions goes . While, principle, action A(0), . . . , A(T 1) considered elimination, reduce-implication-graph examine repetitions actions already appear a. Specifically, reduce-implication-graph
iterates actions a|+
1 , repeats somewhere future layers PRPG,
one repetition a(t ) considered removal. removing repetition found safe
respect achieving ,12 effectively removed eliminating edges Imp
induced a(t ). procedure considers next repetition a. removing another
12. Note formula WMC constructed exactly get-P function, c.f. Figure 7.

594

fiP ROBABILISTIC -FF

procedure extract-PRPlan(P RP G(a, A, (NbI ), G, , |+
1 )),
selects actions A(0), . . . , A(T 1)
Imp := reduce-implication-graph()
extract-subplan(Imp )
sub-goal(G P (T ))
decreasing time steps := T, . . . , 1
g G(t)
A(t 1), e E(a), con(e) P (t 1), (e) : g add()
add-to-relaxed-plan one time
sub-goal(pre(a) con(e))
else
Imp g(t) := construct-support-graph(support(g(t)))
extract-subplan(Imp g(t) )
endif
endfor
endfor

Figure 9: Extracting probabilistic relaxed plan.
copy safe anymore, procedure breaks inner loop considers next
action.
procedure reduce-implication-graph()
operates PRPG;
returns sub-graph Imp.
Imp := gG\P (T ) Impg(T )
actions a|+
1
edges ((t ), p(t + 1)) Imp , induced a(t ) A(t ), 0
Imp := Imp
remove Imp edges induced A(t )
g G \ P (t)
l leafs(Imp g(T ) ), introduce chance proposition hlg weight g(T ) (l)
V
W
g := ( lleafs(Imp
) l) lleafs(Imp
)uP (m) (l hlg i)
g(T )

g(T )

endfor
V
WMC( gG\P (T ) g ) Imp := Imp else break endif
endfor
endfor
return Imp

Figure 10: procedure reducing implication graph.
illustrate intuition behind focus repetitions actions a, let us consider following example simple logistics-style planning problem probabilistic actions.
Suppose two locations B, truck known initially A, heavy
uneasy grab package known initially truck. goal package
unloaded B reasonably high probability, two actions use moving
truck B (am ), unloading package (au ). Moving truck necessarily
595

fiD OMSHLAK & H OFFMANN

move truck B, extremely high probability. hand, unloading bothersome package succeeds extremely low probability, leaving package
truck otherwise. Given data, consider belief state ba corresponding trying move
truck once, is, action sequence ham i. achieve desired probability success,
PRPG expanded large time horizon , allowing action au
applied sufficiently many times. However, fact truck B known belief state ba ,
thus implication graph also contain amount applications . Trimming
away applications still keep probability sufficiently high.
reader might ask point hope achieve trimming away
applications . point is, intuitively, implication graph reduction mechanism
means understand accomplished already, path ba . Without
understanding, relaxed planning quite indiscriminative search states. Consider
example, assume one two troubled packages, P 1 P 2,
truck, unload actions au1 au2 . PRPG ba contains copies au1 au2 layers
large horizon . Now, say search starts unload P 1. resulting belief, PRPG
still steps situation changed P 2. step PRPG still contains
copies au1 au2 hence heuristic value remains before!
words, without implication graph reduction technique, relevant things accomplished
may remain hidden behind things yet accomplished. example,
really critical because, soon tried unload P 1 P 2,
time horizon decreases one step, heuristic value reduced. is, however, often
case sub-task must accomplished sub-task attacked.
situations, without implication graph reduction, search staggers across huge plateau
first task completed. observed variety benchmarks, hence designed
implication graph reduction make relaxed planning aware already done.
course, since weight propagation may over-estimate true probabilities, hence overestimate achieved past, implication graph reduction may conclude prematurely
sub-task completed. leads us main open question research;
get back end Section 5, discuss context example
Probabilistic-FFs performance bad.
Let us get back explaining extract-PRPlan procedure. implication graph reduction, procedure proceeds relaxed plan extraction. process makes use proposition
sets G(1), . . . , G(T ), used store time-stamped sub-goals arising layers 1
relaxed plan extraction. sub-routine extract-subplan (Figure 11)
1. adds constructed relaxed plan time-stamped actions responsible edges
reduced implication graph Imp ,
2. subgoals everything outside implication graph condition applicability effects
responsible edges Imp .
later phases process, sub-goals added sets G(1), . . . , G(T )
sub-goal procedure simply inserts given proposition sub-goal first layer
appearance PRPG. accomplished extract-and-subgoal pass extract-subplan
Imp , also subgoal goal conjuncts known time .
next phase process, sub-goals considered layer layer decreasing order
time steps 1. sub-goal g time t, certain supporting actions selected
596

fiP ROBABILISTIC -FF

procedure extract-subplan(Imp )
actions helpful achieving uncertain goals G (T )
subgoals essential conditions actions
edge ((t), p(t + 1)) Imp 0
action effect e E(a) responsible time time
add-to-relaxed-plan time
sub-goal((pre(a) con(e)) P (t))
endif endfor
procedure sub-goal(P )
inserts propositions P sub-goals
layers first appearance PRPG
p P
t0 := argmint {p P (t)}
t0 1 G(t0 ) := G(t0 ) {p} endif
endfor
procedure construct-support-graph(support(g(t)))
takes subset support(g(t)) leafs(Impg(t) ) weighted according g(t);
returns sub-graph Imp Imp.

Imp :=
open := support(g(t))
open 6=
open := open \ {p(t )}
choose A(t ), e E(a), con(e) = {p}
(e) : (p(t ), (t )) Impg(t) g(t) ((t )) = ((t ))
(e)
choose q add() g(t) (q(t + 1)) = 1
Imp := Imp {(p(t ), (t )), ((t ), q(t + 1))}
open := open {q(t + 1)}
endfor endwhile
return Imp

Figure 11: Sub-routines extract-PRPlan.
relaxed plan. action effect e E(a) known applicable
time 1, guarantee achieve g certainty, added constructed relaxed
plan 1. Otherwise,
1. use construct-support-graph procedure extract sub-graph Imp g(t) consisting set
implications together ensure achieving g time t,
2. use already discussed procedure extract-subplan
(a) add constructed relaxed plan time-stamped actions responsible edges
Imp g(t) ,
(b) subgoal everything outside implication graph Imp g(t) condition applicability
effects responsible edges Imp g(t) .
597

fiD OMSHLAK & H OFFMANN

Processing way sub-goals G(1) finalizes extraction relaxed plan
estimate. Section 4.5 provides detailed illustration process PRPG constructed
Section 4.3. event, easy verify relaxed plan extract sound relative
weight propagation, following sense.
Proposition 7 Let (A, NbI , G, ) probabilistic planning task, sequence actions ap+
plicable bI , |+
1 relaxation function build-PRPG(a, A, (NbI ), G, , |1 )
returns TRUE. Let A(0)s , . . . , A(T 1)s actions selected A(0), . . . , A(T 1)
extract-PRPlan. constructing relaxed planning graph using A(0)s , . . . , A(T 1)s ,
get-P(T, G) .
Proof: construction: reduce-implication-graph leaves enough edges graph
weight propagation underlying get-P still concludes goal probability high enough.
4.5 Example: Extracting Relaxed Plan PRPG
illustrate process relaxed plan extraction PRPG Figure 8, constructed
belief state problem specification example Section 4.3. example
= 2, G (2) = {b2 }, thus implication graph Imp gets immediately reduced
sub-graph Imp depicted Figure 12a. plan belief state question consists
single action ambr , action instances considered elimination outer loop
reduce-implication-graph ambr (0) ambr (1). ambr (0) chosen examined,
implication sub-graph Imp = Imp reduced removing edges due ambr (0),
resulting Imp appears13 Figure 12b. b2 components evaluated formula
b2 given Equation 24 Equation 25, respectively, weights associated
chance propositions Equation 25 reduced implication graph Imp
(hb2,b2 i) = b2 (1) (b2 (1)) = 1
(hr1,b2 i) = b2 (1) (r1 (1)) = 0.7

.

(27)

mbr
(mbr
1 (1)) = b2 (1) (1 (1)) = 0.7

weight model counting b2 evaluates 0.724 < , thus Imp replace Imp .
alternative action removal ambr (1), seen example Section 4.3 attempt action elimination also result probability estimate lower .
Hence, effect reduce-implication-graph PRPG processed extract-PRPlan
procedure reduction implication graph edges relevant achieving {b2 }
time = 2. reduced implication sub-graph Imp returned reduce-implication-graph
procedure depicted Figure 12a.
Next, extract-subplan procedure iterates edges Imp adds initially
empty relaxed plan applications ambr times 0 1. action ambr preconditions,
E(ambr ) known time 1. Hence, extract-subplan
condition r1 effect mbr
1
invokes sub-goal procedure {r(1)}, latter added proposition set G(1).
subsequent call sub-goal(G P (T )) = sub-goal({r1 }) leads extensions G(2), G(1)
13. dashed edges Figure 12b removed Imp either latter stage Imp chosen replace
Imp .

598

fiP ROBABILISTIC -FF



mbr
88 1 (-1)
qq
]\
qqq
q
q
qq


// r1 (-1)
r1 (-1)



b2 (-1)



// b2 (-1)



// r1 (0)



mbr
88 1 (0)
rrr
]\
rrr
r
r

! //
b2 (0)



// b2 (0)





mbr
1 (1)

! //
b2 (1)

]\



// b2 (1)



! //
b2 (2)

(a)


mbr
88 1 (-1)
qq
]\
qqq
q
q
qq

r
r1 (-1) _ _ _ _// 1 (-1)_ _ _ _// r1 (0)

b2 (-1)



// b2 (-1)



!

// b2 (0)



mbr
1 (1)



// b2 (0)



// b2 (1)



// b2 (1)



]\

!

// b2 (2)

(b)


00 ml
(0)54

r1 (-1)



// r1 (-1)



r2 (-1)



// r2 (-1)



WV

r
01

// r1 (0)
// 1 (0)





RS

// r1 (1)

// r2 (0)

(c)
Figure 12: Illustrations various steps relaxed plan extraction PRPG constructed
Section 4.3, and, particular, implication graph latter, depicted
Figure 8.

already r1 G(1). Hence, outer loop extract-PRPlan starts G(2) = ,
G(1) = {r1 }.
Since G(2) empty, first sub-goal considered extract-PRPlanis r1 G(1). r1
time 1, action effect time 0 passes test statementthe condition r2 ml
known time 0, true14 r1 . Hence, subgoal r1 (1) processed
extracting sub-plan support achieving certainty. First, construct-support-graph
procedure called support(r1 (1)) = {r1 (1), r2 (1)} (see Section 4.3). extracted sub14. fact, easy see construction sub-goal procedure p belongs G(t), condition
noops effect p cannot known time 1.

599

fiD OMSHLAK & H OFFMANN

graph Imp r1 (1) original implication graph Imp depicted Figure 12c, invoking
procedure extract-subplan Imp r1 (1) results adding (i) application aml time 0, (ii)
new subgoals. Hence, proposition sets G(1), G(2) get emptied, thus end
extracting relaxed plan hambr (0), aml (0), ambr (1)i.

5. Empirical Evaluation
implemented Probabilistic-FF C, starting Conformant-FF code. = 1.0,
Probabilistic-FF behaves exactly like Conformant-FF (except Conformant-FF cannot handle
non-deterministic effects). Otherwise, Probabilistic-FF behaves described previous sections, uses Cachet (Sang et al., 2005) weighted model counting. better home
strengths weaknesses approach, empirical evaluation Probabilistic-FF
done two steps. Section 5.1 evaluate Probabilistic-FF problems non-trivial uncertain initial states, deterministic actions. Section 5.2 examine Probabilistic-FF
problems probabilistic action effects, sources uncertainty. compare
Probabilistic-FFs performance probabilistic planner POND (Bryce et al., 2006).
reasons choosing POND reference point twofold. First, similarly Probabilistic-FF,
POND constitutes forward-search planner guided non-admissible heuristic function based
(relaxed) planning graph computations. Second, knowledge, POND clearly
efficient probabilistic planner reported literature.15
experiments run PC running 3GHz 2GB main memory 2MB cache
running Linux. Unless stated otherwise, domain/problem pair tried four levels desired probability success {0.25, 0.5, 0.75, 1.0}. run planner time-limited
1800 seconds user time. Probabilistic-FF run default configuration inherited FF,
performing one trial enforced hill-climbing switching best-first search case failure.
domains without probabilistic effects, found Probabilistic-FFs simpler relaxed plan extraction developed case (Domshlak & Hoffmann, 2006), performs better one described
here. hence switch simpler version domains.16
Unlike Probabilistic-FF, heuristic computation POND element randomization;
namely, probability goal achievement estimated via sending set random particles
relaxed planning graph (the number particles input parameter). problem instance, averaged runtime performance POND 10 independent runs. special
cases POND timed runs certain problem instance, yet
10 runs, average report POND uses lower-bounding time threshold 1800s replace missing time points. cases, PONDs best-case performance differs lot
average performance; cases, best-case performance also reported. note that,
following suggestion Dan Bryce, POND run default parameter setting, and, par15. experiments used recent version 2.1 POND significantly enhances POND2.0 (Bryce et al.,
2006). authors would like thank Dan Bryce Rao Kambhampati providing us binary distribution
POND2.1.
16. Without probabilistic effects, relaxed plan extraction proceeds much like Conformant-FF, additional
straightforward backchaining selecting support unknown goals. complicated techniques developed
deal relaxed plan extraction probabilistic effects appear unstable behavior
simpler techniques. probabilistic effects, simple backchaining meaningful
information many times action must applied order sufficiently support goal.

600

fiP ROBABILISTIC -FF

= 0.25
t/|S|/l

= 0.5
t/|S|/l

= 0.75
t/|S|/l

= 1.0
t/|S|/l

70/71/140
70/70/138

1.39/19 /18
0.28/6/5

4.02/36/35
0.76/13/12

8.06/54/53
1.54/22/21

4.62/71 /70
4.32/70/69

Cube-uni-15
Cube-cub-15

6/90/3375
6/90/3375

3.25/145/26
0.56/41/8

3.94/150/34
1.16/70/13

5.00/169/38
1.95/109/18

25.71/296/42
26.35/365/42

Bomb-50-50
Bomb-50-10
Bomb-50-5
Bomb-50-1

2550/200/> 2100
510/120/> 260
255/110/> 255
51/102/> 251

0.01/1/0
0.00/1/0
0.00/1/0
0.00/1/0

0.10/17/16
0.89/248/22
1.70/468/27
2.12/662/31

0.25/37/36
4.04/778/62
4.80/998/67
6.19/1192/71

0.14/51/50
1.74/911/90
2.17/1131/95
2.58/1325/99

Log-2
Log-3
Log-4

3440/1040/> 2010
3690/1260 /> 3010
3960/1480/> 4010

0.90/117/54
2.85/159/64
2.46/138/75

1.07/152/62
8.80/328/98
8.77/391/81

1.69/205/69
4.60/336/99
6.20/377/95

1.84/295/78
4.14/364/105
8.26/554/107

Grid-2
Grid-3
Grid-4

2040/825 /> 3610
2040/841 /> 3610
2040/857 /> 3610

0.07/39/21
16.01/1629/76
28.15/2167/96

1.35/221/48
15.8/1119/89
51.58/2541/111

6.11/1207/69
82.24/3974/123
50.80/2541/115

6.14/1207/69
66.26/3974/123
193.47/6341/155

Rovers-7
RoversP-7
RoversPP-7
RoversPPP-7

393/97 /> 63 38
393/133 /> 63 38
393/133 /> 63 38
395/140 /> 63 38

0.01/ 37/18
2.15/942/65
8.21/948/65
25.77/950/67

0.01/ 37/18
2.23/983/75
12.48/989/75
41.18/996/79

0.01/ 37/18
2.37/1008/83
12.53/994/77
0.01/UNSAT

0.01/ 37/18
2.29/1008/83
16.20/1014/83
0.01/UNSAT

Instance

#actions/#facts/#states

Safe-uni-70
Safe-cub-70

Table 5: Empirical results problems probabilistic initial states. Times seconds, search
space size |S| (number calls heuristic function), plan length l.

ticular, includes number random particles (64) selected computing PONDs heuristic
estimate (Bryce et al., 2006).
5.1 Initial State Uncertainty Deterministic Actions
examine performance Probabilistic-FF POND collection domains
probabilistic initial states, deterministic action effects. consider domains one
one, discussing set runtime plots. problem instances, Table 5 shows
details, providing features instance size well detailed results Probabilistic-FF,
including number explored search states plan length.
first three domains probabilistic versions traditional conformant benchmarks: Safe,
Cube, Bomb. Safe, n combinations one opens safe. given probability
distribution combination right one. type action Safe trying
combination, objective open safe probability . experimented
two probability distributions n combinations, uniform one (Safe-uni) distribution
declines according cubic function (Safe-cub). Table 5 shows Probabilistic-FF
solve efficiently even n = 70. Figure 13 compares Probabilistic-FF
POND, plotting time performance identical linear scale, x-axes show number
combinations.
graphs easy see Probabilistic-FF outperforms POND least order
magnitude Safe-uni Safe-cub. interesting observation necessarily
difference time performance, relative performance planner Safe-uni
Safe-cub. Note Safe-cub somewhat easier Safe-uni sense that, Safe-cub, fewer
combinations must tried guarantee given probability opening safe.
601

fiD OMSHLAK & H OFFMANN

PFF

POND2.1

70

70
p=0.25
p=0.50
p=0.75
p=1.00

60

50

50

40

40

Time (sec)

Time (sec)

60

p=0.25
p=0.50
p=0.75
p=1.00

30

30

20

20

10

10

0

0
10

30

50

70

10

30

#combinations

50

70

#combinations

(a) Uniform prior distribution combinations.
PFF

POND2.1

70

70
p=0.25
p=0.50
p=0.75
p=1.00

60

50

50

40

40

Time (sec)

Time (sec)

60

p=0.25
p=0.50
p=0.75
p=1.00

30

30

20

20

10

10

0

0
10

30

50

70

10

#combinations

30

50

70

#combinations

(b) Cubic decay prior distribution combinations.
Figure 13: Safe domain, Probabilistic-FF (left) vs. POND (right).
dominant part probability mass lies combinations head cubic distribution
(the last combination probability 0 right combination, thus needs tried
even = 1.0). question whether heuristic functions Probabilistic-FF
POND exploit difference Safe-uni Safe-cub. Table 5 Figure 13 provide
affirmative answer question heuristic function Probabilistic-FF. picture
POND less clear times spent POND (otherwise identical) instances Safe-uni
Safe-cub roughly same.17
Another interesting observation that, Probabilistic-FF POND, moving =
1.0 < 1.0, is, planning qualitative uncertainty truly probabilistic planning,
17. Safe-cub n = 70 {0.75, 1.0}, POND undergoes exponential blow-up shown
graphs since data points would obscure data points; anyway, believe blow-up due
unfortunate troubles numerics.

602

fiP ROBABILISTIC -FF

PFF

POND2.1

30

1800
p=0.25
p=0.50
p=0.75
p=1.00

25

p=0.25
p=0.50
p=0.75
p=1.00

1600
1400
1200
Time (sec)

Time (sec)

20

15

10

1000
800
600
400

5
200
0

0
5

7

9
11
N Grid NxNxN

13

15

5

7

9
11
N Grid NxNxN

13

15

13

15

(a) Uniform prior distribution initial position.
PFF

POND2.1

30

1800
p=0.25
p=0.50
p=0.75
p=1.00

25

p=0.25
p=0.50
p=0.75
p=1.00

1600
1400
1200
Time (sec)

Time (sec)

20

15

10

1000
800
600
400

5
200
0

0
5

7

9
11
N Grid NxNxN

13

15

5

7

9
11
N Grid NxNxN

(b) Cubic decay prior distribution initial position.
Figure 14: Cube domain, Probabilistic-FF (left) vs. POND (right).

typically result performance decline. even get improved performance (except
= 0.75 Safe-uni). reason seems plans become shorter. trend
observed also domains. trend particularly remarkable Probabilistic-FF, since
moving = 1.0 < 1.0 means move case model counting needed
case needed. (In words, Probabilistic-FF automatically specializes
qualitative uncertainty, using model counting. knowledge, true
POND, uses techniques cases.)
Cube, task move corner 3-dimensional grid, actions correspond
moving current cube cell one (up 6) adjacent cube cells. Again, created
problem instances uniform cubic distributions (over initial position dimension),
again, Probabilistic-FF scales well, easily solving instances 15 15 15 cube. Within
time limit, POND capable solving Cube problems cube width 13. Figure 14
603

fiD OMSHLAK & H OFFMANN

compares Probabilistic-FF POND detail, plotting time performance
different linear scales (with x-axes capturing width grid dimension), showing
least order magnitude advantage Probabilistic-FF. Note that,
Probabilistic-FF generally becomes faster decreasing (with decreasing hardness
achieving objective), seem substantial effect performance
POND,
Probabilistic-FF exploits relative easiness Cube-cub (e.g., see Table 5), time
performance POND Cube-cub Cube-uni qualitatively identical.
also tried version Cube task move grid center. Probabilistic-FF
bad so, reaching performance limit n = 7. weakness Cube-center domain
inherited Conformant-FF. detailed Hoffmann Brafman (2006), reason
weakness lies inaccuracy heuristic function domain. two sources
inaccuracy. First, solve Cube-center reality, one must start moving corner
order establish position; relaxation, without delete lists, necessary. Second,
relaxed planning graph computation over-approximates achieved future
steps, also already achieved path considered belief state. even
moderately long paths actions, relaxed planning graph comes (wrong) conclusion
goal already achieved, relaxed plan becomes empty heuristic
information.
Next consider famous Bomb-in-the-Toilet domain (or Bomb, short). version
Bomb contains n bombs toilets, bomb may armed armed independently probability 1/n, resulting huge numbers initially possible world states. Dunking
bomb unclogged toilet disarms bomb, clogs toilet. toilet unclogged
flushing it. Table 5 shows Probabilistic-FF scales nicely n = 50, becomes faster
increases. latter logical desirable toilets means disarming
devices, resulting shorter plans needed. Figures 15 16 compare Probabilistic-FF
POND, plotting time performance Probabilistic-FF linear scale, POND
logarithmic scale. four pairs graphs correspond four choices number toilets
{50, 10, 5, 1}. x-axes graphs correspond number potentially armed
bombs, checked problems n {5, 10, 25, 50}. Figure 15 shows time
Probabilistic-FF least four orders magnitude faster POND; extremes,
hardest combination n = 50, = 1, = 0.75 took Probabilistic-FF less 7 seconds,
POND timed-out problem instances. addition,
Bomb well, Probabilistic-FF exhibit nice pattern improved performance
move non-probabilistic ( = 1.0) probabilistic planning (specifically, 0.5;
0.25, initial state good enough already).
performance Probabilistic-FF improves number toilets, POND seems
exhibit inverse dependence, is, sensitive number states
problem (see Table 5) rather optimal solution depth.
Finally, remark that, though length-optimality explicitly required probabilistic conformant planning, Safe, Cube, Bomb, Probabilistic-FFs plans optimal (the shortest
possible).
604

fiP ROBABILISTIC -FF

PFF

POND2.1

10
p=0.25
p=0.50
p=0.75
p=1.00

1000

8
100

Time (sec)

Time (sec)

6

4

10

1

2

0.1
p=0.25
p=0.50
p=0.75
p=1.00

0

0.01
5

10

25
# bombs

50

5

10

25
# bombs

50

(a) 50 toilets
PFF

POND2.1

10
p=0.25
p=0.50
p=0.75
p=1.00

1000

8
100

Time (sec)

Time (sec)

6

4

10

1

2

0.1
p=0.25
p=0.50
p=0.75
p=1.00

0

0.01
5

10

25
# bombs

50

5

10

25
# bombs

50

(b) 10 toilets
Figure 15: Bomb domain, Probabilistic-FF (left) vs. POND (right).

next three domains adaptations benchmarks deterministic planning: Logistics,
Grid, Rovers. assume reader familiar domains. Logistics-x
instance contains 10 cities, 10 airplanes, 10 packages, city x locations.
packages chance 0.88 airport origin city, uniformly
locations city. effects loading unloading actions conditional (right)
position package. Note higher values x increase space world states,
also initial uncertainty. Grid complex grid world run AIPS98 planning competition (McDermott, 1998), featuring locked positions must opened matching keys.
Grid-x modification instance nr. 2 (of 5) run AIPS98, 6 6 grid, 8 locked
positions, 10 keys 3 must transported goal position. lock x possible, uniformly distributed shapes, 3 goal keys x possible, uniformly distributed
initial positions. effects pickup-key, putdown-key, open-lock actions conditional.
605

fiD OMSHLAK & H OFFMANN

PFF

POND2.1

10
p=0.25
p=0.50
p=0.75
p=1.00

1000

8
100

Time (sec)

Time (sec)

6

4

10

1

2

0.1
p=0.25
p=0.50
p=0.75
p=1.00

0

0.01
5

10

25
# bombs

50

5

10

25
# bombs

50

(c) 5 toilets
PFF

POND2.1

10
p=0.25
p=0.50
p=0.75
p=1.00

1000

8
100

Time (sec)

Time (sec)

6

4

10

1

2

0.1
p=0.25
p=0.50
p=0.75
p=1.00

0

0.01
5

10

25
# bombs

50

5

10

25
# bombs

50

(d) 1 toilet
Figure 16: Bomb domain, Probabilistic-FF (left) vs. POND (right).

Finally, last set problems comes three cascading modifications instance nr. 7 (of
20) Rovers domain used AIPS02 planning competition. problem instance 6
waypoints, 3 rovers, 2 objectives, 6 rock/soil samples. Rovers RoversPPP modify
instance/domain follows.
Rovers original AIPS02 problem instance nr. 7, use hear mainly comparison.
RoversP, sample chance 0.8 original waypoint, chance 0.1
others two waypoints. objective may visible 3 waypoints
uniform distribution (this probabilistic adaptation domain suggested Bryce &
Kambhampati, 2004).
606

fiP ROBABILISTIC -FF

Sandcastle

Sandcastle

0.5
PFF
POND

PFF
POND (min)
POND (avg)
100

0.4

10
Time (sec)

Time (sec)

0.3

0.2

1

0.1

0.1

0

0.01
0.2

0.3

0.4

0.5

0.6


0.7

0.8

0.9

0.2

(a)

0.3

0.4

0.5

0.6


0.7

0.8

0.9

(b)

Figure 17: Probabilistic-FF POND problems (a) Sand-Castle, (b) SlipperyGripper.

RoversPP enhances RoversP conditional probabilities initial state, stating whether
objective visible waypoint depends whether rock sample (intuition: large piece rock) located waypoint. probability visibility much
higher latter case. Specifically, visibility objective depends
locations two rock samples, rock sample present, visibility probability
drops 0.1.
RoversPPP extends RoversPP introducing need collect data water existence.
soil samples certain probability (< 1) wet. communicated
sample data, additional operator tests whether sample wet. so, fact knowthat-water contained goal set true. probability wet depends
location sample.
show runtime plots Logistics, Grid, Rovers, since POND runs either time
memory considered instances domains. Table 5 shows scaling behavior
Probabilistic-FF three domains similar observed previous domains.
goals RoversPPP problem cannot achieved probabilities {0.75, 1.0}.
proved Probabilistic-FFs heuristic function, providing correct answer split seconds.
5.2 Probabilistic Actions
first two domains probabilistic actions famous Sand-Castle (Majercik & Littman,
1998) Slippery-Gripper (Kushmerick et al., 1995) domains. domains simple,
posed first challenges probabilistic planners; performance domains serves
indicator progress relative previous ideas probabilistic planning.
Sand-Castle, states specified two boolean variables moat castle, state
transitions given two actions dig-moat erect-castle. goal erect castle.
607

fiD OMSHLAK & H OFFMANN

1D-walkgrid

2D-walkgrid

PFF
POND

1000

100

100

10

10

Time (sec)

Time (sec)

1000

1

1

0.1

0.1

0.01

0.01

PFF
POND
5

6

7

8

9

10

3

Grid width

(a)

4

5

6
7
Grid width

8

9

10

(b)

Figure 18: Probabilistic-FF POND problems (a) 1D-WalkGrid = 0.9, (b)
2D-WalkGrid = 0.01.

Building moat dig-moat might fail probability 0.5. Erecting castle erect-castle
succeeds probability 0.67 moat already built, probability 0.25, otherwise. failed, erect-castle also destroys moat probability 0.5. Figure 17(a) shows
Probabilistic-FF POND solve problem less second arbitrary high values
, performance planners almost independent required probability
success.
Slippery-Gripper already bit complicated domain. states Slippery-Gripper
specified four boolean variables grip-dry, grip-dirty, block-painted, block-held,
four actions dry, clean, paint, pickup. initial state, block neither painted
held, gripper clean, gripper dry probability 0.7. goal
clean gripper holding painted block. Action dry dries gripper probability 0.8. Action
clean cleans gripper probability 0.85. Action paint paints block probability 1,
makes gripper dirty probability 1 block held, probability 0.1
not. Action pickup picks block probability 0.95 gripper dry,
probability 0.5 gripper wet.
Figure 17(b) depicts (on log-scale) relative performance Probabilistic-FF POND
Slippery-Gripper function growing . performance Probabilistic-FF nicely flat
around 0.06 seconds. time, comparison POND somewhat problematic, because,
fixed , POND Slippery-Gripper exhibited huge variance runtime. Figure 17(b)
plot best runtimes POND, well average runtimes. best run-times POND
different values vary around couple seconds, average runtimes significantly
worse. (For high values POND timed-out sample runs, thus plot provides
lower bound average runtimes.)
next two domains, 1D-WalkGrid 2D-WalkGrid, robot pre-plan sequence conditional movements taking corner grid farthest (from initial
608

fiP ROBABILISTIC -FF

position) corner (Hyafil & Bacchus, 2004). 1D-WalkGrid grid one-dimensional,
2D-WalkGrid grid two-dimensional. Figure 18(a) depicts (on log-scale) snapshot
relative performance Probabilistic-FF POND one-dimensional grids width n
= 0.9. robot initially (1, 1), get (1, n), try moving two
possible directions. two movement actions moves robot right direction
probability 0.8, keeps place probability 0.2. easy see Figure 18(a)
difference two planners domain substantialwhile runtime ProbabilisticFF grows linearly x, dependence POND seemingly exponential.
2D-WalkGrid domain already much challenging probabilistic planning.
2D-WalkGrid problems n n grids robot initially (1, 1), get (n, n),
try moving four possible directions. four movement actions advances
robot right direction probability 0.8, opposite direction probability 0,
either two directions probability 0.1. Figure 18(a) depicts (on log-scale)
snapshot relative performance Probabilistic-FF POND 2D-WalkGrid
low required probability success = 0.01, function grids width n.
plot shows Probabilistic-FF still scales well increasing n (though linearly anymore),
POND time-outs grid widths n > 3. higher values , however, Probabilistic-FF
reach time-out limit rather small grids, notably n = 6 n = 5 = 0.25
= 0.5, respectively. reason Probabilistic-FFs heuristic function good
enough estimating many times, early point plan, probabilistic action must
applied order sufficiently support high goal threshold end plan. explain
phenomenon detail end section, find also appears variant
well-known Logistics domain.
last set problems comes standard Logistics domain. problem instance
x-y-z contains x locations per city, cities, z packages. see Probabilistic-FF
scales much worse, Logistics, presence probabilistic effects initial
state uncertainty (we explain reason end section). Hence use much
smaller instances ones used Section 5.1. Namely, allow direct comparison
previous results domain, closely follow specification Hyafil Bacchus (2004).
use instances configurations x-y-z = 2-2-2, 4-2-2, 2-2-4, distinguish two
levels uncertainty.
L-x-y-z correspond problems uncertainty outcome load unload
actions. Specifically, probabilities success load 0.875 trucks 0.9
airplanes, unload, 0.75 0.8, respectively.
LL-x-y-z extends L-x-y-z independent uniform priors initial location
package within start city.
Figure 19 depicts (on log scale) runtimes Probabilistic-FF POND L-2-2-2, L-4-2-2,
L-2-2-4, function growing . problems, planners appear scale well,
runtime Probabilistic-FF optimal runtime POND roughly same,
average runtime POND somewhat degrading 2-2-2 4-2-2 2-2-4. shows
planners much efficient domain previously known SAT CSP
based techniques. However, moving LL-x-y-z changes picture planners. results
follows:
609

fiD OMSHLAK & H OFFMANN

L-2-2-2

L-4-2-2

100

PFF
POND (min)
POND (avg)

1

0.1

10

Time (sec)

10

Time (sec)

Time (sec)

100
PFF
POND (min)
POND (avg)

10

0.01
0.01

L-2-2-4

100
PFF
POND (min)
POND (avg)

1

0.1

0.25

0.5


(a)

0.75

0.95

0.01
0.01

1

0.1

0.25

0.5


(b)

0.75

0.95

0.01
0.01

0.25

0.5

0.75

0.95



(c)

Figure 19: Probabilistic-FF POND problems Logistics (a) L-2-2-2, (b) L-4-2-2,
(c) L-2-2-4.

1. LL-2-2-2, runtimes Probabilistic-FF identical L-2-2-2,
optimal runtimes POND slightly degraded 28 seconds. However, examined
values , runs POND resulted timeouts.
2. LL-4-2-2, runtimes Probabilistic-FF identical L-4-2-2
{0.01, 0.25, 0.5, 0.75}, yet Probabilistic-FF time-outed = 0.95. optimal runtimes
POND degraded L-4-2-2 9 18 seconds, again, values
, runs POND resulted timeouts.
3. LL-2-2-4, Probabilistic-FF experienced hard times, finishing 0.19 seconds =
0.01, time-outing examined values . optimal runtimes POND
degraded L-2-2-4 120 700 seconds, well, values ,
runs POND resulted timeouts.
also tried variant LL-x-y-z non-uniform priors initial locations packages, resulted qualitatively similar picture absolute relative performance.
LL-x-y-z domain remains challenging, deserves close attention future developments probabilistic planning. context, interesting close look
reasons failure Probabilistic-FF is. turns Probabilistic-FF good enough
estimating many times, early point plan, probabilistic action must applied
order sufficiently support high goal threshold end plan. make concrete,
consider Logistics example uncertain effects load unload actions. Consider package P must go city city B. Lets say P initially airport.
goal threshold high, means that, able succeed, package brought
airport high probability loading onto airplane. exactly point
Probabilistic-FFs heuristic function fails. relaxed plan contains actions unloading P
airport. effect search proceeds quickly loading P onto plane
bringing B. search gets point B unloaded goal location, goal threshold cannot achieved matter many times one unloads P. point,
610

fiP ROBABILISTIC -FF

Probabilistic-FFs enforced hill-climbing enters loop eventually fails relaxed plan
(which over-estimates past achievements) becomes empty.18
challenge devise methods better recognizing many times P
unloaded airport order sufficiently support goal threshold. error made
Probabilistic-FF lies propagation weights implication graph over-estimates
goal probability. Note much critical actions must applied early
plan, actions applied later. action appears early plan,
relaxed plan, executed, long. Recall weight propagation proceeds
backwards, goal towards current state. single backwards step, propagation
makes approximation might lose precision results. several backwards steps,
imprecisions accumulate. Hence quality approximation decreases quickly
number backwards steps. longer distance goal current state is,
information lost. observed phenomenon detailed experiments different
weight propagation schemes, is, different underlying assumptions. propagation
schemes tried, independence assumption, presented paper, far
accurate one. schemes failed deliver good results even much shorter distances
goal current state.
interesting consider issue affects POND, uses different method
estimating probability goal achievement: instead performing backwards propagation
aggregation weight values, POND sends set random particles relaxed planning
graph forward fashion, stops graph building enough particles end goal.
empirical results, seems method suffers similar difficulties Probabilistic-FF,
large extent. PONDs optimal runtimes LL-x-y-z much higher
L-x-y-z. indicates always challenging POND recognize need
applying action many times early plan. interestingly, POND never times-out
L-x-y-z, often time-out LL-x-y-z. indicates that, extent, matter
chance whether PONDs random particles recognize need applying action
many times early plan. intuitive explanation good cases
sufficiently many particles failed reach goal due taking wrong effect a.
Based intuition, one would expect helps increase number random particles
PONDs heuristic function. so, running POND LL-x-y-z increased number
particles, 200 600 instead default value 64. surprise, qualitative behavior
POND change, time-outing similar number cases. unclear us reason
phenomenon is. Certainly, observed situation encoded LL-x-y-z
solved satisfaction either Probabilistic-FFs weight propagation PONDs random particle
methods, current configurations.
time writing, unclear authors better methods could devised. seems
unlikely weight propagation least one resort expensive reasoning exists
manages long distances better independence assumption. alternative way
might simply define weaker notion plans allows repeat certain kinds actions
18. happen L-2-2-2, L-4-2-2, L-2-2-4 instances simply small
high goal probability achieved without thinking much problem; one increases size
instances, problem appears. problem appears earlier presence initial state uncertainty even
small instances LL-2-2-2, LL-4-2-2, LL-2-2-4 uncertainty start position
packages one needs try unloading start airports often.

611

fiD OMSHLAK & H OFFMANN

throwing dice unloading package arbitrarily many times. However, since assumption
observability plan execution, executing plan would
still arise question often action tried. Since Logistics fairly well-solved
domain simpler formalisms virtue Probabilistic-FF, even probabilistic setting
long effects deterministic consider addressing problem quite pressing open
question.

6. Conclusion
developed probabilistic extension Conformant-FFs search space representation, using
synergetic combination Conformant-FFs SAT-based techniques recent techniques
weighted model counting. provided extension conformant relaxed planning
approximate probabilistic reasoning. resulting planner scales well range benchmark domains. particular outperforms close relative, POND, least order magnitude
almost cases tried.
point may somewhat obvious, would like emphasize achievements
solve (this particular) problem all. Probabilistic-FF inherits strengths
weaknesses FF Conformant-FF, like domains FFs Conformant-FFs heuristic
functions yield bad estimates (e.g. mentioned Cube-center variant). Whats more, probabilistic setting introduces several new potential impediments FFs performance. one thing,
weighted model counting inherently harder SAT testing. Though happen
set benchmarks, bound cases cost exact model counting becomes
prohibitive even small examples. promising way address issue lies recent methods
approximate model counting (Gomes, Sabharwal, & Selman, 2006; Gomes, Hoffmann, Sabharwal, & Selman, 2007). methods much efficient exact model counters.
provide high-confidence lower bounds number models. lower bounds used
Probabilistic-FF place exact counts. shown good lower bounds
high confidecne achieved quickly. challenge extend methods
currently designed non-weighted CNFs handle weighted model counting.
importantly perhaps, presence probabilistic effects fundamental weakness Probabilistic-FFs PONDs heuristic information. becomes pitfall performance even straightforward adaptation Logistics domain, otherwise easy
kind planners. outlined, key problem that, obtain high enough confidence
goal achievement, one may apply particular actions several times early plan.
Neither Probabilistic-FFs PONDs heuristics good enough identifying many times.
view, finding techniques address issue currently important open topic
area.
Apart addressing latter challenge, intend work towards applicability real-word
settings. Particularly, look space application settings Rovers domain hints at,
medication-type treatment planning domains, power supply restoration domain (Bertoli,
Cimatti, Slaney, & Thiebaux, 2002).
612

fiP ROBABILISTIC -FF

Acknowledgments
authors would like thank Dan Bryce Rao Kambhampati providing binary distribution POND2.1. Carmel Domshlak partially supported Israel Science Foundations
grant 2008100, well C. Wellner Research Fund. major parts research
accomplished time Jorg Hoffmann employed Intelligent Information
Systems Institute, Cornell University.

Appendix A. Proofs
Proposition 2 Let (A, NbI , G, ) probabilistic planning problem described k state variables, m-step sequence actions A. Then, |Nba | = O(|NbI |+m(k+1))
largest description size action A.
Proof: proof rather straightforward, exploits local structure Nba CPTs.
first nodes/CPTs layer X(0) Nba constitutes exact copy NbI . Then, 1 m,
t-th layer Nba contains k + 1 node {Y(t) } X(t) .
First, let us consider action node Y(t) . specifying CPT TY (t) straightforward
manner prescribed Eq. 4 might result exponential blow up, Eq. 4 suggests
original description compact specification TY (t) . Therefore, TY (t)
described space O(), description efficiently used answering queries
TY (t) (Y(i) = | ) Eq. 4. Next, consider CPT TX(t) state-variable node X(t) X(t) .
time, rather evident Eq. 5 TX(t) described space O() queries
TX(t) (X(t) = x | X(t1) = x ) could efficiently answered. Thus, summing layers
1 m, description size |Nba | = O(|NbI | + m(k + 1))
Lemma 4 Given node v(t ) Impp(t) , p(t) (v(t )) = (v(t )) if, given v
time , sequence effects E(Impv(t )p(t) ) achieves p probability 1.
Proof: proof Lemma 4 backward induction time layers Impv(t )p(t) .
time t, node Impp(t) time-stamped p(t) itself. node
p(t) (p(t)) = (p(t)) = 1, but, given p time t, empty plan corresponding (empty)
E(Impp(t)p(t) ) trivially re-establishes p certainty. Assuming claim holds
nodes Impp(t) time stamped + 1, . . . , t, show holds nodes
time stamped .
easy see that, node v(t ) Impp(t) , get p(t) (v(t )) = (v(t ))
goes zero. First, consider chance nodes (t ) Impvp(t) . node, lb
set zero p(t) (r(t + 1)) = 1 r add(). However,
inductive assumption, case effects E(Imp(t )p(t+1) ) achieve p
probability 1, given occurrence time .
Now, consider fact nodes q(t ) Impvp(t) . node, get nullified
effect e E(a), A(t ), con(e) = q. latter happens if, possible outcomes e, (i) node (t ) belongs Impp(t) , (ii) estimate p(t) ((t )) = ((t )).
words, inductive assumption, given outcome (e) time , effects E(Imp(t )p(t) ) achieve p probability 1. Thus, given q time , effects
E(Impq(t )p(t) ) achieve p probability 1 independently actual outcome e. Alternatively, q(t ) lb > 0, effect e conditioned q(t), exists
613

fiD OMSHLAK & H OFFMANN

outcome e that, according proved chance nodes time-stamped
, effects E(Imp(t )p(t+1) ) achieve p probability 1. Hence, whole set
effects E(Impq(t )p(t+1) ) achieve p probability 1.
Lemma 5 Let (A, NbI , G, ) probabilistic planning task, sequence actions applicable
bI , |+
1 relaxation function A. time step m, proposition p
P, P (t) constructed build-PRPG(a, A, (NbI ), G, , |+
1 ), p time achieved
relaxed plan starting a|+
1
(1) probability > 0 (that is, p negatively known time t) p (t)P (t),

(2) probability 1 (that is, p known time t) p P (t).
Proof: proof direction straightforward induction t. = claim
immediate direct initialization (m) P (m). Assume that, < t,
p (t ) P (t ), p negatively known time , p P (t ), p known
time .
First, consider p(t) (t) P (t), suppose p egatively know time t.
inductive assumption, property PRPG construction (t 1) P (t 1)
(t) P (t), p 6 (t 1) P (t 1). Therefore, p added (t) (and
then, possibly, moved P (t)) first loop build-timestep procedure.
However, so, exists action A(t 1), e E(a), (e) (i)
con(e) (t 1) P (t 1), (ii) p add(). Again, assumption induction
pre(a) known time 1, con(e) negatively known time 1. Hence,
non-zero probability occurring time implies p achieved time probability
greater 0, contradicting p negatively know time t.
Now, let us consider p(t) P (t). Notice that, > m, p(t) P (t)

_
l .
(28)

lsupport(p(t))

Thus, world state w consistent bI , either q w fact proposition
q(m) support(p(t)), or, effect e action a(t ) A(t ), < t, con(e)
P (t ) {(t ) | (e)} support(p(t)). first case, Lemma 4 immediately implies
concatenation a|+
1 arbitrary linearization (relaxed) actions A(0), . . . , A(t 1)
achieves p probability 1, thus p known time t. second case, inductive
assumption implies con(e) known time t, together Lemma 4 implies
concatenation a|+
1 arbitrary linearization (relaxed) actions A(0), . . . , A(t 1)
achieves p probability 1.
proof direction induction well. = claim
immediate direct initialization P (m). Assume that, < t, p
negatively known time , p (t ) P (t ), p known time , p P (t ).
First, suppose p negatively known time t, yet p 6 (t) P (t).
inductive assumption plus A(t 1) containing NOOP actions propositions
(t 1) P (t 1), know p negatively known time 1. so, p become
negatively known time due (e), e E(a), pre(a) known
614

fiP ROBABILISTIC -FF

time 1, con(e) negatively known time 1. inductive assumption,
latter conditions imply con(e) (t 1) P (t 1), pre(a) P (t 1). so, p
added (t) P (t) first loop build-timestep procedure, contradicting
assumption p 6 (t) P (t).
Now, let us consider p known time t. inductive assumption, P (t 1) contains
facts known time 1, thus A(t 1) maximal subset actions A|+
1 applicable
time 1. Let us begin exhaustive classification effects e actions A(t 1)
respect p time t.
(I) (e) : p add(), con(e) P (t 1)
(II) (e) : p add(), con(e) (t 1)
(III) (e) : p 6 add() con(e) 6 P (t 1) (t 1)
set (I) empty, then, construction build-w-impleafs(p(t), Imp),
{(t 1) | (e)} support(p(t)),
e (I). Likewise, construction build-timestep (notably, update ),
e (I),
_

(t 1).
{(t1)|(e)}

Putting two facts together, Eq. 28 holds p time t, thus p P (t).
Now, suppose set (I) empty. hard verify subset effects (III)
makes p known time t. Thus, event least one effects (II) occurs must hold
probability 1. First, construction build-w-impleafs(p(t), Imp),
[
support (p(t))
support (con(e)(t 1))
e(II)

Then, 4 Lemma 4 event least one effects (II) occurs holds
probability 1
_

l
e(II)
lsupport(con(e)(t1))

Putting two facts together, Eq. 28 holds p time t, thus p P (t).

Theorem 6 Let (A, NbI , G, ) probabilistic planning task, sequence actions appli+
cable bI , |+
1 relaxation function A. build-PRPG(a, A, (NbI ), G, , |1 ) returns
+
FALSE, relaxed plan (A, bI , G, ) starts a|1 .
Proof: Let > 0 last layer PRPG upon termination build-PRPG. every
t, construction PRPG Lemma 5, sets P (t ) (t ) contain
(and all) propositions known (respectively unknown) executing actions
action layers including A(t 1).
615

fiD OMSHLAK & H OFFMANN

First, let us show build-PRPG returns FALSE, corresponding termination criterion would hold future iterations. P (t + 1) = P (t), A(t + 1) = A(t).
Subsequently, since P (t + 1) (t + 1) = P (t) (t) A(t + 1) = A(t),
P (t + 2) (t + 2) = P (t + 1) (t + 1). Given that, show P (t + 2) = P (t + 1)
(t + 2) = (t + 1).
Assume contrary exists p(t + 2) P (t + 2) p(t + 1) 6 P (t + 1),
p(t + 1) (t + 1). construction sets P (t + 1) P (t + 2) build-timestep
procedure,
_

l ,
lsupport(p(t+2))

_

6

(29)

l

lsupport(p(t+1))

Consider exhaustive classification effects e actions A(t + 1) respect p
time + 2.
(I) (e) : p add(), con(e) P (t + 1)
(II) (e) : p add(), con(e) (t + 1)
(III) (e) : p 6 add() con(e) 6 P (t + 1) (t + 1)
Suppose set (I) empty, let e (I). P (t) = P (t + 1) con(e)
P (t), thus {(t)
W | (e)} support(p(t + 1)).
W update build-timestep
{(t)|(e)} (t), thus lsupport(p(t+1)) l, contradicting Eq. 29.
Alternatively, assume set (I) empty. Using arguments similar proof
Lemma 5, p(t + 2) P (t + 2) p(t + 1) 6 P (t + 1) case imply
_
l

e(II)
lsupport(con(e)(t+1))

_

6

(30)

l

e(II)
lsupport(con(e)(t))

However, A(t + 1) = A(t), (t + 1) = (t), P (t + 1) = P (t) together imply
action effects possibly take place time + 1 also feasible take place time
t. Therefore, since e (II) con(e) (t + 1) definition (II), Eq. 30
implies
[
[
support (con(e)(t + 1)) (m) 6=
support (con(e)(t)) (m),
(31)
e(II)

e(II)

contradicting termination condition. Hence, arrived contradiction assumption
p(t + 1) 6 P (t + 1).
shown P (t + 2) = P (t + 1) (t + 2) = (t + 1), show
termination criteria implies that, q(t + 2) (t + 2),
(m) support(p(t + 2)) = (m) support(p(t + 1)).
616

fiP ROBABILISTIC -FF

Let Ep(t+2) set effects actions A(t + 1) con(e) (t + 1), and,
outcome (e), p add(). Given that,
(m) support(p(t + 2)) = (m)

[

support(con(e)(t + 1))

[

support(con(e)(t))

eEp(t+2)

= (m)

,

(32)

eEp(t+2)

= (m) support(p(t + 1))
first third equalities definition support sets via Lemma 4, second
equation termination condition.
last things remains shown termination criteria implies get-P(t +
2, G) =get-P(t + 1, G). Considering simple cases first, G 6 P (t + 1) (t + 1),
P (t + 2) (t + 2) = P (t + 1) (t + 1) get-P(t + 2, G) =get-P(t + 1, G) = 0. Otherwise, G P (t + 1), P (t + 2) = P (t + 1) get-P(t + 2, G) =get-P(t + 1, G) = 1.
leaves us case G P (t + 1) (t + 1) G (t + 1) 6= .
P (t + 2) = P (t + 1), (t + 2) = (t + 1), termination condition,
G (t) = G (t + 1) = G (t + 2).
get-P(t + 1, G) =get-P(t, G) know action effects become feasible A(t)
increase estimate probability achieving g G (t + 1) time time
+ 1. However, P (t + 1) = P (t), (t + 1) = (t), A(t + 1) = A(t),
action effect become feasible time + 1 already feasible time t, thus
get-P(t + 1, G) =get-P(t, G) imply get-P(t + 2, G) =get-P(t + 1, G).
point shown build-PRPG returns FALSE, corresponding termination criterion would hold future iterations. Now, assume contrary claim
theorem build-PRPG returns FALSE iteration t, yet exists relaxed plan
(A, bI , G, ) starts a|+
1 . First, = 1, Lemma 5 implies exists time
G P (T ). so, persistence negative termination condition implies
G P (t). However, case would get-P(t, G) = 1 (see second get-P
procedure), thus build-PRPG would return TRUE ever getting check negative
termination condition iteration t. Alternatively, = 0, build-PRPG would terminated
returning TRUE negative termination condition checked even once.
leaves us case 0 < < 1 get-P(t, G) < . (get-P(t, G)
contradict reaching negative termination condition iteration t.) also assume
G P (t) (t) P (t) (t) contains facts negatively known time
t, thus persistence negative termination condition together G 6 P (t) (t) would
imply relaxed plan > 0. Let us consider sub-goals G (t) 6= .
(1) subgoals g G (t), implications Impg(t) due deterministic
outcomes effects E(Impg(t) ), uncertainty achieving G (t) time
due uncertainty initial state. Since initial
V belief state reasoned
relaxation, case get-P(t, G) = WMC( gG\P (t) g ) provides us
upper bound probability achieving goal G a|+
1 concatenated
617

fiD OMSHLAK & H OFFMANN

arbitrary linearization arbitrary subset A(0), . . . , A(t 1). termination subcondition get-P(t + 1, G) =get-P(t, G) persistence action sets A(T ), t,
imply get-P(t, G) provides us upper bound probability achieving G
a|+
1 concatenated arbitrary linearization arbitrary subset A(0), . . . , A(T ),
t. Together get-P(t, G) < , latter conclusion contradicts assumption
desired relaxed plan exists.
(2) exists subgoal g G (t) implications Impg(t) due truly
probabilistic outcomes effects E(Impg(t)
actions A(t)
V ), repeating (relaxed) V
A(t + 1) necessarily result WMC( gG\P (t+1) g ) > WMC( gG\P (t) g ),
contradicting termination sub-condition condition get-P(t + 1, G) =get-P(t, G).
Hence, arrived contradiction assumption build-PRPG returns FALSE time t,
yet exists relaxed plan (A, bI , G, ) starts a|+
1.

References
Bertoli, P., Cimatti, A., Pistore, M., Roveri, M., & Traverso, P. (2001). MBP: model based planner.
Proc. IJCAI01 Workshop Planning Uncertainty Incomplete Information,
Seattle, WA.
Bertoli, P., Cimatti, A., Slaney, J., & Thiebaux, S. (2002). Solving power supply restoration problems planning via symbolic model-checking. Proceedings 15th European Conference Artificial Intelligence (ECAI), pp. 576580, Lion, France.
Blum, A. L., & Furst, M. L. (1997). Fast planning planning graph analysis. Artificial
Intelligence, 90(1-2), 279298.
Bonet, B., & Geffner, H. (2001). Planning heuristic search. Artificial Intelligence, 129(12),
533.
Bonet, B., & Geffner, H. (2000). Planning incomplete information heuristic search belief
space. Proceedings 5th International Conference Artificial Intelligence Planning
Scheduling Systems (AIPS), pp. 5261, Breckenridge, CO.
Boutilier, C., Friedman, N., Goldszmidt, M., & Koller, D. (1996). Context-specific independence
Bayesian networks. Proceedings Twelfth Conference Uncertainty Artificial
Intelligence (UAI), pp. 115123, Portland, OR.
Brafman, R. I., & Domshlak, C. (2006). Factored planning: How, when, not. Proceedings 18th National Conference Artificial Intelligence (AAAI), pp. 809814, Boston,
MA.
Bryce, D., & Kambhampati, S. (2004). Heuristic guidance measures conformant planning.
Proceedings 14th International Conference Automated Planning Scheduling
(ICAPS), pp. 365374, Whistler, BC, Canada.
Bryce, D., Kambhampati, S., & Smith, D. (2006). Sequential Monte Carlo probabilistic planning
reachability heuristics. Proceedings 16th International Conference Automated
Planning Scheduling (ICAPS), pp. 233242, Cumbria, UK.
618

fiP ROBABILISTIC -FF

Chavira, M., & Darwiche, A. (2005). Compiling Bayesian networks local structure. Proceedings 19th International Joint Conference Artificial Intelligence (IJCAI), pp.
13061312, Edinburgh, Scotland.
Darwiche, A. (2000). Recursive conditioning. Artificial Intelligence, 125(1-2), 541.
Darwiche, A. (2001). Constant-space reasoning dynamic Bayesian networks. International Journal Approximate Reasoning, 26(3), 161178.
Dean, T., & Kanazawa, K. (1989). model reasoning persistence causation. Computational Intelligence, 5, 142150.
Dechter, R. (1999). Bucket elimination: unified framework reasoning. Artificial Intelligence,
113, 4185.
Domshlak, C., & Hoffmann, J. (2006). Fast probabilistic planning weighted model counting. Proceedings 16th International Conference Automated Planning
Scheduling (ICAPS), pp. 243252, Cumbria, UK.
Gomes, C. P., Hoffmann, J., Sabharwal, A., & Selman, B. (2007). sampling model counting.
Proceedings 20th International Joint Conference Artificial Intelligence (IJCAI07), Hyderabad, India.
Gomes, C. P., Sabharwal, A., & Selman, B. (2006). Model counting: new strategy obtaining good bounds. Proceedings 21th National Conference Artificial Intelligence
(AAAI-06), pp. 5461, Boston, MA.
Hanks, S., & McDermott, D. (1994). Modeling dynamic uncertain world I: Symbolic
probabilistic reasoning change. Artificial Intelligence, 66(1), 155.
Hoffmann, J., & Nebel, B. (2001). FF planning system: Fast plan generation heuristic
search. Journal Artificial Intelligence Research, 14, 253302.
Hoffmann, J., & Brafman, R. (2006). Conformant planning via heuristic forward search: new
approach. Artificial Intelligence, 170(67), 507541.
Huang, J. (2006). Combining knowledge compilation search efficient conformant probabilistic planning. Proceedings 16th International Conference Automated Planning
Scheduling (ICAPS), pp. 253262, Cumbria, UK.
Hyafil, N., & Bacchus, F. (2004). Utilizing structured representations CSPs conformant
probabilistic planning. Proceedings European Conference Artificial Intelligence
(ECAI), pp. 10331034, Valencia, Spain.
Jensen, F. (1996). Introduction Bayesian Networks. Springer Verlag, New York.
Kushmerick, N., Hanks, S., & Weld, D. (1995). algorithm probabilistic planning. Artificial
Intelligence, 78(1-2), 239286.
Little, I., Aberdeen, D., & Thiebaux, S. (2005). Prottle: probabilistic temporal planner. Proceedings 20th National Conference Artificial Intelligence (AAAI-05), pp. 1181
1186, Pittsburgh, PA.
Littman, M. L., Goldsmith, J., & Mundhenk, M. (1998). computational complexity probabilistic planning. Journal Artificial Intelligence Research, 9, 136.
619

fiD OMSHLAK & H OFFMANN

Majercik, S. M., & Littman, M. L. (1998). MAXPLAN: new approach probabilistic planning. Proceedings 4th International Conference Artificial Intelligence Planning
Systems (AIPS), pp. 8693, Pittsburgh, PA.
Majercik, S. M., & Littman, M. L. (2003). Contingent planning uncertainty via stochastic
satisfiability. Artificial Intelligence, 147(1-2), 119162.
McDermott, D. (1998). 1998 AI Planning Systems Competition. AI Magazine, 2(2), 3555.
McDermott, D. V. (1999). Using regression-match graphs control search planning. Artificial
Intelligence, 109(1-2), 111159.
Onder, N., Whelan, G. C., & Li, L. (2006). Engineering conformant probabilistic planner. Journal
Artificial Intelligence Research, 25, 115.
Pearl, J. (1984). Heuristics - Intelligent Search Strategies Computer Problem Solving. AddisonWesley.
Pearl, J. (1988). Probabilistic Reasoning Intelligent Systems: Networks Plausible Inference.
Morgan Kaufmann, San Mateo, CA.
Rintanen, J. (2003). Expressive equivalence formalisms planning sensing. Proceedings 13th International Conference Automated Planning Scheduling (ICAPS),
pp. 185194, Trento, Italy.
Roth, D. (1996). hardness approximate reasoning. Artificial Intelligence, 82(1-2), 273
302.
Russell, S., & Norvig, P. (2004). Artificial Intelligence: Modern Approach (2 edition). Pearson.
Sang, T., Bacchus, F., Beame, P., Kautz, H., & Pitassi, T. (2004). Combining component caching
clause learning effective model counting. (Online) Proceedings 7th International Conference Theory Applications Satisfiability Testing (SAT), Vancouver, BC,
Canada.
Sang, T., Beame, P., & Kautz, H. (2005). Solving Bayes networks weighted model counting.
Proceedings 20th National Conference Artificial Intelligence (AAAI), pp. 475482,
Pittsburgh, PA.
Shimony, S. E. (1993). role relevance explanation I: Irrelevance statistical independence. International Journal Approximate Reasoning, 8(4), 281324.
Shimony, S. E. (1995). role relevance explanation II: Disjunctive assignments approximate independence. International Journal Approximate Reasoning, 13(1), 2760.
Zhang, N. L., & Poole, D. (1994). simple approach Bayesian network computations.
Proceedings 10th Canadian Conference Artificial Intelligence, pp. 171178, Banff,
Alberta, Canada.

620

fiJournal Artificial Intelligence Research 30 (2007) 361-412

Submitted 07/07; published 11/07

Natural Events
John Bell

jb@dcs.qmul.ac.uk

Department Computer Science,
Queen Mary, University London,
London E1 4NS, UK

Abstract
paper develops inductive theory predictive common sense reasoning.
theory provides basis integrated solution three traditional problems
reasoning change; frame, qualification, ramification problems. theory
also capable representing non-deterministic events, provides means stating
defeasible preferences outcomes conflicting simultaneous events.

1. Introduction
great deal written logical representation common sense reasoning
change since publication McCarthy Hayess (1969) seminal paper,
many theories proposed; see, example, monographs Sandewall (1994),
Shanahan (1997), Reiter (2001).
theories treat events1 deductively, along lines representation actions
used planner strips (Fikes & Nilsson, 1971). event type defined
preconditions effects. example, blocks world, preconditions unstacking
block x block x y, x clear (no block top it), robot hand
empty. effects hand holding x, clear, preconditions
false. Change matter deduction. particular event (a token event
type) occurs particular preconditions hold, particular effects deduced,
necessarily follow, it. Events kind called deductive events
view natural events represented deductively called Deductionism.
Deductive event types thought invariable regularities (or uniformities) sequence. Viewed way strips representation events seen descended
considered Hume Mill discussions causation. Hume (1739, Bk
I, Pt III) suggests inductively acquire knowledge regularities succession
form: A-type events followed B-type events. consider A-type events
cause B-type events, whenever see A-type event expect
followed B-type event. Mill (1898, Bk III, Ch 5) complicates picture considering
assemblages conditions. single assemblage might consist A-type event together
certain conditions must present (positive conditions) certain conditions
must absent (negative conditions). example, assemblage concerning
lighting matches might include striking match, presence oxygen,
absence dampness match head.
1. Events assumed include physical actions agents; whether intentional unintentional.
c
2007
AI Access Foundation. rights reserved.

fiBell

Mill (1898) thought possible, least principle, define assemblages
detailed enough ensure effects: every event combination
objects events, given concurrence circumstances, positive negative,
occurrence always followed phenomenon (p. 214).
However, Hume (1777, pp. 36-38) already argued possibility. always
possible regularity, matter long continued past, continue
future. Consequently set sentences report observed ever
logically implies anything observed. Goodman (1954, p. 59)
puts it, happened imposes logical restrictions happen. So,
Deductionism plausible, necessary assume Nature uniform;
future resemble past, past regularities continue. Now, clearly, Uniformity
cannot justified appealing experience, difficult see else
justified; see, Goodmans discussion (pp. 61-62). Without justification, Deductionism
regarded suspect theory.
Deductionism also suspect practice, impossible practice define preconditions which, together occurrence event, sufficient ensure
effects follow. example, Russell (1913, p. 7) considers problem conflicting
events: put penny slot, draw ticket earthquake upsets machine calculations. order sure expected
effect, must know nothing environment interfere it.
means supposed cause not, itself, adequate insure effect. Russell also
observes cannot usefully solve problem complicating preconditions because:
soon include environment, probability repetition diminished, until,
last, whole environment included, probability repetition becomes almost
nil (pp. 7-8).
problem specifying preconditions always sufficient also arises Mackies
account causal regularities (invariable regularities sequence). example, least
part answer [to question caused particular fire] set
conditions (of positive negative), including presence
inflammable material, absence suitably placed sprinkler, doubt quite
number others (Mackie, 1975, p. 16). list conditions incomplete because, even
causal regularities hold objects, seldom, ever, known full: Causal
knowledge progresses gradually towards formulation regularities, hardly
ever gets there. Causal regularities known typically incomplete . . . know
certain elliptical gappy universal propositions (Mackie, 1974, p. 66).
sufficient-preconditions problem becomes acute consider formal representations intended practical use, preconditions
computationally tractable. McCarthy (1977, p. 1040) gives example using boat
cross river. Given boat rowing boat, equipped oars,
manned oarsman, used convey two passengers across river; provided
boat leak, provided hit rock, provided
hit another boat, provided overturned hippopotamus,
sunk meteorite, vapourized thermonuclear blast, etc. seems list
qualifications need added limited limits imagination.
Accordingly, McCarthy calls sufficient-preconditions problem qualification problem.
362

fiNatural Events

response, Deductionists might argue representations abstractions
approach works well simple domains, assumed qualifications arise. domains, might argue, uniformity assumption
reasonable, deductive theories provide useful representation. may well
true, but, theories kind cannot readily extended complex (less uniform)
domains additional complexity required preconditions quickly becomes
overwhelming. Thus Deductionist approach may appropriate certain applications,
mathematical analysis high-level programming languages elementary commands viewed abstract operations data. inappropriate
representation predictive reasoning natural events, events everyday
experience, irregular treated deductively. Moreover, Deductionist abstraction better thought idealization, problematic one that.
preconditions deductive event hold occurrence, effects logically
guaranteed follow, natural force intervene prevent so.
Deductive events thus natural, supernatural. idealization creates technical
difficulties comes representation events variable effects (including
non-deterministic context-dependent effects) effects always deduced, representation conflicting events (events whose effects individually
consistent jointly inconsistent) joint effects cannot consistently deduced.
Consequently Deductionist theories phenomena (some discussed
sequel) face unnecessary, self-imposed, difficulties. difficult escape conclusion
that, representing natural events deductively, Deductionism starts wrong foot.
conclusion hardly surprising consider predictive reasoning
natural events inductive, rather deductive, nature.2 major purpose
predictive reasoning support practical reasoning; is, reasoning do.
Predictive reasoning normally based partial knowledge (or incomplete belief),
causal regularities, Mackie observes, contexts events concerned
occur. also tends conjectural seeks produce reasonable conclusions
basis known. result tends produce conclusions supradeductive (which may deducible known) defeasible (which may turn
wrong).3 Accordingly, definitions (practical, non-omniscient) rationality
typically couched terms utility expected (rather actual) outcomes
actions. Russell Norvig (2003, p. 36) illustrate point follows: walking
along Champs Elysees one day see old friend across street.
traffic nearby otherwise engaged, rational, start cross street.
Meanwhile 33,000 feet, cargo door falls passing airliner, make
2. philosophy, term inductive reasoning applied form qualitative non-deductive reasoning. thus includes enumerative induction, general rule inferred non-exhaustive
set inferences (for example, emeralds observed green, therefore
emeralds green). form reasoning underlies knowledge regularities.
comes inductive events idea (as explained text below) produce reasonable
conclusions outcomes basis partial information. AI, inductive reasoning
kind formalized non-monotonic logics.
3. J. K. Galbraith remarked two kinds forecasters. dont know,
know dont know.

363

fiBell

side street flattened. irrational cross street? unlikely
obituary would read Idiot attempts cross street.
change perspective results substantial simplification problem specifying preconditions. longer concerned invariable regularities sequence,
necessary connections events effects, rather regularities
sequence normally hold; fairly dependable regularities sequence (Russell, 1913, p. 8), expected connections events effects. Consequently
define preconditions which, together associated events, form conditions
normally sufficient associated effects, otherwise minimal
sense part redundant. Preconditions kind tend
tractable (simple) useful (to occur frequently practice).
give Humeian account predictions involving natural events terms
(fairly) dependable regularities expectations engender. event occurs,
preconditions obtain, aware anything prevent effects
following, form clear expectation (we know) effects follow,
rational (reasonable) predict them. example, block unstacked
block B, preconditions obtain, aware preventer,
clearly expect, predict, longer B. complex cases involve
conflicting events. If, case, clear expectation outcome,
rational predict it. example, clearly expect, predict, airliner door
crush, rather bounce off, intrepid pedestrian. example consider
two conflicting outcomes possible, one probable. However,
cases expectations unclear; torn conflicting expectations
know expect. cases seems reasonable adopt cautious
approach, restrict predictions effects clearly expect. example,
fair coin tossed, clear expectation side
land. half expect land heads half expect land
tails. consider two conflicting outcomes equally probable. caution dictates
predict coin lands one side other,
predict two sides land on. Note that, expectations based
incomplete knowledge, predictions based defeasible. example,
if, unbeknown us, block glued block B unstacked B,
event effects predict have.
thus begin thinking natural events defeasible strips events, stripslike events whose effects always follow (when occur preconditions
true), inferring effects inductively. Accordingly, events kind
called inductive events, view natural events represented inductively
called Inductionism. logic understood include deductive inductive inference, Inductionist objection Deductionism stated succinctly:
Deductionism logical mistake.
paper seen argument Inductionism. begins presenting basic
theory inductive events uses basis comprehensive theory
natural events.
formal language theory expressed defined next section,
basic theory inductive events given Section 3. theory builds
364

fiNatural Events

ideas McCarthy (1986, 9), Lifschitz (1987), Shoham (1988), logico-pragmatic
nature; is, consists set axioms together formal pragmatics, which,
given formal theory containing axioms, interprets particular way,
so, generates predictions theory. basic theory inductive events provides
basis solution qualification problem integrates basis
solution complementary frame problem (McCarthy & Hayes, 1969, p. 487);
is, problem inferring unchanged occurrence event (or,
generally, occurrence several simultaneously occurring events).
Section 4, basic theory inductive events extended introducing distinction
inductive events primary secondary. Whereas
primary events occur independently, secondary events invoked (primary
secondary) events appropriate contexts, causally dependent them.
simplest case, primary event invokes secondary event event so.
case, secondary event succeeds (is followed effects) primary
event invoked succeeds. extension basic theory makes possible
inductive events additional context-dependent effects, thereby providing basis
solution ramification problem (Ginsberg & Smith, 1988); is, problem
representing indirect, context-dependent, effects events. example, agent
holding block agent moves, move-agent event invokes causally
dependent move-block event, effect block moves agent does.
extension also makes possible represent events non-deterministic effects.
example, non-deterministic event tossing fair coin represented
event invoke two conflicting deterministic events, one effect coin
lands heads, lands tails.
theory natural events completed Section 5, deals problem
representing defeasible preferences outcomes conflicting simultaneous events.
two events conflict often clear expectation outcome. example,
two agents attempt go door simultaneously one succeed,
reasonable expect stronger one so. However expectation
defeasible. stronger agent may fail independent reason (the agent may slip,
say), case preference reversed expect weaker agent
succeed (although weaker agent may also slip, etc.). order represent defeasible
asymmetric expectations kind event preferences introduced, formal
pragmatics basic theory refined order interpret correctly.
philosophical justification theory natural events given Section 6,
related work discussed Section 7.
Although causal notions underlie much development theory natural
events, explicit reference causation theory. intended
provide basis definition sufficient causation forms part larger theory
causation (Bell, 2004, 2006, 2008).4
4. According theory, occurrence event e context c sufficient cause effect occurrence e c sufficient ensure ; instance, e succeeds time logical consequence
es effects t+1, e sufficient cause . definition causation obtained requiring sufficient causes also satisfy refinement Lewiss (1986, Ch. 21) counterfactual-dependence

365

fiBell

2. Event Language EL
theory events expressed event language EL, developed
order represent reason events effects, basis partial
information, successive points time. section begins informal introduction
gives formal account.
order represent epistemic partiality natural economical way EL based
Kleenes (1952, 64) strong three-valued logic.5 Kleene introduced truth value undefined order accommodate undecidable mathematical sentences. However also
suggested undefined could interpreted unknown, where: unknown category regard proposition falling, whose value either
know choose moment disregard; exclude two
possibilities true false (p. 335). Thus understood, undefined truth value
par true false, introduction intended practical, logically
conservative, way reasoning partial information; rather revolutionary attack
classical logic.6
keeping interpretation, truth value sentence classical
(either true false) enough known determine it. formal semantics
propositional case thus given follows. model, , consists possibly
partial evaluation function, V , assigns one classical truth value
atomic proposition. truth (|=) falsity (=|) sentences defined
following truth falsity conditions:
|= p iff V (p) = true
=| p iff V (p) = false
|= iff =|
=| iff |=
condition: occurrence event e cause effect context c iff (i) e sufficient cause
c, (ii) depends e closest context c e sufficient cause .
5. Kleenes logic familiar readers background philosophical logic (it is, example, used
Kripke, 1975, basis theory truth), choice use likely appear
natural one them. However, Kleenes logic may unfamiliar readers reasoning actions
change community, may well wonder used established classical
language Situation Calculus (McCarthy & Hayes, 1969). full justification choice
would involve lengthy comparison languages. short, simpler acknowledge epistemic
partiality ubiquitous feature predictive reasoning deal directly, Kleenes
logic, rather indirectly classical logic; means syntactic encoding circumscription (as
Situation Calculus), using modal logic (as TK, Shoham, 1988). representation
partiality Kleenes logic also optimal; cost associated representation
unknown. contrast, partiality classical reasoning requires consideration class
models (or possible worlds) large enough ensure unwanted noise (arbitrary,
compulsory, assignments classical truth values sentences whose truth values determined
theory question) eliminated. profligacy significant considering contemplated
model-building implementation event theories (Bell, 1996, 1); see remarks implementation
Section 8. Finally, indicated introduction Footnote 4, theory events intended
form part larger theory causation, EL embedded partial modal language.
6. Confirmed classicists thus rest assured threatened anything radical,
Bolshevik menace Brouwer Weyl (remark Intuitionism attributed F.P. Ramsey
Blackburne, 1994).

366

fiNatural Events

|= iff |= |=
=| iff =| =|

sentence true false, false true, undefined otherwise;
sentence true true, false either false, undefined
otherwise. Note evaluation function total semantics equivalent
semantics classical propositional calculus. essential difference two
semantics classical assumption evaluation function total; additional
requirement V assigns least one classical truth value atomic proposition.
operators defined classical logic. particular, inclusive disjunction
defined as: =Df ( ); true either disjunct true, false
disjuncts false, undefined otherwise. exclusive disjunction defined
as: =Df ( ) ( ); true truth values
defined different, false truth values defined
same, undefined otherwise.7
Kleenes logic perhaps called demi-classical, becomes classical
truth values constituent atomic sentences classical. Unsurprisingly then,
use Kleenes logic not, itself, solve problems predictive reasoning
beyond representing partiality. is, example, reliance special
causal notion consequence, Linear Logic (Girard, 1987).
expressiveness Kleenes language greatly enhanced adding classicallyvalued definedness operator it. sentence true defined (is either true
false), false otherwise:

|= iff either |= =|
=| iff neither |= =|

classically-valued operators defined follows:

=Df
=Df

F =Df
U =Df
=Df (T T) (F F) (U U)

Thus, sentences : true true, false otherwise; F true
false, false otherwise; U true undefined, false otherwise;

7. Readers unfamiliar Kleenes logic may wish check definitions semantics.
example, |= iff |= ( ) iff =| iff [M =| =| ] iff [M |=
|= ].

367

fiBell

true true not, false otherwise;8 true
truth value, false otherwise.9
first-order extension, given Kleene, straightforward. universal sentence
x true true assignments x, false false assignment,
undefined otherwise. existential quantifier defined classical logic: x =Df
x; thus x true true assignment x, false false
assignments, undefined otherwise.
order represent change, events time points added additional sort.
simplicity, order time assumed discrete linear.
object atom atom form r(u1 , . . . , un )(t), r object relation
symbol, ui object terms, time-point term. example, object atoms
At(O, L)(1) At(O, L)(2) state respectively object location L time 1,
L time 2.
event atom atom form r(u1 , . . . , un )(t), r event relation
symbol, ui event terms, time-point term. example, event atom
Occ(Move(O, L1, L2))(3) states event consisting object moving location
L1 location L2 occurs time 3.
intuition behind fact-event distinction events active agents (causes)
change, facts passive patients change persist time
affected event (until event causes change).10
order represent persistence facts, second-order quantification object
relations second-order relations added EL. object-relation atom atom
form r(u1 , . . . , un )(t), r second-order relation symbol, ui object
relation symbols object terms, time-point term. example, objectrelation atom Inert(At, hO, Li)(4) states relation inert objects L
time 4.
8. conditional captures much flavour classical material implication.
emphasized defining weaker conditional Kleenes logic: =Df . conditional
inadequate, least present purposes, undefined, rather false, true
undefined. case stronger conditional, , could equally defined
as: T. definition makes clear conditional states constraint must
satisfied true, otherwise ignored. conditional quite capture
meaning classical material implication, satisfy (implicitly understood)
condition false, . desired, possible define stronger conditional,
better represents classical material implication, follows: =Df ( ) ( ); or,
equivalently, =Df (T T) (F F). equivalence operator defined
follows: =Df ( ) ( ).
9. addition truth-value designation operator new. Bochvar (1939) added truth operator
different system connectives, undefined operator U special case Rosser Turquettes
(1952) Jk operator. Barringer, Cheng, Jones (1984) give natural deduction system Kleenes logic
defined operator D. system readily extended include operators defined above;
additional introduction elimination rules connectives simply fold unfold
definitions. Similar languages used basis formalization non-monotonic reasoning
(Doherty, 1996).
10. fact-event distinction similar McCarthys (1986, 9) fluent-event distinction. case
adding events ontology facts argued Davidson (1980). Lewis (1986, Ch. 23) goes
treats facts events.

368

fiNatural Events

temporally-indexed relation relation whose atoms temporally indexed; whose
atoms form r(u1 , . . . , un )(t). primitive atemporal relations EL temporal
precedence, <, identity, =. atemporal relations defined terms
temporally-indexed relations follows:
r(u1 , . . . , un ) =Df r(u1 , . . . , un )(t) .
example, Phys(At)(t) abbreviated Phys(At), states (eternally) physical relation.
formal semantics EL sketched follows. Models contain set objects,
set event types, time frame consisting set time points ordered (discrete
linear) precedence relation, functions interpreting terms relations.
twin notions satisfaction violation formula, variable assignment model,
defined means parallel recursion. truth (falsity) sentence model
defined terms satisfaction (violation) assignments model.
classical logic, model said model sentence (a set sentences )
true (if every sentence true ), set sentences semantically
entails sentence iff models also models .
remainder section formal syntax semantics EL defined.
Readers may wish skip next section return consult details necessary.
Definition 1 four sorts EL identified following letters: (objects),
(time points), E (events), R (object relations). vocabulary EL consists
symbols <, =, , D, , , (, ), following countable sets symbols:
CS (constants sort S),
VS (variables sort S),
FS (function symbols arity n 1 sort S),
RO , , RR (relation symbols arity n 0 sorts O, E,and R).
sets RO CR required set. Otherwise sets required
mutually disjoint. Furthermore, VR assumed contain variables arity n 0.
Definition 2 terms EL defined follows.
termS = CS VS {f (u1 , . . . , un ) : n-ary f FS , ui termS } {O, T, R}.
termE = CE {f (u1 , . . . , un ) : n-ary f FE , ui termO }.
Definition 3 EL minimal set satisfies following conditions.
t, termT < EL.
sort u, u termS , u = u EL.
u1 , . . . , un termO , rO n-ary relation symbol RO , termT ,
rO (u1 , . . . , un )(t) EL.
369

fiBell

sort E R, u1 , . . . , un termS w1 , . . . , wm termO (where = 0
n = 0), rS n + m-ary relation symbol RS , termT , rS (u1 , . . . , un ,
w1 , . . . , wm )(t) EL.
u1 , . . . , un termO , vR n-ary variable VR , termT ,
vR (u1 , . . . , un )(t) EL.
, EL, EL, EL, ( ) EL.
sort, v VS EL, v EL.
members EL called formulas (of EL). formulas variable occurs
free called sentences (of EL).
Models EL consist set objects, set E event types, temporal frame
hT , (where set time points before-after relation ),
interpretation functions terms relations. simplicity, time assumed
isomorphic integers. denotations terms always defined vary
time. contrast, temporally-indexed relations may partial may vary
time. Consequently temporally-indexed relation interpreted function time
points partial characteristic functions. defined, partial characteristic function
associated time point maps instances relation {true, false}.
Definition 4 model EL structure hO, E, hT , i, F, R, Vi, where:
O, E mutually disjoint, non-empty, countable sets,
binary relation isomorphic integers,
R = hRO , , RR i. RO set partial functions arity n 0 type
{true, false}. hS, Si {hE, Ei, hR, RO i}, RS set partial functions
arity n + 0 type n Om {true, false}.
F = hFO , FT , FE , FR i. hS, Si {hO, Oi, hT, i, hR, RO i}, FS set
functions arity n 1 type n S. FE set functions
arity n 1 type E.
C , V C , V C , V C i, hV F , V F , V F , V F i, hV R , V R , V R ii interpretation function
V = hhVO

E
R


E
R

E
R
that: VSC : CS hS, Si {hO, Oi, hT, i, hE, Ei, hR, RO i},
R = VC.
VSF : FS FS , VSR : RS (T RS ), VO
R

Definition 5 variable assignment EL model function g = hgO , gT , gE , gR i,
hS, Si {hO, Oi, hT, i, hE, Ei}, gS : VS S, gR : VR (T RO ).
EL-model , interpretation function V variable assignment g , term
evaluation function Vg defined, terms relation symbols EL, follows:


gS (u)


V C (u)

Vg (u) =
VSF (f )(Vg (u1 ), . . . , Vg (un ))


R

VS (u)

370






u VS ,
u CS ,
u = f (u1 , . . . , un ) termS ,
u RS .

fiNatural Events

Table 1: Satisfaction violation conditions EL (see Definition 6)
M, g |= < iff hVg (t), Vg (t )i
M, g =| < iff hVg (t), Vg (t )i
/
M, g |= u = u iff Vg (u) Vg (u )
M, g =| u = u iff Vg (u) Vg (u )
M, g |= u(u1 , . . . , un )(t) iff (Vg (u)(Vg (t)))(Vg (u1 ), . . . , Vg (un )) = true
M, g =| u(u1 , . . . , un )(t) iff (Vg (u)(Vg (t)))(Vg (u1 ), . . . , Vg (un )) = false
M, g |= iff M, g =|
M, g =| iff M, g |=
M, g |= iff either M, g |= M, g =|
M, g =| iff neither M, g |= M, g =|
M, g |= iff M, g |= M, g |=
M, g =| iff M, g =| M, g =|
M, g |= v iff M, g |= every g g v g
M, g =| v iff M, g =| g g v g

Definition 6 Let EL model, g variable assignment , let g v g
indicate variable assignment g differs g assignment variable v.
g satisfies EL-formula (written M, g |= ) violates (written
M, g =| ) according clauses given Table 1.
Let EL model. formula true (written |= ) M, g |=
variable assignments g; formula false (written =| ) M, g =|
variable assignments g; model sentence iff true ;
model set sentences iff model every sentence .
set sentences (semantically) entails sentence (written |= ) iff every model
also model .

3. Inductive Events
formal theory natural events introduced stages, beginning, section,
basic theory inductive events.
Definition 7 theory inductive events, Ind , consists axioms given Table 2;
thus Ind = {(1), (2), (3)}. event theory set EL sentences contains Ind .
Axiom (1) defines notion success, states event e succeeds time iff
true e occurs t, preconditions e true t, effects e true
t+1.11 presence truth operator axiom ensures relation Succ
11. Thus defined, success failure event simple, objective, matter whether occurrence
accompanied preconditions followed effects. speaking success failure

371

fiBell

Table 2: theory inductive events, Ind
e, t(Succ(e)(t) T(Occ(e)(t) Pre(e)(t) Eff(e)(t+1)))

(1)

R T(Phys(R) Theo(R))

(2)

R, x, t(Inert(R, hxi)(t) (Phys(R) (R(x)(t) R(x)(t+1))))

(3)

classical sense every instance either true false. thus possible
reason classically success failure basis partial information.
view fact-event distinction, also necessary represent inertia; is,
temporal persistence facts changed events. definition inertia
begins distinction physical facts (represented physical relations)
theoretical facts (represented theoretical relations). Intuitively, physical facts facts
world directly observe it, whereas theoretical facts product
complex reflection (theorizing about) physical facts.12 example,
representation blocks world locations blocks might represented
object relation At. used define relation Clear, true
location point time blocks location point time.
theory, relation naturally classified physical relation (as represents
physical locations blocks) relation Clear naturally classified theoretical
relation (as represents a, comparatively complex, property locations defined
terms locations blocks). Note that, theoretical facts (ultimately) defined
terms physical facts, theoretical facts supervene physical facts; is, fixing
physical facts point time also fixes theoretical facts point time.
event theories, physical theoretical relations identified means secondorder predicates Phys Theo respectively. Thus Axiom (2) states every object
relation either physical relation theoretical relation. matter notational
convenience convention adopted object relation declared
theoretical relation physical one. convention enforced formal pragmatics
discussed below.
inertia physical facts defined Axiom schema (3); which, simplicity,
henceforth called axiom. axiom, R n-ary object relation symbol, x
vector x1 , . . . , xn object variables, hxi list hx1 , . . . , xn i. axiom states
R inert objects referred x time iff R physical relation
event end purpose (no teleology) implied; could equally talk event occurrence
complete incomplete. natural talk informally intentional actions succeeding failing,
example agent succeeding failing intention move particular location.
attempt made represent intentionality formally.
12. Physical facts thought Quines (1995, Chs. 2-3) observational predications.
compounds primitive observation sentences, human equivalent bird-calls
apes cries (p. 22). example, observational sentences Black (or Thats black) Dog
(or Thats dog) might combined observational predication Black dog (or dog
black). Theoretical facts result complex compounding, involving logical connectives
and, especially, reification.

372

fiNatural Events

truth values object atoms R(x)(t) R(x)(t+1) equivalent. Note
relation Inert classical event theories; Phys classical (by Axiom (2))
right-hand equivalence classically valued. Note also that, event theories
contain occurrences Theo relation, Axiom (2) unnecessary Axiom (3)
simplified accordingly.
turn intended interpretation event theories.
intended interpretation, Axiom (1) used generate expected outcomes
events. Pre(e)(t) Occ(e)(t) true, consistent assume
success atom Succ(e)(t) true, success assumption made, axiom
used conclude expected effects, Eff(e)(t+1), true. Thus interpreted
axiom states that, accompanied preconditions, occurring events normally
sufficient (are normally followed by) effects. interpreted way,
axiom amounts common sense law change.
Similarly, intended interpretation, Axiom (3) used generate expected
persistence physical facts. R physical relation, object atom R(x)(t) defined,
consistent assume inertia atom Inert(R, hxi)(t) true, inertia
assumption made, axiom used conclude truth value R(x) persists
t+1.13 Thus interpreted, axiom states physical facts normally persist,
amounts common sense law inertia.
intended interpretations axioms (1) (3) often conflict. example,
unstack-A-from-B event occurs, preconditions true, relevant facts
events involved, consistent assume unstack event succeeds,
consistent assume fact B inert, assumptions cannot
made success unstack event implies longer B.
cases suggest change always priority inertia, success
assumptions always priority inertia assumptions. conflict resolution
principle defended appealing regularity-based (Humeian) expectation
change. Thus, case hand, experience taught us unstack events
sort described normally succeed, form clear expectation effects
follow. contrast, giving priority inertia would, contrary expectation, result
nothing changing, adopting neutral stance would, contrary expectation, produce
unclear outcome.
intended interpretation event theories enforced formal pragmatics,
defines class preferred models given event theory. section
notion preference1 defined. later refined preference2 Section 5.
order enforce convention object-relations physical unless stated otherwise, preferred1 models event theory models theory
(positive) domain Phys relation large be. Let us say model
Phys-maximal model event theory model and, model
, {R : |= Phys(R)} {R : |= Phys(R)} = . preferred1
models Phys-maximal models .
13. R(x)(t) defined, then, become clear, atom safely ignored. Inert(R, hxi)(t)
consistently assumed, formal pragmatics (in particular, minimization evidential
atoms t+1) ensures R(x)(t+1) undefined, thereby satisfying axiom.

373

fiBell

Beyond requirement, get clearer idea preferred1 model
event theory look like considering inductive version canonical example,
known Yale Shooting Problem (Hanks & McDermott, 1987). time 1 gun
loaded pointed Fred. Nothing relevant happens time 2. time 3 gun fired.
gun still loaded time 3, then, absence information, expect
shot prove fatal Fred longer alive time 4. example
represented formally theory 1 = Ind {(4), (5), (6)}, where:
t(Pre(Shoot )(t) (Alive(t) Loaded (t)))

(4)

t(Eff(Shoot)(t) Alive(t))

(5)

Alive(1) Loaded (1) Occ(Shoot )(3)

(6)

Thus preconditions Shoot event gun loaded victim alive
(Axiom (4)), effect (if successful) victim alive (Axiom (5)).
model time point t, let M/t denote set object occurs literals
temporal index true , let (t) = M/t \ M/t1.14 M/t
thought history represented (and including) t. And,
t, (t) thought representing known present moment,
evidential context predictions t+1 based. also think
dynamic conjectural context t, consists set success inertia
assumptions correspond expectations t+1. Assumptions added
conjectural context consistent current context (the union
evidential context current conjectural context) background theory (the laws
given event theory).
generation preferred1 model, , 1 proceed follows:
M/1 = {Alive(1), Loaded (1)} ,
M/2 = M/1 {Alive(2), Loaded (2)} ,
M/3 = M/2 {Alive(3), Loaded (3), Occ(Shoot )(3)} ,
M/4 = M/3 {Alive(4), Loaded (4)} ,
M/5 = M/4 {Alive(5), Loaded (5)} , . . . .
Thus atoms M/1, evidential context (1),
required boundary conditions 1 , stated Axiom (6).
restriction evidential context (Ockhams razor) appropriate prediction
based available evidence. Now, Alive declared
theoretical relation 1 , notational convention, Phys(Alive) true .
consistent current context (1) (given background theory 1 \{(6)})
assume Inert(Alive)(1), assumption added conjectural context.
Consequently Alive(2) (2) inertia axiom (Axiom (3)). Similarly
Phys(Loaded ) true , consistent current context (1)
{Inert(Alive)(1)} assume Inert(Loaded )(1), assumption added
conjectural context. inertia, Loaded (2) (2). And, accordance
14. usual, literal either atom, , negation, .

374

fiNatural Events

Ockhams razor, atoms (2). analogous reasoning beginning
current context (2) , Alive(3) Loaded (3) (3),
remaining boundary condition Occ(Shoot )(3). And, Ockhams razor, atoms
(3). Now, current context (3) consistent assume either
Succ(Shoot )(3) Inert(Alive)(3). However cannot assumed; were,
would follow axioms change ((1) (5)) inertia Alive(4)
Alive(4) would (4). keeping principle change preferred inertia,
Succ(Shoot )(3) assumed added conjectural context, Alive(4)
(4). consistent current context (3){Succ(Shoot )(3)} assume
Inert(Loaded )(4), inertia, Loaded (4) (4). And, Ockhams razor,
atoms (4). remainder M/ generated
repeated applications inertia axiom Ockhams razor.
example suggests event theories interpreted chronologically.
fits naturally experience times arrow; asymmetry past
(which fixed) future (which open, yet exist). particular,
understanding events terms dependable regularities sequence founded
asymmetry. example also suggests successive time point (at new
present moment) first fix evidential context generate appropriate
conjectural context. evolving context background theory produce
expected changes persistences. Fixing evidential context consists minimizing it;
is, restricting object event literals required boundary
conditions earlier interpretation theory. Generating conjectural context
consists maximizing success inertia assumptions (that is, assuming
suggested evidential context consistent current context
background theory) giving priority former case conflict. definition
preferred1 model event theory thus reflect prioritized chronological
minimaximization involved intended interpretation.
begin defining preference relation 1 . definition (and subsequent
definition 2 ) fewer understood terms set inclusion rather
cardinality.15 keeping discussion, let evidential atom either
object atom event atom success atom, let conjectural atom
either success atom inertia atom.
Definition 8 (Preference1 ) Let models differ interpretation temporally-indexed relations. preferred1 (written 1 )16
iff time point agree t, t:
1. fewer evidential atoms defined , agree truth values
evidential atoms defined ;
2. differ conjectural atoms, success atoms true ;

15. Thus At(T, v, t, ) = { : atom type truth value v time model },
fewer atoms type truth value v time model model At(T, v, t, )
At(T, v, t, ). Similarly, replacing , case more.
16. way writing preferences based comparison evidential contexts.

375

fiBell

3. differ inertia atoms, inertia atoms true .
example, suppose models differ temporally
indexed relations. (1) agree time 2 disagree
Occ(Shoot )(2) undefined true , preferred1 clause 1
definition. (2) agree time 3 disagree
Succ(Shoot )(3) true false , preferred1 clause 2
definition. (3) agree time 3 disagree Succ(Shoot )(3)
Inert(Alive)(3) true whereas Succ(Shoot )(3) Inert(Alive)(3) true
, preferred1 clause 2 definition. (4) agree
time 2 disagree Inert(Alive)(2) true false ,
preferred1 clause 3 definition.
preferred1 models event theory thus obtained focussing
class Phys-maximal models selecting 1 -minimal models
it. Accordingly, definition preferred1 models event theory definition
predictions based instances following generic definitions.
Definition 9 (Preferred Models, Prediction) model said preferredi
model event theory Phys-maximal model model
preferred (which ). event theory
sentence, predictsi (written |i ) iff preferred models also
models .
keeping discussion introduction, definition prediction cautious.
clearer picture emerges consider preferredi models given event theory
abstract level.
Definition 10 (Equivalence, Determinism, Representative Preferred Model) Let
event theory, let preferred models .
said preferencei equivalent (written ) agree interpretation
evidential conjectural atoms.17 event theory deterministici
single -equivalence class, non-deterministici otherwise. representative member
-equivalence class called representative preferredi model .
-equivalence class preferredi models event theory represents possible
history defined theory. deterministici theories define single possible
history, predictions safely based it. However, non-deterministici theories
define one possible history, caution dictates predictions
restricted sentences true possible histories
define.18 representative preferredi models event theory provide concrete way
thinking possible histories.
return (inductive version the) Yale Shooting Problem.
17. two models may differ interpretation terms, truth values atoms
considered definition preferencei .
18. possible define risky notion prediction based single -equivalence class c event theory
. Thus | ci iff true models c. relation used obtain information
particular possible history, serve basis reliable prediction non-deterministici
theories take other, equally possible, histories account.

376

fiNatural Events

Example 1 before, let 1 = Ind {(4), (5), (6)}. 1 deterministic 1 .
evidential literals true representative preferred 1 model agree
set M/ discussed earlier. Thus 1 predicts 1 Shoot event succeeds time 3,
effect Fred alive time 4.
Proposition 1 |1 Succ(Shoot )(3) Alive(4).
Proof Definition 9, sufficient prove conclusion follows preferred 1
models 1 . So, let preferred 1 model 1 . Then, Definition 9, Phys(Alive)
Phys(Loaded ) true .19 Axiom (6), Alive(1) Loaded (1) true
. Definition 8.3, Inert(Alive)(1) true .20 follows Axiom (3)
Alive(2) true . similar reasoning, Inert(Loaded )(1) Loaded (2) also
true (Axiom (3), Definition 8.3). Alive(2) true , follows inertia
(Axiom (3), Definition 8.3) Alive(3) true . Similarly, Loaded (2) true
, follows inertia Loaded (3) true . So, Axiom (4), Pre(Shoot )(3)
true . Axiom (6), occurs atom Occ(Shoot )(3) true . Definition 8.2,
Succ(Shoot )(3) true . follows, Axiom (1), Eff(Shoot )(4) true ,
so, Axiom (5), Alive(4) true .
Yale Shooting Problem interest because, Hanks McDermott (1987)
show, poses problems theories take account times arrow. example
suggests reasoning inertia chronological. related example involving
reasoning change suggested Lifschitz (1987, p. 37). point example
illustrated adding second shot Yale Shooting Problem. Let 1 =
1 {Occ(Shoot )(4)}. expect that, before, first shot succeed
second shot fail (because Fred longer alive second shot occurs).
And, indeed, transpires preferred1 models 1 . However, 1
interpreted chronologically, would preferred models second
shot succeeds first shot fails; success second shot requires Fred
alive time 4.
inductive version Yale Shooting Problem considered (in Shoot
event treated inductively rather deductively) also illustrates need give priority
change (Succ assumptions) inertia (Inert assumptions) case conflict. Without
19. preferred1 model 1 follows Definition 9 Phys-maximal model 1 . So,
Phys(Alive) true , would model 1 Phys(Alive)
Phys atoms true true. would Phys-maximal model
1 , contradicting assumption is. analogous argument justifies subsequent appeals
Definition 9 regarding relation Phys.
20. Inert(Alive)(1) true , would model 1 Inert(Alive)(1)
true therefore preferred1 basis clause 3 Definition 8 time 1.
(M would disagree interpretation temporally-indexed relations,
would agree interpretation temporally-indexed relations time points time 1,
would agree interpretation evidential success atoms time 1,
inertia atoms temporal index 1 (all true together Inert(Alive)(1))
would true.) would follow Definition 9 would preferred1 model 1 ,
contradicting assumption is. analogous argument justifies subsequent appeals
clause n definition preferencei regarding truth value atom temporal index t.

377

fiBell

requirement would preferred models 1 Inert(Alive)(3) true
Succ(Shoot )(3) false, so, contrary expectation, Fred remains alive time 4.
subsequent examples often assumed different names (whether constants
functional expressions) denote different individuals. order enforce convention,
uniqueness names axioms (Lifschitz, 1987, p. 50) used. Let f1 , . . . , fn functions
returning values sort, let x1 , . . . , y1 , . . . variables appropriate sorts.
U [f1 , . . . , fn ] conjunction axioms set:
{x1 , . . . , xk , y1 , . . . , yl fi (x1 , . . . , xk ) = fj (y1 , . . . , yl ) : 1 < j n}
{x1 , . . . , xk , y1 , . . . , yk (fi (x1 , . . . , xk ) = fi (y1 , . . . , yk ) (x1 = y1 . . . xk = yk )) :
1 n} .
axioms express fact functions f1 , . . . , fn injections different
ranges. notation extended constants treating 0-ary functions. Thus,
example, given U [A, B, L1, L2] U [Move], follows constants A, B, etc., denote
different objects, functional expressions Move(A, L1, L2) Move(B, L1, L2)
denote different events.
next example illustrates need restrict inertia axiom physical relations.
Example 2 Block B moved location L1 location L2. expect L1
clear result. example represented follows:
x, l, l , t(Pre(Move(x, l, l ))(t) At(x, l)(t))






(7)

x, l, l , t(Eff(Move(x, l, l ))(t) (At(x, l )(t) At(x, l)(t)))

(8)

l, t(Clear(l)(t) TxAt(x, l)(t))

(9)

Theo(Clear)

(10)

U [B, L1, L2] At(B, L1)(1) Occ(M ove(B, L1, L2))(1)

(11)

Axioms (7) (8) define preconditions effects move events. Axiom (9) defines
location clear true exists block location. use
truth operator definition allows fact relation may partial;
location considered clear none blocks whose locations defined
location. Axiom (10) declares Clear theoretical relation. Finally, Axiom (11)
states boundary conditions.
Let 2 = Ind {(7), . . . , (11)}. 2 single representative preferred 1 model
Clear(L1)(2) true; because, model, move event succeeds, thereby vacating
L1, object replaces B L1. However, non-replacement L1 depends
fact Clear theoretical relation, exempt law inertia.
2 = 2 \ {(10)}, every preferred 1 model 2 object mysteriously replaces B
L1.
Proposition 2 |1 Clear(L1)(2), 2 |1 Clear(L1)(2).
Proof first part, let preferred 1 model 2 . Then, axioms (7) (11),
At(B, L1)(1), Pre(Move(B, L1, L2))(1), Occ(Move(B, L1, L2))(1) true .
378

fiNatural Events

Definition 8.2, Succ(Move(B, L1, L2))(1) true . follows, axioms (1)
(8) At(B, L2)(2) At(B, L1)(2) true . At(B, L1)(1) true ,
follows Axiom (9) Clear(L1)(1) true . Axiom (10) Theo(Clear)
true so, Axiom (2), Phys(Clear) true . follows Axiom (3)
Inert(Clear, hL1i)(1) true (consequently Clear(L1)(2) longer true
inertia). Definition 8.1 follows that, x B, At(x, L1)(2) undefined
. So, At(B, L1)(2) true , follows x, TxAt(x, L1)(2)
true . follows Axiom (9) Clear(L1)(2) true .
second part, let preferred 1 model 2 . Then, before, atoms
At(B, L1)(1), Clear(L1)(1), Succ(Move(B, L1, L2))(1), At(B, L2)(2) At(B, L1)(2)
true . However (in absence Axiom (10)) follows Definition 9
Phys(Clear) true . Definition 8.3, Inert(Clear, hL1i)(1) true .
follows Axiom (3) Clear(L1)(2) true .
restriction inertia axiom justified terms physical-theoretical
distinction follows. law inertia law physical inertia; task represent
persistence physical facts changed events. Applying
theoretical relations (as 2 ) results mysterious consequences; arise
maintaining inertia theoretical fact (Clear(L1)) introduces additional real
change physical fact (a change relation). Moreover, theoretical facts
supervene physical facts, changes (persistences) theoretical facts supervene changes
(persistences) physical facts. sufficient represent changes (persistences)
physical facts, let changes (persistences) theoretical facts take care themselves.
done case 2 , change relation results change
Clear relation. complex examples, several blocks may moved
location simultaneously, move event may may succeed. cases,
axioms change inertia represent changes persistences relation,
changes (persistences) Clear relation take care new facts
fixed; real changes occurred dust settled.21
21. Another, artificial, example involves interaction Goodmans (1954, p. III.4) predicate
Grue common sense inertia. Call object grue green time time 2
blue thereafter. suppose object green time 1 dont know events
occur time 1 affect O. seems natural conclude inertia green
time 2. However, green time 1, also grue time 1, equally reasonable predict
grue (that is, blue) time 2. example represented formally theory
G , consists Ind together following axioms:
x, t(Grue(x)(t) ((t < 2 Green (x)(t)) (t 2 Blue(x)(t)))) ,
x, t(Green(x)(t) Blue(x)(t)) ,
Green(O)(1) .
intended preferred1 models G Green(O)(2) true, unintended preferred1
models G Blue(O)(2) true. problem solved declaring Grue
theoretical predicate (in keeping Goodmans doctrine entrenchment Quines advocation
similarity), projected law inertia.

379

fiBell

4. Primary Secondary Events
theory inductive events provides basis integrated solution qualification problem frame problem. intended interpretation success axiom,
events are, given preconditions, normally sufficient effects. intended
interpretation inertia axiom, physical facts affected events persist.
However, whereas effects successful inductive events certain invariable,
effects natural events may uncertain they, least, may vary
according context events occur.
may seem context-dependent effects, ramifications, represented
domain axioms. However, following example, based Lifschitzs (1990) lampcircuit example Bakers (1991) ice-cream example, shows approach
simplistic.
Example 3 Ollie location L1, holding block B, moves location L2.
expect that, result, Ollie reach L2. Moreover, Ollie holding block
moves, expect move L2.
may seem example represented event theory 3 = Ind
{(12), . . . , (16)}; where:
x, l, l , t(Pre(Move(x, l, l ))(t) At(x, l)(t))

(12)

x, l, l , t(Eff(Move(x, l, l ))(t) At(x, l )(t))

(13)







x, l, l , t((At(x, l)(t) l = l ) At(x, l )(t))

(14)

x, y, l, t((At(x, l)(t) Holding(x, y)(t)) At(y, l)(t))

(15)

U [O, B, L1, L2]
At(O, L1)(1) Holding (O, B)(1) Occ(M ove(O, L1, L2))(1)

(16)

Thus effects Move simplified. fact moved object longer
inferred Axiom (14), states object two
different locations simultaneously, together appropriate inequality. intention
use Axiom (15) infer Ollies movement results movement block B. For,
given Ollie holding B gets L2, follows axiom B L2
also; so, axioms (14) (16), B L1.
However, two representative preferred 1 models 3 , partially
described follows:
M1 {At(O, L2)(2), Holding (O, B)(2), At(B, L2)(2)} ,
M2 {At(O, L2)(2), At(B, L1)(2)} .
change preferred inertia, Ollie succeeds moving L2 models. M1 ,
fact Ollie holding B inert, follows block moves
L2 expected. M2 , fact B L1 inert, so, contrary expectation, B
remains L1.
One reaction failure seek strengthen axioms Axiom (15) making
causally directed, interpreted causally (positively, M1 ),
380

fiNatural Events

rather declaratively (positively M1 , contrapositively M2 ). However
seems response (which discussed Section 7) mistaken
misdiagnoses problem; taking logical problem rather representational
one.
Let us consider problem posed example afresh. theory 3 two
representative preferred models one corresponds expectation.
accounts asymmetry expectation, formal symmetry
broken?
intended positive interpretation Axiom (15) depends appropriate reasoning
inertia, particular appropriate use inertia axiom; necessary
conclude Ollie keeps hold block, rather concluding remains L1.
seems odd using inertia axiom reasoning change; using
inertia axiom (together Axiom (15)) get block move without
event causes move. violating fundamental intuition
underlies fact-event distinction; events causes
physical change.
consideration provides key correct understanding problem.
expect block move Ollie told holding
block moves told releases it. Consequently discount
possibility block remaining L1 additional event would required
order account this. However movement block additional event
additional effect block L2. missing, symmetry-breaking,
causal element example thus event, choice move event
release event seems clear. note blocks moving differs Ollies moving.
block moves Ollie moves holding
so.
order reflect difference, distinction drawn primary secondary
events. Primary secondary events inductive events kind
considering far. However primary events occur independently, secondary events
invoked (in non-mystical Computer Science sense one program (procedure,
process, . . . ) said invoke another) events, causally dependent
sense secondary event succeed invoked invoked
successful event.22 Given distinction, ramifications represented invoking
appropriate secondary events appropriate contexts. Thus, Example 3, Ollies moving
represented primary event which, holding block B moves,
invokes secondary move-B event. move-B event occurs invoked,
succeeds move-Ollie event does. Note secondary events may, turn,
invoke events causally dependent them. instance, current
example block B placed top block B, invoked move-B event turn
invoke move-B event. thus tertiary events, events ever higher order.

22. condition perhaps called success dependence effect dependence order distinguish counterfactual dependence (Lewis, 1986, Ch. 21).

381

fiBell

Table 3: theory invocation, Inv
e, e , t(Inv1 (e, e )(t) (Occ(e)(t) Occ(e )(t)))






(17)




e, t((Succ(e)(t) e Inv1 (e , e)(t)) e (Inv1 (e , e)(t) Succ(e )(t)))














(18)

e, e , t(Inv(e, e )(t) (Inv1 (e, e )(t) e (Inv1 (e, e )(t) Inv(e , e )(t))))

(19)

e, TInv(e, e)(t)

(20)

However, sake convenience, invoked events referred secondary
events.23
Invocations represented EL invocation atoms. invocation atom event
atom form Inv1 (e, e )(t), states event e directly invokes event e time t.
Secondary events typically invoked invocation axioms form:
e, e , t((Occ(e)(t) ) Inv1 (e, e )(t)) ;
formula distinguishes contexts e invokes e . properties
secondary events stated axioms (17)-(20) given Table 3. Axiom (17) requires
invoking invoked events occur. Axiom (18) represents (causal) dependence,
states secondary event succeeds one events invoked
succeeds. axiom stated way order allow cases secondary
event invoked one event. Axioms (19) (20) ensure invocation
acyclic. achieved defining auxiliary (indirect invocation) relation Inv
transitive closure (direct invocation) relation Inv1 (Axiom (19)) requiring
Inv irreflexive (Axiom (20)).24
Events invoke others thought two ways: elementary inductive
events, complex events causal structure. invocation graph
23. Primary secondary events called loose analogy philosophical distinction
primary secondary qualities. Primary qualities (such size, shape motion) fundamental
qualities used science. contrast, secondary qualities sensory qualities (such colour, taste,
smell, felt warmth texture, sound) exist certain contexts (to individual observers
specific conditions) causally dependent primary qualities. Similarly, tertiary
qualities qualities object virtue secondary qualities; example flower
may attractive butterfly colour, wine may expensive taste
(Blackburne, 1994).
24. axiomatization secondary events intended minimal. example, prohibition
event occurring primary event secondary event. happen,
would follow Axiom (18) event would secondary status. certain circumstances
may desirable define order event, require event exactly one order.
done adding axioms following:
e, t(Ord(e, n)(t) ((n = 1 Occ(e)(t) Te Inv1 (e , e)(t))
(n > 1 e (Ord(e , n1)(t) Inv1 (e , e)(t))))) ,
e, n, m, t((Ord(e, n)(t) n = m) TOrd(e, m)(t)) .

382

fiNatural Events

event e (at time point t) directed acyclic graph whose initial vertex e, whose
remaining vertices events invoked e (either directly indirectly), whose edges
represent direct invocation relation. Event es success graph (at t) subgraph
es invocation graph consists chains invocation graph begin
e consist entirely successful events. direct effects e defined
(invariant) effects. indirect effects e effects events success
subgraph. So, particular, successful inductive events thought
effects successful secondary events invoke (either directly indirectly).
Thus, working example, move-Ollie event direct effect moves,
thought indirect context-dependent effects B B move
him. Note effects event may context-dependent two ways.
event may invoke different events different contexts (recall invocation axioms may
context-dependent), invocation graph may vary according context
occurs. Moreover, invocation graph may result different success graphs
context varies ways. instance, working example, move-B may
invoked two different contexts (in B B), succeed one (the
one contemplating) fail another (say B also held
another agent).
Definition 11 theory invocation, Inv , consists axioms given Table 3;
thus Inv = {(17), . . . , (20)}.
invocation atoms event atoms, pragmatics given last section
used without change.
give formal version extension block-carrying example.
Example 4 Ollie location L1. holding block B1, block B2 stacked B1,
block B3 stacked B2. Ollie moves location L2. expect move event
succeed stack blocks move him. However if, independent
reason, B2 move, expect B3 also remain L1.
first part example represented event theory 4 = Ind Inv
{(12), . . . , (15)} {(21), . . . , (24)}, where:
x, y, l, t((On(x, y)(t) At(y, l)(t)) At(x, l)(t))


(21)



x, y, l, l , t((Occ(Move(x, l, l ))(t) Holding (x, y)(t))
Inv1 (Move(x, l, l ), Move(y, l, l ))(t))


(22)



x, y, l, l , t((Occ(Move(x, l, l ))(t) On(y, x)(t))
Inv1 (Move(x, l, l ), Move(y, l, l ))(t))

(23)

U [O, B1, B2, L1, L2] U [Move] At(O, L1)(1) Holding (O, B1)(1)
On(B2, B1)(1) On(B3, B2)(1) Occ(M ove(O, L1, L2))(1)

(24)

Axiom (21) states object x object x location is,
axioms (22) (23) invocation axioms representing ramifications. Axiom (22) states
move-x event invokes move-y event contexts x holding y. Similarly,
383

fiBell

Axiom (23) states move-x event invokes move-y event contexts
x.
single representative preferred 1 model 4 , Ollies movement
successfully invokes movement B1 (because Ollie holding B1 moves),
turn successfully invokes movement B2 (because B2 B1 B1 moves),
turn successfully invokes movement B3 (because B3 B2 B2
moves). Thus, accordance expectation, 4 predicts Ollie succeeds moving
L2 entire stack blocks. Note success invoked event depends
success event invoked it. Thus, example, 4 extended B2
remains L1, extended theory predicts B3 also remains L1.
Proposition 4 |1 At(B3, L2)(2), 4 {At(B2, L1)(2)} | 1 At(B3, L1)(2).
Proof first part, let preferred 1 model 4 . Occ(Move(O, L1, L2))(1)
Holding(O, B1)(1) true (Axiom (24)). follows (axioms (17), (22))
Inv1 (Move(O, L1, L2), Move (B1, L1, L2))(1) Occ(Move(B1, L1, L2))(1) true
. So, On(B2, B1)(1) true (Axiom (24)), follows (axioms (17), (23)),
Inv1 (Move(B1, L1, L2), Move (B2, L1, L2))(1) Occ(Move(B2, L1, L2))(1) true
. so, On(B3, B2)(1) true (Axiom (24)), follows (axioms (17),
(23)) Inv1 (Move(B2, L1, L2), Move (B3, L1, L2))(1) Occ(Move(B3, L1, L2)(1)
true . invocation atoms temporal index 1 defined (Definition 8.1), four events Move(O, L1, L2), Move(B1, L1, L2), Move(B2, L1, L2),
Move(B3, L1, L2), occur time 1 , linked chain invocations
time 1 .25 Moreover, preconditions four events true (axioms (12), (15), (21), (24)). Move(O, L1, L2) primary event time 1
, follows (Definition 8.2) Succ(Move(O, L1, L2))(1) true . Moreover,
Move(B1, L1, L2) directly invoked successful event time 1 , follows (Definition 8.2) Succ(Move(B1, L1, L2))(1) true . Similar reasoning shows success
propagated rest invocation chain; that, turn, Succ(Move(B2, L1, L2))(1)
hence Succ(Move(B3, L1, L2))(1) true . So, Succ(Move(B3, L1, L2))(1)
true , follows (axioms (1), (13)) At(B3, L2)(2) true .
second part, let preferred 1 model 4 = 4 {At(B2, L1)(2)}.
Then, above, events Move(O, L1, L2), Move(B1, L1, L2), Move(B2, L1, L2),
Move(B3, L1, L2) occur time 1 , preconditions true time 1
, linked unique invocation chain time 1 . above,
first two events chain succeed. However, model 4 , At(B2, L1)(2)
true . follows (axioms (14), (24)) At(B2, L2)(2) true . therefore follows (axioms (1) (13)) Succ(Move(B2, L1, L2))(1) true . So,
Move(B2, L1, L2) event directly invokes Move(B3, L1, L2) time 1
, follows Te(Inv1 (e, Move(B3, L1, L2))(1) Succ(e)(1)) true .
T(Succ(Move(B3, L1, L2))(1) e Inv1 (e, Move(B3, L1, L2))(1)) true (Axiom (18)). Inv1 (Move(B2, L1, L2), Move (B3, L1, L2))(1) true Succ
25. unique-names axiom Move Axiom (24) ensures events distinct. view
axioms (19) (20) appeal unique-names axiom strictly necessary. However,
subsequent examples involving multiple events simpler add unique-names axioms
events, assume proofs distinct event terms denote distinct events.

384

fiNatural Events

relation classical (Axiom (1)), follows Succ(Move(B3, L1, L2))(1) true .
However, Phys(At) At(B3, L1)(1) true (axioms (15), (21), (24), Definition 9), follows inertia (Axiom (3), Definition 8.3) At(B3, L1)(2) true
M.
Note introduction secondary events missing causal elements
example, inertia axiom domain axioms ((14), (15) (21)) confined
proper tasks; namely, representing inertia, defining constraining relation
respectively.
philosophical terms, invocations provide means representing contemporaneous
sufficient causation events. Thus event e directly invokes event e time t,
e sufficient cause e t. direct invocation relation, Inv1 , thus represents
causal directedness (causal priority) contemporaneous events. Axioms (17)
(18) respectively ensure contemporaneous causation occurs actual events,
invoked event efficacious invoked efficacious event. account
contemporaneous sufficient causation thought terms regularities, however
reasoning complex; example, might discover event e directly
invokes event e noting whenever e occurs condition true e also occurs,
whenever case e succeeds e does.
Contemporaneous (sufficient) causation events naturally required asymmetric (axioms (19) (20)). However, suggested also cases
symmetric contemporaneous causation events. Taylor (1975) gives example
locomotive caboose coupled together way locomotive
moves iff caboose does. analogous example, suggested Denecker, Dupre,
Belleghem (1998), involves pair gears interlocked, gear rotates
iff does.
become clear, better view cases involving symmetric constraints
contemporaneous events, rather symmetric causation them. Now, clearly,
symmetric constraints cannot represented invocations.26 However, represented individual basis adding particular axioms. example, symmetric
constraint rotation gears represented following axiom:
g, g , t(Intl (g, g )(t) ((Occ(Rot (g))(t) Occ(Rot (g ))(t))
(Succ(Rot (g))(t) Succ(Rot (g ))(t)))) .
first conjunct consequent axiom required order ensure
rotations pairs interlocked gears co-occur; without it, would possible one
rotate events occur fail without occurring. Note also that,
introducing problem, Denecker et al. (1998, p. 34) require representation
behaviour interlocked gears rotate spontaneously.
present problem theories based classical logic; semantics
26. attempt case gears would use following axiom:
g, g , t((Occ(Rot (g))(t) Intl (g, g )(t)) Inv1 (Rot (g), Rot (g ))(t)) .
clearly Intl(g, g )(t), Intl(g , g)(t) Occ(e)(t) hold, contradiction results
axiom axioms (17), (19) (20).

385

fiBell

Table 4: theory symmetrically constrained events, SCon
e, TSCon(e, e)(t)








(25)


e, e , t(SCon(e, e )(t) SCon(e , e)(t))

(26)




e, e , t(SCon(e, e )(t) ((Occ(e)(t) Occ(e )(t)) (Succ(e)(t) Succ(e )(t)))) (27)
e, e , t(SCSet(e, e )(t)
(SCon(e, e )(t) e (SCon(e, e )(t) SCSet(e , e )(t))))


(28)



e, e , t(EInv(e, e )(t)
(Inv1 (e, e )(t) e (SCSet(e , e )(t) TSCSet(e, e )(t)))) (29)
e, e , n, t(IPath(e, e , n)(t)
((n = 0 e = e e EInv(e , e)(t))
(n > 0 e (IPath(e, e , n1)(t) SCon(e , e )(t))))) (30)
e, e , t((SCon(e, e )(t)
e , n(IPath(e , e, n)(t)
e , m(IPath(e , e , m)(t) > n)) Inv1 (e, e )(t))) (31)

classical biconditionals. However potential pitfall effortlessly avoided event theories
accurate representation partiality; Intl (g, g )(t) given,
Occ(Rot (g))(t) Occ(Rot (g ))(t) undefined.
general treatment symmetric constraints events given introducing
symmetric constraint relation SCon. relation represents co-occurrence
co-dependence pairs events. Accordingly expect SCon irreflexive,
symmetric, hold pairs co-occurring events also co-dependent.
properties stated axioms (25)-(27) Table 4.
considered isolation, fact two events symmetrically constrained
provides compelling evidence either cause other. example,
gears case, know g g interlocked g rotating,
reasonable conclude g also rotating, reasonable conclude
rotation g cause rotation g vice versa. Indeed, two events may
even causally connected; gears might rotating shaft
attached driven.
However, additional, external, information direction causation,
use infer direction causation pairs symmetrically constrained events.27 example, know gear g driven (say rotating
shaft attached to), dont know gear g driven,
reasonable conclude driving g causally prior rotation g,
rotation g turn causally prior rotation g . formally,
Inv1 (Drive(g), Rot (g))(t) SCon(Rot (g), Rot (g ))(t), seems reasonable
27. Taylor makes similar appeal external cause discussion locomotive-caboose example.

386

fiNatural Events

conclude Inv1 (Rot (g), Rot (g ))(t). external invocation chain thus extended
across symmetric constraint link. construction invocation chains kind
defined axioms (28)-(31) given Table 4.
Axiom (28) states that, time t, events e e symmetrically constrained set iff symmetrically constrained occur chain symmetric
constrained events.
Axiom (29) defines conditions external invocation symmetrically constrained event. Thus, time t, event e externally invokes event e iff e invokes e e
symmetric constraint set include e.
invocation path symmetrically constrained set begins externally invoked
event consists chain events symmetrically constrains neighbour.
length invocation path determined number links contains;
invocation path consisting externally invoked event length 0, one
consisting event neighbour length 1, etc. Accordingly, Axiom (30)
states conditions invocation path length n events e
e .
Finally, Axiom (31) defines invocation paths symmetrically constrained sets.
requiring invocation link exist symmetrically constrained events e
e whenever shortest invocation path e symmetrically constrained set
shorter shortest invocation path e set.
Definition 12 theory symmetric constraints, SCon , consists axioms given
Table 4; thus SCon = {(25), . . . , (31)}.
ideas illustrated following elaboration gears example.
Example 5 Five interlocking gears, G1 , . . . , G5 , arranged row. G1
driven, invokes rotation G1 , and, hGi , Gi+1 pair, rotation
Gi invokes rotation Gi+1 . However G1 G5 driven, rotation
invokes rotation neighbour, and, turn, rotations invokes
rotation G3 .
first part example represented event theory 5 = Ind Inv
SCon {(32), . . . , (39)}, where:
g, t(Pre(Drive(g))(t) Free(g)(t))

(32)

g, t(Eff(Drive(g))(t) Rotd (g)(t))

(33)

g, t(Pre(Rot (g))(t) Free(g)(t))

(34)

g, t(Eff(Rot (g))(t) Rotd (g)(t))

(35)







g, g , t(Intl (g, g )(t) Intl (g , g)(t))

(36)

g, t(Occ(Drive(g))(t) Inv1 (Drive(g), Rot (g))(t))






g, g , t(Intl (g, g )(t) SCon(Rot (g), Rot (g ))(t))

(37)
(38)

U [G1 , . . . , G5 ] U [Drive, Rot ]


5
^

i=1

Free(Gi )(1)

4
^

Intl (Gi , Gi+1 )(1) Occ(Drive(G1 ))(1)

i=1

387

(39)

fiBell

sake simplicity preconditions effects drive events
rotate events objects assumed gears. Thus gear driven
(can rotate) free so, effect driven (rotating)
rotated (in direction degree are, simplicity, represented).
Axiom (36) states Intl relation (which represents pairs interlocked gears)
symmetric. Axiom (37) states drive-g event invokes rotate-g event, Axiom (38)
states gears g g interlocked, rotation symmetrically constrained.
theory 5 single representative preferred 1 model five gears rotate single invocation chain hDrive(G1 ), Rot (G1 ), Rot (G2 ), Rot (G3 ),
Rot (G4 ), Rot (G5 )i.
Moreover, extended theory 5 {Occ(Drive(G5 ))(1)}, single preferred 1 model
five gears rotate, two invocation chains; hDrive(G1 ),
Rot (G1 ), Rot (G2 ), Rot (G3 )i hDrive(G5 ), Rot (G5 ), Rot (G4 ), Rot (G3 )i.
Proposition 5 |1 Succ(Rot (Gi ))(1) 1 5, 5 |1 Inv(Rot (G1 ), Rot (G5 ))(1).
Moreover, 5 = 5 {Occ(Drive(G5 ))(1)}, 5 |1 Succ(Rot (Gi ))(1) 1 5,
5 |1 Inv(Rot (G1 ), Rot (G3 ))(1) 5 |1 Inv(Rot (G5 ), Rot (G3 ))(1).
Proof Let preferred 1 model 5 . follows, axioms (17), (37)
(39), Occ(Drive(G1 ))(1), Inv1 (Drive(G1 ), Rot (G1 ))(1), Occ(Rot (G1 ))(1) true
. Axiom (39), Intl (G1 , G2 )(1) true , follows Axiom (38)
SCon(Rot (G1 ), Rot (G2 ))(1) true . follows, axioms (26) (27),
SCon(Rot (G2 ), Rot (G1 ))(1) Occ(Rot (G2 ))(1) true . Similar reasoning shows
1 4, SCon(Rot (Gi ), Rot (Gi+1 ))(1) SCon(Rot (Gi+1 ),
Rot (Gi ))(1) true , that, 1 5, Occ(Gi )(1) true .
axioms (32), (34) (39), Pre(Drive(G1 ))(1) true , Pre(Rot (Gi ))(1)
1 5. Definition 8.2, Succ(Drive(G1 ))(1) true ,
Succ(Rot (Gi ))(1) 1 5.
Axiom (28), set SI = {Rot (Gi ) : 1 5} symmetric constraint set
time 1 , Definition 8.1 set. follows Axiom (29)
EInv(Drive(G1 ), Rot (G1 ))(1) true . Moreover follows, Definition 8.1
Axiom (29), Rot (G1 ) initially invoked event SI. follows
Axiom (30) hRot (G1 ), Rot (G1 )i influence path length 0 SI,
shortest influence path G2 SI hRot (G1 ), Rot (G2 )i length 1. follows
Axiom (31) Inv1 (Rot (G1 ), Rot (G2 ))(1) true . analogous reasoning,
shortest influence path G3 SI path hRot (G1 ), Rot (G2 ), Rot (G3 )i
length 2, Inv1 (Rot (G2 ), Rot (G3 ))(1) true . Similar reasoning shows
Inv1 (Rot (G3 ), Rot (G4 ))(1) Inv1 (Rot (G4 ), Rot (G5 ))(1) true . follows
Axiom (19) Inv(Rot (G1 ), Rot (G5 ))(1) true .
let preferred 1 model 5 . reasoning analogous given above,
Succ(Drive(G1 ))(1) true , Succ(Rot (Gi ))(1) 1 5. also
SI = {Rot (Gi ) : 1 5} symmetric constraint set time 1
. However time Rot (G1 ) Rot (G5 ) initially invoked events SI.
shortest influence path G2 SI path hRot (G1 ), Rot (G2 )i length 1,
so, before, Inv1 (Rot (G1 ), Rot (G2 ))(1) true . Analogous reasoning shows
388

fiNatural Events

hRot (G5 ), Rot (G5 )i influence path SI length 0 shortest influence path
G4 SI path hRot (G5 ), Rot (G4 )i length 1, Inv1 (Rot (G5 ), Rot (G4 ))(1)
true . Moreover, shortest influence paths Rot (G3 ) SI paths
hRot (G1 ), Rot (G2 ), Rot (G3 )i hRot (G5 ), Rot (G4 ), Rot (G3 )i, length 2. follows Axiom (31) Inv1 (Rot (G2 ), Rot (G3 ))(1) Inv1 (Rot (G4 ), Rot (G3 ))(1) true
. Thus Axiom (19), Inv(Rot (G1 ), Rot (G3 ))(1) Inv(Rot (G5 ), Rot (G3 ))(1)
true .
Secondary events also used represent non-deterministic effects.
Non-deterministic effects may arise uncertainty preconditions. Suppose, example, initial positions blocks B B uncertain, either B
B conversely, B moved. Intuitively resulting location B
uncertain. B B, B moved location B, otherwise
B remained was. easy see Example 4 adapted
represent example faithfully. B B initially, move-B event invokes
secondary move-B event (Axiom (23)) results B moving B, otherwise
location B remains unchanged. resulting theory thus two representative
preferred1 models; one B moves, one B move.
non-deterministic effects may also arise outcome events question
uncertain. successful, non-deterministic event regularly followed definite
effect, rather one set mutually exclusive possible effects; classic
example tossing fair coin. terms used introduction, expectations
regarding outcome events unclear. order see secondary events
needed represent these, consider following attempt represent coin-tossing.
Example 6 Suppose fair coin showing heads initially coin tossed.
coin fair, result uncertain; coin may show heads may show
tails. Let 6 = Ind {(40), (41), (42)} where:
t(Pre(Toss)(t) (Heads(t) Tails(t)))

(40)

t(Eff(Toss)(t) (Heads(t) Tails(t)))

(41)

Heads(1) Tails(1) Occ(Toss)(1)

(42)

Then, contrary intention, 6 deterministic 1 . 6 single representative preferred 1
model Toss event succeeds effect Heads(2) Tails(2) true. However,
Heads(1) true model, normal application inertia axiom removes
uncertainty determining Heads(2) true.
If, example, one alternative effects event preserves status
quo, inertia favour outcome determine outcome event.
fact inertia intervenes way example suggests something missing
representation toss event. defined, event
intended do. succeeding ensure two distinct outcomes.
Metaphorically speaking, introduce fork point history, resulting
two alternative futures. seems hidden causal element accounts
intuitive understanding example missing formalization it.
389

fiBell

suggest missing component causal structure toss event,
faithfully represented two conflicting secondary events; tossing coin
invokes two conflicting deterministic events, one resulting coin showing heads,
resulting coin showing tails.
formalizing subsequent examples involving nondeterministic events,
following abbreviation useful:
Inv1 (e, {e1 , . . . , en })(t) =Df

Inv1 (e, e1 )(t) . . . Inv1 (e, en )(t) .

Example 7 Let 7 = Ind Inv {(40), . . . , (46)} where:
t(Pre(TossH )(t) Pre(Toss)(t)) t(Eff(TossH )(t) Heads(t))

(43)

t(Pre(TossT )(t) Pre(Toss)(t)) t(Eff(TossT )(t) Tails(t))

(44)

t(Occ(Toss)(t) Inv1 (Toss, {TossH , TossT })(t))

(45)

U [Toss, TossH , TossT ]

(46)

two representative preferred 1 models 7 . models, primary
event Toss succeeds invokes conflicting secondary events TossH TossT . one
models, TossH succeeds TossT fails. model, TossT succeeds
TossH fails.
Proposition 7 |1 Heads(2) Tails(2), 7 |61 Heads(2), 7 |61 Tails(2).
Proof first part, let preferred 1 model 7 . Toss event occurs
time 1 (Axiom (42)) occurrence invokes secondary TossH TossT
events (Axiom (45)), also occur time 1 (Axiom (17)). preconditions
three events true time 1 (axioms (40), (42)-(44)). However, view
effects (axioms (41), (43), (44)), three events cannot succeed time 1 . Toss
invokes two events, event (Definition 8.1), TossH
TossT succeed Toss (Axiom (18)). Moreover, consistent assume
Toss succeed time 1 , follows (Definition 8.2) Toss succeed
time 1 , effect Heads(2) Tails(2) true (axioms (1), (41)).
second part sufficient show preferred 1 model 7
Heads(2) false. So, let EL model R Phys(R) true, satisfies
Axiom (46), satisfies following conditions. evidential atoms
defined satisfy following set literals:
{Heads(1), Tails (1), Occ(Toss)(1), Inv1 (Toss, TossH )(1), Occ(TossH )(1),
Inv1 (Toss, TossT )(1), Occ(TossT )(1)} {Tails(t) : 2} {Heads(t) : 2} ;
thus, example, Heads(1) true Tails(1) false . success atoms
set:
{Succ(Toss)(1), Succ(TossT )(1)}
true , every success atom false . Finally inertia atoms
set:
{Inert(Heads)(0), Inert(Tails)(0), Inert(Heads)(1), Inert(Tails)(1)}
390

fiNatural Events

false , every inertia atom true . Clearly exists. Moreover,
inspection shows preferred 1 model 7 . particular, success Toss
time 1 required (on grounds given proof first part) success
either TossH TossT time 1 (axioms (1), (41), (43), (44), Definition 8.2).
given model, TossT succeeds time 1, combined effect two successful
events Heads(2) false (axioms (1), (41), (44)).
proof third part similar; TossH (rather TossT ) succeeding
time 1 given model.
similar problem posed Russian Shooting Problem (Sandewall, 1994).
revolver loaded single bullet cylinder spun. result
uncertain, cylinder could come rest bullet one six possible
positions. However naive representation, inertia will, again, favour outcome
bullet returns to, effectively remains in, original position. faithful
representation expected outcome spin event obtained invoke
six conflicting secondary spin events, result bullet equally likely come
rest six possible positions.
generally, non-deterministic event seen invoking set conflicting
deterministic events, resulting one possible outcomes.
two possible outcomes, following general form exclusive
alternation useful:
1 | 2 | . . . | n =Df

n
_

m1
^

(

m=1 i=1



n
^

j ) .

j=m+1

Thus 1 | 2 | . . . | n true exactly one alternatives true remainder
false, false alternatives false one true,
undefined otherwise.28
techniques representing ramifications non-deterministic events readily
combined represent events conditional effects, crossing points
railway line. Suppose point P entry point PE , left exit point PL, right
exit point PR. Suppose P set left, train crossing P
emerge PL, otherwise P set right, train emerge PR.
preconditions crossing P simply train PE P set
either left right, effect train either PL PR. P set
left train crosses, event invoke cross-P -left event,
precondition train PE P set left, effect
train PL. Similarly, P set right train crosses, event
invoke cross-P -right event effect train emerges PR.

5. Event Preferences
Conflicts reductio ad absurdum Deductionism. two events conflict,
effects cannot, pain inconsistency, deduced. Consequently, Deductionists wishing
28. So, n = 2, exclusive alternation exclusive disjunction. n > 2, two notions
differ; example, exclusive disjunction 1 (2 3 ) true 1 2 3 is.

391

fiBell

represent simultaneous events forced police events regulate
effects. Gelfond, Lifschitz, Rabinov (1991) suggest done means
cancellations. Suppose, example, bowl full soup. one side
bowl lifted, soup spilt. However, sides bowl lifted
simultaneously, soup spilt. interactions represented means
two elementary lift events (lift-left-side, lift-right-side) composition (lift-bothsides). either elementary events occurs isolation, effect
soup spilt. complex event occurs, spill-effects component actions
cancelled, result bowl lifted soup spilt.
However cancellations appropriate ignore possibility failure. Suppose
reality one elementary lift events fails hand slips. effects
component event cancelled soup spilt.
cancellation cancelled?
Conflicts pose problem inductive events. faced conflicting events expect succeed. Some, possibly all,
expectations regarding events uncertain. reflected formal theory:
conflicting effects give rise conflicting success atoms, resulting failure rather inconsistency. However possibility failure raises problem over-weak predictions
(which amusingly complements over-strong problem Deductionism). two inductive events conflict (and interactions involving them), succeeds
preferred model fails, consequently nothing definite
disjunction effects predicted. appropriate events equal
status; indeed, provides basis representation non-deterministic events given
previous section. appropriate expect one events
succeed. Suppose, example, Stan Ollie attempt move location
simultaneously one succeed. Suppose Ollies success
likely Stans, say bigger. normally expect Ollie
succeed Stan fail. However, abnormal independent circumstances
lead us expect Ollie fail, lead us expect Stan
fail also. Indeed, circumstances, expect Stan succeed. example,
Ollie trips, expect Stan succeed; although, course, may also trip,
etc.
Asymmetric expectations kind thought event preferences, preferences outcomes events. Thus events e e conflict, expect
e succeed, success e preferred e . However, examples
show, preferences kind defeasible order prejudice success
non-preferred event preferred event fail independent reason.
Event preferences represented EL preference atoms, event atoms
form Pref(e, e )(t). keeping discussion, interpreted
stating success event e normally preferred event e
conflict time t. temporal index accommodates possibility event preferences
may vary time; Example 10 below.
logical restriction event preferences required asymmetric (Axiom (47) Table 2). conditions, transitivity, can, course,
added appropriate.
392

fiNatural Events

Table 5: theory event preferences, Pref
e, e , t(Pref(e, e )(t) TPref(e , e)(t))

(47)

Definition 13 theory event preferences given axioms Table 5; thus
Pref = {(47)}. theory natural events, NE , consists axioms given tables 2,
3, 4, 5; thus NE = Ind Inv SCon Pref .
intended interpretation event preferences cannot enforced adding axiom:
e, e , t((Pref(e, e )(t) Pre(e)(t) Occ(e)(t) Succ(e )(t)) Succ(e)(t)) .
Adding axiom would ensure e e conflict, e would succeed (and
e would fail). However, e fail independent reason, axiom
would undesirable effect forcing failure e .
Clearly, event preferences interpreted correctly, flexible approach
needed, necessary extend pragmatics event theories contain
them. aim produce consistent interpretation applicable event
preferences possible, ignore otherwise.
begin with, distinction drawn preferential events, events
preferences consistently applied, non-preferential events, remaining
events consideration. event e said supported model time e
occurs es preconditions true (if Pre(e)(t) Occ(e)(t) true
). e supported time point model, time point model
clear context, e simply said supported. Now, applicable
event preferences form acyclic chain Pref(e, e )(t), Pref(e , e )(t), . . . , supported
events occurring ordered lexicographically; thus given e, e e
supported, e order 1, e order 2, e order 3. generally, model
time point t, supported event e may (or may not) assigned preference rank follows:
e preference rank 1 event e Pref(e, e )(t) true
supported event e Pref(e , e)(t) true,
e preference rank n e preference rank < n
supported event e preference rank n 1 directly preferred e (which
Pref(e , e)(t) true supported event e
preferences Pref(e, e )(t) Pref(e , e )(t) true).
Let e supported event (at time model ). e preferential event (at
) e preference rank (at ), otherwise e non-preferential event (at time
model ).
suppose time models agree event preferences, preferential
events, non-preferential events. Then, t:
393

fiBell

better preferential events preference rank n
agree success events preference rank < n,
events preference rank n succeed ,
good preferential events better preferential
events, agree success preferential events,
better non-preferential events non-preferential events succeed
,
good non-preferential events better nonpreferential events, agree success non-preferential events.
definition preferred model refined.
Definition 14 (Preference2 ) Let models differ interpretation temporally-indexed relations. preferred2 (written 2 )
iff time point agree t, t:
1. fewer evidential atoms defined , agree truth values
evidential atoms defined ;
2. differ conjectural atoms, either
(a) better preferential events, good nonpreferential events;
(b) good preferential events, better nonpreferential events;
3. differ inertia atoms, inertia atoms true .
Note preference2 reduces preference1 event theories include event
preferences.
Four examples given. first illustrates interpretation event preferences.
Example 8 Suppose three agents, Stan, Ollie, Charlie, locations L1, L2
L3 respectively. assumed one agents location point
time, two attempt move location simultaneously,
one succeed. Ollie Stan attempt move location L4 then,
Ollie bigger, Ollies success expected. Similarly, Stan Charlie attempt
move L4 simultaneously, then, Stan bigger, Stans success expected. However,
Charlie much faster Ollie, attempt move L4 simultaneously,
Charlies success expected. Now, suppose fact Stan Ollie attempt
move L4 simultaneously, then, indicated, Ollies success expected. However,
Charlie also attempts move L4, result uncertain preferences
among move events longer interpreted consistently.
394

fiNatural Events

Let 8 = Ind Pref {(12), (13), (14)} {(48), . . . , (52)}; where:
x, y, l, t((At(x, l)(t) x = y) At(y, l)(t))

(48)

Pref(Move(O, L1, L4), Move (S, L2, L4))(1)

(49)

Pref(Move(S, L2, L4), Move (C, L3, L4))(1)

(50)

Pref(Move(C, L3, L4), Move (O, L1, L4))(1)

(51)

U [O, S, C, L1, L2, L3, L4] U [Move]
At(O, L1)(1) At(S, L2)(1) At(C, L3)(1)
Occ(Move(O, L1, L4))(1) Occ(Move(S, L2, L4))(1)

(52)

8 single representative preferred 2 model Ollie succeeds moving
L4. However extended theory 8 = 8 {Occ(Move(C, L3, L4))(1)} three representative preferred 2 models, different member trio succeeds them.
Proposition 8 |2 At(O, L4)(2). However 8 |62 At(O, L4)(2), 8 |62 At(S, L4)(2),
8 |62 At(C, L4)(2).
Proof first part, let preferred 2 model 8 . (Definition 14.1)
events occur time 1 Move(O, L1, L4) Move(S, L2, L4). follows
axioms (12) (52) events supported time 1 .
view effects, one events succeed (axioms (1), (13), (48), (52)).
axioms (49)-(51) Definition 14.1, preference atoms true
Pref(Move(O, L1, L4), Move (S, L2, L4))(1), Pref(Move(S, L2, L4), Move (C, L3, L4))(1),
Pref(Move(C, L3, L4), Move (O, L1, L4))(1). view first these,
event e Pref(Move(O, L1, L4), e)(1) true . And, Move(C, L3, L4)
supported time 1 , supported event e Pref(e, Move(O, L1, L4))(1)
true . Move(O, L1, L4) preference rank 1 time 1 . Moreover,
Move(S, L2, L4) preference rank 1 time 1 , Move(O, L1, L4)
supported event time 1 Pref(Move(O, L1, L4), Move (S, L2, L4))(1) true
. So, Move(O, L1, L4) directly preferred Move(S, L2, L4) time 1 ,
follows Move(S, L2, L4) preference rank 2 time 1 . therefore follows
Definition 14.2(a) Succ(Move(O, L1, L4))(1) true . Consequently effect
At(O, L4)(2) true (axioms (1), (13)).
second part, let EL model R Phys(R) true,
satisfies U [O, S, C, L1, L2, L3, L4] U [Move]. Suppose satisfies following conditions; Loc = {O, S, C, L1, L2, L3, L4}. object event atoms
defined satisfy following sets literals:
{At(O, L1)(t) : 1}, {At(O, l)(t) : 1, l Loc, l 6= L1},
{At(S, L2)(1)}, {At(S, L4)(t) : 2)},
{At(S, l)(1) : l Loc, l 6= L2}, {At(S, l)(t) : 2, l Loc, l 6= L4},
{At(C, L3)(t) : 1} {At(C, l)(t) : 1, l Loc, l 6= L3},
{Occ(Move(O, L1, L4))(1), Occ(Move(S, L2, L4))(1), Occ(Move(C, L3, L4))(1)},
395

fiBell

{Pref(Move(O, L1, L4), Move (S, L2, L4))(1),
Pref(Move(S, L2, L4), Move (C, L3, L4))(1),
Pref(Move(C, L3, L4), Move (O, L1, L4))(1)}.
success atom Succ(Move(S, L2, L4))(1) true success atoms
false . Finally, inertia atoms following sets false :
{Inert(At, hO, li)(0) : l Loc}, {Inert(At, hC, li)(0) : l Loc},
{Inert(At, hS, li)(0) : l Loc}, {Inert(At, hS, li)(1) : l {L2, L4}},
inertia atoms true . Clearly exists. Moreover, inspection shows
preferred 2 model 8 . particular, success Move(S, L2, L4) time 1
justified follows. three events supported time 1
Move(O, L1, L4), Move(S, L2, L4), Move(C, L3, L4) (axioms (12), (52), definition
8 , Definition 14.1). preference atoms true
set given (axioms (49)-(51), Definition 14.1). none three supported events
preference rank 1 time 1 ; Move(O, L1, L4) Move(C, L3, L4)
supported preferred it, Move(S, L2, L4) Move(O, L1, L4)
supported preferred it, Move(C, L3, L4) Move(S, L2, L4)
supported preferred it. follows three events non-preferential time 1
. one events succeed time 1 (axioms (1), (13), (48), (52)).
follows Definition 14.2(b) one succeed. , Move(S, L2, L4)
succeeds time 1, effect At(S, L4)(2) consequently At(O, L4)(2)
true ((1), (13), (48), (52)).
given model also establishes fourth part proposition. third part
preferred 2 model 8 given either Move(O, L1, L4) Move(C, L3, L4)
succeeds time 1.
next example shows event preferences secondary events combined
order represent implicit cancellation implicit cancellation thereof.
Example 9 soup-bowl example represented follows:
t(Pre(LiftL)(t) HoldingL(t)) t(Eff(LiftL)(t) HoldingL(t))

(53)

t(Pre(LiftR)(t) HoldingR(t)) t(Eff(LiftR)(t) HoldingR(t))

(54)

t(Pre(Spill )(t) Spilt (t))

(55)

t(Eff(Spill )(t) (Spilt (t) (HoldingL(t) HoldingR(t))))

(56)

e, t((Occ(e)(t) (e = LiftL e = LiftR) Spilt(t)) Inv1 (e, Spill )(t))

(57)

t(Pre(Lift)(t) (Pre(LiftL)(t) Pre(LiftR)(t)))

(58)

t(Eff(Lift)(t) (Eff(LiftL)(t) Eff(LiftR)(t)))

(59)

t(Occ(Lift)(t) (Occ(LiftL)(t) Occ(LiftR)(t)))

(60)

tPref(Lift, Spill )(t)

(61)

U [Lift, LiftL, LiftR, Spill ]
HoldingL(1) HoldingR(1) Spilt(1) Occ(Lift)(1)
396

(62)

fiNatural Events

Thus axioms (53)-(56) define elementary lift-left (LiftL), lift-right (LiftR) spill events.
Axiom (57) states soup spilt, occurrence either elementary lift
event invokes spill event. Axioms (58)-(60) define complex lift-both event (Lift),
Axiom (61) states success lift-both event normally preferred spill
event.
Let 9 = Ind Inv Pref {(53), . . . , (62)}. 9 single representative
preferred 2 model Lift event succeeds Spill event fails; result
soup spilt. Thus success Lift event implicitly cancels (secondary)
Spilt effect component LiftL LiftR events. Moreover, extended theory 9
{Succ(Lift)(1)} two representative preferred 2 models. one LiftL succeeds (and LiftR
fails), LiftR succeeds (and LiftL fails). Spill succeeds effect
soup spilt. implicit cancellation Spilt effect thus implicitly
cancelled.
Proposition 9 |2 Spilt(2), 9 {Succ(Lift)(1)} |2 Spilt (2).
Proof first part, let preferred 2 model 9 . events Lift, LiftL,
LiftR supported time 1 (axioms (53), (54), (58), (60), (62)). Moreover
LiftL LiftR events invoke Spill event time 1 (axioms (57), (62)),
also supported time 1 (axioms (17), (55), (62)). Lift Spill events
conflict time 1 ; Lift succeeds, Spill fails, vice-versa (axioms (1), (53),
(54), (56), (59)). preference atom Pref(Lift, Spill )(1) preference atom
temporal index 1 true (Axiom (61), Definition 14.1). Consequently,
time 1 , Lift Spill preference ranks 1 2 respectively, LiftL LiftR
non-preferential. success Lift implies success component events (axioms (1), (53), (54), (59)). (Definition 14.2(a)) Lift succeeds (and Spill fails) time 1
. so, Phys(Spilt ) Spilt (1) true (Axiom (62), Definition 9),
follows inertia (Axiom (3), Definition 14.3) Spilt(2) true .
second part, let preferred 2 model 9 {Succ(Lift)(1)}. Then,
above, events Lift, LiftL, LiftR, Spill supported time 1 . Lift
fails (when supported) time 1 , one component lift-events must also fail
time 1 (axioms (1), (53), (54), (59)). However component event succeeds
time 1 (Definition 14.2(b)), consequently Spill (axioms (1), (53) (54),
(56), Definition 14.2(a)), effect Spilt(2) true (axioms (1), (56)).
next example shows event preferences secondary events used
represent changing expectations regarding outcome non-deterministic events.
Example 10 race fast horse strong horse run day
tomorrow. course currently dry. Given remains case, fast horse
expected win. However rain tomorrow, strong horse would
expected win.
example represented theory 10 = Ind Inv Pref {(63), . . . ,
(71)}; where:
t(Pre(RaceFS )(t) Occ(RaceFS )(t))
397

(63)

fiBell

t(Eff(RaceFS )(t) (WinnerF (t) WinnerS (t)))

(64)

t(Pre(WinF )(t) Pre(RaceFS )(t)) t(Eff(WinF )(t) WinnerF (t))

(65)

t(Pre(WinS )(t) Pre(RaceFS )(t)) t(Eff(WinS )(t) WinnerS (t))

(66)

t(Occ(RaceFS )(t) Inv1 (RaceFS , {WinF , WinS })(t))

(67)

t(Pre(Rain)(t) Occ(Rain)(t)) t(Eff(Rain)(t) Dry(t)))

(68)

t(Dry(t) Pref(WinF , WinS )(t))

(69)

t(Dry(t) Pref(WinS , WinF )(t))

(70)

U [RaceFS , WinF , WinS , Rain] Dry(1) Occ(RaceFS )(3)

(71)

Thus Axiom (64) states outcome successful race two horses
(RaceFS ) results either fast horse winning (WinnerF ) strong horse winning
(WinnerS ). causal structure RaceFS event (the fact involves competition two horses) represented invocation conflicting WinF WinS
events (axioms (64)-(67)). Rain results course wet (not dry) (Axiom (68)).
course dry, fast horse expected win (Axiom (69)), otherwise slow
horse expected win (Axiom (70)).
Proposition 10 |2 WinnerF (4), 10 {Occ(Rain)(2)} |2 WinnerS (4).
Proof first part, let preferred 2 model 10 . Phys(Dry) Dry(1)
true (Axiom (71), Definition 9), follows inertia (Axiom (3), Definition 14.3) Dry(3) true . Moreover, event RaceFS occurs time 3
invokes WinF WinS events (axioms (67), (71)). three events supported time 3 (axioms (17), (63), (65), (66), (71)). RaceFS invokes WinF
WinS , succeed (Axiom (18), Definition 14.1). follows
(Definition 14.2(b)) RaceFS succeeds time 3 . success exactly one
two invoked events time 3 consistent success RaceFS (axioms (64)-(66)).
Dry(3) true follows (Axiom (69)) Pref(WinF , WinS )(3) true .
Moreover preference atom temporal index 3 true (Definition 14.1). So, WinF WinS supported time 3 , follows
WinF preference rank 1 WinS preference rank 2 time 3 . Consequently
(Definition 14.2(a)) WinF succeeds time 3, effect WinnerF (4) true
(axioms (1) (65)).
second part, let preferred 2 model 10 {Occ(Rain)(2)}.
Rain event succeeds time 2 effect Dry(3) true (Axiom (68),
Definition 14.2(b)). proof first part, RaceFS one two conflicting
secondary events, WinS WinF , succeed time 3 . Dry(3) true ,
follows (Axiom (70)) Pref(WinS , WinF )(3) true . Moreover,
preference atom temporal index 3 true (Definition 14.1). So, WinS
WinF supported time 3 , follows WinS preference rank 1
WinF preference rank 2 time 3 . follows (Definition 14.2(a))
WinS succeeds time 3 , effect WinnerS (4) true (axioms (1)
(66)).
398

fiNatural Events

generally, event preferences combined secondary events order
give qualitative representation conditional probabilities. probability judgment
form P (Succ(e)(t)|Succ(e )(t)) = n states probability event e succeeding
time t, given event e does, n. Judgments kind represented EL
event atoms form Prob(e, e , n)(t). Conditional probabilities translated
event preferences means following axiom:
e, e , e , n, m, t((Prob(e, e , n)(t) Prob(e , e , m)(t) n > m) Pref(e, e )(t))

(72)

together appropriate invocations. use technique illustrated
final example, probabilistic extension example attributed Reiter (Shanahan, 1997, p. 290).
Example 11 chessman placed haphazardly chessboard. may end (within)
single square, likely overlap four squares, likely still
overlap two squares. situation represented theory 11 =
Ind Inv Pref {(72), (73), . . . , (80)}, where:
t(Pre(Place)(t) Occ(Place)(t))

(73)

t(Eff(Place)(t) (One(t) | Two(t) | Four (t)))

(74)

t(Pre(Place1 )(t) Pre(Place)(t)) t(Eff(Place1 )(t) One(t))

(75)

t(Pre(Place2 )(t) Pre(Place)(t)) t(Eff(Place2 )(t) Two(t))

(76)

t(Pre(Place4 )(t) Pre(Place)(t)) t(Eff(Place4 )(t) Four (t))

(77)

t(Occ(Place)(t) Inv1 (Place, {Place1 , Place2 , Place4 })(t))

(78)

t(Prob(Place1 , Place, 0.2)(t) Prob(Place2 , Place, 0.5)(t)
Prob(Place4 , Place, 0.3)(t))
U [Place, Place1 , Place2 , Place4 ] Occ(Place)(1)

(79)
(80)

Thus Axiom (74) states three mutually-exclusive outcomes placing chessman,
Axiom (78) states occurrence Place event invokes three conflicting secondary events, Place1 , Place2 , Place4 , Axiom (79) associates conditional probability
judgment them, Axiom (72) translates judgments qualitative
event preferences.
Proposition 11 |2 Two(2).
Proof Let preferred 2 model 11 . Place event occurs invokes
three secondary events Place1 , Place2 , Place4 time 1 (axioms (78),
(80)). four events supported time 1 (axioms (17), (73),(75)-(77),(80)).
But, view effects cannot succeed time 1 (axioms (1), (74),
(75)-(77)). preference atoms Pref(Place2 , Place4 )(1), Pref(Place4 , Place1 )(1),
Pref(Place2 , Place1 )(1) true (axioms (72), (79)) preference atoms temporal index 1 defined (Definition 14.1). Consequently,
time 1 , three events Place2 , Place4 , Place1 preference ranks 1, 2
3 respectively, Place non-preferential. However, Place invokes three
399

fiBell

events event ((78), Definition 14.1), succeed
(Axiom (18)). follows Place succeeds time 1 (Definition 14.2(b)).
success Place2 time 1 consistent success Place (axioms (1), (74),
(76)). Consequently, given preference rank, Place2 succeeds time 1 (Definition 14.2(a)), effect Two(2) true (axioms (1), (76)).

6. Philosophical Justification
section justification formal theories prediction discussed justification
theory events given.
Goodman (1954, III.2) discusses related problem justification formal theories enumerative induction, suggests start considering justify
deductive inference. Clearly showing conforms set valid
general rules deduction.29 question arises justify rules
themselves. suggest appealing fundamental underlying
rules simply postpones question invites regress.30 cannot give
foundational justification deduction, proceed? Goodman suggests
showing rules deduction conform particular deductive
inferences actually make sanction. circular, virtuously so:
point rules particular inferences alike justified brought agreement one another. rule amended yields inference unwilling
accept; inference rejected violates rule unwilling amend. process justification delicate one making mutual adjustments rules
accepted inferences; agreement achieved lies justification needed either (p. 64). Note however general consensus counts valid
deductive argument. Classical logicians accept inference valid, Intuitionists not. Similarly, Intuitionists accept inference valid,
Relevantists not. differences explained fact concerned
attempting formalize different notions validity; tends agreement among
agree given intuitive notion deduction.31 suggests justification
given form deductive inference partly philosophical partly empirical,
consist analysis concept deductive validity consideration
examples deductive inference.
Similarly then, order justify formal theory prediction, seek
show, means combination conceptual analysis empirical evidence,
predictions agree actually make consider reasonable.
case logico-pragmatic theory amounts arguing pragmatics appropriate.
29. Or, equally, conforms notion entailment defined terms given formal semantics,
Tarski semantics classical predicate logic.
30. Given formal semantics accompanying notion entailment, justify set rules proving
sound complete relative semantics. question arises
semantics notion entailment justified.
31. example, valid argument one which, accept premises, must (on pain
inconsistency) accept conclusion; valid argument one admits constructive proof
conclusion given premises; valid argument one premises required order
establish conclusion.

400

fiNatural Events

Let logico-pragmatic theory prediction. extension theory
includes satisfies certain stated restrictions. instance, might
require semantic extension , meaning additional axioms
intended interpreted semantically (rather pragmatically); thus, example, 5
semantic extension Inv . tentatively define intended models given
extension models accord expectations given .32
say pragmatics pragmatically sound class extensions
if, every extension class, pragmatics selects intended models
, pragmatics pragmatically complete class extensions if,
every extension class, pragmatics selects intended models .
Thus pragmatic soundness ensures theory produces predictions
would consider reasonable, pragmatic completeness ensures theory
produces predictions.
case event theories seems appropriate concentrate pragmatic soundness completeness preference1 semantic extensions Ind ; for, given
preference1 properties, pragmatic soundness completeness
preference2 extensions Ind include event preferences otherwise semantic seems uncontentious.
order argue pragmatic soundness preference1 show
restrictions imposes necessary. intuitive notion prediction
event theories endeavour formalize context-dependent activity. Prediction
takes place point time, present, past considered fixed future
considered open. Moreover prediction based available
evidence. consists making regularity-based speculations change given
context, (quietly) assuming facts affected changes
persist. properties captured restrictions imposed preference1 .
Location time idea closed past open future captured preferring
models event theory interpreted chronologically. restriction
evidential context subsequent preference change inertia captured
prioritorized minimaximization present time point; first restricting evidential
context required earlier interpretation theory, assuming whenever
possible events succeed, finally assuming wherever possible facts persist.
Finally, physical-theoretical distinction necessary theory contains kinds
relations, inertia property physical world restricted
physical relations. need illustrated Example 2.
need maximize inertia assumptions chronologically attempting represent
inductive reasoning inertia already clear Hanks McDermott (1987)
discussion Yale Shooting Problem. Moreover, inductive extension example
(in events inductive rather deductive), given Example 1, illustrates
need prefer change inertia given time point. However, might objected
clear earlier events succeed favour later ones; is, success
32. question counts intended model theory vexed one; see, example,
discussions Sandewall (1994, pp. 68-69) Collins, Hall, Paul (2004, pp. 32-39). However,
following discussion, sufficient focus cases general agreement expected
outcomes.

401

fiBell

assumptions made chronologically. consider extension Example 1
second, later, shot occurs (as discussion 1 following example),
seems clear expect first shot prove fatal, consequence
second shot fails Fred already dead occurs; although, course,
first shot fail independent reason, would expect second
shot succeed. predicting first shot succeed consider
success may jeopardized later shot. allow later events influence earlier
events way would allow mysterious form backwards causation.
long-standing objection chronological assumption inertia
fit generation explanations. standard example Kautzs (1986)
Stolen Car Problem; car parked, left unattended, discovered stolen
later point time. since become part folklore chronological
assumption inertia pragmatically unsound results conclusion
car stolen discovered, when, intuitively, seems reasonable
conclude car could stolen earlier point unattended.
consequence, proponents chronological maximization inertia prompted
qualify application; example, Sandewall (1994) suggests certain occluded
relations exempt law inertia, least certain intervals time.33
However seems better response, namely argue examples
involving explanation irrelevant considering pragmatic soundness theory
prediction prediction explanation different forms reasoning (Bell,
1998).34
Another long-standing objection chronological assumption inertia involves nondeterminism. Thus claimed, illustrated Example 6, chronological minimization inertia determine outcome non-deterministic events, thereby eliminating intended models. However, rather seek weaken preference criterion, suggest
take care represent causal structure non-deterministic events (the
fact introduce branching histories) correctly; illustrated Example 7.
basis considerations seems reasonable conjecture preference1
pragmatically sound.
33. idea different physical-theoretical distinction. say fact occluded point
time is, indeed, say subject law inertia point time. However,
occluded fact could naturally classified physical one, represented relation
Example 2.
34. Prediction form inductive reasoning; given epistemic context, task produce reasonable conclusions basis it. contrast, explanation form abductive reasoning; given
conclusion epistemic context imply it, task generate appropriate explanations conclusion. reasoning events effects involves extending
epistemic context appropriate ways, conclusion induced (predicted)
extensions. order ensure explanation appropriate reasonable require
extension event therein causes conclusion. Consequently suggest (Bell,
2001, Causal counterfactuals) explanations best dealt counterfactually comprehensive setting provided theory causation sketched Footnote 4. view, event
occurrence together conditions explain world w iff causes closest -worlds
w. Thus, case Stolen Car Problem, occurrence additional steal event
time point interval car unattended cause of, explains, absence
car next time point.

402

fiNatural Events

order argue pragmatic completeness preference1 show
restrictions imposes sufficient. Examples involving ramifications,
Lifschitzs (1990) lamp-circuit Bakers (1991) ice-cream eating pedestrian appear
show otherwise. point examples illustrated Example 3 unintended
models selected pragmatics. However, suggest problem lies
definition preference1 fact need represent causal nature
ramifications (as arising events contemporaneously caused (ultimately)
primary events) correctly; illustrated Example 4.35
absence counterexamples seems reasonable conjecture preference1
pragmatically complete; although, course, always possible new example
show preference1 liberal. so, disastrous
theory proposed here. analysis, example reveal property prediction captured preference1 , preference1 refined accordingly.
Goodmans terms, would simply part delicate process bringing theory
practice agreement.36
Rather seeking justifications kind, Sandewall (1994) proposes radically
different methodology. begins suggesting series ontological characteristics
instances predictive reasoning. include context-free inertia (I), alternative results
(A), ramification (D), concurrency (C), surprises (S), normality (N). Examples
reasoning include several characteristics classified belonging
corresponding family; example, inductive version Yale Shooting Problem
(Example 1 above) belongs family IN, involves reasoning inertia
normal outcome shoot event. Sandewall proposes formal pragmatics,
trajectory semantics, defines class intended models given example
family IAD, uses prove correctness (to provide validations for) various
formal pragmatics theories expressed appropriate formal languages. example,
simple form chronological minimization called PCM proved valid family
IAD; showing that, given example IAD family, PCM selects exactly
models trajectory semantics does. Thus range applicability PCM
established; is, PCM proved applicable instances prediction
characteristics IAD family.
35. discussion gears example, culminating Example 5, shows theory events
restricted presence symmetric constraints, rather used represent
reasoning direction causation among symmetrically constrained events.
36. sceptical reader might object done show theory works toy
examples. However, overlook care taken represent prediction accurately, misunderstand motivation behind choice examples. examples referred justification
given chosen easily represented, well-know benchmark examples specifically designed probe weaknesses; Goodmans (1954, p. 18) terms,
represent clinically pure cases . . . display best advantage symptoms widespread
destructive malady. fact theory represents correctly provides significant empirical
evidence favour. representations also intuitively convincing, provide significant
evidence favour conceptual basis theory.
related objection theory shown work small-scale examples,
guarantee scale easily larger examples. know inherent
limitations scale. particular, definitions events (their preconditions effects)
extended modular way, fact events inductive, rather deductive, means
given theory extended additional events occur without fear contradiction.

403

fiBell

However methodology limited two ways.
Firstly, question trajectory semantics justified. provides
formal definition intended models given example (of IAD family),
sure models selects given example correspond
ones would select? sufficient simply stipulate case.
possible justify formal pragmatics proving equivalent another (as
case PCM trajectory semantics), however point formal pragmatics
squared intuitions means argument kind employed above.
Thus best hope thesis relating formal theory prediction
intuitive notion it.37 Kripke remarked, mathematical substitute
philosophy.
Secondly, trajectory semantics restricted IAD family (essentially
strips events), would need extended IADCSN family could
applied event theories.
Nevertheless, would worthwhile attempt undertake mathematical assessment event theories relative formal theory; extension
trajectory semantics. possible, mathematical investigations kind provide additional means justifying formal theories. attempt prove equivalence
two theories fails, typically highlight inadequacies one them,
suggest intuitions behind need refined. Alternatively,
possible prove theories equivalent, would provide mutuallysupporting evidence robustness intuitions underlying them; would
suggest that, despite appearances contrary, two formal theories capture
properties intuitive notion predictive causal reasoning.38 philosophical
substitute mathematics.

7. Related Work
theory natural events presented paper developed many years,
earlier versions parts appeared elsewhere. earlier fragments
revised combined unified whole.
earlier version theory inductive events (Section 3) suggested previous research (Bell, 1998), model-building implementation discussed White,
Bell, Hodges (1998). theory intellectual origins work McCarthy
(1980, 1986), suggested circumscription could used approach qualification problem frame problem. proposal developed Shoham (1988),
introduced notion chronological minimization classical, temporal, modal
language. Shohams theory offers promise simple intuitive approach two
problems. However, theory limited many ways. particular, propositional
fact-event distinction, possible state general axioms change
37. Similarly, Chuch-Turing thesis thesis, rather theorem, claims equivalence
informal intuitive notion, effective computability, formal theory computability (recursive
functions, Turing machines).
38. equivalence results rival formalizations effective computability (recursive
functions, Turing Machines, etc.) provide mutually-supportive evidence soundness intuitions
underlie them.

404

fiNatural Events

inertia it. Also, Shoham requires theories meet number syntactic restrictions, including restriction two causal rules conflict (see Definition 4.7(7)).
reason ensure theories deterministic, process
chronological minimization interprets correctly. makes impossible
express problems involving (inductive) change inertia, inductive version Yale Shooting Problem (discussed Section 3 above) theory. Lifting
restriction would allow problem expressed, chronological minimization
theory would counter-intuitive result Fred remained alive
shooting one class models, died another. short, chronological minimization
simple. theory inductive events thus thought generalization
refinement Shohams theory fulfills promise.
first general common sense theory change inertia proposed Lifschitz
(1987). axioms defines (in Situation Calculus) substantially different
theory inductive events. However important similarity restriction inertia axiom, basis distinction primitive defined
fluents (the Situation Calculus counterparts object relations). later (Lifschitz, 1990,
p. 371) says distinction regarded technical trick, suggests
alternative, principled, distinction based frames (McCarthy & Hayes, 1969). However seems primitive-defined distinction justified identifying
physical-theoretical distinction introduced Section 3.39
Secondary events (Section 4) suggested previous research (Bell, 1999, 2000).
use representation ramifications compared Thielschers (1997)
treatment. Thielscher views problem ramifications logical one, arises (as
discussed Section 4) lack causal directedness material conditionals.
solution starts deductive strips-like representation events. ramifications
event brought applying series causal constraints stable
state reached. Causal constraints thought directed conditionals two
single effects, stating circumstances first causes second. Thus,
problem posed Example 3 solved Ollie L2 direct effect moving
L1 L2, fact L2 holding block cause additional
effect L2 also. may effect invocation
secondary events cases, two approaches radically different. Thielschers
causal constraints deductive nature, so, begun, application runs
conclusion without possible interruption. thus possibility representing failure
stage indirect-effect-propagation process. So, stands, solution limited
deterministic deductive events, either occur isolation (directly
indirectly) conflict other. Sandewalls (1996) Causal Propagation Semantics
similar Thielschers approach suffers limitations. contrast,
approach, success propagated along invocation chain, producing associated effects,
point event may fail, case propagation terminates; illustrated
39. Readers familiar Goodmans (1954, Ch. 3) paradox know logical complexity predicates relative choice language. here, like Quine (Footnote 12), appeal ordinary
language scientific refinements, refrain venturing fly-bottle. (Wittgenstein,
1953, 309: aim philosophy?To shew fly way fly-bottle.)

405

fiBell

Example 4 above. representation ramifications thus freely combined
non-deterministic events conflicting events.
Several formal theories events employ primitive causation relation; notable examples
A-language family originating Gelfond Lifschitz (1993) Lins (1995)
extension (Toronto) Situation Calculus (Lin & Reiter, 1994). appearance
unanalyzed causation relation formal theory events seems beg question;
appeal made complex notion (causation) order give analysis
simpler one (change). However, rather view causation relation appeal
full-blown causation (see Footnote 4), better view means encoding detailed
causal knowledge. Lins theory ternary relation Caused (p, v, s) true fluent p
caused (by something unspecified) truth value v situation (p. 1986).
keeping interpretation, two axioms given:
Caused (p, true, s) Holds(p, s) ,
Caused (p, f alse, s) Holds(p, s) .
Thus fluent p caused value true (false) situation s, p holds (does
hold) situation s. way illustration, Lin discusses example spring
loaded suitcase. locks up, suitcase opens. Initially suitcase
closed, one lock up, down, down-lock flipped. Naturally expect
suitcase open result. However, attempts formalize example using
ordinary domain axiom inertia fail; lamp circuit example, lock
remains intended models, also unintended models
suitcase remains closed lock changes position result. Consequently Lin
proposes causal domain axiom:
up(L1, s) up(L2, s) Caused (open, true, s) ;

(81)

states locks L1 L2 situation s, suitcase Caused
open s. intention axioms interpreted causally
(positively), effect achieved circumscribing Caused relation adding
inertia axiom states fluents Caused change persist. Thus
according Lins account, ramifications arise result causally-directed domain axioms
(81), facts cause facts change. Indeed, Lin (p. 1986) says (81)
that:
[T]he physical spring loaded mechanism behind causal rule abstracted away. care, may well device
made spring, bombs blow open suitcase time two
locks position. seems natural say fluent open
caused true fact two locks position.
However seems odd common sense point view, events
cause change facts otherwise inert. Moreover, actual cause
abstracted away, difficult see Lins account could extended order include
treatment qualifications; example, suitcase may fail open locks
mechanism rusty, someone sitting suitcase, etc. contrast,
406

fiNatural Events

obvious represent problem using primary secondary events; context
one lock down, flipping down-lock invokes secondary
event which, succeeds, additional effect suitcase open. Moreover,
noted above, introduction secondary events makes possible represent
complex examples ramifications, Example 4.
Secondary events also compared natural actions proposed Reiter
(1996), Lin (1998), Pinto (1998). addition actions initiated agents, suggest
also natural actions arise due nature world (the Laws
Nature, etc.), guaranteed succeed. use illustrated Pintos
treatment Lifschitzs (1990) lamp-circuit example. switches circuit
position (both down) lamp on, otherwise off. Initially
switches opposite positions one flipped. Clearly expect lamp
result. However attempts formalize example using domain axioms
inertia axiom fail. intended models switch retains position inertia
lamp comes result flip event. However also unintended models
lamp remains inertia consequently switch mysteriously
changes position result; problem essentially posed Example 3.
Pintos treatment problem, agent flipping switch results natural action
current flowing circuit, turn results lamp on. natural
action current flowing resolves conflict alternative uses inertia
axiom bringing intermediary state switches (as flowing
current affect position) inertia axiom applied
intended way (as flowing current guaranteed effect lamp on).
proposal aims solve causal-directedness problem introducing additional
events can, perhaps, seen lying somewhere Thielschers logical approach
representational approach. Unlike natural events, natural actions deductive.
difficult see natural actions could used represent qualifications.
example, natural action current flowing guaranteed succeed (turning
lamp on), reality current might flow wire loses conductivity, cut,
etc. clearly complication represented using natural events. context
switches opposite positions, flipping switch invokes secondary event
which, succeeds, results lamp on; lamps coming thus defeasible
secondary effect flipping switch. Moreover, natural actions independent
actions agents, secondary events causally dependent (at least one of)
events invoke them.
Event preferences (Section 5) introduced previous research (Bell, 2001, Simultaneous events). presentation substantially improved, and, examples
show, combination event preferences secondary events provides interesting new
possibilities.
Recently Vo Foo (2005) suggested inductive theory reasoning action
which, suggest, provides basis unified solution frame, qualification,
ramification problems. theory based theory argumentation developed
Bondarenko, Dung, Kowalski, Toni (1997), differs radically mine terms
technical realization. conceptual level interesting similarities. Like
me, Vo Foo suggest event occurrences minimized inertia
407

fiBell

fluents (their counterpart object-relations) maximized (p. 448). Furthermore,
order integrate solution frame qualification problems, they, effect
(p. 493), adopt principle change preferred inertia (Bell, 1998). However,
theory suggestion minimization maximization done
chronologically. Indeed, suggest strength approach
enables provide explanations reasoning backwards (or antichronologically)
examples Stolen Car Problem. However, reasoning chronologically
essential feature predictive reasoning, suspect prove problem
Vo Foos theory. Instead suggest (Footnote 34) explanations treated
counterfactual causes.

8. Conclusion
began arguing Deductionism logical mistake, made case Inductionism. began basic theory inductive events, provides basis
integrated solution qualification frame problems. introduced
distinction primary secondary events order represent causal structure
natural events, thereby providing basis solution ramification problem
problem representing non-determinism. Finally, introduced event preferences, used express defeasible preferences outcomes conflicting
simultaneous events. development theory illustrates benefit starting
right foot, inductive, rather deductive, events. basic theory simple
intuitive, extensions require addition axioms
refinement one clause formal pragmatics.
simple cases may little choose deductive inductive theories events; produce predictions wrong. However inductive
representation natural events accurate reflects defeasibility.
representation inductive events makes possible define primary secondary events,
defeasible event preferences. turn make possible give accurate representations ramifications, non-determinism, conflicting events. turn makes
possible represent complex cases accurately. instance, Example 8, two
stooges attempt move location, one expected succeed, however three
do, none succeeds. always inductive events, example elaborated.
Thus two stooges attempt move preferred one fails independent
reason (he slips, say), stooge normally succeeds (unless also slips).
case three attempt move, Ollie slips, Stan expected succeed.
also slips, Charlie expected succeed; may also slip. Moreover,
example readily combined others. example, stooge could carry stack
blocks; block moves block beneath it, stooge holding it,
moves. know theory events represent reasoning subtlety
complexity.
future work, model-building implementation event theories investigated.
general idea outlined previous research (Bell, 1995), White et al. (1998)
describe implementation (an earlier version of) theory inductive events. Essentially idea build finite initial parts representative preferred models given
408

fiNatural Events

event theory chronologically, suggested informal discussion Yale Shooting
Problem Section 3.
suggested introduction (and Footnote 4), theory natural events forms
part larger theory causation (Bell, 2004, 2006, 2008). Event theories used
represent detailed, regularity-based, causal knowledge events; expressed form
preconditions effects, invocations, event preferences. used basis
general definition sufficient causation, combined refinement Lewiss
(1986, Ch. 21) counterfactual-dependence condition give definition causation.

Acknowledgments
grateful everyone commented work, especially anonymous
referees, Wilfrid Hodges, Robert Miller, Edmund Robinson, Murray Shanahan, Graham
White.

References
Baker, A. B. (1991). Nonmonotonic reasoning framework situation calculus.
Artificial Intelligence, 49, 523.
Barringer, H., Cheng, J., & Jones, C. (1984). logic covering undefinedness program
proofs. Acta Informatica, 21, 251269.
Bell, J. (2001). Causal counterfactuals. Working Notes Common Sense 2001. Available
at: www.cs.nyu.edu/cs/faculty/davise/commonsense01/.
Bell, J. (1995). Pragmatic reasoning; model-based theory. Polos, L., & Masuch, M.
(Eds.), Applied Logic; How, Why, pp. 127. Kluwer. selection papers
Applied Logic Conference, Amsterdam, 1992.
Bell, J. (1996). model-based approach predictive causal reasoning. Doherty (Doherty,
1996), pp. 169195.
Bell, J. (1998). Chronological minimization explanation. Miller, R., & Shanahan,
M. (Eds.), Working papers Common Sense 98; fourth symposium logical
formalizations common sense reasoning.
Bell, J. (1999). Primary secondary events. Thielscher, M. (Ed.), Working notes
4th workshop Nonmonotonic Reasoning, Action Change, pp. 6572.
Bell, J. (2000). Primary secondary events. Electronic Transactions Artificial Intelligence discussion paper. Available at: www.ida.liu.se/ext/etai/rac/. Subsequent
version available at: www.dcs.qmul.ac.uk/jb, 2001.
Bell, J. (2001). Simultaneous events: Conflicts preferences. Proceedings 6th
European Conference Symbolic Quantitative Approaches Reasoning
Uncertainty (ECSQARU 2001), pp. 714725. Springer.
Bell, J. (2004). Causation causal conditionals. Proceedings 9th International
Conference Principles Knowledge Representation Reasoning (KR 2004),
pp. 211. AAAI Press.
409

fiBell

Bell, J. (2006). Causation production. Proceedings 17th European Conference
Artificial Intelligence (ECAI 2006), pp. 327331. IOS Press.
Bell, J. (2008). common sense theory causation. Forthcoming.
Blackburne, S. (1994). Oxford Dictionary Philosophy. Oxford University Press,
Oxford.
Bochvar, D. A. (1939). three-valued logical calculus application analysis
contradictories. Matematiceskij sbornik, 4.
Bondarenko, A., Dung, P. M., Kowalski, R. A., & Toni, F. (1997). abstract
argumentation-theoretic approach default reasoning. Artificial Intelligence, 93,
63101.
Collins, J., Hall, N., & Paul, L. A. (Eds.). (2004). Causation Counterfactuals. MIT
Press, Cambridge, Massachusetts.
Davidson, D. (1980). Essays Actions Events. Oxford University Press, Oxford.
Denecker, M., Dupre, D. T., & Belleghem, K. V. (1998). inductive definition approach
ramifications. Electronic Transactions Artificial Intelligence, 2, 2567.
Doherty, P. (Ed.). (1996). Partiality, Modality, Nonmonotonicity. CSLI Publications,
CSLI, Stanford University, Palo Alto.
Fikes, R. E., & Nilsson, N. J. (1971). strips, new approach application theorem
proving problem solving. Artificial Intelligence, 2, 189208.
Gelfond, M., & Lifschitz, V. (1993). Representing action change logic programs.
Journal Logic Programming, 17, 301322.
Gelfond, M., Lifschitz, V., & Rabinov, A. (1991). limitations situation
calculus?. Boyer, R. (Ed.), Essays Honour Woody Bledsoe, pp. 167179.
Kluwer Academic Publishers.
Ginsberg, M. L., & Smith, D. E. (1988). Reasoning action II: qualification
problem. Artificial Intelligence, 35, 311342.
Girard, J.-Y. (1987). Linear logic. Theoretical Computer Science, 50:1, 1102.
Goodman, N. (1954). Fact, Fiction, Forecast. Harvard University Press, Cambridge
Mass. References 4th edition, 1983.
Hanks, S., & McDermott, D. (1987). Nonmonotonic logic temporal projection. Artificial
Intelligence, 33 (3), 379412.
Hume, D. (1739). Treatise Human Nature. Clarendon Press, Oxford. References
Clarendon edition, 1978.
Hume, D. (1777). Enquiry Concerning Human Understanding. Clarendon Press, Oxford.
References Clarendon edition, 1975.
Kautz, H. (1986). logic persistence. Proceedings 5th National Conference
Artificial Intelligence (AAAI-86), pp. 401405.
Kleene, S. C. (1952). Introduction Metamathematics. North-Holland, Amsterdam.
Kripke, S. (1975). Outline theory truth. Journal Philosophy, 72, 690716.
410

fiNatural Events

Lewis, D. (1986). Philosophical Papers, Vol. II. Oxford University Press, Oxford.
Lifschitz, V. (1987). Formal theories action. Brown, F. (Ed.), Frame Problem
Artificial Intelligence, pp. 3558. Morgan Kaufmann.
Lifschitz, V. (1990). Frames space situations. Artificial Intelligence, 46, 365376.
Lin, F., & Reiter, R. (1994). State constraints revisited. Journal Logic Computation,
4(5), 655678.
Lin, F. (1995). Embracing causality specifying indirect effects actions. Proceedings 14th International Joint Conference Artificial Intelligence (IJCAI 95), pp.
19851991.
Lin, F. (1998). relationships static dynamic causal rules situation
calculus. Ortiz, C. (Ed.), Working Papers AAAI98 Spring Symposium
Prospects Commonsense Theory Causation, pp. 3843.
Mackie, J. L. (1974). Cement Universe. Clarendon Press, Oxford.
Mackie, J. L. (1975). Causes conditions. Sosa, E. (Ed.), Causes Conditionals, pp.
1538. Oxford University Press, Oxford. First published American Philosophical
Quarterly 2, 1965, pages 245-264.
McCarthy, J. (1977). Epistemological problems artificial intelligence. Proceedings
5th International Joint Conference Artificial Intelligence (IJCAI 95), pp. 10381044.
McCarthy, J. (1980). Circumscription form nonmonotonic reasoning. Artificial
Intelligence, 13, 27 39.
McCarthy, J. (1986). Applications circumscription formalizing commonsense knowledge. Artificial Intelligence, 28, 89116.
McCarthy, J., & Hayes, P. J. (1969). philosophical problems standpoint
artificial intelligence. Michie, D., & Meltzer, B. (Eds.), Machine Intelligence 4, pp.
463502. Edinburgh University Press.
Mill, J. S. (1898). System Logic. Longmans, London. References 8th edition,
1941.
Pinto, J. (1998). Causality theories action. Miller, R., & Shanahan, M. (Eds.),
Working papers 4th Symposium Logical Formalizations Commonsense
Reasoning, pp. 349364.
Quine, W. V. (1995). Stimulus Science. Harvard University Press, Cambridge,
Massachusetts.
Reiter, R. (1996). Natural actions, concurrency continuous time situation calculus. Proceedings 5th International Conference Principles Knowledge
Representation Reasoning (KR96.), pp. 213.
Reiter, R. (2001). Knowledge Action; Logical Foundations Specifying Implementing Dynamical Systems. MIT Press, Cambridge, Mass.
Rosser, J., & Turquette, A. (1952). Many-valued Logics. North-Holland, Amsterdam.
Russell, B. (1913). notion cause. Proceedings Aristotelian Society, 13, 126.
411

fiBell

Russell, S., & Norvig, P. (2003). Artificial Intelligence; Modern Approach. Prentice Hall,
New Jersey. 2nd Edition.
Sandewall, E. (1994). Features Fluents; Representation Knowledge Dynamical Systems. Oxford University Press, Oxford.
Sandewall, E. (1996). Assessments ramification methods use domain constraints.
Proceedings 5th International Conference Principles Knowledge Representation Reasoning (KR96.), pp. 99110.
Shanahan, M. (1997). Solving Frame Problem; Mathematical Investigation
Common Sense Law Inertia. MIT Press, Cambridge, Mass.
Shoham, Y. (1988). Reasoning Change. MIT Press, Cambridge Mass.
Taylor, R. (1975). metaphysics causation. Sosa, E. (Ed.), Causation Conditionals, pp. 3943. Oxford University Press.
Thielscher, M. (1997). Ramification causality. Artificial Intelligence, 98, 317364.
Vo, Q. B., & Foo, N. Y. (2005). Reasoning action: argumentation-theoretic
approach. Journal Artificial Intelligence Research, 24, 465518.
White, G., Bell, J., & Hodges, W. (1998). Building models prediction theories. Cohn,
A., Schubert, L., & Shapiro, S. (Eds.), Proc. KR98, pp. 557568, San Francisco.
Morgan Kaufmann.
Wittgenstein, L. (1953). Philosophical Investigations. Blackwell, Oxford.

412

fiJournal Artificial Intelligence Research 30 (2007) 249-272

Submitted 12/06; published 10/07

Topic Role Discovery Social Networks
Experiments Enron Academic Email
Andrew McCallum
Xuerui Wang

mccallum@cs.umass.edu
xuerui@cs.umass.edu

Department Computer Science
University Massachusetts
140 Governors Drive
Amherst, 01003 USA

Andres Corrada-Emmanuel

acorrada@physics.umass.edu

Department Physics
University Massachusetts
666 North Pleasant Street
Amherst, 01003 USA

Abstract
Previous work social network analysis (SNA) modeled existence links
one entity another, attributes language content topics
links. present Author-Recipient-Topic (ART) model social network
analysis, learns topic distributions based direction-sensitive messages sent
entities. model builds Latent Dirichlet Allocation (LDA) AuthorTopic (AT) model, adding key attribute distribution topics conditioned
distinctly sender recipientsteering discovery topics according
relationships people. give results Enron email corpus
researchers email archive, providing evidence clearly relevant topics
discovered, ART model better predicts peoples roles gives lower perplexity
previously unseen messages. also present Role-Author-Recipient-Topic (RART)
model, extension ART explicitly represents peoples roles.

1. Introduction
Social network analysis (SNA) study mathematical models interactions among
people, organizations groups. recent availability large data sets human
interactions (Shetty & Adibi, 2004; Wu, Huberman, Adamic, & Tyler, 2003), popularity
services like MySpace.com LinkedIn.com, salience connections among
9/11 hijackers, growing interest social network analysis.
Historically, research field led social scientists physicists (Lorrain
& White, 1971; Albert & Barabasi, 2002; Watts, 2003; Wasserman & Faust, 1994),
previous work emphasized binary interaction data, directed and/or weighted edges.
not, however, previously significant work researchers backgrounds
statistical natural language processing, analysis captures richness
language contents interactionsthe words, topics, high-dimensional
specifics interactions people.
c
2007
AI Access Foundation. rights reserved.

fiMcCallum, Wang, & Corrada-Emmanuel

Using pure network connectivity properties, SNA often aims discover various categories nodes network. example, addition determining node-degree
distribution heavy-tailed, also find particular nodes inordinately
high number connections, connections particularly well-connected subset
(group block) network (Nowicki & Snijders, 2001; Kemp, Griffiths, & Tenenbaum,
2004; Kemp, Tenenbaum, Griffiths, Yamada, & Ueda, 2006; Kubica, Moore, Schneider, &
Yang, 2002; Airoldi, Blei, Fienberg, & Xing, 2006; Kurihara, Kameya, & Sato, 2006). Furthermore, using properties assign roles certain nodes (Lorrain & White,
1971; Wolfe & Jensen, 2004). However, clear network properties enough
discover roles social network. Consider email messages corporate setting,
imagine situation tightly knit group users trade email messages
roughly symmetric fashion. Thus, network level appear fulfill
role. perhaps, one users fact manager whole groupa
role becomes obvious one accounts language content email
messages.
Outside social network analysis literature, stream new research
machine learning natural language models clustering words order discover
underlying topics combined form documents corpus. Probabilistic
Latent Semantic Indexing (Hofmann, 2001) Latent Dirichlet Allocation (Blei, Ng, &
Jordan, 2003) robustly discover multinomial word distributions topics. Hierarchical
Dirichlet Processes (Teh, Jordan, Beal, & Blei, 2004) determine appropriate number
topics corpus. Author-Topic Model (Steyvers, Smyth, Rosen-Zvi, & Griffiths,
2004) learns topics conditioned mixture authors composed document.
However, none models appropriate SNA, aim capture
directed interactions relationships people.
paper presents Author-Recipient-Topic (ART) model, directed graphical model
words message generated given author set recipients. model
similar Author-Topic (AT) model, crucial enhancement conditions per-message topic distribution jointly author individual recipients,
rather individual authors. Thus discovery topics ART model influenced social structure messages sent received. topic consists
multinomial distribution words. author-recipient pair multinomial
distribution topics. also easily calculate marginal distributions topics
conditioned solely author, solely recipient, order find topics
person likely send receive.
importantly, also effectively use person-conditioned topic distributions measure similarity people, thus discover peoples roles clustering
using similarity.1 example, people receive messages containing requests
photocopying, travel bookings, meeting room arrangements said
role administrative assistant, discovered ART model
topics high probability receiving distribution. Note
1. clustering may either external model simple greedy-agglomerative clustering, internal
model introducing latent variables senders recipients roles, described
Role-Author-Recipient-Topic (RART) model toward end paper.

250

fiTopic Role Discovery Social Networks

discover two people similar roles even graph connected
different sets people.
demonstrate model Enron email corpus comprising 147 people 23k
messages, also 9 months incoming outgoing mail first author,
comprising 825 people 14k messages. show ART discovers extremely
salient topics, also gives evidence ART predicts peoples roles better
SNA. Also, show similarity matrix produced ART different
SNA matrix matrix several appropriate ways. Furthermore, find
ART model gives significantly lower perplexity previously unseen messages AT,
shows ART better topic model email messages.
also describe extension ART model explicitly captures roles people,
generating role associations author recipient(s) message, conditioning
topic distributions role assignments. model, term Role-AuthorRecipient-Topic (RART), naturally represents one person one role.
describe several possible RART variants, describe experiments one
variants.
importance modeling language associated social network interactions
also recently demonstrated Group-Topic (GT) model (Wang, Mohanty, &
McCallum, 2006). Unlike ART, discovers roles, GT discovers groups. Like ART,
uses text data find interesting useful patterns would possible
edge relations alone. GT simultaneously clusters entities groups share similar
interaction patterns, also clusters text (or attributes) interactions
topicsdoing way clustering dimension informs other.
applied voting records corresponding text resolutions U.S. Senate
U.N., Group-Topic model shows incorporating votes results salient
topic clusters, different groupings legislators emerge different topics.
role discovery group discovery primary areas SNA research.

2. Author-Recipient-Topic Models
describing ART model, first describe three related models. Latent Dirichlet
Allocation (LDA) Bayesian network generates document using mixture topics
(Blei et al., 2003). generative process, document d, multinomial distribution
topics randomly sampled Dirichlet parameter , generate
word, topic z chosen topic distribution, word, w, generated
randomly sampling topic-specific multinomial distribution z . robustness
model greatly enhanced integrating uncertainty per-document topic
distribution .
Author model, also termed Multi-label Mixture Model (McCallum, 1999),
Bayesian network simultaneously models document content authors interests
1-1 correspondence topics authors. document d, set
authors ad observed. generate word, author, z, sampled uniformly
set, word, w, generated sampling author-specific multinomial
distribution z . Author-Topic (AT) model similar Bayesian network,
authors interests modeled mixture topics (Steyvers et al., 2004).
251

fiMcCallum, Wang, & Corrada-Emmanuel

Author-Topic Model
(AT)

Author-Recipient-Topic Model
(ART)

Latent Dirichlet Allocation
(LDA)

Author Model
(Multi-label Mixture Model)

[Blei, Ng, Jordan, 2003]

[McCallum 1999]

[Rosen-Zvi, Griffiths, Steyvers, Smyth 2004]



ad

ad



z

x


z



ad





w


Nd






w




z



Nd




z

A,A



w


rd

x





[This paper]

Nd




w


Nd


Figure 1: Three related models, ART model. models, observed word,
w, generated multinomial word distribution, z , specific particular
topic/author, z, however topics selected differently models.
LDA, topic sampled per-document topic distribution, ,
turn sampled Dirichlet topics. Author Model,
one topic associated author (or category), authors sampled
uniformly. Author-Topic model, topic sampled per-author
multinomial distribution, , authors sampled uniformly observed
list documents authors. Author-Recipient-Topic model,
separate topic-distribution author-recipient pair, selection
topic-distribution determined observed author, uniformly sampling recipient set recipients document.

generative process document d, set authors, ad , observed. generate
word, author x chosen uniformly set, topic z selected
topic distribution x specific author, word w generated
topic-specific multinomial distribution z . However, described previously, none
models suitable modeling message data.
email message one sender general one recipients. could
treat sender recipients authors message, employ
model, distinguish author recipients message,
undesirable many real-world situations. manager may send email secretary
vice versa, nature requests language used may quite different. Even
dramatically, consider large quantity junk email receive; modeling
topics messages undistinguished topics write authors would
extremely confounding undesirable since reflect expertise roles.
Alternatively could still employ model ignoring recipient information
email treating email document one author. However,
case (which similar LDA model) losing information recipients,
connections people implied sender-recipient relationships.
252

fiTopic Role Discovery Social Networks

SYMBOL



V
Nd

DESCRIPTION
number topics
number email messages
number email accounts (senders recipients)
number unique words (vocabulary size)
number word tokens message
Table 1: Notation used paper

Thus, propose Author-Recipient-Topic (ART) model email messages.
ART model captures topics directed social network senders recipients
conditioning multinomial distribution topics distinctly author one
recipient message. Unlike AT, ART model takes consideration author
recipients distinctly, addition modeling email content mixture topics.
ART model Bayesian network simultaneously models message content,
well directed social network messages sent. generative
process, message d, author, ad , set recipients, rd , observed.
generate word, recipient, x, chosen uniformly rd , topic z
chosen multinomial topic distribution ad x , distribution specific
author-recipient pair (ad , x). distribution topics could also smoothed
distribution conditioned author only, although find necessary
experiments. Finally, word w generated sampling topic-specific
multinomial distribution z . result discovery topics guided
social network collection message text generated.
graphical model representations models shown Figure 1. ART
model, given hyper-parameters , author ad , set recipients rd
message d, joint distribution topic mixture ij author-recipient pair
(i, j), word mixture topic t, set recipients x, set topics z set
words w corpus given by:
P (, , x, z, w|, , a, r) =





p(ij |)

i=1 j=1




Nd


p(t |)
(P (xdi |rd )P (zdi |ad xdi )P (wdi |zdi ))

t=1

d=1 i=1

Integrating , summing x z, get marginal distribution
corpus:
P (w|, , a, r)
ZZ
Nd X








X
=
p(ij |)
p(t |)
(P (xdi |rd )
(P (zdi |ad xdi )P (wdi |zdi )))dd
i=1 j=1

t=1

d=1 i=1 xdi =1

zdi =1

2.1 Inference Gibbs Sampling
Inference models LDA family cannot performed exactly. Three standard approximate inference methods used obtain practical results: variational methods
253

fiMcCallum, Wang, & Corrada-Emmanuel

Algorithm 1 Inference Parameter Estimation ART
1: initialize author topic assignments randomly tokens
2: repeat
3:
= 1
4:
= 1 Nd
5:
draw xdi zdi P (xdi , zdi |xdi , zdi , w, , , a, r)
6:
update nad xdi zdi mzdi wdi
7:
end
8:
end
9: Markov chain reaches equilibrium
10: compute posterior estimates

(Blei et al., 2003), Gibbs sampling (Griffiths & Steyvers, 2004; Steyvers et al., 2004; RosenZvi, Griffiths, Steyvers, & Smyth, 2004), expectation propagation (Griffiths & Steyvers,
2004; Minka & Lafferty, 2002). choose Gibbs sampling ease implementation.
Note adopt conjugate priors (Dirichlet) multinomial distributions, thus
easily integrate , analytically capturing uncertainty associated
them. way facilitate samplingthat is, need sample
all. One could estimate values hyper-parameters ART model, ,
data using Gibbs EM algorithm (Andrieu, de Freitas, Doucet, & Jordan, 2003).
applications, topic models sensitive hyper-parameters, extremely
important set right values hyper-parameters. However, particular applications discussed paper, trying many different hyper-parameter settings,
find sensitivity hyper-parameters strong. Thus, simplicity, use fixed symmetric Dirichlet distributions ( = 50/T = 0.1)
experiments.
need derive P (xdi , zdi |xdi , zdi , w, , , a, r), conditional distribution
topic recipient word wdi given words topic recipient assignments,
xdi zdi , carry Gibbs sampling procedure ART. begin joint
probability whole data set, chain rule, conditional probability
obtained ease:
z + nad xdi zdi 1
w + mzdi wdi 1
P (xdi , zdi |xdi , zdi , w, , , a, r) PT di
PV di
t=1 (t + nad xdi ) 1
v=1 (v + mzdi v ) 1
nijt number tokens assigned topic author-recipient pair (i, j),
mtv represent number tokens word v assigned topic t.
posterior estimates given training set calculated
z + nijz
w + mtw
, tw = PV
ijz = PT
t=1 (t + nijt )
v=1 (v + mtv )

(1)

Detailed derivation Gibbs sampling ART provided Appendix A. overview
Gibbs sampling procedure use shown Algorithm 1.
254

fiTopic Role Discovery Social Networks

3. Related Work
use social networks discover roles people (or nodes) network goes back
three decades work Lorrain White (1971). based hypothesis
nodes network relate nodes equivalent ways must
role. equivalence given probabilistic interpretation Holland, Laskey,
Leinhardt (1983): nodes assigned class/role stochastically equivalent
probabilities relationships nodes class/role same.
limitation single class/role label node network relaxed recent
work Wolfe Jensen (2004). consider model assigns multiple role labels
given node network. One advantage multiple labels that, factored
model, fewer parameters required estimated non-factored model using
label obliged represent values. find that, two labels three values (giving
32 = 9 possible labelings node) better estimator synthetic data produced
two-label process model using one label nine possible values. is,
course, advantage mixture models, LDA ART model presented here.
study email social networks hampered unavailability public
corpus. research published used email to-from logs. Logs easier
obtain less intrusive users privacy. means previous research
focused topological structure email networks, dynamics email
traffic users. Wu et al. (2003) look information flowed email network
users research labs (mostly HP Labs). conclude epidemic models
information flow work email networks thus identifying hubs network
may guarantee information originating node reaches large fraction
network. finding serves example network properties sufficient
optimize flow email network. Adamic Adar (2004) study efficiency local
information search strategies social networks. find case email
network HP Labs, greedy search strategy works efficiently predicted Kleinberg
(2000) Watts, Dodds, Newman (2002).
approaches, however, limit use network topology discover roles. ART model complements approaches using content
traffic among nodes create language models bring differences invisible
network level.
discussed introduction, also recently developed model group
discovery. addition relation-edge data, Group-Topic (GT) model also takes
consideration textual attributes relations, allows discovery groups
guided emerging textual topics vice-versa (Wang et al., 2006). Experiments
voting data show Group-Topic models joint inference improves groups
topics discovered. modalities information combined discover hidden
structure. example, time text combined Topics Time (TOT) model
(Wang & McCallum, 2006), finds trends time-sensitive topics using continuous
distribution time-stamps. Dynamic Topic Models (Blei & Lafferty, 2006b) incorporate
time topic models transitions Markov process. ART model could
easily extended incorporate temporal information.
255

fiMcCallum, Wang, & Corrada-Emmanuel

discussed earlier, ART model direct offspring Latent Dirichlet Allocation
(Blei et al., 2003), Multi-label Mixture Model (McCallum, 1999), AuthorTopic Model (Steyvers et al., 2004), distinction ART specifically designed
capture language used directed network correspondents. Another recent
model associates topics people Author-Persona-Topic (APT) model (Mimno
& McCallum, 2007). APT designed specifically capture expertise person,
modeling expertise mixture topical intersections, demonstrated task
matching reviewers submitted research papers.
New topic models actively studied recent years many different tasks,
including joint modeling words research paper citations (Erosheva, Fienberg, &
Lafferty, 2004), capturing correlations among topics (Blei & Lafferty, 2006a; Li & McCallum,
2006), taking advantage topical syntactic dependencies (Griffiths, Steyvers, Blei,
& Tenenbaum, 2004), discovering topically-relevant phrases Markov dependencies
word sequences (Wang, McCallum, & Wei, 2007). Many models could easily
combined ART model, would likely prove useful.

4. Experimental Results
present results Enron email corpus personal email one authors
paper (McCallum). Enron email corpus, large body email messages
subpoenaed part investigation Federal Energy Regulatory Commission
(FERC), placed public record. original data set contains 517,431
messages, however MD5 hashes contents, authors dates show 250,484
unique.
Although Enron email data set contains email folders 150 people, two people
appear twice different usernames, remove one person sent automated
calendar reminders, resulting 147 people experiments. hand-corrected variants
email addresses 147 users capture connectivity much
users emails possible. total number email messages traded among users
23,488. model email messages received least one 147
users.
order capture new text entered author message, necessary
remove quoted original messages replies. eliminate extraneous text
simple heuristic: text message forwarded message line time stamp
removed. heuristic certainly incorrectly looses words interspersed quoted
email text. words formed sequences alphabetic characters kept, results
vocabulary 22,901 unique words. remove sensitivity capitalization, text
downcased.
second data set consists personal email sent received McCallum
January September 2004. consists 13,633 unique messages written 825
authors. typical power-law behavior, authors wrote messages,
128 wrote ten emails. applying text normalization filter
(lowercasing, removal quoted email text, etc.) used Enron data set,
obtained text corpus containing 457,057 word tokens, vocabulary 22,901 unique
words.
256

fiTopic Role Discovery Social Networks

(a) Enron authors

(b) Enron author-recipient pairs

(c) McCallum authors

(d) McCallum author-recipient pairs

Figure 2: Power-law relationship frequency occurrence author (or
author-recipient pair) rank determined frequency
occurrence. author plots, treat sender recipients
authors.

conditioning topic distributions author-recipient pairs instead authors, data
may look sparser considering substantially author-recipient pairs
authors. However, shown Figure 2, find number emails
author-recipient pair rank determined count still follow power-law
behavior, authors. example, McCallum data set, 500 possible 680,625
author-recipient pairs responsible 70% email exchange. is, even though
data sparser ART model, power-law behavior makes still possible
obtain good estimation topic distributions prominent author-recipient pairs.
initialize Gibbs chains data sets randomly, find results
robust different initializations. checking perplexity, find usually
Gibbs chain converges hundred iterations, run 10,000 iterations anyway
make sure converges.
4.1 Topics Prominent Relations ART
Table 2 shows highest probability words eight topics ART model trained
147 Enron users 50 topics. quoted titles interpretation
257

fiMcCallum, Wang, & Corrada-Emmanuel

Topic 5
Legal Contracts
section
0.0299
party
0.0265
language
0.0226
contract
0.0203
date
0.0155
enron
0.0151
parties
0.0149
notice
0.0126
days
0.0112
include
0.0111
M.Hain
0.0549
J.Steffes
J.Dasovich
0.0377
R.Shapiro
D.Hyvl
0.0362
K.Ward

Topic 17
Document Review
attached
0.0742
agreement
0.0493
review
0.0340
questions
0.0257
draft
0.0245
letter
0.0239
comments
0.0207
copy
0.0165
revised
0.0161
document
0.0156
G.Nemec
0.0737
B.Tycholiz
G.Nemec
0.0551
M.Whitt
B.Tycholiz
0.0325
G.Nemec

Topic 27
Time Scheduling
day
0.0419
friday
0.0418
morning
0.0369
monday
0.0282
office
0.0282
wednesday
0.0267
tuesday
0.0261
time
0.0218
good
0.0214
thursday
0.0191
J.Dasovich
0.0340
R.Shapiro
J.Dasovich
0.0289
J.Steffes
C.Clair
0.0175
M.Taylor

Topic 45
Sports Pool
game
0.0170
draft
0.0156
week
0.0135
team
0.0135
eric
0.0130
make
0.0125
free
0.0107
year
0.0106
pick
0.0097
phillip
0.0095
E.Bass
0.3050
M.Lenhart
E.Bass
0.0780
P.Love
M.Motley
0.0522
M.Grigsby

Topic 34
Operations
operations
0.0321
team
0.0234
office
0.0173
list
0.0144
bob
0.0129
open
0.0126
meeting
0.0107
gas
0.0107
business
0.0106
houston
0.0099
S.Beck
0.2158
L.Kitchen
S.Beck
0.0826
J.Lavorato
S.Beck
0.0530
S.White

Topic 37
Power Market
market
0.0567
power
0.0563
price
0.0280
system
0.0206
prices
0.0182
high
0.0124
based
0.0120
buy
0.0117
customers
0.0110
costs
0.0106
J.Dasovich
0.1231
J.Steffes
J.Dasovich
0.1133
R.Shapiro
M.Taylor
0.0218
E.Sager

Topic 41
Government Relations
state
0.0404
california
0.0367
power
0.0337
energy
0.0239
electricity
0.0203
davis
0.0183
utilities
0.0158
commission
0.0136
governor
0.0132
prices
0.0089
J.Dasovich
0.3338
R.Shapiro
J.Dasovich
0.2440
J.Steffes
J.Dasovich
0.1394
R.Sanders

Topic 42
Wireless
blackberry
0.0726
net
0.0557
www
0.0409
website
0.0375
report
0.0373
wireless
0.0364
handheld
0.0362
stan
0.0282
fyi
0.0271
named
0.0260
R.Haylett
0.1432
T.Geaccone
T.Geaccone 0.0737
R.Haylett
R.Haylett
0.0420
D.Fossum

Table 2: illustration several topics 50-topic run Enron email data set.
topic shown top 10 words corresponding conditional
probabilities. quoted titles summary topics.
prominent author-recipient pairs topic. example, Mary Hain
in-house lawyer Enron; Eric Bass coordinator fantasy football league
within Enron. Operations topic satisfying see Beck,
Chief Operating Officer Enron; Kitchen President Enron Online;
Lavorato CEO Enron America. Government Relations topic,
see Dasovich, Government Relation Executive, Shapiro, Vice
President Regulatory Affairs, Steffes, Vice President Government
Affairs, Sanders, Vice President WholeSale Services. Wireless
see Haylett, Chief Financial Officer Treasurer, avid
user Blackberry brand wireless, portable email system.

258

fiTopic Role Discovery Social Networks

summary topics. clarity specificity topics typical
topics discovered model. example, Topic 17 (Document Review) comes
messages discussing review comments documents; Topic 27 (Time Scheduling)
comes messages negotiating meeting times.
Beneath word distribution topic three author-recipient pairs
highest probability discussing topiceach pair separated horizontal line,
author recipient. example, Hain, top author messages Legal
Contracts topic, in-house lawyer Enron. inspection messages related
Sports Pool, Eric Bass seems coordinator fantasy football league
among Enron employees. Operations topic, satisfying see Beck,
Chief Operating Officer Enron; Kitchen President Enron Online; Lavorato
CEO Enron America. Government Relations topic, see Dasovich,
Government Relation Executive, Shapiro, Vice President Regulatory Affairs,
Steffes, Vice President Government Affairs, Sanders, Vice President
WholeSale Services. Wireless see Haylett, Chief Financial Officer
Treasurer, avid user Blackberry brand wireless, portable email system.
Results McCallum email data set reported Table 3.
4.2 Stochastic Blockstructures Roles
stochastic equivalence hypothesis SNA states nodes network behave
stochastically equivalently must similar roles. case email network consisting
message counts, natural way measure equivalence examine probability
node communicated nodes. two nodes similar probability distribution
communication partners, consider role-equivalent. Lacking true
distance measure probability distributions, use symmetric measure,
Jensen-Shannon (JS) divergence, obtain symmetric matrix relating
nodes network. Since want consider nodes/users small JS divergence
equivalent, use inverse divergence construct symmetric matrix
larger numbers indicate higher similarity users.
Standard recursive graph-cutting algorithms matrix used cluster users,
rearranging rows/columns form approximately block-diagonal structures.
familiar process blockstructuring used SNA. perform analysis two
data sets: small subset Enron users consisting mostly people associated
Transwestern Pipeline Division within Enron, entirety McCallums email.
begin Enron TransWestern Pipeline Division. analysis employed
closed-universe assumptiononly messages traded among considered authors
data set used.
traditional SNA similarity measure (in case JS divergence distributions
recipients person) shown left matrix Figure 3. Darker shading indicates
two users considered similar. related matrix resulting ART model
(JS divergence recipient-marginalized topic distributions email author) appears
middle Figure 3. Finally, results analysis using topics
model rather ART model seen right. three matrices
similar, interesting differences.
259

fiMcCallum, Wang, & Corrada-Emmanuel

Topic 5
Grant Proposals
proposal
0.0397
data
0.0310
budget
0.0289
work
0.0245
year
0.0238
glenn
0.0225
nsf
0.0209
project
0.0188
sets
0.0157
support
0.0156
smyth
0.1290
mccallum
mccallum
0.0746
stowell
mccallum
0.0739
lafferty
mccallum
0.0532
smyth
pereira
0.0339
lafferty

Topic 31
Meeting Setup
today
0.0512
tomorrow
0.0454
time
0.0413

0.0391
meeting
0.0339
week
0.0255
talk
0.0246
meet
0.0233
morning
0.0228
monday
0.0208
ronb
0.0339
mccallum
wellner
0.0314
mccallum
casutton
0.0217
mccallum
mccallum
0.0200
casutton
mccallum
0.0200
wellner

Topic 38
ML Models
model
0.0479
models
0.0444
inference
0.0191
conditional
0.0181
methods
0.0144
number
0.0136
sequence
0.0126
learning
0.0126
graphical
0.0121
random
0.0121
casutton
0.0498
mccallum
icml04-webadmin 0.0366
icml04-chairs
mccallum
0.0343
casutton
nips04workflow
0.0322
mccallum
weinman
0.0250
mccallum

Topic 41
Friendly Discourse
great
0.0516
good
0.0393

0.0223
sounds
0.0219
work
0.0196
wishes
0.0182
talk
0.0175
interesting
0.0168
time
0.0162
hear
0.0132
mccallum
0.0558
culotta
mccallum
0.0530
casutton
mccallum
0.0274
ronb
mccallum
0.0255
saunders
mccallum
0.0181
pereira

Table 3: four topics prominent McCallums email exchange Padhraic
Smyth, 50-topic run ART 9 months McCallums email. topics provide extremely salient summary McCallum Smyths relationship
time period: wrote grant proposal together; set many
meetings; discussed machine learning models; friendly
other. topic shown 10 highest-probability words corresponding conditional probabilities. quoted titles summary
topics. prominent author-recipient pairs topic. people
smyth also appear sensible associations: stowell McCallums
proposal budget administrator; McCallum also wrote proposal John Lafferty Fernando Pereira; McCallum also sets meetings, discusses machine
learning friendly discourse graduate student advisees: ronb, wellner,
casutton, culotta; not, however, discuss details proposal-writing
them.

Consider Enron employee Geaccone (user 9 matrices Figure 3). According
traditional SNA role measurement, Geaccone McCarty (user 8) similar
roles, however, ART models indicate special similarity. Inspection
email messages users reveals Geaconne Executive Assistant,
McCarty Vice-Presidentrather different rolesand, thus output ART
appropriate. interpret results follows: SNA analysis shows
wrote email similar sets people, ART analysis illustrates used
different language wrote people.
260

fiTopic Role Discovery Social Networks

16 : teb.lokey
15 : steven.harris
14 : kimberly.watson
13 : paul.ybarbo
12 : bill.rapp
11 : kevin.hyatt
10 : drew.fossum
9 : tracy.geaccone
8 : danny.mccarty
7 : shelley.corman
6 : rod.hayslett
5 : stanley.horton
4 : lynn.blair
3 : paul.thomas
2 : larry.campbell
1 : joe.stepenovitch

16

16

15

15

14

14

13

13

12

12

11

11

10

10

9

9

8

8

7

7

6

6

5

5

4

4

3

3

2

2

1

1 2 3 4 5 6 7 8 910111213141516

1
1

2

3

4

5

6

7

8

9 10 11 12 13 14 15 16

1

2

3

4

5

6

7

8

9 10 11 12 13 14 15 16

Figure 3: Left: SNA Inverse JS Network. Middle: ART Inverse JS Network. Right:
Inverse JS Network. Darker shades indicate higher similarity.

Comparing ART AT, models provide similar role distance Geaccone
versus McCarty, ART show differences elsewhere. example,
indicates strong role similarity Geaconne Hayslett (user 6),
boss (and CFO & Vice President Division); hand, ART
correctly designates low role similarity pairin fact, ART assigns low similarity
Geaconne others matrix, appropriate
executive assistant small sample Enron employees.
Another interesting pair people Blair (user 4) Watson (user 14). ART predicts
role-similar, SNA models not. ARTs prediction seems
appropriate since Blair worked gas pipeline logistics Watson worked pipeline
facility planning, two similar jobs.
McCarty, Vice-President CTO Division, also highlights differences
models. ART model puts closest Horton (user 5), President
Division. predicts closest Rapp (user 12), merely lawyer
reviewed business agreements, also close Harris (user 15), mid-level
manager.
Using ART way emphasizes role similarity, group membership.
seen considering Thomas (user 3, energy futures trader), relation
Rapp (user 12, lawyer mentioned above), Lokey (user 16, regulatory
affairs manager). three people work related areas, ART fittingly
indicate role similarity them, (ART marginally AT).
hand, traditional SNA results (Figure 3 left) emphasizes group memberships rather
role similarity placing users 1 3 rather distinct block structure;
three people matrix members Enron Transwestern Division
group, three exchanged email people
Transwestern Division. separate work also developed Group-Topic (GT)
model, explicitly discovers groups way leverages accompanying text (Wang
et al., 2006). future may also develop model integrates ART
SNA metrics jointly model role group memberships.
Based examples, similar examples, posit ART model
appropriate SNA predicting role similarity. thus would claim
261

fiMcCallum, Wang, & Corrada-Emmanuel

120

100

80

60

40

20

0
0

20

40

60

80

100

120

Figure 4: SNA Inverse JS Network 10 topic run McCallum Email Data. Darker
shades indicate higher similarity. Graph partitioning calculated 128
authors ten emails McCallums Email Data. block
0 30 people related McCallums research group UMass.
block 30 50 includes researchers around world.

ART model yields appropriate results SNA model predicting
role-equivalence users, somewhat better model capacity.
also carried analysis personal email McCallum validate
difference ART SNA predictions. 825 users email
corpus, 128 wrote ten emails. perform blockstructure analysis
128 users, shown Figure 4. blocks discovered quite meaningful, e.g.,
block 0 30 people related McCallums research group UMass,
block 30 50 includes researchers around world.
Table 4 shows closest pairs terms JS divergence, calculated ART
model SNA model. difference quality ART SNA halves
table striking.
Almost pairs predicted ART model look reasonable many
predicted SNA opposite. example, ART matches editor reviews, two
email addresses send messages managing journal reviews. User mike mikem
actually two different email addresses person. coreferent email
262

fiTopic Role Discovery Social Networks

Pairs considered alike ART
User Pair
Description
editor reviews
journal review management
mike mikem
person! (manual coreference error)
aepshtey smucker
students McCallums class
coe laurie
UMass admin assistants
mcollins tom.mitchell ML researchers SRI project
mcollins gervasio
ML researchers SRI project
davitz freeman
ML researchers SRI project
mahadeva pal
ML researchers, discussing hiring
kate laurie
UMass admin assistants
ang joshuago
organizing committee conference
Pairs considered alike SNA
User Pair
Description
aepshtey rasmith
students McCallums class
donna editor
Spouse unrelated journal editor
donna krishna
Spouse unrelated conference organizer
donna ramshaw
Spouse unrelated researcher BBN
donna reviews
Spouse unrelated journal editor
donna stromsten
Spouse unrelated visiting researcher
donna yugu
Spouse unrelated grad student
aepshtey smucker
students McCallums class
rasmith smucker
students McCallums class
editor elm
Journal editor Production Editor
Table 4: Pairs considered alike ART SNA McCallum email. pairs
produced ART model accurately quite similar.
top SNA pairs. Many users considered similar SNA merely
appear corpus mostly sending email McCallum. However,
causes people different roles incorrectly declared similarsuch
McCallums spouse JMLR editor.

addresses pre-collapsed hand preprocessing; ART pointed
mistaken omission, indicating potential ART used helpful component
automated coreference system. Users aepshtey smucker students class
taught McCallum. Users coe, laurie kate UMass CS Department administrative
assistants; rarely send email other, write similar things. User
ang Andrew Ng Stanford; joshuago Joshua Goodman Microsoft Research;
organizing committee new conference along McCallum.
hand, pairs declared similar SNA model mostly
extremely poor. pairs include donna, indicate pairs people
similar corpus appeared mostly sending email McCallum,
others. User donna McCallums spouse. pairs sensible.
263

fiMcCallum, Wang, & Corrada-Emmanuel

User Pair
editor reviews
jordan mccallum
mccallum vanessa
croft mccallum
mccallum stromsten
koller mccallum
dkulp mccallum
blei mccallum
mccallum pereira
davitz mccallum

Description
journal editors
ML researchers
grad student working IR
UMass faculty, working IR
ML researchers
ML researchers
UMass faculty
ML researchers
ML researchers
working SRI project

Table 5: Pairs highest rank difference ART SNA McCallum email.
traditional SNA metric indicates pairs people different,
ART indicates similar. strong relations pairs.

example, aepshtey, smucker rasmith students McCallums class. User elm
Erik Learned-Miller correctly indicated similar editor since Production
Editor Journal Machine Learning Research.
highlight difference SNA ART predictions, present Table 5,
obtained using ART SNA rank pairs people similarity,
listing pairs highest rank differences two models.
pairs SNA indicated different, ART indicated similar. every case,
role similarities pairs.
4.3 Perplexity Comparison ART
Models natural languages often evaluated perplexity measure goodness
fit models. lower perplexity language model has, better predicts unseen
words given words previously saw.
perplexity previously unseen message consisting words wd defined
follows, author ad recipient(s) rd given:


log(p(wd |ad , rd ))
Perplexity(wd ) = exp
,
Nd
( defined Equation 1)
p(wd |ad , rd ) =

Nd

i=1


1 XX
ad rt twdi
|rd | rr


!
.

t=1

randomly split data sets training set (9/10) test set (the remaining
1/10). test sets, 92.37% (Enron) 84.51% (McCallum) author-recipient pairs
also appear training sets. Ten Markov chains run different initializations,
264

fiTopic Role Discovery Social Networks

(a) Enron data set

(b) McCallum data set

Figure 5: Perplexity comparison ART two data sets. plot information
rate (logarithm perplexity) here. difference ART
significant one-tailed t-test (Enron data set: p-value < 0.01 except 10
topics p-value = 0.018; McCallum data set: p-value < 1e 5).

samples 2000th iteration used estimate Equation 1.
report average information rate (logarithm perplexity) different number topics
two data sets Figure 5.
clearly shown figure, ART significantly better predictive power
large number randomly selected test documents data sets onetailed t-test. Particularly Enron data set, ART uses much fewer number topics
achieve best predictive performance. also find lowest perplexity
obtained ART achievable parameter setting data sets.
results provide evidence ART discovers meaningful topics context
social network indeed appropriate message data AT.
compare perplexity ART LDA, however (which ART
dominates perplexity) already shown better perplexity LDA
(Rosen-Zvi, Griffiths, Smyth, & Steyvers, 2005). Due much simpler model structure,
author model (McCallum, 1999) much worse perplexity. Measured data
sets, information rates (log perplexity) larger 10, whereas ARTs information
rates mostly 8 9.

5. Role-Author-Recipient-Topic Models
better explore roles authors, additional level latent variables introduced explicitly model roles. particular interest capturing notion person
multiple roles simultaneouslyfor example, person professor
mountain climber. role associated set topics, topics may
overlap. example, professors topics may prominently feature research, meeting times,
grant proposals, friendly relations; climbers topics may prominently feature mountains,
climbing equipment, also meeting times friendly relations.
265

fiMcCallum, Wang, & Corrada-Emmanuel

Role-Author-Recipient-Topic
Model 1
(RART1)
rd

ad



x




Role-Author-Recipient-Topic
Model 2
(RART2)

g



ad

rd

gd

hd









z

R,R



w


rd

gd

hd

h

z





ad



h

R,R











Role-Author-Recipient-Topic
Model 3
(RART3)

Nd



z

R,R





w


Nd







w


Nd


Figure 6: Three possible variants Role-Author-Recipient-Topic (RART) model.

incorporate ART model new set variables take values indicating
role, term augmented model Role-Author-Recipient-Topic (RART) model.
RART, authors, roles message-contents modeled simultaneously. author
multinomial distribution roles. Authors recipients mapped
role assignments, topic selected based roles. Thus clustering
model, appearances topics underlying data, sets correlated topics
gather together clusters indicate roles. sender-role recipient-role pair
multinomial distribution topics, topic multinomial distribution
words.
shown Figure 6, different strategies employed incorporate role
latent variables. First RART1, role assignments made separately word
document. model represents person change role course
email message. RART2, hand, person chooses one role duration
message. recipient message selects role assignment,
word, recipient (with corresponding role) selected condition selection
topic. RART3, recipients together result selection common, shared
role, used condition selection every word message. last model
may help capture fact persons role may depend recipients
message, also restricts recipients single role.
describe generative process RART1 paper detail, leave
two exploration elsewhere. generative process message, author, ad ,
set recipients, rd , observed. generate word, recipient, x, chosen
uniform rd , role g author, role h recipient x
chosen two multinomial role distributions ad x , respectively. Next, topic z
chosen multinomial topic distribution gh , distribution specific
266

fiTopic Role Discovery Social Networks

Role 3
Support UMass CS
olc (lead Linux sysadmin)
gauthier (sysadmin CIIR group)
irsystem (mailing list CIIR sysadmins)
system (mailing list dept. sysadmins)
allan (prof., chair computing committee)
valerie (second Linux sysadmin)
tech (mailing list dept. hardware)
steve (head dept. support)

0.2730
0.1132
0.0916
0.0584
0.0515
0.0385
0.0360
0.0342

Role 4
Working SRI CALO Project
pereira (prof. UPenn)
0.1876
claire (UMass CS business manager)
0.1622
israel (lead system integrator SRI)
0.1140
moll (prof. UMass)
0.0431
mgervasio (computer scientist SRI)
0.0407
melinda.gervasio (same person above) 0.0324
majordomo (SRI CALO mailing list)
0.0210
collin.evans (computer scientist SRI)
0.0205

Table 6: illustration two roles 50-topic, 15-group run McCallum email
data set. role shown prominent users (their short descriptions parenthesis) corresponding conditional probabilities. quoted
titles summary roles. example, Role 3, users
employees (or mailing lists) support staff UMass CS, except allan,
who, however, professor chairing departments computing committee.

author-role recipient-role pair (g, h). Finally, word w generated sampling
topic-specific multinomial distribution z .
RART1 model, given hyper-parameters , , author ad , set
recipients rd message d, joint distribution topic mixture ij
author-role recipient-role pair (i, j), role mixture k author k, word mixture
topic t, set recipients x, set sender roles g, set recipient roles h,
set topics z set words w given (we define R number roles):
P (, , , x, g, h, z, w|, , , a, r)
=

R
R

i=1 j=1

p(ij |)



t=1

p(t |)



k=1

p(k |)

Nd



P (xdi |rd )P (gdi |ad )P (hdi |xdi )P (zdi |gdi hdi )P (wdi |zdi )

d=1 i=1

Integrating , , summing x, g, h z, get marginal
distribution corpus, similar showed ART.
perform inference RART models, Gibbs sampling formulae derived
similar way Appendix A, complex form.

6. Experimental Results RART
Extensive experiments conducted RART1 model. introduce
two sets additional latent variables (author role recipient role), sampling procedure iteration significantly complex. make inference efficient,
instead perform two distinct parts. One strategy found useful
first train ART model, use sample obtain topic assignments recipient assignments word token. Then, next stage, treat topics recipients
observed (locked). Although strategy may recommended arbitrary graphical models, feel reasonable find single sample Gibbs
267

fiMcCallum, Wang, & Corrada-Emmanuel

Role
Role
Role
Role
Role

allan (James Allan)
10 (grant issues)
13 (UMass CIIR group)
2 (natural language researcher)
3 (IT Support UMass CS)
4 (working SRI CALO Project)

0.4538
0.2813
0.0768
0.0326
0.0306

Role
Role
Role
Role
Role

pereira (Fernando Pereira)
2 (natural language researcher)
4 (working SRI CALO Project)
6 (proposal writing)
10 (grant issues)
8 (guests McCallums house)

0.5749
0.1519
0.0649
0.0444
0.0408

Table 7: illustration role distribution two users 50-topic, 15-group run
McCallum email data set. user shown prominent
roles (their short descriptions parenthesis) corresponding conditional
probabilities. example, considering user pereira (Fernando Pereira), top
five role assignments appropriate, viewed McCallums email.

sampling ART model yields good assignments. following results based
15-group, 50-topic run RART1 McCallum email data set.
results show RART model indeed automatically discover meaningful
person-role information explicit inclusion role variable. show
prominent users two roles Table 6. instance, users prominent Role 3
employees (or mailing lists) support staff UMass CS, except allan,
who, however, professor chairing departments computing committee. Role
4 seems represent working SRI CALO project. top prominent
members researchers working CALO project, many SRI. sender
majordomo sends messages SRI CALO mailing list. Users claire moll were,
however, unrelated project, know reason appear
role. users mgervasio melinda.gervasio actually person; satisfyingly
RART found similar role distributions.
One objective RART model capture multiple roles person has.
role distribution two users shown Table 7. example, user allan (James
Allan) mentioned role support, also role member
Center Intelligent Information Retrieval, grant proposal writer, natural
language researcher. Although member SRI CALO Project, allans research
related CALO, perhaps reason CALO appears (weakly) among
roles. Consider also user pereira (Fernando Pereira); top five role assignments
exactly appropriate, viewed McCallums email.
expected, one observe interesting differences sender versus recipient topic
distributions associated role. instance, Role 4 SRI CALO, top three
topics sender role Topic 27 CALO information, Topic 11 mail accounts,
Topic 36 program meetings, recipient roles, prominent Topic 48 task
assignments, Topic 46 CALO-related research paper, Topic 40 java code.

7. Conclusions
presented Author-Recipient-Topic model, Bayesian network social network
analysis discovers discussion topics conditioned sender-recipient relationships
268

fiTopic Role Discovery Social Networks

corpus messages. best knowledge, model combines first time
directionalized connectivity graph social network analysis clustering
words form topics probabilistic language modeling.
model applied discovering topics conditioned message sending relationships, clustering find social roles, summarizing analyzing large bodies
message data. model would form useful component systems routing requests,
expert-finding, message recommendation prioritization, understanding interactions organization order make recommendations improving organizational
efficiency.
Role-Author-Recipient-Topic (RART) models explicitly capture multiple roles
people, based messages sent received. Future work develop models
explicitly capture roles groups.

Acknowledgments
material paper presented part 19th International Joint Conference Artificial Intelligence (IJCAI 2005) Edinburgh, Scotland, July 30August 5,
2005. work supported part Center Intelligent Information Retrieval,
Central Intelligence Agency, National Security Agency, National Science Foundation NSF grant #IIS-0326249, Defense Advanced Research Projects
Agency, Department Interior, NBC, Acquisition Services Division,
contract #NBCHD030010.

Appendix A. Gibbs Sampling Derivation ART
need derive P (xdi , zdi |xdi , zdi , w, , , a, r), conditional distribution topic
recipient word wdi given words topic recipient assignments, xdi
zdi , carry Gibbs sampling procedure ART. begin joint
probability whole data set. Note take advantage conjugate priors
simplify integrals.

=

P (x, z, w|, , a, r)
ZZ
Nd






p(ij |)
p(t |)
P (xdi |rd ) P (zdi |ad xdi )P (wdi |zdi )dd
t=1

i=1 j=1

=



d=1 i=1

!
P



( Tt=1 ) 1 nijt
1 Nd
(
)
ijt
ijt
QT
|rd |
t=1 (t ) t=1
i=1 j=1
i=1 j=1 t=1
d=1
! V
P
Z

V
( Vv=1 v ) v 1 mtv

tv
tv
QV
v=1 (v ) v=1
t=1
t=1 v=1
Z

Z
V



+nijt 1
ijt
dij
tvv +mtv 1 dt
Z



i=1 j=1

t=1

t=1

v=1

269

fiMcCallum, Wang, & Corrada-Emmanuel

QV


QT


v=1 (v + mtv )
t=1 (t + nijt )

PT
P
V
i=1 j=1 ( t=1 (t + nijt )) t=1 ( v=1 (v + mtv ))
|rd | number recipients message d, nijt number tokens assigned
topic author-recipient pair (i, j), mtv represent number tokens word
v assigned topic t.
Using chain rule, obtain conditional probability conveniently. define
wdi word tokens except token wdi .

=



P (xdi , zdi |xdi , zdi , w, , , a, r)
P (xdi , zdi , wdi |xdi , zdi , wdi , , , a, r)
P (x, z, w|, , a, r)

P (wdi |xdi , zdi , wdi , , , a, r)
P (xdi , zdi , wdi |, , a, r)
(wdi +mzdi wdi )
(zdi +nad xdi zdi )
(zdi +nad xdi zdi 1)
(wdi +mzdi wdi 1)
P
P
(
( V
(t +nad xdi ))
(v +mzdi v ))
PT t=1
PV v=1
( t=1 (t +nad xdi )1) ( v=1 (v +mzdi v )1)

z + nad xdi zdi 1
w + mzdi wdi 1
PT di
PV di
t=1 (t + nad xdi ) 1
v=1 (v + mzdi v ) 1

one wants, manipulation turn formula separated update
equations topic recipient token, suitable random systematic scan
updates:
P (xdi |xdi , z, w, , , a, r)
P (zdi |x, zdi , w, , , a, r)

z + nad xdi zdi 1
PT di
t=1 (t + nad xdi ) 1
w + mzdi wdi 1
z + nad xdi zdi 1
PT di
PV di
t=1 (t + nad xdi ) 1
v=1 (v + mzdi v ) 1

References
Adamic, L., & Adar, E. (2004). search social network. http://arXiv.org/abs/condmat/0310120.
Airoldi, E., Blei, D., Fienberg, S., & Xing, E. (2006). Stochastic blockmodels mixedmembership: General formulation nested variational inference. ICML Workshop Statistical Network Analysis.
Albert, R., & Barabasi, A.-L. (2002). Statistical mechanics complex networks. Reviews
Modern Physics, 74 (1), 4797.
Andrieu, C., de Freitas, N., Doucet, A., & Jordan, M. (2003). introduction MCMC
machine learning. Machine Learning, 50, 543.
Blei, D., & Lafferty, J. (2006a). Correlated topic models. Advances Neural Information
Processing Systems 18.
Blei, D. M., & Lafferty, J. D. (2006b). Dynamic topic models. Proceedings 23rd
International Conference Machine Learning.
Blei, D. M., Ng, A. Y., & Jordan, M. J. (2003). Latent Dirichlet allocation. Journal
Machine Learning Research, 3, 9931022.
270

fiTopic Role Discovery Social Networks

Erosheva, E., Fienberg, S., & Lafferty, J. (2004). Mixed membership models scientific
publications. Proceedings National Academy Sciences, 101(Suppl. 1).
Griffiths, T., Steyvers, M., Blei, D., & Tenenbaum, J. (2004). Integrating topics syntax.
Advances Neural Information Processing Systems (NIPS) 17.
Griffiths, T. L., & Steyvers, M. (2004). Finding scientific topics. Proceedings National
Academy Sciences, 101 (suppl. 1), 52285235.
Hofmann, T. (2001). Unsupervised learning probabilistic latent semantic analysis. Machine Learning, 42 (1), 177196.
Holland, P., Laskey, K. B., & Leinhardt, S. (1983). Stochastic blockmodels: first
steps. Social Networks, 5, 109137.
Kemp, C., Tenenbaum, J. B., Griffiths, T. L., Yamada, T., & Ueda, N. (2006). Learning
systems concepts infinite relational model. Proceedings 21st
National Conference Artificial Intelligence.
Kemp, C., Griffiths, T. L., & Tenenbaum, J. (2004). Discovering latent classes relational
data. Tech. rep., MIT AI Memo 2004-019.
Kleinberg, J. (2000). Navigation small world. Nature, 406, 845.
Kubica, J., Moore, A., Schneider, J., & Yang, Y. (2002). Stochastic link group detection.
Proceedings 18th National Conference Artificial Intelligence, pp. 798804.
Kurihara, K., Kameya, Y., & Sato, T. (2006). frequency-based stochastic blockmodel.
Workshop Information Based Induction Sciences.
Li, W., & McCallum, A. (2006). Pachinko allocation: DAG-structured mixture models
topic correlations. Proceedings 23rd International Conference Machine
Learning.
Lorrain, F., & White, H. C. (1971). structural equivalence individuals social
networks. Journal Mathematical Sociology, 1, 4980.
McCallum, A. (1999). Multi-label text classification mixture model trained EM.
16th National Conference Artificial Intelligence Workshop Text Learning.
Mimno, D., & McCallum, A. (2007). Expertise modeling matching papers reviewers.
Proceedings 13th ACM SIGKDD International Conference Knowledge
Discovery Data Mining, pp. 500509.
Minka, T., & Lafferty, J. (2002). Expectation-propagation generative aspect model.
Proceedings 18th Conference Uncertainty Artificial Intelligence.
Nowicki, K., & Snijders, T. A. (2001). Estimation prediction stochastic blockstructures. Journal American Statistical Association, 96 (455), 10771087.
271

fiMcCallum, Wang, & Corrada-Emmanuel

Rosen-Zvi, M., Griffiths, T., Smyth, P., & Steyvers, M. (2005). Learning author-topic
models text corpora. Submitted Journal Machine Learning Research.
Rosen-Zvi, M., Griffiths, T., Steyvers, M., & Smyth, P. (2004). author-topic model
authors documents. Proceedings 20th Conference Uncertainty
Artificial Intelligence.
Shetty, J., & Adibi, J. (2004). Enron email dataset database schema brief statistical
report. Tech. rep., Information Sciences Institute.
Steyvers, M., Smyth, P., Rosen-Zvi, M., & Griffiths, T. (2004). Probabilistic author-topic
models information discovery. Proceedings 10th ACM SIGKDD International Conference Knowledge Discovery Data Mining.
Teh, Y. W., Jordan, M. I., Beal, M. J., & Blei, D. M. (2004). Hierarchical Dirichlet processes.
Tech. rep., UC Berkeley Statistics.
Wang, X., & McCallum, A. (2006). Topics time: non-markov continuous-time model
topical trends. Proceedings 12th ACM SIGKDD International Conference
Know ledge Discovery Data Mining, pp. 424433.
Wang, X., McCallum, A., & Wei, X. (2007). Topical n-grams: Phrase topic discovery, application information retrieval. Proceedings 7th IEEE
International Conference Data Mining.
Wang, X., Mohanty, N., & McCallum, A. (2006). Group topic discovery relations
attributes. Advances Neural Information Processing Systems 18, pp.
14491456.
Wasserman, S., & Faust, K. (1994). Social Network Analysis: Methods Applications.
Cambridge University Press.
Watts, D. J. (2003). Six Degrees: Science Connected Age. W. W. Norton &
Company.
Watts, D. J., Dodds, P. S., & Newman, M. E. J. (2002). Identify search social
networks. Science, 296 (5571), 13021305.
Wolfe, A. P., & Jensen, D. (2004). Playing multiple roles: Discovering overlapping roles
social networks. 21st International Conference Machine Learning Workshop
Statistical Relational Learning Connections Fields.
Wu, F., Huberman, B. A., Adamic, L. A., & Tyler, J. R. (2003). Information flow social
groups. http://arXiv.org/abs/cond-mat/0305305.

272

fiJournal Artificial Intelligence Research 30 (2007) 501-523

Submitted 06/07; published 12/07

Semantics Logic Programs Preferences
Sergio Greco

greco@deis.unical.it

DEIS, Universita della Calabria
via P. Bucci, 87030 Rende - Italy

Irina Trubitsyna

irina@deis.unical.it

DEIS, Universita della Calabria
via P. Bucci, 87030 Rende - Italy

Ester Zumpano

zumpano@deis.unical.it

DEIS, Universita della Calabria
via P. Bucci, 87030 Rende - Italy

Abstract
work contribution prioritized reasoning logic programming presence
preference relations involving atoms. technique, providing new interpretation
prioritized logic programs, inspired semantics Prioritized Logic Programming
enriched use structural information preference Answer Set Optimization Programming. Specifically, analysis logic program carried together
analysis preferences order determine choice order sets
comparable models. new semantics compared approaches known
literature complexity analysis also performed, showing that, respect
similar approaches previously proposed, complexity computing preferred stable models increase.

1. Introduction
increased interest preferences witnessed extensive number proposals
systems preference handling (Grell, Konczak, & Schaub, 2005; Van Nieuwenborgh &
Vermeir, 2003; Wakaki, Inoue, Sakama, & Nitta, 2003, 2004). literature distinguishes
static dynamic preferences. Static preferences fixed time theory specified, i.e. external logic program, whereas dynamic preferences appear
within logic program determined fly. common form
preference consists specifying preference conditions among rules (Brewka, 1996; Brewka
& Eiter, 1999, 2000; Delgrande, Schaub, & Tompits, 2000a, 2000b, 2003; Gelfond & Son,
1997; Schauba & Wang, 2001; Van Nieuwenborgh & Vermeir, 2002, 2004; Wang, Zhou, &
Lin, 2000; Zhang & Foo, 1997), whereas, recent proposals admit expression
preference relations among atoms (Brewka, Niemela, & Truszczynski, 2003; Brewka, 2004;
Sakama & Inoue, 2000; Wakaki et al., 2003). sophisticated forms preferences also
allow specification priorities conjunctions (disjunctions) literals (Brewka
et al., 2003; Delgrande et al., 2000a; Sakama & Inoue, 2000) numerical penalties
suboptimal options (Brewka, 2004).
work contribution prioritized reasoning logic programming presence
preference conditions involving atoms. particular, priorities applied following
natural ordering defined dependencies, proposed Answer Set Optimizac
2007
AI Access Foundation. rights reserved.

fiGreco, Trubitsyna, & Zumpano

tion (ASO) semantics (Brewka et al., 2003), comparison strategy, proposed
Preferred Stable Model (PSM) semantics (Sakama & Inoue, 2000), reviewed also introducing concept comparable models. next example describes intuition
basis proposed approach.
Example 1 following prioritized program hP 1 , 1 i, inspired program presented
Brewka et al. (2003), describes different menus preferences among drinks
desserts:
P1 :

fish beef
red white
pie ice-cream
fish, white
beef, pie
fish, ice-cream

1 :

%1 : white > red fish
%2 : red > white beef
%3 : pie > ice-cream red

symbol denotes exclusive disjunction, i.e. body rule true exactly
one atom head true, whereas rule empty head defines constraint, i.e.
rule satisfied body false. first three rules P 1 select main
dish, drink dessert; last three rules constraints state feasible
solution cannot contain i) fish white ii) beef pie iii) fish ice-cream.
Prioritized rules 1 introduce preferences among drinks (%1 , %2 ) desserts (%3 ).
program P 1 three stable models: M1 = {fish, red, pie}, M2 = {beef, white,
ice-cream} M3 = {beef, red, ice-cream}. PSM returns M1 unique preferred model; whereas ASO technique, following natural ordering preference rules
(%1 %2 precede %3 ), derives M3 unique solution. Thus, two approaches
provide different results.
2
structure preference rules example suggests i) fish beef
alternative options main dish ii) choice drink depends selected main
dish precedes choice dessert. second conclusion based observation
%1 %2 provide opposite valuations choice drink define two different
classes models (menus), considered separately. words, model
M1 (associated menu containing fish) compared models
M2 M3 (associated menus containing beef). Consequently, M1 M3
preferred.
Observe example PSM semantics derives M1 preferred
model M1 preferable M3 (due presence rule %3 ), M3 preferable M2
(due presence rule %2 ) and, transitively, M1 also preferable M2 .
worth noting use transitive closure makes comparison models much
complex two models cannot compared directly. hand ASO
semantics sensitive syntactic changes programs. fact illustrated means
following example.
Example 2 Consider prioritized program hP2 , 2 i, extension prioritized program defined Example 1:
502

fiOn Semantics Logic Programs Preferences

P2 :

fish beef
red white beer
pie ice-cream
fish, white
beef, pie
fish, ice-cream
beer

2 :

%b1 : beer > white > red fish
%b2 : beer > red > white beef
%b3 : pie > ice-cream red

program equivalent one reported Example 1 as, even contains additional choice (beer), option feasible, presence constraint beer.
set stable models associated program P2 , coincides reported
program P 1 Example 1, consists of: M1 = {fish, red, pie}, M2 = {beef,
white, ice-cream} M3 = {beef, red, ice-cream}. Considering set preference
rules, note preferences regarding choice drink beer best option,
stable model containing it. Intuitively, two problems hP 1 , 1 Example 1 hP2 , 2 equivalent must preferred models. ASO
semantics sensitive program change gives M1 M3 solution, whereas,
equivalent program Example 1, returned preferred model M3 only.
change occurs set preferred models PSM semantics.
2
Thus, paper present new semantics, inspired PSM ASO semantics, seems better capture intuitive meaning programs avoids
mentioned problems.
1.1 Contribution
paper provides new semantics prioritized logic programs enriching one proposed Sakama Inoue (2000) additional information gained structure
preference rules proposed Brewka et al. (2003). particular, new semantics
uses different preference relations among stable models introduces natural ordering
among preferences fixes order choices, basis stratification
preference program. decision determined set choices belonging
corresponding level provides subset models given input solution.
decision made, output subset becomes input set following decision
on. proposed semantics drives decision making process taking account catching
additional information regarding non comparable sets models partitioning set
models program looking alternative decisions. end concept
incomparability, taken account previous approaches, introduced.
paper presents detailed comparison approaches dealing preference
relations among atoms. Particular attention devoted PSM ASO semantics.
analysis complexity computing preferred answer sets also performed, showing
that, w.r.t. previous proposals, PSM ASO semantics, complexity
computing preferred stable models increase.
503

fiGreco, Trubitsyna, & Zumpano

1.2 Plan Paper
rest paper organized follows: Section 2 preliminaries Disjunctive
Abductive Logic Programs, Prioritized Logic Programs Answer Set Optimization
semantics given; Section 3 new interpretation prioritized logic programs
presented; Section 4 complexity results provided; Section 5 comparison
presented semantics PSM ASO semantics performed, approaches,
known literature, briefly described; finally, Section 6 outlines conclusions.

2. Preliminaries
assume familiarity relational database theory, disjunctive logic programs, disjunctive deductive databases, (disjunctive) stable model semantics computational complexity (Eiter, Gottlob, & Mannila, 1997b; Gelfond & Lifschitz, 1988, 1991; Papadimitriou,
1994).
2.1 Background
(disjunctive) logic program finite set rules r form a1 ak b1 , ..., bm ,
c1 , ..., cn k + + n > 0, a1 , ..., ak , b1 , ..., bm , c1 , ..., cn atoms.
disjunction a1 ak , denoted head(r), called head r, conjunction
b1 , ..., bm , c1 , ..., cn , denoted body(r), called body r.
Herbrand Universe program P set constants appearing P 1 ,
Herbrand Base BP set ground atoms constructed predicates
appearing P constants . term (resp. atom, rule program)
ground variables occur it. rule r0 ground instance rule r, r0 obtained
r replacing every variable r constant ; ground(P) denotes
set ground instances rules P.
intuitive meaning previous disjunctive rule body(r) true, i.e.
b1 , ..., bm true c1 , ..., cn false, head(r) must true, i.e least one
a1 , ..., ak true (otherwise r satisfied). Rules empty head, called denials
constraints, used define constraints satisfied body false.
paper exclusive disjunction, denoted , used head; statement head(r) =
a1 ... ak true, exactly one a1 , ..., ak true, i.e. disjunctive rule form
a1 ak body shorthand rule a1 ak body (k (k 1)/2)
constraints form ai , aj , body 1 < j k. solution logic program P
given terms stable model (answer set) semantics (Gelfond & Lifschitz, 1988, 1991).
interpretation P model P satisfies rules ground(P).
minimal model semantics, defined positive P, assigns P set minimal models
MM(P), model P minimal, proper subset model P
(Minker, 1982). general disjunctive stable model semantics also applies programs (unstratified) negation (Gelfond & Lifschitz, 1991). Disjunctive stable model
semantics generalizes stable model semantics, previously defined normal programs (Gelfond & Lifschitz, 1988). interpretation , denote P ground positive
program derived ground(P) i) removing rules contain negated atom
1. considering function free programs.

504

fiOn Semantics Logic Programs Preferences

body , ii) removing negated atoms remaining rules.
interpretation (disjunctive) stable model P MM(P ).
general P, stable model semantics assigns P set SM(P) stable models. well known stable models minimal models (i.e. SM(P) MM(P))
negation free programs, minimal stable model semantics coincide (i.e.
SM(P) = MM(P)).
2.2 Extended Abductive Programs
Given atom p(t), literal either p(t) strong negation p(t). extended
program program atoms replaced literals. semantics extended
disjunctive programs also given terms stable models considering p p
different predicate symbols considering implicit constraint p(X), p(X) (Gelfond
& Lifschitz, 1991).
Abductive logic programming extension logic programming perform abductive
reasoning (Kakas, Kowalski, & Toni, 1992; Inoue & Sakama, 1998). abductive program
(ALP) pair hP, Ai, P extended program set literals called
abducibles. hP, Ai represented means extended program = P {g(t)
g 0 (t) | g(t) A} {g 0 (t) g(t) | g(t) A}.
Let ALP G ground atom denoting observation. Then, set
explanation G iff stable model = G ; stable
model A-minimal stable model N N A. Moreover,
minimal explanation (i.e. explanation 0 S) G iff { G}
consistent A-minimal stable model = (Inoue & Sakama, 1998).
shown given ALP P ground atom G denoting observation,
deciding whether exists A-minimal explanation G p3 -complete (Eiter,
Gottlob, & Leone, 1997a).
rest section briefly review two main approaches prioritizing reasoning refer to, i.e. Prioritized Logic Programs Answer Set Optimization, proposed,
respectively, Sakama Inoue (2000) Brewka et al. (2003).
2.3 Prioritized Logic Programs
(partial) preference relation among atoms defined follows: given two atoms e1
e2 , statement e1 e2 (called priority) means e1 higher priority e2 .
Moreover, e1 e2 e2 e3 , e1 e3 . priority statement e1 e2 states
a1 instance e1 a2 instance e2 preference relation a1 a2 holds.
prioritized logic program (PLP) pair hP, P disjunctive program
set priorities. denotes set priorities reflexively transitively
derived .
statement e1 e2 stands e1 e2 e2 6 e1 . Clearly, e1 e2 , sets
ground instantiations e1 e2 empty intersection.
Definition 1 Given prioritized logic program hP, i, relation w defined
stable models P follows. stable models M1 , M2 M3 P:
505

fiGreco, Trubitsyna, & Zumpano

1. M1 w M1 ,
2. M1 w M2 e1 M1 M2 , e2 M2 M1 (e1 e2 ) 6 e3
M2 M1 (e3 e1 ) ,
3. M1 w M2 M2 w M3 , M1 w M3 .
M1 w M2 M1 preferable M2 . Moreover, M1 w M2 M2 6w M1
M1 = M2 .
2
interpretation preferred stable model hP, stable model P
N w implies w N stable model N (equivalently, interpretation N
stable model P N = ). set preferred stable models hP,
denoted PSM(hP, i). Note relation 1 2 two PLPs hP, 1
hP, 2 imply PSM(hP, 2 i) PSM(hP, 1 i).
PLP priority relations used express priorities atoms, whereas priorities
general forms knowledge (conjunctive, disjunctive knowledge, rules, preconditions)
expressed simple rewriting preference program. instance, preference
rule precondition form (e1 e2 ) B expressed PLP e01 e02 ,
e01 e1 , B e02 e2 , B.
semantics prioritized programs proposed Sakama Inoue (2000)
denoted PSM semantics. sound complete procedure allows preferred answer
sets PLP program computed using generate test algorithm
proposed Wakaki et al. (2003). algorithm translates PLP program hP,
answer set program P single logic program [P, , S],
answer sets answer sets P preferable S. details found works
presenting semantics implementation (Sakama & Inoue, 2000; Wakaki et al.,
2004).
complexity answering queries PLP programs least one level
complexity answering queries standard programs (without preferences).
particular, let hP, prioritized logic program, i) deciding existence
preferred stable model p2 -hard; ii) deciding whether atom true (resp. all)
preferable stable model hP, p3 -hard (resp. p3 -hard). worth noting
original work (Sakama & Inoue, 2000) claimed complexity exactly one
level complexity standard programs, proof take account
transitivity property preference relation.
2.4 Answer Set Optimization
answer set optimization program, denoted ASO program, pair hP, i, P
disjunctive program, called Generating Program, Preference Program consisting
finite set rules form: a1 > > ak b1 , ..., bm , c1 , ..., cn bi cj
literals ai boolean combinations2 literals; literal either atom L
(strong) negation L. determines preference ordering answer sets described
generating program P.
2. boolean combination formula built atoms means disjunctions, conjunctions, default
negation.

506

fiOn Semantics Logic Programs Preferences

Definition 2 Let hP, ASO program = {%1 , ..., %n } answer
set P, induces satisfaction vector VS = (vS (%1 ), ..., vS (%n )) where:
vS (%j ) = I, %j Irrelevant S, i.e. i) body %j satisfied ii)
body %j satisfied, none atoms head %j satisfied S.
vS (%j ) = min{i | |= ai %j = a1 > > ak b1 , .., bm , c1 , .., cn }, otherwise. 2
comparison models assumed equal 1 (i.e., vS (%j ) =
equivalent vS (%j ) = 1).
Definition 3 Let S1 S2 two answer sets, i) VS1 VS2 vS1 (%i ) vS2 (%i )
every [1..n]; ii) VS1 < VS2 VS1 VS2 [1..n] vS1 (%i ) < vS2 (%i ).
cases S1 w S2 S1 = S2 3 , respectively.
set literals optimal model ASO program hP, answer set
P answer set 0 P 0 = S.
2
complexity ASO programs depends class generating programs.
disjunctive programs complexity answering queries ASO programs exactly
one level complexity answering queries standard programs (without preferences), i.e. i) deciding existence preferred stable model p2 -complete; ii) deciding
whether literal true (resp. all) preferable stable model hP, p3 -complete
(resp. p3 -complete).
strategy extended introducing meta-preferences among preference
rules: ranked ASO program sequence hP, 1 , ..., n consisting generating program
P sequence pairwise disjoint preference programs . rank rule %
1 n , denoted rank(%), unique integer % . Given two answer
sets S1 S2 , S1 wrank S2 every preference rule %0 vS1 (%0 ) vS2 (%0 )
hold, rule %00 rank(%00 ) < rank(%0 ) vS1 (%00 ) < vS2 (%00 ).
Moreover, procedure deriving natural ordering preference rules introduced.
Firstly, given preference program , dependency graph G() defined. atoms
appearing form vertex set G(). directed edge vertex b
vertex G() rule % appears head r b appears
body r. graph G() acyclic, natural ranking atoms
defined recursively follows: rank(a) = 0 every atom predecessors
G(); otherwise rank(a) maximum ranks predecessors G()
incremented 1. rank preference rule % defined maximum rank
atoms head.
standard semantics ASO programs, priorities examined together,
denoted ASO semantics. alternative semantics, priorities divided
strata following natural order, denoted RASO (ranked ASO) semantics.
3. original work (Brewka et al., 2003) symbols > used instead w =.

507

fiGreco, Trubitsyna, & Zumpano

3. Preferred Answer Sets
paper syntax similar one proposed Brewka et al. (2003) used. Given
two atoms a1 a2 , statement a2 > a1 means a2 higher priority a1 .
(partial) preference relation > among atoms defined follows.
Definition 4 prioritized program pair hP, P disjunctive program
set preference rules form:
a1 > a2 > > ak b1 , ..., bm , c1 , ..., cn
k > 1 a1 , ..., ak , b1 , ..., bm , c1 , ..., cn atoms.

(1)
2

following head body preference rule % denoted head(%)
body(%), respectively. ground prioritized program, denoted ground(hP, i) =
hground(P), ground()i prioritized program, rule r (P ) variables
replaced set ground instances, i.e set rules obtained replacing
variables constants.
Intuitively, preference rule % form (1) describes choice among a1 , ..., ak
(choice options) condition specified body %. head % introduces
preference order among atoms: ai preferred aj 1 < j k. %
applied body(%) true, body % specifies decisions precede
choice. instance, > c b states b true, preferred c.
preference rule exactly two atoms head called binary preference rule,
whereas preference rules empty bodies called preference facts. prioritized
program said binary form preference rules binary.
following example, presenting classical program proposed Brewka et al. (2003),
used running example.
Example 3 Consider prioritized program hP 3 , 3 whose stable models define
menus restaurant:
P 3:

fish beef
red white beer
pie ice-cream
beef, pie
fish, ice-cream

3 :

%1
%2
%3
%4

:
:
:
:

white > red > beer fish
red > white beef
beer > white beef
pie > ice-cream beer

first three rules P 3 select main dish, drink dessert; constraints
state feasible solution cannot contain beef pie fish ice-cream;
rules 3 introduce preferences among drinks desserts.
program P 3 six stable models:
M1 = {fish, white, pie}
M2 = {fish, red, pie}
M3 = {fish, beer, pie}

M4 = {beef, white, ice-cream}
M5 = {beef, red, ice-cream}
M6 = {beef, beer, ice-cream}

techniques proposed Sakama Inoue (2000) Brewka et al. (2003) select
stable models M1 M5 preferred ones, motivation different. Indeed,
PSM semantics states M1 w M2 w M3 w M6 w M4 M5 w M4 , whereas
508

fiOn Semantics Logic Programs Preferences

(R)ASO semantics states Mi w M2 w M3 , Mi w M6 Mi w M4 {1, 5}, i.e.
(R)ASO semantics models M1 M6 compared directly, whereas PSM
semantics models M1 M6 compared transitively.
2
presenting formal semantics programs, preliminary definitions
needed. preference rule form a1 > a2 > > ak body shorthand k 1
binary rules form ai > ai+1 body, [1..k 1] set preferences
established given transitive closure defined follows:
Definition 5 Given prioritized program hP, i, (ground) transitive closure
= 0 {a > c body1 , body2 | > b body1 b > c body2 6= c},
0 set binary preference rules derived ground().
2
Thus, defined set rules explicitly representing preference relations
among choice options. Section 4 show ground prioritized program
= hP, rewritten equivalent program = hP, contains
number rules polynomial size .
structure prioritized programs examined order establish precedence relation among choices made. instance, presence preference rule
> c b suggests selection b precedes choice c thus
establishes precedence relation {b} {a, c}. idea used Brewka
et al. (2003) determining natural ordering among preference rules. detail,
relational order among atoms appearing captured means corresponding dependency graph G(); stratification preference rules established
considering head atoms.
Unfortunately, natural ordering among preference rules established
corresponding dependency graph acyclic. Thus, presence two rules coffee >
tea pie pie > ice-cream coffee admit stratification ,
introduce two mutually dependent choices.
stratification algorithm proposed paper overcomes problem introducing concept collapsed graph, maps node options mutually
dependent choices.
Given (ground) prioritized program = hP, i, G = (V, E) denotes dependency
graph whose set nodes consists atoms P whereas arc b
labeled (resp. p) rule (resp. P) containing head b
body (resp. b either head body). body (preference) facts empty,
assume bodies contain built-in atom true, every fact
C
considered rule true. G denotes (acyclic) collapsed dependency graph derived
G replacing maximal sets mutual dependent nodes (i.e. nodes belonging
C
cycle) unique node. Clearly, node G associated set nodes
G .
C

node G possible assign level follows:
C

node G input degree zero, level(A) = 0;
509

fiGreco, Trubitsyna, & Zumpano

C

node G input degree greater zero,
C
C
level(A) = max{max{level(B)+1|(B, Z, ) G }, max{level(B)|(B, Z, p) G }}.
Observe function level assigns node maximum distance
node input degree zero. following definition introduces concept stratification
preference rules.
Definition 6 Stratification. Given (ground) prioritized program = hP, i,
partitioned h [0], [1], ..., [n]i subprograms (called strata)
C

atom , level(a) = level(A), node G associated a;
rule % , level(%) = max{ level(a) | Body(%) };
[i] = { % | % level(%) = } consists ground preference rules associated
level i.
2
partition h [0], [1], ..., [n]i called stratification.
definition stratification preference rules establishes order
preferences applied considering P . Moreover, assignment level
rule differs one proposed Brewka et al. (2003) two main aspects:
level atoms defined analyzing collapsed dependency graph level
rules established considering body atoms instead head atoms. detailed
comparison two approaches presented Section 5.
Example 4 Consider prioritized program hP 3 , 3 Example 3. transitive closure
3 consists binary preference rules %1,1 : white > red fish, %1,2 : red > beer
fish %1,3 : white > beer fish, derived %1 , rules %2 , %3 %4 . 3
stratified two strata 3 [1] = {%1,1 , %1,2 , %1,3 , %2 , %3 } 3 [2] = {%4 }.
2
structural analysis performed approach goes beyond stratification process
tries understand comparability models. end concepts conflicting
preferences comparable models introduced.
Two ground (binary) preferences form > b body1 b > body2
said conflicting. instance, preferences %1 : white > red fish
%2 : red > white beef Example 1 conflicting, whereas preferences %1
%02 : red > water beef not. set preferences said conflicting
contains two conflicting preference rules.
intuition basis approach clarified example. Suppose
two conflicting preferences %1 : > b c %2 : b > d. two conflicting
preferences %1 %2 specify preference b two different sets models,
b, characterized presence c d, respectively. Thus, c d, (and
atoms c depend) define alternative decisions. decision
made, associated solutions (models) longer comparable.
preference rule % said relevant stable model , % used
compare stable models, |= body() head
510

fiOn Semantics Logic Programs Preferences

atoms belongs . Given prioritized program hP, (ground) preference rule
% : > b body , set stable models, % relevant, SM(P, %) =
{M | SM(P) |= body (a b)}.
Definition 7 Comparable models. Let hP, prioritized program, M1 M2 two
stable models P h [0], ..., [n]i stratification ,
1. M1 M2 comparable [0];
2. M1 M2 comparable [i + 1] [1..n],
(a) comparable [i],
(b) exist two conflicting preference rules %1 , %2 [i]
M1 SM(P, 1 ) SM(P, 2 ) M2 SM(P, 2 ) SM(P, 1 ).
2
Observe that, second condition previous definition comparable models
states presence two conflicting preference rules given level identifies two
sets models, one two conflicting rules relevant. Two models,
appearing different sets considered separately next levels.
words, two stable models M1 M2 , relevant preferences conflicting rules
%1 : > b body1 %2 : b > body2 given level i, comparable levels
greater i, M1 SM(P, 1 ) SM(P, 2 ) M2 SM(P, 2 ) SM(P, 1 ),
M1 |= body1 (a b) body2 M2 |= body2 (a b) body1 .
Example 5 Consider stable models M3 = {fish, beer, pie}, M6 = {beef, beer,
ice-cream}, set preference rules 3 Example 4. stable models M3
M6 comparable 3 [0] definition, comparable 3 [1],
%1,3 relevant M3 (as M3 |= fish (white beer) beef), %3
relevant M6 (as M6 |= beef (white beer) fish), conflicting
preferences belong 3 [0].
2
Fact 1 Let hP, prioritized program without conflicting preferences h [0],
[1], ..., [n]i stratification . Then, two models M1 M2 comparable
[i], [0..n].
2
Proof. proof fact follows directly Definition 7.

2

basis Definition 7 declarative semantics prioritized logic programs
provided. new semantics, denoted PAS (Preferred Answer Sets), given
preferred stable models follows:
Definition 8 Preference Answer Sets. Given prioritized program hP, i,
relation w defined stable models P follows. pair stable models
M1 M2 P, h [0], [1], ..., [n]i stratification , M1 w M2
1. %1 : (e1 > e2 ) body1 [i] e1 M1 M2 , e2 M2 M1 ,
M1 M2 comparable [i], %1 relevant M1 M2 ,
511

fiGreco, Trubitsyna, & Zumpano

2. 6 %2 : (e3 > e4 ) body2 [j], j < i, e3 M2 M1 , e4 M1 M2
%2 relevant M1 M2 .
Moreover, M1 strictly preferable M2 (M1 = M2 ) M1 w M2 M2 6w M1 .

2

Note also relation = could defined directly replacing condition j <
j Item 2 definition.
Definition 9 Preferred Answer Sets. interpretation preferred stable model
prioritized program hP, stable model P exist stable
model N N = . set preferred stable models hP, denoted
PAS(hP, i).
2
Note Definition 8 introduces preferences pairs models also considering
additional information gained structure preference rules.
Example 6 Consider prioritized program hP3 , 3 Example 3 stratification
h3 [0], 3 [1]i presented Example 4.
models comparable [0] definition
owing %1,1 , %1,2 , %1,3 , M1 = M2 = M3 ;
owing %2 , %3 , M5 = M4 M6 = M4 ;
%1,3 %3 conflicting, models M1 M3 , %1,3 relevant, cannot
compared [1] models M4 M6 , %3 relevant.
Therefore, discussed Example 5, M3 M6 comparable 3 [1] and,
consequently, preferred models are: M1 , M5 M6 .
2
previous example stable model M6 considered good M5
beef main dish, best choice drink (red wine beer, respectively)
dessert (ice-cream). Observe ASO PSM semantics discard M6 .
already stated, ASO semantics deduces M1 M5 preferable M6 owing
%3 , PSM semantics states M1 preferable M3 M3 preferable
M6 , owing %1 , %3 .
b 3i
Example 7 Let hP 3 , 3 program Example 3, consider program hP 3 ,
b 3 derived 3 replacing %4


%04 : pie > ice-cream
b [0] = {%1,1 , %1,2 , %1,3 , %2 , %3 , %0 },
new ground preference program unique level
3
4
%1,1 , %1,2 %1,3 derived %1 , shown Example 4. Due %04 , following relations also hold: Mi = Mj {1, 2, 3} j {4, 5, 6}. Therefore, M1
unique preferred model. result obtained PSM ASO semantics. 2
512

fiOn Semantics Logic Programs Preferences

4. Complexity
section provides results concerning computational complexity computing
preferred stable models answering queries PAS semantics. consider data
complexity input domain consists Herbrand universe (we assume
constants occurring also occur P). Clearly, size Herbrand base BP
well sizes ground(P) ground() polynomial size .
following results demonstrate allowing preferences among atoms semantics proposed increases complexity expressivity language one level
polynomial hierarchy. Thus use additional information increase
computational complexity proposed approach respect mentioned
techniques (Brewka et al., 2003; Sakama & Inoue, 2000).
Proposition 1 Let = hP, prioritized program, exists program =
hP, equivalent hground(P), i) stratification computed
polynomial time, ii) hP, derived hground(P), polynomial time.
Proof. start considering program 0 = hground(P), 0 i, 0 binary
C
ground version . size graphs G0 G0 polynomial size 0
C
computed polynomial time. assignment levels nodes G0
done polynomial time, assignment levels atoms rules 0 also
done polynomial time.
Let h0 [0], ..., 0 [n]i stratification 0 . generate new ground prioritized
program hP, equivalent hground(P), size polynomial size 0 .
Initially, assign ground atom ai appearing head preference rule 0
unique index i. Let a1 , ..., ap (indexed) atoms appearing head rules 0 ,
P denotes program ground(P) P
P = {b(i, j, l) bodyi,j | ai > aj bodyi,j 0 [l] }
{b(i, j, l) b(i, k, l1), b(k, j, l2), l = max(l1, l2) | i, j, k [1..p], l1 , l2 [1..n]}
b new predicate symbol. Then, denotes new set ground preference rules
defined follows:
= {ai > aj b(i, j, l) | i, j [1..p] l [0..n] }
stratification obtained associating stratum l preference rules
whose body atom value level attribute equal l, [l] = {ai > aj
b(i, j, l) | ai > aj b(i, j, l) }.
order show equivalence hground(P), hP, i, observe
set stable models ground(P) P equivalent, i.e. SM(P)
stable model N SM(ground(P)) N = {b(i, j, l) | b(i, j, l) }
N SM(ground(P)) stable model SM(P) N =
{b(i, j, l) | b(i, j, l) }, rules ground(P) contain atoms form
b(i, j, l) bodies.
513

fiGreco, Trubitsyna, & Zumpano

Moreover, let N stable model ground(P) corresponding stable
model P (N ), ground preference rule ai > aj bodyi,j [l] whose
body true N , ground rule ai > aj b(i, j, l) [l] whose body also true
vice versa. Therefore two sets [l] [l] equivalent, l [1..n].
Clearly, program hP, derived hground(P), polynomial time.
2
following, sake simplicity presentation, continue refer
program hP, stratification .
Proposition 2 Let hP, prioritized program, M1 M2 two stable models P,
h [0], [1], ..., [n]i stratification . problem checking whether,
given k n, M1 M2 comparable [0], ..., [k] solved polynomial time.
Proof. Obviously M1 M2 comparable [0]. Assuming M1 M2
comparable given level j < k, M1 M2 comparable level j + 1
two conflicting preference rules 1 = > b body1 2 = b > body2 [j]
M1 |= body1 (a b) body2 M2 |= body2 (a b) body1 . check
done polynomial time number rules [j] polynomial size
. Moreover, maximum value k bounded size (which bounded
set atoms BP ), global complexity also polynomial.
2
Corollary 1 Let hP, prioritized program, M1 M2 two interpretations P.
problem checking whether M1 = M2 solved polynomial time.
Proof. Straightforward Definition 8 Proposition 2.

2

Lemma 1 Let hP, prioritized program interpretation P. problem
deciding whether preferred stable model hP, p2 .
Proof. Consider complementary problem deciding whether preferred
stable model hP, i. case sufficient first check stable model.
stable model sufficient guess interpretation N check i) N
stable model P ii) N = . check part i) (as well check
stable model) done means N P oracle problem deciding
whether interpretation stable model disjunctive program coN P-complete,
whereas check part ii) done polynomial time (see Corollary 1). Therefore,
complexity complementary problem N P N P and, consequently, complexity
original problem coN P N P .
2
Theorem 1 Let hP, prioritized program.
1. Deciding whether ground atom G true preferred stable models hP,
p3 -complete;
2. Deciding whether ground atom G true preferred stable models hP,
p3 -complete.
514

fiOn Semantics Logic Programs Preferences

Proof. Membership: first demonstrate deciding whether G true
preferred stable model hP, p3 . result suffices prove complementary problem, consisting deciding whether true preferred stable models,
p3 -complete.
show membership sufficient guess interpretation containing G
check whether preferred stable model. Lemma 1 problem deciding
whether preferred stable model p2 solved means p2
oracle.
Therefore, deciding whether exists preferred stable model containing G
p2
N P = p3 .
Hardness: Given abductive logic program consisting disjunctive program P
set abducibles (positive) atoms A, ground abductive logic program derived prom P

= ground(P) { g 0 (t) g(t) | g(t) ground(A) }
{ g 0 (t) g(t) | g(t) ground(A) }
Let
= { g 0 (t) > g(t) | g(t) ground(A) }
h, denotes prioritized program derived P A.
two stable models M, N SM(), w N respect means
preference p0 (u) > p(u) p0 (u) p(u) N exists
preference q 0 (v) > q(v) q 0 (v) N q(v) exists. implies
ground(A) N ground(A) and, consequently, preferred stable models
A-minimal.
Therefore, problem deciding whether h, A-minimal explanation
goal G equivalent deciding whether h, preferred stable model containing G.
Consequently, problem deciding whether A-minimal explanation G exists
p3 -complete, problem deciding whether preferred stable model h,
containing G exits also p3 -hard, whereas problem deciding whether preferred
2
stable models hP, contain G p3 -hard.
Corollary 2 Let hP, disjunction-free, prioritized program. deciding
whether ground atom true (all) preferred stable models hP, p2 -complete
(p2 -complete).
Proof. complexity one level lower problem deciding whether interpretation stable model disjunction-free program polynomial.
2

5. Analysis Comparison
section compares semantics introduced PSM (R)ASO semantics
briefly discusses recently proposed semantics.
PSM semantics elegant compares pairs models basis
common preferences basis degree satisfaction. consider natural ordering preference rules and, cases, Example 1
3, compares (and consequently discards) models PAS approach
515

fiGreco, Trubitsyna, & Zumpano

comparable. interesting feature PSM technique application transitive
property order derive additional preference relations among problem solutions
new, immediately visible, preference relations captured. However, test
transitive property cannot performed direct comparison two models, lies
complex implementation.
(R)ASO technique powerful tool determines preferred models
evaluating degree satisfaction preference rules. Thus, compares two
models even absence common preferences; preference relation
two models established directly. detail, RASO technique considers
structure preference rules associating degree satisfaction choice options
introduces natural ordering among preferences. case PSM semantics,
(R)ASO semantics also compares and, consequently, discards models
comparable using PAS technique. instance, program hP1 , 1 i, presented
Introduction, RASO discards M1 , second best option drink, even
unique possible choice presence fish.
specifically, preference relation w used PSM approach preorder
relation reflexive transitive; determines equivalent answer set classes
establishes partial preference order among mentioned classes. Consequently
preferred answer sets appearing preferred classes. noted
PSM semantics requires use transitive property order derive,
basis relations obtained direct comparison pairs models, new preference
relations. contrary, (R)ASO semantics uses strict preference relation
asymmetric require application transitive property
compare solutions.
PAS semantics, proposed here, compares two solutions basis common preferences introducing concept comparable models considering
refinement natural order among preference choices. Thus, seen extension PSM semantics also uses additional information derived structure
preference rules, instead comparing models transitively, compares models
considering transitive closure (ground) preference rules.
novelty PAS semantics consideration structural information preference rules. introduces concept comparable models order avoid comparing
models (in opinion) compared associated alternative decisions. Moreover, proposes refinement natural order among preferences
order define order choices. RASO semantics establishes relational order among
atoms appearing means corresponding dependency graph G() cannot
treat case mutually dependent choices. stratification algorithm, proposed
C
paper, overcomes problem considering collapsed graph G , acyclic
construction sensitive syntactic changes. Moreover, RASO semantics
stratification preference rules established considering head atoms; whereas
PAS semantics levels assigned rules basis body atoms, following
intuition describe contexts choices. Thus, stratification proposed
always assigns preference facts first level level rule fixed looking
level body atoms.
advantages adopted approach clarified following example.
516

fiOn Semantics Logic Programs Preferences

Example 8 problem defined means prioritized program hP8 , 8 consists
selecting colors trousers shirt, black blue trousers (r1 )
white, yellow red shirts (r2 ) available. fashion consultant suggests blue
trousers better black ones (%1 ); white shirt better yellow shirt (%2 );
case black trousers white shirt preferred red one (%3 ). Moreover,
blue trousers go white shirt (c1 ) red shirt go blue
trousers (c2 ).
P8 :

r1
r2
c1
c2

:
:
:
:

black blue
white yellow red
blue, white
red, blue

8 :

%1 : blue > black
%2 : white > yellow
%3 : white > red black

program P8 four stable models: M1 = {black, white}, M2 = {black, yellow},
M3 = {blue, yellow} M4 = {black, red}. order define stratification
preference rules, RASO PAS semantics firstly assign level atoms: first level
blue, black yellow second level white red. second step
RASO approach, considering maximum level head atoms, assigns %1 first
level %2 %3 second level, whereas PAS defines level preferences
basis body atoms assigns %1 %2 first level %3 second level. Note
case order %2 relevant determining preferred models. fact,
RASO gives M3 , PAS returns M1 M3 preferred models.
2
formal comparison three semantics carried class
programs specific definition stratification significant. Moreover,
PSM semantics defined prioritized programs hP, consists
binary facts (preference rules rewritten preference facts), following
comparison carried considering programs whose preference rules consist
facts. class programs closure used PSM PAS semantics
coincide.
Given prioritized program hP, denote GSEM = (V, ESEM ) preference
graph stable models P, V = SM(P) denotes set stable models
P ESEM denotes preference relation = defined semantics SEM
{PSM, ASO, PAS}. particular, ESEM consists arcs (Mi , Mj ) Mi = Mj
holds SEM semantics. Therefore, comparison different semantics
performed analyzing corresponding preference graphs. stable model Mi preferred
SEM semantics arc (Mj , Mi ) GSEM .
following example shows relation PSM PAS semantics.
Example 9 Consider prioritized program hP 9 , 9
P 9 : fish beef pork chicken
white fish
red beef
beer pork
water chicken
517

9 : fish > beef
chicken > pork
red > white
red > water
beer > water

fiGreco, Trubitsyna, & Zumpano

program four stable models: M1 = {fish, white}, M2 = {beef, red}, M3 =
{pork, beer} M4 = {chicken, water}, whereas direct preference relations,
PSM semantics, follows: M1 w M2 , M2 w M1 , M3 w M4 , M4 w M3 M2 w M4 .
Consequently, graph GPSM consists four nodes (M1 , M2 , M3
M4 ) four arcs: M1 = M3 , M1 = M4 , M2 = M3 M2 = M4 . Therefore, preferred
models M1 M2 .
Regarding PAS semantics, relation M2 = M4 holds and, thus,
three preferred stable models, namely M1 M2 M3 .
2
Theorem 2 prioritized program hP, consists preference facts,
PSM(hP, i) PAS(hP, i).
Proof. Consider graphs GPSM = (V, EPSM ) GPAS = (V, EPAS ). graphs
acyclic EPAS EPSM . two graphs acyclic, adding edges
create cycles, number nodes without incoming edges decreases. Therefore, set
nodes without incoming edges GPAS contains nodes without incoming edges GPSM
and, consequently, PSM(hP, i) PAS(hP, i).
2
analyze relation ASO PAS semantics. First note that,
observed Introduction, ASO semantics sensitive syntax changes.
instance, prioritized program
abc

1 = > b > c
2 = b >

two preferred stable models: M1 = {a} M2 = {b}. However, program
01 = > b
001 = b > c
2 = b >

abc

derived rewriting rule 1 , M3 = {c} also preferred model.
Thus, consider special class constraints sensitive syntactic
changes. Since every (ground) prioritized program = hP, i, partitioned n strata, n > 1, rewritten program = hP, i,
equivalent PAS semantics (as shown proof Proposition
1), may equivalent RASO semantics (as rules belong
unique stratum 0), continue consider programs = hP, consists
single stratum and, particular, facts.
Given prioritized program hP, consists facts, denote
+ = {a1 > > | ai > ai+1 [1..n-1] n maximum }
set preference rules obtained merging ground preference facts.
Lemma 2 Let hP, prioritized program consists preference facts
ground() = + . Then, ASO(hP, i) PAS(hP, i).
518

fiOn Semantics Logic Programs Preferences

Proof. Consider two graphs GASO = (V, EASO ) GPAS = (V, EPAS ). (M1 , M2 )
EPAS means M1 = M2 , i.e.
i) ground rule %1 : e1 > e2 e1 M1M2 , e2 M2M1 ,
ii) ground rule %2 : e3 > e4 , e3 M2 M1 e4 M1 M2 .
implies ground() = +
i) must ground rule 1 : > e1 > > e2 > +
e1 M1 M2 , e2 M2 M1 ,
ii) must ground rule 2 : > e3 > > e4 > + ,
e3 M2 M1 e4 M1 M2 .
Therefore, M1 = M2 also respect ASO semantics, graph GASO contains arc (M1 , M2 ). Consequently, EPAS EASO , ASO(hP, + i) PAS(hP, + i). 2
find tight relation two semantics, consider restriction
+ obtained deleting atoms appear model ground
preference rules:
+

b = {a1 > > | ai > ai+1 [1..n-1] n maximum

SM(P) s.t. ai , ai+1 }

Theorem 3 Let hP, prioritized program consists preference
b + . Then, ASO(hP, i) = PAS(hP, i).
facts ground() =
b + derived +
Proof. ASO(hP, i) PAS(hP, i) derives Lemma 2,
deleting nodes appear model influence relation =
ASO semantics.
show ASO(hP, i) PAS(hP, i) consider relation ASO semantics.
M1 = M2 means
b + e1 M1 M2 ,
1. ground rule 1 : > e1 > > e2 >
e2 M2 M1 ,

2. ground rule 2 : > e3 > > e4 >
e3 M2 M1 e4 M1 M2 .

+ ,

b+
implies ground() =

1. must ground rule %1 : e1 > e2 e1 M1 M2 , e2
M2 M1 ,
2. ground rule %2 : e3 > e4 , e3 M2 M1 e4 M1 M2 .
519

fiGreco, Trubitsyna, & Zumpano

Therefore, M1 = M2 also holds respect PAS semantics. Consequently,
EASO RPAS , ASO(hP, + i) PAS(hP, + i).
2
extension ASO semantics proposed Brewka (2004) Brewka,
Niemela, Truszczynski (2005). detail, Brewka (2004) provided preference
description language, allowing express complex preferences combining qualitative
quantitative penalty based preferences, whereas Brewka et al. (2005) proposed framework specify problem solutions (outcomes) preferences among them. latter
proposal combines ideas answer-set programming, answer-set optimization CPnets (Boutilier, Brafman, Domshlak, Hoos, & Poole, 2004). semantics
proposed paper different proposed Brewka (2004) Brewka
et al. (2005), cases returns different results (see Examples 2 4).

6. Approaches
Besides approaches managing preferences among atoms, works proposed
literature specify preferences among rules.
Early proposals expressing preferences rules focus Default Logic (Brewka & Eiter,
2000; Delgrande et al., 2000b; Rintanen, 1998), whereas recently emphasis
given logic programs. regard, different proposals developed
representing reasoning user preferences ordered logic programs (Delgrande et al., 2000a; Van Nieuwenborgh & Vermeir, 2002, 2004) preferred answer sets
extended logic programs (Brewka & Eiter, 1999). approaches propose
extension Gelfond Lifschitzs extended logic programming adding preference information (Delgrande et al., 2003; Wang et al., 2000; Zhang & Foo, 1997). proposals
attempt extend well founded semantics logic programs preferences (Brewka,
1996; Schauba & Wang, 2001), extension van-Gelders alternating fixpoint theory
logic programs priorities proposed Wang et al. (2000).
Gelfond Son (1997) proposed methodology reasoning prioritized
default language logic programming answer set semantics. approach
enables specification preferences among rules allows definition set
default rules must satisfied well second set default rules could
ignored.
Ordered logic programs introduced Delgrande et al. (2000a) extended
logic programs whose rules subject strict partial order static dynamic
preferences. approach fully prescriptive enforces ordering information
construction answer set. original program transformed second
extended logic program preferences taken account sense
answer sets obtained evaluating transformed theory correspond preferred
answer sets original theory.
Another methodology logic programs containing preferences set rules
translated logic programs stable model semantics proposed
Delgrande et al. (2003).
520

fiOn Semantics Logic Programs Preferences

7. Conclusions
paper case preferences involving atoms logic programming studied.
particular, behavior technique proposed Sakama Inoue (2000)
Brewka et al. (2003) analyzed semantics, interpreting preference rule
tool representing choice alternative options, proposed. Specifically,
proposed approach extends PSM semantics considering refinement natural
order among preferences introduces concept comparable models. Preferences
logic programs examined together order determine choice order sets
models compared.
new semantics compared PSM ASO semantics. Complexity analysis also performed showing use additional information,
regarding preference order sets non comparable models, increase
complexity computing preferred stable models. Although semantics presented
complexity approaches proposed literature, advantage lies
fact seems better capture intuitive meaning prioritized programs
also considering structural information preference rules.
Prioritized reasoning logic programming PAS semantics easily
implemented top deductive systems based stable model semantics
DeRes, DLV, Smodels (Cholewinski, Marek, & Truszczynski, 1996; Leone, Pfeifer, Faber,
Calimeri, & DellArmi, 2002; Syrjanen & Niemela, 2001). architecture system
prototype implementing prioritized reasoning (with different semantics) top
DLV system presented Caroprese, Trubitsyna, Zumpano (2007).

Acknowledgments
preliminary version papers presented Greco, Trubitsyna, Zumpano
(2006). authors would like thank anonymous referees useful suggestions
Filippo Furfaro comments.

References
Boutilier, C., Brafman, R., Domshlak, C., Hoos, H., Poole, D. (2004). CP-nets: tool
representing reasoning conditional ceteris paribus preference statements.
Journal Artificial Intelligence Research, 21, 135-191.
Brewka, G. (1996). Well-Founded Semantics Extended Logic Programs Dynamic
Preferences. Journal Artificial Intelligence Research, 4, 19-36.
Brewka, G., Eiter, T. (1999). Preferred Answer Sets Extended Logic Programs. Artificial
Intelligence, 109(1-2), 297-356.
Brewka, G., Eiter, T. (2000). Prioritizing Default Logic. Intellectics Computational
Logic, Kluwer, 27-45.
Brewka, G. (2002). Logic programming ordered disjunction. Proceedings 18th National
Conference Artificial Intelligence (AAAI/IAAI), 100-105.
521

fiGreco, Trubitsyna, & Zumpano

Brewka, G., Niemela, I., Truszczynski, M. (2003). Answer Set Optimization. Proceedings
18th International Joint Conference Artificial Intelligence (IJCAI), 867-872.
Brewka, G. (2004). Complex Preferences Answer Set Optimization, Proceedings 9th
International Conference Principles Knowledge Representation Reasoning
(KR), 213-223.
Brewka, G., Niemela, I., Truszczynski, M. (2005). Prioritized Component Systems. Proceedings 20th National Conference Artificial Intelligence (AAAI), 596-601.
Caroprese, L., Trubitsyna, I., Zumpano, E. (2007). Implementing Prioritized Reasoning
Logic Programming. Proceedings International Conference Enterprice Information
Systems (ICEIS), 94-100.
Cholewinski, P., Marek, V. W., Truszczynski, M. (1996). Default Reasoning System DeReS.
Proceedings 5th International Conference Principles Knowledge Representation
Reasoning (KR), 518-528.
Delgrande, J., P., Schaub, T., Tompits, H. (2000). Logic Programs Compiled Preferences. Proceedings 14th European Conference Artificial Intelligence (ECAI), 464-468.
Delgrande, J., P., Schaub, T., Tompits, H. (2000). Compilation Brewka Eiters
Approach Prioritization. Proceedings European Workshop Logics Artificial
Intelligence (JELIA), 376-390.
Delgrande, J., P., Schaub, T., Tompits, H. (2003). Framework Compiling Preferences
Logic Programs. Theory Practice Logic Programming, 3(2), 129-187.
Eiter, T., Gottlob, G., Leone, N. (1997). Abduction Logic Programs: Semantics
Complexity. Theoretical Computer Science 189(1-2), 129177.
Eiter, T., Gottlob, G., Mannila, H. (1997). Disjunctive Datalog. ACM Transaction
Database Systems, 22(3), 364418, 1997.
Gelfond, M., Lifschitz, V. (1988). Stable Model Semantics Logic Programming,
Proceedings International Conference Logic Programming (ICLP), 10701080.
Gelfond, M., Lifschitz, V. (1991). Classical Negation Logic Programs Disjunctive
Databases, New Generation Computing, 9, 365385.
Gelfond, M., Son, T.C. (1997). Reasoning prioritized defaults. Proc. 3rd International
Workshop Logic Programming Knowledge Representation (LPKR), 164-223.
Greco, S., Trubitsyna, I., Zumpano, E. (2006). Semantics Logic Programs
Preferences. Proceedings 10th European Conference Logics Artificial Intelligence
(JELIA), 203-215.
Grell, S., Konczak, K., Schaub, T. (2005). nomore<: System Computing Preferred
Answer Sets. Proceedings 8th International. Conference Logic Programming
Nonmonotonic Reasoning (LPNMR), 394-398.
Janhunen, T., Niemela, I., Simons, P., You, J.-H. (2000). Unfolding partiality disjunctions stable model semantics, Proceedings 7th International Conference Principles Knowledge Representation Reasoning (KR), 411-419.
522

fiOn Semantics Logic Programs Preferences

Inoue, K., Sakama, S. (1998). Negation Failure Head. Journal Logic Programming, 35(1), 39-78.
Kakas, A. C., Kowalski, R. A., Toni, F. (1992). Abductive Logic Programming. Journal
Logic anc Computation, 2(6), 719-770.
Leone, N., Pfeifer, G., Faber, W., Calimeri, F., DellArmi, T., Eiter, T., Gottlob, G., Ianni,
G., Ielpa, G., Koch, K., Perri, S., Polleres, A. (2002). DLV System. Proceedings
8th European Conference Logics Artificial Intelligence (JELIA), 537-540, 2002.
Minker, J. (1982). Indefinite Data Bases Closed World Assumption, Proc. 6-th
Conf. Automated Deduction, 292-308, 1982.
Papadimitriou, C. H. (1994). Computational Complexity. Addison-Wesley.
Rintanen J. (1998). Complexity Prioritized Default Logics, Journal Artificial Intelligence Research, 9, 423-461.
Sakama, C., Inoue, K. (2000). Priorized logic programming application commonsense reasoning. Artificial Intelligence, 123, 185-222.
Schaub, T., Wang , K. (2001). Comparative Study Logic Programs Preference.
Proceedings 17th International Joint Conference Artificial Intelligence (IJCAI),
597-602.
Syrjanen, T., Niemela, I. (2001). Smodels System. Proceedings International Conference Logic Programming Nonmonotonic Reasoning (LPNMR), 434-438.
Van Nieuwenborgh, D., Vermeir, D. (2002). Preferred Answer Sets Ordered Logic
Programs. Proceedings 10th European Conference Logics Artificial Intelligence
(JELIA), 432-443.
Van Nieuwenborgh, D., Vermeir, D. (2002). Ordered Diagnosis, Proceedings 10th International Conference Logic Programming, Artificial Intelligence, Reasoning
(LPAR), 244-258.
Van Nieuwenborgh, D., Heymans, S., Vermeir, D. (2004). Programs Linearly Ordered Multiple Preferences. Proceedings International Conference Logic Programming (ICLP), 180-194.
Wakaki, T., Inoue, K., Sakama, C., Nitta, K. (2003). Computing Preferred Answer Sets
Answer Set Programming. Proceedings 10th International Conference Logic
Programming, Artificial Intelligence, Reasoning (LPAR), 259-273.
Wakaki, T., Inoue, K., Sakama, C., Nitta, K. (2004). PLP System. Proceedings 9th
European Conference Logics Artificial Intelligence (JELIA), 706-709.
Wang, K., Zhou, L., Lin, F. (2000). Alternating Fixpoint Theory Logic Programs
Priority. Proceedings First International Conference Computational Logic, 164-178.
Zhang, Y., Foo, N. (1997). Answer sets prioritized logic programs. Proceedings International Logic Programming Symposium (ILPS), 69-83.

523

fiJournal Artificial Intelligence Research 30 (2007) 1-50

Submitted 11/06; published 9/07

Learning Semantic Definitions Online Information Sources
Mark James Carman
Craig A. Knoblock

mark@bradipo.net
knoblock@isi.edu

University Southern California
Information Sciences Institute
4676 Admiralty Way
Marina del Rey, CA 90292

Abstract
Internet contains large number information sources providing many types
data weather forecasts travel deals financial information. sources
accessed via Web-forms, Web Services, RSS feeds on. order make automated
use sources, need model semantically, writing semantic descriptions
Web Services tedious error prone. paper investigate problem
automatically generating models. introduce framework learning Datalog
definitions Web sources. order learn definitions, system actively invokes
sources compares data produce known sources information.
performs inductive logic search space plausible source definitions
order learn best possible semantic model new source. paper
perform empirical evaluation system using real-world Web sources. evaluation
demonstrates effectiveness approach, showing automatically learn
complex models real sources reasonable time. also compare system
complex schema matching system, showing approach handle kinds
problems tackled latter.

1. Introduction
Recent years seen explosion quantity variety information available
online. One find shopping data (prices availability goods), geospatial data
(weather forecasts, housing information), travel data (flight pricing status), financial
data (exchange rates stock quotes), scratches surface
available. aim work make use vast store information.
amount information increased, reuse across Web portals
applications. Developers realised importance managing content separately
presentation, leading development XML self-describing data format.
Content XML far easier manipulate HTML, simplifying integration across
different sources. Standards also emerged providing programmatic access data
(like SOAP REST) developers easily build programs (called Mash-Ups)
combine content different sites real-time. Many portals provide access
data even provide syntactic definitions (in WSDL) input output
data sources expect. Missing, however, semantic descriptions source
does, required order support automated data integration.
c
2007
AI Access Foundation. rights reserved.

fiCarman & Knoblock

1.1 Structured Querying
Given structured sources available, would like combine data dynamically
answer specific user requests (as opposed statically case Mash-Ups). Dynamic
data requests expressed queries shown below. queries may
require access multiple (publicly available) data sources combine information ways
envisaged producers.
1. Tourism: Get prices availability three star hotels within 100 kilometers
Trento, Italy lie within 1 kilometer ski resort 1 meter snow.
2. Transportation: Determine time need leave work order catch bus
airport pick brother arriving Qantas flight 205.
3. Disaster Prevention: Find phone numbers people living within 1 mile
coast 200 feet elevation.
clear even small set examples powerful ability combine
data disparate sources be. order give queries automated system,
must first express formally query language SQL Datalog (Ullman,
1989). Datalog first query might look follows:
q(hotel, price) :accommodation(hotel, 3*, address), available(hotel, today, price),
distance(address, hTrento,Italyi, dist1), dist1 < 100km,
skiResort(resort, loc1), distance(address, loc1, dist2),
dist2 < 1km, snowCondiditions(resort, today, height), height > 1m.
expression states hotel price pairs generated looking three star hotels
relational table called accommodation, checking price tomorrow night
table called available. address hotel used calculate distance Trento,
must less 100 kilometers. query also checks skiResort
within 1 kilometer hotel, snowConditions today show 1
meter snow.
1.2 Mediators
system capable generating plan answer query called Information
Mediator (Wiederhold, 1992). order generate plan, mediators look sources
relevant query. case, relevant sources might be:
1. Italian Tourism Website: find hotels near Trento, Italy.
2. Ski Search Engine: find ski resorts near hotel.
3. Weather Provider: find much snow fallen ski resort.
mediator know sources relevant, needs know information
source provides. XML defines syntax (formatting) used source, semantics
(intended meaning) information source provides must defined separately.
done using Local-as-View (LAV) source definitions Datalog (Levy, 2000).
Essentially, source definitions describe queries given mediator, return
data source provides. Example definitions shown below. first states
2

fiLearning Semantic Definitions Information Sources Internet

source hotelSearch takes four values input (inputs prefixed $-symbol),
returns list hotels lie within given distance input location.
hotel also returns address well price room given date.
(Note source provides information hotels Italy.)
hotelSearch($location, $distance, $rating, $date, hotel, address, price) :country(location, Italy), accommodation(hotel, rating, address),
available(hotel, date, price), distance(address, location, dist1),
dist1 < distance.
findSkiResorts($address, $distance, resort, location) :skiResort(resort, location), distance(address, location, dist1),
dist1 < distance.
getSkiConditions($resort, $date, height) :snowCondiditions(resort, date, height).
order generate plan answering query, mediator performs process called
query reformulation (Levy, 2000), whereby transforms query new query
(in terms of) relevant information sources.1 (A source relevant refers
relations query.) resulting plan case shown below.
q(hotel, price) :hotelSearch(hTrento,Italyi, 100km, 3*, today, hotel, address, price),
findSkiResorts(address, 1km, resort, location),
getSkiConditions(resort, today, height), height > 1m.
work, questions interest are: definitions information
sources come precisely, happens want add new sources
system? possible generate source definitions automatically?
1.3 Discovering New Sources
example above, mediator knows set relevant sources use successfully
answer query. instead, one sources missing doesnt desired
scope (e.g. getSkiConditions doesnt provide data Trento), mediator first needs
discover source providing information. number variety information
sources increase, undoubtedly rely automated methods discovering
annotating semantic descriptions. order discover relevant sources, system
might inspect service registry2 (such defined UDDI), perform keywordbased search Web index (such Google del.icio.us). research community
looked problem discovering relevant services, developing techniques classifying
services different domains (such weather flights) using service metadata (He &
Kushmerick, 2003) clustering similar services together improve keyword-based search
(Dong, Halevy, Madhavan, Nemes, & Zhang, 2004). techniques, although useful,
sufficient automating service integration.
1. complexity query reformulation known exponential, although efficient algorithms
performing exist (Pottinger & Halevy, 2001).
2. Note technically, service different source. service interface providing access
multiple operations, may provide information. operation affect state
world (e.g. charging somebodys credit card), call information source.
paper, however, use term service refer information sources.

3

fiCarman & Knoblock

1.4 Labeling Service Inputs Outputs
relevant service discovered, problem shifts modeling semantically. Modeling sources hand laborious, automating process makes sense. Since different
services often provide similar overlapping data, possible use knowledge
previously modeled services learn descriptions new ones.
first step modeling source determine type data requires
input produces output. done assigning semantic types (like zipcode,
telephone number, temperature, on) attributes service. Semantic types
restrict possible values attribute subset corresponding primitive type.
research community investigated automating assignment process viewing
classification problem (He & Kushmerick, 2003). system, Kushmerick
trained Support Vector Machine (SVM) metadata describing different sources.
system, given source following:
getWeather($zip, temp)
uses labels getWeather, zip temp (and available metadata) assign
types input output attributes, e.g.: zip zipcode, temp temperature. Note
additional metadata often useful distinguishing possible assignments. (If,
example, name operation listEmployees, temp may referred
temporary employee rather temperature.)
subsequent work, researchers developed comprehensive system used
metadata output data classify service attributes (Lerman, Plangprasopchok, &
Knoblock, 2006). system, Logistic Regression based classifier first assigns semantic types input parameters. Examples input types used invoke
service, output given pattern-language based classifier, assigns types
output parameters. authors argue classification based data
metadata far accurate based metadata alone. Using example,
easy see why. Consider following tuples produced getWeather source:
h90292, 25 Ci, h10274, 15 Ci, h60610, 18 Ci, ...
Given data, classifier certain temp really refers temperature,
indeed even assign specific type, temperatureC (in Celsius).
problem determining semantic types services attributes
interesting, room improvement current techniques, assume
purposes work already solved.
1.5 Generating Definition
know parameter types, invoke service, still unable
make use data returns. that, need also know output attributes
relate input (i.e. definition source). example, getWeather service
need know whether temperature returned current temperature,
predicted high temperature tomorrow average temperature time year.
relationships described following definitions:
getWeather($zip, temp) :- currentTemp(zip, temp).
getWeather($zip, temp) :- forecast(zip, tomorrow, temp).
getWeather($zip, temp) :- averageTemp(zip, today, temp).
4

fiLearning Semantic Definitions Information Sources Internet

relations used definitions would defined domain ontology (or schema).
paper describe system capable learning definitions
correct. system leverages knows domain, i.e. domain
ontology set known information sources, learn know, namely
relationship attributes newly discovered source.
1.6 Outline
paper presents comprehensive treatment methods learning semantic descriptions Web information sources. extends previous work subject (Carman &
Knoblock, 2007) presenting detailed descriptions methods enumerating
search space evaluating individual candidate definitions. provide additional
details regarding evaluation methodology results generated.
paper structured follows. start example motivate source
induction problem formulate problem concisely. discuss approach
learning definitions sources terms known sources information (section
3). give details search procedure generating candidate definitions (section 4)
evaluation procedure scoring candidates search (section 5).
describe extensions basic algorithm (section 6) discussing evaluation setup
experiments (section 7), demonstrate capabilities system. Finally,
contrast approach prior work.

2. Problem
describe detail problem learning definitions newly discovered services.
start concrete example meant learning source definition.
example four types data (semantic types), namely: zipcodes, distances, latitudes
longitudes. also three known sources information. sources
definition Datalog shown below. first service, aptly named source1, takes
zipcode returns latitude longitude coordinates centroid. second
service calculates great circle distance (the shortest distance earths surface)
two pairs coordinates, third converts distance kilometres
miles multiplying input constant 1.609.
source1($zip, lat, long) :- centroid(zip, lat, long).
source2($lat1, $long1, $lat2, $long2, dist) :greatCircleDist(lat1, long1, lat2, long2, dist).
source3($dist1, dist2) :- multiply(dist1, 1.609, dist2).
goal example learn definition newly discovered service, called source4.
service takes two zipcodes input returns distance value output:
source4($zip1, $zip2, dist)
system describe uses type signature (input output type information)
search appropriate definition source. definition discovered case
might following conjunction calls individual sources:
source4($zip1, $zip2, dist):source1($zip1, lat1, long1), source1($zip2, lat2, long2),
source2($lat1, $long1, $lat2, $long2, dist2), source3($dist2, dist).
5

fiCarman & Knoblock

definition states sources output distance calculated input zipcodes,
giving zipcodes source1, taking resulting coordinates calculating
distance using source2, converting distance miles using
source3. test whether definition correct, system must invoke new
source definition see values generated agree other. following
table shows test:
$zip1
80210
60601
10005

$zip2
90266
15201
35555

dist (actual)
842.37
410.31
899.50

dist (predicted)
843.65
410.83
899.21

table, input zipcodes selected randomly set examples,
output source definition shown side side. Since output
values quite similar, system seen sufficient number examples,
confident found correct semantic definition source.
definition given terms source relations, could also
written terms domain relations (the relations used define sources 1 3).
convert definition form, one simply needs replace source relation
definition follows:
source4($zip1, $zip2, dist):centroid(zip1, lat1, long1), centroid(zip2, lat2, long2),
greatCircleDist(lat1, long1, lat2, long2, dist2), multiply(dist1, 1.609, dist2).
Written way, new semantic definition makes sense intuitive level: source
simply calculating distance miles centroids two zipcodes.
2.1 Problem Formulation
given example Source Definition Induction Problem, describe
problem formally, so, introduce concepts notation. (We
note focus paper learning definitions information-providing,
opposed world-altering services.)
domain semantic data-type t, denoted D[t], (possibly infinite) set
constant values {c1 , c2 , ...}, constitute set values variables
type. example D[zipcode] = {90210, 90292, ...}
attribute pair hlabel, semantic data-typei, e.g. hzip1, zipcodei. type
attribute denoted type(a) corresponding domain D[type(a)] abbreviated
D[a].
scheme ordered (finite) set attributes ha1 , ..., unique labels,
n referred arity scheme. example scheme might hzip1 :
zipcode, zip2 : zipcode, dist : distancei. domain scheme A, denoted
D[A], Cartesian product domains attributes scheme {D[a1 ]
... D[an ]}, ai A.
tuple scheme element set D[A]. tuple represented
set name-value pairs, {zip1 = 90210, zip2 = 90292, dist = 8.15}
6

fiLearning Semantic Definitions Information Sources Internet

relation named scheme, airDistance(zip1, zip2, dist). Multiple relations may share scheme.
extension relation r, denoted E[r], subset tuples D[r]. example, E[airDistance] might table containing distance zipcodes
California. (Note extension relation may contain distinct tuples.)
database instance set relations R, denoted I[R], set extensions
{E[r1 ], ..., E[rn ]}, one relation r R.
query language L formal language constructing queries set relations.
denote set queries written using language L set
relations R returning tuples conforming scheme LR,A .
result set produced execution query q LR,A database instance
I[R] denoted EI [q].
source relation s, binding pattern s, distinguishes input
attributes output attributes. (The output attributes source denoted
complement binding pattern3 , sc s\s .)
view definition source query vs written query language LR,s .
Source Definition Induction Problem defined tuple:
hT, R, L, S, V,
set semantic data-types, R set relations, L query language,
set known sources, V set view definitions (one known source),
new source (also referred target).
semantic type must provided set examples values Et D[t].
(We require entire set D[t], domain many types may partially
unknown large enumerated.) addition, predicate eqt (t, t) available
checking equality values semantic type handle case multiple
serialisations variable represent value.
relation r R referred global relation domain predicate
extension virtual, meaning extension generated inspecting every
relevant data source. set relations R may include interpreted predicates,
, whose extension defined virtual.
language L used constructing queries could query language including
SQL XQuery (the XML Query Language). paper use form Datalog.
source extension E[s] complete set tuples
produced source (at given moment time). require corresponding view
definition vs V (written LR,s ) consistent source, that: E[s] EI [vs ],
(where I[R] current virtual database instance global relations). Note
require equivalence, sources may provide incomplete data.
view definition source modeled unknown. solution
Source Definition Induction Problem view definition v LR,s source
E[s ] EI [v ], view definition v 0 LR,s better describes
(provides tighter definition for) source , i.e.:
v 0 LR,s s.t. E[s ] EI [v 0 ] |EI [v 0 ]| < |EI [v ]|
3. \-symbol denotes set difference.

7

fiCarman & Knoblock

Given limited available computation bandwidth, note may possible
guarantee optimality condition holds particular solution; thus paper
simply strive find best solution possible.
2.2 Implicit Assumptions
number assumptions implicit problem formulation. first
exists system capable discovering new sources importantly classifying (to
good accuracy) semantic types input output. Systems capable
discussed section 1.4.
second assumption representation source relational
view definition. sources Internet provide tree structured XML data. may
always obvious best flatten data set relational tuples,
preserving intended meaning data. Consider travel booking site returns
set flight options ticket number, price list flight segments
constitute itinerary. One possibility converting data set tuples would
break ticket individual flight segment tuples (thereby obscuring
relationship price number flight segments). Another would create
one long tuple ticket room number flight segments (thereby
creating tuples many null values). case, obvious which, either,
options preferred. online data sources can, however, modeled quite
naturally relational sources; first tackling relational problem, develop
techniques later applied difficult semi-structured case.
third assumption set domain relations suffices describing source
modeled. instance, consider case domain model contains relations
describing financial data, new source provides weather forecasts. Obviously,
system would unable find adequate description behavior source
would learn model it. practical perspective, limitation big
problem, since user request data (write queries mediator) using relations
domain model anyway. (Thus source cannot described using
relations would needed answer user requests.) words, onus
domain modeler model sufficient relations able describe types
queries user able pose system consequently, types sources
available. said, interesting avenue future research would
investigate problem automating (at least part) process expanding scope
domain model (by adding attributes relations, inventing new ones), based
types sources discovered.
2.3 Problem Discussion
number questions arise problem formulation, first domain
model comes from. principle, set semantic types relations could come
many places. could taken standard data models different domains,
might simplest model possible aptly describes set known sources.
domain model may evolve time sources discovered appropriate
model found. Somewhat related question specific semantic types
8

fiLearning Semantic Definitions Information Sources Internet

ought be. example, sufficient one semantic type distance
one distinguish distance meters distance feet? Generally speaking,
semantic type created attribute syntactically dissimilar
attributes. example, phone number zipcode different syntax,
thus operations accept one types input unlikely accept other.
practice, one might create new semantic type whenever trained classifier recognise
type based syntax alone. general, semantic types are,
harder job system classifying attributes, easier job system
tasked learning definition source.
Another question considered definitions known sources come
from. Initially definitions would need written hand. system learns
definitions new sources, would added set known sources, making
possible learn ever complicated definitions.
order system learn definition new source, must able invoke
source thus needs examples input types. representative set
examples available, efficient accurate learning process be. initial
set examples need provided domain modeler. Then, system learns
time, generate large number examples different semantic types (as output
various sources), retained future use.
Information Integration research reached point mediator technology4
becoming mature practical. need involve human writing source
definitions is, however, Achilles Heel systems. gains flexibility come
ability dynamically reformulate user queries often partially offset
time skill required write definitions incorporating new sources. Thus system
capable learning definitions automatically could greatly enhance viability mediator
technology. motivation alone seems sufficient pursuing problem.

3. Approach
approach take learning semantic models information sources Web
twofold. Firstly, choose model sources using powerful language conjunctive
queries. Secondly, leverage set known sources order learn definition
new one. section discuss aspects detail.
3.1 Modeling Language
source definition language L hypothesis language new definitions
need learnt. often case machine learning, faced trade-off
respect expressiveness language. hypothesis language simple,
may able model real services using it. hand, language
overly complex, space possible hypotheses large learning
feasible. language choose conjunctive queries Datalog,
4. Influential Information Integration systems include TSIMMIS (Garcia-Molina, Hammer, Ireland, Papakonstantinou, Ullman, & Widom, 1995), SIMS (Arens, Knoblock, & Shen, 1996), InfoMaster (Duschka,
1997), Ariadne (Knoblock, Minton, Ambite, Ashish, Muslea, Philpot, & Tejada, 2001).

9

fiCarman & Knoblock

highly expressive relational query language. section argue less expressive
language sufficient purposes.
Researchers interested problem assigning semantics Web Services (He &
Kushmerick, 2003) investigated problem using Machine Learning techniques
classify services (based metadata characteristics) different semantic domains,
weather flights, operations provide different classes operation,
weatherForecast flightStatus. relational perspective, consider
different classes operations relations. instance, consider definition below:
source($zip, temp) :- weatherForecast(zip, tomorrow, temp).
source provides weather data selecting tuples relation called weatherForecast,
desired zipcode date equal tomorrow. query referred
select-project query evaluation performed using relational operators
selection projection. far good, able use simple classifier learn
simple definition source. limitation imposed restricted (select-project)
modeling language becomes obvious, however, consider slightly complicated
sources. Consider source provides temperature Fahrenheit well Celsius.
order model source using select-project query, would require
weatherForecast relation extended new attribute follows:
source($zip, tempC, tempF):- weatherForecast(zip, tomorrow, tempC, tempF).
attributes could conceivably returned weather forecast operation
(such dewpoint, humidity, temperature Kelvin, latitude, etc.), longer relation
need cover all. Better, case, would introduce second
relation convertCtoF makes explicit relationship temperature values.
If, addition, source limits output zipcodes California, reasonable definition
source might be:
source($zip, tempC, tempF):weatherForecast(zip, tomorrow, tempC), convertCtoF(tempC, tempF),
state(zip, California).
definition longer expressed language select-project queries,
involves multiple relations joins across them. Thus simple example, see
modeling services using simple select-project queries sufficient purposes.
need select-project-join queries, also referred conjunctive queries.5 reader
already introduced examples conjunctive queries throughout previous
sections. Conjunctive queries form subset logical query language Datalog
described formally follows:
conjunctive query set relations R expression form:
q(X0 ) :- r1 (X1 ), r2 (X2 ), ..., rl (Xl ).
ri R relation Xi ordered set variable names size
arity(ri ).6 conjunct ri (Xi ) referred literal. set variables

query, denoted vars(q) = li=0 Xi , consists distinguished variables
X0 (from head query), existential variables vars(q)\X0 , (which
5. Evaluating select-project-join query requires additional relational operators: natural join rename.
6. Note conjunctive query also expressed first order logicSas follows:
l
X0 s.t. r1 (X1 ) r2 (X2 ) ... rl (Xl ) q(X0 ) X0 = i=1 Xi

10

fiLearning Semantic Definitions Information Sources Internet

appear body). conjunctive query said safe

distinguished variables appear body, i.e. X0 li=1 Xi .
3.2 Expressive Languages
Modeling sources using conjunctive queries implies aggregate operators like MIN
ORDER cannot used source definitions. functionality sources
described without operators. sources described poorly, however.
Consider hotel search service returns 20 closest hotels given location:
hotelSearch($loc, hotel, dist) :accommodation(hotel, loc1), distance(loc, loc1, dist).
According definition, source return hotels regardless distance. One
cannot express fact closest hotels returned. reason
including aggregate operators hypothesis language search space associated
learning definitions prohibitively large. (Thus leave aggregate operators future
work discussed section 9.2.)
Similarly, source definitions cannot contain disjunction, rules union recursive queries. Again, simplifying assumption holds information sources
greatly reduces search space. means however, weather service providing
forecasts cities US Canada would modeled as:
s($city, temp) :- forecast(city, country, tomorrow, temp).
Since definition restrict domain country attribute, confronted
request forecast Australia, mediator would proceed call service,
oblivious restriction attribute.
also allow negation queries source definitions rarely
require it, including would needlessly complicate search. rare cases
negation particular predicate useful describing certain types sources,
negated predicate included (as distinct predicate) search. instance,
might use describe source, even though strictly speaking negation <.
3.3 Leveraging Known Sources
approach problem discovering semantic definitions new services
leverage set known sources learning new definition. Broadly speaking,
invoking known sources (in methodical manner) see combination
information provide matches information provided new source.
practical perspective, means order model newly discovered source semantically,
require overlap data produced new source set known
sources. One way understand consider new source producing weather data.
none known sources produce weather information, way
system learn whether new source producing historical weather data, weather
forecasts - even describing weather all. (In principle, one could try guess
service based type signature alone, would guarantee
definition correct, making little use mediator.) Given overlapping
data requirement, one might claim little benefit incorporating new sources.
detail reasons case below.
11

fiCarman & Knoblock

obvious benefit learning definitions new sources redundancy.
system able learn one source provides exactly information currently
available source, latter suddenly becomes unavailable, former used
place. example, mediator knows one weather source providing current
conditions learns second source provides similar data,
first goes whatever reason (perhaps access quota reached),
weather data still accessed second.
second perhaps interesting reason wanting learn definition
new source new source may provide data lies outside scope (or
simply present in) data provided sources. example, consider
weather service provides temperature values zipcodes United States.
consider second source provides weather forecasts cities worldwide. system
use first source learn definition second, amount information
available querying increases greatly.
Binding constraints service make accessing certain types information difficult
inefficient. case, discovering new source providing similar data
different binding pattern may improve performance. example, consider hotel
search service accepts zipcode returns set hotels along star rating:
hotelSearch($zip, hotel, rating, street, city, state):accommodation(hotel, rating, street, city, state, zip).
consider simple query names addresses five star hotels California:
q(hotel, street, city, zip):- accommodation(hotel, 5*, street, city, California, zip).
Answering query would require thousands calls known source, one every
zipcode California, mediator could answer query another
source providing zipcodes. contrast, system learnt definition new
source provides exactly data different binding pattern (such
one below), answering query would require one call source:
hotelsByState($state, $rating, hotel, street, city, zip):accommodation(hotel, rating, street, city, state, zip).
Often functionality complex source described terms composition
functionality provided simpler services. instance, consider motivating
example section 2, functionality provided new source calculate distance miles two zipcodes. functionality could achieved
performing four different calls available sources. case, definition learnt
system meant query regarding distance zipcodes could handled efficiently. general, learning definitions complicated sources
terms simpler ones, system benefit computation, optimisation caching
abilities services providing complex functionality.
Finally, newly discovered service may faster access known sources
providing similar data. instance, consider geocoding service takes address
returns latitude longitude coordinates location. variety
algorithms used calculate coordinates, unreasonable geocoding
services take long time (upwards one second) return result. system
able discover new source providing geocoding functionality, using
12

fiLearning Semantic Definitions Information Sources Internet

faster algorithm, could locate display many addresses map
amount time.

4. Inducing Definitions
section describe algorithm generating candidate definitions newly
discovered source. algorithm forms first phase generate test methodology
learning source definitions. defer discussion testing phase later paper.
start briefly discussing work relational rule learning describe
algorithm builds upon ideas.
4.1 Inductive Logic Programming
language conjunctive queries restricted form first-order logic. Machine
Learning community, systems capable learning models using first-order representations
referred Inductive Logic Programming (ILP) systems relational rule learners.
expressiveness modeling language, complexity learning much
higher propositional rule learners (also called attribute-value learners), form
bulk Machine Learning algorithms. Given relational modeling services, many
techniques developed ILP also apply problem.
First Order Inductive Learner (foil) well known ILP search algorithm (CameronJones & Quinlan, 1994). capable learning first-order rules describe target predicate, represented set positive examples (tuples target relation,
denoted E + ) optionally also set negative examples (E ). search viable
definition foil starts empty clause7 progressively adds literals body
(antecedent) rule, thereby making rule specific. process continues
definition (denoted h) covers positive examples negative examples:
E + EI [h] 6=

E EI [h] =

Usually set rules learnt manner removing positive examples covered
first rule repeating process. (The set rules interpreted union
query.) Search foil performed greedy best-first manner, guided information
gain-based heuristic. Many extensions basic algorithm exist, notably
combine declarative background knowledge search process focl (Pazzani &
Kibler, 1992). systems categorised performing top search
start empty clause (the general rule possible) progressively specialize
clause. Bottom approaches, hand, golem (Muggleton & Feng,
1990), perform specific general search starting positive examples target.
4.2 Search
describe actual search procedure use generate candidate definitions
new source. procedure based top-down search strategy used foil.
algorithm takes input type signature new source uses seed search
7. use terms clause query interchangeably refer conjunctive query Datalog. empty
clause query without literals body (right side) clause.

13

fiCarman & Knoblock

input : predicate signature
output: best scoring view definition vbest
invoke target set random inputs;
vbest empty clause ;
3 add vbest empty queue;
4 queue 6= time() < timeout i++ < limit
5
v0 best definition queue;
6
forall v1 expand(v0 )
7
insert v1 queue;
8
eval(v1 ) > 0
9
forall v2 constrain(v1 )
10
insert v2 queue;
11
eval(v2 ) eval(v1 ) v1 v2 ;
12
end
13
end
14
eval(v1 ) eval(vbest ) vbest v1 ;
15
end
16 end
17 return vbest ;
Algorithm 1: Best-first search space candidate source definitions.
1

2

candidate definitions. (We refer new source relation target predicate
set known source relations source predicates.) space candidate definitions
enumerated best-first manner, candidate tested see data returns
similar target. Pseudo-code describing procedure given Algorithm 1.8
first step algorithm invoke new source representative set
input tuples generate examples output tuples characterise functionality
source. set invocations must include positive examples (invocations output
tuples produced) possible, also negative tuples (inputs output
returned). algorithms ability induce correct definition source depends
greatly number positive examples available. Thus minimum number positive
invocations source imposed, meaning algorithm may invoke
source repeatedly using different inputs sufficient positive invocations recorded.
Selecting appropriate input values successfully invoke service easier said
done. defer discussion issues difficulties involved successfully invoking
new source section 6.1, assume moment induction system able
generate table values represent functionality.
next step algorithm initialise search adding empty clause
queue definitions expand. rest algorithm simply best-first search
procedure. iteration highest scoring yet expanded definition (denoted
v0 ) removed queue expanded adding new predicate end
8. implementation algorithm used experiments section 7.3 available at:
http://www.isi.edu/publications/licensed-sw/eidos/index.html

14

fiLearning Semantic Definitions Information Sources Internet

clause (see next section example). candidate generated (denoted v1 )
added queue. algorithm progressively constrains candidate binding
variables newly added predicate, (see section 4.4). eval function (see section
5.3) evaluates quality candidate produced. procedure stops constraining
candidate change evaluation function (eval) drops zero.
compares v1 previous best candidate vbest updates latter accordingly.
principle algorithm terminate perfect candidate definition
discovered - one produces exactly data target. practice never
occurs sources incomplete (dont perfectly overlap other)
noisy. Instead algorithm terminates either queue becomes empty, time limit
reached maximum number iterations performed.
4.3 Example
run example process generating candidate definitions. Consider
newly discovered source, takes zipcode distance, returns
zipcodes lie within given radius (along respective distances). target
predicate representing source is:
source5($zip1, $dist1, zip2, dist2)
assume two known sources. first source definition
learnt example section 2, namely:
source4($zip1, $zip2, dist):centroid(zip1, lat1, long1), centroid(zip2, lat2, long2),
greatCircleDist(lat1, long1, lat2, long2, dist2), multiply(dist1, 1.609, dist2).
second source isnt actually source interpreted predicate:
(dist1, dist2).
search definition new source might proceed follows. first
definition generated empty clause:
source5($ , $ , , ).
null character ( ) represents fact none inputs outputs
restrictions placed values. Prior adding first literal (source predicate),
system check whether output attributes echo input values. case, given
semantic types, two possibilities need checked:
source5($zip1, $ , zip1, ).
source5($ , $dist1, , dist1).
Assuming neither possibilities true (i.e. improves score), literals
added one time refine definition. literal source predicate
assignment variable names attributes. new definition must created every
possible literal includes least one variable already present clause. (For
moment ignore issue binding constraints sources added.) Thus many
candidate definitions would generated, including following:
source5($zip1, $dist1, , ) :- source4($zip1, $ , dist1).
source5($zip1, $ , zip2, )
:- source4($zip1, $zip2, ).
source5($ , $dist1, , dist2) :- (dist1, dist2).
15

fiCarman & Knoblock

Note semantic types type signature target predicate limit greatly
number candidate definitions produced. system evaluates
candidates turn, selecting best one expansion. Assuming first
three best score, would expanded adding another literal, forming
complicated candidates following:
source5($zip1, $dist1, , dist2) :- source4($zip1, $ , dist1), (dist1, dist2).
process continues system discovers definition perfectly describes
source, forced backtrack literal improves score.
4.4 Iterative Expansion
sources used previous example relatively low arity. Internet
rarely case, many sources producing large number attributes type.
problem causes exponential number definitions possible
expansion step. Consider instance stock price service, provides current,
high, low, market-opening market-closing prices given ticker symbol. type
signature service would be:
stockprice($ticker, price, price, price, price, price)
definition predicate added already contains k distinct price
variables, number ways price attributes new relation
P
assigned variable names 5i=0 5i k , prohibitively large even moderate k.9
limit search space case high-arity predicates, first generate candidates
minimal number bound variables new literal progressively constrain
best performing definitions within expansion. (High arity predicates
handled similar fashion foil, Quinlan Cameron-Jones, 1993.) example,
consider using source learn definition new source signature:
source6($ticker, price, price)
start adding literals empty definition before. time though, instead
generating literal every possible assignment variable names attributes
relation, generate simplest assignments binding constraints
met. (This expand procedure referred Algorithm 1.) example,
ticker symbol input stockprice source would need bound, generating single
definition:
source6($tic, , ) :- stockprice($tic, , , , , ).
definition would evaluated, constrained definitions generated
equating variable literal variables clause. (This
constrain procedure Algorithm 1.) Two definitions shown below:
source6($tic, pri1, ) :- stockprice($tic, pri1, , , , ).
source6($tic, pri1, ) :- stockprice($tic, , pri1, , , ).
best definitions would selected constrained further, generating
definitions as:

9. Intuitively, one assign variable
names attributes using k labels k different ways. One
choose 5 attributes 5i ways, one = 0, 1, .., 5. See Weber, Tausend,
Stahl (1995) detailed discussion size hypothesis space ILP.

16

fiLearning Semantic Definitions Information Sources Internet

source6($tic, pri1, pri2) :- stockprice($tic, , pri1, pri2, , ).
source6($tic, pri1, pri2) :- stockprice($tic, , pri1, , pri2, ).
way, best scoring literal found without need iterate
possible assignments variables attributes.
4.5 Domain Predicates vs. Source Predicates
examples sections 4.3 4.4, decision perform search source
predicates rather domain predicates made arbitrary fashion.10
section justify decision. one perform search domain predicates
rather source predicates, testing definition would require additional
query reformulation step. example, consider following candidate definition
source5 containing domain predicate centroid:
source5($zip1, $ , , ) :- centroid(zip1, , ).
order evaluate candidate, system would need first treat definition
query reformulate set rewritings (that together form union query)
various sources follows:
source5($zip1, $ , , ) :- source4($zip1, $ , ).
source5($zip1, $ , , ) :- source4($ , $zip1, ).
union query executed available sources (in case
source4) see tuples candidate definition returns. practice however,
definitions known sources contain multiple literals (as normally do)
domain relations high-arity (as often are), search space
conjunctions domain predicates often much larger corresponding search
space conjunctions source predicates. multiple conjunctions
domain predicates (candidate definitions) end reformulating conjunction
source predicates (union queries). example, consider following candidate definitions
written terms domain predicates:
source5($zip1, $ , , ) :- centroid(zip1, lat, ), greatCircleDist(lat, , , , ).
source5($zip1, $ , , ) :- centroid(zip1, , lon), greatCircleDist( , lon, , , ).
source5($zip1, $ , , ) :- centroid(zip1, lat, lon), greatCircleDist(lat, lon, , , ).
three candidates would reformulate query sources (shown below),
thus indistinguishable given sources available.
source5($zip1, $ , , ) :- source4($zip1, $ , ).
general, number candidate definitions map reformulation
exponential number hidden variables present definitions known sources.
reason, simplify problem search space conjunctions source
predicates. sense, performing search source predicates seen
introducing similarity heuristic focuses search toward definitions similar
structure definitions available sources. note definitions produced
(and will) later converted queries global predicates unfolding
10. note difference domain, source interpreted predicates. Domain predicates
invented domain expert use modeling particular information domain. define common
schema used describing information different sources. Source predicates represent
sources available system. Interpreted predicates, (such ), special type domain
predicate, treated source predicates, since meaning interpreted (understood).

17

fiCarman & Knoblock

possibly tightening remove redundancies. discuss process tightening
unfoldings section 6.6.
4.6 Limiting Search
search space generated top-down search algorithm may large even
small number sources. use semantic types limits greatly ways
variables within definition equated (aka join paths) thus goes long
way reduce size search space. Despite reduction, number sources
available increases, search space becomes large techniques limiting must
used. employ standard (and standard) ILP techniques limiting
space. limitations often referred inductive search bias language bias
(Nedellec, Rouveirol, Ade, Bergadano, & Tausend, 1996).
obvious way limit search restrict number source predicates
occur definition. Whenever definition reaches maximum length, backtracking
performed, allowing search escape local minima may result
greedy enumeration. assumption shorter definitions probable
longer ones, makes sense since service providers likely provide data
simplest form possible. Moreover, simpler definition learnt, useful
mediator, decide trade completeness (the ability express longer
definitions) improved accuracy shorter definitions.
second restriction placed candidate definitions limit number times
source predicate appears given candidate. makes sense
definitions real services tend contain many repeated predicates. Intuitively,
services provide raw data without performing many calculations upon it.
Repeated use predicate definition useful describing form
calculation raw data itself. (Exceptions rule exist, example predicates
representing unit conversion functionality Fahrenheit Celsius, may necessarily
occur multiple times definition source.)
third restriction limits complexity definitions generated reducing
number literals contain variables head clause. Specifically,
limits level existential quantification (sometimes also referred depth,
Muggleton Feng, 1990) variable clause. level defined zero
distinguished variables (those appearing head clause). existential
variables defined recursively one plus lowest level variable appearing
literal. example, candidate definition shown maximum existential
quantification level three shortest path last literal head literal
(via join variables) passes two literals:
source5($zip1, $ , , ) :- source4($zip1, $ , d1), source3($d1, d2), source3($d2, ).
effect bias concentrate search around simpler highly connected
definitions, literal closely linked input output source.
fourth restriction placed source definitions executable.
specifically, possible execute left right, meaning inputs
source appear either target predicate (head clause) one
literals left literal. example, two candidate definitions shown below,
18

fiLearning Semantic Definitions Information Sources Internet

first executable. second definition not, zip2 used input
source4 first literal, without first bound value head clause:
source5($zip1, $ , zip2, ) :- source4($zip1, $zip2, ).
source5($zip1, $ , , ) :- source4($zip1, $zip2, dist1), source4($zip2, $zip1, dist1).
restriction serves two purposes. Firstly, like biases, limits size
search space. Secondly, makes easier evaluate definitions produced. theory,
one could still evaluate second definition generating lots input values
zip2, would require lot invocations minimal gain.
last restriction reduces search space limiting number times
variable appear given literal body clause. Definitions
variable appears multiple times given literal, following example
returns distance zipcode itself, common practice:
source5($zip1, $ , , dist2) :- source4($zip1, $zip1, dist2).
Explicitly preventing definitions generated makes sense sources
requiring rare, better reduce search space exponentially
ignoring them, explicitly check time.

5. Scoring Definitions
proceed problem evaluating candidate definitions generated
search. basic idea compare output produced source output
produced definition input. similar set tuples produced,
higher score candidate. score averaged set different
input tuples see well candidate definition describes new source.
motivating example section 2, source definition learnt
(the definition repeated below) produced one output tuple hdisti every input
tuple hzip1, zip2i:
source4($zip1, $zip2, dist):centroid(zip1, lat1, long1), centroid(zip2, lat2, long2),
greatCircleDist(lat1, long1, lat2, long2, dist2),
multiply(dist1, 1.6093, dist2).
fact made simple compare output service output induced
definition. general however, source modeled (and candidate definitions
modeling it) may produce multiple output tuples input tuple. Take example
source5 section 4.3, produces set output tuples hzip2, dist2i containing
zipcodes lie within given radius input zipcode hzip1, dist1i.
cases, system needs compare set output tuples set produced
definition see tuples same. Since new source
existing sources may complete, two sets may simply overlap, even candidate
definition correctly describes new source. Assuming count number
tuples same, need measure tells us well candidate hypothesis
describes data returned source. One measure following:
score(s, v, I) =

1 X |Os (i) Ov (i)|
|I| iI |Os (i) Ov (i)|
19

fiCarman & Knoblock

new source, v candidate source definition, D[s ] set
input tuples used test source (s set input attributes source s). Os (i)
denotes set tuples returned new source invoked input tuple i. Ov (i)
corresponding set returned candidate definition. Using relational projection
() selection () operators notation introduced section 2.1, sets
written follows. (Note sc represents output attributes s.)
Os (i) sc (s =i (E[s]))



Ov (i) sc (s =i (EI [v]))

view hypothesis testing information retrieval task, consider recall
number common tuples, divided number tuples produced
source, precision number common tuples divided number tuples
produced definition. measure takes precision recall account
calculating average Jaccard similarity sets. table gives
example score calculated input tuple.
input tuple
iI
ha, bi
hc, di
he, f
hg, hi
hi, ji

actual output
tuples Os (i)
{hx, yi, hx, zi}
{hx, wi, hx, zi}
{hx, wi, hx, yi}



predicted output
tuples Ov (i)
{hx, yi}
{hx, wi, hx, yi}
{hx, wi, hx, yi}
{hx, yi}


Jaccard similarity
tuple
1/2
1/3
1
0
#undef!

first two rows table show inputs predicted actual output
tuples overlap. third row, definition produces exactly set tuples
source modeled thus gets maximum score. fourth row,
definition produced tuple, source didnt, definition penalised.
last row, definition correctly predicted tuples would output source.
score function undefined point. certain perspective definition
score well correctly predicted tuples returned
input, giving high score definition produces tuples dangerous.
may cause overly constrained definitions generate output tuples
score well. time, less constrained definitions better predicting
output tuples average may score poorly. example, consider source returns
weather forecasts zipcodes Los Angeles:
source($zip, temp) :- forecast(zip, tomorrow, temp), UScity(zip, Los Angeles).
consider two candidate definitions source. first returns temperature
zipcode, second returns temperature 0 C:
v1 ($zip, temp) :- forecast(zip, tomorrow, temp).
v2 ($zip, temp) :- forecast(zip, tomorrow, temp), temp < 0 C .
Assume source candidates invoked using 20 different randomly selected
zipcodes. zipcodes, source return output, zipcode
lie outside Los Angeles. first candidate likely return output zipcodes,
second candidate would, like source, rarely produce output.
temperature zipcodes greater zero, nothing
20

fiLearning Semantic Definitions Information Sources Internet

whether zipcode Los Angeles. score definitions highly
correctly produce output, system would erroneously prefer second candidate
first (because latter often produces output). prevent happening,
simply ignore inputs definition correctly predicts zero tuples.
setting score average values.
Returning attention table, ignoring last row, overall score
definition would calculated 0.46.
5.1 Partial Definitions
search proceeds toward correct definition service, many semi-complete
(unsafe) definitions generated. definitions produce values
attributes target tuple subset them. example, candidate:
source5($zip1, $dist1, zip2, ) :- source4($zip1, $zip2, dist1).
produces one two output attributes produced source. presents
problem, score defined sets tuples containing output
attributes new source. One solution might wait definitions become
sufficiently long produce outputs, comparing see one best
describes new source. are, however, two reasons would make sense:
space safe definitions large enumerate, thus need compare
partial definitions guide search toward correct definition.
best definition system generate may well partial one, set
known sources may sufficient completely model source.
simplest way compute score partial definition compute function
before, instead using raw source tuples, projecting subset
attributes produced definition. revised score shown below. (Note
projection v\s , denotes subset output attributes
produced view definition v. Note also projection distinct, i.e.
multiple instances tuple may produced.)
score2 (s, v, I) =

1 X |v\s (Os (i)) Ov (i)|
|I| iI |v\s (Os (i)) Ov (i)|

revised score useful however, gives unfair advantage definitions
produce output attributes source. far easier
correctly produce subset output attributes produce them. Consider
example two source definitions shown below. two definitions identical except
second returns output distance value dist2, first not:
source5($zip1, $dist1, zip2, )
:- source4($zip1, $zip2, dist2), (dist2, dist1).
source5($zip1, $dist1, zip2, dist2):- source4($zip1, $zip2, dist2), (dist2, dist1).
Since two identical, projection subset case return
number tuples. means definitions would get score although
second definition clearly better first since produces required outputs.
need able penalise partial definitions way attributes
dont produce. One way first calculate size domain |D[a]|
21

fiCarman & Knoblock

missing attributes. example above, missing attribute distance value.
Since distance continuous value, calculating size domain obvious.
approximate size domain by:
|D[distance]|

max min
accuracy

accuracy error-bound distance values. (We discuss error-bounds
section 5.4.) Note cardinality calculation may specific semantic type.
Armed domain size, penalise score definition dividing
product size domains output attributes generated
definition. essence, saying possible values extra attributes
allowed definition. technique similar techniques used learning
without explicit negative examples (Zelle, Thompson, Califf, & Mooney, 1995).
set missing output attributes given expression sc \v, thus penalty
missing attributes size domain tuples scheme, i.e.:
penalty = |D[sc \v]|
Using penalty value calculate new score, takes account missing
attributes. Simply dividing projected score penalty would adhere
intended meaning compensating missing attribute values, thus may skew
results. Instead, derive new score introducing concept typed dom predicates
follows:
dom predicate semantic data-type t, denoted domt , single arity
relation whose extension set domain datatype, i.e. E[domt ] =
D[t]. Similarly, dom predicate scheme A, denoted domA , relation
whose extension E[domA ] = D[A].
Dom predicates introduced Duschka handle problem query reformulation
presence sources binding constraints (Duschka, 1997). (In work
predicates typed, although typing would resulted efficient algorithm.) use convert partial definition v safe (complete) definition
v 0 . simply adding dom predicate end view definition
generates values missing attributes. example above, v 0 would be:
source5($zip1, $dist1, zip2, x) :source4($zip1, $zip2, dist2), (dist2, dist1), domdistance (x).
x new variable type distance. new view definition v 0 safe,
variables head clause also appear body. general,
turn unsafe view definition v safe definition v 0 appending dom predicate
domsc \v (x1 , ..., xn ), xi distinguished variable (from head clause)
corresponding output attribute v 0 wasnt bound v. use
complete definition calculate score before:
score3 (s, v, I) = score(s, v 0 , I) =

22

1 X |Os (i) Ov0 (i)|
|I| iI |Os (i) Ov0 (i)|

fiLearning Semantic Definitions Information Sources Internet

rewritten (by expanding denominator) follows:
score3 (s, v, I) =

|Os (i) Ov0 (i)|
1 X
|I| iI |Os (i)| + |Ov0 (i)| |Os (i) Ov0 (i)|

remove references v 0 equation considering:
Ov0 (i) = Ov (i) E[domsc \v ] = Ov (i) D[sc \v]
Thus size set given |Ov0 (i)| = |Ov (i)||D[sc \v]| size intersection
calculated taking projection output attributes produced v:
|Os (i) Ov0 (i)| = |v\s (Os (i) Ov (i) D[sc \v])| = |v\s (Os (i)) Ov (i)|
Substituting cardinalities score function given above, arrive following
equation penalised score:
score3 (s, v, I) =

|v\s (Os (i)) Ov (i)|
1 X
|I| iI |Os (i)| + |Ov (i)||D[sc \v]| |v\s (Os (i)) Ov (i)|

5.2 Binding Constraints
candidate definitions generated search may different binding
constraints target predicate. instance partial definition shown below,
variable zip2 output target source, input source4 :
source5($zip1, $dist1, zip2, ) :- source4($zip1, $zip2, dist1).
logical perspective, order test definition correctly, need invoke
source4 every possible value domain zipcodes. practical
two reasons: firstly, system may complete list zipcodes disposal.
Secondly far importantly, invoking source4 thousands different zipcodes
would take long time would probably result system blocked
use service. instead invoking source thousands times,
approximate score definition sampling domain zipcodes
invoking source using sampled values. compensate sampling
scaling (certain components of) score ratio sampled zipcodes
entire domain. Considering example above, randomly choose sample (denoted
[zipcode]) say 20 values domain zipcodes, set tuples returned
definition need scaled factor |D[zipcode]|/20.
general equation computing scaling factor (denoted SF ) shown below.
Note sampling may need performed set attributes. (Here v \s
denotes input attributes v outputs s.)
SF =

|D[v \s ]|
|[v \s ]|

calculate effect scaling factor overall score follows. denote
set tuples returned definition given sampled input Ov (i). value
23

fiCarman & Knoblock

scaled approximate set tuples would returned
definition invoked possible values additional input attributes:
|Ov (i)| |Ov (i)| SF
Assuming sampling performed randomly domain possible values,
intersection tuples produced source definition scale
way. Thus factor affected scaling score defined previously
|Os (i)|. divide throughout scaling factor new scoring function:
score4 (s, v, I) =

|v\s (Os (i)) Ov (i)|
1 X
|I| iI |Os (i)|/SF + |Ov (i)||D[sc \v]| |v\s (Os (i)) Ov (i)|

problem approach often sampled set values small
result intersect set values returned source, even though larger
sample would intersected way. Thus sampling introduces unfair distortions
score certain definitions, causing perform poorly. example, consider
source5 assume scalability purposes, service places limit
maximum value input radius dist1. (This makes sense, otherwise user could
set input radius cover entire US, tuple every possible zipcode would
need returned.) consider sampling performed above. randomly choose
20 zipcodes set possible zipcodes, chance sample containing
zipcode lies within 300 mile radius particular zipcode (in middle
desert) low. Moreover, even one pair zipcodes (out 20) results successful
invocation, sufficient learning good definition service.
get around problem bias sample that, whenever possible, half
values taken positive examples target (those tuples returned new
source) half taken negative examples (those tuples returned source).
sampling positive negative tuples, guarantee approximation
generated accurate possible given limited sample size. denote set
positive negative samples + [v \s ] [v \s ], use values define
positive total scaling factors shown below. (The numerator positive values
different before, values taken output new source.)
SF + =

|v \s (v\s (Os (i)))|
| + [v \s ]|

total scaling factor value before, calculated slightly differently:
SF =

|D[v \s ]|
| + [v \s ]| + | [v \s ]|

score approximated accordingly taking account new scaling
factors. intersection needs scaled using positive scaling factor:
|v\s (Os (i)) Ov (i)| |v\s (Os (i)) Ov (i)| SF +
new scaling results new function evaluating quality view definition:
score5 (s, v, I) =

|v\s (Os (i)) Ov (i)| SF +
1 X
|I| iI |Os (i)| + |Ov (i)||D[sc \v]| SF |v\s (Os (i)) Ov (i)| SF +
24

fiLearning Semantic Definitions Information Sources Internet

5.3 Favouring Shorter Definitions
derived score comparing data source candidate
produce, define evaluation function eval used Algorithm 1. mentioned
section 4.6, shorter definitions target source preferred longer
possibly less accurate ones. accordance principle, scale score
length definition, favour shorter definitions follows:
eval(v) = length(v) score5 (s, v, I)
length(v) length clause < 1 weighting factor. Setting
weighting factor little less 1 (such 0.95) helps remove logically redundant
definitions, sometimes hard detect, often return almost exactly
score shorter equivalent. discuss problem generating non-redundant
clauses section 6.3.
5.4 Approximating Equality
now, ignored problem deciding whether two tuples produced
target source definition same. Since different sources may serialize data
different ways different levels accuracy, must allow flexibility
values tuples contain. instance, example section 2, distance
values returned source definition match exactly, sufficiently
similar accepted value.
numeric types like temperature distance makes sense use error bound (like
0.5 C) percentage error (such 1%) decide two values considered
same. sensing equipment (in case temperature) algorithm (in
case distance) error bound associated values produces.
require error bound numeric type provided problem specification.
(Ideally, bounds would learnt automatically examples.)
certain nominal types like company names, values like hIBM Corporationi
hInternational Business Machines Corp.i represent value, simplistic equality
checking using exact substring matches sufficient deciding whether two values
correspond entity. case, string edit distances JaroWinkler
score better distinguishing strings representing entity representing
different ones (Bilenko, Mooney, Cohen, Ravikumar, & Fienberg, 2003). machine learning
classifier could trained set examples learn available string
edit distances best distinguishes values type threshold set accepting
pair match. require pair similarity metric threshold (or
combinations metrics) provided problem specification.
cases, enumerated types like months year might associated
simple equality checking procedure, values like hJanuaryi, hJani h1i
found equal. actual equality procedure used depend semantic type
assume work procedure given problem definition. note
procedure need 100% accurate, provide sufficient level accuracy
guide system toward correct source description. Indeed, equality rules could
also generated offline training classifier.
25

fiCarman & Knoblock

Complex types date present bigger problem one considers range
possible serializations, including values like h5/4/2006i hThu, 4 May 2006i h2006-05-04i.
cases specialized functions required check equality values
also break complex types constituent parts (in case day, month
year ). latter would form part domain model.
cases, deciding whether two values type considered equal
depends type, also relations used in. Consider
two relations shown below. first provides latitude longitude coordinates
centroid zipcode, second returns coordinates particular address:
centroid(zipcode, latitude, longitude)
geocode(number, street, zipcode, latitude, longitude)
Given different ways calculating centroid zipcode (including using center
mass center population density) error bound 500 meters might make sense
equating latitude longitude coordinates. geocoding service, hand,
error bound 50 meters may reasonable. general, error bounds
associated set global relations, instead semantic types, could
learnt accordingly. relations contain multiple attributes, problem
deciding whether two tuples refer entity called record linkage (Winkler,
1999). entire field research devoted tackling problem. Due complexity
problem variety techniques developed handle it,
investigate here.

6. Extensions
section discuss extensions basic algorithm needed handling real data
sources, well ways reduce size hypothesis space improve quality
definitions produced.
6.1 Generating Inputs
first step source induction algorithm generate set tuples
represent target relation induction process. words, system must
try invoke new source gather example data. without biasing
induction process easier said done. simplest approach generating input values
select constants random set examples given problem specification.
problem approach cases new source produce
output selected inputs. Instead system may need select values according
distribution domain values order source invoke correctly.
example, consider source providing posts used cars sale certain area. source
takes make car input, returns car details:
usedCars($make, model, year, price, phone)
Although hundred different car manufacturers world,
produce bulk cars. Thus invoking source values like Ferrari,
Lotus Aston Martin less likely return tuples, compared
common brands Ford Toyota (unless source providing data sports
cars course). distribution possible values available, system first try
26

fiLearning Semantic Definitions Information Sources Internet

common values, generally, choose values set according
distribution. particular example, might difficult query source
complete set car manufacturers one invocations returns data.
general, set examples may large (such 40,000+ zipcodes US)
number interesting values set (the ones likely return results) may
small, case taking advantage prior knowledge distribution
possible values makes sense. noted also execution system
receive lot output data different sources accesses. data recorded
generate distributions possible values different types.
problem generating viable input data new source becomes yet difficult
input required single value tuple values. case system
first try invoke source random combinations attribute values
examples type. Invoking sources (such source5 ) easy
explicit restriction combination input values:
source5($zip, $distance, zip, distance)
cases, geocoding service combination possible input values highly
restricted:
USGeocoder($number, $street, $zipcode, latitude, longitude)
Randomly selecting input values independently one another unlikely result
successful invocations. (In order invocation succeed, randomly generated
tuple must correspond address actually exists.) cases, failing
invoke source number times, system try invoke sources (such
hotel lookup service below), produce tuples containing required attribute types:
HotelSearch($city, hotel, number, street, zipcode)
general, process invoking sources generate input sources chained
set viable inputs generated.
note problem synthesizing viable input data difficult
interesting research problem. combined approach utilizing value distributions
invoking alternative services performs well experiments (see section 7.3), area
future work develop general solution.
6.2 Dealing Sources
order minimise source accesses, expensive terms time
bandwidth, requests individual sources cached local relational database.
implementation means implicit assumption work
output produced services constant duration induction process.
could problematic service modeled provides (near) real-time data
update frequency less time takes induce definition. weather
prediction service, updated hourly, may present much problem, since
difference predicted temperatures may vary slightly one update
next. real-time flight status service providing coordinates given aircraft
every five minutes, caching may problematic location plane vary
greatly takes, example, one hour induce definition. theory one could test
variation systematically periodically invoking source previously
27

fiCarman & Knoblock

successful input tuple see output changed, update caching policy
accordingly.
6.3 Logical Optimisations
Evaluating definitions expensive terms time (waiting sources return data) computation (calculating joins large tables). Thus makes sense
check candidate redundancy evaluating it. decide definitions
redundant, use concept query containment:
query q1 LR,A said contained another query q2 LR,A
database instance I, set tuples returned first query subset
returned second, i.e. EI [q1 ] EI [q2 ]. denote containment
q1 v q2 . Two queries considered logically equivalent q1 v q2 q2 v q1 .
conjunctive queries learnt paper, testing query containment reduces
problem finding containment mapping (Chandra & Merlin, 1977).11 use
test discover logically equivalent definitions following, (which contain
reordering literals):
source($zip, temp):- getCentroid($zip, lat, lon), getConditions($lat, $lon, temp).
source($zip, temp):- getConditions($lat, $lon, temp), getCentroid($zip, lat, lon).
equivalence checking performed efficiently canonical ordering predicate
variable names chosen priori. Whenever logically equivalent definitions discovered, search backtrack, thereby avoiding entire sub-trees equivalent clauses.
Similarly, test skip logically redundant clauses following (which
equivalent shorter definition without second literal):
source($zip, ):- getCentroid($zip, lat, long), getCentroid($zip, lat, ).
Again, redundancy checking performed efficiently (Levy, Mendelzon, Sagiv, &
Srivastava, 1995) resulting little computational overhead search.
6.4 Functional Sources
information may known functionality certain sources expressed
source definitions. example, sources like Multiply Concatenate,
implemented locally, known complete. (A source considered complete,
returns tuples implied definition, i.e. E[s] = EI [v].) Whenever
information available, induction system take advantage improve search
efficiency. explain how, define class sources call functional sources,
complete input tuple return exactly one output tuple. slightly
restrictive standard ILP concept determinate literals (Cameron-Jones &
Quinlan, 1994), every input tuple return one output tuple. Multiply
Concatenate examples functional sources. system takes advantage fact
functional sources place restrictions input. Whenever functional source
added candidate definition, score definition doesnt change providing
sources inputs none outputs bound. (The set tuples returned new
11. queries contain interpreted predicates, containment testing little involved (Afrati,
Li, & Mitra, 2004).

28

fiLearning Semantic Definitions Information Sources Internet

definition before, new attributes corresponding outputs
source.) Thus new definition need evaluated, added
queue (of definitions expand) is, becomes particularly advantageous
sources input arity high.
6.5 Constants
Constants often used source descriptions define scope service. Consider
weather service provides reports zipcodes California:
calWeather($zip, $date, temp) :- forecast(zip, date, temp), USstate(zip, California).
mediator receives query asking forecast Chicago, know
source relevant query since Chicago California. Although constants
source descriptions useful, simply introducing hypothesis
language could cause search space grow prohibitively. (For states, branching
factor would 50, zipcodes would excess 40,000.) Obviously generate
test methodology make sense domain semantic type large.
Alternatively, one explicitly check repeated values tuples returned
new source (i.e. constants head clause) join source
definition relations (i.e. constants body clause). example,
definition join source relation hzip, date, tempi definition relation
hzip, date, temp, statei would produce tuples state equal California.
constant could added definition.
source($zip, $date, temp) :- forecast(zip, date, temp), USstate(zip, state).
complicated detection procedures would required discovering constants interpreted predicates (i.e. range restrictions numeric attributes).
6.6 Post-Processing
definition learnt new source, may possible tighten
definition removing logical redundancies unfolding. Consider following
definition involving calls two hotel sources, one check availability
check rating:
source($hotel, address, rating):HotelAvailability($hotel, address, price), HotelRating($hotel, rating, address).
unfolding definition (in terms definitions hotel sources) contains
two references accommodation relation:
source($hotel, address, rating):accommodation(hotel, , address), available(hotel, today, price),
accommodation(hotel, rating, address).
first literal redundant removed unfolding. general,
rules used discover redundancy candidate definitions used remove redundant
literals unfolding. Moreover, since post-processing step needs performed
once, time spent searching complicated forms redundancy.
29

fiCarman & Knoblock

7. Evaluation
section describe evaluation source induction algorithm. first
describe experimental setup used experiments performed. Finally,
compare induction algorithm particular complex schema matching system.
7.1 Experimental Setup
source induction algorithm defined paper implemented system called
eidos, stands Efficiently Inducing Definitions Online Sources. eidos implements techniques optimisations discussed sections 4 6. (Certain
extensions section 6 partially implemented: implementation currently
checks constants head clause perform tightening
definitions.) code written Java MySQL database used caching
results source invocations.
eidos tested 25 different problems involving real services several domains
including hotels, financial data, weather cars. domain model used
problem included 70 different semantic types, ranging common
ones like zipcode specific types stock ticker symbols. data model
also contained 36 relations (excluding interpreted predicates), used model 33
different services. modeled services publicly available information sources.
note decision use set known sources problem
(regardless domain) important order make sure tests realistic.
decision made problem difficult standard schema matching/mapping
scenario source schema chosen, provides data known
priori relevant output schema.
order give better sense problem setting complexity known
sources available, list ten (ordered arity). Due space limitations dont
show complete list definitions, input/output types source.
Note sources share semantic types latitude longitude, means
search space associated sources alone large.
1

WeatherConditions($city,state,country,latitude,longitude,time,time,timeoffset,
datetime,temperatureF,sky,pressureIn,direction,speedMph,humidity,temperatureF)
2 WeatherForecast($city,state,country,latitude,longitude,timeoffset,day,date,
temperatureF,temperatureF,time,time,sky,direction,speedMph,humidity)
3 GetDistance($latitude,$longitude,$latitude,$longitude,distanceKm)
4 USGeocoder($street,$zipcode,city,state,latitude,longitude)
5 ConvertDMS($latitudeDMS,$longitudeDMS,latitude,longitude)
6 USGSEarthquakes(decimal,timestamp,latitude,longitude)
7 GetAirportCoords($iata,airport,latitude,longitude)
8 CountryCode($latitude,$longitude,countryAbbr)
9 GetCentroid($zipcode,latitude,longitude)
10 Altitude($latitude,$longitude,distanceM)

order induce definitions problem, source (and candidate definition) invoked least 20 times using random inputs. Whenever possible, system
attempted generate 10 positive examples source (invocations source
returned tuples) 10 negative examples (inputs produced output).
30

fiLearning Semantic Definitions Information Sources Internet

ensure search terminated, number iterations algorithm including backtracking steps limited 30. search time limit 20 minutes also imposed.
inductive search bias used experiments shown below, weighting factor
(defined section 5.3) 0.9 used direct search toward shorter definitions.
Search Bias
Maximum clause length = 7
Maximum predicate repetition = 2
Maximum variable level = 5
Executable candidates
variable repetition within literal
experiments, different procedures used decide equality values
type discussed section 5.4. equality procedures used different
types listed below. accuracy bounds thresholds used chosen maximize
overall performance learning algorithm. (In practice, meta-learning algorithm
could used determine best accuracy bounds different attribute types.)
semantic types listed below, substring matching (checking one string contained
other) used test equality values.
Types
latitudes, longitudes
distances, speeds, temperatures, prices
humidity, pressure, degrees
decimals
companies, hotels, airports
dates

Equality Procedure
accuracy bound 0.002
accuracy bound 1%
accuracy bound 1.0
accuracy bound 0.1
JaroWinkler score 0.85
specialised equality procedure

experiments run dual core 3.2 GHz Pentium 4 4 GB RAM (although
memory limiting factor tests). system running Windows
2003 Server, Java Runtime Environment 1.5 MySQL 5.0.
7.2 Evaluation Criteria
order evaluate induction system, one would like compare problem
definition generated system ideal definition source (denoted vbest
v respectively). words, would like evaluation function, rates
quality definition produced respect hand-written definition
source (i.e. quality : vbest v [0, 1]). problem twofold. Firstly,
obvious define similarity function conjunctive queries many
different possibilities exist (see Markov Marinchev, 2000, particular example).
Secondly, working best definition hand, taking account limitations
domain model fact available sources noisy, incomplete, possibly
less accurate, even serialise data different ways, may extremely difficult, even
possible. order evaluate discovered definitions, instead count
number correctly generated attributes definition. attribute said
correctly generated, if:
31

fiCarman & Knoblock

input, definition correctly restricts domain possible values
attribute,
output, definition correctly predicts value given input tuples.
Consider following definition takes two input values returns difference
square root (providing difference positive):
source($A, $B, C, D) :- sum(B, C, A), product(D, D, C), B.
imagine induction system managed learn source returns
difference input output, i.e.:
source($A, $B, C, ) :- sum(B, C, A).
say first input attribute correctly generated input
constrained respect input attribute B (the inequality missing). input B
deemed correctly generated present sum relation (only one input penalised
missing inequality). output C deemed correctly generated respect
inputs, missing attribute isnt generated all. (Note ordering
variables sum relation different, say sum(A, B, C), C would
generated, correctly generated.)
Given definition correctly generated attributes, one define expressions
precision recall attributes contained source definition. define precision
ratio correctly generated attributes total number attributes generated
definition, i.e.:
precision =

# correctly generated attributes
total # generated attributes

define recall ratio generated attributes total number attributes
would generated ideal definition, given sources available. (In
cases sources available generate values attribute case,
attribute included count.)
recall =

# correctly generated attributes
total # attributes generated

Note defined precision recall schema level terms attributes
involved source definition. could also defined data level terms
tuples returned source definition. Indeed, Jaccard similarity
used score candidate definitions combination data-level precision recall values.
reason choosing schema level metrics evaluation better reflect
semantic correctness learnt definition, far independent
completeness (amount overlap) known target sources.
Returning example above, precision simple definition learnt would
2/3 recall would 2/4. Note that, product relation available
domain model (in case attribute could never generated), recall
would higher 2/3.
32

fiLearning Semantic Definitions Information Sources Internet

7.3 Experiments
definitions learnt system described below. Overall system performed
well able learn intended definition (ignoring missing join variables
superfluous literals) 19 25 problems.
7.3.1 Geospatial Sources
first set problems involved nine geospatial data sources providing variety location
based information. definitions learnt system listed below. reported
terms source predicates rather domain relations (i.e. unfoldings)
corresponding definitions much shorter. makes easier understand
well search algorithm performing.
1
2
3

4
5
6

7
8
9

GetInfoByZip($zip0,cit1,sta2,_,tim4) :GetTimezone($sta2,tim4,_,_), GetCityState($zip0,cit1,sta2).
GetInfoByState($sta0,cit1,zip2,_,tim4) :GetTimezone($sta0,tim4,_,_), GetCityState($zip2,cit1,sta0).
GetDistanceBetweenZipCodes($zip0,$zip1,dis2) :GetCentroid($zip0,lat1,lon2), GetCentroid($zip1,lat4,lon5),
GetDistance($lat1,$lon2,$lat4,$lon5,dis10), ConvertKm2Mi($dis10,dis2).
GetZipCodesWithin($_,$dis1,_,dis3) :<(dis3,dis1).
YahooGeocoder($str0,$zip1,cit2,sta3,_,lat5,lon6) :USGeocoder($str0,$zip1,cit2,sta3,lat5,lon6).
GetCenter($zip0,lat1,lon2,cit3,sta4) :WeatherConditions($cit3,sta4,_,lat1,lon2,_,_,_,_,_,_,_,_,_,_,_),
GetZipcode($cit3,$sta4,zip0).
Earthquakes($_,$_,$_,$_,lat4,lon5,_,dec7,_) :USGSEarthquakes(dec7,_,lat4,lon5).
USGSElevation($lat0,$lon1,dis2) :ConvertFt2M($dis2,dis1), Altitude($lat0,$lon1,dis1).
CountryInfo($cou0,cou1,cit2,_,_,cur5,_,_,_,_) :GetCountryName($cou0,cou1), GoCurrency(cur5,cou0,_),
WeatherConditions($cit2,_,cou1,_,_,_,_,_,_,_,_,_,_,_,_,_).

first two sources provide information zipcodes, name city,
state timezone. differ binding constraints, first taking
zipcode input, second taking state. second source returns many output
tuples per input value, making harder learn definition, even though two sources
provide logically information. induced definitions best possible given
known sources available. (None provided missing output attribute, telephone area-code.) third source calculates distance miles two zipcodes,
(it source4 section 2). correct definition learnt source,
next source, returned zipcodes within given radius, reasonable definition could learnt within time limit.12 Ignoring binding constraints, intended
12. recall problem 1/4 input attribute dis1 determined correctly
generated attribute (it constrained respect output attribute dis3 ), four attributes
generated (the output attribute dis3 generated < predicate). precision
1/1 dis1 generated attribute, correctly generated.

33

fiCarman & Knoblock

definition third, restriction output distance less
input distance. Thus would far easier eidos learn definition
fourth source terms third. Indeed, new definition third
source added set known sources, system able learn following:
4 GetZipCodesWithin($zip0,$dis1,zip2,dis3) :GetDistanceBetweenZipCodes($zip0,$zip2,dis3), <(dis3,dis1).

ability system improve learning ability time set known
sources increases key benefit approach.
Source five geocoding service provided Yahoo. (Geocoding services map addresses latitude longitude coordinates.) eidos learnt functionality
provided service called USGeocoder. Source six simple service providing
latitude/longitude coordinates city state given zipcode. Interestingly,
system learnt sources coordinates better predicted weather conditions service (discussed section 7.3.3), GetCentroid source third
definition. Note new source definition unfolded contain extraneous predicates related weather information.13 additional predicates interfere
usefulness definition, however, query reformulation algorithm still
use source answer queries regardless. (Thus precision recall scores
affected.) post-processing step remove extraneous predicates possible,
would require additional information domain model.14 seventh source provided
earthquake data within bounding box took input. case, system
discovered source indeed providing earthquake data, (lat4 lon5 coordinates earthquake dec7 magnitude). didnt manage, however, work
input coordinates related output. next source provided elevation
data feet, found sufficiently similar known altitude data metres.
Finally, system learnt definition source providing information countries
currency used, name capital city. Since known sources
available provide information, system ended learning weather reports
available capital country.
Problem
1
2
3
4
5
6
7
8
9

# Candidates
25
24
888
3
50
40
11
15
176

# Invocations
5068
9804
11136
11176
13148
15162
14877
177
28784

Time (s)
85
914
449
25
324
283
18
72
559

log10 (Score)
-1.36
-1.08
-0.75
0.25
-0.45
-7.61
-6.87
-8.58
-5.77

Precision
4/4
4/4
3/3
1/1
6/6
5/5
3/3
3/3
4/4

Recall
4/4
4/4
3/3
1/4
6/6
5/5
3/9
3/3
4/4

13. unfolding shown below. conditions predicate could removed without affecting meaning:
GetCenter($zip0, lat1, lon2, cit3, sta4):- municipality(cit3, sta4, zip2, tim3), country( , cou5, ),
northAmerica(cou5), centroid(zip2, lat1, lon2), conditions(lat1, lon2, , , , , , , , , , , ),
timezone(tim3, , ), municipality(cit3, sta4, zip0, ).
14. particular, universally quantified knowledge would needed domain model, e.g.:
lat, lon x1 , ..., x11 s.t. conditions(lat, long, x1 , ..., x11 )

34

fiLearning Semantic Definitions Information Sources Internet

table shows details regarding search performed learn definitions listed above. problem, shows number candidates generated prior
winning definition, along time number source invocations required
learn definition. (The last two values interpreted caution
highly dependent delay accessing sources, caching data
system.) scores shown fifth column normalised version scoring
function used compare definitions search. (Normalisation involved removing
penalty applied missing outputs.) scores small, logarithm
values shown (hence negative values).15 scores interpreted
confidence system definitions produced. closer value zero,
better definitions ability produce tuples source. see
system far confident definitions one five, latter
ones.16 last two columns give precision recall value problem.
average precision problems 100%. (Note high precision value
expected, given induction algorithm relies finding matching tuples
source definition.) average recall geospatial problems also high
84%.
7.3.2 Financial Sources
Two sources tested provided financial data. definitions generated eidos
sources shown below.
10 GetQuote($tic0,pri1,dat2,tim3,pri4,pri5,pri6,pri7,cou8,_,pri10,_,_,pri13,_,com15):YahooFinance($tic0,pri1,dat2,tim3,pri4,pri5,pri6,pri7,cou8),
GetCompanyName($tic0,com15,_,_),Add($pri5,$pri13,pri10),Add($pri4,$pri10,pri1).
11 YahooExchangeRate($_,$cur1,pri2,dat3,_,pri5,pri6) :GetCurrentTime(_,_,dat3,_), GoCurrency(cur1,cou5,pri2),
GoCurrency(_,cou5,pri5), Add($pri2,$pri5,pri12), Add($pri2,$pri6,pri12).

first financial service provided stock quote information, system learnt
source returned exactly information stock market service provided Yahoo.
also able work previous days close plus todays change equal
current price. second source provided rate exchange currencies
given input. case, system fare well. unable learn intended
result, involved calculating exchange rate taking ratio values
first second currency.
Problem
10
11

# Candidates
2844
367

# Invocations
16671
16749

Time (s)
387
282

log10 (Score)
-8.13
-9.84

Precision
12/13
1/5

Recall
12/12
1/4

Details regarding search spaces two problems shown above. average
precision recall problems much lower 56% 63% respectively,
system unable learn intended definition second problem.
15. positive value problem 4 results approximation error.
16. Low scores perfect precision recall (problems 6, 8 9) indicate little overlap
target known sources. fact system learns correct definition cases
testimony robustness approach.

35

fiCarman & Knoblock

7.3.3 Weather Sources
Internet, two types weather information services, provide
forecasts coming days, provide details current weather conditions.
experiments, pair services provided Weather.com used learn definitions number weather sources. first set definitions, correspond
sources provide current weather conditions, listed below:
12 NOAAWeather($ica0,air1,_,_,sky4,tem5,hum6,dir7,spe8,_,pre10,tem11,_,_) :GetAirportInfo($ica0,_,air1,cit3,_,_),
WeatherForecast($cit3,_,_,_,_,_,_,_,_,_,_,_,sky4,dir7,_,_),
WeatherConditions($cit3,_,_,_,_,_,_,_,_,tem5,sky4,pre33,_,spe8,hum6,tem11),
ConvertIn2mb($pre33,pre10).
13 WunderGround($sta0,$cit1,tem2,_,_,pre5,pre6,sky7,dir8,spe9,spe10) :WeatherConditions($cit1,sta0,_,_,_,_,_,_,dat8,tem9,sky7,pre5,dir8,spe13,_,tem2),
WeatherForecast($cit1,sta0,_,_,_,_,_,_,tem24,_,_,_,_,_,spe10,_),
ConvertIn2mb($pre5,pre6),<(tem9,tem24),ConvertTime($dat8,_,_,_,_),<(spe9,spe13).
14 WeatherBugLive($_,cit1,sta2,zip3,tem4,_,_,dir7,_,_) :WeatherConditions($cit1,sta2,_,_,_,_,_,_,_,tem4,_,_,dir7,_,_,_),
GetZipcode($cit1,$sta2,zip3).
15 WeatherFeed($cit0,$_,tem2,_,sky4,tem5,_,_,pre8,lat9,_,_) :WeatherConditions($cit0,_,_,lat9,_,_,_,_,_,_,sky4,pre8,dir12,_,_,tem5),
WeatherForecast($cit0,_,_,_,_,_,_,_,_,tem2,_,_,_,dir12,_,_).
16 WeatherByICAO($ica0,air1,cou2,lat3,lon4,_,dis6,_,sky8,_,_,_,_) :Altitude($lat3,$lon4,dis6), GetAirportInfo($ica0,_,air1,cit6,_,cou8),
WeatherForecast($cit6,_,cou8,_,_,_,_,_,_,_,_,_,sky8,_,_,_),
GetCountryName($cou2,cou8).
17 WeatherByLatLon($_,$_,_,_,_,lat5,lon6,_,dis8,_,_,_,_,_,_) :Altitude($lat5,$lon6,dis8).

first problem, system learnt source 12 provided current conditions airports,
checking weather report cities airport located.
particular problem demonstrates advantages learning definitions new
sources described section 3.3. definition learnt, mediator receives
request current conditions airport, generate answer query
executing single call newly modeled source, (without needing find nearby
city). system performed well next three sources (13 15) learning definitions
cover attributes each. last two problems, system
perform well. case source 16, system spent time learning
attributes airport returned (such country, coordinates, elevation,
etc.). last case, system able learn source returning
coordinates along elevation. note different sources may provide
data different levels accuracy. Thus fact system unable learn
definition particular source could simply mean data returned
source wasnt sufficiently accurate system label match.
addition current weather feeds, system run two problems involving
weather forecast feeds. well first problem, matching bar one
attributes (the country) finding order high low temperatures
36

fiLearning Semantic Definitions Information Sources Internet

inverted. well also second problem, learning definition source
produced output attributes.
18 YahooWeather($zip0,cit1,sta2,_,lat4,lon5,day6,dat7,tem8,tem9,sky10) :WeatherForecast($cit1,sta2,_,lat4,lon5,_,day6,dat7,tem9,tem8,_,_,sky10,_,_,_),
GetCityState($zip0,cit1,sta2).
19 WeatherBugForecast($_,cit1,sta2,_,day4,sky5,tem6,_) :WeatherForecast($cit1,sta2,_,_,_,tim5,day4,_,tem6,_,tim10,_,sky5,_,_,_),
WeatherConditions($cit1,_,_,_,_,tim10,_,tim5,_,_,_,_,_,_,_,_).

Details regarding number candidates generated order learn definitions
different weather sources shown below. average precision definitions produced
91%, average recall 62%.
Problem
12
13
14
15
16
17
18
19

# Candidates
277
1989
98
199
102
45
119
116

# Invocations
579
426
2499
754
946
7669
13876
14857

Time (s)
233
605
930
292
484
1026
759
1217

log10 (Score)
-2.92
-6.35
-13.37
-6.48
-29.69
-26.71
-5.74
-12.56

Precision
8/9
6/9
5/5
5/6
6/7
3/3
10/10
5/5

Recall
8/11
6/10
5/8
5/10
6/9
3/13
10/11
5/7

7.3.4 Hotel Sources
Definitions also learnt sources providing hotel information Yahoo, Google
US Fire Administration. definitions shown below.
20 USFireHotelsByCity($cit0,_,_,sta3,zip4,cou5,_) :HotelsByZip($zip4,_,_,cit0,sta3,cou5).
21 USFireHotelsByZip($zip0,_,_,cit3,sta4,cou5,_) :HotelsByZip($zip0,_,_,cit3,sta4,cou5).
22 YahooHotel($zip0,$_,hot2,str3,cit4,sta5,_,_,_,_,_) :HotelsByZip($zip0,hot2,str3,cit4,sta5,_).
23 GoogleBaseHotels($zip0,_,cit2,sta3,_,_,lat6,lon7,_) :WeatherConditions($cit2,sta3,_,lat6,lon7,_,_,_,_,_,_,_,_,_,_,_),
GetZipcode($cit2,$sta3,zip0).

system performed well three four problems. unable time
allocated discover definition hotel attributes (name, street, latitude longitude) returned Google Web Service. average precision problems
90% average recall 60%.
Problem
20
21
22
23

# Candidates
16
16
43
95

# Invocations
448
1894
3137
4931

Time (s)
48
5
282
1161
37

log10 (Score)
-4.00
-2.56
-2.81
-7.50

Precision
4/4
4/4
5/5
3/5

Recall
4/6
4/6
5/9
3/6

fiCarman & Knoblock

7.3.5 Cars Traffic Sources
last problems system tested pair traffic related Web Services.
first service, provided Yahoo, reported live traffic data (such accidents
construction work) within given radius input zipcode. known sources
available provided information, surprisingly, system unable
learn definition traffic related attributes source. (Instead, system
discovered relationship input zipcode output longitude wasnt
correct, precision problem zero.)
24 YahooTraffic($zip0,$_,_,lat3,lon4,_,_,_) :GetCentroid($zip0,_,lon4), CountryCode($lat3,$lon4,_).
25 YahooAutos($zip0,$mak1,dat2,yea3,mod4,_,_,pri7,_) :GoogleBaseCars($zip0,$mak1,_,mod4,pri7,_,_,yea3),
ConvertTime($dat2,_,dat10,_,_), GetCurrentTime(_,_,dat10,_).

second problem involved classified used-car listing Yahoo took zipcode
car manufacturer input. eidos able learn good definition source,
taking advantage fact cars (defined make, model, year
price) also listed sale Googles classified car listing.
Problem
24
25

# Candidates
81
55

# Invocations
29974
405

Time (s)
1065
815

log10 (Score)
-11.21
-5.29

Precision
0/3
6/6

Recall
0/4
6/6

Since system failed first problem (it found incorrect/non-general relationships different attributes), succeeded second problem find best
possible definition, average precision recall problems 50%.
7.3.6 Overall Results
Across 25 problems, eidos managed generate definitions high accuracy (average
precision 88%) large number attributes (average recall 69%). results
promising, especially considering problems involved real data sources
cases small overlap data produced target provided
known sources (as evidenced low logarithmic scores). addition minimal
overlap, many sources provided incomplete tuples (i.e. tuples containing multiple NULL
N/A values) well erroneous inaccurate data, making problem
difficult. high average precision recall lead us believe Jaccard measure
good job distinguishing correct incorrect definitions presence
data sources noisy (inconsistent) incomplete (missing tuples values).
Comparing different domains, one see system performed better
problems fewer input output attributes (such geospatial problems),
expected given resulting search space much smaller.
38

fiLearning Semantic Definitions Information Sources Internet

7.4 Empirical Comparison
demonstrated effectiveness eidos learning definitions real information
services, show system capable handling problems
well-known complex schema matching system.
iMAP system (Dhamanka, Lee, Doan, Halevy, & Domingos, 2004) (discussed
section 8.4) schema matcher learn complex (many-to-one) mappings
concepts source target schema. uses set special purpose searchers
learn different types mappings. eidos system, hand, uses generic
search algorithm solve comparable problem. Since two systems made
perform similar task, show eidos capable running one problem
domains used evaluation iMAP. chose particular domain online cricket
databases one used evaluation involved aligning data
two independent data sources. (All problems involved generating synthetic data
splitting single database source target schema, would
interesting eidos.)
Player statistics two online cricket databases (cricketbase.com cricinfo.com)
used experiments. Since neither sources provided programmatic access
data, statistics data extracted HTML pages inserted
relational database. extraction process involved flattening data relational
model small amount data cleaning. (The resulting tables similar
necessarily exactly used iMAP experiments.) data
two websites used create three data sources representing website. three
sources representing cricinfo.com used learn definitions three sources
representing cricketbase.com. known sources available system, including
functionality splitting apart comma-separated lists, adding multiplying numbers,
on. definitions learnt describe cricketbase services shown below:
1 CricbasePlayers($cou0,nam1,_,dat3,_,unk5,unk6) :CricinfoPlayer($nam1,dat3,_,_,_,lis5,nam6,unk5,unk6), contains($lis5,cou0),
CricinfoTest($nam6,_,_,_,_,_,_,_,_,_,_,_,_,_,_,_,_,_,_,_,_,_).
2 CricbaseTest($_,nam1,cou2,_,_,_,cou6,cou7,dec8,cou9,_,_,_,cou13,cou14,dec15,_,
dec17,cou18,_,_) :CricinfoTest($nam1,_,_,cou2,cou6,cou18,cou7,_,dec8,dec15,_,cou9,_,_,_,cou14,
cou13,_,_,_,_,dec17).
3 CricbaseODI($_,nam1,cou2,_,_,_,cou6,cou7,dec8,cou9,cou10,_,cou12,cou13,_,dec15,
dec16,dec17,cou18,cou19,_) :CricinfoODI($nam1,_,_,cou2,cou6,_,cou10,_,dec8,_,cou7,cou18,cou19,cou9,_,_,
cou13,cou12,dec15,_,dec16,dec17).

first source provided player profiles country. second third sources provided
detailed player statistics two different types cricket (Test One-Day-International
respectively). system easily found best definition first source. definition
involved looking players country list teams played for. eidos
perform quite well second third problems. two reasons
this. Firstly, arity sources much higher many instances
semantic type (count decimal ), making space possible alignments much larger.
39

fiCarman & Knoblock

(Because large search space, longer timeout 40 minutes used.) Secondly,
high frequency null values (the constant N/A) data fields
confused algorithm, made harder discover overlapping tuples
desired attributes.
Problem
1
2
3

# Candidates
199
1162
3114

# Invocations
3762
1517
4299

Time (s)
432
1319
2127

log10 (Score)
-3.95
-4.70
-6.28

Precision
5/5
8/11
8/14

Recall
5/5
8/16
8/16

Details search performed learn definitions shown above. average
precision problems 77% average recall lower 66%.
values comparable quality matchings reported iMAP.17 results
good, considering eidos searches space many-to-many correspondences,
(trying define set target attributes contemporaneously), iMAP searches
spaces one-to-one many-to-one correspondences. Moreover, eidos first invokes
target source generate representative data (a task performed iMAP)
performs generic search reasonable definitions without relying specialised search
algorithms different types attributes (as done iMAP).

8. Related Work
section describe work paper relates research performed
Machine Learning, Database Semantic Web communities. that,
describe early work performed Artificial Intelligence community. also
discuss algorithm differs standard ILP techniques, particular
direct application techniques possible problem.
8.1 Early Approach
first work concerned learning models describing operations available
Internet performed (in pre-XML era) problem called category translation
(Perkowitz & Etzioni, 1995; Perkowitz, Doorenbos, Etzioni, & Weld, 1997). problem
consisted incomplete internal world model external information source
goal characterize information source terms world model.
world model consisted set objects O, object belonged certain
category (e.g. people) associated set attributes ha1 (o), ..., (o)i, made
strings objects. simple relational interpretation world model would
consider category relation, object tuple. information
source, meanwhile, operation took single value input returned
single tuple output. category translation problem viewed simplification
source definition induction problem, whereby:
17. actual values precision recall cricket domain quoted, accuracy range
68-92% simple matches (one-to-one correspondences source target fields) 50-86%
complex matches (many-to-one correspondences) across synthetic real problems given.

40

fiLearning Semantic Definitions Information Sources Internet

extensions global relations explicit. (There one source per global
relation, doesnt binding constraints, i.e. R = S.)
information provided sources change time.
new source takes single value input returns single tuple output.
order find solutions instances category translation problem, authors employed variant relational path-finding (Richards & Mooney, 1992), extension
foil algorithm, learn models external source. technique described
paper solving instances source induction problem similar
based foil-like inductive search algorithm.
8.2 Direct Application ILP techniques
Researchers became interested field Inductive Logic Programming early
nineties, resulting number different ILP systems developed including foil
(Cameron-Jones & Quinlan, 1994), progol (Muggleton, 1995) aleph18 . Ideally, one
would like apply off-the-shelf ILP systems source definition induction
problem. number issues, however, limit direct applicability systems.
issues summarised follows:





Extensions global relations virtual.
Sources may incomplete respect definitions.
Explicit negative examples target available.
Sources may serialise constants different ways.

first issue fact ILP systems assume extensional
definition target predicate extensional (or cases intentional) definitions
(source) predicates used definition target. words,
assume tables already exist relational database represent
new source known sources. case, need generate tables first
invoking services relevant inputs. One could envisage invoking sources
every possible input using resulting tables perform induction. direct
approach would feasible two reasons. Firstly, complete set possible input
values may known system. Secondly, even possible generate
complete set viable inputs service, may practical query source
large set tuples. Consider source4 section 2, calculates distance
miles two zipcodes. Given 40,000 zipcodes US, generating
extensional representation source would require performing billion
invocations! Performing large number invocations make sense
small number example invocations would suffice characterising functionality
source. paper developed efficient algorithm queries
sources needed order evaluate individual candidate definitions.
second issue regarding incompleteness sources causes problem
candidate evaluated. Since set tuples returned known source may
18. See Aleph Manual Ashwin Srinivasan, available at:
http://web.comlab.ox.ac.uk/oucl/research/areas/machlearn/Aleph/aleph.html

41

fiCarman & Knoblock

subset implied definition, set tuples returned
candidate hypothesis executed sources. means
system tries evaluate hypothesis comparing tuples output
new source, cannot sure tuple produced new source
hypothesis fact logically implied it. fact taken account
evaluation function scoring candidate definitions, discussed section 5.
third issue regarding lack explicit negative examples target predicate
also affects evaluation candidate hypotheses. classic approach dealing
problem assume closed world, tuples (over head relation)
explicitly declared positive must negative. Since new source may
fact incomplete respect best possible definition it, assumption
necessarily hold. words, particular tuple produced
candidate definition executed tuple returned new source
necessarily mean candidate definition incorrect.
fourth issue fact data provided different sources may
need reconciled, sense different serialisations (strings representing)
value (such Monday Mon instance) must recognized. Since ILP
systems designed operate single database containing multiple tables,
issue heterogeneity data handled current systems. section 5.4
discussed heterogeneity resolved system.
8.3 Machine Learning Approaches
Since advent services Internet, researchers investigating ways
model automatically. Primarily, interest centered using machine learning
techniques classify input output types service, facilitate service
discovery. & Kushmerick proposed using Support Vector Machine classify
input output attributes different semantic types based metadata interface
descriptions (He & Kushmerick, 2003, 2004). notion semantic types (such
zipcode) opposed syntactic types (like integer ) went way toward defining
functionality source provides. Recently, researchers (Lerman et al., 2006)
proposed use logistic regression assigning semantic types input parameters
based metadata, pattern language assigning semantic types output
parameters based data source produces. work classifying input
output attributes service semantic types forms prerequisite work
article. purposes paper, assumed problem solved.
addition classifying input/output attributes services, & Kushmerick
investigated idea classifying services different service types.
precisely, used classification techniques assign service interfaces different semantic domains (such weather flights) operations interface
provides different classes operation (such weatherForecast flightStatus).
resulting source description (hypothesis) language limited select-project queries,
sufficiently expressive describe many sources available Internet.
According approach, since every operation must characterized particular operation class, operations provide overlapping (non-identical) functionality would
42

fiLearning Semantic Definitions Information Sources Internet

need assigned different classes would operations provide composed functionality (such as, example, operation provides weather flight data).
need exhaustive set operation classes (and accompanying training data) major
limitation approach, shared work described paper, relies
expressive language describing service operations.
One way eliminate need predefined set operation types use unsupervised clustering techniques generate (operation) classes automatically examples
(WSDL documents). idea implemented system called Woogle (Dong et al.,
2004). system clustered service interfaces together using similarity score based
co-occurrence metadata labels. took advantage clusters produced improve keyword-based search Web Services. advantage unsupervised approach
labeled training data required, time-consuming generate.
clustering approaches, however, useful service discovery, suffer limitations
previous approach comes expressiveness.
8.4 Database Approaches
database community long interested problem integrating data
disparate sources. Specifically, areas data warehousing (Widom, 1995) information integration (Wiederhold, 1996), researchers interested resolving semantic
heterogeneity exists different databases data combined
accessed via single interface. schema mapping problem problem determining
mapping relations contained source schema particular relation
target schema. mapping defines transformation used populate
target relation data source schema. Mappings may arbitrarily complex
procedures, general declarative queries SQL Datalog. complexity queries makes schema mapping problem far difficult highly
investigated schema matching problem (Rahm & Bernstein, 2001), involves finding
1-to-1 correspondences fields source target schema.
source definition induction problem viewed type schema mapping
problem, known sources define source schema unknown source
specifies target relation. order solve schema mapping problem, one typically
takes advantage available auxiliary information (including source target data
instances, labels respective schemas, on). problems generally
simpler, however, data (the extensions relations) source target
schema usually explicitly available. source induction, data hidden behind
service interface, binding constraints, data extremely large
even (in case sources providing mathematical functions) infinite. Thus making
problem considerably difficult.
schema integration system CLIO (Yan, Miller, Haas, & Fagin, 2001) helps users
build SQL queries map data source target schema. CLIO, foreign keys
instance data used generate integration rules semi-automatically. Since CLIO
relies heavily user involvement, make sense compare directly
automated system developed paper.
43

fiCarman & Knoblock

Another closely related problem complex schema matching, goal
discover complex (many-to-one) mappings two relational tables XML schemas.
problem far complicated basic (one-to-one) schema matching because:
space possible correspondences relations longer Cartesian
product source target relations, powerset source relation times
target relation.
Many-to-one mappings require mapping function, simple like concatenate(x,y,z), arbitrarily complex formula z = x2 + y.
iMAP system (Dhamanka et al., 2004) tries learn many-to-one mappings concepts set source relations target relation. uses set special
purpose searchers learn different types mappings (such mathematical expressions,
unit conversions time/date manipulations). uses meta-heuristic control
search performed different special purpose searchers. one views
source schema functions available use mappings (such concatenate(x,y,z), add(x,y,z), etc.) set known sources source definition induction
problem, complex schema matching source induction problems somewhat
similar. main differences problems are:
data associated source schema explicit (and static) complex schema
matching, hidden (and dynamic) source induction.
general, set known sources source induction problem much larger
(and data provide may less consistent), set mapping functions
source relations complex schema matching problem.
paper develop general framework handling source induction problem.
Since iMAP provides functionality similar system, perform
simple empirical comparison section 7.4.
8.5 Semantic Web Approach
stated goal Semantic Web (Berners-Lee, Hendler, & Lassila, 2001) enable
machine understanding Web resources. done annotating resources
semantically meaningful metadata. Thus work described paper much
line Semantic Web, far attempting discover semantically
meaningful definitions online information sources. De facto standards annotating
services semantic markup around number years. standards
provide service owners metadata language adding declarative statements service
interface descriptions attempt describe semantics service terms
functionality (e.g. book purchase operation) data (e.g. weather forecast)
provides. Work languages related article two perspectives:
viewed alternative approach gaining knowledge semantics
newly discovered source (providing semantic metadata associated it).
Semantic Web Service annotation languages seen target language
semantic descriptions learnt paper.
44

fiLearning Semantic Definitions Information Sources Internet

Web Service already semantically annotated, heterogeneity may still exist
ontology used service provider used consumer, case
learning capabilities described paper may required reconcile differences.
importantly, interested vast number sources semantic
markup currently unavailable. work article complements Semantic
Web community providing way automatically annotating sources semantic
information; thereby relieving service providers burden manually annotating
services. learnt, Datalog source definitions converted Description Logicbased representations used OWL-S (Martin, Paolucci, McIlraith, Burstein,
McDermott, McGuinness, Parsia, Payne, Sabou, Solanki, Srinivasan, & Sycara, 2004)
WSMO (Roman, Keller, Lausen, de Bruijn, Lara, Stollberg, Polleres, Feier, Bussler, &
Fensel, 2005). reason use Datalog paper (rather Description Logics)
mediator-based integration systems rely representation language.

9. Discussion
paper presented completely automatic approach learning definitions
online services. approach exploits definition sources either given
system learned previously. resulting framework significant advance
prior approaches focused learning inputs outputs class
service. demonstrated empirically viability approach.
key contribution article procedure learning semantic definitions
online information services is:
Fully automated : Definitions learnt completely automated manner without
need user intervention.
expressive: query language defining sources conjunctive
queries, far expressive previous attribute-value approaches.
Sufficiently robust: procedure able learn definitions presence noisy
incomplete data, thus sufficiently robust handle real data sources.
Data-access efficient: procedure samples data live sources, invoking
sparingly required, making highly efficient terms source accesses.
Evolving: procedures ability learn definitions improves time new
definition learnt added set known sources.
9.1 Application Scenarios
number different application scenarios system capable learning
definitions online sources. generally involve providing semantic definitions data
integration systems, exploit integrate available sources.
obvious application work would system (depicted left side
Figure 1) crawls Web, searching information sources. Upon finding source,
system would use classifier assign semantic types it, followed inductive
learner generate definition it. definition could used annotate
source Semantic Web, mediator answering queries. Importantly,
entire process could run minimal user involvement.
45

fiCarman & Knoblock

Figure 1: Architecture diagrams three different application scenarios.

challenging application scenario (shown center Figure 1) would involve
real-time service discovery. Consider case mediator unable answer
particular query desired information lies scope sources available.
search performed based missing conjuncts (relation names constants)
query using specialised Web Service search engine, Woogle (Dong et al.,
2004). services returned would annotated semantic types and, possible,
semantic definitions. definitions provided mediator, would complete
query processing return answer user. scenario may seem little farfetched one considers specific example: imagine user interacting geospatial
browser (an online atlas). user turns particular information layer, ski
resorts, source available current field view (of, instance, Italy),
results would displayed. background search could performed new
source discovered, provides ski resorts Europe. relevant data could
displayed, user unaware search performed.
Perhaps likely application scenario (to right Figure 1) source
induction system would mixed initiative one. case human would annotate
different operations service interface semantic definitions. time,
system would attempt induce definitions remaining operations, prompt
user suggestions them. scenario classifier may needed,
since attributes name different operations would likely
semantic type. Moreover, since definitions learnt system may cases
contain erroneous superfluous predicates, user could also involved process
checking improving definitions discovered.
46

fiLearning Semantic Definitions Information Sources Internet

9.2 Opportunities Research
number future directions work allow techniques applied
broadly. discuss two directions, improving search algorithm extending
query language.
number known sources grows, search space, necessary develop additional heuristics better direct search toward best definition.
Many heuristic techniques developed ILP community may
applicable source induction problem. pressing perhaps need develop
robust termination condition halting search sufficiently good definition
discovered. number available sources increases, simple timeout used
experiments ineffective certain (more complicated) definitions necessarily
take longer learn others.
Another way increase applicability work extend query language
better describes sources available. Often online sources return complete
set results rather cut list maximum cardinality. example
YahooHotel source described section 7.3.4 returns maximum 20 hotels near given
location, orders according distance. case, recognising specific
ordering tuples produced would useful mediator. second useful
extension query language would ability describe sources using procedural
construct if-then-else. construct needed describe behaviour sources
certain inputs. example, consider YahooGeocoder section 7.3.1, takes
input tuple containing street name, number, zipcode. geocoder unable
locate corresponding address database (because doesnt exist), instead
returning tuples, returns centroid zipcode. Describing behavior
possible using procedural constructs.

Acknowledgments
research based upon work supported part Defense Advanced Research
Projects Agency (DARPA), Department Interior, NBC, Acquisition Services Division, Contract No. NBCHD030010. U.S. Government authorized
reproduce distribute reports Governmental purposes notwithstanding copyright annotation thereon. views conclusions contained herein
authors interpreted necessarily representing official policies
endorsements, either expressed implied, organizations person
connected them.

References
Afrati, F. N., Li, C., & Mitra, P. (2004). containment conjunctive queries using arithmetic comparisions. 9th International Conference Extending Database Technology (EDBT 2004) Heraklion-Crete, Greece.
47

fiCarman & Knoblock

Arens, Y., Knoblock, C. A., & Shen, W.-M. (1996). Query reformulation dynamic
information integration. Journal Intelligent Information Systems - Special Issue
Intelligent Information Integration, 6 (2/3), 99130.
Berners-Lee, T., Hendler, J., & Lassila, O. (2001). semantic web. Scientific American,
284 (5), 3443.
Bilenko, M., Mooney, R. J., Cohen, W. W., Ravikumar, P., & Fienberg, S. E. (2003).
Adaptive name matching information integration.. IEEE Intelligent Systems, 18 (5),
1623.
Cameron-Jones, R. M., & Quinlan, J. R. (1994). Efficient top-down induction logic
programs. SIGART Bulletin, 5 (1), 3342.
Carman, M. J., & Knoblock, C. A. (2007). Learning semantic descriptions web information sources. Proceedings Twentieth International Joint Conference
Artificial Intelligence (IJCAI-07) Hyderabad, India.
Chandra, A. K., & Merlin, P. M. (1977). Optimal implementation conjunctive queries
relational data bases. Proceedings 9th ACM Symposium Theory
Computing (STOC), pp. 7790 Boulder, Colorado.
Dhamanka, R., Lee, Y., Doan, A., Halevy, A., & Domingos, P. (2004). imap: Discovering
complex semantic matches database schemas. SIGMOD 04: Proceedings
2004 ACM SIGMOD International Conference Management Data.
Dong, X., Halevy, A. Y., Madhavan, J., Nemes, E., & Zhang, J. (2004). Simlarity search
web services. Proceedings VLDB.
Duschka, O. M. (1997). Query Planning Optimization Information Integration. Ph.D.
thesis, Department Computer Science, Stanford University.
Garcia-Molina, H., Hammer, J., Ireland, K., Papakonstantinou, Y., Ullman, J., & Widom,
J. (1995). Integrating accessing heterogeneous information sources tsimmis.
Proceedings AAAI Symposium Information Gathering, pp. 61-64.
He, A., & Kushmerick, N. (2003). Learning attach semantic metadata web services.
2nd International Semantic Web Conference (ISWC).
He, A., & Kushmerick, N. (2004). Iterative ensemble classification relational data:
case study semantic web services. 15th European Conference Machine
Learning (ECML2004) Pisa, Italy. Springer.
Knoblock, C. A., Minton, S., Ambite, J. L., Ashish, N., Muslea, I., Philpot, A., & Tejada,
S. (2001). ariadne approach web-based information integration. International
Journal Cooperative Information Systems, 10 (1-2), 145169.
Lerman, K., Plangprasopchok, A., & Knoblock, C. A. (2006). Automatically labeling data
used web services. Proceedings 21st National Conference Artificial
Intelligence (AAAI).
48

fiLearning Semantic Definitions Information Sources Internet

Levy, A. Y. (2000). Logic-based techniques data integration. Minker, J. (Ed.), LogicBased Artificial Intelligence. Kluwer Publishers.
Levy, A. Y., Mendelzon, A. O., Sagiv, Y., & Srivastava, D. (1995). Answering queries using
views. Proceedings 14th ACM SIGACT-SIGMOD-SIGART Symposium
Principles Database Systems, pp. 95104 San Jose, Calif.
Markov, Z., & Marinchev, I. (2000). Metric-based inductive learning using semantic height
functions. Proceedings 11th European Conference Machine Learning
(ECML 2000). Springer.
Martin, D., Paolucci, M., McIlraith, S., Burstein, M., McDermott, D., McGuinness, D.,
Parsia, B., Payne, T., Sabou, M., Solanki, M., Srinivasan, N., & Sycara, K. (2004).
Bringing semantics web services: owl-s approach. Proceedings First
International Workshop Semantic Web Services Web Process Composition
(SWSWPC 2004).
Muggleton, S., & Feng, C. (1990). Efficient induction logic programs. Proceedings
1st Conference Algorithmic Learning Theory.
Muggleton, S. (1995). Inverse entailment Progol. New Generation Computing, Special
issue Inductive Logic Programming, 13 (3-4), 245286.
Nedellec, C., Rouveirol, C., Ade, H., Bergadano, F., & Tausend, B. (1996). Declarative
bias ILP. De Raedt, L. (Ed.), Advances Inductive Logic Programming, pp.
82103. IOS Press.
Pazzani, M. J., & Kibler, D. F. (1992). utility knowledge inductive learning.
Machine Learning, 9, 5794.
Perkowitz, M., & Etzioni, O. (1995). Category translation: Learning understand information internet. Proceedings Fourteenth International Joint Conference
Artificial Intelligence (IJCAI-95).
Perkowitz, M., Doorenbos, R. B., Etzioni, O., & Weld, D. S. (1997). Learning understand information internet: example-based approach. Journal Intelligent
Information Systems, 8 (2), 133153.
Pottinger, R., & Halevy, A. Y. (2001). Minicon: scalable algorithm answering queries
using views. VLDB Journal, 10 (2-3).
Quinlan, J. R., & Cameron-Jones, R. M. (1993). FOIL: midterm report. Machine
Learning: ECML-93, European Conference Machine Learning, Proceedings, Vol.
667, pp. 320. Springer-Verlag.
Rahm, E., & Bernstein, P. (2001). survey approaches automatic schema matching.
VLDB Journal, 10 (4).
Richards, B. L., & Mooney, R. J. (1992). Learning relations pathfinding. National
Conference Artificial Intelligence, pp. 5055.
49

fiCarman & Knoblock

Roman, D., Keller, U., Lausen, H., de Bruijn, J., Lara, R., Stollberg, M., Polleres, A.,
Feier, C., Bussler, C., & Fensel, D. (2005). Web service modeling ontology. Applied
Ontology, 1 (1), 77106.
Ullman, J. D. (1989). Principles Database Knowledge-Base Systems, Vol. 2. Computer Science Press, Rockville, Maryland.
Weber, I., Tausend, B., & Stahl, I. (1995). Language series revisited: complexity
hypothesis spaces ILP. Proceedings 8th European Conference Machine
Learning, Vol. 912, pp. 360363. Springer-Verlag.
Widom, J. (1995). Research problems data warehousing. CIKM 95: Proceedings
fourth International Conference Information Knowledge Management, pp.
2530. ACM Press.
Wiederhold, G. (1992). Mediators architecture future information systems. Computer, 25 (3), 3849.
Wiederhold, G. (Ed.). (1996). Intelligent Integration Information. Kluwer Academic
Publishers, Boston MA.
Winkler, W. (1999). state record linkage current research problems. Tech. rep.,
Statistical Research Division, U.S. Bureau Census, Washington, DC.
Yan, L. L., Miller, R. J., Haas, L. M., & Fagin, R. (2001). Data-driven understanding
refinement schema mappings. SIGMOD 01: Proceedings 2001 ACM
SIGMOD International Conference Management data.
Zelle, J. M., Thompson, C. A., Califf, M. E., & Mooney, R. J. (1995). Inducing logic
programs without explicit negative examples. Proceedings Fifth International
Workshop Inductive Logic Programming.

50

fiJournal Artificial Intelligence Research 30 (2007) 621-657

Submitted 03/07; published 12/07

Query-time Entity Resolution
Indrajit Bhattacharya

indrajbh@in.ibm.com

IBM India Research Laboratory
Vasant Kunj, New Delhi 110 070, India

Lise Getoor

getoor@cs.umd.edu

Department Computer Science
University Maryland, College Park, MD 20742 USA

Abstract
Entity resolution problem reconciling database references corresponding
real-world entities. Given abundance publicly available databases
unresolved entities, motivate problem query-time entity resolution: quick
accurate resolution answering queries unclean databases query-time.
Since collective entity resolution approaches related references resolved jointly
shown accurate independent attribute-based resolution
off-line entity resolution, focus developing new algorithms collective resolution
answering entity resolution queries query-time. purpose, first formally
show that, collective resolution, precision recall individual entities follow
geometric progression neighbors increasing distances considered. Unfolding
progression leads naturally two stage expand resolve query processing strategy.
strategy, first extract related records query using two novel expansion
operators, resolve extracted records collectively. show
strategy adapted query-time entity resolution identifying resolving
database references helpful processing query.
validate approach two large real-world publication databases show
usefulness collective resolution time demonstrate need adaptive
strategies query processing. show queries answered
real-time using adaptive approach preserving gains collective resolution.
addition experiments real datasets, use synthetically generated data empirically
demonstrate validity performance trends predicted analysis collective
entity resolution wide range structural characteristics data.

1. Introduction
growing abundance publicly available data digital form, intense research data integration. critical component data integration process
entity resolution problem, uncertain references data real-world entities
people, places, organizations, events, etc., need resolved according
underlying real-world entities. Entity resolution needed order solve deduplication problem, goal identify consolidate pairs records references
within relational table duplicates other. also comes
fuzzy match problem, tuples two heterogeneous databases different keys,
possibly different schemas, need matched consolidated. goes different
c
2007
AI Access Foundation. rights reserved.

fiBhattacharya & Getoor

names even within data mining database communities, including record linkage,
object consolidation, reference reconciliation.
problem long history, recent years seen significant fruitful
research problem. However, spite widespread research interest
practical nature problem, many publicly accessible databases remain unresolved,
partially resolved, best. popular publication databases, CiteSeer PubMed,
representative examples. CiteSeer contains several records paper author,
author names PubMed resolved all. due variety reasons,
ranging rapid often uncontrolled growth databases computational
expenses involved maintaining resolved entities.
Yet, millions users access query databases everyday, mostly seeking information that, implicitly explicitly, requires knowledge resolved entities. example,
may query CiteSeer database computer science publications looking books
Russell (Pasula, Marthi, Milch, Russell, & Shpitser, 2003). query would easy
answer author names CiteSeer correctly mapped entities. But,
unfortunately, case. According CiteSeer records, Stuart Russell Peter
Norvig written 100 different books together. One main reasons behind databases containing unresolved entities entity resolution generally perceived
expensive process large databases. Also, maintaining clean database requires
significant effort keep pace incoming records. Alternatively, may searching
different online social network communities person named Jon Doe. case,
online community may individually records clean. Even then, query
results return records sources aggregated together may multiple
representations Jon Doe entity. Additionally, cases, sufficient
simply return records match query name, S. Russell Jon Doe exactly.
order retrieve references correctly, may need retrieve records similar
names well, Stuart Russel John Doe. And, importantly, results
useful, need partition records returned according real-world
entities correspond. on-the-fly partitioning returned results also
necessary accessing third-party external databases provide full access
possibly due privacy concerns, accessed via specific query
interfaces.
paper, propose alternative solution answering entity resolution queries,
obviate need maintaining resolved entities database. Instead,
investigate entity resolution query-time, goal enable users query
unresolved partially resolved database resolve relevant entities fly. user
may access several databases everyday want resolve entities every
database queries. needs resolve entities relevant
particular query. instance, looking books Stuart Russell CiteSeer,
useful resolve authors CiteSeer. Since resolution needs
performed query-time, requirement resolution process needs quick,
even entirely accurate.
Though entity resolution queries addressed literature,
significant progress general entity resolution problem. Recent research focused use additional relational information database references improve
622

fiQuery-time Entity Resolution

resolution accuracy (Bhattacharya & Getoor, 2004; Singla & Domingos, 2004; Dong, Halevy,
& Madhavan, 2005; Ananthakrishna, Chaudhuri, & Ganti, 2002; Kalashnikov, Mehrotra, &
Chen, 2005). improvement made possible resolving related references records
jointly, rather independently. Intuitively, corresponds notion figuring
two records refer underlying entity may turn give us useful information resolving record pairs related. Imagine trying decide
two authors Stuart Russell Russell person. confident
decision already decided co-authors Peter Norvig P.
Norvig person.
others done, earlier work (Bhattacharya & Getoor, 2004, 2007),
demonstrated using extensive experiments multiple real synthetic datasets
collective resolution significantly improves entity resolution accuracy attribute-based
naive relational baselines. However, application query-time entity resolution
straight-forward, precisely problem focus paper.
first difficulty collective resolution works database whole
specific query. Secondly, accuracy improvement comes considerable computation
cost arising dependencies related resolutions. added computational
expense makes application query-time resolution challenging.
paper, builds significantly extends work presented Bhattacharya, Licamele, Getoor (2006), investigate application collective resolution queries. First, formally analyze accuracies different decisions collective
resolution depend structural characteristics data. recursive nature dependency leads naturally recursive expand resolve strategy
processing queries. relevant records necessary answering query extracted
recursive expansion process collective resolution performed extracted records. Using analysis, show recursive expansion process
terminated reasonably small depths accurately answering query; returns fall
exponentially neighbors away considered.
However, problem unconstrained expansion process return many
records even small depths; thus query may still impossible resolve
real-time. address issue using adaptive strategy considers
informative related records answering query. significantly reduces
number records need investigated query time, but, importantly,
compromise resolution accuracy query.
specific contributions paper follows:
1. First, motivate formulate problem query-time entity resolution.
entity resolution approach based relational clustering algorithm. best
knowledge, clustering based queries presence relations received
little attention literature.
2. collective resolution using relational clustering, present analysis
accuracy different resolution decisions depends structural
characteristics data. introduce notion precision recall individual entities, show follow geometric progression neighbors
increasing distances considered resolved. analysis shows collective
623

fiBhattacharya & Getoor

use relationships sometimes hurt entity resolution accuracy.
previously reported literature. analysis additionally demonstrates convergent nature resolution performance recursive query-resolution strategy
propose.
3. resolving queries collectively, propose two-phase expand resolve algorithm. first extracts related records query using two novel expansion
operators, resolves query considering extracted records.
improve algorithm using adaptive approach selectively considers
informative ones among related records query. enables
collective resolution query-time without compromising resolution accuracy
query.
4. present experimental results two large real-world datasets strategy
enables collective resolution seconds. compare multiple baselines
show accuracy achieved using collective query resolution significantly higher
achieved using traditional approaches.
5. also use synthetically generated data demonstrate gains collective query
resolution wide range attribute relational characteristics. additionally show empirical results agreement trends predicted
analysis collective resolution.
rest paper organized follows. Section 2, formalize relational
entity resolution problem entity resolution queries, also illustrate
example. Section 3, briefly review relational clustering algorithm employ
collective entity resolution then, Section 4, investigate resolution accuracy
related entities depend collective resolution using algorithm.
Section 5, extend collective resolution queries, describe analyze unconstrained recursive strategy collectively resolving query. modify approach
Section 6 present adaptive algorithm extracts informative
references resolving query. present experimental results real synthetic data
Section 7, review related work Section 8 finally conclude Section 9.

2. Entity Resolution Queries: Formulation
section, formally introduce entity resolution problem also entity resolution
queries, illustrate using realistic example resolving authors
citation database CiteSeer PubMed.
simplest formulation entity resolution problem, collection
references, R = {ri }, attributes {R.A1 , . . . , R.Ak }. Let E = {ej } unobserved
domain entities. particular reference ri , denote entity maps
E(ri ). say two references ri rj co-referent correspond
entity, E(ri ) = E(rj ). Note case unresolved database,
mapping E(R) provided. Further, domain entities E even number
entities known. However, many domains, may additional information
relationships references. model relationships generic way, use
624

fiQuery-time Entity Resolution

h1

h2

Mouse Immunity Model

r1
W Wang

r2
C Chen

r3

r4

r5

Ansari

W Wang

Ansari

h 3 Measuring Protienbound Fluxetine
r6
r7
r8
L Li

C Chen

Better Mouse Immunity Model

h 4 Autoimmunity Biliary Cirrhosis
r9
r 10
W W Wang

W Wang

Ansari

Figure 1: example set papers represented references connected hyper-edges.
References represented ovals shaded according entities. paper
represented hyper-edge (shown rectangle) spanning multiple references.

set hyper-edges H = {hi }. hyper-edge connects multiple references. capture
this, associate set references hi .R hyper-edge hi . Note reference
may associated zero hyper-edges.
Let us look sample domain see represented framework.
Consider database academic publications similar DBLP, CiteSeer PubMed.
publication database set author names. every author name,
reference ri R. reference ri , ri .N ame records observed name author
publication. addition, attributes R.Email record
information author reference may available paper. come
relationships domain. author references publication connected
co-author relationship. represented using hyper-edge hi H
publication rj hi .R reference rj publication.
publications additional information title, keywords, etc, represented
attributes H.
illustrate, consider following four papers, use running example:
1. W. Wang, C. Chen, A. Ansari, mouse immunity model
2. W. Wang, A. Ansari, better mouse immunity model
3. L. Li, C. Chen, W. Wang,Measuring protein-bound fluxetine
4. W. W. Wang, A. Ansari, Autoimmunity biliary cirrhosis
represent notation, 10 references {r1 , . . . , r10 } R, one
author name, r1 .N ame = W Wang, etc. also 4 hyper-edges {h1 , . . . , h4 }
H, one paper. first hyper-edge h1 connects three references r1 , r2
r3 corresponding names W. Wang , C. Chen A. Ansari. represented
pictorially Figure 1.
Given representation, entity resolution task defined partitioning
clustering references according underlying entity-reference mapping E(R).
Two references ri rj assigned cluster
625

fiBhattacharya & Getoor

coreferent, i.e., E(ri ) = E(rj ). illustrate, assume six underlying entities
example. illustrated Figure 1 using different shading entity.
example, Wangs papers 1, 2 4 names individual Wang
paper 3 reference different person. Also, Chens papers 1 3
different individuals. Then, correct entity resolution example database 10
references returns 6 entity clusters: {{r1 , r4 , r9 }, {r8 }, {r2 }, {r7 }, {r3 , r5 , r10 }, {r6 }}.
first two clusters correspond two different people named Wang, next two two
different people named Chen, fifth Ansari last Li.
query database references called entity resolution query answering
requires knowledge underlying entity mapping E(R). consider two different
types entity resolution queries. commonly, queries specified using particular
value attribute R.A references serves quasi-identifier
underlying entities. answer query Q(R.A = a) partition group
references r.A = according underlying entities. references
people, name often serves weak noisy identifier. example bibliographic
domain, consider queries specified using R.N ame. retrieve papers written
person named W. Wang, issue query using R.N ame W. Wang. Since
names ambiguous, treating identifiers leads undesirable results. case,
would incorrect return set {r1 , r4 , r8 } references name W Wang
answer query. answer indicate r8 person
two. Additionally, answer include reference r9 W W Wang,
maps entity author first paper. Therefore, correct answer
entity resolution query W Wang partition {{r1 , r4 , r9 }, {r8 }}.
Entity resolution queries may alternatively specified using specific reference. Imagine CiteSeer user looking paper contains author name. user may
interested looking papers written author, even though may
know author precisely. correct answer query reference
r group references coreferent r, or, words, correspond
underlying entity. example, consider query specified using reference r1
corresponding name W. Wang first paper. correct answer
query set references {r1 , r4 , r9 }. distinguish first type entity
resolution query, note include cluster {r8 } corresponding
entity also name W. Wang. second query type may answered first
reducing instance first type Q(R.A = r1 .A), selecting entity
corresponding reference r1 . denote E(R)=E(r1 ) (Q(R.A = r1 .A)). rest
paper, focus queries first type.

3. Collective Entity Resolution Relational Clustering
Although entity resolution queries studied literature, general
entity resolution problem received lot attention. review related work detail
Section 8. section, briefly review different categories proposed approaches
discussing may adapted query-time entity resolution.
entity resolution applications, data labeled underlying entities hard
acquire. focus unsupervised approaches resolving entities. Traditionally,
626

fiQuery-time Entity Resolution

attributes individual references, names, affiliation, etc., person references,
used comparing references. similarity measure generally employed attributes,
pairs references attribute similarity certain threshold
considered co-referent. attribute-based entity resolution approach (A)
often runs problems. example, hard infer attributes
references r1 r8 co-referent although name, r1 r9
co-referent although names different.
relations references available, may also taken account
computing similarities naive relational entity resolution approach (NR)
(Ananthakrishna et al., 2002; Bhattacharya & Getoor, 2007). computing similarities
two references, approach additionally considers attributes related
references comparing attributes related references. example,
approach returns higher similarity r1 (W. Wang) r9 (W. W. Wang)
attribute-based approach, since co-authors r3 r10 similar (identical, case) names. Although approach improve performance cases,
always work. instance, two W. Wang references r1 r8
co-referent, though co-authors identical names C. Chen.
Instead considering attribute similarities related references, collective
entity resolution approach (Pasula et al., 2003; Bhattacharya & Getoor, 2004; Singla
& Domingos, 2004; McCallum & Wellner, 2004; Li, Morie, & Roth, 2005; Dong et al.,
2005; Kalashnikov et al., 2005) takes account resolution decisions them.
previous example, correct evidence use pair references r1 r8
co-author references map entity, although similar names.
Therefore, order resolve W. Wang references collective resolution approach,
necessary resolve C. Chen references well, instead considering similarity
attributes. collective entity resolution approach recently shown
improve entity resolution accuracy previous approaches computationally
challenging. references cannot resolved independently. Instead, resolution
decision affected resolutions hyper-edges.
earlier work (Bhattacharya & Getoor, 2004, 2006, 2007), developed relational
clustering algorithm (RC-ER) collective entity resolution using relationships. goal
approach cluster references according entities taking relationships
account. associate cluster label r.C reference denote current
cluster membership. Starting initial set clusters C = {ci } references,
algorithm iteratively merges pair clusters similar. capture
collective nature cluster assignment, similarity measure pairs clusters
considers cluster labels related references. similarity two clusters ci
cj defined linear combination attribute similarity simA relational
similarity simR :
sim(ci , cj ) = (1 ) simA (ci , cj ) + simR (ci , cj )

(1)

(0 1) combination weight. interesting aspect collective
approach dynamic nature relational similarity. similarity two
references depends current cluster labels related references, therefore
changes related references change clusters. example, similarity two
627

fiBhattacharya & Getoor

clusters containing references W. Wang W. W. Wang increases co-author
references named A. Ansari assigned cluster. briefly review
two components similarity measure defined.
Attribute Similarity: reference attribute, use similarity measure
returns value 0 1 two attribute values indicating degree similarity
them. Several sophisticated similarity measures developed names,
popular TF-IDF schemes may used textual attributes keywords.
measure works best attribute may chosen. Finally, weighted linear
combination similarities different attributes yields combined attribute
similarity two reference clusters.
Relational Similarity: Relational similarity two clusters considers similarity cluster neighborhoods. neighborhood cluster defined
hyper-edges associated references cluster. Recall reference r
associated one hyper-edges H. Therefore, hyper-edge set c.H
cluster c references defined
c.H =

[

{h | h H r h.R}

(2)

rRr.C=c

set defines hyper-edges connect cluster c clusters,
ones relational similarity needs consider. illustrate, references
running example correctly clustered Figure 1(b), hyper-edge set
larger Wang cluster {h1 , h2 , h4 }, hyper-edges associated
references r1 , r4 r9 cluster.
Given hyper-edge set cluster c, neighborhood N br(c) cluster c
set clusters labels references spanned hyper-edges:
N br(c) =

[

{cj | cj = r.C}

(3)

hc.H,rh

example Wang cluster, neighborhood consists Ansari cluster one
Chen clusters, connected edge-set. Then, relational similarity
measure two clusters, considers similarity cluster neighborhoods.
neighborhoods essentially sets (or multi-sets) cluster labels many possible ways define similarity two neighborhoods (Bhattacharya & Getoor, 2007).
specific similarity measure use experiments paper Jaccard
similarity1 :
simR (ci , cj ) = Jaccard(N br(ci ), N br(cj ))
(4)
Clustering Algorithm: Given similarity measure pair clusters, greedy
relational clustering algorithm used collective entity resolution. Figure 2 shows
high-level pseudo-code complete algorithm. algorithm first identifies candidate set potential duplicates using blocking approach (Hernandez & Stolfo, 1995;
Monge & Elkan, 1997; McCallum, Nigam, & Ungar, 2000). Next, initializes clusters
1. Jaccard similarity two sets B defined Jaccard(A, B) =

628

|AB|
|AB|

fiQuery-time Entity Resolution

1.
2.

Algorithm RC-ER (Reference set R)
Find similar references R using blocking
Initialize clusters using bootstrapping

3.
4.

clusters ci , cj similar(ci , cj )
Insert hsim(ci , cj ), cj , cj priority queue

5.
6.
7.
8.
9.
10.
11.
12.
13.
14.

priority queue empty
Extract hsim(ci , cj ), ci , cj queue
sim(ci , cj ) less threshold, stop
Merge ci cj new cluster cij
Remove entries ci cj queue
cluster ck similar(cij , ck )
Insert hsim(cij , ck ), cij , ck queue
cluster cn neighbor cij
ck similar(ck , cn )
Update sim(ck , cn ) queue
Figure 2: High-level description relational clustering algorithm

references, identifies similar clusters potential merge-candidates
cluster, inserts merge-candidates priority queue iterates
following steps. step, identifies current closest pair clusters candidate set merges create new cluster. identifies new candidate pairs
updates similarity measures related cluster pairs. key step
evidence flows one resolution decision related ones distinguishes relational clustering traditional clustering approaches. algorithm terminates
similarity closest pair falls threshold list potential candidates exhausted. algorithm efficiently implemented run O(nk log n) time
n references block similar names connected k blocks
hyper-edges.
3.1 Issues Collective Resolution Queries
previous work, (and others) shown collective resolution using relationships
improves entity resolution accuracy significantly offline cleaning databases. So, naturally, would like use approach query-time entity resolution well.
However, attribute-based naive relational approaches discussed earlier
applied query-time straight-forward fashion, case collective
resolution. Two issues come using collective resolution queries. First,
set references influence resolution decisions query need identified.
answering resolution query S. Russell using attribute-based approach,
sufficient consider papers S. Russell (or, similar names) author name.
collective resolution, contrast, co-authors author names, P.
629

fiBhattacharya & Getoor

Norvig Peter Norvig, also need clustered according entities.
turn requires clustering co-authors on. first task analyze
dependencies collective resolution identify references database
relevant answering query. enough. set references influencing
query may extremely large, query still needs answered quickly even though
answer may completely accurate. second issue performing resolution
task query-time. two problems address next sections.

4. Analysis Collective Resolution using Relational Clustering
collective entity resolution, seen resolution performance query
becomes dependent resolution accuracy related entities. analyze
references influence entity resolution query extent, need
analyze nature dependence collective resolution general. section,
identify structural properties data affect collective entity resolution
formally model interdependent nature resolution performance. analysis
also helps us understand collective resolution using relational clustering helps,
and, equally importantly, adverse effect compared traditional
attribute-based resolution.
goal entity resolution algorithm partition set R = {ri } references
set clusters C = {ci } according underlying entities E = {ei }. accuracy resolution depends closely separation references clusters
corresponds underlying entities. consider two different measures performance.
first measure recall entity. entity ei , recall counts many pairs
references corresponding ei correctly assigned computed cluster.
second measure precision computed cluster. cluster ci , precision counts
many pairs references assigned ci truly correspond underlying entity.
(Alternatively, imprecision measures many pairs references assigned cluster
correspond entity.) next two subsections, analyze
two performance metrics influenced, first, attribute values references,
then, observed relationships them.
4.1 Influence Attributes
First, consider entity resolution algorithm follows traditional attribute-based approach analysis performance. algorithm considers attributes
individual references. uses similarity measure defined domain attributes,
considers pair-wise attribute similarity references resolving them. Let us
define two references -similar attribute-similarity least . Then, given
resolution threshold , attribute-based approach assigns pair references
cluster -similar. illustrate using example, using
similarity measure defined names appropriately determined similarity threshold
, attribute-based approach would assign three W. Wang references (r1 , r4 , r8 )
one cluster c1 W. W. Wang reference (r9 ) different cluster c2 . resolution
Wang references perfect terms precision recall, since references r1 , r4
r9 map one entity e1 r8 maps second entity e2 . Cluster c1 precision less
630

fiQuery-time Entity Resolution

1, since incorrectly includes references two different entities, recall less
1 entity e1 , since references dispersed two different clusters.
order analyze performance attribute-based resolution approach given
arbitrary dataset, characterize dataset terms attribute values
references. Intuitively, attribute-based approach works well references
corresponding entity similar terms attributes,
references corresponding different entities not. capture formally, define
two probabilities measure attribute-similarity references map
entity, attribute-similarity map different entities:
attribute identification probability aI (e, ): probability pair references chosen randomly corresponding entity e -similar
other.
attribute ambiguity probability aA (e1 , e2 , ): probability pair references chosen randomly one corresponds entity e1 entity
e2 -similar other.
illustrate using four Wang references, r1 , r4 r9 correspond
entity e1 r8 corresponds different entity e2 . Also, assume similarity
measure names appropriate threshold , references r1 , r4 r8 -similar
other. Then, 3 pairs references corresponding entity e1 , one (r1
r4 ) -similar, attribute identification probability aI (e1 , ) entity e1 0.33.
hand, three pairs references one maps e1
e2 , two (r1 r8 , r4 r8 ) -similar. means attribute ambiguity
probability aA (e1 , e2 , ) e1 e2 0.66.
seen example, performance attribute-based clustering algorithm represented terms two probabilities. specified
threshold , pairs references entity correctly recalled ones
-similar, exactly aI (e, ) captures. Therefore, recall domain
entity e R(e, ) = aI (e, ). hand, consider cluster assignment
references correspond two entities e1 e2 . pairs incorrectly clustered
together correspond two different entities, yet -similar.
aA (e1 , e2 , ) captures. Therefore imprecision cluster assignment reference
pairs corresponding entities e1 e2 I(e1 , e2 , ) = aA (e1 , e2 , ). Alternatively,
precision given P (e1 , e2 , ) 1 I(e1 , e2 , ) = 1 aA (e1 , e2 , ).
4.2 Influence Relationships
Now, consider collective entity resolution approach additionally makes use
relationships, analyze impact entity resolution accuracy. Recall
set H = {hj } observed co-occurrence relationships references. cooccurrences references useful entity resolution result strong
ties relations underlying entities. Specifically, assume references
entity ei co-occur frequently references small set entities {e1i , . . . , eki },
call entity neighbors, denoted N (ei ), entity ei .
631

fiBhattacharya & Getoor

W.W. Wang
W. Wang

h4

A. Ansari
A. Ansari

W. Wang
W. Wang

h1

h1
h3

C. Chen
C. Chen

Figure 3: Illustration (a) identifying relation (b) ambiguous relation running
example. Dashed lines represent co-occurrence relations.

Assuming neighborhood relationship among underlying entities allows us
analyze performance relational clustering approach. reference pairs
-similar terms attributes, attribute evidence enough resolution.
now, unlike attribute-based clustering, pair references -similar terms
attributes, < , considered candidates clustered together.
actually get assigned cluster. reference pairs ring
uncertainty , relationships play role determining similar
enough, consequently, clustered together. Specifically, references ri
rj co-occur hyper-edge h references ri rj co-occur hyper-edge
h , relational similarity pair (ri , ri ) (rj , rj ) belong
cluster. general, multiple relationships may needed tipping balance,
simplicity, assume single pair related references sufficient.
words, ri ri get assigned cluster rj rj cluster.
analyze impact approach entity resolution performance.
Without loss generality, assume (rj , rj ) pair get clustered together first
relational clustering algorithm. results pair (ri , ri ) also getting clustered
later iteration considering relational evidence. see accurate,
consider two situations, attribute evidence. first shown Figure 3(a),
pairs truly correspond entity. collective resolution decision
correct say hyper-edges h h identifying relationships entity.
Formally,
IRel(h, h , e) ri , rj h.R, ri , rj h .R,
E(ri ) = E(ri ) = e, E(rj ) = E(rj )

(5)

hand, may different scenario, pairs references correspond two different entities. second scenario depicted Figure 3(b).
first decision resolve (rj , rj ) co-referent incorrect, relational evidence obtained
hyper-edges h h consequently leads incorrect resolution (ri , ri ).
situation, collective resolution hurts accuracy, say h h form ambiguous
relationships pairs entities, whose references may incorrectly clustered
result relationships. Formally,
IAmb(h, h , e, e ) ri , rj h.R, ri , rj h .R,
632

fiQuery-time Entity Resolution

E(ri ) = e, E(ri ) = e , e 6= e ,
E(rj ) 6= E(rj )

(6)

general, reference ri co-occurrence relation h includes
one reference. may think multiple co-occurrence pairs involving ri .
Cluster labels references pairs influence resolution decisions ri .
resolving ri another reference ri participates co-occurrence relation h ,
fraction common cluster labels h h determines whether ri
ri clustered together. assigned cluster, h h labeled
identifying ambiguous relationships based whether ri ri actually co-referent
not.
Formally, define:
identifying relationship probability rI (e, ): probability randomly chosen pair -similar references corresponding entity e identifying relationships
h h entity.
ambiguous relationship probability rA (e1 , e2 , ): probability pair
-similar references, chosen randomly one corresponds entity e1
entity e2 , ambiguous relationships h h pair
entities.
illustrate probabilities using example, two Wang entities, e1
references r1 , r4 r9 , e2 reference r8 . Assume attribute
threshold six pairs considered potential matches. three pairs
references corresponding e1 , identifying relationships Ansari
entity. So, rI (e1 , ) = 1. measure relational ambiguity two Wang
entities, consider 3 possible pairs (r1 r8 , r4 r8 , r9 r8 ).
one (r1 r8 ) pair ambiguous relationships two different Chen entities. So,
rA (e1 , e2 , ) = 0.33.
Given two probabilities, analyze performance relational clustering algorithm combines attribute relational evidence collective entity resolution.
hard see recall entity depends recursively recall
neighbor entities. pair references entity e resolved correctly basis
attributes alone probability aI (e, ) (the identifying attribute probability). Furthermore, may still resolved correctly presence identifying relationships
neighbor entity, related reference pair neighbor resolved correctly. Denoting
R(e, , ) recall entity e neighbors R(N (e), , ), have:
R(e, , ) = aI (e, ) + (1 aI (e, )) rI (e, ) R(N (e), , )

(7)

hand, consider pair entities e1 e2 . cluster assignment
pair references corresponding e1 e2 imprecise basis attributes
alone probability aA (e1 , e2 , ). Even otherwise, cluster assignment go wrong
considering relational evidence. happens presence ambiguous relationships
references corresponding another pair entities, references also clustered
633

fiBhattacharya & Getoor

together incorrectly. imprecision I(e1 , e2 , , ) cluster assignment reference
pairs corresponding entities e1 e2 turns be:
I(e1 , e2 , , ) = aA (e1 , e2 , ) + (1 aA (e1 , e2 , )) rA (e1 , e2 , ) I(N (e1 ), N (e2 ), , ) (8)
general, entity e multiple neighbors ei neighborhood N (e). formalize performance dependence multiple neighbors, assume co-occurrence
involving references corresponding e chosen random, probability selecting
co-occurrence reference corresponding ei pei . recall given as:
|N (e)|

R(e) = aI (e) + (1 aI (e)) rI (e)

X

pei R(ei )

(9)

i=1

Note dropped notational brevity. defining imprecision, observe
reference corresponding neighbor ei1 e1 may co-occur reference
neighbor ej2 e2 probability pei 1 pej 2 . imprecision given as:
|N (e1 )| |N (e2 )|

I(e1 , e2 ) = aA (e1 , e2 ) + (1 aA (e1 , e2 )) rA (e1 , e2 )

X

X

i=1

j=1

pei 1 pej 2 I(ei1 , ej2 )

(10)

Given similarity thresholds , relational clustering increases recall beyond
achievable using attributes alone. improvement larger probability identifying relationships higher. flip side, imprecision also increases relational
clustering. Typically, low attribute threshold corresponds high precision used,
recall increased using relational evidence. probability ambiguous
relations rA small, accompanying increase imprecision negligible, performance improved overall. However, higher ambiguous relationship probability
rA , less effective relational clustering. Thus balance ambiguous
identifying relations determines overall benefit collective resolution using relational
clustering. rA high compared rI , imprecision increases faster recall,
overall performance adversely affected compared attribute-based clustering. Eq. (9)
Eq. (10) quantify dependence resolution performance entity nature
relationships entities. next section, use equations
design analyze relational clustering algorithm answering entity resolution queries.

5. Collective Resolution Queries
analysis collective resolution using relational clustering showed resolution accuracy underlying entity depends resolution accuracy related/neighboring entities. problem answering entity resolution queries, goal
resolve entities database. need resolve entities
references retrieved query. seen collective resolution leads
potential performance improvements attribute-based resolution. investigate
collective resolution applied answering queries get similar improvements.
obvious hurdle illustrated expressions performance metrics Eq. (9)
Eq. (10). show order get performance benefits resolving query using
634

fiQuery-time Entity Resolution

relational clustering, need resolve neighboring entities well. Furthermore,
resolve neighboring entities, need resolve neighboring entities, on.
entities need resolved large number, resolving
expensive terms query-processing time. Also, none actually going
retrieved part answer query. critical identify resolve
entities contribute improving resolution accuracy query.
propose two-stage query processing strategy, consisting extraction phase,
identifying relevant references need resolved answering query,
resolution phase, relevant references extracted collectively
resolved using relational clustering. Unfolding Eq. (9) Eq. (10) starting query
entities leads natural expansion process. section, describe extraction
process using two novel expansion operators and, parallel, analyze improvement
resolution accuracy obtained considering co-occurrences.
Recall entity resolution query Q(R.A = a) specified using attribute
value it. answer query consists partitioning references
r r.A = value -similar a. correct answer query,
general, involves references multiple entities {eq }. measure resolution accuracy
query using two metrics before. query entities eq , measure recall
R(eq ) imprecision I(eq , e ) respect entity e . Entity e may may
belong {eq }.
going details algorithm collective resolution queries,
briefly recall accuracy attribute-based strategy resolving query. approach
considers references r r.A -similar a, resolves using attributes
only. recall results approach R(eq , ) = aI (eq , ), imprecision
given I(eq , e , ) = aA (eq , e , ).
propose two expansion operators constructing relevant set entity
resolution query. denote level-0 references references -similar
query attribute. references user interested in, goal
resolve correctly. first operator introduce attribute expansion
operator XA , A-expansion short. Given attribute value
attribute, XA (a, ) returns references r whose attributes r.A exactly match similar a. query Q(R.A = a), level-0 references retrieved expanding
Q as:
Rel0 (Q) = XA (a, )
first step Figure 4 shows A-expansion query Q(R.N ame = W.W ang)
example. retrieves four references (r1 ,r4 ,r8 ,r9 ) name W. Wang W. W.
Wang.
consider co-occurrence relations, construct level-1 references including
references co-occur level-0 references. this, use second operator,
call hyper-edge expansion XH , H-expansion. reference r, XH (r)
returns references share hyper-edge r, set R references XH (R)

returns rR XH (r). Collective entity resolution requires consider co-occurring
references reference. achieved performing H-expansion references
635

fiBhattacharya & Getoor

Q
R.Name=W_Wang

1

r 11 A_Ansari

Rel (Q)

0

Rel (Q)

r 9 W_W_Wang

r 10 A_Ansari

r 4 W_Wang

r 5 A_Ansari

r 54 A_Ansari

r 3 A_Ansari

r 23 C_Chen
...

r 1 W_Wang

r 2 C_Chen

r 8 W_Wang

r 7 C_Chen
r 6 L_Li

Rel2 (Q)

...

r 89 C_Chen
r 16 L_Li
...
r 66 L_Li

Figure 4: Relevant set query Q(R.N ame = W.W ang) using H-expansion Aexpansion alternately

level-0 retrieve level-1 references:
Rel1 (Q) = XH (Rel0 (Q))
Figure 4 illustrates operation example, XH (r1 ) retrieves references C.
Chen (r2 ) A. Ansari (r3 ), on.
perform collective resolution query, additionally need resolve references level-1. One option level-1 references attribute-based resolution using
conservative -similarity keep imprecision minimum. use analysis technique evaluate performance approach. Expanding Eq. (9),
substituting aI (eiq , ) recall neighboring entity eiq eq , recall
query entity is:
R(eq , , ) = aI (eq , ) + (1 aI (eq , )) rI (eq , )

k
X

e

pi q aI (eiq , )

i=1

Similarly, substituting aA (eiq , ej , ) Eq. (10) imprecision neighboring
entity eiq , get following expression imprecision:
I(eq , e , , ) = aA (eq , e , ) + (1 aA (eq , e , )) rA (eq , e , )

k X
l
X

e





pi q pej aA (eiq , e j , )

i=1 j=1

appreciate easily implications considering first-order neighbors, may
assume attribute identification probability attribute ambiguity probability
entities involved, i.e., aI (e, ) = aI () aA (e, e , ) = aA (). Then,
P
using ki=1 pei = 1 entity e, expression recall simplifies
R(eq , , ) = aI () + (1 aI ()) rI () aI ()
= aI ()[1 + (1 aI ())rI ()]
636

fiQuery-time Entity Resolution

Similarly, expression imprecision simplifies
I(eq , e , , ) = aA ()[1 + (1 aA ())rA ()]
see attribute-clustering first level neighbors potentially increases
recall query entity eq , imprecision goes well. However, balance rA rI favorable, increase imprecision insignificant much
smaller corresponding increase recall, overall performance
improvement.
better this? go step consider co-occurrence
relations resolving level-1 references well. So, instead considering attributebased resolution references level-1 before, perform collective resolution them.
consider -similar references, call level-2 references (Rel2 (Q)), using
A-expansion:
Rel2 (Q) = XA (Rel1 (Q))
Note overloaded A-expansion operator set R references: XA (R) =
rR XA (r.A). level-3 references second order neighbors co-occur
level-2 references. retrieved using H-expansion level-2 references:



Rel3 (Q) = XH (Rel2 (Q))
Finally, level-1 references earlier, resolve level-3 references using similarity attributes alone.
order evaluate impact resolution accuracy query, unfold
recursions Eq. (9) Eq. (10) two levels, substitute aI (eiq , ) recall
aA (ei , ej , ) imprecision second order neighbors. trend expressions
becomes clearly visible assume, before, aI aA identical entities, and,
additionally, rI rA also same, i.e., rI (e1 , e2 , ) = rI () rA (e1 , e2 , ) = rA ().
Then, work algebraic steps get following expressions recall
precision query entity eq :
R(eq ) = aI [1 + (1 aI )rI + (1 aI )2 rI2 ]


I(eq , e ) = aA [1 + (1 aA )rA + (1

2
aA )2 rA
]

(11)
(12)

continue unfold recursion grow relevant set query.
Formally, expansion process alternates A-expansion H-expansion:
Reli (Q) = XA (Q)
XH (Reli1 (Q))
XA (Reli1 (Q))

= 0
odd
even

proceed recursively consider higher order co-occurrences query, additional terms appear expressions precision recall. imply
need continue process arbitrary levels get optimum benefit. Using
simplifying assumptions attribute relational probabilities, expressions recall imprecision nth order co-occurrences turns geometric
637

fiBhattacharya & Getoor

progressions n + 1 terms. common ratio two geometric progressions
(1 aI ())rI () (1 aA ())rA () respectively. Typically, ratios significantly smaller 1, therefore converge quickly increasing co-occurrence
level. improvement resolution accuracy query Q falls quickly
expansion depth, terminate expansion process cut-off depth
without compromising accuracy:


Rel(Q) =


[

Reli (Q)

i=0

course, assumptions attribute relational probabilities entityindependent hold practice, performance trends increasing levels
co-occurrence cannot exactly captured geometric progressions common ratio
successive terms. converging trends still hold general,
rate convergence still determined four probabilities aI , aA , rI rA
entities encountered expansion process. Intuitively, smaller values
rI rA indicate less sensitivity co-occurrences, convergence quicker.
hand, higher values aI aA mean entities resolved based
attributes alone correctly incorrectly impact co-occurrence relations
smaller. Therefore convergence quicker higher values aI aA .
Apart imposing cutoff expansion depth, size relevant set
also significantly reduced restricting attribute expansion beyond level-0 exact
e (r). considers references exactly attribute
A-expansion XA
r disregards -similar references. Interestingly, show restricted
strategy alternates exact A-expansion H-expansion reduce recall
significantly.

6. Adaptive Query Expansion
limited depth query expansion strategy proposed previous section effective
approach able answer queries quickly accurately many domains. However,
domains, size relevant set generated extremely large even
small expansion depths, result, retrieved references cannot resolved
query-time. section, propose adaptive strategies based estimating
ambiguity individual references makes algorithm even efficient
preserving accuracy.
main reason behind explosive growth relevant set increasing levels
query expansion strategy previous section unconstrained treats
co-occurrences equally important resolving entity. blindly expands
references current relevant set, also includes new references generated
expansion operation. Given limited time process query, approach infeasible
domains dense relationships. solution identify references
likely helpful resolving query, focus references.
illustrate using example Figure 4, observe Chen Li significantly
common ambiguous names Ansari even different W. Wang entities
likely collaborators named Chen Li. Therefore, h-expanding Rel0 (rq )
638

fiQuery-time Entity Resolution

W. Wang, Ansari informative Chen Li. Similarly, n-expanding
Rel1 (rq ), choose expand name A. Ansari further, since two A.
Ansari references likely coreferent. need evidence
Chens Lis.
describe formally, ambiguity value attribute probability two references ri rj database ri .A = rj .A =
coreferent: Amb(a) = P (E(ri ) 6= E(rj ) | ri .A = rj .A = a). goal adaptive expansion
add less ambiguous references relevant set expand ambiguous
references currently relevant set. first define adaptive versions two expansion operators treating ambiguity estimation process black-box, look
ways estimate ambiguity references.
6.1 Adaptive Expansion Operators
goal adaptive expansion selectively choose references expand
current relevant set, also new references included every expansion step.
adaptive hyper-edge expansion, set upper-bound hmax number new
references h-expansion particular level generate. Formally, want
|XH (Reli (Q))| hmax |Reli (Q)|. value hmax may depend depth
small enough rule full h-expansion current relevant set. Then, given hmax ,
strategy choose least ambiguous references XH (Reli (Q)), since provide
informative evidence resolving references Reli (Q). achieve this,
sort h-expanded references increasing order ambiguity select first k
them, k = hmax |Reli (Q)|.
i1

Reladapt
(Q, hmax ) = LeastAmb(k, XH (Reladapt
(Q)))

(13)

setting adaptive attribute expansion similar. positive number amax , exact a-expansion Reli (Q) allowed include amax |Reli (Q)| references. Note selection preference needs flipped ambiguous names
e (Reli (Q)) decreasing
need evidence, expanded first. sort XA
order ambiguity select first k sorted list, k = amax |Reli (Q)|.
could potentially retrieve references ambiguous name, totally ignoring
references name. avoid this, choose top k ambiguous references
Reli (Q) expansion, expand references chosen.

e

Reladapt
(Q, nmax ) = XA
(M ostAmb(k, Reladapt
(Q)))

(14)

Though cannot directly control number new references added, r k reasonable estimate, r average number references per name.
6.2 Ambiguity Estimation
adaptive expansion scheme proposed section crucially dependent estimates name ambiguity. describe one possible scheme worked quite well.
Recall want estimate probability two randomly picked references
value attribute correspond different entities. reference attribute A1 , denoted
639

fiBhattacharya & Getoor

1.
2.

Algorithm Query-time Resolve (R.Name name)
RSet = RelevantFrontier(name)
RC-ER(RSet)

1.
5.
3.
4.
5.
6.
7.
8.
9.
10.
10.
11.

Algorithm FindRelevantRefs(R.Name name)
Initialize RSet {}
Initialize depth 0
Initialize FrontierRefs {}
depth < d*
depth even 0
R = XA (FrontierRefs)
else
R = XH (FrontierRefs)
FrontierRefs = R
Add FrontierRefs RSet
Increment depth
Return RSet
Figure 5: High-level description query-time entity resolution algorithm

R.A1 , naive estimate ambiguity value n attribute is:
Amb(r.A1 ) =

|R.A1 =r.A1 (R)|
,
|R|

|R.A1 =r.A1 (R)| denotes number references value r.A1 A1 . estimate clearly good since number references certain attribute value
always match number different entity labels attribute. much
better additional attribute A2 . Given A2 , ambiguity value A1
estimated
|(R.A2 (R.A1 =r.A1 (R)))|
Amb(r.A1 | r.A2 ) =
,
|R|
|(R.A2 (R.A1 =r.A1 (R)))| number distinct values observed A2 references R.A1 = r.A1 . example, estimate ambiguity last name
counting number different first names observed it. provides better estimate
ambiguity value attribute A1 , A2 correlated A1 .
multiple uncorrelated attributes Ai available references, approach
generalized obtain better ambiguity estimates.
Putting everything together, high-level pseudo code query-time entity resolution
algorithm shown Figure 5. algorithm works two stages first, identifies
relevant set references given entity name query, performs relational
clustering extracted relevant references. relevant references extracted using
recursive process already seen. relevant references depth
obtained expanding relevant references depth i1, expansion dependent
640

fiQuery-time Entity Resolution

whether odd step even step. actual expansion operator used
may either unconstrained adaptive.

7. Empirical Evaluation
experimental evaluation query-time resolution strategies, used realworld synthetically generated datasets. First, describe real datasets
experiments performed move experiments synthetic data.
7.1 Experiments Real Data
real-world data, used two citation datasets different characteristics.
first dataset, arXiv, contains papers high energy physics used KDD Cup
20032 . 58,515 references 9,200 authors, contained 29,555 publications. number author references per publication ranges 1 10 average 1.90.
second dataset Elsevier BioBase database3 publications biology used
recent IBM KDD-Challenge competition. includes publications Immunology
Infectious Diseases years 1998 2001. dataset contains 156,156 publications 831,991 author references. number author references per publication
significantly higher arXiv ranges 1 100 (average 5.3). names
database initials first middle names (if available), unlike arXiv,
initialed complete names. number distinct names BioBase 303,693,
number references name ranging 1 193 (average 2.7). Unlike
arXiv, BioBase includes keywords, topic classification, language, country correspondence
affiliation corresponding author attributes paper, use
attributes resolution addition author names. BioBase diverse terms
attributes, covering 20 languages, 136 countries, 1,282 topic classifications 7,798
keywords.
entity resolution queries arXiv, selected ambiguous names correspond
one author entity. gave us 75 queries, number true entities
selected names varying 2 11 (average 2.4). BioBase, selected
queries top 100 author names highest number references. average
number references 100 names 106, number entities
selected names ranges 1 100 (average 32), thereby providing wide variety entity
resolution settings queries.
7.1.1 Relevant Set Size Vs. Resolution Time
begin exploring growth rate relevant set query expansion depth
two datasets. Figure 6(a) plots size relevant set sample query
name T. Lee arXiv M. Yamashita BioBase. growth rate arXiv
query moderate. number references name T. Lee 7, number
relevant references depth 0, size grows 7,500 depth 7. contrast,
BioBase plots clearly demonstrate exponential growth relevant references
2. http://www.cs.cornell.edu/projects/kddcup/index.html
3. http://help.sciencedirect.com/robo/projects/sdhelp/about biobase.htm

641

fiBhattacharya & Getoor

800

900

BioBase: similar
BioBase: exact
arXive: exact

700

700
time (secs)

# references
(in thousands)

600
500
400
300

600
500
400
300

200

200

100

100

0

0
0

(a)

BioBase
arXiv

800

1

2

3

4

expansion depth

5

6

7

0
(b)

10

20
30
40
50
#references (in thousands)

60

70

Figure 6: (a) Size relevant set increasing expansion depth sample queries
arXiv BioBase (b) Execution time RC-ER increasing number
references

depth name expansion strategies. 84 relevant references depth
0. references expanded using name similarity expansion, 722 relevant
references depth 1, 65,000 depth 3 586,000 depth 5.
restricted similarity measure two names considered similar first
initials match, last names first character differ overall
2 characters. liberal measure would result significantly faster growth. also
observe exact expansion, growth slower still 45,000 references
depth 3, 384,000 depth 5 783,000 depth 7. interesting note growth
slows beyond depth 5; references entire dataset
already covered depth (BioBase 831,991 references total). growth
rates two examples arXiv BioBase typical queries
two datasets.
Next, Figure 6(b), observe relational clustering algorithm RC-ER scales
increasing number references relevant set. execution times reported
Dell Precision 870 server 3.2GHz Intel Xeon processor 3GB memory.
plot shows algorithm scales well increasing references, gradient
different two datasets. mainly due difference average number
references per hyper-edge. suggests arXiv, RC-ER capable handling
relevant sets generated using unconstrained expansion. BioBase, would require
600 secs 40,000 references, 900 secs 65,000. clearly
possible use RC-ER unconstrained expansion query-time resolution BioBase
even depth 3.
7.1.2 Entity Resolution Accuracy Queries
next experiment, evaluate several algorithms entity resolution queries.
compare entity resolution accuracy pair-wise co-reference decisions using F1
measure (which harmonic mean precision recall). fair comparison,
consider best F1 algorithms possible thresholds determining
642

fiQuery-time Entity Resolution

Table 1: Average entity resolution accuracy (F1) different algorithms 75 arXiv
queries 100 BioBase queries


A*
NR
NR*
RC-ER Depth-1
RC-ER Depth-3

arXiv
0.721
0.778
0.956
0.952
0.964
0.970

BioBase
0.701
0.687
0.710
0.753
0.813
0.820

duplicates. algorithms, compare attribute-based entity resolution (A), naive
relational entity resolution (NR) uses attributes related references, relational
clustering algorithm collective entity resolution (RC-ER) using unconstrained expansion
depth 3. also consider transitive closures pair-wise decisions first
two approaches (A* NR*). attribute similarity, use Soft TF-IDF
Jaro-Winkler similarity names, shown perform best namebased resolution (Bilenko, Mooney, Cohen, Ravikumar, & Fienberg, 2003), TF-IDF
similarity textual attributes.
average F1 scores queries shown Table 1 algorithm
two datasets. shows RC-ER improves accuracy significantly baselines.
example BioBase, improvement 21% NR, 25% A* 13%
NR*. demonstrates potential benefits collective resolution answering
queries, validates recent results context offline entity resolution (Bhattacharya
& Getoor, 2004, 2007; Singla & Domingos, 2004; Dong et al., 2005; McCallum & Wellner,
2004). earlier work (Bhattacharya & Getoor, 2007) demonstrated using
extensive experiments real synthetic datasets relational clustering algorithm
(RC-ER) improves entity resolution performance traditional baselines context
offline data cleaning, entire database cleaned whole. numbers
Table 1 confirm similar improvements obtained localized resolution
well. predicted analysis, accuracy improvement comes
depth-1 relevant references. 56 100 BioBase queries, accuracy
improve beyond depth-1 relevant references. remaining 44 queries, average
improvement 2%. However, 8 ambiguous queries, accuracy improves
5%, biggest improvement high 27% (from 0.67 0.85 F1).
instances fewer arXiv, biggest improvement 37.5% (from 0.727 1.0).
one hand, shows considering related records resolving collectively
leads significant improvement accuracy. hand, also demonstrates
potential benefits considering higher order neighbors, fall quickly
beyond depth 1. also serves validate analysis collective query resolution
Section 4.
643

fiBhattacharya & Getoor

Table 2: Average query processing time unconstrained expansion


A*
NR
NR*
RC-ER Depth-1
RC-ER Depth-3

1

arXiv
0.41
0.41
0.43
0.428
0.45
1.36

BioBase
9.35
9.59
28.54
28.69
11.88
606.98

1

depth 1
depth 2

depth 1
depth 2

0.9

0.7
recall

precision

0.8
0.9

0.6
0.5

0.8

0.4
0.3
0.7

0.2
1

0.8

0.6

0.4

0.2

0

1

0.8

similarity threshold

(a)

0.6
0.4
similarity threshold

0.2

0

(b)
1

1

0.9
0.8
recall

precision

0.9

0.8

0.7
0.6
0.5

0.7

0.4

depth 1
depth 2

0.6
1

0.8

depth 1
depth 2

0.3
0.6

0.4

0.2

0

1

similarity threshold

(c)

0.8

0.6
0.4
similarity threshold

0.2

0

(d)

Figure 7: Average precision recall different similarity thresholds (a-b) BioBase
(c-d) arXiv

last two rows Table 1 show converging nature entity resolution performance
increasing depth. verify explicitly precision recall Figure 7.
top two plots show average precision recall BioBase queries different similarity
thresholds RC-ER. bottom two plots show arXiv. see
precision curve depth 1 coincides stays marginally precision curve
depth 3 BioBase arXiv. recall curves show opposite trend recall
644

fiQuery-time Entity Resolution

marginally improves depth 3. agreement derived expressions
precision recall increasing depth Eq. (12). difference recall depths
2.
1 3 quantified aI (1 aI )2 rI2 , difference precision aA (1 aA )2 rA
explanation small difference average precision recall two
plots factors, averaged queries, significantly smaller
1 arXiv BioBase. investigate converging nature performance
detail varying structural properties experiments synthetic data
Section 7.2.
7.1.3 Reducing Time Adaptive Expansion
first set experiments show effectiveness two-phase query processing strategy
terms entity resolution performance. challenge, described earlier,
obtaining benefits real-time. So, next, focus time required
process queries two datasets using unconstrained expansion depth 3.
results shown Table 2. arXiv, average processing time depth-3 expansion
1.36 secs, 406 relevant references average. shows two-phase strategy
unconstrained expansion practical processing strategy entity resolution queries
resolves query entities accurately, extremely quickly well. However,
BioBase, average number references reached depth 3 44,000,
time taken resolve collectively 10 minutes. unacceptable
answering queries, next focus processing time improved using
proposed adaptive strategies. Note time taken depth-1 expansion around 12
secs, close attribute-based baseline (A) less time
naive relational algorithm (NR).
Since unconstrained expansion effective arXiv, focus BioBase evaluating adaptive strategies. estimating ambiguity references, use last names
first initial secondary attribute. results good estimates ambiguity ambiguity estimate name strongly correlated (correlation coeff. 0.8)
number entities name. First, evaluate adaptive H-expansion. Since
H-expansion occurs first depth 1, query, construct relevant set cutoff
depth = 1, use adaptive H-expansion depth 1. expansion upper-bound hmax
set 4. compare three different adaptive H-expansion strategies: (a) choosing
least ambiguous references, (b) choosing ambiguous references (c) random
selection. Then, query, evaluate entity resolution accuracy using RC-ER
relevant sets constructed using three adaptive strategies. average accuracies
three strategies 100 queries shown first column Table 3. Least
ambiguous selection, strategy propose, clearly shows biggest improvement ambiguous smallest, random selection between. Notably,
even without many depth-1 references, improve accuracy NR*
virtue collective resolution.
perform similar set experiments evaluating adaptive attribute expansion.
Recall depth 2 lowest depth adaptive attribute expansion performed.
query, construct relevant set = 3 using adaptive A-expansion
depth 1 unconstrained H-expansion depths 1 3. expansion upper-bound
645

fiBhattacharya & Getoor

Table 3: Avg. resolution accuracy F1 different adaptive expansion strategies

Least Ambiguous
Ambiguous
Random

H-expansion
0.790
0.761
0.770

A-expansion
0.815
0.821
0.820

amax set 0.2, average 1 5 names expanded. Again, compare three
strategies: (a) expanding least ambiguous names, (b) expanding ambiguous
names (c) random expansion. average accuracies three schemes
100 queries listed second column Table 3. experiment adaptive Aexpansion bring difference three schemes clearly adaptive
H-expansion. comparing A-expansion depth 2 and, average,
much improvement obtained beyond depth 1 ceiling effect.
shows almost benefit depth 3 comes proposed strategy
expanding ambiguous names.
two experiments demonstrate effectiveness two adaptive expansion
schemes isolation. Now, look results use together.
100 queries, construct relevant set Rel(rq ) = 3 using adaptive Hexpansion adaptive exact A-expansion. Since improvement collective
resolution comes depth-1 references, consider two different experiments.
first experiment (AX-2), use adaptive expansion depths 2 beyond,
unconstrained H-expansion depth 1. second experiment (AX-1), use adaptive
H-expansion even depth 1, hmax = 6. them, use adaptive expansion
higher depths 2 3 parameters hmax = 3 3 amax = 0.2 2.
Table 4: Comparison unconstrained adaptive expansion BioBase

relevant-set size
time (cpu secs)
accuracy (F1)

Unconstrained
44,129.5
606.98
0.821

AX-2
5,510.52
43.44
0.818

AX-1
3,743.52
31.28
0.820

Table 4, compare two adaptive schemes unconstrained expansion
= 3 queries. Clearly, accuracy remains almost unaffected schemes.
First, note AX-2 matches accuracy unconstrained expansion, shows
almost improvement depth 1. accuracy achieved even though
uses adaptive expansion expands small fraction Rel1 (Q), thereby reduces
average size relevant set 44,000 5,500. significantly, AX-1 also matches
improvement even without including many depth-1 references. reduction
size relevant set immense impact query processing time. average
processing time drops 600 secs unconstrained expansion 43 secs


646

fi1.1
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2

1

pR=0.2
pR=0.5
pR=1.0

0.9
0.8
Precision

Recall

Query-time Entity Resolution

0.7
0.6
0.5

pRa=0.0
pRa=0.3
pRa=0.6

0.4
0.3
0.7

0.6
0.5
Sim. Threshold

0.4

0.7

0.65

0.6
0.55
0.5
Sim. Threshold

0.45

Figure 8: Effect (a) identifying relations recall (b) ambiguous relations precision collective clustering. Error bars show standard deviation.

AX-2, 31 secs AX-1, thus making possible use collective entity
resolution query-time resolution.
7.1.4 Adaptive Depth Selection
improvement, investigate processing time reduced setting
expansion depth adaptively, depending ambiguity query name, compared
fixed queries. simple setup, set 1 queries number
different first initials last name less 10 (out 26), explore depth 2
ambiguous queries. reduces expansion depth 2 1 18 100
queries. result, average processing time queries reduced 35% 11.5
secs 17.7 secs reduction accuracy. three queries, original
processing time depth 2 greater 30 secs. preliminary experiments,
evaluated original set 100 queries inherently ambiguous. general
setting, bigger fraction queries lower ambiguity, impact expected
even significant.
7.2 Experiments using Synthetic Data
addition experiments real datasets, performed experiments synthetically
generated data. enables us reason beyond specific datasets, also empirically
verify performance analysis relational clustering general, specifically
entity resolution queries. designed generator synthetic data (Bhattacharya
& Getoor, 2007) allows us control different properties underlying entities
relations them, also observed co-occurrence relationships
entity references. Among properties, control number entities,
average number neighbor entities per entity, number average size
observed co-occurrences. Additionally, control ambiguity entity attributes,
number ambiguous relationships entities. present overview
synthetic data generation process Appendix A.
647

fiBhattacharya & Getoor

1

0.9
0.85
Precision

0.8
Recall

0.95

t=0.9
t=0.6
t=0.5

0.9
0.7
0.6
0.5

0.8
0.75
0.7

0.4

0.65

0.3

0.6

0.2

t=0.9
t=0.6
t=0.5

0.55
0

1
2
Expansion Level

3

0

1
2
Expansion Level

3

Figure 9: Change (a) precision (b) recall increasing expansion levels used
collective clustering. Error bars show standard deviation.

performed number different experiments synthetic data. first set
experiments, investigate influence identifying relationships collective resolution using relational clustering. generate 500 co-occurrence relations
100 entities 200 entity-entity relationships, using varying probability co-occurrences
pR = {0.2, 0.5, 1.0} data. probability ambiguous relationships held fixed,
higher pR translates higher probability identifying co-occurrences data.
Figure 8(a) shows recall different similarity thresholds three different co-occurrence
probabilities. results confirm recall increases progressively identifying
relationships thresholds. curves pR = 0.5 pR = 1.0 flatten
recall achievable.
Next, observe effect ambiguous relations precision collective resolution using relational clustering. add 200 binary relationships 100 entities
three stages increasing ambiguous relationship probability (pR
= {0, 0.3, 0.6}).
perform collective resolution 500 co-occurrence relations generated
three settings. Figure 8(b) plot precision different similarity threshold three different values pR
. plots confirm progressive decrease precision thresholds
higher pR
.

experiments, results averaged 200 different runs.

Next, evaluate collective resolution queries. Recall last two rows Table 1 clearly demonstrate converging nature performance increasing expansion
levels queries real datasets. ran experiments synthetic data verify
trend. run, generated 2,500 co-occurrence relations 500 entities
average 2 neighbors per entity. performed localized collective clustering
case, using query ambiguous attribute value (that corresponds
highest number underlying entities). Figure 9(c) (d), show recall precision change increasing expansion level query. Recall improves increasing
expansion level, precision decreases overall, predicted analysis. Importantly, recall increases significantly faster rate decrease precision.
general, rate increase/decrease depends structural properties data,
shown analysis. experiments, seen different rates
648

fiQuery-time Entity Resolution

change, overall trend remains same. analysis also showed precision
recall converge quickly increasing expansion levels. confirmed
two plots curves flatten level 3.
7.3 Current Limitations
Finally, discuss two current limitations collective entity resolution approach.
Recall similarity measure Eqn. 1 involves weighting parameter combining
attribute relational similarity. experiments, report best accuracy
values query. Selecting optimal value query
unresolved issue. However, experiments reveal even fixed ( = 0.5)
queries brings significant improvements baselines.
second issue determination termination threshold RC-ER. Note
issue baselines well, report best accuracy
thresholds. area ongoing research. Preliminary experiments shown
best threshold often query specific setting threshold depending
ambiguity query results significantly better accuracy fixed threshold
queries. empirical evaluation, cleaned entire arXiv dataset offline running
RC-ER references together, terminated threshold maximizes
resolution accuracy references. results overall accuracy (F1) 0.98.
However, average accuracy measured 75 queries test set 0.87.
comparison, best obtainable accuracy resolving queries individually
different threshold 0.97. suggests may potential benefits localized
cleaning global counterpart offline setting.

8. Related Work
entity resolution problem studied many different areas different
names deduplication, record linkage, co-reference resolution, reference reconciliation,
object consolidation, etc. Much work focused traditional attribute-based
entity resolution. Extensive research done defining approximate string similarity
measures (Monge & Elkan, 1996; Navarro, 2001; Bilenko et al., 2003; Chaudhuri, Ganjam,
Ganti, & Motwani, 2003) may used unsupervised entity resolution.
approach uses adaptive supervised algorithms learn similarity measures labeled
data (Tejada, Knoblock, & Minton, 2001; Bilenko & Mooney, 2003).
Resolving entities optimally known computationally hard even attributes considered (Cohen, Kautz, & McAllester, 2000). Therefore, efficiency
received lot attention attribute-based data cleaning. goal essentially avoid
irrelevant expensive attribute similarity computations using blocking approach without affecting accuracy significantly (Hernandez & Stolfo, 1995; Monge & Elkan, 1997; McCallum et al., 2000). merge/purge problem posed Hernandez Stolfo (1995)
efficient schemes retrieve potential duplicates without resorting quadratic complexity. use sorted neighborhood method appropriate key chosen
matching. Records sorted grouped according key potential matches
identified using sliding window technique. However, keys may badly distorted
matches cannot spanned window cases retrieved.
649

fiBhattacharya & Getoor

solution propose multi-pass method different keys merging
results using transitive closure. Monge Elkan (1997) combine union find algorithm
priority queue look-up find connected components undirected graph. McCallum et al. (2000) propose use canopies first partition data overlapping
clusters using cheap distance metric use accurate expensive distance
metric data pairs lie within canopy. Chaudhuri et al. (2003) use
error tolerant index data warehousing applications probabilistically looking
small set candidate reference tuples matching incoming tuple.
considered probabilistically safe since closest tuples database retrieved
high probability. also efficient since small number matches needs
performed. Swoosh (Benjelloun, Garcia-Molina, Su, & Widom, 2005) recently
proposed generic entity resolution framework considers resolving merging
duplicates database operator goal minimize number record-level
feature-level operations. alternative approach reduce complexity individual similarity computations. Gravano, Ipeirotis, Koudas, Srivastava (2003) propose
sampling approach quickly compute cosine similarity tuples fast text-joins
within SQL framework. approaches enable efficient data cleaning
attributes references considered.
Many recently proposed approaches take relations account data integration
(Ananthakrishna et al., 2002; Bhattacharya & Getoor, 2004, 2005; Kalashnikov et al., 2005;
Dong et al., 2005). Ananthakrishna et al. (2002) introduce relational deduplication data
warehouse applications dimensional hierarchy relations. Kalashnikov et al. (2005) enhance attribute similarity ambiguous reference
many entity choices relationship analysis entities, like affiliation
co-authorship. earlier work, proposed different measures relational similarity relational clustering algorithm collective entity resolution using relationships
(Bhattacharya & Getoor, 2004, 2007). Dong et al. (2005) collectively resolve entities multiple types propagating relational evidences dependency graph, demonstrate
benefits collective resolution real datasets. Long, Zhang, Wu, Yu (2006) proposed model general multi-type relational clustering, though applied
specifically entity resolution. perform collective factorization related matrices
using spectral methods identify cluster space minimizes distortion relationships individual features time. approaches make use
relationships either entity matching (where domain entities known) entity
resolution (where underlying entities also need discovered) shown
increase performance significantly attribute-based solutions problems.
However, price pay terms computational complexity increases due
couple different reasons. Firstly, number potential matches increases
relationships considered individual similarity computations also become expensive. Secondly, collective resolution using relationships necessitates iterative solutions
make multiple passes data. approaches still
shown scalable practice, cannot employed query-time cleaning
straight-forward manner.
idea multi-relational clustering also comes Inductive Logic Programming
(ILP) literature. Emde Wettschereck (1996) used multi-relational similarity
650

fiQuery-time Entity Resolution

instance-based classification representations first order logic. define similarity
two objects, e.g., two people, combination similarity attribute
values, age, weight, etc., similarity objects
related to, companies work for. similar naive relational
similarity discussed earlier, except similarity connected objects
also defined recursively terms connected objects. Kirsten Wrobel (1998)
used recursive relational similarity measure agglomerative clustering first
order representations. recursive comparison neighbors shown effective
terms accuracy results, computational challenge major drawback.
Probabilistic approaches cast entity resolution classification problem
extensively studied. groundwork done Fellegi Sunter (1969). Others (Winkler, 2002; Ravikumar & Cohen, 2004) recently built upon work. Adaptive
machine learning approaches proposed data integration (Sarawagi & Bhamidipaty, 2002; Tejada et al., 2001), active learning requires user label informative
examples. Probabilistic models use relationships collective entity resolution
applied named entity recognition citation matching (Pasula et al., 2003; McCallum & Wellner, 2004; Li et al., 2005; Singla & Domingos, 2004). probabilistic
approaches superior similarity-based clustering algorithms associate
degree confidence every decision, learned models provide valuable insight
domain. However, probabilistic inference collective entity resolution known
scalable practice, particularly relationships also considered. approaches mostly shown work small datasets, significantly slower
clustering counterparts.
Little work done literature query-centric cleaning relational approaches answering queries, execution time important accuracy resolution. Approaches proposed localized evaluation Bayesian networks (Draper
& Hanks, 1994), clustering problems. Recently, Chandel, Nagesh, Sarawagi
(2006) addressed efficiency issues computing top-k entity matches dictionary context entity extraction unstructured documents. process top-k
searches batches speed-up achieved sharing computation different
searches. Fuxman, Fazli, Miller (2005) motivate problem answering queries
databases violate integrity constraints address scalability issues resolving inconsistencies dynamically query-time. However, relational aspect problem,
major scalability issue address, come settings. earlier work relational clustering(Bhattacharya & Getoor, 2007), used
idea relevant references experimental evaluation BioBase dataset.
also discussed here, dataset entity labels 100 frequent
names. Therefore, instead running collective resolution entire BioBase dataset,
evaluated 100 names separately, using relevant references case.
relevant references ones directly connected references names
interest. concept focused cleaning, performance analysis relational clustering, expand-resolve strategy and, importantly, idea adaptive expansion
query-time resolution addressed paper.
One first papers make use relational features classification problem
Chakrabarti, Dom, Indyk (1998). showed problem classifying
651

fiBhattacharya & Getoor

hyper-linked documents, naive use relationships hurt performance. Specifically,
key terms neighboring documents thrown document whose topic
classified, classification accuracy degrades instead improving. parallel scenario
clustering using relationships naive relational model (NR) may perform worse
attribute model (A) presence highly ambiguous relationships. Chakrabarti
et al. (1998) showed relationships however used improved classification
topic labels neighboring documents used evidence instead naively
considering terms contain. earlier work (Bhattacharya & Getoor, 2004,
2007), shown similar results collective clustering using relationships,
cluster labels neighboring labels lead improved clustering performance compared
naive relational attribute-based clustering. interesting result shown
paper theory empirically even collective use relationships
hurt clustering accuracy compared attribute-based clustering. happens
relationships references dense ambiguous, errors propagate
relationships exceed identifying evidence provide.

9. Conclusions
paper, motivated problem query-time entity resolution accessing
unresolved third-party databases. answering entity resolution queries, addressed challenges using collective approaches, recently shown significant
performance improvements traditional baselines offline setting. first hurdle
collective resolution arises interdependent nature resolution decisions.
first formally analyzed recursive nature dependency, showed precision recall individual entities grow geometric progression increasing levels
neighbors considered collectively resolved. proposed two-stage expand
resolve strategy answering queries based analysis, using two novel expansion
operators. showed using analysis sufficient consider neighbors small
expansion depths, since resolution accuracy query converges quickly increasing
expansion level. second challenge answering queries computation
quick. achieve this, improved unconstrained expansion strategy propose
adaptive algorithm, dramatically reduces size relevant references
and, result, processing time identifying informative references
query. demonstrated using experiments two real datasets strategies
enable collective resolution query-time, without compromising accuracy. additionally performed various experiments synthetically generated data wide range
settings verify trends predicted analysis. summary, addressed
motivated critical data integration retrieval problem, proposed algorithms
solving accurately efficiently, provided theoretical analysis validate approach
explain works, and, finally, shown experimental results multiple real-world
synthetically generated datasets demonstrate works extremely well practice. presented results bibliographic data, techniques applicable
relational domains.
shown dramatic reduction query processing time comes
adaptive expansion, research necessary able answer entity resolution queries
652

fiQuery-time Entity Resolution

order milli-seconds, may demanded many scenarios. Interesting directions
future research include exploring stronger coupling extraction resolution
phases query processing, expansion happens on-demand
resolution process finds residual ambiguity high requires additional evidence
taking decisions. would directly address problem determining
expansion depth. reported preliminary experiments paper,
work needs done adaptive depth determination depending ambiguity.
context, may imagine soft thresholds adaptive expansion, expansion
operator automatically determines number hyper-edges names expanded
residual ambiguity falls specified level. interesting extensions
include caching intermediate resolutions, related resolutions performed
query stored retrieved required answering future queries.

Acknowledgments
wish thank anonymous reviewers constructive suggestions greatly
improved paper. work supported National Science Foundation, NSF
#0423845 NSF #0438866, additional support ITIC KDD program.

Appendix
Synthetic Data Generator
designed synthetic data generator allows us control different structural
attribute-based characteristics data(Bhattacharya & Getoor, 2007).
present overview generation algorithm.
generation process two stages. first stage, create collaboration
graph among underlying entities entity attributes. second, generate
observed co-occurrence relations collaboration graph. high level description
generative process shown Figure 10. Next, describe two stages
generation process greater detail.
graph creation stage, turn, two sub-stages. First, create domain
entities attributes add relationships them. creating entities,
control number entities ambiguity attributes. create N entities
attributes one another. simplicity without losing generality,
entity e single floating point attribute e.x, instead character string. parameter
pa controls ambiguity entity attributes; probability pa attribute new
entity chosen values already use existing entities. binary
relationships added created entities. attributes,
parameter controlling ambiguity relationships, defined Section 4.
binary relationship (ei , ej ), first ei chosen randomly ej sampled (ei , ej )
ambiguous relationship probability pR
a.
describing process generating co-occurrence relationships graph,
let us consider little detail issue attribute ambiguity. finally needs
controlled ambiguity reference attributes. depend
entity attributes, completely determined entities. Taking example
653

fiBhattacharya & Getoor

1.
2.
3.
4.
5.
6.
7.

Creation Stage
Repeat N times
Create random attribute x ambiguity pa
Create entity e attribute x
Repeat times
Choose entity ei randomly
Choose entity ej prob pR
ambiguous relationship (ei , ej )
Set ei = N br(ej ) ej = N br(ei )

8.
9.
10.
11.
12.
13.
14.
15.
16.

Generation Stage
Repeat R times
Randomly choose entity e
Generate reference r using N (e.x, 1)
Initialize hyper-edge h = hri
Repeat probability pc
Randomly choose ej N br(e) without replacement
Generate reference rj using N (ej .x, 1)
Add rj hyper-edge h
Output hyper-edge h

Figure 10: High-level description synthetic data generation algorithm

names, two people names John Michael Smyth James Daniel Smith
still ambiguous terms observed names data depending
generation process observed names. words, attribute ambiguity references
depends separation entity attributes dispersion created
generation process. make assumption entity e attribute e.x,
references generated Gaussian distribution mean x variance 1.0. So,
high probability, reference attribute generated e.x range
[e.x 3, e.x + 3]. range attribute domain considered occupied
entity e. entity ambiguous attribute occupied range intersects
another entity.
come generation co-occurrence relationships entity collaboration graph. stage, R co-occurrence relationships hyper-edges generated,
references. hyper-edge hri , ri1 , . . . , rik i, two aspects need controlled many references references included hyper-edge.
done follows. First, sample entity ei serves initiator entity
hyper-edge. entities eij hyper-edge repeatedly sampled (without replacement) neighbors initiator entity ei . size hyper-edge
determined using parameter pc . sampling step hyper-edge terminated
probability pc selection eij . process also terminated neighbors
initiator entity exhausted. Finally, references rij need generated
selected entities eij . done entity e sampling Gaussian
distribution N (e.x, 1).
654

fiQuery-time Entity Resolution

References
Ananthakrishna, R., Chaudhuri, S., & Ganti, V. (2002). Eliminating fuzzy duplicates
data warehouses. International Conference Large Databases (VLDB),
Hong Kong, China.
Benjelloun, O., Garcia-Molina, H., Su, Q., & Widom, J. (2005). Swoosh: generic approach
entity resolution. Tech. rep., Stanford University.
Bhattacharya, I., & Getoor, L. (2004). Iterative record linkage cleaning integration. SIGMOD Workshop Research Issues Data Mining Knowledge
Discovery (DMKD), Paris, France.
Bhattacharya, I., & Getoor, L. (2005). Relational clustering multi-type entity resolution. ACM SIGKDD Workshop Multi Relational Data Mining (MRDM),
Chicago, IL, USA.
Bhattacharya, I., & Getoor, L. (2006). Mining Graph Data (L. Holder D. Cook, eds.),
chap. Entity Resolution Graphs. Wiley.
Bhattacharya, I., & Getoor, L. (2007). Collective entity resolution relational data. ACM
Transactions Knowledge Discovery Data (TKDD), 1 (1).
Bhattacharya, I., Licamele, L., & Getoor, L. (2006). Query-time entity resolution.
ACM International Conference Knowledge Discovery Data Mining (SIGKDD),
Philadelphia, PA, USA.
Bilenko, M., & Mooney, R. (2003). Adaptive duplicate detection using learnable string
similarity measures. ACM International Conference Knowledge Discovery
Data Mining (SIGKDD), Washington DC, USA.
Bilenko, M., Mooney, R., Cohen, W., Ravikumar, P., & Fienberg, S. (2003). Adaptive name
matching information integration.. IEEE Intelligent Systems, 18 (5), 1623.
Chakrabarti, S., Dom, B., & Indyk, P. (1998). Enhanced hypertext categorization using
hyperlinks. Proceedings ACM International Conference Management
Data (SIGMOD).
Chandel, A., Nagesh, P. C., & Sarawagi, S. (2006). Efficient batch top-k search
dictionary-based entity recognition. IEEE International Conference Data
Engineering (ICDE), Washington, DC, USA.
Chaudhuri, S., Ganjam, K., Ganti, V., & Motwani, R. (2003). Robust efficient fuzzy
match online data cleaning. ACM International Conference Management
Data (SIGMOD), San Diego, CA, USA.
Cohen, W., Kautz, H., & McAllester, D. (2000). Hardening soft information sources.
ACM International Conference Knowledge Discovery Data Mining (SIGKDD),
Boston, MA, USA.
Dong, X., Halevy, A., & Madhavan, J. (2005). Reference reconciliation complex information spaces. ACM International Conference Management Data
(SIGMOD), Baltimore, MD, USA.
655

fiBhattacharya & Getoor

Draper, D., & Hanks, S. (1994). Localized partial evaluation belief networks.
Annual Conference Uncertainty Artificial Intelligence (UAI), Seattle, WA, USA.
Emde, W., & Wettschereck, D. (1996). Relational instance based learning. Proceedings
International Conference Machine Learning (ICML).
Fellegi, I., & Sunter, A. (1969). theory record linkage. Journal American
Statistical Association, 64, 11831210.
Fuxman, A., Fazli, E., & Miller, R. (2005). Conquer: Efficient management inconsistent
databases. ACM International Conference Management Data (SIGMOD), Baltimore, MD, USA.
Gravano, L., Ipeirotis, P., Koudas, N., & Srivastava, D. (2003). Text joins data cleansing integration rdbms. IEEE International Conference Data
Engineering (ICDE), Bangalore, India.
Hernandez, M., & Stolfo, S. (1995). merge/purge problem large databases.
ACM International Conference Management Data (SIGMOD), San Jose, CA,
USA.
Kalashnikov, D., Mehrotra, S., & Chen, Z. (2005). Exploiting relationships domainindependent data cleaning. SIAM International Conference Data Mining (SIAM
SDM), Newport Beach, CA, USA.
Kirsten, M., & Wrobel, S. (1998). Relational distance-based clustering. Proceedings
International Workshop Inductive Logic Programming (ILP).
Li, X., Morie, P., & Roth, D. (2005). Semantic integration text: ambiguous names
identifiable entities. AI Magazine. Special Issue Semantic Integration, 26 (1).
Long, B., Zhang, Z. M., Wu, X., & Yu, P. S. (2006). Spectral clustering multi-type relational data. Proceedings 23rd International Conference Machine Learning
(ICML).
McCallum, A., Nigam, K., & Ungar, L. (2000). Efficient clustering high-dimensional data
sets application reference matching. ACM International Conference
Knowledge Discovery Data Mining (SIGKDD), Boston, MA, USA.
McCallum, A., & Wellner, B. (2004). Conditional models identity uncertainty application noun coreference. Advances Neural Information Processing Systems
(NIPS), Vancouver, BC, Canada.
Monge, A., & Elkan, C. (1996). field matching problem: Algorithms applications.
ACM International Conference Knowledge Discovery Data Mining
(SIGKDD), Portland, OR, USA.
Monge, A., & Elkan, C. (1997). efficient domain-independent algorithm detecting
approximately duplicate database records. SIGMOD Workshop Research
Issues Data Mining Knowledge Discovery (DMKD), Tuscon, AZ, USA.
Navarro, G. (2001). guided tour approximate string matching. ACM Computing
Surveys, 33 (1), 3188.
656

fiQuery-time Entity Resolution

Pasula, H., Marthi, B., Milch, B., Russell, S., & Shpitser, I. (2003). Identity uncertainty
citation matching. Advances Neural Information Processing Systems (NIPS),
Vancouver, BC, Canada.
Ravikumar, P., & Cohen, W. (2004). hierarchical graphical model record linkage.
Conference Uncertainty Artificial Intelligence (UAI), Banff, Alberta,
Canada.
Sarawagi, S., & Bhamidipaty, A. (2002). Interactive deduplication using active learning.
Proceedings Eighth ACM International Conference Knowledge Discovery
Data Mining (SIGKDD), Edmonton, Alberta, Canada.
Singla, P., & Domingos, P. (2004). Multi-relational record linkage. SIGKDD Workshop Multi-Relational Data Mining (MRDM), Seattle, WA, USA.
Tejada, S., Knoblock, C., & Minton, S. (2001). Learning object identification rules
information integration. Information Systems Journal, 26 (8), 635656.
Winkler, W. (2002). Methods record linkage Bayesian networks. Tech. rep., Statistical Research Division, U.S. Census Bureau, Washington, DC.

657

fiJournal Artificial Intelligence Research 30 (2007) 321359

Submitted 11/06; published 10/07

New Inference Rules Max-SAT
Chu Min Li

chu-min.li@u-picardie.fr

LaRIA, Universite de Picardie Jules Verne
33 Rue St. Leu, 80039 Amiens Cedex 01, France

Felip Manya

felip@iiia.csic.es

IIIA, Artificial Intelligence Research Institute
CSIC, Spanish National Research Council
Campus UAB, 08193 Bellaterra, Spain

Jordi Planes

jplanes@diei.udl.es

Computer Science Department, Universitat de Lleida
Jaume II, 69, 25001 Lleida, Spain

Abstract
Exact Max-SAT solvers, compared SAT solvers, apply little inference
node proof tree. Commonly used SAT inference rules like unit propagation produce
simplified formula preserves satisfiability but, unfortunately, solving Max-SAT
problem simplified formula equivalent solving original formula.
paper, define number original inference rules that, besides applied
efficiently, transform Max-SAT instances equivalent Max-SAT instances
easier solve. soundness rules, seen refinements unit resolution
adapted Max-SAT, proved novel simple way via integer programming
transformation. aim finding powerful inference rules practice,
developed new Max-SAT solver, called MaxSatz, incorporates rules,
performed experimental investigation. results provide empirical evidence
MaxSatz competitive, least, random Max-2SAT, random Max-3SAT, MaxCut, Graph 3-coloring instances, well benchmarks Max-SAT
Evaluation 2006.

1. Introduction
recent years growing interest developing fast exact Max-SAT
solvers (Alber, Gramm, & Niedermeier, 2001; Alsinet, Manya, & Planes, 2003b, 2005;
de Givry, Larrosa, Meseguer, & Schiex, 2003; Li, Manya, & Planes, 2005; Xing & Zhang,
2004; Zhang, Shen, & Manya, 2003) due potential solve over-constrained NPhard problems encoded formalism Boolean CNF formulas. Nowadays, Max-SAT
solvers able solve lot instances beyond reach solvers developed
five years ago. Nevertheless, yet considerable gap difficulty
instances solved current SAT solvers instances solved best performing
Max-SAT solvers.
motivation behind work bridge gap complete SAT solvers
exact Max-SAT solvers investigating technology previously developed
SAT (Goldberg & Novikov, 2001; Li, 1999; Marques-Silva & Sakallah, 1999; Zhang, 1997;
Zhang, Madigan, Moskewicz, & Malik, 2001) extended incorporated Maxc
2007
AI Access Foundation. rights reserved.

fiLi, Manya & Planes

SAT. precisely, focus attention branch bound Max-SAT solvers based
Davis-Putnam-Logemann-Loveland (DPLL) procedure (Davis, Logemann, & Loveland,
1962; Davis & Putnam, 1960).
One main differences SAT solvers Max-SAT solvers former
make intensive use unit propagation node proof tree. Unit propagation,
highly powerful inference rule, transforms SAT instance satisfiability
equivalent SAT instance easier solve. Unfortunately, solving Max-SAT
problem is, general, equivalent solving ; i.e., number unsatisfied
clauses every truth assignment. example, apply
unit propagation CNF formula = {x1 , x1 x2 , x1 x2 , x1 x3 , x1 x3 },
obtain = {2, 2}, equivalent interpretation satisfying
x1 unsatisfies one clause two clauses . Therefore, want compute
optimal solution, cannot apply unit propagation SAT solvers.
proposed previous work (Li et al., 2005) use unit propagation compute
lower bounds branch bound Max-SAT solvers instead using unit propagation
simplify CNF formulas. approach, detect disjoint inconsistent subsets clauses
via unit propagation. turns number disjoint inconsistent subsets detected
underestimation number clauses become unsatisfied current
partial assignment extended complete assignment. underestimation plus
number clauses unsatisfied current partial assignment provides good performing
lower bound, captures lower bounds based inconsistency counts
state-of-the-art Max-SAT solvers implement (Alsinet, Manya, & Planes, 2003a; Alsinet
et al., 2003b; Borchers & Furman, 1999; Wallace & Freuder, 1996; Zhang et al., 2003),
well improved lower bounds (Alsinet, Manya, & Planes, 2004; Alsinet et al., 2005;
Xing & Zhang, 2004, 2005).
one hand, number disjoint inconsistent subsets detected conservative underestimation lower bound, since every inconsistent subset increases
lower bound one independently number clauses unsatisfied optimal
assignment. However, optimal assignment violate one clause inconsistent subset. Therefore, able improve lower bound based counting
number disjoint inconsistent subsets clauses.
hand, despite fact good quality lower bounds prune large parts
search space accelerate dramatically search optimal solution, whenever
lower bound reach best solution found far (upper bound), solver
continues exploring search space current node. search, solvers
often redetect inconsistencies computing lower bound different nodes.
Basically, problem lower bound computation methods simplify
CNF formula way unsatisfied clauses become explicit. Lower bounds
pruning technique.
overcome two problems, define set sound inference rules
transform Max-SAT instance Max-SAT instance easier solve.
Max-SAT, inference rule sound whenever equivalent.
Let us see example inference rule: Given Max-SAT instance contains
three clauses form l1 , l2 , l1 l2 , l1 , l2 literals, replace CNF
322

fiNew Inference Rules Max-SAT

formula
= ( {l1 , l2 , l1 l2 }) {2, l1 l2 }.
Note rule detects contradiction l1 , l2 , l1 l2 and, therefore, replaces
clauses empty clause. addition, rule adds clause l1 l2 ensure
equivalence . assignment containing either l1 = 0, l2 = 1,
l1 = 1, l2 = 0, l1 = 1, l2 = 1, number unsatisfied clauses {l1 , l2 , l1 l2 } 1,
assignment containing l1 = 0, l2 = 0, number unsatisfied clauses 2.
Note even assignment containing l1 = 0, l2 = 0 best assignment
subset {l1 , l2 , l1 l2 }, best whole formula. adding l1 l2 ,
rule ensures number unsatisfied clauses also
l1 = 0, l2 = 0.
inference rule adds new clause l1 l2 , may contribute another contradiction detectable via unit propagation. case, rule allows increase
lower bound 2 instead 1. Moreover, rule makes explicit contradiction among
l1 , l2 , l1 l2 , contradiction need redetected current
node.
inference rules defined paper already known literature (Bansal & Raman, 1999; Niedermeier & Rossmanith, 2000), others original
Max-SAT. new rules inspired different unit resolution refinements applied
SAT, selected could applied natural efficient way.
sense, summarize work telling defined Max-SAT counterpart
SAT unit propagation.
aim finding powerful inference rules practice,
designed implemented new Max-SAT solver, called MaxSatz, incorporates
rules, well lower bound defined previous work (Li et al., 2005), performed
experimental investigation. results provide empirical evidence MaxSatz
competitive, least, random Max-2SAT, random Max-3SAT, Max-Cut, Graph
3-coloring instances, well benchmarks Max-SAT Evaluation 20061 .
structure paper follows. Section 2, give preliminary definitions. Section 3, describe basic branch bound Max-SAT solver. Section 4,
define inference rules prove soundness novel simple way via integer
programming transformation. also give examples illustrate inference rules
may produce better quality lower bounds. Section 5, present implementation
inference rules MaxSatz. Section 6, describe main features MaxSatz.
Section 7, report experimental investigation. Section 8, present related
work. Section 9, present conclusions future work.

2. Preliminaries
propositional logic variable xi may take values 0 (for false) 1 (for true). literal li
variable xi negation xi . clause disjunction literals, CNF formula
conjunction clauses. length clause number literals. size
, denoted ||, sum length clauses.
1. http://www.iiia.csic.es/maxsat06

323

fiLi, Manya & Planes

assignment truth values propositional variables satisfies literal xi xi
takes value 1 satisfies literal xi xi takes value 0, satisfies clause
satisfies least one literal clause, satisfies CNF formula satisfies
clauses formula. empty clause, denoted 2, contains literals cannot
satisfied. assignment CNF formula complete variables occurring
assigned; otherwise, partial.
Max-SAT problem CNF formula problem finding assignment
values propositional variables minimizes number unsatisfied clauses (or
equivalently, maximizes number satisfied clauses). Max-SAT called MaxkSAT clauses k literals per clause. following, represent CNF
formula multiset clauses, since duplicated clauses allowed Max-SAT instance.
CNF formulas 1 2 equivalent 1 2 number unsatisfied
clauses every complete assignment 1 2 .

3. Basic Max-SAT Solver
space possible assignments CNF formula represented search
tree, internal nodes represent partial assignments leaf nodes represent complete
assignments. basic branch bound algorithm Max-SAT explores search tree
depth-first manner. every node, algorithm compares number clauses unsatisfied best complete assignment found far called upper bound (U B)
number clauses unsatisfied current partial assignment (#emptyClauses) plus
underestimation minimum number non-empty clauses become unsatisfied
extend current partial assignment complete assignment (underestimation).
sum #emptyClauses + underestimation lower bound (LB) minimum
number clauses unsatisfied complete assignment extended current partial
assignment. Obviously, LB U B, better solution cannot found point
search. case, algorithm prunes subtree current node backtracks
higher level search tree.
LB < U B, algorithm tries find possible better solution extending
current partial assignment instantiating one variable; leads creation
two branches current branch: left branch corresponds assigning new
variable false, right branch corresponds assigning new variable true.
case, formula associated left (right) branch obtained formula
current node deleting clauses containing literal x (x) removing
occurrences literal x (x); i.e., algorithm applies one-literal rule.
solution Max-SAT value U B takes exploring entire search
tree.
Figure 1 shows pseudo-code basic solver Max-SAT. use following
notations:
simplifyFormula() procedure simplifies applying sound inference rules.
#emptyClauses() function returns number empty clauses .
324

fiNew Inference Rules Max-SAT

Input: max-sat(, U B) : CNF formula upper bound U B
1: simplifyFormula();
2: = contains empty clauses
3:
return #emptyClauses();
4: end
5: LB #emptyClauses() + underestimation(, U B);
6: LB U B
7:
return U B;
8: end
9: x selectVariable();
10: U B min(U B, max-sat(x , U B));
11: return min(U B, max-sat(x , U B));
Output: minimal number unsatisfied clauses
Figure 1: basic branch bound algorithm Max-SAT
LB lower bound minimum number unsatisfied clauses current
partial assignment extended complete assignment. assume initial
value 0.
underestimation(, U B) function returns underestimation minimum
number non-empty clauses become unsatisfied current partial
assignment extended complete assignment.
U B upper bound number unsatisfied clauses optimal solution.
assume initial value total number clauses input formula.
selectVariable() function returns variable following heuristic.
x (x ) formula obtained applying one-literal rule using literal
x (x).
State-of-the-art Max-SAT solvers implement basic algorithm augmented powerful inference techniques, good quality lower bounds, clever variable selection heuristics,
efficient data structures.
recently defined (Li et al., 2005) lower bound computation method
underestimation lower bound number disjoint inconsistent subsets
detected using unit propagation. pseudo-code shown Figure 2.
Example 1 Let following CNF formula:
{x1 , x2 , x3 , x4 , x1 x2 x3 , x4 , x5 , x5 x2 , x5 x2 }.
approach able establish number disjoint inconsistent
subsets clauses least 3. Therefore, underestimation lower bound 3.
steps performed following ones:
325

fiLi, Manya & Planes

Input: underestimation(, U B) : CNF formula upper bound U B
1: underestimation 0;
2: apply one-literal rule unit clauses (unit propagation) empty
clause derived;
3: empty clause derived
4:
return underestimation;
5: end
6: without clauses used derive empty clause;
7: underestimation := underestimation + 1;
8: underestimation+#emptyClauses() U B
9:
return underestimation;
10: end
11: go 2;
Output: underestimation lower bound
Figure 2: Computation underestimation using unit propagation
1. = {x4 , x4 , x5 , x5 x2 , x5 x2 }, first inconsistent subset detected using unit
propagation {x1 , x2 , x3 , x1 x2 x3 }, underestimation = 1.
2. = {x5 , x5 x2 , x5 x2 }, second inconsistent subset detected using unit propagation
{x4 , x4 }, underestimation = 2.
3. = , third inconsistent subset detected using unit propagation {x5 , x5 x2 , x5
x2 }, underestimation = 3. Since empty, algorithm stops.

4. Inference Rules
define set inference rules considered paper. inspired different
unit resolution refinements applied SAT, selected could applied
natural efficient way. already known literature (Bansal &
Raman, 1999; Niedermeier & Rossmanith, 2000), others original Max-SAT.
presenting rules, define integer programming transformation CNF
formula used establish soundness rules. method proving soundness
novel Max-SAT, provides clear short proofs.
4.1 Integer Programming Transformation CNF Formula
Assume = {c1 , ..., cm } CNF formula clauses variables x1 , ..., xn .
Let ci (1 m) xi1 ... xik xik+1 ... xik+r . Note put positive literals
ci negative ones.
consider variables ci integer variables taking values 0 1, define
integer transformation ci
Ei (xi1 , ..., xik , xik+1 , ..., xik+r ) = (1 xi1 )...(1 xik )xik+1 ...xik+r
326

fiNew Inference Rules Max-SAT

Obviously, Ei value 0 iff least one variables xij (1 j k) instantiated
1 least one variables xis (k + 1 k + r) instantiated 0.
words, Ei =0 iff ci satisfied. Otherwise Ei =1.
literal l corresponds integer denoted l convenience. intention
correspondence literal l satisfied integer l 1 unsatisfied
integer l 0. l positive literal x, corresponding integer l x, l 1-x=1-l,
l negative literal x, l 1-x l x=1-(1-x)=1-l. Consequently, l=1-l
case.
generically write ci l1 l2 ... lk+r . integer programming transformation

Ei = (1 l1 )(1 l2 )...(1 lk+r ).
integer programming transformation CNF formula = {c1 , ..., cm }
variables x1 , ..., xn defined
E(x1 , ..., xn ) =


X

Ei

(1)

i=1

integer programming transformation used (Huang & Jin, 1997; Li & Huang,
2005) design local search procedure, called pseudo-Boolean formulation Boros
Hammer (2002). Here, extend empty clauses: ci empty, Ei =1.
Given assignment variables x1 , ..., xn , value E number
unsatisfied clauses . satisfies clauses , E = 0. Obviously, minimum
number unsatisfied clauses minimum value E.
Let 1 2 two CNF formulas, let E1 E2 integer programming
transformations. clear 1 2 equivalent if, if, E1 =E2 every
complete assignment 1 2 .
4.2 Inference Rules
next define inference rules prove soundness using previous integer
programming transformation. rest section, 1 , 2 denote CNF formulas,
E1 , E2 , E integer programming transformations. prove 1 2
equivalent, prove E1 = E2 .
Rule 1 (Bansal & Raman, 1999) 1 ={l1 l2 ... lk , l1 l2 ... lk } ,
2 ={l2 ... lk } equivalent 1 .
Proof 1
E1 = (1 l1 )(1 l2 )...(1 lk ) + l1 (1 l2 )...(1 lk ) + E
= (1 l2 )...(1 lk ) + E
= E2



General case resolution work Max-SAT (Bansal & Raman, 1999). Rule 1
establishes resolution works two clauses give strictly shorter resolvent.
327

fiLi, Manya & Planes

Rule 1 known literature replacement almost common clauses. pay
special attention case k=2, resolvent unit clause, case k=1,
resolvent empty clause. describe latter case following rule:
Rule 2 (Niedermeier & Rossmanith, 2000) 1 ={l, l} , 2 ={2} equivalent
1 .
Proof 2 E1 =1-l+ l+E =1+ E =E2



Rule 2, known complementary unit clause rule, used replace two
complementary unit clauses empty clause. new empty clause contributes
lower bounds search space current node incrementing number
unsatisfied clauses, incrementing underestimation, means
contradiction redetected again. practice, simple rule gives rise
considerable gains.
following rule complicated case:
Rule 3 1 ={l1 , l1 l2 , l2 } , 2 ={2, l1 l2 } equivalent 1 .
Proof 3
E1 = 1 l1 + l1 l2 + 1 l2 + E
= 1 + 1 l1 + l2 (l1 1) + E
= 1 + 1 l1 l2 (1 l1 ) + E
= 1 + (1 l1 )(1 l2 ) + E
= E2



Rule 3 replaces three clauses empty clause, adds new binary clause
keep equivalence 1 2 .
Pattern 1 considered compute underestimations Alsinet et al. (2004) Shen
Zhang (2004); also captured method computing underestimations based
unit propagation (Li et al., 2005). Larrosa Heras mentioned (2005) existential
directional arc consistency (de Givry, Zytnicki, Heras, & Larrosa, 2005) capture
rule. Note underestimation computation methods Alsinet et al. Shen
Zhang add additional clause approach, detect contradictions.
Let us define rule generalizes Rule 2 Rule 3. presenting rule,
define lemma needed prove soundness.
Lemma 1 1 ={l1 , l1 l2 } 2 ={l2 , l2 l1 } , 1 2 equivalent.
Proof 4
E1 = 1 l1 + l1 (1 l2 ) + E
= 1 l1 + l1 l1 l2 + E
= 1 l2 + l2 l1 l2 + E
= 1 l2 + (1 l1 )l2 + E
= E2


328

fiNew Inference Rules Max-SAT

Rule 4 1 ={l1 , l1 l2 , l2 l3 , ..., lk lk+1 , lk+1 } , 2 ={2, l1 l2 , l2 l3 , ..., lk
lk+1 } equivalent 1 .
Proof 5 prove soundness rule induction k. k=1, 1 = {l1 , l1
l2 , l2 } . applying Rule 3, get {2, l1 l2 } , 2 k = 1. Therefore,
1 2 equivalent.
Assume Rule 4 sound k = n. Let us prove sound k = n + 1.
case:
1 = {l1 , l1 l2 , l2 l3 , ..., ln ln+1 , ln+1 ln+2 , ln+2 } .
applying Lemma 1 last two clauses 1 (before ), get
{l1 , l1 l2 , l2 l3 , ..., ln ln+1 , ln+1 , ln+1 ln+2 } .
applying induction hypothesis first n + 1 clauses previous CNF formula,
get
{2, l1 l2 , l2 l3 , ..., ln ln+1 , ln+1 ln+2 } ,
2 k = n + 1. Therefore, 1 2 equivalent rule sound.

Rule 4 original inference rule. captures linear unit resolution refutations
clauses resolvents used exactly once. rule simply adds empty clause,
eliminates two unit clauses binary clauses used refutation, adds new
binary clauses obtained negating literals eliminated binary clauses.
So, operations involved performed efficiently.
Rule 3 Rule 4 make explicit contradiction, need redetected
current subtree. So, lower bound computation becomes incremental. Moreover,
binary clauses added Rule 3 Rule 4 may contribute compute better quality
lower bounds either acting premises inference rule part
inconsistent subset clauses, illustrated following example.
Example 2 Let ={x1 , x1 x2 , x3 , x3 x2 , x4 , x1 x4 , x3 x4 }. Depending ordering
unit clauses propagated, unit propagation detects one following three
inconsistent subsets clauses: {x1 , x1 x2 , x3 , x3 x2 }, {x1 , x4 , x1 x4 }, {x3 , x4 , x3
x4 }. inconsistent subset detected removed, remaining set clauses
satisfiable. Without applying Rule 3 Rule 4, lower bound computed 1,
underestimation computed using unit propagation 1.
Note Rule 4 applied first inconsistent subset {x1 , x1 x2 , x3 , x3 x2 }.
Rule 4 applied, contradiction made explicit clauses x1 x2 x3 x2
added. So, becomes {2, x1 x2 , x3 x2 , x4 , x1 x4 , x3 x4 }. turns {2}
inconsistent set clauses detectable unit propagation. Therefore, lower bound
computed 2.
inconsistent subset {x1 , x4 , x1 x4 } detected, Rule 3 applied. Then,
contradiction made explicit clause x1 x4 added. So, becomes {2, x1 x4 , x1
x2 , x3 , x3 x2 , x3 x4 }. turns {2} inconsistent set clauses detectable
unit propagation. Therefore, lower bound computed 2.
329

fiLi, Manya & Planes

Similarly, inconsistent subset {x3 , x4 , x3 x4 } detected Rule 3 applied,
lower bound computed 2.
observe that, example, Rule 3 Rule 4 make explicit contradiction, also allow improve lower bound.
Unit propagation needs least one unit clause detect contradiction. drawback
Rule 3 Rule 4 consume two unit clauses deriving one contradiction. possible situation that, branching, two unit clauses could allow
unit propagation derive two disjoint inconsistent subsets clauses, show
following example.
Example 3 Let ={x1 , x1 x2 , x1 x3 , x2 x3 x4 , x5 , x5 x6 , x5 x7 , x6 x7 x4 , x1 x5 }.
Rule 3 replaces x1 , x5 , x1 x5 empty clause x1 x5 . that, x4
selected next branching variable assigned 0, unit clause
contradiction detected via unit propagation. lower bound 1
situation. However, Rule 3 applied branching, two unit clauses
branching. case, propagation x1 allows detect inconsistent subset
{x1 , x1 x2 , x1 x3 , x2 x3 }, propagation x5 allows detect inconsistent
subset {x5 , x5 x6 , x5 x7 , x6 x7 }. So, lower bound computed branching 2.
one hand, Rule 3 Rule 4 add clauses contribute detect additional
conflicts. hand, application Rule 3 Rule 4 consumes two unit
clauses, cannot used detect conflicts. final effect two
factors empirically analyzed Section 7.
Finally, present two new rules capture unit resolution refutations
(i) exactly one unit clause consumed, (ii) unit clause used twice linear
derivation empty clause.
Rule 5 1 ={l1 , l1 l2 , l1 l3 , l2 l3 } , 2 ={2, l1 l2 l3 , l1 l2 l3 }
equivalent 1 .
Proof 6
E1 = 1 l1 + l1 (1 l2 ) + l1 (1 l3 ) + l2 l3 + E
= 1 l1 + l1 l1 l2 + l1 l1 l3 + l2 l3 + E
= 1 + l2 l3 l1 l2 l3 + l1 l1 l2 l1 l3 + l1 l2 l3 + E
= 1 + (1 l1 )l2 l3 + l1 (1 l2 l3 + l2 l3 ) + E
= 1 + (1 l1 )l2 l3 + l1 (1 l2 )(1 l3 ) + E
= E2



combine linear derivation Rule 5 obtain Rule 6:
Rule 6 1 ={l1 , l1 l2 , l2 l3 , ..., lk lk+1 , lk+1 lk+2 , lk+1 lk+3 , lk+2 lk+3 } ,
2 ={2, l1 l2 , l2 l3 , ..., lk lk+1 , lk+1 lk+2 lk+3 , lk+1 lk+2 lk+3 }
equivalent 1 .
330

fiNew Inference Rules Max-SAT

Proof 7 prove soundness rule induction k. k=1,
1 = {l1 , l1 l2 , l2 l3 , l2 l4 , l3 l4 } .
Lemma 1, get
Rule 5, get

{l1 l2 , l2 , l2 l3 , l2 l4 , l3 l4 } .
{l1 l2 , 2, l2 l3 l4 , l2 l3 l4 } ,

2 k = 1. Therefore, 1 2 equivalent.
Assume Rule 6 sound k = n. Let us prove sound k = n + 1.
case:
1 = {l1 , l1 l2 , l2 l3 , ..., ln+1 ln+2 , ln+2 ln+3 , ln+2 ln+4 , ln+3 ln+4 } .
Lemma 1, get
{l1 l2 , l2 , l2 l3 , ..., ln+1 ln+2 , ln+2 ln+3 , ln+2 ln+4 , ln+3 ln+4 } .
applying induction hypothesis, get
{l1 l2 , 2, l2 l3 , ..., ln+1 ln+2 , ln+2 ln+3 ln+4 , ln+2 ln+3 ln+4 } ,
2 k = n + 1. Therefore, 1 2 equivalent rule sound.

Similarly Rule 3 Rule 4, Rule 5 Rule 6 make explicit contradiction,
need redetected subsequent search. Therefore, lower bound computation becomes incremental. Moreover, also add clauses improve
quality lower bound, illustrated following example.
Example 4 Let ={x1 , x1 x2 , x1 x3 , x2 x3 , x4 , x1 x4 , x2 x4 , x3 x4 }. Depending
ordering unit clauses propagated, unit propagation detect one
following inconsistent subsets: {x1 , x1 x2 , x1 x3 , x2 x3 }, {x4 , x1 x4 , x2 x4 , x1 x2 },
{x4 , x1 x4 , x3 x4 , x1 x3 }, Rule 5 applicable. Rule 5 applied, lower
bound computed using underestimation function Figure 2 1, since remaining
clauses satisfiable inconsistent subset clauses removed. Rule 5 allows
add two ternary clauses contributing another contradiction. example, Rule 5
applied {x1 , x1 x2 , x1 x3 , x2 x3 } adds clauses x1 x2 x3 x1 x2 x3 ,
which, remaining clauses ({x4 , x1 x4 , x2 x4 , x3 x4 }), give second
contradiction detectable via unit propagation. lower bound computed using Rule 5
2.
contrast Rule 3 Rule 4, Rule 5 Rule 6 consume exactly one unit clause
deriving empty clause. Since unit clause used derive conflict
via unit propagation, Rule 5 Rule 6 limit detection conflicts via
unit propagation.
331

fiLi, Manya & Planes

5. Implementation Inference Rules
section, describe implementation inference rules presented Section 4. suppose CNF formula loaded and, every literal , list clauses
containing constructed. application rule means clauses 1
removed CNF formula, new clauses 2 inserted formula,
lower bound increased 1. Note inference rules selected approach,
2 contains fewer literals fewer clauses 1 , new clauses 2 inserted
place removed clauses 1 inference rule applied. Therefore,
need dynamic memory management implementation faster.
Rule 1 k=2 Rule 2 applied using matching algorithm (see, e.g., Cormen,
Leiserson, Rivest, & Stein, 2001, efficient implementation) lists clauses.
first time complexity O(m), number clauses CNF
formula. second time complexity O(u), u number unit clauses
CNF formula. rules applied every node, lower bound computation application inference rules. Rule 1 (k=2) applied many times
possible derive unit clauses applying Rule 2.
implementation Rule 3, Rule 4, Rule 5, Rule 6 entirely based unit
propagation. Given CNF formula , unit propagation constructs implication graph
G (see, e.g., Beame, Kautz, & Sabharwal, 2003), applicability inference
rules detected. section, first describe construction implication graph,
describe determine applicability Rule 3, Rule 4, Rule 5, Rule 6.
Then, analyze complexity, termination (in)completeness application
rules. Finally discuss extension inference rules weighted Max-SAT
implementation.
5.1 Implication Graph
Given CNF formula , Figure 3 shows unit propagation constructs implication
graph whose nodes literals.
Note every node G corresponds different literal, considered
different literals. CNF formula contains several copies unit clause ,
algorithm adds one node label .
Example 5 Let ={x1 , x1 , x1 x2 , x1 x3 , x2 x3 x4 , x5 , x5 x6 , x5 x7 , x6 x7 x4 , x5 x8 }.
U nitP ropagation constructs implication graph Figure 4, add special
node 2 highlight contradiction.
G always acyclic every added edge connects new node. well known
time complexity unit propagation O(||), || size (see, e.g.,
Freeman, 1995).
associate clause c=1 2 ...k1 k node k node k added G
c. Note node k incoming edge c unit (k=1),
node one incoming edge c binary (k=2). G constructed,
G contains literal (i.e., unit propagation deduces contradiction),
easy identify nodes exists path G; i.e., clauses
332

fiNew Inference Rules Max-SAT

Input: U nitP ropagation() : CNF formula containing complementary unit
clauses literal
initialize G empty graph
add node labeled every literal unit clause c
repeat
1 , 2 , ..., k1 nodes G, c = 1 2 ... k1 k clause , k
node G,
add G node labeled k
add G directed edge node k every (1 < k)
end
nodes added literal nodes
G
Return G
Output: Implication graph G
Figure 3: Unit propagation constructing implication graphs

x2
x4

x1
x3
x6
x5

x4
x7
x8

Figure 4: Example implication graph

333

fiLi, Manya & Planes

x1
c1
x5
c5

x2
c2
x6
c6

x3
c3
x4
c7

x4
c4

Figure 5: Example implication graph
implying . clauses constitute inconsistent subset .
example, clauses x1 , x1 x2 , x1 x3 x2 x3 x4 imply x4 , clauses x5 , x5 x6 , x5 x7
x6 x7 x4 imply x4 . Clause x5 x8 contribute contradiction.
inconsistent subset {x1 , x1 x2 , x1 x3 , x2 x3 x4 , x5 , x5 x6 , x5 x7 , x6 x7 x4 }.
5.2 Applicability Rule 3, Rule 4, Rule 5, Rule 6
assume unit propagation deduces contradiction and, therefore, implication
graph G contains literal . Let set nodes
exists path , let set nodes exists path
, let S=S . clause associated node G, also use S, ,
denote set clauses associated nodes S, , , respectively.
Lemma 2 Lemma 3 used detect applicability Rule 3, Rule 4, Rule 5,
Rule 6.
Lemma 2 Rule 3 Rule 4 applicable
1. (resp. ), one unit clause clauses binary,
2. nodes (resp. ) form implication chain starting unit clause ending
(resp. ),
3. empty.
Proof 8 Starting node corresponding unit clause (resp. ),
following parallel two implication chains, 1 Rule 3 Rule 4 writing
clause corresponding node.
Example 6 Let following CNF formula containing clauses c1 c7 : {c1 : x1 , c2 :
x1 x2 , c3 : x2 x3 , c4 : x3 x4 , c5 : x5 , c6 : x5 x6 , c7 : x6 x4 }. Unit propagation constructs implication graph shown Figure 5, contains complementary
literals x4 x4 .
Rule 4 applicable =x4 , ={x1 (c1 ), x2 (c2 ), x3 (c3 ), x4 (c4 )},
={x5 (c5 ), x6 (c6 ), x4 (c7 )}. easy verify three conditions Lemma 2
satisfied.
Remark: rewritten {c1 : x1 , c2 : x1 x2 , c3 : x2 x3 , c4 : x3 x4 , c7 :
x4 x6 , c6 : x6 x5 , c5 : x5 } compared 1 Rule 4.
334

fiNew Inference Rules Max-SAT

x1
c1

x2
c2

x3
c3
x4
c4

x4
c5

Figure 6: Example implication graph
application Rule 3 Rule 4 consists replacing every binary clause c
binary clause obtained negating every literal c, removing two unit clauses
, incrementing #emptyClauses() 1.
Lemma 3 Rule 5 Rule 6 applicable
1. S=S , one unit clause clauses binary; i.e.,
nodes S, except node corresponding unit clause, exactly one
incoming edge G.
2. non-empty contains k (k >0) nodes forming implication chain
form 1 2 k , k last node chain.
3. (S )-(S ) contains exactly three nodes : , , third one. Let k+1
third literal,
k+1 , G contains following implications
k k+1
k
k+1 , G contains following implications
k
k k+1
Proof 9 Assume, without loss generality, k+1 ; case k+1 symmetric. implication chain formed nodes corresponds clauses {1 ,
1 2 , . . . , k1 k }, which, together three clauses {k k+1 , k+1 , k }
corresponding k k+1 k , give 1 Rule 5 Rule 6.
Example 7 Let following CNF formula containing clauses c1 c5 : {c1 : x1 , c2 :
x1 x2 , c3 : x2 x3 , c4 : x2 x4 , c5 : x3 x4 }. Unit propagation constructs implication
graph shown Figure 6, contains complementary literals x4 x4 .
Sx4 ={x1 (c1 ), x2 (c2 ), x4 (c4 )} Sx4 ={x1 (c1 ), x2 (c2 ), x3 (c3 ), x4 (c5 )}.
nodes Sx4 Sx4 obviously form implication chain: x1 x2 . (Sx4 Sx4 )-(Sx4
Sx4 )={x3 (c3 ), x4 (c4 ), x4 (c5 )}. G contains x2 x3 x4 x2 x4 . Rule 6 applicable.
application Rule 5 Rule 6 consists removing unit clause
, replacing binary clause c binary clause obtained c
negating two literals c, replacing three binary clauses (S )-(S )
two ternary clauses, incrementing #emptyClauses() 1.
335

fiLi, Manya & Planes

5.3 Complexity, Termination, (In)Completeness Rule Applications
branch bound algorithm Max-SAT, combine application inference rules computation underestimation lower bound. Given CNF
formula , function underestimation uses unit propagation construct implication
graph G. G contains two nodes literal , G analyzed determine
whether inference rule applicable. rule applicable, applied
transformed equivalent Max-SAT instance. Otherwise, clauses contributing
contradiction removed , underestimation incremented 1.
procedure repeated unit propagation cannot derive contradictions. Finally,
removed clauses, except removed replaced due inference rule applications,
reinserted . underestimation, together new , returned.
well known unit propagation implemented time complexity linear
size (see, e.g., Freeman, 1995). complexity determining applicability
inference rules using Lemma 2 Lemma 3 linear size G, bounded
number literals , assume graph represented doubly-linked
lists. application inference rule obviously linear size G. So, whole
time complexity function underestimation inference rule applications O(d ||),
number contradictions function underestimation able detect
using unit propagation. Observe factor needed application
rules inserts new clauses place removed clauses.
Since every inference rule application reduces size , function underestimation
inference rule applications linear space complexity, always terminates. Recall
new clauses added inference rules stored place old ones.
data structures loading statically efficiently maintained.
proved inference rules sound. following example shows
application rules necessarily complete implementation, sense
possible applications inference rules necessarily done.
Example 8 Let ={x1 , x3 , x4 , x1 x3 x4 , x1 x2 , x2 }. Unit propagation may discover
inconsistent subset S={x1 , x3 , x4 , x1 x3 x4 }. case, inference rule applicable S. Then, underestimation lower bound incremented 1,
becomes {x1 x2 , x2 }. Unit propagation cannot detect contradictions , function underestimation stops reinserting {x1 , x3 , x4 , x1 x3 x4 } . value
1 returned, together unchanged . Note Rule 3 applicable subset
{x1 , x1 x2 , x2 } , applied.
Actually, function underestimation applies Rule 3 unit propagation detects
inconsistent subset {x1 , x1 x2 , x2 } instead {x1 , x3 , x4 , x1 x3 x4 }. detection
inconsistent subset depends ordering unit clauses propagated unit
propagation. example, inconsistent subset {x1 , x1 x2 , x2 } discovered unit
clause x2 propagated x3 x4 . study needed define orderings
unit clauses maximize application inference rules.
Observe algorithm deterministic, always computes lower bound
order clauses changed.
336

fiNew Inference Rules Max-SAT

5.4 Inference Rules Weighted Max-SAT
inference rules presented paper naturally extended weighted Max-SAT.
weighted Max-SAT, every clause associated weight problem consists
finding truth assignment sum weights unsatisfied clauses
minimum. example, weighted version Rule 3 could
Rule 7 1 ={(l1 , w1 ), (l1 l2 , w2 ), (l2 , w3 )} , 2 ={(2, w), (l1 l2 , w), (l1 , w1
w), (l1 l2 , w2 w), (l2 , w3 w)} equivalent 1
w1 , w2 w3 positive integers representing clause weight, w=min(w1 ,
w2 , w3 ). Mandatory clauses, satisfied optimal solution, specified
weight . Note w6=, -w= w=, optimal solution
found solver backtrack. Clauses weight 0 removed. Observe 1
rewritten 11 12 , 11 ={(l1 , w), (l1 l2 , w), (l2 , w)}, 12 ={(l1 , w1
w), (l1 l2 , w2 w), (l2 , w3 w)} . Then, weighted inference rule equivalent
unweighted version applied w times (unweighted) clauses 11 .
Similarly, weighted version Rule 4 could
Rule 8 1 ={(l1 , w1 ) (l1 l2 , w2 ), (l2 l3 , w3 ), . . . , (lk lk+1 , wk+1 ), (lk+1 , wk+2 )} ,
2 ={(2, w), (l1 l2 , w), (l2 l3 , w), . . . , (lk lk+1 , w), (l1 , w1 w), (l1 l2 , w2
w), (l2 l3 , w3 w), . . . , (lk lk+1 , wk+1 w), (lk+1 , wk+2 w)} equivalent 1
w=min(w1 , w2 , . . . , wk+2 ). Observe 1 also rewritten 11 12 ,
11 ={(l1 , w) (l1 l2 , w), (l2 l3 , w), . . . , (lk lk+1 , w), (lk+1 , w)}, weighted version
Rule 4 equivalent unweighted Rule 4 applied w times (unweighted) clauses
11 .
current implementation inference rules naturally extended weighted
inference rules. inconsistent subformula detected rule applicable (clause
weights considered detection inconsistent subformula applicability rule, provided clauses weight 0 discarded), 11
12 separated computing minimal weight w clauses detected
inconsistent subformula, rule applied 11 . derived clauses clauses
12 used subsequent reasoning.

6. MaxSatz: New Max-SAT Solver
implemented new Max-SAT solver, called MaxSatz, incorporates lower
bound computation method based unit propagation defined Section 3, applies
inference rules defined Section 4. name MaxSatz comes fact
implementation algorithm incorporates technology developed
SAT solver Satz (Li & Anbulagan, 1997b, 1997a).
MaxSatz incorporates lower bound based unit propagation, applies Rule 1,
Rule 2, Rule 3, Rule 4, Rule 5, Rule 6. addition, MaxSatz applies following
techniques:
Pure literal rule: literal appears either positive polarity negative
polarity, delete clauses containing literal.
337

fiLi, Manya & Planes

Empty-Unit clause rule (Alsinet et al., 2003a): Let neg1(x) (pos1(x)) number
unit clauses x negative (positive). #emptyClauses() + neg1(x) U B,
assign x false. #emptyClauses() + pos1(x) U B, assign x
true.
Dominating Unit Clause (DUC) rule (Niedermeier & Rossmanith, 2000): number clauses literal x (x) appears greater neg1(x) (pos1(x)),
assign x false (true).
Variable selection heuristic: Let neg2(x) (pos2(x)) number binary clauses
x negative (positive), let neg3(x) (pos3(x)) number clauses
containing three literals x negative (positive). select
variable x (neg1(x)+4neg2(x)+neg3(x))*(pos1(x)+4pos2(x)+pos3(x))
largest. fact binary clauses counted four times
clauses determined empirically.
Value selection heuristic: Let x selected branching variable. neg1(x) + 4
neg2(x) + neg3(x) < pos1(x) + 4 pos2(x) + pos3(x), set x true. Otherwise set x
false. heuristics also determined empirically.
paper, order compare inference rules defined, used three simplified versions MaxSatz:
MaxSat0: apply inference rule defined Section 4.
MaxSat12: applies rules 1 2, rules 3, 4, 5 6.
MaxSat1234: applies rules 1, 2, 3 4, rules 5 6.
Actually, MaxSatz corresponds MaxSat123456 terminology. MaxSat12 corresponds improved version solver U P (Li et al., 2005), using special ordering
propagating unit clauses unit propagation. MaxSat12 maintains two queues
unit propagation: Q1 Q2 . MaxSat12 starts search inconsistent subformula via unit propagation, Q1 contains unit clauses CNF formula
consideration (more recently derived unit clauses end Q1 ), Q2 empty.
unit clauses derived application unit propagation stored Q2 ,
unit propagation use unit clause Q1 unless Q2 empty. Intuitively,
ordering prefers unit clauses non-unit clauses starting application
unit propagation. way, derived inconsistent subset contains, general, less unit
clauses. unit clauses consumed contribute detect
inconsistent subsets. experimental results (Li, Manya, & Planes, 2006) show
search tree size MaxSat12 substantially smaller UP, MaxSat12
substantially faster UP. MaxSat0, Maxsat1234, MaxSatz use ordering
MaxSat12 propagating unit clauses unit propagation.
source code MaxSat0, MaxSat12, MaxSat1234, MaxSatz found
http://web.udl.es/usuaris/m4372594/jair-maxsatz-solvers.zip, http://www.laria.upicardie.fr/cli/maxsatz.tar.gz.
338

fiNew Inference Rules Max-SAT

7. Experimental Results
report experimental investigation performed unweighted Max-SAT order
evaluate inference rules defined Section 4, compare MaxSatz
best performing state-of-the-art solvers publicly available paper
submitted. experiments performed Linux Cluster processors 2 GHz
AMD Opteron 1 Gb RAM.
structure section follows. first describe solvers benchmarks
considered. Then, present experimental evaluation inference
rules. Finally, show experimental comparison MaxSatz solvers.
7.1 Solvers Benchmarks
MaxSatz compared following Max-SAT solvers:
BF2 (Borchers & Furman, 1999): branch bound Max-SAT solver uses
MOMS dynamic variable selection heuristic consider underestimations
computation lower bound. developed Borchers Furman
1999.
AGN3 (Alber et al., 2001): branch bound Max-2SAT solver. developed
Alber, Gramm Niedermeier 1998.
AMP4 (Alsinet et al., 2003b): branch bound Max-SAT solver based BF
incorporates lower bound better quality Jeroslow-Wang variable selection
heuristic (Jeroslow & Wang, 1990). developed Alsinet, Manya Planes
presented SAT-2003.
toolbar5 (de Givry et al., 2003; Larrosa & Heras, 2005): Max-SAT solver whose
inference inspired soft arc consistency properties implemented weighted CSP
solvers. developed de Givry, Larrosa, Meseguer Schiex first
presented CP-2003. used version 2.2 default parameters.
MaxSolver6 (Xing & Zhang, 2004): branch bound Max-SAT solver applies
number efficient inference rules. developed Xing Zhang presented
CP-2004. used second release solver.
Lazy7 (Alsinet et al., 2005): branch bound Max-SAT solver lazy data
structures static variable selection heuristic. developed Alsinet, Manya
Planes presented SAT-2005.
2.
3.
4.
5.
6.
7.

Downloaded October 2004 http://infohost.nmt.edu/borchers/satcodes.tar.gz
Downloaded October 2005 http://www-fs.informatik.uni-tuebingen.de/gramm/
Available http://web.udl.es/usuaris/m4372594/software.html
Downloaded October 2005 http://carlit.toulouse.inra.fr/cgi-bin/awki.cgi/ToolBarIntro
Downloaded October 2005 http://cic.cs.wustl.edu/maxsolver/
Available http://web.udl.es/usuaris/m4372594/software.html

339

fiLi, Manya & Planes

UP8 (Li et al., 2005): branch bound Max-SAT solver lower bound
computation method based unit propagation (cf. Section 3). developed
Li, Manya Planes presented CP-2005.
used benchmarks randomly generated Max-2SAT instances Max-3SAT instances, graph 3-coloring instances9 , well Max-Cut instances10 . also considered
unweighted Max-SAT benchmarks submitted Max-SAT Evaluation 2006, including
Max-Cut, Max-Ones, Ramsey numbers, random Max-2SAT Max-3SAT instances.
generated Max-2SAT instances Max-3SAT instances using generator mwff.c
developed Bart Selman, allows duplicated clauses. Max-Cut, first
generated random graph edges every edge randomly selected among
set possible edges. graph connected, discarded. graph
connected, used encoding Shen Zhang (2005) encode Max-Cut
instance CNF: created, edge (xi , xj ), exactly two binary clauses (xi xj )
(xi xj ). collection binary clauses, Max-Cut instance
cut weight k iff Max-SAT instance assignment + k clauses
satisfied.
graph 3-coloring, first used Culbersons generator generate random kcolorable graph type IID (independent random edge assignment, variability=0)
k vertices fixed edge density. used Culbersons converter SAT standard conversion three colors generate Max-SAT instance: vertex xi
color j {1, 2, 3}, propositional variable xij defined meaning vertex
colored color j. vertex xi , four clauses added encode vertex
colored exactly one color: xi1 xi2 xi3 , xi1 xi2 , xi1 xi3 , xi2 xi3 ; and,
edge (xi , xj ), three clauses added encode vertex xi vertex xj
color: xi1 xj1 , xi2 xj2 , xi3 xj3 .
random Max-2SAT Max-3SAT instances, clauses entirely independent
structure. graph 3-coloring instances Max-Cut instances
used paper, clauses independent structure. example,
Max-Cut instance, every time clause xi xj , also clause xi xj ;
satisfaction two clauses means corresponding edge cut.
graph 3-coloring instance, every time ternary clause xi1 xi2 xi3 encoding
vertex colored least color, also three binary clauses xi1 xi2 , xi1 xi3 ,
xi2 xi3 encoding vertex cannot colored two colors. MaxCut instances contain binary clauses, graph 3-coloring instances contain ternary
clause every vertex graph. derive optimal cut optimal
assignment Max-SAT encoding Max-Cut instance, optimal assignment
Max-SAT encoding 3-coloring instance may assign one color vertices.
8. Available http://web.udl.es/usuaris/m4372594/software.html
9. Given undirected graph G = (V, E), V = {x1 , . . . , xn } set vertices E set
edges, set three colors, graph 3-coloring problem problem coloring every vertex
one three colors way that, edge (xi , xj ) E, vertex xi vertex xj
color.
10. Given undirected graph G = (V, E), let wxi ,xj weight associated edge (xi , xj ) E.
P
weighted Max-Cut problem find subset V W (S, S) = xi S,xj wxi ,xj
maximized, = V S. paper, set weight wxi ,xj = 1 edges.

340

fiNew Inference Rules Max-SAT

Max-Cut Ramsey numbers instances Max-SAT Evaluation 2006 contain different structures. example, underlying graphs Max-Cut instances
different origins fault diagnosis problems, coding theory problems, graph
clique problems. Max-2SAT Max-3SAT instances evaluation contain
duplicated clauses.
computed initial upper bound local search solver instance.
provide parameter solver except instance solved initial
upper bound. words, used default values parameters.
instances Max-SAT Evaluation 2006 solved conditions
evaluation; i.e., initial upper bound provided solvers, maximum time
allowed solve instance 30 minutes.
7.2 Evaluation Inference Rules
first experiment performed evaluate impact inference rules Section 4,
solved sets 100 random Max-2SAT instances 50 100 variables; number
clauses ranged 400 4500 50 variables, 400 1000 100 variables.
results obtained shown Figure 7. Along horizontal axis number
clauses, along vertical axis mean time (left plot), seconds, needed solve
instance set, mean number branches proof tree (right plot). Notice
use log scale represent run-time branches.
observe rules powerful Max-2SAT gain increases
number variables number clauses increase. 50 variables 1000
clauses (the clause variable ratio 20), MaxSatz 7.6 times faster MaxSat1234;
100 variables 1000 clauses (the clause variable ratio 10), MaxSatz 9.2
times faster MaxSat1234. search tree MaxSatz also substantially smaller
MaxSat1234. Rule 5 Rule 6 powerful Rule 3 Rule 4
Max-2SAT. intuitive explanation MaxSatz MaxSat1234 detect many
inconsistent subsets clauses containing one unit clause subsets containing two unit
clauses, Rule 5 Rule 6 applied many times Rule 3 Rule 4
MaxSatz.
Recall that, one hand, every application Rule 3 Rule 4 consumes two
unit clauses produces one empty clause, limiting unit propagation detecting
conflicts subsequent search. hand, Rule 3 Rule 4 add clauses
may contribute detect conflicts. Depending number clauses (or
precisely, clause variable ratio) formula, two factors different
importance. relatively clauses, unit propagation relatively
easily derive contradiction unit clause, binary clauses added Rule 3
Rule 4 relatively important deriving additional conflicts improving lower
bound, explains search tree MaxSat1234 smaller search tree
MaxSat12 instances 100 variables less 600 clauses. contrary,
many clauses, unit propagation easily derives contradiction unit
clause, two unit clauses consumed Rule 3 Rule 4 would probably allow
derive two disjoint inconsistent subsets clauses. addition, binary clauses added
Rule 3 Rule 4 relatively less important deriving additional conflicts, considering
341

fiLi, Manya & Planes

large number clauses formula. case, search tree MaxSat1234
larger search tree MaxSat12. However, cases, MaxSat1234 faster
MaxSat12, meaning incremental lower bound computation due Rule 3
Rule 4 effective, since redetection many conflicts avoided thanks Rule 3
Rule 4.

Max-2SAT - 50 variables
1e+07

1000

1e+06

branches (log scale)

time (logscale)

Max-2SAT - 50 variables
10000

100
10
1
MaxSat0
MaxSat12
MaxSat1234
MaxSatz

0.1
0.01
1000

2000

3000

100000
10000
MaxSat0
MaxSat12
MaxSat1234
MaxSatz

1000
100

4000

1000

2000

number clauses

1000

1e+07

100
10
1

0.01
400

MaxSat0
MaxSat12
MaxSat1234
MaxSatz
500

600
700
800
number clauses

4000

Max-2SAT - 100 variables
1e+08
branches (log scale)

time (logscale)

Max-2SAT - 100 variables
10000

0.1

3000

number clauses

900

1e+06
100000
10000
MaxSat0
MaxSat12
MaxSat1234
MaxSatz

1000
100
400

1000

500

600
700
800
number clauses

900

1000

Figure 7: Comparison among MaxSat12, MaxSat1234 MaxSatz random Max-2SAT instances.

Rule 5 Rule 6 limit unit propagation detecting conflicts, since
application produces one empty clause consumes one unit clause, allows
derive one conflict case. added ternary clauses allow improve
lower bound, search tree MaxSatz substantially smaller search
tree MaxSat1234. incremental lower bound computation due Rule 5 Rule 6
also contributes time performance MaxSatz. example, search tree
MaxSatz instances 50 variables 2000 clauses 11.5 times smaller
search tree MaxSat1234, MaxSatz 14 times faster MaxSat1234.
second experiment, solved random Max-3SAT instances instead random
Max-2SAT instances. solved instances 50 70 variables; number clauses
ranged 400 1200 50 variables, 500 1000 70 variables. results
obtained shown Figure 8.
342

fiNew Inference Rules Max-SAT

Max-3SAT - 50 variables

Max-3SAT - 50 variables
1e+07
branches (log scale)

time (log scale)

1000

100

10
MaxSat0
MaxSat12
MaxSat1234
MaxSatz

1

0.1
400

600

800
1000
number clauses

1e+06

100000

1000
400

1200

Max-3SAT - 70 variables

600
800
1000
number clauses

1200

Max-3SAT - 70 variables
1e+08
branches (log scale)

10000

time (logscale)

MaxSat0
MaxSat12
MaxSat1234
MaxSatz

10000

1000

100
MaxSat0
MaxSat12
MaxSat1234
MaxSatz

10

1
500

600

700
800
number clauses

900

1000

1e+07

1e+06
MaxSat0
MaxSat12
MaxSat1234
MaxSatz

100000

10000
500

600

700
800
number clauses

900

1000

Figure 8: Comparison among MaxSat12, MaxSat1234 MaxSatz random Max-3SAT instances.

Although rules involve ternary clauses, also powerful Max-3SAT.
Similarly Max-2SAT, Rule 3 Rule 4 slightly improve lower bound
relatively clauses, improve lower bound number clauses
increases. improve time performance thanks incremental lower bound
computation allowed. gain increases number clauses increases.
example, problems 70 variables, number clauses 600, MaxSat1234
36% faster MaxSat12 and, number clauses 1000, gain 44%.
Rule 5 Rule 6 improve lower bound time performance MaxSatz.
gain increases number clauses increases.
third experiment considered Max-Cut problem graphs 50 vertices
number edges ranging 200 800. Figure 9 shows results comparing
inference rules Max-Cut instances. observe rules allow us solve
instances much faster. Similarly random Max-2SAT, Rule 3 Rule 4
improve lower bound many clauses, improve time performance
due incremental lower bound computation allowed. Rule 5 Rule 6
powerful Rule 3 Rule 4 instances, contain binary clauses
structure. addition, reduction tree size due Rule 5 Rule 6
contributes time performance MaxSatz incrementality lower
bound computation, random Max-2SAT. example, search tree MaxSatz
instances 800 edges 40 times smaller search tree MaxSat1234,
MaxSatz 47 times faster.
343

fiLi, Manya & Planes

Max-Cut - 50 nodes
1e+09

10000

1e+08
branches (log scale)

time (log scale)

Max-Cut - 50 nodes
100000

1000
100
10
1

MaxSat0
MaxSat12
MaxSat1234
MaxSatz

0.1
0.01
200

300

400
500
600
number edges

1e+07
1e+06
100000
10000

MaxSat0
MaxSat12
MaxSat1234
MaxSatz

1000
700

100
200

800

300

400
500
600
number edges

700

800

Figure 9: Experimental results Max-Cut

fourth experiment considered graph 3-coloring instances 24 60 vertices, density edges ranging 20% 90%. Figure 10 shows results
comparing inference rules graph 3-coloring instances. observe Rule 1
Rule 2 useful instances; tree size MaxSat0 MaxSat12 almost
same, MaxSat12 slower MaxSat0. contrary, rules
useful instances, especially allow reduce search tree size
deriving better lower bounds.

Graph 3-coloring 24 nodes

Graph 3-coloring 24 nodes
10000
Branches (log scale)

time (log scale)

0.1

0.01

0.001
MaxSat0
MaxSat12
MaxSat1234
MaxSatz

1e-04
20

30

40

50
60
% edges

70

1000

100
MaxSat0
MaxSat12
MaxSat1234
MaxSatz

10
80

90

20

30

Graph 3-coloring 60 nodes

50
60
% edges

70

80

90

80

90

Graph 3-coloring 60 nodes
1e+08
Branches (log scale)

10000

time (log scale)

40

1000

100
MaxSat0
MaxSat12
MaxSat1234
MaxSatz

10

1
20

30

40

50
60
% edges

70

1e+07

1e+06
MaxSat0
MaxSat12
MaxSat1234
MaxSatz

100000
80

90

20

30

40

50
60
% edges

Figure 10: Experimental results Graph 3-Coloring
344

70

fiNew Inference Rules Max-SAT

Note Rule 3 Rule 4 impact Rule 5 Rule 6 reducing
cost solving instances. probably due fact two unit clauses
needed detect contradiction, Rule 3 Rule 4 applied many times.
Also note instances 60 vertices become easier solve density
graph high.
fifth experiment, compared different inference rules benchmarks submitted Max-SAT Evaluation 2006. Solvers ran conditions
evaluation. Table 1, first column name benchmark set, second
column number instances set, rest columns display average
time, seconds, needed solver solve instance (the number solved instances
brackets). maximum time allowed solve instance 30 minutes.
clear MaxSat12 better MaxSat0, MaxSat1234 better MaxSat12,
MaxSatz better MaxSat1234. example, MaxSatz solves three MAXCUT
johnson instances within time limit, solvers solve two instances.
average time MaxSatz solve one three instances 44.46 seconds,
third instance needing time solved two instances.
Set Name
MAXCUT brock
MAXCUT c-fat
MAXCUT hamming
MAXCUT johnson
MAXCUT keller
MAXCUT p hat
MAXCUT san
MAXCUT sanr
MAXCUT max cut
MAXCUT SPINGLASS
MAXONE
RAMSEY
MAX2SAT 100VARS
MAX2SAT 140VARS
MAX2SAT 60VARS
MAX2SAT DISCARDED
MAX3SAT 40VARS
MAX3SAT 60VARS

#Instances
12
7
6
4
2
12
11
4
40
5
45
48
50
50
50
180
50
50

MaxSat0
471.01(10)
1.92 (5)
39.42(2)
14.91(2)
512.66(2)
72.16(9)
801.95(7)
323.67(3)
610.28(35)
0.22 (2)
0.03 (45)
8.93 (34)
95.01(50)
153.28(49)
1.35 (50)
126.98(162)
11.52(50)
167.17(50)

MaxSat12
277.12(12)
3.11 (5)
29.43(2)
8.57 (2)
213.64(2)
286.09(12)
305.75(7)
134.74(3)
481.48(40)
0.19 (2)
0.03 (45)
8.42 (34)
11.30(50)
51.76(50)
0.08 (50)
71.85(173)
3.33 (50)
72.72(50)

MaxSat1234
225.11(12)
2.84 (5)
29.48(2)
7.21 (2)
163.26(2)
226.24(12)
245.70(7)
107.76(3)
450.05(40)
0.15 (2)
0.03 (45)
7.80 (34)
8.14 (50)
34.14(50)
0.06 (50)
68.97(175)
2.52 (50)
52.14(50)

MaxSatz
14.01(12)
0.07(5)
171.30(3)
44.46(3)
6.82(2)
16.81(12)
258.65(11)
71.00(4)
7.18(40)
0.14(2)
0.03(45)
7.78(34)
1.25(50)
6.94(50)
0.02(50)
22.72(180)
1.92(50)
40.27(50)

Table 1: Evaluation rules benchmarks MAX-SAT Evaluation 2006.
7.3 Comparison MaxSatz Solvers
first experiment, performed compare MaxSatz state-of-the-art
Max-SAT solvers, solved sets 100 random Max-2SAT instances 50, 100 150
variables; number clauses ranged 400 4500 50 variables, 400
1000 100 variables, 300 650 150 variables. results solving
instances BF, AGN, AMP, Lazy, toolbar, MaxSolver, MaxSatz shown
Figure 11. Along horizontal axis number clauses, along vertical axis
mean time, seconds, needed solve instance set. solver needed
much time solve instances point, stopped corresponding point
shown figure. 50 variable instances, BF one point
figure (for 400 clauses); 100 variable instances, BF AMP also one
345

fiLi, Manya & Planes

point figure (for 400 clauses). version MaxSolver used limits number
clauses 1000 instances solved. ran instances 1000 clauses.
see dramatic differences performance MaxSatz rest solvers
Figure 11. hardest instances, MaxSatz two orders magnitude faster
second best performing solvers (UP). instances, MaxSatz needs 1 second
solve instance solvers like MaxSolver toolbar able solve
instances 10,000 seconds.
second experiment, solved random Max-3SAT instances instead random
Max-2SAT instances. results obtained shown Figure 12. consider
AGN solve Max-2SAT instances. solved instances 50, 70
100 variables; number clauses ranged 500 1200 50 variables, 500
1000 70 variables, 450 800 100 variables. 70 variables, AMP
one point figure (for 500 clauses) BF slow. 100 variables,
compared two best solvers. again, observe dramatic differences
performance profile MaxSatz rest solvers. Particularly remarkable
differences MaxSatz toolbar (the second best performing solver Max3SAT), see MaxSatz 1,000 times faster toolbar hardest
instances.
third experiment, considered Max-Cut problem graphs 50 vertices
number edges ranging 200 700. Figure 13 shows results obtained. BF
one point figure (for 200 edges). MaxSolver solved instances 500 edges
(1000 clauses). observe MaxSatz superior rest solvers.
fourth experiment, considered 3-coloring problem graphs 24
60 vertices, density edges ranging 20% 90%. AGN considered
solve Max-2SAT instances. 60 vertices, compared three
best solvers, MaxSolver different version limiting number clauses
instance solved. Figure 14 shows comparative results different solvers.
MaxSatz best performing solver, MaxSolver substantially better
rest solvers.

Max-Cut - 50 nodes
10000

time (log scale)

1000
100
BF
AMP
AGN
Lazy
toolbar
MaxSolver

MaxSatz

10
1
0.1

0.01
200 300 400 500 600 700
number edges

Figure 13: Experimental results Max-Cut
346

fiNew Inference Rules Max-SAT

Max-2SAT - 50 variables
10000

time (log scale)

1000
100
10

BF
AMP
AGN
Lazy
toolbar
MaxSolver

MaxSatz

1
0.1
0.01
0.001
1000 2000 3000 4000
number clauses
Max-2SAT - 100 variables
100000

time (log scale)

10000
1000
100

BF
AMP
AGN
Lazy
toolbar
MaxSolver

MaxSatz

10
1
0.1

0.01
400 500 600 700 800 900 1000
number clauses
Max-2SAT - 150 variables
100000
10000
time (log scale)

1000
100
10

BF
AMP
AGN
Lazy
toolbar
MaxSolver

MaxSatz

1
0.1
0.01
0.001
1e-04
300

400
500
600
number clauses

Figure 11: Experimental results 50-variable, 100-variable 150-variable random Max2SAT instances.

347

fiLi, Manya & Planes

Max-3SAT - 50 variables
10000

time (log scale)

1000
100
BF
AMP
Lazy
toolbar
MaxSolver

MaxSatz

10
1
0.1
600
800
1000
number clauses

1200

Max-3SAT - 70 variables

time (log scale)

10000

1000

100
AMP
Lazy
toolbar
MaxSolver

MaxSatz

10

1
500 600 700 800 900 1000
number clauses
Max-3SAT - 100 variables
100000

time (log scale)

10000
1000
100
10
1
0.1

toolbar
MaxSatz

0.01
500
600
700
number clauses

800

Figure 12: Experimental results 50-variable, 70-variable 100-variable random Max3SAT instances.

348

fiNew Inference Rules Max-SAT

Graph 3-coloring 24 nodes
10000

time (log scale)

1000
100
10
1

BF
AMP
Lazy
MaxSolver
toolbar

MaxSatz

0.1
0.01
0.001
1e-04

20 30 40 50 60 70 80 90
% edges
Graph 3-coloring 60 nodes
100000

time (log scale)

10000
1000
100
10

MaxSolver

MaxSatz

1

20 30 40 50 60 70 80 90
% edges

Figure 14: Experimental results Graph 3-Coloring

fifth experiment, compared Max-SAT solvers benchmarks submitted
Max-SAT Evaluation 2006. Solvers ran conditions evaluation.
Table 2, first column name benchmark set, second column
number instances set, rest columns display average time, seconds,
needed solver solve instance within time limit 30 minutes (the number
instances solved within time limit brackets). dash means corresponding
solver cannot solve set instances. clear MaxSatz best performing
solver sets.

8. Related Work
simplest method compute lower bound consists counting number
clauses unsatisfied current partial assignment (Borchers & Furman, 1999). One step
forward incorporate underestimation number clauses become
unsatisfied current partial assignment extended complete assignment.
basic method defined Wallace Freuder (1996):
349

fi#Instances
12
7
6
4
2
12
11
4
40
5
45
48
50
50
50
180
50
50

BF
(0)
6.06 (1)
(0)
(0)
(0)
605.44(2)
(0)
(0)
(0)
0.21 (1)
0.02 (21)
8.53 (30)
0.14 (10)
0.08 (10)
1.92 (3)
357.65(28)
170.49(22)
4.07 (16)

AMP
545.81(1)
1.95 (3)
636.04(1)
394.17(2)
197.15(1)
107.79(8)
563.19(1)
428.18(1)
(0)
0.13 (1)
0.03 (45)
38.44(30)
143.23(11)
91.93(12)
514.02(44)
439.54(76)
202.18(50)
168.00(25)

AGN
856.65(8)
32.70(5)
159.99(1)
92.90(2)
39.36(1)
16.11(8)
72.35(2)
909.32(3)
1742.79(3)
12.70(2)
185.69(30)
126.34(28)
6.34 (50)
99.70(108)
-

toolbar
470.23(12)
42.84(5)
145.84(2)
11.07(2)
255.39(2)
235.60(11)
568.09(7)
234.89(3)
736.34(18)
5.72 (2)
35.35(44)
4.14(27)
244.05(34)
262.30(26)
2.01 (50)
178.23(116)
10.19 (50)
361.95(43)

Lazy
159.28 (12)
13.23 (4)
265.35 (2)
13.50 (2)
348.75 (2)
259.33 (10)
956.54 (5)
410.53 (3)
1027.21 (7)
0.05 (1)
278.58 (26)
10.48 (25)
273.44 (22)
217.12 (17)
26.44 (50)
85.08 (87)
69.72 (50)
242.40 (28)

MaxSolver
380.09(2)
41.58(3)
(0)
1.34 (1)
(0)
14.00(8)
283.34(2)
138.32(1)
(0)
570.68(2)
0.06 (45)
0.20 (20)
532.47(16)
168.42(18)
81.82(50)
308.58(73)
66.34(49)
139.03(22)


629.85(9)
7.19 (5)
294.89(2)
29.42(2)
615.54(2)
140.23(9)
812.47(5)
538.10(3)
623.03(13)
0.86 (2)
0.31 (45)
19.65(25)
192.34(48)
75.57(39)
0.94 (50)
166.29(149)
60.50(50)
166.76(37)

Table 2: Experimental results benchmarks MAX-SAT Evaluation 2006.

MaxSatz
14.01(12)
0.07(5)
171.30(3)
44.46(3)
6.82 (2)
16.81(12)
258.65(11)
71.00(4)
7.18(40)
0.14(2)
0.03 (45)
7.78 (34)
1.25 (50)
6.94 (50)
0.02 (50)
22.72(180)
1.92(50)
40.27(50)

350

Li, Manya & Planes

Set Name
MAXCUT brock
MAXCUT c-fat
MAXCUT hamming
MAXCUT johnson
MAXCUT keller
MAXCUT DIMACS p hat
MAXCUT san
MAXCUT sanr
MAXCUT max cut
MAXCUT SPINGLASS
MAXONE
RAMSEY ram k
MAX2SAT 100VARS
MAX2SAT 140VARS
MAX2SAT 60VARS
MAX2SAT DISCARDED
MAX3SAT 40VARS
MAX3SAT 60VARS

fiNew Inference Rules Max-SAT

LB() = #emptyClauses() +
x

X

occurs

min(ic(x), ic(x))


CNF formula associated current partial assignment, ic(x) (ic(x))
inconsistency count x (x) number unit clauses contain x (x).
underestimation lower bound improved applying binary clauses
Directional Arc Consistency (DAC) count defined Wallace (1995) Max-CSP.
DAC count value variable x number variables inconsistent
value x. example, contains clauses x y, x y, x y, value
0 x inconsistent y. Note value 0 also inconsistent x.
two inconsistencies disjoint cannot summed. Wallace defined direction
x y, inconsistency value 0 x counted. defining
direction every pair variables sharing constraint, one computes DAC count
values x checking variables direction x defined.
underestimation considering DAC count Wallace follows:

x

X

occurs

(min(ic(x), ic(x)) + min(dac(x), dac(x))


dac(x) (dac(x)) DAC count value 1(0) x. Wallace statically defined
directions, dac(x) dac(x) computed preprocessing step every
x need recomputed search. improved Larrosa, Meseguer
Schiex (1999) introducing reversible DAC, searches better directions
obtain better lower bound every node search tree. improvement DAC
counts additional incorporation inconsistencies contributed disjoint subsets
variables, based particular variable partitions (Larrosa & Meseguer, 2002).
Inconsistent DAC counts deal unit binary clauses. Lower bounds dealing
longer clauses include star rule (Shen & Zhang, 2004; Alsinet et al., 2004) (Li
et al., 2005).
star rule, underestimation lower bound number disjoint
inconsistent subformulas form {l1 , . . . , lk , l1 lk }. star rule, k = 1,
equivalent inconsistency counts Wallace Freuder.
subsumes inconsistent count method based unit clauses star rule.
effectiveness producing good lower bound illustrated following example:
let CNF formula containing clauses x1 , x1 x2 , x1 x3 , x2 x3 x4 , x5 , x5 x6 , x5
x7 , x6 x7 x4 . easily detects inconsistent subset 8 clauses 7 variables,
time linear size formula. Note subset detected
lower bounds described above, except variable partition based approach Larrosa
Meseguer (2002) case 7 variables partition.
mention two lower bound computation methods. One called LB4
defined Shen Zhang (2004). similar restricted Max-2SAT instances
using static variable ordering. Another based linear programming
defined Xing Zhang (2005).
Regin et al. (2001) suggested use arc consistency, instead unit propagation, detect
disjoint inconsistent subsets constraints weighted constraint networks. However,
351

fiLi, Manya & Planes

best knowledge, idea incorporated lower bound computation
method implemented Constraint Programming community.
good lower bound computation method dramatic impact performance
Max-SAT solver. Another approach speed Max-SAT solver consists applying
inference rules transform Max-SAT instance equivalent simpler Max-SAT
instance . Inference rules proven useful practice include: (i) pure
literal rule (Alsinet et al., 2003b; Xing & Zhang, 2004; Li et al., 2005; Zhang et al., 2003);
(ii) dominating unit clause rule, first proposed Niedermeier Rossmanith (2000),
later applied several solvers (Alsinet et al., 2004; Xing & Zhang, 2004; Li et al.,
2005); (iii) almost common clause rule, first proposed Bansal Raman (1999)
restated Rule 1 paper. rule extended weighted Max-SAT byAlsinet
et al. (2004); called neighborhood resolution Larrosa Heras (2005); used
preprocessing technique Alsinet et al. (2004), Shen Zhang (2005), Li et al. (2005);
(iv) complementary unit clause rule (Niedermeier & Rossmanith, 2000), restated Rule
2 paper; (v) coefficient-determining unit propagation rule (Xing & Zhang,
2005) based integer programming.
inference rules presented paper simplify Max-SAT formula allow
improve lower bound computation, since transform Max-SAT formula
simpler equivalent formula containing empty clauses. soundness
(i.e., fact transform formula equivalent one) proved several
ways, including (i) checking possible variable assignments, (ii) using integer programming
done Section 4, (iii) using soft local consistency techniques defined Weighted
Constraint Networks (WCN); Max-SAT defined subcase WCN variables
Boolean unit costs used.
Soft local consistency techniques WCN based two basic equivalence preserving
transformations called projection extension (Schiex, 2000; Cooper & Schiex, 2004).
Given Max-SAT instance, projection replaces two binary clauses x x
unit clause x, Rule 1 k=2. Extension inverse operation projection
replaces unit clause x two binary clauses x x selected variable
y. projection operation rather straightforward SAT Max-SAT instance,
extension operation ingenious. see this, note Rule 3 proved
applied extension followed projection:
l1 , l1 l2 , l2 = l1 l2 , l1 l2 , l1 l2 , l2
= l1 l2 , l2 , l2
= l1 l2 , 2
Lemma 1 also proved using extension followed projection:
l1 , l1 l2 = l1 l2 , l1 l2 , l1 l2
= l1 l2 , l2
extension operation cannot used unguided way may cancel
previous projection. One way guide use define ordering variables
352

fiNew Inference Rules Max-SAT

enforce directional arc consistency (Cooper, 2003; Cooper & Schiex, 2004). Directional arc
consistency allows concentrate weights variables shifting weights
earlier variables later ones given ordering. example x1 < x2 given variable
ordering, one extend unit clause x1 x1 x2 , x1 x2 , cannot extend unit clause x2
x1 x2 , x1 x2 , allowing unit clauses concentrated variable x2 . Nevertheless,
define variable ordering efficiently exploit much possible power
soft arc consistency techniques lower bound computation remains open problem.
approach inference rules Max-SAT presented paper need
predefined ordering among variables, since rule applications combining several projection extension operations entirely guided unit propagation.
projection extension operations extended constraints involving
two variables achieve high-order consistency WCN (Cooper, 2005). MaxSAT instance, extended projection extension operations stated using Rule 1
k>2. two formulas 1 2 Rule 1, replacing 1 2 projection
2 1 extension. Given unit clause x three variables x, y, z, extension
unit clause x set three variables done follows : replacing x
x x y, x x x z, x z, x z x z.
Rule 5 proved applied extending four clauses 1 ternary clauses
three variables l1 , l2 l3 , applying projection operation obtain 2 .
Larrosa et al. (2007), based logical approach, independently parallel
work, defined implemented chain resolution rule cycle resolution rule
weighted Max-SAT. two rules extensions Rules 2-RES 3-RES presented,
also independently parallel work (Heras & Larrosa, 2006).
chain resolution could stated follows:


(li , mi mi+1 )1ik ,




(li li+1 , ui+1 mi+1 )1i<k ,

(l1 , u1 ),
(li li+1 , mi+1 )1i<k ,
(li li+1 , ui+1 )1i<k ,
=



(l , u
mk+1 ),
(lk , uk+1 )


k k+1
(2, mk+1 )













where, 1ik+1, ui weight corresponding clause, mi =min(u1 , u2 , . . . , ui ),
variables literals different. weight mandatory clause denoted
, subtraction extended ui =. chain resolution rule
equivalent Rule 4 applied unweighted Max-SAT. main difference
chain resolution rule weighted version Rule 4 presented Section 5.4
chain resolution shifts part weight unit clause (l1 , m1 mk+1 ),
derived weighted version Rule 4, create unit clauses (li , mi mi+1 )1<ik ,
(l1 , m1 mk+1 ) becoming (l1 , m1 m2 ).
cycle resolution rule could stated follows:
353

fiLi, Manya & Planes



(li li+1 , ui )1i<k ,
(l1 lk , uk )



=

















(l1 li , mi1 mi )2ik ,
(li li+1 , ui mi )2i<k ,
(l1 li li+1 , mi )2i<k ,
(l1 li li+1 , mi )2i<k ,
(l1 lk , uk mk ),
(l1 , mk )

















subset binary clauses cyclic structure, cycle resolution rule allows
derive unit clause. Note detection cyclic structure appears rather timeconsuming applied every node search tree 2(k-2) new ternary
clauses inserted. So, Larrosa et al. apply cycle resolution rule practice
case k=3, similar Rule 5, applied unweighted Max-SAT.
cycle resolution rule applied unweighted Max-SAT k=3 replace Rule 5
Rule 6 MaxSatz, following differences compared Rule 5 Rule 6:
application Rule 5 Rule 6 entirely based inconsistent subformulas
detected unit propagation. detection applicability Rule 5 Rule 6
easy low overhead, since inconsistent subformulas always detected
MaxSatz compute lower bound (with without Rule 5 Rule 6). Every
application Rule 5 Rule 6 allows increment lower bound 1.
cycle resolution rule needs extra detection cyclic structure, allows
derive unit clause cyclic structure. derived unit clause could
used unit propagation, possibly could allow detect inconsistent
subformula increase lower bound 1.
would interesting future research topic implement cycle resolution rule
MaxSat1234 (i.e., MaxSatz without Rule 5 Rule 6) evaluate overhead detecting
cyclic structure usefulness unit clauses ternary clauses derived
using cycle resolution rule, compare implemented solver MaxSatz.
would also interesting compare chain resolution rule cycle resolution rule
weighted inference rules presented Section 5.4.
general Max-SAT resolution rule, conclusions clausal
form, defined Larrosa Heras (2005). Independently, Bonet et al. (2006, 2007)
Heras Larrosa (2006) defined version rule conclusions clausal
form. Bonet et al. (2006, 2007) also proved rule complete Max-SAT. Recently,
Ansotegui et al. (2007b, 2007a) shown Max-SAT resolution many-valued CNF
formulas provides logical framework global local consistency properties defined
WCN.

9. Conclusions Future Work
One main drawbacks state-of-the-art Max-SAT solvers lack suitable
inference techniques allow detect much contradictions possible simplify
formula node search tree. Existing approaches put emphasis
computing underestimations good quality, problem underestimations
354

fiNew Inference Rules Max-SAT

contradictions computed again. Furthermore, turns
U P , one currently best performing underestimations consisting detecting
disjoint inconsistent subsets clauses CNF formula via unit propagation, still
conservative. make computation lowers incremental improve
underestimation, defined number original inference rules Max-SAT that,
based derived contradictions unit propagation, transform Max-SAT instance
equivalent Max-SAT instance easier solve. rules carefully selected
taking account applied efficiently. Since rules based
contradiction detection, particularly useful hard Max-SAT instances
containing many contradictions.
aim finding powerful inference rules practice,
developed new Max-SAT solver, called MaxSatz, incorporates rules,
performed experimental investigation. results comparing MaxSatz inference
rules MaxSatz without inference rules provide empirical evidence usefulness
rules making lower bound computation incremental improving
quality lower bounds. results comparing MaxSatz large selection
solvers available time submitting paper provide empirical evidence
MaxSatz, least instances solved, faster solvers. observed gains
several orders magnitude hardest instances. Interestingly, benchmarks
used, second best solver generally different: Max-2SAT, toolbar Max3SAT, MaxSolver Max-Cut, MaxSolver graph 3-coloring. So, MaxSatz
robust rest solvers. worth mentioning MaxSatz, enhanced
lower bound based failed literal detection (Li et al., 2006), best performing
solver unweighted Max-SAT instances Max-SAT Evaluation 2006. second
third best performing solvers were, respectively, improved versions toolbar Lazy11 .
future work plan study orderings unit clauses unit propagation
maximize application inference rules, define new inference rules ternary
clauses. extending results paper weighted Max-SAT,
suitable modeling problems maximum clique, set covering combinatorial
auctions, well constraint satisfaction problems hard instances Model RB (Xu,
Boussemart, Hemery, & Lecoutre, 2005; Xu & Li, 2006). also adapting results
paper partial Max-SAT solvers developed Argelich Manya (2005, 2006,
2007).

Acknowledgments
Research partially supported projects TIN2004-07933-C03-03 TIN2006-15662-C0202 funded Ministerio de Educacion Ciencia. first author partially supported National 973 Program China Grant No. 2005CB321900. second
author supported grant Ramon Cajal. Finally, would like thank referees
detailed comments suggestions.
11. See http://www.iiia.csic.es/maxsat06 details. Note results Max-SAT Evaluation
2006 compared results paper obtained cluster
conditions.

355

fiLi, Manya & Planes

References
Alber, J., Gramm, J., & Niedermeier, R. (2001). Faster exact algorithms hard problems:
parameterized point view. Discrete Mathematics, 229 (13), 327.
Alsinet, T., Manya, F., & Planes, J. (2003a). Improved branch bound algorithms
Max-2-SAT weighted Max-2-SAT. Proceedings Catalonian Conference
Artificial Intelligence (CCIA-03), P. Mallorca, Spain, Vol. 100 Frontiers
Artificial Intelligence Applications, pp. 435442. IOS Press.
Alsinet, T., Manya, F., & Planes, J. (2003b). Improved branch bound algorithms
Max-SAT. Proceedings 6th International Conference Theory
Applications Satisfiability Testing (SAT-03), Portofino, Italy, pp. 408415.
Alsinet, T., Manya, F., & Planes, J. (2004). Max-SAT solver lazy data structures. Proceedings 9th Ibero-American Conference Artificial Intelligence
(IBERAMIA-04), Puebla, Mexico, LNCS 3315, pp. 334342. Springer.
Alsinet, T., Manya, F., & Planes, J. (2005). Improved exact solver weighted MaxSAT. Proceedings 8th International Conference Theory Applications
Satisfiability Testing (SAT-05), St. Andrews, Scotland, LNCS 3569, pp. 371377.
Springer.
Ansotegui, C., Bonet, M. L., Levy, J., & Manya, F. (2007a). Inference rules high-order
consistency weighted CSP. Proceedings 22nd National Conference
Artificial Intelligence (AAAI-07), Vancouver, Canada, pp. 167172. AAAI Press.
Ansotegui, C., Bonet, M. L., Levy, J., & Manya, F. (2007b). logic behind weighted CSP.
Proceedings 20th International Joint Conference Artificial Intelligence
(IJCAI-07), Hyderabad, India, pp. 3237. AAAI Press.
Argelich, J., & Manya, F. (2005). Solving over-constrained problems SAT technology.
Proceedings 8th International Conference Theory Applications
Satisfiability Testing (SAT-05), St. Andrews, Scotland, LNCS 3569, pp. 115. Springer.
Argelich, J., & Manya, F. (2006). Exact Max-SAT solvers over-constrained problems.
Journal Heuristics, 12 (45), 375392.
Argelich, J., & Manya, F. (2007). Partial Max-SAT solvers clause learning. Proceedings 10th International Conference Theory Applications Satisfiability
Testing (SAT-07), Lisbon, Portugal, LNCS 4501, pp. 2840. Springer.
Bansal, N., & Raman, V. (1999). Upper bounds MaxSat: improved. Proceedings 10th International Symposium Algorithms Computation (ISAAC-99),
Chennai, India, LNCS 1741, pp. 247260. Springer.
Beame, P., Kautz, H., & Sabharwal, A. (2003). Understanding power clause learning.
Proceedings 18th International Joint Conference Artificial Intelligence
(IJCAI-03), Acapulco, Mexico, pp. 9499. Morgan Kaufman.
Bonet, M. L., Levy, J., & Manya, F. (2006). complete calculus Max-SAT. Proceedings 9th International Conference Theory Applications Satisfiability
Testing (SAT-06), Seattle, USA, LNCS 4121, pp. 240251. Springer.
356

fiNew Inference Rules Max-SAT

Bonet, M. L., Levy, J., & Manya, F. (2007). Resolution Max-SAT. Artificial Intelligence,
171, 606618.
Borchers, B., & Furman, J. (1999). two-phase exact algorithm MAX-SAT weighted
MAX-SAT problems. Journal Combinatorial Optimization, 2, 299306.
Boros, E., & Hammer, P. (2002). Pseudo-Boolean optimization. Discrete Applied Mathematics, 123, 155225.
Cooper, M. C. (2003). Reduction operations fuzzy valued constraint satisfaction. Fuzzy
Sets Systems, 134, 311342.
Cooper, M. C. (2005). High-order consistency valued constraint satisfaction. Constraints,
10, 283305.
Cooper, M. C., & Schiex, T. (2004). Arc consistency soft constraints. Artificial Intelligence, 154 (12), 199227.
Cormen, T. H., Leiserson, C. E., Rivest, R. L., & Stein, C. (2001). Introduction Algorithms
(second edition). MIT Press.
Davis, M., Logemann, G., & Loveland, D. (1962). machine program theorem-proving.
Communications ACM, 5, 394397.
Davis, M., & Putnam, H. (1960). computing procedure quantification theory. Journal
ACM, 7 (3), 201215.
de Givry, S., Larrosa, J., Meseguer, P., & Schiex, T. (2003). Solving Max-SAT weighted
CSP. Proceedings 9th International Conference Principles Practice
Constraint Programming (CP-03), Kinsale, Ireland, LNCS 2833, pp. 363376.
Springer.
de Givry, S., Zytnicki, M., Heras, F., & Larrosa, J. (2005). Existential arc consistency: Getting closer full arc consistency weighted csps. Proceedings 19th International Joint Conference Artificial Intelligence (IJCAI-05), Edinburgh, Scotland,
pp. 8489.
Freeman, J. W. (1995). Improvements Propositional Satisfiability Search Algorithms.
Ph.D. thesis, Department Computer Information Science, University Pennsylvania, PA, USA.
Goldberg, E., & Novikov, Y. (2001). BerkMin: fast robust SAT solver. Proceedings
Design, Automation Test Europe (DATE-02), Paris, France, pp. 142149.
IEEE Computer Society.
Heras, F., & Larrosa, J. (2006). New inference rules efficient Max-SAT solving. Proceedings 21st National Conference Artificial Intelligence (AAAI-06), Boston,
USA. AAAI Press.
Huang, W. Q., & Jin, R. C. (1997). Solar: learning human algorithm solving
SAT. Science China (Series E), 27 (2), 179186.
Jeroslow, R. G., & Wang, J. (1990). Solving propositional satisfiability problems. Annals
Mathematics Artificial Intelligence, 1, 167187.
357

fiLi, Manya & Planes

Larrosa, J., & Heras, F. (2005). Resolution Max-SAT relation local consistency
weighted CSPs. Proceedings 19th International Joint Conference Artificial Intelligence (IJCAI-05), Edinburgh, Scotland, pp. 193198. Morgan Kaufmann.
Larrosa, J., Heras, F., & de Givry, S. (2007). logical approach efficient Max-SAT
solving. Artificial Intelligence, (in press).
Larrosa, J., & Meseguer, P. (2002). Partition-based lower bound Max-CSP. Constraints,
7 (34), 407419.
Larrosa, J., Meseguer, P., & Schiex, T. (1999). Maintaining reversible DAC Max-CSP.
Artificial Intelligence, 107 (1), 149163.
Li, C. M. (1999). constraint-based approach narrow search trees satisfiability.
Information Processing Letters, 71, 7580.
Li, C. M., & Anbulagan (1997a). Heuristics based unit propagation satisfiability
problems. Proceedings 15th International Joint Conference Artificial
Intelligence (IJCAI-97), Nagoya, Japan, pp. 366371. Morgan Kaufmann.
Li, C. M., & Anbulagan (1997b). Look-ahead versus look-back satisfiability problems.
Proceedings 3rd International Conference Principles Constraint Programming (CP-97), Linz, Austria, LNCS 1330, pp. 341355. Springer.
Li, C. M., & Huang, W. Q. (2005). Diversification determinism local search
satisfiability. Proceedings 8th International Conference Theory Applications Satisfiability Testing (SAT-05), St. Andrews, Scotland, LNCS 3569, pp.
158172. Springer.
Li, C. M., Manya, F., & Planes, J. (2005). Exploiting unit propagation compute lower
bounds branch bound Max-SAT solvers. Proceedings 11th International Conference Principles Practice Constraint Programming (CP-05),
Sitges, Spain, LNCS 3709, pp. 403414. Springer.
Li, C. M., Manya, F., & Planes, J. (2006). Detecting disjoint inconsistent subformulas
computing lower bounds Max-SAT. Proceedings 21st National Conference
Artificial Intelligence (AAAI-06), Boston, USA, pp. 8691. AAAI Press.
Marques-Silva, J. P., & Sakallah, K. A. (1999). GRASP: search algorithm propositional
satisfiability. IEEE Transactions Computers, 48 (5), 506521.
Niedermeier, R., & Rossmanith, P. (2000). New upper bounds maximum satisfiability.
Journal Algorithms, 36, 6388.
Regin, J. C., Petit, T., Bessiere, C., & Puget, J. F. (2001). New lower bounds constraint
violations over-constrained problems. 7th International Conference Principles Practice Constraint Programming (CP-01), Paphos, Cyprus, LNCS 2239,
pp. 332345. Springer.
Schiex, T. (2000). Arc consistency soft constraints. Proceedings 6th International Conference Principles Constraint Programming (CP-00), Singapore,
LNCS 1894, pp. 411424. Springer.
358

fiNew Inference Rules Max-SAT

Shen, H., & Zhang, H. (2004). Study lower bound functions max-2-sat. Proceedings
National Conference Artificial Intelligence (AAAI-04), San Jose, USA, pp.
185190. AAAI Press.
Shen, H., & Zhang, H. (2005). Improving exact algorithms max-2-sat. Annals Mathematics Artificial Intelligence, 44, 419436.
Wallace, R. J. (1995). Directed arc consistency preprocessing. Constraint Processing,
Selected Papers, LNCS 923, pp. 121137. Springer.
Wallace, R. J., & Freuder, E. (1996). Comparative studies constraint satisfaction
Davis-Putnam algorithms maximum satisfiability problems. Johnson, D., &
Trick, M. (Eds.), Cliques, Coloring Satisfiability, Vol. 26, pp. 587615. American
Mathematical Society.
Xing, Z., & Zhang, W. (2004). Efficient strategies (weighted) maximum satisfiability.
Proceedings 10th International Conference Principles Practice Constraint Programming (CP-04), Toronto, Canada, LNCS 3258, pp. 690705. Springer.
Xing, Z., & Zhang, W. (2005). efficient exact algorithm (weighted) maximum satisfiability. Artificial Intelligence, 164 (2), 4780.
Xu, K., Boussemart, F., Hemery, F., & Lecoutre, C. (2005). simple model generate
hard satisfiable instances. Proceedings 19th International Joint Conference
Artificial Intelligence (IJCAI-05), Edinburgh, Scotland, pp. 337342.
Xu, K., & Li, W. (2006). Many hard examples exact phase transitions. Theoretical
Computer Science, 355, 291302.
Zhang, H. (1997). SATO: efficient propositional prover. Proceedings Conference
Automated Deduction (CADE-97), pp. 272275.
Zhang, H., Shen, H., & Manya, F. (2003). Exact algorithms MAX-SAT. Electronic
Notes Theoretical Computer Science, 86 (1).
Zhang, L., Madigan, C., Moskewicz, M., & Malik, S. (2001). Efficient conflict driven learning
Boolean satisfiability solver. International Conference Computer Aided
Design (ICCAD-01), San Jose, USA, pp. 279285.

359

fiJournal Artificial Intelligence Research 30 (2007) 101-132

Submitted 10/05; published 9/07

Planning Spectrum One, Two, Three, Infinity
Marco Pistore

pistore@dit.unitn.it

Department Information Communication Technology
University Trento
Via Sommarive 14, 38050 Povo (Trento), Italy

Moshe Y. Vardi

vardi@cs.rice.edu

Department Computer Science
Rice University
6100 S. Main Street, Houston, Texas

Abstract
Linear Temporal Logic (LTL) widely used defining conditions execution
paths dynamic systems. case dynamic systems allow nondeterministic
evolutions, one specify, along LTL formula , paths
required satisfy formula. Two extreme cases universal interpretation A.,
requires formula satisfied execution paths, existential
interpretation E., requires formula satisfied execution path.
LTL applied definition goals planning problems nondeterministic
domains, two extreme cases restrictive. often impossible develop plans
achieve goal nondeterministic evolutions system, weak
require goal satisfied execution.
paper explore alternative interpretations LTL formula
extreme cases. define new language permits arbitrary combination
E quantifiers, thus allowing, instance, require finite execution
extended execution satisfying LTL formula (AE.),
finite execution whose extensions satisfy LTL formula (EA.). show
eight combinations path quantifiers relevant, corresponding alternation
quantifiers length one (A E), two (AE EA), three (AEA EAE),
infinity ((AE) (EA) ). also present planning algorithm new language
based automata-theoretic approach, study complexity.

1. Introduction
automated task planning (Fikes & Nilsson, 1971; Penberthy & Weld, 1992; Ghallab, Nau,
& Traverso, 2004), given description dynamic domain basic actions
performed it, given goal defines success condition achieved, one
find suitable plan, is, description actions executed domain
order achieve goal. Classical planning concentrates called reachability
goals, is, goals define set final desired states reached. Quite often
practical applications require plans deal goals general sets
final states. Several planning approaches recently proposed, temporal logic
formulas used goal language, thus allowing goals define conditions
whole plan execution paths, i.e., sequences states resulting execution
plans (Bacchus & Kabanza, 1998, 2000; Calvanese, de Giacomo, & Vardi, 2002; Cerrito &
c
2007
AI Access Foundation. rights reserved.

fiPistore & Vardi

Mayer, 1998; Dal Lago, Pistore, & Traverso, 2002; de Giacomo & Vardi, 1999; Kvarnstrom
& Doherty, 2001; Pistore & Traverso, 2001). approaches use Linear Temporal
Logic (LTL) (Emerson, 1990) goal language. LTL allows one express reachability
goals (e.g., F q reach q), maintainability goals (e.g., G q maintain q), well goals
combine reachability maintainability requirements (e.g., F G q reach set
states q maintained), Boolean combinations goals.
planning nondeterministic domains (Cimatti, Pistore, Roveri, & Traverso, 2003;
Peot & Smith, 1992; Warren, 1976), actions allowed different outcomes,
possible know planning time different possible outcomes actually
take place. Nondeterminism action outcome necessary modeling realistic way
several practical domains, ranging robotics autonomous controllers two-player
games.1 instance, realistic robotic application one take account
actions like pick object might result failure (e.g., object slips
robots hand). consequence nondeterminism execution plan may lead
one possible execution path. Therefore, one distinguish whether given
goal satisfied possible execution paths (in case speak strong
planning), possible execution paths (weak planning). case
LTL goal , strong planning corresponds interpreting formula universal
way, A., weak planning corresponds interpreting existential way,
E..
Weak strong plans two extreme ways satisfying LTL formula. nondeterministic planning domains, might impossible achieve goals strong way:
instance, robotic application might impossible fulfill given task objects
keep slipping robots hand. hand, weak plans unreliable,
since achieve goal overly optimistic assumptions outcomes
action executions.
case reachability goals, strong cyclic planning (Cimatti et al., 2003; Daniele,
Traverso, & Vardi, 1999) shown provide viable compromise weak
strong planning. Formally, plan strong cyclic possible partial execution
plan always extended execution reaches goal state. Strong cyclic
planning allows plans encode iterative trial-and-error strategies, like pick
object succeed. execution strategies may loop forever case
action pick object continuously fails, failure achieving goal
unfair execution usually acceptable. Branching-time logics like CTL CTL* allow
expressing goals take account nondeterminism. Indeed, Daniele et al. (1999)
show encode strong cyclic reachability goals CTL formulas. However, CTL
CTL* path quantifiers interleaved temporal operators, making difficult
extend encoding strong cyclic planning proposed Daniele et al. (1999) generic
temporal goals.
paper define new logic allows exploring different degrees
LTL formula satisfied exist strong goal A. weak goal
E.. consider logic formulas form ., LTL formula
path quantifier generalizes E quantifiers used strong weak planning.
1. See work Ghallab et al. (2004) deeper discussion fundamental role nondeterminism
planning problems practical applications.

102

fiThe Planning Spectrum One, Two, Three, Infinity

path quantifier (finite infinite) word alphabet {A, E}. path quantifier
seen definition two-player game selection outcome action
execution. Player (corresponding symbol A) chooses action outcomes order
make goal fail, player E (corresponding symbol E) chooses action outcomes
order satisfy goal . turn, active player controls outcome action
execution finite number actions passes control player.2
say plan satisfies goal . player E winning strategy, namely if,
possible moves player A, player E always able build execution path
satisfies LTL formula .
Different path quantifiers define different alternations turns players E.
instance, goal A. require formula satisfied independently
hostile player chooses outcomes actions, is, ask strong plan.
goal E. require formula satisfied action outcomes chosen
friendly player E, is, ask weak plan. goal AE. require
every plan execution led player extended player E successful execution
satisfies formula ; case reachability goal, corresponds asking
strong cyclic solution. goal EA. require that, initial set actions
controlled player E, guarantee formula satisfied independently
player choose outcome following actions. final example,
goal (AE) . = AEAEA . require formula satisfied executions
player E possibility controlling action outcome infinite number
times.
Path quantifiers define arbitrary combinations turns players E,
hence different degrees satisfying LTL goal. show, however, that, rather surprisingly, finite number alternatives exist strong weak planning:
eight canonical path quantifiers give rise plans different strength, every
path quantifier equivalent canonical one. canonical path quantifiers correspond
games length one (A E), two (AE EA), three (AEA EAE),
games defining infinite alternation players E ((AE) (EA) ).
also show that, case reachability goals = F q, canonical path quantifiers
collapse. three different degrees solution possible, corresponding weak
(E. F q), strong (A. F q), strong cyclic (AE. F q) planning.
Finally, present planning algorithm new goal language study
complexity. algorithm based automata-theoretic approach (Emerson & Jutla,
1988; Kupferman, Vardi, & Wolper, 2000): planning domains goals represented
suitable automata, planning reduced problem checking whether given
automaton nonempty. proposed algorithm time complexity doubly
exponential size goal formula. known planning problem
2EXPTIME-complete goals form A. (Pnueli & Rosner, 1990), hence
complexity algorithm optimal.
structure paper follows. Section 2 present preliminaries
automata theory temporal logics. Section 3 define planning domains
plans. Section 4 define AE-LTL, new logic path quantifier, study basic
2. path quantifier finite word, player last turn chooses action outcome
rest infinite execution.

103

fiPistore & Vardi

properties. Section 5 present planning algorithm AE-LTL, Section 6
apply new logic particular cases reachability maintainability goals.
Section 7 make comparisons related works present concluding remarks.

2. Preliminaries
section introduces preliminaries automata theory temporal logics.
2.1 Automata Theory
Given nonempty alphabet , infinite word infinite sequence 0 , 1 , 2 , . . .
symbols . Finite state automata proposed finite structures accept
sets infinite words. paper, interested tree automata, namely finite
state automata recognize trees alphabet , rather words.
Definition 1 (tree) (leafless) tree subset N that:
root tree;
x N x ;
x , x N N, also x ;
x (i+1) , x N N, also x .
arity x number children, namely arity(x) = |{i : x }|. Let
N. Tree D-tree arity(x) x . -labelled tree pair (, ),
tree : . following, denote -labelled tree (, )
, let = dom( ).
Let -labelled tree. path p (possibly infinite) sequence x0 , x1 , . . . nodes
xi dom( ) xk+1 = xk ik+1 . following, denote P ( ) set
finite paths P ( ) set infinite paths . Given (finite infinite) path p,
denote (p) string (x0 ) (x1 ) , x0 , x1 , . . . sequence nodes
path p. say finite (resp. infinite) path p0 finite (resp. infinite) extension
finite path p sequence nodes p prefix sequence nodes p0 .
tree automaton automaton accepts sets trees. paper, consider
particular family tree automata, namely parity tree automata (Emerson & Jutla, 1991).
Definition 2 (parity tree automata) parity tree automaton parity index k
tuple = h, D, Q, q0 , , i, where:
finite, nonempty alphabet;
N finite set arities;
Q finite set states;
q0 Q initial state;
104

fiThe Planning Spectrum One, Two, Three, Infinity





: Q 2Q transition function, (q, , d) 2Q ;
: Q {0, . . . , k} parity mapping.
tree automaton accepts tree accepting run automaton tree.
Intuitively, parity tree automaton state q reading d-ary node
tree labeled , nondeterministically chooses d-tuple hq1 , . . . , qd (q, , d)
makes copies itself, one child node tree, state
i-th copy updated qi . run parity tree automaton accepting if, along every
infinite path, minimal priority visited infinitely often even number.
Definition 3 (tree acceptance) parity tree automaton = h, D, Q, q0 , , accepts -labelled D-tree exists accepting run r , namely exists
mapping r : Q that:
r() = q0 ;
x arity(x) = hr(x 0), . . . r(x (d1))i (r(x), (x), d);
along every infinite path x0 , x1 , . . .
infinitely many nodes xi even.

, minimal integer h (r(xi )) = h

tree automaton nonempty exists tree



accepted A.

Emerson Jutla (1991) shown emptiness parity tree automaton
decided time exponential parity index polynomial number
states.
Theorem 1 emptiness parity tree automaton n states index k
determined time nO(k) .
2.2 Temporal Logics
Formulas Linear Temporal Logic (LTL) (Emerson, 1990) built top set Prop
atomic propositions using standard Boolean operators, unary temporal operator
X (next), binary temporal operator U (until). following assume
fixed set atomic propositions Prop, define = 2Prop set subsets
Prop.
Definition 4 (LTL) LTL formulas Prop defined following grammar,
q Prop:
::= q | | | X | U
define following auxiliary operators: F = > U (eventually future )
G = F (always future ). LTL formulas interpreted infinite words
. following, write w |=LTL whenever infinite word w satisfies LTL
formula .
Definition 5 (LTL semantics) Let w = 0 , 1 , . . . infinite word let
LTL formula. define w, |=LTL , N, follows:
105

fiPistore & Vardi

w, |=LTL q iff q ;
w, |=LTL iff hold w, |=LTL ;
w, |=LTL 0 iff w, |=LTL w, |=LTL 0 ;
w, |=LTL X iff w, i+1 |=LTL ;
w, |=LTL U 0 iff j w, k |=LTL k < j
w, j |=LTL 0 .
say w satisfies , written w |=LTL , w, 0 |=LTL .
CTL* (Emerson, 1990) example branching-time logic. Path quantifiers
(for paths) E (for path) prefix arbitrary combinations linear time
operators.
Definition 6 (CTL*) CTL* formulas Prop defined following grammar,
q Prop:
::= q | | | | E
::= | | | X | U
CTL* formulas interpreted -labelled trees. following, write
whenever satisfies CTL* formula .



|=CTL*

Definition 7 (CTL* semantics) Let -labelled tree let CTL* formula.
define , x |=CTL* , x , follows:


, x |=CTL* q iff q (x);



, x |=CTL* iff hold , x |=CTL* ;



, x |=CTL* 0



, x |=CTL* iff , p |=CTL* holds infinite paths p = x0 , x1 , . . . x0 = x;



,x



iff

|=CTL* E iff
x0 = x;

, x |=CTL* , x |=CTL* 0 ;

,p

|=CTL* holds infinite path p = x0 , x1 , . . .

, p |=CTL* , p P ( ), defined follows:



, p |=CTL* iff p = x0 , x1 , . . . , x0 |=CTL* ;



, p |=CTL* iff hold , p |=CTL* ;



, p |=CTL* 0



, p |=CTL* X iff , p0 |=CTL* , p0 = x1 , x2 , . . . p = x0 , x1 , x2 , . . .;



, p |=CTL* U 0 iff j 0 , pk |=CTL* 0 k < j
, pj |=CTL* 0 , pi = xi , xi+1 , . . . p = x0 , x1 , . . ..

iff

, p |=CTL* , p |=CTL* 0 ;

106

fiThe Planning Spectrum One, Two, Three, Infinity

put_B_on_A


B

C

B


put_C_on_B
C

C
B


Figure 1: possible scenario blocks-world domain.
say



satisfies CTL* formula , written



|=CTL* ,

, |=CTL* .

following theorem states possible build tree automaton accepts
trees satisfying CTL* formula. tree automaton number states
doubly exponential parity index exponential length formula.
proof theorem given Emerson Jutla (1988).
Theorem 2 Let CTL* formula, let N finite set arities. One
build parity tree automaton AD
accepts exactly -labelled D-trees satisfy .
2
automaton AD
2
formula .

O(||)

states parity index 2O(||) , || length

3. Planning Domains Plans
(nondeterministic) planning domain (Cimatti et al., 2003) expressed terms
set states, one designated initial state, set actions, transition
function describing (the execution of) action leads one state possibly many
different states.
Definition 8 (planning domain) planning domain tuple = h, 0 , A, Ri where:
finite set states;
0 initial state;
finite set actions;
R : 2 transition relation.
require 0 0 R(, a).
assume states ordered, write R(, a) = h1 , 2 , . . . , n whenever
R(, a) = {1 , 2 , . . . , n } 1 < 2 < < n .
Example 1 Consider blocks-world domain consisting set blocks, initially
table, stacked top order build towers (see
Figure 1).
states domain possible configurations blocks: case
three blocks 13 states, corresponding blocks table (1 configuration),
2-block tower remaining block table (6 configurations), 3-block tower
(6 possible configurations). assume initially blocks table.
107

fiPistore & Vardi

actions domain put X , put X table, wait, X
two (different) blocks. Actions put X put X table possible
blocks top X (otherwise could pick X). addition, action
put X requires blocks top (otherwise could put X
top ).
assume outcome action put X nondeterministic: indeed, trying
put block top tower may fail, case tower destroyed. Also action
wait nondeterministic: possible table bumped towers
destroyed.
plan guides evolution planning domain issuing actions executed.
case nondeterministic domains, conditional plans (Cimatti et al., 2003; Pistore &
Traverso, 2001) required, is, next action issued plan may depend
outcome previous actions. consider general definition plans:
plan mapping sequence states, representing past history domain
evolution, action executed.
Definition 9 (plan) plan partial function : + * that:
(w ) = a, 0 R(, a) 0 ;
(w ) = a, 0 R(, a) iff w 0 dom();
w dom() w 6= , w dom();
() defined iff = 0 initial state domain.
conditions previous definition ensure plan defines action executed
exactly finite paths w + reached executing plan initial
state domain.
Example 2 possible plan blocks-world domain Example 1 represented Figure 2. remark importance plans action executed depends
whole sequence states corresponding past history evolution. Indeed,
according plan Figure 2, two different actions put C put C table
performed state block B top A, depending past history.
Since consider nondeterministic planning domains, execution action may
lead different outcomes. Therefore, execution plan planning domain
described (A)-labelled tree. Component label tree corresponds
state planning domain, component describes action executed
state.
Definition 10 (execution tree) execution tree domain plan
(A)-labelled tree defined follows:


() = (0 , a0 ) 0

initial state domain a0 = (0 );
108

fiThe Planning Spectrum One, Two, Three, Infinity

w

(w)

ABC

put B

B
ABC AC

put C B

B
ABC AC

C
B


B
ABC AC

C
B


B
AC

B
ABC AC

C
B


B
AC

put C table

history

put B table

ABC

wait
wait

Figure 2: plan blocks-world domain.
p = x0 , . . . , xn P ( ) (p) = (0 , a0 ) (1 , a1 ) (n , ), R(n , ) =
0
h00 , . . . , d1
i, every 0 < following conditions hold: xn dom( )
(xn i) = (i0 , a0i ) a0i = (0 1 n i0 ).
planning problem consists planning domain goal g defines set
desired behaviors. following, assume goal g defines set execution
trees, namely execution trees exhibit behaviors described goal (we say
execution trees satisfy goal).
Definition 11 (planning problem) planning problem pair (D, g),
planning domain g goal. solution planning problem (D, g) plan
execution tree satisfies goal g.

4. Logic Path Quantifiers
section define new logic based LTL extends
possibility defining conditions sets paths satisfy LTL property.
start motivating logic necessary defining planning goals.
Example 3 Consider blocks-world domain introduced previous section. Intuitively, plan Example 2 solution goal building tower consisting
blocks A, B, C destroying it. goal easily formulated LTL
109

fiPistore & Vardi

formula:
1 = F ((C B B table) F (C table B table table)).
Notice however that, due nondeterminism outcome actions, plan may
fail satisfy goal. possible, instance, action put C B fails
tower destroyed. case, plan proceeds performing wait actions, hence
tower never finished. Formally, plan solution goal requires
path execution structure satisfies LTL formula 1 .
Clearly, better ways achieve goal building tower destroying
it: fail building tower, rather giving up, restart building keep
trying succeed. strategy allows achieving goal paths:
keep destroying tower try build achieve goal.
see, logic path quantifiers going define allow us formalize
mean paths.
Consider following LTL formula:
2 = F G ((C B B table).
formula requires building tower maintaining it. case two possible
ways fail achieve goal. fail build tower; or, built, fail
maintain (remember wait action may nondeterministically lead destruction
tower). Similarly case formula 1 , planning goal requires satisfying
formula 2 paths execution tree unsatisfiable. hand, goal
requires satisfying paths weak; logic allows us demanding
paths satisfy formula.
Finally, consider following LTL formula:
3 = G F ((C B B table).
requires tower exists infinitely many time, i.e., tower gets destroyed,
rebuild it. Intuitively, goal admits plans achieve often, i.e.,
paths, 2 . again, path logic needed give formal meaning
paths.
order able represent planning goals discussed previous example,
consider logic formulas form ., LTL formula path
quantifier defines set infinite paths formula checked. Two
extreme cases path quantifier A, used denote must hold
paths, path quantifier E, used denote must hold paths.
general, path quantifier (finite infinite) word alphabet {A, E} defines
alternation selection two modalities corresponding E A. instance,
writing AE. require finite paths infinite extension satisfies
, writing EA. require extensions finite path satisfy .
path quantifier seen definition two-player game selection
paths satisfy LTL formula. Player (corresponding A) tries build
path satisfy LTL formula, player E (corresponding E) tries
110

fiThe Planning Spectrum One, Two, Three, Infinity

build path LTL formula holds. Different path quantifiers define different
alternations turns players E. game starts path consisting
initial state, and, turns, players E extend path finite
number nodes. case path quantifier finite word, player moves last
game extends finite path built far infinite path. formula satisfied
player E winning strategy, namely if, possible moves player A,
always able build path satisfies LTL formula.
Example 4 Let us consider three LTL formulas defined Example 3, let us see
path quantifiers introduced applied.
case formula 1 , plan presented Example 2 satisfies requirement E.1 :
path tower built destroyed. also satisfies stronger
requirement EA.1 stresses fact that, case, tower built
destroyed, safely give control player A. Formula 1 satisfied
stronger way, however. Indeed, plan keeps trying build tower satisfies
requirement AE.1 , well requirement AEA.1 : player cannot reach state
satisfaction goal prevented.
Let us consider formula 2 . case, find plans satisfying AE.2 ,
plan satisfy requirement AEA.2 . Indeed, player simple strategy win,
gets control built tower: bump table. Similar considerations hold
also formula 3 . Also case, find plans requirement AE.3 ,
requirement AEA.3 . case, however, plans exist also requirement AEAEAE .3 :
player E gets control infinitely often, rebuild tower needed.
rest section give formal definition study basic properties
logic path quantifiers.
4.1 Finite Games
start considering games finite number moves, path quantifiers
corresponding finite words {A, E}.
Definition 12 (AE-LTL) AE-LTL formula pair g = ., LTL
formula {A, E}+ path quantifier.
following definition describes games corresponding finite path quantifiers.
Definition 13 (semantics AE-LTL) Let p finite path -labelled tree
Then:
p |= A. finite extensions p0 p holds p0 |= ..
p |= E. finite extension p0 p holds p0 |= ..
p |= A. infinite extensions p0 p holds

(p0 ) |=LTL .

p |= E. infinite extension p0 p holds
111

(p0 ) |=LTL .

.

fiPistore & Vardi

say -labelled tree satisfies AE-LTL formula g, write
p0 |= g, p0 = root .



|= g,

AE-LTL allows path quantifiers consisting arbitrary combination
Es. combination corresponds different set rules game
E. Theorem 4 show freedom definition path quantifier
needed. six path quantifiers sufficient capture possible games.
result based concept equivalent path quantifiers.
Consider formulas A. F p AE. F p. easy see two formulas equisatisfiable, i.e., tree satisfies A. F p also satisfies AE. F p, vice-versa.
case, path quantifiers AE power, depends fact
use path quantifiers combination LTL formula F p. combine
two path quantifiers different LTL formulas, G p, possible find
trees satisfy latter path quantifier former. reason, cannot
consider two path quantifiers equivalent. Indeed, order two path quantifiers
equivalent, equi-satisfiable LTL formulas. intuition
formalized following definition.
Definition 14 (equivalent path quantifiers) Let 0 two path quantifiers.
say implies 0 , written
0 , -labelled trees LTL formulas
0
, |= . implies |= .. say equivalent 0 , written 0 ,
0
0

.
following lemma describes basic properties path quantifiers
equivalences among them. exploit results proof Theorem 4.
Lemma 3 Let , 0 {A, E} . following implications equivalences hold.
1. AA0 A0 EE0 E0 .
2. A0

0 0

E0 , 0 empty.

3. A0

AEA0 EAE0

E0 .

4. AEAE0 AE0 EAEA0 EA0 .
Proof. proof lemma, order prove 0
00 prove that, given
0
arbitrary tree arbitrary LTL formula , p |= . implies p |= 00 . every
finite path p . Indeed, p |= 0 . implies p |= 00 . finite paths p, easy
prove, induction , p |= 0 . implies p |= 00 . finite paths p.
following, refer proof technique prefix induction.
1. show that, every finite path p, p |= AA0 . p |= A0 .:
equivalence AA0 A0 follows prefix induction.
Let us assume p |= AA0 .. prove p |= A0 ., is, p0 |= 0 .
every finite3 extension p0 p. Since p |= AA0 ., Definition 13 know that,
3. assume 0 empty word. proof case 0 empty word similar.

112

fiThe Planning Spectrum One, Two, Three, Infinity

every finite extension p0 p, p0 |= A0 .. Hence, Definition 13, know
every finite extension p00 p0 , p00 |= 0 .. Since p0 finite extension p0 ,
conclude p0 |= 0 .. Therefore, p0 |= 0 . holds finite extensions p0
p.
Let us assume p |= A0 .. prove p |= AA0 ., is, finite
extensions p0 p, finite extensions p00 p0 , p00 |= 0 .. remark
finite path p00 also finite extension p, therefore p00 |= 0 . holds since
p |= A0 ..
concludes proof equivalence AA0 A0 . proof
equivalence EE0 E0 similar.
2. Let us assume first 0 empty word. distinguish two cases, depending
first symbol 0 . 0 = A00 , prove AA00
A00 ,
0
00
already item 1 lemma. = E , show that,
every finite path p, p |= AE00 . p |= E00 .: A0
0 follows
00
prefix induction. Let us assume p |= AE .. Then, finite extensions p0
p exists finite4 extension p00 p0 p00 |= 0 .. Let us take p0 = p.
know finite extension p00 p p00 |= 0 ., is,
according Definition 13, p |= E0 ..
Let us assume 0 empty word. hypothesis, 0 6= ,
empty. distinguish two cases, depending last symbol . = 00A,
prove 00AA
00A, already item 1 lemma.
= 00 E, prove every finite path p, p |= EA. p |= E.:
00 EA
00 E follows prefix induction. Let us assume p |= EA..
Definition 13, exists finite extension p0 p that, every infinite
extension p00 p0 (p00 ) |=LTL . Let p00 infinite extension p0 .
know p00 also infinite extension p, (p00 ) |=LTL . Then,
Definition 13 deduce p |= E..
concludes proof A0

0 . proof 0

E0 similar.

3. item 1 lemma know A0
AA0 item 2 know
0
0
AA
AEA . concludes proof A0
AEA0 . proof
EAE0
E0 similar.
4. item 3 lemma know (A)EAE0
(A)E0 . Moreover,
0
0
item 3, know A(E )
AEA(E ). Therefore, deduce AE0
0
0
AEAE . proof EA EAEA0 similar.

prove first main result paper: finite path quantifier
equivalent canonical path quantifier length three.
Theorem 4 finite path quantifier canonical finite path quantifier
0 {A, E,AE, EA,AEA, EAE}
4. assume 00 empty word. proof case 00 empty similar.

113

fiPistore & Vardi

0 . Moreover, following implications hold canonical finite
path quantifiers:
(1)
/o /o /o / AEA o/ /o /o / AE











/

/
/
/

EA
EAE /o /o o/ / E




Proof. first prove path quantifier equivalent canonical path
quantifier 0 . iterative application Lemma 3(1), obtain path quantifier
00 00 00 contain two adjacent E. Then, iterative
application Lemma 3(4), transform 00 equivalent path quantifier 0
length 3. canonical path quantifiers (1) precisely quantifiers
length 3 contain two adjacent E.
implications (1):


AEA EAE

E come Lemma 3(3);

AEA

EA AE

EAE come Lemma 3(2);

AEA

AE EA

EAE come Lemma 3(2).



remark Lemma 3 Theorem 4 depend usage LTL formula
. depend general observation
0 whenever player E select
game 0 set paths subset selected game .
4.2 Infinite Games
consider infinite games, namely path quantifiers consisting infinite words
alphabet {A, E}. see infinite games express finite path quantifiers
studied previous subsection, infinite games, corresponding infinite alternation two players E, cannot expressed
finite path quantifiers.
case infinite games, assume player E moves according strategy
suggests extend finite path. say |= ., infinite
game, winning strategy player E. strategy winning if, whenever
p infinite path obtained according i.e., allowing player play
arbitrary way requiring player E follows strategy p satisfies LTL
formula .
Definition 15 (strategy) strategy -labelled tree mapping : P ( )
P ( ) maps every finite path p one finite extensions (p).
Definition 16 (semantics AE-LTL) Let = 0 1 {A, E} infinite
path quantifier. infinite path p possible outcome game strategy
generating sequence it, namely, infinite sequence p0 , p1 , . . . finite paths
that:
pi finite prefixes p;
114

fiThe Planning Spectrum One, Two, Three, Infinity

p0 = root tree

;

= E pi+1 = (pi );
= pi+1 (arbitrary) extension pi .
denote P (, ) set infinite paths possible outcomes game
strategy . tree satisfies AE-LTL formula g = ., written |= g,
strategy (p) |=LTL paths p P (, ).
remark possible paths generating sequence stop growing, i.e.,
pi pi = pj j i. case, according previous
definition, infinite paths p extend pi possible outcomes.
next lemmas extend analysis equivalence among path quantifiers
infinite games.5 first lemma shows finite path quantifiers particular cases
infinite path quantifiers, namely, correspond infinite path quantifiers
end infinite sequence E.
Lemma 5 Let finite path quantifier. (A) (E) E.
Proof. prove (A) A. proof equivalence similar.
First, prove (A)
A. Let tree LTL formula
|= (A) .. Moreover, let strategy p P ((A) , ) satisfy .
order prove |= A. sufficient use strategy moves player
E, namely, whenever need prove p |= E0 . according Definition 13, take
p0 = (p) move prove p0 |= 0 .. way, infinite paths selected
Definition 13 coincide possible outcomes game (A) , hence satisfy
LTL formula .
concludes proof (A)
A. prove
(A) . distinguish
three cases.
Case = (A)n , n 0.
case, (Lemma 3(1)) (A) = (A) . Let tree
LTL formula. |= A. paths satisfy formula .
easy check also |= (A) . paths satisfy formula .
sufficient conclude (A)nA (A)n (A) .
Case = E0 .
case, EA. Indeed, arbitrary path quantifier starts E
ends A. Lemma 3(1), collapse adjacent occurrences
E , thus obtaining (EA)n n > 0. Moreover, Lemma 3(4)
(EA)n EA.
Let tree LTL formula. |= EA.
finite path p infinite extensions p satisfy . Now, let
5. definitions implication equivalence relations (Definition 14) also apply case
infinite path quantifiers.

115

fiPistore & Vardi

strategy () = p. every infinite path p P (E0 (A) , )
satisfies . Indeed, since player E first turn, possible outcomes
infinite extensions () = p.
concludes proof E0A

E0 (A) .

Case = (A)n E0 , n > 0.
Reasoning proof previous case, easy show AEA.
Let tree LTL formula. |= AEA.
every finite path p finite extension p0 p infinite
extensions p0 satisfy formula . Let strategy p0 = (p)
finite extension p infinite extensions p0 satisfy . every
infinite path p P ((A)n E0 (A) , ) satisfies . Indeed, let p0 , p1 , . . . , pn , pn+1 , . . .
generating sequence p. pn+1 = (pn ) p infinite extension pn+1 .
construction know p satisfies .
concludes proof (A)n E0A

(A)n E0 (A) .

Every finite path quantifier falls one three considered cases. Therefore,
conclude
(A) every finite path quantifier .

next lemma defines sufficient condition proving
useful proofs forthcoming lemmas.

0 . condition

Lemma 6 Let 0 two infinite path quantifiers. Let us assume -labelled
trees strategy strategy 0 P (0 , 0 ) P (, ).

0 .
Proof. Let us assume |= .. suitable strategy
p P (, ) satisfy LTL formula . Let 0 strategy P (0 , 0 )
P (, ). hypothesis, possible outcomes game 0 strategy 0 satisfy LTL
formula , hence |= 0 .. concludes proof
0 .

next lemma show games players E alternate infinitely
often equivalent one two games (AE) (EA) . is, assume
player extends path turn passes player.
Lemma 7 Let infinite path quantifier contains infinite number
infinite number E. (AE) (EA) .
Proof. Let = (A)m1 (E)n1 (A)m2 (E)n2 mi , ni > 0. show (AE) .
First, prove (AE)
. Let strategy tree let p infinite
path . show p P (, ) p P ((AE) , ). Lemma 6
sufficient proving (AE)
.
Let p0 , p1 , . . . generating sequence p according . Moreover, let p00 = ,
p02i+1 = pm1 +n1 ++mi1 +ni1 +mi p02i+2 = pm1 +n1 ++mi1 +ni1 +mi +1 . easy
check p00 , p01 , p02 , . . . valid generating sequence p according game (AE)
strategy . Indeed, extensions p00 p01 , p02 p03 , p04 p05 , . . . moves player A,
116

fiThe Planning Spectrum One, Two, Three, Infinity

hence arbitrary. Extensions p01 p02 , p03 p04 , . . . correspond extensions
pm1 pm1 +1 , pm1 +n1 +m2 pm1 +n1 +m2 +1 , . . . , moves player E hence
respect strategy .
prove
(AE) . Let strategy tree . define strategy
p P (, ). Lemma 6 sufficient proving
p P ((AE) , ),


(AE) .
= kp (p) kp = P|p| ni . is, strategy path
Let p finite path. (p)
i=1
p obtained applying kp times strategy . number times strategy applied
depends length |p| path p.
p possible
show that, p possible outcome game strategy ,

outcome game (AE) strategy . Let p0 , p1 , . . . generating sequence p

according (AE) .
p0 , p1 , ..., p1 , (p1 ), 2 (p1 ), ..., n1 (p1 ), p3 , ..., p3 ,
| {z } |
{z
} | {z }
m1 times

m2 times
n1 times
2
n2
(p3 ), (p3 ), ..., (p3 ), p5 , ..., p5 , ...

|

{z

n2 times

} | {z }
m3 times

valid generating sequence p according . extensions corresponding
occurrence symbol E consist application strategy hence valid
player E. Moreover, extension ni (p2i1 ) p2i+1 valid move player
p2i+1 extension ni (p2i1 ). Indeed, ni (p2i1 ) prefix p2i (and hence p2i+1 )
P|p2i1 |
2i1 ) = kp2i1 (p2i1 ) kp
since p2i = (p
2i1 =
x=1 nx ni , since |p2i1 | i.
conditions Definition 16 easily checked.
concludes proof (AE) = (A)m1 (E)n1 (A)m2 (E)n2 . proof
(EA) = (E)m1 (A)n1 (E)m2 (A)n2 similar.

next lemma contains auxiliary results path quantifiers.
Lemma 8 Let finite path quantifier 0 infinite path quantifier.
1. A0
2. (A)

0 0

E0 .

A0 E0

(E) .

Proof.
1. prove A0
0 . Let strategy tree let p infinite
path . show p P (0 , ) p P (A0 , ). Let p0 , p1 , . . .
generating sequence p according 0 . easy check
p0 , p1 , . . . , pi1 , pi , pi , pi+1 , . . ., length , valid generating sequence
p according A0 . Indeed, extension pi pi valid move player
A. concludes proof A0
0 .
prove 0
E0 . 0 = (E) , E0 = E(E) = (E) = 0 ,
E0
0 trivially true. 0 6= (E) , assume, without loss
generality, 0 = A00 . case, let strategy tree let p
117

fiPistore & Vardi

path . show p P (E0 , ) p P (0 , ). Let p0 , p1 , . . .
generating sequence p according E0 . easy check
p0 , p1 , . . . , pi , pi+2 , . . ., length , valid generating sequence p
according 0 . Indeed, extension pi pi+2 valid, corresponds
first symbol 0 assumed symbol A. concludes proof
0
E0 .
2. prove (A)

0 . proof 0

(E) similar.

Let strategy tree let p infinite path . show
p P ((A) , ) p P (0 , ). Let p0 , p1 , . . . generating sequence p
according 0 . easy check p0 , p1 , . . . valid generating sequence p according (A) . fact, (A) defines less restrictive
conditions generating sequences 0 .
sufficient conclude (A)

0 .



complete picture Theorem 4: finite infinite path quantifier
equivalent canonical path quantifier defines game consisting alternated moves
players E length one, two, three, infinity.
Theorem 9 finite infinite path quantifier canonical path quantifier
0 {A, E,AE, EA,AEA, EAE, (AE) , (EA) }
0 . Moreover, following implications hold canonical path
quantifiers:
(2)
/o /o /o / AEA /o /o /o / (AE) /o /o /o / AE









EA /o /o /o /








(EA)






/o /o o/ / EAE /o /o o/ / E

Proof. first prove path quantifier equivalent canonical path quantifier.
Theorem 4, true finite path quantifiers, consider infinite path
quantifiers.
Let infinite path quantifier. distinguish three cases:
contains infinite number infinite number E: then, Lemma 7,
equivalent one canonical games (AE) (EA) .
contains finite number A: case, ends infinite sequence E,
and, Lemma 5, 00 finite path quantifier 00 . Theorem 4, 00
equivalent canonical path quantifier, concludes proof
case.
contains finite number E: case similar previous one.
implications (2):
118

fiThe Planning Spectrum One, Two, Three, Infinity

(AE)
(AE) .

(EA) comes Lemma 8(1), taking empty word 0 =

AEA
(AE) , (AE)
8(2).

AE, EA

(EA) , (EA)

EAE come Lemmas 5

implications come Theorem 4.



4.3 Strictness Implications
conclude section showing arrows diagram Theorem 9
describe strict implications, namely, eight canonical path quantifiers different.
Let us consider following {i, p, q}-labelled binary tree, root labelled
node two children labelled p q:
'&%$
!"#
iM
qqq MMMMM
q
q
MMM
q
M&
qqq
()*+
/.-,
()*+
/.-,
p =xq
q
=

===
=


==
=

==

=




()*+
/.-,
/.-,
()*+
()*+
/.-,
()*+
/.-,
p.
q.
p.
q.
...
...
...
...








()*+
/.-,
/.-,
/.-,
()*+
/.-,
()*+
/.-,
/.-,
/.-,
()*+
/.-,
()*+
p ()*+
p
p ()*+
q
q
p
q
q ()*+

Let us consider following LTL formulas:
F p: player E satisfy formula moves least once, visiting p-labelled
node.
G F p: player E satisfy formula visit infinite number p-labelled
nodes, is, final move finite game, moves infinitely often
infinite game.
F G p: player E satisfy formula takes control game
certain point on, is, final move finite game.
G q: player E satisfy formula player never plays, since player
immediately visit q-labelled node.
X p: player E satisfy formula playing first turn moving left
child root node.
following graph shows formulas hold path quantifiers:
Fp

GFp

FGp

G q

/o o/ / AEA /o / (AE) /o o/ / AE


Xp




















EA /o o/ / (EA) /o o/ / EAE /o /o o/ / E
119

fiPistore & Vardi

5. Planning Algorithm AE-LTL
section present planning algorithm AE-LTL goals. start showing
build parity tree automaton accepts trees satisfy given AE-LTL
formula. show tree automaton adapted, accepts
trees correspond valid plans given planning domain. way, problem
checking whether exists plan given domain AE-LTL goal
reduced emptiness problem tree automata. Finally, study complexity
planning AE-LTL goals prove problem 2EXPTIME-complete.
5.1 Tree Automata AE-LTL Formulas
Berwanger, Gradel, Kreutzer (2003) shown AE-LTL formulas expressed directly CTL* formulas. reduction exploits equivalence expressive
power CTL* monadic path logic (Moller & Rabinovich, 1999). tree automaton
obtained AE-LTL formula using reduction Theorem 2. However,
translation proposed Berwanger et al. (2003) upper bound non-elementary
complexity, hence useful complexity analysis. paper describe
different, direct reduction better suited purposes.
-labelled tree satisfies formula . suitable subset paths
tree satisfy . subset paths chosen according . order
characterize suitable subsets paths, assume w-marking tree ,
use labels w define selected paths.
Definition 17 (w-marking) w-marking -labelled tree ({w, w})-labelled tree w dom( ) = dom(w ) and, whenever (x) = , w (x) = (, w)
w (x) = (, w).
exploit w-markings follows. associate AE-LTL formula . CTL*
formula [[.]] tree satisfies formula . wmarking satisfies [[.]].
Definition 18 (AE-LTL CTL*) Let . AE-LTL formula. CTL* formula
[[.]] defined follows:
[[A.]] =
[[E.]] = E
[[EA.]] = EF w A(F w )
[[AEA.]] = AG EF w A(F w )
[[AE.]] = AG EXG w A(F G w )
[[EAE.]] = EF AG EXG w A(F G w )
[[(AE) .]] = AG EF w A(G F w )
[[(EA) .]] = EF AG EF w A(G F w )
case path quantifiers E, direct translation CTL*
exploit w-marking. cases, CTL* formula [[.]] conjunction
120

fiThe Planning Spectrum One, Two, Three, Infinity

two sub-formulas. first one characterizes good markings according path
quantifier , second one guarantees paths selected according
marking satisfy LTL formula . case path quantifiers EA AEA, mark
w nodes that, reached, guarantee formula satisfied. selected
paths hence contain node labelled w (formula F w). case
path quantifiers AE EAE, mark w descendants node define
infinite path satisfies . selected paths hence that, certain node
on, continuously labelled w (formula F G w). case path quantifiers (AE)
(EA) , finally, mark w nodes player E wants reach according
strategy passing turn player A. selected paths hence
contain infinite number nodes labelled w (formula G F w), is, paths along
player E moves infinitely often.
Theorem 10 -labelled tree satisfies AE-LTL formula .
w-marking satisfies formula [[.]].
Proof. proof, consider cases = AEA, = AE = (AE) .
cases similar.
Assume tree satisfies .. show exists w-marking w
satisfies [[.]].
Case = AEA. According Definition 13, tree satisfies AEA., every
finite path p extended finite path p0 infinite extensions
p00 p0 satisfy . Let us mark w nodes w correspond
extension p0 path p. construction, marked tree satisfies AG EF w.
remains show marked tree satisfies A(F w ).
Let us consider path p00 tree satisfies F w, let us show p00 also
satisfies . Since p00 satisfies F w, know contains nodes marked w. Let
p0 finite prefix path p00 first node marked w. construction,
exists finite path p p0 finite extension p infinite
extensions p0 satisfy . consequence, also p00 satisfies .
Case = AE. According Definition 13, tree satisfies AE.,
finite paths p infinite extension p satisfies . Therefore,
define mapping : P ( ) P ( ) associates finite path p infinite
extension m(p) satisfies . assume, without loss generality, that, p0
finite extension p also prefix m(p), m(p0 ) = m(p). is,
far p0 extends finite path p along infinite path m(p) associates
p0 infinite path m(p).
every finite path p, let us mark w node w child p
along infinite path m(p). construction, marked tree satisfies AG EXG w.
remains show marked tree satisfies A(F G w ).
Let us consider path p00 tree satisfies F G w, let us show p00 also
satisfies . Since p00 satisfies F G w, know path p
descendants p along p00 marked w. order prove p00 satisfies
121

fiPistore & Vardi

show p00 = m(p). Assume contradiction m(p) 6= p00 let p0
longest common prefix m(p) p00 . observe p prefix p0 , hence
m(p) = m(p0 ). implies child node p0 along p00 marked w,
absurd, since definition p descendants p along p00 marked
w.
Case = (AE) . According Definition 16, tree satisfies (AE) .,
exists suitable strategy player E possible outcomes game
strategy satisfy . Let us mark w nodes w correspond
extension (p) finite path p. is, mark w nodes
reached move player E according strategy . marked
tree satisfies formula AG EF w, is, every finite path p extended
finite path p0 node corresponding p0 marked w. Indeed,
construction, sufficient take p0 = (p00 ) extension p00 p. remains
show marked tree satisfies A(G F w ).
Let us consider path p tree satisfies G F w, let us show p also
satisfies . purpose, show p possible outcome game
strategy . remark that, given arbitrary finite prefix p0 p always possible
find finite extension p00 p0 (p00 ) also prefix p. Indeed,
set paths P = {p : (p) finite prefix p} infinite, infinite nodes
marked w path p.
Now, let p0 , p1 , p2 , . . . sequence finite paths defined follows: p0 = ()
root three; p2k+1 shortest extension p2k (p2k+1 )
prefix p; p2k+2 = (p2k+1 ). easy check p0 , p1 , p2 , . . . generating
sequence p according (AE) . Hence, Definition 16, infinite path p
satisfies LTL formula .
concludes proof satisfies ., exists w-marking
satisfies [[.]].
Assume w-marked tree w satisfies [[.]]. show satisfies
..
Case = AEA. marked tree satisfies formula AG EF w. means
finite path p (AG) exists finite extension p0 final node
p0 marked w (EF w) . Let p00 infinite extension finite path p0 .
show p00 satisfies LTL formula . Clearly, p00 satisfies formula F w.
Since tree satisfies formula A(F w ), infinite paths satisfy F w
also satisfy . Therefore, p00 satisfies LTL formula .
Case = AE. marked tree satisfies formula AG EXG w. Then,
finite path p (AG) exists infinite extension p0 that, certain
node on, nodes p0 marked w (EXG w). show that, p0
infinite extension finite path p, p0 satisfies LTL formula . Clearly,
p0 satisfies formula F G w. Since tree satisfies formula A(F G w ),
infinite paths satisfy F G w also satisfy . Therefore, p0 satisfies LTL
formula .
122

fiThe Planning Spectrum One, Two, Three, Infinity

Case = (AE) . Let strategy that, every finite path p, node
corresponding (p) marked w. remark always possible define
strategy. fact, marked tree satisfies formula AG EF w, hence,
finite path p extended finite path p0 node corresponding
p0 marked w.
Let p possible outcome game strategy . prove p satisfies
LTL formula . Definition 16, infinite path p contains infinite set
nodes marked w: nodes reached move player E. Hence,
p satisfies formula G F w. Since tree satisfies formula A(G F w ),
infinite paths satisfy G F w also satisfy . Therefore, path p satisfies LTL
formula .
concludes proof that, exists w-marking tree
|= ..



satisfies [[.]],


Kupferman (1999) defines extension CTL* existential quantification
atomic propositions (EGCTL*) examines complexity model checking satisfiability
new logic. remark AE-LTL seen subset EGCTL*. Indeed,
according Theorem 10, -labelled tree satisfies AE-LTL formula .
satisfies EGCTL* formula w.[[.]].
following definition show transform parity tree automaton
CTL* formula [[.]] parity tree automaton AE-LTL formula ..
transformation performed abstracting away information w-marking
input alphabet transition relation tree automaton.
Definition 19 Let = h{w, w}, D, Q, q0 , , parity tree automaton. parity
tree automaton Aw = h, D, Q, q0 , w , i, obtained abstracting away wmarking, defined follows: w (q, , d) = (q, (, w), d) (q, (, w), d).
Lemma 11 Let Aw two parity tree automata Definition 19. Aw accepts
exactly -labelled trees w-marking accepted A.
Proof. Let w ({w, w})-labelled tree let corresponding -labelled
tree, obtained abstracting away w-marking. show w accepted A,
accepted Aw . Let r : Q accepting run w A. r also
accepting run Aw . Indeed, x , arity(x) = d, w (x) = (, m)
{w, w}, hr(x 0), . . . , r(x d1)i (r(x), (, m), d). (x) = ,
and, definition Aw , hr(x 0), . . . , r(x d1)i w (r(x), , d).
show that, -labelled tree accepted Aw , ({w, w})labelled tree w w-marking accepted A. Let r : Q
accepting run Aw . definition run, know x , arity(x) =
(x) = , hr(x 0), . . . , r(x d1)i w (r(x), , d). definition w ,
know hr(x 0), . . . , r(x d1)i (r(x), (, w), d) (r(x), (, w), d). Let us define
w (x) = (, w) hr(x 0), . . . , r(x d1)i (r(x), (, w), d), w (x) = (, w) otherwise.
easy check r accepting run w A.

123

fiPistore & Vardi

ingredients defining tree automaton accepts
trees satisfy given AE-LTL formula.
Definition 20 (tree automaton AE-LTL) Let N finite set arities,
let . AE-LTL formula. parity tree automaton AD
. obtained applying
transformation described Definition 19 parity automaton AD
[[.]] built according
Theorem 2.
Theorem 12 parity tree automaton AD
. accepts exactly -labelled D-trees
satisfy formula ..
Proof. Theorem 2, parity tree automaton AD
[[.]] accepts D-trees satisfy
CTL* formula [[.]]. Therefore, parity tree automaton AD
. accepts D-trees
satisfy formula . Lemma 11 Theorem 10.

parity tree automaton AD
. parity index exponential number
states doubly exponential length formula .
2
Proposition 13 parity tree automaton AD
. 2

O(||)

states parity index 2O(||) .

Proof. construction Definition 19 change number states
parity index automaton. Therefore, proposition follows Theorem 2.

5.2 Planning Algorithm
describe automaton AD
. exploited order build plan goal
. given domain.
start defining tree automaton accepts trees define valid
plans planning domain = h, 0 , A, Ri. recall that, according Definition 8,
transition relation R maps state action tuple next states
h1 , 2 , . . . , n = R(, a).
following assume finite set arities compatible domain
D, namely, R(, a) = h1 , . . . , A, D.
Definition 21 (tree automaton planning domain) Let = h, 0 , A, Ri
planning domain let set arities compatible domain D.

tree automaton AD
corresponding planning domain AD = hA, D, , 0 , , 0 i,
h1 , . . . , (, (, a), d) h1 , . . . , = R(, a) > 0, 0 () = 0
.
According Definition 10, (A)-labelled tree obtained plan
domain D. show also converse true, namely, (A)-labelled tree
accepted tree automaton AD
induces plan.
Definition 22 (plan induced tree) Let (A)-labelled tree accepted automaton AD
. plan induced domain defined follows: (0 , 1 , . . . , n ) = finite path p (p) = (0 , a0 )
(1 , a1 ) (n , ) = .
124

fiThe Planning Spectrum One, Two, Three, Infinity

following lemma shows Definitions 10 22 define one-to-one correspondence valid plans planning domain trees accepted automaton
AD
D.
Lemma 14 Let tree accepted automaton AD
let corresponding
induced plan. valid plan domain D, execution tree corresponding
. Conversely, let plan domain let corresponding execution
structure. accepted automaton AD
plan induced .
Proof. lemma direct consequence Definitions 10 22.



define parity tree automaton accepts trees correspond
plans domain satisfy goal g = .. parity tree automaton obtained
combining suitable way tree automaton AE-LTL formula g (Definition 20)
tree automaton domain (Definition 21).
Definition 23 (instrumented tree automaton) Let set arities compatible planning domain D. Let also AD
g = h, D, Q, q0 , , parity tree automaton accepts trees satisfy AE-LTL formula g. parity tree
automaton AD
D,g corresponding planning domain goal g defined follows:

AD,g = hA, D, Q, (q0 , 0 ), 0 , 0 i, h(q1 , 1 ), . . . , (qd , )i 0 ((q, ), (, a), d)
hq1 , . . . , qd (q, , d) h1 , . . . , = R(, a) > 0, 0 (q, ) = (q).
following lemmas show solutions planning problem (D, g) one-to-one
correspondence trees accepted tree automaton AD
D,g .
Lemma 15 Let (A)-labelled tree accepted automaton AD
D,g , let
plan induced domain D. plan solution planning problem
(D, g).
Proof. According Definition 11, prove execution tree corresponding
satisfies goal g. Lemma 14, amounts proving tree satisfies g.
construction, easy check (A)-labeled tree accepted AD
D,g ,

also accepted Ag . Indeed, rD,g : Q accepting run AD
D,g ,

rg : Q accepting run Ag , rg (x) = q whenever rD,g = (q, )
.

Lemma 16 Let solution planning problem (D, g). execution tree
accepted automaton AD
D,g .
Proof. Let execution tree . Lemma 14 know accepted AD
D.
Moreover, definition solution planning problem, know accepted also
AD
g . construction, easy check (A)-labeled tree accepted


AD AD
g , also accepted AD,g . Indeed, let rD : accepting

run AD
let rg : Q accepting run Ag . rD,g : Q

accepting run AD,g , rD,g (x) = (q, ) rD (x) = rg (x) = q.

125

fiPistore & Vardi

consequence, checking whether goal g satisfied domain reduced
problem checking whether automaton AD
D,g nonempty.
Theorem 17 Let planning domain g AE-LTL formula. plan exists
goal g domain tree automaton AD
D,g nonempty.
Proposition 18 parity tree automaton AD
D,g domain = (, 0 , A, R) goal
g = . || 22

O(||)

states parity index 2O(||) .

Proof. consequence Proposition 13 definition automaton AD
D,g .
5.3 Complexity
study time complexity planning algorithm defined Subsection 5.2.
Given planning domain D, planning problem AE-LTL goals g = .
decided time doubly exponential size formula applying
Theorem 1 tree automaton AD
D,g .
Lemma 19 Let planning domain. existence plan AE-LTL goal g = .
O(||)
domain decided time 22
.
Proof. Theorem 17 existence plan goal g domain reduced
emptiness problem parity tree automaton AD
D,g . Proposition 18, parity tree
O(||)

2
automaton AD
|| states parity index 2O(||) . Since assume
D,g 2
domain fixed, Theorem 1, emptiness automaton AD
D,g decided time

22

O(||)

.



doubly exponential time bound tight. Indeed, realizability problem
LTL formula , known 2EXPTIME-complete (Pnueli & Rosner, 1990),
reduced planning problem goal A.. realizability problem one assumes
program environment alternate control evolution system.
precisely, execution 0 , 1 , . . . states decided program
even, environment odd. say given formula realizable
program executions satisfy independently actions
environment.
Theorem 20 Let planning domain. problem deciding existence plan
AE-LTL goal g = . domain 2EXPTIME-complete.
Proof. realizability formula reduced problem checking exis
tence plan goal A. planning domain = {init} ( {p, e}), init, {e}, R ,
with:
R(init, 0 ) = {( 0 , e)}
0

R(init, e) =

0

R((, p), ) = {( , e)}

R((, p), e) =

0

R((, e), e) = {( 0 , p) : 0 }

R((, e), ) =
126

fiThe Planning Spectrum One, Two, Three, Infinity

, 0 .
States (, p) program controls evolution actions 0 .
States (, e) environment controls evolution; nondeterministic action e performed state. Finally, state init used assign initial
move program.
Since realizability problem 2EXPTIME-complete size LTL formula
(Pnueli & Rosner, 1990), planning problem 2EXPTIME-hard size goal
g = .. 2EXPTIME-completeness follows Lemma 19.

remark that, case goals form E., algorithm better
complexity defined. case, plan exists E.
infinite sequence 0 , 1 , . . . states satisfies i+1 R(i , ai )
action ai . is, planning problem reduced model checking problem
LTL formula , problem known PSPACE-complete (Sistla & Clarke,
1985). conjecture that, canonical path quantifiers except E, doubly
exponential bound Theorem 20 tight.
remarks order complexity satisfiability validity problems
AE-LTL goals. problems PSPACE-complete. Indeed, AE-LTL formula
. satisfiable LTL formula satisfiable6 , latter problem
known PSPACE-complete (Sistla & Clarke, 1985). similar argument holds also
validity.
complexity model checking problem AE-LTL recently addressed
Kupferman Vardi (2006). Kupferman Vardi introduce mCTL*, variant
CTL*, path quantifiers memoryful interpretation. show memoryful quantification express (with linear cost) semantics path quantifiers
AE-LTL. example, AE-LTL formula AE. expressed mCTL* formula
AG E . Kupferman Vardi show model checking problem new logic
EXPSPACE-complete, result holds also subset mCTL* corresponds formulas AE.. Therefore, model checking problem AE-LTL finite
path quantifiers also EXPSPACE-complete. best knowledge complexity
model checking AE-LTL formulas (AE) . (EA) . still open problem.

6. Two Specific Cases: Reachability Maintainability Goals
section consider two basic classes goals particularly relevant
field planning.
6.1 Reachability Goals
first class goals reachability goals corresponding LTL formula F q,
q propositional formula. literature planning concentrates
class goals, several works address problem defining plans
different strength kind goals (see, e.g., Cimatti et al., 2003 citations).
6. tree satisfies . paths satisfy , path satisfies seen also
tree satisfies ..

127

fiPistore & Vardi

context AE-LTL, soon player E takes control, immediately achieve
reachability goal possible all. fact control given back player
goal achieved irrelevant. Therefore, significant path quantifiers
reachability goals A, E, AE.
Proposition 21 Let q propositional formula atomic propositions Prop. Then,
following results hold every labelled tree . |= E. F q iff |= EA. F q iff |= EAE. F q
iff |= (EA) . F q. Moreover |= AE. F q iff |= AEA. F q iff |= (AE) . F q.
Proof. prove |= AE. F q iff |= AEA. F q iff |= (AE) . F q. cases
similar.
Let us assume |= AE. F q. Moreover, let p finite path . know p
extended infinite path p0 (p0 ) |= F q. According semantics
LTL, (p0 ) |= F q means node x path p0 q (x). Clearly,
infinite paths contain node x also satisfy LTL formula F q. Therefore,
finite extension p00 p infinite extensions p00 satisfy LTL
formula F q: sufficient take p00 finite extension p contains node x. Since
property holds every finite path p, conclude |= AEA. F q.
proven |= AE. F q implies |= AEA. F q. Theorem 9 know
AEA
(AE)
AE, hence |= AEA. F q implies |= (AE) . F q implies |= AE. F q.
concludes proof.

following diagram shows implications among significant path quantifiers
reachability goals:
(3)
/o /o /o / AE /o /o /o / E
remark three goals A. F q, E. F q, AE. F q correspond, respectively,
strong, weak, strong cyclic planning problems Cimatti et al. (2003).
6.2 Maintainability Goals
consider another particular case, namely maintainability goals G q, q
propositional formula. Maintainability goals properties complementary
properties reachability goals. case, soon player takes control,
violate maintainability goal possible all. fact player E take control
player hence irrelevant, interesting path quantifiers A, E,
EA.
Proposition 22 Let q propositional formula atomic propositions Prop. Then,
following results hold every labelled tree . |= A. G q iff |= AE. G q iff |=
AEA. G q iff |= (AE) . G q. Moreover |= EA. G q iff |= EAE. G q iff |= (EA) . G q.
Proof. proof similar proof Proposition 21.



following diagram shows implications among significant path quantifiers
maintainability goals:
/o /o /o / EA /o /o /o / E
128

fiThe Planning Spectrum One, Two, Three, Infinity

goals A. G q, E. G q, EA. G q correspond maintainability variants strong, weak,
strong cyclic planning problems. Indeed, correspond requiring condition q
maintained evolutions despite nondeterminism (A. G q), condition q maintained
evolutions (E. G q), possible reach state condition
q always maintained despite nondeterminism (EA. G p).

7. Related Works Concluding Remarks
paper defined AE-LTL, new temporal logic extends LTL
possibility declaring complex path quantifiers define different degrees
LTL formula satisfied computation tree. propose use AE-LTL formulas
expressing temporally extended goals nondeterministic planning domains.
defined planning algorithm AE-LTL goals based automata-theoretic
framework: existence plan reduced checking emptiness suitable parity
tree automaton. studied time complexity planning algorithm, proving
2EXPTIME-complete length AE-LTL formula.
field planning, several works use temporal logics defining goals.
approaches (Bacchus & Kabanza, 1998, 2000; Calvanese et al., 2002; Cerrito & Mayer,
1998; de Giacomo & Vardi, 1999; Kvarnstrom & Doherty, 2001) use linear temporal logics
goal language, able express conditions degree goal
satisfied respect nondeterminism execution. Notable exceptions
works described Pistore, Bettin, Traverso (2001), Pistore Traverso (2001)
Dal Lago et al. (2002). Pistore et al. (2001) Pistore Traverso (2001) use CTL
goal language, Dal Lago et al. (2002) define new branching time logic allows
expressing temporally extended goals deal explicitly failure recovery
goal achievement. goal languages, however, path quantifiers interleaved
temporal operators, hence rather different AE-LTL.
field temporal logics, work alternating temporal logic (ATL) (Alur,
Henzinger, & Kupferman, 2002) related work. ATL, path quantifiers
CTL CTL* replaced game quantifiers. Nevertheless, obvious way
expressed formulas form ., path quantifier LTL formula
ATL , expressive logic studied Alur et al. (2002). conjecture
logic ATL incomparable expressiveness.
comments order practical impact 2EXPTIME complexity
planning algorithm. First all, many planning problems expect
complex large domains, goals relatively simple (see, e.g., experimental
evaluation performed Pistore et al. (2001) case planning goals expressed CTL
formulas). cases, doubly exponential complexity algorithm size
formula may bottleneck. larger AE-LTL goals, doubly exponential time
complexity may feasible, noted worst-case complexity.
also note improved algorithms plan synthesis active research area, including
analysis simpler LTL goals (Alur & La Torre, 2004) development improved
automata-theoretic algorithms (Kupferman & Vardi, 2005).
automata-theoretic framework used paper wider applicability AE-LTL goals. interesting direction future investigations application
129

fiPistore & Vardi

framework variants AE-LTL allow nesting path quantifiers,
goals combine AE-LTL propositional temporal operators. would allow,
instance, specify goals compose requirements different strength. simple
example goals (AE. F p)(A. G p), requires achieve condition p strong
cyclic way, maintaining condition q strong way. impossibility define kind
goals is, opinion, strongest limitation AE-LTL respect CTL
CTL*.
Another direction future investigations extension approach proposed
paper case planning partial observability (de Giacomo & Vardi, 1999),
one assumes agent executing plan observe part state
hence choices actions execute may depend part.
also plan explore implementation issues and, particular, possibility
exploiting BDD-based symbolic techniques planning algorithm AE-LTL goals.
cases, techniques shown able deal effectively domains
goals significant complexity, despite exponential worst-case time complexity
problems (Bertoli, Cimatti, Pistore, Roveri, & Traverso, 2001; Pistore et al., 2001).

Acknowledgments
shorter version paper, without proofs, published Pistore Vardi
(2003). authors would like thank Erich Gradel comments reduction
AE-LTL formulas CTL* formulas.

References
Alur, R., Henzinger, T., & Kupferman, O. (2002). Alternating-time temporal logic. Journal
ACM, 49 (5), 672713.
Alur, R., & La Torre, S. (2004). Deterministic generators games LTL fragments.
ACM Trans. Comput. Log., 5 (1), 125.
Bacchus, F., & Kabanza, F. (1998). Planning temporally extended goals. Ann.
Mathematics Artificial Intelligence, 22, 527.
Bacchus, F., & Kabanza, F. (2000). Using temporal logic express search control knowledge
planning. Artificial Intelligence, 116 (1-2), 123191.
Bertoli, P., Cimatti, A., Pistore, M., Roveri, M., & Traverso, P. (2001). MBP: Model
Based Planner. Proc. IJCAI01 workshop Planning Uncertainty
Incomplete Information.
Berwanger, D., Gradel, E., & Kreutzer, S. (2003). upon time West - Determinacy, definability, complexity path games. Prof. 10th Int. Conf Logic
Programming, Artificial Intelligence, Reasoning (LPAR03), pp. 229243.
Calvanese, D., de Giacomo, G., & Vardi, M. (2002). Reasoning actions planning
LTL action theories. Proc. 8th Int. Conf. Principles Knowledge
Representation Reasoning (KR02), pp. 593602.
130

fiThe Planning Spectrum One, Two, Three, Infinity

Cerrito, S., & Mayer, M. (1998). Bounded model search linear temporal logic
application planning. Proc. 2nd Int. Conf. Analytic Tableaux Related
Methods (TABLEAUX98), Vol. 1397 LNAI, pp. 124140. Springer Verlag.
Cimatti, A., Pistore, M., Roveri, M., & Traverso, P. (2003). Weak, strong, strong cyclic
planning via symbolic model checking.. Artificial Intelligence, 147 (1-2), 3584.
Dal Lago, U., Pistore, M., & Traverso, P. (2002). Planning language extended
goals. Proc. 18th National Conf. Artificial Intelligence (AAAI02). AAAI
Press.
Daniele, M., Traverso, P., & Vardi, M. (1999). Strong cyclic planning revisited. Proc.
5th European Conf. Planning (ECP99), Vol. 1809 LNAI, pp. 3548. Springer
Verlag.
de Giacomo, G., & Vardi, M. (1999). Automata-theoretic approach planning temporally extended goals. Proc. 5th European Conf. Planning (ECP99), Vol.
1809 LNAI, pp. 226238. Springer Verlag.
Emerson, E. A. (1990). Temporal modal logic. van Leeuwen, J. (Ed.), Handbook
Theoretical Computer Science, Volume B: Formal Models Semantics. Elsevier.
Emerson, E., & Jutla, C. (1988). complexity tree automata logics programs.
Proc. 29th IEEE Symp. Foundations Computer Science, pp. 328337.
Emerson, E., & Jutla, C. (1991). Tree automata, -calculus determinacy. Proc.
32nd IEEE Symp. Foundations Computer Science, pp. 368377.
Fikes, R., & Nilsson, N. (1971). STRIPS: new approach application theorem
proving problem solving. Artificial Intelligence, 2 (3-4), 189208.
Ghallab, M., Nau, D., & Traverso, P. (2004). Automated Planning: Theory Practice.
Elsevier.
Kupferman, O. (1999). Augmenting branching temporal logics existential quantification atomic propositions. Journal Logic Computation, 9 (2), 135147.
Kupferman, O., & Vardi, M. (2005). Safraless decision procedures. Proc. 46th IEEE
Symp. Foundations Computer Science (FOCS05), pp. 531542. IEEE Computer
Society.
Kupferman, O., & Vardi, M. (2006). Memoryful branching-time logic. Proc.
21th IEEE Symposium Logic Computer Science (LICS 2006). IEEE Computer
Society.
Kupferman, O., Vardi, M., & Wolper, P. (2000). automata-theoretic approach branching time model checking. Journal ACM, 47 (2).
Kvarnstrom, J., & Doherty, P. (2001). TALplanner: temporal logic based forward chaining
planner. Ann. Mathematics Artificial Intelligence, 30, 119169.
Moller, F., & Rabinovich, A. (1999). expressive power CTL*. Proc. 14th
Annual IEEE Symposium Logic Computer Science (LICS99), pp. 360369.
IEEE Computer Science Press.
131

fiPistore & Vardi

Penberthy, J., & Weld, D. (1992). UCPOP: sound, complete, partial order planner
ADL. Proc. 3rd Int. Conf. Principles Knowledge Representation
Reasoning (KR92).
Peot, M., & Smith, D. (1992). Conditional nonlinear planning. Proc. 1st Int. Conf.
AI Planning Systems (AIPS92), pp. 189197. Morgan Kaufmann Publisher.
Pistore, M., Bettin, R., & Traverso, P. (2001). Symbolic techniques planning
extended goals non-deterministic domains. Proc. 6th European Conf.
Planning (ECP01).
Pistore, M., & Traverso, P. (2001). Planning model checking extended goals nondeterministic domains. Proc. 17th Int. Joint Conf. Artificial Intelligence
(IJCAI01). AAAI Press.
Pistore, M., & Vardi, M. (2003). planning specturm one, two, three, infinity.
Proc. 18th IEEE Symposium Logic Computer Science (LICS 2003), pp.
234243.
Pnueli, A., & Rosner, R. (1990). Distributed reactive systems hard synthesize.
Proc. 31st IEEE Symp. Foundation Computer Science, pp. 746757.
Sistla, A., & Clarke, E. (1985). complexity propositional linear temporal logic.
Journal ACM, 32, 733749.
Warren, D. (1976). Generating conditional plans programs. Proc. Summer
Conf. Artificial Intelligence Simulation Behaviour (AISB76), pp. 344354.

132

fiJournal Artificial Intelligence Research 30 (2007) 213-247

Submitted 12/06; published 10/07

Compressed Pattern Databases
Ariel Felner

felner@bgu.ac.il

Department Information Systems Engineering,
Ben-Gurion University Negev
Beer-Sheva, Israel, 85104

Richard E. Korf

korf@cs.ucla.edu

Department Computer Science
University California Los Angeles
Los Angeles, CA, 90095

Ram Meshulam

meshulr1@cs.biu.ac.il

Department Computer Science
Bar-Ilan University
Ramat-Gan, Israel, 52900

Robert Holte

holte@cs.ualberta.ac.ca

Department Computing Science
University Alberta
Edmonton, Canada

Abstract
pattern database (PDB) heuristic function implemented lookup
table stores lengths optimal solutions subproblem instances.
Standard PDBs distinct entry table subproblem instance.
paper investigate compressing PDBs merging several entries
one, thereby allowing use PDBs exceed available memory
uncompressed form. introduce number methods determining
entries merge discuss relative merits. vary domainindependent approaches allow set entries PDB merged,
intelligent methods take account structure problem.
choice best compression method based domain-dependent
attributes. present experimental results number combinatorial
problems, including four-peg Towers Hanoi problem, sliding-tile
puzzles, Top-Spin puzzle. Towers Hanoi, show
search time reduced three orders magnitude using
compressed PDBs compared uncompressed PDBs size.
modest improvements observed domains.

1. Introduction Overview
Heuristic search algorithms A* (Hart, Nilsson, & Raphael, 1968) IDA* (Korf,
1985) find optimal solutions state space search problems. guided cost
function f (n) = g(n) + h(n), g(n) cost reaching node n initial state,
h(n) heuristic function estimates cost reaching goal state node
c
2007
AI Access Foundation. rights reserved.

fiFelner, Korf, Meshulam, & Holte

n. h(n) admissible, means never overestimates actual cost,
algorithms guaranteed find optimal solution path one exists.
Pattern databases admissible heuristic functions implemented lookup tables stored
memory (Culberson & Schaeffer, 1998). best known heuristics number
combinatorial problems. paper investigate idea compressing pattern
database heuristics order improve accuracy heuristics, given amount
memory.
begin describing three different problem domains used paper, order
ground discussion concrete examples.
1.1 Problem Domains
1.1.1 4-peg Towers Hanoi

Figure 1: Five-disc four-peg Towers Hanoi problem
well-known three-peg Towers Hanoi problem consists three pegs n discs
different sizes initially stacked decreasing order size one peg.
task transfer discs initial peg goal peg. top disc
peg moved, larger disc never placed top smaller disc.
three-peg problem, simple recursive algorithm provably returns optimal
solution. idea move n 1 smallest discs intermediate peg, move
largest disc initial peg goal peg, finally move n 1 smallest
discs intermediate peg goal peg.
four-peg Towers Hanoi problem (TOH4), (Hinz, 1997) shown Figure 1,
interesting. recursive algorithm three-peg problem doesnt yield optimal
solutions, two intermediate pegs, dont know priori
distribute n1 smallest discs intermediate pegs optimal solution.
exists deterministic algorithm finding solution, conjecture generates
optimal solution (Frame, 1941; Stewart, 1941), conjecture remains unproven
(Dunkel, 1941). Thus, systematic search currently method guaranteed find
optimal solutions problems given number discs.
1.1.2 Sliding-Tile Puzzles
One classic domains AI literature sliding-tile puzzle. Three common
versions puzzle 3x3 8-puzzle, 4x4 15-puzzle 5x5 24-puzzle.
consists square frame containing set numbered square tiles, empty position
called blank. legal operators slide tile horizontally vertically
214

fiCompressed Pattern Databases

1

2

3

5

1

2

3

4

6

7

8

9

1

2

4

5

6

7

10 11 12 13 14

3

4

5

8

9

10 11

15 16 17 18 19

6

7

8

12 13 14 15

20 21 22 23 24

Figure 2: 8-, 15- 24-puzzle goal states
adjacent blank blank position. problem rearrange tiles
random initial configuration particular desired goal configuration. 8-puzzle
contains 181,440 reachable states, 15-puzzle contains 1013 reachable states,
24-puzzle contains almost 1025 reachable states. traditional goal states puzzles
shown Figure 2.
1.1.3 Top-Spin Puzzle

Reverse
circle
18

19 20 1

2

3
4

17
16

5

15

6

14

7
13
12 11 10 9

8

Figure 3: (20,4)-Top-Spin Puzzle
(n,r)-Top-Spin puzzle n tokens arranged ring. ring tokens
shifted cyclically clockwise counterclockwise. tokens pass reverse circle
fixed top ring. given time r tokens located inside reverse
circle. tokens reversed (rotated 180 degrees). task rearrange
puzzle tokens sorted increasing order. (20,4) version puzzle
shown figure 3 goal position tokens 19, 20, 1 2 reverse circle
reversed. encoding puzzle N operators, one clockwise
circular shift length 0 . . . N 1 entire ring followed reversal/rotation
tokens reverse circle. operator cost one. encoding
analyzed (Chen & Skiena, 1996). Practically, puzzle implemented cyclic
215

fiFelner, Korf, Meshulam, & Holte

buffer operator reverses set r consecutive tokens1 . Note n!
different possible ways permute tokens. However, since puzzle cyclic,
relative location different tokens matters, thus (n 1)! different
unique states.
1.2 Pattern Database Heuristics
Heuristics typically implemented functions states domain nonnegative number. example, well-know heuristic sliding-tile puzzles
Manhattan distance. computed determining tile minimum distance
grid units must travel reach goal location, summing values
tiles except blank. lower bound optimal solution length, tile
must move least Manhattan distance, move moves one tile.
Pattern databases (PDBs) heuristics form lookup tables. pattern database stores memory cost optimal solution instance subproblem
original problem. costs used admissible heuristics original
problem. PDBs used lower bounds combinatorial puzzles (Culberson &
Schaeffer, 1998; Korf, 1997; Korf & Felner, 2002; Felner, Korf, & Hanan, 2004a; Felner,
Meshulam, Holte, & Korf, 2004b), multiple sequence alignment (Zhou & Hansen, 2004; McNoughtton, Lu, Schaeffer, & Szafron, 2002; Schroedl, 2005; Edelkamp & Kissmann, 2007),
vertex cover (Felner et al., 2004a), planning problems (Edelkamp, 2001).
example, consider four-peg Towers Hanoi problem 15 discs.
ignore 15 discs, 415 = 230 different possible configurations
15 discs. imagine array contains entry possible configuration
15 discs, whose value exact number moves required optimally solve
corresponding 15-disc problem instance. Note doesnt matter discs choose,
since absolute sizes dont matter. long different sizes
relative size matters. entry fit byte memory, table occupy exactly
one gigabyte memory. example PDB.
build PDB, execute complete breadth-first search starting 15 discs
goal peg. configuration encountered first time, store search
depth corresponding entry PDB. PDB given size built once,
reused solve multiple problem instances goal state.
use PDB heuristic solve four-peg Towers Hanoi problem
15 discs. state encountered search, look configuration
given subset 15 discs PDB, use stored value heuristic full
state. Since value number moves needed get subset 15 discs
goal peg, lower bound total number moves needed get discs
problem goal peg.
1.3 Compressed Pattern Databases
size PDB number entries contains. general, larger PDB is,
accurate is, efficient search algorithm using heuristic is.
1. physical puzzle, first rotate ring tokens reverse circle.

216

fiCompressed Pattern Databases

example, solving TOH4 problem 20 discs, values PDB based
20 discs accurate based 15 discs. drawback large PDBs,
however, amount memory consume.
main idea paper compress PDBs large fit memory
uncompressed form size fit memory. compressing done
partitioning original PDB groups entries. group entries original
PDB mapped single entry compressed PDB. order preserve admissibility,
value stored compressed PDB minimum among values
group original PDB.
example, given PDB four-peg Towers Hanoi problem based 20 discs,
divide discs 15 largest discs 5 smallest discs. partition
PDB entries 415 groups entries based positions 15 largest discs.
group 45 = 1024 different entries correspond different
positions 5 smallest discs. compressed PDB store one entry
groups. entry compressed PDB correspond different configuration
15 largest discs, value minimum value configurations
5 smallest discs original PDB, order preserve admissibility.
Note general, values compressed PDB much larger hence
accurate corresponding values simple 15-disc PDB, despite fact
two databases size. reason entry simple 15disc PDB number moves needed solve corresponding 15-disc problem,
whereas entry compressed PDB minimum number moves needed
solve instance 20-disc problem 15 largest discs one particular
configuration.
1.4 Overview
primary questions address paper make best use given
amount memory compressed PDBs, determine entries PDB
compress. Specifically make following contributions:
introduce number methods compressing PDBs. methods vary
general methods constrained methods. general methods often result
significant loss information, methods rely structure
underlying problem space necessarily domain specific.
show best compression methods often domain dependent, provide
guidelines choosing promising method given domain. Experiments
4-peg Towers Hanoi, sliding-tile puzzles Top-Spin puzzle show
given amount memory search effort many times reduced
using compressed PDBs using uncompressed PDB size.
also describe methods generating PDBs using external memory compressing size available memory.
paper organized follows. first provide definitions used throughout paper. consider build PDBs, particular, build com217

fiFelner, Korf, Meshulam, & Holte

pressed PDBs original PDB wont fit memory. discuss different
compressing methods. Next, present experimental results Towers Hanoi,
sliding-tile puzzles Top-Spin Problem. Finally offer conclusions.
preliminary version paper appeared earlier (Felner et al., 2004b).

2. Definitions
begin providing abstract characterization search spaces combinatorial problems, sufficient structure define PDBs associated constructs. definitions
used throughout paper.
2.1 Combinatorial Problems Vectors State Variables
problem space usually described abstractly set atomic states, set
operators map states states. corresponds labeled graph, called problemspace graph. addition, specific problem instance problem space together
particular initial state (set of) goal state(s). task find optimal path
initial state goal state.
state combinatorial problem described vector state variables,
assigned particular value. domains studied paper, variables
correspond different objects problem, values correspond different
locations occupy. example, Towers Hanoi problem,
variable disc, value indicates peg disc on. slidingtile puzzles, variable physical tile one blank, value
indicates position occupied tile. Top-Spin puzzle, variable
token, whose value indicates position. convenience, paper, often
refer variables objects, values locations, general latter
terms simply convenient synonyms variables values, respectively. size
problem space number distinct legal combinations value assignments
variables reachable given initial state.
combinatorial problem permutation problem number values equals
number variables, value assigned one variable. example,
Top-Spin sliding-tile puzzles permutation problems location
occupied one object. Towers Hanoi permutation problem
peg hold one disc.
operator formulation partial function state vector state vector.
operator changes values variables. Note number variables
values changed might different different domains even different
operators domain. Towers Hanoi, value one variable
changed operator, since one disc moves time. sliding-tile puzzles
two variables change values operator, one physical tile blank
exchange locations move. Top-Spin, values four variables changed since
four tokens change locations.
goal specified state set states. permutation problems,
sliding-tile puzzles Top-Spin, goal state usually canonical state object
218

fiCompressed Pattern Databases

location i. standard goal state Towers Hanoi discs
single goal peg, thus state variables value.
2.2 Pattern Databases
Given vector state variables, set operators, subset variables defines
subproblem assign values variables subset, called pattern variables,
values remaining variables treated dont cares. example,
Towers Hanoi, subproblem would include subset discs.
pattern specific assignment values pattern variables. example,
pattern might particular configuration subset discs.
pattern space set different reachable patterns given subproblem.
example, pattern space four-peg Towers Hanoi subproblem P pattern
variables includes different possible assignments P discs pegs,
size 4P . permutation problems n elements P pattern variables, pattern
space typically n (n 1) . . . (n P + 1) states.
state original state space projected onto pattern pattern space
considering pattern variables, ignoring variables. refer set
states project pattern states pattern.
goal pattern projection goal state onto pattern variables. Multiple goal
states may give rise multiple goal patterns, single goal pattern.
edge two different patterns p1 p2 pattern space
exist two states s1 s2 original problem, p1 projection
s1 , p2 projection s2 , operator original problem space
connects s1 s2 .2 effect operator patterns called pattern move.
distance two patterns pattern space number edges pattern
moves shortest path two patterns.
distance two patterns p1 p2 pattern space therefore lower
bound shortest distance pair states s1 s2 p1
projection s1 p2 projection s2 .
pattern database (PDB) lookup table includes entry pattern
pattern space. value stored pattern distance pattern
pattern space goal pattern. PDB value stored given pattern therefore
admissible heuristic states project onto pattern.

3. Building Pattern Databases
general, PDB built running breadth-first search pattern space backwards
goal pattern entire pattern space spanned. However, since operators
problem apply states original problem, patterns directly,
building PDB slightly different different domains.
Towers Hanoi problem, simply ignore non-pattern discs. words,
P discs pattern, simply search Towers Hanoi problem space
P discs. state, keep track depth breadth-first search.
2. sometimes called edge homomorphism.

219

fiFelner, Korf, Meshulam, & Holte

sliding-tile puzzles, keep track blank position, even
included pattern, order determine whether move legal not. Thus,
state search uniquely determined positions pattern tiles
blank. equivalent problem space includes tiles,
non-pattern non-blank tiles indistinguishable other.
original application PDBs sliding-tile puzzles (Culberson & Schaeffer,
1998), moves counted PDB values. drawback approach
multiple PDBs, way combine values without sacrificing admissibility
take maximum value. Additive pattern databases (Korf & Felner, 2002) allow us
sum values multiple pattern databases without violating admissibility, much
effective applicable. order construct additive pattern databases
sliding-tile puzzles, count moves pattern tiles, ignore moves
non-pattern tiles. adopt approach here.
Top-Spin, goal put tokens correct cyclic order, representation linear rather cyclic. reconcile two different representations,
always keep token one location one. operator moves token one, immediately
followed cyclic shift tokens restore token one location one, additional cost. pattern doesnt include token one, must keep track position
token one, order correctly implement shifts. state, store
number moves involve least one pattern token, either reversal,
subsequent shift restore token one position one. example, reversal changes
position token one, counted pattern move even reversal doesnt
include pattern tokens, pattern tokens move subsequent cyclic
shift tokens.
pattern first generated, number pattern moves needed reach
state stored corresponding entry PDB. PDB needs built
specific goal state.
3.1 Mapping Patterns PDB Indices
PDBs sometimes implemented sophisticated data structures lexicographic
trees (Felner et al., 2004a) octrees (McNoughtton et al., 2002). addition, symbolic
pattern databases (Edelkamp, 2002) based binary decision diagrams (BDDs) (Dunkel,
1992). Nevertheless, PDBs commonly implemented arrays entries,
storing heuristic value specific pattern. Thus, simplicity, paper assume
PDBs implemented arrays.
save memory, want avoid store patterns along
heuristic values. done representing pattern unique index
PDB. particular mapping patterns indices domain specific.
example, state Towers Hanoi problem uniquely represented
specifying peg disc on, since discs peg must sorted
order size. four-peg problem, peg specified two bits, complete
problem state uniquely specified string 2n bits, n number
discs. Furthermore, every bit string represents legal state problem.
220

fiCompressed Pattern Databases

permutation problems, two obvious ways store PDB k variables
- sparse mapping compact mapping.
sparse mapping - simplest organization k-dimensional array,
dimension range 0 n 1. individual pattern mapped
table taking value pattern variable separate index array.
example, pattern three variables (X,Y,Z), whose values (2,1,3)
respectively, would mapped array element A[2][1][3]. total size
array configurations k elements nk . called sparse mapping.
advantage sparse mapping simple implement indices
efficiently computed. disadvantage efficient terms
space, since wastes entries two equal indices, since entries
correspond valid configuration.
compact mapping - Another method indexing PDBs permutation problems
called compact mapping. particular, permutation k elements
n possible locations mapped bijectively unique index range 0
n n 1 . . . n k + 1. One mapping maps permutation
index lexicographic ordering permutations. example, assuming
k = n = 3, permutation (2 1 3) mapped third index, since preceded
(1 2 3) (1 3 2) lexicographic order. advantage compact mapping
waste space. disadvantage computing indices
complex. (Myrvold & Ruskey, 2001) provide linear-time algorithms bijective
mappings permutations integers, (Korf & Shultze, 2005) provide
linear-time algorithms index permutation represents position
lexicographic order. least experiments (reported below), even
advanced mapping algorithm, access time sparse mapping faster
compact mapping counterpart.
worth noting memory savings compact mapping sparse
mapping decreases number variables domain increases beyond number
elements PDB. example, consider 6-tile PDB 24 Puzzle. Sparse mapping
requires 256 = 244 106 entries, compact mapping uses 25 24 . . . 20 =
128 106 entries. Indeed, since memory savings modest, sparse mapping
simpler often used implement 6-tile PDBs (Korf & Felner, 2002; Felner
et al., 2004a; Felner, Zahavi, Holte, & Schaeffer, 2005; Zahavi, Felner, Holte, & Schaeffer,
2006). Similarly, sparse mapping also used implement 5-tile PDBs 35
puzzle (Felner et al., 2004a).
3.2 Building Large Pattern Databases
Compressed PDBs used isnt sufficient memory store uncompressed
PDBs. raises question generate compressed PDB without exhausting
memory first place.
Consider PDB four-peg Towers Hanoi problem example. Since state
uniquely represented bit string index length 2n, heuristic values
221

fiFelner, Korf, Meshulam, & Holte

stored. use unsigned character array, store values 255 one byte,
sufficient maximum number moves needed solve problem
18-discs (Korf, 2003). Thus, 15-disc PDB, PDB compressed size 15-disc
PDB, would occupy 415 bytes, gigabyte memory. 16-disc PDB would need four
gigabytes, however. Given machine two gigabytes memory, example,
generate 16-disc PDB compressed size 15-disc PDB?
generate PDB, must perform complete breadth-first search 16-disc
problem space, starting standard goal state. state generated, largest
15 discs used index PDB, entry empty, search depth
stored. breadth-first search normally implemented first-in first-out queue
nodes generated, yet expanded. Initially, goal state placed
queue, step remove expand node head queue,
append children tail queue. keep track search depth
placing marker queue nodes successive depths. maximum size
queue determined maximum number nodes depth search.
example, 16-disc problem, number 162, 989, 898 nodes depth 134 (Korf,
2003). Since state 16-disc problem stored 32 bits, queue requires
651, 959, 592 bytes, 622 megabytes memory.
order breadth-first search terminate, however, able detect
whether encountered particular state before. efficient way
store bit array, one bit state, initialized zeros. Whenever state
first encountered, corresponding bit set one. Whenever generate node,
check bit, discard node bit already set one. 16-disc problem
need 416 bits, 512 megabytes array.
622 megabytes queue, plus 512 megabytes bit array, one gigabyte
pattern database exceeds capacity two gigabyte machine. cant use
PDB replace bit array, PDB entry represents four different states
16-disc problem, separately detectable.
case compressing 16-disc PDB, solution simple. Since breadth-first
search queue FIFO, accesses sequential, efficiently stored
magnetic disk instead memory. simple implementation keep two different files,
one nodes current depth, nodes next depth. first file
read sequentially, children appended tail second file. first
file exhausted end current search depth, second file becomes new
first file, another file created children next depth. Moving queue
disk creates enough space store bit array PDB memory.
Unfortunately, wont work compressing larger PDBs. example, complete
breadth-first search 17-disc problem require two megabytes bit
array. bit array cannot stored disk, accessed randomly, random
access byte disk requires average 5 milliseconds latency.
Techniques delayed duplicate detection developed performing large
breadth-first searches disk, without storing bit state memory (Munagala &
Ranade, 1999; Korf, 2003, 2004; Korf & Shultze, 2005). key idea immediately
check node see previously generated, delay duplicate detection
large numbers duplicates eliminated sequentially accessing nodes
222

fiCompressed Pattern Databases

disk. Using techniques, complete breadth-first searches performed
four-peg Towers Hanoi problem 22 discs (Korf & Felner, 2007).
Breadth-first search delayed duplicate detection performed using relatively
little memory, allowing compressed PDB built memory time. However,
technique efficient memory. Thus, alternative, build
compressed PDB two phases.
first phase performs breadth-first search disk, without compressed PDB
memory. phase, state expanded, write another disk file
ordered pair consisting index state compressed PDB, followed
depth breadth-first search. file simply linear list pairs,
written sequentially. Note depths file sorted order.
second phase, build compressed PDB memory, sequentially reading
file. ordered pair, look index PDB. empty, store
corresponding depth PDB, full, simply ignore ordered pair.
Finally, write compressed PDB disk use future searches, delete file
ordered pairs. scheme allows us use almost memory breadth-first
search, regardless size compressed PDB.

4. Compressing Pattern Databases
previous studies, PDBs one entry pattern pattern space.
section, describe different methods compressing PDBs merging number
PDB entries single entry. order preserve admissibility, merged entry
store minimum value entries merged, consequent loss information
original entries larger values minimum.
idea compress large tables smaller size merging several entries together
suggested past outside AI community, e.g., form bit-state
hashing (Bloom, 1970) form hash compaction (Stern & Dill., 1995).
ideal compression scheme would group together entries value.
would preserve information, result PDB whose size number
distinct values original PDB. course, almost impossible achieve
practice.
compress PDB factor k, typically partition entire pattern space
M/k sets k patterns each, size original PDB. compressed
PDB contain one entry set. key making method effective
values stored original PDB k entries close one another
possible minimize resulting loss information. One questions addressed
paper identify PDB entries similar values merged.
4.1 Compressing Nearby Patterns
effective heuristic identify PDB entries similar values compress entries
correspond patterns close together pattern space. Assume two
patterns p1 p2 close pattern space, meaning distance
small. Furthermore, assume operators reversible.
distances p1 goal pattern p2 goal pattern (i.e., PDB values)
223

fiFelner, Korf, Meshulam, & Holte

also similar. formally:
(d(p1 , p2 ) = c) = (|P DB(p1 ) P DB(p2 )| c).
two patterns compressed entry guaranteed loss
information c moves. Therefore, would like compress PDB
patterns mapped entry close pattern space.
provide number different methods compressing PDBs. general
methods often result significant loss information, methods rely
structure underlying problem space necessarily domain-specific.
4.2 Compression Based General Mapping Functions

Regular PDB

0
1
2

compressed PDB

Regular PDB

6
6

3

5
4

4
5

3
3

0 5
1 3

Compress DIV 3

0
1

6
6

2
3

5
4

4
5

3
3

compressed PDB

0 3
1 3

Compress MOD 3

Figure 4: Compressed pattern database
easiest way compress PDB use general function maps exactly k
original patterns compressed entry. compresses PDB entries
compressed PDB M/k entries. Two examples functions mapping indices
original PDB compressed PDB are:
Compressed index(i) = DIV k
Compressed index(i) = OD k
DIV integer division k, MOD remainder division k.
advantage mapping functions general, thus PDB size
compressed fit amount available memory.
Figure 4 shows two ways compress PDB size 6 factor 3
compressed PDB size 2. Note values specific PDB figure locally
correlated indices. Therefore, easy see case DIV operator
better MOD operator since compresses highly correlated values
therefore resulting loss information smaller.
challenge build PDB entries similar indices come
patterns close pattern space. values locally correlated.
224

fiCompressed Pattern Databases

Given locally correlated values, better compress DIV operator, rather
compressing arbitrary set k entries. shown below, many domains
possible build PDB locally correlated entries correspond nearby patterns.
4.3 Compression Based Individual Variables
compute PDB, use function map state index PDB,
uniquely represents corresponding pattern. Many functions map values
particular variables particular bits index. example, described above,
natural representation state n-disc four-peg Towers Hanoi problem
bit string 2n bits. representation, pairs bits represent locations different
discs. true sparse representation described permutation problems, different indices multi-dimensional array encode locations different
tiles tokens. situation little complex compact representation
permutation problems, principle applies.
compress PDBs, map indices original PDB indices
compressed PDB ignoring certain bits. bits correspond particular variables,
effect compressing entries ignoring values variables.
operators problem space change values small number variables,
patterns differ variables tend close together pattern
space, distances goal also tend similar. Thus, compressing
entries loss information small.
compact sparse mappings described calculate index
PDB according predefined order variables. Assume last variable
order q different possible values. sparse mapping permutation problems
q = n, compact mapping q = n P + 1, n total number
variables, P number pattern variables. divide index q,
compressing entries differ value last variable. problems
means set entries compressed together, pattern objects
last one located location. example, patterns indexed
P DB[a][b][c][d] compressed COM P RESSED P DB[a][b][c]. disadvantage
forced compress factor n sparse mapping case, nP +1
compact mapping case, even doesnt exactly fit available memory.
idea compressing last variable generalized compressing last two
variables. compression factor would n, n2 , n3 etc. sparse mapping,
n P + 1, (n P + 1) (n P + 2), (n P + 1) (n P + 2) (n P + 3) etc.
compact mapping. Thus, method may achieve high correlation values
compressed entries, allows compression certain values.
4.3.1 Comparing Compressed Uncompress PDBs Size
denote uncompressed PDB set P variables P DBP , similarly
uncompressed PDB P C variables P DBP C . denote PDB P variables
compressed C variables CP DBP/C . provide following two propositions
comparing P DBP C CP DBP/C .
1. size CP DBP/C equal size P DBP C .
225

fiFelner, Korf, Meshulam, & Holte

Proof: easy see size n|P C| using sparse mapping,
(n (n 1) (n 2) . . . (n |P | + |C| + 1)) using compact mapping.
2. Assume P set variables C P . state search
space CP DBP/C (s) P DBP C (s).
Proof: mappings based P C variables. However,
P DBP C completely ignores C variables, CP DBP/C contains minimum values
P DBP combinations C variables.
Thus, given memory size , PDB larger compressed individual variables size least accurate usually accurate uncompressed
PDB size variables.
4.4 Compressing Cliques


G

d+1

Figure 5: Cliques PDBs

Suppose given set patterns form clique pattern space. means
patterns set reachable one move pattern space.
Thus, PDB entries nodes differ one another one,
assuming operators reversible. value d, rest
value + 1 shown Figure 5. worthwhile compress cliques pattern
space since loss information guaranteed one move. identify
general structure q entries PDB represent clique size q, map
q patterns one entry.
existence cliques pattern space domain dependent. Furthermore,
take advantage them, need compression function map members clique
index compressed PDB. conditions exist problem
spaces, exist domains considered.
combinatorial problems operators move one object time,
Towers Hanoi standard sliding-tile puzzles, cliques often represent states
differ location single object. Therefore, compression based object (or
variable) amounts compressing cliques practice. coincidence necessarily
occur general. shown below, Top-Spin, patterns differ
location one object cliques, domain two compression methods
coincide.
Compressing cliques size q done following two ways:
lossy compression : Store minimum value q entries. admissibility
heuristic preserved loss information one move.
226

fiCompressed Pattern Databases

lossless compression: Store minimum value q entries. Assume
value d. Store also q additional bits, one entry clique, indicates
whether entrys value + 1. preserves information
original PDB, usually require less memory.
idea compressing cliques generalized set z nodes diameter
r. words, pair nodes within set least one connecting path
consisting r fewer edges. clique special case r = 1. compress
set nodes one entry taking minimum entries lose r
moves. Alternatively, lossless compression need additional z log(r + 1) bits
indicate exact value. size entry b bits beneficial terms
memory use lossless compression sets nodes diameter r long
log(r + 1) < b.
4.5 Inconsistency Compressed Heuristic
admissible heuristic h consistent two states, x y, |h(x)h(y)| dist(x, y)
dist(x, y) shortest path x problem space. particular,
neighboring states h values two states differ one move. admissible
heuristic h inconsistent least one pair nodes x y, |h(x) h(y)| > dist(x, y).
Compressed PDBs inconsistent since loss information different
different states. example, let x neighboring states (with edge cost
1) respectively mapped patterns lines 2 3 left
frame figure 4. original heuristics consistent (5 4 respectively)
compressed heuristics inconsistent (5 3). Pathmax (PMX) one approach
correcting inconsistent heuristics (Mero, 1984). propagates heuristic values
parent node p child c follows. h(p) dist(p, c) lower bound dist(c, Goal)
therefore used instead h(c) larger. new approach handling
inconsistent heuristics called bidirectional pathmax (BPMX) (Felner et al., 2005; Zahavi,
Felner, Schaeffer, & Sturtevant, 2007). generalizes PMX BPMX, heuristic
values propagated directions order increase heuristic values nodes
neighborhood. Preliminary results applying BPMX compressed PDBs show
cases small reduction number generated nodes achieved.
present experimental results obtained compressed pattern databases
example domains.

5. 4-peg Towers Hanoi Problem (TOH4)
state space TOH4 many small cycles, meaning many paths
pair states. example, move disc twice row, achieve
effect single move disc. another example, move disc
peg peg B, another disc peg C peg D, applying two moves
opposite order effect. forbid moving disc twice
row, apply commutative operators one order, get branching factor 3.766.
7-disc problem, optimal solution depth 25 moves, complete search
depth generate 3.76625 nodes. However, 47 = 16, 384 unique states.
227

fiFelner, Korf, Meshulam, & Holte

Thus, depth-first search, IDA*, generate enormous numbers duplicate
nodes, hopelessly inefficient domain.
Thus, order search domain used Frontier-A* (FA*), modification
A* designed save memory (Korf, Zhang, Thayer, & Hohwald, 2005). FA* saves
Open list deletes nodes memory expanded. order
keep regenerating Closed nodes, node Open list, FA* stores
operators lead Closed nodes, expanding node operators
used.
5.1 Additive Pattern Databases TOH4
applicability PDB heuristics TOH4 first shown (Felner et al., 2004a).
Consider 16-disc problem. build PDB ten largest discs including
entry 410 legal patterns discs. value entry
minimum number moves required move ten discs corresponding positions
goal peg, assuming discs problem. problem-solving
search, given state 16-disc problem, compute index corresponding
ten largest discs, look value configuration PDB. value
admissible heuristic complete 16-disc problem, solution 16-disc
problem must move largest ten discs goal peg, addition smallest six
discs
similar PDB built six smallest discs. Values ten-disc PDB
six-disc PDB added together get admissible heuristic value
complete state. reason complete solution must move discs
goal peg. Furthermore, move moves one disc, PDB values two
subproblems count moves respective pattern discs. Therefore, sum
PDB values two disjoint sets discs lower bound number moves needed
solve original problem. idea additive PDBs first introduced (Korf &
Felner, 2002) sliding-tile puzzles. deeper analysis additive PDBs provided
by(Felner et al., 2004a).
Note PDB based n discs contain exactly values largest n
discs, smallest n discs, set n discs. reason matters
discs different sizes, absolute sizes. Furthermore, PDB
discs also contains PDB n discs, n < m. look pattern n discs, simply
assign n remaining discs goal peg, look resulting pattern
m-disc PDB. Thus, practice need single PDB largest number
discs group partition. case, ten-disc PDB contains PDB
largest ten discs PDB smallest six discs. general, effective
heuristic based partitioning discs groups maximize size largest
group, subject available memory. largest PDB use machine
gigabyte memory 14 discs. 414 entries, one byte per entry occupies
256 megabytes. rest memory used Open list FA*.
Given PDB 14 discs, two ways use 16-disc problem. first
called static partitioning. method, statically partition discs one group
14 discs remaining 2 discs, use partition nodes
228

fiCompressed Pattern Databases

Heuristic
Static 13-3
Static 14-2
Dynamic 14-2

Path
161
161
161

Avg h
72.17
87.04
93.46

Nodes
134,653,232
36,479,151
12,827,732

Seconds
48.75
14.34
21.56

Table 1: Static vs Dynamic Partitioning 16-disc problem
search. method called dynamic partitioning. state search,
compute 16 15/2 = 120 different ways dividing discs groups 14 2,
look PDB values pair, sum two values, return maximum
overall heuristic value. Here, exact partitioning disjoint sets discs
dynamically determined state search. Table 1, taken (Felner et al.,
2004a), compares static partitioning dynamic partitioning solving standard
initial state 16-disc TOH4. row corresponds different PDB setting.
static partitions divide discs large group largest discs smaller group
smallest discs. columns provide optimal path length, average heuristic
value PDB, number generated nodes amount time taken solve
standard initial state. 14-2 split much better 13-3 split since 14-disc PDB
much informed 13-disc PDB. 14-2 split, dynamically partitioned
heuristic accurate, search generates fewer nodes, therefore FA* requires less
memory, takes longer run due multiple heuristic calculations state.
Static partitioning simpler implement, consumes much less time per node,
generates nodes dynamic partitioning, thus occupying memory. Static
dynamic partitioning apply domain additive PDBs apply.
5.2 Compressed Pattern Databases TOH4
explained above, states TOH4 represented bit strings, pairs
adjacent bits represent positions particular discs. Therefore, compressing PDBs
easy. example, smallest disc represented least significant two
bits, compression based smallest disc accomplished right shift two
bits bit string. Note logically equivalent DIV 4. refer
compressing smallest disc.
practice, compressing smallest disc amounts compressing cliques domain.
TOH4, largest cliques size four, since smallest disc always move among
four pegs without moving larger discs. Thus, store PDB P discs
table size 4P 1 , instead 4P , compressing four states smallest disc
one entry.
compressed PDB, one entry configuration P 1
largest discs. Lossy compression would store minimum value four entries
original PDB correspond entry compressed PDB, lose one
move entries. Alternatively, lossless compression would store four additional
bits entry compressed PDB, indicate location smallest disc
whether value minimum value one greater.
229

fiFelner, Korf, Meshulam, & Holte

Heuristic
Static 14+2
Static 13+3
Static 12+4
Static 11+5

h(s)
116
102
90
74

Avg h
87.04
72.17
59.01
47.32

Nodes
36,479,151
134,653,232
375,244,455
> 462,093,281

Time
14.34
54.02
184.62
> 243.15

Mem
256M
64M
16M
4M

Table 2: Solving 16 discs without compression
generalized compressing smallest two (or more) discs. fix
position largest P 2 discs, consider 16 different configurations two
smallest discs. form set nodes diameter three. Thus, compress
16 entries one entry, lose three moves state. Alternatively,
lossless compression add 2 16 = 32 bits one byte entry compressed
PDB, total five bytes, store exact values, compared 16 bytes
uncompressed PDB.
5.3 Experiments 16-disc 4-peg Towers Hanoi
provide experimental results various compressing methods 16-disc
4-peg Towers Hanoi problem. results solving standard version
problem, moving discs one peg another. optimal solution
problem 161 moves long. Unless stated otherwise, experiments paper
conducted 2.4Ghz PC one gigabyte main memory.
5.3.1 Uncompressed PDBs Different Sizes
comparison purposes, Table 2 shows results uncompressed PDBs built static
partitioning 14 + 2, 13 + 3, 12 + 4 11 + 5. first column shows heuristic
used. case, larger group contained largest discs. second column
shows heuristic value initial state. next column average heuristic
value entries larger PDB (the 14-disc PDB, 13-disc PDB etc). next
columns present number generated nodes, amount time seconds,
amount memory needed megabytes larger PDB, optimally solve 16-disc
problem. werent able solve problem 11 + 5 heuristic running
memory Open list.
5.3.2 Compressing Largest Discs
explained above, domain compressing cliques identical compressing
smallest disc. complementary method compress largest discs. implementation smallest discs represented least significant bits larger discs
represents significant bits. particular representation, compressing
largest z discs accomplished masking corresponding 2z bits.
logically equivalent taking representation MOD 4z, largest discs represented
significant bits.
230

fiCompressed Pattern Databases

Discs
0
.5
1
1.5
2
2.5

h(s)
116
101
100
85
84
69

Avg h
87.04
80.55
72.17
66.46
59.01
53.94

Nodes
36,479,151
70,433,127
285,190,821
410,850,034
791,374,842
1,086,889,788

Time
14.34
28.69
143.78
269.55
543.10
776.22

Mem
256M
128M
64M
32M
16M
4M

Table 3: Solving 16 discs 14-2 PDB 14-disc PDB compressed based
large discs

Table 3 presents results solving 16-disc TOH4 problem compressing largest
discs. statically divided discs two groups. largest fourteen discs define
14-disc PDB. smallest two group separate PDB
42 = 16 entries. compute heuristic state, values 2-disc PDB
14-disc PDB added. different rows table correspond different degrees
compression 14-disc PDB. 2-disc PDB occupies 16 entries hence
need compress it.
first column shows number largest discs compressed. first row
represents compression. whole numbered rows based masking bits
used represent disc. fractional numbers based masking one two
bits used represent disc. example, row 1.5 first column based
masking bits largest disc, significant bit two bits
next largest disc. rest columns format Table 2.
table clearly shows running time increases significantly compressing
largest discs. reason locations largest discs large impact
PDB values. Thus, values compressed correlated
other, great deal information lost. provides evidence claim
values uncorrelated compressed.
Comparing Table 3 Table 2 shows compressing largest discs performs worse
PDB similar size without compression. example, 64 megabytes memory
better solve problem simple PDB 13 discs plus small PDB 3 discs
(2nd line Table 2), 14-disc PDB compressed largest disc, plus small
PDB 2 discs (3rd line Table 3). Thus, compressing largest discs beneficial
TOH4.3
231

fiFelner, Korf, Meshulam, & Holte

Discs
0
1
2
3
4
5
6
7
8
9
1 lls

h(s)
116
115
113
111
110
103
99
98
96
75
116

Avg h
87.04
86.48
85.67
84.45
82.74
80.85
78.54
74.81
68.34
62.71
87.04

r
0
1
3
5
9
13
17
25
33
41
0

Nodes
36,479,151
37,964,227
40,055,436
44,996,743
45,808,328
61,132,726
76,121,867
97,260,058
164,292,964
315,930,865
36,479,151

Time
14.34
14.69
15.41
16.94
17.36
23.78
33.72
36.63
67.59
155.22
15.87

Mem
256M
64M
16M
4M
1M
256K
64K
16K
4K
1K
96M

Table 4: Solving 16 discs 14-disc PDB compressed small discs
5.3.3 Compressing Cliques Smallest Discs
Table 4 presents results 14-2 static partitioning 16 discs, compressing
14-disc PDB smallest discs. representation compression based smallest
z discs accomplished masking left 2z bits. logically equivalent
performing MOD 4z. different rows table correspond compressing
14-disc PDB different numbers discs. rows represent lossy compression, except
last row represent lossless compression (denoted lls). first row Table
4 complete 14-disc PDB compression. second row corresponds
compressing smallest 14 largest discs. case, 14-disc PDB contains
413 entries correspond different possible configurations 13 largest discs.
entries, store minimum four possibilities smallest disc.
row corresponds compressing cliques since four possible positions smallest
disc reached one another single move. third row compresses
two smallest discs 14 largest storing minimum 16 possibilities single
entry on.
important result compressing PDB several orders
magnitude, information preserved. example, compressing five smallest
14 largest discs reduces memory factor 45 = 1024, increased
search effort less factor two number generated nodes
time solve problem. PDB compressed factor 49 = 262, 144,
search effort increased factor ten.
Comparing first four lines tables 2 4 shows TOH4, compressing
larger PDB smaller size smallest discs much better original PDB
3. contradict equation 2 section 4.3.1. equation dealt configuration
compressed uncompressed PDBs indexed variables. case, however,
compared compressed PDB indexed discs 2-14 (where disc 1 compressed)
uncompressed PDB indexed discs 1-13. equation valid compare uncompressed
PDB discs 2-14 compared compressed PDB.

232

fiCompressed Pattern Databases

PDBs

Discs

14-3
14-3
15-2
16-1

0
0
1
2

16-2

2

Type

Avg h
Nodes
17-disc problem
static
90.5 >393,887,912
dynamic
95.7
238,561,590
static
103.7
155,737,832
static
123.8
17,293,603
18-disc problem
static
123.8
380,117,836

Time

Memory

>421
2501
83
7

256M
256M
256M
256M

463

256M

Table 5: Solving 17 18-disc Towers Hanoi
size. example, comparing third line tables shows compressed
PDB 16 megabytes memory solved problem ten times faster
simple uncompressed PDB size indices based discs
(discs 1-12 case). empirical evidence equation 2 section 4.3.1.
last row Table 4 represents lossless compression full 14-disc PDB
smallest 14 discs, stored one additional bit position disc.
used 8 + 4 = 12 bits per four entries instead 8 4 = 32 bits uncompressed
PDB (row 1). number generated nodes identical row one, table clearly
shows worthwhile using lossless compression TOH4 since requires
time memory lossy compression one two smallest discs (rows 2
3).
Avg h column gives average heuristic entries PDB. difference average h value compressed PDB, average h value
uncompressed PDB (87.04), gives average loss information due compression.
maximum possible loss information lossy compression z discs, diameter r,
presented fourth column Table 4. length optimal solution
problem z discs z less 15, since problems, two states
furtherest apart problem space standard initial goal states.4 observe
average loss information half maximum possible information loss d.
summarize set experiments, conclude compressing large discs
effective values compressed patterns highly correlated. contrast,
compressing small discs extremely efficient values compressed
entries highly correlated.
5.4 17 18-Disc Problems
also solved 17- 18-disc problems compressing smallest discs. optimal
solutions standard initial state 193 225 moves respectively. Results
presented Table 5. Static partitioning largest 14 discs smallest 3 discs
cannot solve 17-disc problem, since memory exhausted reaching goal
4. Surprisingly, true 15 discs, 20 discs (Korf, 2003, 2004).

233

fiFelner, Korf, Meshulam, & Holte

7 minutes (row 1). uncompressed PDB 14 discs able solve
17-disc problem dynamic partitioning (row 2).
largest PDB could compute entirely 1 gigabyte memory 16
discs. database constructed bit-array detect duplicate nodes, requiring
416 = 4 gigabits, half gigabyte. Given amount memory full 14-disc
PDB, 256MB, solved 17-disc problem 83 seconds 15-disc PDB compressed
smallest disc, 7 seconds 16-disc PDB compressed smallest two
discs. improvement almost two orders magnitude compared row 1.
improvement 2.5 orders magnitude compared dynamically partitioned heuristic
14-disc PDB row 2. PDB 16 discs compressed 2 discs consumes exactly
amount memory uncompressed PDB 14 discs much
informed, includes almost information 16 discs. PDB
also able solve 18-disc problem 8 minutes.
5.5 Using Symmetry Disk Storage Solve 31 Discs
algorithms described able find shortest paths legal states
TOH4. However, much better interested shortest path
standard initial state, discs located one peg, standard goal state,
located another peg (Hinz, 1997). take advantage
symmetry standard initial goal states. particular, need
search half way goal, first middle state discs largest
distributed two intermediate pegs. Given middle state, reach
goal state moving largest disc goal peg, applying moves made
reach middle state reverse order, interchanging initial goal pegs.
challenge take advantage heuristic function half-depth search
middle state. difficulty solve n disc problem, 2n1 middle
states, one way distribute n 1 smallest discs two intermediate
pegs. PDB heuristic provides solution problem. Rather building PDB
breadth-first search starting single goal state, simply start search
2n1 middle states depth zero, search breadth-first entire pattern space
generated. resulting PDB values minimum number moves required
reach middle states. refer Multiple-Goal Pattern Database,
MGPDB (Korf & Felner, 2007).
constructed heuristic follows. first constructed 22-disc MGPDB compressed size 15-disc PDB, compressing 7 smallest discs. database
occupied exactly gigabyte memory, one byte per entry, constructed
memory, using magnetic disk storage states breadth-first search. also
constructed separate 8-disc MGPDB, required little time memory.
used MGPDBs compute heuristics problems 31 discs.
31-disc problem, goal search middle state 30 smallest discs
distributed two intermediate pegs. Thus, dont need consider largest disc.
state search, statically divided 30 discs largest 22 discs,
smallest 8 discs. looked configuration 22 largest discs 22-disc
MGPDB, looked configuration 8 smallest discs 8-disc MGPDB,
234

fiCompressed Pattern Databases

added resulting values together. Similarly, also looked configuration
22 smallest discs 22-disc MGPDB, looked configuration 8
largest discs 8-disc MGPDG, added theses values together well. Finally,
took maximum two sums overall heuristic.
search algorithm used frontier version breadth-first heuristic search
(BFHS) (Zhou & Hansen, 2006), A* cost function f (s) = g(s) + h(s),
g(s) depth state initial state, h(s) MGPDB heuristic described
above, estimates distance closest middle state. Using techniques,
number others, able verify presumed optimal solution four-peg
Towers Hanoi problems 31 discs. 31-disc problem took 100 CPU-days
run, used two terabytes disk storage. Due unrecoverable disk error
resulting loss single disk block, one 200 million probability
shorter solution 31-disc problem. able solve smaller problems
errors. represents current state-of-the-art four-peg Towers Hanoi
Problem. interested reader referred (Korf & Felner, 2007) details
experiments.

6. Sliding-Tile Puzzles
11
00
00
11
00
11
00
11
00
11

771 partitioning

Figure 6: 7-7-1 partitioning disjoint sets 15-Puzzle
best method solving sliding-tile puzzles optimally uses disjoint additive
pattern databases (Korf & Felner, 2002). case, variables represent tiles values
represent locations. tiles partitioned disjoint sets, PDB built
set. PDB stores cost moving tiles pattern set given
arrangement goal positions. Since set pattern tiles count moves
pattern tiles, move moves one tile, values different disjoint PDBs
added together results still admissible. deeper analysis additive
PDBs, see (Felner et al., 2004a).
x z partitioning partition tiles disjoint sets cardinalities x,
z. Figure 6 shows 7-7-1 disjoint partitioning 15-puzzle used paper.
geometric symmetry domain used allow another set PDB lookups
(Culberson & Schaeffer, 1998; Korf & Felner, 2002; Felner et al., 2004a). example,
reflect puzzle main diagonal, get another partitioning puzzle
geometrically symmetric original partitioning. Therefore, PDB
used retrieve values regular partitioning reflected partitioning.
maximum values taken admissible heuristic.
235

fiFelner, Korf, Meshulam, & Holte

6.1 Combining Functional Heuristics PDBs
many domains exist simple functional heuristics calculated efficiently. example Manhattan distance (MD) heuristic sliding-tile puzzles.
domains, PDB store additional increment () functional
heuristic, order save memory. denote PDB DPDB. search
add values DPDB value functional heuristic.
sliding-tile puzzles build DPDB storing additional increment
MD, results conflicts tiles PDB. conflicts come
units two moves, since tile moves away Manhattan-distance path, must
return path total two additional moves. Compressing DPDB
sliding-tile puzzle effective. Consider pair adjacent patterns
sliding-tile puzzle whose values stored DPDB. Since adjacent,
Manhattan distances differ one, numbers additional moves MDs
often same. Thus, much information preserved compressing two
entries taking minimum.

3
6 7
1011
a) goal pattern

0 0 3
0 0 0 7
0 0 1011
0 0 2 2
b) PDB values tile 6

Figure 7: goal pattern tiles {3,6,7,10,11} values tile 6
example, consider subproblem 15-puzzle includes tiles {3,6,7,10,11}.
corresponding goal pattern shown Figure 7.a. Assume tiles except
tile 6 goal positions, assume tile 6 location x, course
cannot {3,7,10,11}. values Figure 7.b written location x correspond
number moves MDs pattern tiles must move order properly
place tile 6 goal location, given current location x. example, suppose
tile 6 placed bottom row tile 10 belongs. case tile 6
linear conflict (Hansson, Mayer, & Yung, 1992) tile 10, one must
make least two horizontal moves MD. Thus write number 2
location. locations moves beyond MD needed write 0.
Note adjacent positions Figure 7.b value. Thus, build
DPDB compress two entries correspond patterns, information
lost cases. fact, 7-7-1 partition used experiments below,
compressing two patterns one, found 80%
pairs compressed stored exactly value compression.
6.2 Compressing PDBs Sliding-Tile Puzzles
Since 15 puzzle permutation problem, sparse mapping compact
mapping defined section 3.1 applicable. 7-tile PDB experiments,
236

fiCompressed Pattern Databases

sparse mapping uses multi-dimensional array size 167 268 106 entries.
Alternatively, compact mapping uses array size 16 15 . . . 10 57 106
entries. Compact mapping complex implement turned time
consuming experiments needs smaller amount memory.
6.2.1 Cliques Sliding-Tile Puzzles
sliding-tile puzzles full compression one variable, tile, equivalent
clique compression. Since every move moves single tile adjacent location,
largest clique pattern space size two, single edge. edges,
locations tiles pattern except one fixed, remaining tile one
two adjacent positions. refer compressing two states edge compression.
sparse mapping, 16 different entries variable correspond
16 different possible locations tile 15-puzzle. order take advantage
edge compression, divided 16 locations following 8 pairs: (0,1), (2,3)
. . . (14,15). Instead storing 16 entries location last tile, store 8
entries, one pairs. Thus, size PDB 166 8, half
size original PDB 167 different entries. Note compressing
particular edges logically done applying DIV 2 index last tile.
Compressing edges (cliques) compact mapping complicated.
PDB based P tiles, 16 P + 1 entries last tile. example,
P = 7, 16 different locations, 10 legal positions place
last tile, since 6 occupied tiles. use pairing mechanism
described compressing edges compress 16 locations 8 entries.
slightly smaller 10 entries original compact mapping. Edge
compressing effective compact mapping number pattern tiles
considerably smaller half size puzzle. example, 24-puzzle,
efficient compress edges PDBs 6 tiles even compact mapping. Note
alternative method would compress 10 entries compact mapping
5 entries (by Div 2). However, shown necessarily compress adjacent
locations last tile, therefore correspond edge (clique) compression.
6.3 Results 15-Puzzle
Table 6 presents results different compressing methods 15-puzzle sparse mapping, Table 7 presents similar results compact mapping. values tables
averages 1000 random initial states used (Korf & Felner, 2002).
Heuristic column defines partitioning used. example, 1 7-7-1 means
used one 7-7-1 partitioning. 2 7-7-1 means used two different 7-7-1 partitionings took maximum heuristic. + means also took
partitioning reflected main diagonal. next column indicates
compressing method used. subscript ls shown means lossless compression
used, otherwise compression lossy. next columns present number
nodes generated IDA*, average running time seconds, amount memory
megabytes one byte per entry, average heuristic initial states. time
237

fiFelner, Korf, Meshulam, & Holte



Heuristic

1
2
3
4
5

1
1
1
1
1

6
7
8

1+
1+
1+

9
10

2
2+

Compress
Nodes Time
One PDB lookup
7-7-1
464,977 0.058
7-7-1 edge
565,881 0.069
7-7-1 edgels
487,430 0.070
7-7-1 row
1,129,659 0.131
7-7-1 2 tiles
1,312,647 0.152
PDB lookup reflection
7-7-1
124,482 0.020
7-7-1 edge
148,213 0.022
7-7-1 row
242,289 0.048
Two different PDBs
7-7-1 edge
147,336 0.021
7-7-1 edge
66,692 0.016

Mem

Av h

524M
262M
262M
131M
131M

43.64
43.02
43.59
42.43
42.21

524M
262M
131M

44.53
43.98
43.39

524M
524M

43.98
44.92

Table 6: 15-puzzle results. Different compressing methods one lookups
sparse mapping

needed precompute PDB traditionally omitted, since one needs precompute
once, PDB used solve many problem instances needed.
6.3.1 Sparse mapping
Row 1 Table 6 presents benchmark results single 7-7-1 partitioning
compression.5 . next four rows (2-5) present results different compression methods
7-7-1 PDB. Row 2 gives results 7-7-1 PDB two 7-tile PDBs
compressed edges. size PDB cut half, overall effort
increased 20% number generated nodes overall
running time. Row 3 presents results 7-7-1 partitioning used lossless
compression edges. number generated nodes decreased 15%
lossy compression, overall time increased little. due additional constant
time handling lossless compression.6 Row 4 provides results case 16
different locations one tile compressed four different entries saving
row tiles position, column. logically done DIV 4.
cases moving row 1 row 2 (in Table 6) row 2 4, amount memory
5. best results 15 puzzle achieved using 7-8 partitioning (Korf & Felner, 2002).
partitioning cannot implemented sparse mapping would need 4 Giga bytes memory.
Thus, used 7-7-1 partitioning set experiments.
6. reason number generated nodes identical 7-7-1 partitioning without
compression rare cases PDBs, two entries compressed edges
differed one move. Thus, information lost even lossless compression
used. rare cases caused special way treated location blank. full
technical treatment blank handled provided (Felner et al., 2004a).

238

fiCompressed Pattern Databases

reduced factor two. However, number generated nodes increased
20% edge compression, number generated nodes increased factor 2.5
going edge compression row compression. reason correlation
among values compressed entries. edge compression loss information
one move, significantly effect overall performance.
row compression, loss information much greater four values compressed
significantly different other. Thus, effect overall performance
much greater. Row 5 represents alternative way compress PDB factor 4.
case, locations two tiles compressed eight locations each. Results
little worse row compression, correlation among compressed
values even less case.
next three rows (6-8) show tendency two sets PDB lookups
performed 7-7-1 PDB, original set set reflected main
diagonal. Row 6 presents results uncompressed versions PDBs. Note
additional PDB lookup PDB row 1 improved results
factor almost four. compressing edges row 7, correlation among
compressed values high, loss information one move, running
time roughly compared compression. row compression row 8,
correlation values worse, search effort increases.
Edge compression causes small loss information reduces memory half.
Thus, use amount memory original uncompressed PDB
two compressed PDBs. Row 9 presents results took two different 7-7-1 PDBs, compressed factor two using edges, took maximum. configuration
uses amount memory benchmark uncompressed single 7-7-1 partitioning
row 1, solves problem almost three times faster. Row 10 also computes
reflection main diagonal two different compressed PDBs takes
maximum 4 different partitionings. reduced number generated nodes
factor 7 factor 2, compared uncompressed versions amount
memory row 1 6, respectively. terms running time speedup
modest decreased 16 milliseconds. 4 PDB
lookups diminishing return adding lookups.7
6.3.2 Compact mapping
Table 7 presents results PDB built compact mapping. first line
provides results 7-7-1 partitioning used sparse mapping table 6
compact mapping. indexing algorithm used line simple algorithm
calculating exact index takes time quadratic number objects
pattern. Note number generated nodes identical line 1 table 6
amount memory needed much smaller. hand, results show
actual CPU time compact mapping worse corresponding sparse
mapping. rest table used advanced algorithm index calculation
7. See (Holte, Felner, Newton, Meshulam, & Furcy, 2006) deeper discussion advanced
methods reduce constant time per node number PDB lookups performed.
Furthermore, exact CPU time measured experiments taken care since
greatly influenced implementation, compiler hardware machine used.

239

fiFelner, Korf, Meshulam, & Holte



Heuristic

1

1 7-7-1

2
3
4
5
6

1
1
1
1
1

7-7-1
7-7-1
7-7-1
7-7-1
7-7-1

Compress
Nodes Time
Simple compact mapping
none
464,977 0.232
Advanced compact mapping
none
464,977 0.121
edge
565,881 0.142
edge ls
487,430 0.130
last tile
996,773 0.240
first tile
1,024,972 0.261

Mem

Av h

55M

43.64

55M
44M
44M
27.5M
27.5M

43.64
43.02
43.59
42.87
42.94

Table 7: 15-puzzle results. Compressing compact mapping
compact mapping presented (Korf & Shultze, 2005). advanced algorithm
time calculate exact index reduced linear number objects.
done help another lookup table stores values shift operations needed
algorithm. See (Korf & Shultze, 2005) deeper discussion treatment
method. Using advanced algorithm reduced running time factor
two simple quadratic algorithm still slower corresponding
sparse mapping reported table 6.
Lines 3 4 provide results lossy lossless edge compressing advanced
compact mapping. results report number generated nodes corresponding sparse mapping table 6. Compact mapping 10 entries last
tile (since 6 locations occupied tiles). Edge compression (lines 3 4)
slightly reduced 8 entries offering small memory reduction 20%
uncompressed 7-7-1 compact mapping PDB. probably cost effective
allow another compressed PDB stored amount memory
uncompressed PDB. Line 5 presents results compressed index last tile
10 entries 5 taking maximum two adjacent entries. equivalent
Div 2. memory reduction factor 2. However, since neighboring entries
compact mapping necessarily correspond cliques, number generated
nodes significantly increased loss information guaranteed 1
edge (clique) compressing. last line provides similar results compressing
performed index first tile (from 16 locations 8). equivalent
MOD 2. Again, entries compressed cliques loss data
rather large.
6.3.3 Summary 15 puzzle results
results 15 puzzle show edge (clique) compressing effective
puzzle information preserved type compressing. compressing techniques cause significant loss information efficient domain.
Edge compressing provides significant memory reduction factor 2 sparse mapping
used. encouraging since sparse mapping probably best choice larger
versions puzzle (e.g., 24, 35, etc.). one chooses use compact mapping
240

fiCompressed Pattern Databases

memory saved edge compressing rather modest probably effective. Unlike
4-peg Towers Hanoi problem, could find compressing method memory
saving factor larger 2 proved efficient tile puzzle.
best existing heuristic 15 puzzle PDB based 7-8 partitioning
tiles, reflection main diagonal (Korf & Felner, 2002). solved problem implementing partitioning compact mapping used 562 megabytes.
average number generated nodes 36,710, average running time
.018 seconds fast compact mapping. reduction almost factor two
simple quadratic compact mapping. Since 7-8 PDBs implemented compact
mapping could improve results compression. worth noting
best version 7-7-1 partitioning (line 10 Table 6) uses slightly less memory
(524 megabytes) runs slightly faster(.016 seconds), generates twice many nodes.
(66,692).
6.4 Results 24-Puzzle

Figure 8: 6-6-6-6 PDB 24-Puzzle reflection
best existing heuristic 24-puzzle one gigabyte memory
available 6-6-6-6 partitioning reflection main diagonal (Korf &
Felner, 2002) shown Figure 8. compressed 6-6-6-6 partitioning found
similar 15 puzzle lossy compression edges effective generated
20% nodes. However, adding another 6-6-6-6 partitioning could
achieve significant reduction overall time. Due geometrical attributes
puzzle, 6-6-6-6 partitioning reflection (Korf & Felner, 2002) good
adding another set 6-6-6-6 partitioning, even without compression, achieves
small reduction node generations.
also tried 7-7-5-5 partitioning refection, stored one gigabyte
memory compressing 7-tile PDBs. Even without compression, number
generated nodes much better 6-6-6-6 partitioning probably
best 4-way partitioning puzzle.
One way obtain speedup domain might compress larger PDBs
8-8-8 partitioning, beyond scope work. 8-8-8 PDB
implemented (Felner & Adler, 2005) using sophisticated method instance-dependent
PDBs. method based idea first presented (Zhou & Hansen, 2004),
relevant parts PDB stored memory given particular initial goal
states.
241

fiFelner, Korf, Meshulam, & Holte

7. Top-Spin
tried different compression methods Top-Spin domain well. Top-Spin
one object moved move. Therefore, simple disjoint additive PDBs
applicable here. simple way build PDB domain specify number
pattern tokens, remaining tokens indistinguishable. Here, used
compact mapping.
7.1 Cliques Top-Spin
Due nature Top-Spin, largest cliques size two, simply edges, unlike
domains correspond compression single variables. example,
assume 3-token PDB tokens (2, 3, 4) (9,4) Top-Spin problem. Note patterns
(, 2, 3, 4, , , , , ) (, , 4, 3, 2, , , , ) adjacent, therefore belong edge
clique size two. However, three tokens move here, hence three pattern variables
change values. Thus, compressing edges (cliques) simple compressing
value single variable problem.
7.2 Compression Based Individual Variables
fact, Top-Spin, compressing individual variables ignoring
variables. words, PDB based P variables, compressed C variables,
actually identical memory values PDB based P C variables.
explain this, first examine compression single variable. Consider threevariable P DB3 based tokens (1, 2, 3), four-variable P DB4 based tokens (1, 2, 3, 4)
(9,4) Top-Spin problem. non-pattern tokens represented . goal pattern P DB3 (1, 2, 3, , , , , , ), goal pattern P DB4 (1, 2, 3, 4, , , , , ).
Let p1 = (1, 2, , , , , , , 3) example pattern P DB3 . reach p1
goal pattern two moves, since operators space inverses,
P DB3 (p1 ) = 2. apply two moves pattern (1, 2, 3, 4, , , , , ),
reach pattern (1, 2, , , 4, , , , 3), well call p2 . Thus, P DB4 (p2 ) = 2.
consider P DB41 P DB4 compressed token variable 4. definition,
P DB41 (p1 ) minimum value locations token 4, P DB4 (pi ). fact,
constructed p2 P DB4 (p2 ) = P DB3 (p1 ). Since smaller value,
P DB41 (p1 ) = P DB4 (p2 ) = P DB3 (p1 ). argument applies example
pattern. Furthermore, apply argument PDB built compressing
number individual variables. Thus special case Top-Spin, equation 2
section 4.3.1 becomes CP DBP/C (s) = P DBP C (s). means Top-Spin, compression based individual variables offers benefits compared simply ignoring
variables PDB size.
7.3 Experimental Results Top-Spin
Since compression based individual variables benefit here, tried general compression applying DIV OD operators PDB indices. experimented
(17,4)-Top-Spin problem started compact mapping PDB 9 consecutive tokens, including 1 token. Note exceptions noted below,
242

fiCompressed Pattern Databases

Comp. Factor
1
2
3
4
5
6
7
8
9
1

Avg. Value

Avg Nodes
9-token PDB
10.52
40,810,940
10.20
59,827,209
10.03
87,517,365
9.88
86,424,249
9.76 127,276,981
9.69 147,626,798
9.61 128,757,535
9.54 159,711,937
9.53 313,375,790
8-token PDB
9.53 313,375,790

Avg Time

Size PDB

87.36
127.54
183.70
184.19
264.33
307.42
267.73
331.97
650.83

495M
247M
164M
123M
99M
82M
71M
62M
55M

650.83

55M

Table 8: Results (17,4) Top-Spin PDBs 9 8 tokens 9-token PDB
compressed DIV operator

Comp. Factor
1
2
3
4
5
6
7
8
9

Avg. Value
10.52
10.13
9.89
9.82
9.65
9.53
9.38
9.49
9.17

Avg Nodes
40,810,941
50,363,034
57,576,194
76,123,453
87,573,074
87,356,615
85,280,514
152,480,885
89,543,322

Avg Time
87.37
109.88
119.86
158.47
183.05
186.15
205.25
321.23
197.18

Size PDB
495M
247M
164M
123M
99M
82M
71M
62M
55M

Table 9: Results for(17,4) Top-Spin 9-token PDB compressed MOD

compressions preserve structure state variables correlation
values compressed entries.
Table 8 presents results DIV compression performed PDB. line
represents different compression factor, second argument DIV operator.
expected, larger compression factor increased search effort, reduced amount
memory. Note DIV 9 corresponds compression based single variable,
since 8 variables set 17-variable permutation problem, exactly
9 possible locations remaining next variable. Thus, explained previous
section line identical uncompressed PDB size 8 (the last line table).
243

fiNumber generated nodes (in Millions)

Felner, Korf, Meshulam, & Holte

350
DIV
MOD

300
250
200
150
100
50
0
1

2

3

4
5
6
7
compression degree

8

9

Figure 9: Nodes generated DIV MOD 9-token PDB (17,4)- Top-Spin
problem

Table 9 shows results compressing PDB MOD operator,
form Table 8. Figure 9 compares two methods. Surprisingly, MOD outperformed DIV. counterintuitive DIV compresses entries tend
many state variables common. best explanation phenomenon follows.
described above, Top-Spin location several tokens changed single move.
believe distance two states similar, differing swap
two tokens example, greater distance randomly-chosen pair
states.8 Thus, states grouped together DIV operator tend less
highly correlated random groupings, groupings induced MOD operator.
Note last line Table 9 (compression MOD 9) used amount
memory uncompressed 8-token PDB (last line Table 8) takes 30%
long solve problems. shows benefit compression problem well.
Compression MOD operator effective given size memory
8-token PDB, better build larger 9-token PDB compress size.
reduces search effort factor 3.

8. Conclusions
introduced new method improving performance PDBs, compressing
larger PDBs fit smaller amounts memory. applied technique
four-peg Towers Hanoi problem, sliding-tile puzzles, Top-Spin puzzle.
experiments confirm given specific amount memory , usually better use
memory compressed PDBs uncompressed PDBs. practically
achieved either larger PDB compressed size , maximizing k compressed
PDBs size M/k.
8. performed several experiments confirm this. Indeed, (12,4) - Top-Spin version, pair
random states distanced 9.28 moves away average two states
differ two adjacent tokens 12 moves away. Similarly, (16,4) - TopSpin average distances
14.04 16 moves, respectively.

244

fiCompressed Pattern Databases

introduced number different methods compressing PDB, ranging
general mapping functions indices DIV MOD, methods take
account structure problem space. general, want group together PDB
entries similar values. achieved grouping patterns close
pattern space. particular, states form clique problem
space PDB values differ one, hence natural candidates
compression. exact method finding cliques (or nearby patterns) PDB
depends domain exact way PDB implemented.
TOH4 sparse mapping tile puzzle, PDB constructed
easily way cliques reside nearby entries PDB thus, PDB
values locally correlated. Therefore, compressing nearby PDB entries proved useful
settings. Top-Spin, however, values PDB stored standard way
locally correlated thus compressing nearby PDB entries effective.
domain effective compress patterns far apart PDB. Similarly,
neighboring entries compact mapping tile puzzle correspond cliques.
Thus, compression prove useful setting could improve 7-8
partitioning 15 puzzle.
Towers Hanoi problem, achieved dramatic improvements several orders
magnitude running time, compared uncompressed PDBs size, used
technique verifying optimal solutions problems 31 discs,
current state art. sliding-tile puzzles showed compression
preserve information techniques offer practical improvements
sparse mapping compact mapping. Top-Spin, achieved
improvements naive compression method (the MOD method).
also described several methods generating PDBs large fit
memory prior compression, using auxiliary disk storage.

9. Acknowledgements
research supported Israel Science Foundation (ISF) grant No. 728/06
Ariel Felner. also supported NSF grant No. EIA-0113313 Richard Korf.

References
Bloom, B. H. (1970). Space/time trade-offs hash coding allowable errors. Communications ACM, 13(3), 422426.
Chen, T., & Skiena, S. (1996). Sorting fixed-length reversals. Discrete Applied Mathematics, 71 (1-3), 269295.
Culberson, J. C., & Schaeffer, J. (1998). Pattern databases. Computational Intelligence,
14 (3), 318334.
Dunkel, O. (1941). Editorial note concerning advanced problem 3918. American Mathematical Monthly, 48, 219.
Dunkel, O. (1992). Symbolic boolean manipulation ordered binary decision diagrams.
ACM Computing Surveys, 24(3), 142170.
245

fiFelner, Korf, Meshulam, & Holte

Edelkamp, S. (2001). Planning pattern databases. Proceedings 6th European
Conference Planning (ECP-01), pp. 1334.
Edelkamp, S. (2002). Symbolic pattern databases heuristic search planning. Proc.
International Conference AI Planning Scheduling (AIPS), pp. 274293.
Edelkamp, S., & Kissmann, P. (2007). Externalizing multiple sequence alignment problem affine gap costs. German Conference Artificial Intelligence (KI), LNCS
4467, pp. 444447.
Felner, A., & Adler, A. (2005). Solving 24-puzzle instance dependent pattern
databases. Proceedings SARA-05, pp. 248260, Edinburgh, Scotland.
Felner, A., Korf, R. E., & Hanan, S. (2004a). Additive pattern database heuristics. Journal
Artificial Intelligence Research (JAIR), 22, 279318.
Felner, A., Meshulam, R., Holte, R., & Korf, R. (2004b). Compressing pattern databases.
Proceedings Nineteenth National Conference Artificial Intelligence (AAAI04), pp. 638643.
Felner, A., Zahavi, U., Holte, R., & Schaeffer, J. (2005). Dual lookups pattern databases. Proceedings Nineteenth International Joint Conference Artificial
Intelligence (IJCAI-05), pp. 103108.
Frame, J. S. (1941). Solution advanced problem 3918. American Mathematical Monthly,
48, 216217.
Hansson, O., Mayer, A., & Yung, M. (1992). Criticizing solutions relaxed models yields
powerful admissible heuristics. Information Sciences, 63(3), 207227.
Hart, P. E., Nilsson, N. J., & Raphael, B. (1968). formal basis heuristic determination minimum cost paths. IEEE Transactions Systems Science Cybernetics,
SCC-4(2), 100107.
Hinz, A. M. (1997). tower Hanoi. Algebras Combinatorics: Proceedings
ICAC97, pp. 277289, Hong Kong. Springer-Verlag.
Holte, R. C., Felner, A., Newton, J., Meshulam, R., & Furcy, D. (2006). Maximizing
multiple pattern databases speeds heuristic search. Artificial Intelligence, 170,
11231136.
Korf, R. E. (1985). Depth-first iterative-deepening: optimal admissible tree search.
Artificial Intelligence, 27(1), 97109.
Korf, R. E. (1997). Finding optimal solutions Rubiks Cube using pattern databases.
Proceedings Fourteenth National Conference Artificial Intelligence (AAAI97), pp. 700705.
Korf, R. E. (2003). Delayed duplicate detection: Extended abstract. Proceedings
18th International Joint Conference Artificial Intelligence (IJCAI-03), pp. 1539
1541, Acapulco, Mexico.
Korf, R. E. (2004). Best-first frontier search delayed duplicate detection. Proceedings
19th National Conference Artificial Intelligence (AAAI-2004), pp. 650657,
San Jose, CA.
246

fiCompressed Pattern Databases

Korf, R. E., & Felner, A. (2002). Disjoint pattern database heuristics. Artificial Intelligence,
134, 922.
Korf, R. E., & Felner, A. (2007). Recent progress heuristic search: case study
four-peg towers hanoi problem. Proceedings 20th International Joint
Conference Artificial Intelligence (IJCAI-07), pp. 23242329.
Korf, R. E., & Shultze, P. (2005). Large-scale, parallel breadth-first search. Proceedings
20th National Conference Artificial Intelligence (AAAI-2005), pp. 13801385,
Pittsburgh, PA.
Korf, R. E., Zhang, W., Thayer, I., & Hohwald, H. (2005). Frontier search. Journal
Association Computing Machinery (JACM), 52 (5), 715748.
McNoughtton, M., Lu, P., Schaeffer, J., & Szafron, D. (2002). Memory efficient A* heuristics
multiple sequence alignment. Proceedings Eighteenth National Conference
Artificial Intelligence (AAAI-02), pp. 737743.
Mero, L. (1984). heuristic search algorithm modifiable estimate. Artificial Intelligence, 23, 1327.
Munagala, K., & Ranade, A. (1999). I/o complexity graph algorithms. Proceedings
10th Annual Symposium Discrete Algorithms, pp. 687694. ACM-SIAM.
Myrvold, W., & Ruskey, F. (2001). Ranking unranking permutations linear time.
Information Processing Letters, 79, 281284.
Schroedl, S. (2005). improved search algorithm optimal multiple-sequence alignment.
Journal Artificial Intelligence Research (JAIR), 23, 587623.
Stern, U., & Dill., D. L. (1995). Improved probabilistic verification hash compaction.
Advanced Research Working Conference Correct Hardware Design Verification
Methods, pp. 206240.
Stewart, B. (1941). Solution advanced problem 3918. American Mathematical Monthly,
48, 217219.
Zahavi, U., Felner, A., Holte, R., & Schaeffer, J. (2006). Dual search permutation state
spaces. Proceedings Twenty First National Conference Artificial Intelligence (AAAI-06), pp. 10761081.
Zahavi, U., Felner, A., Schaeffer, J., & Sturtevant, N. (2007). Inconsistent heurstics. Proceedings Twenty Second National Conference Artificial Intelligence (AAAI07). appear.
Zhou, R., & Hansen, E. (2004). Space-efficient memory-based heuristics. Proceedings
Nineteenth National Conference Artificial Intelligence (AAAI-04), pp. 677682.
Zhou, R., & Hansen, E. (2006). Breadth-first heuristic search. Artificial Intelligence, 170 (45), 385408.

247

fiJournal Artificial Intelligence Research 30 (2007) 457-500

Submitted 05/07; published 11/07

Using Linguistic Cues Automatic Recognition
Personality Conversation Text
Francois Mairesse

f.mairesse@sheffield.ac.uk

Department Computer Science, University Sheffield
211 Portobello Street, Sheffield S1 4DP, United Kingdom

Marilyn A. Walker

m.a.walker@sheffield.ac.uk

Department Computer Science, University Sheffield
211 Portobello Street, Sheffield S1 4DP, United Kingdom

Matthias R. Mehl

mehl@email.arizona.edu

Department Psychology, University Arizona
1503 E University Blvd. Building 68, Tucson, AZ 85721, USA

Roger K. Moore

r.k.moore@dcs.shef.ac.uk

Department Computer Science, University Sheffield
211 Portobello Street, Sheffield S1 4DP, United Kingdom

Abstract
well known utterances convey great deal information speaker
addition semantic content. One type information consists cues
speakers personality traits, fundamental dimension variation humans.
Recent work explores automatic detection types pragmatic variation
text conversation, emotion, deception, speaker charisma, dominance, point
view, subjectivity, opinion sentiment. Personality affects aspects
linguistic production, thus personality recognition may useful tasks,
addition many potential applications. However, date, little work
automatic recognition personality traits. article reports experimental results
recognition Big Five personality traits, conversation text, utilising
self observer ratings personality. work reports classification results,
experiment classification, regression ranking models. model, analyse
effect different feature sets accuracy. Results show traits, type
statistical model performs significantly better baseline, ranking models
perform best overall. also present experiment suggesting ranking models
accurate multi-class classifiers modelling personality. addition, recognition
models trained observed personality perform better models trained using selfreports, optimal feature set depends personality trait. qualitative analysis
learned models confirms previous findings linking language personality,
revealing many new linguistic markers.

1. Introduction
Personality complex attributesbehavioural, temperamental, emotional
mentalthat characterise unique individual.

well known utterances convey great deal information speaker
addition semantic content. One type information consists cues
c
2007
AI Access Foundation. rights reserved.

fiMairesse, Walker, Mehl & Moore

speakers personality traits, fundamental dimension variation humans.
Personality typically assessed along five dimensions known Big Five:
Extraversion vs. Introversion (sociable, assertive, playful vs. aloof, reserved, shy)
Emotional stability vs. Neuroticism (calm, unemotional vs. insecure, anxious)
Agreeableness vs. Disagreeable (friendly, cooperative vs. antagonistic, faultfinding)
Conscientiousness vs. Unconscientious (self-disciplined, organised vs. inefficient, careless)
Openness experience (intellectual, insightful vs. shallow, unimaginative)
five personality traits repeatedly obtained applying factor analyses
various lists trait adjectives used personality description questionnaires (sample
adjectives above) (Norman, 1963; Peabody & Goldberg, 1989; Goldberg, 1990). basis
factor analyses Lexical Hypothesis (Allport & Odbert, 1936), i.e.
relevant individual differences encoded language, important
difference, likely expressed single word. Despite known
limits (Eysenck, 1991; Paunonen & Jackson, 2000), last 50 years Big Five model
become standard psychology experiments using Big Five shown
personality traits influence many aspects task-related individual behaviour. example,
success interpersonal tasks depends personalities participants,
personality traits influence leadership ability (Hogan, Curphy, & Hogan, 1994), general job
performance (Furnham, Jackson, & Miller, 1999), attitude toward machines (Sigurdsson,
1991), sales ability (Furnham et al., 1999), teacher effectiveness (Rushton, Murray, & Erdle,
1987), academic ability motivation (Furnham & Mitchell, 1991; Komarraju &
Karau, 2005). However, date little work automatic recognition
personality traits (Argamon, Dhawle, Koppel, & Pennebaker, 2005; Mairesse & Walker,
2006a, 2006b; Oberlander & Nowson, 2006).
Recent work AI explores methods automatic detection types pragmatic variation text conversation, emotion (Oudeyer, 2002; Liscombe, Venditti, & Hirschberg, 2003), deception (Newman, Pennebaker, Berry, & Richards, 2003;
Enos, Benus, Cautin, Graciarena, Hirschberg, & Shriberg, 2006; Graciarena, Shriberg,
Stolcke, Enos, Hirschberg, & Kajarekar, 2006; Hirschberg, Benus, Brenier, Enos, Friedman, Gilman, Girand, Graciarena, Kathol, Michaelis, Pellom, Shriberg, & Stolcke, 2005),
speaker charisma (Rosenberg & Hirschberg, 2005), mood (Mishne, 2005), dominance
meetings (Rienks & Heylen, 2006), point view subjectivity (Wilson, Wiebe, & Hwa,
2004; Wiebe, Wilson, Bruce, Bell, & Martin, 2004; Wiebe & Riloff, 2005; Stoyanov, Cardie,
& Wiebe, 2005; Somasundaran, Ruppenhofer, & Wiebe, 2007), sentiment opinion
(Turney, 2002; Pang & Lee, 2005; Popescu & Etzioni, 2005; Breck, Choi, & Cardie, 2007).
contrast pragmatic phenomena, may relatively contextualised
short-lived, personality usually considered longer term, stable, aspect
individuals (Scherer, 2003). However, evidence personality interacts with,
affects, aspects linguistic production. example, strong relations
extraversion conscientiousness traits positive affects,
458

fiRecognising Personality Conversation Text

neuroticism disagreeableness various negative affects (Watson & Clark, 1992). Lying leads inconsistencies impressions agreeableness personality trait across modes
(visual vs. acoustic), inconsistencies used cues deception detection
human judges (Heinrich & Borkenau, 1998). Outgoing energetic people (i.e. extravert)
successful deception, apprehensive (i.e. neurotic) individuals
successful (Riggio, Salinas, & Tucker, 1988), individuals score highly agreeableness openness experience traits also better detecting deception (Enos
et al., 2006). Features used automatically recognise introversion extraversion
studies also important automatically identifying deception (Newman et al., 2003).
Speaker charisma shown correlate strongly extraversion (Bono & Judge,
2004), individuals dominate meetings similar characteristics extraverts,
verbosity (Rienks & Heylen, 2006). Oberlander Nowson (2006) suggest
opinion mining could benefit personality information. Thus evidence suggests
incorporating personality models tasks may improve accuracy.
also hypothesise computational recognition user personality could useful many computational applications. Identification leaders using personality
dimensions could useful analysing meetings conversations suspected terrorists (Hogan et al., 1994; Tucker & Whittaker, 2004; Nunn, 2005). Dating websites could
analyse text messages try match personalities increase chances successful
relationship (Donnellan, Conger, & Bryant, 2004). Tutoring systems might effective
could adapt learners personality (Komarraju & Karau, 2005). Automatically
identifying authors personality corpus could also improve language generation,
individual differences language affect way concepts expressed (Reiter &
Sripada, 2004). Studies also shown users evaluation conversational agents
depends personality (Reeves & Nass, 1996; Cassell & Bickmore, 2003),
suggests requirement systems adapt users personality, like humans
(Funder & Sneed, 1993; McLarney-Vesotski, Bernieri, & Rempala, 2006).
applications would possible acquire personality information
asking user author directly (John, Donahue, & Kentle, 1991; Costa & McCrae,
1992), explore whether possible acquire personality models Big Five
personality traits observation individual linguistic outputs text conversation.
date, know two studies besides automatic recognition user
personality (Argamon et al., 2005; Mairesse & Walker, 2006a, 2006b; Oberlander & Nowson,
2006). work applied classification models recognition personality
texts blog postings. knowledge, results presented first
examine recognition personality dialogue (Mairesse & Walker, 2006a, 2006b),
apply regression ranking models allow us model personality recognition
using continuous scales traditional psychology. also systematically examine
use different feature sets, suggested psycholinguistic research, report statistically
significant results.
start Section 2 reviewing psychology findings linking personality
language; findings motivate features used learning experiments described
Section 3. Section 3 overviews methods use automatically train personality
models, using conversation written language samples, self-ratings
observer ratings personality traits. explore use classification models (Section 4),
459

fiMairesse, Walker, Mehl & Moore

regression models (Section 5), ranking models (Section 6), effect different
feature sets model accuracy. results show traits, type statistical
model performs significantly better baseline, ranking models perform best
overall. addition, models trained observed personality scores perform better
models trained using self-reports, optimal feature set dependent personality
trait. rules derived features used learned models confirm previous findings
linking language personality, revealing many new linguistic markers. delay
review Argamon et al. (2005) Oberlander Nowson (2006) Section 7,
better compare results own, sum discuss future work
Section 8.

2. Personality Markers Language
believe might possible automatically recognise personality linguistic
cues? Psychologists documented existence cues discovering correlations
range linguistic variables personality traits, across wide range linguistic
levels, including acoustic parameters (Smith, Brown, Strong, & Rencher, 1975; Scherer,
1979), lexical categories (Pennebaker & King, 1999; Pennebaker, Mehl, & Niederhoffer,
2003; Mehl, Gosling, & Pennebaker, 2006; Fast & Funder, 2007), n-grams (Oberlander &
Gill, 2006), speech-act type (Vogel & Vogel, 1986). correlations reported
literature generally weak (see Section 3.3), clear whether features
improve accuracies statistical models unseen subjects. Big Five traits,
extraversion received attention researchers. However, studies focusing
systematically Big Five traits becoming common.
2.1 Markers Extraversion
summarise various findings linking extraversion language cues Table 1,
different levels language production speech, syntax content selection. review Furnham (1990) describes linguistic features linked extraversion traits,
Dewaele Furnham (1999) review studies focusing link extraversion
language learning speech production.
Findings include higher correlation extraversion oral language, especially study involves complex task. Extraverts talk more, louder
repetitively, fewer pauses hesitations, higher speech rates,
shorter silences, higher verbal output, lower type/token ratio less formal language, introverts use broader vocabulary (Scherer, 1979; Furnham, 1990; Gill &
Oberlander, 2002). Extraverts also use positive emotion words, show agreements compliments introverts (Pennebaker & King, 1999). Extravert students
learning French second language produce back-channels, implicit style lower lexical richness formal situations. seems complex
task higher level anxiety, easier differentiate introverts
extraverts (Dewaele & Furnham, 1999).
Heylighen Dewaele (2002) also note extraversion significantly correlated
contextuality, opposed formality. Contextuality seen high reliance
shared knowledge conversational partners, leading use many deictic
460

fiRecognising Personality Conversation Text

Level
Conversational
behaviour
Topic
selection

Style
Syntax

Lexicon

Speech

Introvert
Listen
Less back-channel behaviour
Self-focused
Problem talk, dissatisfaction
Strict selection
Single topic
semantic errors
self-references
Formal
Many hedges (tentative words)
Many nouns, adjectives, prepositions (explicit)
Elaborated constructions
Many words per sentence
Many articles
Many negations
Correct
Rich
High diversity
Many exclusive inclusive words
social words
positive emotion words
Many negative emotion words
Received accent
Slow speech rate
disfluencies
Many unfilled pauses
Long response latency
Quiet
Low voice quality
Non-nasal voice
Low frequency variability

Extravert
Initiate conversation
back-channel behaviour
self-focused*
Pleasure talk, agreement, compliment
Think loud*
Many topics
Many semantic errors
Many self-references
Informal
hedges (tentative words)
Many verbs, adverbs, pronouns (implicit)
Simple constructions*
words per sentence
articles
negations
Loose*
Poor
Low diversity
exclusive inclusive words
Many social words
Many positive emotion words
negative emotion words
Local accent*
High speech rate
Many disfluencies*
unfilled pauses
Short response latency
Loud
High voice quality
Nasal voice
High frequency variability

Table 1: Summary identified language cues extraversion various production levels, based previous studies Scherer (1979), Furnham (1990), Pennebaker
King (1999), Dewaele Furnham (1999), Gill (2003), Mehl et al. (2006).
Asterisks indicate cue based hypothesis, opposed study
results.

expressions pronouns, verbs, adverbs interjections, whereas formal language
less ambiguous assumes less common knowledge. order measure variation,
Heylighen Dewaele suggest use metric called formality, defined as:
F = (noun freq + adjective freq + preposition freq + article freq - pronoun freq - verb
freq - adverb freq - interjection freq + 100)/2
argue measure important dimension variation
linguistic expressions, shown Bibers factor analysis various genres (Biber, 1988).
addition introversion, authors also find formality correlates positively
level education femininity speaker. Situational variables related
use formal language audience size, time span dialogues,
unavailability feedback, difference backgrounds spatial location speakers,
well preceding amount conversation.
461

fiMairesse, Walker, Mehl & Moore

Scherer (1979) shows extraverts perceived talking louder
nasal voice, American extraverts tend make fewer pauses, German extraverts produce pauses introverts. Thus personality markers culture-dependent,
even among western societies.
Oberlander Gill (2006) use content analysis tools n-gram language models
identify markers extravert introvert emails. replicate previous findings
identify new personality markers first person singular pronouns (e.g., dont)
formal greetings (e.g., Hello) introversion, less formal phrases Take care
Hi characterise extraverts.

2.2 Markers Big Five Traits
Pennebaker King (1999) identify many linguistic features associated
Big Five personality traits. use Linguistic Inquiry Word Count (LIWC)
tool count word categories essays written students whose personality
assessed using questionnaire. authors find small significant correlations
linguistic dimensions personality traits. Neurotics use 1st person singular
pronouns, negative emotion words less positive emotion words. hand,
agreeable people express positive fewer negative emotions. also use fewer
articles. Conscientious people avoid negations, negative emotion words words reflecting
discrepancies (e.g., would). Finally, openness experience characterised
preference longer words words expressing tentativity (e.g., perhaps maybe),
well avoidance 1st person singular pronouns present tense forms.
Additionally, Mehl et al. (2006) study markers personality perceived observers.
find use words related insight avoidance past tense indicates
openness experience, swearing marks disagreeableness. authors also show
linguistic cues vary greatly across gender. example, males perceived
conscientious produce filler words, females dont. Gender differences also
found markers self-assessed personality: use 2nd person pronouns indicates
conscientious male, unconscientious female.
Gill Oberlander (2003) study correlates emotional stability: find neurotics use concrete frequent words. However, also show observers dont
use cues correctly, observer reports neuroticism correlate negatively selfreports.
Concerning prosody, Smith et al. (1975) also show speech rate positively correlated perceived competence (conscientiousness), speech rate inverted-U
relationship benevolence (agreeableness), suggesting need non-linear models.
traits produced findings others. reason might
reflected language, like extraversion. However, possible
focus consequence extraversion correlated linguistic cues
analysed easily (e.g., verbosity).
462

fiRecognising Personality Conversation Text

3. Experimental Method
conduct set experiments examine whether automatically trained models
used recognise personality unseen subjects. approach summarised
five steps:
1. Collect individual corpora;
2. Collect associated personality ratings participant;
3. Extract relevant features texts;
4. Build statistical models personality ratings based features;
5. Test learned models linguistic outputs unseen individuals.
following sections describe steps detail.
3.1 Sources Language Personality
Introvert
Ive waking time far.
been, 5 days? Dear me, Ill never
keep up, morning
person all. maybe Ill adjust,
not. want internet access
room, dont yet,
Wed??? think. aint soon
enough, cause got calculus homework [...]

Extravert
really random thoughts.
want best things life.
fear want much!
fall flat face
dont amount anything.
feel like born BIG things
earth. knows...
Persian party today.

Neurotic
One friends barged in,
jumped seat. crazy.
tell again.
Im fastidious actually.
certain things annoy me. things
would annoy would actually
annoy normal human being,
know Im freak.

Emotionally stable
excel sport
know push body harder
anyone know, matter test
always push body harder everyone
else. want best matter
sport event. also
good love ride
bike.

Table 2: Extracts essays corpus, participants rated extremely introvert,
extravert, neurotic, emotionally stable.

use data Pennebaker King (1999) Mehl et al. (2006) experiments. first corpus contains 2,479 essays psychology students (1.9 million
words), told write whatever comes mind 20 minutes. data
collected analysed Pennebaker King (1999); sample shown Table 2.
463

fiMairesse, Walker, Mehl & Moore

Introvert
- Yeah would kilograms. Yeah see
youre saying.
- Tuesday class. dont know.
- dont know. A16. Yeah, kind cool.
- dont know. cant wait
every night,
know?
- Yeah. dont know. bed
there? Well ok just...

Extravert
- Thats first yogurt experience here.
Really watery. Why?
- Damn. New game.
- Oh.
- Thats rude. That.
- Yeah, he, like other.
likes her.
- going end breaking
hes going like.

Unconscientious
- Chinese. Get together.
- tried yell window.
Oh. xxxxs fucking dumb ass. Look
him. Look him, dude. Look him.
wish camera. Hes fucking brushing
t-shirt tooth brush. Get kick
it. Dont steal nothing.

Conscientious
- dont, dont know fact
would imagine historically women
entered prostitution done
so, everyone, majority
extreme desperation think. dont
know, think people understand
desperation dont dont see [...]

Table 3: Extracts EAR corpus, participants rated extremely introvert, extravert, unconscientious, conscientious. participants utterances
shown.

Personality assessed asking student fill Big Five Inventory questionnaire (John et al., 1991), asks participants evaluate 5 point scale well
personality matches series descriptions.
second source data consists conversation extracts recorded using Electronically Activated Recorder (EAR) (Mehl, Pennebaker, Crow, Dabbs, & Price, 2001), collected
Mehl et al. (2006). preserve participants privacy, random snippets conversation recorded. corpus much smaller essays corpus (96 participants
total 97,468 words 15,269 utterances). essays corpus consists
texts, EAR corpus contains sound extracts transcripts. corpus therefore
allows us build models personality recognition speech. participants utterances transcribed (not conversational partners), making impossible
reconstruct whole conversations. Nevertheless, conversation extracts less formal
essays, personality may best observed absence behavioural constraints. Table 4 shows essays corpus much larger EAR corpus,
amount data per subject comparable, i.e. 766 words per subject essays
1,015 EAR corpus. Table 3 shows examples conversations EAR corpus
different personality traits.
personality ratings, EAR corpus contains self-reports ratings 18
independent observers. Psychologists use self-reports facilitate evaluating personality large number participants, large number standard self-report
tests. Observers asked make judgments rating descriptions Big Five
Inventory (John & Srivastava, 1999) 7 point scale (from strongly disagree strongly
464

fiRecognising Personality Conversation Text

Dataset
Source language
Personality reports
Number words
Subjects
Words per subject

Essays
Written
Self reports
1.9 million
2,479
766.4

EAR
Spoken
Self observer
97,468
96
1,015.3

Table 4: Comparison essays EAR corpora.
agree), without knowing participants. Observers divided three groups,
rating one third participants, listening participants entire set sound
files (130 files average). personality assessment based audio recordings,
contain information transcripts (e.g., ambient sounds, including captured conversations). Mehl et al. (2006) report strong inter-observer reliabilities across
Big Five dimensions (intraclass correlations based one-way random effect models: mean
r = 0.84, p < .01). observers ratings averaged participant, produce
final scores used experiments.
Interestingly, average correlations frequency counts psycholinguistic
word categories Big Five personality dimensions considerably larger
EAR corpus student essays studied Pennebaker King. Moreover,
correlations reported Mehl et al. seem higher observer reports
self-reports. Based observation, hypothesise models observed personality
outperform models self-assessed personality.
3.2 Features
features used experiments motivated previous psychological findings
correlations measurable linguistic factors personality traits. Features
divided subsets depending source described subsections below.
total feature set summarised Table 6. experimental results given Sections 4,
5, 6 examine effect feature subset model accuracy.
3.2.1 Content Syntax
extracted set linguistic features essay conversation transcript,
starting frequency counts 88 word categories Linguistic Inquiry Word
Count (LIWC) utility (Pennebaker et al., 2001). features include syntactic (e.g.,
ratio pronouns) semantic information (e.g., positive emotion words),
validated expert judges. LIWC features illustrated Table 5. Pennebaker
King (1999) previously found significant correlations features
Big Five personality traits. Relevant word categories extraversion include social
words, emotion words, first person pronouns, present tense verbs. Mehl et al. (2006)
showed LIWC features extracted EAR corpus significantly correlated
self observer reports personality.
also added 14 additional features MRC Psycholinguistic database (Coltheart, 1981), contains statistics 150,000 words, estimates age
465

fiMairesse, Walker, Mehl & Moore

Feature
Anger words
Metaphysical issues
Physical state/function
Inclusive words
Social processes
Family members
Past tense verbs
References friends
Imagery words
Syllables per word
Concreteness
Frequency use

Type
LIWC
LIWC
LIWC
LIWC
LIWC
LIWC
LIWC
LIWC
MRC
MRC
MRC
MRC

Example
hate, kill, pissed
God, heaven, coffin
ache, breast, sleep
with, and, include
talk, us, friend
mom, brother, cousin
walked, were,
pal, buddy, coworker
Low: future, peace - High: table, car
Low: - High: uncompromisingly
Low: patience, candor - High: ship
Low: duly, nudity - High: he,

Table 5: Examples LIWC word categories MRC psycholinguistic features (Pennebaker et al., 2001; Coltheart, 1981). MRC features associate word
numerical value.

acquisition, frequency use, familiarity. introverts take longer reflect
utterances, Heylighen Dewaele (2002) suggest vocabulary richer
precise, implying lower frequency use. MRC feature set previously used
Gill Oberlander (2002), showed extraversion negatively correlated
concreteness. Concreteness also indicates neuroticism, well use frequent
words (Gill & Oberlander, 2003). Table 5 shows examples MRC scales. MRC
feature computed averaging feature value words essay conversational extract. Part-of-Speech tags computed identify correct entry
database among set homonyms.
3.2.2 Utterance Type
Various facets personality traits seem depend level initiative speaker
type utterance used (e.g., assertiveness, argumentativeness, inquisitiveness, etc.).
example, extraverts assertive emails (Gill & Oberlander, 2002),
extravert second language learners shown produce back-channel behaviour
(Vogel & Vogel, 1986). therefore introduced features characterising types utterance produced. automatically tagged utterance EAR corpus speech
act categories Walker Whittaker (1990), using heuristic rules based utterances parse tree:
Command: utterance using imperative form, command verb (e.g., must to)
yes/no second person question modal auxiliary like can;
Prompt: single word utterance used back-channelling (e.g., Yeah, OK, Huh, etc.);
Question: interrogative utterance isnt command;
Assertion: utterance.
466

fiRecognising Personality Conversation Text

LIWC FEATURES (Pennebaker et al., 2001):
Standard counts:
- Word count (WC), words per sentence (WPS), type/token ratio (Unique), words captured (Dic), words
longer 6 letters (Sixltr), negations (Negate), assents (Assent), articles (Article),
prepositions (Preps), numbers (Number)
- Pronouns (Pronoun): 1st person singular (I), 1st person plural (We), total 1st person (Self), total
2nd person (You), total 3rd person (Other)
Psychological processes:
- Affective emotional processes (Affect): positive emotions (Posemo), positive feelings (Posfeel), optimism
energy (Optim), negative emotions (Negemo), anxiety fear (Anx), anger (Anger),
sadness (Sad)
- Cognitive Processes (Cogmech): causation (Cause), insight (Insight), discrepancy (Discrep), inhibition
(Inhib), tentative (Tentat), certainty (Certain)
- Sensory perceptual processes (Senses): seeing (See), hearing (Hear), feeling (Feel)
- Social processes (Social): communication (Comm), references people (Othref), friends (Friends),
family (Family), humans (Humans)
Relativity:
- Time (Time), past tense verb (Past), present tense verb (Present), future tense verb (Future)
- Space (Space): (Up), (Down), inclusive (Incl), exclusive (Excl)
- Motion (Motion)
Personal concerns:
- Occupation (Occup): school (School), work job (Job), achievement (Achieve)
- Leisure activity (Leisure): home (Home), sports (Sports), television movies (TV), music (Music)
- Money financial issues (Money)
- Metaphysical issues (Metaph): religion (Relig), death (Death), physical states functions (Physcal),
body states symptoms (Body), sexuality (Sexual), eating drinking (Eating), sleeping
(Sleep), Grooming (Groom)
dimensions:
- Punctuation (Allpct): period (Period), comma (Comma), colon (Colon), semi-colon (Semic), question
(Qmark), exclamation (Exclam), dash (Dash), quote (Quote), apostrophe (Apostro), parenthesis
(Parenth), (Otherp)
- Swear words (Swear), nonfluencies (Nonfl), fillers (Fillers)
MRC FEATURES (Coltheart, 1981):
Number letters (Nlet), phonemes (Nphon), syllables (Nsyl), Kucera-Francis written frequency (K-Ffreq), Kucera-Francis number categories (K-F-ncats), Kucera-Francis number samples (K-F-nsamp),
Thorndike-Lorge written frequency (T-L-freq), Brown verbal frequency (Brown-freq), familiarity rating
(Fam), concreteness rating (Conc), imageability rating (Imag), meaningfulness Colorado Norms (Meanc),
meaningfulness Paivio Norms (Meanp), age acquisition (AOA)
UTTERANCE TYPE FEATURES:
Ratio commands (Command), prompts back-channels (Prompt), questions (Question), assertions (Assertion)
PROSODIC FEATURES:
Average, minimum, maximum standard deviation voices pitch Hz (Pitch-mean, Pitch-min,
Pitch-max, Pitch-stddev) intensity dB (Int-mean, Int-min, Int-max, Int-stddev), voiced time (Voiced)
speech rate (Word-per-sec)

Table 6: Description features, feature labels brackets.
evaluated automatic tagger applying set 100 hand-labelled utterances
randomly selected EAR corpus. obtain 88% correct labels, mostly
assertions. Table 7 summarises partition evaluation results speech act
type. speech act, corresponding feature value ratio number
occurrences speech act total number utterances text.
467

fiMairesse, Walker, Mehl & Moore

Label
Assertion
Command
Prompt
Question


Fraction
73.0%
4.3%
7.0%
15.7%
100%

Labelling accuracy
0.95
0.50
0.57
1.00
0.88

Table 7: Partition speech acts automatically extracted EAR corpus,
classification accuracies sample 100 hand-labelled utterances.

3.2.3 Prosody
Personality also shown influence speech production. Extraversion associated
variation fundamental frequency (Scherer, 1979), higher voice quality
intensity (Mallory & Miller, 1958), fewer shorter silent pauses (Siegman
& Pope, 1965). Smith et al. (1975) showed speech rate positively correlated
perceived competence (conscientiousness). Interestingly, authors found speech
rate inverted-U relationship benevolence (agreeableness), suggesting need
non-linear models. See Section 3.4.
added prosodic features based audio data EAR conversation extracts.
EAR recorded participants anytime day, necessary automatically remove non-voiced signal. used Praat (Boersma, 2001) compute features
characterising voices pitch intensity (mean, extremas standard deviation),
added estimate speech rate dividing number words voiced time.
important aspect work features extracted without manual
annotation beyond transcription, didnt filter utterances speakers
may captured EAR even though utilised microphone pointing towards
participants head. Although advances speaker recognition techniques might improve
accuracy prosodic features, make assumption noise introduced
surrounding speakers little effect prosodic features, therefore
affect performance statistical models. assumption still remains tested,
personality similarity-attraction effect (Byrne & Nelson, 1965) might influence
personality distribution participants conversational partners.
included features mentioned section (117) models based
EAR corpus. Models computed using essays corpus contain LIWC MRC
features (102), speech acts meaningful dialogues.
3.3 Correlational Analysis
order assess individual features important modelling personality regardless
model used, report previous correlational studies LIWC features
data well analyses new MRC, utterance type prosodic features.
LIWC features already analysed Mehl et al. (2006) EAR dataset,
468

fiRecognising Personality Conversation Text

Pennebaker King (1999) essays.1 Tables 8 11 show features correlating
significantly personality ratings (p < .05, correlations .05 only), combining
together results previous studies new findings provide insight features
likely influence personality recognition models Sections 4.3, 5.3 6.3.
correlation magnitudes Tables 8 9 LIWC MRC features
essays data set show although extraversion well perceived conversations,
isnt strongly reflected written language, correlation magnitudes
essays dataset noticeably low. Table 10 shows word count (WC) important feature modelling extraversion conversation, observer reports
self-reports. Interestingly, marker doesnt hold written language (see Table 9).
markers common observed self-reported extraversion include variation
intensity (Int-stddev), mean intensity (Int-mean), word repetitions (Unique), words
high concreteness (Conc) imageability (Imag). See Table 11.
hand, words related anger, affect, swearing, positive negative emotions (Posemo
Negemo) perceived extravert, dont mark self-assessed extraversion
conversations.
Tables 10 11 show emotional stability, markers hold
self-reports observer reports: high word count low mean pitch (Pitch-mean).
Surprisingly, observed emotional stability associated swearing anger words,
self-assessed ratings. reported Mehl et al. (2006), neurotics expected
produce self-references (Self I). Pennebaker King (1999) show neurotics
use self-references also observed essays, well use words related
negative emotions anxiety. Table 11 shows conversations, self-assessed neurotics
tend low constant voice intensity (Int-mean Int-stddev),
markers arent used observers all.
emotional stability expressed differently various datasets, markers
agreeableness consistent: words related swearing (Swear) anger (Anger) indicate self-assessed observed disagreeableness, regardless source language.
See Tables 8, 9 10. Interestingly, Table 11 shows agreeable people
back-channelling (Prompt), suggesting tend listen conversational
partners. observers dont seem take prosody account evaluating agreeableness, Table 11 shows prosodic cues pitch variation (Pitch-stddev)
maximum voice intensity (Max-int) indicate self-assessed disagreeableness.
far markers conscientiousness concerned, Tables 8 10 show
similar agreeableness, unconscientious participants also use words related
swearing (Swear), anger (Anger) negative emotions (Negemo), regardless
dataset assessment method. hand, observed conscientiousness associated
words expressing insight, back-channels (Prompt), longer words (Nphon, Nlet, Nsyl
Sixltr) well words acquired late children (AOA), self-assessed
conscientiousness mostly expressed positive feelings (Posfeel) conversations.
avoidance negative language seems main marker conscientiousness
essays, features Table 8 correlate weakly self-reports.
1. correlations differ Pennebaker Kings study use additional student essays
collected following years.

469

fiMairesse, Walker, Mehl & Moore

Trait
LIWC
Achieve
Affect
AllPct
Anger
Anx
Apostro
Article
Assent
Body
Cause
Certain
Cogmech
Comm
Comma
Death
Dic
Excl
Exclam
Family
Feel
Fillers
Friends
Future
Groom
Hear
Home
Humans

Incl
Inhib
Insight
Job
Leisure
Metaph
Motion
Music
Negate
Negemo
Nonfl
Number
Occup
Optim

Othref
Parenth
Period
Physcal
Posemo
Posfeel
Preps
Present
Pronoun
Qmark

Extraversion

.03
.03
-.08**
-.03
-.01
-.08**
-.08**
.01
-.05**
.01
.05*
-.03
-.02
-.02
-.02
.05*
-.01
.00
.05*
-.01
-.04*
.06**
-.02
-.02
-.03
-.01
.04
.05*
.04*
-.03
-.01
.02
-.03
-.01
.03
-.04*
-.08**
-.03
-.03
-.03
.03
.03
.06**
.07**
-.06**
-.05*
-.02
.07**
.07**
.00
.00
.07**
-.06**

Emotional
stability
.01
-.07**
-.04
-.08**
-.14**
-.04
.11**
.02
-.04
-.03
-.01
-.02
.00
.01
-.04
-.09**
.02
-.05*
-.05*
-.09**
.01
-.04*
.01
-.02
.00
-.02
-.02
-.15**
-.01
.02
-.01
.01
.07**
.01
-.01
.06**
-.12**
-.18**
.01
.05*
.05*
.04
-.01
.02
.03
-.03
-.05*
.07**
-.01
.06**
-.12**
-.12**
-.05*

Agreeableness

-.01
-.04
-.01
-.16**
.03
-.02
-.03
.00
-.04*
.00
.03
-.02
-.01
-.02
-.02
.06**
-.02
.06**
.09**
.04
-.01
.02
.02
.01
-.01
.04*
-.03
.05*
.03
-.02
.00
.01
.03
-.01
.05*
-.01
-.11**
-.11**
.01
-.03
.04
.01
.03
.01
-.04*
-.01
-.03
.05*
.03
.04
-.01
.04*
-.04

Conscientiousness

.02
-.06**
-.04
-.14**
.05*
-.06**
.02
-.04
-.04*
-.04
.04*
-.06**
-.05**
-.01
-.06**
.06**
-.01
.00
.04*
.02
-.03
.01
.07**
.01
-.04*
.06**
-.08**
.04
.04*
-.02
-.03
.05**
-.01
-.08**
.03
-.07**
-.07**
-.11**
-.05*
-.02
.09**
.08**
.01
.01
-.01
-.01
-.03
.02
-.02
.08**
-.03
.02
-.06**

Openness
experience
-.07**
.04*
.10**
.06**
-.04
.05**
.11**
.04*
.02
-.05*
.04
.02
.03
.10**
.05*
-.20**
.07**
-.03
-.07**
-.04*
-.01
-.12**
-.04
-.05**
.04*
-.15**
.04
-.14**
-.03
.04*
.05*
-.05**
-.05**
.08**
-.13**
.10**
.01
.04
.02
-.06**
-.18**
-.07**
.01
.06**
.10**
.04
.01
.02
.08**
-.04
-.09**
-.06**
.08**

Table 8: Pearsons correlation coefficients LIWC features personality ratings
essays dataset, based analysis Pennebaker King (1999)
(* = significant p < .05 level, ** = p < .01). features correlate
significantly least one trait shown.

470

fiRecognising Personality Conversation Text

Trait
LIWC (2)
Quote
Relig
Sad
School
See
Self
Semic
Sexual
Sixltr
Sleep
Social
Space
Sports
Swear
Tentat
Time
TV
Unique

WC

WPS

MRC
AOA
Brown-freq
Conc
Fam
Imag
K-F-freq
K-F-ncats
K-F-nsamp
Meanc
Meanp
Nlet
Nphon
Nsyl
T-L-freq

Extraversion

Emotional
stability

Agreeableness

Conscientiousness

Openness
experience

-.05*
.00
.00
.03
.00
.07**
-.03
.07**
-.06**
-.01
.08**
-.02
.01
-.01
-.06**
-.02
-.04
-.05**
.03
.03
.06**
-.01
-.01

-.02
.03
-.12**
.05**
.09**
-.14**
.02
-.02
.06**
-.03
.00
.05*
.09**
.00
-.01
.02
.04*
.10**
.06**
-.06**
.07**
.02
.03

-.01
.00
.00
.06**
.00
.06**
.02
.00
-.05*
-.02
.02
.03
.02
-.14**
-.03
.07**
-.02
-.04*
.02
.01
.04*
.02
-.06**

-.03
-.06**
.01
.10**
-.03
.04*
.00
-.04
.02
.03
-.02
.01
.00
-.11**
-.06**
.09**
-.04*
-.05*
-.01
.02
.01
-.02
-.04*

.09**
.07**
-.01
-.20**
.05**
-.14**
.05**
.09**
.10**
-.08**
.02
-.04
-.05**
.08**
.05*
-.15**
.04
.09**
-.06**
.05*
.04
.06**
.11**

-.01
.05*
.02
.08**
.05*
-.01
.06**
.06**
.06**
.02
-.09**
-.08**
-.07**
.01

.05*
-.06**
-.06**
-.05*
-.04*
.10**
-.04*
-.01
-.10**
-.02
.09**
.08**
.07**
.10**

-.04*
.03
.03
.08**
.05*
.00
.08**
.03
.05**
.05*
-.03
-.03
-.02
.01

.06**
.06**
-.01
.05**
.00
.05*
.07**
.05**
-.01
.00
.00
.01
.04
.06**

.11**
-.07**
-.10**
-.17**
-.08**
.07**
-.12**
-.07**
-.11**
-.04*
.15**
.14**
.13**
.05**

Table 9: Continuation Table 8, i.e. Pearsons correlation coefficients LIWC
MRC features personality ratings essays dataset (* = significant
p < .05 level, ** = p < .01). features correlate significantly
least one trait shown.
Tables 8 9 show openness experience trait yielding highest correlations essays corpus: articles, second person pronouns (You) long words (Sixltr)
indicate openness, non-open participants tend talk occupations (Occup,
Home School) (Self). far conversations concerned, observers
use similar cues openness conscientiousness, insight words, longer words,
back-channels high age acquisition (AOA).
section shows features likely vary depending source language
method assessment personality. analyses help evaluate
usefulness individual features, question features combined
predict personality accurately addressed statistical models.
471

fiMairesse, Walker, Mehl & Moore

Dataset
Trait
LIWC
Affect
Anger
Articles
Assent
Cause
Cogmech
Comm
Dic
Discrep
Eating
Family
Feel
Female
Filler
Friend
Hear
Home
Humans

Inhib
Insight
Metaph
Money
Negemo
Nonfl

Othref
Past
Physcal
Posfeel
Pronoun
Relig
Self
Senses
Sexual
Sixltr
Social
Space
Sports
Swear
Tentat
Unique

WC

Extra

Observer reports
Emot
Agree Consc

Open

Extra

Emot

.40**
.37**
.21*
-.29**
-.13
.04
-.18
-.07
.08
.25*
.26*
.21*
.29**
-.01
.14
-.20
-.02
-.01
.03
.19
.04
.30**
-.02
.36**
-.01
.09
.00
-.19
.30**
.28**
-.02
.30**
.09
-.04
.24*
-.04
-.04
.03
.10
.30**
-.04
-.6**
.06
.63**

.13
.30**
.32**
-.02
-.23*
-.01
-.27**
-.16
-.03
.15
-.23*
.06
-.03
-.19
-.01
-.23*
-.19
.21*
-.41**
.01
-.02
.07
.24*
.18
.05
.02
.05
-.07
.24*
.04
-.30**
.06
-.42**
-.12
.21*
-.04
-.06
.18
.28**
.27**
.15
-.18
.04
.28**

.00
-.14
.14
.03
.00
.23*
-.26*
-.08
.23*
-.11
-.04
.05
-.17
.01
-.14
-.29**
.06
-.12
-.17
.00
.32**
-.02
.01
-.11
.06
-.17
-.22*
-.31**
-.17
.05
-.28**
-.07
-.15
-.26*
-.22*
.24*
-.31**
-.07
-.11
-.17
.30**
-.12
-.05
.20

.05
-.02
.03
-.11
.00
.11
-.01
.02
.10
-.03
.14
.08
.24*
-.05
.20*
-.04
.04
.07
.21*
.02
-.06
.20
-.08
.03
-.02
.02
.02
-.10
-.07
.06
.12
.26*
.25*
.03
-.05
-.20
.06
-.10
.03
-.08
-.14
-.32**
.06
.29**

-.13
.07
.00
-.05
-.09
.01
-.13
-.15
-.01
-.02
-.02
.05
.07
-.13
.01
-.08
-.12
-.03
-.16
.02
-.10
.10
.01
-.05
.17
.04
.13
-.18
-.06
-.14
-.07
.15
-.17
-.10
.04
-.15
.04
.09
.21*
.06
.04
-.22*
.07
.22*

-.20
-.49**
.03
.30**
.03
.24*
-.14
-.17
.13
-.31**
-.12
.03
.04
.04
-.08
-.19
.03
-.01
-.21*
-.22*
.34**
-.10
-.13
-.44**
.09
-.07
-.13
-.25*
-.39**
.05
-.23*
-.09
-.25*
-.18
-.49**
.25*
-.17
-.21*
-.15
-.51**
.26*
-.03
-.08
.10

-.24*
-.56**
-.15
.24*
.15
.20*
.00
-.05
.10
-.43**
-.03
-.03
.03
.20*
-.13
-.07
.04
-.23*
-.08
-.14
.29**
-.26*
-.24*
-.49**
.24*
-.09
-.14
-.18
-.47**
.14
-.17
-.27**
-.13
-.15
-.48**
.30**
-.15
-.24*
-.19
-.61**
.15
-.03
-.11
.07

Self-reports
Agree Consc
-.17
-.30**
.04
.19
.07
.08
.20*
.16
.15
-.10
.26**
-.08
.29**
.20
.05
.13
.29**
-.20
.23*
-.18
.03
-.10
-.22*
-.16
-.03
.05
.07
-.05
-.16
-.07
.19
-.06
.18
.12
-.19
-.01
.12
-.18
-.15
-.28**
.05
-.18
-.05
.18

-.19
-.30**
-.09
-.03
-.02
.00
.12
-.01
.09
-.19
.04
.02
.12
.18
.16
.07
-.03
-.06
.01
-.11
.01
-.09
-.06
-.25*
-.02
.05
.01
.05
-.27**
.23*
.05
-.09
.02
.03
-.23*
.19
.06
.01
-.05
-.29**
.14
-.05
.03
.03

Open
.13
.10
-.04
.08
-.23*
-.06
-.17
-.20*
-.09
-.05
-.14
.02
-.22*
-.08
-.11
-.19
-.07
.01
-.08
-.12
.05
.03
-.15
.10
.17
-.28**
-.19
-.26**
.05
.11
-.21*
.04
-.08
-.14
.04
.03
-.21*
.23*
-.03
.06
.05
-.03
.31**
.06

Table 10: Pearsons correlation coefficients LIWC features personality ratings
EAR dataset, based analysis Mehl et al. (2006) (* = significant
p < .05 level, ** = p < .01). features correlate significantly
least one trait shown.
3.4 Statistical Models
Various systems require different levels granularity modelling personality: might
important cluster users large groups correctly possible, system
might need discriminate individual users. Depending application
adaptation capabilities target system, possible use different types personality
models, depending whether personality modelling treated classification problem,
472

fiRecognising Personality Conversation Text

Dataset
Trait
Prosody
Int-max
Int-mean
Int-stddev
Pitch-max
Pitch-mean
Pitch-min
Pitch-stddev
Voiced
Word-per-sec
MRC
AOA
Brown-freq
Conc
Fam
Imag
K-F-freq
K-F-ncats
K-F-nsamp
Meanc
Nlet
Nphon
Nsyl
T-L-freq
Utterance
type
Assertion
Command
Prompt
Question

Extra

Observer reports
Emot
Agree Consc

Open

Extra

Emot

Self-reports
Agree Consc

.42**
.32**
.40**
.28**
.17
-.17
-.13
.23*
.07

.12
.20
.03
.10
-.45**
-.23*
.13
.27**
-.14

.07
-.02
-.08
.13
.06
-.02
.07
.06
-.12

-.13
-.06
-.12
.05
.04
.08
.03
.03
-.04

.05
.04
-.08
.23*
-.18
-.04
.11
.21*
-.17

.19
.21*
.36**
-.03
.12
.09
-.28**
-.02
.20*

.10
.22*
.28**
-.11
-.25*
-.08
.01
.07
.07

-.25*
-.05
.00
-.10
.07
.21*
-.34**
-.04
.09

-.01
-.16
-.06
-.03
.03
.04
.03
-.03
.02

.14
.03
.10
.01
-.04
.08
-.03
.03
.04

-.23*
-.26*
.24*
-.17
.33**
-.27**
-.24*
-.24*
.29**
-.14
-.12
-.16
-.24*

.01
-.41**
-.05
-.28**
.00
-.04
-.24*
-.20*
-.10
.17
.09
-.04
-.06

.26**
-.08
-.20*
-.24*
-.23*
.07
-.03
-.03
-.18
.25*
.25*
.23*
.06

.26**
.07
-.33**
-.07
-.33**
.17
.08
.16
-.25*
.31**
.36**
.34**
.16

.21*
-.16
-.32**
-.18
-.35**
.16
.00
.20
-.34**
.25*
.28**
.19
.13

-.12
-.04
.23*
-.03
.25*
-.22*
-.01
-.15
.23*
-.23*
-.16
-.13
-.19

.04
-.15
-.10
-.21*
-.09
-.06
-.06
-.04
-.12
.03
.02
-.02
-.07

.05
.14
.01
.17
.01
-.24*
.17
.03
.08
-.18
-.20
-.06
-.18

-.05
.07
-.12
.01
-.06
.05
.05
.08
-.06
.13
.15
.12
.06

.08
-.12
-.02
-.13
-.03
-.01
-.23*
-.17
-.07
.12
.13
.10
-.08

-.05
.00
-.10
.13

-.21*
.01
.07
.22*

-.03
-.08
.36**
-.16

.01
-.20*
.27**
-.11

-.09
.00
.25*
-.04

-.02
.13
-.05
.01

-.06
.21*
.01
-.01

-.09
-.01
.22*
-.02

.21*
.00
-.05
-.24*

-.14
.16
.02
.10

Open

Table 11: Continuation Table 10, i.e. Pearsons correlation coefficients features
personality ratings EAR dataset (* = significant p < .05 level,
** = p < .01). features correlate significantly least one trait
shown.
previous work Argamon et al. (2005) Oberlander Nowson (2006), whether
model personality traits via scalar values actually generated self-reports
observer methods used corpus collection described Section 3.1.
support applications dialogue system adaptation, output generation
limited points extremes personality scale, introvert vs. extravert
language neurotic vs. emotionally stable, develop classification models splitting
subjects two equal size groups.
However, model personality traits scalar values, two choices.
treat personality modelling regression problem ranking problem.
regression models replicate actual scalar values seen personality ratings
data, also good argument treating personality ranking problem
definition, personality evaluation assesses relative differences individuals, e.g.
one person described extravert average population not. Moreover,
Freund, Iyer, Schapire, Singer (1998) argue ranking models better fit
learning problems scales arbitrary values (rather reflecting real world
measures).
473

fiMairesse, Walker, Mehl & Moore

classification regression models, use Weka toolbox (Witten & Frank,
2005) training evaluation. order evaluate models personality classification,
compare six different learning algorithms baseline returning majority class.
classification algorithms analysed C4.5 decision tree learning (J48), Nearest
neighbour (k = 1), Naive Bayes (NB), Ripper (JRip), Adaboost (10 rounds boosting)
Support vector machines linear kernels (SMO).
regression, compare five algorithms baseline model returning mean
personality score. focus linear regression model, M5 regression tree, M5
model tree returning linear model, REPTree decision tree, model based Support
vector machines linear kernels (SMOreg). Parameters algorithms set
Wekas default values.
Concerning ranking problem, train personality models Big Five trait
using RankBoost, boosting algorithm ranking (Freund et al., 1998; Schapire, 1999).
Given personality trait model, linguistic features personality scores converted training set ordered pairs examples x, y:
= {(x, y)| x, language samples two individuals,
x higher score personality trait}
example x represented set indicator functions hs (x) 1 m.
indicator functions calculated thresholding feature values (counts) described
Section 3.2. example, one indicator function is:
(

h100 (x) =

1 Word-per-sec(x) 0.73
0 otherwise

h100 (x) = 1 xs average speech rate 0.73 words per second. single parameter associated indicator function, ranking score example
x calculated
X
F (x) =
hs (x)


score used rank various language samples (written text conversation extracts),
goal duplicating ranking found training data, training examples used set parameter values . Training process setting
parameters minimise following loss function:
Loss =

1 X
eval(F (x) F (y))
|T | (x,y)T

eval function returns 1 ranking scores (x, y) pair misordered, 0
otherwise. words, ranking loss percentage misordered pairs,
order predicted scores doesnt match order dictated personality scores
questionnaire.
techniques used work express learned models rules decision
trees, support analysis differences personality models (see Sections 4.3,
5.3 6.3).
474

fiRecognising Personality Conversation Text

4. Classification Results
evaluate binary classification models based essays corpus self-reports
personality, well models based EAR corpus self observer reports.
results averaged 10-fold cross-validation, significance tests done
using two-tailed paired t-test p < .05 level.
4.1 Essays Corpus
Classification results essays corpus self-reports Table 12. Interestingly,
openness experience easiest trait model five classifiers six significantly
outperform baseline four produce best performance trait,
accuracies 62.1% using support vector machines (SMO). Emotional stability
produces second best performance four classifiers six, 57.4% accuracy
SMO model. Conscientiousness hardest trait model two classifiers
significantly outperform baseline, however SMO model performs well best
model extraversion agreeableness, around 55% correct classifications.
find support vector machines generally perform best, Naive Bayes
AdaboostM1 second position. SMO significantly outperforms majority class baseline
trait. J48 decision tree recognising extraversion shown Figure 1,
rule-based JRip model classifying openness experience 58.8% accuracy illustrated
Table 16.

Trait
Base J48
NN
NB
JRIP
Extraversion
50.04 54.44 53.27 53.35 52.70
Emotional stability
50.08 51.09
51.62
56.42 55.90
Agreeableness
50.36 53.51 50.16
53.88 52.63
Conscientiousness
50.57 51.37
52.10
53.80
52.71
Openness experience 50.32 54.24 53.07
59.57 58.85
statistically significant improvement majority
baseline (two-tailed paired t-test, p < .05)

ADA
55.00
55.98
52.71
54.45
59.09
class

SMO
54.93
57.35
55.78
55.29
62.11

Table 12: Classification accuracy two equal size bins essays corpus, using selfreports. Models majority class baseline (Base); J48 decision tree (J48);
Nearest neighbour (NN); Naive Bayes (NB); JRip rule set (JRIP); AdaboostM1
(ADA); Support vector machines (SMO).

Feature set comparison: order evaluate feature set contributes
final result, trained binary classifiers using algorithms producing best overall
results feature set. analyse LIWC MRC features essays
corpus, utterance type prosodic features dont apply written texts. use
Naive Bayes, AdaboostM1 SMO classifiers give best performances
full feature set. Results shown Table 13.
475

fiMairesse, Walker, Mehl & Moore

Articles
7.23

> 7.23

Sexuality

Introvert

0.12

> 0.12
Parentheses

Apostrophes
2.57

> 2.57

17.91

> 17.91


0.64

Sadness

Achievement

Words per sentence

Extravert

1.52
Introvert

> 0.64

0.64

> 1.52
Extravert

1.44
Extravert

Introvert
> 1.44
Introvert

> 0.64
Familiarity

Introvert

> 599.7

599.7

Positive emotions

Introvert

1.66

> 1.66
Grooming

Introvert
0.11

> 0.11

Extravert

Introvert

Figure 1: J48 decision tree binary classification extraversion, based essays
corpus self-reports.

Remarkably, see LIWC features outperform MRC features every
trait, LIWC features always perform slightly better full
feature set. clearly suggests MRC features arent helpful LIWC features
classifying personality written text, however Table 13 shows still
outperform baseline four traits five.
Concerning algorithms, find AdaboostM1 performs best extraversion
(56.3% correct classifications), SMO produces best models traits.
suggests support vector machines promising modelling personality general.
easiest trait model still openness experience, 62.5% accuracy using LIWC
features only.
4.2 EAR Corpus
Classification accuracies EAR corpus Table 14. find extraversion
easiest trait model using observer reports, Naive Bayes AdaboostM1
476

fiRecognising Personality Conversation Text

Feature set
None
LIWC features
MRC features
Classifier
Base
NB
ADA
SMO
NB
ADA
SMO
Set size
0
88
88
88
14
14
14
Extraversion
50.04 52.71
56.34 52.75
52.87 51.45
53.88
Emotional stability
50.08 56.02 55.33 58.20 52.39
52.06
53.52
Agreeableness
50.36 54.12 52.71
56.39 53.03 52.06
53.31
Conscientiousness
50.57 53.92 54.48 55.62 53.03
52.95
53.84
Openness experience 50.32 58.92 58.64 62.52 55.41 56.70 57.47
statistically significant improvement majority class
baseline (two-tailed paired t-test, p < .05)
Table 13: Classification accuracies two equal size bins essays corpus using
majority class baseline (Base), Naive Bayes (NB), AdaboostM1 (ADA) Support Vector Machine (SMO) classifiers, different feature sets. Best model
trait bold.

outperforming baseline accuracy 73.0%. J48 decision tree extraversion 66.8% accuracy shown Figure 2. Emotional stability modelled
comparable success using Naive Bayes classifier, however improvement baseline lower extraversion (22.8% vs. 25.2%) classifiers dont perform
well. Models observed conscientiousness also outperform baseline, 67.7% accuracy using Naive Bayes classifier, best model agreeableness produces 61.3%
correct classifications. None models openness experience significantly outperform baseline, suggests openness experience expressed clearly
stream consciousness essays self-reports EAR dataset. Support vector
machines dont perform well essays corpus, probably sparseness dataset. Self-reports much harder model observer reports given
dataset size, none self-report classifiers significantly outperform majority
class baseline.
Feature set comparison: EAR corpus investigated importance 4
feature sets: utterance type, LIWC, MRC, prosodic features. use Naive Bayes
models observer ratings perform best features. Interestingly,
Table 15 shows good classification accuracies extraversion come combination LIWC, MRC prosodic features, outperform baseline own,
dont well 73.0% accuracy full feature set. Moreover, extraversion
trait prosody seems make difference. LIWC features main
indicators emotional stability, although model features still performs better. MRC features important classifying conscientiousness (66.8%),
prosodic features produce best model openness experience 64.6% accuracy,
improving model features. Although utterance type features never outperform baseline own, lack significance could result small
1. Although equal size bins used, baseline accuracies differ 50% random
sampling cross-validation.

477

fiMairesse, Walker, Mehl & Moore

Data
Obs
Obs
Obs
Obs
Obs
Self
Self
Self
Self
Self

Trait Base J48
NN
NB
JRIP ADA
SMO
Extra 47.78 66.78 59.33 73.00 60.44
73.00 65.78
Emot 51.11 62.56 58.22 73.89 56.22
48.78
60.33
Agree 47.78 48.78 51.89 61.33 51.89
52.89
56.33
Consc 47.78 57.67 61.56 67.67 61.56
60.22 57.11
Open 47.78 52.22 46.78 57.00
49.67
50.56
55.89
Extra 47.78 48.78 49.67 57.33
50.56
54.44
49.89
Emot 51.11 45.56 46.78 50.44
46.78
41.89
44.33
Agree 52.22 47.89 50.89 58.33
56.89
55.22
52.33
Consc 51.11 33.44 45.56 39.33
43.11
46.11
53.22
Open 51.11 52.00 42.22 61.44
45.00
56.00
47.78
statistically significant improvement majority class
baseline (two-tailed paired t-test, p < .05)

Table 14: Classification accuracy two equal size bins EAR corpus, observer
ratings (Obs) self-reports (Self). Models majority class baseline (Base)1 ;
J48 decision tree (J48); Nearest neighbour (NN); Naive Bayes (NB); JRip rules
set (JRIP); AdaboostM1 (ADA); Support vector machines (SMO).

Feature set
None Type LIWC
MRC
Prosody
Set size
0
4
88
14
11
Extraversion
47.78
45.67
68.89
68.78
67.56
Emotional stability
51.11
60.22
69.89
60.78
61.78
Agreeableness
47.78
57.56
54.00
58.67
50.44
Conscientiousness
47.78
59.67
60.22
66.78
52.11
Openness experience 47.78
53.11
61.11
54.00
64.56
statistically significant improvement majority class
baseline (two-tailed paired t-test, p < .05)
Table 15: Classification accuracies EAR corpus observer reports using Naive
Bayes classifier, different feature sets (None=baseline, Type=utterance type).
Models performing better full feature set bold.

dataset size, since Section 3.3 showed utterance type features strongly correlate
several personality traits.
4.3 Qualitative Analysis
Decision trees rule-based models easily understood, therefore help
uncover new linguistic markers personality. models replicate previous findings,
link verbosity extraversion (c.f. Word count node Figure 2),
also provide many new markers.
478

fiRecognising Personality Conversation Text

Word count
1284

> 1284
Extravert

Metaphysical issues
0.25

> 0.25

Commas
8.72

Articles
> 8.72

Eating

Extravert

3.51

> 3.51

Extravert

Space

0.51

> 0.51

3.22

Introvert

Sad

Extravert

> 3.22
Frequency use

0.15

> 0.15

6072

Introvert

Extravert

Extravert

> 6072
Introvert

Figure 2: J48 decision tree binary classification extraversion, based EAR corpus
observer reports.

#
1
2
3
4
5
6

Ordered rules
(School 1.47) (Motion 1.71) open
(Occup 2.49) (Sixltr 13.11) (School 1.9) (I 10.5) open
(Fam 600.335106) (Friends 0.67) open
(Nlet 3.502543) (Number 1.13) open
(School 0.98) (You 0) (AllPct 13.4) open
feature values Open

Table 16: JRip rule set binary classification openness experience, based
essays corpus.

model self-assessed openness experience detailed Table 16 shows students referring lot school work tend low scores trait (Rules 1, 2
5). expected, avoidance longer words also indicative lack cre479

fiMairesse, Walker, Mehl & Moore

ativity/conventionality (Rules 4 5), well use high-familiarity words
references friends (Rule 3).
model observed extraversion Figure 2 shows word count important feature classifying trait observer. model also suggests given
low verbosity, extraversion still manifest use words related metaphysical issues together articles, well use many commas.
association extraversion avoidance articles probably reflects use
pronouns common nouns confirms previous findings associating extraversion
implicit language (Heylighen & Dewaele, 2002).
Interestingly, decision tree trained essays corpus Figure 1 self-reported
extraversion differs lot observer model Figure 2. word count
important feature observers, doesnt seem marker self-assessed extraversion
(see Section 3.3), although number words per sentence used discriminate
subset data. hand, self-report model associates introversion
use articles, also case observer model. sexual content
doesnt affect observer model, second important feature modelling selfreported extraversion. example, participants using many sex-related words modelled
introvert, unless avoid parentheses words related sadness.

5. Regression Results
also trained regression models using corpora. baseline model returning
mean personality scores training set. use relative absolute error
evaluation, ratio models prediction error error produced
baseline. low relative error therefore indicates model performs better
constant mean baseline, 100% relative error implies performance equivalent
baseline. results averaged 10-fold cross-validation, significance
tests done using two-tailed paired t-test p < .05 level.
5.1 Essays Corpus
Regression results essays corpus self-reports Table 17. Paired t-tests
show emotional stability openness experience produce models significantly
improve baseline. classification task, openness experience
easiest trait model using essays: four regression models five outperform baseline. M5 model tree produces best result 93.3% relative error openness
experience (6.7% error decrease), 96.4% relative error emotional stability.
terms correlation model predictions actual ratings, model
emotional stability openness experience produce Pearsons correlation coefficients
0.24 0.33, respectively. Although magnitude improvement seems relatively
small, one needs keep mind difficulty regression task binary classification task: fine-grained personality recognition problem, requiring
association exact scalar value individual.
Feature set comparison: Table 18 provides results comparison LIWC
MRC feature sets using linear regression model, M5 model tree support
480

fiRecognising Personality Conversation Text

Trait
Base
LR
M5R
M5
REP
Extraversion
100.00 99.17
99.31
99.22
99.98
Emotional stability
100.00 96.87
99.75
96.43
99.35
Agreeableness
100.00 98.92
99.86
99.22
99.78
Conscientiousness
100.00 98.68
100.62
98.56
100.47
Openness experience 100.00 93.58
97.68 93.27
99.82
statistically significant improvement mean value
baseline (two-tailed paired t-test, p < .05)

SMO
100.65
98.35
100.28
99.30
94.19

Table 17: Relative error regression models trained essays corpus features.
Models mean value baseline (Base), linear regression (LR); M5 regression tree (M5R), M5 model tree linear models (M5), REPTree (REP)
Support vector machines regression (SMO).

vector machine algorithm regression (SMOreg). Overall, LIWC features perform better
MRC features except extraversion, linear regression model
MRC features produces better results full feature set. traits,
LIWC features perform better full feature set, almost always
significantly outperform baseline. model openness experience produces
lowest relative error, 6.50% improvement baseline.
Feature set
None
LIWC features
MRC features
Regression model
Base
LR
M5
SMO
LR
M5
SMO
Extraversion
100.00 99.39
99.25 100.8
98.79 98.79 99.13
Emotional stability
100.00 96.71 96.42 98.03
99.49
99.54
99.89
Agreeableness
100.00 98.50 98.52 99.52
99.75
99.81
99.31
Conscientiousness
100.00 98.23 98.14 99.46
99.23
99.23
99.16
Openness experience 100.00 93.50 93.70 94.14 97.44 97.44 97.26
statistically significant improvement mean value
baseline (two-tailed paired t-test, p < .05)
Table 18: Relative error regression models trained essays corpus MRC
LIWC feature sets only. Models linear regression (LR); M5 model tree
(M5); Support vector machines regression (SMO). Best models bold.

5.2 EAR Corpus
Regression results EAR corpus Table 19. paired t-test (two-tailed, p < .05)
cross-validation folds shows error reduction significant observed
extraversion (79.9% relative error, i.e. 20.1% error decrease), conscientiousness (14.3% improvement) emotional stability (13.3% improvement). extraversion easiest
trait model observer ratings, models agreeableness openness experience
dont outperform baseline.
481

fiMairesse, Walker, Mehl & Moore

terms correlation model predictions actual ratings, models
extraversion, emotional stability conscientiousness respectively produce Pearsons
correlation coefficients 0.54, 0.47 0.44, significantly outperforming baseline.
correlations relatively high, given average correlations ratings
pair observers 0.54 extraversion, 0.29 emotional stability 0.51
conscientiousness (18 observers, 31 33 data points pair).
Linear regression support vector machines perform poorly, suggesting
require bigger dataset essays corpus. classification task, self-reports
EAR corpus clearly difficult model: none models show significant
improvement baseline.

Data
Obs
Obs
Obs
Obs
Obs
Self
Self
Self
Self
Self

Trait
Base
LR M5R
M5
REP
Extraversion
100.00 179.16
82.16
80.15
79.94
Emotional stability
100.00 302.74
92.03
86.75 100.51
Agreeableness
100.00 242.68
96.73
111.16
99.37
Conscientiousness
100.00 188.18
82.68
90.85
98.08
Openness experience 100.00 333.65 101.64
119.53
102.76
Extraversion
100.00 204.96 104.50
118.44
99.94
Emotional stability
100.00 321.97 104.10
108.39
99.91
Agreeableness
100.00 349.87 106.90
110.84
101.64
Conscientiousness
100.00 177.12 103.39
120.29
107.33
Openness experience 100.00 413.70 107.12
122.68
126.31
statistically significant improvement mean value
baseline (two-tailed paired t-test, p < .05)

SMO
140.05
162.05
173.97
131.75
213.20
176.51
233.19
201.80
124.91
233.01

Table 19: Relative error regression models, observer ratings (Obs) self-reports
(Self) EAR corpus. Models mean value baseline (Base); linear
regression (LR); M5 regression tree (M5R); M5 model tree linear models
(M5); REPTree decision tree (REPT); Support vector machines regression
(SMO). relative error baseline model 100%.

Feature set comparison: trained regression models individual feature set
using observer reports, since self-reports didnt produce significant result using
features. focus three regression tree algorithms perform best
features. Table 20 shows LIWC good predictors observed extraversion,
REPTree outperforms model features 76.4% relative error
(23.6% improvement baseline). LIWC features also produce best regression
model conscientiousness (82.1% relative error, 17.9% improvement). Surprisingly,
best model emotional stability contains prosodic features, 85.3% relative
error (14.7% improvement). finding suggests speech cues crucial
perception neuroticism, could explain Gill Oberlander (2003) reported
low correlation self-assessed observed emotional stability using text only.
482

fiRecognising Personality Conversation Text

classification task, utterance type features dont show significant improvement
own.
Set
Model
Extra
Emot
Agree
Consc
Open

Utterance type
LIWC features
MRC features
M5R
M5
REP
M5R
M5
REP
M5R
M5
REP
100.0
103.7
101.8
81.61
77.84
76.38
99.23
102.2
99.69
102.5
103.0
102.6
90.79
109.6
109.6
93.13
96.08
104.4
102.4
102.7
111.1
98.49
111.7
102.5
104.1
112.5
102.2
100.0
95.04
104.1
82.13
96.62
93.50
97.00
102.0
91.24
101.1
99.03
109.9
105.1
129.5
103.7
106.2
111.6
105.5
statistically significant improvement mean value
baseline (two-tailed paired t-test, p < .05)

Prosodic features
M5R
M5
REP
94.07
90.91
88.31
92.24
85.32
97.95
100.0
108.4
108.9
100.0
104.7
101.7
100.1
113.5
99.93

Table 20: Relative error regression models trained EAR corpus individual
feature sets. Models M5 regression tree (M5R); M5 model tree linear
models (M5); REPTree regression tree (REP). Best models bold.

5.3 Qualitative Analysis
Regression trees extraversion conscientiousness Figures 3 4. suggested
correlations Section 3.3, model Figure 3 shows voices pitch
variation intensity play important role modelling extraversion. high verbal
output perceived sign extraversion (see Word Count nodes), confirming previous
findings (Scherer, 1979). hand, low mean pitch combined constant
voice intensity characterises high introverts.
Figure 4 suggests conscientious people use fewer swear words content related
sexuality, preferring longer words. figure also shows conscientious
people use fewer pronouns, i.e. explicit style, well words related
communication (e.g., talk share).

6. Ranking Results
Results corpora different feature sets Tables 21 22. models
trained 100 rounds boosting. baseline model ranks extracts randomly,
producing ranking loss 0.5 average (lower better). Results averaged
10-fold cross-validation, significance tests done using two-tailed paired t-test
p < .05 level.
6.1 Essays Corpus
Table 21 shows openness experience produces best ranking model
essays corpus, producing ranking loss 0.39 (lower better). Remarkably, trait
easiest model three recognition tasks corpus.
case conversational data, seems streams consciousness, generally
personal writings, likely exhibit cues relative authors openness experience.
Emotional stability produces second best model ranking loss 0.42, followed
conscientiousness extraversion, model agreeableness produces highest
483

fiMairesse, Walker, Mehl & Moore

Word count
675

> 675
Word count

Mean pitch
231

> 231

Intensity variation
6.39
2.86

3.23

1299

> 1299

3.83

4.24

> 6.39
3.02

Figure 3: M5 regression tree observed extraversion, computed using EAR corpus.
target output ranges 1 5.5, 5.5 means strongly extravert (the
highest value means observer ratings). mean pitch value
expressed Hertz, intensity variation (standard deviation) decibels.

ranking loss. models significantly outperform random ranking baseline,
actual improvement still relatively small.
Feature set
Base
LIWC MRC
Extraversion
0.50 0.44 0.44
0.46
Emotional stability
0.50 0.42 0.42
0.47
Agreeableness
0.50 0.46 0.46
0.48
Conscientiousness
0.50 0.44 0.44
0.47
Openness experience 0.50 0.39 0.39
0.44
statistically significant improvement
random ordering baseline
(two-tailed paired t-test, p < .05)
Table 21: Ranking loss essays corpus 10-fold cross-validation different
feature sets random ordering baseline (Base). Best models bold
(lower better).

Feature set comparison: evaluate features contribute ranking accuracy,
trained ranking model feature set. Table 21 clearly shows LIWC
features contributors model accuracy, inclusion MRC features
doesnt reduce ranking loss trait.
484

fiRecognising Personality Conversation Text

Swear words
0.93

> 0.93
Sexuality words

Pronouns
16.7
4.01

> 16.7
3.63

0.62
Comm. words

1.46
3.15

> 1.46
3.26

> 0.62
Syllables per word
> 1.14

1.14
2.90

Body states words

0.59
2.96

> 0.59
2.98

Figure 4: M5 regression tree observed conscientiousness, computed using EAR corpus. target output ranges 1 7, 7 means strongly conscientious
(Comm. words ratio words related communication).

6.2 EAR Corpus
Concerning EAR corpus, Table 22 reporting experiments using features, shows
models extraversion, agreeableness, conscientiousness, openness experience
better random ranking baseline. Emotional stability difficult trait
model, agreeableness conscientiousness produce best results, ranking
losses 0.31 0.33 respectively.
Feature set
None

LIWC MRC Type
Extraversion
0.50
0.35 0.36
0.45
0.55
Emotional stability
0.50
0.41
0.41
0.39
0.43
Agreeableness
0.50 0.31 0.32
0.44
0.45
Conscientiousness
0.50 0.33 0.36
0.41
0.44
Openness experience
0.50
0.38 0.37
0.41
0.49
statistically significant improvement random
ordering baseline (two-tailed paired t-test, p < .05)

Prosody
0.26
0.45
0.54
0.55
0.44

Table 22: Ranking loss EAR corpus observer reports1 10-fold crossvalidation different feature sets (None=baseline, Type=utterance type). Best
models bold (lower better).

485

fiMairesse, Walker, Mehl & Moore

Feature set comparison: looking individual feature sets, Table 22 shows
LIWC features perform significantly better baseline dimensions emotional stability, emotional stability best predicted MRC features (0.39
ranking loss). Interestingly, prosodic features good predictors extraversion,
lower ranking error full feature set (0.26). model produces best overall
result, 74% chance model detect extravert among two
unseen conversation extracts. previous recognition tasks, utterance type features
never significantly outperform baseline.
6.3 Qualitative Analysis
RankBoost rules indicate impact feature recognition personality
trait magnitude parameter associated feature. Tables 23
25 show rules impact best models, associated
values. feature labels Table 6. example, model extraversion Table 23
confirms previous findings associating trait longer conversations (Rule 5),
high speech rate (Rules 1 4) high pitch (Rules 2, 6 7) (Nass & Lee, 2001).
new markers emerge, high pitch variation introverts (Rules 15, 18
20), contradicting previous findings reported Scherer (1979).
Extraversion model prosodic features
# Positive rules

# Negative rules
1 Word-per-sec 0.73 1.43 11 Pitch-max 636.35
2 Pitch-mean 194.61 0.41 12 Pitch-slope 312.67
3 Voiced 647.35
0.41 13 Int-min 54.30
4 Word-per-sec 2.22 0.36 14 Word-per-sec 1.69
5 Voiced 442.95
0.31 15 Pitch-stddev 115.49
6 Pitch-max 599.88
0.30 16 Pitch-max 637.27
7 Pitch-mean 238.99 0.26 17 Pitch-slope 260.51
8 Int-stddev 6.96
0.24 18 Pitch-stddev 118.10
9 Int-max 85.87
0.24 19 Int-stddev 6.30
10 Voiced 132.35
0.23 20 Pitch-stddev 119.73


-0.05
-0.06
-0.06
-0.06
-0.06
-0.06
-0.12
-0.15
-0.18
-0.47

Table 23: Subset RankBoost model extraversion prosodic features only,
based EAR conversations observer reports. Rows 1-10 represent rules
producing highest score increase, rows 11-20 indicate evidence
end scale, i.e. introversion.

Concerning agreeableness, Rules 1 20 Table 24 suggest agreeable people
use longer words shorter sentences, Rules 2 4 show express
tentativity (with words like maybe perhaps) positive emotions (e.g., happy good).
Anger swear words greatly reduce agreeableness score (Rules 12, 13, 18 19),
well use negations (Rule 15).
1. also built models self-reports personality based EAR corpus, none significantly
outperforms baseline.

486

fiRecognising Personality Conversation Text

Agreeableness model features
# Positive rules

# Negative rules
1 Nphon 2.66
0.56 11 Fam 601.61
2 Tentat 2.83
0.50 12 Swear 0.41
3 Colon 0.03
0.41 13 Anger 0.92
4 Posemo 2.67 0.32 14 Time 3.71
5 Voiced 584
0.32 15 Negate 3.52
6 Relig 0.43
0.27 16 Fillers 0.54
7 Insight 2.09
0.25 17 Time 3.69
8 Prompt 0.06 0.25 18 Swear 0.61
9 Comma 4.60 0.23 19 Swear 0.45
10 Money 0.38
0.20 20 WPS 6.13


-0.16
-0.18
-0.19
-0.20
-0.20
-0.22
-0.23
-0.27
-0.27
-0.45

Table 24: Best RankBoost model based EAR conversations agreeableness. Rows
1-10 represent rules producing highest score increase, rows 11-20
indicate evidence end scale, i.e. disagreeableness.

Table 25 shows conscientious people talk lot work (Rule 1),
unconscientious people swear lot (Rules 19). Insight words (e.g., think know)
also good indicator conscientiousness, well words expressing positive feelings like
happy love (Rule 2 3). Interestingly, conscientious people modelled
high variation voice intensity (Rule 4). hand, Rule 20 shows
speaking loud produces opposite effect, well high pitch (Rule 13).
Long utterances also indicative low conscientiousness (Rule 12).
rule sets presented contain extreme rules ranking models,
contain many additional personality cues arent identified typical
correlational analysis. example, high speech rate high mean pitch tend
contribute high extraversion ranking Table 23s model, dont correlate
significantly observer ratings, detailed Table 11. Similarly, positive emotion
words (Posemo) avoidance long utterances (WPS) indicate agreeableness
model Table 24, features dont correlate significantly agreeableness
ratings.

7. Related Work
knowledge, two studies automatic recognition personality. studies focused classification written texts based
self-reports, rather using continuous modelling techniques here.
Argamon et al. (2005) use essays corpus Pennebaker King (1999),
results directly comparable ours. work, use top-down approach
feature definition: feature set consists relative frequencies 675 function words
word categories based networks theory Systemic Functional Grammar. However,
simplify task removing middle third dataset, thereby potentially
increasing precision cost reducing recall maximum 67%. train SMO
models top third lower third essays corpus two personality traits
487

fiMairesse, Walker, Mehl & Moore

Conscientiousness model
# Positive rules

#
1 Occup 1.21
0.37 11
2 Insight 2.15
0.36 12
3 Posfeel 0.30
0.30 13
4 Int-stddev 7.83 0.29 14
5 Nlet 3.29
0.27 15
6 Comm 1.20
0.26 16
7 Nphon 2.66
0.25 17
8 Nphon 2.67
0.22 18
9 Nphon 2.76
0.20 19
10 K-F-nsamp 329 0.19 20

features
Negative rules
Swear 0.20
WPS 6.25
Pitch-mean 229
Othref 7.64
Humans 0.83
Swear 0.93
Swear 0.17
Relig 0.32
Swear 0.65
Int-max 86.84


-0.18
-0.19
-0.20
-0.20
-0.21
-0.21
-0.24
-0.27
-0.31
-0.50

Table 25: Best RankBoost model based EAR conversations conscientiousness. Rows
1-10 represent rules producing highest score increase, rows 11-20
indicate evidence end scale, i.e. unconscientiousness.

extraversion emotional stability, achieving accuracies subset data
58% traits.
believe likely personality recognition models need based full
range values useful practical application. Nevertheless, order
direct comparison, also removed middle third essays dataset trained
SMO classifier LIWC features. obtain 57% classification accuracy extraversion 60% emotional stability, whereas algorithm applied
whole corpus, obtain accuracies 55% extraversion 57% emotional stability,
significantly outperforming baseline (see Table 12). Using EAR conversational data
observer reports, accuracies SMO models remain 65% extraversion
increase 63% emotional stability (see Table 14).
results suggest feature set combination Argamon et al.
could possibly improve performance, feature sets perform comparably. Using
features, Argamon et al. identify relative frequencies set function words
best predictor extraversion, suggesting refer norms certainty
salient. Concerning emotional stability, feature set characterising appraisal
produces far best results. Appraisal features relative frequencies positive
negative words well frequencies category Attitude network (e.g., affect,
appreciation, judgement, etc.). find neurotics tend use words related
negative appraisal affect, fewer appreciation appraisal words, suggesting
focus personal feelings.
Oberlander Nowson (2006) follow bottom-up feature discovery method training Naive Bayes SMO models four Big Five traits corpus personal
weblogs, using n-gram features extracted dataset. order able compare
Argamon et al., report experiments remove texts non-extreme
personality scores corpus, also report experiments applying classification
algorithms seven different ways partitioning whole corpus classes, motivated
approximating continuous modelling approach. Although, results arent directly
488

fiRecognising Personality Conversation Text

comparable based different corpora, report results
use instances dataset, believe discarding test data increases
precision cost making recall unacceptably low.
building Naive Bayes models using frequent bi-grams tri-grams
computed full corpus, Oberlander Nowson (2006) find model agreeableness one outperforming baseline (54% accuracy, level significance
mentioned). keeping n-grams distinctive two extreme sets given
trait, accuracies range 65% extraversion 72% emotional stability. Finally,
applying automatic feature selection algorithm filtered set, accuracies increase range 83% emotional stability 93% agreeableness. testing
whether models generalise different corpus weblogs, Nowson Oberlander
(2007) report binary classification accuracies ranging 55% extraversion 65%
conscientiousness. Interestingly, models trained extreme instances
original corpus seem outperform models trained full corpus, although level
significance mentioned. studies show careful feature selection greatly improves
classification accuracy, n-grams appropriate model self-reports personality, although, Oberlander Nowson point out, features likely overfit.
would therefore interesting test future work whether feature sets used
generalise another dataset.
Oberlander Nowson (2006) also report results 3-way 5-way classification,
order approximate finer-grained continuous personality ratings used psychology
(as scalar models present here). obtain maximum 44.7%
extraversion 5 bins, using raw n-grams (baseline 33.8%). results
directly comparable different corpus, different feature
sets. Moreover, provided results multiple classification experiments,
models cannot take account fact different classes part
total ordering, thus resulting models forced ignore importance
features correlate ordering across classes. believe regression
ranking models appropriate finer-grained personality recognition (see Sections
5 6).
evaluate claim, first mapped output best classifier ranking
compared RankBoost models. trained Naive Bayes classifier EAR
corpus observer reports features, using 5 equal size bins.2 test fold
10-fold cross-validation, computed ranking loss produced classifier based
ordering five classes. Results Table 26 show RankBoost significantly
outperforms classifier four traits five (p < .05), improvement close
significance emotional stability (p = 0.12).
RankBoosts goal minimise ranking loss, comparison likely
favour ranking models. Therefore, also mapped output RankBoost models
5 classification bins see whether RankBoost could perform well classifier
classification task. divided output ranking 5 bins, containing 20%
slice contiguously ranked instances. Results Table 26 show Naive Bayes
classifier never outperforms RankBoost significantly, ranking model produces
2. Oberlander Nowson use unequal bins defined personality trait using standard deviation
mean, may easier task equal size bins.

489

fiMairesse, Walker, Mehl & Moore

Task
Ranking
Classification
Model
Base NB Rank Base NB Rank
Extraversion
0.50 0.48 0.35
20.0 32.3
32.1
Emotional stability
0.50 0.50 0.41
20.0 21.9
21.9
Agreeableness
0.50 0.50 0.31
20.0 28.4
37.8
Conscientiousness
0.50 0.46 0.33
20.0 34.7
30.3
Openness experience 0.50 0.53 0.38
20.0 19.8
26.8
statistically significant improvement
model (two-tailed t-test, p < .05)
Table 26: Comparison ranking (Rank) classification models (NB) personality ranking classification tasks (5 bins). Evaluation metrics ranking
loss (lower better) classification accuracy (higher better), respectively.
Results averaged 10-fold cross-validation.

better mean accuracy agreeableness (38%) openness experience (27%),
accuracy emotional stability (22%). sum, find ranking models perform
well classification better ranking compared best classifier, thus
modelling personality using continuous models accurate.

8. Discussion Future Work
show personality recognised computers language cues.3
recent work AI explores methods automatic detection types pragmatic
variation text conversation, opinion, emotion, deception, date,
know two studies besides automatic recognition user personality (Argamon et al., 2005; Mairesse & Walker, 2006a, 2006b; Oberlander & Nowson, 2006).
knowledge, results presented first demonstrate statistically significant
results texts recognise personality conversation (Mairesse & Walker, 2006a,
2006b). present first results applying regression ranking models order
model personality recognition using continuous scales traditional psychology.
also systematically examine use different feature sets, suggested previous psycholinguistic research. Although features suggested psycholinguistic
literature, reported correlations personality ratings generally weak:
obvious would improve accuracies statistical models unseen subjects.
Computational work modelling personality primarily focused methods
expressing personality virtual agents tutorial systems, concepts related personality politeness, emotion, social intelligence (Walker, Cahn, & Whittaker,
1997; Andre, Klesen, Gebhard, Allen, & Rist, 1999; Lester, Towns, & FitzGerald, 1999;
Wang, Johnson, Mayer, Rizzo, Shaw, & Collins, 2005) inter alia. Studies shown
user evaluations agent personality depend users personality (Reeves & Nass,
1996; Cassell & Bickmore, 2003), suggesting ability model users personality
3. online demo personality recognition tool based models presented paper
downloaded www.dcs.shef.ac.uk/cogsys/recognition.html

490

fiRecognising Personality Conversation Text

required. Models present automatic recognition user personality
one way acquire user model (Chu-Carroll & Carberry, 1994; Thompson, Goker,
& Langley, 2004; Zukerman & Litman, 2001). plan test models user models
context adaptive dialogue system.
Table 27 summarises results personality traits recognition tasks
analysed. clearly emerges extraversion easiest trait model
spoken language, followed emotional stability conscientiousness. Concerning written language, models openness experience produce best results recognition
tasks. also see feature selection important, best models
contain small subset full feature set. Prosodic features important modelling observed extraversion, emotional stability openness experience. MRC features
useful models emotional stability, LIWC features beneficial traits.
also analysed qualitatively features influence specific models,
recognition tasks, well reporting correlations feature personality
traits Section 3.3.
Although parameters algorithms optimised, bottom
Table 27 seems indicate simple models like Naive Bayes regression trees tend
outperform complex ones (e.g., support vector machines), confirming results
Oberlander Nowson (2006). However, experiments larger essays corpus
(more 2,400 texts) show support vector machines boosting algorithms produce higher classification accuracies. therefore likely algorithms would also
perform better spoken data trained much larger corpus EAR
dataset, parameters optimised.
hypothesised models observed personality outperform models selfassessed personality. results suggest observed personality may easier
model self-reports, least conversational data. EAR corpus, find many
good results models observed personality, models self-assessed personality
never outperform baseline. may due objective observers using similar cues
models, self-reports personality may influenced factors
desirability trait (Edwards, 1953). Hogan (1982) introduced distinction
agents observers perspective personality assessment. agents
perspective conceptually taps persons identity (or personality inside),
observers perspective contrast taps persons reputation (or personality
outside). facets personality important psychological implications. persons
identity shapes way person experiences world. persons reputation, however,
psychologically less important: determines whether people get hired fired (e.g.,
reputation honesty), get married divorced, get adored stigmatised.
harder assess, observers perspective received comparatively little attention
psychology. Given everyday life people act observers peoples behaviours
time, external perspective naturally high theoretical importance
social relevance (Hogan, 1982).
Recent research exploring issue psychology based Brunswikian Lens
model (Brunswik, 1956), used extensively recent years explain
kernel truth social perception strangers. Use lens model personality
research reflects widely shared assumptions expression personality commu491

fiMairesse, Walker, Mehl & Moore

Task
Baseline

Classification
n/a
none
50%

n/a

Regression
none
0%

n/a

Ranking
none

0.50

1%
4%
2%
2%
7%

Rank
Rank
Rank
Rank
Rank

LIWC
LIWC
LIWC
LIWC
LIWC

0.44
0.42
0.46
0.44
0.39

24%
15%
3%
18%
1%

Rank
Rank
Rank
Rank
Rank

prosody
MRC


LIWC

0.26
0.39
0.31
0.33
0.37

Self-report models trained written data (essays):
Extraversion
Emotional stability
Agreeableness
Conscientiousness
Openness experience

ADA
SMO
SMO
SMO
SMO

LIWC
LIWC
LIWC
LIWC
LIWC

56%
58%
56%
56%
63%

LR
M5
LR
M5
M5

MRC
LIWC
LIWC
LIWC


Observer report models trained spoken data (EAR):
Extraversion
Emotional stability
Agreeableness
Conscientiousness
Openness experience

NB
NB
NB
NB
NB





prosody

73%
74%
61%
68%
65%

REP
M5
M5R
M5R
M5

LIWC
prosody
all*
LIWC
type*

Table 27: Comparison best models trait, three recognition tasks.
table entry contains algorithm, feature set, model performance.
See Sections 3.2 3.4 details. Depending task, evaluation metric either (1) classification accuracy; (2) percentage improvement
regression baseline; (3) ranking loss. Asterisks indicate results arent
significant p < .05 level.

nicatively functional, i.e. (a) latent attributes persons expressed via observable
cues; (b) observers rely observable cues infer latent attributes others; (c) observers use appropriate cues is, implicit assumptions relations
observable cues latent attributes extent accurate. model also
useful identifying observable cues mediate convergences judgments
latent attributes direct measures attributes (Scherer, 2003; Heinrich &
Borkenau, 1998).
discrepancies markers self-assessed observed personality,
another issue identification appropriate model given specific application.
gold standard approximated either observer self-reports, however
likely specific trait one type report closer true personality.
hypothesis remains tested traits high visibility (e.g., extraversion)
accurately assessed using observer reports, tend yield higher interjudge agreement (Funder, 1995), low visibility traits (e.g., emotional stability)
better assessed oneself. personality recogniser aiming estimate true personality
would therefore switch observer models self-report models, depending
trait assessment.
Beyond practical applications personality recognition models, work also
attempt explore different ways looking relation personality language. looked various personality recognition tasks, applied different learning
492

fiRecognising Personality Conversation Text

methods Section 3.4. tasks vary complexity: ranking model directly
derived regression model, classification model derived either
ranking regression model. type model closer actual relation
language, generally behaviour, personality? personality vary continuously, clusters people similar trait combinations? relation
continuous, classification algorithms never able produce accurate models
two classes, dont take account ordering classes.
ranking models outperform classifiers (see Section 7), given wide range individual
differences reflected literature Big Five (Allport & Odbert, 1936; Norman,
1963; Goldberg, 1990), believe personality varies continuously among members
population, suggesting regression ranking models accurate
long run. hypothesis supported recent work medical research showing
antisocial personality disorder varies continuously (Marcus, Lilienfeld, Edens, & Poythress,
2006). Regression provides detailed model output variables, depending whether absolute differences personality scores meaningful,
relative orderings people matter, ranking may appropriate. Additional
models could also tried ranking task, support vector algorithms ordinal regression (Herbrich, Graepel, & Obermayer, 2000). Moreover, future work
assess whether optimising parameters learning algorithms improves performance.
future work, would like improve models examine well
perform across dialogue domains. clear whether accuracies high enough
useful. Applications involving speech recognition introduce noise features
except prosodic features, probably reducing model accuracy, since EAR
corpus relatively small, expect training data would improve performance.
Additionally, believe inclusion gender feature would produce better
models, actual language correlates perceived personality shown depend
gender speaker (Mehl et al., 2006). also believe future work
investigate combination individual features trait-dependent way. Another issue
poor performance utterance type featuressince significant correlation
results features Section 3.3, unclear features useful
statistical models. could possibly arise small size datasets,
relatively low accuracy hand-crafted automatic tagger, compared
work using supervised learning methods (Stolcke, Ries, Coccaro, Shriberg, Bates, Jurafsky,
Taylor, Martin, Ess-Dykema, & Meteer, 2000; Webb, Hepple, & Wilks, 2005).
begun test models spoken language generator (Mairesse &
Walker, 2007). future work, plan compare utility models trained out-ofdomain corpora, here, methods training models, terms
utility automatic adaptation output generation dialogue systems.

Acknowledgments
would like thank James Pennebaker giving us access essays data.
work partially funded Royal Society Wolfson Research Merit Award Marilyn
Walker, Vice Chancellors studentship Francois Mairesse.
493

fiMairesse, Walker, Mehl & Moore

References
Allport, G. W., & Odbert, H. S. (1936). Trait names: psycho-lexical study. Psychological
Monographs, 47 (1, Whole No. 211), 171220.
Andre, E., Klesen, M., Gebhard, P., Allen, S., & Rist, T. (1999). Integrating models
personality emotions lifelike characters. Proceedings Workshop
Affect Interactions - Towards new Generation Interfaces, pp. 136149.
Argamon, S., Dhawle, S., Koppel, M., & Pennebaker, J. (2005). Lexical predictors
personality type. Proceedings Joint Annual Meeting Interface
Classification Society North America.
Biber, D. (1988). Variation across Speech Writing. Cambridge University Press.
Boersma, P. (2001). Praat, system phonetics computer. Glot International,
5 (9/10), 341345.
Bono, J. E., & Judge, T. A. (2004). Personality transformational transactional
leadership: meta-analysis. Journal Applied Psychology, 89 (5), 901910.
Breck, E., Choi, Y., & Cardie, C. (2007). Identifying expressions opinion context.
Twentieth International Joint Conference Artificial Intelligence (IJCAI).
Brunswik, E. (1956). Perception Representative Design Psychological Experiments. University California Press, Berkeley, CA.
Byrne, D., & Nelson, D. (1965). Attraction linear function proportion positive
reinforcements. Journal Personality Social Psychology, 1, 659663.
Cassell, J., & Bickmore, T. (2003). Negotiated collusion: Modeling social language
relationship effects intelligent agents. User Modeling User-Adapted Interaction,
13, 89132.
Chu-Carroll, J., & Carberry, S. (1994). plan-based model response generation
collaborative task-oriented dialogue. Proceedings 12th National Conference
Artificial Intelligence (AAAI), pp. 799805.
Coltheart, M. (1981). MRC psycholinguistic database. Quarterly Journal Experimental Psychology, 33A, 497505.
Costa, P. T., & McCrae, R. R. (1992). NEO PI-R Professional Manual. Psychological
Assessment Resources, Odessa, FL.
Dewaele, J.-M., & Furnham, A. (1999). Extraversion: unloved variable applied
linguistic research. Language Learning, 49 (3), 509544.
Donnellan, M. B., Conger, R. D., & Bryant, C. M. (2004). Big Five enduring
marriages. Journal Research Personality, 38, 481504.
494

fiRecognising Personality Conversation Text

Edwards, A. L. (1953). relationship judged desirability trait
probability endorsed. Journal Applied Psychology, 37, 9093.
Enos, F., Benus, S., Cautin, R., Graciarena, M., Hirschberg, J., & Shriberg, E. (2006).
Personality factors human deception detection: Comparing human machine
performance. Proceedings ICSLP.
Eysenck, H. J. (1991). Dimensions personality: 16, 5 3? criteria taxonomic
paradigm. Personality Individual Differences, 12 (8), 773790.
Fast, L. A., & Funder, D. C. (2007). Personality manifest word use: Correlations
self-report, acquaintance-report, behavior. Journal Personality Social
Psychology, press.
Freund, Y., Iyer, R., Schapire, R. E., & Singer, Y. (1998). efficient boosting algorithm
combining preferences. Proceedings 15th International Conference
Machine Learning, pp. 170178.
Funder, D. C. (1995). accuracy personality judgment: realistic approach.
Psychological Review, 102, 652670.
Funder, D. C., & Sneed, C. D. (1993). Behavioral manifestations personality: ecological approach judgmental accuracy. Journal Personality Social Psychology,
64 (3), 479490.
Furnham, A. (1990). Language personality. Giles, H., & Robinson, W. (Eds.),
Handbook Language Social Psychology. Winley.
Furnham, A., Jackson, C. J., & Miller, T. (1999). Personality, learning style work
performance. Personality Individual Differences, 27, 11131122.
Furnham, A., & Mitchell, J. (1991). Personality, needs, social skills academic achievement: longitudinal study. Personality Individual Differences, 12, 10671073.
Gill, A., & Oberlander, J. (2003). Perception e-mail personality zero-acquaintance:
Extraversion takes care itself; neuroticism worry. Proceedings 25th
Annual Conference Cognitive Science Society, pp. 456461.
Gill, A. (2003). Personality Language: Projection Perception Personality
Computer-Mediated Communication. Ph.D. thesis, University Edinburgh.
Gill, A. J., & Oberlander, J. (2002). Taking care linguistic features extraversion.
Proceedings 24th Annual Conference Cognitive Science Society, pp.
363368.
Goldberg, L. R. (1990). alternative description personality: Big-Five factor
structure. Journal Personality Social Psychology, 59, 12161229.
Graciarena, M., Shriberg, E., Stolcke, A., Enos, F., Hirschberg, J., & Kajarekar, S. (2006).
Combining prosodic, lexical cepstral systems deceptive speech detection.
Proceedings IEEE ICASSP.
495

fiMairesse, Walker, Mehl & Moore

Heinrich, C. U., & Borkenau, P. (1998). Deception deception detection: role
cross-modal inconsistency. Journal Personality, 66 (5), 687712.
Herbrich, R., Graepel, T., & Obermayer, K. (2000). Large margin rank boundaries
ordinal regression. Smola, A. J., Bartlett, P., Scholkopf, B., & Schuurmans, D.
(Eds.), Advances Large Margin Classifiers, pp. 115132. MIT Press, Cambridge,
MA.
Heylighen, F., & Dewaele, J.-M. (2002). Variation contextuality language:
empirical measure. Context Context, Special issue Foundations Science, 7 (3),
293340.
Hirschberg, J., Benus, S., Brenier, J. M., Enos, F., Friedman, S., Gilman, S., Girand,
C., Graciarena, M., Kathol, A., Michaelis, L., Pellom, B., Shriberg, E., & Stolcke,
A. (2005). Distinguishing deceptive non-deceptive speech. Proceedings
Interspeech2005 - Eurospeech.
Hogan, R. (1982). socioanalytic theory personality. Nebraska Symposium Motivation,
30, 5589.
Hogan, R., Curphy, G. J., & Hogan, J. (1994). know leadership: Effectiveness personality. American Psychologist, 49 (6), 493504.
John, O. P., Donahue, E. M., & Kentle, R. L. (1991). Big Five Inventory: Versions
4a 5b. Tech. rep., Berkeley: University California, Institute Personality
Social Research.
John, O. P., & Srivastava, S. (1999). Big Five trait taxonomy: History, measurement,
theoretical perspectives. Pervin, L. A., & John, O. P. (Eds.), Handbook
personality theory research. New York: Guilford Press.
Komarraju, M., & Karau, S. J. (2005). relationship Big Five personality
traits academic motivation. Personality Individual Differences, 39, 557567.
Lester, J. C., Towns, S. G., & FitzGerald, P. J. (1999). Achieving affective impact: Visual
emotive communication lifelike pedagogical agents. International Journal
Artificial Intelligence Education, 10 (3-4), 278291.
Liscombe, J., Venditti, J., & Hirschberg, J. (2003). Classifying subject ratings emotional
speech using acoustic features. Proceedings Interspeech2003 - Eurospeech.
Mairesse, F., & Walker, M. (2006a). Automatic recognition personality conversation.
Proceedings HLT-NAACL.
Mairesse, F., & Walker, M. (2006b). Words mark nerds: Computational models personality recognition language. Proceedings 28th Annual Conference
Cognitive Science Society, pp. 543548.
Mairesse, F., & Walker, M. (2007). PERSONAGE: Personality generation dialogue.
Proceedings 45th Annual Meeting Association Computational Linguistics (ACL), pp. 496503.
496

fiRecognising Personality Conversation Text

Mallory, P., & Miller, V. (1958). possible basis association voice characteristics
personality traits. Speech Monograph, 25, 255260.
Marcus, D. K., Lilienfeld, S. O., Edens, J. F., & Poythress, N. G. (2006). antisocial
personality disorder continuous categorical? taxometric analysis. Psychological
Medicine, 36 (11), 15711582.
McLarney-Vesotski, A. R., Bernieri, F., & Rempala, D. (2006). Personality perception:
developmental study. Journal Research Personality, 40 (5), 652674.
Mehl, M. R., Gosling, S. D., & Pennebaker, J. W. (2006). Personality natural habitat: Manifestations implicit folk theories personality daily life. Journal
Personality Social Psychology, 90, 862877.
Mehl, M., Pennebaker, J., Crow, M., Dabbs, J., & Price, J. (2001). Electronically
Activated Recorder (EAR): device sampling naturalistic daily activities
conversations. Behavior Research Methods, Instruments, Computers, 33, 517
523.
Mishne, G. (2005). Experiments mood classification blog posts. Proceedings
ACM SIGIR 2005 Workshop Stylistic Analysis Text Information Access.
Nass, C., & Lee, K. (2001). computer-synthesized speech manifest personality? experimental tests recognition, similarity-attraction, consistency-attraction. Journal
Experimental Psychology: Applied, 7 (3), 171181.
Newman, M. L., Pennebaker, J. W., Berry, D. S., & Richards, J. M. (2003). Lying words:
Predicting deception linguistic style. Personality Social Psychology Bulletin,
29, 665675.
Norman, W. T. (1963). Toward adequate taxonomy personality attributes: Replicated
factor structure peer nomination personality rating. Journal Abnormal Social
Psychology, 66, 574583.
Nowson, S., & Oberlander, J. (2007). Identifying bloggers: Towards large scale personality classification personal weblogs. Proceedings International Conference
Weblogs Social Media.
Nunn, S. (2005). Preventing next terrorist attack: theory practice homeland security information systems. Journal Homeland Security Emergency
Management, 2 (3).
Oberlander, J., & Gill, A. J. (2006). Language character: stratified corpus comparison individual differences e-mail communication. Discourse Processes, 42,
239270.
Oberlander, J., & Nowson, S. (2006). Whose thumb anyway? classifying author personality weblog text. Proceedings 44th Annual Meeting Association
Computational Linguistics (ACL).
497

fiMairesse, Walker, Mehl & Moore

Oudeyer, P.-Y. (2002). Novel useful features algorithms recognition emotions
speech. Proceedings 1st International Conference Speech Prosody, pp.
547550.
Pang, B., & Lee, L. (2005). Seeing stars: Exploiting class relationships sentiment
categorization respect rating scales. Proceedings 43rd Annual Meeting
Association Computational Linguistics (ACL), pp. 115124.
Paunonen, S. V., & Jackson, D. N. (2000). beyond Big Five? plenty!. Journal
Personality, 68 (5), 821836.
Peabody, D., & Goldberg, L. R. (1989). determinants factor structures
personality-trait descriptor. Journal Personality Social Psychology, 57 (3),
552567.
Pennebaker, J. W., Francis, M. E., & Booth, R. J. (2001). Inquiry Word Count: LIWC
2001. Lawrence Erlbaum, Mahwah, NJ.
Pennebaker, J. W., & King, L. A. (1999). Linguistic styles: Language use individual
difference. Journal Personality Social Psychology, 77, 12961312.
Pennebaker, J. W., Mehl, M., & Niederhoffer, K. (2003). Psychological aspects natural
language use: words, selves. Annual Review Psychology, 54, 547577.
Popescu, A., & Etzioni, O. (2005). Extracting product features opinions reviews.
Proceedings HTL-EMNLP.
Reeves, B., & Nass, C. (1996). Media Equation. University Chicago Press.
Reiter, E., & Sripada, S. G. (2004). Contextual influences near-synonym choice.
Proceedings International Natural Language Generation Conference, pp. 161
170.
Rienks, R., & Heylen, D. (2006). Dominance detection meetings using easily obtainable
features. Bourlard, H., & Renals, S. (Eds.), Revised Selected Papers 2nd Joint
Workshop Multimodal Interaction Related Machine Learning Algorithms, Vol.
3869 Lecture Notes Computer Science. Springer Verlag.
Riggio, R. E., Salinas, C., & Tucker, J. (1988). Personality deception ability. Personality
Individual Differences, 9 (1), 189191.
Rosenberg, A., & Hirschberg, J. (2005). Acoustic/prosodic lexical correlates charismatic speech. Proceedings Interspeech2005 - Eurospeech.
Rushton, J. P., Murray, H. G., & Erdle, S. (1987). Combining trait consistency learning specificity approaches personality, illustrative data faculty teaching
performance. Personality Individual Differences, 8, 5966.
Schapire, R. (1999). brief introduction boosting. Proceedings Sixteenth International Joint Conference Artificial Intelligence, 2, 14011406.
498

fiRecognising Personality Conversation Text

Scherer, K. R. (1979). Personality markers speech. Scherer, K. R., & Giles, H. (Eds.),
Social markers speech, pp. 147209. Cambridge University Press.
Scherer, K. R. (2003). Vocal communication emotion: review research paradigms.
Speech Communication, 40 (1-2), 227256.
Siegman, A., & Pope, B. (1965). Personality variables associated productivity
verbal fluency initial interview. Proceedings 73rd Annual Conference
American Psychological Association.
Sigurdsson, J. F. (1991). Computer experience, attitudes toward computers personality
characteristics psychology undergraduates. Personality Individual Differences,
12 (6), 617624.
Smith, B. L., Brown, B. L., Strong, W. J., & Rencher, A. C. (1975). Effects speech rate
personality perception. Language Speech, 18, 145152.
Somasundaran, S., Ruppenhofer, J., & Wiebe, J. (2007). Detecting arguing sentiment
meetings. Proceedings 8th SIGdial Workshop Discourse Dialogue.
Stolcke, A., Ries, K., Coccaro, N., Shriberg, E., Bates, R., Jurafsky, D., Taylor, P., Martin,
R., Ess-Dykema, C. V., & Meteer, M. (2000). Dialogue act modeling automatic
tagging recognition conversational speech. Computational Linguistics, 26 (3),
339371.
Stoyanov, V., Cardie, C., & Wiebe, J. (2005). Multi-perspective question answering using
OpQA corpus. Proceedings HLT-EMNLP.
Thompson, C. A., Goker, M. H., & Langley, P. (2004). personalized system conversational recommendations. Journal Artificial Intelligence Research, 21, 393428.
Tucker, S., & Whittaker, S. (2004). Accessing multimodal meeting data: Systems, problems possibilities. Lecture Notes Computer Science, Machine Learning
Multimodal Interaction, 3361, 111.
Turney, P. D. (2002). Thumbs thumbs down? Semantic orientation applied unspervised classification reviews. Proceedings 40th Annual Meeting
Association Computational Linguistics (ACL), pp. 417424.
Vogel, K., & Vogel, S. (1986). Linterlangue et la personalite de lapprenant. International
Journal Applied Linguistics, 24 (1), 4868.
Walker, M., Cahn, J. E., & Whittaker, S. J. (1997). Improvising linguistic style: Social
affective bases agent personality. Proceedings 1st Conference
Autonomous Agents, pp. 96105.
Walker, M., & Whittaker, S. (1990). Mixed initiative dialogue: investigation
discourse segmentation. Proceedings 28th Annual Meeting Association
Computational Linguistics (ACL), pp. 7078.
499

fiMairesse, Walker, Mehl & Moore

Wang, N., Johnson, W. L., Mayer, R. E., Rizzo, P., Shaw, E., & Collins, H. (2005).
politeness effect: Pedagogical agents learning gains. Frontiers Artificial Intelligence Applications, 125, 686693.
Watson, D., & Clark, L. A. (1992). traits temperament: General specific
factors emotional experience relation five factor model. Journal
Personality, 60 (2), 44176.
Webb, N., Hepple, M., & Wilks, Y. (2005). Error analysis dialogue act classification.
Proceedings 8th International Conference Text, Speech Dialogue.
Wiebe, J., & Riloff, E. (2005). Creating subjective objective sentence classifiers
unannotated texts. Proceedings 6th International Conference Intelligent
Text Processing Computational Linguistics.
Wiebe, J., Wilson, T., Bruce, R., Bell, M., & Martin, M. (2004). Learning subjective
language. Computational Linguistic, 30 (3), 277308.
Wilson, T., Wiebe, J., & Hwa, R. (2004). mad you? finding strong
weak opinion clauses. Proceedings 19th National Conference Artificial
Intelligence (AAAI), pp. 761769.
Witten, I. H., & Frank, E. (2005). Data Mining: Practical machine learning tools
techniques. Morgan Kaufmann, San Francisco, CA.
Zukerman, I., & Litman, D. (2001). Natural language processing user modeling: Synergies limitations. User Modeling User-Adapted Interaction, 11 (1-2), 129158.

500

fiJournal Articial Intelligence Research 30 (2007) 273-320

Submitted 02/07; published 10/07

Reasoning Expressive Fuzzy Description Logics
Giorgos Stoilos
Giorgos Stamou

gstoil@image.ece.ntua.gr
gstam@softlab.ece.ntua.gr

Department Electrical Computer Engineering,
National Technical University Athens,
Zographou 15780, Athens, GR

Je Z. Pan

jpan@csd.abdn.ac.uk

Department Computing Science,
University Aberdeen, UK

Vassilis Tzouvaras

tzouvaras@image.ece.ntua.gr

Department Electrical Computer Engineering,
National Technical University Athens,
Zographou 15780, Athens, GR

Ian Horrocks

horrocks@cs.man.ac.uk

School Computer Science, University Manchester
Manchester, M13 9PL, UK

Abstract
widely recognized today management imprecision vagueness
yield intelligent realistic knowledge-based applications. Description Logics (DLs)
family knowledge representation languages gained considerable attention
last decade, mainly due decidability existence empirically high
performance reasoning algorithms. paper, extend well known fuzzy ALC
DL fuzzy SHIN DL, extends fuzzy ALC DL transitive role axioms
(S), inverse roles (I), role hierarchies (H) number restrictions (N ). illustrate
transitive role axioms dicult handle presence fuzzy interpretations
handle properly. extend results adding role hierarchies
nally number restrictions. main contributions paper decidability proof
fuzzy DL languages fuzzy-SI fuzzy-SHIN , well decision procedures
knowledge base satisability problem fuzzy-SI fuzzy-SHIN .

1. Introduction
Nowadays, many applications domains use form knowledge representation language order improve capabilities. Encoding human knowledge providing
means reason benet applications lot, enabling provide intelligent answers complex user dened tasks. Examples modern applications
recently adopted knowledge representation languages World Wide Web (BernersLee, Hendler, & Lassila, 2001; Baader, Horrocks, & Sattler, 2002b), knowledge
used improve abilities agents interoperability disparate systems,
multimedia processing applications (Alejandro, Belle, & Smith, 2003; Benitez, Smith, &
Chang, 2000), use knowledge order bridge gap human percepc
2007
AI Access Foundation. rights reserved.

fiStoilos, Stamou, Pan, Tzouvaras & Horrocks

tion objects exist within multimedia documents, computer perception
pixel values, conguration applications (McGuiness, 2003), etc. Unfortunately,
occasions traditional knowledge representation languages fail accurately represent
concepts appear domain interest. example, particularly case
domain knowledge inherently imprecise vague. Concepts like near
destination (Berners-Lee et al., 2001), highQuality audio system (McGuiness, 2003),
many children, faulty reactor (Horrocks & Sattler, 1999), soon many more,
require special modelling features. past many applications various research areas, like decision making, image processing, robotics medical diagnosis adopted
special mathematical frameworks intended modelling types concepts
(Zimmermann, 1987; Larsen & Yager, 1993; Krishnapuram & Keller, 1992). One
mathematical framework fuzzy set theory (Zadeh, 1965). Though fuzzy extensions various logical formalisms, like propositional, predicate modal logics investigated
past (Hajek, 1998), framework yet well developed Description
Logics much research work needs done. precisely, need
reasoning expressive fuzzy Description Logics.
order achieve knowledge reusability high interoperability, modern applications
often use concept ontology (Berners-Lee et al., 2001) represent knowledge
exists within domain. Ontologies created encoding full knowledge
possess specic entity world using knowledge representation language. logical formalism gained considerable attention last decade Description Logics
(Baader, McGuinness, Nardi, & Patel-Schneider, 2002a). Description Logics (DLs)
family class-based (concept-based) knowledge representation formalisms, equipped
well dened model-theoretic semantics (Tarski, 1956). characterized use
various constructors build complex concept descriptions simpler ones, emphasis
decidability key reasoning problems, provision sound, complete
empirically tractable reasoning services. well-dened semantics powerful
reasoning tools exist Description Logics makes ideal encoding knowledge
many applications like Semantic Web (Baader et al., 2002b; Pan, 2004), multimedia applications (Meghini, Sebastiani, & Straccia, 2001), medical applications (Rector &
Horrocks, 1997), databases (Calvanese, De Giacomo, Lenzerini, Nardi, & Rosati, 1998)
many more. Interestingly, current standard Semantic Web ontology languages, OWL
(Bechhofer, van Harmelen, Hendler, Horrocks, McGuinness, Patel-Schneider, & eds., 2004),
based Description Logics represent knowledge support wide range reasoning services. precisely, without regarding annotation properties OWL, OWL
Lite species OWL equivalent SHIF(D+ ) DL, OWL DL equivalent
SHOIN (D+ ) (Horrocks, Patel-Schneider, & van Harmelen, 2003). Although DLs provide
considerable expressive power, feature limitations regarding ability represent
vague (fuzzy) knowledge. obvious, order make applications use DLs able
cope information extend theory capable representing
kind information. One important theory fuzzy set theory. Fuzzy Description
Logics interesting logical formalisms used numerous domains like
multimedia information retrieval (Fagin, 1998; Meghini et al., 2001) provide ranking
degrees, geospatial (Chen, Fellah, & Bishr, 2005) cope vague concepts like near,
far many more.
274

fiReasoning Expressive Fuzzy Description Logics

order make need handle vagueness knowledge evident application fuzzy set theory intuitive, let us consider example. Suppose
creating knowledge-based image processing application. application task
(semi)automatically detect recognize image objects. Suppose also content
images represents humans animals. domain one use standard features Description Logics encode knowledge. example, knowledge base describing
human bodies could contain following entities
Arm isPartOf.Body
Body isPartOf.Human
subsumption relation isPartOf obviously transitive relation.
knowledge captured aid DL (Sattler, 1996). Moreover, one might
want capture knowledge role hasPart inverse role isPartOf,
writing hasPart := isPartOf , thus able state something body
tail also animal as,
Body hasPart.Tail Animal.
new feature one would require SI DL (Horrocks & Sattler, 1999).
new axiom gives us ability recognize concept Arm Tail subsumed
isPartOf.Animal. Finally, SI DL extended role hierarchies
number restrictions. Hence, one able capture fact role hasDirectPart
sub-role role hasPart, writing isDirectPartOf isPartOf, also provide
accurate denition concept Body giving axiom,
Body isDirectPartOf.Human 2hasArm 2hasArm
stating body direct part human also exactly two arms.
used standard Description Logic features. suppose
run image analysis algorithm. algorithms usually segment image regions
try annotate appropriate semantic labels using low level image features.
process involves number vague concepts since image region might red,
blue, circular, small smooth textured degree two image regions might
totally degree adjacent (since pixels adjacent),
one contained within other, etc. Hence decide membership
region specic concept certain degree (Athanasiadis, Mylonas, Avrithis,
& Kollias, 2007). example, case could object o1 isPartOf
object o2 degree 0.8, o2 isPartOf o3 degree 0.9, o1 Arm
degree 0.75 o2 Body degree 0.85. fuzzy knowledge one
could deduce o3 belongs concept hasPart.Body hasPart.Arm degree
0.75. together denition form Human hasPart.Body hasPart.Arm,
represents equivalence, means good chance o3 Human.
Observe, denition, order someone human, force
Body explicitly part Arm. reasonable choice present
application, depending level segmentation, might several
275

fiStoilos, Stamou, Pan, Tzouvaras & Horrocks

segmented regions o2 o3 . obvious applications handling
inherent vagueness certainly benets specic application.
paper extend well known fuzzy ALC (f-ALC) DL (Straccia, 2001)
fuzzy SHIN DL (f-SHIN ), extends f-ALC DL inverse role constructor,
transitive role axioms, role hierarchies number restrictions constructor. Moreover,
prove decidability f-SHIN DL providing tableaux algorithm deciding
standard DL inference problems. order provide algorithm proceed
two steps. First, focus f-SI language studying properties fuzzy transitive
roles value existential restrictions, well applicability techniques used
classical SI language ensure termination algorithm (Horrocks & Sattler,
1999). see great diculty handling axioms context fuzzy
DLs, nishing investigation see similar notions classical SI
language applied. Secondly, extend results adding role hierarchies
number restrictions. provide necessary extensions reasoning algorithm
f-SI, thus providing reasoning algorithm f-SHIN language. Discarding datatypes,
SHIN slightly expressive SHIF (OWL Lite) slightly less expressive
SHOIN (OWL DL). order achieve goal extend techniques used
classical SHIN language ensure correctness algorithm (Horrocks &
Sattler, 1999; Horrocks, Sattler, & Tobies, 2000). Finally, prove decidability
extended algorithm. many benets following approach. one
hand provide gradual presentation complex algorithm f-SHIN ,
hand provide reasoning algorithm less expressive, ecient fuzzy
DL language, f-SI. classical SI language known Pspace-complete, contrast
Exptime-completeness SHIN (Tobies, 2001), hence algorithm f-SI
used future research providing ecient optimized implementations.
Please note fuzzy DLs (Straccia, 2001) complementary approaches
extend DLs, like probabilistic DLs (Koller, Levy, & Pfeer, 1997; Giugno & Lukasiewicz,
2002; Ding & Peng, 2004), possibilistic DLs (Hollunder, 1994). precisely,
theories meant used capturing dierent types imperfect information
knowledge. Fuzziness purposed capturing vague (fuzzy) knowledge, i.e. facts
certain degrees truth assigned them, like example degree
truth someone tall. hand, possibilistic probabilistic logics
purposed capturing cases knowledge uncertain due lack information
knowledge specic situation future event, like example sensor reading
weather forecast. facts assigned degrees possibility, belief probability,
rather truth degrees. Dubois Prade (2001) provide comprehensive analysis
theories along dierent properties.
rest paper organized follows. Section 2 briey introduces DL SHIN
provides preliminaries notion fuzzy set set theoretic
logical operations extended fuzzy set framework. Section 3 introduces
syntax semantics fuzzy SHIN DL, call f-SHIN .1 language. Section
4 provides investigation semantics fuzzy DLs fuzzy transitive relations
1. previous approach fuzzy DLs notation fALC used (Straccia, 2004), notation
exible represent fuzzy DLs use dierent norm operations, see later on.
approaches (Tresp & Molitor, 1998; Holldobler, Khang, & Storr, 2002) naming ALC F

276

fiReasoning Expressive Fuzzy Description Logics

participate value existential restrictions. section 5 give detailed presentation
reasoning algorithm deciding consistency fuzzy-SI ABox provide
proofs termination, soundness completeness procedure. Then,
section 6 extend previous results adding role hierarchies number restrictions.
precisely, results section 4 enriched considering transitive roles roles
hierarchies value existential restrictions. Using results extend algorithm
section 5 handle new feature nally prove soundness, completeness
termination. last, section 7 review previous work fuzzy Description
Logics section 8 concludes paper.

2. Preliminaries
current section briey introduce classical DLs fuzzy set theory, recalling
mathematical properties fuzzy set theoretic operators.
2.1 Description Logics SHIN DL
Description Logics (DLs) (Baader et al., 2002a) family logic-based knowledge representation formalisms designed represent reason knowledge application
domain structured well-understood way. based common family
languages, called description languages, provide set constructors build concept (class) role (property) descriptions. descriptions used axioms
assertions DL knowledge bases reasoned respect (w.r.t.) DL
knowledge bases DL systems.
section, briey introduce SHIN DL, extended
f-SHIN DL later. description language consists alphabet distinct concept names
(C), role names (R) individual (object) names (I); together set constructors
construct concept role descriptions.
dene notions SHIN -roles SHIN -concepts.
Denition 2.1 Let RN R role name R SHIN -role. SHIN -role descriptions
(or simply SHIN -roles) dened abstract syntax: ::= RN | R . inverse
relation roles symmetric, avoid considering roles R , dene
function Inv returns inverse role, precisely,

RN R = RN ,
Inv(R) :=
RN
R = RN .
set SHIN -concept descriptions (or simply SHIN -concepts) smallest set
that:
1. every concept name CN C SHIN -concept,
2. C SHIN -concepts R SHIN -role, C, C D, C D, R.C
R.C also SHIN -concepts, called general negation (or simply negation),
used easily confused ALCF (ALC extended functional restrictions, Horrocks
& Sattler, 1999), pronounced.

277

fiStoilos, Stamou, Pan, Tzouvaras & Horrocks

Constructor
top
bottom
concept name
general negation
conjunction
disjunction
exists restriction
value restriction
at-most restriction
at-least restriction

Syntax



CN
C
CD
CD
R.C
R.C
nR
nR

Semantics


CNI
\ C
C DI
C DI
{x | y.x, RI C }
{x | y.x, RI C }
{x | {y | RI (x, y)} n}
{x | {y | RI (x, y)} n}

Table 1: Semantics SHIN -concepts

disjunction, conjunction, value restrictions existential restriction, respectively,

3. simple2 SHIN -role n N, ( nS) ( nS) also SHIN concepts, called at-most at-least number restrictions.
removing point 3 denition obtain set SI-concepts.
Description Logics model-theoretic semantics, dened terms interpretations. interpretation (written I) consists domain (written )
interpretation function (written ), domain nonempty set objects
interpretation function maps individual name element aI ,
concept name CN C subset CNI , role name RN R binary
relation RN . interpretation function extended give semantics
concept role descriptions. given Table 1.
SHIN knowledge base (KB) consists TBox, RBox ABox. SHIN
TBox nite set concept inclusion axioms form C D, concept equivalence
axioms form C D, C, SHIN -concepts. interpretation satises
C C DI satises C C = DI . Note concept inclusion
axioms form called general concept inclusions (Horrocks & Sattler, 1999;
Baader, 1990). SHIN RBox nite set transitive role axioms (Trans(R)), role
inclusion axioms (R S). interpretation satises Trans(R) if, x, y, z ,
{x, y, y, z} RI x, z RI , satises R RI . set role
*
inclusion axioms denes role hierarchy. role hierarchy introduce
transitive-reexive closure . last, observe R S, semantics role
inclusion axioms imply Inv(R)I Inv(S)I , semantics inverse roles imply
Trans(Inv(R)). SI RBox obtained SHIN RBox disallow role inclusion
axioms. SHIN ABox nite set individual axioms (or assertions) form
.
: C, called concept assertions, a, b : R, called role assertions, form = b.
2. role called simple neither transitive transitive sub-roles. crucial order
get decidable logic (Horrocks, Sattler, & Tobies, 1999).

278

fiReasoning Expressive Fuzzy Description Logics

interpretation satises : C aI C , satises a, b : R aI , bI RI ,
.
satises = b aI = bI . SI ABox obtained SHIN ABox disallowing
.
inequality axioms = b. interpretation satises SHIN knowledge base
satises axioms . satisable (unsatisable) exists (does exist)
interpretation satises . Let C, SHIN -concepts, C satisable
(unsatisable) w.r.t. exists (does exist) interpretation s.t. C = ;
C subsumes w.r.t. every interpretation C DI . Given
concept axiom, role axiom, assertion , entails , written |= ,
models satises .
2.2 Fuzzy Sets
Fuzzy set theory fuzzy logic widely used today capturing inherent vagueness
(the lack distinct boundaries sets) exists real life applications (Klir & Yuan,
1995). notion fuzzy set rst introduced Zadeh (1965). classical
set theory element either belongs set not, fuzzy set theory elements belong
certain degree. formally, let X collection elements (called universe
discourse) i.e X = {x1 , x2 , . . .}. crisp subset X collection elements
X dened aid characteristic function (x) assigns
x X value 1 0 element belongs X not, respectively.
hand, fuzzy subset X, dened membership function (x), simply A(x),
x X. membership function assigns x X value 0
1 represents degree element belongs A. Additionally, fuzzy
binary relation R two crisp sets X function R : X [0, 1].
example, one say om belongs set people degree 0.8, writing
all(T om) = 0.8, object o1 part object o2 degree 0.6, writing
isP artOf (o1 , o2 ) = 0.6. Several properties fuzzy binary relations investigated
literature (Klir & Yuan, 1995). example, binary fuzzy relation called sup-min
transitive R(x, z) supyY {min(R(x, y), R(y, z))}, inverse relation R
dened R1 (y, x) = R(x, y) (Klir & Yuan, 1995).
Using idea, important operations dened crisp sets relations,
like boolean operations (complement, union, intersection etc.), extended order
cover fuzzy sets fuzzy relations. Accordingly, sound complete mathematical
framework plays important role management imprecise vague information dened used wide set scientic areas including expert systems
decision making (Zimmermann, 1987), pattern recognition (Kandel, 1982), image analysis
computer vision (Krishnapuram & Keller, 1992), medicine (Oguntade & Beaumont,
1982), control (Sugeno, 1985), etc.
2.3 Fuzzy Set Theoretic Operations
section, explain extend boolean operations logical implications
context fuzzy sets fuzzy logics. operations performed
mathematical functions unit interval.
operation complement performed unary operation, c : [0, 1] [0, 1], called
fuzzy complement. order provide meaningful fuzzy complements, functions
279

fiStoilos, Stamou, Pan, Tzouvaras & Horrocks

satisfy certain properties. precisely, satisfy boundary conditions,
c(0) = 1 c(1) = 0, monotonic decreasing, b, c(a) c(b).
current paper use Lukasiewicz negation, c(a) = 1 a, additionally
continuous involutive, [0, 1], c(c(a)) = holds. cases fuzzy
intersection fuzzy union mathematical functions used binary unit
interval. functions usually called norm operations referred t-norms (t),
case fuzzy intersection, t-conorms (or s-norms) (u), case fuzzy union
(Klement, Mesiar, & Pap, 2004). operations satisfy certain mathematical
properties. precisely, t-norm (t-conorm) satises boundary condition, t(a, 1) =
(u(a, 0) = a), monotonic increasing, b t(a, b) t(a, d) (u(a, b) u(a, d)),
commutative, t(a, b) = t(b, a) (u(a, b) = u(b, a)), associative, t(a, t(b, c)) = t(t(a, b), c)
(u(a, u(b, c)) = u(u(a, b), c)). Though wealth operations literature
(Klir & Yuan, 1995) restrict attention specic ones. precisely,
using Godel t-norm, t(a, b) = min(a, b) Godel t-conorm, u(a, b) = max(a, b).
Additionally aforementioned properties, operations also idempotent, i.e.
min(a, a) = max(a, a) = a, hold. Finally, fuzzy implication performed
binary operation, form J : [0, 1] [0, 1] [0, 1]. current paper use
Kleene-Dienes fuzzy implication provided equation, J (a, b) = max(c(a), b).
reason restricting attention operations would made clear section
5.1. recall property max norm operation going use
investigation properties transitive relations framework fuzzy set
theory.
Lemma 2.2 (Hajek, 1998) a, b [0, 1], j takes values index set J,
max operation satises following property:
inf jJ max(a, bj ) = max(a, inf jJ bj ).

3. fKD -SHIN DL
section, introduce fuzzy extension SHIN DL presented Section 2.1.
Following Stoilos, Stamou, Tzouvaras, Pan, Horrocks (2005b), since using
Kleene-Dienes (KD) fuzzy implication language, call fKD -SHIN . presentation follows standard syntax semantics fuzzy DLs, introduced
literature (Straccia, 2001; Holldobler et al., 2002; Sanchez & Tettamanzi, 2004).
precisely, fKD -SHIN rst presented Straccia (2005b). completeness reasons
also present language fKD -SHIN here. Please also note presentation
diers Straccia (2005b) semantics concept role inclusion axioms.
usual, consider alphabet distinct concept names (C), role names (R)
individual names (I). abstract syntax fKD -SHIN -concepts fKD -SHIN -roles
(and respectively fKD -SI-concepts fKD -SI-roles) SHIN counterparts; however, semantics based fuzzy interpretations (see below). Similarly,
fKD -SHIN keeps syntax concept role axioms counterparts
SHIN . Interestingly, fKD -SHIN extends SHIN individual axioms (assertions) fuzzy
individual axioms, fuzzy assertions (following, Straccia, 2001), membership degrees
asserted.
280

fiReasoning Expressive Fuzzy Description Logics

Firstly, using membership functions range interval [0, 1], classical interpretations extended concept fuzzy interpretations (Straccia, 2001).
abuse symbols dene fuzzy interpretation pair = (I , ),3
domain non-empty set objects fuzzy interpretation function,
maps
1. individual name element aI ,
2. concept name C membership function AI : [0, 1],
3. role name R R membership function RI : [0, 1].
example, AI (o) gives degree object belongs fuzzy
concept A, e.g. AI (o) = 0.8. using fuzzy set theoretic operations dened section
2.3, fuzzy interpretation function extended give semantics fKD -SHIN concepts fKD -SHIN -roles. example, since use max function fuzzy
union membership degree object fuzzy concept (C D)I equal
max(C (a), DI (a)). Moreover since, according Table 1, value restriction R.C
implication form, y(R(x, y) C(y)), interpret inf (Hajek, 1998),
Kleene-Dienes fuzzy implication nally equation, inf bI {max(1
RI (a, b), C (b))}. complete set semantics depicted Table 2. note
many proposals semantics number restrictions fuzzy DLs (Sanchez &
Tettamanzi, 2004; Straccia, 2005b). choose follow semantics proposed Straccia
(2005b) since based First-Order interpretation number restrictions (Baader
et al., 2002a). Moreover, shown Stoilos, Stamou, Tzouvaras, Pan, Horrocks
(2005a) see section 6, semantics inference services
fKD -SHIN stay decidable reasoning reduced simple counting problem,
yielding ecient algorithm. Note that, although semantics
presented elsewhere (Sanchez & Tettamanzi, 2004; Straccia, 2005b), include
simply sake completeness.
fKD -SHIN knowledge base consists TBox, RBox ABox. Let
concept name C fKD -SHIN concept. fKD -SHIN TBox nite set fuzzy
concept axioms form C, called fuzzy inclusion introductions, form
C, called fuzzy equivalence introductions. fuzzy interpretation satises C
, AI (o) C (o). fuzzy interpretation satises C , AI (o) = C (o).
fuzzy interpretation satises fKD -SHIN TBox satises fuzzy concept
axioms ; case, say model .
two remarks here. Firstly, give crisp subsumption fuzzy concepts here,
usual way subsumption dened context fuzzy sets (Klir & Yuan,
1995). contrast, Straccia (2005b) denes fuzzy subsumption fuzzy concepts.
noted Bobillo, Delgado, Gomez-Romero (2006) fKD -DLs fuzzy subsumption
sometimes counterintuitive. Secondly, see, allowing simple TBoxes.
TBox called simple neither includes cyclic general concept inclusions, i.e.
axioms form C C, concept name never dened
3. rest paper, use = (I , ) represent fuzzy interpretations instead crisp interpretations.

281

fiStoilos, Stamou, Pan, Tzouvaras & Horrocks

Constructor
top
bottom
general negation
conjunction
disjunction
exists restriction
value restriction
at-most
at-least
inverse role

Syntax



C
CD
CD
R.C
R.C
pR
pR
R

Semantics

(a) = 1
(a) = 0
(C)I (a) = 1 C (a)
(C D)I (a) = min(C (a), DI (a))
(C D)I (a) = max(C (a), DI (a))
(R.C)I (a) = supbI {min(RI (a, b), C (b))}
(R.C)I (a) = inf bI {max(1 RI (a, b), C (b))}

inf b1 ,...,bp+1 maxp+1
i=1 {1 R (a, bi )}
p
supb1 ,...,bp mini=1 {RI (a, bi )}
(R )I (b, a) = RI (a, b)

Table 2: Semantics fKD -SHIN -concepts fKD -SHIN -roles

either directly indirectly. procedure deal cyclic general TBoxes,
context fuzzy DLs, recently developed Stoilos, Straccia, Stamou, Pan
(2006), also parallel slightly dierent technique presented Li, Xu, Lu,
Kang (2006a). process involves additional expansion rules preprocessing step
called normalization, aected expressivity underlying fuzzy DL.
Hence, order keep presentation simple consider general TBoxes
following, focus decidability reasoning fKD -SI fKD -SHIN ,
involve many technical details. end section 6 comment
issue handling GCIs fKD -SHIN language.
fKD -SHIN RBox nite set fuzzy transitive role axioms form Trans(R)
fuzzy role inclusion axioms form R S, R, fKD -SHIN -roles. fuzzy
interpretation satises Trans(R) a, c , RI (a, c) supbI {min(RI (a, b), RI (b, c))},
satises R a, b , RI (a, b) (a, b). Note semantics result
denition sup-min transitive relations fuzzy set theory. fuzzy interpretation
satises fKD -SHIN RBox R satises fuzzy transitive role axioms R;
case, say model R. Similarly classical SHIN language,
semantics inverse roles role inclusion axioms fKD -SHIN imply Trans(R)
R holds Trans(Inv(R)) Inv(R) Inv(S) .
fKD -SHIN ABox nite set fuzzy assertions (Straccia, 2001) form
(a : C)n (a, b : R)n, stands , >, <, n [0, 1]
.
form =
b. Intuitively, fuzzy assertion form (a : C) n means membership
degree individual concept C least equal n. call assertions dened
, > positive assertions, dened , < negative assertions. Formally, given
fuzzy interpretation I,
satises (a : C) n
satises (a : C) n
satises (a, b : R) n
satises (a, b : R) n
.
satises = b
282







C (aI ) n,
C (aI ) n,
RI (aI , bI ) n,
RI (aI , bI ) n,
aI = bI .

fiReasoning Expressive Fuzzy Description Logics

satisability fuzzy assertions >, < dened analogously. Observe that,
also simulate assertions form (a : C) = n considering two assertions form
(a : C) n (a : C) n (Holldobler et al., 2002; Straccia, 2001). fuzzy interpretation
satises fKD -SHIN ABox satises fuzzy assertions A; case,
say model A.
Furthermore, noted Straccia (2001, 2005b), due mathematical properties norm operations dened section 2.3, following fKD -SHIN -concept equivalences satised:
,
, C
C, C C, C

C .
Furthermore, since Lukasiewicz complement involutive holds that, C C.
Moreover, De Morgan laws: C1 C2 (C1 C2 ), C1 C2 (C1 C2 ),
satised. consequence satisability De Morgan laws use
Kleene-Dienes fuzzy implication following concept equivalences also hold.
R.C



R.(C),

p1 R



(p1 + 1)R,

R.C



p1 R



R.(C),

(p1 1)R, p1 N
,
p1 = 0

last note classical laws contradiction (C C ) excluded middle
(C C
), hold.
Example 3.1 Let us revisit fuzzy knowledge base () informally introduced
section 1. Formally, knowledge base dened follows: = , R, A,


=

{Arm isPartOf.Body,
Body isPartOf.Human},



=

{(o1 , o2 : isPartOf) 0.8,(o2 , o3 : isPartOf) 0.9,
(o2 : Body) 0.85, (o1 : Arm) 0.75},

R

=

{Trans(isPartOf)}.

Now, order fuzzy interpretation model hold
ArmI (oIi ) (isPartOf.Body)I (oIi ) BodyI (oIi ) (isPartOf.Body)I (oIi ), oIi .
Furthermore, isPartOf (oI1 , oI2 ) 0.8, isPartOf (oI2 , oI3 ) 0.9, BodyI (oI2 ) 0.85
ArmI (oI1 ) 0.75, also model A. model RBox R,
also satisfy isPartOf (oI1 , oI3 ) supaI {min(isPartOf (oI1 , a), isPartOf (a, oI3 ))} =
sup{. . . , min(0.8, 0.9), . . .} 0.8.
let us consider concept hasPart.Body hasPart.Arm mentioned
Section 1. Due semantics existential restrictions presented Table 2,



(hasPart.Body)I (oI3 )

=

supaI {min((isPartOf ) (oI3 , a), BodyI (a))} 0.85,

(hasPart.Arm)I (oI3 )

=

supaI {min((isPartOf ) (oI3 , a), ArmI (a))} 0.75.



Hence o3 would belong intersection two concepts minimum membership
degree greater equal 0.75, claimed Section 1.


283

fiStoilos, Stamou, Pan, Tzouvaras & Horrocks

n
>n

<m
nm
nm


n>m
nm

Table 3: Conjugated pairs fuzzy assertions
Following Straccia (2001), introduce concept conjugated pairs fuzzy assertions represent pairs assertions form contradiction. possible conjugated
pairs dened Table 3, represents SI assertion. example, = : C,
assertions (a : C) 0.7 (a : C) < 0.7 conjugate. Furthermore, due
presence inverse roles role inclusion axioms denition slightly extended
Straccia (2001) hence, one also take consideration possible
inverse roles role hierarchy checking conjugation two role assertions. ex* S, assertion (a, b : R) 0.9, conjugates (b, : Inv(S)) 0.4;
ample, R
similarly rest inequalities.
Now, dene reasoning problems fKD -SHIN DL.
fuzzy interpretation satises fKD -SHIN knowledge base satises
axioms ; case, called model . fKD -SHIN knowledge base
satisable (unsatisable) exists (does exist) fuzzy interpretation
satises axioms . fKD -SHIN -concept C satisable (unsatisable) w.r.t.
RBox R TBox exists (does exist) model R
C (a) = n, n (0, 1]. case, C called
n-satisable w.r.t. R (Navara, 2000). Let C two fKD -SHIN -concepts.
say C subsumed w.r.t. R every model R holds
that, x .C (x) DI (x). Furthermore, fKD -SHIN ABox consistent w.r.t. R
exists model R also model A. Moreover, given
fuzzy concept axiom fuzzy assertion {C D, C D, n}, fKD -SHIN
knowledge base entails , written |= , models also satisfy .
Furthermore, studying Table 3, conclude fKD -SHIN ABox
contain number positive negative assertions without forming contradiction.
Therefore, useful compute lower upper bounds truth-values. Given
fKD -SHIN knowledge base assertion , greatest lower bound w.r.t.
glb(, ) = sup{n : |= n}, sup = 0. Similarly, least upper bound
w.r.t. lub(, ) = inf{n : |= n}, inf = 1. decision procedure
solve best truth-value bound provided Straccia (2001). procedure
membership degrees appear fKD -SHIN ABox, together complemented
values degrees 0, 0.5 1, collected set membership degrees N
subsequently entailment fuzzy assertions n n, n N
tested, thus determining glb lub. Obviously procedure independent
expressivity DL language, thus also applicable context.
Remark 3.2 Table 2 see semantics value existential restrictions fuzzy DLs dened aid inmum supremum operation. means construct innite interpretation I, i.e. interpretation
284

fiReasoning Expressive Fuzzy Description Logics

= {b1 , b2 , . . .} contains innite number objects, R.C n-satisable
((R.C)I (a) = n ) bi , max(1 RI (a, bi ), C (bi )) > n.
possible since although maximum membership degrees involved
individual object bi strictly greater n limit innite sequence could converge
n. fact rst noted fuzzy DLs Hajek (2005), introducing notion
witnessed model fuzzy DLs. model called witnessed (R.C)I (a) = n
b either RI (a, bi ) = 1n C (bi ) = n, i.e. b
witnesses membership degree R.C. Fortunately, fuzzy logics
innite model witnessed model. precisely, Hajek proves
property Lukasiewicz fuzzy logic4 . concludes proofs
modied apply fuzzy logic dened fuzzy operators using current
paper. operators denable Lukasiewicz logic (Mostert &
Shields, 1957). rest paper, without loss generality, going consider
witnessed models.
paper, provide algorithm decide fuzzy ABox consistency problem
w.r.t. RBox expressive fuzzy DLs. Many reasoning problems reduced
problem. Firstly, concept satisability fuzzy concept C reduced
consistency checking fuzzy ABox {(a : C) > 0}. Secondly, paper,
consider unfoldable TBoxes, KB satisability reduced ABox consistency
w.r.t. RBox. TBox unfoldable contains cycles contains unique
introductions, i.e., concept axioms concept names appearing left hand side
and, concept name A, one axiom appears
left side. knowledge base unfoldable TBox transformed equivalent
one empty TBox transformation called unfolding, expansion (Nebel, 1990):
Concept inclusion introductions C replaced concept equivalence introductions
C, new concept name, stands qualities distinguish
elements elements C. Subsequently, C complex concept
expression, dened terms concept names, dened TBox, replace
denitions C. proved initial TBox expanded one
equivalent.
Moreover, problem entailment reduced problem fuzzy knowledge
base satisability (Straccia, 2001). precisely, = , R, A, |= n
= , R, { n} unsatisable. , denote negation
inequalities; e.g., <, < . Finally,
subsumption problem two fuzzy concepts C w.r.t. TBox also reduced
fuzzy knowledge base satisability problem. formally, Straccia (2001), proved
, , |= C , , {(a : C) n, (a : D) < n}, n {n1 , n2 }, n1 (0, 0.5]
n2 (0.5, 1], unsatisable. reduction extended order fuzzy
knowledge base also include RBox. Please note that, crisp DLs, order check
concept C subsumed concept check unsatisability concept,
C D. reduction unsatisability applicable fKD -DLs since fuzzy
operations use satisfy laws contradiction excluded middle.
4. Lukasiewicz fuzzy logic uses t-norm t(a, b) = max(0, + b 1), t-conorm u(a, b) = min(1, + b),
Lukasiewicz complement fuzzy implication J (a, b) = min(1, 1 + b)

285

fiStoilos, Stamou, Pan, Tzouvaras & Horrocks

conclude section example.
Example 3.3 Consider sample knowledge base (). applying transformation unfolding, dened earlier, one would obtain following expanded fuzzy TBox:


=

{Arm Arm isPartOf.Body,
Body Body isPartOf.Human}

respective fuzzy assertions would transformed


=

{(o2 : Body isPartOf.Human) 0.85,
(o1 : Arm isPartOf.Body) 0.75}

Now, let us formally specify query introduced section 1. = , R,
modied knowledge base, unfolding, query would form |= (o3 :
hasPart.Body hasPart.Arm) 0.75. According previous discussion order
check entailment query one check consistency fuzzy
ABox {(o3 : hasPart.Body hasPart.Arm) < 0.75}, w.r.t. RBox R, since
expansion remove . task following sections provide procedure
decides consistency fuzzy ABox w.r.t. RBox.


4. Transitivity Fuzzy Description Logics
classical DLs, role R transitive a, b, c , a, b RI b, c RI
imply a, c RI . Sattler (1996) shows that, a, b, c1 , . . . , cn , R transitive, b
R-successor a, c1 , . . . , cn R-successors b, (R.C)I , Rsuccessors instances (R.C)I , e.g., b (R.C)I because: (i) a, ci RI
(as R transitive), (ii) ci C (as (R.C)I ) (iii) b (R.C)I (due
semantics R.C). words, means following concept subsumption
holds, R.C R.(R.C).
property suggests value restrictions transitive relations (R.C)
propagated along path individuals. propagation crucial reasoning algorithms order retain tree-model property (Baader et al., 2002a), property
leads decidable decision procedures (Vardi, 1997). goal rest section investigate property context fuzzy Description Logics allow
transitive role axioms. determine similar propagation occurs is,
nd membership degree propagation carries subsequent objects.
rst time investigation presented literature.
fuzzy DLs, objects instances possible fuzzy concepts degree, ranging
interval [0, 1]. shown Section 3, fuzzy role R transitive i,
a, c , RI (a, c) supbI min(RI (a, b), RI (b, c)). Since holds supremum,
arbitrary b that, RI (a, c) min(RI (a, b), RI (b, c)) applying fuzzy
complement sides get, c(RI (a, c)) c(min(RI (a, b), RI (b, c))). follows,
show value restrictions, also existential restrictions transitive
286

fiReasoning Expressive Fuzzy Description Logics

roles (R.C) propagated, satisfy inmum supremum restrictions.
look value restrictions. Let a, b objects R transitive
role. (R.C)I (a) va , (note c represents fuzzy complement)
monotonicity
(1) inf dI max(c(RI (a, d)), C (d)) va
(2) inf dI max(c(min(RI (a, b), RI (b, d))), C (d)) va
(3) inf dI max(max(c(RI (a, b)), c(RI (b, d))), C (d)) va

De organ
associativity

(4) inf dI max(c(RI (a, b)), max(c(RI (b, d)), C (d))) va

Lemma

max(c(RI (a, b)), inf

max(c(RI (b, d)), C (d)))

(5)
dI
(6) max(c(RI (a, b)), (R.C)I (b)) va ,

va

2.2



means either c(RI (a, b)) va (R.C)I (b) va . remarks here.
Firstly, b arbitrary object . words, object x ,
c(RI (a, x)) < va , (R.C)I (x) va . Similarly, (R.C)I (a) > va c(RI (a, x)),
(R.C)I (x) > va . Hence, following result obtained.
Corollary 4.1 (R.C)I (a) n Trans(R) then, fKD -DL, (R.(R.C))I (a) n
holds.
Now, let a, b , R transitive role consider case (R.C)I (a) ea .
applying fuzzy complement sides inequation, since fuzzy complements
monotonic decreasing, obtain c((R.C)I (a)) c(ea ). Based semantics
language rewritten ((R.C))I (a) c(ea ) using concept
equivalences presented previous section have, (R.(C))I (a) c(ea ). Hence,
using results value restrictions conclude object x ,
c(RI (a, x)) < c(ea ) RI (a, x) > ea , (R.(C))I (x) c(ea ) (R.C)I (x) ea
similarly, (R.(C))I (a) > c(ea ) c(RI (a, x)), i.e. (R.C)I (a) < c(ea ) RI (a, x),
(R.(C))I (x) > c(ea ) thus (R.C)I (x) < ea . Hence, able show
next result.
Corollary 4.2 (R.C)I (a) n Trans(R) then, fKD -DL, (R.(R.C))I (a) n
holds.
results used properties 11 12 Denition 5.1.

5. Reasoning Transitive Inverse Roles fKD -DLs
current section show reason transitive inverse roles
context fuzzy DLs, thus providing reasoning algorithm fKD -SI language.
algorithm used order provide ecient implementations applications
need expressive power fKD -SHIN .
section 3, shown inference services fuzzy DLs, like entailment
subsumption, reduced problem ABox consistency checking w.r.t.
RBox. tableaux algorithms, tableaux algorithm checking ABox consistency
tries prove satisability assertion constructing, fKD -SI ABox A,
fuzzy tableau A, i.e., abstraction model A. Given notion fuzzy
tableau, quite straightforward prove algorithm decision procedure ABox
287

fiStoilos, Stamou, Pan, Tzouvaras & Horrocks

consistency. fuzzy tableau present seen extension tableau
presented Horrocks et al. (2000) handle degrees. rst extension
presented Stoilos et al. (2005b), revise denition.
Without loss generality, assume concepts C occurring negation
normal form (NNF) (Hollunder, Nutt, & Schmidt-Schaus, 1990); i.e., negations occur
front concept names only. fKD -SI-concept transformed equivalent one
NNF pushing negations inwards using combination De Morgan laws (which
satised operations dened section 2.3). Next, fuzzy concept D,
denote sub(D) set contains closed sub-concepts
(Horrocks & Sattler, 1999). set sub-concepts concepts appear within
ABox denoted sub(A).
following, use symbols placeholder inequalities , >
, < symbol placeholder types inequalities. Furthermore,
use symbols , denote reections; e.g., reection
> <.
Denition 5.1 fKD -SI ABox, R fKD -SI RBox, RA set roles
occurring R together inverses IA set individuals A,
fuzzy tableau respect R, dened quadruple (S, L, E, V) that:
set elements, L : Ssub(A) [0, 1] maps element concept, member
sub(A), membership degree element concept, E : RA [0, 1]
maps role RA pair elements membership degree pair
role, V : IA maps individuals occurring elements S. s, S,
C, sub(A), n [0, 1] R RA , satises:
1. L(s, ) = 0 L(s,
) = 1 S,
2. L(s, A)n, L(s, A) 1 n,
3. L(s, C D) n, L(s, C) n L(s, D) n,
4. L(s, C D) n, L(s, C) n L(s, D) n,
5. L(s, C D) n, L(s, C) n L(s, D) n,
6. L(s, C D) n, L(s, C) n L(s, D) n,
7. L(s, R.C) n, E(R, s, t) 1 n L(t, C) n,
8. L(s, R.C) n, E(R, s, t) n L(t, C) n,
9. L(s, R.C) n, exists E(R, s, t) n L(t, C) n,
10. L(s, R.C)n, exists E(R, s, t) 1n L(t, C)n,
11. L(s, R.C) n Trans(R), E(R, s, t) n L(t, R.C) n,
12. L(s, R.C) n, Trans(R), E(R, s, t) 1 n L(t, R.C) n,
13. E(R, s, t)n E(Inv(R), t, s)n,
288

fiReasoning Expressive Fuzzy Description Logics

14. (a : C)n A, L(V(a), C)n,
15. (a, b : R)n A, E(R, V(a), V(b))n
remarks regarding Denition 5.1. First, observe use notation
E(R, s, t) instead simply E(R, s, t) order distinguish role R
ordered pair nodes s, t. Moreover, denition based semantics
fuzzy interpretations, presented Table 2, order nd properties fuzzy models
according relation holds membership degree, specic value
inequality type. Then, based properties would develop tableaux expansion
rules, try construct abstracted model. example, property 3, due
semantics C D, (C D)I (s) n, C (s) = n1 , DI (s) = n2 ,
min(n1 , n2 ) = (C D)I (s) n. Due properties min norm
conclude n1 n n2 n, hold. Furthermore, property 7, due
semantics R.C, (R.C)I (s) n have, max(1 RI (s, t), C (s)) n, hence either
1 RI (s, t) n RI (s, t) 1 n C (t) n. Similarly, constructed properties
possible relations node, fKD -SI-concept value unit interval.
Properties 9 10 based fact assume existence witnessed
models. Otherwise, assumption could made. Hence, intuitively fuzzy tableau
abstraction witnessed models fuzzy ABox. Finally, property 14 means
fuzzy assertion form (a : C) > n exists fuzzy ABox, membership
degree node V(a) concept C fuzzy tableau, strictly greater
n. Similarly, rest inequalities well property 15.
prove lemma connecting ABox consistency existence
fuzzy tableau A.
Lemma 5.2 fKD -SI ABox consistent w.r.t. R, exists fuzzy tableau
w.r.t. R.
Proof: direction = (S, L, E, V) fuzzy tableau ABox w.r.t. R,
construct fuzzy interpretation =(I , ) model A.
interpretation dened follows:


=



aI

(s)

=
=

V(a), IA
L(s,
)

(s)
AI (s)

=
=

RI (s, t)

=

L(s, )
L(s, A) concept names
+
(s, t) s, Trans(R)
(s, t) s, otherwise

(s, t) binary fuzzy relation dened (s, t) = E(R, s, t) s, SS,
RE+ represents sup-min transitive closure (Klir & Yuan, 1995).
prove model A, show induction structure concepts
L(s, C)n implies C (s)n S. First, Property 1 ensures top
289

fiStoilos, Stamou, Pan, Tzouvaras & Horrocks

bottom concepts interpreted correctly. Together properties 14, 15,
interpretation individuals roles, implies satises assertion A.
Without loss generality, following, show cases L(s, C) n.
rest inequalities shown similar way.
1. concept name denition nL(s, A) = AI (s).
2. L(s, A) n, due property 2 L(s, A) 1 n. denition I, AI (s)
1 n, hence (A)I (s) c(1 n) = n.
3. L(s, C D) n, L(s, C) n L(s, D) n. induction, C (s) n,
(s) n, hence (C D)I (s) = min(C (s), DI (s)) n.
4. L(s, C D) n, L(s, C) n L(s, D) n. induction either C (s) n
(s) n (C D)I (s) = max(C (s), DI (s)) n.
5. L(s, R.C) n, exists that, E(R, s, t) n L(t, C)
n. denition RI (s, t) n induction C (t) n. Hence, (R.C)I (s) =
suptI min(RI (s, t), C (t)) n.
6. L(s, R.C) n RI (s, t) = p, either
(a) E(R, s, t) = p,
(b) exist several paths l 1 form, E(R, s, sl1 ) = pl1 , E(R, sl1 , sl2 ) =
pl2 , . . . , E(R, slm , t) = plm+1 . membership degree p pair s,
transitive closure R, would equal maximum degree (since cannot
innite number dierent paths) minimum degrees path.
degree lower equal 1 n (since =)
exists path, k, degrees:
E(R, ski , ski+1 ) = pki , 0 m, sk0 s, skm+1 t,
holds pki > 1 n, pki would greater equal
minimum degree path. Hence, due Property 12 ski
L(ski , R.C) n.
case p 1 n max(1 p, C (t)) n. case p 1 n,
L(t, C) n, induction C (t) n thus also max(1 RI (s, t), C (t)) n.
cases (R.C)I (s) n.
converse, =(I , ) (witnessed) model w.r.t. R, fuzzy
tableau = (S, L, E, V) w.r.t. R dened as:


=



E(R, s, t)
L(s, C)

=
=

RI (s, t)
C (s)

V(a)

=

aI

290

fiReasoning Expressive Fuzzy Description Logics

1. Property 1 satised since fuzzy interpretation.
2. Let L(s, C) n. denition implies (C)I (s) = n n C (s) =
1 n 1 n, L(s, C) 1 n Property 2 satised. Similarly
inequalities {, <}.
3. Let L(s, C D) n. denition implies (C D)I (s) = n n
min(C (s), DI (s)) = n n. denition, L(s, C) n L(s, D) n satises
Property 3. Property 4 proved similar way.
4. Let L(s, C D) n. denition implies (C D)I (s) = n n
max(C (s), DI (s)) = n n. denition , either L(s, C) n L(s, D) n,
satises Property 5. Property 6 proved similar way.
5. Let L(s, R.C) n. denition implies (R.C)I (s) = n n
inf yI max(1 RI (s, y), C (y)) = n n. means either
1 RI (s, t) = n n C (t) = n n, denition either E(R, s, t) 1 n
L(t, C) n. Thus, satises Property 7. Property 8 proved similar way.
6. Let L(s, R.C) n. denition implies (R.C)I (s) = n n
supyI min(RI (s, y), C (y)) = n n. means exists
RI (s, t) = n n C (t) = n n. denition satises Property
9. Property 10 proved similar way.
7. Property 12 denition 5.1 satised result semantics transitive roles
value restrictions investigated section 4. Hence, (R.C)I (s)
n, Trans(R) either RI (s, t) 1 n, (R.C)I (t) n holds, otherwise
(R.C)I (s) > n, Trans(R) either RI (s, t) < 1 n (R.C)I (t) > n holds.
denition L(s, R.C) n, Trans(R) either E(R, s, t) 1 n
L(t, R.C) n. similar reasons Property 11, holds.
8. satises Property 13 Denition 5.1 direct consequence semantics
inverse relations.
9. satises Properties 14 15 Denition 5.1 model A.




5.1 Algorithm Constructing fKD -SI Fuzzy Tableau
present tableaux algorithm tries construct, given fKD -SI ABox
fKD -SI RBox R, fuzzy tableau w.r.t. R. prove algorithm construct
fuzzy tableau R exists fuzzy tableau R, thus decides
consistency fKD -SI ABoxes w.r.t. RBoxes.
Like tableaux algorithm presented Horrocks et al. (2000), algorithm works
completion-forests rather completion-trees, since ABox might contain several
individuals arbitrary roles connecting them. Due presence transitive roles,
termination algorithm ensured use blocking, expansion
291

fiStoilos, Stamou, Pan, Tzouvaras & Horrocks

terminated two individuals path asserted belong concepts. fKD -SI provides inverse roles transitive role axioms, algorithm uses
dynamic blocking (Horrocks & Sattler, 1999); i.e., blocked nodes (and sub-branches)
un-blocked blocked later. noted Horrocks Sattler (1999)
un-blocking re-blocking technique crucial presence inverse roles since
information might propagated completion-forest aect branches.
example consider nodes x, z, edges x, x, z suppose x
blocks y. presence inverse roles possible z adds information node x,
although z successor x. case block must broken. Finally, even
cases node blocked un-blocking occur necessary allow
expansion performed. example node might contain inverse information
allowed propagated upwards render completion-forest unsatisable. Thus,
dynamic blocking uses notions directly indirectly blocked nodes.
Denition 5.3 (Completion-Forest) completion-forest FA fKD -SI ABox
collection trees whose distinguished roots arbitrarily connected edges.
node x labelled set L(x) = {C, , n}, C sub(A), {, >, , <}
n [0, 1]. edge x, labelled set L(x, y) = {R, , n}, R RA
(possibly inverse) roles occurring A. Intuitively, triple C, , n (R, , n), called
membership triple, represents membership degree type assertion node
(pair nodes) concept C sub(A) (role R RA ).
nodes x connected edge x, R, , n L(x, y),
called R,n -successor x x called R,n -predecessor y. R,n successor Inv(R),n -predecessor x, called R,n -neighbour x. Let
R>,n -neighbour x, edge x, conjugates triples R, , n m.
Similarly, extend cases R,n -, R<,n - R,n -neighbours.
node x R-successor (resp. R-predecessor R-neighbour) R,n successor (resp. R,n -predecessor R,n -neighbour) role R. node x
positive (resp. negative) successor (resp. predecessor neighbour) {>, }
(resp. {<, }). usual, ancestor transitive closure predecessor.
node x blocked root node either directly indirectly blocked.
node x directly blocked none ancestors blocked, ancestor
L(x) = L(y). case, say directly blocks x. node x indirectly
blocked one predecessor blocked.
node x said contain clash exist two conjugated triples, one
following triples within L(x):
, , n,
, , n, n > 0, n < 1 respectively
, >, n,
, <, n
C, <, 0, C, >, 1
Moreover, edge x, y, L(x, y) said contain clash exist two conjugated
triples L(x, y), L(x, y) {Inv(R), , n | R, , n L(y, x)}, x,
root nodes, contains two conjugated triples.
denition completion-forest quite intuitive. Since fuzzy ABox contains fuzzy
assertions form (a : C)n (a, b : R)n, nodes edges forest
292

fiReasoning Expressive Fuzzy Description Logics

Rule
( )

1.
2.


Description
C, , n L(x)
C, , 1 n L(x)
L(x) L(x) {C, , 1 n}

( )

1.
2.


C1 C2 , , n L(x), x indirectly blocked,
{C1 , , n, C2 , , n} L(x)
L(x) L(x) {C1 , , n, C2 , , n}

( )

1.
2.


C1 C2 , , n L(x), x indirectly blocked,
{C1 , , n, C2 , , n} L(x)
L(x) L(x) {C1 , , n, C2 , , n}

( )

1.
2.


C1 C2 , , n L(x), x indirectly blocked,
{C1 , , n, C2 , , n} L(x) =
L(x) L(x) {C} C {C1 , , n, C2 , , n}

( )

1.
2.


C1 C2 , , nL(x), x indirectly blocked,
{C1 , , n, C2 , , n} L(x) =
L(x) L(x) {C} C {C1 , , n, C2 , , n}

( )

1.
2.


R.C, , n L(x), x blocked,
x R,n -neighbour C, , n L(y)
create new node L(x, y) = {R, , n}, L(y) = {C, , n}

( )

1.
2.


R.C, , n L(x), x blocked,
x R ,1n -neighbour C, , n L(y)
create new node L(x, y) = {R, , 1 n}, L(y) = {C, , n}

( )

1.
2.
3.


R.C, , n L(x), x indirectly blocked,
x R ,n1 -neighbour C, , n L(y)
x, conjugates R, , 1 n
L(y) L(y) {C, , n}

( )

1.
2.
3.


R.C, , n L(x), x indirectly blocked
x R,n1 -neighbour C, , n L(y)
x, conjugates R, , n
L(y) L(y) {C, , n}

(+ )

1.
2.
3.


R.C, , n L(x) Trans(R), x indirectly blocked,
x R ,n1 -neighbour R.C, , n L(y)
x, conjugates R, , 1 n
L(y) L(y) {R.C, , n}

(+ )

1.
2.
3.


R.C, , n L(x) Trans(R), x indirectly blocked
x R,n1 -neighbour R.C, , n L(y)
x, conjugates R, , n
L(y) L(y) {R.C, , n}

Table 4: fKD -SI completion rules
must contain information concept, type inequality membership
degree every individual, forest represented node.
Denition 5.4 (Tableaux Algorithm) fKD -SI ABox A, algorithm initialises
forest FA contain (i) root node xai , individual ai IA occurring A, labelled L(x) {Ci , , n} L(xai ) assertion form (ai : Ci )n
293

fiStoilos, Stamou, Pan, Tzouvaras & Horrocks

A, (ii) edge xai , xaj , assertion (ai , aj : Ri )n A, labelled
L(xai , xaj ) {Ri , , n} L(xai , xaj ). Moreover, algorithm expands R
adding axiom Trans(Inv(R)) Trans(R) R. FA expanded repeatedly
applying completion rules Table 4. completion forest complete when,
node x, L(x) contains clash, none completion rules Table 4 applicable. algorithm stops clash occurs; answers consistent w.r.t. R
completion rules applied way yield complete clash-free
conpletion forest, inconsistent w.r.t. R otherwise.
remarks regarding Denition 5.4. expansion rules based
properties semantics presented Denition 5.1. example, consider ()-rule.
Now, R.C, , 0.7 L(x), R, , 0.6 L(x, y), means last triple
violates property 7 Denition 5.1. property says membership degree
edge x, role R lower equal degree 1 0.7, otherwise
membership degree C greater equal 0.7. Interpreted
membership triples means triple form R, , n exists L(x, y),
n 1 0.7, triple form R, >, n, n < 1 0.7. order discover
restrictions violated ()-rule compares triples edge x,
articial triple R, , 0.3 conjugation. present case conjugation occurs, thus
add triple C, , 0.7 label y. Similar arguments hold rest
properties. Please note articial triples added completion-forest
used perform checks membership degrees. Secondly, tableaux
algorithm, see dealing nite number membership degrees. fact,
Table 4, see arbitrary fuzzy assertion form (x : D)n either
value n complement c(n) appear expansion node x D, , n L(x).
nite property membership degrees makes blocking possible algorithm.
property consequence fuzzy operations used context, i.e. Godel tnorm t-conorm, Lukasiewicz complement Kleene-Dienes fuzzy implication
usually hold combinations fuzzy operations. Finding appropriate
blocking condition norms used combination Description Logics
include transitive relations open research issue. Finally, worth noting since
assume concepts negation normal form ( )-rule applies
concept names. But, since employ rule handling negated concepts
absolutely necessary fuzzy DLs. Hence, able produce NNF form
negated concepts apply ( )-rule directly them. might base
optimization, since might able identify clashes earlier, generalizations
norm operations, since case might able produce NNF
negated concepts. either case, proof lemma 5.9 would require slight modication
order correctly interpret negated concepts.
Example 5.5 Let us see examples applications expansion rules.
( ): Let R.C, , 0.7 L(x) Inv(R), >, 0.3 L(y, x). According
denition R-neighbour, R>,0.3 -neighbour, hence x, conjugates
R, , 0.3, additionally C, , 0.3 L(y). Thus, add C, , 0.3
L(y).
294

fiReasoning Expressive Fuzzy Description Logics

( ): Let Inv(R).C, , 0.7 L(x). create new node forest set,
Inv(R), , 0.7 L(x, y), C, , 0.7 L(y).
(+ ): Let Inv(R).C, <, 0.5 L(x), Inv(R), , 0.7 L(x, y) Trans(R).
Inv(R),0.7 -neighbour x, hence x, conjugates Inv(R), <, 0.5,
additionally Inv(R).C, <, 0.5 L(y). Hence, Inv(R).C, <, 0.5 added
L(y).

revisit example 3.3 see procedure presented section
used determine consistency ABox.
Example 5.6 Recall fuzzy ABox = {(o1 , o2 : isPartOf) 0.8, (o2 , o3 :
isPartOf) 0.9, (o2 : Body) 0.85 (o1 : Arm) 0.75}, wanted test
consistency fuzzy ABox = {(o3 : Inv(isPartOf).Body Inv(isPartOf).Arm) <
0.75}, w.r.t. R = {Trans(isPartOf)}. According Denition 5.4 algorithm initializes
completion-forest contain following triples (note node xoi
individual oi ):
(1)
(2)
(3)
(4)
(5)

isPartOf, , 0.8 L(xo1 , xo2 )
isPartOf, , 0.9 L(xo2 , xo3 )
Body, , 0.85 L(xo2 )
Arm, , 0.75 L(xo1 )
isPartOf .Body isPartOf .Arm, <, 0.75 L(xo3 )

Furthermore, algorithm expands R adding axiom Trans(isPartOf ). Please note
simplicity expanded concepts Arm Body membership
triples. Subsequently, applying expansion rules Table 4 following steps:
(6)

isPartOf .Body, <, 0.75 L(xo3 ) | isPartOf .Arm, <, 0.75 L(xo3 )

(< )

Hence point two possible completion forests. rst one have,
(61 )
(71 )
(81 )

isPartOf .Body, <, 0.75 L(xo3 )
Body, <, 0.75 L(xo2 )
clash (71 ) (3)

(< ) : (61 ), (2)

second possible completion-forest have.
(62 )
(72 )
(82 )
(92 )
(102 )

isPartOf .Arm), <, 0.75 L(xo3 )
Arm, <, 0.75 L(xo2 )
isPartOf .Arm), <, 0.75 L(xo2 )
Arm, <, 0.75 L(xo1 )
clash (92 ) (4)

(< ) : (62 ), (2)
(+ ) : (62 ), (2)
(< ) : (82 ), (1)

Thus, since possible expansions result clash, inconsistent knowledge base
entails fuzzy assertion.
295

fiStoilos, Stamou, Pan, Tzouvaras & Horrocks

Example 5.7 Consider fuzzy knowledge base = , A, R, TBox = {C
R .(P .A)}, ABox = {(a : A) 0.8, (a, b : P ) 0.8, (b : C) 0.8, (b : R.C)
0.8, (b : R.(R.C)) 0.8} RBox R = {Trans(R)}. First algorithm expands R
adding axiom Trans(R ). Then, order check consistency w.r.t. R
algorithm initializes following completion-forest:
(1)
(2)
(3)
(4)
(5)

A, , 0.8 L(xa )
C, , 0.8 L(xb )
R.C, , 0.8 L(xb )
R.(R.C), , 0.8 L(xb )
P, , 0.8 L(xa , xb ).

Then, get following application expansion rules,
(6)
(7)
(8)

C, , 0.8 L(xo1 ), R, , 0.8 L(xb , xo1 )
R.C, , 0.8 L(xo1 )
R.(R.C), , 0.8 L(xo1 )

( ) : (3)
( ) : (4)
(+ ) : (4)

see L(xb ) = L(xo1 ), hence xo1 blocked xb . hand
indirectly blocked. Hence, since R .(P .A), , 0.8 L(xo1 ) (due denition
C TBox) following application expansion rules,
(9)
(10)
(11)
(12)

P .A, , 0.8 L(xb )
A, , 0.8 L(xa )
A, , 0.2 L(xa )
clash (11) (1)

( ) : (6)
( ) : (9)
( ) : (10)

Please note adding P .A, , 0.8 L(xb ) causes blocking node xo1
broken since longer holds L(xb ) = L(xo1 ). Hence, notions indirectly
blocked nodes dynamic blocking crucial presence inverse roles order
correctly identify consistent inconsistent ABoxes. Also note algorithm
chosen expand xo1 (since node blocked) rather xb , would
created another node, say xo2 , L(xo1 ) = L(xo2 ). C, , 0.8
would added xo1 , since xo2 would indirectly blocked, block xo2 would
broken, would hold L(xb ) = L(xo1 ). Hence xo1 would permanently
blocked xo2 indirectly blocked. algorithm would choice
identify clash node xa , showed steps (9) (12).
5.2 Decidability fKD -SI
soundness completeness algorithm demonstrated proving
SI ABox A, always terminates returns consistent consistent.
Lemma 5.8 (Termination) fKD -SI ABox RBox R, tableaux algorithm terminates, started R.
Proof: Let = |sub(A)|, k = |RA | l number dierent membership degrees appearing A. Obviously l linear length A. Termination
consequence following properties expansion rules:
296

fiReasoning Expressive Fuzzy Description Logics

1. expansion rules never remove nodes forest concepts node labels.
2. ()- ()-rule generate new nodes, generation triggered
R.C, , n R.C, , n node label R.C R.C sub(A).
nodes removed, rules applied label repeatedly. Since sub(A) contains R.C R.C, out-degree forest
bounded 2ml.
3. Nodes labelled triples form C, , n, 28ml dierent
possible labellings pair nodes. Thus, path p length least 28ml (note
concepts cause non-termination interact either value n
negation, both), exist two nodes x, p contain
label. Since path nodes blocked cannot become longer, paths
length 28ml .


previous lemma suggests tableaux algorithm runs exponential space.
due well-known problem inherited crisp SI language (Tobies, 2001). Consider
example following concepts taken Tobies (2001),
C R.D R.(R.D)
(A1 B1 ) (A2 B2 ) . . . (An Bn )
R transitive role. consider want check consistency
fuzzy ABox = {(a : C) n}. Concept C causes generation R,n -successors bi
also holds (bi : D) n. due -rule, might choose add
either (bi : Ai ) n (bi : Bi ) n, 2n possible ways expanding D. Hence,
algorithm might create path exponential depth blocking applies. Tobies (2001)
presents optimized blocking technique leads Pspace algorithm SI.
technique involves rened blocking strategy well modication tableaux
expansion rules. Investigating applicability technique fKD -SI interesting
open problem.
Lemma 5.9 (Soundness) expansion rules applied fKD -SI ABox
RBox R yield complete clash-free completion-forest,
fuzzy tableau w.r.t. R.
Proof: Let FA complete clash-free completion-forest constructed tableaux
algorithm A. construction fuzzy tableau = (S, L, E, V) based
construction fuzzy model, presented Straccia (2001):
set triples form A, , ni , positive integer, might exist within
set triples L(x), maximum value ni chosen membership degree x
fuzzy set AI , i.e. degree L(x, A) case. maximum value participates
triple form A, >, n small factor added maximum. existence
value ensured clash-freeness FA . Please also note without loss
generality force factors equal. Furthermore, triple form
C, , ni L(x) exists, triples C, , ni L(x) do, membership degree
297

fiStoilos, Stamou, Pan, Tzouvaras & Horrocks

set 0. cases value existential restriction exists well non conjugated
relation, special care choice made order choose high value
causes conjugation interpretation. last, order interpret concepts
form A, concept name, rst compute maximum degree node
concept use compute A. function returns maximum
degree denoted glb (Straccia, 2001). Please note labellings L(s, C) refer
nodes fuzzy tableau, L(x) nodes completion-forest. fuzzy
tableau dened follows:

L(x, )

=
=

{x | x node FA , x blocked},
0, x S,

L(x,
)
L(x, C)

=
=

1, x S,
glb[C, , ni ], C, , ni L(x) x blocked,

L(x, A)
E(R, x, y)

=
=

V(ai )

=

1 L(x, A), x FA blocked, A, , n L(x),
{glb[R , , ni ] | 1. R,ni -neighbour x
2.R, , ni L(x, z) blocks z
3.Inv(R), , ni L(y, z) x blocks z},
xai , xai root node,

R represents either R Inv(R). shown fuzzy tableau
w.r.t. R:
1. Property 1 Denition 5.1 satised due construction FA
clash-free.
2. Property 2 Denition 5.1 satised -rule apply force
factors equal. Let L(x, A) = n1 n. denition implies
1 n 1 n1 = L(x, A).
3. Properties 3-6 Denition 5.1 satised none apply
x S. example, let L(x, C D) = n1 n. denition implies that,
either C D, , n1 L(x) C D, >, n L(x), n1 = n + . Completeness
FA implies either C, , n1 L(x) D, , n1 L(x) C, >, n L(x)
D, >, n L(x). Hence, L(s, C) = glb[C, , ni ] L(s, C D) n, L(s, D) =
glb = [C, , ni ] L(s, C D) n. rest properties follow similar way.
4. Property 7 Denition 5.1 satised. Let x L(x, R.C) = n1 n
E(R, x, y) 1 n. denition implies either R.C, , n1 L(x)
R.C, >, n L(x) n1 = n + . Moreover, since glb function
create unnecessary conjugation either:
(a) R,r -neighbour x
(b) R, , r L(x, z), blocks z thus L(y) = L(z),
(c) Inv(R), , r L(y, z), x blocks z, thus L(x) = L(z).
298

fiReasoning Expressive Fuzzy Description Logics

R, , r Inv(R), , r causes conjugation. Hence, 3 cases, -rule
ensures either C, , n1 L(y) C, >, n L(y). Thus, either L(y, C) n1
n, L(y, C) n + = n1 n. case L(x, R.C) > n L(x, R.C) n,
latter regards property 8, shown similar way.
5. Property 9 Denition 5.1 satised. Let x L(x, R.C) = n1 n.
denition implies either R.C, , n1 L(x) R.C, >, n L(x),
n1 = n + . -rule ensures either:
(a) predecessor Inv(R), , n1 L(y, x) C, , n1 L(y)
dually > n . predecessor x cannot blocked,
S, E(R, x, y) n1 n L(y, C) n1 E(R, x, y) n + = n1 n
L(y, C) n + = n1 n.
(b) successor R, , n L(x, y), C, , n L(y) dually >
n . blocked, E(R, x, y) n1 , L(y, C) n1
E(R, x, y) n + , L(y, C) n + = n1 . Otherwise, blocked
z. Hence, z R, , n1 L(x, z), C, , n1 L(z) R, >, n
L(x, z), C, >, n L(z). cases L(z, C) n E(R, x, z) n.
Similar proof applies L(x, R.C) > n also Property 10 L(x, R.C)n.
6. Property 12 Denition 5.1 satised. Let x L(x, R.C) = n1 n
E(R, x, y) 1 n. denition implies either R.C, , n1 L(x)
R.C, >, n L(x) n1 = n + . Moreover, since glb function
create unnecessary conjugation either:
(a) R,r -neighbour x
(b) R, , r L(x, z), blocks z thus L(y) = L(z),
(c) Inv(R), , r L(y, z), x blocks z, thus L(x) = L(z).
R, , r Inv(R), , r causes conjugation. Hence, 3 cases, + rule ensures either R.C, , n1 L(y) R.C, >, n L(y). Thus, either
L(y, R.C) n1 n, L(y, R.C) n + = n1 n. case L(x, R.C) > n
L(R.C, , n, latter regards property 11, shown similar way.
7. Property 13 Denition 5.1 satised because, E(R, x, y)n, either:
(a) R,n1 -neighbour x, x Inv(R),n1 -neighbour y.
(b) R, , n1 L(x, z), blocks z, Inv(Inv(R)), , n1 L(x, z)
(c) Inv(R), , n1 L(y, z) x blocks z.
3 cases, E(Inv(R), y, x)n.
8. Properties 14 15 satised cause initialization completion-forest
fact algorithm never blocks root nodes.


299

fiStoilos, Stamou, Pan, Tzouvaras & Horrocks

Lemma 5.10 (Completeness) Let fKD -SI ABox R RBox.
fuzzy tableau w.r.t. R, expansion rules applied way
tableaux algorithm yields complete clash-free completion-forest R.
Proof: proof completeness based proof crisp DLs presented Horrocks
Sattler (1999) Horrocks et al. (2000).
Let = (S, L, E, V) fuzzy tableau A. Using , trigger application
expansion rules yield completion-forest FA complete
clash-free.
Since know fuzzy tableau (T ) steer application rules
yield complete clash-free completion-forest. Horrocks Sattler
(1999) Horrocks et al. (2000) dene mapping maps nodes FA elements
S, guide application non-deterministic rules . method
diers one used crisp DLs (Horrocks & Sattler, 1999) following way.
Using membership degree node concept, found fuzzy tableau, create
articial triples tested conjugation candidate triples
non-deterministic rules insert completion-forest. triples dont cause
conjugation added. modied rules, used guide expansion,
presented Table 5.
( )

1.
2.


( )

1.
2.


C1 C2 , , n L(x), x indirectly blocked,
{C1 , , n, C2 , , n} L(x) =
L(x) L(x) {C} C {C1 , , n, C2 , , n}
conjugated C1 , , L((x), C1 ) C2 , , L((x), C2 )
C1 C2 , , n L(x), x indirectly blocked,
{C1 , , n, C2 , , n} L(x) =
L(x) L(x) {C} C {C1 , , n, C2 , , n}
conjugated C1 , , L((x), C1 ) C2 , , L((x), C2 )

Table 5: - -rules
ensures new fuzzy assertion membership degree node concept,
created non-deterministic rule, restrictive one already known
fuzzy tableau, thus avoiding possible conjugations. together termination
property ensure completeness algorithm.


Theorem 5.11 tableaux algorithm decision procedure consistency fKD -SI
ABoxes satisability subsumption fKD -SI concepts respect simple
terminologies.
Theorem 5.11 immediate consequence lemmas 5.1, 5.9 5.10. Moreover,
discussed section 3, subsumption reduced consistency checking ABoxes.

6. Adding Role Hierarchies Number Restrictions
current section provide necessary extensions reasoning algorithm
presented previous section, order provide reasoning support fuzzy DL
300

fiReasoning Expressive Fuzzy Description Logics

language fKD -SHIN . achieve goal extend results section 4 also
considering role hierarchies, also provide investigation number
restrictions constructor.
classical DLs, results transitive roles value restrictions obtained Sattler
(1996), extended Horrocks Sattler (1999) also consider role hierarchies.
* R,
precisely, show x (R.C)I , x, P , Trans(P ) P
(P.C)I . fuzzy DLs also include role hierarchies easily extend results
obtained section 4. Let (R.C)I (x) ca , P (x, y) = p, Trans(P ), ca , p [0, 1],
consider also P * R. Since P transitive, x, arbitrary
z holds that, P (x, y) min(P (x, z), P (z, y)). Due semantics role
inclusion axioms RI (x, y) min(P (x, z), P (z, y)). Then, work
similar way section 4 get that, max(c(P (a, b)), (P.C)I (b)) va , means
either c(P (a, b)) va (P.C)I (b) va . similar result obtained
case (R.C)I (a) > n. Hence, get following result:
* R, fKD -DL holds
Corollary 6.1 (R.C)I (a) n, Trans(P ) P

that, (P.(P.C)) (a) n.

Finally, case negative assertions existential restrictions following
easily obtained.
* R, fKD -DL holds
Corollary 6.2 (R.C)I (a) n, Trans(P ) P
that, (P.(P.C))I (a) n.

investigate fuzzy number restrictions. Although, Table 2 seems
semantics number restrictions quite complicated, see intuitively,
quite similar crisp counterparts, long also consider membership
degrees.
Consider example at-least restriction ( pR)I (a) n, .
according Table 2 have,
p

sup

min{RI (a, bi )} n.

b1 ,...,bp i=1

means must least p pairs a, bi , RI (a, bi ) n, holds.
semantics quite intuitive similar crisp number restrictions. one
would require least p pairs RI (a, bi ) 1, simply means p
pairs. Similarly, work ( pR)I (a) > n.
Consider at-most restriction form ( pR)I (a) n. Based semantics
inequation,
inf
b1 ,...,bp+1

p+1



max{1 RI (a, bi )} n.
i=1

means p + 1 pairs a, bi , formed, least one pair
c(RI (a, bk )) n, holds. also view equation dierent way
resembles crisp number restrictions. perspective say that,
301

fiStoilos, Stamou, Pan, Tzouvaras & Horrocks

p pairs a, bi c(RI (a, bi )) < n, holds. Similarly, at-most restriction
form ( pR)I (a) > n implies at-most p pairs a, bi , holds
c(RI (a, bi )) n. Hence reasoning w.r.t. number restrictions reduced counting
many role assertions (a, bi : R) ni satisfy inequalities. nd
p assertions satisfy inequalities, non-deterministically merge
individual bi , case crisp SHIN algorithm (Horrocks et al., 2000).
Now, lets consider extreme boundaries 0 1, apply equation classical
at-most restriction, ( pR)I . fuzzy equivalent assertions ( pR)I (a) 1,
implies p bi that, c(RI (a, bi )) < 1 RI (a, bi ) > 0,
holds. Since considering 0 1 last inequality implies, RI (a, bi ) = 1, i.e.
at-most p successors RI .
Dually, also provide intuitive meaning cases involve negative
inequalities, like example cases ( pR)I (a) n1 ( pR)I (a) n2 . Applying
negation rst equation obtain, (( pR))I (a) c(n1 ), c fuzzy complement. Since min max operations satisfy De Morgan laws, assertion
translated ( (p 1)R)I (a) 1 n1 , p 1, negation normal form
former assertion. Similarly, equation ( pR)I (a) n2 transformed
equivalent, ( (p + 1)R)I (a) 1 n2 .
Using results proceed denition fKD -SHIN fuzzy tableau.
Similarly 5.1 consider concepts NNF. achieved using
concept equivalences number restrictions section 3. denition fuzzy tableau
fKD -SHIN rst appeared Stoilos, Stamou, Tzouvaras, Pan, Horrocks (2005c),
revised denition better represent properties fuzzy models.
dening fuzzy tableau fKD -SHIN extend denition sub-concepts
concept ABox A.
Denition 6.3 fuzzy concept role hierarchy R dene sub(D, R)
smallest set fKD -SHIN -concepts satises following:
sub(D, R),
sub(D, R) closed sub-concepts D,
* S, R.C sub(D, R)
S.C sub(D, R) R
* S, R.C sub(D, R)
S.C sub(D, R) R

Finally, dene sub(A, R) =



(a:D)nA

sub(D, R).

R clear context simply write sub(A).
Denition 6.4 fKD -SHIN ABox, R fKD -SHIN RBox, RA set
roles occurring R together inverses, IA set individuals A,
fuzzy tableau w.r.t. R dened Denition 5.1 additional
properties:
* R, E(P, s, t) n L(t, P.C) n,
11. L(s, R.C) n, Trans(P ) P

302

fiReasoning Expressive Fuzzy Description Logics

12. L(s, R.C)n, Trans(P ) P
* R, E(P, s, t) 1n L(t, P.C)n,
* S, E(S, s, t) n,
16. E(R, s, t) n R

17. L(s, pR) n, RT (s, , n) p,
18. L(s, pR) n, RT (s, , 1 n) p + 1,
(s, , n) p 1,
19. L(s, pR) n, R
(s, , 1 n) p,
20. L(s, pR) n, R
.
21. =
b A, V(a) =
V(b)

RT (s, , n) = {t | E(R, s, t)n} returns set elements participate R element degree, greater equal, greater, lower equal
(s, , n) = {t | E(R, s, t) n} returns elements dont
lower n, R
satisfy given inequality.
Denition 5.1, based semantics language observations made beginning section properties value existential restrictions, transitive roles role hierarchies involved, semantic
meaning at-most at-least number restrictions. Thus, property 18 read
as, L(s, pR) n at-most p E(R, s, t) 1 n, i.e.
E(R, s, t) > 1 n, L(s, pR) > n, at-most p
E(R, s, t) < 1 n.
Lemma 6.5 fKD -SHIN ABox consistent w.r.t. R, exists fuzzy tableau
w.r.t. R.
Proof: proof lemma similar lemma 5.2 important
technical details. direction, = (S, L, E, V) fuzzy tableau w.r.t. R,
model = (, ) R constructed = S, aI = V(a), IA ,

(s) = L(s,
), (s) = L(s, ) S, AI (s) = L(s, A),
concept names A, roles have:
+
(s, t),
Trans(R)

R (s, t) =

max (RE (s, t), P (s, t)) otherwise
P
* R,P =R

Observe interpretation non-transitive roles recursive order correctly
interpret non-transitive roles transitive sub-role. denition
RI property 12, RI (s, t) = n (0, 1], either E(R, s, t) = n, E(R, s, t) = 0
exist several paths l 1 form,
E(P, s, sl1 ) = pl1 , E(P, sl1 , sl2 ) = pl2 , . . . , E(P, slm , t) = plm+1
Trans(P ), P
* R E(R, s, t) = max(0, supl {min(pl1 , . . . , plm+1 )}).
Property 16 ensures s, , P (s, t) RI (s, t) P * R. Again,
induction structure concepts show L(s, C)n implies C (s)n
S. Here, restrict attention cases dierent lemma
5.2. Similarly lemma 5.2 also restrict attention inequalities .
303

fiStoilos, Stamou, Pan, Tzouvaras & Horrocks

6. L(s, R.C) n RI (s, t) = p, either
(a) E(R, s, t) = p,
(b) E(R, s, t) = p. Then, exist several paths l 1 form, E(P, s, sl1 ) =
* R.
pl1 , E(P, sl1 , sl2 ) = pl2 , . . . , E(P, slm , t) = plm+1 , Trans(P ) P
membership degree p pair s, (P + )I , would equal maximum degree (since cannot innite number paths) minimum
degrees path. degree lower equal
1 n exists path k degrees
E(P, ski , ski+1 ) = pki , 0 km , sk0 s, skm+1
lower equal 1 n, pki would greater equal
minimum degree path. Hence, due property 11, would
L(ski , P.C) n, 1 km .
case p 1 n max(1 p, C (t)) n. case p 1 n
L(t, C) n, C (t) n thus also max(1 p, C (t)) n. cases
(R.C)I (s) n.
7. L(s, pR) n have, E(R, s, ti ) n, 1 p. denition RI (s, ti )
n, thus
p

n sup {. . . , min{RI (s, ti )}, . . .} = ( pR)I (s).
i=1

ti

8. pR, , n p pairs s, ti which, E(R, s, ti ) 1 n,
1 p. Thus p + 1-tuples formed would least one
pair s, tp+1 E(R, s, tp+1 ) 1 n (even E(R, s, tp+1 ) = 0 1 n).
Hence, RI (s, tp+1 ) 1 n c(RI (s, tp+1 )) n. Finally, that,
p

n inf {. . . , max(max{c(RI (s, ti ))}, c(RI (s, tp+1 ))), . . .} = ( pR)I (s).
ti

i=1

converse, =(I , ) model w.r.t. R, fuzzy tableau =
(S, L, E, V) R dened exactly lemma 5.2. Then,
1. Properties 1-10 13 Denition 5.1 16-20 Denition 6.4 satised
direct consequence semantics fKD -SHIN concepts.
2. Property 12 Denition 6.4 satised consequence semantics transitive roles, role hierarchies value restrictions investigated
* R Trans(P ) either
beginning section. Hence, (R.C)I (s) n, P
P (s, t) 1 n, (P.C)I (t) n holds, otherwise (R.C)I (s) > n, P * R
Trans(P ) either P (s, t) < 1 n (P.C)I (t) > n holds. denition
* R Trans(P ) either E(P, s, t) 1 n L(t, P.C) n.
L(s, R.C) n, P
Similarly, property 11 Denition 6.4.
3. satises Properties 14-15 Denition 5.1 Property 21 Denition 6.4
model A.


304

fiReasoning Expressive Fuzzy Description Logics

6.1 Constructing fKD -SHIN Fuzzy Tableau
section show algorithm fKD -SI, presented section 5.1,
extended deal fKD -SHIN ABoxes. number modications
need made, like denition R-neighbours, (+ )- (+ )-rules, blocking
strategy, clash denition addition rules number restrictions.
important modication algorithm fKD -SI blocking strategy.
noted Horrocks Sattler (1999) DL language provides inverse roles,
transitive role axioms, number restrictions lacks nite-model property; i.e.
fKD -SHIN -concepts satisable innite interpretations. means
usual blocking techniques create cycle predecessor blocked node
blocking one, might fail construct correct tableau due lemma 6.5 correct
model. crucial remark dierence innite witnessed model,
presented remark 3.2. Although fKD -SHIN -concept satisable
innite interpretations, interpretations still witnessed w.r.t. membership
degrees. innite nite property interpretations comes constructs
language, witnessed non-witnessed property comes continuity
fuzzy operators (Hajek, 2005).
Consider example node x contains triple form 1R, , 1.
successor x, say y, blocked ancestor x, say z, dynamic blocking
techniques would create cycle leading x back z. extra edge x, z might
violate number restriction x. overcome problem construction tableau completion-forest performed repeatedly copying sub-tree underneath
node causes blocking, z case. Thus, able obtain innite
constructed nite forest. Furthermore, order copied nodes satisable
new locations extra condition, compared dynamic blocking employed.
new blocking technique called pair-wise blocking (Horrocks & Sattler, 1999); i.e.,
blocking occurs two nodes belong set concepts, predecessors also
belong set concepts edges connect also equal.
way unravelling guaranteed.
Denition 6.6 (fKD -SHIN Completion Forest) First extend denition Rsuccessors, predecessors neighbours. nodes x connected edge x,
* R, called R,n -successor x x called
P, , n L(x, y), P
R,n -predecessor y. R,n -successor Inv(R),n -predecessor x,
called R,n -neighbour x.
role R, node x FA , inequality membership degree n [0, 1]
FA
(x, , n) = {y | R ,n -neighbour x, x, conjugates
dene: RC
R, , n}. Intuitively, set contains R-neighbours x conjugate given
triple.
node x blocked root node either directly indirectly blocked.
node x directly blocked none ancestors blocked, ancestors x ,
that:
1. root node,
2. x successor x successor ,
305

fiStoilos, Stamou, Pan, Tzouvaras & Horrocks

3. L(x) = L(y) L(x ) = L(y ) and,
4. L(x , x) = L(y , y).
case say blocks x. node indirectly blocked one ancestors
blocked, successor node x L(x, y) = .
node x, L(x) said contain clash contains fKD -SI clash,
contains,
triple pR, , n x p+1 Ri ,ni -neighbours y0 , . . . , yp , x, yi conjugates
R, , 1 n yi = yj , ni , n [0, 1], 0 < j p,
triple pR, , n x p Ri ,ni -neighbours y0 , . . . , yp1 , x, yi conjugates
R, , n yi = yj , ni , n [0, 1], 0 < j p 1.
Denition 6.7 (fKD -SHIN Tableaux Algorithm) initialisation forest (FA )
fKD -SHIN ABox similar initialisation forest fKD -SI ABox
A, dierence, equalities inequalities need considered. precisely,
.
.
.
.
xaj ai =
aj relation = empty.
also initialise relation = xai =
latter used keep track nodes merged due application rule
number restrictions. Finally, algorithm expands R adding axioms Inv(R) Inv(S)
R R. FA expanded repeatedly applying completion rules
Tables 4 6. Note Table 6 abuse syntax use notation Inv(L(x, y))
indicate set triples obtained L(x, y) applying function Inv role R
triple R, , n L(x, y).
Example 6.8 Now, let us see examples new expansion rules.
(+ ): Let S.C, >, 0.6 L(x), Inv(P ), , 0.7 L(y, x) Trans(R) P
* S, R,0.7 -neighbour x, since
R S. Then, role R, R
Inv(R),0.7 -predecessor x, x, conjugates Inv(R), <, 0.4, R.C, >
, 0.6 L(y). Hence, R.C, >, 0.6 added L(y).
( ): Let 2S, , 0.7 L(x), S, >, 0.7 L(x, y1 ), S, >, 0.8 L(x, y2 )
* S. Hence, x 3 n -neighbours conjugated
P, , 0.4 L(x, y3 ) P
S, , 1 0.7 S, , 0.3 none ancestor x. Hence nondeterministically merge two them. replace triple S, >, 0.7 L(x, y1 )
S, >, 0.2 rule applicable. although y1 n neighbour x, x, y1 conjugate anymore S, , 0.3. Intuitively,
means connection x y1 weak thus contradict
at-most restriction x.

obvious algorithm used order perform reasoning weaker
language fKD -SHIF (fKD -SHI plus functional number restrictions Horrocks & Sattler,
1999. SHIF obtained SHIN allowing cardinalities 0 1 at-most
at-least restriction. worth noting that, without counting datatypes, SHIF
logical underpinning OWL Lite ontology language (Horrocks et al., 2003).
306

fiReasoning Expressive Fuzzy Description Logics

Rule
(+ )

1.
2.
3.
4.


Description
S.C, , n L(x), x indirectly blocked,
* S,
R, Trans(R), R
x R ,n -neighbour with, R.C, , n L(y),
x, conjugates R, , 1 n
L(y) L(y) {R.C, , n},

(+ )

1.
2.
3.
4.


S.C, , n L(x), x indirectly blocked
* S,
R, Trans(R), R
x R,n -neighbour with, R.C, , n L(y),
x, conjugates R, , n
L(y) L(y) {R.C, , n},

( )

1.
2.


pR, , n L(x), x blocked,
p R,n -neighbours y1 , . . . , yp x yi = yj 1 < j p
create p new nodes y1 , . . . , yp , L(x, yi ) = {R, , n} yi = yj 1 < j p

( )

1.


pR, , n L(x), x blocked,
apply ( )-rule triple (p + 1)R, , 1 n

( )

1.
2.
3.


pR, , n L(x), x indirectly blocked,
.
FA
(x, , 1 n) > p, two y, z, = z
RC
neither root node ancestor z
1. L(z) L(z) L(y)
2. z ancestor x
L(z, x) L(z, x) Inv(L(x, y))
else
L(x, z) L(x, z) L(x, y)
.
.
3. L(x, y) set u = z u u =

( )

1.


pR, , n L(x), x indirectly blocked,
apply ( )-rule triple (p 1)R, , 1 n

(r )

1.
2.


pR, , n L(x),
.
FA
(x, , 1 n) > p, two y, z, root nodes, = z
RC
1. L(z) L(z) L(y)
2. edges y, w:
i. edge z, w exist, create L(z, w) =
ii. L(z, w) L(z, w) L(y, w)
3. edges w, y:
i. edge w, z exist, create L(w, z) =
ii. L(w, z) L(w, z) L(w, y)
4. Set L(y) = remove edges to/from
.
.
.
5. Set u =
z u u = set = z

(r )

1.


pR, , n L(x),
apply (r )-rule triple (p 1)R, , 1 n

Table 6: Additional tableaux rules fKD -SHIN
6.2 Decidability fKD -SHIN
proof termination, soundness completeness fKD -SHIN slightly involved fKD -SI. mainly due requirement apply unravelling
process constructed nite completion forest.
Lemma 6.9 (Termination) Let fKD -SHIN ABox R RBox.
tableaux algorithm terminates started R.
307

fiStoilos, Stamou, Pan, Tzouvaras & Horrocks

Proof: Let = |sub(A)|, k = |RA |, pmax = max{p | pR sub(A)} l number
dierent membership degrees appearing A. termination algorithm
consequence properties ensure termination case crisp SHIN
language (Horrocks et al., 2000). brief following observations. Firstly,
rules remove nodes concepts node labels rules , , r
r , either expand set , means nodes
blocked remain blocked forever. Secondly, expansion rules (,
dual ones negative inequalities) applied node
reasons SHIN case (Horrocks et al., 2000). Since sub(A) contains
concepts R.C R.C, out-degree tree bounded 2lmpmax . Finally,
nite number possible labellings pair nodes edge, since concepts
taken sub(A) number membership degrees nite. Thus,
28mlk possible labellings pair nodes edge. Hence, path p length
least 28mlk , pair-wise blocking condition implies 2 nodes x, p
directly blocks x.


Lemma 6.10 (Soundness) expansion rules applied fKD -SHIN ABox
RBox R, yield complete clash-free completion forest,
fuzzy tableau w.r.t. R.
Proof: Let FA complete clash-free completion forest constructed tableaux
algorithm A. Since SHIN language nite model property (Horrocks & Sattler, 1999) unravel possibly blocked tree order obtain
innite tableau. constructions fuzzy tableau works follows. individual
corresponds path FA . Moving blocked nodes blocking ones
dene innite paths. precisely, path sequence pairs nodes FA
form p = [ xx0 , . . . , xxn ]. path dene Tail(p) := xn Tail (p) := x0 .
n
0
], denote path [ xx0 , . . . , xxn , xxn+1
]. set Paths(FA ) dened inductively
[p | xxn+1


n
n+1
0
n+1
follows:
x

root nodes xai FA , [ xaai ] Paths(FA ),


path p Paths(FA ) node z FA :
z successor Tail(p) z neither blocked root node,
[p | zz ] Paths(FA ),
node FA , successor Tail(p) z blocks y, [p | zy ]
Paths(FA )
Please node since root nodes never blocked, blocking nodes
place occur path rst place. Moreover, p Paths(FA ),
Tail(p) blocked; Tail(p) = Tail (p) Tail (p) blocked last L(Tail(p)) =
L(Tail (p)).
Membership degrees dened exactly case fKD -SI. Then, fuzzy tableau
dened case fKD -SI following dierences:
308

fiReasoning Expressive Fuzzy Description Logics

E(R, p, [p| xx ])
E(R, [q| xx ], q)
E(R, [ xx ], [ yy ])



=
=
=
=

V(ai )

=

Paths(FA ),
glb[R, , n], R, , n L(Tail(p), x )
glb[Inv(R), , n], Inv(R), , n L(Tail(q), x )
glb[R , , n], x, root nodes R-neighbour x,
xai
[ ] xai root node FA L(xai ) =

xai
xa
[ xaj ] L(xaj ) = xaj root node,

j

.
L(xaj ) = xai = xaj

shown fuzzy tableau w.r.t. R:
1. Properties 1-6 Property 13 Denition 5.1 satised due reasons
proof lemma 5.9.
2. property 7, let p, q L(p, R.C) = n1 n E(R, p, q) 1 n,
i.e. E(R, p, q) > 1 n. denition implies either R.C, , n1
L(Tail(p)) R.C, >, n L(Tail(p)) n1 = n + . q = [p| xx ], x
R-successor Tail(p) and, since glb create unnecessary conjugations
R, , r L(Tail(p), x ) conjugates R, , 1 n. Hence, due
completeness FA either C, , n1 L(x ) C, >, n L(x ).
denition Paths(FA ) L(x ) = L(x) = L(q). p = [q| xx ], x
Inv(R)-successor Tail(q) again, denition glb implies Inv(R), , r
L(Tail(q), x ) conjugates Inv(R), , 1 n. Thus, due completeness FA ,
either C, , n1 L(Tail(q)) = L(q) C, >, n L(Tail(q)) = L(q). p = [ xx ]
q = [ yy ] two root nodes x, R-neighbour x, since -rule
apply wither C, , n1 L(y) = L(q) C, >, n L(y) = L(q).
Similar proof holds L(p, R.C) > n property 8, denition 5.1
modied properties 11 12 denition 6.4.
3. property 9 Denition 5.1, assume L(p, R.C) = n1 n let Tail(p) = x.
denition implies either R.C, , n1 L(x) R.C, >, n L(x),
n1 = n + . show q E(R, p, q)
n1 n L(q, C) n1 n. Since -rule applicable
FA either C, , n1 L(y) C, >, n L(y). two possibilities:
(a) successor x, either root node not. case
root node x, since predecessor y, p = [ xx ] q = [ yy ] S.
case root node blocked, q = [p| yy ] S; blocked
z then, q = [p| yz ] S.
(b) x Inv(R)-successor y. Since x successor distinguish cases
x root node not. x root y, hence q = [ yy ] S.
x root node either p = [q| xx ], Tail(q) = y, p = [q| xx ],
Tail(q) = u = y, x blocks x u predecessor x . denition
pair-wise blocking L(y) = L(u) L(y, x) = L(u, x ).
cases, E(R, p, q) n1 n, L(q, C) n1 n. Similar proof applies
L(p, R.C) > n property 10.
309

fiStoilos, Stamou, Pan, Tzouvaras & Horrocks

4. Property 16 denition 6.4 satised due denition R-successor takes
account role hierarchy.
5. Property 17 assume L(p, mR) = n1 n. denition implies
either mR, , n1 L(x) mR, >, n L(x), n1 = n + .
means individuals y1 , . . . , ym FA yi R,n R>,n -neighbour x. show yi s, path
qi , E(R, p, qi ) n1 , qi = qj 1 < j m. proof
similar one given Horrocks et al. (2000). based fact
case z blocks several yi s, construction paths distinguishes
yi seting qi = [p| yzi ], thus ensuring existence dierent paths
. Thus, yi dierent path qi E(R, p, qi ) n1 n,
E(R, p, qi ) n + n RT (p, , n) m. Similarly L(p, mR) > n
property 18.
6. Property 19 denition 6.4 suppose exists p L(p, mR) =
(p, , 1 n) > m. show implies RFA (Tail(p),
n1 n R
C
, 1 n) > m, completion-forest, thus contradicting either clash-freeness
completeness FA . precisely, one show construction
create conjugated paths exist FA .
case node construction creates two distinct paths form
qi = [p| yyi ]. shown Horrocks et al. (2000), proof relies fact
function Tail injective paths , i.e. q1 q2 , Tail (q1 ) = = Tail (q2 )
implies q1 = q2 . Hence, paths cannot distinct. Similar observations hold
L(p, mS) > n property 20.
7. Properties 14 15 Denition 5.1 satised cause initialization
completion-forest fact algorithm never blocks root nodes. Furthermore, root node xai whose label edges removed r -rule,
another root node xaj xai = xaj {C, , n|(ai : C) n A} L(xaj ).
8. Property 21 Denition 6.4 satised r -rule identify two
root nodes xai , xaj xai = xaj holds.


Lemma 6.11 (Completeness) Let fKD -SHIN fuzzy ABox R RBox.
fuzzy tableau w.r.t. R, expansion rules applied R
way tableaux algorithm yields complete clash-free completion-forest.
Proof: proof quite similar proof lemma 5.10. new algorithm
new non-deterministic rules, existence fuzzy tableau w.r.t.
R help us steer application non-deterministic rules. following table
show modied rule . rest non-deterministic rules guided
modifying similar way.


310

fiReasoning Expressive Fuzzy Description Logics

( )

1.
3.


pR, , n L(x), x indirectly blocked,
.
FA
(x, , 1 n) > p, two y, z, =
z
RC
neither root node ancestor z (y) = (z)
1. L(z) L(z) L(y)
2. z ancestor x
L(z, x) L(z, x) Inv(L(x, y))
else
L(x, z) L(x, z) L(x, y)
.
.
3. L(x, y) set u =
z u u =


Table 7: -rule
Theorem 6.12 tableaux algorithm decision procedure consistency problem
fKD -SHIN ABoxes satisability subsumption fKD -SHIN -concepts
respect simple terminologies.
conclude section investigating complexity proposed algorithm.
Lemma 6.13 fKD -SHIN ABox role hierarchy R, sub(A, R) = O(|A|
|R|).
Proof: proof quite similar one presented Tobies (2001). Since sub(A, R)
contains concepts C (a : C)n closed sub-concepts C,
contains O(|A|) concepts. Additionally, add concept R.C R.C
* close sub(A, R)
sub(A, R) S.R sub(A, R) S.R sub(A, R) R
sub-concepts . may yield two concept every concept
sub(A, R) role R. Thus, sub(A, R) = O(2|A| |R|).


Lemma 6.14 fKD -SHIN -algorithm runs 2-Nexptime.
Proof: Let fKD -SHIN ABox R RBox. Let = sub(A), k = |RA |,
pmax maximum number p occurs number restriction l number
dierent membership degrees appearing A. Following Tobies (2001) set n = |A| + |R|,
due lemma 6.13 holds = O(2|A| |R|) = O(n2 ), k = O(|A| + |R|),
pmax = O(2|A| ) = O(2n ) l = O(|A|) = O(n). proof lemma 6.9 shown
paths completion-forest become longer 28mlk out-degree
bounded 2lmpmax . Hence, fKD -SHIN algorithm construct forest

8mlk

(2lmpmax )2

8n2 nn

= O((2n n2 2n )2

8n4

) = O(2n2

n5

) = O(22 )

nodes.


Hence, fKD -SHIN algorithm theoretical complexity SHIN algorithm (Tobies, 2001).
Concluding presentation issue reasoning expressive fuzzy DLs
comment handle GCIs fKD -SI fKD -SHIN languages. noted
Horrocks Sattler (1999), SHIN expressive enough internalize GCIs
single concept, hence reducing reasoning GCIs concept satisability. idea
311

fiStoilos, Stamou, Pan, Tzouvaras & Horrocks

behind internalization semantic restrictions imposed axioms form
C encoded within concept form C D. remarked
Stoilos et al. (2006) reduction concept inclusions hold fKD -DLs, since
semantics axiom C dierent concept C D. Hence,
internalization method proposed Horrocks Sattler (1999) SHIN language
cannot applied fKD -SHIN language.
Stoilos et al. (2006) Li et al. (2006a) propose techniques handle
GCIs fKD -DLs. Stoilos et al. (2006) use DL language fKD -ALC order present
technique, Li et al. (2006a) use language fKD -SHI. procedures
applied cases fKD -SI fKD -SHIN , since independent
underlying DL formalism. Roughly speaking techniques performed three steps.
rst step ABox normalized, replacing assertion form (a : C) > n
(a : C) < n assertions (a : C) n + (a : C) n , respectively,
small number [0, 1]. Obviously, normalized ABox assertions
inequalities present. second step set relative membership degrees
constructed: X = {0, 0.5, 1} {n, 1 n | n}, obviously {, }. Finally,
tableaux expansion rule employed transfer semantic restrictions imposed
GCI C fuzzy assertions ABox. precisely, C ,
node x FA degree n X , algorithm adds either C, , n D, , n
L(x). remark rule proposed Li et al. (2006a) slightly dierent.
noted Stoilos et al. (2006), tableaux algorithms need slightly changed
order handle GCIs. First, due normalization step, degrees taken
interval [, 1 + ], thus clash denitions , >, n
, <, n removed since
assertion > < exist anymore clashes C, <, 0 C, >, 1 replaced
C, , C, , 1 + , respectively. termination algorithm aected
since set membership degrees nite (taken set X ), practical
complexity increases dramatically since non-deterministic choice axiom
C degree n X . proof soundness aected much
showed Stoilos et al. (2006) glb function replaced simple max, due
lack assertions inequalities > <, non-deterministic rule handling
subsumptions also modied guided, order provide us proof
completeness.
Example 6.15 Let knowledge base = { 1R C}, {(a, b : R) 0.6, (a : C) <
0.6}. Intuitively, concept axioms states domain role R concept C.5
Obviously, knowledge base unsatisable since concept axiom suggests xI
, supbI min1i=1 (RI (xI , bIi )) = RI (xI , cI ) C (xI ), arbitrary cI ,
1
ABox assertions state exists aI bI RI (aI , bI ) 0.6 >
C (aI ). concept inclusion axioms GCI, hence use technique
GCIs.
First, apply normalization step original ABox, obtaining normalized
one: {(a, b : R) 0.6, (a : C) 0.6 }. Secondly, collect set relative
membership degrees: X = {0, 0.5, 1} {0.4, 0.4 + , 0.6 , 0.6}.
5. domain axiom also stated R. C, use form order show
algorithm behaves number restrictions.

312

fiReasoning Expressive Fuzzy Description Logics

Then, algorithm initializes completion-forest contain following nodes
respective triples:
(1)
(2)

R, , 0.6 L(xa , xb )
C, , 0.6 L(xa )

algorithm expands completion forest using rules Tables 4 6
additional rule presented Stoilos et al. (2006). rule applied axiom
1R C adds either 1R, , n C, , n L(xa ), n X . Hence,
point algorithm chooses 0.6 X adds either 1R, , 0.6, C, , 0.6.
former case 1R, , 0.6 L(xa ) xa 1 R,0.6 -neighbour xb , xa , xb
conjugated R, , 0.6 , latter case {C, , 0.6 , C, , 0.6} L(xa ),
hence L(xa ) contains pair conjugated triples thus clash. conclude
possible expansions result clash, thus knowledge base unsatisable.


7. Related Work
many eorts past extend description logics fuzzy set theory
(Yen, 1991; Tresp & Molitor, 1998; Straccia, 2001; Holldobler et al., 2002; Sanchez & Tettamanzi, 2006; Straccia, 2005b; Hajek, 2005; Li, Xu, Lu, & Kang, 2006b). rst eort
presented Yen (1991). extension, explicit membership functions domain
used well membership manipulators, like moreOrLess, order
alter membership functions dene new concepts already dened ones. later
approach presented Tresp Molitor (1998), membership manipulators also
appear. Regarding reasoning algorithms Yen described structural subsumption algorithm
rather small DL language Tresp Molitor tableaux calculus ALC F
(ALC extended fuzzy set theory membership manipulator constructor).
application tableaux rules creates set equations inequations later
solved optimization method. Moreover, determining subsumption entailment relation two concepts, respect (KB), assertions KB
considered crisp form (i.e. belongs C degree 1). application
reasoning algorithm solution equations minimum value solution set
taken degree KB entails crisp assertion concept subsumed
another.
fuzzy extension ALC language also considered Straccia (2001, 1998).
Reasoning algorithms problem crisp entailment subsumption provided,
based tableaux calculus. algorithm proved PSPACE-complete.
Moreover, complete reasoning algorithms fuzzy ALC provided Holldobler et al.
(2002), membership manipulators (linguistic hedges) also used primitive
concepts. approach later extended Holldobler, Nga, Khang (2005) allow
linguistic hedges also complex concepts. languages presented called ALC F H
ALC F LH (ALC plus linguistic hedges linear linguistic hedges, respectively).
approaches also min-max norms Kleene-Dienes implication used
perform fuzzy set theoretic operations.
313

fiStoilos, Stamou, Pan, Tzouvaras & Horrocks

Approaches towards expressive DLs, presented Sanchez Tettamanzi
(2004), Sanchez Tettamanzi (2006), Straccia (2005b), Straccia (2005a) Stoilos
et al. (2005c). language considered Sanchez Tettamanzi (2004) ALCQ (ALC
plus qualied number restrictions, Tobies, 2001). authors also include fuzzy quantiers
novel approach fuzzy DLs, norm operations ones
used here. Subsequently, Sanchez Tettamanzi (2006) propose procedure calculate
satisability interval fuzzy concept. Due presence fuzzy quantiers
clear inference problems, like entailment subsumption solved. Straccia
(2005b) considered semantics fuzzy SHOIN (D+ ), DL counterpart
OWL DL language. approach generalized norm operations used
semantics, reasoning algorithms provided well investigation
properties value existential restrictions, transitive relations role hierarchies
participate concepts. Furthermore, semantics number restrictions
analyzed. approach Straccia used Stoilos et al. (2005c), order provide
abstract syntax semantics concept role descriptions axioms fuzzy
OWL language. Additionally, Stoilos et al. (2005c) present method translate fuzzy
OWL ontology fuzzy SHOIN knowledge base, thus reasoning fuzzy OWL
reduced reasoning expressive fuzzy DLs. last language considered Straccia
(2005a) ALC(D) (ALC plus concrete domains), additionally reasoning algorithm
based optimization technique presented. norm operations used ones
used current paper, plus Lukasiewicz t-norm, t(a, b) = max(0, + b 1),
t-conorm, u(a, b) = min(1, + b) fuzzy implication J (a, b) = min(1, 1 + b).
approach towards fuzzy DLs concrete domains also presented Liu, Tian,
(1994) modelling selection research development projects.
previous approaches reasoning respect simple acyclic TBoxes
considered. Stoilos et al. (2006) propose method perform reasoning w.r.t. general
and/or cyclic TBoxes language fKD -ALC. method applies preprocessing step
ABox, called normalization extends classical fKD -ALC algorithm
(Straccia, 2001) additional rule, order deal general cyclic axioms.
Moreover, Li et al. (2006a) extend fuzzy tableau fKD -SHI proposed Stoilos et al.
(2005a) additional rule also handle general cyclic TBoxes language
fKD -SHI. Interestingly, technique used Stoilos et al. (2006) dierent
presented Li et al. (2006a).
also worth noting works Bonatti Tettamanzi (2005), complexity
fuzzy DL languages investigated. Furthermore, Hajek (2005) investigates properties
fuzzy ALC language, arbitrary continuous norm operations used provides
interesting results. precisely, Hajek shows problems concept satisability
subsumption decidable Lukasiewicz fuzzy ALC (fL -ALC), product
fuzzy ALC (fP -ALC) Godel fuzzy ALC (fG -ALC) witnessed satisability subsumption decidable. unrestricted models fP -ALC fG -ALC lack nite
model property (Hajek, 2005). accomplished reducing problems
problem propositional satisability fuzzy propositional logic. results extended fuzzy DLs truth constants, i.e. ABox consistency, Hajek
(2006). Moreover, Straccia (2004) present technique fKD -ALCH knowledge
base reduced crisp ALCH knowledge base. Hence, reasoning fuzzy KB
314

fiReasoning Expressive Fuzzy Description Logics

performed using existing optimized DL systems. Then, Bobillo et al. (2006)
extended technique able reduce fKD -SHOIN KB crisp SHOIN KB.
last, Li, Xu, Lu, Kang, Wang (2005) Li et al. (2006b), also use idea
reduction order annotate concepts roles crisp languages ALCN
ALCQ, respectively degrees denoted sub-scripts syntax concepts roles
provide reasoning languages fKD -ALCN fKD -ALCQ.
previous approaches, reasoning algorithms rather inexpressive fuzzy DLs, i.e.
fuzzy-ALC extended concept modiers concrete domains number restrictions
qualied number restrictions general TBoxes presented. far know
rst presentation reasoning algorithm complex fuzzy DL languages.
order achieve goal provided investigation semantics
extended language fuzzy transitive relations role hierarchies considered
value existential restrictions number restrictions constructor. aim
investigation discover properties classical SI SHIN languages,
like propagation value restrictions counting R-neighbours also apply
fuzzy case. found apart value restrictions also existential restrictions
propagated. Additionally, shown membership degree
concepts new nodes source nodes. Moreover,
seen role hierarchies smoothly integrated classical case. Additionally,
analysis semantics number restrictions shown despite complex
semantics might appear, regarding reasoning also eciently handled,
classical case. Furthermore, investigated applicability blocking
strategies, like dynamic blocking pair-wise blocking, used crisp SI
SHIN language ensure termination proposed algorithms. seen
properties norm operations used ensure blocking conditions also
applied. Based investigations, able provide tableaux reasoning
algorithm, decide key inference problems expressive fuzzy DLs,
proved soundness, completeness termination.

8. Conclusions Future Work
Making applications capable coping vagueness imprecision result
creation systems applications provide us high quality results
answers complex user dened tasks. direction extend fuzzy set
theory underlying logical formalisms use order represent knowledge
perform reasoning tasks. DL logical formalism gained lot attention last
decade, cause decidability, powerful reasoning tools implemented
well-dened model-theoretic semantics.
Towards extending DLs fuzzy set theory presented two expressive
fuzzy DLs, fKD -SI fKD -SHIN . investigated properties semantics
result adding fuzziness expressive fuzzy DLs, i.e. fuzzy DLs allow
transitive inverse roles, role hierarchies number restrictions provided
sound, complete terminating reasoning algorithms formalisms. Even
though handling fuzziness expressive languages seems quite dicult reasoning
previously known, show fKD -SI fKD -SHIN min, max norms
315

fiStoilos, Stamou, Pan, Tzouvaras & Horrocks

still decidable. shown techniques used classical case also
applied extended frameworks, happen closely investigating
properties languages proving techniques also work
new setting. current paper addressed nominals (O) (Horrocks & Sattler,
2005). Note fuzzy DL literature, proposals crisp nominals (Stoilos
et al., 2005c) fuzzy nominals (Bobillo et al., 2006). Thus, nominal constructor
yet mature notion fuzzy DLs research needed order nd appropriate
semantics them, considering also issue application point view.
far future directions concerned, include extension algorithm fKD -SHIN , order provide reasoning support fuzzy DL fKD -SHOIQ.
SHOIQ extends SHIN qualied number restrictions (Tobies, 2001),
important real life applications (Rector & Horrocks, 1997), nominals. Thus,
also intend compare properties dierent proposals nominals fuzzy
DLs. Again, although expect similar notions classical SHOIQ language
applied fKD -SHOIQ, need investigate new setting prove
work. Furthermore, additional research eort focused investigation
reasoning problem f-SI f-SHIN languages, extended norm
operations. Regarding f-SHIN , might dicult problem since counting
number restrictions might possible anymore.

Acknowledgments
work supported FP6 Network Excellence EU project Knowledge Web (IST2004-507482). Giorgos Stoilos, Giorgos Stamou Vassilis Tzouvaras also partially
funded European Commission FP6 Integrated Project X-Media (FP6-026978).

References
Alejandro, J., Belle, T., & Smith, J. (2003). Modal keywords, ontologies reasoning
video understanding. Proceedings International Conference Image
Video Retrieval.
Athanasiadis, T., Mylonas, P., Avrithis, Y., & Kollias, S. (2007). Semantic image segmentation object labeling. IEEE Transactions Circuits Systems Video
Technology, 17 (3), 298312.
Baader, F. (1990). Augmenting Concept Languages Transitive Closure Roles:
Alternative Terminological Cycles. Research report RR-90-13. abridged version
appeaered Proc. IJCAI-91,pp.446-451.
Baader, F., McGuinness, D., Nardi, D., & Patel-Schneider, P. (2002a). Description
Logic Handbook: Theory, implementation applications. Cambridge University
Press.
Baader, F., Horrocks, I., & Sattler, U. (2002b). Description Logics Semantic Web.
KI Kunstliche Intelligenz, 16 (4), 5759.
316

fiReasoning Expressive Fuzzy Description Logics

Bechhofer, S., van Harmelen, F., Hendler, J., Horrocks, I., McGuinness, D. L., PatelSchneider, P. F., & eds., L. A. S. (2004). OWL web ontology language reference.
Tech. rep..
Benitez, A. B., Smith, J. R., & Chang, S. (2000). MediaNet: multimedia information network knowledge representation. Proc. SPIE Vol. 4210, p. 1-12, Internet Multimedia Management Systems, John R. Smith; Chinh Le; Sethuraman Panchanathan;
C.-C. J. Kuo; Eds., pp. 112.
Berners-Lee, T., Hendler, J., & Lassila, O. (2001). semantic web. Scientic American.
Bobillo, F., Delgado, M., & Gomez-Romero, J. (2006). crisp representation fuzzy
shoin fuzzy nominals general concept inclusions. Proc. 2nd International Workshop Uncertainty Reasoning Semantic Web (URSW 06),
Athens, Georgia.
Bonatti, P., & Tettamanzi, A. (2005). complexity results fuzzy description logics.
V. Di Gesu, F. Masulli, A. P. (Ed.), WILF 2003 International Workshop Fuzzy
Logic Applications, LNCS 2955, Berlin. Springer Verlag.
Calvanese, D., De Giacomo, G., Lenzerini, M., Nardi, D., & Rosati, R. (1998). Description
logic framework information integration. Proc. 6th Int. Conf.
Principles Knowledge Representation Reasoning (KR98), pp. 213.
Chen, H., Fellah, S., & Bishr, Y. (2005). Rules geospatial semantic web applications.
W3C Workshop Rule Languages Interoperability.
Ding, Z., & Peng, Y. (2004). Probabilistic Extension Ontology Language OWL.
Proceedings 37th Hawaii International Conference System Sciences (HICSS37)., p. 10, Big Island, Hawaii.
Dubois, D., & Prade, H. (2001). Possibility theory, probability theory many-valued
logics: clarication. Ann. Math. Artif. Intell., 32 (1-4), 3566.
Fagin, R. (1998). Fuzzy queries multimedia database systems. Proc. Seventeenth ACM
Symp. Principles Database Systems, pp. 110.
Giugno, R., & Lukasiewicz, T. (2002). P-SHOQ(D): probabilistic extension shoq(d)
probabilistic ontologies semantic web. JELIA 02: Proceedings
European Conference Logics Articial Intelligence, pp. 8697, London, UK.
Springer-Verlag.
Hajek, P. (1998). Metamathematics fuzzy logic. Kluwer.
Hajek, P. (2005). Making fuzzy description logic general. Fuzzy Sets Systems,
154 (1), 115.
Hajek, P. (2006). Computational complexity t-norm based propositional fuzzy logics
rational truth constants. Fuzzy Sets Systems, 157 (13), 677682.
Holldobler, S., Khang, T. D., & Storr, H.-P. (2002). fuzzy description logic hedges
concept modiers. Proceedings InTech/VJFuzzy2002, pp. 2534.
Holldobler, S., Nga, N. H., & Khang, T. D. (2005). fuzzy description logic ALC F LH .
International workshop Description Logics. CEUR.
317

fiStoilos, Stamou, Pan, Tzouvaras & Horrocks

Hollunder, B. (1994). alternative proof method possibilistic logic application
terminological logics. Proceedings 10th Annual Conference Uncertainty Articial Intelligence (UAI-94), pp. 327335, San Francisco, CA. Morgan
Kaufmann Publishers.
Hollunder, B., Nutt, W., & Schmidt-Schaus, M. (1990). Subsumption algorithms concept
description languages. European Conference Articial Intelligence, pp. 348353.
Horrocks, I., Patel-Schneider, P. F., & van Harmelen, F. (2003). SHIQ RDF
OWL: making web ontology language. Web Semantics, 1.
Horrocks, I., & Sattler, U. (1999). description logic transitive inverse roles
role hierarchies. Journal Logic Computation, 9, 385410.
Horrocks, I., & Sattler, U. (2005). tableaux decision procedure SHOIQ. Proc.
19th Int. Joint Conf. Articial Intelligence (IJCAI 05).
Horrocks, I., Sattler, U., & Tobies, S. (1999). Practical reasoning expressive description
logics. Proceedings 6th International Conference Logic Programming
Automated Reasoning (LPAR99), No. 1705 LNAI, pp. 161180. SpringerVerlag.
Horrocks, I., Sattler, U., & Tobies, S. (2000). Reasoning Individuals Description
Logic SHIQ . MacAllester, D. (Ed.), CADE-2000, No. 1831 LNAI, pp. 482496.
Springer-Verlag.
Kandel, A. (1982). Fuzzy Techniques Pattern Recognition. Wiley.
Klement, E. P., Mesiar, R., & Pap, E. (2004). Triangular norms. position paper I: basic
analytical algebraic properties. Fuzzy Sets Systems, 143, 526.
Klir, G. J., & Yuan, B. (1995). Fuzzy Sets Fuzzy Logic: Theory Applications.
Prentice-Hall.
Koller, D., Levy, A., & Pfeer, A. (1997). P-CLASSIC: tractable probabilistic Description Logic. Proceedings 14th National Conference Articial Intelligence
(AAAI-97)., pp. 390397.
Krishnapuram, R., & Keller, J. (1992). Fuzzy set theoretic approach computer vision:
overview. IEEE International Conference Fuzzy Systems, pp. 135142.
Larsen, H., & Yager, R. (1993). use fuzzy relational thesauri classicatory problem
solving information restrieval exprert systems. IEEE Trans. System, Man,
Cybernetics, 23 (1), 3141.
Li, Y., Xu, B., Lu, J., & Kang, D. (2006a). Discrete tableau algorithms FSHI.
Proceedings International Workshop Description Logics (DL 2006), Lake
District, UK.
Li, Y., Xu, B., Lu, J., & Kang, D. (2006b). Reasoning technique extended fuzzy ALCQ
. ICCSA (2), pp. 11791188.
Li, Y., Xu, B., Lu, J., Kang, D., & Wang, P. (2005). Extended fuzzy description logic ALCN .
Proceedings 9th International Conference Knowledge Based Intelligent
Information EngineeringSystems (KES-05), pp. 896902.
318

fiReasoning Expressive Fuzzy Description Logics

Liu, O., Tian, Q., & Ma, J. (1994). fuzzy description logic approach model management r&d project selection. Proceedings 8th Pacic Asian Conference
Information Systems (PACIS-04).
McGuiness, D. (2003). Conguration. Baader, F., Calvanese, D., McGuinness, D.,
Nardi, D., & Patel-Schneider, P. F. (Eds.), Description Logic Handbook: Theory,
Implementation, Applications, pp. 388405. Cambridge University Press.
Meghini, C., Sebastiani, F., & Straccia, U. (2001). model multimedia information
retrieval. Journal ACM, 48 (5), 909970.
Mostert, P., & Shields, A. (1957). structure semigroups compact manifold
boundary. Annals Mathematics, 65 (1), 117143.
Navara, M. (2000). Satisability fuzzy logic. Neural Network World, 10 (5), 845858.
Nebel, B. (1990). Terminological reasoning inherently intractable. Journal Articial
Intelligence, 43, 235249.
Oguntade, O., & Beaumont, P. (1982). Ophthalmological prognosis via fuzzy subsets. Fuzzy
Sets Systems, 7 (2), 123179.
Pan, J. Z. (2004). Description Logics: Reasoning Support Semantic Web. Ph.D. thesis, School Computer Science, University Manchester, Oxford Rd, Manchester M13 9PL, UK.
Rector, A. L., & Horrocks, I. (1997). Experience building large, re-usable medical ontology
using description logic transitivity concept inclusions. Proceedings
Workshop Ontological Engineering, AAAI Spring Symposium, Stanford CA., pp.
100107. Hanley Belfus, Inc., Philadelphia, PA.
Sanchez, D., & Tettamanzi, A. (2004). Generalizing quantication fuzzy description logic.
Proceedings 8th Fuzzy Days Dortmund.
Sanchez, D., & Tettamanzi, A. A. (2006). Fuzzy quantication fuzzy description logics.
Sanchez, E. (Ed.), Capturing Intelligence: Fuzzy Logic Semantic Web.
Elsevier.
Sattler, U. (1996). concept language extended dierent kinds transitive roles.
KI 96: Proceedings 20th Annual German Conference Articial Intelligence,
pp. 333345. Springer-Verlag.
Stoilos, G., Stamou, G., Tzouvaras, V., Pan, J., & Horrocks, I. (2005a). fuzzy description logic f-SHIN . Proceedings International Workshop Uncertainty
Reasoning Semantic Web.
Stoilos, G., Stamou, G., Tzouvaras, V., Pan, J., & Horrocks, I. (2005b). fuzzy description
logic multimedia knowledge representation. Proc. International Workshop
Multimedia Semantic Web.
Stoilos, G., Stamou, G., Tzouvaras, V., Pan, J., & Horrocks, I. (2005c). Fuzzy OWL:
Uncertainty semantic web. Proc. International Workshop OWL:
Experiences Directions.
319

fiStoilos, Stamou, Pan, Tzouvaras & Horrocks

Stoilos, G., Straccia, U., Stamou, G., & Pan, J. (2006). General concept inclusions fuzzy
description logics. Proceedings 17th International Conference Articial
Intelligence (ECAI 06), pp. 457461. IOS Press.
Straccia, U. (2001). Reasoning within fuzzy description logics. Journal Articial Intelligence Research, 14, 137166.
Straccia, U. (2005a). Description logics fuzzy concrete domains. 21st Conf.
Uncertainty Articial Intelligence (UAI-05), Edinburgh.
Straccia, U. (2005b). Towards fuzzy description logic semantic web. Proceedings
2nd European Semantic Web Conference.
Straccia, U. (1998). fuzzy description logic. AAAI 98/IAAI 98: Proceedings
fteenth national/tenth conference Articial intelligence/Innovative applications
articial intelligence, pp. 594599. American Association Articial Intelligence.
Straccia, U. (2004). Transforming fuzzy description logics classical description logics.
Proceedings 9th European Conference Logics Articial Intelligence
(JELIA-04), No. 3229 Lecture Notes Computer Science, pp. 385399, Lisbon,
Portugal. Springer Verlag.
Sugeno, M. (1985). Industrial Applications Fuzzy Control. North-Holland.
Tarski, A. (1956). Logic, Semantics, Metamathemetics: Papers 1923 1938. Oxford
University Press.
Tobies, S. (2001). Complexity Results Practical Algorithms Logics Knowledge Representation. Ph.D. thesis, Rheinisch-Westfalischen Technischen Hochschule Aachen.
URL http://lat.inf.tu-dresden.de/research/phd/Tobies-PhD-2001.pdf .
Tresp, C., & Molitor, R. (1998). description logic vague knowledge. proc
13th European Conf. Articial Intelligence (ECAI-98).
Vardi, M. Y. (1997). modal logic robustly decidable?. DIMACS Series
Discrete Mathematics Theoretical Computer Science, pp. 149184.
Yen, J. (1991). Generalising term subsumption languages fuzzy logic. Proc
12th Int. Joint Conf Articial Intelligence (IJCAI-91), pp. 472477.
Zadeh, L. A. (1965). Fuzzy sets. Information Control, 8, 338353.
Zimmermann, H. (1987). Fuzzy Sets, Decision Making, Expert Systems. Kluwer, Boston.

320

fiJournal Artificial Intelligence Research 30 (2007) 133179

Submitted 3/07; published 9/07

Chain: Dynamic Double Auction Framework Matching
Patient Agents
Jonathan Bredin

bredin@acm.org

Dept. Mathematics Computer Science, Colorado College
Colorado Springs, CO 80903, USA

David C. Parkes
Quang Duong

parkes@eecs.harvard.edu
qduong@fas.harvard.edu

School Engineering Applied Sciences, Harvard University
Cambridge, 02138, USA

Abstract
paper present evaluate general framework design truthful
auctions matching agents dynamic, two-sided market. single commodity,
resource task, bought sold multiple buyers sellers arrive
depart time. algorithm, Chain, provides first framework allows
truthful dynamic double auction (DA) constructed truthful, single-period (i.e.
static) double-auction rule. pricing matching method Chain construction
unique amongst dynamic-auction rules adopt building block. examine
experimentally allocative efficiency Chain instantiated various single-period
rules, including canonical McAfee double-auction rule. baseline also consider
non-truthful double auctions populated zero-intelligence plus-style learning agents.
Chain-based auctions perform well comparison schemes, especially arrival
intensity falls agent valuations become volatile.

1. Introduction
Electronic markets increasingly popular method facilitate increased efficiency
supply chain, firms using markets procure goods services. Two-sided
markets facilitate trade many buyers many sellers find application
trading diverse resources, including bandwidth, securities pollution rights. Recent
years also brought increased attention resource allocation context ondemand computing grid computing. Even within settings cooperative coordination,
multiple robots, researchers turned auctions methods task
allocation joint exploration (Gerkey & Mataric, 2002; Lagoudakis et al., 2005; Lin &
Zheng, 2005).
paper consider dynamic two-sided market single commodity, instance unit resource (e.g. time computer, quantity memory chips)
task perform (e.g. standard database query execute, location visit).
agent, whether buyer seller, arrives dynamically needs matched within time
interval. Cast task-allocation problem, seller perform task allocated
within time interval incurs cost assigned. buyer positive value
task assigned (to seller) within time interval. arrival time, acceptable time interval, value (negative seller) trade private information
c
2007
AI Access Foundation. rights reserved.

fiBredin, Parkes Duong

agent. Agents self-interested choose misrepresent
information market order obtain desirable price.
matching problem combines elements online algorithms sequential decision
making considerations mechanism design. Unlike traditional sequential decision
making, protocol problem must provide incentives agents report truthful
information match-maker. Unlike traditional mechanism design, dynamic
problem agents arrive leave time. model problem dynamic
double auction (DA) identical items. match-maker becomes auctioneer.
seller brings task performed time window buyer brings
capability perform single task. double-auction setting also interest
right protocol matching dynamic business-to-business exchange.
Uncertainty future coupled two-sided nature market leads
interesting mechanism design problem. example, consider scenario
auctioneer must decide (and whether) match seller reported cost $6
end time interval present unmatched buyer, one reported
value $8 one reported value $9. auctioneer pair higher bidder
seller? happens seller, willing sell $4, arrives auctioneer
acts upon matching decision? matching algorithm designed
agent benefit misstating earliest arrival, latest departure, value
trade?
Chain provides general framework allows truthful dynamic double auction
constructed truthful, single-period (i.e. static) double-auction rule. auctions
constructed Chain truthful, sense dominant strategy agent,
whatever future auction dynamics bids agents, report true
value trade (negative selling) true patience (maximal tolerance trade delay)
immediately upon arrival market. also allow randomized mechanisms and,
case, require strong truthfulness: DA truthful possible random
coin flips mechanism. One DAs class auctions implied Chain
dynamic generalization McAfees (1992) canonical truthful, no-deficit auction
single period. Thus, provide first examples truthful, dynamic DAs allow
dynamic price competition buyers sellers.1
main technical challenge presented dynamic DAs provide truthfulness without incurring budget deficit, handling uncertainty future trade opportunities.
particular concern ensure agent indirectly affect price
effect bid prices faced agents thus supply demand
market. need preclude availability trades depends
price faced agents. example, buyer required pay $4 DA
trade might like decrease price potentially matching seller receive $6
$3 allow trade.
Chain modular approach auction design, takes building block singleperiod matching rule provides method invoke rule multiple periods
also providing truthfulness. characterize properties well-defined single1. closest work literature due Blum et al. (2006), present truthful, dynamic DA
model matches bids asks based price sampled bid-independent distribution.
compare performance schemes scheme Section 6.

134

fiChain: Online Double Auction

period matching rule must satisfy order Chain truthful. identify
technical property strong no-trade, isolate agents fail trade
current period nevertheless survive eligible trade future period.
auction designer defines strong no-trade predicate, addition providing welldefined single-period matching rule. Instances within class include constructed
terms price-based matching rules competition-based matching rules.
depend history adaptive, competition-based rules use
active bids asks determine prices current period, facilitating direct
competitive processes.
proving Chain, combined well-defined matching rule valid
strong no-trade predicate, truthful leverage recent price-based characterization
truthful online mechanisms (Hajiaghayi et al., 2005). also show pricing
matching rules defined Chain unique amongst family mechanisms
constructed single-period matching rule building block. Throughout work
assume constant limits every buyer sellers patience. motivate assumption
provide simple environment truthful, no-deficit DA implement
constant fraction number efficient trades, constant.
adopt allocative efficiency design objective, say auction protocols
maximize expected total value sequence trades. also consider net
efficiency, wherein net outflow payments marketmaker also accounted
considering quality design. Experimental results explore allocative efficiency
Chain instantiated various single-period matching rules range different
assumptions market volatility maximal patience. baseline consider
efficiency standard (non-truthful) open outcry DA populated simple adaptive
trading agents modeled zero-intelligence plus (ZIP) agents (Cliff & Bruten, 1998;
Preist & van Tol, 1998). also compare efficiency Chain truthful
online DA due Blum et al. (2006), selects fixed trading price guarantee
competitiveness adversarial model.
within truthful mechanisms find adaptive, price-based instantiations
Chain effective high arrival intensity low volatility. Even defining
single, well-chosen price optimized market conditions reasonably
effective promoting efficient trades low volatility environments. hand,
medium low arrival intensity medium high volatility find Chainbased DAs allow dynamic price competition, McAfee-based rule,
efficient. qualitative observations hold whether one interested allocative efficiency net efficiency, although adaptive, price-based methods better
performance terms net efficiency. Blum et al. (2006) rule fairs poorly
tests, perhaps unsurprising given optimized worst-case performance
adversarial setting. populated ZIP agents, find non-truthful DAs
provide good efficiency low volatility environments poor performance
high volatility environments. good performance ZIP-based market occurs
agents learn bid approximately truthfully; i.e., market operates truthful,
without incurring stringent cost (e.g., trading constraints) imposing
truthfulness explicitly. equilibrium analysis available truthful DAs;
135

fiBredin, Parkes Duong

way knowing close ZIP agents playing equilibrium, note
ZIP agents even consider performing time-based manipulations.
1.1 Outline
Section 2 introduces dynamic DA model, including assumptions, presents
desiderata online DAs price-based characterization design truthful
dynamic auctions. Section 3 defines Chain algorithm together building block
well-defined, single-period matching rule strong no-trade predicate. Section 4
gives number instantiations price-based competition-based matching rules,
including general method define strong no-trade predicate given price-based instantiation. Section 5 proves truthfulness, no-deficit feasibility Chain auctions
also establishes uniqueness amongst auctions constructed singleperiod matching-rule building block. importance assumption maximal
agent patience established. Section 6 presents empirical analysis, including description simple adaptive agents use populate non-truthful open-outcry DA
provide benchmark. Section 7 gives related work. Section 8 conclude
discussion merits truthfulness markets present possible extensions.

2. Preliminaries: Basic Definitions
Consider dynamic auction model discrete, possibly infinite, time periods =
{1, 2, . . .}, indexed t. double auction (DA) provides market single commodity.
Agents either buyers sellers interested trading single unit commodity.
agents type, = (ai , di , wi ) , set possible types agent i, defines
arrival ai , departure di , value wi R trade. agent buyer, wi > 0.
agent seller, wi 0. assume maximal patience K, di ai + K
agents.
arrival time models first time agent learns market
learns value trade. Thus, information type available
period ai (not even agent i) agent cannot engage trade period ai .
departure time, di , models final period buyer positive value trade,
final period seller willing engage trade. model risk-neutral
agents quasi-linear utility, wi p trade occurs [ai , di ] payment p
collected (with p < 0 agent seller). Agents rational self-interested,
act maximize expected utility. assumption, sellers utility payments
received true departure period.
Throughout paper adopt bid refer, generically, claim agent
either buyer seller makes DA type. addition, need
specific distinction claims made buyers claims made sellers
refer bid buyer ask seller.
2.1 Example
Consider following naive generalization (static) trade-reduction DA (Lavi & Nisan,
2005; McAfee, 1992) dynamic environment. bid agent claim
136

fiChain: Online Double Auction

type = (ai , di , wi ), necessarily made period = ai . Bids active [ai , di ]
trade occurred.
period t, use trade-reduction DA determine (if any)
active bids trade price. trades occur immediately. trade-reduction
DA (tr-DA) works follows: Let B denote set bids denote set asks.
Insert dummy bid value + B dummy ask value 0 S.
|B| 2 |S| 2 sort B order decreasing value. Let wb0 wb1 . . .
ws0 ws1 . . . denote bid ask values (b0 , s0 ) denoting dummy bid-ask
pair. Let 0 index last pair bids asks clear efficient trade,
wbm + wsm 0 wbm+1 + wsm+1 < 0. 2 bids {b1 , . . . , bm1 } asks
{s1 , . . . , sm1 } trade payment wbm collected winning buyer payment
wsm made winning seller.
First consider static tr-DA following bids asks:

B
wi wi
b1 15 s1 -1
b2 10 s2 -1
b3 4 s3 -2
b4 3 s4 -2
s5 -5
line indicates bids (14) asks (14) could matched efficient trade.
rules tr-DA, bids (13) asks (13) trade, payments $3 collected
winning buyers payment $2 made winning sellers. auctioneer earns profit
$3. asterisk notation indicates bids asks trade. tr-DA truthful,
sense dominant-strategy every agent report true value whatever
reports agents. intuition, consider buy-side. payment made
winners independent bid price losing bidder could win bidding
$4, point payment would $4 true value.
consider dynamic variation buyer types {(1, 2, 15), (1, 2, 10), (1, 2, 4), (2, 2, 3)}
seller types {(1, 2, 1), (2, 2, 1), (1, 1, 2), (2, 2, 2), (1, 2, 5)}. agents truthful, dynamic tr-DA plays follows:
period 1
period 2

B

B
wi wi
wi wi
b1 15 s1 -1
b2 10 s2 -1
b3 4 s4 -2
b2 10 s3 -2
b3 4 s5 -5
b4 3 s5 -5
period 1, buyer 1 seller 1 trade payments $10 $2 respectively.
period 2, buyer 2 seller 2 trade payments $4 $2 respectively.
construct two kinds manipulation show dynamic DA truthful. First,
buyer 1 better delaying reported arrival period 2:
137

fiBredin, Parkes Duong

period 1
period 2

B

B
wi wi
wi wi
b1 15 s2 -1
b2 10 s1 -1
b3 4 s4 -2
b3 4 s3 -2
s5 -5
b4 3 s5 -5
Now, buyer 2 trades period 1 set price buyer 1 period 2. Instead,
buyer 1 trades period 2 makes payment $4.
Second, buyer 3 better increasing reported value:
period 1
period 2

B

B
wi wi
wi wi
b3 6 s2 -1
b1 15 s1 -1


b4 3 s4 -2
b2 10 s3 -2
b3 6 s5 -5
s5 -5
Now, buyers 1 2 trade period 1 allows buyer 3 win (at price
true value) period 2. particularly interesting manipulation
agents manipulation increasing bid true value. so, allows
trades occur makes auction less competitive next period.
2.2 Dynamic Double Auctions: Desiderata
consider direct-revelation, dynamic DAs restrict message agent
send auctioneer single, direct claim type. also consider closed
auctions agent receives feedback reporting type cannot condition
strategy report another agent.2
Given this, let denote set agent types reported period t, = ( 1 , 2 , . . . , , . . . , )
denote complete type profile (perhaps unbounded), denote type profile restricted agents (reported) arrival later period t. report = (ai , di , wi )
represents commitment buy (sell) one unit commodity period [ai , di ]
payment wi . Thus, seller reports departure time di > di , must
commit complete trade occurs true departure even though seller
modeled utility payments received true departure.
dynamic DA, = (, x), defines allocation policy = { }tT payment
policy x = {xt }tT , ( ) {0, 1} indicates whether agent trades period
given reports t, xti ( ) R indicates payment made agent i, negative
payment received agent. auction rules also stochastic, ( )
xti ( ) random variables. dynamic DA well defined, must hold
( ) = 1 one period [ai , di ] zero otherwise, payment collected
agent zero except periods [ai , di ].
formalizing desiderata dynamic DAs, convenient adopt ((), x())
denote complete sequence allocation decisions given reports , shorthand
2. restriction direct-revelation, online mechanisms without loss generality combined
simple heart-beat message agent indicate presence period reported
arrival-departure interval. See work Pai Vohra (2006) Parkes (2007).

138

fiChain: Online Double Auction

() {0, 1} xi () R indicate whether agent trades reported arrivaldeparture interval, total payment made agent i, respectively. slight abuse
notation, write denote agent reported type later period t.
Let B denote set buyers denote set sellers.
shall require dynamic DA satisfies no-deficit, feasibility, individual-rationality
truthfulness. No-deficit ensures auctioneer cash surplus every period:
Definition 1 (no-deficit) dynamic DA, = (, x) no-deficit if:
X
X


xti ( ) 0, t,

(1)

[ai ,min(t,di )]

Feasibility ensures auctioneer need take short position
commodity traded market period:
Definition 2 (feasible trade) dynamic DA, = (, x) feasible if:
X
X
X
X




( ) 0, t,
( )
,iS [ai ,min(t,di )]

(2)

,iB [ai ,min(t,di )]

definition feasible trade assumes auctioneer hold item
matched seller-buyer pair, instance releasing buyer upon
reported departure. See remark concluding section discussion
assumption.
Let vi (i , (i , )) R denote value agent type allocation
decision made policy given report (i , ), i.e. vi (i , (i , )) = wi agent
trades period [ai , di ] 0 trades outside interval buyer,
trades outside interval seller. Individual-rationality requires agent
utility non-negative reports true type, whatever reports agents:
Definition 3 (individual-rational) dynamic DA, = (, x) individual-rational
(IR) vi (i , ()) xi () 0 i, .
order define truthfulness, introduce notation C(i ) denote
set available misreports agent true type . standard model adopted
offline mechanism design, typical assume C(i ) = misreports available.
Here, shall assume early-arrival misreports, C(i ) = {i = (ai , di , wi ) : ai ai
di }. assumption limited misreports adopted earlier work online mechanism
design (Hajiaghayi et al., 2004), well-motivated arrival time first
period buyer first decides acquire item period seller first
decides sell item.
Definition 4 (truthful) Dynamic DA, = (, x), dominant-strategy incentivecompatible, truthful, given limited misreports C if:




vi (i , (i ,
)) xi (i ,
) vi (i , (i ,
)) xi (i ,
).
C( ),
C(i ), ,

.

139

fiBredin, Parkes Duong

robust equilibrium concept: agent maximizes utility reporting
true type whatever reports agents. Truthfulness useful simplifies
decision problem facing bidders: agent determine optimal bidding strategy
without model either auction dynamics agents. case
allocation payment policy stochastic, adopt requirement strong
truthfulness agent maximizes utility whatever random sequence coin
flips within auction.
Remark. flexible definition feasibility, auctioneer able take
long position commodity, allows auctioneer time trades receiving unit
sold seller one period releasing buyer later period. allows
truthfulness environments bidders overstate departure period.
settings unreasonable requirement, however, instance commodity represents task performed, physical good traded
electronic market.3 cases, definition feasibility strengthened require exact trade-balance every period. tradeoff available misreports must
restricted, agents limited reporting late-departures addition
early-arrivals (Lavi & Nisan, 2005; Hajiaghayi et al., 2005). rest paper
work relaxed feasibility, early-arrival model. Chain framework immediately extended strong-feasibility, early-arrival late-departure model
executing trades immediately rather delaying trade buyers departure.

3. Chain: Framework Truthful Dynamic DAs
Chain provides general algorithmic framework construct truthful dynamic
DAs well-defined single-period matching rules, tr-DA rules described
earlier section.
introducing Chain need definitions: Bids reported Chain
active di (for reported departure period di ), bid unmatched
still eligible matched. period, single-period matching rule used
determine whether active bids trade also (if any) bids
match remain active next period.
define building blocks, well-defined single-period matching rules, introduce important concept strong no-trade predicate, defined singleperiod matching rule.
3.1 Building Block: Single-Period Matching Rule

n
defining matching rule, helpful adopt bt Rm
>0 R0 denote
active bids active asks period t, 0 n 0 bids asks
respectively. bids asks active earlier periods longer active
form history period t, denoted H Rh h 0 size history.
single-period matching rule (hereafter matching rule), Mmr = (mr , xmr ) defines
allocation rule mr (H , bt , st , ) {0, 1}(m+n) payment rule xmr (H , bt , st , )

3. Note task computational task, tasks handled within model requiring
seller performs task matched commitment hold onto result
matched buyer ready depart.

140

fiChain: Online Double Auction

function SimpleMatch(H ,bt ,st )
matched :=
pt := mean(|H |)
(bt 6= )&(st 6= )
:= 0, bi := , j := 0, sj :=
(bi < pt )&(bt 6= )
:= random(bt ), bt := bt \ {i}
end
(sj < pt )&(st 6= )
j := random(st ), st := st \ {j}
end
(i 6= 0)&(j 6= 0)
matched := matched {(i, j)}
end
end
end function

Figure 1: well-defined matching rule defined terms mean bid price history.
R(m+n) . Here, include random event allow explicitly stochastic matching
allocation rules.
Definition 5 (well-defined matching rule) matching rule Mmr = (mr , xmr ) welldefined strongly truthful, no-deficit, individual-rational, strong-feasible.
Here, properties truthfulness, no-deficit, individual-rationality exactly
single-period specializations defined previous section. instance,
matching rule truthful sense dominant strategy agent
DA defined rule, static environment, bid truthfully
possible random events . Similarly individual-rationality. No-deficit requires
total payments always non-negative. Strong-feasibility requires exactly
number asks accepted bids, random events.
One example well-defined matching rule tr-DA, invariant
history bids asks. example well-defined, adaptive (history-dependent)
price-based matching rule, consider procedure SimpleMatch Figure 1. SimpleMatch matching rule computes mean absolute value bids asks
history H adopts clearing price current period. stochastic
matching rule bids asks picked sets bt st random
offered price. reason properties SimpleMatch follows:
(a) truthful: price pt independent bids probability bid (or
ask) matched independent bid (or ask) price
(b) no-deficit: payment pt collected matched buyer made
matched seller
(c) individual-rational: bids bi pt asks sj pt accepted.
(d) feasible: bids asks introduced matched set balanced pairs
141

fiBredin, Parkes Duong

3.2 Reasoning Trade (Im)Possibility
addition defining matching rule Mmr , allow designer (optionally) designate
subset losing bids satisfy property strong no-trade. Bids satisfy strong
no-trade losing bids trade possible bid price (c.f. ask price
asks), moreover additional independence conditions hold bids
provided designation.
first define weaker concept no-trade.
following, notation
mr,i (H , bt , st , |wi ) indicates allocation decision made bid (or ask) bid
(ask) price replaced wi :
Definition 6 (no-trade) Given matching rule Mmr = (mr , xmr ) set agents,
NTt , trade possible period given random events
mr,i (H , bt , st , |wi ) = 0, every wi R>0 bt every wi R0
st .
easily happen trade possible, instance agent buyer
sellers side market. Let SNTt NTt denote set
agents designated property strong no-trade. Unlike no-trade property,
strong no-trade need uniquely defined matching rule. valid, however,
construction offered designer strong no-trade must satisfy following:
Definition 7 (strong no-trade) construction strong no-trade, SNTt NTt ,
valid matching rule when:
(a) NTt di > t, whether SNTt unchanged alternate reports
= (ai , di , wi ) 6= di > t,
(b) SNTt di > t, set {j : j SNTt , j 6= i, dj > t} unchanged
reports = (ai , di , wi ) 6= di > t, independent even whether agent
present market.
strong no-trade conditions must checked agents reported departure later current period. Condition (a) requires agent NTt cannot
affect whether satisfies strong no-trade predicate long continues
report departure later current period. Condition (b) defined recursively,
requires agent identified satisfying strong no-trade, report
must affect designation strong no-trade agents, reported departure
later current period, continues report departure later current
period even delays reported arrival later period.
Strong no-trade allows flexibility determining whether bid eligible
matching. Specifically, bids satisfy strong no-trade amongst lose
current period remain candidate trade future period. property
defined ensure surviving agent not, could not, affect set
agents competes future periods.
142

fiChain: Online Double Auction

Example 1 Consider tr-DA matching rule defined earlier bids asks
B

wi
wi


b1 10 s1 4
b2 8 s2 6
b3 6 s3 8
Bid 1 ask 1 trade price 8 6 respectively. NTt = bids 2 3 could
trade (unilaterally) submitted bid price greater 10. Similarly
asks 2 3. consider order book

B
wi
wi
b1 8 s1 6
b2 7 s2 10
b3 2 s3 12
trade occurs. case, NTt = {b1 , b2 , b3 , s1 }. trade possible bids, even
bids 2 3, wb1 + ws2 = 8 10 < 0. But, trade possible asks 2 3,
wb2 + ws1 = 7 6 0 either ask could trade submitting low enough ask price.
Example 2 Consider tr-DA matching rule explore possible alternative constructions strong no-trade.
(i) Dictatorial: period t, identify agent could present period
way oblivious agent reports. Let denote index agent. NTt ,
include SNTt = {i}. Strong no-trade condition (a) satisfied whether
selected dictator agent-independent, given selected, whether
trade possible agent-independent. Condition (b) trivially satisfied
|SNTt | = 1 cross-agent coupling consider.
(ii) SNTt := NTt . Consider order book

B
wi
wi
b1 3 s1 4
b2 2 s2 6
b3 1 s3 8
Suppose bids asks remain market least one period. Clearly,
NTt = {b1 , b2 , b3 , s1 , s2 , s3 }. Consider candidate construction SNTt = NTt . Strong notrade condition (a) satisfied whether set NTt agent-independent.
Condition (b) satisfied, however. Consider bid 2. bid 2s report 8 instead
2 trade would possible bids 1 3, SNTt = NTt = {b2 , s1 , s2 , s3 }. Thus,
whether bids 1 3 satisfy strong no-trade predicate depends value bid
2. valid construction strong no-trade tr-DA matching rule.
(iii) SNTt = NTt |bt | < 2 |st | < 2, SNTt = otherwise. above, strong
no-trade condition (a) immediately satisfied. Moreover, condition (b) satisfied
trade possible bid ask irrespective bid values
simply enough bids asks allow trade tr-DA (which needs least 2 bids
least 2 asks).
143

fiBredin, Parkes Duong

Figure 2: decision process Chain upon arrival new bid. admitted, bid
participates sequence matching events remains unmatched
strong no-trade set. bid matches first available opportunity priced
immediately.

Example 3 Consider variant SimpleMatch matching rule, defined fixed
price 9. ask whether SNTt := NTt valid construction strong no-trade.
Throughout example suppose bids asks remain market least one
period. First consider bid wb1 = 8 two asks values ws1 = 6
ws2 = 7. Here, NTt = {s1 , s2 } asks cannot trade whatever price since
bid high enough meet fixed trading price 9. Moreover, SNTt = {s1 , s2 }
valid construction; strong no-trade condition (a) satisfied condition (b)
satisfied whether ask 2 NTt (and thus SNTt ) independent
price ask 1, vice versa. consider instead bid wb1 = 8 ask
ws1 = 10. Now, NTt = {b1 , s1 } SNTt = {b1 , s1 } candidate strong no-trade set.
However bid 1 declared value 10 instead 8 NTt = {b1 } ask 1 drops
SNTt . Thus, strong no-trade condition (b) satisfied.
see examples quite delicate provide valid, nontrivial construction strong no-trade. Note, however, SNTt = (trivial) valid
construction matching rule. Note also strong no-trade conditions (a)
(b) require information reported departure period bid. Thus,
matching rules use temporal information bids, information used
construction strong no-trade.
3.3 Chain: Matching Rules Truthful, Dynamic DAs
control flow Chain illustrated Figure 2. Upon arrival new bid, admission
decision made bid admitted value wi least admission price qi .
admitted bid competes sequence matching events, matching event simply
applies matching rule set active bids asks. bid fails match
period strong no-trade set (i
/ SNTt ), priced leaves
market without trading. Otherwise, still departure time (t di ),
available matching next period.
bid always one three states: active, matched priced-out. Bids active
admitted market di , matched priced-out.
144

fiChain: Online Double Auction

active bid becomes matched first period (if any) trades single-period
matching rule. active bid marked priced-out first period loses
strong no-trade set. soon bid longer active, enters
history, H , information bid price used defining matching rules
future periods.
Let E denote set bids expire current period. well-defined
matching rule, coupled valid strong no-trade construction, must provide Chain
following information, given history H , active bids bt active asks st ,
expiration set E period t:
(a) bid ask, whether wins loses
(b) winning bid ask, payment collected (negative ask)
(c) losing bid ask, whether satisfies strong no-trade condition
Note expiration set E used strong no-trade construction.
information made available matching rule. following table summarizes
use information within Chain. Note winning bid cannot set SNTt :
Lose
Win

SNTt
priced-out
matched

SNTt
survive
n/a

describe Chain defining events occur bid upon arrival
market, period remains active:
Upon arrival: Consider possible earlier arrival periods [di K, ai 1] consistent
reported type. periods consider bid maximally

patient. bid would lose SNTt one arrival periods
, admitted. Otherwise, bid would win periods


/ SNTt , define admission price as:
q(ai , di , , ) :=

max

[di K,ai 1],iSNT
/





[pti , ],

(3)



pti payment agent would made (negative seller) arrival
period (as determined running myopic matching rule period).

agent would lose earlier arrival periods (and SNTt ),
bid maximally patient, admission price defaults bid
admitted.
active: Consider period [ai , di ]. bid selected trade myopic
matching rule, mark matched define final payment:
xti ( ) = max(q(ai , di , , ), pti ),

(4)

pti price (negative seller) determined myopic matching rule
current period. buyer, collect payment delay transferring
item period di . seller, collect item delay making
payment reported departure period. bid loses SNTt ,
mark bid priced-out.
145

fiBredin, Parkes Duong

illustrate Chain instantiating various matching rules next section.
Section 5 prove Chain strongly truthful no-deficit coupled
well-defined matching rule valid strong no-trade construction. see
delay buyer delivery seller payment ensures truthful revelation traders departure
information. instance, absence delay, buyer might able better
over-reporting departure information, still trading early enough lower price.
3.4 Comments
choose allow single-period matching rules use reported arrival
departure associated active bids asks. maintains clean separation
non-temporal considerations (in matching rules) temporal considerations (in
wider framework Chain). also simplicity. single-period matching rules
allowed depend reported arrival-departure interval, long (singleperiod) rules monotonic tighter arrival-departure intervals, sense agent
wins = (ai , di , wi ) continues win improved price instead
reports (ai , di , wi ) [ai , di ] [ai , di ]. However, whether trade possible must
independent reported arrival-departure interval similarly strong no-trade.
Determinations would need made respect patient type
(di K, di , wi ) given report = (ai , di , wi ).

4. Practical Instantiations: Price-Based Competition-Based Rules
section offer number instantiations Chain online DA framework.
present two different classes well-defined matching rules: price-based
compute simple price statistics based history used matching,
refer competition-based leverage history also consider direct
competition active bids asks period. case, establish
matching rules well-defined provide valid strong no-trade construction.
4.1 Price-Based Matching Rules
one rules constructs single price, pt , period based history H
earlier bids asks traded expired. purpose define variations
real valued statistic, (H ), used define price given history. Generalizing
SimpleMatch procedure, introduced Section 3.1, price pt used determine
trades period t. also provide construction strong no-trade context.
main concern setting prices may volatile, price updates
driving admission price higher (via max operator admission rule Chain)
effect pricing bids asks market. describe various forms
smoothing windowing, designed provide adaptivity dampening shortterm variations. case, parameters (e.g. smoothing factor, window
size) determined empirically off-line tuning.
experiment five price variants:
History-EWMA: Exponentially-weighted moving average. bid history, H , used
define price pt period t, computed pt := (H ) + (1 )pt1 , (0, 1]
146

fiChain: Online Double Auction

smoothing constant (H ) statistic defined bids asks enter history
period t. Experimentally find mean statistic, mean (H ), absolute
values bids asks enter history performs well 0.05 lower
scenarios test. cases (H ) well-defined (or
zero) new bids asks, set pt := pt1 .
History-median: Compute price pt statistic fixed-size window
recent history, pt := (H , ) window-size, i.e. defining bids introduced
history H periods [t , . . . , t]. Experimentally, find median statistic,
median (H , ), absolute bid ask values performs well scenarios test,
window size depending inversely volatility agents valuations. Typically,
observe optimal window sizes 20 150, depending volatility. cases
(H , ) well-defined (or zero) new bids asks, set
pt := pt1 .
History-clearing: Identical history-median rule except statistic (H , )
defined (bm sm )/2 bm sm lowest value pair trades would
executed efficient (value-maximizing) trade given bids asks enter history
H periods [t , . . . , t]. Empirically, find similar optimal window sizes historyclearing history-median.
History-McAfee: Define statistic (H , ) represent McAfee price, defined
Section 4.2, bids H simultaneously arrived.
Fixed price: simple rule computes single fixed price pt := p trading periods,
price optimized offline maximize average-case efficiency dynamic DA
given Chain associated single-period matching rule leverages price p
candidate trading price.
pricing variant, procedure Match (see Figures 34) used determine
bids win (at price pt ), lose, and, lose, satisfy strong notrade predicate. subroutine used determine current price referred
determineprice Match. provide input Match set E addition
(H , bt , st ) Match also constructs strong no-trade set, E used exclusively purpose.
proof following lemma technical postponed Appendix.
Lemma 1 Procedure Match defines valid strong no-trade construction.
Theorem 1 Procedure Match defines well-defined matching rule valid strong notrade construction.
Proof: No-deficit, feasibility, individual-rationality immediate construction
Match since bids asks added matched pairs, payment,
payment less equal value. Truthfulness also easy see:
order bid (or ask) selected independent bid price, price
faces, selected, independent bid. price less equal bid,
whether trades depends order. rest claim follows
Lemma 1.

147

fiBredin, Parkes Duong

function Match(H ,bt ,st ,E )
matched := , lose := , NTt := , SNTt :=
stop := false
pt := determineprice(H )
stop
:= 0, j := 0, checkedB := , checkedS :=
((checkedB bt )&(i=0)) ((checkedS st )&(j=0))
(i = 0)&(j = 0)

k := random(bt \ checkedB st \ checkedS )
else (i = 0)
k := random(bt \ checkedB )
else (j = 0)
k := random(st \ checkedS )
end
(k bt )
checkedB := checkedB {k}
(bk pt )
:= k
end
else
checkedS := checkedS {k}
(sk pt )
j := k
end
end
end
(i 6= 0)&(j 6= 0)
matched :=
matched
{(i, j)}
lose := lose
(checkedB \ {i})
(checkedS \ {j})




b := b \ checkedB , := \ checkedS
else
stop := true
end
end
end function
Figure 3: procedure used single-period matching applying Chain pricebased rules. algorithm continues Figure 4.

148

fiChain: Online Double Auction

function Match (continued)(H ,bt ,st ,E )
(i 6= 0)&(j =S
0)
lose := lose st , NTt := bt
(k bt ((bk pt )&(dk = t))) (k st (dk = t))
SNTt := bt
else
SNTt := bt \ checkedB
end
else (j 6= 0)&(i
= 0)
lose := lose bt , NTt := st
(k st ((sk pt )&(dk = t))) (k bt (dk = t))
SNTt := st
else
SNTt := st \ checkedS
end
else (i = 0)&(j
= 0)


NT := b
k = t)) (k st (dk = t))
(k bt (dS


SNT := b st
end
end
end function



I-a

II

III

Figure 4: Continuing procedure Figure 3 single-period matching applying Chain
price-based rules.

Example 4 (i) Bid bt = {8}, ask st = {6}, indexed {1, 2} price pt = 9. outer
loop Figure 3 terminates j = 2 = 0 Case II. bid marked
loser NTt = {2}. bid depart immediately, SNTt = {2}, otherwise
SNTt = .
(ii) Bid bt = {8}, asks st = {6, 7}, indexed {1, 2, 3}, price pt = 9. Suppose
ask 2 selected ask 3 outer loop. loop terminates j = 2
= 0 Case II NTt = {2, 3}. Suppose bid asks leave market later
period. SNTt = {3} checkedS = {2}.
(iii) Bid bt = {8} ask st = {10}, indexed {1, 2}, price pt = 9 bid
ask patient. outer loop terminates = 0 j = 0 Case III
NTt = {1, 2}. However, SNTt = .

4.2 Competition-Based Matching Rules
one rules determines bids match current period price
competition active bids. present three variations: McAfee, WindowedMcAfee Active-McAfee. latter two rules hybrid rules leverage
149

fiBredin, Parkes Duong

history past offers, smoothing prices generated competition-based matching
rules.
McAfee: Use static DA protocol due McAfee matching rule. Let B denote
set bids denote set asks. min(|B|, |S|) < 2, trade.
Otherwise, first insert two dummy bids value {, 0} two dummy asks value
{0, } set bids asks. Let b0 b1 . . . bm s0 s1 . . .
sn . . . denote bid ask values (b0 , s0 ) denoting dummy pair (, 0) (bm , sn )
denoting dummy pair (0, ) ties otherwise broken random. Let 0 index
last pair bids asks clear efficient trade, bm + sm 0
bm+1 + sm+1 < 0. 1, consider following two cases:
m+1
bm pm+1 sm first bids
(Case I) price pm+1 = bm+1
2
asks trade payment pm+1 collected winning buyer made
winning seller.

(Case II) Otherwise, first 1 bids asks trade payment bm collected
winning buyer payment sm made winning seller.
define NTt , replace bid trade bid reporting large value
see whether bid trades. determine whether trade possible ask
trade: replace ask ask reporting value > 0, small . Say
quorum least two bids least two asks, i.e.
min(|bt |, |st |) 2. Define strong no-trade follows: set SNTt := NTt = bt st
quorum SNTt := otherwise.
Lemma 2 bid bi McAfee matching rule, bid (or ask) j
bid bi make trade possible bid (or ask) j quorum.
Proof: Without loss generality, suppose three bids three asks. Label
bids (a, c, e) asks (b, d, f ), ordered highest lowest (a, b)
competitive bid-ask pair. Proceed case analysis bids. analysis symmetric
asks omitted. Let tp(i) {0, 1} denote whether trade possible bid i,
NTt tp(i) = 0. bid a: b (a d)/2 tp(c) = tp(e) = 1
inequality always satisfied large enough a; (c d)/2 tp(b) = 1
(c b)/2 tp(d) = tp(f ) = 1, inequalities satisfied
large enough a. bid c: b (c d)/2 tp(a) = 1 when, addition,
c > a, tp(e) = 1 one inequalities satisfied large enough c;
similarly c (a d)/2 tp(b) = 1 c (a b)/2 tp(d) = tp(f ) = 1.
Analysis bid e follows bid c.

Lemma 3 construction strong no-trade valid valid strong notrade construction includes one losing bid ask depart
current period period quorum.
Proof: see valid construction, notice strong no-trade condition (a)
holds since bid (or ask) always NTt SNTt . Similarly, condition (b)
trivially holds (with bids asks remaining SNTt even bid
150

fiChain: Online Double Auction

present market). see definition essentially maximal, consider
min(|bt |, |st |) 2. contradiction, suppose two losing bids {i, j} departure
current period designated strong no-trade. But, strong no-trade condition
(b) fails Lemma 2 either bid could submitted alternate bid price
would remove bid NTt thus necessarily also SNTt .

construction offered SNTt cannot extended even include one agent selected
random set NTt depart immediately, case quorum.
construction would fail strong no-trade condition (b) set NTt contains
one bid (or ask) depart current period, bid
absence market would cause agent (randomly) selected SNTt .

Windowed-McAfee: myopic matching rule parameterized window size .
Augment active bids asks bids asks introduced history H
periods {t + 1, . . . , t}. Run McAfee augmented set bids asks
determine bids asks would trade. Denote candidate set C.
active agents identified matching C may able trade period
C also contain non-active agents.
Let B denote, respectively, active bids active asks set C. WindowedMcAfee proceeds picking random subset min(|B |, |S |) bids asks trade.
|B | =
6 |S |, bids asks trade.
Define strong no-trade matching rule as:
(i) active asks active bids, SNTt := bt
(ii) active bids active asks, SNTt := st
(iii) fewer 2 asks fewer 2 bids augmented bid set,
SNTt := bt st ,
otherwise set SNTt := . cases clear SNTt NTt .
Lemma 4 strong no-trade construction windowed-McAfee valid.
Proof: valid SNT criteria case (iii) follows immediately validity
SNT criteria standard McAfee matching rule. Consider case (i). Case (ii)
symmetric omitted. strong no-trade condition (a), see bids NTt
also SNTt , whether designated strong no-trade independent
bid price simply active asks. Similarly, strong
no-trade condition (b), see bids (and never asks) SNTt whatever
bid price particular bid (and even whether present).

Empirically, find efficiency Windowed-McAfee sensitive size

H , frequently best choice small window size includes active
bids.
Active-McAfee: Active-McAfee augments active bids asks include unexpired traded priced-out offers. proceeds Windowed-McAfee given
augmented bid set.
151

fiBredin, Parkes Duong

4.3 Extended Examples
next provide two stylized examples demonstrate matching performed Chain
using price-based competition-based matching rule. examples,
assume maximal patience K = 2. Moreover, describe Chain determines
bid ask trades, remember winning buyer allocated good
reported departure winning seller receive payment reported
departure.
Example 5 Consider Chain using adaptive, price-based matching rule. particular
details prices determined relevant. Assume prices periods 1
2 {p1 , p2 } = {8, 7} maximal patience three periods. consider period
3 suppose order book empty end period 2 bids asks
Table 1 arrive period 3.

B
wi di di K qi
pi SNT?
wi di di K qi
pi SNT?
b1 * 15 4
2
7
7
N
s1 -1 4
2
-7 n/a

s2 * -3 5
3
-6.5
N
b2 * 10 3
1
8
8
N
b3 7 3
1
8 n/a
N
s3 -4 3
1
-7 n/a

s4 * -5 4
2
-7 -6.5
N
b4 6 5
3
n/a
N
s5 -10 5
3
n/a



Table 1: Bids asks arrive period 3. Bids {b1 , b2 } match asks {s2 , s4 } (as indicated
*). Bid b3 priced-out upon admission qb3 > wb3 (indicated strikethrough). admission price qi payment made agent trades
pi . Column SNT? indicates whether bid ask satisfies strong no-trade
predicate. Asks {s1 , s5 } survive next period SNT
di > 3.

Bids {b1 , b2 , b4 } asks {s1 , .., s5 } admitted. Bid b3 priced qb3 =
max(p1 , p2 , ) = max(8, 7, ) = 8 > wb3 = 7 Eq. (3). Note b4 s5
admitted despite low bids (asks) maximal patience admission
prices . Now, suppose p3 := 6.5 defined matching rule consider
applying Match admitted bids asks.
Suppose bids randomly ordered (b4 , b2 , b1 ) asks
(s4 , s2 , s1 , s3 , s5 ). Bid b4 picked first priced-out wb4 = 6 < p3 = 6.5. Bid
b2 tentatively accepted (wb2 = 10 p3 = 6.5) ask s4 accepted (ws4 = 5
p3 = 6.5). Bid b2 matched ask s4 , payment max(qb2 , p3 ) = max(8, 6.5) = 8
b2 Eq. (4) payment max(qs4 , p3 ) = max(, 6.5) = 6.5 s4 . Bid b1
tentatively accepted (15 6.5) matched ask s2 , accepted
3 6.5. payments max(7, 6.5) = 7 b1 max(, 6.5) = 6.5 s2 .
Ask s3 expires asks s1 s5 survive marked SNT period
never offered chance match bid. asks active period
4.
Note role admission price truthfulness. bid b1 delayed arrival
period 4, admission price would max(p2 , p3 , ) = max(7, 6.5) = 7 payment
152

fiChain: Online Double Auction

period 4 (if matches) least 7. Similarly, ask s4 delayed arrival, admission
price would max(7, 6.5, ) = 6.5 maximal payment receive period
4 6.5.
Example 6 Consider Chain using McAfee-based matching rule K = 3
bids asks arriving period 3. Suppose prices periods 1 2
would faced buyer {p1b , p2b } = {8, 7} {p1s , p2s } = {7, 6} seller.
prices determined inserting additional bid (with value ) additional
ask (with value 0) order books periods 1 2. illustrate
period 3. Consider bids asks period 3 Table 2.

wi di
b1 * 15 4
b2 * 10 3
b3 7 3
b4 6 5


B
di K qi
pi SNT?
wi di di K qi
pi SNT?
2
7
7
N
s1 * -1 4
2
-6
-4
N
1
8
8
N
s2 * -3 5
3
-4
N
1
8 n/a
N
s3 -4 3
1
-6 n/a
N
3
n/a
N
s4 -5 4
2
-6 n/a
N
s5 -10 5
3
n/a
N

Table 2: Bids asks arrive period 3. Bids {b1 , b2 } match asks {s1 , s2 } (as indicated
*). Bid b3 priced-out upon admission qb3 > wb3 . admission price
qi payment made agent trades pi . Column SNT? indicates whether
bid ask satisfies strong no-trade predicate. asks bids survive
next period.

bid b3 admitted. myopic matching rule runs (static) McAfee
auction rule bids {b1 , b2 , b4 } asks {s1 , .., s5 }. Consider bids asks decreasing
order value, last efficient trade indexed = 3 wb4 + ws3 = 6 4 0.
pm+1 = (0(5))/2 = 2.5 (inserting dummy bid value 0 described Section 4.2).
Price pm+1 = 2.5 > s3 = 4 trade cannot executed McAfee. Instead,
buyers {b1 , b2 } trade face price pbm = wb4 = 6 sellers {s1 , s2 } trade face price
psm = ws3 = 4. Bids b4 asks {s3 , s4 , s5 } priced-out survive
next round. Ultimately, payment max(qb1 , pbm ) = max(7, 6) = 7 collected buyer b1
payment max(qb2 , pbm ) = max(8, 6) = 8 collected buyer b2 . sellers, payment
max(6, 4) = 4 max(, 4) = 4 s1 s2 respectively.
prices p3b p3s used Eq. (3) define admission price bids
asks arrivals periods 4 5 determined follows. buy-side price,
introduce additional bid bid-price . bid values considered McAfee
would (, 15, 10, 6, 0) ask values would (1, 3, 4, 5, 10), dummy
bid value 0 included buy-side. last efficient pair trade = 4
6 5 0 pm+1 = (0 (10))/2 = 5, satisfies bid-ask pair. Therefore
buy-side price, p3b := 5. sell-side, introduce additional ask ask-price
0 bid values considered McAfee (15, 10, 6, 0) (again, dummy bid
included) ask values (0, 1, 3, 4, 5, 10). time = 3 last
efficient pair trade 6 3 0. pm+1 = (0 (4))/2 = 2 price
153

fiBredin, Parkes Duong

satisfy s2 , pm+1 > s2 price psm+1 = s2 = 3 adopted. Therefore sell-side
price, p3s := 3.
Again, see bidder 1 cannot improve price delaying entry period
4. admission price bidder would max(p2b , p3b ) = max(7, p3b ) 7 thus
payment period 4, matches, least 7.4 Similarly ask s1 , would face
admission price max{p2s , p3s } = max{6, 4} = 4 receive payment 4
period 4. leave exercise reader verify p3s = 4 ask s1 delays
arrival period 4 (in comparison, p3s = 3 ask s1 truthful).
McAfee-based pricing scheme computes price clears order book
following every period least two bids two asks, bid activity
periods tend short comparison adaptive, price-based rules orders
kept active longer asymmetry number bids asks
market. fact, one interesting artifact occurs adaptive, price-based matching
rules admission-price SNT perpetuate kind bid-ask asymmetry.
market asks bids, SNT becomes likely future asks, bids.
Therefore, bids much likely asks immediately priced market
failing meet admission price constraint.

5. Theoretical Analysis: Truthfulness, Uniqueness, Justifying
Bounded-Patience
section prove Chain combined well-defined matching rule valid
strong no-trade construction generates truthful, no-deficit, feasible individual-rational
dynamic DA. Section 5.2, establish uniqueness Chain amongst dynamic DAs
constructed single-period matching rules building blocks. Section 5.3,
establish importance existence maximal bound bidder patience
presenting simple environment truthful, no-deficit DA implement even
single trade despite number efficient trades increased without bound.
5.1 Chain Mechanism Strongly Truthful
helpful adopt price-based interpretation valid single-period matching rule.
Given rule Mmr , define agent-independent price, zi (H , \ i, ) R = bt st ,
i, bids bt , asks st , history H , random events .
have:
(A1) wi zi (H , \ i, ) > 0 mr,i (H , bt , st , ) = 1, wi zi (H , \ i, ) <
0 mr,i (H , bt , st , ) = 0
(A2) payment xmr,i (H , bt , st , ) = zi (H , \ i, ) mr,i (H , bt , st , ) = 1
xmr,i (H , bt , st , ) = 0 otherwise
4. check p3b := 6 case. Suppose bidder 1 present period 3. consider
introducing additional bid value bids values {, 10, 6, 0} (with dummy bid)
ask values {1, 3, 4, 5, 10}. = 3 pm+1 = (0 (5))/2 = 2.5,
support trade bid b4 ask s3 . Instead, pbm = wb4 = 6 adopted, would
p3b := 6. course, exactly price determined McAfee bid b1 period 3 bidder
truthful.

154

fiChain: Online Double Auction

interpretation agent-independent price, zi (H , \ i, ),
least wi agent loses greater wi otherwise. particular, zi (H , \
i, ) = NTt . Although agents price explicit matching rule
agent trades, well known price exists truthful, single-parameter
mechanism; e.g., see works Archer Tardos (2001) Goldberg Hartline (2003).5
Moving forward adopt price zi characterize matching rule used building block
Chain, assume without loss generality properties (A1) (A2).
Given this, establish truthfulness Chain appeal price-based
characterization due Hajiaghayi et al. (2005) truthful, dynamic mechanisms. state
(without proof) variant characterization result holds stochastic policies
(, x) strong-truthfulness. theorem state also specialized DA
environment. continue adopt capture realization stochastic events
internal mechanism:
Theorem 2 (Hajiaghayi et al., 2005) dynamic DA = (, x), perhaps stochastic,
strongly truthful misreports limited early-arrivals if, every agent i,
, , random events , exists price pi (ai , di , , ) that:
(B1) price independent agent reported value
(B2) price monotonic-increasing tighter [ai , di ] [ai , di ]
(B3) trade (i , ) = 1 whenever pi (ai , di , , ) < wi (i , ) = 0 whenever
pi (ai , di , , ) > wi , trade performed buyer upon departure period
di .
(B4) agents payment xi (i , ) = pi (ai , di , , ) (i , ) = 1,
xi (i , ) = 0 otherwise, payment made seller upon departure, di .
random event independent report agent much affects
price agent i.
single-period, price-based characterization, price pi (ai , di , , ) need
always explicit Chain. Rather, theorem states given truthful dynamic
DA, Chain, exists well-defined price function properties valueindependence (B1) arrival-departure monotonicity (B2), define
trade (B3) payment (B4).
establish truthfulness Chain, prove well-defined respect
following price function:
pi (ai , di , , ) = max(q(ai , di , , ), pi (ai , di , , )),

(5)


q(ai , di , , ) =

max


t[di K,ai 1],iSNT
/

(zi (H , \ i, ), )

(6)

5. single-parameter mechanism one private information agent limited one
number. fits single-period matching problem arrival departure information
discarded. Moreover, although buyers sellers, problem effectively singleparameter buyer usefully pretend seller vice versa.

155

fiBredin, Parkes Duong


p(ai , di , , ) =



zi (H , \ i, ) , decision(i) = 1
+
, otherwise

(7)

decision(i) = 0 indicates SNTt [ai , di ] decision(i) = 1
otherwise, [ai , di ] first period
/ SNTt . refer
decision period. Term q(ai , di , , ) denotes admission price, defined
periods agent arrives
/ SNTt arrived period. Note
carefully rules Chain implicit defining price function. instance,
whether SNTt period depends, example, bids
remain active period.
establish conditions (B1)(B4). proofs technical lemmas deferred
Appendix. following lemma helpful gets heart strong notrade concept.
Lemma 5 set active agents (other i) period Chain independent
report agent remains active, would unchanged arrival later
period t.
following result establishes properties (B1) (B2).
Lemma 6 price constructed admission price q post-arrival price p valueindependent monotonic-increasing matching rule Chain well-defined,
strong no-trade construction valid, agent patience bounded K.
established properties (B1) (B2) price function pi (ai , di , , ),
need establish (B3) (B4) show truthfulness. timing aspect (B3) (B4),
requires buyer receives item seller receives payment upon
reported departure, already clear definition Chain.
Theorem 3 online DA Chain strongly truthful, no-deficit, feasible individualrational matching rule well-defined, strong no-trade construction valid,
agent patience bounded K.
Proof: Properties (B1) (B2) follow Lemma 6. timing aspects (B3)
(B4) immediate. complete proof, first consider (B3). q > wi , agent
priced admission Chain reflects zi (H , \ i, ) > wi
[di K, ai 1]
/ SNTt , thus bid would lose arrived
period (either could trade, payment greater reported value,
NTt ). Also, decision period, p = , consistent
Chain, bid price bid trade SNTt periods
[ai , di ]. Suppose decision period q < wi . p > wi ,
trade. case Chain, price zi (H , \ i, )
greater wi thus agent priced-out. p < wi bid trade
indeed does, price zi period satisfies (A1) (A2) respect
matching rule. Turning (B4), immediate payments collected Chain
156

fiChain: Online Double Auction

equal price pi (ai , di , , ), bid trades pi (ai , di , , ) wi
thus q wi p wi . admission price q(ai , di , , ) = q(ai , di , , ) q wi
price zi well-defined properties (A1) (A2). Similarly, payment pt
defined matching rule Chain decision period equal p.
Chain individual-rational feasible follows inspection. Chain nodeficit payment collected every agent (whether buyer seller)
least defined valid matching rule decision period (it higher
admission price higher matching price), matching rules
no-deficit, auctioneer delays making payment seller reported
departure collects payment buyer immediately upon match.

remark information reported bidders currently participating market, instance assist valuation process. information
delayed least maximal patience bidder, bid current bidder
cannot influence bids asks faces, without strategic
consequences. course, without constraint, bidders participate
market multiple times, effect feedback would require careful analysis bring
us outside private values framework.
5.2 Chain Unique amongst Dynamic DAs constructed Myopic
Matching Rules
follows, establish Chain unique amongst truthful, dynamic DAs
adopt well-defined, myopic matching rules simple building blocks. this, define
class canonical, dynamic DAs, take well-defined single period matching rule
coupled valid strong no-trade construction, satisfy following requirements:
(i) agents active matched priced-out,
(ii) agents participate single-period matching rule active
(iii) agents matched trade single-period matching rule.
think restrictions capture essence means construct
dynamic DA single-period matching rules. Notice number design elements
left undefined, including payment collected matched bids, mark active
bid priced-out, rule use upon admission, use strong no-trade
information within dynamic DA. establishing uniqueness result, leverage
necessary sufficient price-based characterization Theorem 2, exactly determine
price function pi (ai , di , , ) defined Eq. (4) associated Chain.
proofs two technical lemmas deferred Appendix.
Lemma 7 strongly truthful, canonical dynamic DA must define price pi (ai , di , , )
zi (H , \ i, ) decision period bid (if exists). Moreover, bid
must priced-out period matched.
Lemma 8 strongly truthful, canonical individual-rational dynamic DA must define
price pi (ai , di , , ) q(ai , di , , ), bid wi < q(ai , di , , ) must pricedout upon admission.
157

fiBredin, Parkes Duong

Theorem 4 dynamic DA algorithm Chain uniquely defines strongly truthful,
individual-rational auction among canonical dynamic DAs designate bids pricedout necessary.
Proof: decision period, must pi (ai , di , , ) = , canonical
(iii) coupled (B3). Combining Lemmas 7 8, pi (ai , di , , )
max(q(ai , di , , ), p(ai , di , , )). also established bid must pricedout bid value less admission price, fails match decision
period. Left show price exactly Chain, bid admitted
value wi q(ai , di , , ) retained active strong notrade set. last two control aspects determined choose rule
designates bids priced-out necessary. prefer allow bid remain active
compromise truthfulness individual-rationality. Finally, suppose
contradiction p = pi (ai , di , , ) > max(q(ai , di , , ), p(ai , di , , )).
agent max(q(ai , di , , ), p(ai , di , , )) < wi < p would prefer bid wi =
q(ai , di , , ), p(ai , di , , )) avoid winning otherwise payment would
greater value.

5.3 Bounded Patience Required Reasonable Efficiency
Chain depends maximal bound patience used calculate admission price faced
bidder entering market Eq. (3). motivate assumption
existence maximal patience, construct simple environment number
trades implemented truthful, no-deficit DA made arbitrarily small fraction
number efficient trades even small number bidders potentially unbounded patience. illustrates bound bidder patience required dynamic
DAs reasonable performance.
achieving negative result, impose additional requirement anonymity,
anonymity property already satisfied Chain, coupled matching rules
satisfy anonymity, case rules presented Section 4. defining
anonymity, extend earlier definition dynamic DA, = (, x), allocation
policy = { }tT defines probability ( ) [0, 1] agent trades period
given reports . Payment, x = {xt }tT , continues define payment xti ( ) agent
period t, random variable mechanism stochastic.
Definition 8 (anonymity) dynamic DA, = (, x) anonymous allocation policy
= { }tT defines probability trade ( ) period independent
identity invariant permutation ( \ i) payment xti ( ), contingent
trade agent i, independent identity invariant permutation ( \ i).
consider following simple environment. Informally, random
number high-valued phases bids asks high value might
single bidder patience exceeds bids asks phase.
high-valued phases followed number, perhaps zero, low-valued phases
bounded-patience bids asks. Formally, Th 1 high-valued phases
(a random variable, unknown auction), duration L 1 periods, indexed
k {0, 1, . . . , Th 1} with:
158

fiChain: Online Double Auction

N N 1 bids type (1 + kL, (k + 1)L, vH ),
0 1 bids type (1 + kL, d, vH ) mark-up parameter, > 1
high-patience parameter, ,
N asks type (1 + kL, (k + 1)L, (vH )),
followed number (perhaps zero) low-valued phases, also duration L,
indexed k {Th , . . . , }, with:
N N 1 bids type (1 + kL, (k + 1)L, vL )
N asks type (1 + kL, (k + 1)L, (vL )),
N 1, 0 < vL < vH , bid-spread parameter > 0. Note phase
last phase, additional bids asks arriving future.
Definition 9 (reasonable DA) dynamic DA reasonable simple environment
parameterization new bids, N 1, periods-per-phase, L 1,
execute least one trade new bids new asks phase,
choice high value vH , low value vL < vH , bid-spread > 0, mark-up > 1, high
patience d.
dynamic DAs presented Section 4 parameterized make
reasonable suitably large N 1 L 1, without possibility bid
unbounded patience.
Theorem 5 strongly truthful, individual-rational, no-deficit, feasible, anonymous dynamic DA reasonable bidders patience unbounded.
Proof: Fix N 1, L 1, number high-valued phases, Th 1, set
departure high-patience agent = (Th + 1)L. Keep vH > vL > 0, > 0, > 1
variables set within proof. Assume dynamic DA reasonable,
selects least one new bid-ask pair trade phase. Consider phase k = 0
N 1 agents types (1, L, vH ), N type (1, L, (vH )) 1 agent patient type,
(1, (Th + 1)L, vH ). patient bid deviates (1, L, vH ), bids identical,
probability least 1/N bid would win anonymity reasonableness.
Also, anonymity, individual-rationality no-deficit payment made
winning bid same, must p [vH , vH ]. (If payment less
this, DA would run deficit since sellers require least much payment
individual-rationality.) Condition case patient bid would win
deviates reports (1, L, vH ). Suppose bidder truthful, reports (1, (Th + 1)L, vH )
trade phase. But, phase k = 0 last phase new bids
asks, bid able trade future strong-truthfulness
DA would need make payment least vH vH = ( 1)vH later phase
prevent bid useful deviation (1, L, vH ) winning phase k = 0. But, if:
N < ( 1)vH ,
159

(8)

fiBredin, Parkes Duong

DA cannot make payment without failing no-deficit (because N upperbound surplus auctioneer could extract bidders phase without
violating individual-rationality). later pick values , vH , satisfy Eq. (8).
So, bid must trade reports (1, (Th + 1)L, vH ), event would win
report (1, L, vH ), insurance last phase new bids
asks. Moreover, trade payment, p [vH , vH ], ensure agent true
type (1, L, vH ) cannot benefit reporting (1, (Th + 1)L, vH ).
suppose last phase new bids asks, Th > 1.
consider would happen patient bid phase k = 0 deviated reported
(1 + Th L, (Th + 1)L, vL ). before, bid would win probability least 1/N
anonymity reasonableness, payment p [vL , vL ]. Condition
case patient bid would win, report (1, L, vH )
report (1 + Th L, (Th + 1)L, vL ). truthful, trades phase k = 0 payment
least vH . reported (1 + Th L, (Th + 1)L, vL ), would trade phase k = Th
payment vL . strong truthfulness, DA must make additional payment
patient agent least (vH vL ) (vH (vH )) = vH vL . But, suppose
high low values that,
(Th + 1)N < vH vL .

(9)

Making payment case would violate no-deficit, (Th +1)N upperbound surplus auctioneer extract bidders across phases, including
current phase, without violating individual-rationality. fix vL > 0,
< vL choose vH > (Th + 1)N + vL + satisfy Eq. (9) > (N /vH ) + 1
satisfy Eq. (8). Thus, proved truthful dynamic DA choose bidask pair trade period k = 0. proof readily extended show similar
problem choosing bid-ask pair period k < Th , considering truthful type
(1 + kL, (Th + 1)L, vH ).

drive home negative result: notice number efficient trades
increased without limit choosing arbitrarily large Th , truthful, dynamic DA properties able execute even single trade
{0, . . . , Th 1} periods. Moreover, see vanishingly small fraction
high-patience agents required negative result. proof requires
least one patient agent possible high-valued phases.

6. Experimental Analysis
section, evaluate simulation Chain-based DAs introduced
Section 4. measure allocative efficiency (total value trades), net efficiency
(total value discounted revenue flows auctioneer), revenue
auctioneer. values normalized total offline value optimal matching.
comparison also implement several matching schemes: truthful, surplusmaximizing matching algorithm presented Blum et al. (2006), untruthful greedy
matching algorithm using truthful bids input provide upper-bound performance,
untruthful DA populated simple adaptive agents modeled
Zero-intelligence Plus trading algorithm leveraged study static
DAs (Cliff & Bruten, 1998; Preist & van Tol, 1998).
160

fiChain: Online Double Auction

6.1 Experimental Set-up
Traders arrive market Poisson stream exchange single commodity discrete
moments. standard model arrival dynamic systems, economic otherwise.
trader, equally likely buyer seller, arrives previous exponentially distributed delay, probability density function (pdf):
f (x) = ex ,

x 0,

(10)

> 0 represents arrival intensity agents per second. Later present results
interarrival time, 1 , varied 0.05 1.5; i.e., arrival intensity
varied 20 23 . single trial continues least 5,000 buyers 5,000 sellers
entered market. experiments vary maximal patience K 2
10. distribution agents activity period (or patience, di ai ), consider
uniform distribution pdf:
f (x) =

1
,
K

x [0, K],

(11)

truncated exponential distribution pdf:
f (x) = ex ,

x [0, K],

(12)

= ln(0.05)/K 95% underlying exponential distribution less
maximal patience. arrival time activity duration rounded nearest
integral time period. trader arrives departs period assumed
need immediate trade active one period.
traders valuation represents sample drawn arrival uniform distribution spread 20% current mean valuation. (The value positive bid
negative ask.) simulate market volatility, run experiments vary
average valuation using Brownian motion, common model valuation volatility upon
many option pricing models based (Copeland & Weston, 1992). every time
period, mean valuation randomly increases decreases constant multiplier, e ,
approximate volatility varied 0 0.15 experiments.
plot mean efficiency 100 runs experiment, sets bids
asks used across double auctions. parameters auction rule reoptimized
market environment; e.g., find optimal fixed price optimal
smoothing parameters offline given ability sample market model.
6.2 Chain Implementation
implement Chain five price-based matching rules (history-clearing, historymedian, history-McAfee, history-EWMA, fixed-price) three competition-based
matching rules (McAfee, active-McAfee, windowed-McAfee).
price-based implementations keep fixed-size set recently expired,
traded, priced-out offers, H . Offers priced-out admission prices inserted
H prior computing pt . history-clearing metric computes price maximize
number trades agents represented H contemporary. historymedian metric chooses price median absolute valuation offers
161

fiBredin, Parkes Duong

H . history-McAfee method computes McAfee price scenario
agents represented H simultaneously present. EWMA metric computes
exponentially-weighted average bids order expire, trade, price out.
simulations initialize price average mean buy sell valuations.
two bids expire period, included arbitrary order moving
average.
None metrics require one parameter, optimized offline
access model market environment. Parameter optimization proceeds uniformly sampling parameter range, smoothing result averaging result
immediate neighbors. optimization repeats twice narrower range
smoothed maximum, returning parameter maximizes (expected) allocative efficiency. None price-based methods appeared sensitive small (<10%) changes
size H . simulations, window size chosen 150 offers. EWMA, smoothing factor usually chosen around 0.05 lower.
windowed-McAfee matching rule, however, extremely sensitive window size simulations volatile valuations, search process frequently converged suboptimal
local maxima.
admission price price-based methods computed first determining
whether Match would check value bid bid price bid arrived
earlier period . Rather simulate entire Match procedure, sufficient
determine probability event. determined checking construction

strong no-trade sets earlier period. SNTt contains non-departing buyers
(sellers), probability additional seller (buyer) would examined 1
= 1. Otherwise probability equal ratio number bids (asks) examined included SNTt one total number bids (asks) present.

Finally, probability price agent would faced period defined pt


(pt sellers), otherwise . Here, pt history-dependent price defined
period .
competition-based matching rules price non-trading bids end
period trade occurs (because definition strong no-trade context).
admission prices calculated considering price bid (ask) would
faced period reported arrival. period, price bid (ask)
determined inserting additional bid (ask) valuation (0) applying
competition-based matching rule (counterfactual) state. determine
whether agent would win reported value, price would face.
6.3 Optimal Offline Matching
use commercial integer program solver (CPLEX6 ) compute optimal offline
solution, i.e. complete knowledge offers received time. determining
offline solution enforce constraint trade executed activity
periods buyer, i, seller, j, overlap,
(ai dj ) (aj di )
6. www.ilog.com

162

(13)

fiChain: Online Double Auction

integer-program formulation maximize total value is:
max

X

xij (wi + wj )

(14)

(i,j)overlap

X

s.t. 0

xij 1, j ask

i:(i,j)overlap

0

X

xij 1, bid

j:(i,j)overlap

xij {0, 1}, i, j,

(i, j) overlap bid-ask pair could potentially trade
overlapping arrival departure intervals satisfying Eq. (13). decision variable xij
{0, 1} indicates bid matches ask j. provides optimal, offline allocative
efficiency.
6.4 Greedy Online Matching
implement greedy matching algorithm immediately matches offers yield nonnegative budget surplus. non-truthful matching rule provides additional
comparison point efficiency matching schemes. time period,
greedy matching algorithm orders active bids asks valuations, exactly
McAfee mechanism does, matches offers pairs longer generate positive
surplus. algorithms performance allows us infer number offers
optimal matching defers matching amount surplus lost McAfee
method due trade reduction due additional constraint admission pricing.
6.5 Worst-Case Optimal Matching
Blum et al. (2006) derive mechanism equivalent fixed-price matching mechanism,
except price used chosen cumulative distribution
1
ln
D(x) =
r



x wmin
(r 1)wmin



,

(15)

r fixed point equation
r = ln



wmax wmin
(r 1)wmin



,

(16)

wmin 0 wmax 0 minimum maximum absolute valuations
traders market. simulations, give mechanism exact knowledge
minimum maximum absolute valuations schedule. Blum et al. (2006) show
method guarantees expected competitive ratio max(2, ln(wmax /wmin ))
respect optimal offline solution adversarial setting. interested see
performed practice simulations.
163

fiBredin, Parkes Duong

6.6 Strategic Open-outcry Matching: ZIP Agents
compare Chain existing literature continuous double auctions, implement
DA every period sorts active offers matches highest valued bids
lowest valued asks long match yields positive net surplus. DA prices
trading pair mean pairs declared valuations. Since trade price depends
bidders declaration, market support truthful bidding strategies. must
therefore adopt method simulate behavior bidding agents within simple open
outcry market.
this, randomly assign bid one several protocol agents use
modified ZIP trading algorithm, initially presented Cliff Bruten (1998)
improved upon Preist van Tol (1998). ZIP algorithm common benchmark
used compare learned bidding behavior simple double-auction trading environment
agents present adjust bids seeking profitable trade.
adapt ZIP algorithm use dynamic environment.
experiments consider five protocol agents. New offers assigned
uniformly random protocol agent, remains persistent throughout simulation. offer associated patience category, k {low, medium, high}, defined
evenly partition range possible offer patience. protocol agent, j, defined
parameters (rj , j , j ) maintains profit margin, kj , patience category k.
Parameters (j , j ) control adaptivity protocol agent adjusts target
profit margin individual offer, j U (0.1, 0.2) defining offer-level learning
rate j U (0.2, 0.8) defining offer-level damping factor. Parameter rj [0, 1]
learning rate adopted updating profit margins.
protocol agents trained 10 trials final performance measured
11th trial. learning rate decreases training session depends
initial learning rate rj0 adjustment rate rj+ . period {1, . . . , tkend } trial
k {1, . . . , + 1}, = 10 number trials used training tkend
number periods trial k, learning rate defined as:
rj := 1

rj0

+ (k

1)rj+

+




tkend

2

rj+

!

(17)

rj+ = (1 rj0 )/(T + 1). define rj0 := 0.7. effect adjustment rule
rj initially 0.3, decreases training, trends 0.0 tend trial k = 11.
Within given trial, upon assignment new offer patience category k, protocol
agent managing offer initializes (i (t), (t)) := (kj , 0), (t) represents target
profit margin offer (t) represents profit-margin correction term. target
profit margin profit margin correction term adjusted offer subsequent
periods bid remains active.
target profit margin used define bid price offer period
remains active:
wi (t) := wi (1 + (t)).
164

(18)

fiChain: Online Double Auction

end period offer matches simply expires, profit margin
kj patience category updated as:
kj := (1 rj )kj + rj (t),

(19)

amount adaptivity depends learning rate rj . profit margin
offer decays lifetime, update adjusts towards small profit margin
offer expires took many periods trade, larger profit margin otherwise.
long-term learning protocol agent occurs profit margin assigned
patience category.
start period protocol agent also computes target prices bids
asks patience category. used drive adjustment target profit
margin active bid ask. Target prices bk (t) sk (t) computed as:

{wi (t 1)} + , 0 > max {wi (t 1)} + max {wi (t 1)}
(1 + ) max
iS(t1)
iB k (t1)
iB k (t1)
k
b (t) :=
(1 ) max {wi (t 1)} , otherwise
iB k (t1)

(20)

and,
sk (t)

:=


(1 + )

(1 )

max {wi (t 1)} + , 0 > max {wi (t 1)} + max {wi (t 1)}
iB(t1)

k (t1)

k (t1)

max {wi (t 1)} , otherwise

k (t1)

(21)

, U (0, 0.05). Here, B(t 1) S(t 1) denote set active bids asks
market period 1 (defined market clearing), B k (t 1) k (t 1)
denote restrictions patience category k. target price bid category k
set something slightly greater competitive bid previous round
bid could trade, slightly less otherwise. Similarly target price
asks, prices negative, increasing target price makes ask
competitive.
Target prices used adjust target profit margin start period
active offers arrived earlier period, influence target prices
profit-margin correction term:
(t) :=

(wi (t 1) + (t))
1,
wi

(22)

profit-margin correction term, (t), defined terms target price ik (t)
(equal bk (t) bid sk (t) otherwise) as,
(t) := j (t 1) + (1 j )j (ik (t) wi (t 1)),

(23)

j j offer-level learning rates damping factor. value wi
-1 term Eq. (22) provide normalization. Eq. (23) Widrow-Hoff (Hassoun, 1995)
rule, designed minimize least mean square error profit margin adopted
mimic earlier ZIP designs.
165

fiBredin, Parkes Duong

6.7 Experimental Results
experimental results show market conditions drive DA choice. compare allocative efficiency, revenue, net efficiency. results averaged 100 trials.
experiments found minimal qualitative differences use two
patience distributions. uniform patience distribution provides slight increase efficiency result using exponential patience, caused larger proportion patient
agents relaxes somewhat admission-price constraint Eq. (3). reason
choose report results uniform patience distribution.
performance methods summarized Table 3, omit performance markets plots keep presentation results clear possible.
plot price-based results median- clearing-based prices
performance typically around performance Chain instantiated
history-EWMA price. plot windowed-McAfee results inconsistent performance, cases, upon manual inspection, optimal choose
smallest possible window size, i.e. including active bids making equivalent
active-McAfee.
plots also leave performance Blum et al. (2006) worst-case optimal
matching scheme dominated fixed-price Chain instantiation
many cases failed yield substantial surplus. note modeling assumption made Blum et al. (2006) quite different work: worry
performance adversarial environment consider probabilistic environments.
fixed-price Chain mechanism operates essentially identically surplus-maximizing
scheme Blum et al. (2006), except Chain also use additional statistical information set ideal price, rather drawing price distribution used
guarantee worst-case performance adversary. defer results Blum
et al. (2006) scheme Table 3.
Figures 58 plot results two sets experiments, one high-patience/low-volatility
one low-patience/high-volatility, vary inter-arrival time (and thus
arrival intensity), volatility maximal patience. plots allocative efficiency
except Figure 6, consider net efficiency. Active-McAfee included Figure 5,
plots improve upon McAfee performance
environments. emphasize: results greedy provide upper-bound
best possible performance non-truthful algorithm, simulated
truthful inputs.
Figure 5 (left) see within truthful DAs, McAfee-based DA
best efficiency medium low arrival intensities. also general decrease
performance, relative optimal offline solution, arrival intensity falls.
trend, also observed greedy (non-truthful) DA, occurs Chain scheme
myopic matches soon static DA building block finds match,
better less myopic arrival intensity low. McAfee-based DAs less
sensitive methods aggressively update prices using
active traders. price-based DAs experience inefficiencies due lag price updates
use expired, traded, priced-out offers calculate prices.
166

fiChain: Online Double Auction

(patience=6, volatility=0.01)
greedy
zip
mcafee
ewma
active-mcafee
fixed-price

1.2
1

greedy
mcafee
active-mcafee
ewma
fixed-price
zip

1.4
Allocative Efficiency

1.4
Allocative Efficiency

(patience=2, volatility=0.08)

0.8
0.6
0.4
0.2

1.2
1
0.8
0.6
0.4
0.2

0

0
0

0.2

0.4

0.6
0.8
1
Inter-arrival Time

1.2

1.4

0

0.2

0.4

0.6
0.8
1
Inter-arrival Time

1.2

1.4

Figure 5: Allocative efficiency vs. inter-arrival time (1 / intensity) several DAs. left
plot shows high-patience, low-volatility simulations, whereas right plots results
low-patience, high-volatility runs. sets experiments use uniform patience distributions.

(patience=6, volatility=0.01)
greedy
zip
mcafee
ewma
active-mcafee
fixed-price

1.2
1

greedy
mcafee
active-mcafee
ewma
fixed-price
zip

1.4
1.2
Net Efficiency

1.4

Net Efficiency

(patience=2, volatility=0.08)

0.8
0.6

1
0.8
0.6

0.4

0.4

0.2

0.2

0

0
0

0.2

0.4

0.6
0.8
1
Inter-arrival Time

1.2

1.4

0

0.2

0.4

0.6
0.8
1
Inter-arrival Time

1.2

1.4

Figure 6: Net efficiency vs. inter-arrival time (1 / intensity) several DAs. left plot
shows high-patience, low-volatility simulations, whereas right plots results lowpatience, high-volatility runs. sets experiments use uniform patience distributions.

167

fiBredin, Parkes Duong

high arrival intensity see Active-McAfee dominates McAfee. Active-McAfee
smooths price, helps mitigate impact fluctuations cost admission
price via Eq. (3) return less responsiveness. helpful well-behaved markets
high arrival intensity low volatility helpful environments
studied, additional responsiveness provided (vanilla) McAfee scheme paid
off.
ZIP market also good performance high-patience/low-volatility environment. reason simple: easy environment simple learning agents,
agents quickly learn truthful. emphasize ZIP market results
treated caution certainly optimistic. ZIP agents
programmed consider timing-based manipulations. effect environment
ZIP market tends operate truthful market, without cost imposing
truthfulness explicitly via market-clearing rules. comparison Chain auctions
fully strategyproof, value temporal manipulations.
Compare Figure 5 (right), low patience high volatility.
see McAfee dominates across range arrival intensities. Moreover, performance
ZIP quite poor agents enough time adjust bids
(patience low) high volatility makes difficult environment. volatile
valuations, possibility valuation swings leaves open possibility larger profits,
luring agents set wider profit margins, market changes. ZIP agents
also fewer concurrent competitive offers use setting useful price targets
learning. might expect, high volatility also negatively impacts efficiency
fixed-price scheme.
Figure 6 see net efficiency trends qualitatively similar except
competition-based DAs McAfee fare less well comparison price-based
DAs. auctioneer accrues revenue competition-based matching rules
McAfee often generate buy sell prices spread. Together
competition-based schemes intrinsically dynamic, drives increased
price spread Chain via admission price constraints. Figure 6 (left) see
fixed-price scheme performs well high arrival intensity EWMA dominates
intermediate arrival intensities. McAfee scheme still dominant lower patience
higher volatility (Figure 6, right).
reinforce observations, Table 3 present net efficiency, allocative
efficiency (normalized) revenue across arrival intensities (i.e. inter-arrival time
0.05 1.5) low high volatility trials. five price-based methods,
three competition-based methods, three comparison methods included.
highlight best performing competition-based method, price-based method, well
performance ZIP market (skipping non-truthful, greedy algorithm).
omit information mean standard error measurement case
error exceed tenth percent mean optimal surplus. within
truthful DAs, see McAfee-based scheme dominates overall allocative
net efficiency low high volatility, although EWMA competes McAfee
net efficiency low volatility markets. Notice also good performance ZIPbased market (with aforementioned caveat restricted strategy space) low
volatilities.
168

fiChain: Online Double Auction

scenario
low-volt/high-pat
high-volt/low-pat
net
alloc rev
net
alloc rev
0.33 0.47 0.14 0.40 0.45 0.05
0.24 0.35 0.11 0.32 0.37 0.05
0.24 0.26 0.02 0.21 0.23 0.03
0.33 0.34 0.01 0.17 0.17 0.01
0.33 0.35 0.03 0.19 0.22 0.03
0.23 0.23 0.00 0.04 0.04 0.00
0.33 0.34 0.01 0.15 0.16 0.01
0.33 0.34 0.01 0.17 0.18 0.01
0.10 0.10 0.00 0.02 0.02 0.00
0.86 0.86 0.00 0.87 0.87 0.00
0.82 0.82 0.00 0.23 0.23 0.00

mcafee
active-mcafee
windowed-mcafee
history-clearing
history-ewma
history-fixed
history-mcafee
history-median
blum et al.
greedy
zip

Table 3: Net efficiency, allocative efficiency auctioneer revenue (all normalized optimal
value trade), averaged across arrival intensities (0.051.5) low high
value volatility. best performing competition-based, price-based (ignoring
greedy, truthful) results highlighted.

(patience=6, inter-arrival=1.0)
1.4

greedy
zip
mcafee
ewma
fixed-price

1

greedy
mcafee
ewma
zip
fixed-price

1.2
Allocative Efficiency

1.2
Allocative Efficiency

(patience=2, inter-arrival=1.0)
1.4

0.8
0.6
0.4
0.2

1
0.8
0.6
0.4
0.2

0

0
0

0.02

0.04

0.06

0.08

0.1

0.12

0.14

0

Volatility

0.02 0.04 0.06 0.08

0.1

0.12 0.14

Volatility

Figure 7: Allocative efficiency vs. volatility several DAs fairly low arrival intensity.
left plot large maximal patience right plot small maximal patience.
sets experiments use uniform patience distributions.

Figure 7 plots allocative efficiency versus volatility high patience (left) low
patience (right) fairly low arrival intensity. Higher volatility hurts methods
especially ZIP agents, struggle learn appropriate profit price targets,
probably due opportunities update prices every individual offer. McAfee
scheme fairs well, showing good robustness large patience small patience
environments. fixed-price scheme best performance zero volatility
efficiency falls extremely quickly volatility increases.
169

fiBredin, Parkes Duong

(inter-arrival=1.0, volatility=0.01)
1.4

greedy
zip
mcafee
ewma
fixed-price

1

greedy
zip
mcafee
ewma
fixed-price

1.2
Allocative Efficiency

1.2
Allocative Efficiency

(inter-arrival=1.0, volatility=0.08)
1.4

0.8
0.6
0.4
0.2

1
0.8
0.6
0.4
0.2

0

0
0

2

4
6
Maximal Patience

8

10

0

2

4
6
Maximal Patience

8

10

Figure 8: Allocative efficiency vs. maximal patience several DAs fairly low arrival intensity.
left plot low volatility right plot high volatility. sets
experiments use uniform patience distributions.

also consider effect varying maximal patience. shown Figure 8,
low volatility (left) high volatility (right). Again, McAfee scheme best
truthful DAs based Chain. also see performance ZIP improves
patience increases due opportunities learning. Perversely, larger patience
negatively affect truthful DAs. part simply performance
greedy online schemes, relative offline optimal, decreases patience increases
offline optimal matching able draw benefit lack myopia.
also suspected another culprit, however. possibility presence patient
agents requires truthful DAs include additional terms max operator Eq. (3)
prevent manipulations, leading higher admission prices less admitted offers.
better understand effect experimented delayed market clearing McAfee
scheme, market matches agents every -th period (the clearing duration).
idea make tradeoff using fewer admission prices possibility
miss opportunity match impatient offers.
Figure 9 shows allocative efficiency matching mechanism clears less frequently
different maximal patience, K. Figure 9 (left) low volatility.
see best clearing duration roughly 1, 2, 3 4 maximal patience K
{4, 6, 8, 10} optimizing clearing duration performance McAfee remains
approximately constant maximal patience increases. Figure 9 (right) consider
effect high volatility environment, results averaged 500 trials
performance DA higher variance. see qualitatively similar trend, although
higher maximal patience hurts overall cannot fully compensated tuning
clearing duration.

7. Related Work
Static two-sided market problems widely studied (Myerson & Satterthwaite, 1983;
Chatterjee & Samuelson, 1987; Satterthwaite & Williams, 1989; Yoon, 2001; Deshmukh
170

fiChain: Online Double Auction

(inter-arrival=1.0 patience=K, volatility=0.01)

(inter-arrival=1.0 patience=K, volatility=0.08)

0.55

0.45
0.4
Allocative Efficiency

Allocative Efficiency

0.5
0.45
0.4
0.35
0.3
K=4
K=6
K=8
K=10

0.25
0.2
0.15
0

0.35
0.3
0.25
K=4
K=6
K=8
K=10

0.2
0.15
2

4
6
Clearing Duration

8

10

0

2

4
6
Clearing Duration

8

10

Figure 9: Allocative efficiency vs. clearing duration McAfee-based Chain auction fairly
low arrival intensity maximal patience varied 4 10. left plot
low volatility right plot high volatility. sets experiments use
uniform patience distributions.

et al., 2002). classic result, Myerson Satterthwaite proved impossible
achieve efficiency voluntary participation without running deficit, even relaxing
dominant-strategy equilibrium Bayesian-Nash equilibrium. truthful DAs
known static problems (McAfee, 1992; Huang et al., 2002; Babaioff & Nisan, 2004;
Babaioff & Walsh, 2005). instance, McAfee introduced DA sometimes forfeits
trade return achieving truthfulness. McAfees auction achieves asymptotic efficiency
number buyers sellers increases. Huang et al. extend McAfees mechanism
handle agents exchanging multiple units single commodity. Babaioff colleagues
considered extensions work supply-chain spatially distributed markets.
problem also similar traditional continuous double auction (CDA),
buyers sellers may time submit offers market pairs offer soon
matching offer submitted. Early work considered market efficiency CDAs
human experiments labs (Smith, 1962), recent work investigates use software
agents execute trades (Rust et al., 1994; Cliff & Bruten, 1998; Gjerstad & Dickhaut,
1998; Tesauro & Bredin, 2002). markets dominant strategy equilibria,
populations software trading agents learn extract virtually available surplus,
even simple automated trading strategies outperform human traders (Das et al., 2001).
However, studies CDAs assume traders share known deadline
trades must executed. quite different setting, dynamic
arrival departure.
Truthful one-sided online auctions, agents arrive depart across time,
received recent attention (Lavi & Nisan, 2000; Hajiaghayi et al., 2004, 2005; Porter,
2004; Lavi & Nisan, 2005). adopt extend monotonicity-based truthful characterization work Hajiaghayi et al. (2005) developing framework truthful
DAs. model DAs must also address constraints timing
occur Porter, Hajiaghayi, Lavi Nisans work. previous works, items
171

fiBredin, Parkes Duong

reusable expiring could allocated particular periods. work
provide limited allowance match-maker, allowing hold onto sellers item
matched buyer ready depart (perhaps seller departed).
closest work literature due Blum et al. (2006), present online matching algorithms dynamic DA model. main focus paper
design matching algorithms good worst-case performance adversarial setting,
i.e. within framework competitive analysis. Issues related incentive compatibility
receive less attention. One way work general also study
goals profit maximizing number trades, addition goal maximizing
social welfare consider work. However, algorithmic result
present truthful model (where agents misreport arrival departure)
goal social welfare. DA describe instance Chain
fixed price drawn distribution start time, used matching
price every period. Perhaps unsurprisingly, given worst-case approach, observe
auction performs significantly worse Chain defined fixed price
picked optimize welfare given distributional information domain.

8. Conclusions
presented general framework construct algorithms match buyers sellers
online markets valuation activity-period information private agents.
algorithms guarantee truthful dominant strategies first imposing minimum admission price offer pricing pairing offer first opportunity.
heart Chain framework lies pricing algorithm must offer either
determine price independent information describing offer choose discard
offer. pricing algorithm chosen match market conditions. present
several examples suitable pricing schemes, including fixed-price, moving-average,
McAfee-based schemes.
often not, find competition-based scheme employs McAfeebased rule truthfully price market delivers best allocative efficiency. exceptionally low volatility high arrival intensity, find adaptive price-based schemes
exponentially-weighted moving average (EWMA) even fixed price schemes
perform well. see qualitatively similar results net efficiency, revenue
accrues auctioneer discounted, albeit price-based rules EWMA
improved performance price spread. observations rooted
simulations comparing market efficiency mechanism optimal offline solution.
Additionally, compare efficiency truthful markets fixed-price worstcase optimal scheme presented Blum et al. (2006), market strategic agents using
variant ZIP price update algorithm developed Cliff Bruten (1998)
continuous double auctions, non-truthful, greedy matching algorithm provide
upper-bound performance. best schemes yield around 33% net efficiency
low volatility, high patience environments 40% net efficiency high volatility, low
patience environments, greedy bound suggests much 86% efficiency
possible non-strategic agents. note Blum et al.scheme, designed
adversarial settings, fairs poorly simulations (< 10%).
172

fiChain: Online Double Auction

One argue, think convincingly, truthfulness brings benefits
avoids waste costly counterspeculation promotes fairness markets (Sandholm,
2000; Abdulkadiroglu et al., 2006). hand, certainly interest
gap efficiency greedy matching non-truthful matching
truthful auctions large. Here, observe ZIP-populated (non-truthful)
markets achieve around 82% efficiency low volatility environments collapse around
23% efficiency high volatility environments. Based this, one might conjecture
designing truthfulness especially important badly behaved, highly volatile (thin)
environments less important well behaved, less volatile (thick) environments.
Formalizing tradeoff providing absolute truthfulness approximate
truthfulness, considering nature environment, interesting direction future work (see paper Parkes et al., 2001). Given reporting market
statistics incorporated within framework (see Section 5.1), given markets also play role information aggregation value discovery, future research
also consider additional aspect market design. Perhaps interesting tradeoff
efficiency, truthful value revelation, process information aggregation.
general Chain framework achieves good efficiency, tuning seems possible. One direction adopt meta-pricing scheme chooses, blends, prices
competing algorithms. Another direction consider richer temporal models; e.g.,
value goods agents might decay grow time better account time
value assets. richer temporal model might also consider possibility agents
match-maker taking short positions (including short-term cash deficits) increase trade.
also interesting extend work markets non-identical goods
complex valuation models bundle trades (Chu & Shen, 2007; Babaioff & Walsh,
2005; Gonen et al., 2007), dynamic matching problems without prices,
online variation classic marriage problem (Gusfield & Irving, 1989).

Acknowledgments
earlier version paper appeared Proceedings 21st Conference Uncertainty Artificial Intelligence, 2005. paper characterizes necessary conditions
truthful online trade; truthfully matches offers using generalized framework based
upon arbitrary truthful static pricing rule; compares efficiency truthful
framework achieved non-truthful markets populated strategic trading agents
worst-case optimal double auctions.
Parkes supported part NSF grant IIS-0238147 Alfred P. Sloan Fellowship
Bredin would like thank Harvard School Engineering Applied Sciences
hosting sabbatical much work completed. Thanks also
three anonymous reviewers, provided excellent suggestions improving earlier
draft paper.

Appendix: Proofs
Lemma 1 Procedure Match defines valid strong no-trade construction.
173

fiBredin, Parkes Duong

Proof: cases, SNTt NTt . set NTt correctly constructed: equal
remaining bids bt (j = 0) Case I, remaining bids st (i = 0) Case II,
remaining bids asks otherwise. case, bid (or ask) NTt could
traded price available bid ask opposite market
given order.
verifying strong no-trade (SNT) conditions (a) (b), proceed case analysis.
Case I. (i 6= 0) (j = 0). NTt := bt .
(I-1) k st (dk = t) SNTt := bt . SNT-a, consider l NTt dl > t.
l deviates changes remain Case NTt unchanged still
contains l. l deviates 0 then, go Case III SNTt := bt st still
contains l. SNT-b, consider l SNTt deviates dl > t. Again, either
remain case SNTt unchanged 0 go Case III.
SNTt still contains bt therefore unchanged agents dk > t.
(I-2) Buyer k bt dk = bk pt SNTt := bt . SNT-a, consider l NTt
dl > t. remain case deviation buyer l buyer k
ensure 6= 0, SNTt remains unchanged still contains l. SNT-b,
l SNTt dl > deviates remain case SNTt unchanged.
(I-3) seller dk > buyer dk = willing accept price.
SNTt := bt \ checkedB . SNT-a, consider l NTt dl > t. First, suppose
l checkedB 6= l. l deviates still dl > t, even := l
remain case l enter SNTt . Second, suppose l checkedB
(i = l). l deviates still dl > t, even (i = 0) (j = 0), go
Case III SNTt = l enter SNTt . Third, suppose l
/ checkedB


dl > t. Deviating dl > effect remain case l
remains SNTt . SNT-b, consider l SNTt dl > t, i.e. l
/ checkedB .
l deviates dl > t, effect remain case SNTt
remains unchanged.
Case II. (j 6= 0) (i = 0). NTt := st . Symmetric Case I.
Case III. (i = 0) (j = 0). NTt := bt st .
(III-1) k bt (dk = t) k st (dk > t) SNTt := bt st . SNT-a, consider
l NTt dl > t. must ask. l deviates remain case,
l remains SNTt . j := l, go Case II SNTt := st l remains
SNTt . SNT-b, consider l SNTt dl > t, must ask. l
deviates remain case, SNTt unchanged. l deviates j := l,
go Case II, SNTt := st , buyers bt removed SNTt . OK
buyers depart period anyway.
(III-2) k st cdot(dk = t) k bt (dk > t) SNTt := bt st . Symmetric Case
III-1.
(III-3) k bt (dk = t) k st cdot(dk = t). SNTt := bt st . SNT-a SNT-b
trivially met bids asks departure past current period.
174

fiChain: Online Double Auction

(III-4) k bt (dk > t) k st (dk > t) SNTt := . SNT-a, consider l NTt
dl > t. Assume l bid. l deviates dl > = 0 remain
case l SNTt . l deviates dl > := l, go
Case necessarily Sub-case (I-a) dl >
bid willing accept price (else 6= 0 first place). Thus, would
SNTt := bt \ checkedB l would SNTt . SNT-b, trivially
satisfied agents l SNTt .

Lemma 5 set active agents (other i) period Chain independent
report agent remains active, would unchanged arrival later
period t.
Proof: Fix arrival period ai . Show ai ai , set active agents period
ai active without agent arrival ai > t. Proceed
induction number periods ai . period = ai trivial.
consider period ai + r, r 1 assume inductive hypothesis

ai + r 1. Since still active then, SNTt = ai + r 1, therefore

agents SNTt survive period independent agent report strong
no-trade condition (b). completes proof.

Lemma 6 price constructed admission price q post-arrival price p valueindependent monotonic-increasing matching rule Chain well-defined,
strong no-trade construction valid, agent patience bounded K.
Proof: First fix ai , di . show value-independence (B1), first note q
value-independent, since whether SNTt pre-arrival period valueindependent strong no-trade condition (a) price zi (H , \ i, ) period
agent-independent definition. Term p also value-independent: decision period
agent i, any, independent wi since agents remain active
independent agent active Lemma 5, whether SNTt
value-independent strong no-trade (a); price value-independent
set active agents value-independent.
fix show price monotonically-increasing tighter arrival-departure
interval (B2). First note q monotonic-increasing [ai , di ] [ai , di ] earlier
di later ai increases domain [di K, ai 1] q defined. Fix
ai ai . Argue price increases earlier di di , di > ai . see this, note
either di < pi (ai , di , , ) = di di , di price constant
di < point becomes . Fix di ai . Argue price increases
later ai ai , ai di K. First, ai t, p unchanged Lemma 5.
interesting case ai > t, especially q(ai , di , , ) < p(ai , di , , ).
reporting later arrival, agent delay decision period perhaps hope
achieve lower price. But, note case [di K, ai 1] since di K ai
[ai , ai 1] q(ai , di , , ) p(H , \ i, ) q includes price
period since
/ SNTt pre-arrival period Lemma 5. Overall, see
although p may decrease, max(q, p) cannot decrease.

175

fiBredin, Parkes Duong

Lemma 7 strongly truthful, canonical dynamic DA must define price pi (ai , di , , )
zi (H , \ i, ) decision period bid (if exists). Moreover, bid
must priced-out period matched.
Proof: (a) First, suppose zi (H , \ i, ) > wi bid priced-out instead
survives active bid next period.
/ SNTt , set active bids
period +1 need independent agent bid price zi (H t+1 , At+1 \ i, )
need agent-independent. Yet, canonical rule (iii) requires price used
determine whether agent matches, dynamic DA need
truthful. (b) assume contradiction pi (ai , di , , ) < zi (H , \ i, ). First,
zi (H , \ i, ) < , agent value pi (ai , di , , ) < wi < zi (H , \ i, )
report wi = zi (H , \ i, ) + trade final payment less true
value (whereas would priced-out reported true value). zi (H , \i, ) = ,
pi (ai , di , , ) < zi (H , \i, ) implies bids survive period even
though priced-out matching rule strong no-trade set.
compromises truthfulness dynamic DA, discussed part (a).

Lemma 8 strongly truthful, canonical individual-rational dynamic DA must define
price pi (ai , di , , ) q(ai , di , , ), bid wi < q(ai , di , , ) must pricedout upon admission.
Proof: Suppose di < ai + K [di K, ai 1] non-empty. di = ai + K 1,
= di K decision period (and
/ SNTt ),
pi (ai , di , , ) pi (di K, di , , ) zi (H , \ i, ),

(24)

first inequality monotonicity (B2) second follows Lemma 7
since di K decision period, would remain one report = (di K, di , wi )
Lemma 5. establishes pi (ai , di , , ) q(ai , di , , ) di = ai + K 1.
di = ai + K 2, need Eq. (24), also = di K + 1 decision period
(and
/ SNTt ) have,

pi (ai , di , , ) pi (di K + 1, di , , ) zi (H , \ i, ),

(25)

reasoning above. generalizes di = ai + K r r {2, . . . , K}
establish pi (ai , di , , ) q(ai , di , , ) general case. see bid must
priced-out wi < q(ai , di , , ), note remain active could match
matching rule canonical (iii) need trade, thus fail individual-rationality
since payment collected would value.


References
Abdulkadiroglu, A., Pathak, P. A., Roth, A. E., & Sonmez, T. (2006). Changing Boston
school choice mechanism. Tech. rep., National Bureau Economic Research Working
Paper No. 11965.
Archer, A., & Tardos, E. (2001). Truthful mechanisms one-parameter agents. Proceedings 42nd IEEE Symposium Foundations Computer Science, pp. 482491.
176

fiChain: Online Double Auction

Babaioff, M., & Nisan, N. (2004). Concurrent auctions across supply chain. Journal
Artificial Intelligence Research, 21, 595629.
Babaioff, M., Nisan, N., & Pavlov, E. (2001). Mechanisms spatially distributed market.
Proceedings 5th ACM Conference Electronic Commerce, pp. 920.
Babaioff, M., & Walsh, W. E. (2005). Incentive-compatible, budget-balanced, yet highly
efficient auctions supply chain formation. Decision Support Systems, 39, 123149.
Blum, A., Sandholm, T., & Zinkevich, M. (2006). Online algorithms market clearing.
Journal ACM, 53, 845879.
Chatterjee, K., & Samuelson, L. (1987). Bargaining two-sided incomplete information:
infinite horizon model alternating offers. Review Economic Studies, 54,
175192.
Chu, L. Y., & Shen, Z. M. (2007). Truthful double auction mechanisms e-marketplace.
Operations Research. appear.
Cliff, D., & Bruten, J. (1998). Simple bargaining agents decentralized market-based
control.. Proceedings European Simulation Multiconference Simulation Past, Present Future, pp. 478485, Manchester, UK.
Copeland, T. E., & Weston, J. F. (1992). Financial Theory Corporate Policy (Third
edition). Addison-Wesley, Reading, MA.
Das, R., Hanson, J. E., Kephart, J. O., & Tesauro, G. (2001). Agent-human interactions
continuous double auction. Proceedings 17th International Joint
Conference Artificial Intelligence, pp. 11691187.
Deshmukh, K., Goldberg, A. V., Hartline, J. D., & Karlin, A. R. (2002). Truthful competitive double auctions. Proceedings European Symposium Algorithms,
pp. 361373.
Gerkey, B. P., & Mataric, M. J. (2002). Sold!: Auction methods multirobot coordination.
IEEE Transactions Robotics Automation, 18 (5), 758768.
Gjerstad, S., & Dickhaut, J. (1998). Price formation double auctions. Games
Economic Behavior, 22 (1), 129.
Goldberg, A., & Hartline, J. (2003). Envy-free auctions digital goods. Proceedings
4th ACM Conference Electronic Commerce, pp. 2935.
Gonen, M., Gonen, R., & Pavlov, E. (2007). Generalized trade reduction mechanisms.
Proceedings 8th ACM Conference Electronic Commerce, pp. 2029.
Gusfield, D., & Irving, R. W. (1989). Stable Marriage Problem: Structure Algorithms. MIT Press, Cambridge, MA.
Hajiaghayi, M. T., Kleinberg, R., Mahdian, M., & Parkes, D. C. (2005). Online auctions
re-usable goods. Proceedings 6th ACM Conference Electronic Commerce,
pp. 165174.
Hajiaghayi, M. T., Kleinberg, R., & Parkes, D. C. (2004). Adaptive limited-supply online
auctions. Proceedings 5th ACM Conference Electronic Commerce, pp.
7180.
177

fiBredin, Parkes Duong

Hassoun, M. H. (1995). Fundamentals Artificial Neural Networks. MIT Press, Cambridge,
MA.
Huang, P., Scheller-Wolf, A., & Sycara, K. (2002). Design multi-unit double auction
e-market. Computational Intelligence, 18, 596617.
Lagoudakis, M., Markakis, V., Kempe, D., Keskinocak, P., Koenig, S., Kleywegt, A., Tovey,
C., Meyerson, A., & Jain, S. (2005). Auction-based multi-robot routing. Proceedings
Robotics Science Systems Conference, pp. 343350.
Lavi, R., & Nisan, N. (2005). Online ascending auctions gradually expiring goods.
Proceedings ACM-SIAM Symposium Discrete Algorithms, pp. 11461155.
Lavi, R., & Nisan, N. (2000). Competitive analysis incentive compatible on-line auctions.
Proceedings 2nd ACM Conference Electronic Commerce, pp. 233241.
Lin, L., & Zheng, Z. (2005). Combinatorial bids based multi-robot task allocation method.
Proceedings 2005 IEEE International Conference Robotics Automation, pp. 11451150.
McAfee, R. P. (1992). dominant strategy double auction. Journal Economic Theory,
56 (2), 434450.
Myerson, R. B., & Satterthwaite, M. A. (1983). Efficient mechanisms bilateral trading.
Journal Economic Theory, 29, 265281.
Pai, M., & Vohra, R. (2006). Optimal dynamic auctions. Tech. rep., Kellogg School
Management, Northwestern University.
Parkes, D. C. (2007). Online mechanisms. Nisan, N., Roughgarden, T., Tardos, E., &
Vazirani, V. (Eds.), Algorithmic Game Theory, chap. 16. Cambridge University Press.
Parkes, D. C., Kalagnanam, J. R., & Eso, M. (2001). Achieving budget-balance
Vickrey-based payment schemes exchanges. Proceedings 17th International Joint Conference Artificial Intelligence, pp. 11611168.
Porter, R. (2004). Mechanism design online real-time scheduling. Proceedings
5th ACM Conference Electronic Commerce, pp. 6170.
Preist, C., & van Tol, M. (1998). Adaptive agents persistent shout double auction.
Proceedings First International Conference Information Computation
Economies, pp. 1118.
Rust, J., Miller, J., & Palmer, R. (1994). Characterizing effective trading strategies: Insights
computerized double auction tournament. Journal Economic Dynamics
Control, 18, 6196.
Sandholm, T. (2000). Issues computational Vickrey auctions. International Journal
Electronic Commerce, 4 (3), 107129.
Satterthwaite, M. A., & Williams, S. R. (1989). Bilateral trade sealed bid k-double
auction: Existence efficiency. Journal Economic Theory, 48, 107133.
Smith, V. L. (1962). experimental study competitive market behavior. Journal
Political Economy, 70, 111137.
178

fiChain: Online Double Auction

Tesauro, G., & Bredin, J. (2002). Strategic sequential bidding auctions using dynamic programming. Proceedings First International Joint Conference Autonomous
Agents Multiagent Systems, pp. 591598, Bologna, Italy.
Yoon, K. (2001). Modified Vickrey Double Auction. Journal Economic Theory, 101,
572584.

179

fiJournal Artificial Intelligence Research 30 (2007) 51 - 100

Submitted 03/07; published 09/07

Graph Abstraction Real-time Heuristic Search
Vadim Bulitko
Nathan Sturtevant
Jieshan Lu
Timothy Yau

BULITKO @ UALBERTA . CA
NATHANST @ CS . UALBERTA . CA
JIESHAN @ CS . UALBERTA . CA
THYAU @ UALBERTA . CA

Department Computing Science, University Alberta
Edmonton, Alberta, T6G 2E8, CANADA

Abstract
Real-time heuristic search methods used situated agents applications require
amount planning per move independent problem size. agents plan
actions time local search space avoid getting trapped local minima improving heuristic function time. extend wide class real-time search algorithms
automatically-built state abstraction prove completeness convergence resulting
family algorithms. analyze impact abstraction extensive empirical study
real-time pathfinding. Abstraction found improve efficiency providing better trading offs
planning time, learning speed negatively correlated performance measures.
Keywords: learning real-time heuristic search, state abstraction, goal-directed navigation.

1. Introduction Motivation
paper study problem agent-centered real-time heuristic search (Koenig, 2001).
distinctive property search agent must repeatedly plan execute actions
within constant time interval independent size problem solved.
restriction severely limits range applicable algorithms. instance, static search algorithms
(e.g., A* Hart, Nilsson, & Raphael, 1968), re-planning algorithms (e.g., D* Stenz, 1995),
anytime algorithms (e.g., ARA* Likhachev, Gordon, & Thrun, 2004) anytime re-planning
algorithms (e.g., AD* Likhachev, Ferguson, Gordon, Stentz, & Thrun, 2005) cannot guarantee
constant bound planning time per action. LRTA* provides guarantees planning
actions time updating heuristic function, solution quality poor
lengthy convergence process (Korf, 1990; Ishida, 1992).
motivating example, consider navigation gridworld maps commercial computer
games. games, agent tasked go location map current
location. agent must react quickly users command regardless maps size
complexity. Consequently, game companies impose time-per-action limit pathfinding algorithms. example, Bioware Corp., major game company, limits planning time 1-3 ms
pathfinding units (and many units planning simultaneously).
additional challenge comes form limited sensing virtual reality trainers
Artificial Intelligence controlled characters may access entire map priori, order
avoid unrealistic behavior (Dini, van Lent, Carpenter, & Iyer, 2006). agents build
internal map model based sensing limited amount map around position.
efficient search agent would minimize delay incurred planning actions, explore
learn environment quickly, always discover optimal path goal. Unfortunately,
c
2007
AI Access Foundation. rights reserved.

fiB ULITKO , TURTEVANT, L U , & YAU

measures negatively correlated (or antagonistic) optimizing performance one
measure results worse performance one others. instance, reducing amount
planning done action improves agents response time, leads slower learning
due lower-quality actions taken agent.
propose use graph abstraction improve efficiency search agents make
following four contributions. First, introduce new algorithm, Path Refinement Learning
Real-time Search (PR LRTS)1 , enhances existing real-time heuristic search algorithms
automatically-built graph abstraction. PR LRTS learns heuristic function abstract space
thereby substantially accelerating learning. Actions abstract space refined actions
environment A* algorithm. approach allows agents generate actions constant
time, explore environment quickly, converge near-optimal solutions. paper use
previously published clique abstraction (Sturtevant & Buro, 2005). contributions specific
abstraction three-fold. First, introduce initial clique building repair procedure
detail previously published. Second, prove worst-case bound suboptimality
path induced abstraction. Third, present first application state abstraction
real-time heuristic search.
standard practice heuristic search literature promote new algorithms trading
small amount one performance measure large gain another performance measure.
instance, state abstraction non-real time heuristic search shown trade little solution
quality substantial reduction running time (e.g., Holte, Mkadmi, Zimmer, & MacDonald,
1996; Botea, Muller, & Schaeffer, 2004). Unfortunately, always clear whether tradeoffs made optimally. second contribution, demonstrate PR LRTS outperforms
number algorithms respect two antagonistic measures (e.g., learning speed
amount planning per action).
third contribution, analyze effects abstraction search respect commonly
used performance measures: solution suboptimality, amount planning per action, total travel,
total planning time, memory footprint. Knowing effects deepens understanding realtime heuristic search methods well guides practitioner selecting appropriate
search algorithm configuration application. Fourth, show theoretically PR LRTS
unifies extends several well known existing heuristic search algorithms satisfies realtime operation, completeness, convergence properties. contribution viewed
follow-up previous unification extension efforts (Bulitko & Lee, 2006).
rest paper organized follows. begin formulating problem real-time
heuristic search Section 2. new algorithm, PR LRTS, described Section 4. Empirical
results follow Section 5. Theoretical results presented Section 6. review existing
agent-centered search algorithms well work automatic graph abstraction Section 7.
paper concluded discussion current limitations future research.

2. Real-time Heuristic Search
defining property real-time heuristic search amount planning performed
agent per action constant upper-bound depend problem size. Low bounds
preferred applications, guarantee agents fast response presented new
goal. real-time search agent plans next action considering states local search space
1. early version algorithm published conference paper (Bulitko, Sturtevant, & Kazakevich, 2005).

52

fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCH

1 sc s0
2 sc 6= sg
3
sense environment, update agents model
4
compute partial path p originates current state sc
5
execute p
6
update current state sc
7 end
Figure 1: Real-time heuristic search (a single trial).
surrounding current position. heuristic function (or simply heuristic) estimates cumulative
cost state goal, used agent rank available actions select
promising one. process shown schematically Figure 1. Agents current state sc
set initial state s0 line 1. long goal sg reached (line 2), agent senses
environment around (see Section 3 details) updates model search graph
operating line 3. computes (partial) path current state toward goal
state line 4. real-time property requires lines 3 4 execute constant-bounded time
regardless problem size. accomplished calling real-time heuristic search algorithm
line 4. paper, discuss three candidate algorithms: LRTA* Section 2.1, LRTS
Section 2.2, PR LRTS Section 4. would called line 4. agent
executes path line 5 updates current state line 6.
trial defined agents problem-solving experience traveling start state
goal state. goal state reached, agent teleported start state next
trial begins. convergence process defined first sequence trials agent longer
updates heuristic function model search problem. first trial without updates
final trial learning process said converged.
2.1 Learning Real-time A* (LRTA*)
first review best known real-time heuristic search algorithm, Learning Real-Time A*
(LRTA*) (Korf, 1990). algorithm shown Figure 2. line 1, d-ply breadth-first search
duplicate detection used find frontier states precisely actions away current state
s. standard path-max (Mero, 1984) technique used deal possible inconsistencies
heuristic function computing g + h-values. value state, s, sum
cost shortest path sc s, denoted g(s, s), estimated cost shortest path
sg (i.e., heuristic value h(s, sg )). state minimizes sum identified s0
line 2. heuristic value current state updated line 3. Finally, path one action
toward promising frontier state s0 returned line 4.
path LRTA*(sc , sg , d)
1
2
3
4

generate successor states sc actions away
find state s0 lowest g(sc , s0 ) + h(s0 , sg )
update h(sc , sg ) g(sc , s0 ) + h(s0 , sg ) greater current h
return first action along optimal path sc s0
Figure 2: LRTA* algorithm.

53

fiB ULITKO , TURTEVANT, L U , & YAU

2.2 Learning Real-time Search (LRTS)
LRTS extends LRTA* three ways: puts weight heuristic function, uses maxof-min learning rule, utilizes backtracking. review extensions detail
Section 7.2 walk LRTS operation below. LRTS three control parameters: lookahead
N, optimality weight (0, 1], learning quota [0, ]. operates follows.
current state sc , agent running LRTS conducts full-width d-ply lookahead search (line 1
Figure 3). ply, finds promising state (line 2). Assuming initial heuristic
h admissible, safely increase h(sc ) maximum among f -values promising states
levels (line 3). total learning amount u (updated line 4) exceeds learning quota
, agent backtracks previous state planned (lines 5, 8). Otherwise, returns
path moves current state sc promising state level (line 6).
learning amount u reset 0 agent start state (i.e., beginning trial).
path LRTS(sc , sg , d, , )
1
2
3

generate successor states sc , actions away, = 1 . . .
level i, find state si lowest f (si ) = g(sc , si ) + h(si , sg )
update h(sc , sg ) max f (si ) greater current h

4
5
6
7
8
9

increase amount learning u h
u
return path actions sc sd
else
return path actions backtrack previous state, set u =
end

1id

Figure 3: LRTS algorithm.
LRTS parameters previously studied length (Bulitko & Lee, 2006). summarize trends. Higher lookahead reduces convergence travel, convergence memory, suboptimality. However, increases first-move lag. lower heuristic weight leads less optimal
solutions and, generally speaking, reduces convergence travel convergence memory. First-move
lag influenced . lower learning quota causes backtracking tends reduce
convergence travel convergence memory; affect first-move lag.
2.3 Notation
Definition 2.1 search problem defined tuple (G, c, s0 , sg , h0 ) G = (S, E)
directed weighted graph (henceforth search graph). finite set states (or vertices)
E finite set edges them. edge weights defined cost function
c : E (0, ) c(s1 , s2 ) travel cost edge e = (s1 , s2 ). s0 start
state, sg goal state, h0 : [0, ) initial heuristic function. assume
h0 (sg ) = 0. Out-edges state called moves actions. number out-edges (i.e.,
out-degree state) called branching factor state.
Definition 2.2 solution search problem path start state s0 goal state sg .
path denoted (s0 , s1 , . . . , sg ) si valid state valid edge
pair states (si , si+1 ). travel cost path sum travel costs edges.
54

fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCH

Definition 2.3 times, search agent resides single search state sc called current
state. agent change current state executing actions thus incurring travel
cost. Initially, current state coincides start state s0 . agent said succeed
makes current state coincide goal state sg .
assume goal state reachable state agent get start
state. needed completeness real-time heuristic search algorithms. also follow
standard practice real-time heuristic search literature assume environment
stationary deterministic. Additionally, support backtracking (Shue & Zamani, 1993; Shue,
Li, & Zamani, 2001) (i.e., reversing agents actions), require every action reverse
action. needed backtracking enabled algorithm.
Definition 2.4 travel cost state s1 state s2 denoted dist(s1 , s2 ) defined cost
shortest path s1 s2 . Throughout paper, assume dist satisfies triangle
inequality: s1 , s2 , s3 [dist(s1 , s3 ) dist(s1 , s2 ) + dist(s2 , s3 )]. Then, state, s, h (s)
defined minimal travel cost goal: h (s) = dist(s, sg ). heuristic function, h,
approximation h . admissible overestimate h : [h(s) h (s)]. value
h state referred heuristic value state s. assume heuristic
function h(sg ) = 0 trivially holds admissible h.
experiments break ties moves fixed fashion (e.g., always prefer
action north, north east, east, etc.) entails agents behavior
identical trials final trial. necessarily mean entire search graph
explored learned heuristic accurate states.
Definition 2.5 Convergence travel cumulative cost edges traversed agent
convergence process. Convergence planning amount planning effort expended
agent convergence process. first-move lag amount planning effort expended
agent first move final trial. Convergence memory measured total
number heuristic values stored convergence process. standard practice realtime heuristic search literature (e.g., Korf, 1990; Shimbo & Ishida, 2003) store heuristic
values hash table. Hash table misses handled procedurally specified initial heuristic h0
(e.g., Manhattan distance grid-based pathfinding). convergence memory number
entries hash table convergence. Finally, suboptimality defined percentage points
final-trial solution cost excess relative shortest-path cost. instance, agent
incurred travel cost 120 shortest-path cost 100, suboptimality 20%.
measure planning effort two ways. First, report number states algorithm
touched (i.e., considered) planning. measure called edges traversed (e.g., Holte
et al., 1996, p. 325). Second, report physical CPU time, measured 2.0GHz PowerPC G5
computer gcc 4.0 Mac OS 10.4.8. measure convergence memory terms
number heuristic values stored. meaningful heuristic value stored takes
fixed amount memory (i.e., double type C++) implementation algorithm.
Definition 2.6 search algorithm exhibits real-time performance heuristic search problem
planning effort per move constant-bounded constant independent problem size
(assuming fixed maximum branching factor).
55

fiB ULITKO , TURTEVANT, L U , & YAU

objectives real-time search agent complete (i.e., arrive goal state
every trial), converge (i.e., finish learning process finite number trials),
minimize five performance measures described above. rest paper discuss
existing new algorithms compare terms objectives.
2.4 Application: Goal-directed Navigation
One motivating applications heuristic search goal-directed navigation, also known
pathfinding. special case heuristic search problem formalized previous section
search graph (S, E) defined terrain map. Thus, states/vertices correspond
geographical positions map, edges describe passability blocking, cost function
represents difficulty/time traversing terrain.
Real-time pathfinding motivated primarily time-sensitive robotics (e.g., Koenig & Simmons, 1998; Koenig, 1999; Kitano, Tadokoro, Noda, Matsubara, Takahashi, Shinjou, & Shimada,
1999; Koenig, Tovey, & Smirnov, 2003) computer games. latter include real-time strategy
games (e.g., Blizzard Entertainment, 2002), first-person shooters (e.g., id Software, 1993), roleplaying games (e.g., BioWare Corp., 1998). these, time plays critical role since number
agents perform pathfinding simultaneously gamers would like rapid response fluid
gameplay. result, pathfinding become major computational expense: Age Empires
II (Ensemble Studios, 1999) takes 60-70% simulation time (Pottinger, 2000).
paper, follow footsteps Furcy Koenig (2000), Shimbo Ishida (2003),
Koenig (2004), Botea et al. (2004), Hernandez Meseguer (2005a, 2005b), Sigmundarson
Bjornsson (2006), Koenig Likhachev (2006) situate empirical study navigation
two-dimensional grid-based maps. cells square cell connected four cardinally
(i.e., west, north, east, south) four diagonally neighboring cells. cell occupied
agent (i.e., free) wall (i.e., blocked).
free grid cell constitutes vertex/state search space S. agent travel
two free neighboring cells, s1 s2 , edge (s1 , s2
) added set edges E.
paper, set edge costs 1 cardinal moves 2 diagonal moves. cell initially
occupied agent s0 ; target cell sg . example converting grid-based map
search problem defined (G, c, s0 , sg , h0 ) shown Figure 4. Note allow
diagonal moves cut corners and, thus, state s6 connected states s1 , s5 , s7 , sg .
done non-zero size agent able pass zero-width bottleneck
formed two diagonally adjacent blocked cells. case one corner (e.g.,
states
s5 s6 Figure 4), allowing cut would lead actual travel distance
exceeding 2 since non-zero-width agent walk around corner.
Video games often feature repeated pathfinding experiences map two reasons:
(i) units commute source destination (e.g., resource collectors
real-time strategy games) (ii) ally units share results learning (i.e., heuristic
function). Since trial typically improves heuristic values many states, even single trial
single unit use units different start states long share goal
state. often case state abstraction entire region map (e.g., room
role-playing game players home base real-time strategy game) mapped
single abstract state. Thus, single-trial learning experiences multiple units approximated
multi-trial learning experience single unit. latter scenario study paper,
56

fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCH

Goal

s7

s8

sg

s6

Start

s1

s4

s5

s0

s2

s3

Figure 4: 34 grid-based map (left) converted 9-state search graph (right). Thinner
cardinaldirection edges cost 1, thicker diagonal edges cost 2.
line Furcy Koenig (2000), Shimbo Ishida (2003), Sigmundarson Bjornsson (2006)
others.

3. Search Graph Discovery
paper, require search agent know problem entirety. Instead, portion
search problem neighborhood current state sc sensed agent time
step. assume agent remember parts problem sensed far.
words, times agent internal representation (model) search space like.
model updated agent discovers search graph (line 3 Figure 1).
Let us illustrate exploration process goal-directed navigation. terrain map initially
unknown agent. moves around environment, grid cells whose coordinates within
fixed visibility radius agents current position sensed. Formally, agent situated cell
(x, y) check status (free/blocked) cell (x0 , 0 ) |x x0 | r |y 0 | r,
r N visibility radius. Thus, two visible cells (x0 , 0 ) (x00 , 00 ) agent tell
edge cost. similar virtual sensors used Thalmann,
Noser, Huang (1997).
One common approach assume regular structure unknown part search
space (Koenig et al., 2003; Koenig, 2004; Bulitko & Lee, 2006; Koenig & Likhachev, 2006).
instance, grid-based pathfinding, agent assume obstacles gridworld
senses otherwise (this sometimes called free space assumption). demonstrate
Figure 5, agent assumes space obstacle-free (a) builds internal
model accordingly (b). Exploration reveals obstacles environment (c) cause agent
update model (d). impose restriction search agent never needs add edges
model exploration weights discovered edges never change. words, agents
initial model optimistic contains superset edges actual search graph. Adding edges
allowing arbitrary edge weight changes may require agent explore environment explicitly. Combining exploration exploitation effectively active research area (for early work,
refer Sutton, 1990) addressed paper.
Map discovery natural robotics sensors limited ranges. software domains,
agent theoretically access entire environment. Several types arguments
made justify restricting agents senses software domains. First, omniscient virtual
57

fiB ULITKO , TURTEVANT, L U , & YAU

Actual search space:

Agent's model:

Explored actual search space:

Updated agent's model:

(a)

(b)

(c)

(d)

Figure 5: (a): initially part search space shown solid lines sensed agent
(shown stick figure). agents model assumes regular structure unknown
part (b). agent moves north-east, senses additional part search space
(c) updates model correspondingly (d).
humans tend behave unrealistically and, thus, less suitable virtual reality trainers (Dini
et al., 2006). Likewise, commercial games, revealing entire map AI player viewed
negatively cheating. Second, computationally expensive sense (Orkin, 2006)
reason entire environment (Thalmann et al., 1997; Aylett & Luck, 2000). Consequently,
localized sensing used large-scale multi-unit systems (Reynolds, 1987).

4. Path Refinement Learning Real-time Search (PR LRTS)
Real-time heuristic search algorithms plan using small part search graph surrounds
agents current state. order avoid getting stuck infinite loops, update heuristic
function time. approach guarantees action planned constant-bounded
amount time. downside slow convergence.
central idea PR LRTS address downside running real-time search
smaller abstract search graph refining produced abstract path ground-level path.
abstract graph image original graph abstraction operator. operator
maps region states original graph single abstract state abstract graph.
applied multiple times, hierarchy abstractions formed. hierarchy forest (a tree
connected component search graph) formalized Section 4.2.
variety terminologies used literature discussing relationship states different levels abstraction. different contexts abstract states
referred clusters (Botea et al., 2004), sectors/regions (Sturtevant, 2007), images (Holte
et al., 1996). abstraction forest, line (Bacchus & Yang, 1994; Bulitko
et al., 2005; Sturtevant & Buro, 2005), sometimes call image abstraction operator parent
pre-image children. terms confused successor states lookahead
search. first describe PR LRTS intuitive level illustrate example Section 4.1. give formal details Section 4.2 describe abstraction operator detail.
4.1 Path Refinement
PR LRTS computes paths several levels abstraction. First, path found
abstract search space (at level `). abstract path defines region lower-level abstract
58

fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCH

path PR LRTS(sc , sg )
1
2
3
4
5
6
7
8
9
10
11
12
13

level(sc ) > `
return
end
p =PR LRTS(parent(sc ), parent(sg ))
p 6=
sg = child(end(p))
end
C = {s | parent(s) p}
switch(algorithm[level(sc )])
A* : return A*(sc , sg , C)
LRTS : return LRTS(sc , sg , C)
pass-through : return p
end switch

Figure 6: PR LRTS algorithm.
space searched refining abstract path. refinement proceeds incrementally
level-0 (i.e., ground) search space reached ground path produced. order
keep amount planning per move constant-bounded regardless ground space size,
need real-time algorithm abstract search graph. paper, use LRTS
fixed top level abstraction (`), A* refinement lower levels.2 abstract levels
left pass-through merely increase amount state aggregation; processing
carried them. design choice motivated experimentation (Section 5).
PR LRTS operates recursively presented Figure 6. line 1 checks states passed
top level abstraction pathfinding occur. so, empty path
returned (line 2). Otherwise, function calls recursively compute path
abstract image sc (denoted parent(sc ) line 4) abstract image sg . returned
path (if non-empty checked line 5) used derive new destination line 6. Specifically,
new destination sg child end abstract path p.3 line 8, compute
corridor C comprised pre-images states path p. corridor C empty
path p computed line 4 empty. Finally, run algorithm assigned current level
abstraction (i.e., level sc sg ) lines 10 11. A* LRTS tasked
find either full (in case A*) partial path (in case LRTS) sc sg limited
set states C. convention, empty corridor (C = ) allows A*/LRTS search entire
graph. Note processing happens pass-through level (line 12).4
2. agent explores environment moving about, actually use Local Repair A* instead A*.
described Section 7.
3. child used, choices may lead better performance. Intuitively, child chosen
child(end(p)) closest representative abstract state end(p) among children(end(p)).
pathfinding, implement child(s) return element children(s) geographically closest average coordinates states children(s). Also, goal state sg happens pre-image end(p)
pick child(end(p)).
4. Also note functions child parent handle pass-through levels. Specifically, line 6, state sg
computed child first non-pass-through level level path p computed. Likewise, line
8, states forming corridor C first non-pass-through level (level i) level path p (level
j). Thus, parent(s) apply abstraction mapping j times parent(s) p level j.

59

fiB ULITKO , TURTEVANT, L U , & YAU

implementation A* standard (Hart et al., 1968) except run (line 10) subgraph
defined corridor C (line 8). implementation LRTS taken literature (Bulitko
& Lee, 2006) described Section 2.2. Like A*, run LRTS corridor C.

Figure 7: path refinement process. original graph (level 0) shown bottom.
abstract graph (level 1) shown top.
illustration purposes, consider example Figure 7. example ` = 1, one
level abstraction (shown top) used addition ground level (shown bottom).
sc current state sg destination state. LRTS assigned level 1 A*
assigned level 0. Subfigure (i) shows ground state space one level abstraction
above. agent must plan path sc sg located ground level. First, abstract
parents sc sg , parent(sc ) = s0c parent(sg ) = s0g , located. LRTS = 3
plans three steps abstract space (ii). corridor C ground level comprised children
abstract path built (iii). child representing end abstract path set
new destination sg (iv). Finally, A* run within corridor find path sc new
destination sg (v).
agent executing path computed PR LRTS, new areas search graph may
seen. causes updates abstraction hierarchy agent maintains. PR LRTS clears
recomputes abstract paths upon discovering new areas search graph. Also, ground
path proves invalid (e.g., runs newly discovered obstacle), execution stops PR LRTS
replans current state using updated abstraction hierarchy.
Graph discovery lead arbitrary updates abstract search graphs agent maintains.
implementation, LRTS operating abstract graph resets heuristic function abstract search graph updated way. hand, updates ground-level graph
limited state edge removals (Section 3). Consequently, heuristic learned ground
level remains admissible need reset upon updates.
4.2 Automatic Graph Abstraction
use term abstraction operator (or abstraction, short) mean graph homomorphism
line Holte et al. (1996). Namely, abstraction many-to-one function maps (abstracts)
one states single abstract state. Adjacent vertices mapped adjacent identical
vertices (Property 5 below). Given graph homomorphism function model search
problem, PR LRTS agent builds ` additional abstract search graphs, collectively called abstrac60

fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCH

tion hierarchy, follows. first applies graph homomorphism search graph model
(called ground-level graph). result abstract search graph level 1. process
repeated abstract search graph level ` computed. homomorphic abstraction
used long resulting hierarchy abstract graphs satisfies several key properties. following introduce properties informally illustrate example. Appendix B
formalize them.
Property 1 Every abstract graph search graph sense Definition 2.1 Section 2.
Property 2 Every state unique abstract parent (except states top level abstraction).
Property 3 Every state abstract level, least one child state below.
Property 4 Given heuristic search problem, number children abstract state upperbounded constant independent number states ground-level graph.
corollary property number ground-level states abstract single
state fixed level abstraction also constant-bounded constant independent
ground-level graph size.
Property 5 (Graph homomorphism) Every edge search graph level abstraction
either corresponding edge level states connected edge abstract
single abstract state.
Property 6 abstract edge exists two states edge least
child one state child other.
Property 7 two children abstract state connected path whose states
children abstract state.
Property 8 abstraction hierarchy consistent agents model search problem
times. is, properties 1 7 satisfied respect agents model.
paper, use clique-based abstraction mechanism (Sturtevant & Buro, 2005). operates finding fully connected components (cliques) search graph mapping
single abstract state. method building abstractions favored recent analysis Sturtevant
Jansen (2007) earlier analysis Holte et al. (1996, Section 5.2) showed reduction
search effort due abstraction maximized minimizing edge diameter set children
maximizing size. clique, edge diameter (i.e., maximum number edges
two elements) one number states clique maximized.
present clique-based abstraction mechanism developing several stages handtraceable example. illustrate properties introduced satisfied
example. formal introduction clique abstraction technique complete pseudocode
found Appendix A. review ways building abstraction Section 7.3. Note
general clique computation NP-complete, finding cliques two-dimensional grid-based search
graphs done efficiently (Appendix A).
61

fiB ULITKO , TURTEVANT, L U , & YAU

single application abstraction procedure illustrated Figure 8. Cliques size four
first located graph, meaning states s0 , s1 , s2 s4 abstracted s01 .
cliques size three already abstracted first step, cliques size two
abstracted next. includes s5 s3 abstracted s02 , s7 s8
abstracted s03 . sg degree 1, add s03 ; however s6 degree two,
abstracted parent, s04 . Adding degree 1 states neighbors reduces number
resulting abstract states increases edge diameter set children (it becomes 2
set {s7 , s8 , sg }). minor detail abstraction happens effective grid-based
pathfinding. One use pure clique abstraction well.
s7

s8

sg

s'3

s6
s1

s4

s'4

s5
s'1

s0

s2

s'2

s3

Level 0 (original graph)

Level 1 (abstract graph)

Figure 8: Clique abstraction: original search graph Figure 4 shown left abstracted
search graph right.

s7

s8

sg

s'3
s''2

s6
s1

s4

s'4

s5
s'1

s0

s2

s'''
1

s'2

s''1

s3

Level 0 (original graph)

Level 1

Level 2

Level 3

Figure 9: Three iterations clique abstraction procedure.
abstraction process successively applied single abstract state connected component original graph remains (Figure 9, Level 3). illustrate
abstraction properties Figure 9. Property 1 requires four abstraction levels
Figure 9 search graph sense Definition 2.1 Section 2. Property 2 requires
62

fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCH

state levels 0, 1, 2 unique parent level above. Property 3 requires
state levels 1, 2, 3 non-empty set children level below. Property 4 places
upper bound number children abstract state have. example bound
4. Properties 5 6 require that, two abstract states connected path, parents
children also connected. Consider, instance, abstract states s02 s03 .
connected level 1 abstract path p = (s02 , s01 , s04 , s03 ) them. Thus, child
s02 also connected child s03 level 0. instance, s3 connected s7 . Property 7
requires children node s01 connected internal path within s01 . (s00 , s01 , s02 , s04 ) form
clique, property satisfied.
costs abstract edges (e.g., edge (s01 , s02 ) Figure 8) defined arbitrary way
long resulting search graph satisfies properties Section 2. However, better performance, low-cost abstract path abstraction low-cost ground path. paper
experiment grid-based navigation and, correspondingly, define cost edge (s01 , s02 )
Euclidean distance average coordinates children(s01 ) children(s02 ) (Figure 10).

Figure 10: Coordinates edge costs levels abstraction hierarchy. grid level
(leftmost illustration) vertex
coordinates given column/row labels. Ground
edges cost 1 (cardinal) 2 (diagonal). Abstract states labeled (x, y). Abstract
edges labeled approximate cost.

practice, Property 8 satisfied repairing agents abstraction hierarchy upon updates
agents model. illustrate, imagine agent discovered discrepancies
terrain elevation state s4 s6 (Figure 8) prevent able traverse edge
(s4 , s6 ). update model removing edge. Additionally, degree-one state s6
join clique {s7 , s8 }. point, agents abstraction hierarchy needs repaired.
accomplished replacing abstract states s04 s03 single abstract state s05 . edges (s01 , s04 )
(s04 , s03 ) removed. one level abstraction used repair
propagated higher levels well. repair mechanism presented detail Appendix A.2.
prove Section 6 PR LRTS algorithm operate abstraction mechanism
satisfies properties listed above.
63

fiB ULITKO , TURTEVANT, L U , & YAU

Figure 11: Two six maps used experiments.

5. Empirical Study
Empirical evaluation effects state abstraction learning real-time heuristic search
presented four parts. Section 5.1, introduce concept trading antagonistic
measures demonstrate PR LRTS makes trade-offs efficiently. due use
abstraction and, consequently, investigate effects abstraction independently LRTS
control parameters Section 5.2. study PR LRTS performance scales problem
size (Section 5.3). Finally, examine interplay effects abstraction LRTS
control parameters. domain-specific study present details Appendix F.
experimental setup follows. used 3000 problems randomly generated three
maps modeled environments role-playing game (BioWare Corp., 1998) three maps
modeled battlefields real-time strategy game (Blizzard Entertainment, 2002). six
maps 5672, 5852, 6176, 7629, 9749, 18841 states grids 139 148 193 193.
Two maps Figure 11. four maps shown Appendix C. 3000 problems
uniformly distributed across five buckets bucket represents range optimal solution
costs. first 600 problems optimal path cost [50, 60) range, next 600 problems
fell [60, 70) bucket last 600 problems [90, 100) bucket.
experimented various assignments algorithms (A*, LRTS, none) levels abstraction. experimentation, found keeping LRTS top, A* bottom level
leaving intermediate levels pass-through yielded best results testbed. following, present results 160 PR LRTS configurations, denoted LRTS` (d, , ), `
level abstraction LRTS control parameters d, , operates, A* running
bottom level. ` = 0, run LRTS ground level run A* all. LRTS
parameter space follows: ` {0, 1, 2, 3, 4}, lookahead depth {1, 3, 5, 9}, optimality
weight {0.2, 0.4, 0.8, 1.0}, learning quota {100.0, }. Two visibility radii used:
10 1000. analysis, focus case visibility radius 10, line
previous publications area (Bulitko et al., 2005; Bulitko & Lee, 2006). Experiments
visibility radius 1000 yielded similar results. point reference, ran single nonreal-time algorithm: A*. algorithms implemented within Hierarchical Open Graph
framework (Sturtevant, 2005) C++ run cluster, aggregate 1.7 years Intel
Xeon 3.0GHz CPU.
64

fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCH

5.1 Antagonistic Performance Measure Trade-off
practitioners viewpoint, section viewed parameter selection guide. start
finding sets parameters optimize performance PR LRTS along single measure.
consider optimizing pairs antagonistic performance measures.
research optimizing single performance measures within LRTS published Bulitko
Lee (2006). Table 1 extend results include A* PR LRTS. best algorithms
single performance measure A* LRTA* use abstraction. exception
convergence planning interplay planning per move convergence travel.
Table 1: Optimizing single performance measure.
Measure
convergence travel
first-move lag (states touched)
conv. memory
suboptimality
conv. planning (states touched)

best algorithm
A*
LRTA*
A*
A* LRTA*
LRTS3 (d = 1, = 0.2 0.4, ) LRTS2 (d = 1, = 0.2 0.4, )

power abstraction comes attempt optimize two negatively correlated (or
antagonistic) performance measures simultaneously. Consider, instance, convergence travel
first-move lag. order lower convergence travel, agent needs select better actions.
done increasing amount planning per move which, turn, increases first-move
lag. measures negatively correlated, performance along one measure traded
performance along other. Thus, interested algorithms make trade-offs
efficiently. order make analysis specific, first introduce concept dominance
respect set parameterized algorithms.
Definition 5.1 Algorithm said dominate algorithm B respect performance measures
x set problems P average performance measured x worse
Bs: avgP x(A) worse avgP x(B) avgP y(A) worse avgP y(B).
Algorithm C called dominated set algorithms set contains another algorithm
dominates it.
definition illustrated Figure 12 non-dominated algorithms shown solid circles dominated algorithms shown hollow circles. Intuitively, non-dominated algorithms
make trade-off performance measures x efficiently among algorithms
set. considered practice one wants optimize performance measures. Dominated algorithms safely excluded consideration regardless relative
importance measures x particular application.
Non-dominated algorithms ten pairs antagonistic measures summarized Table 2.
A* weighted version Korfs LRTA* extreme cases performance measures: A*
minimizes convergence travel uses heuristic memory; LRTA* minimizes first-move lag.
non-dominated algorithms PR LRTS abstraction. words, abstraction
path-refinement improve efficiency trading antagonistic performance measures. Figure 13
shows dominance plot convergence planning first-move lag. PR LRTS forms frontier
65

fiperformance
measure 2

performance
measure 2

worse

worse

B ULITKO , TURTEVANT, L U , & YAU

B


better

better

Nondominated
algorithms

better

performance
measure 1

better

worse

performance
measure 1

worse

Figure 12: Left: algorithm dominates algorithm B (left). Right: non-dominated algorithms
shown solid circles, dominated algorithms shown hollow circles.
non-dominated algorithms (the rightmost non-dominated point weighted LRTA*
extremely low first-move lag). Plots combinations Appendix D.

Firstmove Lag (states touched)

Dominated
Nondominated

3

10

LRTS3(1,0.4,)
2

10

LRTS2(1,0.4,)

LRTS1(1,0.4,)

1

10

LRTS(1,0.4,)
4

10

5

10
Convergence Planning (states touched)

6

10

Figure 13: Dominance convergence planning first-move lag.
dominance analysis done respect performance measures averaged
benchmark set problems. Dominance analysis level individual problems found
Appendix E shows similar trends.
5.2 Effects Abstraction Individual Performance Measures
section study effects abstraction individual performance measures. arbitrarily choose three diverse LRTS parameter combinations lookahead d, optimality weight ,
learning quota : (1, 1.0, ), (3, 0.2, 100), (9, 0.4, ). plots Figure 14, qualitative
summary Table 3, analysis trends below.
Convergence planning decreases abstraction level. increase planning per move higher abstraction levels overcompensated decrease convergence
travel. exact shape curves due interplay two measures.
66

fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCH

Table 2: Trading antagonistic performance measures.
Measure 1
first-move lag
(states touched)
first-move lag
(states touched)
first-move lag
(states touched)
first-move lag
(time)
first-move lag
(time)
first-move lag
(time)
suboptimality
suboptimality
suboptimality
suboptimality

Measure 2
conv. travel
conv. memory
conv. plan.
(states touched)
conv. travel
conv. memory
conv. plan.
(time)
conv. plan.
(states touched)
conv. plan.
(time)
conv. travel
conv. memory

Non-dominated algorithms (extreme cases italic)
A*, LRTA*( = 0.4),
LRTS1...4 (d {1, 3, 5, 9}, {0.2, 0.4, 0.8}, {100, })
A*, LRTA*( = 0.2),
LRTS1...4 (d {1, 3, 5, 9}, {0.2, 0.4}, {100, })
LRTS1...3 (d = 1, = 0.4, = ),
LRTA*( = 0.4)
A*, LRTA*( = 0.4),
LRTS1...4 (d {1, 3, 5, 9}, {0.2, 0.4}, {100, })
A*, LRTA*( {0.2, 0.4}),
LRTS1...4 (d {1, 3, 5}, {0.2, 0.4}, {100, })
A*, LRTA*( = 0.4),
LRTS1...3 (d {1, 3}, {0.2, 0.4}, {100, })
A*,
LRTS2...3 (d {1, 3, 5}, {0.2, 0.4, 0.8}, {100, })
A*
A*
A*

First-move lag increases abstraction level. due fact corridor
ground level induced abstract path length computed LRTS abstract level
increases abstraction level. two additional factors affecting shape curves.
First, average out-degree abstract states varies abstraction level. Second, boundaries
abstract graphs often seen lookahead = 9 higher abstraction level.
Convergence memory decreases abstraction level learning algorithm (LRTS) operates smaller abstract maps incurs smaller travel cost. practice, amount learning
LRTS tends correlate tightly travel. instance, LRTS2 (3, 0.8, ) correlation
convergence memory convergence travel empirically measured 0.9544
confidence 99%.
Suboptimality increases abstraction. increase due fact abstraction
level progressively simplifies ground graph topology and, abstract path guaranteed
refinable ground path, may lead agent away shortest solution. illustrative
example given Appendix B.1 refinement complete abstract path 221% longer
optimal ground path. Derivation theoretical upper bound suboptimality due
abstraction found Appendix B.2. second mechanism explains suboptimality rises faster
shallower LRTS searches. Specifically, A* ground level refines abstract d-step path
finding ground-level solution current state ground representative end
abstract path. solution guaranteed optimal within corridor necessarily
pass geographically closely intermediate states abstract path. Thus, giving A*
corridor induced longer abstract path liberates plot path possibly far-off
intermediate states abstract path. phenomenon illustrated Appendix B.1
feeding A* abstract path small fragments results suboptimality giving
big picture abstract path entirety. third factor affecting suboptimality curves
67

fi4

6

33 4
x 10

22
B ULITKO
, TURTEVANT, L U , & YAU

3
2

Convergence Travel

22

4

x 10

3
2
1

00
0

11

22

33

0 Abstraction
1
2 Level3
Abstraction
Level
Abstraction Level

44
4

First!Move Lag

6000

First!Move Lag
First!Move Lag

44

4

2000

00 0

0 000 0
0

4000
4000

4000

30

2000
2000
2000

20

00 0
0 0 0 1 1 1 2 2 2 3 33
Abstraction
Level
Abstraction
Level
Abstraction
Level

4 44

10

1000

2

x 10
6
2x 10

1.5
1.5 x 106

2

11

1.5

0.5
0.5

1

00

0.5

1500
1500
0

00

0

1000
1000
1500

1

30
1500
1500
30
0 1500
0
20
1000
1000
20

6000
6000

3030 30

6 6

11
22
33
Abstraction
Level
Abstraction Level

2000
2000
0.50.5
4000 0.5

11
00

00

x 10
x 10
22
6000
6000
6
0
x 10
02
1
2
3
1.51.5
Abstraction Level
40001.5
4000
6000 1 1

Suboptimality (%)
Convergence Memory
Suboptimality
(%)
Convergence
Memory
Convergence
Memory
Suboptimality
(%)

Convergence Travel
Convergence Travel

33

4

00

1

4 4

x 10
x 10
44

11

Convergence
Memory Memory
Convergence
Convergence
MemoryConvergence
Planning Planning
Convergence
ConvergencePlanning

First!Move Lag
First!Move
Convergence Travel
First!Move Lag
Lag
Convergence Planning
ConvergenceTravel
Travel
Convergence
Convergence
Planning
Convergence
Planning

4

x 10 4
4 x 10
4

4 4

1
2
3
Abstraction Level

4

11
22
3 3
Abstraction
Level
Abstraction
Level

4 4

500
500
1000

222 2
333 3
111 1
1Abstraction
2 Level
3
Level
Abstraction
Abstraction
Level
Abstraction
Level
Abstraction Level

1
2
3
Abstraction Level

444 4
4

4

00

500
0

00

0

10
500
10500
500
0
0 0
00 0
00 00

11
22
3 3
Abstraction
Level
Abstraction
Level

d=1,!=1,T="
d=1,!=1,T="
1
2
3
d=3,!=0.2,T=100
Abstraction Level
d=3,!=0.2,T=100
d=9,!=0.4,T="
d=9,!=0.4,T="

4

d=1,!=1,T="
d=3,!=0.2,T=100
1
2
3
1111
222 2Level333 3
Abstraction
Abstraction
Level
Abstraction
Level
Abstraction
Level
Abstraction
Level

4
444 4

d=9,!=0.4,T="

Suboptimality (%)

Suboptimality (%)
Suboptimality (%)

Figure 14: Effects abstraction in0 PR LRTS.
Error bars indicate standard errors
d=1,!=1,T="
d=1,!=1,T="
d=1,!=1,T="
0
1
2
3
4
d=3,!=0.2,T=100
d=3,!=0.2,T=100
d=3,!=0.2,T=100
2020 20
small see data points.Abstraction
Level
d=9,!=0.4,T="
d=9,!=0.4,T="
d=9,!=0.4,T="

1010 10

figure optimality weight . Setting lower values leads higher suboptimality
0
independently
00
0
1 abstraction
2
3
4(Bulitko & Lee, 2006).
00
1 1 Abstraction
22
33
44
Level
Convergence
travel
decreases
abstraction bottom level search constrained within
Abstraction
Level
Abstraction Level
narrow corridor induced abstract path. decrease noticeable shallow lookahead searches (d = 1 = 3). Algorithms using lookahead = 9 low convergence
travel even without abstraction, convergence travel lower bounded double optimal
solution cost (one optimal solution first trial map discovered one
final trial map discovery heuristic learning). Consequently, abstraction diminished
gains deeper lookahead (d = 9), although effect would disappear larger maps.
Table 3: Qualitative effects abstraction: general trends.
measure / parameter
first-move lag
convergence planning
convergence memory
suboptimality
convergence travel

0`






Given higher abstraction reduces convergence travel, one may ask compares
reducing convergence travel non-abstract algorithms simply terminating convergence
process final trial. Figure 15 compare four algorithms single problem: A*,
non-abstract LRTS(3, 0.4, ) two abstract versions: LRTS2 (3, 0.4, ) LRTS4 (3, 0.4, ).
left plot figure demonstrates well-known fact convergence learning heuristic
search algorithms non-monotinic (e.g. Shimbo & Ishida, 2003). right plot shows cost
shortest solution function cumulative travel. prefer algorithms find shorter solutions traveling little possible. plot, abstract algorithms perform better (lower
68

fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCH

A*
LRTS(3,0.4,)
LRTS2(3,0.4,)

Travel trial

180

LRTS4(3,0.4,)

160
140
120
100
80

2

4

6
Trial

8

A*
LRTS(3,0.4,)
LRTS2(3,0.4,)

200
Shortest solution found

200

180

140
120
100
80

10

LRTS4(3,0.4,)

160

200

400

600
800
1000
Cumulative travel

1200

1400

Figure 15: Convergence process level individual trials.
curves) preferred. words, single problem, better run abstract algorithms non-abstract algorithms regardless early convergence process terminated.
observe case problems assignments d, , tried.
certain cases, prematurely terminating convergence process non-abstract algorithm indeed
beneficial. Future research investigate extent one automatically select best
algorithm number trials run for.
5.3 Effects Abstraction: Scaling Problem Size
section investigate effects abstraction problem size increases. measure
size problem cost shortest path start goal position (henceforth
optimal solution cost).
Figures 16 17 show five performance measures plotted bucket averages. data
point, use middle bucket (e.g., 55, 65, . . . ) horizontal coordinate. error bars
indicate standard errors. Overall, results demonstrate abstraction enables PR LRTS
applied larger problems significantly dampening increase convergence travel, convergence planning, convergence memory. advantages come price suboptimality
first-move lag. former clearly increases abstraction lookahead small (Figure 16)
virtually bucket-independent. lookahead = 9 (Figure 17) draws curves together
deeper lookahead diminishes effects abstraction suboptimality (cf. Figure 36).
First-move lag virtually bucket-independent except case = 9 abstraction levels
3 4 (Figure 17). There, first-move lag capped problems lower buckets goal
seen start state higher levels abstraction. Consequently, LRTS computes
abstract path shorter nine moves. leads smaller corridor less work
A* refining path. Consequently, first-move lag reduced. problems become
larger, LRTS room compute full nine-move abstract path first-move lag increases.
abstraction level 3 phenomenon takes place bucket 85 seeing goal state
start state frequent enough make impact. happens abstraction level
4 proximity abstract goal continues cut search short even largest problems.
Finally, observe minute decrease first-move lag larger problems. appears
due fact problems higher buckets tend start state located cluttered
region map (so optimal solution cost necessarily higher). Walls reduce number
states touched agent first move reduce first-move lag.
69

fiB ULITKO , TURTEVANT, L U , & YAU

4

5

x 10

4
Convergence Planning

Convergence Travel

5
4
3
2
1
0

2000

400

3

300

2

1

0

55 65 75 85 95
Optimal Solution Cost

x 10

FirstMove Lag

6

55 65 75 85 95
Optimal Solution Cost

200

100

0

55 65 75 85 95
Optimal Solution Cost

30

1500

Suboptimality (%)

Convergence Memory

L=0

25

1000

500

L=1
L=2

20

L=3

15

L=4

10
5

0

0

55 65 75 85 95
Optimal Solution Cost

55 65 75 85 95
Optimal Solution Cost

Figure 16: Scaling up. curve shows bucketed means LRTSL (1, 1.0, ). Error bars indicate standard errors small see data points.

6. Theoretical Analysis
PR LRTS subsumes several known algorithms abstraction used. Clearly, LRTS (Bulitko & Lee, 2006) special case PR LRTS abstraction used. LRTS subsumes generalizes several real-time search algorithms including LRTA* (Korf, 1990), weighted
LRTA* (Shimbo & Ishida, 2003), -Trap (Bulitko, 2004) SLA*/SLA*T (Shue & Zamani, 1993;
Shue et al., 2001).
Theorem 6.1 (real-time operation) heuristic search problem, LRTS` (d, , ) amount
planning per action constant-bounded. constant depends constant control
parameters N, (0, 1], [0, ] independent problems number states.
first prove auxiliary lemma.
Lemma 6.1 (downward refinement property) abstract path p = (sa , . . . , sb ), two
children ends connected path lying entirely corridor induced p. means
abstract path refined within corridor formed children. Formally:
1 k ` p = (sa , . . . , sb ) [p (S(k), E(k)) =
s0a children(s1 ) s0b children(sm )
p0 = (s0a , . . . , s0b ) [p0 (S(k 1), E(k 1)) & s0 p0 [s0 sp children(s)]]].
70

(6.1)

fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCH

5

4000

2000

6000
5000

6

4

2

0

0

200

6

55 65 75 85 95
Optimal Solution Cost

x 10

FirstMove Lag

6000

8
Convergence Planning

Convergence Travel

8000

4000
3000
2000

55 65 75 85 95
Optimal Solution Cost

1000

55 65 75 85 95
Optimal Solution Cost

L=1

150

100

50

0

55 65 75 85 95
Optimal Solution Cost

Suboptimality (%)

Convergence Memory

L=0

5

L=2
L=3

4

L=4

3

2

55 65 75 85 95
Optimal Solution Cost

Figure 17: Scaling up. curve shows bucketed means LRTSL (9, 0.4, ). Error bars indicate standard errors small see data points.
Proof. proof induction number edges abstract path. base case 0.
means two children single abstract state connected path lies entirely
set children abstract state. holds due Property 7.
Suppose statement holds abstract paths length j. show
holds abstract paths length j+1. Consider arbitrary abstract path p (S(k), E(k)), k >
0 j + 1 edges. represent p (s1 , . . . , sj+1 , sj+2 ). Consider arbitrary children
s01 children(s1 ) s0j+2 children(sj+2 ). need show path p0 (S(k
1), E(k 1)) lies entirely union children states p (let us denote
Cp ). Let s0j+1 arbitrary child state sj+1 . Since s1 sj+1 j edges apart,
inductive supposition, path s01 s0j+1 lies entirely Cp . left
show s0j+1 s0j+2 connected within Cp . s0j+1 s0j+2 parent,
Property 7 guarantees connected. different parents, Property 6 provides
guarantee. Either way, induction step completed.
prove Theorem 6.1.
Proof. abstract level `, LRTS(d, , ) considers bd abstract states
algorithm design (cf. Section 2.2), b maximum degree state. assumed earlier
paper, maximum degree state depend number states. resulting
abstract path longer abstract edges induces corridor ground level. corridor
consists ground-level states abstract abstract states path. size corridor
71

fiB ULITKO , TURTEVANT, L U , & YAU

upper-bounded number edges path (at d) multiplied maximum number
ground-level children abstract state level `. latter upper-bounded constant
independent number ground-level states due Property 4. A* running corridor
constant-bounded size takes constant-bounded time. Finally, abstraction repair O(`) `
independent graph size (Appendix A.2).
Completeness defined ability reach goal state every trial. prove completeness LRTS` (d, , ) based following reasoning. Recall LRTS` (d, , ) uses
LRTS algorithm build abstract path level `. uses corridor-restricted A*
ground level refine abstract path sequence ground-level edges. Due Property 7
Section 4.2, A* always able find path ground-level states sc sg
lie within corridor C time execution gets line 9 Figure 6. Due exploration
process, agents model search graph may different graph actually
reality. Consequently, path found A* may contain ground-level edge agent believes
exist reality not. following lemma demonstrates execution failure
possible finite number times given search graph:
Lemma 6.2 finite number path execution failures trial.
Proof. contradiction: suppose infinite number failures. failure due
discovery least one new blocked edge vertex ground-level graph.
infinitely many blocked edges vertices finite graph.
direct corollary lemma trial, moment time
graph discoveries made trial. Therefore, executing A*s path indeed allow
agent follow abstract path actual map.
Lemma 6.3 LRTS complete abstract graph.
Proof. First, show abstract graph satisfies properties LRTS shown
complete (Theorem 7.5, Bulitko & Lee, 2006). is, abstract graph finite, action
reversible, self-loops, actions positive cost, goal state reachable
every state. graph also stationary deterministically traversible (p.122, Bulitko
& Lee, 2006). Due abstraction mechanism requirements Section 4.2, properties listed
satisfied clique abstraction mechanism long ground-level graph satisfies
properties well (which require Section 2). Thus, LRTS running abstract graph
ground graph complete.
PR LRTS, however, LRTS abstract graph execute actions. Instead,
current (abstract) state computed abstract parent agents current ground-level state.
Therefore, critical question whether agent able find ground-level path current
state ground-level state corresponding end abstract path computed line 6
Figure 6. failure would mean corridor computed line 8 Figure 6
used refine path contain ground-level path sc sg . Due downward
refinement property (Lemma 6.1), due graph discovery.
According Lemma 6.2, finite number failures, A* algorithm operating
ground level guaranteed find path reach end abstract path computed LRTS.
Thus, LRTS effective ability execute abstract actions. Putting results
72

fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCH

together, conclude valid d, , parameters, LRTS abstract graph finds
goal every trial.
two lemmas lead directly following statement.
Theorem 6.2 LRTS` (d, , ) complete.
Proof. follows directly Lemma 6.2 Lemma 6.3.
Theorem 6.3 LRTS` (d, , ) fixed tie-breaking converges final solution finite
number trials. subsequent trials, update search graph model heuristic
follows path.
Proof. Follows Lemma 6.2 Theorem 7.6 (Bulitko & Lee, 2006) way
Lemma 6.3 Theorem 6.2 proved above.
Theoretical results suboptimality found Appendix B.2

7. Related Research
Existing heuristic search methods situated methods divided two categories: full
search real-time search. Full-search algorithms form entire solution given current
knowledge search graph. contrast, real-time search plans small segment (frequently
first action) solution executes right away. Due local nature planning,
real-time search algorithms need update heuristic function avoid getting stuck local
minima heuristic function.
7.1 Full Search
common full-search algorithm version A* (Hart et al., 1968) called Local Repair A* (Stout,
1996). it, full search conducted agents current state goal state free space
assumption. agent executes computed path either destination reached
path becomes invalid (e.g., previously unknown wall blocks way). latter case, agent
replans current position goal. Local Repair A* suffers two problems. First,
searches shortest solution and, general search problem, may end expanding number
states exponential solution cost due inaccuracies heuristic function (Pearl, 1984).
Second, re-planning episodes re-use results previous search.
first problem addressed suboptimal versions A* frequently implemented
via weighting heuristic function (Pohl, 1970, 1973). weighted A* (WA*) usually finds
longer solution less time. suboptimal solution found, improved upon
conducting additional searches. done re-using open list successive
searches (Hansen, Zilberstein, & Danilchenko, 1997; Likhachev et al., 2004; Hansen & Zhou, 2007)
re-running A* tunnel induced suboptimal solution (Furcy, 2006). later case,
beam search backtracking used place weighted A* (Furcy & Koenig, 2005).
second problem addressed incremental search methods D* (Stenz, 1995), D*
Lite (Koenig & Likhachev, 2002a) LPA* (Koenig & Likhachev, 2002b). algorithms reuse
information previous search, thus speeding subsequent replanning episodes.
73

fiB ULITKO , TURTEVANT, L U , & YAU

algorithms, full path computed first move executed
agent. Consequently, planning time per move constant-bounded increases
problem size. Thus, agent-centered full search real-time.
7.2 Learning Real-time Search
Since seminal work LRTA* (Korf, 1990), research field learning real-time heuristic
search flourished resulting twenty algorithms numerous variations.
described following four attributes:
local search space set states whose heuristic values accessed planning
stage. two common choices full-width limited-depth lookahead (Korf, 1990; Shimbo &
Ishida, 2003; Shue & Zamani, 1993; Shue et al., 2001; Furcy & Koenig, 2000; Hernandez &
Meseguer, 2005a, 2005b; Sigmundarson & Bjornsson, 2006; Rayner, Davison, Bulitko, Anderson,
& Lu, 2007) A*-shaped lookahead (Koenig, 2004; Koenig & Likhachev, 2006). Additional
choices decision-theoretic based shaping (Russell & Wefald, 1991) dynamic lookahead
depth-selection (Bulitko, 2004; Lustrek & Bulitko, 2006).
local learning space set states whose heuristic values updated. Common
choices are: current state (Korf, 1990; Shimbo & Ishida, 2003; Shue & Zamani, 1993; Shue
et al., 2001; Furcy & Koenig, 2000; Bulitko, 2004), states within local search space (Koenig,
2004; Koenig & Likhachev, 2006) previously visited states neighbors (Hernandez &
Meseguer, 2005a, 2005b; Sigmundarson & Bjornsson, 2006; Rayner et al., 2007).
learning rule used update heuristic values states learning space.
common choices dynamic programming mini-min (Korf, 1990; Shue & Zamani, 1993; Shue
et al., 2001; Hernandez & Meseguer, 2005a, 2005b; Sigmundarson & Bjornsson, 2006; Rayner
et al., 2007), weighted versions (Shimbo & Ishida, 2003), max mins (Bulitko, 2004), modified Dijkstras algorithm (Koenig, 2004), updates respect shortest path
current state best-looking state frontier local search space (Koenig & Likhachev,
2006). Additionally, several algorithms learn one heuristic function (Russell & Wefald,
1991; Furcy & Koenig, 2000; Shimbo & Ishida, 2003).
Control strategy decides move following planning learning phases. Commonly
used strategies include: first move optimal path promising frontier state (Korf,
1990; Furcy & Koenig, 2000; Hernandez & Meseguer, 2005a, 2005b), entire path (Bulitko,
2004), backtracking moves (Shue & Zamani, 1993; Shue et al., 2001; Bulitko, 2004; Sigmundarson & Bjornsson, 2006).
Given multitude proposed algorithms, unification efforts undertaken. particular, Bulitko Lee (2006) suggested framework, called Learning Real Time Search (LRTS),
combine extend LRTA* (Korf, 1990), weighted LRTA* (Shimbo & Ishida, 2003), SLA* (Shue
& Zamani, 1993), SLA*T (Shue et al., 2001), large extent, -Trap (Bulitko, 2004).
dimensions described above, LRTS operates follows. uses full-width fixed-depth local search
space transposition tables prune duplicate states. LRTS uses max mins learning rule
update heuristic value current state (its local learning space). control strategy moves
agent promising frontier state cumulative volume heuristic function updates
trial user-specified quota backtracks previous state otherwise (Section 2.2).
Within LRTS, unification several algorithms accomplished implementing
several methods local search space selection, learning rule, control strategy.
74

fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCH

methods engaged run-time via user-specified parameters. resulting parameter space contained original algorithms plus numerous new combinations, enabling tuning
performance according specific problem objective function particular application.
demonstration, Bulitko et al. (2005) tuned LRTS ten maps computer game Baldurs
Gate (BioWare Corp., 1998) achieved convergence speed two orders magnitude
faster LRTA*, finding paths within 3% optimal. time, LRTS
five times faster first move incremental A*. Despite improvements, LRTS
real-time search algorithms converge slowly A* and, visually, may behave unintelligently
repeatedly revisiting dead-ends corners.
7.3 State Abstraction
idea abstraction previously applied full search methods. particular, HPA*
PRA* (Botea et al., 2004; Sturtevant & Buro, 2005) use abstraction speed A* search: instead
running A* lowest-level graph, instead run A* smaller abstract graph. PRA*
computes abstract path refines similar manner PR LRTS. However, PRA*
dynamically chooses abstract level use, computes path intermediate level
(i.e., pass-through levels). PRA* also widens corridors decrease suboptimality
cost lower speed.
HPA* abstracts map using large regions, selects connection points (gates) neighboring regions. gates region, optimal paths gates pre-computed off-line
using A* stored table. means refining abstract path (i.e., sequence
region gates) done simply concatenating stored optimal paths. Smoothing applied
post-processing step decrease suboptimality resulting path.
algorithms based ideas presented Holte et al. (1996), used
abstraction mechanism similar manner use clique abstraction. method,
STAR abstraction, also described radius abstraction. is, state selected,
aggregated together states fixed radius original state. Holte et al. (1996)s
work initially gain wide acclaim, because, time, little interest problems
small enough fit memory. Motivating applications, pathfinding computer
games, resulted resurgence interest techniques.
class algorithms first plan abstract path, refined traversable path.
Another approach build abstraction directly used planning realworld. includes methods like framed quad-trees (Yahja, Stentz, Singh, & Brummit, 1998),
efficiently represent sparse maps. Quad-trees multi-resolution representation,
areas map represented high-resolution, others represented lower resolution.
abstraction differs abstractions like clique abstraction applied
once; applications would produce lower resolution maps, although clique abstraction
could applied graph implied framed quad-tree representation.
One common use abstraction provide better heuristics. Holte, Perez, Zimmer,
MacDonald (1995) used result abstract search provide accurate heuristic lowlevel search performed path refinement. Similarly, pattern databases abstractions
built solved off-line. abstract solution costs stored used search
heuristic function (Culberson & Schaeffer, 1996; Felner, Zahavi, Schaeffer, & Holte, 2005).
75

fiB ULITKO , TURTEVANT, L U , & YAU

PR LRTS presented paper first real-time heuristic search algorithm use
automatically-built state abstraction. Path-refinement algorithms listed conduct full-search
therefore cannot guarantee constant-bounded planning time agents moves.

8. Limitations Future Work
results presented paper open several directions future research. First, PR LRTS
able operate wide class homomorphic graph abstraction techniques. Thus, would
interest investigate extent effects graph abstraction real-time search
presented paper specific clique abstraction mechanism pathfinding domain.
Recent work shown clique abstraction parameters well-tuned minimize
work done traditional path planning (Sturtevant & Jansen, 2007). experiments pathfinding
suggested clique abstraction well-suited map abstraction represents key
properties underlying space well. particular, branching factor stays roughly constant
higher levels abstraction. empty map, instance, number nodes level
abstraction reduced factor four clique abstraction, branching factor
every state stay same. (Corner states 3 neighbors, edge states 5
neighbors, middle states 8 neighbors.) may case domains.
instance, sliding tile puzzle maximum branching factor abstract states quickly increases
abstraction level. result, corridor derived abstract path PR LRTS becomes
excessively wide effectively constrain A* search ground level. conjecture
algorithms use homomorphic abstractions effective domain abstraction
preserves average, minimum, maximum branching factor original problem
level abstraction. Clique abstraction, likely work well three-dimensional pathfinding,
problem-specific mechanisms would needed permutation-type puzzles. area
open research provide abstraction.
Second, PR LRTS uses abstract solution restrict search original ground-level
graph. interesting combine complementary approach using cost
optimal solution abstract problem heuristic estimate original search graph
context real-time search. particular, looking effective ways propagating heuristic
values higher lower levels abstraction hierarchy.
Third, state aggregation one way generalizing learning. Future research consider
combining function approximation heuristic function, commonly practiced
large-scale applications reinforcement learning.
Fourth, presently investigating applications PR LRTS dynamic environments.
particular, studying extent savings memory gained learning higher
abstraction level afford application PR LRTS moving target search. existing algorithm (Ishida & Korf, 1991) requires learning number heuristic values quadratic size
map. prohibitive case commercial game maps.
Finally, presently extending graph abstraction method presented paper
stochastic environments formulated Markov Decision Processes.
76

fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCH

9. Conclusions
Situated agents real-time environments expected act quickly efficiently learning
initially unknown environment. Response time learning speed antagonistic performance
measures planning leads better actions and, consequently, faster convergence longer
response time. Full search algorithms, local repair A*, converge quickly
constant-bounded planning time per move. Real-time heuristic search algorithms constantbounded planning times per move, learn slowly.
paper, attempted combine best approaches suggest hybrid algorithm, PR LRTS, learns heuristic function smaller abstract space uses corridorrestricted A* generate partial ground-level path. large-scale empirical study, PR LRTS
found dominate virtually tested algorithms use abstraction respect
several performance measure pairs. combination learning planning brings real-time performance much larger search spaces, substantially benefiting applications pathfinding
robotics video games.

Acknowledgments
Funding provided National Science Engineering Research Council Canada,
Alberta Ingenuity Centre Machine Learning, Informatics Circle Research Excellence,
University Alberta. appreciate input David Thue, Rich Korf, Rob Holte, Csaba
Szepesvari, David Furcy, Adi Botea. Special thanks go Jonathan Schaeffer anonymous reviewers whose detailed comments greatly improved paper. research enabled use WestGrid computing resources, funded part Canada Foundation Innovation, Alberta Innovation Science, BC Advanced Education, participating
research institutions. particular, would like acknowledge help Roman Baranowski,
Masao Fujinaga, Doug Phillips.

Appendix A. Clique Abstraction
describe clique abstraction mechanism several stages. First, present
algorithm building initial abstraction hierarchy using free space assumption.
describe repair procedure updates abstract graphs agent explores environment.
Finally, consider suboptimality solution caused abstraction examples derive worstcase upper bound.
A.1 Building Initial Abstraction Hierarchy
pseudo-code building initial clique abstraction Figure 18. abstract procedure
(lines 5 14) takes set states level maps single abstract state level
+ 1. involves creating new abstract state storing parent child links. If, line 20,
new abstract edge added one already exists, add extra edge increase
count associated edge. counts used facilitate abstraction repair described
next section.
general, clique-finding NP-complete problem (Garey & Johnson, 1990). However,
eight-connected two-dimensional grid-based search graphs largest possible clique size 4.
77

fiB ULITKO , TURTEVANT, L U , & YAU

graph CliqueAbstraction(graph g)
1
initialize graph g 0
2
= 4...2
3
unabstracted state g
4
part i-clique c
5
g 0 g 0 {abstract(c)}
6
end
7
end
8
end
9
10 unabstracted state g
11
degree(s) = 1
12
set parent(s) parent(neighbor(s))
13
else
14
g 0 g 0 {abstract(n)}
15
end
16 end
17
18 edge e = (v1 , v2 )
19
parent(v1 ) 6= parent(v2 )
20
g 0 g 0 {(parent(v1 ), parent(v2 ))}
21
end
22 end
23 return g 0
Figure 18: Building initial clique abstraction.
degree
state also constant-bounded (as required Section 2) time per

clique constant (i.e., 83 state accesses check eight neighbors find 3 form 4-clique
together current state). Thus, total running time single clique abstraction
O(|S|), |S| number states original search graph. abstraction procedure
reduces graph size least constant factor greater one, total cost abstracting
graph also O(|S|) cost additional abstraction step reduced exponentially.
A.2 Repairing Abstraction Hierarchy
agent explores environment, may find edges states blocked. cases,
remove corresponding states edges model need propagate changes
abstract graphs abstraction hierarchy. demonstrate repair code Figure 19
example also shows repair procedure amortized constant-time cost.
Figure 20 remove edges Level 0 graph bottom left figure. right
side figure shows full abstract graph edges removed. level
show portion abstract graph assume states edges graph.
shown schematically Level 0 gray.
Level 0 four states marked form abstract state level 1. also
true states marked A. joined edge level 1, abstracted
78

fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCH

RemoveEdge(edge e, level l, graph g)
1
decrease edge count e
2
child edge count e 6= 0 return end
3
e = (v1 , v2 )
4
remove e g[l]
5
parent(v1 ) = parent(v2 )
6
AddToRepairQ(parent(v1 ))
7
else
8
RemoveEdge((parent(v1 ), parent(v2 )), l + 1, g)
9
end
RemoveState(state s, level l, graph g)
10 edge e incident
11
RemoveEdge(e, l, g)
12 end
13 remove g[l]
14 AddToRepairQ(parent(s))
HandleRepairQ()
15 RepairQ empty
16
remove state lowest level l g
17
abstraction properties hold
18
AddToRepairQ(parent(s))
19
split state s1 . . . sn abstraction properties holds si
20
= 1 . . . n either:
21
1. Merge si existing abstract state
22
2. Extract si new abstract state
23
end
24
end
25 end
Figure 19: Repairing abstraction hierarchy.
four edges level 0. remove edges level 0 graph using RemoveEdge()
procedure Figure 19, first three removals simply decrement count associated
abstract edge (line 1-2). fourth removal, however, result removing
edge (line 4). removal recursively propagated (line 8)
abstraction hierarchy, change abstract graph level 2, edge count
decremented.
22 edges must removed perform full split top bottom
states level 0 Figure 20. Removing first edge E E level 2 requires
removal 10 underlying edges level 0 correspond 4 edges level 1 (all edges
A, B, B).
State repair first occurs remove edge E E. case E E
parent, G added repair queue (line 5 6). repair queue processed
set removal operations. edge E E removed, children G level 3
longer form clique. Thus, G must split two states H H. Initially states
79

fiB ULITKO , TURTEVANT, L U , & YAU

removal / repair
Level 3

removal / repair
H'

Level 3

split

split

G

E'

H
F'

E'

Level 2

Level 1

Level 2

split

E

F

B'

C'

D'



B

C



E

Level 1

split

E

F

F

A'

B'

C'

D'



B

C



split

E

(10 level 0 edges)

A'

F

A'

Level 0

Level 0

split



split

(4 level 1 edges)

A'

F'

B

C



split



B

C



Figure 20: example repairing clique abstraction.

edge them, edge removed last edges level
0 removed. repair code work many abstraction mechanisms. Specifically,
check abstract states children still form clique (line 17) changed check
corresponding property non-clique abstraction.
example, amortized cost abstraction repair constant. Imagine agent traversing graph level 0 left right discovering wall splitting top bottom rows
states (as shown split label figure). step graph sensed
agent edges removed level 0 graph. Removing three edges (A, A), (A, B),
(B, A) level 1 requires removing six edges level 0. Similarly, removing three edges
(E, E), (E, F), (F, E) requires removing 12 edges level 0. general, agent traveling
level 0 must move twice far (or remove twice many states) repair required
additional level abstraction. Thus, number abstraction levels repaired traversing n
ground edges, is:
n
n
n
n
n
1 + 2 + 3 + 4 + + log2 (n) = O(n).
2
4
8
16
n

Consequently, example, amortized repair cost per edge traveled O(1). general,
worst-case complexity repair O(`) and, PR LRTS, ` constant independent graph size.
repairs propagated abstraction hierarchy (line 18 Figure 19).
80

fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCH

Appendix B. Abstraction Properties
Abstraction properties informally introduced illustrated example Section 4.2.
appendix makes presentation mathematically precise. section, variables i, k, run
natural numbers including 0.
Property 1. agent using abstraction maintains hierarchy ` abstract search graphs addition model environment. abstract graphs search graph sense
Section 2. following denote abstract search graph level i, 1 `
(G(i), c(i), s0 (i), sg (i), h0 (i)). before, G(i) = (S(i), E(i)).
Property 2. state search graph level n < ` unique parent state s0 level
n + 1 abstract search graph. formally:


S(k), k < ` !s0 S(k + 1) parent(s) = s0 .

(B.1)

Property 3. state search graph level m, 0 < `, least one child
state s0 level 1. notation children(s) represents set children state s. Thus,
s0 children(s):


S(k), k > 0 s0 S(k 1) s0 children(s) .

(B.2)

Property 4. Given heuristic search problem S, instance problem, number
children abstract state upper-bounded constant independent number states:
S, search problem ((S, E), c, s0 , sg , h0 ) i, 0 < ` S(i)
[| children(s)| < m] .

(B.3)

Property 5. (Graph homomorphism) Every edge (s1 , s2 ) E(k), k < n either corresponding abstract edge level k + 1 s1 s2 abstract state:
s1 , s2 S(k), k < `
[(s1 , s2 ) E(k) = (parent(s1 ), parent(s2 )) E(k + 1) parent(s1 ) = parent(s2 ))] .(B.4)

Property 6. edge exists abstract states s1 s2 edge
child s1 child s2 :
s1 , s2 S(k), k > 0


0
0
(s1 , s2 ) E(k) = s1 children(s1 ) s2 children(s2 ) (s01 , s02 ) E(k 1) .
last property, need following definition.
81

(B.5)

fiB ULITKO , TURTEVANT, L U , & YAU

Definition B.1 path p space (S(k), E(k)), 0 k ` defined ordered sequence
states S(k) whose two sequential states constitute valid edge E(k). Formally, p
path (S(k), E(k)) if:
s1 , . . . , sm S(k) [p = (s1 , . . . , sm ) & i, 1 [(si , si+1 ) E(k)]] .

(B.6)

use notation p (S(k), E(k)) indicate vertices edges path p
sets S(k), E(k) respectively. notation p indicates state path p.
Property 7 two children abstract state connected path whose states
children abstract state:
S(k), 0 < k ` s01 , s02 children(s) p = (s01 , . . . , s02 ) (S(k 1), E(k 1)). (B.7)
B.1 Abstraction-induced Suboptimality: Examples
Abstraction cause suboptimality. Figure 21 left, refining abstract path. Solid
arrows indicate abstract path. Ground-level path shown thinner dashed arrows.
agents position shown goals position G. white cells form corridor
induced abstract path. optimal path shown right.

Figure 21: Abstraction causes suboptimality.
Partial path refinement increase suboptimality. Refining entire abstract path (Figure 22,
left) yield shorter paths refining segment abstract path (Figure 22, right). Solid
arrows indicate abstract path. ground-level path shown thinner dashed arrows.
agents position shown goals position G.
B.2 Abstraction-induced Suboptimality: Upper Bound
two factors contribute suboptimality paths returned PR LRTS. first
factor parameters chosen LRTS, weighted allow suboptimality. effect
analyzed literature (Bulitko & Lee, 2006). analyze suboptimality
introduced abstraction. simplicity analysis consider uniform abstraction
level k states abstracted parent next level abstraction. assumption simplifies analysis also enables application analysis non-clique abstraction
mechanism maintain property. proving result, introduce two simple lemmas:
82

fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCH

Figure 22: Partial path refinement increases suboptimality.
Lemma B.1 Suppose abstract edges cost. lowest-cost path p states
B j edges lowest-cost abstract path abstract parents A0 B 0
j abstract edges.
Proof. prove contradiction. Suppose lowest-cost abstract path q A0 B 0
> j edges. consider abstract images states p. either abstract
edge coincide due Property 5. Thus form abstract path p0 A0
B 0 due Property 2 j edges. Since assumption theorem
abstract edges cost, lowest-cost path q A0 B 0 must higher
cost path p0 A0 B 0 (Figure 23, right). results contradiction.
Lemma B.2 path created refining abstract edge level ` cannot longer O(k ` )
level 0.
Proof. demonstrated right portion Figure 24. assume every abstract state
exactly k children. So, level ` abstraction state cannot k `
children. Assuming path cannot visit single node once, refined path
therefore O(k ` ) edges.
present main result:
Theorem B.1 Assume every abstract state k children ground level edge costs
[1, e]. level ` abstraction, cost path created refining abstract path
level ` level 0 (the original space) O(ek ` ) times costly optimal path
abstract edges happen uniform cost O(e2 k 2` ) abstract edges costs [1, ek ` ]
(from Lemma B.2).
Proof. First, deal case edges abstract graph uniform cost. Consider
two level-0 states B abstract level-` states A0 , B 0 (left side Figure 23). lowestcost path p B j edges lowest-cost abstract path A0 B 0
j abstract edges Lemma B.1.
83

fiB ULITKO , TURTEVANT, L U , & YAU

path p', j edges

path q, > j edges

A'

B'



B

A'

path p, j edges

B'

path p', j edges

Figure 23: Proving lowest-cost abstract path j edges.
Suppose agent state seeking go state B. agent first computes
lowest-cost abstract path A0 B 0 . worst case, abstract path j edges.
Suppose two abstract paths A0 B 0 : t01 t02 shown Figure 24, left.
j edges and, due uniform abstract edge cost assumption, cost. worst
case scenario, t01 refined lowest-cost path t1 B t02 refined
highest-cost path t2 B. analyzing cost ratio t1 t2 arrive
upper bound theorem.
1 edge

path t'2 : j edges

A'

level !

B'

level 0
path t'1 : j edges

k ! edges

Figure 24: Paths t01 , t02 cost yet refine shortest longest paths.
Due Lemma B.2, one abstract edge level ` refined k ` level-0 edges.
worst case, t1 j edges t2 jk ` 1 edges (the result abstracting ` levels k `
states single state). Furthermore, edges t1 cost 1 leading total cost t1
j. edges t2 cost e leading total cost t2 e(jk ` 1). Thus, ratio
t2 t1 costs higher ek ` proves first statement theorem.
case abstract edges non-uniform costs [1, ek ` ], consider two abstract paths t01 t02 A0 B 0 . cost ejk ` , highest possible
cost level-` image cost-j ground path. path t01 , abstract cost might overestimated
j abstract edges, cost ek ` refine level-0 path t1 j edges
cost 1 each. Thus, total cost t1 j lowest possible cost B.
Path t02 cost t01 ejk ` abstract edges, cost 1. Since
abstract edges refined k ` edges level 0, path t02 refined path t2
ejk ` k ` edges, cost e. Consequently, total cost t2
e ejk ` k ` = je2 k 2` . Thus, ratio costs t1 t2 e2 k 2` .
84

fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCH

t'1
t'1


A'

B



B

B'

w
c

c
t'2

w

w

j

w

w

j

Figure 25: grid-based example achieving worst case suboptimality.
worst-case upper bound tight, occurs severely underestimate cost
suboptimal path overestimate cost optimal path. Figure 25 show
happen practice; level-0 map shown left. lowest-cost path (t1 ) states
B straight line cost j. corridors width 1. length corridors,
w, chosen level ` abstraction, states corridor abstract together
single state. map cliques size two (i.e., k = 2 Theorem B.1).
right part Figure 25 shows level-` abstract graph thick lines original map
light gray. abstraction, path t02 A0 B 0 (the abstract parents
B) goes lower part map. path t02 abstract cost 2c + j + w
abstract edges refine w ground-level edges each. Thus, total cost refined path t2
w (2c + j) = 2cw + jw. Path t01 abstract image t1 abstract cost w = k `
j edges, leading total abstract cost jk ` = jw. shown right side
figure highly zigzagged path.
choose c t02 costs much t01 . agent bad luck
choosing refine t02 . make certainty, make cost t01 slightly higher
cost t02 . accomplished setting 2c + j + w jw. here, 2c jw j w
c jw = jk ` = j2` . result, agent chooses refine t02 t2 , cost
2cw + jw = 2j2` 2` + j2` = O(j22` ). ratio cost t1 22` ,
corresponds bound theorem k = 2, e = 1.
experimental results demonstrate large suboptimality occur practice. illustration, consider histogram suboptimality values 3000 problems
parametrizations PR LRTS Figure 26.
suboptimality become practical concern, one use ideas HPA* (Botea
et al., 2004), optimal path costs within regions pre-computed cached. precomputation help prevent severe over- under-estimation abstract path costs
assumed worst-case analysis Theorem B.1.

Appendix C. Maps Used Empirical Study
four additional maps shown Figure 27.
85

fiB ULITKO , TURTEVANT, L U , & YAU

1

Percentage problems

10

0

10

1

10

2

10

3

10

20

40

60
80
Suboptimality (%)

100

120

Figure 26: Histogram suboptimality experiments.

Figure 27: four additional maps used experiments.

Appendix D. Dominance Average: Plots
Six plots corresponding entries Table 2 shown Figures 28, 29.
86

fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCH

A*
LRTS4(9,0.2,)
(9,0.2,100)
(9,0.4,)
(9,0.4,100)
LRTS
(9,0.2,100)
LRTS33(9,0.2,)
(9,0.4,)
(9,0.4,100)

Dominated
Nondominated

LRTS2(9,0.2,)

Firstmove Lag (states touched)

LRTS
(5,0.2,)
LRTS
(5,0.4,)
(5,0.4,100)
33
3

10

LRTS
LRTS33(3,0.2,)
(3,0.4,)
LRTS (1,0.4,)
4

LRTS3(1,0.4,)
2

10

LRTS2(1,0.4,)

LRTS2(1,0.8,)
LRTS1(1,0.4,)

LRTS1(1,0.8,)

1

10

LRTS(1,0.4,)
3

4

10

10
Convergence Travel

A*

Dominated
Nondominated

LRTS2(9,0.2,)
LRTS2(9,0.2,100)
LRTS (5,0.2,)
3
LRTS (5,0.2,100)
3
LRTS
LRTS44(3,0.2,)
(3,0.4,)

3

Firstmove Lag (seconds)

10

LRTSLRTS
(3,0.2,)
(5,0.4,)
3
2
LRTS4(1,0.4,)
LRTS4(1,0.2,)
LRTS3(1,0.4,)
LRTS (1,0.4,100)
3

4

LRTS
LRTS
(1,0.4,)
(1,0.2,) LRTS (1,0.4,100)
2 2
2

10

LRTS
(1,0.4,)
LRTS
(1,0.2,)
1
1

LRTS(1,0.4,)
3

4

10

10
Convergence Travel

A*

Dominated
Nondominated
3

Firstmove Lag (seconds)

10

LRTS (3,0.2,)
3

LRTS3(1,0.4,)
LRTS (1,0.4,100)
3

4

10

LRTS
LRTS
(1,0.4,)
(1,0.2,) LRTS (1,0.4,100)
2 2
2
LRTS
LRTS11(1,0.4,)
(1,0.2,)

LRTS(1,0.4,)
1

10
Convergence Planning (seconds)

0

10

Figure 28: Dominance several pairs performance measures. Part 1.

Appendix E. Dominance Individual Problems
Section 5.1 introduced concept dominance demonstrated PR LRTS abstraction dominates extreme search algorithms use abstraction. analysis done using cost values averaged 3000 problems. section consider
87

fiB ULITKO , TURTEVANT, L U , & YAU

A*
LRTS4(9,0.2,100)
(9,0.2,)
LRTS (9,0.2,)
(9,0.2,100)
LRTS43(5,0.2,)
(5,0.2,100)
(5,0.4,100)
(5,0.4,)

Dominated
Nondominated

4

Firstmove Lag (states touched)

LRTS3(5,0.2,)
(5,0.2,100)
(5,0.4,)
(5,0.4,100)
3

10

LRTS3(3,0.2,)
(3,0.4,)
LRTS4(1,0.2,)
(1,0.2,100)
(1,0.4,)
(1,0.4,100)
4

LRTS
(1,0.2,100)
LRTS33(1,0.2,)
(1,0.4,)
2

10

LRTS
LRTS22(1,0.2,)
(1,0.4,)

LRTS
(1,0.2,)
LRTS
(1,0.4,)
11

1

10

LRTS(1,0.2,)

0

500

1000

1500

Convergence Memory
A*
LRTS (5,0.2,100)
(5,0.4,!)
4

Dominated
Non!dominated

LRTS3(5,0.2,100)
LRTS4(3,0.2,!)
(3,0.2,100)
LRTS
LRTS4 (3,0.4,!)
4

!3

First!move Lag (seconds)

10

LRTS3(3,0.2,!)
LRTS4(1,0.2,!)
(1,0.2,100)
(1,0.4,100)
4
LRTS
(1,0.2,100)
LRTS333(1,0.2,!)
(1,0.4,100)

!4

LRTS
LRTS22(1,0.2,!)
(1,0.4,100)

10

LRTS1(1,0.2,!)

LRTS(1,0.2,!)
LRTS(1,0.4,!)

0

500

1000

1500

Convergence Memory

Dominated
Nondominated

25
LRTS3(1,0.4,)

Suboptimality (%)

20

LRTS2(1,0.4,)

15

LRTS3(3,0.2,)
LRTS
LRTS
(3,0.4,)
(3,0.4,100)
33

10

LRTS3(5,0.2,)
LRTS3(5,0.4,)
(5,0.4,100)
LRTS
LRTS33(5,0.8,)
(5,0.8,100)

5

0

A*
4

10

5

10
Convergence Planning (states touched)

6

10

Figure 29: Dominance several pairs performance measures. Part 2.
dominance individual problems. Due high variance problems difficulty,
report percentages problems dominance achieved. every pair algorithms,
measure percentage problems first algorithm dominates second.
measure percentage problems second algorithm dominates first. ratio
two percentages call dominance ratio.
88

fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCH

4

10

3

FirstMove Lag

10

2

10

1

10

0

10
2
10

3

4

10

5

10

10

Convergence Travel
4

x 10

Convergence Travel

FirstMove Lag
700

14

600

12
LRTS_3(1,1.0,)

LRTS_3(1,1.0,)

500
10
8
6
4
2

400
300
200
100

5
10
LRTS(5,0.8,)

15

200
400
LRTS(5,0.8,)

4

x 10

600

Figure 30: Top: LRTS3 (1, 1.0, ) shown filled star; LRTS(5, 0.8, ) shown hollow
star. Bottom left: convergence travel. Bottom right: first-move lag.
Table 4: Statistics two algorithms Figure 30.
Algorithm

Convergence travel

First-move lag



LRTS3(1,1.0,!)

72.83%

97.27%

70.97%

LRTS(5,0.8,!)

27.17%

2.67%

0.87%

Dominance ratio
81.89

top Figure 30 see reproduction corresponding plot Figure 28
two particular algorithms marked stars. filled star LRTS3 (1, 1.0, ) uses three
levels abstraction. hollow star LRTS(5, 0.8, ) operates entirely ground level.
Statistics reported Table 4. bottom left figure shows advantages PR LRTS
respect convergence travel. approximately 73% 3000 problems, PR LRTS
travels less LRTS convergence (points 45-degree line). respect
first-move lag, PR LRTS superior LRTS 97% problems (bottom right
figure). Finally, 71% problems PR LRTS dominates LRTS (i.e., outperforms
89

fiB ULITKO , TURTEVANT, L U , & YAU

25

Suboptimality (%)

20
15
10
5
0
3
10

6

4

5

10

10
Convergence Planning

6

Convergence Planning

x 10

7

10

10

Suboptimality (%)

6
80

4

LRTS_3(5,0.8,)

LRTS_3(5,0.8,)

5

3
2
1

1

2
3
4
LRTS(3,0.2,)

5

60

40

20

0

6

0

6

x 10

20

40
60
LRTS(3,0.2,)

80

Figure 31: Top: LRTS3 (5, 0.8, ) shown filled star; LRTS(3, 0.2, ) shown hollow
star. Bottom left: convergence planning. Bottom right: suboptimality.
respect measures). hand, LRTS dominates PR LRTS approximately
1% problems. leads dominance ratio 81.89.
Table 5: Statistics two algorithms Figure 31.
Algorithm

Convergence planning

Suboptimality



LRTS3(5,0.8,!)

80.03%

55.80%

48.97%

LRTS(3,0.2,!)

19.93%

40.97%

12.2%

Dominance ratio
4.01

Similarly, Figure 31 compares two algorithms respect convergence planning suboptimality final solution. top figure, corresponding plot Figure 29
LRTS3 (5, 0.8, ) shown filled star LRTS(3, 0.2, ) shown hollow star. Percent
points domination individual problems found Table 5. plot bottom left
figure shows PR LRTS lower convergence planning cost LRTS 80%
problems. plot bottom right shows suboptimality solutions algorithms
90

fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCH

produced. PR LRTS optimal LRTS 56% time. Finally, PR LRTS
dominates LRTS 49% problems. Domination way (i.e., LRTS dominates
PR LRTS) happens 12.2% problems. leads dominance ratio 4.01.
several factors influence results. First, high variance difficulty
individual problems due distribution five buckets optimal path distance. Consequently, high variance algorithms trade antagonistic performance measures
problems. case large difference mean values,
Figure 30, dominance average supported dominance majority individual problems. Conversely, small difference mean values (e.g., 2.3% suboptimality algorithms
Figure 31) lead overwhelming dominance level individual problems.
extended analysis pairs algorithms displayed Figures 28, 29. convergence travel first-move lag, dominance ratio varies 5.48 values
infinity averaging 534.32 standard error 123.47. convergence planning
suboptimality, dominance ratio varies 0.79 values infinity averaging 5.16 standard error 1.51. Finally, set 181 algorithms tested
study. Therefore, results viewed approximation actual dominance
relationship among algorithms.

Appendix F. Interaction Abstraction LRTS Parameters
Section 5.2 observed general trends influence abstraction five performance measures. abstraction level adds another dimension parameter space LRTS, previously
defined d, , , natural question four parameters interact. order facilitate
comprehensible visualization paper, reduce LRTS parameter space d, ,
d, setting = (i.e., disabling backtracking LRTS). justified two reasons. First,
recent studies (Bulitko & Lee, 2006; Sigmundarson & Bjornsson, 2006) shown effects
backtracking highly domain-specific.
Table 6 gives overview influence abstraction parameters LRTS qualitative level. detailed analysis five performance measures follows.
important note experiments performed set fixed cost paths fixed size
maps. Consequently, map boundary effects observed higher levels abstraction.
detail contribution below.
Table 6: Influence LRTS parameters impact abstraction. cell table represents impact abstraction either amplified (A) diminished (D) increase
. Lower-case indicate minor effect, - indicates effect.
increase






measure / control parameter
convergence travel
first-move lag
convergence planning
convergence memory
suboptimality

increase





Convergence travel: increasing abstraction level generally decreases convergence travel
LRTS learns smaller abstract maps. Independently, increasing lookahead depth LRTS
91

fiB ULITKO , TURTEVANT, L U , & YAU

Convergence Travel
x 10

x 10

Level 2
Level 0
Optimality Weight

4
3
2
1
0
1
0.8
Optimality Weight

4

Difference Convergence Travel
1

4

2

0.8

1.5

1
0.4

9
0.4
0.2

1

3

0.5

5

0.2

Lookahead Depth

1

Convergence Travel

3
5
Lookahead Depth

9

Difference Convergence Travel
2500

1
Level 4
Level 2
Optimality Weight

6000
4000
2000
0
1
0.8
Optimality Weight

2000

0.8

1500
1000
0.4

500

9
0.4
0.2

1

3

5

0.2

Lookahead Depth

1

3
5
Lookahead Depth

9

Figure 32: Convergence travel: impact abstraction function d, . Top two graphs:
LRTS(d, ) vs. LRTS2 (d, ). Bottom two graphs: LRTS2 (d, ) vs. LRTS4 (d, ).
similar effect (Bulitko & Lee, 2006). Convergence travel lower-bounded doubled optimal
cost start goal (as first trial reveal parts map and, consequently,
cannot final). Therefore, decreasing convergence travel via either two mechanisms diminishes
gains mechanism. effect seen Figure 32 noticeable
gap convergence travel abstractions levels 0 2. lookahead 9,
small difference using abstraction levels 2 4. Thus, increasing lookahead
slightly diminishes effect abstraction (hence table). Increasing increases
convergence travel. higher value , gained using abstraction.
increase amplifies advantage abstraction.
First-move lag generally increases abstraction level lookahead depth.
lookahead depth increases, size corridor used A* search increases well. Thus,
increasing amplifies first-move lag due abstraction, PR LRTS must plan within
lookahead space (within LRTS) inside corridor (within A*) (Figure 33).
Deeper lookahead amplifies impact abstraction. simplified analysis below,
assume map obstacle free leads levels abstraction regular grids
(ignoring boundary effects). length path two points (expressed number
actions) is, thus, decreased factor two abstraction level. assumptions,
total number states PR LRTS touches first move (d2 ) abstract graph
92

fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCH

FirstMove Lag

Difference FirstMove Lag
100

1
Level 2
Level 0

200
Optimality Weight

3000
2000
1000
0
1
0.8
Optimality Weight

300

0.8

400
500
600
700
0.4

800

9
0.4
0.2

1

3

900

5

0.2

Lookahead Depth

1

FirstMove Lag

3
5
Lookahead Depth

9

Difference FirstMove Lag
1

500

Level 4
Level 2
Optimality Weight

4000
3000
2000
1000
0
1
0.8
Optimality Weight

0.8
1000

1500
0.4
2000

9
0.4
0.2

1

3

5

0.2

Lookahead Depth

1

3
5
Lookahead Depth

9

Figure 33: First-move lag: impact abstraction function d, . Top two graphs: LRTS(d, )
vs. LRTS2 (d, ). Bottom two graphs: LRTS2 (d, ) vs. LRTS4 (d, ).
(d 2` ) ground graph. latter quantity simply number edges ground
path computed number edges abstract path (d) multiplied reduction factor
2` . Adding abstraction levels increases first-move lag (d 2`+ ). increase
linear function lookahead depth d. Thus, larger values amplify effect adding extra
abstraction levels.
several points glossed simplified analysis. First, reduction
path length always two-fold assumed above. presence walls, higher levels
abstraction less likely locate merge fully-fledged 4-element cliques. Second, boundaries
abstract graph reached LRTS less moves higher abstraction level.
effectively decreases quantity formula size corridor
reduced generous estimate d2` . Finally, feeding A* longer abstract path often improves
performance analyzed previous section (cf. Figure 22). explains
abstraction level 4 deepening lookahead diminishing returns seen Figure 33.
Optimality weight affect number states touched LRTS abstract level.
hand, change cost resulting A* search different abstract path may
computed LRTS. Overall, however, effect first-move lag impact
abstraction inconsequential (Figure 33).
93

fiB ULITKO , TURTEVANT, L U , & YAU

Convergence Planning

6

Difference Convergence Planning

x 10

1

6

x 10

Level 2
Level 0

2
Optimality Weight

3
2
1
0
1
0.8

0.8
1.5

1
0.4

0.5

9

Optimality Weight

0.4
0.2

1

3

5

0.2

Lookahead Depth

1

Convergence Planning

9

Difference Convergence Planning
25000

1

4

x 10

Level 4
Level 2

20000
Optimality Weight

6
4
2
0
1
0.8
Optimality Weight

3
5
Lookahead Depth

0.8

15000
10000
5000

0.4

0

9
0.4
0.2

1

3

5000

5

0.2

Lookahead Depth

1

3
5
Lookahead Depth

9

Figure 34: Convergence planning: impact abstraction function d, . Top two graphs:
LRTS(d, ) vs. LRTS2 (d, ). Bottom two graphs: LRTS2 (d, ) vs. LRTS4 (d, ).
Convergence planning: abstraction level increases, convergence planning generally
decreases. effect complex, deeper lookahead increases cost
individual planning step, overall decreases planning costs convergence faster. interplay
two trends moderates overall influence seen Figure 34.
effect convergence planning non-trivial. general, lower values reduce
convergence planning cost. Note convergence planning cost product average planning
time per unit distance convergence travel. discussed above, optimality weight
amplifies effects abstraction convergence travel. time, substantially
affect increase planning per move abstraction goes up. Combining two influences,
conclude optimality weight amplify effects abstraction convergence planning.
confirmed empirically Figure 34.
Convergence memory: Abstraction decreases amount memory used convergence fewer states learn. effects convergence travel described above. strong correlation convergence
travel convergence memory previously discussed. Visually Figures 32 35
display similar trends.
Suboptimality: Increasing abstraction level increases suboptimality. plain LRTS, lookahead depth effect suboptimality final solution. However, combine deeper
94

fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCH

Convergence Memory

Difference Convergence Memory
1000

1
Level 2
Level 0
Optimality Weight

1500
1000
500
0
1
0.8
Optimality Weight

800

0.8

600
400
0.4
200

9
0.4
0.2

1

3

5

0.2

Lookahead Depth

1

Convergence Memory

3
5
Lookahead Depth

9

Difference Convergence Memory
90

1
Level 4
Level 2

80
Optimality Weight

150
100
50
0
1
0.8
Optimality Weight

70

0.8

60
50
40
30
0.4

20

9
0.4
0.2

1

3

10

5

0.2

Lookahead Depth

1

3
5
Lookahead Depth

9

Figure 35: Convergence memory: impact abstraction function d, . Top two graphs:
LRTS(d, ) vs. LRTS2 (d, ). Bottom two graphs: LRTS2 (d, ) vs. LRTS4 (d, ).

lookahead abstraction suboptimality arising abstraction decreases. deeper lookahead abstract goal state seen earlier making PR LRTS corridor-constrained A*. Additionally,
discussed Section 5.2 Figure 22, refining shorter paths (computed LRTS lower
d) introduces additional suboptimality. suboptimality lower bounded 0%, increasing lookahead diminishes effects abstraction suboptimality (Figure 36) hence Table 6.
Increasing decreases amount suboptimality abstraction used. combined abstraction increasing minor amplification effect difference abstraction
makes (Figure 36) two reasons. First, abstract levels graphs fairly small makes
less difference there. Second, degree suboptimality abstract path translate directly
degree suboptimality resulting ground path A* may still find reasonable
ground path. Thus, influence abstract level overshadowed suboptimaly
introduced process refinement (cf. Figure 21).

95

fiB ULITKO , TURTEVANT, L U , & YAU

Suboptimality (%)

Difference Suboptimality (%)
0

1
Level 2
Level 0

2
Optimality Weight

30
20
10
0
0.2
0.4

5

0.8
1

Optimality Weight

9

3

0.8

4
6
8
10

0.4

12

1
0.2

Lookahead Depth

1

Suboptimality (%)

3
5
Lookahead Depth

9

Difference Suboptimality (%)
0

1
Level 4
Level 2

2
Optimality Weight

30
20
10
0
0.2
0.4

5

0.8
Optimality Weight

1

9

14

3

0.8
4
6
8

0.4

10

1
0.2

Lookahead Depth

1

3
5
Lookahead Depth

9

Figure 36: Suboptimality: impact abstraction function d, . Top two graphs: LRTS(d, )
vs. LRTS2 (d, ). Bottom two graphs: LRTS2 (d, ) vs. LRTS4 (d, ).

96

fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCH

References
Aylett, R., & Luck, M. (2000). Applying artificial intelligence virtual reality: Intelligent virtual
environments. Applied Artificial Intelligence, 14(1), 332.
Bacchus, F., & Yang, Q. (1994). Downward refinement efficiency hierarchical problem
solving.. Artificial Intelligence, 71(1), 43101.
BioWare Corp. (1998). Baldurs Gate., Published Interplay, http://www.bioware.com/bgate/,
November 30, 1998.
Blizzard Entertainment (2002). Warcraft III: Reign Chaos., Published Blizzard Entertainment,
http://www.blizzard.com/war3, July 3, 2002.
Botea, A., Muller, M., & Schaeffer, J. (2004). Near Optimal Hierarchical Path-Finding. Journal
Game Development, 1(1), 728.
Bulitko, V. (2004). Learning adaptive real-time search. Tech. rep. http: // arxiv. org / abs / cs.AI
/ 0407016, Computer Science Research Repository (CoRR).
Bulitko, V., & Lee, G. (2006). Learning real time search: unifying framework. Journal
Artificial Intelligence Research (JAIR), 25, 119 157.
Bulitko, V., Sturtevant, N., & Kazakevich, M. (2005). Speeding learning real-time search via
automatic state abstraction. Proceedings National Conference Artificial Intelligence (AAAI), pp. 1349 1354, Pittsburgh, Pennsylvania.
Culberson, J., & Schaeffer, J. (1996). Searching pattern databases. CSCI (Canadian AI
Conference), Advances Artificial Intelligence, pp. 402416. Springer-Verlag.
Dini, D. M., van Lent, M., Carpenter, P., & Iyer, K. (2006). Building robust planning execution
systems virtual worlds. Proceedings Artificial Intelligence Interactive Digital
Entertainment conference (AIIDE), pp. 2935, Marina del Rey, California.
Ensemble Studios (1999). Age Empires II: Age Kings., Published Microsoft Game Studios,
http://www.microsoft.com/games/age2, June 30, 1999.
Felner, A., Zahavi, U., Schaeffer, J., & Holte, R. (2005). Dual lookups pattern databases.
Proceedings International Joint Conference Artificial Intelligence (IJCAI), pp. 103
108, Edinburgh, United Kingdom.
Furcy, D. (2006). ITSA*: Iterative tunneling search A*. Proceedings National
Conference Artificial Intelligence (AAAI), Workshop Heuristic Search, Memory-Based
Heuristics Applications, Boston, Massachusetts.
Furcy, D., & Koenig, S. (2000). Speeding convergence real-time search. Proceedings
National Conference Artificial Intelligence (AAAI), pp. 891897.
Furcy, D., & Koenig, S. (2005). Limited discrepancy beam search. Proceedings International Joint Conference Artificial Intelligence (IJCAI), pp. 125131.
Garey, M. R., & Johnson, D. S. (1990). Computers Intractability; Guide Theory
NP-Completeness. W. H. Freeman & Co., New York, NY, USA.
Hansen, E. A., & Zhou, R. (2007). Anytime heuristic search. Journal Artificial Intelligence
Research (JAIR), 28, 267297.
97

fiB ULITKO , TURTEVANT, L U , & YAU

Hansen, E. A., Zilberstein, S., & Danilchenko, V. A. (1997). Anytime heuristic search: First results.
Tech. rep. CMPSCI 97-50, Computer Science Department, University Massachusetts.
Hart, P., Nilsson, N., & Raphael, B. (1968). formal basis heuristic determination
minimum cost paths. IEEE Transactions Systems Science Cybernetics, 4(2), 100107.
Hernandez, C., & Meseguer, P. (2005a). Improving convergence LRTA*(k). Proceedings
International Joint Conference Artificial Intelligence (IJCAI), Workshop Planning
Learning Priori Unknown Dynamic Domains, pp. 6975, Edinburgh, UK.
Hernandez, C., & Meseguer, P. (2005b). LRTA*(k). Proceedings International Joint
Conference Artificial Intelligence (IJCAI), pp. 12381243, Edinburgh, UK.
Holte, R., Mkadmi, T., Zimmer, R. M., & MacDonald, A. J. (1996). Speeding problem solving
abstraction: graph oriented approach. Artificial Intelligence, 85(1-2), 321361.
Holte, R., Perez, M., Zimmer, R., & MacDonald, A. (1995). Hierarchical A*: Searching abstraction
hierarchies efficiently. Tech. rep. tr-95-18, University Ottawa.
id Software (1993). Doom., Published id Software, http://en.wikipedia.org/wiki/Doom, December 10, 1993.
Ishida, T. (1992). Moving target search intelligence. National Conference Artificial
Intelligence (AAAI), pp. 525532.
Ishida, T., & Korf, R. (1991). Moving target search. Proceedings International Joint
Conference Artificial Intelligence (IJCAI), pp. 204210.
Kitano, H., Tadokoro, S., Noda, I., Matsubara, H., Takahashi, T., Shinjou, A., & Shimada, S. (1999).
Robocup rescue: Search rescue large-scale disasters domain autonomous agents
research. Proceedings IEEE Conference Man, Systems, Cybernetics, Vol. 4,
pp. 739743.
Koenig, S. (1999). Exploring unknown environments real-time search reinforcement learning. Proceedings Neural Information Processing Systems, pp. 10031009.
Koenig, S. (2004). comparison fast search methods real-time situated agents. Proceedings Int. Joint Conf. Autonomous Agents Multiagent Systems, pp. 864 871.
Koenig, S., & Likhachev, M. (2002a). D* Lite. Proceedings National Conference
Artificial Intelligence (AAAI), pp. 476483.
Koenig, S., & Likhachev, M. (2002b). Incremental A*. Advances Neural Information Processing Systems (NIPS), pp. 15391546.
Koenig, S. (2001). Agent-centered search. Artificial Intelligence Magazine, 22(4), 109132.
Koenig, S., & Likhachev, M. (2006). Real-time adaptive A*. Proceedings International
Joint Conference Autonomous Agents Multiagent Systems (AAMAS), pp. 281288.
Koenig, S., & Simmons, R. (1998). Solving robot navigation problems initial pose uncertainty
using real-time heuristic search. Proceedings International Conference Artificial
Intelligence Planning Systems, pp. 144 153.
Koenig, S., Tovey, C., & Smirnov, Y. (2003). Performance bounds planning unknown terrain.
Artificial Intelligence, 147, 253279.
98

fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCH

Korf, R. (1990). Real-time heuristic search. Artificial Intelligence, 42(2-3), 189211.
Likhachev, M., Ferguson, D., Gordon, G., Stentz, A., & Thrun, S. (2005). Anytime dynamic A*:
anytime, replanning algorithm. Proceedings International Conference Automated
Planning Scheduling (ICAPS).
Likhachev, M., Gordon, G. J., & Thrun, S. (2004). Ara*: Anytime a* provable bounds suboptimality. Thrun, S., Saul, L., & Scholkopf, B. (Eds.), Advances Neural Information
Processing Systems 16. MIT Press, Cambridge, MA.
Lustrek, M., & Bulitko, V. (2006). Lookahead pathology real-time path-finding. Proceedings
National Conference Artificial Intelligence (AAAI), Workshop Learning Search,
pp. 108114, Boston, Massachusetts.
Mero, L. (1984). heuristic search algorithm modifiable estimate. Artificial Intelligence, 23,
1327.
Orkin, J. (2006). 3 states & plan: AI F.E.A.R. Proceedings Game Developers
Conference (GDC). http://www.jorkin.com/gdc2006 orkin jeff fear.doc.
Pearl, J. (1984). Heuristics. Addison-Wesley.
Pohl, I. (1970). First results effect error heuristic search. Meltzer, B., & Michie, D.
(Eds.), Machine Intelligence, Vol. 5, pp. 219236. American Elsevier, New York.
Pohl, I. (1973). avoidance (relative) catastrophe, heuristic competence, genuine dynamic
weighting computaional issues heuristic problem solving. Proceedings International Joint Conference Artificial Intelligence (IJCAI), pp. 1217.
Pottinger, D. C. (2000). Terrain analysis realtime strategy games. Proceedings Computer
Game Developers Conference. www.gamasutra.com/features/gdcarchive/2000/pottinger.doc.
Rayner, D. C., Davison, K., Bulitko, V., Anderson, K., & Lu, J. (2007). Real-time heuristic search
priority queue. Proceedings International Joint Conference Artificial
Intelligence (IJCAI), pp. 23722377, Hyderabad, India.
Reynolds, C. W. (1987). Flocks, herds schools: distributed behavioral model. SIGGRAPH
87: Proceedings 14th Annual Conference Computer Graphics Interactive Techniques, pp. 2534, New York, NY, USA. ACM Press.
Russell, S., & Wefald, E. (1991). right thing: Studies limited rationality. MIT Press.
Shimbo, M., & Ishida, T. (2003). Controlling learning process real-time heuristic search.
Artificial Intelligence, 146(1), 141.
Shue, L.-Y., Li, S.-T., & Zamani, R. (2001). intelligent heuristic algorithm project scheduling
problems. Proceedings 32nd Annual Meeting Decision Sciences Institute.
Shue, L.-Y., & Zamani, R. (1993). admissible heuristic search algorithm. Proceedings
7th International Symposium Methodologies Intelligent Systems (ISMIS-93), Vol. 689
LNAI, pp. 6975.
Sigmundarson, S., & Bjornsson, Y. (2006). Value Back-Propagation vs. Backtracking RealTime Search. Proceedings National Conference Artificial Intelligence (AAAI),
Workshop Learning Search, Boston, Massachusetts, USA. AAAI Press.
99

fiB ULITKO , TURTEVANT, L U , & YAU

Stenz, A. (1995). focussed D* algorithm real-time replanning. Proceedings
International Joint Conference Artificial Intelligence (IJCAI), pp. 16521659.
Stout, B. (1996). Smart moves: Intelligent pathfinding. Game Developer Magazine, October, 2835.
Sturtevant, N. (2005). HOG - Hierarchical Open Graph. http://www.cs.ualberta.ca/nathanst/hog/.
Sturtevant, N. (2007). Memory-efficient abstractions pathfinding. Proceedings third
conference Artificial Intelligence Interactive Digital Entertainment, pp. 3136, Stanford, California.
Sturtevant, N., & Buro, M. (2005). Partial pathfinding using map abstraction refinement.
Proceedings National Conference Artificial Intelligence (AAAI), pp. 13921397,
Pittsburgh, Pennsylvania.
Sturtevant, N., & Jansen, R. (2007). analysis map-based abstraction refinement.
Proceedings 7th International Symposium Abstraction, Reformulation Approximation, Whistler, British Columbia. (in press).
Sutton, R. (1990). Integrated architectures learning, planning, reacting based approximating dynamic programming. Proceedings Seventh International Conference
Machine Learning, pp. 216224. Morgan Kaufmann.
Thalmann, D., Noser, H., & Huang, Z. (1997). Autonomous virtual actors based virtual sensors.
Lecture Notes Computer Science (LNCS), Creating Personalities Synthetic Actors,
Towards Autonomous Personality Agents, Vol. 1195, pp. 2542. Springer-Verlag, London.
Yahja, A., Stentz, A. T., Singh, S., & Brummit, B. (1998). Framed-quadtree path planning mobile
robots operating sparse environments. Proceedings, IEEE Conference Robotics
Automation, (ICRA), Leuven, Belgium.

100

fi
