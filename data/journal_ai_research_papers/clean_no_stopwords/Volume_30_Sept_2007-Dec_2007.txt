Journal Artificial Intelligence Research 30 (2007) 525-564Submitted 1/07; published 12/07Framework Kernel-Based Multi-Category ClassificationSimon I. Hillsih22@eng.cam.ac.ukDepartment Engineering,University Cambridge,Cambridge, UKArnaud Doucetarnaud@cs.ubc.caDepts. Statistics Computer ScienceUniversity British Columbia,Vancouver, CanadaAbstractgeometric framework understanding multi-category classification introduced,many existing all-together algorithms understood. structure enablesparsimonious optimisation, direct extension binary methodology.focus Support Vector Classification, parallels drawn related methods.ability framework compare algorithms illustrated brief discussionFisher consistency. utility improving understanding multi-category analysisdemonstrated derivation improved generalisation bounds.also described architecture provides insights regardingimprove speed existing multi-category classification algorithms. initial example might achieved developed formulation straightforwardmulti-category Sequential Minimal Optimisation algorithm. Proof-of-concept experimentalresults shown this, combined mapping pairwise results, comparablebenchmark optimisation speeds.1. Introductionproblem extending classification methods standard dichotomous frameworkgeneral polychotomous arrangement one considerednumber authors. Essentially, task learn training data bestassign one possible classes subsequent input data, known beforehand.key contribution work introduce overarching framework understanding multi-category kernel-based classification methods. particular framework makes assumptions constructions used individual approaches clear.result enables operation existing multi-category methods transparently compared contrasted intuitive consistent manner. Further, insightafforded architecture suggests ways developing efficient algorithmsbringing together best existing techniques.central idea behind approach introduce (M 1)-dimensional spacedivided class-specific regions. aim learn (M 1)-dimensionalfunction f () lies class region corresponding class argument.shown straightforward generalisation = 2 case, twoc2007AI Access Foundation. rights reserved.fiHill & Doucetclass-specific regions f () 0 f () < 0. Indeed, framework, unlike manyapproaches, binary case treated special case.Discussion done primarily Support Vector Classification (SVC) contextinitially, extended methodologies. geometric structure employedintroduced detail Section 2, together derivation optimisationproblem, shown generalisation standard all-together optimisationproblems overviewed Hsu Lin (2002). discussed along reviewexisting Support Vector (SV) multi-category methods Section 3.Following consider overall algorithm performance Section 4 discussingFisher consistency, Section 5 looking generalisation bounds. Section 6 discussesmethodologies, particular -Support Vector Classification (-SVC), Least SquaresSupport Vector Classification (LS-SVC), Lagrangian Support Vector Classification (LSVC),Proximal Support Vector Classification (PSVC), Bayes Point Machines (BPM).followed return SVC problem Sequential Minimal Optimisation (SMO)algorithm derived Section 7. Issues related details best implementSMO algorithm (e.g. point selection) discussed, options improvingspeed convergence. implemented several examples Section 8, initialexperimental exercise.2. Setting Multi-Category ProblemSection key geometric construction presented, mechanismsusing formulate optimisation problem. Finally, extensions generic structuredescribed. basic construction described Subsection 2.1. Following this,Subsection 2.2 describes example empirical SV loss cases, Subsection 2.3 discussesrelative class knowledge incorporated Subsection 2.4 details overviewderivation SV optimisation problem.2.1 Geometric Constructionbinary classification case, class determination input set X oftenperformed considering sign underlying real-valued function f : X R (Vapnik,1998, example). progressing -class case, underlying vector-valued function f : X RM 1 found, f = f1 . . . fM 1. basic idea behinduse (M 1)-dimensional space able introduce equally separableclass-target vectors. class input x determined identifying class-targetvector f (x) closest.seen effectively takes place binary SV classification,classes, denoted B, class targets y(A) = 1 y(B) = +1. Considerthird class, C, possibility. one-dimensional numerical label insufficientclasses equidistant, case little known relationshipclasses logical arrangement would compare every class everyequivalent way. order class targets must equidistant sense.526fiA Framework Kernel-Based Multi-Category Classificationtwo-dimensional arrangement illustrated Figure 1 allows this. classtarget vectorsy(A) =h3221, y(B) =h3221, y(C) =0 1.(1)ky()k = 11 classes (with = {A, B, . . . } denoting set possibleclasses) improves tractability later. example class-target vectors, however,Class C01Class Boundary12p31Class BoundaryClassClass B12p31Class BoundaryFigure 1: Possible class labels classification three. class-target vectors corresponding classes A, B C shown. class boundaries givensolid lines.general important understand optimisation methods described applicable regardless rotation. Indeed, although apparent Cartesiancoordinate asymmetry may appear intuitive, important consideration relativepositioning class-target vectors respect other. optimisation proceduredependence particular orientation. proven SV methodspart derivation optimisation process Section 2.4.approach described = 3 taken considering larger values. typically = 3 used work example case, extensionshigher values follow without consideration. example target vectorsmight easily found higher dimensions discussed Hill Doucet (2005).1. Note work k k denotes 2-norm vector, i.e. kyk =normalisation imply kyk527q2y12 + + yM1 and, further,fiHill & Doucet2.2 SV Empirical Multi-Category Losssetting classification process, class assigned subset (M 1)dimensional output space. particular, straightforward approach, subsetsVoronoi regions associated class targets. result, class boundariesfound forming hyperplanes class regions consist points equidistanttwo relevant class targets. input x, classifier output givenfunction h found observing regions f (x) lies i.e.h(x) = class associated region f (x) lies.(2)describing empirical loss vectors perpendicular hyperplane dividingregion y(A) y(B) typically used2 . DefinevA (B) =y(B) y(A)ky(B) y(A)k(3)vectors illustrated class C Figure 2 margin introduceddefined = yT ()v () , {A, B, C} 6= . Notedependency , explicitly noted referring constant. Discussionsmight case presented later. definition vectors v usedaim measure distance direction perpendicular class boundariesdone inner product relevant vector v.margin used cases finding empirical loss. severaldifferent ways combine individual loss components, fundamental starting pointillustrated Figure 2. training point x classC f (x) falls outsiderequired region. penalised vB (C)f (x) analogous way binarySV classification empirical loss (1 yf (x)). Indeed binary case vB (A) = y(A)vA (B) = y(B) = 1. parallel, region zero lossbinary case f (x) > 1, region zero loss here, dottedlines.Consider training data {(xi , ) : {1, . . . , N }} used learnbest classify new input x. Denote indicator function I(); empirical losspolychotomous classification problem given Allwein, Schapire, Singer (2001),Crammer Singer (2001a), Lee et al. (2001, 2004) then,EM P =NXI(h(xi ) 6= ),(4)i=1namely number misclassified training samples. dichotomous SV techniques,loss used bounds EM P , thus generating straightforward optimisationproblem.setting multi-category SV classification, approach used many differentauthors, however exact empirical loss functions differed. prevalentunderstood within framework Figures 1 2, four illustratedFigure 3 object class C. four loss functions involve either adding together2. exception case presented Lee, Lin, Wahba (2001, 2004), discussed HillDoucet (2005, App. C).528fiA Framework Kernel-Based Multi-Category Classification"y(C )vB (C )vB (C )f (x)vA (C )f (x)Figure 2: Elements involved determining empirical loss associated training sampleclass C. Note unlabelled solid lines class boundaries, regiondotted line region zero loss training samples class C.Contour Linear Summed Error Surface y=[0 1]2.5221.51.5f2(x)f2(x)Contour Quadratic Summed Error Surface y=[0 1]2.510.500.5310.50210f (x)120.533211221.5f2(x)f2(x)123Contour Linear Maximal Error Surface y=[0 1]T2.51.510.510.500.530f (x)1Contour Quadratic Maximal Error Surface y=[0 1]T2.50210f (x)120.5331210f (x)1231Figure 3: Four possible loss functions three class problem (see Figure 1). lossfunctions shown respect target vector = [0 1]T . Traditionaladditive losses shown top, (see equations (6) (5)), possible variantsfollowing proposals Crammer Singer (2001a) bottom (see equations (8)(7)). cases class boundary shown dot-dash line.margin infringements, taking largest infringement. linear quadraticversions two options illustrated. Algebraically, summed loss training529fiHill & Doucetpoint expressed,SL,i =X(i )SQ,i =X(i )f (xi )v (i ) , 0maxmax2f (xi )v (i ) , 0(5)(6)SL stands summed linear loss SQ summed quadratic loss.top two Subfigures Figure 3. Using notation, maximal loss trainingpoint expressed,max f (xi )v (i ), 0(i )n2=maxmax f (xi )v (i ), 0L,i =Q,imax(i )(7)(8)ML stands maximal linear MQ maximal quadratic. bottomtwo Subfigures Figure 3. expressions apparent ith summandempirical loss (equation (4)) bound 12 SQ,i, 12 Q,i, 1 SL,i 1 L,i .loss arrangements cast transparent way SV framework,work SL,i initially focussed on, commonly adopted,albeit implicitly, previous contributions. SQ,i discussed respect LSVCSubsection 6.3.terms practioners preferred approach, however, clearly choice mustline underlying probabilistic model data. seems unlikelyone best choice implementations. case practioner particularidea model wishes use methodology get feel data,presumably optimal use computationally efficient approach oftenapproaches converge similar results. end approach outlinedpaper interest describes methods potentially used speedloss cases.2.3 Relative Class Knowledgeframework developed based assumption classestreated equally, may desirable cases. may priorknowledge suggesting classes are, sense, closer other, thuslikely mistaken other. may also reason preferringerr side choosing one class others another cost overallaccuracy.classical example deeming important choose one class anothercomes binary case detection radar. military combat clearly extremelyimportant detect incoming missiles planes. result understandableclassification algorithm may set return many false positives falsenegatives. Hence errors made classing enemy weaponry unimportant farheavily penalised errors made classifying nonthreatening phenomena weaponry.530fiA Framework Kernel-Based Multi-Category Classificationtwo ways introduce relative class knowledge framework presented.first traditional method error weighting, introduced alltogether SV framework Lee et al. (2001). solution different type misclassification (e.g. classifying input instead ) error weightedamount; ().approach incorporating weights could equivalently viewed varyinglength vectors v, i.e. v () ()v (). alternative, possibly complementary, approach allocate class unequal volume (M 1)-dimensionaloutput space. enabled varying angle class boundarieshence orientation vectors v, i.e. v () R ()v () R () rotation matrix. may also useful incorporate set variable valueswhich, class denoted { () : ( )}, () sizemargin side (, ) boundary. Clearly greater volume allocatedclass diverse input vectors mapped it.Training PointsFound f(x)8ClassClass BClass CClassClass BClass CClass Boundary560f2(x)x242502104108642024681086x1(a) Classes feature space420f1(x)246810(b) Output resultFigure 4: simple example illustrating potential case differently sized class areas.arrangement target area class could increased.Unfortunately obvious construct principled approach determiningdifferent volumes. key issue region support classfeature space. instance case illustrated Figure 4 possible find linearprojection feature space separate classes standard classregions. However, changing class region sizes projection would possible.may advantage avoiding complicated feature space (possiblyhigher dimension).2.4 Derivation SVC Optimisation ProblemStandard SV mappings inputs higher dimensional feature space, : X F usedorder estimate (M 1)-dimensional function f (). mth element f ()linear function feature space, characterised weight vector wm offset bm .531fiHill & Doucetsummarise,f (x) =h(x), w1h(x), w2...(x), w(M 1)ffF+b1b2...b(M 1)= (x) + b.(9)important realise that, although class separation achieved component,fm (), accurate classification really accomplished use elements,together.optimisation problem follows discussion previous Subsectionswritten (in standard SV form) as,N1XXX1(i )i,kwm k2F + CMinimise2m=1i=1 (i )PM 1m=1 (h(xi ), wm + bm ) v,m (i ) (i ) i, , = 1, ..., N , ( )Subjecti, 0, = 1, ..., N , ( )(10)slack variable i, quantifies empirical loss involved mistaking classpoint xi (which ) (6= ). C quantifies trade-off regularisation(introduced kwm k2F ) empirical loss, v,m () mth element v ().Framing equation (10) terms Lagrangian gives,N1X1 X2L=kwm kF + C2m=1NXX(i )i,1Xi,Xri, i,i=1 (i )i=1 (i )XNX(h(xi ), wm + bm ) v,m (i ) (i ) + i,m=1i=1 (i )!(11){i, , ri, : (1, . . . , N ), ( )} Lagrangian multipliers. standardSV methodology find optimal solution first finding Wolfe dual,maximising respect dual variables, namely Lagrangian multipliers(Cristianini & Shawe-Taylor, 2000; Vapnik, 1998, example). First let V() denote(M 1) (M 1) matrix columns given vectors v (),V() =vA () vB () . . . v6= () . . .().represent mth row V() vm(12)Lemma 1 dual Lagrangian presented equation (11) is,NNNX1 XXLD =Ti (i )V (i )V(j )j K(xi , xj ) +2i=1i=1 j=1532(13)fiA Framework Kernel-Based Multi-Category Classificationwhere,=(i ) =i,A i,B . . . i,6=i . . .(i ) B (i ) . . . 6=i (i ) . . .(14)(15)kernel function denoted K(xi , xj ) = h(xi ), (xj )iF . derivationequation (13) also introduces constraints that,CD (i ) i, 0, i, ( )(16)NX(17)V(i )i = 0.i=1derivation presented technical report authors Hill Doucet(2005, App. A).also remains confirm optimisation problem unique maximum,problem unimodal. case shown quadraticterm equation (13) effectively equivalent quadratic expression involving positivedefinite matrix. case, shown Hill Doucet (2005, App. B).final issue consider rotational invariance structuring probleminitially raised Subsection 2.1. Note influence rotational orientationequation (13) summation term Ti VT (i )V(j )j K(xi , xj ). Considerchosen orientation rotated way described rotation matrix R,quadratic term becomes,Ti VT (i )RT RV(j )j K(xi , xj ) = Ti VT (i )V(j )j K(xi , xj )(18)due fact rotation matrices orthonormal. one aspectconsidered, namely constraints equation (17), however clearaffected rotation either. Hence optimisation problem rotationallyinvariant.related issue geometric structure implicitly introduces ordinal regressionalong (M 1) axes. is, looking example, three-class case illustratedFigure 1 essentially two real valued outputs i.e. f1 () f2 (). Now, alonghorizontal vertical line one held constant, outputingvalue, region value falls determines class assignment. givesimpression ordinal regression using ranges single value output determinetwo classes essence approach.raises two questions methodology presented subject problemsordinal regression? And, looking structure way, factpotentially arranged quite asymmetrically, appears arbitrary cause concern?answer questions No. aim structuring ouput spaceway avoid situation encountered ordinal regression classesequivalently compared other. Furthermore, clearrotational invariance structure, particular orientation chosen goingaffect optimisation problem way whatsoever.533fiHill & DoucetNote introduced terminology function f () expressed,f (x) =NXV(i )i K(x, xi ) + b.(19)i=1clearly natural extension binary framework, comparison previoussimilar contributions forms next Section. offset, b determinedrealising non-extremal Lagrangian coefficients i, lie edge zero-lossregion analogous finding b two-class case.3. Discussion Previous SV Approachesthree main methods applying binary classification techniquesgeneric multi-category problem. one-against-all method, pairwise couplingmethod method Error Correcting Output Codes (ECOCs). discussedhere, applied conjunction SV methods. extensive literature reviewforms large part work Rifkin Klautau (2004); contrast, Sectionvarious methods discussed respect approach described Section 2.Essentially, one-against-all pairwise methods made work well,invariably require heuristic component resolve issues associated combiningresults. Many authors tried overcome framing problem singleoptimisation, also done Section 2, however approaches substantially slowerconverge. key contribution work demonstrate consistent3 resultobtained mapping pairwise results ad hoc way framework Figure 1fine-tuning result, consistent final optimum. provides combinationfast training consistency.Contributions Rifkin Klautau (2004) argue one-against-allpairwise methods made perform practically well methods. maywell case, depending implicit model behind heuristics involvedcome surprise. Indeed, many quick black-box implementations approach maywell optimal.Often however desirable clear understanding optimisation processsignificant contribution framework presented within many single optimisation SV methods understood compared directly. Further, frameworkmulti-category versions algorithms formulated understoodconsistent way, discussed Section 6. Finally, fact manydifferent efforts made find method involving single optimisationcompetitive terms speed evidence desire research communityovercome heuristic solutions.Section one-against-all method reviewed Subsection 3.1, pairwise coupling Subsection 3.2 ECOCs Subsection 3.3. Efforts develop single optimisation3. Here, subsequent usage, use consistent consistency refer factapproaches quite ambiguous exactly class output, hence need heuristicchoose, all-together solution suffer i.e. results consistentother. Fisher consistency discussed Section 4.534fiA Framework Kernel-Based Multi-Category Classificationapproaches, known all-together methods discussed Subsection 3.4. relate framework presented also clarified therein.3.1 One-Against-All Methodone-against-all method received attention SV community,also earliest approach considered. idea generate classifiers. these,classifier determines whether input belongs class i. obvious stumblingblock case one classifier determines particular inputbelong class interest. Hence important place techniqueeither avoiding resolving problem.Early implementations (Scholkopf, Burges, & Vapnik, 1995; Blanz, Scholkopf, Bulthoff,Burges, Vapnik, & Vetter, 1996) used underlying real-valued output, choosing highest output indicate strongest likelihood class membership. variantintroduced Mayoraz Alpaydn (1999) attempt make outputsreliably comparable; see also Wang, Vuurpijl, Schomaker (2000).aside, note function f () found framework proposed Section2 used produce one-against-all classifier. see consider functionf () = yT ()f () y() class-target vector class . new input x wouldclassed f (x) largest scalar function.3.2 Pairwise Coupling Methodpairwise coupling method involves finding (M2 1) different classifiers,compares one class another. Given input, output class decidedvote similar method. One particular problem addressed circular onewhich, example, AB classifier chooses class A, AC classifier class CBC classifier class B.authors (Hastie & Tibshirani, 1998; Platt, Cristianini, & Shawe-Taylor, 2000;Furnkranz, 2002) proposed heuristics resolving problems, howeversubstantive purely SV approach seems Kreel (1999). techniqueconsiders classifier vote and, case tie, real-valued outputs referred to.downside (M2 1) classifiers found independently,comparison always meaningful. Nonetheless, shown Kreel supportedAllwein et al. (2001), Hsu Lin (2002) Rifkin Klautau (2004), appearseffective methodology faster all-together methods considerable margin.alternative approach presented Allwein et al. (2001) work unifying pairwise,one-against-all class codes discussed Subsection 3.3.interesting note function f () found framework proposed Section2 used find classifier two classes B. see consider(B)f () v (B) defined equation (3). new input xfunction fAB () = vAwould classed fAB (x) 0 B otherwise. Results usedSection 7 construct best worlds approach.535fiHill & Doucet3.3 Class Codesunderlying idea behind ECOCs assign class particular binary codetrain individual classifiers identify bit code (Sejnowski & Rosenberg,1987; Dietterich & Bakiri, 1995). Eight classes can, example, assigned 3bit code ([1, 1, 1], [1, 1, +1], etc.). general least log2 bits required.Dietterich Bakiri (1995) propose using bits order small errorscorrected.ECOC SV methods described Kindermann, Leopold, Paa (2000)Rennie Rifkin (2001). Minimum length code methods presented Sebald(2000), Sebald Bucklew (2001) Suykens Vandewalle (1999). Howeverimplementations often problem classes treated inconsistently. duefact codes smaller Hamming distances classesothers. approach becomes much like utilising Ordinal Regression (see,example, Crammer Singer (2001b) Herbrich, Graepel, Obermayer (2000b)more, SV context) perform classification performance becomes dependent ordering labels (Weston, 1999). Essentially ordinal regression performsclassification based region R scalar output lies. instance,class may assigned input x f (x) [a, b), class B f (x) [b, c),on.see parallel coding approaches consider four-class caseminimum length codes, that,y(A) =y(C) =1 1+1 1y(B) =y(D) =1 +1+1 +1.Two functions f1 f2 need found corresspond first second elementscodes respectively. However class clearly class classesB C. Hence comparison classes longer consistent. Althoughless extreme ordinal regression main problem classes comparedequivalent way remains. reason, well lack computationalaccuracy advantage, methods particularly popular.Allwein et al. (2001) shown pairwise one-against-all methods viewedspecial cases ECOC approaches4 . Indeed code length equals (theone-against-all case) exceeds inconsistency problem describedmade disappear. Even viewing pairwise one-against-all approaches specialcases ECOC Allwein et al. (2001) still must employ heuristic (in case code-based)find final answer.3.4 All-Together Methodsconsistent result obtained arranging multi-category problemsingle optimisation perform. described Hsu Lin (2002)all-together methods number authors (Bredensteiner & Bennett, 1999; Crammer4. exception binary nature code formulation case pairwise comparisoncode word elements take values {1, 0, 1}.536fiA Framework Kernel-Based Multi-Category Classification& Singer, 2001a; Guermeur, 2000, 2002; Weston & Watkins, 1999; Weston, 1999; Vapnik,1998) present variety methods. see many relate describedSection 2, note aim find functions {f () : } that, class(x) =arg max {f (x) : }. Weston Watkins (1999) aim find functions formf () = h(), w + bNXX1Xi,kw k2F + C2i=1 (i )ff, ( )(xi ), wi F + bi h(xi ), w + b + 2 i,Subjecti, 0Minimising(20)shown detail authors (Hill & Doucet, 2005, App. C)optimisation arrangement identical Section 2 f () = yT ()f () f ()introduced Section 2. Furthermore, all-together approaches mentioned,exception Crammer Singer (2001a), shown Guermeur (2002)converge solution. However key problem algorithmsresulting kernel expressions quite complicated framing optimisationprocess leads convoluted expressions.alternative Crammer Singer (2001a) propose all-together one-against-allmethod maximal loss L,i equation (7) (see also Figure 3) givenew optimisation algorithm. comparative work Hsu Lin (2002) find harddraw definitive conclusions Crammer Singer (2001a) approach comparisonothers note variable performance regard optimisation times required.also suggest algorithmic improvements traditional methods, eventuallyconclude that, available techniques, pairwise coupling methods (see Section 3.2) muchfaster appear suitable practical use.standard form methodology introduced Section 2 results optimalsolution equivalent all-together approaches two key points differentiate it.first increased flexibility incorporate approaches describedSubsection 2.3 without increased computational effort. second easilytake advantage relatively much faster pairwise methods. discussedSubsection 7.4.3.4.1 Another All-Together ApproachLee et al. (2001, 2004) presented unique all-together approach uses -lengthtarget codes. classes = {A, B, . . . } take form(A) =(B) =111111...1153711...11fiHill & Douceton. resulting optimisation problem posedNXX1Xi,kw k2F + C2i=1 (i )h(xi ), w + b yi () i,PSubjecth(xi ), w + b = 0i, 0Minimise(21)+ b+ bh(), wAoutput given f () =h(),w...=B FBFW () + b W = wA wB . . . , class membership determinedobserving element f () maximal. approach understoodframework Section 2 when, similarly Subsection 3.4 f () = yT ()f () f ()introduced Section 2. discussed Hill Doucet (2005, App.C), shown setting vA (B) = y(A) = M11 causes optimisationproblem equation (21) generic approach equation (10).4. Brief Look Fisher ConsistencyLee et al. (2001, 2004) (Subsubsection 3.4.1) approach key featureFisher consistent5 . recently discussed context multicategoryclassification Tewari Bartlett (2007), Zhang (2004a, 2004b). Sectionsimply aim show key results authors understoodframework presented Section 2.considering Fisher consistency multicategory case first define vector(22)= P ( = A|x) P ( = B|x) . . .p(x) = pA (x) pB (x) . . .analogous vector p Tewari Bartlett (2007), vector P(|X)Zhang(2004b, Eqn.(7)). also express empirical loss function, (, f (x)) =P() max v ()f (x) , 0 , cf. equation (5), define vector by,(f (x)) =(A, f (x)) (B, f (x)) . . ..(23)notation -risk, terminology Tewari Bartlett (2007)given by,EX [ (, f (x))] = EX E|X [ (, f (x))](24)= EX pT (x) (f (x))optimal classification rule choose class = arg max [p (x)]. Fisherconsistent multicategory classifier g(x) = f (x), cf. Subsection 3.4, that,= arg max [p (x)] = arg max [g (x)](25)5. referred classification calibrated Tewari Bartlett (2007) infinite-sample consistentZhang (2004b).538fiA Framework Kernel-Based Multi-Category ClassificationTewari Bartlett (2007) illustrate two class case reference equation(24), plot (A, f (x)) (B, f (x)) y(A) = 1 y(B) = +1.Bartlett, Jordan, McAuliffe (2004) shown provided plot differentiable f (x) = 0 consistency attained. caseone tangent plot f (x) = 0. noteworthy particular x,value f (x) minimises inner product equation (24) determinedpoint line slope ppBA (x)(x) tangent. plot differentiablesample x pA (x) > pB (x), sample x pA (x ) < pB (x ) mayvalue f (x) = f (x ) = 0 even though f minimises -risk.Whereas plot straightforward 2D plot, considering three class casemust turn 3D surfaces consider tangent planes normal given p(x) e.g. TewariBartlett (2007, Figs.2&3). illustrated all-together methodsinconsistent including Weston Watkins (1999), Weston (1999)Crammer Singer (2001a). However, also case approach Lee et al.(2001, 2004) consistent.order better understand happening, consider similaritiesmethod introduced Weston Watkins (1999), Weston (1999), Lee et al.(2001, 2004) (3.4). additive approach forming loss function(in contrast maximum approach Crammer & Singer, 2001a). key differencechoice vectors v. Weston Watkins (1999), Weston (1999) use,example vA (B) [y(B) y(A)], Lee et al. (2001, 2004) use e.g. vA (B) = y(A). factalso consider using vectors either combination these,extreme versions. Examples resulting loss functions shown Figure 5, cf. Figure 3.becomes interesting terms Fisher consistency happensplots loss contours classes overlaid. consider plotsclass C Figure 5. particular consider Lee et al. (2001, 2004) (LLW) case.clearly identify four regions zero loss, loss due class A,loss due class B combined loss. overlaying contour plotssimilarly seek identify regions.presented Figure 6, regions seperated solid black lines.seen regions identified Weston Watkins (1999), Weston (1999)Lee et al. (2001, 2004) plots correspond planes (and edges) Figures 2(b) 3(b)Tewari Bartlett (2007). Further, keeping discussion becomes clearpotential inconsistency problems occur region boundaries intersect classboundaries. reason Lee et al. (2001, 2004) case manages avoidregion boundaries coincide particular setting. scenarios illustrated Figure 6correspond following example vectors v, left right, top bottom;0.2y(B) y(A)y(A)y(B) 5y(A)vA (B)y(B) 2y(A)y(B) y(A)y(B) 0.5y(A)539Excess LLW case.LLW case.LLW WW case.LLW WW B case.WW case.Excess WW case.(26)fiHill & DoucetExcess LLWLee Lin WahbaExcess WW333222111000111222332101233321012333210123Figure 5: illustration losses respect class C. correspondchanging vectors v. Recall Weston Watkins (1999), Weston (1999)(WW) case loss contours parallel class boundaries (Figure 3)clear cases LLW WW onwards Figure 6 inconsistent,question remains Excess LLW case. investigate createdplots similar Figures 2 3 Tewari Bartlett (2007), shown Figure7. clear reverse view labelled Point Interestgoing pose consistency problem.results give quick geometric insight Lee et al. (2001, 2004)approach appears Fisher consistent approach involving summed linear losses.performed similar investigation effect changing v within contextCrammer Singer (2001a) framework seems clear alwaysproblem central point reasonable choice vectors v, cf. Tewari Bartlett(2007, Fig. 2a).5. Generalisation Boundsimportant aspect many kernel based algorithms SVC, Structural RiskMinimisation (SRM) ideas applied order obtain distribution-free boundsperformance. approach underlies initial work SVC particular, resultsideas Vapnik Chervonenkis (VC) dimension.section build body work concerned boundingperformance multicategory classifiers. originally published Guermeur (2002),important realise paper draws heavily work Elisseeff,Guermeur, Paugam-Moisy (1999). insight also found workPaugam-Moisy, Elisseeff, Guermeur (2000).540fiA Framework Kernel-Based Multi-Category ClassificationExcess LLWLee Lin WahbaLLW WW33322211100011122233210123332LLW WW B1012333Weston Watkins332221110001112222101233321011012323Excess WW333223332101Figure 6: Region Identification six different cases represent rotation vectors v, starting top left progression passes Lee et al. (2001,2004) case (middle top), bottom left WestonWatkins (1999), Weston (1999) case (middle bottom).(a) Front View(b) Reverse ViewFigure 7: Loss surfaces Excess LLW case Figure 6541fiHill & Doucetusing geometric approach presented above, becomes possible reducemultidimensional bounding problem scalar problem, thus fully utilisetraditional approaches bounding. approaches also drawn Elisseeff et al.(1999), however viewing problem manner proposed becomes possibleadopt virtually unchanged. key references work Bartlett (1998)Williamson, Smola, Scholkopf (2001).finalPresult working demonstrate bound derived dependent12termi=1 kwi kF , cf. equation (10). keeping results Guermeur(2002), Elisseeff et al. (1999), well traditional two-class bound analyses (Scholkopf& Smola, 2002). Note notation Section inconsistentused elsewhere paper, however difference apparent.5.1 Basic Definitionsstarting reference canonical function Elisseeff et al. (1999), PaugamMoisy et al. (2000), Guermeur (2002), rewritten present notation.introduce also dimensional vector yc elements,1 input classc=+1 input class .introduce function g : X RM ,g() = f ()(27)matrix columns class target vectors y, cf. Section 3.Definition 1 (The Original Canonical Function) Define R1 (x) indexgR1 (x) (x) = max g (x) R2 (x) index gR2 (x) (x) = max6=R1 (x) g (x).canonical function g : X RM , given by,(11= R1 (x)2 g gR2 (x) = 2 [y() y(R2 (x))] f (x) = vR2 (x) ()f (x)g (x) =11otherwise.2 g gR1 (x) = 2 [y() y(R1 (x))] f (x) = vR1 (x) ()f (x)(28)constant proportionality.Clearly, example classified correctly, terms vR()f (x)1 (x)negative vR2 (x) (R1 (x))f (x) positive. Paugam-Moisy et al. (2000), Guermeur (2002) define margin = min yc g (x), however, recall vA (B) =vB (A), gR1 (x) (x) = gR2 (x) (x). Hence, R1 (x) R2 (x) actual classccx yRgR1 (x) (x) = yRgR2 (x) (x). case neither1 (x)2 (x)correct class demonstrated margin going determinedgR1 (x) (x) uniquely, term need ever considered.case margin simply given min6=R1 (x) vT (R1 (x))f (x).definition Paugam-Moisy et al. (2000), Guermeur (2002) somewhat nonintuitive, make reference actual class point, merely R1 (x),may equal class . equivalent defining margin542fiA Framework Kernel-Based Multi-Category Classificationtwo-class classifier absolute value function f (x). somethingappears mainstream texts Vapnik (1998, p. 402), Scholkopf Smola (2002, p.142) Hastie, Tibshirani, Friedman (2001, p. 110), instance. However generalideas texts, approach Section 2 related Definition2, Paugam-Moisy et al. (2000, Defn. 6) Guermeur (2002, Defn. 5).anticipation introduce alternative canonical function f (x, ),f (x, ) = VT ()f (x)(29)V() given equation (12). x correctly classified elements fpositive.Definition 2 (Empirical Margin Risk) Conceptually, empirical margin riskfraction training samples whose positioning (M 1) dimensional space lies outsideregion zero-loss. Formally expressed fixed margin > 0training set = {xi , }Ni=1 as,RS (f ) =1|{(xi , ) : ( ) , f (xi , ) < }|N(30)definition used pseudo-metric. definition note1Pp denotes norm kxkp = ( |xi |p ) p .Definition 3 (Pseudo-Metric) Let F : X RM 1 set functions (f , f ),SF 2 . set points X , define pseudo-metric dF,1 by,,SdF,1 (f , f ) = max(x,)SX()fififif (x, ) f (x, )fi .(31)define covering number (Vapnik, 1998; Scholkopf & Smola, 2002, example).Definition 4 (Covering Number) Let F , dF ,S pseudo-metric space, B(f , r)closed ball F radius r centre f . covering number N , F, dF ,Sset F F smallest cardinality set F that,[FB(f, ).(32)f Fsets F satisfying property called covers F: element Fdistance less element F. |S| = 2N define also,,SNp,q, F, 2N = sup N, F, dFp ,q .22SX 2N543fiHill & Doucet5.2 Presentation Boundsuse final definition consideration of,f (x, ) =sign [min f (x, )] ,min f (x, ),| min f (x, )|otherwise,(33)analogous definition g used Elisseeff et al. (1999, 4), Paugam-Moisyet al. (2000, 6) Guermeur (2002, 2). used define set scalar-valuedfunctions,F = {f : f F}(34)leading Theorem 1, below. advantage approach presentedfunction f scalar and, such, lot straightforward use proofstructure outlined Bartlett (1998, Lemma 4) cf. Elisseeff et al. (1999, Cor. 2), PaugamMoisy et al. (2000, Cor. 1), Guermeur (2002, Thm. 1). elaborated on, twodifferent approaches contrasted Hill (2007, 4.2,A.2)Theorem 1 probability least (1 ), every value (0, 1], risk R(f )function f computed numerical class discriminant model F trained setsize N (denoted SN ), boundedR(f )RS N (f )+211, F , 2N+ loglog 2N,1+2N2N(35)Proof Theorem 1starting point proof equivalent Elisseeff et al. (1999, Eqn. (5)),namely, ,PSN1sup R(f ) RS N (f ) 2PSN ,SeN sup RSe (f ) RS N (f ). (36)NNf Ff Faim bound right-hand side starting point considerpermutations (X )2N realises transposition two elementsranking SeN SN . Let U uniform distribution setpermutations so,PSN ,SeN11sup U : sup RSe (f ) RSN (f ).sup RSe (f ) RSN (f )NNNNf Ff F,SeNNDenote 2 cover set F F , elements f . identical reasoningBartlett (1998, proof Lemma 4) defining,fi ofi1 fifin fifififi,f , SNfifi : fif (xi , ) fiN2544fiA Framework Kernel-Based Multi-Category Classificationinequality leads to,1PSN ,SeN sup RSe (f ) RS N (f )NNf F()1sup U : supf , SeNf , SNNef FSN , SNfi1efififisup U : f , SN f , SNF.Nf Ffifidefinition fiF fi = N,1 2 , F , 2N seen leads1PSN ,SeN sup RSe (f ) RS N (f )NNf F!(37)X11N,1(ai bi ), F , 2N sup P2NN(ai ,bi ){1, +1}, P (i = 1) = P (i = +1) = 0.5 Independent,Identically Distributed (IID). Meanwhilefifi(fi efiei , fi 21 fif xai =0 otherwisebi =(fififififif (xi , ) fi0 otherwise.12right-hand term equation (37) bounded using Hoeffdings inequality(Elisseeff et al., 1999, Theorem 5) that,2 !11, F , 2N exp 2N.PSN ,SeN sup RSe (f ) RS N (f )N,1NN2Nf F(38)rearranged demonstrate that,111, F , 2Nlog 2PSN ,SeN sup R e (f ) RSN (f )log 2N,1+SN2N2NNf Fso, equation (36)11+ ., F , 2Nlog PSN sup R(f ) RSN (f )log 2N,12N2Nf FNow, probability least (1 ) = PSN supf F R(f ) RS N (f ) ,case R(f ) RS N (f ) . Hence, probability least (1 )r1 h1R(f ) RSN (f ) +log 2N,1, F , 2Nlog () + .(39)2N2N545fiHill & Doucetanalogous result Theorem 4 Elisseeff et al. (1999). Using togetherProposition 8 Bartlett (1998) demonstrates that,211R(f ) RsN (f ) +, F , 2N+ log(35)log 2N,1+2N2Nconcludes proof Theorem 1.5.2.1 Bounding N,12 , F , 2Nusing Entropy Numbersgeneralised risk Theorem1 bounded expression involvingcovering number, N,1 2 , F , 2N , clear determine number exactly,standard approach bound it. done following ideas Williamsonet al. (2001). first step define entropy numbers Guermeur (2002, Defns. 7 & 8),Williamson et al. (2001, eqns. 7-10).Definition 5 (Entropy Numbers Operator Norm) Given pseudo-metric space,SF ,S(F , dF,1 ) then, nth entropy number set F F respect ,1 ,n,Sn(40)n (F) , inf > 0 : N , F, dF,1entropy number operator : F follows introduction unit ballF , denoted UF . nth entropy number defined as,n (T ) , n (T (UF ))(41)kT k = sup kT (f )kM .(42)operator norm given by,f UFunderstand entropy number explicitly, denote (UF ) set ,assume metric dM .then, keepingequation (40), entropynumber given n (T ) , inf > 0 : N , M,n .Note firstdefinition clear see n (F) boundedpartF ,S, N , F, ,1 n; Guermeur (2002, Thm. 3), Williamson et al. (2001,, 2N ,Prop. 12). Note also Definition4,orderboundN,F,12,Ssufficient bound N 2 , F , dF,1 , discussed following Theorem.,STheorem 2 (Bound log N 2 , F , dF) log covering number,1PM 1,S2N 2 , F , dFm=1 kwm kF ,,1 set F F bounded term proportionali.e.1X,Skwm k2F(43)rlog N, F , dF,12m=1r > 0.546fiA Framework Kernel-Based Multi-Category ClassificationProof Theorem 2proof begins fact, highlighted Williamson et al. (2001, Thm. 10) (seealso Guermeur, 2002, Thm. 4), Maureys Theorem used bound entropynumbers. Theorem note qp vector space containing vectors dimension1Pq norm kf kqp = ( qi=1 |fi |p ) p . Furthermore (F , ) denotes set boundedoperators normed spaces (F , k kF ) (M , k kM ).Maureys Theorem considers (H , q ) H Hilbert space.states exists constant c > 0 that, n, q N,vuu log 1 + qlog n+1.(44)n (T ) ckT klog n + 1Guermeur (2002) must rely generalisation Maureys Theorem matrixoutput spaces, directly applicable vector output spaces. mentionedGuermeur (2002), claimed problem, extensionderived, although done. current formulation problem however,theorem used directly bound entropy number, and, stated, alsoused bound covering number operator. steps follows,vuu log 1 + Nlog n+1= ckT k(45)n (T )2log n + 1,SNn(46), (UF ) , dM,12,S,SNN.(47), F , dF, (UF ) , dM,1,122remains demonstrate third and, particular, aim(f ) = min f (x1 , 1 ) min f (x2 , 2 ) . . . min f (xN , N ) .(48)mapping : F vector space normkakM ,S = max |ai |.(49)1i|S|case Maureys Theorem clearly directly applicable, equations (45)(46). expressions equations (48) (49) far simpler counterpartsGuermeur (2002, 2.3) due scalar form f equation (33).comparison two approaches, see Hill (2007, 4.2.1,A.2.1). proving equation(47), consider first,fifififi,Sfi,1 (f ), (f ) = max fimin f (x, ) min f (x, )fifi(x,)Sand, meanwhile,fifififi,Sf(x,)f=max(x,)f,fdFfifi,1(x,)S547fiHill & Doucetclear see that,fififififififififimax fif (x, ) f (x, )fi max fimin f (x, ) min f (x, )fifi(x,)S(x,)S,SF ,S,1 f , f ,1 (f ), (f )(50)means that, provided f , f UF , equation (47) correct. extended versionderivation presented Hill (2007, B.2).remains bound kT k. Now, equation (49),fifififikT (f )kM ,S = max min v (i )W(xi ) .(51)6=iii|S|Cauchy-Schwarz inequality (Guermeur, 2002, A.2) Xradius ball including (X ),(52)kT (f )kM ,S X max min kv ()Wk26=means that,min kvT ()Wk26=kT k X maxvuM 1uXkwm k2F .X(53)m=1made assumption f UF , however casestraightforward arrive analogous solution. found Williamsonet al. (2001, V.B), Elisseeff et al. (1999, Prop. 4) Guermeur (2002, Prop. 1), example.Combining result equation (45)vvuuM 1Nulog1+uXlog n+1kwm k2Fn (TF ) cX2log n + 1m=1rearranged give,4c2 2X log(1 + N )log n2PM 1m=1kwm k2F1n 1, always going case bound covering number.Equation (46) gives,4c2 2 log(1 + N ) PM 1 kw k2FMF ,SXm=1log N, TF (UF ) , ,1122so, finally, equation (47)log N2, F,S, dF,14c2 2X log(1 + N )2548PM 1m=1kwm k2F1.fiA Framework Kernel-Based Multi-Category Classificationdemonstrates result equation (43) Theorem 2 moreover showsconstant r given by,4c2 2X log(1 + N ).(54)r=2concludes proof Theorem 25.3 Summary Generalisation BoundsSubsection 5.2, Theorem 1 showed risk R(f ) function f boundedprobability least (1 ) by,R(f )RS N (f )+211, F , 2N+ loglog 2N,1+ .2N2N(35),SWhere, Definition 4; N,1 2 , F , 2N = supSX 2N N 2 , F , dF,1 ,Theorem 21X,Skwm k2F(43)r, F , dFlog N,12m=1r positive given equation (54). resultv" 1u#u 1X412R(f ) RSN (f ) +kwm kF + logr+ .2NNm=1(55)mentioned derivation result, methodology employedkeeping two-class derivation bound derived Guermeur (2002).due use scalar function f , introduced equation (33). usefunction logical consequence viewing problem geometric frameworkSection 2. allows mapping vector space, two-class case,rather matrix space, work Guermeur (2002).use f simplify working, final resultderived bound tighter Guermeur (2002). rederivedpresent notation Hill (2007, App. A) assumption Maureys Theoremapplicable directly maintained. presenting first define set(M 1)/unique class combinations. class pair (, ) (, )2equivalent expression equation (55) is,vuuX41u 1kvT ()Wk2 + logr+ .R(f ) RS N (f ) +2NN(,)r=8c2 2 2X (M 1) log(1 + N ).2549(56)fiHill & Doucet6. Kernel-Based Methodssection use framework presented Section 2 described respect-SVC, LS-SVC, LSVC, PSVC, BPM.6.1 -Support Vector Classificationcase two-class optimisation problem (Scholkopf & Smola, 2002)!NX1yi [h(xi ), wiF + b]2, SubjectkwkF +Minimise0, and, 02(57)i=1extension polychotomous case straightforward, namelyN1XXX XX1Minimisei,()kwm k2F +2m=1i=1 (i )()PM 1m=1 v,m (i ) [h(xi ), wm + bm ] i,Subjecti, 0, and, 0.(58)Following usual Lagrangian dual approach results final aim maximiseLD =N N 11 XX XV (i )V(j )j K(xi , xj )2(59)i=1 j=1 m=1subject 0 i, 1, i, ( ),output given equation (19).PNi=1 V(i )i= 0,PN Pi=1(i ) i,> .6.2 Least Squares Support Vector ClassificationLS-SVC developed length Van Gestel, Suykens, Baesens, Viaene, Vanthienen,Dedene, De Moor, Vandewalle (2001) much standard SVC, exceptempirical loss taken quadratic; see top-left corner Figure 3,equation (6). Multiclass versions published (Van Gestel, Suykens, Lanckriet,Lambrechts, De Moor, & Vandewalle, 2002) rely coding schemes discussedSubsection 3.3. two-class case aims!NX1(60)i2 , Subject yi [h(xi ), wiF + b] = 1kwk2F + CMinimise2i=1alternative multi-category extension coding approach exists, i.e.N1XXX12Minimisei,kwm k2F + C2m=1Subject1Xi=1 (i )v,m (i ) [h(xi ), wm + bm ] = (i ) i, .m=1550(61)fiA Framework Kernel-Based Multi-Category ClassificationNow, defineZm ==T1...TN( ) . . . (x )vT ( )(x1 )vmN1N.Z = ZT1 . . . ZTM 1=V =(1 ) . . .(N )V(1 ) . . .V(N )definitions shown (Van Gestel et al., 2001) optimisationproblem becomes equivalent finding b satisfy,0VVZ Z + CIb=0.(62)classifier found solving linear equations. Note finding Z Zrequire reference feature space, kernel evaluations. final outputequation (19).6.3 Lagrangian Support Vector Classificationintroduced Mangasarian Musicant (2001), LSVC algorithmstrength computationally efficient, easy implement. usesquadratic empirical loss, illustrated top-left corner Figure 3, detailedequation (6). method two-class classification aimsNMinimiseX1i2kwk2F + b2 + C2i=1!, Subject yi [h(xi ), wiF + b] 1 .(63)reformulated multi-category problem resulting in,1Minimise2Subject1X1Xm=1kwm k2F + b2m + CNXXi=1 (i )2i,(64)v,m (i ) [h(xi ), wm + bm ] (i ) i, .m=1dual is,NN NX11 XX(i )V (i )V(j )j [K(xi , xj ) + 1] +LD =22C(65)i=1i=1 j=1needs maximised subject i, 0 i, ( ).Pdone b = Ni=1 V(i )i . final solution takes form equation(19).551fiHill & Doucet6.4 Proximal Support Vector ClassificationFollowing LSVC method, PSVC approach developed FungMangasarian (2001b, 2001a). presented multi-category approachone-against-all algorithm, all-together one. two-class aim!NX1222, Subject yi [h(xi ), wiF + b] = 1 . (66)kwkF + b + CMinimise2i=1is, more, LS-SVC Subsection 6.2 except b2 term.reformulated multi-category problem resulting in,1NXXX12i,kwm k2F + b2m + CMinimise2m=1i=1 (i )(67)1Xv,m (i ) [h(xi ), wm + bm ] = (i ) i, .Subjectm=1Now, define v = v1T (1 ) . . . v1T (N ) v2T (1 ) . . . vN(N ) ,LS-SVC optimisation problem exact solution,1= + Z Z + v veverything defined Section 6.2 b =solution takes form equation (19).PNi=1 V(i )i .(68)before, final6.5 Bayes Point MachinesBPMs introduced Herbrich, Graepel, Campbell (2000a) ideasextended multi-category problem. short consider term VersionSpace, V. two-class case region weight vector w lie withoutinducing classification errors training set.Within version space uniform distribution assumed possible linear (in featurespace) classifiers, h, outside assumed zero. Bayes point classifier givenh(69)hbp = arg min EX EH|{xi ,yi }N [ (h(X), H(X))]i=1hH(, ) loss function (typically zero-one loss function used) innerexpectation classifiers H H. One problem definition usualknowledge PX evaluation EX impossible.assumptions form PX (see Herbrich et al., 2000a, more) can, however,shown centre mass,wcm =Ew|{xi ,yi }N [w]i=1kEw|{xi ,yi }N [w]ki=1552(70)fiA Framework Kernel-Based Multi-Category Classificationgood approximation wbp . Eventually problem becomes identify V,contiguous convex space, find wcm given uniformdistribution assumed weight vectors space.Note version space definedV = {w : yi h(xi ), wi > 0, kwk = 1, i} ,(71)considering multiple classes condition yi h(xi ), wi > 0 becomes VT (i )W(xi ) >0 0 ... 0inequality indicates component-wise inequalities, maTintroduced. result version space giventrix W = w1 . . . wM 1nV = (w1 , w2 , . . . , wM 1 ) : VT (i )W(xi ) > 0 0 . . . 0, kwm k = 1 m, ,(72)identical form equation (71). Extensions kernel billiards algorithmdescribed Herbrich et al. (2000a) used find Wcm , analogous wcmequation (70). method including training errors also seamlessly incorporated.7. Implementation Sequential Minimal Optimisationgeometric construction introduced Section 2 allows insight multi-categoryproblem, motivate alternative approaches efficiently solve all-togetheroptimisation problem. One possibility SVC presented here, based vector-valuedversion SMO first introduced binary classification Platt (1999).several advantages, including fact reasonably straightforward understand,relatively easy implement, quite efficient flexible, addition well establishedknown.SMO optimises respect two points time, denote c d.notation, Kij = K(xi , xj ), dual Lagrangian equation (13) becomes11L = Tc (c ) + Td (d ) Tc VT (c )V(c )c Kcc Td VT (d )V(d )d Kdd22Tc VT (c )V(d )d Kcd Tc VT (c )zc Td VT (d )zd + constant.(73)Pzc vector elements zc,m = Ni=1,i6=c,d vm (i )Kic similarly zd,m .shown Hill Doucet (2005, 6); expressing c terms ,constraint equation (17), finding minimum setting L(d ) = 0,SMO update takes form,= oldnew+V1 (d )(xc ) (xd ) + VT (d )(d ) VT (c )(c ) (74)Kdd + Kcc 2Kdcwhere, V1 (d ) exists provided vectors {v (d ) : ( )} linearly independent, nearly always case, although possible conceive pathologicalcases. Recall introduced equation (9) cf. (19).553fiHill & Doucet7.1 ClippingRecall elements c upper lower bounded (equation (16)),hence clipping may required. best understood Figure 8, relatesIllustration Clipping Considerations1.2d,210.80.6Start pointd,2old0.4new0.2End point0d,10.20.200.20.40.6d,10.811.21.41.6(a) vector illustration proposed (b) Constraints within update mustupdatemadeFigure 8: proposed update three-class problem. new point shown Subfigure 8(b) outside allowed regions. correspond overall limits0 CD1 (d ) (upright box) limits imposed c considerations (tiltedbox).three-class case, however ideas generically applicable. Given updatenew new lie outside constraintsequation (74) form new= old+ , coldnewline traced back along longer case.Ultimately [0, 1) foundnew,clipped= old+ .optimisation surface convex, improvements still made every update.7.2 Updating Non-Extremal ComponentsOften, updates form equation (74) involve vectors oldoldcextremal components (i.e. components constraint-introduced limits).lead computational bottleneck update suggests componentslie outside allowed region result clipping procedure returningoriginal vectors.avoid consider two points update labelled c d,denote number non-extremal components Pc Pd respectively.update likely possible6 Pd > 1 Pc and, case, let Pd + Pc + 16. Otherwise one solution, current one.554fiA Framework Kernel-Based Multi-Category Classificationnon-extremal components grouped new vector . remaining elementsc dependent these. Owing linearity relationshipc , introduced constraint equation (17) becomes apparente + Ad c =e c + Ac=(75)e , Ad ,e c , Ac .e ce containdescribe dependencies,extremal components updated, together zeros, Ac Admatrices consisting ones zeros map variable components backoriginal positions vectors c . shown (Hill & Doucet, 2005, App.E), SMO update case is,= oldnew+(ATd VT (d )V(d )Ad )1 ATd VT (d )Kdd + Kcc 2Kdc(xc ) (xd ) + VT (d )(d ) VT (c )(c ) .(76)Again, clipping performed Subsection 7.1. Note expressionevaluations () actually change optimisation process. others, especiallymatrix-valued numerator may held memory speed procedure, possible.7.3 Point Selectionremains select points c d. Platt (1999), presents number heuristics, howeverimprovements suggested Keerthi, Shevade, Bhattacharyya, Murthy (2001) appearefficient form basis overviewed here. binary caseessential approach identify points requiring highest lowest offsets border underlying function f () might expected, i.e. signrelevant point. considering two classes, B multi-category arrangementdirectly analogous approach taken problem reduced two-classproblem across mutual boundary, comparable scalar metric found.starting point methodology construct Lagrangian governsdual optimisation problem given equation (13);NL=NNi=1i=1NXX1 XXTiTi (i )V (i )V(j )Tj K(xi , xj )2i=1 j=1+NXXi, (i, CD (i ))NXTi VT (i )i=1i=1 (i ){i, , i, : {1, . . . , N }, ( )} {m : {1, . . . , (M 1)}}Lagrangian multipliers. Differentiating respect setting result equalzero implies that,VT (i ) ((xi ) + ) = (i ) +(77)and, hence,= VT (i ) ((i ) + ) (xi ).555(78)fiHill & DoucetKKT conditions satisfied.combinations two classes (denoted B).Perform two-class SMO along direction vB (A)updates given equation (76) iup , ilow found (79)Table 1: Algorithm Pseudo-CodeConsider update two points classes B let = A, recallequality, discussed Keerthi et al. (2001), b. mind becomesapparent equivalent metric updating difference respectivevalues across boundary two classes. find perpendicular distance,take inner product perpendicular boundary, instance vB (A)vB(A) = B (A) + i,B i,B vB(A)(xi ).(79)expression directly comparable equivalent key starting point pointselection process directly analogous scalar used Keerthi et al. (2001). Indeed(A).parameters bup blow used equivalent extreme values vB7.4 Multi-Category SMO SummaryFollowing becomes possible put together complete approach;1. Select initial two classes consider denoted generically B.2. two classes determine two points maximum minimum values(A) equation (79). denotedvBilow respectivelycorrespond associated bup blow work Keerthi et al. (2001).3. Perform updates outlined equations (74) (76) convergencecriteria (e.g. updates threshold) achieved. Point selectionmade following standard two loop approach loop attempting updatepoints loop considering non-extremal ones. Updates attemptedrespect either iup ilow maximal minimal points updatediteration.4. convergence achieved two classes select another twoclasses repeat steps 2 3. possible combinations classesattempted.5. Repeat entire process updates made. point Karush-KuhnTucker (KKT) conditions nearly satisfied, checkedensure least within acceptable limit satisfaction.summarised pseudocode Table 1.approach clearly closely related structure pairwise coupling algorithm(Subsection 3.2) however single optimisation problem focus. Clearly556fiA Framework Kernel-Based Multi-Category Classificationalgorithm may computationally intense Kreel (1999) two reasons.First, stage updates involves matrix multiplications instead scalar ones. Second,indicated step 5, one pass may required. hand, mightreduction overall iterations required particular class-class combinationoptimisation starting scratch, rather updates previous combinationsmay positive impact.Experimentally however observed traditional pairwise coupling approach computationally efficient, also noted literature (Hsu& Lin, 2002; Rifkin & Klautau, 2004). alluded Subsection 3.2, combined approach possible, referred combined pairwise, all-together algorithm.Broadly, follows;1. Perform pairwise optimisation described Kreel (1999). optimisationrequires implementation (M2 1) standard SV classifiers slight changeinstead using standard 2-class value 1, use values correspondingparticular pairwise optimisation.2. Map results classification spatial arrangement (Figures 1 2 example).done easily observing product V(i )i equation (19)element i, multiplies v (i ) recall perpendicular boundary. result binary classification optimisationclasses used directly provide value i, . Noteconstraint equation (17) still satisfied.3. Finalise all-together single optimisation following steps outlined earlierSubsection.short bulk optimisation performed standard pairwise methodology.geometrical approach detailed Section 2 used manipulate outputunified consistent result obtained little additional computational effort.clear advantage practitioner sure exactly basisclassification made without resort ad hoc heuristics.8. ExamplesExtensive investigations comparative performance multi-category SVM methodsdetailed Hsu Lin (2002), present current benchmark trainingtimes. discussed, work found pairwise coupling approaches farcomputationally efficient others. also found case firstSMO algorithm proposed Subsection 7.4 main aim Section investigateperformance combined pairwise, all-together algorithm. standard binarydescribed multi-category SMO coded straightforward way. dynamiccaching low-level code refinements used initial proof-of-concept investigationfelt detailed optimisations best done together consistent way,dedicated comparative work Hsu Lin (2002).datasets used obtained University California repository (Blake &Merz, 1998). illustrative purposes training test output results DNA557fiHill & Doucetdataset presented Figure 9. clear see pairwise resultFound f(x) Final422f (x)022f (x)Found f(x), Initial Mapping42440220f1(x)24442422202442424Found f(x) Final4f (x)2f (x)Found f(x), Initial Mapping0f1(x)0220f (x)2414420f (x)1Figure 9: DNA data outputs training test data cases. mapped pairwiseoptimised all-together results shown. Margins analogous twoclass case clearly visible shown dashed lines. Training data formstop row, test data bottom. numerous, N case given greentriangles, EI blue circles, IE red squares. stars indicativeclass target vectors.mapped classification plane Figure 1, changes made performingall-together additional optimisation. short N class appears intermingled little EI class less IE class. well all-togetheroutputs fill corners margin intersections completely, pairwiseoutputs tend cut off. often observed implementations.training time heavily dependent tolerance within convergencedesired. value, referred Keerthi et al. (2001) indicates variation allowedbup blow discussed Subsections 7.3 7.4. effectadditionally investigated two values , results tabulated Tables 23. experiments Gaussian kernels used appropriate values Cchosen trial error output accuracies (where accuracy refers percentageclassification error rate) all-together implementation comparableHsu Lin (2002).actual accuracies recorded given Table, however recall that, notedSection 3.1, optimisation problem solved generic all-together one and,such, judicious choices C mean accuracy rates achievablealgorithms. Clearly implicit model behind pairwise approach slightlydifferent may indeed able achieve slightly different accuracy results.mind aim incessantly tweak hyperparameters achieve marginallysuperior results, simply look big picture performance.558fiA Framework Kernel-Based Multi-Category ClassificationProblemDNAVehicleSatimageSegmentVowelLetter34671126N20007664435207989115000Pair0.80.43.02.40.7129.0= 0.03CAlone1.11.52.75.310.841.813.247.93.513.3129.92119.2Pair1.10.53.63.21.0142.3= 0.001CAlone3.711.73.53.99.027.616.242.018.522.81373.75573.4Table 2: Optimisation times (seconds) various example problems. Columns present results obtained using pairwise algorithm all-together SMO algorithmdiscussed. cases Pair refers pairwise optimisation time results, meanwhile denotes additional refinement time i.e. required progresspairwise result all-together result. Finally Alone identifies time takenall-together algorithm without initial pairwise optimisation.ProblemDNAVehicleSatimageSegmentVowelLetter34671126N20007664435207989115000= 0.03CER(Pair) ER(All)4.44.615.018.810.610.83.02.63.03.08.88.8= 0.001CER(Pair) ER(All)4.64.517.520.09.79.23.03.03.03.08.98.8Table 3: Optimisation error rates (percentages) various example problems. Columnspresent experimentally obtained results using pairwise all-together multicategory SMO algorithms discussed. ER(Pair) refers test error ratepairwise method ER(All) all-together algorithm.continuing mindset, class weightings introduced, target vectors set equidistant. Clearly may well case could actuallyperturbed, class weights introduced improve performance, additionalcomputational effort, however initial investigation done.experiments run 2.8GHz P4 1GB RAM7 . Tables 2 3following points become apparent,1. optimisation times presented magnitudes similar HsuLin. Although aim work produce highly refined optimal code, although comparisons always going problematicterms implementation specifics, result is, itself, positive. Generally,accurate implementation algorithm presented preceding sections(when = 0.001C) convergence times similar Hsu Linall-together implementation. Briefly, optimisation times were; DNA, 13.5s,vehicle 88.6s, satimage 48.2s, segment 66.4s, vowel 14.1s, letter8786.2s. consider advantage obtained extra computational power roughly equivalent effect extra coding.7. Hsu Lin (2002) 500MHz P3 384MB RAM.559fiHill & Doucetworth noting additional intrinsic value intuitiveness, flexibilityease implementation presented algorithm, something standardSMO algorithm well known for. highlighted, additional computational effortrequired alter class regions introduce class weights (Subsection 2.3), neitherconsidered Hsu Lin (2002).2. possible approximately quantify relative effect combining pairwiseall-together algorithms context. short typically halves them, althoughvariation quite large. result appears roughly consistentvalues .3. anticipated, error rate results strongly favour pairwise all-togethermethods; always going case-by-case issue.9. Conclusiongeometric framework understanding multi-category classification introduced,many existing all-together algorithms understood. structureallows derivation parsimonious optimisation function, direct extensionbinary SV classification optimisation function. seen specialcase considerations need made order mathematics reduce standardresult number classes, = 2. Further, framework enables considerablegeneralisation problem incorporation relative class knowledge withoutadditional computational complexity. far actual optimisation results concerned,virtues proposed framework, fact, apply all-together methodswell.found Hsu Lin (2002) Rifkin Klautau (2004), among others,pairwise SV method converges substantial speed advantage existingmulti-category methods. However pairwise results require heuristic combine them.avoided mapping geometric framework described finetuning obtain consistent all-together solution. refining performedmulti-category all-together algorithm.ability framework compare algorithms illustrated briefdiscussion Fisher consistency. shown graphically illustrated different lossstructures compare result Fisher inconsistent optimisation problems.Generalisation bounds derived aim framework presentedtighter previously presented literature. also benefitedsimpler derivation previously presented due fact well-known scalarmethods developed two class case directly applicable. Previouslyneed extend cumbersome vector methods.addition providing generic flexible framework, architecture maywell provide insights regarding improve speed existing multicategory SV classification algorithms (whether coupled pairwise optimisation, not).initial example might achieved developed formulationstraightforward multi-category SMO variant algorithm. proof-of-concept experimentalresults shown this, combined mapping pairwise results, already560fiA Framework Kernel-Based Multi-Category Classificationcomparable optimisation speeds achieved Hsu Lin (2002) benchmarkwork, despite fact implementation code highly refined includes featuresdynamic caching. Future efforts based geometric framework describedable outperform existing standards.ReferencesAllwein, E. L., Schapire, R. E., & Singer, Y. (2001). Reducing multiclass binary: unifying approach margin classifiers. Journal Machine Learning Research, 1 (113-141).Bartlett, P. L. (1998). sample complexity pattern classification neural networks: size weights important size network. IEEETransactions Information Theory, 44 (2), 525536.Bartlett, P. L., Jordan, M. I., & McAuliffe, J. D. (2004). Large margin classifiers: Convexloss, low noise convergence rates. Advances Neural Information ProcessingSystems, 16.Blake, C. L., & Merz, C. J. (1998). UCI repository machine learning databases..http://www.ics.uci.edu/mlearn/MLRepository.html.Blanz, V., Scholkopf, B., Bulthoff, H., Burges, C. J. C., Vapnik, V. N., & Vetter, T. (1996).Comparison view-based object recognition algorithms using realistic 3D models.von der Malsburg, C., von Seelen, W., Vorbruggen, J. C., & Sendhoff, B. (Eds.),Artificial Neural Networks, Vol. 1112 Springer Lecture Notes Computer Science,pp. 251256, Berlin.Bredensteiner, E. J., & Bennett, K. P. (1999). Multicategory classification support vectormachines. Computational Optimizations Applications, 12, 5379.Crammer, K., & Singer, Y. (2001a). algorithmic implementation multiclasskernel-based vector machines. Journal Machine Learning Research, 2, 265292.Crammer, K., & Singer, Y. (2001b). Pranking ranking. Advances Neural Information Processing, Vol. 14.Cristianini, N., & Shawe-Taylor, J. (2000). Introduction Support Vector MachinesKernel-Based Learning Methods (1st edition). Cambridge University Press.Dietterich, T., & Bakiri, G. (1995). Solving multiclass learning problems via error-correctingoutput codes. Journal Artificial Intelligence Research, 2, 263286.Elisseeff, A., Guermeur, Y., & Paugam-Moisy, H. (1999). Margin error generalization capabilities multi-class discriminant systems. Tech. rep. NC2-TR-1999-051-R,NeuroCOLT2.Fung, G., & Mangasarian, O. L. (2001a). Multicategory proximal support vector machineclassifiers. Tech. rep. 01-06, Data Mining Institute.Fung, G., & Mangasarian, O. L. (2001b). Proximal support vector machine classifiers.Proceedings KDD-2001, pp. 7786, San Francisco.Furnkranz, J. (2002). Round robin classification. Journal Machine Learning, 2, 721747.561fiHill & DoucetGuermeur, Y. (2000). Combining discriminant models new multi-class SVMs. Tech.rep., NeuroCOLT2.Guermeur, Y. (2002). Combining discriminant models new multi-class SVMs. PatternAnalysis Applications, 5, 168179.Hastie, T., & Tibshirani, R. (1998). Classification pairwise coupling. Michael, M.J. K., Jordan, I., & Solla, S. A. (Eds.), Advances Neural Information Processing,Vol. 10, pp. 507513. MIT Press.Hastie, T., Tibshirani, R., & Friedman, J. (2001). Elements Statistical Learning.Springer.Herbrich, R., Graepel, T., & Campbell, C. (2000a). Bayes point machines. JournalMachine Learning Research, 1, 245279.Herbrich, R., Graepel, T., & Obermayer, K. (2000b). Large margin rank boundariesordinal regression. Advances Large Margin Classifiers, 1, 115132.Hill, S. I. (2007). Notes generalisation performance Fisher consistency multicategory classifiers. Tech. rep. CUED/F-INFENG/TR.583, Engineering Dept, University Cambridge.Hill, S. I., & Doucet, A. (2005). framework kernel-based multi-category classification.Tech. rep. CUED/F-INFENG/TR.508, Engineering Dept., University Cambridge.Hsu, C.-W., & Lin, C.-J. (2002). comparison methods multi-class support vectormachines. IEEE Transactions Neural Networks, 13, 415425.Keerthi, S. S., Shevade, S. K., Bhattacharyya, C., & Murthy, K. R. K. (2001). ImprovementsPlatts SMO algorithm SVM classifier design. Neural Computation, 13, 637649.Kindermann, J., Leopold, E., & Paa, G. (2000). Multi-class classification error correcting codes. Leopold, E., & Kirsten, M. (Eds.), Treffen der GI-Fachgruppe 1.1.3Maschinelles Lernen. GMD Report 114.Kreel, U. H.-G. (1999). Pairwise classification support vector machines. Scholkopf,B., Burges, C. J. C., & Smola, A. J. (Eds.), Advances Kernel Methods: SupportVector Learning. MIT Press.Lee, Y., Lin, Y., & Wahba, G. (2001). Multicategory support vector machines. Tech. rep.1043, Department Statistics, University Wisconsin.Lee, Y., Lin, Y., & Wahba, G. (2004). Multicategory support vector machines, theory,application classification microarray data satellite radiance data.Journal American Statistical Association, 99, 659672.Mangasarian, O. L., & Musicant, D. R. (2001). Lagrangian support vector machines. JournalMachine Learning Research, 1, 161177.Mayoraz, E., & Alpaydn, E. (1999). Support vector machines multi-class classification. Proceedings International Workshop Artifical Neural Networks(IWANN99).Paugam-Moisy, H., Elisseeff, A., & Guermeur, Y. (2000). Generalization performancemulticlass discriminant models..562fiA Framework Kernel-Based Multi-Category ClassificationPlatt, J. C. (1999). Fast training support vector machines using sequential minimaloptimization. Scholkopf, B., Burges, C. J. C., & Smola, A. J. (Eds.), AdvancesKernel Methods - Support Vector Learning, pp. 185208. MIT Press, Cambridge, MA.Platt, J. C., Cristianini, N., & Shawe-Taylor, J. (2000). Large margin DAGs multiclassclassification. Solla, S. A., Lean, T. K., & Muller, K.-R. (Eds.), Advances NeuralInformation Processing, Vol. 12, pp. 547553. MIT Press.Rennie, J. D. M., & Rifkin, R. (2001). Improving multiclass text classificationsupport vector machine. Memo AIM-2001-026, Massachusetts Institute TechnologyArtificial Intelligence Laboratory.Rifkin, R., & Klautau, A. (2004). defense one-vs-all classification. Journal MachineLearning Research, 5, 101141.Scholkopf, B., Burges, C. J. C., & Vapnik, V. N. (1995). Extracting support data giventask. Fayyad, U. M., & Uthurusamy, R. (Eds.), Proceedings, First InternationalConference Knowledge Discovery Data Mining, pp. 252257, Menlo Park, CA.AAAI Press.Scholkopf, B., & Smola, A. J. (2002). Learning Kernels. MIT Press.Sebald, D. J. (2000). Nonlinear Signal Processing Digital Communications using SupportVector Machines New Form Adaptive Decision Feedback Equalizer. Ph.D.thesis, University Wisconsin-Madison.Sebald, D. J., & Bucklew, J. A. (2001). Support vector machines multiple hypothesistest problem. IEEE Transactions Signal Processing, 49 (11), 28652872.Sejnowski, T. J., & Rosenberg, C. R. (1987). Parallel networks learn pronounceEnglish text.. Journal Complex Systems, 1, 145168.Suykens, J. A. K., & Vandewalle, J. (1999). Multiclass least squares support vector machines. Proceedings International Joint Conference Neural Networks(IJCNN99), Washington DC, USA.Tewari, A., & Bartlett, P. L. (2007). consistency multiclass classification methods.Journal Machine Learning Research, 8, 10071025.Van Gestel, T., Suykens, J. A. K., Baesens, B., Viaene, S., Vanthienen, J., Dedene, G.,De Moor, B., & Vandewalle, J. (2001). Benchmarking least squares support vectormachine classifiers. Machine Learning, 54 (1), 532.Van Gestel, T., Suykens, J. A. K., Lanckriet, G., Lambrechts, A., De Moor, B., & Vandewalle, J. (2002). Multiclass LS-SVMs: Moderated outputs coding-decodingschemes. Neural Processing Letters, 15, 4558.Vapnik, V. N. (1998). Statistical Learning Theory. Wiley.Wang, F., Vuurpijl, L. G., & Schomaker, L. R. B. (2000). Support vector machinesclassification western handwritten capitals. Schomaker, L. R. B., & Vuurpijl, L. G. (Eds.), Proceedings 7th International Workshop FrontiersHandwriting Recognition, pp. 167176.Weston, J. A. E. (1999). Extensions Support Vector Method. Ph.D. thesis, UniversityLondon.563fiHill & DoucetWeston, J. A. E., & Watkins, C. (1999). Support vector machines multi-class pattern recognition. Proceedings 7th European Symposium Artificial NeuralNetworks.Williamson, R. C., Smola, A. J., & Scholkopf, B. (2001). Generalization performanceregularization networks support vector machines via entropy numbers compactoperators. IEEE Transactions Information Theory, 47 (6), 25162532.Zhang, T. (2004a). infinity-sample theory multi-category large margin classification.Advances Neural Information Processing, 16.Zhang, T. (2004b). Statistical analysis multi-category large margin classification.Journal Machine Learning Research, 5, 12251251.564fiJournal Articial Intelligence Research 30 (2007) 659-684Submitted 06/07; published 12/07Learning Play Using Low-Complexity Rule-Based Policies:Illustrations Ms. Pac-ManIstvn SzitaAndrs Lrinczszityu@eotvos.elte.huandras.lorincz@elte.huDept. Information SystemsEtvs University, Hungary, H-1117Abstractarticle propose method deal certain combinatorial reinforcement learning tasks. demonstrate approach popular Ms. Pac-Man game.dene set high-level observation action modules, rule-based policiesconstructed automatically. policies, actions temporally extended, maywork concurrently. policy agent encoded compact decision list. components list selected large pool rules, either hand-craftedgenerated automatically. suitable selection rules learnt cross-entropymethod, recent global optimization algorithm ts framework smoothly. Crossentropy-optimized policies perform better hand-crafted policy, reach scoreaverage human players. argue learning successful mainly (i) policiesmay apply concurrent actions thus policy space suciently rich, (ii) searchbiased towards low-complexity policies therefore, solutions compact descriptionfound quickly exist.1. Introductionlast two decades, reinforcement learning (RL) reached mature state,laid solid foundations. large variety algorithms, including valuefunction-based, direct policy search hybrid methods. reviews subjects,see, e.g., books Bertsekas Tsitsiklis (1996) Sutton Barto (1998).basic properties many algorithms relatively well understood, e.g. conditionsconvergence, complexity, eect various parameters, although needless saystill lots important open questions. also plenty test problems(like various maze-navigation tasks, pole-balancing, car hill etc.)capabilities RL algorithms demonstrated, number large-scale RLapplications also growing steadily. However, current RL algorithms farout-of-the-box methods, still need demonstrations showing RLecient complex tasks.think games (including diverse set classical board games, card games, modern computer games, etc.) ideal test environments reinforcement learning. Gamesintended interesting challenging human intelligence therefore,ideal means explore articial intelligence still missing. Furthermore,games well RL paradigm: goal-oriented sequential decision problems,decision long-term eects. many cases, hidden information, randomevents, unknown environment, known unknown players account (part of) dicultyc 2007 AI Access Foundation. rights reserved.fiSzita & Lrinczplaying game. circumstances focus reinforcement learning. Gamesalso attractive testing new methods: decision space huge cases,nding good strategy challenging task.another great advantage using games test problems: rules gamesxed, danger `tailoring task algorithm' i.e., tweak rulesand/or environment meet capabilities proposed RL algorithmreduced, compared, e.g., various maze navigation tasks.RL tried many classical games, including checkers (Samuel, 1959), backgammon (Tesauro, 1994), chess (Baxter, Tridgell, & Weaver, 2001). hand,modern computer games got spotlight recently, manysuccessful attempts learn AI tools. Notable exceptions are, example, roleplaying game Baldur's Gate (Spronck, Sprinkhuizen-Kuyper, & Postma, 2003), real-timestrategy game Wargus (Ponsen & Spronck, 2004), possibly, Tetris (Szita & Lrincz,2006). games pose new challenges RL, example, many observationsconsidered parallel, observation space action space huge.spirit, decided investigate arcade game Ms. Pac-Man. gameinteresting largely unsolved, also imposes several important questionsRL, overview Section 8. provide hand-coded high-level actionsobservations, task RL learn combine good policy.apply rule-based policies, easy interpret enable one includehuman domain-knowledge easily. learning, apply cross-entropy method,recently developed general optimization algorithm. show hybrid approachsuccessful either tabula rasa learning hand-coded strategy alone.next section introduce Ms. Pac-Man game briey discussformalized reinforcement learning task. sections 3 4, shall shortly describecross-entropy optimization method rule-based policies, respectively. section 5,details learning experiments provided, section 6 present results.Section 7 provides review related literature, nally, section 8 summarizediscuss approach emphasis implications RL problems.2. Pac-Man Reinforcement Learningvideo-game Pac-Man rst released 1979, reached immense success.considered one popular video games date (Wikipedia, 2006).player maneuvers Pac-Man maze (see Fig. 1), Pac-Man eats dotsmaze. particular maze 174 dots,1 one worth 10 points. levelnished dots eaten. make things dicult, also fourghosts maze try catch Pac-Man, succeed, Pac-Man loses life.Initially, three lives, gets extra life reaching 10,000 points.four power-up items corners maze, called power dots (worth40 points). Pac-Man eats power dot, ghosts turn blue short period (15seconds), slow try escape Pac-Man. time, Pac-Man1. maze original Pac-Man game slightly dierent. description applies opensource Pac-Man implementation Courtillat (2001). two versions equivalent termscomplexity entertainment value.660fiLearning play Ms. Pac-ManFigure 1: snapshot Pac-Man gameable eat them, worth 200, 400, 800 1600 points, consecutively. pointvalues reset 200 time another power dot eaten, player would wanteat four ghosts per power dot. ghost eaten, remains hurry back centermaze ghost reborn. certain intervals, fruit appears near centermaze remains while. Eating fruit worth 100 points.investigations restricted learning optimal policy rst level,maximum achievable score 174 10 + 4 40 + 4 (200 + 400 + 800 + 1600) = 13900 plus100 points time fruit eaten.original version Pac-Man, ghosts move complex deterministic route,possible learn deterministic action sequence require observations.Many patterns found enthusiastic players. Pac-Man's sequels,notably Ms. Pac-Man, randomness added movement ghosts. way,single optimal action sequence, observations necessary optimal decisionmaking. respects, game play mostly unchanged.implementation, ghosts moved randomly 20% time straight towardsPac-Man remaining 80%, ghosts may turn back (following Koza, 1992, Chapter12). emphasize presence randomness, shall refer implementationMs. Pac-Man-clone.2.1 Ms. Pac-Man RL TaskMs. Pac-Man meets criteria reinforcement learning task. agent makesequence decisions depend observations. environment stochastic(because paths ghosts unpredictable). also well-dened reward function(the score eating things), actions inuence rewards collected future.661fiSzita & Lrinczfull description state would include (1) whether dots eaten (onebit dot one power dot), (2) position direction Ms. Pac-Man,(3) position direction four ghosts, (4) whether ghosts blue (one bitghost), so, long remain blue (in range 1 15 seconds) (5)whether fruit present, time left appears/disappears (6) numberlives left. size resulting state space astronomical, kind functionapproximation feature-extraction necessary RL.action space much smaller, four basic actions: go north/south/east/west. However, typical game consists multiple hundreds steps,number possible combinations still enormous. indicates need temporallyextended actions.moderate amount domain knowledge Ms. Pac-Man: one, quiteeasy dene high-level observations action modules potentially useful.hand, constructing well-performing policy seems much dicult. Therefore,provide mid-level domain knowledge algorithm: use domain knowledgepreprocess state information dene action modules. hand,role policy search reinforcement learning combine observations modulesrule-based policies nd proper combination.3. Cross-Entropy Methodgoal optimize rule-based policies performing policy search spacelegal rule-based policies. search apply cross-entropy method (CEM),recently published global optimization algorithm (Rubinstein, 1999). aims nd(approximate) solution global optimization tasks following formx := arg max f (x).xf general objective function (e.g., need assume continuity dierentiability). summarize mechanism method briey (see also section 7.2overview applications).3.1 Intuitive Descriptionoptimization algorithms maintain single candidate solution x(t) timestep, CEM maintains distribution possible solutions. distribution, solutioncandidates drawn random. essentially random guessing, nice trickturned highly eective optimization method.3.1.1 Power Random GuessingRandom guessing overly simple `optimization' method: draw many samplesxed distribution g , select best sample estimation optimum.limit case innitely many samples, random guessing nds global optimum.two notes here: (i) shown Wolpert Macready (1997),general problems, uniform random guessing worse method, (ii)nonetheless, practical problems, uniform random guessing extremely inecient.662fiLearning play Ms. Pac-ManThus, random guessing safe start with, one proceeds collectionexperience, limited much possible.eciency random guessing depends greatly distribution gsamples drawn. example, g sharply peaked around x , samplesmay sucient get good estimate. case opposite, distributionsharply peaked around x 6= x : tremendous number examples may needed getgood estimate global optimum. Naturally, nding good distribution leasthard nding x .3.1.2 Improving Efficiency Random Guessingdrawing moderately many samples distribution g , may able giveacceptable approximation x , may still obtain better sampling distribution.basic idea CEM selects best samples, modies gbecomes peaked around them. Consider example, x 0-1 vector gBernoulli distribution coordinate. Suppose drawn 1000 samplesselected 10 best. see majority selected samples, ith coordinate1, CEM shifts Bernoulli distribution corresponding component towards 1.Afterwards, next set samples drawn already modied distribution.idea seems plausible: majority best-scoring samples ith coordinate1, structure tness landscape, may hope ithcoordinate x also 1. follows, describe update rule CEMformal way sketch derivation.3.2 Formal Description Cross-Entropy Methodpick g family parameterized distributions, denoted G , describealgorithm iteratively improves parameters distribution g .Let N number samples drawn, let samples x(1) , . . . , x(N )drawn independently distribution g . R, set high-valued samples,L := {x(i) | f (x(i) ) , 1 N },provides approximation level setL := {x | f (x) }.Let U uniform distribution level set L . large values , distribution peaked around x , would suitable random sampling. raises twopotential problems: (i) large values L contain points (possibly none),making accurate approximation impossible, (ii) level set L usually memberparameterized distribution family.rst problem easy avoid choosing lower values . However,make compromise, setting low would inhibit large improvement steps.compromise achieved follows: CEM chooses ratio [0, 1] adjusts Lset best N samples. corresponds setting := f (x(N ) ), providedsamples arranged decreasing order values. best N samples calledelite samples. practice, typically chosen range [0.02, 0.1].663fiSzita & Lrinczproblem solved changing goal approximation: CEM choosesdistribution g distribution family G approximates best empirical distribution L . best g found minimizing distance G uniformdistribution elite samples. measure distance cross-entropy distance(often called Kullback-Leibler divergence). cross-entropy distance two distributionsg h denedZg(x)DCE (g||h) = g(x) logdxh(x)general form cross-entropy method summarized Table 1. knownmild regularity conditions, CE method converges probability 1 (Margolin,2004). Furthermore, suciently large population, global optimum foundhigh probability.input: Ginput: g0 Ginput: Ninput:input:0 1,1 N ,draw x(i) distribution gtcompute fi := f (x(i) )sort fi -values descending ordert+1 := fNEt+1 := {x(i) | f (x(i) ) t+1 }gt+1 := arg mingG DCE (g||Uniform(Et+1 ))end loop%%%%%%parameterized distrib. familyinitial distributionpopulation sizeselection rationumber iterationsCEM iteration main loop% draw N samples% evaluate% level set threshold% get elite samples% get nearest distrib. GTable 1: Pseudo-code general cross-entropy method3.3 Cross-Entropy Method Bernoulli Distributionmany parameterized distribution families, parameters minimum cross-entropymember computed easily simple statistics elite samples. provideformulae Bernoulli distributions, needed policy learning proceduredetailed next section. Derivations well list discrete continuousdistributions simple update rules found tutorial de Boer, Kroese,Mannor, Rubinstein (2004).Let domain optimization = {0, 1}m , component drawnindependent Bernoulli distributions, i.e., G = Bernoullim . distribution g G parameterized m-dimensional vector p = (p1 , . . . , pm ). using g sampling,664fiLearning play Ms. Pac-Mancomponent j sample x1, probability pj ;xj =0, probability 1 pj .drawing N samples x(1) , . . . , x(N ) xing threshold value , let E denote setelite samples, i.e.,E := {x(i) | f (x(i) ) }notation, distribution g 0 minimum CE-distance uniform distribution elite set following parameters:p0 := (p01 , . . . , p0m ),PP(i)(i)x(i) E (xj = 1)x(i) E (xj = 1)0P=pj :=Nx(i) E 1(1)words, parameters g 0 simply component wise empirical probabilities1's elite set. derivation rule, see tutorial de Boer et al. (2004).Changing distribution parameters p p0 coarse, cases,applying step-size parameter preferable. resulting algorithm summarizedTable 2.input: p0 = (p0,1 , . . . , p0,m )input: Ninput:input:0 1,1 N ,draw x(i) Bernoullim (pt )compute fi := f (x(i) )sort fi -values descending ordert+1 := fNEt+1 := {x(i) | f (x(i) ) t+1 }P(i)p0j :=x(i) E (xj = 1) /( N )pt+1,j := p0j + (1 ) pt,jend loop%%%%%initial distribution parameterspopulation sizeselection rationumber iterationsCEM iteration main loop% draw N samples% evaluate%%%%level set thresholdget elite samplesget parameters nearest distrib.update step-sizeTable 2: Pseudo-code cross-entropy method Bernoulli distributionsalso need optimize functions = {1, 2, . . . , K}m K > 2.simplest case, distributions domain parameterizedK parameters:PKp = (p1,1 , . . . , p1,K ; . . . ; pm,1 , . . . , pm,K ) 0 pj,k 1 k=1 pj,k = 1 j (thisspecial case multinomial distribution).update rule parameters essentially Eq. 1 Bernoulli case:PP(i)(i)(i) E (xj = k)x(i) E (xj = k)x0P=.(2)pj,k :=Nx(i) E 1665fiSzita & LrinczNote constraintPK0k=1 pj,k= 1 satised automatically j .4. Rule-Based Policiesbasic formulation, rule sentence form [Condition] holds,[Action]. rule-based policy set rules mechanism breaking ties, i.e.,decide rule executed, multiple rules satised conditions.Rule-based policies human-readable, easy include domain knowledge,able represent complex behaviors. reasons, often used manyareas articial intelligence (see section 7.3 short overview related literature).order apply rule-based policies Ms. Pac-Man, need specify four things:(1) possible actions (2) possible conditionsconstructed observations, (3) make rules conditions actions,(4) combine rules policies. answers described followingsections.4.1 Action Modulesdening action modules Ms. Pac-Man, listed modules easyimplement considered potentially useful (see Table 3). way, kept human work minimum, still managed formalize part domain knowledgeproblem. consequence, list action modules means optimal: actions could eective appropriate denition, othersmay superuous. example, four dierent modules ghost avoidance:FromGhost escapes nearest ghost, without considering positionghosts; ToLowerGhostDensity tries take account inuence multiple ghosts;FromGhostCenter moves geometrical center ghosts, thus, able avoidsurrounded trapped, but, hand, easily bump ghostso; nally, ToGhostFreeArea considers whole board search safelocation, agent avoid shepherded ghosts. modulesmay strengths weaknesses, possibly combination neededsuccess. also actions, potentially useful, listed(for example, moving towards fruit).Note also modules exclusive. example, escapingghosts, Ms. Pac-Man may prefer route dots eaten, may wanthead towards power dot. Without possibility concurrent actions, performanceMs. Pac-Man agent may reduced considerably (which investigated experimentalsection 5.3).need mechanism conict resolution, dierent action modules may suggest dierent directions. assigning priorities modules. agentswitches action module, also decides priority. also decision,learning decision part learning task.22. Action priorities learnt indirectly: rule xed priority, action switchedrule, also inherits priority. action switched dierent rulesdierent priorities. mechanism described detail section 4.6.666fiLearning play Ms. Pac-ManTable 3: List action modules used rule construction.NameDescriptionToDotToPowerDotFromPowerDotGo towards nearest dot.Go towards nearest power dot.Go direction opposite nearest powerdot.Go towards nearest edible (blue) ghost.Go direction opposite nearest ghost.Go towards maximally safe junction.four directions, safety nearest junction estimated direction. Ms. PacMan n steps away junctionnearest ghost k steps away, safetyvalue junction n k . negative valuemeans Ms. Pac-Man possibly cannot reachjunction.Go direction maximizes Euclideandistance geometrical center ghosts.Go current direction, chooserandom available action (except turning back)impossible.go direction cumulative ghostdensity decreases fastest. ghost denesdensity cloud (with radius = 10 linear decay), cumulative ghost densitycalculated.Choose location board minimum ghost distance largest, head towardsshortest path.ToEdGhostFromGhostToSafeJunctionFromGhostCenterKeepDirectionToLowerGhostDensityToGhostFreeArea667fiSzita & LrinczTable 4: List observations used rule construction. Distances denote lengthshortest path, unless noted otherwise. Distance particular object type +object exists moment.NameDescriptionConstantNearestDotNearestPowerDotNearestGhostNearestEdGhostMaxJunctionSafetyConstant 1 value.Distance nearest dot.Distance nearest power dot.Distance nearest ghost.Distance nearest edible (blue) ghost.four directions, safety nearestjunction direction estimated, deneddescription action ToSafeJunction.observation returns value maximally safe junction.Euclidean distance geometrical centerghosts.Euclidean distance geometrical centeruneaten dots.ghost denes density cloud (with radius= 10 linear decay). Returns valuecumulative ghost density.travelling salesman distance ghosts:length shortest route startsMs. Pac-Man reaches four ghosts (notconsidering movement).GhostCenterDistDotCenterDistGhostDensityTotalDistToGhostsimplemented following mechanism: decision agent concernsaction modules: agent either switch or, switch action module. is,principle, agent able use subset action modules, instead selectingsingle one time step. Basically, module highest priority decides directionMs. Pac-Man. one equally ranked directions, lower-prioritymodules checked. direction cannot decided checking switched-on modulesorder decreasing priority (for example, module switched on, two directionsranked equally switched-on modules), random direction chosen.Ms. Pac-Man make decisions time advances whole grid cell (themechanism ensures never stands still), according 25 game ticks approx. 0.2seconds simulated game time.4.2 Observations, Conditions RulesSimilarly actions, easily dene list observations potentially usefuldecision making. observations descriptions summarized Table 4.668fiLearning play Ms. Pac-ManModules could improved many ways, example, checking whetherenough time intercept edible ghosts calculating NearestEdGhost takingconsideration movement ghosts calculating NearestGhost, NearestEdGhostMaxJunctionSafety. kept implementation modules simple possible.designed reasonable modules, eort made make module denitionsoptimal, complete non-redundant.necessary tools dening conditions rule. typical conditiontrue observations given range. note status action modulealso important proper decision making. example, agent may decideghost close, switches modules except escape module. Thereforeallow conditions check whether action module `on' `o'.sake simplicity, conditions restricted form [observation]< [value], [observation] > [value], [action]+, [action]-, conjunctionterms. example,(NearestDot<5) (NearestGhost>8) (FromGhost+)valid condition rules.conditions actions, rules constructed easily. implementation, rule form [Condition], [Action]. example,(NearestDot<5) (NearestGhost>8) (FromGhost+)FromGhostCenter+valid rule.4.3 Constructing Policies RulesDecision lists standard forms constructing policies single rules.approach pursue here, too. Decision lists simply lists rules, togethermechanism decides order rules checked.rule priority assigned. agent make decision, checksrule list starting ones highest priority. conditions rule fullled,corresponding action executed, decision-making process halts.Note principle, priority rule dierent priority actionmodules. However, sake simplicity, make distinction: rule priorityk switches action module, priority action module also taken k .Intuitively, makes sense: important rule activated, eect alsoimportant. rule priority k switches module, executed, regardlesspriority module.may worth noting many possible alternatives ordering rulesactions:rule could xed priority, part provided domain knowledge(Spronck, Ponsen, Sprinkhuizen-Kuyper, & Postma, 2006).priority rule could free parameter learned CEMmethod.669fiSzita & LrinczInstead absolute priorities, agent could also learn relative ordering rules(Timuri, Spronck, & van den Herik, 2007).order rules could determined heuristic decision mechanism.example, generality rule e.g., rules few/many conditions large/small domains could taken account. heuristics used linearclassier systems (see e.g. work Bull & Kovacs, 2005)principle, one would like nd interesting solutions using computer minimalbias `domain knowledge'. regard, eciency simple priority management method satisfactory, experiment priority heuristics.4.4 ExampleLet us consider example shown Table 5. rule-based policy Ms. PacMan agent.Table 5: hand-coded policy playing Ms. Pac-Man. Bracketed numbers denotepriorities, [1] highest priority.[1][1][2][2][3][3][3][3]NearestGhost<4 FromGhost+NearestGhost>7 JunctionSafety>4 FromGhostNearestEdGhost>99 ToEdGhostNearestEdGhost<99 ToEdGhost+Constant>0 KeepDirection+FromPowerDot- ToPowerDot+GhostDensity<1.5 NearestPowerDot<5 FromPowerDot+NearestPowerDot>10 FromPowerDot-rst two rules manage ghost avoidance: ghost close, agentee, gets safe distance. Ghost avoidance priorityactivities. next two rules regulate edible ghostboard, agent chase (the value NearestEdGhost innity (> 99)edible ghosts, 41 board, are). activity alsorelatively high priority, eating ghosts worth lots points, must doneblueness ghosts disappears, must done quickly. fth rule saysagent turn back, directions equally good. rule preventsunnecessary zigzagging (while dots eaten), surprisingly eective.remaining rules tweak management power dots. Basically, agent prefers eatpower dot. However, blue ghosts board, power dot resetsscore counter 200, bad move. Furthermore, ghost density low aroundagent, probably hard collect ghosts, preferablewait eating power dot.670fiLearning play Ms. Pac-Man4.5 Mechanism Decision Makingmechanism decision making depicted Fig 2. short, (hidden) state-spaceworld Ms. Pac-Man Ghosts. dynamics (hidden) statespace determines vector observations, checked conditions.conditions rule satised, corresponding action module switched o.consequence, multiple actions may eect once. example, decision depictedFig. 2 sets two actions work together.Figure 2: Decision-making mechanism Ms. Pac-Man agent. time step t,agent receives actual observations state action modules.checks rules script order, executes rst rule satisedconditions.Initially, action module switched-o state. module switchedon, remains either explicitly switched another modulepriority switched replaces it.4.6 Learning Rule-Based Policies CEMapply CEM searching space rule-based policies. Learning composedthree phases: (1) generation random policies drawn according current parameterset, (2) evaluation policies, consists playing game Ms. Pac-Manmeasure score, (3) updating parameter set using CEM update rules.4.6.1 Drawing Random Scripts Predefined Rule-BaseSuppose predened rule-base containing K rules (for example, one listedAppendix A). policy rule slots. slot lled K rules,671fiSzita & Lrinczleft empty. result, policies could contain rules, possibly much less.rule slot xed priority, too, set {1, 2, 3}.3 priority rule slotchange learning. Learning can, however, push important rule high-priorityslot low-priority one, vice versa.1 m, slot lled rule rule-base probability pi ,left empty probability 1 pi . decided slotPKbe lled,particular rule j (1 j K ) selected probability qi,j , j=1 qi,j = 1slot {1, . . . , m}. result, policies could contain rules, possibly muchless. pi values qi,j values learnt simultaneously cross-entropymethod (Table 2), using update rules (1) (2), respectively. gives total+ K parameters optimize (although eective number parameters muchless, qi,j values unused slots irrelevant). Initial probabilities setpi = 1/2 qi,j = 1/K .4.6.2 Drawing Random Rules without Predefined Rule-Basestudied situations lessened domain knowledge; use predened rulebase. Script generation kept same, rule-base K rules generatedrandomly. case generated dierent rule-bases rule slots; lowratio meaningful rules counteracted increased rule variety.random rule random pair randomly drawn condition set randomlydrawn action. Random condition sets contained 2 conditions. random action constructed follows: action module selected uniformly set modules listedTable 3, switched probability 50%. construction random condition starts uniformly random selection module either Table 3 Table4. selected module action, condition [action]- [action]+equal probability. selected module observation, condition[observation]<[value] [observation]>[value] equal probability, [value]selected uniformly ve-element set. values set determined separately observation module follows: played 100 games using xed policyrecorded histogram values observation. Subsequently, ve-element setdetermined would split histogram regions equal area. example,value set NearestGhost {12, 8, 6, 5, 4}.design random rule generation procedure contains arbitrary elements (e.g.number conditions rule, number values observation comparedto). intuition behind procedure generate rules suciently versatile,ratio meaningless rules (e.g. rules unsatisable conditions) large.However, optimization form done point.5. Description ExperimentsAccording assumptions, eectiveness described architecture basedthree pillars: (1) human domain knowledge provided modules rules; (2)3. According preliminary experiments, quality learned policy improve increasingpriority set number slots.672fiLearning play Ms. Pac-Maneectiveness optimization algorithm; (3) possibility concurrent actions.Below, describe set experiments designed test assumptions.5.1 Full Architecturerst experiment, random rules used. construction, use modulesdened sections 4.1 4.2. second experiment, rules generated randomly,hand-coded. case, role learning determine rulesused.5.1.1 Learning Random Rule Constructionrst experiment, rule-base generated randomly, described section 4.6.2.number rule slots xed = 100 (priorities distributed evenly), onecontaining K = 100 randomly generated rules. values K selectedcoarse search parameter space.parameters CEM follows: population size N = 1000, selection ratio= 0.05, step size = 0.6.4 values fairly standard CEM,tried varying them. step, probabilities using rule slot (thatis, values pi , qi,j ) slightly decreased, using decay rate = 0.98.larger decay rate, useful rules also annulled often. hand, smallerdecay aect performance, many superuous rules left policies.score given policy huge variance due random factors game.Therefore, obtain reliable tness estimations, score policy averaged3 subsequent games. Learning lasted 50 episodes, sucient tuneprobability close either 0 1. performed 10 parallel training runs. experimenttype denoted CE-RandomRB.5.1.2 Learning Hand-Coded Rulessecond experiment constructed rule-base K = 42 hand-coded rules (shownAppendix A) thought potentially useful. could placed one= 30 rule slots.5 parameters experiment identical previousone. experiment type denoted CE-FixedRB.5.2 Eect Learning Algorithmfollowing experiment, compared performance CEM simple stochasticgradient optimization. single comparison sucient measure eciencyCEM; serves provide point reference. comparison relevant,algorithms similar complexity move gradually towardsbest samples found far. dierence SG maintains single solution4. Note per-episode learning rate. would correspond per-instance learning rate0 = /( N ) = 0.012 on-line learning algorithm.5. contrast previous experiment, rules meaningful potentially useful. Thereforeneed large pool rules, much lower used. found algorithmfairly insensitive choice m; signicant changes performance observed parametermodied factor 3.673fiSzita & Lrinczcandidate time, whereas CEM maintains distribution solutions. Thus, CEMmaintains memory solutions becomes less fragile occasional wrong parameterchanges.particular form stochastic gradient search following: initial policydrawn random (consisting 6 rules). that, generated 100 random mutationcurrent solution candidate step, evaluated obtained policies. bestperforming mutation chosen next solution candidate. Mutations generatedusing following procedure: (1) rule, condition changed random newcondition probability 0.05; (2) rule, action changed random newaction probability 0.05. listed parameter values (number rules policy, numbermutated policies, probabilities mutation) results coarse parameter-spaceoptimization.number episodes set 500. way, evaluated numberdierent policies (50,000) CEM experiments. random rule-basexed rule-base experiments repeated using stochastic gradient method, executing10 parallel training runs. resulting policies denoted SG-RandomRB SGFixedRB, respectively.5.3 Eect Parallel ActionsAccording assumptions, possibility parallel actions plays crucial rolesuccess architecture. conrm assumption, repeated previous experimentsconcurrent actions disabled. agent switches action module,action modules switched automatically. experiment types denotedCE-RandomRB-1action, CE-FixedRB-1action, SG-RandomRB-1action SGFixedRB-1action.5.4 Baseline Experimentsorder isolate assess contribution learning, performed two additionalexperiments dierent amounts domain knowledge learning. Furthermore,asked human subjects play game.5.4.1 Random Policiesrst non-learning experiment, used rule-base 42 hand-coded rules (identicalrule-base CE-FixedRB). Ten rules selected random, random prioritiesassigned them. measured performance policies constructed way.5.4.2 Hand-Coded Policysecond non-learning experiment, hand-coded rules priorities,is, hand-coded full policy. policy shown Table 5, constructedtrial-and-error. Naturally, policy constructed knowing resultslearning experiments.674fiLearning play Ms. Pac-ManTable 6: Ms. Pac-Man results. See text details. Abbreviations: CE: learningcross-entropy method, SG: learning stochastic gradient, randomRB:randomly generated rule-base, fixedRB: xed, hand-coded rule-base, 1action:one action module work time.MethodAvg. Score(25%/75% percentiles)638241355449(6147/6451)(6682/9369)(3356/5233)(4843/6090)CE-randomRB-1actionCE-fixedRB-1actionSG-randomRB-1actionSG-fixedRB-1action5417563122674415(5319/5914)(5705/5982)6(1770/2694)(3835/5364)Random policyHand-coded policyHuman play67675478064(140/940)(6190/9045)(5700/10665)CE-randomRBCE-fixedRBSG-randomRBSG-fixedRB81865.4.3 Human Playnal experiment, human subjects asked play rst level Ms. PacMan measured performance. subjects played Pac-Man and/orsimilar games before, none experienced player.6. Experimental ResultsHuman experiments performed rst level open-source Pac-Man cloneCourtillat (2001). experiments applied Delphi re-implementationcode.learning experiments, 10 parallel learning runs executed, one 50episodes. training period sucient tune probabilities close either 01, learned policy could determined unambiguously cases. obtainedpolicy tested playing 50 consecutive games, giving total 500 test games perexperiment. non-learning experiments agents played 500 test games, too, usingrandom policies hand-coded policy, respectively. human subject played 20games, giving total 100 test games. Results summarized Table 6. provide25% 75% percentile values instead variances, distribution scoreshighly non-Gaussian.6. fact average smaller 25% percentile caused highly skewed distributionscores. games, agent reached score range 5800 300, except gamesextremely low score. games aect 25% percentile lowered averagesignicantly.675fiSzita & Lrincz[1][1][2][2][2][3]NearestGhost<3 FromGhost+MaxJunctionSafety>3 FromGhostNearestEdGhost>99 ToPowerDot+NearestEdGhost<99 ToEdGhost+GhostDensity<1.5 NearestPowerDot<5 FromPowerDot+Constant>0 ToCenterofDots+Figure 3: Best policy learned CE-fixedRB. Average score 50 games: 9480.[1][1][1][2][2][2][3]MaxJunctionSafety>2.5 ToLowerGhostDensity- FromGhostNearestGhost<6 MaxJunctionSafety<1 FromGhost+NearestGhost>6 FromGhostCenter- ToEdGhost+ToEdGhost- CenterOfDots>20 ToEdGhost+ToEdGhost- NearestEdGhost<99 ToEdGhost+NearestDot>1 GhostCenterDist>0 KeepDirection+ToGhostFreeArea- ToDot- ToPowerDot+Figure 4: Best policy learned CE-randomRB. Average score 50 games: 7199.Note presence always-true (and thus, superuous) conditions likeToLowerGhostDensity-, FromGhostCenter-, ToGhostFreeArea- ToDot-.Fig. 3 shows best individual policy learned CE-fixedRB, reaching 9480 pointsaverage. Ghost avoidance given highest priority, turned ghostclose. Otherwise Ms. Pac-Man concentrates eating power dots subsequentlyeating blue ghosts. also takes care eat power dot blueghosts board, otherwise would miss opportunity eat 1600-pointghost (and possibly several others, too). lowest priority setting, agent looksordinary dots, although rule eect previous rules decidedirection (for example, endgame power dots left ghostsoriginal form).Policies learnt CE-randomRB behave similarly ones learnt CE-fixedRB,although behavior somewhat obscured superuous conditions and/or rules,demonstrated clearly example policy shown Fig. 4. noise generatedrandom rules, algorithm often fails learn correct priorities variousactivities.eect enabling/disabling concurrent actions also signicant. instructivetake look best policy learned CE-fixedRB-1action shown Fig. 5:agent concentrate eating ghosts, major source reward. However,cannot use modules necessary ghost avoidance long-term survival.results also show CEM performs signicantly better stochastic gradientlearning. believe, however, dierence could lowered thorough searchparameter space. SG many global optimization methods like evolutionarymethods simulated annealing could reach similar performances CEM. Accordingde Boer et al. (2004) applications cited section 7.2, advantage CEM676fiLearning play Ms. Pac-Man[2] NearestEdGhost>99 ToPowerDot+[2] NearestEdGhost<99 ToEdGhost+Figure 5: Best policy learned CE-fixedRB-1action. Average score 50 games:6041.maintains distribution solutions reach robust performancelittle eort, requiring little tuning parameters: canonical setparameters (0.01 0.1, 0.5 0.8, population large possible)performance method robust. claim coincides experiencesparameter-optimization process.Finally, interesting analyze dierences tactics humancomputer players. One fundamental tactic human players try lureghosts close Ms. Pac-Man ghosts close other. way,eaten fast turn blue. behavior evolvedexperiments. Besides, tactics CEM chance discover,lacking appropriate sensors. example, human player (and does) calculatetime remaining blue period, approximate future position ghosts,on.7. Related Literaturesection, review literature learning Pac-Man game, various components learning architecture: cross-entropy method, rule-based policies,concurrent actions.7.1 Previous Work (Ms.) Pac-ManVariants Pac-Man used previously several studies. direct comparisonperformances possible cases, however, simplied versionsgame used studies.Koza (1992) uses Ms. Pac-Man example application genetic programming.uses dierent score value fruit (worth 2000 points instead 100 points usedhere), shape board (and consequently, number dots) also dierent,therefore scores cannot directly compared. However, Koza reports (on p. 355)Pac Man could scored additional 9000 points captured four monstersfour occasions turned blue. score, one reported,translates approximately 5000 points scoring system.Lucas (2005) also uses full-scale Ms. Pac-Man game test problem. trainsneural network position evaluator hand-crafted input features. purposestraining, uses evolutionary strategy approach. obtained controller ablereach 4781 116 points, averaged 100 games.Bonet Stauer (1999) restrict observations 10 10 window centered Ms. PacMan, uses neural network temporal-dierence learning learn reactive con677fiSzita & Lrincztroller. series increasingly dicult learning tasks, able teach basicpellet-collecting ghost-avoidance behaviors greatly simplied versions game:used simple mazes containing power dots one ghost.Gallagher Ryan (2003) denes behavior agent parameterized nitestate automata. parameters learnt population-based incremental learning,evolutionary method similar CEM. run simplied version Pac-Man;single ghost power dots, takes away complexity game.Tiong (2002) codes rule-based policies Pac-Man hand, uses learningimprove them. tests, similarly ours, based Pac-Man implementationCourtillat (2001), limits number ghosts 1. best-performing rule setreaches 2164 points average maximal 2700. However, results likelyscale well increasing number ghosts: ghost eaten 1.4 timesaverage (out possible 4 times per game).77.2 Cross-Entropy Methodcross-entropy method Rubinstein (1999) general algorithm global optimizationtasks, bearing close resemblance estimation-of-distribution evolutionary methods (see e.g.paper Muehlenbein, 1998). areas successful application range combinatorial optimization problems like optimal buer allocation problem (Allon, Kroese, Raviv,& Rubinstein, 2005), DNA sequence alignment (Keith & Kroese, 2002) independent process analysis (Szab, Pczos, & Lrincz, 2006).cross-entropy method several successful reinforcement learning applications, too:Dambreville (2006) uses CEM learning input-output hierarchical HMM controlspredator agent partially observable grid world; Menache, Mannor, Shimkin (2005)use radial basis function approximation value function continuous maze navigation task, use CEM adapt parameters basis functions; nally, Mannor,Rubinstein, Gat (2003) apply CEM policy search simple grid world maze navigation problem. Recently, cross-entropy method also applied successfullygame Tetris Szita Lrincz (2006).7.3 Rule-Based Policiesrepresentation policies rule sequences widespread technique complex problems like computer games. example, many Pac-Man-related papers listeduse rule-based representation.Learning classier systems (Holland, 1986) genetic-algorithm based methodsevolve suitable rules given task. Bull (2004) gives excellent general overviewpointers references. Hayek machine Baum (1996) similar architecture,agents (corresponding simple rules) dene economical system: make bidsexecuting tasks hope obtain rewards. Schaul (2005) appliesarchitecture Sokoban game.Dynamic scripting (Spronck et al., 2006) another prominent example usinglearning rule-based policies. uses hand-coded rule-base reinforcement-learning7. Results cited section 3.6.678fiLearning play Ms. Pac-Manlike principle determine rules included policy. Dynamic scriptingsuccessful applications state-of-the-art computer games like role-playing gameNeverwinter Nights (Spronck et al., 2006) real-time strategy game Wargus (Ponsen& Spronck, 2004).7.4 Concurrent Actionstraditional formalizations RL tasks, agent select execute single actiontime. work known us handles concurrent actions explicitly Rohanimanesh Mahadevan (2001). formalize RL tasks concurrent actionsframework semi-Markov decision processes present simple grid world demonstrations.8. Summary Closing Remarksarticle proposed method learns play Ms. Pac-Man. denedset high-level observation action modules following properties: (i) actionstemporally extended, (ii) actions exclusive, may work concurrently.method uncover action combinations together priorities. Thus, agentpursue multiple goals parallel.decision agent concerns whether action module turned (ifo) (if on). Furthermore, decisions depend current observationsmay depend state action modules. policy agent representedlist if-then rules priorities. policies easy interpret analyze.also easy incorporate additional human knowledge. cross-entropy method usedlearning policies play well. Learning biased towards low-complexity policies,consequence policy representation applied cross entropy learningmethod. CEM, higher complexity solutions harder discover special meansused counteract premature convergence. solutions higher complexities,noise injection suggested previous work (Szita & Lrincz, 2006). Learnedlow complexity policies reached better score hand-coded policy average humanplayers.applied architecture potentials handle large, structured observation-action-spaces, partial observability, temporally extended concurrent actions. Despiteversatility, policy search eective, biased towards low-complexitypolicies. properties attractive point view large-scale applications.8.1 Role Domain Knowledgedemonstrating abilities RL algorithm, desirable learning startsscratch, contribution learning clearly measurable. However, choicestest problems often misleading: many `abstract' domains contain considerable amountdomain knowledge implicitly. example, consider grid world navigation tasks,often used class problems tabula rasa learning.simple version grid world navigation task, state integer uniquelyidenties position agent, atomic actions moves grid cells north/south/east/west actual cell. importantly, unique identication679fiSzita & Lrinczposition means moves agent change direction agenttask laboratory coordinate framework, sometimes called allocentric coordinates,egocentric coordinates. concepts north, south, etc. correspondhigh-level abstraction, meaning humans only, must consideredpart domain knowledge. domain knowledge provided us similar gridworld sense also provide high-level observations allocentric form,`distance nearest ghost d' `Ms. Pac-Man position (11, 2)'. Similarly, action `gonorth' action `go towards nearest power dot' essentially level.implicit presence high-level concepts becomes even apparent moveabstract MDPs `real world'. Consider robotic implementation mazetask: full state information, i.e. state well state environmentavailable robot. sees local features may see local featurestime. obtain exact position, move one unit's length prescribed direction,robot integrate information movement sensors, optical/radar sensors etc.information fusion, although necessary, topic reinforcement learning. Thus,task, great amount domain knowledge needs providedCE based policy search method could applied.opinion, role human knowledge selects set observationsactions suit learning algorithm. extra knowledge typically necessaryapplications. Nonetheless, numerous (more-or-less successful) approaches exist obtainingdomain knowledge automatically. According one approach, set observationschosen rich (and redundant) set observations feature selection method.cross-entropy method seems promising here, (see paper Szita, 2006,application feature selection brain fMRI data 2006 Pittsburgh Brain ActivityInterpretation Competition). According dierent approach, successful combinationslower level rules joined higher level concepts/rules. Machine learningpowerful tools here, e.g. arithmetic coding data compression (Witten, Neal, & Cleary,1987). applied many areas, including writing tool Dasher developed WardMacKay (2002). extensions included framework reinforcementlearning.8.2 Low-Complexity Policiesspace legal policies huge (potentially innite), interesting questionsearch eective huge space. Direct search formidable. thinkimplicit bias towards low-complexity policies useful studied here.low-complexity policy, mean following: policy may consist manyrules, cases, applied concurrently. Unused rulesget rewarded get punished unless limit useful rule, eective lengthpolicies biased towards short policies. implicit bias strengthened explicitone work: absence explicit reinforcement, probability applying ruledecays, indierent rules get wiped quickly. seems promising use frequent lowcomplexity rule combinations building blocks continued search powerfulstill low-complexity policies.680fiLearning play Ms. Pac-Manbias towards short policies reduces eective search space considerably. Moreover, many real-life problems, low-complexity solutions exist (for excellent analysispossible reasons, see paper Schmidhuber, 1997). Therefore, search concentratedrelevant part policy space, pays less attention complex policies (whichtherefore less likely according Occam's razor arguments.)AcknowledgmentsPlease send correspondence Andrs Lrincz. authors would like thank anonymous reviewers detailed comments suggestions improving presentationpaper. material based upon work supported partially European OceAerospace Research Development, Air Force Oce Scientic Research, Air ForceResearch Laboratory, Contract No. FA-073029. research also supportedEC FET grant, `New Ties project' contract 003752. opinions, ndingsconclusions recommendations expressed material authorsnecessarily reect views European Oce Aerospace Research Development, Air Force Oce Scientic Research, Air Force Research Laboratory, EC,members EC New Ties project.Appendix A. Hand-Coded Rule-Baselist rules hand-coded rule-base used experiments.12345678910111213141516171819202122232425Constant>0 ToDot+Constant>0 ToCenterofDots+NearestGhost<4 FromGhost+NearestGhost<3 FromGhost+NearestGhost<5 FromGhost+NearestGhost>5 FromGhostNearestGhost>6 FromGhostNearestGhost>7 FromGhostConstant>0 ToSafeJunction+MaxJunctionSafety<3 ToSafeJunction+MaxJunctionSafety<1 ToSafeJunction+MaxJunctionSafety>3 ToSafeJunctionMaxJunctionSafety>3 FromGhostMaxJunctionSafety>5 ToSafeJunctionMaxJunctionSafety>5 FromGhostConstant>0 KeepDirection+Constant>0 ToEdGhost+NearestGhost<4 ToPowerDot+NearestEdGhost<99 ToPowerDotNearestEdGhost<99 NearestPowerDot<5 FromPowerDot+NearestEdGhost<99 FromPowerDot+NearestEdGhost>99 FromPowerDotNearestEdGhost>99 ToPowerDot+GhostDensity>1 ToLowerGhostDensity+GhostDensity<0.5 ToLowerGhostDensity681fiSzita & Lrincz2627282930313233343536373839404142NearestPowerDot<2 NearestGhost<5 ToPowerDot+NearestGhost>7 MaxJunctionSafety>4 FromGhostGhostDensity<1.5 NearestPowerDot<5 FromPowerDot+NearestPowerDot>10 FromPowerDotTotalDistToGhosts>30 FromPowerDot+MaxJunctionSafety<3 FromGhost+MaxJunctionSafety<2 FromGhost+MaxJunctionSafety<1 FromGhost+MaxJunctionSafety<0 FromGhost+Constant>0 FromGhostCenter+NearestGhost<4 FromGhost+NearestGhost>7 MaxJunctionSafety>4 FromGhostNearestEdGhost>99 ToEdGhostNearestEdGhost<99 ToEdGhost+FromPowerDot- ToPowerDot+GhostDensity<1.5 NearestPowerDot<5 FromPowerDot+NearestPowerDot>10 FromPowerDot-ReferencesAllon, G., Kroese, D. P., Raviv, T., & Rubinstein, R. Y. (2005). Application crossentropy method buer allocation problem simulation-based environment.Annals Operations Research, 134, 137151.Baum, E. B. (1996). Toward model mind laissez-faire economy idiots.Proceedings 13rd International Conference Machine Learning, pp. 2836.Baxter, J., Tridgell, A., & Weaver, L. (2001). Machines learn play games, chap.Reinforcement learning chess, pp. 91116. Nova Science Publishers, Inc.Bertsekas, D. P., & Tsitsiklis, J. N. (1996). Neuro-Dynamic Programming. Athena Scientic.Bonet, J. S. D., & Stauer, C. P. (1999). Learning play Pac-Man using incrementalreinforcement learning.. [Online; accessed 09 October 2006].Bull, L. (2004). Applications Learning Classier Systems, chap. Learning Classier Systems: Brief Introduction, pp. 313. Springer.Bull, L., & Kovacs, T. (2005). Foundations Learning Classier Systems, chap. FoundationsLearning Classier Systems: Introduction, pp. 314. Springer.Courtillat, P. (2001). NoN-SeNS Pacman 1.6 C sourcecode.. [Online; accessed 09October 2006].Dambreville, F. (2006). Cross-entropic learning machine decision partiallyobservable universe. Journal Global Optimization. appear.de Boer, P.-T., Kroese, D. P., Mannor, S., & Rubinstein, R. Y. (2004). tutorialcross-entropy method. Annals Operations Research, 134, 1967.682fiLearning play Ms. Pac-ManGallagher, M., & Ryan, A. (2003). Learning play pac-man: evolutionary, rule-basedapproach. et. al., R. S. (Ed.), Proc. Congress Evolutionary Computation, pp.24622469.Holland, J. H. (1986). Escaping brittleness: possibilities general-purpose learningalgorithms applied parallel rule-based systems. Mitchell, Michalski, & Carbonell(Eds.), Machine Learning, Articial Intelligence Approach. Volume II, chap. 20,pp. 593623. Morgan Kaufmann.Keith, J., & Kroese, D. P. (2002). Sequence alignment rare event simulation. Proceedings 2002 Winter Simulation Conference, pp. 320327.Koza, J. (1992). Genetic programming: programming computers meansnatural selection. MIT Press.Lucas, S. M. (2005). Evolving neural network location evaluator play Ms. Pac-Man.IEEE Symposium Computational Intelligence Games, pp. 203210.Mannor, S., Rubinstein, R. Y., & Gat, Y. (2003). cross-entropy method fast policysearch. 20th International Conference Machine Learning.Margolin, L. (2004). convergence cross-entropy method. Annals OperationsResearch, 134, 201214.Menache, I., Mannor, S., & Shimkin, N. (2005). Basis function adaptation temporaldierence reinforcement learning. Annals Operations Research, 134 (1), 215238.Muehlenbein, H. (1998). equation response selection use prediction.Evolutionary Computation, 5, 303346.Ponsen, M., & Spronck, P. (2004). Improving adaptive game AI evolutionary learning.Computer Games: Articial Intelligence, Design Education.Rohanimanesh, K., & Mahadevan, S. (2001). Decision-theoretic planning concurrenttemporally extended actions. Proceedings 17th Conference UnceraintyArticial Intelligence, pp. 472479.Rubinstein, R. Y. (1999). cross-entropy method combinatorial continuousoptimization. Methodology Computing Applied Probability, 1, 127190.Samuel, A. L. (1959). studies machine learning using game checkers. IBMJournal Research Development, 6, 211229.Schaul, T. (2005). Evolving compact concept-based Sokoban solver. Master's thesis, colePolytechnique Fdrale de Lausanne.Schmidhuber, J. (1997). computer scientist's view life, universe, everything.Freksa, C., Jantzen, M., & Valk, R. (Eds.), Foundations Computer Science:Potential - Theory - Cognition, Vol. 1337 Lecture Notes Computer Science, pp.201208. Springer, Berlin.683fiSzita & LrinczSpronck, P., Ponsen, M., Sprinkhuizen-Kuyper, I., & Postma, E. (2006). Adaptive game aidynamic scripting. Machine Learning, 63 (3), 217248.Spronck, P., Sprinkhuizen-Kuyper, I., & Postma, E. (2003). Online adaptation computergame opponent AI. Proceedings 15th Belgium-Netherlands ConferenceArticial Intelligence, pp. 291298.Sutton, R. S., & Barto, A. G. (1998). Reinforcement Learning: Introduction. MIT Press,Cambridge.Szab, Z., Pczos, B., & Lrincz, A. (2006). Cross-entropy optimization independentprocess analysis. ICA, pp. 909916.Szita, I. (2006). select 100 voxels best prediction simplisticapproach. Tech. rep., Etvs Lornd University, Hungary.Szita, I., & Lrincz, A. (2006). Learning Tetris using noisy cross-entropy method. NeuralComputation, 18 (12), 29362941.Tesauro, G. (1994). TD-Gammon, self-teaching backgammon program, achieves masterlevel play. Neural Computation, 6 (2), 215219.Timuri, T., Spronck, P., & van den Herik, J. (2007). Automatic rule ordering dynamicscripting. Third Articial Intelligence Interactive Digital EntertainmentConference, pp. 4954.Tiong, A. L. K. (2002). Rule set representation tness functions articial pac manplaying agent. Bachelor's thesis, Department Information Technology ElectricalEngineering.Ward, D. J., & MacKay, D. J. C. (2002). Fast hands-free writing gaze direction. Nature,418, 838540.Wikipedia (2006). Pac-Man Wikipedia, free encyclopedia. Wikipedia. [Online;accessed 20 May 2007].Witten, I. A., Neal, R. M., & Cleary, J. G. (1987). Arithmetic coding data compression.Communications ACM, 30, 520540.Wolpert, D. H., & Macready, W. G. (1997). free lunch theorems optimization. IEEETransactions Evolutionary Computation, 1, 6782.684fiJournal Artificial Intelligence Research 30 (2007) 181-212Submitted 03/07; published 10/07Knowledge Derived WikipediaComputing Semantic RelatednessSimone Paolo PonzettoMichael StrubePONZETTO @ EML - RESEARCH . DESTRUBE @ EML - RESEARCH . DEEML Research gGmbH, Natural Language Processing GroupSchloss-Wolfsbrunnenweg 33, 69118 Heidelberg, Germanyhttp://www.eml-research.de/nlpAbstractWikipedia provides semantic network computing semantic relatedness structuredfashion search engine coverage WordNet. present experimentsusing Wikipedia computing semantic relatedness compare WordNet various benchmarking datasets. Existing relatedness measures perform better using Wikipedia baselinegiven Google counts, show Wikipedia outperforms WordNet datasets.also address question whether Wikipedia integrated NLP applicationsknowledge base. Including Wikipedia improves performance machine learning basedcoreference resolution system, indicating represents valuable resource NLP applications. Finally, show method easily used languages Englishcomputing semantic relatedness German dataset.1. Introductionadvances Natural Language Processing (NLP) made recently investigating data-driven methods, namely statistical techniques, believe advances cruciallydepend availability world domain knowledge. essential high-level linguistic tasks require language understanding capabilities question answering (e.g., Hovy,Gerber, Hermjakob, Junk, & Lin, 2001) recognizing textual entailment (Bos & Markert, 2005;Tatu, Iles, Slavick, Novischi, & Moldovan, 2006, inter alia). However, many domainindependent knowledge bases available provide large amount information namedentities (the leaves taxonomy) contain continuously updated knowledge processingcurrent information.article approach problem novel1 perspective making use widecoverage online encyclopedia, namely Wikipedia. use encyclopedia anyone editcompute semantic relatedness taking system categories Wikipedia semanticnetwork. way overcome well known knowledge acquisition bottleneck derivingknowledge resource large, collaboratively created encyclopedia. questionwhether quality resource high enough used successfully NLP applications.performing two different evaluations provide answer question.show Wikipedia derived semantic relatedness correlates well human judgments, alsoinformation used include lexical semantic information NLP application,namely coreference resolution, world knowledge considered important since early1. article builds upon extends Ponzetto Strube (2006a) Strube Ponzetto (2006).c2007AI Access Foundation. rights reserved.fiP ONZETTO & TRUBEresearch (Charniak, 1973; Hobbs, 1978), integrated recently means WordNet(Harabagiu, Bunescu, & Maiorano, 2001; Poesio, Ishikawa, Schulte im Walde, & Vieira, 2002).begin introducing Wikipedia measures semantic relatedness Section 2.Section 3 show semantic relatedness measures ported Wikipedia. evaluate approach using datasets designed evaluating measures Section 4.available datasets small seem assembled rather arbitrarily perform additionalextrinsic evaluation means coreference resolution system Section 5. Section 6 showrelatedness measures computed using Wikipedia easily ported languageEnglish, i.e. German. give details implementation Section 7, present related workSection 8 conclude future work directions Section 9.2. Wikipedia Semantic Relatedness Measuressection describe structure Wikipedia present measures use computingsemantic relatedness within categorization network.2.1 WikipediaWikipedia multilingual web based encyclopedia. collaborative open source medium,edited volunteers. Wikipedia provides large domain-independent encyclopedic repository. English version, 14 February 2006, contains 971,518 articles 18.4 millioninternal hyperlinks2 .text Wikipedia highly structured. Apart article pages formatted termssections paragraphs, various relations exists pages themselves. include:Redirect pages: pages used redirect query actual article page containinginformation entity denoted query. used point alternative expressionsentity article, accordingly models synonymy. Examples include CARSICKNESS3 redirecting AUTOMOBILE DISEASE pages respectively, wellU.S.A., U.S., USA, US, ESTADOS UNIDOS YANKEE LAND redirectingUNITED STATES page.Disambiguation pages: pages collect links number possible entities originalquery could pointed to. models homonymy. instance, page BUSH containslinks pages SHRUB, BUSH LOUISIANA, GEORGE H.W. BUSH GEORGE W.BUSH.Internal links: Articles mentioning encyclopedic entries point internal hyperlinks. models article cross-reference. instance, page PATAPHYSICS contains links term inventor, ALFRED JARRY, followers RAYMOND QUENEAU,well distinctive elements philosophy NONSENSICAL LANGUAGE.Since May 2004 Wikipedia provides also semantic network means categories: articles assigned one categories, categorized provide so-called2. Wikipedia downloaded http://download.wikimedia.org. experiments use EnglishGerman Wikipedia database dump 19 20 February 2006, except otherwise stated.3. following use Sans Serif words queries, CAPITALS Wikipedia pages MALL C APSconcepts Wikipedia categories.182fiK NOWLEDGE ERIVED F ROM W IKIPEDIACategoriesFundamentalInformationTechnologySystemsInformation systemsTop 10KnowledgeNatureSocietyThoughtScienceOrganizationsNatural sciencesInterdisciplinary fieldsAbstractionComputer scienceInformation scienceBeliefMathematicsPhilosophyApplied mathematicsComputational scienceLifeCyberneticsArtificial lifeBranches philosophyLogicMathematical logicBiologyMetaphysicsNeuroscienceCognitive scienceLinguisticsComputational linguisticsArtificial intelligenceArtificial intelligence applicationsCognitionCognitive architectureOntologyPataphysicsSpeech recognitionNatural language processingFigure 1: Wikipedia category network. top nodes network (C ATEGORIES , F UNDAMEN TAL , OP 10) structurally identical content bearing categories.category tree. practice, tree designed strict hierarchy, allows multiple categorization schemes coexist simultaneously. category system considered directed acyclicgraph, though encyclopedia editing software prevent users create cyclesgraph (which nevertheless avoided according Wikipedia categorization guidelines).Due flexible nature, refer Wikipedia category tree category network.February 2006, 94% articles categorized 103,759 categories. illustrationhigher regions hierarchy given Figure 1.strength Wikipedia lies size, could used overcome limited coveragescalability issues current knowledge bases. large size represents also challenge:search space Wikipedia category graph large terms depth, branching factormultiple inheritance relations. Problems arise also finding robust methods retrieving relevant183fiP ONZETTO & TRUBEinformation. instance, large amount disambiguation pages requires efficient algorithmdisambiguating queries, order able return desired articles.Since Wikipedia exists since 2001 considered reliable source information even shorter amount time (Giles, 2005), researchers NLP begun recentlywork content use resource. Wikipedia used successfully applications question answering (Ahn, Jijkoun, Mishne, Muller, de Rijke, & Schlobach, 2004;Ahn, Bos, Curran, Kor, Nissim, & Webber, 2005; Lo & Lam, 2006, inter alia), named entity disambiguation (Bunescu & Pasca, 2006), text categorization (Gabrilovich & Markovitch, 2006)computing document similarity (Gabrilovich & Markovitch, 2007).2.2 Taxonomy Based Semantic Relatedness MeasuresApproaches measuring semantic relatedness use lexical resources transform resourcenetwork graph compute relatedness using paths it. extensive overview lexicalresource-based approaches measuring semantic relatedness presented Budanitsky Hirst(2006).2.2.1 ERMINOLOGYSemantic relatedness indicates much two concepts semantically distant networktaxonomy using relations (i.e. hyponymic/hypernymic, antonymic, meronymickind functional relations including is-made-of, is-an-attribute-of, etc.). limitedhyponymy/hyperonymy (i.e. isa) relations, measure quantifies semantic similarity instead(see Budanitsky & Hirst, 2006, discussion semantic relatedness vs. semantic similarity).fact, two concepts related necessarily similar (e.g. cars gasoline, seeResnik, 1999). distinction holds lexical database WordNet,relations concepts semantically typed, cannot applied computing metricsWikipedia. category relations Wikipedia neither typed show uniformsemantics. Wikipedia categorization guidelines state categories mainly used browsesimilar articles. Therefore users assign categories rather liberally without makeunderlying semantics relations explicit.following, use generic term semantic relatedness, encompassesWordNet Wikipedia measures. However, noted applied WordNet,measures indicate semantic similarity, make use subsumption hierarchy.2.2.2 PATH BASED EASURESmeasures compute relatedness function number edges path twonodes c1 c2 words w1 w2 mapped to. Rada, Mili, Bicknell, Blettner (1989)traverse MeSH, term hierarchy indexing articles Medline, compute semantic distancestraightforwardly terms number edges terms hierarchy. Accordingly,semantic relatedness defined inverse score semantic distance (pl henceforth).Since edge counting approach relies uniform modeling hierarchy, researchersstarted develop measures computing semantic relatedness abstract problem.Leacock Chodorow (1998) propose normalized path-length measure takes accountdepth taxonomy concepts found (lch). Wu Palmer (1994) present184fiK NOWLEDGE ERIVED F ROM W IKIPEDIAinstead scaled measure takes account depth nodes together depthleast common subsumer (wup).2.2.3 NFORMATION C ONTENT BASED EASURESmeasure Resnik (1995) computes relatedness concepts functioninformation content, given probability occurrence corpus (res). Relatedness modeled extent [the concepts] share information, given informationcontent least common subsumer. Similarly path-length based measures, elaborate measure definitions based information content later developed. includesmeasures Jiang Conrath (1997) Lin (1998), hereafter referred respectivelyjcn lin, shown correlate better human judgments Resniksmeasure.2.2.4 EXT OVERLAP BASED EASURESLesk (1986) defines relatedness two words function text (i.e. gloss) overlap.extended gloss overlap (lesk) measure Banerjee Pedersen (2003) computes overlapscore extending glosses concepts consideration include glosses relatedconcepts hierarchy. Given two glosses g1 g2 taken definitions words w1 w2 ,Poverlap score overlap(g1 , g2 ) computed n m2 n phrasal m-word overlaps (Banerjee& Pedersen, 2003). overlap score computed using non-linear function, occurrenceswords text collection known approximate Zipfian distribution.3. Computing Semantic Relatedness WikipediaWikipedia based semantic relatedness computation described following Subsections:1. Retrieve two unambiguous Wikipedia pages pair words, w1 , w2 (e.g. kingrook) refer to, namely pages = {p1 , p2 } (Section 3.1).2. Connect category network parsing pages extracting two sets categoriesC1 = {c1 | c1 category p1 } C2 = {c2 | c2 category p2 } pages assigned(Section 3.2).3. Compute set paths pairs categories two pages, namely paths ={pathc1 ,c2 | c1 C1 , c2 C2 } (Section 3.2).4. Compute semantic relatedness based two pages extracted (for text overlap based measures) paths found along category network (for path length information content based measures) (Section 3.3).3.1 Page Retrieval DisambiguationGiven pair words, w1 w2 , page retrieval page p accomplished1. querying page titled word w,2. following redirects (e.g. CAR redirecting AUTOMOBILE),185fiP ONZETTO & TRUBE3. resolving ambiguous page queries. due many queries Wikipedia returningdisambiguation page. instance, querying king returns Wikipedia disambiguation pageKING, points pages including MONARCH, KING (CHESS), KING KONG,KING-FM (a broadcasting station), B.B. KING (the blues guitarist) MARTIN LUTHERKING.choose approach disambiguation maximizes relatedness, namely let pagequeries disambiguate (see Figure 2). disambiguation page p1 querying word w1hit, first get hyperlinks page p2 obtained querying word w2 withoutdisambiguating. bootstrap disambiguation process, since could casequeries ambiguous, e.g. king rook. take word w2 Wikipediainternal links page p2 lexical association list L2 = {w2 } {l2 | l2 link p2 } useddisambiguation i.e., use term list {rook, rook (chess), rook (bird), rook (rocket),. . . } disambiguating page KING. Links rook (chess) split extract labelparentheses i.e., rook (chess) splits rook chess. link p1 containsoccurrence disambiguating term l2 L2 (i.e. link KING (CHESS) KING pagecontaining term chess extracted ROOK page), linked page returned (KING(CHESS)), else return first article linked disambiguation page (MONARCH).disambiguation strategy provides less accurate solution following disambiguationpage links. Nevertheless realizes practical solution many pages contain largenumber links (e.g. 34 13 KING ROOK pages respectively).3.2 Category Network SearchGiven pages p1 p2 , extract lists categories C1 C2 belong (i.e.KING (CHESS) ROOK (CHESS) belong C HESS PIECES category). Given categorysets C1 C2 , category pair hc1 , c2 i, c1 C1 , c2 C2 look paths connectingtwo categories c1 c2 . perform depth-limited search maximum depth 4least common subsumer. additionally limit search category level greater2, i.e. consider levels 0 2 (where level 0 represented topnode C ATEGORIES Figure 1). noticed limiting search improves results.probably due upper regions Wikipedia category network strongly connected(see Figure 1). Accordingly, value search depth established system prototypingfinding depth search value maximizes correlation relatedness scoresbest performing Wikipedia measure human judgments given datasets MillerCharles (1991) Rubenstein Goodenough (1965).3.3 Relatedness Measure ComputationFinally, given set paths found category pairs, compute network basedmeasures selecting paths satisfying measure definitions, namely shortest pathpath-based measures path informative least common subsumer informationcontent based measures.order apply Resniks measure Wikipedia couple intrinsic information content measure relying hierarchical structure category network (Seco, Veale, & Hayes,2004), rather computing information content probabilities occurrence186fiK NOWLEDGE ERIVED F ROM W IKIPEDIAfunction GET-PAGES(w1 , w2 ) returns pages1: pages {}2: pages pages GET-UNAMBIGUOUS-PAGE(w1 , w2 )3: pages pages GET-UNAMBIGUOUS-PAGE(w2 , w1 )4: return pagesfunction GET-UNAMBIGUOUS-PAGE(w1 , w2 ) returns page1: page getArticleT itled(w1 )2: page redirection page3:page f ollowRedirect(page)4: end5: page disambiguation page6:l0 first link pageotherP age getArticleT itled(w2 ),L1 = {l1 | l1 link page}L2 = {w2 } {l2 | l2 link otherP age}7:li L18:lj L29:MATCHES?(li ,lj )10:page getArticleT itled(li ), goto (5)11:end12:end13:end14:page getArticleT itled(l0 )15: end16: return pagefunction MATCHES?(l1 , l2 ) returns true false1: T1 SPLIT-BY-PARENTHESIS(l1 )T2 SPLIT-BY-PARENTHESIS(l2 )2: ti T13:tj T24:ORTHOGRAPHICALLY-MATCHES(ti , tj )5:return true6:end7:end8: end9: return falseFigure 2: Algorithm Wikipedia page retrieval disambiguation187fiP ONZETTO & TRUBEconcepts corpus. Seco et al. (2004) show method correlates better human judgments original approach Resnik (1995). intrinsic information content category node n hierarchy given function child nodes, namelyic(n) = 1log(hypo(n) + 1)log(C)(1)hypo(n) number hyponyms node n C equals total number conceptualnodes hierarchy.Gloss overlap measures computed article pages, since relevant text givencategory pages. order adapt Lesk measure Wikipedia (Equation 2), gloss overlapmeasures (gloss) computed first paragraph pages. relatedness score givenapplying double normalization step overlap score. first normalize sum textlengths take output value hyperbolic tangent function order minimizerole outliers skewing score distribution.overlap(t1 , t2 )lesk wikipedia(t1 , t2 ) = tanhlength(t1 ) + length(t2 )(2)4. Experimentssection describes evaluation methodology based experiments word pair lists.compare performance WordNet Wikipedia based relatedness measures datasetsextensively used literature standard benchmark tests. addition,evaluate performance relatedness measures derived Wikipedia using different versions online encyclopedia February May 2007.4.1 Experiments Englishevaluate relatedness measures four standard datasets, namely Miller Charles (1991)list 30 noun pairs (hereafter referred M&C), Rubenstein Goodenoughs (1965) 65 wordpair synonymity list (R&G) M&C subset, WordSimilarity-353 Test Collection(353-TC) Finkelstein, Gabrilovich, Matias, Rivlin, Solan, Wolfman, Ruppin (2002)4 ,finally 2,682 pairs nominal subset (KLEB) reader based lexical cohesiondataset Beigman Klebanov Shamir (2006). 353-TC dataset partitionedtraining testing subsets, experiment full list (353 word pairs) testdata subset (153 pairs). Similarly, KLEB dataset contains relatively large amount nounpairs, split two 50-50% partitions performing machine learning based experimentslearning relatedness words.4.1.1 E VALUATIONFollowing literature semantic relatedness, evaluate performance taking Pearsonproduct-moment correlation coefficient r relatedness measure scores corresponding human judgments. dataset report correlation computed pairs (all).case word pairs least one words could found lexical resource4. Available http://www.cs.technion.ac.il/gabr/resources/data/wordsim353/wordsim353.html.188fiK NOWLEDGE ERIVED F ROM W IKIPEDIADatasetM&CR&G353-TCfull353-TCtestKLEBfullKLEBtestnon-missnon-missnon-missnon-missnon-missnon-missGooglejaccard0.330.330.220.220.080.080.100.100.020.020.030.03WordNet 2.1wuplchres0.770.82 0.780.770.82 0.780.820.86 0.810.820.86 0.810.300.34 0.340.320.36 0.350.280.35 0.380.300.38 0.390.150.15 0.180.150.15 0.180.150.14 0.180.150.14 0.18pl0.720.720.780.780.280.270.290.280.070.100.060.09lesk0.370.370.350.350.210.210.210.210.140.140.160.16pl0.470.500.510.530.450.450.500.500.290.300.310.31Wikipedia (February 2006)wuplchresgloss0.430.450.230.460.490.490.290.470.500.520.300.460.540.550.340.470.480.490.380.210.480.490.390.210.550.570.460.230.550.570.460.230.280.300.180.130.290.310.190.130.300.320.190.150.310.320.180.15SVM0.620.38Table 1: Results correlation human judgments relatedness measures(i.e. WordNet Wikipedia) relatedness score set 0. addition, report correlationscore obtained disregarding pairs containing missing words (non-miss). baseline,compute word pair w1 w2 Google correlation coefficient taking Jaccardsimilarity coefficient (Salton & McGill, 1983) page hits.jaccard =Hits(w1 w2 )Hits(w1 ) + Hits(w2 ) Hits(w1 w2 )co-occurrence distributional similarity measure serves baseline. choose Jaccardsimilarity coefficient combinatorial measure take accountactual word distributions (Lee, 1999) here, take Google hits.models also usage similarity coefficients, e.g. van Rijsbergen (1979) showsDice Jaccards coefficients monotonic other.4.1.2 E XPERIMENTAL SETTINGExperiments performed measure datasets. 353-TC KLEB,experiment integrating different measures performing regression using Support Vector Machine (Vapnik, 1995) estimate functional dependence human relatedness judgmentsmultiple relatedness scores. learner trained tested using available Google, WordNetWikipedia scores. used RBF kernel degree 3. Feature selection performedfind optimal feature space using genetic algorithm (Mierswa, Wurst, Klinkenberg, Scholz,& Euler, 2006) cross-validation training data. addition, performed modelselection optimal parameter estimation grid search (Hsu, Chang, & Lin, 2006).4.1.3 ISCUSSIONTable 1 shows correlation coefficients different measures human judgments. Bestperformance per dataset highlighted bold5 . WordNet Wikipedia perform better5. Differences performance statistically significant 95% significance level (p = 0.05). computing statistical significance performed paired t-test dataset pairs corresponding relatedness measures (e.g.WordNet Wikipedia path measures). Additionally, performed test WordNetWikipedia measure Google baseline, SVM combined measure best performingmeasure 353-TC KLEB test datasets. statistically non-significant differences performancefound lesk Wikipedia gloss measure M&C dataset.189fiP ONZETTO & TRUBEGoogle baseline. WordNet performs extremely well M&C R&G datasets,performance drastically decreases applied 353-TC KLEB datasets. Wikipediahowever perform well M&C R&G datasets outperforms WordNet353-TC KLEB. case KLEB full dataset, report performance competitivestate-of-the-art WordNet based measure (information content induced taxonomy glossinformation, Beigman Klebanov, 2006). due coverage, 353-TC dataset2 pairs containing least one word present WordNet, amount13 Wikipedia. KLEB dataset 114 pairs missing WordNet 150 missingWikipedia. problems seem caused rather sense proliferation WordNet. measuresfact computed looking possible sense pairs given words (as word sensesgiven), taking best scoring (e.g. shortest, informative) path. allows unplausiblepaths returned. noted however caused WordNet itself,provide sense coverage, rather relatedness measures. fact, sense disambiguationapart one performed measures possible. Using Wikipedia pagesentry points, access page texts hyperlinks, used disambiguatesubsequently limit focus search. example, using fertility disambiguate egg,correctly return Wikipedia page OVUM, whereas shortest path WordNet makes usesecond sense egg, namely oval reproductive body fowl (especially hen) used food.addition problem sense proliferation, WordNet seems suffer principlelink proliferation problem, e.g., shortest path egg fertility traverses hierarchyone root nodes (i.e. E NTITY). One could suggest limit search WordNetWikipedia, though noted supposed taken care measuresthemselves, e.g. scaling depth path nodes.Besides, Wikipedia performs better WordNet present experimental setting353-TC KLEB datasets model semantic relatedness, rather similarity. WordNet measures used (all except lesk) instead designed quantify similarity, thus yieldingpoor performance. supported 353-TC annotation guidelines, define similarity belonging domain representing features concept, wellBeigman Klebanov (2006) reporting competitive results (Pearson correlation coefficient r =0.47) WordNet-based relatedness measure. 353-TC contains also highly rated word pairscell phone energy crisis closely related, since tend occur frequently together, similar, share properties all. Finally, additional supportgiven fact competitive results given Wikipedia KLEB dataset,specifically designed relatedness mind (Beigman Klebanov & Shamir, 2006).Finkelstein et al. (2002) suggest integrating word-vector based relatedness measureWordNet based one useful, accounts word co-occurrences helps recoveringcases words cannot found available resources, e.g. dictionary ontology.Accordingly, 353-TC KLEB test sets report best performance integratingavailable measures performing feature selection. 353-TC data, score r =0.62 outperforms combined WordNetword-vector measure Finkelstein et al. (2002) (r =0.55), well score r = 0.38 KLEB test data outperforming score r =0.32 obtained using best performing (Wikipedia-based) relatedness measure (lch). Insteadintegrating word-vector based relatedness measure WordNet based one, results indicatecompetitive performance achieved also using different knowledge baseWikipedia.190fiK NOWLEDGE ERIVED F ROM W IKIPEDIAanalysis above, one could conclude Wikipedia yields better relatedness scoresWordNet applied datasets designed evaluate relatedness words. practice,believe extremely difficult perform fair comparison two knowledge sourceslimiting application small datasets. addition, always clear linguisticnotion (i.e. similarity vs. relatedness) underlies datasets (cf. 353-TC). reasonperform additional experiments making use datasets synonymity tests80 TOEFL (Landauer & Dumais, 1997), 50 ESL (Turney, 2001) 300 Readers Digest WordPower Game (Jarmasz & Szpakowicz, 2003) questions. datasets pose also problem sincecontain verbs, unlikely found encyclopedic resource Wikipedia.reasons evaluate Section 5 approach applying real-world NLPtask, namely coreference resolution, relatedness hundreds thousands wordpairs computed, thus providing reliable evaluation.4.2 Evaluation Wikipedia Throughout TimeOne appealing features Wikipedia provides large coverage knowledge base, also shows quasi-exponential growth respect number articles(Table 2)6 . evaluated whether growth rate affects methodology computingrelatedness words. experiments word pairs datasets, using Wikipedia Englishdatabase dump 19 February 2006, repeated using dumps 25 September 200627 May 2007. performance Wikipedia-based relatedness measures M&C,R&G, 353-TC KLEB datasets presented Tables 3 4. highlighted Figure 3,notable differences performance different Wikipedia versions M&CR&G dataset. Nevertheless simple one-tailed paired sample t-test 0.05 level revealsnone variations different Wikipedia versions statistically significant. Qualitativeanalysis reveals improvements due queries getting correctly disambiguated i.e.lad correctly disambiguates BOY September 2006 May 2007 Wikipedia, ratherSECT, February version LAD disambiguation page contains SECT firstlink used disambiguation occurring Lad sub-sect Jainist Digambara sect.differences accidental easily spotted significance test.WordNet 2.1#word-sense pairs/#articles#synsets/#categories207,016117,597English WikipediaFeb. 06Sep. 06May 07971,518 1,403,207 1,803,843103,759165,744244,376Table 2: Statistics WordNet Wikipediaresults show method robust (thus replicable) disregarding Wikipedia version. However, observe improvement despite quasi-exponential growthWikipedia, articles added Wikipedia provide crucial information respect experiments.6. See instance http://en.wikipedia.org/wiki/Wikipedia:Modelling Wikipedias growth.191fiP ONZETTO & TRUBEDatasetM&CR&G353-TCfull353-TCtestKLEBfullKLEBtestnon-missnon-missnon-missnon-missnon-missnon-misspl0.590.630.570.600.470.480.520.520.260.280.270.29wup0.540.610.590.650.490.500.570.570.260.280.260.29Wikipedialchres0.58 0.310.64 0.410.60 0.300.66 0.370.51 0.350.53 0.360.60 0.490.61 0.490.27 0.130.29 0.150.28 0.140.31 0.17gloss0.580.600.520.540.250.260.260.260.110.110.120.13SVM0.620.37Table 3: Correlation Wikipedia scores (September 2006) human judgmentsDatasetM&CR&G353-TCfull353-TCtestKLEBfullKLEBtestnon-missnon-missnon-missnon-missnon-missnon-misspl0.570.570.580.580.480.480.540.540.310.320.280.29wup0.540.540.580.580.520.520.630.630.310.330.290.30Wikipedialchres0.57 0.310.57 0.310.61 0.380.61 0.380.53 0.410.54 0.410.64 0.600.64 0.600.33 0.190.34 0.200.30 0.180.31 0.18gloss0.550.550.530.530.200.200.220.220.100.100.110.11SVM0.660.37Table 4: Correlation Wikipedia scores (May 2007) human judgments5. Case Study: Coreference Resolutionextend machine learning based coreference resolver features capturing different semantic knowledge sources. features represent relatedness scores mined WordNetWikipedia. Coreference resolution provides application evaluate performance relatedness measures previously evaluated using datasets limited size. extrinsic evaluation provides better insight usefulness Wikipedia relatedness measures NLP applications intrinsic evaluation described Section 4.5.1 Machine Learning Based Coreference Resolution Semantic Knowledgelast years seen boost work devoted development machine learning basedcoreference resolution systems (Soon, Ng, & Lim, 2001; Ng & Cardie, 2002; Yang, Zhou, Su,& Tan, 2003; Luo, Ittycheriah, Jing, Kambhatla, & Roukos, 2004, inter alia). machinelearning proved yield performance rates fully competitive rule based systems, currentcoreference resolution systems mostly relying rather shallow features, distancecoreferent expressions, string matching, linguistic form. shallow featuressufficient correctly identifying many coreferential relations expressions192fiK NOWLEDGE ERIVED F ROM W IKIPEDIACorrelation coefficient (Pearson r)0.70.8M&CR&G353-TC full353-TC test353-TC SVMKLEB fullKLEB testKLEB SVM0.7Correlation coefficient (Pearson r)0.80.60.50.40.30.2Jan 06M&CR&G353-TC full353-TC test353-TC SVMKLEB fullKLEB testKLEB SVM0.60.50.40.3Mar 06May 06Jul 06Sep 06Nov 06Jan 07Mar 07May 07Jul 070.2Jan 06Mar 06May 06Jul 06Wikipedia database dumpSep 06Nov 06Jan 07Mar 07May 07Jul 07Wikipedia database dump(a) pairs(b) Non-missing pairsFigure 3: Performance variation Wikipedia-based relatedness measures throughout timetext. example, consider fragment Automatic Content Extraction (ACE) 2003data.frequent visitors say given sheer weight countrys totalitarian ideologygenerations mass indoctrination, changing countrys course something akinturning huge ship sea. Opening North Korea up, even modestly, exposing peopleidea Westerners South Koreans devils, alone represents extraordinarychange. [...] people begin get clearer idea deprivation suffered,especially relative neighbors. society focusedstability, [...].order correctly resolve coreferent expressions highlighted bold (which annotatedcoreferent ACE data), lexical semantic encyclopedic knowledge required, i.e.,North Korea country, countries consist people societies. resolutionrequires knowledge base (e.g. generated Wikipedia) look-up reasoning contentrelatedness holding different expressions (e.g. path measure along linksWordNet Wikipedia semantic networks). following explore scenario includingknowledge mined WordNet Wikipedia coreference resolution. start machinelearning based baseline system taken Ponzetto Strube (2006b), includes setshallow linguistic features Soon et al. (2001) well semantic parsing information termssemantic role labeling (Gildea & Jurafsky, 2002; Carreras & Marquez, 2005, SRL henceforth),analyze performance variations given including previously discussed relatednessmeasures feature set. overview system present remainder sectiongiven Figure 4.5.2 Coreference Resolution Using Semantic Knowledge Sourcessubsection presents coreference resolution system uses semantic relatedness featuresinduced WordNet Wikipedia capture information knowledge sources.193fiPreprocessingpipelineRawtextBaseline feature extractor(Ponzetto Strube, 2006b)PoS taggerSemantic featureChunkerNERextractorMaxEntclassifierText annotatedcoreference chainsP ONZETTO & TRUBEWordNetWikipediaSEMANTICSFigure 4: Overview coreference resolution system extrinsic evaluation WordNetWikipedia relatedness measures. start baseline system PonzettoStrube (2006b) includes features Soon et al. (2001) semantic roleinformation. include different times features WordNet Wikipediaregister performance variations.5.2.1 C ORPORA U SEDestablish competitive coreference resolver, system initially prototyped using MUC6 MUC-7 data sets (Chinchor & Sundheim, 2003; Chinchor, 2001), using standard partitioning 30 texts training 20-30 texts testing. Then, developed tested systemACE 2003 Training Data corpus (Mitchell, Strassel, Przybocki, Davis, Doddington, Grishman, Meyers, Brunstain, Ferro, & Sundheim, 2003)7 . Newswire (NWIRE) Broadcast News (BNEWS) sections split 60-20-20% document-based partitions training,development, testing, later per-partition merged (MERGED) system evaluation.distribution coreference chains referring expressions given Table 5.5.2.2 L EARNING LGORITHMlearning coreference decisions, used Maximum Entropy (Berger, Della Pietra, & Della Pietra, 1996) model, implemented using MALLET library8 . Coreference resolution viewedbinary classification task: given pair REs, classifier decide whether coreferent not. MaxEnt model produces probability category (coreferent not)candidate pair, conditioned context x candidate occurs. conditionalprobability calculated by:7. used training data corpus only, availability test data restricted ACE participants. Therefore,results report cannot compared directly using official test data.8. http://mallet.cs.umass.edu194fiK NOWLEDGE ERIVED F ROM W IKIPEDIATRAIN.DEVELTESTTOTALTOTAL (%)TRAIN.DEVELTESTTOTALTOTAL (%)#coref chains5872012281,016BNEWS (147 docs 33,479 tokens)#pronouns#common nouns #proper names876 (36.1%)572 (23.6%)980 (40.3%)315 (33.4%)163 (17.3%)465 (49.3%)291 (30.7%)238 (25.1%)420 (44.2%)1,4829731,86534.3%22.5%43.2%#coref chains9043993541,657NWIRE (105 docs 57,205 tokens)#pronouns#common nouns1037 (24.3%)1210 (28.3%)358 (20.3%)485 (27.5%)329 (21.6%)484 (31.7%)1,7242,17922.8%28.8%#proper names2023 (47.4%)923 (52.2%)712 ( 46.7%)3,65848.4%Table 5: Partitions ACE 2003 training data corpus"#1 Xfi (x, y)p(y|x) =Zxfi (x, y) value feature outcome context x, weight associatedmodel. Zx normalization constant. features used model binaryvalued feature functions (or indicator functions), e.g.fWIKI PL (WIKI PL = 0.1, COREF) =1 candidate pair coreferentsemantic relatedness lexicalheads 0.1 using pl measure0 otherwiseuse L-BFGS algorithm (Malouf, 2002) estimate parameters Maximum Entropymodel. prevent model overfitting, employ tunable Gaussian prior smoothingmethod. Training performed using multi-conditional learning (McCallum, Pal, Druck, & Wang,2006), state-of-the-art hybrid method combining generative discriminative methods modelparameter estimation.apply set preprocessing components including POS tagger (Gimenez & Marquez,2004), NP chunker (Kudoh & Matsumoto, 2000) Alias-I LingPipe Named Entity Recognizer9 text order identify noun phrases, taken referring expressions (REs) used instance generation. Therefore, use automatically extracted nounphrases, rather assuming perfect NP chunking. contrast related workscoreference resolution (e.g., Luo et al., 2004; Kehler, Appelt, Taylor, & Simma, 2004).Instances created following Soon et al. (2001). create positive training instancepair adjacent coreferent REs. Negative instances obtained pairing anaphoric9. http://alias-i.com/lingpipe195fiP ONZETTO & TRUBEREs occurring anaphor antecedent. testing textprocessed left right: paired preceding right left, pairlabeled coreferent output, beginning document reached. classifier imposespartitioning available REs clustering set expressions labeled coreferentcoreference chain.5.2.3 BASELINE YSTEM F EATURESFollowing Ng Cardie (2002), core baseline system reimplements Soon et al. (2001)system. system uses twelve features. Given potential antecedent REi potential anaphorREj features computed follows10 .(a) Lexical features1. STRING MATCH REi REj spelling, else F.2. ALIAS one alias other; else F.(b) Grammatical features3. PRONOUN REi pronoun; else F.4. J PRONOUN REj pronoun; else F.5. J DEF REj starts the; else F.6. J DEM REj starts this, that, these, those; else F.7. NUMBER REi REj agree number; else F.8. GENDER U either REi REj undefined gender. Else definedagree T; else F.9. PROPER NAME REi REj proper names; else F.10. APPOSITIVE REj apposition REi ; else F.(c) Semantic features11. WN CLASS U either REi REj undefined WordNet semantic class. Elsedefined one T; else F.(d) Distance features12. DISTANCE many sentences REi REj apart.addition 12 features Soon et al. (2001), employ SRL features taken Ponzetto Strube (2006b). Semantic roles taken output ASSERT parser (Pradhan,Ward, Hacioglu, Martin, & Jurafsky, 2004), SVM based semantic role tagger uses fullsyntactic analysis automatically identify verb predicates sentence together semantic arguments, output PropBank arguments (Palmer, Gildea, & Kingsbury, 2005).10. Possible values U(nknown), T(rue) F(alse). Note contrast Ng Cardie (2002) interpret ALIASlexical feature, solely relies string comparison acronym string matching.196fiK NOWLEDGE ERIVED F ROM W IKIPEDIAoften case semantic arguments output parser align previously identified noun phrases. case, pass semantic role label twophrases share head. Labels form ARG1 pred1 . . . ARGn predn n semanticroles filled constituent, semantic argument label always defined respectpredicate. Given level semantic information available level, introduce twonew features.(e) SRL features13. SEMROLE semantic role argument-predicate pairs REi .14. J SEMROLE semantic role argument-predicate pairs REj .ACE 2003 data, 11,406 32,502 automatically extracted noun phrases tagged2,801 different argument-predicate pairs. baseline feature set obtained startingfeatures Soon et al. (2001), plus SRL features, removing selected usingbackward feature selection (see Subsection 5.3.2).5.2.4 W ORD N ET F EATURESWN CLASS feature baseline system noisy, lack coverage,sense proliferation ambiguity11 . accordingly enrich semantic information availableclassifier using semantic similarity measures based WordNet taxonomy (Pedersen,Patwardhan, & Michelizzi, 2004). measures use include path length based measures (Radaet al., 1989; Wu & Palmer, 1994; Leacock & Chodorow, 1998), well ones based informationcontent (Resnik, 1995; Jiang & Conrath, 1997; Lin, 1998).case, measures obtained computing similarity scores headlemmata (for common nouns, e.g. house) full NPs (for named entities, e.g. George W. Bush)potential antecedent-anaphor pair. order deal sense disambiguation problem,factorize possible sense pairs: given candidate pair, take cross productantecedent anaphor sense form pairs synsets. measure WN SIMILARITY,compute similarity score synset pairs, create following features.15. WN SIMILARITY BEST highest similarity score hSENSEREi ,n , SENSEREj ,msynset pairs.16. WN SIMILARITY AVG average similarity score hSENSEREi ,n , SENSEREj ,msynset pairs.Pairs containing REs cannot mapped WordNet synsets assumed maximallydissimilar, i.e. similarity score set 0.5.2.5 W IKIPEDIA F EATURESinclude features derived Wikipedia. Pages paths retrieved following proceduredescribed Section 3. case WordNet, query head lemmata common nounsfull NPs named entities. Given candidate coreference pair REi/j disambiguated11. Following Soon et al. (2001) mapped first WordNet sense head noun.197fiP ONZETTO & TRUBEWikipedia pages pREi/j point to, obtained querying pages titled tREi/j , extractfollowing features:17. I/J GLOSS CONTAINS U Wikipedia page titled tREi/j available. Else firstparagraph text pREi/j contains tREj/i ; else F.18. I/J RELATED CONTAINS U Wikipedia page titled tREi/j available. Elseleast one Wikipedia hyperlink pREi/j contains tREj/i ; else F.19. I/J CATEGORIES CONTAINS U Wikipedia page titled tREi/j available. Elselist categories pREi/j belongs contains tREj/i ; else F.20. GLOSS OVERLAP overlap score first paragraph text pREi pREjcomputed using Equation 2.Additionally, use Wikipedia category graph. use relatedness measures describedSubsections 2.2.2 2.2.3. Given pREi/j lists categories CREi/j belong to,factorize possible category pairs. is, take cross product antecedentanaphor category form pairs Wikipedia synsets. measure WIKI RELATEDNESS,compute relatedness score category pairs, create following features.21. WIKI RELATEDNESS BEST highest relatedness score hCREi ,n , CREj ,m category pairs.22. WIKI RELATEDNESS AVG average relatedness score hCREi ,n , CREj ,m category pairs.5.3 Experiments5.3.1 P ERFORMANCE ETRICSreport following tables MUC score (Vilain, Burger, Aberdeen, Connolly, & Hirschman,1995). Scores Table 6 computed noun phrases appearing either key systemresponse, whereas Tables 7 8 refer scoring phrases appear keyresponse. therefore discard responses present key, referringexpressions annotated ACE 2003 data belong categories Person (i.e. humans), Organization (e.g. corporations, agencies), Facility (i.e. buildings), Location (e.g. geographical areaslandmasses) Geo-political entities (i.e. nations, regions, government people, cf.North Korea example above)12 . makes impossible perform full coreference resolutionincluding, e.g. identification referential expressions, implies results establishupper limit improvements given semantic features.also report accuracy score three types ACE mentions, namely pronouns, common nouns proper names. Accuracy percentage REs given mention type correctlyresolved divided total number REs type direct antecedent givenkey. said correctly resolved direct antecedent identify mentionsbelong coreference class key.12. Cf. ACE 2003 Entity Detection Tracking (EDT) Annotation Guidelines available http://projects.ldc.upenn.edu/ace/docs/EDT-Guidelines-V2-5.pdf: identify mentions animalsinanimate objects time.198fiK NOWLEDGE ERIVED F ROM W IKIPEDIAoriginalSoon et al.duplicatedbaselineR58.664.9MUC-6PF167.3 62.365.665.3R56.1MUC-7PF165.5 60.455.168.561.1Table 6: Results MUC5.3.2 F EATURE ELECTIONdetermining relevant feature sets follow iterative procedure similar wrapperapproach feature selection (Kohavi & John, 1997) using development data. featureselection algorithm performs hill-climbing search along feature space. case baseline system perform backward feature selection, since interested obtaining minimalfeature set provides competitive baseline13 . start model basedavailable features (Ponzetto & Strube, 2006b). train models obtained removing onefeature time. choose worst performing feature, namely one whose removal giveslargest improvement based MUC score F-measure development data, removemodel. train classifiers removing remaining features separatelyenhanced model. process iteratively run long significant improvement observed.evaluating WordNet Wikipedia features, perform instead forward greedy featureselection: start minimal set previously kept baseline features iteratively addfeatures WordNet Wikipedia give best MUC score F-measure improvementdevelopment data selection step. interested evaluatingadditional contribution information, avoid external factors improvements dueremoval baseline features. summary features selected backwardforward feature selections given Table 9.5.3.3 R ESULTSTable 6 compares results duplicated Soon et al. (2001) baseline originalsystem MUC data. assume slight improvements system dueuse current preprocessing components another classifier. Tables 7 8 show comparisonperformance baseline system (Ponzetto & Strube, 2006b) ones incremented semantic features mined WordNet Wikipedia ACE data. Statisticallysignificant performance improvements highlighted bold14 .13. assumption adding SRL features core baseline features Soon et al. (2001) couldyield best performance. practice, analysis feature selection development data highlightsSoon et al.s (2001) features J DEM, PROPER NAME WN CLASS (BNEWS), J DEM (NWIRE)DISTANCE (MERGED) indeed removed baseline feature set SRL information included. Nonebest performing features Soon et al. (2001) (STRING MATCH, ALIAS APPOSITIVE) removed,thus supporting feature relevance analysis (pp. 534535).14. take performance variations different experimental runs statistically significant case changesMUC F-measure statistically significant 0.05 level higher. follow Soon et al. (2001)performing simple one-tailed, paired sample t-test baseline systems MUC score F-measuresystems F-measure scores test documents.199fiP ONZETTO & TRUBEbaseline+WordNet+WikipediaR50.559.158.3P82.082.481.9BNEWSF1Ap62.5 44.268.8 43.168.1 41.2Acn17.440.938.9Apn58.064.662.3R56.362.460.7P86.781.481.8NWIREF1Ap68.3 43.870.7 45.469.7 44.1Acn35.043.040.1Apn71.668.771.6Table 7: Results ACE 2003 data (BNEWS NWIRE sections)baseline+WordNet+WikipediaR54.560.659.4P85.479.482.2F166.568.768.9Ap40.542.438.9Acn30.143.241.4Apn73.066.074.5Table 8: Results ACE (merged BNEWS/NWIRE)5.3.4 ISCUSSIONtables show semantic features improve system recall, rather acting semantic filterimproving precision. Semantics therefore seems trigger response cases shallowfeatures seem suffice. one-tailed, paired sample t-test reveals BNEWSMERGED sections difference performance WordNet Wikipedia statistically significant (p < 0.05), thus proving Wikipedia indeed competitive WordNetcoreference resolution scenario.WordNet Wikipedia features tend consistently increase performance common nounsdataset partitions. WordNet features able improve 23.5%, 8% 13.1% accuracy rate common nouns BNEWS, NWIRE MERGED datasets (+35, +28 +65correctly resolved common nouns 149 349 498 respectively), whereas employingWikipedia yields slightly smaller improvements (+21.5%, +5.1% +11.3% accuracy increasedatasets). accuracy common nouns shows features derived Wikipediacompetitive ones WordNet. performance gap three datasets relativelysmall, indicates usefulness using encyclopedic knowledge base replacementlexical taxonomy.semantic relatedness clearly helps common nouns, always improve performance proper names, features string matching alias suffice, cf. performance degradation induced WordNet NWIRE MERGED datasets. suggestssemantic information use tends play role mostly common noun resolution,surface features cannot account complex preferences semantic knowledge required. Nevertheless, Wikipedia exhibits general better performance resolution proper namesWordNet, yields results always least good baseline. surprising, Wikipedia contains larger amount information named entities WordNet.particular, qualitative analysis development data shows Wikipedia useful instanceidentifying cases REs coreferent geo-political discourse entity, e.g. YemeniYemen American United States, thanks feature redirection, i.e. YEMENIredirects YEMEN. linguistic point view far clear whether casesrepresent genuine cases coreference, redirection helps cover meronymy.200fiK NOWLEDGE ERIVED F ROM W IKIPEDIAbackwardfeatureselectionforwardfeatureselectionstartingfeaturesremovedWordNetfeaturesaddedWikipediafeaturesaddedBNEWSWN CLASSPROPER NAMEJ DEMjcn averagejcn bestpl bestwup averagewup averagepl bestpl averageglossNWIREMERGEDJ DEMDISTANCEjcn bestlin averagepl bestlch bestpl bestpl averagewup averagelch bestpl bestpl averageTable 9: Feature selectionFeature selection improves results15 . due fact full feature set extremely redundant: order explore usefulness knowledge sources included overlapping features (i.e. using best average similarity/relatedness measures time),well features capturing phenomenon different points view (i.e. using multiplemeasures time). order yield desired performance improvements, turnsessential filter irrelevant features. instance, case Wikipedia noneI/J GLOSS, RELATED CATEGORIES CONTAINS features survives feature selection process (see Table 9). hand, cases WordNet Wikipedia least onebest one average measure always included among selected features. suggestsincluding information available senses (in terms average relatedness measures) provides sensible information handle ambiguity. Finally, multiple measures includedselected feature sets, e.g. selected features WordNet BNEWS data includemeasure Wu Palmer (1994) one Jiang Conrath (1997), indicatingrather best overall measure, competitive results obtained integratingdifferent ones.6. Experiments GermanExcept Gurevych (2005) ported semantic relatedness measures German using GermaNet(Lemnitzer & Kunze, 2002), topic semantic relatedness explored almost exclusivelyEnglish language using WordNet. Research semantic relatedness languagesEnglish hindered differences structure organization respectivewordnets large variation coverage. instance, Gurevych Niederlich (2005a)implement API specifically designed GermaNet access. Furthermore, GermaNet muchsmaller WordNet even cover word pairs relatively small dataset providedRubenstein Goodenough (1965) Gurevych Niederlich (2005b) translatedGerman. contrast, structure organization Wikipedia across languages,semantic relatedness measures developed English applied languages15. experienced system prototyping simply including full feature set without performing featureselection gave worst significant performance variations all.201fiP ONZETTO & TRUBEGermaNet 4.0#word-sense pairs/#articles#synsets/#categories60,64641,777German WikipediaFeb. 06Jun. 06 Sep. 06387,586 410,586 471,06525,03528,65633,130Table 10: Statistics GermaNet Wikipediawithout changing methods accessing them. coverage German Wikipedia alsoconsiderably large shown Table 10.knowledge exist datasets evaluating semantic relatedness measures languages English. Gurevych translated dataset Rubenstein Goodenough(1965) German supplied judgments native speakers German. Gurevych (2005)evaluated several semantic relatedness measures R&G dataset using GermaNet knowledgesource. GermaNet cover words 65 word pairs report results57 word pairs best results obtained res followed lin. Table 11 adopt resultsreported Gurevych supply numbers computed 65 word pairs includingones covered GermaNet. case results given Table 1, word pairsleast one words could found GermaNet assigned relatedness score016 .numbers obtain experiments using Wikipedia compare well numbersreported. contrast results English R&G dataset, Wikipedia performs goodGermaNet considering pairs viz., statistically significant difference using one-tailedpaired sample t-test (p < 0.05) respective best performing measures, GermaNet linWikipedia wup shows performance slightly considering available pairsonly. German R&G dataset one Wikipedia shows best overall performance,one larger coverage corresponding wordnet (4 missingpairs versus 8).previously pointed analysis performance 353-TC English dataset,Wikipedia able yield competitive performance datasets specifically designed capturesemantic relatedness, rather stricter notion similarity. seems supportedpresent scenario well, data Gurevych Niederlich (2005b) rated explicitlysemantic relatedness, using definition Budanitsky Hirst (2006) summarizedSection 2.2.1.7. Implementation DetailsWikipedia freely available download, accessed using robust Open Source applications, e.g. MediaWiki software17 , integrated within Linux, Apache, MySQL PHP (LAMP)software bundle. briefly present following main components Application Programming Interface (API) developed part present work18 . architectureWikiRelate! API (Ponzetto & Strube, 2007a) consists following modules:16. complete list German word pairs corresponding human judgments automatically computedmeasures obtained Gurevych Niederlich (2005b).17. http://www.mediawiki.org18. WikiRelate! software downloaded http://www.eml-research.de/nlp.202fiK NOWLEDGE ERIVED F ROM W IKIPEDIADatasetnon-missR&GGooglejaccard0.260.26GermaNet 4.0linres lesk0.66 0.64 0.490.73 0.76 0.53Wikipedia (February 2006)plwup lchres gloss0.58 0.65 0.64 0.62 0.330.62 0.70 0.69 0.67 0.34Wikipedia (June 2006)0.65 0.64 0.58 0.330.69 0.69 0.62 0.35non-miss0.580.61non-missWikipedia (September 2006)0.59 0.65 0.64 0.50 0.380.63 0.70 0.69 0.55 0.40Table 11: Results German R&G Dataset1. RDBMS: lowest level, encyclopedia content stored relational databasemanagement system (e.g. MySQL).2. MediaWiki: suite PHP routines interacting RDBMS.3. WWW-Wikipedia Perl library19 : responsible querying MediaWiki, parsing structuring returned encyclopedia pages.4. XML-RPC server: intermediate communication layer Java Perl routines.5. Java wrapper library: provides simple facade create access encyclopedia pageobjects compute relatedness scores.information flow API summarized sequence diagram Figure 5. higherinput/output layer user interacts provided Java API Wikipediaqueried. API provides factory classes querying Wikipedia, order retrieve encyclopedia entries well relatedness scores word pairs. practice, Java library workswrapper order provide simple user access terms facade. library responsibleissuing HTTP requests XML-RPC daemon provides layer calling Perl routinesJava API. Perl routines take care bulk querying encyclopedia entries MediaWiki software (which turn queries database) efficiently parsing text responsesstructured objects.8. Related Worksection relate work existing body literature computing semantic relatedness application various NLP tasks.19. http://search.cpan.org/dist/WWW-Wikipedia/203fi2044. Relatedness score computation3. Wikipedia pages lookuploop: foreach word2. Create category tree Java data structure1. Retrieve Wikipedia category tree: XML-RPC daemonPerl objectWiki markup text: HTTP request: WWW-Wikipedia: Perl module call: Category extraction path searchXML-RPC response: HTTP request: Create graph category tree queryResult set: SQL query (categories links): Java wrapper libraryResult set: article lookup: Database: SQL query (page): MediaWikiPHP Article object: PHP module call: WebserverP ONZETTO & TRUBEFigure 5: WikiRelate! API processing sequence diagram. Wikipedia pages relatedness measures accessed Java API facade. wrapper communicates Perllibrary designed Wikipedia access parsing XML-RPC server. WWWWikipedia turn accesses database encyclopedia stored meansappropriate queries MediaWiki.fiK NOWLEDGE ERIVED F ROM W IKIPEDIA8.1 Computing Semantic RelatednessResearch area computing semantic relatedness similarity generally dividedtwo categories firstly measures distributional similarity using largely unstructured informationtext secondly approaches using structured lexical databases WordNet.Measures distributional similarity (Landauer & Dumais, 1997; Lee, 1999; Dagan, 2000; Turney, 2001; Weeds & Weir, 2005, inter alia) based distributional hypothesis, i.e. hypothesis similar words appear similar contexts hence similar meaning. reasonsdiscussed detail Budanitsky Hirst (2006, pp.4144), measures distributional similaritymeasures semantic relatedness distinct, (1) measures semantic relatednesscover relations concepts measures distributional similarity capture relations words; (2) semantic relatedness symmetric relation distributional similaritypotentially asymmetric relationship; (3) measures semantic relatedness depend predefinedknowledge source created humans may presumed true, unbiased complete(Budanitsky & Hirst, 2006, p.43); measures distributional similarity depend entirely corporacausing problems imbalance data sparseness; problem may overcome usingrepresentative, large corpora; however, computing distributional similarity scale well(Gorman & Curran, 2006). Budanitsky Hirst (2006) conclude measures distributionalsimilarity cannot replace measures semantic relatedness similarity.Approaches using structured lexical databases traced back work Rada et al. (1989)measured semantic similarity MeSH, term hierarchy indexing articles Medline.compute semantic similarity straightforwardly terms numbers edges termshierarchy. Research area proceeded two directions. Firstly, different knowledge sourcesproposed. Early on, WordNet used provide broad coverage lexical database (Resnik,1993; Wu & Palmer, 1994; Resnik, 1995). Later Jarmasz Szpakowicz (2003) explored useRogets Thesaurus computing semantic similarity. Secondly, major advances achieveddeveloping sophisticated measures semantic similarity relatedness.article propose new knowledge source computing semantic relatedness, i.e.Wikipedia associated categorization network. believe many NLP applicationsbenefit using Wikipedia evaluate hypothesis including Wikipedia based semanticrelatedness measures features state-of-the-art coreference resolution system.8.2 Using Semantic Relatedness Coreference NLP ApplicationsVieira Poesio (2000), Harabagiu et al. (2001), Markert Nissim (2005) explore useWordNet different coreference resolution subtasks, resolving bridging references, otherand definite NP anaphora, MUC-style coreference resolution. present systemsinfer coreference relations set potential antecedents means WordNet search.approach WordNet cast search results terms semantic similarity measures.output used features learner. measures specifically developedcoreference resolution simply taken off-the-shelf applied task without specifictuning e.g. contrast Harabagiu et al. (2001), weight WordNet relations differentlyorder compute confidence measure path.Semantic relatedness measures proven useful many applications NaturalLanguage Processing word sense disambiguation (Kohomban & Lee, 2005; Patwardhan,Banerjee, & Pedersen, 2005), information retrieval (Finkelstein et al., 2002), information extraction205fiP ONZETTO & TRUBEpattern induction (Stevenson & Greenwood, 2005), interpretation noun compounds (Kim & Baldwin, 2005), paraphrase detection (Mihalcea, Corley, & Strapparava, 2006) spelling correction(Budanitsky & Hirst, 2006).9. Conclusionsarticle investigated use Wikipedia computing semantic relatedness application real-world NLP task, coreference resolution. assumed Wikipedia categorygraph represent semantic network modeling relations concepts, computedrelatedness it. Even categorization feature introduced Wikipediathree years ago, results indicate semantic relatedness computed using Wikipedia category network consistently correlates better human judgments simple baseline basedGoogle counts. also competitive WordNet datasets specifically modeling semanticrelatedness human judgments. available dataset small seem assembledrather arbitrarily perform extrinsic evaluation NLP application, i.e. coreference resolution system, register datasets statistically significant differencesimprovements given features induced WordNet ones Wikipedia.Wikipedia provides large amount information encyclopedic entries leavescategory network, e.g. named entities. encyclopedia gets continuously updated derivedknowledge used analyze current information. text category networkprovide semi-structured information mined precision unstructured datagathered web. Unfortunately, Wikipedia categorization still suffers limitations, i.e., cannot considered fully-fledged ontology, relations categoriessemantically-typed. near future concentrate making semantic relationsconcepts explicit Wikipedia category network (Ponzetto & Strube, 2007b). availability explicit semantic relations allow inducing semantic similarity rather semanticrelatedness measures, may suitable coreference resolution. interesting results indicate collaboratively created folksonomy actuallyused NLP applications benefit hand-crafted taxonomies ontologies.Acknowledgments. work funded Klaus Tschira Foundation, Heidelberg,Germany. first author supported KTF grant (09.003.2004). thank threeanonymous JAIR reviewers extensive reviews colleague Vivi Nastase usefulfeedback.ReferencesAhn, D., Jijkoun, V., Mishne, G., Muller, K., de Rijke, M., & Schlobach, S. (2004). Using WikipediaTREC QA track. Proceedings Thirteenth Text REtrieval Conference, Gaithersburg, Md., 1619 November 2004.Ahn, K., Bos, J., Curran, J. R., Kor, D., Nissim, M., & Webber, B. (2005). Question answeringQED TREC-2005. Proceedings Fourteenth Text REtrieval Conference, Gaithersburg, Md., 1518 November 2005.Banerjee, S., & Pedersen, T. (2003). Extended gloss overlap measure semantic relatedness.Proceedings 18th International Joint Conference Artificial Intelligence, Acapulco,206fiK NOWLEDGE ERIVED F ROM W IKIPEDIAMexico, 915 August 2003, pp. 805810.Beigman Klebanov, B. (2006). Semantic relatedness: Computational investigation human data.Proceedings 3rd Midwest Computational Linguistics Colloquium, Urbana-Champaign,Ill., 20-21 May 2006.Beigman Klebanov, B., & Shamir, E. (2006). Reader-based exploration lexical cohesion. Language Resources Evaluation, 40(2), 109126.Berger, A., Della Pietra, S. A., & Della Pietra, V. J. (1996). maximum entropy approach naturallanguage processing. Computational Linguistics, 22(1), 3971.Bos, J., & Markert, K. (2005). Recognising textual entailment logical inference. Proceedings Human Language Technology Conference 2005 Conference EmpiricalMethods Natural Language Processing, Vancouver, B.C., Canada, 68 October 2005, pp.628635.Budanitsky, A., & Hirst, G. (2006). Evaluating WordNet-based measures semantic distance.Computational Linguistics, 32(1), 1347.Bunescu, R., & Pasca, M. (2006). Using encyclopedic knowledge named entity disambiguation. Proceedings 11th Conference European Chapter AssociationComputational Linguistics, Trento, Italy, 37 April 2006, pp. 916.Carreras, X., & Marquez, L. (2005). Introduction CoNLL-2005 shared task: Semantic role labeling. Proceedings 9th Conference Computational Natural Language Learning,Ann Arbor, Mich., USA, 2930 June 2005, pp. 152164.Charniak, E. (1973). Jack Janet search theory knowledge. Advance PapersThird International Joint Conference Artificial Intelligence, Stanford, Cal., pp. 337343,Los Altos, Cal. W. Kaufmann.Chinchor, N. (2001). Message Understanding Conference (MUC) 7. LDC2001T02, Philadelphia,Penn: Linguistic Data Consortium.Chinchor, N., & Sundheim, B. (2003).Message Understanding Conference (MUC) 6.LDC2003T13, Philadelphia, Penn: Linguistic Data Consortium.Dagan, I. (2000). Contextual word similarity. Dale, R., Moisl, H., & H., S. (Eds.), HandbookNatural Language Processing, pp. 459476. New York, N.Y.: Marcel Dekker Inc.Finkelstein, L., Gabrilovich, E., Matias, Y., Rivlin, E., Solan, Z., Wolfman, G., & Ruppin, E. (2002).Placing search context: concept revisited. ACM Transactions Information Systems,20(1), 116131.Gabrilovich, E., & Markovitch, S. (2006). Overcoming brittleness bottleneck using Wikipedia:Enhancing text categorization encyclopedic knowledge. Proceedings 21st National Conference Artificial Intelligence, Boston, Mass., 1620 July 2006, pp. 13011306.Gabrilovich, E., & Markovitch, S. (2007). Computing semantic relatedness using Wikipedia-basedexplicit semantic analysis. Proceedings 20th International Joint ConferenceArtificial Intelligence, Hyderabad, India, 612 January 2007, pp. 16061611.Gildea, D., & Jurafsky, D. (2002). Automatic labeling semantic roles. Computational Linguistics,28(3), 245288.207fiP ONZETTO & TRUBEGiles, J. (2005). Internet encyclopedias go head head. Nature, 438, 900901.Gimenez, J., & Marquez, L. (2004). SVMTool: general POS tagger generator based supportvector machines. Proceedings 4th International Conference Language ResourcesEvaluation, Lisbon, Portugal, 2628 May 2004, pp. 4346.Gorman, J., & Curran, J. R. (2006). Scaling distributional similarity large corpora. Proceedings21st International Conference Computational Linguistics 44th Annual MeetingAssociation Computational Linguistics, Sydney, Australia, 1721 July 2006, pp.361368.Gurevych, I. (2005). Using structure conceptual network computing semantic relatedness.Proceedings 2nd International Joint Conference Natural Language Processing,Jeju Island, South Korea, 1113 October 2005, pp. 767778.Gurevych, I., & Niederlich, H. (2005a). Accessing GermaNet data computing semantic relatedness. Companion Volume Proceedings 43rd Annual Meeting AssociationComputational Linguistics, Ann Arbor, Mich., 2530 June 2005, pp. 58.Gurevych, I., & Niederlich, H. (2005b). Measuring semantic relatedness GermaNet word senses.Tech. rep., EML Research gGmbH.Harabagiu, S. M., Bunescu, R. C., & Maiorano, S. J. (2001). Text knowledge miningcoreference resolution. Proceedings 2nd Conference North American ChapterAssociation Computational Linguistics, Pittsburgh, Penn., 27 June 2001, pp. 5562.Hobbs, J. R. (1978). Resolving pronominal references. Lingua, 44, 311338.Hovy, E., Gerber, L., Hermjakob, U., Junk, M., & Lin, C.-Y. (2001). Question answering Webclopedia. Proceedings Thirteenth Text REtrieval Conference, Gaithersburg, Md.,1316 November 2001.Hsu, C.-W., Chang, C.-C., & Lin, C.-J. (2006). Practical Guide Support Vector Classification.http://www.csie.ntu.edu.tw/cjlin/papers/guide/guide.pdf.Jarmasz, M., & Szpakowicz, S. (2003). Rogets Thesaurus semantic similarity. Proceedings International Conference Recent Advances Natural Language Processing,Borovets, Bulgaria, 1012 September 2003, pp. 212219.Jiang, J. J., & Conrath, D. W. (1997). Semantic similarity based corpus statistics lexical taxonomy. Proceedings 10th International Conference Research ComputationalLinguistics (ROCLING).Kehler, A., Appelt, D., Taylor, L., & Simma, A. (2004). (non)utility predicate-argumentfrequencies pronoun interpretation. Proceedings Human Language TechnologyConference North American Chapter Association Computational Linguistics,Boston, Mass., 27 May 2004, pp. 289296.Kim, S. N., & Baldwin, T. (2005). Automatic interpretation noun compounds using WordNetsimilarity. Proceedings 2nd International Joint Conference Natural LanguageProcessing, Jeju Island, South Korea, 1113 October 2005, pp. 945956.Kohavi, R., & John, G. H. (1997). Wrappers feature subset selection. Artificial IntelligenceJournal, 97(1-2), 273324.208fiK NOWLEDGE ERIVED F ROM W IKIPEDIAKohomban, U. S., & Lee, W. S. (2005). Learning semantic classes word sense disambiguation.Proceedings 43rd Annual Meeting Association Computational Linguistics,Ann Arbor, Mich., 2530 June 2005, pp. 3441.Kudoh, T., & Matsumoto, Y. (2000). Use Support Vector Machines chunk identification.Proceedings 4th Conference Computational Natural Language Learning, Lisbon,Portugal, 1314 September 2000, pp. 142144.Landauer, T. K., & Dumais, S. T. (1997). solution Platos problem: Latent SemanticAnalysis theory acquisition, induction, representation knowledge. PsychologicalReview, 104, 211240.Leacock, C., & Chodorow, M. (1998). Combining local context WordNet similarityword sense identification. Fellbaum, C. (Ed.), WordNet. Electronic Lexical Database,chap. 11, pp. 265283. Cambridge, Mass.: MIT Press.Lee, L. (1999). Measures distributional similarity. Proceedings 37th Annual MeetingAssociation Computational Linguistics, College Park, Md., 2026 June 1999, pp.2531.Lemnitzer, L., & Kunze, C. (2002). GermaNet representation, visualization, application.Proceedings 3rd International Conference Language Resources Evaluation,Las Palmas, Canary Islands, Spain, 2931 May 2002, pp. 14851491.Lesk, M. (1986). Automatic sense disambiguation using machine readable dictionaries: tellpine cone ice cream cone. Proceedings 5th Annual Conference SystemsDocumentation, Toronto, Ontario, Canada, pp. 2426.Lin, D. (1998). information-theoretic definition similarity. Proceedings 15th International Conference Machine Learning, Madison, Wisc., 2427 July 1998, pp. 296304.Lo, K. K., & Lam, W. (2006). Using semantic relations world knowledge question answering. Proceedings Fifteenth Text REtrieval Conference, Gaithersburg, Md., 1417November 2006.Luo, X., Ittycheriah, A., Jing, H., Kambhatla, N., & Roukos, S. (2004). mention-synchronouscoreference resolution algorithm based Bell Tree. Proceedings 42nd AnnualMeeting Association Computational Linguistics, Barcelona, Spain, 2126 July 2004,pp. 136143.Malouf, R. (2002). comparison algorithms maximum entropy parameter estimation.Proceedings 6th Conference Computational Natural Language Learning, Taipei,Taiwan, 31 August 1 September 2002, pp. 4955.Markert, K., & Nissim, M. (2005). Comparing knowledge sources nominal anaphora resolution.Computational Linguistics, 31(3), 367401.McCallum, A., Pal, C., Druck, G., & Wang, X. (2006). Multi-conditional learning: Generative/discriminative training clustering classification. Proceedings 21st National Conference Artificial Intelligence, Boston, Mass., 1620 July 2006, pp. 433439.Mierswa, I., Wurst, M., Klinkenberg, R., Scholz, M., & Euler, T. (2006). YALE: Rapid prototypingcomplex data mining tasks. Proceedings 12th ACM SIGKDD International209fiP ONZETTO & TRUBEConference Knowledge Discovery Data Mining, Philadelphia, Penn., 2023 August2006, pp. 935940.Mihalcea, R., Corley, C., & Strapparava, C. (2006). Corpus-based knowledge-based measurestext semantic similarity. Proceedings 21st National Conference ArtificialIntelligence, Boston, Mass., 1620 July 2006, pp. 775780.Miller, G. A., & Charles, W. G. (1991). Contextual correlates semantic similarity. LanguageCognitive Processes, 6(1), 128.Mitchell, A., Strassel, S., Przybocki, M., Davis, J., Doddington, G., Grishman, R., Meyers, A.,Brunstain, A., Ferro, L., & Sundheim, B. (2003). TIDES extraction (ACE) 2003 multilingualtraining data. LDC2004T09, Philadelphia, Penn.: Linguistic Data Consortium.Ng, V., & Cardie, C. (2002). Improving machine learning approaches coreference resolution.Proceedings 40th Annual Meeting Association Computational Linguistics,Philadelphia, Penn., 712 July 2002, pp. 104111.Palmer, M., Gildea, D., & Kingsbury, P. (2005). proposition bank: annotated corpussemantic roles. Computational Linguistics, 31(1), 71105.Patwardhan, S., Banerjee, S., & Pedersen, T. (2005). SenseRelate::TargetWord generalizedframework word sense disambiguation. Proceedings 20th National ConferenceArtificial Intelligence, Pittsburgh, Penn., 913 July 2005.Pedersen, T., Patwardhan, S., & Michelizzi, J. (2004). WordNet::Similarity Measuring relatedness concepts. Companion Volume Proceedings Human LanguageTechnology Conference North American Chapter Association ComputationalLinguistics, Boston, Mass., 27 May 2004, pp. 267270.Poesio, M., Ishikawa, T., Schulte im Walde, S., & Vieira, R. (2002). Acquiring lexical knowledgeanaphora resolution. Proceedings 3rd International Conference LanguageResources Evaluation, Las Palmas, Canary Islands, Spain, 2931 May 2002, pp. 12201225.Ponzetto, S. P., & Strube, M. (2006a). Exploiting semantic role labeling, WordNet Wikipediacoreference resolution. Proceedings Human Language Technology ConferenceNorth American Chapter Association Computational Linguistics, New York,N.Y., 49 June 2006, pp. 192199.Ponzetto, S. P., & Strube, M. (2006b). Semantic role labeling coreference resolution. Companion Volume Proceedings 11th Conference European ChapterAssociation Computational Linguistics, Trento, Italy, 37 April 2006, pp. 143146.Ponzetto, S. P., & Strube, M. (2007a). API measuring relatedness words Wikipedia.Companion Volume Proceedings 45th Annual Meeting AssociationComputational Linguistics, Prague, Czech Republic, 2330 June 2007, pp. 4952.Ponzetto, S. P., & Strube, M. (2007b). Deriving large scale taxonomy Wikipedia. Proceedings 22nd National Conference Artificial Intelligence, Vancouver, B.C., Canada,2226 July 2007, pp. 14401447.Pradhan, S., Ward, W., Hacioglu, K., Martin, J. H., & Jurafsky, D. (2004). Shallow semantic parsing using Support Vector Machines. Proceedings Human Language Technology210fiK NOWLEDGE ERIVED F ROM W IKIPEDIAConference North American Chapter Association Computational Linguistics,Boston, Mass., 27 May 2004, pp. 233240.Rada, R., Mili, H., Bicknell, E., & Blettner, M. (1989). Development application metricsemantic nets. IEEE Transactions Systems, Man Cybernetics, 19(1), 1730.Resnik, P. (1993). Selection Information: Class-based Approach Lexical Relationships.Ph.D. thesis, Department Computer Information Science, University Pennsylvania,Philadelphia, Penn.Resnik, P. (1995). Using information content evaluate semantic similarity taxonomy.Proceedings 14th International Joint Conference Artificial Intelligence, Montreal,Canada, 2025 August 1995, Vol. 1, pp. 448453.Resnik, P. (1999). Semantic similarity taxonomy: information-based measure application problems ambiguity natural language. Journal Artificial IntelligenceResearch, 11, 95130.Rubenstein, H., & Goodenough, J. (1965). Contextual correlates synonymy. CommunicationsACM, 8(10), 627633.Salton, G., & McGill, M. (1983). Introduction Modern Information Retrieval. New York, N.Y.:McGraw-Hill.Seco, N., Veale, T., & Hayes, J. (2004). intrinsic information content metric semantic similarity WordNet. Proceedings 16th European Conference Artificial Intelligence,Valencia, Spain, 2327 August 2004, pp. 10891090.Soon, W. M., Ng, H. T., & Lim, D. C. Y. (2001). machine learning approach coreferenceresolution noun phrases. Computational Linguistics, 27(4), 521544.Stevenson, M., & Greenwood, M. (2005). semantic approach IE pattern induction. Proceedings 43rd Annual Meeting Association Computational Linguistics, AnnArbor, Mich., 2530 June 2005, pp. 379386.Strube, M., & Ponzetto, S. P. (2006). WikiRelate! Computing semantic relatedness using Wikipedia.Proceedings 21st National Conference Artificial Intelligence, Boston, Mass., 1620 July 2006, pp. 14191424.Tatu, M., Iles, B., Slavick, J., Novischi, A., & Moldovan, D. (2006). COGEX Second Recognizing Textual Entailment Challenge. Proceedings Second PASCAL RecognisingTextual Entailment Challenge Workshop, Venice, Italy, 10 April 2006, pp. 104109.Turney, P. (2001). Mining web synonyms: PMI-IR versus LSA TOEFL. Proceedings12th European Conference Machine Learning, Freiburg, Germany, 37 September,2001, pp. 491502.van Rijsbergen, C. (1979). Information Retrieval. London, U.K.: Butterworths.Vapnik, V. (1995). Nature Statistical Learning Theory. Springer-Verlag, Berlin, Germany.Vieira, R., & Poesio, M. (2000). empirically-based system processing definite descriptions.Computational Linguistics, 26(4), 539593.Vilain, M., Burger, J., Aberdeen, J., Connolly, D., & Hirschman, L. (1995). model-theoreticcoreference scoring scheme. Proceedings 6th Message Understanding Conference(MUC-6), pp. 4552, San Mateo, Cal. Morgan Kaufmann.211fiP ONZETTO & TRUBEWeeds, J., & Weir, D. (2005). Co-occurrence retrieval: flexible framework lexical distributional similarity. Computational Linguistics, 31(4), 439475.Wu, Z., & Palmer, M. (1994). Verb semantics lexical selection. Proceedings 32ndAnnual Meeting Association Computational Linguistics, Las Cruces, N.M., 2730June 1994, pp. 133138.Yang, X., Zhou, G., Su, J., & Tan, C. L. (2003). Coreference resolution using competition learningapproach. Proceedings 41st Annual Meeting Association ComputationalLinguistics, Sapporo, Japan, 712 July 2003, pp. 176183.212fiJournal Artificial Intelligence Research 30 (2007) 413-456Submitted 05/2007; published 11/2007Individual Domain AdaptationSentence Planning DialogueMarilyn Walkerlynwalker@gmail.comDepartment Computer Science, University Sheffield211 Portobello Street, Sheffield S1 4DP, United KingdomAmanda Stentamanda.stent@gmail.comDepartment Computer Science, Stony Brook UniversityStony Brook, NY 11794, USAFrancois Mairessef.mairesse@sheffield.ac.ukDepartment Computer Science, University Sheffield,211 Portobello Street, Sheffield S1 4DP, United KingdomRashmi Prasadrjprasad@linc.cis.upenn.eduInstitute Research Cognitive Science, University Pennsylvania,3401 Walnut Street, Suite 400A, Philadelphia, PA 19104, USAAbstractOne biggest challenges development deployment spoken dialoguesystems design spoken language generation module. challenge arisesneed generator adapt many features dialogue domain, userpopulation, dialogue context. promising approach trainable generation,uses general-purpose linguistic knowledge automatically adapted featuresinterest, application domain, individual user, user group. paperpresent evaluate trainable sentence planner providing restaurant informationMATCH dialogue system. show trainable sentence planning producecomplex information presentations whose quality comparable output templatebased generator tuned domain. also show method easily supportsadapting sentence planner individuals, individualized sentence plannersgenerally perform better models trained tested population individuals.Previous work documented utilized individual preferences content selection,knowledge, results provide first demonstration individual preferencessentence planning operations, affecting content order, discourse structure sentencestructure system responses. Finally, evaluate contribution different featuresets, show that, application, n-gram features often well features basedhigher-level linguistic representations.1. IntroductionOne robust findings studies human-human dialogue people adaptinteractions match conversational partners needs behaviors (Goffman,1981; Brown & Levinson, 1987; Pennebaker & King, 1999). People adapt contentutterances (Garrod & Anderson, 1987; Luchok & McCroskey, 1978). choosesyntactic structures match partners syntax (Levelt & Kelter, 1982; Branigan,Pickering, & Cleland, 2000; Reitter, Keller, & Moore, 2006; Stenchikova & Stent, 2007),c2007AI Access Foundation. rights reserved.fiWalker, Stent, Mairesse, & Prasadadapt choice words referring expressions (Clark & Wilkes-Gibbs, 1986;Brennan & Clark, 1996). also adapt speaking rate, amplitude, claritypronunciation (Jungers, Palmer, & Speer, 2002; Coulston, Oviatt, & Darves, 2002; Ferguson& Kewley-Port, 2002).However, beyond state art reproduce type adaptationspoken language generation module dialogue system, i.e. componentshandle response generation information presentation. standard generation systemincludes modules content planning, sentence planning, surface realization (Kittredge,Korelsky, & Rambow, 1991; Reiter & Dale, 2000). content planner takes inputcommunicative goal; selects content realize goal organizes contentcontent plan. sentence planner takes input content plan. decidescontent allocated sentences, sentences ordered, discourse cuesuse express relationships content elements. outputs sentence plan.Finally, surface realizer determines words word order sentencesentence plan. outputs text speech realization original communicative goal.findings human-human dialogue suggest adaptation could potentiallyuseful stage generation pipeline. Yet date, work adaptationindividual users utilizes models users knowledge, needs, preferences adaptcontent content planning (Jokinen & Kanto, 2004; Rich, 1979; Wahlster & Kobsa,1989; Zukerman & Litman, 2001; Carenini & Moore, 2006), rather applying modelsindividual linguistic preferences form output, determined sentenceplanning surface realization.However, consider alternative realizations restaurant recommendation Figure 1. Columns B contain human ratings quality realizations usersB. differences rating feedback suggest user different perceptions quality potential realizations. Data experiment collectingfeedback users B, 20 realizations 30 different recommendation contentplans (600 examples), shows feedback two users easily distinguished:paired t-test supports hypothesis two samples sampled distinct distributions (t = 17.4, p < 0.001). perceptual differences appear general:examined user feedback evaluation experiment described Rambow,Rogati, Walker (2001) 60 users rated output 7 different spoken languagegenerators 20 content plans, found significant differences user perceptionsutterance quality (F = 1.2, p < 0.002). led us hypothesize individualizedsentence planners dialogue systems might high utility.addition studies, also find evidence work individualvariation inherent many aspects language generation, including content ordering,referring expression generation, syntactic choice, lexical choice, prosody generation.common knowledge individual authors identified linguisticfeatures written texts (Madigan, Genkin, Lewis, Argamon, Fradkin, & Ye,2005; Oberlander & Brew, 2000).examination weather report corpus five weather forecasters showed individual differences lexical choice expressing specific weather-related concepts(Reiter & Sripada, 2002).414fiIndividual Domain Adaptation DialogueAlt Realization6Chanpen Thai best overall quality among selected restaurants since Thai restaurant, good service, price 24dollars, good food quality.7Chanpen Thai best overall quality among selected restaurants good service, good food quality, Thairestaurant, price 24 dollars.4Chanpen Thai best overall quality among selected restaurants. good food quality, good service, Thai restaurant, price 24 dollars.9Chanpen Thai Thai restaurant, good food quality, price24 dollars, good service. best overall qualityamong selected restaurants.5Chanpen Thai best overall quality among selected restaurants. good service. good food quality. price 24dollars, Thai restaurant.3Chanpen Thai best overall quality among selected restaurants. price 24 dollars. Thai restaurant, goodservice. good food quality.10 Chanpen Thai best overall quality among selected restaurants. good food quality. price 24 dollars. Thairestaurant, good service.2Chanpen Thai best overall quality among selected restaurants. price 24 dollars, Thai restaurant. goodfood quality good service.1Chanpen Thai best overall quality among selected restaurants. Thai restaurant good food quality. price 24dollars, good service.8Chanpen Thai Thai restaurant, good food quality.good service. price 24 dollars. best overall qualityamong selected restaurants.1B4AVG2.5253.5243243322.5333333444433.5423Figure 1: alternative realizations content plan Figure 4, feedbackUsers B, mean (AVG) feedback (1=worst 5=best).Rules learned generating nominal referring expressions perform better individual speakers provided feature learning algorithm (Jordan & Walker,2005), experiment evaluating choice referring expression shows 70%agreement among native speakers best choice (Yeh & Mellish, 1997). Chai,Hong, Zhou, Prasov (2004) show also individual differencesgesture generating multimodal references, corpus study accentedpronouns reported Kothari (2007) suggests accentuation also partly determined individual linguistic style.Automatic evaluation techniques applied human-generated reference outputsmachine translation automatic summarization perform better multiple outputs provided comparison (Papenini, Roukos, Ward, & Zhu, 2002; Nenkova,Passonneau, & McKeown, 2007): attributed large variationhumans generate given particular content express. also reflected finding human subjects produce many different valid content orderings askedorder specific set content items produce best possible summary (Barzilay,Elhadad, & McKeown, 2002; Lapata, 2003).415fiWalker, Stent, Mairesse, & Prasadpast, linguistic variation among individuals considered problem generation researchers work around, rather potential area study (McKeown, Kukich,& Shaw, 1994; Reiter, 2002; Reiter, Sripada, & Robertson, 2003). part, duehand-crafting generation components resources. impossible encodehand, individual, rules sentence planning realization. Furthermore,domain experts dont agree best way express domain concept,generation dictionary encoded? difficult simply get good output respectsinteracting domain linguistic constraints even considerable handcraftingrules (Kittredge, Korelsky, & Rambow, 1991).Modeling individual differences also problem statistical methodslearning paradigms used assume single correct output (Lapata, 2003;Jordan & Walker, 2005; Hardt & Rambow, 2001) inter alia. believe simplestway deal inherent variability possible generation outputs treat generationranking problem explain below, techniques overgenerate using userdomain-independent rules, filter rank possibilities using domain userspecific corpora feedback (Langkilde & Knight, 1998; Langkilde-Geary, 2002; Bangalore& Rambow, 2000; Rambow, Rogati, & Walker, 2001). approach advantagedialogue systems also affords joint optimization generator textto-speech engine (Bulyko & Ostendorf, 2001; Nakatsu & White, 2006). manyproblems generation ranking models individualization could applied,text planning, cue word selection, referring expression generation (Mellish, ODonnell,Oberlander, & Knott, 1998; Litman, 1996; Di Eugenio, Moore, & Paolucci, 1997; Marciniak& Strube, 2004). However, recently work generation acknowledgedindividual differences tried model (Guo & Stent, 2005; Mairesse &Walker, 2005; Belz, 2005; Lin, 2006).article describes SPaRKy (Sentence Planning Rhetorical Knowledge), sentence planner uses rhetorical relations adapts users individual sentenceplanning preferences.1 SPaRKy two components: randomized sentence plan generator (SPG) produces multiple alternative realizations information presentation,sentence plan ranker (SPR) trained (using human feedback) rankalternative realizations (See Figure 1). mentioned above, previous work documentedutilized individual preferences content selection, knowledge, resultsprovide first demonstration individual preferences sentence planning operations,affecting content ordering, discourse structure, sentence structure, sentence scopesystem responses. also show learned preferences domain-specific.Section 2 compares approach results previous work. Section 3 providesoverview MATCH system architecture, generate dialogue system responsesusing either SPaRKy, domain-specific template-based generator described evaluated previous work (Stent, Walker, Whittaker, & Maloor, 2002; Walker et al., 2004).Sections 4, 5 6 describe SPaRKy detail; describe SPG, automaticgeneration features used training SPR, boosting used train SPR.Sections 7 8 present quantitative qualitative results:1. Java version SPaRKy downloaded www.dcs.shef.ac.uk/cogsys/sparky.html416fiIndividual Domain Adaptation Dialogue1. First, show SPaRKy learns select sentence plans significantlybetter randomly selected sentence plan, average less 10% worsesentence plan ranked highest human judges. also show that,experiments, simple n-gram features perform well features based higher-levellinguistic representations.2. Second, show SPaRKys SPG produce realizations comparableMATCHs template-based generator, gaprealization SPR selects trained multiple users selectedhuman.3. Third, show SPaRKy trained particular individuals, performsbetter trained feedback multiple individuals. firstresults suggesting individual sentence planning preferences exist,modeled trainable generation system. also show casesperformance individualized SPRs statistically indistinguishableMATCHs template-based generator, compare-2, User B prefers SPaRKy,compare-3, User prefers template-based generator.4. Fourth, show differences learned models make sense termsprevious rule-based approaches sentence planning. analyze qualitativedifferences learned group individual models, show SPaRKylearns specific rules interaction content items sentence planningoperations, rules model individual differences, would difficultcapture hand-crafted generator.sum discuss future work Section 9.2. Related Workdiscuss related work adaptation generation using standard generation architecture contains modules content planning (Section 2.1), sentence planning(Section 2.2) surface realization (Section 2.3) (Kittredge, Korelsky, & Rambow, 1991;Reiter & Dale, 2000).2.1 Adaptation Content Planningsignificant research use user models discourse context adaptcontent information presentations dialogue (Joshi, Webber, & Weischedel, 1984,1986; Chu-Carroll & Carberry, 1995; Zukerman & Litman, 2001) inter alia,user models (not information presentation strategies) sensitive particular individuals. Several studies investigated use quantitative models user preferencesselection content recommendations comparisons (Carenini & Moore, 2006; Walkeret al., 2004; Polifroni & Walker, 2006), Moore, Foster, Lemon, White (2004) usemodels referring expression generation, sentence planning surface realization. Elhadad, Kan, Klavans, McKeown (2005) applied group models (physician,lay person) individual user models task summarizing medical information.417fiWalker, Stent, Mairesse, & PrasadMcCoy (1989) used context information design helpful system-generated corrections.work looked use statistical techniques adapting content selectioncontent ordering methods particular domains (Barzilay, Elhadad, & McKeown, 2002;Duboue & McKeown, 2003; Lapata, 2003), individual users.2.2 Adaptation Sentence Planningfirst trainable sentence planner SPoT, precursor SPaRKy output information gathering utterances travel domain (Walker, Rambow, & Rogati, 2002).Evaluations SPoT demonstrated performed well template-based generatordeveloped travel domain field-tested DARPA Communicator evaluations(Rambow, Rogati, & Walker, 2001; Walker et al., 2002). Information gathering utterancesconsiderably simpler information presentations: usually exhibitcomplexities rhetorical structure, little interaction domain-specificcontent items sentence structures. Thus SPoT generator produce utterances variation rhetorical structure; learned optimize speech-act orderingsentence structure choices, adapt individuals.2.3 Adaptation Surface RealizationWork adaptation surface realization mainly focused decisions lexicalsyntactic choice, using models target text, individual text models, althoughrecent research also shown n-gram models trained user-specific corporaadapt generators reproduce individualized lexical syntactic choices (Lin, 2006; Belz,2005). Paiva Evans (2004) present technique training generator learningrelationship particular generation decisions text variables measuredoutput corpus. technique applied generator decisions formreferring expression syntactic structure, used capture stylistic, ratherindividual, differences. Gupta Stent (2005) use discourse context speakerknowledge referring expression generation dialogue.User models also used adapt surface realization. approach learningranking user feedback applied multimedia presentation planning (Stent& Guo, 2005) joint optimization syntactic realizer text-to-speechengine (Nakatsu & White, 2006). work look individual differences.Research also focused factors affect stylistic variation realizationchoices reflect personality, politeness, emotion domain specific style (Hovy, 1987; DiMarco& Foster, 1997; Walker, Cahn, & Whittaker, 1997; Andre, Rist, van Mulken, Klesen, &Baldes, 2000; Bouayad-Agha, Scott, & Power, 2000; Fleischman & Hovy, 2002; Piwek,2003; Porayska-Pomsta & Mellish, 2004; Isard, Brockmann, & Oberlander, 2006; Gupta,Walker, & Romano, 2007; Mairesse & Walker, 2007). None work attemptedreproduce individual stylistic variation.418fiIndividual Domain Adaptation Dialogue3. Overview MATCHs Spoken Language GeneratorDialog ManagerCommunicativegoalSPUR text plannerContentplanSPaRKyTextplan trees(tptrees)Sentence plangeneratorPairs(sentence plan [sptree],dependency tree [dtree])TemplatebasedgeneratorSentence planrankerTextRanked list(sptree, dtree) pairsRealPro surface realizerTextFigure 2: Architecture MATCHs Spoken Language Generator.MATCH (Multimodal Access City Help) multimodal dialogue system findingrestaurants entertainment options New York City (Johnston, Bangalore, Vasireddy,Stent, Ehlen, Walker, Whittaker, & Maloor, 2002). Information presentations MATCHinclude route descriptions, well user-tailored recommendations comparisonsrestaurants. Figure 2 shows MATCHs architecture spoken language generation (SLG).content planning module SPUR text planner (Section 3.1) (Walker et al., 2004).two modules producing text spoken dialogue responses SPURs output: highly engineered domain-specific template-based realizer (Section 3.2);SPaRKy sentence planner followed RealPro surface realizer (Lavoie & Rambow,1997) (Section 3.3). Example template-based SPaRKy outputs dialogue strategy Figure 3. SPUR SPaRKy trainable, produce different outputdepending user discourse context.419fiWalker, Stent, Mairesse, & PrasadStrategyrecommendSystemTemplaterecommendSPaRKycompare-2Templatecompare-2SPaRKycompare-3Templatecompare-3SPaRKyRealizationCaffe Cielo best overall value among selectedrestaurants. Caffe Cielo good decor good service.Italian restaurant.Caffe Cielo, Italian restaurant, good decorgood service, best overall quality amongselected restaurants.Caffe Buon Gustos Italian restaurant.hand, Johns Pizzerias Italian, Pizza restaurant.Caffe Buon Gusto Italian restaurant, JohnsPizzeria Italian , Pizza restaurant.Among selected restaurants, following offer exceptional overall value. Uguales price 33 dollars.good decor good service. French, Italianrestaurant. Da Andreas price 28 dollars. gooddecor good service. Italian restaurant.Johns Pizzerias price 20 dollars. mediocre decordecent service. Italian, Pizza restaurant.Da Andrea, Uguale, Johns Pizzeria offer exceptionalvalue among selected restaurants. Da Andrea Italian restaurant, good service, good decor,price 28 dollars. Johns Pizzeria Italian ,Pizza restaurant. decent service. mediocredecor. price 20 dollars. Uguale French, Italianrestaurant, good service. good decor,price 33 dollars.AVG44244.54Figure 3: Template outputs sample SPaRKy output dialogue strategy. AVG= Averaged score two human users.3.1 SPURinput SPUR high-level communicative goal MATCH dialoguemanager output content plan recommendation comparison. SPURselects organizes content communicated based communicative goal,conciseness parameter, decision-theoretic user model. produces targeted recommendations comparisons: restaurants mentioned attributes selectedrestaurant user model predicts user want know about. ThusSPUR produce wide variety content plans.Figure 4 shows sample content plan recommendation. content plan gives risealternate realizations recommendations Chanpen Thai Figure 1. Followingbottom-up approach text-planning (Marcu, 1997; Mellish, ODonnell, Oberlander, &Knott, 1998), content plan consists set assertions must communicateduser set rhetorical relations hold assertions maycommunicated well. rhetorical relation designates one facts nucleirelation, i.e. main point, facts satellites, i.e. supplementaryfacts (Mann & Thompson, 1987). Three rhetorical relations (Mann & Thompson, 1987)used SPUR: justify relation recommendation strategy, contrastelaboration relations comparison strategies. relations Figure 4 specifynucleus (1) claim made recommendation, satellites(assertions 2 5) provide justifying evidence claim.420fiIndividual Domain Adaptation Dialoguerelations:justify(nuc:1, sat:2); justify (nuc:1, sat:3 ); justify(nuc:1, sat:4);justify(nuc:1, sat:5)content: 1. assert(best (Chanpen Thai))2. assert(is (Chanpen Tai, cuisine(Thai)))3. assert(has-att(Chanpen Thai, food-quality(good)))4. assert(has-att(Chanpen Thai, service(good)))5. assert(is (Chanpen Thai, price(24 dollars)))Figure 4: content plan recommendation.3.2 Template-Based Generatororder produce utterances content plans produced SPUR, first implemented evaluated template-based generator MATCH (Stent, Walker, Whittaker,& Maloor, 2002; Walker et al., 2004). template-based generator designedmake possible evaluate algorithms user-specific content selection based SPURsdecision-theoretic user model. performs sentence planning, including discourse cueinsertion, clause combining referring expression generation. produces one high quality output content plan three dialogue strategies: recommend, compare-2compare-3. Recommendations comparisons one form evaluative argument,realization strategies based guidelines argumentation theory producingeffective evaluative arguments, summarized Carenini Moore (2000).templates highly tailored domain, template-based generator expectedperform well comparison SPaRKy.Following argumentation guidelines, template-based generator realizes recommendations nucleus ordered first, followed satellites. satellitesordered maximize opportunity aggregation. produce concise recommendations given content communicated, phrases identical verbs subjectsgrouped, lists coordination used aggregrate assertionssubject. Figure 5 provides examples aggregration number assertions variesaccording SPURs conciseness parameter (Z-value).realization template comparisons focuses communicating elaborationcontrast relations. Figure 6 contains content plan comparisons. nucleusassertion (1) Carmines exceptional restaurants. satellites(assertions 2 7 representing selected attributes restaurant) elaborateclaim nucleus (assertion 1). Contrast relations hold assertions 2 3,4 5, 6 7. One way communicate elaboration relationstructure comparison satellites grouped together, followingnucleus. communicate contrast relation, satellites produced fixed order,parallel structure maintained across options (Prevost, 1995; Prince, 1985).satellites initially ordered terms evidential strength, reorderedallow aggregation. Figure 7 illustrates aggregation comparisons varyingnumbers assertions.421fiWalker, Stent, Mairesse, & PrasadZ1.50.70.3-0.5-0.7-1.5OutputKomodo best overall value among selected restaurants. Komodos Japanese,Latin American restaurant.Komodo best overall value among selected restaurants. Komodos Japanese,Latin American restaurant.Komodo best overall value among selected restaurants. Komodos price$29. Japanese, Latin American restaurant.Komodo best overall value among selected restaurants. Komodos price$29 good service. Japanese, Latin American restaurant.Komodo best overall value among selected restaurants. Komodos price$29 good service good food quality. Japanese, LatinAmerican restaurant.Komodo best overall value among selected restaurants. Komodos price$29 good service, good food quality good decor. Japanese,Latin American restaurant.Figure 5: Recommendations East Village Japanese Task, different settingsconciseness parameter Z.strategy: compare3items:Above, Carminesrelations: elaboration(nuc:1,sat:2);elaboration(nuc:1,sat:3);elaboration(nuc:1,sat:4);elaboration(nuc:1,sat:5);elaboration(nuc:1,sat:6); elaboration(nuc:1,sat:7); contrast(nuc:2,nuc:3);contrast(nuc:4,nuc:5); contrast(nuc:6,nuc:7)content: 1. assert(exceptional(Above,Carmines))2. assert(has-att(Above, decor(good)))3. assert(has-att(Carmines, decor(decent)))4. assert(has-att(Above, service(good)))5. assert(has-att(Carmines, service(good)))6. assert(has-att(Above, cuisine(New American)))7. assert(has-att(Carmines, cuisine(Italian)))Figure 6: content plan comparison.3.3 SPaRKyLike template-based generator, SPaRKy takes input content plans produced SPUR. Figure 2 shows SPaRKy two modules: sentence plan generator (SPG), sentence plan ranker (SPR). SPG uses set clause-combiningoperations (Figure 12); produces large set alternative realizations input contentplan (See Figure 1). SPR ranks alternative realizations using model learnedusers ratings training set content plans. SPG described Section 4.features used train SPR described Section 5; procedure trainingSPR described Section 6.SPaRKy trained using user feedback, rather handcrafted,trained individualized spoken language generator. discussed above,422fiIndividual Domain Adaptation DialogueZ1.50.70.3-0.5-0.7-1.5OutputAmong selected restaurants, following offer exceptional overall value. Komodogood service.Among selected restaurants, following offer exceptional overall value. Komodogood service good decor.Among selected restaurants, following offer exceptional overall value. Komodosprice $29. good food quality, good service good decor. Takahachisprice $27. good food quality, good service decent decor.Among selected restaurants, following offer exceptional overall value. Komodosprice $29. good food quality, good service good decor. Takahachisprice $27. good food quality, good service decent decor. Japonicasprice is$37. excellent food quality, good service decent decorAmong selected restaurants, following offer exceptional overall value. Komodosprice $29. good food quality, good service good decor. Takahachisprice $27. good food quality, good service decent decor. Japonicasprice $37. excellent food quality, good service decent decor. Shabu-Tatsusprice $31. good food quality, good service decent decor.Among selected restaurants, following offer exceptional overall value. Komodosprice $29. good food quality, good service good decor. Takahachisprice $27. good food quality, good service decent decor. Japonicasprice $37. excellent food quality, good service decent decor. Shabu-Tatsusprice $31. good food quality, good service decent decor. Bond Streetsprice $51. excellent food quality, good service good decor. Dojos price$14. decent food quality, mediocre service mediocre decor.Figure 7: Comparisons East Village Japanese Task, different settingsconciseness parameter Z.feedback two users Figure 1 suggests user different perceptionsquality potential realizations. significant part Sections 7 8dedicated examining differences model trained averaged feedback,shown AVG Figure 1, trained individual feedback users B.4. Sentence Plan Generationinput SPaRKys SPG content plan SPUR. Content planssample recommendation comparison Figure 4 Figure 6. Figure 1 showsalternative SPaRKy realizations recommendation Figure 4, Figure 8 showsalternative SPaRKy realizations comparison Figure 6. Content plans specifyassertions include information presentation, rhetorical relationsholding them, order assertions express rhetoricalrelations them. task known discourse planning. SPG two stagesprocessing; first discourse planning, sentence planning.4.1 Discourse PlanningDiscourse planning algorithms characterized as: schema-based (McKeown, 1985;Kittredge, Korelsky, & Rambow, 1991); top-down algorithms using plan operators (Moore& Paris, 1993); bottom-up approaches use, example, constraint satisfactionalgorithms (Marcu, 1996, 1997) genetic algorithms (Mellish, ODonnell, Oberlander, &423fiWalker, Stent, Mairesse, & PrasadAlt Realization11 Carmines offer exceptional value among selected restaurants.Above, New American restaurant, good decor, good service.Carmines, Italian restaurant, good service, decent decor.12 Carmines offer exceptional value among selected restaurants.good decor, Carmines decent decor. Carminesgood service. New American restaurant. hand,Carmines Italian restaurant.13 Carmines offer exceptional value among selected restaurants.New American restaurant. good decor. good service.Carmines, Italian restaurant, decent decor good service.14 Carmines offer exceptional value among selected restaurants.good decor Carmines decent decor,Carmines good service. New American restaurantCarmines Italian restaurant.20 Carmines offer exceptional value among selected restaurants.Carmines decent decor good decor, Carminesgood service. Carmines Italian restaurant. Above, however,New American restaurant.25 Carmines offer exceptional value among selected restaurants.good decor. Carmines Italian restaurant. goodservice. Carmines decent decor. New American restaurant.Carmines good service.2B2AVG2322.5333454.5232.5NRNRNRFigure 8: alternative realizations compare-3 plan Figure 6, feedbackUsers B, mean (AVG) feedback (1=worst 5=best).NR = generated ranked.justifyinfernucleus: <1>assertrecobestsatellite: <2>assertrecocuisinesatellite: <3>assertrecofoodqualitysatellite: <4>assertrecoservicesatellite: <5>assertrecopriceFigure 9: tp-tree plan Figure 4, used generate Alternatives 1, 3, 4, 5, 6, 710 Figure 1.Knott, 1998). SPaRKy, SPG takes bottom-up approach discourse planningusing principles Centering Theory (Grosz, Joshi, & Weinstein, 1995). Content itemsgrouped talk thing, linear orderamong groupings left unspecified. centering constraints resultAlt-25 Figure 8, repeatedly changes discourse center, never generated.discourse planning stage produces one text-plan trees (tp-trees). tp-treerecommend plan Figure 4 Figure 9, tp-trees compare-3 planFigure 6 Figure 10. tp-tree, leaf represents single assertion labeled424fiIndividual Domain Adaptation Dialogueelaborationinfernucleus:<1>assert-com-list_exceptionalcontrastcontrastnucleus:<4>assert-com-servicenucleus:<2>assert-com-decorcontrastnucleus:<6>assert-com-cuisinenucleus:<5>assert-com-servicenucleus:<3>assert-com-decornucleus:<7>assert-com-cuisineelaborationnucleus:<1>assert-com-list_exceptionalcontrastinferinfernucleus:<2>assert-com-decornucleus:<3>assert-com-decornucleus:<7>assert-com-cuisinenucleus:<5>assert-com-servicenucleus:<6>assert-com-cuisinenucleus:<4>assert-com-serviceFigure 10: Tp-trees comparisons shown alternatives 12 14 (top) alternatives 11 13 (bottom) Figure 8.speech act. Interior nodes labeled rhetorical relations. additionrhetorical relations content plan, SPG uses relation infer combinationsspeech acts rhetorical relation expressed content plan (Marcu,1997). infer relation similar joint relation RST; joins multiple satellitesmononuclear relation nuclei multinuclear relation.simple assertion, leaf, tp-tree associated one syntacticrealizations (d-trees), using dependency tree representation, called DSyntS (Figure 11)(Melcuk, 1988; Lavoie & Rambow, 1997). association simple assertionspotential d-trees specifying syntactic realizations specified hand-craftedgeneration dictionary. Leaves d-trees generation dictionary variables,instantiated content plan, e.g. Thai replaces cuisine type variable.4.2 Sentence Planningsentence planning, SPG assigns assertions sentences, orders sentences,inserts discourse cues, performs referring expression generation. uses set clausecombining operations operate tp-trees incrementally transform elementaryd-trees associated leaves single lexico-structural representation. outputprocess two parallel structures: (1) sentence plan tree (sp-tree), binary treeleaves labeled assertions input tp-tree, interior nodes labeledclause-combining operations; (2) one d-trees reflect parallel operationspredicate-argument representations.clause-combining operations general operations similar aggregation operations used research (Rambow & Korelsky, 1992; Danlos, 2000). operations425fiWalker, Stent, Mairesse, & Prasadassert-com-cuisineassert-com-food qualityBE3 [class:verb ](Chanpen Thai [number:sg class:proper noun article:no-art person:3rd ]II restaurant [class:common noun article:indef ](Thai [class:adjective ]))HAVE1 [class:verb ](Chanpen Thai [number:sg class:proper noun article:no-art person:3rd ]II quality [class:common noun article:no-art ](ATTR good [class:adjective ]ATTR food [class:common noun ]))Figure 11: Example d-trees generation dictionary used SPG.examples use given Figure 12. applied bottom-up left-to-rightfashion, choice operation constrained rhetorical relation holdingassertions combined (Scott & de Souza, 1990), specified Figure 12.addition ordering assertions, clause-combining operation may insert cue wordsassertions. Figure 13 gives list cue words used SPG. choicecue-word determined type rhetorical relation2 .SPG generates random sample possible sp-trees tp-tree, prespecified number sp-trees, randomly selecting among clause-combining operationsaccording probability distribution favors preferred operations. Table 14 showsprobability distribution used experiments, hand-crafted based assumedpreferences operations merge, relative-clause with-reduction,one way knowledge injected random process biastowards producing higher quality sentence plans.3SPG handles referring expression generation converting proper name pronoun proper name appears previous utterance. Referring expressiongeneration rules applied locally, across adjacent utterances, rather globally acrossentire presentation (Brennan, Friedman, & Pollard, 1987). Referring expressionsmanipulated d-trees, either intrasententially incremental creationsp-tree, intersententially, full sp-tree contains period operations.2. alternative approach cue-word impose constraint rhetorical relation musthold (Webber, Knott, Stone, & Joshi, 1999; Forbes, Miltsakaki, Prasad, Sarkar, Joshi, & Webber, 2003).3. probability distribution could learned corpus (Marcu, 1997; Prasad, Joshi, Dinesh, Lee,& Miltsakaki, 2005).4. infer relation holds clauses contain possession predicate, second clausearbitrarily selected reduction. justify relation holds, satellite RST relationalways undergoes reduction, syntactic constraints satisfied.5. infer relation holds, clause arbitrarily selected reduction. justify relation holds,clause undergoes relative clause formation satellite clause. motivated factrelative clause formation generally seen occur modifying relative clause provides additionalinformation noun modifies, additional/elaborated informationinformational status information main clause.426fiIndividual Domain Adaptation DialogueOperationRelDescriptionMergeinfercontrastWithreductionjustifyinferRelativeclausejustifyinferTwo clauses combinedidentical matrix verbsidentical arguments adjuncts except one.nonidentical arguments coordinated.Two clauses identical subject arguments identifiedone clauses havepossession matrix verb.possession clause undergoes withparticipial clause formationattached non-reducedclause.4Two clauses identicalsubject identified. Oneclause attached subjectclause relativeclause.5justify, inCuefer conwordconjunction trastCuewordinsertion(onhand)contrastPeriodjustify,contrast,inferelaborationTwo clauses conjoinedcue word (coordinating subordinating conjunction). orderarguments connective determined ordernucleus (N) satellite(S), yielding two distinct operations, cue-word-conjunctionns cue-word-conjunctionsn.cue-word insertion combinesclauses inserting cue wordstart second clause(Carmines Italian restaurant. HOWEVER,New American restaurant), resulting two separate sentences.Two clauses joined period.Sample 1stargChanpenThaigood service.Sample2nd argChanpenThaigoodfoodquality.ResultChanpenThaiThai restaurant.ChanpenThaigoodfoodquality.Chanpen ThaiThai restaurant,good foodquality.ChanpenThaibestoverall qualityamongselectedrestaurants.ChanpenThaibestoverall qualityamongselectedrestaurants.ChanpenThailocatedMidtownWest.ChanpenThai,locatedMidtown West,best overallquality amongselectedrestaurants.Chanpen Thaibest overallquality amongselectedrestaurants, sinceThairestaurant,good service.ChanpenThaiThairestaurant,goodservice.Chanpen Thaigood servicegood food quality.Penanggooddecor.Baluchismediocredecor.Penanggood decor.hand,Baluchismediocre decor.ChanpenThaiThai restaurant,goodfoodquality.ChanpenThaigoodservice.Chanpen ThaiThai restaurant,good foodquality.good service.Figure 12: Clause combining operations examples.third fourth sentences Alt 13 Figure 8 show conversion named restaurant(Carmines) pronoun.sp-trees Alts 6 8 Figure 1 shown Figs. 15 16. Leaf labelsconcise names assertions content plan, e.g. assert-reco-best claim (labelled1) Figure 4. combination operations switch order arguments,satellite nucleus (SN) nucleus satellite (NS), labels interiornodes indicate whether occurred, specify rhetorical relation operationrealizes. labels keep track operations substitutions used constructingtree subsequently used tree feature set described Section 5, one427fiWalker, Stent, Mairesse, & PrasadRST relationjustifycontrastinferelaborationAggregation operatorwith-reduction, relative-clause, cue-word conj. because, cue-wordconj. since, periodmerge, cue-word insert. however, cue-word conj. while, cue-word conj.and, cue-word conj. but, cue-word insert. hand, periodmerge, cue-word conj. and, periodperiodFigure 13: RST relation constraints aggregation operators.Aggregation operatormerge, with-reduction, relative-clausecue-word conj. because, cue-word conj. since, cue-word conj. while,cue-word conj. and, cue-word conj.cue-word insert. however, cue-word insert. handperiodProbability0.800.100.090.01Figure 14: Probability distribution aggregation operators. final operation randomly chosen selected set uniform distribution.feature sets tested training SPR. example, label root treeFigure 15 (CW-SINCE-NS-justify) specifies cw-conjunction operationused, since cue word, nucleus first (NS), realize justify relation.Similarly, bottom left-most interior node (WITH-NS-infer) indicates withreduction operation used, nucleus satellite (NS), realizeinfer relation.Figure 17 shows d-tree content plan Figure 4. d-tree showsSPG treats period operation part lexico-structural representationd-tree. d-tree split multiple d-trees nodes sent RealProsurface realization.Note tp-tree different realizations, depending operationsSPG. example, tp-tree Figure 9 yields Alt 6 Alt 2 Figure 1. AltCWSINCENSjustifyassertrecobestCWCONJUNCTIONinferWITHNSinferassertrecocuisineCWCONJUNCTIONinferassertreco assertrecoservicepriceassertrecofoodqualityFigure 15: Sentence Plan Tree (SP-tree) Alternative 6 Figure 1.428fiIndividual Domain Adaptation DialoguePERIODjustifyassertrecobestPERIODinferWITHNSinferassertrecofoodqualityPERIODinferassertrecocuisineassertrecoserviceassertrecopriceFigure 16: Sentence Plan Tree (SP-tree) Alternative 8 Figure 1.PERIOD_justifyHAVE1PERIOD_inferChampen_ThaiPERIOD_inferChampen_ThaiChampen_ThairestaurantbestservicedollarpricequalitygoodrestaurantBE3goodThaioverallAMONG1selectedHAVE1BE3quality24Champen_ThaisfoodFigure 17: Dependency tree alternative 8 Figure 1.2 highly rated, average human rating 4. However, Alt 6 poor realizationplan, average human rating 2.5.summarize, SPaRKys SPG transforms input content plan set alternativepairs sentence-plan trees d-trees. First, assertions input content plangrouped using principles centering theory. Second, assertions assigned sentencesdiscourse cues inserted using clause combining operations. Third, decisionsrealization referring expressions made basis recency. rhetorical relationsclause-combining operations domain-independent.SPaRKy uses two types domain-dependent knowledge: probability distributionclause-combining operations, d-trees input RealPro surfacerealizer. order use SPaRKy new domain, might necessary to:429fiWalker, Stent, Mairesse, & Prasadadd new rhetorical relations content planner used additional rhetorical relations;modify probability distribution clause-combining operations, either handlearning corpus;construct new set d-trees capture syntactic structure sentencesdomain, unless used surface realizer could take logical forms semanticrepresentations input.5. Feature Generationtrain use SPR, potential realization generated SPG, alongcorresponding sp-tree d-tree, encoded set real-valued features (binary featuresmodeled values 0 1) three feature types:N-Gram features simple word n-gram features generated realizationSPG outputs;Concept features concept n-gram features generated named entitiesrealization SPG outputs;Tree features features represent structural configurations sp-treesd-trees output SPG.features automatically generated described below.5.1 N-Gram FeaturesN-gram features capture information lexical selection lexical ordering realizations output SPaRKy. two-step approach used generate features. First,domain-specific rule-based named-entity tagger (using MATCHs lexicons restaurant,cuisine type location names) replaces specific tokens types, e.g. Babborestname. Then, unigram, bigram trigram features counts automaticallygenerated. tokens begin end indicate beginning end realization.N-gram feature names prefixed n-gram. example, ngram-cuisinenamerestaurant-with counts occurrences cuisine type followed restaurant(as realization Italian restaurant with); ngram-begin-restname-whichcounts occurrences realizations starting restaurants name followed which.also count words per presentation, per sentence presentation.5.2 Concept FeaturesConcept features capture information concepts selected presentation,linear order realization. two-step approach used generate features.First, named-entity tagger marks names items restaurant database, e.g.Uguale. Then, unigram, bigram trigram features counts automaticallygenerated sequences concepts sentence plan realization.n-gram features, tokens begin end indicate beginning end realization.430fiIndividual Domain Adaptation DialogueConcept feature names prefixed conc. example, conc-decor-claimset 1 claim expressed directly information decor, featureconc-begin-service characterizes utterances starting information service.concept n-gram features, use * separate individual features. also countconcepts per presentation, per sentence presentation.5.3 Tree FeaturesTree features capture declaratively way merge, infer cue-word operations applied tp-trees, inspired parsing features used Collins(2000). count occurrences certain structural linguistic configurationssp-trees associated d-trees SPG generated. Tree feature names prefixedr rule (sp-tree) sentence (d-tree).Several feature templates used generate tree features. Local feature templatesrecord structural configurations local particular node (its ancestors, daughters etc.);global feature templates, used sp-tree features, record properties entire sp-tree.four types local feature template: traversal features, sister features, ancestorfeatures leaf features. Traversal, sister ancestor features generated nodessp-trees d-trees; leaf features generated sp-trees only. valuefeature count described configuration tree. discard featuresoccur fewer 10 times avoid specific particular content plans.node tree, traversal features record preorder traversalsubtree rooted node, subtrees depths. Feature names concatenation prefix trav-, names nodes (starting currentnode) traversal path. * used separate node names. example r-travwith-ns-infer*assert-reco-food-quality*assert-reco-cuisine (with value 1)bottom-left subtree Figure 16.Sister features record consecutive sister nodes. Names concatenationprefix sis-, names sister nodes. example r-sis-assert-recobest*cw-conjunction-infer (with value 1) tree Figure 15.node tree, ancestor features record initial subpaths pathnode root. Feature names concatenation prefix anc-names nodes (starting current node). example r-anc-assert-recocuisine*with-ns-infer*cw-conjunction-infer (with value 1) tree Figure 15.Leaf features record initial substrings frontier sp-tree. Namesconcatenation prefix leaf-, names frontier nodes (startingcurrent node). example, sp-tree Figure 15 value 1 leaf-assert-recobest also leaf-assert-reco-best*leaf-assert-reco-cuisine, sp-treeFigure 16 value 1 leaf-assert-reco-food-quality*assert-reco-cuisine.Global features apply sp-tree. record, sp-treeoperation labeling non-frontier node, (1) minimal number leaves dominatednode labeled rule tree (MIN); (2) maximal number leaves dominatednode labeled rule (MAX); (3) average number leaves dominatednode labeled rule (AVG). example, sp-tree Figure 15 value431fiWalker, Stent, Mairesse, & Prasad4 cw-conjunction-infer-max, value 2 cw-conjunction-infer-min value 3cw-conjunction-infer-avg.6. Training Sentence Plan RankerSPR ranks alternative information presentations using model learned user ratings set training data. training procedure follows:content plan training data, SPG generates set alternativesentence plans using random selection sentence planning operators (Section 4);Features automatically generated surface realizations sentence plansalternative sentence plan represented terms number realvalued features (Section 5);Feedback perceived quality realization alternative sentenceplan collected one users;RankBoost boosting method (Freund, Iyer, Schapire, & Singer, 1998) learnsfunction featural representation realization feedback,attempts duplicate rankings training examples.use RankBoost three reasons. First, produces ranking input alternatives rather selection one best alternative. Second, handle many sparsefeatures. Third, function learns rule-based model showing effectfeature ranking competing examples. models inspectedcompared. allows us qualitatively analyze models (Section 8) orderunderstand preferences individuals, differences SPRs individualsvs. groups.section describes training SPR detail. SPUR content plannerproduces content plans three dialogue strategies:recommend: recommend entity set entitiescompare-2: compare two entitiescompare-3: compare three entitiesdialogue strategy, start set 30 representative content plansSPUR. SPG parameterized produced 20 distinct (sp-tree, d-tree) pairscontent plan. realized RealPro. Separately, also obtainedoutput content plan template-based generator (Section 3.2).SPaRKy realizations template-based realizations randomly ordered placed series Web pages. 1830 realizations ratedscale 1 5 first two authors paper, neither implementedtemplate-based realizer SPG. raters worked rating task sessions one hour time several hours day, period week.instructed look 21 realizations particular content plan ratingthem, try use whole rating scale, indicate spontaneous rating without432fiIndividual Domain Adaptation Dialoguerepeatedly re-labelling alternative realizations. discuss ratingsbasis ratings time. Given cognitive load long durationrating task, impossible raters keep track realizations cameSPaRKy template-based generator, likely impossiblegenerate gestalt evaluation alternative.(sp-tree, d-tree, realization) triple example input RankBoost; ratingsused feedback. experiments examine two uses ratings. First,train test SPR average ratings two users, i.e. considertwo users representing single user group. Second, train test individualizedSPRs, one user.SPR trained using RankBoost algorithm (Freund, Iyer, Schapire, & Singer,1998), describe briefly here. First, training corpus converted setordered pairs examples x, y:= {(x, y)| x, alternatives plan,x preferred user ratings}alternative realization x represented set indicator functions hs (x)1 m. indicator functions calculated thresholding feature values(counts) described Section 5. example, one indicator function is:h100 (x) =1 leaf-assert-reco-best(x) 10 otherwiseh100 (x) = 1 leftmost leaf assertion claim Figure 15. singleparameter associated indicator function, ranking scoreexample x calculatedXhs (x)F (x) =score used rank competing sp-trees content plan goalduplicating ranking found training data. Training process settingparameters minimize following loss function:RankLoss =1 Xeval(F (x) F (y))|T | (x,y)Teval function returns 1 ranking scores (x, y) pair misordered (so xranked higher even though training data ranked higher x), 0otherwise. words, RankLoss percentage misordered pairs. lossfunction minimized, ranking errors (cases ranking scores disagree humanjudgments) reduced. Initially parameter values set zero. optimizationmethod greedily picks single parameter time parameter makeimpact loss function updates parameter value minimizeloss.experiments described below, use two evaluation metrics:433fiWalker, Stent, Mairesse, & PrasadRankLoss: value training methods loss function;TopRank: difference human rating top realizationcontent plan human rating realization SPR predictstop ranked.7. Quantitative Resultssection, describe three experiments SPaRKy:1. Feature sets trainable sentence planning: examine features (ngram, concept, tree, all) lead best performance sentence planning task,find n-gram features sometimes perform well features.2. Comparison template-based generation: show performancetrainable sentence planner using best performing feature set consistenttemplate-based generator, although overall template-based generatorstill performs better.3. Individualized sentence planners: show people quite specific individual preferences regarding three tasks sentence planning: information ordering, sentence aggregation, use discourse cues; furthermore, trainablesentence planner model individual preferences. Moreover showcases individualized sentence planners better than, statistically indistinguishable from, template-based generator.report results separately comparisons two entities among threeentities. two types comparison generated using different strategiesSPG, produce text different terms length structure.7.1 Feature Sets Trainable Sentence PlanningUsing cross-validation methodology, repeatedly train SPR random 90%corpus, test remaining 10%. Here, use averaged feedback useruser B feedback. Figure 18 repeats examples Figure 1, showinguser rankings rankings ranking function learned trainedSPRs users B AVG user.Table 1 shows RankLoss feature set (Section 5). Paired t-tests comparingranking loss different feature sets show surprisingly performance differences amongfeatures. Using features (All) always produces best results, differencesalways significant.n-gram features give results comparable features compare-2recommend. analysis learned models suggests one reason ngram features perform well individual lexical items uniquelyassociated many combination operators, lexical itemwith-ns operator. means detailed representations content structureinformation presentation represented tree features equivalent n-gramfeatures application domain.434fiIndividual Domain Adaptation DialogueAlt Realization6Chanpen Thai best overall quality among selected restaurants since Thai restaurant, goodservice, price 24 dollars, good food quality.7Chanpen Thai best overall quality among selected restaurants good service, goodfood quality, Thai restaurant, price 24dollars.4Chanpen Thai best overall quality among selected restaurants. good food quality, goodservice, Thai restaurant, price 24 dollars.9Chanpen Thai Thai restaurant, good food quality,price 24 dollars, good service.best overall quality among selected restaurants.5Chanpen Thai best overall quality among selected restaurants. good service. good foodquality. price 24 dollars, Thai restaurant.3Chanpen Thai best overall quality among selected restaurants. price 24 dollars. Thairestaurant, good service. good food quality.10 Chanpen Thai best overall quality among selected restaurants. good food quality. price 24dollars. Thai restaurant, good service.2Chanpen Thai best overall quality among selected restaurants. price 24 dollars, Thairestaurant. good food quality good service.1Chanpen Thai best overall quality among selected restaurants. Thai restaurant good foodquality. price 24 dollars, good service.8Chanpen Thai Thai restaurant, good food quality.good service. price 24 dollars. bestoverall quality among selected restaurants.1B4SPRA0.16SPRB0.65SPRAV G0.58250.380.540.42240.530.620.53240.470.530.63320.590.320.46330.640.400.62330.670.460.58440.750.500.74430.640.520.45420.810.290.73Figure 18: alternative realizations content plan Figure 4, feedbackusers B (1=worst 5=best) rankings trained SPRsusers B mean(A,B) ([0, 1]).concept features always perform worse features, indicatinglinear ordering concepts accounts variation rating feedback.two types comparison, performance using concept features approachesfeature sets. However, recommendations, performance using concept featuresmuch worse using n-gram features features. qualitative analysispresented Section 8, discuss aspects models recommendationsmight account large difference performance.Table 2 shows results features using TopRank evaluation metric, calculated two-fold cross-validation, comparable previous work (Walker, Rambow,& Rogati, 2002; Stent, Prasad, & Walker, 2004).6 evaluated SPaRKy test setscomparing three data points content plan: Human (the score best sentenceplan SPaRKys SPG produce selected human users); SPaRKy (thescore SPRs top-ranked selected sentence); Random (the score sentence plan6. TopRank metric sensitive distribution ranking feedback SPR scores test set,means sensitive number cross-validation folds.435fiWalker, Stent, Mairesse, & PrasadFeature set/StrategyRandom BaselineConceptN-GramTreecompare-20.500.16 (p < .000)0.14 (p < .161)0.14 (p < .087)0.13compare-30.500.16 (p < .021)0.15 (p < .035)0.16 (p < .007)0.14recommend0.500.32 (p < .000)0.21 (p < .197)0.22 (p < .001)0.20Table 1: AVG models ranking error different feature sets, strategies. Resultsaveraged 10-fold cross-validation, testing mean feedback. p valuesparentheses indicate level significance decrease accuracycompared model using features. Cases different feature setsperform well features marked bold.randomly selected alternative sentence plans). three presentation types,paired t-test comparing SPaRKy Human Random showed SPaRKy significantly better Random (df = 59, p < .001) significantly worse Human(df = 59, p < .001). difference SPaRKy scores Human scoresindicates much performance could improved SPR perfect replicatingHuman ratings.UserAVGAVGAVGStrategyrecommendcompare-2compare-3SPaRKy3.6 (0.77)4.0 (0.66)3.6 (0.68)Human3.9 (0.55)4.4 (0.54)4.0 (0.49)Random2.8 (0.81)2.8 (1.30)2.7 (1.20)Table 2: TopRank scores recommend, compare-2 compare-3 (N = 180), usingfeatures, SPaRKy trained AVG feedback, standard deviations.7.2 Comparison Template GenerationUserAVGAVGAVGStrategyrecommendcompare-2compare-3SPaRKy3.6 (0.59)3.9 (0.52)3.4 (0.38)Human4.4 (0.37)4.6 (0.39)4.6 (0.35)Template4.2 (0.74)3.6 (0.75)4.1 (1.23)Table 3: TopRank scores MATCHs template-based generator, SPaRKy(AVG)Human. N = 180, standard deviations.436fiIndividual Domain Adaptation Dialoguedescribed above, raters also rated single output template-based generator MATCH content plan training data. Table 3 shows meanTopRank scores template-based generators output (Template), comparedbest plan trained SPR selects (SPaRKy), best plan selected humanoracle (Human). fold, SPaRKy Human oracle select best 10sentence plans text plan, template-based generator produces singleoutput single human-rated score. paired t-test comparing Human Templateshows significant differences recommend compare3, Human significantly better compare-2 (df = 29, = 4.8, p < .001).users evidently like compare-2 template. paired t-test comparing SPaRKyTemplate shows template-based generator significantly better recommend compare-3 (df = 29, = 2.1, p < .05), trend SPaRKybetter compare-2 (df = 29, = 2.0, p = .055).Also, standard deviation Template strategies wider Human SPaRKy,indicating template-based generator performs well overall, performs poorlyinputs. One reason might SPURs decision-theoretic user modelselects wide range number content items different users, concisenesssettings (See Figures 5 7). means difficult handcraft template-basedgenerator handle different cases well.gap Human scores (produced SPG selected humanrather SPR) Template scores shows SPG produces sentenceplans good template-based generator, accuracy SPR needsimproved. Below, Section 7.3 shows SPR trained individuals,SPaRKys performance indistinguishable template-based generatorcases.7.3 Comparing Individualized Models Group Modelsdiscussed Section 1 differences rating feedback users Bcompeting realizations (See Figure 1) suggest user different perceptionsquality potential realizations. quantify utility feasibility trainingindividualized SPRs, first examine feasibility training models individual users.results Table 1 based corpus 600 examples, rated user,may involve much effort users. would like know whether highperforming individualized SPR trained less labelled data. Figure 19 plotsranking error rates function amount training data. data suggestserror rates around 0.20 could acquired much smaller training set, i.e.training set around 120 examples, certainly feasible.recommendtest dataBs test dataAVGs test datamodel0.170.520.31Bs model0.520.170.31AVG model0.290.270.20Table 4: Ranking error various configurations recommend strategy.437fiWalker, Stent, Mairesse, & Prasad0.45UserUser B0.4Average test error0.350.30.250.20.15050100150200250300Number sentences training setFigure 19: Variation testing error users function numbertraining utterances.compare-2test dataBs test dataAVGs test datamodel0.160.230.17Bs model0.260.110.16AVG model0.200.130.13Table 5: Ranking error various configurations compare-2 strategy.compare-3test dataBs test dataAVGs test datamodel0.130.260.17Bs model0.300.140.20AVG model0.180.180.14Table 6: Ranking error various configurations compare-3 strategy.examine trained individualized SPRs accurate. results Tables 4, 56 show RankLoss several training testing configurations strategy (using10-fold cross-validation). compare two individualized models models trainedBs mean feedback (AVG). model, test test data,test data models. shows well model might fit customizingSPR new domain user group. example, train model recommendations438fiIndividual Domain Adaptation Dialogueusing feedback group users, deploy system individual user,might expect model fit differences similar Table 4.course, may strongly conflicting preferences group users.example, consider differences ratings users B average ratingsFigure 1. Alt-1 Alt-7 equivalent using average feedback, user dislikesAlt-7 likes Alt-1 vice versa user B. Column 3 Table 4 shows averagemodel, used SPR user user B much higher ranking error (.29.27 respectively) SPR customized user (.17 error) customizeduser B (.17 error).examination Tables 4, 5 6 shows general, striking differencesmodels trained tested one individuals feedback (RankLoss ranges 0.110.17) cross-tested models (RankLoss ranges 0.13 0.52). Also, average(AVG) models always perform poorly users B individually-tailoredmodels. baseline comparison, model ranking sentence alternatives randomlyproduces error rate 0.5 average; Table 4 shows models trained one usersdata tested others perform badly random model baseline.suggests differences users ratings random noise.cases, average model also performs significantly worse individualmodels even tested feedback average user (the diagonal Tables 4, 56). suggests cases harder get good model averageuser case, possibly feedback inconsistent. recommendations,performance individual model significantly better average model (df = 9,= 2.6, p < .02). compare-2 average model better user (df = 9, = 2.3,p < .05), user Bs model better average model (df = 9, = 3.1, p < .01).UserBBBStrategyrecommendcompare-2compare-3recommendcompare-2compare-3SPaRKy3.5 (0.87)3.8 (0.98)3.1 (1.02)4.4 (0.70)4.4 (0.69)4.4 (0.62)Human3.9 (0.61)4.3 (0.73)3.6 (0.80)4.7 (0.46)4.7 (0.53)4.8 (0.40)Template3.9 (1.05)4.2 (0.64)3.9 (1.19)4.5 (0.76)3.1 (1.21)4.2 (1.34)Table 7: TopRank scores Individualized SPaRKy compared MATCHstemplate-based generator rated separately Users B, individualUser User B Human Oracles. Standard Deviations parentheses. N =180.also compare template-based generator individualized SPaRKy generators using TopRank metric (See Table 7). comparisons done pairedt-tests using Bonferroni adjustment multiple comparisons.recommend, significant differences SPaRKy TemplateUser (df = 59, = 2.3, p = .07), User B (df = 59, = 1.6, p = .3).439fiWalker, Stent, Mairesse, & Prasadalso significant differences either user Template Human (df = 59,< 1.5, p > 0.4).compare-2, large differences Users B. User appearslike template compare-2 (average rating 4.2) User B (average rating 3.1). User A, significant differences SPaRKy Template(df = 59, = 2.3, p = .07), Template Human (df = 59, = 0.1, p = .09),User B strongly prefers SPaRKy Template (df = 59, = 7.7, p < .001).compare-3, also large differences Users B. User likestemplate compare-3 (average rating 3.9), strongly prefers individualizedSPaRKy (average rating 3.1) (df = 59, = 3.4, p < .004). User B also likes template(average rating 4.2), significant differences SPaRKy (average rating4.4) (df = 59, = 1.0, p = .95).users, every strategy, even individually trained SPRs, stillsignificant gap SPaRKy Human scores, indicating performanceSPR could improved (df = 59, = 3.0, p < .006).results demonstrate trainable sentence planning produce output comparable better template-based generator, less programming effortflexibility.8. Qualitative Analysisimportant aspect RankBoost learned models expressed rules: qualitative examination learned models may highlight individual differences linguisticpreferences, help us understand SPaRKys SPG produce sentence plansbetter produced template-based generator, individuallytrained SPRs usually select sentence plans good templates. qualitatively compare learned ranking models individualized SPRs, assesslinguistic aspects utterance (which features) important individual,important are. evaluate whether individual oriented towards particularfeature examining features indicator functions hs (x) non-zero values.evaluate important feature individual examining magnitudeparameters .two potential problems approach, first problemfeature templates produce thousands features, redundant,differences models indicator functions spurious. Therefore, allowmeaningful qualitative comparisons models, one pair perfectly correlatedfeatures eliminated.second problem arises RankBoosts greedy algorithm. selectionparameter set round boosting highly dependent training set,models derived single episode training highly variable. compareindicator functions independently training set, adopt bootstrapping methodidentify feature set user independent particular training episode.repeatedly randomly selecting 10 alternatives training 10 testing contentplan, created 50 different training sets user. average valuesfeatures selected RankBoost 50 training runs, conduct experiments using440fiIndividual Domain Adaptation DialogueModelAVGBStrategyrecommendcompare-2compare-3recommendcompare-2compare-3recommendcompare-2compare-3Tree453763503547474547Feature TypeN-Gram Concept Leaf36974612129412914451103371113496361313496Global343314454Table 8: Features top 100 highest average user model.100 features user highest average magnitude. Section 8.1discuss differences types feature selected bootsrapping algorithmoutlined. Section 8.2 discusses differences models produced using tree featuresuser user B, section 8.3 discusses differences average modelindividual models.8.1 Types Bootstrapped Featuresbootstrapping process selects total 100 features strategytype feedback (individual averaged). found differences features alongdimensions.Table 8 shows number features type top 100 (averaged50 training runs). 9 features shared three strategies AVGmodel; shared features usually n-gram features. User A, 6 features sharedthree strategies (mostly n-gram features). User B, features sharedthree strategies.also found features capture specific interactions domain-specificcontent items syntactic structure, difficult model rule-basedtemplate-based generator. example Rule (1) Figure 20 significantly lowers ranking sentence plan neighborhood information (assert-reconbhd) combined subsequent content items via with-ns operation. Amongbootstrapped features average user, 16 features compare-2 count interactionsdomain-specific content syntactic structure. compare-3, 22 features countinteractions, bootstrapped features recommend include 39 features.examine models derived features detail below.8.2 Differences Individual Modelsanalyze individual linguistic preferences information presentation strategies, qualitatively compare two models Users B. believequalitative analysis provides additional evidence differences users rankingpreferences random noise. identify differences among features selected441fiWalker, Stent, Mairesse, & PrasadN12345678910111213141516171819202122232425262728Conditionr-anc-assert-reco-nbhd*with-ns-infer 1cw-conjunction-infer-avg-leaves-under 3.1r-anc-assert-reco*with-ns-infer*cw-conjunction-infer 1leaf-assert-reco-best*assert-reco-price 1cw-conjunction-infer-avg-leaves-under 2.8r-trav-with-ns-infer*assert*assert 1r-anc-cw-conjunction-infer*cw-conjunction-infer 1with-ns-infer-min-leaves-under 1r-anc-assert-reco*with-ns-infer 1cw-conjunction-infer-max-leaves-under 3.5r-trav-with-ns-infer*assert-reco*assert-reco 1r-anc-assert*with-ns-infer 1r-anc-with-ns-infer*relative-clause-infer 1r-anc-assert*with-ns-infer*relative-clause-infer 1cw-conjunction-infer-avg-leaves-under 4.1r-anc-assert-reco-cuisine*with-ns-infer*period-infer 1cw-conjunction-infer-avg-leaves-under 2.2r-anc-assert-reco-food-quality*merge-infer 1r-anc-assert-reco*merge-infer 2.5r-anc-assert-reco-decor*merge-infer 1r-anc-assert*merge-infer 2.5r-trav-merge-infer 1.5r-trav-with-ns-infer*assert-reco-service*assert-reco-food-quality1leaf-assert-reco-food-quality*assert-reco-cuisine 1cw-conjunction-infer-avg-leaves-under 3.8leaf-assert-reco-food-quality 1s-trav-have1*propernoun-restaurant*II-quality*attr-among1 1s-anc-attr-with*have1 1-1.26-0.58-0.33-0.29-0.27-0.22-0.17-0.13-0.11-0.07-0.07-0.03-0.01-0.01-0.010.100.150.180.200.220.250.270.400.460.460.600.680.71Figure 20: subset rules corresponding values User model, ordered .RankBoost, values, using models derived using bootstrapping tree features only, since easier interpret qualitatively. course many different modelspossible. User model consists 109 rules; subset Figure 20. User Bsmodel consists 90 rules, subset shown Figure 21. first considerindividual models account rating differences Alt-6 Alt-8 Figure 1 (repeated Figure 18 ratings trained SPRs), discussdifferences.Comparing Alt-6 Alt-8: Alt-6 highly ranked User B User A.Alt-6 instantiates Rule 21 Figure 21, expressing User Bs preferences linear ordercontent. (Alt-6s sp-tree Figure 15.) Rule 21 increases rating examplesclaim, i.e. assert-reco-best (Chanpen Thai best overall quality),realized first. Thus, unlike user A, user B prefers claim beginning utterance(the ordering claim left unspecified argumentation theory (Carenini & Moore,2000)). Rule 22 increases rating examples initial claim immediately442fiIndividual Domain Adaptation DialogueN123456789101112131415161718192021222324Conditionr-sis-assert-reco-relative-clause-infer 1r-sis-period-infer-assert-reco 1r-anc-assert-reco-nbhd*with-ns-infer 1r-anc-assert-reco*period-infer*period-infer 1.5r-anc-assert-reco-food-quality*with-ns-infer*relative-clause-infer 1r-anc-assert-reco-cuisine*with-ns-infer*relative-clause-infer 1r-anc-assert-reco*period-infer 1leaf-assert-reco-price 1r-anc-assert*period-infer*period-infer 1.5leaf-assert-reco-decor 1r-anc-assert*relative-clause-infer*period-infer 1.5r-trav-relative-clause-infer*assert-reco*with-ns-infer 1cw-conjunction-infer-avg-leaves-under 3.1cw-conjunction-infer-avg-leaves-under 3.3cw-conjunction-infer-avg-leaves-under 2.2r-anc-assert*relative-clause-infer*period-infer 1leaf-assert-reco-service 1s-trav-attr-with 1r-anc-assert-reco-cuisine*with-ns-infer*cw-conjunction-infer 1cw-conjunction-infer-avg-leaves-under 3.6leaf-assert-reco-best 1leaf-assert-reco-best*assert-reco-cuisine 1cw-conjunction-infer-avg-leaves-under 2.8r-trav-with-ns-infer*assert-reco-cuisine*assert-reco-food-quality 1-1.01-0.71-0.50-0.49-0.41-0.39-0.35-0.32-0.26-0.14-0.07-0.05-0.03-0.03-0.010.030.070.180.270.360.470.500.520.76Figure 21: subset rules corresponding values User Bs model, ordered .followed type cuisine (assert-reco-cuisine). rules interact Rule 19Figure 21, specifies preference information following assert-reco-cuisinecombined via with-ns operation, conjoined (cw-conjunction-infer)additional evidence. Alt-6 also instantiates Rule 23 User Bs model, value.52 associated multiple uses cw-conjunction-infer operation.User low rating Alt-6 arises dislike with-ns operation (Rules 3,8, 9, 11 12) cw-conjunction-infer operation (Rules 3, 5, 7, 10 15)Figure 20. (Contrast User Bs Rule 23 User Rules 5 17.) Alt-6 also failsinstantiate preference food quality cuisine information occur first (Rules 2426). Finally, user also prefers claim assert-reco-best realizedsentence (Rule 27).contrast, Alt-8 rated highly User User B (see Figure 1). Eventhough Alt-8 instantiates negatively evaluated with-ns operation (Rules 3, 8, 9 11Figure 20), instances cw-conjunction-infer (Rules 3, 5, 7, 10 15).Moreover Alt-8 follows ordering preferences (Rules 24 26) describe sp-treesassert-reco-food-quality left frontier, trees followedassert-reco-cuisine. (See Alt-8s sp-tree Figure 16.) Rule 27 also increases ratingAlt-8 large positive reflecting expression claim sentence.443fiWalker, Stent, Mairesse, & Prasadhand, Alt-8 rated poorly User B; violates Bs preferenceslinear order (remember Rules 21 22 specify B prefers claim first, followedcuisine information). Also, Bs model rules radically decrease rankingexamples using period-infer operation (Rules 2, 4, 7 9).Thus, Alt-6 Alt-8 show users B prefer different combination operators,different ordering content, e.g. B likes claim first likes recommendationsfood quality first followed cuisine. mentioned above, previous workgeneration evaluative arguments states claim may appear first last (Carenini& Moore, 2000). relevant guideline producing effective evaluative arguments statesplacing main claim first helps users follow line reasoning, delayingclaim end argument also effective user likely disagreeclaim. template-based generator MATCH always placed claim first,analysis suggests may effective user A.similarities differences: also individual differences preferences particular operations, specific content operation interactions. example,User model demotes examples with-ns operation applied (Rules3, 6 8 Figure 20), User B generally likes examples with-nsused (Rule 18 Figure 21). However, neither B like with-ns used combinecontent neighborhood information. User model value -1.26,User Bs model value -0.50 (see Rule 1 Figure 20 Rule 3 Figure 21.)rules capture specific interaction sp-tree domain-specific contentwith-ns-infer combination operation. Utterances instantiating rules placeinformation adjunctival with-clause following clause realizing restaurantsneighborhood. constraint type information with-clause.utterance (1) below, with-clause realizes restaurants food quality, whereas (2)contains information restaurants service.(1) Mont Blanc good service, price 34 dollars, located MidtownWest, good food quality. best overall quality among selectedrestaurants.(2) Mont Blanc located Midtown West, good service, price 34 dollars,good food quality. best overall quality among selectedrestaurants.Moreover, users like with-ns combines cuisine food-quality information example (3) (Rule 23 Figure 20 Rule 24 Figure 21).(3) Komodo best overall quality among selected restaurants sinceJapanese, Latin American restaurant, good food quality, goodservice, price 29 dollars.User B radically reduces rating cuisine, food-quality combinationcombined information using relative-clause-infer operation,example (5) (Rules 5 6 Figure 21).444fiIndividual Domain Adaptation Dialogue(4) Bond Street good decor. Japanese, Sushi restaurant, excellentfood quality, good service. best overall quality among selectedrestaurants.Example (4) interesting contrast example (3). Example (4) instantiates Rule24 Figure 21, also instantiates number negatively valued features. discussedabove, User B prefers examples claim expressed first (Rule 21 Figure 21),User Bs model explicitly reduces rating examples information decorexpressed first (Rule 10 Figure 21).general, User likes merge-infer operation (Rules 19, 21 22), especially applied assert-reco-food-quality (Rule 18), assert-reco-decor(Rule 20). User strongly prefers hear food quality first (Rule 26 Figure 20),followed cuisine information (Rule 24). contrast, User B rules reducerating examples price decor first (Rules 8 10 Figure 21). User B alsopreferences merge-infer likes cw-conjunction operation (Rule 20Figure 21). Finally, User B dislikes relative-clause-infer operation general(Rule 1), combination with-ns operation (Rule 12) period-inferoperation (Rule 11).addition evidence discussed individual differences languagegeneration, believe fact model differences interpretable showsdifferences user perception quality system utterances true individualdifferences, random noise.8.3 Average Model DifferencesTable 22 shows subset rules largest magnitudes exampleAVG model using 100 feature bootstrapping process described above. Section 8.2presented results average model performs statistically worse recommendationseither individual models. may due fact average modelessentially trying learn contradictory feedback two users. see whetherexamination models provides support hypothesis, first examinelearned model ranks Alt-6 Alt-8 shown Figure 18 column SPRAV G .average feedback Alt-6 2.5 average feedback Alt-8 3, trainedSPR ranks Alt-8 second highest Alt-6 fifth 10.mid-value ranking Alt-6 arises number interacting rules,similar User Bs similar User As. Alt-6 instantiates Rules26 27 Figure 22 increase ranking sentence plans claim,i.e. assert-reco-best realized first, sentence plans claim immediatelyfollowed information type cuisine (assert-reco-cuisine). rulesidentical Bs Rules 21 22 Figure 21. Rule 18 additionally increases rankingsentence plans cuisine information followed service information, appliesAlt-6 increase ranking. However Rule 3 lowers ranking Alt-6, sincecombines 3 different assertions single DSyntS tree.Alt-8 highly ranked SPRAV G , largely result several rules increaseranking. Rule 31 specifies increase ranking sentence plans claimsentence, true Alt-8 Alt-6. rule also appears Rule 27445fiWalker, Stent, Mairesse, & PrasadN12345678910111213141516171819202122232425262728293031Conditions-anc-attr-with*locates-trav-have1*i-restaurant*cuisine-type*ii-quality*attr-good*attrfoods-trav-propernoun-restaurant 2.5r-anc-cw-conjunction-infer*cw-conjunction-infer*period-justifyr-sis-assert-reco-relative-clause-inferr-anc-assert-reco-decor*with-ns-infer*period-infer*period-justifyr-anc-assert-reco-cuisine*with-ns-infer*relative-clause-inferperiod-justify-avg-leaves-under 5.5cw-conjunction-infer-avg-leaves-under 3.1r-anc-assert-reco-nbhd*with-ns-inferr-sis-cw-conjunction-infer-relative-clause-inferperiod-infer-avg-leaves-under 3.4r-anc-assert-reco-food-quality*merge-infers-trav-propernoun-restaurant 5.5r-anc-assert-reco-decor*merge-infers-anc-attr-with*i-restaurant*have1r-anc-assert-reco-decor*with-ns-inferleaf-assert-reco-best*assert-reco-cuisine*assert-reco-services-trav-propernoun-restaurant 3.5r-anc-assert-reco-cuisine*with-ns-infer*period-infer*period-justifyleaf-assert-reco-food-qualityperiod-infer-avg-leaves-under 3.2r-sis-merge-infer-assert-recoperiod-justify-avg-leaves-under 6.5s-anc-attr-with*have1leaf-assert-reco-best*assert-reco-cuisineleaf-assert-reco-bestmerge-infer-max-leaves-underleaf-assert-reco-food-quality*assert-reco-cuisinemerge-infer-max-leaves-under 2.5s-trav-have1*propernoun-restaurant*ii-quality*attr-among1-0.87-0.81-0.81-0.77-0.74-0.62-0.62-0.60-0.54-0.45-0.400.140.150.190.190.220.260.260.290.290.320.360.420.480.490.500.500.510.770.960.97Figure 22: subset rules largest magnitudes learned rankingrecommendations given AVG feedback.model Figure 20. Alt-8 also instantiates Rules 21 29 identicaluser ordering preferences (Rules 24 26 Figure 20) rules describe sptrees assert-reco-food-quality left frontier, trees followedassert-reco-cuisine. (See Alt-8s sp-tree Figure 16.) Rule 3 also applies Alt-8,reducing ranking due number content items realizes.similarities differences: many rules average modelsimilar either Bs models both, average model retains number446fiIndividual Domain Adaptation Dialoguepreferences seen individual models. example, Rules 1 10 reduceranking sentence plan neighborhood information combined subsequentinformation using with-ns combination operator. Rule 1 expresses termslexical items d-tree, whereas Rule 10 expresses terms semantic featuresderived sp-tree. Examples 1 2 Section 8.2 illustrate interaction.rules similar User A. example, Rules 4 9 (like Rules2 5 Figure 20) reduce rating sentence plans use operation cw-conjinfer. addition, Rules 22, 23, 24, 28 expresses preferences merging information,similar Rules 19, 21 22. Rule 15 expresses preferenceinformation atmosphere (assert-reco-decor) combined using mergeoperation, specified Rule 20. Rule 20 Figure 22 also similar Rule 16assert-reco-cuisine combined subsequent information with-ns operation.rules similar Bs model. example, Rule 5 reduces rankingsentence plans using relative clause operation, also specified User BsRule 1, Rules 16 25 indicate general preference use with-ns operation,strong preference User Bs model (see Bs Rule 18 Figure 21).Note cases, learned model tries account Bs preferences, even contradict one another. example, Rule 27 specifies preferenceclaim come first, Bs Rule 21, whereas Rule 26 24, specifying preference food quality cuisine information expressed first. Thusmodel suggest reduction performance may arise trying accountcontradictory preferences users B.9. Conclusionsarticle describes SPaRKy, two-stage sentence planner generates many alternative realizations input content plans ranks using statistical modeltrained human feedback. demonstrate training technique developedSPoT (Walker, Rambow, & Rogati, 2002), generalizes easily new domains,extended handle rhetorical structures required complex typesinformation presentation.One novel contributions paper show trainable generationused train sentence planners tailored individual users preferences. Previous work modeling individuals mainly applied content planning. studieshuman-human dialogue suggest modeling types individual differences couldvaluable spoken language generation, past, linguistic variation among individualsconsidered problem generation (McKeown, Kukich, & Shaw, 1994; Reiter, 2002;Reiter, Sripada, & Robertson, 2003). Here, show users different perceptionsquality alternative realizations content plan, individualized models perform better trained groups users. qualitative analysis indicatestrainable sentence generation sensitive variations domain application, presentationtype, individual human preferences arrangement particular content types.first results showing individual preferences apply sentence planning.also compared SPaRKy template-based generator described Section 3.2:generator highly tuned domain previously shown produce high447fiWalker, Stent, Mairesse, & Prasadquality outputs user evaluation (Stent, Prasad, & Walker, 2004). SPaRKytrained group users, template-based generation better recommendcompare-3, cases performance individualized SPRs statisticallyindistinguishable MATCHs template-based generator: exceptions that,compare-2, User B prefers SPaRKy, compare-3 User prefers templatebased generator. cases, Human scores (outputs produced SPG selectedhuman) good better template-based generator, even complexinformation presentations extended comparisons.results show gap performance trained SPRhuman performance. suggests might possible improve SPRdifferent feature sets different ranking algorithm. leave comparisonranking algorithms future work. Here, report results many different feature sets(n-gram, concept tree) investigate effect performance. Table 1 showscombination three feature sets performs significantly better recommendcompare-3 tree features earlier work (Walker, Rambow, & Rogati, 2002;Stent, Prasad, & Walker, 2004; Mairesse & Walker, 2005). Interestingly, cases,simple features like n-grams perform well features representing linguistic structuretree features. might particular lexical items, e.g. with,often uniquely associated combination operator, e.g. with-ns operator,shown impact user perceptions utterance quality (Section 8). workneeded determine whether performance similarities simply due factvariation form generated SPaRKys SPG limited. work alsoexamined tradeoffs n-gram features linguistically complex features termstradeoffs time accuracy (Pantel, Ravichandran, & Hovy, 2004). AlthoughSPaRKy trained offline, time compute features rank SPG outputs remainsissue using SPaRKy real-time spoken dialogue system.potential limitation approach time effort required elicit userfeedback training system, described Section 6. Section 7.3 showedRankLoss error rates around 0.20 could acquired much smaller training set, i.e.training set around 120 examples. However typical users would probably wantprovide ratings 120 examples. Future work explore alternative training regimesperhaps utilizing ratings several users. example, could identify examplesdistinguish existing users, present examples new users.Also, instead users rating information presentations using MATCH, perhapsmethod users rate information presentations using MATCH could developed,i.e. course dialogue MATCH recommendation comparisonpresented user, system could display screen rating formpresentation. Another approach would train different type user feedbackcollected automatically monitoring users behavior, e.g. measures cognitive loadreading time.Another limitation SPaRKys dictionary handcrafted, i.e. associationssimple assertions syntactic realizations (d-trees) specified hand, likegenerators. Recent work begun address limitation investigating techniqueslearning generation dictionary automatically different types corpora,448fiIndividual Domain Adaptation Dialogueuser reviews (Barzilay & Lee, 2002; Higashinaka, Walker, & Prasad, 2007; Snyder &Barzilay, 2007).final limitation use two individuals provide proof-of-concept argument value user-tailored trainable sentence planning. argued throughoutpaper individual differences document general, particularusers B, result random noise user feedback. Nevertheless,hope future work test results larger population individualsorder provide support arguments order characterize fullrange individual differences preferences language variation dialogue interaction.Acknowledgmentswork partially funded DARPA Communicator Contract MDA972-99-30003, Royal Society Wolfson Research Merit Award M. Walker, ViceChancellors studentship F. Mairesse.ReferencesAndre, E., Rist, T., van Mulken, S., Klesen, M., & Baldes, S. (2000). Embodied Conversational Agents, chap. automated design believable dialogues animatedpresentation teams, pp. 220255. MIT Press.Bangalore, S., & Rambow, O. (2000). Exploiting probabilistic hierarchical modelgeneration. Proc. International Conference Computational Linguistics.Barzilay, R., Elhadad, N., & McKeown, K. R. (2002). Inferring strategies sentenceordering multidocument news summarization. Journal Artificial IntelligenceResearch, 17, 3555.Barzilay, R., & Lee, L. (2002). Bootstrapping lexical choice via multiple-sequence alignment.Proc. Conference Empirical Methods Natural Language Processing.Belz, A. (2005). Corpus-driven generation weather forecasts. Proc. 3rd Corpus Linguistics Conference.Bouayad-Agha, N., Scott, D., & Power, R. (2000). Integrating content style documents: case study patient information leaflets. Information Design Journal, 9 (2),161176.Branigan, H., Pickering, M., & Cleland, A. (2000). Syntactic coordination dialogue.Cognition, 75, B13B25.Brennan, S. E., & Clark, H. H. (1996). Conceptual pacts lexical choice conversation.Journal Experimental Psychology: Learning, Memory Cognition, 22 (6), 14821493.449fiWalker, Stent, Mairesse, & PrasadBrennan, S. E., Friedman, M. W., & Pollard, C. J. (1987). centering approach pronouns. Proc. Annual Meeting Association Computational Linguistics.Brown, P., & Levinson, S. (1987). Politeness: Universals Language Usage. Cambridge University Press.Bulyko, I., & Ostendorf, M. (2001). Joint prosody prediction unit selection concatenative speech synthesis. Proc. International Conference Acoustic SpeechSignal Processing.Carenini, G., & Moore, J. D. (2000). strategy generating evaluative arguments.Proc. International Natural Language Generation Conference.Carenini, G., & Moore, J. D. (2006). Generating evaluating evaluative arguments.Artificial Intelligence Journal, 170 (11), 925952.Chai, J., Hong, P., Zhou, M., & Prasov, Z. (2004). Optimization multimodal interpretation. Proc. Annual Meeting Association Computational Linguistics.Chu-Carroll, J., & Carberry, S. (1995). Response generation collaborative negotiation.Proc. Annual Meeting Association Computational Linguistics.Clark, H. H., & Wilkes-Gibbs, D. (1986). Referring collaborative process. Cognition,22, 139.Collins, M. (2000). Discriminative reranking natural language parsing. Proc.International Conference Machine Learning.Coulston, R., Oviatt, S., & Darves, C. (2002). Amplitude convergence childrens conversational speech animated personas. Proc. International Spoken LanguageProcessing Conference.Danlos, L. (2000). G-TAG: lexicalized formalism text generation inspired treeadjoining grammar. Abeille, A., & Rambow, O. (Eds.), Tree Adjoining Grammars:Formalisms, Linguistic Analysis, Processing. CSLI Publications.Di Eugenio, B., Moore, J. D., & Paolucci, M. (1997). Learning features predict cueusage. Proc. Annual Meeting Association Computational Linguistics.DiMarco, C., & Foster, M. E. (1997). automated generation Web documentstailored individual reader. Proc. AAAI Spring SymposiumNatural Language Processing World Wide Web.Duboue, P. A., & McKeown, K. R. (2003). Statistical acquisition content selection rulesnatural language generation. Proc. Conference Empirical MethodsNatural Language Processing.450fiIndividual Domain Adaptation DialogueElhadad, N., Kan, M.-Y., Klavans, J., & McKeown, K. (2005). Customization unifiedframework summarizing medical literature. Journal Artificial IntelligenceMedicine, 33 (2), 179198.Ferguson, S. H., & Kewley-Port, D. (2002). Vowel intelligibility clear conversationalspeech normal-hearing hearing-impaired listeners. Journal AcousticalSociety America, 112 (1), 259271.Fleischman, M., & Hovy, E. (2002). Emotional variation speech-based natural languagegeneration. Proc. International Natural Language Generation Conference.Forbes, K., Miltsakaki, E., Prasad, R., Sarkar, A., Joshi, A., & Webber, B. (2003). DLTAG system: Discourse parsing lexicalized tree adjoining grammar. JournalLogic, Language Information, 12 (3), 261279.Freund, Y., Iyer, R., Schapire, R., & Singer, Y. (1998).efficient boosting algorithm combining preferences.Machine Learning: ProceedingsFifteenth International Conference.Extended version availablehttp://www.research.att.com/ schapire.Garrod, S., & Anderson, A. (1987). Saying mean dialogue: study conceptual semantic coordination. Cognition, 27, 181218.Goffman, E. (1981). Forms Talk. University Pennsylvania Press, Philadelphia, Pennsylvania, USA.Grosz, B. J., Joshi, A. K., & Weinstein, S. (1995). Centering: framework modelinglocal coherence discourse. Computational Linguistics, 21 (2), 203225.Guo, H., & Stent, A. (2005). Trainable adapatable multimedia presentation generation.Proc. International Conference Multimodal Interfaces. Demo paper.Gupta, S., Walker, M., & Romano, D. (2007). rude you?: Evaluating politenessaffect interaction. Proc. Second International Conference AffectiveComputing Intelligent Interaction.Gupta, S., & Stent, A. (2005). Automatic evaluation referring expression generation usingcorpora. Proc. Workshop Using Corpora Natural Language Generation.Hardt, D., & Rambow, O. (2001). Generation VP ellipsis: corpus-based approach.Proc. Annual Meeting Association Computational Linguistics.Higashinaka, R., Walker, M., & Prasad, R. (2007). unsupervised method learning generation lexicons spoken dialogue systems mining user reviews. ACMTransactions Speech Language Processing, 4 (4).Hovy, E. (1987). pragmatic decision criteria generation. Kempen, G. (Ed.),Natural Language Generation, pp. 317. Martinus Nijhoff.Isard, A., Brockmann, C., & Oberlander, J. (2006). Individuality alignment generateddialogues. Proc.of International Natural Language Generation Conference.451fiWalker, Stent, Mairesse, & PrasadJohnston, M., Bangalore, S., Vasireddy, G., Stent, A., Ehlen, P., Walker, M., Whittaker,S., & Maloor, P. (2002). MATCH: architecture multimodal dialogue systems.Proc. Annual Meeting Association Computational Linguistics.Jokinen, K., & Kanto, K. (2004). User expertise modelling adaptivity speech-basede-mail system. Proc. Annual Meeting Association ComputationalLinguistics.Jordan, P., & Walker, M. (2005). Learning content selection rules generating objectdescriptions dialogue. Journal Artificial Intelligence Research, 24, 157194.Joshi, A. K., Webber, B., & Weischedel, R. M. (1986). aspects default reasoninginteractive discourse. Tech. rep. MS-CIS-86-27, University Pennsylvania.Joshi, A. K., Webber, B. L., & Weischedel, R. M. (1984). Preventing false inferences.Proc. International Conference Computational Linguistics.Jungers, M. K., Palmer, C., & Speer, S. R. (2002). Time time: coordinatinginfluence tempo music speech. Cognitive Processing, 12, 2135.Kittredge, R., Korelsky, T., & Rambow, O. (1991). need domain communicationknowledge. Computational Intelligence, 7 (4), 305314.Kothari, A. (2007). Accented pronouns unusual antecedents: corpus study. Proc.8th SIGdial Workshop Discourse Dialogue.Langkilde, I., & Knight, K. (1998). Generation exploits corpus-based statistical knowledge. Proc. International Conference Computational LinguisticsMeeting Association Computational Linguistics.Langkilde-Geary, I. (2002). empirical verification coverage correctnessgeneral-purpose sentence generator. Proc. International Natural LanguageGeneration Conference.Lapata, M. (2003). Probabilistic text structuring: Experiments sentence ordering.Proc. Annual Meeting Association Computational Linguistics.Lavoie, B., & Rambow, O. (1997). fast portable realizer text generation systems.Proc. Conference Applied Natural Language Processing.Levelt, W. J. M., & Kelter, S. (1982). Surface form memory question answering.Cognitive Psychology, 14, 78106.Lin, J. (2006). Using distributional similarity identify individual verb choice. Proc.International Natural Language Generation Conference.Litman, D. (1996). Cue phrase classification using machine learning. Journal ArtificialIntelligence Research, 5, 5394.452fiIndividual Domain Adaptation DialogueLuchok, J. A., & McCroskey, J. C. (1978). effect quality evidence attitudechange source credibility. Southern Speech Communication Journal, 43, 371383.Madigan, D., Genkin, A., Lewis, D., Argamon, S., Fradkin, D., & Ye, L. (2005). Authoridentification large scale. Proc. Meeting Classification SocietyNorth America.Mairesse, F., & Walker, M. (2007). PERSONAGE: Personality generation dialogue.Proc. Annual Meeting Association Computational Linguistics.Mairesse, F., & Walker, M. (2005). Learning personalize spoken generation dialoguesystems. Proc. Interspeech.Mann, W., & Thompson, S. (1987). Rhetorical structure theory: Description construction text structures. Kempen, G. (Ed.), Natural Language Generation, pp.8396. Martinus Nijhoff.Marciniak, T., & Strube, M. (2004). Classification-based generation using TAG. Proc.International Natural Language Generation Conference.Marcu, D. (1996). Building rhetorical structure trees. Proc. ConferenceArtificial Intelligence Conference Innovative Applications Artificial Intelligence.Marcu, D. (1997). local global coherence: bottom-up approach text planning.Proc. Conference Artificial Intelligence.McCoy, K. F. (1989). Generating context-sensitive responses object related misconceptions. Artificial Intelligence, 41 (2), 157195.McKeown, K., Kukich, K., & Shaw, J. (1994). Practical issues automatic documentgeneration. Proc. Conference Applied Natural Language Processing.McKeown, K. R. (1985). Discourse strategies generating natural language text. ArtificialIntelligence, 27 (1), 142.Mellish, C., ODonnell, M., Oberlander, J., & Knott, A. (1998). architecture opportunistic text generation. Proc. Ninth International Workshop NaturalLanguage Generation.Melcuk, I. A. (1988). Dependency Syntax: Theory Practice. State University NewYork Press, Albany, New York.Moore, J. D., & Paris, C. L. (1993). Planning text advisory dialogues: Capturingintentional rhetorical information. Computational Linguistics, 19 (4), 651694.Moore, J. D., Foster, M. E., Lemon, O., & White, M. (2004). Generating tailored, comparative descriptions spoken dialogue. Proc. Seventeenth InternationalFlorida Artificial Intelligence Research Society Conference.453fiWalker, Stent, Mairesse, & PrasadNakatsu, C., & White, M. (2006). Learning say well: Reranking realizationspredicted synthesis quality. Proc. Annual Meeting AssociationComputational Linguistics.Nenkova, A., Passonneau, R. J., & McKeown, K. (2007). pyramid method: incorporating human content selection variation summarization evaluation. ACM Transactions Speech Language Processing, 4 (2).Oberlander, J., & Brew, C. (2000). Stochastic text generation. Philosophical TransactionsRoyal Society London, Series A, 358, 13731385.Paiva, D. S., & Evans, R. (2004). framework stylistically controlled generation.Proc. International Natural Language Generation Conference.Pantel, P., Ravichandran, D., & Hovy, E. (2004). Towards terascale knowledge acquisition.Proc. International Conference Computational Linguistics.Papenini, K., Roukos, S., Ward, T., & Zhu, W.-J. (2002). Bleu: method automaticevaluation machine translation. Proc. Annual Meeting AssociationComputational Linguistics.Pennebaker, J. W., & King, L. A. (1999). Linguistic styles: Language use individualdifference. Journal Personality Social Psychology, 77, 12961312.Piwek, P. (2003). flexible pragmatics-driven language generator animated agents.Proc. European Meeting Association Computational Linguistics.Polifroni, J., & Walker, M. (2006). analysis automatic content selection algorithmsspoken dialogue system summaries. Proc. IEEE/ACL ConferenceSpoken Language Technology.Porayska-Pomsta, K., & Mellish, C. (2004). Modelling politeness natural language generation. Proc. International Natural Language Generation Conference.Prasad, R., Joshi, A., Dinesh, N., Lee, A., & Miltsakaki, E. (2005). Penn DiscourseTreeBank resource natural language generation. Proc. CorpusLinguistics Workshop Using Corpora Natural Language Generation.Prevost, S. (1995). Semantics Contrast Information Structure SpecifyingIntonation Spoken Language Generation. Ph.D. thesis, University Pennsylvania.Prince, E. F. (1985). Fancy syntax shared knowledge. Journal Pragmatics, 9 (1),6581.Rambow, O., Rogati, M., & Walker, M. (2001). Evaluating trainable sentence plannerspoken dialogue travel system. Proc. Annual Meeting AssociationComputational Linguistics.Rambow, O., & Korelsky, T. (1992). Applied text generation. Proc. ConferenceApplied Natural Language Processing.454fiIndividual Domain Adaptation DialogueReiter, E. (2002). corpora gold standards NLG?. Proc. InternationalNatural Language Generation Conference.Reiter, E., & Dale, R. (2000). Building Natural Language Generation Systems. CambridgeUniversity Press.Reiter, E., & Sripada, S. (2002). Human variation lexical choice. ComputationalLinguistics, 28, 545553.Reiter, E., Sripada, S., & Robertson, R. (2003). Acquiring correct knowledge naturallanguage generation. Journal Artificial Intelligence Research, 18, 491516.Reitter, D., Keller, F., & Moore, J. D. (2006). Computational modeling structural priming dialogue. Proc. Joint Conference Human Language TechnologiesMeeting North American Chapter Association ComputationalLinguistics.Rich, E. (1979). User modelling via stereotypes. Cognitive Science, 3, 329354.Scott, D. R., & de Souza, C. S. (1990). Getting message across RST-based textgeneration. Dale, R., Mellish, C., & Zock, M. (Eds.), Current Research NaturalLanguage Generation, pp. 4773. Academic Press.Snyder, B., & Barzilay, R. (2007). Database-text alignment via structured multilabel classification. Proc. International Joint Conference Artificial Intelligence.Stenchikova, S., & Stent, A. (2007). Measuring adaptation dialogs. Proc.8th SIGdial Workshop Discourse Dialogue.Stent, A., & Guo, H. (2005). new data-driven approach multimedia presentationgeneration. Proc. EuroIMSA.Stent, A., Prasad, R., & Walker, M. (2004). Trainable sentence planning complexinformation presentation spoken dialog systems. Proc. Annual MeetingAssociation Computational Linguistics.Stent, A., Walker, M., Whittaker, S., & Maloor, P. (2002). User-tailored generationspoken dialogue: experiment. Proc. International Conference SpokenLanguage Processing.Wahlster, W., & Kobsa, A. (1989). User models dialogue systems. User ModelsDialogue Systems, pp. 434. Springer Verlag, Berlin.Walker, M., Rambow, O., & Rogati, M. (2002). Training sentence planner spokendialogue using boosting. Computer Speech Language: Special Issue SpokenLanguage Generation, 16 (3-4), 409433.Walker, M. A., Cahn, J. E., & Whittaker, S. J. (1997). Improvising linguistic style: Socialaffective bases agent personality. Proc. First Conference AutomousAgents.455fiWalker, Stent, Mairesse, & PrasadWalker, M. A., et al. (2002). DARPA communicator: Cross-system results 2001evaluation. Proc. International Spoken Language Processing Conference.Walker, M. A., et al. (2004). Generation evaluation user tailored responses multimodal dialogue. Cognitive Science, 28 (5), 811840.Webber, B., Knott, A., Stone, M., & Joshi, A. (1999). little trees made of?:structural presuppositional account using lexicalized tag. Proc. AnnualMeeting Association Computational Linguistics.Yeh, C.-L., & Mellish, C. (1997). empirical study generation anaphoraChinese. Computational Linguistics, 23-1, 169190.Zukerman, I., & Litman, D. (2001). Natural language processing user modeling: Synergies limitations. User Modeling User-Adapted Interaction, 11 (1-2), 129158.456fiJournal Artificial Intelligence Research 30 (2007) 565-620Submitted 3/07; published 12/07Probabilistic Planning via Heuristic Forward SearchWeighted Model CountingCarmel DomshlakDCARMEL @ IE . TECHNION . AC . ILTechnion - Israel Institute Technology,Haifa, IsraelJorg HoffmannJ OERG .H OFFMANN @ DERI .University Innsbruck, DERI,Innsbruck, AustriaAbstractpresent new algorithm probabilistic planning observability. algorithm,called Probabilistic-FF, extends heuristic forward-search machinery Conformant-FF problems probabilistic uncertainty initial state action effects. Specifically,Probabilistic-FF combines Conformant-FFs techniques powerful machinery weightedmodel counting (weighted) CNFs, serving elegantly define search spaceheuristic function. evaluation Probabilistic-FF shows fine scalability range probabilistic domains, constituting several orders magnitude improvement previous resultsarea. use problematic case point main open issue addressedresearch.1. Introductionpaper address problem probabilistic planning observability (Kushmerick,Hanks, & Weld, 1995), also known AI planning community conditional (Majercik &Littman, 2003) conformant (Hyafil & Bacchus, 2004) probabilistic planning. problemsgiven initial belief state form probability distribution world states W ,set actions (possibly) probabilistic effects, set alternative goal states WG W .solution problem single sequence actions transforms system onegoal states probability exceeding given threshold . basic assumptionproblem system cannot observed time plan execution. settinguseful controlling systems uncertain initial state non-deterministic actions, sensingexpensive unreliable. Non-probabilistic conformant planning may fail due non-existenceplan achieves goals 100% certainty. Even plan, plannecessarily contain information actions useful achieve requestedthreshold .state-of-the-art performance probabilistic planners advancing much slowlydeterministic planners, scaling 5-10 step plans problems 20 world states15-20 step plans problems 100 world states (Kushmerick et al., 1995; Majercik &Littman, 1998; Hyafil & Bacchus, 2004). Since probabilistic planning inherently harderdeterministic counterpart (Littman, Goldsmith, & Mundhenk, 1998), difference evolutionrates surprising. However, recent developments area (Onder, Whelan, & Li,2006; Bryce, Kambhampati, & Smith, 2006; Huang, 2006), particular work here, showdramatic improvements probabilistic planning obtained.c2007AI Access Foundation. rights reserved.fiD OMSHLAK & H OFFMANNpaper introduce Probabilistic-FF, new probabilistic planner based heuristic forward search space implicitly represented probabilistic belief states. planner naturalextension recent (non-probabilistic) conformant planner Conformant-FF (Hoffmann & Brafman, 2006). main trick replace Conformant-FFs SAT-based techniques recentpowerful technique probabilistic reasoning weighted model counting (WMC) propositional CNFs (Sang, Beame, & Kautz, 2005). detail, Conformant-FF forward searchbelief space belief state corresponds set world states consideredpossible. main trick Conformant-FF use CNF formulas implicit representation belief states. Implicit, context, means formulas (a) encode semanticsexecuting action sequence initial belief state, propositional variables correspondingfacts time-stamps. actual knowledge belief states (and be) inferredformulas. particularly, fact p known true belief state(a) p(m), time endpoint formula. knowledge computedConformant-FF belief states known facts, well (symmetrically) factsknown false. suffices STRIPS-style planning, is, determine applicableactions goal belief states. heuristic function, FFs (Hoffmann & Nebel, 2001) relaxedplanning graph technique enriched approximate SAT reasoning.basic ideas underlying Probabilistic-FF are:(i) Define time-stamped Bayesian networks (BNs) describing probabilistic belief states.(ii) Extend Conformant-FFs belief state CNFs model BNs.(iii) addition SAT reasoning used Conformant-FF, use weighted model-countingdetermine whether probability (unknown) goals belief state high enough.(iv) Introduce approximate probabilistic reasoning Conformant-FFs heuristic function.Note synergetic effect: Probabilistic-FF re-uses Conformant-FFs technology recognizefacts true false probability 1. fully serves determine applicable actions,well detect whether part goal already known. fact, Conformant-FFs CNFbased techniques specifically made suit probabilistic setting: without probabilitiesone could imagine successfully replacing CNFs BDDs, probabilities seems muchproblematic.algorithms present cover probabilistic initial belief states given Bayesian networks,deterministic probabilistic actions, conditional effects, standard action preconditions.experiments show approach quite effective range domains. contrastSAT CSP based approaches mentioned (Majercik & Littman, 1998; Hyafil & Bacchus,2004), Probabilistic-FF find 100-step plans problem instances billions world states.However, comparison entirely fair due different nature results provided;SAT CSP based approaches provide guarantees length solution. approachclosely related Probabilistic-FF implemented POND (Bryce et al., 2006): system, likeProbabilistic-FF, conformant probabilistic planning threshold , using non-admissible,planning-graph based heuristic guide search. Hence comparison Probabilistic-FFPOND fair, experiments perform comparative evaluation Probabilistic-FFPOND. two approaches related, significant differences search566fiP ROBABILISTIC -FFspace representation, well definition computation heuristic function.1 runtwo approaches range domains partly taken probabilistic planning literature,partly obtained enriching conformant benchmarks probabilities, partly obtainedenriching classical benchmarks probabilistic uncertainty. almost cases, Conformant-FFoutperforms POND least order magnitude. make interesting observationsregarding behavior two planners; particular identify domain derivedclassical Logistics domain approaches fail scale. apparent reason neitherapproach good enough detecting many times, early point plan, probabilisticaction must applied order sufficiently support high goal threshold end plan.Devising methods better regard pressing open issue line work.paper structured follows. next section provides technical background, formallydefining problem address illustrating running example. Section 3 detailsprobabilistic belief states represented time-stamped Bayesian networks, Bayesiannetworks encoded weighted CNF formulas, necessary reasoning performedrepresentation. Section 4 explains illustrates extension Conformant-FFs heuristic function probabilistic settings. Section 5 provides empirical results, Section 6concludes. proofs moved Appendix A.2. Backgroundprobabilistic planning framework consider adds probabilistic uncertainty subsetclassical ADL language, namely (sequential) STRIPS conditional effects. STRIPSplanning tasks described set propositions P triples (A, I, G), correspondingaction set, initial world state, goals. G sets propositions, describesconcrete initial state wI , G describes set goal states w G. Actions pairs(pre(a), E(a)) precondition (conditional) effects. conditional effect e triple(con(e), add(e), del(e)) (possibly empty) proposition sets, corresponding effects condition, add, delete lists, respectively. precondition pre(a) also proposition set,action applicable world state w w pre(a). applicable w,result applying w undefined. applicable w, conditional effectse E(a) w con(e) occur. Occurrence conditional effect e w results worldstate w add(e) \ del(e).action applied w, proposition q q add(e) del(e )(possibly same) occurring e, e E(a), result applying w undefined. Thus,require actions self-contradictory, is, A, every e, e E(a),exists world state w con(e) con(e ), add(e) del(e ) = . Finally, actionsequence plan world state results iterative execution actions, startingwI , leads goal state w G.2.1 Probabilistic Planningprobabilistic planning setting extends (i) probabilistic uncertaintyinitial state, (ii) actions probabilistic effects. general, probabilistic planning1. POND use implicit belief states, probabilistic part heuristic function uses sampling techniques,rather probabilistic reasoning techniques employ.567fiD OMSHLAK & H OFFMANNtasks quadruples (A, bI , G, ), corresponding action set, initial belief state, goals,acceptable goal satisfaction probability. before, G set propositions. initial statelonger assumed known precisely. Instead, given probability distributionworld states, bI , bI (w) describes likelihood w initial world state.Similarly classical planning, actions pairs (pre(a), E(a)), effect set E(a)richer structure semantics. e E(a) pair (con(e), (e)) propositional condition set probabilistic outcomes. probabilistic outcome (e)triplet (P r(), add(), del()), add delete lists before, P r() probability outcome occurs result effect e. Naturally,P require probabilistic effectsdefine probability distributions outcomes, is, (e) P r() = 1. special casedeterministic effects e modeled way via (e) = {} P r() = 1. Unconditional actionsmodeled single effect e con(e) = . before, applicable w,result applying w undefined. Otherwise, applicable w, existsexactly one effect e E(a) con(e) w, (e), applying w resultsw add() \ del() probability P r(). likelihood [b, a] (w ) world state wbelief state [b, a], resulting applying probabilistic action b, given[b, a] (w ) =Xwpre(a)b(w)X(e)P r() w = w \ , add(), del() ,(1)e effect con(e) w, () Kronecker step function takesvalue 1 argument predicate evaluates TRUE, 0 otherwise.formalism covers problem-description features supported previously proposedformalisms conformant probabilistic planning (Kushmerick et al., 1995; Majercik & Littman,1998; Hyafil & Bacchus, 2004; Onder et al., 2006; Bryce et al., 2006; Huang, 2006), corresponds called Unary Nondeterminism (1ND) normal form (Rintanen, 2003). notesuccinct forms specifying probabilistic planning problems (Rintanen, 2003),yet 1ND normal form appears intuitive perspective knowledge engineering.Example 1 Say robot block physically one two locations.information captured propositions r1 , r2 robot, b1 , b2 block, respectively. robot either move one location another, carrying block.robot moves without block, move guaranteed succeed. provides uspair symmetrically defined deterministic actions {move-right, move-lef t}. action move-right empty precondition, single conditional effect e = ({r1 }, {})P r() = 1, add() = {r2 }, del() = {r1 }. robot tries move carrying block,move succeeds probability 0.7, probability 0.2 robot ends movingwithout block, probability 0.1 move robot fails completely. provides uspair (again, symmetrically defined) probabilistic actions {move-b-right, move-b-lef t}.action move-b-right empty precondition, two conditional effects specifiedTable 1.specified semantics structure components (A, bI , G, ) ,ready specify actual task probabilistic planning setting. Recall actionstransform probabilistic belief states belief states. action sequence , belief568fiP ROBABILISTIC -FFE(a)con(e)er1 b 1er1 b1(e)P r()add()del()12310.70.20.11.0{r2 , b2 }{r2 }{r1 , b1 }{r1 }Table 1: Possible effects outcomes action move-b-right Example 1.state b, new belief state [b, a] resulting applying b given= hib,[b, a] = [b, a] ,.= hai,[[b, a] , ] , = hai , A, 6=(2)setting, achieving G certainty typically unrealistic. Hence, specifies requiredlower bound probability achieving G. sequence actions called planba (G) belief state ba = [bI , a].2.2 Specifying Initial Belief StateConsidering initial belief state, practical considerations force us limit attentioncompactly representable probability distributions bI . numerous alternativescompact representation structured probability distributions, Bayes networks (BNs) (Pearl, 1988)date far popular representation model.2 Therefore, Probabilistic-FFassume initial belief state bI described BN NbI set propositions P.excellent introductions BNs abound (e.g., see Jensen, 1996), suffices brieflydefine notation. BN N = (G, ) represents probability distribution directed acyclicgraph G, set nodes X stands random variables (assumed discrete paper),, set tables conditional probabilities (CPTs)one table TX node X X .possible value x Dom(X) (where Dom(X) denotes domain X), table TXlists probability event X = x given possible value assignment immediateancestors (parents) P a(X) G. Thus, table size exponential in-degree X. Usually,assumed either in-degree small (Pearl, 1988), probabilistic dependence XP a(X) induces significant local structure allowing compact representation TX (Shimony,1993, 1995; Boutilier, Friedman, Goldszmidt, & Koller, 1996). (Otherwise, representationdistribution BN would good idea first place.) joint probability completeassignment variables X given product |X | terms taken respectiveCPTs (Pearl, 1988):P r ([X] | [P a(X)]) =TX ([X] | [P a(X)]) ,P r() =XXXX[] stands partial assignment provided corresponding subset X .2. BNs choice here, framework support models well, e.g. stochastic decision trees.569fiD OMSHLAK & H OFFMANNProbabilistic-FF allow NbI described multi-valued variables underlyingplanning problem. significantly simplifies process specifying NbI since STRIPS3propositions PSknot correspond true random variables underlying problem specification.Specifically, let i=1 Pi partition P proposition set Pi uniquely correspondsdomain multi-valued variable underlying problem. is, every world state wevery Pi , |Pi | > 1, exactly one proposition q Pi holds w. variablesBN NbI describing initial belief state bI X = {X1 , . . . , Xk }, Dom(Xi ) = Pi|Pi | > 1, Dom(Xi ) = {q, q} Pi = {q}.Example 2 illustration NbI , consider running example, say robotknown initially one two possible locations probability P r(r1 ) = 0.9P r(r2 ) = 0.1. Suppose correlation belief initial locations robotblock. believe that, robot r1 , P r(b1 ) = 0.7 (and P r(b2 ) = 0.3),robot r2 , P r(b1 ) = 0.2 (and P r(b2 ) = 0.8). initial belief state BN NbI definedtwo variables R (robot) B (block) Dom(R) = {r1 , r2 } Dom(B) = {b1 , b2 },respectively, depicted Figure 1.r10.9r20.1R// Br1r2b10.70.2b20.30.8Figure 1: Bayes network NbI Example 1.hard see STRIPS-style actions equivalently specified termsmulti-valued variables X . Specifically, |Pi | > 1, action add propositionq Pi without deleting proposition q Pi , thus, consider settingXi = q. |Pi | = 1, adding deleting q Pi standard semantics setting Xi = qXi = q, respectively. simplicity presentation, assume actions selfcontradictory level X wellif two conditional effects e, e E(a) possibly occurworld state w, subsets X affected two effects disjoint. Finally,goal G directly corresponds partial assignment X (unless G self-contradictory,requiring q q q, q Pi .)3. Belief Statessection, explain representation of, reasoning about, belief states. first explainprobabilistic belief states represented time-stamped BNs, explainBNs encoded reasoned form weighted CNF formulas. representationbelief states weighted CNFs illustrated belief state running exampleFigure 2. finally provide details works Probabilistic-FF.3. Specifying NbI directly P would require identifying multi-valued variables anyway, followed connectingpropositions corresponding multi-valued variable complete DAG, normalizing CPTspropositions certain manner.570fiP ROBABILISTIC -FF1 2r3 1 1r2r1 r20.9 0.1R(0)B(0)IIIIIIIIII$$::uuuuuuuuuub1 b2r1 0.7 0.3r2 0.2 0.8Y(1)r1010r2101// Rn66 (1)nnnnnnnnnn1 2 3 1nnnnnr1 b1 0.7 0.2 0.1 0PPPPPP0 0 0 1PPP othrwPPPPPPP((// B(1)b1 b210 1b 1 01 1b2 0 1r1 r2r1 1 0r2 1 0// R(2)// B(2)b1 b2b1 1 0b2 0 1Figure 2: Bayes network Nba running Example 1-2 action sequence= hmove-b-right, move-lef ti.3.1 Bayesian NetworksProbabilistic-FF performs forward search space belief states. search states beliefstates (that is, probability distributions world states w), search restricted beliefstates reachable initial belief state bI sequences actions a. key decisionone make actual representation belief states. Let bI initial belief statecaptured BN NbI , let ba belief state resulting applying bI sequenceactions a. One well-known problems area decision-theoretic planningdescription ba directly state variables X becomes less less structured number(especially stochastic) actions increases. overcome limitation, represent beliefstates ba BN Nba explicitly captures sequential application starting bI , tradingrepresentation size cost inference, compared representing belief states directlydistributions world states. formally specify structure BN Nba , assumingactions applicable corresponding belief states application, latershowing Probabilistic-FF makes sure indeed case. note belief-stateBNs similar spirit structure proposed AI literature verifyingprobabilistic plan achieves goals certain probability (Dean & Kanazawa, 1989; Hanks &McDermott, 1994; Kushmerick et al., 1995).Figure 2 illustrates construction Nba running example = hmove-b-right,move-lef ti. general, let = ha1 , . . . , sequence actions, numbered accordingappearance a. 0 m, let X(t) replica state variables X , X(t) X(t)571fiD OMSHLAK & H OFFMANNcorresponding X X . variable set Nba union X(0) , . . . , X(m) , plusadditional variables introduce actions a.First, X(0) X(0) , set parents P a(X(0) ) conditional probability tablesTX(0) simply copy state variable X NbI . Now, consider action a,let = a. action introduce discrete variable Y(t)mediatesvariable layers X(t1) X(t) . domain Y(t) set Dom(Y(t) ) = eE(a) (e), is,union probabilistic outcomes possible effects a. parents Y(t) Nba setP a(Y(t) ) =[eE(a)X(i1) | con(e) Dom(X) 6= ,(3)and, Dom(P a(Y(t) )), setTY (t) (Y(i)(P r(),= | ) =0,con (e()),otherwise(4)e() denotes effect e (e).refer set variables Y(t) created actions Y. Now, let EX (a)E(a) probabilistic effects affect variable X X . EX (a) = , setP a(X(t) ) = {X(t1) },(1, x = x ,.(5)TX(t) (X(t) = x | X(t1) = x ) =0, otherwiseOtherwise, EX (a) 6= , let x Dom(X) value provided X (e), e EX (a).Recall outcomes effects E(a) mutually exclusive. Hence, set P a(X(t) ) ={X(t1) , Y(t1) },TX(i) (X(i) = x | X(i1) = x , Y(i1)1,= ) = 1,0,e() EX (a) x = x ,e() 6 EX (a) x = x , ,otherwise(6)e() denotes effect responsible outcome .hard verify Equations 4-6 capture frame axioms probabilistic semantics ourSactions. principle, accomplishes construction Nba variablesXba =t=0 X(t) . note, however, mediating variable Y(t) really neededtruly probabilistic actions. Specifically, deterministic action a, let EX (a) E(a)conditional effects add and/or delete propositions associated domain variable X X . EX (a) = , set P a(X(t) ) = {X(t1) }, TX(t) according Equation 5.Otherwise, set[nP a(X(t) ) = {X(t1) }X(t1)| con(e) Dom(X) 6= ,(7)eEX (a)specify TX(t) follows. Let xe Dom(X) value (the deterministic outcomeof) effect e EX (a) provides X. Dom(P a(X(t) )), exists e EX (a)572fiP ROBABILISTIC -FFcon(e) , setTX(t) (X(t)(1,= x | ) =0,x = xe ,otherwise(8)x = [X(t1) ],otherwise(9)Otherwise, setTX(t) (X(t)(1,= x | ) =0,Due self-consistency action, hard verify Equations 8-9 consistent,and, together Equation 5, capture semantics conditional deterministic actions.special treatment deterministic actions illustrated Figure 2 direct dependenciesX(2) X(1) .Proposition 1 Let (A, NbI , G, ) probabilistic planning problem, m-step sequenceactions applicable bI . Let P r joint probability distribution induced Nbavariables Xba . belief state ba corresponds marginal distribution P r X(m) , is:ba (X ) = P r(X(m) ), G(m) partial assignment provided G X(m) , probabilityba (G) achieves G starting bI equal P r(G(m) ).already mentioned, belief-state BNs constructed along principles outlinedused Dean Kanazawa (1989), Hanks McDermott (1994), Kushmerick et al.(1995), thus correctness Proposition 1 immediate previous results.point, worth bringing attention fact variables X(1) , . . . , X(m) completelydeterministic. Moreover, CPTs variables Nba compactly representable dueeither low number parents, local structure induced large amount context-specificindependence, both. compactness CPTs Nba implied compactnessSTRIPS-style specification planning actions. exploiting compactness actionspecification, size Nba description kept linear size inputnumber actions a.Proposition 2 Let (A, NbI , G, ) probabilistic planning problem described k state variables, m-step sequence actions A. Then, |Nba | = O(|NbI |+m(k+1))largest description size action A.proof Proposition 2, well proofs formal claims paper, relegatedAppendix A, pp. 613.3.2 Weighted CNFsGiven representation belief states BNs, next select mechanism reasoningBNs. general, computing probability query BNs known #Pcomplete (Roth, 1996). addition, hard verify, using analysis similar onesDarwiche (2001) Brafman Domshlak (2006), networks arising worktypically exhibit large tree-width. numerous exact algorithms inference BNsproposed literature (Darwiche, 2000; Dechter, 1999; Zhang & Poole, 1994),classical algorithms scale well large networks exhibiting high tree-width. positive573fiD OMSHLAK & H OFFMANNside, however, observation guides recent advances area probabilistic reasoningreal-world domains typically exhibit significant degree deterministic dependenciescontext-specific independencies problem variables. Targeting property practicalBNs already resulted powerful inference techniques (Chavira & Darwiche, 2005; Sang et al.,2005). general principle underlying techniques(i) Compile BN N weighted propositional logic formula (N ) CNF,(ii) Perform efficient weighted model counting (N ) reusing (and adapting) certaintechniques appear powerful enhancing backtracking DPLL-style search SAT.One observation early stages developing Probabilistic-FF typenetworks type queries problems make machinery solving BNsweighted CNF model counting attractive needs. First, Section 3.1 alreadyshown BNs representing belief states exhibit large amount deterministic nodescontext-specific independence. Second, queries interest correspond computingprobability evidence G(m) Nba , type query clear interpretation termsmodel counting (Sang et al., 2005). Hence, taking route Probabilistic-FF, compilebelief state BNs weighted CNFs following encoding scheme proposed Sang et al. (2005),answer probabilistic queries using Cachet (Sang, Bacchus, Beame, Kautz, & Pitassi, 2004), onepowerful systems date exact weighted model counting CNFs.general, weighted CNFs weights formulas specified follows. LetV = {V1 , . . . , Vn } set propositional variables Dom(Vi ) = {vi , vi }, let :0+ non-negative, real-valued weight function literals V.Dom(Vi ) Rpartial assignment V,Qweight () assignment defined product literalsweights, is, () = l (l). Finally, propositional logic formula called weighteddefined weighted set propositional variables. weighted formula V,weight () defined sum weights complete assignments V satisfying, is,X() =() ( |= ),Dom(V)Dom(V) = Dom(Vi ). instance, variables Vi (vi ) = (vi ) = 1,() simply stands number complete assignments V satisfy .Given initial belief state BN NbI , sequence actions = ha1 , . . . , applicablebI , describe weighted CNF encoding (Nba ) (or (ba ), short) belief stateba built used Probabilistic-FF. First, formally specify generic scheme introducedSang et al. (2005) encoding BN N variables X weighted CNF (N ).encoding formula (N ) contains two sets variables. First, variable Z Xvalue z Dom(Z), formula (N ) contains state proposition literals {z, z}, weighted(z) = (z) = 1. state propositions act (ba ) regular SAT propositions. Now,variable Z Xba , let Dom(Z) = {z1 , . . . , zk } arbitrary fixed ordering Dom(Z).Recall row TZ [i] CPT Z corresponds assignment (or set assignments) P a(Z). Thus, number rows TZ upper bounded number differentassignments P a(Z), (as happens case) significantly lower dependence Z P a(Z) induces substantial local structure. Following ordering Dom(Z)above, entry TZ [i, j] contains conditional probability P r(zj | ). every CPT entry574fiP ROBABILISTIC -FFprocedure basic-WMC()= return 1empty clause return 0select variable Vreturn basic-WMC(|v ) (v) + basic-WMC(|v ) (v)Figure 3: Basic DPPL-style weighted model counting.TZ [i, j] last one (i.e., TZ [i, k]), formula (N ) contains chance proposition literals{hzji i, hzji i}. chance variables aim capturing probabilistic information CPTsNba . Specifically, weight literal hzji set P r(zj | , z1 , . . . , zj1 ),conditional probability entry true, given row true, prior entry rowtrue:TZ [i, j]Pj11 k=1 TZ [i, k]hzj = 1 hzjihzji =(10)Considering clauses (N ), variable Z X , CPT entry TZ [i, j],formula (N ) contains clausehz1i hzj1hzji zj ,(11)conjunction literals forming assignment Dom(P a(Z)). clausesensure weights complete assignments variables (N ) equal probability corresponding atomic events postulated BN N . illustrate constructionEquations 10-11, let boolean variables B parents ternary variable C (withDom(C) = {C1 , C2 , C3 }) BN, let P r(C1 |A, B) = 0.2, P r(C2 |A, B) = 0.4,P r(C3 |A, B) = 0.4. Let raw corresponding assignment A, B P a(C) i-throw CPT TC . encoding BN, first two entries raw TC capturedpair respective chance propositionshC1i i, hC2i i. AccordingEquation 10, weights0.4propositions set hC1 = 0.2, hC1 = 10.2 = 0.5. Then, accordingEquation 11, encoding contains three clausesB hC1i C1B hC1i hC2i C2B hC1i hC2i C3Finally, variable Z X , formula (N ) contains standard set clauses encodingexactly one relationship state propositions capturing value Z. accomplishes encoding N (N ). next Section 3.3 illustrate encodingbelief state BN running example.weighted CNF encoding (ba ) belief state BN Nba provides input weightedmodel counting procedure. simple recursive DPPL-style procedure basic-WMC underlying Cachet (Sang et al., 2004) depicted Figure 3, formula |v obtained setting575fiD OMSHLAK & H OFFMANNliteral v true. Theorem 3 Sang et al. (2005) shows weighted CNF encodingBN N , P r(Q|E) general query respect N , query Q, evidence E,have:basic-WMC( Q E)P r(Q|E) =,(12)basic-WMC( E)query Q evidence E fact arbitrary formulas propositional logic. Note that,special (and relevant us) case empty evidence, Equation 12 reduces P r(Q) =basic-WMC(Q), is, single call basic-WMC procedure. Corollary 3 immediateProposition 1 Theorem 3 Sang et al. (2005).Corollary 3 Let (A, bI , G, ) probabilistic planning task BN NbI describing bI ,m-step sequence actions applicable bI . probability ba (G) achieves G startingbI given by:ba (G) = WMC ((ba ) G(m)) ,(13)G(m) conjunction goal literals time-stamped time endpoint a.3.3 Example: Weighted CNF Encoding Belief Statesillustrate generic BN-to-WCNF encoding scheme Sang et al. (2005) beliefstate BN Nba running example Figure 2.0 2, introduce time-stamped state propositions r1 (i), r2 (i), b1 (i), b2 (i). Likewise,introduce four state propositions 1 (1), 2 (1), 3 (1), 1 (1) corresponding valuesvariable Y(1) . first set clauses (ba ) ensure exactly one relationshipstate propositions capturing value variable Nba :1 (1) 2 (1) 3 (1) 1 (1) ,1i<j4 :(yi (1) yj (1)) ,0i2 :(14)(r1 (i) r2 (i)) , (r1 (i) r2 (i))(b1 (i) b2 (i)) , (b1 (i) b2 (i))proceed encoding CPTs Nba . root nodes one rowCPTs chance propositions identified corresponding state variables (Sanget al., 2005). Hence, root variable R(0) need neither additional clauses specialchance propositions, state proposition r1 (0) (ba ) treated chance proposition(r1 (0)) = 0.9.Encoding variable B(0) bit involved. CPT TB(0) contains two (content-wisedifferent) rows corresponding given r1 given r2 cases, cases inducenon-deterministic dependence B(0) R(0) . encode content TB(0) introducetwo chance variables hb1 (0)1 hb1 (0)2 (hb1 (0)1 i) = 0.7 (hb1 (0)2 i) = 0.2.positive literals hb1 (0)1 hb1 (0)2 capture events b1 given r1 b1 given r2 ,negations hb1 (0)1 hb1 (0)2 capture complementary events b2 given r2 b2given r2 , respectively. consider given r1 row TB(0) . encode row, need576fiP ROBABILISTIC -FF(ba ) contain r1 (0) hb1 (0)1 b1 (0) r1 (0) hb1 (0)1 b2 (0). Similar encodingrequired row given r2 , thus encoding TB 0 introduces four additional clauses:r1 (0) hb1 (0)1 b1 (0) , r1 (0) hb1 (0)1 b2 (0)(15)r2 (0) hb1 (0)2 b1 (0) , r2 (0) hb1 (0)2 b2 (0)finished NbI part Nba , proceed encoding variable Y(1) corresponding probabilistic action move-b-right. encode first row TY(1) introduce three chance propositions h1 (1)1 i, h2 (1)1 i, h3 (1)1 i; general, chance variables needed last entries CPT rows. weights chance propositions0.2= 0.6(6),set according Equation 10 h1 (1)1 = 0.7, h2 (1)1 = 10.70.11h3 (1) = 10.9 = 0.1. Using chance propositions, add (ba ) four clausesEquation 11, notably first four clauses Equation 16 below.Proceeding second row TY(1) , observe value R(0) B(0) case fullydetermines value Y(1) . deterministic dependence encoded without usingchance propositions using last two clauses Equation 16.r1 (0) b1 (0) h1 (1)1 1 (1) ,r1 (0) b1 (0) h1 (1)1 h2 (1)1 2 (1) ,r1 (0) b1 (0) h1 (1)1 h2 (1)1 h3 (1)1 3 (1) ,(16)r1 (0) b1 (0) h1 (1)1 h2 (1)1 h3 (1)1 1 (1) ,r1 (0) 1 (1) , b1 (0) 1 (1)Using state/chance variables introduced R0 , B 0 , Y(1) , encode CPTs R(1)B(1) as:R(1) : (1 (1) r2 (1)) , (2 (1) r2 (1)) ,(3 (1) r1 (0) r1 (1)) , 1 (1) r1 (0) r1 (1) ,(3 (1) r1 (0) r1 (1)) , 1 (1) r2 (0) r2 (1)B(1) : (1 (1) b2 (1)) ,(17)(1 (1) b1 (0) b1 (1)) ,(1 (1) b2 (0) b2 (1))Since CPTs R(1) B(1) completely deterministic, encoding well usingchance propositions. Finally, encode (deterministic) CPTs R(2) B(2) as:R(2) : (r1 (2))B(2) : (b1 (1) b1 (2))(18)(b2 (1) b2 (2))unary clause (r1 (2)) reduction (r1 (1) r1 (2)) (r2 (1) r1 (2)). accomplishes encoding (ba ).577fiD OMSHLAK & H OFFMANN3.4 Conformant-FF Probabilistic-FFBesides fact weighted model counting attractive kinds BNs arising context, weighted CNF representation belief states works extremely well ideas underlying Conformant-FF (Hoffmann & Brafman, 2006). outlined introduction already;give details.stated, Conformant-FF forward search non-probabilistic belief spacebelief state corresponds set world states considered possible. main trickConformant-FF use CNF formulas implicit representation belief states,formulas (a) encode semantics executing action sequence initial belief state. Factsknown true false inferred formulas. computation partialknowledge constitutes lazy kind belief state representation, comparison approachesuse explicit enumeration (Bonet & Geffner, 2000) BDDs (Bertoli, Cimatti, Pistore, Roveri,& Traverso, 2001) fully represent belief states. basic ideas underlying Probabilistic-FF are:(i) Define time-stamped Bayesian Networks (BN) describing probabilistic belief states (Section 3.1 above).(ii) Extend Conformant-FFs belief state CNFs model BN (Section 3.2 above).(iii) addition SAT reasoning used Conformant-FF, use weighted model-countingdetermine whether probability (unknown) goals belief state high enough(directly below).(iv) Introduce approximate probabilistic reasoning Conformant-FFs heuristic function (Section 4 below).detail, given probabilistic planning task (A, bI , G, ), belief state ba correspondingapplicable bI m-step action sequence a, proposition q P, say q knownba ba (q) = 1, negatively known ba ba (q) = 0, unknown ba , otherwise. begindetermining whether q known, negatively known, unknown time m. Re-usingConformant-FF machinery, classification requires two SAT tests (ba ) q(m)(ba ) q(m), respectively. information provided classification used threefold. First,subgoal g G negatively known time m, ba (G) = 0. extreme,subgoals G known time m, ba (G) = 1. Finally, subgoalsG known rest unknown time m, accomplish evaluating belief state batesting whetherba (G) = WMC ((ba ) G(m)) .(19)Note also sets (positively/negatively) known propositions time stepsallows us significantly simplify CNF formula (ba ) G(m) insertingcorresponding values known propositions.evaluating considered action sequence a, get ba (G) , done.Otherwise, forward search continues, actions applicable ba (and thus usedgenerate successor belief states) actions whose preconditions known ba .578fiP ROBABILISTIC -FF4. Heuristic Functionkey component heuristic search procedure heuristic function. quality (informedness) computational cost function determine performance search.heuristic function usually obtained solutions relaxation actual problem interest (Pearl, 1984; Russell & Norvig, 2004). classical planning, successful ideause relaxation ignores delete effects actions (McDermott, 1999; Bonet & Geffner,2001; Hoffmann & Nebel, 2001). particular, heuristic FF planning system basednotion relaxed plan, plan achieves goals assuming deletelists actions empty. relaxed plan computed using Graphplan-style (Blum & Furst,1997) technique combining forward chaining graph construction phase backward chainingplan extraction phase. heuristic value h(w) FF provides world state w encounteredsearch length relaxed plan w. Conformant-FF, methodologyextended setting conformant planning initial state uncertainty (without uncertaintyaction effects). Herein, extend Conformant-FFs machinery handle probabilistic initialstates effects. Section 4.1 provides background techniques used FF ConformantFF, Sections 4.2 4.4 detail algorithms forward backward chaining phasesProbabilistic-FF, respectively. algorithms two phases Probabilistic-FF heuristiccomputation illustrated running example Sections 4.3 4.5, respectively.4.1 FF Conformant-FFspecify relaxed plans computed FF; provide coarse sketchcomputed Conformant-FF. purpose latter slowly prepare readercome: Conformant-FFs techniques re-used Probabilistic-FF anyway, hencedescribed full detail part Sections 4.2 4.4.Formally, relaxed plans classical planning computed follows. Starting w, FFbuilds relaxed planning graph sequence alternating proposition layers P (t) actionlayers A(t), P (0) w, A(t) set actions whose preconditionscontained P (t), P (t + 1) obtained P (t) including add effects (with fulfilledconditions) actions A(t). is, P (t) always contains facts true onewould execute (the relaxed versions of) actions earlier layers A(t 1). relaxedplanning graph constructed either reaches propositional layer P (m) containsgoals, construction reaches fixpoint P (t) = P (t + 1) without reaching goals.latter case corresponds (all) situations relaxed plan exist,existence relaxed plan necessary condition existence real plan, state wexcluded search space setting h(w) = . former case G P (m), relaxedplan subset actions A(1), . . . , A(m) suffices achieve goals (under ignoringdelete lists), extracted simple backchaining loop: goal P (m), selectaction A(1), . . . , A(m) achieves goal, iterate process consideringactions preconditions respective effect conditions new subgoals. heuristic estimateh(w) set length extracted relaxed plan, is, number actions selectedbackchaining process.Aiming extending machinery FF conformant planning, Conformant-FF, Hoffmann Brafman (2006) suggested extend relaxed planning graph additional fact layers (t) containing facts unknown time t, reason unknown579fiD OMSHLAK & H OFFMANNfacts become known relaxed planning graph. complexity type reasoningprohibitive, Conformant-FF relaxes planning task ignoring delete lists,also one unknown conditions action effect. is, action appearslayer A(t), effect e con(e) P (t) (t) con(e) (t) 6= ,con(e) (t) arbitrarily reduced contain exactly one literal, reasoning donecon(e) reduced form beginning.Vrelaxation converts implications ( ccon(e)uP (t) c(t)) q(t + 1) action effectsinduce unknown propositions 2-projections take form binary implications c(t) q(t + 1), arbitrary c con(e) (t). Due layered structureplanning graph, set binary implications c(t) q(t + 1) seen formingdirected acyclic graph Imp. given relaxations, graph captures exactly dependencies truth propositions time. Hence, checking whether proposition q becomesknown time done follows. First, backchain implication edges Imp endq(t), collect set support(q(t)) leafs4 reached. Then, CNF formuladescribing possible initial states, test SAT check whether_llsupport(q(t))test succeed least one leafs support(q(t)) true every possibleinitial state. given relaxations, case if, applying actionsrelaxed planning graph, q always true time t.5process extracting relaxed plan constructed conformant relaxed planninggraph extension FFs respective process machinery selects actions responsiblerelevant paths Imp. overall Conformant-FF heuristic machinery sound completerelaxed tasks, yields heuristic function highly informative across range challengingdomains (Hoffmann & Brafman, 2006).work, adopt Conformant-FFs relaxations, ignoring delete lists action effects, well one propositions effects condition. Accordingly, adoptfollowing notations Conformant-FF. Given set actions A, denote |+1 function+set possible actions, |1 maps action similarempty delete lists one conditioning propositions effect removed;++|+denote action set obtained applying |+1 (a), write a|1 . A|11 actions++denotea|A, is, A|+=a||.actionsequence1 sequence11+actions obtained applying |1 every action along a, is,(hi,= hia|+.1 =++ha|1 |1 , = haiprobabilistic planning task (A, bI , G, ), task (A|+1 , bI , G, ) called relaxation++(A, bI , G, ). Finally, a|1 plan (A|1 , bI , G, ), called relaxed plan(A, bI , G, ).4. Following Conformant-FF terminology, leafs refer nodes zero in-degree.5. Note would possible full SAT check, without 2-projection (without relying Imp), seewhether q becomes known t. However, indicated above, full check every unknown propositionevery level relaxed planning graph every search state would likely expensive, computationally.580fiP ROBABILISTIC -FFnext two sections describe machinery underlying Probabilistic-FF heuristicestimation. Due similarity conceptual relaxations used Probabilistic-FFConformant-FF, Probabilistic-FF inherits almost Conformant-FFs machinery. course,new contributions algorithms dealing probabilistic belief states probabilisticactions.4.2 Probabilistic Relaxed Planning GraphsLike FF Conformant-FF, Probabilistic-FF computes heuristic function two steps, firstone chaining forward build relaxed planning graph, second step chaining backwardextract relaxed plan. section, describe detail Probabilistic-FFs forward chaining step,building probabilistic relaxed planning graph (or PRPG, short). Section 4.4, showone extract (probabilistic) relaxed plan PRPG. provide detailed illustrationPRPG construction process basis running example; since illustrationlengthy, moved separate Section 4.3.algorithms building PRPG quite involved; instructive first consider (someof) key points delving details. main issue is, course, needextend Conformant-FFs machinery ability determine goal set sufficientlylikely, rather known true sure. achieve that, must introducerelaxed planning effective reasoning probabilistic initial state, effectsprobabilistic actions. turns reasoning obtained certain weightedextension implication graph. nutshell, want determine likely factq true time t, propagate certain weights backwards implication graph,starting q(t); weight q(t) set 1, weight p(t ) gives estimateprobability achieving q given p holds . Computing probability exactly would,course, expensive. estimation based assuming independence variousprobabilistic events involved. choice made carefully; experimented widelyvarious options deciding favor technique.simplifying assumption weight propagation constitutes, course, another relaxation,top relaxations already inherited Conformant-FF. particularly problematicaspect assuming independence under-estimating technique. actual weightnode p(t ) probability achieving q given p holds may lowerestimate. effect, PRPG may decide wrongly relaxed plan exists: even executerelaxed actions contained successful PRPG, probability achieving goalexecution may less required threshold. words, lose soundness (relativerelaxed tasks) relaxed planning process.experimented alternative weight propagation method, based opposite assumption, relevant probabilistic events always co-occur, hence weights mustpropagated according simple maximization operations. propagation method yieldeduninformative heuristic values, hence inacceptable empirical behaviour Probabilistic-FF,even simple benchmarks. view, seems unlikely under-estimating yet informative efficient weight computation exists. experimented alternativenon under-estimating propagation schemes, particular one based assuming probabilistic events completely disjoint (and hence weights added); schemes gave better581fiD OMSHLAK & H OFFMANNperformance maximization, lagged far behind independence assumptionchallenging benchmarks.Let us get actual algorithm building PRPG. coarse outline algorithmfollows. PRPG built layer-wise fashion, iteration extending PRPG, reachingtime t, another layer, reaching time + 1. actions new step whosepreconditions known hold t. Effects conditioned unknown facts (note reductioneffect conditions single fact) constitute new edges implication graph. differenceConformant-FF, dont obtain single edge condition add effect; instead, obtain edgescondition chance nodes, chance node represents probabilistic outcomeeffect; chance nodes, turn, linked edges respective add effects. weightschance nodes set probabilities respective outcomes, weightsnodes set 1. weights static weights dynamically modifiedweight propagation; rather, static weights form input propagation.implication graph edges inserted layer, algorithm checks whether newfacts become known. check done much like corresponding check Conformant-FF,testing whether disjunction support leafs proposition p + 1 impliedinitial state formula. two differences Conformant-FF are: (1) leafs relevant whosedynamic weight 1 (otherwise, achieving leaf guaranteed accomplish p + 1). (2)Another reason p become known may outcomes unconditional effect (oreffect known condition) result achievement p time + 1. elegantly formulateoverall test single implication test support leafs whose dynamic weight equalsweight.Like FFs Conformant-FFs algorithms, PRPG process two termination criteria.PRPG terminates positively goal probability high enough time t; PRPG terminatesnegatively if, + 1, nothing changed may result higher goal propabilityfuture . goal probability layer computed based weighted model countingformula derived support leafs goals known true. criteria negativetermination check: whether new facts become known unknown (not negatively known);whether possibly relevant new support leafs appeared; whether goal probabilityincreased. neither case, stop safelyif PRPG terminates unsuccessfullyguarantee relaxed plan, corresponding belief hencedead end.Let us get details. Figure 4 depicts main routine building PRPG beliefstate ba . already specified, sets P (t), (t), A(t) contain propositionsknown hold time (hold probability 1), propositions unknown holdtime (hold probability less 1 greater 0), actions knownapplicable time t, respectively. layers 0 PRPG capture applying relaxed actionsstarting ba . layers 1 PRPG correspond m-step action sequence leadinginitial belief state belief state question ba . inherit latter techniqueConformant-FF; sense, PRPG reasons past. may look confusing firstsight, simple reason. Imagine PRPG starts level 0 instead. Then, check whetherproposition becomes known, SAT tests regarding support leafs beliefstate formula, (ba ), instead initial state formula (similarly weighted model countingtest whether goal likely enough). Testing (ba ) possible, expensive582fiP ROBABILISTIC -FFprocedure build-PRPG(a, A, (NbI ), G, , |+1 ),returns Bool saying relaxed plan belief stategiven = ham , . . . , a1 i,builds data structures relaxed plan extracted:= (NbI ), Imp :=P (m) := {p | p known }, (m) := {p | p unknown }:= 1A(t) := {at |+1 } N OOPbuild-timestep(t, A(t))endfor:= 0get-P(t, G) <A(t) := {a|+1 | A, pre(a) P (t)} N OOPbuild-timestep(t, A(t))P (t + 1) = P (t)(t + 1) = (t)p (t + 1) : (m) support(p(t + 1)) = (m) support(p(t))get-P(t + 1, G) = get-P(t, G)return FALSEendif:= + 1endwhile:= t, return TRUEFigure 4: Main routine building probabilistic relaxed planning graph (PRPG).computationally.6 negative-index layers chain implication graph way backinitial state, hence enable us perform SAT tests typically much smaller initialstate formula.Returning Figure 4, PRPG initialized empty implication set Imp, P (m)(m) assigned propositions known unknown initial belief state,weighted CNF formula initialized (NbI ). formula implication/weighted model checking tests run asking whether proposition becomes known/whethergoal likely enough. PRPG built, incrementally extended clausescapture behavior different effect outcomes.loop builds sets P time steps 1 iterative invocationbuild-timestep procedure time expands PRPG single time level.iteration 1, sets P (t + 1) (t + 1) made contain propositionsknown/unknown applying relaxed version action (remember= ha1 , . . . , i). simplify presentation, action set A(t) contains set dummyactions N OOP simplytransportpropositions time layer time layer t+1.formally, N OOP = noopp | p P , pre(noopp ) = , E(noopp ) = {({p}, {})},= (1.0, {p}, )}).6. Conformant-FF, configuration implemented option; significantly slows searchdomains, brings advantages cases.583fiD OMSHLAK & H OFFMANNsubsequent loop constructs relaxed planning graph layer 0 onwards by,again, iterative invocation build-timestep procedure. actions layer 0relaxations actions whose preconditions known hold time certainty.iterative construction controlled two termination tests. First, goal estimated holdlayer probability higher , know relaxed plan estimate extracted.Otherwise, graph reaches fix point, know relaxed (and thus, real) planbI exists. postpone discussion two termination criteria, focustime layer construction procedure build-timestep.procedure build-timestep(t, A),builds P (t + 1), (t + 1), implication edges + 1,induced action setP (t + 1) := P (t), (t + 1) :=effects e action A, con(e) P (t) (t)(e)(t + 1) := (t + 1) add()introduce new fact (t) ((t)) = P r()Imp := Imp {((t), p(t + 1)) | p add()}endforcon(e) (t)SthenImp := Imp (e) {(con(e)(t), (t))}elseV:= (e) (t) , (e) ((t) (t))endifendforp (t + 1)build-w-impleafs(p(t + 1), Imp)support(p(t + 1)) := {l | l leafs(Impp(t+1) ) p(t+1) (l) = (l)}Wlsupport(p(t+1)) l P (t + 1) := P (t + 1) {p} endifendfor(t + 1) := (t + 1) \ P (t + 1)Figure 5: Building time step PRPG.build-timestep procedure shown Figure 5. first loop build-timestep proceedsoutcomes (relaxed) actions given set may occur time t.probabilistic outcome introduce new chance proposition weighted conditional likelihoodoutcome.7 that, extend Imp binary implications new chanceproposition add list outcome. uncertain condition con(e)corresponding effect time t, is, con(e) (t), also add implicationscon(e) chance propositions created outcomes e. Otherwise, con(e)known time t, uncertainty ability make effect e hold timet. case, ground chance propositions created outcomes eimplication graph, simply extend running formula clauses capturing exactlyone relationship chance propositions corresponding alternative outcomes e7. course, implementation special case treatment deterministic actions, using chance nodes(rather single chance node static weight 1).584fiP ROBABILISTIC -FFtime t. way, probabilistic uncertainty outcome e treatedproperty initial belief state bI ; type knowledge add knowledgebase formula initializing build-PRPG (NbI ).NotationImpvuImpuleafs(Imp )E(Imp )Descriptiongraph containing exactly paths node v node u Imp.subgraph Imp formed node u ancestors u Imp.set zero in-degree nodes subgraph Imp Imp.set time-stamped action effects responsible implication edgessubgraph Imp Imp.Table 2: Overview notations around implication graph.second loop checks whether proposition p, unknown time t, becomes knowntime + 1. part build-timestep procedure somewhat involved; Table 2 providesoverview main notations used follows discussing various usesimplication graph Imp.First thing second loop build-timestep, call build-w-impleafs procedure associates node v(t ) Impp(t+1) estimate p(t+1) (v(t )) probability achievingp time + 1 effects E(Impv(t )p(t+1) ), given v holds time . words,dynamic weight (according p(t + 1)) implication graph nodes computed. Note v(t )either time-stamped proposition q(t ) q P, chance proposition (t )probabilistic outcome .discuss build-w-impleafs procedure detail below. proceeding understandsecond loop build-timestep, main thing need know following lemma:Lemma 4 Given node v(t ) Impp(t+1) , p(t+1) (v(t )) = (v(t )) if,given v time , sequence effects E(Impv(t )p(t+1) ) achieves p + 1 probability 1.words, v(t ) leads p(t + 1) certainty iff dynamic weight v(t ) equals staticweight. simple consequence weight propagation arranged; hold truereasonable weight propagation scheme (do mark node certain not). fullproof lemma appears Appendix pp. 613.Re-consider second loop build-timestep. happens following.finished build-w-impleafs weight propagation p time + 1,1. collect leafs support(p(t + 1)) Impp(t) meet criteria Lemma 4,2. check (by call SAT solver) whether knowledge-base formula implies disjunction leafs.implication holds, examined fact p time added set facts known timet. Finally, procedure removes set facts known possibly hold time + 1facts proven hold time + 1 certainty.understand above, consider following. Lemma 4, support(p(t + 1)) containsexactly set leafs achieving lead p(t + 1) certainty. Hence basically585fiD OMSHLAK & H OFFMANNprocedure build-w-impleafs (p(t), Imp)top-down propagation weights p(t) p(t) nodes Impp(t)p(t) (p(t)) := 1decreasing time steps := (t 1) . . . (m)chance nodes (t ) Impp(t)Q1 p(t) (r(t + 1)):= radd(),r(t +1)Impp(t)p(t) ((t )) := ((t )) (1 )endforfact nodes q(t ) Impp(t):= 1A(tE(a), con(e) = qh ), ePp(t) ((t )):= 1 (e),(t )Impp(t)endforp(t) (q(t )) := 1endforendforFigure 6: build-w-impleafs procedure weight back-propagation implication graph.use implication test Conformant-FF. Note, however, word basicallyprevious sentence hides subtle important detail. difference situation ConformantFF, support(p(t + 1)) may contain two kinds nodes: (1) proposition nodes start layerPRPG, i.e., layer corresponding initial belief; (2) chance nodes later layersPRPG, corresponding outcomes effects unknown conditions. pointdiscussed updates onWthe formula neededthose keep track alternativeeffect outcomes. Hence testing lsupport(p(t+1)) l testing whether either: (1) pknown + 1 always triggered certainty least one proposition trueinitial world; (2) p known + 1 triggered outcomes effectappear certainty. get following result:Lemma 5 Let (A, NbI , G, ) probabilistic planning task, sequence actions applicablebI , |+1 relaxation function A. time step m, proposition pP, P (t) constructed build-PRPG(a, A, (NbI ), G, , |+1 ), p time achieved+relaxed plan starting a|1(1) probability > 0 (that is, p negatively known time t) p (t)P (t),(2) probability 1 (that is, p known time t) p P (t).consequence arguments outlined above. full proof Lemma 5 givenAppendix pp. 614.Let us consider weight-propagating8 procedure build-w-impleafs depicted Figure 6.procedure performs layered, top-down weight propagation given node9 p(t) Imp8. weight propagation scheme build-w-impleafs procedure similar nature used heuristicsmodule recent probabilistic temporal planner Prottle Little, Aberdeen, Thiebaux (2005).9. Note instantiated + 1 called build-timestep.586fiP ROBABILISTIC -FFleafs Impp(t) . order traversal ensures node Impp(t) processed successors Impp(t) . chance nodes (t ), dynamic weightp(t) ((t )) set1. probability outcome takes place time given corresponding actioneffect e() take place , times2. estimate probability achieving p time effects E(Imp(t )p(t) ).first quantity given global, static weight ((t )) assigned (t ) firstloop build-timestep. second quantity derived dynamic weights p(t) (r(t + 1))r add(), computed previous iteration outermost loop build-w-impleafs.Making heuristic assumption effect sets E(Impr(t +1)p(t) ) different r add()pairwise independent, set probability failure achieve p effectsE(Imp(t )p(t) ). computation (t ) decomposed artifacts ,weight propagation starts taking place. fact nodes q(t ), dynamic weightp(t) (q(t )) set probability action effect conditioned q time allows(possibly indirectly) achieving desired fact p time t. Making heuristic assumptionindependence various effects conditioned q , computing p(t) (q(t ))decomposed outcomes effects.procedure get-P (t, G)estimates probability achieving G time p.G 6 P (t) (t) return 0 endifG P (t) return 1 endifg G \ P (t)l leafs(Impg(t) ), introduce chance proposition hlg weight g(t) (l)WVg := ( lleafs(Impg(t) ) l) lleafs(Impg(t) )uP (m) (l hlg i)endforVreturn WMC( gG\P (t) g )Figure 7: Estimating goal likelihood given time step.remains explained build-PRPG procedure two termination criterialoop constructing planning graph layer 0 onwards. first test madecall get-P procedure, checks whether PRPG built time layer containsrelaxed plan (A, NbI , G, ). get-P procedure shown Figure 7. First, onesubgoals negatively known time t, then, Lemma 5, overall probability achievinggoal 0. extreme, subgoals known time t, probabilityachieving goal 1. correctness latter test implied Lemma 5 non-interferencerelaxed actions. leaves us main case uncertainsubgoals. uncertainty either due dependence subgoals actual initial worldstate, due achieving subgoals using probabilistic actions, due both. uncertaintyinitial state fully captured weighted CNF formula (NbI ) . Likewise,outcomes chance propositions (t ) introduced implication graph build-timestepprocedure chained Imp propositions add lists outcomes,587fiD OMSHLAK & H OFFMANNchained Imp unknown (relaxed) conditions outcomes, any. Therefore,action outcome time < relevant achieving subgoal g G time t,corresponding node (t ) must appear Impg(t) , weight back-propagatedbuild-w-impleafs(g(t), Imp) leafs Impg(t) . get-P procedure exploitsback-propagated estimates by, again, taking heuristic assumption independenceachieving different subgoals. Namely, probability achieving unknown sub-goals G \ P (t)estimated weighted model counting formula , conjoined probabilistic theoriesg achieving unknown goal g isolation. understand formulas g , consider that,order make g true t, must achieve least one leafs l Impg(t) ; hence left partconjunction. hand, make l true, achieves g(t) (estimated)probability g(t) (l); hence right part conjunction requires us pay price setl true.10explained start section, positive PRPG termination test may fire evenreal goal probability high enough. is, get-P may return value higher realgoal probability, due approximation (independence assumption) done weight propagation. course, due approximation, may also happen get-P returns value lowerreal goal probability.second PRPPG termination test comes check whether reached pointconstruction PRPG allows us conclude relaxed plan (A, NbI , G, )starts given action sequence a. termination criterion asks whether, time steptime step + 1, potentially relevant changes occurred. potentially relevant changewould goal-satisfaction probability estimate get-P grows, known unknownpropositions grow, support leafs latter propositions Imp correspondinitial belief state grow.11 none occurs, would hold future iterations > t,implying required goal satisfaction probability would never reached. words,PRPG construction complete.Theorem 6 Let (A, NbI , G, ) probabilistic planning task, sequence actions appli+cable bI , |+1 relaxation function A. build-PRPG(a, A, (NbI ), G, , |1 ) returns+FALSE, relaxed plan (A, bI , G, ) starts a|1 .Note Theorem 6 holds despite approximation done weight propagation, makingassumption probabilistic independence. Theorem 6 hold, requirementweight propagation this: real weight still grows, estimated weight still grows.requirement met independence assumption. would met assumptionco-occurence, propagating weights maximization operations, thereby conservatively underestimating weights. propagation, PRPG fails cannot concludeplan respective belief. another good argument (besides bad quality heuristicsobserved empirically) using conservative estimation.10. introduce extra chance propositions hlg i, instead assign weight g(t) (l) l itself,outcome correct: pay also setting l false.11. understand latter, note PRPG always added replicas probabilistic actionsirrelevant achieving goals, effects known conditions. action effects (sinceirrelevant) influence estimate goal-satisfaction probability, chance propositions correspondingoutcomes effects may become support leafs unknown proposition p. latter case,set support leafs support(p(t )) infinitely grow , projection support(p(t ))initial belief state (that is, support(p(t)) (t)) guaranteed reach fix point.588fiP ROBABILISTIC -FFfull proof Theorem 6 given Appendix pp. 615. theorem finalizespresentation analysis process constructing probabilistic relaxed planning graphs.4.3 Example: PRPG Constructionillustrate construction PRPG algorithm Figures 4-7, let us consider simplification running Examples 1-2(i) actions {move-b-right, move-lef t} constitute action set A,(ii) goal G = {r1 , b2 }, required lower bound probability success = 0.9,(iii) initial belief state bI given BN NbI Example 2,(iv) belief state ba evaluated heuristic function corresponds actions sequence= hmove-b-righti.effects/outcomes actions considered construction PRPG describedTable 3, embr re-notation effect e Table 1, effect e Table 1 effectivelyignored due emptiness add effects.E(a)con(e)con(e)|+1(e)P r()add()0.70.20.11.0{r2 , b2 }{r2 }{r1 }1.01.01.01.0{r1 }{r2 }{b1 }{b2 }embr{r1 , b1 }{r1 }aml (move-lef t)eml{r2 }{r2 }mbr1mbr2mbr3mlnoopr1noopr2noopb1noopb2er1{r1 }{r2 }{b1 }{b2 }{r1 }{r2 }{b1 }{b2 }r1r2b1b2ambr(move-b-right)er2eb1eb2Table 3: Actions |+1 relaxation PRPG construction example.initialization phase build-PRPG procedure results = (NbI ), Imp := ,P (1) = , (1) = {r1 , r2 , b1 , b2 }. content (1) depicted first columnnodes Figure 8. first loop build-PRPG (constructing PRPG past layerscorresponding a) makes single iteration, calls build-timestep procedure = 1A(-1) = {ambr } N OOP S. (In follows, using names actions refermbr empty, thus adds|+1 relaxations given Table 3.) add list outcome 3nodes implication graph. that, chance nodes introduced Imp callbuild-timestep appear second column Figure 8. first outer loop build-timestepresults Imp given columns 1-3 Figure 8, (0) = (1), extension .second outer loop build-timestep, weight propagating procedure build-w-impleafscalled unknown fact p(0) (0) = {r1 (0), r2(0) , b1 (0), b2 (0)}, generating p(0)oriented weights Table 4. p(0) (0), set supporting leafs support(p(0)) =589fiD OMSHLAK & H OFFMANNWV00 ml (0)54mbr (-1)mbr1 AA1AA (0)MLML]\]\mbrmbr (0)88 2q88 2 (-1);;;;;qqqrrrr;;;;qq;;rrrr;;qqqr;r01;;;; // r1 (0);; // r1 (1)// 1// 1 (-1)r1 (-1)(0);;;;;;;;;RSHI ;HI ;;// r2 (0)// r2 (-1)// r2 (0)// r2 (1)r2 (-1)b1 (-1)// b1 (-1)b2 (-1)// b2 (-1)!// b1 (0)// b1 (0)// b2 (0)// b2 (0)!mbr1 (1)ML]\mbr2 (1);;;;;;;;;;;;;;HI ;;r// 2// r2 (2)(1)// b1 (1)// b1 (1)// b2 (1)// b2 (1)// b1 (2)!// b2 (2)Figure 8: implication graph Imp. odd columns nodes depict sets unknown propositions (t). even columns nodes depict change propositions introducedprobabilistic outcomes actions A(t).{p(1)}, none implied = NbI , thus set known facts P (0) remains equalP (1) = , (1) equal = (1).r1 (0)r2 (0)b1 (0)b2 (0)= 0= 1mbrmbrrrr1 r2 b1 b2 121 2 b1 b21110.7 0.21111 0.71r1 r2 b1 b210.9 110.71Table 4: columns table correspond nodes implication graph Imp,row provides weights p(0) p(0) (0). entry row p(0)empty node associated corresponding column belongimplication subgraph Impp(0) .finished loop, build-PRPG procedure proceeds loopbuilds future layers PRPG. test goal (un)satisficing get-P(0, G) < evaluatesTRUE get get-P(0, G) = 0.63 < 0.9, thus loop proceeds first iteration.see former, consider implication graph Imp constructed far (columns 1-3 Fig590fiP ROBABILISTIC -FFure 8). goal G = {r1 , b2 } leafs(Impr1 (0) ) = {r1 (1)}, leafs(Impb2 (0) ) ={r1 (1), b2 (1)}. {r1 (0), b2 (0)} (0) = (NbI ),get-P(0, G) = WMC ((NbI ) r1 b2 ) ,r1 = (hr1,r1 i) (r1 hr1,r1 i) ,b2 = (hr1,b2 hb2,b2 i) (r1 (1) hr1,b2 i) (b2 (1) hb2,b2 i) ,(20)(hr1,r1 i) = r1 (0) (r1 (1)) = 1(hb2,b2 i) = b2 (0) (b2 (1)) = 1.(21)(hr1,b2 i) = b2 (0) (r1 (1)) = 0.7Observe two models (NbI ) consistent r2 immediately falsify sub-formula(NbI ) r1 . Hence,get-P(0, G) = WMC (NbI ) r1 b2 |r1 (1)=1,b1 (1)=1 +WMC (NbI ) r1 b2 |r1 (1)=1,b2 (1)=1= bI (r1 , b1 ) (hr1,r1 i) (hr1,b2 i) + bI (r1 , b2 ) (hr1,r1 i) (hr1,b2 i) (hb2,b2 i)= 0.63 1 0.7 + 0.27 1 0.7 1= 0.63first iteration loop, build-PRPG calls build-timestep procedure= 0 A(0) = {ambr , aml } N OOP S. chance nodes introduced Imp callbuild-timestep appear forth column Figure 8. first outer loop build-timestepresults Imp given columns 1-5 Figure 8, (1) = (0), extension .before, second loop build-timestep, build-w-impleafs procedure calledunknown fact p(1) (1) = {r1 (1), r2(1) , b1 (1), b2 (1)}, generating p(1)-oriented weights.interesting case case weight propagation build-w-impleafs(r1 (1), Imp), resultingweightsr1 (1) (r1 (1)) = 1r1 (1) (r1 (-1)) = 1mlr1 (1) ( (0)) = 1r1r1 (1) ( (0)) = 1r1 (1) (r1 (0)) = 1r1 (1) (r2 (0)) = 1r1 (1) (r2 (-1)) = 1r1 (1) (mbr1 (-1))mbrr1 (1) (2 (-1))= 0.7r1 (1) (r1 (-1)) = 1r1 (1) (r2 (-1)) = 1= 0.2nodes Impr1 (1) . that, set supporting leafs r1 (1) assigned support(r1 (1)) ={r1 (1), r2 (1)}, since = (NbI ) implies r1 (1) r2 (1), fact r1 concludedknown time 1, added P (1). nodes p(1) (1) stillsupport(p(1)) = {p(1)}, thus remain unknown time = 1 well. Puttingthings together, call build-w-impleafs procedure results P (1) = {r1 (1)},591fiD OMSHLAK & H OFFMANN(1) = {r2(1) , b1 (1), b2 (1)}. loop build-PRPG procedure proceeds checking fixpoint termination test, immediately fails due P (1) 6= P (0). Hence,loop proceeds next iteration corresponding = 1.test goal (un)satisficing get-P(1, G) < still evaluates TRUEget-P(1, G) = 0.899 < 0.9. Let us follow evaluation get-P(1, G) detail well. Considering implication graph Imp constructed far time = 1 (columns 1-5 Figure 8),G (1) = {b2 (1)}, leafs(Impb2 (1) ) = {r1 (1), b2 (1)}, (still) = (NbI ),obtainget-P(1, G) = WMC ((NbI ) b2 ) ,b2 = (hr1,b2 hb2,b2 i) (r1 (1) hr1,b2 i) (b2 (1) hb2,b2 i) ,(22)structure b2 Equation 22 identical Equation 20, weights associatedauxiliary chance propositions different, notably(hb2,b2 i) = b2 (1) (b2 (1)) = 1.(hr1,b2 i) = b2 (1) (r1 (1)) = 0.91(23)difference (hr1,b2 i) Equation 21 Equation 23 stems fact r1 (1)supports b2 (1) via effect embr time 1 also via different instanceeffect time 0. Now, model (NbI ) falsify b2 one sets r1b2 false. Hence,get-P(1, G) = bI (r1 , b1 ) (hr1,b2 i) +bI (r1 , b2 ) (hr1,b2 i) (hb2,b2 i) +bI (r2 , b2 ) (hb2,b2 i)= 0.63 0.91 + 0.27 0.91 1 + 0.08 1= 0.899verified get-P(1, G) < , loop proceeds construction time = 2,calls build-timestep procedure = 1 A(1) = {ambr , aml } N OOP S. chancenodes introduced Imp call build-timestep appear sixth column Figure 8.first outer loop build-timestep results Imp given columns 1-7 Figure 8,mbrmbr= (NbI ) mbr(1)(1)(1)123mbrmbrmbrmbrmbrmbr(1)(1)(1)(1)(0)(0)121323(24)Next, build-w-impleafs procedure called usual unknown fact p(2) (2) ={r2(2) , b1 (2), b2 (2)}. information worth detailing leafs(Impb2 (2) ) =mbr{b2 (1), r1 (1), mbr1 (1)}, support(b2 (2)) = {b2 (1), 1 (1)}. However, stillWlsupport(p(2)) l p(2) (2), thus set known facts P (2) remains equalP (1) = {r1 }.592fiP ROBABILISTIC -FFReturning call build-w-impleafs procedure, build-PRPG proceeds checkingfixpoint termination condition. time, first three equalities condition hold, yetcondition satisfied due get-P(2, G) > get-P(t, G). see latter, noticeget-P(2, G) = WMC ( b2 ) ,given Equation 24,b2 = hr1,b2 hb2,b2 mbr1 (1) (r1 (1) hr1,b2 i) (b2 (1) hb2,b2 i) ,(25)(hb2,b2 i) = b2 (1) (b2 (1)) = 1.(hr1,b2 i) = b2 (1) (r1 (1)) = 0.91(mbr1 (1))=b2 (1) (mbr1 (1))(26)= 0.7hard verifyget-P(2, G) = get-P(1, G) + bI (r2 , b1 ) (mbr1 (1))= 0.899 + 0.02 0.7= 0.913Note get-P(2, G) , therefore build-PRPG aborts looppassing goal satisficing test, sets = 2. finalizes construction PRPG, thus,example.4.4 Extracting Probabilistic Relaxed Planconstruction PRPG succeeds reaching goals estimated probability success get-P(T, G) exceeding , extract relaxed plan consisting A(0), . . . , A(T1), use size heuristic value evaluated belief state ba .get technical details, consider key differencesrelaxed (no delete lists) probabilistic planning one hand, relaxed classical relaxed qualitative conformant planning hand. relaxed probabilistic planning, mightmake sense execute action numerous times consecutive time steps. fact,might essential think throwing dice game 6 appears. contrast,relaxed classical qualitatively uncertain settings needed effectexecuted, remains true forever. Another complication probabilistic planning requiredgoal-achievement probability specified conjunction (or, possibly, complicatedlogical combination) different facts. increasing probability achieving individual sub-goal g G relaxed planning always increase overall probability achieving G,choosing right distribution effort among sub-goals pass required thresholdwhole goal G non-trivial problem.fundamental problem aforementioned lack guarantees weight propagation.one hand, construction PRPG Lemma 5 imply a|+1 concatenatedRarbitrary linearization A(0), . . . , A(T 1) executable bI . hand, dueindependence assumption made build-w-impleafs procedure, get-P(T, G)593fiD OMSHLAK & H OFFMANNRimply probability achieving G a|+1 concatenated exceeds . real relaxedplan, sense, might even exist constructed PRPG.answer difficulties extract relaxed plans correct relativeweight propagation. Namely, use implication graph reduction algorithm computesminimal subset graph still according weight propagation sufficientlysupports goal. relaxed plan corresponds subset. Obviously, solvesdifficulty lack real relaxed plans; relaxed plan extraction accordingindependence assumption (besides ignoring deletes removing one conditioneffect). mechanism also naturally takes care need apply action several times:corresponds several implication graph edges needed order obtain sufficientweight. choice effort distributed among sub-goals circumvented sensesub-goals considered conjunction, is, reduction performed all.course, remains choice parts implication graph removed.found useful heuristic make choice based actions alreadyapplied path belief. detail below.Making another assumption top previous relaxations course bad heuristicquality. relaxed plans extract guaranteed actually achieve desired goal probability. Since relaxed plans used search guidance, per se theoretical weaknessmarginal importance. However, over-estimation goal probability might result badheuristic relaxed plan include right actions, apply oftenenough. Section 5, discuss example domain Probabilistic-FF fails scaleprecisely reason.Figure 9 shows main routine extract-PRPlan extracting relaxed plan givenPRPG (note index highest PRPG layer, c.f. Figure 4). sub-routinesextract-PRPlan shown Figures 10-11. high level, extract-PRPlan procedure consiststwo parts:1. Reduction implication graph, aiming identifying set time-stamped action effectsignored without decreasing estimate goal-achievement probability get-P(T, G)desired threshold ,2. Extraction valid relaxed plan ar (schematically) constructing PRPG ar insteadfull set A(0), . . . , A(T ) would still result get-P(T, G) .first part accomplished reduce-implication-graph procedure, depicted Figure 10.first step algorithm, procedure considers parts implication graphrelevant achieving unknown sub-goals. Next, reduce-implication-graph performsgreedy iterative elimination actions future layers 0, . . . , 1 PRPG probability estimate get-P(T, G) reduced set actions goes . While, principle, action A(0), . . . , A(T 1) considered elimination, reduce-implication-graph examine repetitions actions already appear a. Specifically, reduce-implication-graphiterates actions a|+1 , repeats somewhere future layers PRPG,one repetition a(t ) considered removal. removing repetition found saferespect achieving ,12 effectively removed eliminating edges Impinduced a(t ). procedure considers next repetition a. removing another12. Note formula WMC constructed exactly get-P function, c.f. Figure 7.594fiP ROBABILISTIC -FFprocedure extract-PRPlan(P RP G(a, A, (NbI ), G, , |+1 )),selects actions A(0), . . . , A(T 1)Imp := reduce-implication-graph()extract-subplan(Imp )sub-goal(G P (T ))decreasing time steps := T, . . . , 1g G(t)A(t 1), e E(a), con(e) P (t 1), (e) : g add()add-to-relaxed-plan one timesub-goal(pre(a) con(e))elseImp g(t) := construct-support-graph(support(g(t)))extract-subplan(Imp g(t) )endifendforendforFigure 9: Extracting probabilistic relaxed plan.copy safe anymore, procedure breaks inner loop considers nextaction.procedure reduce-implication-graph()operates PRPG;returns sub-graph Imp.Imp := gG\P (T ) Impg(T )actions a|+1edges ((t ), p(t + 1)) Imp , induced a(t ) A(t ), 0Imp := Impremove Imp edges induced A(t )g G \ P (t)l leafs(Imp g(T ) ), introduce chance proposition hlg weight g(T ) (l)VWg := ( lleafs(Imp) l) lleafs(Imp)uP (m) (l hlg i)g(T )g(T )endforVWMC( gG\P (T ) g ) Imp := Imp else break endifendforendforreturn ImpFigure 10: procedure reducing implication graph.illustrate intuition behind focus repetitions actions a, let us consider following example simple logistics-style planning problem probabilistic actions.Suppose two locations B, truck known initially A, heavyuneasy grab package known initially truck. goal packageunloaded B reasonably high probability, two actions use movingtruck B (am ), unloading package (au ). Moving truck necessarily595fiD OMSHLAK & H OFFMANNmove truck B, extremely high probability. hand, unloading bothersome package succeeds extremely low probability, leaving packagetruck otherwise. Given data, consider belief state ba corresponding trying movetruck once, is, action sequence ham i. achieve desired probability success,PRPG expanded large time horizon , allowing action auapplied sufficiently many times. However, fact truck B known belief state ba ,thus implication graph also contain amount applications . Trimmingaway applications still keep probability sufficiently high.reader might ask point hope achieve trimming awayapplications . point is, intuitively, implication graph reduction mechanismmeans understand accomplished already, path ba . Withoutunderstanding, relaxed planning quite indiscriminative search states. Considerexample, assume one two troubled packages, P 1 P 2,truck, unload actions au1 au2 . PRPG ba contains copies au1 au2 layerslarge horizon . Now, say search starts unload P 1. resulting belief, PRPGstill steps situation changed P 2. step PRPG still containscopies au1 au2 hence heuristic value remains before!words, without implication graph reduction technique, relevant things accomplishedmay remain hidden behind things yet accomplished. example,really critical because, soon tried unload P 1 P 2,time horizon decreases one step, heuristic value reduced. is, however, oftencase sub-task must accomplished sub-task attacked.situations, without implication graph reduction, search staggers across huge plateaufirst task completed. observed variety benchmarks, hence designedimplication graph reduction make relaxed planning aware already done.course, since weight propagation may over-estimate true probabilities, hence overestimate achieved past, implication graph reduction may conclude prematurelysub-task completed. leads us main open question research;get back end Section 5, discuss context exampleProbabilistic-FFs performance bad.Let us get back explaining extract-PRPlan procedure. implication graph reduction, procedure proceeds relaxed plan extraction. process makes use propositionsets G(1), . . . , G(T ), used store time-stamped sub-goals arising layers 1relaxed plan extraction. sub-routine extract-subplan (Figure 11)1. adds constructed relaxed plan time-stamped actions responsible edgesreduced implication graph Imp ,2. subgoals everything outside implication graph condition applicability effectsresponsible edges Imp .later phases process, sub-goals added sets G(1), . . . , G(T )sub-goal procedure simply inserts given proposition sub-goal first layerappearance PRPG. accomplished extract-and-subgoal pass extract-subplanImp , also subgoal goal conjuncts known time .next phase process, sub-goals considered layer layer decreasing ordertime steps 1. sub-goal g time t, certain supporting actions selected596fiP ROBABILISTIC -FFprocedure extract-subplan(Imp )actions helpful achieving uncertain goals G (T )subgoals essential conditions actionsedge ((t), p(t + 1)) Imp 0action effect e E(a) responsible time timeadd-to-relaxed-plan timesub-goal((pre(a) con(e)) P (t))endif endforprocedure sub-goal(P )inserts propositions P sub-goalslayers first appearance PRPGp Pt0 := argmint {p P (t)}t0 1 G(t0 ) := G(t0 ) {p} endifendforprocedure construct-support-graph(support(g(t)))takes subset support(g(t)) leafs(Impg(t) ) weighted according g(t);returns sub-graph Imp Imp.Imp :=open := support(g(t))open 6=open := open \ {p(t )}choose A(t ), e E(a), con(e) = {p}(e) : (p(t ), (t )) Impg(t) g(t) ((t )) = ((t ))(e)choose q add() g(t) (q(t + 1)) = 1Imp := Imp {(p(t ), (t )), ((t ), q(t + 1))}open := open {q(t + 1)}endfor endwhilereturn ImpFigure 11: Sub-routines extract-PRPlan.relaxed plan. action effect e E(a) known applicabletime 1, guarantee achieve g certainty, added constructed relaxedplan 1. Otherwise,1. use construct-support-graph procedure extract sub-graph Imp g(t) consisting setimplications together ensure achieving g time t,2. use already discussed procedure extract-subplan(a) add constructed relaxed plan time-stamped actions responsible edgesImp g(t) ,(b) subgoal everything outside implication graph Imp g(t) condition applicabilityeffects responsible edges Imp g(t) .597fiD OMSHLAK & H OFFMANNProcessing way sub-goals G(1) finalizes extraction relaxed planestimate. Section 4.5 provides detailed illustration process PRPG constructedSection 4.3. event, easy verify relaxed plan extract sound relativeweight propagation, following sense.Proposition 7 Let (A, NbI , G, ) probabilistic planning task, sequence actions ap+plicable bI , |+1 relaxation function build-PRPG(a, A, (NbI ), G, , |1 )returns TRUE. Let A(0)s , . . . , A(T 1)s actions selected A(0), . . . , A(T 1)extract-PRPlan. constructing relaxed planning graph using A(0)s , . . . , A(T 1)s ,get-P(T, G) .Proof: construction: reduce-implication-graph leaves enough edges graphweight propagation underlying get-P still concludes goal probability high enough.4.5 Example: Extracting Relaxed Plan PRPGillustrate process relaxed plan extraction PRPG Figure 8, constructedbelief state problem specification example Section 4.3. example= 2, G (2) = {b2 }, thus implication graph Imp gets immediately reducedsub-graph Imp depicted Figure 12a. plan belief state question consistssingle action ambr , action instances considered elimination outer loopreduce-implication-graph ambr (0) ambr (1). ambr (0) chosen examined,implication sub-graph Imp = Imp reduced removing edges due ambr (0),resulting Imp appears13 Figure 12b. b2 components evaluated formulab2 given Equation 24 Equation 25, respectively, weights associatedchance propositions Equation 25 reduced implication graph Imp(hb2,b2 i) = b2 (1) (b2 (1)) = 1(hr1,b2 i) = b2 (1) (r1 (1)) = 0.7.(27)mbr(mbr1 (1)) = b2 (1) (1 (1)) = 0.7weight model counting b2 evaluates 0.724 < , thus Imp replace Imp .alternative action removal ambr (1), seen example Section 4.3 attempt action elimination also result probability estimate lower .Hence, effect reduce-implication-graph PRPG processed extract-PRPlanprocedure reduction implication graph edges relevant achieving {b2 }time = 2. reduced implication sub-graph Imp returned reduce-implication-graphprocedure depicted Figure 12a.Next, extract-subplan procedure iterates edges Imp adds initiallyempty relaxed plan applications ambr times 0 1. action ambr preconditions,E(ambr ) known time 1. Hence, extract-subplancondition r1 effect mbr1invokes sub-goal procedure {r(1)}, latter added proposition set G(1).subsequent call sub-goal(G P (T )) = sub-goal({r1 }) leads extensions G(2), G(1)13. dashed edges Figure 12b removed Imp either latter stage Imp chosen replaceImp .598fiP ROBABILISTIC -FFmbr88 1 (-1)qq]\qqqqqqq// r1 (-1)r1 (-1)b2 (-1)// b2 (-1)// r1 (0)mbr88 1 (0)rrr]\rrrrr! //b2 (0)// b2 (0)mbr1 (1)! //b2 (1)]\// b2 (1)! //b2 (2)(a)mbr88 1 (-1)qq]\qqqqqqqrr1 (-1) _ _ _ _// 1 (-1)_ _ _ _// r1 (0)b2 (-1)// b2 (-1)!// b2 (0)mbr1 (1)// b2 (0)// b2 (1)// b2 (1)]\!// b2 (2)(b)00 ml(0)54r1 (-1)// r1 (-1)r2 (-1)// r2 (-1)WVr01// r1 (0)// 1 (0)RS// r1 (1)// r2 (0)(c)Figure 12: Illustrations various steps relaxed plan extraction PRPG constructedSection 4.3, and, particular, implication graph latter, depictedFigure 8.already r1 G(1). Hence, outer loop extract-PRPlan starts G(2) = ,G(1) = {r1 }.Since G(2) empty, first sub-goal considered extract-PRPlanis r1 G(1). r1time 1, action effect time 0 passes test statementthe condition r2 mlknown time 0, true14 r1 . Hence, subgoal r1 (1) processedextracting sub-plan support achieving certainty. First, construct-support-graphprocedure called support(r1 (1)) = {r1 (1), r2 (1)} (see Section 4.3). extracted sub14. fact, easy see construction sub-goal procedure p belongs G(t), conditionnoops effect p cannot known time 1.599fiD OMSHLAK & H OFFMANNgraph Imp r1 (1) original implication graph Imp depicted Figure 12c, invokingprocedure extract-subplan Imp r1 (1) results adding (i) application aml time 0, (ii)new subgoals. Hence, proposition sets G(1), G(2) get emptied, thus endextracting relaxed plan hambr (0), aml (0), ambr (1)i.5. Empirical Evaluationimplemented Probabilistic-FF C, starting Conformant-FF code. = 1.0,Probabilistic-FF behaves exactly like Conformant-FF (except Conformant-FF cannot handlenon-deterministic effects). Otherwise, Probabilistic-FF behaves described previous sections, uses Cachet (Sang et al., 2005) weighted model counting. better homestrengths weaknesses approach, empirical evaluation Probabilistic-FFdone two steps. Section 5.1 evaluate Probabilistic-FF problems non-trivial uncertain initial states, deterministic actions. Section 5.2 examine Probabilistic-FFproblems probabilistic action effects, sources uncertainty. compareProbabilistic-FFs performance probabilistic planner POND (Bryce et al., 2006).reasons choosing POND reference point twofold. First, similarly Probabilistic-FF,POND constitutes forward-search planner guided non-admissible heuristic function based(relaxed) planning graph computations. Second, knowledge, POND clearlyefficient probabilistic planner reported literature.15experiments run PC running 3GHz 2GB main memory 2MB cacherunning Linux. Unless stated otherwise, domain/problem pair tried four levels desired probability success {0.25, 0.5, 0.75, 1.0}. run planner time-limited1800 seconds user time. Probabilistic-FF run default configuration inherited FF,performing one trial enforced hill-climbing switching best-first search case failure.domains without probabilistic effects, found Probabilistic-FFs simpler relaxed plan extraction developed case (Domshlak & Hoffmann, 2006), performs better one describedhere. hence switch simpler version domains.16Unlike Probabilistic-FF, heuristic computation POND element randomization;namely, probability goal achievement estimated via sending set random particlesrelaxed planning graph (the number particles input parameter). problem instance, averaged runtime performance POND 10 independent runs. specialcases POND timed runs certain problem instance, yet10 runs, average report POND uses lower-bounding time threshold 1800s replace missing time points. cases, PONDs best-case performance differs lotaverage performance; cases, best-case performance also reported. note that,following suggestion Dan Bryce, POND run default parameter setting, and, par15. experiments used recent version 2.1 POND significantly enhances POND2.0 (Bryce et al.,2006). authors would like thank Dan Bryce Rao Kambhampati providing us binary distributionPOND2.1.16. Without probabilistic effects, relaxed plan extraction proceeds much like Conformant-FF, additionalstraightforward backchaining selecting support unknown goals. complicated techniques developeddeal relaxed plan extraction probabilistic effects appear unstable behaviorsimpler techniques. probabilistic effects, simple backchaining meaningfulinformation many times action must applied order sufficiently support goal.600fiP ROBABILISTIC -FF= 0.25t/|S|/l= 0.5t/|S|/l= 0.75t/|S|/l= 1.0t/|S|/l70/71/14070/70/1381.39/19 /180.28/6/54.02/36/350.76/13/128.06/54/531.54/22/214.62/71 /704.32/70/69Cube-uni-15Cube-cub-156/90/33756/90/33753.25/145/260.56/41/83.94/150/341.16/70/135.00/169/381.95/109/1825.71/296/4226.35/365/42Bomb-50-50Bomb-50-10Bomb-50-5Bomb-50-12550/200/> 2100510/120/> 260255/110/> 25551/102/> 2510.01/1/00.00/1/00.00/1/00.00/1/00.10/17/160.89/248/221.70/468/272.12/662/310.25/37/364.04/778/624.80/998/676.19/1192/710.14/51/501.74/911/902.17/1131/952.58/1325/99Log-2Log-3Log-43440/1040/> 20103690/1260 /> 30103960/1480/> 40100.90/117/542.85/159/642.46/138/751.07/152/628.80/328/988.77/391/811.69/205/694.60/336/996.20/377/951.84/295/784.14/364/1058.26/554/107Grid-2Grid-3Grid-42040/825 /> 36102040/841 /> 36102040/857 /> 36100.07/39/2116.01/1629/7628.15/2167/961.35/221/4815.8/1119/8951.58/2541/1116.11/1207/6982.24/3974/12350.80/2541/1156.14/1207/6966.26/3974/123193.47/6341/155Rovers-7RoversP-7RoversPP-7RoversPPP-7393/97 /> 63 38393/133 /> 63 38393/133 /> 63 38395/140 /> 63 380.01/ 37/182.15/942/658.21/948/6525.77/950/670.01/ 37/182.23/983/7512.48/989/7541.18/996/790.01/ 37/182.37/1008/8312.53/994/770.01/UNSAT0.01/ 37/182.29/1008/8316.20/1014/830.01/UNSATInstance#actions/#facts/#statesSafe-uni-70Safe-cub-70Table 5: Empirical results problems probabilistic initial states. Times seconds, searchspace size |S| (number calls heuristic function), plan length l.ticular, includes number random particles (64) selected computing PONDs heuristicestimate (Bryce et al., 2006).5.1 Initial State Uncertainty Deterministic Actionsexamine performance Probabilistic-FF POND collection domainsprobabilistic initial states, deterministic action effects. consider domains oneone, discussing set runtime plots. problem instances, Table 5 showsdetails, providing features instance size well detailed results Probabilistic-FF,including number explored search states plan length.first three domains probabilistic versions traditional conformant benchmarks: Safe,Cube, Bomb. Safe, n combinations one opens safe. given probabilitydistribution combination right one. type action Safe tryingcombination, objective open safe probability . experimentedtwo probability distributions n combinations, uniform one (Safe-uni) distributiondeclines according cubic function (Safe-cub). Table 5 shows Probabilistic-FFsolve efficiently even n = 70. Figure 13 compares Probabilistic-FFPOND, plotting time performance identical linear scale, x-axes show numbercombinations.graphs easy see Probabilistic-FF outperforms POND least ordermagnitude Safe-uni Safe-cub. interesting observation necessarilydifference time performance, relative performance planner Safe-uniSafe-cub. Note Safe-cub somewhat easier Safe-uni sense that, Safe-cub, fewercombinations must tried guarantee given probability opening safe.601fiD OMSHLAK & H OFFMANNPFFPOND2.17070p=0.25p=0.50p=0.75p=1.006050504040Time (sec)Time (sec)60p=0.25p=0.50p=0.75p=1.0030302020101000103050701030#combinations5070#combinations(a) Uniform prior distribution combinations.PFFPOND2.17070p=0.25p=0.50p=0.75p=1.006050504040Time (sec)Time (sec)60p=0.25p=0.50p=0.75p=1.00303020201010001030507010#combinations305070#combinations(b) Cubic decay prior distribution combinations.Figure 13: Safe domain, Probabilistic-FF (left) vs. POND (right).dominant part probability mass lies combinations head cubic distribution(the last combination probability 0 right combination, thus needs triedeven = 1.0). question whether heuristic functions Probabilistic-FFPOND exploit difference Safe-uni Safe-cub. Table 5 Figure 13 provideaffirmative answer question heuristic function Probabilistic-FF. picturePOND less clear times spent POND (otherwise identical) instances Safe-uniSafe-cub roughly same.17Another interesting observation that, Probabilistic-FF POND, moving =1.0 < 1.0, is, planning qualitative uncertainty truly probabilistic planning,17. Safe-cub n = 70 {0.75, 1.0}, POND undergoes exponential blow-up showngraphs since data points would obscure data points; anyway, believe blow-up dueunfortunate troubles numerics.602fiP ROBABILISTIC -FFPFFPOND2.1301800p=0.25p=0.50p=0.75p=1.0025p=0.25p=0.50p=0.75p=1.00160014001200Time (sec)Time (sec)201510100080060040052000057911N Grid NxNxN131557911N Grid NxNxN13151315(a) Uniform prior distribution initial position.PFFPOND2.1301800p=0.25p=0.50p=0.75p=1.0025p=0.25p=0.50p=0.75p=1.00160014001200Time (sec)Time (sec)201510100080060040052000057911N Grid NxNxN131557911N Grid NxNxN(b) Cubic decay prior distribution initial position.Figure 14: Cube domain, Probabilistic-FF (left) vs. POND (right).typically result performance decline. even get improved performance (except= 0.75 Safe-uni). reason seems plans become shorter. trendobserved also domains. trend particularly remarkable Probabilistic-FF, sincemoving = 1.0 < 1.0 means move case model counting neededcase needed. (In words, Probabilistic-FF automatically specializesqualitative uncertainty, using model counting. knowledge, truePOND, uses techniques cases.)Cube, task move corner 3-dimensional grid, actions correspondmoving current cube cell one (up 6) adjacent cube cells. Again, createdproblem instances uniform cubic distributions (over initial position dimension),again, Probabilistic-FF scales well, easily solving instances 15 15 15 cube. Withintime limit, POND capable solving Cube problems cube width 13. Figure 14603fiD OMSHLAK & H OFFMANNcompares Probabilistic-FF POND detail, plotting time performancedifferent linear scales (with x-axes capturing width grid dimension), showingleast order magnitude advantage Probabilistic-FF. Note that,Probabilistic-FF generally becomes faster decreasing (with decreasing hardnessachieving objective), seem substantial effect performancePOND,Probabilistic-FF exploits relative easiness Cube-cub (e.g., see Table 5), timeperformance POND Cube-cub Cube-uni qualitatively identical.also tried version Cube task move grid center. Probabilistic-FFbad so, reaching performance limit n = 7. weakness Cube-center domaininherited Conformant-FF. detailed Hoffmann Brafman (2006), reasonweakness lies inaccuracy heuristic function domain. two sourcesinaccuracy. First, solve Cube-center reality, one must start moving cornerorder establish position; relaxation, without delete lists, necessary. Second,relaxed planning graph computation over-approximates achieved futuresteps, also already achieved path considered belief state. evenmoderately long paths actions, relaxed planning graph comes (wrong) conclusiongoal already achieved, relaxed plan becomes empty heuristicinformation.Next consider famous Bomb-in-the-Toilet domain (or Bomb, short). versionBomb contains n bombs toilets, bomb may armed armed independently probability 1/n, resulting huge numbers initially possible world states. Dunkingbomb unclogged toilet disarms bomb, clogs toilet. toilet uncloggedflushing it. Table 5 shows Probabilistic-FF scales nicely n = 50, becomes fasterincreases. latter logical desirable toilets means disarmingdevices, resulting shorter plans needed. Figures 15 16 compare Probabilistic-FFPOND, plotting time performance Probabilistic-FF linear scale, PONDlogarithmic scale. four pairs graphs correspond four choices number toilets{50, 10, 5, 1}. x-axes graphs correspond number potentially armedbombs, checked problems n {5, 10, 25, 50}. Figure 15 shows timeProbabilistic-FF least four orders magnitude faster POND; extremes,hardest combination n = 50, = 1, = 0.75 took Probabilistic-FF less 7 seconds,POND timed-out problem instances. addition,Bomb well, Probabilistic-FF exhibit nice pattern improved performancemove non-probabilistic ( = 1.0) probabilistic planning (specifically, 0.5;0.25, initial state good enough already).performance Probabilistic-FF improves number toilets, POND seemsexhibit inverse dependence, is, sensitive number statesproblem (see Table 5) rather optimal solution depth.Finally, remark that, though length-optimality explicitly required probabilistic conformant planning, Safe, Cube, Bomb, Probabilistic-FFs plans optimal (the shortestpossible).604fiP ROBABILISTIC -FFPFFPOND2.110p=0.25p=0.50p=0.75p=1.0010008100Time (sec)Time (sec)6410120.1p=0.25p=0.50p=0.75p=1.0000.0151025# bombs5051025# bombs50(a) 50 toiletsPFFPOND2.110p=0.25p=0.50p=0.75p=1.0010008100Time (sec)Time (sec)6410120.1p=0.25p=0.50p=0.75p=1.0000.0151025# bombs5051025# bombs50(b) 10 toiletsFigure 15: Bomb domain, Probabilistic-FF (left) vs. POND (right).next three domains adaptations benchmarks deterministic planning: Logistics,Grid, Rovers. assume reader familiar domains. Logistics-xinstance contains 10 cities, 10 airplanes, 10 packages, city x locations.packages chance 0.88 airport origin city, uniformlylocations city. effects loading unloading actions conditional (right)position package. Note higher values x increase space world states,also initial uncertainty. Grid complex grid world run AIPS98 planning competition (McDermott, 1998), featuring locked positions must opened matching keys.Grid-x modification instance nr. 2 (of 5) run AIPS98, 6 6 grid, 8 lockedpositions, 10 keys 3 must transported goal position. lock x possible, uniformly distributed shapes, 3 goal keys x possible, uniformly distributedinitial positions. effects pickup-key, putdown-key, open-lock actions conditional.605fiD OMSHLAK & H OFFMANNPFFPOND2.110p=0.25p=0.50p=0.75p=1.0010008100Time (sec)Time (sec)6410120.1p=0.25p=0.50p=0.75p=1.0000.0151025# bombs5051025# bombs50(c) 5 toiletsPFFPOND2.110p=0.25p=0.50p=0.75p=1.0010008100Time (sec)Time (sec)6410120.1p=0.25p=0.50p=0.75p=1.0000.0151025# bombs5051025# bombs50(d) 1 toiletFigure 16: Bomb domain, Probabilistic-FF (left) vs. POND (right).Finally, last set problems comes three cascading modifications instance nr. 7 (of20) Rovers domain used AIPS02 planning competition. problem instance 6waypoints, 3 rovers, 2 objectives, 6 rock/soil samples. Rovers RoversPPP modifyinstance/domain follows.Rovers original AIPS02 problem instance nr. 7, use hear mainly comparison.RoversP, sample chance 0.8 original waypoint, chance 0.1others two waypoints. objective may visible 3 waypointsuniform distribution (this probabilistic adaptation domain suggested Bryce &Kambhampati, 2004).606fiP ROBABILISTIC -FFSandcastleSandcastle0.5PFFPONDPFFPOND (min)POND (avg)1000.410Time (sec)Time (sec)0.30.210.10.100.010.20.30.40.50.60.70.80.90.2(a)0.30.40.50.60.70.80.9(b)Figure 17: Probabilistic-FF POND problems (a) Sand-Castle, (b) SlipperyGripper.RoversPP enhances RoversP conditional probabilities initial state, stating whetherobjective visible waypoint depends whether rock sample (intuition: large piece rock) located waypoint. probability visibility muchhigher latter case. Specifically, visibility objective dependslocations two rock samples, rock sample present, visibility probabilitydrops 0.1.RoversPPP extends RoversPP introducing need collect data water existence.soil samples certain probability (< 1) wet. communicatedsample data, additional operator tests whether sample wet. so, fact knowthat-water contained goal set true. probability wet dependslocation sample.show runtime plots Logistics, Grid, Rovers, since POND runs either timememory considered instances domains. Table 5 shows scaling behaviorProbabilistic-FF three domains similar observed previous domains.goals RoversPPP problem cannot achieved probabilities {0.75, 1.0}.proved Probabilistic-FFs heuristic function, providing correct answer split seconds.5.2 Probabilistic Actionsfirst two domains probabilistic actions famous Sand-Castle (Majercik & Littman,1998) Slippery-Gripper (Kushmerick et al., 1995) domains. domains simple,posed first challenges probabilistic planners; performance domains servesindicator progress relative previous ideas probabilistic planning.Sand-Castle, states specified two boolean variables moat castle, statetransitions given two actions dig-moat erect-castle. goal erect castle.607fiD OMSHLAK & H OFFMANN1D-walkgrid2D-walkgridPFFPOND10001001001010Time (sec)Time (sec)1000110.10.10.010.01PFFPOND56789103Grid width(a)4567Grid width8910(b)Figure 18: Probabilistic-FF POND problems (a) 1D-WalkGrid = 0.9, (b)2D-WalkGrid = 0.01.Building moat dig-moat might fail probability 0.5. Erecting castle erect-castlesucceeds probability 0.67 moat already built, probability 0.25, otherwise. failed, erect-castle also destroys moat probability 0.5. Figure 17(a) showsProbabilistic-FF POND solve problem less second arbitrary high values, performance planners almost independent required probabilitysuccess.Slippery-Gripper already bit complicated domain. states Slippery-Gripperspecified four boolean variables grip-dry, grip-dirty, block-painted, block-held,four actions dry, clean, paint, pickup. initial state, block neither paintedheld, gripper clean, gripper dry probability 0.7. goalclean gripper holding painted block. Action dry dries gripper probability 0.8. Actionclean cleans gripper probability 0.85. Action paint paints block probability 1,makes gripper dirty probability 1 block held, probability 0.1not. Action pickup picks block probability 0.95 gripper dry,probability 0.5 gripper wet.Figure 17(b) depicts (on log-scale) relative performance Probabilistic-FF PONDSlippery-Gripper function growing . performance Probabilistic-FF nicely flataround 0.06 seconds. time, comparison POND somewhat problematic, because,fixed , POND Slippery-Gripper exhibited huge variance runtime. Figure 17(b)plot best runtimes POND, well average runtimes. best run-times PONDdifferent values vary around couple seconds, average runtimes significantlyworse. (For high values POND timed-out sample runs, thus plot provideslower bound average runtimes.)next two domains, 1D-WalkGrid 2D-WalkGrid, robot pre-plan sequence conditional movements taking corner grid farthest (from initial608fiP ROBABILISTIC -FFposition) corner (Hyafil & Bacchus, 2004). 1D-WalkGrid grid one-dimensional,2D-WalkGrid grid two-dimensional. Figure 18(a) depicts (on log-scale) snapshotrelative performance Probabilistic-FF POND one-dimensional grids width n= 0.9. robot initially (1, 1), get (1, n), try moving twopossible directions. two movement actions moves robot right directionprobability 0.8, keeps place probability 0.2. easy see Figure 18(a)difference two planners domain substantialwhile runtime ProbabilisticFF grows linearly x, dependence POND seemingly exponential.2D-WalkGrid domain already much challenging probabilistic planning.2D-WalkGrid problems n n grids robot initially (1, 1), get (n, n),try moving four possible directions. four movement actions advancesrobot right direction probability 0.8, opposite direction probability 0,either two directions probability 0.1. Figure 18(a) depicts (on log-scale)snapshot relative performance Probabilistic-FF POND 2D-WalkGridlow required probability success = 0.01, function grids width n.plot shows Probabilistic-FF still scales well increasing n (though linearly anymore),POND time-outs grid widths n > 3. higher values , however, Probabilistic-FFreach time-out limit rather small grids, notably n = 6 n = 5 = 0.25= 0.5, respectively. reason Probabilistic-FFs heuristic function goodenough estimating many times, early point plan, probabilistic action mustapplied order sufficiently support high goal threshold end plan. explainphenomenon detail end section, find also appears variantwell-known Logistics domain.last set problems comes standard Logistics domain. problem instancex-y-z contains x locations per city, cities, z packages. see Probabilistic-FFscales much worse, Logistics, presence probabilistic effects initialstate uncertainty (we explain reason end section). Hence use muchsmaller instances ones used Section 5.1. Namely, allow direct comparisonprevious results domain, closely follow specification Hyafil Bacchus (2004).use instances configurations x-y-z = 2-2-2, 4-2-2, 2-2-4, distinguish twolevels uncertainty.L-x-y-z correspond problems uncertainty outcome load unloadactions. Specifically, probabilities success load 0.875 trucks 0.9airplanes, unload, 0.75 0.8, respectively.LL-x-y-z extends L-x-y-z independent uniform priors initial locationpackage within start city.Figure 19 depicts (on log scale) runtimes Probabilistic-FF POND L-2-2-2, L-4-2-2,L-2-2-4, function growing . problems, planners appear scale well,runtime Probabilistic-FF optimal runtime POND roughly same,average runtime POND somewhat degrading 2-2-2 4-2-2 2-2-4. showsplanners much efficient domain previously known SAT CSPbased techniques. However, moving LL-x-y-z changes picture planners. resultsfollows:609fiD OMSHLAK & H OFFMANNL-2-2-2L-4-2-2100PFFPOND (min)POND (avg)10.110Time (sec)10Time (sec)Time (sec)100PFFPOND (min)POND (avg)100.010.01L-2-2-4100PFFPOND (min)POND (avg)10.10.250.5(a)0.750.950.010.0110.10.250.5(b)0.750.950.010.010.250.50.750.95(c)Figure 19: Probabilistic-FF POND problems Logistics (a) L-2-2-2, (b) L-4-2-2,(c) L-2-2-4.1. LL-2-2-2, runtimes Probabilistic-FF identical L-2-2-2,optimal runtimes POND slightly degraded 28 seconds. However, examinedvalues , runs POND resulted timeouts.2. LL-4-2-2, runtimes Probabilistic-FF identical L-4-2-2{0.01, 0.25, 0.5, 0.75}, yet Probabilistic-FF time-outed = 0.95. optimal runtimesPOND degraded L-4-2-2 9 18 seconds, again, values, runs POND resulted timeouts.3. LL-2-2-4, Probabilistic-FF experienced hard times, finishing 0.19 seconds =0.01, time-outing examined values . optimal runtimes PONDdegraded L-2-2-4 120 700 seconds, well, values ,runs POND resulted timeouts.also tried variant LL-x-y-z non-uniform priors initial locations packages, resulted qualitatively similar picture absolute relative performance.LL-x-y-z domain remains challenging, deserves close attention future developments probabilistic planning. context, interesting close lookreasons failure Probabilistic-FF is. turns Probabilistic-FF good enoughestimating many times, early point plan, probabilistic action must appliedorder sufficiently support high goal threshold end plan. make concrete,consider Logistics example uncertain effects load unload actions. Consider package P must go city city B. Lets say P initially airport.goal threshold high, means that, able succeed, package broughtairport high probability loading onto airplane. exactly pointProbabilistic-FFs heuristic function fails. relaxed plan contains actions unloading Pairport. effect search proceeds quickly loading P onto planebringing B. search gets point B unloaded goal location, goal threshold cannot achieved matter many times one unloads P. point,610fiP ROBABILISTIC -FFProbabilistic-FFs enforced hill-climbing enters loop eventually fails relaxed plan(which over-estimates past achievements) becomes empty.18challenge devise methods better recognizing many times Punloaded airport order sufficiently support goal threshold. error madeProbabilistic-FF lies propagation weights implication graph over-estimatesgoal probability. Note much critical actions must applied earlyplan, actions applied later. action appears early plan,relaxed plan, executed, long. Recall weight propagation proceedsbackwards, goal towards current state. single backwards step, propagationmakes approximation might lose precision results. several backwards steps,imprecisions accumulate. Hence quality approximation decreases quicklynumber backwards steps. longer distance goal current state is,information lost. observed phenomenon detailed experiments differentweight propagation schemes, is, different underlying assumptions. propagationschemes tried, independence assumption, presented paper, faraccurate one. schemes failed deliver good results even much shorter distancesgoal current state.interesting consider issue affects POND, uses different methodestimating probability goal achievement: instead performing backwards propagationaggregation weight values, POND sends set random particles relaxed planninggraph forward fashion, stops graph building enough particles end goal.empirical results, seems method suffers similar difficulties Probabilistic-FF,large extent. PONDs optimal runtimes LL-x-y-z much higherL-x-y-z. indicates always challenging POND recognize needapplying action many times early plan. interestingly, POND never times-outL-x-y-z, often time-out LL-x-y-z. indicates that, extent, matterchance whether PONDs random particles recognize need applying actionmany times early plan. intuitive explanation good casessufficiently many particles failed reach goal due taking wrong effect a.Based intuition, one would expect helps increase number random particlesPONDs heuristic function. so, running POND LL-x-y-z increased numberparticles, 200 600 instead default value 64. surprise, qualitative behaviorPOND change, time-outing similar number cases. unclear us reasonphenomenon is. Certainly, observed situation encoded LL-x-y-zsolved satisfaction either Probabilistic-FFs weight propagation PONDs random particlemethods, current configurations.time writing, unclear authors better methods could devised. seemsunlikely weight propagation least one resort expensive reasoning existsmanages long distances better independence assumption. alternative waymight simply define weaker notion plans allows repeat certain kinds actions18. happen L-2-2-2, L-4-2-2, L-2-2-4 instances simply smallhigh goal probability achieved without thinking much problem; one increases sizeinstances, problem appears. problem appears earlier presence initial state uncertainty evensmall instances LL-2-2-2, LL-4-2-2, LL-2-2-4 uncertainty start positionpackages one needs try unloading start airports often.611fiD OMSHLAK & H OFFMANNthrowing dice unloading package arbitrarily many times. However, since assumptionobservability plan execution, executing plan wouldstill arise question often action tried. Since Logistics fairly well-solveddomain simpler formalisms virtue Probabilistic-FF, even probabilistic settinglong effects deterministic consider addressing problem quite pressing openquestion.6. Conclusiondeveloped probabilistic extension Conformant-FFs search space representation, usingsynergetic combination Conformant-FFs SAT-based techniques recent techniquesweighted model counting. provided extension conformant relaxed planningapproximate probabilistic reasoning. resulting planner scales well range benchmark domains. particular outperforms close relative, POND, least order magnitudealmost cases tried.point may somewhat obvious, would like emphasize achievementssolve (this particular) problem all. Probabilistic-FF inherits strengthsweaknesses FF Conformant-FF, like domains FFs Conformant-FFs heuristicfunctions yield bad estimates (e.g. mentioned Cube-center variant). Whats more, probabilistic setting introduces several new potential impediments FFs performance. one thing,weighted model counting inherently harder SAT testing. Though happenset benchmarks, bound cases cost exact model counting becomesprohibitive even small examples. promising way address issue lies recent methodsapproximate model counting (Gomes, Sabharwal, & Selman, 2006; Gomes, Hoffmann, Sabharwal, & Selman, 2007). methods much efficient exact model counters.provide high-confidence lower bounds number models. lower bounds usedProbabilistic-FF place exact counts. shown good lower boundshigh confidecne achieved quickly. challenge extend methodscurrently designed non-weighted CNFs handle weighted model counting.importantly perhaps, presence probabilistic effects fundamental weakness Probabilistic-FFs PONDs heuristic information. becomes pitfall performance even straightforward adaptation Logistics domain, otherwise easykind planners. outlined, key problem that, obtain high enough confidencegoal achievement, one may apply particular actions several times early plan.Neither Probabilistic-FFs PONDs heuristics good enough identifying many times.view, finding techniques address issue currently important open topicarea.Apart addressing latter challenge, intend work towards applicability real-wordsettings. Particularly, look space application settings Rovers domain hints at,medication-type treatment planning domains, power supply restoration domain (Bertoli,Cimatti, Slaney, & Thiebaux, 2002).612fiP ROBABILISTIC -FFAcknowledgmentsauthors would like thank Dan Bryce Rao Kambhampati providing binary distribution POND2.1. Carmel Domshlak partially supported Israel Science Foundationsgrant 2008100, well C. Wellner Research Fund. major parts researchaccomplished time Jorg Hoffmann employed Intelligent InformationSystems Institute, Cornell University.Appendix A. ProofsProposition 2 Let (A, NbI , G, ) probabilistic planning problem described k state variables, m-step sequence actions A. Then, |Nba | = O(|NbI |+m(k+1))largest description size action A.Proof: proof rather straightforward, exploits local structure Nba CPTs.first nodes/CPTs layer X(0) Nba constitutes exact copy NbI . Then, 1 m,t-th layer Nba contains k + 1 node {Y(t) } X(t) .First, let us consider action node Y(t) . specifying CPT TY (t) straightforwardmanner prescribed Eq. 4 might result exponential blow up, Eq. 4 suggestsoriginal description compact specification TY (t) . Therefore, TY (t)described space O(), description efficiently used answering queriesTY (t) (Y(i) = | ) Eq. 4. Next, consider CPT TX(t) state-variable node X(t) X(t) .time, rather evident Eq. 5 TX(t) described space O() queriesTX(t) (X(t) = x | X(t1) = x ) could efficiently answered. Thus, summing layers1 m, description size |Nba | = O(|NbI | + m(k + 1))Lemma 4 Given node v(t ) Impp(t) , p(t) (v(t )) = (v(t )) if, given vtime , sequence effects E(Impv(t )p(t) ) achieves p probability 1.Proof: proof Lemma 4 backward induction time layers Impv(t )p(t) .time t, node Impp(t) time-stamped p(t) itself. nodep(t) (p(t)) = (p(t)) = 1, but, given p time t, empty plan corresponding (empty)E(Impp(t)p(t) ) trivially re-establishes p certainty. Assuming claim holdsnodes Impp(t) time stamped + 1, . . . , t, show holds nodestime stamped .easy see that, node v(t ) Impp(t) , get p(t) (v(t )) = (v(t ))goes zero. First, consider chance nodes (t ) Impvp(t) . node, lbset zero p(t) (r(t + 1)) = 1 r add(). However,inductive assumption, case effects E(Imp(t )p(t+1) ) achieve pprobability 1, given occurrence time .Now, consider fact nodes q(t ) Impvp(t) . node, get nullifiedeffect e E(a), A(t ), con(e) = q. latter happens if, possible outcomes e, (i) node (t ) belongs Impp(t) , (ii) estimate p(t) ((t )) = ((t )).words, inductive assumption, given outcome (e) time , effects E(Imp(t )p(t) ) achieve p probability 1. Thus, given q time , effectsE(Impq(t )p(t) ) achieve p probability 1 independently actual outcome e. Alternatively, q(t ) lb > 0, effect e conditioned q(t), exists613fiD OMSHLAK & H OFFMANNoutcome e that, according proved chance nodes time-stamped, effects E(Imp(t )p(t+1) ) achieve p probability 1. Hence, whole seteffects E(Impq(t )p(t+1) ) achieve p probability 1.Lemma 5 Let (A, NbI , G, ) probabilistic planning task, sequence actions applicablebI , |+1 relaxation function A. time step m, proposition pP, P (t) constructed build-PRPG(a, A, (NbI ), G, , |+1 ), p time achievedrelaxed plan starting a|+1(1) probability > 0 (that is, p negatively known time t) p (t)P (t),(2) probability 1 (that is, p known time t) p P (t).Proof: proof direction straightforward induction t. = claimimmediate direct initialization (m) P (m). Assume that, < t,p (t ) P (t ), p negatively known time , p P (t ), p knowntime .First, consider p(t) (t) P (t), suppose p egatively know time t.inductive assumption, property PRPG construction (t 1) P (t 1)(t) P (t), p 6 (t 1) P (t 1). Therefore, p added (t) (andthen, possibly, moved P (t)) first loop build-timestep procedure.However, so, exists action A(t 1), e E(a), (e) (i)con(e) (t 1) P (t 1), (ii) p add(). Again, assumption inductionpre(a) known time 1, con(e) negatively known time 1. Hence,non-zero probability occurring time implies p achieved time probabilitygreater 0, contradicting p negatively know time t.Now, let us consider p(t) P (t). Notice that, > m, p(t) P (t)_l .(28)lsupport(p(t))Thus, world state w consistent bI , either q w fact propositionq(m) support(p(t)), or, effect e action a(t ) A(t ), < t, con(e)P (t ) {(t ) | (e)} support(p(t)). first case, Lemma 4 immediately impliesconcatenation a|+1 arbitrary linearization (relaxed) actions A(0), . . . , A(t 1)achieves p probability 1, thus p known time t. second case, inductiveassumption implies con(e) known time t, together Lemma 4 impliesconcatenation a|+1 arbitrary linearization (relaxed) actions A(0), . . . , A(t 1)achieves p probability 1.proof direction induction well. = claimimmediate direct initialization P (m). Assume that, < t, pnegatively known time , p (t ) P (t ), p known time , p P (t ).First, suppose p negatively known time t, yet p 6 (t) P (t).inductive assumption plus A(t 1) containing NOOP actions propositions(t 1) P (t 1), know p negatively known time 1. so, p becomenegatively known time due (e), e E(a), pre(a) known614fiP ROBABILISTIC -FFtime 1, con(e) negatively known time 1. inductive assumption,latter conditions imply con(e) (t 1) P (t 1), pre(a) P (t 1). so, padded (t) P (t) first loop build-timestep procedure, contradictingassumption p 6 (t) P (t).Now, let us consider p known time t. inductive assumption, P (t 1) containsfacts known time 1, thus A(t 1) maximal subset actions A|+1 applicabletime 1. Let us begin exhaustive classification effects e actions A(t 1)respect p time t.(I) (e) : p add(), con(e) P (t 1)(II) (e) : p add(), con(e) (t 1)(III) (e) : p 6 add() con(e) 6 P (t 1) (t 1)set (I) empty, then, construction build-w-impleafs(p(t), Imp),{(t 1) | (e)} support(p(t)),e (I). Likewise, construction build-timestep (notably, update ),e (I),_(t 1).{(t1)|(e)}Putting two facts together, Eq. 28 holds p time t, thus p P (t).Now, suppose set (I) empty. hard verify subset effects (III)makes p known time t. Thus, event least one effects (II) occurs must holdprobability 1. First, construction build-w-impleafs(p(t), Imp),[support (p(t))support (con(e)(t 1))e(II)Then, 4 Lemma 4 event least one effects (II) occurs holdsprobability 1_le(II)lsupport(con(e)(t1))Putting two facts together, Eq. 28 holds p time t, thus p P (t).Theorem 6 Let (A, NbI , G, ) probabilistic planning task, sequence actions appli+cable bI , |+1 relaxation function A. build-PRPG(a, A, (NbI ), G, , |1 ) returns+FALSE, relaxed plan (A, bI , G, ) starts a|1 .Proof: Let > 0 last layer PRPG upon termination build-PRPG. everyt, construction PRPG Lemma 5, sets P (t ) (t ) contain(and all) propositions known (respectively unknown) executing actionsaction layers including A(t 1).615fiD OMSHLAK & H OFFMANNFirst, let us show build-PRPG returns FALSE, corresponding termination criterion would hold future iterations. P (t + 1) = P (t), A(t + 1) = A(t).Subsequently, since P (t + 1) (t + 1) = P (t) (t) A(t + 1) = A(t),P (t + 2) (t + 2) = P (t + 1) (t + 1). Given that, show P (t + 2) = P (t + 1)(t + 2) = (t + 1).Assume contrary exists p(t + 2) P (t + 2) p(t + 1) 6 P (t + 1),p(t + 1) (t + 1). construction sets P (t + 1) P (t + 2) build-timestepprocedure,_l ,lsupport(p(t+2))_6(29)llsupport(p(t+1))Consider exhaustive classification effects e actions A(t + 1) respect ptime + 2.(I) (e) : p add(), con(e) P (t + 1)(II) (e) : p add(), con(e) (t + 1)(III) (e) : p 6 add() con(e) 6 P (t + 1) (t + 1)Suppose set (I) empty, let e (I). P (t) = P (t + 1) con(e)P (t), thus {(t)W | (e)} support(p(t + 1)).W update build-timestep{(t)|(e)} (t), thus lsupport(p(t+1)) l, contradicting Eq. 29.Alternatively, assume set (I) empty. Using arguments similar proofLemma 5, p(t + 2) P (t + 2) p(t + 1) 6 P (t + 1) case imply_le(II)lsupport(con(e)(t+1))_6(30)le(II)lsupport(con(e)(t))However, A(t + 1) = A(t), (t + 1) = (t), P (t + 1) = P (t) together implyaction effects possibly take place time + 1 also feasible take place timet. Therefore, since e (II) con(e) (t + 1) definition (II), Eq. 30implies[[support (con(e)(t + 1)) (m) 6=support (con(e)(t)) (m),(31)e(II)e(II)contradicting termination condition. Hence, arrived contradiction assumptionp(t + 1) 6 P (t + 1).shown P (t + 2) = P (t + 1) (t + 2) = (t + 1), showtermination criteria implies that, q(t + 2) (t + 2),(m) support(p(t + 2)) = (m) support(p(t + 1)).616fiP ROBABILISTIC -FFLet Ep(t+2) set effects actions A(t + 1) con(e) (t + 1), and,outcome (e), p add(). Given that,(m) support(p(t + 2)) = (m)[support(con(e)(t + 1))[support(con(e)(t))eEp(t+2)= (m),(32)eEp(t+2)= (m) support(p(t + 1))first third equalities definition support sets via Lemma 4, secondequation termination condition.last things remains shown termination criteria implies get-P(t +2, G) =get-P(t + 1, G). Considering simple cases first, G 6 P (t + 1) (t + 1),P (t + 2) (t + 2) = P (t + 1) (t + 1) get-P(t + 2, G) =get-P(t + 1, G) = 0. Otherwise, G P (t + 1), P (t + 2) = P (t + 1) get-P(t + 2, G) =get-P(t + 1, G) = 1.leaves us case G P (t + 1) (t + 1) G (t + 1) 6= .P (t + 2) = P (t + 1), (t + 2) = (t + 1), termination condition,G (t) = G (t + 1) = G (t + 2).get-P(t + 1, G) =get-P(t, G) know action effects become feasible A(t)increase estimate probability achieving g G (t + 1) time time+ 1. However, P (t + 1) = P (t), (t + 1) = (t), A(t + 1) = A(t),action effect become feasible time + 1 already feasible time t, thusget-P(t + 1, G) =get-P(t, G) imply get-P(t + 2, G) =get-P(t + 1, G).point shown build-PRPG returns FALSE, corresponding termination criterion would hold future iterations. Now, assume contrary claimtheorem build-PRPG returns FALSE iteration t, yet exists relaxed plan(A, bI , G, ) starts a|+1 . First, = 1, Lemma 5 implies exists timeG P (T ). so, persistence negative termination condition impliesG P (t). However, case would get-P(t, G) = 1 (see second get-Pprocedure), thus build-PRPG would return TRUE ever getting check negativetermination condition iteration t. Alternatively, = 0, build-PRPG would terminatedreturning TRUE negative termination condition checked even once.leaves us case 0 < < 1 get-P(t, G) < . (get-P(t, G)contradict reaching negative termination condition iteration t.) also assumeG P (t) (t) P (t) (t) contains facts negatively known timet, thus persistence negative termination condition together G 6 P (t) (t) wouldimply relaxed plan > 0. Let us consider sub-goals G (t) 6= .(1) subgoals g G (t), implications Impg(t) due deterministicoutcomes effects E(Impg(t) ), uncertainty achieving G (t) timedue uncertainty initial state. Since initialV belief state reasonedrelaxation, case get-P(t, G) = WMC( gG\P (t) g ) provides usupper bound probability achieving goal G a|+1 concatenated617fiD OMSHLAK & H OFFMANNarbitrary linearization arbitrary subset A(0), . . . , A(t 1). termination subcondition get-P(t + 1, G) =get-P(t, G) persistence action sets A(T ), t,imply get-P(t, G) provides us upper bound probability achieving Ga|+1 concatenated arbitrary linearization arbitrary subset A(0), . . . , A(T ),t. Together get-P(t, G) < , latter conclusion contradicts assumptiondesired relaxed plan exists.(2) exists subgoal g G (t) implications Impg(t) due trulyprobabilistic outcomes effects E(Impg(t)actions A(t)V ), repeating (relaxed) VA(t + 1) necessarily result WMC( gG\P (t+1) g ) > WMC( gG\P (t) g ),contradicting termination sub-condition condition get-P(t + 1, G) =get-P(t, G).Hence, arrived contradiction assumption build-PRPG returns FALSE time t,yet exists relaxed plan (A, bI , G, ) starts a|+1.ReferencesBertoli, P., Cimatti, A., Pistore, M., Roveri, M., & Traverso, P. (2001). MBP: model based planner.Proc. IJCAI01 Workshop Planning Uncertainty Incomplete Information,Seattle, WA.Bertoli, P., Cimatti, A., Slaney, J., & Thiebaux, S. (2002). Solving power supply restoration problems planning via symbolic model-checking. Proceedings 15th European Conference Artificial Intelligence (ECAI), pp. 576580, Lion, France.Blum, A. L., & Furst, M. L. (1997). Fast planning planning graph analysis. ArtificialIntelligence, 90(1-2), 279298.Bonet, B., & Geffner, H. (2001). Planning heuristic search. Artificial Intelligence, 129(12),533.Bonet, B., & Geffner, H. (2000). Planning incomplete information heuristic search beliefspace. Proceedings 5th International Conference Artificial Intelligence PlanningScheduling Systems (AIPS), pp. 5261, Breckenridge, CO.Boutilier, C., Friedman, N., Goldszmidt, M., & Koller, D. (1996). Context-specific independenceBayesian networks. Proceedings Twelfth Conference Uncertainty ArtificialIntelligence (UAI), pp. 115123, Portland, OR.Brafman, R. I., & Domshlak, C. (2006). Factored planning: How, when, not. Proceedings 18th National Conference Artificial Intelligence (AAAI), pp. 809814, Boston,MA.Bryce, D., & Kambhampati, S. (2004). Heuristic guidance measures conformant planning.Proceedings 14th International Conference Automated Planning Scheduling(ICAPS), pp. 365374, Whistler, BC, Canada.Bryce, D., Kambhampati, S., & Smith, D. (2006). Sequential Monte Carlo probabilistic planningreachability heuristics. Proceedings 16th International Conference AutomatedPlanning Scheduling (ICAPS), pp. 233242, Cumbria, UK.618fiP ROBABILISTIC -FFChavira, M., & Darwiche, A. (2005). Compiling Bayesian networks local structure. Proceedings 19th International Joint Conference Artificial Intelligence (IJCAI), pp.13061312, Edinburgh, Scotland.Darwiche, A. (2000). Recursive conditioning. Artificial Intelligence, 125(1-2), 541.Darwiche, A. (2001). Constant-space reasoning dynamic Bayesian networks. International Journal Approximate Reasoning, 26(3), 161178.Dean, T., & Kanazawa, K. (1989). model reasoning persistence causation. Computational Intelligence, 5, 142150.Dechter, R. (1999). Bucket elimination: unified framework reasoning. Artificial Intelligence,113, 4185.Domshlak, C., & Hoffmann, J. (2006). Fast probabilistic planning weighted model counting. Proceedings 16th International Conference Automated PlanningScheduling (ICAPS), pp. 243252, Cumbria, UK.Gomes, C. P., Hoffmann, J., Sabharwal, A., & Selman, B. (2007). sampling model counting.Proceedings 20th International Joint Conference Artificial Intelligence (IJCAI07), Hyderabad, India.Gomes, C. P., Sabharwal, A., & Selman, B. (2006). Model counting: new strategy obtaining good bounds. Proceedings 21th National Conference Artificial Intelligence(AAAI-06), pp. 5461, Boston, MA.Hanks, S., & McDermott, D. (1994). Modeling dynamic uncertain world I: Symbolicprobabilistic reasoning change. Artificial Intelligence, 66(1), 155.Hoffmann, J., & Nebel, B. (2001). FF planning system: Fast plan generation heuristicsearch. Journal Artificial Intelligence Research, 14, 253302.Hoffmann, J., & Brafman, R. (2006). Conformant planning via heuristic forward search: newapproach. Artificial Intelligence, 170(67), 507541.Huang, J. (2006). Combining knowledge compilation search efficient conformant probabilistic planning. Proceedings 16th International Conference Automated PlanningScheduling (ICAPS), pp. 253262, Cumbria, UK.Hyafil, N., & Bacchus, F. (2004). Utilizing structured representations CSPs conformantprobabilistic planning. Proceedings European Conference Artificial Intelligence(ECAI), pp. 10331034, Valencia, Spain.Jensen, F. (1996). Introduction Bayesian Networks. Springer Verlag, New York.Kushmerick, N., Hanks, S., & Weld, D. (1995). algorithm probabilistic planning. ArtificialIntelligence, 78(1-2), 239286.Little, I., Aberdeen, D., & Thiebaux, S. (2005). Prottle: probabilistic temporal planner. Proceedings 20th National Conference Artificial Intelligence (AAAI-05), pp. 11811186, Pittsburgh, PA.Littman, M. L., Goldsmith, J., & Mundhenk, M. (1998). computational complexity probabilistic planning. Journal Artificial Intelligence Research, 9, 136.619fiD OMSHLAK & H OFFMANNMajercik, S. M., & Littman, M. L. (1998). MAXPLAN: new approach probabilistic planning. Proceedings 4th International Conference Artificial Intelligence PlanningSystems (AIPS), pp. 8693, Pittsburgh, PA.Majercik, S. M., & Littman, M. L. (2003). Contingent planning uncertainty via stochasticsatisfiability. Artificial Intelligence, 147(1-2), 119162.McDermott, D. (1998). 1998 AI Planning Systems Competition. AI Magazine, 2(2), 3555.McDermott, D. V. (1999). Using regression-match graphs control search planning. ArtificialIntelligence, 109(1-2), 111159.Onder, N., Whelan, G. C., & Li, L. (2006). Engineering conformant probabilistic planner. JournalArtificial Intelligence Research, 25, 115.Pearl, J. (1984). Heuristics - Intelligent Search Strategies Computer Problem Solving. AddisonWesley.Pearl, J. (1988). Probabilistic Reasoning Intelligent Systems: Networks Plausible Inference.Morgan Kaufmann, San Mateo, CA.Rintanen, J. (2003). Expressive equivalence formalisms planning sensing. Proceedings 13th International Conference Automated Planning Scheduling (ICAPS),pp. 185194, Trento, Italy.Roth, D. (1996). hardness approximate reasoning. Artificial Intelligence, 82(1-2), 273302.Russell, S., & Norvig, P. (2004). Artificial Intelligence: Modern Approach (2 edition). Pearson.Sang, T., Bacchus, F., Beame, P., Kautz, H., & Pitassi, T. (2004). Combining component cachingclause learning effective model counting. (Online) Proceedings 7th International Conference Theory Applications Satisfiability Testing (SAT), Vancouver, BC,Canada.Sang, T., Beame, P., & Kautz, H. (2005). Solving Bayes networks weighted model counting.Proceedings 20th National Conference Artificial Intelligence (AAAI), pp. 475482,Pittsburgh, PA.Shimony, S. E. (1993). role relevance explanation I: Irrelevance statistical independence. International Journal Approximate Reasoning, 8(4), 281324.Shimony, S. E. (1995). role relevance explanation II: Disjunctive assignments approximate independence. International Journal Approximate Reasoning, 13(1), 2760.Zhang, N. L., & Poole, D. (1994). simple approach Bayesian network computations.Proceedings 10th Canadian Conference Artificial Intelligence, pp. 171178, Banff,Alberta, Canada.620fiJournal Artificial Intelligence Research 30 (2007) 361-412Submitted 07/07; published 11/07Natural EventsJohn Belljb@dcs.qmul.ac.ukDepartment Computer Science,Queen Mary, University London,London E1 4NS, UKAbstractpaper develops inductive theory predictive common sense reasoning.theory provides basis integrated solution three traditional problemsreasoning change; frame, qualification, ramification problems. theoryalso capable representing non-deterministic events, provides means statingdefeasible preferences outcomes conflicting simultaneous events.1. Introductiongreat deal written logical representation common sense reasoningchange since publication McCarthy Hayess (1969) seminal paper,many theories proposed; see, example, monographs Sandewall (1994),Shanahan (1997), Reiter (2001).theories treat events1 deductively, along lines representation actionsused planner strips (Fikes & Nilsson, 1971). event type definedpreconditions effects. example, blocks world, preconditions unstackingblock x block x y, x clear (no block top it), robot handempty. effects hand holding x, clear, preconditionsfalse. Change matter deduction. particular event (a token eventtype) occurs particular preconditions hold, particular effects deduced,necessarily follow, it. Events kind called deductive eventsview natural events represented deductively called Deductionism.Deductive event types thought invariable regularities (or uniformities) sequence. Viewed way strips representation events seen descendedconsidered Hume Mill discussions causation. Hume (1739, BkI, Pt III) suggests inductively acquire knowledge regularities successionform: A-type events followed B-type events. consider A-type eventscause B-type events, whenever see A-type event expectfollowed B-type event. Mill (1898, Bk III, Ch 5) complicates picture consideringassemblages conditions. single assemblage might consist A-type event togethercertain conditions must present (positive conditions) certain conditionsmust absent (negative conditions). example, assemblage concerninglighting matches might include striking match, presence oxygen,absence dampness match head.1. Events assumed include physical actions agents; whether intentional unintentional.c2007AI Access Foundation. rights reserved.fiBellMill (1898) thought possible, least principle, define assemblagesdetailed enough ensure effects: every event combinationobjects events, given concurrence circumstances, positive negative,occurrence always followed phenomenon (p. 214).However, Hume (1777, pp. 36-38) already argued possibility. alwayspossible regularity, matter long continued past, continuefuture. Consequently set sentences report observed everlogically implies anything observed. Goodman (1954, p. 59)puts it, happened imposes logical restrictions happen. So,Deductionism plausible, necessary assume Nature uniform;future resemble past, past regularities continue. Now, clearly, Uniformitycannot justified appealing experience, difficult see elsejustified; see, Goodmans discussion (pp. 61-62). Without justification, Deductionismregarded suspect theory.Deductionism also suspect practice, impossible practice define preconditions which, together occurrence event, sufficient ensureeffects follow. example, Russell (1913, p. 7) considers problem conflictingevents: put penny slot, draw ticket earthquake upsets machine calculations. order sure expectedeffect, must know nothing environment interfere it.means supposed cause not, itself, adequate insure effect. Russell alsoobserves cannot usefully solve problem complicating preconditions because:soon include environment, probability repetition diminished, until,last, whole environment included, probability repetition becomes almostnil (pp. 7-8).problem specifying preconditions always sufficient also arises Mackiesaccount causal regularities (invariable regularities sequence). example, leastpart answer [to question caused particular fire] setconditions (of positive negative), including presenceinflammable material, absence suitably placed sprinkler, doubt quitenumber others (Mackie, 1975, p. 16). list conditions incomplete because, evencausal regularities hold objects, seldom, ever, known full: Causalknowledge progresses gradually towards formulation regularities, hardlyever gets there. Causal regularities known typically incomplete . . . knowcertain elliptical gappy universal propositions (Mackie, 1974, p. 66).sufficient-preconditions problem becomes acute consider formal representations intended practical use, preconditionscomputationally tractable. McCarthy (1977, p. 1040) gives example using boatcross river. Given boat rowing boat, equipped oars,manned oarsman, used convey two passengers across river; providedboat leak, provided hit rock, providedhit another boat, provided overturned hippopotamus,sunk meteorite, vapourized thermonuclear blast, etc. seems listqualifications need added limited limits imagination.Accordingly, McCarthy calls sufficient-preconditions problem qualification problem.362fiNatural Eventsresponse, Deductionists might argue representations abstractionsapproach works well simple domains, assumed qualifications arise. domains, might argue, uniformity assumptionreasonable, deductive theories provide useful representation. may welltrue, but, theories kind cannot readily extended complex (less uniform)domains additional complexity required preconditions quickly becomesoverwhelming. Thus Deductionist approach may appropriate certain applications,mathematical analysis high-level programming languages elementary commands viewed abstract operations data. inappropriaterepresentation predictive reasoning natural events, events everydayexperience, irregular treated deductively. Moreover, Deductionist abstraction better thought idealization, problematic one that.preconditions deductive event hold occurrence, effects logicallyguaranteed follow, natural force intervene prevent so.Deductive events thus natural, supernatural. idealization creates technicaldifficulties comes representation events variable effects (includingnon-deterministic context-dependent effects) effects always deduced, representation conflicting events (events whose effects individuallyconsistent jointly inconsistent) joint effects cannot consistently deduced.Consequently Deductionist theories phenomena (some discussedsequel) face unnecessary, self-imposed, difficulties. difficult escape conclusionthat, representing natural events deductively, Deductionism starts wrong foot.conclusion hardly surprising consider predictive reasoningnatural events inductive, rather deductive, nature.2 major purposepredictive reasoning support practical reasoning; is, reasoning do.Predictive reasoning normally based partial knowledge (or incomplete belief),causal regularities, Mackie observes, contexts events concernedoccur. also tends conjectural seeks produce reasonable conclusionsbasis known. result tends produce conclusions supradeductive (which may deducible known) defeasible (which may turnwrong).3 Accordingly, definitions (practical, non-omniscient) rationalitytypically couched terms utility expected (rather actual) outcomesactions. Russell Norvig (2003, p. 36) illustrate point follows: walkingalong Champs Elysees one day see old friend across street.traffic nearby otherwise engaged, rational, start cross street.Meanwhile 33,000 feet, cargo door falls passing airliner, make2. philosophy, term inductive reasoning applied form qualitative non-deductive reasoning. thus includes enumerative induction, general rule inferred non-exhaustiveset inferences (for example, emeralds observed green, thereforeemeralds green). form reasoning underlies knowledge regularities.comes inductive events idea (as explained text below) produce reasonableconclusions outcomes basis partial information. AI, inductive reasoningkind formalized non-monotonic logics.3. J. K. Galbraith remarked two kinds forecasters. dont know,know dont know.363fiBellside street flattened. irrational cross street? unlikelyobituary would read Idiot attempts cross street.change perspective results substantial simplification problem specifying preconditions. longer concerned invariable regularities sequence,necessary connections events effects, rather regularitiessequence normally hold; fairly dependable regularities sequence (Russell, 1913, p. 8), expected connections events effects. Consequentlydefine preconditions which, together associated events, form conditionsnormally sufficient associated effects, otherwise minimalsense part redundant. Preconditions kind tendtractable (simple) useful (to occur frequently practice).give Humeian account predictions involving natural events terms(fairly) dependable regularities expectations engender. event occurs,preconditions obtain, aware anything prevent effectsfollowing, form clear expectation (we know) effects follow,rational (reasonable) predict them. example, block unstackedblock B, preconditions obtain, aware preventer,clearly expect, predict, longer B. complex cases involveconflicting events. If, case, clear expectation outcome,rational predict it. example, clearly expect, predict, airliner doorcrush, rather bounce off, intrepid pedestrian. example considertwo conflicting outcomes possible, one probable. However,cases expectations unclear; torn conflicting expectationsknow expect. cases seems reasonable adopt cautiousapproach, restrict predictions effects clearly expect. example,fair coin tossed, clear expectation sideland. half expect land heads half expect landtails. consider two conflicting outcomes equally probable. caution dictatespredict coin lands one side other,predict two sides land on. Note that, expectations basedincomplete knowledge, predictions based defeasible. example,if, unbeknown us, block glued block B unstacked B,event effects predict have.thus begin thinking natural events defeasible strips events, stripslike events whose effects always follow (when occur preconditionstrue), inferring effects inductively. Accordingly, events kindcalled inductive events, view natural events represented inductivelycalled Inductionism. logic understood include deductive inductive inference, Inductionist objection Deductionism stated succinctly:Deductionism logical mistake.paper seen argument Inductionism. begins presenting basictheory inductive events uses basis comprehensive theorynatural events.formal language theory expressed defined next section,basic theory inductive events given Section 3. theory builds364fiNatural Eventsideas McCarthy (1986, 9), Lifschitz (1987), Shoham (1988), logico-pragmaticnature; is, consists set axioms together formal pragmatics, which,given formal theory containing axioms, interprets particular way,so, generates predictions theory. basic theory inductive events providesbasis solution qualification problem integrates basissolution complementary frame problem (McCarthy & Hayes, 1969, p. 487);is, problem inferring unchanged occurrence event (or,generally, occurrence several simultaneously occurring events).Section 4, basic theory inductive events extended introducing distinctioninductive events primary secondary. Whereasprimary events occur independently, secondary events invoked (primarysecondary) events appropriate contexts, causally dependent them.simplest case, primary event invokes secondary event event so.case, secondary event succeeds (is followed effects) primaryevent invoked succeeds. extension basic theory makes possibleinductive events additional context-dependent effects, thereby providing basissolution ramification problem (Ginsberg & Smith, 1988); is, problemrepresenting indirect, context-dependent, effects events. example, agentholding block agent moves, move-agent event invokes causallydependent move-block event, effect block moves agent does.extension also makes possible represent events non-deterministic effects.example, non-deterministic event tossing fair coin representedevent invoke two conflicting deterministic events, one effect coinlands heads, lands tails.theory natural events completed Section 5, deals problemrepresenting defeasible preferences outcomes conflicting simultaneous events.two events conflict often clear expectation outcome. example,two agents attempt go door simultaneously one succeed,reasonable expect stronger one so. However expectationdefeasible. stronger agent may fail independent reason (the agent may slip,say), case preference reversed expect weaker agentsucceed (although weaker agent may also slip, etc.). order represent defeasibleasymmetric expectations kind event preferences introduced, formalpragmatics basic theory refined order interpret correctly.philosophical justification theory natural events given Section 6,related work discussed Section 7.Although causal notions underlie much development theory naturalevents, explicit reference causation theory. intendedprovide basis definition sufficient causation forms part larger theorycausation (Bell, 2004, 2006, 2008).44. According theory, occurrence event e context c sufficient cause effect occurrence e c sufficient ensure ; instance, e succeeds time logical consequencees effects t+1, e sufficient cause . definition causation obtained requiring sufficient causes also satisfy refinement Lewiss (1986, Ch. 21) counterfactual-dependence365fiBell2. Event Language ELtheory events expressed event language EL, developedorder represent reason events effects, basis partialinformation, successive points time. section begins informal introductiongives formal account.order represent epistemic partiality natural economical way EL basedKleenes (1952, 64) strong three-valued logic.5 Kleene introduced truth value undefined order accommodate undecidable mathematical sentences. However alsosuggested undefined could interpreted unknown, where: unknown category regard proposition falling, whose value eitherknow choose moment disregard; exclude twopossibilities true false (p. 335). Thus understood, undefined truth valuepar true false, introduction intended practical, logicallyconservative, way reasoning partial information; rather revolutionary attackclassical logic.6keeping interpretation, truth value sentence classical(either true false) enough known determine it. formal semanticspropositional case thus given follows. model, , consists possiblypartial evaluation function, V , assigns one classical truth valueatomic proposition. truth (|=) falsity (=|) sentences definedfollowing truth falsity conditions:|= p iff V (p) = true=| p iff V (p) = false|= iff =|=| iff |=condition: occurrence event e cause effect context c iff (i) e sufficient causec, (ii) depends e closest context c e sufficient cause .5. Kleenes logic familiar readers background philosophical logic (it is, example, usedKripke, 1975, basis theory truth), choice use likely appearnatural one them. However, Kleenes logic may unfamiliar readers reasoning actionschange community, may well wonder used established classicallanguage Situation Calculus (McCarthy & Hayes, 1969). full justification choicewould involve lengthy comparison languages. short, simpler acknowledge epistemicpartiality ubiquitous feature predictive reasoning deal directly, Kleeneslogic, rather indirectly classical logic; means syntactic encoding circumscription (asSituation Calculus), using modal logic (as TK, Shoham, 1988). representationpartiality Kleenes logic also optimal; cost associated representationunknown. contrast, partiality classical reasoning requires consideration classmodels (or possible worlds) large enough ensure unwanted noise (arbitrary,compulsory, assignments classical truth values sentences whose truth values determinedtheory question) eliminated. profligacy significant considering contemplatedmodel-building implementation event theories (Bell, 1996, 1); see remarks implementationSection 8. Finally, indicated introduction Footnote 4, theory events intendedform part larger theory causation, EL embedded partial modal language.6. Confirmed classicists thus rest assured threatened anything radical,Bolshevik menace Brouwer Weyl (remark Intuitionism attributed F.P. RamseyBlackburne, 1994).366fiNatural Events|= iff |= |==| iff =| =|sentence true false, false true, undefined otherwise;sentence true true, false either false, undefinedotherwise. Note evaluation function total semantics equivalentsemantics classical propositional calculus. essential difference twosemantics classical assumption evaluation function total; additionalrequirement V assigns least one classical truth value atomic proposition.operators defined classical logic. particular, inclusive disjunctiondefined as: =Df ( ); true either disjunct true, falsedisjuncts false, undefined otherwise. exclusive disjunction definedas: =Df ( ) ( ); true truth valuesdefined different, false truth values definedsame, undefined otherwise.7Kleenes logic perhaps called demi-classical, becomes classicaltruth values constituent atomic sentences classical. Unsurprisingly then,use Kleenes logic not, itself, solve problems predictive reasoningbeyond representing partiality. is, example, reliance specialcausal notion consequence, Linear Logic (Girard, 1987).expressiveness Kleenes language greatly enhanced adding classicallyvalued definedness operator it. sentence true defined (is either truefalse), false otherwise:|= iff either |= =|=| iff neither |= =|classically-valued operators defined follows:=Df=DfF =DfU =Df=Df (T T) (F F) (U U)Thus, sentences : true true, false otherwise; F truefalse, false otherwise; U true undefined, false otherwise;7. Readers unfamiliar Kleenes logic may wish check definitions semantics.example, |= iff |= ( ) iff =| iff [M =| =| ] iff [M |=|= ].367fiBelltrue true not, false otherwise;8 truetruth value, false otherwise.9first-order extension, given Kleene, straightforward. universal sentencex true true assignments x, false false assignment,undefined otherwise. existential quantifier defined classical logic: x =Dfx; thus x true true assignment x, false falseassignments, undefined otherwise.order represent change, events time points added additional sort.simplicity, order time assumed discrete linear.object atom atom form r(u1 , . . . , un )(t), r object relationsymbol, ui object terms, time-point term. example, object atomsAt(O, L)(1) At(O, L)(2) state respectively object location L time 1,L time 2.event atom atom form r(u1 , . . . , un )(t), r event relationsymbol, ui event terms, time-point term. example, event atomOcc(Move(O, L1, L2))(3) states event consisting object moving locationL1 location L2 occurs time 3.intuition behind fact-event distinction events active agents (causes)change, facts passive patients change persist timeaffected event (until event causes change).10order represent persistence facts, second-order quantification objectrelations second-order relations added EL. object-relation atom atomform r(u1 , . . . , un )(t), r second-order relation symbol, ui objectrelation symbols object terms, time-point term. example, objectrelation atom Inert(At, hO, Li)(4) states relation inert objects Ltime 4.8. conditional captures much flavour classical material implication.emphasized defining weaker conditional Kleenes logic: =Df . conditionalinadequate, least present purposes, undefined, rather false, trueundefined. case stronger conditional, , could equally definedas: T. definition makes clear conditional states constraint mustsatisfied true, otherwise ignored. conditional quite capturemeaning classical material implication, satisfy (implicitly understood)condition false, . desired, possible define stronger conditional,better represents classical material implication, follows: =Df ( ) ( ); or,equivalently, =Df (T T) (F F). equivalence operator definedfollows: =Df ( ) ( ).9. addition truth-value designation operator new. Bochvar (1939) added truth operatordifferent system connectives, undefined operator U special case Rosser Turquettes(1952) Jk operator. Barringer, Cheng, Jones (1984) give natural deduction system Kleenes logicdefined operator D. system readily extended include operators defined above;additional introduction elimination rules connectives simply fold unfolddefinitions. Similar languages used basis formalization non-monotonic reasoning(Doherty, 1996).10. fact-event distinction similar McCarthys (1986, 9) fluent-event distinction. caseadding events ontology facts argued Davidson (1980). Lewis (1986, Ch. 23) goestreats facts events.368fiNatural Eventstemporally-indexed relation relation whose atoms temporally indexed; whoseatoms form r(u1 , . . . , un )(t). primitive atemporal relations EL temporalprecedence, <, identity, =. atemporal relations defined termstemporally-indexed relations follows:r(u1 , . . . , un ) =Df r(u1 , . . . , un )(t) .example, Phys(At)(t) abbreviated Phys(At), states (eternally) physical relation.formal semantics EL sketched follows. Models contain set objects,set event types, time frame consisting set time points ordered (discretelinear) precedence relation, functions interpreting terms relations.twin notions satisfaction violation formula, variable assignment model,defined means parallel recursion. truth (falsity) sentence modeldefined terms satisfaction (violation) assignments model.classical logic, model said model sentence (a set sentences )true (if every sentence true ), set sentences semanticallyentails sentence iff models also models .remainder section formal syntax semantics EL defined.Readers may wish skip next section return consult details necessary.Definition 1 four sorts EL identified following letters: (objects),(time points), E (events), R (object relations). vocabulary EL consistssymbols <, =, , D, , , (, ), following countable sets symbols:CS (constants sort S),VS (variables sort S),FS (function symbols arity n 1 sort S),RO , , RR (relation symbols arity n 0 sorts O, E,and R).sets RO CR required set. Otherwise sets requiredmutually disjoint. Furthermore, VR assumed contain variables arity n 0.Definition 2 terms EL defined follows.termS = CS VS {f (u1 , . . . , un ) : n-ary f FS , ui termS } {O, T, R}.termE = CE {f (u1 , . . . , un ) : n-ary f FE , ui termO }.Definition 3 EL minimal set satisfies following conditions.t, termT < EL.sort u, u termS , u = u EL.u1 , . . . , un termO , rO n-ary relation symbol RO , termT ,rO (u1 , . . . , un )(t) EL.369fiBellsort E R, u1 , . . . , un termS w1 , . . . , wm termO (where = 0n = 0), rS n + m-ary relation symbol RS , termT , rS (u1 , . . . , un ,w1 , . . . , wm )(t) EL.u1 , . . . , un termO , vR n-ary variable VR , termT ,vR (u1 , . . . , un )(t) EL., EL, EL, EL, ( ) EL.sort, v VS EL, v EL.members EL called formulas (of EL). formulas variable occursfree called sentences (of EL).Models EL consist set objects, set E event types, temporal framehT , (where set time points before-after relation ),interpretation functions terms relations. simplicity, time assumedisomorphic integers. denotations terms always defined varytime. contrast, temporally-indexed relations may partial may varytime. Consequently temporally-indexed relation interpreted function timepoints partial characteristic functions. defined, partial characteristic functionassociated time point maps instances relation {true, false}.Definition 4 model EL structure hO, E, hT , i, F, R, Vi, where:O, E mutually disjoint, non-empty, countable sets,binary relation isomorphic integers,R = hRO , , RR i. RO set partial functions arity n 0 type{true, false}. hS, Si {hE, Ei, hR, RO i}, RS set partial functionsarity n + 0 type n Om {true, false}.F = hFO , FT , FE , FR i. hS, Si {hO, Oi, hT, i, hR, RO i}, FS setfunctions arity n 1 type n S. FE set functionsarity n 1 type E.C , V C , V C , V C i, hV F , V F , V F , V F i, hV R , V R , V R ii interpretation functionV = hhVOERERERthat: VSC : CS hS, Si {hO, Oi, hT, i, hE, Ei, hR, RO i},R = VC.VSF : FS FS , VSR : RS (T RS ), VORDefinition 5 variable assignment EL model function g = hgO , gT , gE , gR i,hS, Si {hO, Oi, hT, i, hE, Ei}, gS : VS S, gR : VR (T RO ).EL-model , interpretation function V variable assignment g , termevaluation function Vg defined, terms relation symbols EL, follows:gS (u)V C (u)Vg (u) =VSF (f )(Vg (u1 ), . . . , Vg (un ))RVS (u)370u VS ,u CS ,u = f (u1 , . . . , un ) termS ,u RS .fiNatural EventsTable 1: Satisfaction violation conditions EL (see Definition 6)M, g |= < iff hVg (t), Vg (t )iM, g =| < iff hVg (t), Vg (t )i/M, g |= u = u iff Vg (u) Vg (u )M, g =| u = u iff Vg (u) Vg (u )M, g |= u(u1 , . . . , un )(t) iff (Vg (u)(Vg (t)))(Vg (u1 ), . . . , Vg (un )) = trueM, g =| u(u1 , . . . , un )(t) iff (Vg (u)(Vg (t)))(Vg (u1 ), . . . , Vg (un )) = falseM, g |= iff M, g =|M, g =| iff M, g |=M, g |= iff either M, g |= M, g =|M, g =| iff neither M, g |= M, g =|M, g |= iff M, g |= M, g |=M, g =| iff M, g =| M, g =|M, g |= v iff M, g |= every g g v gM, g =| v iff M, g =| g g v gDefinition 6 Let EL model, g variable assignment , let g v gindicate variable assignment g differs g assignment variable v.g satisfies EL-formula (written M, g |= ) violates (writtenM, g =| ) according clauses given Table 1.Let EL model. formula true (written |= ) M, g |=variable assignments g; formula false (written =| ) M, g =|variable assignments g; model sentence iff true ;model set sentences iff model every sentence .set sentences (semantically) entails sentence (written |= ) iff every modelalso model .3. Inductive Eventsformal theory natural events introduced stages, beginning, section,basic theory inductive events.Definition 7 theory inductive events, Ind , consists axioms given Table 2;thus Ind = {(1), (2), (3)}. event theory set EL sentences contains Ind .Axiom (1) defines notion success, states event e succeeds time ifftrue e occurs t, preconditions e true t, effects e truet+1.11 presence truth operator axiom ensures relation Succ11. Thus defined, success failure event simple, objective, matter whether occurrenceaccompanied preconditions followed effects. speaking success failure371fiBellTable 2: theory inductive events, Inde, t(Succ(e)(t) T(Occ(e)(t) Pre(e)(t) Eff(e)(t+1)))(1)R T(Phys(R) Theo(R))(2)R, x, t(Inert(R, hxi)(t) (Phys(R) (R(x)(t) R(x)(t+1))))(3)classical sense every instance either true false. thus possiblereason classically success failure basis partial information.view fact-event distinction, also necessary represent inertia; is,temporal persistence facts changed events. definition inertiabegins distinction physical facts (represented physical relations)theoretical facts (represented theoretical relations). Intuitively, physical facts factsworld directly observe it, whereas theoretical facts productcomplex reflection (theorizing about) physical facts.12 example,representation blocks world locations blocks might representedobject relation At. used define relation Clear, truelocation point time blocks location point time.theory, relation naturally classified physical relation (as representsphysical locations blocks) relation Clear naturally classified theoreticalrelation (as represents a, comparatively complex, property locations definedterms locations blocks). Note that, theoretical facts (ultimately) definedterms physical facts, theoretical facts supervene physical facts; is, fixingphysical facts point time also fixes theoretical facts point time.event theories, physical theoretical relations identified means secondorder predicates Phys Theo respectively. Thus Axiom (2) states every objectrelation either physical relation theoretical relation. matter notationalconvenience convention adopted object relation declaredtheoretical relation physical one. convention enforced formal pragmaticsdiscussed below.inertia physical facts defined Axiom schema (3); which, simplicity,henceforth called axiom. axiom, R n-ary object relation symbol, xvector x1 , . . . , xn object variables, hxi list hx1 , . . . , xn i. axiom statesR inert objects referred x time iff R physical relationevent end purpose (no teleology) implied; could equally talk event occurrencecomplete incomplete. natural talk informally intentional actions succeeding failing,example agent succeeding failing intention move particular location.attempt made represent intentionality formally.12. Physical facts thought Quines (1995, Chs. 2-3) observational predications.compounds primitive observation sentences, human equivalent bird-callsapes cries (p. 22). example, observational sentences Black (or Thats black) Dog(or Thats dog) might combined observational predication Black dog (or dogblack). Theoretical facts result complex compounding, involving logical connectivesand, especially, reification.372fiNatural Eventstruth values object atoms R(x)(t) R(x)(t+1) equivalent. Noterelation Inert classical event theories; Phys classical (by Axiom (2))right-hand equivalence classically valued. Note also that, event theoriescontain occurrences Theo relation, Axiom (2) unnecessary Axiom (3)simplified accordingly.turn intended interpretation event theories.intended interpretation, Axiom (1) used generate expected outcomesevents. Pre(e)(t) Occ(e)(t) true, consistent assumesuccess atom Succ(e)(t) true, success assumption made, axiomused conclude expected effects, Eff(e)(t+1), true. Thus interpretedaxiom states that, accompanied preconditions, occurring events normallysufficient (are normally followed by) effects. interpreted way,axiom amounts common sense law change.Similarly, intended interpretation, Axiom (3) used generate expectedpersistence physical facts. R physical relation, object atom R(x)(t) defined,consistent assume inertia atom Inert(R, hxi)(t) true, inertiaassumption made, axiom used conclude truth value R(x) persistst+1.13 Thus interpreted, axiom states physical facts normally persist,amounts common sense law inertia.intended interpretations axioms (1) (3) often conflict. example,unstack-A-from-B event occurs, preconditions true, relevant factsevents involved, consistent assume unstack event succeeds,consistent assume fact B inert, assumptions cannotmade success unstack event implies longer B.cases suggest change always priority inertia, successassumptions always priority inertia assumptions. conflict resolutionprinciple defended appealing regularity-based (Humeian) expectationchange. Thus, case hand, experience taught us unstack eventssort described normally succeed, form clear expectation effectsfollow. contrast, giving priority inertia would, contrary expectation, resultnothing changing, adopting neutral stance would, contrary expectation, produceunclear outcome.intended interpretation event theories enforced formal pragmatics,defines class preferred models given event theory. sectionnotion preference1 defined. later refined preference2 Section 5.order enforce convention object-relations physical unless stated otherwise, preferred1 models event theory models theory(positive) domain Phys relation large be. Let us say modelPhys-maximal model event theory model and, model, {R : |= Phys(R)} {R : |= Phys(R)} = . preferred1models Phys-maximal models .13. R(x)(t) defined, then, become clear, atom safely ignored. Inert(R, hxi)(t)consistently assumed, formal pragmatics (in particular, minimization evidentialatoms t+1) ensures R(x)(t+1) undefined, thereby satisfying axiom.373fiBellBeyond requirement, get clearer idea preferred1 modelevent theory look like considering inductive version canonical example,known Yale Shooting Problem (Hanks & McDermott, 1987). time 1 gunloaded pointed Fred. Nothing relevant happens time 2. time 3 gun fired.gun still loaded time 3, then, absence information, expectshot prove fatal Fred longer alive time 4. examplerepresented formally theory 1 = Ind {(4), (5), (6)}, where:t(Pre(Shoot )(t) (Alive(t) Loaded (t)))(4)t(Eff(Shoot)(t) Alive(t))(5)Alive(1) Loaded (1) Occ(Shoot )(3)(6)Thus preconditions Shoot event gun loaded victim alive(Axiom (4)), effect (if successful) victim alive (Axiom (5)).model time point t, let M/t denote set object occurs literalstemporal index true , let (t) = M/t \ M/t1.14 M/tthought history represented (and including) t. And,t, (t) thought representing known present moment,evidential context predictions t+1 based. also thinkdynamic conjectural context t, consists set success inertiaassumptions correspond expectations t+1. Assumptions addedconjectural context consistent current context (the unionevidential context current conjectural context) background theory (the lawsgiven event theory).generation preferred1 model, , 1 proceed follows:M/1 = {Alive(1), Loaded (1)} ,M/2 = M/1 {Alive(2), Loaded (2)} ,M/3 = M/2 {Alive(3), Loaded (3), Occ(Shoot )(3)} ,M/4 = M/3 {Alive(4), Loaded (4)} ,M/5 = M/4 {Alive(5), Loaded (5)} , . . . .Thus atoms M/1, evidential context (1),required boundary conditions 1 , stated Axiom (6).restriction evidential context (Ockhams razor) appropriate predictionbased available evidence. Now, Alive declaredtheoretical relation 1 , notational convention, Phys(Alive) true .consistent current context (1) (given background theory 1 \{(6)})assume Inert(Alive)(1), assumption added conjectural context.Consequently Alive(2) (2) inertia axiom (Axiom (3)). SimilarlyPhys(Loaded ) true , consistent current context (1){Inert(Alive)(1)} assume Inert(Loaded )(1), assumption addedconjectural context. inertia, Loaded (2) (2). And, accordance14. usual, literal either atom, , negation, .374fiNatural EventsOckhams razor, atoms (2). analogous reasoning beginningcurrent context (2) , Alive(3) Loaded (3) (3),remaining boundary condition Occ(Shoot )(3). And, Ockhams razor, atoms(3). Now, current context (3) consistent assume eitherSucc(Shoot )(3) Inert(Alive)(3). However cannot assumed; were,would follow axioms change ((1) (5)) inertia Alive(4)Alive(4) would (4). keeping principle change preferred inertia,Succ(Shoot )(3) assumed added conjectural context, Alive(4)(4). consistent current context (3){Succ(Shoot )(3)} assumeInert(Loaded )(4), inertia, Loaded (4) (4). And, Ockhams razor,atoms (4). remainder M/ generatedrepeated applications inertia axiom Ockhams razor.example suggests event theories interpreted chronologically.fits naturally experience times arrow; asymmetry past(which fixed) future (which open, yet exist). particular,understanding events terms dependable regularities sequence foundedasymmetry. example also suggests successive time point (at newpresent moment) first fix evidential context generate appropriateconjectural context. evolving context background theory produceexpected changes persistences. Fixing evidential context consists minimizing it;is, restricting object event literals required boundaryconditions earlier interpretation theory. Generating conjectural contextconsists maximizing success inertia assumptions (that is, assumingsuggested evidential context consistent current contextbackground theory) giving priority former case conflict. definitionpreferred1 model event theory thus reflect prioritized chronologicalminimaximization involved intended interpretation.begin defining preference relation 1 . definition (and subsequentdefinition 2 ) fewer understood terms set inclusion rathercardinality.15 keeping discussion, let evidential atom eitherobject atom event atom success atom, let conjectural atomeither success atom inertia atom.Definition 8 (Preference1 ) Let models differ interpretation temporally-indexed relations. preferred1 (written 1 )16iff time point agree t, t:1. fewer evidential atoms defined , agree truth valuesevidential atoms defined ;2. differ conjectural atoms, success atoms true ;15. Thus At(T, v, t, ) = { : atom type truth value v time model },fewer atoms type truth value v time model model At(T, v, t, )At(T, v, t, ). Similarly, replacing , case more.16. way writing preferences based comparison evidential contexts.375fiBell3. differ inertia atoms, inertia atoms true .example, suppose models differ temporallyindexed relations. (1) agree time 2 disagreeOcc(Shoot )(2) undefined true , preferred1 clause 1definition. (2) agree time 3 disagreeSucc(Shoot )(3) true false , preferred1 clause 2definition. (3) agree time 3 disagree Succ(Shoot )(3)Inert(Alive)(3) true whereas Succ(Shoot )(3) Inert(Alive)(3) true, preferred1 clause 2 definition. (4) agreetime 2 disagree Inert(Alive)(2) true false ,preferred1 clause 3 definition.preferred1 models event theory thus obtained focussingclass Phys-maximal models selecting 1 -minimal modelsit. Accordingly, definition preferred1 models event theory definitionpredictions based instances following generic definitions.Definition 9 (Preferred Models, Prediction) model said preferredimodel event theory Phys-maximal model modelpreferred (which ). event theorysentence, predictsi (written |i ) iff preferred models alsomodels .keeping discussion introduction, definition prediction cautious.clearer picture emerges consider preferredi models given event theoryabstract level.Definition 10 (Equivalence, Determinism, Representative Preferred Model) Letevent theory, let preferred models .said preferencei equivalent (written ) agree interpretationevidential conjectural atoms.17 event theory deterministicisingle -equivalence class, non-deterministici otherwise. representative member-equivalence class called representative preferredi model .-equivalence class preferredi models event theory represents possiblehistory defined theory. deterministici theories define single possiblehistory, predictions safely based it. However, non-deterministici theoriesdefine one possible history, caution dictates predictionsrestricted sentences true possible historiesdefine.18 representative preferredi models event theory provide concrete waythinking possible histories.return (inductive version the) Yale Shooting Problem.17. two models may differ interpretation terms, truth values atomsconsidered definition preferencei .18. possible define risky notion prediction based single -equivalence class c event theory. Thus | ci iff true models c. relation used obtain informationparticular possible history, serve basis reliable prediction non-deterministicitheories take other, equally possible, histories account.376fiNatural EventsExample 1 before, let 1 = Ind {(4), (5), (6)}. 1 deterministic 1 .evidential literals true representative preferred 1 model agreeset M/ discussed earlier. Thus 1 predicts 1 Shoot event succeeds time 3,effect Fred alive time 4.Proposition 1 |1 Succ(Shoot )(3) Alive(4).Proof Definition 9, sufficient prove conclusion follows preferred 1models 1 . So, let preferred 1 model 1 . Then, Definition 9, Phys(Alive)Phys(Loaded ) true .19 Axiom (6), Alive(1) Loaded (1) true. Definition 8.3, Inert(Alive)(1) true .20 follows Axiom (3)Alive(2) true . similar reasoning, Inert(Loaded )(1) Loaded (2) alsotrue (Axiom (3), Definition 8.3). Alive(2) true , follows inertia(Axiom (3), Definition 8.3) Alive(3) true . Similarly, Loaded (2) true, follows inertia Loaded (3) true . So, Axiom (4), Pre(Shoot )(3)true . Axiom (6), occurs atom Occ(Shoot )(3) true . Definition 8.2,Succ(Shoot )(3) true . follows, Axiom (1), Eff(Shoot )(4) true ,so, Axiom (5), Alive(4) true .Yale Shooting Problem interest because, Hanks McDermott (1987)show, poses problems theories take account times arrow. examplesuggests reasoning inertia chronological. related example involvingreasoning change suggested Lifschitz (1987, p. 37). point exampleillustrated adding second shot Yale Shooting Problem. Let 1 =1 {Occ(Shoot )(4)}. expect that, before, first shot succeedsecond shot fail (because Fred longer alive second shot occurs).And, indeed, transpires preferred1 models 1 . However, 1interpreted chronologically, would preferred models secondshot succeeds first shot fails; success second shot requires Fredalive time 4.inductive version Yale Shooting Problem considered (in Shootevent treated inductively rather deductively) also illustrates need give prioritychange (Succ assumptions) inertia (Inert assumptions) case conflict. Without19. preferred1 model 1 follows Definition 9 Phys-maximal model 1 . So,Phys(Alive) true , would model 1 Phys(Alive)Phys atoms true true. would Phys-maximal model1 , contradicting assumption is. analogous argument justifies subsequent appealsDefinition 9 regarding relation Phys.20. Inert(Alive)(1) true , would model 1 Inert(Alive)(1)true therefore preferred1 basis clause 3 Definition 8 time 1.(M would disagree interpretation temporally-indexed relations,would agree interpretation temporally-indexed relations time points time 1,would agree interpretation evidential success atoms time 1,inertia atoms temporal index 1 (all true together Inert(Alive)(1))would true.) would follow Definition 9 would preferred1 model 1 ,contradicting assumption is. analogous argument justifies subsequent appealsclause n definition preferencei regarding truth value atom temporal index t.377fiBellrequirement would preferred models 1 Inert(Alive)(3) trueSucc(Shoot )(3) false, so, contrary expectation, Fred remains alive time 4.subsequent examples often assumed different names (whether constantsfunctional expressions) denote different individuals. order enforce convention,uniqueness names axioms (Lifschitz, 1987, p. 50) used. Let f1 , . . . , fn functionsreturning values sort, let x1 , . . . , y1 , . . . variables appropriate sorts.U [f1 , . . . , fn ] conjunction axioms set:{x1 , . . . , xk , y1 , . . . , yl fi (x1 , . . . , xk ) = fj (y1 , . . . , yl ) : 1 < j n}{x1 , . . . , xk , y1 , . . . , yk (fi (x1 , . . . , xk ) = fi (y1 , . . . , yk ) (x1 = y1 . . . xk = yk )) :1 n} .axioms express fact functions f1 , . . . , fn injections differentranges. notation extended constants treating 0-ary functions. Thus,example, given U [A, B, L1, L2] U [Move], follows constants A, B, etc., denotedifferent objects, functional expressions Move(A, L1, L2) Move(B, L1, L2)denote different events.next example illustrates need restrict inertia axiom physical relations.Example 2 Block B moved location L1 location L2. expect L1clear result. example represented follows:x, l, l , t(Pre(Move(x, l, l ))(t) At(x, l)(t))(7)x, l, l , t(Eff(Move(x, l, l ))(t) (At(x, l )(t) At(x, l)(t)))(8)l, t(Clear(l)(t) TxAt(x, l)(t))(9)Theo(Clear)(10)U [B, L1, L2] At(B, L1)(1) Occ(M ove(B, L1, L2))(1)(11)Axioms (7) (8) define preconditions effects move events. Axiom (9) defineslocation clear true exists block location. usetruth operator definition allows fact relation may partial;location considered clear none blocks whose locations definedlocation. Axiom (10) declares Clear theoretical relation. Finally, Axiom (11)states boundary conditions.Let 2 = Ind {(7), . . . , (11)}. 2 single representative preferred 1 modelClear(L1)(2) true; because, model, move event succeeds, thereby vacatingL1, object replaces B L1. However, non-replacement L1 dependsfact Clear theoretical relation, exempt law inertia.2 = 2 \ {(10)}, every preferred 1 model 2 object mysteriously replaces BL1.Proposition 2 |1 Clear(L1)(2), 2 |1 Clear(L1)(2).Proof first part, let preferred 1 model 2 . Then, axioms (7) (11),At(B, L1)(1), Pre(Move(B, L1, L2))(1), Occ(Move(B, L1, L2))(1) true .378fiNatural EventsDefinition 8.2, Succ(Move(B, L1, L2))(1) true . follows, axioms (1)(8) At(B, L2)(2) At(B, L1)(2) true . At(B, L1)(1) true ,follows Axiom (9) Clear(L1)(1) true . Axiom (10) Theo(Clear)true so, Axiom (2), Phys(Clear) true . follows Axiom (3)Inert(Clear, hL1i)(1) true (consequently Clear(L1)(2) longer trueinertia). Definition 8.1 follows that, x B, At(x, L1)(2) undefined. So, At(B, L1)(2) true , follows x, TxAt(x, L1)(2)true . follows Axiom (9) Clear(L1)(2) true .second part, let preferred 1 model 2 . Then, before, atomsAt(B, L1)(1), Clear(L1)(1), Succ(Move(B, L1, L2))(1), At(B, L2)(2) At(B, L1)(2)true . However (in absence Axiom (10)) follows Definition 9Phys(Clear) true . Definition 8.3, Inert(Clear, hL1i)(1) true .follows Axiom (3) Clear(L1)(2) true .restriction inertia axiom justified terms physical-theoreticaldistinction follows. law inertia law physical inertia; task representpersistence physical facts changed events. Applyingtheoretical relations (as 2 ) results mysterious consequences; arisemaintaining inertia theoretical fact (Clear(L1)) introduces additional realchange physical fact (a change relation). Moreover, theoretical factssupervene physical facts, changes (persistences) theoretical facts supervene changes(persistences) physical facts. sufficient represent changes (persistences)physical facts, let changes (persistences) theoretical facts take care themselves.done case 2 , change relation results changeClear relation. complex examples, several blocks may movedlocation simultaneously, move event may may succeed. cases,axioms change inertia represent changes persistences relation,changes (persistences) Clear relation take care new factsfixed; real changes occurred dust settled.2121. Another, artificial, example involves interaction Goodmans (1954, p. III.4) predicateGrue common sense inertia. Call object grue green time time 2blue thereafter. suppose object green time 1 dont know eventsoccur time 1 affect O. seems natural conclude inertia greentime 2. However, green time 1, also grue time 1, equally reasonable predictgrue (that is, blue) time 2. example represented formally theoryG , consists Ind together following axioms:x, t(Grue(x)(t) ((t < 2 Green (x)(t)) (t 2 Blue(x)(t)))) ,x, t(Green(x)(t) Blue(x)(t)) ,Green(O)(1) .intended preferred1 models G Green(O)(2) true, unintended preferred1models G Blue(O)(2) true. problem solved declaring Gruetheoretical predicate (in keeping Goodmans doctrine entrenchment Quines advocationsimilarity), projected law inertia.379fiBell4. Primary Secondary Eventstheory inductive events provides basis integrated solution qualification problem frame problem. intended interpretation success axiom,events are, given preconditions, normally sufficient effects. intendedinterpretation inertia axiom, physical facts affected events persist.However, whereas effects successful inductive events certain invariable,effects natural events may uncertain they, least, may varyaccording context events occur.may seem context-dependent effects, ramifications, representeddomain axioms. However, following example, based Lifschitzs (1990) lampcircuit example Bakers (1991) ice-cream example, shows approachsimplistic.Example 3 Ollie location L1, holding block B, moves location L2.expect that, result, Ollie reach L2. Moreover, Ollie holding blockmoves, expect move L2.may seem example represented event theory 3 = Ind{(12), . . . , (16)}; where:x, l, l , t(Pre(Move(x, l, l ))(t) At(x, l)(t))(12)x, l, l , t(Eff(Move(x, l, l ))(t) At(x, l )(t))(13)x, l, l , t((At(x, l)(t) l = l ) At(x, l )(t))(14)x, y, l, t((At(x, l)(t) Holding(x, y)(t)) At(y, l)(t))(15)U [O, B, L1, L2]At(O, L1)(1) Holding (O, B)(1) Occ(M ove(O, L1, L2))(1)(16)Thus effects Move simplified. fact moved object longerinferred Axiom (14), states object twodifferent locations simultaneously, together appropriate inequality. intentionuse Axiom (15) infer Ollies movement results movement block B. For,given Ollie holding B gets L2, follows axiom B L2also; so, axioms (14) (16), B L1.However, two representative preferred 1 models 3 , partiallydescribed follows:M1 {At(O, L2)(2), Holding (O, B)(2), At(B, L2)(2)} ,M2 {At(O, L2)(2), At(B, L1)(2)} .change preferred inertia, Ollie succeeds moving L2 models. M1 ,fact Ollie holding B inert, follows block movesL2 expected. M2 , fact B L1 inert, so, contrary expectation, Bremains L1.One reaction failure seek strengthen axioms Axiom (15) makingcausally directed, interpreted causally (positively, M1 ),380fiNatural Eventsrather declaratively (positively M1 , contrapositively M2 ). Howeverseems response (which discussed Section 7) mistakenmisdiagnoses problem; taking logical problem rather representationalone.Let us consider problem posed example afresh. theory 3 tworepresentative preferred models one corresponds expectation.accounts asymmetry expectation, formal symmetrybroken?intended positive interpretation Axiom (15) depends appropriate reasoninginertia, particular appropriate use inertia axiom; necessaryconclude Ollie keeps hold block, rather concluding remains L1.seems odd using inertia axiom reasoning change; usinginertia axiom (together Axiom (15)) get block move withoutevent causes move. violating fundamental intuitionunderlies fact-event distinction; events causesphysical change.consideration provides key correct understanding problem.expect block move Ollie told holdingblock moves told releases it. Consequently discountpossibility block remaining L1 additional event would requiredorder account this. However movement block additional eventadditional effect block L2. missing, symmetry-breaking,causal element example thus event, choice move eventrelease event seems clear. note blocks moving differs Ollies moving.block moves Ollie moves holdingso.order reflect difference, distinction drawn primary secondaryevents. Primary secondary events inductive events kindconsidering far. However primary events occur independently, secondary eventsinvoked (in non-mystical Computer Science sense one program (procedure,process, . . . ) said invoke another) events, causally dependentsense secondary event succeed invoked invokedsuccessful event.22 Given distinction, ramifications represented invokingappropriate secondary events appropriate contexts. Thus, Example 3, Ollies movingrepresented primary event which, holding block B moves,invokes secondary move-B event. move-B event occurs invoked,succeeds move-Ollie event does. Note secondary events may, turn,invoke events causally dependent them. instance, currentexample block B placed top block B, invoked move-B event turninvoke move-B event. thus tertiary events, events ever higher order.22. condition perhaps called success dependence effect dependence order distinguish counterfactual dependence (Lewis, 1986, Ch. 21).381fiBellTable 3: theory invocation, Inve, e , t(Inv1 (e, e )(t) (Occ(e)(t) Occ(e )(t)))(17)e, t((Succ(e)(t) e Inv1 (e , e)(t)) e (Inv1 (e , e)(t) Succ(e )(t)))(18)e, e , t(Inv(e, e )(t) (Inv1 (e, e )(t) e (Inv1 (e, e )(t) Inv(e , e )(t))))(19)e, TInv(e, e)(t)(20)However, sake convenience, invoked events referred secondaryevents.23Invocations represented EL invocation atoms. invocation atom eventatom form Inv1 (e, e )(t), states event e directly invokes event e time t.Secondary events typically invoked invocation axioms form:e, e , t((Occ(e)(t) ) Inv1 (e, e )(t)) ;formula distinguishes contexts e invokes e . propertiessecondary events stated axioms (17)-(20) given Table 3. Axiom (17) requiresinvoking invoked events occur. Axiom (18) represents (causal) dependence,states secondary event succeeds one events invokedsucceeds. axiom stated way order allow cases secondaryevent invoked one event. Axioms (19) (20) ensure invocationacyclic. achieved defining auxiliary (indirect invocation) relation Invtransitive closure (direct invocation) relation Inv1 (Axiom (19)) requiringInv irreflexive (Axiom (20)).24Events invoke others thought two ways: elementary inductiveevents, complex events causal structure. invocation graph23. Primary secondary events called loose analogy philosophical distinctionprimary secondary qualities. Primary qualities (such size, shape motion) fundamentalqualities used science. contrast, secondary qualities sensory qualities (such colour, taste,smell, felt warmth texture, sound) exist certain contexts (to individual observersspecific conditions) causally dependent primary qualities. Similarly, tertiaryqualities qualities object virtue secondary qualities; example flowermay attractive butterfly colour, wine may expensive taste(Blackburne, 1994).24. axiomatization secondary events intended minimal. example, prohibitionevent occurring primary event secondary event. happen,would follow Axiom (18) event would secondary status. certain circumstancesmay desirable define order event, require event exactly one order.done adding axioms following:e, t(Ord(e, n)(t) ((n = 1 Occ(e)(t) Te Inv1 (e , e)(t))(n > 1 e (Ord(e , n1)(t) Inv1 (e , e)(t))))) ,e, n, m, t((Ord(e, n)(t) n = m) TOrd(e, m)(t)) .382fiNatural Eventsevent e (at time point t) directed acyclic graph whose initial vertex e, whoseremaining vertices events invoked e (either directly indirectly), whose edgesrepresent direct invocation relation. Event es success graph (at t) subgraphes invocation graph consists chains invocation graph begine consist entirely successful events. direct effects e defined(invariant) effects. indirect effects e effects events successsubgraph. So, particular, successful inductive events thoughteffects successful secondary events invoke (either directly indirectly).Thus, working example, move-Ollie event direct effect moves,thought indirect context-dependent effects B B movehim. Note effects event may context-dependent two ways.event may invoke different events different contexts (recall invocation axioms maycontext-dependent), invocation graph may vary according contextoccurs. Moreover, invocation graph may result different success graphscontext varies ways. instance, working example, move-B mayinvoked two different contexts (in B B), succeed one (theone contemplating) fail another (say B also heldanother agent).Definition 11 theory invocation, Inv , consists axioms given Table 3;thus Inv = {(17), . . . , (20)}.invocation atoms event atoms, pragmatics given last sectionused without change.give formal version extension block-carrying example.Example 4 Ollie location L1. holding block B1, block B2 stacked B1,block B3 stacked B2. Ollie moves location L2. expect move eventsucceed stack blocks move him. However if, independentreason, B2 move, expect B3 also remain L1.first part example represented event theory 4 = Ind Inv{(12), . . . , (15)} {(21), . . . , (24)}, where:x, y, l, t((On(x, y)(t) At(y, l)(t)) At(x, l)(t))(21)x, y, l, l , t((Occ(Move(x, l, l ))(t) Holding (x, y)(t))Inv1 (Move(x, l, l ), Move(y, l, l ))(t))(22)x, y, l, l , t((Occ(Move(x, l, l ))(t) On(y, x)(t))Inv1 (Move(x, l, l ), Move(y, l, l ))(t))(23)U [O, B1, B2, L1, L2] U [Move] At(O, L1)(1) Holding (O, B1)(1)On(B2, B1)(1) On(B3, B2)(1) Occ(M ove(O, L1, L2))(1)(24)Axiom (21) states object x object x location is,axioms (22) (23) invocation axioms representing ramifications. Axiom (22) statesmove-x event invokes move-y event contexts x holding y. Similarly,383fiBellAxiom (23) states move-x event invokes move-y event contextsx.single representative preferred 1 model 4 , Ollies movementsuccessfully invokes movement B1 (because Ollie holding B1 moves),turn successfully invokes movement B2 (because B2 B1 B1 moves),turn successfully invokes movement B3 (because B3 B2 B2moves). Thus, accordance expectation, 4 predicts Ollie succeeds movingL2 entire stack blocks. Note success invoked event dependssuccess event invoked it. Thus, example, 4 extended B2remains L1, extended theory predicts B3 also remains L1.Proposition 4 |1 At(B3, L2)(2), 4 {At(B2, L1)(2)} | 1 At(B3, L1)(2).Proof first part, let preferred 1 model 4 . Occ(Move(O, L1, L2))(1)Holding(O, B1)(1) true (Axiom (24)). follows (axioms (17), (22))Inv1 (Move(O, L1, L2), Move (B1, L1, L2))(1) Occ(Move(B1, L1, L2))(1) true. So, On(B2, B1)(1) true (Axiom (24)), follows (axioms (17), (23)),Inv1 (Move(B1, L1, L2), Move (B2, L1, L2))(1) Occ(Move(B2, L1, L2))(1) true. so, On(B3, B2)(1) true (Axiom (24)), follows (axioms (17),(23)) Inv1 (Move(B2, L1, L2), Move (B3, L1, L2))(1) Occ(Move(B3, L1, L2)(1)true . invocation atoms temporal index 1 defined (Definition 8.1), four events Move(O, L1, L2), Move(B1, L1, L2), Move(B2, L1, L2),Move(B3, L1, L2), occur time 1 , linked chain invocationstime 1 .25 Moreover, preconditions four events true (axioms (12), (15), (21), (24)). Move(O, L1, L2) primary event time 1, follows (Definition 8.2) Succ(Move(O, L1, L2))(1) true . Moreover,Move(B1, L1, L2) directly invoked successful event time 1 , follows (Definition 8.2) Succ(Move(B1, L1, L2))(1) true . Similar reasoning shows successpropagated rest invocation chain; that, turn, Succ(Move(B2, L1, L2))(1)hence Succ(Move(B3, L1, L2))(1) true . So, Succ(Move(B3, L1, L2))(1)true , follows (axioms (1), (13)) At(B3, L2)(2) true .second part, let preferred 1 model 4 = 4 {At(B2, L1)(2)}.Then, above, events Move(O, L1, L2), Move(B1, L1, L2), Move(B2, L1, L2),Move(B3, L1, L2) occur time 1 , preconditions true time 1, linked unique invocation chain time 1 . above,first two events chain succeed. However, model 4 , At(B2, L1)(2)true . follows (axioms (14), (24)) At(B2, L2)(2) true . therefore follows (axioms (1) (13)) Succ(Move(B2, L1, L2))(1) true . So,Move(B2, L1, L2) event directly invokes Move(B3, L1, L2) time 1, follows Te(Inv1 (e, Move(B3, L1, L2))(1) Succ(e)(1)) true .T(Succ(Move(B3, L1, L2))(1) e Inv1 (e, Move(B3, L1, L2))(1)) true (Axiom (18)). Inv1 (Move(B2, L1, L2), Move (B3, L1, L2))(1) true Succ25. unique-names axiom Move Axiom (24) ensures events distinct. viewaxioms (19) (20) appeal unique-names axiom strictly necessary. However,subsequent examples involving multiple events simpler add unique-names axiomsevents, assume proofs distinct event terms denote distinct events.384fiNatural Eventsrelation classical (Axiom (1)), follows Succ(Move(B3, L1, L2))(1) true .However, Phys(At) At(B3, L1)(1) true (axioms (15), (21), (24), Definition 9), follows inertia (Axiom (3), Definition 8.3) At(B3, L1)(2) trueM.Note introduction secondary events missing causal elementsexample, inertia axiom domain axioms ((14), (15) (21)) confinedproper tasks; namely, representing inertia, defining constraining relationrespectively.philosophical terms, invocations provide means representing contemporaneoussufficient causation events. Thus event e directly invokes event e time t,e sufficient cause e t. direct invocation relation, Inv1 , thus representscausal directedness (causal priority) contemporaneous events. Axioms (17)(18) respectively ensure contemporaneous causation occurs actual events,invoked event efficacious invoked efficacious event. accountcontemporaneous sufficient causation thought terms regularities, howeverreasoning complex; example, might discover event e directlyinvokes event e noting whenever e occurs condition true e also occurs,whenever case e succeeds e does.Contemporaneous (sufficient) causation events naturally required asymmetric (axioms (19) (20)). However, suggested also casessymmetric contemporaneous causation events. Taylor (1975) gives examplelocomotive caboose coupled together way locomotivemoves iff caboose does. analogous example, suggested Denecker, Dupre,Belleghem (1998), involves pair gears interlocked, gear rotatesiff does.become clear, better view cases involving symmetric constraintscontemporaneous events, rather symmetric causation them. Now, clearly,symmetric constraints cannot represented invocations.26 However, represented individual basis adding particular axioms. example, symmetricconstraint rotation gears represented following axiom:g, g , t(Intl (g, g )(t) ((Occ(Rot (g))(t) Occ(Rot (g ))(t))(Succ(Rot (g))(t) Succ(Rot (g ))(t)))) .first conjunct consequent axiom required order ensurerotations pairs interlocked gears co-occur; without it, would possible onerotate events occur fail without occurring. Note also that,introducing problem, Denecker et al. (1998, p. 34) require representationbehaviour interlocked gears rotate spontaneously.present problem theories based classical logic; semantics26. attempt case gears would use following axiom:g, g , t((Occ(Rot (g))(t) Intl (g, g )(t)) Inv1 (Rot (g), Rot (g ))(t)) .clearly Intl(g, g )(t), Intl(g , g)(t) Occ(e)(t) hold, contradiction resultsaxiom axioms (17), (19) (20).385fiBellTable 4: theory symmetrically constrained events, SCone, TSCon(e, e)(t)(25)e, e , t(SCon(e, e )(t) SCon(e , e)(t))(26)e, e , t(SCon(e, e )(t) ((Occ(e)(t) Occ(e )(t)) (Succ(e)(t) Succ(e )(t)))) (27)e, e , t(SCSet(e, e )(t)(SCon(e, e )(t) e (SCon(e, e )(t) SCSet(e , e )(t))))(28)e, e , t(EInv(e, e )(t)(Inv1 (e, e )(t) e (SCSet(e , e )(t) TSCSet(e, e )(t)))) (29)e, e , n, t(IPath(e, e , n)(t)((n = 0 e = e e EInv(e , e)(t))(n > 0 e (IPath(e, e , n1)(t) SCon(e , e )(t))))) (30)e, e , t((SCon(e, e )(t)e , n(IPath(e , e, n)(t)e , m(IPath(e , e , m)(t) > n)) Inv1 (e, e )(t))) (31)classical biconditionals. However potential pitfall effortlessly avoided event theoriesaccurate representation partiality; Intl (g, g )(t) given,Occ(Rot (g))(t) Occ(Rot (g ))(t) undefined.general treatment symmetric constraints events given introducingsymmetric constraint relation SCon. relation represents co-occurrenceco-dependence pairs events. Accordingly expect SCon irreflexive,symmetric, hold pairs co-occurring events also co-dependent.properties stated axioms (25)-(27) Table 4.considered isolation, fact two events symmetrically constrainedprovides compelling evidence either cause other. example,gears case, know g g interlocked g rotating,reasonable conclude g also rotating, reasonable concluderotation g cause rotation g vice versa. Indeed, two events mayeven causally connected; gears might rotating shaftattached driven.However, additional, external, information direction causation,use infer direction causation pairs symmetrically constrained events.27 example, know gear g driven (say rotatingshaft attached to), dont know gear g driven,reasonable conclude driving g causally prior rotation g,rotation g turn causally prior rotation g . formally,Inv1 (Drive(g), Rot (g))(t) SCon(Rot (g), Rot (g ))(t), seems reasonable27. Taylor makes similar appeal external cause discussion locomotive-caboose example.386fiNatural Eventsconclude Inv1 (Rot (g), Rot (g ))(t). external invocation chain thus extendedacross symmetric constraint link. construction invocation chains kinddefined axioms (28)-(31) given Table 4.Axiom (28) states that, time t, events e e symmetrically constrained set iff symmetrically constrained occur chain symmetricconstrained events.Axiom (29) defines conditions external invocation symmetrically constrained event. Thus, time t, event e externally invokes event e iff e invokes e esymmetric constraint set include e.invocation path symmetrically constrained set begins externally invokedevent consists chain events symmetrically constrains neighbour.length invocation path determined number links contains;invocation path consisting externally invoked event length 0, oneconsisting event neighbour length 1, etc. Accordingly, Axiom (30)states conditions invocation path length n events ee .Finally, Axiom (31) defines invocation paths symmetrically constrained sets.requiring invocation link exist symmetrically constrained events ee whenever shortest invocation path e symmetrically constrained setshorter shortest invocation path e set.Definition 12 theory symmetric constraints, SCon , consists axioms givenTable 4; thus SCon = {(25), . . . , (31)}.ideas illustrated following elaboration gears example.Example 5 Five interlocking gears, G1 , . . . , G5 , arranged row. G1driven, invokes rotation G1 , and, hGi , Gi+1 pair, rotationGi invokes rotation Gi+1 . However G1 G5 driven, rotationinvokes rotation neighbour, and, turn, rotations invokesrotation G3 .first part example represented event theory 5 = Ind InvSCon {(32), . . . , (39)}, where:g, t(Pre(Drive(g))(t) Free(g)(t))(32)g, t(Eff(Drive(g))(t) Rotd (g)(t))(33)g, t(Pre(Rot (g))(t) Free(g)(t))(34)g, t(Eff(Rot (g))(t) Rotd (g)(t))(35)g, g , t(Intl (g, g )(t) Intl (g , g)(t))(36)g, t(Occ(Drive(g))(t) Inv1 (Drive(g), Rot (g))(t))g, g , t(Intl (g, g )(t) SCon(Rot (g), Rot (g ))(t))(37)(38)U [G1 , . . . , G5 ] U [Drive, Rot ]5^i=1Free(Gi )(1)4^Intl (Gi , Gi+1 )(1) Occ(Drive(G1 ))(1)i=1387(39)fiBellsake simplicity preconditions effects drive eventsrotate events objects assumed gears. Thus gear driven(can rotate) free so, effect driven (rotating)rotated (in direction degree are, simplicity, represented).Axiom (36) states Intl relation (which represents pairs interlocked gears)symmetric. Axiom (37) states drive-g event invokes rotate-g event, Axiom (38)states gears g g interlocked, rotation symmetrically constrained.theory 5 single representative preferred 1 model five gears rotate single invocation chain hDrive(G1 ), Rot (G1 ), Rot (G2 ), Rot (G3 ),Rot (G4 ), Rot (G5 )i.Moreover, extended theory 5 {Occ(Drive(G5 ))(1)}, single preferred 1 modelfive gears rotate, two invocation chains; hDrive(G1 ),Rot (G1 ), Rot (G2 ), Rot (G3 )i hDrive(G5 ), Rot (G5 ), Rot (G4 ), Rot (G3 )i.Proposition 5 |1 Succ(Rot (Gi ))(1) 1 5, 5 |1 Inv(Rot (G1 ), Rot (G5 ))(1).Moreover, 5 = 5 {Occ(Drive(G5 ))(1)}, 5 |1 Succ(Rot (Gi ))(1) 1 5,5 |1 Inv(Rot (G1 ), Rot (G3 ))(1) 5 |1 Inv(Rot (G5 ), Rot (G3 ))(1).Proof Let preferred 1 model 5 . follows, axioms (17), (37)(39), Occ(Drive(G1 ))(1), Inv1 (Drive(G1 ), Rot (G1 ))(1), Occ(Rot (G1 ))(1) true. Axiom (39), Intl (G1 , G2 )(1) true , follows Axiom (38)SCon(Rot (G1 ), Rot (G2 ))(1) true . follows, axioms (26) (27),SCon(Rot (G2 ), Rot (G1 ))(1) Occ(Rot (G2 ))(1) true . Similar reasoning shows1 4, SCon(Rot (Gi ), Rot (Gi+1 ))(1) SCon(Rot (Gi+1 ),Rot (Gi ))(1) true , that, 1 5, Occ(Gi )(1) true .axioms (32), (34) (39), Pre(Drive(G1 ))(1) true , Pre(Rot (Gi ))(1)1 5. Definition 8.2, Succ(Drive(G1 ))(1) true ,Succ(Rot (Gi ))(1) 1 5.Axiom (28), set SI = {Rot (Gi ) : 1 5} symmetric constraint settime 1 , Definition 8.1 set. follows Axiom (29)EInv(Drive(G1 ), Rot (G1 ))(1) true . Moreover follows, Definition 8.1Axiom (29), Rot (G1 ) initially invoked event SI. followsAxiom (30) hRot (G1 ), Rot (G1 )i influence path length 0 SI,shortest influence path G2 SI hRot (G1 ), Rot (G2 )i length 1. followsAxiom (31) Inv1 (Rot (G1 ), Rot (G2 ))(1) true . analogous reasoning,shortest influence path G3 SI path hRot (G1 ), Rot (G2 ), Rot (G3 )ilength 2, Inv1 (Rot (G2 ), Rot (G3 ))(1) true . Similar reasoning showsInv1 (Rot (G3 ), Rot (G4 ))(1) Inv1 (Rot (G4 ), Rot (G5 ))(1) true . followsAxiom (19) Inv(Rot (G1 ), Rot (G5 ))(1) true .let preferred 1 model 5 . reasoning analogous given above,Succ(Drive(G1 ))(1) true , Succ(Rot (Gi ))(1) 1 5. alsoSI = {Rot (Gi ) : 1 5} symmetric constraint set time 1. However time Rot (G1 ) Rot (G5 ) initially invoked events SI.shortest influence path G2 SI path hRot (G1 ), Rot (G2 )i length 1,so, before, Inv1 (Rot (G1 ), Rot (G2 ))(1) true . Analogous reasoning shows388fiNatural EventshRot (G5 ), Rot (G5 )i influence path SI length 0 shortest influence pathG4 SI path hRot (G5 ), Rot (G4 )i length 1, Inv1 (Rot (G5 ), Rot (G4 ))(1)true . Moreover, shortest influence paths Rot (G3 ) SI pathshRot (G1 ), Rot (G2 ), Rot (G3 )i hRot (G5 ), Rot (G4 ), Rot (G3 )i, length 2. follows Axiom (31) Inv1 (Rot (G2 ), Rot (G3 ))(1) Inv1 (Rot (G4 ), Rot (G3 ))(1) true. Thus Axiom (19), Inv(Rot (G1 ), Rot (G3 ))(1) Inv(Rot (G5 ), Rot (G3 ))(1)true .Secondary events also used represent non-deterministic effects.Non-deterministic effects may arise uncertainty preconditions. Suppose, example, initial positions blocks B B uncertain, either BB conversely, B moved. Intuitively resulting location Buncertain. B B, B moved location B, otherwiseB remained was. easy see Example 4 adaptedrepresent example faithfully. B B initially, move-B event invokessecondary move-B event (Axiom (23)) results B moving B, otherwiselocation B remains unchanged. resulting theory thus two representativepreferred1 models; one B moves, one B move.non-deterministic effects may also arise outcome events questionuncertain. successful, non-deterministic event regularly followed definiteeffect, rather one set mutually exclusive possible effects; classicexample tossing fair coin. terms used introduction, expectationsregarding outcome events unclear. order see secondary eventsneeded represent these, consider following attempt represent coin-tossing.Example 6 Suppose fair coin showing heads initially coin tossed.coin fair, result uncertain; coin may show heads may showtails. Let 6 = Ind {(40), (41), (42)} where:t(Pre(Toss)(t) (Heads(t) Tails(t)))(40)t(Eff(Toss)(t) (Heads(t) Tails(t)))(41)Heads(1) Tails(1) Occ(Toss)(1)(42)Then, contrary intention, 6 deterministic 1 . 6 single representative preferred 1model Toss event succeeds effect Heads(2) Tails(2) true. However,Heads(1) true model, normal application inertia axiom removesuncertainty determining Heads(2) true.If, example, one alternative effects event preserves statusquo, inertia favour outcome determine outcome event.fact inertia intervenes way example suggests something missingrepresentation toss event. defined, eventintended do. succeeding ensure two distinct outcomes.Metaphorically speaking, introduce fork point history, resultingtwo alternative futures. seems hidden causal element accountsintuitive understanding example missing formalization it.389fiBellsuggest missing component causal structure toss event,faithfully represented two conflicting secondary events; tossing coininvokes two conflicting deterministic events, one resulting coin showing heads,resulting coin showing tails.formalizing subsequent examples involving nondeterministic events,following abbreviation useful:Inv1 (e, {e1 , . . . , en })(t) =DfInv1 (e, e1 )(t) . . . Inv1 (e, en )(t) .Example 7 Let 7 = Ind Inv {(40), . . . , (46)} where:t(Pre(TossH )(t) Pre(Toss)(t)) t(Eff(TossH )(t) Heads(t))(43)t(Pre(TossT )(t) Pre(Toss)(t)) t(Eff(TossT )(t) Tails(t))(44)t(Occ(Toss)(t) Inv1 (Toss, {TossH , TossT })(t))(45)U [Toss, TossH , TossT ](46)two representative preferred 1 models 7 . models, primaryevent Toss succeeds invokes conflicting secondary events TossH TossT . onemodels, TossH succeeds TossT fails. model, TossT succeedsTossH fails.Proposition 7 |1 Heads(2) Tails(2), 7 |61 Heads(2), 7 |61 Tails(2).Proof first part, let preferred 1 model 7 . Toss event occurstime 1 (Axiom (42)) occurrence invokes secondary TossH TossTevents (Axiom (45)), also occur time 1 (Axiom (17)). preconditionsthree events true time 1 (axioms (40), (42)-(44)). However, vieweffects (axioms (41), (43), (44)), three events cannot succeed time 1 . Tossinvokes two events, event (Definition 8.1), TossHTossT succeed Toss (Axiom (18)). Moreover, consistent assumeToss succeed time 1 , follows (Definition 8.2) Toss succeedtime 1 , effect Heads(2) Tails(2) true (axioms (1), (41)).second part sufficient show preferred 1 model 7Heads(2) false. So, let EL model R Phys(R) true, satisfiesAxiom (46), satisfies following conditions. evidential atomsdefined satisfy following set literals:{Heads(1), Tails (1), Occ(Toss)(1), Inv1 (Toss, TossH )(1), Occ(TossH )(1),Inv1 (Toss, TossT )(1), Occ(TossT )(1)} {Tails(t) : 2} {Heads(t) : 2} ;thus, example, Heads(1) true Tails(1) false . success atomsset:{Succ(Toss)(1), Succ(TossT )(1)}true , every success atom false . Finally inertia atomsset:{Inert(Heads)(0), Inert(Tails)(0), Inert(Heads)(1), Inert(Tails)(1)}390fiNatural Eventsfalse , every inertia atom true . Clearly exists. Moreover,inspection shows preferred 1 model 7 . particular, success Tosstime 1 required (on grounds given proof first part) successeither TossH TossT time 1 (axioms (1), (41), (43), (44), Definition 8.2).given model, TossT succeeds time 1, combined effect two successfulevents Heads(2) false (axioms (1), (41), (44)).proof third part similar; TossH (rather TossT ) succeedingtime 1 given model.similar problem posed Russian Shooting Problem (Sandewall, 1994).revolver loaded single bullet cylinder spun. resultuncertain, cylinder could come rest bullet one six possiblepositions. However naive representation, inertia will, again, favour outcomebullet returns to, effectively remains in, original position. faithfulrepresentation expected outcome spin event obtained invokesix conflicting secondary spin events, result bullet equally likely comerest six possible positions.generally, non-deterministic event seen invoking set conflictingdeterministic events, resulting one possible outcomes.two possible outcomes, following general form exclusivealternation useful:1 | 2 | . . . | n =Dfn_m1^(m=1 i=1n^j ) .j=m+1Thus 1 | 2 | . . . | n true exactly one alternatives true remainderfalse, false alternatives false one true,undefined otherwise.28techniques representing ramifications non-deterministic events readilycombined represent events conditional effects, crossing pointsrailway line. Suppose point P entry point PE , left exit point PL, rightexit point PR. Suppose P set left, train crossing Pemerge PL, otherwise P set right, train emerge PR.preconditions crossing P simply train PE P seteither left right, effect train either PL PR. P setleft train crosses, event invoke cross-P -left event,precondition train PE P set left, effecttrain PL. Similarly, P set right train crosses, eventinvoke cross-P -right event effect train emerges PR.5. Event PreferencesConflicts reductio ad absurdum Deductionism. two events conflict,effects cannot, pain inconsistency, deduced. Consequently, Deductionists wishing28. So, n = 2, exclusive alternation exclusive disjunction. n > 2, two notionsdiffer; example, exclusive disjunction 1 (2 3 ) true 1 2 3 is.391fiBellrepresent simultaneous events forced police events regulateeffects. Gelfond, Lifschitz, Rabinov (1991) suggest done meanscancellations. Suppose, example, bowl full soup. one sidebowl lifted, soup spilt. However, sides bowl liftedsimultaneously, soup spilt. interactions represented meanstwo elementary lift events (lift-left-side, lift-right-side) composition (lift-bothsides). either elementary events occurs isolation, effectsoup spilt. complex event occurs, spill-effects component actionscancelled, result bowl lifted soup spilt.However cancellations appropriate ignore possibility failure. Supposereality one elementary lift events fails hand slips. effectscomponent event cancelled soup spilt.cancellation cancelled?Conflicts pose problem inductive events. faced conflicting events expect succeed. Some, possibly all,expectations regarding events uncertain. reflected formal theory:conflicting effects give rise conflicting success atoms, resulting failure rather inconsistency. However possibility failure raises problem over-weak predictions(which amusingly complements over-strong problem Deductionism). two inductive events conflict (and interactions involving them), succeedspreferred model fails, consequently nothing definitedisjunction effects predicted. appropriate events equalstatus; indeed, provides basis representation non-deterministic events givenprevious section. appropriate expect one eventssucceed. Suppose, example, Stan Ollie attempt move locationsimultaneously one succeed. Suppose Ollies successlikely Stans, say bigger. normally expect Olliesucceed Stan fail. However, abnormal independent circumstanceslead us expect Ollie fail, lead us expect Stanfail also. Indeed, circumstances, expect Stan succeed. example,Ollie trips, expect Stan succeed; although, course, may also trip,etc.Asymmetric expectations kind thought event preferences, preferences outcomes events. Thus events e e conflict, expecte succeed, success e preferred e . However, examplesshow, preferences kind defeasible order prejudice successnon-preferred event preferred event fail independent reason.Event preferences represented EL preference atoms, event atomsform Pref(e, e )(t). keeping discussion, interpretedstating success event e normally preferred event econflict time t. temporal index accommodates possibility event preferencesmay vary time; Example 10 below.logical restriction event preferences required asymmetric (Axiom (47) Table 2). conditions, transitivity, can, course,added appropriate.392fiNatural EventsTable 5: theory event preferences, Prefe, e , t(Pref(e, e )(t) TPref(e , e)(t))(47)Definition 13 theory event preferences given axioms Table 5; thusPref = {(47)}. theory natural events, NE , consists axioms given tables 2,3, 4, 5; thus NE = Ind Inv SCon Pref .intended interpretation event preferences cannot enforced adding axiom:e, e , t((Pref(e, e )(t) Pre(e)(t) Occ(e)(t) Succ(e )(t)) Succ(e)(t)) .Adding axiom would ensure e e conflict, e would succeed (ande would fail). However, e fail independent reason, axiomwould undesirable effect forcing failure e .Clearly, event preferences interpreted correctly, flexible approachneeded, necessary extend pragmatics event theories containthem. aim produce consistent interpretation applicable eventpreferences possible, ignore otherwise.begin with, distinction drawn preferential events, eventspreferences consistently applied, non-preferential events, remainingevents consideration. event e said supported model time eoccurs es preconditions true (if Pre(e)(t) Occ(e)(t) true). e supported time point model, time point modelclear context, e simply said supported. Now, applicableevent preferences form acyclic chain Pref(e, e )(t), Pref(e , e )(t), . . . , supportedevents occurring ordered lexicographically; thus given e, e esupported, e order 1, e order 2, e order 3. generally, modeltime point t, supported event e may (or may not) assigned preference rank follows:e preference rank 1 event e Pref(e, e )(t) truesupported event e Pref(e , e)(t) true,e preference rank n e preference rank < nsupported event e preference rank n 1 directly preferred e (whichPref(e , e)(t) true supported event epreferences Pref(e, e )(t) Pref(e , e )(t) true).Let e supported event (at time model ). e preferential event (at) e preference rank (at ), otherwise e non-preferential event (at timemodel ).suppose time models agree event preferences, preferentialevents, non-preferential events. Then, t:393fiBellbetter preferential events preference rank nagree success events preference rank < n,events preference rank n succeed ,good preferential events better preferentialevents, agree success preferential events,better non-preferential events non-preferential events succeed,good non-preferential events better nonpreferential events, agree success non-preferential events.definition preferred model refined.Definition 14 (Preference2 ) Let models differ interpretation temporally-indexed relations. preferred2 (written 2 )iff time point agree t, t:1. fewer evidential atoms defined , agree truth valuesevidential atoms defined ;2. differ conjectural atoms, either(a) better preferential events, good nonpreferential events;(b) good preferential events, better nonpreferential events;3. differ inertia atoms, inertia atoms true .Note preference2 reduces preference1 event theories include eventpreferences.Four examples given. first illustrates interpretation event preferences.Example 8 Suppose three agents, Stan, Ollie, Charlie, locations L1, L2L3 respectively. assumed one agents location pointtime, two attempt move location simultaneously,one succeed. Ollie Stan attempt move location L4 then,Ollie bigger, Ollies success expected. Similarly, Stan Charlie attemptmove L4 simultaneously, then, Stan bigger, Stans success expected. However,Charlie much faster Ollie, attempt move L4 simultaneously,Charlies success expected. Now, suppose fact Stan Ollie attemptmove L4 simultaneously, then, indicated, Ollies success expected. However,Charlie also attempts move L4, result uncertain preferencesamong move events longer interpreted consistently.394fiNatural EventsLet 8 = Ind Pref {(12), (13), (14)} {(48), . . . , (52)}; where:x, y, l, t((At(x, l)(t) x = y) At(y, l)(t))(48)Pref(Move(O, L1, L4), Move (S, L2, L4))(1)(49)Pref(Move(S, L2, L4), Move (C, L3, L4))(1)(50)Pref(Move(C, L3, L4), Move (O, L1, L4))(1)(51)U [O, S, C, L1, L2, L3, L4] U [Move]At(O, L1)(1) At(S, L2)(1) At(C, L3)(1)Occ(Move(O, L1, L4))(1) Occ(Move(S, L2, L4))(1)(52)8 single representative preferred 2 model Ollie succeeds movingL4. However extended theory 8 = 8 {Occ(Move(C, L3, L4))(1)} three representative preferred 2 models, different member trio succeeds them.Proposition 8 |2 At(O, L4)(2). However 8 |62 At(O, L4)(2), 8 |62 At(S, L4)(2),8 |62 At(C, L4)(2).Proof first part, let preferred 2 model 8 . (Definition 14.1)events occur time 1 Move(O, L1, L4) Move(S, L2, L4). followsaxioms (12) (52) events supported time 1 .view effects, one events succeed (axioms (1), (13), (48), (52)).axioms (49)-(51) Definition 14.1, preference atoms truePref(Move(O, L1, L4), Move (S, L2, L4))(1), Pref(Move(S, L2, L4), Move (C, L3, L4))(1),Pref(Move(C, L3, L4), Move (O, L1, L4))(1). view first these,event e Pref(Move(O, L1, L4), e)(1) true . And, Move(C, L3, L4)supported time 1 , supported event e Pref(e, Move(O, L1, L4))(1)true . Move(O, L1, L4) preference rank 1 time 1 . Moreover,Move(S, L2, L4) preference rank 1 time 1 , Move(O, L1, L4)supported event time 1 Pref(Move(O, L1, L4), Move (S, L2, L4))(1) true. So, Move(O, L1, L4) directly preferred Move(S, L2, L4) time 1 ,follows Move(S, L2, L4) preference rank 2 time 1 . therefore followsDefinition 14.2(a) Succ(Move(O, L1, L4))(1) true . Consequently effectAt(O, L4)(2) true (axioms (1), (13)).second part, let EL model R Phys(R) true,satisfies U [O, S, C, L1, L2, L3, L4] U [Move]. Suppose satisfies following conditions; Loc = {O, S, C, L1, L2, L3, L4}. object event atomsdefined satisfy following sets literals:{At(O, L1)(t) : 1}, {At(O, l)(t) : 1, l Loc, l 6= L1},{At(S, L2)(1)}, {At(S, L4)(t) : 2)},{At(S, l)(1) : l Loc, l 6= L2}, {At(S, l)(t) : 2, l Loc, l 6= L4},{At(C, L3)(t) : 1} {At(C, l)(t) : 1, l Loc, l 6= L3},{Occ(Move(O, L1, L4))(1), Occ(Move(S, L2, L4))(1), Occ(Move(C, L3, L4))(1)},395fiBell{Pref(Move(O, L1, L4), Move (S, L2, L4))(1),Pref(Move(S, L2, L4), Move (C, L3, L4))(1),Pref(Move(C, L3, L4), Move (O, L1, L4))(1)}.success atom Succ(Move(S, L2, L4))(1) true success atomsfalse . Finally, inertia atoms following sets false :{Inert(At, hO, li)(0) : l Loc}, {Inert(At, hC, li)(0) : l Loc},{Inert(At, hS, li)(0) : l Loc}, {Inert(At, hS, li)(1) : l {L2, L4}},inertia atoms true . Clearly exists. Moreover, inspection showspreferred 2 model 8 . particular, success Move(S, L2, L4) time 1justified follows. three events supported time 1Move(O, L1, L4), Move(S, L2, L4), Move(C, L3, L4) (axioms (12), (52), definition8 , Definition 14.1). preference atoms trueset given (axioms (49)-(51), Definition 14.1). none three supported eventspreference rank 1 time 1 ; Move(O, L1, L4) Move(C, L3, L4)supported preferred it, Move(S, L2, L4) Move(O, L1, L4)supported preferred it, Move(C, L3, L4) Move(S, L2, L4)supported preferred it. follows three events non-preferential time 1. one events succeed time 1 (axioms (1), (13), (48), (52)).follows Definition 14.2(b) one succeed. , Move(S, L2, L4)succeeds time 1, effect At(S, L4)(2) consequently At(O, L4)(2)true ((1), (13), (48), (52)).given model also establishes fourth part proposition. third partpreferred 2 model 8 given either Move(O, L1, L4) Move(C, L3, L4)succeeds time 1.next example shows event preferences secondary events combinedorder represent implicit cancellation implicit cancellation thereof.Example 9 soup-bowl example represented follows:t(Pre(LiftL)(t) HoldingL(t)) t(Eff(LiftL)(t) HoldingL(t))(53)t(Pre(LiftR)(t) HoldingR(t)) t(Eff(LiftR)(t) HoldingR(t))(54)t(Pre(Spill )(t) Spilt (t))(55)t(Eff(Spill )(t) (Spilt (t) (HoldingL(t) HoldingR(t))))(56)e, t((Occ(e)(t) (e = LiftL e = LiftR) Spilt(t)) Inv1 (e, Spill )(t))(57)t(Pre(Lift)(t) (Pre(LiftL)(t) Pre(LiftR)(t)))(58)t(Eff(Lift)(t) (Eff(LiftL)(t) Eff(LiftR)(t)))(59)t(Occ(Lift)(t) (Occ(LiftL)(t) Occ(LiftR)(t)))(60)tPref(Lift, Spill )(t)(61)U [Lift, LiftL, LiftR, Spill ]HoldingL(1) HoldingR(1) Spilt(1) Occ(Lift)(1)396(62)fiNatural EventsThus axioms (53)-(56) define elementary lift-left (LiftL), lift-right (LiftR) spill events.Axiom (57) states soup spilt, occurrence either elementary liftevent invokes spill event. Axioms (58)-(60) define complex lift-both event (Lift),Axiom (61) states success lift-both event normally preferred spillevent.Let 9 = Ind Inv Pref {(53), . . . , (62)}. 9 single representativepreferred 2 model Lift event succeeds Spill event fails; resultsoup spilt. Thus success Lift event implicitly cancels (secondary)Spilt effect component LiftL LiftR events. Moreover, extended theory 9{Succ(Lift)(1)} two representative preferred 2 models. one LiftL succeeds (and LiftRfails), LiftR succeeds (and LiftL fails). Spill succeeds effectsoup spilt. implicit cancellation Spilt effect thus implicitlycancelled.Proposition 9 |2 Spilt(2), 9 {Succ(Lift)(1)} |2 Spilt (2).Proof first part, let preferred 2 model 9 . events Lift, LiftL,LiftR supported time 1 (axioms (53), (54), (58), (60), (62)). MoreoverLiftL LiftR events invoke Spill event time 1 (axioms (57), (62)),also supported time 1 (axioms (17), (55), (62)). Lift Spill eventsconflict time 1 ; Lift succeeds, Spill fails, vice-versa (axioms (1), (53),(54), (56), (59)). preference atom Pref(Lift, Spill )(1) preference atomtemporal index 1 true (Axiom (61), Definition 14.1). Consequently,time 1 , Lift Spill preference ranks 1 2 respectively, LiftL LiftRnon-preferential. success Lift implies success component events (axioms (1), (53), (54), (59)). (Definition 14.2(a)) Lift succeeds (and Spill fails) time 1. so, Phys(Spilt ) Spilt (1) true (Axiom (62), Definition 9),follows inertia (Axiom (3), Definition 14.3) Spilt(2) true .second part, let preferred 2 model 9 {Succ(Lift)(1)}. Then,above, events Lift, LiftL, LiftR, Spill supported time 1 . Liftfails (when supported) time 1 , one component lift-events must also failtime 1 (axioms (1), (53), (54), (59)). However component event succeedstime 1 (Definition 14.2(b)), consequently Spill (axioms (1), (53) (54),(56), Definition 14.2(a)), effect Spilt(2) true (axioms (1), (56)).next example shows event preferences secondary events usedrepresent changing expectations regarding outcome non-deterministic events.Example 10 race fast horse strong horse run daytomorrow. course currently dry. Given remains case, fast horseexpected win. However rain tomorrow, strong horse wouldexpected win.example represented theory 10 = Ind Inv Pref {(63), . . . ,(71)}; where:t(Pre(RaceFS )(t) Occ(RaceFS )(t))397(63)fiBellt(Eff(RaceFS )(t) (WinnerF (t) WinnerS (t)))(64)t(Pre(WinF )(t) Pre(RaceFS )(t)) t(Eff(WinF )(t) WinnerF (t))(65)t(Pre(WinS )(t) Pre(RaceFS )(t)) t(Eff(WinS )(t) WinnerS (t))(66)t(Occ(RaceFS )(t) Inv1 (RaceFS , {WinF , WinS })(t))(67)t(Pre(Rain)(t) Occ(Rain)(t)) t(Eff(Rain)(t) Dry(t)))(68)t(Dry(t) Pref(WinF , WinS )(t))(69)t(Dry(t) Pref(WinS , WinF )(t))(70)U [RaceFS , WinF , WinS , Rain] Dry(1) Occ(RaceFS )(3)(71)Thus Axiom (64) states outcome successful race two horses(RaceFS ) results either fast horse winning (WinnerF ) strong horse winning(WinnerS ). causal structure RaceFS event (the fact involves competition two horses) represented invocation conflicting WinF WinSevents (axioms (64)-(67)). Rain results course wet (not dry) (Axiom (68)).course dry, fast horse expected win (Axiom (69)), otherwise slowhorse expected win (Axiom (70)).Proposition 10 |2 WinnerF (4), 10 {Occ(Rain)(2)} |2 WinnerS (4).Proof first part, let preferred 2 model 10 . Phys(Dry) Dry(1)true (Axiom (71), Definition 9), follows inertia (Axiom (3), Definition 14.3) Dry(3) true . Moreover, event RaceFS occurs time 3invokes WinF WinS events (axioms (67), (71)). three events supported time 3 (axioms (17), (63), (65), (66), (71)). RaceFS invokes WinFWinS , succeed (Axiom (18), Definition 14.1). follows(Definition 14.2(b)) RaceFS succeeds time 3 . success exactly onetwo invoked events time 3 consistent success RaceFS (axioms (64)-(66)).Dry(3) true follows (Axiom (69)) Pref(WinF , WinS )(3) true .Moreover preference atom temporal index 3 true (Definition 14.1). So, WinF WinS supported time 3 , followsWinF preference rank 1 WinS preference rank 2 time 3 . Consequently(Definition 14.2(a)) WinF succeeds time 3, effect WinnerF (4) true(axioms (1) (65)).second part, let preferred 2 model 10 {Occ(Rain)(2)}.Rain event succeeds time 2 effect Dry(3) true (Axiom (68),Definition 14.2(b)). proof first part, RaceFS one two conflictingsecondary events, WinS WinF , succeed time 3 . Dry(3) true ,follows (Axiom (70)) Pref(WinS , WinF )(3) true . Moreover,preference atom temporal index 3 true (Definition 14.1). So, WinSWinF supported time 3 , follows WinS preference rank 1WinF preference rank 2 time 3 . follows (Definition 14.2(a))WinS succeeds time 3 , effect WinnerS (4) true (axioms (1)(66)).398fiNatural Eventsgenerally, event preferences combined secondary events ordergive qualitative representation conditional probabilities. probability judgmentform P (Succ(e)(t)|Succ(e )(t)) = n states probability event e succeedingtime t, given event e does, n. Judgments kind represented ELevent atoms form Prob(e, e , n)(t). Conditional probabilities translatedevent preferences means following axiom:e, e , e , n, m, t((Prob(e, e , n)(t) Prob(e , e , m)(t) n > m) Pref(e, e )(t))(72)together appropriate invocations. use technique illustratedfinal example, probabilistic extension example attributed Reiter (Shanahan, 1997, p. 290).Example 11 chessman placed haphazardly chessboard. may end (within)single square, likely overlap four squares, likely stilloverlap two squares. situation represented theory 11 =Ind Inv Pref {(72), (73), . . . , (80)}, where:t(Pre(Place)(t) Occ(Place)(t))(73)t(Eff(Place)(t) (One(t) | Two(t) | Four (t)))(74)t(Pre(Place1 )(t) Pre(Place)(t)) t(Eff(Place1 )(t) One(t))(75)t(Pre(Place2 )(t) Pre(Place)(t)) t(Eff(Place2 )(t) Two(t))(76)t(Pre(Place4 )(t) Pre(Place)(t)) t(Eff(Place4 )(t) Four (t))(77)t(Occ(Place)(t) Inv1 (Place, {Place1 , Place2 , Place4 })(t))(78)t(Prob(Place1 , Place, 0.2)(t) Prob(Place2 , Place, 0.5)(t)Prob(Place4 , Place, 0.3)(t))U [Place, Place1 , Place2 , Place4 ] Occ(Place)(1)(79)(80)Thus Axiom (74) states three mutually-exclusive outcomes placing chessman,Axiom (78) states occurrence Place event invokes three conflicting secondary events, Place1 , Place2 , Place4 , Axiom (79) associates conditional probabilityjudgment them, Axiom (72) translates judgments qualitativeevent preferences.Proposition 11 |2 Two(2).Proof Let preferred 2 model 11 . Place event occurs invokesthree secondary events Place1 , Place2 , Place4 time 1 (axioms (78),(80)). four events supported time 1 (axioms (17), (73),(75)-(77),(80)).But, view effects cannot succeed time 1 (axioms (1), (74),(75)-(77)). preference atoms Pref(Place2 , Place4 )(1), Pref(Place4 , Place1 )(1),Pref(Place2 , Place1 )(1) true (axioms (72), (79)) preference atoms temporal index 1 defined (Definition 14.1). Consequently,time 1 , three events Place2 , Place4 , Place1 preference ranks 1, 23 respectively, Place non-preferential. However, Place invokes three399fiBellevents event ((78), Definition 14.1), succeed(Axiom (18)). follows Place succeeds time 1 (Definition 14.2(b)).success Place2 time 1 consistent success Place (axioms (1), (74),(76)). Consequently, given preference rank, Place2 succeeds time 1 (Definition 14.2(a)), effect Two(2) true (axioms (1), (76)).6. Philosophical Justificationsection justification formal theories prediction discussed justificationtheory events given.Goodman (1954, III.2) discusses related problem justification formal theories enumerative induction, suggests start considering justifydeductive inference. Clearly showing conforms set validgeneral rules deduction.29 question arises justify rulesthemselves. suggest appealing fundamental underlyingrules simply postpones question invites regress.30 cannot givefoundational justification deduction, proceed? Goodman suggestsshowing rules deduction conform particular deductiveinferences actually make sanction. circular, virtuously so:point rules particular inferences alike justified brought agreement one another. rule amended yields inference unwillingaccept; inference rejected violates rule unwilling amend. process justification delicate one making mutual adjustments rulesaccepted inferences; agreement achieved lies justification needed either (p. 64). Note however general consensus counts validdeductive argument. Classical logicians accept inference valid, Intuitionists not. Similarly, Intuitionists accept inference valid,Relevantists not. differences explained fact concernedattempting formalize different notions validity; tends agreement amongagree given intuitive notion deduction.31 suggests justificationgiven form deductive inference partly philosophical partly empirical,consist analysis concept deductive validity considerationexamples deductive inference.Similarly then, order justify formal theory prediction, seekshow, means combination conceptual analysis empirical evidence,predictions agree actually make consider reasonable.case logico-pragmatic theory amounts arguing pragmatics appropriate.29. Or, equally, conforms notion entailment defined terms given formal semantics,Tarski semantics classical predicate logic.30. Given formal semantics accompanying notion entailment, justify set rules provingsound complete relative semantics. question arisessemantics notion entailment justified.31. example, valid argument one which, accept premises, must (on paininconsistency) accept conclusion; valid argument one admits constructive proofconclusion given premises; valid argument one premises required orderestablish conclusion.400fiNatural EventsLet logico-pragmatic theory prediction. extension theoryincludes satisfies certain stated restrictions. instance, mightrequire semantic extension , meaning additional axiomsintended interpreted semantically (rather pragmatically); thus, example, 5semantic extension Inv . tentatively define intended models givenextension models accord expectations given .32say pragmatics pragmatically sound class extensionsif, every extension class, pragmatics selects intended models, pragmatics pragmatically complete class extensions if,every extension class, pragmatics selects intended models .Thus pragmatic soundness ensures theory produces predictionswould consider reasonable, pragmatic completeness ensures theoryproduces predictions.case event theories seems appropriate concentrate pragmatic soundness completeness preference1 semantic extensions Ind ; for, givenpreference1 properties, pragmatic soundness completenesspreference2 extensions Ind include event preferences otherwise semantic seems uncontentious.order argue pragmatic soundness preference1 showrestrictions imposes necessary. intuitive notion predictionevent theories endeavour formalize context-dependent activity. Predictiontakes place point time, present, past considered fixed futureconsidered open. Moreover prediction based availableevidence. consists making regularity-based speculations change givencontext, (quietly) assuming facts affected changespersist. properties captured restrictions imposed preference1 .Location time idea closed past open future captured preferringmodels event theory interpreted chronologically. restrictionevidential context subsequent preference change inertia capturedprioritorized minimaximization present time point; first restricting evidentialcontext required earlier interpretation theory, assuming wheneverpossible events succeed, finally assuming wherever possible facts persist.Finally, physical-theoretical distinction necessary theory contains kindsrelations, inertia property physical world restrictedphysical relations. need illustrated Example 2.need maximize inertia assumptions chronologically attempting representinductive reasoning inertia already clear Hanks McDermott (1987)discussion Yale Shooting Problem. Moreover, inductive extension example(in events inductive rather deductive), given Example 1, illustratesneed prefer change inertia given time point. However, might objectedclear earlier events succeed favour later ones; is, success32. question counts intended model theory vexed one; see, example,discussions Sandewall (1994, pp. 68-69) Collins, Hall, Paul (2004, pp. 32-39). However,following discussion, sufficient focus cases general agreement expectedoutcomes.401fiBellassumptions made chronologically. consider extension Example 1second, later, shot occurs (as discussion 1 following example),seems clear expect first shot prove fatal, consequencesecond shot fails Fred already dead occurs; although, course,first shot fail independent reason, would expect secondshot succeed. predicting first shot succeed considersuccess may jeopardized later shot. allow later events influence earlierevents way would allow mysterious form backwards causation.long-standing objection chronological assumption inertiafit generation explanations. standard example Kautzs (1986)Stolen Car Problem; car parked, left unattended, discovered stolenlater point time. since become part folklore chronologicalassumption inertia pragmatically unsound results conclusioncar stolen discovered, when, intuitively, seems reasonableconclude car could stolen earlier point unattended.consequence, proponents chronological maximization inertia promptedqualify application; example, Sandewall (1994) suggests certain occludedrelations exempt law inertia, least certain intervals time.33However seems better response, namely argue examplesinvolving explanation irrelevant considering pragmatic soundness theoryprediction prediction explanation different forms reasoning (Bell,1998).34Another long-standing objection chronological assumption inertia involves nondeterminism. Thus claimed, illustrated Example 6, chronological minimization inertia determine outcome non-deterministic events, thereby eliminating intended models. However, rather seek weaken preference criterion, suggesttake care represent causal structure non-deterministic events (thefact introduce branching histories) correctly; illustrated Example 7.basis considerations seems reasonable conjecture preference1pragmatically sound.33. idea different physical-theoretical distinction. say fact occluded pointtime is, indeed, say subject law inertia point time. However,occluded fact could naturally classified physical one, represented relationExample 2.34. Prediction form inductive reasoning; given epistemic context, task produce reasonable conclusions basis it. contrast, explanation form abductive reasoning; givenconclusion epistemic context imply it, task generate appropriate explanations conclusion. reasoning events effects involves extendingepistemic context appropriate ways, conclusion induced (predicted)extensions. order ensure explanation appropriate reasonable requireextension event therein causes conclusion. Consequently suggest (Bell,2001, Causal counterfactuals) explanations best dealt counterfactually comprehensive setting provided theory causation sketched Footnote 4. view, eventoccurrence together conditions explain world w iff causes closest -worldsw. Thus, case Stolen Car Problem, occurrence additional steal eventtime point interval car unattended cause of, explains, absencecar next time point.402fiNatural Eventsorder argue pragmatic completeness preference1 showrestrictions imposes sufficient. Examples involving ramifications,Lifschitzs (1990) lamp-circuit Bakers (1991) ice-cream eating pedestrian appearshow otherwise. point examples illustrated Example 3 unintendedmodels selected pragmatics. However, suggest problem liesdefinition preference1 fact need represent causal natureramifications (as arising events contemporaneously caused (ultimately)primary events) correctly; illustrated Example 4.35absence counterexamples seems reasonable conjecture preference1pragmatically complete; although, course, always possible new exampleshow preference1 liberal. so, disastroustheory proposed here. analysis, example reveal property prediction captured preference1 , preference1 refined accordingly.Goodmans terms, would simply part delicate process bringing theorypractice agreement.36Rather seeking justifications kind, Sandewall (1994) proposes radicallydifferent methodology. begins suggesting series ontological characteristicsinstances predictive reasoning. include context-free inertia (I), alternative results(A), ramification (D), concurrency (C), surprises (S), normality (N). Examplesreasoning include several characteristics classified belongingcorresponding family; example, inductive version Yale Shooting Problem(Example 1 above) belongs family IN, involves reasoning inertianormal outcome shoot event. Sandewall proposes formal pragmatics,trajectory semantics, defines class intended models given examplefamily IAD, uses prove correctness (to provide validations for) variousformal pragmatics theories expressed appropriate formal languages. example,simple form chronological minimization called PCM proved valid familyIAD; showing that, given example IAD family, PCM selects exactlymodels trajectory semantics does. Thus range applicability PCMestablished; is, PCM proved applicable instances predictioncharacteristics IAD family.35. discussion gears example, culminating Example 5, shows theory eventsrestricted presence symmetric constraints, rather used representreasoning direction causation among symmetrically constrained events.36. sceptical reader might object done show theory works toyexamples. However, overlook care taken represent prediction accurately, misunderstand motivation behind choice examples. examples referred justificationgiven chosen easily represented, well-know benchmark examples specifically designed probe weaknesses; Goodmans (1954, p. 18) terms,represent clinically pure cases . . . display best advantage symptoms widespreaddestructive malady. fact theory represents correctly provides significant empiricalevidence favour. representations also intuitively convincing, provide significantevidence favour conceptual basis theory.related objection theory shown work small-scale examples,guarantee scale easily larger examples. know inherentlimitations scale. particular, definitions events (their preconditions effects)extended modular way, fact events inductive, rather deductive, meansgiven theory extended additional events occur without fear contradiction.403fiBellHowever methodology limited two ways.Firstly, question trajectory semantics justified. providesformal definition intended models given example (of IAD family),sure models selects given example correspondones would select? sufficient simply stipulate case.possible justify formal pragmatics proving equivalent another (ascase PCM trajectory semantics), however point formal pragmaticssquared intuitions means argument kind employed above.Thus best hope thesis relating formal theory predictionintuitive notion it.37 Kripke remarked, mathematical substitutephilosophy.Secondly, trajectory semantics restricted IAD family (essentiallystrips events), would need extended IADCSN family couldapplied event theories.Nevertheless, would worthwhile attempt undertake mathematical assessment event theories relative formal theory; extensiontrajectory semantics. possible, mathematical investigations kind provide additional means justifying formal theories. attempt prove equivalencetwo theories fails, typically highlight inadequacies one them,suggest intuitions behind need refined. Alternatively,possible prove theories equivalent, would provide mutuallysupporting evidence robustness intuitions underlying them; wouldsuggest that, despite appearances contrary, two formal theories captureproperties intuitive notion predictive causal reasoning.38 philosophicalsubstitute mathematics.7. Related Worktheory natural events presented paper developed many years,earlier versions parts appeared elsewhere. earlier fragmentsrevised combined unified whole.earlier version theory inductive events (Section 3) suggested previous research (Bell, 1998), model-building implementation discussed White,Bell, Hodges (1998). theory intellectual origins work McCarthy(1980, 1986), suggested circumscription could used approach qualification problem frame problem. proposal developed Shoham (1988),introduced notion chronological minimization classical, temporal, modallanguage. Shohams theory offers promise simple intuitive approach twoproblems. However, theory limited many ways. particular, propositionalfact-event distinction, possible state general axioms change37. Similarly, Chuch-Turing thesis thesis, rather theorem, claims equivalenceinformal intuitive notion, effective computability, formal theory computability (recursivefunctions, Turing machines).38. equivalence results rival formalizations effective computability (recursivefunctions, Turing Machines, etc.) provide mutually-supportive evidence soundness intuitionsunderlie them.404fiNatural Eventsinertia it. Also, Shoham requires theories meet number syntactic restrictions, including restriction two causal rules conflict (see Definition 4.7(7)).reason ensure theories deterministic, processchronological minimization interprets correctly. makes impossibleexpress problems involving (inductive) change inertia, inductive version Yale Shooting Problem (discussed Section 3 above) theory. Liftingrestriction would allow problem expressed, chronological minimizationtheory would counter-intuitive result Fred remained aliveshooting one class models, died another. short, chronological minimizationsimple. theory inductive events thus thought generalizationrefinement Shohams theory fulfills promise.first general common sense theory change inertia proposed Lifschitz(1987). axioms defines (in Situation Calculus) substantially differenttheory inductive events. However important similarity restriction inertia axiom, basis distinction primitive definedfluents (the Situation Calculus counterparts object relations). later (Lifschitz, 1990,p. 371) says distinction regarded technical trick, suggestsalternative, principled, distinction based frames (McCarthy & Hayes, 1969). However seems primitive-defined distinction justified identifyingphysical-theoretical distinction introduced Section 3.39Secondary events (Section 4) suggested previous research (Bell, 1999, 2000).use representation ramifications compared Thielschers (1997)treatment. Thielscher views problem ramifications logical one, arises (asdiscussed Section 4) lack causal directedness material conditionals.solution starts deductive strips-like representation events. ramificationsevent brought applying series causal constraints stablestate reached. Causal constraints thought directed conditionals twosingle effects, stating circumstances first causes second. Thus,problem posed Example 3 solved Ollie L2 direct effect movingL1 L2, fact L2 holding block cause additionaleffect L2 also. may effect invocationsecondary events cases, two approaches radically different. Thielscherscausal constraints deductive nature, so, begun, application runsconclusion without possible interruption. thus possibility representing failurestage indirect-effect-propagation process. So, stands, solution limiteddeterministic deductive events, either occur isolation (directlyindirectly) conflict other. Sandewalls (1996) Causal Propagation Semanticssimilar Thielschers approach suffers limitations. contrast,approach, success propagated along invocation chain, producing associated effects,point event may fail, case propagation terminates; illustrated39. Readers familiar Goodmans (1954, Ch. 3) paradox know logical complexity predicates relative choice language. here, like Quine (Footnote 12), appeal ordinarylanguage scientific refinements, refrain venturing fly-bottle. (Wittgenstein,1953, 309: aim philosophy?To shew fly way fly-bottle.)405fiBellExample 4 above. representation ramifications thus freely combinednon-deterministic events conflicting events.Several formal theories events employ primitive causation relation; notable examplesA-language family originating Gelfond Lifschitz (1993) Lins (1995)extension (Toronto) Situation Calculus (Lin & Reiter, 1994). appearanceunanalyzed causation relation formal theory events seems beg question;appeal made complex notion (causation) order give analysissimpler one (change). However, rather view causation relation appealfull-blown causation (see Footnote 4), better view means encoding detailedcausal knowledge. Lins theory ternary relation Caused (p, v, s) true fluent pcaused (by something unspecified) truth value v situation (p. 1986).keeping interpretation, two axioms given:Caused (p, true, s) Holds(p, s) ,Caused (p, f alse, s) Holds(p, s) .Thus fluent p caused value true (false) situation s, p holds (doeshold) situation s. way illustration, Lin discusses example springloaded suitcase. locks up, suitcase opens. Initially suitcaseclosed, one lock up, down, down-lock flipped. Naturally expectsuitcase open result. However, attempts formalize example usingordinary domain axiom inertia fail; lamp circuit example, lockremains intended models, also unintended modelssuitcase remains closed lock changes position result. Consequently Linproposes causal domain axiom:up(L1, s) up(L2, s) Caused (open, true, s) ;(81)states locks L1 L2 situation s, suitcase Causedopen s. intention axioms interpreted causally(positively), effect achieved circumscribing Caused relation addinginertia axiom states fluents Caused change persist. Thusaccording Lins account, ramifications arise result causally-directed domain axioms(81), facts cause facts change. Indeed, Lin (p. 1986) says (81)that:[T]he physical spring loaded mechanism behind causal rule abstracted away. care, may well devicemade spring, bombs blow open suitcase time twolocks position. seems natural say fluent opencaused true fact two locks position.However seems odd common sense point view, eventscause change facts otherwise inert. Moreover, actual causeabstracted away, difficult see Lins account could extended order includetreatment qualifications; example, suitcase may fail open locksmechanism rusty, someone sitting suitcase, etc. contrast,406fiNatural Eventsobvious represent problem using primary secondary events; contextone lock down, flipping down-lock invokes secondaryevent which, succeeds, additional effect suitcase open. Moreover,noted above, introduction secondary events makes possible representcomplex examples ramifications, Example 4.Secondary events also compared natural actions proposed Reiter(1996), Lin (1998), Pinto (1998). addition actions initiated agents, suggestalso natural actions arise due nature world (the LawsNature, etc.), guaranteed succeed. use illustrated Pintostreatment Lifschitzs (1990) lamp-circuit example. switches circuitposition (both down) lamp on, otherwise off. Initiallyswitches opposite positions one flipped. Clearly expect lampresult. However attempts formalize example using domain axiomsinertia axiom fail. intended models switch retains position inertialamp comes result flip event. However also unintended modelslamp remains inertia consequently switch mysteriouslychanges position result; problem essentially posed Example 3.Pintos treatment problem, agent flipping switch results natural actioncurrent flowing circuit, turn results lamp on. naturalaction current flowing resolves conflict alternative uses inertiaaxiom bringing intermediary state switches (as flowingcurrent affect position) inertia axiom appliedintended way (as flowing current guaranteed effect lamp on).proposal aims solve causal-directedness problem introducing additionalevents can, perhaps, seen lying somewhere Thielschers logical approachrepresentational approach. Unlike natural events, natural actions deductive.difficult see natural actions could used represent qualifications.example, natural action current flowing guaranteed succeed (turninglamp on), reality current might flow wire loses conductivity, cut,etc. clearly complication represented using natural events. contextswitches opposite positions, flipping switch invokes secondary eventwhich, succeeds, results lamp on; lamps coming thus defeasiblesecondary effect flipping switch. Moreover, natural actions independentactions agents, secondary events causally dependent (at least one of)events invoke them.Event preferences (Section 5) introduced previous research (Bell, 2001, Simultaneous events). presentation substantially improved, and, examplesshow, combination event preferences secondary events provides interesting newpossibilities.Recently Vo Foo (2005) suggested inductive theory reasoning actionwhich, suggest, provides basis unified solution frame, qualification,ramification problems. theory based theory argumentation developedBondarenko, Dung, Kowalski, Toni (1997), differs radically mine termstechnical realization. conceptual level interesting similarities. Likeme, Vo Foo suggest event occurrences minimized inertia407fiBellfluents (their counterpart object-relations) maximized (p. 448). Furthermore,order integrate solution frame qualification problems, they, effect(p. 493), adopt principle change preferred inertia (Bell, 1998). However,theory suggestion minimization maximization donechronologically. Indeed, suggest strength approachenables provide explanations reasoning backwards (or antichronologically)examples Stolen Car Problem. However, reasoning chronologicallyessential feature predictive reasoning, suspect prove problemVo Foos theory. Instead suggest (Footnote 34) explanations treatedcounterfactual causes.8. Conclusionbegan arguing Deductionism logical mistake, made case Inductionism. began basic theory inductive events, provides basisintegrated solution qualification frame problems. introduceddistinction primary secondary events order represent causal structurenatural events, thereby providing basis solution ramification problemproblem representing non-determinism. Finally, introduced event preferences, used express defeasible preferences outcomes conflictingsimultaneous events. development theory illustrates benefit startingright foot, inductive, rather deductive, events. basic theory simpleintuitive, extensions require addition axiomsrefinement one clause formal pragmatics.simple cases may little choose deductive inductive theories events; produce predictions wrong. However inductiverepresentation natural events accurate reflects defeasibility.representation inductive events makes possible define primary secondary events,defeasible event preferences. turn make possible give accurate representations ramifications, non-determinism, conflicting events. turn makespossible represent complex cases accurately. instance, Example 8, twostooges attempt move location, one expected succeed, however threedo, none succeeds. always inductive events, example elaborated.Thus two stooges attempt move preferred one fails independentreason (he slips, say), stooge normally succeeds (unless also slips).case three attempt move, Ollie slips, Stan expected succeed.also slips, Charlie expected succeed; may also slip. Moreover,example readily combined others. example, stooge could carry stackblocks; block moves block beneath it, stooge holding it,moves. know theory events represent reasoning subtletycomplexity.future work, model-building implementation event theories investigated.general idea outlined previous research (Bell, 1995), White et al. (1998)describe implementation (an earlier version of) theory inductive events. Essentially idea build finite initial parts representative preferred models given408fiNatural Eventsevent theory chronologically, suggested informal discussion Yale ShootingProblem Section 3.suggested introduction (and Footnote 4), theory natural events formspart larger theory causation (Bell, 2004, 2006, 2008). Event theories usedrepresent detailed, regularity-based, causal knowledge events; expressed formpreconditions effects, invocations, event preferences. used basisgeneral definition sufficient causation, combined refinement Lewiss(1986, Ch. 21) counterfactual-dependence condition give definition causation.Acknowledgmentsgrateful everyone commented work, especially anonymousreferees, Wilfrid Hodges, Robert Miller, Edmund Robinson, Murray Shanahan, GrahamWhite.ReferencesBaker, A. B. (1991). Nonmonotonic reasoning framework situation calculus.Artificial Intelligence, 49, 523.Barringer, H., Cheng, J., & Jones, C. (1984). logic covering undefinedness programproofs. Acta Informatica, 21, 251269.Bell, J. (2001). Causal counterfactuals. Working Notes Common Sense 2001. Availableat: www.cs.nyu.edu/cs/faculty/davise/commonsense01/.Bell, J. (1995). Pragmatic reasoning; model-based theory. Polos, L., & Masuch, M.(Eds.), Applied Logic; How, Why, pp. 127. Kluwer. selection papersApplied Logic Conference, Amsterdam, 1992.Bell, J. (1996). model-based approach predictive causal reasoning. Doherty (Doherty,1996), pp. 169195.Bell, J. (1998). Chronological minimization explanation. Miller, R., & Shanahan,M. (Eds.), Working papers Common Sense 98; fourth symposium logicalformalizations common sense reasoning.Bell, J. (1999). Primary secondary events. Thielscher, M. (Ed.), Working notes4th workshop Nonmonotonic Reasoning, Action Change, pp. 6572.Bell, J. (2000). Primary secondary events. Electronic Transactions Artificial Intelligence discussion paper. Available at: www.ida.liu.se/ext/etai/rac/. Subsequentversion available at: www.dcs.qmul.ac.uk/jb, 2001.Bell, J. (2001). Simultaneous events: Conflicts preferences. Proceedings 6thEuropean Conference Symbolic Quantitative Approaches ReasoningUncertainty (ECSQARU 2001), pp. 714725. Springer.Bell, J. (2004). Causation causal conditionals. Proceedings 9th InternationalConference Principles Knowledge Representation Reasoning (KR 2004),pp. 211. AAAI Press.409fiBellBell, J. (2006). Causation production. Proceedings 17th European ConferenceArtificial Intelligence (ECAI 2006), pp. 327331. IOS Press.Bell, J. (2008). common sense theory causation. Forthcoming.Blackburne, S. (1994). Oxford Dictionary Philosophy. Oxford University Press,Oxford.Bochvar, D. A. (1939). three-valued logical calculus application analysiscontradictories. Matematiceskij sbornik, 4.Bondarenko, A., Dung, P. M., Kowalski, R. A., & Toni, F. (1997). abstractargumentation-theoretic approach default reasoning. Artificial Intelligence, 93,63101.Collins, J., Hall, N., & Paul, L. A. (Eds.). (2004). Causation Counterfactuals. MITPress, Cambridge, Massachusetts.Davidson, D. (1980). Essays Actions Events. Oxford University Press, Oxford.Denecker, M., Dupre, D. T., & Belleghem, K. V. (1998). inductive definition approachramifications. Electronic Transactions Artificial Intelligence, 2, 2567.Doherty, P. (Ed.). (1996). Partiality, Modality, Nonmonotonicity. CSLI Publications,CSLI, Stanford University, Palo Alto.Fikes, R. E., & Nilsson, N. J. (1971). strips, new approach application theoremproving problem solving. Artificial Intelligence, 2, 189208.Gelfond, M., & Lifschitz, V. (1993). Representing action change logic programs.Journal Logic Programming, 17, 301322.Gelfond, M., Lifschitz, V., & Rabinov, A. (1991). limitations situationcalculus?. Boyer, R. (Ed.), Essays Honour Woody Bledsoe, pp. 167179.Kluwer Academic Publishers.Ginsberg, M. L., & Smith, D. E. (1988). Reasoning action II: qualificationproblem. Artificial Intelligence, 35, 311342.Girard, J.-Y. (1987). Linear logic. Theoretical Computer Science, 50:1, 1102.Goodman, N. (1954). Fact, Fiction, Forecast. Harvard University Press, CambridgeMass. References 4th edition, 1983.Hanks, S., & McDermott, D. (1987). Nonmonotonic logic temporal projection. ArtificialIntelligence, 33 (3), 379412.Hume, D. (1739). Treatise Human Nature. Clarendon Press, Oxford. ReferencesClarendon edition, 1978.Hume, D. (1777). Enquiry Concerning Human Understanding. Clarendon Press, Oxford.References Clarendon edition, 1975.Kautz, H. (1986). logic persistence. Proceedings 5th National ConferenceArtificial Intelligence (AAAI-86), pp. 401405.Kleene, S. C. (1952). Introduction Metamathematics. North-Holland, Amsterdam.Kripke, S. (1975). Outline theory truth. Journal Philosophy, 72, 690716.410fiNatural EventsLewis, D. (1986). Philosophical Papers, Vol. II. Oxford University Press, Oxford.Lifschitz, V. (1987). Formal theories action. Brown, F. (Ed.), Frame ProblemArtificial Intelligence, pp. 3558. Morgan Kaufmann.Lifschitz, V. (1990). Frames space situations. Artificial Intelligence, 46, 365376.Lin, F., & Reiter, R. (1994). State constraints revisited. Journal Logic Computation,4(5), 655678.Lin, F. (1995). Embracing causality specifying indirect effects actions. Proceedings 14th International Joint Conference Artificial Intelligence (IJCAI 95), pp.19851991.Lin, F. (1998). relationships static dynamic causal rules situationcalculus. Ortiz, C. (Ed.), Working Papers AAAI98 Spring SymposiumProspects Commonsense Theory Causation, pp. 3843.Mackie, J. L. (1974). Cement Universe. Clarendon Press, Oxford.Mackie, J. L. (1975). Causes conditions. Sosa, E. (Ed.), Causes Conditionals, pp.1538. Oxford University Press, Oxford. First published American PhilosophicalQuarterly 2, 1965, pages 245-264.McCarthy, J. (1977). Epistemological problems artificial intelligence. Proceedings5th International Joint Conference Artificial Intelligence (IJCAI 95), pp. 10381044.McCarthy, J. (1980). Circumscription form nonmonotonic reasoning. ArtificialIntelligence, 13, 27 39.McCarthy, J. (1986). Applications circumscription formalizing commonsense knowledge. Artificial Intelligence, 28, 89116.McCarthy, J., & Hayes, P. J. (1969). philosophical problems standpointartificial intelligence. Michie, D., & Meltzer, B. (Eds.), Machine Intelligence 4, pp.463502. Edinburgh University Press.Mill, J. S. (1898). System Logic. Longmans, London. References 8th edition,1941.Pinto, J. (1998). Causality theories action. Miller, R., & Shanahan, M. (Eds.),Working papers 4th Symposium Logical Formalizations CommonsenseReasoning, pp. 349364.Quine, W. V. (1995). Stimulus Science. Harvard University Press, Cambridge,Massachusetts.Reiter, R. (1996). Natural actions, concurrency continuous time situation calculus. Proceedings 5th International Conference Principles KnowledgeRepresentation Reasoning (KR96.), pp. 213.Reiter, R. (2001). Knowledge Action; Logical Foundations Specifying Implementing Dynamical Systems. MIT Press, Cambridge, Mass.Rosser, J., & Turquette, A. (1952). Many-valued Logics. North-Holland, Amsterdam.Russell, B. (1913). notion cause. Proceedings Aristotelian Society, 13, 126.411fiBellRussell, S., & Norvig, P. (2003). Artificial Intelligence; Modern Approach. Prentice Hall,New Jersey. 2nd Edition.Sandewall, E. (1994). Features Fluents; Representation Knowledge Dynamical Systems. Oxford University Press, Oxford.Sandewall, E. (1996). Assessments ramification methods use domain constraints.Proceedings 5th International Conference Principles Knowledge Representation Reasoning (KR96.), pp. 99110.Shanahan, M. (1997). Solving Frame Problem; Mathematical InvestigationCommon Sense Law Inertia. MIT Press, Cambridge, Mass.Shoham, Y. (1988). Reasoning Change. MIT Press, Cambridge Mass.Taylor, R. (1975). metaphysics causation. Sosa, E. (Ed.), Causation Conditionals, pp. 3943. Oxford University Press.Thielscher, M. (1997). Ramification causality. Artificial Intelligence, 98, 317364.Vo, Q. B., & Foo, N. Y. (2005). Reasoning action: argumentation-theoreticapproach. Journal Artificial Intelligence Research, 24, 465518.White, G., Bell, J., & Hodges, W. (1998). Building models prediction theories. Cohn,A., Schubert, L., & Shapiro, S. (Eds.), Proc. KR98, pp. 557568, San Francisco.Morgan Kaufmann.Wittgenstein, L. (1953). Philosophical Investigations. Blackwell, Oxford.412fiJournal Artificial Intelligence Research 30 (2007) 249-272Submitted 12/06; published 10/07Topic Role Discovery Social NetworksExperiments Enron Academic EmailAndrew McCallumXuerui Wangmccallum@cs.umass.eduxuerui@cs.umass.eduDepartment Computer ScienceUniversity Massachusetts140 Governors DriveAmherst, 01003 USAAndres Corrada-Emmanuelacorrada@physics.umass.eduDepartment PhysicsUniversity Massachusetts666 North Pleasant StreetAmherst, 01003 USAAbstractPrevious work social network analysis (SNA) modeled existence linksone entity another, attributes language content topicslinks. present Author-Recipient-Topic (ART) model social networkanalysis, learns topic distributions based direction-sensitive messages sententities. model builds Latent Dirichlet Allocation (LDA) AuthorTopic (AT) model, adding key attribute distribution topics conditioneddistinctly sender recipientsteering discovery topics accordingrelationships people. give results Enron email corpusresearchers email archive, providing evidence clearly relevant topicsdiscovered, ART model better predicts peoples roles gives lower perplexitypreviously unseen messages. also present Role-Author-Recipient-Topic (RART)model, extension ART explicitly represents peoples roles.1. IntroductionSocial network analysis (SNA) study mathematical models interactions amongpeople, organizations groups. recent availability large data sets humaninteractions (Shetty & Adibi, 2004; Wu, Huberman, Adamic, & Tyler, 2003), popularityservices like MySpace.com LinkedIn.com, salience connections among9/11 hijackers, growing interest social network analysis.Historically, research field led social scientists physicists (Lorrain& White, 1971; Albert & Barabasi, 2002; Watts, 2003; Wasserman & Faust, 1994),previous work emphasized binary interaction data, directed and/or weighted edges.not, however, previously significant work researchers backgroundsstatistical natural language processing, analysis captures richnesslanguage contents interactionsthe words, topics, high-dimensionalspecifics interactions people.c2007AI Access Foundation. rights reserved.fiMcCallum, Wang, & Corrada-EmmanuelUsing pure network connectivity properties, SNA often aims discover various categories nodes network. example, addition determining node-degreedistribution heavy-tailed, also find particular nodes inordinatelyhigh number connections, connections particularly well-connected subset(group block) network (Nowicki & Snijders, 2001; Kemp, Griffiths, & Tenenbaum,2004; Kemp, Tenenbaum, Griffiths, Yamada, & Ueda, 2006; Kubica, Moore, Schneider, &Yang, 2002; Airoldi, Blei, Fienberg, & Xing, 2006; Kurihara, Kameya, & Sato, 2006). Furthermore, using properties assign roles certain nodes (Lorrain & White,1971; Wolfe & Jensen, 2004). However, clear network properties enoughdiscover roles social network. Consider email messages corporate setting,imagine situation tightly knit group users trade email messagesroughly symmetric fashion. Thus, network level appear fulfillrole. perhaps, one users fact manager whole grouparole becomes obvious one accounts language content emailmessages.Outside social network analysis literature, stream new researchmachine learning natural language models clustering words order discoverunderlying topics combined form documents corpus. ProbabilisticLatent Semantic Indexing (Hofmann, 2001) Latent Dirichlet Allocation (Blei, Ng, &Jordan, 2003) robustly discover multinomial word distributions topics. HierarchicalDirichlet Processes (Teh, Jordan, Beal, & Blei, 2004) determine appropriate numbertopics corpus. Author-Topic Model (Steyvers, Smyth, Rosen-Zvi, & Griffiths,2004) learns topics conditioned mixture authors composed document.However, none models appropriate SNA, aim capturedirected interactions relationships people.paper presents Author-Recipient-Topic (ART) model, directed graphical modelwords message generated given author set recipients. modelsimilar Author-Topic (AT) model, crucial enhancement conditions per-message topic distribution jointly author individual recipients,rather individual authors. Thus discovery topics ART model influenced social structure messages sent received. topic consistsmultinomial distribution words. author-recipient pair multinomialdistribution topics. also easily calculate marginal distributions topicsconditioned solely author, solely recipient, order find topicsperson likely send receive.importantly, also effectively use person-conditioned topic distributions measure similarity people, thus discover peoples roles clusteringusing similarity.1 example, people receive messages containing requestsphotocopying, travel bookings, meeting room arrangements saidrole administrative assistant, discovered ART modeltopics high probability receiving distribution. Note1. clustering may either external model simple greedy-agglomerative clustering, internalmodel introducing latent variables senders recipients roles, describedRole-Author-Recipient-Topic (RART) model toward end paper.250fiTopic Role Discovery Social Networksdiscover two people similar roles even graph connecteddifferent sets people.demonstrate model Enron email corpus comprising 147 people 23kmessages, also 9 months incoming outgoing mail first author,comprising 825 people 14k messages. show ART discovers extremelysalient topics, also gives evidence ART predicts peoples roles betterSNA. Also, show similarity matrix produced ART differentSNA matrix matrix several appropriate ways. Furthermore, findART model gives significantly lower perplexity previously unseen messages AT,shows ART better topic model email messages.also describe extension ART model explicitly captures roles people,generating role associations author recipient(s) message, conditioningtopic distributions role assignments. model, term Role-AuthorRecipient-Topic (RART), naturally represents one person one role.describe several possible RART variants, describe experiments onevariants.importance modeling language associated social network interactionsalso recently demonstrated Group-Topic (GT) model (Wang, Mohanty, &McCallum, 2006). Unlike ART, discovers roles, GT discovers groups. Like ART,uses text data find interesting useful patterns would possibleedge relations alone. GT simultaneously clusters entities groups share similarinteraction patterns, also clusters text (or attributes) interactionstopicsdoing way clustering dimension informs other.applied voting records corresponding text resolutions U.S. SenateU.N., Group-Topic model shows incorporating votes results salienttopic clusters, different groupings legislators emerge different topics.role discovery group discovery primary areas SNA research.2. Author-Recipient-Topic Modelsdescribing ART model, first describe three related models. Latent DirichletAllocation (LDA) Bayesian network generates document using mixture topics(Blei et al., 2003). generative process, document d, multinomial distributiontopics randomly sampled Dirichlet parameter , generateword, topic z chosen topic distribution, word, w, generatedrandomly sampling topic-specific multinomial distribution z . robustnessmodel greatly enhanced integrating uncertainty per-document topicdistribution .Author model, also termed Multi-label Mixture Model (McCallum, 1999),Bayesian network simultaneously models document content authors interests1-1 correspondence topics authors. document d, setauthors ad observed. generate word, author, z, sampled uniformlyset, word, w, generated sampling author-specific multinomialdistribution z . Author-Topic (AT) model similar Bayesian network,authors interests modeled mixture topics (Steyvers et al., 2004).251fiMcCallum, Wang, & Corrada-EmmanuelAuthor-Topic Model(AT)Author-Recipient-Topic Model(ART)Latent Dirichlet Allocation(LDA)Author Model(Multi-label Mixture Model)[Blei, Ng, Jordan, 2003][McCallum 1999][Rosen-Zvi, Griffiths, Steyvers, Smyth 2004]adadzxzadwNdwzNdzA,Awrdx[This paper]NdwNdFigure 1: Three related models, ART model. models, observed word,w, generated multinomial word distribution, z , specific particulartopic/author, z, however topics selected differently models.LDA, topic sampled per-document topic distribution, ,turn sampled Dirichlet topics. Author Model,one topic associated author (or category), authors sampleduniformly. Author-Topic model, topic sampled per-authormultinomial distribution, , authors sampled uniformly observedlist documents authors. Author-Recipient-Topic model,separate topic-distribution author-recipient pair, selectiontopic-distribution determined observed author, uniformly sampling recipient set recipients document.generative process document d, set authors, ad , observed. generateword, author x chosen uniformly set, topic z selectedtopic distribution x specific author, word w generatedtopic-specific multinomial distribution z . However, described previously, nonemodels suitable modeling message data.email message one sender general one recipients. couldtreat sender recipients authors message, employmodel, distinguish author recipients message,undesirable many real-world situations. manager may send email secretaryvice versa, nature requests language used may quite different. Evendramatically, consider large quantity junk email receive; modelingtopics messages undistinguished topics write authors wouldextremely confounding undesirable since reflect expertise roles.Alternatively could still employ model ignoring recipient informationemail treating email document one author. However,case (which similar LDA model) losing information recipients,connections people implied sender-recipient relationships.252fiTopic Role Discovery Social NetworksSYMBOLVNdDESCRIPTIONnumber topicsnumber email messagesnumber email accounts (senders recipients)number unique words (vocabulary size)number word tokens messageTable 1: Notation used paperThus, propose Author-Recipient-Topic (ART) model email messages.ART model captures topics directed social network senders recipientsconditioning multinomial distribution topics distinctly author onerecipient message. Unlike AT, ART model takes consideration authorrecipients distinctly, addition modeling email content mixture topics.ART model Bayesian network simultaneously models message content,well directed social network messages sent. generativeprocess, message d, author, ad , set recipients, rd , observed.generate word, recipient, x, chosen uniformly rd , topic zchosen multinomial topic distribution ad x , distribution specificauthor-recipient pair (ad , x). distribution topics could also smootheddistribution conditioned author only, although find necessaryexperiments. Finally, word w generated sampling topic-specificmultinomial distribution z . result discovery topics guidedsocial network collection message text generated.graphical model representations models shown Figure 1. ARTmodel, given hyper-parameters , author ad , set recipients rdmessage d, joint distribution topic mixture ij author-recipient pair(i, j), word mixture topic t, set recipients x, set topics z setwords w corpus given by:P (, , x, z, w|, , a, r) =p(ij |)i=1 j=1Ndp(t |)(P (xdi |rd )P (zdi |ad xdi )P (wdi |zdi ))t=1d=1 i=1Integrating , summing x z, get marginal distributioncorpus:P (w|, , a, r)ZZNd XX=p(ij |)p(t |)(P (xdi |rd )(P (zdi |ad xdi )P (wdi |zdi )))ddi=1 j=1t=1d=1 i=1 xdi =1zdi =12.1 Inference Gibbs SamplingInference models LDA family cannot performed exactly. Three standard approximate inference methods used obtain practical results: variational methods253fiMcCallum, Wang, & Corrada-EmmanuelAlgorithm 1 Inference Parameter Estimation ART1: initialize author topic assignments randomly tokens2: repeat3:= 14:= 1 Nd5:draw xdi zdi P (xdi , zdi |xdi , zdi , w, , , a, r)6:update nad xdi zdi mzdi wdi7:end8:end9: Markov chain reaches equilibrium10: compute posterior estimates(Blei et al., 2003), Gibbs sampling (Griffiths & Steyvers, 2004; Steyvers et al., 2004; RosenZvi, Griffiths, Steyvers, & Smyth, 2004), expectation propagation (Griffiths & Steyvers,2004; Minka & Lafferty, 2002). choose Gibbs sampling ease implementation.Note adopt conjugate priors (Dirichlet) multinomial distributions, thuseasily integrate , analytically capturing uncertainty associatedthem. way facilitate samplingthat is, need sampleall. One could estimate values hyper-parameters ART model, ,data using Gibbs EM algorithm (Andrieu, de Freitas, Doucet, & Jordan, 2003).applications, topic models sensitive hyper-parameters, extremelyimportant set right values hyper-parameters. However, particular applications discussed paper, trying many different hyper-parameter settings,find sensitivity hyper-parameters strong. Thus, simplicity, use fixed symmetric Dirichlet distributions ( = 50/T = 0.1)experiments.need derive P (xdi , zdi |xdi , zdi , w, , , a, r), conditional distributiontopic recipient word wdi given words topic recipient assignments,xdi zdi , carry Gibbs sampling procedure ART. begin jointprobability whole data set, chain rule, conditional probabilityobtained ease:z + nad xdi zdi 1w + mzdi wdi 1P (xdi , zdi |xdi , zdi , w, , , a, r) PT diPV dit=1 (t + nad xdi ) 1v=1 (v + mzdi v ) 1nijt number tokens assigned topic author-recipient pair (i, j),mtv represent number tokens word v assigned topic t.posterior estimates given training set calculatedz + nijzw + mtw, tw = PVijz = PTt=1 (t + nijt )v=1 (v + mtv )(1)Detailed derivation Gibbs sampling ART provided Appendix A. overviewGibbs sampling procedure use shown Algorithm 1.254fiTopic Role Discovery Social Networks3. Related Workuse social networks discover roles people (or nodes) network goes backthree decades work Lorrain White (1971). based hypothesisnodes network relate nodes equivalent ways mustrole. equivalence given probabilistic interpretation Holland, Laskey,Leinhardt (1983): nodes assigned class/role stochastically equivalentprobabilities relationships nodes class/role same.limitation single class/role label node network relaxed recentwork Wolfe Jensen (2004). consider model assigns multiple role labelsgiven node network. One advantage multiple labels that, factoredmodel, fewer parameters required estimated non-factored model usinglabel obliged represent values. find that, two labels three values (giving32 = 9 possible labelings node) better estimator synthetic data producedtwo-label process model using one label nine possible values. is,course, advantage mixture models, LDA ART model presented here.study email social networks hampered unavailability publiccorpus. research published used email to-from logs. Logs easierobtain less intrusive users privacy. means previous researchfocused topological structure email networks, dynamics emailtraffic users. Wu et al. (2003) look information flowed email networkusers research labs (mostly HP Labs). conclude epidemic modelsinformation flow work email networks thus identifying hubs networkmay guarantee information originating node reaches large fractionnetwork. finding serves example network properties sufficientoptimize flow email network. Adamic Adar (2004) study efficiency localinformation search strategies social networks. find case emailnetwork HP Labs, greedy search strategy works efficiently predicted Kleinberg(2000) Watts, Dodds, Newman (2002).approaches, however, limit use network topology discover roles. ART model complements approaches using contenttraffic among nodes create language models bring differences invisiblenetwork level.discussed introduction, also recently developed model groupdiscovery. addition relation-edge data, Group-Topic (GT) model also takesconsideration textual attributes relations, allows discovery groupsguided emerging textual topics vice-versa (Wang et al., 2006). Experimentsvoting data show Group-Topic models joint inference improves groupstopics discovered. modalities information combined discover hiddenstructure. example, time text combined Topics Time (TOT) model(Wang & McCallum, 2006), finds trends time-sensitive topics using continuousdistribution time-stamps. Dynamic Topic Models (Blei & Lafferty, 2006b) incorporatetime topic models transitions Markov process. ART model couldeasily extended incorporate temporal information.255fiMcCallum, Wang, & Corrada-Emmanueldiscussed earlier, ART model direct offspring Latent Dirichlet Allocation(Blei et al., 2003), Multi-label Mixture Model (McCallum, 1999), AuthorTopic Model (Steyvers et al., 2004), distinction ART specifically designedcapture language used directed network correspondents. Another recentmodel associates topics people Author-Persona-Topic (APT) model (Mimno& McCallum, 2007). APT designed specifically capture expertise person,modeling expertise mixture topical intersections, demonstrated taskmatching reviewers submitted research papers.New topic models actively studied recent years many different tasks,including joint modeling words research paper citations (Erosheva, Fienberg, &Lafferty, 2004), capturing correlations among topics (Blei & Lafferty, 2006a; Li & McCallum,2006), taking advantage topical syntactic dependencies (Griffiths, Steyvers, Blei,& Tenenbaum, 2004), discovering topically-relevant phrases Markov dependenciesword sequences (Wang, McCallum, & Wei, 2007). Many models could easilycombined ART model, would likely prove useful.4. Experimental Resultspresent results Enron email corpus personal email one authorspaper (McCallum). Enron email corpus, large body email messagessubpoenaed part investigation Federal Energy Regulatory Commission(FERC), placed public record. original data set contains 517,431messages, however MD5 hashes contents, authors dates show 250,484unique.Although Enron email data set contains email folders 150 people, two peopleappear twice different usernames, remove one person sent automatedcalendar reminders, resulting 147 people experiments. hand-corrected variantsemail addresses 147 users capture connectivity muchusers emails possible. total number email messages traded among users23,488. model email messages received least one 147users.order capture new text entered author message, necessaryremove quoted original messages replies. eliminate extraneous textsimple heuristic: text message forwarded message line time stampremoved. heuristic certainly incorrectly looses words interspersed quotedemail text. words formed sequences alphabetic characters kept, resultsvocabulary 22,901 unique words. remove sensitivity capitalization, textdowncased.second data set consists personal email sent received McCallumJanuary September 2004. consists 13,633 unique messages written 825authors. typical power-law behavior, authors wrote messages,128 wrote ten emails. applying text normalization filter(lowercasing, removal quoted email text, etc.) used Enron data set,obtained text corpus containing 457,057 word tokens, vocabulary 22,901 uniquewords.256fiTopic Role Discovery Social Networks(a) Enron authors(b) Enron author-recipient pairs(c) McCallum authors(d) McCallum author-recipient pairsFigure 2: Power-law relationship frequency occurrence author (orauthor-recipient pair) rank determined frequencyoccurrence. author plots, treat sender recipientsauthors.conditioning topic distributions author-recipient pairs instead authors, datamay look sparser considering substantially author-recipient pairsauthors. However, shown Figure 2, find number emailsauthor-recipient pair rank determined count still follow power-lawbehavior, authors. example, McCallum data set, 500 possible 680,625author-recipient pairs responsible 70% email exchange. is, even thoughdata sparser ART model, power-law behavior makes still possibleobtain good estimation topic distributions prominent author-recipient pairs.initialize Gibbs chains data sets randomly, find resultsrobust different initializations. checking perplexity, find usuallyGibbs chain converges hundred iterations, run 10,000 iterations anywaymake sure converges.4.1 Topics Prominent Relations ARTTable 2 shows highest probability words eight topics ART model trained147 Enron users 50 topics. quoted titles interpretation257fiMcCallum, Wang, & Corrada-EmmanuelTopic 5Legal Contractssection0.0299party0.0265language0.0226contract0.0203date0.0155enron0.0151parties0.0149notice0.0126days0.0112include0.0111M.Hain0.0549J.SteffesJ.Dasovich0.0377R.ShapiroD.Hyvl0.0362K.WardTopic 17Document Reviewattached0.0742agreement0.0493review0.0340questions0.0257draft0.0245letter0.0239comments0.0207copy0.0165revised0.0161document0.0156G.Nemec0.0737B.TycholizG.Nemec0.0551M.WhittB.Tycholiz0.0325G.NemecTopic 27Time Schedulingday0.0419friday0.0418morning0.0369monday0.0282office0.0282wednesday0.0267tuesday0.0261time0.0218good0.0214thursday0.0191J.Dasovich0.0340R.ShapiroJ.Dasovich0.0289J.SteffesC.Clair0.0175M.TaylorTopic 45Sports Poolgame0.0170draft0.0156week0.0135team0.0135eric0.0130make0.0125free0.0107year0.0106pick0.0097phillip0.0095E.Bass0.3050M.LenhartE.Bass0.0780P.LoveM.Motley0.0522M.GrigsbyTopic 34Operationsoperations0.0321team0.0234office0.0173list0.0144bob0.0129open0.0126meeting0.0107gas0.0107business0.0106houston0.0099S.Beck0.2158L.KitchenS.Beck0.0826J.LavoratoS.Beck0.0530S.WhiteTopic 37Power Marketmarket0.0567power0.0563price0.0280system0.0206prices0.0182high0.0124based0.0120buy0.0117customers0.0110costs0.0106J.Dasovich0.1231J.SteffesJ.Dasovich0.1133R.ShapiroM.Taylor0.0218E.SagerTopic 41Government Relationsstate0.0404california0.0367power0.0337energy0.0239electricity0.0203davis0.0183utilities0.0158commission0.0136governor0.0132prices0.0089J.Dasovich0.3338R.ShapiroJ.Dasovich0.2440J.SteffesJ.Dasovich0.1394R.SandersTopic 42Wirelessblackberry0.0726net0.0557www0.0409website0.0375report0.0373wireless0.0364handheld0.0362stan0.0282fyi0.0271named0.0260R.Haylett0.1432T.GeacconeT.Geaccone 0.0737R.HaylettR.Haylett0.0420D.FossumTable 2: illustration several topics 50-topic run Enron email data set.topic shown top 10 words corresponding conditionalprobabilities. quoted titles summary topics.prominent author-recipient pairs topic. example, Mary Hainin-house lawyer Enron; Eric Bass coordinator fantasy football leaguewithin Enron. Operations topic satisfying see Beck,Chief Operating Officer Enron; Kitchen President Enron Online;Lavorato CEO Enron America. Government Relations topic,see Dasovich, Government Relation Executive, Shapiro, VicePresident Regulatory Affairs, Steffes, Vice President GovernmentAffairs, Sanders, Vice President WholeSale Services. Wirelesssee Haylett, Chief Financial Officer Treasurer, aviduser Blackberry brand wireless, portable email system.258fiTopic Role Discovery Social Networkssummary topics. clarity specificity topics typicaltopics discovered model. example, Topic 17 (Document Review) comesmessages discussing review comments documents; Topic 27 (Time Scheduling)comes messages negotiating meeting times.Beneath word distribution topic three author-recipient pairshighest probability discussing topiceach pair separated horizontal line,author recipient. example, Hain, top author messages LegalContracts topic, in-house lawyer Enron. inspection messages relatedSports Pool, Eric Bass seems coordinator fantasy football leagueamong Enron employees. Operations topic, satisfying see Beck,Chief Operating Officer Enron; Kitchen President Enron Online; LavoratoCEO Enron America. Government Relations topic, see Dasovich,Government Relation Executive, Shapiro, Vice President Regulatory Affairs,Steffes, Vice President Government Affairs, Sanders, Vice PresidentWholeSale Services. Wireless see Haylett, Chief Financial OfficerTreasurer, avid user Blackberry brand wireless, portable email system.Results McCallum email data set reported Table 3.4.2 Stochastic Blockstructures Rolesstochastic equivalence hypothesis SNA states nodes network behavestochastically equivalently must similar roles. case email network consistingmessage counts, natural way measure equivalence examine probabilitynode communicated nodes. two nodes similar probability distributioncommunication partners, consider role-equivalent. Lacking truedistance measure probability distributions, use symmetric measure,Jensen-Shannon (JS) divergence, obtain symmetric matrix relatingnodes network. Since want consider nodes/users small JS divergenceequivalent, use inverse divergence construct symmetric matrixlarger numbers indicate higher similarity users.Standard recursive graph-cutting algorithms matrix used cluster users,rearranging rows/columns form approximately block-diagonal structures.familiar process blockstructuring used SNA. perform analysis twodata sets: small subset Enron users consisting mostly people associatedTranswestern Pipeline Division within Enron, entirety McCallums email.begin Enron TransWestern Pipeline Division. analysis employedclosed-universe assumptiononly messages traded among considered authorsdata set used.traditional SNA similarity measure (in case JS divergence distributionsrecipients person) shown left matrix Figure 3. Darker shading indicatestwo users considered similar. related matrix resulting ART model(JS divergence recipient-marginalized topic distributions email author) appearsmiddle Figure 3. Finally, results analysis using topicsmodel rather ART model seen right. three matricessimilar, interesting differences.259fiMcCallum, Wang, & Corrada-EmmanuelTopic 5Grant Proposalsproposal0.0397data0.0310budget0.0289work0.0245year0.0238glenn0.0225nsf0.0209project0.0188sets0.0157support0.0156smyth0.1290mccallummccallum0.0746stowellmccallum0.0739laffertymccallum0.0532smythpereira0.0339laffertyTopic 31Meeting Setuptoday0.0512tomorrow0.0454time0.04130.0391meeting0.0339week0.0255talk0.0246meet0.0233morning0.0228monday0.0208ronb0.0339mccallumwellner0.0314mccallumcasutton0.0217mccallummccallum0.0200casuttonmccallum0.0200wellnerTopic 38ML Modelsmodel0.0479models0.0444inference0.0191conditional0.0181methods0.0144number0.0136sequence0.0126learning0.0126graphical0.0121random0.0121casutton0.0498mccallumicml04-webadmin 0.0366icml04-chairsmccallum0.0343casuttonnips04workflow0.0322mccallumweinman0.0250mccallumTopic 41Friendly Discoursegreat0.0516good0.03930.0223sounds0.0219work0.0196wishes0.0182talk0.0175interesting0.0168time0.0162hear0.0132mccallum0.0558culottamccallum0.0530casuttonmccallum0.0274ronbmccallum0.0255saundersmccallum0.0181pereiraTable 3: four topics prominent McCallums email exchange PadhraicSmyth, 50-topic run ART 9 months McCallums email. topics provide extremely salient summary McCallum Smyths relationshiptime period: wrote grant proposal together; set manymeetings; discussed machine learning models; friendlyother. topic shown 10 highest-probability words corresponding conditional probabilities. quoted titles summarytopics. prominent author-recipient pairs topic. peoplesmyth also appear sensible associations: stowell McCallumsproposal budget administrator; McCallum also wrote proposal John Lafferty Fernando Pereira; McCallum also sets meetings, discusses machinelearning friendly discourse graduate student advisees: ronb, wellner,casutton, culotta; not, however, discuss details proposal-writingthem.Consider Enron employee Geaccone (user 9 matrices Figure 3). Accordingtraditional SNA role measurement, Geaccone McCarty (user 8) similarroles, however, ART models indicate special similarity. Inspectionemail messages users reveals Geaconne Executive Assistant,McCarty Vice-Presidentrather different rolesand, thus output ARTappropriate. interpret results follows: SNA analysis showswrote email similar sets people, ART analysis illustrates useddifferent language wrote people.260fiTopic Role Discovery Social Networks16 : teb.lokey15 : steven.harris14 : kimberly.watson13 : paul.ybarbo12 : bill.rapp11 : kevin.hyatt10 : drew.fossum9 : tracy.geaccone8 : danny.mccarty7 : shelley.corman6 : rod.hayslett5 : stanley.horton4 : lynn.blair3 : paul.thomas2 : larry.campbell1 : joe.stepenovitch1616151514141313121211111010998877665544332211 2 3 4 5 6 7 8 9101112131415161123456789 10 11 12 13 14 15 16123456789 10 11 12 13 14 15 16Figure 3: Left: SNA Inverse JS Network. Middle: ART Inverse JS Network. Right:Inverse JS Network. Darker shades indicate higher similarity.Comparing ART AT, models provide similar role distance Geacconeversus McCarty, ART show differences elsewhere. example,indicates strong role similarity Geaconne Hayslett (user 6),boss (and CFO & Vice President Division); hand, ARTcorrectly designates low role similarity pairin fact, ART assigns low similarityGeaconne others matrix, appropriateexecutive assistant small sample Enron employees.Another interesting pair people Blair (user 4) Watson (user 14). ART predictsrole-similar, SNA models not. ARTs prediction seemsappropriate since Blair worked gas pipeline logistics Watson worked pipelinefacility planning, two similar jobs.McCarty, Vice-President CTO Division, also highlights differencesmodels. ART model puts closest Horton (user 5), PresidentDivision. predicts closest Rapp (user 12), merely lawyerreviewed business agreements, also close Harris (user 15), mid-levelmanager.Using ART way emphasizes role similarity, group membership.seen considering Thomas (user 3, energy futures trader), relationRapp (user 12, lawyer mentioned above), Lokey (user 16, regulatoryaffairs manager). three people work related areas, ART fittinglyindicate role similarity them, (ART marginally AT).hand, traditional SNA results (Figure 3 left) emphasizes group memberships ratherrole similarity placing users 1 3 rather distinct block structure;three people matrix members Enron Transwestern Divisiongroup, three exchanged email peopleTranswestern Division. separate work also developed Group-Topic (GT)model, explicitly discovers groups way leverages accompanying text (Wanget al., 2006). future may also develop model integrates ARTSNA metrics jointly model role group memberships.Based examples, similar examples, posit ART modelappropriate SNA predicting role similarity. thus would claim261fiMcCallum, Wang, & Corrada-Emmanuel120100806040200020406080100120Figure 4: SNA Inverse JS Network 10 topic run McCallum Email Data. Darkershades indicate higher similarity. Graph partitioning calculated 128authors ten emails McCallums Email Data. block0 30 people related McCallums research group UMass.block 30 50 includes researchers around world.ART model yields appropriate results SNA model predictingrole-equivalence users, somewhat better model capacity.also carried analysis personal email McCallum validatedifference ART SNA predictions. 825 users emailcorpus, 128 wrote ten emails. perform blockstructure analysis128 users, shown Figure 4. blocks discovered quite meaningful, e.g.,block 0 30 people related McCallums research group UMass,block 30 50 includes researchers around world.Table 4 shows closest pairs terms JS divergence, calculated ARTmodel SNA model. difference quality ART SNA halvestable striking.Almost pairs predicted ART model look reasonable manypredicted SNA opposite. example, ART matches editor reviews, twoemail addresses send messages managing journal reviews. User mike mikemactually two different email addresses person. coreferent email262fiTopic Role Discovery Social NetworksPairs considered alike ARTUser PairDescriptioneditor reviewsjournal review managementmike mikemperson! (manual coreference error)aepshtey smuckerstudents McCallums classcoe laurieUMass admin assistantsmcollins tom.mitchell ML researchers SRI projectmcollins gervasioML researchers SRI projectdavitz freemanML researchers SRI projectmahadeva palML researchers, discussing hiringkate laurieUMass admin assistantsang joshuagoorganizing committee conferencePairs considered alike SNAUser PairDescriptionaepshtey rasmithstudents McCallums classdonna editorSpouse unrelated journal editordonna krishnaSpouse unrelated conference organizerdonna ramshawSpouse unrelated researcher BBNdonna reviewsSpouse unrelated journal editordonna stromstenSpouse unrelated visiting researcherdonna yuguSpouse unrelated grad studentaepshtey smuckerstudents McCallums classrasmith smuckerstudents McCallums classeditor elmJournal editor Production EditorTable 4: Pairs considered alike ART SNA McCallum email. pairsproduced ART model accurately quite similar.top SNA pairs. Many users considered similar SNA merelyappear corpus mostly sending email McCallum. However,causes people different roles incorrectly declared similarsuchMcCallums spouse JMLR editor.addresses pre-collapsed hand preprocessing; ART pointedmistaken omission, indicating potential ART used helpful componentautomated coreference system. Users aepshtey smucker students classtaught McCallum. Users coe, laurie kate UMass CS Department administrativeassistants; rarely send email other, write similar things. Userang Andrew Ng Stanford; joshuago Joshua Goodman Microsoft Research;organizing committee new conference along McCallum.hand, pairs declared similar SNA model mostlyextremely poor. pairs include donna, indicate pairs peoplesimilar corpus appeared mostly sending email McCallum,others. User donna McCallums spouse. pairs sensible.263fiMcCallum, Wang, & Corrada-EmmanuelUser Paireditor reviewsjordan mccallummccallum vanessacroft mccallummccallum stromstenkoller mccallumdkulp mccallumblei mccallummccallum pereiradavitz mccallumDescriptionjournal editorsML researchersgrad student working IRUMass faculty, working IRML researchersML researchersUMass facultyML researchersML researchersworking SRI projectTable 5: Pairs highest rank difference ART SNA McCallum email.traditional SNA metric indicates pairs people different,ART indicates similar. strong relations pairs.example, aepshtey, smucker rasmith students McCallums class. User elmErik Learned-Miller correctly indicated similar editor since ProductionEditor Journal Machine Learning Research.highlight difference SNA ART predictions, present Table 5,obtained using ART SNA rank pairs people similarity,listing pairs highest rank differences two models.pairs SNA indicated different, ART indicated similar. every case,role similarities pairs.4.3 Perplexity Comparison ARTModels natural languages often evaluated perplexity measure goodnessfit models. lower perplexity language model has, better predicts unseenwords given words previously saw.perplexity previously unseen message consisting words wd definedfollows, author ad recipient(s) rd given:log(p(wd |ad , rd ))Perplexity(wd ) = exp,Nd( defined Equation 1)p(wd |ad , rd ) =Ndi=11 XXad rt twdi|rd | rr!.t=1randomly split data sets training set (9/10) test set (the remaining1/10). test sets, 92.37% (Enron) 84.51% (McCallum) author-recipient pairsalso appear training sets. Ten Markov chains run different initializations,264fiTopic Role Discovery Social Networks(a) Enron data set(b) McCallum data setFigure 5: Perplexity comparison ART two data sets. plot informationrate (logarithm perplexity) here. difference ARTsignificant one-tailed t-test (Enron data set: p-value < 0.01 except 10topics p-value = 0.018; McCallum data set: p-value < 1e 5).samples 2000th iteration used estimate Equation 1.report average information rate (logarithm perplexity) different number topicstwo data sets Figure 5.clearly shown figure, ART significantly better predictive powerlarge number randomly selected test documents data sets onetailed t-test. Particularly Enron data set, ART uses much fewer number topicsachieve best predictive performance. also find lowest perplexityobtained ART achievable parameter setting data sets.results provide evidence ART discovers meaningful topics contextsocial network indeed appropriate message data AT.compare perplexity ART LDA, however (which ARTdominates perplexity) already shown better perplexity LDA(Rosen-Zvi, Griffiths, Smyth, & Steyvers, 2005). Due much simpler model structure,author model (McCallum, 1999) much worse perplexity. Measured datasets, information rates (log perplexity) larger 10, whereas ARTs informationrates mostly 8 9.5. Role-Author-Recipient-Topic Modelsbetter explore roles authors, additional level latent variables introduced explicitly model roles. particular interest capturing notion personmultiple roles simultaneouslyfor example, person professormountain climber. role associated set topics, topics mayoverlap. example, professors topics may prominently feature research, meeting times,grant proposals, friendly relations; climbers topics may prominently feature mountains,climbing equipment, also meeting times friendly relations.265fiMcCallum, Wang, & Corrada-EmmanuelRole-Author-Recipient-TopicModel 1(RART1)rdadxRole-Author-Recipient-TopicModel 2(RART2)gadrdgdhdzR,RwrdgdhdhzadhR,RRole-Author-Recipient-TopicModel 3(RART3)NdzR,RwNdwNdFigure 6: Three possible variants Role-Author-Recipient-Topic (RART) model.incorporate ART model new set variables take values indicatingrole, term augmented model Role-Author-Recipient-Topic (RART) model.RART, authors, roles message-contents modeled simultaneously. authormultinomial distribution roles. Authors recipients mappedrole assignments, topic selected based roles. Thus clusteringmodel, appearances topics underlying data, sets correlated topicsgather together clusters indicate roles. sender-role recipient-role pairmultinomial distribution topics, topic multinomial distributionwords.shown Figure 6, different strategies employed incorporate rolelatent variables. First RART1, role assignments made separately worddocument. model represents person change role courseemail message. RART2, hand, person chooses one role durationmessage. recipient message selects role assignment,word, recipient (with corresponding role) selected condition selectiontopic. RART3, recipients together result selection common, sharedrole, used condition selection every word message. last modelmay help capture fact persons role may depend recipientsmessage, also restricts recipients single role.describe generative process RART1 paper detail, leavetwo exploration elsewhere. generative process message, author, ad ,set recipients, rd , observed. generate word, recipient, x, chosenuniform rd , role g author, role h recipient xchosen two multinomial role distributions ad x , respectively. Next, topic zchosen multinomial topic distribution gh , distribution specific266fiTopic Role Discovery Social NetworksRole 3Support UMass CSolc (lead Linux sysadmin)gauthier (sysadmin CIIR group)irsystem (mailing list CIIR sysadmins)system (mailing list dept. sysadmins)allan (prof., chair computing committee)valerie (second Linux sysadmin)tech (mailing list dept. hardware)steve (head dept. support)0.27300.11320.09160.05840.05150.03850.03600.0342Role 4Working SRI CALO Projectpereira (prof. UPenn)0.1876claire (UMass CS business manager)0.1622israel (lead system integrator SRI)0.1140moll (prof. UMass)0.0431mgervasio (computer scientist SRI)0.0407melinda.gervasio (same person above) 0.0324majordomo (SRI CALO mailing list)0.0210collin.evans (computer scientist SRI)0.0205Table 6: illustration two roles 50-topic, 15-group run McCallum emaildata set. role shown prominent users (their short descriptions parenthesis) corresponding conditional probabilities. quotedtitles summary roles. example, Role 3, usersemployees (or mailing lists) support staff UMass CS, except allan,who, however, professor chairing departments computing committee.author-role recipient-role pair (g, h). Finally, word w generated samplingtopic-specific multinomial distribution z .RART1 model, given hyper-parameters , , author ad , setrecipients rd message d, joint distribution topic mixture ijauthor-role recipient-role pair (i, j), role mixture k author k, word mixturetopic t, set recipients x, set sender roles g, set recipient roles h,set topics z set words w given (we define R number roles):P (, , , x, g, h, z, w|, , , a, r)=RRi=1 j=1p(ij |)t=1p(t |)k=1p(k |)NdP (xdi |rd )P (gdi |ad )P (hdi |xdi )P (zdi |gdi hdi )P (wdi |zdi )d=1 i=1Integrating , , summing x, g, h z, get marginaldistribution corpus, similar showed ART.perform inference RART models, Gibbs sampling formulae derivedsimilar way Appendix A, complex form.6. Experimental Results RARTExtensive experiments conducted RART1 model. introducetwo sets additional latent variables (author role recipient role), sampling procedure iteration significantly complex. make inference efficient,instead perform two distinct parts. One strategy found usefulfirst train ART model, use sample obtain topic assignments recipient assignments word token. Then, next stage, treat topics recipientsobserved (locked). Although strategy may recommended arbitrary graphical models, feel reasonable find single sample Gibbs267fiMcCallum, Wang, & Corrada-EmmanuelRoleRoleRoleRoleRoleallan (James Allan)10 (grant issues)13 (UMass CIIR group)2 (natural language researcher)3 (IT Support UMass CS)4 (working SRI CALO Project)0.45380.28130.07680.03260.0306RoleRoleRoleRoleRolepereira (Fernando Pereira)2 (natural language researcher)4 (working SRI CALO Project)6 (proposal writing)10 (grant issues)8 (guests McCallums house)0.57490.15190.06490.04440.0408Table 7: illustration role distribution two users 50-topic, 15-group runMcCallum email data set. user shown prominentroles (their short descriptions parenthesis) corresponding conditionalprobabilities. example, considering user pereira (Fernando Pereira), topfive role assignments appropriate, viewed McCallums email.sampling ART model yields good assignments. following results based15-group, 50-topic run RART1 McCallum email data set.results show RART model indeed automatically discover meaningfulperson-role information explicit inclusion role variable. showprominent users two roles Table 6. instance, users prominent Role 3employees (or mailing lists) support staff UMass CS, except allan,who, however, professor chairing departments computing committee. Role4 seems represent working SRI CALO project. top prominentmembers researchers working CALO project, many SRI. sendermajordomo sends messages SRI CALO mailing list. Users claire moll were,however, unrelated project, know reason appearrole. users mgervasio melinda.gervasio actually person; satisfyinglyRART found similar role distributions.One objective RART model capture multiple roles person has.role distribution two users shown Table 7. example, user allan (JamesAllan) mentioned role support, also role memberCenter Intelligent Information Retrieval, grant proposal writer, naturallanguage researcher. Although member SRI CALO Project, allans researchrelated CALO, perhaps reason CALO appears (weakly) amongroles. Consider also user pereira (Fernando Pereira); top five role assignmentsexactly appropriate, viewed McCallums email.expected, one observe interesting differences sender versus recipient topicdistributions associated role. instance, Role 4 SRI CALO, top threetopics sender role Topic 27 CALO information, Topic 11 mail accounts,Topic 36 program meetings, recipient roles, prominent Topic 48 taskassignments, Topic 46 CALO-related research paper, Topic 40 java code.7. Conclusionspresented Author-Recipient-Topic model, Bayesian network social networkanalysis discovers discussion topics conditioned sender-recipient relationships268fiTopic Role Discovery Social Networkscorpus messages. best knowledge, model combines first timedirectionalized connectivity graph social network analysis clusteringwords form topics probabilistic language modeling.model applied discovering topics conditioned message sending relationships, clustering find social roles, summarizing analyzing large bodiesmessage data. model would form useful component systems routing requests,expert-finding, message recommendation prioritization, understanding interactions organization order make recommendations improving organizationalefficiency.Role-Author-Recipient-Topic (RART) models explicitly capture multiple rolespeople, based messages sent received. Future work develop modelsexplicitly capture roles groups.Acknowledgmentsmaterial paper presented part 19th International Joint Conference Artificial Intelligence (IJCAI 2005) Edinburgh, Scotland, July 30August 5,2005. work supported part Center Intelligent Information Retrieval,Central Intelligence Agency, National Security Agency, National Science Foundation NSF grant #IIS-0326249, Defense Advanced Research ProjectsAgency, Department Interior, NBC, Acquisition Services Division,contract #NBCHD030010.Appendix A. Gibbs Sampling Derivation ARTneed derive P (xdi , zdi |xdi , zdi , w, , , a, r), conditional distribution topicrecipient word wdi given words topic recipient assignments, xdizdi , carry Gibbs sampling procedure ART. begin jointprobability whole data set. Note take advantage conjugate priorssimplify integrals.=P (x, z, w|, , a, r)ZZNdp(ij |)p(t |)P (xdi |rd ) P (zdi |ad xdi )P (wdi |zdi )ddt=1i=1 j=1=d=1 i=1!P( Tt=1 ) 1 nijt1 Nd()ijtijtQT|rd |t=1 (t ) t=1i=1 j=1i=1 j=1 t=1d=1! VPZV( Vv=1 v ) v 1 mtvtvtvQVv=1 (v ) v=1t=1t=1 v=1ZZV+nijt 1ijtdijtvv +mtv 1 dtZi=1 j=1t=1t=1v=1269fiMcCallum, Wang, & Corrada-EmmanuelQVQTv=1 (v + mtv )t=1 (t + nijt )PTPVi=1 j=1 ( t=1 (t + nijt )) t=1 ( v=1 (v + mtv ))|rd | number recipients message d, nijt number tokens assignedtopic author-recipient pair (i, j), mtv represent number tokens wordv assigned topic t.Using chain rule, obtain conditional probability conveniently. definewdi word tokens except token wdi .=P (xdi , zdi |xdi , zdi , w, , , a, r)P (xdi , zdi , wdi |xdi , zdi , wdi , , , a, r)P (x, z, w|, , a, r)P (wdi |xdi , zdi , wdi , , , a, r)P (xdi , zdi , wdi |, , a, r)(wdi +mzdi wdi )(zdi +nad xdi zdi )(zdi +nad xdi zdi 1)(wdi +mzdi wdi 1)PP(( V(t +nad xdi ))(v +mzdi v ))PT t=1PV v=1( t=1 (t +nad xdi )1) ( v=1 (v +mzdi v )1)z + nad xdi zdi 1w + mzdi wdi 1PT diPV dit=1 (t + nad xdi ) 1v=1 (v + mzdi v ) 1one wants, manipulation turn formula separated updateequations topic recipient token, suitable random systematic scanupdates:P (xdi |xdi , z, w, , , a, r)P (zdi |x, zdi , w, , , a, r)z + nad xdi zdi 1PT dit=1 (t + nad xdi ) 1w + mzdi wdi 1z + nad xdi zdi 1PT diPV dit=1 (t + nad xdi ) 1v=1 (v + mzdi v ) 1ReferencesAdamic, L., & Adar, E. (2004). search social network. http://arXiv.org/abs/condmat/0310120.Airoldi, E., Blei, D., Fienberg, S., & Xing, E. (2006). Stochastic blockmodels mixedmembership: General formulation nested variational inference. ICML Workshop Statistical Network Analysis.Albert, R., & Barabasi, A.-L. (2002). Statistical mechanics complex networks. ReviewsModern Physics, 74 (1), 4797.Andrieu, C., de Freitas, N., Doucet, A., & Jordan, M. (2003). introduction MCMCmachine learning. Machine Learning, 50, 543.Blei, D., & Lafferty, J. (2006a). Correlated topic models. Advances Neural InformationProcessing Systems 18.Blei, D. M., & Lafferty, J. D. (2006b). Dynamic topic models. Proceedings 23rdInternational Conference Machine Learning.Blei, D. M., Ng, A. Y., & Jordan, M. J. (2003). Latent Dirichlet allocation. JournalMachine Learning Research, 3, 9931022.270fiTopic Role Discovery Social NetworksErosheva, E., Fienberg, S., & Lafferty, J. (2004). Mixed membership models scientificpublications. Proceedings National Academy Sciences, 101(Suppl. 1).Griffiths, T., Steyvers, M., Blei, D., & Tenenbaum, J. (2004). Integrating topics syntax.Advances Neural Information Processing Systems (NIPS) 17.Griffiths, T. L., & Steyvers, M. (2004). Finding scientific topics. Proceedings NationalAcademy Sciences, 101 (suppl. 1), 52285235.Hofmann, T. (2001). Unsupervised learning probabilistic latent semantic analysis. Machine Learning, 42 (1), 177196.Holland, P., Laskey, K. B., & Leinhardt, S. (1983). Stochastic blockmodels: firststeps. Social Networks, 5, 109137.Kemp, C., Tenenbaum, J. B., Griffiths, T. L., Yamada, T., & Ueda, N. (2006). Learningsystems concepts infinite relational model. Proceedings 21stNational Conference Artificial Intelligence.Kemp, C., Griffiths, T. L., & Tenenbaum, J. (2004). Discovering latent classes relationaldata. Tech. rep., MIT AI Memo 2004-019.Kleinberg, J. (2000). Navigation small world. Nature, 406, 845.Kubica, J., Moore, A., Schneider, J., & Yang, Y. (2002). Stochastic link group detection.Proceedings 18th National Conference Artificial Intelligence, pp. 798804.Kurihara, K., Kameya, Y., & Sato, T. (2006). frequency-based stochastic blockmodel.Workshop Information Based Induction Sciences.Li, W., & McCallum, A. (2006). Pachinko allocation: DAG-structured mixture modelstopic correlations. Proceedings 23rd International Conference MachineLearning.Lorrain, F., & White, H. C. (1971). structural equivalence individuals socialnetworks. Journal Mathematical Sociology, 1, 4980.McCallum, A. (1999). Multi-label text classification mixture model trained EM.16th National Conference Artificial Intelligence Workshop Text Learning.Mimno, D., & McCallum, A. (2007). Expertise modeling matching papers reviewers.Proceedings 13th ACM SIGKDD International Conference KnowledgeDiscovery Data Mining, pp. 500509.Minka, T., & Lafferty, J. (2002). Expectation-propagation generative aspect model.Proceedings 18th Conference Uncertainty Artificial Intelligence.Nowicki, K., & Snijders, T. A. (2001). Estimation prediction stochastic blockstructures. Journal American Statistical Association, 96 (455), 10771087.271fiMcCallum, Wang, & Corrada-EmmanuelRosen-Zvi, M., Griffiths, T., Smyth, P., & Steyvers, M. (2005). Learning author-topicmodels text corpora. Submitted Journal Machine Learning Research.Rosen-Zvi, M., Griffiths, T., Steyvers, M., & Smyth, P. (2004). author-topic modelauthors documents. Proceedings 20th Conference UncertaintyArtificial Intelligence.Shetty, J., & Adibi, J. (2004). Enron email dataset database schema brief statisticalreport. Tech. rep., Information Sciences Institute.Steyvers, M., Smyth, P., Rosen-Zvi, M., & Griffiths, T. (2004). Probabilistic author-topicmodels information discovery. Proceedings 10th ACM SIGKDD International Conference Knowledge Discovery Data Mining.Teh, Y. W., Jordan, M. I., Beal, M. J., & Blei, D. M. (2004). Hierarchical Dirichlet processes.Tech. rep., UC Berkeley Statistics.Wang, X., & McCallum, A. (2006). Topics time: non-markov continuous-time modeltopical trends. Proceedings 12th ACM SIGKDD International ConferenceKnow ledge Discovery Data Mining, pp. 424433.Wang, X., McCallum, A., & Wei, X. (2007). Topical n-grams: Phrase topic discovery, application information retrieval. Proceedings 7th IEEEInternational Conference Data Mining.Wang, X., Mohanty, N., & McCallum, A. (2006). Group topic discovery relationsattributes. Advances Neural Information Processing Systems 18, pp.14491456.Wasserman, S., & Faust, K. (1994). Social Network Analysis: Methods Applications.Cambridge University Press.Watts, D. J. (2003). Six Degrees: Science Connected Age. W. W. Norton &Company.Watts, D. J., Dodds, P. S., & Newman, M. E. J. (2002). Identify search socialnetworks. Science, 296 (5571), 13021305.Wolfe, A. P., & Jensen, D. (2004). Playing multiple roles: Discovering overlapping rolessocial networks. 21st International Conference Machine Learning WorkshopStatistical Relational Learning Connections Fields.Wu, F., Huberman, B. A., Adamic, L. A., & Tyler, J. R. (2003). Information flow socialgroups. http://arXiv.org/abs/cond-mat/0305305.272fiJournal Artificial Intelligence Research 30 (2007) 501-523Submitted 06/07; published 12/07Semantics Logic Programs PreferencesSergio Grecogreco@deis.unical.itDEIS, Universita della Calabriavia P. Bucci, 87030 Rende - ItalyIrina Trubitsynairina@deis.unical.itDEIS, Universita della Calabriavia P. Bucci, 87030 Rende - ItalyEster Zumpanozumpano@deis.unical.itDEIS, Universita della Calabriavia P. Bucci, 87030 Rende - ItalyAbstractwork contribution prioritized reasoning logic programming presencepreference relations involving atoms. technique, providing new interpretationprioritized logic programs, inspired semantics Prioritized Logic Programmingenriched use structural information preference Answer Set Optimization Programming. Specifically, analysis logic program carried togetheranalysis preferences order determine choice order setscomparable models. new semantics compared approaches knownliterature complexity analysis also performed, showing that, respectsimilar approaches previously proposed, complexity computing preferred stable models increase.1. Introductionincreased interest preferences witnessed extensive number proposalssystems preference handling (Grell, Konczak, & Schaub, 2005; Van Nieuwenborgh &Vermeir, 2003; Wakaki, Inoue, Sakama, & Nitta, 2003, 2004). literature distinguishesstatic dynamic preferences. Static preferences fixed time theory specified, i.e. external logic program, whereas dynamic preferences appearwithin logic program determined fly. common formpreference consists specifying preference conditions among rules (Brewka, 1996; Brewka& Eiter, 1999, 2000; Delgrande, Schaub, & Tompits, 2000a, 2000b, 2003; Gelfond & Son,1997; Schauba & Wang, 2001; Van Nieuwenborgh & Vermeir, 2002, 2004; Wang, Zhou, &Lin, 2000; Zhang & Foo, 1997), whereas, recent proposals admit expressionpreference relations among atoms (Brewka, Niemela, & Truszczynski, 2003; Brewka, 2004;Sakama & Inoue, 2000; Wakaki et al., 2003). sophisticated forms preferences alsoallow specification priorities conjunctions (disjunctions) literals (Brewkaet al., 2003; Delgrande et al., 2000a; Sakama & Inoue, 2000) numerical penaltiessuboptimal options (Brewka, 2004).work contribution prioritized reasoning logic programming presencepreference conditions involving atoms. particular, priorities applied followingnatural ordering defined dependencies, proposed Answer Set Optimizac2007AI Access Foundation. rights reserved.fiGreco, Trubitsyna, & Zumpanotion (ASO) semantics (Brewka et al., 2003), comparison strategy, proposedPreferred Stable Model (PSM) semantics (Sakama & Inoue, 2000), reviewed also introducing concept comparable models. next example describes intuitionbasis proposed approach.Example 1 following prioritized program hP 1 , 1 i, inspired program presentedBrewka et al. (2003), describes different menus preferences among drinksdesserts:P1 :fish beefred whitepie ice-creamfish, whitebeef, piefish, ice-cream1 :%1 : white > red fish%2 : red > white beef%3 : pie > ice-cream redsymbol denotes exclusive disjunction, i.e. body rule true exactlyone atom head true, whereas rule empty head defines constraint, i.e.rule satisfied body false. first three rules P 1 select maindish, drink dessert; last three rules constraints state feasiblesolution cannot contain i) fish white ii) beef pie iii) fish ice-cream.Prioritized rules 1 introduce preferences among drinks (%1 , %2 ) desserts (%3 ).program P 1 three stable models: M1 = {fish, red, pie}, M2 = {beef, white,ice-cream} M3 = {beef, red, ice-cream}. PSM returns M1 unique preferred model; whereas ASO technique, following natural ordering preference rules(%1 %2 precede %3 ), derives M3 unique solution. Thus, two approachesprovide different results.2structure preference rules example suggests i) fish beefalternative options main dish ii) choice drink depends selected maindish precedes choice dessert. second conclusion based observation%1 %2 provide opposite valuations choice drink define two differentclasses models (menus), considered separately. words, modelM1 (associated menu containing fish) compared modelsM2 M3 (associated menus containing beef). Consequently, M1 M3preferred.Observe example PSM semantics derives M1 preferredmodel M1 preferable M3 (due presence rule %3 ), M3 preferable M2(due presence rule %2 ) and, transitively, M1 also preferable M2 .worth noting use transitive closure makes comparison models muchcomplex two models cannot compared directly. hand ASOsemantics sensitive syntactic changes programs. fact illustrated meansfollowing example.Example 2 Consider prioritized program hP2 , 2 i, extension prioritized program defined Example 1:502fiOn Semantics Logic Programs PreferencesP2 :fish beefred white beerpie ice-creamfish, whitebeef, piefish, ice-creambeer2 :%b1 : beer > white > red fish%b2 : beer > red > white beef%b3 : pie > ice-cream redprogram equivalent one reported Example 1 as, even contains additional choice (beer), option feasible, presence constraint beer.set stable models associated program P2 , coincides reportedprogram P 1 Example 1, consists of: M1 = {fish, red, pie}, M2 = {beef,white, ice-cream} M3 = {beef, red, ice-cream}. Considering set preferencerules, note preferences regarding choice drink beer best option,stable model containing it. Intuitively, two problems hP 1 , 1 Example 1 hP2 , 2 equivalent must preferred models. ASOsemantics sensitive program change gives M1 M3 solution, whereas,equivalent program Example 1, returned preferred model M3 only.change occurs set preferred models PSM semantics.2Thus, paper present new semantics, inspired PSM ASO semantics, seems better capture intuitive meaning programs avoidsmentioned problems.1.1 Contributionpaper provides new semantics prioritized logic programs enriching one proposed Sakama Inoue (2000) additional information gained structurepreference rules proposed Brewka et al. (2003). particular, new semanticsuses different preference relations among stable models introduces natural orderingamong preferences fixes order choices, basis stratificationpreference program. decision determined set choices belongingcorresponding level provides subset models given input solution.decision made, output subset becomes input set following decisionon. proposed semantics drives decision making process taking account catchingadditional information regarding non comparable sets models partitioning setmodels program looking alternative decisions. end conceptincomparability, taken account previous approaches, introduced.paper presents detailed comparison approaches dealing preferencerelations among atoms. Particular attention devoted PSM ASO semantics.analysis complexity computing preferred answer sets also performed, showingthat, w.r.t. previous proposals, PSM ASO semantics, complexitycomputing preferred stable models increase.503fiGreco, Trubitsyna, & Zumpano1.2 Plan Paperrest paper organized follows: Section 2 preliminaries DisjunctiveAbductive Logic Programs, Prioritized Logic Programs Answer Set Optimizationsemantics given; Section 3 new interpretation prioritized logic programspresented; Section 4 complexity results provided; Section 5 comparisonpresented semantics PSM ASO semantics performed, approaches,known literature, briefly described; finally, Section 6 outlines conclusions.2. Preliminariesassume familiarity relational database theory, disjunctive logic programs, disjunctive deductive databases, (disjunctive) stable model semantics computational complexity (Eiter, Gottlob, & Mannila, 1997b; Gelfond & Lifschitz, 1988, 1991; Papadimitriou,1994).2.1 Background(disjunctive) logic program finite set rules r form a1 ak b1 , ..., bm ,c1 , ..., cn k + + n > 0, a1 , ..., ak , b1 , ..., bm , c1 , ..., cn atoms.disjunction a1 ak , denoted head(r), called head r, conjunctionb1 , ..., bm , c1 , ..., cn , denoted body(r), called body r.Herbrand Universe program P set constants appearing P 1 ,Herbrand Base BP set ground atoms constructed predicatesappearing P constants . term (resp. atom, rule program)ground variables occur it. rule r0 ground instance rule r, r0 obtainedr replacing every variable r constant ; ground(P) denotesset ground instances rules P.intuitive meaning previous disjunctive rule body(r) true, i.e.b1 , ..., bm true c1 , ..., cn false, head(r) must true, i.e least onea1 , ..., ak true (otherwise r satisfied). Rules empty head, called denialsconstraints, used define constraints satisfied body false.paper exclusive disjunction, denoted , used head; statement head(r) =a1 ... ak true, exactly one a1 , ..., ak true, i.e. disjunctive rule forma1 ak body shorthand rule a1 ak body (k (k 1)/2)constraints form ai , aj , body 1 < j k. solution logic program Pgiven terms stable model (answer set) semantics (Gelfond & Lifschitz, 1988, 1991).interpretation P model P satisfies rules ground(P).minimal model semantics, defined positive P, assigns P set minimal modelsMM(P), model P minimal, proper subset model P(Minker, 1982). general disjunctive stable model semantics also applies programs (unstratified) negation (Gelfond & Lifschitz, 1991). Disjunctive stable modelsemantics generalizes stable model semantics, previously defined normal programs (Gelfond & Lifschitz, 1988). interpretation , denote P ground positiveprogram derived ground(P) i) removing rules contain negated atom1. considering function free programs.504fiOn Semantics Logic Programs Preferencesbody , ii) removing negated atoms remaining rules.interpretation (disjunctive) stable model P MM(P ).general P, stable model semantics assigns P set SM(P) stable models. well known stable models minimal models (i.e. SM(P) MM(P))negation free programs, minimal stable model semantics coincide (i.e.SM(P) = MM(P)).2.2 Extended Abductive ProgramsGiven atom p(t), literal either p(t) strong negation p(t). extendedprogram program atoms replaced literals. semantics extendeddisjunctive programs also given terms stable models considering p pdifferent predicate symbols considering implicit constraint p(X), p(X) (Gelfond& Lifschitz, 1991).Abductive logic programming extension logic programming perform abductivereasoning (Kakas, Kowalski, & Toni, 1992; Inoue & Sakama, 1998). abductive program(ALP) pair hP, Ai, P extended program set literals calledabducibles. hP, Ai represented means extended program = P {g(t)g 0 (t) | g(t) A} {g 0 (t) g(t) | g(t) A}.Let ALP G ground atom denoting observation. Then, setexplanation G iff stable model = G ; stablemodel A-minimal stable model N N A. Moreover,minimal explanation (i.e. explanation 0 S) G iff { G}consistent A-minimal stable model = (Inoue & Sakama, 1998).shown given ALP P ground atom G denoting observation,deciding whether exists A-minimal explanation G p3 -complete (Eiter,Gottlob, & Leone, 1997a).rest section briefly review two main approaches prioritizing reasoning refer to, i.e. Prioritized Logic Programs Answer Set Optimization, proposed,respectively, Sakama Inoue (2000) Brewka et al. (2003).2.3 Prioritized Logic Programs(partial) preference relation among atoms defined follows: given two atoms e1e2 , statement e1 e2 (called priority) means e1 higher priority e2 .Moreover, e1 e2 e2 e3 , e1 e3 . priority statement e1 e2 statesa1 instance e1 a2 instance e2 preference relation a1 a2 holds.prioritized logic program (PLP) pair hP, P disjunctive programset priorities. denotes set priorities reflexively transitivelyderived .statement e1 e2 stands e1 e2 e2 6 e1 . Clearly, e1 e2 , setsground instantiations e1 e2 empty intersection.Definition 1 Given prioritized logic program hP, i, relation w definedstable models P follows. stable models M1 , M2 M3 P:505fiGreco, Trubitsyna, & Zumpano1. M1 w M1 ,2. M1 w M2 e1 M1 M2 , e2 M2 M1 (e1 e2 ) 6 e3M2 M1 (e3 e1 ) ,3. M1 w M2 M2 w M3 , M1 w M3 .M1 w M2 M1 preferable M2 . Moreover, M1 w M2 M2 6w M1M1 = M2 .2interpretation preferred stable model hP, stable model PN w implies w N stable model N (equivalently, interpretation Nstable model P N = ). set preferred stable models hP,denoted PSM(hP, i). Note relation 1 2 two PLPs hP, 1hP, 2 imply PSM(hP, 2 i) PSM(hP, 1 i).PLP priority relations used express priorities atoms, whereas prioritiesgeneral forms knowledge (conjunctive, disjunctive knowledge, rules, preconditions)expressed simple rewriting preference program. instance, preferencerule precondition form (e1 e2 ) B expressed PLP e01 e02 ,e01 e1 , B e02 e2 , B.semantics prioritized programs proposed Sakama Inoue (2000)denoted PSM semantics. sound complete procedure allows preferred answersets PLP program computed using generate test algorithmproposed Wakaki et al. (2003). algorithm translates PLP program hP,answer set program P single logic program [P, , S],answer sets answer sets P preferable S. details found workspresenting semantics implementation (Sakama & Inoue, 2000; Wakaki et al.,2004).complexity answering queries PLP programs least one levelcomplexity answering queries standard programs (without preferences).particular, let hP, prioritized logic program, i) deciding existencepreferred stable model p2 -hard; ii) deciding whether atom true (resp. all)preferable stable model hP, p3 -hard (resp. p3 -hard). worth notingoriginal work (Sakama & Inoue, 2000) claimed complexity exactly onelevel complexity standard programs, proof take accounttransitivity property preference relation.2.4 Answer Set Optimizationanswer set optimization program, denoted ASO program, pair hP, i, Pdisjunctive program, called Generating Program, Preference Program consistingfinite set rules form: a1 > > ak b1 , ..., bm , c1 , ..., cn bi cjliterals ai boolean combinations2 literals; literal either atom L(strong) negation L. determines preference ordering answer sets describedgenerating program P.2. boolean combination formula built atoms means disjunctions, conjunctions, defaultnegation.506fiOn Semantics Logic Programs PreferencesDefinition 2 Let hP, ASO program = {%1 , ..., %n } answerset P, induces satisfaction vector VS = (vS (%1 ), ..., vS (%n )) where:vS (%j ) = I, %j Irrelevant S, i.e. i) body %j satisfied ii)body %j satisfied, none atoms head %j satisfied S.vS (%j ) = min{i | |= ai %j = a1 > > ak b1 , .., bm , c1 , .., cn }, otherwise. 2comparison models assumed equal 1 (i.e., vS (%j ) =equivalent vS (%j ) = 1).Definition 3 Let S1 S2 two answer sets, i) VS1 VS2 vS1 (%i ) vS2 (%i )every [1..n]; ii) VS1 < VS2 VS1 VS2 [1..n] vS1 (%i ) < vS2 (%i ).cases S1 w S2 S1 = S2 3 , respectively.set literals optimal model ASO program hP, answer setP answer set 0 P 0 = S.2complexity ASO programs depends class generating programs.disjunctive programs complexity answering queries ASO programs exactlyone level complexity answering queries standard programs (without preferences), i.e. i) deciding existence preferred stable model p2 -complete; ii) decidingwhether literal true (resp. all) preferable stable model hP, p3 -complete(resp. p3 -complete).strategy extended introducing meta-preferences among preferencerules: ranked ASO program sequence hP, 1 , ..., n consisting generating programP sequence pairwise disjoint preference programs . rank rule %1 n , denoted rank(%), unique integer % . Given two answersets S1 S2 , S1 wrank S2 every preference rule %0 vS1 (%0 ) vS2 (%0 )hold, rule %00 rank(%00 ) < rank(%0 ) vS1 (%00 ) < vS2 (%00 ).Moreover, procedure deriving natural ordering preference rules introduced.Firstly, given preference program , dependency graph G() defined. atomsappearing form vertex set G(). directed edge vertex bvertex G() rule % appears head r b appearsbody r. graph G() acyclic, natural ranking atomsdefined recursively follows: rank(a) = 0 every atom predecessorsG(); otherwise rank(a) maximum ranks predecessors G()incremented 1. rank preference rule % defined maximum rankatoms head.standard semantics ASO programs, priorities examined together,denoted ASO semantics. alternative semantics, priorities dividedstrata following natural order, denoted RASO (ranked ASO) semantics.3. original work (Brewka et al., 2003) symbols > used instead w =.507fiGreco, Trubitsyna, & Zumpano3. Preferred Answer Setspaper syntax similar one proposed Brewka et al. (2003) used. Giventwo atoms a1 a2 , statement a2 > a1 means a2 higher priority a1 .(partial) preference relation > among atoms defined follows.Definition 4 prioritized program pair hP, P disjunctive programset preference rules form:a1 > a2 > > ak b1 , ..., bm , c1 , ..., cnk > 1 a1 , ..., ak , b1 , ..., bm , c1 , ..., cn atoms.(1)2following head body preference rule % denoted head(%)body(%), respectively. ground prioritized program, denoted ground(hP, i) =hground(P), ground()i prioritized program, rule r (P ) variablesreplaced set ground instances, i.e set rules obtained replacingvariables constants.Intuitively, preference rule % form (1) describes choice among a1 , ..., ak(choice options) condition specified body %. head % introducespreference order among atoms: ai preferred aj 1 < j k. %applied body(%) true, body % specifies decisions precedechoice. instance, > c b states b true, preferred c.preference rule exactly two atoms head called binary preference rule,whereas preference rules empty bodies called preference facts. prioritizedprogram said binary form preference rules binary.following example, presenting classical program proposed Brewka et al. (2003),used running example.Example 3 Consider prioritized program hP 3 , 3 whose stable models definemenus restaurant:P 3:fish beefred white beerpie ice-creambeef, piefish, ice-cream3 :%1%2%3%4::::white > red > beer fishred > white beefbeer > white beefpie > ice-cream beerfirst three rules P 3 select main dish, drink dessert; constraintsstate feasible solution cannot contain beef pie fish ice-cream;rules 3 introduce preferences among drinks desserts.program P 3 six stable models:M1 = {fish, white, pie}M2 = {fish, red, pie}M3 = {fish, beer, pie}M4 = {beef, white, ice-cream}M5 = {beef, red, ice-cream}M6 = {beef, beer, ice-cream}techniques proposed Sakama Inoue (2000) Brewka et al. (2003) selectstable models M1 M5 preferred ones, motivation different. Indeed,PSM semantics states M1 w M2 w M3 w M6 w M4 M5 w M4 , whereas508fiOn Semantics Logic Programs Preferences(R)ASO semantics states Mi w M2 w M3 , Mi w M6 Mi w M4 {1, 5}, i.e.(R)ASO semantics models M1 M6 compared directly, whereas PSMsemantics models M1 M6 compared transitively.2presenting formal semantics programs, preliminary definitionsneeded. preference rule form a1 > a2 > > ak body shorthand k 1binary rules form ai > ai+1 body, [1..k 1] set preferencesestablished given transitive closure defined follows:Definition 5 Given prioritized program hP, i, (ground) transitive closure= 0 {a > c body1 , body2 | > b body1 b > c body2 6= c},0 set binary preference rules derived ground().2Thus, defined set rules explicitly representing preference relationsamong choice options. Section 4 show ground prioritized program= hP, rewritten equivalent program = hP, containsnumber rules polynomial size .structure prioritized programs examined order establish precedence relation among choices made. instance, presence preference rule> c b suggests selection b precedes choice c thusestablishes precedence relation {b} {a, c}. idea used Brewkaet al. (2003) determining natural ordering among preference rules. detail,relational order among atoms appearing captured means corresponding dependency graph G(); stratification preference rules establishedconsidering head atoms.Unfortunately, natural ordering among preference rules establishedcorresponding dependency graph acyclic. Thus, presence two rules coffee >tea pie pie > ice-cream coffee admit stratification ,introduce two mutually dependent choices.stratification algorithm proposed paper overcomes problem introducing concept collapsed graph, maps node options mutuallydependent choices.Given (ground) prioritized program = hP, i, G = (V, E) denotes dependencygraph whose set nodes consists atoms P whereas arc blabeled (resp. p) rule (resp. P) containing head bbody (resp. b either head body). body (preference) facts empty,assume bodies contain built-in atom true, every factCconsidered rule true. G denotes (acyclic) collapsed dependency graph derivedG replacing maximal sets mutual dependent nodes (i.e. nodes belongingCcycle) unique node. Clearly, node G associated set nodesG .Cnode G possible assign level follows:Cnode G input degree zero, level(A) = 0;509fiGreco, Trubitsyna, & ZumpanoCnode G input degree greater zero,CClevel(A) = max{max{level(B)+1|(B, Z, ) G }, max{level(B)|(B, Z, p) G }}.Observe function level assigns node maximum distancenode input degree zero. following definition introduces concept stratificationpreference rules.Definition 6 Stratification. Given (ground) prioritized program = hP, i,partitioned h [0], [1], ..., [n]i subprograms (called strata)Catom , level(a) = level(A), node G associated a;rule % , level(%) = max{ level(a) | Body(%) };[i] = { % | % level(%) = } consists ground preference rules associatedlevel i.2partition h [0], [1], ..., [n]i called stratification.definition stratification preference rules establishes orderpreferences applied considering P . Moreover, assignment levelrule differs one proposed Brewka et al. (2003) two main aspects:level atoms defined analyzing collapsed dependency graph levelrules established considering body atoms instead head atoms. detailedcomparison two approaches presented Section 5.Example 4 Consider prioritized program hP 3 , 3 Example 3. transitive closure3 consists binary preference rules %1,1 : white > red fish, %1,2 : red > beerfish %1,3 : white > beer fish, derived %1 , rules %2 , %3 %4 . 3stratified two strata 3 [1] = {%1,1 , %1,2 , %1,3 , %2 , %3 } 3 [2] = {%4 }.2structural analysis performed approach goes beyond stratification processtries understand comparability models. end concepts conflictingpreferences comparable models introduced.Two ground (binary) preferences form > b body1 b > body2said conflicting. instance, preferences %1 : white > red fish%2 : red > white beef Example 1 conflicting, whereas preferences %1%02 : red > water beef not. set preferences said conflictingcontains two conflicting preference rules.intuition basis approach clarified example. Supposetwo conflicting preferences %1 : > b c %2 : b > d. two conflictingpreferences %1 %2 specify preference b two different sets models,b, characterized presence c d, respectively. Thus, c d, (andatoms c depend) define alternative decisions. decisionmade, associated solutions (models) longer comparable.preference rule % said relevant stable model , % usedcompare stable models, |= body() head510fiOn Semantics Logic Programs Preferencesatoms belongs . Given prioritized program hP, (ground) preference rule% : > b body , set stable models, % relevant, SM(P, %) ={M | SM(P) |= body (a b)}.Definition 7 Comparable models. Let hP, prioritized program, M1 M2 twostable models P h [0], ..., [n]i stratification ,1. M1 M2 comparable [0];2. M1 M2 comparable [i + 1] [1..n],(a) comparable [i],(b) exist two conflicting preference rules %1 , %2 [i]M1 SM(P, 1 ) SM(P, 2 ) M2 SM(P, 2 ) SM(P, 1 ).2Observe that, second condition previous definition comparable modelsstates presence two conflicting preference rules given level identifies twosets models, one two conflicting rules relevant. Two models,appearing different sets considered separately next levels.words, two stable models M1 M2 , relevant preferences conflicting rules%1 : > b body1 %2 : b > body2 given level i, comparable levelsgreater i, M1 SM(P, 1 ) SM(P, 2 ) M2 SM(P, 2 ) SM(P, 1 ),M1 |= body1 (a b) body2 M2 |= body2 (a b) body1 .Example 5 Consider stable models M3 = {fish, beer, pie}, M6 = {beef, beer,ice-cream}, set preference rules 3 Example 4. stable models M3M6 comparable 3 [0] definition, comparable 3 [1],%1,3 relevant M3 (as M3 |= fish (white beer) beef), %3relevant M6 (as M6 |= beef (white beer) fish), conflictingpreferences belong 3 [0].2Fact 1 Let hP, prioritized program without conflicting preferences h [0],[1], ..., [n]i stratification . Then, two models M1 M2 comparable[i], [0..n].2Proof. proof fact follows directly Definition 7.2basis Definition 7 declarative semantics prioritized logic programsprovided. new semantics, denoted PAS (Preferred Answer Sets), givenpreferred stable models follows:Definition 8 Preference Answer Sets. Given prioritized program hP, i,relation w defined stable models P follows. pair stable modelsM1 M2 P, h [0], [1], ..., [n]i stratification , M1 w M21. %1 : (e1 > e2 ) body1 [i] e1 M1 M2 , e2 M2 M1 ,M1 M2 comparable [i], %1 relevant M1 M2 ,511fiGreco, Trubitsyna, & Zumpano2. 6 %2 : (e3 > e4 ) body2 [j], j < i, e3 M2 M1 , e4 M1 M2%2 relevant M1 M2 .Moreover, M1 strictly preferable M2 (M1 = M2 ) M1 w M2 M2 6w M1 .2Note also relation = could defined directly replacing condition j <j Item 2 definition.Definition 9 Preferred Answer Sets. interpretation preferred stable modelprioritized program hP, stable model P exist stablemodel N N = . set preferred stable models hP, denotedPAS(hP, i).2Note Definition 8 introduces preferences pairs models also consideringadditional information gained structure preference rules.Example 6 Consider prioritized program hP3 , 3 Example 3 stratificationh3 [0], 3 [1]i presented Example 4.models comparable [0] definitionowing %1,1 , %1,2 , %1,3 , M1 = M2 = M3 ;owing %2 , %3 , M5 = M4 M6 = M4 ;%1,3 %3 conflicting, models M1 M3 , %1,3 relevant, cannotcompared [1] models M4 M6 , %3 relevant.Therefore, discussed Example 5, M3 M6 comparable 3 [1] and,consequently, preferred models are: M1 , M5 M6 .2previous example stable model M6 considered good M5beef main dish, best choice drink (red wine beer, respectively)dessert (ice-cream). Observe ASO PSM semantics discard M6 .already stated, ASO semantics deduces M1 M5 preferable M6 owing%3 , PSM semantics states M1 preferable M3 M3 preferableM6 , owing %1 , %3 .b 3iExample 7 Let hP 3 , 3 program Example 3, consider program hP 3 ,b 3 derived 3 replacing %4%04 : pie > ice-creamb [0] = {%1,1 , %1,2 , %1,3 , %2 , %3 , %0 },new ground preference program unique level34%1,1 , %1,2 %1,3 derived %1 , shown Example 4. Due %04 , following relations also hold: Mi = Mj {1, 2, 3} j {4, 5, 6}. Therefore, M1unique preferred model. result obtained PSM ASO semantics. 2512fiOn Semantics Logic Programs Preferences4. Complexitysection provides results concerning computational complexity computingpreferred stable models answering queries PAS semantics. consider datacomplexity input domain consists Herbrand universe (we assumeconstants occurring also occur P). Clearly, size Herbrand base BPwell sizes ground(P) ground() polynomial size .following results demonstrate allowing preferences among atoms semantics proposed increases complexity expressivity language one levelpolynomial hierarchy. Thus use additional information increasecomputational complexity proposed approach respect mentionedtechniques (Brewka et al., 2003; Sakama & Inoue, 2000).Proposition 1 Let = hP, prioritized program, exists program =hP, equivalent hground(P), i) stratification computedpolynomial time, ii) hP, derived hground(P), polynomial time.Proof. start considering program 0 = hground(P), 0 i, 0 binaryCground version . size graphs G0 G0 polynomial size 0Ccomputed polynomial time. assignment levels nodes G0done polynomial time, assignment levels atoms rules 0 alsodone polynomial time.Let h0 [0], ..., 0 [n]i stratification 0 . generate new ground prioritizedprogram hP, equivalent hground(P), size polynomial size 0 .Initially, assign ground atom ai appearing head preference rule 0unique index i. Let a1 , ..., ap (indexed) atoms appearing head rules 0 ,P denotes program ground(P) PP = {b(i, j, l) bodyi,j | ai > aj bodyi,j 0 [l] }{b(i, j, l) b(i, k, l1), b(k, j, l2), l = max(l1, l2) | i, j, k [1..p], l1 , l2 [1..n]}b new predicate symbol. Then, denotes new set ground preference rulesdefined follows:= {ai > aj b(i, j, l) | i, j [1..p] l [0..n] }stratification obtained associating stratum l preference ruleswhose body atom value level attribute equal l, [l] = {ai > ajb(i, j, l) | ai > aj b(i, j, l) }.order show equivalence hground(P), hP, i, observeset stable models ground(P) P equivalent, i.e. SM(P)stable model N SM(ground(P)) N = {b(i, j, l) | b(i, j, l) }N SM(ground(P)) stable model SM(P) N ={b(i, j, l) | b(i, j, l) }, rules ground(P) contain atoms formb(i, j, l) bodies.513fiGreco, Trubitsyna, & ZumpanoMoreover, let N stable model ground(P) corresponding stablemodel P (N ), ground preference rule ai > aj bodyi,j [l] whosebody true N , ground rule ai > aj b(i, j, l) [l] whose body also truevice versa. Therefore two sets [l] [l] equivalent, l [1..n].Clearly, program hP, derived hground(P), polynomial time.2following, sake simplicity presentation, continue referprogram hP, stratification .Proposition 2 Let hP, prioritized program, M1 M2 two stable models P,h [0], [1], ..., [n]i stratification . problem checking whether,given k n, M1 M2 comparable [0], ..., [k] solved polynomial time.Proof. Obviously M1 M2 comparable [0]. Assuming M1 M2comparable given level j < k, M1 M2 comparable level j + 1two conflicting preference rules 1 = > b body1 2 = b > body2 [j]M1 |= body1 (a b) body2 M2 |= body2 (a b) body1 . checkdone polynomial time number rules [j] polynomial size. Moreover, maximum value k bounded size (which boundedset atoms BP ), global complexity also polynomial.2Corollary 1 Let hP, prioritized program, M1 M2 two interpretations P.problem checking whether M1 = M2 solved polynomial time.Proof. Straightforward Definition 8 Proposition 2.2Lemma 1 Let hP, prioritized program interpretation P. problemdeciding whether preferred stable model hP, p2 .Proof. Consider complementary problem deciding whether preferredstable model hP, i. case sufficient first check stable model.stable model sufficient guess interpretation N check i) Nstable model P ii) N = . check part i) (as well checkstable model) done means N P oracle problem decidingwhether interpretation stable model disjunctive program coN P-complete,whereas check part ii) done polynomial time (see Corollary 1). Therefore,complexity complementary problem N P N P and, consequently, complexityoriginal problem coN P N P .2Theorem 1 Let hP, prioritized program.1. Deciding whether ground atom G true preferred stable models hP,p3 -complete;2. Deciding whether ground atom G true preferred stable models hP,p3 -complete.514fiOn Semantics Logic Programs PreferencesProof. Membership: first demonstrate deciding whether G truepreferred stable model hP, p3 . result suffices prove complementary problem, consisting deciding whether true preferred stable models,p3 -complete.show membership sufficient guess interpretation containing Gcheck whether preferred stable model. Lemma 1 problem decidingwhether preferred stable model p2 solved means p2oracle.Therefore, deciding whether exists preferred stable model containing Gp2N P = p3 .Hardness: Given abductive logic program consisting disjunctive program Pset abducibles (positive) atoms A, ground abductive logic program derived prom P= ground(P) { g 0 (t) g(t) | g(t) ground(A) }{ g 0 (t) g(t) | g(t) ground(A) }Let= { g 0 (t) > g(t) | g(t) ground(A) }h, denotes prioritized program derived P A.two stable models M, N SM(), w N respect meanspreference p0 (u) > p(u) p0 (u) p(u) N existspreference q 0 (v) > q(v) q 0 (v) N q(v) exists. impliesground(A) N ground(A) and, consequently, preferred stable modelsA-minimal.Therefore, problem deciding whether h, A-minimal explanationgoal G equivalent deciding whether h, preferred stable model containing G.Consequently, problem deciding whether A-minimal explanation G existsp3 -complete, problem deciding whether preferred stable model h,containing G exits also p3 -hard, whereas problem deciding whether preferred2stable models hP, contain G p3 -hard.Corollary 2 Let hP, disjunction-free, prioritized program. decidingwhether ground atom true (all) preferred stable models hP, p2 -complete(p2 -complete).Proof. complexity one level lower problem deciding whether interpretation stable model disjunction-free program polynomial.25. Analysis Comparisonsection compares semantics introduced PSM (R)ASO semanticsbriefly discusses recently proposed semantics.PSM semantics elegant compares pairs models basiscommon preferences basis degree satisfaction. consider natural ordering preference rules and, cases, Example 13, compares (and consequently discards) models PAS approach515fiGreco, Trubitsyna, & Zumpanocomparable. interesting feature PSM technique application transitiveproperty order derive additional preference relations among problem solutionsnew, immediately visible, preference relations captured. However, testtransitive property cannot performed direct comparison two models, liescomplex implementation.(R)ASO technique powerful tool determines preferred modelsevaluating degree satisfaction preference rules. Thus, compares twomodels even absence common preferences; preference relationtwo models established directly. detail, RASO technique considersstructure preference rules associating degree satisfaction choice optionsintroduces natural ordering among preferences. case PSM semantics,(R)ASO semantics also compares and, consequently, discards modelscomparable using PAS technique. instance, program hP1 , 1 i, presentedIntroduction, RASO discards M1 , second best option drink, evenunique possible choice presence fish.specifically, preference relation w used PSM approach preorderrelation reflexive transitive; determines equivalent answer set classesestablishes partial preference order among mentioned classes. Consequentlypreferred answer sets appearing preferred classes. notedPSM semantics requires use transitive property order derive,basis relations obtained direct comparison pairs models, new preferencerelations. contrary, (R)ASO semantics uses strict preference relationasymmetric require application transitive propertycompare solutions.PAS semantics, proposed here, compares two solutions basis common preferences introducing concept comparable models consideringrefinement natural order among preference choices. Thus, seen extension PSM semantics also uses additional information derived structurepreference rules, instead comparing models transitively, compares modelsconsidering transitive closure (ground) preference rules.novelty PAS semantics consideration structural information preference rules. introduces concept comparable models order avoid comparingmodels (in opinion) compared associated alternative decisions. Moreover, proposes refinement natural order among preferencesorder define order choices. RASO semantics establishes relational order amongatoms appearing means corresponding dependency graph G() cannottreat case mutually dependent choices. stratification algorithm, proposedCpaper, overcomes problem considering collapsed graph G , acyclicconstruction sensitive syntactic changes. Moreover, RASO semanticsstratification preference rules established considering head atoms; whereasPAS semantics levels assigned rules basis body atoms, followingintuition describe contexts choices. Thus, stratification proposedalways assigns preference facts first level level rule fixed lookinglevel body atoms.advantages adopted approach clarified following example.516fiOn Semantics Logic Programs PreferencesExample 8 problem defined means prioritized program hP8 , 8 consistsselecting colors trousers shirt, black blue trousers (r1 )white, yellow red shirts (r2 ) available. fashion consultant suggests bluetrousers better black ones (%1 ); white shirt better yellow shirt (%2 );case black trousers white shirt preferred red one (%3 ). Moreover,blue trousers go white shirt (c1 ) red shirt go bluetrousers (c2 ).P8 :r1r2c1c2::::black bluewhite yellow redblue, whitered, blue8 :%1 : blue > black%2 : white > yellow%3 : white > red blackprogram P8 four stable models: M1 = {black, white}, M2 = {black, yellow},M3 = {blue, yellow} M4 = {black, red}. order define stratificationpreference rules, RASO PAS semantics firstly assign level atoms: first levelblue, black yellow second level white red. second stepRASO approach, considering maximum level head atoms, assigns %1 firstlevel %2 %3 second level, whereas PAS defines level preferencesbasis body atoms assigns %1 %2 first level %3 second level. Notecase order %2 relevant determining preferred models. fact,RASO gives M3 , PAS returns M1 M3 preferred models.2formal comparison three semantics carried classprograms specific definition stratification significant. Moreover,PSM semantics defined prioritized programs hP, consistsbinary facts (preference rules rewritten preference facts), followingcomparison carried considering programs whose preference rules consistfacts. class programs closure used PSM PAS semanticscoincide.Given prioritized program hP, denote GSEM = (V, ESEM ) preferencegraph stable models P, V = SM(P) denotes set stable modelsP ESEM denotes preference relation = defined semantics SEM{PSM, ASO, PAS}. particular, ESEM consists arcs (Mi , Mj ) Mi = Mjholds SEM semantics. Therefore, comparison different semanticsperformed analyzing corresponding preference graphs. stable model Mi preferredSEM semantics arc (Mj , Mi ) GSEM .following example shows relation PSM PAS semantics.Example 9 Consider prioritized program hP 9 , 9P 9 : fish beef pork chickenwhite fishred beefbeer porkwater chicken5179 : fish > beefchicken > porkred > whitered > waterbeer > waterfiGreco, Trubitsyna, & Zumpanoprogram four stable models: M1 = {fish, white}, M2 = {beef, red}, M3 ={pork, beer} M4 = {chicken, water}, whereas direct preference relations,PSM semantics, follows: M1 w M2 , M2 w M1 , M3 w M4 , M4 w M3 M2 w M4 .Consequently, graph GPSM consists four nodes (M1 , M2 , M3M4 ) four arcs: M1 = M3 , M1 = M4 , M2 = M3 M2 = M4 . Therefore, preferredmodels M1 M2 .Regarding PAS semantics, relation M2 = M4 holds and, thus,three preferred stable models, namely M1 M2 M3 .2Theorem 2 prioritized program hP, consists preference facts,PSM(hP, i) PAS(hP, i).Proof. Consider graphs GPSM = (V, EPSM ) GPAS = (V, EPAS ). graphsacyclic EPAS EPSM . two graphs acyclic, adding edgescreate cycles, number nodes without incoming edges decreases. Therefore, setnodes without incoming edges GPAS contains nodes without incoming edges GPSMand, consequently, PSM(hP, i) PAS(hP, i).2analyze relation ASO PAS semantics. First note that,observed Introduction, ASO semantics sensitive syntax changes.instance, prioritized programabc1 = > b > c2 = b >two preferred stable models: M1 = {a} M2 = {b}. However, program01 = > b001 = b > c2 = b >abcderived rewriting rule 1 , M3 = {c} also preferred model.Thus, consider special class constraints sensitive syntacticchanges. Since every (ground) prioritized program = hP, i, partitioned n strata, n > 1, rewritten program = hP, i,equivalent PAS semantics (as shown proof Proposition1), may equivalent RASO semantics (as rules belongunique stratum 0), continue consider programs = hP, consistssingle stratum and, particular, facts.Given prioritized program hP, consists facts, denote+ = {a1 > > | ai > ai+1 [1..n-1] n maximum }set preference rules obtained merging ground preference facts.Lemma 2 Let hP, prioritized program consists preference factsground() = + . Then, ASO(hP, i) PAS(hP, i).518fiOn Semantics Logic Programs PreferencesProof. Consider two graphs GASO = (V, EASO ) GPAS = (V, EPAS ). (M1 , M2 )EPAS means M1 = M2 , i.e.i) ground rule %1 : e1 > e2 e1 M1M2 , e2 M2M1 ,ii) ground rule %2 : e3 > e4 , e3 M2 M1 e4 M1 M2 .implies ground() = +i) must ground rule 1 : > e1 > > e2 > +e1 M1 M2 , e2 M2 M1 ,ii) must ground rule 2 : > e3 > > e4 > + ,e3 M2 M1 e4 M1 M2 .Therefore, M1 = M2 also respect ASO semantics, graph GASO contains arc (M1 , M2 ). Consequently, EPAS EASO , ASO(hP, + i) PAS(hP, + i). 2find tight relation two semantics, consider restriction+ obtained deleting atoms appear model groundpreference rules:+b = {a1 > > | ai > ai+1 [1..n-1] n maximumSM(P) s.t. ai , ai+1 }Theorem 3 Let hP, prioritized program consists preferenceb + . Then, ASO(hP, i) = PAS(hP, i).facts ground() =b + derived +Proof. ASO(hP, i) PAS(hP, i) derives Lemma 2,deleting nodes appear model influence relation =ASO semantics.show ASO(hP, i) PAS(hP, i) consider relation ASO semantics.M1 = M2 meansb + e1 M1 M2 ,1. ground rule 1 : > e1 > > e2 >e2 M2 M1 ,2. ground rule 2 : > e3 > > e4 >e3 M2 M1 e4 M1 M2 .+ ,b+implies ground() =1. must ground rule %1 : e1 > e2 e1 M1 M2 , e2M2 M1 ,2. ground rule %2 : e3 > e4 , e3 M2 M1 e4 M1 M2 .519fiGreco, Trubitsyna, & ZumpanoTherefore, M1 = M2 also holds respect PAS semantics. Consequently,EASO RPAS , ASO(hP, + i) PAS(hP, + i).2extension ASO semantics proposed Brewka (2004) Brewka,Niemela, Truszczynski (2005). detail, Brewka (2004) provided preferencedescription language, allowing express complex preferences combining qualitativequantitative penalty based preferences, whereas Brewka et al. (2005) proposed framework specify problem solutions (outcomes) preferences among them. latterproposal combines ideas answer-set programming, answer-set optimization CPnets (Boutilier, Brafman, Domshlak, Hoos, & Poole, 2004). semanticsproposed paper different proposed Brewka (2004) Brewkaet al. (2005), cases returns different results (see Examples 2 4).6. ApproachesBesides approaches managing preferences among atoms, works proposedliterature specify preferences among rules.Early proposals expressing preferences rules focus Default Logic (Brewka & Eiter,2000; Delgrande et al., 2000b; Rintanen, 1998), whereas recently emphasisgiven logic programs. regard, different proposals developedrepresenting reasoning user preferences ordered logic programs (Delgrande et al., 2000a; Van Nieuwenborgh & Vermeir, 2002, 2004) preferred answer setsextended logic programs (Brewka & Eiter, 1999). approaches proposeextension Gelfond Lifschitzs extended logic programming adding preference information (Delgrande et al., 2003; Wang et al., 2000; Zhang & Foo, 1997). proposalsattempt extend well founded semantics logic programs preferences (Brewka,1996; Schauba & Wang, 2001), extension van-Gelders alternating fixpoint theorylogic programs priorities proposed Wang et al. (2000).Gelfond Son (1997) proposed methodology reasoning prioritizeddefault language logic programming answer set semantics. approachenables specification preferences among rules allows definition setdefault rules must satisfied well second set default rules couldignored.Ordered logic programs introduced Delgrande et al. (2000a) extendedlogic programs whose rules subject strict partial order static dynamicpreferences. approach fully prescriptive enforces ordering informationconstruction answer set. original program transformed secondextended logic program preferences taken account senseanswer sets obtained evaluating transformed theory correspond preferredanswer sets original theory.Another methodology logic programs containing preferences set rulestranslated logic programs stable model semantics proposedDelgrande et al. (2003).520fiOn Semantics Logic Programs Preferences7. Conclusionspaper case preferences involving atoms logic programming studied.particular, behavior technique proposed Sakama Inoue (2000)Brewka et al. (2003) analyzed semantics, interpreting preference ruletool representing choice alternative options, proposed. Specifically,proposed approach extends PSM semantics considering refinement naturalorder among preferences introduces concept comparable models. Preferenceslogic programs examined together order determine choice order setsmodels compared.new semantics compared PSM ASO semantics. Complexity analysis also performed showing use additional information,regarding preference order sets non comparable models, increasecomplexity computing preferred stable models. Although semantics presentedcomplexity approaches proposed literature, advantage liesfact seems better capture intuitive meaning prioritized programsalso considering structural information preference rules.Prioritized reasoning logic programming PAS semantics easilyimplemented top deductive systems based stable model semanticsDeRes, DLV, Smodels (Cholewinski, Marek, & Truszczynski, 1996; Leone, Pfeifer, Faber,Calimeri, & DellArmi, 2002; Syrjanen & Niemela, 2001). architecture systemprototype implementing prioritized reasoning (with different semantics) topDLV system presented Caroprese, Trubitsyna, Zumpano (2007).Acknowledgmentspreliminary version papers presented Greco, Trubitsyna, Zumpano(2006). authors would like thank anonymous referees useful suggestionsFilippo Furfaro comments.ReferencesBoutilier, C., Brafman, R., Domshlak, C., Hoos, H., Poole, D. (2004). CP-nets: toolrepresenting reasoning conditional ceteris paribus preference statements.Journal Artificial Intelligence Research, 21, 135-191.Brewka, G. (1996). Well-Founded Semantics Extended Logic Programs DynamicPreferences. Journal Artificial Intelligence Research, 4, 19-36.Brewka, G., Eiter, T. (1999). Preferred Answer Sets Extended Logic Programs. ArtificialIntelligence, 109(1-2), 297-356.Brewka, G., Eiter, T. (2000). Prioritizing Default Logic. Intellectics ComputationalLogic, Kluwer, 27-45.Brewka, G. (2002). Logic programming ordered disjunction. Proceedings 18th NationalConference Artificial Intelligence (AAAI/IAAI), 100-105.521fiGreco, Trubitsyna, & ZumpanoBrewka, G., Niemela, I., Truszczynski, M. (2003). Answer Set Optimization. Proceedings18th International Joint Conference Artificial Intelligence (IJCAI), 867-872.Brewka, G. (2004). Complex Preferences Answer Set Optimization, Proceedings 9thInternational Conference Principles Knowledge Representation Reasoning(KR), 213-223.Brewka, G., Niemela, I., Truszczynski, M. (2005). Prioritized Component Systems. Proceedings 20th National Conference Artificial Intelligence (AAAI), 596-601.Caroprese, L., Trubitsyna, I., Zumpano, E. (2007). Implementing Prioritized ReasoningLogic Programming. Proceedings International Conference Enterprice InformationSystems (ICEIS), 94-100.Cholewinski, P., Marek, V. W., Truszczynski, M. (1996). Default Reasoning System DeReS.Proceedings 5th International Conference Principles Knowledge RepresentationReasoning (KR), 518-528.Delgrande, J., P., Schaub, T., Tompits, H. (2000). Logic Programs Compiled Preferences. Proceedings 14th European Conference Artificial Intelligence (ECAI), 464-468.Delgrande, J., P., Schaub, T., Tompits, H. (2000). Compilation Brewka EitersApproach Prioritization. Proceedings European Workshop Logics ArtificialIntelligence (JELIA), 376-390.Delgrande, J., P., Schaub, T., Tompits, H. (2003). Framework Compiling PreferencesLogic Programs. Theory Practice Logic Programming, 3(2), 129-187.Eiter, T., Gottlob, G., Leone, N. (1997). Abduction Logic Programs: SemanticsComplexity. Theoretical Computer Science 189(1-2), 129177.Eiter, T., Gottlob, G., Mannila, H. (1997). Disjunctive Datalog. ACM TransactionDatabase Systems, 22(3), 364418, 1997.Gelfond, M., Lifschitz, V. (1988). Stable Model Semantics Logic Programming,Proceedings International Conference Logic Programming (ICLP), 10701080.Gelfond, M., Lifschitz, V. (1991). Classical Negation Logic Programs DisjunctiveDatabases, New Generation Computing, 9, 365385.Gelfond, M., Son, T.C. (1997). Reasoning prioritized defaults. Proc. 3rd InternationalWorkshop Logic Programming Knowledge Representation (LPKR), 164-223.Greco, S., Trubitsyna, I., Zumpano, E. (2006). Semantics Logic ProgramsPreferences. Proceedings 10th European Conference Logics Artificial Intelligence(JELIA), 203-215.Grell, S., Konczak, K., Schaub, T. (2005). nomore<: System Computing PreferredAnswer Sets. Proceedings 8th International. Conference Logic ProgrammingNonmonotonic Reasoning (LPNMR), 394-398.Janhunen, T., Niemela, I., Simons, P., You, J.-H. (2000). Unfolding partiality disjunctions stable model semantics, Proceedings 7th International Conference Principles Knowledge Representation Reasoning (KR), 411-419.522fiOn Semantics Logic Programs PreferencesInoue, K., Sakama, S. (1998). Negation Failure Head. Journal Logic Programming, 35(1), 39-78.Kakas, A. C., Kowalski, R. A., Toni, F. (1992). Abductive Logic Programming. JournalLogic anc Computation, 2(6), 719-770.Leone, N., Pfeifer, G., Faber, W., Calimeri, F., DellArmi, T., Eiter, T., Gottlob, G., Ianni,G., Ielpa, G., Koch, K., Perri, S., Polleres, A. (2002). DLV System. Proceedings8th European Conference Logics Artificial Intelligence (JELIA), 537-540, 2002.Minker, J. (1982). Indefinite Data Bases Closed World Assumption, Proc. 6-thConf. Automated Deduction, 292-308, 1982.Papadimitriou, C. H. (1994). Computational Complexity. Addison-Wesley.Rintanen J. (1998). Complexity Prioritized Default Logics, Journal Artificial Intelligence Research, 9, 423-461.Sakama, C., Inoue, K. (2000). Priorized logic programming application commonsense reasoning. Artificial Intelligence, 123, 185-222.Schaub, T., Wang , K. (2001). Comparative Study Logic Programs Preference.Proceedings 17th International Joint Conference Artificial Intelligence (IJCAI),597-602.Syrjanen, T., Niemela, I. (2001). Smodels System. Proceedings International Conference Logic Programming Nonmonotonic Reasoning (LPNMR), 434-438.Van Nieuwenborgh, D., Vermeir, D. (2002). Preferred Answer Sets Ordered LogicPrograms. Proceedings 10th European Conference Logics Artificial Intelligence(JELIA), 432-443.Van Nieuwenborgh, D., Vermeir, D. (2002). Ordered Diagnosis, Proceedings 10th International Conference Logic Programming, Artificial Intelligence, Reasoning(LPAR), 244-258.Van Nieuwenborgh, D., Heymans, S., Vermeir, D. (2004). Programs Linearly Ordered Multiple Preferences. Proceedings International Conference Logic Programming (ICLP), 180-194.Wakaki, T., Inoue, K., Sakama, C., Nitta, K. (2003). Computing Preferred Answer SetsAnswer Set Programming. Proceedings 10th International Conference LogicProgramming, Artificial Intelligence, Reasoning (LPAR), 259-273.Wakaki, T., Inoue, K., Sakama, C., Nitta, K. (2004). PLP System. Proceedings 9thEuropean Conference Logics Artificial Intelligence (JELIA), 706-709.Wang, K., Zhou, L., Lin, F. (2000). Alternating Fixpoint Theory Logic ProgramsPriority. Proceedings First International Conference Computational Logic, 164-178.Zhang, Y., Foo, N. (1997). Answer sets prioritized logic programs. Proceedings International Logic Programming Symposium (ILPS), 69-83.523fiJournal Artificial Intelligence Research 30 (2007) 1-50Submitted 11/06; published 9/07Learning Semantic Definitions Online Information SourcesMark James CarmanCraig A. Knoblockmark@bradipo.netknoblock@isi.eduUniversity Southern CaliforniaInformation Sciences Institute4676 Admiralty WayMarina del Rey, CA 90292AbstractInternet contains large number information sources providing many typesdata weather forecasts travel deals financial information. sourcesaccessed via Web-forms, Web Services, RSS feeds on. order make automateduse sources, need model semantically, writing semantic descriptionsWeb Services tedious error prone. paper investigate problemautomatically generating models. introduce framework learning Datalogdefinitions Web sources. order learn definitions, system actively invokessources compares data produce known sources information.performs inductive logic search space plausible source definitionsorder learn best possible semantic model new source. paperperform empirical evaluation system using real-world Web sources. evaluationdemonstrates effectiveness approach, showing automatically learncomplex models real sources reasonable time. also compare systemcomplex schema matching system, showing approach handle kindsproblems tackled latter.1. IntroductionRecent years seen explosion quantity variety information availableonline. One find shopping data (prices availability goods), geospatial data(weather forecasts, housing information), travel data (flight pricing status), financialdata (exchange rates stock quotes), scratches surfaceavailable. aim work make use vast store information.amount information increased, reuse across Web portalsapplications. Developers realised importance managing content separatelypresentation, leading development XML self-describing data format.Content XML far easier manipulate HTML, simplifying integration acrossdifferent sources. Standards also emerged providing programmatic access data(like SOAP REST) developers easily build programs (called Mash-Ups)combine content different sites real-time. Many portals provide accessdata even provide syntactic definitions (in WSDL) input outputdata sources expect. Missing, however, semantic descriptions sourcedoes, required order support automated data integration.c2007AI Access Foundation. rights reserved.fiCarman & Knoblock1.1 Structured QueryingGiven structured sources available, would like combine data dynamicallyanswer specific user requests (as opposed statically case Mash-Ups). Dynamicdata requests expressed queries shown below. queries mayrequire access multiple (publicly available) data sources combine information waysenvisaged producers.1. Tourism: Get prices availability three star hotels within 100 kilometersTrento, Italy lie within 1 kilometer ski resort 1 meter snow.2. Transportation: Determine time need leave work order catch busairport pick brother arriving Qantas flight 205.3. Disaster Prevention: Find phone numbers people living within 1 milecoast 200 feet elevation.clear even small set examples powerful ability combinedata disparate sources be. order give queries automated system,must first express formally query language SQL Datalog (Ullman,1989). Datalog first query might look follows:q(hotel, price) :accommodation(hotel, 3*, address), available(hotel, today, price),distance(address, hTrento,Italyi, dist1), dist1 < 100km,skiResort(resort, loc1), distance(address, loc1, dist2),dist2 < 1km, snowCondiditions(resort, today, height), height > 1m.expression states hotel price pairs generated looking three star hotelsrelational table called accommodation, checking price tomorrow nighttable called available. address hotel used calculate distance Trento,must less 100 kilometers. query also checks skiResortwithin 1 kilometer hotel, snowConditions today show 1meter snow.1.2 Mediatorssystem capable generating plan answer query called InformationMediator (Wiederhold, 1992). order generate plan, mediators look sourcesrelevant query. case, relevant sources might be:1. Italian Tourism Website: find hotels near Trento, Italy.2. Ski Search Engine: find ski resorts near hotel.3. Weather Provider: find much snow fallen ski resort.mediator know sources relevant, needs know informationsource provides. XML defines syntax (formatting) used source, semantics(intended meaning) information source provides must defined separately.done using Local-as-View (LAV) source definitions Datalog (Levy, 2000).Essentially, source definitions describe queries given mediator, returndata source provides. Example definitions shown below. first states2fiLearning Semantic Definitions Information Sources Internetsource hotelSearch takes four values input (inputs prefixed $-symbol),returns list hotels lie within given distance input location.hotel also returns address well price room given date.(Note source provides information hotels Italy.)hotelSearch($location, $distance, $rating, $date, hotel, address, price) :country(location, Italy), accommodation(hotel, rating, address),available(hotel, date, price), distance(address, location, dist1),dist1 < distance.findSkiResorts($address, $distance, resort, location) :skiResort(resort, location), distance(address, location, dist1),dist1 < distance.getSkiConditions($resort, $date, height) :snowCondiditions(resort, date, height).order generate plan answering query, mediator performs process calledquery reformulation (Levy, 2000), whereby transforms query new query(in terms of) relevant information sources.1 (A source relevant refersrelations query.) resulting plan case shown below.q(hotel, price) :hotelSearch(hTrento,Italyi, 100km, 3*, today, hotel, address, price),findSkiResorts(address, 1km, resort, location),getSkiConditions(resort, today, height), height > 1m.work, questions interest are: definitions informationsources come precisely, happens want add new sourcessystem? possible generate source definitions automatically?1.3 Discovering New Sourcesexample above, mediator knows set relevant sources use successfullyanswer query. instead, one sources missing doesnt desiredscope (e.g. getSkiConditions doesnt provide data Trento), mediator first needsdiscover source providing information. number variety informationsources increase, undoubtedly rely automated methods discoveringannotating semantic descriptions. order discover relevant sources, systemmight inspect service registry2 (such defined UDDI), perform keywordbased search Web index (such Google del.icio.us). research communitylooked problem discovering relevant services, developing techniques classifyingservices different domains (such weather flights) using service metadata (He &Kushmerick, 2003) clustering similar services together improve keyword-based search(Dong, Halevy, Madhavan, Nemes, & Zhang, 2004). techniques, although useful,sufficient automating service integration.1. complexity query reformulation known exponential, although efficient algorithmsperforming exist (Pottinger & Halevy, 2001).2. Note technically, service different source. service interface providing accessmultiple operations, may provide information. operation affect stateworld (e.g. charging somebodys credit card), call information source.paper, however, use term service refer information sources.3fiCarman & Knoblock1.4 Labeling Service Inputs Outputsrelevant service discovered, problem shifts modeling semantically. Modeling sources hand laborious, automating process makes sense. Since differentservices often provide similar overlapping data, possible use knowledgepreviously modeled services learn descriptions new ones.first step modeling source determine type data requiresinput produces output. done assigning semantic types (like zipcode,telephone number, temperature, on) attributes service. Semantic typesrestrict possible values attribute subset corresponding primitive type.research community investigated automating assignment process viewingclassification problem (He & Kushmerick, 2003). system, Kushmericktrained Support Vector Machine (SVM) metadata describing different sources.system, given source following:getWeather($zip, temp)uses labels getWeather, zip temp (and available metadata) assigntypes input output attributes, e.g.: zip zipcode, temp temperature. Noteadditional metadata often useful distinguishing possible assignments. (If,example, name operation listEmployees, temp may referredtemporary employee rather temperature.)subsequent work, researchers developed comprehensive system usedmetadata output data classify service attributes (Lerman, Plangprasopchok, &Knoblock, 2006). system, Logistic Regression based classifier first assigns semantic types input parameters. Examples input types used invokeservice, output given pattern-language based classifier, assigns typesoutput parameters. authors argue classification based datametadata far accurate based metadata alone. Using example,easy see why. Consider following tuples produced getWeather source:h90292, 25 Ci, h10274, 15 Ci, h60610, 18 Ci, ...Given data, classifier certain temp really refers temperature,indeed even assign specific type, temperatureC (in Celsius).problem determining semantic types services attributesinteresting, room improvement current techniques, assumepurposes work already solved.1.5 Generating Definitionknow parameter types, invoke service, still unablemake use data returns. that, need also know output attributesrelate input (i.e. definition source). example, getWeather serviceneed know whether temperature returned current temperature,predicted high temperature tomorrow average temperature time year.relationships described following definitions:getWeather($zip, temp) :- currentTemp(zip, temp).getWeather($zip, temp) :- forecast(zip, tomorrow, temp).getWeather($zip, temp) :- averageTemp(zip, today, temp).4fiLearning Semantic Definitions Information Sources Internetrelations used definitions would defined domain ontology (or schema).paper describe system capable learning definitionscorrect. system leverages knows domain, i.e. domainontology set known information sources, learn know, namelyrelationship attributes newly discovered source.1.6 Outlinepaper presents comprehensive treatment methods learning semantic descriptions Web information sources. extends previous work subject (Carman &Knoblock, 2007) presenting detailed descriptions methods enumeratingsearch space evaluating individual candidate definitions. provide additionaldetails regarding evaluation methodology results generated.paper structured follows. start example motivate sourceinduction problem formulate problem concisely. discuss approachlearning definitions sources terms known sources information (section3). give details search procedure generating candidate definitions (section 4)evaluation procedure scoring candidates search (section 5).describe extensions basic algorithm (section 6) discussing evaluation setupexperiments (section 7), demonstrate capabilities system. Finally,contrast approach prior work.2. Problemdescribe detail problem learning definitions newly discovered services.start concrete example meant learning source definition.example four types data (semantic types), namely: zipcodes, distances, latitudeslongitudes. also three known sources information. sourcesdefinition Datalog shown below. first service, aptly named source1, takeszipcode returns latitude longitude coordinates centroid. secondservice calculates great circle distance (the shortest distance earths surface)two pairs coordinates, third converts distance kilometresmiles multiplying input constant 1.609.source1($zip, lat, long) :- centroid(zip, lat, long).source2($lat1, $long1, $lat2, $long2, dist) :greatCircleDist(lat1, long1, lat2, long2, dist).source3($dist1, dist2) :- multiply(dist1, 1.609, dist2).goal example learn definition newly discovered service, called source4.service takes two zipcodes input returns distance value output:source4($zip1, $zip2, dist)system describe uses type signature (input output type information)search appropriate definition source. definition discovered casemight following conjunction calls individual sources:source4($zip1, $zip2, dist):source1($zip1, lat1, long1), source1($zip2, lat2, long2),source2($lat1, $long1, $lat2, $long2, dist2), source3($dist2, dist).5fiCarman & Knoblockdefinition states sources output distance calculated input zipcodes,giving zipcodes source1, taking resulting coordinates calculatingdistance using source2, converting distance miles usingsource3. test whether definition correct, system must invoke newsource definition see values generated agree other. followingtable shows test:$zip1802106060110005$zip2902661520135555dist (actual)842.37410.31899.50dist (predicted)843.65410.83899.21table, input zipcodes selected randomly set examples,output source definition shown side side. Since outputvalues quite similar, system seen sufficient number examples,confident found correct semantic definition source.definition given terms source relations, could alsowritten terms domain relations (the relations used define sources 1 3).convert definition form, one simply needs replace source relationdefinition follows:source4($zip1, $zip2, dist):centroid(zip1, lat1, long1), centroid(zip2, lat2, long2),greatCircleDist(lat1, long1, lat2, long2, dist2), multiply(dist1, 1.609, dist2).Written way, new semantic definition makes sense intuitive level: sourcesimply calculating distance miles centroids two zipcodes.2.1 Problem Formulationgiven example Source Definition Induction Problem, describeproblem formally, so, introduce concepts notation. (Wenote focus paper learning definitions information-providing,opposed world-altering services.)domain semantic data-type t, denoted D[t], (possibly infinite) setconstant values {c1 , c2 , ...}, constitute set values variablestype. example D[zipcode] = {90210, 90292, ...}attribute pair hlabel, semantic data-typei, e.g. hzip1, zipcodei. typeattribute denoted type(a) corresponding domain D[type(a)] abbreviatedD[a].scheme ordered (finite) set attributes ha1 , ..., unique labels,n referred arity scheme. example scheme might hzip1 :zipcode, zip2 : zipcode, dist : distancei. domain scheme A, denotedD[A], Cartesian product domains attributes scheme {D[a1 ]... D[an ]}, ai A.tuple scheme element set D[A]. tuple representedset name-value pairs, {zip1 = 90210, zip2 = 90292, dist = 8.15}6fiLearning Semantic Definitions Information Sources Internetrelation named scheme, airDistance(zip1, zip2, dist). Multiple relations may share scheme.extension relation r, denoted E[r], subset tuples D[r]. example, E[airDistance] might table containing distance zipcodesCalifornia. (Note extension relation may contain distinct tuples.)database instance set relations R, denoted I[R], set extensions{E[r1 ], ..., E[rn ]}, one relation r R.query language L formal language constructing queries set relations.denote set queries written using language L setrelations R returning tuples conforming scheme LR,A .result set produced execution query q LR,A database instanceI[R] denoted EI [q].source relation s, binding pattern s, distinguishes inputattributes output attributes. (The output attributes source denotedcomplement binding pattern3 , sc s\s .)view definition source query vs written query language LR,s .Source Definition Induction Problem defined tuple:hT, R, L, S, V,set semantic data-types, R set relations, L query language,set known sources, V set view definitions (one known source),new source (also referred target).semantic type must provided set examples values Et D[t].(We require entire set D[t], domain many types may partiallyunknown large enumerated.) addition, predicate eqt (t, t) availablechecking equality values semantic type handle case multipleserialisations variable represent value.relation r R referred global relation domain predicateextension virtual, meaning extension generated inspecting everyrelevant data source. set relations R may include interpreted predicates,, whose extension defined virtual.language L used constructing queries could query language includingSQL XQuery (the XML Query Language). paper use form Datalog.source extension E[s] complete set tuplesproduced source (at given moment time). require corresponding viewdefinition vs V (written LR,s ) consistent source, that: E[s] EI [vs ],(where I[R] current virtual database instance global relations). Noterequire equivalence, sources may provide incomplete data.view definition source modeled unknown. solutionSource Definition Induction Problem view definition v LR,s sourceE[s ] EI [v ], view definition v 0 LR,s better describes(provides tighter definition for) source , i.e.:v 0 LR,s s.t. E[s ] EI [v 0 ] |EI [v 0 ]| < |EI [v ]|3. \-symbol denotes set difference.7fiCarman & KnoblockGiven limited available computation bandwidth, note may possibleguarantee optimality condition holds particular solution; thus papersimply strive find best solution possible.2.2 Implicit Assumptionsnumber assumptions implicit problem formulation. firstexists system capable discovering new sources importantly classifying (togood accuracy) semantic types input output. Systems capablediscussed section 1.4.second assumption representation source relationalview definition. sources Internet provide tree structured XML data. mayalways obvious best flatten data set relational tuples,preserving intended meaning data. Consider travel booking site returnsset flight options ticket number, price list flight segmentsconstitute itinerary. One possibility converting data set tuples wouldbreak ticket individual flight segment tuples (thereby obscuringrelationship price number flight segments). Another would createone long tuple ticket room number flight segments (therebycreating tuples many null values). case, obvious which, either,options preferred. online data sources can, however, modeled quitenaturally relational sources; first tackling relational problem, developtechniques later applied difficult semi-structured case.third assumption set domain relations suffices describing sourcemodeled. instance, consider case domain model contains relationsdescribing financial data, new source provides weather forecasts. Obviously,system would unable find adequate description behavior sourcewould learn model it. practical perspective, limitation bigproblem, since user request data (write queries mediator) using relationsdomain model anyway. (Thus source cannot described usingrelations would needed answer user requests.) words, onusdomain modeler model sufficient relations able describe typesqueries user able pose system consequently, types sourcesavailable. said, interesting avenue future research wouldinvestigate problem automating (at least part) process expanding scopedomain model (by adding attributes relations, inventing new ones), basedtypes sources discovered.2.3 Problem Discussionnumber questions arise problem formulation, first domainmodel comes from. principle, set semantic types relations could comemany places. could taken standard data models different domains,might simplest model possible aptly describes set known sources.domain model may evolve time sources discovered appropriatemodel found. Somewhat related question specific semantic types8fiLearning Semantic Definitions Information Sources Internetought be. example, sufficient one semantic type distanceone distinguish distance meters distance feet? Generally speaking,semantic type created attribute syntactically dissimilarattributes. example, phone number zipcode different syntax,thus operations accept one types input unlikely accept other.practice, one might create new semantic type whenever trained classifier recognisetype based syntax alone. general, semantic types are,harder job system classifying attributes, easier job systemtasked learning definition source.Another question considered definitions known sources comefrom. Initially definitions would need written hand. system learnsdefinitions new sources, would added set known sources, makingpossible learn ever complicated definitions.order system learn definition new source, must able invokesource thus needs examples input types. representative setexamples available, efficient accurate learning process be. initialset examples need provided domain modeler. Then, system learnstime, generate large number examples different semantic types (as outputvarious sources), retained future use.Information Integration research reached point mediator technology4becoming mature practical. need involve human writing sourcedefinitions is, however, Achilles Heel systems. gains flexibility comeability dynamically reformulate user queries often partially offsettime skill required write definitions incorporating new sources. Thus systemcapable learning definitions automatically could greatly enhance viability mediatortechnology. motivation alone seems sufficient pursuing problem.3. Approachapproach take learning semantic models information sources Webtwofold. Firstly, choose model sources using powerful language conjunctivequeries. Secondly, leverage set known sources order learn definitionnew one. section discuss aspects detail.3.1 Modeling Languagesource definition language L hypothesis language new definitionsneed learnt. often case machine learning, faced trade-offrespect expressiveness language. hypothesis language simple,may able model real services using it. hand, languageoverly complex, space possible hypotheses large learningfeasible. language choose conjunctive queries Datalog,4. Influential Information Integration systems include TSIMMIS (Garcia-Molina, Hammer, Ireland, Papakonstantinou, Ullman, & Widom, 1995), SIMS (Arens, Knoblock, & Shen, 1996), InfoMaster (Duschka,1997), Ariadne (Knoblock, Minton, Ambite, Ashish, Muslea, Philpot, & Tejada, 2001).9fiCarman & Knoblockhighly expressive relational query language. section argue less expressivelanguage sufficient purposes.Researchers interested problem assigning semantics Web Services (He &Kushmerick, 2003) investigated problem using Machine Learning techniquesclassify services (based metadata characteristics) different semantic domains,weather flights, operations provide different classes operation,weatherForecast flightStatus. relational perspective, considerdifferent classes operations relations. instance, consider definition below:source($zip, temp) :- weatherForecast(zip, tomorrow, temp).source provides weather data selecting tuples relation called weatherForecast,desired zipcode date equal tomorrow. query referredselect-project query evaluation performed using relational operatorsselection projection. far good, able use simple classifier learnsimple definition source. limitation imposed restricted (select-project)modeling language becomes obvious, however, consider slightly complicatedsources. Consider source provides temperature Fahrenheit well Celsius.order model source using select-project query, would requireweatherForecast relation extended new attribute follows:source($zip, tempC, tempF):- weatherForecast(zip, tomorrow, tempC, tempF).attributes could conceivably returned weather forecast operation(such dewpoint, humidity, temperature Kelvin, latitude, etc.), longer relationneed cover all. Better, case, would introduce secondrelation convertCtoF makes explicit relationship temperature values.If, addition, source limits output zipcodes California, reasonable definitionsource might be:source($zip, tempC, tempF):weatherForecast(zip, tomorrow, tempC), convertCtoF(tempC, tempF),state(zip, California).definition longer expressed language select-project queries,involves multiple relations joins across them. Thus simple example, seemodeling services using simple select-project queries sufficient purposes.need select-project-join queries, also referred conjunctive queries.5 readeralready introduced examples conjunctive queries throughout previoussections. Conjunctive queries form subset logical query language Datalogdescribed formally follows:conjunctive query set relations R expression form:q(X0 ) :- r1 (X1 ), r2 (X2 ), ..., rl (Xl ).ri R relation Xi ordered set variable names sizearity(ri ).6 conjunct ri (Xi ) referred literal. set variablesquery, denoted vars(q) = li=0 Xi , consists distinguished variablesX0 (from head query), existential variables vars(q)\X0 , (which5. Evaluating select-project-join query requires additional relational operators: natural join rename.6. Note conjunctive query also expressed first order logicSas follows:lX0 s.t. r1 (X1 ) r2 (X2 ) ... rl (Xl ) q(X0 ) X0 = i=1 Xi10fiLearning Semantic Definitions Information Sources Internetappear body). conjunctive query said safedistinguished variables appear body, i.e. X0 li=1 Xi .3.2 Expressive LanguagesModeling sources using conjunctive queries implies aggregate operators like MINORDER cannot used source definitions. functionality sourcesdescribed without operators. sources described poorly, however.Consider hotel search service returns 20 closest hotels given location:hotelSearch($loc, hotel, dist) :accommodation(hotel, loc1), distance(loc, loc1, dist).According definition, source return hotels regardless distance. Onecannot express fact closest hotels returned. reasonincluding aggregate operators hypothesis language search space associatedlearning definitions prohibitively large. (Thus leave aggregate operators futurework discussed section 9.2.)Similarly, source definitions cannot contain disjunction, rules union recursive queries. Again, simplifying assumption holds information sourcesgreatly reduces search space. means however, weather service providingforecasts cities US Canada would modeled as:s($city, temp) :- forecast(city, country, tomorrow, temp).Since definition restrict domain country attribute, confrontedrequest forecast Australia, mediator would proceed call service,oblivious restriction attribute.also allow negation queries source definitions rarelyrequire it, including would needlessly complicate search. rare casesnegation particular predicate useful describing certain types sources,negated predicate included (as distinct predicate) search. instance,might use describe source, even though strictly speaking negation <.3.3 Leveraging Known Sourcesapproach problem discovering semantic definitions new servicesleverage set known sources learning new definition. Broadly speaking,invoking known sources (in methodical manner) see combinationinformation provide matches information provided new source.practical perspective, means order model newly discovered source semantically,require overlap data produced new source set knownsources. One way understand consider new source producing weather data.none known sources produce weather information, waysystem learn whether new source producing historical weather data, weatherforecasts - even describing weather all. (In principle, one could try guessservice based type signature alone, would guaranteedefinition correct, making little use mediator.) Given overlappingdata requirement, one might claim little benefit incorporating new sources.detail reasons case below.11fiCarman & Knoblockobvious benefit learning definitions new sources redundancy.system able learn one source provides exactly information currentlyavailable source, latter suddenly becomes unavailable, former usedplace. example, mediator knows one weather source providing currentconditions learns second source provides similar data,first goes whatever reason (perhaps access quota reached),weather data still accessed second.second perhaps interesting reason wanting learn definitionnew source new source may provide data lies outside scope (orsimply present in) data provided sources. example, considerweather service provides temperature values zipcodes United States.consider second source provides weather forecasts cities worldwide. systemuse first source learn definition second, amount informationavailable querying increases greatly.Binding constraints service make accessing certain types information difficultinefficient. case, discovering new source providing similar datadifferent binding pattern may improve performance. example, consider hotelsearch service accepts zipcode returns set hotels along star rating:hotelSearch($zip, hotel, rating, street, city, state):accommodation(hotel, rating, street, city, state, zip).consider simple query names addresses five star hotels California:q(hotel, street, city, zip):- accommodation(hotel, 5*, street, city, California, zip).Answering query would require thousands calls known source, one everyzipcode California, mediator could answer query anothersource providing zipcodes. contrast, system learnt definition newsource provides exactly data different binding pattern (suchone below), answering query would require one call source:hotelsByState($state, $rating, hotel, street, city, zip):accommodation(hotel, rating, street, city, state, zip).Often functionality complex source described terms compositionfunctionality provided simpler services. instance, consider motivatingexample section 2, functionality provided new source calculate distance miles two zipcodes. functionality could achievedperforming four different calls available sources. case, definition learntsystem meant query regarding distance zipcodes could handled efficiently. general, learning definitions complicated sourcesterms simpler ones, system benefit computation, optimisation cachingabilities services providing complex functionality.Finally, newly discovered service may faster access known sourcesproviding similar data. instance, consider geocoding service takes addressreturns latitude longitude coordinates location. varietyalgorithms used calculate coordinates, unreasonable geocodingservices take long time (upwards one second) return result. systemable discover new source providing geocoding functionality, using12fiLearning Semantic Definitions Information Sources Internetfaster algorithm, could locate display many addresses mapamount time.4. Inducing Definitionssection describe algorithm generating candidate definitions newlydiscovered source. algorithm forms first phase generate test methodologylearning source definitions. defer discussion testing phase later paper.start briefly discussing work relational rule learning describealgorithm builds upon ideas.4.1 Inductive Logic Programminglanguage conjunctive queries restricted form first-order logic. MachineLearning community, systems capable learning models using first-order representationsreferred Inductive Logic Programming (ILP) systems relational rule learners.expressiveness modeling language, complexity learning muchhigher propositional rule learners (also called attribute-value learners), formbulk Machine Learning algorithms. Given relational modeling services, manytechniques developed ILP also apply problem.First Order Inductive Learner (foil) well known ILP search algorithm (CameronJones & Quinlan, 1994). capable learning first-order rules describe target predicate, represented set positive examples (tuples target relation,denoted E + ) optionally also set negative examples (E ). search viabledefinition foil starts empty clause7 progressively adds literals body(antecedent) rule, thereby making rule specific. process continuesdefinition (denoted h) covers positive examples negative examples:E + EI [h] 6=E EI [h] =Usually set rules learnt manner removing positive examples coveredfirst rule repeating process. (The set rules interpreted unionquery.) Search foil performed greedy best-first manner, guided informationgain-based heuristic. Many extensions basic algorithm exist, notablycombine declarative background knowledge search process focl (Pazzani &Kibler, 1992). systems categorised performing top searchstart empty clause (the general rule possible) progressively specializeclause. Bottom approaches, hand, golem (Muggleton & Feng,1990), perform specific general search starting positive examples target.4.2 Searchdescribe actual search procedure use generate candidate definitionsnew source. procedure based top-down search strategy used foil.algorithm takes input type signature new source uses seed search7. use terms clause query interchangeably refer conjunctive query Datalog. emptyclause query without literals body (right side) clause.13fiCarman & Knoblockinput : predicate signatureoutput: best scoring view definition vbestinvoke target set random inputs;vbest empty clause ;3 add vbest empty queue;4 queue 6= time() < timeout i++ < limit5v0 best definition queue;6forall v1 expand(v0 )7insert v1 queue;8eval(v1 ) > 09forall v2 constrain(v1 )10insert v2 queue;11eval(v2 ) eval(v1 ) v1 v2 ;12end13end14eval(v1 ) eval(vbest ) vbest v1 ;15end16 end17 return vbest ;Algorithm 1: Best-first search space candidate source definitions.12candidate definitions. (We refer new source relation target predicateset known source relations source predicates.) space candidate definitionsenumerated best-first manner, candidate tested see data returnssimilar target. Pseudo-code describing procedure given Algorithm 1.8first step algorithm invoke new source representative setinput tuples generate examples output tuples characterise functionalitysource. set invocations must include positive examples (invocations outputtuples produced) possible, also negative tuples (inputs outputreturned). algorithms ability induce correct definition source dependsgreatly number positive examples available. Thus minimum number positiveinvocations source imposed, meaning algorithm may invokesource repeatedly using different inputs sufficient positive invocations recorded.Selecting appropriate input values successfully invoke service easier saiddone. defer discussion issues difficulties involved successfully invokingnew source section 6.1, assume moment induction system ablegenerate table values represent functionality.next step algorithm initialise search adding empty clausequeue definitions expand. rest algorithm simply best-first searchprocedure. iteration highest scoring yet expanded definition (denotedv0 ) removed queue expanded adding new predicate end8. implementation algorithm used experiments section 7.3 available at:http://www.isi.edu/publications/licensed-sw/eidos/index.html14fiLearning Semantic Definitions Information Sources Internetclause (see next section example). candidate generated (denoted v1 )added queue. algorithm progressively constrains candidate bindingvariables newly added predicate, (see section 4.4). eval function (see section5.3) evaluates quality candidate produced. procedure stops constrainingcandidate change evaluation function (eval) drops zero.compares v1 previous best candidate vbest updates latter accordingly.principle algorithm terminate perfect candidate definitiondiscovered - one produces exactly data target. practice neveroccurs sources incomplete (dont perfectly overlap other)noisy. Instead algorithm terminates either queue becomes empty, time limitreached maximum number iterations performed.4.3 Examplerun example process generating candidate definitions. Considernewly discovered source, takes zipcode distance, returnszipcodes lie within given radius (along respective distances). targetpredicate representing source is:source5($zip1, $dist1, zip2, dist2)assume two known sources. first source definitionlearnt example section 2, namely:source4($zip1, $zip2, dist):centroid(zip1, lat1, long1), centroid(zip2, lat2, long2),greatCircleDist(lat1, long1, lat2, long2, dist2), multiply(dist1, 1.609, dist2).second source isnt actually source interpreted predicate:(dist1, dist2).search definition new source might proceed follows. firstdefinition generated empty clause:source5($ , $ , , ).null character ( ) represents fact none inputs outputsrestrictions placed values. Prior adding first literal (source predicate),system check whether output attributes echo input values. case, givensemantic types, two possibilities need checked:source5($zip1, $ , zip1, ).source5($ , $dist1, , dist1).Assuming neither possibilities true (i.e. improves score), literalsadded one time refine definition. literal source predicateassignment variable names attributes. new definition must created everypossible literal includes least one variable already present clause. (Formoment ignore issue binding constraints sources added.) Thus manycandidate definitions would generated, including following:source5($zip1, $dist1, , ) :- source4($zip1, $ , dist1).source5($zip1, $ , zip2, ):- source4($zip1, $zip2, ).source5($ , $dist1, , dist2) :- (dist1, dist2).15fiCarman & KnoblockNote semantic types type signature target predicate limit greatlynumber candidate definitions produced. system evaluatescandidates turn, selecting best one expansion. Assuming firstthree best score, would expanded adding another literal, formingcomplicated candidates following:source5($zip1, $dist1, , dist2) :- source4($zip1, $ , dist1), (dist1, dist2).process continues system discovers definition perfectly describessource, forced backtrack literal improves score.4.4 Iterative Expansionsources used previous example relatively low arity. Internetrarely case, many sources producing large number attributes type.problem causes exponential number definitions possibleexpansion step. Consider instance stock price service, provides current,high, low, market-opening market-closing prices given ticker symbol. typesignature service would be:stockprice($ticker, price, price, price, price, price)definition predicate added already contains k distinct pricevariables, number ways price attributes new relationPassigned variable names 5i=0 5i k , prohibitively large even moderate k.9limit search space case high-arity predicates, first generate candidatesminimal number bound variables new literal progressively constrainbest performing definitions within expansion. (High arity predicateshandled similar fashion foil, Quinlan Cameron-Jones, 1993.) example,consider using source learn definition new source signature:source6($ticker, price, price)start adding literals empty definition before. time though, insteadgenerating literal every possible assignment variable names attributesrelation, generate simplest assignments binding constraintsmet. (This expand procedure referred Algorithm 1.) example,ticker symbol input stockprice source would need bound, generating singledefinition:source6($tic, , ) :- stockprice($tic, , , , , ).definition would evaluated, constrained definitions generatedequating variable literal variables clause. (Thisconstrain procedure Algorithm 1.) Two definitions shown below:source6($tic, pri1, ) :- stockprice($tic, pri1, , , , ).source6($tic, pri1, ) :- stockprice($tic, , pri1, , , ).best definitions would selected constrained further, generatingdefinitions as:9. Intuitively, one assign variablenames attributes using k labels k different ways. Onechoose 5 attributes 5i ways, one = 0, 1, .., 5. See Weber, Tausend,Stahl (1995) detailed discussion size hypothesis space ILP.16fiLearning Semantic Definitions Information Sources Internetsource6($tic, pri1, pri2) :- stockprice($tic, , pri1, pri2, , ).source6($tic, pri1, pri2) :- stockprice($tic, , pri1, , pri2, ).way, best scoring literal found without need iteratepossible assignments variables attributes.4.5 Domain Predicates vs. Source Predicatesexamples sections 4.3 4.4, decision perform search sourcepredicates rather domain predicates made arbitrary fashion.10section justify decision. one perform search domain predicatesrather source predicates, testing definition would require additionalquery reformulation step. example, consider following candidate definitionsource5 containing domain predicate centroid:source5($zip1, $ , , ) :- centroid(zip1, , ).order evaluate candidate, system would need first treat definitionquery reformulate set rewritings (that together form union query)various sources follows:source5($zip1, $ , , ) :- source4($zip1, $ , ).source5($zip1, $ , , ) :- source4($ , $zip1, ).union query executed available sources (in casesource4) see tuples candidate definition returns. practice however,definitions known sources contain multiple literals (as normally do)domain relations high-arity (as often are), search spaceconjunctions domain predicates often much larger corresponding searchspace conjunctions source predicates. multiple conjunctionsdomain predicates (candidate definitions) end reformulating conjunctionsource predicates (union queries). example, consider following candidate definitionswritten terms domain predicates:source5($zip1, $ , , ) :- centroid(zip1, lat, ), greatCircleDist(lat, , , , ).source5($zip1, $ , , ) :- centroid(zip1, , lon), greatCircleDist( , lon, , , ).source5($zip1, $ , , ) :- centroid(zip1, lat, lon), greatCircleDist(lat, lon, , , ).three candidates would reformulate query sources (shown below),thus indistinguishable given sources available.source5($zip1, $ , , ) :- source4($zip1, $ , ).general, number candidate definitions map reformulationexponential number hidden variables present definitions known sources.reason, simplify problem search space conjunctions sourcepredicates. sense, performing search source predicates seenintroducing similarity heuristic focuses search toward definitions similarstructure definitions available sources. note definitions produced(and will) later converted queries global predicates unfolding10. note difference domain, source interpreted predicates. Domain predicatesinvented domain expert use modeling particular information domain. define commonschema used describing information different sources. Source predicates representsources available system. Interpreted predicates, (such ), special type domainpredicate, treated source predicates, since meaning interpreted (understood).17fiCarman & Knoblockpossibly tightening remove redundancies. discuss process tighteningunfoldings section 6.6.4.6 Limiting Searchsearch space generated top-down search algorithm may large evensmall number sources. use semantic types limits greatly waysvariables within definition equated (aka join paths) thus goes longway reduce size search space. Despite reduction, number sourcesavailable increases, search space becomes large techniques limiting mustused. employ standard (and standard) ILP techniques limitingspace. limitations often referred inductive search bias language bias(Nedellec, Rouveirol, Ade, Bergadano, & Tausend, 1996).obvious way limit search restrict number source predicatesoccur definition. Whenever definition reaches maximum length, backtrackingperformed, allowing search escape local minima may resultgreedy enumeration. assumption shorter definitions probablelonger ones, makes sense since service providers likely provide datasimplest form possible. Moreover, simpler definition learnt, usefulmediator, decide trade completeness (the ability express longerdefinitions) improved accuracy shorter definitions.second restriction placed candidate definitions limit number timessource predicate appears given candidate. makes sensedefinitions real services tend contain many repeated predicates. Intuitively,services provide raw data without performing many calculations upon it.Repeated use predicate definition useful describing formcalculation raw data itself. (Exceptions rule exist, example predicatesrepresenting unit conversion functionality Fahrenheit Celsius, may necessarilyoccur multiple times definition source.)third restriction limits complexity definitions generated reducingnumber literals contain variables head clause. Specifically,limits level existential quantification (sometimes also referred depth,Muggleton Feng, 1990) variable clause. level defined zerodistinguished variables (those appearing head clause). existentialvariables defined recursively one plus lowest level variable appearingliteral. example, candidate definition shown maximum existentialquantification level three shortest path last literal head literal(via join variables) passes two literals:source5($zip1, $ , , ) :- source4($zip1, $ , d1), source3($d1, d2), source3($d2, ).effect bias concentrate search around simpler highly connecteddefinitions, literal closely linked input output source.fourth restriction placed source definitions executable.specifically, possible execute left right, meaning inputssource appear either target predicate (head clause) oneliterals left literal. example, two candidate definitions shown below,18fiLearning Semantic Definitions Information Sources Internetfirst executable. second definition not, zip2 used inputsource4 first literal, without first bound value head clause:source5($zip1, $ , zip2, ) :- source4($zip1, $zip2, ).source5($zip1, $ , , ) :- source4($zip1, $zip2, dist1), source4($zip2, $zip1, dist1).restriction serves two purposes. Firstly, like biases, limits sizesearch space. Secondly, makes easier evaluate definitions produced. theory,one could still evaluate second definition generating lots input valueszip2, would require lot invocations minimal gain.last restriction reduces search space limiting number timesvariable appear given literal body clause. Definitionsvariable appears multiple times given literal, following examplereturns distance zipcode itself, common practice:source5($zip1, $ , , dist2) :- source4($zip1, $zip1, dist2).Explicitly preventing definitions generated makes sense sourcesrequiring rare, better reduce search space exponentiallyignoring them, explicitly check time.5. Scoring Definitionsproceed problem evaluating candidate definitions generatedsearch. basic idea compare output produced source outputproduced definition input. similar set tuples produced,higher score candidate. score averaged set differentinput tuples see well candidate definition describes new source.motivating example section 2, source definition learnt(the definition repeated below) produced one output tuple hdisti every inputtuple hzip1, zip2i:source4($zip1, $zip2, dist):centroid(zip1, lat1, long1), centroid(zip2, lat2, long2),greatCircleDist(lat1, long1, lat2, long2, dist2),multiply(dist1, 1.6093, dist2).fact made simple compare output service output induceddefinition. general however, source modeled (and candidate definitionsmodeling it) may produce multiple output tuples input tuple. Take examplesource5 section 4.3, produces set output tuples hzip2, dist2i containingzipcodes lie within given radius input zipcode hzip1, dist1i.cases, system needs compare set output tuples set produceddefinition see tuples same. Since new sourceexisting sources may complete, two sets may simply overlap, even candidatedefinition correctly describes new source. Assuming count numbertuples same, need measure tells us well candidate hypothesisdescribes data returned source. One measure following:score(s, v, I) =1 X |Os (i) Ov (i)||I| iI |Os (i) Ov (i)|19fiCarman & Knoblocknew source, v candidate source definition, D[s ] setinput tuples used test source (s set input attributes source s). Os (i)denotes set tuples returned new source invoked input tuple i. Ov (i)corresponding set returned candidate definition. Using relational projection() selection () operators notation introduced section 2.1, setswritten follows. (Note sc represents output attributes s.)Os (i) sc (s =i (E[s]))Ov (i) sc (s =i (EI [v]))view hypothesis testing information retrieval task, consider recallnumber common tuples, divided number tuples producedsource, precision number common tuples divided number tuplesproduced definition. measure takes precision recall accountcalculating average Jaccard similarity sets. table givesexample score calculated input tuple.input tupleiIha, bihc, dihe, fhg, hihi, jiactual outputtuples Os (i){hx, yi, hx, zi}{hx, wi, hx, zi}{hx, wi, hx, yi}predicted outputtuples Ov (i){hx, yi}{hx, wi, hx, yi}{hx, wi, hx, yi}{hx, yi}Jaccard similaritytuple1/21/310#undef!first two rows table show inputs predicted actual outputtuples overlap. third row, definition produces exactly set tuplessource modeled thus gets maximum score. fourth row,definition produced tuple, source didnt, definition penalised.last row, definition correctly predicted tuples would output source.score function undefined point. certain perspective definitionscore well correctly predicted tuples returnedinput, giving high score definition produces tuples dangerous.may cause overly constrained definitions generate output tuplesscore well. time, less constrained definitions better predictingoutput tuples average may score poorly. example, consider source returnsweather forecasts zipcodes Los Angeles:source($zip, temp) :- forecast(zip, tomorrow, temp), UScity(zip, Los Angeles).consider two candidate definitions source. first returns temperaturezipcode, second returns temperature 0 C:v1 ($zip, temp) :- forecast(zip, tomorrow, temp).v2 ($zip, temp) :- forecast(zip, tomorrow, temp), temp < 0 C .Assume source candidates invoked using 20 different randomly selectedzipcodes. zipcodes, source return output, zipcodelie outside Los Angeles. first candidate likely return output zipcodes,second candidate would, like source, rarely produce output.temperature zipcodes greater zero, nothing20fiLearning Semantic Definitions Information Sources Internetwhether zipcode Los Angeles. score definitions highlycorrectly produce output, system would erroneously prefer second candidatefirst (because latter often produces output). prevent happening,simply ignore inputs definition correctly predicts zero tuples.setting score average values.Returning attention table, ignoring last row, overall scoredefinition would calculated 0.46.5.1 Partial Definitionssearch proceeds toward correct definition service, many semi-complete(unsafe) definitions generated. definitions produce valuesattributes target tuple subset them. example, candidate:source5($zip1, $dist1, zip2, ) :- source4($zip1, $zip2, dist1).produces one two output attributes produced source. presentsproblem, score defined sets tuples containing outputattributes new source. One solution might wait definitions becomesufficiently long produce outputs, comparing see one bestdescribes new source. are, however, two reasons would make sense:space safe definitions large enumerate, thus need comparepartial definitions guide search toward correct definition.best definition system generate may well partial one, setknown sources may sufficient completely model source.simplest way compute score partial definition compute functionbefore, instead using raw source tuples, projecting subsetattributes produced definition. revised score shown below. (Noteprojection v\s , denotes subset output attributesproduced view definition v. Note also projection distinct, i.e.multiple instances tuple may produced.)score2 (s, v, I) =1 X |v\s (Os (i)) Ov (i)||I| iI |v\s (Os (i)) Ov (i)|revised score useful however, gives unfair advantage definitionsproduce output attributes source. far easiercorrectly produce subset output attributes produce them. Considerexample two source definitions shown below. two definitions identical exceptsecond returns output distance value dist2, first not:source5($zip1, $dist1, zip2, ):- source4($zip1, $zip2, dist2), (dist2, dist1).source5($zip1, $dist1, zip2, dist2):- source4($zip1, $zip2, dist2), (dist2, dist1).Since two identical, projection subset case returnnumber tuples. means definitions would get score althoughsecond definition clearly better first since produces required outputs.need able penalise partial definitions way attributesdont produce. One way first calculate size domain |D[a]|21fiCarman & Knoblockmissing attributes. example above, missing attribute distance value.Since distance continuous value, calculating size domain obvious.approximate size domain by:|D[distance]|max minaccuracyaccuracy error-bound distance values. (We discuss error-boundssection 5.4.) Note cardinality calculation may specific semantic type.Armed domain size, penalise score definition dividingproduct size domains output attributes generateddefinition. essence, saying possible values extra attributesallowed definition. technique similar techniques used learningwithout explicit negative examples (Zelle, Thompson, Califf, & Mooney, 1995).set missing output attributes given expression sc \v, thus penaltymissing attributes size domain tuples scheme, i.e.:penalty = |D[sc \v]|Using penalty value calculate new score, takes account missingattributes. Simply dividing projected score penalty would adhereintended meaning compensating missing attribute values, thus may skewresults. Instead, derive new score introducing concept typed dom predicatesfollows:dom predicate semantic data-type t, denoted domt , single arityrelation whose extension set domain datatype, i.e. E[domt ] =D[t]. Similarly, dom predicate scheme A, denoted domA , relationwhose extension E[domA ] = D[A].Dom predicates introduced Duschka handle problem query reformulationpresence sources binding constraints (Duschka, 1997). (In workpredicates typed, although typing would resulted efficient algorithm.) use convert partial definition v safe (complete) definitionv 0 . simply adding dom predicate end view definitiongenerates values missing attributes. example above, v 0 would be:source5($zip1, $dist1, zip2, x) :source4($zip1, $zip2, dist2), (dist2, dist1), domdistance (x).x new variable type distance. new view definition v 0 safe,variables head clause also appear body. general,turn unsafe view definition v safe definition v 0 appending dom predicatedomsc \v (x1 , ..., xn ), xi distinguished variable (from head clause)corresponding output attribute v 0 wasnt bound v. usecomplete definition calculate score before:score3 (s, v, I) = score(s, v 0 , I) =221 X |Os (i) Ov0 (i)||I| iI |Os (i) Ov0 (i)|fiLearning Semantic Definitions Information Sources Internetrewritten (by expanding denominator) follows:score3 (s, v, I) =|Os (i) Ov0 (i)|1 X|I| iI |Os (i)| + |Ov0 (i)| |Os (i) Ov0 (i)|remove references v 0 equation considering:Ov0 (i) = Ov (i) E[domsc \v ] = Ov (i) D[sc \v]Thus size set given |Ov0 (i)| = |Ov (i)||D[sc \v]| size intersectioncalculated taking projection output attributes produced v:|Os (i) Ov0 (i)| = |v\s (Os (i) Ov (i) D[sc \v])| = |v\s (Os (i)) Ov (i)|Substituting cardinalities score function given above, arrive followingequation penalised score:score3 (s, v, I) =|v\s (Os (i)) Ov (i)|1 X|I| iI |Os (i)| + |Ov (i)||D[sc \v]| |v\s (Os (i)) Ov (i)|5.2 Binding Constraintscandidate definitions generated search may different bindingconstraints target predicate. instance partial definition shown below,variable zip2 output target source, input source4 :source5($zip1, $dist1, zip2, ) :- source4($zip1, $zip2, dist1).logical perspective, order test definition correctly, need invokesource4 every possible value domain zipcodes. practicaltwo reasons: firstly, system may complete list zipcodes disposal.Secondly far importantly, invoking source4 thousands different zipcodeswould take long time would probably result system blockeduse service. instead invoking source thousands times,approximate score definition sampling domain zipcodesinvoking source using sampled values. compensate samplingscaling (certain components of) score ratio sampled zipcodesentire domain. Considering example above, randomly choose sample (denoted[zipcode]) say 20 values domain zipcodes, set tuples returneddefinition need scaled factor |D[zipcode]|/20.general equation computing scaling factor (denoted SF ) shown below.Note sampling may need performed set attributes. (Here v \sdenotes input attributes v outputs s.)SF =|D[v \s ]||[v \s ]|calculate effect scaling factor overall score follows. denoteset tuples returned definition given sampled input Ov (i). value23fiCarman & Knoblockscaled approximate set tuples would returneddefinition invoked possible values additional input attributes:|Ov (i)| |Ov (i)| SFAssuming sampling performed randomly domain possible values,intersection tuples produced source definition scaleway. Thus factor affected scaling score defined previously|Os (i)|. divide throughout scaling factor new scoring function:score4 (s, v, I) =|v\s (Os (i)) Ov (i)|1 X|I| iI |Os (i)|/SF + |Ov (i)||D[sc \v]| |v\s (Os (i)) Ov (i)|problem approach often sampled set values smallresult intersect set values returned source, even though largersample would intersected way. Thus sampling introduces unfair distortionsscore certain definitions, causing perform poorly. example, considersource5 assume scalability purposes, service places limitmaximum value input radius dist1. (This makes sense, otherwise user couldset input radius cover entire US, tuple every possible zipcode wouldneed returned.) consider sampling performed above. randomly choose20 zipcodes set possible zipcodes, chance sample containingzipcode lies within 300 mile radius particular zipcode (in middledesert) low. Moreover, even one pair zipcodes (out 20) results successfulinvocation, sufficient learning good definition service.get around problem bias sample that, whenever possible, halfvalues taken positive examples target (those tuples returned newsource) half taken negative examples (those tuples returned source).sampling positive negative tuples, guarantee approximationgenerated accurate possible given limited sample size. denote setpositive negative samples + [v \s ] [v \s ], use values definepositive total scaling factors shown below. (The numerator positive valuesdifferent before, values taken output new source.)SF + =|v \s (v\s (Os (i)))|| + [v \s ]|total scaling factor value before, calculated slightly differently:SF =|D[v \s ]|| + [v \s ]| + | [v \s ]|score approximated accordingly taking account new scalingfactors. intersection needs scaled using positive scaling factor:|v\s (Os (i)) Ov (i)| |v\s (Os (i)) Ov (i)| SF +new scaling results new function evaluating quality view definition:score5 (s, v, I) =|v\s (Os (i)) Ov (i)| SF +1 X|I| iI |Os (i)| + |Ov (i)||D[sc \v]| SF |v\s (Os (i)) Ov (i)| SF +24fiLearning Semantic Definitions Information Sources Internet5.3 Favouring Shorter Definitionsderived score comparing data source candidateproduce, define evaluation function eval used Algorithm 1. mentionedsection 4.6, shorter definitions target source preferred longerpossibly less accurate ones. accordance principle, scale scorelength definition, favour shorter definitions follows:eval(v) = length(v) score5 (s, v, I)length(v) length clause < 1 weighting factor. Settingweighting factor little less 1 (such 0.95) helps remove logically redundantdefinitions, sometimes hard detect, often return almost exactlyscore shorter equivalent. discuss problem generating non-redundantclauses section 6.3.5.4 Approximating Equalitynow, ignored problem deciding whether two tuples producedtarget source definition same. Since different sources may serialize datadifferent ways different levels accuracy, must allow flexibilityvalues tuples contain. instance, example section 2, distancevalues returned source definition match exactly, sufficientlysimilar accepted value.numeric types like temperature distance makes sense use error bound (like0.5 C) percentage error (such 1%) decide two values consideredsame. sensing equipment (in case temperature) algorithm (incase distance) error bound associated values produces.require error bound numeric type provided problem specification.(Ideally, bounds would learnt automatically examples.)certain nominal types like company names, values like hIBM CorporationihInternational Business Machines Corp.i represent value, simplistic equalitychecking using exact substring matches sufficient deciding whether two valuescorrespond entity. case, string edit distances JaroWinklerscore better distinguishing strings representing entity representingdifferent ones (Bilenko, Mooney, Cohen, Ravikumar, & Fienberg, 2003). machine learningclassifier could trained set examples learn available stringedit distances best distinguishes values type threshold set acceptingpair match. require pair similarity metric threshold (orcombinations metrics) provided problem specification.cases, enumerated types like months year might associatedsimple equality checking procedure, values like hJanuaryi, hJani h1ifound equal. actual equality procedure used depend semantic typeassume work procedure given problem definition. noteprocedure need 100% accurate, provide sufficient level accuracyguide system toward correct source description. Indeed, equality rules couldalso generated offline training classifier.25fiCarman & KnoblockComplex types date present bigger problem one considers rangepossible serializations, including values like h5/4/2006i hThu, 4 May 2006i h2006-05-04i.cases specialized functions required check equality valuesalso break complex types constituent parts (in case day, monthyear ). latter would form part domain model.cases, deciding whether two values type considered equaldepends type, also relations used in. Considertwo relations shown below. first provides latitude longitude coordinatescentroid zipcode, second returns coordinates particular address:centroid(zipcode, latitude, longitude)geocode(number, street, zipcode, latitude, longitude)Given different ways calculating centroid zipcode (including using centermass center population density) error bound 500 meters might make senseequating latitude longitude coordinates. geocoding service, hand,error bound 50 meters may reasonable. general, error boundsassociated set global relations, instead semantic types, couldlearnt accordingly. relations contain multiple attributes, problemdeciding whether two tuples refer entity called record linkage (Winkler,1999). entire field research devoted tackling problem. Due complexityproblem variety techniques developed handle it,investigate here.6. Extensionssection discuss extensions basic algorithm needed handling real datasources, well ways reduce size hypothesis space improve qualitydefinitions produced.6.1 Generating Inputsfirst step source induction algorithm generate set tuplesrepresent target relation induction process. words, system musttry invoke new source gather example data. without biasinginduction process easier said done. simplest approach generating input valuesselect constants random set examples given problem specification.problem approach cases new source produceoutput selected inputs. Instead system may need select values accordingdistribution domain values order source invoke correctly.example, consider source providing posts used cars sale certain area. sourcetakes make car input, returns car details:usedCars($make, model, year, price, phone)Although hundred different car manufacturers world,produce bulk cars. Thus invoking source values like Ferrari,Lotus Aston Martin less likely return tuples, comparedcommon brands Ford Toyota (unless source providing data sportscars course). distribution possible values available, system first try26fiLearning Semantic Definitions Information Sources Internetcommon values, generally, choose values set accordingdistribution. particular example, might difficult query sourcecomplete set car manufacturers one invocations returns data.general, set examples may large (such 40,000+ zipcodes US)number interesting values set (the ones likely return results) maysmall, case taking advantage prior knowledge distributionpossible values makes sense. noted also execution systemreceive lot output data different sources accesses. data recordedgenerate distributions possible values different types.problem generating viable input data new source becomes yet difficultinput required single value tuple values. case systemfirst try invoke source random combinations attribute valuesexamples type. Invoking sources (such source5 ) easyexplicit restriction combination input values:source5($zip, $distance, zip, distance)cases, geocoding service combination possible input values highlyrestricted:USGeocoder($number, $street, $zipcode, latitude, longitude)Randomly selecting input values independently one another unlikely resultsuccessful invocations. (In order invocation succeed, randomly generatedtuple must correspond address actually exists.) cases, failinginvoke source number times, system try invoke sources (suchhotel lookup service below), produce tuples containing required attribute types:HotelSearch($city, hotel, number, street, zipcode)general, process invoking sources generate input sources chainedset viable inputs generated.note problem synthesizing viable input data difficultinteresting research problem. combined approach utilizing value distributionsinvoking alternative services performs well experiments (see section 7.3), areafuture work develop general solution.6.2 Dealing Sourcesorder minimise source accesses, expensive terms timebandwidth, requests individual sources cached local relational database.implementation means implicit assumption workoutput produced services constant duration induction process.could problematic service modeled provides (near) real-time dataupdate frequency less time takes induce definition. weatherprediction service, updated hourly, may present much problem, sincedifference predicted temperatures may vary slightly one updatenext. real-time flight status service providing coordinates given aircraftevery five minutes, caching may problematic location plane varygreatly takes, example, one hour induce definition. theory one could testvariation systematically periodically invoking source previously27fiCarman & Knoblocksuccessful input tuple see output changed, update caching policyaccordingly.6.3 Logical OptimisationsEvaluating definitions expensive terms time (waiting sources return data) computation (calculating joins large tables). Thus makes sensecheck candidate redundancy evaluating it. decide definitionsredundant, use concept query containment:query q1 LR,A said contained another query q2 LR,Adatabase instance I, set tuples returned first query subsetreturned second, i.e. EI [q1 ] EI [q2 ]. denote containmentq1 v q2 . Two queries considered logically equivalent q1 v q2 q2 v q1 .conjunctive queries learnt paper, testing query containment reducesproblem finding containment mapping (Chandra & Merlin, 1977).11 usetest discover logically equivalent definitions following, (which containreordering literals):source($zip, temp):- getCentroid($zip, lat, lon), getConditions($lat, $lon, temp).source($zip, temp):- getConditions($lat, $lon, temp), getCentroid($zip, lat, lon).equivalence checking performed efficiently canonical ordering predicatevariable names chosen priori. Whenever logically equivalent definitions discovered, search backtrack, thereby avoiding entire sub-trees equivalent clauses.Similarly, test skip logically redundant clauses following (whichequivalent shorter definition without second literal):source($zip, ):- getCentroid($zip, lat, long), getCentroid($zip, lat, ).Again, redundancy checking performed efficiently (Levy, Mendelzon, Sagiv, &Srivastava, 1995) resulting little computational overhead search.6.4 Functional Sourcesinformation may known functionality certain sources expressedsource definitions. example, sources like Multiply Concatenate,implemented locally, known complete. (A source considered complete,returns tuples implied definition, i.e. E[s] = EI [v].) Wheneverinformation available, induction system take advantage improve searchefficiency. explain how, define class sources call functional sources,complete input tuple return exactly one output tuple. slightlyrestrictive standard ILP concept determinate literals (Cameron-Jones &Quinlan, 1994), every input tuple return one output tuple. MultiplyConcatenate examples functional sources. system takes advantage factfunctional sources place restrictions input. Whenever functional sourceadded candidate definition, score definition doesnt change providingsources inputs none outputs bound. (The set tuples returned new11. queries contain interpreted predicates, containment testing little involved (Afrati,Li, & Mitra, 2004).28fiLearning Semantic Definitions Information Sources Internetdefinition before, new attributes corresponding outputssource.) Thus new definition need evaluated, addedqueue (of definitions expand) is, becomes particularly advantageoussources input arity high.6.5 ConstantsConstants often used source descriptions define scope service. Considerweather service provides reports zipcodes California:calWeather($zip, $date, temp) :- forecast(zip, date, temp), USstate(zip, California).mediator receives query asking forecast Chicago, knowsource relevant query since Chicago California. Although constantssource descriptions useful, simply introducing hypothesislanguage could cause search space grow prohibitively. (For states, branchingfactor would 50, zipcodes would excess 40,000.) Obviously generatetest methodology make sense domain semantic type large.Alternatively, one explicitly check repeated values tuples returnednew source (i.e. constants head clause) join sourcedefinition relations (i.e. constants body clause). example,definition join source relation hzip, date, tempi definition relationhzip, date, temp, statei would produce tuples state equal California.constant could added definition.source($zip, $date, temp) :- forecast(zip, date, temp), USstate(zip, state).complicated detection procedures would required discovering constants interpreted predicates (i.e. range restrictions numeric attributes).6.6 Post-Processingdefinition learnt new source, may possible tightendefinition removing logical redundancies unfolding. Consider followingdefinition involving calls two hotel sources, one check availabilitycheck rating:source($hotel, address, rating):HotelAvailability($hotel, address, price), HotelRating($hotel, rating, address).unfolding definition (in terms definitions hotel sources) containstwo references accommodation relation:source($hotel, address, rating):accommodation(hotel, , address), available(hotel, today, price),accommodation(hotel, rating, address).first literal redundant removed unfolding. general,rules used discover redundancy candidate definitions used remove redundantliterals unfolding. Moreover, since post-processing step needs performedonce, time spent searching complicated forms redundancy.29fiCarman & Knoblock7. Evaluationsection describe evaluation source induction algorithm. firstdescribe experimental setup used experiments performed. Finally,compare induction algorithm particular complex schema matching system.7.1 Experimental Setupsource induction algorithm defined paper implemented system calledeidos, stands Efficiently Inducing Definitions Online Sources. eidos implements techniques optimisations discussed sections 4 6. (Certainextensions section 6 partially implemented: implementation currentlychecks constants head clause perform tighteningdefinitions.) code written Java MySQL database used cachingresults source invocations.eidos tested 25 different problems involving real services several domainsincluding hotels, financial data, weather cars. domain model usedproblem included 70 different semantic types, ranging commonones like zipcode specific types stock ticker symbols. data modelalso contained 36 relations (excluding interpreted predicates), used model 33different services. modeled services publicly available information sources.note decision use set known sources problem(regardless domain) important order make sure tests realistic.decision made problem difficult standard schema matching/mappingscenario source schema chosen, provides data knownpriori relevant output schema.order give better sense problem setting complexity knownsources available, list ten (ordered arity). Due space limitations dontshow complete list definitions, input/output types source.Note sources share semantic types latitude longitude, meanssearch space associated sources alone large.1WeatherConditions($city,state,country,latitude,longitude,time,time,timeoffset,datetime,temperatureF,sky,pressureIn,direction,speedMph,humidity,temperatureF)2 WeatherForecast($city,state,country,latitude,longitude,timeoffset,day,date,temperatureF,temperatureF,time,time,sky,direction,speedMph,humidity)3 GetDistance($latitude,$longitude,$latitude,$longitude,distanceKm)4 USGeocoder($street,$zipcode,city,state,latitude,longitude)5 ConvertDMS($latitudeDMS,$longitudeDMS,latitude,longitude)6 USGSEarthquakes(decimal,timestamp,latitude,longitude)7 GetAirportCoords($iata,airport,latitude,longitude)8 CountryCode($latitude,$longitude,countryAbbr)9 GetCentroid($zipcode,latitude,longitude)10 Altitude($latitude,$longitude,distanceM)order induce definitions problem, source (and candidate definition) invoked least 20 times using random inputs. Whenever possible, systemattempted generate 10 positive examples source (invocations sourcereturned tuples) 10 negative examples (inputs produced output).30fiLearning Semantic Definitions Information Sources Internetensure search terminated, number iterations algorithm including backtracking steps limited 30. search time limit 20 minutes also imposed.inductive search bias used experiments shown below, weighting factor(defined section 5.3) 0.9 used direct search toward shorter definitions.Search BiasMaximum clause length = 7Maximum predicate repetition = 2Maximum variable level = 5Executable candidatesvariable repetition within literalexperiments, different procedures used decide equality valuestype discussed section 5.4. equality procedures used differenttypes listed below. accuracy bounds thresholds used chosen maximizeoverall performance learning algorithm. (In practice, meta-learning algorithmcould used determine best accuracy bounds different attribute types.)semantic types listed below, substring matching (checking one string containedother) used test equality values.Typeslatitudes, longitudesdistances, speeds, temperatures, priceshumidity, pressure, degreesdecimalscompanies, hotels, airportsdatesEquality Procedureaccuracy bound 0.002accuracy bound 1%accuracy bound 1.0accuracy bound 0.1JaroWinkler score 0.85specialised equality procedureexperiments run dual core 3.2 GHz Pentium 4 4 GB RAM (althoughmemory limiting factor tests). system running Windows2003 Server, Java Runtime Environment 1.5 MySQL 5.0.7.2 Evaluation Criteriaorder evaluate induction system, one would like compare problemdefinition generated system ideal definition source (denoted vbestv respectively). words, would like evaluation function, ratesquality definition produced respect hand-written definitionsource (i.e. quality : vbest v [0, 1]). problem twofold. Firstly,obvious define similarity function conjunctive queries manydifferent possibilities exist (see Markov Marinchev, 2000, particular example).Secondly, working best definition hand, taking account limitationsdomain model fact available sources noisy, incomplete, possiblyless accurate, even serialise data different ways, may extremely difficult, evenpossible. order evaluate discovered definitions, instead countnumber correctly generated attributes definition. attribute saidcorrectly generated, if:31fiCarman & Knoblockinput, definition correctly restricts domain possible valuesattribute,output, definition correctly predicts value given input tuples.Consider following definition takes two input values returns differencesquare root (providing difference positive):source($A, $B, C, D) :- sum(B, C, A), product(D, D, C), B.imagine induction system managed learn source returnsdifference input output, i.e.:source($A, $B, C, ) :- sum(B, C, A).say first input attribute correctly generated inputconstrained respect input attribute B (the inequality missing). input Bdeemed correctly generated present sum relation (only one input penalisedmissing inequality). output C deemed correctly generated respectinputs, missing attribute isnt generated all. (Note orderingvariables sum relation different, say sum(A, B, C), C wouldgenerated, correctly generated.)Given definition correctly generated attributes, one define expressionsprecision recall attributes contained source definition. define precisionratio correctly generated attributes total number attributes generateddefinition, i.e.:precision =# correctly generated attributestotal # generated attributesdefine recall ratio generated attributes total number attributeswould generated ideal definition, given sources available. (Incases sources available generate values attribute case,attribute included count.)recall =# correctly generated attributestotal # attributes generatedNote defined precision recall schema level terms attributesinvolved source definition. could also defined data level termstuples returned source definition. Indeed, Jaccard similarityused score candidate definitions combination data-level precision recall values.reason choosing schema level metrics evaluation better reflectsemantic correctness learnt definition, far independentcompleteness (amount overlap) known target sources.Returning example above, precision simple definition learnt would2/3 recall would 2/4. Note that, product relation availabledomain model (in case attribute could never generated), recallwould higher 2/3.32fiLearning Semantic Definitions Information Sources Internet7.3 Experimentsdefinitions learnt system described below. Overall system performedwell able learn intended definition (ignoring missing join variablessuperfluous literals) 19 25 problems.7.3.1 Geospatial Sourcesfirst set problems involved nine geospatial data sources providing variety locationbased information. definitions learnt system listed below. reportedterms source predicates rather domain relations (i.e. unfoldings)corresponding definitions much shorter. makes easier understandwell search algorithm performing.123456789GetInfoByZip($zip0,cit1,sta2,_,tim4) :GetTimezone($sta2,tim4,_,_), GetCityState($zip0,cit1,sta2).GetInfoByState($sta0,cit1,zip2,_,tim4) :GetTimezone($sta0,tim4,_,_), GetCityState($zip2,cit1,sta0).GetDistanceBetweenZipCodes($zip0,$zip1,dis2) :GetCentroid($zip0,lat1,lon2), GetCentroid($zip1,lat4,lon5),GetDistance($lat1,$lon2,$lat4,$lon5,dis10), ConvertKm2Mi($dis10,dis2).GetZipCodesWithin($_,$dis1,_,dis3) :<(dis3,dis1).YahooGeocoder($str0,$zip1,cit2,sta3,_,lat5,lon6) :USGeocoder($str0,$zip1,cit2,sta3,lat5,lon6).GetCenter($zip0,lat1,lon2,cit3,sta4) :WeatherConditions($cit3,sta4,_,lat1,lon2,_,_,_,_,_,_,_,_,_,_,_),GetZipcode($cit3,$sta4,zip0).Earthquakes($_,$_,$_,$_,lat4,lon5,_,dec7,_) :USGSEarthquakes(dec7,_,lat4,lon5).USGSElevation($lat0,$lon1,dis2) :ConvertFt2M($dis2,dis1), Altitude($lat0,$lon1,dis1).CountryInfo($cou0,cou1,cit2,_,_,cur5,_,_,_,_) :GetCountryName($cou0,cou1), GoCurrency(cur5,cou0,_),WeatherConditions($cit2,_,cou1,_,_,_,_,_,_,_,_,_,_,_,_,_).first two sources provide information zipcodes, name city,state timezone. differ binding constraints, first takingzipcode input, second taking state. second source returns many outputtuples per input value, making harder learn definition, even though two sourcesprovide logically information. induced definitions best possible givenknown sources available. (None provided missing output attribute, telephone area-code.) third source calculates distance miles two zipcodes,(it source4 section 2). correct definition learnt source,next source, returned zipcodes within given radius, reasonable definition could learnt within time limit.12 Ignoring binding constraints, intended12. recall problem 1/4 input attribute dis1 determined correctlygenerated attribute (it constrained respect output attribute dis3 ), four attributesgenerated (the output attribute dis3 generated < predicate). precision1/1 dis1 generated attribute, correctly generated.33fiCarman & Knoblockdefinition third, restriction output distance lessinput distance. Thus would far easier eidos learn definitionfourth source terms third. Indeed, new definition thirdsource added set known sources, system able learn following:4 GetZipCodesWithin($zip0,$dis1,zip2,dis3) :GetDistanceBetweenZipCodes($zip0,$zip2,dis3), <(dis3,dis1).ability system improve learning ability time set knownsources increases key benefit approach.Source five geocoding service provided Yahoo. (Geocoding services map addresses latitude longitude coordinates.) eidos learnt functionalityprovided service called USGeocoder. Source six simple service providinglatitude/longitude coordinates city state given zipcode. Interestingly,system learnt sources coordinates better predicted weather conditions service (discussed section 7.3.3), GetCentroid source thirddefinition. Note new source definition unfolded contain extraneous predicates related weather information.13 additional predicates interfereusefulness definition, however, query reformulation algorithm stilluse source answer queries regardless. (Thus precision recall scoresaffected.) post-processing step remove extraneous predicates possible,would require additional information domain model.14 seventh source providedearthquake data within bounding box took input. case, systemdiscovered source indeed providing earthquake data, (lat4 lon5 coordinates earthquake dec7 magnitude). didnt manage, however, workinput coordinates related output. next source provided elevationdata feet, found sufficiently similar known altitude data metres.Finally, system learnt definition source providing information countriescurrency used, name capital city. Since known sourcesavailable provide information, system ended learning weather reportsavailable capital country.Problem123456789# Candidates2524888350401115176# Invocations50689804111361117613148151621487717728784Time (s)85914449253242831872559log10 (Score)-1.36-1.08-0.750.25-0.45-7.61-6.87-8.58-5.77Precision4/44/43/31/16/65/53/33/34/4Recall4/44/43/31/46/65/53/93/34/413. unfolding shown below. conditions predicate could removed without affecting meaning:GetCenter($zip0, lat1, lon2, cit3, sta4):- municipality(cit3, sta4, zip2, tim3), country( , cou5, ),northAmerica(cou5), centroid(zip2, lat1, lon2), conditions(lat1, lon2, , , , , , , , , , , ),timezone(tim3, , ), municipality(cit3, sta4, zip0, ).14. particular, universally quantified knowledge would needed domain model, e.g.:lat, lon x1 , ..., x11 s.t. conditions(lat, long, x1 , ..., x11 )34fiLearning Semantic Definitions Information Sources Internettable shows details regarding search performed learn definitions listed above. problem, shows number candidates generated priorwinning definition, along time number source invocations requiredlearn definition. (The last two values interpreted cautionhighly dependent delay accessing sources, caching datasystem.) scores shown fifth column normalised version scoringfunction used compare definitions search. (Normalisation involved removingpenalty applied missing outputs.) scores small, logarithmvalues shown (hence negative values).15 scores interpretedconfidence system definitions produced. closer value zero,better definitions ability produce tuples source. seesystem far confident definitions one five, latterones.16 last two columns give precision recall value problem.average precision problems 100%. (Note high precision valueexpected, given induction algorithm relies finding matching tuplessource definition.) average recall geospatial problems also high84%.7.3.2 Financial SourcesTwo sources tested provided financial data. definitions generated eidossources shown below.10 GetQuote($tic0,pri1,dat2,tim3,pri4,pri5,pri6,pri7,cou8,_,pri10,_,_,pri13,_,com15):YahooFinance($tic0,pri1,dat2,tim3,pri4,pri5,pri6,pri7,cou8),GetCompanyName($tic0,com15,_,_),Add($pri5,$pri13,pri10),Add($pri4,$pri10,pri1).11 YahooExchangeRate($_,$cur1,pri2,dat3,_,pri5,pri6) :GetCurrentTime(_,_,dat3,_), GoCurrency(cur1,cou5,pri2),GoCurrency(_,cou5,pri5), Add($pri2,$pri5,pri12), Add($pri2,$pri6,pri12).first financial service provided stock quote information, system learntsource returned exactly information stock market service provided Yahoo.also able work previous days close plus todays change equalcurrent price. second source provided rate exchange currenciesgiven input. case, system fare well. unable learn intendedresult, involved calculating exchange rate taking ratio valuesfirst second currency.Problem1011# Candidates2844367# Invocations1667116749Time (s)387282log10 (Score)-8.13-9.84Precision12/131/5Recall12/121/4Details regarding search spaces two problems shown above. averageprecision recall problems much lower 56% 63% respectively,system unable learn intended definition second problem.15. positive value problem 4 results approximation error.16. Low scores perfect precision recall (problems 6, 8 9) indicate little overlaptarget known sources. fact system learns correct definition casestestimony robustness approach.35fiCarman & Knoblock7.3.3 Weather SourcesInternet, two types weather information services, provideforecasts coming days, provide details current weather conditions.experiments, pair services provided Weather.com used learn definitions number weather sources. first set definitions, correspondsources provide current weather conditions, listed below:12 NOAAWeather($ica0,air1,_,_,sky4,tem5,hum6,dir7,spe8,_,pre10,tem11,_,_) :GetAirportInfo($ica0,_,air1,cit3,_,_),WeatherForecast($cit3,_,_,_,_,_,_,_,_,_,_,_,sky4,dir7,_,_),WeatherConditions($cit3,_,_,_,_,_,_,_,_,tem5,sky4,pre33,_,spe8,hum6,tem11),ConvertIn2mb($pre33,pre10).13 WunderGround($sta0,$cit1,tem2,_,_,pre5,pre6,sky7,dir8,spe9,spe10) :WeatherConditions($cit1,sta0,_,_,_,_,_,_,dat8,tem9,sky7,pre5,dir8,spe13,_,tem2),WeatherForecast($cit1,sta0,_,_,_,_,_,_,tem24,_,_,_,_,_,spe10,_),ConvertIn2mb($pre5,pre6),<(tem9,tem24),ConvertTime($dat8,_,_,_,_),<(spe9,spe13).14 WeatherBugLive($_,cit1,sta2,zip3,tem4,_,_,dir7,_,_) :WeatherConditions($cit1,sta2,_,_,_,_,_,_,_,tem4,_,_,dir7,_,_,_),GetZipcode($cit1,$sta2,zip3).15 WeatherFeed($cit0,$_,tem2,_,sky4,tem5,_,_,pre8,lat9,_,_) :WeatherConditions($cit0,_,_,lat9,_,_,_,_,_,_,sky4,pre8,dir12,_,_,tem5),WeatherForecast($cit0,_,_,_,_,_,_,_,_,tem2,_,_,_,dir12,_,_).16 WeatherByICAO($ica0,air1,cou2,lat3,lon4,_,dis6,_,sky8,_,_,_,_) :Altitude($lat3,$lon4,dis6), GetAirportInfo($ica0,_,air1,cit6,_,cou8),WeatherForecast($cit6,_,cou8,_,_,_,_,_,_,_,_,_,sky8,_,_,_),GetCountryName($cou2,cou8).17 WeatherByLatLon($_,$_,_,_,_,lat5,lon6,_,dis8,_,_,_,_,_,_) :Altitude($lat5,$lon6,dis8).first problem, system learnt source 12 provided current conditions airports,checking weather report cities airport located.particular problem demonstrates advantages learning definitions newsources described section 3.3. definition learnt, mediator receivesrequest current conditions airport, generate answer queryexecuting single call newly modeled source, (without needing find nearbycity). system performed well next three sources (13 15) learning definitionscover attributes each. last two problems, systemperform well. case source 16, system spent time learningattributes airport returned (such country, coordinates, elevation,etc.). last case, system able learn source returningcoordinates along elevation. note different sources may providedata different levels accuracy. Thus fact system unable learndefinition particular source could simply mean data returnedsource wasnt sufficiently accurate system label match.addition current weather feeds, system run two problems involvingweather forecast feeds. well first problem, matching bar oneattributes (the country) finding order high low temperatures36fiLearning Semantic Definitions Information Sources Internetinverted. well also second problem, learning definition sourceproduced output attributes.18 YahooWeather($zip0,cit1,sta2,_,lat4,lon5,day6,dat7,tem8,tem9,sky10) :WeatherForecast($cit1,sta2,_,lat4,lon5,_,day6,dat7,tem9,tem8,_,_,sky10,_,_,_),GetCityState($zip0,cit1,sta2).19 WeatherBugForecast($_,cit1,sta2,_,day4,sky5,tem6,_) :WeatherForecast($cit1,sta2,_,_,_,tim5,day4,_,tem6,_,tim10,_,sky5,_,_,_),WeatherConditions($cit1,_,_,_,_,tim10,_,tim5,_,_,_,_,_,_,_,_).Details regarding number candidates generated order learn definitionsdifferent weather sources shown below. average precision definitions produced91%, average recall 62%.Problem1213141516171819# Candidates27719899819910245119116# Invocations579426249975494676691387614857Time (s)23360593029248410267591217log10 (Score)-2.92-6.35-13.37-6.48-29.69-26.71-5.74-12.56Precision8/96/95/55/66/73/310/105/5Recall8/116/105/85/106/93/1310/115/77.3.4 Hotel SourcesDefinitions also learnt sources providing hotel information Yahoo, GoogleUS Fire Administration. definitions shown below.20 USFireHotelsByCity($cit0,_,_,sta3,zip4,cou5,_) :HotelsByZip($zip4,_,_,cit0,sta3,cou5).21 USFireHotelsByZip($zip0,_,_,cit3,sta4,cou5,_) :HotelsByZip($zip0,_,_,cit3,sta4,cou5).22 YahooHotel($zip0,$_,hot2,str3,cit4,sta5,_,_,_,_,_) :HotelsByZip($zip0,hot2,str3,cit4,sta5,_).23 GoogleBaseHotels($zip0,_,cit2,sta3,_,_,lat6,lon7,_) :WeatherConditions($cit2,sta3,_,lat6,lon7,_,_,_,_,_,_,_,_,_,_,_),GetZipcode($cit2,$sta3,zip0).system performed well three four problems. unable timeallocated discover definition hotel attributes (name, street, latitude longitude) returned Google Web Service. average precision problems90% average recall 60%.Problem20212223# Candidates16164395# Invocations448189431374931Time (s)485282116137log10 (Score)-4.00-2.56-2.81-7.50Precision4/44/45/53/5Recall4/64/65/93/6fiCarman & Knoblock7.3.5 Cars Traffic Sourceslast problems system tested pair traffic related Web Services.first service, provided Yahoo, reported live traffic data (such accidentsconstruction work) within given radius input zipcode. known sourcesavailable provided information, surprisingly, system unablelearn definition traffic related attributes source. (Instead, systemdiscovered relationship input zipcode output longitude wasntcorrect, precision problem zero.)24 YahooTraffic($zip0,$_,_,lat3,lon4,_,_,_) :GetCentroid($zip0,_,lon4), CountryCode($lat3,$lon4,_).25 YahooAutos($zip0,$mak1,dat2,yea3,mod4,_,_,pri7,_) :GoogleBaseCars($zip0,$mak1,_,mod4,pri7,_,_,yea3),ConvertTime($dat2,_,dat10,_,_), GetCurrentTime(_,_,dat10,_).second problem involved classified used-car listing Yahoo took zipcodecar manufacturer input. eidos able learn good definition source,taking advantage fact cars (defined make, model, yearprice) also listed sale Googles classified car listing.Problem2425# Candidates8155# Invocations29974405Time (s)1065815log10 (Score)-11.21-5.29Precision0/36/6Recall0/46/6Since system failed first problem (it found incorrect/non-general relationships different attributes), succeeded second problem find bestpossible definition, average precision recall problems 50%.7.3.6 Overall ResultsAcross 25 problems, eidos managed generate definitions high accuracy (averageprecision 88%) large number attributes (average recall 69%). resultspromising, especially considering problems involved real data sourcescases small overlap data produced target providedknown sources (as evidenced low logarithmic scores). addition minimaloverlap, many sources provided incomplete tuples (i.e. tuples containing multiple NULLN/A values) well erroneous inaccurate data, making problemdifficult. high average precision recall lead us believe Jaccard measuregood job distinguishing correct incorrect definitions presencedata sources noisy (inconsistent) incomplete (missing tuples values).Comparing different domains, one see system performed betterproblems fewer input output attributes (such geospatial problems),expected given resulting search space much smaller.38fiLearning Semantic Definitions Information Sources Internet7.4 Empirical Comparisondemonstrated effectiveness eidos learning definitions real informationservices, show system capable handling problemswell-known complex schema matching system.iMAP system (Dhamanka, Lee, Doan, Halevy, & Domingos, 2004) (discussedsection 8.4) schema matcher learn complex (many-to-one) mappingsconcepts source target schema. uses set special purpose searcherslearn different types mappings. eidos system, hand, uses genericsearch algorithm solve comparable problem. Since two systems madeperform similar task, show eidos capable running one problemdomains used evaluation iMAP. chose particular domain online cricketdatabases one used evaluation involved aligning datatwo independent data sources. (All problems involved generating synthetic datasplitting single database source target schema, wouldinteresting eidos.)Player statistics two online cricket databases (cricketbase.com cricinfo.com)used experiments. Since neither sources provided programmatic accessdata, statistics data extracted HTML pages insertedrelational database. extraction process involved flattening data relationalmodel small amount data cleaning. (The resulting tables similarnecessarily exactly used iMAP experiments.) datatwo websites used create three data sources representing website. threesources representing cricinfo.com used learn definitions three sourcesrepresenting cricketbase.com. known sources available system, includingfunctionality splitting apart comma-separated lists, adding multiplying numbers,on. definitions learnt describe cricketbase services shown below:1 CricbasePlayers($cou0,nam1,_,dat3,_,unk5,unk6) :CricinfoPlayer($nam1,dat3,_,_,_,lis5,nam6,unk5,unk6), contains($lis5,cou0),CricinfoTest($nam6,_,_,_,_,_,_,_,_,_,_,_,_,_,_,_,_,_,_,_,_,_).2 CricbaseTest($_,nam1,cou2,_,_,_,cou6,cou7,dec8,cou9,_,_,_,cou13,cou14,dec15,_,dec17,cou18,_,_) :CricinfoTest($nam1,_,_,cou2,cou6,cou18,cou7,_,dec8,dec15,_,cou9,_,_,_,cou14,cou13,_,_,_,_,dec17).3 CricbaseODI($_,nam1,cou2,_,_,_,cou6,cou7,dec8,cou9,cou10,_,cou12,cou13,_,dec15,dec16,dec17,cou18,cou19,_) :CricinfoODI($nam1,_,_,cou2,cou6,_,cou10,_,dec8,_,cou7,cou18,cou19,cou9,_,_,cou13,cou12,dec15,_,dec16,dec17).first source provided player profiles country. second third sources provideddetailed player statistics two different types cricket (Test One-Day-Internationalrespectively). system easily found best definition first source. definitioninvolved looking players country list teams played for. eidosperform quite well second third problems. two reasonsthis. Firstly, arity sources much higher many instancessemantic type (count decimal ), making space possible alignments much larger.39fiCarman & Knoblock(Because large search space, longer timeout 40 minutes used.) Secondly,high frequency null values (the constant N/A) data fieldsconfused algorithm, made harder discover overlapping tuplesdesired attributes.Problem123# Candidates19911623114# Invocations376215174299Time (s)43213192127log10 (Score)-3.95-4.70-6.28Precision5/58/118/14Recall5/58/168/16Details search performed learn definitions shown above. averageprecision problems 77% average recall lower 66%.values comparable quality matchings reported iMAP.17 resultsgood, considering eidos searches space many-to-many correspondences,(trying define set target attributes contemporaneously), iMAP searchesspaces one-to-one many-to-one correspondences. Moreover, eidos first invokestarget source generate representative data (a task performed iMAP)performs generic search reasonable definitions without relying specialised searchalgorithms different types attributes (as done iMAP).8. Related Worksection describe work paper relates research performedMachine Learning, Database Semantic Web communities. that,describe early work performed Artificial Intelligence community. alsodiscuss algorithm differs standard ILP techniques, particulardirect application techniques possible problem.8.1 Early Approachfirst work concerned learning models describing operations availableInternet performed (in pre-XML era) problem called category translation(Perkowitz & Etzioni, 1995; Perkowitz, Doorenbos, Etzioni, & Weld, 1997). problemconsisted incomplete internal world model external information sourcegoal characterize information source terms world model.world model consisted set objects O, object belonged certaincategory (e.g. people) associated set attributes ha1 (o), ..., (o)i, madestrings objects. simple relational interpretation world model wouldconsider category relation, object tuple. informationsource, meanwhile, operation took single value input returnedsingle tuple output. category translation problem viewed simplificationsource definition induction problem, whereby:17. actual values precision recall cricket domain quoted, accuracy range68-92% simple matches (one-to-one correspondences source target fields) 50-86%complex matches (many-to-one correspondences) across synthetic real problems given.40fiLearning Semantic Definitions Information Sources Internetextensions global relations explicit. (There one source per globalrelation, doesnt binding constraints, i.e. R = S.)information provided sources change time.new source takes single value input returns single tuple output.order find solutions instances category translation problem, authors employed variant relational path-finding (Richards & Mooney, 1992), extensionfoil algorithm, learn models external source. technique describedpaper solving instances source induction problem similarbased foil-like inductive search algorithm.8.2 Direct Application ILP techniquesResearchers became interested field Inductive Logic Programming earlynineties, resulting number different ILP systems developed including foil(Cameron-Jones & Quinlan, 1994), progol (Muggleton, 1995) aleph18 . Ideally, onewould like apply off-the-shelf ILP systems source definition inductionproblem. number issues, however, limit direct applicability systems.issues summarised follows:Extensions global relations virtual.Sources may incomplete respect definitions.Explicit negative examples target available.Sources may serialise constants different ways.first issue fact ILP systems assume extensionaldefinition target predicate extensional (or cases intentional) definitions(source) predicates used definition target. words,assume tables already exist relational database representnew source known sources. case, need generate tables firstinvoking services relevant inputs. One could envisage invoking sourcesevery possible input using resulting tables perform induction. directapproach would feasible two reasons. Firstly, complete set possible inputvalues may known system. Secondly, even possible generatecomplete set viable inputs service, may practical query sourcelarge set tuples. Consider source4 section 2, calculates distancemiles two zipcodes. Given 40,000 zipcodes US, generatingextensional representation source would require performing billioninvocations! Performing large number invocations make sensesmall number example invocations would suffice characterising functionalitysource. paper developed efficient algorithm queriessources needed order evaluate individual candidate definitions.second issue regarding incompleteness sources causes problemcandidate evaluated. Since set tuples returned known source may18. See Aleph Manual Ashwin Srinivasan, available at:http://web.comlab.ox.ac.uk/oucl/research/areas/machlearn/Aleph/aleph.html41fiCarman & Knoblocksubset implied definition, set tuples returnedcandidate hypothesis executed sources. meanssystem tries evaluate hypothesis comparing tuples outputnew source, cannot sure tuple produced new sourcehypothesis fact logically implied it. fact taken accountevaluation function scoring candidate definitions, discussed section 5.third issue regarding lack explicit negative examples target predicatealso affects evaluation candidate hypotheses. classic approach dealingproblem assume closed world, tuples (over head relation)explicitly declared positive must negative. Since new source mayfact incomplete respect best possible definition it, assumptionnecessarily hold. words, particular tuple producedcandidate definition executed tuple returned new sourcenecessarily mean candidate definition incorrect.fourth issue fact data provided different sources mayneed reconciled, sense different serialisations (strings representing)value (such Monday Mon instance) must recognized. Since ILPsystems designed operate single database containing multiple tables,issue heterogeneity data handled current systems. section 5.4discussed heterogeneity resolved system.8.3 Machine Learning ApproachesSince advent services Internet, researchers investigating waysmodel automatically. Primarily, interest centered using machine learningtechniques classify input output types service, facilitate servicediscovery. & Kushmerick proposed using Support Vector Machine classifyinput output attributes different semantic types based metadata interfacedescriptions (He & Kushmerick, 2003, 2004). notion semantic types (suchzipcode) opposed syntactic types (like integer ) went way toward definingfunctionality source provides. Recently, researchers (Lerman et al., 2006)proposed use logistic regression assigning semantic types input parametersbased metadata, pattern language assigning semantic types outputparameters based data source produces. work classifying inputoutput attributes service semantic types forms prerequisite workarticle. purposes paper, assumed problem solved.addition classifying input/output attributes services, & Kushmerickinvestigated idea classifying services different service types.precisely, used classification techniques assign service interfaces different semantic domains (such weather flights) operations interfaceprovides different classes operation (such weatherForecast flightStatus).resulting source description (hypothesis) language limited select-project queries,sufficiently expressive describe many sources available Internet.According approach, since every operation must characterized particular operation class, operations provide overlapping (non-identical) functionality would42fiLearning Semantic Definitions Information Sources Internetneed assigned different classes would operations provide composed functionality (such as, example, operation provides weather flight data).need exhaustive set operation classes (and accompanying training data) majorlimitation approach, shared work described paper, reliesexpressive language describing service operations.One way eliminate need predefined set operation types use unsupervised clustering techniques generate (operation) classes automatically examples(WSDL documents). idea implemented system called Woogle (Dong et al.,2004). system clustered service interfaces together using similarity score basedco-occurrence metadata labels. took advantage clusters produced improve keyword-based search Web Services. advantage unsupervised approachlabeled training data required, time-consuming generate.clustering approaches, however, useful service discovery, suffer limitationsprevious approach comes expressiveness.8.4 Database Approachesdatabase community long interested problem integrating datadisparate sources. Specifically, areas data warehousing (Widom, 1995) information integration (Wiederhold, 1996), researchers interested resolving semanticheterogeneity exists different databases data combinedaccessed via single interface. schema mapping problem problem determiningmapping relations contained source schema particular relationtarget schema. mapping defines transformation used populatetarget relation data source schema. Mappings may arbitrarily complexprocedures, general declarative queries SQL Datalog. complexity queries makes schema mapping problem far difficult highlyinvestigated schema matching problem (Rahm & Bernstein, 2001), involves finding1-to-1 correspondences fields source target schema.source definition induction problem viewed type schema mappingproblem, known sources define source schema unknown sourcespecifies target relation. order solve schema mapping problem, one typicallytakes advantage available auxiliary information (including source target datainstances, labels respective schemas, on). problems generallysimpler, however, data (the extensions relations) source targetschema usually explicitly available. source induction, data hidden behindservice interface, binding constraints, data extremely largeeven (in case sources providing mathematical functions) infinite. Thus makingproblem considerably difficult.schema integration system CLIO (Yan, Miller, Haas, & Fagin, 2001) helps usersbuild SQL queries map data source target schema. CLIO, foreign keysinstance data used generate integration rules semi-automatically. Since CLIOrelies heavily user involvement, make sense compare directlyautomated system developed paper.43fiCarman & KnoblockAnother closely related problem complex schema matching, goaldiscover complex (many-to-one) mappings two relational tables XML schemas.problem far complicated basic (one-to-one) schema matching because:space possible correspondences relations longer Cartesianproduct source target relations, powerset source relation timestarget relation.Many-to-one mappings require mapping function, simple like concatenate(x,y,z), arbitrarily complex formula z = x2 + y.iMAP system (Dhamanka et al., 2004) tries learn many-to-one mappings concepts set source relations target relation. uses set specialpurpose searchers learn different types mappings (such mathematical expressions,unit conversions time/date manipulations). uses meta-heuristic controlsearch performed different special purpose searchers. one viewssource schema functions available use mappings (such concatenate(x,y,z), add(x,y,z), etc.) set known sources source definition inductionproblem, complex schema matching source induction problems somewhatsimilar. main differences problems are:data associated source schema explicit (and static) complex schemamatching, hidden (and dynamic) source induction.general, set known sources source induction problem much larger(and data provide may less consistent), set mapping functionssource relations complex schema matching problem.paper develop general framework handling source induction problem.Since iMAP provides functionality similar system, performsimple empirical comparison section 7.4.8.5 Semantic Web Approachstated goal Semantic Web (Berners-Lee, Hendler, & Lassila, 2001) enablemachine understanding Web resources. done annotating resourcessemantically meaningful metadata. Thus work described paper muchline Semantic Web, far attempting discover semanticallymeaningful definitions online information sources. De facto standards annotatingservices semantic markup around number years. standardsprovide service owners metadata language adding declarative statements serviceinterface descriptions attempt describe semantics service termsfunctionality (e.g. book purchase operation) data (e.g. weather forecast)provides. Work languages related article two perspectives:viewed alternative approach gaining knowledge semanticsnewly discovered source (providing semantic metadata associated it).Semantic Web Service annotation languages seen target languagesemantic descriptions learnt paper.44fiLearning Semantic Definitions Information Sources InternetWeb Service already semantically annotated, heterogeneity may still existontology used service provider used consumer, caselearning capabilities described paper may required reconcile differences.importantly, interested vast number sources semanticmarkup currently unavailable. work article complements SemanticWeb community providing way automatically annotating sources semanticinformation; thereby relieving service providers burden manually annotatingservices. learnt, Datalog source definitions converted Description Logicbased representations used OWL-S (Martin, Paolucci, McIlraith, Burstein,McDermott, McGuinness, Parsia, Payne, Sabou, Solanki, Srinivasan, & Sycara, 2004)WSMO (Roman, Keller, Lausen, de Bruijn, Lara, Stollberg, Polleres, Feier, Bussler, &Fensel, 2005). reason use Datalog paper (rather Description Logics)mediator-based integration systems rely representation language.9. Discussionpaper presented completely automatic approach learning definitionsonline services. approach exploits definition sources either givensystem learned previously. resulting framework significant advanceprior approaches focused learning inputs outputs classservice. demonstrated empirically viability approach.key contribution article procedure learning semantic definitionsonline information services is:Fully automated : Definitions learnt completely automated manner withoutneed user intervention.expressive: query language defining sources conjunctivequeries, far expressive previous attribute-value approaches.Sufficiently robust: procedure able learn definitions presence noisyincomplete data, thus sufficiently robust handle real data sources.Data-access efficient: procedure samples data live sources, invokingsparingly required, making highly efficient terms source accesses.Evolving: procedures ability learn definitions improves time newdefinition learnt added set known sources.9.1 Application Scenariosnumber different application scenarios system capable learningdefinitions online sources. generally involve providing semantic definitions dataintegration systems, exploit integrate available sources.obvious application work would system (depicted left sideFigure 1) crawls Web, searching information sources. Upon finding source,system would use classifier assign semantic types it, followed inductivelearner generate definition it. definition could used annotatesource Semantic Web, mediator answering queries. Importantly,entire process could run minimal user involvement.45fiCarman & KnoblockFigure 1: Architecture diagrams three different application scenarios.challenging application scenario (shown center Figure 1) would involvereal-time service discovery. Consider case mediator unable answerparticular query desired information lies scope sources available.search performed based missing conjuncts (relation names constants)query using specialised Web Service search engine, Woogle (Dong et al.,2004). services returned would annotated semantic types and, possible,semantic definitions. definitions provided mediator, would completequery processing return answer user. scenario may seem little farfetched one considers specific example: imagine user interacting geospatialbrowser (an online atlas). user turns particular information layer, skiresorts, source available current field view (of, instance, Italy),results would displayed. background search could performed newsource discovered, provides ski resorts Europe. relevant data coulddisplayed, user unaware search performed.Perhaps likely application scenario (to right Figure 1) sourceinduction system would mixed initiative one. case human would annotatedifferent operations service interface semantic definitions. time,system would attempt induce definitions remaining operations, promptuser suggestions them. scenario classifier may needed,since attributes name different operations would likelysemantic type. Moreover, since definitions learnt system may casescontain erroneous superfluous predicates, user could also involved processchecking improving definitions discovered.46fiLearning Semantic Definitions Information Sources Internet9.2 Opportunities Researchnumber future directions work allow techniques appliedbroadly. discuss two directions, improving search algorithm extendingquery language.number known sources grows, search space, necessary develop additional heuristics better direct search toward best definition.Many heuristic techniques developed ILP community mayapplicable source induction problem. pressing perhaps need developrobust termination condition halting search sufficiently good definitiondiscovered. number available sources increases, simple timeout usedexperiments ineffective certain (more complicated) definitions necessarilytake longer learn others.Another way increase applicability work extend query languagebetter describes sources available. Often online sources return completeset results rather cut list maximum cardinality. exampleYahooHotel source described section 7.3.4 returns maximum 20 hotels near givenlocation, orders according distance. case, recognising specificordering tuples produced would useful mediator. second usefulextension query language would ability describe sources using proceduralconstruct if-then-else. construct needed describe behaviour sourcescertain inputs. example, consider YahooGeocoder section 7.3.1, takesinput tuple containing street name, number, zipcode. geocoder unablelocate corresponding address database (because doesnt exist), insteadreturning tuples, returns centroid zipcode. Describing behaviorpossible using procedural constructs.Acknowledgmentsresearch based upon work supported part Defense Advanced ResearchProjects Agency (DARPA), Department Interior, NBC, Acquisition Services Division, Contract No. NBCHD030010. U.S. Government authorizedreproduce distribute reports Governmental purposes notwithstanding copyright annotation thereon. views conclusions contained hereinauthors interpreted necessarily representing official policiesendorsements, either expressed implied, organizations personconnected them.ReferencesAfrati, F. N., Li, C., & Mitra, P. (2004). containment conjunctive queries using arithmetic comparisions. 9th International Conference Extending Database Technology (EDBT 2004) Heraklion-Crete, Greece.47fiCarman & KnoblockArens, Y., Knoblock, C. A., & Shen, W.-M. (1996). Query reformulation dynamicinformation integration. Journal Intelligent Information Systems - Special IssueIntelligent Information Integration, 6 (2/3), 99130.Berners-Lee, T., Hendler, J., & Lassila, O. (2001). semantic web. Scientific American,284 (5), 3443.Bilenko, M., Mooney, R. J., Cohen, W. W., Ravikumar, P., & Fienberg, S. E. (2003).Adaptive name matching information integration.. IEEE Intelligent Systems, 18 (5),1623.Cameron-Jones, R. M., & Quinlan, J. R. (1994). Efficient top-down induction logicprograms. SIGART Bulletin, 5 (1), 3342.Carman, M. J., & Knoblock, C. A. (2007). Learning semantic descriptions web information sources. Proceedings Twentieth International Joint ConferenceArtificial Intelligence (IJCAI-07) Hyderabad, India.Chandra, A. K., & Merlin, P. M. (1977). Optimal implementation conjunctive queriesrelational data bases. Proceedings 9th ACM Symposium TheoryComputing (STOC), pp. 7790 Boulder, Colorado.Dhamanka, R., Lee, Y., Doan, A., Halevy, A., & Domingos, P. (2004). imap: Discoveringcomplex semantic matches database schemas. SIGMOD 04: Proceedings2004 ACM SIGMOD International Conference Management Data.Dong, X., Halevy, A. Y., Madhavan, J., Nemes, E., & Zhang, J. (2004). Simlarity searchweb services. Proceedings VLDB.Duschka, O. M. (1997). Query Planning Optimization Information Integration. Ph.D.thesis, Department Computer Science, Stanford University.Garcia-Molina, H., Hammer, J., Ireland, K., Papakonstantinou, Y., Ullman, J., & Widom,J. (1995). Integrating accessing heterogeneous information sources tsimmis.Proceedings AAAI Symposium Information Gathering, pp. 61-64.He, A., & Kushmerick, N. (2003). Learning attach semantic metadata web services.2nd International Semantic Web Conference (ISWC).He, A., & Kushmerick, N. (2004). Iterative ensemble classification relational data:case study semantic web services. 15th European Conference MachineLearning (ECML2004) Pisa, Italy. Springer.Knoblock, C. A., Minton, S., Ambite, J. L., Ashish, N., Muslea, I., Philpot, A., & Tejada,S. (2001). ariadne approach web-based information integration. InternationalJournal Cooperative Information Systems, 10 (1-2), 145169.Lerman, K., Plangprasopchok, A., & Knoblock, C. A. (2006). Automatically labeling dataused web services. Proceedings 21st National Conference ArtificialIntelligence (AAAI).48fiLearning Semantic Definitions Information Sources InternetLevy, A. Y. (2000). Logic-based techniques data integration. Minker, J. (Ed.), LogicBased Artificial Intelligence. Kluwer Publishers.Levy, A. Y., Mendelzon, A. O., Sagiv, Y., & Srivastava, D. (1995). Answering queries usingviews. Proceedings 14th ACM SIGACT-SIGMOD-SIGART SymposiumPrinciples Database Systems, pp. 95104 San Jose, Calif.Markov, Z., & Marinchev, I. (2000). Metric-based inductive learning using semantic heightfunctions. Proceedings 11th European Conference Machine Learning(ECML 2000). Springer.Martin, D., Paolucci, M., McIlraith, S., Burstein, M., McDermott, D., McGuinness, D.,Parsia, B., Payne, T., Sabou, M., Solanki, M., Srinivasan, N., & Sycara, K. (2004).Bringing semantics web services: owl-s approach. Proceedings FirstInternational Workshop Semantic Web Services Web Process Composition(SWSWPC 2004).Muggleton, S., & Feng, C. (1990). Efficient induction logic programs. Proceedings1st Conference Algorithmic Learning Theory.Muggleton, S. (1995). Inverse entailment Progol. New Generation Computing, Specialissue Inductive Logic Programming, 13 (3-4), 245286.Nedellec, C., Rouveirol, C., Ade, H., Bergadano, F., & Tausend, B. (1996). Declarativebias ILP. De Raedt, L. (Ed.), Advances Inductive Logic Programming, pp.82103. IOS Press.Pazzani, M. J., & Kibler, D. F. (1992). utility knowledge inductive learning.Machine Learning, 9, 5794.Perkowitz, M., & Etzioni, O. (1995). Category translation: Learning understand information internet. Proceedings Fourteenth International Joint ConferenceArtificial Intelligence (IJCAI-95).Perkowitz, M., Doorenbos, R. B., Etzioni, O., & Weld, D. S. (1997). Learning understand information internet: example-based approach. Journal IntelligentInformation Systems, 8 (2), 133153.Pottinger, R., & Halevy, A. Y. (2001). Minicon: scalable algorithm answering queriesusing views. VLDB Journal, 10 (2-3).Quinlan, J. R., & Cameron-Jones, R. M. (1993). FOIL: midterm report. MachineLearning: ECML-93, European Conference Machine Learning, Proceedings, Vol.667, pp. 320. Springer-Verlag.Rahm, E., & Bernstein, P. (2001). survey approaches automatic schema matching.VLDB Journal, 10 (4).Richards, B. L., & Mooney, R. J. (1992). Learning relations pathfinding. NationalConference Artificial Intelligence, pp. 5055.49fiCarman & KnoblockRoman, D., Keller, U., Lausen, H., de Bruijn, J., Lara, R., Stollberg, M., Polleres, A.,Feier, C., Bussler, C., & Fensel, D. (2005). Web service modeling ontology. AppliedOntology, 1 (1), 77106.Ullman, J. D. (1989). Principles Database Knowledge-Base Systems, Vol. 2. Computer Science Press, Rockville, Maryland.Weber, I., Tausend, B., & Stahl, I. (1995). Language series revisited: complexityhypothesis spaces ILP. Proceedings 8th European Conference MachineLearning, Vol. 912, pp. 360363. Springer-Verlag.Widom, J. (1995). Research problems data warehousing. CIKM 95: Proceedingsfourth International Conference Information Knowledge Management, pp.2530. ACM Press.Wiederhold, G. (1992). Mediators architecture future information systems. Computer, 25 (3), 3849.Wiederhold, G. (Ed.). (1996). Intelligent Integration Information. Kluwer AcademicPublishers, Boston MA.Winkler, W. (1999). state record linkage current research problems. Tech. rep.,Statistical Research Division, U.S. Bureau Census, Washington, DC.Yan, L. L., Miller, R. J., Haas, L. M., & Fagin, R. (2001). Data-driven understandingrefinement schema mappings. SIGMOD 01: Proceedings 2001 ACMSIGMOD International Conference Management data.Zelle, J. M., Thompson, C. A., Califf, M. E., & Mooney, R. J. (1995). Inducing logicprograms without explicit negative examples. Proceedings Fifth InternationalWorkshop Inductive Logic Programming.50fiJournal Artificial Intelligence Research 30 (2007) 621-657Submitted 03/07; published 12/07Query-time Entity ResolutionIndrajit Bhattacharyaindrajbh@in.ibm.comIBM India Research LaboratoryVasant Kunj, New Delhi 110 070, IndiaLise Getoorgetoor@cs.umd.eduDepartment Computer ScienceUniversity Maryland, College Park, MD 20742 USAAbstractEntity resolution problem reconciling database references correspondingreal-world entities. Given abundance publicly available databasesunresolved entities, motivate problem query-time entity resolution: quickaccurate resolution answering queries unclean databases query-time.Since collective entity resolution approaches related references resolved jointlyshown accurate independent attribute-based resolutionoff-line entity resolution, focus developing new algorithms collective resolutionanswering entity resolution queries query-time. purpose, first formallyshow that, collective resolution, precision recall individual entities followgeometric progression neighbors increasing distances considered. Unfoldingprogression leads naturally two stage expand resolve query processing strategy.strategy, first extract related records query using two novel expansionoperators, resolve extracted records collectively. showstrategy adapted query-time entity resolution identifying resolvingdatabase references helpful processing query.validate approach two large real-world publication databases showusefulness collective resolution time demonstrate need adaptivestrategies query processing. show queries answeredreal-time using adaptive approach preserving gains collective resolution.addition experiments real datasets, use synthetically generated data empiricallydemonstrate validity performance trends predicted analysis collectiveentity resolution wide range structural characteristics data.1. Introductiongrowing abundance publicly available data digital form, intense research data integration. critical component data integration processentity resolution problem, uncertain references data real-world entitiespeople, places, organizations, events, etc., need resolved accordingunderlying real-world entities. Entity resolution needed order solve deduplication problem, goal identify consolidate pairs records referenceswithin relational table duplicates other. also comesfuzzy match problem, tuples two heterogeneous databases different keys,possibly different schemas, need matched consolidated. goes differentc2007AI Access Foundation. rights reserved.fiBhattacharya & Getoornames even within data mining database communities, including record linkage,object consolidation, reference reconciliation.problem long history, recent years seen significant fruitfulresearch problem. However, spite widespread research interestpractical nature problem, many publicly accessible databases remain unresolved,partially resolved, best. popular publication databases, CiteSeer PubMed,representative examples. CiteSeer contains several records paper author,author names PubMed resolved all. due variety reasons,ranging rapid often uncontrolled growth databases computationalexpenses involved maintaining resolved entities.Yet, millions users access query databases everyday, mostly seeking information that, implicitly explicitly, requires knowledge resolved entities. example,may query CiteSeer database computer science publications looking booksRussell (Pasula, Marthi, Milch, Russell, & Shpitser, 2003). query would easyanswer author names CiteSeer correctly mapped entities. But,unfortunately, case. According CiteSeer records, Stuart Russell PeterNorvig written 100 different books together. One main reasons behind databases containing unresolved entities entity resolution generally perceivedexpensive process large databases. Also, maintaining clean database requiressignificant effort keep pace incoming records. Alternatively, may searchingdifferent online social network communities person named Jon Doe. case,online community may individually records clean. Even then, queryresults return records sources aggregated together may multiplerepresentations Jon Doe entity. Additionally, cases, sufficientsimply return records match query name, S. Russell Jon Doe exactly.order retrieve references correctly, may need retrieve records similarnames well, Stuart Russel John Doe. And, importantly, resultsuseful, need partition records returned according real-worldentities correspond. on-the-fly partitioning returned results alsonecessary accessing third-party external databases provide full accesspossibly due privacy concerns, accessed via specific queryinterfaces.paper, propose alternative solution answering entity resolution queries,obviate need maintaining resolved entities database. Instead,investigate entity resolution query-time, goal enable users queryunresolved partially resolved database resolve relevant entities fly. usermay access several databases everyday want resolve entities everydatabase queries. needs resolve entities relevantparticular query. instance, looking books Stuart Russell CiteSeer,useful resolve authors CiteSeer. Since resolution needsperformed query-time, requirement resolution process needs quick,even entirely accurate.Though entity resolution queries addressed literature,significant progress general entity resolution problem. Recent research focused use additional relational information database references improve622fiQuery-time Entity Resolutionresolution accuracy (Bhattacharya & Getoor, 2004; Singla & Domingos, 2004; Dong, Halevy,& Madhavan, 2005; Ananthakrishna, Chaudhuri, & Ganti, 2002; Kalashnikov, Mehrotra, &Chen, 2005). improvement made possible resolving related references recordsjointly, rather independently. Intuitively, corresponds notion figuringtwo records refer underlying entity may turn give us useful information resolving record pairs related. Imagine trying decidetwo authors Stuart Russell Russell person. confidentdecision already decided co-authors Peter Norvig P.Norvig person.others done, earlier work (Bhattacharya & Getoor, 2004, 2007),demonstrated using extensive experiments multiple real synthetic datasetscollective resolution significantly improves entity resolution accuracy attribute-basednaive relational baselines. However, application query-time entity resolutionstraight-forward, precisely problem focus paper.first difficulty collective resolution works database wholespecific query. Secondly, accuracy improvement comes considerable computationcost arising dependencies related resolutions. added computationalexpense makes application query-time resolution challenging.paper, builds significantly extends work presented Bhattacharya, Licamele, Getoor (2006), investigate application collective resolution queries. First, formally analyze accuracies different decisions collectiveresolution depend structural characteristics data. recursive nature dependency leads naturally recursive expand resolve strategyprocessing queries. relevant records necessary answering query extractedrecursive expansion process collective resolution performed extracted records. Using analysis, show recursive expansion processterminated reasonably small depths accurately answering query; returns fallexponentially neighbors away considered.However, problem unconstrained expansion process return manyrecords even small depths; thus query may still impossible resolvereal-time. address issue using adaptive strategy considersinformative related records answering query. significantly reducesnumber records need investigated query time, but, importantly,compromise resolution accuracy query.specific contributions paper follows:1. First, motivate formulate problem query-time entity resolution.entity resolution approach based relational clustering algorithm. bestknowledge, clustering based queries presence relations receivedlittle attention literature.2. collective resolution using relational clustering, present analysisaccuracy different resolution decisions depends structuralcharacteristics data. introduce notion precision recall individual entities, show follow geometric progression neighborsincreasing distances considered resolved. analysis shows collective623fiBhattacharya & Getooruse relationships sometimes hurt entity resolution accuracy.previously reported literature. analysis additionally demonstrates convergent nature resolution performance recursive query-resolution strategypropose.3. resolving queries collectively, propose two-phase expand resolve algorithm. first extracts related records query using two novel expansionoperators, resolves query considering extracted records.improve algorithm using adaptive approach selectively considersinformative ones among related records query. enablescollective resolution query-time without compromising resolution accuracyquery.4. present experimental results two large real-world datasets strategyenables collective resolution seconds. compare multiple baselinesshow accuracy achieved using collective query resolution significantly higherachieved using traditional approaches.5. also use synthetically generated data demonstrate gains collective queryresolution wide range attribute relational characteristics. additionally show empirical results agreement trends predictedanalysis collective resolution.rest paper organized follows. Section 2, formalize relationalentity resolution problem entity resolution queries, also illustrateexample. Section 3, briefly review relational clustering algorithm employcollective entity resolution then, Section 4, investigate resolution accuracyrelated entities depend collective resolution using algorithm.Section 5, extend collective resolution queries, describe analyze unconstrained recursive strategy collectively resolving query. modify approachSection 6 present adaptive algorithm extracts informativereferences resolving query. present experimental results real synthetic dataSection 7, review related work Section 8 finally conclude Section 9.2. Entity Resolution Queries: Formulationsection, formally introduce entity resolution problem also entity resolutionqueries, illustrate using realistic example resolving authorscitation database CiteSeer PubMed.simplest formulation entity resolution problem, collectionreferences, R = {ri }, attributes {R.A1 , . . . , R.Ak }. Let E = {ej } unobserveddomain entities. particular reference ri , denote entity mapsE(ri ). say two references ri rj co-referent correspondentity, E(ri ) = E(rj ). Note case unresolved database,mapping E(R) provided. Further, domain entities E even numberentities known. However, many domains, may additional informationrelationships references. model relationships generic way, use624fiQuery-time Entity Resolutionh1h2Mouse Immunity Modelr1W Wangr2C Chenr3r4r5AnsariW WangAnsarih 3 Measuring Protienbound Fluxetiner6r7r8L LiC ChenBetter Mouse Immunity Modelh 4 Autoimmunity Biliary Cirrhosisr9r 10W W WangW WangAnsariFigure 1: example set papers represented references connected hyper-edges.References represented ovals shaded according entities. paperrepresented hyper-edge (shown rectangle) spanning multiple references.set hyper-edges H = {hi }. hyper-edge connects multiple references. capturethis, associate set references hi .R hyper-edge hi . Note referencemay associated zero hyper-edges.Let us look sample domain see represented framework.Consider database academic publications similar DBLP, CiteSeer PubMed.publication database set author names. every author name,reference ri R. reference ri , ri .N ame records observed name authorpublication. addition, attributes R.Email recordinformation author reference may available paper. comerelationships domain. author references publication connectedco-author relationship. represented using hyper-edge hi Hpublication rj hi .R reference rj publication.publications additional information title, keywords, etc, representedattributes H.illustrate, consider following four papers, use running example:1. W. Wang, C. Chen, A. Ansari, mouse immunity model2. W. Wang, A. Ansari, better mouse immunity model3. L. Li, C. Chen, W. Wang,Measuring protein-bound fluxetine4. W. W. Wang, A. Ansari, Autoimmunity biliary cirrhosisrepresent notation, 10 references {r1 , . . . , r10 } R, oneauthor name, r1 .N ame = W Wang, etc. also 4 hyper-edges {h1 , . . . , h4 }H, one paper. first hyper-edge h1 connects three references r1 , r2r3 corresponding names W. Wang , C. Chen A. Ansari. representedpictorially Figure 1.Given representation, entity resolution task defined partitioningclustering references according underlying entity-reference mapping E(R).Two references ri rj assigned cluster625fiBhattacharya & Getoorcoreferent, i.e., E(ri ) = E(rj ). illustrate, assume six underlying entitiesexample. illustrated Figure 1 using different shading entity.example, Wangs papers 1, 2 4 names individual Wangpaper 3 reference different person. Also, Chens papers 1 3different individuals. Then, correct entity resolution example database 10references returns 6 entity clusters: {{r1 , r4 , r9 }, {r8 }, {r2 }, {r7 }, {r3 , r5 , r10 }, {r6 }}.first two clusters correspond two different people named Wang, next two twodifferent people named Chen, fifth Ansari last Li.query database references called entity resolution query answeringrequires knowledge underlying entity mapping E(R). consider two differenttypes entity resolution queries. commonly, queries specified using particularvalue attribute R.A references serves quasi-identifierunderlying entities. answer query Q(R.A = a) partition groupreferences r.A = according underlying entities. referencespeople, name often serves weak noisy identifier. example bibliographicdomain, consider queries specified using R.N ame. retrieve papers writtenperson named W. Wang, issue query using R.N ame W. Wang. Sincenames ambiguous, treating identifiers leads undesirable results. case,would incorrect return set {r1 , r4 , r8 } references name W Wanganswer query. answer indicate r8 persontwo. Additionally, answer include reference r9 W W Wang,maps entity author first paper. Therefore, correct answerentity resolution query W Wang partition {{r1 , r4 , r9 }, {r8 }}.Entity resolution queries may alternatively specified using specific reference. Imagine CiteSeer user looking paper contains author name. user mayinterested looking papers written author, even though mayknow author precisely. correct answer query referencer group references coreferent r, or, words, correspondunderlying entity. example, consider query specified using reference r1corresponding name W. Wang first paper. correct answerquery set references {r1 , r4 , r9 }. distinguish first type entityresolution query, note include cluster {r8 } correspondingentity also name W. Wang. second query type may answered firstreducing instance first type Q(R.A = r1 .A), selecting entitycorresponding reference r1 . denote E(R)=E(r1 ) (Q(R.A = r1 .A)). restpaper, focus queries first type.3. Collective Entity Resolution Relational ClusteringAlthough entity resolution queries studied literature, generalentity resolution problem received lot attention. review related work detailSection 8. section, briefly review different categories proposed approachesdiscussing may adapted query-time entity resolution.entity resolution applications, data labeled underlying entities hardacquire. focus unsupervised approaches resolving entities. Traditionally,626fiQuery-time Entity Resolutionattributes individual references, names, affiliation, etc., person references,used comparing references. similarity measure generally employed attributes,pairs references attribute similarity certain thresholdconsidered co-referent. attribute-based entity resolution approach (A)often runs problems. example, hard infer attributesreferences r1 r8 co-referent although name, r1 r9co-referent although names different.relations references available, may also taken accountcomputing similarities naive relational entity resolution approach (NR)(Ananthakrishna et al., 2002; Bhattacharya & Getoor, 2007). computing similaritiestwo references, approach additionally considers attributes relatedreferences comparing attributes related references. example,approach returns higher similarity r1 (W. Wang) r9 (W. W. Wang)attribute-based approach, since co-authors r3 r10 similar (identical, case) names. Although approach improve performance cases,always work. instance, two W. Wang references r1 r8co-referent, though co-authors identical names C. Chen.Instead considering attribute similarities related references, collectiveentity resolution approach (Pasula et al., 2003; Bhattacharya & Getoor, 2004; Singla& Domingos, 2004; McCallum & Wellner, 2004; Li, Morie, & Roth, 2005; Dong et al.,2005; Kalashnikov et al., 2005) takes account resolution decisions them.previous example, correct evidence use pair references r1 r8co-author references map entity, although similar names.Therefore, order resolve W. Wang references collective resolution approach,necessary resolve C. Chen references well, instead considering similarityattributes. collective entity resolution approach recently shownimprove entity resolution accuracy previous approaches computationallychallenging. references cannot resolved independently. Instead, resolutiondecision affected resolutions hyper-edges.earlier work (Bhattacharya & Getoor, 2004, 2006, 2007), developed relationalclustering algorithm (RC-ER) collective entity resolution using relationships. goalapproach cluster references according entities taking relationshipsaccount. associate cluster label r.C reference denote currentcluster membership. Starting initial set clusters C = {ci } references,algorithm iteratively merges pair clusters similar. capturecollective nature cluster assignment, similarity measure pairs clustersconsiders cluster labels related references. similarity two clusters cicj defined linear combination attribute similarity simA relationalsimilarity simR :sim(ci , cj ) = (1 ) simA (ci , cj ) + simR (ci , cj )(1)(0 1) combination weight. interesting aspect collectiveapproach dynamic nature relational similarity. similarity tworeferences depends current cluster labels related references, thereforechanges related references change clusters. example, similarity two627fiBhattacharya & Getoorclusters containing references W. Wang W. W. Wang increases co-authorreferences named A. Ansari assigned cluster. briefly reviewtwo components similarity measure defined.Attribute Similarity: reference attribute, use similarity measurereturns value 0 1 two attribute values indicating degree similaritythem. Several sophisticated similarity measures developed names,popular TF-IDF schemes may used textual attributes keywords.measure works best attribute may chosen. Finally, weighted linearcombination similarities different attributes yields combined attributesimilarity two reference clusters.Relational Similarity: Relational similarity two clusters considers similarity cluster neighborhoods. neighborhood cluster definedhyper-edges associated references cluster. Recall reference rassociated one hyper-edges H. Therefore, hyper-edge set c.Hcluster c references definedc.H =[{h | h H r h.R}(2)rRr.C=cset defines hyper-edges connect cluster c clusters,ones relational similarity needs consider. illustrate, referencesrunning example correctly clustered Figure 1(b), hyper-edge setlarger Wang cluster {h1 , h2 , h4 }, hyper-edges associatedreferences r1 , r4 r9 cluster.Given hyper-edge set cluster c, neighborhood N br(c) cluster cset clusters labels references spanned hyper-edges:N br(c) =[{cj | cj = r.C}(3)hc.H,rhexample Wang cluster, neighborhood consists Ansari cluster oneChen clusters, connected edge-set. Then, relational similaritymeasure two clusters, considers similarity cluster neighborhoods.neighborhoods essentially sets (or multi-sets) cluster labels many possible ways define similarity two neighborhoods (Bhattacharya & Getoor, 2007).specific similarity measure use experiments paper Jaccardsimilarity1 :simR (ci , cj ) = Jaccard(N br(ci ), N br(cj ))(4)Clustering Algorithm: Given similarity measure pair clusters, greedyrelational clustering algorithm used collective entity resolution. Figure 2 showshigh-level pseudo-code complete algorithm. algorithm first identifies candidate set potential duplicates using blocking approach (Hernandez & Stolfo, 1995;Monge & Elkan, 1997; McCallum, Nigam, & Ungar, 2000). Next, initializes clusters1. Jaccard similarity two sets B defined Jaccard(A, B) =628|AB||AB|fiQuery-time Entity Resolution1.2.Algorithm RC-ER (Reference set R)Find similar references R using blockingInitialize clusters using bootstrapping3.4.clusters ci , cj similar(ci , cj )Insert hsim(ci , cj ), cj , cj priority queue5.6.7.8.9.10.11.12.13.14.priority queue emptyExtract hsim(ci , cj ), ci , cj queuesim(ci , cj ) less threshold, stopMerge ci cj new cluster cijRemove entries ci cj queuecluster ck similar(cij , ck )Insert hsim(cij , ck ), cij , ck queuecluster cn neighbor cijck similar(ck , cn )Update sim(ck , cn ) queueFigure 2: High-level description relational clustering algorithmreferences, identifies similar clusters potential merge-candidatescluster, inserts merge-candidates priority queue iteratesfollowing steps. step, identifies current closest pair clusters candidate set merges create new cluster. identifies new candidate pairsupdates similarity measures related cluster pairs. key stepevidence flows one resolution decision related ones distinguishes relational clustering traditional clustering approaches. algorithm terminatessimilarity closest pair falls threshold list potential candidates exhausted. algorithm efficiently implemented run O(nk log n) timen references block similar names connected k blockshyper-edges.3.1 Issues Collective Resolution Queriesprevious work, (and others) shown collective resolution using relationshipsimproves entity resolution accuracy significantly offline cleaning databases. So, naturally, would like use approach query-time entity resolution well.However, attribute-based naive relational approaches discussed earlierapplied query-time straight-forward fashion, case collectiveresolution. Two issues come using collective resolution queries. First,set references influence resolution decisions query need identified.answering resolution query S. Russell using attribute-based approach,sufficient consider papers S. Russell (or, similar names) author name.collective resolution, contrast, co-authors author names, P.629fiBhattacharya & GetoorNorvig Peter Norvig, also need clustered according entities.turn requires clustering co-authors on. first task analyzedependencies collective resolution identify references databaserelevant answering query. enough. set references influencingquery may extremely large, query still needs answered quickly even thoughanswer may completely accurate. second issue performing resolutiontask query-time. two problems address next sections.4. Analysis Collective Resolution using Relational Clusteringcollective entity resolution, seen resolution performance querybecomes dependent resolution accuracy related entities. analyzereferences influence entity resolution query extent, needanalyze nature dependence collective resolution general. section,identify structural properties data affect collective entity resolutionformally model interdependent nature resolution performance. analysisalso helps us understand collective resolution using relational clustering helps,and, equally importantly, adverse effect compared traditionalattribute-based resolution.goal entity resolution algorithm partition set R = {ri } referencesset clusters C = {ci } according underlying entities E = {ei }. accuracy resolution depends closely separation references clusterscorresponds underlying entities. consider two different measures performance.first measure recall entity. entity ei , recall counts many pairsreferences corresponding ei correctly assigned computed cluster.second measure precision computed cluster. cluster ci , precision countsmany pairs references assigned ci truly correspond underlying entity.(Alternatively, imprecision measures many pairs references assigned clustercorrespond entity.) next two subsections, analyzetwo performance metrics influenced, first, attribute values references,then, observed relationships them.4.1 Influence AttributesFirst, consider entity resolution algorithm follows traditional attribute-based approach analysis performance. algorithm considers attributesindividual references. uses similarity measure defined domain attributes,considers pair-wise attribute similarity references resolving them. Let usdefine two references -similar attribute-similarity least . Then, givenresolution threshold , attribute-based approach assigns pair referencescluster -similar. illustrate using example, usingsimilarity measure defined names appropriately determined similarity threshold, attribute-based approach would assign three W. Wang references (r1 , r4 , r8 )one cluster c1 W. W. Wang reference (r9 ) different cluster c2 . resolutionWang references perfect terms precision recall, since references r1 , r4r9 map one entity e1 r8 maps second entity e2 . Cluster c1 precision less630fiQuery-time Entity Resolution1, since incorrectly includes references two different entities, recall less1 entity e1 , since references dispersed two different clusters.order analyze performance attribute-based resolution approach givenarbitrary dataset, characterize dataset terms attribute valuesreferences. Intuitively, attribute-based approach works well referencescorresponding entity similar terms attributes,references corresponding different entities not. capture formally, definetwo probabilities measure attribute-similarity references mapentity, attribute-similarity map different entities:attribute identification probability aI (e, ): probability pair references chosen randomly corresponding entity e -similarother.attribute ambiguity probability aA (e1 , e2 , ): probability pair references chosen randomly one corresponds entity e1 entitye2 -similar other.illustrate using four Wang references, r1 , r4 r9 correspondentity e1 r8 corresponds different entity e2 . Also, assume similaritymeasure names appropriate threshold , references r1 , r4 r8 -similarother. Then, 3 pairs references corresponding entity e1 , one (r1r4 ) -similar, attribute identification probability aI (e1 , ) entity e1 0.33.hand, three pairs references one maps e1e2 , two (r1 r8 , r4 r8 ) -similar. means attribute ambiguityprobability aA (e1 , e2 , ) e1 e2 0.66.seen example, performance attribute-based clustering algorithm represented terms two probabilities. specifiedthreshold , pairs references entity correctly recalled ones-similar, exactly aI (e, ) captures. Therefore, recall domainentity e R(e, ) = aI (e, ). hand, consider cluster assignmentreferences correspond two entities e1 e2 . pairs incorrectly clusteredtogether correspond two different entities, yet -similar.aA (e1 , e2 , ) captures. Therefore imprecision cluster assignment referencepairs corresponding entities e1 e2 I(e1 , e2 , ) = aA (e1 , e2 , ). Alternatively,precision given P (e1 , e2 , ) 1 I(e1 , e2 , ) = 1 aA (e1 , e2 , ).4.2 Influence RelationshipsNow, consider collective entity resolution approach additionally makes userelationships, analyze impact entity resolution accuracy. Recallset H = {hj } observed co-occurrence relationships references. cooccurrences references useful entity resolution result strongties relations underlying entities. Specifically, assume referencesentity ei co-occur frequently references small set entities {e1i , . . . , eki },call entity neighbors, denoted N (ei ), entity ei .631fiBhattacharya & GetoorW.W. WangW. Wangh4A. AnsariA. AnsariW. WangW. Wangh1h1h3C. ChenC. ChenFigure 3: Illustration (a) identifying relation (b) ambiguous relation runningexample. Dashed lines represent co-occurrence relations.Assuming neighborhood relationship among underlying entities allows usanalyze performance relational clustering approach. reference pairs-similar terms attributes, attribute evidence enough resolution.now, unlike attribute-based clustering, pair references -similar termsattributes, < , considered candidates clustered together.actually get assigned cluster. reference pairs ringuncertainty , relationships play role determining similarenough, consequently, clustered together. Specifically, references rirj co-occur hyper-edge h references ri rj co-occur hyper-edgeh , relational similarity pair (ri , ri ) (rj , rj ) belongcluster. general, multiple relationships may needed tipping balance,simplicity, assume single pair related references sufficient.words, ri ri get assigned cluster rj rj cluster.analyze impact approach entity resolution performance.Without loss generality, assume (rj , rj ) pair get clustered together firstrelational clustering algorithm. results pair (ri , ri ) also getting clusteredlater iteration considering relational evidence. see accurate,consider two situations, attribute evidence. first shown Figure 3(a),pairs truly correspond entity. collective resolution decisioncorrect say hyper-edges h h identifying relationships entity.Formally,IRel(h, h , e) ri , rj h.R, ri , rj h .R,E(ri ) = E(ri ) = e, E(rj ) = E(rj )(5)hand, may different scenario, pairs references correspond two different entities. second scenario depicted Figure 3(b).first decision resolve (rj , rj ) co-referent incorrect, relational evidence obtainedhyper-edges h h consequently leads incorrect resolution (ri , ri ).situation, collective resolution hurts accuracy, say h h form ambiguousrelationships pairs entities, whose references may incorrectly clusteredresult relationships. Formally,IAmb(h, h , e, e ) ri , rj h.R, ri , rj h .R,632fiQuery-time Entity ResolutionE(ri ) = e, E(ri ) = e , e 6= e ,E(rj ) 6= E(rj )(6)general, reference ri co-occurrence relation h includesone reference. may think multiple co-occurrence pairs involving ri .Cluster labels references pairs influence resolution decisions ri .resolving ri another reference ri participates co-occurrence relation h ,fraction common cluster labels h h determines whether riri clustered together. assigned cluster, h h labeledidentifying ambiguous relationships based whether ri ri actually co-referentnot.Formally, define:identifying relationship probability rI (e, ): probability randomly chosen pair -similar references corresponding entity e identifying relationshipsh h entity.ambiguous relationship probability rA (e1 , e2 , ): probability pair-similar references, chosen randomly one corresponds entity e1entity e2 , ambiguous relationships h h pairentities.illustrate probabilities using example, two Wang entities, e1references r1 , r4 r9 , e2 reference r8 . Assume attributethreshold six pairs considered potential matches. three pairsreferences corresponding e1 , identifying relationships Ansarientity. So, rI (e1 , ) = 1. measure relational ambiguity two Wangentities, consider 3 possible pairs (r1 r8 , r4 r8 , r9 r8 ).one (r1 r8 ) pair ambiguous relationships two different Chen entities. So,rA (e1 , e2 , ) = 0.33.Given two probabilities, analyze performance relational clustering algorithm combines attribute relational evidence collective entity resolution.hard see recall entity depends recursively recallneighbor entities. pair references entity e resolved correctly basisattributes alone probability aI (e, ) (the identifying attribute probability). Furthermore, may still resolved correctly presence identifying relationshipsneighbor entity, related reference pair neighbor resolved correctly. DenotingR(e, , ) recall entity e neighbors R(N (e), , ), have:R(e, , ) = aI (e, ) + (1 aI (e, )) rI (e, ) R(N (e), , )(7)hand, consider pair entities e1 e2 . cluster assignmentpair references corresponding e1 e2 imprecise basis attributesalone probability aA (e1 , e2 , ). Even otherwise, cluster assignment go wrongconsidering relational evidence. happens presence ambiguous relationshipsreferences corresponding another pair entities, references also clustered633fiBhattacharya & Getoortogether incorrectly. imprecision I(e1 , e2 , , ) cluster assignment referencepairs corresponding entities e1 e2 turns be:I(e1 , e2 , , ) = aA (e1 , e2 , ) + (1 aA (e1 , e2 , )) rA (e1 , e2 , ) I(N (e1 ), N (e2 ), , ) (8)general, entity e multiple neighbors ei neighborhood N (e). formalize performance dependence multiple neighbors, assume co-occurrenceinvolving references corresponding e chosen random, probability selectingco-occurrence reference corresponding ei pei . recall given as:|N (e)|R(e) = aI (e) + (1 aI (e)) rI (e)Xpei R(ei )(9)i=1Note dropped notational brevity. defining imprecision, observereference corresponding neighbor ei1 e1 may co-occur referenceneighbor ej2 e2 probability pei 1 pej 2 . imprecision given as:|N (e1 )| |N (e2 )|I(e1 , e2 ) = aA (e1 , e2 ) + (1 aA (e1 , e2 )) rA (e1 , e2 )XXi=1j=1pei 1 pej 2 I(ei1 , ej2 )(10)Given similarity thresholds , relational clustering increases recall beyondachievable using attributes alone. improvement larger probability identifying relationships higher. flip side, imprecision also increases relationalclustering. Typically, low attribute threshold corresponds high precision used,recall increased using relational evidence. probability ambiguousrelations rA small, accompanying increase imprecision negligible, performance improved overall. However, higher ambiguous relationship probabilityrA , less effective relational clustering. Thus balance ambiguousidentifying relations determines overall benefit collective resolution using relationalclustering. rA high compared rI , imprecision increases faster recall,overall performance adversely affected compared attribute-based clustering. Eq. (9)Eq. (10) quantify dependence resolution performance entity naturerelationships entities. next section, use equationsdesign analyze relational clustering algorithm answering entity resolution queries.5. Collective Resolution Queriesanalysis collective resolution using relational clustering showed resolution accuracy underlying entity depends resolution accuracy related/neighboring entities. problem answering entity resolution queries, goalresolve entities database. need resolve entitiesreferences retrieved query. seen collective resolution leadspotential performance improvements attribute-based resolution. investigatecollective resolution applied answering queries get similar improvements.obvious hurdle illustrated expressions performance metrics Eq. (9)Eq. (10). show order get performance benefits resolving query using634fiQuery-time Entity Resolutionrelational clustering, need resolve neighboring entities well. Furthermore,resolve neighboring entities, need resolve neighboring entities, on.entities need resolved large number, resolvingexpensive terms query-processing time. Also, none actually goingretrieved part answer query. critical identify resolveentities contribute improving resolution accuracy query.propose two-stage query processing strategy, consisting extraction phase,identifying relevant references need resolved answering query,resolution phase, relevant references extracted collectivelyresolved using relational clustering. Unfolding Eq. (9) Eq. (10) starting queryentities leads natural expansion process. section, describe extractionprocess using two novel expansion operators and, parallel, analyze improvementresolution accuracy obtained considering co-occurrences.Recall entity resolution query Q(R.A = a) specified using attributevalue it. answer query consists partitioning referencesr r.A = value -similar a. correct answer query,general, involves references multiple entities {eq }. measure resolution accuracyquery using two metrics before. query entities eq , measure recallR(eq ) imprecision I(eq , e ) respect entity e . Entity e may maybelong {eq }.going details algorithm collective resolution queries,briefly recall accuracy attribute-based strategy resolving query. approachconsiders references r r.A -similar a, resolves using attributesonly. recall results approach R(eq , ) = aI (eq , ), imprecisiongiven I(eq , e , ) = aA (eq , e , ).propose two expansion operators constructing relevant set entityresolution query. denote level-0 references references -similarquery attribute. references user interested in, goalresolve correctly. first operator introduce attribute expansionoperator XA , A-expansion short. Given attribute valueattribute, XA (a, ) returns references r whose attributes r.A exactly match similar a. query Q(R.A = a), level-0 references retrieved expandingQ as:Rel0 (Q) = XA (a, )first step Figure 4 shows A-expansion query Q(R.N ame = W.W ang)example. retrieves four references (r1 ,r4 ,r8 ,r9 ) name W. Wang W. W.Wang.consider co-occurrence relations, construct level-1 references includingreferences co-occur level-0 references. this, use second operator,call hyper-edge expansion XH , H-expansion. reference r, XH (r)returns references share hyper-edge r, set R references XH (R)returns rR XH (r). Collective entity resolution requires consider co-occurringreferences reference. achieved performing H-expansion references635fiBhattacharya & GetoorQR.Name=W_Wang1r 11 A_AnsariRel (Q)0Rel (Q)r 9 W_W_Wangr 10 A_Ansarir 4 W_Wangr 5 A_Ansarir 54 A_Ansarir 3 A_Ansarir 23 C_Chen...r 1 W_Wangr 2 C_Chenr 8 W_Wangr 7 C_Chenr 6 L_LiRel2 (Q)...r 89 C_Chenr 16 L_Li...r 66 L_LiFigure 4: Relevant set query Q(R.N ame = W.W ang) using H-expansion Aexpansion alternatelylevel-0 retrieve level-1 references:Rel1 (Q) = XH (Rel0 (Q))Figure 4 illustrates operation example, XH (r1 ) retrieves references C.Chen (r2 ) A. Ansari (r3 ), on.perform collective resolution query, additionally need resolve references level-1. One option level-1 references attribute-based resolution usingconservative -similarity keep imprecision minimum. use analysis technique evaluate performance approach. Expanding Eq. (9),substituting aI (eiq , ) recall neighboring entity eiq eq , recallquery entity is:R(eq , , ) = aI (eq , ) + (1 aI (eq , )) rI (eq , )kXepi q aI (eiq , )i=1Similarly, substituting aA (eiq , ej , ) Eq. (10) imprecision neighboringentity eiq , get following expression imprecision:I(eq , e , , ) = aA (eq , e , ) + (1 aA (eq , e , )) rA (eq , e , )k XlXepi q pej aA (eiq , e j , )i=1 j=1appreciate easily implications considering first-order neighbors, mayassume attribute identification probability attribute ambiguity probabilityentities involved, i.e., aI (e, ) = aI () aA (e, e , ) = aA (). Then,Pusing ki=1 pei = 1 entity e, expression recall simplifiesR(eq , , ) = aI () + (1 aI ()) rI () aI ()= aI ()[1 + (1 aI ())rI ()]636fiQuery-time Entity ResolutionSimilarly, expression imprecision simplifiesI(eq , e , , ) = aA ()[1 + (1 aA ())rA ()]see attribute-clustering first level neighbors potentially increasesrecall query entity eq , imprecision goes well. However, balance rA rI favorable, increase imprecision insignificant muchsmaller corresponding increase recall, overall performanceimprovement.better this? go step consider co-occurrencerelations resolving level-1 references well. So, instead considering attributebased resolution references level-1 before, perform collective resolution them.consider -similar references, call level-2 references (Rel2 (Q)), usingA-expansion:Rel2 (Q) = XA (Rel1 (Q))Note overloaded A-expansion operator set R references: XA (R) =rR XA (r.A). level-3 references second order neighbors co-occurlevel-2 references. retrieved using H-expansion level-2 references:Rel3 (Q) = XH (Rel2 (Q))Finally, level-1 references earlier, resolve level-3 references using similarity attributes alone.order evaluate impact resolution accuracy query, unfoldrecursions Eq. (9) Eq. (10) two levels, substitute aI (eiq , ) recallaA (ei , ej , ) imprecision second order neighbors. trend expressionsbecomes clearly visible assume, before, aI aA identical entities, and,additionally, rI rA also same, i.e., rI (e1 , e2 , ) = rI () rA (e1 , e2 , ) = rA ().Then, work algebraic steps get following expressions recallprecision query entity eq :R(eq ) = aI [1 + (1 aI )rI + (1 aI )2 rI2 ]I(eq , e ) = aA [1 + (1 aA )rA + (12aA )2 rA](11)(12)continue unfold recursion grow relevant set query.Formally, expansion process alternates A-expansion H-expansion:Reli (Q) = XA (Q)XH (Reli1 (Q))XA (Reli1 (Q))= 0oddevenproceed recursively consider higher order co-occurrences query, additional terms appear expressions precision recall. implyneed continue process arbitrary levels get optimum benefit. Usingsimplifying assumptions attribute relational probabilities, expressions recall imprecision nth order co-occurrences turns geometric637fiBhattacharya & Getoorprogressions n + 1 terms. common ratio two geometric progressions(1 aI ())rI () (1 aA ())rA () respectively. Typically, ratios significantly smaller 1, therefore converge quickly increasing co-occurrencelevel. improvement resolution accuracy query Q falls quicklyexpansion depth, terminate expansion process cut-off depthwithout compromising accuracy:Rel(Q) =[Reli (Q)i=0course, assumptions attribute relational probabilities entityindependent hold practice, performance trends increasing levelsco-occurrence cannot exactly captured geometric progressions common ratiosuccessive terms. converging trends still hold general,rate convergence still determined four probabilities aI , aA , rI rAentities encountered expansion process. Intuitively, smaller valuesrI rA indicate less sensitivity co-occurrences, convergence quicker.hand, higher values aI aA mean entities resolved basedattributes alone correctly incorrectly impact co-occurrence relationssmaller. Therefore convergence quicker higher values aI aA .Apart imposing cutoff expansion depth, size relevant setalso significantly reduced restricting attribute expansion beyond level-0 exacte (r). considers references exactly attributeA-expansion XAr disregards -similar references. Interestingly, show restrictedstrategy alternates exact A-expansion H-expansion reduce recallsignificantly.6. Adaptive Query Expansionlimited depth query expansion strategy proposed previous section effectiveapproach able answer queries quickly accurately many domains. However,domains, size relevant set generated extremely large evensmall expansion depths, result, retrieved references cannot resolvedquery-time. section, propose adaptive strategies based estimatingambiguity individual references makes algorithm even efficientpreserving accuracy.main reason behind explosive growth relevant set increasing levelsquery expansion strategy previous section unconstrained treatsco-occurrences equally important resolving entity. blindly expandsreferences current relevant set, also includes new references generatedexpansion operation. Given limited time process query, approach infeasibledomains dense relationships. solution identify referenceslikely helpful resolving query, focus references.illustrate using example Figure 4, observe Chen Li significantlycommon ambiguous names Ansari even different W. Wang entitieslikely collaborators named Chen Li. Therefore, h-expanding Rel0 (rq )638fiQuery-time Entity ResolutionW. Wang, Ansari informative Chen Li. Similarly, n-expandingRel1 (rq ), choose expand name A. Ansari further, since two A.Ansari references likely coreferent. need evidenceChens Lis.describe formally, ambiguity value attribute probability two references ri rj database ri .A = rj .A =coreferent: Amb(a) = P (E(ri ) 6= E(rj ) | ri .A = rj .A = a). goal adaptive expansionadd less ambiguous references relevant set expand ambiguousreferences currently relevant set. first define adaptive versions two expansion operators treating ambiguity estimation process black-box, lookways estimate ambiguity references.6.1 Adaptive Expansion Operatorsgoal adaptive expansion selectively choose references expandcurrent relevant set, also new references included every expansion step.adaptive hyper-edge expansion, set upper-bound hmax number newreferences h-expansion particular level generate. Formally, want|XH (Reli (Q))| hmax |Reli (Q)|. value hmax may depend depthsmall enough rule full h-expansion current relevant set. Then, given hmax ,strategy choose least ambiguous references XH (Reli (Q)), since provideinformative evidence resolving references Reli (Q). achieve this,sort h-expanded references increasing order ambiguity select first kthem, k = hmax |Reli (Q)|.i1Reladapt(Q, hmax ) = LeastAmb(k, XH (Reladapt(Q)))(13)setting adaptive attribute expansion similar. positive number amax , exact a-expansion Reli (Q) allowed include amax |Reli (Q)| references. Note selection preference needs flipped ambiguous namese (Reli (Q)) decreasingneed evidence, expanded first. sort XAorder ambiguity select first k sorted list, k = amax |Reli (Q)|.could potentially retrieve references ambiguous name, totally ignoringreferences name. avoid this, choose top k ambiguous referencesReli (Q) expansion, expand references chosen.eReladapt(Q, nmax ) = XA(M ostAmb(k, Reladapt(Q)))(14)Though cannot directly control number new references added, r k reasonable estimate, r average number references per name.6.2 Ambiguity Estimationadaptive expansion scheme proposed section crucially dependent estimates name ambiguity. describe one possible scheme worked quite well.Recall want estimate probability two randomly picked referencesvalue attribute correspond different entities. reference attribute A1 , denoted639fiBhattacharya & Getoor1.2.Algorithm Query-time Resolve (R.Name name)RSet = RelevantFrontier(name)RC-ER(RSet)1.5.3.4.5.6.7.8.9.10.10.11.Algorithm FindRelevantRefs(R.Name name)Initialize RSet {}Initialize depth 0Initialize FrontierRefs {}depth < d*depth even 0R = XA (FrontierRefs)elseR = XH (FrontierRefs)FrontierRefs = RAdd FrontierRefs RSetIncrement depthReturn RSetFigure 5: High-level description query-time entity resolution algorithmR.A1 , naive estimate ambiguity value n attribute is:Amb(r.A1 ) =|R.A1 =r.A1 (R)|,|R||R.A1 =r.A1 (R)| denotes number references value r.A1 A1 . estimate clearly good since number references certain attribute valuealways match number different entity labels attribute. muchbetter additional attribute A2 . Given A2 , ambiguity value A1estimated|(R.A2 (R.A1 =r.A1 (R)))|Amb(r.A1 | r.A2 ) =,|R||(R.A2 (R.A1 =r.A1 (R)))| number distinct values observed A2 references R.A1 = r.A1 . example, estimate ambiguity last namecounting number different first names observed it. provides better estimateambiguity value attribute A1 , A2 correlated A1 .multiple uncorrelated attributes Ai available references, approachgeneralized obtain better ambiguity estimates.Putting everything together, high-level pseudo code query-time entity resolutionalgorithm shown Figure 5. algorithm works two stages first, identifiesrelevant set references given entity name query, performs relationalclustering extracted relevant references. relevant references extracted usingrecursive process already seen. relevant references depthobtained expanding relevant references depth i1, expansion dependent640fiQuery-time Entity Resolutionwhether odd step even step. actual expansion operator usedmay either unconstrained adaptive.7. Empirical Evaluationexperimental evaluation query-time resolution strategies, used realworld synthetically generated datasets. First, describe real datasetsexperiments performed move experiments synthetic data.7.1 Experiments Real Datareal-world data, used two citation datasets different characteristics.first dataset, arXiv, contains papers high energy physics used KDD Cup20032 . 58,515 references 9,200 authors, contained 29,555 publications. number author references per publication ranges 1 10 average 1.90.second dataset Elsevier BioBase database3 publications biology usedrecent IBM KDD-Challenge competition. includes publications ImmunologyInfectious Diseases years 1998 2001. dataset contains 156,156 publications 831,991 author references. number author references per publicationsignificantly higher arXiv ranges 1 100 (average 5.3). namesdatabase initials first middle names (if available), unlike arXiv,initialed complete names. number distinct names BioBase 303,693,number references name ranging 1 193 (average 2.7). UnlikearXiv, BioBase includes keywords, topic classification, language, country correspondenceaffiliation corresponding author attributes paper, useattributes resolution addition author names. BioBase diverse termsattributes, covering 20 languages, 136 countries, 1,282 topic classifications 7,798keywords.entity resolution queries arXiv, selected ambiguous names correspondone author entity. gave us 75 queries, number true entitiesselected names varying 2 11 (average 2.4). BioBase, selectedqueries top 100 author names highest number references. averagenumber references 100 names 106, number entitiesselected names ranges 1 100 (average 32), thereby providing wide variety entityresolution settings queries.7.1.1 Relevant Set Size Vs. Resolution Timebegin exploring growth rate relevant set query expansion depthtwo datasets. Figure 6(a) plots size relevant set sample queryname T. Lee arXiv M. Yamashita BioBase. growth rate arXivquery moderate. number references name T. Lee 7, numberrelevant references depth 0, size grows 7,500 depth 7. contrast,BioBase plots clearly demonstrate exponential growth relevant references2. http://www.cs.cornell.edu/projects/kddcup/index.html3. http://help.sciencedirect.com/robo/projects/sdhelp/about biobase.htm641fiBhattacharya & Getoor800900BioBase: similarBioBase: exactarXive: exact700700time (secs)# references(in thousands)600500400300600500400300200200100100000(a)BioBasearXiv8001234expansion depth5670(b)1020304050#references (in thousands)6070Figure 6: (a) Size relevant set increasing expansion depth sample queriesarXiv BioBase (b) Execution time RC-ER increasing numberreferencesdepth name expansion strategies. 84 relevant references depth0. references expanded using name similarity expansion, 722 relevantreferences depth 1, 65,000 depth 3 586,000 depth 5.restricted similarity measure two names considered similar firstinitials match, last names first character differ overall2 characters. liberal measure would result significantly faster growth. alsoobserve exact expansion, growth slower still 45,000 referencesdepth 3, 384,000 depth 5 783,000 depth 7. interesting note growthslows beyond depth 5; references entire datasetalready covered depth (BioBase 831,991 references total). growthrates two examples arXiv BioBase typical queriestwo datasets.Next, Figure 6(b), observe relational clustering algorithm RC-ER scalesincreasing number references relevant set. execution times reportedDell Precision 870 server 3.2GHz Intel Xeon processor 3GB memory.plot shows algorithm scales well increasing references, gradientdifferent two datasets. mainly due difference average numberreferences per hyper-edge. suggests arXiv, RC-ER capable handlingrelevant sets generated using unconstrained expansion. BioBase, would require600 secs 40,000 references, 900 secs 65,000. clearlypossible use RC-ER unconstrained expansion query-time resolution BioBaseeven depth 3.7.1.2 Entity Resolution Accuracy Queriesnext experiment, evaluate several algorithms entity resolution queries.compare entity resolution accuracy pair-wise co-reference decisions using F1measure (which harmonic mean precision recall). fair comparison,consider best F1 algorithms possible thresholds determining642fiQuery-time Entity ResolutionTable 1: Average entity resolution accuracy (F1) different algorithms 75 arXivqueries 100 BioBase queriesA*NRNR*RC-ER Depth-1RC-ER Depth-3arXiv0.7210.7780.9560.9520.9640.970BioBase0.7010.6870.7100.7530.8130.820duplicates. algorithms, compare attribute-based entity resolution (A), naiverelational entity resolution (NR) uses attributes related references, relationalclustering algorithm collective entity resolution (RC-ER) using unconstrained expansiondepth 3. also consider transitive closures pair-wise decisions firsttwo approaches (A* NR*). attribute similarity, use Soft TF-IDFJaro-Winkler similarity names, shown perform best namebased resolution (Bilenko, Mooney, Cohen, Ravikumar, & Fienberg, 2003), TF-IDFsimilarity textual attributes.average F1 scores queries shown Table 1 algorithmtwo datasets. shows RC-ER improves accuracy significantly baselines.example BioBase, improvement 21% NR, 25% A* 13%NR*. demonstrates potential benefits collective resolution answeringqueries, validates recent results context offline entity resolution (Bhattacharya& Getoor, 2004, 2007; Singla & Domingos, 2004; Dong et al., 2005; McCallum & Wellner,2004). earlier work (Bhattacharya & Getoor, 2007) demonstrated usingextensive experiments real synthetic datasets relational clustering algorithm(RC-ER) improves entity resolution performance traditional baselines contextoffline data cleaning, entire database cleaned whole. numbersTable 1 confirm similar improvements obtained localized resolutionwell. predicted analysis, accuracy improvement comesdepth-1 relevant references. 56 100 BioBase queries, accuracyimprove beyond depth-1 relevant references. remaining 44 queries, averageimprovement 2%. However, 8 ambiguous queries, accuracy improves5%, biggest improvement high 27% (from 0.67 0.85 F1).instances fewer arXiv, biggest improvement 37.5% (from 0.727 1.0).one hand, shows considering related records resolving collectivelyleads significant improvement accuracy. hand, also demonstratespotential benefits considering higher order neighbors, fall quicklybeyond depth 1. also serves validate analysis collective query resolutionSection 4.643fiBhattacharya & GetoorTable 2: Average query processing time unconstrained expansionA*NRNR*RC-ER Depth-1RC-ER Depth-31arXiv0.410.410.430.4280.451.36BioBase9.359.5928.5428.6911.88606.981depth 1depth 2depth 1depth 20.90.7recallprecision0.80.90.60.50.80.40.30.70.210.80.60.40.2010.8similarity threshold(a)0.60.4similarity threshold0.20(b)110.90.8recallprecision0.90.80.70.60.50.70.4depth 1depth 20.610.8depth 1depth 20.30.60.40.201similarity threshold(c)0.80.60.4similarity threshold0.20(d)Figure 7: Average precision recall different similarity thresholds (a-b) BioBase(c-d) arXivlast two rows Table 1 show converging nature entity resolution performanceincreasing depth. verify explicitly precision recall Figure 7.top two plots show average precision recall BioBase queries different similaritythresholds RC-ER. bottom two plots show arXiv. seeprecision curve depth 1 coincides stays marginally precision curvedepth 3 BioBase arXiv. recall curves show opposite trend recall644fiQuery-time Entity Resolutionmarginally improves depth 3. agreement derived expressionsprecision recall increasing depth Eq. (12). difference recall depths2.1 3 quantified aI (1 aI )2 rI2 , difference precision aA (1 aA )2 rAexplanation small difference average precision recall twoplots factors, averaged queries, significantly smaller1 arXiv BioBase. investigate converging nature performancedetail varying structural properties experiments synthetic dataSection 7.2.7.1.3 Reducing Time Adaptive Expansionfirst set experiments show effectiveness two-phase query processing strategyterms entity resolution performance. challenge, described earlier,obtaining benefits real-time. So, next, focus time requiredprocess queries two datasets using unconstrained expansion depth 3.results shown Table 2. arXiv, average processing time depth-3 expansion1.36 secs, 406 relevant references average. shows two-phase strategyunconstrained expansion practical processing strategy entity resolution queriesresolves query entities accurately, extremely quickly well. However,BioBase, average number references reached depth 3 44,000,time taken resolve collectively 10 minutes. unacceptableanswering queries, next focus processing time improved usingproposed adaptive strategies. Note time taken depth-1 expansion around 12secs, close attribute-based baseline (A) less timenaive relational algorithm (NR).Since unconstrained expansion effective arXiv, focus BioBase evaluating adaptive strategies. estimating ambiguity references, use last namesfirst initial secondary attribute. results good estimates ambiguity ambiguity estimate name strongly correlated (correlation coeff. 0.8)number entities name. First, evaluate adaptive H-expansion. SinceH-expansion occurs first depth 1, query, construct relevant set cutoffdepth = 1, use adaptive H-expansion depth 1. expansion upper-bound hmaxset 4. compare three different adaptive H-expansion strategies: (a) choosingleast ambiguous references, (b) choosing ambiguous references (c) randomselection. Then, query, evaluate entity resolution accuracy using RC-ERrelevant sets constructed using three adaptive strategies. average accuraciesthree strategies 100 queries shown first column Table 3. Leastambiguous selection, strategy propose, clearly shows biggest improvement ambiguous smallest, random selection between. Notably,even without many depth-1 references, improve accuracy NR*virtue collective resolution.perform similar set experiments evaluating adaptive attribute expansion.Recall depth 2 lowest depth adaptive attribute expansion performed.query, construct relevant set = 3 using adaptive A-expansiondepth 1 unconstrained H-expansion depths 1 3. expansion upper-bound645fiBhattacharya & GetoorTable 3: Avg. resolution accuracy F1 different adaptive expansion strategiesLeast AmbiguousAmbiguousRandomH-expansion0.7900.7610.770A-expansion0.8150.8210.820amax set 0.2, average 1 5 names expanded. Again, compare threestrategies: (a) expanding least ambiguous names, (b) expanding ambiguousnames (c) random expansion. average accuracies three schemes100 queries listed second column Table 3. experiment adaptive Aexpansion bring difference three schemes clearly adaptiveH-expansion. comparing A-expansion depth 2 and, average,much improvement obtained beyond depth 1 ceiling effect.shows almost benefit depth 3 comes proposed strategyexpanding ambiguous names.two experiments demonstrate effectiveness two adaptive expansionschemes isolation. Now, look results use together.100 queries, construct relevant set Rel(rq ) = 3 using adaptive Hexpansion adaptive exact A-expansion. Since improvement collectiveresolution comes depth-1 references, consider two different experiments.first experiment (AX-2), use adaptive expansion depths 2 beyond,unconstrained H-expansion depth 1. second experiment (AX-1), use adaptiveH-expansion even depth 1, hmax = 6. them, use adaptive expansionhigher depths 2 3 parameters hmax = 3 3 amax = 0.2 2.Table 4: Comparison unconstrained adaptive expansion BioBaserelevant-set sizetime (cpu secs)accuracy (F1)Unconstrained44,129.5606.980.821AX-25,510.5243.440.818AX-13,743.5231.280.820Table 4, compare two adaptive schemes unconstrained expansion= 3 queries. Clearly, accuracy remains almost unaffected schemes.First, note AX-2 matches accuracy unconstrained expansion, showsalmost improvement depth 1. accuracy achieved even thoughuses adaptive expansion expands small fraction Rel1 (Q), thereby reducesaverage size relevant set 44,000 5,500. significantly, AX-1 also matchesimprovement even without including many depth-1 references. reductionsize relevant set immense impact query processing time. averageprocessing time drops 600 secs unconstrained expansion 43 secs646fi1.110.90.80.70.60.50.40.30.21pR=0.2pR=0.5pR=1.00.90.8PrecisionRecallQuery-time Entity Resolution0.70.60.5pRa=0.0pRa=0.3pRa=0.60.40.30.70.60.5Sim. Threshold0.40.70.650.60.550.5Sim. Threshold0.45Figure 8: Effect (a) identifying relations recall (b) ambiguous relations precision collective clustering. Error bars show standard deviation.AX-2, 31 secs AX-1, thus making possible use collective entityresolution query-time resolution.7.1.4 Adaptive Depth Selectionimprovement, investigate processing time reduced settingexpansion depth adaptively, depending ambiguity query name, comparedfixed queries. simple setup, set 1 queries numberdifferent first initials last name less 10 (out 26), explore depth 2ambiguous queries. reduces expansion depth 2 1 18 100queries. result, average processing time queries reduced 35% 11.5secs 17.7 secs reduction accuracy. three queries, originalprocessing time depth 2 greater 30 secs. preliminary experiments,evaluated original set 100 queries inherently ambiguous. generalsetting, bigger fraction queries lower ambiguity, impact expectedeven significant.7.2 Experiments using Synthetic Dataaddition experiments real datasets, performed experiments syntheticallygenerated data. enables us reason beyond specific datasets, also empiricallyverify performance analysis relational clustering general, specificallyentity resolution queries. designed generator synthetic data (Bhattacharya& Getoor, 2007) allows us control different properties underlying entitiesrelations them, also observed co-occurrence relationshipsentity references. Among properties, control number entities,average number neighbor entities per entity, number average sizeobserved co-occurrences. Additionally, control ambiguity entity attributes,number ambiguous relationships entities. present overviewsynthetic data generation process Appendix A.647fiBhattacharya & Getoor10.90.85Precision0.8Recall0.95t=0.9t=0.6t=0.50.90.70.60.50.80.750.70.40.650.30.60.2t=0.9t=0.6t=0.50.55012Expansion Level3012Expansion Level3Figure 9: Change (a) precision (b) recall increasing expansion levels usedcollective clustering. Error bars show standard deviation.performed number different experiments synthetic data. first setexperiments, investigate influence identifying relationships collective resolution using relational clustering. generate 500 co-occurrence relations100 entities 200 entity-entity relationships, using varying probability co-occurrencespR = {0.2, 0.5, 1.0} data. probability ambiguous relationships held fixed,higher pR translates higher probability identifying co-occurrences data.Figure 8(a) shows recall different similarity thresholds three different co-occurrenceprobabilities. results confirm recall increases progressively identifyingrelationships thresholds. curves pR = 0.5 pR = 1.0 flattenrecall achievable.Next, observe effect ambiguous relations precision collective resolution using relational clustering. add 200 binary relationships 100 entitiesthree stages increasing ambiguous relationship probability (pR= {0, 0.3, 0.6}).perform collective resolution 500 co-occurrence relations generatedthree settings. Figure 8(b) plot precision different similarity threshold three different values pR. plots confirm progressive decrease precision thresholdshigher pR.experiments, results averaged 200 different runs.Next, evaluate collective resolution queries. Recall last two rows Table 1 clearly demonstrate converging nature performance increasing expansionlevels queries real datasets. ran experiments synthetic data verifytrend. run, generated 2,500 co-occurrence relations 500 entitiesaverage 2 neighbors per entity. performed localized collective clusteringcase, using query ambiguous attribute value (that correspondshighest number underlying entities). Figure 9(c) (d), show recall precision change increasing expansion level query. Recall improves increasingexpansion level, precision decreases overall, predicted analysis. Importantly, recall increases significantly faster rate decrease precision.general, rate increase/decrease depends structural properties data,shown analysis. experiments, seen different rates648fiQuery-time Entity Resolutionchange, overall trend remains same. analysis also showed precisionrecall converge quickly increasing expansion levels. confirmedtwo plots curves flatten level 3.7.3 Current LimitationsFinally, discuss two current limitations collective entity resolution approach.Recall similarity measure Eqn. 1 involves weighting parameter combiningattribute relational similarity. experiments, report best accuracyvalues query. Selecting optimal value queryunresolved issue. However, experiments reveal even fixed ( = 0.5)queries brings significant improvements baselines.second issue determination termination threshold RC-ER. Noteissue baselines well, report best accuracythresholds. area ongoing research. Preliminary experiments shownbest threshold often query specific setting threshold dependingambiguity query results significantly better accuracy fixed thresholdqueries. empirical evaluation, cleaned entire arXiv dataset offline runningRC-ER references together, terminated threshold maximizesresolution accuracy references. results overall accuracy (F1) 0.98.However, average accuracy measured 75 queries test set 0.87.comparison, best obtainable accuracy resolving queries individuallydifferent threshold 0.97. suggests may potential benefits localizedcleaning global counterpart offline setting.8. Related Workentity resolution problem studied many different areas differentnames deduplication, record linkage, co-reference resolution, reference reconciliation,object consolidation, etc. Much work focused traditional attribute-basedentity resolution. Extensive research done defining approximate string similaritymeasures (Monge & Elkan, 1996; Navarro, 2001; Bilenko et al., 2003; Chaudhuri, Ganjam,Ganti, & Motwani, 2003) may used unsupervised entity resolution.approach uses adaptive supervised algorithms learn similarity measures labeleddata (Tejada, Knoblock, & Minton, 2001; Bilenko & Mooney, 2003).Resolving entities optimally known computationally hard even attributes considered (Cohen, Kautz, & McAllester, 2000). Therefore, efficiencyreceived lot attention attribute-based data cleaning. goal essentially avoidirrelevant expensive attribute similarity computations using blocking approach without affecting accuracy significantly (Hernandez & Stolfo, 1995; Monge & Elkan, 1997; McCallum et al., 2000). merge/purge problem posed Hernandez Stolfo (1995)efficient schemes retrieve potential duplicates without resorting quadratic complexity. use sorted neighborhood method appropriate key chosenmatching. Records sorted grouped according key potential matchesidentified using sliding window technique. However, keys may badly distortedmatches cannot spanned window cases retrieved.649fiBhattacharya & Getoorsolution propose multi-pass method different keys mergingresults using transitive closure. Monge Elkan (1997) combine union find algorithmpriority queue look-up find connected components undirected graph. McCallum et al. (2000) propose use canopies first partition data overlappingclusters using cheap distance metric use accurate expensive distancemetric data pairs lie within canopy. Chaudhuri et al. (2003) useerror tolerant index data warehousing applications probabilistically lookingsmall set candidate reference tuples matching incoming tuple.considered probabilistically safe since closest tuples database retrievedhigh probability. also efficient since small number matches needsperformed. Swoosh (Benjelloun, Garcia-Molina, Su, & Widom, 2005) recentlyproposed generic entity resolution framework considers resolving mergingduplicates database operator goal minimize number record-levelfeature-level operations. alternative approach reduce complexity individual similarity computations. Gravano, Ipeirotis, Koudas, Srivastava (2003) proposesampling approach quickly compute cosine similarity tuples fast text-joinswithin SQL framework. approaches enable efficient data cleaningattributes references considered.Many recently proposed approaches take relations account data integration(Ananthakrishna et al., 2002; Bhattacharya & Getoor, 2004, 2005; Kalashnikov et al., 2005;Dong et al., 2005). Ananthakrishna et al. (2002) introduce relational deduplication datawarehouse applications dimensional hierarchy relations. Kalashnikov et al. (2005) enhance attribute similarity ambiguous referencemany entity choices relationship analysis entities, like affiliationco-authorship. earlier work, proposed different measures relational similarity relational clustering algorithm collective entity resolution using relationships(Bhattacharya & Getoor, 2004, 2007). Dong et al. (2005) collectively resolve entities multiple types propagating relational evidences dependency graph, demonstratebenefits collective resolution real datasets. Long, Zhang, Wu, Yu (2006) proposed model general multi-type relational clustering, though appliedspecifically entity resolution. perform collective factorization related matricesusing spectral methods identify cluster space minimizes distortion relationships individual features time. approaches make userelationships either entity matching (where domain entities known) entityresolution (where underlying entities also need discovered) shownincrease performance significantly attribute-based solutions problems.However, price pay terms computational complexity increases duecouple different reasons. Firstly, number potential matches increasesrelationships considered individual similarity computations also become expensive. Secondly, collective resolution using relationships necessitates iterative solutionsmake multiple passes data. approaches stillshown scalable practice, cannot employed query-time cleaningstraight-forward manner.idea multi-relational clustering also comes Inductive Logic Programming(ILP) literature. Emde Wettschereck (1996) used multi-relational similarity650fiQuery-time Entity Resolutioninstance-based classification representations first order logic. define similaritytwo objects, e.g., two people, combination similarity attributevalues, age, weight, etc., similarity objectsrelated to, companies work for. similar naive relationalsimilarity discussed earlier, except similarity connected objectsalso defined recursively terms connected objects. Kirsten Wrobel (1998)used recursive relational similarity measure agglomerative clustering firstorder representations. recursive comparison neighbors shown effectiveterms accuracy results, computational challenge major drawback.Probabilistic approaches cast entity resolution classification problemextensively studied. groundwork done Fellegi Sunter (1969). Others (Winkler, 2002; Ravikumar & Cohen, 2004) recently built upon work. Adaptivemachine learning approaches proposed data integration (Sarawagi & Bhamidipaty, 2002; Tejada et al., 2001), active learning requires user label informativeexamples. Probabilistic models use relationships collective entity resolutionapplied named entity recognition citation matching (Pasula et al., 2003; McCallum & Wellner, 2004; Li et al., 2005; Singla & Domingos, 2004). probabilisticapproaches superior similarity-based clustering algorithms associatedegree confidence every decision, learned models provide valuable insightdomain. However, probabilistic inference collective entity resolution knownscalable practice, particularly relationships also considered. approaches mostly shown work small datasets, significantly slowerclustering counterparts.Little work done literature query-centric cleaning relational approaches answering queries, execution time important accuracy resolution. Approaches proposed localized evaluation Bayesian networks (Draper& Hanks, 1994), clustering problems. Recently, Chandel, Nagesh, Sarawagi(2006) addressed efficiency issues computing top-k entity matches dictionary context entity extraction unstructured documents. process top-ksearches batches speed-up achieved sharing computation differentsearches. Fuxman, Fazli, Miller (2005) motivate problem answering queriesdatabases violate integrity constraints address scalability issues resolving inconsistencies dynamically query-time. However, relational aspect problem,major scalability issue address, come settings. earlier work relational clustering(Bhattacharya & Getoor, 2007), usedidea relevant references experimental evaluation BioBase dataset.also discussed here, dataset entity labels 100 frequentnames. Therefore, instead running collective resolution entire BioBase dataset,evaluated 100 names separately, using relevant references case.relevant references ones directly connected references namesinterest. concept focused cleaning, performance analysis relational clustering, expand-resolve strategy and, importantly, idea adaptive expansionquery-time resolution addressed paper.One first papers make use relational features classification problemChakrabarti, Dom, Indyk (1998). showed problem classifying651fiBhattacharya & Getoorhyper-linked documents, naive use relationships hurt performance. Specifically,key terms neighboring documents thrown document whose topicclassified, classification accuracy degrades instead improving. parallel scenarioclustering using relationships naive relational model (NR) may perform worseattribute model (A) presence highly ambiguous relationships. Chakrabartiet al. (1998) showed relationships however used improved classificationtopic labels neighboring documents used evidence instead naivelyconsidering terms contain. earlier work (Bhattacharya & Getoor, 2004,2007), shown similar results collective clustering using relationships,cluster labels neighboring labels lead improved clustering performance comparednaive relational attribute-based clustering. interesting result shownpaper theory empirically even collective use relationshipshurt clustering accuracy compared attribute-based clustering. happensrelationships references dense ambiguous, errors propagaterelationships exceed identifying evidence provide.9. Conclusionspaper, motivated problem query-time entity resolution accessingunresolved third-party databases. answering entity resolution queries, addressed challenges using collective approaches, recently shown significantperformance improvements traditional baselines offline setting. first hurdlecollective resolution arises interdependent nature resolution decisions.first formally analyzed recursive nature dependency, showed precision recall individual entities grow geometric progression increasing levelsneighbors considered collectively resolved. proposed two-stage expandresolve strategy answering queries based analysis, using two novel expansionoperators. showed using analysis sufficient consider neighbors smallexpansion depths, since resolution accuracy query converges quickly increasingexpansion level. second challenge answering queries computationquick. achieve this, improved unconstrained expansion strategy proposeadaptive algorithm, dramatically reduces size relevant referencesand, result, processing time identifying informative referencesquery. demonstrated using experiments two real datasets strategiesenable collective resolution query-time, without compromising accuracy. additionally performed various experiments synthetically generated data wide rangesettings verify trends predicted analysis. summary, addressedmotivated critical data integration retrieval problem, proposed algorithmssolving accurately efficiently, provided theoretical analysis validate approachexplain works, and, finally, shown experimental results multiple real-worldsynthetically generated datasets demonstrate works extremely well practice. presented results bibliographic data, techniques applicablerelational domains.shown dramatic reduction query processing time comesadaptive expansion, research necessary able answer entity resolution queries652fiQuery-time Entity Resolutionorder milli-seconds, may demanded many scenarios. Interesting directionsfuture research include exploring stronger coupling extraction resolutionphases query processing, expansion happens on-demandresolution process finds residual ambiguity high requires additional evidencetaking decisions. would directly address problem determiningexpansion depth. reported preliminary experiments paper,work needs done adaptive depth determination depending ambiguity.context, may imagine soft thresholds adaptive expansion, expansionoperator automatically determines number hyper-edges names expandedresidual ambiguity falls specified level. interesting extensionsinclude caching intermediate resolutions, related resolutions performedquery stored retrieved required answering future queries.Acknowledgmentswish thank anonymous reviewers constructive suggestions greatlyimproved paper. work supported National Science Foundation, NSF#0423845 NSF #0438866, additional support ITIC KDD program.AppendixSynthetic Data Generatordesigned synthetic data generator allows us control different structuralattribute-based characteristics data(Bhattacharya & Getoor, 2007).present overview generation algorithm.generation process two stages. first stage, create collaborationgraph among underlying entities entity attributes. second, generateobserved co-occurrence relations collaboration graph. high level descriptiongenerative process shown Figure 10. Next, describe two stagesgeneration process greater detail.graph creation stage, turn, two sub-stages. First, create domainentities attributes add relationships them. creating entities,control number entities ambiguity attributes. create N entitiesattributes one another. simplicity without losing generality,entity e single floating point attribute e.x, instead character string. parameterpa controls ambiguity entity attributes; probability pa attribute newentity chosen values already use existing entities. binaryrelationships added created entities. attributes,parameter controlling ambiguity relationships, defined Section 4.binary relationship (ei , ej ), first ei chosen randomly ej sampled (ei , ej )ambiguous relationship probability pRa.describing process generating co-occurrence relationships graph,let us consider little detail issue attribute ambiguity. finally needscontrolled ambiguity reference attributes. dependentity attributes, completely determined entities. Taking example653fiBhattacharya & Getoor1.2.3.4.5.6.7.Creation StageRepeat N timesCreate random attribute x ambiguity paCreate entity e attribute xRepeat timesChoose entity ei randomlyChoose entity ej prob pRambiguous relationship (ei , ej )Set ei = N br(ej ) ej = N br(ei )8.9.10.11.12.13.14.15.16.Generation StageRepeat R timesRandomly choose entity eGenerate reference r using N (e.x, 1)Initialize hyper-edge h = hriRepeat probability pcRandomly choose ej N br(e) without replacementGenerate reference rj using N (ej .x, 1)Add rj hyper-edge hOutput hyper-edge hFigure 10: High-level description synthetic data generation algorithmnames, two people names John Michael Smyth James Daniel Smithstill ambiguous terms observed names data dependinggeneration process observed names. words, attribute ambiguity referencesdepends separation entity attributes dispersion createdgeneration process. make assumption entity e attribute e.x,references generated Gaussian distribution mean x variance 1.0. So,high probability, reference attribute generated e.x range[e.x 3, e.x + 3]. range attribute domain considered occupiedentity e. entity ambiguous attribute occupied range intersectsanother entity.come generation co-occurrence relationships entity collaboration graph. stage, R co-occurrence relationships hyper-edges generated,references. hyper-edge hri , ri1 , . . . , rik i, two aspects need controlled many references references included hyper-edge.done follows. First, sample entity ei serves initiator entityhyper-edge. entities eij hyper-edge repeatedly sampled (without replacement) neighbors initiator entity ei . size hyper-edgedetermined using parameter pc . sampling step hyper-edge terminatedprobability pc selection eij . process also terminated neighborsinitiator entity exhausted. Finally, references rij need generatedselected entities eij . done entity e sampling Gaussiandistribution N (e.x, 1).654fiQuery-time Entity ResolutionReferencesAnanthakrishna, R., Chaudhuri, S., & Ganti, V. (2002). Eliminating fuzzy duplicatesdata warehouses. International Conference Large Databases (VLDB),Hong Kong, China.Benjelloun, O., Garcia-Molina, H., Su, Q., & Widom, J. (2005). Swoosh: generic approachentity resolution. Tech. rep., Stanford University.Bhattacharya, I., & Getoor, L. (2004). Iterative record linkage cleaning integration. SIGMOD Workshop Research Issues Data Mining KnowledgeDiscovery (DMKD), Paris, France.Bhattacharya, I., & Getoor, L. (2005). Relational clustering multi-type entity resolution. ACM SIGKDD Workshop Multi Relational Data Mining (MRDM),Chicago, IL, USA.Bhattacharya, I., & Getoor, L. (2006). Mining Graph Data (L. Holder D. Cook, eds.),chap. Entity Resolution Graphs. Wiley.Bhattacharya, I., & Getoor, L. (2007). Collective entity resolution relational data. ACMTransactions Knowledge Discovery Data (TKDD), 1 (1).Bhattacharya, I., Licamele, L., & Getoor, L. (2006). Query-time entity resolution.ACM International Conference Knowledge Discovery Data Mining (SIGKDD),Philadelphia, PA, USA.Bilenko, M., & Mooney, R. (2003). Adaptive duplicate detection using learnable stringsimilarity measures. ACM International Conference Knowledge DiscoveryData Mining (SIGKDD), Washington DC, USA.Bilenko, M., Mooney, R., Cohen, W., Ravikumar, P., & Fienberg, S. (2003). Adaptive namematching information integration.. IEEE Intelligent Systems, 18 (5), 1623.Chakrabarti, S., Dom, B., & Indyk, P. (1998). Enhanced hypertext categorization usinghyperlinks. Proceedings ACM International Conference ManagementData (SIGMOD).Chandel, A., Nagesh, P. C., & Sarawagi, S. (2006). Efficient batch top-k searchdictionary-based entity recognition. IEEE International Conference DataEngineering (ICDE), Washington, DC, USA.Chaudhuri, S., Ganjam, K., Ganti, V., & Motwani, R. (2003). Robust efficient fuzzymatch online data cleaning. ACM International Conference ManagementData (SIGMOD), San Diego, CA, USA.Cohen, W., Kautz, H., & McAllester, D. (2000). Hardening soft information sources.ACM International Conference Knowledge Discovery Data Mining (SIGKDD),Boston, MA, USA.Dong, X., Halevy, A., & Madhavan, J. (2005). Reference reconciliation complex information spaces. ACM International Conference Management Data(SIGMOD), Baltimore, MD, USA.655fiBhattacharya & GetoorDraper, D., & Hanks, S. (1994). Localized partial evaluation belief networks.Annual Conference Uncertainty Artificial Intelligence (UAI), Seattle, WA, USA.Emde, W., & Wettschereck, D. (1996). Relational instance based learning. ProceedingsInternational Conference Machine Learning (ICML).Fellegi, I., & Sunter, A. (1969). theory record linkage. Journal AmericanStatistical Association, 64, 11831210.Fuxman, A., Fazli, E., & Miller, R. (2005). Conquer: Efficient management inconsistentdatabases. ACM International Conference Management Data (SIGMOD), Baltimore, MD, USA.Gravano, L., Ipeirotis, P., Koudas, N., & Srivastava, D. (2003). Text joins data cleansing integration rdbms. IEEE International Conference DataEngineering (ICDE), Bangalore, India.Hernandez, M., & Stolfo, S. (1995). merge/purge problem large databases.ACM International Conference Management Data (SIGMOD), San Jose, CA,USA.Kalashnikov, D., Mehrotra, S., & Chen, Z. (2005). Exploiting relationships domainindependent data cleaning. SIAM International Conference Data Mining (SIAMSDM), Newport Beach, CA, USA.Kirsten, M., & Wrobel, S. (1998). Relational distance-based clustering. ProceedingsInternational Workshop Inductive Logic Programming (ILP).Li, X., Morie, P., & Roth, D. (2005). Semantic integration text: ambiguous namesidentifiable entities. AI Magazine. Special Issue Semantic Integration, 26 (1).Long, B., Zhang, Z. M., Wu, X., & Yu, P. S. (2006). Spectral clustering multi-type relational data. Proceedings 23rd International Conference Machine Learning(ICML).McCallum, A., Nigam, K., & Ungar, L. (2000). Efficient clustering high-dimensional datasets application reference matching. ACM International ConferenceKnowledge Discovery Data Mining (SIGKDD), Boston, MA, USA.McCallum, A., & Wellner, B. (2004). Conditional models identity uncertainty application noun coreference. Advances Neural Information Processing Systems(NIPS), Vancouver, BC, Canada.Monge, A., & Elkan, C. (1996). field matching problem: Algorithms applications.ACM International Conference Knowledge Discovery Data Mining(SIGKDD), Portland, OR, USA.Monge, A., & Elkan, C. (1997). efficient domain-independent algorithm detectingapproximately duplicate database records. SIGMOD Workshop ResearchIssues Data Mining Knowledge Discovery (DMKD), Tuscon, AZ, USA.Navarro, G. (2001). guided tour approximate string matching. ACM ComputingSurveys, 33 (1), 3188.656fiQuery-time Entity ResolutionPasula, H., Marthi, B., Milch, B., Russell, S., & Shpitser, I. (2003). Identity uncertaintycitation matching. Advances Neural Information Processing Systems (NIPS),Vancouver, BC, Canada.Ravikumar, P., & Cohen, W. (2004). hierarchical graphical model record linkage.Conference Uncertainty Artificial Intelligence (UAI), Banff, Alberta,Canada.Sarawagi, S., & Bhamidipaty, A. (2002). Interactive deduplication using active learning.Proceedings Eighth ACM International Conference Knowledge DiscoveryData Mining (SIGKDD), Edmonton, Alberta, Canada.Singla, P., & Domingos, P. (2004). Multi-relational record linkage. SIGKDD Workshop Multi-Relational Data Mining (MRDM), Seattle, WA, USA.Tejada, S., Knoblock, C., & Minton, S. (2001). Learning object identification rulesinformation integration. Information Systems Journal, 26 (8), 635656.Winkler, W. (2002). Methods record linkage Bayesian networks. Tech. rep., Statistical Research Division, U.S. Census Bureau, Washington, DC.657fiJournal Artificial Intelligence Research 30 (2007) 321359Submitted 11/06; published 10/07New Inference Rules Max-SATChu Min Lichu-min.li@u-picardie.frLaRIA, Universite de Picardie Jules Verne33 Rue St. Leu, 80039 Amiens Cedex 01, FranceFelip Manyafelip@iiia.csic.esIIIA, Artificial Intelligence Research InstituteCSIC, Spanish National Research CouncilCampus UAB, 08193 Bellaterra, SpainJordi Planesjplanes@diei.udl.esComputer Science Department, Universitat de LleidaJaume II, 69, 25001 Lleida, SpainAbstractExact Max-SAT solvers, compared SAT solvers, apply little inferencenode proof tree. Commonly used SAT inference rules like unit propagation producesimplified formula preserves satisfiability but, unfortunately, solving Max-SATproblem simplified formula equivalent solving original formula.paper, define number original inference rules that, besides appliedefficiently, transform Max-SAT instances equivalent Max-SAT instanceseasier solve. soundness rules, seen refinements unit resolutionadapted Max-SAT, proved novel simple way via integer programmingtransformation. aim finding powerful inference rules practice,developed new Max-SAT solver, called MaxSatz, incorporates rules,performed experimental investigation. results provide empirical evidenceMaxSatz competitive, least, random Max-2SAT, random Max-3SAT, MaxCut, Graph 3-coloring instances, well benchmarks Max-SATEvaluation 2006.1. Introductionrecent years growing interest developing fast exact Max-SATsolvers (Alber, Gramm, & Niedermeier, 2001; Alsinet, Manya, & Planes, 2003b, 2005;de Givry, Larrosa, Meseguer, & Schiex, 2003; Li, Manya, & Planes, 2005; Xing & Zhang,2004; Zhang, Shen, & Manya, 2003) due potential solve over-constrained NPhard problems encoded formalism Boolean CNF formulas. Nowadays, Max-SATsolvers able solve lot instances beyond reach solvers developedfive years ago. Nevertheless, yet considerable gap difficultyinstances solved current SAT solvers instances solved best performingMax-SAT solvers.motivation behind work bridge gap complete SAT solversexact Max-SAT solvers investigating technology previously developedSAT (Goldberg & Novikov, 2001; Li, 1999; Marques-Silva & Sakallah, 1999; Zhang, 1997;Zhang, Madigan, Moskewicz, & Malik, 2001) extended incorporated Maxc2007AI Access Foundation. rights reserved.fiLi, Manya & PlanesSAT. precisely, focus attention branch bound Max-SAT solvers basedDavis-Putnam-Logemann-Loveland (DPLL) procedure (Davis, Logemann, & Loveland,1962; Davis & Putnam, 1960).One main differences SAT solvers Max-SAT solvers formermake intensive use unit propagation node proof tree. Unit propagation,highly powerful inference rule, transforms SAT instance satisfiabilityequivalent SAT instance easier solve. Unfortunately, solving Max-SATproblem is, general, equivalent solving ; i.e., number unsatisfiedclauses every truth assignment. example, applyunit propagation CNF formula = {x1 , x1 x2 , x1 x2 , x1 x3 , x1 x3 },obtain = {2, 2}, equivalent interpretation satisfyingx1 unsatisfies one clause two clauses . Therefore, want computeoptimal solution, cannot apply unit propagation SAT solvers.proposed previous work (Li et al., 2005) use unit propagation computelower bounds branch bound Max-SAT solvers instead using unit propagationsimplify CNF formulas. approach, detect disjoint inconsistent subsets clausesvia unit propagation. turns number disjoint inconsistent subsets detectedunderestimation number clauses become unsatisfied currentpartial assignment extended complete assignment. underestimation plusnumber clauses unsatisfied current partial assignment provides good performinglower bound, captures lower bounds based inconsistency countsstate-of-the-art Max-SAT solvers implement (Alsinet, Manya, & Planes, 2003a; Alsinetet al., 2003b; Borchers & Furman, 1999; Wallace & Freuder, 1996; Zhang et al., 2003),well improved lower bounds (Alsinet, Manya, & Planes, 2004; Alsinet et al., 2005;Xing & Zhang, 2004, 2005).one hand, number disjoint inconsistent subsets detected conservative underestimation lower bound, since every inconsistent subset increaseslower bound one independently number clauses unsatisfied optimalassignment. However, optimal assignment violate one clause inconsistent subset. Therefore, able improve lower bound based countingnumber disjoint inconsistent subsets clauses.hand, despite fact good quality lower bounds prune large partssearch space accelerate dramatically search optimal solution, wheneverlower bound reach best solution found far (upper bound), solvercontinues exploring search space current node. search, solversoften redetect inconsistencies computing lower bound different nodes.Basically, problem lower bound computation methods simplifyCNF formula way unsatisfied clauses become explicit. Lower boundspruning technique.overcome two problems, define set sound inference rulestransform Max-SAT instance Max-SAT instance easier solve.Max-SAT, inference rule sound whenever equivalent.Let us see example inference rule: Given Max-SAT instance containsthree clauses form l1 , l2 , l1 l2 , l1 , l2 literals, replace CNF322fiNew Inference Rules Max-SATformula= ( {l1 , l2 , l1 l2 }) {2, l1 l2 }.Note rule detects contradiction l1 , l2 , l1 l2 and, therefore, replacesclauses empty clause. addition, rule adds clause l1 l2 ensureequivalence . assignment containing either l1 = 0, l2 = 1,l1 = 1, l2 = 0, l1 = 1, l2 = 1, number unsatisfied clauses {l1 , l2 , l1 l2 } 1,assignment containing l1 = 0, l2 = 0, number unsatisfied clauses 2.Note even assignment containing l1 = 0, l2 = 0 best assignmentsubset {l1 , l2 , l1 l2 }, best whole formula. adding l1 l2 ,rule ensures number unsatisfied clauses alsol1 = 0, l2 = 0.inference rule adds new clause l1 l2 , may contribute another contradiction detectable via unit propagation. case, rule allows increaselower bound 2 instead 1. Moreover, rule makes explicit contradiction amongl1 , l2 , l1 l2 , contradiction need redetected currentnode.inference rules defined paper already known literature (Bansal & Raman, 1999; Niedermeier & Rossmanith, 2000), others originalMax-SAT. new rules inspired different unit resolution refinements appliedSAT, selected could applied natural efficient way.sense, summarize work telling defined Max-SAT counterpartSAT unit propagation.aim finding powerful inference rules practice,designed implemented new Max-SAT solver, called MaxSatz, incorporatesrules, well lower bound defined previous work (Li et al., 2005), performedexperimental investigation. results provide empirical evidence MaxSatzcompetitive, least, random Max-2SAT, random Max-3SAT, Max-Cut, Graph3-coloring instances, well benchmarks Max-SAT Evaluation 20061 .structure paper follows. Section 2, give preliminary definitions. Section 3, describe basic branch bound Max-SAT solver. Section 4,define inference rules prove soundness novel simple way via integerprogramming transformation. also give examples illustrate inference rulesmay produce better quality lower bounds. Section 5, present implementationinference rules MaxSatz. Section 6, describe main features MaxSatz.Section 7, report experimental investigation. Section 8, present relatedwork. Section 9, present conclusions future work.2. Preliminariespropositional logic variable xi may take values 0 (for false) 1 (for true). literal livariable xi negation xi . clause disjunction literals, CNF formulaconjunction clauses. length clause number literals. size, denoted ||, sum length clauses.1. http://www.iiia.csic.es/maxsat06323fiLi, Manya & Planesassignment truth values propositional variables satisfies literal xi xitakes value 1 satisfies literal xi xi takes value 0, satisfies clausesatisfies least one literal clause, satisfies CNF formula satisfiesclauses formula. empty clause, denoted 2, contains literals cannotsatisfied. assignment CNF formula complete variables occurringassigned; otherwise, partial.Max-SAT problem CNF formula problem finding assignmentvalues propositional variables minimizes number unsatisfied clauses (orequivalently, maximizes number satisfied clauses). Max-SAT called MaxkSAT clauses k literals per clause. following, represent CNFformula multiset clauses, since duplicated clauses allowed Max-SAT instance.CNF formulas 1 2 equivalent 1 2 number unsatisfiedclauses every complete assignment 1 2 .3. Basic Max-SAT Solverspace possible assignments CNF formula represented searchtree, internal nodes represent partial assignments leaf nodes represent completeassignments. basic branch bound algorithm Max-SAT explores search treedepth-first manner. every node, algorithm compares number clauses unsatisfied best complete assignment found far called upper bound (U B)number clauses unsatisfied current partial assignment (#emptyClauses) plusunderestimation minimum number non-empty clauses become unsatisfiedextend current partial assignment complete assignment (underestimation).sum #emptyClauses + underestimation lower bound (LB) minimumnumber clauses unsatisfied complete assignment extended current partialassignment. Obviously, LB U B, better solution cannot found pointsearch. case, algorithm prunes subtree current node backtrackshigher level search tree.LB < U B, algorithm tries find possible better solution extendingcurrent partial assignment instantiating one variable; leads creationtwo branches current branch: left branch corresponds assigning newvariable false, right branch corresponds assigning new variable true.case, formula associated left (right) branch obtained formulacurrent node deleting clauses containing literal x (x) removingoccurrences literal x (x); i.e., algorithm applies one-literal rule.solution Max-SAT value U B takes exploring entire searchtree.Figure 1 shows pseudo-code basic solver Max-SAT. use followingnotations:simplifyFormula() procedure simplifies applying sound inference rules.#emptyClauses() function returns number empty clauses .324fiNew Inference Rules Max-SATInput: max-sat(, U B) : CNF formula upper bound U B1: simplifyFormula();2: = contains empty clauses3:return #emptyClauses();4: end5: LB #emptyClauses() + underestimation(, U B);6: LB U B7:return U B;8: end9: x selectVariable();10: U B min(U B, max-sat(x , U B));11: return min(U B, max-sat(x , U B));Output: minimal number unsatisfied clausesFigure 1: basic branch bound algorithm Max-SATLB lower bound minimum number unsatisfied clauses currentpartial assignment extended complete assignment. assume initialvalue 0.underestimation(, U B) function returns underestimation minimumnumber non-empty clauses become unsatisfied current partialassignment extended complete assignment.U B upper bound number unsatisfied clauses optimal solution.assume initial value total number clauses input formula.selectVariable() function returns variable following heuristic.x (x ) formula obtained applying one-literal rule using literalx (x).State-of-the-art Max-SAT solvers implement basic algorithm augmented powerful inference techniques, good quality lower bounds, clever variable selection heuristics,efficient data structures.recently defined (Li et al., 2005) lower bound computation methodunderestimation lower bound number disjoint inconsistent subsetsdetected using unit propagation. pseudo-code shown Figure 2.Example 1 Let following CNF formula:{x1 , x2 , x3 , x4 , x1 x2 x3 , x4 , x5 , x5 x2 , x5 x2 }.approach able establish number disjoint inconsistentsubsets clauses least 3. Therefore, underestimation lower bound 3.steps performed following ones:325fiLi, Manya & PlanesInput: underestimation(, U B) : CNF formula upper bound U B1: underestimation 0;2: apply one-literal rule unit clauses (unit propagation) emptyclause derived;3: empty clause derived4:return underestimation;5: end6: without clauses used derive empty clause;7: underestimation := underestimation + 1;8: underestimation+#emptyClauses() U B9:return underestimation;10: end11: go 2;Output: underestimation lower boundFigure 2: Computation underestimation using unit propagation1. = {x4 , x4 , x5 , x5 x2 , x5 x2 }, first inconsistent subset detected using unitpropagation {x1 , x2 , x3 , x1 x2 x3 }, underestimation = 1.2. = {x5 , x5 x2 , x5 x2 }, second inconsistent subset detected using unit propagation{x4 , x4 }, underestimation = 2.3. = , third inconsistent subset detected using unit propagation {x5 , x5 x2 , x5x2 }, underestimation = 3. Since empty, algorithm stops.4. Inference Rulesdefine set inference rules considered paper. inspired differentunit resolution refinements applied SAT, selected could appliednatural efficient way. already known literature (Bansal &Raman, 1999; Niedermeier & Rossmanith, 2000), others original Max-SAT.presenting rules, define integer programming transformation CNFformula used establish soundness rules. method proving soundnessnovel Max-SAT, provides clear short proofs.4.1 Integer Programming Transformation CNF FormulaAssume = {c1 , ..., cm } CNF formula clauses variables x1 , ..., xn .Let ci (1 m) xi1 ... xik xik+1 ... xik+r . Note put positive literalsci negative ones.consider variables ci integer variables taking values 0 1, defineinteger transformation ciEi (xi1 , ..., xik , xik+1 , ..., xik+r ) = (1 xi1 )...(1 xik )xik+1 ...xik+r326fiNew Inference Rules Max-SATObviously, Ei value 0 iff least one variables xij (1 j k) instantiated1 least one variables xis (k + 1 k + r) instantiated 0.words, Ei =0 iff ci satisfied. Otherwise Ei =1.literal l corresponds integer denoted l convenience. intentioncorrespondence literal l satisfied integer l 1 unsatisfiedinteger l 0. l positive literal x, corresponding integer l x, l 1-x=1-l,l negative literal x, l 1-x l x=1-(1-x)=1-l. Consequently, l=1-lcase.generically write ci l1 l2 ... lk+r . integer programming transformationEi = (1 l1 )(1 l2 )...(1 lk+r ).integer programming transformation CNF formula = {c1 , ..., cm }variables x1 , ..., xn definedE(x1 , ..., xn ) =XEi(1)i=1integer programming transformation used (Huang & Jin, 1997; Li & Huang,2005) design local search procedure, called pseudo-Boolean formulation BorosHammer (2002). Here, extend empty clauses: ci empty, Ei =1.Given assignment variables x1 , ..., xn , value E numberunsatisfied clauses . satisfies clauses , E = 0. Obviously, minimumnumber unsatisfied clauses minimum value E.Let 1 2 two CNF formulas, let E1 E2 integer programmingtransformations. clear 1 2 equivalent if, if, E1 =E2 everycomplete assignment 1 2 .4.2 Inference Rulesnext define inference rules prove soundness using previous integerprogramming transformation. rest section, 1 , 2 denote CNF formulas,E1 , E2 , E integer programming transformations. prove 1 2equivalent, prove E1 = E2 .Rule 1 (Bansal & Raman, 1999) 1 ={l1 l2 ... lk , l1 l2 ... lk } ,2 ={l2 ... lk } equivalent 1 .Proof 1E1 = (1 l1 )(1 l2 )...(1 lk ) + l1 (1 l2 )...(1 lk ) + E= (1 l2 )...(1 lk ) + E= E2General case resolution work Max-SAT (Bansal & Raman, 1999). Rule 1establishes resolution works two clauses give strictly shorter resolvent.327fiLi, Manya & PlanesRule 1 known literature replacement almost common clauses. payspecial attention case k=2, resolvent unit clause, case k=1,resolvent empty clause. describe latter case following rule:Rule 2 (Niedermeier & Rossmanith, 2000) 1 ={l, l} , 2 ={2} equivalent1 .Proof 2 E1 =1-l+ l+E =1+ E =E2Rule 2, known complementary unit clause rule, used replace twocomplementary unit clauses empty clause. new empty clause contributeslower bounds search space current node incrementing numberunsatisfied clauses, incrementing underestimation, meanscontradiction redetected again. practice, simple rule gives riseconsiderable gains.following rule complicated case:Rule 3 1 ={l1 , l1 l2 , l2 } , 2 ={2, l1 l2 } equivalent 1 .Proof 3E1 = 1 l1 + l1 l2 + 1 l2 + E= 1 + 1 l1 + l2 (l1 1) + E= 1 + 1 l1 l2 (1 l1 ) + E= 1 + (1 l1 )(1 l2 ) + E= E2Rule 3 replaces three clauses empty clause, adds new binary clausekeep equivalence 1 2 .Pattern 1 considered compute underestimations Alsinet et al. (2004) ShenZhang (2004); also captured method computing underestimations basedunit propagation (Li et al., 2005). Larrosa Heras mentioned (2005) existentialdirectional arc consistency (de Givry, Zytnicki, Heras, & Larrosa, 2005) capturerule. Note underestimation computation methods Alsinet et al. ShenZhang add additional clause approach, detect contradictions.Let us define rule generalizes Rule 2 Rule 3. presenting rule,define lemma needed prove soundness.Lemma 1 1 ={l1 , l1 l2 } 2 ={l2 , l2 l1 } , 1 2 equivalent.Proof 4E1 = 1 l1 + l1 (1 l2 ) + E= 1 l1 + l1 l1 l2 + E= 1 l2 + l2 l1 l2 + E= 1 l2 + (1 l1 )l2 + E= E2328fiNew Inference Rules Max-SATRule 4 1 ={l1 , l1 l2 , l2 l3 , ..., lk lk+1 , lk+1 } , 2 ={2, l1 l2 , l2 l3 , ..., lklk+1 } equivalent 1 .Proof 5 prove soundness rule induction k. k=1, 1 = {l1 , l1l2 , l2 } . applying Rule 3, get {2, l1 l2 } , 2 k = 1. Therefore,1 2 equivalent.Assume Rule 4 sound k = n. Let us prove sound k = n + 1.case:1 = {l1 , l1 l2 , l2 l3 , ..., ln ln+1 , ln+1 ln+2 , ln+2 } .applying Lemma 1 last two clauses 1 (before ), get{l1 , l1 l2 , l2 l3 , ..., ln ln+1 , ln+1 , ln+1 ln+2 } .applying induction hypothesis first n + 1 clauses previous CNF formula,get{2, l1 l2 , l2 l3 , ..., ln ln+1 , ln+1 ln+2 } ,2 k = n + 1. Therefore, 1 2 equivalent rule sound.Rule 4 original inference rule. captures linear unit resolution refutationsclauses resolvents used exactly once. rule simply adds empty clause,eliminates two unit clauses binary clauses used refutation, adds newbinary clauses obtained negating literals eliminated binary clauses.So, operations involved performed efficiently.Rule 3 Rule 4 make explicit contradiction, need redetectedcurrent subtree. So, lower bound computation becomes incremental. Moreover,binary clauses added Rule 3 Rule 4 may contribute compute better qualitylower bounds either acting premises inference rule partinconsistent subset clauses, illustrated following example.Example 2 Let ={x1 , x1 x2 , x3 , x3 x2 , x4 , x1 x4 , x3 x4 }. Depending orderingunit clauses propagated, unit propagation detects one following threeinconsistent subsets clauses: {x1 , x1 x2 , x3 , x3 x2 }, {x1 , x4 , x1 x4 }, {x3 , x4 , x3x4 }. inconsistent subset detected removed, remaining set clausessatisfiable. Without applying Rule 3 Rule 4, lower bound computed 1,underestimation computed using unit propagation 1.Note Rule 4 applied first inconsistent subset {x1 , x1 x2 , x3 , x3 x2 }.Rule 4 applied, contradiction made explicit clauses x1 x2 x3 x2added. So, becomes {2, x1 x2 , x3 x2 , x4 , x1 x4 , x3 x4 }. turns {2}inconsistent set clauses detectable unit propagation. Therefore, lower boundcomputed 2.inconsistent subset {x1 , x4 , x1 x4 } detected, Rule 3 applied. Then,contradiction made explicit clause x1 x4 added. So, becomes {2, x1 x4 , x1x2 , x3 , x3 x2 , x3 x4 }. turns {2} inconsistent set clauses detectableunit propagation. Therefore, lower bound computed 2.329fiLi, Manya & PlanesSimilarly, inconsistent subset {x3 , x4 , x3 x4 } detected Rule 3 applied,lower bound computed 2.observe that, example, Rule 3 Rule 4 make explicit contradiction, also allow improve lower bound.Unit propagation needs least one unit clause detect contradiction. drawbackRule 3 Rule 4 consume two unit clauses deriving one contradiction. possible situation that, branching, two unit clauses could allowunit propagation derive two disjoint inconsistent subsets clauses, showfollowing example.Example 3 Let ={x1 , x1 x2 , x1 x3 , x2 x3 x4 , x5 , x5 x6 , x5 x7 , x6 x7 x4 , x1 x5 }.Rule 3 replaces x1 , x5 , x1 x5 empty clause x1 x5 . that, x4selected next branching variable assigned 0, unit clausecontradiction detected via unit propagation. lower bound 1situation. However, Rule 3 applied branching, two unit clausesbranching. case, propagation x1 allows detect inconsistent subset{x1 , x1 x2 , x1 x3 , x2 x3 }, propagation x5 allows detect inconsistentsubset {x5 , x5 x6 , x5 x7 , x6 x7 }. So, lower bound computed branching 2.one hand, Rule 3 Rule 4 add clauses contribute detect additionalconflicts. hand, application Rule 3 Rule 4 consumes two unitclauses, cannot used detect conflicts. final effect twofactors empirically analyzed Section 7.Finally, present two new rules capture unit resolution refutations(i) exactly one unit clause consumed, (ii) unit clause used twice linearderivation empty clause.Rule 5 1 ={l1 , l1 l2 , l1 l3 , l2 l3 } , 2 ={2, l1 l2 l3 , l1 l2 l3 }equivalent 1 .Proof 6E1 = 1 l1 + l1 (1 l2 ) + l1 (1 l3 ) + l2 l3 + E= 1 l1 + l1 l1 l2 + l1 l1 l3 + l2 l3 + E= 1 + l2 l3 l1 l2 l3 + l1 l1 l2 l1 l3 + l1 l2 l3 + E= 1 + (1 l1 )l2 l3 + l1 (1 l2 l3 + l2 l3 ) + E= 1 + (1 l1 )l2 l3 + l1 (1 l2 )(1 l3 ) + E= E2combine linear derivation Rule 5 obtain Rule 6:Rule 6 1 ={l1 , l1 l2 , l2 l3 , ..., lk lk+1 , lk+1 lk+2 , lk+1 lk+3 , lk+2 lk+3 } ,2 ={2, l1 l2 , l2 l3 , ..., lk lk+1 , lk+1 lk+2 lk+3 , lk+1 lk+2 lk+3 }equivalent 1 .330fiNew Inference Rules Max-SATProof 7 prove soundness rule induction k. k=1,1 = {l1 , l1 l2 , l2 l3 , l2 l4 , l3 l4 } .Lemma 1, getRule 5, get{l1 l2 , l2 , l2 l3 , l2 l4 , l3 l4 } .{l1 l2 , 2, l2 l3 l4 , l2 l3 l4 } ,2 k = 1. Therefore, 1 2 equivalent.Assume Rule 6 sound k = n. Let us prove sound k = n + 1.case:1 = {l1 , l1 l2 , l2 l3 , ..., ln+1 ln+2 , ln+2 ln+3 , ln+2 ln+4 , ln+3 ln+4 } .Lemma 1, get{l1 l2 , l2 , l2 l3 , ..., ln+1 ln+2 , ln+2 ln+3 , ln+2 ln+4 , ln+3 ln+4 } .applying induction hypothesis, get{l1 l2 , 2, l2 l3 , ..., ln+1 ln+2 , ln+2 ln+3 ln+4 , ln+2 ln+3 ln+4 } ,2 k = n + 1. Therefore, 1 2 equivalent rule sound.Similarly Rule 3 Rule 4, Rule 5 Rule 6 make explicit contradiction,need redetected subsequent search. Therefore, lower bound computation becomes incremental. Moreover, also add clauses improvequality lower bound, illustrated following example.Example 4 Let ={x1 , x1 x2 , x1 x3 , x2 x3 , x4 , x1 x4 , x2 x4 , x3 x4 }. Dependingordering unit clauses propagated, unit propagation detect onefollowing inconsistent subsets: {x1 , x1 x2 , x1 x3 , x2 x3 }, {x4 , x1 x4 , x2 x4 , x1 x2 },{x4 , x1 x4 , x3 x4 , x1 x3 }, Rule 5 applicable. Rule 5 applied, lowerbound computed using underestimation function Figure 2 1, since remainingclauses satisfiable inconsistent subset clauses removed. Rule 5 allowsadd two ternary clauses contributing another contradiction. example, Rule 5applied {x1 , x1 x2 , x1 x3 , x2 x3 } adds clauses x1 x2 x3 x1 x2 x3 ,which, remaining clauses ({x4 , x1 x4 , x2 x4 , x3 x4 }), give secondcontradiction detectable via unit propagation. lower bound computed using Rule 52.contrast Rule 3 Rule 4, Rule 5 Rule 6 consume exactly one unit clausederiving empty clause. Since unit clause used derive conflictvia unit propagation, Rule 5 Rule 6 limit detection conflicts viaunit propagation.331fiLi, Manya & Planes5. Implementation Inference Rulessection, describe implementation inference rules presented Section 4. suppose CNF formula loaded and, every literal , list clausescontaining constructed. application rule means clauses 1removed CNF formula, new clauses 2 inserted formula,lower bound increased 1. Note inference rules selected approach,2 contains fewer literals fewer clauses 1 , new clauses 2 insertedplace removed clauses 1 inference rule applied. Therefore,need dynamic memory management implementation faster.Rule 1 k=2 Rule 2 applied using matching algorithm (see, e.g., Cormen,Leiserson, Rivest, & Stein, 2001, efficient implementation) lists clauses.first time complexity O(m), number clauses CNFformula. second time complexity O(u), u number unit clausesCNF formula. rules applied every node, lower bound computation application inference rules. Rule 1 (k=2) applied many timespossible derive unit clauses applying Rule 2.implementation Rule 3, Rule 4, Rule 5, Rule 6 entirely based unitpropagation. Given CNF formula , unit propagation constructs implication graphG (see, e.g., Beame, Kautz, & Sabharwal, 2003), applicability inferencerules detected. section, first describe construction implication graph,describe determine applicability Rule 3, Rule 4, Rule 5, Rule 6.Then, analyze complexity, termination (in)completeness applicationrules. Finally discuss extension inference rules weighted Max-SATimplementation.5.1 Implication GraphGiven CNF formula , Figure 3 shows unit propagation constructs implicationgraph whose nodes literals.Note every node G corresponds different literal, considereddifferent literals. CNF formula contains several copies unit clause ,algorithm adds one node label .Example 5 Let ={x1 , x1 , x1 x2 , x1 x3 , x2 x3 x4 , x5 , x5 x6 , x5 x7 , x6 x7 x4 , x5 x8 }.U nitP ropagation constructs implication graph Figure 4, add specialnode 2 highlight contradiction.G always acyclic every added edge connects new node. well knowntime complexity unit propagation O(||), || size (see, e.g.,Freeman, 1995).associate clause c=1 2 ...k1 k node k node k added Gc. Note node k incoming edge c unit (k=1),node one incoming edge c binary (k=2). G constructed,G contains literal (i.e., unit propagation deduces contradiction),easy identify nodes exists path G; i.e., clauses332fiNew Inference Rules Max-SATInput: U nitP ropagation() : CNF formula containing complementary unitclauses literalinitialize G empty graphadd node labeled every literal unit clause crepeat1 , 2 , ..., k1 nodes G, c = 1 2 ... k1 k clause , knode G,add G node labeled kadd G directed edge node k every (1 < k)endnodes added literal nodesGReturn GOutput: Implication graph GFigure 3: Unit propagation constructing implication graphsx2x4x1x3x6x5x4x7x8Figure 4: Example implication graph333fiLi, Manya & Planesx1c1x5c5x2c2x6c6x3c3x4c7x4c4Figure 5: Example implication graphimplying . clauses constitute inconsistent subset .example, clauses x1 , x1 x2 , x1 x3 x2 x3 x4 imply x4 , clauses x5 , x5 x6 , x5 x7x6 x7 x4 imply x4 . Clause x5 x8 contribute contradiction.inconsistent subset {x1 , x1 x2 , x1 x3 , x2 x3 x4 , x5 , x5 x6 , x5 x7 , x6 x7 x4 }.5.2 Applicability Rule 3, Rule 4, Rule 5, Rule 6assume unit propagation deduces contradiction and, therefore, implicationgraph G contains literal . Let set nodesexists path , let set nodes exists path, let S=S . clause associated node G, also use S, ,denote set clauses associated nodes S, , , respectively.Lemma 2 Lemma 3 used detect applicability Rule 3, Rule 4, Rule 5,Rule 6.Lemma 2 Rule 3 Rule 4 applicable1. (resp. ), one unit clause clauses binary,2. nodes (resp. ) form implication chain starting unit clause ending(resp. ),3. empty.Proof 8 Starting node corresponding unit clause (resp. ),following parallel two implication chains, 1 Rule 3 Rule 4 writingclause corresponding node.Example 6 Let following CNF formula containing clauses c1 c7 : {c1 : x1 , c2 :x1 x2 , c3 : x2 x3 , c4 : x3 x4 , c5 : x5 , c6 : x5 x6 , c7 : x6 x4 }. Unit propagation constructs implication graph shown Figure 5, contains complementaryliterals x4 x4 .Rule 4 applicable =x4 , ={x1 (c1 ), x2 (c2 ), x3 (c3 ), x4 (c4 )},={x5 (c5 ), x6 (c6 ), x4 (c7 )}. easy verify three conditions Lemma 2satisfied.Remark: rewritten {c1 : x1 , c2 : x1 x2 , c3 : x2 x3 , c4 : x3 x4 , c7 :x4 x6 , c6 : x6 x5 , c5 : x5 } compared 1 Rule 4.334fiNew Inference Rules Max-SATx1c1x2c2x3c3x4c4x4c5Figure 6: Example implication graphapplication Rule 3 Rule 4 consists replacing every binary clause cbinary clause obtained negating every literal c, removing two unit clauses, incrementing #emptyClauses() 1.Lemma 3 Rule 5 Rule 6 applicable1. S=S , one unit clause clauses binary; i.e.,nodes S, except node corresponding unit clause, exactly oneincoming edge G.2. non-empty contains k (k >0) nodes forming implication chainform 1 2 k , k last node chain.3. (S )-(S ) contains exactly three nodes : , , third one. Let k+1third literal,k+1 , G contains following implicationsk k+1kk+1 , G contains following implicationskk k+1Proof 9 Assume, without loss generality, k+1 ; case k+1 symmetric. implication chain formed nodes corresponds clauses {1 ,1 2 , . . . , k1 k }, which, together three clauses {k k+1 , k+1 , k }corresponding k k+1 k , give 1 Rule 5 Rule 6.Example 7 Let following CNF formula containing clauses c1 c5 : {c1 : x1 , c2 :x1 x2 , c3 : x2 x3 , c4 : x2 x4 , c5 : x3 x4 }. Unit propagation constructs implicationgraph shown Figure 6, contains complementary literals x4 x4 .Sx4 ={x1 (c1 ), x2 (c2 ), x4 (c4 )} Sx4 ={x1 (c1 ), x2 (c2 ), x3 (c3 ), x4 (c5 )}.nodes Sx4 Sx4 obviously form implication chain: x1 x2 . (Sx4 Sx4 )-(Sx4Sx4 )={x3 (c3 ), x4 (c4 ), x4 (c5 )}. G contains x2 x3 x4 x2 x4 . Rule 6 applicable.application Rule 5 Rule 6 consists removing unit clause, replacing binary clause c binary clause obtained cnegating two literals c, replacing three binary clauses (S )-(S )two ternary clauses, incrementing #emptyClauses() 1.335fiLi, Manya & Planes5.3 Complexity, Termination, (In)Completeness Rule Applicationsbranch bound algorithm Max-SAT, combine application inference rules computation underestimation lower bound. Given CNFformula , function underestimation uses unit propagation construct implicationgraph G. G contains two nodes literal , G analyzed determinewhether inference rule applicable. rule applicable, appliedtransformed equivalent Max-SAT instance. Otherwise, clauses contributingcontradiction removed , underestimation incremented 1.procedure repeated unit propagation cannot derive contradictions. Finally,removed clauses, except removed replaced due inference rule applications,reinserted . underestimation, together new , returned.well known unit propagation implemented time complexity linearsize (see, e.g., Freeman, 1995). complexity determining applicabilityinference rules using Lemma 2 Lemma 3 linear size G, boundednumber literals , assume graph represented doubly-linkedlists. application inference rule obviously linear size G. So, wholetime complexity function underestimation inference rule applications O(d ||),number contradictions function underestimation able detectusing unit propagation. Observe factor needed applicationrules inserts new clauses place removed clauses.Since every inference rule application reduces size , function underestimationinference rule applications linear space complexity, always terminates. Recallnew clauses added inference rules stored place old ones.data structures loading statically efficiently maintained.proved inference rules sound. following example showsapplication rules necessarily complete implementation, sensepossible applications inference rules necessarily done.Example 8 Let ={x1 , x3 , x4 , x1 x3 x4 , x1 x2 , x2 }. Unit propagation may discoverinconsistent subset S={x1 , x3 , x4 , x1 x3 x4 }. case, inference rule applicable S. Then, underestimation lower bound incremented 1,becomes {x1 x2 , x2 }. Unit propagation cannot detect contradictions , function underestimation stops reinserting {x1 , x3 , x4 , x1 x3 x4 } . value1 returned, together unchanged . Note Rule 3 applicable subset{x1 , x1 x2 , x2 } , applied.Actually, function underestimation applies Rule 3 unit propagation detectsinconsistent subset {x1 , x1 x2 , x2 } instead {x1 , x3 , x4 , x1 x3 x4 }. detectioninconsistent subset depends ordering unit clauses propagated unitpropagation. example, inconsistent subset {x1 , x1 x2 , x2 } discovered unitclause x2 propagated x3 x4 . study needed define orderingsunit clauses maximize application inference rules.Observe algorithm deterministic, always computes lower boundorder clauses changed.336fiNew Inference Rules Max-SAT5.4 Inference Rules Weighted Max-SATinference rules presented paper naturally extended weighted Max-SAT.weighted Max-SAT, every clause associated weight problem consistsfinding truth assignment sum weights unsatisfied clausesminimum. example, weighted version Rule 3 couldRule 7 1 ={(l1 , w1 ), (l1 l2 , w2 ), (l2 , w3 )} , 2 ={(2, w), (l1 l2 , w), (l1 , w1w), (l1 l2 , w2 w), (l2 , w3 w)} equivalent 1w1 , w2 w3 positive integers representing clause weight, w=min(w1 ,w2 , w3 ). Mandatory clauses, satisfied optimal solution, specifiedweight . Note w6=, -w= w=, optimal solutionfound solver backtrack. Clauses weight 0 removed. Observe 1rewritten 11 12 , 11 ={(l1 , w), (l1 l2 , w), (l2 , w)}, 12 ={(l1 , w1w), (l1 l2 , w2 w), (l2 , w3 w)} . Then, weighted inference rule equivalentunweighted version applied w times (unweighted) clauses 11 .Similarly, weighted version Rule 4 couldRule 8 1 ={(l1 , w1 ) (l1 l2 , w2 ), (l2 l3 , w3 ), . . . , (lk lk+1 , wk+1 ), (lk+1 , wk+2 )} ,2 ={(2, w), (l1 l2 , w), (l2 l3 , w), . . . , (lk lk+1 , w), (l1 , w1 w), (l1 l2 , w2w), (l2 l3 , w3 w), . . . , (lk lk+1 , wk+1 w), (lk+1 , wk+2 w)} equivalent 1w=min(w1 , w2 , . . . , wk+2 ). Observe 1 also rewritten 11 12 ,11 ={(l1 , w) (l1 l2 , w), (l2 l3 , w), . . . , (lk lk+1 , w), (lk+1 , w)}, weighted versionRule 4 equivalent unweighted Rule 4 applied w times (unweighted) clauses11 .current implementation inference rules naturally extended weightedinference rules. inconsistent subformula detected rule applicable (clauseweights considered detection inconsistent subformula applicability rule, provided clauses weight 0 discarded), 1112 separated computing minimal weight w clauses detectedinconsistent subformula, rule applied 11 . derived clauses clauses12 used subsequent reasoning.6. MaxSatz: New Max-SAT Solverimplemented new Max-SAT solver, called MaxSatz, incorporates lowerbound computation method based unit propagation defined Section 3, appliesinference rules defined Section 4. name MaxSatz comes factimplementation algorithm incorporates technology developedSAT solver Satz (Li & Anbulagan, 1997b, 1997a).MaxSatz incorporates lower bound based unit propagation, applies Rule 1,Rule 2, Rule 3, Rule 4, Rule 5, Rule 6. addition, MaxSatz applies followingtechniques:Pure literal rule: literal appears either positive polarity negativepolarity, delete clauses containing literal.337fiLi, Manya & PlanesEmpty-Unit clause rule (Alsinet et al., 2003a): Let neg1(x) (pos1(x)) numberunit clauses x negative (positive). #emptyClauses() + neg1(x) U B,assign x false. #emptyClauses() + pos1(x) U B, assign xtrue.Dominating Unit Clause (DUC) rule (Niedermeier & Rossmanith, 2000): number clauses literal x (x) appears greater neg1(x) (pos1(x)),assign x false (true).Variable selection heuristic: Let neg2(x) (pos2(x)) number binary clausesx negative (positive), let neg3(x) (pos3(x)) number clausescontaining three literals x negative (positive). selectvariable x (neg1(x)+4neg2(x)+neg3(x))*(pos1(x)+4pos2(x)+pos3(x))largest. fact binary clauses counted four timesclauses determined empirically.Value selection heuristic: Let x selected branching variable. neg1(x) + 4neg2(x) + neg3(x) < pos1(x) + 4 pos2(x) + pos3(x), set x true. Otherwise set xfalse. heuristics also determined empirically.paper, order compare inference rules defined, used three simplified versions MaxSatz:MaxSat0: apply inference rule defined Section 4.MaxSat12: applies rules 1 2, rules 3, 4, 5 6.MaxSat1234: applies rules 1, 2, 3 4, rules 5 6.Actually, MaxSatz corresponds MaxSat123456 terminology. MaxSat12 corresponds improved version solver U P (Li et al., 2005), using special orderingpropagating unit clauses unit propagation. MaxSat12 maintains two queuesunit propagation: Q1 Q2 . MaxSat12 starts search inconsistent subformula via unit propagation, Q1 contains unit clauses CNF formulaconsideration (more recently derived unit clauses end Q1 ), Q2 empty.unit clauses derived application unit propagation stored Q2 ,unit propagation use unit clause Q1 unless Q2 empty. Intuitively,ordering prefers unit clauses non-unit clauses starting applicationunit propagation. way, derived inconsistent subset contains, general, less unitclauses. unit clauses consumed contribute detectinconsistent subsets. experimental results (Li, Manya, & Planes, 2006) showsearch tree size MaxSat12 substantially smaller UP, MaxSat12substantially faster UP. MaxSat0, Maxsat1234, MaxSatz use orderingMaxSat12 propagating unit clauses unit propagation.source code MaxSat0, MaxSat12, MaxSat1234, MaxSatz foundhttp://web.udl.es/usuaris/m4372594/jair-maxsatz-solvers.zip, http://www.laria.upicardie.fr/cli/maxsatz.tar.gz.338fiNew Inference Rules Max-SAT7. Experimental Resultsreport experimental investigation performed unweighted Max-SAT orderevaluate inference rules defined Section 4, compare MaxSatzbest performing state-of-the-art solvers publicly available papersubmitted. experiments performed Linux Cluster processors 2 GHzAMD Opteron 1 Gb RAM.structure section follows. first describe solvers benchmarksconsidered. Then, present experimental evaluation inferencerules. Finally, show experimental comparison MaxSatz solvers.7.1 Solvers BenchmarksMaxSatz compared following Max-SAT solvers:BF2 (Borchers & Furman, 1999): branch bound Max-SAT solver usesMOMS dynamic variable selection heuristic consider underestimationscomputation lower bound. developed Borchers Furman1999.AGN3 (Alber et al., 2001): branch bound Max-2SAT solver. developedAlber, Gramm Niedermeier 1998.AMP4 (Alsinet et al., 2003b): branch bound Max-SAT solver based BFincorporates lower bound better quality Jeroslow-Wang variable selectionheuristic (Jeroslow & Wang, 1990). developed Alsinet, Manya Planespresented SAT-2003.toolbar5 (de Givry et al., 2003; Larrosa & Heras, 2005): Max-SAT solver whoseinference inspired soft arc consistency properties implemented weighted CSPsolvers. developed de Givry, Larrosa, Meseguer Schiex firstpresented CP-2003. used version 2.2 default parameters.MaxSolver6 (Xing & Zhang, 2004): branch bound Max-SAT solver appliesnumber efficient inference rules. developed Xing Zhang presentedCP-2004. used second release solver.Lazy7 (Alsinet et al., 2005): branch bound Max-SAT solver lazy datastructures static variable selection heuristic. developed Alsinet, ManyaPlanes presented SAT-2005.2.3.4.5.6.7.Downloaded October 2004 http://infohost.nmt.edu/borchers/satcodes.tar.gzDownloaded October 2005 http://www-fs.informatik.uni-tuebingen.de/gramm/Available http://web.udl.es/usuaris/m4372594/software.htmlDownloaded October 2005 http://carlit.toulouse.inra.fr/cgi-bin/awki.cgi/ToolBarIntroDownloaded October 2005 http://cic.cs.wustl.edu/maxsolver/Available http://web.udl.es/usuaris/m4372594/software.html339fiLi, Manya & PlanesUP8 (Li et al., 2005): branch bound Max-SAT solver lower boundcomputation method based unit propagation (cf. Section 3). developedLi, Manya Planes presented CP-2005.used benchmarks randomly generated Max-2SAT instances Max-3SAT instances, graph 3-coloring instances9 , well Max-Cut instances10 . also consideredunweighted Max-SAT benchmarks submitted Max-SAT Evaluation 2006, includingMax-Cut, Max-Ones, Ramsey numbers, random Max-2SAT Max-3SAT instances.generated Max-2SAT instances Max-3SAT instances using generator mwff.cdeveloped Bart Selman, allows duplicated clauses. Max-Cut, firstgenerated random graph edges every edge randomly selected amongset possible edges. graph connected, discarded. graphconnected, used encoding Shen Zhang (2005) encode Max-Cutinstance CNF: created, edge (xi , xj ), exactly two binary clauses (xi xj )(xi xj ). collection binary clauses, Max-Cut instancecut weight k iff Max-SAT instance assignment + k clausessatisfied.graph 3-coloring, first used Culbersons generator generate random kcolorable graph type IID (independent random edge assignment, variability=0)k vertices fixed edge density. used Culbersons converter SAT standard conversion three colors generate Max-SAT instance: vertex xicolor j {1, 2, 3}, propositional variable xij defined meaning vertexcolored color j. vertex xi , four clauses added encode vertexcolored exactly one color: xi1 xi2 xi3 , xi1 xi2 , xi1 xi3 , xi2 xi3 ; and,edge (xi , xj ), three clauses added encode vertex xi vertex xjcolor: xi1 xj1 , xi2 xj2 , xi3 xj3 .random Max-2SAT Max-3SAT instances, clauses entirely independentstructure. graph 3-coloring instances Max-Cut instancesused paper, clauses independent structure. example,Max-Cut instance, every time clause xi xj , also clause xi xj ;satisfaction two clauses means corresponding edge cut.graph 3-coloring instance, every time ternary clause xi1 xi2 xi3 encodingvertex colored least color, also three binary clauses xi1 xi2 , xi1 xi3 ,xi2 xi3 encoding vertex cannot colored two colors. MaxCut instances contain binary clauses, graph 3-coloring instances contain ternaryclause every vertex graph. derive optimal cut optimalassignment Max-SAT encoding Max-Cut instance, optimal assignmentMax-SAT encoding 3-coloring instance may assign one color vertices.8. Available http://web.udl.es/usuaris/m4372594/software.html9. Given undirected graph G = (V, E), V = {x1 , . . . , xn } set vertices E setedges, set three colors, graph 3-coloring problem problem coloring every vertexone three colors way that, edge (xi , xj ) E, vertex xi vertex xjcolor.10. Given undirected graph G = (V, E), let wxi ,xj weight associated edge (xi , xj ) E.Pweighted Max-Cut problem find subset V W (S, S) = xi S,xj wxi ,xjmaximized, = V S. paper, set weight wxi ,xj = 1 edges.340fiNew Inference Rules Max-SATMax-Cut Ramsey numbers instances Max-SAT Evaluation 2006 contain different structures. example, underlying graphs Max-Cut instancesdifferent origins fault diagnosis problems, coding theory problems, graphclique problems. Max-2SAT Max-3SAT instances evaluation containduplicated clauses.computed initial upper bound local search solver instance.provide parameter solver except instance solved initialupper bound. words, used default values parameters.instances Max-SAT Evaluation 2006 solved conditionsevaluation; i.e., initial upper bound provided solvers, maximum timeallowed solve instance 30 minutes.7.2 Evaluation Inference Rulesfirst experiment performed evaluate impact inference rules Section 4,solved sets 100 random Max-2SAT instances 50 100 variables; numberclauses ranged 400 4500 50 variables, 400 1000 100 variables.results obtained shown Figure 7. Along horizontal axis numberclauses, along vertical axis mean time (left plot), seconds, needed solveinstance set, mean number branches proof tree (right plot). Noticeuse log scale represent run-time branches.observe rules powerful Max-2SAT gain increasesnumber variables number clauses increase. 50 variables 1000clauses (the clause variable ratio 20), MaxSatz 7.6 times faster MaxSat1234;100 variables 1000 clauses (the clause variable ratio 10), MaxSatz 9.2times faster MaxSat1234. search tree MaxSatz also substantially smallerMaxSat1234. Rule 5 Rule 6 powerful Rule 3 Rule 4Max-2SAT. intuitive explanation MaxSatz MaxSat1234 detect manyinconsistent subsets clauses containing one unit clause subsets containing two unitclauses, Rule 5 Rule 6 applied many times Rule 3 Rule 4MaxSatz.Recall that, one hand, every application Rule 3 Rule 4 consumes twounit clauses produces one empty clause, limiting unit propagation detectingconflicts subsequent search. hand, Rule 3 Rule 4 add clausesmay contribute detect conflicts. Depending number clauses (orprecisely, clause variable ratio) formula, two factors differentimportance. relatively clauses, unit propagation relativelyeasily derive contradiction unit clause, binary clauses added Rule 3Rule 4 relatively important deriving additional conflicts improving lowerbound, explains search tree MaxSat1234 smaller search treeMaxSat12 instances 100 variables less 600 clauses. contrary,many clauses, unit propagation easily derives contradiction unitclause, two unit clauses consumed Rule 3 Rule 4 would probably allowderive two disjoint inconsistent subsets clauses. addition, binary clauses addedRule 3 Rule 4 relatively less important deriving additional conflicts, considering341fiLi, Manya & Planeslarge number clauses formula. case, search tree MaxSat1234larger search tree MaxSat12. However, cases, MaxSat1234 fasterMaxSat12, meaning incremental lower bound computation due Rule 3Rule 4 effective, since redetection many conflicts avoided thanks Rule 3Rule 4.Max-2SAT - 50 variables1e+0710001e+06branches (log scale)time (logscale)Max-2SAT - 50 variables10000100101MaxSat0MaxSat12MaxSat1234MaxSatz0.10.0110002000300010000010000MaxSat0MaxSat12MaxSat1234MaxSatz1000100400010002000number clauses10001e+071001010.01400MaxSat0MaxSat12MaxSat1234MaxSatz500600700800number clauses4000Max-2SAT - 100 variables1e+08branches (log scale)time (logscale)Max-2SAT - 100 variables100000.13000number clauses9001e+0610000010000MaxSat0MaxSat12MaxSat1234MaxSatz10001004001000500600700800number clauses9001000Figure 7: Comparison among MaxSat12, MaxSat1234 MaxSatz random Max-2SAT instances.Rule 5 Rule 6 limit unit propagation detecting conflicts, sinceapplication produces one empty clause consumes one unit clause, allowsderive one conflict case. added ternary clauses allow improvelower bound, search tree MaxSatz substantially smaller searchtree MaxSat1234. incremental lower bound computation due Rule 5 Rule 6also contributes time performance MaxSatz. example, search treeMaxSatz instances 50 variables 2000 clauses 11.5 times smallersearch tree MaxSat1234, MaxSatz 14 times faster MaxSat1234.second experiment, solved random Max-3SAT instances instead randomMax-2SAT instances. solved instances 50 70 variables; number clausesranged 400 1200 50 variables, 500 1000 70 variables. resultsobtained shown Figure 8.342fiNew Inference Rules Max-SATMax-3SAT - 50 variablesMax-3SAT - 50 variables1e+07branches (log scale)time (log scale)100010010MaxSat0MaxSat12MaxSat1234MaxSatz10.14006008001000number clauses1e+0610000010004001200Max-3SAT - 70 variables6008001000number clauses1200Max-3SAT - 70 variables1e+08branches (log scale)10000time (logscale)MaxSat0MaxSat12MaxSat1234MaxSatz100001000100MaxSat0MaxSat12MaxSat1234MaxSatz101500600700800number clauses90010001e+071e+06MaxSat0MaxSat12MaxSat1234MaxSatz10000010000500600700800number clauses9001000Figure 8: Comparison among MaxSat12, MaxSat1234 MaxSatz random Max-3SAT instances.Although rules involve ternary clauses, also powerful Max-3SAT.Similarly Max-2SAT, Rule 3 Rule 4 slightly improve lower boundrelatively clauses, improve lower bound number clausesincreases. improve time performance thanks incremental lower boundcomputation allowed. gain increases number clauses increases.example, problems 70 variables, number clauses 600, MaxSat123436% faster MaxSat12 and, number clauses 1000, gain 44%.Rule 5 Rule 6 improve lower bound time performance MaxSatz.gain increases number clauses increases.third experiment considered Max-Cut problem graphs 50 verticesnumber edges ranging 200 800. Figure 9 shows results comparinginference rules Max-Cut instances. observe rules allow us solveinstances much faster. Similarly random Max-2SAT, Rule 3 Rule 4improve lower bound many clauses, improve time performancedue incremental lower bound computation allowed. Rule 5 Rule 6powerful Rule 3 Rule 4 instances, contain binary clausesstructure. addition, reduction tree size due Rule 5 Rule 6contributes time performance MaxSatz incrementality lowerbound computation, random Max-2SAT. example, search tree MaxSatzinstances 800 edges 40 times smaller search tree MaxSat1234,MaxSatz 47 times faster.343fiLi, Manya & PlanesMax-Cut - 50 nodes1e+09100001e+08branches (log scale)time (log scale)Max-Cut - 50 nodes1000001000100101MaxSat0MaxSat12MaxSat1234MaxSatz0.10.01200300400500600number edges1e+071e+0610000010000MaxSat0MaxSat12MaxSat1234MaxSatz1000700100200800300400500600number edges700800Figure 9: Experimental results Max-Cutfourth experiment considered graph 3-coloring instances 24 60 vertices, density edges ranging 20% 90%. Figure 10 shows resultscomparing inference rules graph 3-coloring instances. observe Rule 1Rule 2 useful instances; tree size MaxSat0 MaxSat12 almostsame, MaxSat12 slower MaxSat0. contrary, rulesuseful instances, especially allow reduce search tree sizederiving better lower bounds.Graph 3-coloring 24 nodesGraph 3-coloring 24 nodes10000Branches (log scale)time (log scale)0.10.010.001MaxSat0MaxSat12MaxSat1234MaxSatz1e-042030405060% edges701000100MaxSat0MaxSat12MaxSat1234MaxSatz1080902030Graph 3-coloring 60 nodes5060% edges7080908090Graph 3-coloring 60 nodes1e+08Branches (log scale)10000time (log scale)401000100MaxSat0MaxSat12MaxSat1234MaxSatz1012030405060% edges701e+071e+06MaxSat0MaxSat12MaxSat1234MaxSatz10000080902030405060% edgesFigure 10: Experimental results Graph 3-Coloring34470fiNew Inference Rules Max-SATNote Rule 3 Rule 4 impact Rule 5 Rule 6 reducingcost solving instances. probably due fact two unit clausesneeded detect contradiction, Rule 3 Rule 4 applied many times.Also note instances 60 vertices become easier solve densitygraph high.fifth experiment, compared different inference rules benchmarks submitted Max-SAT Evaluation 2006. Solvers ran conditionsevaluation. Table 1, first column name benchmark set, secondcolumn number instances set, rest columns display averagetime, seconds, needed solver solve instance (the number solved instancesbrackets). maximum time allowed solve instance 30 minutes.clear MaxSat12 better MaxSat0, MaxSat1234 better MaxSat12,MaxSatz better MaxSat1234. example, MaxSatz solves three MAXCUTjohnson instances within time limit, solvers solve two instances.average time MaxSatz solve one three instances 44.46 seconds,third instance needing time solved two instances.Set NameMAXCUT brockMAXCUT c-fatMAXCUT hammingMAXCUT johnsonMAXCUT kellerMAXCUT p hatMAXCUT sanMAXCUT sanrMAXCUT max cutMAXCUT SPINGLASSMAXONERAMSEYMAX2SAT 100VARSMAX2SAT 140VARSMAX2SAT 60VARSMAX2SAT DISCARDEDMAX3SAT 40VARSMAX3SAT 60VARS#Instances1276421211440545485050501805050MaxSat0471.01(10)1.92 (5)39.42(2)14.91(2)512.66(2)72.16(9)801.95(7)323.67(3)610.28(35)0.22 (2)0.03 (45)8.93 (34)95.01(50)153.28(49)1.35 (50)126.98(162)11.52(50)167.17(50)MaxSat12277.12(12)3.11 (5)29.43(2)8.57 (2)213.64(2)286.09(12)305.75(7)134.74(3)481.48(40)0.19 (2)0.03 (45)8.42 (34)11.30(50)51.76(50)0.08 (50)71.85(173)3.33 (50)72.72(50)MaxSat1234225.11(12)2.84 (5)29.48(2)7.21 (2)163.26(2)226.24(12)245.70(7)107.76(3)450.05(40)0.15 (2)0.03 (45)7.80 (34)8.14 (50)34.14(50)0.06 (50)68.97(175)2.52 (50)52.14(50)MaxSatz14.01(12)0.07(5)171.30(3)44.46(3)6.82(2)16.81(12)258.65(11)71.00(4)7.18(40)0.14(2)0.03(45)7.78(34)1.25(50)6.94(50)0.02(50)22.72(180)1.92(50)40.27(50)Table 1: Evaluation rules benchmarks MAX-SAT Evaluation 2006.7.3 Comparison MaxSatz Solversfirst experiment, performed compare MaxSatz state-of-the-artMax-SAT solvers, solved sets 100 random Max-2SAT instances 50, 100 150variables; number clauses ranged 400 4500 50 variables, 4001000 100 variables, 300 650 150 variables. results solvinginstances BF, AGN, AMP, Lazy, toolbar, MaxSolver, MaxSatz shownFigure 11. Along horizontal axis number clauses, along vertical axismean time, seconds, needed solve instance set. solver neededmuch time solve instances point, stopped corresponding pointshown figure. 50 variable instances, BF one pointfigure (for 400 clauses); 100 variable instances, BF AMP also one345fiLi, Manya & Planespoint figure (for 400 clauses). version MaxSolver used limits numberclauses 1000 instances solved. ran instances 1000 clauses.see dramatic differences performance MaxSatz rest solversFigure 11. hardest instances, MaxSatz two orders magnitude fastersecond best performing solvers (UP). instances, MaxSatz needs 1 secondsolve instance solvers like MaxSolver toolbar able solveinstances 10,000 seconds.second experiment, solved random Max-3SAT instances instead randomMax-2SAT instances. results obtained shown Figure 12. considerAGN solve Max-2SAT instances. solved instances 50, 70100 variables; number clauses ranged 500 1200 50 variables, 5001000 70 variables, 450 800 100 variables. 70 variables, AMPone point figure (for 500 clauses) BF slow. 100 variables,compared two best solvers. again, observe dramatic differencesperformance profile MaxSatz rest solvers. Particularly remarkabledifferences MaxSatz toolbar (the second best performing solver Max3SAT), see MaxSatz 1,000 times faster toolbar hardestinstances.third experiment, considered Max-Cut problem graphs 50 verticesnumber edges ranging 200 700. Figure 13 shows results obtained. BFone point figure (for 200 edges). MaxSolver solved instances 500 edges(1000 clauses). observe MaxSatz superior rest solvers.fourth experiment, considered 3-coloring problem graphs 2460 vertices, density edges ranging 20% 90%. AGN consideredsolve Max-2SAT instances. 60 vertices, compared threebest solvers, MaxSolver different version limiting number clausesinstance solved. Figure 14 shows comparative results different solvers.MaxSatz best performing solver, MaxSolver substantially betterrest solvers.Max-Cut - 50 nodes10000time (log scale)1000100BFAMPAGNLazytoolbarMaxSolverMaxSatz1010.10.01200 300 400 500 600 700number edgesFigure 13: Experimental results Max-Cut346fiNew Inference Rules Max-SATMax-2SAT - 50 variables10000time (log scale)100010010BFAMPAGNLazytoolbarMaxSolverMaxSatz10.10.010.0011000 2000 3000 4000number clausesMax-2SAT - 100 variables100000time (log scale)100001000100BFAMPAGNLazytoolbarMaxSolverMaxSatz1010.10.01400 500 600 700 800 900 1000number clausesMax-2SAT - 150 variables10000010000time (log scale)100010010BFAMPAGNLazytoolbarMaxSolverMaxSatz10.10.010.0011e-04300400500600number clausesFigure 11: Experimental results 50-variable, 100-variable 150-variable random Max2SAT instances.347fiLi, Manya & PlanesMax-3SAT - 50 variables10000time (log scale)1000100BFAMPLazytoolbarMaxSolverMaxSatz1010.16008001000number clauses1200Max-3SAT - 70 variablestime (log scale)100001000100AMPLazytoolbarMaxSolverMaxSatz101500 600 700 800 900 1000number clausesMax-3SAT - 100 variables100000time (log scale)1000010001001010.1toolbarMaxSatz0.01500600700number clauses800Figure 12: Experimental results 50-variable, 70-variable 100-variable random Max3SAT instances.348fiNew Inference Rules Max-SATGraph 3-coloring 24 nodes10000time (log scale)1000100101BFAMPLazyMaxSolvertoolbarMaxSatz0.10.010.0011e-0420 30 40 50 60 70 80 90% edgesGraph 3-coloring 60 nodes100000time (log scale)10000100010010MaxSolverMaxSatz120 30 40 50 60 70 80 90% edgesFigure 14: Experimental results Graph 3-Coloringfifth experiment, compared Max-SAT solvers benchmarks submittedMax-SAT Evaluation 2006. Solvers ran conditions evaluation.Table 2, first column name benchmark set, second columnnumber instances set, rest columns display average time, seconds,needed solver solve instance within time limit 30 minutes (the numberinstances solved within time limit brackets). dash means correspondingsolver cannot solve set instances. clear MaxSatz best performingsolver sets.8. Related Worksimplest method compute lower bound consists counting numberclauses unsatisfied current partial assignment (Borchers & Furman, 1999). One stepforward incorporate underestimation number clauses becomeunsatisfied current partial assignment extended complete assignment.basic method defined Wallace Freuder (1996):349fi#Instances1276421211440545485050501805050BF(0)6.06 (1)(0)(0)(0)605.44(2)(0)(0)(0)0.21 (1)0.02 (21)8.53 (30)0.14 (10)0.08 (10)1.92 (3)357.65(28)170.49(22)4.07 (16)AMP545.81(1)1.95 (3)636.04(1)394.17(2)197.15(1)107.79(8)563.19(1)428.18(1)(0)0.13 (1)0.03 (45)38.44(30)143.23(11)91.93(12)514.02(44)439.54(76)202.18(50)168.00(25)AGN856.65(8)32.70(5)159.99(1)92.90(2)39.36(1)16.11(8)72.35(2)909.32(3)1742.79(3)12.70(2)185.69(30)126.34(28)6.34 (50)99.70(108)-toolbar470.23(12)42.84(5)145.84(2)11.07(2)255.39(2)235.60(11)568.09(7)234.89(3)736.34(18)5.72 (2)35.35(44)4.14(27)244.05(34)262.30(26)2.01 (50)178.23(116)10.19 (50)361.95(43)Lazy159.28 (12)13.23 (4)265.35 (2)13.50 (2)348.75 (2)259.33 (10)956.54 (5)410.53 (3)1027.21 (7)0.05 (1)278.58 (26)10.48 (25)273.44 (22)217.12 (17)26.44 (50)85.08 (87)69.72 (50)242.40 (28)MaxSolver380.09(2)41.58(3)(0)1.34 (1)(0)14.00(8)283.34(2)138.32(1)(0)570.68(2)0.06 (45)0.20 (20)532.47(16)168.42(18)81.82(50)308.58(73)66.34(49)139.03(22)629.85(9)7.19 (5)294.89(2)29.42(2)615.54(2)140.23(9)812.47(5)538.10(3)623.03(13)0.86 (2)0.31 (45)19.65(25)192.34(48)75.57(39)0.94 (50)166.29(149)60.50(50)166.76(37)Table 2: Experimental results benchmarks MAX-SAT Evaluation 2006.MaxSatz14.01(12)0.07(5)171.30(3)44.46(3)6.82 (2)16.81(12)258.65(11)71.00(4)7.18(40)0.14(2)0.03 (45)7.78 (34)1.25 (50)6.94 (50)0.02 (50)22.72(180)1.92(50)40.27(50)350Li, Manya & PlanesSet NameMAXCUT brockMAXCUT c-fatMAXCUT hammingMAXCUT johnsonMAXCUT kellerMAXCUT DIMACS p hatMAXCUT sanMAXCUT sanrMAXCUT max cutMAXCUT SPINGLASSMAXONERAMSEY ram kMAX2SAT 100VARSMAX2SAT 140VARSMAX2SAT 60VARSMAX2SAT DISCARDEDMAX3SAT 40VARSMAX3SAT 60VARSfiNew Inference Rules Max-SATLB() = #emptyClauses() +xXoccursmin(ic(x), ic(x))CNF formula associated current partial assignment, ic(x) (ic(x))inconsistency count x (x) number unit clauses contain x (x).underestimation lower bound improved applying binary clausesDirectional Arc Consistency (DAC) count defined Wallace (1995) Max-CSP.DAC count value variable x number variables inconsistentvalue x. example, contains clauses x y, x y, x y, value0 x inconsistent y. Note value 0 also inconsistent x.two inconsistencies disjoint cannot summed. Wallace defined directionx y, inconsistency value 0 x counted. definingdirection every pair variables sharing constraint, one computes DAC countvalues x checking variables direction x defined.underestimation considering DAC count Wallace follows:xXoccurs(min(ic(x), ic(x)) + min(dac(x), dac(x))dac(x) (dac(x)) DAC count value 1(0) x. Wallace statically defineddirections, dac(x) dac(x) computed preprocessing step everyx need recomputed search. improved Larrosa, MeseguerSchiex (1999) introducing reversible DAC, searches better directionsobtain better lower bound every node search tree. improvement DACcounts additional incorporation inconsistencies contributed disjoint subsetsvariables, based particular variable partitions (Larrosa & Meseguer, 2002).Inconsistent DAC counts deal unit binary clauses. Lower bounds dealinglonger clauses include star rule (Shen & Zhang, 2004; Alsinet et al., 2004) (Liet al., 2005).star rule, underestimation lower bound number disjointinconsistent subformulas form {l1 , . . . , lk , l1 lk }. star rule, k = 1,equivalent inconsistency counts Wallace Freuder.subsumes inconsistent count method based unit clauses star rule.effectiveness producing good lower bound illustrated following example:let CNF formula containing clauses x1 , x1 x2 , x1 x3 , x2 x3 x4 , x5 , x5 x6 , x5x7 , x6 x7 x4 . easily detects inconsistent subset 8 clauses 7 variables,time linear size formula. Note subset detectedlower bounds described above, except variable partition based approach LarrosaMeseguer (2002) case 7 variables partition.mention two lower bound computation methods. One called LB4defined Shen Zhang (2004). similar restricted Max-2SAT instancesusing static variable ordering. Another based linear programmingdefined Xing Zhang (2005).Regin et al. (2001) suggested use arc consistency, instead unit propagation, detectdisjoint inconsistent subsets constraints weighted constraint networks. However,351fiLi, Manya & Planesbest knowledge, idea incorporated lower bound computationmethod implemented Constraint Programming community.good lower bound computation method dramatic impact performanceMax-SAT solver. Another approach speed Max-SAT solver consists applyinginference rules transform Max-SAT instance equivalent simpler Max-SATinstance . Inference rules proven useful practice include: (i) pureliteral rule (Alsinet et al., 2003b; Xing & Zhang, 2004; Li et al., 2005; Zhang et al., 2003);(ii) dominating unit clause rule, first proposed Niedermeier Rossmanith (2000),later applied several solvers (Alsinet et al., 2004; Xing & Zhang, 2004; Li et al.,2005); (iii) almost common clause rule, first proposed Bansal Raman (1999)restated Rule 1 paper. rule extended weighted Max-SAT byAlsinetet al. (2004); called neighborhood resolution Larrosa Heras (2005); usedpreprocessing technique Alsinet et al. (2004), Shen Zhang (2005), Li et al. (2005);(iv) complementary unit clause rule (Niedermeier & Rossmanith, 2000), restated Rule2 paper; (v) coefficient-determining unit propagation rule (Xing & Zhang,2005) based integer programming.inference rules presented paper simplify Max-SAT formula allowimprove lower bound computation, since transform Max-SAT formulasimpler equivalent formula containing empty clauses. soundness(i.e., fact transform formula equivalent one) proved severalways, including (i) checking possible variable assignments, (ii) using integer programmingdone Section 4, (iii) using soft local consistency techniques defined WeightedConstraint Networks (WCN); Max-SAT defined subcase WCN variablesBoolean unit costs used.Soft local consistency techniques WCN based two basic equivalence preservingtransformations called projection extension (Schiex, 2000; Cooper & Schiex, 2004).Given Max-SAT instance, projection replaces two binary clauses x xunit clause x, Rule 1 k=2. Extension inverse operation projectionreplaces unit clause x two binary clauses x x selected variabley. projection operation rather straightforward SAT Max-SAT instance,extension operation ingenious. see this, note Rule 3 provedapplied extension followed projection:l1 , l1 l2 , l2 = l1 l2 , l1 l2 , l1 l2 , l2= l1 l2 , l2 , l2= l1 l2 , 2Lemma 1 also proved using extension followed projection:l1 , l1 l2 = l1 l2 , l1 l2 , l1 l2= l1 l2 , l2extension operation cannot used unguided way may cancelprevious projection. One way guide use define ordering variables352fiNew Inference Rules Max-SATenforce directional arc consistency (Cooper, 2003; Cooper & Schiex, 2004). Directional arcconsistency allows concentrate weights variables shifting weightsearlier variables later ones given ordering. example x1 < x2 given variableordering, one extend unit clause x1 x1 x2 , x1 x2 , cannot extend unit clause x2x1 x2 , x1 x2 , allowing unit clauses concentrated variable x2 . Nevertheless,define variable ordering efficiently exploit much possible powersoft arc consistency techniques lower bound computation remains open problem.approach inference rules Max-SAT presented paper needpredefined ordering among variables, since rule applications combining several projection extension operations entirely guided unit propagation.projection extension operations extended constraints involvingtwo variables achieve high-order consistency WCN (Cooper, 2005). MaxSAT instance, extended projection extension operations stated using Rule 1k>2. two formulas 1 2 Rule 1, replacing 1 2 projection2 1 extension. Given unit clause x three variables x, y, z, extensionunit clause x set three variables done follows : replacing xx x y, x x x z, x z, x z x z.Rule 5 proved applied extending four clauses 1 ternary clausesthree variables l1 , l2 l3 , applying projection operation obtain 2 .Larrosa et al. (2007), based logical approach, independently parallelwork, defined implemented chain resolution rule cycle resolution ruleweighted Max-SAT. two rules extensions Rules 2-RES 3-RES presented,also independently parallel work (Heras & Larrosa, 2006).chain resolution could stated follows:(li , mi mi+1 )1ik ,(li li+1 , ui+1 mi+1 )1i<k ,(l1 , u1 ),(li li+1 , mi+1 )1i<k ,(li li+1 , ui+1 )1i<k ,=(l , umk+1 ),(lk , uk+1 )k k+1(2, mk+1 )where, 1ik+1, ui weight corresponding clause, mi =min(u1 , u2 , . . . , ui ),variables literals different. weight mandatory clause denoted, subtraction extended ui =. chain resolution ruleequivalent Rule 4 applied unweighted Max-SAT. main differencechain resolution rule weighted version Rule 4 presented Section 5.4chain resolution shifts part weight unit clause (l1 , m1 mk+1 ),derived weighted version Rule 4, create unit clauses (li , mi mi+1 )1<ik ,(l1 , m1 mk+1 ) becoming (l1 , m1 m2 ).cycle resolution rule could stated follows:353fiLi, Manya & Planes(li li+1 , ui )1i<k ,(l1 lk , uk )=(l1 li , mi1 mi )2ik ,(li li+1 , ui mi )2i<k ,(l1 li li+1 , mi )2i<k ,(l1 li li+1 , mi )2i<k ,(l1 lk , uk mk ),(l1 , mk )subset binary clauses cyclic structure, cycle resolution rule allowsderive unit clause. Note detection cyclic structure appears rather timeconsuming applied every node search tree 2(k-2) new ternaryclauses inserted. So, Larrosa et al. apply cycle resolution rule practicecase k=3, similar Rule 5, applied unweighted Max-SAT.cycle resolution rule applied unweighted Max-SAT k=3 replace Rule 5Rule 6 MaxSatz, following differences compared Rule 5 Rule 6:application Rule 5 Rule 6 entirely based inconsistent subformulasdetected unit propagation. detection applicability Rule 5 Rule 6easy low overhead, since inconsistent subformulas always detectedMaxSatz compute lower bound (with without Rule 5 Rule 6). Everyapplication Rule 5 Rule 6 allows increment lower bound 1.cycle resolution rule needs extra detection cyclic structure, allowsderive unit clause cyclic structure. derived unit clause couldused unit propagation, possibly could allow detect inconsistentsubformula increase lower bound 1.would interesting future research topic implement cycle resolution ruleMaxSat1234 (i.e., MaxSatz without Rule 5 Rule 6) evaluate overhead detectingcyclic structure usefulness unit clauses ternary clauses derivedusing cycle resolution rule, compare implemented solver MaxSatz.would also interesting compare chain resolution rule cycle resolution ruleweighted inference rules presented Section 5.4.general Max-SAT resolution rule, conclusions clausalform, defined Larrosa Heras (2005). Independently, Bonet et al. (2006, 2007)Heras Larrosa (2006) defined version rule conclusions clausalform. Bonet et al. (2006, 2007) also proved rule complete Max-SAT. Recently,Ansotegui et al. (2007b, 2007a) shown Max-SAT resolution many-valued CNFformulas provides logical framework global local consistency properties definedWCN.9. Conclusions Future WorkOne main drawbacks state-of-the-art Max-SAT solvers lack suitableinference techniques allow detect much contradictions possible simplifyformula node search tree. Existing approaches put emphasiscomputing underestimations good quality, problem underestimations354fiNew Inference Rules Max-SATcontradictions computed again. Furthermore, turnsU P , one currently best performing underestimations consisting detectingdisjoint inconsistent subsets clauses CNF formula via unit propagation, stillconservative. make computation lowers incremental improveunderestimation, defined number original inference rules Max-SAT that,based derived contradictions unit propagation, transform Max-SAT instanceequivalent Max-SAT instance easier solve. rules carefully selectedtaking account applied efficiently. Since rules basedcontradiction detection, particularly useful hard Max-SAT instancescontaining many contradictions.aim finding powerful inference rules practice,developed new Max-SAT solver, called MaxSatz, incorporates rules,performed experimental investigation. results comparing MaxSatz inferencerules MaxSatz without inference rules provide empirical evidence usefulnessrules making lower bound computation incremental improvingquality lower bounds. results comparing MaxSatz large selectionsolvers available time submitting paper provide empirical evidenceMaxSatz, least instances solved, faster solvers. observed gainsseveral orders magnitude hardest instances. Interestingly, benchmarksused, second best solver generally different: Max-2SAT, toolbar Max3SAT, MaxSolver Max-Cut, MaxSolver graph 3-coloring. So, MaxSatzrobust rest solvers. worth mentioning MaxSatz, enhancedlower bound based failed literal detection (Li et al., 2006), best performingsolver unweighted Max-SAT instances Max-SAT Evaluation 2006. secondthird best performing solvers were, respectively, improved versions toolbar Lazy11 .future work plan study orderings unit clauses unit propagationmaximize application inference rules, define new inference rules ternaryclauses. extending results paper weighted Max-SAT,suitable modeling problems maximum clique, set covering combinatorialauctions, well constraint satisfaction problems hard instances Model RB (Xu,Boussemart, Hemery, & Lecoutre, 2005; Xu & Li, 2006). also adapting resultspaper partial Max-SAT solvers developed Argelich Manya (2005, 2006,2007).AcknowledgmentsResearch partially supported projects TIN2004-07933-C03-03 TIN2006-15662-C0202 funded Ministerio de Educacion Ciencia. first author partially supported National 973 Program China Grant No. 2005CB321900. secondauthor supported grant Ramon Cajal. Finally, would like thank refereesdetailed comments suggestions.11. See http://www.iiia.csic.es/maxsat06 details. Note results Max-SAT Evaluation2006 compared results paper obtained clusterconditions.355fiLi, Manya & PlanesReferencesAlber, J., Gramm, J., & Niedermeier, R. (2001). Faster exact algorithms hard problems:parameterized point view. Discrete Mathematics, 229 (13), 327.Alsinet, T., Manya, F., & Planes, J. (2003a). Improved branch bound algorithmsMax-2-SAT weighted Max-2-SAT. Proceedings Catalonian ConferenceArtificial Intelligence (CCIA-03), P. Mallorca, Spain, Vol. 100 FrontiersArtificial Intelligence Applications, pp. 435442. IOS Press.Alsinet, T., Manya, F., & Planes, J. (2003b). Improved branch bound algorithmsMax-SAT. Proceedings 6th International Conference TheoryApplications Satisfiability Testing (SAT-03), Portofino, Italy, pp. 408415.Alsinet, T., Manya, F., & Planes, J. (2004). Max-SAT solver lazy data structures. Proceedings 9th Ibero-American Conference Artificial Intelligence(IBERAMIA-04), Puebla, Mexico, LNCS 3315, pp. 334342. Springer.Alsinet, T., Manya, F., & Planes, J. (2005). Improved exact solver weighted MaxSAT. Proceedings 8th International Conference Theory ApplicationsSatisfiability Testing (SAT-05), St. Andrews, Scotland, LNCS 3569, pp. 371377.Springer.Ansotegui, C., Bonet, M. L., Levy, J., & Manya, F. (2007a). Inference rules high-orderconsistency weighted CSP. Proceedings 22nd National ConferenceArtificial Intelligence (AAAI-07), Vancouver, Canada, pp. 167172. AAAI Press.Ansotegui, C., Bonet, M. L., Levy, J., & Manya, F. (2007b). logic behind weighted CSP.Proceedings 20th International Joint Conference Artificial Intelligence(IJCAI-07), Hyderabad, India, pp. 3237. AAAI Press.Argelich, J., & Manya, F. (2005). Solving over-constrained problems SAT technology.Proceedings 8th International Conference Theory ApplicationsSatisfiability Testing (SAT-05), St. Andrews, Scotland, LNCS 3569, pp. 115. Springer.Argelich, J., & Manya, F. (2006). Exact Max-SAT solvers over-constrained problems.Journal Heuristics, 12 (45), 375392.Argelich, J., & Manya, F. (2007). Partial Max-SAT solvers clause learning. Proceedings 10th International Conference Theory Applications SatisfiabilityTesting (SAT-07), Lisbon, Portugal, LNCS 4501, pp. 2840. Springer.Bansal, N., & Raman, V. (1999). Upper bounds MaxSat: improved. Proceedings 10th International Symposium Algorithms Computation (ISAAC-99),Chennai, India, LNCS 1741, pp. 247260. Springer.Beame, P., Kautz, H., & Sabharwal, A. (2003). Understanding power clause learning.Proceedings 18th International Joint Conference Artificial Intelligence(IJCAI-03), Acapulco, Mexico, pp. 9499. Morgan Kaufman.Bonet, M. L., Levy, J., & Manya, F. (2006). complete calculus Max-SAT. Proceedings 9th International Conference Theory Applications SatisfiabilityTesting (SAT-06), Seattle, USA, LNCS 4121, pp. 240251. Springer.356fiNew Inference Rules Max-SATBonet, M. L., Levy, J., & Manya, F. (2007). Resolution Max-SAT. Artificial Intelligence,171, 606618.Borchers, B., & Furman, J. (1999). two-phase exact algorithm MAX-SAT weightedMAX-SAT problems. Journal Combinatorial Optimization, 2, 299306.Boros, E., & Hammer, P. (2002). Pseudo-Boolean optimization. Discrete Applied Mathematics, 123, 155225.Cooper, M. C. (2003). Reduction operations fuzzy valued constraint satisfaction. FuzzySets Systems, 134, 311342.Cooper, M. C. (2005). High-order consistency valued constraint satisfaction. Constraints,10, 283305.Cooper, M. C., & Schiex, T. (2004). Arc consistency soft constraints. Artificial Intelligence, 154 (12), 199227.Cormen, T. H., Leiserson, C. E., Rivest, R. L., & Stein, C. (2001). Introduction Algorithms(second edition). MIT Press.Davis, M., Logemann, G., & Loveland, D. (1962). machine program theorem-proving.Communications ACM, 5, 394397.Davis, M., & Putnam, H. (1960). computing procedure quantification theory. JournalACM, 7 (3), 201215.de Givry, S., Larrosa, J., Meseguer, P., & Schiex, T. (2003). Solving Max-SAT weightedCSP. Proceedings 9th International Conference Principles PracticeConstraint Programming (CP-03), Kinsale, Ireland, LNCS 2833, pp. 363376.Springer.de Givry, S., Zytnicki, M., Heras, F., & Larrosa, J. (2005). Existential arc consistency: Getting closer full arc consistency weighted csps. Proceedings 19th International Joint Conference Artificial Intelligence (IJCAI-05), Edinburgh, Scotland,pp. 8489.Freeman, J. W. (1995). Improvements Propositional Satisfiability Search Algorithms.Ph.D. thesis, Department Computer Information Science, University Pennsylvania, PA, USA.Goldberg, E., & Novikov, Y. (2001). BerkMin: fast robust SAT solver. ProceedingsDesign, Automation Test Europe (DATE-02), Paris, France, pp. 142149.IEEE Computer Society.Heras, F., & Larrosa, J. (2006). New inference rules efficient Max-SAT solving. Proceedings 21st National Conference Artificial Intelligence (AAAI-06), Boston,USA. AAAI Press.Huang, W. Q., & Jin, R. C. (1997). Solar: learning human algorithm solvingSAT. Science China (Series E), 27 (2), 179186.Jeroslow, R. G., & Wang, J. (1990). Solving propositional satisfiability problems. AnnalsMathematics Artificial Intelligence, 1, 167187.357fiLi, Manya & PlanesLarrosa, J., & Heras, F. (2005). Resolution Max-SAT relation local consistencyweighted CSPs. Proceedings 19th International Joint Conference Artificial Intelligence (IJCAI-05), Edinburgh, Scotland, pp. 193198. Morgan Kaufmann.Larrosa, J., Heras, F., & de Givry, S. (2007). logical approach efficient Max-SATsolving. Artificial Intelligence, (in press).Larrosa, J., & Meseguer, P. (2002). Partition-based lower bound Max-CSP. Constraints,7 (34), 407419.Larrosa, J., Meseguer, P., & Schiex, T. (1999). Maintaining reversible DAC Max-CSP.Artificial Intelligence, 107 (1), 149163.Li, C. M. (1999). constraint-based approach narrow search trees satisfiability.Information Processing Letters, 71, 7580.Li, C. M., & Anbulagan (1997a). Heuristics based unit propagation satisfiabilityproblems. Proceedings 15th International Joint Conference ArtificialIntelligence (IJCAI-97), Nagoya, Japan, pp. 366371. Morgan Kaufmann.Li, C. M., & Anbulagan (1997b). Look-ahead versus look-back satisfiability problems.Proceedings 3rd International Conference Principles Constraint Programming (CP-97), Linz, Austria, LNCS 1330, pp. 341355. Springer.Li, C. M., & Huang, W. Q. (2005). Diversification determinism local searchsatisfiability. Proceedings 8th International Conference Theory Applications Satisfiability Testing (SAT-05), St. Andrews, Scotland, LNCS 3569, pp.158172. Springer.Li, C. M., Manya, F., & Planes, J. (2005). Exploiting unit propagation compute lowerbounds branch bound Max-SAT solvers. Proceedings 11th International Conference Principles Practice Constraint Programming (CP-05),Sitges, Spain, LNCS 3709, pp. 403414. Springer.Li, C. M., Manya, F., & Planes, J. (2006). Detecting disjoint inconsistent subformulascomputing lower bounds Max-SAT. Proceedings 21st National ConferenceArtificial Intelligence (AAAI-06), Boston, USA, pp. 8691. AAAI Press.Marques-Silva, J. P., & Sakallah, K. A. (1999). GRASP: search algorithm propositionalsatisfiability. IEEE Transactions Computers, 48 (5), 506521.Niedermeier, R., & Rossmanith, P. (2000). New upper bounds maximum satisfiability.Journal Algorithms, 36, 6388.Regin, J. C., Petit, T., Bessiere, C., & Puget, J. F. (2001). New lower bounds constraintviolations over-constrained problems. 7th International Conference Principles Practice Constraint Programming (CP-01), Paphos, Cyprus, LNCS 2239,pp. 332345. Springer.Schiex, T. (2000). Arc consistency soft constraints. Proceedings 6th International Conference Principles Constraint Programming (CP-00), Singapore,LNCS 1894, pp. 411424. Springer.358fiNew Inference Rules Max-SATShen, H., & Zhang, H. (2004). Study lower bound functions max-2-sat. ProceedingsNational Conference Artificial Intelligence (AAAI-04), San Jose, USA, pp.185190. AAAI Press.Shen, H., & Zhang, H. (2005). Improving exact algorithms max-2-sat. Annals Mathematics Artificial Intelligence, 44, 419436.Wallace, R. J. (1995). Directed arc consistency preprocessing. Constraint Processing,Selected Papers, LNCS 923, pp. 121137. Springer.Wallace, R. J., & Freuder, E. (1996). Comparative studies constraint satisfactionDavis-Putnam algorithms maximum satisfiability problems. Johnson, D., &Trick, M. (Eds.), Cliques, Coloring Satisfiability, Vol. 26, pp. 587615. AmericanMathematical Society.Xing, Z., & Zhang, W. (2004). Efficient strategies (weighted) maximum satisfiability.Proceedings 10th International Conference Principles Practice Constraint Programming (CP-04), Toronto, Canada, LNCS 3258, pp. 690705. Springer.Xing, Z., & Zhang, W. (2005). efficient exact algorithm (weighted) maximum satisfiability. Artificial Intelligence, 164 (2), 4780.Xu, K., Boussemart, F., Hemery, F., & Lecoutre, C. (2005). simple model generatehard satisfiable instances. Proceedings 19th International Joint ConferenceArtificial Intelligence (IJCAI-05), Edinburgh, Scotland, pp. 337342.Xu, K., & Li, W. (2006). Many hard examples exact phase transitions. TheoreticalComputer Science, 355, 291302.Zhang, H. (1997). SATO: efficient propositional prover. Proceedings ConferenceAutomated Deduction (CADE-97), pp. 272275.Zhang, H., Shen, H., & Manya, F. (2003). Exact algorithms MAX-SAT. ElectronicNotes Theoretical Computer Science, 86 (1).Zhang, L., Madigan, C., Moskewicz, M., & Malik, S. (2001). Efficient conflict driven learningBoolean satisfiability solver. International Conference Computer AidedDesign (ICCAD-01), San Jose, USA, pp. 279285.359fiJournal Artificial Intelligence Research 30 (2007) 101-132Submitted 10/05; published 9/07Planning Spectrum One, Two, Three, InfinityMarco Pistorepistore@dit.unitn.itDepartment Information Communication TechnologyUniversity TrentoVia Sommarive 14, 38050 Povo (Trento), ItalyMoshe Y. Vardivardi@cs.rice.eduDepartment Computer ScienceRice University6100 S. Main Street, Houston, TexasAbstractLinear Temporal Logic (LTL) widely used defining conditions executionpaths dynamic systems. case dynamic systems allow nondeterministicevolutions, one specify, along LTL formula , pathsrequired satisfy formula. Two extreme cases universal interpretation A.,requires formula satisfied execution paths, existentialinterpretation E., requires formula satisfied execution path.LTL applied definition goals planning problems nondeterministicdomains, two extreme cases restrictive. often impossible develop plansachieve goal nondeterministic evolutions system, weakrequire goal satisfied execution.paper explore alternative interpretations LTL formulaextreme cases. define new language permits arbitrary combinationE quantifiers, thus allowing, instance, require finite executionextended execution satisfying LTL formula (AE.),finite execution whose extensions satisfy LTL formula (EA.). showeight combinations path quantifiers relevant, corresponding alternationquantifiers length one (A E), two (AE EA), three (AEA EAE),infinity ((AE) (EA) ). also present planning algorithm new languagebased automata-theoretic approach, study complexity.1. Introductionautomated task planning (Fikes & Nilsson, 1971; Penberthy & Weld, 1992; Ghallab, Nau,& Traverso, 2004), given description dynamic domain basic actionsperformed it, given goal defines success condition achieved, onefind suitable plan, is, description actions executed domainorder achieve goal. Classical planning concentrates called reachabilitygoals, is, goals define set final desired states reached. Quite oftenpractical applications require plans deal goals general setsfinal states. Several planning approaches recently proposed, temporal logicformulas used goal language, thus allowing goals define conditionswhole plan execution paths, i.e., sequences states resulting executionplans (Bacchus & Kabanza, 1998, 2000; Calvanese, de Giacomo, & Vardi, 2002; Cerrito &c2007AI Access Foundation. rights reserved.fiPistore & VardiMayer, 1998; Dal Lago, Pistore, & Traverso, 2002; de Giacomo & Vardi, 1999; Kvarnstrom& Doherty, 2001; Pistore & Traverso, 2001). approaches use Linear TemporalLogic (LTL) (Emerson, 1990) goal language. LTL allows one express reachabilitygoals (e.g., F q reach q), maintainability goals (e.g., G q maintain q), well goalscombine reachability maintainability requirements (e.g., F G q reach setstates q maintained), Boolean combinations goals.planning nondeterministic domains (Cimatti, Pistore, Roveri, & Traverso, 2003;Peot & Smith, 1992; Warren, 1976), actions allowed different outcomes,possible know planning time different possible outcomes actuallytake place. Nondeterminism action outcome necessary modeling realistic wayseveral practical domains, ranging robotics autonomous controllers two-playergames.1 instance, realistic robotic application one take accountactions like pick object might result failure (e.g., object slipsrobots hand). consequence nondeterminism execution plan may leadone possible execution path. Therefore, one distinguish whether givengoal satisfied possible execution paths (in case speak strongplanning), possible execution paths (weak planning). caseLTL goal , strong planning corresponds interpreting formula universalway, A., weak planning corresponds interpreting existential way,E..Weak strong plans two extreme ways satisfying LTL formula. nondeterministic planning domains, might impossible achieve goals strong way:instance, robotic application might impossible fulfill given task objectskeep slipping robots hand. hand, weak plans unreliable,since achieve goal overly optimistic assumptions outcomesaction executions.case reachability goals, strong cyclic planning (Cimatti et al., 2003; Daniele,Traverso, & Vardi, 1999) shown provide viable compromise weakstrong planning. Formally, plan strong cyclic possible partial executionplan always extended execution reaches goal state. Strong cyclicplanning allows plans encode iterative trial-and-error strategies, like pickobject succeed. execution strategies may loop forever caseaction pick object continuously fails, failure achieving goalunfair execution usually acceptable. Branching-time logics like CTL CTL* allowexpressing goals take account nondeterminism. Indeed, Daniele et al. (1999)show encode strong cyclic reachability goals CTL formulas. However, CTLCTL* path quantifiers interleaved temporal operators, making difficultextend encoding strong cyclic planning proposed Daniele et al. (1999) generictemporal goals.paper define new logic allows exploring different degreesLTL formula satisfied exist strong goal A. weak goalE.. consider logic formulas form ., LTL formulapath quantifier generalizes E quantifiers used strong weak planning.1. See work Ghallab et al. (2004) deeper discussion fundamental role nondeterminismplanning problems practical applications.102fiThe Planning Spectrum One, Two, Three, Infinitypath quantifier (finite infinite) word alphabet {A, E}. path quantifierseen definition two-player game selection outcome actionexecution. Player (corresponding symbol A) chooses action outcomes ordermake goal fail, player E (corresponding symbol E) chooses action outcomesorder satisfy goal . turn, active player controls outcome actionexecution finite number actions passes control player.2say plan satisfies goal . player E winning strategy, namely if,possible moves player A, player E always able build execution pathsatisfies LTL formula .Different path quantifiers define different alternations turns players E.instance, goal A. require formula satisfied independentlyhostile player chooses outcomes actions, is, ask strong plan.goal E. require formula satisfied action outcomes chosenfriendly player E, is, ask weak plan. goal AE. requireevery plan execution led player extended player E successful executionsatisfies formula ; case reachability goal, corresponds askingstrong cyclic solution. goal EA. require that, initial set actionscontrolled player E, guarantee formula satisfied independentlyplayer choose outcome following actions. final example,goal (AE) . = AEAEA . require formula satisfied executionsplayer E possibility controlling action outcome infinite numbertimes.Path quantifiers define arbitrary combinations turns players E,hence different degrees satisfying LTL goal. show, however, that, rather surprisingly, finite number alternatives exist strong weak planning:eight canonical path quantifiers give rise plans different strength, everypath quantifier equivalent canonical one. canonical path quantifiers correspondgames length one (A E), two (AE EA), three (AEA EAE),games defining infinite alternation players E ((AE) (EA) ).also show that, case reachability goals = F q, canonical path quantifierscollapse. three different degrees solution possible, corresponding weak(E. F q), strong (A. F q), strong cyclic (AE. F q) planning.Finally, present planning algorithm new goal language studycomplexity. algorithm based automata-theoretic approach (Emerson & Jutla,1988; Kupferman, Vardi, & Wolper, 2000): planning domains goals representedsuitable automata, planning reduced problem checking whether givenautomaton nonempty. proposed algorithm time complexity doublyexponential size goal formula. known planning problem2EXPTIME-complete goals form A. (Pnueli & Rosner, 1990), hencecomplexity algorithm optimal.structure paper follows. Section 2 present preliminariesautomata theory temporal logics. Section 3 define planning domainsplans. Section 4 define AE-LTL, new logic path quantifier, study basic2. path quantifier finite word, player last turn chooses action outcomerest infinite execution.103fiPistore & Vardiproperties. Section 5 present planning algorithm AE-LTL, Section 6apply new logic particular cases reachability maintainability goals.Section 7 make comparisons related works present concluding remarks.2. Preliminariessection introduces preliminaries automata theory temporal logics.2.1 Automata TheoryGiven nonempty alphabet , infinite word infinite sequence 0 , 1 , 2 , . . .symbols . Finite state automata proposed finite structures acceptsets infinite words. paper, interested tree automata, namely finitestate automata recognize trees alphabet , rather words.Definition 1 (tree) (leafless) tree subset N that:root tree;x N x ;x , x N N, also x ;x (i+1) , x N N, also x .arity x number children, namely arity(x) = |{i : x }|. LetN. Tree D-tree arity(x) x . -labelled tree pair (, ),tree : . following, denote -labelled tree (, ), let = dom( ).Let -labelled tree. path p (possibly infinite) sequence x0 , x1 , . . . nodesxi dom( ) xk+1 = xk ik+1 . following, denote P ( ) setfinite paths P ( ) set infinite paths . Given (finite infinite) path p,denote (p) string (x0 ) (x1 ) , x0 , x1 , . . . sequence nodespath p. say finite (resp. infinite) path p0 finite (resp. infinite) extensionfinite path p sequence nodes p prefix sequence nodes p0 .tree automaton automaton accepts sets trees. paper, considerparticular family tree automata, namely parity tree automata (Emerson & Jutla, 1991).Definition 2 (parity tree automata) parity tree automaton parity index ktuple = h, D, Q, q0 , , i, where:finite, nonempty alphabet;N finite set arities;Q finite set states;q0 Q initial state;104fiThe Planning Spectrum One, Two, Three, Infinity: Q 2Q transition function, (q, , d) 2Q ;: Q {0, . . . , k} parity mapping.tree automaton accepts tree accepting run automaton tree.Intuitively, parity tree automaton state q reading d-ary nodetree labeled , nondeterministically chooses d-tuple hq1 , . . . , qd (q, , d)makes copies itself, one child node tree, statei-th copy updated qi . run parity tree automaton accepting if, along everyinfinite path, minimal priority visited infinitely often even number.Definition 3 (tree acceptance) parity tree automaton = h, D, Q, q0 , , accepts -labelled D-tree exists accepting run r , namely existsmapping r : Q that:r() = q0 ;x arity(x) = hr(x 0), . . . r(x (d1))i (r(x), (x), d);along every infinite path x0 , x1 , . . .infinitely many nodes xi even., minimal integer h (r(xi )) = htree automaton nonempty exists treeaccepted A.Emerson Jutla (1991) shown emptiness parity tree automatondecided time exponential parity index polynomial numberstates.Theorem 1 emptiness parity tree automaton n states index kdetermined time nO(k) .2.2 Temporal LogicsFormulas Linear Temporal Logic (LTL) (Emerson, 1990) built top set Propatomic propositions using standard Boolean operators, unary temporal operatorX (next), binary temporal operator U (until). following assumefixed set atomic propositions Prop, define = 2Prop set subsetsProp.Definition 4 (LTL) LTL formulas Prop defined following grammar,q Prop:::= q | | | X | Udefine following auxiliary operators: F = > U (eventually future )G = F (always future ). LTL formulas interpreted infinite words. following, write w |=LTL whenever infinite word w satisfies LTLformula .Definition 5 (LTL semantics) Let w = 0 , 1 , . . . infinite word letLTL formula. define w, |=LTL , N, follows:105fiPistore & Vardiw, |=LTL q iff q ;w, |=LTL iff hold w, |=LTL ;w, |=LTL 0 iff w, |=LTL w, |=LTL 0 ;w, |=LTL X iff w, i+1 |=LTL ;w, |=LTL U 0 iff j w, k |=LTL k < jw, j |=LTL 0 .say w satisfies , written w |=LTL , w, 0 |=LTL .CTL* (Emerson, 1990) example branching-time logic. Path quantifiers(for paths) E (for path) prefix arbitrary combinations linear timeoperators.Definition 6 (CTL*) CTL* formulas Prop defined following grammar,q Prop:::= q | | | | E::= | | | X | UCTL* formulas interpreted -labelled trees. following, writewhenever satisfies CTL* formula .|=CTL*Definition 7 (CTL* semantics) Let -labelled tree let CTL* formula.define , x |=CTL* , x , follows:, x |=CTL* q iff q (x);, x |=CTL* iff hold , x |=CTL* ;, x |=CTL* 0, x |=CTL* iff , p |=CTL* holds infinite paths p = x0 , x1 , . . . x0 = x;,xiff|=CTL* E iffx0 = x;, x |=CTL* , x |=CTL* 0 ;,p|=CTL* holds infinite path p = x0 , x1 , . . ., p |=CTL* , p P ( ), defined follows:, p |=CTL* iff p = x0 , x1 , . . . , x0 |=CTL* ;, p |=CTL* iff hold , p |=CTL* ;, p |=CTL* 0, p |=CTL* X iff , p0 |=CTL* , p0 = x1 , x2 , . . . p = x0 , x1 , x2 , . . .;, p |=CTL* U 0 iff j 0 , pk |=CTL* 0 k < j, pj |=CTL* 0 , pi = xi , xi+1 , . . . p = x0 , x1 , . . ..iff, p |=CTL* , p |=CTL* 0 ;106fiThe Planning Spectrum One, Two, Three, Infinityput_B_on_ABCBput_C_on_BCCBFigure 1: possible scenario blocks-world domain.saysatisfies CTL* formula , written|=CTL* ,, |=CTL* .following theorem states possible build tree automaton acceptstrees satisfying CTL* formula. tree automaton number statesdoubly exponential parity index exponential length formula.proof theorem given Emerson Jutla (1988).Theorem 2 Let CTL* formula, let N finite set arities. Onebuild parity tree automaton ADaccepts exactly -labelled D-trees satisfy .2automaton AD2formula .O(||)states parity index 2O(||) , || length3. Planning Domains Plans(nondeterministic) planning domain (Cimatti et al., 2003) expressed termsset states, one designated initial state, set actions, transitionfunction describing (the execution of) action leads one state possibly manydifferent states.Definition 8 (planning domain) planning domain tuple = h, 0 , A, Ri where:finite set states;0 initial state;finite set actions;R : 2 transition relation.require 0 0 R(, a).assume states ordered, write R(, a) = h1 , 2 , . . . , n wheneverR(, a) = {1 , 2 , . . . , n } 1 < 2 < < n .Example 1 Consider blocks-world domain consisting set blocks, initiallytable, stacked top order build towers (seeFigure 1).states domain possible configurations blocks: casethree blocks 13 states, corresponding blocks table (1 configuration),2-block tower remaining block table (6 configurations), 3-block tower(6 possible configurations). assume initially blocks table.107fiPistore & Vardiactions domain put X , put X table, wait, Xtwo (different) blocks. Actions put X put X table possibleblocks top X (otherwise could pick X). addition, actionput X requires blocks top (otherwise could put Xtop ).assume outcome action put X nondeterministic: indeed, tryingput block top tower may fail, case tower destroyed. Also actionwait nondeterministic: possible table bumped towersdestroyed.plan guides evolution planning domain issuing actions executed.case nondeterministic domains, conditional plans (Cimatti et al., 2003; Pistore &Traverso, 2001) required, is, next action issued plan may dependoutcome previous actions. consider general definition plans:plan mapping sequence states, representing past history domainevolution, action executed.Definition 9 (plan) plan partial function : + * that:(w ) = a, 0 R(, a) 0 ;(w ) = a, 0 R(, a) iff w 0 dom();w dom() w 6= , w dom();() defined iff = 0 initial state domain.conditions previous definition ensure plan defines action executedexactly finite paths w + reached executing plan initialstate domain.Example 2 possible plan blocks-world domain Example 1 represented Figure 2. remark importance plans action executed dependswhole sequence states corresponding past history evolution. Indeed,according plan Figure 2, two different actions put C put C tableperformed state block B top A, depending past history.Since consider nondeterministic planning domains, execution action maylead different outcomes. Therefore, execution plan planning domaindescribed (A)-labelled tree. Component label tree correspondsstate planning domain, component describes action executedstate.Definition 10 (execution tree) execution tree domain plan(A)-labelled tree defined follows:() = (0 , a0 ) 0initial state domain a0 = (0 );108fiThe Planning Spectrum One, Two, Three, Infinityw(w)ABCput BBABC ACput C BBABC ACCBBABC ACCBBACBABC ACCBBACput C tablehistoryput B tableABCwaitwaitFigure 2: plan blocks-world domain.p = x0 , . . . , xn P ( ) (p) = (0 , a0 ) (1 , a1 ) (n , ), R(n , ) =0h00 , . . . , d1i, every 0 < following conditions hold: xn dom( )(xn i) = (i0 , a0i ) a0i = (0 1 n i0 ).planning problem consists planning domain goal g defines setdesired behaviors. following, assume goal g defines set executiontrees, namely execution trees exhibit behaviors described goal (we sayexecution trees satisfy goal).Definition 11 (planning problem) planning problem pair (D, g),planning domain g goal. solution planning problem (D, g) planexecution tree satisfies goal g.4. Logic Path Quantifierssection define new logic based LTL extendspossibility defining conditions sets paths satisfy LTL property.start motivating logic necessary defining planning goals.Example 3 Consider blocks-world domain introduced previous section. Intuitively, plan Example 2 solution goal building tower consistingblocks A, B, C destroying it. goal easily formulated LTL109fiPistore & Vardiformula:1 = F ((C B B table) F (C table B table table)).Notice however that, due nondeterminism outcome actions, plan mayfail satisfy goal. possible, instance, action put C B failstower destroyed. case, plan proceeds performing wait actions, hencetower never finished. Formally, plan solution goal requirespath execution structure satisfies LTL formula 1 .Clearly, better ways achieve goal building tower destroyingit: fail building tower, rather giving up, restart building keeptrying succeed. strategy allows achieving goal paths:keep destroying tower try build achieve goal.see, logic path quantifiers going define allow us formalizemean paths.Consider following LTL formula:2 = F G ((C B B table).formula requires building tower maintaining it. case two possibleways fail achieve goal. fail build tower; or, built, failmaintain (remember wait action may nondeterministically lead destructiontower). Similarly case formula 1 , planning goal requires satisfyingformula 2 paths execution tree unsatisfiable. hand, goalrequires satisfying paths weak; logic allows us demandingpaths satisfy formula.Finally, consider following LTL formula:3 = G F ((C B B table).requires tower exists infinitely many time, i.e., tower gets destroyed,rebuild it. Intuitively, goal admits plans achieve often, i.e.,paths, 2 . again, path logic needed give formal meaningpaths.order able represent planning goals discussed previous example,consider logic formulas form ., LTL formula pathquantifier defines set infinite paths formula checked. Twoextreme cases path quantifier A, used denote must holdpaths, path quantifier E, used denote must hold paths.general, path quantifier (finite infinite) word alphabet {A, E} definesalternation selection two modalities corresponding E A. instance,writing AE. require finite paths infinite extension satisfies, writing EA. require extensions finite path satisfy .path quantifier seen definition two-player game selectionpaths satisfy LTL formula. Player (corresponding A) tries buildpath satisfy LTL formula, player E (corresponding E) tries110fiThe Planning Spectrum One, Two, Three, Infinitybuild path LTL formula holds. Different path quantifiers define differentalternations turns players E. game starts path consistinginitial state, and, turns, players E extend path finitenumber nodes. case path quantifier finite word, player moves lastgame extends finite path built far infinite path. formula satisfiedplayer E winning strategy, namely if, possible moves player A,always able build path satisfies LTL formula.Example 4 Let us consider three LTL formulas defined Example 3, let us seepath quantifiers introduced applied.case formula 1 , plan presented Example 2 satisfies requirement E.1 :path tower built destroyed. also satisfies strongerrequirement EA.1 stresses fact that, case, tower builtdestroyed, safely give control player A. Formula 1 satisfiedstronger way, however. Indeed, plan keeps trying build tower satisfiesrequirement AE.1 , well requirement AEA.1 : player cannot reach statesatisfaction goal prevented.Let us consider formula 2 . case, find plans satisfying AE.2 ,plan satisfy requirement AEA.2 . Indeed, player simple strategy win,gets control built tower: bump table. Similar considerations holdalso formula 3 . Also case, find plans requirement AE.3 ,requirement AEA.3 . case, however, plans exist also requirement AEAEAE .3 :player E gets control infinitely often, rebuild tower needed.rest section give formal definition study basic propertieslogic path quantifiers.4.1 Finite Gamesstart considering games finite number moves, path quantifierscorresponding finite words {A, E}.Definition 12 (AE-LTL) AE-LTL formula pair g = ., LTLformula {A, E}+ path quantifier.following definition describes games corresponding finite path quantifiers.Definition 13 (semantics AE-LTL) Let p finite path -labelled treeThen:p |= A. finite extensions p0 p holds p0 |= ..p |= E. finite extension p0 p holds p0 |= ..p |= A. infinite extensions p0 p holds(p0 ) |=LTL .p |= E. infinite extension p0 p holds111(p0 ) |=LTL ..fiPistore & Vardisay -labelled tree satisfies AE-LTL formula g, writep0 |= g, p0 = root .|= g,AE-LTL allows path quantifiers consisting arbitrary combinationEs. combination corresponds different set rules gameE. Theorem 4 show freedom definition path quantifierneeded. six path quantifiers sufficient capture possible games.result based concept equivalent path quantifiers.Consider formulas A. F p AE. F p. easy see two formulas equisatisfiable, i.e., tree satisfies A. F p also satisfies AE. F p, vice-versa.case, path quantifiers AE power, depends factuse path quantifiers combination LTL formula F p. combinetwo path quantifiers different LTL formulas, G p, possible findtrees satisfy latter path quantifier former. reason, cannotconsider two path quantifiers equivalent. Indeed, order two path quantifiersequivalent, equi-satisfiable LTL formulas. intuitionformalized following definition.Definition 14 (equivalent path quantifiers) Let 0 two path quantifiers.say implies 0 , written0 , -labelled trees LTL formulas0, |= . implies |= .. say equivalent 0 , written 0 ,00.following lemma describes basic properties path quantifiersequivalences among them. exploit results proof Theorem 4.Lemma 3 Let , 0 {A, E} . following implications equivalences hold.1. AA0 A0 EE0 E0 .2. A00 0E0 , 0 empty.3. A0AEA0 EAE0E0 .4. AEAE0 AE0 EAEA0 EA0 .Proof. proof lemma, order prove 000 prove that, given0arbitrary tree arbitrary LTL formula , p |= . implies p |= 00 . everyfinite path p . Indeed, p |= 0 . implies p |= 00 . finite paths p, easyprove, induction , p |= 0 . implies p |= 00 . finite paths p.following, refer proof technique prefix induction.1. show that, every finite path p, p |= AA0 . p |= A0 .:equivalence AA0 A0 follows prefix induction.Let us assume p |= AA0 .. prove p |= A0 ., is, p0 |= 0 .every finite3 extension p0 p. Since p |= AA0 ., Definition 13 know that,3. assume 0 empty word. proof case 0 empty word similar.112fiThe Planning Spectrum One, Two, Three, Infinityevery finite extension p0 p, p0 |= A0 .. Hence, Definition 13, knowevery finite extension p00 p0 , p00 |= 0 .. Since p0 finite extension p0 ,conclude p0 |= 0 .. Therefore, p0 |= 0 . holds finite extensions p0p.Let us assume p |= A0 .. prove p |= AA0 ., is, finiteextensions p0 p, finite extensions p00 p0 , p00 |= 0 .. remarkfinite path p00 also finite extension p, therefore p00 |= 0 . holds sincep |= A0 ..concludes proof equivalence AA0 A0 . proofequivalence EE0 E0 similar.2. Let us assume first 0 empty word. distinguish two cases, dependingfirst symbol 0 . 0 = A00 , prove AA00A00 ,000already item 1 lemma. = E , show that,every finite path p, p |= AE00 . p |= E00 .: A00 follows00prefix induction. Let us assume p |= AE .. Then, finite extensions p0p exists finite4 extension p00 p0 p00 |= 0 .. Let us take p0 = p.know finite extension p00 p p00 |= 0 ., is,according Definition 13, p |= E0 ..Let us assume 0 empty word. hypothesis, 0 6= ,empty. distinguish two cases, depending last symbol . = 00A,prove 00AA00A, already item 1 lemma.= 00 E, prove every finite path p, p |= EA. p |= E.:00 EA00 E follows prefix induction. Let us assume p |= EA..Definition 13, exists finite extension p0 p that, every infiniteextension p00 p0 (p00 ) |=LTL . Let p00 infinite extension p0 .know p00 also infinite extension p, (p00 ) |=LTL . Then,Definition 13 deduce p |= E..concludes proof A00 . proof 0E0 similar.3. item 1 lemma know A0AA0 item 2 know00AAAEA . concludes proof A0AEA0 . proofEAE0E0 similar.4. item 3 lemma know (A)EAE0(A)E0 . Moreover,00item 3, know A(E )AEA(E ). Therefore, deduce AE000AEAE . proof EA EAEA0 similar.prove first main result paper: finite path quantifierequivalent canonical path quantifier length three.Theorem 4 finite path quantifier canonical finite path quantifier0 {A, E,AE, EA,AEA, EAE}4. assume 00 empty word. proof case 00 empty similar.113fiPistore & Vardi0 . Moreover, following implications hold canonical finitepath quantifiers:(1)/o /o /o / AEA o/ /o /o / AE////EAEAE /o /o o/ / EProof. first prove path quantifier equivalent canonical pathquantifier 0 . iterative application Lemma 3(1), obtain path quantifier00 00 00 contain two adjacent E. Then, iterativeapplication Lemma 3(4), transform 00 equivalent path quantifier 0length 3. canonical path quantifiers (1) precisely quantifierslength 3 contain two adjacent E.implications (1):AEA EAEE come Lemma 3(3);AEAEA AEEAE come Lemma 3(2);AEAAE EAEAE come Lemma 3(2).remark Lemma 3 Theorem 4 depend usage LTL formula. depend general observation0 whenever player E selectgame 0 set paths subset selected game .4.2 Infinite Gamesconsider infinite games, namely path quantifiers consisting infinite wordsalphabet {A, E}. see infinite games express finite path quantifiersstudied previous subsection, infinite games, corresponding infinite alternation two players E, cannot expressedfinite path quantifiers.case infinite games, assume player E moves according strategysuggests extend finite path. say |= ., infinitegame, winning strategy player E. strategy winning if, wheneverp infinite path obtained according i.e., allowing player playarbitrary way requiring player E follows strategy p satisfies LTLformula .Definition 15 (strategy) strategy -labelled tree mapping : P ( )P ( ) maps every finite path p one finite extensions (p).Definition 16 (semantics AE-LTL) Let = 0 1 {A, E} infinitepath quantifier. infinite path p possible outcome game strategygenerating sequence it, namely, infinite sequence p0 , p1 , . . . finite pathsthat:pi finite prefixes p;114fiThe Planning Spectrum One, Two, Three, Infinityp0 = root tree;= E pi+1 = (pi );= pi+1 (arbitrary) extension pi .denote P (, ) set infinite paths possible outcomes gamestrategy . tree satisfies AE-LTL formula g = ., written |= g,strategy (p) |=LTL paths p P (, ).remark possible paths generating sequence stop growing, i.e.,pi pi = pj j i. case, according previousdefinition, infinite paths p extend pi possible outcomes.next lemmas extend analysis equivalence among path quantifiersinfinite games.5 first lemma shows finite path quantifiers particular casesinfinite path quantifiers, namely, correspond infinite path quantifiersend infinite sequence E.Lemma 5 Let finite path quantifier. (A) (E) E.Proof. prove (A) A. proof equivalence similar.First, prove (A)A. Let tree LTL formula|= (A) .. Moreover, let strategy p P ((A) , ) satisfy .order prove |= A. sufficient use strategy moves playerE, namely, whenever need prove p |= E0 . according Definition 13, takep0 = (p) move prove p0 |= 0 .. way, infinite paths selectedDefinition 13 coincide possible outcomes game (A) , hence satisfyLTL formula .concludes proof (A)A. prove(A) . distinguishthree cases.Case = (A)n , n 0.case, (Lemma 3(1)) (A) = (A) . Let treeLTL formula. |= A. paths satisfy formula .easy check also |= (A) . paths satisfy formula .sufficient conclude (A)nA (A)n (A) .Case = E0 .case, EA. Indeed, arbitrary path quantifier starts Eends A. Lemma 3(1), collapse adjacent occurrencesE , thus obtaining (EA)n n > 0. Moreover, Lemma 3(4)(EA)n EA.Let tree LTL formula. |= EA.finite path p infinite extensions p satisfy . Now, let5. definitions implication equivalence relations (Definition 14) also apply caseinfinite path quantifiers.115fiPistore & Vardistrategy () = p. every infinite path p P (E0 (A) , )satisfies . Indeed, since player E first turn, possible outcomesinfinite extensions () = p.concludes proof E0AE0 (A) .Case = (A)n E0 , n > 0.Reasoning proof previous case, easy show AEA.Let tree LTL formula. |= AEA.every finite path p finite extension p0 p infiniteextensions p0 satisfy formula . Let strategy p0 = (p)finite extension p infinite extensions p0 satisfy . everyinfinite path p P ((A)n E0 (A) , ) satisfies . Indeed, let p0 , p1 , . . . , pn , pn+1 , . . .generating sequence p. pn+1 = (pn ) p infinite extension pn+1 .construction know p satisfies .concludes proof (A)n E0A(A)n E0 (A) .Every finite path quantifier falls one three considered cases. Therefore,conclude(A) every finite path quantifier .next lemma defines sufficient condition provinguseful proofs forthcoming lemmas.0 . conditionLemma 6 Let 0 two infinite path quantifiers. Let us assume -labelledtrees strategy strategy 0 P (0 , 0 ) P (, ).0 .Proof. Let us assume |= .. suitable strategyp P (, ) satisfy LTL formula . Let 0 strategy P (0 , 0 )P (, ). hypothesis, possible outcomes game 0 strategy 0 satisfy LTLformula , hence |= 0 .. concludes proof0 .next lemma show games players E alternate infinitelyoften equivalent one two games (AE) (EA) . is, assumeplayer extends path turn passes player.Lemma 7 Let infinite path quantifier contains infinite numberinfinite number E. (AE) (EA) .Proof. Let = (A)m1 (E)n1 (A)m2 (E)n2 mi , ni > 0. show (AE) .First, prove (AE). Let strategy tree let p infinitepath . show p P (, ) p P ((AE) , ). Lemma 6sufficient proving (AE).Let p0 , p1 , . . . generating sequence p according . Moreover, let p00 = ,p02i+1 = pm1 +n1 ++mi1 +ni1 +mi p02i+2 = pm1 +n1 ++mi1 +ni1 +mi +1 . easycheck p00 , p01 , p02 , . . . valid generating sequence p according game (AE)strategy . Indeed, extensions p00 p01 , p02 p03 , p04 p05 , . . . moves player A,116fiThe Planning Spectrum One, Two, Three, Infinityhence arbitrary. Extensions p01 p02 , p03 p04 , . . . correspond extensionspm1 pm1 +1 , pm1 +n1 +m2 pm1 +n1 +m2 +1 , . . . , moves player E hencerespect strategy .prove(AE) . Let strategy tree . define strategyp P (, ). Lemma 6 sufficient provingp P ((AE) , ),(AE) .= kp (p) kp = P|p| ni . is, strategy pathLet p finite path. (p)i=1p obtained applying kp times strategy . number times strategy applieddepends length |p| path p.p possibleshow that, p possible outcome game strategy ,outcome game (AE) strategy . Let p0 , p1 , . . . generating sequence paccording (AE) .p0 , p1 , ..., p1 , (p1 ), 2 (p1 ), ..., n1 (p1 ), p3 , ..., p3 ,| {z } |{z} | {z }m1 timesm2 timesn1 times2n2(p3 ), (p3 ), ..., (p3 ), p5 , ..., p5 , ...|{zn2 times} | {z }m3 timesvalid generating sequence p according . extensions correspondingoccurrence symbol E consist application strategy hence validplayer E. Moreover, extension ni (p2i1 ) p2i+1 valid move playerp2i+1 extension ni (p2i1 ). Indeed, ni (p2i1 ) prefix p2i (and hence p2i+1 )P|p2i1 |2i1 ) = kp2i1 (p2i1 ) kpsince p2i = (p2i1 =x=1 nx ni , since |p2i1 | i.conditions Definition 16 easily checked.concludes proof (AE) = (A)m1 (E)n1 (A)m2 (E)n2 . proof(EA) = (E)m1 (A)n1 (E)m2 (A)n2 similar.next lemma contains auxiliary results path quantifiers.Lemma 8 Let finite path quantifier 0 infinite path quantifier.1. A02. (A)0 0E0 .A0 E0(E) .Proof.1. prove A00 . Let strategy tree let p infinitepath . show p P (0 , ) p P (A0 , ). Let p0 , p1 , . . .generating sequence p according 0 . easy checkp0 , p1 , . . . , pi1 , pi , pi , pi+1 , . . ., length , valid generating sequencep according A0 . Indeed, extension pi pi valid move playerA. concludes proof A00 .prove 0E0 . 0 = (E) , E0 = E(E) = (E) = 0 ,E00 trivially true. 0 6= (E) , assume, without lossgenerality, 0 = A00 . case, let strategy tree let p117fiPistore & Vardipath . show p P (E0 , ) p P (0 , ). Let p0 , p1 , . . .generating sequence p according E0 . easy checkp0 , p1 , . . . , pi , pi+2 , . . ., length , valid generating sequence paccording 0 . Indeed, extension pi pi+2 valid, correspondsfirst symbol 0 assumed symbol A. concludes proof0E0 .2. prove (A)0 . proof 0(E) similar.Let strategy tree let p infinite path . showp P ((A) , ) p P (0 , ). Let p0 , p1 , . . . generating sequence paccording 0 . easy check p0 , p1 , . . . valid generating sequence p according (A) . fact, (A) defines less restrictiveconditions generating sequences 0 .sufficient conclude (A)0 .complete picture Theorem 4: finite infinite path quantifierequivalent canonical path quantifier defines game consisting alternated movesplayers E length one, two, three, infinity.Theorem 9 finite infinite path quantifier canonical path quantifier0 {A, E,AE, EA,AEA, EAE, (AE) , (EA) }0 . Moreover, following implications hold canonical pathquantifiers:(2)/o /o /o / AEA /o /o /o / (AE) /o /o /o / AEEA /o /o /o /(EA)/o /o o/ / EAE /o /o o/ / EProof. first prove path quantifier equivalent canonical path quantifier.Theorem 4, true finite path quantifiers, consider infinite pathquantifiers.Let infinite path quantifier. distinguish three cases:contains infinite number infinite number E: then, Lemma 7,equivalent one canonical games (AE) (EA) .contains finite number A: case, ends infinite sequence E,and, Lemma 5, 00 finite path quantifier 00 . Theorem 4, 00equivalent canonical path quantifier, concludes proofcase.contains finite number E: case similar previous one.implications (2):118fiThe Planning Spectrum One, Two, Three, Infinity(AE)(AE) .(EA) comes Lemma 8(1), taking empty word 0 =AEA(AE) , (AE)8(2).AE, EA(EA) , (EA)EAE come Lemmas 5implications come Theorem 4.4.3 Strictness Implicationsconclude section showing arrows diagram Theorem 9describe strict implications, namely, eight canonical path quantifiers different.Let us consider following {i, p, q}-labelled binary tree, root labellednode two children labelled p q:'&%$!"#iMqqq MMMMMqqMMMqM&qqq()*+/.-,()*+/.-,p =xqq===========()*+/.-,/.-,()*+()*+/.-,()*+/.-,p.q.p.q.............()*+/.-,/.-,/.-,()*+/.-,()*+/.-,/.-,/.-,()*+/.-,()*+p ()*+pp ()*+qqpqq ()*+Let us consider following LTL formulas:F p: player E satisfy formula moves least once, visiting p-labellednode.G F p: player E satisfy formula visit infinite number p-labellednodes, is, final move finite game, moves infinitely ofteninfinite game.F G p: player E satisfy formula takes control gamecertain point on, is, final move finite game.G q: player E satisfy formula player never plays, since playerimmediately visit q-labelled node.X p: player E satisfy formula playing first turn moving leftchild root node.following graph shows formulas hold path quantifiers:FpGFpFGpG q/o o/ / AEA /o / (AE) /o o/ / AEXpEA /o o/ / (EA) /o o/ / EAE /o /o o/ / E119fiPistore & Vardi5. Planning Algorithm AE-LTLsection present planning algorithm AE-LTL goals. start showingbuild parity tree automaton accepts trees satisfy given AE-LTLformula. show tree automaton adapted, acceptstrees correspond valid plans given planning domain. way, problemchecking whether exists plan given domain AE-LTL goalreduced emptiness problem tree automata. Finally, study complexityplanning AE-LTL goals prove problem 2EXPTIME-complete.5.1 Tree Automata AE-LTL FormulasBerwanger, Gradel, Kreutzer (2003) shown AE-LTL formulas expressed directly CTL* formulas. reduction exploits equivalence expressivepower CTL* monadic path logic (Moller & Rabinovich, 1999). tree automatonobtained AE-LTL formula using reduction Theorem 2. However,translation proposed Berwanger et al. (2003) upper bound non-elementarycomplexity, hence useful complexity analysis. paper describedifferent, direct reduction better suited purposes.-labelled tree satisfies formula . suitable subset pathstree satisfy . subset paths chosen according . ordercharacterize suitable subsets paths, assume w-marking tree ,use labels w define selected paths.Definition 17 (w-marking) w-marking -labelled tree ({w, w})-labelled tree w dom( ) = dom(w ) and, whenever (x) = , w (x) = (, w)w (x) = (, w).exploit w-markings follows. associate AE-LTL formula . CTL*formula [[.]] tree satisfies formula . wmarking satisfies [[.]].Definition 18 (AE-LTL CTL*) Let . AE-LTL formula. CTL* formula[[.]] defined follows:[[A.]] =[[E.]] = E[[EA.]] = EF w A(F w )[[AEA.]] = AG EF w A(F w )[[AE.]] = AG EXG w A(F G w )[[EAE.]] = EF AG EXG w A(F G w )[[(AE) .]] = AG EF w A(G F w )[[(EA) .]] = EF AG EF w A(G F w )case path quantifiers E, direct translation CTL*exploit w-marking. cases, CTL* formula [[.]] conjunction120fiThe Planning Spectrum One, Two, Three, Infinitytwo sub-formulas. first one characterizes good markings according pathquantifier , second one guarantees paths selected accordingmarking satisfy LTL formula . case path quantifiers EA AEA, markw nodes that, reached, guarantee formula satisfied. selectedpaths hence contain node labelled w (formula F w). casepath quantifiers AE EAE, mark w descendants node defineinfinite path satisfies . selected paths hence that, certain nodeon, continuously labelled w (formula F G w). case path quantifiers (AE)(EA) , finally, mark w nodes player E wants reach accordingstrategy passing turn player A. selected paths hencecontain infinite number nodes labelled w (formula G F w), is, paths alongplayer E moves infinitely often.Theorem 10 -labelled tree satisfies AE-LTL formula .w-marking satisfies formula [[.]].Proof. proof, consider cases = AEA, = AE = (AE) .cases similar.Assume tree satisfies .. show exists w-marking wsatisfies [[.]].Case = AEA. According Definition 13, tree satisfies AEA., everyfinite path p extended finite path p0 infinite extensionsp00 p0 satisfy . Let us mark w nodes w correspondextension p0 path p. construction, marked tree satisfies AG EF w.remains show marked tree satisfies A(F w ).Let us consider path p00 tree satisfies F w, let us show p00 alsosatisfies . Since p00 satisfies F w, know contains nodes marked w. Letp0 finite prefix path p00 first node marked w. construction,exists finite path p p0 finite extension p infiniteextensions p0 satisfy . consequence, also p00 satisfies .Case = AE. According Definition 13, tree satisfies AE.,finite paths p infinite extension p satisfies . Therefore,define mapping : P ( ) P ( ) associates finite path p infiniteextension m(p) satisfies . assume, without loss generality, that, p0finite extension p also prefix m(p), m(p0 ) = m(p). is,far p0 extends finite path p along infinite path m(p) associatesp0 infinite path m(p).every finite path p, let us mark w node w child palong infinite path m(p). construction, marked tree satisfies AG EXG w.remains show marked tree satisfies A(F G w ).Let us consider path p00 tree satisfies F G w, let us show p00 alsosatisfies . Since p00 satisfies F G w, know path pdescendants p along p00 marked w. order prove p00 satisfies121fiPistore & Vardishow p00 = m(p). Assume contradiction m(p) 6= p00 let p0longest common prefix m(p) p00 . observe p prefix p0 , hencem(p) = m(p0 ). implies child node p0 along p00 marked w,absurd, since definition p descendants p along p00 markedw.Case = (AE) . According Definition 16, tree satisfies (AE) .,exists suitable strategy player E possible outcomes gamestrategy satisfy . Let us mark w nodes w correspondextension (p) finite path p. is, mark w nodesreached move player E according strategy . markedtree satisfies formula AG EF w, is, every finite path p extendedfinite path p0 node corresponding p0 marked w. Indeed,construction, sufficient take p0 = (p00 ) extension p00 p. remainsshow marked tree satisfies A(G F w ).Let us consider path p tree satisfies G F w, let us show p alsosatisfies . purpose, show p possible outcome gamestrategy . remark that, given arbitrary finite prefix p0 p always possiblefind finite extension p00 p0 (p00 ) also prefix p. Indeed,set paths P = {p : (p) finite prefix p} infinite, infinite nodesmarked w path p.Now, let p0 , p1 , p2 , . . . sequence finite paths defined follows: p0 = ()root three; p2k+1 shortest extension p2k (p2k+1 )prefix p; p2k+2 = (p2k+1 ). easy check p0 , p1 , p2 , . . . generatingsequence p according (AE) . Hence, Definition 16, infinite path psatisfies LTL formula .concludes proof satisfies ., exists w-markingsatisfies [[.]].Assume w-marked tree w satisfies [[.]]. show satisfies..Case = AEA. marked tree satisfies formula AG EF w. meansfinite path p (AG) exists finite extension p0 final nodep0 marked w (EF w) . Let p00 infinite extension finite path p0 .show p00 satisfies LTL formula . Clearly, p00 satisfies formula F w.Since tree satisfies formula A(F w ), infinite paths satisfy F walso satisfy . Therefore, p00 satisfies LTL formula .Case = AE. marked tree satisfies formula AG EXG w. Then,finite path p (AG) exists infinite extension p0 that, certainnode on, nodes p0 marked w (EXG w). show that, p0infinite extension finite path p, p0 satisfies LTL formula . Clearly,p0 satisfies formula F G w. Since tree satisfies formula A(F G w ),infinite paths satisfy F G w also satisfy . Therefore, p0 satisfies LTLformula .122fiThe Planning Spectrum One, Two, Three, InfinityCase = (AE) . Let strategy that, every finite path p, nodecorresponding (p) marked w. remark always possible definestrategy. fact, marked tree satisfies formula AG EF w, hence,finite path p extended finite path p0 node correspondingp0 marked w.Let p possible outcome game strategy . prove p satisfiesLTL formula . Definition 16, infinite path p contains infinite setnodes marked w: nodes reached move player E. Hence,p satisfies formula G F w. Since tree satisfies formula A(G F w ),infinite paths satisfy G F w also satisfy . Therefore, path p satisfies LTLformula .concludes proof that, exists w-marking tree|= ..satisfies [[.]],Kupferman (1999) defines extension CTL* existential quantificationatomic propositions (EGCTL*) examines complexity model checking satisfiabilitynew logic. remark AE-LTL seen subset EGCTL*. Indeed,according Theorem 10, -labelled tree satisfies AE-LTL formula .satisfies EGCTL* formula w.[[.]].following definition show transform parity tree automatonCTL* formula [[.]] parity tree automaton AE-LTL formula ..transformation performed abstracting away information w-markinginput alphabet transition relation tree automaton.Definition 19 Let = h{w, w}, D, Q, q0 , , parity tree automaton. paritytree automaton Aw = h, D, Q, q0 , w , i, obtained abstracting away wmarking, defined follows: w (q, , d) = (q, (, w), d) (q, (, w), d).Lemma 11 Let Aw two parity tree automata Definition 19. Aw acceptsexactly -labelled trees w-marking accepted A.Proof. Let w ({w, w})-labelled tree let corresponding -labelledtree, obtained abstracting away w-marking. show w accepted A,accepted Aw . Let r : Q accepting run w A. r alsoaccepting run Aw . Indeed, x , arity(x) = d, w (x) = (, m){w, w}, hr(x 0), . . . , r(x d1)i (r(x), (, m), d). (x) = ,and, definition Aw , hr(x 0), . . . , r(x d1)i w (r(x), , d).show that, -labelled tree accepted Aw , ({w, w})labelled tree w w-marking accepted A. Let r : Qaccepting run Aw . definition run, know x , arity(x) =(x) = , hr(x 0), . . . , r(x d1)i w (r(x), , d). definition w ,know hr(x 0), . . . , r(x d1)i (r(x), (, w), d) (r(x), (, w), d). Let us definew (x) = (, w) hr(x 0), . . . , r(x d1)i (r(x), (, w), d), w (x) = (, w) otherwise.easy check r accepting run w A.123fiPistore & Vardiingredients defining tree automaton acceptstrees satisfy given AE-LTL formula.Definition 20 (tree automaton AE-LTL) Let N finite set arities,let . AE-LTL formula. parity tree automaton AD. obtained applyingtransformation described Definition 19 parity automaton AD[[.]] built accordingTheorem 2.Theorem 12 parity tree automaton AD. accepts exactly -labelled D-treessatisfy formula ..Proof. Theorem 2, parity tree automaton AD[[.]] accepts D-trees satisfyCTL* formula [[.]]. Therefore, parity tree automaton AD. accepts D-treessatisfy formula . Lemma 11 Theorem 10.parity tree automaton AD. parity index exponential numberstates doubly exponential length formula .2Proposition 13 parity tree automaton AD. 2O(||)states parity index 2O(||) .Proof. construction Definition 19 change number statesparity index automaton. Therefore, proposition follows Theorem 2.5.2 Planning Algorithmdescribe automaton AD. exploited order build plan goal. given domain.start defining tree automaton accepts trees define validplans planning domain = h, 0 , A, Ri. recall that, according Definition 8,transition relation R maps state action tuple next statesh1 , 2 , . . . , n = R(, a).following assume finite set arities compatible domainD, namely, R(, a) = h1 , . . . , A, D.Definition 21 (tree automaton planning domain) Let = h, 0 , A, Riplanning domain let set arities compatible domain D.tree automaton ADcorresponding planning domain AD = hA, D, , 0 , , 0 i,h1 , . . . , (, (, a), d) h1 , . . . , = R(, a) > 0, 0 () = 0.According Definition 10, (A)-labelled tree obtained plandomain D. show also converse true, namely, (A)-labelled treeaccepted tree automaton ADinduces plan.Definition 22 (plan induced tree) Let (A)-labelled tree accepted automaton AD. plan induced domain defined follows: (0 , 1 , . . . , n ) = finite path p (p) = (0 , a0 )(1 , a1 ) (n , ) = .124fiThe Planning Spectrum One, Two, Three, Infinityfollowing lemma shows Definitions 10 22 define one-to-one correspondence valid plans planning domain trees accepted automatonADD.Lemma 14 Let tree accepted automaton ADlet correspondinginduced plan. valid plan domain D, execution tree corresponding. Conversely, let plan domain let corresponding executionstructure. accepted automaton ADplan induced .Proof. lemma direct consequence Definitions 10 22.define parity tree automaton accepts trees correspondplans domain satisfy goal g = .. parity tree automaton obtainedcombining suitable way tree automaton AE-LTL formula g (Definition 20)tree automaton domain (Definition 21).Definition 23 (instrumented tree automaton) Let set arities compatible planning domain D. Let also ADg = h, D, Q, q0 , , parity tree automaton accepts trees satisfy AE-LTL formula g. parity treeautomaton ADD,g corresponding planning domain goal g defined follows:AD,g = hA, D, Q, (q0 , 0 ), 0 , 0 i, h(q1 , 1 ), . . . , (qd , )i 0 ((q, ), (, a), d)hq1 , . . . , qd (q, , d) h1 , . . . , = R(, a) > 0, 0 (q, ) = (q).following lemmas show solutions planning problem (D, g) one-to-onecorrespondence trees accepted tree automaton ADD,g .Lemma 15 Let (A)-labelled tree accepted automaton ADD,g , letplan induced domain D. plan solution planning problem(D, g).Proof. According Definition 11, prove execution tree correspondingsatisfies goal g. Lemma 14, amounts proving tree satisfies g.construction, easy check (A)-labeled tree accepted ADD,g ,also accepted Ag . Indeed, rD,g : Q accepting run ADD,g ,rg : Q accepting run Ag , rg (x) = q whenever rD,g = (q, ).Lemma 16 Let solution planning problem (D, g). execution treeaccepted automaton ADD,g .Proof. Let execution tree . Lemma 14 know accepted ADD.Moreover, definition solution planning problem, know accepted alsoADg . construction, easy check (A)-labeled tree acceptedAD ADg , also accepted AD,g . Indeed, let rD : acceptingrun ADlet rg : Q accepting run Ag . rD,g : Qaccepting run AD,g , rD,g (x) = (q, ) rD (x) = rg (x) = q.125fiPistore & Vardiconsequence, checking whether goal g satisfied domain reducedproblem checking whether automaton ADD,g nonempty.Theorem 17 Let planning domain g AE-LTL formula. plan existsgoal g domain tree automaton ADD,g nonempty.Proposition 18 parity tree automaton ADD,g domain = (, 0 , A, R) goalg = . || 22O(||)states parity index 2O(||) .Proof. consequence Proposition 13 definition automaton ADD,g .5.3 Complexitystudy time complexity planning algorithm defined Subsection 5.2.Given planning domain D, planning problem AE-LTL goals g = .decided time doubly exponential size formula applyingTheorem 1 tree automaton ADD,g .Lemma 19 Let planning domain. existence plan AE-LTL goal g = .O(||)domain decided time 22.Proof. Theorem 17 existence plan goal g domain reducedemptiness problem parity tree automaton ADD,g . Proposition 18, parity treeO(||)2automaton AD|| states parity index 2O(||) . Since assumeD,g 2domain fixed, Theorem 1, emptiness automaton ADD,g decided time22O(||).doubly exponential time bound tight. Indeed, realizability problemLTL formula , known 2EXPTIME-complete (Pnueli & Rosner, 1990),reduced planning problem goal A.. realizability problem one assumesprogram environment alternate control evolution system.precisely, execution 0 , 1 , . . . states decided programeven, environment odd. say given formula realizableprogram executions satisfy independently actionsenvironment.Theorem 20 Let planning domain. problem deciding existence planAE-LTL goal g = . domain 2EXPTIME-complete.Proof. realizability formula reduced problem checking existence plan goal A. planning domain = {init} ( {p, e}), init, {e}, R ,with:R(init, 0 ) = {( 0 , e)}0R(init, e) =0R((, p), ) = {( , e)}R((, p), e) =0R((, e), e) = {( 0 , p) : 0 }R((, e), ) =126fiThe Planning Spectrum One, Two, Three, Infinity, 0 .States (, p) program controls evolution actions 0 .States (, e) environment controls evolution; nondeterministic action e performed state. Finally, state init used assign initialmove program.Since realizability problem 2EXPTIME-complete size LTL formula(Pnueli & Rosner, 1990), planning problem 2EXPTIME-hard size goalg = .. 2EXPTIME-completeness follows Lemma 19.remark that, case goals form E., algorithm bettercomplexity defined. case, plan exists E.infinite sequence 0 , 1 , . . . states satisfies i+1 R(i , ai )action ai . is, planning problem reduced model checking problemLTL formula , problem known PSPACE-complete (Sistla & Clarke,1985). conjecture that, canonical path quantifiers except E, doublyexponential bound Theorem 20 tight.remarks order complexity satisfiability validity problemsAE-LTL goals. problems PSPACE-complete. Indeed, AE-LTL formula. satisfiable LTL formula satisfiable6 , latter problemknown PSPACE-complete (Sistla & Clarke, 1985). similar argument holds alsovalidity.complexity model checking problem AE-LTL recently addressedKupferman Vardi (2006). Kupferman Vardi introduce mCTL*, variantCTL*, path quantifiers memoryful interpretation. show memoryful quantification express (with linear cost) semantics path quantifiersAE-LTL. example, AE-LTL formula AE. expressed mCTL* formulaAG E . Kupferman Vardi show model checking problem new logicEXPSPACE-complete, result holds also subset mCTL* corresponds formulas AE.. Therefore, model checking problem AE-LTL finitepath quantifiers also EXPSPACE-complete. best knowledge complexitymodel checking AE-LTL formulas (AE) . (EA) . still open problem.6. Two Specific Cases: Reachability Maintainability Goalssection consider two basic classes goals particularly relevantfield planning.6.1 Reachability Goalsfirst class goals reachability goals corresponding LTL formula F q,q propositional formula. literature planning concentratesclass goals, several works address problem defining plansdifferent strength kind goals (see, e.g., Cimatti et al., 2003 citations).6. tree satisfies . paths satisfy , path satisfies seen alsotree satisfies ..127fiPistore & Vardicontext AE-LTL, soon player E takes control, immediately achievereachability goal possible all. fact control given back playergoal achieved irrelevant. Therefore, significant path quantifiersreachability goals A, E, AE.Proposition 21 Let q propositional formula atomic propositions Prop. Then,following results hold every labelled tree . |= E. F q iff |= EA. F q iff |= EAE. F qiff |= (EA) . F q. Moreover |= AE. F q iff |= AEA. F q iff |= (AE) . F q.Proof. prove |= AE. F q iff |= AEA. F q iff |= (AE) . F q. casessimilar.Let us assume |= AE. F q. Moreover, let p finite path . know pextended infinite path p0 (p0 ) |= F q. According semanticsLTL, (p0 ) |= F q means node x path p0 q (x). Clearly,infinite paths contain node x also satisfy LTL formula F q. Therefore,finite extension p00 p infinite extensions p00 satisfy LTLformula F q: sufficient take p00 finite extension p contains node x. Sinceproperty holds every finite path p, conclude |= AEA. F q.proven |= AE. F q implies |= AEA. F q. Theorem 9 knowAEA(AE)AE, hence |= AEA. F q implies |= (AE) . F q implies |= AE. F q.concludes proof.following diagram shows implications among significant path quantifiersreachability goals:(3)/o /o /o / AE /o /o /o / Eremark three goals A. F q, E. F q, AE. F q correspond, respectively,strong, weak, strong cyclic planning problems Cimatti et al. (2003).6.2 Maintainability Goalsconsider another particular case, namely maintainability goals G q, qpropositional formula. Maintainability goals properties complementaryproperties reachability goals. case, soon player takes control,violate maintainability goal possible all. fact player E take controlplayer hence irrelevant, interesting path quantifiers A, E,EA.Proposition 22 Let q propositional formula atomic propositions Prop. Then,following results hold every labelled tree . |= A. G q iff |= AE. G q iff |=AEA. G q iff |= (AE) . G q. Moreover |= EA. G q iff |= EAE. G q iff |= (EA) . G q.Proof. proof similar proof Proposition 21.following diagram shows implications among significant path quantifiersmaintainability goals:/o /o /o / EA /o /o /o / E128fiThe Planning Spectrum One, Two, Three, Infinitygoals A. G q, E. G q, EA. G q correspond maintainability variants strong, weak,strong cyclic planning problems. Indeed, correspond requiring condition qmaintained evolutions despite nondeterminism (A. G q), condition q maintainedevolutions (E. G q), possible reach state conditionq always maintained despite nondeterminism (EA. G p).7. Related Works Concluding Remarkspaper defined AE-LTL, new temporal logic extends LTLpossibility declaring complex path quantifiers define different degreesLTL formula satisfied computation tree. propose use AE-LTL formulasexpressing temporally extended goals nondeterministic planning domains.defined planning algorithm AE-LTL goals based automata-theoreticframework: existence plan reduced checking emptiness suitable paritytree automaton. studied time complexity planning algorithm, proving2EXPTIME-complete length AE-LTL formula.field planning, several works use temporal logics defining goals.approaches (Bacchus & Kabanza, 1998, 2000; Calvanese et al., 2002; Cerrito & Mayer,1998; de Giacomo & Vardi, 1999; Kvarnstrom & Doherty, 2001) use linear temporal logicsgoal language, able express conditions degree goalsatisfied respect nondeterminism execution. Notable exceptionsworks described Pistore, Bettin, Traverso (2001), Pistore Traverso (2001)Dal Lago et al. (2002). Pistore et al. (2001) Pistore Traverso (2001) use CTLgoal language, Dal Lago et al. (2002) define new branching time logic allowsexpressing temporally extended goals deal explicitly failure recoverygoal achievement. goal languages, however, path quantifiers interleavedtemporal operators, hence rather different AE-LTL.field temporal logics, work alternating temporal logic (ATL) (Alur,Henzinger, & Kupferman, 2002) related work. ATL, path quantifiersCTL CTL* replaced game quantifiers. Nevertheless, obvious wayexpressed formulas form ., path quantifier LTL formulaATL , expressive logic studied Alur et al. (2002). conjecturelogic ATL incomparable expressiveness.comments order practical impact 2EXPTIME complexityplanning algorithm. First all, many planning problems expectcomplex large domains, goals relatively simple (see, e.g., experimentalevaluation performed Pistore et al. (2001) case planning goals expressed CTLformulas). cases, doubly exponential complexity algorithm sizeformula may bottleneck. larger AE-LTL goals, doubly exponential timecomplexity may feasible, noted worst-case complexity.also note improved algorithms plan synthesis active research area, includinganalysis simpler LTL goals (Alur & La Torre, 2004) development improvedautomata-theoretic algorithms (Kupferman & Vardi, 2005).automata-theoretic framework used paper wider applicability AE-LTL goals. interesting direction future investigations application129fiPistore & Vardiframework variants AE-LTL allow nesting path quantifiers,goals combine AE-LTL propositional temporal operators. would allow,instance, specify goals compose requirements different strength. simpleexample goals (AE. F p)(A. G p), requires achieve condition p strongcyclic way, maintaining condition q strong way. impossibility define kindgoals is, opinion, strongest limitation AE-LTL respect CTLCTL*.Another direction future investigations extension approach proposedpaper case planning partial observability (de Giacomo & Vardi, 1999),one assumes agent executing plan observe part statehence choices actions execute may depend part.also plan explore implementation issues and, particular, possibilityexploiting BDD-based symbolic techniques planning algorithm AE-LTL goals.cases, techniques shown able deal effectively domainsgoals significant complexity, despite exponential worst-case time complexityproblems (Bertoli, Cimatti, Pistore, Roveri, & Traverso, 2001; Pistore et al., 2001).Acknowledgmentsshorter version paper, without proofs, published Pistore Vardi(2003). authors would like thank Erich Gradel comments reductionAE-LTL formulas CTL* formulas.ReferencesAlur, R., Henzinger, T., & Kupferman, O. (2002). Alternating-time temporal logic. JournalACM, 49 (5), 672713.Alur, R., & La Torre, S. (2004). Deterministic generators games LTL fragments.ACM Trans. Comput. Log., 5 (1), 125.Bacchus, F., & Kabanza, F. (1998). Planning temporally extended goals. Ann.Mathematics Artificial Intelligence, 22, 527.Bacchus, F., & Kabanza, F. (2000). Using temporal logic express search control knowledgeplanning. Artificial Intelligence, 116 (1-2), 123191.Bertoli, P., Cimatti, A., Pistore, M., Roveri, M., & Traverso, P. (2001). MBP: ModelBased Planner. Proc. IJCAI01 workshop Planning UncertaintyIncomplete Information.Berwanger, D., Gradel, E., & Kreutzer, S. (2003). upon time West - Determinacy, definability, complexity path games. Prof. 10th Int. Conf LogicProgramming, Artificial Intelligence, Reasoning (LPAR03), pp. 229243.Calvanese, D., de Giacomo, G., & Vardi, M. (2002). Reasoning actions planningLTL action theories. Proc. 8th Int. Conf. Principles KnowledgeRepresentation Reasoning (KR02), pp. 593602.130fiThe Planning Spectrum One, Two, Three, InfinityCerrito, S., & Mayer, M. (1998). Bounded model search linear temporal logicapplication planning. Proc. 2nd Int. Conf. Analytic Tableaux RelatedMethods (TABLEAUX98), Vol. 1397 LNAI, pp. 124140. Springer Verlag.Cimatti, A., Pistore, M., Roveri, M., & Traverso, P. (2003). Weak, strong, strong cyclicplanning via symbolic model checking.. Artificial Intelligence, 147 (1-2), 3584.Dal Lago, U., Pistore, M., & Traverso, P. (2002). Planning language extendedgoals. Proc. 18th National Conf. Artificial Intelligence (AAAI02). AAAIPress.Daniele, M., Traverso, P., & Vardi, M. (1999). Strong cyclic planning revisited. Proc.5th European Conf. Planning (ECP99), Vol. 1809 LNAI, pp. 3548. SpringerVerlag.de Giacomo, G., & Vardi, M. (1999). Automata-theoretic approach planning temporally extended goals. Proc. 5th European Conf. Planning (ECP99), Vol.1809 LNAI, pp. 226238. Springer Verlag.Emerson, E. A. (1990). Temporal modal logic. van Leeuwen, J. (Ed.), HandbookTheoretical Computer Science, Volume B: Formal Models Semantics. Elsevier.Emerson, E., & Jutla, C. (1988). complexity tree automata logics programs.Proc. 29th IEEE Symp. Foundations Computer Science, pp. 328337.Emerson, E., & Jutla, C. (1991). Tree automata, -calculus determinacy. Proc.32nd IEEE Symp. Foundations Computer Science, pp. 368377.Fikes, R., & Nilsson, N. (1971). STRIPS: new approach application theoremproving problem solving. Artificial Intelligence, 2 (3-4), 189208.Ghallab, M., Nau, D., & Traverso, P. (2004). Automated Planning: Theory Practice.Elsevier.Kupferman, O. (1999). Augmenting branching temporal logics existential quantification atomic propositions. Journal Logic Computation, 9 (2), 135147.Kupferman, O., & Vardi, M. (2005). Safraless decision procedures. Proc. 46th IEEESymp. Foundations Computer Science (FOCS05), pp. 531542. IEEE ComputerSociety.Kupferman, O., & Vardi, M. (2006). Memoryful branching-time logic. Proc.21th IEEE Symposium Logic Computer Science (LICS 2006). IEEE ComputerSociety.Kupferman, O., Vardi, M., & Wolper, P. (2000). automata-theoretic approach branching time model checking. Journal ACM, 47 (2).Kvarnstrom, J., & Doherty, P. (2001). TALplanner: temporal logic based forward chainingplanner. Ann. Mathematics Artificial Intelligence, 30, 119169.Moller, F., & Rabinovich, A. (1999). expressive power CTL*. Proc. 14thAnnual IEEE Symposium Logic Computer Science (LICS99), pp. 360369.IEEE Computer Science Press.131fiPistore & VardiPenberthy, J., & Weld, D. (1992). UCPOP: sound, complete, partial order plannerADL. Proc. 3rd Int. Conf. Principles Knowledge RepresentationReasoning (KR92).Peot, M., & Smith, D. (1992). Conditional nonlinear planning. Proc. 1st Int. Conf.AI Planning Systems (AIPS92), pp. 189197. Morgan Kaufmann Publisher.Pistore, M., Bettin, R., & Traverso, P. (2001). Symbolic techniques planningextended goals non-deterministic domains. Proc. 6th European Conf.Planning (ECP01).Pistore, M., & Traverso, P. (2001). Planning model checking extended goals nondeterministic domains. Proc. 17th Int. Joint Conf. Artificial Intelligence(IJCAI01). AAAI Press.Pistore, M., & Vardi, M. (2003). planning specturm one, two, three, infinity.Proc. 18th IEEE Symposium Logic Computer Science (LICS 2003), pp.234243.Pnueli, A., & Rosner, R. (1990). Distributed reactive systems hard synthesize.Proc. 31st IEEE Symp. Foundation Computer Science, pp. 746757.Sistla, A., & Clarke, E. (1985). complexity propositional linear temporal logic.Journal ACM, 32, 733749.Warren, D. (1976). Generating conditional plans programs. Proc. SummerConf. Artificial Intelligence Simulation Behaviour (AISB76), pp. 344354.132fiJournal Artificial Intelligence Research 30 (2007) 213-247Submitted 12/06; published 10/07Compressed Pattern DatabasesAriel Felnerfelner@bgu.ac.ilDepartment Information Systems Engineering,Ben-Gurion University NegevBeer-Sheva, Israel, 85104Richard E. Korfkorf@cs.ucla.eduDepartment Computer ScienceUniversity California Los AngelesLos Angeles, CA, 90095Ram Meshulammeshulr1@cs.biu.ac.ilDepartment Computer ScienceBar-Ilan UniversityRamat-Gan, Israel, 52900Robert Holteholte@cs.ualberta.ac.caDepartment Computing ScienceUniversity AlbertaEdmonton, CanadaAbstractpattern database (PDB) heuristic function implemented lookuptable stores lengths optimal solutions subproblem instances.Standard PDBs distinct entry table subproblem instance.paper investigate compressing PDBs merging several entriesone, thereby allowing use PDBs exceed available memoryuncompressed form. introduce number methods determiningentries merge discuss relative merits. vary domainindependent approaches allow set entries PDB merged,intelligent methods take account structure problem.choice best compression method based domain-dependentattributes. present experimental results number combinatorialproblems, including four-peg Towers Hanoi problem, sliding-tilepuzzles, Top-Spin puzzle. Towers Hanoi, showsearch time reduced three orders magnitude usingcompressed PDBs compared uncompressed PDBs size.modest improvements observed domains.1. Introduction OverviewHeuristic search algorithms A* (Hart, Nilsson, & Raphael, 1968) IDA* (Korf,1985) find optimal solutions state space search problems. guided costfunction f (n) = g(n) + h(n), g(n) cost reaching node n initial state,h(n) heuristic function estimates cost reaching goal state nodec2007AI Access Foundation. rights reserved.fiFelner, Korf, Meshulam, & Holten. h(n) admissible, means never overestimates actual cost,algorithms guaranteed find optimal solution path one exists.Pattern databases admissible heuristic functions implemented lookup tables storedmemory (Culberson & Schaeffer, 1998). best known heuristics numbercombinatorial problems. paper investigate idea compressing patterndatabase heuristics order improve accuracy heuristics, given amountmemory.begin describing three different problem domains used paper, orderground discussion concrete examples.1.1 Problem Domains1.1.1 4-peg Towers HanoiFigure 1: Five-disc four-peg Towers Hanoi problemwell-known three-peg Towers Hanoi problem consists three pegs n discsdifferent sizes initially stacked decreasing order size one peg.task transfer discs initial peg goal peg. top discpeg moved, larger disc never placed top smaller disc.three-peg problem, simple recursive algorithm provably returns optimalsolution. idea move n 1 smallest discs intermediate peg, movelargest disc initial peg goal peg, finally move n 1 smallestdiscs intermediate peg goal peg.four-peg Towers Hanoi problem (TOH4), (Hinz, 1997) shown Figure 1,interesting. recursive algorithm three-peg problem doesnt yield optimalsolutions, two intermediate pegs, dont know prioridistribute n1 smallest discs intermediate pegs optimal solution.exists deterministic algorithm finding solution, conjecture generatesoptimal solution (Frame, 1941; Stewart, 1941), conjecture remains unproven(Dunkel, 1941). Thus, systematic search currently method guaranteed findoptimal solutions problems given number discs.1.1.2 Sliding-Tile PuzzlesOne classic domains AI literature sliding-tile puzzle. Three commonversions puzzle 3x3 8-puzzle, 4x4 15-puzzle 5x5 24-puzzle.consists square frame containing set numbered square tiles, empty positioncalled blank. legal operators slide tile horizontally vertically214fiCompressed Pattern Databases12351234678912456710 11 12 13 143458910 1115 16 17 18 1967812 13 14 1520 21 22 23 24Figure 2: 8-, 15- 24-puzzle goal statesadjacent blank blank position. problem rearrange tilesrandom initial configuration particular desired goal configuration. 8-puzzlecontains 181,440 reachable states, 15-puzzle contains 1013 reachable states,24-puzzle contains almost 1025 reachable states. traditional goal states puzzlesshown Figure 2.1.1.3 Top-Spin PuzzleReversecircle1819 20 1234171651561471312 11 10 98Figure 3: (20,4)-Top-Spin Puzzle(n,r)-Top-Spin puzzle n tokens arranged ring. ring tokensshifted cyclically clockwise counterclockwise. tokens pass reverse circlefixed top ring. given time r tokens located inside reversecircle. tokens reversed (rotated 180 degrees). task rearrangepuzzle tokens sorted increasing order. (20,4) version puzzleshown figure 3 goal position tokens 19, 20, 1 2 reverse circlereversed. encoding puzzle N operators, one clockwisecircular shift length 0 . . . N 1 entire ring followed reversal/rotationtokens reverse circle. operator cost one. encodinganalyzed (Chen & Skiena, 1996). Practically, puzzle implemented cyclic215fiFelner, Korf, Meshulam, & Holtebuffer operator reverses set r consecutive tokens1 . Note n!different possible ways permute tokens. However, since puzzle cyclic,relative location different tokens matters, thus (n 1)! differentunique states.1.2 Pattern Database HeuristicsHeuristics typically implemented functions states domain nonnegative number. example, well-know heuristic sliding-tile puzzlesManhattan distance. computed determining tile minimum distancegrid units must travel reach goal location, summing valuestiles except blank. lower bound optimal solution length, tilemust move least Manhattan distance, move moves one tile.Pattern databases (PDBs) heuristics form lookup tables. pattern database stores memory cost optimal solution instance subproblemoriginal problem. costs used admissible heuristics originalproblem. PDBs used lower bounds combinatorial puzzles (Culberson &Schaeffer, 1998; Korf, 1997; Korf & Felner, 2002; Felner, Korf, & Hanan, 2004a; Felner,Meshulam, Holte, & Korf, 2004b), multiple sequence alignment (Zhou & Hansen, 2004; McNoughtton, Lu, Schaeffer, & Szafron, 2002; Schroedl, 2005; Edelkamp & Kissmann, 2007),vertex cover (Felner et al., 2004a), planning problems (Edelkamp, 2001).example, consider four-peg Towers Hanoi problem 15 discs.ignore 15 discs, 415 = 230 different possible configurations15 discs. imagine array contains entry possible configuration15 discs, whose value exact number moves required optimally solvecorresponding 15-disc problem instance. Note doesnt matter discs choose,since absolute sizes dont matter. long different sizesrelative size matters. entry fit byte memory, table occupy exactlyone gigabyte memory. example PDB.build PDB, execute complete breadth-first search starting 15 discsgoal peg. configuration encountered first time, store searchdepth corresponding entry PDB. PDB given size built once,reused solve multiple problem instances goal state.use PDB heuristic solve four-peg Towers Hanoi problem15 discs. state encountered search, look configurationgiven subset 15 discs PDB, use stored value heuristic fullstate. Since value number moves needed get subset 15 discsgoal peg, lower bound total number moves needed get discsproblem goal peg.1.3 Compressed Pattern Databasessize PDB number entries contains. general, larger PDB is,accurate is, efficient search algorithm using heuristic is.1. physical puzzle, first rotate ring tokens reverse circle.216fiCompressed Pattern Databasesexample, solving TOH4 problem 20 discs, values PDB based20 discs accurate based 15 discs. drawback large PDBs,however, amount memory consume.main idea paper compress PDBs large fit memoryuncompressed form size fit memory. compressing donepartitioning original PDB groups entries. group entries originalPDB mapped single entry compressed PDB. order preserve admissibility,value stored compressed PDB minimum among valuesgroup original PDB.example, given PDB four-peg Towers Hanoi problem based 20 discs,divide discs 15 largest discs 5 smallest discs. partitionPDB entries 415 groups entries based positions 15 largest discs.group 45 = 1024 different entries correspond differentpositions 5 smallest discs. compressed PDB store one entrygroups. entry compressed PDB correspond different configuration15 largest discs, value minimum value configurations5 smallest discs original PDB, order preserve admissibility.Note general, values compressed PDB much larger henceaccurate corresponding values simple 15-disc PDB, despite facttwo databases size. reason entry simple 15disc PDB number moves needed solve corresponding 15-disc problem,whereas entry compressed PDB minimum number moves neededsolve instance 20-disc problem 15 largest discs one particularconfiguration.1.4 Overviewprimary questions address paper make best use givenamount memory compressed PDBs, determine entries PDBcompress. Specifically make following contributions:introduce number methods compressing PDBs. methods varygeneral methods constrained methods. general methods often resultsignificant loss information, methods rely structureunderlying problem space necessarily domain specific.show best compression methods often domain dependent, provideguidelines choosing promising method given domain. Experiments4-peg Towers Hanoi, sliding-tile puzzles Top-Spin puzzle showgiven amount memory search effort many times reducedusing compressed PDBs using uncompressed PDB size.also describe methods generating PDBs using external memory compressing size available memory.paper organized follows. first provide definitions used throughout paper. consider build PDBs, particular, build com217fiFelner, Korf, Meshulam, & Holtepressed PDBs original PDB wont fit memory. discuss differentcompressing methods. Next, present experimental results Towers Hanoi,sliding-tile puzzles Top-Spin Problem. Finally offer conclusions.preliminary version paper appeared earlier (Felner et al., 2004b).2. Definitionsbegin providing abstract characterization search spaces combinatorial problems, sufficient structure define PDBs associated constructs. definitionsused throughout paper.2.1 Combinatorial Problems Vectors State Variablesproblem space usually described abstractly set atomic states, setoperators map states states. corresponds labeled graph, called problemspace graph. addition, specific problem instance problem space togetherparticular initial state (set of) goal state(s). task find optimal pathinitial state goal state.state combinatorial problem described vector state variables,assigned particular value. domains studied paper, variablescorrespond different objects problem, values correspond differentlocations occupy. example, Towers Hanoi problem,variable disc, value indicates peg disc on. slidingtile puzzles, variable physical tile one blank, valueindicates position occupied tile. Top-Spin puzzle, variabletoken, whose value indicates position. convenience, paper, oftenrefer variables objects, values locations, general latterterms simply convenient synonyms variables values, respectively. sizeproblem space number distinct legal combinations value assignmentsvariables reachable given initial state.combinatorial problem permutation problem number values equalsnumber variables, value assigned one variable. example,Top-Spin sliding-tile puzzles permutation problems locationoccupied one object. Towers Hanoi permutation problempeg hold one disc.operator formulation partial function state vector state vector.operator changes values variables. Note number variablesvalues changed might different different domains even differentoperators domain. Towers Hanoi, value one variablechanged operator, since one disc moves time. sliding-tile puzzlestwo variables change values operator, one physical tile blankexchange locations move. Top-Spin, values four variables changed sincefour tokens change locations.goal specified state set states. permutation problems,sliding-tile puzzles Top-Spin, goal state usually canonical state object218fiCompressed Pattern Databaseslocation i. standard goal state Towers Hanoi discssingle goal peg, thus state variables value.2.2 Pattern DatabasesGiven vector state variables, set operators, subset variables definessubproblem assign values variables subset, called pattern variables,values remaining variables treated dont cares. example,Towers Hanoi, subproblem would include subset discs.pattern specific assignment values pattern variables. example,pattern might particular configuration subset discs.pattern space set different reachable patterns given subproblem.example, pattern space four-peg Towers Hanoi subproblem P patternvariables includes different possible assignments P discs pegs,size 4P . permutation problems n elements P pattern variables, patternspace typically n (n 1) . . . (n P + 1) states.state original state space projected onto pattern pattern spaceconsidering pattern variables, ignoring variables. refer setstates project pattern states pattern.goal pattern projection goal state onto pattern variables. Multiple goalstates may give rise multiple goal patterns, single goal pattern.edge two different patterns p1 p2 pattern spaceexist two states s1 s2 original problem, p1 projections1 , p2 projection s2 , operator original problem spaceconnects s1 s2 .2 effect operator patterns called pattern move.distance two patterns pattern space number edges patternmoves shortest path two patterns.distance two patterns p1 p2 pattern space therefore lowerbound shortest distance pair states s1 s2 p1projection s1 p2 projection s2 .pattern database (PDB) lookup table includes entry patternpattern space. value stored pattern distance patternpattern space goal pattern. PDB value stored given pattern thereforeadmissible heuristic states project onto pattern.3. Building Pattern Databasesgeneral, PDB built running breadth-first search pattern space backwardsgoal pattern entire pattern space spanned. However, since operatorsproblem apply states original problem, patterns directly,building PDB slightly different different domains.Towers Hanoi problem, simply ignore non-pattern discs. words,P discs pattern, simply search Towers Hanoi problem spaceP discs. state, keep track depth breadth-first search.2. sometimes called edge homomorphism.219fiFelner, Korf, Meshulam, & Holtesliding-tile puzzles, keep track blank position, evenincluded pattern, order determine whether move legal not. Thus,state search uniquely determined positions pattern tilesblank. equivalent problem space includes tiles,non-pattern non-blank tiles indistinguishable other.original application PDBs sliding-tile puzzles (Culberson & Schaeffer,1998), moves counted PDB values. drawback approachmultiple PDBs, way combine values without sacrificing admissibilitytake maximum value. Additive pattern databases (Korf & Felner, 2002) allow ussum values multiple pattern databases without violating admissibility, mucheffective applicable. order construct additive pattern databasessliding-tile puzzles, count moves pattern tiles, ignore movesnon-pattern tiles. adopt approach here.Top-Spin, goal put tokens correct cyclic order, representation linear rather cyclic. reconcile two different representations,always keep token one location one. operator moves token one, immediatelyfollowed cyclic shift tokens restore token one location one, additional cost. pattern doesnt include token one, must keep track positiontoken one, order correctly implement shifts. state, storenumber moves involve least one pattern token, either reversal,subsequent shift restore token one position one. example, reversal changesposition token one, counted pattern move even reversal doesntinclude pattern tokens, pattern tokens move subsequent cyclicshift tokens.pattern first generated, number pattern moves needed reachstate stored corresponding entry PDB. PDB needs builtspecific goal state.3.1 Mapping Patterns PDB IndicesPDBs sometimes implemented sophisticated data structures lexicographictrees (Felner et al., 2004a) octrees (McNoughtton et al., 2002). addition, symbolicpattern databases (Edelkamp, 2002) based binary decision diagrams (BDDs) (Dunkel,1992). Nevertheless, PDBs commonly implemented arrays entries,storing heuristic value specific pattern. Thus, simplicity, paper assumePDBs implemented arrays.save memory, want avoid store patterns alongheuristic values. done representing pattern unique indexPDB. particular mapping patterns indices domain specific.example, state Towers Hanoi problem uniquely representedspecifying peg disc on, since discs peg must sortedorder size. four-peg problem, peg specified two bits, completeproblem state uniquely specified string 2n bits, n numberdiscs. Furthermore, every bit string represents legal state problem.220fiCompressed Pattern Databasespermutation problems, two obvious ways store PDB k variables- sparse mapping compact mapping.sparse mapping - simplest organization k-dimensional array,dimension range 0 n 1. individual pattern mappedtable taking value pattern variable separate index array.example, pattern three variables (X,Y,Z), whose values (2,1,3)respectively, would mapped array element A[2][1][3]. total sizearray configurations k elements nk . called sparse mapping.advantage sparse mapping simple implement indicesefficiently computed. disadvantage efficient termsspace, since wastes entries two equal indices, since entriescorrespond valid configuration.compact mapping - Another method indexing PDBs permutation problemscalled compact mapping. particular, permutation k elementsn possible locations mapped bijectively unique index range 0n n 1 . . . n k + 1. One mapping maps permutationindex lexicographic ordering permutations. example, assumingk = n = 3, permutation (2 1 3) mapped third index, since preceded(1 2 3) (1 3 2) lexicographic order. advantage compact mappingwaste space. disadvantage computing indicescomplex. (Myrvold & Ruskey, 2001) provide linear-time algorithms bijectivemappings permutations integers, (Korf & Shultze, 2005) providelinear-time algorithms index permutation represents positionlexicographic order. least experiments (reported below), evenadvanced mapping algorithm, access time sparse mapping fastercompact mapping counterpart.worth noting memory savings compact mapping sparsemapping decreases number variables domain increases beyond numberelements PDB. example, consider 6-tile PDB 24 Puzzle. Sparse mappingrequires 256 = 244 106 entries, compact mapping uses 25 24 . . . 20 =128 106 entries. Indeed, since memory savings modest, sparse mappingsimpler often used implement 6-tile PDBs (Korf & Felner, 2002; Felneret al., 2004a; Felner, Zahavi, Holte, & Schaeffer, 2005; Zahavi, Felner, Holte, & Schaeffer,2006). Similarly, sparse mapping also used implement 5-tile PDBs 35puzzle (Felner et al., 2004a).3.2 Building Large Pattern DatabasesCompressed PDBs used isnt sufficient memory store uncompressedPDBs. raises question generate compressed PDB without exhaustingmemory first place.Consider PDB four-peg Towers Hanoi problem example. Since stateuniquely represented bit string index length 2n, heuristic values221fiFelner, Korf, Meshulam, & Holtestored. use unsigned character array, store values 255 one byte,sufficient maximum number moves needed solve problem18-discs (Korf, 2003). Thus, 15-disc PDB, PDB compressed size 15-discPDB, would occupy 415 bytes, gigabyte memory. 16-disc PDB would need fourgigabytes, however. Given machine two gigabytes memory, example,generate 16-disc PDB compressed size 15-disc PDB?generate PDB, must perform complete breadth-first search 16-discproblem space, starting standard goal state. state generated, largest15 discs used index PDB, entry empty, search depthstored. breadth-first search normally implemented first-in first-out queuenodes generated, yet expanded. Initially, goal state placedqueue, step remove expand node head queue,append children tail queue. keep track search depthplacing marker queue nodes successive depths. maximum sizequeue determined maximum number nodes depth search.example, 16-disc problem, number 162, 989, 898 nodes depth 134 (Korf,2003). Since state 16-disc problem stored 32 bits, queue requires651, 959, 592 bytes, 622 megabytes memory.order breadth-first search terminate, however, able detectwhether encountered particular state before. efficient waystore bit array, one bit state, initialized zeros. Whenever statefirst encountered, corresponding bit set one. Whenever generate node,check bit, discard node bit already set one. 16-disc problemneed 416 bits, 512 megabytes array.622 megabytes queue, plus 512 megabytes bit array, one gigabytepattern database exceeds capacity two gigabyte machine. cant usePDB replace bit array, PDB entry represents four different states16-disc problem, separately detectable.case compressing 16-disc PDB, solution simple. Since breadth-firstsearch queue FIFO, accesses sequential, efficiently storedmagnetic disk instead memory. simple implementation keep two different files,one nodes current depth, nodes next depth. first fileread sequentially, children appended tail second file. firstfile exhausted end current search depth, second file becomes newfirst file, another file created children next depth. Moving queuedisk creates enough space store bit array PDB memory.Unfortunately, wont work compressing larger PDBs. example, completebreadth-first search 17-disc problem require two megabytes bitarray. bit array cannot stored disk, accessed randomly, randomaccess byte disk requires average 5 milliseconds latency.Techniques delayed duplicate detection developed performing largebreadth-first searches disk, without storing bit state memory (Munagala &Ranade, 1999; Korf, 2003, 2004; Korf & Shultze, 2005). key idea immediatelycheck node see previously generated, delay duplicate detectionlarge numbers duplicates eliminated sequentially accessing nodes222fiCompressed Pattern Databasesdisk. Using techniques, complete breadth-first searches performedfour-peg Towers Hanoi problem 22 discs (Korf & Felner, 2007).Breadth-first search delayed duplicate detection performed using relativelylittle memory, allowing compressed PDB built memory time. However,technique efficient memory. Thus, alternative, buildcompressed PDB two phases.first phase performs breadth-first search disk, without compressed PDBmemory. phase, state expanded, write another disk fileordered pair consisting index state compressed PDB, followeddepth breadth-first search. file simply linear list pairs,written sequentially. Note depths file sorted order.second phase, build compressed PDB memory, sequentially readingfile. ordered pair, look index PDB. empty, storecorresponding depth PDB, full, simply ignore ordered pair.Finally, write compressed PDB disk use future searches, delete fileordered pairs. scheme allows us use almost memory breadth-firstsearch, regardless size compressed PDB.4. Compressing Pattern Databasesprevious studies, PDBs one entry pattern pattern space.section, describe different methods compressing PDBs merging numberPDB entries single entry. order preserve admissibility, merged entrystore minimum value entries merged, consequent loss informationoriginal entries larger values minimum.idea compress large tables smaller size merging several entries togethersuggested past outside AI community, e.g., form bit-statehashing (Bloom, 1970) form hash compaction (Stern & Dill., 1995).ideal compression scheme would group together entries value.would preserve information, result PDB whose size numberdistinct values original PDB. course, almost impossible achievepractice.compress PDB factor k, typically partition entire pattern spaceM/k sets k patterns each, size original PDB. compressedPDB contain one entry set. key making method effectivevalues stored original PDB k entries close one anotherpossible minimize resulting loss information. One questions addressedpaper identify PDB entries similar values merged.4.1 Compressing Nearby Patternseffective heuristic identify PDB entries similar values compress entriescorrespond patterns close together pattern space. Assume twopatterns p1 p2 close pattern space, meaning distancesmall. Furthermore, assume operators reversible.distances p1 goal pattern p2 goal pattern (i.e., PDB values)223fiFelner, Korf, Meshulam, & Holtealso similar. formally:(d(p1 , p2 ) = c) = (|P DB(p1 ) P DB(p2 )| c).two patterns compressed entry guaranteed lossinformation c moves. Therefore, would like compress PDBpatterns mapped entry close pattern space.provide number different methods compressing PDBs. generalmethods often result significant loss information, methods relystructure underlying problem space necessarily domain-specific.4.2 Compression Based General Mapping FunctionsRegular PDB012compressed PDBRegular PDB6635445330 51 3Compress DIV 3016623544533compressed PDB0 31 3Compress MOD 3Figure 4: Compressed pattern databaseeasiest way compress PDB use general function maps exactly koriginal patterns compressed entry. compresses PDB entriescompressed PDB M/k entries. Two examples functions mapping indicesoriginal PDB compressed PDB are:Compressed index(i) = DIV kCompressed index(i) = OD kDIV integer division k, MOD remainder division k.advantage mapping functions general, thus PDB sizecompressed fit amount available memory.Figure 4 shows two ways compress PDB size 6 factor 3compressed PDB size 2. Note values specific PDB figure locallycorrelated indices. Therefore, easy see case DIV operatorbetter MOD operator since compresses highly correlated valuestherefore resulting loss information smaller.challenge build PDB entries similar indices comepatterns close pattern space. values locally correlated.224fiCompressed Pattern DatabasesGiven locally correlated values, better compress DIV operator, rathercompressing arbitrary set k entries. shown below, many domainspossible build PDB locally correlated entries correspond nearby patterns.4.3 Compression Based Individual Variablescompute PDB, use function map state index PDB,uniquely represents corresponding pattern. Many functions map valuesparticular variables particular bits index. example, described above,natural representation state n-disc four-peg Towers Hanoi problembit string 2n bits. representation, pairs bits represent locations differentdiscs. true sparse representation described permutation problems, different indices multi-dimensional array encode locations differenttiles tokens. situation little complex compact representationpermutation problems, principle applies.compress PDBs, map indices original PDB indicescompressed PDB ignoring certain bits. bits correspond particular variables,effect compressing entries ignoring values variables.operators problem space change values small number variables,patterns differ variables tend close together patternspace, distances goal also tend similar. Thus, compressingentries loss information small.compact sparse mappings described calculate indexPDB according predefined order variables. Assume last variableorder q different possible values. sparse mapping permutation problemsq = n, compact mapping q = n P + 1, n total numbervariables, P number pattern variables. divide index q,compressing entries differ value last variable. problemsmeans set entries compressed together, pattern objectslast one located location. example, patterns indexedP DB[a][b][c][d] compressed COM P RESSED P DB[a][b][c]. disadvantageforced compress factor n sparse mapping case, nP +1compact mapping case, even doesnt exactly fit available memory.idea compressing last variable generalized compressing last twovariables. compression factor would n, n2 , n3 etc. sparse mapping,n P + 1, (n P + 1) (n P + 2), (n P + 1) (n P + 2) (n P + 3) etc.compact mapping. Thus, method may achieve high correlation valuescompressed entries, allows compression certain values.4.3.1 Comparing Compressed Uncompress PDBs Sizedenote uncompressed PDB set P variables P DBP , similarlyuncompressed PDB P C variables P DBP C . denote PDB P variablescompressed C variables CP DBP/C . provide following two propositionscomparing P DBP C CP DBP/C .1. size CP DBP/C equal size P DBP C .225fiFelner, Korf, Meshulam, & HolteProof: easy see size n|P C| using sparse mapping,(n (n 1) (n 2) . . . (n |P | + |C| + 1)) using compact mapping.2. Assume P set variables C P . state searchspace CP DBP/C (s) P DBP C (s).Proof: mappings based P C variables. However,P DBP C completely ignores C variables, CP DBP/C contains minimum valuesP DBP combinations C variables.Thus, given memory size , PDB larger compressed individual variables size least accurate usually accurate uncompressedPDB size variables.4.4 Compressing CliquesGd+1Figure 5: Cliques PDBsSuppose given set patterns form clique pattern space. meanspatterns set reachable one move pattern space.Thus, PDB entries nodes differ one another one,assuming operators reversible. value d, restvalue + 1 shown Figure 5. worthwhile compress cliques patternspace since loss information guaranteed one move. identifygeneral structure q entries PDB represent clique size q, mapq patterns one entry.existence cliques pattern space domain dependent. Furthermore,take advantage them, need compression function map members cliqueindex compressed PDB. conditions exist problemspaces, exist domains considered.combinatorial problems operators move one object time,Towers Hanoi standard sliding-tile puzzles, cliques often represent statesdiffer location single object. Therefore, compression based object (orvariable) amounts compressing cliques practice. coincidence necessarilyoccur general. shown below, Top-Spin, patterns differlocation one object cliques, domain two compression methodscoincide.Compressing cliques size q done following two ways:lossy compression : Store minimum value q entries. admissibilityheuristic preserved loss information one move.226fiCompressed Pattern Databaseslossless compression: Store minimum value q entries. Assumevalue d. Store also q additional bits, one entry clique, indicateswhether entrys value + 1. preserves informationoriginal PDB, usually require less memory.idea compressing cliques generalized set z nodes diameterr. words, pair nodes within set least one connecting pathconsisting r fewer edges. clique special case r = 1. compressset nodes one entry taking minimum entries lose rmoves. Alternatively, lossless compression need additional z log(r + 1) bitsindicate exact value. size entry b bits beneficial termsmemory use lossless compression sets nodes diameter r longlog(r + 1) < b.4.5 Inconsistency Compressed Heuristicadmissible heuristic h consistent two states, x y, |h(x)h(y)| dist(x, y)dist(x, y) shortest path x problem space. particular,neighboring states h values two states differ one move. admissibleheuristic h inconsistent least one pair nodes x y, |h(x) h(y)| > dist(x, y).Compressed PDBs inconsistent since loss information differentdifferent states. example, let x neighboring states (with edge cost1) respectively mapped patterns lines 2 3 leftframe figure 4. original heuristics consistent (5 4 respectively)compressed heuristics inconsistent (5 3). Pathmax (PMX) one approachcorrecting inconsistent heuristics (Mero, 1984). propagates heuristic valuesparent node p child c follows. h(p) dist(p, c) lower bound dist(c, Goal)therefore used instead h(c) larger. new approach handlinginconsistent heuristics called bidirectional pathmax (BPMX) (Felner et al., 2005; Zahavi,Felner, Schaeffer, & Sturtevant, 2007). generalizes PMX BPMX, heuristicvalues propagated directions order increase heuristic values nodesneighborhood. Preliminary results applying BPMX compressed PDBs showcases small reduction number generated nodes achieved.present experimental results obtained compressed pattern databasesexample domains.5. 4-peg Towers Hanoi Problem (TOH4)state space TOH4 many small cycles, meaning many pathspair states. example, move disc twice row, achieveeffect single move disc. another example, move discpeg peg B, another disc peg C peg D, applying two movesopposite order effect. forbid moving disc twicerow, apply commutative operators one order, get branching factor 3.766.7-disc problem, optimal solution depth 25 moves, complete searchdepth generate 3.76625 nodes. However, 47 = 16, 384 unique states.227fiFelner, Korf, Meshulam, & HolteThus, depth-first search, IDA*, generate enormous numbers duplicatenodes, hopelessly inefficient domain.Thus, order search domain used Frontier-A* (FA*), modificationA* designed save memory (Korf, Zhang, Thayer, & Hohwald, 2005). FA* savesOpen list deletes nodes memory expanded. orderkeep regenerating Closed nodes, node Open list, FA* storesoperators lead Closed nodes, expanding node operatorsused.5.1 Additive Pattern Databases TOH4applicability PDB heuristics TOH4 first shown (Felner et al., 2004a).Consider 16-disc problem. build PDB ten largest discs includingentry 410 legal patterns discs. value entryminimum number moves required move ten discs corresponding positionsgoal peg, assuming discs problem. problem-solvingsearch, given state 16-disc problem, compute index correspondingten largest discs, look value configuration PDB. valueadmissible heuristic complete 16-disc problem, solution 16-discproblem must move largest ten discs goal peg, addition smallest sixdiscssimilar PDB built six smallest discs. Values ten-disc PDBsix-disc PDB added together get admissible heuristic valuecomplete state. reason complete solution must move discsgoal peg. Furthermore, move moves one disc, PDB values twosubproblems count moves respective pattern discs. Therefore, sumPDB values two disjoint sets discs lower bound number moves neededsolve original problem. idea additive PDBs first introduced (Korf &Felner, 2002) sliding-tile puzzles. deeper analysis additive PDBs providedby(Felner et al., 2004a).Note PDB based n discs contain exactly values largest ndiscs, smallest n discs, set n discs. reason mattersdiscs different sizes, absolute sizes. Furthermore, PDBdiscs also contains PDB n discs, n < m. look pattern n discs, simplyassign n remaining discs goal peg, look resulting patternm-disc PDB. Thus, practice need single PDB largest numberdiscs group partition. case, ten-disc PDB contains PDBlargest ten discs PDB smallest six discs. general, effectiveheuristic based partitioning discs groups maximize size largestgroup, subject available memory. largest PDB use machinegigabyte memory 14 discs. 414 entries, one byte per entry occupies256 megabytes. rest memory used Open list FA*.Given PDB 14 discs, two ways use 16-disc problem. firstcalled static partitioning. method, statically partition discs one group14 discs remaining 2 discs, use partition nodes228fiCompressed Pattern DatabasesHeuristicStatic 13-3Static 14-2Dynamic 14-2Path161161161Avg h72.1787.0493.46Nodes134,653,23236,479,15112,827,732Seconds48.7514.3421.56Table 1: Static vs Dynamic Partitioning 16-disc problemsearch. method called dynamic partitioning. state search,compute 16 15/2 = 120 different ways dividing discs groups 14 2,look PDB values pair, sum two values, return maximumoverall heuristic value. Here, exact partitioning disjoint sets discsdynamically determined state search. Table 1, taken (Felner et al.,2004a), compares static partitioning dynamic partitioning solving standardinitial state 16-disc TOH4. row corresponds different PDB setting.static partitions divide discs large group largest discs smaller groupsmallest discs. columns provide optimal path length, average heuristicvalue PDB, number generated nodes amount time taken solvestandard initial state. 14-2 split much better 13-3 split since 14-disc PDBmuch informed 13-disc PDB. 14-2 split, dynamically partitionedheuristic accurate, search generates fewer nodes, therefore FA* requires lessmemory, takes longer run due multiple heuristic calculations state.Static partitioning simpler implement, consumes much less time per node,generates nodes dynamic partitioning, thus occupying memory. Staticdynamic partitioning apply domain additive PDBs apply.5.2 Compressed Pattern Databases TOH4explained above, states TOH4 represented bit strings, pairsadjacent bits represent positions particular discs. Therefore, compressing PDBseasy. example, smallest disc represented least significant twobits, compression based smallest disc accomplished right shift twobits bit string. Note logically equivalent DIV 4. refercompressing smallest disc.practice, compressing smallest disc amounts compressing cliques domain.TOH4, largest cliques size four, since smallest disc always move amongfour pegs without moving larger discs. Thus, store PDB P discstable size 4P 1 , instead 4P , compressing four states smallest discone entry.compressed PDB, one entry configuration P 1largest discs. Lossy compression would store minimum value four entriesoriginal PDB correspond entry compressed PDB, lose onemove entries. Alternatively, lossless compression would store four additionalbits entry compressed PDB, indicate location smallest discwhether value minimum value one greater.229fiFelner, Korf, Meshulam, & HolteHeuristicStatic 14+2Static 13+3Static 12+4Static 11+5h(s)1161029074Avg h87.0472.1759.0147.32Nodes36,479,151134,653,232375,244,455> 462,093,281Time14.3454.02184.62> 243.15Mem256M64M16M4MTable 2: Solving 16 discs without compressiongeneralized compressing smallest two (or more) discs. fixposition largest P 2 discs, consider 16 different configurations twosmallest discs. form set nodes diameter three. Thus, compress16 entries one entry, lose three moves state. Alternatively,lossless compression add 2 16 = 32 bits one byte entry compressedPDB, total five bytes, store exact values, compared 16 bytesuncompressed PDB.5.3 Experiments 16-disc 4-peg Towers Hanoiprovide experimental results various compressing methods 16-disc4-peg Towers Hanoi problem. results solving standard versionproblem, moving discs one peg another. optimal solutionproblem 161 moves long. Unless stated otherwise, experiments paperconducted 2.4Ghz PC one gigabyte main memory.5.3.1 Uncompressed PDBs Different Sizescomparison purposes, Table 2 shows results uncompressed PDBs built staticpartitioning 14 + 2, 13 + 3, 12 + 4 11 + 5. first column shows heuristicused. case, larger group contained largest discs. second columnshows heuristic value initial state. next column average heuristicvalue entries larger PDB (the 14-disc PDB, 13-disc PDB etc). nextcolumns present number generated nodes, amount time seconds,amount memory needed megabytes larger PDB, optimally solve 16-discproblem. werent able solve problem 11 + 5 heuristic runningmemory Open list.5.3.2 Compressing Largest Discsexplained above, domain compressing cliques identical compressingsmallest disc. complementary method compress largest discs. implementation smallest discs represented least significant bits larger discsrepresents significant bits. particular representation, compressinglargest z discs accomplished masking corresponding 2z bits.logically equivalent taking representation MOD 4z, largest discs representedsignificant bits.230fiCompressed Pattern DatabasesDiscs0.511.522.5h(s)116101100858469Avg h87.0480.5572.1766.4659.0153.94Nodes36,479,15170,433,127285,190,821410,850,034791,374,8421,086,889,788Time14.3428.69143.78269.55543.10776.22Mem256M128M64M32M16M4MTable 3: Solving 16 discs 14-2 PDB 14-disc PDB compressed basedlarge discsTable 3 presents results solving 16-disc TOH4 problem compressing largestdiscs. statically divided discs two groups. largest fourteen discs define14-disc PDB. smallest two group separate PDB42 = 16 entries. compute heuristic state, values 2-disc PDB14-disc PDB added. different rows table correspond different degreescompression 14-disc PDB. 2-disc PDB occupies 16 entries henceneed compress it.first column shows number largest discs compressed. first rowrepresents compression. whole numbered rows based masking bitsused represent disc. fractional numbers based masking one twobits used represent disc. example, row 1.5 first column basedmasking bits largest disc, significant bit two bitsnext largest disc. rest columns format Table 2.table clearly shows running time increases significantly compressinglargest discs. reason locations largest discs large impactPDB values. Thus, values compressed correlatedother, great deal information lost. provides evidence claimvalues uncorrelated compressed.Comparing Table 3 Table 2 shows compressing largest discs performs worsePDB similar size without compression. example, 64 megabytes memorybetter solve problem simple PDB 13 discs plus small PDB 3 discs(2nd line Table 2), 14-disc PDB compressed largest disc, plus smallPDB 2 discs (3rd line Table 3). Thus, compressing largest discs beneficialTOH4.3231fiFelner, Korf, Meshulam, & HolteDiscs01234567891 llsh(s)11611511311111010399989675116Avg h87.0486.4885.6784.4582.7480.8578.5474.8168.3462.7187.04r0135913172533410Nodes36,479,15137,964,22740,055,43644,996,74345,808,32861,132,72676,121,86797,260,058164,292,964315,930,86536,479,151Time14.3414.6915.4116.9417.3623.7833.7236.6367.59155.2215.87Mem256M64M16M4M1M256K64K16K4K1K96MTable 4: Solving 16 discs 14-disc PDB compressed small discs5.3.3 Compressing Cliques Smallest DiscsTable 4 presents results 14-2 static partitioning 16 discs, compressing14-disc PDB smallest discs. representation compression based smallestz discs accomplished masking left 2z bits. logically equivalentperforming MOD 4z. different rows table correspond compressing14-disc PDB different numbers discs. rows represent lossy compression, exceptlast row represent lossless compression (denoted lls). first row Table4 complete 14-disc PDB compression. second row correspondscompressing smallest 14 largest discs. case, 14-disc PDB contains413 entries correspond different possible configurations 13 largest discs.entries, store minimum four possibilities smallest disc.row corresponds compressing cliques since four possible positions smallestdisc reached one another single move. third row compressestwo smallest discs 14 largest storing minimum 16 possibilities singleentry on.important result compressing PDB several ordersmagnitude, information preserved. example, compressing five smallest14 largest discs reduces memory factor 45 = 1024, increasedsearch effort less factor two number generated nodestime solve problem. PDB compressed factor 49 = 262, 144,search effort increased factor ten.Comparing first four lines tables 2 4 shows TOH4, compressinglarger PDB smaller size smallest discs much better original PDB3. contradict equation 2 section 4.3.1. equation dealt configurationcompressed uncompressed PDBs indexed variables. case, however,compared compressed PDB indexed discs 2-14 (where disc 1 compressed)uncompressed PDB indexed discs 1-13. equation valid compare uncompressedPDB discs 2-14 compared compressed PDB.232fiCompressed Pattern DatabasesPDBsDiscs14-314-315-216-1001216-22TypeAvg hNodes17-disc problemstatic90.5 >393,887,912dynamic95.7238,561,590static103.7155,737,832static123.817,293,60318-disc problemstatic123.8380,117,836TimeMemory>4212501837256M256M256M256M463256MTable 5: Solving 17 18-disc Towers Hanoisize. example, comparing third line tables shows compressedPDB 16 megabytes memory solved problem ten times fastersimple uncompressed PDB size indices based discs(discs 1-12 case). empirical evidence equation 2 section 4.3.1.last row Table 4 represents lossless compression full 14-disc PDBsmallest 14 discs, stored one additional bit position disc.used 8 + 4 = 12 bits per four entries instead 8 4 = 32 bits uncompressedPDB (row 1). number generated nodes identical row one, table clearlyshows worthwhile using lossless compression TOH4 since requirestime memory lossy compression one two smallest discs (rows 23).Avg h column gives average heuristic entries PDB. difference average h value compressed PDB, average h valueuncompressed PDB (87.04), gives average loss information due compression.maximum possible loss information lossy compression z discs, diameter r,presented fourth column Table 4. length optimal solutionproblem z discs z less 15, since problems, two statesfurtherest apart problem space standard initial goal states.4 observeaverage loss information half maximum possible information loss d.summarize set experiments, conclude compressing large discseffective values compressed patterns highly correlated. contrast,compressing small discs extremely efficient values compressedentries highly correlated.5.4 17 18-Disc Problemsalso solved 17- 18-disc problems compressing smallest discs. optimalsolutions standard initial state 193 225 moves respectively. Resultspresented Table 5. Static partitioning largest 14 discs smallest 3 discscannot solve 17-disc problem, since memory exhausted reaching goal4. Surprisingly, true 15 discs, 20 discs (Korf, 2003, 2004).233fiFelner, Korf, Meshulam, & Holte7 minutes (row 1). uncompressed PDB 14 discs able solve17-disc problem dynamic partitioning (row 2).largest PDB could compute entirely 1 gigabyte memory 16discs. database constructed bit-array detect duplicate nodes, requiring416 = 4 gigabits, half gigabyte. Given amount memory full 14-discPDB, 256MB, solved 17-disc problem 83 seconds 15-disc PDB compressedsmallest disc, 7 seconds 16-disc PDB compressed smallest twodiscs. improvement almost two orders magnitude compared row 1.improvement 2.5 orders magnitude compared dynamically partitioned heuristic14-disc PDB row 2. PDB 16 discs compressed 2 discs consumes exactlyamount memory uncompressed PDB 14 discs muchinformed, includes almost information 16 discs. PDBalso able solve 18-disc problem 8 minutes.5.5 Using Symmetry Disk Storage Solve 31 Discsalgorithms described able find shortest paths legal statesTOH4. However, much better interested shortest pathstandard initial state, discs located one peg, standard goal state,located another peg (Hinz, 1997). take advantagesymmetry standard initial goal states. particular, needsearch half way goal, first middle state discs largestdistributed two intermediate pegs. Given middle state, reachgoal state moving largest disc goal peg, applying moves madereach middle state reverse order, interchanging initial goal pegs.challenge take advantage heuristic function half-depth searchmiddle state. difficulty solve n disc problem, 2n1 middlestates, one way distribute n 1 smallest discs two intermediatepegs. PDB heuristic provides solution problem. Rather building PDBbreadth-first search starting single goal state, simply start search2n1 middle states depth zero, search breadth-first entire pattern spacegenerated. resulting PDB values minimum number moves requiredreach middle states. refer Multiple-Goal Pattern Database,MGPDB (Korf & Felner, 2007).constructed heuristic follows. first constructed 22-disc MGPDB compressed size 15-disc PDB, compressing 7 smallest discs. databaseoccupied exactly gigabyte memory, one byte per entry, constructedmemory, using magnetic disk storage states breadth-first search. alsoconstructed separate 8-disc MGPDB, required little time memory.used MGPDBs compute heuristics problems 31 discs.31-disc problem, goal search middle state 30 smallest discsdistributed two intermediate pegs. Thus, dont need consider largest disc.state search, statically divided 30 discs largest 22 discs,smallest 8 discs. looked configuration 22 largest discs 22-discMGPDB, looked configuration 8 smallest discs 8-disc MGPDB,234fiCompressed Pattern Databasesadded resulting values together. Similarly, also looked configuration22 smallest discs 22-disc MGPDB, looked configuration 8largest discs 8-disc MGPDG, added theses values together well. Finally,took maximum two sums overall heuristic.search algorithm used frontier version breadth-first heuristic search(BFHS) (Zhou & Hansen, 2006), A* cost function f (s) = g(s) + h(s),g(s) depth state initial state, h(s) MGPDB heuristic describedabove, estimates distance closest middle state. Using techniques,number others, able verify presumed optimal solution four-pegTowers Hanoi problems 31 discs. 31-disc problem took 100 CPU-daysrun, used two terabytes disk storage. Due unrecoverable disk errorresulting loss single disk block, one 200 million probabilityshorter solution 31-disc problem. able solve smaller problemserrors. represents current state-of-the-art four-peg Towers HanoiProblem. interested reader referred (Korf & Felner, 2007) detailsexperiments.6. Sliding-Tile Puzzles11000011001100110011771 partitioningFigure 6: 7-7-1 partitioning disjoint sets 15-Puzzlebest method solving sliding-tile puzzles optimally uses disjoint additivepattern databases (Korf & Felner, 2002). case, variables represent tiles valuesrepresent locations. tiles partitioned disjoint sets, PDB builtset. PDB stores cost moving tiles pattern set givenarrangement goal positions. Since set pattern tiles count movespattern tiles, move moves one tile, values different disjoint PDBsadded together results still admissible. deeper analysis additivePDBs, see (Felner et al., 2004a).x z partitioning partition tiles disjoint sets cardinalities x,z. Figure 6 shows 7-7-1 disjoint partitioning 15-puzzle used paper.geometric symmetry domain used allow another set PDB lookups(Culberson & Schaeffer, 1998; Korf & Felner, 2002; Felner et al., 2004a). example,reflect puzzle main diagonal, get another partitioning puzzlegeometrically symmetric original partitioning. Therefore, PDBused retrieve values regular partitioning reflected partitioning.maximum values taken admissible heuristic.235fiFelner, Korf, Meshulam, & Holte6.1 Combining Functional Heuristics PDBsmany domains exist simple functional heuristics calculated efficiently. example Manhattan distance (MD) heuristic sliding-tile puzzles.domains, PDB store additional increment () functionalheuristic, order save memory. denote PDB DPDB. searchadd values DPDB value functional heuristic.sliding-tile puzzles build DPDB storing additional incrementMD, results conflicts tiles PDB. conflicts comeunits two moves, since tile moves away Manhattan-distance path, mustreturn path total two additional moves. Compressing DPDBsliding-tile puzzle effective. Consider pair adjacent patternssliding-tile puzzle whose values stored DPDB. Since adjacent,Manhattan distances differ one, numbers additional moves MDsoften same. Thus, much information preserved compressing twoentries taking minimum.36 71011a) goal pattern0 0 30 0 0 70 0 10110 0 2 2b) PDB values tile 6Figure 7: goal pattern tiles {3,6,7,10,11} values tile 6example, consider subproblem 15-puzzle includes tiles {3,6,7,10,11}.corresponding goal pattern shown Figure 7.a. Assume tiles excepttile 6 goal positions, assume tile 6 location x, coursecannot {3,7,10,11}. values Figure 7.b written location x correspondnumber moves MDs pattern tiles must move order properlyplace tile 6 goal location, given current location x. example, supposetile 6 placed bottom row tile 10 belongs. case tile 6linear conflict (Hansson, Mayer, & Yung, 1992) tile 10, one mustmake least two horizontal moves MD. Thus write number 2location. locations moves beyond MD needed write 0.Note adjacent positions Figure 7.b value. Thus, buildDPDB compress two entries correspond patterns, informationlost cases. fact, 7-7-1 partition used experiments below,compressing two patterns one, found 80%pairs compressed stored exactly value compression.6.2 Compressing PDBs Sliding-Tile PuzzlesSince 15 puzzle permutation problem, sparse mapping compactmapping defined section 3.1 applicable. 7-tile PDB experiments,236fiCompressed Pattern Databasessparse mapping uses multi-dimensional array size 167 268 106 entries.Alternatively, compact mapping uses array size 16 15 . . . 10 57 106entries. Compact mapping complex implement turned timeconsuming experiments needs smaller amount memory.6.2.1 Cliques Sliding-Tile Puzzlessliding-tile puzzles full compression one variable, tile, equivalentclique compression. Since every move moves single tile adjacent location,largest clique pattern space size two, single edge. edges,locations tiles pattern except one fixed, remaining tile onetwo adjacent positions. refer compressing two states edge compression.sparse mapping, 16 different entries variable correspond16 different possible locations tile 15-puzzle. order take advantageedge compression, divided 16 locations following 8 pairs: (0,1), (2,3). . . (14,15). Instead storing 16 entries location last tile, store 8entries, one pairs. Thus, size PDB 166 8, halfsize original PDB 167 different entries. Note compressingparticular edges logically done applying DIV 2 index last tile.Compressing edges (cliques) compact mapping complicated.PDB based P tiles, 16 P + 1 entries last tile. example,P = 7, 16 different locations, 10 legal positions placelast tile, since 6 occupied tiles. use pairing mechanismdescribed compressing edges compress 16 locations 8 entries.slightly smaller 10 entries original compact mapping. Edgecompressing effective compact mapping number pattern tilesconsiderably smaller half size puzzle. example, 24-puzzle,efficient compress edges PDBs 6 tiles even compact mapping. Notealternative method would compress 10 entries compact mapping5 entries (by Div 2). However, shown necessarily compress adjacentlocations last tile, therefore correspond edge (clique) compression.6.3 Results 15-PuzzleTable 6 presents results different compressing methods 15-puzzle sparse mapping, Table 7 presents similar results compact mapping. values tablesaverages 1000 random initial states used (Korf & Felner, 2002).Heuristic column defines partitioning used. example, 1 7-7-1 meansused one 7-7-1 partitioning. 2 7-7-1 means used two different 7-7-1 partitionings took maximum heuristic. + means also tookpartitioning reflected main diagonal. next column indicatescompressing method used. subscript ls shown means lossless compressionused, otherwise compression lossy. next columns present numbernodes generated IDA*, average running time seconds, amount memorymegabytes one byte per entry, average heuristic initial states. time237fiFelner, Korf, Meshulam, & HolteHeuristic12345111116781+1+1+91022+CompressNodes TimeOne PDB lookup7-7-1464,977 0.0587-7-1 edge565,881 0.0697-7-1 edgels487,430 0.0707-7-1 row1,129,659 0.1317-7-1 2 tiles1,312,647 0.152PDB lookup reflection7-7-1124,482 0.0207-7-1 edge148,213 0.0227-7-1 row242,289 0.048Two different PDBs7-7-1 edge147,336 0.0217-7-1 edge66,692 0.016MemAv h524M262M262M131M131M43.6443.0243.5942.4342.21524M262M131M44.5343.9843.39524M524M43.9844.92Table 6: 15-puzzle results. Different compressing methods one lookupssparse mappingneeded precompute PDB traditionally omitted, since one needs precomputeonce, PDB used solve many problem instances needed.6.3.1 Sparse mappingRow 1 Table 6 presents benchmark results single 7-7-1 partitioningcompression.5 . next four rows (2-5) present results different compression methods7-7-1 PDB. Row 2 gives results 7-7-1 PDB two 7-tile PDBscompressed edges. size PDB cut half, overall effortincreased 20% number generated nodes overallrunning time. Row 3 presents results 7-7-1 partitioning used losslesscompression edges. number generated nodes decreased 15%lossy compression, overall time increased little. due additional constanttime handling lossless compression.6 Row 4 provides results case 16different locations one tile compressed four different entries savingrow tiles position, column. logically done DIV 4.cases moving row 1 row 2 (in Table 6) row 2 4, amount memory5. best results 15 puzzle achieved using 7-8 partitioning (Korf & Felner, 2002).partitioning cannot implemented sparse mapping would need 4 Giga bytes memory.Thus, used 7-7-1 partitioning set experiments.6. reason number generated nodes identical 7-7-1 partitioning withoutcompression rare cases PDBs, two entries compressed edgesdiffered one move. Thus, information lost even lossless compressionused. rare cases caused special way treated location blank. fulltechnical treatment blank handled provided (Felner et al., 2004a).238fiCompressed Pattern Databasesreduced factor two. However, number generated nodes increased20% edge compression, number generated nodes increased factor 2.5going edge compression row compression. reason correlationamong values compressed entries. edge compression loss informationone move, significantly effect overall performance.row compression, loss information much greater four values compressedsignificantly different other. Thus, effect overall performancemuch greater. Row 5 represents alternative way compress PDB factor 4.case, locations two tiles compressed eight locations each. Resultslittle worse row compression, correlation among compressedvalues even less case.next three rows (6-8) show tendency two sets PDB lookupsperformed 7-7-1 PDB, original set set reflected maindiagonal. Row 6 presents results uncompressed versions PDBs. Noteadditional PDB lookup PDB row 1 improved resultsfactor almost four. compressing edges row 7, correlation amongcompressed values high, loss information one move, runningtime roughly compared compression. row compression row 8,correlation values worse, search effort increases.Edge compression causes small loss information reduces memory half.Thus, use amount memory original uncompressed PDBtwo compressed PDBs. Row 9 presents results took two different 7-7-1 PDBs, compressed factor two using edges, took maximum. configurationuses amount memory benchmark uncompressed single 7-7-1 partitioningrow 1, solves problem almost three times faster. Row 10 also computesreflection main diagonal two different compressed PDBs takesmaximum 4 different partitionings. reduced number generated nodesfactor 7 factor 2, compared uncompressed versions amountmemory row 1 6, respectively. terms running time speedupmodest decreased 16 milliseconds. 4 PDBlookups diminishing return adding lookups.76.3.2 Compact mappingTable 7 presents results PDB built compact mapping. first lineprovides results 7-7-1 partitioning used sparse mapping table 6compact mapping. indexing algorithm used line simple algorithmcalculating exact index takes time quadratic number objectspattern. Note number generated nodes identical line 1 table 6amount memory needed much smaller. hand, results showactual CPU time compact mapping worse corresponding sparsemapping. rest table used advanced algorithm index calculation7. See (Holte, Felner, Newton, Meshulam, & Furcy, 2006) deeper discussion advancedmethods reduce constant time per node number PDB lookups performed.Furthermore, exact CPU time measured experiments taken care sincegreatly influenced implementation, compiler hardware machine used.239fiFelner, Korf, Meshulam, & HolteHeuristic11 7-7-123456111117-7-17-7-17-7-17-7-17-7-1CompressNodes TimeSimple compact mappingnone464,977 0.232Advanced compact mappingnone464,977 0.121edge565,881 0.142edge ls487,430 0.130last tile996,773 0.240first tile1,024,972 0.261MemAv h55M43.6455M44M44M27.5M27.5M43.6443.0243.5942.8742.94Table 7: 15-puzzle results. Compressing compact mappingcompact mapping presented (Korf & Shultze, 2005). advanced algorithmtime calculate exact index reduced linear number objects.done help another lookup table stores values shift operations neededalgorithm. See (Korf & Shultze, 2005) deeper discussion treatmentmethod. Using advanced algorithm reduced running time factortwo simple quadratic algorithm still slower correspondingsparse mapping reported table 6.Lines 3 4 provide results lossy lossless edge compressing advancedcompact mapping. results report number generated nodes corresponding sparse mapping table 6. Compact mapping 10 entries lasttile (since 6 locations occupied tiles). Edge compression (lines 3 4)slightly reduced 8 entries offering small memory reduction 20%uncompressed 7-7-1 compact mapping PDB. probably cost effectiveallow another compressed PDB stored amount memoryuncompressed PDB. Line 5 presents results compressed index last tile10 entries 5 taking maximum two adjacent entries. equivalentDiv 2. memory reduction factor 2. However, since neighboring entriescompact mapping necessarily correspond cliques, number generatednodes significantly increased loss information guaranteed 1edge (clique) compressing. last line provides similar results compressingperformed index first tile (from 16 locations 8). equivalentMOD 2. Again, entries compressed cliques loss datarather large.6.3.3 Summary 15 puzzle resultsresults 15 puzzle show edge (clique) compressing effectivepuzzle information preserved type compressing. compressing techniques cause significant loss information efficient domain.Edge compressing provides significant memory reduction factor 2 sparse mappingused. encouraging since sparse mapping probably best choice largerversions puzzle (e.g., 24, 35, etc.). one chooses use compact mapping240fiCompressed Pattern Databasesmemory saved edge compressing rather modest probably effective. Unlike4-peg Towers Hanoi problem, could find compressing method memorysaving factor larger 2 proved efficient tile puzzle.best existing heuristic 15 puzzle PDB based 7-8 partitioningtiles, reflection main diagonal (Korf & Felner, 2002). solved problem implementing partitioning compact mapping used 562 megabytes.average number generated nodes 36,710, average running time.018 seconds fast compact mapping. reduction almost factor twosimple quadratic compact mapping. Since 7-8 PDBs implemented compactmapping could improve results compression. worth notingbest version 7-7-1 partitioning (line 10 Table 6) uses slightly less memory(524 megabytes) runs slightly faster(.016 seconds), generates twice many nodes.(66,692).6.4 Results 24-PuzzleFigure 8: 6-6-6-6 PDB 24-Puzzle reflectionbest existing heuristic 24-puzzle one gigabyte memoryavailable 6-6-6-6 partitioning reflection main diagonal (Korf &Felner, 2002) shown Figure 8. compressed 6-6-6-6 partitioning foundsimilar 15 puzzle lossy compression edges effective generated20% nodes. However, adding another 6-6-6-6 partitioning couldachieve significant reduction overall time. Due geometrical attributespuzzle, 6-6-6-6 partitioning reflection (Korf & Felner, 2002) goodadding another set 6-6-6-6 partitioning, even without compression, achievessmall reduction node generations.also tried 7-7-5-5 partitioning refection, stored one gigabytememory compressing 7-tile PDBs. Even without compression, numbergenerated nodes much better 6-6-6-6 partitioning probablybest 4-way partitioning puzzle.One way obtain speedup domain might compress larger PDBs8-8-8 partitioning, beyond scope work. 8-8-8 PDBimplemented (Felner & Adler, 2005) using sophisticated method instance-dependentPDBs. method based idea first presented (Zhou & Hansen, 2004),relevant parts PDB stored memory given particular initial goalstates.241fiFelner, Korf, Meshulam, & Holte7. Top-Spintried different compression methods Top-Spin domain well. Top-Spinone object moved move. Therefore, simple disjoint additive PDBsapplicable here. simple way build PDB domain specify numberpattern tokens, remaining tokens indistinguishable. Here, usedcompact mapping.7.1 Cliques Top-SpinDue nature Top-Spin, largest cliques size two, simply edges, unlikedomains correspond compression single variables. example,assume 3-token PDB tokens (2, 3, 4) (9,4) Top-Spin problem. Note patterns(, 2, 3, 4, , , , , ) (, , 4, 3, 2, , , , ) adjacent, therefore belong edgeclique size two. However, three tokens move here, hence three pattern variableschange values. Thus, compressing edges (cliques) simple compressingvalue single variable problem.7.2 Compression Based Individual Variablesfact, Top-Spin, compressing individual variables ignoringvariables. words, PDB based P variables, compressed C variables,actually identical memory values PDB based P C variables.explain this, first examine compression single variable. Consider threevariable P DB3 based tokens (1, 2, 3), four-variable P DB4 based tokens (1, 2, 3, 4)(9,4) Top-Spin problem. non-pattern tokens represented . goal pattern P DB3 (1, 2, 3, , , , , , ), goal pattern P DB4 (1, 2, 3, 4, , , , , ).Let p1 = (1, 2, , , , , , , 3) example pattern P DB3 . reach p1goal pattern two moves, since operators space inverses,P DB3 (p1 ) = 2. apply two moves pattern (1, 2, 3, 4, , , , , ),reach pattern (1, 2, , , 4, , , , 3), well call p2 . Thus, P DB4 (p2 ) = 2.consider P DB41 P DB4 compressed token variable 4. definition,P DB41 (p1 ) minimum value locations token 4, P DB4 (pi ). fact,constructed p2 P DB4 (p2 ) = P DB3 (p1 ). Since smaller value,P DB41 (p1 ) = P DB4 (p2 ) = P DB3 (p1 ). argument applies examplepattern. Furthermore, apply argument PDB built compressingnumber individual variables. Thus special case Top-Spin, equation 2section 4.3.1 becomes CP DBP/C (s) = P DBP C (s). means Top-Spin, compression based individual variables offers benefits compared simply ignoringvariables PDB size.7.3 Experimental Results Top-SpinSince compression based individual variables benefit here, tried general compression applying DIV OD operators PDB indices. experimented(17,4)-Top-Spin problem started compact mapping PDB 9 consecutive tokens, including 1 token. Note exceptions noted below,242fiCompressed Pattern DatabasesComp. Factor1234567891Avg. ValueAvg Nodes9-token PDB10.5240,810,94010.2059,827,20910.0387,517,3659.8886,424,2499.76 127,276,9819.69 147,626,7989.61 128,757,5359.54 159,711,9379.53 313,375,7908-token PDB9.53 313,375,790Avg TimeSize PDB87.36127.54183.70184.19264.33307.42267.73331.97650.83495M247M164M123M99M82M71M62M55M650.8355MTable 8: Results (17,4) Top-Spin PDBs 9 8 tokens 9-token PDBcompressed DIV operatorComp. Factor123456789Avg. Value10.5210.139.899.829.659.539.389.499.17Avg Nodes40,810,94150,363,03457,576,19476,123,45387,573,07487,356,61585,280,514152,480,88589,543,322Avg Time87.37109.88119.86158.47183.05186.15205.25321.23197.18Size PDB495M247M164M123M99M82M71M62M55MTable 9: Results for(17,4) Top-Spin 9-token PDB compressed MODcompressions preserve structure state variables correlationvalues compressed entries.Table 8 presents results DIV compression performed PDB. linerepresents different compression factor, second argument DIV operator.expected, larger compression factor increased search effort, reduced amountmemory. Note DIV 9 corresponds compression based single variable,since 8 variables set 17-variable permutation problem, exactly9 possible locations remaining next variable. Thus, explained previoussection line identical uncompressed PDB size 8 (the last line table).243fiNumber generated nodes (in Millions)Felner, Korf, Meshulam, & Holte350DIVMOD3002502001501005001234567compression degree89Figure 9: Nodes generated DIV MOD 9-token PDB (17,4)- Top-SpinproblemTable 9 shows results compressing PDB MOD operator,form Table 8. Figure 9 compares two methods. Surprisingly, MOD outperformed DIV. counterintuitive DIV compresses entries tendmany state variables common. best explanation phenomenon follows.described above, Top-Spin location several tokens changed single move.believe distance two states similar, differing swaptwo tokens example, greater distance randomly-chosen pairstates.8 Thus, states grouped together DIV operator tend lesshighly correlated random groupings, groupings induced MOD operator.Note last line Table 9 (compression MOD 9) used amountmemory uncompressed 8-token PDB (last line Table 8) takes 30%long solve problems. shows benefit compression problem well.Compression MOD operator effective given size memory8-token PDB, better build larger 9-token PDB compress size.reduces search effort factor 3.8. Conclusionsintroduced new method improving performance PDBs, compressinglarger PDBs fit smaller amounts memory. applied techniquefour-peg Towers Hanoi problem, sliding-tile puzzles, Top-Spin puzzle.experiments confirm given specific amount memory , usually better usememory compressed PDBs uncompressed PDBs. practicallyachieved either larger PDB compressed size , maximizing k compressedPDBs size M/k.8. performed several experiments confirm this. Indeed, (12,4) - Top-Spin version, pairrandom states distanced 9.28 moves away average two statesdiffer two adjacent tokens 12 moves away. Similarly, (16,4) - TopSpin average distances14.04 16 moves, respectively.244fiCompressed Pattern Databasesintroduced number different methods compressing PDB, ranginggeneral mapping functions indices DIV MOD, methods takeaccount structure problem space. general, want group together PDBentries similar values. achieved grouping patterns closepattern space. particular, states form clique problemspace PDB values differ one, hence natural candidatescompression. exact method finding cliques (or nearby patterns) PDBdepends domain exact way PDB implemented.TOH4 sparse mapping tile puzzle, PDB constructedeasily way cliques reside nearby entries PDB thus, PDBvalues locally correlated. Therefore, compressing nearby PDB entries proved usefulsettings. Top-Spin, however, values PDB stored standard waylocally correlated thus compressing nearby PDB entries effective.domain effective compress patterns far apart PDB. Similarly,neighboring entries compact mapping tile puzzle correspond cliques.Thus, compression prove useful setting could improve 7-8partitioning 15 puzzle.Towers Hanoi problem, achieved dramatic improvements several ordersmagnitude running time, compared uncompressed PDBs size, usedtechnique verifying optimal solutions problems 31 discs,current state art. sliding-tile puzzles showed compressionpreserve information techniques offer practical improvementssparse mapping compact mapping. Top-Spin, achievedimprovements naive compression method (the MOD method).also described several methods generating PDBs large fitmemory prior compression, using auxiliary disk storage.9. Acknowledgementsresearch supported Israel Science Foundation (ISF) grant No. 728/06Ariel Felner. also supported NSF grant No. EIA-0113313 Richard Korf.ReferencesBloom, B. H. (1970). Space/time trade-offs hash coding allowable errors. Communications ACM, 13(3), 422426.Chen, T., & Skiena, S. (1996). Sorting fixed-length reversals. Discrete Applied Mathematics, 71 (1-3), 269295.Culberson, J. C., & Schaeffer, J. (1998). Pattern databases. Computational Intelligence,14 (3), 318334.Dunkel, O. (1941). Editorial note concerning advanced problem 3918. American Mathematical Monthly, 48, 219.Dunkel, O. (1992). Symbolic boolean manipulation ordered binary decision diagrams.ACM Computing Surveys, 24(3), 142170.245fiFelner, Korf, Meshulam, & HolteEdelkamp, S. (2001). Planning pattern databases. Proceedings 6th EuropeanConference Planning (ECP-01), pp. 1334.Edelkamp, S. (2002). Symbolic pattern databases heuristic search planning. Proc.International Conference AI Planning Scheduling (AIPS), pp. 274293.Edelkamp, S., & Kissmann, P. (2007). Externalizing multiple sequence alignment problem affine gap costs. German Conference Artificial Intelligence (KI), LNCS4467, pp. 444447.Felner, A., & Adler, A. (2005). Solving 24-puzzle instance dependent patterndatabases. Proceedings SARA-05, pp. 248260, Edinburgh, Scotland.Felner, A., Korf, R. E., & Hanan, S. (2004a). Additive pattern database heuristics. JournalArtificial Intelligence Research (JAIR), 22, 279318.Felner, A., Meshulam, R., Holte, R., & Korf, R. (2004b). Compressing pattern databases.Proceedings Nineteenth National Conference Artificial Intelligence (AAAI04), pp. 638643.Felner, A., Zahavi, U., Holte, R., & Schaeffer, J. (2005). Dual lookups pattern databases. Proceedings Nineteenth International Joint Conference ArtificialIntelligence (IJCAI-05), pp. 103108.Frame, J. S. (1941). Solution advanced problem 3918. American Mathematical Monthly,48, 216217.Hansson, O., Mayer, A., & Yung, M. (1992). Criticizing solutions relaxed models yieldspowerful admissible heuristics. Information Sciences, 63(3), 207227.Hart, P. E., Nilsson, N. J., & Raphael, B. (1968). formal basis heuristic determination minimum cost paths. IEEE Transactions Systems Science Cybernetics,SCC-4(2), 100107.Hinz, A. M. (1997). tower Hanoi. Algebras Combinatorics: ProceedingsICAC97, pp. 277289, Hong Kong. Springer-Verlag.Holte, R. C., Felner, A., Newton, J., Meshulam, R., & Furcy, D. (2006). Maximizingmultiple pattern databases speeds heuristic search. Artificial Intelligence, 170,11231136.Korf, R. E. (1985). Depth-first iterative-deepening: optimal admissible tree search.Artificial Intelligence, 27(1), 97109.Korf, R. E. (1997). Finding optimal solutions Rubiks Cube using pattern databases.Proceedings Fourteenth National Conference Artificial Intelligence (AAAI97), pp. 700705.Korf, R. E. (2003). Delayed duplicate detection: Extended abstract. Proceedings18th International Joint Conference Artificial Intelligence (IJCAI-03), pp. 15391541, Acapulco, Mexico.Korf, R. E. (2004). Best-first frontier search delayed duplicate detection. Proceedings19th National Conference Artificial Intelligence (AAAI-2004), pp. 650657,San Jose, CA.246fiCompressed Pattern DatabasesKorf, R. E., & Felner, A. (2002). Disjoint pattern database heuristics. Artificial Intelligence,134, 922.Korf, R. E., & Felner, A. (2007). Recent progress heuristic search: case studyfour-peg towers hanoi problem. Proceedings 20th International JointConference Artificial Intelligence (IJCAI-07), pp. 23242329.Korf, R. E., & Shultze, P. (2005). Large-scale, parallel breadth-first search. Proceedings20th National Conference Artificial Intelligence (AAAI-2005), pp. 13801385,Pittsburgh, PA.Korf, R. E., Zhang, W., Thayer, I., & Hohwald, H. (2005). Frontier search. JournalAssociation Computing Machinery (JACM), 52 (5), 715748.McNoughtton, M., Lu, P., Schaeffer, J., & Szafron, D. (2002). Memory efficient A* heuristicsmultiple sequence alignment. Proceedings Eighteenth National ConferenceArtificial Intelligence (AAAI-02), pp. 737743.Mero, L. (1984). heuristic search algorithm modifiable estimate. Artificial Intelligence, 23, 1327.Munagala, K., & Ranade, A. (1999). I/o complexity graph algorithms. Proceedings10th Annual Symposium Discrete Algorithms, pp. 687694. ACM-SIAM.Myrvold, W., & Ruskey, F. (2001). Ranking unranking permutations linear time.Information Processing Letters, 79, 281284.Schroedl, S. (2005). improved search algorithm optimal multiple-sequence alignment.Journal Artificial Intelligence Research (JAIR), 23, 587623.Stern, U., & Dill., D. L. (1995). Improved probabilistic verification hash compaction.Advanced Research Working Conference Correct Hardware Design VerificationMethods, pp. 206240.Stewart, B. (1941). Solution advanced problem 3918. American Mathematical Monthly,48, 217219.Zahavi, U., Felner, A., Holte, R., & Schaeffer, J. (2006). Dual search permutation statespaces. Proceedings Twenty First National Conference Artificial Intelligence (AAAI-06), pp. 10761081.Zahavi, U., Felner, A., Schaeffer, J., & Sturtevant, N. (2007). Inconsistent heurstics. Proceedings Twenty Second National Conference Artificial Intelligence (AAAI07). appear.Zhou, R., & Hansen, E. (2004). Space-efficient memory-based heuristics. ProceedingsNineteenth National Conference Artificial Intelligence (AAAI-04), pp. 677682.Zhou, R., & Hansen, E. (2006). Breadth-first heuristic search. Artificial Intelligence, 170 (45), 385408.247fiJournal Artificial Intelligence Research 30 (2007) 457-500Submitted 05/07; published 11/07Using Linguistic Cues Automatic RecognitionPersonality Conversation TextFrancois Mairessef.mairesse@sheffield.ac.ukDepartment Computer Science, University Sheffield211 Portobello Street, Sheffield S1 4DP, United KingdomMarilyn A. Walkerm.a.walker@sheffield.ac.ukDepartment Computer Science, University Sheffield211 Portobello Street, Sheffield S1 4DP, United KingdomMatthias R. Mehlmehl@email.arizona.eduDepartment Psychology, University Arizona1503 E University Blvd. Building 68, Tucson, AZ 85721, USARoger K. Moorer.k.moore@dcs.shef.ac.ukDepartment Computer Science, University Sheffield211 Portobello Street, Sheffield S1 4DP, United KingdomAbstractwell known utterances convey great deal information speakeraddition semantic content. One type information consists cuesspeakers personality traits, fundamental dimension variation humans.Recent work explores automatic detection types pragmatic variationtext conversation, emotion, deception, speaker charisma, dominance, pointview, subjectivity, opinion sentiment. Personality affects aspectslinguistic production, thus personality recognition may useful tasks,addition many potential applications. However, date, little workautomatic recognition personality traits. article reports experimental resultsrecognition Big Five personality traits, conversation text, utilisingself observer ratings personality. work reports classification results,experiment classification, regression ranking models. model, analyseeffect different feature sets accuracy. Results show traits, typestatistical model performs significantly better baseline, ranking modelsperform best overall. also present experiment suggesting ranking modelsaccurate multi-class classifiers modelling personality. addition, recognitionmodels trained observed personality perform better models trained using selfreports, optimal feature set depends personality trait. qualitative analysislearned models confirms previous findings linking language personality,revealing many new linguistic markers.1. IntroductionPersonality complex attributesbehavioural, temperamental, emotionalmentalthat characterise unique individual.well known utterances convey great deal information speakeraddition semantic content. One type information consists cuesc2007AI Access Foundation. rights reserved.fiMairesse, Walker, Mehl & Moorespeakers personality traits, fundamental dimension variation humans.Personality typically assessed along five dimensions known Big Five:Extraversion vs. Introversion (sociable, assertive, playful vs. aloof, reserved, shy)Emotional stability vs. Neuroticism (calm, unemotional vs. insecure, anxious)Agreeableness vs. Disagreeable (friendly, cooperative vs. antagonistic, faultfinding)Conscientiousness vs. Unconscientious (self-disciplined, organised vs. inefficient, careless)Openness experience (intellectual, insightful vs. shallow, unimaginative)five personality traits repeatedly obtained applying factor analysesvarious lists trait adjectives used personality description questionnaires (sampleadjectives above) (Norman, 1963; Peabody & Goldberg, 1989; Goldberg, 1990). basisfactor analyses Lexical Hypothesis (Allport & Odbert, 1936), i.e.relevant individual differences encoded language, importantdifference, likely expressed single word. Despite knownlimits (Eysenck, 1991; Paunonen & Jackson, 2000), last 50 years Big Five modelbecome standard psychology experiments using Big Five shownpersonality traits influence many aspects task-related individual behaviour. example,success interpersonal tasks depends personalities participants,personality traits influence leadership ability (Hogan, Curphy, & Hogan, 1994), general jobperformance (Furnham, Jackson, & Miller, 1999), attitude toward machines (Sigurdsson,1991), sales ability (Furnham et al., 1999), teacher effectiveness (Rushton, Murray, & Erdle,1987), academic ability motivation (Furnham & Mitchell, 1991; Komarraju &Karau, 2005). However, date little work automatic recognitionpersonality traits (Argamon, Dhawle, Koppel, & Pennebaker, 2005; Mairesse & Walker,2006a, 2006b; Oberlander & Nowson, 2006).Recent work AI explores methods automatic detection types pragmatic variation text conversation, emotion (Oudeyer, 2002; Liscombe, Venditti, & Hirschberg, 2003), deception (Newman, Pennebaker, Berry, & Richards, 2003;Enos, Benus, Cautin, Graciarena, Hirschberg, & Shriberg, 2006; Graciarena, Shriberg,Stolcke, Enos, Hirschberg, & Kajarekar, 2006; Hirschberg, Benus, Brenier, Enos, Friedman, Gilman, Girand, Graciarena, Kathol, Michaelis, Pellom, Shriberg, & Stolcke, 2005),speaker charisma (Rosenberg & Hirschberg, 2005), mood (Mishne, 2005), dominancemeetings (Rienks & Heylen, 2006), point view subjectivity (Wilson, Wiebe, & Hwa,2004; Wiebe, Wilson, Bruce, Bell, & Martin, 2004; Wiebe & Riloff, 2005; Stoyanov, Cardie,& Wiebe, 2005; Somasundaran, Ruppenhofer, & Wiebe, 2007), sentiment opinion(Turney, 2002; Pang & Lee, 2005; Popescu & Etzioni, 2005; Breck, Choi, & Cardie, 2007).contrast pragmatic phenomena, may relatively contextualisedshort-lived, personality usually considered longer term, stable, aspectindividuals (Scherer, 2003). However, evidence personality interacts with,affects, aspects linguistic production. example, strong relationsextraversion conscientiousness traits positive affects,458fiRecognising Personality Conversation Textneuroticism disagreeableness various negative affects (Watson & Clark, 1992). Lying leads inconsistencies impressions agreeableness personality trait across modes(visual vs. acoustic), inconsistencies used cues deception detectionhuman judges (Heinrich & Borkenau, 1998). Outgoing energetic people (i.e. extravert)successful deception, apprehensive (i.e. neurotic) individualssuccessful (Riggio, Salinas, & Tucker, 1988), individuals score highly agreeableness openness experience traits also better detecting deception (Enoset al., 2006). Features used automatically recognise introversion extraversionstudies also important automatically identifying deception (Newman et al., 2003).Speaker charisma shown correlate strongly extraversion (Bono & Judge,2004), individuals dominate meetings similar characteristics extraverts,verbosity (Rienks & Heylen, 2006). Oberlander Nowson (2006) suggestopinion mining could benefit personality information. Thus evidence suggestsincorporating personality models tasks may improve accuracy.also hypothesise computational recognition user personality could useful many computational applications. Identification leaders using personalitydimensions could useful analysing meetings conversations suspected terrorists (Hogan et al., 1994; Tucker & Whittaker, 2004; Nunn, 2005). Dating websites couldanalyse text messages try match personalities increase chances successfulrelationship (Donnellan, Conger, & Bryant, 2004). Tutoring systems might effectivecould adapt learners personality (Komarraju & Karau, 2005). Automaticallyidentifying authors personality corpus could also improve language generation,individual differences language affect way concepts expressed (Reiter &Sripada, 2004). Studies also shown users evaluation conversational agentsdepends personality (Reeves & Nass, 1996; Cassell & Bickmore, 2003),suggests requirement systems adapt users personality, like humans(Funder & Sneed, 1993; McLarney-Vesotski, Bernieri, & Rempala, 2006).applications would possible acquire personality informationasking user author directly (John, Donahue, & Kentle, 1991; Costa & McCrae,1992), explore whether possible acquire personality models Big Fivepersonality traits observation individual linguistic outputs text conversation.date, know two studies besides automatic recognition userpersonality (Argamon et al., 2005; Mairesse & Walker, 2006a, 2006b; Oberlander & Nowson,2006). work applied classification models recognition personalitytexts blog postings. knowledge, results presented firstexamine recognition personality dialogue (Mairesse & Walker, 2006a, 2006b),apply regression ranking models allow us model personality recognitionusing continuous scales traditional psychology. also systematically examineuse different feature sets, suggested psycholinguistic research, report statisticallysignificant results.start Section 2 reviewing psychology findings linking personalitylanguage; findings motivate features used learning experiments describedSection 3. Section 3 overviews methods use automatically train personalitymodels, using conversation written language samples, self-ratingsobserver ratings personality traits. explore use classification models (Section 4),459fiMairesse, Walker, Mehl & Mooreregression models (Section 5), ranking models (Section 6), effect differentfeature sets model accuracy. results show traits, type statisticalmodel performs significantly better baseline, ranking models perform bestoverall. addition, models trained observed personality scores perform bettermodels trained using self-reports, optimal feature set dependent personalitytrait. rules derived features used learned models confirm previous findingslinking language personality, revealing many new linguistic markers. delayreview Argamon et al. (2005) Oberlander Nowson (2006) Section 7,better compare results own, sum discuss future workSection 8.2. Personality Markers Languagebelieve might possible automatically recognise personality linguisticcues? Psychologists documented existence cues discovering correlationsrange linguistic variables personality traits, across wide range linguisticlevels, including acoustic parameters (Smith, Brown, Strong, & Rencher, 1975; Scherer,1979), lexical categories (Pennebaker & King, 1999; Pennebaker, Mehl, & Niederhoffer,2003; Mehl, Gosling, & Pennebaker, 2006; Fast & Funder, 2007), n-grams (Oberlander &Gill, 2006), speech-act type (Vogel & Vogel, 1986). correlations reportedliterature generally weak (see Section 3.3), clear whether featuresimprove accuracies statistical models unseen subjects. Big Five traits,extraversion received attention researchers. However, studies focusingsystematically Big Five traits becoming common.2.1 Markers Extraversionsummarise various findings linking extraversion language cues Table 1,different levels language production speech, syntax content selection. review Furnham (1990) describes linguistic features linked extraversion traits,Dewaele Furnham (1999) review studies focusing link extraversionlanguage learning speech production.Findings include higher correlation extraversion oral language, especially study involves complex task. Extraverts talk more, louderrepetitively, fewer pauses hesitations, higher speech rates,shorter silences, higher verbal output, lower type/token ratio less formal language, introverts use broader vocabulary (Scherer, 1979; Furnham, 1990; Gill &Oberlander, 2002). Extraverts also use positive emotion words, show agreements compliments introverts (Pennebaker & King, 1999). Extravert studentslearning French second language produce back-channels, implicit style lower lexical richness formal situations. seems complextask higher level anxiety, easier differentiate introvertsextraverts (Dewaele & Furnham, 1999).Heylighen Dewaele (2002) also note extraversion significantly correlatedcontextuality, opposed formality. Contextuality seen high relianceshared knowledge conversational partners, leading use many deictic460fiRecognising Personality Conversation TextLevelConversationalbehaviourTopicselectionStyleSyntaxLexiconSpeechIntrovertListenLess back-channel behaviourSelf-focusedProblem talk, dissatisfactionStrict selectionSingle topicsemantic errorsself-referencesFormalMany hedges (tentative words)Many nouns, adjectives, prepositions (explicit)Elaborated constructionsMany words per sentenceMany articlesMany negationsCorrectRichHigh diversityMany exclusive inclusive wordssocial wordspositive emotion wordsMany negative emotion wordsReceived accentSlow speech ratedisfluenciesMany unfilled pausesLong response latencyQuietLow voice qualityNon-nasal voiceLow frequency variabilityExtravertInitiate conversationback-channel behaviourself-focused*Pleasure talk, agreement, complimentThink loud*Many topicsMany semantic errorsMany self-referencesInformalhedges (tentative words)Many verbs, adverbs, pronouns (implicit)Simple constructions*words per sentencearticlesnegationsLoose*PoorLow diversityexclusive inclusive wordsMany social wordsMany positive emotion wordsnegative emotion wordsLocal accent*High speech rateMany disfluencies*unfilled pausesShort response latencyLoudHigh voice qualityNasal voiceHigh frequency variabilityTable 1: Summary identified language cues extraversion various production levels, based previous studies Scherer (1979), Furnham (1990), PennebakerKing (1999), Dewaele Furnham (1999), Gill (2003), Mehl et al. (2006).Asterisks indicate cue based hypothesis, opposed studyresults.expressions pronouns, verbs, adverbs interjections, whereas formal languageless ambiguous assumes less common knowledge. order measure variation,Heylighen Dewaele suggest use metric called formality, defined as:F = (noun freq + adjective freq + preposition freq + article freq - pronoun freq - verbfreq - adverb freq - interjection freq + 100)/2argue measure important dimension variationlinguistic expressions, shown Bibers factor analysis various genres (Biber, 1988).addition introversion, authors also find formality correlates positivelylevel education femininity speaker. Situational variables relateduse formal language audience size, time span dialogues,unavailability feedback, difference backgrounds spatial location speakers,well preceding amount conversation.461fiMairesse, Walker, Mehl & MooreScherer (1979) shows extraverts perceived talking loudernasal voice, American extraverts tend make fewer pauses, German extraverts produce pauses introverts. Thus personality markers culture-dependent,even among western societies.Oberlander Gill (2006) use content analysis tools n-gram language modelsidentify markers extravert introvert emails. replicate previous findingsidentify new personality markers first person singular pronouns (e.g., dont)formal greetings (e.g., Hello) introversion, less formal phrases Take careHi characterise extraverts.2.2 Markers Big Five TraitsPennebaker King (1999) identify many linguistic features associatedBig Five personality traits. use Linguistic Inquiry Word Count (LIWC)tool count word categories essays written students whose personalityassessed using questionnaire. authors find small significant correlationslinguistic dimensions personality traits. Neurotics use 1st person singularpronouns, negative emotion words less positive emotion words. hand,agreeable people express positive fewer negative emotions. also use fewerarticles. Conscientious people avoid negations, negative emotion words words reflectingdiscrepancies (e.g., would). Finally, openness experience characterisedpreference longer words words expressing tentativity (e.g., perhaps maybe),well avoidance 1st person singular pronouns present tense forms.Additionally, Mehl et al. (2006) study markers personality perceived observers.find use words related insight avoidance past tense indicatesopenness experience, swearing marks disagreeableness. authors also showlinguistic cues vary greatly across gender. example, males perceivedconscientious produce filler words, females dont. Gender differences alsofound markers self-assessed personality: use 2nd person pronouns indicatesconscientious male, unconscientious female.Gill Oberlander (2003) study correlates emotional stability: find neurotics use concrete frequent words. However, also show observers dontuse cues correctly, observer reports neuroticism correlate negatively selfreports.Concerning prosody, Smith et al. (1975) also show speech rate positively correlated perceived competence (conscientiousness), speech rate inverted-Urelationship benevolence (agreeableness), suggesting need non-linear models.traits produced findings others. reason mightreflected language, like extraversion. However, possiblefocus consequence extraversion correlated linguistic cuesanalysed easily (e.g., verbosity).462fiRecognising Personality Conversation Text3. Experimental Methodconduct set experiments examine whether automatically trained modelsused recognise personality unseen subjects. approach summarisedfive steps:1. Collect individual corpora;2. Collect associated personality ratings participant;3. Extract relevant features texts;4. Build statistical models personality ratings based features;5. Test learned models linguistic outputs unseen individuals.following sections describe steps detail.3.1 Sources Language PersonalityIntrovertIve waking time far.been, 5 days? Dear me, Ill neverkeep up, morningperson all. maybe Ill adjust,not. want internet accessroom, dont yet,Wed??? think. aint soonenough, cause got calculus homework [...]Extravertreally random thoughts.want best things life.fear want much!fall flat facedont amount anything.feel like born BIG thingsearth. knows...Persian party today.NeuroticOne friends barged in,jumped seat. crazy.tell again.Im fastidious actually.certain things annoy me. thingswould annoy would actuallyannoy normal human being,know Im freak.Emotionally stableexcel sportknow push body harderanyone know, matter testalways push body harder everyoneelse. want best mattersport event. alsogood love ridebike.Table 2: Extracts essays corpus, participants rated extremely introvert,extravert, neurotic, emotionally stable.use data Pennebaker King (1999) Mehl et al. (2006) experiments. first corpus contains 2,479 essays psychology students (1.9 millionwords), told write whatever comes mind 20 minutes. datacollected analysed Pennebaker King (1999); sample shown Table 2.463fiMairesse, Walker, Mehl & MooreIntrovert- Yeah would kilograms. Yeah seeyoure saying.- Tuesday class. dont know.- dont know. A16. Yeah, kind cool.- dont know. cant waitevery night,know?- Yeah. dont know. bedthere? Well ok just...Extravert- Thats first yogurt experience here.Really watery. Why?- Damn. New game.- Oh.- Thats rude. That.- Yeah, he, like other.likes her.- going end breakinghes going like.Unconscientious- Chinese. Get together.- tried yell window.Oh. xxxxs fucking dumb ass. Lookhim. Look him, dude. Look him.wish camera. Hes fucking brushingt-shirt tooth brush. Get kickit. Dont steal nothing.Conscientious- dont, dont know factwould imagine historically womenentered prostitution doneso, everyone, majorityextreme desperation think. dontknow, think people understanddesperation dont dont see [...]Table 3: Extracts EAR corpus, participants rated extremely introvert, extravert, unconscientious, conscientious. participants utterancesshown.Personality assessed asking student fill Big Five Inventory questionnaire (John et al., 1991), asks participants evaluate 5 point scale wellpersonality matches series descriptions.second source data consists conversation extracts recorded using Electronically Activated Recorder (EAR) (Mehl, Pennebaker, Crow, Dabbs, & Price, 2001), collectedMehl et al. (2006). preserve participants privacy, random snippets conversation recorded. corpus much smaller essays corpus (96 participantstotal 97,468 words 15,269 utterances). essays corpus consiststexts, EAR corpus contains sound extracts transcripts. corpus thereforeallows us build models personality recognition speech. participants utterances transcribed (not conversational partners), making impossiblereconstruct whole conversations. Nevertheless, conversation extracts less formalessays, personality may best observed absence behavioural constraints. Table 4 shows essays corpus much larger EAR corpus,amount data per subject comparable, i.e. 766 words per subject essays1,015 EAR corpus. Table 3 shows examples conversations EAR corpusdifferent personality traits.personality ratings, EAR corpus contains self-reports ratings 18independent observers. Psychologists use self-reports facilitate evaluating personality large number participants, large number standard self-reporttests. Observers asked make judgments rating descriptions Big FiveInventory (John & Srivastava, 1999) 7 point scale (from strongly disagree strongly464fiRecognising Personality Conversation TextDatasetSource languagePersonality reportsNumber wordsSubjectsWords per subjectEssaysWrittenSelf reports1.9 million2,479766.4EARSpokenSelf observer97,468961,015.3Table 4: Comparison essays EAR corpora.agree), without knowing participants. Observers divided three groups,rating one third participants, listening participants entire set soundfiles (130 files average). personality assessment based audio recordings,contain information transcripts (e.g., ambient sounds, including captured conversations). Mehl et al. (2006) report strong inter-observer reliabilities acrossBig Five dimensions (intraclass correlations based one-way random effect models: meanr = 0.84, p < .01). observers ratings averaged participant, producefinal scores used experiments.Interestingly, average correlations frequency counts psycholinguisticword categories Big Five personality dimensions considerably largerEAR corpus student essays studied Pennebaker King. Moreover,correlations reported Mehl et al. seem higher observer reportsself-reports. Based observation, hypothesise models observed personalityoutperform models self-assessed personality.3.2 Featuresfeatures used experiments motivated previous psychological findingscorrelations measurable linguistic factors personality traits. Featuresdivided subsets depending source described subsections below.total feature set summarised Table 6. experimental results given Sections 4,5, 6 examine effect feature subset model accuracy.3.2.1 Content Syntaxextracted set linguistic features essay conversation transcript,starting frequency counts 88 word categories Linguistic Inquiry WordCount (LIWC) utility (Pennebaker et al., 2001). features include syntactic (e.g.,ratio pronouns) semantic information (e.g., positive emotion words),validated expert judges. LIWC features illustrated Table 5. PennebakerKing (1999) previously found significant correlations featuresBig Five personality traits. Relevant word categories extraversion include socialwords, emotion words, first person pronouns, present tense verbs. Mehl et al. (2006)showed LIWC features extracted EAR corpus significantly correlatedself observer reports personality.also added 14 additional features MRC Psycholinguistic database (Coltheart, 1981), contains statistics 150,000 words, estimates age465fiMairesse, Walker, Mehl & MooreFeatureAnger wordsMetaphysical issuesPhysical state/functionInclusive wordsSocial processesFamily membersPast tense verbsReferences friendsImagery wordsSyllables per wordConcretenessFrequency useTypeLIWCLIWCLIWCLIWCLIWCLIWCLIWCLIWCMRCMRCMRCMRCExamplehate, kill, pissedGod, heaven, coffinache, breast, sleepwith, and, includetalk, us, friendmom, brother, cousinwalked, were,pal, buddy, coworkerLow: future, peace - High: table, carLow: - High: uncompromisinglyLow: patience, candor - High: shipLow: duly, nudity - High: he,Table 5: Examples LIWC word categories MRC psycholinguistic features (Pennebaker et al., 2001; Coltheart, 1981). MRC features associate wordnumerical value.acquisition, frequency use, familiarity. introverts take longer reflectutterances, Heylighen Dewaele (2002) suggest vocabulary richerprecise, implying lower frequency use. MRC feature set previously usedGill Oberlander (2002), showed extraversion negatively correlatedconcreteness. Concreteness also indicates neuroticism, well use frequentwords (Gill & Oberlander, 2003). Table 5 shows examples MRC scales. MRCfeature computed averaging feature value words essay conversational extract. Part-of-Speech tags computed identify correct entrydatabase among set homonyms.3.2.2 Utterance TypeVarious facets personality traits seem depend level initiative speakertype utterance used (e.g., assertiveness, argumentativeness, inquisitiveness, etc.).example, extraverts assertive emails (Gill & Oberlander, 2002),extravert second language learners shown produce back-channel behaviour(Vogel & Vogel, 1986). therefore introduced features characterising types utterance produced. automatically tagged utterance EAR corpus speechact categories Walker Whittaker (1990), using heuristic rules based utterances parse tree:Command: utterance using imperative form, command verb (e.g., must to)yes/no second person question modal auxiliary like can;Prompt: single word utterance used back-channelling (e.g., Yeah, OK, Huh, etc.);Question: interrogative utterance isnt command;Assertion: utterance.466fiRecognising Personality Conversation TextLIWC FEATURES (Pennebaker et al., 2001):Standard counts:- Word count (WC), words per sentence (WPS), type/token ratio (Unique), words captured (Dic), wordslonger 6 letters (Sixltr), negations (Negate), assents (Assent), articles (Article),prepositions (Preps), numbers (Number)- Pronouns (Pronoun): 1st person singular (I), 1st person plural (We), total 1st person (Self), total2nd person (You), total 3rd person (Other)Psychological processes:- Affective emotional processes (Affect): positive emotions (Posemo), positive feelings (Posfeel), optimismenergy (Optim), negative emotions (Negemo), anxiety fear (Anx), anger (Anger),sadness (Sad)- Cognitive Processes (Cogmech): causation (Cause), insight (Insight), discrepancy (Discrep), inhibition(Inhib), tentative (Tentat), certainty (Certain)- Sensory perceptual processes (Senses): seeing (See), hearing (Hear), feeling (Feel)- Social processes (Social): communication (Comm), references people (Othref), friends (Friends),family (Family), humans (Humans)Relativity:- Time (Time), past tense verb (Past), present tense verb (Present), future tense verb (Future)- Space (Space): (Up), (Down), inclusive (Incl), exclusive (Excl)- Motion (Motion)Personal concerns:- Occupation (Occup): school (School), work job (Job), achievement (Achieve)- Leisure activity (Leisure): home (Home), sports (Sports), television movies (TV), music (Music)- Money financial issues (Money)- Metaphysical issues (Metaph): religion (Relig), death (Death), physical states functions (Physcal),body states symptoms (Body), sexuality (Sexual), eating drinking (Eating), sleeping(Sleep), Grooming (Groom)dimensions:- Punctuation (Allpct): period (Period), comma (Comma), colon (Colon), semi-colon (Semic), question(Qmark), exclamation (Exclam), dash (Dash), quote (Quote), apostrophe (Apostro), parenthesis(Parenth), (Otherp)- Swear words (Swear), nonfluencies (Nonfl), fillers (Fillers)MRC FEATURES (Coltheart, 1981):Number letters (Nlet), phonemes (Nphon), syllables (Nsyl), Kucera-Francis written frequency (K-Ffreq), Kucera-Francis number categories (K-F-ncats), Kucera-Francis number samples (K-F-nsamp),Thorndike-Lorge written frequency (T-L-freq), Brown verbal frequency (Brown-freq), familiarity rating(Fam), concreteness rating (Conc), imageability rating (Imag), meaningfulness Colorado Norms (Meanc),meaningfulness Paivio Norms (Meanp), age acquisition (AOA)UTTERANCE TYPE FEATURES:Ratio commands (Command), prompts back-channels (Prompt), questions (Question), assertions (Assertion)PROSODIC FEATURES:Average, minimum, maximum standard deviation voices pitch Hz (Pitch-mean, Pitch-min,Pitch-max, Pitch-stddev) intensity dB (Int-mean, Int-min, Int-max, Int-stddev), voiced time (Voiced)speech rate (Word-per-sec)Table 6: Description features, feature labels brackets.evaluated automatic tagger applying set 100 hand-labelled utterancesrandomly selected EAR corpus. obtain 88% correct labels, mostlyassertions. Table 7 summarises partition evaluation results speech acttype. speech act, corresponding feature value ratio numberoccurrences speech act total number utterances text.467fiMairesse, Walker, Mehl & MooreLabelAssertionCommandPromptQuestionFraction73.0%4.3%7.0%15.7%100%Labelling accuracy0.950.500.571.000.88Table 7: Partition speech acts automatically extracted EAR corpus,classification accuracies sample 100 hand-labelled utterances.3.2.3 ProsodyPersonality also shown influence speech production. Extraversion associatedvariation fundamental frequency (Scherer, 1979), higher voice qualityintensity (Mallory & Miller, 1958), fewer shorter silent pauses (Siegman& Pope, 1965). Smith et al. (1975) showed speech rate positively correlatedperceived competence (conscientiousness). Interestingly, authors found speechrate inverted-U relationship benevolence (agreeableness), suggesting neednon-linear models. See Section 3.4.added prosodic features based audio data EAR conversation extracts.EAR recorded participants anytime day, necessary automatically remove non-voiced signal. used Praat (Boersma, 2001) compute featurescharacterising voices pitch intensity (mean, extremas standard deviation),added estimate speech rate dividing number words voiced time.important aspect work features extracted without manualannotation beyond transcription, didnt filter utterances speakersmay captured EAR even though utilised microphone pointing towardsparticipants head. Although advances speaker recognition techniques might improveaccuracy prosodic features, make assumption noise introducedsurrounding speakers little effect prosodic features, thereforeaffect performance statistical models. assumption still remains tested,personality similarity-attraction effect (Byrne & Nelson, 1965) might influencepersonality distribution participants conversational partners.included features mentioned section (117) models basedEAR corpus. Models computed using essays corpus contain LIWC MRCfeatures (102), speech acts meaningful dialogues.3.3 Correlational Analysisorder assess individual features important modelling personality regardlessmodel used, report previous correlational studies LIWC featuresdata well analyses new MRC, utterance type prosodic features.LIWC features already analysed Mehl et al. (2006) EAR dataset,468fiRecognising Personality Conversation TextPennebaker King (1999) essays.1 Tables 8 11 show features correlatingsignificantly personality ratings (p < .05, correlations .05 only), combiningtogether results previous studies new findings provide insight featureslikely influence personality recognition models Sections 4.3, 5.3 6.3.correlation magnitudes Tables 8 9 LIWC MRC featuresessays data set show although extraversion well perceived conversations,isnt strongly reflected written language, correlation magnitudesessays dataset noticeably low. Table 10 shows word count (WC) important feature modelling extraversion conversation, observer reportsself-reports. Interestingly, marker doesnt hold written language (see Table 9).markers common observed self-reported extraversion include variationintensity (Int-stddev), mean intensity (Int-mean), word repetitions (Unique), wordshigh concreteness (Conc) imageability (Imag). See Table 11.hand, words related anger, affect, swearing, positive negative emotions (PosemoNegemo) perceived extravert, dont mark self-assessed extraversionconversations.Tables 10 11 show emotional stability, markers holdself-reports observer reports: high word count low mean pitch (Pitch-mean).Surprisingly, observed emotional stability associated swearing anger words,self-assessed ratings. reported Mehl et al. (2006), neurotics expectedproduce self-references (Self I). Pennebaker King (1999) show neuroticsuse self-references also observed essays, well use words relatednegative emotions anxiety. Table 11 shows conversations, self-assessed neuroticstend low constant voice intensity (Int-mean Int-stddev),markers arent used observers all.emotional stability expressed differently various datasets, markersagreeableness consistent: words related swearing (Swear) anger (Anger) indicate self-assessed observed disagreeableness, regardless source language.See Tables 8, 9 10. Interestingly, Table 11 shows agreeable peopleback-channelling (Prompt), suggesting tend listen conversationalpartners. observers dont seem take prosody account evaluating agreeableness, Table 11 shows prosodic cues pitch variation (Pitch-stddev)maximum voice intensity (Max-int) indicate self-assessed disagreeableness.far markers conscientiousness concerned, Tables 8 10 showsimilar agreeableness, unconscientious participants also use words relatedswearing (Swear), anger (Anger) negative emotions (Negemo), regardlessdataset assessment method. hand, observed conscientiousness associatedwords expressing insight, back-channels (Prompt), longer words (Nphon, Nlet, NsylSixltr) well words acquired late children (AOA), self-assessedconscientiousness mostly expressed positive feelings (Posfeel) conversations.avoidance negative language seems main marker conscientiousnessessays, features Table 8 correlate weakly self-reports.1. correlations differ Pennebaker Kings study use additional student essayscollected following years.469fiMairesse, Walker, Mehl & MooreTraitLIWCAchieveAffectAllPctAngerAnxApostroArticleAssentBodyCauseCertainCogmechCommCommaDeathDicExclExclamFamilyFeelFillersFriendsFutureGroomHearHomeHumansInclInhibInsightJobLeisureMetaphMotionMusicNegateNegemoNonflNumberOccupOptimOthrefParenthPeriodPhyscalPosemoPosfeelPrepsPresentPronounQmarkExtraversion.03.03-.08**-.03-.01-.08**-.08**.01-.05**.01.05*-.03-.02-.02-.02.05*-.01.00.05*-.01-.04*.06**-.02-.02-.03-.01.04.05*.04*-.03-.01.02-.03-.01.03-.04*-.08**-.03-.03-.03.03.03.06**.07**-.06**-.05*-.02.07**.07**.00.00.07**-.06**Emotionalstability.01-.07**-.04-.08**-.14**-.04.11**.02-.04-.03-.01-.02.00.01-.04-.09**.02-.05*-.05*-.09**.01-.04*.01-.02.00-.02-.02-.15**-.01.02-.01.01.07**.01-.01.06**-.12**-.18**.01.05*.05*.04-.01.02.03-.03-.05*.07**-.01.06**-.12**-.12**-.05*Agreeableness-.01-.04-.01-.16**.03-.02-.03.00-.04*.00.03-.02-.01-.02-.02.06**-.02.06**.09**.04-.01.02.02.01-.01.04*-.03.05*.03-.02.00.01.03-.01.05*-.01-.11**-.11**.01-.03.04.01.03.01-.04*-.01-.03.05*.03.04-.01.04*-.04Conscientiousness.02-.06**-.04-.14**.05*-.06**.02-.04-.04*-.04.04*-.06**-.05**-.01-.06**.06**-.01.00.04*.02-.03.01.07**.01-.04*.06**-.08**.04.04*-.02-.03.05**-.01-.08**.03-.07**-.07**-.11**-.05*-.02.09**.08**.01.01-.01-.01-.03.02-.02.08**-.03.02-.06**Opennessexperience-.07**.04*.10**.06**-.04.05**.11**.04*.02-.05*.04.02.03.10**.05*-.20**.07**-.03-.07**-.04*-.01-.12**-.04-.05**.04*-.15**.04-.14**-.03.04*.05*-.05**-.05**.08**-.13**.10**.01.04.02-.06**-.18**-.07**.01.06**.10**.04.01.02.08**-.04-.09**-.06**.08**Table 8: Pearsons correlation coefficients LIWC features personality ratingsessays dataset, based analysis Pennebaker King (1999)(* = significant p < .05 level, ** = p < .01). features correlatesignificantly least one trait shown.470fiRecognising Personality Conversation TextTraitLIWC (2)QuoteReligSadSchoolSeeSelfSemicSexualSixltrSleepSocialSpaceSportsSwearTentatTimeTVUniqueWCWPSMRCAOABrown-freqConcFamImagK-F-freqK-F-ncatsK-F-nsampMeancMeanpNletNphonNsylT-L-freqExtraversionEmotionalstabilityAgreeablenessConscientiousnessOpennessexperience-.05*.00.00.03.00.07**-.03.07**-.06**-.01.08**-.02.01-.01-.06**-.02-.04-.05**.03.03.06**-.01-.01-.02.03-.12**.05**.09**-.14**.02-.02.06**-.03.00.05*.09**.00-.01.02.04*.10**.06**-.06**.07**.02.03-.01.00.00.06**.00.06**.02.00-.05*-.02.02.03.02-.14**-.03.07**-.02-.04*.02.01.04*.02-.06**-.03-.06**.01.10**-.03.04*.00-.04.02.03-.02.01.00-.11**-.06**.09**-.04*-.05*-.01.02.01-.02-.04*.09**.07**-.01-.20**.05**-.14**.05**.09**.10**-.08**.02-.04-.05**.08**.05*-.15**.04.09**-.06**.05*.04.06**.11**-.01.05*.02.08**.05*-.01.06**.06**.06**.02-.09**-.08**-.07**.01.05*-.06**-.06**-.05*-.04*.10**-.04*-.01-.10**-.02.09**.08**.07**.10**-.04*.03.03.08**.05*.00.08**.03.05**.05*-.03-.03-.02.01.06**.06**-.01.05**.00.05*.07**.05**-.01.00.00.01.04.06**.11**-.07**-.10**-.17**-.08**.07**-.12**-.07**-.11**-.04*.15**.14**.13**.05**Table 9: Continuation Table 8, i.e. Pearsons correlation coefficients LIWCMRC features personality ratings essays dataset (* = significantp < .05 level, ** = p < .01). features correlate significantlyleast one trait shown.Tables 8 9 show openness experience trait yielding highest correlations essays corpus: articles, second person pronouns (You) long words (Sixltr)indicate openness, non-open participants tend talk occupations (Occup,Home School) (Self). far conversations concerned, observersuse similar cues openness conscientiousness, insight words, longer words,back-channels high age acquisition (AOA).section shows features likely vary depending source languagemethod assessment personality. analyses help evaluateusefulness individual features, question features combinedpredict personality accurately addressed statistical models.471fiMairesse, Walker, Mehl & MooreDatasetTraitLIWCAffectAngerArticlesAssentCauseCogmechCommDicDiscrepEatingFamilyFeelFemaleFillerFriendHearHomeHumansInhibInsightMetaphMoneyNegemoNonflOthrefPastPhyscalPosfeelPronounReligSelfSensesSexualSixltrSocialSpaceSportsSwearTentatUniqueWCExtraObserver reportsEmotAgree ConscOpenExtraEmot.40**.37**.21*-.29**-.13.04-.18-.07.08.25*.26*.21*.29**-.01.14-.20-.02-.01.03.19.04.30**-.02.36**-.01.09.00-.19.30**.28**-.02.30**.09-.04.24*-.04-.04.03.10.30**-.04-.6**.06.63**.13.30**.32**-.02-.23*-.01-.27**-.16-.03.15-.23*.06-.03-.19-.01-.23*-.19.21*-.41**.01-.02.07.24*.18.05.02.05-.07.24*.04-.30**.06-.42**-.12.21*-.04-.06.18.28**.27**.15-.18.04.28**.00-.14.14.03.00.23*-.26*-.08.23*-.11-.04.05-.17.01-.14-.29**.06-.12-.17.00.32**-.02.01-.11.06-.17-.22*-.31**-.17.05-.28**-.07-.15-.26*-.22*.24*-.31**-.07-.11-.17.30**-.12-.05.20.05-.02.03-.11.00.11-.01.02.10-.03.14.08.24*-.05.20*-.04.04.07.21*.02-.06.20-.08.03-.02.02.02-.10-.07.06.12.26*.25*.03-.05-.20.06-.10.03-.08-.14-.32**.06.29**-.13.07.00-.05-.09.01-.13-.15-.01-.02-.02.05.07-.13.01-.08-.12-.03-.16.02-.10.10.01-.05.17.04.13-.18-.06-.14-.07.15-.17-.10.04-.15.04.09.21*.06.04-.22*.07.22*-.20-.49**.03.30**.03.24*-.14-.17.13-.31**-.12.03.04.04-.08-.19.03-.01-.21*-.22*.34**-.10-.13-.44**.09-.07-.13-.25*-.39**.05-.23*-.09-.25*-.18-.49**.25*-.17-.21*-.15-.51**.26*-.03-.08.10-.24*-.56**-.15.24*.15.20*.00-.05.10-.43**-.03-.03.03.20*-.13-.07.04-.23*-.08-.14.29**-.26*-.24*-.49**.24*-.09-.14-.18-.47**.14-.17-.27**-.13-.15-.48**.30**-.15-.24*-.19-.61**.15-.03-.11.07Self-reportsAgree Consc-.17-.30**.04.19.07.08.20*.16.15-.10.26**-.08.29**.20.05.13.29**-.20.23*-.18.03-.10-.22*-.16-.03.05.07-.05-.16-.07.19-.06.18.12-.19-.01.12-.18-.15-.28**.05-.18-.05.18-.19-.30**-.09-.03-.02.00.12-.01.09-.19.04.02.12.18.16.07-.03-.06.01-.11.01-.09-.06-.25*-.02.05.01.05-.27**.23*.05-.09.02.03-.23*.19.06.01-.05-.29**.14-.05.03.03Open.13.10-.04.08-.23*-.06-.17-.20*-.09-.05-.14.02-.22*-.08-.11-.19-.07.01-.08-.12.05.03-.15.10.17-.28**-.19-.26**.05.11-.21*.04-.08-.14.04.03-.21*.23*-.03.06.05-.03.31**.06Table 10: Pearsons correlation coefficients LIWC features personality ratingsEAR dataset, based analysis Mehl et al. (2006) (* = significantp < .05 level, ** = p < .01). features correlate significantlyleast one trait shown.3.4 Statistical ModelsVarious systems require different levels granularity modelling personality: mightimportant cluster users large groups correctly possible, systemmight need discriminate individual users. Depending applicationadaptation capabilities target system, possible use different types personalitymodels, depending whether personality modelling treated classification problem,472fiRecognising Personality Conversation TextDatasetTraitProsodyInt-maxInt-meanInt-stddevPitch-maxPitch-meanPitch-minPitch-stddevVoicedWord-per-secMRCAOABrown-freqConcFamImagK-F-freqK-F-ncatsK-F-nsampMeancNletNphonNsylT-L-freqUtterancetypeAssertionCommandPromptQuestionExtraObserver reportsEmotAgree ConscOpenExtraEmotSelf-reportsAgree Consc.42**.32**.40**.28**.17-.17-.13.23*.07.12.20.03.10-.45**-.23*.13.27**-.14.07-.02-.08.13.06-.02.07.06-.12-.13-.06-.12.05.04.08.03.03-.04.05.04-.08.23*-.18-.04.11.21*-.17.19.21*.36**-.03.12.09-.28**-.02.20*.10.22*.28**-.11-.25*-.08.01.07.07-.25*-.05.00-.10.07.21*-.34**-.04.09-.01-.16-.06-.03.03.04.03-.03.02.14.03.10.01-.04.08-.03.03.04-.23*-.26*.24*-.17.33**-.27**-.24*-.24*.29**-.14-.12-.16-.24*.01-.41**-.05-.28**.00-.04-.24*-.20*-.10.17.09-.04-.06.26**-.08-.20*-.24*-.23*.07-.03-.03-.18.25*.25*.23*.06.26**.07-.33**-.07-.33**.17.08.16-.25*.31**.36**.34**.16.21*-.16-.32**-.18-.35**.16.00.20-.34**.25*.28**.19.13-.12-.04.23*-.03.25*-.22*-.01-.15.23*-.23*-.16-.13-.19.04-.15-.10-.21*-.09-.06-.06-.04-.12.03.02-.02-.07.05.14.01.17.01-.24*.17.03.08-.18-.20-.06-.18-.05.07-.12.01-.06.05.05.08-.06.13.15.12.06.08-.12-.02-.13-.03-.01-.23*-.17-.07.12.13.10-.08-.05.00-.10.13-.21*.01.07.22*-.03-.08.36**-.16.01-.20*.27**-.11-.09.00.25*-.04-.02.13-.05.01-.06.21*.01-.01-.09-.01.22*-.02.21*.00-.05-.24*-.14.16.02.10OpenTable 11: Continuation Table 10, i.e. Pearsons correlation coefficients featurespersonality ratings EAR dataset (* = significant p < .05 level,** = p < .01). features correlate significantly least one traitshown.previous work Argamon et al. (2005) Oberlander Nowson (2006), whethermodel personality traits via scalar values actually generated self-reportsobserver methods used corpus collection described Section 3.1.support applications dialogue system adaptation, output generationlimited points extremes personality scale, introvert vs. extravertlanguage neurotic vs. emotionally stable, develop classification models splittingsubjects two equal size groups.However, model personality traits scalar values, two choices.treat personality modelling regression problem ranking problem.regression models replicate actual scalar values seen personality ratingsdata, also good argument treating personality ranking problemdefinition, personality evaluation assesses relative differences individuals, e.g.one person described extravert average population not. Moreover,Freund, Iyer, Schapire, Singer (1998) argue ranking models better fitlearning problems scales arbitrary values (rather reflecting real worldmeasures).473fiMairesse, Walker, Mehl & Mooreclassification regression models, use Weka toolbox (Witten & Frank,2005) training evaluation. order evaluate models personality classification,compare six different learning algorithms baseline returning majority class.classification algorithms analysed C4.5 decision tree learning (J48), Nearestneighbour (k = 1), Naive Bayes (NB), Ripper (JRip), Adaboost (10 rounds boosting)Support vector machines linear kernels (SMO).regression, compare five algorithms baseline model returning meanpersonality score. focus linear regression model, M5 regression tree, M5model tree returning linear model, REPTree decision tree, model based Supportvector machines linear kernels (SMOreg). Parameters algorithms setWekas default values.Concerning ranking problem, train personality models Big Five traitusing RankBoost, boosting algorithm ranking (Freund et al., 1998; Schapire, 1999).Given personality trait model, linguistic features personality scores converted training set ordered pairs examples x, y:= {(x, y)| x, language samples two individuals,x higher score personality trait}example x represented set indicator functions hs (x) 1 m.indicator functions calculated thresholding feature values (counts) describedSection 3.2. example, one indicator function is:(h100 (x) =1 Word-per-sec(x) 0.730 otherwiseh100 (x) = 1 xs average speech rate 0.73 words per second. single parameter associated indicator function, ranking score examplex calculatedXF (x) =hs (x)score used rank various language samples (written text conversation extracts),goal duplicating ranking found training data, training examples used set parameter values . Training process settingparameters minimise following loss function:Loss =1 Xeval(F (x) F (y))|T | (x,y)Teval function returns 1 ranking scores (x, y) pair misordered, 0otherwise. words, ranking loss percentage misordered pairs,order predicted scores doesnt match order dictated personality scoresquestionnaire.techniques used work express learned models rules decisiontrees, support analysis differences personality models (see Sections 4.3,5.3 6.3).474fiRecognising Personality Conversation Text4. Classification Resultsevaluate binary classification models based essays corpus self-reportspersonality, well models based EAR corpus self observer reports.results averaged 10-fold cross-validation, significance tests doneusing two-tailed paired t-test p < .05 level.4.1 Essays CorpusClassification results essays corpus self-reports Table 12. Interestingly,openness experience easiest trait model five classifiers six significantlyoutperform baseline four produce best performance trait,accuracies 62.1% using support vector machines (SMO). Emotional stabilityproduces second best performance four classifiers six, 57.4% accuracySMO model. Conscientiousness hardest trait model two classifierssignificantly outperform baseline, however SMO model performs well bestmodel extraversion agreeableness, around 55% correct classifications.find support vector machines generally perform best, Naive BayesAdaboostM1 second position. SMO significantly outperforms majority class baselinetrait. J48 decision tree recognising extraversion shown Figure 1,rule-based JRip model classifying openness experience 58.8% accuracy illustratedTable 16.TraitBase J48NNNBJRIPExtraversion50.04 54.44 53.27 53.35 52.70Emotional stability50.08 51.0951.6256.42 55.90Agreeableness50.36 53.51 50.1653.88 52.63Conscientiousness50.57 51.3752.1053.8052.71Openness experience 50.32 54.24 53.0759.57 58.85statistically significant improvement majoritybaseline (two-tailed paired t-test, p < .05)ADA55.0055.9852.7154.4559.09classSMO54.9357.3555.7855.2962.11Table 12: Classification accuracy two equal size bins essays corpus, using selfreports. Models majority class baseline (Base); J48 decision tree (J48);Nearest neighbour (NN); Naive Bayes (NB); JRip rule set (JRIP); AdaboostM1(ADA); Support vector machines (SMO).Feature set comparison: order evaluate feature set contributesfinal result, trained binary classifiers using algorithms producing best overallresults feature set. analyse LIWC MRC features essayscorpus, utterance type prosodic features dont apply written texts. useNaive Bayes, AdaboostM1 SMO classifiers give best performancesfull feature set. Results shown Table 13.475fiMairesse, Walker, Mehl & MooreArticles7.23> 7.23SexualityIntrovert0.12> 0.12ParenthesesApostrophes2.57> 2.5717.91> 17.910.64SadnessAchievementWords per sentenceExtravert1.52Introvert> 0.640.64> 1.52Extravert1.44ExtravertIntrovert> 1.44Introvert> 0.64FamiliarityIntrovert> 599.7599.7Positive emotionsIntrovert1.66> 1.66GroomingIntrovert0.11> 0.11ExtravertIntrovertFigure 1: J48 decision tree binary classification extraversion, based essayscorpus self-reports.Remarkably, see LIWC features outperform MRC features everytrait, LIWC features always perform slightly better fullfeature set. clearly suggests MRC features arent helpful LIWC featuresclassifying personality written text, however Table 13 shows stilloutperform baseline four traits five.Concerning algorithms, find AdaboostM1 performs best extraversion(56.3% correct classifications), SMO produces best models traits.suggests support vector machines promising modelling personality general.easiest trait model still openness experience, 62.5% accuracy using LIWCfeatures only.4.2 EAR CorpusClassification accuracies EAR corpus Table 14. find extraversioneasiest trait model using observer reports, Naive Bayes AdaboostM1476fiRecognising Personality Conversation TextFeature setNoneLIWC featuresMRC featuresClassifierBaseNBADASMONBADASMOSet size0888888141414Extraversion50.04 52.7156.34 52.7552.87 51.4553.88Emotional stability50.08 56.02 55.33 58.20 52.3952.0653.52Agreeableness50.36 54.12 52.7156.39 53.03 52.0653.31Conscientiousness50.57 53.92 54.48 55.62 53.0352.9553.84Openness experience 50.32 58.92 58.64 62.52 55.41 56.70 57.47statistically significant improvement majority classbaseline (two-tailed paired t-test, p < .05)Table 13: Classification accuracies two equal size bins essays corpus usingmajority class baseline (Base), Naive Bayes (NB), AdaboostM1 (ADA) Support Vector Machine (SMO) classifiers, different feature sets. Best modeltrait bold.outperforming baseline accuracy 73.0%. J48 decision tree extraversion 66.8% accuracy shown Figure 2. Emotional stability modelledcomparable success using Naive Bayes classifier, however improvement baseline lower extraversion (22.8% vs. 25.2%) classifiers dont performwell. Models observed conscientiousness also outperform baseline, 67.7% accuracy using Naive Bayes classifier, best model agreeableness produces 61.3%correct classifications. None models openness experience significantly outperform baseline, suggests openness experience expressed clearlystream consciousness essays self-reports EAR dataset. Support vectormachines dont perform well essays corpus, probably sparseness dataset. Self-reports much harder model observer reports givendataset size, none self-report classifiers significantly outperform majorityclass baseline.Feature set comparison: EAR corpus investigated importance 4feature sets: utterance type, LIWC, MRC, prosodic features. use Naive Bayesmodels observer ratings perform best features. Interestingly,Table 15 shows good classification accuracies extraversion come combination LIWC, MRC prosodic features, outperform baseline own,dont well 73.0% accuracy full feature set. Moreover, extraversiontrait prosody seems make difference. LIWC features mainindicators emotional stability, although model features still performs better. MRC features important classifying conscientiousness (66.8%),prosodic features produce best model openness experience 64.6% accuracy,improving model features. Although utterance type features never outperform baseline own, lack significance could result small1. Although equal size bins used, baseline accuracies differ 50% randomsampling cross-validation.477fiMairesse, Walker, Mehl & MooreDataObsObsObsObsObsSelfSelfSelfSelfSelfTrait Base J48NNNBJRIP ADASMOExtra 47.78 66.78 59.33 73.00 60.4473.00 65.78Emot 51.11 62.56 58.22 73.89 56.2248.7860.33Agree 47.78 48.78 51.89 61.33 51.8952.8956.33Consc 47.78 57.67 61.56 67.67 61.5660.22 57.11Open 47.78 52.22 46.78 57.0049.6750.5655.89Extra 47.78 48.78 49.67 57.3350.5654.4449.89Emot 51.11 45.56 46.78 50.4446.7841.8944.33Agree 52.22 47.89 50.89 58.3356.8955.2252.33Consc 51.11 33.44 45.56 39.3343.1146.1153.22Open 51.11 52.00 42.22 61.4445.0056.0047.78statistically significant improvement majority classbaseline (two-tailed paired t-test, p < .05)Table 14: Classification accuracy two equal size bins EAR corpus, observerratings (Obs) self-reports (Self). Models majority class baseline (Base)1 ;J48 decision tree (J48); Nearest neighbour (NN); Naive Bayes (NB); JRip rulesset (JRIP); AdaboostM1 (ADA); Support vector machines (SMO).Feature setNone Type LIWCMRCProsodySet size04881411Extraversion47.7845.6768.8968.7867.56Emotional stability51.1160.2269.8960.7861.78Agreeableness47.7857.5654.0058.6750.44Conscientiousness47.7859.6760.2266.7852.11Openness experience 47.7853.1161.1154.0064.56statistically significant improvement majority classbaseline (two-tailed paired t-test, p < .05)Table 15: Classification accuracies EAR corpus observer reports using NaiveBayes classifier, different feature sets (None=baseline, Type=utterance type).Models performing better full feature set bold.dataset size, since Section 3.3 showed utterance type features strongly correlateseveral personality traits.4.3 Qualitative AnalysisDecision trees rule-based models easily understood, therefore helpuncover new linguistic markers personality. models replicate previous findings,link verbosity extraversion (c.f. Word count node Figure 2),also provide many new markers.478fiRecognising Personality Conversation TextWord count1284> 1284ExtravertMetaphysical issues0.25> 0.25Commas8.72Articles> 8.72EatingExtravert3.51> 3.51ExtravertSpace0.51> 0.513.22IntrovertSadExtravert> 3.22Frequency use0.15> 0.156072IntrovertExtravertExtravert> 6072IntrovertFigure 2: J48 decision tree binary classification extraversion, based EAR corpusobserver reports.#123456Ordered rules(School 1.47) (Motion 1.71) open(Occup 2.49) (Sixltr 13.11) (School 1.9) (I 10.5) open(Fam 600.335106) (Friends 0.67) open(Nlet 3.502543) (Number 1.13) open(School 0.98) (You 0) (AllPct 13.4) openfeature values OpenTable 16: JRip rule set binary classification openness experience, basedessays corpus.model self-assessed openness experience detailed Table 16 shows students referring lot school work tend low scores trait (Rules 1, 25). expected, avoidance longer words also indicative lack cre479fiMairesse, Walker, Mehl & Mooreativity/conventionality (Rules 4 5), well use high-familiarity wordsreferences friends (Rule 3).model observed extraversion Figure 2 shows word count important feature classifying trait observer. model also suggests givenlow verbosity, extraversion still manifest use words related metaphysical issues together articles, well use many commas.association extraversion avoidance articles probably reflects usepronouns common nouns confirms previous findings associating extraversionimplicit language (Heylighen & Dewaele, 2002).Interestingly, decision tree trained essays corpus Figure 1 self-reportedextraversion differs lot observer model Figure 2. word countimportant feature observers, doesnt seem marker self-assessed extraversion(see Section 3.3), although number words per sentence used discriminatesubset data. hand, self-report model associates introversionuse articles, also case observer model. sexual contentdoesnt affect observer model, second important feature modelling selfreported extraversion. example, participants using many sex-related words modelledintrovert, unless avoid parentheses words related sadness.5. Regression Resultsalso trained regression models using corpora. baseline model returningmean personality scores training set. use relative absolute errorevaluation, ratio models prediction error error producedbaseline. low relative error therefore indicates model performs betterconstant mean baseline, 100% relative error implies performance equivalentbaseline. results averaged 10-fold cross-validation, significancetests done using two-tailed paired t-test p < .05 level.5.1 Essays CorpusRegression results essays corpus self-reports Table 17. Paired t-testsshow emotional stability openness experience produce models significantlyimprove baseline. classification task, openness experienceeasiest trait model using essays: four regression models five outperform baseline. M5 model tree produces best result 93.3% relative error opennessexperience (6.7% error decrease), 96.4% relative error emotional stability.terms correlation model predictions actual ratings, modelemotional stability openness experience produce Pearsons correlation coefficients0.24 0.33, respectively. Although magnitude improvement seems relativelysmall, one needs keep mind difficulty regression task binary classification task: fine-grained personality recognition problem, requiringassociation exact scalar value individual.Feature set comparison: Table 18 provides results comparison LIWCMRC feature sets using linear regression model, M5 model tree support480fiRecognising Personality Conversation TextTraitBaseLRM5RM5REPExtraversion100.00 99.1799.3199.2299.98Emotional stability100.00 96.8799.7596.4399.35Agreeableness100.00 98.9299.8699.2299.78Conscientiousness100.00 98.68100.6298.56100.47Openness experience 100.00 93.5897.68 93.2799.82statistically significant improvement mean valuebaseline (two-tailed paired t-test, p < .05)SMO100.6598.35100.2899.3094.19Table 17: Relative error regression models trained essays corpus features.Models mean value baseline (Base), linear regression (LR); M5 regression tree (M5R), M5 model tree linear models (M5), REPTree (REP)Support vector machines regression (SMO).vector machine algorithm regression (SMOreg). Overall, LIWC features perform betterMRC features except extraversion, linear regression modelMRC features produces better results full feature set. traits,LIWC features perform better full feature set, almost alwayssignificantly outperform baseline. model openness experience produceslowest relative error, 6.50% improvement baseline.Feature setNoneLIWC featuresMRC featuresRegression modelBaseLRM5SMOLRM5SMOExtraversion100.00 99.3999.25 100.898.79 98.79 99.13Emotional stability100.00 96.71 96.42 98.0399.4999.5499.89Agreeableness100.00 98.50 98.52 99.5299.7599.8199.31Conscientiousness100.00 98.23 98.14 99.4699.2399.2399.16Openness experience 100.00 93.50 93.70 94.14 97.44 97.44 97.26statistically significant improvement mean valuebaseline (two-tailed paired t-test, p < .05)Table 18: Relative error regression models trained essays corpus MRCLIWC feature sets only. Models linear regression (LR); M5 model tree(M5); Support vector machines regression (SMO). Best models bold.5.2 EAR CorpusRegression results EAR corpus Table 19. paired t-test (two-tailed, p < .05)cross-validation folds shows error reduction significant observedextraversion (79.9% relative error, i.e. 20.1% error decrease), conscientiousness (14.3% improvement) emotional stability (13.3% improvement). extraversion easiesttrait model observer ratings, models agreeableness openness experiencedont outperform baseline.481fiMairesse, Walker, Mehl & Mooreterms correlation model predictions actual ratings, modelsextraversion, emotional stability conscientiousness respectively produce Pearsonscorrelation coefficients 0.54, 0.47 0.44, significantly outperforming baseline.correlations relatively high, given average correlations ratingspair observers 0.54 extraversion, 0.29 emotional stability 0.51conscientiousness (18 observers, 31 33 data points pair).Linear regression support vector machines perform poorly, suggestingrequire bigger dataset essays corpus. classification task, self-reportsEAR corpus clearly difficult model: none models show significantimprovement baseline.DataObsObsObsObsObsSelfSelfSelfSelfSelfTraitBaseLR M5RM5REPExtraversion100.00 179.1682.1680.1579.94Emotional stability100.00 302.7492.0386.75 100.51Agreeableness100.00 242.6896.73111.1699.37Conscientiousness100.00 188.1882.6890.8598.08Openness experience 100.00 333.65 101.64119.53102.76Extraversion100.00 204.96 104.50118.4499.94Emotional stability100.00 321.97 104.10108.3999.91Agreeableness100.00 349.87 106.90110.84101.64Conscientiousness100.00 177.12 103.39120.29107.33Openness experience 100.00 413.70 107.12122.68126.31statistically significant improvement mean valuebaseline (two-tailed paired t-test, p < .05)SMO140.05162.05173.97131.75213.20176.51233.19201.80124.91233.01Table 19: Relative error regression models, observer ratings (Obs) self-reports(Self) EAR corpus. Models mean value baseline (Base); linearregression (LR); M5 regression tree (M5R); M5 model tree linear models(M5); REPTree decision tree (REPT); Support vector machines regression(SMO). relative error baseline model 100%.Feature set comparison: trained regression models individual feature setusing observer reports, since self-reports didnt produce significant result usingfeatures. focus three regression tree algorithms perform bestfeatures. Table 20 shows LIWC good predictors observed extraversion,REPTree outperforms model features 76.4% relative error(23.6% improvement baseline). LIWC features also produce best regressionmodel conscientiousness (82.1% relative error, 17.9% improvement). Surprisingly,best model emotional stability contains prosodic features, 85.3% relativeerror (14.7% improvement). finding suggests speech cues crucialperception neuroticism, could explain Gill Oberlander (2003) reportedlow correlation self-assessed observed emotional stability using text only.482fiRecognising Personality Conversation Textclassification task, utterance type features dont show significant improvementown.SetModelExtraEmotAgreeConscOpenUtterance typeLIWC featuresMRC featuresM5RM5REPM5RM5REPM5RM5REP100.0103.7101.881.6177.8476.3899.23102.299.69102.5103.0102.690.79109.6109.693.1396.08104.4102.4102.7111.198.49111.7102.5104.1112.5102.2100.095.04104.182.1396.6293.5097.00102.091.24101.199.03109.9105.1129.5103.7106.2111.6105.5statistically significant improvement mean valuebaseline (two-tailed paired t-test, p < .05)Prosodic featuresM5RM5REP94.0790.9188.3192.2485.3297.95100.0108.4108.9100.0104.7101.7100.1113.599.93Table 20: Relative error regression models trained EAR corpus individualfeature sets. Models M5 regression tree (M5R); M5 model tree linearmodels (M5); REPTree regression tree (REP). Best models bold.5.3 Qualitative AnalysisRegression trees extraversion conscientiousness Figures 3 4. suggestedcorrelations Section 3.3, model Figure 3 shows voices pitchvariation intensity play important role modelling extraversion. high verbaloutput perceived sign extraversion (see Word Count nodes), confirming previousfindings (Scherer, 1979). hand, low mean pitch combined constantvoice intensity characterises high introverts.Figure 4 suggests conscientious people use fewer swear words content relatedsexuality, preferring longer words. figure also shows conscientiouspeople use fewer pronouns, i.e. explicit style, well words relatedcommunication (e.g., talk share).6. Ranking ResultsResults corpora different feature sets Tables 21 22. modelstrained 100 rounds boosting. baseline model ranks extracts randomly,producing ranking loss 0.5 average (lower better). Results averaged10-fold cross-validation, significance tests done using two-tailed paired t-testp < .05 level.6.1 Essays CorpusTable 21 shows openness experience produces best ranking modelessays corpus, producing ranking loss 0.39 (lower better). Remarkably, traiteasiest model three recognition tasks corpus.case conversational data, seems streams consciousness, generallypersonal writings, likely exhibit cues relative authors openness experience.Emotional stability produces second best model ranking loss 0.42, followedconscientiousness extraversion, model agreeableness produces highest483fiMairesse, Walker, Mehl & MooreWord count675> 675Word countMean pitch231> 231Intensity variation6.392.863.231299> 12993.834.24> 6.393.02Figure 3: M5 regression tree observed extraversion, computed using EAR corpus.target output ranges 1 5.5, 5.5 means strongly extravert (thehighest value means observer ratings). mean pitch valueexpressed Hertz, intensity variation (standard deviation) decibels.ranking loss. models significantly outperform random ranking baseline,actual improvement still relatively small.Feature setBaseLIWC MRCExtraversion0.50 0.44 0.440.46Emotional stability0.50 0.42 0.420.47Agreeableness0.50 0.46 0.460.48Conscientiousness0.50 0.44 0.440.47Openness experience 0.50 0.39 0.390.44statistically significant improvementrandom ordering baseline(two-tailed paired t-test, p < .05)Table 21: Ranking loss essays corpus 10-fold cross-validation differentfeature sets random ordering baseline (Base). Best models bold(lower better).Feature set comparison: evaluate features contribute ranking accuracy,trained ranking model feature set. Table 21 clearly shows LIWCfeatures contributors model accuracy, inclusion MRC featuresdoesnt reduce ranking loss trait.484fiRecognising Personality Conversation TextSwear words0.93> 0.93Sexuality wordsPronouns16.74.01> 16.73.630.62Comm. words1.463.15> 1.463.26> 0.62Syllables per word> 1.141.142.90Body states words0.592.96> 0.592.98Figure 4: M5 regression tree observed conscientiousness, computed using EAR corpus. target output ranges 1 7, 7 means strongly conscientious(Comm. words ratio words related communication).6.2 EAR CorpusConcerning EAR corpus, Table 22 reporting experiments using features, showsmodels extraversion, agreeableness, conscientiousness, openness experiencebetter random ranking baseline. Emotional stability difficult traitmodel, agreeableness conscientiousness produce best results, rankinglosses 0.31 0.33 respectively.Feature setNoneLIWC MRC TypeExtraversion0.500.35 0.360.450.55Emotional stability0.500.410.410.390.43Agreeableness0.50 0.31 0.320.440.45Conscientiousness0.50 0.33 0.360.410.44Openness experience0.500.38 0.370.410.49statistically significant improvement randomordering baseline (two-tailed paired t-test, p < .05)Prosody0.260.450.540.550.44Table 22: Ranking loss EAR corpus observer reports1 10-fold crossvalidation different feature sets (None=baseline, Type=utterance type). Bestmodels bold (lower better).485fiMairesse, Walker, Mehl & MooreFeature set comparison: looking individual feature sets, Table 22 showsLIWC features perform significantly better baseline dimensions emotional stability, emotional stability best predicted MRC features (0.39ranking loss). Interestingly, prosodic features good predictors extraversion,lower ranking error full feature set (0.26). model produces best overallresult, 74% chance model detect extravert among twounseen conversation extracts. previous recognition tasks, utterance type featuresnever significantly outperform baseline.6.3 Qualitative AnalysisRankBoost rules indicate impact feature recognition personalitytrait magnitude parameter associated feature. Tables 2325 show rules impact best models, associatedvalues. feature labels Table 6. example, model extraversion Table 23confirms previous findings associating trait longer conversations (Rule 5),high speech rate (Rules 1 4) high pitch (Rules 2, 6 7) (Nass & Lee, 2001).new markers emerge, high pitch variation introverts (Rules 15, 1820), contradicting previous findings reported Scherer (1979).Extraversion model prosodic features# Positive rules# Negative rules1 Word-per-sec 0.73 1.43 11 Pitch-max 636.352 Pitch-mean 194.61 0.41 12 Pitch-slope 312.673 Voiced 647.350.41 13 Int-min 54.304 Word-per-sec 2.22 0.36 14 Word-per-sec 1.695 Voiced 442.950.31 15 Pitch-stddev 115.496 Pitch-max 599.880.30 16 Pitch-max 637.277 Pitch-mean 238.99 0.26 17 Pitch-slope 260.518 Int-stddev 6.960.24 18 Pitch-stddev 118.109 Int-max 85.870.24 19 Int-stddev 6.3010 Voiced 132.350.23 20 Pitch-stddev 119.73-0.05-0.06-0.06-0.06-0.06-0.06-0.12-0.15-0.18-0.47Table 23: Subset RankBoost model extraversion prosodic features only,based EAR conversations observer reports. Rows 1-10 represent rulesproducing highest score increase, rows 11-20 indicate evidenceend scale, i.e. introversion.Concerning agreeableness, Rules 1 20 Table 24 suggest agreeable peopleuse longer words shorter sentences, Rules 2 4 show expresstentativity (with words like maybe perhaps) positive emotions (e.g., happy good).Anger swear words greatly reduce agreeableness score (Rules 12, 13, 18 19),well use negations (Rule 15).1. also built models self-reports personality based EAR corpus, none significantlyoutperforms baseline.486fiRecognising Personality Conversation TextAgreeableness model features# Positive rules# Negative rules1 Nphon 2.660.56 11 Fam 601.612 Tentat 2.830.50 12 Swear 0.413 Colon 0.030.41 13 Anger 0.924 Posemo 2.67 0.32 14 Time 3.715 Voiced 5840.32 15 Negate 3.526 Relig 0.430.27 16 Fillers 0.547 Insight 2.090.25 17 Time 3.698 Prompt 0.06 0.25 18 Swear 0.619 Comma 4.60 0.23 19 Swear 0.4510 Money 0.380.20 20 WPS 6.13-0.16-0.18-0.19-0.20-0.20-0.22-0.23-0.27-0.27-0.45Table 24: Best RankBoost model based EAR conversations agreeableness. Rows1-10 represent rules producing highest score increase, rows 11-20indicate evidence end scale, i.e. disagreeableness.Table 25 shows conscientious people talk lot work (Rule 1),unconscientious people swear lot (Rules 19). Insight words (e.g., think know)also good indicator conscientiousness, well words expressing positive feelings likehappy love (Rule 2 3). Interestingly, conscientious people modelledhigh variation voice intensity (Rule 4). hand, Rule 20 showsspeaking loud produces opposite effect, well high pitch (Rule 13).Long utterances also indicative low conscientiousness (Rule 12).rule sets presented contain extreme rules ranking models,contain many additional personality cues arent identified typicalcorrelational analysis. example, high speech rate high mean pitch tendcontribute high extraversion ranking Table 23s model, dont correlatesignificantly observer ratings, detailed Table 11. Similarly, positive emotionwords (Posemo) avoidance long utterances (WPS) indicate agreeablenessmodel Table 24, features dont correlate significantly agreeablenessratings.7. Related Workknowledge, two studies automatic recognition personality. studies focused classification written texts basedself-reports, rather using continuous modelling techniques here.Argamon et al. (2005) use essays corpus Pennebaker King (1999),results directly comparable ours. work, use top-down approachfeature definition: feature set consists relative frequencies 675 function wordsword categories based networks theory Systemic Functional Grammar. However,simplify task removing middle third dataset, thereby potentiallyincreasing precision cost reducing recall maximum 67%. train SMOmodels top third lower third essays corpus two personality traits487fiMairesse, Walker, Mehl & MooreConscientiousness model# Positive rules#1 Occup 1.210.37 112 Insight 2.150.36 123 Posfeel 0.300.30 134 Int-stddev 7.83 0.29 145 Nlet 3.290.27 156 Comm 1.200.26 167 Nphon 2.660.25 178 Nphon 2.670.22 189 Nphon 2.760.20 1910 K-F-nsamp 329 0.19 20featuresNegative rulesSwear 0.20WPS 6.25Pitch-mean 229Othref 7.64Humans 0.83Swear 0.93Swear 0.17Relig 0.32Swear 0.65Int-max 86.84-0.18-0.19-0.20-0.20-0.21-0.21-0.24-0.27-0.31-0.50Table 25: Best RankBoost model based EAR conversations conscientiousness. Rows1-10 represent rules producing highest score increase, rows 11-20indicate evidence end scale, i.e. unconscientiousness.extraversion emotional stability, achieving accuracies subset data58% traits.believe likely personality recognition models need based fullrange values useful practical application. Nevertheless, orderdirect comparison, also removed middle third essays dataset trainedSMO classifier LIWC features. obtain 57% classification accuracy extraversion 60% emotional stability, whereas algorithm appliedwhole corpus, obtain accuracies 55% extraversion 57% emotional stability,significantly outperforming baseline (see Table 12). Using EAR conversational dataobserver reports, accuracies SMO models remain 65% extraversionincrease 63% emotional stability (see Table 14).results suggest feature set combination Argamon et al.could possibly improve performance, feature sets perform comparably. Usingfeatures, Argamon et al. identify relative frequencies set function wordsbest predictor extraversion, suggesting refer norms certaintysalient. Concerning emotional stability, feature set characterising appraisalproduces far best results. Appraisal features relative frequencies positivenegative words well frequencies category Attitude network (e.g., affect,appreciation, judgement, etc.). find neurotics tend use words relatednegative appraisal affect, fewer appreciation appraisal words, suggestingfocus personal feelings.Oberlander Nowson (2006) follow bottom-up feature discovery method training Naive Bayes SMO models four Big Five traits corpus personalweblogs, using n-gram features extracted dataset. order able compareArgamon et al., report experiments remove texts non-extremepersonality scores corpus, also report experiments applying classificationalgorithms seven different ways partitioning whole corpus classes, motivatedapproximating continuous modelling approach. Although, results arent directly488fiRecognising Personality Conversation Textcomparable based different corpora, report resultsuse instances dataset, believe discarding test data increasesprecision cost making recall unacceptably low.building Naive Bayes models using frequent bi-grams tri-gramscomputed full corpus, Oberlander Nowson (2006) find model agreeableness one outperforming baseline (54% accuracy, level significancementioned). keeping n-grams distinctive two extreme sets giventrait, accuracies range 65% extraversion 72% emotional stability. Finally,applying automatic feature selection algorithm filtered set, accuracies increase range 83% emotional stability 93% agreeableness. testingwhether models generalise different corpus weblogs, Nowson Oberlander(2007) report binary classification accuracies ranging 55% extraversion 65%conscientiousness. Interestingly, models trained extreme instancesoriginal corpus seem outperform models trained full corpus, although levelsignificance mentioned. studies show careful feature selection greatly improvesclassification accuracy, n-grams appropriate model self-reports personality, although, Oberlander Nowson point out, features likely overfit.would therefore interesting test future work whether feature sets usedgeneralise another dataset.Oberlander Nowson (2006) also report results 3-way 5-way classification,order approximate finer-grained continuous personality ratings used psychology(as scalar models present here). obtain maximum 44.7%extraversion 5 bins, using raw n-grams (baseline 33.8%). resultsdirectly comparable different corpus, different featuresets. Moreover, provided results multiple classification experiments,models cannot take account fact different classes parttotal ordering, thus resulting models forced ignore importancefeatures correlate ordering across classes. believe regressionranking models appropriate finer-grained personality recognition (see Sections5 6).evaluate claim, first mapped output best classifier rankingcompared RankBoost models. trained Naive Bayes classifier EARcorpus observer reports features, using 5 equal size bins.2 test fold10-fold cross-validation, computed ranking loss produced classifier basedordering five classes. Results Table 26 show RankBoost significantlyoutperforms classifier four traits five (p < .05), improvement closesignificance emotional stability (p = 0.12).RankBoosts goal minimise ranking loss, comparison likelyfavour ranking models. Therefore, also mapped output RankBoost models5 classification bins see whether RankBoost could perform well classifierclassification task. divided output ranking 5 bins, containing 20%slice contiguously ranked instances. Results Table 26 show Naive Bayesclassifier never outperforms RankBoost significantly, ranking model produces2. Oberlander Nowson use unequal bins defined personality trait using standard deviationmean, may easier task equal size bins.489fiMairesse, Walker, Mehl & MooreTaskRankingClassificationModelBase NB Rank Base NB RankExtraversion0.50 0.48 0.3520.0 32.332.1Emotional stability0.50 0.50 0.4120.0 21.921.9Agreeableness0.50 0.50 0.3120.0 28.437.8Conscientiousness0.50 0.46 0.3320.0 34.730.3Openness experience 0.50 0.53 0.3820.0 19.826.8statistically significant improvementmodel (two-tailed t-test, p < .05)Table 26: Comparison ranking (Rank) classification models (NB) personality ranking classification tasks (5 bins). Evaluation metrics rankingloss (lower better) classification accuracy (higher better), respectively.Results averaged 10-fold cross-validation.better mean accuracy agreeableness (38%) openness experience (27%),accuracy emotional stability (22%). sum, find ranking models performwell classification better ranking compared best classifier, thusmodelling personality using continuous models accurate.8. Discussion Future Workshow personality recognised computers language cues.3recent work AI explores methods automatic detection types pragmaticvariation text conversation, opinion, emotion, deception, date,know two studies besides automatic recognition user personality (Argamon et al., 2005; Mairesse & Walker, 2006a, 2006b; Oberlander & Nowson, 2006).knowledge, results presented first demonstrate statistically significantresults texts recognise personality conversation (Mairesse & Walker, 2006a,2006b). present first results applying regression ranking models ordermodel personality recognition using continuous scales traditional psychology.also systematically examine use different feature sets, suggested previous psycholinguistic research. Although features suggested psycholinguisticliterature, reported correlations personality ratings generally weak:obvious would improve accuracies statistical models unseen subjects.Computational work modelling personality primarily focused methodsexpressing personality virtual agents tutorial systems, concepts related personality politeness, emotion, social intelligence (Walker, Cahn, & Whittaker,1997; Andre, Klesen, Gebhard, Allen, & Rist, 1999; Lester, Towns, & FitzGerald, 1999;Wang, Johnson, Mayer, Rizzo, Shaw, & Collins, 2005) inter alia. Studies shownuser evaluations agent personality depend users personality (Reeves & Nass,1996; Cassell & Bickmore, 2003), suggesting ability model users personality3. online demo personality recognition tool based models presented paperdownloaded www.dcs.shef.ac.uk/cogsys/recognition.html490fiRecognising Personality Conversation Textrequired. Models present automatic recognition user personalityone way acquire user model (Chu-Carroll & Carberry, 1994; Thompson, Goker,& Langley, 2004; Zukerman & Litman, 2001). plan test models user modelscontext adaptive dialogue system.Table 27 summarises results personality traits recognition tasksanalysed. clearly emerges extraversion easiest trait modelspoken language, followed emotional stability conscientiousness. Concerning written language, models openness experience produce best results recognitiontasks. also see feature selection important, best modelscontain small subset full feature set. Prosodic features important modelling observed extraversion, emotional stability openness experience. MRC featuresuseful models emotional stability, LIWC features beneficial traits.also analysed qualitatively features influence specific models,recognition tasks, well reporting correlations feature personalitytraits Section 3.3.Although parameters algorithms optimised, bottomTable 27 seems indicate simple models like Naive Bayes regression trees tendoutperform complex ones (e.g., support vector machines), confirming resultsOberlander Nowson (2006). However, experiments larger essays corpus(more 2,400 texts) show support vector machines boosting algorithms produce higher classification accuracies. therefore likely algorithms would alsoperform better spoken data trained much larger corpus EARdataset, parameters optimised.hypothesised models observed personality outperform models selfassessed personality. results suggest observed personality may easiermodel self-reports, least conversational data. EAR corpus, find manygood results models observed personality, models self-assessed personalitynever outperform baseline. may due objective observers using similar cuesmodels, self-reports personality may influenced factorsdesirability trait (Edwards, 1953). Hogan (1982) introduced distinctionagents observers perspective personality assessment. agentsperspective conceptually taps persons identity (or personality inside),observers perspective contrast taps persons reputation (or personalityoutside). facets personality important psychological implications. personsidentity shapes way person experiences world. persons reputation, however,psychologically less important: determines whether people get hired fired (e.g.,reputation honesty), get married divorced, get adored stigmatised.harder assess, observers perspective received comparatively little attentionpsychology. Given everyday life people act observers peoples behaviourstime, external perspective naturally high theoretical importancesocial relevance (Hogan, 1982).Recent research exploring issue psychology based Brunswikian Lensmodel (Brunswik, 1956), used extensively recent years explainkernel truth social perception strangers. Use lens model personalityresearch reflects widely shared assumptions expression personality commu491fiMairesse, Walker, Mehl & MooreTaskBaselineClassificationn/anone50%n/aRegressionnone0%n/aRankingnone0.501%4%2%2%7%RankRankRankRankRankLIWCLIWCLIWCLIWCLIWC0.440.420.460.440.3924%15%3%18%1%RankRankRankRankRankprosodyMRCLIWC0.260.390.310.330.37Self-report models trained written data (essays):ExtraversionEmotional stabilityAgreeablenessConscientiousnessOpenness experienceADASMOSMOSMOSMOLIWCLIWCLIWCLIWCLIWC56%58%56%56%63%LRM5LRM5M5MRCLIWCLIWCLIWCObserver report models trained spoken data (EAR):ExtraversionEmotional stabilityAgreeablenessConscientiousnessOpenness experienceNBNBNBNBNBprosody73%74%61%68%65%REPM5M5RM5RM5LIWCprosodyall*LIWCtype*Table 27: Comparison best models trait, three recognition tasks.table entry contains algorithm, feature set, model performance.See Sections 3.2 3.4 details. Depending task, evaluation metric either (1) classification accuracy; (2) percentage improvementregression baseline; (3) ranking loss. Asterisks indicate results arentsignificant p < .05 level.nicatively functional, i.e. (a) latent attributes persons expressed via observablecues; (b) observers rely observable cues infer latent attributes others; (c) observers use appropriate cues is, implicit assumptions relationsobservable cues latent attributes extent accurate. model alsouseful identifying observable cues mediate convergences judgmentslatent attributes direct measures attributes (Scherer, 2003; Heinrich &Borkenau, 1998).discrepancies markers self-assessed observed personality,another issue identification appropriate model given specific application.gold standard approximated either observer self-reports, howeverlikely specific trait one type report closer true personality.hypothesis remains tested traits high visibility (e.g., extraversion)accurately assessed using observer reports, tend yield higher interjudge agreement (Funder, 1995), low visibility traits (e.g., emotional stability)better assessed oneself. personality recogniser aiming estimate true personalitywould therefore switch observer models self-report models, dependingtrait assessment.Beyond practical applications personality recognition models, work alsoattempt explore different ways looking relation personality language. looked various personality recognition tasks, applied different learning492fiRecognising Personality Conversation Textmethods Section 3.4. tasks vary complexity: ranking model directlyderived regression model, classification model derived eitherranking regression model. type model closer actual relationlanguage, generally behaviour, personality? personality vary continuously, clusters people similar trait combinations? relationcontinuous, classification algorithms never able produce accurate modelstwo classes, dont take account ordering classes.ranking models outperform classifiers (see Section 7), given wide range individualdifferences reflected literature Big Five (Allport & Odbert, 1936; Norman,1963; Goldberg, 1990), believe personality varies continuously among memberspopulation, suggesting regression ranking models accuratelong run. hypothesis supported recent work medical research showingantisocial personality disorder varies continuously (Marcus, Lilienfeld, Edens, & Poythress,2006). Regression provides detailed model output variables, depending whether absolute differences personality scores meaningful,relative orderings people matter, ranking may appropriate. Additionalmodels could also tried ranking task, support vector algorithms ordinal regression (Herbrich, Graepel, & Obermayer, 2000). Moreover, future workassess whether optimising parameters learning algorithms improves performance.future work, would like improve models examine wellperform across dialogue domains. clear whether accuracies high enoughuseful. Applications involving speech recognition introduce noise featuresexcept prosodic features, probably reducing model accuracy, since EARcorpus relatively small, expect training data would improve performance.Additionally, believe inclusion gender feature would produce bettermodels, actual language correlates perceived personality shown dependgender speaker (Mehl et al., 2006). also believe future workinvestigate combination individual features trait-dependent way. Another issuepoor performance utterance type featuressince significant correlationresults features Section 3.3, unclear features usefulstatistical models. could possibly arise small size datasets,relatively low accuracy hand-crafted automatic tagger, comparedwork using supervised learning methods (Stolcke, Ries, Coccaro, Shriberg, Bates, Jurafsky,Taylor, Martin, Ess-Dykema, & Meteer, 2000; Webb, Hepple, & Wilks, 2005).begun test models spoken language generator (Mairesse &Walker, 2007). future work, plan compare utility models trained out-ofdomain corpora, here, methods training models, termsutility automatic adaptation output generation dialogue systems.Acknowledgmentswould like thank James Pennebaker giving us access essays data.work partially funded Royal Society Wolfson Research Merit Award MarilynWalker, Vice Chancellors studentship Francois Mairesse.493fiMairesse, Walker, Mehl & MooreReferencesAllport, G. W., & Odbert, H. S. (1936). Trait names: psycho-lexical study. PsychologicalMonographs, 47 (1, Whole No. 211), 171220.Andre, E., Klesen, M., Gebhard, P., Allen, S., & Rist, T. (1999). Integrating modelspersonality emotions lifelike characters. Proceedings WorkshopAffect Interactions - Towards new Generation Interfaces, pp. 136149.Argamon, S., Dhawle, S., Koppel, M., & Pennebaker, J. (2005). Lexical predictorspersonality type. Proceedings Joint Annual Meeting InterfaceClassification Society North America.Biber, D. (1988). Variation across Speech Writing. Cambridge University Press.Boersma, P. (2001). Praat, system phonetics computer. Glot International,5 (9/10), 341345.Bono, J. E., & Judge, T. A. (2004). Personality transformational transactionalleadership: meta-analysis. Journal Applied Psychology, 89 (5), 901910.Breck, E., Choi, Y., & Cardie, C. (2007). Identifying expressions opinion context.Twentieth International Joint Conference Artificial Intelligence (IJCAI).Brunswik, E. (1956). Perception Representative Design Psychological Experiments. University California Press, Berkeley, CA.Byrne, D., & Nelson, D. (1965). Attraction linear function proportion positivereinforcements. Journal Personality Social Psychology, 1, 659663.Cassell, J., & Bickmore, T. (2003). Negotiated collusion: Modeling social languagerelationship effects intelligent agents. User Modeling User-Adapted Interaction,13, 89132.Chu-Carroll, J., & Carberry, S. (1994). plan-based model response generationcollaborative task-oriented dialogue. Proceedings 12th National ConferenceArtificial Intelligence (AAAI), pp. 799805.Coltheart, M. (1981). MRC psycholinguistic database. Quarterly Journal Experimental Psychology, 33A, 497505.Costa, P. T., & McCrae, R. R. (1992). NEO PI-R Professional Manual. PsychologicalAssessment Resources, Odessa, FL.Dewaele, J.-M., & Furnham, A. (1999). Extraversion: unloved variable appliedlinguistic research. Language Learning, 49 (3), 509544.Donnellan, M. B., Conger, R. D., & Bryant, C. M. (2004). Big Five enduringmarriages. Journal Research Personality, 38, 481504.494fiRecognising Personality Conversation TextEdwards, A. L. (1953). relationship judged desirability traitprobability endorsed. Journal Applied Psychology, 37, 9093.Enos, F., Benus, S., Cautin, R., Graciarena, M., Hirschberg, J., & Shriberg, E. (2006).Personality factors human deception detection: Comparing human machineperformance. Proceedings ICSLP.Eysenck, H. J. (1991). Dimensions personality: 16, 5 3? criteria taxonomicparadigm. Personality Individual Differences, 12 (8), 773790.Fast, L. A., & Funder, D. C. (2007). Personality manifest word use: Correlationsself-report, acquaintance-report, behavior. Journal Personality SocialPsychology, press.Freund, Y., Iyer, R., Schapire, R. E., & Singer, Y. (1998). efficient boosting algorithmcombining preferences. Proceedings 15th International ConferenceMachine Learning, pp. 170178.Funder, D. C. (1995). accuracy personality judgment: realistic approach.Psychological Review, 102, 652670.Funder, D. C., & Sneed, C. D. (1993). Behavioral manifestations personality: ecological approach judgmental accuracy. Journal Personality Social Psychology,64 (3), 479490.Furnham, A. (1990). Language personality. Giles, H., & Robinson, W. (Eds.),Handbook Language Social Psychology. Winley.Furnham, A., Jackson, C. J., & Miller, T. (1999). Personality, learning style workperformance. Personality Individual Differences, 27, 11131122.Furnham, A., & Mitchell, J. (1991). Personality, needs, social skills academic achievement: longitudinal study. Personality Individual Differences, 12, 10671073.Gill, A., & Oberlander, J. (2003). Perception e-mail personality zero-acquaintance:Extraversion takes care itself; neuroticism worry. Proceedings 25thAnnual Conference Cognitive Science Society, pp. 456461.Gill, A. (2003). Personality Language: Projection Perception PersonalityComputer-Mediated Communication. Ph.D. thesis, University Edinburgh.Gill, A. J., & Oberlander, J. (2002). Taking care linguistic features extraversion.Proceedings 24th Annual Conference Cognitive Science Society, pp.363368.Goldberg, L. R. (1990). alternative description personality: Big-Five factorstructure. Journal Personality Social Psychology, 59, 12161229.Graciarena, M., Shriberg, E., Stolcke, A., Enos, F., Hirschberg, J., & Kajarekar, S. (2006).Combining prosodic, lexical cepstral systems deceptive speech detection.Proceedings IEEE ICASSP.495fiMairesse, Walker, Mehl & MooreHeinrich, C. U., & Borkenau, P. (1998). Deception deception detection: rolecross-modal inconsistency. Journal Personality, 66 (5), 687712.Herbrich, R., Graepel, T., & Obermayer, K. (2000). Large margin rank boundariesordinal regression. Smola, A. J., Bartlett, P., Scholkopf, B., & Schuurmans, D.(Eds.), Advances Large Margin Classifiers, pp. 115132. MIT Press, Cambridge,MA.Heylighen, F., & Dewaele, J.-M. (2002). Variation contextuality language:empirical measure. Context Context, Special issue Foundations Science, 7 (3),293340.Hirschberg, J., Benus, S., Brenier, J. M., Enos, F., Friedman, S., Gilman, S., Girand,C., Graciarena, M., Kathol, A., Michaelis, L., Pellom, B., Shriberg, E., & Stolcke,A. (2005). Distinguishing deceptive non-deceptive speech. ProceedingsInterspeech2005 - Eurospeech.Hogan, R. (1982). socioanalytic theory personality. Nebraska Symposium Motivation,30, 5589.Hogan, R., Curphy, G. J., & Hogan, J. (1994). know leadership: Effectiveness personality. American Psychologist, 49 (6), 493504.John, O. P., Donahue, E. M., & Kentle, R. L. (1991). Big Five Inventory: Versions4a 5b. Tech. rep., Berkeley: University California, Institute PersonalitySocial Research.John, O. P., & Srivastava, S. (1999). Big Five trait taxonomy: History, measurement,theoretical perspectives. Pervin, L. A., & John, O. P. (Eds.), Handbookpersonality theory research. New York: Guilford Press.Komarraju, M., & Karau, S. J. (2005). relationship Big Five personalitytraits academic motivation. Personality Individual Differences, 39, 557567.Lester, J. C., Towns, S. G., & FitzGerald, P. J. (1999). Achieving affective impact: Visualemotive communication lifelike pedagogical agents. International JournalArtificial Intelligence Education, 10 (3-4), 278291.Liscombe, J., Venditti, J., & Hirschberg, J. (2003). Classifying subject ratings emotionalspeech using acoustic features. Proceedings Interspeech2003 - Eurospeech.Mairesse, F., & Walker, M. (2006a). Automatic recognition personality conversation.Proceedings HLT-NAACL.Mairesse, F., & Walker, M. (2006b). Words mark nerds: Computational models personality recognition language. Proceedings 28th Annual ConferenceCognitive Science Society, pp. 543548.Mairesse, F., & Walker, M. (2007). PERSONAGE: Personality generation dialogue.Proceedings 45th Annual Meeting Association Computational Linguistics (ACL), pp. 496503.496fiRecognising Personality Conversation TextMallory, P., & Miller, V. (1958). possible basis association voice characteristicspersonality traits. Speech Monograph, 25, 255260.Marcus, D. K., Lilienfeld, S. O., Edens, J. F., & Poythress, N. G. (2006). antisocialpersonality disorder continuous categorical? taxometric analysis. PsychologicalMedicine, 36 (11), 15711582.McLarney-Vesotski, A. R., Bernieri, F., & Rempala, D. (2006). Personality perception:developmental study. Journal Research Personality, 40 (5), 652674.Mehl, M. R., Gosling, S. D., & Pennebaker, J. W. (2006). Personality natural habitat: Manifestations implicit folk theories personality daily life. JournalPersonality Social Psychology, 90, 862877.Mehl, M., Pennebaker, J., Crow, M., Dabbs, J., & Price, J. (2001). ElectronicallyActivated Recorder (EAR): device sampling naturalistic daily activitiesconversations. Behavior Research Methods, Instruments, Computers, 33, 517523.Mishne, G. (2005). Experiments mood classification blog posts. ProceedingsACM SIGIR 2005 Workshop Stylistic Analysis Text Information Access.Nass, C., & Lee, K. (2001). computer-synthesized speech manifest personality? experimental tests recognition, similarity-attraction, consistency-attraction. JournalExperimental Psychology: Applied, 7 (3), 171181.Newman, M. L., Pennebaker, J. W., Berry, D. S., & Richards, J. M. (2003). Lying words:Predicting deception linguistic style. Personality Social Psychology Bulletin,29, 665675.Norman, W. T. (1963). Toward adequate taxonomy personality attributes: Replicatedfactor structure peer nomination personality rating. Journal Abnormal SocialPsychology, 66, 574583.Nowson, S., & Oberlander, J. (2007). Identifying bloggers: Towards large scale personality classification personal weblogs. Proceedings International ConferenceWeblogs Social Media.Nunn, S. (2005). Preventing next terrorist attack: theory practice homeland security information systems. Journal Homeland Security EmergencyManagement, 2 (3).Oberlander, J., & Gill, A. J. (2006). Language character: stratified corpus comparison individual differences e-mail communication. Discourse Processes, 42,239270.Oberlander, J., & Nowson, S. (2006). Whose thumb anyway? classifying author personality weblog text. Proceedings 44th Annual Meeting AssociationComputational Linguistics (ACL).497fiMairesse, Walker, Mehl & MooreOudeyer, P.-Y. (2002). Novel useful features algorithms recognition emotionsspeech. Proceedings 1st International Conference Speech Prosody, pp.547550.Pang, B., & Lee, L. (2005). Seeing stars: Exploiting class relationships sentimentcategorization respect rating scales. Proceedings 43rd Annual MeetingAssociation Computational Linguistics (ACL), pp. 115124.Paunonen, S. V., & Jackson, D. N. (2000). beyond Big Five? plenty!. JournalPersonality, 68 (5), 821836.Peabody, D., & Goldberg, L. R. (1989). determinants factor structurespersonality-trait descriptor. Journal Personality Social Psychology, 57 (3),552567.Pennebaker, J. W., Francis, M. E., & Booth, R. J. (2001). Inquiry Word Count: LIWC2001. Lawrence Erlbaum, Mahwah, NJ.Pennebaker, J. W., & King, L. A. (1999). Linguistic styles: Language use individualdifference. Journal Personality Social Psychology, 77, 12961312.Pennebaker, J. W., Mehl, M., & Niederhoffer, K. (2003). Psychological aspects naturallanguage use: words, selves. Annual Review Psychology, 54, 547577.Popescu, A., & Etzioni, O. (2005). Extracting product features opinions reviews.Proceedings HTL-EMNLP.Reeves, B., & Nass, C. (1996). Media Equation. University Chicago Press.Reiter, E., & Sripada, S. G. (2004). Contextual influences near-synonym choice.Proceedings International Natural Language Generation Conference, pp. 161170.Rienks, R., & Heylen, D. (2006). Dominance detection meetings using easily obtainablefeatures. Bourlard, H., & Renals, S. (Eds.), Revised Selected Papers 2nd JointWorkshop Multimodal Interaction Related Machine Learning Algorithms, Vol.3869 Lecture Notes Computer Science. Springer Verlag.Riggio, R. E., Salinas, C., & Tucker, J. (1988). Personality deception ability. PersonalityIndividual Differences, 9 (1), 189191.Rosenberg, A., & Hirschberg, J. (2005). Acoustic/prosodic lexical correlates charismatic speech. Proceedings Interspeech2005 - Eurospeech.Rushton, J. P., Murray, H. G., & Erdle, S. (1987). Combining trait consistency learning specificity approaches personality, illustrative data faculty teachingperformance. Personality Individual Differences, 8, 5966.Schapire, R. (1999). brief introduction boosting. Proceedings Sixteenth International Joint Conference Artificial Intelligence, 2, 14011406.498fiRecognising Personality Conversation TextScherer, K. R. (1979). Personality markers speech. Scherer, K. R., & Giles, H. (Eds.),Social markers speech, pp. 147209. Cambridge University Press.Scherer, K. R. (2003). Vocal communication emotion: review research paradigms.Speech Communication, 40 (1-2), 227256.Siegman, A., & Pope, B. (1965). Personality variables associated productivityverbal fluency initial interview. Proceedings 73rd Annual ConferenceAmerican Psychological Association.Sigurdsson, J. F. (1991). Computer experience, attitudes toward computers personalitycharacteristics psychology undergraduates. Personality Individual Differences,12 (6), 617624.Smith, B. L., Brown, B. L., Strong, W. J., & Rencher, A. C. (1975). Effects speech ratepersonality perception. Language Speech, 18, 145152.Somasundaran, S., Ruppenhofer, J., & Wiebe, J. (2007). Detecting arguing sentimentmeetings. Proceedings 8th SIGdial Workshop Discourse Dialogue.Stolcke, A., Ries, K., Coccaro, N., Shriberg, E., Bates, R., Jurafsky, D., Taylor, P., Martin,R., Ess-Dykema, C. V., & Meteer, M. (2000). Dialogue act modeling automatictagging recognition conversational speech. Computational Linguistics, 26 (3),339371.Stoyanov, V., Cardie, C., & Wiebe, J. (2005). Multi-perspective question answering usingOpQA corpus. Proceedings HLT-EMNLP.Thompson, C. A., Goker, M. H., & Langley, P. (2004). personalized system conversational recommendations. Journal Artificial Intelligence Research, 21, 393428.Tucker, S., & Whittaker, S. (2004). Accessing multimodal meeting data: Systems, problems possibilities. Lecture Notes Computer Science, Machine LearningMultimodal Interaction, 3361, 111.Turney, P. D. (2002). Thumbs thumbs down? Semantic orientation applied unspervised classification reviews. Proceedings 40th Annual MeetingAssociation Computational Linguistics (ACL), pp. 417424.Vogel, K., & Vogel, S. (1986). Linterlangue et la personalite de lapprenant. InternationalJournal Applied Linguistics, 24 (1), 4868.Walker, M., Cahn, J. E., & Whittaker, S. J. (1997). Improvising linguistic style: Socialaffective bases agent personality. Proceedings 1st ConferenceAutonomous Agents, pp. 96105.Walker, M., & Whittaker, S. (1990). Mixed initiative dialogue: investigationdiscourse segmentation. Proceedings 28th Annual Meeting AssociationComputational Linguistics (ACL), pp. 7078.499fiMairesse, Walker, Mehl & MooreWang, N., Johnson, W. L., Mayer, R. E., Rizzo, P., Shaw, E., & Collins, H. (2005).politeness effect: Pedagogical agents learning gains. Frontiers Artificial Intelligence Applications, 125, 686693.Watson, D., & Clark, L. A. (1992). traits temperament: General specificfactors emotional experience relation five factor model. JournalPersonality, 60 (2), 44176.Webb, N., Hepple, M., & Wilks, Y. (2005). Error analysis dialogue act classification.Proceedings 8th International Conference Text, Speech Dialogue.Wiebe, J., & Riloff, E. (2005). Creating subjective objective sentence classifiersunannotated texts. Proceedings 6th International Conference IntelligentText Processing Computational Linguistics.Wiebe, J., Wilson, T., Bruce, R., Bell, M., & Martin, M. (2004). Learning subjectivelanguage. Computational Linguistic, 30 (3), 277308.Wilson, T., Wiebe, J., & Hwa, R. (2004). mad you? finding strongweak opinion clauses. Proceedings 19th National Conference ArtificialIntelligence (AAAI), pp. 761769.Witten, I. H., & Frank, E. (2005). Data Mining: Practical machine learning toolstechniques. Morgan Kaufmann, San Francisco, CA.Zukerman, I., & Litman, D. (2001). Natural language processing user modeling: Synergies limitations. User Modeling User-Adapted Interaction, 11 (1-2), 129158.500fiJournal Articial Intelligence Research 30 (2007) 273-320Submitted 02/07; published 10/07Reasoning Expressive Fuzzy Description LogicsGiorgos StoilosGiorgos Stamougstoil@image.ece.ntua.grgstam@softlab.ece.ntua.grDepartment Electrical Computer Engineering,National Technical University Athens,Zographou 15780, Athens, GRJe Z. Panjpan@csd.abdn.ac.ukDepartment Computing Science,University Aberdeen, UKVassilis Tzouvarastzouvaras@image.ece.ntua.grDepartment Electrical Computer Engineering,National Technical University Athens,Zographou 15780, Athens, GRIan Horrockshorrocks@cs.man.ac.ukSchool Computer Science, University ManchesterManchester, M13 9PL, UKAbstractwidely recognized today management imprecision vaguenessyield intelligent realistic knowledge-based applications. Description Logics (DLs)family knowledge representation languages gained considerable attentionlast decade, mainly due decidability existence empirically highperformance reasoning algorithms. paper, extend well known fuzzy ALCDL fuzzy SHIN DL, extends fuzzy ALC DL transitive role axioms(S), inverse roles (I), role hierarchies (H) number restrictions (N ). illustratetransitive role axioms dicult handle presence fuzzy interpretationshandle properly. extend results adding role hierarchiesnally number restrictions. main contributions paper decidability prooffuzzy DL languages fuzzy-SI fuzzy-SHIN , well decision proceduresknowledge base satisability problem fuzzy-SI fuzzy-SHIN .1. IntroductionNowadays, many applications domains use form knowledge representation language order improve capabilities. Encoding human knowledge providingmeans reason benet applications lot, enabling provide intelligent answers complex user dened tasks. Examples modern applicationsrecently adopted knowledge representation languages World Wide Web (BernersLee, Hendler, & Lassila, 2001; Baader, Horrocks, & Sattler, 2002b), knowledgeused improve abilities agents interoperability disparate systems,multimedia processing applications (Alejandro, Belle, & Smith, 2003; Benitez, Smith, &Chang, 2000), use knowledge order bridge gap human percepc2007AI Access Foundation. rights reserved.fiStoilos, Stamou, Pan, Tzouvaras & Horrockstion objects exist within multimedia documents, computer perceptionpixel values, conguration applications (McGuiness, 2003), etc. Unfortunately,occasions traditional knowledge representation languages fail accurately representconcepts appear domain interest. example, particularly casedomain knowledge inherently imprecise vague. Concepts like neardestination (Berners-Lee et al., 2001), highQuality audio system (McGuiness, 2003),many children, faulty reactor (Horrocks & Sattler, 1999), soon many more,require special modelling features. past many applications various research areas, like decision making, image processing, robotics medical diagnosis adoptedspecial mathematical frameworks intended modelling types concepts(Zimmermann, 1987; Larsen & Yager, 1993; Krishnapuram & Keller, 1992). Onemathematical framework fuzzy set theory (Zadeh, 1965). Though fuzzy extensions various logical formalisms, like propositional, predicate modal logics investigatedpast (Hajek, 1998), framework yet well developed DescriptionLogics much research work needs done. precisely, needreasoning expressive fuzzy Description Logics.order achieve knowledge reusability high interoperability, modern applicationsoften use concept ontology (Berners-Lee et al., 2001) represent knowledgeexists within domain. Ontologies created encoding full knowledgepossess specic entity world using knowledge representation language. logical formalism gained considerable attention last decade Description Logics(Baader, McGuinness, Nardi, & Patel-Schneider, 2002a). Description Logics (DLs)family class-based (concept-based) knowledge representation formalisms, equippedwell dened model-theoretic semantics (Tarski, 1956). characterized usevarious constructors build complex concept descriptions simpler ones, emphasisdecidability key reasoning problems, provision sound, completeempirically tractable reasoning services. well-dened semantics powerfulreasoning tools exist Description Logics makes ideal encoding knowledgemany applications like Semantic Web (Baader et al., 2002b; Pan, 2004), multimedia applications (Meghini, Sebastiani, & Straccia, 2001), medical applications (Rector &Horrocks, 1997), databases (Calvanese, De Giacomo, Lenzerini, Nardi, & Rosati, 1998)many more. Interestingly, current standard Semantic Web ontology languages, OWL(Bechhofer, van Harmelen, Hendler, Horrocks, McGuinness, Patel-Schneider, & eds., 2004),based Description Logics represent knowledge support wide range reasoning services. precisely, without regarding annotation properties OWL, OWLLite species OWL equivalent SHIF(D+ ) DL, OWL DL equivalentSHOIN (D+ ) (Horrocks, Patel-Schneider, & van Harmelen, 2003). Although DLs provideconsiderable expressive power, feature limitations regarding ability representvague (fuzzy) knowledge. obvious, order make applications use DLs ablecope information extend theory capable representingkind information. One important theory fuzzy set theory. Fuzzy DescriptionLogics interesting logical formalisms used numerous domains likemultimedia information retrieval (Fagin, 1998; Meghini et al., 2001) provide rankingdegrees, geospatial (Chen, Fellah, & Bishr, 2005) cope vague concepts like near,far many more.274fiReasoning Expressive Fuzzy Description Logicsorder make need handle vagueness knowledge evident application fuzzy set theory intuitive, let us consider example. Supposecreating knowledge-based image processing application. application task(semi)automatically detect recognize image objects. Suppose also contentimages represents humans animals. domain one use standard features Description Logics encode knowledge. example, knowledge base describinghuman bodies could contain following entitiesArm isPartOf.BodyBody isPartOf.Humansubsumption relation isPartOf obviously transitive relation.knowledge captured aid DL (Sattler, 1996). Moreover, one mightwant capture knowledge role hasPart inverse role isPartOf,writing hasPart := isPartOf , thus able state something bodytail also animal as,Body hasPart.Tail Animal.new feature one would require SI DL (Horrocks & Sattler, 1999).new axiom gives us ability recognize concept Arm Tail subsumedisPartOf.Animal. Finally, SI DL extended role hierarchiesnumber restrictions. Hence, one able capture fact role hasDirectPartsub-role role hasPart, writing isDirectPartOf isPartOf, also provideaccurate denition concept Body giving axiom,Body isDirectPartOf.Human 2hasArm 2hasArmstating body direct part human also exactly two arms.used standard Description Logic features. supposerun image analysis algorithm. algorithms usually segment image regionstry annotate appropriate semantic labels using low level image features.process involves number vague concepts since image region might red,blue, circular, small smooth textured degree two image regions mighttotally degree adjacent (since pixels adjacent),one contained within other, etc. Hence decide membershipregion specic concept certain degree (Athanasiadis, Mylonas, Avrithis,& Kollias, 2007). example, case could object o1 isPartOfobject o2 degree 0.8, o2 isPartOf o3 degree 0.9, o1 Armdegree 0.75 o2 Body degree 0.85. fuzzy knowledge onecould deduce o3 belongs concept hasPart.Body hasPart.Arm degree0.75. together denition form Human hasPart.Body hasPart.Arm,represents equivalence, means good chance o3 Human.Observe, denition, order someone human, forceBody explicitly part Arm. reasonable choice presentapplication, depending level segmentation, might several275fiStoilos, Stamou, Pan, Tzouvaras & Horrockssegmented regions o2 o3 . obvious applications handlinginherent vagueness certainly benets specic application.paper extend well known fuzzy ALC (f-ALC) DL (Straccia, 2001)fuzzy SHIN DL (f-SHIN ), extends f-ALC DL inverse role constructor,transitive role axioms, role hierarchies number restrictions constructor. Moreover,prove decidability f-SHIN DL providing tableaux algorithm decidingstandard DL inference problems. order provide algorithm proceedtwo steps. First, focus f-SI language studying properties fuzzy transitiveroles value existential restrictions, well applicability techniques usedclassical SI language ensure termination algorithm (Horrocks & Sattler,1999). see great diculty handling axioms context fuzzyDLs, nishing investigation see similar notions classical SIlanguage applied. Secondly, extend results adding role hierarchiesnumber restrictions. provide necessary extensions reasoning algorithmf-SI, thus providing reasoning algorithm f-SHIN language. Discarding datatypes,SHIN slightly expressive SHIF (OWL Lite) slightly less expressiveSHOIN (OWL DL). order achieve goal extend techniques usedclassical SHIN language ensure correctness algorithm (Horrocks &Sattler, 1999; Horrocks, Sattler, & Tobies, 2000). Finally, prove decidabilityextended algorithm. many benets following approach. onehand provide gradual presentation complex algorithm f-SHIN ,hand provide reasoning algorithm less expressive, ecient fuzzyDL language, f-SI. classical SI language known Pspace-complete, contrastExptime-completeness SHIN (Tobies, 2001), hence algorithm f-SIused future research providing ecient optimized implementations.Please note fuzzy DLs (Straccia, 2001) complementary approachesextend DLs, like probabilistic DLs (Koller, Levy, & Pfeer, 1997; Giugno & Lukasiewicz,2002; Ding & Peng, 2004), possibilistic DLs (Hollunder, 1994). precisely,theories meant used capturing dierent types imperfect informationknowledge. Fuzziness purposed capturing vague (fuzzy) knowledge, i.e. factscertain degrees truth assigned them, like example degreetruth someone tall. hand, possibilistic probabilistic logicspurposed capturing cases knowledge uncertain due lack informationknowledge specic situation future event, like example sensor readingweather forecast. facts assigned degrees possibility, belief probability,rather truth degrees. Dubois Prade (2001) provide comprehensive analysistheories along dierent properties.rest paper organized follows. Section 2 briey introduces DL SHINprovides preliminaries notion fuzzy set set theoreticlogical operations extended fuzzy set framework. Section 3 introducessyntax semantics fuzzy SHIN DL, call f-SHIN .1 language. Section4 provides investigation semantics fuzzy DLs fuzzy transitive relations1. previous approach fuzzy DLs notation fALC used (Straccia, 2004), notationexible represent fuzzy DLs use dierent norm operations, see later on.approaches (Tresp & Molitor, 1998; Holldobler, Khang, & Storr, 2002) naming ALC F276fiReasoning Expressive Fuzzy Description Logicsparticipate value existential restrictions. section 5 give detailed presentationreasoning algorithm deciding consistency fuzzy-SI ABox provideproofs termination, soundness completeness procedure. Then,section 6 extend previous results adding role hierarchies number restrictions.precisely, results section 4 enriched considering transitive roles roleshierarchies value existential restrictions. Using results extend algorithmsection 5 handle new feature nally prove soundness, completenesstermination. last, section 7 review previous work fuzzy DescriptionLogics section 8 concludes paper.2. Preliminariescurrent section briey introduce classical DLs fuzzy set theory, recallingmathematical properties fuzzy set theoretic operators.2.1 Description Logics SHIN DLDescription Logics (DLs) (Baader et al., 2002a) family logic-based knowledge representation formalisms designed represent reason knowledge applicationdomain structured well-understood way. based common familylanguages, called description languages, provide set constructors build concept (class) role (property) descriptions. descriptions used axiomsassertions DL knowledge bases reasoned respect (w.r.t.) DLknowledge bases DL systems.section, briey introduce SHIN DL, extendedf-SHIN DL later. description language consists alphabet distinct concept names(C), role names (R) individual (object) names (I); together set constructorsconstruct concept role descriptions.dene notions SHIN -roles SHIN -concepts.Denition 2.1 Let RN R role name R SHIN -role. SHIN -role descriptions(or simply SHIN -roles) dened abstract syntax: ::= RN | R . inverserelation roles symmetric, avoid considering roles R , denefunction Inv returns inverse role, precisely,RN R = RN ,Inv(R) :=RNR = RN .set SHIN -concept descriptions (or simply SHIN -concepts) smallest setthat:1. every concept name CN C SHIN -concept,2. C SHIN -concepts R SHIN -role, C, C D, C D, R.CR.C also SHIN -concepts, called general negation (or simply negation),used easily confused ALCF (ALC extended functional restrictions, Horrocks& Sattler, 1999), pronounced.277fiStoilos, Stamou, Pan, Tzouvaras & HorrocksConstructortopbottomconcept namegeneral negationconjunctiondisjunctionexists restrictionvalue restrictionat-most restrictionat-least restrictionSyntaxCNCCDCDR.CR.CnRnRSemanticsCNI\ CC DIC DI{x | y.x, RI C }{x | y.x, RI C }{x | {y | RI (x, y)} n}{x | {y | RI (x, y)} n}Table 1: Semantics SHIN -conceptsdisjunction, conjunction, value restrictions existential restriction, respectively,3. simple2 SHIN -role n N, ( nS) ( nS) also SHIN concepts, called at-most at-least number restrictions.removing point 3 denition obtain set SI-concepts.Description Logics model-theoretic semantics, dened terms interpretations. interpretation (written I) consists domain (written )interpretation function (written ), domain nonempty set objectsinterpretation function maps individual name element aI ,concept name CN C subset CNI , role name RN R binaryrelation RN . interpretation function extended give semanticsconcept role descriptions. given Table 1.SHIN knowledge base (KB) consists TBox, RBox ABox. SHINTBox nite set concept inclusion axioms form C D, concept equivalenceaxioms form C D, C, SHIN -concepts. interpretation satisesC C DI satises C C = DI . Note concept inclusionaxioms form called general concept inclusions (Horrocks & Sattler, 1999;Baader, 1990). SHIN RBox nite set transitive role axioms (Trans(R)), roleinclusion axioms (R S). interpretation satises Trans(R) if, x, y, z ,{x, y, y, z} RI x, z RI , satises R RI . set role*inclusion axioms denes role hierarchy. role hierarchy introducetransitive-reexive closure . last, observe R S, semantics roleinclusion axioms imply Inv(R)I Inv(S)I , semantics inverse roles implyTrans(Inv(R)). SI RBox obtained SHIN RBox disallow role inclusionaxioms. SHIN ABox nite set individual axioms (or assertions) form.: C, called concept assertions, a, b : R, called role assertions, form = b.2. role called simple neither transitive transitive sub-roles. crucial orderget decidable logic (Horrocks, Sattler, & Tobies, 1999).278fiReasoning Expressive Fuzzy Description Logicsinterpretation satises : C aI C , satises a, b : R aI , bI RI ,.satises = b aI = bI . SI ABox obtained SHIN ABox disallowing.inequality axioms = b. interpretation satises SHIN knowledge basesatises axioms . satisable (unsatisable) exists (does exist)interpretation satises . Let C, SHIN -concepts, C satisable(unsatisable) w.r.t. exists (does exist) interpretation s.t. C = ;C subsumes w.r.t. every interpretation C DI . Givenconcept axiom, role axiom, assertion , entails , written |= ,models satises .2.2 Fuzzy SetsFuzzy set theory fuzzy logic widely used today capturing inherent vagueness(the lack distinct boundaries sets) exists real life applications (Klir & Yuan,1995). notion fuzzy set rst introduced Zadeh (1965). classicalset theory element either belongs set not, fuzzy set theory elements belongcertain degree. formally, let X collection elements (called universediscourse) i.e X = {x1 , x2 , . . .}. crisp subset X collection elementsX dened aid characteristic function (x) assignsx X value 1 0 element belongs X not, respectively.hand, fuzzy subset X, dened membership function (x), simply A(x),x X. membership function assigns x X value 01 represents degree element belongs A. Additionally, fuzzybinary relation R two crisp sets X function R : X [0, 1].example, one say om belongs set people degree 0.8, writingall(T om) = 0.8, object o1 part object o2 degree 0.6, writingisP artOf (o1 , o2 ) = 0.6. Several properties fuzzy binary relations investigatedliterature (Klir & Yuan, 1995). example, binary fuzzy relation called sup-mintransitive R(x, z) supyY {min(R(x, y), R(y, z))}, inverse relation Rdened R1 (y, x) = R(x, y) (Klir & Yuan, 1995).Using idea, important operations dened crisp sets relations,like boolean operations (complement, union, intersection etc.), extended ordercover fuzzy sets fuzzy relations. Accordingly, sound complete mathematicalframework plays important role management imprecise vague information dened used wide set scientic areas including expert systemsdecision making (Zimmermann, 1987), pattern recognition (Kandel, 1982), image analysiscomputer vision (Krishnapuram & Keller, 1992), medicine (Oguntade & Beaumont,1982), control (Sugeno, 1985), etc.2.3 Fuzzy Set Theoretic Operationssection, explain extend boolean operations logical implicationscontext fuzzy sets fuzzy logics. operations performedmathematical functions unit interval.operation complement performed unary operation, c : [0, 1] [0, 1], calledfuzzy complement. order provide meaningful fuzzy complements, functions279fiStoilos, Stamou, Pan, Tzouvaras & Horrockssatisfy certain properties. precisely, satisfy boundary conditions,c(0) = 1 c(1) = 0, monotonic decreasing, b, c(a) c(b).current paper use Lukasiewicz negation, c(a) = 1 a, additionallycontinuous involutive, [0, 1], c(c(a)) = holds. cases fuzzyintersection fuzzy union mathematical functions used binary unitinterval. functions usually called norm operations referred t-norms (t),case fuzzy intersection, t-conorms (or s-norms) (u), case fuzzy union(Klement, Mesiar, & Pap, 2004). operations satisfy certain mathematicalproperties. precisely, t-norm (t-conorm) satises boundary condition, t(a, 1) =(u(a, 0) = a), monotonic increasing, b t(a, b) t(a, d) (u(a, b) u(a, d)),commutative, t(a, b) = t(b, a) (u(a, b) = u(b, a)), associative, t(a, t(b, c)) = t(t(a, b), c)(u(a, u(b, c)) = u(u(a, b), c)). Though wealth operations literature(Klir & Yuan, 1995) restrict attention specic ones. precisely,using Godel t-norm, t(a, b) = min(a, b) Godel t-conorm, u(a, b) = max(a, b).Additionally aforementioned properties, operations also idempotent, i.e.min(a, a) = max(a, a) = a, hold. Finally, fuzzy implication performedbinary operation, form J : [0, 1] [0, 1] [0, 1]. current paper useKleene-Dienes fuzzy implication provided equation, J (a, b) = max(c(a), b).reason restricting attention operations would made clear section5.1. recall property max norm operation going useinvestigation properties transitive relations framework fuzzy settheory.Lemma 2.2 (Hajek, 1998) a, b [0, 1], j takes values index set J,max operation satises following property:inf jJ max(a, bj ) = max(a, inf jJ bj ).3. fKD -SHIN DLsection, introduce fuzzy extension SHIN DL presented Section 2.1.Following Stoilos, Stamou, Tzouvaras, Pan, Horrocks (2005b), since usingKleene-Dienes (KD) fuzzy implication language, call fKD -SHIN . presentation follows standard syntax semantics fuzzy DLs, introducedliterature (Straccia, 2001; Holldobler et al., 2002; Sanchez & Tettamanzi, 2004).precisely, fKD -SHIN rst presented Straccia (2005b). completeness reasonsalso present language fKD -SHIN here. Please also note presentationdiers Straccia (2005b) semantics concept role inclusion axioms.usual, consider alphabet distinct concept names (C), role names (R)individual names (I). abstract syntax fKD -SHIN -concepts fKD -SHIN -roles(and respectively fKD -SI-concepts fKD -SI-roles) SHIN counterparts; however, semantics based fuzzy interpretations (see below). Similarly,fKD -SHIN keeps syntax concept role axioms counterpartsSHIN . Interestingly, fKD -SHIN extends SHIN individual axioms (assertions) fuzzyindividual axioms, fuzzy assertions (following, Straccia, 2001), membership degreesasserted.280fiReasoning Expressive Fuzzy Description LogicsFirstly, using membership functions range interval [0, 1], classical interpretations extended concept fuzzy interpretations (Straccia, 2001).abuse symbols dene fuzzy interpretation pair = (I , ),3domain non-empty set objects fuzzy interpretation function,maps1. individual name element aI ,2. concept name C membership function AI : [0, 1],3. role name R R membership function RI : [0, 1].example, AI (o) gives degree object belongs fuzzyconcept A, e.g. AI (o) = 0.8. using fuzzy set theoretic operations dened section2.3, fuzzy interpretation function extended give semantics fKD -SHIN concepts fKD -SHIN -roles. example, since use max function fuzzyunion membership degree object fuzzy concept (C D)I equalmax(C (a), DI (a)). Moreover since, according Table 1, value restriction R.Cimplication form, y(R(x, y) C(y)), interpret inf (Hajek, 1998),Kleene-Dienes fuzzy implication nally equation, inf bI {max(1RI (a, b), C (b))}. complete set semantics depicted Table 2. notemany proposals semantics number restrictions fuzzy DLs (Sanchez &Tettamanzi, 2004; Straccia, 2005b). choose follow semantics proposed Straccia(2005b) since based First-Order interpretation number restrictions (Baaderet al., 2002a). Moreover, shown Stoilos, Stamou, Tzouvaras, Pan, Horrocks(2005a) see section 6, semantics inference servicesfKD -SHIN stay decidable reasoning reduced simple counting problem,yielding ecient algorithm. Note that, although semanticspresented elsewhere (Sanchez & Tettamanzi, 2004; Straccia, 2005b), includesimply sake completeness.fKD -SHIN knowledge base consists TBox, RBox ABox. Letconcept name C fKD -SHIN concept. fKD -SHIN TBox nite set fuzzyconcept axioms form C, called fuzzy inclusion introductions, formC, called fuzzy equivalence introductions. fuzzy interpretation satises C, AI (o) C (o). fuzzy interpretation satises C , AI (o) = C (o).fuzzy interpretation satises fKD -SHIN TBox satises fuzzy conceptaxioms ; case, say model .two remarks here. Firstly, give crisp subsumption fuzzy concepts here,usual way subsumption dened context fuzzy sets (Klir & Yuan,1995). contrast, Straccia (2005b) denes fuzzy subsumption fuzzy concepts.noted Bobillo, Delgado, Gomez-Romero (2006) fKD -DLs fuzzy subsumptionsometimes counterintuitive. Secondly, see, allowing simple TBoxes.TBox called simple neither includes cyclic general concept inclusions, i.e.axioms form C C, concept name never dened3. rest paper, use = (I , ) represent fuzzy interpretations instead crisp interpretations.281fiStoilos, Stamou, Pan, Tzouvaras & HorrocksConstructortopbottomgeneral negationconjunctiondisjunctionexists restrictionvalue restrictionat-mostat-leastinverse roleSyntaxCCDCDR.CR.CpRpRRSemantics(a) = 1(a) = 0(C)I (a) = 1 C (a)(C D)I (a) = min(C (a), DI (a))(C D)I (a) = max(C (a), DI (a))(R.C)I (a) = supbI {min(RI (a, b), C (b))}(R.C)I (a) = inf bI {max(1 RI (a, b), C (b))}inf b1 ,...,bp+1 maxp+1i=1 {1 R (a, bi )}psupb1 ,...,bp mini=1 {RI (a, bi )}(R )I (b, a) = RI (a, b)Table 2: Semantics fKD -SHIN -concepts fKD -SHIN -roleseither directly indirectly. procedure deal cyclic general TBoxes,context fuzzy DLs, recently developed Stoilos, Straccia, Stamou, Pan(2006), also parallel slightly dierent technique presented Li, Xu, Lu,Kang (2006a). process involves additional expansion rules preprocessing stepcalled normalization, aected expressivity underlying fuzzy DL.Hence, order keep presentation simple consider general TBoxesfollowing, focus decidability reasoning fKD -SI fKD -SHIN ,involve many technical details. end section 6 commentissue handling GCIs fKD -SHIN language.fKD -SHIN RBox nite set fuzzy transitive role axioms form Trans(R)fuzzy role inclusion axioms form R S, R, fKD -SHIN -roles. fuzzyinterpretation satises Trans(R) a, c , RI (a, c) supbI {min(RI (a, b), RI (b, c))},satises R a, b , RI (a, b) (a, b). Note semantics resultdenition sup-min transitive relations fuzzy set theory. fuzzy interpretationsatises fKD -SHIN RBox R satises fuzzy transitive role axioms R;case, say model R. Similarly classical SHIN language,semantics inverse roles role inclusion axioms fKD -SHIN imply Trans(R)R holds Trans(Inv(R)) Inv(R) Inv(S) .fKD -SHIN ABox nite set fuzzy assertions (Straccia, 2001) form(a : C)n (a, b : R)n, stands , >, <, n [0, 1].form =b. Intuitively, fuzzy assertion form (a : C) n means membershipdegree individual concept C least equal n. call assertions dened, > positive assertions, dened , < negative assertions. Formally, givenfuzzy interpretation I,satises (a : C) nsatises (a : C) nsatises (a, b : R) nsatises (a, b : R) n.satises = b282C (aI ) n,C (aI ) n,RI (aI , bI ) n,RI (aI , bI ) n,aI = bI .fiReasoning Expressive Fuzzy Description Logicssatisability fuzzy assertions >, < dened analogously. Observe that,also simulate assertions form (a : C) = n considering two assertions form(a : C) n (a : C) n (Holldobler et al., 2002; Straccia, 2001). fuzzy interpretationsatises fKD -SHIN ABox satises fuzzy assertions A; case,say model A.Furthermore, noted Straccia (2001, 2005b), due mathematical properties norm operations dened section 2.3, following fKD -SHIN -concept equivalences satised:,, CC, C C, CC .Furthermore, since Lukasiewicz complement involutive holds that, C C.Moreover, De Morgan laws: C1 C2 (C1 C2 ), C1 C2 (C1 C2 ),satised. consequence satisability De Morgan laws useKleene-Dienes fuzzy implication following concept equivalences also hold.R.CR.(C),p1 R(p1 + 1)R,R.Cp1 RR.(C),(p1 1)R, p1 N,p1 = 0last note classical laws contradiction (C C ) excluded middle(C C), hold.Example 3.1 Let us revisit fuzzy knowledge base () informally introducedsection 1. Formally, knowledge base dened follows: = , R, A,={Arm isPartOf.Body,Body isPartOf.Human},={(o1 , o2 : isPartOf) 0.8,(o2 , o3 : isPartOf) 0.9,(o2 : Body) 0.85, (o1 : Arm) 0.75},R={Trans(isPartOf)}.Now, order fuzzy interpretation model holdArmI (oIi ) (isPartOf.Body)I (oIi ) BodyI (oIi ) (isPartOf.Body)I (oIi ), oIi .Furthermore, isPartOf (oI1 , oI2 ) 0.8, isPartOf (oI2 , oI3 ) 0.9, BodyI (oI2 ) 0.85ArmI (oI1 ) 0.75, also model A. model RBox R,also satisfy isPartOf (oI1 , oI3 ) supaI {min(isPartOf (oI1 , a), isPartOf (a, oI3 ))} =sup{. . . , min(0.8, 0.9), . . .} 0.8.let us consider concept hasPart.Body hasPart.Arm mentionedSection 1. Due semantics existential restrictions presented Table 2,(hasPart.Body)I (oI3 )=supaI {min((isPartOf ) (oI3 , a), BodyI (a))} 0.85,(hasPart.Arm)I (oI3 )=supaI {min((isPartOf ) (oI3 , a), ArmI (a))} 0.75.Hence o3 would belong intersection two concepts minimum membershipdegree greater equal 0.75, claimed Section 1.283fiStoilos, Stamou, Pan, Tzouvaras & Horrocksn>n<mnmnmn>mnmTable 3: Conjugated pairs fuzzy assertionsFollowing Straccia (2001), introduce concept conjugated pairs fuzzy assertions represent pairs assertions form contradiction. possible conjugatedpairs dened Table 3, represents SI assertion. example, = : C,assertions (a : C) 0.7 (a : C) < 0.7 conjugate. Furthermore, duepresence inverse roles role inclusion axioms denition slightly extendedStraccia (2001) hence, one also take consideration possibleinverse roles role hierarchy checking conjugation two role assertions. ex* S, assertion (a, b : R) 0.9, conjugates (b, : Inv(S)) 0.4;ample, Rsimilarly rest inequalities.Now, dene reasoning problems fKD -SHIN DL.fuzzy interpretation satises fKD -SHIN knowledge base satisesaxioms ; case, called model . fKD -SHIN knowledge basesatisable (unsatisable) exists (does exist) fuzzy interpretationsatises axioms . fKD -SHIN -concept C satisable (unsatisable) w.r.t.RBox R TBox exists (does exist) model RC (a) = n, n (0, 1]. case, C calledn-satisable w.r.t. R (Navara, 2000). Let C two fKD -SHIN -concepts.say C subsumed w.r.t. R every model R holdsthat, x .C (x) DI (x). Furthermore, fKD -SHIN ABox consistent w.r.t. Rexists model R also model A. Moreover, givenfuzzy concept axiom fuzzy assertion {C D, C D, n}, fKD -SHINknowledge base entails , written |= , models also satisfy .Furthermore, studying Table 3, conclude fKD -SHIN ABoxcontain number positive negative assertions without forming contradiction.Therefore, useful compute lower upper bounds truth-values. GivenfKD -SHIN knowledge base assertion , greatest lower bound w.r.t.glb(, ) = sup{n : |= n}, sup = 0. Similarly, least upper boundw.r.t. lub(, ) = inf{n : |= n}, inf = 1. decision proceduresolve best truth-value bound provided Straccia (2001). proceduremembership degrees appear fKD -SHIN ABox, together complementedvalues degrees 0, 0.5 1, collected set membership degrees Nsubsequently entailment fuzzy assertions n n, n Ntested, thus determining glb lub. Obviously procedure independentexpressivity DL language, thus also applicable context.Remark 3.2 Table 2 see semantics value existential restrictions fuzzy DLs dened aid inmum supremum operation. means construct innite interpretation I, i.e. interpretation284fiReasoning Expressive Fuzzy Description Logics= {b1 , b2 , . . .} contains innite number objects, R.C n-satisable((R.C)I (a) = n ) bi , max(1 RI (a, bi ), C (bi )) > n.possible since although maximum membership degrees involvedindividual object bi strictly greater n limit innite sequence could convergen. fact rst noted fuzzy DLs Hajek (2005), introducing notionwitnessed model fuzzy DLs. model called witnessed (R.C)I (a) = nb either RI (a, bi ) = 1n C (bi ) = n, i.e. bwitnesses membership degree R.C. Fortunately, fuzzy logicsinnite model witnessed model. precisely, Hajek provesproperty Lukasiewicz fuzzy logic4 . concludes proofsmodied apply fuzzy logic dened fuzzy operators using currentpaper. operators denable Lukasiewicz logic (Mostert &Shields, 1957). rest paper, without loss generality, going considerwitnessed models.paper, provide algorithm decide fuzzy ABox consistency problemw.r.t. RBox expressive fuzzy DLs. Many reasoning problems reducedproblem. Firstly, concept satisability fuzzy concept C reducedconsistency checking fuzzy ABox {(a : C) > 0}. Secondly, paper,consider unfoldable TBoxes, KB satisability reduced ABox consistencyw.r.t. RBox. TBox unfoldable contains cycles contains uniqueintroductions, i.e., concept axioms concept names appearing left hand sideand, concept name A, one axiom appearsleft side. knowledge base unfoldable TBox transformed equivalentone empty TBox transformation called unfolding, expansion (Nebel, 1990):Concept inclusion introductions C replaced concept equivalence introductionsC, new concept name, stands qualities distinguishelements elements C. Subsequently, C complex conceptexpression, dened terms concept names, dened TBox, replacedenitions C. proved initial TBox expanded oneequivalent.Moreover, problem entailment reduced problem fuzzy knowledgebase satisability (Straccia, 2001). precisely, = , R, A, |= n= , R, { n} unsatisable. , denote negationinequalities; e.g., <, < . Finally,subsumption problem two fuzzy concepts C w.r.t. TBox also reducedfuzzy knowledge base satisability problem. formally, Straccia (2001), proved, , |= C , , {(a : C) n, (a : D) < n}, n {n1 , n2 }, n1 (0, 0.5]n2 (0.5, 1], unsatisable. reduction extended order fuzzyknowledge base also include RBox. Please note that, crisp DLs, order checkconcept C subsumed concept check unsatisability concept,C D. reduction unsatisability applicable fKD -DLs since fuzzyoperations use satisfy laws contradiction excluded middle.4. Lukasiewicz fuzzy logic uses t-norm t(a, b) = max(0, + b 1), t-conorm u(a, b) = min(1, + b),Lukasiewicz complement fuzzy implication J (a, b) = min(1, 1 + b)285fiStoilos, Stamou, Pan, Tzouvaras & Horrocksconclude section example.Example 3.3 Consider sample knowledge base (). applying transformation unfolding, dened earlier, one would obtain following expanded fuzzy TBox:={Arm Arm isPartOf.Body,Body Body isPartOf.Human}respective fuzzy assertions would transformed={(o2 : Body isPartOf.Human) 0.85,(o1 : Arm isPartOf.Body) 0.75}Now, let us formally specify query introduced section 1. = , R,modied knowledge base, unfolding, query would form |= (o3 :hasPart.Body hasPart.Arm) 0.75. According previous discussion ordercheck entailment query one check consistency fuzzyABox {(o3 : hasPart.Body hasPart.Arm) < 0.75}, w.r.t. RBox R, sinceexpansion remove . task following sections provide proceduredecides consistency fuzzy ABox w.r.t. RBox.4. Transitivity Fuzzy Description Logicsclassical DLs, role R transitive a, b, c , a, b RI b, c RIimply a, c RI . Sattler (1996) shows that, a, b, c1 , . . . , cn , R transitive, bR-successor a, c1 , . . . , cn R-successors b, (R.C)I , Rsuccessors instances (R.C)I , e.g., b (R.C)I because: (i) a, ci RI(as R transitive), (ii) ci C (as (R.C)I ) (iii) b (R.C)I (duesemantics R.C). words, means following concept subsumptionholds, R.C R.(R.C).property suggests value restrictions transitive relations (R.C)propagated along path individuals. propagation crucial reasoning algorithms order retain tree-model property (Baader et al., 2002a), propertyleads decidable decision procedures (Vardi, 1997). goal rest section investigate property context fuzzy Description Logics allowtransitive role axioms. determine similar propagation occurs is,nd membership degree propagation carries subsequent objects.rst time investigation presented literature.fuzzy DLs, objects instances possible fuzzy concepts degree, ranginginterval [0, 1]. shown Section 3, fuzzy role R transitive i,a, c , RI (a, c) supbI min(RI (a, b), RI (b, c)). Since holds supremum,arbitrary b that, RI (a, c) min(RI (a, b), RI (b, c)) applying fuzzycomplement sides get, c(RI (a, c)) c(min(RI (a, b), RI (b, c))). follows,show value restrictions, also existential restrictions transitive286fiReasoning Expressive Fuzzy Description Logicsroles (R.C) propagated, satisfy inmum supremum restrictions.look value restrictions. Let a, b objects R transitiverole. (R.C)I (a) va , (note c represents fuzzy complement)monotonicity(1) inf dI max(c(RI (a, d)), C (d)) va(2) inf dI max(c(min(RI (a, b), RI (b, d))), C (d)) va(3) inf dI max(max(c(RI (a, b)), c(RI (b, d))), C (d)) vaDe organassociativity(4) inf dI max(c(RI (a, b)), max(c(RI (b, d)), C (d))) vaLemmamax(c(RI (a, b)), infmax(c(RI (b, d)), C (d)))(5)dI(6) max(c(RI (a, b)), (R.C)I (b)) va ,va2.2means either c(RI (a, b)) va (R.C)I (b) va . remarks here.Firstly, b arbitrary object . words, object x ,c(RI (a, x)) < va , (R.C)I (x) va . Similarly, (R.C)I (a) > va c(RI (a, x)),(R.C)I (x) > va . Hence, following result obtained.Corollary 4.1 (R.C)I (a) n Trans(R) then, fKD -DL, (R.(R.C))I (a) nholds.Now, let a, b , R transitive role consider case (R.C)I (a) ea .applying fuzzy complement sides inequation, since fuzzy complementsmonotonic decreasing, obtain c((R.C)I (a)) c(ea ). Based semanticslanguage rewritten ((R.C))I (a) c(ea ) using conceptequivalences presented previous section have, (R.(C))I (a) c(ea ). Hence,using results value restrictions conclude object x ,c(RI (a, x)) < c(ea ) RI (a, x) > ea , (R.(C))I (x) c(ea ) (R.C)I (x) easimilarly, (R.(C))I (a) > c(ea ) c(RI (a, x)), i.e. (R.C)I (a) < c(ea ) RI (a, x),(R.(C))I (x) > c(ea ) thus (R.C)I (x) < ea . Hence, able shownext result.Corollary 4.2 (R.C)I (a) n Trans(R) then, fKD -DL, (R.(R.C))I (a) nholds.results used properties 11 12 Denition 5.1.5. Reasoning Transitive Inverse Roles fKD -DLscurrent section show reason transitive inverse rolescontext fuzzy DLs, thus providing reasoning algorithm fKD -SI language.algorithm used order provide ecient implementations applicationsneed expressive power fKD -SHIN .section 3, shown inference services fuzzy DLs, like entailmentsubsumption, reduced problem ABox consistency checking w.r.t.RBox. tableaux algorithms, tableaux algorithm checking ABox consistencytries prove satisability assertion constructing, fKD -SI ABox A,fuzzy tableau A, i.e., abstraction model A. Given notion fuzzytableau, quite straightforward prove algorithm decision procedure ABox287fiStoilos, Stamou, Pan, Tzouvaras & Horrocksconsistency. fuzzy tableau present seen extension tableaupresented Horrocks et al. (2000) handle degrees. rst extensionpresented Stoilos et al. (2005b), revise denition.Without loss generality, assume concepts C occurring negationnormal form (NNF) (Hollunder, Nutt, & Schmidt-Schaus, 1990); i.e., negations occurfront concept names only. fKD -SI-concept transformed equivalent oneNNF pushing negations inwards using combination De Morgan laws (whichsatised operations dened section 2.3). Next, fuzzy concept D,denote sub(D) set contains closed sub-concepts(Horrocks & Sattler, 1999). set sub-concepts concepts appear withinABox denoted sub(A).following, use symbols placeholder inequalities , >, < symbol placeholder types inequalities. Furthermore,use symbols , denote reections; e.g., reection> <.Denition 5.1 fKD -SI ABox, R fKD -SI RBox, RA set rolesoccurring R together inverses IA set individuals A,fuzzy tableau respect R, dened quadruple (S, L, E, V) that:set elements, L : Ssub(A) [0, 1] maps element concept, membersub(A), membership degree element concept, E : RA [0, 1]maps role RA pair elements membership degree pairrole, V : IA maps individuals occurring elements S. s, S,C, sub(A), n [0, 1] R RA , satises:1. L(s, ) = 0 L(s,) = 1 S,2. L(s, A)n, L(s, A) 1 n,3. L(s, C D) n, L(s, C) n L(s, D) n,4. L(s, C D) n, L(s, C) n L(s, D) n,5. L(s, C D) n, L(s, C) n L(s, D) n,6. L(s, C D) n, L(s, C) n L(s, D) n,7. L(s, R.C) n, E(R, s, t) 1 n L(t, C) n,8. L(s, R.C) n, E(R, s, t) n L(t, C) n,9. L(s, R.C) n, exists E(R, s, t) n L(t, C) n,10. L(s, R.C)n, exists E(R, s, t) 1n L(t, C)n,11. L(s, R.C) n Trans(R), E(R, s, t) n L(t, R.C) n,12. L(s, R.C) n, Trans(R), E(R, s, t) 1 n L(t, R.C) n,13. E(R, s, t)n E(Inv(R), t, s)n,288fiReasoning Expressive Fuzzy Description Logics14. (a : C)n A, L(V(a), C)n,15. (a, b : R)n A, E(R, V(a), V(b))nremarks regarding Denition 5.1. First, observe use notationE(R, s, t) instead simply E(R, s, t) order distinguish role Rordered pair nodes s, t. Moreover, denition based semanticsfuzzy interpretations, presented Table 2, order nd properties fuzzy modelsaccording relation holds membership degree, specic valueinequality type. Then, based properties would develop tableaux expansionrules, try construct abstracted model. example, property 3, duesemantics C D, (C D)I (s) n, C (s) = n1 , DI (s) = n2 ,min(n1 , n2 ) = (C D)I (s) n. Due properties min normconclude n1 n n2 n, hold. Furthermore, property 7, duesemantics R.C, (R.C)I (s) n have, max(1 RI (s, t), C (s)) n, hence either1 RI (s, t) n RI (s, t) 1 n C (t) n. Similarly, constructed propertiespossible relations node, fKD -SI-concept value unit interval.Properties 9 10 based fact assume existence witnessedmodels. Otherwise, assumption could made. Hence, intuitively fuzzy tableauabstraction witnessed models fuzzy ABox. Finally, property 14 meansfuzzy assertion form (a : C) > n exists fuzzy ABox, membershipdegree node V(a) concept C fuzzy tableau, strictly greatern. Similarly, rest inequalities well property 15.prove lemma connecting ABox consistency existencefuzzy tableau A.Lemma 5.2 fKD -SI ABox consistent w.r.t. R, exists fuzzy tableauw.r.t. R.Proof: direction = (S, L, E, V) fuzzy tableau ABox w.r.t. R,construct fuzzy interpretation =(I , ) model A.interpretation dened follows:=aI(s)==V(a), IAL(s,)(s)AI (s)==RI (s, t)=L(s, )L(s, A) concept names+(s, t) s, Trans(R)(s, t) s, otherwise(s, t) binary fuzzy relation dened (s, t) = E(R, s, t) s, SS,RE+ represents sup-min transitive closure (Klir & Yuan, 1995).prove model A, show induction structure conceptsL(s, C)n implies C (s)n S. First, Property 1 ensures top289fiStoilos, Stamou, Pan, Tzouvaras & Horrocksbottom concepts interpreted correctly. Together properties 14, 15,interpretation individuals roles, implies satises assertion A.Without loss generality, following, show cases L(s, C) n.rest inequalities shown similar way.1. concept name denition nL(s, A) = AI (s).2. L(s, A) n, due property 2 L(s, A) 1 n. denition I, AI (s)1 n, hence (A)I (s) c(1 n) = n.3. L(s, C D) n, L(s, C) n L(s, D) n. induction, C (s) n,(s) n, hence (C D)I (s) = min(C (s), DI (s)) n.4. L(s, C D) n, L(s, C) n L(s, D) n. induction either C (s) n(s) n (C D)I (s) = max(C (s), DI (s)) n.5. L(s, R.C) n, exists that, E(R, s, t) n L(t, C)n. denition RI (s, t) n induction C (t) n. Hence, (R.C)I (s) =suptI min(RI (s, t), C (t)) n.6. L(s, R.C) n RI (s, t) = p, either(a) E(R, s, t) = p,(b) exist several paths l 1 form, E(R, s, sl1 ) = pl1 , E(R, sl1 , sl2 ) =pl2 , . . . , E(R, slm , t) = plm+1 . membership degree p pair s,transitive closure R, would equal maximum degree (since cannotinnite number dierent paths) minimum degrees path.degree lower equal 1 n (since =)exists path, k, degrees:E(R, ski , ski+1 ) = pki , 0 m, sk0 s, skm+1 t,holds pki > 1 n, pki would greater equalminimum degree path. Hence, due Property 12 skiL(ski , R.C) n.case p 1 n max(1 p, C (t)) n. case p 1 n,L(t, C) n, induction C (t) n thus also max(1 RI (s, t), C (t)) n.cases (R.C)I (s) n.converse, =(I , ) (witnessed) model w.r.t. R, fuzzytableau = (S, L, E, V) w.r.t. R dened as:=E(R, s, t)L(s, C)==RI (s, t)C (s)V(a)=aI290fiReasoning Expressive Fuzzy Description Logics1. Property 1 satised since fuzzy interpretation.2. Let L(s, C) n. denition implies (C)I (s) = n n C (s) =1 n 1 n, L(s, C) 1 n Property 2 satised. Similarlyinequalities {, <}.3. Let L(s, C D) n. denition implies (C D)I (s) = n nmin(C (s), DI (s)) = n n. denition, L(s, C) n L(s, D) n satisesProperty 3. Property 4 proved similar way.4. Let L(s, C D) n. denition implies (C D)I (s) = n nmax(C (s), DI (s)) = n n. denition , either L(s, C) n L(s, D) n,satises Property 5. Property 6 proved similar way.5. Let L(s, R.C) n. denition implies (R.C)I (s) = n ninf yI max(1 RI (s, y), C (y)) = n n. means either1 RI (s, t) = n n C (t) = n n, denition either E(R, s, t) 1 nL(t, C) n. Thus, satises Property 7. Property 8 proved similar way.6. Let L(s, R.C) n. denition implies (R.C)I (s) = n nsupyI min(RI (s, y), C (y)) = n n. means existsRI (s, t) = n n C (t) = n n. denition satises Property9. Property 10 proved similar way.7. Property 12 denition 5.1 satised result semantics transitive rolesvalue restrictions investigated section 4. Hence, (R.C)I (s)n, Trans(R) either RI (s, t) 1 n, (R.C)I (t) n holds, otherwise(R.C)I (s) > n, Trans(R) either RI (s, t) < 1 n (R.C)I (t) > n holds.denition L(s, R.C) n, Trans(R) either E(R, s, t) 1 nL(t, R.C) n. similar reasons Property 11, holds.8. satises Property 13 Denition 5.1 direct consequence semanticsinverse relations.9. satises Properties 14 15 Denition 5.1 model A.5.1 Algorithm Constructing fKD -SI Fuzzy Tableaupresent tableaux algorithm tries construct, given fKD -SI ABoxfKD -SI RBox R, fuzzy tableau w.r.t. R. prove algorithm constructfuzzy tableau R exists fuzzy tableau R, thus decidesconsistency fKD -SI ABoxes w.r.t. RBoxes.Like tableaux algorithm presented Horrocks et al. (2000), algorithm workscompletion-forests rather completion-trees, since ABox might contain severalindividuals arbitrary roles connecting them. Due presence transitive roles,termination algorithm ensured use blocking, expansion291fiStoilos, Stamou, Pan, Tzouvaras & Horrocksterminated two individuals path asserted belong concepts. fKD -SI provides inverse roles transitive role axioms, algorithm usesdynamic blocking (Horrocks & Sattler, 1999); i.e., blocked nodes (and sub-branches)un-blocked blocked later. noted Horrocks Sattler (1999)un-blocking re-blocking technique crucial presence inverse roles sinceinformation might propagated completion-forest aect branches.example consider nodes x, z, edges x, x, z suppose xblocks y. presence inverse roles possible z adds information node x,although z successor x. case block must broken. Finally, evencases node blocked un-blocking occur necessary allowexpansion performed. example node might contain inverse informationallowed propagated upwards render completion-forest unsatisable. Thus,dynamic blocking uses notions directly indirectly blocked nodes.Denition 5.3 (Completion-Forest) completion-forest FA fKD -SI ABoxcollection trees whose distinguished roots arbitrarily connected edges.node x labelled set L(x) = {C, , n}, C sub(A), {, >, , <}n [0, 1]. edge x, labelled set L(x, y) = {R, , n}, R RA(possibly inverse) roles occurring A. Intuitively, triple C, , n (R, , n), calledmembership triple, represents membership degree type assertion node(pair nodes) concept C sub(A) (role R RA ).nodes x connected edge x, R, , n L(x, y),called R,n -successor x x called R,n -predecessor y. R,n successor Inv(R),n -predecessor x, called R,n -neighbour x. LetR>,n -neighbour x, edge x, conjugates triples R, , n m.Similarly, extend cases R,n -, R<,n - R,n -neighbours.node x R-successor (resp. R-predecessor R-neighbour) R,n successor (resp. R,n -predecessor R,n -neighbour) role R. node xpositive (resp. negative) successor (resp. predecessor neighbour) {>, }(resp. {<, }). usual, ancestor transitive closure predecessor.node x blocked root node either directly indirectly blocked.node x directly blocked none ancestors blocked, ancestorL(x) = L(y). case, say directly blocks x. node x indirectlyblocked one predecessor blocked.node x said contain clash exist two conjugated triples, onefollowing triples within L(x):, , n,, , n, n > 0, n < 1 respectively, >, n,, <, nC, <, 0, C, >, 1Moreover, edge x, y, L(x, y) said contain clash exist two conjugatedtriples L(x, y), L(x, y) {Inv(R), , n | R, , n L(y, x)}, x,root nodes, contains two conjugated triples.denition completion-forest quite intuitive. Since fuzzy ABox contains fuzzyassertions form (a : C)n (a, b : R)n, nodes edges forest292fiReasoning Expressive Fuzzy Description LogicsRule( )1.2.DescriptionC, , n L(x)C, , 1 n L(x)L(x) L(x) {C, , 1 n}( )1.2.C1 C2 , , n L(x), x indirectly blocked,{C1 , , n, C2 , , n} L(x)L(x) L(x) {C1 , , n, C2 , , n}( )1.2.C1 C2 , , n L(x), x indirectly blocked,{C1 , , n, C2 , , n} L(x)L(x) L(x) {C1 , , n, C2 , , n}( )1.2.C1 C2 , , n L(x), x indirectly blocked,{C1 , , n, C2 , , n} L(x) =L(x) L(x) {C} C {C1 , , n, C2 , , n}( )1.2.C1 C2 , , nL(x), x indirectly blocked,{C1 , , n, C2 , , n} L(x) =L(x) L(x) {C} C {C1 , , n, C2 , , n}( )1.2.R.C, , n L(x), x blocked,x R,n -neighbour C, , n L(y)create new node L(x, y) = {R, , n}, L(y) = {C, , n}( )1.2.R.C, , n L(x), x blocked,x R ,1n -neighbour C, , n L(y)create new node L(x, y) = {R, , 1 n}, L(y) = {C, , n}( )1.2.3.R.C, , n L(x), x indirectly blocked,x R ,n1 -neighbour C, , n L(y)x, conjugates R, , 1 nL(y) L(y) {C, , n}( )1.2.3.R.C, , n L(x), x indirectly blockedx R,n1 -neighbour C, , n L(y)x, conjugates R, , nL(y) L(y) {C, , n}(+ )1.2.3.R.C, , n L(x) Trans(R), x indirectly blocked,x R ,n1 -neighbour R.C, , n L(y)x, conjugates R, , 1 nL(y) L(y) {R.C, , n}(+ )1.2.3.R.C, , n L(x) Trans(R), x indirectly blockedx R,n1 -neighbour R.C, , n L(y)x, conjugates R, , nL(y) L(y) {R.C, , n}Table 4: fKD -SI completion rulesmust contain information concept, type inequality membershipdegree every individual, forest represented node.Denition 5.4 (Tableaux Algorithm) fKD -SI ABox A, algorithm initialisesforest FA contain (i) root node xai , individual ai IA occurring A, labelled L(x) {Ci , , n} L(xai ) assertion form (ai : Ci )n293fiStoilos, Stamou, Pan, Tzouvaras & HorrocksA, (ii) edge xai , xaj , assertion (ai , aj : Ri )n A, labelledL(xai , xaj ) {Ri , , n} L(xai , xaj ). Moreover, algorithm expands Radding axiom Trans(Inv(R)) Trans(R) R. FA expanded repeatedlyapplying completion rules Table 4. completion forest complete when,node x, L(x) contains clash, none completion rules Table 4 applicable. algorithm stops clash occurs; answers consistent w.r.t. Rcompletion rules applied way yield complete clash-freeconpletion forest, inconsistent w.r.t. R otherwise.remarks regarding Denition 5.4. expansion rules basedproperties semantics presented Denition 5.1. example, consider ()-rule.Now, R.C, , 0.7 L(x), R, , 0.6 L(x, y), means last tripleviolates property 7 Denition 5.1. property says membership degreeedge x, role R lower equal degree 1 0.7, otherwisemembership degree C greater equal 0.7. Interpretedmembership triples means triple form R, , n exists L(x, y),n 1 0.7, triple form R, >, n, n < 1 0.7. order discoverrestrictions violated ()-rule compares triples edge x,articial triple R, , 0.3 conjugation. present case conjugation occurs, thusadd triple C, , 0.7 label y. Similar arguments hold restproperties. Please note articial triples added completion-forestused perform checks membership degrees. Secondly, tableauxalgorithm, see dealing nite number membership degrees. fact,Table 4, see arbitrary fuzzy assertion form (x : D)n eithervalue n complement c(n) appear expansion node x D, , n L(x).nite property membership degrees makes blocking possible algorithm.property consequence fuzzy operations used context, i.e. Godel tnorm t-conorm, Lukasiewicz complement Kleene-Dienes fuzzy implicationusually hold combinations fuzzy operations. Finding appropriateblocking condition norms used combination Description Logicsinclude transitive relations open research issue. Finally, worth noting sinceassume concepts negation normal form ( )-rule appliesconcept names. But, since employ rule handling negated conceptsabsolutely necessary fuzzy DLs. Hence, able produce NNF formnegated concepts apply ( )-rule directly them. might baseoptimization, since might able identify clashes earlier, generalizationsnorm operations, since case might able produce NNFnegated concepts. either case, proof lemma 5.9 would require slight modicationorder correctly interpret negated concepts.Example 5.5 Let us see examples applications expansion rules.( ): Let R.C, , 0.7 L(x) Inv(R), >, 0.3 L(y, x). Accordingdenition R-neighbour, R>,0.3 -neighbour, hence x, conjugatesR, , 0.3, additionally C, , 0.3 L(y). Thus, add C, , 0.3L(y).294fiReasoning Expressive Fuzzy Description Logics( ): Let Inv(R).C, , 0.7 L(x). create new node forest set,Inv(R), , 0.7 L(x, y), C, , 0.7 L(y).(+ ): Let Inv(R).C, <, 0.5 L(x), Inv(R), , 0.7 L(x, y) Trans(R).Inv(R),0.7 -neighbour x, hence x, conjugates Inv(R), <, 0.5,additionally Inv(R).C, <, 0.5 L(y). Hence, Inv(R).C, <, 0.5 addedL(y).revisit example 3.3 see procedure presented sectionused determine consistency ABox.Example 5.6 Recall fuzzy ABox = {(o1 , o2 : isPartOf) 0.8, (o2 , o3 :isPartOf) 0.9, (o2 : Body) 0.85 (o1 : Arm) 0.75}, wanted testconsistency fuzzy ABox = {(o3 : Inv(isPartOf).Body Inv(isPartOf).Arm) <0.75}, w.r.t. R = {Trans(isPartOf)}. According Denition 5.4 algorithm initializescompletion-forest contain following triples (note node xoiindividual oi ):(1)(2)(3)(4)(5)isPartOf, , 0.8 L(xo1 , xo2 )isPartOf, , 0.9 L(xo2 , xo3 )Body, , 0.85 L(xo2 )Arm, , 0.75 L(xo1 )isPartOf .Body isPartOf .Arm, <, 0.75 L(xo3 )Furthermore, algorithm expands R adding axiom Trans(isPartOf ). Please notesimplicity expanded concepts Arm Body membershiptriples. Subsequently, applying expansion rules Table 4 following steps:(6)isPartOf .Body, <, 0.75 L(xo3 ) | isPartOf .Arm, <, 0.75 L(xo3 )(< )Hence point two possible completion forests. rst one have,(61 )(71 )(81 )isPartOf .Body, <, 0.75 L(xo3 )Body, <, 0.75 L(xo2 )clash (71 ) (3)(< ) : (61 ), (2)second possible completion-forest have.(62 )(72 )(82 )(92 )(102 )isPartOf .Arm), <, 0.75 L(xo3 )Arm, <, 0.75 L(xo2 )isPartOf .Arm), <, 0.75 L(xo2 )Arm, <, 0.75 L(xo1 )clash (92 ) (4)(< ) : (62 ), (2)(+ ) : (62 ), (2)(< ) : (82 ), (1)Thus, since possible expansions result clash, inconsistent knowledge baseentails fuzzy assertion.295fiStoilos, Stamou, Pan, Tzouvaras & HorrocksExample 5.7 Consider fuzzy knowledge base = , A, R, TBox = {CR .(P .A)}, ABox = {(a : A) 0.8, (a, b : P ) 0.8, (b : C) 0.8, (b : R.C)0.8, (b : R.(R.C)) 0.8} RBox R = {Trans(R)}. First algorithm expands Radding axiom Trans(R ). Then, order check consistency w.r.t. Ralgorithm initializes following completion-forest:(1)(2)(3)(4)(5)A, , 0.8 L(xa )C, , 0.8 L(xb )R.C, , 0.8 L(xb )R.(R.C), , 0.8 L(xb )P, , 0.8 L(xa , xb ).Then, get following application expansion rules,(6)(7)(8)C, , 0.8 L(xo1 ), R, , 0.8 L(xb , xo1 )R.C, , 0.8 L(xo1 )R.(R.C), , 0.8 L(xo1 )( ) : (3)( ) : (4)(+ ) : (4)see L(xb ) = L(xo1 ), hence xo1 blocked xb . handindirectly blocked. Hence, since R .(P .A), , 0.8 L(xo1 ) (due denitionC TBox) following application expansion rules,(9)(10)(11)(12)P .A, , 0.8 L(xb )A, , 0.8 L(xa )A, , 0.2 L(xa )clash (11) (1)( ) : (6)( ) : (9)( ) : (10)Please note adding P .A, , 0.8 L(xb ) causes blocking node xo1broken since longer holds L(xb ) = L(xo1 ). Hence, notions indirectlyblocked nodes dynamic blocking crucial presence inverse roles ordercorrectly identify consistent inconsistent ABoxes. Also note algorithmchosen expand xo1 (since node blocked) rather xb , wouldcreated another node, say xo2 , L(xo1 ) = L(xo2 ). C, , 0.8would added xo1 , since xo2 would indirectly blocked, block xo2 wouldbroken, would hold L(xb ) = L(xo1 ). Hence xo1 would permanentlyblocked xo2 indirectly blocked. algorithm would choiceidentify clash node xa , showed steps (9) (12).5.2 Decidability fKD -SIsoundness completeness algorithm demonstrated provingSI ABox A, always terminates returns consistent consistent.Lemma 5.8 (Termination) fKD -SI ABox RBox R, tableaux algorithm terminates, started R.Proof: Let = |sub(A)|, k = |RA | l number dierent membership degrees appearing A. Obviously l linear length A. Terminationconsequence following properties expansion rules:296fiReasoning Expressive Fuzzy Description Logics1. expansion rules never remove nodes forest concepts node labels.2. ()- ()-rule generate new nodes, generation triggeredR.C, , n R.C, , n node label R.C R.C sub(A).nodes removed, rules applied label repeatedly. Since sub(A) contains R.C R.C, out-degree forestbounded 2ml.3. Nodes labelled triples form C, , n, 28ml dierentpossible labellings pair nodes. Thus, path p length least 28ml (noteconcepts cause non-termination interact either value nnegation, both), exist two nodes x, p containlabel. Since path nodes blocked cannot become longer, pathslength 28ml .previous lemma suggests tableaux algorithm runs exponential space.due well-known problem inherited crisp SI language (Tobies, 2001). Considerexample following concepts taken Tobies (2001),C R.D R.(R.D)(A1 B1 ) (A2 B2 ) . . . (An Bn )R transitive role. consider want check consistencyfuzzy ABox = {(a : C) n}. Concept C causes generation R,n -successors bialso holds (bi : D) n. due -rule, might choose addeither (bi : Ai ) n (bi : Bi ) n, 2n possible ways expanding D. Hence,algorithm might create path exponential depth blocking applies. Tobies (2001)presents optimized blocking technique leads Pspace algorithm SI.technique involves rened blocking strategy well modication tableauxexpansion rules. Investigating applicability technique fKD -SI interestingopen problem.Lemma 5.9 (Soundness) expansion rules applied fKD -SI ABoxRBox R yield complete clash-free completion-forest,fuzzy tableau w.r.t. R.Proof: Let FA complete clash-free completion-forest constructed tableauxalgorithm A. construction fuzzy tableau = (S, L, E, V) basedconstruction fuzzy model, presented Straccia (2001):set triples form A, , ni , positive integer, might exist withinset triples L(x), maximum value ni chosen membership degree xfuzzy set AI , i.e. degree L(x, A) case. maximum value participatestriple form A, >, n small factor added maximum. existencevalue ensured clash-freeness FA . Please also note without lossgenerality force factors equal. Furthermore, triple formC, , ni L(x) exists, triples C, , ni L(x) do, membership degree297fiStoilos, Stamou, Pan, Tzouvaras & Horrocksset 0. cases value existential restriction exists well non conjugatedrelation, special care choice made order choose high valuecauses conjugation interpretation. last, order interpret conceptsform A, concept name, rst compute maximum degree nodeconcept use compute A. function returns maximumdegree denoted glb (Straccia, 2001). Please note labellings L(s, C) refernodes fuzzy tableau, L(x) nodes completion-forest. fuzzytableau dened follows:L(x, )=={x | x node FA , x blocked},0, x S,L(x,)L(x, C)==1, x S,glb[C, , ni ], C, , ni L(x) x blocked,L(x, A)E(R, x, y)==V(ai )=1 L(x, A), x FA blocked, A, , n L(x),{glb[R , , ni ] | 1. R,ni -neighbour x2.R, , ni L(x, z) blocks z3.Inv(R), , ni L(y, z) x blocks z},xai , xai root node,R represents either R Inv(R). shown fuzzy tableauw.r.t. R:1. Property 1 Denition 5.1 satised due construction FAclash-free.2. Property 2 Denition 5.1 satised -rule apply forcefactors equal. Let L(x, A) = n1 n. denition implies1 n 1 n1 = L(x, A).3. Properties 3-6 Denition 5.1 satised none applyx S. example, let L(x, C D) = n1 n. denition implies that,either C D, , n1 L(x) C D, >, n L(x), n1 = n + . CompletenessFA implies either C, , n1 L(x) D, , n1 L(x) C, >, n L(x)D, >, n L(x). Hence, L(s, C) = glb[C, , ni ] L(s, C D) n, L(s, D) =glb = [C, , ni ] L(s, C D) n. rest properties follow similar way.4. Property 7 Denition 5.1 satised. Let x L(x, R.C) = n1 nE(R, x, y) 1 n. denition implies either R.C, , n1 L(x)R.C, >, n L(x) n1 = n + . Moreover, since glb functioncreate unnecessary conjugation either:(a) R,r -neighbour x(b) R, , r L(x, z), blocks z thus L(y) = L(z),(c) Inv(R), , r L(y, z), x blocks z, thus L(x) = L(z).298fiReasoning Expressive Fuzzy Description LogicsR, , r Inv(R), , r causes conjugation. Hence, 3 cases, -ruleensures either C, , n1 L(y) C, >, n L(y). Thus, either L(y, C) n1n, L(y, C) n + = n1 n. case L(x, R.C) > n L(x, R.C) n,latter regards property 8, shown similar way.5. Property 9 Denition 5.1 satised. Let x L(x, R.C) = n1 n.denition implies either R.C, , n1 L(x) R.C, >, n L(x),n1 = n + . -rule ensures either:(a) predecessor Inv(R), , n1 L(y, x) C, , n1 L(y)dually > n . predecessor x cannot blocked,S, E(R, x, y) n1 n L(y, C) n1 E(R, x, y) n + = n1 nL(y, C) n + = n1 n.(b) successor R, , n L(x, y), C, , n L(y) dually >n . blocked, E(R, x, y) n1 , L(y, C) n1E(R, x, y) n + , L(y, C) n + = n1 . Otherwise, blockedz. Hence, z R, , n1 L(x, z), C, , n1 L(z) R, >, nL(x, z), C, >, n L(z). cases L(z, C) n E(R, x, z) n.Similar proof applies L(x, R.C) > n also Property 10 L(x, R.C)n.6. Property 12 Denition 5.1 satised. Let x L(x, R.C) = n1 nE(R, x, y) 1 n. denition implies either R.C, , n1 L(x)R.C, >, n L(x) n1 = n + . Moreover, since glb functioncreate unnecessary conjugation either:(a) R,r -neighbour x(b) R, , r L(x, z), blocks z thus L(y) = L(z),(c) Inv(R), , r L(y, z), x blocks z, thus L(x) = L(z).R, , r Inv(R), , r causes conjugation. Hence, 3 cases, + rule ensures either R.C, , n1 L(y) R.C, >, n L(y). Thus, eitherL(y, R.C) n1 n, L(y, R.C) n + = n1 n. case L(x, R.C) > nL(R.C, , n, latter regards property 11, shown similar way.7. Property 13 Denition 5.1 satised because, E(R, x, y)n, either:(a) R,n1 -neighbour x, x Inv(R),n1 -neighbour y.(b) R, , n1 L(x, z), blocks z, Inv(Inv(R)), , n1 L(x, z)(c) Inv(R), , n1 L(y, z) x blocks z.3 cases, E(Inv(R), y, x)n.8. Properties 14 15 satised cause initialization completion-forestfact algorithm never blocks root nodes.299fiStoilos, Stamou, Pan, Tzouvaras & HorrocksLemma 5.10 (Completeness) Let fKD -SI ABox R RBox.fuzzy tableau w.r.t. R, expansion rules applied waytableaux algorithm yields complete clash-free completion-forest R.Proof: proof completeness based proof crisp DLs presented HorrocksSattler (1999) Horrocks et al. (2000).Let = (S, L, E, V) fuzzy tableau A. Using , trigger applicationexpansion rules yield completion-forest FA completeclash-free.Since know fuzzy tableau (T ) steer application rulesyield complete clash-free completion-forest. Horrocks Sattler(1999) Horrocks et al. (2000) dene mapping maps nodes FA elementsS, guide application non-deterministic rules . methoddiers one used crisp DLs (Horrocks & Sattler, 1999) following way.Using membership degree node concept, found fuzzy tableau, createarticial triples tested conjugation candidate triplesnon-deterministic rules insert completion-forest. triples dont causeconjugation added. modied rules, used guide expansion,presented Table 5.( )1.2.( )1.2.C1 C2 , , n L(x), x indirectly blocked,{C1 , , n, C2 , , n} L(x) =L(x) L(x) {C} C {C1 , , n, C2 , , n}conjugated C1 , , L((x), C1 ) C2 , , L((x), C2 )C1 C2 , , n L(x), x indirectly blocked,{C1 , , n, C2 , , n} L(x) =L(x) L(x) {C} C {C1 , , n, C2 , , n}conjugated C1 , , L((x), C1 ) C2 , , L((x), C2 )Table 5: - -rulesensures new fuzzy assertion membership degree node concept,created non-deterministic rule, restrictive one already knownfuzzy tableau, thus avoiding possible conjugations. together terminationproperty ensure completeness algorithm.Theorem 5.11 tableaux algorithm decision procedure consistency fKD -SIABoxes satisability subsumption fKD -SI concepts respect simpleterminologies.Theorem 5.11 immediate consequence lemmas 5.1, 5.9 5.10. Moreover,discussed section 3, subsumption reduced consistency checking ABoxes.6. Adding Role Hierarchies Number Restrictionscurrent section provide necessary extensions reasoning algorithmpresented previous section, order provide reasoning support fuzzy DL300fiReasoning Expressive Fuzzy Description Logicslanguage fKD -SHIN . achieve goal extend results section 4 alsoconsidering role hierarchies, also provide investigation numberrestrictions constructor.classical DLs, results transitive roles value restrictions obtained Sattler(1996), extended Horrocks Sattler (1999) also consider role hierarchies.* R,precisely, show x (R.C)I , x, P , Trans(P ) P(P.C)I . fuzzy DLs also include role hierarchies easily extend resultsobtained section 4. Let (R.C)I (x) ca , P (x, y) = p, Trans(P ), ca , p [0, 1],consider also P * R. Since P transitive, x, arbitraryz holds that, P (x, y) min(P (x, z), P (z, y)). Due semantics roleinclusion axioms RI (x, y) min(P (x, z), P (z, y)). Then, worksimilar way section 4 get that, max(c(P (a, b)), (P.C)I (b)) va , meanseither c(P (a, b)) va (P.C)I (b) va . similar result obtainedcase (R.C)I (a) > n. Hence, get following result:* R, fKD -DL holdsCorollary 6.1 (R.C)I (a) n, Trans(P ) Pthat, (P.(P.C)) (a) n.Finally, case negative assertions existential restrictions followingeasily obtained.* R, fKD -DL holdsCorollary 6.2 (R.C)I (a) n, Trans(P ) Pthat, (P.(P.C))I (a) n.investigate fuzzy number restrictions. Although, Table 2 seemssemantics number restrictions quite complicated, see intuitively,quite similar crisp counterparts, long also consider membershipdegrees.Consider example at-least restriction ( pR)I (a) n, .according Table 2 have,psupmin{RI (a, bi )} n.b1 ,...,bp i=1means must least p pairs a, bi , RI (a, bi ) n, holds.semantics quite intuitive similar crisp number restrictions. onewould require least p pairs RI (a, bi ) 1, simply means ppairs. Similarly, work ( pR)I (a) > n.Consider at-most restriction form ( pR)I (a) n. Based semanticsinequation,infb1 ,...,bp+1p+1max{1 RI (a, bi )} n.i=1means p + 1 pairs a, bi , formed, least one pairc(RI (a, bk )) n, holds. also view equation dierent wayresembles crisp number restrictions. perspective say that,301fiStoilos, Stamou, Pan, Tzouvaras & Horrocksp pairs a, bi c(RI (a, bi )) < n, holds. Similarly, at-most restrictionform ( pR)I (a) > n implies at-most p pairs a, bi , holdsc(RI (a, bi )) n. Hence reasoning w.r.t. number restrictions reduced countingmany role assertions (a, bi : R) ni satisfy inequalities. ndp assertions satisfy inequalities, non-deterministically mergeindividual bi , case crisp SHIN algorithm (Horrocks et al., 2000).Now, lets consider extreme boundaries 0 1, apply equation classicalat-most restriction, ( pR)I . fuzzy equivalent assertions ( pR)I (a) 1,implies p bi that, c(RI (a, bi )) < 1 RI (a, bi ) > 0,holds. Since considering 0 1 last inequality implies, RI (a, bi ) = 1, i.e.at-most p successors RI .Dually, also provide intuitive meaning cases involve negativeinequalities, like example cases ( pR)I (a) n1 ( pR)I (a) n2 . Applyingnegation rst equation obtain, (( pR))I (a) c(n1 ), c fuzzy complement. Since min max operations satisfy De Morgan laws, assertiontranslated ( (p 1)R)I (a) 1 n1 , p 1, negation normal formformer assertion. Similarly, equation ( pR)I (a) n2 transformedequivalent, ( (p + 1)R)I (a) 1 n2 .Using results proceed denition fKD -SHIN fuzzy tableau.Similarly 5.1 consider concepts NNF. achieved usingconcept equivalences number restrictions section 3. denition fuzzy tableaufKD -SHIN rst appeared Stoilos, Stamou, Tzouvaras, Pan, Horrocks (2005c),revised denition better represent properties fuzzy models.dening fuzzy tableau fKD -SHIN extend denition sub-conceptsconcept ABox A.Denition 6.3 fuzzy concept role hierarchy R dene sub(D, R)smallest set fKD -SHIN -concepts satises following:sub(D, R),sub(D, R) closed sub-concepts D,* S, R.C sub(D, R)S.C sub(D, R) R* S, R.C sub(D, R)S.C sub(D, R) RFinally, dene sub(A, R) =(a:D)nAsub(D, R).R clear context simply write sub(A).Denition 6.4 fKD -SHIN ABox, R fKD -SHIN RBox, RA setroles occurring R together inverses, IA set individuals A,fuzzy tableau w.r.t. R dened Denition 5.1 additionalproperties:* R, E(P, s, t) n L(t, P.C) n,11. L(s, R.C) n, Trans(P ) P302fiReasoning Expressive Fuzzy Description Logics12. L(s, R.C)n, Trans(P ) P* R, E(P, s, t) 1n L(t, P.C)n,* S, E(S, s, t) n,16. E(R, s, t) n R17. L(s, pR) n, RT (s, , n) p,18. L(s, pR) n, RT (s, , 1 n) p + 1,(s, , n) p 1,19. L(s, pR) n, R(s, , 1 n) p,20. L(s, pR) n, R.21. =b A, V(a) =V(b)RT (s, , n) = {t | E(R, s, t)n} returns set elements participate R element degree, greater equal, greater, lower equal(s, , n) = {t | E(R, s, t) n} returns elements dontlower n, Rsatisfy given inequality.Denition 5.1, based semantics language observations made beginning section properties value existential restrictions, transitive roles role hierarchies involved, semanticmeaning at-most at-least number restrictions. Thus, property 18 readas, L(s, pR) n at-most p E(R, s, t) 1 n, i.e.E(R, s, t) > 1 n, L(s, pR) > n, at-most pE(R, s, t) < 1 n.Lemma 6.5 fKD -SHIN ABox consistent w.r.t. R, exists fuzzy tableauw.r.t. R.Proof: proof lemma similar lemma 5.2 importanttechnical details. direction, = (S, L, E, V) fuzzy tableau w.r.t. R,model = (, ) R constructed = S, aI = V(a), IA ,(s) = L(s,), (s) = L(s, ) S, AI (s) = L(s, A),concept names A, roles have:+(s, t),Trans(R)R (s, t) =max (RE (s, t), P (s, t)) otherwiseP* R,P =RObserve interpretation non-transitive roles recursive order correctlyinterpret non-transitive roles transitive sub-role. denitionRI property 12, RI (s, t) = n (0, 1], either E(R, s, t) = n, E(R, s, t) = 0exist several paths l 1 form,E(P, s, sl1 ) = pl1 , E(P, sl1 , sl2 ) = pl2 , . . . , E(P, slm , t) = plm+1Trans(P ), P* R E(R, s, t) = max(0, supl {min(pl1 , . . . , plm+1 )}).Property 16 ensures s, , P (s, t) RI (s, t) P * R. Again,induction structure concepts show L(s, C)n implies C (s)nS. Here, restrict attention cases dierent lemma5.2. Similarly lemma 5.2 also restrict attention inequalities .303fiStoilos, Stamou, Pan, Tzouvaras & Horrocks6. L(s, R.C) n RI (s, t) = p, either(a) E(R, s, t) = p,(b) E(R, s, t) = p. Then, exist several paths l 1 form, E(P, s, sl1 ) =* R.pl1 , E(P, sl1 , sl2 ) = pl2 , . . . , E(P, slm , t) = plm+1 , Trans(P ) Pmembership degree p pair s, (P + )I , would equal maximum degree (since cannot innite number paths) minimumdegrees path. degree lower equal1 n exists path k degreesE(P, ski , ski+1 ) = pki , 0 km , sk0 s, skm+1lower equal 1 n, pki would greater equalminimum degree path. Hence, due property 11, wouldL(ski , P.C) n, 1 km .case p 1 n max(1 p, C (t)) n. case p 1 nL(t, C) n, C (t) n thus also max(1 p, C (t)) n. cases(R.C)I (s) n.7. L(s, pR) n have, E(R, s, ti ) n, 1 p. denition RI (s, ti )n, thuspn sup {. . . , min{RI (s, ti )}, . . .} = ( pR)I (s).i=1ti8. pR, , n p pairs s, ti which, E(R, s, ti ) 1 n,1 p. Thus p + 1-tuples formed would least onepair s, tp+1 E(R, s, tp+1 ) 1 n (even E(R, s, tp+1 ) = 0 1 n).Hence, RI (s, tp+1 ) 1 n c(RI (s, tp+1 )) n. Finally, that,pn inf {. . . , max(max{c(RI (s, ti ))}, c(RI (s, tp+1 ))), . . .} = ( pR)I (s).tii=1converse, =(I , ) model w.r.t. R, fuzzy tableau =(S, L, E, V) R dened exactly lemma 5.2. Then,1. Properties 1-10 13 Denition 5.1 16-20 Denition 6.4 satiseddirect consequence semantics fKD -SHIN concepts.2. Property 12 Denition 6.4 satised consequence semantics transitive roles, role hierarchies value restrictions investigated* R Trans(P ) eitherbeginning section. Hence, (R.C)I (s) n, PP (s, t) 1 n, (P.C)I (t) n holds, otherwise (R.C)I (s) > n, P * RTrans(P ) either P (s, t) < 1 n (P.C)I (t) > n holds. denition* R Trans(P ) either E(P, s, t) 1 n L(t, P.C) n.L(s, R.C) n, PSimilarly, property 11 Denition 6.4.3. satises Properties 14-15 Denition 5.1 Property 21 Denition 6.4model A.304fiReasoning Expressive Fuzzy Description Logics6.1 Constructing fKD -SHIN Fuzzy Tableausection show algorithm fKD -SI, presented section 5.1,extended deal fKD -SHIN ABoxes. number modicationsneed made, like denition R-neighbours, (+ )- (+ )-rules, blockingstrategy, clash denition addition rules number restrictions.important modication algorithm fKD -SI blocking strategy.noted Horrocks Sattler (1999) DL language provides inverse roles,transitive role axioms, number restrictions lacks nite-model property; i.e.fKD -SHIN -concepts satisable innite interpretations. meansusual blocking techniques create cycle predecessor blocked nodeblocking one, might fail construct correct tableau due lemma 6.5 correctmodel. crucial remark dierence innite witnessed model,presented remark 3.2. Although fKD -SHIN -concept satisableinnite interpretations, interpretations still witnessed w.r.t. membershipdegrees. innite nite property interpretations comes constructslanguage, witnessed non-witnessed property comes continuityfuzzy operators (Hajek, 2005).Consider example node x contains triple form 1R, , 1.successor x, say y, blocked ancestor x, say z, dynamic blockingtechniques would create cycle leading x back z. extra edge x, z mightviolate number restriction x. overcome problem construction tableau completion-forest performed repeatedly copying sub-tree underneathnode causes blocking, z case. Thus, able obtain inniteconstructed nite forest. Furthermore, order copied nodes satisablenew locations extra condition, compared dynamic blocking employed.new blocking technique called pair-wise blocking (Horrocks & Sattler, 1999); i.e.,blocking occurs two nodes belong set concepts, predecessors alsobelong set concepts edges connect also equal.way unravelling guaranteed.Denition 6.6 (fKD -SHIN Completion Forest) First extend denition Rsuccessors, predecessors neighbours. nodes x connected edge x,* R, called R,n -successor x x calledP, , n L(x, y), PR,n -predecessor y. R,n -successor Inv(R),n -predecessor x,called R,n -neighbour x.role R, node x FA , inequality membership degree n [0, 1]FA(x, , n) = {y | R ,n -neighbour x, x, conjugatesdene: RCR, , n}. Intuitively, set contains R-neighbours x conjugate giventriple.node x blocked root node either directly indirectly blocked.node x directly blocked none ancestors blocked, ancestors x ,that:1. root node,2. x successor x successor ,305fiStoilos, Stamou, Pan, Tzouvaras & Horrocks3. L(x) = L(y) L(x ) = L(y ) and,4. L(x , x) = L(y , y).case say blocks x. node indirectly blocked one ancestorsblocked, successor node x L(x, y) = .node x, L(x) said contain clash contains fKD -SI clash,contains,triple pR, , n x p+1 Ri ,ni -neighbours y0 , . . . , yp , x, yi conjugatesR, , 1 n yi = yj , ni , n [0, 1], 0 < j p,triple pR, , n x p Ri ,ni -neighbours y0 , . . . , yp1 , x, yi conjugatesR, , n yi = yj , ni , n [0, 1], 0 < j p 1.Denition 6.7 (fKD -SHIN Tableaux Algorithm) initialisation forest (FA )fKD -SHIN ABox similar initialisation forest fKD -SI ABoxA, dierence, equalities inequalities need considered. precisely,....xaj ai =aj relation = empty.also initialise relation = xai =latter used keep track nodes merged due application rulenumber restrictions. Finally, algorithm expands R adding axioms Inv(R) Inv(S)R R. FA expanded repeatedly applying completion rulesTables 4 6. Note Table 6 abuse syntax use notation Inv(L(x, y))indicate set triples obtained L(x, y) applying function Inv role Rtriple R, , n L(x, y).Example 6.8 Now, let us see examples new expansion rules.(+ ): Let S.C, >, 0.6 L(x), Inv(P ), , 0.7 L(y, x) Trans(R) P* S, R,0.7 -neighbour x, sinceR S. Then, role R, RInv(R),0.7 -predecessor x, x, conjugates Inv(R), <, 0.4, R.C, >, 0.6 L(y). Hence, R.C, >, 0.6 added L(y).( ): Let 2S, , 0.7 L(x), S, >, 0.7 L(x, y1 ), S, >, 0.8 L(x, y2 )* S. Hence, x 3 n -neighbours conjugatedP, , 0.4 L(x, y3 ) PS, , 1 0.7 S, , 0.3 none ancestor x. Hence nondeterministically merge two them. replace triple S, >, 0.7 L(x, y1 )S, >, 0.2 rule applicable. although y1 n neighbour x, x, y1 conjugate anymore S, , 0.3. Intuitively,means connection x y1 weak thus contradictat-most restriction x.obvious algorithm used order perform reasoning weakerlanguage fKD -SHIF (fKD -SHI plus functional number restrictions Horrocks & Sattler,1999. SHIF obtained SHIN allowing cardinalities 0 1 at-mostat-least restriction. worth noting that, without counting datatypes, SHIFlogical underpinning OWL Lite ontology language (Horrocks et al., 2003).306fiReasoning Expressive Fuzzy Description LogicsRule(+ )1.2.3.4.DescriptionS.C, , n L(x), x indirectly blocked,* S,R, Trans(R), Rx R ,n -neighbour with, R.C, , n L(y),x, conjugates R, , 1 nL(y) L(y) {R.C, , n},(+ )1.2.3.4.S.C, , n L(x), x indirectly blocked* S,R, Trans(R), Rx R,n -neighbour with, R.C, , n L(y),x, conjugates R, , nL(y) L(y) {R.C, , n},( )1.2.pR, , n L(x), x blocked,p R,n -neighbours y1 , . . . , yp x yi = yj 1 < j pcreate p new nodes y1 , . . . , yp , L(x, yi ) = {R, , n} yi = yj 1 < j p( )1.pR, , n L(x), x blocked,apply ( )-rule triple (p + 1)R, , 1 n( )1.2.3.pR, , n L(x), x indirectly blocked,.FA(x, , 1 n) > p, two y, z, = zRCneither root node ancestor z1. L(z) L(z) L(y)2. z ancestor xL(z, x) L(z, x) Inv(L(x, y))elseL(x, z) L(x, z) L(x, y)..3. L(x, y) set u = z u u =( )1.pR, , n L(x), x indirectly blocked,apply ( )-rule triple (p 1)R, , 1 n(r )1.2.pR, , n L(x),.FA(x, , 1 n) > p, two y, z, root nodes, = zRC1. L(z) L(z) L(y)2. edges y, w:i. edge z, w exist, create L(z, w) =ii. L(z, w) L(z, w) L(y, w)3. edges w, y:i. edge w, z exist, create L(w, z) =ii. L(w, z) L(w, z) L(w, y)4. Set L(y) = remove edges to/from...5. Set u =z u u = set = z(r )1.pR, , n L(x),apply (r )-rule triple (p 1)R, , 1 nTable 6: Additional tableaux rules fKD -SHIN6.2 Decidability fKD -SHINproof termination, soundness completeness fKD -SHIN slightly involved fKD -SI. mainly due requirement apply unravellingprocess constructed nite completion forest.Lemma 6.9 (Termination) Let fKD -SHIN ABox R RBox.tableaux algorithm terminates started R.307fiStoilos, Stamou, Pan, Tzouvaras & HorrocksProof: Let = |sub(A)|, k = |RA |, pmax = max{p | pR sub(A)} l numberdierent membership degrees appearing A. termination algorithmconsequence properties ensure termination case crisp SHINlanguage (Horrocks et al., 2000). brief following observations. Firstly,rules remove nodes concepts node labels rules , , rr , either expand set , means nodesblocked remain blocked forever. Secondly, expansion rules (,dual ones negative inequalities) applied nodereasons SHIN case (Horrocks et al., 2000). Since sub(A) containsconcepts R.C R.C, out-degree tree bounded 2lmpmax . Finally,nite number possible labellings pair nodes edge, since conceptstaken sub(A) number membership degrees nite. Thus,28mlk possible labellings pair nodes edge. Hence, path p lengthleast 28mlk , pair-wise blocking condition implies 2 nodes x, pdirectly blocks x.Lemma 6.10 (Soundness) expansion rules applied fKD -SHIN ABoxRBox R, yield complete clash-free completion forest,fuzzy tableau w.r.t. R.Proof: Let FA complete clash-free completion forest constructed tableauxalgorithm A. Since SHIN language nite model property (Horrocks & Sattler, 1999) unravel possibly blocked tree order obtaininnite tableau. constructions fuzzy tableau works follows. individualcorresponds path FA . Moving blocked nodes blocking onesdene innite paths. precisely, path sequence pairs nodes FAform p = [ xx0 , . . . , xxn ]. path dene Tail(p) := xn Tail (p) := x0 .n0], denote path [ xx0 , . . . , xxn , xxn+1]. set Paths(FA ) dened inductively[p | xxn+1nn+10n+1follows:xroot nodes xai FA , [ xaai ] Paths(FA ),path p Paths(FA ) node z FA :z successor Tail(p) z neither blocked root node,[p | zz ] Paths(FA ),node FA , successor Tail(p) z blocks y, [p | zy ]Paths(FA )Please node since root nodes never blocked, blocking nodesplace occur path rst place. Moreover, p Paths(FA ),Tail(p) blocked; Tail(p) = Tail (p) Tail (p) blocked last L(Tail(p)) =L(Tail (p)).Membership degrees dened exactly case fKD -SI. Then, fuzzy tableaudened case fKD -SI following dierences:308fiReasoning Expressive Fuzzy Description LogicsE(R, p, [p| xx ])E(R, [q| xx ], q)E(R, [ xx ], [ yy ])====V(ai )=Paths(FA ),glb[R, , n], R, , n L(Tail(p), x )glb[Inv(R), , n], Inv(R), , n L(Tail(q), x )glb[R , , n], x, root nodes R-neighbour x,xai[ ] xai root node FA L(xai ) =xaixa[ xaj ] L(xaj ) = xaj root node,j.L(xaj ) = xai = xajshown fuzzy tableau w.r.t. R:1. Properties 1-6 Property 13 Denition 5.1 satised due reasonsproof lemma 5.9.2. property 7, let p, q L(p, R.C) = n1 n E(R, p, q) 1 n,i.e. E(R, p, q) > 1 n. denition implies either R.C, , n1L(Tail(p)) R.C, >, n L(Tail(p)) n1 = n + . q = [p| xx ], xR-successor Tail(p) and, since glb create unnecessary conjugationsR, , r L(Tail(p), x ) conjugates R, , 1 n. Hence, duecompleteness FA either C, , n1 L(x ) C, >, n L(x ).denition Paths(FA ) L(x ) = L(x) = L(q). p = [q| xx ], xInv(R)-successor Tail(q) again, denition glb implies Inv(R), , rL(Tail(q), x ) conjugates Inv(R), , 1 n. Thus, due completeness FA ,either C, , n1 L(Tail(q)) = L(q) C, >, n L(Tail(q)) = L(q). p = [ xx ]q = [ yy ] two root nodes x, R-neighbour x, since -ruleapply wither C, , n1 L(y) = L(q) C, >, n L(y) = L(q).Similar proof holds L(p, R.C) > n property 8, denition 5.1modied properties 11 12 denition 6.4.3. property 9 Denition 5.1, assume L(p, R.C) = n1 n let Tail(p) = x.denition implies either R.C, , n1 L(x) R.C, >, n L(x),n1 = n + . show q E(R, p, q)n1 n L(q, C) n1 n. Since -rule applicableFA either C, , n1 L(y) C, >, n L(y). two possibilities:(a) successor x, either root node not. caseroot node x, since predecessor y, p = [ xx ] q = [ yy ] S.case root node blocked, q = [p| yy ] S; blockedz then, q = [p| yz ] S.(b) x Inv(R)-successor y. Since x successor distinguish casesx root node not. x root y, hence q = [ yy ] S.x root node either p = [q| xx ], Tail(q) = y, p = [q| xx ],Tail(q) = u = y, x blocks x u predecessor x . denitionpair-wise blocking L(y) = L(u) L(y, x) = L(u, x ).cases, E(R, p, q) n1 n, L(q, C) n1 n. Similar proof appliesL(p, R.C) > n property 10.309fiStoilos, Stamou, Pan, Tzouvaras & Horrocks4. Property 16 denition 6.4 satised due denition R-successor takesaccount role hierarchy.5. Property 17 assume L(p, mR) = n1 n. denition implieseither mR, , n1 L(x) mR, >, n L(x), n1 = n + .means individuals y1 , . . . , ym FA yi R,n R>,n -neighbour x. show yi s, pathqi , E(R, p, qi ) n1 , qi = qj 1 < j m. proofsimilar one given Horrocks et al. (2000). based factcase z blocks several yi s, construction paths distinguishesyi seting qi = [p| yzi ], thus ensuring existence dierent paths. Thus, yi dierent path qi E(R, p, qi ) n1 n,E(R, p, qi ) n + n RT (p, , n) m. Similarly L(p, mR) > nproperty 18.6. Property 19 denition 6.4 suppose exists p L(p, mR) =(p, , 1 n) > m. show implies RFA (Tail(p),n1 n RC, 1 n) > m, completion-forest, thus contradicting either clash-freenesscompleteness FA . precisely, one show constructioncreate conjugated paths exist FA .case node construction creates two distinct paths formqi = [p| yyi ]. shown Horrocks et al. (2000), proof relies factfunction Tail injective paths , i.e. q1 q2 , Tail (q1 ) = = Tail (q2 )implies q1 = q2 . Hence, paths cannot distinct. Similar observations holdL(p, mS) > n property 20.7. Properties 14 15 Denition 5.1 satised cause initializationcompletion-forest fact algorithm never blocks root nodes. Furthermore, root node xai whose label edges removed r -rule,another root node xaj xai = xaj {C, , n|(ai : C) n A} L(xaj ).8. Property 21 Denition 6.4 satised r -rule identify tworoot nodes xai , xaj xai = xaj holds.Lemma 6.11 (Completeness) Let fKD -SHIN fuzzy ABox R RBox.fuzzy tableau w.r.t. R, expansion rules applied Rway tableaux algorithm yields complete clash-free completion-forest.Proof: proof quite similar proof lemma 5.10. new algorithmnew non-deterministic rules, existence fuzzy tableau w.r.t.R help us steer application non-deterministic rules. following tableshow modied rule . rest non-deterministic rules guidedmodifying similar way.310fiReasoning Expressive Fuzzy Description Logics( )1.3.pR, , n L(x), x indirectly blocked,.FA(x, , 1 n) > p, two y, z, =zRCneither root node ancestor z (y) = (z)1. L(z) L(z) L(y)2. z ancestor xL(z, x) L(z, x) Inv(L(x, y))elseL(x, z) L(x, z) L(x, y)..3. L(x, y) set u =z u u =Table 7: -ruleTheorem 6.12 tableaux algorithm decision procedure consistency problemfKD -SHIN ABoxes satisability subsumption fKD -SHIN -conceptsrespect simple terminologies.conclude section investigating complexity proposed algorithm.Lemma 6.13 fKD -SHIN ABox role hierarchy R, sub(A, R) = O(|A||R|).Proof: proof quite similar one presented Tobies (2001). Since sub(A, R)contains concepts C (a : C)n closed sub-concepts C,contains O(|A|) concepts. Additionally, add concept R.C R.C* close sub(A, R)sub(A, R) S.R sub(A, R) S.R sub(A, R) Rsub-concepts . may yield two concept every conceptsub(A, R) role R. Thus, sub(A, R) = O(2|A| |R|).Lemma 6.14 fKD -SHIN -algorithm runs 2-Nexptime.Proof: Let fKD -SHIN ABox R RBox. Let = sub(A), k = |RA |,pmax maximum number p occurs number restriction l numberdierent membership degrees appearing A. Following Tobies (2001) set n = |A| + |R|,due lemma 6.13 holds = O(2|A| |R|) = O(n2 ), k = O(|A| + |R|),pmax = O(2|A| ) = O(2n ) l = O(|A|) = O(n). proof lemma 6.9 shownpaths completion-forest become longer 28mlk out-degreebounded 2lmpmax . Hence, fKD -SHIN algorithm construct forest8mlk(2lmpmax )28n2 nn= O((2n n2 2n )28n4) = O(2n2n5) = O(22 )nodes.Hence, fKD -SHIN algorithm theoretical complexity SHIN algorithm (Tobies, 2001).Concluding presentation issue reasoning expressive fuzzy DLscomment handle GCIs fKD -SI fKD -SHIN languages. notedHorrocks Sattler (1999), SHIN expressive enough internalize GCIssingle concept, hence reducing reasoning GCIs concept satisability. idea311fiStoilos, Stamou, Pan, Tzouvaras & Horrocksbehind internalization semantic restrictions imposed axioms formC encoded within concept form C D. remarkedStoilos et al. (2006) reduction concept inclusions hold fKD -DLs, sincesemantics axiom C dierent concept C D. Hence,internalization method proposed Horrocks Sattler (1999) SHIN languagecannot applied fKD -SHIN language.Stoilos et al. (2006) Li et al. (2006a) propose techniques handleGCIs fKD -DLs. Stoilos et al. (2006) use DL language fKD -ALC order presenttechnique, Li et al. (2006a) use language fKD -SHI. proceduresapplied cases fKD -SI fKD -SHIN , since independentunderlying DL formalism. Roughly speaking techniques performed three steps.rst step ABox normalized, replacing assertion form (a : C) > n(a : C) < n assertions (a : C) n + (a : C) n , respectively,small number [0, 1]. Obviously, normalized ABox assertionsinequalities present. second step set relative membership degreesconstructed: X = {0, 0.5, 1} {n, 1 n | n}, obviously {, }. Finally,tableaux expansion rule employed transfer semantic restrictions imposedGCI C fuzzy assertions ABox. precisely, C ,node x FA degree n X , algorithm adds either C, , n D, , nL(x). remark rule proposed Li et al. (2006a) slightly dierent.noted Stoilos et al. (2006), tableaux algorithms need slightly changedorder handle GCIs. First, due normalization step, degrees takeninterval [, 1 + ], thus clash denitions , >, n, <, n removed sinceassertion > < exist anymore clashes C, <, 0 C, >, 1 replacedC, , C, , 1 + , respectively. termination algorithm aectedsince set membership degrees nite (taken set X ), practicalcomplexity increases dramatically since non-deterministic choice axiomC degree n X . proof soundness aected muchshowed Stoilos et al. (2006) glb function replaced simple max, duelack assertions inequalities > <, non-deterministic rule handlingsubsumptions also modied guided, order provide us proofcompleteness.Example 6.15 Let knowledge base = { 1R C}, {(a, b : R) 0.6, (a : C) <0.6}. Intuitively, concept axioms states domain role R concept C.5Obviously, knowledge base unsatisable since concept axiom suggests xI, supbI min1i=1 (RI (xI , bIi )) = RI (xI , cI ) C (xI ), arbitrary cI ,1ABox assertions state exists aI bI RI (aI , bI ) 0.6 >C (aI ). concept inclusion axioms GCI, hence use techniqueGCIs.First, apply normalization step original ABox, obtaining normalizedone: {(a, b : R) 0.6, (a : C) 0.6 }. Secondly, collect set relativemembership degrees: X = {0, 0.5, 1} {0.4, 0.4 + , 0.6 , 0.6}.5. domain axiom also stated R. C, use form order showalgorithm behaves number restrictions.312fiReasoning Expressive Fuzzy Description LogicsThen, algorithm initializes completion-forest contain following nodesrespective triples:(1)(2)R, , 0.6 L(xa , xb )C, , 0.6 L(xa )algorithm expands completion forest using rules Tables 4 6additional rule presented Stoilos et al. (2006). rule applied axiom1R C adds either 1R, , n C, , n L(xa ), n X . Hence,point algorithm chooses 0.6 X adds either 1R, , 0.6, C, , 0.6.former case 1R, , 0.6 L(xa ) xa 1 R,0.6 -neighbour xb , xa , xbconjugated R, , 0.6 , latter case {C, , 0.6 , C, , 0.6} L(xa ),hence L(xa ) contains pair conjugated triples thus clash. concludepossible expansions result clash, thus knowledge base unsatisable.7. Related Workmany eorts past extend description logics fuzzy set theory(Yen, 1991; Tresp & Molitor, 1998; Straccia, 2001; Holldobler et al., 2002; Sanchez & Tettamanzi, 2006; Straccia, 2005b; Hajek, 2005; Li, Xu, Lu, & Kang, 2006b). rst eortpresented Yen (1991). extension, explicit membership functions domainused well membership manipulators, like moreOrLess, orderalter membership functions dene new concepts already dened ones. laterapproach presented Tresp Molitor (1998), membership manipulators alsoappear. Regarding reasoning algorithms Yen described structural subsumption algorithmrather small DL language Tresp Molitor tableaux calculus ALC F(ALC extended fuzzy set theory membership manipulator constructor).application tableaux rules creates set equations inequations latersolved optimization method. Moreover, determining subsumption entailment relation two concepts, respect (KB), assertions KBconsidered crisp form (i.e. belongs C degree 1). applicationreasoning algorithm solution equations minimum value solution settaken degree KB entails crisp assertion concept subsumedanother.fuzzy extension ALC language also considered Straccia (2001, 1998).Reasoning algorithms problem crisp entailment subsumption provided,based tableaux calculus. algorithm proved PSPACE-complete.Moreover, complete reasoning algorithms fuzzy ALC provided Holldobler et al.(2002), membership manipulators (linguistic hedges) also used primitiveconcepts. approach later extended Holldobler, Nga, Khang (2005) allowlinguistic hedges also complex concepts. languages presented called ALC F HALC F LH (ALC plus linguistic hedges linear linguistic hedges, respectively).approaches also min-max norms Kleene-Dienes implication usedperform fuzzy set theoretic operations.313fiStoilos, Stamou, Pan, Tzouvaras & HorrocksApproaches towards expressive DLs, presented Sanchez Tettamanzi(2004), Sanchez Tettamanzi (2006), Straccia (2005b), Straccia (2005a) Stoiloset al. (2005c). language considered Sanchez Tettamanzi (2004) ALCQ (ALCplus qualied number restrictions, Tobies, 2001). authors also include fuzzy quantiersnovel approach fuzzy DLs, norm operations onesused here. Subsequently, Sanchez Tettamanzi (2006) propose procedure calculatesatisability interval fuzzy concept. Due presence fuzzy quantiersclear inference problems, like entailment subsumption solved. Straccia(2005b) considered semantics fuzzy SHOIN (D+ ), DL counterpartOWL DL language. approach generalized norm operations usedsemantics, reasoning algorithms provided well investigationproperties value existential restrictions, transitive relations role hierarchiesparticipate concepts. Furthermore, semantics number restrictionsanalyzed. approach Straccia used Stoilos et al. (2005c), order provideabstract syntax semantics concept role descriptions axioms fuzzyOWL language. Additionally, Stoilos et al. (2005c) present method translate fuzzyOWL ontology fuzzy SHOIN knowledge base, thus reasoning fuzzy OWLreduced reasoning expressive fuzzy DLs. last language considered Straccia(2005a) ALC(D) (ALC plus concrete domains), additionally reasoning algorithmbased optimization technique presented. norm operations used onesused current paper, plus Lukasiewicz t-norm, t(a, b) = max(0, + b 1),t-conorm, u(a, b) = min(1, + b) fuzzy implication J (a, b) = min(1, 1 + b).approach towards fuzzy DLs concrete domains also presented Liu, Tian,(1994) modelling selection research development projects.previous approaches reasoning respect simple acyclic TBoxesconsidered. Stoilos et al. (2006) propose method perform reasoning w.r.t. generaland/or cyclic TBoxes language fKD -ALC. method applies preprocessing stepABox, called normalization extends classical fKD -ALC algorithm(Straccia, 2001) additional rule, order deal general cyclic axioms.Moreover, Li et al. (2006a) extend fuzzy tableau fKD -SHI proposed Stoilos et al.(2005a) additional rule also handle general cyclic TBoxes languagefKD -SHI. Interestingly, technique used Stoilos et al. (2006) dierentpresented Li et al. (2006a).also worth noting works Bonatti Tettamanzi (2005), complexityfuzzy DL languages investigated. Furthermore, Hajek (2005) investigates propertiesfuzzy ALC language, arbitrary continuous norm operations used providesinteresting results. precisely, Hajek shows problems concept satisabilitysubsumption decidable Lukasiewicz fuzzy ALC (fL -ALC), productfuzzy ALC (fP -ALC) Godel fuzzy ALC (fG -ALC) witnessed satisability subsumption decidable. unrestricted models fP -ALC fG -ALC lack nitemodel property (Hajek, 2005). accomplished reducing problemsproblem propositional satisability fuzzy propositional logic. results extended fuzzy DLs truth constants, i.e. ABox consistency, Hajek(2006). Moreover, Straccia (2004) present technique fKD -ALCH knowledgebase reduced crisp ALCH knowledge base. Hence, reasoning fuzzy KB314fiReasoning Expressive Fuzzy Description Logicsperformed using existing optimized DL systems. Then, Bobillo et al. (2006)extended technique able reduce fKD -SHOIN KB crisp SHOIN KB.last, Li, Xu, Lu, Kang, Wang (2005) Li et al. (2006b), also use ideareduction order annotate concepts roles crisp languages ALCNALCQ, respectively degrees denoted sub-scripts syntax concepts rolesprovide reasoning languages fKD -ALCN fKD -ALCQ.previous approaches, reasoning algorithms rather inexpressive fuzzy DLs, i.e.fuzzy-ALC extended concept modiers concrete domains number restrictionsqualied number restrictions general TBoxes presented. far knowrst presentation reasoning algorithm complex fuzzy DL languages.order achieve goal provided investigation semanticsextended language fuzzy transitive relations role hierarchies consideredvalue existential restrictions number restrictions constructor. aiminvestigation discover properties classical SI SHIN languages,like propagation value restrictions counting R-neighbours also applyfuzzy case. found apart value restrictions also existential restrictionspropagated. Additionally, shown membership degreeconcepts new nodes source nodes. Moreover,seen role hierarchies smoothly integrated classical case. Additionally,analysis semantics number restrictions shown despite complexsemantics might appear, regarding reasoning also eciently handled,classical case. Furthermore, investigated applicability blockingstrategies, like dynamic blocking pair-wise blocking, used crisp SISHIN language ensure termination proposed algorithms. seenproperties norm operations used ensure blocking conditions alsoapplied. Based investigations, able provide tableaux reasoningalgorithm, decide key inference problems expressive fuzzy DLs,proved soundness, completeness termination.8. Conclusions Future WorkMaking applications capable coping vagueness imprecision resultcreation systems applications provide us high quality resultsanswers complex user dened tasks. direction extend fuzzy settheory underlying logical formalisms use order represent knowledgeperform reasoning tasks. DL logical formalism gained lot attention lastdecade, cause decidability, powerful reasoning tools implementedwell-dened model-theoretic semantics.Towards extending DLs fuzzy set theory presented two expressivefuzzy DLs, fKD -SI fKD -SHIN . investigated properties semanticsresult adding fuzziness expressive fuzzy DLs, i.e. fuzzy DLs allowtransitive inverse roles, role hierarchies number restrictions providedsound, complete terminating reasoning algorithms formalisms. Eventhough handling fuzziness expressive languages seems quite dicult reasoningpreviously known, show fKD -SI fKD -SHIN min, max norms315fiStoilos, Stamou, Pan, Tzouvaras & Horrocksstill decidable. shown techniques used classical case alsoapplied extended frameworks, happen closely investigatingproperties languages proving techniques also worknew setting. current paper addressed nominals (O) (Horrocks & Sattler,2005). Note fuzzy DL literature, proposals crisp nominals (Stoiloset al., 2005c) fuzzy nominals (Bobillo et al., 2006). Thus, nominal constructoryet mature notion fuzzy DLs research needed order nd appropriatesemantics them, considering also issue application point view.far future directions concerned, include extension algorithm fKD -SHIN , order provide reasoning support fuzzy DL fKD -SHOIQ.SHOIQ extends SHIN qualied number restrictions (Tobies, 2001),important real life applications (Rector & Horrocks, 1997), nominals. Thus,also intend compare properties dierent proposals nominals fuzzyDLs. Again, although expect similar notions classical SHOIQ languageapplied fKD -SHOIQ, need investigate new setting provework. Furthermore, additional research eort focused investigationreasoning problem f-SI f-SHIN languages, extended normoperations. Regarding f-SHIN , might dicult problem since countingnumber restrictions might possible anymore.Acknowledgmentswork supported FP6 Network Excellence EU project Knowledge Web (IST2004-507482). Giorgos Stoilos, Giorgos Stamou Vassilis Tzouvaras also partiallyfunded European Commission FP6 Integrated Project X-Media (FP6-026978).ReferencesAlejandro, J., Belle, T., & Smith, J. (2003). Modal keywords, ontologies reasoningvideo understanding. Proceedings International Conference ImageVideo Retrieval.Athanasiadis, T., Mylonas, P., Avrithis, Y., & Kollias, S. (2007). Semantic image segmentation object labeling. IEEE Transactions Circuits Systems VideoTechnology, 17 (3), 298312.Baader, F. (1990). Augmenting Concept Languages Transitive Closure Roles:Alternative Terminological Cycles. Research report RR-90-13. abridged versionappeaered Proc. IJCAI-91,pp.446-451.Baader, F., McGuinness, D., Nardi, D., & Patel-Schneider, P. (2002a). DescriptionLogic Handbook: Theory, implementation applications. Cambridge UniversityPress.Baader, F., Horrocks, I., & Sattler, U. (2002b). Description Logics Semantic Web.KI Kunstliche Intelligenz, 16 (4), 5759.316fiReasoning Expressive Fuzzy Description LogicsBechhofer, S., van Harmelen, F., Hendler, J., Horrocks, I., McGuinness, D. L., PatelSchneider, P. F., & eds., L. A. S. (2004). OWL web ontology language reference.Tech. rep..Benitez, A. B., Smith, J. R., & Chang, S. (2000). MediaNet: multimedia information network knowledge representation. Proc. SPIE Vol. 4210, p. 1-12, Internet Multimedia Management Systems, John R. Smith; Chinh Le; Sethuraman Panchanathan;C.-C. J. Kuo; Eds., pp. 112.Berners-Lee, T., Hendler, J., & Lassila, O. (2001). semantic web. Scientic American.Bobillo, F., Delgado, M., & Gomez-Romero, J. (2006). crisp representation fuzzyshoin fuzzy nominals general concept inclusions. Proc. 2nd International Workshop Uncertainty Reasoning Semantic Web (URSW 06),Athens, Georgia.Bonatti, P., & Tettamanzi, A. (2005). complexity results fuzzy description logics.V. Di Gesu, F. Masulli, A. P. (Ed.), WILF 2003 International Workshop FuzzyLogic Applications, LNCS 2955, Berlin. Springer Verlag.Calvanese, D., De Giacomo, G., Lenzerini, M., Nardi, D., & Rosati, R. (1998). Descriptionlogic framework information integration. Proc. 6th Int. Conf.Principles Knowledge Representation Reasoning (KR98), pp. 213.Chen, H., Fellah, S., & Bishr, Y. (2005). Rules geospatial semantic web applications.W3C Workshop Rule Languages Interoperability.Ding, Z., & Peng, Y. (2004). Probabilistic Extension Ontology Language OWL.Proceedings 37th Hawaii International Conference System Sciences (HICSS37)., p. 10, Big Island, Hawaii.Dubois, D., & Prade, H. (2001). Possibility theory, probability theory many-valuedlogics: clarication. Ann. Math. Artif. Intell., 32 (1-4), 3566.Fagin, R. (1998). Fuzzy queries multimedia database systems. Proc. Seventeenth ACMSymp. Principles Database Systems, pp. 110.Giugno, R., & Lukasiewicz, T. (2002). P-SHOQ(D): probabilistic extension shoq(d)probabilistic ontologies semantic web. JELIA 02: ProceedingsEuropean Conference Logics Articial Intelligence, pp. 8697, London, UK.Springer-Verlag.Hajek, P. (1998). Metamathematics fuzzy logic. Kluwer.Hajek, P. (2005). Making fuzzy description logic general. Fuzzy Sets Systems,154 (1), 115.Hajek, P. (2006). Computational complexity t-norm based propositional fuzzy logicsrational truth constants. Fuzzy Sets Systems, 157 (13), 677682.Holldobler, S., Khang, T. D., & Storr, H.-P. (2002). fuzzy description logic hedgesconcept modiers. Proceedings InTech/VJFuzzy2002, pp. 2534.Holldobler, S., Nga, N. H., & Khang, T. D. (2005). fuzzy description logic ALC F LH .International workshop Description Logics. CEUR.317fiStoilos, Stamou, Pan, Tzouvaras & HorrocksHollunder, B. (1994). alternative proof method possibilistic logic applicationterminological logics. Proceedings 10th Annual Conference Uncertainty Articial Intelligence (UAI-94), pp. 327335, San Francisco, CA. MorganKaufmann Publishers.Hollunder, B., Nutt, W., & Schmidt-Schaus, M. (1990). Subsumption algorithms conceptdescription languages. European Conference Articial Intelligence, pp. 348353.Horrocks, I., Patel-Schneider, P. F., & van Harmelen, F. (2003). SHIQ RDFOWL: making web ontology language. Web Semantics, 1.Horrocks, I., & Sattler, U. (1999). description logic transitive inverse rolesrole hierarchies. Journal Logic Computation, 9, 385410.Horrocks, I., & Sattler, U. (2005). tableaux decision procedure SHOIQ. Proc.19th Int. Joint Conf. Articial Intelligence (IJCAI 05).Horrocks, I., Sattler, U., & Tobies, S. (1999). Practical reasoning expressive descriptionlogics. Proceedings 6th International Conference Logic ProgrammingAutomated Reasoning (LPAR99), No. 1705 LNAI, pp. 161180. SpringerVerlag.Horrocks, I., Sattler, U., & Tobies, S. (2000). Reasoning Individuals DescriptionLogic SHIQ . MacAllester, D. (Ed.), CADE-2000, No. 1831 LNAI, pp. 482496.Springer-Verlag.Kandel, A. (1982). Fuzzy Techniques Pattern Recognition. Wiley.Klement, E. P., Mesiar, R., & Pap, E. (2004). Triangular norms. position paper I: basicanalytical algebraic properties. Fuzzy Sets Systems, 143, 526.Klir, G. J., & Yuan, B. (1995). Fuzzy Sets Fuzzy Logic: Theory Applications.Prentice-Hall.Koller, D., Levy, A., & Pfeer, A. (1997). P-CLASSIC: tractable probabilistic Description Logic. Proceedings 14th National Conference Articial Intelligence(AAAI-97)., pp. 390397.Krishnapuram, R., & Keller, J. (1992). Fuzzy set theoretic approach computer vision:overview. IEEE International Conference Fuzzy Systems, pp. 135142.Larsen, H., & Yager, R. (1993). use fuzzy relational thesauri classicatory problemsolving information restrieval exprert systems. IEEE Trans. System, Man,Cybernetics, 23 (1), 3141.Li, Y., Xu, B., Lu, J., & Kang, D. (2006a). Discrete tableau algorithms FSHI.Proceedings International Workshop Description Logics (DL 2006), LakeDistrict, UK.Li, Y., Xu, B., Lu, J., & Kang, D. (2006b). Reasoning technique extended fuzzy ALCQ. ICCSA (2), pp. 11791188.Li, Y., Xu, B., Lu, J., Kang, D., & Wang, P. (2005). Extended fuzzy description logic ALCN .Proceedings 9th International Conference Knowledge Based IntelligentInformation EngineeringSystems (KES-05), pp. 896902.318fiReasoning Expressive Fuzzy Description LogicsLiu, O., Tian, Q., & Ma, J. (1994). fuzzy description logic approach model management r&d project selection. Proceedings 8th Pacic Asian ConferenceInformation Systems (PACIS-04).McGuiness, D. (2003). Conguration. Baader, F., Calvanese, D., McGuinness, D.,Nardi, D., & Patel-Schneider, P. F. (Eds.), Description Logic Handbook: Theory,Implementation, Applications, pp. 388405. Cambridge University Press.Meghini, C., Sebastiani, F., & Straccia, U. (2001). model multimedia informationretrieval. Journal ACM, 48 (5), 909970.Mostert, P., & Shields, A. (1957). structure semigroups compact manifoldboundary. Annals Mathematics, 65 (1), 117143.Navara, M. (2000). Satisability fuzzy logic. Neural Network World, 10 (5), 845858.Nebel, B. (1990). Terminological reasoning inherently intractable. Journal ArticialIntelligence, 43, 235249.Oguntade, O., & Beaumont, P. (1982). Ophthalmological prognosis via fuzzy subsets. FuzzySets Systems, 7 (2), 123179.Pan, J. Z. (2004). Description Logics: Reasoning Support Semantic Web. Ph.D. thesis, School Computer Science, University Manchester, Oxford Rd, Manchester M13 9PL, UK.Rector, A. L., & Horrocks, I. (1997). Experience building large, re-usable medical ontologyusing description logic transitivity concept inclusions. ProceedingsWorkshop Ontological Engineering, AAAI Spring Symposium, Stanford CA., pp.100107. Hanley Belfus, Inc., Philadelphia, PA.Sanchez, D., & Tettamanzi, A. (2004). Generalizing quantication fuzzy description logic.Proceedings 8th Fuzzy Days Dortmund.Sanchez, D., & Tettamanzi, A. A. (2006). Fuzzy quantication fuzzy description logics.Sanchez, E. (Ed.), Capturing Intelligence: Fuzzy Logic Semantic Web.Elsevier.Sattler, U. (1996). concept language extended dierent kinds transitive roles.KI 96: Proceedings 20th Annual German Conference Articial Intelligence,pp. 333345. Springer-Verlag.Stoilos, G., Stamou, G., Tzouvaras, V., Pan, J., & Horrocks, I. (2005a). fuzzy description logic f-SHIN . Proceedings International Workshop UncertaintyReasoning Semantic Web.Stoilos, G., Stamou, G., Tzouvaras, V., Pan, J., & Horrocks, I. (2005b). fuzzy descriptionlogic multimedia knowledge representation. Proc. International WorkshopMultimedia Semantic Web.Stoilos, G., Stamou, G., Tzouvaras, V., Pan, J., & Horrocks, I. (2005c). Fuzzy OWL:Uncertainty semantic web. Proc. International Workshop OWL:Experiences Directions.319fiStoilos, Stamou, Pan, Tzouvaras & HorrocksStoilos, G., Straccia, U., Stamou, G., & Pan, J. (2006). General concept inclusions fuzzydescription logics. Proceedings 17th International Conference ArticialIntelligence (ECAI 06), pp. 457461. IOS Press.Straccia, U. (2001). Reasoning within fuzzy description logics. Journal Articial Intelligence Research, 14, 137166.Straccia, U. (2005a). Description logics fuzzy concrete domains. 21st Conf.Uncertainty Articial Intelligence (UAI-05), Edinburgh.Straccia, U. (2005b). Towards fuzzy description logic semantic web. Proceedings2nd European Semantic Web Conference.Straccia, U. (1998). fuzzy description logic. AAAI 98/IAAI 98: Proceedingsfteenth national/tenth conference Articial intelligence/Innovative applicationsarticial intelligence, pp. 594599. American Association Articial Intelligence.Straccia, U. (2004). Transforming fuzzy description logics classical description logics.Proceedings 9th European Conference Logics Articial Intelligence(JELIA-04), No. 3229 Lecture Notes Computer Science, pp. 385399, Lisbon,Portugal. Springer Verlag.Sugeno, M. (1985). Industrial Applications Fuzzy Control. North-Holland.Tarski, A. (1956). Logic, Semantics, Metamathemetics: Papers 1923 1938. OxfordUniversity Press.Tobies, S. (2001). Complexity Results Practical Algorithms Logics Knowledge Representation. Ph.D. thesis, Rheinisch-Westfalischen Technischen Hochschule Aachen.URL http://lat.inf.tu-dresden.de/research/phd/Tobies-PhD-2001.pdf .Tresp, C., & Molitor, R. (1998). description logic vague knowledge. proc13th European Conf. Articial Intelligence (ECAI-98).Vardi, M. Y. (1997). modal logic robustly decidable?. DIMACS SeriesDiscrete Mathematics Theoretical Computer Science, pp. 149184.Yen, J. (1991). Generalising term subsumption languages fuzzy logic. Proc12th Int. Joint Conf Articial Intelligence (IJCAI-91), pp. 472477.Zadeh, L. A. (1965). Fuzzy sets. Information Control, 8, 338353.Zimmermann, H. (1987). Fuzzy Sets, Decision Making, Expert Systems. Kluwer, Boston.320fiJournal Artificial Intelligence Research 30 (2007) 133179Submitted 3/07; published 9/07Chain: Dynamic Double Auction Framework MatchingPatient AgentsJonathan Bredinbredin@acm.orgDept. Mathematics Computer Science, Colorado CollegeColorado Springs, CO 80903, USADavid C. ParkesQuang Duongparkes@eecs.harvard.eduqduong@fas.harvard.eduSchool Engineering Applied Sciences, Harvard UniversityCambridge, 02138, USAAbstractpaper present evaluate general framework design truthfulauctions matching agents dynamic, two-sided market. single commodity,resource task, bought sold multiple buyers sellers arrivedepart time. algorithm, Chain, provides first framework allowstruthful dynamic double auction (DA) constructed truthful, single-period (i.e.static) double-auction rule. pricing matching method Chain constructionunique amongst dynamic-auction rules adopt building block. examineexperimentally allocative efficiency Chain instantiated various single-periodrules, including canonical McAfee double-auction rule. baseline also considernon-truthful double auctions populated zero-intelligence plus-style learning agents.Chain-based auctions perform well comparison schemes, especially arrivalintensity falls agent valuations become volatile.1. IntroductionElectronic markets increasingly popular method facilitate increased efficiencysupply chain, firms using markets procure goods services. Two-sidedmarkets facilitate trade many buyers many sellers find applicationtrading diverse resources, including bandwidth, securities pollution rights. Recentyears also brought increased attention resource allocation context ondemand computing grid computing. Even within settings cooperative coordination,multiple robots, researchers turned auctions methods taskallocation joint exploration (Gerkey & Mataric, 2002; Lagoudakis et al., 2005; Lin &Zheng, 2005).paper consider dynamic two-sided market single commodity, instance unit resource (e.g. time computer, quantity memory chips)task perform (e.g. standard database query execute, location visit).agent, whether buyer seller, arrives dynamically needs matched within timeinterval. Cast task-allocation problem, seller perform task allocatedwithin time interval incurs cost assigned. buyer positive valuetask assigned (to seller) within time interval. arrival time, acceptable time interval, value (negative seller) trade private informationc2007AI Access Foundation. rights reserved.fiBredin, Parkes Duongagent. Agents self-interested choose misrepresentinformation market order obtain desirable price.matching problem combines elements online algorithms sequential decisionmaking considerations mechanism design. Unlike traditional sequential decisionmaking, protocol problem must provide incentives agents report truthfulinformation match-maker. Unlike traditional mechanism design, dynamicproblem agents arrive leave time. model problem dynamicdouble auction (DA) identical items. match-maker becomes auctioneer.seller brings task performed time window buyer bringscapability perform single task. double-auction setting also interestright protocol matching dynamic business-to-business exchange.Uncertainty future coupled two-sided nature market leadsinteresting mechanism design problem. example, consider scenarioauctioneer must decide (and whether) match seller reported cost $6end time interval present unmatched buyer, one reportedvalue $8 one reported value $9. auctioneer pair higher bidderseller? happens seller, willing sell $4, arrives auctioneeracts upon matching decision? matching algorithm designedagent benefit misstating earliest arrival, latest departure, valuetrade?Chain provides general framework allows truthful dynamic double auctionconstructed truthful, single-period (i.e. static) double-auction rule. auctionsconstructed Chain truthful, sense dominant strategy agent,whatever future auction dynamics bids agents, report truevalue trade (negative selling) true patience (maximal tolerance trade delay)immediately upon arrival market. also allow randomized mechanisms and,case, require strong truthfulness: DA truthful possible randomcoin flips mechanism. One DAs class auctions implied Chaindynamic generalization McAfees (1992) canonical truthful, no-deficit auctionsingle period. Thus, provide first examples truthful, dynamic DAs allowdynamic price competition buyers sellers.1main technical challenge presented dynamic DAs provide truthfulness without incurring budget deficit, handling uncertainty future trade opportunities.particular concern ensure agent indirectly affect priceeffect bid prices faced agents thus supply demandmarket. need preclude availability trades dependsprice faced agents. example, buyer required pay $4 DAtrade might like decrease price potentially matching seller receive $6$3 allow trade.Chain modular approach auction design, takes building block singleperiod matching rule provides method invoke rule multiple periodsalso providing truthfulness. characterize properties well-defined single1. closest work literature due Blum et al. (2006), present truthful, dynamic DAmodel matches bids asks based price sampled bid-independent distribution.compare performance schemes scheme Section 6.134fiChain: Online Double Auctionperiod matching rule must satisfy order Chain truthful. identifytechnical property strong no-trade, isolate agents fail tradecurrent period nevertheless survive eligible trade future period.auction designer defines strong no-trade predicate, addition providing welldefined single-period matching rule. Instances within class include constructedterms price-based matching rules competition-based matching rules.depend history adaptive, competition-based rules useactive bids asks determine prices current period, facilitating directcompetitive processes.proving Chain, combined well-defined matching rule validstrong no-trade predicate, truthful leverage recent price-based characterizationtruthful online mechanisms (Hajiaghayi et al., 2005). also show pricingmatching rules defined Chain unique amongst family mechanismsconstructed single-period matching rule building block. Throughout workassume constant limits every buyer sellers patience. motivate assumptionprovide simple environment truthful, no-deficit DA implementconstant fraction number efficient trades, constant.adopt allocative efficiency design objective, say auction protocolsmaximize expected total value sequence trades. also consider netefficiency, wherein net outflow payments marketmaker also accountedconsidering quality design. Experimental results explore allocative efficiencyChain instantiated various single-period matching rules range differentassumptions market volatility maximal patience. baseline considerefficiency standard (non-truthful) open outcry DA populated simple adaptivetrading agents modeled zero-intelligence plus (ZIP) agents (Cliff & Bruten, 1998;Preist & van Tol, 1998). also compare efficiency Chain truthfulonline DA due Blum et al. (2006), selects fixed trading price guaranteecompetitiveness adversarial model.within truthful mechanisms find adaptive, price-based instantiationsChain effective high arrival intensity low volatility. Even definingsingle, well-chosen price optimized market conditions reasonablyeffective promoting efficient trades low volatility environments. hand,medium low arrival intensity medium high volatility find Chainbased DAs allow dynamic price competition, McAfee-based rule,efficient. qualitative observations hold whether one interested allocative efficiency net efficiency, although adaptive, price-based methods betterperformance terms net efficiency. Blum et al. (2006) rule fairs poorlytests, perhaps unsurprising given optimized worst-case performanceadversarial setting. populated ZIP agents, find non-truthful DAsprovide good efficiency low volatility environments poor performancehigh volatility environments. good performance ZIP-based market occursagents learn bid approximately truthfully; i.e., market operates truthful,without incurring stringent cost (e.g., trading constraints) imposingtruthfulness explicitly. equilibrium analysis available truthful DAs;135fiBredin, Parkes Duongway knowing close ZIP agents playing equilibrium, noteZIP agents even consider performing time-based manipulations.1.1 OutlineSection 2 introduces dynamic DA model, including assumptions, presentsdesiderata online DAs price-based characterization design truthfuldynamic auctions. Section 3 defines Chain algorithm together building blockwell-defined, single-period matching rule strong no-trade predicate. Section 4gives number instantiations price-based competition-based matching rules,including general method define strong no-trade predicate given price-based instantiation. Section 5 proves truthfulness, no-deficit feasibility Chain auctionsalso establishes uniqueness amongst auctions constructed singleperiod matching-rule building block. importance assumption maximalagent patience established. Section 6 presents empirical analysis, including description simple adaptive agents use populate non-truthful open-outcry DAprovide benchmark. Section 7 gives related work. Section 8 concludediscussion merits truthfulness markets present possible extensions.2. Preliminaries: Basic DefinitionsConsider dynamic auction model discrete, possibly infinite, time periods ={1, 2, . . .}, indexed t. double auction (DA) provides market single commodity.Agents either buyers sellers interested trading single unit commodity.agents type, = (ai , di , wi ) , set possible types agent i, definesarrival ai , departure di , value wi R trade. agent buyer, wi > 0.agent seller, wi 0. assume maximal patience K, di ai + Kagents.arrival time models first time agent learns marketlearns value trade. Thus, information type availableperiod ai (not even agent i) agent cannot engage trade period ai .departure time, di , models final period buyer positive value trade,final period seller willing engage trade. model risk-neutralagents quasi-linear utility, wi p trade occurs [ai , di ] payment pcollected (with p < 0 agent seller). Agents rational self-interested,act maximize expected utility. assumption, sellers utility paymentsreceived true departure period.Throughout paper adopt bid refer, generically, claim agenteither buyer seller makes DA type. addition, needspecific distinction claims made buyers claims made sellersrefer bid buyer ask seller.2.1 ExampleConsider following naive generalization (static) trade-reduction DA (Lavi & Nisan,2005; McAfee, 1992) dynamic environment. bid agent claim136fiChain: Online Double Auctiontype = (ai , di , wi ), necessarily made period = ai . Bids active [ai , di ]trade occurred.period t, use trade-reduction DA determine (if any)active bids trade price. trades occur immediately. trade-reductionDA (tr-DA) works follows: Let B denote set bids denote set asks.Insert dummy bid value + B dummy ask value 0 S.|B| 2 |S| 2 sort B order decreasing value. Let wb0 wb1 . . .ws0 ws1 . . . denote bid ask values (b0 , s0 ) denoting dummy bid-askpair. Let 0 index last pair bids asks clear efficient trade,wbm + wsm 0 wbm+1 + wsm+1 < 0. 2 bids {b1 , . . . , bm1 } asks{s1 , . . . , sm1 } trade payment wbm collected winning buyer paymentwsm made winning seller.First consider static tr-DA following bids asks:Bwi wib1 15 s1 -1b2 10 s2 -1b3 4 s3 -2b4 3 s4 -2s5 -5line indicates bids (14) asks (14) could matched efficient trade.rules tr-DA, bids (13) asks (13) trade, payments $3 collectedwinning buyers payment $2 made winning sellers. auctioneer earns profit$3. asterisk notation indicates bids asks trade. tr-DA truthful,sense dominant-strategy every agent report true value whateverreports agents. intuition, consider buy-side. payment madewinners independent bid price losing bidder could win bidding$4, point payment would $4 true value.consider dynamic variation buyer types {(1, 2, 15), (1, 2, 10), (1, 2, 4), (2, 2, 3)}seller types {(1, 2, 1), (2, 2, 1), (1, 1, 2), (2, 2, 2), (1, 2, 5)}. agents truthful, dynamic tr-DA plays follows:period 1period 2BBwi wiwi wib1 15 s1 -1b2 10 s2 -1b3 4 s4 -2b2 10 s3 -2b3 4 s5 -5b4 3 s5 -5period 1, buyer 1 seller 1 trade payments $10 $2 respectively.period 2, buyer 2 seller 2 trade payments $4 $2 respectively.construct two kinds manipulation show dynamic DA truthful. First,buyer 1 better delaying reported arrival period 2:137fiBredin, Parkes Duongperiod 1period 2BBwi wiwi wib1 15 s2 -1b2 10 s1 -1b3 4 s4 -2b3 4 s3 -2s5 -5b4 3 s5 -5Now, buyer 2 trades period 1 set price buyer 1 period 2. Instead,buyer 1 trades period 2 makes payment $4.Second, buyer 3 better increasing reported value:period 1period 2BBwi wiwi wib3 6 s2 -1b1 15 s1 -1b4 3 s4 -2b2 10 s3 -2b3 6 s5 -5s5 -5Now, buyers 1 2 trade period 1 allows buyer 3 win (at pricetrue value) period 2. particularly interesting manipulationagents manipulation increasing bid true value. so, allowstrades occur makes auction less competitive next period.2.2 Dynamic Double Auctions: Desiderataconsider direct-revelation, dynamic DAs restrict message agentsend auctioneer single, direct claim type. also consider closedauctions agent receives feedback reporting type cannot conditionstrategy report another agent.2Given this, let denote set agent types reported period t, = ( 1 , 2 , . . . , , . . . , )denote complete type profile (perhaps unbounded), denote type profile restricted agents (reported) arrival later period t. report = (ai , di , wi )represents commitment buy (sell) one unit commodity period [ai , di ]payment wi . Thus, seller reports departure time di > di , mustcommit complete trade occurs true departure even though sellermodeled utility payments received true departure.dynamic DA, = (, x), defines allocation policy = { }tT paymentpolicy x = {xt }tT , ( ) {0, 1} indicates whether agent trades periodgiven reports t, xti ( ) R indicates payment made agent i, negativepayment received agent. auction rules also stochastic, ( )xti ( ) random variables. dynamic DA well defined, must hold( ) = 1 one period [ai , di ] zero otherwise, payment collectedagent zero except periods [ai , di ].formalizing desiderata dynamic DAs, convenient adopt ((), x())denote complete sequence allocation decisions given reports , shorthand2. restriction direct-revelation, online mechanisms without loss generality combinedsimple heart-beat message agent indicate presence period reportedarrival-departure interval. See work Pai Vohra (2006) Parkes (2007).138fiChain: Online Double Auction() {0, 1} xi () R indicate whether agent trades reported arrivaldeparture interval, total payment made agent i, respectively. slight abusenotation, write denote agent reported type later period t.Let B denote set buyers denote set sellers.shall require dynamic DA satisfies no-deficit, feasibility, individual-rationalitytruthfulness. No-deficit ensures auctioneer cash surplus every period:Definition 1 (no-deficit) dynamic DA, = (, x) no-deficit if:XXxti ( ) 0, t,(1)[ai ,min(t,di )]Feasibility ensures auctioneer need take short positioncommodity traded market period:Definition 2 (feasible trade) dynamic DA, = (, x) feasible if:XXXX( ) 0, t,( ),iS [ai ,min(t,di )](2),iB [ai ,min(t,di )]definition feasible trade assumes auctioneer hold itemmatched seller-buyer pair, instance releasing buyer uponreported departure. See remark concluding section discussionassumption.Let vi (i , (i , )) R denote value agent type allocationdecision made policy given report (i , ), i.e. vi (i , (i , )) = wi agenttrades period [ai , di ] 0 trades outside interval buyer,trades outside interval seller. Individual-rationality requires agentutility non-negative reports true type, whatever reports agents:Definition 3 (individual-rational) dynamic DA, = (, x) individual-rational(IR) vi (i , ()) xi () 0 i, .order define truthfulness, introduce notation C(i ) denoteset available misreports agent true type . standard model adoptedoffline mechanism design, typical assume C(i ) = misreports available.Here, shall assume early-arrival misreports, C(i ) = {i = (ai , di , wi ) : ai aidi }. assumption limited misreports adopted earlier work online mechanismdesign (Hajiaghayi et al., 2004), well-motivated arrival time firstperiod buyer first decides acquire item period seller firstdecides sell item.Definition 4 (truthful) Dynamic DA, = (, x), dominant-strategy incentivecompatible, truthful, given limited misreports C if:vi (i , (i ,)) xi (i ,) vi (i , (i ,)) xi (i ,).C( ),C(i ), ,.139fiBredin, Parkes Duongrobust equilibrium concept: agent maximizes utility reportingtrue type whatever reports agents. Truthfulness useful simplifiesdecision problem facing bidders: agent determine optimal bidding strategywithout model either auction dynamics agents. caseallocation payment policy stochastic, adopt requirement strongtruthfulness agent maximizes utility whatever random sequence coinflips within auction.Remark. flexible definition feasibility, auctioneer able takelong position commodity, allows auctioneer time trades receiving unitsold seller one period releasing buyer later period. allowstruthfulness environments bidders overstate departure period.settings unreasonable requirement, however, instance commodity represents task performed, physical good tradedelectronic market.3 cases, definition feasibility strengthened require exact trade-balance every period. tradeoff available misreports mustrestricted, agents limited reporting late-departures additionearly-arrivals (Lavi & Nisan, 2005; Hajiaghayi et al., 2005). rest paperwork relaxed feasibility, early-arrival model. Chain framework immediately extended strong-feasibility, early-arrival late-departure modelexecuting trades immediately rather delaying trade buyers departure.3. Chain: Framework Truthful Dynamic DAsChain provides general algorithmic framework construct truthful dynamicDAs well-defined single-period matching rules, tr-DA rules describedearlier section.introducing Chain need definitions: Bids reported Chainactive di (for reported departure period di ), bid unmatchedstill eligible matched. period, single-period matching rule useddetermine whether active bids trade also (if any) bidsmatch remain active next period.define building blocks, well-defined single-period matching rules, introduce important concept strong no-trade predicate, defined singleperiod matching rule.3.1 Building Block: Single-Period Matching Rulendefining matching rule, helpful adopt bt Rm>0 R0 denoteactive bids active asks period t, 0 n 0 bids asksrespectively. bids asks active earlier periods longer activeform history period t, denoted H Rh h 0 size history.single-period matching rule (hereafter matching rule), Mmr = (mr , xmr ) definesallocation rule mr (H , bt , st , ) {0, 1}(m+n) payment rule xmr (H , bt , st , )3. Note task computational task, tasks handled within model requiringseller performs task matched commitment hold onto resultmatched buyer ready depart.140fiChain: Online Double Auctionfunction SimpleMatch(H ,bt ,st )matched :=pt := mean(|H |)(bt 6= )&(st 6= ):= 0, bi := , j := 0, sj :=(bi < pt )&(bt 6= ):= random(bt ), bt := bt \ {i}end(sj < pt )&(st 6= )j := random(st ), st := st \ {j}end(i 6= 0)&(j 6= 0)matched := matched {(i, j)}endendend functionFigure 1: well-defined matching rule defined terms mean bid price history.R(m+n) . Here, include random event allow explicitly stochastic matchingallocation rules.Definition 5 (well-defined matching rule) matching rule Mmr = (mr , xmr ) welldefined strongly truthful, no-deficit, individual-rational, strong-feasible.Here, properties truthfulness, no-deficit, individual-rationality exactlysingle-period specializations defined previous section. instance,matching rule truthful sense dominant strategy agentDA defined rule, static environment, bid truthfullypossible random events . Similarly individual-rationality. No-deficit requirestotal payments always non-negative. Strong-feasibility requires exactlynumber asks accepted bids, random events.One example well-defined matching rule tr-DA, invarianthistory bids asks. example well-defined, adaptive (history-dependent)price-based matching rule, consider procedure SimpleMatch Figure 1. SimpleMatch matching rule computes mean absolute value bids askshistory H adopts clearing price current period. stochasticmatching rule bids asks picked sets bt st randomoffered price. reason properties SimpleMatch follows:(a) truthful: price pt independent bids probability bid (orask) matched independent bid (or ask) price(b) no-deficit: payment pt collected matched buyer madematched seller(c) individual-rational: bids bi pt asks sj pt accepted.(d) feasible: bids asks introduced matched set balanced pairs141fiBredin, Parkes Duong3.2 Reasoning Trade (Im)Possibilityaddition defining matching rule Mmr , allow designer (optionally) designatesubset losing bids satisfy property strong no-trade. Bids satisfy strongno-trade losing bids trade possible bid price (c.f. ask priceasks), moreover additional independence conditions hold bidsprovided designation.first define weaker concept no-trade.following, notationmr,i (H , bt , st , |wi ) indicates allocation decision made bid (or ask) bid(ask) price replaced wi :Definition 6 (no-trade) Given matching rule Mmr = (mr , xmr ) set agents,NTt , trade possible period given random eventsmr,i (H , bt , st , |wi ) = 0, every wi R>0 bt every wi R0st .easily happen trade possible, instance agent buyersellers side market. Let SNTt NTt denote setagents designated property strong no-trade. Unlike no-trade property,strong no-trade need uniquely defined matching rule. valid, however,construction offered designer strong no-trade must satisfy following:Definition 7 (strong no-trade) construction strong no-trade, SNTt NTt ,valid matching rule when:(a) NTt di > t, whether SNTt unchanged alternate reports= (ai , di , wi ) 6= di > t,(b) SNTt di > t, set {j : j SNTt , j 6= i, dj > t} unchangedreports = (ai , di , wi ) 6= di > t, independent even whether agentpresent market.strong no-trade conditions must checked agents reported departure later current period. Condition (a) requires agent NTt cannotaffect whether satisfies strong no-trade predicate long continuesreport departure later current period. Condition (b) defined recursively,requires agent identified satisfying strong no-trade, reportmust affect designation strong no-trade agents, reported departurelater current period, continues report departure later currentperiod even delays reported arrival later period.Strong no-trade allows flexibility determining whether bid eligiblematching. Specifically, bids satisfy strong no-trade amongst losecurrent period remain candidate trade future period. propertydefined ensure surviving agent not, could not, affect setagents competes future periods.142fiChain: Online Double AuctionExample 1 Consider tr-DA matching rule defined earlier bids asksBwiwib1 10 s1 4b2 8 s2 6b3 6 s3 8Bid 1 ask 1 trade price 8 6 respectively. NTt = bids 2 3 couldtrade (unilaterally) submitted bid price greater 10. Similarlyasks 2 3. consider order bookBwiwib1 8 s1 6b2 7 s2 10b3 2 s3 12trade occurs. case, NTt = {b1 , b2 , b3 , s1 }. trade possible bids, evenbids 2 3, wb1 + ws2 = 8 10 < 0. But, trade possible asks 2 3,wb2 + ws1 = 7 6 0 either ask could trade submitting low enough ask price.Example 2 Consider tr-DA matching rule explore possible alternative constructions strong no-trade.(i) Dictatorial: period t, identify agent could present periodway oblivious agent reports. Let denote index agent. NTt ,include SNTt = {i}. Strong no-trade condition (a) satisfied whetherselected dictator agent-independent, given selected, whethertrade possible agent-independent. Condition (b) trivially satisfied|SNTt | = 1 cross-agent coupling consider.(ii) SNTt := NTt . Consider order bookBwiwib1 3 s1 4b2 2 s2 6b3 1 s3 8Suppose bids asks remain market least one period. Clearly,NTt = {b1 , b2 , b3 , s1 , s2 , s3 }. Consider candidate construction SNTt = NTt . Strong notrade condition (a) satisfied whether set NTt agent-independent.Condition (b) satisfied, however. Consider bid 2. bid 2s report 8 instead2 trade would possible bids 1 3, SNTt = NTt = {b2 , s1 , s2 , s3 }. Thus,whether bids 1 3 satisfy strong no-trade predicate depends value bid2. valid construction strong no-trade tr-DA matching rule.(iii) SNTt = NTt |bt | < 2 |st | < 2, SNTt = otherwise. above, strongno-trade condition (a) immediately satisfied. Moreover, condition (b) satisfiedtrade possible bid ask irrespective bid valuessimply enough bids asks allow trade tr-DA (which needs least 2 bidsleast 2 asks).143fiBredin, Parkes DuongFigure 2: decision process Chain upon arrival new bid. admitted, bidparticipates sequence matching events remains unmatchedstrong no-trade set. bid matches first available opportunity pricedimmediately.Example 3 Consider variant SimpleMatch matching rule, defined fixedprice 9. ask whether SNTt := NTt valid construction strong no-trade.Throughout example suppose bids asks remain market least oneperiod. First consider bid wb1 = 8 two asks values ws1 = 6ws2 = 7. Here, NTt = {s1 , s2 } asks cannot trade whatever price sincebid high enough meet fixed trading price 9. Moreover, SNTt = {s1 , s2 }valid construction; strong no-trade condition (a) satisfied condition (b)satisfied whether ask 2 NTt (and thus SNTt ) independentprice ask 1, vice versa. consider instead bid wb1 = 8 askws1 = 10. Now, NTt = {b1 , s1 } SNTt = {b1 , s1 } candidate strong no-trade set.However bid 1 declared value 10 instead 8 NTt = {b1 } ask 1 dropsSNTt . Thus, strong no-trade condition (b) satisfied.see examples quite delicate provide valid, nontrivial construction strong no-trade. Note, however, SNTt = (trivial) validconstruction matching rule. Note also strong no-trade conditions (a)(b) require information reported departure period bid. Thus,matching rules use temporal information bids, information usedconstruction strong no-trade.3.3 Chain: Matching Rules Truthful, Dynamic DAscontrol flow Chain illustrated Figure 2. Upon arrival new bid, admissiondecision made bid admitted value wi least admission price qi .admitted bid competes sequence matching events, matching event simplyapplies matching rule set active bids asks. bid fails matchperiod strong no-trade set (i/ SNTt ), priced leavesmarket without trading. Otherwise, still departure time (t di ),available matching next period.bid always one three states: active, matched priced-out. Bids activeadmitted market di , matched priced-out.144fiChain: Online Double Auctionactive bid becomes matched first period (if any) trades single-periodmatching rule. active bid marked priced-out first period losesstrong no-trade set. soon bid longer active, entershistory, H , information bid price used defining matching rulesfuture periods.Let E denote set bids expire current period. well-definedmatching rule, coupled valid strong no-trade construction, must provide Chainfollowing information, given history H , active bids bt active asks st ,expiration set E period t:(a) bid ask, whether wins loses(b) winning bid ask, payment collected (negative ask)(c) losing bid ask, whether satisfies strong no-trade conditionNote expiration set E used strong no-trade construction.information made available matching rule. following table summarizesuse information within Chain. Note winning bid cannot set SNTt :LoseWinSNTtpriced-outmatchedSNTtsurviven/adescribe Chain defining events occur bid upon arrivalmarket, period remains active:Upon arrival: Consider possible earlier arrival periods [di K, ai 1] consistentreported type. periods consider bid maximallypatient. bid would lose SNTt one arrival periods, admitted. Otherwise, bid would win periods/ SNTt , define admission price as:q(ai , di , , ) :=max[di K,ai 1],iSNT/[pti , ],(3)pti payment agent would made (negative seller) arrivalperiod (as determined running myopic matching rule period).agent would lose earlier arrival periods (and SNTt ),bid maximally patient, admission price defaults bidadmitted.active: Consider period [ai , di ]. bid selected trade myopicmatching rule, mark matched define final payment:xti ( ) = max(q(ai , di , , ), pti ),(4)pti price (negative seller) determined myopic matching rulecurrent period. buyer, collect payment delay transferringitem period di . seller, collect item delay makingpayment reported departure period. bid loses SNTt ,mark bid priced-out.145fiBredin, Parkes Duongillustrate Chain instantiating various matching rules next section.Section 5 prove Chain strongly truthful no-deficit coupledwell-defined matching rule valid strong no-trade construction. seedelay buyer delivery seller payment ensures truthful revelation traders departureinformation. instance, absence delay, buyer might able betterover-reporting departure information, still trading early enough lower price.3.4 Commentschoose allow single-period matching rules use reported arrivaldeparture associated active bids asks. maintains clean separationnon-temporal considerations (in matching rules) temporal considerations (inwider framework Chain). also simplicity. single-period matching rulesallowed depend reported arrival-departure interval, long (singleperiod) rules monotonic tighter arrival-departure intervals, sense agentwins = (ai , di , wi ) continues win improved price insteadreports (ai , di , wi ) [ai , di ] [ai , di ]. However, whether trade possible mustindependent reported arrival-departure interval similarly strong no-trade.Determinations would need made respect patient type(di K, di , wi ) given report = (ai , di , wi ).4. Practical Instantiations: Price-Based Competition-Based Rulessection offer number instantiations Chain online DA framework.present two different classes well-defined matching rules: price-basedcompute simple price statistics based history used matching,refer competition-based leverage history also consider directcompetition active bids asks period. case, establishmatching rules well-defined provide valid strong no-trade construction.4.1 Price-Based Matching Rulesone rules constructs single price, pt , period based history Hearlier bids asks traded expired. purpose define variationsreal valued statistic, (H ), used define price given history. GeneralizingSimpleMatch procedure, introduced Section 3.1, price pt used determinetrades period t. also provide construction strong no-trade context.main concern setting prices may volatile, price updatesdriving admission price higher (via max operator admission rule Chain)effect pricing bids asks market. describe various formssmoothing windowing, designed provide adaptivity dampening shortterm variations. case, parameters (e.g. smoothing factor, windowsize) determined empirically off-line tuning.experiment five price variants:History-EWMA: Exponentially-weighted moving average. bid history, H , useddefine price pt period t, computed pt := (H ) + (1 )pt1 , (0, 1]146fiChain: Online Double Auctionsmoothing constant (H ) statistic defined bids asks enter historyperiod t. Experimentally find mean statistic, mean (H ), absolutevalues bids asks enter history performs well 0.05 lowerscenarios test. cases (H ) well-defined (orzero) new bids asks, set pt := pt1 .History-median: Compute price pt statistic fixed-size windowrecent history, pt := (H , ) window-size, i.e. defining bids introducedhistory H periods [t , . . . , t]. Experimentally, find median statistic,median (H , ), absolute bid ask values performs well scenarios test,window size depending inversely volatility agents valuations. Typically,observe optimal window sizes 20 150, depending volatility. cases(H , ) well-defined (or zero) new bids asks, setpt := pt1 .History-clearing: Identical history-median rule except statistic (H , )defined (bm sm )/2 bm sm lowest value pair trades wouldexecuted efficient (value-maximizing) trade given bids asks enter historyH periods [t , . . . , t]. Empirically, find similar optimal window sizes historyclearing history-median.History-McAfee: Define statistic (H , ) represent McAfee price, definedSection 4.2, bids H simultaneously arrived.Fixed price: simple rule computes single fixed price pt := p trading periods,price optimized offline maximize average-case efficiency dynamic DAgiven Chain associated single-period matching rule leverages price pcandidate trading price.pricing variant, procedure Match (see Figures 34) used determinebids win (at price pt ), lose, and, lose, satisfy strong notrade predicate. subroutine used determine current price referreddetermineprice Match. provide input Match set E addition(H , bt , st ) Match also constructs strong no-trade set, E used exclusively purpose.proof following lemma technical postponed Appendix.Lemma 1 Procedure Match defines valid strong no-trade construction.Theorem 1 Procedure Match defines well-defined matching rule valid strong notrade construction.Proof: No-deficit, feasibility, individual-rationality immediate constructionMatch since bids asks added matched pairs, payment,payment less equal value. Truthfulness also easy see:order bid (or ask) selected independent bid price, pricefaces, selected, independent bid. price less equal bid,whether trades depends order. rest claim followsLemma 1.147fiBredin, Parkes Duongfunction Match(H ,bt ,st ,E )matched := , lose := , NTt := , SNTt :=stop := falsept := determineprice(H )stop:= 0, j := 0, checkedB := , checkedS :=((checkedB bt )&(i=0)) ((checkedS st )&(j=0))(i = 0)&(j = 0)k := random(bt \ checkedB st \ checkedS )else (i = 0)k := random(bt \ checkedB )else (j = 0)k := random(st \ checkedS )end(k bt )checkedB := checkedB {k}(bk pt ):= kendelsecheckedS := checkedS {k}(sk pt )j := kendendend(i 6= 0)&(j 6= 0)matched :=matched{(i, j)}lose := lose(checkedB \ {i})(checkedS \ {j})b := b \ checkedB , := \ checkedSelsestop := trueendendend functionFigure 3: procedure used single-period matching applying Chain pricebased rules. algorithm continues Figure 4.148fiChain: Online Double Auctionfunction Match (continued)(H ,bt ,st ,E )(i 6= 0)&(j =S0)lose := lose st , NTt := bt(k bt ((bk pt )&(dk = t))) (k st (dk = t))SNTt := btelseSNTt := bt \ checkedBendelse (j 6= 0)&(i= 0)lose := lose bt , NTt := st(k st ((sk pt )&(dk = t))) (k bt (dk = t))SNTt := stelseSNTt := st \ checkedSendelse (i = 0)&(j= 0)NT := bk = t)) (k st (dk = t))(k bt (dSSNT := b stendendend functionI-aIIIIIFigure 4: Continuing procedure Figure 3 single-period matching applying Chainprice-based rules.Example 4 (i) Bid bt = {8}, ask st = {6}, indexed {1, 2} price pt = 9. outerloop Figure 3 terminates j = 2 = 0 Case II. bid markedloser NTt = {2}. bid depart immediately, SNTt = {2}, otherwiseSNTt = .(ii) Bid bt = {8}, asks st = {6, 7}, indexed {1, 2, 3}, price pt = 9. Supposeask 2 selected ask 3 outer loop. loop terminates j = 2= 0 Case II NTt = {2, 3}. Suppose bid asks leave market laterperiod. SNTt = {3} checkedS = {2}.(iii) Bid bt = {8} ask st = {10}, indexed {1, 2}, price pt = 9 bidask patient. outer loop terminates = 0 j = 0 Case IIINTt = {1, 2}. However, SNTt = .4.2 Competition-Based Matching Rulesone rules determines bids match current period pricecompetition active bids. present three variations: McAfee, WindowedMcAfee Active-McAfee. latter two rules hybrid rules leverage149fiBredin, Parkes Duonghistory past offers, smoothing prices generated competition-based matchingrules.McAfee: Use static DA protocol due McAfee matching rule. Let B denoteset bids denote set asks. min(|B|, |S|) < 2, trade.Otherwise, first insert two dummy bids value {, 0} two dummy asks value{0, } set bids asks. Let b0 b1 . . . bm s0 s1 . . .sn . . . denote bid ask values (b0 , s0 ) denoting dummy pair (, 0) (bm , sn )denoting dummy pair (0, ) ties otherwise broken random. Let 0 indexlast pair bids asks clear efficient trade, bm + sm 0bm+1 + sm+1 < 0. 1, consider following two cases:m+1bm pm+1 sm first bids(Case I) price pm+1 = bm+12asks trade payment pm+1 collected winning buyer madewinning seller.(Case II) Otherwise, first 1 bids asks trade payment bm collectedwinning buyer payment sm made winning seller.define NTt , replace bid trade bid reporting large valuesee whether bid trades. determine whether trade possible asktrade: replace ask ask reporting value > 0, small . Sayquorum least two bids least two asks, i.e.min(|bt |, |st |) 2. Define strong no-trade follows: set SNTt := NTt = bt stquorum SNTt := otherwise.Lemma 2 bid bi McAfee matching rule, bid (or ask) jbid bi make trade possible bid (or ask) j quorum.Proof: Without loss generality, suppose three bids three asks. Labelbids (a, c, e) asks (b, d, f ), ordered highest lowest (a, b)competitive bid-ask pair. Proceed case analysis bids. analysis symmetricasks omitted. Let tp(i) {0, 1} denote whether trade possible bid i,NTt tp(i) = 0. bid a: b (a d)/2 tp(c) = tp(e) = 1inequality always satisfied large enough a; (c d)/2 tp(b) = 1(c b)/2 tp(d) = tp(f ) = 1, inequalities satisfiedlarge enough a. bid c: b (c d)/2 tp(a) = 1 when, addition,c > a, tp(e) = 1 one inequalities satisfied large enough c;similarly c (a d)/2 tp(b) = 1 c (a b)/2 tp(d) = tp(f ) = 1.Analysis bid e follows bid c.Lemma 3 construction strong no-trade valid valid strong notrade construction includes one losing bid ask departcurrent period period quorum.Proof: see valid construction, notice strong no-trade condition (a)holds since bid (or ask) always NTt SNTt . Similarly, condition (b)trivially holds (with bids asks remaining SNTt even bid150fiChain: Online Double Auctionpresent market). see definition essentially maximal, considermin(|bt |, |st |) 2. contradiction, suppose two losing bids {i, j} departurecurrent period designated strong no-trade. But, strong no-trade condition(b) fails Lemma 2 either bid could submitted alternate bid pricewould remove bid NTt thus necessarily also SNTt .construction offered SNTt cannot extended even include one agent selectedrandom set NTt depart immediately, case quorum.construction would fail strong no-trade condition (b) set NTt containsone bid (or ask) depart current period, bidabsence market would cause agent (randomly) selected SNTt .Windowed-McAfee: myopic matching rule parameterized window size .Augment active bids asks bids asks introduced history Hperiods {t + 1, . . . , t}. Run McAfee augmented set bids asksdetermine bids asks would trade. Denote candidate set C.active agents identified matching C may able trade periodC also contain non-active agents.Let B denote, respectively, active bids active asks set C. WindowedMcAfee proceeds picking random subset min(|B |, |S |) bids asks trade.|B | =6 |S |, bids asks trade.Define strong no-trade matching rule as:(i) active asks active bids, SNTt := bt(ii) active bids active asks, SNTt := st(iii) fewer 2 asks fewer 2 bids augmented bid set,SNTt := bt st ,otherwise set SNTt := . cases clear SNTt NTt .Lemma 4 strong no-trade construction windowed-McAfee valid.Proof: valid SNT criteria case (iii) follows immediately validitySNT criteria standard McAfee matching rule. Consider case (i). Case (ii)symmetric omitted. strong no-trade condition (a), see bids NTtalso SNTt , whether designated strong no-trade independentbid price simply active asks. Similarly, strongno-trade condition (b), see bids (and never asks) SNTt whateverbid price particular bid (and even whether present).Empirically, find efficiency Windowed-McAfee sensitive sizeH , frequently best choice small window size includes activebids.Active-McAfee: Active-McAfee augments active bids asks include unexpired traded priced-out offers. proceeds Windowed-McAfee givenaugmented bid set.151fiBredin, Parkes Duong4.3 Extended Examplesnext provide two stylized examples demonstrate matching performed Chainusing price-based competition-based matching rule. examples,assume maximal patience K = 2. Moreover, describe Chain determinesbid ask trades, remember winning buyer allocated goodreported departure winning seller receive payment reporteddeparture.Example 5 Consider Chain using adaptive, price-based matching rule. particulardetails prices determined relevant. Assume prices periods 12 {p1 , p2 } = {8, 7} maximal patience three periods. consider period3 suppose order book empty end period 2 bids asksTable 1 arrive period 3.Bwi di di K qipi SNT?wi di di K qipi SNT?b1 * 15 4277Ns1 -1 42-7 n/as2 * -3 53-6.5Nb2 * 10 3188Nb3 7 318 n/aNs3 -4 31-7 n/as4 * -5 42-7 -6.5Nb4 6 53n/aNs5 -10 53n/aTable 1: Bids asks arrive period 3. Bids {b1 , b2 } match asks {s2 , s4 } (as indicated*). Bid b3 priced-out upon admission qb3 > wb3 (indicated strikethrough). admission price qi payment made agent tradespi . Column SNT? indicates whether bid ask satisfies strong no-tradepredicate. Asks {s1 , s5 } survive next period SNTdi > 3.Bids {b1 , b2 , b4 } asks {s1 , .., s5 } admitted. Bid b3 priced qb3 =max(p1 , p2 , ) = max(8, 7, ) = 8 > wb3 = 7 Eq. (3). Note b4 s5admitted despite low bids (asks) maximal patience admissionprices . Now, suppose p3 := 6.5 defined matching rule considerapplying Match admitted bids asks.Suppose bids randomly ordered (b4 , b2 , b1 ) asks(s4 , s2 , s1 , s3 , s5 ). Bid b4 picked first priced-out wb4 = 6 < p3 = 6.5. Bidb2 tentatively accepted (wb2 = 10 p3 = 6.5) ask s4 accepted (ws4 = 5p3 = 6.5). Bid b2 matched ask s4 , payment max(qb2 , p3 ) = max(8, 6.5) = 8b2 Eq. (4) payment max(qs4 , p3 ) = max(, 6.5) = 6.5 s4 . Bid b1tentatively accepted (15 6.5) matched ask s2 , accepted3 6.5. payments max(7, 6.5) = 7 b1 max(, 6.5) = 6.5 s2 .Ask s3 expires asks s1 s5 survive marked SNT periodnever offered chance match bid. asks active period4.Note role admission price truthfulness. bid b1 delayed arrivalperiod 4, admission price would max(p2 , p3 , ) = max(7, 6.5) = 7 payment152fiChain: Online Double Auctionperiod 4 (if matches) least 7. Similarly, ask s4 delayed arrival, admissionprice would max(7, 6.5, ) = 6.5 maximal payment receive period4 6.5.Example 6 Consider Chain using McAfee-based matching rule K = 3bids asks arriving period 3. Suppose prices periods 1 2would faced buyer {p1b , p2b } = {8, 7} {p1s , p2s } = {7, 6} seller.prices determined inserting additional bid (with value ) additionalask (with value 0) order books periods 1 2. illustrateperiod 3. Consider bids asks period 3 Table 2.wi dib1 * 15 4b2 * 10 3b3 7 3b4 6 5Bdi K qipi SNT?wi di di K qipi SNT?277Ns1 * -1 42-6-4N188Ns2 * -3 53-4N18 n/aNs3 -4 31-6 n/aN3n/aNs4 -5 42-6 n/aNs5 -10 53n/aNTable 2: Bids asks arrive period 3. Bids {b1 , b2 } match asks {s1 , s2 } (as indicated*). Bid b3 priced-out upon admission qb3 > wb3 . admission priceqi payment made agent trades pi . Column SNT? indicates whetherbid ask satisfies strong no-trade predicate. asks bids survivenext period.bid b3 admitted. myopic matching rule runs (static) McAfeeauction rule bids {b1 , b2 , b4 } asks {s1 , .., s5 }. Consider bids asks decreasingorder value, last efficient trade indexed = 3 wb4 + ws3 = 6 4 0.pm+1 = (0(5))/2 = 2.5 (inserting dummy bid value 0 described Section 4.2).Price pm+1 = 2.5 > s3 = 4 trade cannot executed McAfee. Instead,buyers {b1 , b2 } trade face price pbm = wb4 = 6 sellers {s1 , s2 } trade face pricepsm = ws3 = 4. Bids b4 asks {s3 , s4 , s5 } priced-out survivenext round. Ultimately, payment max(qb1 , pbm ) = max(7, 6) = 7 collected buyer b1payment max(qb2 , pbm ) = max(8, 6) = 8 collected buyer b2 . sellers, paymentmax(6, 4) = 4 max(, 4) = 4 s1 s2 respectively.prices p3b p3s used Eq. (3) define admission price bidsasks arrivals periods 4 5 determined follows. buy-side price,introduce additional bid bid-price . bid values considered McAfeewould (, 15, 10, 6, 0) ask values would (1, 3, 4, 5, 10), dummybid value 0 included buy-side. last efficient pair trade = 46 5 0 pm+1 = (0 (10))/2 = 5, satisfies bid-ask pair. Thereforebuy-side price, p3b := 5. sell-side, introduce additional ask ask-price0 bid values considered McAfee (15, 10, 6, 0) (again, dummy bidincluded) ask values (0, 1, 3, 4, 5, 10). time = 3 lastefficient pair trade 6 3 0. pm+1 = (0 (4))/2 = 2 price153fiBredin, Parkes Duongsatisfy s2 , pm+1 > s2 price psm+1 = s2 = 3 adopted. Therefore sell-sideprice, p3s := 3.Again, see bidder 1 cannot improve price delaying entry period4. admission price bidder would max(p2b , p3b ) = max(7, p3b ) 7 thuspayment period 4, matches, least 7.4 Similarly ask s1 , would faceadmission price max{p2s , p3s } = max{6, 4} = 4 receive payment 4period 4. leave exercise reader verify p3s = 4 ask s1 delaysarrival period 4 (in comparison, p3s = 3 ask s1 truthful).McAfee-based pricing scheme computes price clears order bookfollowing every period least two bids two asks, bid activityperiods tend short comparison adaptive, price-based rules orderskept active longer asymmetry number bids asksmarket. fact, one interesting artifact occurs adaptive, price-based matchingrules admission-price SNT perpetuate kind bid-ask asymmetry.market asks bids, SNT becomes likely future asks, bids.Therefore, bids much likely asks immediately priced marketfailing meet admission price constraint.5. Theoretical Analysis: Truthfulness, Uniqueness, JustifyingBounded-Patiencesection prove Chain combined well-defined matching rule validstrong no-trade construction generates truthful, no-deficit, feasible individual-rationaldynamic DA. Section 5.2, establish uniqueness Chain amongst dynamic DAsconstructed single-period matching rules building blocks. Section 5.3,establish importance existence maximal bound bidder patiencepresenting simple environment truthful, no-deficit DA implement evensingle trade despite number efficient trades increased without bound.5.1 Chain Mechanism Strongly Truthfulhelpful adopt price-based interpretation valid single-period matching rule.Given rule Mmr , define agent-independent price, zi (H , \ i, ) R = bt st ,i, bids bt , asks st , history H , random events .have:(A1) wi zi (H , \ i, ) > 0 mr,i (H , bt , st , ) = 1, wi zi (H , \ i, ) <0 mr,i (H , bt , st , ) = 0(A2) payment xmr,i (H , bt , st , ) = zi (H , \ i, ) mr,i (H , bt , st , ) = 1xmr,i (H , bt , st , ) = 0 otherwise4. check p3b := 6 case. Suppose bidder 1 present period 3. considerintroducing additional bid value bids values {, 10, 6, 0} (with dummy bid)ask values {1, 3, 4, 5, 10}. = 3 pm+1 = (0 (5))/2 = 2.5,support trade bid b4 ask s3 . Instead, pbm = wb4 = 6 adopted, wouldp3b := 6. course, exactly price determined McAfee bid b1 period 3 biddertruthful.154fiChain: Online Double Auctioninterpretation agent-independent price, zi (H , \ i, ),least wi agent loses greater wi otherwise. particular, zi (H , \i, ) = NTt . Although agents price explicit matching ruleagent trades, well known price exists truthful, single-parametermechanism; e.g., see works Archer Tardos (2001) Goldberg Hartline (2003).5Moving forward adopt price zi characterize matching rule used building blockChain, assume without loss generality properties (A1) (A2).Given this, establish truthfulness Chain appeal price-basedcharacterization due Hajiaghayi et al. (2005) truthful, dynamic mechanisms. state(without proof) variant characterization result holds stochastic policies(, x) strong-truthfulness. theorem state also specialized DAenvironment. continue adopt capture realization stochastic eventsinternal mechanism:Theorem 2 (Hajiaghayi et al., 2005) dynamic DA = (, x), perhaps stochastic,strongly truthful misreports limited early-arrivals if, every agent i,, , random events , exists price pi (ai , di , , ) that:(B1) price independent agent reported value(B2) price monotonic-increasing tighter [ai , di ] [ai , di ](B3) trade (i , ) = 1 whenever pi (ai , di , , ) < wi (i , ) = 0 wheneverpi (ai , di , , ) > wi , trade performed buyer upon departure perioddi .(B4) agents payment xi (i , ) = pi (ai , di , , ) (i , ) = 1,xi (i , ) = 0 otherwise, payment made seller upon departure, di .random event independent report agent much affectsprice agent i.single-period, price-based characterization, price pi (ai , di , , ) needalways explicit Chain. Rather, theorem states given truthful dynamicDA, Chain, exists well-defined price function properties valueindependence (B1) arrival-departure monotonicity (B2), definetrade (B3) payment (B4).establish truthfulness Chain, prove well-defined respectfollowing price function:pi (ai , di , , ) = max(q(ai , di , , ), pi (ai , di , , )),(5)q(ai , di , , ) =maxt[di K,ai 1],iSNT/(zi (H , \ i, ), )(6)5. single-parameter mechanism one private information agent limited onenumber. fits single-period matching problem arrival departure informationdiscarded. Moreover, although buyers sellers, problem effectively singleparameter buyer usefully pretend seller vice versa.155fiBredin, Parkes Duongp(ai , di , , ) =zi (H , \ i, ) , decision(i) = 1+, otherwise(7)decision(i) = 0 indicates SNTt [ai , di ] decision(i) = 1otherwise, [ai , di ] first period/ SNTt . referdecision period. Term q(ai , di , , ) denotes admission price, definedperiods agent arrives/ SNTt arrived period. Notecarefully rules Chain implicit defining price function. instance,whether SNTt period depends, example, bidsremain active period.establish conditions (B1)(B4). proofs technical lemmas deferredAppendix. following lemma helpful gets heart strong notrade concept.Lemma 5 set active agents (other i) period Chain independentreport agent remains active, would unchanged arrival laterperiod t.following result establishes properties (B1) (B2).Lemma 6 price constructed admission price q post-arrival price p valueindependent monotonic-increasing matching rule Chain well-defined,strong no-trade construction valid, agent patience bounded K.established properties (B1) (B2) price function pi (ai , di , , ),need establish (B3) (B4) show truthfulness. timing aspect (B3) (B4),requires buyer receives item seller receives payment uponreported departure, already clear definition Chain.Theorem 3 online DA Chain strongly truthful, no-deficit, feasible individualrational matching rule well-defined, strong no-trade construction valid,agent patience bounded K.Proof: Properties (B1) (B2) follow Lemma 6. timing aspects (B3)(B4) immediate. complete proof, first consider (B3). q > wi , agentpriced admission Chain reflects zi (H , \ i, ) > wi[di K, ai 1]/ SNTt , thus bid would lose arrivedperiod (either could trade, payment greater reported value,NTt ). Also, decision period, p = , consistentChain, bid price bid trade SNTt periods[ai , di ]. Suppose decision period q < wi . p > wi ,trade. case Chain, price zi (H , \ i, )greater wi thus agent priced-out. p < wi bid tradeindeed does, price zi period satisfies (A1) (A2) respectmatching rule. Turning (B4), immediate payments collected Chain156fiChain: Online Double Auctionequal price pi (ai , di , , ), bid trades pi (ai , di , , ) withus q wi p wi . admission price q(ai , di , , ) = q(ai , di , , ) q wiprice zi well-defined properties (A1) (A2). Similarly, payment ptdefined matching rule Chain decision period equal p.Chain individual-rational feasible follows inspection. Chain nodeficit payment collected every agent (whether buyer seller)least defined valid matching rule decision period (it higheradmission price higher matching price), matching rulesno-deficit, auctioneer delays making payment seller reporteddeparture collects payment buyer immediately upon match.remark information reported bidders currently participating market, instance assist valuation process. informationdelayed least maximal patience bidder, bid current biddercannot influence bids asks faces, without strategicconsequences. course, without constraint, bidders participatemarket multiple times, effect feedback would require careful analysis bringus outside private values framework.5.2 Chain Unique amongst Dynamic DAs constructed MyopicMatching Rulesfollows, establish Chain unique amongst truthful, dynamic DAsadopt well-defined, myopic matching rules simple building blocks. this, defineclass canonical, dynamic DAs, take well-defined single period matching rulecoupled valid strong no-trade construction, satisfy following requirements:(i) agents active matched priced-out,(ii) agents participate single-period matching rule active(iii) agents matched trade single-period matching rule.think restrictions capture essence means constructdynamic DA single-period matching rules. Notice number design elementsleft undefined, including payment collected matched bids, mark activebid priced-out, rule use upon admission, use strong no-tradeinformation within dynamic DA. establishing uniqueness result, leveragenecessary sufficient price-based characterization Theorem 2, exactly determineprice function pi (ai , di , , ) defined Eq. (4) associated Chain.proofs two technical lemmas deferred Appendix.Lemma 7 strongly truthful, canonical dynamic DA must define price pi (ai , di , , )zi (H , \ i, ) decision period bid (if exists). Moreover, bidmust priced-out period matched.Lemma 8 strongly truthful, canonical individual-rational dynamic DA must defineprice pi (ai , di , , ) q(ai , di , , ), bid wi < q(ai , di , , ) must pricedout upon admission.157fiBredin, Parkes DuongTheorem 4 dynamic DA algorithm Chain uniquely defines strongly truthful,individual-rational auction among canonical dynamic DAs designate bids pricedout necessary.Proof: decision period, must pi (ai , di , , ) = , canonical(iii) coupled (B3). Combining Lemmas 7 8, pi (ai , di , , )max(q(ai , di , , ), p(ai , di , , )). also established bid must pricedout bid value less admission price, fails match decisionperiod. Left show price exactly Chain, bid admittedvalue wi q(ai , di , , ) retained active strong notrade set. last two control aspects determined choose ruledesignates bids priced-out necessary. prefer allow bid remain activecompromise truthfulness individual-rationality. Finally, supposecontradiction p = pi (ai , di , , ) > max(q(ai , di , , ), p(ai , di , , )).agent max(q(ai , di , , ), p(ai , di , , )) < wi < p would prefer bid wi =q(ai , di , , ), p(ai , di , , )) avoid winning otherwise payment wouldgreater value.5.3 Bounded Patience Required Reasonable EfficiencyChain depends maximal bound patience used calculate admission price facedbidder entering market Eq. (3). motivate assumptionexistence maximal patience, construct simple environment numbertrades implemented truthful, no-deficit DA made arbitrarily small fractionnumber efficient trades even small number bidders potentially unbounded patience. illustrates bound bidder patience required dynamicDAs reasonable performance.achieving negative result, impose additional requirement anonymity,anonymity property already satisfied Chain, coupled matching rulessatisfy anonymity, case rules presented Section 4. defininganonymity, extend earlier definition dynamic DA, = (, x), allocationpolicy = { }tT defines probability ( ) [0, 1] agent trades periodgiven reports . Payment, x = {xt }tT , continues define payment xti ( ) agentperiod t, random variable mechanism stochastic.Definition 8 (anonymity) dynamic DA, = (, x) anonymous allocation policy= { }tT defines probability trade ( ) period independentidentity invariant permutation ( \ i) payment xti ( ), contingenttrade agent i, independent identity invariant permutation ( \ i).consider following simple environment. Informally, randomnumber high-valued phases bids asks high value mightsingle bidder patience exceeds bids asks phase.high-valued phases followed number, perhaps zero, low-valued phasesbounded-patience bids asks. Formally, Th 1 high-valued phases(a random variable, unknown auction), duration L 1 periods, indexedk {0, 1, . . . , Th 1} with:158fiChain: Online Double AuctionN N 1 bids type (1 + kL, (k + 1)L, vH ),0 1 bids type (1 + kL, d, vH ) mark-up parameter, > 1high-patience parameter, ,N asks type (1 + kL, (k + 1)L, (vH )),followed number (perhaps zero) low-valued phases, also duration L,indexed k {Th , . . . , }, with:N N 1 bids type (1 + kL, (k + 1)L, vL )N asks type (1 + kL, (k + 1)L, (vL )),N 1, 0 < vL < vH , bid-spread parameter > 0. Note phaselast phase, additional bids asks arriving future.Definition 9 (reasonable DA) dynamic DA reasonable simple environmentparameterization new bids, N 1, periods-per-phase, L 1,execute least one trade new bids new asks phase,choice high value vH , low value vL < vH , bid-spread > 0, mark-up > 1, highpatience d.dynamic DAs presented Section 4 parameterized makereasonable suitably large N 1 L 1, without possibility bidunbounded patience.Theorem 5 strongly truthful, individual-rational, no-deficit, feasible, anonymous dynamic DA reasonable bidders patience unbounded.Proof: Fix N 1, L 1, number high-valued phases, Th 1, setdeparture high-patience agent = (Th + 1)L. Keep vH > vL > 0, > 0, > 1variables set within proof. Assume dynamic DA reasonable,selects least one new bid-ask pair trade phase. Consider phase k = 0N 1 agents types (1, L, vH ), N type (1, L, (vH )) 1 agent patient type,(1, (Th + 1)L, vH ). patient bid deviates (1, L, vH ), bids identical,probability least 1/N bid would win anonymity reasonableness.Also, anonymity, individual-rationality no-deficit payment madewinning bid same, must p [vH , vH ]. (If payment lessthis, DA would run deficit since sellers require least much paymentindividual-rationality.) Condition case patient bid would windeviates reports (1, L, vH ). Suppose bidder truthful, reports (1, (Th + 1)L, vH )trade phase. But, phase k = 0 last phase new bidsasks, bid able trade future strong-truthfulnessDA would need make payment least vH vH = ( 1)vH later phaseprevent bid useful deviation (1, L, vH ) winning phase k = 0. But, if:N < ( 1)vH ,159(8)fiBredin, Parkes DuongDA cannot make payment without failing no-deficit (because N upperbound surplus auctioneer could extract bidders phase withoutviolating individual-rationality). later pick values , vH , satisfy Eq. (8).So, bid must trade reports (1, (Th + 1)L, vH ), event would winreport (1, L, vH ), insurance last phase new bidsasks. Moreover, trade payment, p [vH , vH ], ensure agent truetype (1, L, vH ) cannot benefit reporting (1, (Th + 1)L, vH ).suppose last phase new bids asks, Th > 1.consider would happen patient bid phase k = 0 deviated reported(1 + Th L, (Th + 1)L, vL ). before, bid would win probability least 1/Nanonymity reasonableness, payment p [vL , vL ]. Conditioncase patient bid would win, report (1, L, vH )report (1 + Th L, (Th + 1)L, vL ). truthful, trades phase k = 0 paymentleast vH . reported (1 + Th L, (Th + 1)L, vL ), would trade phase k = Thpayment vL . strong truthfulness, DA must make additional paymentpatient agent least (vH vL ) (vH (vH )) = vH vL . But, supposehigh low values that,(Th + 1)N < vH vL .(9)Making payment case would violate no-deficit, (Th +1)N upperbound surplus auctioneer extract bidders across phases, includingcurrent phase, without violating individual-rationality. fix vL > 0,< vL choose vH > (Th + 1)N + vL + satisfy Eq. (9) > (N /vH ) + 1satisfy Eq. (8). Thus, proved truthful dynamic DA choose bidask pair trade period k = 0. proof readily extended show similarproblem choosing bid-ask pair period k < Th , considering truthful type(1 + kL, (Th + 1)L, vH ).drive home negative result: notice number efficient tradesincreased without limit choosing arbitrarily large Th , truthful, dynamic DA properties able execute even single trade{0, . . . , Th 1} periods. Moreover, see vanishingly small fractionhigh-patience agents required negative result. proof requiresleast one patient agent possible high-valued phases.6. Experimental Analysissection, evaluate simulation Chain-based DAs introducedSection 4. measure allocative efficiency (total value trades), net efficiency(total value discounted revenue flows auctioneer), revenueauctioneer. values normalized total offline value optimal matching.comparison also implement several matching schemes: truthful, surplusmaximizing matching algorithm presented Blum et al. (2006), untruthful greedymatching algorithm using truthful bids input provide upper-bound performance,untruthful DA populated simple adaptive agents modeledZero-intelligence Plus trading algorithm leveraged study staticDAs (Cliff & Bruten, 1998; Preist & van Tol, 1998).160fiChain: Online Double Auction6.1 Experimental Set-upTraders arrive market Poisson stream exchange single commodity discretemoments. standard model arrival dynamic systems, economic otherwise.trader, equally likely buyer seller, arrives previous exponentially distributed delay, probability density function (pdf):f (x) = ex ,x 0,(10)> 0 represents arrival intensity agents per second. Later present resultsinterarrival time, 1 , varied 0.05 1.5; i.e., arrival intensityvaried 20 23 . single trial continues least 5,000 buyers 5,000 sellersentered market. experiments vary maximal patience K 210. distribution agents activity period (or patience, di ai ), consideruniform distribution pdf:f (x) =1,Kx [0, K],(11)truncated exponential distribution pdf:f (x) = ex ,x [0, K],(12)= ln(0.05)/K 95% underlying exponential distribution lessmaximal patience. arrival time activity duration rounded nearestintegral time period. trader arrives departs period assumedneed immediate trade active one period.traders valuation represents sample drawn arrival uniform distribution spread 20% current mean valuation. (The value positive bidnegative ask.) simulate market volatility, run experiments varyaverage valuation using Brownian motion, common model valuation volatility uponmany option pricing models based (Copeland & Weston, 1992). every timeperiod, mean valuation randomly increases decreases constant multiplier, e ,approximate volatility varied 0 0.15 experiments.plot mean efficiency 100 runs experiment, sets bidsasks used across double auctions. parameters auction rule reoptimizedmarket environment; e.g., find optimal fixed price optimalsmoothing parameters offline given ability sample market model.6.2 Chain Implementationimplement Chain five price-based matching rules (history-clearing, historymedian, history-McAfee, history-EWMA, fixed-price) three competition-basedmatching rules (McAfee, active-McAfee, windowed-McAfee).price-based implementations keep fixed-size set recently expired,traded, priced-out offers, H . Offers priced-out admission prices insertedH prior computing pt . history-clearing metric computes price maximizenumber trades agents represented H contemporary. historymedian metric chooses price median absolute valuation offers161fiBredin, Parkes DuongH . history-McAfee method computes McAfee price scenarioagents represented H simultaneously present. EWMA metric computesexponentially-weighted average bids order expire, trade, price out.simulations initialize price average mean buy sell valuations.two bids expire period, included arbitrary order movingaverage.None metrics require one parameter, optimized offlineaccess model market environment. Parameter optimization proceeds uniformly sampling parameter range, smoothing result averaging resultimmediate neighbors. optimization repeats twice narrower rangesmoothed maximum, returning parameter maximizes (expected) allocative efficiency. None price-based methods appeared sensitive small (<10%) changessize H . simulations, window size chosen 150 offers. EWMA, smoothing factor usually chosen around 0.05 lower.windowed-McAfee matching rule, however, extremely sensitive window size simulations volatile valuations, search process frequently converged suboptimallocal maxima.admission price price-based methods computed first determiningwhether Match would check value bid bid price bid arrivedearlier period . Rather simulate entire Match procedure, sufficientdetermine probability event. determined checking constructionstrong no-trade sets earlier period. SNTt contains non-departing buyers(sellers), probability additional seller (buyer) would examined 1= 1. Otherwise probability equal ratio number bids (asks) examined included SNTt one total number bids (asks) present.Finally, probability price agent would faced period defined pt(pt sellers), otherwise . Here, pt history-dependent price definedperiod .competition-based matching rules price non-trading bids endperiod trade occurs (because definition strong no-trade context).admission prices calculated considering price bid (ask) wouldfaced period reported arrival. period, price bid (ask)determined inserting additional bid (ask) valuation (0) applyingcompetition-based matching rule (counterfactual) state. determinewhether agent would win reported value, price would face.6.3 Optimal Offline Matchinguse commercial integer program solver (CPLEX6 ) compute optimal offlinesolution, i.e. complete knowledge offers received time. determiningoffline solution enforce constraint trade executed activityperiods buyer, i, seller, j, overlap,(ai dj ) (aj di )6. www.ilog.com162(13)fiChain: Online Double Auctioninteger-program formulation maximize total value is:maxXxij (wi + wj )(14)(i,j)overlapXs.t. 0xij 1, j aski:(i,j)overlap0Xxij 1, bidj:(i,j)overlapxij {0, 1}, i, j,(i, j) overlap bid-ask pair could potentially tradeoverlapping arrival departure intervals satisfying Eq. (13). decision variable xij{0, 1} indicates bid matches ask j. provides optimal, offline allocativeefficiency.6.4 Greedy Online Matchingimplement greedy matching algorithm immediately matches offers yield nonnegative budget surplus. non-truthful matching rule provides additionalcomparison point efficiency matching schemes. time period,greedy matching algorithm orders active bids asks valuations, exactlyMcAfee mechanism does, matches offers pairs longer generate positivesurplus. algorithms performance allows us infer number offersoptimal matching defers matching amount surplus lost McAfeemethod due trade reduction due additional constraint admission pricing.6.5 Worst-Case Optimal MatchingBlum et al. (2006) derive mechanism equivalent fixed-price matching mechanism,except price used chosen cumulative distribution1lnD(x) =rx wmin(r 1)wmin,(15)r fixed point equationr = lnwmax wmin(r 1)wmin,(16)wmin 0 wmax 0 minimum maximum absolute valuationstraders market. simulations, give mechanism exact knowledgeminimum maximum absolute valuations schedule. Blum et al. (2006) showmethod guarantees expected competitive ratio max(2, ln(wmax /wmin ))respect optimal offline solution adversarial setting. interested seeperformed practice simulations.163fiBredin, Parkes Duong6.6 Strategic Open-outcry Matching: ZIP Agentscompare Chain existing literature continuous double auctions, implementDA every period sorts active offers matches highest valued bidslowest valued asks long match yields positive net surplus. DA pricestrading pair mean pairs declared valuations. Since trade price dependsbidders declaration, market support truthful bidding strategies. musttherefore adopt method simulate behavior bidding agents within simple openoutcry market.this, randomly assign bid one several protocol agents usemodified ZIP trading algorithm, initially presented Cliff Bruten (1998)improved upon Preist van Tol (1998). ZIP algorithm common benchmarkused compare learned bidding behavior simple double-auction trading environmentagents present adjust bids seeking profitable trade.adapt ZIP algorithm use dynamic environment.experiments consider five protocol agents. New offers assigneduniformly random protocol agent, remains persistent throughout simulation. offer associated patience category, k {low, medium, high}, definedevenly partition range possible offer patience. protocol agent, j, definedparameters (rj , j , j ) maintains profit margin, kj , patience category k.Parameters (j , j ) control adaptivity protocol agent adjusts targetprofit margin individual offer, j U (0.1, 0.2) defining offer-level learningrate j U (0.2, 0.8) defining offer-level damping factor. Parameter rj [0, 1]learning rate adopted updating profit margins.protocol agents trained 10 trials final performance measured11th trial. learning rate decreases training session dependsinitial learning rate rj0 adjustment rate rj+ . period {1, . . . , tkend } trialk {1, . . . , + 1}, = 10 number trials used training tkendnumber periods trial k, learning rate defined as:rj := 1rj0+ (k1)rj++tkend2rj+!(17)rj+ = (1 rj0 )/(T + 1). define rj0 := 0.7. effect adjustment rulerj initially 0.3, decreases training, trends 0.0 tend trial k = 11.Within given trial, upon assignment new offer patience category k, protocolagent managing offer initializes (i (t), (t)) := (kj , 0), (t) represents targetprofit margin offer (t) represents profit-margin correction term. targetprofit margin profit margin correction term adjusted offer subsequentperiods bid remains active.target profit margin used define bid price offer periodremains active:wi (t) := wi (1 + (t)).164(18)fiChain: Online Double Auctionend period offer matches simply expires, profit marginkj patience category updated as:kj := (1 rj )kj + rj (t),(19)amount adaptivity depends learning rate rj . profit marginoffer decays lifetime, update adjusts towards small profit marginoffer expires took many periods trade, larger profit margin otherwise.long-term learning protocol agent occurs profit margin assignedpatience category.start period protocol agent also computes target prices bidsasks patience category. used drive adjustment target profitmargin active bid ask. Target prices bk (t) sk (t) computed as:{wi (t 1)} + , 0 > max {wi (t 1)} + max {wi (t 1)}(1 + ) maxiS(t1)iB k (t1)iB k (t1)kb (t) :=(1 ) max {wi (t 1)} , otherwiseiB k (t1)(20)and,sk (t):=(1 + )(1 )max {wi (t 1)} + , 0 > max {wi (t 1)} + max {wi (t 1)}iB(t1)k (t1)k (t1)max {wi (t 1)} , otherwisek (t1)(21), U (0, 0.05). Here, B(t 1) S(t 1) denote set active bids asksmarket period 1 (defined market clearing), B k (t 1) k (t 1)denote restrictions patience category k. target price bid category kset something slightly greater competitive bid previous roundbid could trade, slightly less otherwise. Similarly target priceasks, prices negative, increasing target price makes askcompetitive.Target prices used adjust target profit margin start periodactive offers arrived earlier period, influence target pricesprofit-margin correction term:(t) :=(wi (t 1) + (t))1,wi(22)profit-margin correction term, (t), defined terms target price ik (t)(equal bk (t) bid sk (t) otherwise) as,(t) := j (t 1) + (1 j )j (ik (t) wi (t 1)),(23)j j offer-level learning rates damping factor. value wi-1 term Eq. (22) provide normalization. Eq. (23) Widrow-Hoff (Hassoun, 1995)rule, designed minimize least mean square error profit margin adoptedmimic earlier ZIP designs.165fiBredin, Parkes Duong6.7 Experimental Resultsexperimental results show market conditions drive DA choice. compare allocative efficiency, revenue, net efficiency. results averaged 100 trials.experiments found minimal qualitative differences use twopatience distributions. uniform patience distribution provides slight increase efficiency result using exponential patience, caused larger proportion patientagents relaxes somewhat admission-price constraint Eq. (3). reasonchoose report results uniform patience distribution.performance methods summarized Table 3, omit performance markets plots keep presentation results clear possible.plot price-based results median- clearing-based pricesperformance typically around performance Chain instantiatedhistory-EWMA price. plot windowed-McAfee results inconsistent performance, cases, upon manual inspection, optimal choosesmallest possible window size, i.e. including active bids making equivalentactive-McAfee.plots also leave performance Blum et al. (2006) worst-case optimalmatching scheme dominated fixed-price Chain instantiationmany cases failed yield substantial surplus. note modeling assumption made Blum et al. (2006) quite different work: worryperformance adversarial environment consider probabilistic environments.fixed-price Chain mechanism operates essentially identically surplus-maximizingscheme Blum et al. (2006), except Chain also use additional statistical information set ideal price, rather drawing price distribution usedguarantee worst-case performance adversary. defer results Blumet al. (2006) scheme Table 3.Figures 58 plot results two sets experiments, one high-patience/low-volatilityone low-patience/high-volatility, vary inter-arrival time (and thusarrival intensity), volatility maximal patience. plots allocative efficiencyexcept Figure 6, consider net efficiency. Active-McAfee included Figure 5,plots improve upon McAfee performanceenvironments. emphasize: results greedy provide upper-boundbest possible performance non-truthful algorithm, simulatedtruthful inputs.Figure 5 (left) see within truthful DAs, McAfee-based DAbest efficiency medium low arrival intensities. also general decreaseperformance, relative optimal offline solution, arrival intensity falls.trend, also observed greedy (non-truthful) DA, occurs Chain schememyopic matches soon static DA building block finds match,better less myopic arrival intensity low. McAfee-based DAs lesssensitive methods aggressively update prices usingactive traders. price-based DAs experience inefficiencies due lag price updatesuse expired, traded, priced-out offers calculate prices.166fiChain: Online Double Auction(patience=6, volatility=0.01)greedyzipmcafeeewmaactive-mcafeefixed-price1.21greedymcafeeactive-mcafeeewmafixed-pricezip1.4Allocative Efficiency1.4Allocative Efficiency(patience=2, volatility=0.08)0.80.60.40.21.210.80.60.40.20000.20.40.60.81Inter-arrival Time1.21.400.20.40.60.81Inter-arrival Time1.21.4Figure 5: Allocative efficiency vs. inter-arrival time (1 / intensity) several DAs. leftplot shows high-patience, low-volatility simulations, whereas right plots resultslow-patience, high-volatility runs. sets experiments use uniform patience distributions.(patience=6, volatility=0.01)greedyzipmcafeeewmaactive-mcafeefixed-price1.21greedymcafeeactive-mcafeeewmafixed-pricezip1.41.2Net Efficiency1.4Net Efficiency(patience=2, volatility=0.08)0.80.610.80.60.40.40.20.20000.20.40.60.81Inter-arrival Time1.21.400.20.40.60.81Inter-arrival Time1.21.4Figure 6: Net efficiency vs. inter-arrival time (1 / intensity) several DAs. left plotshows high-patience, low-volatility simulations, whereas right plots results lowpatience, high-volatility runs. sets experiments use uniform patience distributions.167fiBredin, Parkes Duonghigh arrival intensity see Active-McAfee dominates McAfee. Active-McAfeesmooths price, helps mitigate impact fluctuations cost admissionprice via Eq. (3) return less responsiveness. helpful well-behaved marketshigh arrival intensity low volatility helpful environmentsstudied, additional responsiveness provided (vanilla) McAfee scheme paidoff.ZIP market also good performance high-patience/low-volatility environment. reason simple: easy environment simple learning agents,agents quickly learn truthful. emphasize ZIP market resultstreated caution certainly optimistic. ZIP agentsprogrammed consider timing-based manipulations. effect environmentZIP market tends operate truthful market, without cost imposingtruthfulness explicitly via market-clearing rules. comparison Chain auctionsfully strategyproof, value temporal manipulations.Compare Figure 5 (right), low patience high volatility.see McAfee dominates across range arrival intensities. Moreover, performanceZIP quite poor agents enough time adjust bids(patience low) high volatility makes difficult environment. volatilevaluations, possibility valuation swings leaves open possibility larger profits,luring agents set wider profit margins, market changes. ZIP agentsalso fewer concurrent competitive offers use setting useful price targetslearning. might expect, high volatility also negatively impacts efficiencyfixed-price scheme.Figure 6 see net efficiency trends qualitatively similar exceptcompetition-based DAs McAfee fare less well comparison price-basedDAs. auctioneer accrues revenue competition-based matching rulesMcAfee often generate buy sell prices spread. Togethercompetition-based schemes intrinsically dynamic, drives increasedprice spread Chain via admission price constraints. Figure 6 (left) seefixed-price scheme performs well high arrival intensity EWMA dominatesintermediate arrival intensities. McAfee scheme still dominant lower patiencehigher volatility (Figure 6, right).reinforce observations, Table 3 present net efficiency, allocativeefficiency (normalized) revenue across arrival intensities (i.e. inter-arrival time0.05 1.5) low high volatility trials. five price-based methods,three competition-based methods, three comparison methods included.highlight best performing competition-based method, price-based method, wellperformance ZIP market (skipping non-truthful, greedy algorithm).omit information mean standard error measurement caseerror exceed tenth percent mean optimal surplus. withintruthful DAs, see McAfee-based scheme dominates overall allocativenet efficiency low high volatility, although EWMA competes McAfeenet efficiency low volatility markets. Notice also good performance ZIPbased market (with aforementioned caveat restricted strategy space) lowvolatilities.168fiChain: Online Double Auctionscenariolow-volt/high-pathigh-volt/low-patnetalloc revnetalloc rev0.33 0.47 0.14 0.40 0.45 0.050.24 0.35 0.11 0.32 0.37 0.050.24 0.26 0.02 0.21 0.23 0.030.33 0.34 0.01 0.17 0.17 0.010.33 0.35 0.03 0.19 0.22 0.030.23 0.23 0.00 0.04 0.04 0.000.33 0.34 0.01 0.15 0.16 0.010.33 0.34 0.01 0.17 0.18 0.010.10 0.10 0.00 0.02 0.02 0.000.86 0.86 0.00 0.87 0.87 0.000.82 0.82 0.00 0.23 0.23 0.00mcafeeactive-mcafeewindowed-mcafeehistory-clearinghistory-ewmahistory-fixedhistory-mcafeehistory-medianblum et al.greedyzipTable 3: Net efficiency, allocative efficiency auctioneer revenue (all normalized optimalvalue trade), averaged across arrival intensities (0.051.5) low highvalue volatility. best performing competition-based, price-based (ignoringgreedy, truthful) results highlighted.(patience=6, inter-arrival=1.0)1.4greedyzipmcafeeewmafixed-price1greedymcafeeewmazipfixed-price1.2Allocative Efficiency1.2Allocative Efficiency(patience=2, inter-arrival=1.0)1.40.80.60.40.210.80.60.40.20000.020.040.060.080.10.120.140Volatility0.02 0.04 0.06 0.080.10.12 0.14VolatilityFigure 7: Allocative efficiency vs. volatility several DAs fairly low arrival intensity.left plot large maximal patience right plot small maximal patience.sets experiments use uniform patience distributions.Figure 7 plots allocative efficiency versus volatility high patience (left) lowpatience (right) fairly low arrival intensity. Higher volatility hurts methodsespecially ZIP agents, struggle learn appropriate profit price targets,probably due opportunities update prices every individual offer. McAfeescheme fairs well, showing good robustness large patience small patienceenvironments. fixed-price scheme best performance zero volatilityefficiency falls extremely quickly volatility increases.169fiBredin, Parkes Duong(inter-arrival=1.0, volatility=0.01)1.4greedyzipmcafeeewmafixed-price1greedyzipmcafeeewmafixed-price1.2Allocative Efficiency1.2Allocative Efficiency(inter-arrival=1.0, volatility=0.08)1.40.80.60.40.210.80.60.40.2000246Maximal Patience8100246Maximal Patience810Figure 8: Allocative efficiency vs. maximal patience several DAs fairly low arrival intensity.left plot low volatility right plot high volatility. setsexperiments use uniform patience distributions.also consider effect varying maximal patience. shown Figure 8,low volatility (left) high volatility (right). Again, McAfee scheme besttruthful DAs based Chain. also see performance ZIP improvespatience increases due opportunities learning. Perversely, larger patiencenegatively affect truthful DAs. part simply performancegreedy online schemes, relative offline optimal, decreases patience increasesoffline optimal matching able draw benefit lack myopia.also suspected another culprit, however. possibility presence patientagents requires truthful DAs include additional terms max operator Eq. (3)prevent manipulations, leading higher admission prices less admitted offers.better understand effect experimented delayed market clearing McAfeescheme, market matches agents every -th period (the clearing duration).idea make tradeoff using fewer admission prices possibilitymiss opportunity match impatient offers.Figure 9 shows allocative efficiency matching mechanism clears less frequentlydifferent maximal patience, K. Figure 9 (left) low volatility.see best clearing duration roughly 1, 2, 3 4 maximal patience K{4, 6, 8, 10} optimizing clearing duration performance McAfee remainsapproximately constant maximal patience increases. Figure 9 (right) considereffect high volatility environment, results averaged 500 trialsperformance DA higher variance. see qualitatively similar trend, althoughhigher maximal patience hurts overall cannot fully compensated tuningclearing duration.7. Related WorkStatic two-sided market problems widely studied (Myerson & Satterthwaite, 1983;Chatterjee & Samuelson, 1987; Satterthwaite & Williams, 1989; Yoon, 2001; Deshmukh170fiChain: Online Double Auction(inter-arrival=1.0 patience=K, volatility=0.01)(inter-arrival=1.0 patience=K, volatility=0.08)0.550.450.4Allocative EfficiencyAllocative Efficiency0.50.450.40.350.3K=4K=6K=8K=100.250.20.1500.350.30.25K=4K=6K=8K=100.20.15246Clearing Duration8100246Clearing Duration810Figure 9: Allocative efficiency vs. clearing duration McAfee-based Chain auction fairlylow arrival intensity maximal patience varied 4 10. left plotlow volatility right plot high volatility. sets experiments useuniform patience distributions.et al., 2002). classic result, Myerson Satterthwaite proved impossibleachieve efficiency voluntary participation without running deficit, even relaxingdominant-strategy equilibrium Bayesian-Nash equilibrium. truthful DAsknown static problems (McAfee, 1992; Huang et al., 2002; Babaioff & Nisan, 2004;Babaioff & Walsh, 2005). instance, McAfee introduced DA sometimes forfeitstrade return achieving truthfulness. McAfees auction achieves asymptotic efficiencynumber buyers sellers increases. Huang et al. extend McAfees mechanismhandle agents exchanging multiple units single commodity. Babaioff colleaguesconsidered extensions work supply-chain spatially distributed markets.problem also similar traditional continuous double auction (CDA),buyers sellers may time submit offers market pairs offer soonmatching offer submitted. Early work considered market efficiency CDAshuman experiments labs (Smith, 1962), recent work investigates use softwareagents execute trades (Rust et al., 1994; Cliff & Bruten, 1998; Gjerstad & Dickhaut,1998; Tesauro & Bredin, 2002). markets dominant strategy equilibria,populations software trading agents learn extract virtually available surplus,even simple automated trading strategies outperform human traders (Das et al., 2001).However, studies CDAs assume traders share known deadlinetrades must executed. quite different setting, dynamicarrival departure.Truthful one-sided online auctions, agents arrive depart across time,received recent attention (Lavi & Nisan, 2000; Hajiaghayi et al., 2004, 2005; Porter,2004; Lavi & Nisan, 2005). adopt extend monotonicity-based truthful characterization work Hajiaghayi et al. (2005) developing framework truthfulDAs. model DAs must also address constraints timingoccur Porter, Hajiaghayi, Lavi Nisans work. previous works, items171fiBredin, Parkes Duongreusable expiring could allocated particular periods. workprovide limited allowance match-maker, allowing hold onto sellers itemmatched buyer ready depart (perhaps seller departed).closest work literature due Blum et al. (2006), present online matching algorithms dynamic DA model. main focus paperdesign matching algorithms good worst-case performance adversarial setting,i.e. within framework competitive analysis. Issues related incentive compatibilityreceive less attention. One way work general also studygoals profit maximizing number trades, addition goal maximizingsocial welfare consider work. However, algorithmic resultpresent truthful model (where agents misreport arrival departure)goal social welfare. DA describe instance Chainfixed price drawn distribution start time, used matchingprice every period. Perhaps unsurprisingly, given worst-case approach, observeauction performs significantly worse Chain defined fixed pricepicked optimize welfare given distributional information domain.8. Conclusionspresented general framework construct algorithms match buyers sellersonline markets valuation activity-period information private agents.algorithms guarantee truthful dominant strategies first imposing minimum admission price offer pricing pairing offer first opportunity.heart Chain framework lies pricing algorithm must offer eitherdetermine price independent information describing offer choose discardoffer. pricing algorithm chosen match market conditions. presentseveral examples suitable pricing schemes, including fixed-price, moving-average,McAfee-based schemes.often not, find competition-based scheme employs McAfeebased rule truthfully price market delivers best allocative efficiency. exceptionally low volatility high arrival intensity, find adaptive price-based schemesexponentially-weighted moving average (EWMA) even fixed price schemesperform well. see qualitatively similar results net efficiency, revenueaccrues auctioneer discounted, albeit price-based rules EWMAimproved performance price spread. observations rootedsimulations comparing market efficiency mechanism optimal offline solution.Additionally, compare efficiency truthful markets fixed-price worstcase optimal scheme presented Blum et al. (2006), market strategic agents usingvariant ZIP price update algorithm developed Cliff Bruten (1998)continuous double auctions, non-truthful, greedy matching algorithm provideupper-bound performance. best schemes yield around 33% net efficiencylow volatility, high patience environments 40% net efficiency high volatility, lowpatience environments, greedy bound suggests much 86% efficiencypossible non-strategic agents. note Blum et al.scheme, designedadversarial settings, fairs poorly simulations (< 10%).172fiChain: Online Double AuctionOne argue, think convincingly, truthfulness brings benefitsavoids waste costly counterspeculation promotes fairness markets (Sandholm,2000; Abdulkadiroglu et al., 2006). hand, certainly interestgap efficiency greedy matching non-truthful matchingtruthful auctions large. Here, observe ZIP-populated (non-truthful)markets achieve around 82% efficiency low volatility environments collapse around23% efficiency high volatility environments. Based this, one might conjecturedesigning truthfulness especially important badly behaved, highly volatile (thin)environments less important well behaved, less volatile (thick) environments.Formalizing tradeoff providing absolute truthfulness approximatetruthfulness, considering nature environment, interesting direction future work (see paper Parkes et al., 2001). Given reporting marketstatistics incorporated within framework (see Section 5.1), given markets also play role information aggregation value discovery, future researchalso consider additional aspect market design. Perhaps interesting tradeoffefficiency, truthful value revelation, process information aggregation.general Chain framework achieves good efficiency, tuning seems possible. One direction adopt meta-pricing scheme chooses, blends, pricescompeting algorithms. Another direction consider richer temporal models; e.g.,value goods agents might decay grow time better account timevalue assets. richer temporal model might also consider possibility agentsmatch-maker taking short positions (including short-term cash deficits) increase trade.also interesting extend work markets non-identical goodscomplex valuation models bundle trades (Chu & Shen, 2007; Babaioff & Walsh,2005; Gonen et al., 2007), dynamic matching problems without prices,online variation classic marriage problem (Gusfield & Irving, 1989).Acknowledgmentsearlier version paper appeared Proceedings 21st Conference Uncertainty Artificial Intelligence, 2005. paper characterizes necessary conditionstruthful online trade; truthfully matches offers using generalized framework basedupon arbitrary truthful static pricing rule; compares efficiency truthfulframework achieved non-truthful markets populated strategic trading agentsworst-case optimal double auctions.Parkes supported part NSF grant IIS-0238147 Alfred P. Sloan FellowshipBredin would like thank Harvard School Engineering Applied Scienceshosting sabbatical much work completed. Thanks alsothree anonymous reviewers, provided excellent suggestions improving earlierdraft paper.Appendix: ProofsLemma 1 Procedure Match defines valid strong no-trade construction.173fiBredin, Parkes DuongProof: cases, SNTt NTt . set NTt correctly constructed: equalremaining bids bt (j = 0) Case I, remaining bids st (i = 0) Case II,remaining bids asks otherwise. case, bid (or ask) NTt couldtraded price available bid ask opposite marketgiven order.verifying strong no-trade (SNT) conditions (a) (b), proceed case analysis.Case I. (i 6= 0) (j = 0). NTt := bt .(I-1) k st (dk = t) SNTt := bt . SNT-a, consider l NTt dl > t.l deviates changes remain Case NTt unchanged stillcontains l. l deviates 0 then, go Case III SNTt := bt st stillcontains l. SNT-b, consider l SNTt deviates dl > t. Again, eitherremain case SNTt unchanged 0 go Case III.SNTt still contains bt therefore unchanged agents dk > t.(I-2) Buyer k bt dk = bk pt SNTt := bt . SNT-a, consider l NTtdl > t. remain case deviation buyer l buyer kensure 6= 0, SNTt remains unchanged still contains l. SNT-b,l SNTt dl > deviates remain case SNTt unchanged.(I-3) seller dk > buyer dk = willing accept price.SNTt := bt \ checkedB . SNT-a, consider l NTt dl > t. First, supposel checkedB 6= l. l deviates still dl > t, even := lremain case l enter SNTt . Second, suppose l checkedB(i = l). l deviates still dl > t, even (i = 0) (j = 0), goCase III SNTt = l enter SNTt . Third, suppose l/ checkedBdl > t. Deviating dl > effect remain case lremains SNTt . SNT-b, consider l SNTt dl > t, i.e. l/ checkedB .l deviates dl > t, effect remain case SNTtremains unchanged.Case II. (j 6= 0) (i = 0). NTt := st . Symmetric Case I.Case III. (i = 0) (j = 0). NTt := bt st .(III-1) k bt (dk = t) k st (dk > t) SNTt := bt st . SNT-a, considerl NTt dl > t. must ask. l deviates remain case,l remains SNTt . j := l, go Case II SNTt := st l remainsSNTt . SNT-b, consider l SNTt dl > t, must ask. ldeviates remain case, SNTt unchanged. l deviates j := l,go Case II, SNTt := st , buyers bt removed SNTt . OKbuyers depart period anyway.(III-2) k st cdot(dk = t) k bt (dk > t) SNTt := bt st . Symmetric CaseIII-1.(III-3) k bt (dk = t) k st cdot(dk = t). SNTt := bt st . SNT-a SNT-btrivially met bids asks departure past current period.174fiChain: Online Double Auction(III-4) k bt (dk > t) k st (dk > t) SNTt := . SNT-a, consider l NTtdl > t. Assume l bid. l deviates dl > = 0 remaincase l SNTt . l deviates dl > := l, goCase necessarily Sub-case (I-a) dl >bid willing accept price (else 6= 0 first place). Thus, wouldSNTt := bt \ checkedB l would SNTt . SNT-b, triviallysatisfied agents l SNTt .Lemma 5 set active agents (other i) period Chain independentreport agent remains active, would unchanged arrival laterperiod t.Proof: Fix arrival period ai . Show ai ai , set active agents periodai active without agent arrival ai > t. Proceedinduction number periods ai . period = ai trivial.consider period ai + r, r 1 assume inductive hypothesisai + r 1. Since still active then, SNTt = ai + r 1, thereforeagents SNTt survive period independent agent report strongno-trade condition (b). completes proof.Lemma 6 price constructed admission price q post-arrival price p valueindependent monotonic-increasing matching rule Chain well-defined,strong no-trade construction valid, agent patience bounded K.Proof: First fix ai , di . show value-independence (B1), first note qvalue-independent, since whether SNTt pre-arrival period valueindependent strong no-trade condition (a) price zi (H , \ i, ) periodagent-independent definition. Term p also value-independent: decision periodagent i, any, independent wi since agents remain activeindependent agent active Lemma 5, whether SNTtvalue-independent strong no-trade (a); price value-independentset active agents value-independent.fix show price monotonically-increasing tighter arrival-departureinterval (B2). First note q monotonic-increasing [ai , di ] [ai , di ] earlierdi later ai increases domain [di K, ai 1] q defined. Fixai ai . Argue price increases earlier di di , di > ai . see this, noteeither di < pi (ai , di , , ) = di di , di price constantdi < point becomes . Fix di ai . Argue price increaseslater ai ai , ai di K. First, ai t, p unchanged Lemma 5.interesting case ai > t, especially q(ai , di , , ) < p(ai , di , , ).reporting later arrival, agent delay decision period perhaps hopeachieve lower price. But, note case [di K, ai 1] since di K ai[ai , ai 1] q(ai , di , , ) p(H , \ i, ) q includes priceperiod since/ SNTt pre-arrival period Lemma 5. Overall, seealthough p may decrease, max(q, p) cannot decrease.175fiBredin, Parkes DuongLemma 7 strongly truthful, canonical dynamic DA must define price pi (ai , di , , )zi (H , \ i, ) decision period bid (if exists). Moreover, bidmust priced-out period matched.Proof: (a) First, suppose zi (H , \ i, ) > wi bid priced-out insteadsurvives active bid next period./ SNTt , set active bidsperiod +1 need independent agent bid price zi (H t+1 , At+1 \ i, )need agent-independent. Yet, canonical rule (iii) requires price useddetermine whether agent matches, dynamic DA needtruthful. (b) assume contradiction pi (ai , di , , ) < zi (H , \ i, ). First,zi (H , \ i, ) < , agent value pi (ai , di , , ) < wi < zi (H , \ i, )report wi = zi (H , \ i, ) + trade final payment less truevalue (whereas would priced-out reported true value). zi (H , \i, ) = ,pi (ai , di , , ) < zi (H , \i, ) implies bids survive period eventhough priced-out matching rule strong no-trade set.compromises truthfulness dynamic DA, discussed part (a).Lemma 8 strongly truthful, canonical individual-rational dynamic DA must defineprice pi (ai , di , , ) q(ai , di , , ), bid wi < q(ai , di , , ) must pricedout upon admission.Proof: Suppose di < ai + K [di K, ai 1] non-empty. di = ai + K 1,= di K decision period (and/ SNTt ),pi (ai , di , , ) pi (di K, di , , ) zi (H , \ i, ),(24)first inequality monotonicity (B2) second follows Lemma 7since di K decision period, would remain one report = (di K, di , wi )Lemma 5. establishes pi (ai , di , , ) q(ai , di , , ) di = ai + K 1.di = ai + K 2, need Eq. (24), also = di K + 1 decision period(and/ SNTt ) have,pi (ai , di , , ) pi (di K + 1, di , , ) zi (H , \ i, ),(25)reasoning above. generalizes di = ai + K r r {2, . . . , K}establish pi (ai , di , , ) q(ai , di , , ) general case. see bid mustpriced-out wi < q(ai , di , , ), note remain active could matchmatching rule canonical (iii) need trade, thus fail individual-rationalitysince payment collected would value.ReferencesAbdulkadiroglu, A., Pathak, P. A., Roth, A. E., & Sonmez, T. (2006). Changing Bostonschool choice mechanism. Tech. rep., National Bureau Economic Research WorkingPaper No. 11965.Archer, A., & Tardos, E. (2001). Truthful mechanisms one-parameter agents. Proceedings 42nd IEEE Symposium Foundations Computer Science, pp. 482491.176fiChain: Online Double AuctionBabaioff, M., & Nisan, N. (2004). Concurrent auctions across supply chain. JournalArtificial Intelligence Research, 21, 595629.Babaioff, M., Nisan, N., & Pavlov, E. (2001). Mechanisms spatially distributed market.Proceedings 5th ACM Conference Electronic Commerce, pp. 920.Babaioff, M., & Walsh, W. E. (2005). Incentive-compatible, budget-balanced, yet highlyefficient auctions supply chain formation. Decision Support Systems, 39, 123149.Blum, A., Sandholm, T., & Zinkevich, M. (2006). Online algorithms market clearing.Journal ACM, 53, 845879.Chatterjee, K., & Samuelson, L. (1987). Bargaining two-sided incomplete information:infinite horizon model alternating offers. Review Economic Studies, 54,175192.Chu, L. Y., & Shen, Z. M. (2007). Truthful double auction mechanisms e-marketplace.Operations Research. appear.Cliff, D., & Bruten, J. (1998). Simple bargaining agents decentralized market-basedcontrol.. Proceedings European Simulation Multiconference Simulation Past, Present Future, pp. 478485, Manchester, UK.Copeland, T. E., & Weston, J. F. (1992). Financial Theory Corporate Policy (Thirdedition). Addison-Wesley, Reading, MA.Das, R., Hanson, J. E., Kephart, J. O., & Tesauro, G. (2001). Agent-human interactionscontinuous double auction. Proceedings 17th International JointConference Artificial Intelligence, pp. 11691187.Deshmukh, K., Goldberg, A. V., Hartline, J. D., & Karlin, A. R. (2002). Truthful competitive double auctions. Proceedings European Symposium Algorithms,pp. 361373.Gerkey, B. P., & Mataric, M. J. (2002). Sold!: Auction methods multirobot coordination.IEEE Transactions Robotics Automation, 18 (5), 758768.Gjerstad, S., & Dickhaut, J. (1998). Price formation double auctions. GamesEconomic Behavior, 22 (1), 129.Goldberg, A., & Hartline, J. (2003). Envy-free auctions digital goods. Proceedings4th ACM Conference Electronic Commerce, pp. 2935.Gonen, M., Gonen, R., & Pavlov, E. (2007). Generalized trade reduction mechanisms.Proceedings 8th ACM Conference Electronic Commerce, pp. 2029.Gusfield, D., & Irving, R. W. (1989). Stable Marriage Problem: Structure Algorithms. MIT Press, Cambridge, MA.Hajiaghayi, M. T., Kleinberg, R., Mahdian, M., & Parkes, D. C. (2005). Online auctionsre-usable goods. Proceedings 6th ACM Conference Electronic Commerce,pp. 165174.Hajiaghayi, M. T., Kleinberg, R., & Parkes, D. C. (2004). Adaptive limited-supply onlineauctions. Proceedings 5th ACM Conference Electronic Commerce, pp.7180.177fiBredin, Parkes DuongHassoun, M. H. (1995). Fundamentals Artificial Neural Networks. MIT Press, Cambridge,MA.Huang, P., Scheller-Wolf, A., & Sycara, K. (2002). Design multi-unit double auctione-market. Computational Intelligence, 18, 596617.Lagoudakis, M., Markakis, V., Kempe, D., Keskinocak, P., Koenig, S., Kleywegt, A., Tovey,C., Meyerson, A., & Jain, S. (2005). Auction-based multi-robot routing. ProceedingsRobotics Science Systems Conference, pp. 343350.Lavi, R., & Nisan, N. (2005). Online ascending auctions gradually expiring goods.Proceedings ACM-SIAM Symposium Discrete Algorithms, pp. 11461155.Lavi, R., & Nisan, N. (2000). Competitive analysis incentive compatible on-line auctions.Proceedings 2nd ACM Conference Electronic Commerce, pp. 233241.Lin, L., & Zheng, Z. (2005). Combinatorial bids based multi-robot task allocation method.Proceedings 2005 IEEE International Conference Robotics Automation, pp. 11451150.McAfee, R. P. (1992). dominant strategy double auction. Journal Economic Theory,56 (2), 434450.Myerson, R. B., & Satterthwaite, M. A. (1983). Efficient mechanisms bilateral trading.Journal Economic Theory, 29, 265281.Pai, M., & Vohra, R. (2006). Optimal dynamic auctions. Tech. rep., Kellogg SchoolManagement, Northwestern University.Parkes, D. C. (2007). Online mechanisms. Nisan, N., Roughgarden, T., Tardos, E., &Vazirani, V. (Eds.), Algorithmic Game Theory, chap. 16. Cambridge University Press.Parkes, D. C., Kalagnanam, J. R., & Eso, M. (2001). Achieving budget-balanceVickrey-based payment schemes exchanges. Proceedings 17th International Joint Conference Artificial Intelligence, pp. 11611168.Porter, R. (2004). Mechanism design online real-time scheduling. Proceedings5th ACM Conference Electronic Commerce, pp. 6170.Preist, C., & van Tol, M. (1998). Adaptive agents persistent shout double auction.Proceedings First International Conference Information ComputationEconomies, pp. 1118.Rust, J., Miller, J., & Palmer, R. (1994). Characterizing effective trading strategies: Insightscomputerized double auction tournament. Journal Economic DynamicsControl, 18, 6196.Sandholm, T. (2000). Issues computational Vickrey auctions. International JournalElectronic Commerce, 4 (3), 107129.Satterthwaite, M. A., & Williams, S. R. (1989). Bilateral trade sealed bid k-doubleauction: Existence efficiency. Journal Economic Theory, 48, 107133.Smith, V. L. (1962). experimental study competitive market behavior. JournalPolitical Economy, 70, 111137.178fiChain: Online Double AuctionTesauro, G., & Bredin, J. (2002). Strategic sequential bidding auctions using dynamic programming. Proceedings First International Joint Conference AutonomousAgents Multiagent Systems, pp. 591598, Bologna, Italy.Yoon, K. (2001). Modified Vickrey Double Auction. Journal Economic Theory, 101,572584.179fiJournal Artificial Intelligence Research 30 (2007) 51 - 100Submitted 03/07; published 09/07Graph Abstraction Real-time Heuristic SearchVadim BulitkoNathan SturtevantJieshan LuTimothy YauBULITKO @ UALBERTA . CANATHANST @ CS . UALBERTA . CAJIESHAN @ CS . UALBERTA . CATHYAU @ UALBERTA . CADepartment Computing Science, University AlbertaEdmonton, Alberta, T6G 2E8, CANADAAbstractReal-time heuristic search methods used situated agents applications requireamount planning per move independent problem size. agents planactions time local search space avoid getting trapped local minima improving heuristic function time. extend wide class real-time search algorithmsautomatically-built state abstraction prove completeness convergence resultingfamily algorithms. analyze impact abstraction extensive empirical studyreal-time pathfinding. Abstraction found improve efficiency providing better trading offsplanning time, learning speed negatively correlated performance measures.Keywords: learning real-time heuristic search, state abstraction, goal-directed navigation.1. Introduction Motivationpaper study problem agent-centered real-time heuristic search (Koenig, 2001).distinctive property search agent must repeatedly plan execute actionswithin constant time interval independent size problem solved.restriction severely limits range applicable algorithms. instance, static search algorithms(e.g., A* Hart, Nilsson, & Raphael, 1968), re-planning algorithms (e.g., D* Stenz, 1995),anytime algorithms (e.g., ARA* Likhachev, Gordon, & Thrun, 2004) anytime re-planningalgorithms (e.g., AD* Likhachev, Ferguson, Gordon, Stentz, & Thrun, 2005) cannot guaranteeconstant bound planning time per action. LRTA* provides guarantees planningactions time updating heuristic function, solution quality poorlengthy convergence process (Korf, 1990; Ishida, 1992).motivating example, consider navigation gridworld maps commercial computergames. games, agent tasked go location map currentlocation. agent must react quickly users command regardless maps sizecomplexity. Consequently, game companies impose time-per-action limit pathfinding algorithms. example, Bioware Corp., major game company, limits planning time 1-3 mspathfinding units (and many units planning simultaneously).additional challenge comes form limited sensing virtual reality trainersArtificial Intelligence controlled characters may access entire map priori, orderavoid unrealistic behavior (Dini, van Lent, Carpenter, & Iyer, 2006). agents buildinternal map model based sensing limited amount map around position.efficient search agent would minimize delay incurred planning actions, explorelearn environment quickly, always discover optimal path goal. Unfortunately,c2007AI Access Foundation. rights reserved.fiB ULITKO , TURTEVANT, L U , & YAUmeasures negatively correlated (or antagonistic) optimizing performance onemeasure results worse performance one others. instance, reducing amountplanning done action improves agents response time, leads slower learningdue lower-quality actions taken agent.propose use graph abstraction improve efficiency search agents makefollowing four contributions. First, introduce new algorithm, Path Refinement LearningReal-time Search (PR LRTS)1 , enhances existing real-time heuristic search algorithmsautomatically-built graph abstraction. PR LRTS learns heuristic function abstract spacethereby substantially accelerating learning. Actions abstract space refined actionsenvironment A* algorithm. approach allows agents generate actions constanttime, explore environment quickly, converge near-optimal solutions. paper usepreviously published clique abstraction (Sturtevant & Buro, 2005). contributions specificabstraction three-fold. First, introduce initial clique building repair proceduredetail previously published. Second, prove worst-case bound suboptimalitypath induced abstraction. Third, present first application state abstractionreal-time heuristic search.standard practice heuristic search literature promote new algorithms tradingsmall amount one performance measure large gain another performance measure.instance, state abstraction non-real time heuristic search shown trade little solutionquality substantial reduction running time (e.g., Holte, Mkadmi, Zimmer, & MacDonald,1996; Botea, Muller, & Schaeffer, 2004). Unfortunately, always clear whether tradeoffs made optimally. second contribution, demonstrate PR LRTS outperformsnumber algorithms respect two antagonistic measures (e.g., learning speedamount planning per action).third contribution, analyze effects abstraction search respect commonlyused performance measures: solution suboptimality, amount planning per action, total travel,total planning time, memory footprint. Knowing effects deepens understanding realtime heuristic search methods well guides practitioner selecting appropriatesearch algorithm configuration application. Fourth, show theoretically PR LRTSunifies extends several well known existing heuristic search algorithms satisfies realtime operation, completeness, convergence properties. contribution viewedfollow-up previous unification extension efforts (Bulitko & Lee, 2006).rest paper organized follows. begin formulating problem real-timeheuristic search Section 2. new algorithm, PR LRTS, described Section 4. Empiricalresults follow Section 5. Theoretical results presented Section 6. review existingagent-centered search algorithms well work automatic graph abstraction Section 7.paper concluded discussion current limitations future research.2. Real-time Heuristic Searchdefining property real-time heuristic search amount planning performedagent per action constant upper-bound depend problem size. Low boundspreferred applications, guarantee agents fast response presented newgoal. real-time search agent plans next action considering states local search space1. early version algorithm published conference paper (Bulitko, Sturtevant, & Kazakevich, 2005).52fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCH1 sc s02 sc 6= sg3sense environment, update agents model4compute partial path p originates current state sc5execute p6update current state sc7 endFigure 1: Real-time heuristic search (a single trial).surrounding current position. heuristic function (or simply heuristic) estimates cumulativecost state goal, used agent rank available actions selectpromising one. process shown schematically Figure 1. Agents current state scset initial state s0 line 1. long goal sg reached (line 2), agent sensesenvironment around (see Section 3 details) updates model search graphoperating line 3. computes (partial) path current state toward goalstate line 4. real-time property requires lines 3 4 execute constant-bounded timeregardless problem size. accomplished calling real-time heuristic search algorithmline 4. paper, discuss three candidate algorithms: LRTA* Section 2.1, LRTSSection 2.2, PR LRTS Section 4. would called line 4. agentexecutes path line 5 updates current state line 6.trial defined agents problem-solving experience traveling start stategoal state. goal state reached, agent teleported start state nexttrial begins. convergence process defined first sequence trials agent longerupdates heuristic function model search problem. first trial without updatesfinal trial learning process said converged.2.1 Learning Real-time A* (LRTA*)first review best known real-time heuristic search algorithm, Learning Real-Time A*(LRTA*) (Korf, 1990). algorithm shown Figure 2. line 1, d-ply breadth-first searchduplicate detection used find frontier states precisely actions away current states. standard path-max (Mero, 1984) technique used deal possible inconsistenciesheuristic function computing g + h-values. value state, s, sumcost shortest path sc s, denoted g(s, s), estimated cost shortest pathsg (i.e., heuristic value h(s, sg )). state minimizes sum identified s0line 2. heuristic value current state updated line 3. Finally, path one actiontoward promising frontier state s0 returned line 4.path LRTA*(sc , sg , d)1234generate successor states sc actions awayfind state s0 lowest g(sc , s0 ) + h(s0 , sg )update h(sc , sg ) g(sc , s0 ) + h(s0 , sg ) greater current hreturn first action along optimal path sc s0Figure 2: LRTA* algorithm.53fiB ULITKO , TURTEVANT, L U , & YAU2.2 Learning Real-time Search (LRTS)LRTS extends LRTA* three ways: puts weight heuristic function, uses maxof-min learning rule, utilizes backtracking. review extensions detailSection 7.2 walk LRTS operation below. LRTS three control parameters: lookaheadN, optimality weight (0, 1], learning quota [0, ]. operates follows.current state sc , agent running LRTS conducts full-width d-ply lookahead search (line 1Figure 3). ply, finds promising state (line 2). Assuming initial heuristich admissible, safely increase h(sc ) maximum among f -values promising stateslevels (line 3). total learning amount u (updated line 4) exceeds learning quota, agent backtracks previous state planned (lines 5, 8). Otherwise, returnspath moves current state sc promising state level (line 6).learning amount u reset 0 agent start state (i.e., beginning trial).path LRTS(sc , sg , d, , )123generate successor states sc , actions away, = 1 . . .level i, find state si lowest f (si ) = g(sc , si ) + h(si , sg )update h(sc , sg ) max f (si ) greater current h456789increase amount learning u hureturn path actions sc sdelsereturn path actions backtrack previous state, set u =end1idFigure 3: LRTS algorithm.LRTS parameters previously studied length (Bulitko & Lee, 2006). summarize trends. Higher lookahead reduces convergence travel, convergence memory, suboptimality. However, increases first-move lag. lower heuristic weight leads less optimalsolutions and, generally speaking, reduces convergence travel convergence memory. First-movelag influenced . lower learning quota causes backtracking tends reduceconvergence travel convergence memory; affect first-move lag.2.3 NotationDefinition 2.1 search problem defined tuple (G, c, s0 , sg , h0 ) G = (S, E)directed weighted graph (henceforth search graph). finite set states (or vertices)E finite set edges them. edge weights defined cost functionc : E (0, ) c(s1 , s2 ) travel cost edge e = (s1 , s2 ). s0 startstate, sg goal state, h0 : [0, ) initial heuristic function. assumeh0 (sg ) = 0. Out-edges state called moves actions. number out-edges (i.e.,out-degree state) called branching factor state.Definition 2.2 solution search problem path start state s0 goal state sg .path denoted (s0 , s1 , . . . , sg ) si valid state valid edgepair states (si , si+1 ). travel cost path sum travel costs edges.54fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCHDefinition 2.3 times, search agent resides single search state sc called currentstate. agent change current state executing actions thus incurring travelcost. Initially, current state coincides start state s0 . agent said succeedmakes current state coincide goal state sg .assume goal state reachable state agent get startstate. needed completeness real-time heuristic search algorithms. also followstandard practice real-time heuristic search literature assume environmentstationary deterministic. Additionally, support backtracking (Shue & Zamani, 1993; Shue,Li, & Zamani, 2001) (i.e., reversing agents actions), require every action reverseaction. needed backtracking enabled algorithm.Definition 2.4 travel cost state s1 state s2 denoted dist(s1 , s2 ) defined costshortest path s1 s2 . Throughout paper, assume dist satisfies triangleinequality: s1 , s2 , s3 [dist(s1 , s3 ) dist(s1 , s2 ) + dist(s2 , s3 )]. Then, state, s, h (s)defined minimal travel cost goal: h (s) = dist(s, sg ). heuristic function, h,approximation h . admissible overestimate h : [h(s) h (s)]. valueh state referred heuristic value state s. assume heuristicfunction h(sg ) = 0 trivially holds admissible h.experiments break ties moves fixed fashion (e.g., always preferaction north, north east, east, etc.) entails agents behavioridentical trials final trial. necessarily mean entire search graphexplored learned heuristic accurate states.Definition 2.5 Convergence travel cumulative cost edges traversed agentconvergence process. Convergence planning amount planning effort expendedagent convergence process. first-move lag amount planning effort expendedagent first move final trial. Convergence memory measured totalnumber heuristic values stored convergence process. standard practice realtime heuristic search literature (e.g., Korf, 1990; Shimbo & Ishida, 2003) store heuristicvalues hash table. Hash table misses handled procedurally specified initial heuristic h0(e.g., Manhattan distance grid-based pathfinding). convergence memory numberentries hash table convergence. Finally, suboptimality defined percentage pointsfinal-trial solution cost excess relative shortest-path cost. instance, agentincurred travel cost 120 shortest-path cost 100, suboptimality 20%.measure planning effort two ways. First, report number states algorithmtouched (i.e., considered) planning. measure called edges traversed (e.g., Holteet al., 1996, p. 325). Second, report physical CPU time, measured 2.0GHz PowerPC G5computer gcc 4.0 Mac OS 10.4.8. measure convergence memory termsnumber heuristic values stored. meaningful heuristic value stored takesfixed amount memory (i.e., double type C++) implementation algorithm.Definition 2.6 search algorithm exhibits real-time performance heuristic search problemplanning effort per move constant-bounded constant independent problem size(assuming fixed maximum branching factor).55fiB ULITKO , TURTEVANT, L U , & YAUobjectives real-time search agent complete (i.e., arrive goal stateevery trial), converge (i.e., finish learning process finite number trials),minimize five performance measures described above. rest paper discussexisting new algorithms compare terms objectives.2.4 Application: Goal-directed NavigationOne motivating applications heuristic search goal-directed navigation, also knownpathfinding. special case heuristic search problem formalized previous sectionsearch graph (S, E) defined terrain map. Thus, states/vertices correspondgeographical positions map, edges describe passability blocking, cost functionrepresents difficulty/time traversing terrain.Real-time pathfinding motivated primarily time-sensitive robotics (e.g., Koenig & Simmons, 1998; Koenig, 1999; Kitano, Tadokoro, Noda, Matsubara, Takahashi, Shinjou, & Shimada,1999; Koenig, Tovey, & Smirnov, 2003) computer games. latter include real-time strategygames (e.g., Blizzard Entertainment, 2002), first-person shooters (e.g., id Software, 1993), roleplaying games (e.g., BioWare Corp., 1998). these, time plays critical role since numberagents perform pathfinding simultaneously gamers would like rapid response fluidgameplay. result, pathfinding become major computational expense: Age EmpiresII (Ensemble Studios, 1999) takes 60-70% simulation time (Pottinger, 2000).paper, follow footsteps Furcy Koenig (2000), Shimbo Ishida (2003),Koenig (2004), Botea et al. (2004), Hernandez Meseguer (2005a, 2005b), SigmundarsonBjornsson (2006), Koenig Likhachev (2006) situate empirical study navigationtwo-dimensional grid-based maps. cells square cell connected four cardinally(i.e., west, north, east, south) four diagonally neighboring cells. cell occupiedagent (i.e., free) wall (i.e., blocked).free grid cell constitutes vertex/state search space S. agent traveltwo free neighboring cells, s1 s2 , edge (s1 , s2) added set edges E.paper, set edge costs 1 cardinal moves 2 diagonal moves. cell initiallyoccupied agent s0 ; target cell sg . example converting grid-based mapsearch problem defined (G, c, s0 , sg , h0 ) shown Figure 4. Note allowdiagonal moves cut corners and, thus, state s6 connected states s1 , s5 , s7 , sg .done non-zero size agent able pass zero-width bottleneckformed two diagonally adjacent blocked cells. case one corner (e.g.,statess5 s6 Figure 4), allowing cut would lead actual travel distanceexceeding 2 since non-zero-width agent walk around corner.Video games often feature repeated pathfinding experiences map two reasons:(i) units commute source destination (e.g., resource collectorsreal-time strategy games) (ii) ally units share results learning (i.e., heuristicfunction). Since trial typically improves heuristic values many states, even single trialsingle unit use units different start states long share goalstate. often case state abstraction entire region map (e.g., roomrole-playing game players home base real-time strategy game) mappedsingle abstract state. Thus, single-trial learning experiences multiple units approximatedmulti-trial learning experience single unit. latter scenario study paper,56fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCHGoals7s8sgs6Starts1s4s5s0s2s3Figure 4: 34 grid-based map (left) converted 9-state search graph (right). Thinnercardinaldirection edges cost 1, thicker diagonal edges cost 2.line Furcy Koenig (2000), Shimbo Ishida (2003), Sigmundarson Bjornsson (2006)others.3. Search Graph Discoverypaper, require search agent know problem entirety. Instead, portionsearch problem neighborhood current state sc sensed agent timestep. assume agent remember parts problem sensed far.words, times agent internal representation (model) search space like.model updated agent discovers search graph (line 3 Figure 1).Let us illustrate exploration process goal-directed navigation. terrain map initiallyunknown agent. moves around environment, grid cells whose coordinates withinfixed visibility radius agents current position sensed. Formally, agent situated cell(x, y) check status (free/blocked) cell (x0 , 0 ) |x x0 | r |y 0 | r,r N visibility radius. Thus, two visible cells (x0 , 0 ) (x00 , 00 ) agent telledge cost. similar virtual sensors used Thalmann,Noser, Huang (1997).One common approach assume regular structure unknown part searchspace (Koenig et al., 2003; Koenig, 2004; Bulitko & Lee, 2006; Koenig & Likhachev, 2006).instance, grid-based pathfinding, agent assume obstacles gridworldsenses otherwise (this sometimes called free space assumption). demonstrateFigure 5, agent assumes space obstacle-free (a) builds internalmodel accordingly (b). Exploration reveals obstacles environment (c) cause agentupdate model (d). impose restriction search agent never needs add edgesmodel exploration weights discovered edges never change. words, agentsinitial model optimistic contains superset edges actual search graph. Adding edgesallowing arbitrary edge weight changes may require agent explore environment explicitly. Combining exploration exploitation effectively active research area (for early work,refer Sutton, 1990) addressed paper.Map discovery natural robotics sensors limited ranges. software domains,agent theoretically access entire environment. Several types argumentsmade justify restricting agents senses software domains. First, omniscient virtual57fiB ULITKO , TURTEVANT, L U , & YAUActual search space:Agent's model:Explored actual search space:Updated agent's model:(a)(b)(c)(d)Figure 5: (a): initially part search space shown solid lines sensed agent(shown stick figure). agents model assumes regular structure unknownpart (b). agent moves north-east, senses additional part search space(c) updates model correspondingly (d).humans tend behave unrealistically and, thus, less suitable virtual reality trainers (Diniet al., 2006). Likewise, commercial games, revealing entire map AI player viewednegatively cheating. Second, computationally expensive sense (Orkin, 2006)reason entire environment (Thalmann et al., 1997; Aylett & Luck, 2000). Consequently,localized sensing used large-scale multi-unit systems (Reynolds, 1987).4. Path Refinement Learning Real-time Search (PR LRTS)Real-time heuristic search algorithms plan using small part search graph surroundsagents current state. order avoid getting stuck infinite loops, update heuristicfunction time. approach guarantees action planned constant-boundedamount time. downside slow convergence.central idea PR LRTS address downside running real-time searchsmaller abstract search graph refining produced abstract path ground-level path.abstract graph image original graph abstraction operator. operatormaps region states original graph single abstract state abstract graph.applied multiple times, hierarchy abstractions formed. hierarchy forest (a treeconnected component search graph) formalized Section 4.2.variety terminologies used literature discussing relationship states different levels abstraction. different contexts abstract statesreferred clusters (Botea et al., 2004), sectors/regions (Sturtevant, 2007), images (Holteet al., 1996). abstraction forest, line (Bacchus & Yang, 1994; Bulitkoet al., 2005; Sturtevant & Buro, 2005), sometimes call image abstraction operator parentpre-image children. terms confused successor states lookaheadsearch. first describe PR LRTS intuitive level illustrate example Section 4.1. give formal details Section 4.2 describe abstraction operator detail.4.1 Path RefinementPR LRTS computes paths several levels abstraction. First, path foundabstract search space (at level `). abstract path defines region lower-level abstract58fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCHpath PR LRTS(sc , sg )12345678910111213level(sc ) > `returnendp =PR LRTS(parent(sc ), parent(sg ))p 6=sg = child(end(p))endC = {s | parent(s) p}switch(algorithm[level(sc )])A* : return A*(sc , sg , C)LRTS : return LRTS(sc , sg , C)pass-through : return pend switchFigure 6: PR LRTS algorithm.space searched refining abstract path. refinement proceeds incrementallylevel-0 (i.e., ground) search space reached ground path produced. orderkeep amount planning per move constant-bounded regardless ground space size,need real-time algorithm abstract search graph. paper, use LRTSfixed top level abstraction (`), A* refinement lower levels.2 abstract levelsleft pass-through merely increase amount state aggregation; processingcarried them. design choice motivated experimentation (Section 5).PR LRTS operates recursively presented Figure 6. line 1 checks states passedtop level abstraction pathfinding occur. so, empty pathreturned (line 2). Otherwise, function calls recursively compute pathabstract image sc (denoted parent(sc ) line 4) abstract image sg . returnedpath (if non-empty checked line 5) used derive new destination line 6. Specifically,new destination sg child end abstract path p.3 line 8, computecorridor C comprised pre-images states path p. corridor C emptypath p computed line 4 empty. Finally, run algorithm assigned current levelabstraction (i.e., level sc sg ) lines 10 11. A* LRTS taskedfind either full (in case A*) partial path (in case LRTS) sc sg limitedset states C. convention, empty corridor (C = ) allows A*/LRTS search entiregraph. Note processing happens pass-through level (line 12).42. agent explores environment moving about, actually use Local Repair A* instead A*.described Section 7.3. child used, choices may lead better performance. Intuitively, child chosenchild(end(p)) closest representative abstract state end(p) among children(end(p)).pathfinding, implement child(s) return element children(s) geographically closest average coordinates states children(s). Also, goal state sg happens pre-image end(p)pick child(end(p)).4. Also note functions child parent handle pass-through levels. Specifically, line 6, state sgcomputed child first non-pass-through level level path p computed. Likewise, line8, states forming corridor C first non-pass-through level (level i) level path p (levelj). Thus, parent(s) apply abstraction mapping j times parent(s) p level j.59fiB ULITKO , TURTEVANT, L U , & YAUimplementation A* standard (Hart et al., 1968) except run (line 10) subgraphdefined corridor C (line 8). implementation LRTS taken literature (Bulitko& Lee, 2006) described Section 2.2. Like A*, run LRTS corridor C.Figure 7: path refinement process. original graph (level 0) shown bottom.abstract graph (level 1) shown top.illustration purposes, consider example Figure 7. example ` = 1, onelevel abstraction (shown top) used addition ground level (shown bottom).sc current state sg destination state. LRTS assigned level 1 A*assigned level 0. Subfigure (i) shows ground state space one level abstractionabove. agent must plan path sc sg located ground level. First, abstractparents sc sg , parent(sc ) = s0c parent(sg ) = s0g , located. LRTS = 3plans three steps abstract space (ii). corridor C ground level comprised childrenabstract path built (iii). child representing end abstract path setnew destination sg (iv). Finally, A* run within corridor find path sc newdestination sg (v).agent executing path computed PR LRTS, new areas search graph mayseen. causes updates abstraction hierarchy agent maintains. PR LRTS clearsrecomputes abstract paths upon discovering new areas search graph. Also, groundpath proves invalid (e.g., runs newly discovered obstacle), execution stops PR LRTSreplans current state using updated abstraction hierarchy.Graph discovery lead arbitrary updates abstract search graphs agent maintains.implementation, LRTS operating abstract graph resets heuristic function abstract search graph updated way. hand, updates ground-level graphlimited state edge removals (Section 3). Consequently, heuristic learned groundlevel remains admissible need reset upon updates.4.2 Automatic Graph Abstractionuse term abstraction operator (or abstraction, short) mean graph homomorphismline Holte et al. (1996). Namely, abstraction many-to-one function maps (abstracts)one states single abstract state. Adjacent vertices mapped adjacent identicalvertices (Property 5 below). Given graph homomorphism function model searchproblem, PR LRTS agent builds ` additional abstract search graphs, collectively called abstrac60fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCHtion hierarchy, follows. first applies graph homomorphism search graph model(called ground-level graph). result abstract search graph level 1. processrepeated abstract search graph level ` computed. homomorphic abstractionused long resulting hierarchy abstract graphs satisfies several key properties. following introduce properties informally illustrate example. Appendix Bformalize them.Property 1 Every abstract graph search graph sense Definition 2.1 Section 2.Property 2 Every state unique abstract parent (except states top level abstraction).Property 3 Every state abstract level, least one child state below.Property 4 Given heuristic search problem, number children abstract state upperbounded constant independent number states ground-level graph.corollary property number ground-level states abstract singlestate fixed level abstraction also constant-bounded constant independentground-level graph size.Property 5 (Graph homomorphism) Every edge search graph level abstractioneither corresponding edge level states connected edge abstractsingle abstract state.Property 6 abstract edge exists two states edge leastchild one state child other.Property 7 two children abstract state connected path whose stateschildren abstract state.Property 8 abstraction hierarchy consistent agents model search problemtimes. is, properties 1 7 satisfied respect agents model.paper, use clique-based abstraction mechanism (Sturtevant & Buro, 2005). operates finding fully connected components (cliques) search graph mappingsingle abstract state. method building abstractions favored recent analysis SturtevantJansen (2007) earlier analysis Holte et al. (1996, Section 5.2) showed reductionsearch effort due abstraction maximized minimizing edge diameter set childrenmaximizing size. clique, edge diameter (i.e., maximum number edgestwo elements) one number states clique maximized.present clique-based abstraction mechanism developing several stages handtraceable example. illustrate properties introduced satisfiedexample. formal introduction clique abstraction technique complete pseudocodefound Appendix A. review ways building abstraction Section 7.3. Notegeneral clique computation NP-complete, finding cliques two-dimensional grid-based searchgraphs done efficiently (Appendix A).61fiB ULITKO , TURTEVANT, L U , & YAUsingle application abstraction procedure illustrated Figure 8. Cliques size fourfirst located graph, meaning states s0 , s1 , s2 s4 abstracted s01 .cliques size three already abstracted first step, cliques size twoabstracted next. includes s5 s3 abstracted s02 , s7 s8abstracted s03 . sg degree 1, add s03 ; however s6 degree two,abstracted parent, s04 . Adding degree 1 states neighbors reduces numberresulting abstract states increases edge diameter set children (it becomes 2set {s7 , s8 , sg }). minor detail abstraction happens effective grid-basedpathfinding. One use pure clique abstraction well.s7s8sgs'3s6s1s4s'4s5s'1s0s2s'2s3Level 0 (original graph)Level 1 (abstract graph)Figure 8: Clique abstraction: original search graph Figure 4 shown left abstractedsearch graph right.s7s8sgs'3s''2s6s1s4s'4s5s'1s0s2s'''1s'2s''1s3Level 0 (original graph)Level 1Level 2Level 3Figure 9: Three iterations clique abstraction procedure.abstraction process successively applied single abstract state connected component original graph remains (Figure 9, Level 3). illustrateabstraction properties Figure 9. Property 1 requires four abstraction levelsFigure 9 search graph sense Definition 2.1 Section 2. Property 2 requires62fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCHstate levels 0, 1, 2 unique parent level above. Property 3 requiresstate levels 1, 2, 3 non-empty set children level below. Property 4 placesupper bound number children abstract state have. example bound4. Properties 5 6 require that, two abstract states connected path, parentschildren also connected. Consider, instance, abstract states s02 s03 .connected level 1 abstract path p = (s02 , s01 , s04 , s03 ) them. Thus, childs02 also connected child s03 level 0. instance, s3 connected s7 . Property 7requires children node s01 connected internal path within s01 . (s00 , s01 , s02 , s04 ) formclique, property satisfied.costs abstract edges (e.g., edge (s01 , s02 ) Figure 8) defined arbitrary waylong resulting search graph satisfies properties Section 2. However, better performance, low-cost abstract path abstraction low-cost ground path. paperexperiment grid-based navigation and, correspondingly, define cost edge (s01 , s02 )Euclidean distance average coordinates children(s01 ) children(s02 ) (Figure 10).Figure 10: Coordinates edge costs levels abstraction hierarchy. grid level(leftmost illustration) vertexcoordinates given column/row labels. Groundedges cost 1 (cardinal) 2 (diagonal). Abstract states labeled (x, y). Abstractedges labeled approximate cost.practice, Property 8 satisfied repairing agents abstraction hierarchy upon updatesagents model. illustrate, imagine agent discovered discrepanciesterrain elevation state s4 s6 (Figure 8) prevent able traverse edge(s4 , s6 ). update model removing edge. Additionally, degree-one state s6join clique {s7 , s8 }. point, agents abstraction hierarchy needs repaired.accomplished replacing abstract states s04 s03 single abstract state s05 . edges (s01 , s04 )(s04 , s03 ) removed. one level abstraction used repairpropagated higher levels well. repair mechanism presented detail Appendix A.2.prove Section 6 PR LRTS algorithm operate abstraction mechanismsatisfies properties listed above.63fiB ULITKO , TURTEVANT, L U , & YAUFigure 11: Two six maps used experiments.5. Empirical StudyEmpirical evaluation effects state abstraction learning real-time heuristic searchpresented four parts. Section 5.1, introduce concept trading antagonisticmeasures demonstrate PR LRTS makes trade-offs efficiently. due useabstraction and, consequently, investigate effects abstraction independently LRTScontrol parameters Section 5.2. study PR LRTS performance scales problemsize (Section 5.3). Finally, examine interplay effects abstraction LRTScontrol parameters. domain-specific study present details Appendix F.experimental setup follows. used 3000 problems randomly generated threemaps modeled environments role-playing game (BioWare Corp., 1998) three mapsmodeled battlefields real-time strategy game (Blizzard Entertainment, 2002). sixmaps 5672, 5852, 6176, 7629, 9749, 18841 states grids 139 148 193 193.Two maps Figure 11. four maps shown Appendix C. 3000 problemsuniformly distributed across five buckets bucket represents range optimal solutioncosts. first 600 problems optimal path cost [50, 60) range, next 600 problemsfell [60, 70) bucket last 600 problems [90, 100) bucket.experimented various assignments algorithms (A*, LRTS, none) levels abstraction. experimentation, found keeping LRTS top, A* bottom levelleaving intermediate levels pass-through yielded best results testbed. following, present results 160 PR LRTS configurations, denoted LRTS` (d, , ), `level abstraction LRTS control parameters d, , operates, A* runningbottom level. ` = 0, run LRTS ground level run A* all. LRTSparameter space follows: ` {0, 1, 2, 3, 4}, lookahead depth {1, 3, 5, 9}, optimalityweight {0.2, 0.4, 0.8, 1.0}, learning quota {100.0, }. Two visibility radii used:10 1000. analysis, focus case visibility radius 10, lineprevious publications area (Bulitko et al., 2005; Bulitko & Lee, 2006). Experimentsvisibility radius 1000 yielded similar results. point reference, ran single nonreal-time algorithm: A*. algorithms implemented within Hierarchical Open Graphframework (Sturtevant, 2005) C++ run cluster, aggregate 1.7 years IntelXeon 3.0GHz CPU.64fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCH5.1 Antagonistic Performance Measure Trade-offpractitioners viewpoint, section viewed parameter selection guide. startfinding sets parameters optimize performance PR LRTS along single measure.consider optimizing pairs antagonistic performance measures.research optimizing single performance measures within LRTS published BulitkoLee (2006). Table 1 extend results include A* PR LRTS. best algorithmssingle performance measure A* LRTA* use abstraction. exceptionconvergence planning interplay planning per move convergence travel.Table 1: Optimizing single performance measure.Measureconvergence travelfirst-move lag (states touched)conv. memorysuboptimalityconv. planning (states touched)best algorithmA*LRTA*A*A* LRTA*LRTS3 (d = 1, = 0.2 0.4, ) LRTS2 (d = 1, = 0.2 0.4, )power abstraction comes attempt optimize two negatively correlated (orantagonistic) performance measures simultaneously. Consider, instance, convergence travelfirst-move lag. order lower convergence travel, agent needs select better actions.done increasing amount planning per move which, turn, increases first-movelag. measures negatively correlated, performance along one measure tradedperformance along other. Thus, interested algorithms make trade-offsefficiently. order make analysis specific, first introduce concept dominancerespect set parameterized algorithms.Definition 5.1 Algorithm said dominate algorithm B respect performance measuresx set problems P average performance measured x worseBs: avgP x(A) worse avgP x(B) avgP y(A) worse avgP y(B).Algorithm C called dominated set algorithms set contains another algorithmdominates it.definition illustrated Figure 12 non-dominated algorithms shown solid circles dominated algorithms shown hollow circles. Intuitively, non-dominated algorithmsmake trade-off performance measures x efficiently among algorithmsset. considered practice one wants optimize performance measures. Dominated algorithms safely excluded consideration regardless relativeimportance measures x particular application.Non-dominated algorithms ten pairs antagonistic measures summarized Table 2.A* weighted version Korfs LRTA* extreme cases performance measures: A*minimizes convergence travel uses heuristic memory; LRTA* minimizes first-move lag.non-dominated algorithms PR LRTS abstraction. words, abstractionpath-refinement improve efficiency trading antagonistic performance measures. Figure 13shows dominance plot convergence planning first-move lag. PR LRTS forms frontier65fiperformancemeasure 2performancemeasure 2worseworseB ULITKO , TURTEVANT, L U , & YAUBbetterbetterNondominatedalgorithmsbetterperformancemeasure 1betterworseperformancemeasure 1worseFigure 12: Left: algorithm dominates algorithm B (left). Right: non-dominated algorithmsshown solid circles, dominated algorithms shown hollow circles.non-dominated algorithms (the rightmost non-dominated point weighted LRTA*extremely low first-move lag). Plots combinations Appendix D.Firstmove Lag (states touched)DominatedNondominated310LRTS3(1,0.4,)210LRTS2(1,0.4,)LRTS1(1,0.4,)110LRTS(1,0.4,)410510Convergence Planning (states touched)610Figure 13: Dominance convergence planning first-move lag.dominance analysis done respect performance measures averagedbenchmark set problems. Dominance analysis level individual problems foundAppendix E shows similar trends.5.2 Effects Abstraction Individual Performance Measuressection study effects abstraction individual performance measures. arbitrarily choose three diverse LRTS parameter combinations lookahead d, optimality weight ,learning quota : (1, 1.0, ), (3, 0.2, 100), (9, 0.4, ). plots Figure 14, qualitativesummary Table 3, analysis trends below.Convergence planning decreases abstraction level. increase planning per move higher abstraction levels overcompensated decrease convergencetravel. exact shape curves due interplay two measures.66fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCHTable 2: Trading antagonistic performance measures.Measure 1first-move lag(states touched)first-move lag(states touched)first-move lag(states touched)first-move lag(time)first-move lag(time)first-move lag(time)suboptimalitysuboptimalitysuboptimalitysuboptimalityMeasure 2conv. travelconv. memoryconv. plan.(states touched)conv. travelconv. memoryconv. plan.(time)conv. plan.(states touched)conv. plan.(time)conv. travelconv. memoryNon-dominated algorithms (extreme cases italic)A*, LRTA*( = 0.4),LRTS1...4 (d {1, 3, 5, 9}, {0.2, 0.4, 0.8}, {100, })A*, LRTA*( = 0.2),LRTS1...4 (d {1, 3, 5, 9}, {0.2, 0.4}, {100, })LRTS1...3 (d = 1, = 0.4, = ),LRTA*( = 0.4)A*, LRTA*( = 0.4),LRTS1...4 (d {1, 3, 5, 9}, {0.2, 0.4}, {100, })A*, LRTA*( {0.2, 0.4}),LRTS1...4 (d {1, 3, 5}, {0.2, 0.4}, {100, })A*, LRTA*( = 0.4),LRTS1...3 (d {1, 3}, {0.2, 0.4}, {100, })A*,LRTS2...3 (d {1, 3, 5}, {0.2, 0.4, 0.8}, {100, })A*A*A*First-move lag increases abstraction level. due fact corridorground level induced abstract path length computed LRTS abstract levelincreases abstraction level. two additional factors affecting shape curves.First, average out-degree abstract states varies abstraction level. Second, boundariesabstract graphs often seen lookahead = 9 higher abstraction level.Convergence memory decreases abstraction level learning algorithm (LRTS) operates smaller abstract maps incurs smaller travel cost. practice, amount learningLRTS tends correlate tightly travel. instance, LRTS2 (3, 0.8, ) correlationconvergence memory convergence travel empirically measured 0.9544confidence 99%.Suboptimality increases abstraction. increase due fact abstractionlevel progressively simplifies ground graph topology and, abstract path guaranteedrefinable ground path, may lead agent away shortest solution. illustrativeexample given Appendix B.1 refinement complete abstract path 221% longeroptimal ground path. Derivation theoretical upper bound suboptimality dueabstraction found Appendix B.2. second mechanism explains suboptimality rises fastershallower LRTS searches. Specifically, A* ground level refines abstract d-step pathfinding ground-level solution current state ground representative endabstract path. solution guaranteed optimal within corridor necessarilypass geographically closely intermediate states abstract path. Thus, giving A*corridor induced longer abstract path liberates plot path possibly far-offintermediate states abstract path. phenomenon illustrated Appendix B.1feeding A* abstract path small fragments results suboptimality givingbig picture abstract path entirety. third factor affecting suboptimality curves67fi4633 4x 1022B ULITKO, TURTEVANT, L U , & YAU32Convergence Travel224x 103210001122330 Abstraction12 Level3AbstractionLevelAbstraction Level444First!Move Lag6000First!Move LagFirst!Move Lag444200000 00 000 00400040004000302000200020002000 00 0 0 1 1 1 2 2 2 3 33AbstractionLevelAbstractionLevelAbstractionLevel4 441010002x 1062x 101.51.5 x 1062111.50.50.51000.515001500000010001000150013015001500300 15000201000100020600060003030 306 6112233AbstractionLevelAbstraction Level200020000.50.54000 0.5110000x 10x 10226000600060x 10021231.51.5Abstraction Level40001.540006000 1 1Suboptimality (%)Convergence MemorySuboptimality(%)ConvergenceMemoryConvergenceMemorySuboptimality(%)Convergence TravelConvergence Travel3340014 4x 10x 104411ConvergenceMemory MemoryConvergenceConvergenceMemoryConvergencePlanning PlanningConvergenceConvergencePlanningFirst!Move LagFirst!MoveConvergence TravelFirst!Move LagLagConvergence PlanningConvergenceTravelTravelConvergenceConvergencePlanningConvergencePlanning4x 10 44 x 1044 4123Abstraction Level411223 3AbstractionLevelAbstractionLevel4 45005001000222 2333 3111 11Abstraction2 Level3LevelAbstractionAbstractionLevelAbstractionLevelAbstraction Level123Abstraction Level444 444005000000105001050050000 000 000 0011223 3AbstractionLevelAbstractionLeveld=1,!=1,T="d=1,!=1,T="123d=3,!=0.2,T=100Abstraction Leveld=3,!=0.2,T=100d=9,!=0.4,T="d=9,!=0.4,T="4d=1,!=1,T="d=3,!=0.2,T=1001231111222 2Level333 3AbstractionAbstractionLevelAbstractionLevelAbstractionLevelAbstractionLevel4444 4d=9,!=0.4,T="Suboptimality (%)Suboptimality (%)Suboptimality (%)Figure 14: Effects abstraction in0 PR LRTS.Error bars indicate standard errorsd=1,!=1,T="d=1,!=1,T="d=1,!=1,T="01234d=3,!=0.2,T=100d=3,!=0.2,T=100d=3,!=0.2,T=1002020 20small see data points.AbstractionLeveld=9,!=0.4,T="d=9,!=0.4,T="d=9,!=0.4,T="1010 10figure optimality weight . Setting lower values leads higher suboptimality0independently0001 abstraction234(Bulitko & Lee, 2006).001 1 Abstraction223344LevelConvergencetraveldecreasesabstraction bottom level search constrained withinAbstractionLevelAbstraction Levelnarrow corridor induced abstract path. decrease noticeable shallow lookahead searches (d = 1 = 3). Algorithms using lookahead = 9 low convergencetravel even without abstraction, convergence travel lower bounded double optimalsolution cost (one optimal solution first trial map discovered onefinal trial map discovery heuristic learning). Consequently, abstraction diminishedgains deeper lookahead (d = 9), although effect would disappear larger maps.Table 3: Qualitative effects abstraction: general trends.measure / parameterfirst-move lagconvergence planningconvergence memorysuboptimalityconvergence travel0`Given higher abstraction reduces convergence travel, one may ask comparesreducing convergence travel non-abstract algorithms simply terminating convergenceprocess final trial. Figure 15 compare four algorithms single problem: A*,non-abstract LRTS(3, 0.4, ) two abstract versions: LRTS2 (3, 0.4, ) LRTS4 (3, 0.4, ).left plot figure demonstrates well-known fact convergence learning heuristicsearch algorithms non-monotinic (e.g. Shimbo & Ishida, 2003). right plot shows costshortest solution function cumulative travel. prefer algorithms find shorter solutions traveling little possible. plot, abstract algorithms perform better (lower68fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCHA*LRTS(3,0.4,)LRTS2(3,0.4,)Travel trial180LRTS4(3,0.4,)16014012010080246Trial8A*LRTS(3,0.4,)LRTS2(3,0.4,)200Shortest solution found2001801401201008010LRTS4(3,0.4,)1602004006008001000Cumulative travel12001400Figure 15: Convergence process level individual trials.curves) preferred. words, single problem, better run abstract algorithms non-abstract algorithms regardless early convergence process terminated.observe case problems assignments d, , tried.certain cases, prematurely terminating convergence process non-abstract algorithm indeedbeneficial. Future research investigate extent one automatically select bestalgorithm number trials run for.5.3 Effects Abstraction: Scaling Problem Sizesection investigate effects abstraction problem size increases. measuresize problem cost shortest path start goal position (henceforthoptimal solution cost).Figures 16 17 show five performance measures plotted bucket averages. datapoint, use middle bucket (e.g., 55, 65, . . . ) horizontal coordinate. error barsindicate standard errors. Overall, results demonstrate abstraction enables PR LRTSapplied larger problems significantly dampening increase convergence travel, convergence planning, convergence memory. advantages come price suboptimalityfirst-move lag. former clearly increases abstraction lookahead small (Figure 16)virtually bucket-independent. lookahead = 9 (Figure 17) draws curves togetherdeeper lookahead diminishes effects abstraction suboptimality (cf. Figure 36).First-move lag virtually bucket-independent except case = 9 abstraction levels3 4 (Figure 17). There, first-move lag capped problems lower buckets goalseen start state higher levels abstraction. Consequently, LRTS computesabstract path shorter nine moves. leads smaller corridor less workA* refining path. Consequently, first-move lag reduced. problems becomelarger, LRTS room compute full nine-move abstract path first-move lag increases.abstraction level 3 phenomenon takes place bucket 85 seeing goal statestart state frequent enough make impact. happens abstraction level4 proximity abstract goal continues cut search short even largest problems.Finally, observe minute decrease first-move lag larger problems. appearsdue fact problems higher buckets tend start state located clutteredregion map (so optimal solution cost necessarily higher). Walls reduce numberstates touched agent first move reduce first-move lag.69fiB ULITKO , TURTEVANT, L U , & YAU45x 104Convergence PlanningConvergence Travel5432102000400330021055 65 75 85 95Optimal Solution Costx 10FirstMove Lag655 65 75 85 95Optimal Solution Cost200100055 65 75 85 95Optimal Solution Cost301500Suboptimality (%)Convergence MemoryL=0251000500L=1L=220L=315L=41050055 65 75 85 95Optimal Solution Cost55 65 75 85 95Optimal Solution CostFigure 16: Scaling up. curve shows bucketed means LRTSL (1, 1.0, ). Error bars indicate standard errors small see data points.6. Theoretical AnalysisPR LRTS subsumes several known algorithms abstraction used. Clearly, LRTS (Bulitko & Lee, 2006) special case PR LRTS abstraction used. LRTS subsumes generalizes several real-time search algorithms including LRTA* (Korf, 1990), weightedLRTA* (Shimbo & Ishida, 2003), -Trap (Bulitko, 2004) SLA*/SLA*T (Shue & Zamani, 1993;Shue et al., 2001).Theorem 6.1 (real-time operation) heuristic search problem, LRTS` (d, , ) amountplanning per action constant-bounded. constant depends constant controlparameters N, (0, 1], [0, ] independent problems number states.first prove auxiliary lemma.Lemma 6.1 (downward refinement property) abstract path p = (sa , . . . , sb ), twochildren ends connected path lying entirely corridor induced p. meansabstract path refined within corridor formed children. Formally:1 k ` p = (sa , . . . , sb ) [p (S(k), E(k)) =s0a children(s1 ) s0b children(sm )p0 = (s0a , . . . , s0b ) [p0 (S(k 1), E(k 1)) & s0 p0 [s0 sp children(s)]]].70(6.1)fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCH5400020006000500064200200655 65 75 85 95Optimal Solution Costx 10FirstMove Lag60008Convergence PlanningConvergence Travel800040003000200055 65 75 85 95Optimal Solution Cost100055 65 75 85 95Optimal Solution CostL=115010050055 65 75 85 95Optimal Solution CostSuboptimality (%)Convergence MemoryL=05L=2L=34L=43255 65 75 85 95Optimal Solution CostFigure 17: Scaling up. curve shows bucketed means LRTSL (9, 0.4, ). Error bars indicate standard errors small see data points.Proof. proof induction number edges abstract path. base case 0.means two children single abstract state connected path lies entirelyset children abstract state. holds due Property 7.Suppose statement holds abstract paths length j. showholds abstract paths length j+1. Consider arbitrary abstract path p (S(k), E(k)), k >0 j + 1 edges. represent p (s1 , . . . , sj+1 , sj+2 ). Consider arbitrary childrens01 children(s1 ) s0j+2 children(sj+2 ). need show path p0 (S(k1), E(k 1)) lies entirely union children states p (let us denoteCp ). Let s0j+1 arbitrary child state sj+1 . Since s1 sj+1 j edges apart,inductive supposition, path s01 s0j+1 lies entirely Cp . leftshow s0j+1 s0j+2 connected within Cp . s0j+1 s0j+2 parent,Property 7 guarantees connected. different parents, Property 6 providesguarantee. Either way, induction step completed.prove Theorem 6.1.Proof. abstract level `, LRTS(d, , ) considers bd abstract statesalgorithm design (cf. Section 2.2), b maximum degree state. assumed earlierpaper, maximum degree state depend number states. resultingabstract path longer abstract edges induces corridor ground level. corridorconsists ground-level states abstract abstract states path. size corridor71fiB ULITKO , TURTEVANT, L U , & YAUupper-bounded number edges path (at d) multiplied maximum numberground-level children abstract state level `. latter upper-bounded constantindependent number ground-level states due Property 4. A* running corridorconstant-bounded size takes constant-bounded time. Finally, abstraction repair O(`) `independent graph size (Appendix A.2).Completeness defined ability reach goal state every trial. prove completeness LRTS` (d, , ) based following reasoning. Recall LRTS` (d, , ) usesLRTS algorithm build abstract path level `. uses corridor-restricted A*ground level refine abstract path sequence ground-level edges. Due Property 7Section 4.2, A* always able find path ground-level states sc sglie within corridor C time execution gets line 9 Figure 6. Due explorationprocess, agents model search graph may different graph actuallyreality. Consequently, path found A* may contain ground-level edge agent believesexist reality not. following lemma demonstrates execution failurepossible finite number times given search graph:Lemma 6.2 finite number path execution failures trial.Proof. contradiction: suppose infinite number failures. failure duediscovery least one new blocked edge vertex ground-level graph.infinitely many blocked edges vertices finite graph.direct corollary lemma trial, moment timegraph discoveries made trial. Therefore, executing A*s path indeed allowagent follow abstract path actual map.Lemma 6.3 LRTS complete abstract graph.Proof. First, show abstract graph satisfies properties LRTS showncomplete (Theorem 7.5, Bulitko & Lee, 2006). is, abstract graph finite, actionreversible, self-loops, actions positive cost, goal state reachableevery state. graph also stationary deterministically traversible (p.122, Bulitko& Lee, 2006). Due abstraction mechanism requirements Section 4.2, properties listedsatisfied clique abstraction mechanism long ground-level graph satisfiesproperties well (which require Section 2). Thus, LRTS running abstract graphground graph complete.PR LRTS, however, LRTS abstract graph execute actions. Instead,current (abstract) state computed abstract parent agents current ground-level state.Therefore, critical question whether agent able find ground-level path currentstate ground-level state corresponding end abstract path computed line 6Figure 6. failure would mean corridor computed line 8 Figure 6used refine path contain ground-level path sc sg . Due downwardrefinement property (Lemma 6.1), due graph discovery.According Lemma 6.2, finite number failures, A* algorithm operatingground level guaranteed find path reach end abstract path computed LRTS.Thus, LRTS effective ability execute abstract actions. Putting results72fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCHtogether, conclude valid d, , parameters, LRTS abstract graph findsgoal every trial.two lemmas lead directly following statement.Theorem 6.2 LRTS` (d, , ) complete.Proof. follows directly Lemma 6.2 Lemma 6.3.Theorem 6.3 LRTS` (d, , ) fixed tie-breaking converges final solution finitenumber trials. subsequent trials, update search graph model heuristicfollows path.Proof. Follows Lemma 6.2 Theorem 7.6 (Bulitko & Lee, 2006) wayLemma 6.3 Theorem 6.2 proved above.Theoretical results suboptimality found Appendix B.27. Related ResearchExisting heuristic search methods situated methods divided two categories: fullsearch real-time search. Full-search algorithms form entire solution given currentknowledge search graph. contrast, real-time search plans small segment (frequentlyfirst action) solution executes right away. Due local nature planning,real-time search algorithms need update heuristic function avoid getting stuck localminima heuristic function.7.1 Full Searchcommon full-search algorithm version A* (Hart et al., 1968) called Local Repair A* (Stout,1996). it, full search conducted agents current state goal state free spaceassumption. agent executes computed path either destination reachedpath becomes invalid (e.g., previously unknown wall blocks way). latter case, agentreplans current position goal. Local Repair A* suffers two problems. First,searches shortest solution and, general search problem, may end expanding numberstates exponential solution cost due inaccuracies heuristic function (Pearl, 1984).Second, re-planning episodes re-use results previous search.first problem addressed suboptimal versions A* frequently implementedvia weighting heuristic function (Pohl, 1970, 1973). weighted A* (WA*) usually findslonger solution less time. suboptimal solution found, improved uponconducting additional searches. done re-using open list successivesearches (Hansen, Zilberstein, & Danilchenko, 1997; Likhachev et al., 2004; Hansen & Zhou, 2007)re-running A* tunnel induced suboptimal solution (Furcy, 2006). later case,beam search backtracking used place weighted A* (Furcy & Koenig, 2005).second problem addressed incremental search methods D* (Stenz, 1995), D*Lite (Koenig & Likhachev, 2002a) LPA* (Koenig & Likhachev, 2002b). algorithms reuseinformation previous search, thus speeding subsequent replanning episodes.73fiB ULITKO , TURTEVANT, L U , & YAUalgorithms, full path computed first move executedagent. Consequently, planning time per move constant-bounded increasesproblem size. Thus, agent-centered full search real-time.7.2 Learning Real-time SearchSince seminal work LRTA* (Korf, 1990), research field learning real-time heuristicsearch flourished resulting twenty algorithms numerous variations.described following four attributes:local search space set states whose heuristic values accessed planningstage. two common choices full-width limited-depth lookahead (Korf, 1990; Shimbo &Ishida, 2003; Shue & Zamani, 1993; Shue et al., 2001; Furcy & Koenig, 2000; Hernandez &Meseguer, 2005a, 2005b; Sigmundarson & Bjornsson, 2006; Rayner, Davison, Bulitko, Anderson,& Lu, 2007) A*-shaped lookahead (Koenig, 2004; Koenig & Likhachev, 2006). Additionalchoices decision-theoretic based shaping (Russell & Wefald, 1991) dynamic lookaheaddepth-selection (Bulitko, 2004; Lustrek & Bulitko, 2006).local learning space set states whose heuristic values updated. Commonchoices are: current state (Korf, 1990; Shimbo & Ishida, 2003; Shue & Zamani, 1993; Shueet al., 2001; Furcy & Koenig, 2000; Bulitko, 2004), states within local search space (Koenig,2004; Koenig & Likhachev, 2006) previously visited states neighbors (Hernandez &Meseguer, 2005a, 2005b; Sigmundarson & Bjornsson, 2006; Rayner et al., 2007).learning rule used update heuristic values states learning space.common choices dynamic programming mini-min (Korf, 1990; Shue & Zamani, 1993; Shueet al., 2001; Hernandez & Meseguer, 2005a, 2005b; Sigmundarson & Bjornsson, 2006; Rayneret al., 2007), weighted versions (Shimbo & Ishida, 2003), max mins (Bulitko, 2004), modified Dijkstras algorithm (Koenig, 2004), updates respect shortest pathcurrent state best-looking state frontier local search space (Koenig & Likhachev,2006). Additionally, several algorithms learn one heuristic function (Russell & Wefald,1991; Furcy & Koenig, 2000; Shimbo & Ishida, 2003).Control strategy decides move following planning learning phases. Commonlyused strategies include: first move optimal path promising frontier state (Korf,1990; Furcy & Koenig, 2000; Hernandez & Meseguer, 2005a, 2005b), entire path (Bulitko,2004), backtracking moves (Shue & Zamani, 1993; Shue et al., 2001; Bulitko, 2004; Sigmundarson & Bjornsson, 2006).Given multitude proposed algorithms, unification efforts undertaken. particular, Bulitko Lee (2006) suggested framework, called Learning Real Time Search (LRTS),combine extend LRTA* (Korf, 1990), weighted LRTA* (Shimbo & Ishida, 2003), SLA* (Shue& Zamani, 1993), SLA*T (Shue et al., 2001), large extent, -Trap (Bulitko, 2004).dimensions described above, LRTS operates follows. uses full-width fixed-depth local searchspace transposition tables prune duplicate states. LRTS uses max mins learning ruleupdate heuristic value current state (its local learning space). control strategy movesagent promising frontier state cumulative volume heuristic function updatestrial user-specified quota backtracks previous state otherwise (Section 2.2).Within LRTS, unification several algorithms accomplished implementingseveral methods local search space selection, learning rule, control strategy.74fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCHmethods engaged run-time via user-specified parameters. resulting parameter space contained original algorithms plus numerous new combinations, enabling tuningperformance according specific problem objective function particular application.demonstration, Bulitko et al. (2005) tuned LRTS ten maps computer game BaldursGate (BioWare Corp., 1998) achieved convergence speed two orders magnitudefaster LRTA*, finding paths within 3% optimal. time, LRTSfive times faster first move incremental A*. Despite improvements, LRTSreal-time search algorithms converge slowly A* and, visually, may behave unintelligentlyrepeatedly revisiting dead-ends corners.7.3 State Abstractionidea abstraction previously applied full search methods. particular, HPA*PRA* (Botea et al., 2004; Sturtevant & Buro, 2005) use abstraction speed A* search: insteadrunning A* lowest-level graph, instead run A* smaller abstract graph. PRA*computes abstract path refines similar manner PR LRTS. However, PRA*dynamically chooses abstract level use, computes path intermediate level(i.e., pass-through levels). PRA* also widens corridors decrease suboptimalitycost lower speed.HPA* abstracts map using large regions, selects connection points (gates) neighboring regions. gates region, optimal paths gates pre-computed off-lineusing A* stored table. means refining abstract path (i.e., sequenceregion gates) done simply concatenating stored optimal paths. Smoothing appliedpost-processing step decrease suboptimality resulting path.algorithms based ideas presented Holte et al. (1996), usedabstraction mechanism similar manner use clique abstraction. method,STAR abstraction, also described radius abstraction. is, state selected,aggregated together states fixed radius original state. Holte et al. (1996)swork initially gain wide acclaim, because, time, little interest problemssmall enough fit memory. Motivating applications, pathfinding computergames, resulted resurgence interest techniques.class algorithms first plan abstract path, refined traversable path.Another approach build abstraction directly used planning realworld. includes methods like framed quad-trees (Yahja, Stentz, Singh, & Brummit, 1998),efficiently represent sparse maps. Quad-trees multi-resolution representation,areas map represented high-resolution, others represented lower resolution.abstraction differs abstractions like clique abstraction appliedonce; applications would produce lower resolution maps, although clique abstractioncould applied graph implied framed quad-tree representation.One common use abstraction provide better heuristics. Holte, Perez, Zimmer,MacDonald (1995) used result abstract search provide accurate heuristic lowlevel search performed path refinement. Similarly, pattern databases abstractionsbuilt solved off-line. abstract solution costs stored used searchheuristic function (Culberson & Schaeffer, 1996; Felner, Zahavi, Schaeffer, & Holte, 2005).75fiB ULITKO , TURTEVANT, L U , & YAUPR LRTS presented paper first real-time heuristic search algorithm useautomatically-built state abstraction. Path-refinement algorithms listed conduct full-searchtherefore cannot guarantee constant-bounded planning time agents moves.8. Limitations Future Workresults presented paper open several directions future research. First, PR LRTSable operate wide class homomorphic graph abstraction techniques. Thus, wouldinterest investigate extent effects graph abstraction real-time searchpresented paper specific clique abstraction mechanism pathfinding domain.Recent work shown clique abstraction parameters well-tuned minimizework done traditional path planning (Sturtevant & Jansen, 2007). experiments pathfindingsuggested clique abstraction well-suited map abstraction represents keyproperties underlying space well. particular, branching factor stays roughly constanthigher levels abstraction. empty map, instance, number nodes levelabstraction reduced factor four clique abstraction, branching factorevery state stay same. (Corner states 3 neighbors, edge states 5neighbors, middle states 8 neighbors.) may case domains.instance, sliding tile puzzle maximum branching factor abstract states quickly increasesabstraction level. result, corridor derived abstract path PR LRTS becomesexcessively wide effectively constrain A* search ground level. conjecturealgorithms use homomorphic abstractions effective domain abstractionpreserves average, minimum, maximum branching factor original problemlevel abstraction. Clique abstraction, likely work well three-dimensional pathfinding,problem-specific mechanisms would needed permutation-type puzzles. areaopen research provide abstraction.Second, PR LRTS uses abstract solution restrict search original ground-levelgraph. interesting combine complementary approach using costoptimal solution abstract problem heuristic estimate original search graphcontext real-time search. particular, looking effective ways propagating heuristicvalues higher lower levels abstraction hierarchy.Third, state aggregation one way generalizing learning. Future research considercombining function approximation heuristic function, commonly practicedlarge-scale applications reinforcement learning.Fourth, presently investigating applications PR LRTS dynamic environments.particular, studying extent savings memory gained learning higherabstraction level afford application PR LRTS moving target search. existing algorithm (Ishida & Korf, 1991) requires learning number heuristic values quadratic sizemap. prohibitive case commercial game maps.Finally, presently extending graph abstraction method presented paperstochastic environments formulated Markov Decision Processes.76fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCH9. ConclusionsSituated agents real-time environments expected act quickly efficiently learninginitially unknown environment. Response time learning speed antagonistic performancemeasures planning leads better actions and, consequently, faster convergence longerresponse time. Full search algorithms, local repair A*, converge quicklyconstant-bounded planning time per move. Real-time heuristic search algorithms constantbounded planning times per move, learn slowly.paper, attempted combine best approaches suggest hybrid algorithm, PR LRTS, learns heuristic function smaller abstract space uses corridorrestricted A* generate partial ground-level path. large-scale empirical study, PR LRTSfound dominate virtually tested algorithms use abstraction respectseveral performance measure pairs. combination learning planning brings real-time performance much larger search spaces, substantially benefiting applications pathfindingrobotics video games.AcknowledgmentsFunding provided National Science Engineering Research Council Canada,Alberta Ingenuity Centre Machine Learning, Informatics Circle Research Excellence,University Alberta. appreciate input David Thue, Rich Korf, Rob Holte, CsabaSzepesvari, David Furcy, Adi Botea. Special thanks go Jonathan Schaeffer anonymous reviewers whose detailed comments greatly improved paper. research enabled use WestGrid computing resources, funded part Canada Foundation Innovation, Alberta Innovation Science, BC Advanced Education, participatingresearch institutions. particular, would like acknowledge help Roman Baranowski,Masao Fujinaga, Doug Phillips.Appendix A. Clique Abstractiondescribe clique abstraction mechanism several stages. First, presentalgorithm building initial abstraction hierarchy using free space assumption.describe repair procedure updates abstract graphs agent explores environment.Finally, consider suboptimality solution caused abstraction examples derive worstcase upper bound.A.1 Building Initial Abstraction Hierarchypseudo-code building initial clique abstraction Figure 18. abstract procedure(lines 5 14) takes set states level maps single abstract state level+ 1. involves creating new abstract state storing parent child links. If, line 20,new abstract edge added one already exists, add extra edge increasecount associated edge. counts used facilitate abstraction repair describednext section.general, clique-finding NP-complete problem (Garey & Johnson, 1990). However,eight-connected two-dimensional grid-based search graphs largest possible clique size 4.77fiB ULITKO , TURTEVANT, L U , & YAUgraph CliqueAbstraction(graph g)1initialize graph g 02= 4...23unabstracted state g4part i-clique c5g 0 g 0 {abstract(c)}6end7end8end910 unabstracted state g11degree(s) = 112set parent(s) parent(neighbor(s))13else14g 0 g 0 {abstract(n)}15end16 end1718 edge e = (v1 , v2 )19parent(v1 ) 6= parent(v2 )20g 0 g 0 {(parent(v1 ), parent(v2 ))}21end22 end23 return g 0Figure 18: Building initial clique abstraction.degreestate also constant-bounded (as required Section 2) time perclique constant (i.e., 83 state accesses check eight neighbors find 3 form 4-cliquetogether current state). Thus, total running time single clique abstractionO(|S|), |S| number states original search graph. abstraction procedurereduces graph size least constant factor greater one, total cost abstractinggraph also O(|S|) cost additional abstraction step reduced exponentially.A.2 Repairing Abstraction Hierarchyagent explores environment, may find edges states blocked. cases,remove corresponding states edges model need propagate changesabstract graphs abstraction hierarchy. demonstrate repair code Figure 19example also shows repair procedure amortized constant-time cost.Figure 20 remove edges Level 0 graph bottom left figure. rightside figure shows full abstract graph edges removed. levelshow portion abstract graph assume states edges graph.shown schematically Level 0 gray.Level 0 four states marked form abstract state level 1. alsotrue states marked A. joined edge level 1, abstracted78fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCHRemoveEdge(edge e, level l, graph g)1decrease edge count e2child edge count e 6= 0 return end3e = (v1 , v2 )4remove e g[l]5parent(v1 ) = parent(v2 )6AddToRepairQ(parent(v1 ))7else8RemoveEdge((parent(v1 ), parent(v2 )), l + 1, g)9endRemoveState(state s, level l, graph g)10 edge e incident11RemoveEdge(e, l, g)12 end13 remove g[l]14 AddToRepairQ(parent(s))HandleRepairQ()15 RepairQ empty16remove state lowest level l g17abstraction properties hold18AddToRepairQ(parent(s))19split state s1 . . . sn abstraction properties holds si20= 1 . . . n either:211. Merge si existing abstract state222. Extract si new abstract state23end24end25 endFigure 19: Repairing abstraction hierarchy.four edges level 0. remove edges level 0 graph using RemoveEdge()procedure Figure 19, first three removals simply decrement count associatedabstract edge (line 1-2). fourth removal, however, result removingedge (line 4). removal recursively propagated (line 8)abstraction hierarchy, change abstract graph level 2, edge countdecremented.22 edges must removed perform full split top bottomstates level 0 Figure 20. Removing first edge E E level 2 requiresremoval 10 underlying edges level 0 correspond 4 edges level 1 (all edgesA, B, B).State repair first occurs remove edge E E. case E Eparent, G added repair queue (line 5 6). repair queue processedset removal operations. edge E E removed, children G level 3longer form clique. Thus, G must split two states H H. Initially states79fiB ULITKO , TURTEVANT, L U , & YAUremoval / repairLevel 3removal / repairH'Level 3splitsplitGE'HF'E'Level 2Level 1Level 2splitEFB'C'D'BCELevel 1splitEFFA'B'C'D'BCsplitE(10 level 0 edges)A'FA'Level 0Level 0splitsplit(4 level 1 edges)A'F'BCsplitBCFigure 20: example repairing clique abstraction.edge them, edge removed last edges level0 removed. repair code work many abstraction mechanisms. Specifically,check abstract states children still form clique (line 17) changed checkcorresponding property non-clique abstraction.example, amortized cost abstraction repair constant. Imagine agent traversing graph level 0 left right discovering wall splitting top bottom rowsstates (as shown split label figure). step graph sensedagent edges removed level 0 graph. Removing three edges (A, A), (A, B),(B, A) level 1 requires removing six edges level 0. Similarly, removing three edges(E, E), (E, F), (F, E) requires removing 12 edges level 0. general, agent travelinglevel 0 must move twice far (or remove twice many states) repair requiredadditional level abstraction. Thus, number abstraction levels repaired traversing nground edges, is:nnnnn1 + 2 + 3 + 4 + + log2 (n) = O(n).24816nConsequently, example, amortized repair cost per edge traveled O(1). general,worst-case complexity repair O(`) and, PR LRTS, ` constant independent graph size.repairs propagated abstraction hierarchy (line 18 Figure 19).80fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCHAppendix B. Abstraction PropertiesAbstraction properties informally introduced illustrated example Section 4.2.appendix makes presentation mathematically precise. section, variables i, k, runnatural numbers including 0.Property 1. agent using abstraction maintains hierarchy ` abstract search graphs addition model environment. abstract graphs search graph senseSection 2. following denote abstract search graph level i, 1 `(G(i), c(i), s0 (i), sg (i), h0 (i)). before, G(i) = (S(i), E(i)).Property 2. state search graph level n < ` unique parent state s0 leveln + 1 abstract search graph. formally:S(k), k < ` !s0 S(k + 1) parent(s) = s0 .(B.1)Property 3. state search graph level m, 0 < `, least one childstate s0 level 1. notation children(s) represents set children state s. Thus,s0 children(s):S(k), k > 0 s0 S(k 1) s0 children(s) .(B.2)Property 4. Given heuristic search problem S, instance problem, numberchildren abstract state upper-bounded constant independent number states:S, search problem ((S, E), c, s0 , sg , h0 ) i, 0 < ` S(i)[| children(s)| < m] .(B.3)Property 5. (Graph homomorphism) Every edge (s1 , s2 ) E(k), k < n either corresponding abstract edge level k + 1 s1 s2 abstract state:s1 , s2 S(k), k < `[(s1 , s2 ) E(k) = (parent(s1 ), parent(s2 )) E(k + 1) parent(s1 ) = parent(s2 ))] .(B.4)Property 6. edge exists abstract states s1 s2 edgechild s1 child s2 :s1 , s2 S(k), k > 000(s1 , s2 ) E(k) = s1 children(s1 ) s2 children(s2 ) (s01 , s02 ) E(k 1) .last property, need following definition.81(B.5)fiB ULITKO , TURTEVANT, L U , & YAUDefinition B.1 path p space (S(k), E(k)), 0 k ` defined ordered sequencestates S(k) whose two sequential states constitute valid edge E(k). Formally, ppath (S(k), E(k)) if:s1 , . . . , sm S(k) [p = (s1 , . . . , sm ) & i, 1 [(si , si+1 ) E(k)]] .(B.6)use notation p (S(k), E(k)) indicate vertices edges path psets S(k), E(k) respectively. notation p indicates state path p.Property 7 two children abstract state connected path whose stateschildren abstract state:S(k), 0 < k ` s01 , s02 children(s) p = (s01 , . . . , s02 ) (S(k 1), E(k 1)). (B.7)B.1 Abstraction-induced Suboptimality: ExamplesAbstraction cause suboptimality. Figure 21 left, refining abstract path. Solidarrows indicate abstract path. Ground-level path shown thinner dashed arrows.agents position shown goals position G. white cells form corridorinduced abstract path. optimal path shown right.Figure 21: Abstraction causes suboptimality.Partial path refinement increase suboptimality. Refining entire abstract path (Figure 22,left) yield shorter paths refining segment abstract path (Figure 22, right). Solidarrows indicate abstract path. ground-level path shown thinner dashed arrows.agents position shown goals position G.B.2 Abstraction-induced Suboptimality: Upper Boundtwo factors contribute suboptimality paths returned PR LRTS. firstfactor parameters chosen LRTS, weighted allow suboptimality. effectanalyzed literature (Bulitko & Lee, 2006). analyze suboptimalityintroduced abstraction. simplicity analysis consider uniform abstractionlevel k states abstracted parent next level abstraction. assumption simplifies analysis also enables application analysis non-clique abstractionmechanism maintain property. proving result, introduce two simple lemmas:82fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCHFigure 22: Partial path refinement increases suboptimality.Lemma B.1 Suppose abstract edges cost. lowest-cost path p statesB j edges lowest-cost abstract path abstract parents A0 B 0j abstract edges.Proof. prove contradiction. Suppose lowest-cost abstract path q A0 B 0> j edges. consider abstract images states p. either abstractedge coincide due Property 5. Thus form abstract path p0 A0B 0 due Property 2 j edges. Since assumption theoremabstract edges cost, lowest-cost path q A0 B 0 must highercost path p0 A0 B 0 (Figure 23, right). results contradiction.Lemma B.2 path created refining abstract edge level ` cannot longer O(k ` )level 0.Proof. demonstrated right portion Figure 24. assume every abstract stateexactly k children. So, level ` abstraction state cannot k `children. Assuming path cannot visit single node once, refined paththerefore O(k ` ) edges.present main result:Theorem B.1 Assume every abstract state k children ground level edge costs[1, e]. level ` abstraction, cost path created refining abstract pathlevel ` level 0 (the original space) O(ek ` ) times costly optimal pathabstract edges happen uniform cost O(e2 k 2` ) abstract edges costs [1, ek ` ](from Lemma B.2).Proof. First, deal case edges abstract graph uniform cost. Considertwo level-0 states B abstract level-` states A0 , B 0 (left side Figure 23). lowestcost path p B j edges lowest-cost abstract path A0 B 0j abstract edges Lemma B.1.83fiB ULITKO , TURTEVANT, L U , & YAUpath p', j edgespath q, > j edgesA'B'BA'path p, j edgesB'path p', j edgesFigure 23: Proving lowest-cost abstract path j edges.Suppose agent state seeking go state B. agent first computeslowest-cost abstract path A0 B 0 . worst case, abstract path j edges.Suppose two abstract paths A0 B 0 : t01 t02 shown Figure 24, left.j edges and, due uniform abstract edge cost assumption, cost. worstcase scenario, t01 refined lowest-cost path t1 B t02 refinedhighest-cost path t2 B. analyzing cost ratio t1 t2 arriveupper bound theorem.1 edgepath t'2 : j edgesA'level !B'level 0path t'1 : j edgesk ! edgesFigure 24: Paths t01 , t02 cost yet refine shortest longest paths.Due Lemma B.2, one abstract edge level ` refined k ` level-0 edges.worst case, t1 j edges t2 jk ` 1 edges (the result abstracting ` levels k `states single state). Furthermore, edges t1 cost 1 leading total cost t1j. edges t2 cost e leading total cost t2 e(jk ` 1). Thus, ratiot2 t1 costs higher ek ` proves first statement theorem.case abstract edges non-uniform costs [1, ek ` ], consider two abstract paths t01 t02 A0 B 0 . cost ejk ` , highest possiblecost level-` image cost-j ground path. path t01 , abstract cost might overestimatedj abstract edges, cost ek ` refine level-0 path t1 j edgescost 1 each. Thus, total cost t1 j lowest possible cost B.Path t02 cost t01 ejk ` abstract edges, cost 1. Sinceabstract edges refined k ` edges level 0, path t02 refined path t2ejk ` k ` edges, cost e. Consequently, total cost t2e ejk ` k ` = je2 k 2` . Thus, ratio costs t1 t2 e2 k 2` .84fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCHt'1t'1A'BBB'wcct'2wwjwwjFigure 25: grid-based example achieving worst case suboptimality.worst-case upper bound tight, occurs severely underestimate costsuboptimal path overestimate cost optimal path. Figure 25 showhappen practice; level-0 map shown left. lowest-cost path (t1 ) statesB straight line cost j. corridors width 1. length corridors,w, chosen level ` abstraction, states corridor abstract togethersingle state. map cliques size two (i.e., k = 2 Theorem B.1).right part Figure 25 shows level-` abstract graph thick lines original maplight gray. abstraction, path t02 A0 B 0 (the abstract parentsB) goes lower part map. path t02 abstract cost 2c + j + wabstract edges refine w ground-level edges each. Thus, total cost refined path t2w (2c + j) = 2cw + jw. Path t01 abstract image t1 abstract cost w = k `j edges, leading total abstract cost jk ` = jw. shown right sidefigure highly zigzagged path.choose c t02 costs much t01 . agent bad luckchoosing refine t02 . make certainty, make cost t01 slightly highercost t02 . accomplished setting 2c + j + w jw. here, 2c jw j wc jw = jk ` = j2` . result, agent chooses refine t02 t2 , cost2cw + jw = 2j2` 2` + j2` = O(j22` ). ratio cost t1 22` ,corresponds bound theorem k = 2, e = 1.experimental results demonstrate large suboptimality occur practice. illustration, consider histogram suboptimality values 3000 problemsparametrizations PR LRTS Figure 26.suboptimality become practical concern, one use ideas HPA* (Boteaet al., 2004), optimal path costs within regions pre-computed cached. precomputation help prevent severe over- under-estimation abstract path costsassumed worst-case analysis Theorem B.1.Appendix C. Maps Used Empirical Studyfour additional maps shown Figure 27.85fiB ULITKO , TURTEVANT, L U , & YAU1Percentage problems1001011021031020406080Suboptimality (%)100120Figure 26: Histogram suboptimality experiments.Figure 27: four additional maps used experiments.Appendix D. Dominance Average: PlotsSix plots corresponding entries Table 2 shown Figures 28, 29.86fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCHA*LRTS4(9,0.2,)(9,0.2,100)(9,0.4,)(9,0.4,100)LRTS(9,0.2,100)LRTS33(9,0.2,)(9,0.4,)(9,0.4,100)DominatedNondominatedLRTS2(9,0.2,)Firstmove Lag (states touched)LRTS(5,0.2,)LRTS(5,0.4,)(5,0.4,100)33310LRTSLRTS33(3,0.2,)(3,0.4,)LRTS (1,0.4,)4LRTS3(1,0.4,)210LRTS2(1,0.4,)LRTS2(1,0.8,)LRTS1(1,0.4,)LRTS1(1,0.8,)110LRTS(1,0.4,)341010Convergence TravelA*DominatedNondominatedLRTS2(9,0.2,)LRTS2(9,0.2,100)LRTS (5,0.2,)3LRTS (5,0.2,100)3LRTSLRTS44(3,0.2,)(3,0.4,)3Firstmove Lag (seconds)10LRTSLRTS(3,0.2,)(5,0.4,)32LRTS4(1,0.4,)LRTS4(1,0.2,)LRTS3(1,0.4,)LRTS (1,0.4,100)34LRTSLRTS(1,0.4,)(1,0.2,) LRTS (1,0.4,100)2 2210LRTS(1,0.4,)LRTS(1,0.2,)11LRTS(1,0.4,)341010Convergence TravelA*DominatedNondominated3Firstmove Lag (seconds)10LRTS (3,0.2,)3LRTS3(1,0.4,)LRTS (1,0.4,100)3410LRTSLRTS(1,0.4,)(1,0.2,) LRTS (1,0.4,100)2 22LRTSLRTS11(1,0.4,)(1,0.2,)LRTS(1,0.4,)110Convergence Planning (seconds)010Figure 28: Dominance several pairs performance measures. Part 1.Appendix E. Dominance Individual ProblemsSection 5.1 introduced concept dominance demonstrated PR LRTS abstraction dominates extreme search algorithms use abstraction. analysis done using cost values averaged 3000 problems. section consider87fiB ULITKO , TURTEVANT, L U , & YAUA*LRTS4(9,0.2,100)(9,0.2,)LRTS (9,0.2,)(9,0.2,100)LRTS43(5,0.2,)(5,0.2,100)(5,0.4,100)(5,0.4,)DominatedNondominated4Firstmove Lag (states touched)LRTS3(5,0.2,)(5,0.2,100)(5,0.4,)(5,0.4,100)310LRTS3(3,0.2,)(3,0.4,)LRTS4(1,0.2,)(1,0.2,100)(1,0.4,)(1,0.4,100)4LRTS(1,0.2,100)LRTS33(1,0.2,)(1,0.4,)210LRTSLRTS22(1,0.2,)(1,0.4,)LRTS(1,0.2,)LRTS(1,0.4,)11110LRTS(1,0.2,)050010001500Convergence MemoryA*LRTS (5,0.2,100)(5,0.4,!)4DominatedNon!dominatedLRTS3(5,0.2,100)LRTS4(3,0.2,!)(3,0.2,100)LRTSLRTS4 (3,0.4,!)4!3First!move Lag (seconds)10LRTS3(3,0.2,!)LRTS4(1,0.2,!)(1,0.2,100)(1,0.4,100)4LRTS(1,0.2,100)LRTS333(1,0.2,!)(1,0.4,100)!4LRTSLRTS22(1,0.2,!)(1,0.4,100)10LRTS1(1,0.2,!)LRTS(1,0.2,!)LRTS(1,0.4,!)050010001500Convergence MemoryDominatedNondominated25LRTS3(1,0.4,)Suboptimality (%)20LRTS2(1,0.4,)15LRTS3(3,0.2,)LRTSLRTS(3,0.4,)(3,0.4,100)3310LRTS3(5,0.2,)LRTS3(5,0.4,)(5,0.4,100)LRTSLRTS33(5,0.8,)(5,0.8,100)50A*410510Convergence Planning (states touched)610Figure 29: Dominance several pairs performance measures. Part 2.dominance individual problems. Due high variance problems difficulty,report percentages problems dominance achieved. every pair algorithms,measure percentage problems first algorithm dominates second.measure percentage problems second algorithm dominates first. ratiotwo percentages call dominance ratio.88fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCH4103FirstMove Lag10210110010210341051010Convergence Travel4x 10Convergence TravelFirstMove Lag7001460012LRTS_3(1,1.0,)LRTS_3(1,1.0,)500108642400300200100510LRTS(5,0.8,)15200400LRTS(5,0.8,)4x 10600Figure 30: Top: LRTS3 (1, 1.0, ) shown filled star; LRTS(5, 0.8, ) shown hollowstar. Bottom left: convergence travel. Bottom right: first-move lag.Table 4: Statistics two algorithms Figure 30.AlgorithmConvergence travelFirst-move lagLRTS3(1,1.0,!)72.83%97.27%70.97%LRTS(5,0.8,!)27.17%2.67%0.87%Dominance ratio81.89top Figure 30 see reproduction corresponding plot Figure 28two particular algorithms marked stars. filled star LRTS3 (1, 1.0, ) uses threelevels abstraction. hollow star LRTS(5, 0.8, ) operates entirely ground level.Statistics reported Table 4. bottom left figure shows advantages PR LRTSrespect convergence travel. approximately 73% 3000 problems, PR LRTStravels less LRTS convergence (points 45-degree line). respectfirst-move lag, PR LRTS superior LRTS 97% problems (bottom rightfigure). Finally, 71% problems PR LRTS dominates LRTS (i.e., outperforms89fiB ULITKO , TURTEVANT, L U , & YAU25Suboptimality (%)201510503106451010Convergence Planning6Convergence Planningx 1071010Suboptimality (%)6804LRTS_3(5,0.8,)LRTS_3(5,0.8,)53211234LRTS(3,0.2,)56040200606x 10204060LRTS(3,0.2,)80Figure 31: Top: LRTS3 (5, 0.8, ) shown filled star; LRTS(3, 0.2, ) shown hollowstar. Bottom left: convergence planning. Bottom right: suboptimality.respect measures). hand, LRTS dominates PR LRTS approximately1% problems. leads dominance ratio 81.89.Table 5: Statistics two algorithms Figure 31.AlgorithmConvergence planningSuboptimalityLRTS3(5,0.8,!)80.03%55.80%48.97%LRTS(3,0.2,!)19.93%40.97%12.2%Dominance ratio4.01Similarly, Figure 31 compares two algorithms respect convergence planning suboptimality final solution. top figure, corresponding plot Figure 29LRTS3 (5, 0.8, ) shown filled star LRTS(3, 0.2, ) shown hollow star. Percentpoints domination individual problems found Table 5. plot bottom leftfigure shows PR LRTS lower convergence planning cost LRTS 80%problems. plot bottom right shows suboptimality solutions algorithms90fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCHproduced. PR LRTS optimal LRTS 56% time. Finally, PR LRTSdominates LRTS 49% problems. Domination way (i.e., LRTS dominatesPR LRTS) happens 12.2% problems. leads dominance ratio 4.01.several factors influence results. First, high variance difficultyindividual problems due distribution five buckets optimal path distance. Consequently, high variance algorithms trade antagonistic performance measuresproblems. case large difference mean values,Figure 30, dominance average supported dominance majority individual problems. Conversely, small difference mean values (e.g., 2.3% suboptimality algorithmsFigure 31) lead overwhelming dominance level individual problems.extended analysis pairs algorithms displayed Figures 28, 29. convergence travel first-move lag, dominance ratio varies 5.48 valuesinfinity averaging 534.32 standard error 123.47. convergence planningsuboptimality, dominance ratio varies 0.79 values infinity averaging 5.16 standard error 1.51. Finally, set 181 algorithms testedstudy. Therefore, results viewed approximation actual dominancerelationship among algorithms.Appendix F. Interaction Abstraction LRTS ParametersSection 5.2 observed general trends influence abstraction five performance measures. abstraction level adds another dimension parameter space LRTS, previouslydefined d, , , natural question four parameters interact. order facilitatecomprehensible visualization paper, reduce LRTS parameter space d, ,d, setting = (i.e., disabling backtracking LRTS). justified two reasons. First,recent studies (Bulitko & Lee, 2006; Sigmundarson & Bjornsson, 2006) shown effectsbacktracking highly domain-specific.Table 6 gives overview influence abstraction parameters LRTS qualitative level. detailed analysis five performance measures follows.important note experiments performed set fixed cost paths fixed sizemaps. Consequently, map boundary effects observed higher levels abstraction.detail contribution below.Table 6: Influence LRTS parameters impact abstraction. cell table represents impact abstraction either amplified (A) diminished (D) increase. Lower-case indicate minor effect, - indicates effect.increasemeasure / control parameterconvergence travelfirst-move lagconvergence planningconvergence memorysuboptimalityincreaseConvergence travel: increasing abstraction level generally decreases convergence travelLRTS learns smaller abstract maps. Independently, increasing lookahead depth LRTS91fiB ULITKO , TURTEVANT, L U , & YAUConvergence Travelx 10x 10Level 2Level 0Optimality Weight4321010.8Optimality Weight4Difference Convergence Travel1420.81.510.490.40.2130.550.2Lookahead Depth1Convergence Travel35Lookahead Depth9Difference Convergence Travel25001Level 4Level 2Optimality Weight600040002000010.8Optimality Weight20000.8150010000.450090.40.21350.2Lookahead Depth135Lookahead Depth9Figure 32: Convergence travel: impact abstraction function d, . Top two graphs:LRTS(d, ) vs. LRTS2 (d, ). Bottom two graphs: LRTS2 (d, ) vs. LRTS4 (d, ).similar effect (Bulitko & Lee, 2006). Convergence travel lower-bounded doubled optimalcost start goal (as first trial reveal parts map and, consequently,cannot final). Therefore, decreasing convergence travel via either two mechanisms diminishesgains mechanism. effect seen Figure 32 noticeablegap convergence travel abstractions levels 0 2. lookahead 9,small difference using abstraction levels 2 4. Thus, increasing lookaheadslightly diminishes effect abstraction (hence table). Increasing increasesconvergence travel. higher value , gained using abstraction.increase amplifies advantage abstraction.First-move lag generally increases abstraction level lookahead depth.lookahead depth increases, size corridor used A* search increases well. Thus,increasing amplifies first-move lag due abstraction, PR LRTS must plan withinlookahead space (within LRTS) inside corridor (within A*) (Figure 33).Deeper lookahead amplifies impact abstraction. simplified analysis below,assume map obstacle free leads levels abstraction regular grids(ignoring boundary effects). length path two points (expressed numberactions) is, thus, decreased factor two abstraction level. assumptions,total number states PR LRTS touches first move (d2 ) abstract graph92fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCHFirstMove LagDifference FirstMove Lag1001Level 2Level 0200Optimality Weight300020001000010.8Optimality Weight3000.84005006007000.480090.40.21390050.2Lookahead Depth1FirstMove Lag35Lookahead Depth9Difference FirstMove Lag1500Level 4Level 2Optimality Weight4000300020001000010.8Optimality Weight0.8100015000.4200090.40.21350.2Lookahead Depth135Lookahead Depth9Figure 33: First-move lag: impact abstraction function d, . Top two graphs: LRTS(d, )vs. LRTS2 (d, ). Bottom two graphs: LRTS2 (d, ) vs. LRTS4 (d, ).(d 2` ) ground graph. latter quantity simply number edges groundpath computed number edges abstract path (d) multiplied reduction factor2` . Adding abstraction levels increases first-move lag (d 2`+ ). increaselinear function lookahead depth d. Thus, larger values amplify effect adding extraabstraction levels.several points glossed simplified analysis. First, reductionpath length always two-fold assumed above. presence walls, higher levelsabstraction less likely locate merge fully-fledged 4-element cliques. Second, boundariesabstract graph reached LRTS less moves higher abstraction level.effectively decreases quantity formula size corridorreduced generous estimate d2` . Finally, feeding A* longer abstract path often improvesperformance analyzed previous section (cf. Figure 22). explainsabstraction level 4 deepening lookahead diminishing returns seen Figure 33.Optimality weight affect number states touched LRTS abstract level.hand, change cost resulting A* search different abstract path maycomputed LRTS. Overall, however, effect first-move lag impactabstraction inconsequential (Figure 33).93fiB ULITKO , TURTEVANT, L U , & YAUConvergence Planning6Difference Convergence Planningx 1016x 10Level 2Level 02Optimality Weight321010.80.81.510.40.59Optimality Weight0.40.21350.2Lookahead Depth1Convergence Planning9Difference Convergence Planning2500014x 10Level 4Level 220000Optimality Weight642010.8Optimality Weight35Lookahead Depth0.8150001000050000.4090.40.213500050.2Lookahead Depth135Lookahead Depth9Figure 34: Convergence planning: impact abstraction function d, . Top two graphs:LRTS(d, ) vs. LRTS2 (d, ). Bottom two graphs: LRTS2 (d, ) vs. LRTS4 (d, ).Convergence planning: abstraction level increases, convergence planning generallydecreases. effect complex, deeper lookahead increases costindividual planning step, overall decreases planning costs convergence faster. interplaytwo trends moderates overall influence seen Figure 34.effect convergence planning non-trivial. general, lower values reduceconvergence planning cost. Note convergence planning cost product average planningtime per unit distance convergence travel. discussed above, optimality weightamplifies effects abstraction convergence travel. time, substantiallyaffect increase planning per move abstraction goes up. Combining two influences,conclude optimality weight amplify effects abstraction convergence planning.confirmed empirically Figure 34.Convergence memory: Abstraction decreases amount memory used convergence fewer states learn. effects convergence travel described above. strong correlation convergencetravel convergence memory previously discussed. Visually Figures 32 35display similar trends.Suboptimality: Increasing abstraction level increases suboptimality. plain LRTS, lookahead depth effect suboptimality final solution. However, combine deeper94fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCHConvergence MemoryDifference Convergence Memory10001Level 2Level 0Optimality Weight15001000500010.8Optimality Weight8000.86004000.420090.40.21350.2Lookahead Depth1Convergence Memory35Lookahead Depth9Difference Convergence Memory901Level 4Level 280Optimality Weight15010050010.8Optimality Weight700.8605040300.42090.40.2131050.2Lookahead Depth135Lookahead Depth9Figure 35: Convergence memory: impact abstraction function d, . Top two graphs:LRTS(d, ) vs. LRTS2 (d, ). Bottom two graphs: LRTS2 (d, ) vs. LRTS4 (d, ).lookahead abstraction suboptimality arising abstraction decreases. deeper lookahead abstract goal state seen earlier making PR LRTS corridor-constrained A*. Additionally,discussed Section 5.2 Figure 22, refining shorter paths (computed LRTS lowerd) introduces additional suboptimality. suboptimality lower bounded 0%, increasing lookahead diminishes effects abstraction suboptimality (Figure 36) hence Table 6.Increasing decreases amount suboptimality abstraction used. combined abstraction increasing minor amplification effect difference abstractionmakes (Figure 36) two reasons. First, abstract levels graphs fairly small makesless difference there. Second, degree suboptimality abstract path translate directlydegree suboptimality resulting ground path A* may still find reasonableground path. Thus, influence abstract level overshadowed suboptimalyintroduced process refinement (cf. Figure 21).95fiB ULITKO , TURTEVANT, L U , & YAUSuboptimality (%)Difference Suboptimality (%)01Level 2Level 02Optimality Weight30201000.20.450.81Optimality Weight930.8468100.41210.2Lookahead Depth1Suboptimality (%)35Lookahead Depth9Difference Suboptimality (%)01Level 4Level 22Optimality Weight30201000.20.450.8Optimality Weight191430.84680.41010.2Lookahead Depth135Lookahead Depth9Figure 36: Suboptimality: impact abstraction function d, . Top two graphs: LRTS(d, )vs. LRTS2 (d, ). Bottom two graphs: LRTS2 (d, ) vs. LRTS4 (d, ).96fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCHReferencesAylett, R., & Luck, M. (2000). Applying artificial intelligence virtual reality: Intelligent virtualenvironments. Applied Artificial Intelligence, 14(1), 332.Bacchus, F., & Yang, Q. (1994). Downward refinement efficiency hierarchical problemsolving.. Artificial Intelligence, 71(1), 43101.BioWare Corp. (1998). Baldurs Gate., Published Interplay, http://www.bioware.com/bgate/,November 30, 1998.Blizzard Entertainment (2002). Warcraft III: Reign Chaos., Published Blizzard Entertainment,http://www.blizzard.com/war3, July 3, 2002.Botea, A., Muller, M., & Schaeffer, J. (2004). Near Optimal Hierarchical Path-Finding. JournalGame Development, 1(1), 728.Bulitko, V. (2004). Learning adaptive real-time search. Tech. rep. http: // arxiv. org / abs / cs.AI/ 0407016, Computer Science Research Repository (CoRR).Bulitko, V., & Lee, G. (2006). Learning real time search: unifying framework. JournalArtificial Intelligence Research (JAIR), 25, 119 157.Bulitko, V., Sturtevant, N., & Kazakevich, M. (2005). Speeding learning real-time search viaautomatic state abstraction. Proceedings National Conference Artificial Intelligence (AAAI), pp. 1349 1354, Pittsburgh, Pennsylvania.Culberson, J., & Schaeffer, J. (1996). Searching pattern databases. CSCI (Canadian AIConference), Advances Artificial Intelligence, pp. 402416. Springer-Verlag.Dini, D. M., van Lent, M., Carpenter, P., & Iyer, K. (2006). Building robust planning executionsystems virtual worlds. Proceedings Artificial Intelligence Interactive DigitalEntertainment conference (AIIDE), pp. 2935, Marina del Rey, California.Ensemble Studios (1999). Age Empires II: Age Kings., Published Microsoft Game Studios,http://www.microsoft.com/games/age2, June 30, 1999.Felner, A., Zahavi, U., Schaeffer, J., & Holte, R. (2005). Dual lookups pattern databases.Proceedings International Joint Conference Artificial Intelligence (IJCAI), pp. 103108, Edinburgh, United Kingdom.Furcy, D. (2006). ITSA*: Iterative tunneling search A*. Proceedings NationalConference Artificial Intelligence (AAAI), Workshop Heuristic Search, Memory-BasedHeuristics Applications, Boston, Massachusetts.Furcy, D., & Koenig, S. (2000). Speeding convergence real-time search. ProceedingsNational Conference Artificial Intelligence (AAAI), pp. 891897.Furcy, D., & Koenig, S. (2005). Limited discrepancy beam search. Proceedings International Joint Conference Artificial Intelligence (IJCAI), pp. 125131.Garey, M. R., & Johnson, D. S. (1990). Computers Intractability; Guide TheoryNP-Completeness. W. H. Freeman & Co., New York, NY, USA.Hansen, E. A., & Zhou, R. (2007). Anytime heuristic search. Journal Artificial IntelligenceResearch (JAIR), 28, 267297.97fiB ULITKO , TURTEVANT, L U , & YAUHansen, E. A., Zilberstein, S., & Danilchenko, V. A. (1997). Anytime heuristic search: First results.Tech. rep. CMPSCI 97-50, Computer Science Department, University Massachusetts.Hart, P., Nilsson, N., & Raphael, B. (1968). formal basis heuristic determinationminimum cost paths. IEEE Transactions Systems Science Cybernetics, 4(2), 100107.Hernandez, C., & Meseguer, P. (2005a). Improving convergence LRTA*(k). ProceedingsInternational Joint Conference Artificial Intelligence (IJCAI), Workshop PlanningLearning Priori Unknown Dynamic Domains, pp. 6975, Edinburgh, UK.Hernandez, C., & Meseguer, P. (2005b). LRTA*(k). Proceedings International JointConference Artificial Intelligence (IJCAI), pp. 12381243, Edinburgh, UK.Holte, R., Mkadmi, T., Zimmer, R. M., & MacDonald, A. J. (1996). Speeding problem solvingabstraction: graph oriented approach. Artificial Intelligence, 85(1-2), 321361.Holte, R., Perez, M., Zimmer, R., & MacDonald, A. (1995). Hierarchical A*: Searching abstractionhierarchies efficiently. Tech. rep. tr-95-18, University Ottawa.id Software (1993). Doom., Published id Software, http://en.wikipedia.org/wiki/Doom, December 10, 1993.Ishida, T. (1992). Moving target search intelligence. National Conference ArtificialIntelligence (AAAI), pp. 525532.Ishida, T., & Korf, R. (1991). Moving target search. Proceedings International JointConference Artificial Intelligence (IJCAI), pp. 204210.Kitano, H., Tadokoro, S., Noda, I., Matsubara, H., Takahashi, T., Shinjou, A., & Shimada, S. (1999).Robocup rescue: Search rescue large-scale disasters domain autonomous agentsresearch. Proceedings IEEE Conference Man, Systems, Cybernetics, Vol. 4,pp. 739743.Koenig, S. (1999). Exploring unknown environments real-time search reinforcement learning. Proceedings Neural Information Processing Systems, pp. 10031009.Koenig, S. (2004). comparison fast search methods real-time situated agents. Proceedings Int. Joint Conf. Autonomous Agents Multiagent Systems, pp. 864 871.Koenig, S., & Likhachev, M. (2002a). D* Lite. Proceedings National ConferenceArtificial Intelligence (AAAI), pp. 476483.Koenig, S., & Likhachev, M. (2002b). Incremental A*. Advances Neural Information Processing Systems (NIPS), pp. 15391546.Koenig, S. (2001). Agent-centered search. Artificial Intelligence Magazine, 22(4), 109132.Koenig, S., & Likhachev, M. (2006). Real-time adaptive A*. Proceedings InternationalJoint Conference Autonomous Agents Multiagent Systems (AAMAS), pp. 281288.Koenig, S., & Simmons, R. (1998). Solving robot navigation problems initial pose uncertaintyusing real-time heuristic search. Proceedings International Conference ArtificialIntelligence Planning Systems, pp. 144 153.Koenig, S., Tovey, C., & Smirnov, Y. (2003). Performance bounds planning unknown terrain.Artificial Intelligence, 147, 253279.98fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCHKorf, R. (1990). Real-time heuristic search. Artificial Intelligence, 42(2-3), 189211.Likhachev, M., Ferguson, D., Gordon, G., Stentz, A., & Thrun, S. (2005). Anytime dynamic A*:anytime, replanning algorithm. Proceedings International Conference AutomatedPlanning Scheduling (ICAPS).Likhachev, M., Gordon, G. J., & Thrun, S. (2004). Ara*: Anytime a* provable bounds suboptimality. Thrun, S., Saul, L., & Scholkopf, B. (Eds.), Advances Neural InformationProcessing Systems 16. MIT Press, Cambridge, MA.Lustrek, M., & Bulitko, V. (2006). Lookahead pathology real-time path-finding. ProceedingsNational Conference Artificial Intelligence (AAAI), Workshop Learning Search,pp. 108114, Boston, Massachusetts.Mero, L. (1984). heuristic search algorithm modifiable estimate. Artificial Intelligence, 23,1327.Orkin, J. (2006). 3 states & plan: AI F.E.A.R. Proceedings Game DevelopersConference (GDC). http://www.jorkin.com/gdc2006 orkin jeff fear.doc.Pearl, J. (1984). Heuristics. Addison-Wesley.Pohl, I. (1970). First results effect error heuristic search. Meltzer, B., & Michie, D.(Eds.), Machine Intelligence, Vol. 5, pp. 219236. American Elsevier, New York.Pohl, I. (1973). avoidance (relative) catastrophe, heuristic competence, genuine dynamicweighting computaional issues heuristic problem solving. Proceedings International Joint Conference Artificial Intelligence (IJCAI), pp. 1217.Pottinger, D. C. (2000). Terrain analysis realtime strategy games. Proceedings ComputerGame Developers Conference. www.gamasutra.com/features/gdcarchive/2000/pottinger.doc.Rayner, D. C., Davison, K., Bulitko, V., Anderson, K., & Lu, J. (2007). Real-time heuristic searchpriority queue. Proceedings International Joint Conference ArtificialIntelligence (IJCAI), pp. 23722377, Hyderabad, India.Reynolds, C. W. (1987). Flocks, herds schools: distributed behavioral model. SIGGRAPH87: Proceedings 14th Annual Conference Computer Graphics Interactive Techniques, pp. 2534, New York, NY, USA. ACM Press.Russell, S., & Wefald, E. (1991). right thing: Studies limited rationality. MIT Press.Shimbo, M., & Ishida, T. (2003). Controlling learning process real-time heuristic search.Artificial Intelligence, 146(1), 141.Shue, L.-Y., Li, S.-T., & Zamani, R. (2001). intelligent heuristic algorithm project schedulingproblems. Proceedings 32nd Annual Meeting Decision Sciences Institute.Shue, L.-Y., & Zamani, R. (1993). admissible heuristic search algorithm. Proceedings7th International Symposium Methodologies Intelligent Systems (ISMIS-93), Vol. 689LNAI, pp. 6975.Sigmundarson, S., & Bjornsson, Y. (2006). Value Back-Propagation vs. Backtracking RealTime Search. Proceedings National Conference Artificial Intelligence (AAAI),Workshop Learning Search, Boston, Massachusetts, USA. AAAI Press.99fiB ULITKO , TURTEVANT, L U , & YAUStenz, A. (1995). focussed D* algorithm real-time replanning. ProceedingsInternational Joint Conference Artificial Intelligence (IJCAI), pp. 16521659.Stout, B. (1996). Smart moves: Intelligent pathfinding. Game Developer Magazine, October, 2835.Sturtevant, N. (2005). HOG - Hierarchical Open Graph. http://www.cs.ualberta.ca/nathanst/hog/.Sturtevant, N. (2007). Memory-efficient abstractions pathfinding. Proceedings thirdconference Artificial Intelligence Interactive Digital Entertainment, pp. 3136, Stanford, California.Sturtevant, N., & Buro, M. (2005). Partial pathfinding using map abstraction refinement.Proceedings National Conference Artificial Intelligence (AAAI), pp. 13921397,Pittsburgh, Pennsylvania.Sturtevant, N., & Jansen, R. (2007). analysis map-based abstraction refinement.Proceedings 7th International Symposium Abstraction, Reformulation Approximation, Whistler, British Columbia. (in press).Sutton, R. (1990). Integrated architectures learning, planning, reacting based approximating dynamic programming. Proceedings Seventh International ConferenceMachine Learning, pp. 216224. Morgan Kaufmann.Thalmann, D., Noser, H., & Huang, Z. (1997). Autonomous virtual actors based virtual sensors.Lecture Notes Computer Science (LNCS), Creating Personalities Synthetic Actors,Towards Autonomous Personality Agents, Vol. 1195, pp. 2542. Springer-Verlag, London.Yahja, A., Stentz, A. T., Singh, S., & Brummit, B. (1998). Framed-quadtree path planning mobilerobots operating sparse environments. Proceedings, IEEE Conference RoboticsAutomation, (ICRA), Leuven, Belgium.100fi