Journal Artificial Intelligence Research 5 (1996) 139-161

Submitted 4/96; published 10/96

Learning First-Order Definitions Functions
J. R. Quinlan

quinlan@cs.su.oz.au

Basser Department Computer Science
University Sydney
Sydney 2006 Australia

Abstract

First-order learning involves finding clause-form definition relation examples
relation relevant background information. paper, particular first-order
learning system modified customize finding definitions functional relations.
restriction leads faster learning times and, cases, definitions
higher predictive accuracy. first-order learning systems might benefit similar
specialization.

1. Introduction
Empirical learning subfield AI develops algorithms constructing theories
data. classification research area used attribute-value formalism,
data represented vectors values fixed set attributes labelled
one small number discrete classes. learning system develops mapping
attribute values classes used classify unseen data.
Despite well-documented successes algorithms developed paradigm (e.g.,
Michie, Spiegelhalter, Taylor, 1994; Langley Simon, 1995), potential
applications learning fit within it. Data may concern objects observations
arbitrarily complex structure cannot captured values predetermined
set attributes. Similarly, propositional theory language employed attribute-value
learners may inadequate express patterns structured data. Instead, may
necessary describe learning input relations, relation set tuples
constants, represent learned first-order language. Four examples
practical learning tasks kind are:

Speeding logic programs (Zelle Mooney, 1993). idea learn

guard nondeterministic clause inhibits execution unless lead
solution. Input learner consists Prolog program one
execution traces. one example Dolphin, system cited above, transformed
program complexity O(n!) O(n2 ).

Learning search control heuristics (Leckie Zukerman, 1993). Formulation pref-

erence criteria improve eciency planning applications similar avor.
One task investigated familiar `blocks world' varying numbers
blocks must rearranged robot manipulator. input learning concerns
particular situation search includes complete description current planning state goals. amount information increases

c 1996 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiQuinlan

number blocks inter-relationships, cannot encoded fixed set
values.
Recovering software specifications. Cohen (1994) describes application based
software system consisting million lines C code. Part system implements virtual relations compute projections joins underlying base
relations, goal reconstruct definitions. Input learning consists
queries, responses, traces showing base relations accessed answering queries. output logical description virtual relation; since
involves quantified variables, lies beyond scope propositional attribute-value
languages.
Learning properties organic molecules (Muggleton, King, Sternberg, 1992;
Srinivasan, Muggleton, Sternberg, King, 1996). approach learning
papers based representing structure molecules
addition properties molecules molecule segments. latter paper notes
discovery useful indicator mutagenicity expressed terms structure.
development learning methods based powerful relational formalism
sometimes called inductive logic programming (Muggleton, 1992; Lavrac Dzeroski,
1994; De Raedt, 1996). Input typically consists tuples belong, belong,
target relation, together relevant information expressed set background
relations. learning task formulate definition target relation terms
background relations.
relational learning task described detail following section. Several
algorithms relational learning developed recently, Section 3 introduces
one system called foil (Quinlan, 1990). foil used relations
kind, one particularly common use relations represent functions. Changes
foil effect customize learning functional relations outlined Section 4.
Several comparative studies, presented Section 5, show specialization leads
much shorter learning times and, cases, accurate definitions. Related work
learning functional relations discussed Section 6, paper ends
conclusions study directions development.

2. Relational Learning

n-ary relation consists set n-tuples ground terms (here constants).
constants ith position tuples belong type, types may differentiated constants may taken belong single universal type.
alternative extensional definition (possibly infinite) set, relation
specified intensionally via n-argument predicate RI defined Prolog program.

hc1 ; c2 ; :::cn 2 RI (c1 ; c2 ; :::; cn ) true
constants fci g, intensional extensional definitions equivalent.
convenience, subscripts RI omitted R used denote
either set tuples predicate.
140

fiLearning First-Order Definitions Functions

Input relational learning task consists extensional information target
relation R extensional intensional definitions collection background relations.
Examples tuples known belong target relation provided and, cases,
examples tuples known belong R. goal learn Prolog program
R covers tuples known belong R tuples known belong R
or, words, program agrees extensional information provided
R.
Many relations interest infinite. alternative selecting examples belong
belong R define finite vocabulary V specify relations respect
vocabulary. is, R represented finite set tuples, constants
belong V . Since specification R complete vocabulary, tuples
belong R inferred closed world assumption complement
tuples R.
function f (X1 ; X2 ; :::; Xk ) k arguments represented k+1-ary relation
F (X1 ; X2 ; :::; Xk ; Xk+1 ) where, tuple F , value last argument
result applying f first k arguments. (Rouveirol (1994) proves attening
used remove non-constant function symbols first-order language.)
functional relations additional property constants fc1 ; c2 ; ::; ck g
exactly one value ck+1 hc1 ; c2 ; :::; ck+1 belongs F .
example, consider three-argument predicate append(A,B,C) whose meaning
result appending list list B list C.1 corresponding relation append
infinite, restricted vocabulary defined lists containing elements
f1,2,3g whose length less equal 3. 40 lists
[ ], [1], [2], [3], [1,2], ...., [3,3,2], [3,3,3]

64,000 3-tuples lists. respect vocabulary, append consists 142
3-tuples, viz.:

h[ ],[ ],[ ]i, h[ ],[1],[1]i, ..., h[2],[1,3],[2,1,3]i, ..., h[3,3,3],[ ],[3,3,3]i.
also background relation components, components(A,B,C) means list
head B tail C. goal learn intensional definition append given
background relation components. suitable result might expressed
append([ ],A,A).
append(A,B,C) :- components(A,D,E), append(E,B,F), components(C,D,F).

recognizable Prolog definition append.
1. Prolog, append invoked combination arguments bound find possible
values unbound arguments. Section 5.1, however, append treated function
first two arguments third.

141

fiQuinlan

Initialization:
definition := null program
remaining := tuples belonging target relation R
remaining empty
/* Grow new clause */
clause := R(A; B; :::) :While clause covers tuples known belong R
/* Specialize clause */
Find appropriate literal(s) L
Add L body clause
Remove remaining tuples R covered clause
Add clause definition
Figure 1: Outline foil

3. Description foil

common many first-order learning systems, foil requires background relations also defined extensionally sets tuples constants.2 Although intensional
definition learned particular set examples, intended executable
Prolog program background relations may also specified intensionally
definitions rather sets ground tuples. instance, although append definition
might learned particular examples lists, correctly append
arbitrary lists, provided components specified suitable clausal definition. (The
applicability learned definitions unseen examples cannot guaranteed, however; Bell
Weber (1993) call open domain assumption.)
language foil expresses theories restricted form Prolog omits
cuts, fail, disjunctive goals, functions constants, allows negated literals
not(L(...)). essentially Datalog language specified Ullman (1988), except
requirement variables negated literal appear also head
another unnegated literal; foil interprets using negation failure (Bratko, 1990).

3.1 Broad-brush overview
outlined Figure 1, foil uses separate-and-conquer method, iteratively learning
clause removing tuples target relation R covered clause none
remain. clause grown repeated specialization, starting general clause
2. Prominent exceptions include focl (Pazzani Kibler, 1992), filp (Bergadano Gunetti, 1993),
Foidl (Mooney Califf, 1995), allow background relations defined extensionally,
Progol (Muggleton, 1995), information relations non-ground form.

142

fiLearning First-Order Definitions Functions

head adding literals body clause cover tuples known
belong R.
Literals appear body clause restricted requirement
programs function-free, constants appearing equalities. possible
literal forms foil considers are:

Q(X1 ; X2 ; :::; Xk ) (Q(X1 ; X2 ; :::; Xk )), Q relation Xi's de-

note known variables bound earlier clause new variables.
least one variable must bound earlier partial clause, either
head literal body.

Xi =Xj Xi 6=Xj , known variables Xi Xj type.
Xi =c Xi6=c, Xi known variable c constant appropriate

type. constants designated suitable appear definition
considered { reasonable definition append might reference null list [ ]
arbitrary list [1,2].

Xi Xj , Xi > Xj , Xi t, Xi > t, Xi Xj known variables
numeric values threshold chosen foil.

learned definition must pure Prolog, negated literal forms (Q(:::)) Xi 6=...
excluded option.
Clause construction guided different possible bindings variables partial
clause satisfy clause body. clause contains k variables, binding k-tuple
constants specifies value variables sequence. possible binding
labelled according whether tuple values variables clause head
belong target relation.
illustration, consider tiny task constructing definition plus(A,B,C),
meaning A+B = C, using background relation dec(A,B), denoting B = A,1.
vocabulary restricted integers 0, 1, 2, plus consists tuples

h0,0,0i, h1,0,1i, h2,0,2i, h0,1,1i, h1,1,2i, h0,2,2i
dec contains h1,0i h2,1i.
initial clause consists head
plus(A,B,C) :-

variable unique. labelled bindings corresponding initial partial
clause tuples belong, belong, target relation, i.e.:

h0,0,0i
h0,0,1i
h1,0,0i
h1,2,2i
h2,2,0i

h1,0,1i
h0,0,2i
h1,0,2i
h2,0,0i
h2,2,1i

h2,0,2i
h0,1,0i
h1,1,0i
h2,0,1i
h2,2,2i

h0,1,1i
h0,1,2i
h1,1,1i
h2,1,0i

143

h1,1,2i
h0,2,0i
h1,2,0i
h2,1,1i

h0,2,2i
h0,2,1i
h1,2,1i
h2,1,2i

.

fiQuinlan

foil repeatedly tries construct clause covers tuples target relation

R tuples definitely R. restated finding clause

bindings bindings, one reason adding literal clause
move direction increasing relative proportion bindings. gainful
literals evaluated using information-based heuristic. Let number
bindings partial clause n n respectively. average information provided
discovery one bindings label
!
n


(n ; n ) = , log2 n + n bits.
literal L added, bindings may excluded rest give
rise one bindings new partial clause. Suppose k n bindings
excluded L, numbers bindings new partial clause
respectively. L chosen increase proportion bindings, total
information gained adding L

k (I (n; n ) , (m ; )) bits.
Consider result specializing clause addition literal A=0.
nine bindings eliminated corresponding values variables
satisfy new partial clause. bindings reduced

h0,0,0i h0,1,1i h0,2,2i
h0,0,1i h0,0,2i h0,1,0i h0,1,2i h0,2,0i h0,2,1i
proportion bindings increased 6/27 3/9. information
gained adding literal therefore 3 (I (6; 21) , (3; 6)) 2 bits. Adding
literal B=C excludes bindings, giving complete first clause
plus(A,B,C) :- A=0, B=C.

or, would commonly written,
plus(0,B,B).

clause covers three tuples plus removed set tuples
covered subsequent clauses. commencement search second clause,
head plus(A,B,C) bindings

h1,0,1i
h0,0,1i
h1,0,0i
h1,2,2i
h2,2,0i

h2,0,2i
h0,0,2i
h1,0,2i
h2,0,0i
h2,2,1i

h1,1,2i
h0,1,0i h0,1,2i h0,2,0i h0,2,1i
h1,1,0i h1,1,1i h1,2,0i h1,2,1i
h2,0,1i h2,1,0i h2,1,1i h2,1,2i
h2,2,2i
.

literals added body first clause gain information. quite different justification adding literal introduce new variables
may needed final clause. Determinate literals based idea introduced
144

fiLearning First-Order Definitions Functions

Golem (Muggleton Feng, 1992). determinate literal one introduces new
variables new partial clause exactly one binding binding
current clause, one binding binding. Determinate literals useful introduce new variables, neither reduce potential coverage
clause increase number bindings.
bindings include A=0, literal dec(A,D) determinate
because, value A, one value satisfies literal. Similarly, since
bindings contain none C=0, literal dec(C,E) also determinate.
Figure 1, literals L added foil step

literal greatest gain, gain near maximum possible
(namely n (n ; n )) ; otherwise
determinate literals found; otherwise
literal highest positive gain; otherwise
first literal investigated introduces new variable.
start second clause, literal near-maximum gain determinate
literals added clause body. partial clause
plus(A,B,C) :- dec(A,D), dec(C,E),

five variables bindings satisfy

h1,0,1,0,0i h2,0,2,1,1i h1,1,2,0,1i
h1,0,2,0,1i h1,1,1,0,0i h2,0,1,1,0i h2,1,1,1,0i h2,1,2,1,1i
literal plus(B,D,E), uses newly-introduced variables, satisfied
three bindings none bindings, giving complete second clause
plus(A,B,C) :- dec(A,D), dec(C,E), plus(B,D,E).

tuples plus covered one clauses, constitute complete
intensional definition target relation.

3.2 Details omitted
foil good deal complex overview would suggest. Since

important paper, matters following discussed here,
covered (Quinlan Cameron-Jones, 1993; 1995):

Recursive soundness. goal able execute learned definitions

ordinary Prolog programs, important terminate. foil elaborate
mechanism ensure recursive literal (such plus(B,D,E) above)
added clause body cause problems respect, least ground
queries.
145

fiQuinlan

Pruning. practical applications numerous background relations, number

possible literals L could added step grows exponentially
number variables partial clause. foil employs heuristics limit
space, Golem's bound depth variable (Muggleton Feng,
1992). importantly, regions literal space pruned without
examination shown contain neither determinate literals,
literals higher gain best gainful literal found far.
complete search. presented above, foil straightforward greedy hillclimbing algorithm. fact, foil sometimes reach impasse
search clause, contains limited non-chronological backtracking facility
allow recover situations.
Simplifying definitions. addition partial clause determinate literals
found may seem excessive. However, clause completed, foil examines
literal clause body see whether could discarded without causing
simpler clause match tuples target relation R. Similarly,
definition complete, clause checked see whether could omitted
without leaving tuples R uncovered. also heuristics aim
make clauses understandable substituting simpler literals (such variable
equalities) literals based complex relations.
Recognizing boundaries closed worlds. literals appear discriminate
bindings consequence boundary effects attributable
limited vocabulary.3 definition including literals executed larger
vocabularies, open domain assumption mentioned may violated. foil
contains optional mechanism describing literals might satisfied
bindings outside closed world, allowing literals unpredictable behavior
excluded.
Quinlan (1990) Quinlan Cameron-Jones (1995) summarize several applications
successfully addressed foil, also discussed Section 5.

4. Learning Functional Relations
learning approach used foil makes assumptions form target

relation R. However, append plus above, relation often used represent
function { tuple constants satisfies R, last constant uniquely determined
others. Bergadano Gunetti (1993) show property exploited
make learning task tractable.

4.1 Functional relations foil
Although foil learn definitions functional relations, handicapped two ways:
Ground queries: foil's approach recursive soundness assumes ground
queries made learned definition. is, definition R(X1 ; X2 ; :::; Xn )

3. example arises Section 5.1.

146

fiLearning First-Order Definitions Functions

used provide true-false answers queries form R(c1 ; c2 ; :::; cn )?
ci 's constants. R functional relation, however, sensible query
would seem R(c1 ; c2 ; :::; cn,1 ; X )? determine value function
specified ground arguments. case plus, instance, would expect ask plus(1,1,2)? (\is 1+1=2?"), rather plus(1,1,X)? (\what 1+1?").
R(c1 ; c2 ; :::; cn,1 ; X )? called standard query functional relations.
Negative examples: foil needs tuples belong target relation
least not. common ILP systems Golem (Muggleton
Feng, 1992), latter used detect partial clause still general.
specified foil directly or, commonly, derived
closed world assumption that, respect vocabulary, tuples R
given. second mechanism often lead large collections tuples
R; nearly 64,000 append illustration earlier. Every
tuple belonging R results binding start clause,
uncomfortably many bindings must maintained tested stage
clause development.4 However, functional relations need explicit counterexamples, even set tuples belonging R complete respect
vocabulary { knowing hc1 ; c2 ; :::; cn belongs R implies
constant c0n hc1 ; c2 ; :::; c0n R.
problematic aspects foil vis vis functional relations suggest modifications
address them. alterations lead new system, ffoil, still close spirit
progenitor.

4.2 Description ffoil

Since last argument functional relation special role, referred
output argument relation. Similarly, variable corresponding argument
head clause called output variable.
fundamental change ffoil concerns bindings partial clauses
way labelled. new constant 2 introduced indicate undetermined
value output variable binding. Bindings labelled according value
output variable, namely value correct (given value earlier
constants), value incorrect, fi value undetermined.
outline ffoil (Figure 2) similar Figure 1, differences
highlighted. start clause one binding every remaining tuple
target relation. output variable value 2 bindings value
changed subsequent literal assigns value variable. small
plus example Section 3.1, initial bindings first clause
h0,0,2i fi h1,0,2i fi h2,0,2i fi h0,1,2i fi h1,1,2i fi h0,2,2i fi
Like ancestor, ffoil also assesses potential literals adding clause body
gainful determinate, although concepts must adjusted accommodate new
label fi. Suppose r distinct constants range target function.
4. reason, foil includes option sample bindings instead using them.

147

fiQuinlan

Initialization:
definition := null program
remaining := tuples belonging target relation R
remaining empty
/* Grow new clause */
clause := R(A; B; :::) :While clause fi bindings
/* Specialize clause */
Find appropriate literal(s) L
Add L body clause
Remove remaining tuples R covered clause
Add clause definition
Simplify final definition
Add default clause
Figure 2: Outline ffoil

fi binding converted binding changing 2 correct value
function, binding changing 2 r , 1 incorrect values.
computing information gain, ffoil thus counts fi binding 1 binding r , 1
bindings. determinate literal one introduces one variables that,
new partial clause, exactly one binding current fi binding
one binding current binding. ffoil uses preference criterion
adding literals L: literal near-maximum gain, determinate literals,
gainful literal, finally non-determinate literal introduces new variable.
first literal chosen foil Section 3.1 A=0 since increases concentration bindings 9 64 3 9 (with corresponding information gain).
ffoil's perspective, however, literal simply reduces six fi bindings three gives
gain; range plus set f0,1,2g, r = 3, putative concentration
bindings would alter 6 18 3 9. literal A=C, hand, causes
value output variable determined results bindings

h0,0,0i h1,0,1i h2,0,2i
h0,1,0i h1,1,1i h0,2,0i .
corresponds increase concentration bindings notional 6 18

3 6, information gain 2 bits. literal added
clause body, ffoil finds literal B=0 eliminates bindings, giving
148

fiLearning First-Order Definitions Functions

complete clause
plus(A,B,C) :- A=C, B=0.

remaining tuples plus give bindings

h0,1,2i fi h1,1,2i fi h0,2,2i fi
start second clause. literals dec(B,D) dec(E,A) determinate
and, added clause, bindings become

h0,1,2,0,1i fi h1,1,2,0,2i fi h0,2,2,1,1i fi
output variable still undetermined. partial clause specialized
adding literal plus(E,D,C), new bindings

h0,1,1,0,1i h1,1,2,0,2i h0,2,2,1,1i
give correct value C case. Since fi bindings, clause

also complete.
One important consequence new way bindings initialized start
clause easily overlooked. foil, one binding tuple
belong R; since clause excludes bindings, discriminates tuples
R tuples R. reason learned clauses regarded
set executed order without changing set answers query.
ffoil, however, initial bindings concern remaining tuples R, learned
clause depends context established earlier clauses. example, suppose target
relation background relation defined
= fhv,1i, hw,1i, hx,1i, hy,0i, hz,0ig
= fhvi, hwi, hxig .

first clause learned ffoil might
S(A,1) :- T(A).

remaining bindings fhy,0i, hz,0ig could covered clause
S(A,0).

latter clause clearly correct standard queries covered
first clause. example illustrates, learned clauses must interpreted order
learned, clause must ended cut `!' protect later
clauses giving possibly incorrect answers query. Since target relation R
functional, one correct response standard query defined above,
use cuts safe cannot rule correct answer.
foil ffoil tend give easily learning definitions explain noisy
data. result over-specialized clauses cover target relation partially.
tasks definition learned ffoil incomplete, final global simplification
149

fiQuinlan

phase invoked. Clauses definition generalized removing literals long
total number errors target relation increase. way, accuracy
individual clauses balanced accuracy definition whole; simplifying
clause removing literal may increase number errors made clause,
offset reduction number uncovered bindings consequently
lower global error rate. clauses simplified much possible, entire
clauses contribute nothing accuracy definition removed.
final step Figure 2, target relation assumed represent total function,
consequence response must always returned standard query.
safeguard, ffoil adds default clause

R(X1 ; X2 ; :::; Xn,1 ; c):
c common value function.5 common value output
argument plus 2, complete definition example, normal Prolog notation,
becomes
plus(A,0,A) :- !.
plus(A,B,C) :- dec(B,D), dec(E,A), plus(E,D,C), !.
plus(A,B,2).

4.3 Advantages disadvantages ffoil

Although definitions plus Sections 3.1 4.2 superficially similar,
considerable differences learning processes constructed
operational characteristics used.

ffoil generally needs maintain fewer bindings learns quickly. Whereas

foil keeps 27 bindings learning definition plus, ffoil never uses
6.

output variable guaranteed bound every clause learned ffoil.
necessarily case foil, since requirement every variable
appearing head must also appear clause body.

Definitions found ffoil often execute eciently foil counterparts.

Firstly, ffoil definitions, use cuts, exploit fact cannot
one correct answer standard query. Secondly, clause bodies constructed
ffoil tend use output variable bound, less
backtracking evaluation. illustration, foil definition Section
3.1 evaluates 81 goals answering query plus(1,1,X)?, many six
evaluations needed ffoil definition query.

also entries side ledger:
5. default clause added value function occurs once.

150

fiLearning First-Order Definitions Functions

Task

Bkgd
Relns

append
last element
reverse
left shift
translate

2
3
10
12
14

Length 3
Bindings
Time





foil ffoil

142 63,858
3.0
39
81
0.0
40 1560
2.6
39 1561
0.5
40 3120 817.9

Length 4
Bindings
Time





foil ffoil

0.5 1593 396,502 22.4
0.0 340
1024
0.5
0.3 341 115,940 195.9
0.3 340 115,940 26.6
1.1 341 115,940 495.9

10.9
0.3
9.0
6.8
28.0

Table 1: Results tasks (Bratko, 1990).

foil applicable learning tasks ffoil, limited learning
definitions functional relations.

implementation ffoil complex foil. example, many

heuristics pruning literal search space checking recursive soundness
require special cases constant 2 fi bindings.

5. Empirical Trials

section performance ffoil variety learning tasks summarized
compared foil (release 6.4). Since systems similar respects,
comparison highlights consequences restricting target relation function.
Times DEC AXP 3000/900 workstation. learned definitions first
three subsections may found Appendix.

5.1 Small list manipulation programs

Quinlan Cameron-Jones (1993) report results applying foil 16 tasks taken
Bratko's (1990) well-known Prolog text. list-processing examples exercises
Chapter 3 attempted sequence, background information task
includes previously-encountered relations (even though irrelevant
task hand). Two different vocabularies used: 40 lists length 3
three elements 341 lists length 4 four elements.
Table 1 describes five functional relations set presents performance
foil ffoil them. learned definitions correct arbitrary lists,
one exception { foil's definition reverse learned larger vocabulary includes
clause
reverse(A,A) :- append(A,A,C), del(D,E,C).

exploits bounded length lists.6 times reveal considerable advantage
6. C twice length E one element longer C still length 4,
length must 0 1. case reverse.

151

fiQuinlan

Task
foil ffoil
quicksort
4.7
2.2
bubblesort 7.3
0.4
Table 2: Times (sec) learning sort.

[3,3]
0.7
0.8
Golem 4.8
Progol 43.0

ffoil
foil

Time (secs)
Ratio [3,3]
[3,4] [4,4]
[4,5] [3,4] [4,4]
[4,5]
1.5
4.5
15.0 2.1
6.4
21.4
4.3
11.9
146.3 5.4 14.9
182.9
14.6
59.6
>395 3.0 12.4 >82.3
447.9 5271.9 >76575 10.4 122.6 >1780.8

Table 3: Comparative times quicksort task.

ffoil tasks except second. fact, first last task larger
vocabulary, times understate ffoil's advantage. total number bindings
append 3413 , 40 million, foil option used sample 1%
bindings prevent foil exceeding available memory. possible run foil

bindings, time required learn definition would considerably
longer. Similarly, foil exhausted available memory translation task 232,221
possible bindings used, results obtained using sample 50%
bindings.

5.2 Learning quicksort bubblesort
tasks concern learning sort lists examples sorted lists. first,
target relation qsort(A,B) means B sorted form A. Three background
relations provided: components append before, partition(A,B,C,D), meaning
partitioning list B value gives list C elements less list
elements greater A. second task, background relations learning
bsort(A,B) components lt(A,B), meaning A<B. vocabulary used tasks
lists length 4 non-repeated elements drawn f1,2,3,4g.
thus 65 4160 bindings task.
foil ffoil learn \standard" definition quicksort. Times shown Table
2 comparable, mainly ffoil learns super uous over-specialized clause
later discarded favor general recursive clause. outcome bubblesort
quite different { ffoil learns twenty times faster foil definition
verbose.
quicksort task provides opportunity compare ffoil two wellknown relational learning systems. Like ffoil foil, Golem (Muggleton
152

fiLearning First-Order Definitions Functions

Task
foil ffoil
Ackermann's function
12.3
0.2
greatest common divisor 237.5
1.2
Table 4: Times (sec) arithmetic functions.

Feng, 1992) Progol (release 4.1) (Muggleton, 1995) implemented C,
timing comparisons meaningful. Furthermore, systems include quicksort among
demonstration learning tasks, reasonable assume parameters
control systems set appropriate values.
four learning systems evaluated using four sets training examples, obtained
varying maximum length lists size alphabet nonrepeating elements appear lists, (Quinlan, 1991). Denoting set
pair [S ,A], four datasets [3,3], [3,4], [4,4], [4,5]. total numbers
possible bindings tasks, 256, 1681, 4225, 42,436 respectively, span two orders
magnitude. Table 3 summarizes execution times7 required systems
datasets. Neither Golem Progol completed last task; Golem exhausted available
swap space 60Mb, Progol terminated using nearly day cpu time.
table also shows ratio execution time latter three simplest dataset
[3,3]. growth ffoil's execution time far slower systems,
primarily ffoil needs tuples others use tuples.
Golem's execution time seems grow slightly slower foil's, Progol's growth
rate much higher.

5.3 Arithmetic functions

systems also used learn definitions complex functions arithmetic.
Ackermann's function
8
>
= 0
< n+1
f (m; n) = > f (m , 1; 1)
n = 0
: f (m , 1; f (m; n , 1)) otherwise
provides testing example recursion control; background relation succ(A,B) represents B=A+1. Finding greatest common divisor two numbers another interesting
task; background relation plus. tasks vocabulary consists integers
0 20 1 20 respectively, giving 51 tuples Ackermann(A,B,C) A, B
C less equal 20, 400 tuples gcd(A,B,C).
shown Table 4, ffoil 60 times faster foil learning definition
Ackermann 200 times faster gcd. due solely ffoil's smaller
numbers bindings. gcd, example, foil starts 203 8,000 bindings whereas
ffoil never uses 400 bindings.
7. Diculties experienced running Golem AXP 3000/900, times table
DECstation 5000/260.

153

fiQuinlan

foil ffoil learn exactly program Ackermann's function
mirrors definition above. case gcd, however, definitions highlight
potential simplification achievable ordered clauses. definition found foil
gcd(A,A,A).
gcd(A,B,C) :- plus(B,D,A), gcd(B,A,C).
gcd(A,B,C) :- plus(A,D,B), gcd(A,D,C).

learned ffoil (omitting default clause)
gcd(A,A,A) :- !.
gcd(A,B,C) :- plus(A,D,B), gcd(A,D,C), !.
gcd(A,B,C) :- gcd(B,A,C), !.

last clause exploits fact cases less equal B
filtered first two clauses.

5.4 Finding past tense English verbs
previous examples concerned tasks compact, correct definition
known exist. application, learning change English verb phonetic
notation present past tense, real-world avor totally correct
definition would extremely complex. considerable literature built around
task, starting connectionist community, moving symbolic learning
work Ling (1994), relational learning (Quinlan, 1994; Mooney Califf, 1995).
Quinlan (1994) proposes representing task relation past(A,B,C), interpreted
past tense verb formed stripping ending B adding string C.
single background relation split(A,B,C) shows ways word split two
non-empty substrings B C. Following experiment reported (Ling, 1994), corpus
1391 verbs used generate ten randomly-selected learning tasks, containing 500
verbs definition learned 500 different verbs used test definition.
Prolog interpreter used evaluate definitions learned foil, unseen word
w mapped test query past(w,X,Y)?. result query judged correct
X bound proper strings. multiple responses
query, first used { disadvantages foil somewhat, since system
attempt reorder learned clauses maximum accuracy single-response queries.
average accuracy definitions found foil 83.7%.
apply ffoil task, relation past(A,B,C) must factored two functional
relations delete(A,B) add(A,C) since ffoil currently learn functions
single output variable. training test sets verbs used, giving rise
two separate learning tasks, test judged correct delete add
give correct results unseen verb. definitions learned ffoil higher
average accuracy 88.9%; ten trials, ffoil outperforms foil nine inferior
one, difference significant 1% level using one-tailed sign test.
average time required ffoil learn pair definitions, approximately 7.5 minutes,
somewhat less time taken foil learn single definition.
154

fiLearning First-Order Definitions Functions

Object Edges

B
C

E
Total

54
42
28
57
96
277

Correct

Time (sec)

foil ffoil mfoil Golem fors foil ffoil

16
21
22
17
22
2.5
9
15
12
9
12
1.7
8
11
9
5
8
3.3
10
22
6
11
16
2.4
16
54
10
10
29
4.7
59
123
59
52
87 14.6
(21%) (44%) (21%) (19%) (31%)

9.1
11.0
9.7
11.1
5.9
46.8

Table 5: Cross-validation results finite element mesh data.

5.5 Finite element mesh design
application, first discussed Dolsak Muggleton (1992), concerns division
object appropriate number regions finite element simulation. edge
object cut number intervals task learn determine suitable
number { fine division requires excessive computation simulation,
coarse partitioning results poor approximation object's true behavior.
data concern five objects total 277 edges. target relation mesh(A,B)
specifies edge number intervals B recommended expert, ranging
1 12. Thirty background relations describe properties edge, shape
topological relationship edges object. Five trials conducted,
information one object withheld, definition learned edges
remaining objects, definition tested edges omitted object.
Table 5 shows, trial, number edges definitions learned
foil ffoil predict number intervals specified expert. Table 5 also shows
published results mesh task three relational learning systems. numbers
edges mfoil Golem predict correct number intervals taken
(Lavrac Dzeroski, 1994). general relational learning systems like foil,
fors (Karalic, 1995), like ffoil, specialized learning functional relations
kind. Since general relational learning systems could return multiple answers
query mesh(e,X)? edge e, first answer used; puts disadvantage
respect foil fors accounts least part lower accuracy. Using
one-tailed sign test 5% level, ffoil's accuracy significantly higher
achieved foil Golem, differences significant.
time required ffoil domain approximately three times used
foil. turnabout caused ffoil's global pruning phase, requires many literal
eliminations order maximize overall accuracy training data. one ply
cross-validation, instance, initial definition, consisting 30 clauses containing 64
body literals, fails cover 146 249 given tuples target relation mesh.
global pruning, however, final definition 9 clauses 15 body literals,
makes 101 errors training data.
155

fiQuinlan

6. Related Research

Mooney Califf's (1995) recent system Foidl strong uence development ffoil. Three features together distinguish Foidl earlier systems like
foil are:

Following example focl (Pazzani Kibler, 1992), background relations

defined intensionally programs rather extensionally tuple sets.
eliminates problem applications complete extensional definition
background relations would impossibly large.

Examples tuples belong target relation needed. Instead,
argument target relation mode Foidl assumes output
completeness, i.e., tuples relation show valid outputs inputs
appear.

learned definition ordered every clause ends cut.
Output completeness weaker restriction functionality since may several
correct answers standard query R(c1 ; c2 ; :::; cn,1 ; X )?. However, fact
clause ends cut reduces exibility somewhat, since answers query must
generated single clause.
Although Foidl ffoil learn ordered clauses cuts,
different ways. ffoil learns clause, sequence clauses cover remaining
tuples, first clause definition first clause learned. Foidl instead
follows Webb Brkic (1993) learning last clause first, prepending sequence
clauses filter exceptions learned clause. strategy advantage
general rules learned first still act defaults clauses cover
specialized situations.
principal differences Foidl ffoil thus use intensional versus
extensional background knowledge order clauses learned.
subsidiary differences { example, Foidl never manipulates bindings explicitly
estimates number syntactically. However, many ways ffoil may viewed
intermediate system lying mid-way foil Foidl.
Foidl motivated past tense task described Section 5.4, performs
extremely well it. formulation task Foidl uses relation past(A,B)
indicate B past tense verb A, together intensional background
relation split(S,H,T) denote possible ways dividing string substrings H
T. Definitions learned Foidl compact intelligible, slightly higher
accuracy (89.3%) ffoil's using ten sets training test examples.
interesting see systems compare applications.
Bergadano Gunetti (1993) first pointed advantages learning systems
restricting relations functions. filp system assumes relations, target
background, functional, although allow functions multiple outputs.
assumption greatly reduces number literals considered specializing clause,
leading shorter learning times. (On hand, many tasks discussed
previous section involve non-functional background relations would satisfy filp's
156

fiLearning First-Order Definitions Functions

functionality assumption.) theory, filp also requires oracle answer non-ground
queries regarding unspecified tuples target background relations, although
would required relevant tuples provided initially. filp guarantees
learned definition completely consistent given examples, inappropriate
noisy domains discussed Sections 5.4 5.5.
contrast ffoil Foidl, definitions learned filp consist unordered
sets clauses, despite fact target relation known functional.
prevents clause exploiting context established earlier clauses. gcd task
(Section 5.3), definition learned filp would require bodies second
third clauses include literal plus(...,...,...). domains past tense task,
complexity definitions learned ffoil Foidl would greatly increased
constrained unordered clauses.

7. Conclusion
study, mature relational learning system modified customize
functional relations. fact specialized ffoil performs much better
general foil relations kind lends support Bergadano Gunetti's
(1993) thesis functional relations easier learn. interesting speculate
similar improvement might well obtainable customizing general first-order
systems Progol (Muggleton, 1995) learning functional relations.
Results quicksort experiments suggest ffoil scales better general
first-order systems learning functional relations, past tense
mesh design experiments demonstrate effectiveness noisy domains.
Nevertheless, hoped improve ffoil several ways. system
extended multifunctions one output variable, permitted
filp Foidl. Secondly, many real-world tasks Sections 5.4 5.5
result definitions output variable usually bound equated
constant rather appearing body literal. applications, ffoil heavily
biased towards constructing next clause cover frequent function value
remaining tuples, binding tends highest gain. time
clause specialized exclude exceptions, however, end covering
tuples relation. special cases could filtered first, clauses like
would simpler would cover tuples target relation. better learning
strategy situations would seem grow new clause every function value
uncovered tuples, retain one greatest coverage discard rest.
would involve increase computation lead better, concise
definitions.
Although conceptual changes moving foil ffoil relatively slight,
effects code level substantial (with three 19 files make
foil escaping modification). result decided preserve separate
systems, rather incorporating ffoil option foil. available (for
academic research purposes) anonymous ftp ftp.cs.su.oz.au, directory pub, file names
foil6.sh ffoil2.sh.
157

fiQuinlan

Acknowledgements
research made possible grant Australian Research Council. Thanks
William Cohen, Ray Mooney, Michael Pazzani, anonymous reviewers comments helped improve paper.

Appendix: Learned Definitions
definition learned foil appears left ffoil right.
latter's default clauses irrelevant tasks, omitted.

List processing functions (Section 5.1)
(a) Using lists length 3:
append([ ],B,B).
append(A,B,C) :- components(A,D,E),
components(C,D,F), append(E,B,F).
last(A,B) :- components(A,B,[ ]).
last(A,B) :- components(A,C,D), last(D,B).
reverse(A,A) :- append(A,C,D),
components(D,E,A).
reverse(A,B) :- last(A,C), last(B,D),
components(A,D,E),
components(B,C,F), reverse(E,G),
del(D,B,G).
shift(A,B) :- components(A,C,D), del(C,B,D),
append(D,E,B).
translate([ ],[ ]).
translate(A,B) :- components(A,C,D),
components(B,E,F), translate(D,F),
means(C,E).

append([ ],B,B) :- !.
append(A,B,C) :- components(A,D,E),
append(E,B,F), components(C,D,F), !.
last(A,B) :- components(A,C,D), last(D,B), !.
last(A,B) :- member(B,A), !.
reverse(A,A) :- append(A,C,D),
components(D,E,A), !.
reverse(A,B) :- components(A,C,D),
reverse(D,E), append(F,D,A),
append(E,F,B).

append([ ],B,B).
append(A,B,C) :- components(A,D,E),
components(C,D,F), append(E,B,F).
last(A,B) :- components(A,B,[ ]).
last(A,B) :- components(A,C,D), last(D,B).
reverse(A,A) :- append(A,A,C), del(D,E,C).
reverse(A,B) :- components(A,C,D),
reverse(D,E), append(F,D,A),
append(E,F,B).

append([ ],B,B) :- !.
append(A,B,C) :- components(A,D,E),
append(E,B,F), components(C,D,F), !.
last(A,B) :- components(A,C,D), last(D,B), !.
last(A,B) :- member(B,A), !.
reverse(A,A) :- append(A,C,D),
components(D,E,A), !.
reverse(A,B) :- components(A,C,D),
reverse(D,E), append(F,D,A),
append(E,F,B).
shift(A,B) :- components(A,C,D),
append(E,D,A), append(D,E,B).

shift(A,B) :- components(A,C,D),
append(E,D,A), append(D,E,B).
translate([ ],[ ]) :- !.
translate(A,B) :- components(A,C,D),
translate(D,E), means(C,F),
components(B,F,E).

(b) Using lists length 4:

shift(A,B) :- components(A,C,D), del(C,B,D),
append(D,E,B).

158

fiLearning First-Order Definitions Functions

translate([ ],[ ]).
translate(A,B) :- components(A,C,D),
components(B,E,F), translate(D,F),
means(C,E).

translate([ ],[ ]) :- !.
translate(A,B) :- components(A,C,D),
translate(D,E), means(C,F),
components(B,F,E).

Quicksort bubblesort (Section 5.2)
qsort([ ],[ ]).
qsort(A,B) :- components(A,C,D),
partition(C,D,E,F), qsort(E,G),
qsort(F,H), components(I,C,H),
append(G,I,B).
bsort([ ],[ ]).
bsort(A,A) :- components(A,C,[ ]).
bsort(A,B) :- components(A,C,D),
components(B,C,E), bsort(D,E),
components(E,F,G), lt(C,F).
bsort(A,B) :- components(A,C,D),
components(B,E,F), bsort(D,G),
components(G,E,H), lt(E,C),
components(I,C,H), bsort(I,F).

qsort([ ],[ ]) :- !.
qsort(A,B) :- components(A,C,D),
partition(C,D,E,F), qsort(E,G),
qsort(F,H), components(I,C,H),
append(G,I,B), !.
bsort([ ],[ ]) :- !.
bsort(A,A) :- components(A,C,[ ]), !.
bsort(A,B) :- components(A,C,D), bsort(D,E),
components(E,F,G),
components(B,C,E), lt(C,F), !.
bsort(A,B) :- components(A,C,D), bsort(D,E),
components(E,F,G),
components(D,H,I),
components(J,C,I), bsort(J,K),
components(B,F,K), !.
bsort(A,B) :- components(A,C,D), bsort(D,E),
components(F,C,E), bsort(F,B), !.

Arithmetic functions (Section 5.3)
Ackermann(0,B,C) :- succ(B,C).
Ackermann(A,0,C) :- succ(D,A),
Ackermann(D,1,C).
Ackermann(A,B,C) :- succ(D,A), succ(E,B),
Ackermann(A,E,F),
Ackermann(D,F,C).
gcd(A,A,A).
gcd(A,B,C) :- plus(B,D,A), gcd(B,A,C).
gcd(A,B,C) :- plus(A,D,B), gcd(A,D,C).

Ackermann(0,B,C) :- succ(B,C), !.
Ackermann(A,0,C) :- succ(0,D), succ(E,A),
Ackermann(E,D,C), !.
Ackermann(A,B,C) :- succ(D,A), succ(E,B),
Ackermann(A,E,F),
Ackermann(D,F,C), !.
gcd(A,A,A) :- !.
gcd(A,B,C) :- plus(A,D,B), gcd(A,D,C), !.
gcd(A,B,C) :- gcd(B,A,C), !.

References

Bell, S., & Weber, S. (1993). close logical relationship foil frameworks Helft Plotkin. Proceedings Third International Workshop Inductive
Logic Programming, Bled, Slovenia, pp. 127{147.
Bergadano, F., & Gunetti, D. (1993). interactive system learn functional logic programs. Proceedings Thirteenth International Joint Conference Artificial Intelligence, Chambery, France, pp. 1044{1049. San Francisco: Morgan Kaufmann.
Bratko, I. (1990). Prolog Programming Artificial Intelligence (2nd edition). Wokingham,
UK: Addison-Wesley.
159

fiQuinlan

Cameron-Jones, R. M., & Quinlan, J. R. (1994). Ecient top-down induction logic
programs. SIGART, 5, 33{42.
De Raedt, L. (Ed.). (1996). Advances Inductive Logic Programming. Amsterdam: IOS
Press.
Dolsak, B., & Muggleton, S. (1992). application inductive logic programming
finite element mesh design. Muggleton, S. (Ed.), Inductive Logic Programming, pp.
453{472. London: Academic Press.
Karalic, A. (1995). First Order Regression. Ph.D. thesis, Faculty Electrical Engineering
Computer Science, University Ljubljana, Slovenia.
Langley, P., & Simon, H. A. (1995). Applications machine learning rule induction.
Communications ACM, 38 (11), 55{64.
Lavrac, N., & Dzeroski, S. (1994). Inductive Logic Programming. London: Ellis Horwood.
Ling, C. X. (1994). Learning past tense english verbs: symbolic pattern associator
versus connectionist models. Journal Artificial Intelligence Research, 1, 209{229.
Michie, D., Spiegelhalter, D. J., & Taylor, C. C. (Eds.). (1994). Machine Learning, Neural
Statistical Classification. Hertfordshire, UK: Ellis Horwood.
Mooney, R. J., & Califf, M. E. (1995). Induction first-order decision lists: results
learning past tense english verbs. Journal Artificial Intelligence Research, 3,
1{24.
Muggleton, S. (Ed.). (1992). Inductive Logic Programming. London: Academic Press.
Muggleton, S. (1995). Inverse entailment progol. New Generation Computing, 13,
245{286.
Muggleton, S., & Feng, C. (1992). Ecient induction logic programs. Muggleton, S.
(Ed.), Inductive Logic Programming, pp. 281{298. London: Academic Press.
Muggleton, S., King, R. D., & Sternberg, M. J. (1992). Protein secondary structure prediction using logic-based machine learning. Protein Engineering, 5, 646{657.
Pazzani, M. J., & Kibler, D. (1992). utility knowledge inductive learning. Machine
Learning, 9, 57{94.
Quinlan, J. R. (1990). Learning logical definitions relations. Machine Learning, 5,
239{266.
Quinlan, J. R. (1991). Determinate literals inductive logic programming. Proceedings
Twelfth International Joint Conference Artificial Intelligence, Sydney, pp. 746{750.
San Francisco: Morgan Kaufmann.
Quinlan, J. R. (1994). Past tenses verbs first-order learning. Proceedings AI'94
Seventh Australian Joint Conference Artificial Intelligence, Armidale, Australia,
pp. 13{20. Singapore: World Scientific.
160

fiLearning First-Order Definitions Functions

Quinlan, J. R., & Cameron-Jones, R. M. (1993). Foil: midterm report. Proceedings European Conference Machine Learning, Vienna, pp. 3{20. Berlin: Springer-Verlag.
Quinlan, J. R., & Cameron-Jones, R. M. (1995). Induction logic programs: foil
related systems. New Generation Computing, 13, 287{312.
Rouveirol, C. (1994). Flattening saturation: two representation changes generalization. Machine Learning, 14, 219{232.
Srinivasan, A., Muggleton, S. H., Sternberg, M. J. E., & King, R. D. (1996). Theories
mutagenicity: study first-order feature-based induction. Artificial Intelligence, 84, 277{299.
Ullman, J. D. (1988). Principles Database Knowledge-Base Systems. Rockville, MD:
Computer Science Press.
Webb, G. I., & Brkic, N. (1993). Learning decision lists prepending inferred rules. Proceedings Australian Workshop Machine Learning Hybrid Systems, Melbourne,
Australia, pp. 6{10.
Zelle, J. M., & Mooney, R. J. (1993). Combining foil ebg speed-up logic programs.
Proceedings Thirteenth International Joint Conference Artificial Intelligence,
Chambery, France, pp. 1106{1111. San Francisco: Morgan Kaufmann.

161

fiJournal Artificial Intelligence Research 5 (1996) 329349

Submitted 5/96; published 12/96

Quantitative Results Comparing Three Intelligent Interfaces
Information Capture: Case Study Adding Name Information
Electronic Personal Organizer
Jeffrey C. Schlimmer
School Electrical Engineering & Computer Science
Washington State University, Pullman, WA 99164-2752, U.S.A.
Patricia Crane Wells
AllPen Software, Inc.
16795 Lark Avenue, Suite 200, Los Gatos, CA 95030, U.S.A.

SCHLIMME@EECS.WSU.EDU

PATRICIA@ALLPEN.COM

Abstract
Efficiently entering information computer key enjoying benefits
computing. paper describes three intelligent user interfaces: handwriting recognition,
adaptive menus, predictive fillin. context adding persons name address
electronic organizer, tests show handwriting recognition slower typing
on-screen, soft keyboard, adaptive menus predictive fillin twice fast.
paper also presents strategies applying three interfaces information
collection domains.

1. Introduction
meet someone new, often wish get name phone number. may
write small notebook personal organizer. takes minutes do,
put business card small slip paper organizer, promising copy
later time.1 later time comes, face tedious task finding nowseveral names go organizer recopying information.
comfortable computers, may use electronic organizer (a small computer
includes software managing names appointments). Looking someones phone
number faster devices, adding tedious, owning costly.
concession reality, devices often include pockets holding queued slips
paper.
solutions could propose eliminate procrastination? adding persons
name2 organizer fun (say choice inspirational message, gratuitous
violence, lottery ticket), might add names readily. Avoiding whimsy,
could get desired effect making faster add persons name. reason
paper organizers use index tabs; electronic organizers use automatic filing. faster still,
organizer could read card handwritten note (via optical character handwriting

1. friend places rubber band around organizer ensure paper slips dont escape
time.
2. brevity, well refer persons name, address, phone numbers, e-mail, etc. name. Whether
aggregate information persons first last name intended clear context.

1996 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiS CHLIMMER & W ELLS

recognition). Applying artificial intelligence ideas, could even imagine organizer
predicts need write you.
paper describes electronic organizer almost fast slip paper,
certainly much faster previous organizers. uses commercial hardware (Newton,
described Section 2). software three interface components designed speed
adding persons name (described Section 3): handwriting recognition, adaptive menus
recent values, predictive fillin. primary contributions paper detailed
evaluations benefits three components (described Section 4).
Adding persons name organizer special case capturing organizing
information. ubiquitous task. Big businesses institute careful procedures
custom forms databases, billions smaller, one-or-two-person tasks
could done efficiently accurately getting information computer
easier. Even small gains would repeated many times whenever someone needed
collect information make decision, monitor process, investigate something new.
secondary contributions paper consideration three components may
applied broadly (described Section 5).
three interface components robust familiar. Whether intelligent
arguable. advocate behavior-based definition may also apply here, i.e.,
question whether device intelligence answered examining
behavior rather internal processes representations (e.g., Agre & Chapman, 1987;
Horswill & Brooks, 1988). Even not, goal address question
much intelligence, agency, support one wants interface (Lee, 1990; Rissland, 1984).
assert: much speed users performance task. Furthermore, much
research directed automatically learning hard-code study (e.g.,
Dent, Boticario, McDermott, Mitchell, & Zabowski, 1992; Hermens & Schlimmer, 1994;
Schlimmer & Hermens, 1993; Yoshida, 1994). Even learning works perfectly, result
worthwhile? claim answer found empirical study usefulness
various user interface components.

2. Newton
Newton operating system introduced Apple Computer, Inc. 1993. designed
single-user, highly-portable computer. Frames central data structure Newton.
stored persistent object databases maintained RAM (Smith, 1994).
Newton computer includes pressure-sensitive, bitmapped display
user writes, draws, taps enter information (Culbert, 1994). small enough hold
one hand weigh around one US pound. Battery life one days worth
continuous use. thorough overview hardware software context current pen
computers, reader may wish consult (Meyer, 1995).
lowest levels, Newton supports recognition. handwriting recognition
highly publicized first introduced. recognizer allows free-form input
printed cursive writing.3 uses on-line recognition convert writing Unicode4 text.
recognizer uses contextual information limit types characters within specific
fields combinations characters within words. latter relies heavily
3. Throughout paper references handwriting also refer handprinting. distinction required,
latter term used explicitly.
4. character encoding similar ASCII two-bytes per character languages larger character
sets.

330

fiT HREE NTERFACES NORMATION C APTURE: C ASE TUDY DDING N AME NFORMATION

dictionaryonly words appearing dictionary recognized. user types
new word using on-screen soft keyboard,5 Newton volunteers add dictionary
future recognition. Optionally, user invoke secondary recognizer
use dictionary attempts recognize written letter letter; Section 4
describes accuracy option. Application developers customize handwriting
recognition providing special purpose dictionaries regular expression describing
syntax words recognized.
Newton computers include several applications ROM serve
electronic organizer. Relevant point paper, Newton computers date
include application called Names storing retrieving peoples names, addresses,
etc.; Figure 1 depicts application. Section 4 describes experiments using standard
enhanced version Names application add peoples names.

Figure 1: Names application included Newton computers depicted one
quarter life size Apple Newton MessagePad 100 used experiments.
user taps field, expands ease writing. picture, First Name field
expanded. folder tab button top screen displaying names
one eleven user-defined folders. left right, buttons bottom
application screen showing time battery state (labeled clock
face), changing display name (labeled Show), adding new name
(labeled New), refiling name (labeled file folder picture), printing/
faxing/infrared beaming/mailing/duplicating/deleting name (labeled
envelope picture), closing application (labeled large X).
universal buttons visible applications. left right, provide access
Names application, calendar application, storage place
applications, scrolling buttons, undo, find, natural language recognition.

3. Names++
Newton computers built-in Names application includes one three components
suggested Section 1 speed adding new persons name. recognizes handwriting,
5. Throughout paper references typing refer tapping on-screen soft keyboard.

331

fiS CHLIMMER & W ELLS

recognition dictionary expanded needed. Names++ extended version
Names wrote include two components.
3.1

Adaptive Menus

Names++ extends Names adding adaptive menu 9 Names 17 fields: 7 menus
consisting 4 recently entered values 2 menus 4 recently entered values prepended
fixed choices. word user needs menu, choose rather write
out. Figure 2 depicts Names++ menu open City field. choices

Figure 2: Names++ application. picture, user tapped word
City opened menu recently used city names. user chooses one
cities, copied City field name. Compare
Figure 1. Note Names++ includes features Names relevant adding new
name.
menu four recently entered values specific field. (Each field
separate menu.) may convenient user series related names
add, perhaps people company city. course, user adds
four unusual values row, common choices inadvertently dropped menu.
sophisticated approach would list number recent values
number common; Names++ doesnt explore sake simplicity
speed. menus adaptive, users use linear search examine
choices cannot rely muscle-level memory choice locations. menus include
choices, cost search likely dominate Fitts law effect.6
Two Names fields already menu. Honorific field offered user Ms.,
Mrs., Mr., Dr.; Country field offered menu thirteen countries.
completeness, Names++ prepends four recent values fields menus.
Technically split menus.7 Mitchell Shneiderman (1989) compared large
statically ordered menus (unsplit) also prepended most-recently-used choices
6. Fitts law states time move given distance target width W proportional log D/
W.
7. confused splitting menu choices across multiple menus (Witten, Cleary, & Greenberg, 1984).

332

fiT HREE NTERFACES NORMATION C APTURE: C ASE TUDY DDING N AME NFORMATION

(split, exactly condition). Static faster split menus one task;
difference another. Sears Shneiderman (1994) later found evidence favor split
menus including 1758% improvement selection time compared unsplit menus.
also compared alternative organizations split part recommend limiting
number split choices four less (which Names++ does) sorting split choices
frequency (which Names++ approximates most-recently-used). context menu
hierarchies, Snowberry, Parkinson, Sisson (1985) found adding items containing
upcoming selections resulted greater accuracy faster search times. result
confirmed (Kreigh, Pesot, Halcomb, 1990) may much effect
preventing users getting lost menu hierarchies assisting making
selections per se. test adaptive (split) menus Names++ understand relative
contribution compared interfaces data entry task.
four Phone Number fields menus, give user way categorize
phone number rather enter number itself. category menus (Norman,
1991). phone menus include choices Phone, Home, Work, Fax, Car,
Beeper, Mobile, Other. phone fields identical menus. Names++
modify them. menus provided First Name, Last Name, Birthday fields.
Section 5 describes input fields menus.
understand computational space time demands adaptive menus, note
Names++ stores menus single object object database. size object
linear number fields menus (f) number choices menu
(c), fc. menu implemented circular queue, time update object
would constant menu, f. Names++ uses slightly slower array
implementation menus takes fc time. practice works slightly
one half second nine fields four choices.
3.2

Predictive Fillin

Names++ also extends Names automatically filling 11 empty fields new name
predicted values. treats previous names case base (Kolodner, 1993) copies
information relevant case. Specifically, user adds company new name
matches previous names company, Names++ copies address
previous name new one. Values copied verbatim two address lines
City, State, Zip Code, Country fields. user ID electronic mail address
dropped e-mail address copied new name. (The remaining components
e-mail address likely people company.) last
word Phone Number values dropped; area code prefix copied
new name typical area code-prefix-extension phone number. user writes
chooses another value Company, replacing value field, predictive fillin
recopies dependent values previous name. Figure 3 illustrates sequence events
users perspective.
Names++ behaves similarly user adds city state matches previous
name, copies less information matching company found. value
copied predictive fillin incorrect, user write choose correct value
manually. Table 1 summarizes fields menus predictive fillin. structure
predictive fillin fixed design Names++. work attempts learn comparable
structure examples (e.g., Dent et al., 1992; Hermens & Schlimmer, 1994; Schlimmer &

333

fiS CHLIMMER & W ELLS

Figure 3: Names++ application user adds company new name.
left panel, application finds previous name matching company, displays
dialog, fills remaining fields predicted information copied
previous name. center panel shows much information filled. right
panel shows completed name. example user written four
additional words complete name.
Hermens, 1993; Yoshida, 1994). goal determine whether end result
learning worthwhile.
one previous name matches company, city, state new name,
Names++ fills fields values recent name. Values second-most
recent occurrence name added menus. gives user chance select
alternate addresses company alternate zip codes city.
terms computational requirements, Names++ needs additional storage
predictive fillin; object database previously added names reused case base.
Matching new names company, city, state previous name implemented
Newton primitive; informal study depicted Figure 4 indicates Newtons proprietary
algorithm appears run time linear number names match found
logarithmic matches found.
Names++ source code on-line Appendix A.

4. Experiments
hypothesize recognition, adaptive menus, predictive fillin speed adding new
name. find extent, conducted experiment
subjects added names using different combinations three interface components.
4.1

Method

Five computer science students ages 18 35 years age participated
subjects experiments. Prior experiments used Newton computer
least six months familiar Newtons handwriting recognition QWERTY
layout Newtons on-screen keyboard.
experiment used within-subject design subject participated
six conditions summarized Table 2. Conditions designed assess contribution
334

fiTime Seconds

HREE NTERFACES NORMATION C APTURE: C ASE TUDY DDING N AME NFORMATION

J

5.2

J
1.6

BJ
BJ
0.1 B
JBJ
0.7

10

E

J
BG

B

B
640
Number Names

200

Figure 4: Time find matching name using Newton function number
names database match exists (circles upper line) several matches
exist (squares lower line). axes linear scale. upper line linear fit;
lower line logarithmic. comparison experiment, interpolated values
200 names shown open symbols.
interface component separately collectively. control, Typed condition,
subject types values without using components. Null condition,
subject writes words using remedial recognition steps (to described) types words
recognizable. subject add words Newtons dictionary
asked assistance either adaptive menus predictive fillin.
condition extends Null requiring subject add words Newtons dictionary
asked. condition extends Null adding adaptive menus. PF condition extends
Null adding predictive fillin. condition combines extensions D, AM,
PF.
used pair Apple Newton MessagePad 100 computers (running Newton OS
version 1.3) experiment three versions Names++ application. One version
interface components disabled used Typed, Null, conditions.
second version adaptive menus used AM. third version adaptive menus
predictive fillin used PF All.
set 448 name records experiments donated development officer
Washington State University. job involves contacting alumni others solicit
support university programs. Almost records include first last name, full
mailing address, one three phone numbers. include honorific, country, email address. Informal tests indicated MessagePads could hold 250 names
Names++ installed, selected random set 200 records.

335

fiS CHLIMMER & W ELLS

Menu Choices
Field
Honorific

Predictive Fillin

Built-in Adaptive
4

Company

City

State

Notes
Ms., Mrs., Mr., Dr.

4

First Name
Last Name
Title

4

Company

4

Address (1)

4

Address (2)

Yes
label tap menu.

Yes

City

4

Yes

State

4

Yes

Yes

Zip Code

4

Yes

Yes

4

Yes

Yes

4

Yes

Country

13

E-Mail
Phone 1

8

Phone 2

8

Phone 3

8

Phone 4

8

Area Code
Prefix

Yes
User ID removed.
Category menu used select
type phone number rather
phone number itself. Choices
include Phone, Home,
Work, Fax, Car, Beeper,
Mobile, Other.

Area Code

Birthdate

Table 1: Name++ fields adaptive menus predictive fillin.
Condition

Writing

Add Dictionary

Adaptive Menus

Predictive Fillin

Typed
Null

Yes



Yes



Yes

PF

Yes



Yes

Yes
Yes
Yes
Yes

Yes

Yes

Table 2: Experimental conditions, one row per condition. Columns indicate
user interface components used. Blank cells represent No.
simulate worst case recognition, adaptive menus, predictive fillin, chose
5 names (listed below) residual 248 names company
preload set 200 names. (To preserve anonymity here, first last names swapped
phone numbers replaced artificial values. Actual first last name pairs phone
numbers used experiment.)
336

fiT HREE NTERFACES NORMATION C APTURE: C ASE TUDY DDING N AME NFORMATION

Robert Anderson
Account Marketing Rep
IBM
W 201 N River Drive
Spokane, WA 99201
509 555 0000
509 555 1111

Eric Brice
Director Engineering
RAIMA Corp
3245 146th Place SE
Bellevue, WA 98007
206 555 2222
206 555 3333
205 555 4444

Peter Friedman
President
NOVA Information Systems
12277 134th Court NE
Suite 203
Redmond, WA 98052
206 555 7777

Thomas Leland
Staffing Manager
Aldus Corporation
411 First Ave South
Seattle WA 98104 2871
206 555 8888
206 555 9999

Mike Carlson
VP Engineering & Estimating
General Construction
2111 N Northgate Way
Suite 305
Seattle, WA 98133
206 555 5555
206 555 6666

score words names entered total time, used sheet
Figure 5. Fictitious data corresponding subjects entering second name
condition also depicted.

Figure 5: Scoring sheet used time name added. 1 center right
columns indicates first word field value entered using recognition
(cf. Figure 6), adaptive menu (cf. Figure 2), predictive fillin (cf. Figure 3). 2
indicates second word, on. highest digit row corresponds
number words fields value.
facilitate setting condition, constructed backup images MessagePads
correctly configured six conditions. images, 200 names
appropriate version Names++ installed. images All, added
First, Last, Company names dictionary using built-in feature Newton.
initialize adaptive menus images All, used special purpose
application. Prior use MessagePads completely erased restored
backup image appropriate condition tested.

337

fiS CHLIMMER & W ELLS

task subject enter five names twice six
conditions. first time name entered condition simulates worst-case scenario;
second time, best.
4.2

Procedure

Subjects given listing one five names MessagePad initialized one
six experimental conditions. subject entered name condition; name/
condition pairs randomly ordered subject counteract subject learning
effects. instructed enter names quickly. Subjects made mistakes.
instructed correct finishing. Times reported include time correct
mistakes.
Subjects given precise script follow entering name. done
partially bias results hypotheses partially minimize individual variation.
Specifically, subject instructed enter values field order, top
bottom, completing one going next (cf. Figure 1). conditions involving
handwriting, word correctly recognized, subject check menu
alternate recognitions (depicted left panel Figure 6). intended word

Figure 6: Remedial steps handwritten word correctly recognized.
example, subject wrote Brice misrecognized Brian.
subject double-taps word, menu alternative recognitions appears (left
panel). none correct, subject requests recognition without
dictionary (or letter letter). Another double-tap word generates second
menu alternatives (middle panel). none correct, subject entered
word tapping buttons on-screen keyboard (right panel).
list, select Try letters attempts recognition without dictionary.
result correct, check second menu alternative
recognitions (depicted center panel Figure 6). intended word
second menu, tap button keyboard picture, type word using
on-screen keyboard, close keyboard. word already part
dictionary, Newton asked would like add (depicted right panel Figure 6).
Note recognition menus, original handwriting shown near
338

fiT HREE NTERFACES NORMATION C APTURE: C ASE TUDY DDING N AME NFORMATION

bottom. first choice Newtons best guess, second choice best guess
different capitalization. subject instructed ensure words correctly
capitalized.
Typed, subject instructed enter data using Newtons on-screen soft
keyboard. Null, subject enter data handwriting. All,
subject instructed add words Newtons dictionary asked. All,
subject instructed check fields menu (if one) writing data.
special instructions required PF beyond default adding words
dictionary.
stopwatch started subject tapped New button stopped
last field value correctly entered. Choosing manual timing method simplified
development experimental software. method word field
entered recorded scoring sheet indicated Figure 5.
experiment took three five hours subject spread
two sessions approximately two hours within week. Subjects took short
breaks adding name minimize fatigue.
subject completed experiment, asked rank favorite
methods entering names least.
4.3

Results

Table 3 summarizes median standard deviation subjects time enter name
six conditions. Times include user input, predictive fillin computation, time
correct errors (if any). first row reports time add novel name, simulation
worst case. second row reports time repeat name, simulation best case.
ANOVA reveals significant main effect condition F(5, 21.07) < 0.001. interaction
number times name entered condition also significant F(5, 19.61) < 0.001.
Comparing worst cases across conditions, post-hoc multiple comparisons test using
Tukeys HSD indicates Typed significantly different (faster)
conditions. (All p < 0.05.) Comparing worst best cases within condition, D, AM,
PF, significantly faster. Comparing best cases across conditions, Typed, AM,
PF significantly faster Null; significantly faster Typed, PF, D,
Null. pairwise comparisons significant.
Typed

Null





PF



Worst

2.72 (0.86)

4.25 (1.31)

4.50 (1.45)

4.32 (1.70)

4.07 (1.26)

4.15 (1.13)

Best

2.52 (0.60)

3.65 (1.24)

3.30 (1.09)

1.37 (0.51)

2.02 (0.45)

1.08 (0.24)

Table 3: Median time minutes add new name five names five subjects
(25 samples per cell, standard deviation parentheses). Columns list six
experimental conditions.
difference within D, AM, PF across worst best cases confirms
hypothesis interfaces speed entering names, 29%, 210%, 110% compared
Null, respectively. surprised find predictive fillin fast
adaptive menus (though difference statistically significant). designing data
entry system one might tempted implement adaptive menus given algorithmic
simplicity, especially compared sophisticated methods machine learning
proposed predictive fillin. However, latter suffer recency effects imposed
339

fiS CHLIMMER & W ELLS

limited size adaptive menus; entering new data related distant
past, predictive fillin would little difficulty providing assistance adaptive menus
could not. Adaptive menus could refined use frequency frequency-recency
combination, performance suggests implementing adaptive menus
predictive fillin. Combined adding words dictionary, speed entering names
294%. practical terms, interfaces could make entering name electronic
organizer faster writing paper certainly fast enough capture
information phone conversation.
Prior work confirms difference Typed conditions. Ward
Blesser (1986) state normal writing speed rarely greater 69 characters per minute
(cpm) single line text. Using fact mean number characters per name
experiment 98.2, subjects achieved 30 cpm. MacKenzie, Nonnecke, Riddersma,
McQueen, Meltz (1994) compare four interfaces entering numeric text data
pen-based computers, including hand printing using on-screen keyboard. (The
two interfaces experimental gesture-based techniques entering single characters.)
numeric entry conditions, found on-screen keyboard 30 words per
minute (wpm) 1.2% error whereas hand printing 18.5 wpm 10.4% error.
text entry conditions, keyboard 23 wpm 1.1% error whereas hand printing
16 wpm 8.1% error. Using fact mean number words per name
experiment 20.8, subjects achieved 8.3 wpm typing 6.3 wpm handwriting
mixed numeric/text input. key point comparison studies
found using stylus tap on-screen keyboard faster handwriting printing.
Differences speed studies likely result differences
experimental procedures (theirs versus ours): single versus multiple field fillin, copying
information memory screen versus paper, block comb-type (letter) versus
open (word) interface.
Figure 7 presents Box plot summaries time data. interest reduction
variance time adaptive menus predictive fillin best case (right plot).
Differences individual performance reduced interface components.
left half Table 4 lists recognition accuracy field conditions,
subjects, names. first row indicates 94% first names written
correctly recognized immediately. checking first menu alternate recognitions,
accuracy rises 95%. Similarly, second row indicates 59% second names
written correctly recognized immediately. rate rose 74% letter-by-letter
recognition invoked 79% checking second menu alternate
recognitions. Phone numbers enjoyed second highest recognition rate first names.
reference, Cesar Shinghal (1990) report 90% recognition rate hand
printed, Canadian postal codes {letter, digit, letter, space, digit, letter, digit}.
comparable observed rates first names, second address lines, phone
numbers.
right half Table 4 lists percentage words entered using typing, adaptive
menus, predictive fillin field conditions, subjects, names. first row
indicates 5% first names typed. row State indicates 32% state
names typed, 20% chosen adaptive menu, 39% predictively
filled in. (Note numbers row total 100% left half
table lists percentages words written right half lists percentages
words.)
340

fiTime Minutes

HREE NTERFACES NORMATION C APTURE: C ASE TUDY DDING N AME NFORMATION

*
10

10
*
*
*
*
*

5

*

*

*

5
*

Worst Case



Fillin

Menu

Dictionary

Null

0

Typed

*



Fillin

Menu

Dictionary

Typed

0

Null

*

Best Case
Experimental Condition

Figure 7: Box plots time enter name condition worst best cases.
box summarizes 25 values. Values outside inner fences plotted
asterisks. Values outside outer fences plotted circles (Wilkinson, Hill,
Vang, 1992).
Combining left right halves Table 4 reveal many difficult-torecognize fields considerable assistance adaptive menus predictive fillin.
accentuates speed improvements providing help needed. Figure 8
depicts relationship fields, recognition accuracy,
adaptive menus predictive fillin. Several fields near perfect recognition accuracy;
recognized without resorting typing. instance, numeric fields easier
recognize; Phone Number fields recognized nearly 90% even though area
code, prefix, suffix varied name name. First Last name fields also
high recognition accuracy. first names built-in dictionary. two
last names were, others often recognized letter letter. Recognition
poorer Company Address fields. Words full capitals (e.g., RAIMA) words
combination numbers letters (e.g., 146th) difficult recognize.
low recognition accuracy State field apparently due oversight Newtons
dictionary. WA included many two-letter abbreviations US states are.
compensate low accuracy, Names++ includes adaptive menu and/or predictive fillin
difficult-to-recognize fields.
Table 5 summarizes subjects preference condition enter name. lists frequency
ranking five subjects. Subjects partitioned conditions non-overlapping
groups (Typed, Null), (D, AM, PF), (ALL). (The authors know suitable statistic
asserting differences.) results contradict MacKenzie et al. (1994)
found subjects preferred typing handwriting, mildly text entry
341

fiS CHLIMMER & W ELLS

100

XFirst Name

GPhone

GAddress (2)
XLast Name
75

Title

Recognition (%)

City

Company

Address (1)

Zip Code
50

X

G

25
State

Recognition
Adaptive Menus
Predictive Fillin


0
0

200

400

600
800
Number Words

1000

1200

Figure 8: Recognition rate function number total words entered
conditions subjects names. Fields adaptive menus predictive fillin
(or both) marked. Note every field less 75% accuracy either
adaptive menu predictive fillin (or both).
strongly numeric entry. restricted hand printing input block comb-type
interface; unnaturalness may account dispreference toward handwriting.
Writing stylus advantages. Meyer (1995) points out, keyboards
faster linear text entry, pen input device natural, handle text
graphic input, jump quickly point point. Writing pen also supports
heads writing, allowing user visually attend aspects task hand.
Typing on-screen keyboard requires heads entry.
One subject experimented Names++ outside experimental setting offered
number observations. First, adaptive menus short, sometimes menus
would useless matter long were. wished City Company
fields menus longer (especially City). frustrating one common
city names large metropolitan region bumped short list. contrast, Title
fields menu rarely useful, see point maintaining it. principles
outlined Section 5 suggest similar revisions.
342

fiT HREE NTERFACES NORMATION C APTURE: C ASE TUDY DDING N AME NFORMATION

Field

Cumulative Recognition Accuracy
Letter
Correct
1st Menu
2nd Menu
Letter

Percent Words Entered
Adaptive Predictive
Typed
Menu
Fillin

First Name

94

95

95

95

5

Second
Name

59

59

74

80

21

Title

52

62

66

68

26

20

Company

42

49

59

61

31

20

Address

48

60

62

67

23

10

Address 2

81

85

87

87

10

City

62

62

67

71

19

12

20

State

22

22

22

22

32

20

39

Zip

51

52

58

59

29

10

20

Phone

86

89

89

89

10

20
20

15

Table 4: left columns list cumulative recognition accuracy field words
written conditions, names subjects. right columns list
percentage words field entered typing, adaptive menus, predictive
fillin. 5190 values total. Blank cells represent 0.
5th

6th

Typed

1

4

Null

4

1

Condition

1st

2nd



3rd

1

4
1



2

2

PF

3

2



4th

5

Table 5: Subjects frequency ranking preference different conditions
means enter name. 30 values total. Blanks cells represent 0.
Second, found predictive fillin helpful. Sometimes filled didnt
expect to. also noted predictive fillin copies many fields,
encourages user add complete name. may advantage harried
setting.

5. Design Recommendations
Given experimental results, configure handwriting recognition,
adaptive menus, predictive fillin another application (or redesigned Names++)?
handwritten input, recognition use dictionaries specific type field: numbers
numeric fields, lists domain terms text fields.
5.1

Adaptive Menus

adaptive menus, add menu field might repeated values.
accidentally added adaptive menu field never value twice,
343

fiS CHLIMMER & W ELLS

Last Name

John
Jim
Bob
Jerry
Paul
David
Steve
Ron
Bill
Tom
Robert
Jack
Dennis
Robin
Rich
Julie
James
Edmund

Dave

Title

President
Executive Director
Vice President - Human Resources
Vice President
Travel Consultant
Staffing Specialist
Sales Representative
Program Officer
Principal
Manager
Industrial Research Marketing Manager
Human Resources Manager
Human Resources
General Manager
Chair
Account Manager
consultant Seattle Govt. Relations
Western Regional Sales Manager
Vice President/Managing Principal
Vice President, Finance & Administra
0%
25%
50%
75%
100%
Percent Values

Brown
Wood
Smith
Lee
Baker
Thomas
Schroeder
Ray
Nelson
Jones
Johnson
Hoffman
Hand
Frost
Evans
Erickson
Dalpiaz
Anderson
Adams
Zipp

Boeing
Hewlett-Packard Company
Tektronix, Inc.
Battelle
Fluke Corporation
Microsoft Corporation
Mentor Graphics Corporation
ELDEC Corporation
Puget Sound Power & Light
Motorola Inc.
ARCO Products Company
University Washington
Sundstrand
Sandia National Laboratories
Honeywell
Washington Technology Center
Intel Corporation
Asymetrix Corporation
Oregon State University
Digital Equipment Corporation
0%
25%
50%
75%

Company

First Name

mistake would harmless. user would surely notice choices useless
avoid checking menu. menu appropriate, user would save time
choosing common values it.
long menu be? Long enough include common values
short enough checked quickly. make sure menu long enough, study often
fields values repeat. Names++, Figures 9a 9b depict frequency histogram

100%

Figure 9a: Frequency values First Name, Last Name, Title, Company
fields 448 names used Section 4. plot histogram 20
common values. Dark lines indicate percent values could chosen
different sized menus. menu includes choices top vertical
position, would allow user choose percentage field values indicated
horizontal position.

344

fiP.O. Box 3707
P.O. Box 3999
Pacific Northwest Laboratories
P.O. Box 999
P.O. Box 500
One Microsoft Way
P.O. Box C9090
P.O. Box 100
8005 S.W. Boeckman Road
160520 Microsoft BVUE
P.O. Box 97034
Cherry Point Refinery
Boeing Commercial Airplane Company
Post Office Box 8100
P.O. Box 97001
Battelle Boulevard
TAF C-34
P.O. Box 9090
P.O. Box 1970
FJ-15

City

Address

HREE NTERFACES NORMATION C APTURE: C ASE TUDY DDING N AME NFORMATION

WA

State

ID
TX
IL
NY

AZ
UT
OH
NM
MN
MI
KS
FL
British Columbia
Virginia
VA
Texas
0%
25%
50%
75%
Percent Values

99352
98124-2207
98124-2499
99220
98206
98195
98124
98052-6399
98009
98046-0100
98006
99336
98206-9090
98073-9701
98004
97077
97070-7777
99163
97070
98477
0%
25%

Zip Code


CA

Seattle
Bellevue
Richland
Redmond
Spokane
Everett
Beaverton
Hillsboro
Wilsonville
Lynnwood
Vancouver
Pullman
Kennewick
Tacoma
San Francisco
Portland
Blaine
San Ramon
Kirkland
Corvallis

100%

50%

75%

100%

Figure 9b: Frequency values Address, City, State, Zip Code fields
448 names used Section 4.
20 common values 8 fields drawn 448 name records used
experiments. Overlaid plot line indicating percent field values could
chosen particular size menu. instance, First Name field Figure 9a,
histogram almost flat. menu including John would allow user choose
value field less 5% time. menu included 20 first names
shown, user could choose value 25% time. field menu
long enough include common values would take long
check. (Also, Newton computer used Section 4 limits menus 23 choices
screen size.) contrast, Company field Figure 9a, menu including

345

fiS CHLIMMER & W ELLS

Boeing would allow user choose value 10% time. included
20 values shown, user could choose value 50% time.
Studying histograms aiming menus include 50% fields values,
might re-engineer Names++ menus size 20 Company Field, size 10
City field, size 5 State field. fields flat histograms would
need large menus include high percentage field values. Recall Section 4 reports
one subjects frustration Title field. President seems repeated
field 448 names used.
5.2

Predictive fillin

Set predictive fillin field functionally dependent (Ullman, 1988) another.
functional dependency related artificial intelligence idea determination
(Russell, 1989). Intuitively, one field R, range, functionally depends another field D,
domain, if, given value D, compute unique value R. predictive fillin
find previous entry value new entry, copies
previous entrys value R new entry. Names++, Company field
domain Address field range functional dependency.
Predictive fillin functionally dependent fields probably strict
strategy. functional dependencies useful predictive fillin
domain values unique database. so, predictive fillin cannot find
previously matching entry cannot copy relevant information. instance, US
citizens address functionally dependent Social Security number. application
like Names++ dont expect see Social Security number twice, predictive
fillin would never opportunity help user filling address. Functional
dependencies repeated domain values database, dense functional
dependencies, used set predictive fillin.
Conversely, non-functional dependencies may close enough functional
useful predictive fillin. Technically, dependency functional unless one value
range computed every value domain. values range
computed values domain, dependency might still useful (Raju &
Majumdar, 1988, Russell, 1989, Ziarko, 1992). instance, companies single
office address, may one. still quite useful fill address
fields Names++ finds previous name matching Company field. user
interface strategies compensate possible range values arise;
instance, Names++ puts alternate addresses Address fields adaptive menu.
Therefore, dense dependencies functional nearly so, dense approximatelyfunctional dependencies, used set predictive fillin.
determine dense approximately-functional dependencies hold new
application area, may necessary repeat type empirical domain analysis
described adaptive menus. Names++, used common sense knowledge
people, companies, addresses set predictive fillin. Recall goal
discover end result automatic learning worthwhile (e.g., Dent et al., 1992;
Hermens & Schlimmer, 1994; Schlimmer & Hermens, 1993; Yoshida, 1994). recommend
considering field number logical components dependencies may exist
parts rather whole fields. instance, person company may share
common telephone number area code prefix, likely different

346

fiT HREE NTERFACES NORMATION C APTURE: C ASE TUDY DDING N AME NFORMATION

extensions. predictively filling last component phone number, Names++
fills much without adding poor quality information.

6. Related Work
Though interested different tasks, researchers studied using intelligent user
interfaces speed information capture. instance, Hermens Schlimmer (1994) built
electronic form filler tried provide default values every field form.
field form decision tree calculate default value. Like Names++,
calculations used previously entered information generate defaults predictively fill
fields. Unlike Names++, calculations constructed run-time using
machine learning method. (Names++ alter predictive fillin run-time. cf. Table 1.)
field tested system single electronic form filled several hundred times
eight month period. report 87% reduction keystrokes; loosely translating
speedup yields 669% speedup approximately 3 times 210% speedup
observed entering name.
Studying text prediction without field boundaries, Pomerleau (1995) built typing
completion aid. Without relying note-taking properties, system predicts completion
current word typed (presumably editor). connectionist network
estimates probability number possible completions current word;
likely, threshold, offered user. Pomerleau tested system pair
subjects two-week period reports increase typing speed 2% English
text 1318% computer program code. modest gain may due inefficiencies
learning method, lack redundancy task, limitations user
interface itself.
complement earlier research, paper reports individual collective
accuracy three user interface components. reports user task time showing
components significantly improve efficiency. paper also clarifies issue confounded
earlier work. learning interface less effective expected, due inherent
limitation interface itself, learning method perform inadequately?
answer second question, work compares two learning methods.
paper, hand-built predictive fillin structures (cf. Table 1) able assess
quality predictive fillin interface directly.

7. Conclusion
paper makes two main contributions. First, presents study impact three
user interface components time enter information computer: handwriting
recognition, adaptive menus, predictive fillin. Handwriting recognition slower
typing preferred users. Advances handwriting recognition may make faster,
recognition would still much slower choosing value menu predictive
fillin. three components work well together preferred users.
Second, paper discusses principles applying adaptive menus predictive fillin
new application areas. Fields few, frequently repeated values candidates
adaptive menus; functional dependencies indicate candidates predictive fillin. Whether
characteristics learned run-time topic future research.

347

fiS CHLIMMER & W ELLS

Acknowledgments
Kerry Hersh Raghavendra provided names used Section 4. Apple Computer developed
supports Newton Newton ToolKit programming environment. Newton AI
group WSU provided many useful comments earlier draft paper. Geoff Allen,
Karl Hakimian, Mike Kibler, EECS staff provided consistent reliable
computing environment. Anonymous reviewers earlier draft paper provided
many (many) valuable suggestions. work supported part NASA grant
number NCC 2-794.

References
Agre, P. E., & Chapman, D. (1987). Pengi: implementation theory activity.
Proceedings Sixth National Conference Artificial Intelligence (pp. 268272).
Seattle, WA: AAAI Press.
Cesar, M., & Shinghal, R. (1990). algorithm segmenting handwriting postal codes.
Int. J. Man-Machine Studies, 33, 6380.
Culbert, M. (1994). Low power hardware high performance PDA. Proceedings
1994 IEEE Computer Conference. San Francisco, CA: IEEE.
Dent, L., Boticario, J., McDermott, J., Mitchell, T., & Zabowski, D. (1992). personal
learning apprentice. Proceedings Tenth National Conference Artificial
Intelligence (pp. 96103). San Jose, CA: AAAI Press.
Hermens, L. A., & Schlimmer, J. C. (1994). machine learning apprentice
completion repetitive forms. IEEE Expert, 9, 1, 2833.
Horswill, I. D., & Brooks, R. A. (1988). Situated vision dynamic world: Chasing objects.
Proceedings Seventh National Conference Artificial Intelligence (pp. 796800).
St. Paul, MN: AAAI Press.
Kolodner, J. (1993). Case-based reasoning. San Francisco, CA: Morgan Kaufmann.
Kreigh, R. J., Pesot, J. F., & Halcomb, C. G. (1990). evaluation look-ahead help fields
various types menu hierarchies. Int. J. Man-Machine Studies, 32, 649661.
Lee, J. (1990). Intelligent interfaces UIMS. D. A. Duce, M. R. Gomes, F. R. A.
Hopgood, & J. R. Lee (Eds.), User interface management design. NY: SpringerVerlag.
MacKenzie, S. I., Nonnecke, B., Riddersma, S., McQueen, C., & Meltz, M. (1994).
Alphanumeric entry pen-based computers. Int. J. Human-Computer Studies, 41,
755792.
Meyer, A. (1995). Pen computing: technology overview vision. SIGCHI Bulletin, 27,
3, 4690.
Mitchell, J., & Shneiderman, B. (1989). Dynamic versus static menus: exploratory
comparison. SIGCHI Bulletin, 20, 4, 33-37.
348

fiT HREE NTERFACES NORMATION C APTURE: C ASE TUDY DDING N AME NFORMATION

Norman, K. L. (1991). psychology menu selection: Designing cognitive control
human/computer interface. Norwood, NJ: Ablex.
Pomerleau, D. A. (1995). connectionist technique accelerated textual input: Letting
network typing. Advances Neural Information Processing Systems 7.
Cambridge, MA: MIT Press.
Rissland, E. L. (1984). Ingredients intelligent user interfaces. Int. J. Man-Machine
Studies, 21, 377388.
Raju, K. V. S. V. N., & Majumdar, A. K. (1988). Fuzzy functional dependencies lossless
join decomposition fuzzy relational database systems. ACM Trans. Database Syst. 13,
2, 129166.
Russell, S. J. (1989). use knowledge analogy induction. San Francisco, CA:
Morgan Kaufmann.
Schlimmer, J. C., & Hermens, L. A. (1993). Software agents: Completing patterns
constructing interfaces. Journal Artificial Intelligence Research, 1, 6189.
Sears, A. & Shneiderman, B. (1994). Split menus: Effectively using selection frequency
organize menus. ACM Trans. Computer-Human Interaction, 1, 1, 2751.
Smith, W. R. (1994). Newton application architecture. Proceedings 1994 IEEE
Computer Conference. San Francisco, CA: IEEE.
Snowberry, K., Parkinson, S., & Sisson, N. (1985). Effects help fields navigating
hierarchical menu structures. Int. J. Man-Machine Studies, 22, 479491.
Ullman, J. D. (1988). Principles database knowledge-base systems: Volume 1.
Rockville, MD: Computer Science Press.
Ward, J. R., & Blesser, B. (1986). Interactive recognition handprinted characters
computer input. SIGCHI Bulletin, 18, 1, 4457.
Wilkinson, L., Hill, M., & Vang, E. (1992). SYSTAT: Graphics, Version 5.2 Edition.
Evanston, IL: SYSTAT, Inc.
Witten, I. H., Cleary, J. G., & Greenberg, S. (1984). frequency-based menu-splitting
algorithms. Int. J. Man-Machine Studies, 21, 135-148.
Yoshida, K. (1994). User command prediction graph-based induction. Sixth IEEE
International Conference Tools Artificial Intelligence (pp. 732735). New
Orleans, LA: IEEE.
Ziarko, W. (1992). discovery, analysis, representation data dependencies.
Piatetsky-Shapiro, G., & Frawley, W. (Eds.), Knowledge discovery databases. Palo
Alto, CA: AAAI Press.

349

fiJournal Artificial Intelligence Research 5 (1996) 239-288

Submitted 3/96; published 11/96

MUSE CSP: Extension
Constraint Satisfaction Problem
Randall A. Helzerman
Mary P. Harper

School Electrical Computer Engineering
1285 Electrical Engineering Building
Purdue University
West Lafayette, 47907-1285 USA

helz@ecn.purdue.edu
harper@ecn.purdue.edu

Abstract

paper describes extension constraint satisfaction problem (CSP) called
MUSE CSP (MU ltiply SE gmented C onstraint atisfaction P roblem). extension
especially useful problems segment multiple sets partially shared
variables. problems arise naturally signal processing applications including computer vision, speech processing, handwriting recognition. applications,
often dicult segment data one way given low-level information utilized
segmentation algorithms. MUSE CSP used compactly represent several
similar instances constraint satisfaction problem. multiple instances CSP
common variables domains constraints,
combined single instance MUSE CSP, reducing work required apply
constraints. introduce concepts MUSE node consistency, MUSE arc consistency,
MUSE path consistency. demonstrate MUSE CSP used compactly represent lexically ambiguous sentences multiple sentence hypotheses
often generated speech recognition algorithms grammar constraints
used provide parses syntactically correct sentences. Algorithms MUSE arc
path consistency provided. Finally, discuss create MUSE CSP
set CSPs labeled indicate variable shared
single CSP.

1. Introduction
paper describes extension constraint satisfaction problem (CSP) called MUSE
CSP (MU ltiply SE gmented C onstraint atisfaction P roblem). extension especially
useful problems segment multiple sets partially shared variables.
First, describe constraint satisfaction problem define extension.

1.1 Constraint Satisfaction Problem
Constraint satisfaction problems (CSP) rich history Artificial Intelligence (Davis
& Rosenfeld, 1981; Dechter, Meiri, & Pearl, 1991; Dechter & Pearl, 1988; Freuder, 1989,
1990; Mackworth, 1977; Mackworth & Freuder, 1985; Villain & Kautz, 1986; Waltz, 1975)
(for general reference, see Tsang, 1993). Constraint satisfaction provides convenient way
represent solve certain types problems. general, problems
solved assigning mutually compatible values predetermined number variables
c 1996


AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiHelzerman & Harper

set constraints. approach used variety disciplines including
machine vision, belief maintenance, temporal reasoning, graph theory, circuit design,
diagnostic reasoning. using CSP approach (e.g., Figure 1), variables typically depicted vertices nodes, node associated finite set possible
values, constraints imposed variables depicted using arcs. arc looping
node represents unary constraint (a constraint single variable),
arc two nodes represents binary constraint (a constraint two variables).
classic example CSP map coloring problem (e.g., Figure 1), color must
assigned country two neighboring countries color.
variable represents country's color, constraint arc two variables indicates
two joined countries adjacent assigned color.
Formally, CSP (Mackworth, 1977) defined Definition 1.

Definition 1 (Constraint Satisfaction Problem)
N = fi; j; : : :g set nodes (or variables), jN j = n,
L = fa; b; : : :g set labels, jLj = l,
Li = faja 2 L (i; a) admissibleg,
R1 unary constraint, (i; a) admissible R1 (i; a),
R2 binary constraint, (i; a) , (j; b) admissible R2 (i; a; j; b).
CSP network contains n-tuples Ln satisfy R1 R2 . Since

labels associated node may incompatible labels assigned nodes,
desirable, constraints suciently tight (van Beek, 1994), eliminate
many labels possible enforcing local consistency conditions globally
consistent solution extracted (Dechter, 1992). Node arc consistency defined
Definitions 2 3, respectively. addition, may desirable eliminate many label
pairs possible using path consistency, defined Definition 4.

Definition 2 (Node Consistency) instance CSP said node consistent
node's domain contains labels unary constraint R1 holds, i.e.:
8i 2 N : 8a 2 Li : R1 (i; a)
Definition 3 (Arc Consistency) instance CSP said arc consistent

every pair nodes j , element Li (the domain i) least one element Lj
binary constraint R2 holds, i.e.:
8i; j 2 N : 8a 2 Li : 9b 2 Lj : R2 (i; a; j; b)
{red, green, blue}
Different
Color

1
2

3

{red, green, blue}

Different
Color

1
2

3

{red, green, blue}

Different
Color

Figure 1: map coloring problem example CSP.
240

fiMUSE CSP: Extension Constraint Satisfaction Problem

Definition 4 (Path Consistency) instance CSP said path consistent if:
8i; j 2 N : 6= j ) (8a 2 Li : 8b 2 Lj : 8k 2 N : k 6= ^ k 6= j ^ P ath(i; k; j ) )
(R2(i,a,j,b)) 9c 2 Lk : R2 (i; a; k; c) ^ R2 (k; c; j; b)))
Path(i; k; j ) indicates path arcs length two connecting j
goes k.

Node consistency easily enforced operation Li = Li \ fxjR1 (i; x)g, requiring
O(nl) time (where n number variables l maximum domain size). Arc
consistency enforced ensuring every label node supported least one
label node shares binary constraint (Mackworth, 1977; Mackworth
& Freuder, 1985; Mohr & Henderson, 1986). arc consistency algorithm AC-4 (Mohr
& Henderson, 1986) worst-case running time (el2) (where e number
constraint arcs). AC-3 (Mackworth & Freuder, 1985) often performs better AC-4
practice, though slower running time worst case. AC-6 (Bessiere, 1994)
worst-case running time AC-4 faster AC-3 AC-4 practice.
Path consistency ensures pair labelings (i; a) , (j; b) allowed (i; j ) arc
directly also allowed arc paths j . Montanari proven ensure
path consistency complete graph, suces check every arc path length two
(Montanari, 1974). path consistency algorithm PC-4 (Han & Lee, 1988) worstcase running time O(n3 l3) time (where n number variables CSP).

1.2 Multiply Segmented Constraint Satisfaction Problem

many types problems solved using CSP less direct
fashion. also problems might benefit CSP approach,
dicult represent single CSP. class problems paper addresses.
example, suppose map represented Figure 1 scanned noisy computer
vision system, resulting uncertainty whether line regions 1 2
really border artifact noise. situation would yield two CSP problems
depicted Figure 2. brute-force approach would solve problems,
would reasonable scenes containing ambiguous borders. However,
number ambiguous borders increases, number CSP networks would grow
combinatorially explosive fashion. case ambiguous segmentation,
ecient merge constraint networks single network would compactly
represent instances simultaneously, shown Figure 3. Notice CSP
instances combined directed acyclic graph paths DAG
start end correspond CSPs combined. paper, develop
extension CSP called MUSE CSP (MU ltiply SE gmented C onstraint atisfaction
P roblem), represents multiple instances CSP problem DAG.
multiple, similar instances CSP, separately applying constraints
instance result much duplicated work. avoid duplication,
provided way combine multiple instances CSP MUSE CSP,
241

fiHelzerman & Harper

{red, green, blue}

{red, green, blue}

1

1

3
Different
Color

3

1

{red, green, blue}

2

3
1

Different
Color

1

Different
Color

2

3
{red, green, blue}

{red, green, blue}

3

2

Different
Color

Figure 2: ambiguous map yields two CSP problems.

start

{red, green, blue}

Different
Color

Different
Color

1
{red, green, blue}

3
{red, green, blue}

Different
Color

1

{red, green,
blue}

Different
Color

Different
Color

1

3

2

2

3

end

{red, green, blue}

{red, green, blue}

{red, green, blue}

Different
Color

{red, green, blue}

Different
Color

Figure 3: two CSP problems Figure 2 captured single instance
MUSE CSP. directed edges form DAG directed paths
DAG correspond instances CSPs combined.

242

fiMUSE CSP: Extension Constraint Satisfaction Problem

developed concepts MUSE node consistency, MUSE arc consistency, MUSE path
consistency. Formally, define MUSE CSP follows:

Definition 5 (MUSE CSP)
N = fi; j; : : :g set nodes (or variables), jN j = n,
2N set segments jj = s,
L = fa; b; : : :g set labels, jLj = l,
Li = faja 2 L (i; a) admissible least one segmentg,
R1 unary constraint, (i; a) admissible R1 (i; a),
R2 binary constraint, (i; a) , (j; b) admissible R2 (i; a; j; b).
segments different sets nodes representing CSP instances
combined form MUSE CSP. solution MUSE CSP defined solution
one segments:

Definition 6 (Solution MUSE CSP) solution MUSE CSP assignment ff
segment = fi1; : : :; ip g 2 ff 2 Li1 Lip R1(ix ; ff(ix )) holds
every node ix 2 , R2(ix ; ff(ix); iy ; ff(iy )) holds every pair nodes ix ; iy 2 ,
ix 6= iy .
Depending application, solution MUSE CSP could also set
consistent labels single path MUSE CSP, single set labels
paths (or CSPs), compatible sets labels paths.
MUSE CSP solved modified backtracking algorithm finds
consistent label assignment segment. However, constraints suciently
tight, search space pruned enforcing local consistency conditions, node,
arc, path consistency. gain eciency resulting enforcing local consistency
conditions backtracking, node, arc, path consistency must modified MUSE
CSP. definitions MUSE CSP node consistency, arc consistency, path consistency
appear Definitions 7, 8, 9, respectively.

Definition 7 (MUSE Node Consistency) instance MUSE CSP said node consistent
node's domain Li contains labels unary constraint R1 holds,
i.e.:
8i 2 N : 8a 2 Li : R1 (i; a)
Definition 8 (MUSE Arc Consistency) instance MUSE CSP said MUSE arc consis-

tent every label domain Li least one segment whose nodes'
domains contain least one label b binary constraint R2 holds, i.e.:

8i 2 N : 8a 2 Li : 9 2 : 2 ^ 8j 2 : j 6= ) 9b 2 Lj : R2 (i; a; j; b)

Definition 9 (MUSE Path Consistency) instance MUSE CSP said path consistent
if:

8i; j 2 N : 6= j ) (8a 2 Li : 8b 2 Lj : 9 2 : i; j 2 ^ 8k 2 : k 6= ^ k 6= j ^ P ath(i; k; j ) )
(R2 (i; a; j; b) ) 9c 2 Lk : R2 (i; a; k; c) ^ R2 (k; c; j; b)))
243

fiHelzerman & Harper

a.

b.

3

{c,d}

start

1

{e}

3

{e}

{d}

end

2

{a,b}


e 1

b
e 1

c
e 0 1

b
e 0 1

start

end

2

1
{b}

4

4
{f}

{f}
c
1 0
b 0 1


b
f 1 1

c
f 0 1

b

1

b
f 1

f


1

Figure 4: a. MUSE CSP MUSE arc consistency achieved; b. MUSE CSP
MUSE arc consistency achieved.
MUSE CSP node consistent segments node consistent. Unfortunately,
MUSE CSP arc consistency requires attention. enforcing arc consistency
CSP, label 2 Li eliminated node whenever domain Lj
labels together satisfy binary constraints. However, MUSE CSP,
label eliminated node, must unsupported arcs every
segment appears, required definition MUSE arc consistency shown
Definition 8. Notice Definition 8 reduces Definition 3 number segments
one.
demonstrate MUSE arc consistency applies MUSE CSP, consider MUSE
CSP Figure 4a. Notice label c 2 L2 supported labels L3
L4 , receive support labels L1. label considered
MUSE arc consistent? answer node 2 member paths
DAG contain node 3 node 4, neither support label
c. segment nodes label supports
c, c eliminated L2. c eliminated L2, also eliminated
L1 . elimination c L2 causes loose support node
2. Since node 2 member every path, segment provides support a.
MUSE arc consistent DAG depicted Figure 4b. Note MUSE arc consistency
ensure individual segments arc consistent CSPs. example, Figure
5 MUSE arc consistent even though segments CSP arc consistent.
c receives arc support (which local computation) arcs least
one paths. cannot ensure values support label
mutually consistent considering MUSE arc consistency alone. case, MUSE path
consistency together MUSE arc consistency would needed eliminate illegal
labels c a.
enforcing path consistency CSP, R2 (i; a; j; b) becomes false if, third
node k, label c 2 Lk R2 (i; a; k; c) R2 (k; c; j; b) true.
244

fiMUSE CSP: Extension Constraint Satisfaction Problem

c
e 1 1

b
e 0 1

3

{c,d}

start

1

{e}

end

2

{a,b}

4
{f}

c
1 0
b 0 1

b
f 1 1

c
f 0 1

Figure 5: MUSE CSP MUSE arc consistent, arc consistent
segment.
MUSE CSP, binary constraint becomes path inconsistent one segment, could still
allowed another. Therefore, definition MUSE path consistency modified
shown Definition 9.
Enforcement MUSE arc path consistency requires modification traditional
CSP algorithms. algorithms described introduce several applications
MUSE CSP proven useful.

2. MUSE CSP Constraint-based Parsing
desirable represent MUSE CSP directed acyclic graph (DAG)
directed paths DAG correspond instances CSP problems. often
easy determine variables shared construct DAG.
application presented section one MUSE CSP useful. parsing
problem naturally represented DAG presence ambiguity. many
cases, word multiple parts speech; convenient represent
words nodes MUSE CSP. speech recognition systems, identification
correct words sentence improved using syntactic constraints. However, word
recognition algorithm often produces lattice word candidates. Clearly, individually
parsing sentences lattice inecient.

2.1 Parsing Constraint Dependency Grammar
Maruyama developed new grammar called Constraint Dependency Grammar (CDG)
(Maruyama, 1990a, 1990b, 1990c). showed CDG parsing cast
CSP finite domain, constraints used rule ungrammatical sentences.
CDG four-tuple, h; R; L; C i, where:
245

fiHelzerman & Harper

= finite set preterminal symbols, lexical categories.
R = finite set uniquely named roles (or role-ids) = fr1; : : :; rp g.
L = finite set labels = fl1 ; : : :; lq g.
C = finite set constraints assignment must satisfy.

sentence = w1 w2w3 : : :wn 2 string length n. word wi 2
sentence s, must keep track p different roles (or variables). role variable
takes role values form <l; m>, l 2 L 2 fnil; 1; 2; : : :ng. Role values
denoted examples label-modifiee. parsing, label L indicates different
syntactic function. value role value <l; m>, assigned particular
role wi, specifies position word wi modifying takes
function specified label, l (e.g., subj-3 indicates word label
subject modifies third word sentence). sentence said
generated grammar G exists assignment maps role value
n p roles constraint set C (described next paragraph)
satisfied.
constraint set logical formula form: 8x1 ; x2; : : :; xa (and P1 P2 : : : Pm ),
xi ranges role values roles word s.
subformula Pi C must form: (if Antecedent Consequent), Antecedent
Consequent predicates predicates joined logical connectives.
basic components used express constraints.

Variables: x1 , x2, : : : xa (a = 2 (Maruyama, 1990a)).
Constants: elements subsets [ L [ R [ fnil, 1, 2, : : :, ng, n corresponds
number words sentence.

Functions:
(pos x) returns position word role value x.
(rid x) returns role-id role value x.
(lab x) returns label role value x.
(mod x) returns position modifiee role value x.
(cat y) returns category (i.e., element ) word position y.
Predicates: =, >, <1 .
Logical Connectives: and, or, not.
subformula Pi called unary constraint contains one variable binary constraint contains two. CDG grammar two associated parameters, degree
arity. degree grammar G number roles. arity grammar, a,
corresponds maximum number variables subformulas C .
Consider example grammar, G1 , defined using following four-tuple:
h1 = fdet; noun; verbg; R1 = fgovernorg, L1 = fdet; root; subjg, C1 (see constraints
Figure 6)i. G1 degree one arity two. illustrate process parsing
1. Note 1 > nil 1 < nil false, nil integer. MUSE networks, relate position
intervals using <, >, =.

246

fiMUSE CSP: Extension Constraint Satisfaction Problem

constraint satisfaction, Figure 6 shows steps parsing sentence dog
eats. simplify presentation example, grammar uses single role,
governor role, denoted G constraint network Figure 6. governor
role indicates function word fills sentence governed head word.
word called head phrase forms basis phrase (e.g., verb
head sentence). useful grammars, would also include several needs roles
(e.g, need1, need2) make certain head word constituents needs
complete (e.g., singular count noun needs determiner complete noun phrase).
determine whether sentence, dog eats, generated grammar, CDG
parser must able assign least one role value n p roles satisfies
grammar constraints (n = 3 sentence length, p = 1 number roles).
values role selected finite set L1 fnil, 1, 2, 3g, CDG parsing
viewed constraint satisfaction problem finite domain. Therefore, constraint
satisfaction used determine possible parses sentence.
Initially, word, possible role values assigned governor role.
assume word must either modify another word (other itself) modify
word (m=nil). Nothing gained CDG word modify itself. Next unary
constraints applied role values constraint network. role value
incompatible unary constraint satisfies antecedent,
consequent. Notice Figure 6 role values associated governor role
first word (the) satisfy antecedent first unary constraint, det-nil, subjnil, subj-2, subj-3, root-nil, root-2, root-3 satisfy consequent,
incompatible constraint. role value violates unary constraint, node
consistency eliminates role values role never participate
parse sentence. unary constraints applied top constraint
network Figure 6, second network produced.
Next, binary constraints applied. Binary constraints determine pairs role
values legally coexist. keep track pairs role values, arcs constructed connecting role roles network, arc associated arc matrix,
whose row column indices role values associated two roles connects.
entries arc matrix either 1 (indicating two role values indexing
entry compatible) 0 (indicating role values cannot simultaneously exist). Initially, entries matrix set 1, indicating pair role values
indexing entry initially compatible (because constraints applied).
example, single binary constraint (shown Figure 6) applied pairs
role values indexing entries matrices. example, x=det-3
y=root-nil eats, consequent binary constraint fails; hence, role values
incompatible. indicated replacing entry 1 0.
Following binary constraints, roles constraint network still contain
role values incompatible parse sentence. Role values
supported binary constraints eliminated achieving arc consistency.
example, det-3 supported remaining role value eats thus
deleted role.
arc consistency, example sentence single parse one
value per role sentence. parse sentence consists assignment role values
247

fiHelzerman & Harper


det
1

dog

eats

noun
2

verb
3

G

G
{detnil, det2, det3,
subjnil, subj2, subj3,
rootnil, root2, root3}

G

{detnil, det1, det3,
subjnil, subj1, subj3,
rootnil, root1, root3}

{detnil, det1, det2,
subjnil, subj1, subj2,
rootnil, root1, root2}

1. (if (= (cat (pos x)) det)
2. (if (= (cat (pos x)) noun)
(and (= (lab x) det)
(and (= (lab x) subj)
(< (pos x) (mod x))))
(< (pos x) (mod x))))

Apply Unary Constraints
Enforce Node Consistency:

3. (if (= (cat (pos x)) verb)
(and (= (lab x) root)
(= (mod x) nil)))

det
1

dog

eats

noun
2

verb
3

G

G

G
{subj3}

{det2, det3}

{rootnil}
rootnil

subj3
det2

1

det3

1

subj3

1

rootnil
det2

1

det3

1

(if (and (= (lab x) det)
(= (mod x) (pos y)))
(= (cat (pos y)) noun))

Apply Binary Constraints:


det
1

dog

eats

noun
2

G

verb
3

G

G
{subj3}

{det2, det3}

{rootnil}
rootnil

subj3
det2

1

det3

1

subj3

1

rootnil
det2

1

det3

0

Enforce Arc Consistency:


det
1

dog

eats

noun
2

verb
3

G

G

{det2}

{subj3}

G
{rootnil}

Figure 6: Using constraints parse sentence: dog eats.
248

fiMUSE CSP: Extension Constraint Satisfaction Problem

roles unary binary constraints satisfied assignment.
general, one parse sentence; hence, one
assignment values roles sentence. Note assignment example
sentence is:

pos word cat governor role's value
1 det
det-2
2 dog noun
subj-3
3 eats verb
root-nil
one possible sentence part speech words
known advance, parsing problem cast CSP. However,
ambiguity present written spoken sentences handled uniformly requires use
MUSE CSP.

2.2 Processing Lexically Ambiguous Sentences CDG
One shortcoming Maruyama's constraint-based parser requires word
single part speech; however, many words English language one
lexical category. assumption captured way Maruyama writes constraints
involving category information; category determined based position
word sentence. However, even simple example, word dog could
either noun verb prior propagation syntactic constraints. Since parsing
used lexically disambiguate sentence, ideally, parsing algorithm
require part speech words known prior parsing.
Lexically ambiguous words easily accommodated creating CSP
possible combination lexical categories; however, would combinatorially explosive.
contrast, using MUSE CSP, create separate word node legal part
speech word, sharing words ambiguous across segments. Since
position uniquely define category word, must allow category information
accessed role value rather position word sentence
(i.e., use (cat x) rather (cat (pos x))). associate category information
role value, could instead create role values lexical category word
store values single word node. However, representation
convenient MUSE CSP representation problem. lexically augmented
CSP, one role per word (this usually case), role values
associated one lexical category one role cannot support role values associated
another lexical category another role word. Additional constraints
must propagated enforce requirement. MUSE CSP representation
suffer problem. using separate node part speech, MUSE CSP
directly represents independence alternative lexical categories given word.
space requirements arc matrices MUSE representation lower
lexicalized CSP arc roles different lexical categories
word MUSE representation. Note MUSE arc consistency equivalent
performing arc consistency lexically augmented CSP (after additional constraints
249

fiHelzerman & Harper

propagated)2. importantly, MUSE CSP represent lattices cannot
combined single CSP.
technique creating separate nodes different instances word also
used handle feature analysis (like number person) parsing (Harper & Helzerman,
1995b). Since words multiple feature values, often ecient create
single node set feature values, apply syntactic constraints, split node
set nodes single feature value prior applying constraints pertaining
feature type. Node splitting also used support use context-specific
constraints (Harper & Helzerman, 1995b).

2.3 Lattice Example

Much motivation extending CSP comes work spoken language parsing
(Harper & Helzerman, 1995a; Harper, Jamieson, Zoltowski, & Helzerman, 1992; Zoltowski,
Harper, Jamieson, & Helzerman, 1992). output hidden-Markov-model-based
speech recognizer thought lattice word candidates. Unfortunately,
lattice contains many word candidates never appear sentence covering
duration speech utterance. converting lattice word graph, many word
candidates lattice eliminated. Figure 7 depicts word graph constructed
simple lattice. Notice word tour eliminated word graph
constructed. order accommodate words occur time intervals may
overlap, word's position lattice represented tuple (b; e)
b < e. positional relations defined constraints easily modified operate
tuples (Harper & Helzerman, 1995a).
construction, word graph often contains spurious sentence hypotheses
pruned using variety constraints (e.g., syntactic, semantic, etc.).
apply constraints individual sentences rule ungrammatical; however,
individually processing sentence hypothesis inecient since many high degree
similarity. spoken language parsing problem structured MUSE CSP problem,
constraints used parse individual sentences would applied word graph
sentence hypotheses, eliminating consideration many hypotheses
ungrammatical.
developed MUSE CSP constraint-based parser, PARSEC (Harper & Helzerman, 1995a, 1995b; Harper et al., 1992; Zoltowski et al., 1992), capable parsing
word graphs containing multiple sentences produced speech recognition module.
developed syntactic semantic constraints parsing single sentences,
applied word graph, eliminate hypotheses syntactically semantically
incorrect. MUSE CSP used parser thought parse forest
pruned using constraints. applying constraints wide variety knowledge
sources, parser prunes composite structure many role values associated
role, well word nodes remaining role values. Several experiments
(Harper et al., 1992; Zoltowski et al., 1992) considered effective syntactic
2. simple demonstration, consider merging nodes 3 4 Figure 5 single node
value e f keep track fact type 3 4, respectively. circumstances,
CSP arc consistency give results MUSE CSP arc consistency; even though c appear
solutions, eliminated. Note example uses one role per node.

250

fiMUSE CSP: Extension Constraint Satisfaction Problem

tour


wreck
hard


1



nice

beach


recognizes

2

3

4

5

wreck



(4,6)

(1,2)

hard

start


(1,2)

6

(2,3)

speech

7

8



nice

(6,7)

(7,8)

9

beach
(8,9)


(3,4)

end

recognizes
(4,8)

speech
(8,9)

Figure 7: Multiple sentence hypotheses parsed simultaneously applying constraints word graph rather individual sentences extracted
lattice.
semantic constraints pruning word nodes appear sentence hypothesis.
work speech processing, MUSE arc consistency algorithm effective
pruning role values composite structure never appear parse
sentence (i.e., individual CSP). Constraints usually tight enough MUSE
arc consistency eliminates role values participate least one parse
represented sentences.
MUSE CSP useful way process multiple sentences arc consistency
algorithm effective eliminating role values cannot appear sentence parses.
Several factors contribute effectiveness arc consistency algorithm
problem. First, syntactic constraints fairly tight constraints. Second, role
values contain segmental information constrain problem. Consider word
graph Figure 8. value s-(3,4) associated role marked N word
cannot support values role marked G word dogs position (3,5),
legal segment involving position (3,5). figure, mark
entries value associated one role segmentally incompatible values
another N. entries equivalent 0. Third, many times constraints
create symmetric dependencies words sentence. example, one constraint
might indicate verb needs subject left, another subject must
governed verb right.

2.4 Demonstration Utility MUSE CSP Parsing

demonstrate utility MUSE CSP simultaneously parsing multiple CSP instances,
consider problem determining strings length 3n consisting a's, b's, c's
251

fiHelzerman & Harper

obj(1,2) obj(2,3)
s(3,4)

N

N

s(3,5)

0

1

{obj(1,2),
obj(2,3)}

{rootnil}

G

start

N

G

N

N {npnil}

G
dogs
(3,5)

{s(3,4),
s(3,5)}

end

{blanknil}
{subj(2,3),
subj(3,4),
subj(3,5)}


(1,2)


(2,3)
{obj(1,2),
obj(2,3)}

G

N {np(1,2),
np(2,3)}
dog
(3,4)

obj(1,2) obj(2,3)
s(3,4)

0

1

s(3,5)

N

N

Figure 8: parsing word graphs, values assigned roles contain segmental
information make incompatible values associated
roles. example, s-(3,4) cannot support values associated
G N roles word dogs.
language bn cn . value n = 3, problem represented
single MUSE CSP problem shown Figure 9 (the roles role values depicted
simplify figure). devised constraints language (see Figure 10)
eliminate role values sentences language well ungrammatical
role values sentence language. constraints applied followed
MUSE arc consistency lattice like Figure 9 length divisible three,
grammatical sentence remain single parse. lattices containing
sentences lengths divisible three, role values eliminated
MUSE arc consistency (there grammatical sentence). Hence, search
required extract parse one. n = 3 case Figure 9, parse appears
Figure 11. single parse result regardless n chosen. Note modifiees
role values parse used ensure a, corresponding
c; b, corresponding a; c, corresponding b. Figure
12 examines time needed extract parse sentences language bn cn
MUSE CSPs representing strings length 3n, 1 n 7, containing a, b, c.
time perform MUSE AC-1 extract solution compared time extract
solution without preprocessing. time perform MUSE AC-1 extract
parse stable sentence length grows, time extract parse grows quickly
sentence lengths greater 15 MUSE arc consistency used.
previous example involves grammar one parse single
sentence lattice; however, simple matter provide similar demonstrations
252

fiMUSE CSP: Extension Constraint Satisfaction Problem

start



















(1,2)

(2,3)

(3,4)

(4,5)

(5,6)

(6,7)

(7,8)

(8.9)

(9,10)

b

b

b

b

b

b

b

b

b

(1,2)

(2,3)

(3,4)

(4,5)

(5,6)

(6,7)

(7,8)

(8.9)

(9,10)

c

c

c

c

c

c

(1,2)

(2,3)

(3,4)

(4,5)

(5,6)

(6,7)

c

c

c

(7,8)

(8.9)

(9,10)

end

Figure 9: single MUSE CSP simultaneously test possible orderings a's, b's,
c's membership language anbncn , n = 3.

2

= fa, b, cg
= fgovernorg
L2 = fa, b, cg
C2 = see below:
R2

; 3 Unary Constraints
(if (and (=
(=
(and (=
(>

(cat
(rid
(lab
(mod

x)
x)
x)
x)

a)
governor))
a)
(pos x))))

(if (and (=
(=
(and (=
(<

(cat
(rid
(lab
(mod

x)
x)
x)
x)

c)
governor))
c)
(pos x))))

(if (and (=
(=
(and (=
(<

(cat
(rid
(lab
(mod

x)
x)
x)
x)

b)
governor))
b)
(pos x))))

; 8 Binary Constraints
(if (and (= (lab x) a)
(or (= (lab y) b)
(= (lab y) c)))
(< (pos x) (pos y)))

(if (and (= (lab x) b)
(= (lab y) c))
(< (pos x) (pos y)))

(if (and (=
(=
(>
(< (mod

(lab x)
(lab y)
(pos x)
x) (mod

a)
a)
(pos y)))
y)))

(if (and (=
(=
(=
(= (lab

(if (and (=
(=
(>
(< (mod

(lab x)
(lab y)
(pos x)
x) (mod

b)
b)
(pos y)))
y)))

(if (and (= (lab x) b)
(= (mod x) (pos y))
(= (rid y) governor))
(= (lab y) a))

(if (and (=
(=
(>
(< (mod

(lab x)
(lab y)
(pos x)
x) (mod

c)
c)
(pos y)))
y)))

(if (and (=
(=
(=
(= (lab

(lab x) a)
(mod x) (pos y))
(rid y) governor))
y) c))

(lab x) c)
(mod x) (pos y))
(rid y) governor))
y) b))

Figure 10: G2 = h2; R2; L2; C2i accepts language bn cn , n 0.
253

fiHelzerman & Harper

pos
(1,2)
(2,3)
(3,4)
(4,5)
(5,6)
(6,7)
(7,8)
(8,9)
(9,10)

cat governor role's value



b
b
b
c
c
c

a-(9,10)
a-(8,9)
a-(7,8)
b-(3,4)
b-(2,3)
b-(1,2)
c-(6,7)
c-(5,6)
c-(4,5)

Figure 11: single parse remaining network depicted Figure 9 applying
constraints G2 enforcing MUSE arc consistency.

2500

CPU Time seconds

2000

Extract without MUSE AC1
1500

1000

500

Extract plus MUSE AC1
0
2

4

6

8

10

12
14
Lattice Length

16

18

20

22

Figure 12: graph depicts time extract parse language bn cn
MUSE CSP representing sentences length 3n, n varies 1
7. time extract parse without MUSE arc consistency compared
time perform MUSE AC-1 extract parse.

254

fiMUSE CSP: Extension Constraint Satisfaction Problem

3

= fa, b, cg
= fgovernorg
L3 = fw1, w2g
C3 = see below:
R3

; 2 Unary Constraints
(if (= (lab x) w1)
(< (pos x) (mod y)))

(if (= (lab x) w2)
(> (pos x) (mod y)))
; 6 Binary Constraints

(if (and (= (lab x) w1)
(= (lab y) w2))
(< (pos x) (pos y)))
(if (and (=
(=
(>
(> (mod

(lab x)
(lab y)
(pos x)
x) (mod

w1)
w1)
(pos y)))
y)))

(if (and (=
(=
(and (=
(=

(lab
(mod
(lab
(cat

w1)
(pos y)))
w2)
(cat y))))

x)
x)
y)
x)

(if (and (= (lab x) w1)
(= (lab y) w2))
(> (mod x) (mod y)))
(if (and (= (lab x) w2)
(= (lab y) w2)
(> (pos x) (pos y)))
(< (mod x) (mod y)))
(if (and (= (lab x) w2)
(= (mod x) (pos y)))
(= (lab y) w1))

Figure 13: G3 = h3 ; R3; L3; C3i accepts language ww.
complex cases. example, constraint grammar shown Figure 13
parse possible sentences given length language ww, w
fa; b; cg+. Consider MUSE CSP Figure 14 (the roles role values
depicted simplify figure). applying constraints performing MUSE arc
consistency MUSE CSP, precisely 81 strings ww,
parses compactly represented constraint network. constraints plus MUSE
arc consistency eliminate every value cannot appear parse. lattices containing
odd length sentences, role values remain MUSE arc consistency. Figure 15 shows
time needed extract parses sentences language ww
MUSE CSPs vary length w 1 8. time perform MUSE AC-1
extract parses grows slowly sentence length increases number parses
increases sentence length; however, grows slowly time extract
parses MUSE arc consistency used.
Similar results also obtained grammars used parse word graphs constructed spoken sentences resource management ATIS domains (Harper
et al., 1992; Zoltowski et al., 1992; Harper & Helzerman, 1995a).

3. MUSE CSP Arc Consistency Algorithm
section, introduce algorithm, MUSE AC-1, achieve MUSE CSP arc consistency. algorithm builds upon AC-4 algorithm (Mohr & Henderson, 1986),
present algorithm first comparison purposes.
255

fiHelzerman & Harper

start

















(1,2)

(2,3)

(3,4)

(4,5)

(5,6)

(6,7)

(7,8)

(8.9)

b

b

b

b

b

b

b

b

(1,2)

(2,3)

(3,4)

(4,5)

(5,6)

(6,7)

(7,8)

(8.9)

c

c

c

c

c

c

(1,2)

(2,3)

(3,4)

(4,5)

(5,6)

(6,7)

c

c

(7,8)

(8.9)

end

Figure 14: single MUSE CSP simultaneously test possible orderings a's, b's,
c's membership language ww jwj = 4 .

3000

CPU Time seconds

2500

2000
Extract without MUSE AC1
1500

1000

500
Extract plus MUSE AC1
0
2

4

6

8
10
Lattice Length

12

14

16

Figure 15: graph depicts time extract parses language ww
MUSE CSP representing sentences length 2 16 w 2 fa; b; cg+.
time extract parses without MUSE arc consistency compared
time perform MUSE AC-1 extract parses.

256

fiMUSE CSP: Extension Constraint Satisfaction Problem

Notation

Meaning

ordered pair nodes.
node pairs (i; j ). (i; j ) 2 E , (j; i) 2 E .
E
ordered pair node label 2 Li .
(i; a)
faja 2 L (i; a) permitted constraints (i.e., admissible)g
Li
R2 (i; a; j; b) = 1 indicates admissibility 2 Li b 2 Lj given
R2 (i; a; j; b)
binary constraints.
Counter[(i; j ); a] number labels Lj compatible 2 Li .
(j; b) 2 [i; a] means 2 Li b 2 Lj simultaneously
[i; a]
admissible. implies supports b.
[i; a] = 1 indicates label admissible (and
[i; a]
already eliminated from) node i.
queue arc support deleted.
List
(i; j )

Figure 16: Data structures notation arc consistency algorithm, AC-4.

3.1 CSP Arc Consistency: AC-4
AC-4 builds maintains several data structures, described Figure 16, allow
eciently achieve arc consistency CSP. Note modified notation
slightly eliminate subscripts (which become quite cumbersome path consistency
algorithm). Figure 17 shows code initializing data structures, Figure 18
contains algorithm eliminating inconsistent labels domains. algorithm
requires (el2) time, e number constraint arcs, l domain size (Mohr
& Henderson, 1986).
AC-4, label 2 Li compatible b 2 Lj , supports b (and vice
versa). keep track much support label has, number labels Lj
compatible Li counted total stored Counter[(i; j ); a]
algorithm Figure 17. Counter[(i; j ); a] zero, removed Li
(because cannot appear solution), ordered pair (i; a) placed List,
M[i; a] set 1 (to avoid removing element Li once). algorithm
must also keep track labels label supports using S[i; a], set arc
label pairs. example, S[i; a] = f(j; b); (j; c)g means Li supports b c Lj .
ever removed Li , b c loose support.
preprocessing step Figure 17, algorithm Figure 18 loops List
becomes empty, point CSP arc consistent. (i; a) popped List
procedure, element (j; b) S[i; a], Counter[(j; i); b] decremented.
Counter[(j; i); b] becomes zero, b would removed Lj , (j; b) placed List,
M[j; b] set 1.
257

fiHelzerman & Harper

1. List := ;
2. 2 N
3.
2 Li f
4.
[i; a] := ;
5.
[i; a] := 0; g
6. (i; j ) 2 E
7.
2 Li f
8.
Total := 0;
9.
b 2 Lj
10.
R2 (i; a; j; b) f
11.
Total := Total+1;
12.
[j; b] := [j; b] [ f(i; a)g; g
13.
Total = 0 f
14.
Li := Li , fag;
15.
List := List [ f(i; a)g;
16.
[i; a] := 1; g
17.
Counter[(i; j ); a] := Total; g

Figure 17: Initialization data structures AC-4.

1. List 6= f
2.
pop (i; a) List;
3.
(j; b) 2 S[i; a] f
4.
Counter[(j; i); b] := Counter[(j; i); b] , 1;
5.
Counter[(j; i); b] = 0 ^ [j; b] = 0 f
6.
Lj := Lj , fbg;
7.
List := List [ f(j; b)g;
8.
[j; b] := 1; g g g

Figure 18: Eliminating inconsistent labels domains AC-4.

258

fiMUSE CSP: Extension Constraint Satisfaction Problem

Next, describe MUSE arc consistency algorithm MUSE CSP, called MUSE
AC-1. purposely keep notation presentation MUSE AC-1 close possible
AC-4 reader benefit similarity two algorithms.

3.2 MUSE AC-1

MUSE arc consistency enforced removing labels Li violate conditions Definition 8. MUSE AC-1 builds maintains several data structures, described
Figure 19, allow eciently perform operation. Many data structures
borrowed AC-4, others exploit DAG representation MUSE CSP
determine values incompatible segments. Figure 22 shows
code initializing data structures, Figures 23 24 contain algorithm
eliminating inconsistent labels domains.
MUSE AC-1 AC-4, label node compatible label b node j ,
supports b. keep track much support label has, number labels Lj
compatible Li counted, total stored Counter[(i; j ); a].
CSP arc consistency, Counter[(i; j ); a] zero, would immediately removed
Li, would mean could never appear solution. However, MUSE
arc consistency, may case, even though participate
solution segments contain j , could another segment
would perfectly legal. label cannot become globally inadmissible
incompatible every segment. Hence, MUSE CSP, Counter[(i; j ); a] zero,
algorithm simply places [(i; j ); a] List records fact setting M[(i; j ); a] 1.
placing [(i; j ); a] List, algorithm indicating segments containing
j support label a.
MUSE AC-1 must also keep track labels j label Li supports
using S[(i; j ); a], set node-label pairs. example, S[(i; j ); a] = f(j; b); (j; c)g means
Li supports b c Lj . ever invalid Li , b c loose
support.
DAG, MUSE AC-1 able use properties DAG identify
local (and hence eciently computable) conditions labels become globally
inadmissible. Segments defined paths MUSE CSP start end.
value associated variable supported variables precede
follow it, way value used segment,
deleted arc consistency algorithm. addition, value variable's domain
supported constraints values associated second variable, second
variable preceded followed variables values supporting value,
solution involves path variables MUSE DAG, value cannot
supported segment involving two variables. two ideas provide basis
remaining data structures used MUSE AC-1.
Consider Figure 20, shows nodes adjacent node DAG.
every segment DAG contains node represented directed path
DAG going node i, either node j node k must every segment containing
i. Hence, label remain Li, must compatible least one label
either Lj Lk . Also, either n must contained every segment containing
259

fiHelzerman & Harper

Notation

Meaning

(i; j )

ordered pair nodes.
node pairs (i; j ) exists path directed edges G
j . (i; j ) 2 E , (j; i) 2 E .
ordered pair node label 2 Li .

E

(i; a)
[(i; j ); a]

ordered pair node pair (i; j ) label 2 Li .
faja 2 L (i; a) permitted constraints (i.e., admissible)g

Li

2 (i; a; j; b)

R

Counter[(i; j ); a]
S[(i; j ); a]
M[(i; j ); a]
List

G

Next-Edgei
Prev-Edgei
Local-Prev-Support(i; a)
Local-Next-Support(i; a)
Prev-Support[(i; j ); a]
Next-Support[(i; j ); a]

2 (i; a; j; b) = 1 indicates admissibility 2 Li b 2 Lj given
binary constraints.
number labels Lj compatible 2 Li .
(j; b) 2 [(i; j ); a] means 2 Li b 2 Lj simultaneously
admissible. implies supports b.
M[(i; j ); a] = 1 indicates label admissible (and
already eliminated from) segments containing j .
queue arc support deleted.
G set node pairs (i; j ) exists directed
edge j .
Next-Edgei contains node pairs (i; j ) exists
directed edge (i; j ) 2 G. also contains (i; end) last node
segment.
Prev-Edgei contains node pairs (j; i) exists
directed edge (j; i) 2 G. also contains (start; i) first node
segment.
set elements (i; j ) (j; i) 2 Prev-Edgei , j 6= start,
must compatible least one j 's labels.
Local-Prev-Support(i; a) becomes empty, longer admissible.
set elements (i; j ) (i; j ) 2 Next-Edgei , j 6= end,
must compatible least one j 's labels.
Local-Next-Support(i; a) becomes empty, longer admissible.
(i; k) 2 Prev-Support[(i; j ); a] implies (k; j ) 2 Prev-Edgej ,
k 6= start, 2 Li compatible least one j 's
one k's labels. Prev-Support[(i; j ); a] becomes empty,
longer admissible segments containing j .
(i; k) 2 Next-Support[(i; j ); a] implies (j; k) 2 Next-Edgej ,
k 6= end, 2 Li compatible least one j 's
one k's labels. Next-Support[(i; j ); a] becomes empty,
longer admissible segments containing j .
R

Figure 19: Data structures notation MUSE AC-1.

260

fiMUSE CSP: Extension Constraint Satisfaction Problem

n

j




k
{...,a,...}

LocalPrevSupport(i,a) = {(i,n),(i,m)}
LocalNextSupport(i,a) = {(i,j)}

Figure 20: Local-Prev-Support Local-Next-Support example DAG. sets indicate label allowed every segment contains n, m, j ,
disallowed every segment contains k. solid directed lines
members G, solid undirected lines represent members E .

i, label remain Li, must also compatible least one label either
Ln Lm .
order track dependency, two sets maintained label node i,
Local-Next-Support(i; a) Local-Prev-Support(i; a). Local-Next-Support(i; a) set
ordered node pairs (i; j ) (i; j ) 2 Next-Edgei , (i; j ) 2 E , least one
label b 2 Lj compatible a. Local-Prev-Support(i; a) set ordered pairs
(i; j ) (j; i) 2 Prev-Edgei , (i; j ) 2 E , least one label b 2 Lj
compatible a. Dummy ordered pairs also created handle cases node
beginning end network: (start; i) 2 Prev-Edgei , (i; start) added
Local-Prev-Support(i; a), (i; end) 2 Next-Edgei , (i; end) added Local-NextSupport(i; a). prevent label ruled nodes precede
follow DAG. Whenever one i's adjacent nodes, j , longer labels b
domain compatible a, (i; j ) removed Local-PrevSupport(i; a) Local-Next-Support(i; a), depending whether edge j
j , respectively. either Local-Prev-Support(i; a) Local-Next-Support(i; a)
becomes empty, longer part MUSE arc consistent instance,
eliminated Li . Figure 20, label admissible segments containing
j , segments containing k. constraints,
labels j become inconsistent i, (i; j ) would eliminated Local-NextSupport(a; i), leaving empty set. case, would longer supported

segment.
algorithm utilize similar conditions nodes directly connected
Next-Edgei Prev-Edgei . Consider Figure 21. Suppose label node
compatible label Lj , incompatible labels Lx Ly ,
reasonable eliminate segments containing j , segments
would include either node x . determine whether label admissible
set segments containing j , calculate Prev-Support[(i; j ); a] NextSupport[(i; j ); a] sets. Next-Support[(i; j ); a] includes (i; k) arcs support
261

fiHelzerman & Harper

z
{...,a,...}

x
j

w



Figure 21: Next-Edgej = f(j; x); (j; )g; Counter[(i; x); a] = 0, Counter[(i; ); a] = 0,
inadmissible every segment containing j . solid directed lines members G, solid undirected lines represent members
E .
given directed edge j k, (i; j ) supports a. Prev-Support[(i; j ); a]
includes (i; k) arcs support given directed edge k
j , (i; j ) supports a. Note Prev-Support[(i; j ); a] contain ordered pair
(i; j ) (i; j ) 2 Prev-Edgej , Next-Support[(i; j ); a] contain ordered pair (i; j )
(j; i) 2 Next-Edgej . elements included edge nodes
j sucient allow j 's labels support segment containing j . Dummy
ordered pairs also created handle cases node beginning end
network: (start; j ) 2 Prev-Edgej , (i; start) added Prev-Support[(i; j ); a],
(j; end) 2 Next-Edgej , (i; end) added Next-Support[(i; j ); a]. prevent
label ruled nodes precede follow DAG.
Figure 22 shows Prev-Support, Next-Support, Local-Next-Support, Local-PrevSupport sets initialization algorithm creates simple example DAG.
initialization step, sets contain node pairs allowed based connectivity G. Later, consistency step node pairs support
associated label eliminated set.
illustrate data structures used second step MUSE AC-1 shown
Figure 23, consider happens initially [(1; 3); a] 2 List MUSE CSP depicted
Figure 22. [(1; 3); a] placed List indicate label L1 supported
labels associated node 3. value popped List, necessary
(3; x) 2 S[(1; 3); a] decrement Counter[(3; 1); x] one. Counter[(3; 1); x]
becomes 0, [(3; 1); x] already placed List, added future
processing. done, necessary remove [(1; 3); a]'s uence MUSE
DAG. handle this, examine two sets Prev-Support[(1; 3); a] = f(1; 2); (1; 3)g
262

fiMUSE CSP: Extension Constraint Satisfaction Problem

1.
2.
3.
4.
5.
6.
7.
8.
9.
10.
11.
12.
13.
14.
15.
16.
17.
18.
19.
20.
21.
22.
23.

List := ;
E := f(i; j )j9 2 : i; j 2 ^ 6= j ^ i; j 2 N g;
(i; j) 2 E
2 Li f
S[(i; j ); a] := ;
M[(i; j ); a] := 0;
Local-Prev-Support(i; a) := ; Local-Next-Support(i; a) := ;
Prev-Support[(i; j ); a] := ; Next-Support[(i; j ); a] := ; g
(i; j) 2 E
2 Li f

Total := 0;

b 2 Lj
R2 (i; a; j; b) f

Total := Total+1;
S[(j; i); b] := S[(j; i); b] [ f(i; a)g; g
Total=0 f
List := List [ f[(i; j ); a]g;
M[(i; j ); a] := 1; g
Counter[(i; j ); a] := Total;
Prev-Support[(i; j ); a] := f(i; x)j(i; x) 2 E ^ (x; j ) 2 Prev-Edgej g
[ f(i; j )j(i; j ) 2 Prev-Edgej g
[ f(i; start)j(start; j ) 2 Prev-Edgej g;
Next-Support[(i; j ); a] := f(i; x)j(i; x) 2 E ^ (j; x) 2 Next-Edgej g
[ f(i; j )j(j; i) 2 Next-Edgej g
[ f(i; end)j(j; end) 2 Next-Edgej g;
Local-Prev-Support(i; a) := f(i; x)j(i; x) 2 E ^ (x; i) 2 Prev-Edgei g
[ f(i; start)j(start; i) 2 Prev-Edgei g;
Local-Next-Support(i; a) := f(i; x)j(i; x) 2 E ^ (i; x) 2 Next-Edgei g
[ f(i; end)j(i; end) 2 Next-Edgei g; g
{c}

2

start

1

3

{a,b}

end
{d}

Prev-Support[(1; 2);a] = f(1; 2)g
Prev-Support[(1; 3);a] = f(1; 2); (1; 3)g
Prev-Support[(1; 2);b] = f(1; 2)g
Prev-Support[(1; 3);b] = f(1; 2); (1; 3)g
Prev-Support[(2; 1);c] = f(2; start)g
Prev-Support[(2; 3);c] = f(2; 3); (2; 1)g
Prev-Support[(3; 1);d] = f(3; start)g
Prev-Support[(3; 2);d] = f(3; 1)g
Local-Prev-Support(1;a) = f(1; start)g
Local-Prev-Support(1;b) = f(1; start)g
Local-Prev-Support(2;c) = f(2; 1)g
Local-Prev-Support(3;d) = f(3; 1); (3; 2)g

Next-Support[(1; 2);a] = f(1; 3)g
Next-Support[(1; 3);a] = f(1; end)g
Next-Support[(1; 2);b] = f(1; 3)g
Next-Support[(1; 3);b] = f(1; end)g
Next-Support[(2; 1);c] = f(2; 1); (2; 3)g
Next-Support[(2; 3);c] = f(2; end)g
Next-Support[(3; 1);d] = f(3; 1); (3; 2)g
Next-Support[(3; 2);d] = f(3; 2)g
Local-Next-Support(1;a) = f(1; 2); (1; 3)g
Local-Next-Support(1;b) = f(1; 2); (1; 3)g
Local-Next-Support(2;c) = f(2; 3)g
Local-Next-Support(3;d) = f(3; end)g

Figure 22: Initialization data structures MUSE AC-1 along simple example.
263

fiHelzerman & Harper

1. List 6= f
2.
Pop [(i; j ); a] List;
3.
(j; b) 2 S[(i; j ); a] f
4.
Counter[(j; i); b] := Counter[(j; i); b] , 1;
5.
Counter[(j; i); b] = 0 ^ M[(j; i); b] = 0 f
6.
List := List [ f[(j; i); b]g;
7.
M[(j; i); b] := 1; g g
8.
Update-Support-Sets([(i; j ); a]); (see Figure 24) g

Figure 23: Eliminating inconsistent labels domains MUSE AC-1.
Update-Support-Sets ([(i; j ); a]) f
1. (i; x) 2 Prev-Support[(i; j ); a] ^ x 6= j ^ x 6= start f
2.
Prev-Support[(i; j ); a] := Prev-Support[(i; j ); a] , f(i; x)g ;
3.
Next-Support[(i; x); a] := Next-Support[(i; x); a] , f(i; j )g;
4.
Next-Support[(i; x); a] = ^ M[(i; x); a] = 0 f
5.
List := List [ f[(i; x); a]g;
6.
M[(i; x); a] := 1; g g
7. (i; x) 2 Next-Support[(i; j ); a] ^ x 6= j ^ x 6= end f
8.
Next-Support[(i; j ); a] := Next-Support[(i; j ); a] , f(i; x)g;
9.
Prev-Support[(i; x); a] := Prev-Support[(i; x); a] , f(i; j )g;
10.
Prev-Support[(i; x); a] = ^ M[(i; x); a] = 0 f
11.
List := List [ f[(i; x); a]g;
12.
M[(i; x); a] := 1; g g
13. (j; i) 2 Prev-Edgei
14. Local-Prev-Support(i; a) := Local-Prev-Support(i; a) , f(i; j )g;
15. Local-Prev-Support(i; a) = f
16. Li := Li , fag;
17. (i; x) 2 Local-Next-Support(i; a) ^ x 6= j ^ x 6= end f
18.
Local-Next-Support(i; a) := Local-Next-Support(i; a) , f(i; x)g;
19.
M[(i; x); a] = 0 f
20.
List := List [ f[(i; x); a]g;
21.
M[(i; x); a] := 1; g g g
22. (i; j ) 2 Next-Edgei
23. Local-Next-Support(i; a) := Local-Next-Support(i; a) , f(i; j )g;
24. Local-Next-Support(i; a) = f
25. Li := Li , fag;
26. (i; x) 2 Local-Prev-Support(i; a) ^ x 6= j ^ x 6= start f
27.
Local-Prev-Support(i; a) := Local-Prev-Support(i; a) , f(i; x)g;
28.
M[(i; x); a] = 0 f
29.
List := List [ f[(i; x); a]g;
30.
M[(i; x); a] := 1; g g g g

Figure 24: function Update-Support-Sets([(i; j ); a]) MUSE AC-1.
264

fiMUSE CSP: Extension Constraint Satisfaction Problem

Next-Support[(1; 3); a] = f(1; end)g. Note value (1; end) Next-Support[(1; 3); a]
value (1; 3) Prev-Support[(1; 3); a], require action
dummy values. However, value (1; 2) Prev-Support[(1; 3); a] indicates (1; 3)
member Next-Support[(1; 2); a], since admissible (1; 3), (1; 3)
removed Next-Support[(1; 2); a], leaving empty set. Note NextSupport[(1; 2); a] empty, assuming M[(1; 2); a] = 0, [(1; 2); a] added List
processing. Next, (1; 3) removed Local-Next-Support(1; a), leaving set
f(1; 2)g. next iteration loop [(1; 2); a] popped List.
Prev-Support[(1; 2); a] Next-Support[(1; 2); a] processed, Next-Support[(1; 2); a] =
Prev-Support[(1; 2); a] contains dummy, requiring action. Finally, (1; 2)
removed Local-Next-Support(1; a), set becomes empty, longer compatible segment containing node 1 eliminated consideration
possible label node 1. eliminated node 1, also necessary remove
support 2 L1 labels nodes precede node 1, nodes x
(1; x) 2 Local-Prev-Support(1; a). Since Local-Prev-Support(1; a) = f(1; start)g,
start dummy node, work done.
contrast, consider happens initially [(1; 2); a] 2 List MUSE CSP
Figure 22. case, Prev-Support[(1; 2); a] contains (1; 2) requires additional
work; whereas, Next-Support[(1; 2); a] contains (1; 3), indicating (1; 2) must removed
Prev-Support[(1; 3); a]'s set. removal, Prev-Support[(1; 3); a] non-empty,
segment containing nodes 1 3 still supports label L1. reason
two cases provide different results constraint arc nodes 1 3
contained every segment; whereas, constraint arc nodes 1 2 found
one them.

3.3 Running Time Space Complexity MUSE AC-1
worst-case running time routine initialize MUSE AC-1 data structures
(in Figure 22) O(n2 l2 + n3 l), n number nodes MUSE CSP l
number labels. Given number (i; j ) elements E O(n2 )
domain size O(l), size Counter arrays O(n2 l). determine
number supporters given arc-label pair requires O(l) work; hence, initializing
Counter arrays requires O(n2 l2) time. However, O(n2 l) Prev-Support
Next-Support sets, Prev-Support[(i; j ); a] Next-Support[(i; j ); a] requires
O(n) time compute, time calculate Prev-Support Next-Support sets
O(n3 l). Finally, time needed calculate Local-Next-Support Local-PrevSupport sets O(n2 l) O(nl) sets O(n) elements per set.
worst-case running time algorithm prunes labels MUSE
arc consistent (in Figures 23 24) also operates O(n2 l2 + n3 l) time. Clearly
Counter array contains O(n2 l) entries (a similar argument made array)
keep track algorithm. Counter[(i; j ); a] l magnitude,
never become negative, maximum running time line 4 Figure 23
(given elements appear List M) O(n2 l2).
O(n2 l) Next-Support Prev-Support lists, O(n) size, maximum
running time required lines 3 9 Figure 24 O(n3 l). Finally, since O(nl)
265

fiHelzerman & Harper

Approach
CSPs
MUSE CSP

Nodes
Degree
Number
Number
per Path Node splitting Constraint Networks Nodes

n
n

kn

k
k

1

n
kn

Asymptotic
Time

kn n2 l2
2
(kn) l2 + (kn)3 l

Table 1: Comparison space time complexity MUSE arc consistency
MUSE CSP arc consistency multiple CSPs representing node splitting
problem (e.g., lexical ambiguity parsing).
Local-Prev-Support Local-Next-Support sets eliminate O(n) elements,
maximum running time lines 14 23 Figure 24 O(n2 l). Hence, maximum
running time MUSE CSP arc consistency algorithm O(n2 l2 + n3 l).
space complexity MUSE CSP AC-1 also O(n2 l2 + n3 l) arrays
Counter contain O(n2 l) elements, O(n2 l) sets, containing O(l)
items; O(n2 l) Prev-Support Next-Support sets, containing O(n) items; O(nl)
Local-Next-Support Local-Prev-Support sets, containing O(n) items.
comparison, worst-case running time space complexity CSP arc consistency O(n2 l2), assuming n2 constraint arcs. Note applications
l = n, worst-case running times algorithms order (this
true parsing spoken language MUSE CSP). Also, representable planar
DAG (in terms Prev-Edge Next-Edge, E), running times two
algorithms order average number values Prev-Support
Next-Support would constant. hand, compare MUSE CSP
use multiple CSPs problems k alternative variables particular
variable CSP, MUSE CSP AC-1 asymptotically attractive, shown
Table 1.

3.4 Correctness MUSE AC-1

Next prove correctness MUSE AC-1.
Theorem 1 label eliminated Li MUSE AC-1 label
unsupported arcs (i; x) every segment.

Proof:
1. must show label eliminated, inadmissible every segment.
label eliminated domain MUSE AC-1 (see lines 16 25 Figure 24)
Local-Prev-Support set Local-Next-Support set becomes empty
(see lines 15 24 Figure 24). either case, label eliminated
make MUSE CSP instance MUSE arc consistent. prove label's
local support sets become empty, label cannot participate MUSE arc
consistent instance MUSE CSP. proven Local-Next-Support (LocalPrev-Support follows symmetry.) Observe 2 Li , unsupported
266

fiMUSE CSP: Extension Constraint Satisfaction Problem

nodes immediately follow DAG, cannot participate
MUSE arc consistent instance MUSE CSP. line 23 Figure 24, (i; j )
removed Local-Next-Support(i; a) set [(i; j ); a] must popped
List. removal (i; j ) Local-Next-Support(i; a) indicates that,
segment containing j , 2 Li inadmissible. remains shown
[(i; j ); a] put List 2 Li unsupported every segment contains
j . proven induction number iterations loop
Figure 23.
Base case: initialization routine puts [(i; j ); a] List 2 Li incompatible every label Lj (line 17 Figure 22). Therefore, 2 Li unsupported
segments containing j .
Induction step: Assume start kth iteration loop
[(x; ); c] ever put List indicate c 2 Lx inadmissible
every segment contains x . remains show kth
iteration, [(i; j ); a] put List, 2 Li unsupported every segment
contains j . several ways new [(i; j ); a] put
List:
(a) labels Lj compatible 2 Li eliminated.
item could placed List either initialization (see line 17
Figure 22) previous iteration loop (see line 6 Figure
23)), CSP AC-4 algorithm. obvious that, case, 2 Li
inadmissible every segment containing j .
(b) Prev-Support[(i; j ); a] = (see line 10 Figure 24) indicating 2 Li
incompatible nodes k (k; j ) 2 Prev-Edgej . way
[(i; j ); a] placed List reason (at line 11) tuples
form [(i; k); a] (where (k; j ) 2 Prev-Edgej ) already put List.
induction hypothesis, [(i; k); a] items placed List
2 Li inadmissible segments containing k DAG.
supported node immediately precedes j DAG,
unsupported every segment contains j . Therefore, correct
put [(i; j ); a] List.
(c) Next-Support[(i; j ); a] = (see line 4 Figure 24) indicating 2 Li
incompatible nodes k (j; k) 2 Next-Edgej . way [(i; j ); a]
placed List (at line 5) reason tuples form
[(i; k); a] (where (j; k) 2 Next-Edgej ) already put List. induction
hypothesis, [(i; k); a] items placed List 2 Li inadmissible segments containing k DAG. supported
node immediately follows j DAG, inadmissible
every segment contains j . Therefore, correct put [(i; j ); a] List.
(d) Local-Next-Support(i; a) = (see line 24 Figure 24) indicating 2 Li
incompatible nodes k (i; k) 2 Next-Edgei . way
[(i; j ); a] placed List (at line 29) reason node
follows DAG supports a, pairs (i; k) legally removed
267

fiHelzerman & Harper





1

...

1

...

c

...

b

...

Local_Prev_Support(i,a) = {(i,j),...}
Local_Next_Support(i,a) = {(i,k},...}

j



k

{b,...}

Prev_Support[(i,j),a] nonempty
{c,...}

{a,...}
c

Prev_Support[(i,k),a] = {(i,k),...}

...

Next_Support[(i,k),a] nonempty

1

b

...

Next_Support[(i,j),a] = {(i,j),...}

1

Figure 25: 2 Li MUSE AC-1, must preceded node j followed
node k support a.
Local-Next-Support(i; a) previous iterations.
segment containing supports a, follows segment containing
j supports label.
(e) Local-Prev-Support(i; a) = (see line 15 Figure 24) indicating 2 Li
incompatible nodes k (k; i) 2 Prev-Edgei . way
[(i; j ); a] placed List (at line 20) reason node
precedes DAG supports a, pairs (i; k) legally
removed Local-Prev-Support(i; a) previous iterations.
segment containing supports a, follows segment containing
j supports label.
beginning (k + 1)th iteration loop, every [(x; ); c] List
implies c supported segment contains x . Therefore,
induction, true iterations loop Figure 23. Hence,
label's local support sets become empty, label cannot participate MUSE arc
consistent instance MUSE CSP.
2. must also show eliminated Li MUSE arc consistency
algorithm, must MUSE arc consistent. MUSE arc consistent,
must exist least one path start end goes node
nodes n path contain least one label compatible
2 Li . deleted MUSE AC-1, Local-Next-Support(i; a) 6=
Local-Prev-Support(i; a) 6= . Hence, must preceded followed least
one node supports 2 Li ; otherwise, would deleted. depicted
Figure 25, know must node j precedes that,
start, must contain least one label b supports a, NextSupport[(i; j ); a] Prev-Support[(i; j ); a] must non-empty. Similarly, must
node k follows that, end, must contain least one
label c supports a, Next-Support[(i; k); a] Prev-Support[(i; k); a] must
non-empty.
268

fiMUSE CSP: Extension Constraint Satisfaction Problem

show path DAG, must show path beginning
start reaches nodes along path support 2 Li ,
path beginning reaches end nodes along
path support 2 Li . show necessity path end
nodes along path support 2 Li given remains MUSE AC-1;
necessity path start shown similar way.
Base case: 2 Li MUSE AC-1, must exist least one node
follows i, say k, [(i; k); a] never placed List. Hence,
R2 (i; a; k; c) = 1 least one c 2 Lk Next-Support[(i; k); a] PrevSupport[(i; k); a] must non-empty.
Induction Step: Assume path n nodes follows supports
2 Li, none nodes end node. implies n
nodes contains least one label compatible Next-Support[(i; n); a]
Prev-Support[(i; n); a] must non-empty n nodes.
Next, show path length (n + 1) must also support 2 Li ; otherwise,
label would deleted MUSE AC-1. already noted
nth node path induction step, Next-Support[(i; n); a] must
non-empty; hence, must exist least one node, say n0 , follows nth
node path length n supports 2 Li . n0 end node,
case. n0 end, way (i; n0) member
Next-Support[(i; n); a] [(i; n0); a] placed List. hasn't,
R2 (i; a; n0; l) = 1 least one l 2 Ln Next-Support[(i; n0); a] PrevSupport[(i; n0); a] must non-empty. case, (i; n0) would
removed Next-Support[(i; n); a], n would longer support 2 Li .
Hence, 2 Li MUSE AC-1, must path nodes end
node n end node, R2 (i; a; n; l) = 1 least one l 2 Ln
Next-Support[(i; n); a] Prev-Support[(i; n); a] must non-empty. Hence
MUSE arc consistent.
0

2

theorem, may conclude MUSE AC-1 builds largest MUSE arc
consistent structure. MUSE arc consistency takes account segments,
single CSP selected MUSE CSP MUSE arc consistency enforced,
CSP arc consistency could eliminate additional labels.

3.5 Profile MUSE AC-1

Given fact MUSE AC-1 operates composite data structure, benefits
using algorithm high payoff individually processing CSPs. section 2.4,
provided several examples payoff obvious. gain insight factors
uencing effectiveness MUSE CSP, conducted experiment
randomly generate MUSE CSP instances two different graph topologies. tree
topology characterized two parameters: branching factor (how many nodes follow
non-leaf node tree) path length (how many nodes path
root node leaf node). lattice topology characteristic MUSE CSP
269

fiHelzerman & Harper

produced hidden-Markov-model-based spoken language recognition system
constraint-based parser. Lattices also characterized length
branching factor.
experiment, examined trees path length four branching
factor two three, lattices path length four branching factor
two three. initialized variable either 3 6 labels. randomly
generated constraints network, varying probability R2 (i; a; j; b) = 1
0.05 .95 steps 0.05. probability, 6 instances generated. lower
probability R2 (i; a; j; b) = 1, tighter constraints. Note probability
constraint two nodes understood probability constraint
two nodes given constraint allowed them. example, nodes
level tree topology different segments, constraints
cannot occur them.
results experiment displayed Figures 26 27. four
panels figure, four curves displayed. MUSE AC-1 appears curves
displaying average number labels remaining MUSE AC-1 applied instances
MUSE CSP probability constraint varies. curves labeled Solution
indicate average number labels remaining MUSE AC-1 used
solution. CSP AC associated curves display number labels remain
least one segment segment extracted MUSE CSP CSP
arc consistency applied. Unused indicates difference number labels
remain MUSE AC-1 number CSP arc consistent least one
segment.
topologies, probability R2 (i; a; j; b) = 1 low (e.g., .1) high
(e.g., .8), MUSE AC-1 tracks performance arc consistency performed
individual instances either topology. However, topology impact range
low high probabilities true. constraints randomly generated,
MUSE AC-1 performed, tree topology fewer remaining values lattice
topology CSP arc consistent. results suggest MUSE CSP AC-1 may
effective topologies others. However, tree topology
randomly generated constraints values two variables independent
probabilities generated. case lattice; pair variables
set randomly generated constraints, shared paths lattice.
Notice increasing number values domain seems impact
tree increasing branching factor, probably branching factor
increases, number independent nodes.
experiment show problem tightly constrained, MUSE AC-1
effectively used eliminate values unsupported constraints. Clearly,
case parsing problems presented section 2.4. small set syntactic
constraints effectively eliminates values never used parse sentence,
even lattice branching factor three arbitrarily long paths.
270

fiMUSE CSP: Extension Constraint Satisfaction Problem

a. Tree branching factor 2, path length 4, 3 labels per variable, 15 variables.

b. Tree branching factor 3, path length 4, 3 labels per variable, 90 variables.
3

Average number role values per role 3

Average number role values per role 3

3

2.5
MUSE AC1
2

CSP AC

1.5

Solution

1

0.5

2.5
MUSE AC1
2

CSP AC

1.5
Solution
1

0.5
Unused

Unused
0
0

0.1

0.2

0.3

0.4
0.5
0.6
0.7
Probability R2(i,a,j,b)=1

0.8

0.9

0
0

1

c. Tree branching factor 2, path length 4, 6 labels per variable, 15 variables.

0.2

0.3

0.8

0.9

1

Average number role values per role 6

6

5
MUSE AC1
4

CSP AC
3

2
Solution
1

5

4

MUSE AC1
CSP AC

3

Solution

2

1

Unused
0
0

0.4
0.5
0.6
0.7
Probability R2(i,a,j,b)=1

d. Tree branching factor 3, path length 4, 6 labels per variable, 90 variables.

6

Average number role values per role 6

0.1

0.1

0.2

0.3

0.4
0.5
0.6
0.7
Probability R2(i,a,j,b)=1

Unused
0.8

0.9

0
0

1

0.1

0.2

0.3

0.4
0.5
0.6
0.7
Probability R2(i,a,j,b)=1

0.8

0.9

1

Figure 26: Simulation results trees path length 4, branching factor 2
3, 3 6 labels per variable.

271

fiHelzerman & Harper

a. Lattice branching factor 2, path length 4, 3 labels per variable, 8 variables.

b. Lattice branching factor 3, path length 4, 3 labels per variable, 12 variables.

3

3
MUSE AC1

Average number role values per role 3

Average number role values per role 3

CSP AC
MUSE AC1

2.5

2
Solution
1.5

1

0.5
Unused

0
0

0.1

0.2

0.3

0.4
0.5
0.6
0.7
Probability R2(i,a,j,b)=1

0.8

0.9

2

Solution

1.5

1

Unused
0.5

0
0

1

c. Lattice branching factor 2, path length 4, 6 labels per variable, 8 variables.

0.1

0.2

0.3

0.4
0.5
0.6
0.7
Probability R2(i,a,j,b)=1

0.8

0.9

1

d. Lattice branching factor 3, path length 4, 6 labels per variable, 12 variables.

6

6
MUSE AC1

MUSE AC1

Average number role values per role 6

Average number role values per role 6

CSP AC

2.5

CSP AC

5

4
Solution
3

2

1

5
CSP AC

4
Solution
3

2

Unused

1

Unused
0
0

0.1

0.2

0.3

0.4
0.5
0.6
0.7
Probability R2(i,a,j,b)=1

0.8

0.9

0
0

1

0.1

0.2

0.3

0.4
0.5
0.6
0.7
Probability R2(i,a,j,b)=1

0.8

0.9

1

Figure 27: Simulation results lattices path length 4, branching factor 2
3, 3 6 labels per variable.

272

fiMUSE CSP: Extension Constraint Satisfaction Problem

Local-Next-Support(B, b1) = {(B, E)}
Local-Next-Support(B, b2) = {(B, C), (B, E)}
Local-Next-Support(B, b3) = {(B, C)}

Next-Support[(B, C), b3] = {(B, D)}
Next-Support[(B, C), b2] = {(B, F)}

C
{c1}

start


{a1}


{d1}

B

end

{b1, b2, b3}
{e1}

{f1}

E

F

Figure 28: Using MUSE arc consistency data structures guide backtracking search.

3.6 Extracting Solutions MUSE CSP MUSE AC-1
Solutions regular CSP problems typically generated using backtracking (or fancier
search algorithms) assemble set labels, one node, consistently
admissible. Extracting solutions MUSE CSPs done similar way,
desirable make modifications search algorithms take advantage
extra information contained MUSE AC-1 data structures.
Consider example shown Figure 28. figure presents simple MUSE CSP.
Suppose interested solutions segment highlighted: fA, B, C,
Dg. Suppose also one solution segment: a1 A, b3 B, c1
C, d1 D. wish find solution depth-first search.
begin assigning a1 A. However, domain B, addition desired
label b3, also contains labels b1 b2, valid segments.
initially (and naively) choose b1 B continue depth-first search, would
waste lot time backtracking. Fortunately, enforcing MUSE arc consistency,
MUSE data structures contain useful information concerning segments
labels valid. case, backtracking algorithm check Local-Next-Support(B,
b1) determine outgoing nodes b1 compatible with. Since (B, C)
element Local-Next-Support(B, b1), smart search algorithm would choose b1
label B.
However, looking local support sets might enough. search
algorithm rejected b1 label B, would go consider b2. Local-NextSupport(B, b2) indicates b2 valid label segments contain
C, fails tell us b2 valid segment examining. Despite
this, search algorithm still eliminate b2 looking Next-Support[(B, C), b2],
indicates b2 compatible segments containing node F. Clearly,
type information effectively guide search solution along certain
path. Improved search strategies MUSE CSPs focus future research efforts.
273

fiHelzerman & Harper

4. MUSE CSP Path Consistency Algorithm
section, introduce algorithm achieve MUSE CSP path consistency, MUSE
PC-1, builds upon PC-4 algorithm (Han & Lee, 1988).

4.1 MUSE PC-1

MUSE path consistency enforced setting R2 (i; a; j; b) false violates
conditions Definition 9. MUSE PC-1 builds maintains several data structures comparable data structures defined MUSE AC-1, described Figure 29, allow
eciently perform operation. Figure 32 shows code initializing data structures, Figures 33 34 contain algorithm eliminating MUSE path inconsistent
binary constraints.
MUSE PC-1 must keep track labels Lk support R2 (i; a; j; b). keep track
much path support R2 (i; a; j; b) has, number labels Lk satisfy
R2 (i; a; k; c) R2 (k; c; j; b) counted using Counter[(i; j ); k; a; b]. Additionally,
algorithm must keep track set S[(i; j ); k; a; b], contains members form
(k; c) R2 (i; a; k; c) R2 (k; c; j; b) supported R2 (i; a; j; b). R2 (i; a; j; b)
ever becomes false segment containing i, j , k, R2 (i; a; k; c) R2 (k; c; j; b)
loose support. MUSE PC-1 also uses Local-Next-Support, Local-PrevSupport, Prev-Support, Next-Support sets similar MUSE AC-1.
MUSE PC-1 able use properties DAG identify local (and hence
eciently computable) conditions binary constraints fail lack path
support. Consider Figure 30, shows nodes adjacent node j
DAG. every segment DAG contains node j represented
directed path DAG going node node j , node must precede
follow nodes j R2 (i; a; j; b) hold. order track dependency, two sets
maintained [(i; j ); a; b] tuple: Local-Prev-Support[(i; j ); a; b] Local-NextSupport[(i; j ); a; b]. Note distinguish Local-Prev-Support[(i; j ); a; b] LocalPrev-Support[(j; i); b; a] separately keep track elements directly preceding
directly preceding j . also distinguish Local-Next-Support[(i; j ); a; b] LocalNext-Support[(j; i); b; a]. sets become empty, (i; j ) arc
longer support R2 (i; a; j; b). Local-Prev-Support[(i; j ); a; b] set ordered node pairs
(i; x) (x; i) 2 Prev-Edgei , (i; x) 2 E , least one label 2 Lx
compatible R2 (i; a; j; b). Local-Next-Support[(i; j ); a; b] set ordered
node pairs (i; x) (i; x) 2 Next-Edgei , (i; x) 2 E , least one label
2 Lx compatible R2 (i; a; j; b). Dummy ordered pairs also created
handle cases node beginning end network: (start; i) 2 PrevEdgei , (i; start) added Local-Prev-Support[(i; j ); a; b], (i; end) 2 Next-Edgei ,
(i; end) added Local-Next-support[(i; j ); a; b].
algorithm utilize similar conditions nodes may directly connected j . Consider Figure 31. Suppose R2 (i; a; j; b) compatible
label Lk , incompatible labels Lx Ly , R2 (i; a; j; b)
R2 (j; b; i; a) false segments containing i, j , k segments would
include either node x . determine whether constraint admissible
set segments containing i, j , k, calculate Prev-Support[(i; j ); k; a; b], Prev274

fiMUSE CSP: Extension Constraint Satisfaction Problem

Notation

Meaning
ordered pair nodes.

(i; j )

node pairs (i; j ) exists path directed edges G
j . (i; j ) 2 E , (j; i) 2 E .
ordered quadruple node pair (i; j ), node k, labels
2 Li b 2 Lj .

E

[(i; j ); k; a; b]

faja 2 L (i; a) permitted constraints (i.e., admissible)g

Li

2 (i; a; j; b) = 1 indicates admissibility 2 Li b 2 Lj given
binary constraints.

2 (i; a; j; b)

R

R

Counter[(i; j ); k; a; b]
S[(i; j ); k; a; b]
M[(i; j ); k; a; b]
List

G

Next-Edgei
Prev-Edgei
Local-Prev-Support[(i; j ); a; b]
Local-Next-Support[(i; j ); a; b]
Prev-Support[(i; j ); k; a; b]
Next-Support[(i; j ); k; a; b]

number labels Lk compatible R2 (i; a; j; b).
(k; c) 2 [(i; j ); k; a; b] means c 2 Lk compatible
R2 (i; a; j; b).
M[(i; j ); k; a; b] = 1 indicates R2 (i; a; j; b) false paths
including i, j , k.
queue path support deleted.
G set node pairs (i; j ) exists directed
edge j .
Next-Edgei contains node pairs (i; j ) exists
directed edge (i; j ) 2 G. also contains (i; end) last
node segment.
Prev-Edgei contains node pairs (j; i) exists
directed edge (j; i) 2 G. also contains (start; i) first
node segment.
set elements (i; k) (k; i) 2 Prev-Edgei , k 6= start,
R2 (i; a; j; b) must compatible one k 's labels.
Local-Prev-Support[(i; j ); a; b] becomes empty, R2 (i; a; j; b) becomes false.
set elements (i; k) (i; k) 2 Next-Edgei , k 6= end,
R2 (i; a; j; b) must compatible one k 's labels.
Local-Next-Support[(i; j ); a; b] becomes empty, R2 (i; a; j; b) becomes false.
(i; x) 2 Prev-Support[(i; j ); k; a; b] implies (x; k) 2 Prev-Edgek ,
x 6= start, R2 (i; a; j; b) compatible least one k's
one x's labels. Prev-Support[(i; j ); k; a; b] becomes empty,
R2 (i; a; j; b) longer true segments containing i, j , k .
(i; x) 2 Next-Support[(i; j ); k; a; b] means (k; x) 2 Next-Edgek ,
x 6= end, R2 (i; a; j; b) compatible least one k's
one x's labels. Next-Support[(i; j ); k; a; b] becomes empty,
R2 (i; a; j; b) longer true segments containing i, j , k .

Figure 29: Data structures notation MUSE PC-1.

275

fiHelzerman & Harper

l

{...,a,...} n






p

r
j

q

{...,b,...}



LocalPrevSupport[(i,j), a, b] = {(i,l), (i,m)}
LocalPrevSupport[(j,i), b, a] = {(j,p), (j,q)}
LocalNextSupport[(i,j), a, b] = {(i,n), (i,o)}
LocalNextSupport[(j,i), b, a] = {(j,r), (j,s)}

Figure 30: Local-Prev-Support Local-Next-Support path consistency example DAG. solid directed lines members G, solid undirected
line represents (i; j ) (j; i) members E .
Support[(j; i); k; b; a], Next-Support[(i; j ); k; a; b], Next-Support[(j; i); k; b; a] sets. NextSupport[(i; j ); k; a; b] includes (i; x) arcs support R2 (i; a; j; b) given
directed edge k x, R2 (i; a; j; b) = 1, R2 (i; a; k; c) = 1, R2 (k; c; j; b) = 1 (NextSupport[(j; i); k; b; a] defined similarly). Prev-Support[(i; j ); k; a; b] includes (i; x) arcs
support R2 (i; a; j; b) given directed edge x k, R2 (i; a; j; b) = 1,
R2 (i; a; k; c) = 1, R2 (k; c; j; b) = 1 (Prev-Support[(j; i); k; b; a] defined similarly).
Note Prev-Support[(i; j ); k; a; b] contain ordered pair (i; k) (i; k) 2 PrevEdgek , (i; j ) (j; k) 2 Prev-Edgek . Next-Support[(i; j ); k; a; b] contain ordered
pair (i; k) (k; i) 2 Next-Edgek (i; j ) (k; j ) 2 Next-Edgek . elements included edge nodes sucient allow support. Dummy
ordered pairs also created handle cases node beginning end
network: (start; k) 2 Prev-Edgek , (i; start) added Prev-Support[(i; j ); k; a; b],
(k; end) 2 Next-Edgek , (i; end) added Next-Support[(i; j ); k; a; b].

4.2 Running Time, Space Complexity, Correctness MUSE PC-1
worst-case running time routine initialize MUSE PC-1 data structures (in
Figure 32) O(n3 l3 + n4 l2), n number nodes MUSE CSP l
number labels. Given number (i; j ) elements E O(n2 ) domain size
O(l), O(n3 l2) entries Counter array determine number
supporters, requiring O(l) work; hence, initializing Counter array requires O(n3 l3)
time. Additionally, O(n3 l2) sets determine, O(l) values,
time required initialize O(n3 l3). Determining Prev-Support[(i; j ); k; a; b]
276

fiMUSE CSP: Extension Constraint Satisfaction Problem

z

x
{...,c,...}

{...,a,...}



k
w

j {...,b,...}


Figure 31: found Next-Edgek = f(k; x); (k; )g; Counter[(i; j ); x; a; b] =
0; Counter[(i; j ); y; a; b] = 0, R2 (i; a; j; b) ruled every segment containing i, j , k. solid directed lines members G,
solid undirected lines represent members E .

277

fiHelzerman & Harper

1.
2.
3.
4.
5.
6.
7.
8.
9.
10.
11.
12.
13.
14.
15.
16.
17.
18.
19.
20.
21.
22.
23.
24.
25.
26.
27.

List := ;
E := f(i; j )j9 2 : i; j 2 ^ 6= j ^ i; j 2 N g;
(i; j) 2 E
2 Li
b 2 Lj f
Local-Prev-Support[(i; j ); a; b] := ; Local-Next-Support[(i; j ); a; b] := ;
k 2 N (i; k) 2 E ^ (j; k) 2 E f
S[(i; j ); k; a; b] := ;
M[(i; j ); k; a; b] := 0;
Prev-Support[(i; j ); k; a; b] := ; Next-Support[(i; j ); k; a; b] := ; g g
(i; j) 2 E
2 Li
b 2 Lj R2 (i; a; j; b) f
k 2 N (i; k) 2 E ^ (j; k) 2 E f

Total := 0;

c 2 Lk
R2 (i; a; k; c) R2 (k; c; j; b) f

Total := Total+1;
S[(i; k); j; a; c] := S[(i; k); j; a; c] [ f(j; b)g; g
Total = 0 f
List := List [ f[(i; j ); k; a; b]g;
M[(i; j ); k; a; b] := 1; g
Counter[(i; j ); k; a; b] := Total;
Prev-Support[(i; j ); k; a; b] :=
f(i; x)j(i; x) 2 E ^ (x = j _ (j; x) 2 E ) ^ (x; k) 2 Prev-Edgek g
[ f(i; k)j(i; k) 2 Prev-Edgek g
[ f(i; start)j(start; k) 2 Prev-Edgek g;
Next-Support[(i; j ); k; a; b] :=
f(i; x)j(i; x) 2 E ^ (x = j _ (j; x) 2 E ) ^ (k; x) 2 Next-Edgek g
[ f(i; k)j(k; i) 2 Next-Edgek g
[ f(i; end)j(k; end) 2 Next-Edgek g; g
Local-Prev-Support[(i; j ); a; b] :=
f(i; x)j(i; x) 2 E ^ (x = j _ (j; x) 2 E ) ^ (x; i) 2 Prev-Edge ig
[ f(i; start)j(start; i) 2 Prev-Edgei g;
Local-Next-Support[(i; j ); a; b] :=
f(i; x)j(i; x) 2 E ^ (x = j _ (j; x) 2 E ) ^ (i; x) 2 Next-Edgei g
[ f(i; end)j(i; end) 2 Next-Edgeig; g

Figure 32: Initialization data structures MUSE PC-1.

278

fiMUSE CSP: Extension Constraint Satisfaction Problem

1. List 6=
2.
Pop [(i; j ); k; a; b] List;
3.
(k; c) 2 S[(i; j ); k; a; b] f
4.
Counter[(i; k); j; a; c] := Counter[(i; k); j; a; c] , 1;
5.
Counter[(k; i); j; c; a] := Counter[(k; i); j; c; a] , 1;
6.
Counter[(i; k); j; a; c] = 0 ^ M[(i; k); j; a; c] = 0 f
7.
List := List [ f[(i; k); j; a; c]; [(k; i); j; c; a]g;
8.
M[(i; k); j; a; c] := 1; M[(k; i); j; c; a] := 1; g g
9.
Update-Support-Sets([(i; j ); k; a; b]); (see Figure 34) g

Figure 33: Eliminating inconsistent binary constraints MUSE PC-1.
Update-Support-Sets ([(i; j ); k; a; b])f
1. (i; x) 2 Prev-Support[(i; j ); k; a; b] ^ x 6= j ^ x 6= k ^ x 6= start f
2.
Prev-Support[(i; j ); k; a; b] := Prev-Support[(i; j ); k; a; b] , f(i; x)g;
3.
Next-Support[(i; j ); x; a; b] := Next-Support[(i; j ); x; a; b] , f(i; k)g;
4.
Next-Support[(i; j); x; a; b] = ^ M[(i; j ); x; a; b] = 0 f
5.
List := List [ f[(i; j ); x; a; b]; [(j; i); x; b; a]g;
6.
M[(i; j ); x; a; b] := 1; M[(j; i); x; b; a] := 1; g g
7. (i; x) 2 Next-Support[(i; j ); k; a; b] ^ x 6= j ^ x 6= k ^ x 6= end f
8.
Next-Support[(i; j ); k; a; b] := Next-Support[(i; j ); k; a; b] , f(i; x)g;
9.
Prev-Support[(i; j ); x; a; b] := Prev-Support[(i; j ); x; a; b] , f(i; k)g;
10.
Prev-Support[(i; j); x; a; b] = ^ M[(i; j ); x; a; b] = 0 f
11.
List := List [ f[(i; j ); x; a; b]; [(j; i); x; a; b]g;
12.
M[(i; j ); x; a; b] := 1; M[(j; i); x; b; a] := 1; g g
13. (k; i) 2 Prev-Edgei
14. Local-Prev-Support[(i; j ); a; b] := Local-Prev-Support[(i; j ); a; b] , f(i; k)g;
15. Local-Prev-Support[(i; j ); a; b] = f
16. R2 (i; a; j; b) := 0; R2 (j; b; i; a) := 0;
17. (i; x) 2 Local-Next-Support[(i; j ); a; b] ^ x 6= j ^ x 6= k ^ x 6= end f
18.
Local-Next-Support[(i; j ); a; b] := Local-Next-Support[(i; j ); a; b] , f(i; x)g;
19.
M[(i; j ); x; a; b] = 0 f
20.
List := List [ f[(i; j ); x; a; b]; [(j; i); x; b; a]g;
21.
M[(i; j ); x; a; b] := 1; M[(j; i); x; b; a] := 1; g g g
22. (i; k) 2 Next-Edgei
23. Local-Next-Support[(i; j ); a; b] := Local-Next-Support[(i; j ); a; b] , f(i; k)g;
24. Local-Next-Support[(i; j ); a; b] = f
25. R2 (i; a; j; b) := 0; R2 (j; b; i; a) := 0;
26. (i; x) 2 Local-Prev-Support[(i; j ); a; b] ^ x 6= j ^ x 6= k ^ x 6= start dof
27.
Local-Prev-Support[(i; j ); a; b] := Local-Prev-Support[(i; j ); a; b] , f(i; x)g;
28.
M[(i; j ); x; a; b] = 0 f
29.
List := List [ f[(i; j ); x; a; b]; [(j; i); x; b; a]g;
30.
M[(i; j ); x; a; b] := 1; M[(j; i); x; b; a] := 1; g g g g

Figure 34: function Update-Support-Sets([(i; j ); k; a; b]) MUSE PC-1.
279

fiHelzerman & Harper

Approach
CSPs
MUSE CSP

Nodes
Degree
Number
Number
per Path Node splitting Constraint Networks Nodes

n
n

kn

k
k

1

n
kn

Asymptotic
Time

knn3 l3
3
(kn) l3 + (kn)4 l2

Table 2: Comparison space time complexity MUSE path consistency
MUSE CSP path consistency multiple CSPs representing node splitting
problem (e.g., lexical ambiguity parsing).
Next-Support[(i; j ); k; a; b] requires O(n) time, time required calculate
Prev-Support Next-Support sets O(n4 l2). Finally, time needed calculate
Local-Next-Support Local-Prev-Support sets O(n3 l2) O(n2 l2) sets
O(n) elements per set.
worst-case running time algorithm enforces MUSE path consistency
(in Figures 33 34) also operates O(n3 l3 + n4 l2) time. Clearly O(n3 l2)
entries Counter array keep track algorithm. Counter[(i; j ); k; a; b]
l magnitude, never become negative, maximum running
time lines 4 5 Figure 33 (given elements, M, appear list
once) O(n3 l3). O(n3 l2) Prev-Support Next-Support lists,
O(n) size, maximum running time required eliminate O(n) elements
support sets O(n4 l2). Finally, since O(n2 l2) Local-Next-Support
Local-Prev-Support sets eliminate O(n) elements, worst-case time
eliminate items local sets O(n3 l2). Hence, worst-case running time
MUSE CSP path consistency algorithm O(n3 l3 + n4 l2).
space complexity MUSE CSP PC-1 also O(n3 l3 + n4 l2 ) arrays
Counter contain O(n3 l2) elements O(n3 l2) sets, containing
O(l) items; O(n3 l2) Prev-Support Next-Support sets, containing O(n) items;
O(n2 l2) Local-Next-Support Local-Prev-Support sets, containing O(n) items.
comparison, worst-case running time space complexity CSP path consistency, PC-4, O(n3 l3). Note applications representable planar DAG
l = n, worst-case running times algorithms order. compare
MUSE CSP use multiple CSPs problems k alternative variables
particular variable CSP, MUSE CSP path consistency asymptotically
attractive, shown Table 2.
proof correctness MUSE PC-1 similar proof MUSE AC-1,
brie outline proof here. binary constraint looses support MUSE
PC-1 (see lines 16 25 Figure 34) Local-Prev-Support set Local-NextSupport set becomes empty (see lines 15 24 Figure 34, respectively). either case,
inadmissible MUSE path consistent instance. prove constraint's local
support sets become empty cannot participate MUSE path consistent
instance MUSE CSP. proven Local-Next-Support (Local-Prev-Support follows
symmetry). Observe R2 (i; a; j; b) = 1, nodes immediately
280

fiMUSE CSP: Extension Constraint Satisfaction Problem

2 = f 1j, 2j, 3jg
1 = f 4j, 5jg

1

2

3

start

end
4

5

Figure 35: example set CSP problems would good candidate MUSE
CSP lack node sharing.
follow (and similarly j ) DAG incompatible truth constraint,
cannot participate MUSE path consistent instance. line 23 Figure 34,
(i; k) removed Local-Next-Support[(i; j ); a; b] [(i; j ); k; a; b]
popped List. removal (i; k) Local-Next-Support[(i; j ); a; b] indicates
segment containing i, j , k support R2 (i; a; j; b). remains shown
[(i; j ); k; a; b] put List R2 (i; a; j; b) must false every segment
contains i, j , k. proven induction number iterations
loop Figure 33 (much like proof MUSE AC-1). must also show
R2 (i; a; j; b) = 1 MUSE PC-1, MUSE path consistent. R2 (i; a; j; b)
MUSE path consistent, must exist least one path start end
goes nodes j nodes n path contain least one label
consistent constraint. proof would similar second half proof
MUSE AC-1 correctness. this, may conclude MUSE PC-1 builds
largest MUSE path consistent structure.

5. Combining CSPs MUSE CSP
Problems inherent lattice structure problems solved
node splitting approach natural areas application MUSE CSP,
exponential number CSPs replaced single instance MUSE CSP, DAG
representation inherent problem. section discuss DAG construction
application areas would benefit MUSE CSP approach,
obvious construct DAG. set CSP problems
used segments MUSE CSP. example, Figure 35 illustrates two instances
CSP combined single MUSE CSP. However, using MUSE CSP
example would right choice; node sharing cannot offset cost using
extra MUSE AC-1 data structures.
Multiple nodes name various CSPs potentially represented
single node MUSE CSP. assume two nodes, k1 k2 given
name (say k) two instances CSP, domain obey
constraints, i.e.:
1. Lk1 = Lk2 (i.e., domains equal.)
2. R1(k1; a) = R1(k2; a) every 2 Lk1 ; Lk2 (i.e., unary constraints
same.)
281

fiHelzerman & Harper

1 = f 1j, 2jg
2 = f 1j, 3jg
3 = f 2j, 3jg

1

2
start

end

1

3

2

start

end

2

3

Figure 36: example maximal node sharing leads spurious segments.
first DAG contains two paths, f1,2,3g f2g, correspond none
segments. second DAG presents preferred sharing created
Create-DAG routine.
3. R2(k1; a; i; b) = R2(k2; a; i; b) labels 2 Lk1 ; Lk2 b 2 Li ,
segments (i.e., binary constraints same.)
However, illustrated Figure 36, much sharing common nodes introduce
additional segments appear original list CSPs. extra
segments cause extra work done, often desirable create DAG
shares nodes without introducing extra segments. algorithm Create-DAG, shown
Figure 38 takes arbitrary set CSP problems input (a list segments), outputs
DAG representation CSPs shares nodes without introducing spurious
segments. Create-DAG calls auxiliary procedure Order-Sigma defined Figure 39.
data structures used two routines defined Figure 37.
hold individual segments , routine Create-DAG uses special data
structure ordered sets supports useful operations. segment n
integer, [n] node position n . [0] always start node,
[j j , 1] always end node. [k::m] ordered subset consisting
nodes positions k m. addition, ordered set allows us insert node
immediately node j already set. node [pos] structure
name field next-set field, set names nodes follow
node [pos] set segments.
Create-DAG begins adding special purpose start end nodes segment.
calls routine Order-Sigma shown Figure 39 order nodes
segment. Order-Sigma orders nodes segment ones
common tend occur earlier set. order elements, uses operator
> (i.e., larger than) defined nodes. Note start node defined
\largest" node, end node \smallest" node. addition, > j means either
appears segments j does, appear number
segments, lower ordinal number j . Thus operator > induces total
ordering nodes N .
Order-Sigma first called Create-DAG selects largest node
smaller start node. constructs set , set segments
containing i. point, segments ordered start node first
second. calls Order-Sigma order nodes smaller i.
recursive call done, segments considered (i.e., Z ). Note
282

fiMUSE CSP: Extension Constraint Satisfaction Problem

Notation

Meaning



set node sets. node set represents CSP.
node set segment . set modified include
begin end nodes Create-DAG algorithm work
properly. Note [0] always start node, [jj , 1]
always end node. node [pos] structure name
next-set (names nodes follow node DAG).
G set node pairs (i; j ) exists
directed edge j DAG created Create-DAG.
N set nodes placed DAG
Create-DAG.
Z set segments order respect node j
Order-Sigma.
node j used Order-Sigma order remaining
elements smaller node.
U set nodes already considered current call
Order-Sigma.
R set nodes Z Order-Sigma.
node largest node smaller j R , U
(if non-empty) R Order-Sigma.
Order-Sigma, set segments Z contain node i.


G
N
Z
j
U
R



Figure 37: Data structures used Create-DAG Order-Sigma.

283

fiHelzerman & Harper

Create-DAG () f

1.
2.
3.
4.
5.
6.
7.
8.
9.

10.
11.
12.
13.
14.
15.
16.
17.
18.
19.
20.
21.
22.
23.
24.
25.
26.
27.
28.
29.
30.
31.
32.
33.
34.

Add start first node end last node every segment ;
Order-Sigma(, start);
pos := 1 maximum segment length f
:= copy();
2 ^ jj , 1 > pos f
[pos].name = end f
G := G [ f([pos , 1], [pos])g; g
0

0

else f

EDGE SET := f1j 1[pos , 1].name = [pos , 1].name ^
1[pos].name = [pos].nameg;
next-set := f[pos + 1].name j 2 EDGE SETg;
:= , EDGE SET;
node [pos].name N f
N := N [ [pos];
[pos].next := next-set;
G := G [ f([pos , 1], [pos])g; g
0

0

else f
node := get node N name [pos].name;
node.next = next-set f
G := G [ f([pos , 1]; [pos])g; g
else f

new-node : = Create new node;
new-node.name := concatenate([pos].name, ');
node := get node N named new-node.name (if one);
node && node.next !=next-set f
new-node.name := concatenate(new-node.name, ');
node := get node N named new-node.name (if one); g
(node = NULL)
N := N [ new-node;
else new-node := node;
new-node.next := next-set;
Replace [pos].name new-node.name [pos , 1].next;
G := G [ f([pos , 1]; new-node)g;
Replace every occurance [pos] pos new-node
segments EDGE SET; g g g g g
Eliminate start end G 2 ; g

Figure 38: Routine create DAG represent .

284

fiMUSE CSP: Extension Constraint Satisfaction Problem

Order-Sigma (Z; j ) f
1. U := ;
2. Z 6= f
3.
R :=
;

[

4.
5.
6.
7.
8.
9.
10.
11.
12.
13.
14.

2Z

R , U 6=
:= \largest" node R , U less j ;
else
:= \largest" node R less j ;
:= fj 2 Z ^ 2 g ;
Z := Z , ;
=6 end f
2 f
Put j ;
U := U [ ; g
Order-Sigma(S; i) g g g

Figure 39: routine arrange nodes within segments convenient merging.
first iteration loop, preference select largest node
contained segments ordered recursive call Order-Sigma.
items independent ordered segments, create spurious paths
placed early DAG; however, items occur already ordered segments,
placed earlier items occur ordered segments would tend introduce
spurious paths. loop continues segments ordered. worstcase running time Order-Sigma O(n2 ), n sum cardinalities
segments .
Order-Sigma orders nodes segments, Create-DAG begins construct DAG, represented set nodes N set directed edges G.
DAG constructed going segment beginning position
second element (the position start). loop line 3 looks nodes left
right order, one position time, elements segment added
G. node certain name already placed N (i.e., set nodes
already DAG created) adding node graph (as well directed
edge [pos , 1] [pos] G) cannot create spurious paths DAG.
hand, node name [pos] already placed N ,
possible current segment could add paths DAG correspond
segments . avoid adding spurious segments, deal segments
one time share previous node node name
current position. basic idea add edge keep track nodes
follow node DAG. this, easily determine whether
node used occurs another segment later position. node
used followed precisely set next nodes follow
node already placed graph; otherwise, second node would renamed
avoid adding spurious segments. event, create new name node.
285

fiHelzerman & Harper

Note DAG complete, eliminate start end nodes G
(and corresponding outgoing incoming edges) make G consistent use
MUSE arc consistency MUSE path consistency algorithms. running time
Create-DAG also O(n2 ), n sum cardinalities segments .
Even though DAGs produced routine Create-DAG nice properties,
routine probably used starting point custom combining routines
specific intended application area. believe domain-specific information play important role MUSE combination. example domain specific
combining algorithm presented (Harper et al., 1992), describes spoken-language
parsing system uses MUSE CSP. distinguishing feature application's combining algorithm instead avoiding creation extra segments, allows controlled
introduction extra segments extra segments often represent sentences
N-Best sentence spoken language recognition system would miss.

6. Conclusion

conclusion, MUSE CSP used eciently represent several similar instances
constraint satisfaction problem simultaneously. multiple instances CSP
common variables domains compatible constraints,
combined single instance MUSE CSP, much work required enforce
node, arc, path consistency need duplicated across instances, especially
constraints suciently tight.
developed MUSE CSP constraint-based parser, PARSEC (Harper & Helzerman, 1995a; Harper et al., 1992; Zoltowski et al., 1992), capable parsing word
graphs containing multiple sentence hypotheses. developed syntactic semantic
constraints parsing sentences, applied word graph, eliminate hypotheses syntactically semantically incorrect. work speech processing,
MUSE arc consistency algorithm effective pruning incompatible labels
individual CSPs represented composite structure. extracting
parses sentences remaining MUSE CSP MUSE AC-1, usually unnecessary enforce arc consistency CSP represented directed path
network tightness syntactic semantic constraints.
Speech processing area segmenting signal higher-level
chunks problematic. Vision systems handwriting analysis systems comparable
problems. addition, problems allow parallel alternative choices type
variable, parsing lexically ambiguous sentences, also excellent candidates
MUSE CSP.
C++ implementations algorithms described paper available following location: ftp://transform.ecn.purdue.edu/pub/speech/harper code/. directory
contains README file file called muse csp.tar.Z.

286

fiMUSE CSP: Extension Constraint Satisfaction Problem

Acknowledgements
work supported part Purdue Research Foundation grant
Intel Research Council. would like thank anonymous reviewers insightful
recommendations improving paper.

References

Bessiere, C. (1994). Arc-consistency arc-consistency again. Artificial Intelligence, 65,
170{190.
Davis, A. L., & Rosenfeld, A. (1981). Cooperating processes low-level vision: survey.
Artificial Intelligence, 17, 245{263.
Dechter, R. (1992). local global consistency. Artificial Intelligence, 55, 87{107.
Dechter, R., Meiri, I., & Pearl, J. (1991). Temporal constraint networks. Artificial Intelligence, 49, 61{95.
Dechter, R., & Pearl, J. (1988). Network-based heuristics constraint-satisfaction problems. Artificial Intelligence, 34, 1{38.
Freuder, E. (1989). Partial constraint satisfaction. Proceedings International Joint
Conference Artificial Intelligence, pp. 278{283.
Freuder, E. (1990). Complexity K-tree-structured constraint-satisfaction problems.
Proceedings Eighth National Conference Artificial Intelligence, pp. 4{9.
Han, C., & Lee, C. (1988). Comments Mohr Henderson's path consistency algorithm.
Artificial Intelligence, 36, 125{130.
Harper, M. P., & Helzerman, R. A. (1995a). Extensions constraint dependency parsing
spoken language processing. Computer Speech Language, 9 (3), 187{234.
Harper, M. P., & Helzerman, R. A. (1995b). Managing multiple knowledge sources
constraint-based parsing spoken language. Fundamenta Informaticae, 23 (2,3,4),
303{353.
Harper, M. P., Jamieson, L. H., Zoltowski, C. B., & Helzerman, R. (1992). Semantics
constraint parsing word graphs. Proceedings International Conference
Acoustics, Speech, Signal Processing, pp. II{63{II{66.
Mackworth, A. K. (1977). Consistency networks relations. Artificial Intelligence, 8 (1),
99{118.
Mackworth, A. K., & Freuder, E. (1985). complexity polynomial networkconsistency algorithms constraint-satisfaction problems. Artificial Intelligence, 25,
65{74.
287

fiHelzerman & Harper

Maruyama, H. (1990a). Constraint dependency grammar. Tech. rep. #RT0044, IBM,
Tokyo, Japan.
Maruyama, H. (1990b). Constraint dependency grammar weak generative capacity.
Computer Software.
Maruyama, H. (1990c). Structural disambiguation constraint propagation.
Proceedings Annual Meeting ACL, pp. 31{38.
Mohr, R., & Henderson, T. C. (1986). Arc path consistency revisited. Artificial Intelligence, 28, 225{233.
Montanari, U. (1974). Networks constraints: Fundamental properties applications
picture processing. Information Science, 7, 95{132.
van Beek, P. (1994). inherent level local consistency constraint networks.
Proceedings Twelfth National Conference Artificial Intelligence, pp. 368{373.
Villain, M., & Kautz, H. (1986). Constraint-propagation algorithms temporal reasoning.
Proceedings Fifth National Conference Artificial Intelligence, pp. 377{382.
Waltz, D. L. (1975). Understanding line drawings scenes shadows. Winston, P.
(Ed.), Psychology Computer Vision. McGraw Hill, New York.
Zoltowski, C. B., Harper, M. P., Jamieson, L. H., & Helzerman, R. (1992). PARSEC:
constraint-based framework spoken language understanding. Proceedings
International Conference Spoken Language Understanding, pp. 249{252.

288

fiJournal Artificial Intelligence Research 5 (1996) 1-26

Submitted 12/95; published 8/96

Spatial Aggregation: Theory Applications
Kenneth Yip

MIT Artificial Intelligence Laboratory, 545 Technology Square
Cambridge, 02139 USA

yip@martigny.ai.mit.edu

Feng Zhao

fz@cis.ohio-state.edu

Department Computer Information Science, Ohio State University
Columbus, OH 43210 USA

Abstract

Visual thinking plays important role scientific reasoning. Based research
automating diverse reasoning tasks dynamical systems, nonlinear controllers, kinematic mechanisms, uid motion, identified style visual thinking, imagistic
reasoning. Imagistic reasoning organizes computations around image-like, analogue representations perceptual symbolic operations brought bear infer
structure behavior. Programs incorporating imagistic reasoning shown
perform expert level domains defy current analytic numerical methods.
developed computational paradigm, spatial aggregation, unify description class imagistic problem solvers. program written paradigm
following properties. takes continuous field optional objective functions input,
produces high-level descriptions structure, behavior, control actions. computes
multi-layer intermediate representations, called spatial aggregates, forming equivalence classes adjacency relations. employs small set generic operators
aggregation, classification, localization perform bidirectional mapping
information-rich field successively abstract spatial aggregates. uses data
structure, neighborhood graph, common interface modularize computations.
illustrate theory, describe computational structure three implemented
problem solvers { kam, maps, hipair | terms spatial aggregation generic
operators mixing matching library commonly used routines.

1. Introduction

commonly believed two styles scientific thinking: analytical, logical
chain symbolic reasoning premises conclusions, visual, holding imagistic, analogue representations problem one's mind perceptual symbolic
operations brought bear make inferences. Neither style preferred
priori other. However, problems whose complexity precludes direct analytical
approach, certain amount qualitative visual imagination needed provide
necessary \feel" \understanding" physical phenomena. picture clear,
analytical mathematics take lead eciently logical conclusions.
\feel physical understanding" often considered informal, imprecise,
apparently unteachable, necessary scientists engineers.
believe part ability visualize imagine must consist skills generate
images, discover structures relations images, transform structures, predict
structures respond internal dynamics external forcing.

c 1996 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiYip & Zhao

AI work visual reasoning focused diagrams role
controlling search, recent years seen development class problem
solvers imagistic, i.e., problem solvers derive power primarily
use visual apparatus secondarily search analytical methods.
problem solvers designed perform tasks many different domains: control
interpretation numerical experiments (Yip, 1991; Nishida & et al., 1991; Zhao,
1994), kinematics analysis mechanisms (Joskowicz & Sacks, 1991), design controllers
(Zhao, 1995; Bradley, 1992), analysis seismic data (Junker & Braunschweug, 1995),
reasoning uid motion (Yip, 1995). However, important commonalities
underlying them. paper, present framework provide unified description
class problem solvers. framework consists three ideas:

field ontology: input field, mapping one continuum another.

image-like analogue representation. field assumed metric
meaningful talk closeness continuity.1
Structure discovery: central problem solved transformation
information-rich input abstractions well-suited concise structural behavioral
descriptions. transformation thought successive mappings
input space abstract spaces hide details group similar objects
equivalence classes.
Multi-layer spatial aggregates: propose (1) representation neighborhood
graph encode explicitly adjacency relations among objects one level abstraction,
(2) building blocks computational processes small set generic operators
construct, transform, classify, search neighborhood graph. operators
recursively used implement task-specific applications. multi-layer theory
two advantages: (1) nonlocal property lower layer redescribed
local property higher layer, (2) layer neighborhood graph
provides common interface support identical modular computations.
field mapping one continuum (say Rm ) another (say Rn ). concretely,
one visualize m-dimensional space n-vector attached point space.
Fields commonplace science engineering applications. used describe
physical quantities vary space time. Temperature room threedimensional scalar field. Weather data described 4D-spacetime field 6vector attached point: velocity (three components) air ow, temperature (scalar),
pressure (scalar), density (scalar). examples fields include brightness
intensity array vision, configuration space mechanism analysis, phase
space (vector field) dynamical systems.
actual computer representations, often approximate field grid. grid
may uniform non-uniform. field reconstructed numerical simulation
1. Forbus et al. (1991) proposed general methodology qualitative spatial reasoning: Metric Diagram/Place Vocabulary (MD/PV). generally agree methodology. paper inspired
us look refined framework unify class problem solvers integrate visual
symbolic reasoning.

2

fiSpatial Aggregation: Theory Applications

measurements. field contain symbolic abstractions; completely
numerical. Fields composable. One extend dimension underlying space
and/or number components vector attached point space.
representation physical systems, field two distinguishing characteristics.
First, information-rich sense Shannon-Weaver measurement information.
instantaneous field 1283 -grid ow simulation may contain order 108 bits
information. Second, pictorial sense structures relations
implicitly represented field.
consequence information-richness pictorial quality, argue
reasoning fields central computational problem ecient transformation pointwise field description physical system economical symbolic abstractions well suited explaining structure behavior system.2 Figure 1 illustrates
field ontology relates commonly used ontologies Qualitative Physics:
device (DeKleer & Brown, 1984), process (Forbus, 1984), constraint (Kuipers, 1986).
useful, symbolic descriptions must impose conceptual structure system
complexity system understood terms well-defined parts
subparts interactions among them. relevant parts interactions often abstract global properties field. abstract property property whose support
large nonlocal, whereas support property defined subset field
property depends. hand, computational complexity reasons
prefer build recognition procedures basic routines local independent task-level information much possible. considerations lead us
adopt architecture pointwise description final symbolic descriptions
mediated layers equivalence classes objects explicit adjacency relations.
call layer objects spatial aggregate.
spatial aggregates come from? real field, tend continuities
properties (such intensity temperature pressure) field divided
equivalence classes, i.e., open regions particular property varies approximately
uniform way. continuities achieve economy description focusing
open regions boundaries instead pointwise field. Higher-order continuities,
i.e., continuities properties defined open regions, similarly used build
abstract spatial aggregates.
formation equivalence classes presupposes existence continuity. brings
us methodological point. important clearly identify source continuities
field equivalently physical system field represents. discovery valid
general continuities physical system much scientific contribution
subsequent computational use form articulated conceptual model explain
structure behavior.
motivation paper comes desire understand computational
structures shared class automatic problem solvers integrate visual, symbolic,
numerical methods. would like make computational structure explicit
comparisons generalizations made. goal develop way organizing
2. Inferring structural descriptions field ill-posed problem (e.g., recovering 3D shapes
2D images). avoid diculties, assume structure-recovery problem well-posed
main concerns computational eciency appropriate abstractions.

3

fiYip & Zhao

modeling

HARD!
analytical methods

differential
equations
numerical
simulation

physical
system

measurement

modeling

field

interpret

equivalence
class clustering

structural
description

device

modeling

process

modeling

constraint

analytical
functions

qualitative
behavioral
description

envisionment
incremental analysis
process inference
qualitative simulation

Figure 1: Field ontological abstraction reasoning physical systems.
diagram depicts relationships among different ontologies used Qualitative
Physics. central computational problem field reasoning recovery
economical structural descriptions qualitative behavior description explanation. key step structural recovery formation equivalence
classes. Identifying general valid continuities useful equivalence
class relations based important scientific contribution.
programs around image-like analogue representations, appropriate language make
programs written style clear.
next section develops theory spatial aggregation detail. Section 3 describes
language support programs organized around neighborhood graphs. Section 4
illustrates usefulness language describing succinctly computation structure
three implemented programs { kam, maps, hipair. choose programs
illustrations largely familiarity them. Section 5 shows program
spatial aggregation language, using example image analysis. plan
investigate applicability framework several programs,
constructed Kuipers Levitt (1988), Forbus et al. (1991), Gelsey (1995), Junker
Braunschweug (1995).

4

fiSpatial Aggregation: Theory Applications

2. Spatial Aggregation Theory

Given field, spectrum reasoning tasks defined. following list roughly
order increasing complexity:
Infer structural descriptions. Find objects, any, exist field.
shapes, sizes, locations? distributed?
created? evolve parameter (say time) varied?
Classify. Assign semantic labels objects configurations.
Infer correlations. Determine geometry distribution one type
objects correlate another type?
Check consistency. Given two objects configurations, test equivalent
pairwise consistent.
Infer incremental behavior. Given instantaneous configuration, predict
possible short-term behaviors.
Infer behavioral descriptions. Explain summarize evolution objects
set domain-specific interaction rules.

2.1 Requirements imagistic reasoning

Partly motivated Ullman's theory visual analysis (Ullman, 1984), find desirable
following general requirements imagistic reasoning:

Abstractness. problem solver able find objects defined abstract
global properties.

Open-endedness. problem solver architecture applicable variety

domains ( uid motion, seismic data, weather data, phase space, configuration
space). requirement implies basic recognition routines must modular
composable. Task-specific knowledge affects choice ordering
routines.
Eciency. \building blocks" recognition machinery must local
non-goal-specific. \Non-goal-specific" means operations building blocks
depend interpretation objects manipulate. requirement
implies basic routines local supports principle run
parallel.
Soundness. structural behavioral descriptions must consistent
known physical mathematical principles.
Succinctness. structural behavioral descriptions contain qualitatively important distinctions relevant high-level tasks hand.
5

fiYip & Zhao

2.2 Theory

theory imagistic reasoning postulates existence multi-layers spatial aggregates. Figure 2 shows layers spatial aggregates computations organized around
them. primitive aggregate defined equivalence class subsets pointwise
field representation. aggregate composed equivalence classes primitive aggregates. field assumed task-dependent metric. metric induces topology
space hence meaningful talk adjacency. data structure
spatial aggregate neighborhood graph whose nodes represent objects edges represent adjacency relations among objects. input field sampled form lowest
layer abstraction; field also affected control actions higher-level
abstraction layers.
stream construct scheme programming language provides common
interface organizing signal processing computations, neighborhood graph conceptual glue piecing together operations manipulate fields. like visualize
nodes neighborhood graph open sets (in topology) appropriate space. Two
nodes adjacent respective open sets contiguous.3
topological notion adjacency amazingly useful reasoning physical systems. grouping objects equivalence classes, cluster tends give rise connected
component neighborhood graph. reasoning kinematics, neighborhood
graph provides essential connectivity information among free space regions. finding
\interesting" structures, pairwise consistency adjacent nodes localizes search regions. isolating bifurcation patterns, mismatch adjacent objects provides hint
analysis. constraint propagation path search, adjacency structure
imposes locality increase computational eciency. Prevalence simplicity { two
aspects neighborhood graph make powerful data structure unifying many
spatial computations.
theory revolves around computation neighborhood graph nature
processes construct, filter, transform, compare neighborhood graphs.
isolate set generic operators aggregate, classify, re-describe, search correspond
important conceptual pieces common class imagistic problem solvers
kam (Yip, 1991), maps (Zhao, 1994), hipair (Joskowicz & Sacks, 1991).
next section discusses operators detail. Section 4 illustrates use
operators rational reconstruction three implemented computer programs.

3. Language Spatial Aggregation

present language describing computational processes organized around spatial
aggregates. language provides small set operators construct manipulate
neighborhood graphs. operators make conceptual structure several implemented
programs clear.
3. Let B two open sets. B contiguous either \ B 6= ; B \ 6= ;
closure set A. particular, B overlap, contiguous.

6

fiSpatial Aggregation: Theory Applications

Model

classify
search

aggregate

Structural
description

N-graph
consistent?

primitive
objects
filter

map

incremental
analyze

re-describe

Behavioral
description

localize

classify
search

aggregate

Structural
description

N-graph
consistent?

primitive
objects
filter

map

incremental
analyze

Behavioral
description

control

sample

FIELD

Figure 2: schematic representation computational structure analysis field
ontology. multi-layers spatial abstraction. abstraction level defined neighborhood graph, data structure representing spatial aggregates
adjacency relations. input field fed lowest abstraction layer.
Note identical computational structure layer. aggregate operator
computes adjacency relations based task-specific metric. neighborhood
graph common interface map filter routines. remaining operations correspond generic analysis tasks. repertoire task-independent
geometric manipulation routines (which shown) accessible
generic operators.
7

fiYip & Zhao

3.1 Task-level operators

task-level generic operators consist aggregate, classify, re-describe, localize,
search, incremental-analyze, together predicates pairwise-consistent?
consistent?. neighborhood graph \conceptual glue": allows computation
hierarchical structural descriptions organized uniform manner. following
box summarizes language provides user needs supply order
write programs spatial aggregation.

Language Features
User interface functions:
aggregate, classify, re-describe, localize, search,
incremental-analyze, pairwise-consistent?, consistent?

user must specify neighborhood relation, field metric, equivalence
relation operators.

Data types:
{ N-graph constructors, accessors, modifiers.

Examples N-graph include 4-adjacency arrays, minimal spanning tree,
Voronoi diagram.
{ Fields:
bitmap, vector field, etc.
Libraries:
{ Geometric utilities:
intrinsic-geometry, contain?, intersect, @ , .
{ Numerical image processing routines:
FFT, convolution, integrator, linear system solver, vector/matrix algebra.
1.

2.

aggregate(objects combiner)

aggregate operator assembles collection objects spatial structure
using combiner procedure explicates spatial relations among objects
terms neighborhood graph.4 operator returns neighborhood graph
(N-graph). N-graph lazily built.
example, recognize trajectory phase space, aggregate operator might
given set discrete points combiner procedure (such minimal spanning
tree) establish adjacency relations. combiner procedure might use metric
topological properties underlying space.
classify(N-graph cluster-proc class-rules)

4. Recall nodes neighborhood graph objects edges adjacency relations.

8

fiSpatial Aggregation: Theory Applications

classify operator forms equivalence classes according equivalence relation
(using cluster-proc), assigns semantic label equivalence class |
subgraph input N-graph | according classification rules. example,
orbit clustering procedure groups orbits ow pipes.5 classification rules
set production rules. operator returns labeled N-graph.
catalog classification labels domain-specific. classification labels
serve indices storage retrieval shared class properties methods
instantiating them.
3.

re-describe(N-graph desc-type)

4.

localize(N-graph select-proc enumerate-proc)

5.

6.

re-describe operator changes representation primitive object. Like
lambda abstraction scheme, operator allows compound object (say subset
N-graph) treated primitive.
Given classified object, description-type procedure instantiates additional properties specific class objects. example, point set classified
space curve, becomes sensible compute additional geometric properties like
length, curvature, torsion.
localize operator systematically enumerates members equivalence class
(nodes N-graph) selects according select procedure. operator
\opens up" abstraction allow individual members equivalence class
singled out.
search(N-graph initial-states goal-p combiner)

search operator returns paths starting initial-states satisfying
goal-p predicate. combiner procedure controls order graph
traversed.
incremental-analyze(N-graph state-desc delta)

Given N-graph description states constituent laws, incrementalanalyze operator computes infinitesimal change qualitative state due
small perturbation. perturbation delta might temporal, state,
parameter space.
predicates pairwise-consistent? consistent?:



pairwise-consistent?(obj1 obj2 consistency-rules)



consistent?(obj consistency-rules)

pairwise-consistent? predicate decides two objects consistent according
consistency-rules. objects primitive objects nodes
N-graph N-graphs themselves.
Consistent?

tests object well-formed according consistency-rules.

5. ow pipe class orbits continuously deformed other. example
homotopy equivalence class.

9

fiYip & Zhao

3.2 Generic data structure routines
neighborhood graph constructed



N-graph-constructor(objects neighbor-p)



map(N-graph proc)



filter(N-graph mask)

N-graph-constructor takes set primitive objects neighborhood predicate
arguments, returns neighborhood graph. example neighborhood graph Voronoi diagram. predicate neighbor-p tests two nodes
neighbors.
set task-independent routines operate objects neighborhood graphs
support task-level operations.
map routine transforms neighborhood graph using prespecified procedure.
filter selects subset neighborhood graph processing.

addition generic operators, language provides routines perform common
geometric manipulation. following routines especially useful:
1.
2.
3.
4.
5.
6.

computes intrinsic geometric properties
objects (e.g., area, curvature, surface normal).
contain?(obj1 obj2) checks obj2 inside obj1.
intersect(obj1 obj2) computes intersection two objects.
@(object) boundary operator returns boundary object.
dimension boundary co-dimension 1.
(object) co-boundary operator returns new object whose boundary
object. dimension new object one higher object.
convolve(object mask) performs pointwise convolution given mask.

intrinsic-geometry(obj properties)

4. Examples Spatial Aggregation

section, describe architecture three implemented systems kam (Yip, 1991),
maps (Zhao, 1994), hipair (Joskowicz & Sacks, 1991) terms spatial aggregation
framework. Although programs designed different tasks, computations
share strikingly similar pattern: programs construct spatial objects, interpret
via multi-layers abstraction object aggregation, classification, re-description.
Composite objects lower level labeled manipulated primitive units
next higher level.
Despite fact authors two programs, structural similarities among programs apparent us carefully reconstructed
10

fiSpatial Aggregation: Theory Applications

programs defining appropriate neighborhood graphs generic operators. Analyzing programs common framework help us understand
programs do, also greatly enhance ability construct future programs
spatial aggregation operators.

4.1 KAM

task kam explore dynamics Hamiltonian systems produce high-level
summaries qualitative behaviors.
Given state equations Hamiltonian system, kam derives symbolic description
qualitative behavior | terms orbit types,6 orbit bundles, phase portraits,
bifurcation patterns | collection point sets representing orbits (or trajectories)
phase space (see Figure 3). point sets obtained numerical simulation
measurements. provide useful interpretation point set, kam decide (1)
look interesting orbits, (2) group orbits larger structures.
Kam proceeds via sequence intermediate representations allow gradual recovery
orbit structures eventually global dynamical properties system. Kam
able view object multiple levels abstraction. example, orbit
viewed points phase space curve part orbit bundle.
computations kam organized four layers (as shown Figure 4): (1) orbit,
(2) orbit bundle, (3) phase portrait, (4) bifurcation pattern. walk
first level sucient detail illustrate computation synthesized
spatial aggregation operators neighborhood graph. Details remaining levels
described Yip (1991).
input point set. aggregate operator imposes adjacency relation
point set constructing minimal spanning tree (MST). Two points adjacent
neighbors connected edge MST. Although MST appropriate
orbit interpretation, applications might require different adjacency relations (such
Voronoi diagrams k-nearest neighbors). output aggregate operator
neighborhood graph encodes edges MST.
consistent? predicate checks inconsistent edges, i.e., edges
significantly longer nearby edges, neighborhood graph. Deleting
inconsistent edge partition graph subgraphs represents cluster
original point set.
Next, classify operator assigns label, orbit type, neighborhood graph
according shape MST number clusters. assignment unsuccessful, kam assumes input point set contain enough points reveal
structure orbit. Kam request points repeat aggregation step.
assignment successful, re-describe operator takes labeled neighborhood
graph fills information relevant particular orbit type. example,
orbit periodic orbit, period orbit determined. filling
details, re-describe operator packages orbit primitive object passes
6. introduce useful terminology here. dynamical system smooth vector field. orbit
integral curve vector field. orbit bundle collection adjacent orbits
qualitative behavior. phase portrait collection orbits fill phase space. bifurcation
pattern characteristic change structure phase portrait system parameters vary.

11

fiYip & Zhao

(a)

(b-1)

(b-2)

Figure 3: Top: (a) phase portrait Hamiltonian system. geometric structures
phase portrait vary drastically system parameter changes.
Like expert dynamicist, kam explores dynamics nonlinear Hamiltonian
system finding interesting structures phase space. decides initial
conditions parameter values try. interprets finds uses
structures draws guide exploration.
Bottom: (b-1) minimal spanning tree representation point set. (b-2)
Magnifying boxed region | crosses () inconsistent edges. Kam imposes
adjacency relations point set representing trajectory phase space.
structure minimal spanning tree reveals type trajectory.

12

fiSpatial Aggregation: Theory Applications

bifurcation
consistency
rules
phase
portraits

consistent?

aggregate

N-graph

portrait
consistency
rules

bifurcation properties

bifurcation classification rules

consistent?

aggregate

redescribe

N-graph

phase
portrait

portrait properties
classify

wavefront
propagation
orbit bundle
consistency
rules
orbits

bifurcation
pattern

classify
nearest
neighbors

orbit
bundles

redescribe

portrait classification rules

consistent?

aggregate

redescribe

N-graph

orbit
bundle
orbit bundle properties
classify

wavefront
propagation
tree
consistency
rules
point
set

orbit bundle classification rules

consistent?

aggregate

redescribe

N-graph

MST
algorithm

orbit

orbit properties
classify
orbit classification rules

Figure 4: computational structure kam viewed spatial aggregation operators acting neighborhood graphs. four layers abstraction: orbit, orbit bundle,
phase portrait, bifurcation pattern. computation organized around
neighborhood graphs. structural similarities among layers apparent.

13

fiYip & Zhao

force control
switched

control u 1


flow pipe
Region R projected
onto initial phase plane.

control u 2

G
R

Figure 5: Left: Buckling beam due axial load.
Right: Phase spaces buckling beam (upper) locally controlled beam
(lower). stabilize buckling beam far unbuckled state |
unstable equilibrium G, maps (1) finds ow pipe, group qualitatively similar
trajectories, reaches G, (2) deforms trajectory emanating initial
state via force control trajectory close G, (3) switches
conventional linear controller achieve desired stabilization. Let region R
lower phase plane linearly controllable region control u2 . Starting
initial state initial control u1 , system evolves along trajectory
within ow pipe close projection region R. force
control u1 turned deform trajectory system moves
region R linear controller drives system desired unbuckled
state G.
next level abstraction, orbit bundle level, process aggregation,
consistency checks, classification, re-description repeated.

4.2 MAPS

Maps' task analyze qualitative phase-space structures dissipative systems

use analysis results guide synthesis control laws.
Like kam, maps extracts high-level dynamical information phase space structures. maps goes beyond kam two important aspects: (1) maps deals threedimensional structures explicitly (whereas kam reasons cross-sections three-dimensional
structures), (2) maps uses phase space structures synthesize nonlinear control
actions.
Maps synthesizes global control path geometrically (see Figure 5). Given initial
state desired state system control, maps searches path phase
space connects initial desired state. goal directly reachable
initial state, maps pieces together multiple path segments varying control
actions. brute-force search individual control paths continuum clearly infeasible.
Maps partitions continuous phase space manageable discrete set objects |
14

fiSpatial Aggregation: Theory Applications

ow pipes | defining appropriate equivalence relations, searches ow pipes
good control paths.
computations maps organized four layers (as shown Figure 6): (1) stability region, (2) ow pipe, (3) phase portrait, (4) ow pipe graph. input
fixed points dynamical system7 . Two fixed points adjacent connected
saddle trajectories. adjacency relation represented neighborhood
graph. trajectories passing saddles classified equivalence classes
assigned stability region boundary labels. re-describe operator computes regions delimited stability region boundaries represents polyhedra.
stability regions fed next layer.
second layer, stability region triangulated Delaunay method.
aggregate operator constructs neighborhood graph triangulation using adjacency relation defined Voronoi diagram, dual Delaunay triangulation.
triangulated sub-regions classified equivalence classes according topological criterion states two adjacent sub-regions equivalent trajectories
passing connected consistent manner. Equivalence classes
sub-regions classified ow pipes. Recall ow pipe coarse representation
set trajectories qualitative properties. use ow pipes simplifies
considerably control path planning problem.
third layer aggregates ow pipes form phase portrait.
fourth layer control decisions made. Flow pipes different phase
portraits aggregated form larger structure, ow pipe graph, fundamental data structure supporting path planning phase space. Two ow pipes
adjacent phase space regions covered ow pipes overlap. Intuitively, one
switch one ow pipe adjacent one setting appropriate control parameters
generate phase portraits question. Given initial desired state, search
operator searches ow pipe graph solution paths.
Information also passed abstraction layer. connected sequence
ow paths found satisfy control objective, individual trajectory segments within
ow pipe found localize operator using shooting method.

4.3 HIPAIR

Hipair performs kinematic analysis fixed-axes mechanisms built rigid parts. Given
description shapes motion types (such translation rotation) parts,
hipair derives realizable configurations mechanism.
Hipair derives realizable configurations mechanism constructing manipulating configuration space mechanism (see Figure 7). configuration space
space positions orientations parts make mechanism. hipair
partitions configuration space free space regions parts overlap,
blocked space regions overlap. configurations correspond free
space regions realizable. boundaries free space regions determined
7. Fixed points, equilibrium points, critical points phase space velocity vector
vanishes. Fixed points classified three types according behavior nearby trajectories.
fixed point attractor nearby trajectories move towards it. repellor
move away it. saddle move towards move away it.

15

fiYip & Zhao

flow pipe graph
consistency
rules
phase
portraits

aggregate

N-graph

portrait
consistency
rules

search

consistent?

aggregate

N-graph

classify
localize

shooting
method

redescribe

phase
portrait

portrait properties
classify

wavefront
propagation
sub-region
consistency
rules
stability
regions

flow
pipe
graph

reachability rules

flow pipe region overlap

flow
pipes

redescribe

consistent?

portrait classification rules

consistent?

aggregate

redescribe

N-graph

flow
pipes

flow pipe properties
classify

Voronoi diagram
flow pipe classification rules
stability region
consistency
rules
fixed
points

consistent?

aggregate

redescribe

N-graph

stability
regions

stability region properties
classify

saddle trajectories
stability region classification rules

Figure 6: computational structure maps viewed spatial aggregation operators
acting neighborhood graphs. four layers abstraction: stability regions,
ow pipes, phase portrait, ow pipe graph. Note structural similarities
kam maps. Control synthesis implemented search
localize operators acting neighborhood graph representing ow pipe
graph.

16

fiSpatial Aggregation: Theory Applications

x
5

cam


x
follower

5






Figure 7: Left: 3-finger cam-follower. Right: configuration space camfollower. cam rotation. x follower displacement. shaded
regions blocked space, indicating parts overlap. free space
regions realizable configurations cam-follower. boundaries
free space regions determined contact relations cam
fingers follower.
contact relations among parts touch other. region diagram graph whose
nodes free space regions edges specify region adjacencies. region diagram
mechanism composed regions diagrams pairwise interacting parts.
example, region diagram mechanism 10 parts constructed region
diagrams 45 possibly interacting pairs.
computations hipair organized three layers (as shown Figure 8): (1)
free space region, (2) subassembly region diagram, (3) mechanism region diagram.
input shapes parts motion types. Hipair first considers pair interacting parts. looks equations contact curves, i.e., curves configuration
space pair corresponding configurations two parts touch,
pre-compiled table common contact curves. contact curve partitioned segments
intersection points curve either another contact curve boundaries
configuration space. Two segments adjacent share endpoint. aggregate
operator assembles segments adjacency relations neighborhood graph.
search operator traverses neighborhood graph find closed chains segments,
closed chain segments sequence segments intersect itself. closed
chain segment encloses free space region. consistent? predicate discards closed
chains lie inside closed chains. classify operator assigns label
closed chain, re-describe operator computes free space regions delimited
closed chains. free space region subdivided convex regions.
input second layer free space regions. aggregated neighborhood graph. Two free space regions adjacent (or neighbors) touch. Given
initial configuration S0 interacting pair, search operator finds free space
regions reachable S0 depth first search. neighborhood graph re-described
subassembly region diagram.
17

fiYip & Zhao

sub-region
consistency
rules

consistent?

subassembly
aggregate
region
daigrams

region adjacency

sub-region
consistency
rules
free
space
regions

aggregate

mechanism
region
diagram

N-graph region diagram properties
classify
search

consistent?

mechanism classification rules

redescribe

N-graph

subassembly
region
diagram

region diagram properties

classify
region adjacency

closed chain
consistency
rules
contact
curve
segments

redescribe

search

consistent?

aggregate

region diagram classification rules

free
space
regions
free space properties

redescribe

N-graph

classify
shared endpoint

search
free space classification rules

Figure 8: computational structure hipair viewed spatial aggregation operators
acting neighborhood graphs. three layers abstraction: free space
regions, subassembly region diagram, mechanism region diagram. Note
structural similarities hipair, kam, maps. search operator
determines reachability conditions three layers.
third layer, hipair combines subassembly region diagrams mechanism region diagram. mechanism region diagram neighborhood graph whose nodes
realizable sets free space regions edges specify adjacency free space regions.
set free space regions realizable intersections non-empty. example,
let M0 = fR0 ; S0 ; T0 g set free space regions containing initial configuration
mechanism three parts P1 ; P2 ; P3 , R0 , S0 , T0 free space
regions subassembly region diagrams pairs fP1 ; P2 g; fP1 ; P3 g, fP2 ; P3 g
respectively. Suppose R0 one neighbor R1 , S0 one neighbor S1 , T0 none.
three candidate neighbors M0 given by:
M1 = fR1 ; S0 ; T0 g
18

fiSpatial Aggregation: Theory Applications

= fR0 ; S1 ; T0 g
= fR1 ; S1 ; T0 g

M2
M3

consistent? predicate checks candidate neighbors discards unrealizable ones.

5. Illustration

section, show like program spatial aggregation language.
example boundary tracer line drawings.8 pick example image
analysis routines quite naturally written spatial aggregation style.
Boundary tracing basic operation image analysis.9 operation might used
identify group boundary segments object. example, consider
line drawing overlapping 2D objects (see Figure 9). group boundary segments,
one might first decompose figure segments, junctions. tracing process
joins colinear segments.
input boundary tracing program bitmap:
0
0
0
0
0
0
0
0
0
0
0
0
0

0
1
1
1
1
1
1
1
0
0
0
0
0

0
1
0
0
0
0
0
1
0
0
0
0
0

0
1
0
0
1
1
1
1
1
1
1
1
0

0
1
0
0
1
0
0
1
0
0
0
1
0

0
1
0
0
1
0
0
1
0
0
0
1
0

0
1
1
1
1
1
1
1
0
0
0
1
0

0
0
0
0
1
0
0
0
0
0
0
1
0

0
0
0
0
1
0
0
0
0
0
0
1
0

0
0
0
0
1
0
0
0
0
0
0
1
0

0
0
0
0
1
0
0
0
0
0
0
1
0

0
0
0
0
1
0
0
0
0
0
0
1
0

0
0
0
0
1
1
1
1
1
1
1
1
0

0
0
0
0
0
0
0
0
0
0
0
0
0

bitmap rendered Figure 10(a). Figure 11 illustrates output Figure 10(b) (c) computed input bitmap, using spatial aggregation operators.
first define neighborhood relation pixels 4-adjacency (namely,
neighbors pixel pixels immediate north, east, south, west).
often ecient way construct N-graphs directly neighborhood relations,
define explicit N-graph neighborhood constructor finds 4-adjacency neighbors
given pixel.
Next aggregate operator assembles pixels N-graph N-graph
constructor. Pixels N-graph considered similar neighbors neither
junction, junction defined pixel whose value one
two one-value neighbors. classify operator groups pixels equivalence
8. details interpretor language, implemented scheme, discussed elsewhere (BaileyKellogg, Zhao, & Yip, 1996).
9. Jim Mahoney introduced us unified description high-level operations images.

19

fiYip & Zhao

Figure 9: line drawing two overlapping objects.

(a)

(b)

(c)

Figure 10: Boundary tracing operation image analysis: (a) Pixels boundaries two
overlapping objects; (b) Pixels grouped boundary segments; (b) Boundary segments grouped distinct object contours.
classes using similarity threshold returns foreground equivalence classes, shown
Figure 10(b).
foreground equivalence classes re-described higher-level objects, boundary segments, turn aggregated new N-graph using different neighborhood relation. Specifically two boundary segments neighbors minimum separation distance less specified separation. Next, adjacent boundary segments
colinear grouped equivalence classes, called contours. contour represents
complete boundary object. Figure 10(c) shows result grouping.
might want check impossible contours. contour legal closed
self-intersecting. conditions expressed standard pattern language. Pairwise
consistency rules likewise defined.
program written spatial aggregation language shown Figure 12
Figure 13.10
10. actual implementation language described Kellogg, Zhao, Yip (1996), syntax
operators differs slightly Section 3.

20

fiSpatial Aggregation: Theory Applications

contour
consistency
rules
boundary
segments

consistent?
aggregate

redescribe
segment
N-graph

nearness
neighborhood

object
contours

boundary segment classes
classify
colinearity,
threshold

redescribe
pixels

aggregate

pixel
N-graph

4-adjacency
neighborhood

boundary
segments

pixel classes
classify
pixel similarity,
threshold

Figure 11: Boundary tracing operation: data ow spatial aggregation implementation.

6. Related Work

literature visual spatial reasoning enormous (e.g., Kosslyn, 1994; Glasgow,
1993). section, discuss computationally oriented approaches.
first line work investigates diagram-like representations aid heuristic search.
Gelernter (1963) used diagrams geometry theorem prover prune goals
obviously false. Nevins' geometry theorem prover constrained forward deduction conclude facts objects explicitly depicted diagrams (Nevins, 1975). Stallman
Sussman (1977) exploited connectivity locality lumped-parameter model
guide forward reasoning implement symbolic constraint propagation. similar
spirit, Larkin Simon (1987) showed elementary mechanics problem diagrammatic representation reduce search diagram provides convenient indices
clustering objects relations.
second line work concerns analogue simulations naive physics. Funt's whisper
program first AI program uses primarily perceptual primitives predict dynamical events simple blocks world (Funt, 1980). Arguing commonsense predictions
solid uid behavior cannot possibly depend solution complicated equations,
Gardin Meltzer (1989) proposed \molecular" simulation strings uids.
body uid, example, decomposed macro-molecules interacting
according small set local rules. Chandrasekaran Narayanan (1990) proposed
direct analogue simulation motion sliding block inclined plane.
21

fiYip & Zhao

;; 4-adjacency pixel neighborhood:
;; neighbors pixels one unit away using nearness ngraph
(define image-ngraph-fac
(ngraph-near/instantiate image-field-fac 1))
;; Form neighborhood graph pixels
(define image-ngraph
(aggregate pixels image-ngraph-fac))
;; Pixel classifier: two adjacent nodes equivalent
;; value neither junction.
(define pixel/classify
(classify-standard/instantiate
image-ngraph-fac
(lambda (n1 n2)
(if (and (not (is-junction? n1))
(not (is-junction? n2))
(= (pixel/value n1) (pixel/value n2)))
0 1))))
;; Form equivalence classes foreground pixels
(define pixel-classes
(filter
(lambda (cl) (= (pixel/value (car cl)) 1))
(pixel/classify image-ngraph pixels *threshold1*)))
;;; Form boundary segments
(define segments
(redescribe pixel-classes segment/create))

Figure 12: Boundary tracing operation program (part 1): group pixels boundary segments.
objective develop cognitive architecture visual perception mental imagery.
direct representation scene propose consists hierarchical, multi-resolution
symbol structure encoding spatial relations among objects, linked analogical
representation scene (image). major challenge analogue simulation
provide reliable simulation without incorporating extensive physics geometrical
modeling.
third line work consists spatial reasoning research qualitative physics.
Kuipers Levitt (1988) described approach spatial reasoning robot navigation
mapping large-scale spaces. proposed four-level hierarchical representation
incorporating topological metric descriptions terms entities places, paths,
distances, angles. Forbus et al. (1991) developed Metric Diagram/Place Vocabulary
theory. metric diagram contains numerical symbolic descriptions scene,
22

fiSpatial Aggregation: Theory Applications

;; Boundary segment neighborhood defined separation distance
(define segment-ngraph-fac
(ngraph-near/instantiate segment-field-fac separation))
;; Form neighborhood graph boundary segments
(define segment-ngraph
(aggregate segments segment-ngraph-fac))
;; Boundary segments classifier: two adjacent segments
;; equivalent colinear. Two thresholds used
;; determining colinearity: delta threshold separation
;; distance two end-points epsilon angle
;; tangent vectors end-points.
(define segment/classify
(classify-standard/instantiate
segment-ngraph-fac
(lambda (s1 s2)
(if (and (> (length (segment/points s1)) 1)
(> (length (segment/points s2)) 1)
(segment/colinear s1 s2 delta epsilon))
0 1))))
;; Form contours, i.e., equivalence classes boundary segments
(define segment-classes
(segment/classify segment-ngraph segments *threshold2*))
;; Contour consistency check: closed self-intersecting
(define contour-consistency-rules
'(if (and (closed? ?c)
(not (self-intersecting? ?c)))
#t #f))

Figure 13: Boundary tracing operation program (part 2): group boundary segments
distinct object contours.
place vocabulary quantization space according task-specific criteria (see also footnote 1). Comparing spatial aggregation framework MD/PV
framework, note two major differences. First, whereas metric diagram mixed
symbolic/quantitative representation, field purely numerical encode
structures explicitly. Second, theory postulates multi-layer spatial aggregates identical computational structure layer. focusing field ontology,
thought special class metric diagrams, able emphasize importance
structure-recovery problem, commonalities underlying several implemented
programs.

23

fiYip & Zhao

7. Conclusion

developed spatial aggregation paradigm realization imagistic reasoning.
paradigm systematizes important task interpreting time-varying information-rich
fields. paradigm consists three ideas: (1) field ontology, image-like analogue
representation, input, (2) structural discovery { ecient transformation pointwise field representation economical symbolic descriptions { central computational
problem, (3) multi-layer neighborhood graph common interface small
set generic operators { aggregate, classify, redescribe, search { building blocks
computational processes derive symbolic abstractions analogue representation. paradigm relies important observations physical constraints
real field (such continuity conservation) provide useful equivalence relations
economical descriptions, nonlocal property lower layer often redescribed
local property higher layer.
spatial aggregation paradigm supports recovery abstract properties via
multi-layer neighborhood graphs. produces concise descriptions manipulating equivalence classes objects primitives. constructs modular programs generic operators mixing matching library commonly used routines. expresses task-specific
knowledge terms field metric, adjacency relations, consistency predicates, classification
rules, redescription properties.
illustrate theory, examine computational structure three implemented
programs { kam, maps, hipair { integrate symbolic, numerical, visual reasoning. show small set generic operators construct, transform, filter, classify,
search neighborhood graphs capture commonalities programs. develop
language, way organizing programs around neighborhood graphs, make programs
written style clear.
currently developing toolkit support problem solving using generic
operators spatial aggregation paradigm. Many research questions still open.
operators interfaced computational geometry numerical analysis
build robust, ecient programs? scientific problems solved spatial
aggregation?
Imagistic reasoning powerful strategy mapping analog signals generated
physical systems discrete, symbolic representations systems. Spatial aggregation one many realizations. believe reasoning methods derive
power primarily perceptual operations analog representations secondarily search analytical methods might prove effective automating commonsense
reasoning well.

Acknowledgements
thank Chris Bailey-Kellogg help implementing spatial aggregation language, following people helpful discussions comments earlier drafts
paper: Harold Abelson, Andy Berlin, B. Chandrasekaran, Gregor Kiczales, John
Lamping, Shiou Loh, Jim Mahoney, Jeff May, Neal McDonald, Pandurang Nayak, Toyoaki
Nishida, Elisha Sacks, Brian Smith, Jack Smith, Gerry Sussman, Brian Williams.
24

fiSpatial Aggregation: Theory Applications

KY supported NSF National Young Investigator Award ECS-935777. FZ
supported NSF National Young Investigator Award CCR-9457802, Alfred P. Sloan
Foundation Research Fellowship, grant Xerox Palo Alto Research Center, grant
AT&T Foundation, NSF grant CCR-9308639.

References

Bailey-Kellogg, C., Zhao, F., & Yip, K. (1996). Spatial aggregation: language applications. Proceedings AAAI. appear.
Bradley, E. (1992). Taming chaotic circuits. Tech. rep. AI-TR-1388, MIT Artificial Intelligence Lab.
Chandrasekaran, B., & Narayanan, N. (1990). Towards theory commonsense visual
reasoning. Nori, K., & Madhavan, C. (Eds.), Foundations Software Technology
Theoretical Computer Science. Springer.
DeKleer, J., & Brown, J. (1984). qualitative physics based con uences. Artificial
Intelligence, 24.
Forbus, K. (1984). Qualitative process theory. Artificial Intelligence, 24.
Forbus, K., Nielsen, P., & Faltings, B. (1991). Qualitative spatial reasoning: CLOCK
project. Artificial Intelligence, 51.
Funt, B. (1980). Problem solving diagrammatic representations. Artificial Intelligence,
13.
Gardin, F., & Meltzer, B. (1989). Analogical representations naive physics. Artificial
Intelligence, 38.
Gelernter, H. (1963). Realization geometry-theorem proving machine. Computers
Thought. McGraw-Hill.
Gelsey, A. (1995). Automated reasoning machines. Artificial Intelligence, 74.
Glasgow, J. (1993). imagery debate revisited: computational perspective. Computational Intelligence.
Joskowicz, L., & Sacks, E. (1991). Computational kinematics. Artificial Intelligence, 51,
381{416.
Junker, U., & Braunschweug, B. (1995). History-based interpretation finite element
simulations seismic wave fields. Proceedings IJCAI.
Kosslyn, S. M. (1994). Image Brain: resolution imagery debate. MIT Press.
Kuipers, B. (1986). Qualitative simulation. Artificial Intelligence, 29.
Kuipers, B., & Levitt, T. (1988). Navigation mapping large-scale space. AI Magazine,
9(2).
25

fiYip & Zhao

Larkin, J., & Simon, H. (1987). diagram (sometimes) worth ten thousand words.
Cognitive Science, 11.
Nevins, A. (1975). Plane geometry theorem proving using forward chaining. Artificial
Intelligence, 6.
Nishida, T., & et al. (1991). Automated phase portrait analysis integrating qualitative
quantitative analysis. Proceedings AAAI.
Stallman, R., & Sussman, G. J. (1977). Forward reasoning dependency-directed backtracking system computer-aided circuit analysis. Artificial Intelligence, 9.
Ullman, S. (1984). Visual routines. Cognition, 18.
Yip, K. M. (1991). KAM: system intelligently guiding numerical experimentation
computer. MIT Press.
Yip, K. M. (1995). Reasoning uid motion: finding structures. Proceedings
IJCAI.
Zhao, F. (1994). Extracting representing qualitative behaviors complex systems
phase spaces. Artificial Intelligence, 69(1-2), 51{92.
Zhao, F. (1995). Intelligent simulation designing complex dynamical control systems.
Tzafestas, & Verbruggen (Eds.), Artificial intelligence industrial decision making,
control, automation. Kluwer Academic Publishers.

26

fiJournal Artificial Intelligence Research 5 (1996) 301-328

Submitted 4/96; published 12/96

Exploiting Causal Independence Bayesian Network Inference
Nevin Lianwen Zhang

LZHANG @ CS . UST. HK

Department Computer Science,
University Science & Technology, Hong Kong

David Poole

POOLE @ CS . UBC . CA

Department Computer Science, University British Columbia,
2366 Main Mall, Vancouver, B.C., Canada V6T 1Z4

Abstract
new method proposed exploiting causal independencies exact Bayesian network inference. Bayesian network viewed representing factorization joint probability
multiplication set conditional probabilities. present notion causal independence enables one factorize conditional probabilities combination even
smaller factors consequently obtain finer-grain factorization joint probability. new
formulation causal independence lets us specify conditional probability variable given
parents terms associative commutative operator, or, sum max,
contribution parent. start simple algorithm Bayesian network inference
that, given evidence query variable, uses factorization find posterior distribution
query. show algorithm extended exploit causal independence. Empirical
studies, based CPCS networks medical diagnosis, show method efficient
previous methods allows inference larger networks previous algorithms.

1. Introduction
Reasoning uncertain knowledge beliefs long recognized important research
issue AI (Shortliffe & Buchanan, 1975; Duda et al., 1976). Several methodologies
proposed, including certainty factors, fuzzy sets, Dempster-Shafer theory, probability theory.
probabilistic approach far popular among alternatives, mainly due
knowledge representation framework called Bayesian networks belief networks (Pearl, 1988;
Howard & Matheson, 1981).
Bayesian networks graphical representation (in)dependencies amongst random variables.
Bayesian network (BN) DAG nodes representing random variables, arcs representing
direct influence. independence encoded Bayesian network variable
independent non-descendents given parents.
Bayesian networks aid knowledge acquisition specifying probabilities needed.
network structure sparse, number probabilities required much less
number required independencies. structure exploited computationally
make inference faster (Pearl, 1988; Lauritzen & Spiegelhalter, 1988; Jensen et al., 1990; Shafer &
Shenoy, 1990).
definition Bayesian network constrain variable depends parents.
Often, however, much structure probability functions exploited knowledge acquisition inference. One case dependencies depend particular
values variables; dependencies stated rules (Poole, 1993), trees (Boutilier

c 1996 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiZ HANG & P OOLE

et al., 1996) multinets (Geiger & Heckerman, 1996). Another function
described using binary operator applied values parent variables.
latter, known causal independencies, seek exploit paper.
Causal independence refers situation multiple causes contribute independently
common effect. well-known example noisy OR-gate model (Good, 1961). Knowledge
engineers using specific causal independence models simplifying knowledge acquisition (Henrion, 1987; Olesen et al., 1989; Olesen & Andreassen, 1993). Heckerman (1993)
first formalize general concept causal independence. formalization later refined
Heckerman Breese (1994).
Kim Pearl (1983) showed use noisy OR-gate speed inference special
kind BNs known polytrees; DAmbrosio (1994, 1995) showed two level BNs
binary variables. general BNs, Olesen et al. (1989) Heckerman (1993) proposed two ways
using causal independencies transform network structures. Inference transformed
networks efficient original networks (see Section 9).
paper proposes new method exploiting special type causal independence (see Section 4) still covers common causal independence models noisy OR-gates, noisy MAXgates, noisy AND-gates, noisy adders special cases. method based following
observation. BN viewed representing factorization joint probability multiplication list conditional probabilities (Shachter et al., 1990; Zhang & Poole, 1994; Li &
DAmbrosio, 1994). type causal independence studied paper leads factorization conditional probabilities (Section 5). finer-grain factorization joint probability
obtained result. propose extend exact inference algorithms exploit conditional
independencies also make use finer-grain factorization provided causal independence.
state-of-art exact inference algorithm called clique tree propagation (CTP) (Lauritzen &
Spiegelhalter, 1988; Jensen et al., 1990; Shafer & Shenoy, 1990). paper proposes another algorithm called variable elimination (VE ) (Section 3), related SPI (Shachter et al., 1990; Li
& DAmbrosio, 1994), extends make use finer-grain factorization (see Sections 6, 7,
8). Rather compiling secondary structure finding posterior probability
variable, query-oriented; needs part network relevant query given
observations, work necessary answer query. chose instead CTP
simplicity carry inference large networks CTP cannot
deal with.
Experiments (Section 10) performed two CPCS networks provided Pradhan.
networks consist 364 421 nodes respectively contain abundant causal independencies. paper, best one could terms exact inference would first
transform networks using Jensen et al.s Heckermans technique apply CTP.
experiments, computer ran memory constructing clique trees transformed
networks. occurs one cannot answer query all. However, extended algorithm able answer almost randomly generated queries twenty less observations
(findings) networks.
One might propose first perform Jensen et al.s Heckermans transformation apply
. experiments show significantly less efficient extended algorithm.
begin brief review concept Bayesian network issue inference.
302

fiE XPLOITING C AUSAL NDEPENDENCE



B AYESIAN N ETWORK NFERENCE

2. Bayesian Networks
assume problem domain characterized set random variables. Beliefs represented Bayesian network (BN) annotated directed acyclic graph, nodes represent
random variables, arcs represent probabilistic dependencies amongst variables. use
terms node variable interchangeably. Associated node conditional probability variable given parents.
addition explicitly represented conditional probabilities, BN also implicitly represents
conditional independence assertions. Let x1 , x2 , ..., xn enumeration nodes BN
node appears children, let xi set parents node xi .
Bayesian network represents following independence assertion:
variable xi conditionallyindependent variables fx1 ; x2; : : :; xi,1 g given
values parents.
conditional independence assertions conditional probabilities together entail joint probability variables. chain rule, have:

P (x1; x2; : : :; xn)

=

=

n

i=1
n

i=1

P (xi jx1; x2; : : :; xi,1)
P (xi jx );


(1)

second equation true conditional independence assertions. conditional probabilities P (xi jxi ) given specification BN. Consequently, one can,
theory, arbitrary probabilistic reasoning BN.
2.1 Inference
Inference refers process computing posterior probability P (X jY =Y0 ) set X
query variables obtaining observations =Y0 . list observed variables
Y0 corresponding list observed values. Often, X consists one query variable.
theory, P (X jY =Y0 ) obtained marginal probability P (X; ), turn
computed joint probability P (x1 ; x2; : : :; xn) summing variables outside
X [Y one one. practice, viable summing variable joint probability requires exponential number additions.
key efficient inference lies concept factorization. factorization joint
probability list factors (functions) one construct joint probability.
factor function set variables number. say factor contains variable factor function variable; say factor variables depends.
Suppose f1 f2 factors, f1 factor contains variables x1 ; : : :; xi; y1; : : :; yj
write f1 (x1 ; : : :; xi; y1; : : :; yj ) f2 factor variables y1 ; : : :; yj ; z1; : : :; zk ,
y1 ; : : :; yj variables common f1 f2 . product f1 f2 factor
function union variables, namely x1 ; : : :; xi; y1; : : :; yj ; z1; : : :; zk , defined by:

f1 f2)(x1; : : :; xi; y1; : : :; yj ; z1; : : :; zk) = f1(x1; : : :; xi; y1; : : :; yj )f2(y1; : : :; yj ; z1; : : :; zk )

(

303

fiZ HANG & P OOLE

c

b



e

e

2

1

e3

Figure 1: Bayesian network.
Let f (x1 ; : : :; xi ) function variable x1; : : :; xi . Setting, say x1 f (x1 ; : : :; xi) particular
value ff yields f (x1 =ff; x2; : : :; xi), function variables x2 ; : : :; xi.
f (x1; : : :; xi) factor, sum variable, say x1 , resulting factor variables
x2 ; : : :; xi, defined

X

(

x1

f )(x2; : : :; xi) = f (x1 =ff1 ; x2; : : :; xi) + + f (x1=ffm; x2; : : :; xi)

ff1 ; : : :; ffm possible values variable x1.
equation (1), BN viewed representing factorization joint probability.
example, Bayesian network Figure 1 factorizes joint probability P (a; b; c; e1; e2; e3)
following list factors:

P (a); P (b); P (c); P (e1ja; b; c); P (e2ja; b; c); P (e3je1; e2 ):
Multiplying factors yields joint probability.
Suppose joint probability P (z1 ; z2; : : :; zm ) factorized multiplication list factors f1 , f2 , ..., fm . obtaining P (z2 ; : : :; zm ) summing z1 P (z1 ; z2; : : :; zm ) requires exponential number additions, obtaining factorization P (z2 ; : : :; zm ) often
done much less computation. Consider following procedure:
Procedure sum-out(F ; z ):




Inputs: F list factors; z variable.
Output: list factors.

1. Remove F factors, say f1 , ..., fk , contain z ,
2. Add new factor

P Qk f F return F .
z i=1

Theorem 1 Suppose joint probability P (z1 ; z2; : : :; zm) factorized multiplication
list F factors. sum-out(F ; z1 ) returns list factors whose multiplicationis P (z2 ; : : :; zm ).
304

fiE XPLOITING C AUSAL NDEPENDENCE



B AYESIAN N ETWORK NFERENCE

Proof: Suppose F consists factors f1 , f2 , ..., fm suppose z1 appears factors
f1, f2, ..., fk .

P (z2 ; : : :; zm)

=

=

X
z1

P (z1 ; z2; : : :; zm )


XY
z1 i=1

fi = [

k
XY
z1 i=1




fi ][

i=k+1

fi ]:

theorem follows. 2
variables appear factors f1 , f2 , ..., fk participated computation sum-out(F ; z1 ),
often small portion variables. inference BN
tractable many cases, even general problem NP-hard (Cooper, 1990).

3. Variable Elimination Algorithm
Based discussions previous section, present simple algorithm computing P (X jY =Y0 ).
algorithm based intuitions underlying DAmbrosios symbolic probabilistic inference
(SPI) (Shachter et al., 1990; Li & DAmbrosio, 1994), first appeared Zhang Poole (1994).
essentially Dechter (1996)s bucket elimination algorithm belief assessment.
algorithm called variable elimination (VE ) sums variables list
factors one one. ordering variables outside X [Y summed required
input. called elimination ordering.
Procedure (F ; X; Y; Y0; )





Inputs: F list conditional probabilities BN;
X list query variables;
list observed variables;
Y0 corresponding list observed values;
elimination ordering variables outside X [Y .
Output: P (X jY =Y0 ).

1. Set observed variables factors corresponding observed values.
2. empty,

(a) Remove first variable z ,
(b) Call sum-out(F ; z ). Endwhile

3. Set h = multiplication factors F .
/* h function variables X . */

4. Return h(X )=

P h(X ). /* Renormalization */
X

Theorem 2 output VE(F ; X; Y; Y0; ) indeed P (X jY =Y0 ).
Proof: Consider following modifications procedure. First remove step 1. factor
h produced step 3 function variables X . Add new step step 3 sets
observed variables h observed values.
305

fiZ HANG & P OOLE

Let f (y; A) function variable variables A. use f (y; A)jy=ff denote
f (y=ff; A). Let f (y; ,), g (y; ,), h(y; z; ,) three functions variables.
evident

f (y; ,)g (y; ,)jy=ff = f (y; ,)jy=ff g(y; ,)jy=ff;
X
X
[
h(y; z; ,)]jy=ff = [h(y; z; ,)jy=ff ]:
z

z

Consequently, modifications change output procedure.
According Theorem 1, modifications factor produced step 3 simply marginal
probability P (X; ). Consequently, output exactly P (X jY =Y0 ). 2
complexity measured number numerical multiplications numerical summations performs. optimal elimination ordering one results least complexity. problem finding optimal elimination ordering NP-complete (Arnborg et al., 1987).
Commonly used heuristics include minimum deficiency search (Bertele & Brioschi, 1972) maximum cardinality search (Tarjan & Yannakakis, 1984). Kjrulff (1990) empirically shown
minimum deficiency search best existing heuristic. use minimum deficiency search
experiments also found better maximum cardinality search.
3.1



versus Clique Tree Propagation

Clique tree propagation (Lauritzen & Spiegelhalter, 1988; Jensen et al., 1990; Shafer & Shenoy,
1990) compilation step transforms BN secondary structure called clique tree
junction tree. secondary structure allows CTP compute answers queries one
query variable fixed set observations twice time needed answer one query
clique tree. many applications desirable property since user might want compare
posterior probabilities different variables.
CTP takes work build secondary structure observations received.
Bayesian network reused, cost building secondary structure amortized
many cases. observation entails propagation though network.
Given observations, processes one query time. user wants posterior
probabilities several variables, sequence observations, needs run
variables observation sets.
cost, terms number summations multiplications, answering single query
observations using order magnitude using CTP. particular clique
tree propagation sequence encodes elimination ordering; using elimination ordering results approximately summations multiplications factors CTP (there
discrepancy, actually form marginals cliques, works conditional probabilities directly). Observations make simpler (the observed variables eliminated
start algorithm), observation CTP requires propagation evidence.
query oriented, prune nodes irrelevant specific queries (Geiger et al., 1990;
Lauritzen et al., 1990; Baker & Boult, 1990). CTP, hand, clique tree structure
kept static run time, hence allow pruning irrelevant nodes.
CTP encodes particular space-time tradeoff, another. CTP particularly suited
case observations arrive incrementally, want posterior probability node,
306

fiE XPLOITING C AUSAL NDEPENDENCE



B AYESIAN N ETWORK NFERENCE

cost building clique tree amortized many cases. suited
one-off queries, single query variable observations given once.
Unfortunately, large real-world networks CTP cannot deal due time
space complexities (see Section 10 two examples). networks, still answer
possible queries permits pruning irrelevant variables.

4. Causal Independence
Bayesian networks place restriction node depends parents. Unfortunately
means general case need specify exponential (in number parents)
number conditional probabilities node. many cases structure
probability tables exploited acquisition inference. One case
investigate paper known causal independence.
one interpretation, arcs BN represent causal relationships; parents c1; c2; : : :; cm
variable e viewed causes jointly bear effect e. Causal independence refers
situation causes c1 ; c2; : : :; cm contribute independently effect e.
precisely, c1; c2; : : :; cm said causally independent w.r.t. effect e exist
random variables 1; 2; : : :; frame, i.e., set possible values, e

1. i, probabilistically depends ci conditionally independent cj
j given ci ,
2. exists commutative associative binary operator
e = 1 2 : : : .
Using independence notion Pearl (1988), let
given Z , first condition is:

frame e

(X; jZ ) mean X independent

(1; fc2; : : :; cm; 2; : : :; mgjc1)
similarly variables. entails (1; cj jc1) (1; j jc1) cj j
j 6= 1.
refer contribution ci e. less technical terms, causes causally independent w.r.t. common effect individual contributions different causes independent
total influence effect combination individual contributions.
call variable e convergent variable independent contributions different sources collected combined (and lack better name). Non-convergent variables
simply called regular variables. call base combination operator e.
definition causal independence given slightly different given Heckerman Breese (1994) Srinivas (1993). However, still covers common causal independence
models noisy OR-gates (Good, 1961; Pearl, 1988), noisy MAX-gates (Dez, 1993), noisy
AND-gates, noisy adders (Dagum & Galper, 1993) special cases. One see following examples.
Example 1 (Lottery) Buying lotteries affects wealth. amounts money spend
buying different kinds lotteries affect wealth independently. words, causally
307

fiZ HANG & P OOLE

independent w.r.t. change wealth. Let c1; : : :; ck denote amounts money spend
buying k types lottery tickets. Let 1; : : :; k changes wealth due buying
different types lottery tickets respectively. Then, depends probabilistically ci
conditionally independent cj j given ci . Let e total change wealth
due lottery buying. e=1 + +k . Hence c1 ; : : :; ck causally independent w.r.t. e.
base combination operator e numerical addition. example instance causal independence model called noisy adders.
c1 ; : : :; ck amounts money spend buying lottery tickets lottery,
c1 ; : : :; ck causally independent w.r.t. e, winning one ticket reduces
chance winning other. Thus, 1 conditionally independent 2 given c1. However,
ci represent expected change wealth buying tickets lottery, would
causally independent, probabilistically independent (there would arcs ci s).
Example 2 (Alarm) Consider following scenario. different motion sensors
connected burglary alarm. one sensor activates, alarm rings. Different
sensors could different reliability. treat activation sensor random variable.
reliability sensor reflected . assume sensors fail independently1.
Assume alarm caused sensor activation2. alarm=1 _ _m ;
base combination operator logical operator. example instance causal
independence model called noisy OR-gate.
following example instance causal independence models know:
Example 3 (Contract renewal) Faculty members university evaluated teaching, research,
service purpose contract renewal. faculty members contract renewed, renewed without pay raise, renewed pay raise, renewed double pay raise depending
whether performance evaluated unacceptable least one three areas, acceptable
areas, excellent one area, excellent least two areas.
Let c1 , c2, c3 fractions time faculty member spends teaching, research,
service respectively. Let represent evaluation gets ith area. take values 0, 1,
2 depending whether evaluation unacceptable, acceptable, excellent. variable
depends probabilistically ci. reasonable assume conditionally independent
cj j given ci .
Let e represent contract renewal result. variable take values 0, 1, 2, 3 depending
whether contract renewed, renewed pay raise, renewed pay raise,
renewed double pay raise. e=1 23, base combination operator given
following table:

0
1
2
3

0
0
0
0
0

1
0
1
2
3

2
0
2
3
3

3
0
3
3
3

1. called exception independence assumption Pearl (1988).
2. called accountability assumption Pearl (1988). assumption always satisfied introducing
node represent causes (Henrion, 1987).

308

fiE XPLOITING C AUSAL NDEPENDENCE



B AYESIAN N ETWORK NFERENCE

So, fractions time faculty member spends three areas causally independent
w.r.t. contract renewal result.
traditional formulation Bayesian network need specify exponential,
number parents, number conditional probabilities variable. causal independence,
number conditional probabilities P (i jci ) linear m. causal independence
reduce complexity knowledge acquisition (Henrion, 1987; Pearl, 1988; Olesen et al., 1989;
Olesen & Andreassen, 1993). following sections show causal independence also
exploited computational gain.
4.1 Conditional Probabilities Convergent Variables
allows us exploit structure Bayesian network providing factorization joint probability distribution. section show causal independence used factorize
joint distributioneven further. initial factors algorithm form P (ejc1; : : :; cm).
want break simpler factors need table exponential m.
following proposition shows causal independence used this:

Proposition 1 Let e node BN let c1 ; c2; : : :; cm parents e. c1; c2; : : :; cm
causally independent w.r.t. e, conditional probability P (ejc1; : : :; cm) obtained
conditional probabilities P (i jci)

P (e=ffjc1; : : :; cm) =

X

ff1 :::ffk =ff

P (1 =ff1 jc1): : :P (m =ffmjcm );

(2)

value ff e. base combination operator e.
Proof:3 definition causal independence entails independence assertions

(1; fc2; : : :; cmgjc1) (1; 2jc1):
axiom weak union (Pearl, 1988, p. 84), (1; 2jfc1; : : :; cmg). Thus
mutually independent given fc1; : : :; cmg.
Also have, definition causal independence (1; fc2; : : :; cm gjc1),
P (1jfc1; c2; : : :; cmg) = P (1jc1)
Thus have:

P (e=ffjc1; : : :; cm)
= P (1 =ffjc1; : : :; cm)
X
=
P (1=ff1 ; : : :; m=ffm jc1; : : :; cm)
ff1 :::ff =ff
X
=
P (1=ff1 jc1; : : :; cm )P (2=ff2 jc1; : : :; cm) P (m=ffm jc1; : : :; cm)
ff1 :::ff =ff
X
=
P (1=ff1 jc1)P (2=ff2jc2) P (m =ffm jcm)
ff1 :::ff =ff
2
k

k

k

next four sections develop algorithm exploiting causal independence inference.
3. Thanks anonymous reviewer helping us simplify proof.

309

fiZ HANG & P OOLE

5. Causal Independence Heterogeneous Factorizations
section, shall first introduce operator combining factors contain convergent
variables. operator basic ingredient algorithm developed next three sections. Using operator, shall rewrite equation (2) form convenient use
inference introduce concept heterogeneous factorization.
Consider two factors f g . Let e1 , ..., ek convergent variables appear f
g , let list regular variables appear f g , let B list variables
appear f , let C list variables appear g . B C contain
convergent variables, well regular variables. Suppose base combination operator
ei. Then, combination f
g f g function variables e1, ..., ek variables
A, B , C . defined by:4

f
g (e1=X
ff1 ; : : :; ek =ffkX
; A; B; C )
=
:::
f (e1=ff11; : : :; ek =ffk1 ; A; B)
ff11 1 ff12 =ff1

ffk1 k ffk2 =ffk

g (e1=ff12; : : :; ek=ffk2; A; C );

(3)

value ffi ei . shall sometimes write f
g f (e1 ; : : :; ek ; A; B )
g (e1; : : :; ek ; A; C )
make explicit arguments f g .
Note base combination operators different convergent variables different.
following proposition exhibits basic properties combination operator
.
Proposition 2 1. f g share convergent variables, f
g simply multiplication f g . 2. operator
commutative associative.
Proof: first item obvious. commutativity
follows readily commutativity
multiplication base combination operators. shall prove associativity
special
case. general case proved following line reasoning.
Suppose f , g , h three factors contain one variable e variable convergent. need show (f
g )
h=f
(g
h). Let base combination operator e.
associativity , have, value ff e,

f
g )
h(e=ff)

(

=
=
=
=

X

f
g (e=ff4)h(e=ff3)
X
X
[
f (e=ff1 )g(e=ff2)]h(e=ff3 )
ff4 ff3 =ff ff1 ff2 =ff4
X
f (e=ff1)g (e=ff2 )h(e=ff3 )
ff1 ff2 ff3 =ff
X
X
f (e=ff1)[
g (e=ff2 )h(e=ff3)]
ff4 ff3 =ff

ff1 ff4 =ff

ff2ff3 =ff4

4. Note base combination operators summations indexed. convergent variable associated operator, always use binary operator associated corresponding convergent variable.
examples, ease exposition, use one base combination operator. one type
base combination operator (e.g., may use or, sum max different variables network),
keep track operators associated convergent variables. will, however, complicate
description.

310

fiE XPLOITING C AUSAL NDEPENDENCE

X

=

ff1 ff4 =ff



B AYESIAN N ETWORK NFERENCE

f (e=ff1)g
h(e=ff4)

f
(g
h)(e=ff):

=

proposition hence proved.2
following propositions give properties
correspond operations
exploited algorithm . proofs straight forward omitted.
Proposition 3 Suppose f g factors variable z appears f g ,

X

Xz
z

X

fg)

=

(

f
g )

=

(

(

(

z
X
z

f )g;
f )
g:

Proposition 4 Suppose f , g h factors g h share convergent variables,

g (f
h) = (gf )
h:

(4)

5.1 Rewriting Equation 2
Noticing contribution variable possible values e, define functions

fi(e; ci)

fi(e=ff; ci ) = P (i =ffjci);
value ff e. shall refer fi contributing factor ci e.
using operator
, rewrite equation (2) follows
P (ejc1; : : :; cm) =
mi=1 fi (e; ci):

(5)

interesting notice similarity equation (1) equation (5). equation (1)
conditional independence allows one factorize joint probability factors involve less
variables, equation (5) causal independence allows one factorize conditional probability
factors involve less variables. However, ways factors combined
different two equations.
5.2 Heterogeneous Factorizations
Consider Bayesian network Figure 1. factorizes joint probability P (a; b; c; e1; e2; e3)
following list factors:

P (a); P (b); P (c); P (e1ja; b; c); P (e2ja; b; c); P (e3je1; e2 ):
say factorization homogeneous factors combined way,
i.e., multiplication.
suppose ei convergent variables. conditional probabilities factorized follows:

P (e1ja; b; c)
P (e2ja; b; c)
P (e3 je1 ; e2)

=
=
=

f11 (e1; a)
f12 (e1 ; b)
f13 (e1; c);
f21 (e2; a)
f22 (e2 ; b)
f23 (e2; c);
f31 (e3; e1)
f32 (e3; e2 );
311

fiZ HANG & P OOLE

factor f11(e1 ; a), instance, contributing factor e1 .
say following list factors

f11(e1 ; a); f12(e1; b); f13(e1; c); f21(e2 ; a); f22(e2 ; b); f23(e2 ; c); f31(e3 ; e1); f32(e3 ; e2);
P (a); P (b); P (c)
(6)
constitute heterogeneous factorization P (a; b; c; e1; e2; e3) joint probability
obtained combining factors proper order using either multiplication operator
.
word heterogeneous signify fact different factor pairs might combined different ways. call fij heterogeneous factor needs combined
fik operator
combined factors multiplication. contrast,
call factors P (a), P (b), P (c) homogeneous factors.
shall refer heterogeneous factorization heterogeneous factorization represented
BN Figure 1. obvious heterogeneous factorization finer grain
homogeneous factorization represented BN.

6. Flexible Heterogeneous Factorizations Deputation
paper extends exploit finer-grain factorization. compute answer query
summing variables one one factorization .
correctness guaranteed fact factors homogeneous factorization
combined (by multiplication) order distributivity multiplication summations (see proof Theorem 1).
According Proposition 3, operator
distributive summations. However, factors
heterogeneous factorization cannot combined arbitrary order. example, consider heterogeneous factorization (6). correct combine f11(e1 ; a) f12 (e1; b) using
,
combine f31 (e3; e1 ) f32 (e3; e2 ) using
, correct combine f11 (e1; a) f31 (e3; e1)

. want combine latter two multiplication, combined sibling heterogeneous factors.
overcome difficulty, transformation called deputation performed BN.
transformation change answers queries. heterogeneous factorization
represented transformed BN flexible following sense:
heterogeneous factorization joint probability flexible if:
joint probability
=

multiplication homogeneous factors

combination (by
) heterogeneous factors:

(7)

property allows us carry multiplication homogeneous factors arbitrary order,
since
associative commutative, combination heterogeneous factors arbitrary order. conditions Proposition 4 satisfied, also exchange multiplication
combination
. guarantee conditions Proposition 4, elimination ordering needs
constrained (Sections 7 8).
heterogeneous factorization P (a; b; c; e1; e2; e3) given end previous section
flexible. Consider combining heterogeneous factors. Since operator
commutative
312

fiE XPLOITING C AUSAL NDEPENDENCE



B AYESIAN N ETWORK NFERENCE

c

b


e1

e2

e1

e2
e3
e3

Figure 2: BN Figure 1 deputation convergent variables.
associative, one first combine, i, fik s, obtaining conditional probability
ei , combine resulting conditional probabilities. combination

P (e1 ja; b; c)
P (e2 ja; b; c)
P (e3je1 ; e2)
multiplication

P (e1 ja; b; c)P (e2ja; b; c)P (e3je1; e2)
convergent variables e1 e2 appear one factor. Consequently, equation
(7) hold factorization flexible. problem arises convergent variable shared two factors siblings. example, want combine
f11 (e1; a) f31 (e3 ; e1) using
. order tackle problem introduce new deputation
variable heterogeneous factor contains single convergent variable.
Deputation transformation one apply BN make heterogeneous factorization represented BN flexible. Let e convergent variable. depute e make copy
e0 e, make parents e parents e0 , replace e e0 contributing factors e, make
e0 parent e, set conditional probability P (eje0 ) follows:

P (eje0 ) =

(

1
0

e = e0
otherwise

(8)

shall call e0 deputy e. deputy variable e0 convergent variable definition.
variable e, convergent deputation, becomes regular variable deputation.
shall refer new regular variable. contrast, shall refer variables regular
deputation old regular variables. conditional probability P (e0 je) homogeneous
factor definition. sometimes called deputing function written (e0; e) since
ensures e0 e always take value.
deputation BN obtained BN deputing convergent variables. deputation
BN, deputy variables convergent variables deputy variables convergent variables.
313

fiZ HANG & P OOLE

Figure 2 shows deputation BN Figure 1. factorizes joint probability

P (a; b; c; e1; e01; e2; e02; e3; e03)
homogeneous factors

P (a); P (b); P (c); I1(e01; e1); I2(e02; e2); I3(e03; e3);
heterogeneous factors

f11(e01 ; a); f12(e01; b); f13(e01 ; c); f21(e02 ; a); f22(e02; b); f23(e02; c); f31(e03; e1); f32(e03; e2):
factorization three important properties.
1. heterogeneous factor contains one one convergent variable. (Recall ei
longer convergent variables deputies are.)
2. convergent variable e0 appears one one homogeneous factor, namely
deputing function (e0; e).
3. Except deputing functions, none homogeneous factors contain convergent
variables.
properties shared factorization represented deputation BN.
Proposition 5 heterogeneous factorization represented deputation BN flexible.
Proof: Consider combination,
, heterogeneous factors deputation BN. Since
combination operator
commutative associative, carry combination following two steps. First convergent (deputy) variable e0 , combine heterogeneous factors contain e0 , yielding conditional probability P (e0 je ) e0 . combine resulting
conditional probabilities. follows first property mentioned different convergent variables e01 e02, P (e01 je1 ) P (e02 je2 ) share convergent variables. Hence
combination P (e0 je )s multiplication them. Consequently, combination,

, heterogeneous factors deputation BN multiplication conditional
probabilities convergent variables. Therefore,
0

0

0

0

joint probability variables deputation BN
= multiplication conditional probabilities variables
=

multiplication conditional probabilities regular variables

=

multiplication homogeneous factors

multiplication conditional probabilities convergent variables

combination (by
) heterogeneous factors:
proposition hence proved. 2
Deputation change answer query. precisely,
Proposition 6 posterior probability P (X jY =Y0 ) BN deputation.
314

fiE XPLOITING C AUSAL NDEPENDENCE



B AYESIAN N ETWORK NFERENCE

Proof: Let R, E , E 0 lists old regular, new regular, deputy variables deputation BN respectively. suffices show P (R; E ) original BN
deputation BN. new regular variable e, let e0 deputy. easy see quantity
P (e0; e)P (e0j ) deputation BN P (ej ) original BN. Hence,
e
e
e
0

0

P (R; EX) deputation BN
=
P (R; E; E 0)
E
X

=
P (rjr ) [P (eje)P (e0 je )]
E r2R
2E

eX
=
P (rjr ) [ (e0; e)P (e0je )]
r2R
e2E e


=
P (rjr ) P (eje )
0

0

0

0

0

r2R

=

proposition proved.

2

e2 E

P (R; E ) original BN:

7. Tidy Heterogeneous Factorizations
far, encountered heterogeneous factorizations correspond Bayesian networks.
following algorithm, intermediate heterogeneous factorizations necessarily correspond BNs. property combine form appropriate marginal probabilities. general intuition heterogeneous factors must combine sibling heterogeneous factors multiplied factors containing original convergent variable.
previous section, mentioned three properties heterogeneous factorization represented deputation BN, used first property show factorization flexible.
two properties qualify factorization tidy heterogeneous factorization, defined below.
Let z1 , z2 , ..., zk list variables deputation BN convergent (deputy)
variable e0 fz1; z2 ; : : :; zk g, corresponding new regular variable e. flexible heterogeneous factorization P (z1 ; z2; : : :; zk ) said tidy

1. convergent (deputy) variable e02fz1; z2; : : :; zk g, factorization contains deputing function (e0; e) homogeneous factor involves e0 .

2. Except deputing functions, none homogeneous factors contain convergent
variables.
stated earlier, heterogeneous factorization represented deputation BN tidy.
certain conditions, given Theorem 3, one obtain tidy factorization P (z2 ; : : :; zk )
summing z1 tidy factorization P (z1 ; z2; : : :; zk ) using following procedure.
Procedure sum-out1(F1 ; F2; z )



Inputs: F1 list homogeneous factors,
F2 list heterogeneous factors,
z variable.
315

fiZ HANG & P OOLE



Output: list heterogeneous factors list homogeneous factors.

1. Remove F1 factors contain z , multiply resulting in, say, f .
factors, set f =nil.

2. Remove F2 factors contain z , combine using
resulting
in, say, g . factors, set g =nil.

P f F .
1
z
P
Else add new (heterogeneous) factor z fg F2.
Return (F1; F2).

3. g =nil, add new (homogeneous) factor
4.
5.

Theorem 3 Suppose list homogeneous factors F1 list heterogeneous factors F2 constitute tidy factorization P (z1 ; z2; : : :; zk ). z1 either convergent variable, old regular
variable, new regular variable whose deputy list fz2; : : :; zk g, procedure
sum-out1(F1 ; F2; z1) returns tidy heterogeneous factorization P (z2 ; : : :; zk ).
proof theorem quite long hence given appendix.

8. Causal Independence Inference
task compute P (X jY =Y0 ) BN. According Proposition 6,
deputation BN.
elimination ordering consisting variables outside X [Y legitimate deputy
variable e0 appears corresponding new regular variable e. ordering found
using, minor adaptations, minimum deficiency search maximum cardinality search.
following algorithm computes P (X jY =Y0 ) deputation BN. called 1
extension .
Procedure 1 (F1; F2; X; Y; Y0; )





Inputs: F1 list homogeneous factors
deputation BN;
F2 list heterogeneous factors
deputation BN;
X list query variables;
list observed variables;
Y0 corresponding list observed values;
legitimate elimination ordering.
Output: P (X jY =Y0 ).

1. Set observed variables factors observed values.
2. empty,

Remove first variable z .
(F1; F2) = sum-out1(F1; F2; z). Endwhile
316

fiE XPLOITING C AUSAL NDEPENDENCE



B AYESIAN N ETWORK NFERENCE

3. Set h=multiplication factors F1
combination (by
) factors F2.
/* h function variables X . */
4. Return h(X )=

P h(X ). /* renormalization */
X

Theorem 4 output 1 (F1; F2; X; Y; Y0; ) indeed P (X jY =Y0 ).
Proof: Consider following modifications algorithm. First remove step 1. factor
h produced step 3 function variables X . Add new step step 3 sets
observed variables h observed values. shall first show modifications
change output algorithm show output modified algorithm
P (X jY =Y0 ).
Let f (y; ,), g (y; ,), h(y; z; ,) three functions variables. evident

f (y; ,)g (y; ,)jy=ff = f (y; ,)jy=ff g(y; ,)jy=ff;
X
X
[
h(y; z; ,)]jy=ff = [h(y; z; ,)jy=ff ]:
z

z

regular variable, also

f (y; ,)
g (y; ,)jy=ff = f (y; ,)jy=ff
g (y; ,)jy=ff :
Consequently, modifications change output procedure.
Since elimination ordering legitimate, always case deputy variable e0
summed out, neither corresponding new regular variable e. Let z1 , ..., zk remaining variables time execution algorithm. Then, e0 2fz1 ; : : :; zk g implies e2fz1 ; : : :; zk g. fact factorization represented deputation BN tidy
enable us repeatedly apply Theorem 3 conclude that, modifications, factor created
step 3 simply marginal probability P (X; ). Consequently, output P (X jY =Y0 ). 2
8.1 Example
subsection illustrates 1 walking example. Consider computing P (e2 je3=0)
deputation Bayesian network shown Figure 2. Suppose elimination ordering is: a, b,
c, e01, e02, e1, e03 . first step VE1 ,

F1 = fP (a); P (b); P (c); I1(e01; e1); I2(e02; e2); I3(e03; e3=0)g;
F2 = ff11(e01; a); f12(e01; b); f13(e01; c); f21(e02; a); f22(e02; b); f23(e02; c); f31(e03; e1); f32(e03; e2)g:
procedure enters while-loop sums variables one one.
summing a,
F1 = fP (b); P (c); I1(e01; e1); I2(e02; e2); I3(e03; e3=0)g;
F2 = ff12(e01; b); f13P(e01; c); f22(e02; b); f23(e02; c); f31(e03; e1); f32(e03; e2); 1(e01; e02)g;
1 (e01; e02) = P (a)f11(e01 ; a)f21(e02 ; a).
summing b,
F1 = fP (c); I1(e01; e1); I2(e02; e2); I3(e03; e3=0)g;
F2 = ff13(e01; c); f23P(e02; c); f31(e03; e1); f32(e03; e2); 1(e01; e02); 2(e01; e02)g;
2 (e01; e02) = b P (b)f12(e01 ; b)f22(e02; b).
317

fiZ HANG & P OOLE

summing c,
F1 = fI1(e01; e1); I2(e02; e2); I3(e03; e3=0)g;
F2 = ff31(e03; e1); fP
32(e03 ; e2); 1(e01 ; e02); 2(e01 ; e02); 3(e01 ; e02)g;
0
0
3 (e1; e2) = c P (c)f23 (e02; c)f13(e01 ; c).
summing e01 ,
F1 = fI2(e02; e2); I3(e03; e3=0)g;
F2 = ff31(e03; e1); fP
32(e03 ; e2); 4(e1 ; e02)g;
4 (e1; e02) = e I1(e01 ; e1)[ 1(e01; e02)
2 (e01; e02)
3 (e01; e03)].
1
summing e02 ,
F1 = fI3(e03; e3=0)g;
F2 = ff31(e03; e1); fP
32(e03 ; e2); 5(e1 ; e2)g;
5 (e1; e2) = e I2(e02 ; e2) 4(e1 ; e02).
2
summing e1 ,
F1 = fI3(e03; e3=0)g;
F2 = ff32(e03; e2); P6(e03; e2)g;
6 (e03; e2) = e1 f31(e03 ; e1) 5(e1 ; e2).
Finally, summing e03 ,
F 1 = ;;
F2 = f 7(e2)g; P
7 (e2) = e I3(e03 ; e3=0)[f32(e03; e2 )
6(e03; e2 )]. procedure enters step 3,
3
P
nothing example. Finally, procedure returns 7(e2 )= e2 7(e2 ),
P (e2je3 =0), required probability.
0

0

0

8.2 Comparing 1
comparing 1 , notice summing variable, combine
factors contain variable. However, factorization latter works
finer grain factorization used former. running example, latter works
factorization initially consists factors contain two variables; factorization former uses initially include factors contain five variables. hand, latter
uses operator
expensive multiplication. Consider, instance, calculating
f (e; a)
g(e; b). Suppose e convergent variable variables binary. operation requires 24 numerical multiplications 24 , 23 numerical summations. hand,
multiplying f (e; a) g (e; b) requires 23 numerical multiplications.

Despite expensiveness operator
, 1 efficient . shall provide
empirical evidence support claim Section 10. see simple example true,
consider BN Figure 3(1), e convergent variable. Suppose variables binary.
Then, computing P (e) using elimination ordering c1 , c2, c3, c4 requires 25 + 24 +
23 + 22=60 numerical multiplications (25 , 24) + (24 , 23 ) + (23 , 22 ) + (22 , 2)=30
numerical additions. hand, computing P (e) deputation BN shown Figure 3(2)
1 using elimination ordering c1, c2, c3 , c4, e0 requires 22 + 22 + 22 + 22 +
(322 + 22)=32 numerical multiplications 2 + 2 + 2 + 2 + (32 + 2)=16 numerical additions.
Note summing e0 requires 322 + 22 numerical multiplications summing
ci s, four heterogeneous factors, containing argument e0 . Combining
318

fiE XPLOITING C AUSAL NDEPENDENCE

c1

c3

c2



B AYESIAN N ETWORK NFERENCE

c1

c4

c3

c2

c4

e

e

e
(1)

c1

(2)

c3

c2
e1

c4
e2

c1

c2

c3

c4

e1

e2

e

e

3

e
(4)

(3)

Figure 3: BN, deputation transformations.
pairwise requires 322 multiplications. resultant factor needs multiplied deputing
factor (e0; e), requires 22 numerical multiplications.

9. Previous Methods
Two methods proposed previously exploiting causal independence speed inference general BNs (Olesen et al., 1989; Heckerman, 1993). use causal independence
transform topology BN. transformation, conventional algorithms CTP
used inference.
shall illustrate methods using BN Figure 3(1). Let base combination
operator e, let denote contribution ci e, let fi (e; ci) contributing factor ci
e.
parent-divorcing method (Olesen et al., 1989) transforms BN one Figure 3(3).
transformation, variables regular new variables e1 e2
possible values e. conditional probabilities e1 e2 given

P (e1 jc1; c2)=f1(e; c1)
f2 (e; c2);
P (e2 jc3; c4)=f3(e; c3)
f4 (e; c4):

conditional probability e given

P (e=ffje1=ff1; e2=ff2 ) = 1 ff=ff1 ff2,
value ff e, ff1 e1 , ff2 e2 . shall use PD refer algorithm first
performs parent-divorcing transformation uses inference.
319

fiZ HANG & P OOLE

temporal transformation Heckerman (1993) converts BN one Figure 3(4).
variables regular transformation newly introduced variables
possible values e. conditional probability e1 given

P (e1=ffjc1) = f1(1=ff; c1);
value ff e1 . i=2; 3; 4, conditional probability ei (e4 stands e) given

P (ei =ffjei,1 =ff1 ; ci) =

X

ff1 ff2 =ff

fi(e=ff2; ci);

possible value ff ei ff1 ei,1 . shall use TT refer algorithm first
performs temporal transformation uses inference.
factorization represented original BN includes factor contain five variables,
factors transformed BNs contain three variables. general, transformations lead finer-grain factorizations joint probabilities. PD TT
efficient .
However, PD TT efficient 1 . shall provide empirical evidence support
claim next section. illustrate considering calculating P (e).
Figure 3(3) using elimination ordering c1, c2, c3 , c4, e1 , e2 would require 23 + 22 +
23 + 22 + 23 + 22 =36 numerical multiplications 18 numerical additions.5
Figure 3(4) using elimination ordering c1 , e1 , c2, e2 , c3, e3 , c4 would require 22 + 23 + 22 +
23 + 22 + 23 + 22 =40 numerical multiplications 20 numerical additions. cases,
numerical multiplications additions performed 1 . differences drastic
complex networks, shown next section.
saving example may seem marginal. may reasonable conjecture that,
Olesons method produces families three elements, marginal saving hope
for; producing factors two elements rather cliques three elements. However, interacting
causal variables make difference extreme. example, use Olesons
method BN Figure 1, produce6 network Figure 4. triangulation
network least one clique four elements, yet 1 produce factor
two elements.
Note far computing P (e) networks shown Figure 3 concerned, 1
efficient PD, PD efficient TT, TT efficient . experiments
show true general.
5. exactly number operations required determine P (e) using clique-tree propagation
network. clique tree Figure 3(3) three cliques, one containing fc1 ; c2 ; e1 g, one containing fc3 ; c4 ; e2 g,
containing fe1 ; e2 ; eg. first clique contains 8 elements; construct requires 22 + 23 = 12 multiplications.
message needs sent third clique marginal e1 obtained summing c1
c2 . Similarly second clique. third clique 8 elements requires 12 multiplications construct.
order extract P (e) clique, need sum e1 e2 . shown one reason 1
efficient CTP VE; 1 never constructs factor three variables example. Note however,
advantage CTP cost building cliques amortized many queries.
6. Note need produce two variables represent noisy b. need two variables noise
applied case independent. Note noise network e1 = b c
need create one variable, also e1 e2 would variable (or least perfectly correlated).
case would need complicated example show point.

320

fiE XPLOITING C AUSAL NDEPENDENCE





B AYESIAN N ETWORK NFERENCE

b

e

c

11

e21

e

e

2

1

e3

Figure 4: result Applying Olesons method BN Figure 1.

10. Experiments
CPCS networks multi-level, multi-valued BNs medicine. created Pradhan
et al. (1994) based Computer-based Patient Case Simulation system (CPCS-PM) developed
Parker Miller (1987). Two CPCS networks7 used experiments. One
consists 422 nodes 867 arcs, contains 364 nodes. among largest
BNs use present time.
CPCS networks contain abundant causal independencies. matter fact, non-root
variable convergent variable base combination operator MAX. good test cases
inference algorithms exploit causal independencies.
10.1 CTP-based Approaches versus -based Approaches
seen previous section, one kind approach exploiting causal independencies
use transform BNs. Thereafter, inference algorithms, including CTP ,
used inference.
found coupling network transformation techniques CTP able carry
inference two CPCS networks used experiments. computer ran memory
constructing clique trees transformed networks. reported next subsection, however, combination network transformation techniques able answer
many queries.
paper proposed new method exploiting causal independencies. observed
causal independencies lead factorization joint probability finer-grain
factorization entailed conditional independencies alone. One extend inference algorithms, including CTP , exploit finer-grain factorization. paper extended
obtained algorithm called 1 . 1 able answer almost queries two
CPCS networks. conjecture, however, extension CTP would able carry
inference two CPCS networks all. resources 1 takes answer
query BN extension CTP would take construct clique tree
7. Obtained ftp://camis.stanford.edu/pub/pradhan.
V1.0.txt CPCS-networks/std1.08.5.

321

file names CPCS-LM-SM-K0-

fi50
45
40
35
30
25
20
15
10
5
0

Number queries

Number queries

Z HANG & P OOLE

"5ve1"
"5pd"
"5tt"
"5ve"

Number queries

0 1 2 3 4 5 6 7 8 9
CPU time seconds

50
45
40
35
30
25
20
15
10
5
0

"10ve1"
"10pd"
"10tt"
"10ve"

0 1 2 3 4 5 6 7 8 9
CPU time seconds

50
45
40
35
30
25
20
15
10
5
0

"15ve1"
"15pd"
"15tt"

0 1 2 3 4 5 6 7 8 9 10
CPU time seconds

Figure 5: Comparisons 364-node BN.

BN are, seen next subsection, queries two CPCS networks
1 able answer.
summary, CTP based approaches would able deal two CPCS
networks, -based approaches (to different extents).
10.2 Comparisons -based Approaches
subsection provides experimental data compare -based approaches namely PD, TT,
1 . also compare approaches determine much gained
exploiting causal independencies.
364-node network, three types queries one query variable five, ten, fifteen
observations respectively considered. Fifty queries randomly generated query
type. query passed algorithms nodes irrelevant pruned. general, observations mean less irrelevant nodes hence greater difficulty answer query.
CPU times algorithms spent answering queries recorded.
order get statistics algorithms, CPU time consumption limited ten seconds
memory consumption limited ten megabytes.
statistics shown Figure 5. charts, curve 5ve1, instance, displays
time statistics 1 queries five observations. Points X-axis represent CPU times
322

fi50
45
40
35
30
25
20
15
10
5
0



B AYESIAN N ETWORK NFERENCE

Number queries

Number queries

E XPLOITING C AUSAL NDEPENDENCE

"5ve1"
"5pd"
"5tt"
"5ve"

0 1 2 3 4 5 6 7 8 9
CPU time seconds

40
35
30
25
20
15
10
5
0

"10ve1"
"10pd"
"10tt"

0 1 2 3 4 5 6 7 8 9 10
CPU time seconds

Figure 6: Comparisons 422-node BN.
seconds. time point, corresponding point Y-axis represents number fiveobservation queries answered within time 1 .
see 1 able answer queries, PD TT able answer
ten-observation fifteen-observation queries. able answer majority
queries.
get feeling average performances algorithms, regard curves representing functions , instead x. integration, along -axis, curve 10PD, instance,
roughly total amount time PD took answer ten-observation queries PD
able answer. Dividing total number queries answered, one gets average time PD
took answer ten-observation query.
clear average, 1 performed significantly better PD TT, turn
performed much better . average performance PD five- ten-observation queries
roughly TT, slightly better fifteen-observation queries.
422-node network, two types queries five ten observations considered
fifty queries generated type. space time limits imposed
364-node networks. Moreover, approximations made; real numbers smaller 0.00001
regarded zero. Since approximations algorithms, comparisons
fair.
statistics shown Figure 6. curves 5ve1 10ve1 hardly visible
close -axis.
see average, 1 performed significantly better PD, PD performed significantly better TT, TT performed much better .
One might notice TT able answer thirty nine ten-observation queries,
1 PD able to. due limit memory consumption. see
next subsection, memory consumption limit increased twenty megabytes, 1 able
answer forty five ten-observation queries exactly ten seconds.
10.3 Effectiveness 1
established 1 efficient -based algorithm exploiting causal
independencies. section investigate effective 1 is.
323

fiZ HANG & P OOLE

422-node BN
Number queries

Number queries

364-node BN
50
45
40
35
30
25
20
15
10
5
0

"5ve1"
"10ve1"
"15ve1"
"20ve1"

0 1 2 3 4 5 6 7 8 9 10
CPU time seconds

50
45
40
35
30
25
20
15
10
5
0

"5ve1"
"10ve1"
"15ve1"

0

5 10 15 20 25 30 35 40
CPU time seconds

Figure 7: Time statistics 1 .
Experiments carried two CPCS networks answer question.
364-node network, four types queries one query variable five, ten, fifteen, twenty
observations respectively considered. Fifty queries randomly generated query
type. statistics times 1 took answer queries given left chart Figure
7. collecting statistics, ten MB memory limit ten second CPU time limit
imposed guide excessive resource demands. see fifty five-observation queries
network answered less half second. Forty eight ten-observation queries,
forty five fifteen-observation queries, forty twenty-observation queries answered one
second. is, however, one twenty-observation query 1 able answer within
time memory limits.
364-node network, three types queries one query variable five, ten, fifteen,
observations respectively considered. Fifty queries randomly generated query
type. Unlike previous section, approximations made. twenty MB memory limit
forty-second CPU time limit imposed. time statistics shown right hand side
chart. see 1 able answer queries majority queries
answered little time. are, however, three fifteen-observation queries 1 able
answer.

11. Conclusions
paper concerned exploit causal independence exact BN inference. Previous approaches (Olesen et al., 1989; Heckerman, 1993) use causal independencies transform
BNs. Efficiency gained inference easier transformed BNs original
BNs.
new method proposed paper. basic idea. Bayesian network
viewed representing factorization joint probability multiplication list
conditional probabilities. studied notion causal independence enables one
factorize conditional probabilities combination even smaller factors consequently
obtain finer-grain factorization joint probability.
propose extend inference algorithms make use finer-grain factorization.
paper extended algorithm called . Experiments shown extended algo324

fiE XPLOITING C AUSAL NDEPENDENCE



B AYESIAN N ETWORK NFERENCE

rithm, 1 , significantly efficient one first performs Olesen et al.s Heckermans
transformation apply .
choice instead widely known CTP algorithm due ability work
networks CTP cannot deal with. matter fact, CTP able deal networks
used experiments, even Olesen et al.s Heckermans transformation. hand,
1 able answer almost randomly generated queries majority queries
answered little time. would interesting extend CTP make use finer-grain
factorization mentioned above.
seen previous section, queries, especially 422-node network,
took 1 long time answer. also queries 1 able answer.
queries, approximation must. employed approximation technique comparing
algorithms 422-node network. technique captures, extent, heuristic ignoring
minor distinctions. future work, developing way bound error technique
anytime algorithm based technique.

Acknowledgements
grateful Malcolm Pradhan Gregory Provan sharing us CPCS networks.
also thank Jack Breese, Bruce DAmbrosio, Mike Horsch, Runping Qi, Glenn Shafer
valuable discussions, Ronen Brafman, Chris Geib, Mike Horsch anonymous reviewers helpful comments. Mr. Tak Yin Chan great help experimentations.
Research supported NSERC Grant OGPOO44121, Institute Robotics Intelligent
Systems, Hong Kong Research Council grant HKUST658/95E Sino Software Research Center
grant SSRC95/96.EG01.

Appendix A. Proof Theorem 3
Theorem 3 Suppose list homogeneous factors F1 list heterogeneous factors F2 constitute tidy factorization P (z1 ; z2; : : :; zk ). z1 either convergent variable, old regular
variable, new regular variable whose deputy list fz2 ; : : :; zk g, procedure
sum-out1(F1 ; F2; z1) returns tidy heterogeneous factorization P (z2 ; : : :; zk ).
Proof: Suppose f1 , ..., fr heterogeneous factors g1, ..., gs homogeneous
factors. Also suppose f1 , ..., fl , g1, ..., gm factors contain z1 .

P (z2 ; : : :; zk )

=

=

=

=

X

P (z1 ; z2; : : :; zk)

z1

X
z1


rj=1fj

X



i=1

gi


lj=1fj )
(
rj=l+1 fj )]







gi
i=1 i=m+1


X l


[(
j =1 fj
gi)
(
rj=l+1 fj )]
gi
z1
i=1
i=m+1
z1

[(

325

gi

(9)

fiZ HANG & P OOLE

=

X





l
r
[(

j=1 fj gi)
(
j=l+1fj )]
gi ;
z1
i=1
i=m+1

(10)

equation (10) due Proposition 3. Equation (9) follows Proposition 4. matter
Q g due
fact, z1 convergent variable, convergent variable
i=1
first condition tidiness. condition Proposition 4 satisfied z1 appear
fl+1 , ..., fr . hand, z1 old regular variable new regular variable whose
Q g contains convergent variables due
deputy appear list z2 , ..., zk ,
i=1
second condition tidiness. condition Proposition 4 satisfied. thus proved
sum-out1(F1 ; F2; z1) yields flexible heterogeneous factorization P (z2 ; : : :; zk ).
Let e0 convergent variable list z2 , ..., zk . z1 cannot corresponding new regular variable e. Hence factor (e0; e) touched sum-out1(F1 ; F2; z1). Consequently,
show new factor created sum-out1(F1 ; F2; z1) either heterogeneous factor
homogeneous factor contain convergent variable, factorization returned tidy.
Suppose sum-out1(F1 ; F2; z1) create new homogeneous factor. heterogeneous factors F1 contain z1 . z1 convergent variable, say e0, (e0; e) homoP
geneous factor contain e0 . new factor e (e0; e), contain convergent
variables. z1 old regular variable new regular variable whose deputy list z2 ,
..., zk , factors contain z1 contain convergent variables. Hence new factor
contain convergent variables. theorem thus proved. 2
0

References
Arnborg, S., Corneil, D. G., & Proskurowski, A. (1987). Complexity finding embedding
k-tree. SIAM J. Alg. Disc. Meth., 8(2), 277284.
Baker, M., & Boult, T. (1990). Pruning Bayesian networks efficient computation. Proc. Sixth
Conf. Uncertainty Artificial Intelligence, pp. 257264 Cambridge, Mass.
Bertele, U., & Brioschi, F. (1972). Nonserial dynamic programming, Vol. 91 Mathematics
Science Engineering. Academic Press.
Boutilier, C., Friedman, N., Goldszmidt, M., & Koller, D. (1996). Context-specific independence
Bayesian networks. E. Horvitz F. Jensen (Ed.), Proc. Twelthth Conf. Uncertainty
Artificial Intelligence, pp. 115123 Portland, Oregon.
Cooper, G. F. (1990). computational complexity probabilistic inference using Bayesian belief
networks. Artificial Intelligence, 42(2-3), 393405.
Dagum, P., & Galper, A. (1993). Additive belief-network models. D. Heckerman A. Mamdani
(Ed.), Proc. Ninth Conf. Uncertainty Artificial Intelligence, pp. 9198 Washington D.C.
DAmbrosio (1995). Local expression languages probabilistic dependence. International Journal Approximate Reasoning, 13(1), 6181.
DAmbrosio, B. (1994). Symbolic probabilistic inference large BN2O networks. R. Lopez de
Mantaras D. Poole (Ed.), Proc. Tenth Conf. Uncertainty Artificial Intelligence, pp.
128135 Seattle.
326

fiE XPLOITING C AUSAL NDEPENDENCE



B AYESIAN N ETWORK NFERENCE

Dechter, R. (1996). Bucket elimination: unifying framework probabilistic inference. E.
Horvits F. Jensen (Ed.), Proc. Twelthth Conf. Uncertainty Artificial Intelligence, pp.
211219 Portland, Oregon.
Dez, F. J. (1993). Parameter adjustment bayes networks. generalized noisy or-gate. D.
Heckerman A. Mamdani (Ed.), Proc. Ninth Conf. Uncertainty Artificial Intelligence,
pp. 99105 Washington D.C.
Duda, R. O., Hart, P. E., & Nilsson, N. J. (1976). Subjective Bayesian methods rule-based inference systems. Proc. AFIPS Nat. Comp. Conf., pp. 10751082.
Geiger, D., & Heckerman, D. (1996). Knowledge representation inference similarity networks
Bayesian multinets. Artificial Intelligence, 82, 4574.
Geiger, D., Verma, T., & Pearl, J. (1990). d-separation: theorems algorithms. M. Henrion
et. al. (Ed.), Uncertainty Artificial Intelligence 5, pp. 139148. North Holland, New York.
Good, I. (1961). causal calculus (i). British Journal Philosophy Science, 11, 305318.
Heckerman, D. (1993). Causal independence knowledge acquisition inference. Proc.
Ninth Conference Uncertainty Artificial Intelligence, pp. 122127.
Heckerman, D., & Breese, J. (1994). new look causal independence. Proc. Tenth
Conference Uncertainty Artificial Ingelligence, pp. 286292.
Henrion, M. (1987). practical issues constructing belief networks. L. Kanal T. Levitt
J. Lemmer (Ed.), Uncertainty Artificial Intelligence, pp. 161174. North-Holland.
Howard, R. A., & Matheson, J. E. (1981). Influence diagrams. Howard, R. A., & Matheson,
J. (Eds.), Principles Applications Decision Analysis, pp. 720762. Strategic Decisions Group, CA.
Jensen, F. V., Lauritzen, S. L., & Olesen, K. G. (1990). Bayesian updating causal probabilistic
networks local computations. Computational Statistics Quaterly, 4, 269282.
Kim, J., & Pearl, J. (1983). computational model causal diagnostic reasoning inference
engines. Proc. Eighth International Joint Conference Artificial Intelligence, pp.
190193 Karlsruhe, Germany.
Kjrulff, U. (1990). Triangulation graphs - algorithms giving small total state space. Tech. rep.
R 90-09, Department Mathematics Computer Science, Strandvejen, DK 9000 Aalborg,
Denmark.
Lauritzen, S. L., Dawid, A. P., Larsen, B. N., & Leimer, H. G. (1990). Independence properties
directed markov fields. Networks, 20, 491506.
Lauritzen, S. L., & Spiegelhalter, D. J. (1988). Local computations probabilities graphical
structures application expert systems. Journal Royal Statistical Society,
Series B, 50(2), 157224.
327

fiZ HANG & P OOLE

Li, Z., & DAmbrosio, B. (1994). Efficient inference Bayes networks combinatorial optimization problem. International Journal Approximate Reasoning, 11(1), 5581.
Olesen, K. G., & Andreassen, S. (1993). Specification models large expert systems based
causal probabilistic networks. Artificial Intelligence Medicine, 5, 269281.
Olesen, K. G., Kjrulff, U., Jensen, F., Falck, B., Andreassen, S., & Andersen, S. K. (1989).
munin network median nerve - case study loops. Applied Artificial Intelligence,
3, 384403.
Parker, R., & Miller, R. (1987). Using causal knowledge creat simulated patient cases: CPSC
project extension Internist-1. Proc. 11th Symp. Comp. Appl. Medical Care, pp.
473480 Los Alamitos, CA. IEEE Comp Soc Press.
Pearl, J. (1988). Probabilistic Reasoning Intelligent Systems: Networks Plausible Inference.
Morgan Kaufmann, San Mateo, CA.
Poole, D. (1993). Probabilistic Horn abduction Bayesian networks. Artificial Intelligence, 64(1),
81129.
Pradhan, M., Provan, G., Middleton, B., & Henrion, M. (1994). Knowledge engineering large
belief networks. R. Lopez de Mantaras D. Poole (Ed.), Proc. Tenth Conf. Uncertainty
Artificial Intelligence, pp. 484490 Seattle.
Shachter, R. D., DAmbrosio, B. D., & Del Favero, B. D. (1990). Symbolic probabilistic inference
belief networks. Proc. 8th National Conference Artificial Intelligence, pp. 126131
Boston. MIT Press.
Shafer, G., & Shenoy, P. (1990). Probability propagation. Annals Mathematics Artificial
Intelligence, 2, 327352.
Shortliffe, E., & Buchanan, G. B. (1975). model inexact reasoning medicine. Math. Biosci.,
23, 351379.
Srinivas, S. (1993). generalization noisy-or model. Proc. Ninth Conference Uncertainty Artificial Intelligence, pp. 208215.
Tarjan, R. E., & Yannakakis, M. (1984). Simple linear time algorithm test chordality graphs,
test acyclicity hypergraphs, selectively reduce acyclic hypergraphs. SIAM J. Comput.,
13, 566579.
Zhang, N. L., & Poole, D. (1994). simple approach Bayesian network computations. Proc.
Tenth Canadian Conference Artificial Intelligence, pp. 171178.

328

fiJournal Artificial Intelligence Research 5 (1996) 53-94

Submitted 3/95; published 9/96

Cue Phrase Classification Using Machine Learning
Diane J. Litman

AT&T Labs - Research, 600 Mountain Avenue
Murray Hill, NJ 07974 USA

diane@research.att.com

Abstract

Cue phrases may used discourse sense explicitly signal discourse structure,
also sentential sense convey semantic rather structural information. Correctly
classifying cue phrases discourse sentential critical natural language processing
systems exploit discourse structure, e.g., performing tasks anaphora resolution plan recognition. paper explores use machine learning classifying
cue phrases discourse sentential. Two machine learning programs (cgrendel
C4.5) used induce classification models sets pre-classified cue phrases
features text speech. Machine learning shown effective technique
automating generation classification models, also improving
upon previous results. compared manually derived classification models already
literature, learned models often perform higher accuracy contain new
linguistic insights data. addition, ability automatically construct classification models makes easier comparatively analyze utility alternative feature
representations data. Finally, ease retraining makes learning approach
scalable exible manual methods.

1. Introduction

Cue phrases words phrases may sometimes used explicitly signal discourse
structure text speech. particular, used discourse sense, cue
phrase explicitly conveys structural information. used sentential sense, cue
phrase instead conveys semantic rather structural information. following examples
(taken spoken language corpus described Section 2) illustrate sample
discourse sentential usages cue phrases \say" \further":
Discourse
\: : : might concept say researcher worked fifteen years
certain project : : : "
\Further, crucial AI probably expert databases well : : : "
Sentential
\: : : let say bears strong resemblance much work that's
done semantic nets even frames."
\: : : place even stranger away : : : "
example, used discourse sense, cue phrase \say" conveys structural
information example beginning. used sentential sense, \say"
convey structural information instead functions verb.
c 1996 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiLitman

ability correctly classify cue phrases discourse sentential critical
natural language processing systems need recognize convey discourse structure,
tasks improving anaphora resolution (Grosz & Sidner, 1986; Reichman, 1985).
Consider following example, taken corpus described
Section 21 :
system attempts hold rules, say expert database expert system,
expect hold rules fact apply us
appropriate situations.
example, cue phrases \say" \then" discourse usages, explicitly
signal boundaries intervening subtopic discourse structure. Furthermore,
referents noun phrases \the system," \an expert database," \an expert
system" possible referents pronoun \it." structural information
conveyed cue phrases, system determine \the system" relevant
interpreting pronoun \it," \an expert database" \an expert system"
occur within embedded (and concluded) subtopic. Without cue phrases,
reasoning required determine referent \the system" intended referent
\it" would much complex.
Correctly classifying cue phrases discourse sentential important natural
language processing tasks well. discourse/sentential distinction used
improve naturalness synthetic speech text-to-speech systems (Hirschberg, 1990).
Text-to-speech systems generate synthesized speech unrestricted text. cue phrase
classified discourse sentential using features input text,
synthesized using different intonational models discourse sentential usages.
addition, explicitly identifying rhetorical relationships, discourse usages cue
phrases used improve coherence multisentential texts natural language
generation systems (Zuckerman & Pearl, 1986; Moser & Moore, 1995). Cue phrases
also used reduce complexity discourse processing areas argument
understanding (Cohen, 1984) plan recognition (Litman & Allen, 1987; Grosz & Sidner,
1986).
problem cue phrase classification often noted (Grosz & Sidner,
1986), recently, models classifying cue phrases neither developed evaluated
based careful empirical analyses. Even though literature suggests features
might useful cue phrase classification, quantitative analyses actual
classification algorithms use features (nor suggestions different types
features might combined). systems recognize generate cue phrases simply
assume discourse uses utterance clause initial (Reichman, 1985; Zuckerman &
Pearl, 1986). empirical studies showing intonational prominence
certain word classes varies respect discourse function (Halliday & Hassan, 1976;
Altenberg, 1987), studies investigate cue phrases per se.
address limitations, Hirschberg Litman (1993) conducted several empirical
studies specifically addressing cue phrase classification text speech. Hirschberg
Litman pre-classified set naturally occurring cue phrases, described cue phrase
terms prosodic textual features (the features posited literature easy
1. example also described detail Hirschberg Litman (1993).

54

fiCue Phrase Classification Using Machine Learning

automatically code), manually examined data construct classification models
best predicted classifications feature values.
paper examines utility machine learning automating construction
models classifying cue phrases empirical data. set experiments
described use two machine learning programs, cgrendel (Cohen, 1992, 1993)
C4.5 (Quinlan, 1993), induce classification models sets pre-classified cue phrases
features. features, classes training examples used studies
Hirschberg Litman (1993), well additional features, classes training examples, given input machine learning programs. results evaluated
quantitatively qualitatively, comparing error rates content
manually derived learned classification models. experimental results show
machine learning indeed effective technique, automating generation
classification models, also improving upon previous results. accuracy
learned classification models often higher accuracy manually derived
models, learned models often contain new linguistic implications. learning
paradigm also makes easier compare utility different knowledge sources,
update model given new features, classes, training data.
next section summarizes previous work cue phrase classification. Section 3
describes machine learning approach cue phrase classification taken
paper. particular, section describes four sets experiments use machine
learning automatically induce cue phrase classification models. types inputs
outputs machine learning programs presented, methodologies
used evaluate results. Section 4 presents discusses experimental results,
highlights many benefits machine learning approach. Section 5 discusses
practical utility results paper. Finally, Section 6 discusses use machine
learning studies discourse, Section 7 concludes.

2. Previous Work Classifying Cue Phrases
section summarizes Hirschberg's Litman's empirical studies classification
cue phrases speech text (Hirschberg & Litman, 1987, 1993; Litman & Hirschberg,
1990). Hirschberg's Litman's data (cue phrases taken corpora recorded
transcribed speech, classified discourse sentential, coded using speech-based
text-based features) used create input machine learning experiments. Hirschberg's Litman's results (performance figures manually developed cue
phrase classification models) used benchmark evaluating performance
classification models produced machine learning.
first study Hirschberg Litman investigated usage cue phrase \now"
multiple speakers radio call-in show (Hirschberg & Litman, 1987). classification
model based prosodic features developed based manual analysis \training"
set 48 examples \now", evaluated previously unseen test set 52 examples
\now". follow-up study (Hirschberg & Litman, 1993), Hirschberg Litman tested
classification model larger set cue phrases, namely single word cue phrases
technical keynote address single speaker. corpus yielded 953 instances 34
55

fiLitman

Prosodic Model:

composition intermediate phrase = alone
elseif composition intermediate phrase = :alone
position intermediate phrase = first
accent = deaccented
elseif accent = L*
elseif accent = H*
elseif accent = complex
elseif position intermediate phrase = :first

discourse

discourse

discourse

sentential

sentential

sentential

(1)
(2)
(3)
(4)
(5)
(6)
(7)
(8)

Textual Model:

preceding orthography = true
elseif preceding orthography = false

(9)
(10)

discourse
sentential

Figure 1: Decision tree representation manually derived classification models
Hirschberg Litman.
different single word cue phrases derived literature.2 Hirschberg Litman also
used cue phrases first 17 minutes corpus develop complementary cue
phrase classification model based textual features (Litman & Hirschberg, 1990),
tested full corpus (Hirschberg & Litman, 1993). first study
referred \now" study, follow-up study \multiple cue phrase" study.
Note term \multiple" means 34 different single word cue phrases (as opposed
cue phrase \now") considered, cue phrases consisting multiple
words (e.g. \by way") considered.
method Hirschberg Litman used develop prosodic textual classification models follows. first separately classified example cue phrase
data discourse, sentential ambiguous listening recording reading
transcription.3 example also described set prosodic textual features.4
Previous observations literature correlating discourse structure prosodic information, discourse usages cue phrases initial position clause, contributed
choice features. set classified described examples examined
order manually develop classification models shown Figure 1. models
shown using decision trees ease comparison results C4.5
explained below.
Prosody described using Pierrehumbert's theory English intonation (Pierrehumbert, 1980). Pierrehumbert's theory, intonational contours described sequences
low (L) high (H) tones fundamental frequency (F0) contour (the physical
2. Figure 2 contains list 34 cue phrases. Hirschberg Litman (1993) provide full details regarding
distribution cue phrases. frequent cue phrase \and", occurs 320 times.
next frequent cue phrase \now", occurs 69 times. \But," \like," \or" \so" also
occur fifty times. four least frequent cue phrases { \essentially," \otherwise," \since"
\therefore" { occur 2 times.
3. class ambiguous introduced multiple cue phrase study (Hirschberg & Litman, 1993;
Litman & Hirschberg, 1990).
4. Although limited set textual features noted \now" data, analysis \now" data
yield textual classification model.

56

fiCue Phrase Classification Using Machine Learning

correlate pitch). Intonational contours domain intonational phrase.
finite-state grammar describes set tonal sequences intonational phrase.
well-formed intonational phrase consists one intermediate phrases followed
boundary tone. well-formed intermediate phrase one pitch accents followed
phrase accent. Boundary tones phrase accents consist single tone,
pitch accents consist either single tone pair tones. two simple pitch
accents (H* L*) four complex accents (L*+H, L+H*, H*+L, H+L*).
* indicates tone aligned stressed syllable associated lexical item.
Note every stressed syllable accented. Lexical items bear pitch accents
called accented, called deaccented.
Prosody manually transcribed Hirschberg examining fundamental frequency (F0) contour, listening recording. transcription process
performed separately process discourse/sentential classification. produce
F0 contour, recording corpus digitized pitch-tracked using speech analysis software. resulted display F0 x-axis represented time
y-axis represented frequency Hz. Various phrase final characteristics (e.g., phrase accents,
boundary tones, well pauses syllable lengthening) helped identify intermediate
intonational phrases, peaks valleys display F0 contour helped
identify pitch accents. Similar manual transcriptions prosodic phrasing accent
shown reliable across coders (Pitrelli, Beckman, & Hirschberg, 1994).
prosody coded, Hirschberg Litman represented every cue phrase terms
following prosodic features.5 Accent corresponded pitch accent (if any)
associated cue phrase. intonational intermediate phrases
containing cue phrase, feature composition phrase represented whether
cue phrase alone phrase (the phrase contained cue phrase,
cue phrase cue phrases). Position phrase represented whether cue
phrase first (the first lexical item prosodic phrase unit { possibly preceded
cue phrases) not.
textual features used multiple cue phrase study (Hirschberg & Litman, 1993;
Litman & Hirschberg, 1990) extracted automatically transcript. part
speech cue phrase obtained running program tagging words one
approximately 80 parts speech (Church, 1988) transcript.6 Several characteristics
cue phrase's immediate context also noted, particular, whether immediately preceded succeeded orthography (punctuation paragraph boundary),
whether immediately preceded succeeded lexical item corresponding
another cue phrase.
background, classification models shown Figure 1 explained.
prosodic model uniquely classifies cue phrase using features composition
intermediate phrase, position intermediate phrase, accent. cue phrase
uttered single intermediate phrase { possibly cue phrases (i.e., line (1)
Figure 1), larger intermediate phrase initial position (possibly preceded
5. features used Figure 1 discussed here.
6. Another syntactic feature - dominating constituent - obtained running parser Fidditch (Hindle,
1989) transcript. However, since feature appear models manually derived
training data (Litman & Hirschberg, 1990), feature pursued.

57

fiLitman

Model
Classifiable Cue Phrases (N=878) Classifiable Non-Conjuncts (N=495)
Prosodic
24.6 3.0
14.7 3.2
Textual
19.9 2.8
16.1 3.4
Default Class
38.8 3.2
40.8 4.4

Table 1: 95% confidence intervals error rates (%) manually derived classification models Hirschberg Litman, testing data (multiple cue phrase corpus).
cue phrases) L* accent deaccented, classified discourse. part
larger intermediate phrase either initial position H* complex accent,
non-initial position, sentential. textual model classifies cue phrases using
single feature preceding orthography.7 cue phrase preceded type
orthography, classified discourse; otherwise, cue phrase classified sentential.
prosodic model used classify cue phrase training data, i.e.,
100 examples \now" model developed, error rate 2.0%.8
error rate textual model training examples multiple cue phrase
corpus 10.6% (Litman & Hirschberg, 1990).
prosodic textual models evaluated quantifying performance
correctly classifying example cue phrases two test sets data, shown rows
labeled \Prosodic" \Textual" Table 1. test set subset 953 examples
multiple cue phrase corpus. first test set (878 examples) consists
classifiable cue phrases, i.e., cue phrases Hirschberg Litman classified
discourse classified sentential. Note cue phrases Hirschberg
Litman classified ambiguous unable agree upon included
classifiable subset. (These cue phrases considered learning experiments
described Section 4.4, however.) second test set, classifiable non-conjuncts
(495 examples), created classifiable cue phrases removing instances
\and", \or" \but". subset considered particularly reliable since 97.2% nonconjuncts classifiable compared 92.1% example cue phrases. error rate
prosodic model 24.6% classifiable cue phrases 14.7% classifiable
non-conjuncts (Hirschberg & Litman, 1993). error rate textual model 19.9%
classifiable cue phrases 16.1% classifiable non-conjuncts (Hirschberg &
Litman, 1993). last row table shows error rates simple \Default Class"
baseline model always predicts frequent class corpus (sentential).
rates 38.8% classifiable cue phrases 40.8% classifiable non-conjuncts.
7. classification model based part-of-speech also developed (Litman & Hirschberg, 1990;
Hirschberg & Litman, 1993); however, perform well model based orthography
(the error rate part-of-speech model 36.1% larger test set, opposed 19.9%
orthographic model). Furthermore, model combined orthography part-of-speech performed
comparably simpler orthographic model (Hirschberg & Litman, 1993). Hirschberg Litman
also preliminary observations suggesting adjacency cue phrases might prove useful.
8. Following Hirschberg Litman (1993), original 48- 52-example sets (Hirschberg & Litman,
1987) combined.

58

fiCue Phrase Classification Using Machine Learning

Although computed Hirschberg Litman, Table 1 also associates margins errors error percentage, used compute confidence intervals (Freedman,
Pisani, & Purves, 1978). (The margin error 2 standard errors 95% confidence
interval using normal table.) lower bound confidence interval computed
subtracting margin error error rate, upper bound computed
adding margin error. Thus, 95% confidence interval prosodic model
classifiable cue phrase test set (21.6%, 27.6%). Analysis confidence intervals
indicates improvement prosodic textual models default
model significant. example, upper bounds error rates prosodic
textual models classifiable cue phrase test set - 27.6% 22.7% - lower
lower bound default class error rate - 35.6%. methodology using statistical inference determine whether differences error rates significant discussed
fully Section 3.3.

3. Experiments using Machine Learning

section describes experiments use machine learning programs C4.5 (Quinlan,
1993) cgrendel (Cohen, 1992, 1993) automatically induce cue phrase classification
models. cgrendel C4.5 similar learning methods
neural networks cart (Brieman, Friedman, Olshen, & Stone, 1984) induce
classification models preclassified examples. program takes following inputs:
names classes learned, names possible values fixed set features,
training data (i.e., set examples class feature values specified).
output program classification model, expressed C4.5 decision tree
cgrendel ordered set if-then rules. cgrendel C4.5 learn
classification models using greedy search guided \information gain" metric.
first group machine learning experiments replicate training testing conditions used Hirschberg Litman (1993) (reviewed previous section), support
direct comparison manual machine learning approaches. second group
experiments evaluate utility training larger amounts data feasible
manual analysis Hirschberg Litman. third set experiments allow
machine learning algorithms distinguish among 34 cue phrases, evaluate utility developing classification models specialized particular cue phrases. fourth set
experiments consider examples multiple cue phrase corpus,
classifiable cue phrases. set experiments attempt predict third classification
unknown, well classifications discourse sentential. Finally, within
four sets experiments, individual experiment learns classification model using
different feature representation training data. experiments consider features
isolation, comparatively evaluate utility individual feature classification.
experiments consider linguistically motivated sets features, gain insight
feature interactions.

3.1 Machine Learning Inputs

section describes inputs machine learning programs, namely,
names classifications learned, names possible values fixed set
59

fiLitman

Classification
Judge1/Judge2
Cue Phrases
Non-Conjuncts

Total
953
509

Classifiable Cue Phrases
Discourse Sentential
D/D
S/S
341
537
202
293

Unknown
?/? D/S S/D D/? S/? ?/D ?/S
59
5
0
0
0
5
6
11
1
0
0
0
0
2

Table 2: Determining classification cue phrases.
features, training data specifying class feature values example
training set.
3.1.1 Classifications

first input learning program specifies names fixed set classifications.
Hirschberg Litman's 3-way classification cue phrases 2 judges (Hirschberg &
Litman, 1993) transformed classifications used machine learning programs
shown Table 2. Recall Section 2 judge classified cue phrase
discourse, sentential, ambiguous; classifications shown D, S, ? Table 2.
discussed Section 2, classifiable cue phrases cue phrases judges
classified either discourse sentential usages. Thus, machine learning
experiments, cue phrase assigned classification discourse judges classified
discourse (D/D, shown column 3 Table 2). Similarly, cue phrase assigned
classification sentential judges classified sentential (S/S, shown column
4). 878 (92.1%) 953 examples full corpus classifiable, 495 (97.2%)
509 non-conjuncts classifiable.
machine learning experiments, third cue phrase classification also
considered. particular, cue phrase assigned classification unknown
Hirschberg Litman classified ambiguous (?/?, shown column 5),
unable agree upon classification (D/S, S/D, D/?, S/?, ?/D, ?/S, shown
columns 6-11). full corpus, 59 cue phrases (6.2%) judged ambiguous
judges (?/?). 5 cases (.5%) true disagreement (D/S). 11 cue phrases
(1.2%) judged ambiguous first judge classified second judge (?/D
?/S). conjunctions \and," \or" \but" removed corpus,
11 examples (2.2%) judged ambiguous judges: 3 instances \actually,"
2 instances \because" \essentially," 1 instance \generally," \indeed,"
\like" \now." 1 case (.2%) true disagreement (an instance \like").
2 cue phrases (.4%) - instance \like" \otherwise" - judged ambiguous
first judge.
3.1.2 Features

second component input learning program specifies names potential
values fixed set features. set primitive features considered learning
experiments shown Figure 2. Feature values either numeric value one
fixed set user-defined symbolic values. feature representation shown follows
representation Hirschberg Litman except noted. Length intonational phrase (P60

fiCue Phrase Classification Using Machine Learning

Prosodic Features

{ length intonational phrase (P-L): integer.
{ position intonational phrase (P-P): integer.
{ length intermediate phrase (I-L): integer.
{ position intermediate phrase (I-P): integer.
{ composition intermediate phrase (I-C): only, cue phrases, other.
{ accent (A): H*, L*, L*+H, L+H*, H*+L, H+L*, deaccented, ambiguous.
{ accent* (A*): H*, L*, complex, deaccented, ambiguous.
Textual Features
{ preceding cue phrase (C-P): true, false, NA.
{ succeeding cue phrase (C-S): true, false, NA.
{ preceding orthography (O-P): comma, dash, period, paragraph, false, NA.
{ preceding orthography* (O-P*): true, false, NA.
{ succeeding orthography (O-S): comma, dash, period, false, NA.
{ succeeding orthography* (O-S*): true, false, NA.
{ part-of-speech (POS): article, coordinating conjunction, cardinal numeral, subordinating conjunction,
preposition, adjective, singular mass noun, singular proper noun, intensifier, adverb, verb base form,
NA.

Lexical Feature

{ token (T): actually, also, although, and, basically, because, but, essentially, except, finally, first, further,

generally, however, indeed, like, look, next, no, now, ok, or, otherwise, right, say, second, see, similarly,
since, so, then, therefore, well, yes.

Figure 2: Representation features, use C4.5 cgrendel.
L) length intermediate phrase (I-L) represent number words intonational
intermediate phrases containing cue phrase, respectively. feature coded
\now" data, coded (although used) later multiple cue phrase
data. Position intonational phrase (P-P) position intermediate phrase (I-P) use
numeric values rather earlier symbolic values (e.g., first Figure 1). Composition
intermediate phrase (I-C) replaces value alone (meaning phrase contained
example cue phrase, example plus cue phrases) Figure 1
primitive values cue phrases (whose disjunction equivalent
alone); I-C also uses value rather :alone (as used Figure 1). Accent
(A) uses value ambiguous represent cases prosodic analysis yields
disjunction (e.g., \H*+L H*"). Accent* (A*) re-represents symbolic values
feature accent (A) using abstract level description. particular, L*+H,
L+H*, H*+L, H+L* represented separate values single value {
superclass complex { A*. useful abstractions often result learning
process, A* explicitly represented advance prosodic feature representation
potential automated (see Section 5).
textual features, value NA (not applicable) ects fact 39 recorded
examples included transcription, done independently
61

fiLitman

studies performed Hirschberg Litman (1993). coding used Hirschberg
Litman, preceding cue phrase (C-P) succeeding cue phrase (C-S) represented actual
cue phrase (e.g., \and") preceding succeeding cue phrase; value
true encodes cases. prosodic feature set A*, preceding orthography*
(O-P*) succeeding orthography* (O-S*) re-represent symbolic values
preceding orthography (O-P) succeeding orthography (O-S), respectively, using
abstract level description (e.g., comma, dash, period represented separate values
O-S single value true O-S*). done reliability coding
detailed transcriptions orthography known. Part-of-speech (POS) represents
part speech assigned cue phrase Church's program tagging part speech
unrestricted text (Church, 1988); program assign approximately 80 different
values, subset values actually assigned cue phrases
transcripts corpora shown figure. Finally, lexical feature token (T)
new study, represents actual cue phrase described.
3.1.3 Training Data

final input learning program training data, i.e., set examples
class feature values specified. Consider following utterance, taken
multiple cue phrase corpus (Hirschberg & Litman, 1993):
Example 1 [(Now) (now welcomed here)] it's time get
business conference.
utterance contains two cue phrases, corresponding two instances \now".
brackets parentheses illustrate intonational intermediate phrases, respectively,
contain example cue phrases. Note single intonational phrase contains
examples, example uttered different intermediate phrase.
interested feature length intonational phrase (P-L), two examples would
represented training data follows:
P-L Class
9 discourse
9 sentential
first column indicates value assigned feature P-L, second column
indicates example classified. Thus, length intonational phrase
containing first instance \now" 9 words, example cue phrase classified
discourse usage. interested feature composition intermediate
phrase (I-C), two examples would instead represented training data follows:
I-C Class
discourse
sentential
is, intermediate phrase containing first instance \now" contains
cue phrase \now", intermediate phrase containing second instance \now"
contains \now" well 7 lexical items cue phrases. Note
value P-L examples, value I-C different.
62

fiCue Phrase Classification Using Machine Learning

3.2 Machine Learning Outputs

output machine learning programs classification models. C4.5 model
expressed decision tree, consists either leaf node (a class assignment),
decision node (a test feature, one branch subtree possible outcome
test). following example illustrates non-graphical representation decision
node testing feature n possible values:
test1 : : :
:::

elseif testn

:::

Tests form \feature operator value"9 . \Feature" name feature (e.g.
accent), \value" valid value feature (e.g., deaccented). features
symbolic values (e.g., accent), one branch symbolic value, operator
\=" used. features numeric values (e.g., length intonational phrase),
two branches, comparing numeric value threshold value; operators
\" \>" used. Given decision tree, cue phrase classified starting
root tree following appropriate branches leaf reached. Section 4
shows example decision trees produced C4.5.
cgrendel classification model expressed ordered set if-then rules
following form:
test1 ^ : : : ^ testk class
\if" part rule conjunction tests values (varying) features,
tests form \feature operator value." C4.5, \feature" name
feature, \value" valid value feature. Unlike C4.5, operators = =
6
used features symbolic values, used features numeric
values. \then" part rule specifies class assignment (e.g, discourse). Given set
if-then rules, cue phrase classified using rule whose \if" part satisfied.
two rules rules disagree class example, cgrendel
applies one two con ict resolution strategies (chosen user): choose first rule,
choose rule accurate data. experiments reported use
second strategy. rules, cgrendel assigns default class. Section 4
shows example rules produced cgrendel.
C4.5 cgrendel learn classification models using greedy search guided
\information gain" metric. C4.5 uses divide conquer process: training examples
recursively divided subsets (using tests discussed above), subsets
belong single class. test chosen divide examples maximizes
metric called gain ratio (a local measure progress, consider
subsequent tests); metric based information theory discussed detail
Quinlan (1993). test selected, backtracking. Ideally, set chosen
tests result small final decision tree. cgrendel generates set if-then rules
using method called separate conquer (to highlight similarity divide
conquer):
9. additional type test may invoked C4.5 option.

63

fiLitman

Many rule learning systems generate hypotheses using greedy strategy
rules added rule set one one effort form small cover
positive examples; rule, turn created adding one condition
another antecedent rule consistent negative
data. (Cohen, 1993)
Although cgrendel claimed two advantages C4.5, advantages
come play experiments reported here. First, if-then rules appear easier
people understand decision trees (Quinlan, 1993). However, cue phrase
classification task, decision trees produced C4.5 quite compact thus easily
understood. Furthermore, rule representation derived C4.5 decision trees,
using program C4.5rules. Second, cgrendel allows users exploit prior knowledge
learning problem, constraining syntax rules learned. However,
prior knowledge exploited cue phrase experiments. main reason using
C4.5 cgrendel increase reliability comparisons machine
learning manual results. particular, comparable results obtained using
C4.5 cgrendel, performance differences learned manually
derived classification models less likely due specifics particular learning
program, likely ect learned/manual distinction.

3.3 Evaluation

output machine learning experiment classification model
learned training data. learned models qualitatively evaluated examining linguistic content, comparing manually derived models
Figure 1. learned models also quantitatively evaluated examining error
rates testing data comparing error rates error
rates shown Table 1. error rate classification model computed using
model predict classifications set examples classifications already
known, comparing predicted known classifications. cue phrase domain,
error rate computed summing number discourse examples misclassified
sentential number sentential examples misclassified discourse, dividing
total number examples.
error rates learned classification models estimated using two methodologies. Train-and-test error rate estimation (Weiss & Kulikowski, 1991) \holds out" test
set examples, seen training completed. is, model
developed examining training examples; error model estimated
using model classify test examples. evaluation method used
Hirschberg Litman. resampling method cross-validation (Weiss & Kulikowski,
1991) estimates error rate using multiple train-and-test experiments. example, 10fold cross-validation, instead dividing examples training test sets once, 10 runs
learning program performed. total set examples randomly divided 10
disjoint test sets; run thus uses 90% examples test set training
remaining 10% testing. Note iteration cross-validation,
learning process begins scratch; thus new classification model learned
training sample. estimated error rate obtained averaging error rate test64

fiCue Phrase Classification Using Machine Learning

ing portion data 10 runs. method make sense
humans, computers truly ignore previous iterations. sample sizes hundreds
(the classifiable subset multiple cue phrase sample classifiable non-conjunct
subset provide 878 495 examples, respectively) 10-fold cross-validation often provides
better performance estimate hold-out method (Weiss & Kulikowski, 1991).
major advantage cross-validation examples eventually used testing,
almost examples used given training run.
best performing learned models identified comparing error rates
error rates learned models manually derived error rates.
determine whether fact error rate E1 lower another error rate E2
also significant, statistical inference used. particular, confidence intervals two
error rates computed, 95% confidence level. error rate estimated using
single error rate test set (i.e., train-and-test methodology), confidence
interval computed using normal approximation binomial distribution (Freedman
et al., 1978). error rate estimated using average multiple error
rates (i.e., cross-validation methodology), confidence interval computed using
t-Table (Freedman et al., 1978). upper bound 95% confidence interval E1
lower lower bound 95% confidence interval error rate E2,
difference E1 E2 assumed significant.10

3.4 Experimental Conditions
section describes conditions used set machine learning experiments.
experiments differ use training testing corpora, methods estimating error
rates, features classifications used. actual results experiments
presented Section 4.
3.4.1 Four Sets Experiments

learning experiments conceptually divided four sets. experiment
first set estimates error rate using train-and-test method, training
testing samples used Hirschberg Litman (1993) (the \now" data
two subsets multiple cue phrase corpus, respectively). allows direct comparison
manual machine learning approaches. However, prosodic experiments
conducted Hirschberg Litman (1993) replicated. textual training testing
conditions replicated original training corpus (the first 17 minutes
multiple cue phrase corpus) (Litman & Hirschberg, 1990) subset of, rather disjoint
from, test corpus (the full 75 minutes multiple cue phrase corpus) (Hirschberg &
Litman, 1993).
contrast, experiment second set uses cross-validation estimate error
rate. Furthermore, training testing samples taken multiple cue
phrase corpus. experiment uses 90% examples multiple cue phrase
data training, remaining 10% testing. Thus experiment second
set trains much larger amounts data (790 classifiable examples, 445 classifiable
10. Thanks William Cohen suggesting methodology.

65

fiLitman

prosody
hl93features
phrasing
length
position
intonational
intermediate
text
adjacency
orthography
preceding
succeeding
speech-text

P-L
X
X
X
X

P-P I-L I-P
X X X
X
X X X
X
X
X
X
X X

I-C A*
X X X
X X X
X
X

C-P

X
X
X

X

X

X

X

X

X

X

X

C-S O-P

X
X
X
X

O-P* O-S

O-S* POS

X

X

X

X

X
X

X
X

X

X

X

X

X
X

X
X

X

X

Table 3: Multiple feature sets components.
non-conjuncts) experiment first set (100 \nows"). reliability
testing compromised due use cross-validation (Weiss & Kulikowski, 1991).
experiment third set replicates experiment second set, exception learning program allowed distinguish cue phrases.
done adding feature representing cue phrase (the feature token Figure 2)
experiment second set. Since potential use lexical feature
noted used Hirschberg Litman (1993), experiments provide qualitatively new linguistic insights data. example, features may
used differently predict classifications different cue phrases sets cue phrases.
Finally, experiment fourth set replicates experiment first, second,
third set, exception 953 examples multiple cue phrase corpus
considered. practice, learned cue phrase classification model
likely used classify cue phrases, even dicult human judges
classify. experiments fourth set allow learning programs attempt
learn class unknown, addition classes discourse sentential.
3.4.2 Feature Representations within Experiment Sets

Within four sets experiments, individual experiment represents
data using different subset available features. First, data represented
14 single feature sets, corresponding prosodic textual feature shown
Figure 2. experiments comparatively evaluate utility individual feature
classification. representations Example 1 shown illustrate data
represented using single feature set P-L, using single feature set I-C.
Second, data represented 13 multiple feature sets shown Table 3.
sets contains linguistically motivated subset least 2 14 features.
first 7 sets use prosodic features. Prosody considers prosodic features
coded example cue phrase. Hl93features considers coded features
also used model shown Figure 1. Phrasing considers features
intonational intermediate phrases containing example cue phrase (i.e., length
66

fiCue Phrase Classification Using Machine Learning

Example 1 [(

) (now welcomed here)] it's time get business conference.
P-P I-L I-P I-C

A*
C-P C-S O-P O-P* O-S O-S* POS Class
1
1
1 H*+L complex f

par.
f
f
adv. disc.
2
8
1 H*
H*

f
f
f
f
f
adv. sent.


P-L
9
9

Figure 3: Representation Example 1 feature set speech-text.
phrase, position example phrase, composition phrase). Length position
consider one features, respect intonational
intermediate phrase. Conversely, intonational intermediate consider one type
phrase, consider features. next 5 sets use textual features. Text
considers textual features. Adjacency orthography consider single textual
feature, consider preceding succeeding immediate context. Preceding
succeeding consider contextual features relating orthography cue phrases,
limit context. last set, speech-text, uses prosodic textual features.
Figure 3 illustrates two example cue phrases Example 1 would represented
using speech-text. Consider feature values first example cue phrase. Since
example first lexical item intonational intermediate phrases
contain it, position phrases (P-P I-P) 1. Since intermediate phrase
containing cue phrase contains lexical items, length (I-L) 1 word
composition (I-C) cue phrase. values A* indicate
intonational phrase described sequence tones, complex pitch accent H*+L
associated cue phrase. respect textual features, utterance
transcribed began new paragraph. Thus example cue phrase
preceded another cue phrase (C-P), preceded form orthography (O-P
O-P*). Since example cue phrase immediately followed another instance
\now" transcription, cue phrase succeeded another cue phrase (C-S)
succeeded orthography (O-S O-S*). Finally, output part
speech tagging program run transcript corpus yields value adverb
cue phrase's part speech (POS).
first set experiments replicate prosodic experiments conducted
Hirschberg Litman (1993); cue phrases represented using subset feature sets consist prosodic features. second set experiments, examples
represented using 27 different feature sets (the 14 single feature sets 13
multiple feature sets). third set experiments, examples represented using 27
tokenized feature sets, constructed adding lexical feature token Figure 2 (the
cue phrase described) 14 single 13 multiple feature sets
second set experiments. tokenized feature sets referred using names
single multiple feature sets, concatenated \+". following illustrates
two cue phrases Example 1 would represented using P-L+:
P-L
Class
9 discourse
9 sentential
67

fiLitman

representation similar P-L representation shown earlier, except second
column indicates value assigned feature token (T).

4. Results

section examines results running two learning programs { C4.5 cgrendel { four sets cue phrase classification experiments described above. learned
classification models compared classification models shown Figure 1,
error rates learned classification models compared error
rates shown Table 1 error rates learned models.
seen, results suggest machine learning useful automating generation
linguistically viable classification classification models, generating classification models
perform lower error rates manually developed hypotheses, adding
body linguistic knowledge regarding cue phrases.

4.1 Experiment Set 1: Replicating Hirschberg Litman

first group experiments replicate training, testing, evaluation conditions
used Hirschberg Litman (1993), order investigate well machine learning
performs comparison manual development cue phrase classification models.
Figure 4 shows best performing prosodic classification models learned two
machine learning programs; top figure replicates manually derived prosodic
model Figure 1 ease comparison. prosodic features used
represent 100 training examples \now" (i.e., example represented using
feature set prosody Table 3)11, classification models learned shown
manually derived model top Figure 4. Note using learning
programs, decision tree also learned smaller feature sets phrasing
position used represent \now" data. bottom portion figure shows
classification models learned examples represented using
single prosodic feature position intonational phrase (P-P); model also
learned examples represented using multiple feature set intonational.
Recall C4.5 represents learned classification model decision tree.
level tree (shown indentation) specifies test single feature, branch
every possible outcome test. branch either lead assignment class,
another test. example, C4.5 classification model learned prosody classifies
cue phrases using two features position intonational phrase (P-P) position
intermediate phrase (I-P). Note available features prosody (recall
Table 3) used decision tree. tree initially branches based value
feature position intonational phrase.12 first branch leads class assignment
discourse. second branch leads test feature position intermediate phrase.
first branch test leads class assignment discourse, second branch
leads sentential. C4.5 produces unsimplified pruned decision trees. goal
11. Experiment Set 1, feature set prosody contain features P-L I-L. Recall
phrasal length coded later multiple cue phrase study.
12. ease comparison Figure 1, original symbolic representation feature value used
rather integer representation shown Figure 2.

68

fiCue Phrase Classification Using Machine Learning

Manually derived prosodic model (repeated Figure 1):

composition intermediate phrase = alone
elseif composition intermediate phrase = :alone
position intermediate phrase = first
accent = deaccented
elseif accent = L*
elseif accent = H*
elseif accent = complex
elseif position intermediate phrase = :first

discourse

discourse

discourse

sentential

sentential

sentential

(1)
(2)
(3)
(4)
(5)
(6)
(7)
(8)

Decision tree learned prosody, phrasing, position using C4.5:

position intonational phrase = first
elseif position intonational phrase = :first
position intermediate phrase = first
elseif position intermediate phrase = :first
discourse

discourse
sentential

Ruleset learned prosody, phrasing, position using CGRENDEL:

(position intonational phrase 6= first) ^ (position intermediate phrase 6= first)
default discourse

sentential

Decision tree learned P-P intonational using C4.5:

position intonational phrase = first
elseif position intonational phrase = :first

discourse
sentential

Ruleset learned P-P intonational using CGRENDEL:

position intonational phrase 6= first
default discourse

sentential

Figure 4: Example C4.5 cgrendel classification models learned different prosodic
feature representations \now" data.

69

fiLitman

Model
Classifiable Cue Phrases (N=878) Classifiable Non-Conjuncts (N=495)
P-P
18.3 2.6
16.6 3.4
prosody
27.3 3.0
17.8 3.4
phrasing
27.3 3.0
17.8 3.4
position
27.3 3.0
17.8 3.4
intonational
18.3 2.6
16.6 3.4
manual prosodic
24.6 3.0
14.7 3.2

Table 4: 95%-confidence intervals error rates (%) best performing cgrendel
prosodic classification models, testing data. (Training data \now" corpus;
testing data multiple cue phrase corpus.)
pruning process take complex decision tree may also overfitted
training data, produce tree comprehensible whose accuracy
comprised (Quinlan, 1993). Since almost trees improved pruning (Quinlan,
1993), simplified decision trees considered paper.
contrast, cgrendel represents learned classification model set if-then
rules. rule specifies conjunction tests various features, results
assignment class. example, cgrendel ruleset learned prosody classifies
cue phrases using two features position intonational phrase (P-P) position
intermediate phrase (I-P) (the two features used C4.5 decision tree).
values features first, if-then rule applies cue phrase classified
sentential. value either feature first, default applies cue phrase
classified discourse.
examination learned classification models Figure 4 shows
comparable content portion manually derived model classifies cue
phrases solely phrasal position (line (8)). particular, classification models
say cue phrase initial phrasal position classify sentential.
hand, manually derived model also assigns class sentential given
initial phrasal position conjunction certain combinations phrasal composition
accent; learned classification models instead classify cue phrase discourse
cases. shown, discrimination manually obtained model
significantly improve performance compared learned classification
models, fact one case significantly degrades performance.
error rates learned classification models \now" training data
developed follows: 6% models learned prosody, phrasing
position, 9% models learned P-P intonational. Recall
Section 2 error rate manually developed prosodic model Figure 1
training data 2%.
Table 4 presents 95% confidence intervals error rates best performing
cgrendel prosodic classification models. ease comparison, row labeled \manual
prosodic" presents error rates manually developed prosodic model Figure 1
two test sets, originally shown Table 1. table includes
cgrendel models whose performance matches exceeds manual performance.
70

fiCue Phrase Classification Using Machine Learning

Comparison error rates learned manually developed models suggests
machine learning effective technique automating development cue phrase
classification models. particular, within test set, 95% confidence interval
error rate classification models learned multiple feature sets prosody,
phrasing, position overlaps confidence interval error rate
manual prosodic model. also true error rates P-P intonational
classifiable non-conjunct test set. Thus, machine learning supports automatic construction variety cue phrase classification models achieve similar performance
manually constructed models.
results P-P intonational classifiable cue phrase test set
shown italics, suggest machine learning may also useful improving
performance. Although simple classification model learned P-P intonational performs worse manually derived model training data, tested
classifiable cue phrases, learned model (with upper bound error rate 20.9%)
outperforms manually developed model (with lower bound error rate 21.6%).
suggests manually derived model might overfitted training data,
i.e., prosodic feature set useful classifying \now" generalize
cue phrases. noted above, use simplified learned classification models helps
guard overfitting learning approach. ease inducing classification
models many different sets features using machine learning supports generation
evaluation wide variety hypotheses (e.g. P-P, high performing
optimal performing model training data).
Note manual prosodic manual performs significantly better smaller test
set (which contain cue phrases \and", \or", \but"). contrast,
performance improvement P-P intonational smaller test set significant.
also suggests manually derived model generalize well learned
models.
Finally, feature sets shown Table 4, decision trees produced C4.5 perform
error rates rulesets produced cgrendel, test sets. Recall
Figure 4 C4.5 decision trees cgrendel rules fact semantically
equivalent feature set. fact comparable results obtained using C4.5
cgrendel adds extra degree reliability experiments. particular,
duplication results suggests ability match perhaps even improve
upon manual performance using machine learning due specifics either
learning program.

4.2 Experiment Set 2: Using Different Training Sets
second group experiments evaluate utility training larger amounts
data. done using 10-fold cross-validation estimate error, run
90% examples sample used training (and 10 runs,
examples used testing). addition, experiments second set take
training testing data multiple-cue phrase corpus, contrast previous
set experiments training data taken \now" corpus.
seen, changes improve results, learned classification models
71

fiLitman

Model
Classifiable Cue Phrases (N=878) Classifiable Non-Conjuncts (N=495)
P-L
33.0 5.9
(33.2 1.9)
P-P
16.1 3.5
18.8 4.2
I-L
25.5 3.7
(25.6 2.8)
I-P
25.9 4.9
19.4 3.1
I-C
(36.5 5.4)
(35.2 3.4)

28.6 3.6
(30.2 3.1)
A*
28.3 4.3
(28.4 1.7)
prosody
15.5 2.6
17.2 3.1
hl93features
29.4 3.3
18.2 4.2
phrasing
16.1 3.4
19.6 3.9
length
26.1 3.8
(27.4 3.4)
position
18.2 2.3
19.4 2.8
intonational
17.0 4.0
20.6 3.6
intermediate
21.9 2.3
19.4 5.7
manual prosodic
24.6 3.0
14.7 3.2

Table 5: 95%-confidence intervals error rates (%) cgrendel prosodic classification models, testing data. (Training testing done multiple
cue phrase corpus using cross-validation.)
perform lower comparable error rates compared manually developed
models.
4.2.1 Prosodic Models

Table 5 presents error rates classification models learned cgrendel,
28 different prosodic experiments. (For Experiment Sets 2 3, C4.5 error rates
presented Appendix A.) numeric cell shows 95% confidence interval
error rate, equal error percentage obtained cross-validation margin
error ( 2.26 standard errors, using t-Table). top portion table considers
models learned single prosodic feature sets (Figure 2), middle portion
considers models learned multiple feature sets (Table 3), last row
considers manually developed prosodic model. error rates shown italics indicate
performance learned classification model exceeds performance
manual model (given test set). error rates shown parentheses indicate
opposite case - performance manual model exceeds performance
learned model. cases omitted Table 4.
Experiment Set 1, comparison error rates learned manually
developed models suggests machine learning effective technique
automating development cue phrase classification models, also improving
performance. evaluated classifiable cue phrase test set, five learned models
improved performance compared manual model; models except I-C
perform least comparably manual model. Note Experiment Set 1, two
learned models outperformed manual model, five learned models performed
least comparably. ability use large training sets thus appears advantage
automated approach.
72

fiCue Phrase Classification Using Machine Learning

Manually derived prosodic model (repeated Figure 1):

composition intermediate phrase = alone
elseif composition intermediate phrase = :alone
position intermediate phrase = first
accent = deaccented
elseif accent = L*
elseif accent = H*
elseif accent = complex
elseif position intermediate phrase = :first

discourse

discourse

discourse

sentential

sentential

sentential

(1)
(2)
(3)
(4)
(5)
(6)
(7)
(8)

Decision tree learned P-P using C4.5:

position intonational phrase 1
elseif position intonational phrase > 1

discourse
sentential

Ruleset learned P-P using CGRENDEL:

position intonational phrase 2
default discourse

sentential

Decision tree learned prosody using C4.5:

position intonational phrase 1
position intermediate phrase 1
elseif position intermediate phrase > 1
elseif position intonational phrase > 1
length intermediate phrase 1
elseif length intermediate phrase > 1

discourse
sentential

discourse
sentential

Ruleset learned prosody using CGRENDEL:

(position intonational phrase 2) ^ (length intermediate phrase 2)
(7 position intonational phrase 4) ^ (length intonational phrase 10)
(length intermediate phrase 2) ^ (length intonational phrase 7) ^ (accent = H*)
(length intermediate phrase 2) ^ (length intonational phrase 9) ^ (accent = H*+L)
(length intermediate phrase 2) ^ (accent = deaccented)
(length intermediate phrase 8) ^ (length intonational phrase 9) ^ (accent = L*)
sentential

sentential

sentential
sentential

sentential

sentential

default discourse

Figure 5: Example C4.5 cgrendel classification models learned different prosodic
feature representations classifiable cue phrases multiple cue phrase
corpus.
tested classifiable non-conjuncts (where error rate manually
derived model decreases), machine learning useful automating improving
performance. might ect fact manually derived theories already achieve
optimal performance respect examined features less noisy subcorpus,
and/or automatically derived theory subcorpus based smaller
training set used larger subcorpus.
examination best performing learned classification models shows
quite comparable content relevant portions prosodic model Figure 1,
often contain linguistic insights. Consider classification model learned
single feature position intonational phrase (P-P), shown near top Figure 5.
73

fiLitman

learned classification models say cue phrase initial
position intonational phrase, classify sentential; otherwise classify discourse.
Note correspondence line (8) manually derived prosodic model. Also note
classification models comparable13 P-P classification models learned
Experiment Set 1 (shown Figure 4), despite differences training data.
fact single prosodic feature position intonational phrase (P-P) classify cue
phrases least well complicated manual multiple feature learned models
new result learning experiments.
Figure 5 also illustrates complex classification models learned using prosody,
largest prosodic feature set. C4.5 model similar lines (1) (8) manual
model. (The length value 1 equivalent composition value alone.) ruleset
induced prosody cgrendel, first 2 if-then rules correlate sentential status
(among things) non-initial position14 , second 2 rules H* H*+L
accents; rules similar lines (6)-(8) Figure 1. However, last 2 if-then rules
ruleset also correlate accent L* sentential status phrase
certain length, lines (4) (5) Figure 1 provide different interpretation
take length account. Recall length coded Hirschberg Litman
test data. Length thus never used generate revise prosodic model.
utility length new result experiment set.
Although shown, models learned phrasing, position, intonational also
outperform manual model. seen Table 3, models correspond
feature sets supersets P-P subsets prosody.
4.2.2 Textual Models

Table 6 presents error rates classification models learned cgrendel,
24 different textual experiments. Unlike experiments involving prosodic feature sets,
none learned textual models perform significantly better manually derived
model. However, results suggest machine learning still effective technique
automating development cue phrase classification models. particular, five
learned models (O-P, O-P*, text, orthography, preceding) perform comparably
manually derived model, test sets. Note five models learned
five textual feature sets include either feature O-P O-P* (recall Figure 2
Table 3). models perform significantly better remaining learned
textual models.
Figure 6 shows best performing learned textual models. Note similarity
manually derived model. prosodic results, best performing single feature
models perform comparably learned multiple features. fact, cgrendel,
rulesets learned multiple feature sets orthography preceding identical
rulesets learned single features O-P O-P*, even though features
available use. (The corresponding error rates Table 6 identical due
13. different feature values two figures ect fact phrasal position represented
\now" corpus using symbolic values (as Figure 1), multiple cue phrase corpus using
integers (as Figure 2).
14. Tests \feature x" \feature y" merged figure simplicity, e.g., \y feature
x."

74

fiCue Phrase Classification Using Machine Learning

Model
Classifiable Cue Phrases (N=878) Classifiable Non-Conjuncts (N=495)
C-P
(40.7 6.2)
(40.2 4.5)
C-S
(41.3 5.9)
(39.8 4.2)
O-P
20.6 5.7
17.6 3.3
O-P*
18.4 3.7
17.2 2.4
O-S
(34.1 6.3)
(30.2 1.8)
O-S*
(35.2 5.5)
(32.6 3.0)
POS
(37.7 4.1)
(38.2 4.6)
text
18.8 4.2
19.0 3.6
adjacency
(39.7 5.7)
(40.2 3.4)
orthography
18.9 3.4
18.8 3.0
preceding
18.8 3.8
17.6 3.2
succeeding
(33.9 6.0)
(30.0 2.7)
manual textual
19.9 2.8
16.1 3.4

Table 6: 95%-confidence intervals error rates (%) cgrendel textual classification models, testing data. (Training testing done multiple
cue phrase corpus using cross-validation.)
Manually derived textual model (repeated Figure 1):
preceding orthography = true discourse
elseif preceding orthography = false sentential
Decision tree learned O-P*, text, orthography, preceding using C4.5:

preceding orthography* = NA
elseif preceding orthography* = false
elseif preceding orthography* = true

discourse
sentential
discourse

Ruleset learned O-P, O-P*, orthography, preceding using CGRENDEL:

preceding orthography* = false
default discourse

sentential

Ruleset learned text using CGRENDEL:

preceding orthography* = false
part-of-speech = article
default discourse

sentential

sentential

Figure 6: Example C4.5 cgrendel classification models learned different textual
feature representations classifiable cue phrases multiple cue phrase
corpus.
estimation using cross-validation.) cgrendel model text also incorporates feature
part-of-speech. C4.5, models text, orthography preceding identical O-P*.
4.2.3 Prosodic/Textual Models

Table 7 presents error rates classification models learned cgrendel
data represented using speech-text, complete set prosodic textual features (recall
75

fiLitman

Model
Classifiable Cue Phrases (N=878) Classifiable Non-Conjuncts (N=495)
speech-text
15.9 3.2
14.6 4.6
manual prosodic
24.6 3.0
14.7 3.2
manual textual
19.9 2.8
16.1 3.4

Table 7: 95%-confidence intervals error rates (%) cgrendel prosodic/textual
classification model, testing data. (Training testing done multiple cue phrase corpus using cross-validation.)
Table 3). Since Hirschberg Litman develop similar classification model
combined types features, comparison last two rows show error rates
separate prosodic textual models. learned model compared
manual prosodic model, using classifiable cue phrases testing, learning result
significant performance improvement. consistent results discussed above,
several learned prosodic models performed better manually derived prosodic
model test set. performance speech-text significantly better worse
performance either best prosodic textual learned models (Tables 5 6,
respectively).
Figure 7 shows C4.5 cgrendel hypotheses learned speech-text. C4.5
model classifies cue phrases using prosodic textual features performed best
isolation (position intonational phrase preceding orthography*, discussed above),
conjunction additional feature length intermediate phrase (which also appears
model learned prosody Figure 5). Like line (9) manually derived
textual model, learned model associates presence preceding orthography
class discourse. Unlike line (10), however, cue phrases preceded orthography
may classified either discourse sentential, based prosodic feature values (which
available use textual model). branch learned decision tree
corresponding last three lines also similar lines (1), (2), (8) manually
derived prosodic model. (Recall length value 1 equivalent composition value
alone.)
cgrendel model uses similar features used C4.5 well prosodic
feature accent (also used prosody Figure 5), textual features part-of-speech
(also used text Figure 6) preceding cue phrase. Like C4.5, unlike line (10)
manually derived textual model, cgrendel model classifies cue phrases lacking
preceding orthography sentential conjunction certain feature values.
Unlike line (9) manual model, learned model also classifies cue phrases
preceding orthography sentential (if orthography comma, feature values
present). Finally, third fifth learned rules elaborate line (6) additional
prosodic well textual features, first last learned rules elaborate line (8).

4.3 Experiment Set 3: Adding Feature token

experiment third group replicates experiment second group,
exception data representation also includes lexical feature token
76

fiCue Phrase Classification Using Machine Learning

Manually derived prosodic model (repeated Figure 1):

composition intermediate phrase = alone
elseif composition intermediate phrase = :alone
position intermediate phrase = first
accent = deaccented
elseif accent = L*
elseif accent = H*
elseif accent = complex
elseif position intermediate phrase = :first

discourse

discourse

discourse

sentential

sentential

sentential

Manually derived textual model (repeated Figure 1):

preceding orthography = true
elseif preceding orthography = false

(1)
(2)
(3)
(4)
(5)
(6)
(7)
(8)
(9)
(10)

discourse
sentential

Decision tree learned speech-text using C4.5:

position intonational phrase 1
preceding orthography* = NA
elseif preceding orthography* = true
elseif preceding orthography* = false
length intermediate phrase > 12
elseif length intermediate phrase 12
length intermediate phrase 1
elseif length intermediate phrase > 1
elseif position intonational phrase > 1
length intermediate phrase 1
elseif length intermediate phrase > 1
discourse

discourse

discourse
discourse
sentential

discourse

sentential

Ruleset learned speech-text using CGRENDEL:

(preceding orthography = false) ^ (4 position intonational phrase 6) ^
(preceding orthography = false) ^ (length intermediate phrase 2)
(preceding orthography = false) ^ (length intonational phrase 7) ^ (preceding cue phrase = NA)
^ (accent = H*)
(preceding orthography = comma) ^ (length intermediate phrase 5) ^ (length intonational phrase 17)
^ (part-of-speech = adverb)
(preceding orthography = comma) ^ (3 length intonational phrase 8) ^ (accent = H*)
(preceding orthography = comma) ^ (3 length intermediate phrase 8)
^ (length intonational phrase 15)
(position intonational phrase 2) ^ (length intermediate phrase 2)
^ (preceding cue phrase = NA)
sentential

sentential

sentential

sentential

sentential

sentential

default discourse

sentential

Figure 7: C4.5 cgrendel classification models learned prosodic/textual feature representation classifiable cue phrases multiple cue phrase corpus.

77

fiLitman

Model
Classifiable Cue Phrases (N=878) Classifiable Non-Conjuncts (N=495)
P-L+
21.8 4.6
17.4 2.7
P-P+
16.7 2.8
14.8 5.0
I-L+
20.3 3.4
16.0 3.3
I-P+
25.1 4.1
17.0 3.6
I-C+
27.0 3.6
18.4 3.4
A+
19.8 3.2
12.8 3.1
A*+
18.6 3.8
15.4 2.8
prosody+
16.7 2.9
15.8 3.1
hl93features+
24.0 4.5
17.4 4.3
phrasing+
14.5 3.3
12.6 3.3
length+
18.6 2.0
16.2 3.5
position+
15.6 3.3
13.0 3.9
intonational+
15.1 2.2
16.6 4.6
intermediate+
18.5 3.7
16.6 4.0
manual prosodic
24.6 3.0
14.7 3.2

Table 8: 95%-confidence intervals error rates (%) cgrendel prosodic, tokenized classification models, testing data. (Training testing done
multiple cue phrase corpus using cross-validation.)
Figure 2. experiments investigate performance changes classification models allowed treat different cue phrases differently. seen, learning
tokenized feature sets often improves performance learned classification
models. addition, classification models contain new linguistic information regarding particular tokens (e.g., \so").
4.3.1 Prosodic Models

Table 8 presents error learned classification models test sets
multiple cue phrase corpus, tokenized prosodic feature sets. Again, error
rates italics indicate performance learned classification model meaningfully
exceeds performance \manual prosodic" model (which consider feature
token).
One way improvement obtained adding feature token seen
comparing performance learned manually derived models. Table 8, six
cgrendel classification models lower (italicized) error rates manual model.
Table 5, five models italicized. Thus, adding feature token results
additional learned model - length+ - outperforming manually derived model.
Conversely, Table 8, learned models perform significantly worse manually
derived manual. contrast, Table 5, several non-tokenized models perform worse
manual model (I-C larger test set, P-L, I-L, I-C, A, A*, length
non-conjunct test set).
improvement obtained adding feature token also seen comparing
performance tokenized (Table 8) non-tokenized (Table 5) versions
model other. convenience, cases tokenization yields improvement
highlighted Table 9. table shows error rate tokenized versions
feature sets significantly lower error non-tokenized versions, P-L, I-C,
78

fiCue Phrase Classification Using Machine Learning

Model
P-L
I-L
I-C

A*
length

Classifiable Cue Phrases (N=878)
Non-Tokenized Tokenized (+)
33.0 5.9
21.8 4.6
36.5 5.4
27.0 3.6
28.6 3.6
19.8 3.2
28.3 4.3
18.6 3.8
26.1 3.8
18.6 2.0

Classifiable Non-Conjuncts (N=495)
Non-Tokenized
Tokenized (+)
33.2 1.9
17.4 2.7
25.6 2.8
16.0 3.3
35.2 3.4
18.4 3.4
30.2 3.1
12.8 3.1
28.4 1.7
15.4 2.8
27.4 3.4
16.2 3.5

Table 9: Cases adding feature token improves performance prosodic
model.
A, A*, length test sets, I-L non-conjunct test set. Note
overlap feature sets Table 9 discussed previous paragraph.
Figure 8 shows several tokenized single feature prosodic classification models. first
cgrendel model figure shows ruleset learned P-L+, reduces
33.2% 1.9% error rate P-L (length intonational phrase) 17.4% 2.7%,
trained tested using classifiable non-conjuncts (Table 9). Note first rule
uses prosodic feature (like rules Experiment Sets 1 2), fact
similar line (1) manual model. (Recall length value 1 equivalent
composition value alone.) However, unlike rules previous experiment sets,
next 5 rules use prosodic feature lexical feature token. Also unlike
rules previous experiment sets, remaining rules classify cue phrases using
feature token. Examination learned rulesets Figures 8 9 shows
cue phrases often appear last type rule. cue phrases,
example, \finally", \however", \ok", fact always discourse usages multiple
cue phrase corpus. cue phrases, classifying cue phrases using token
corresponds classifying cue phrases using default class (the frequent type
usage multiple cue phrase corpus). Recall use non-tokenized default class
model Table 1.
second example shows ruleset learned I-C+ (composition intermediate
phrase+). first rule corresponds line (1) manually derived model.15
next six rules classify particular cue phrases discourse, independently value I-C.
Note although model cue phrase \say" classified using token,
previous model sophisticated strategy classifying \say" could found.
third example shows cgrendel ruleset learned A+ (accent+). first
rule corresponds line (5) manually derived prosodic model. contrast line
(4), however, cgrendel uses deaccenting predict discourse tokens \say"
\so." token \finally", \however", \now" \ok", discourse assigned (for
accents). deaccented cases, sentential assigned (using default). Similarly,
contrast line (7), complex accent L+H* predicts discourse cue phrases
\further" \indeed" (and also \finally", \however", \now" \ok"), sentential
otherwise.
15. discussed relation Figure 2, I-C values cue phrases multiple cue phrase
corpus replace value alone \now" corpus.

79

fiLitman

Manually derived prosodic model (repeated Figure 1):

composition intermediate phrase = alone
elseif composition intermediate phrase = :alone
position intermediate phrase = first
accent = deaccented
elseif accent = L*
elseif accent = H*
elseif accent = complex
elseif position intermediate phrase = :first

(1)
(2)
(3)
(4)
(5)
(6)
(7)
(8)

discourse

discourse

discourse

sentential

sentential

sentential

Ruleset learned P-L+ using CGRENDEL:

length intonational phrase 1
(7 length intonational phrase 11) ^ (token = although)
(9 length intonational phrase 16) ^ (token = indeed)
(length intonational phrase 20) ^ (token = say)
(11 length intonational phrase 13) ^ (token = then)
(length intonational phrase = 5) ^ (token = well)
token = finally
token =
token = however
token =
token = ok
token = otherwise
token =
discourse

discourse

discourse

discourse

discourse

discourse

discourse

discourse

discourse

discourse

discourse

discourse

discourse

default sentential

Ruleset learned I-C+ using CGRENDEL:

composition intermediate phrase =
token = finally
token = however
token =
token = ok
token = say
token =

discourse

discourse

discourse

discourse

discourse

discourse

discourse

default sentential

Ruleset learned A+ using CGRENDEL:

accent = L*
(accent = deaccented) ^ (token = say)
(accent = deaccented) ^ (token = so)
(accent = L+H*) ^ (token = further)
(accent = L+H*) ^ (token = indeed)
token = finally
token = however
token =
token = ok
discourse

discourse

discourse
discourse

discourse

discourse

discourse

discourse

discourse

default sentential

Figure 8: Example cgrendel classification models learned different tokenized,
prosodic feature representations classifiable non-conjuncts multiple
cue phrase corpus.

80

fiCue Phrase Classification Using Machine Learning

Model
Classifiable Cue Phrases (N=878) Classifiable Non-Conjuncts (N=495)
C-P+
(28.2 3.9)
16.4 4.6
C-S+
(28.9 3.6)
17.2 4.0
O-P+
17.5 4.4
10.0 3.1
O-P*+
17.7 2.9
12.2 2.9
O-S+
26.9 4.7
18.4 3.9
O-S*+
(27.3 3.5)
16.0 3.2
POS+
(27.4 3.6)
17.2 3.9
text+
18.4 3.0
12.0 2.6
adjacency+
(28.6 4.1)
15.2 3.1
orthography+
17.6 3.0
13.6 3.9
preceding+
17.0 4.1
13.6 2.6
succeeding+
25.6 3.9
18.0 4.5
manual textual
19.9 2.8
16.1 3.4

Table 10: 95%-confidence intervals error rates (%) cgrendel textual, tokenized classification models, testing data. (Training testing done
multiple cue phrase corpus using cross-validation.)
summarize, new prosodic results Experiment Set 3 features relating
length, composition, accent, useful (in isolation) predicting classification cue phrases, fact quite useful predicting class individual cue
phrases subsets cue phrases. (Recall result Experiment Sets 1 2
without token, prosodic feature position intonational phrase useful
isolation.)
4.3.2 Textual Models

Table 10 presents error learned classification models test sets
multiple cue phrase corpus, tokenized textual feature sets. Experiment Set 2 (Table 6), none cgrendel classification models lower (italicized)
error rates manual model. However, adding feature token improve
performance many learned rulesets, following models (unlike
non-tokenized counterparts) longer outperformed manual model: O-S+
succeeding+ larger test set, C-P+, C-S+, O-S+, O-S*+, POS+, adjacency+,
succeeding+ non-conjunct test set.
improvement obtained adding feature token also seen comparing
performance tokenized (Table 10) non-tokenized (Table 6) versions
model other, shown Table 11. table shows error rates
tokenized versions feature sets significantly lower error nontokenized versions, C-P, C-S, POS, adjacency test sets, O-P, O-S,
O-S*, text, succeeding non-conjunct test set. Note overlap feature
sets Table 11 discussed previous paragraph.
Figure 9 shows several tokenized single textual feature classification models. first
cgrendel model shows ruleset learned C-P+ (preceding cue phrase+),
reduces 40.2% 4.5% error rate C-P 16.4% 4.6% trained tested using
classifiable non-conjuncts (Table 11). ruleset correlates preceding cue phrases
discourse usages \indeed", omitted transcriptions \further", \now", \so"
81

fiLitman

Manually derived textual model (repeated Figure 1):

preceding orthography = true
elseif preceding orthography = false

discourse
sentential

Ruleset learned C-P+ using CGRENDEL:

(preceding cue phrase = true) ^ (token = indeed)
(preceding cue phrase = NA) ^ (token = further)
(preceding cue phrase = NA) ^ (token = now)
(preceding cue phrase = NA) ^ (token = so)
token = although
token = finally
token = however
token = ok
token = say
token = similarly

discourse
discourse

discourse

discourse

discourse

discourse

discourse

discourse

discourse

default sentential

discourse

Ruleset learned O-P+ using CGRENDEL:

preceding orthography = false
(preceding orthography = comma) ^ (token = then)
sentential

default discourse

sentential

Ruleset learned O-S+ using CGRENDEL:

succeeding orthography = comma
(succeeding orthography = false) ^ (token = so)
succeeding orthography = NA
token = although
token = finally
token =
token = ok
token = say
discourse

discourse

discourse

discourse

discourse

discourse

discourse

discourse

default sentential

Ruleset learned POS+ using CGRENDEL:

(part-of-speech = adverb) ^ (token = finally)
(part-of-speech = singular proper noun) ^ (token = further)
(part-of-speech = adverb) ^ (token = however)
(part-of-speech = adverb) ^ (token = indeed)
(part-of-speech = subordinating conjunction) ^ (token = so)
token = although
token =
token = say
token = ok
discourse

discourse

discourse

discourse

discourse

discourse

discourse

discourse

discourse

default sentential

Figure 9: Example cgrendel classification models learned different tokenized, textual
feature representations classifiable non-conjuncts multiple cue phrase
corpus.

82

fiCue Phrase Classification Using Machine Learning

Model
C-P
C-S
O-P
O-S
O-S*
POS
text
adjacency
succeeding

Classifiable Cue Phrases (N=878)
Non-Tokenized Tokenized (+)
40.7 6.2
28.2 3.9
41.3 5.9
28.9 3.6
37.7 4.1
27.4 3.6
39.7 5.7
28.6 4.1
-

Classifiable Non-Conjuncts (N=495)
Non-Tokenized
Tokenized (+)
40.2 4.5
16.4 4.6
39.8 4.2
17.2 4.0
17.6 3.3
10.0 3.1
30.2 1.8
18.4 3.9
32.6 3.0
16.0 3.2
38.2 4.6
17.2 3.9
19.0 3.6
12.0 2.6
40.2 3.4
15.2 3.1
30.0 2.7
18.0 4.5

Table 11: Cases adding feature token improves performance textual
model.
discourse usages. classifications rest cue phrases predicted using
feature token.
second example shows cgrendel ruleset learned O-P+ (preceding orthography+). ruleset correlates preceding orthography sentential usages cue
phrases (as manually derived model learned models Experiment
Set 2). Unlike models, however, cue phrase \then" also classified sentential,
even preceded orthography (namely, comma).
third example shows cgrendel ruleset learned O-S+ (succeeding orthography). ruleset correlates presence succeeding commas discourse usages
cue phrases, except cue phrase \so", classified discourse usage without
succeeding orthography. model also correlates cue phrases omitted
transcript discourse usages. classifications rest cue phrases
predicted using feature token.
last example shows cgrendel ruleset learned POS+ (part-of-speech+).
ruleset classifies certain cue phrases discourse usages depending part-ofspeech token, well independently part-of-speech.
Finally, Figure 10 shows classification model learned text+, largest tokenized textual feature set. Note three four features used tokenized, single
textual feature models Figure 9 incorporated tokenized, multiple textual
feature model.
summarize, new textual results Experiment Set 3 features based adjacent cue phrases, succeeding orthography, part-of-speech, useful (in isolation)
predicting classification cue phrases, fact quite useful conjunction
feature token. (Recall result Experiment Set 2 without token,
textual features preceding orthography preceding orthography* useful
isolation.)
4.3.3 Prosodic/Textual Models

Table 12 presents error rates classification models learned cgrendel
data represented using speech-text+, complete set prosodic textual
83

fiLitman

Ruleset learned text+ using CGRENDEL:

preceding orthography = false
(preceding orthography = comma) ^ (token = although)
(preceding orthography = comma) ^ (token = no)
(preceding orthography = comma) ^ (token = then)
(succeeding orthography = false) ^ (preceding cue phrase = NA) ^ (token = similarly)
token = actually
token = first
token = since
token = yes
sentential

sentential

sentential

sentential

sentential

sentential

sentential

sentential

sentential

default discourse

Figure 10: cgrendel classification model learned tokenized, multiple textual feature
representation classifiable non-conjuncts multiple cue phrase corpus.
Model
Classifiable Cue Phrases (N=878) Classifiable Non-Conjuncts (N=495)
speech-text+
16.9 3.4
16.6 4.1
manual prosodic
24.6 3.0
14.7 3.2
manual textual
19.9 2.8
16.1 3.4

Table 12: 95%-confidence intervals error rates (%) cgrendel
prosodic/textual, tokenized classification models, testing data. (Training
testing done multiple cue phrase corpus using cross-validation.)
features. Experiment Set 2, performance speech-text+ better
performance either best learned (tokenized) prosodic textual models (Tables 8
10, respectively).
Comparison Tables 7 12 also shows feature set speech-text, tokenization improve performance. contrast prosodic textual feature
sets, tokenization improves performance many learned models (namely
shown Tables 9 11).

4.4 Experiment Set 4: Adding Classification ambiguous
practice, cue phrase classification model classify cue phrases
recording text, \classifiable." experiments fourth set
replicate experiments Experiment Sets 1, 2, 3, exception 953 cue
phrases multiple cue phrase corpus used. means cue phrases
classified discourse, sentential, well unknown (defined Table 2). Experiment
Set 4 investigates whether machine learning explicitly recognize new class unknown.
Recall studies Hirschberg Litman attempt predict class
unknown, occur \now" training corpus. Thus Experiment Set 1,
class unknown similarly learned training data. However, unknown
examples added testing data Experiment Set 1. Obviously performance
degrade, models must incorrectly classify unknown example either discourse
84

fiCue Phrase Classification Using Machine Learning

sentential. example, tested full corpus 953 example cue phrases,
95% confidence intervals error rates P-P intonational 24.8% 2.8%;
recall tested subset corpus corresponding 878 classifiable cue
phrases, error 18.3% 2.6% (Table 4).
Unfortunately, results rerunning Experiment Sets 2 3 show promising
results classifying cue phrases unknown. Despite presence 75 examples
unknown, learned models still classify unknown cue phrases discourse
sentential. example, cgrendel used learning, 2 possible 27 nontokenized models16 (phrasing speech-text) contain rules predict class unknown.
Furthermore, models contains one rule unknown,
rules applies 2 possible 953 examples! Similarly, four possible 27
tokenized models (length+, phrasing+, prosody+, speech-text+) contain least one rule
class unknown. compared training testing using classifiable
cue phrases corpus, error rate full corpus typically (but always)
significantly higher. best performing model Experiment Set 4 speech-text+,
22.4% 4.1% error rate (95% confidence interval).
sum, Experiment Set 4 addressed problem previously unexplored
literature - ability develop classification models predict discourse
sentential usages cue phrases, also usages human judges find dicult classify.
Unfortunately, results experiments suggest learning classify cue
phrases unknown dicult problem. Perhaps training data (recall
75 examples unknown) additional features better results could
obtained.

4.5 Discussion
experimental results suggest machine learning useful tool automating
generation classification models improving upon manually derived results.
Experiment Sets 1 2 performance many learned classification models
comparable performance manually derived models. addition, tested
classifiable cue phrases, several learned prosodic classification models (as well
learned prosodic/textual model) outperform Hirschberg Litman's manually derived
prosodic model. Experiment Set 3 shows learning tokenized feature sets even
improves performance, especially non-conjunct test set. tokenized
non-tokenized learned models perform least well manually derived models.
Many tokenized learned models also outperform non-tokenized counterparts.
textual classification models outperform better prosodic classification models, advantage textual feature values obtained directly
transcript, determining values prosodic features requires manual analysis. (See, however, Section 5 discussion feasibility automating prosodic
analysis. addition, transcript may always available.) hand, almost
high performing textual models dependent orthography. manual tran16. Recall Experiment Sets 2 3 constructed 14 prosodic models, 12 textual models, 1
prosodic/textual model.

85

fiLitman

scriptions prosodic features shown reliable across coders (Pitrelli et al.,
1994), corresponding results reliability orthography.
Examination best performing learned models shows often comparable content relevant portions manually derived models. Examination
models also provides new contributions cue phrase literature. example,
Experiment Sets 1 2 demonstrate utility classifying cue phrases based
single prosodic feature - phrasal position.17 Experiment Set 2 also demonstrates utility
prosodic feature length textual feature preceding cue phrase classifying
cue phrases - conjunction prosodic textual features. Finally, results
Experiment Set 3 demonstrate even though many features useful
classifying cue phrases, may nonetheless informative tokenized
form. true prosodic features based phrasal length, phrasal composition,
accent, textual features based adjacent cue phrases, succeeding position,
part-of-speech.18

5. Utility
results machine learning experiments quite promising, compared
manually derived classification models already literature, learned classification
models often perform comparable higher accuracy. Thus, machine learning
appears effective technique automating generation classification models.
However, given experiments reported still rely manually created training
data, discussion practical utility results order.
Even given manually created training data, results established Hirschberg
Litman (1993) - obtained using even less automation experiments paper
- already practical import. particular, manually derived cue phrase
classification models used improve naturalness synthetic speech text-tospeech system (Hirschberg, 1990). Using text-based model, text-to-speech system
classifies cue phrase text synthesized either discourse sentential
usage. Using prosodic model, system conveys usage synthesizing
cue phrase appropriate type intonation. speech synthesis could
improved (and output made varied) using one higher performing
learned prosodic models presented paper.
results paper could also directly applied area text generation.
example, Moser Moore (1995) concerned implementation cue selection placement strategies natural language generation systems. systems could
enhanced using text-based models cue phrase classification (particularly
17. empirical studies performed Holte (1993) show many datasets, accuracy
single feature rules decision trees often competitive accuracy complex learned
models.
18. contrast, prosodic features phrasal composition accent previously known useful
conjunction phrasal position (Hirschberg & Litman, 1993), part-ofspeech known useful conjunction orthography (Hirschberg & Litman, 1993).
Length, adjacent cue phrases, succeeding position used either manually derived
models (Hirschberg & Litman, 1993) (although length adjacent cue phrases shown useful
- conjunction prosodic textual features - Experiment Set 2).

86

fiCue Phrase Classification Using Machine Learning

tokenized models) additionally specify preceding succeeding orthography, part-ofspeech, adjacent cue phrases appropriate discourse usages.
Finally, results paper could fully automated, could also used
natural language understanding systems, enhancing ability recognize discourse
structure. results obtained Litman Passonneau (1995) Passonneau
Litman (in press) suggest algorithms use cue phrases (in conjunction
features) predict discourse structure outperform algorithms take cue phrases
account. particular, Litman Passonneau develop several algorithms explore
features cue phrases, prosody referential noun phrases best combined
predict discourse structure. Quantitative evaluations results show best
performing algorithms incorporate use discourse usages cue phrases (where cue
phrases classified discourse using phrasal position). discussed Section 1,
discourse structure useful performing tasks anaphora resolution plan
recognition. Recent work also shown discourse structure recognized,
used improve retrieval text (Hearst, 1994) speech (Sti eman, 1995).
Although prosodic features manually labeled Hirschberg Litman,
recent results suggesting least aspects prosody automatically
labeled directly speech. example, Wightman Ostendorf (1994) develop
algorithm able automatically recognize prosodic phrasing 85-86% accuracy
(measured comparing automatically derived labels hand-marked labels); accuracy slightly less human-human accuracy. Recall experimental results
paper show models learned single feature position intonational
phrase - could automatically computed given automatic prosodic phrasing algorithm - perform least well learned prosodic model. Similarly,
accenting versus deaccenting automatically labeled 88% accuracy (Wightman
& Ostendorf, 1994), sophisticated labeling scheme distinguishes
four types accent classes (and somewhat similar prosodic feature accent* used
paper) labeled 85% accuracy (Ostendorf & Ross, press). Recall
Experiment Set 3 tokenized models learned using accent* also classify cue phrases
good results.
Although textual features automatically extracted transcript, transcript manually created. Many natural language understanding systems
deal speech all, thus begin textual representations. spoken language systems transcription process typically automated using speech recognition
system (although introduces sources error).

6. Related Work
paper compared results obtained using machine learning previously
existing manually-obtained results, also used machine learning tool developing theories given new linguistic data (as models resulting Experiment Set 3,
new feature token considered). Siegel (1994) similarly uses machine learning
(in particular, genetic learning algorithm) classify cue phrases previously unstudied set textual features: feature corresponding token, well textual features
containing lexical orthographic item immediately left 4 positions
87

fiLitman

right example. Siegel's input consists one judge's non-ambiguous examples
taken data used Hirschberg Litman (1993) well additional examples;
output form decision trees. Siegel reports 21% estimated error rate,
half corpus used training half testing. Siegel McKeown (1994) also
propose method developing linguistically viable rulesets, based partitioning
training data produced induction.
Machine learning also used several areas discourse analysis. example, learning used develop rules structuring discourse multi-utterance
segments. Grosz Hirschberg (1992) use classification regression tree system
cart (Brieman et al., 1984) construct decision trees classifying aspects discourse
structure intonational feature values. Litman Passonneau (1995) Passonneau
Litman (in press) use system C4.5 construct decision trees classifying utterances discourse segment boundaries, using features relating prosody, referential noun
phrases, cue phrases. addition, C4.5 used develop anaphora resolution
algorithms, training corpora tagged appropriate discourse information (Aone &
Bennett, 1995). Similarly, McCarthy Lehnert (1995) use C4.5 learn decision trees
classify pairs phrases coreferent not. Soderland Lehnert (1994) use
machine learning program ID3 (a predecessor C4.5) support corpus-driven knowledge
acquisition information extraction. Machine learning often results algorithms
outperform manually derived alternatives (Litman & Passonneau, 1995; Passonneau & Litman, press; Aone & Bennett, 1995; McCarthy & Lehnert, 1995), although statistical
inference always used evaluate significance performance differences.
Finally, machine learning also used great success many areas
natural language processing. discussed above, work researchers discourse
analysis concentrated direct application existing symbolic learning approaches
(e.g., C4.5), comparison learning manual methods. researchers
areas natural language processing also addressed issues,
addition applied much wider variety learning approaches, concerned
development learning methods particularly designed language processing.
recent survey learning natural language (Wermter, Riloff, & Scheler, 1996) illustrates
type learning approaches used modified (in particular,
symbolic, connectionist, statistical, hybrid approaches), well scope
problems proved amenable use learning techniques (e.g., grammatical
inference, syntactic disambiguation, word sense disambiguation).

7. Conclusion
paper demonstrated utility machine learning techniques cue phrase
classification. Machine learning supports automatic generation linguistically viable
classification models. compared manually derived models already literature,
many learned models contain new linguistic insights perform least
high (if higher) accuracy. addition, ability automatically construct classification models makes easier comparatively analyze utility alternative feature
representations data. Finally, ease retraining makes learning approach
scalable extensible manual methods.
88

fiCue Phrase Classification Using Machine Learning

first set experiments presented used machine learning programs

cgrendel (Cohen, 1992, 1993) C4.5 (Quinlan, 1993) induce classification models

preclassified cue phrases features used training data
Hirschberg Litman (1993). results evaluated testing data
methodology used Hirschberg Litman (1993). second group experiments
used method cross-validation train test testing data used
Hirschberg Litman (1993). third set experiments induced classification models
using new feature token. fourth set experiments induced classification models
using new classification unknown.
experimental results indicate several learned classification models (including
extremely simple one feature models) significantly lower error rates models
developed Hirschberg Litman (1993). One possible explanation handbuilt classification models derived using small training sets; new data became
available, data used testing updating original models. contrast, machine learning conjunction cross-validation (Experiment Set 2) supported
building classification models using much larger amount data training.
Even learned models derived using small training set (Experiment
Set 1), results showed learning approach helped guard overfitting
training data.
prosodic classification model developed Hirschberg Litman demonstrated utility combining phrasal position phrasal composition accent,
best performing prosodic models Experiment Sets 1 2 demonstrated phrasal
position fact even useful predicting cue phrases used itself.
high performing classification models Experiment Set 2 also demonstrated utility classifying cue phrases based prosodic feature length textual feature
preceding cue phrase, combination features.
machine learning approach made easy retrain new training examples became available (Experiment Set 2), machine learning also made easy retrain
new features become available. particular, value feature token
added representations Experiment Set 2, trivial relearn
models (Experiment Set 3). Allowing learning programs treat cue phrases individually improved accuracy learned classification models, added
body linguistic knowledge regarding cue phrases. Experiment Set 3 demonstrated
useful classifying cue phrases, prosodic features based
phrasal length, phrasal composition, accent, textual features based adjacent
cue phrases, succeeding position, part-of-speech, fact useful used
conjunction feature token.
final advantage machine learning approach ease inducing classification models many different sets features supports exploration comparative
utility different knowledge sources. especially useful understanding tradeoffs accuracy model set features considered.
example, might worth effort code feature automatically obtainable
expensive automatically obtain adding feature results significant
improvement performance.
89

fiLitman

sum, results paper suggest machine learning useful tool
cue phrase classification, amount data precludes effective human analysis,
exibility afforded easy retraining needed (e.g., due additional training
examples, new features, new classifications), and/or analysis goal gain better
understanding different aspects data.
Several areas future work remain. First, still room performance improvement. error rates best performing learned models, even though outperform
manually derived models, perform error rates teens. Note
features coded discussed Hirschberg Litman (1993) considered
paper. may possible lower error rates considering new types
prosodic textual features (e.g., contextual textual features (Siegel, 1994),
features proposed connection general topic discourse
structure), and/or using different kinds learning methods. Second, Experiment Set
4 (and previous literature) show yet, models predicting
cue phrase usage classified unknown, rather discourse sentential.
Again, may possible improve performance existing learned models
considering new features and/or learning methods, perhaps performance could improved providing training data. Finally, currently open question whether
textual models developed here, based transcripts speech, applicable
written texts. Textual models thus need developed using written texts training
data. Machine learning continue useful tool helping address
issues.

Appendix A. C4.5 Results Experiment Sets 2 3
Tables 13, 14 15 present C4.5 error rates Experiment Sets 2 3. C4.5
results Experiment Set 2 shown \Non-Tokenized" columns. comparison
Tables 13 5 shows except larger test set, C4.5 prosodic error rates
fall within cgrendel confidence intervals. similar comparison Tables 14 6
shows except O-P larger test set, C4.5 textual error rates fall within
cgrendel confidence intervals. Finally, comparison Tables 15 7 shows
C4.5 error rate speech-text falls within cgrendel confidence interval. fact
comparable cgrendel C4.5 results generally obtained suggests ability
automate well improve upon manual performance due specifics
either learning program.
C4.5 results Experiment Set 3 shown \Tokenized" columns Tables 13, 14 15. Comparison Tables 8, 10 12 shows error rates C4.5
cgrendel similar Experiment Set 2. However, error rates reported
tables use default C4.5 cgrendel options running learning programs. Comparable performance two learning programs fact generally
achieved overriding one default C4.5 options. detailed Quinlan (1993),
default C4.5 approach { creates separate subtree possible feature value
{ might appropriate many values feature. situation characterizes feature token. C4.5 default option changed allow feature values
grouped one branch decision tree, problematic C4.5 error rates
90

fiCue Phrase Classification Using Machine Learning

Model
P-L
P-P
I-L
I-P
I-C

A*
prosody
hl93features
phrasing
length
position
intonational
intermediate

Classifiable Cue Phrases (N=878)
Non-Tokenized Tokenized (+)
32.5
31.7
16.2
18.4
25.6
26.8
25.9
26.3
36.5
36.6
40.7
40.7
28.3
26.7
16.0
15.2
30.2
29.0
15.9
15.2
24.8
24.4
18.1
18.0
16.8
16.6
21.2
22.3

Classifiable Non-Conjuncts (N=495)
Non-Tokenized
Tokenized (+)
32.2
31.4
18.8
19.0
25.6
25.6
19.4
18.8
35.8
32.8
29.6
29.2
28.8
31.2
19.4
16.0
18.8
18.8
18.0
17.4
26.2
24.2
19.6
17.6
18.8
19.8
21.6
18.4

Table 13: Error rates (%) C4.5 prosodic classification models, testing data. (Training
testing done multiple cue phrase corpus using cross-validation.)
Model
C-P
C-S
O-P
O-P*
O-S
O-S*
POS
text
adjacency
orthography
preceding
succeeding

Classifiable Cue Phrases (N=878)
Non-Tokenized Tokenized (+)
40.7
39.3
40.7
39.9
40.7
35.7
18.4
20.3
35.0
31.6
34.4
32.5
40.7
34.7
19.0
20.6
40.9
39.4
18.9
19.3
18.7
19.3
34.1
32.9

Classifiable Non-Conjuncts (N=495)
Non-Tokenized
Tokenized (+)
39.2
33.6
39.2
39.2
18.6
14.6
17.2
15.0
31.8
31.8
31.0
32.4
41.8
31.8
20.0
15.0
40.6
43.6
17.8
18.0
19.2
16.0
30.0
31.8

Table 14: Error rates (%) C4.5 textual classification models, testing data. (Training
testing done multiple cue phrase corpus using cross-validation.)
indeed improve. example, A+ error rate classifiable non-conjuncts changes
29.2% (Table 13) 11%, within 12.8% 3.1% cgrendel confidence
interval (Table 8).

Acknowledgements
would like thank William Cohen Jason Catlett helpful comments regarding
use cgrendel C4.5, Sandra Carberry, Rebecca Passonneau, three
anonymous JAIR reviewers helpful comments paper. would also like
91

fiLitman

Model
speech-text

Classifiable Cue Phrases (N=878)
Non-Tokenized Tokenized (+)
15.3
13.6

Classifiable Non-Conjuncts (N=495)
Non-Tokenized
Tokenized (+)
16.8
17.6

Table 15: Error rates (%) C4.5 prosodic/textual classification model, testing data.
(Training testing done multiple cue phrase corpus using crossvalidation.)
thank William Cohen, Ido Dagan, Julia Hirschberg, Eric Siegel comments
preliminary version paper (Litman, 1994).

References

Altenberg, B. (1987). Prosodic Patterns Spoken English: Studies Correlation
Prosody Grammar Text-to-Speech Conversion, Vol. 76 Lund Studies
English. Lund University Press, Lund.
Aone, C., & Bennett, S. W. (1995). Evaluating automated manual acquisition
anaphora resolution strategies. Proceedings Thirty-Third Annual Meeting
Association Computational Linguistics (ACL).
Brieman, L., Friedman, J., Olshen, R., & Stone, C. (1984). Classification Regression
Trees. Monterey, CA: Wadsworth Brooks.
Church, K. W. (1988). stochastic parts program noun phrase parser unrestricted
text. Proceedings Second Conference Applied Natural Language Processing.
Cohen, R. (1984). computational theory function clue words argument understanding. Proceedings Tenth International Conference Computational
Linguistics (COLING).
Cohen, W. W. (1992). Compiling knowledge explicit bias. Proceedings
Ninth International Conference Machine Learning.
Cohen, W. W. (1993). Ecient pruning methods separate-and-conquer rule learning
systems. Proceedings Thirteenth International Joint Conference Artificial
Intelligence (IJCAI).
Freedman, D., Pisani, R., & Purves, R. (1978). Statistics. W. W. Norton Company.
Grosz, B., & Hirschberg, J. (1992). intonational characteristics discourse structure. Proceedings International Conference Spoken Language Processing
(ICSLP).
Grosz, B. J., & Sidner, C. L. (1986). Attention, intentions, structure discourse.
Computational Linguistics, 12 (3), 175{204.
92

fiCue Phrase Classification Using Machine Learning

Halliday, M. A. K., & Hassan, R. (1976). Cohesion English. Longman.
Hearst, M. A. (1994). Multi-paragraph segmentation expository text. Proceedings
Thirty-Second Annual Meeting Association Computational Linguistics
(ACL).
Hindle, D. M. (1989). Acquiring disambiguation rules text. Proceedings
Twenty-Seventh Annual Meeting Association Computational Linguistics
(ACL).
Hirschberg, J. (1990). Accent discourse context: Assigning pitch accent synthetic
speech. Proceedings Eighth National Conference Artificial Intelligence
(AAAI).
Hirschberg, J., & Litman, D. (1987). let's talk \now": Identifying cue phrases
intonationally. Proceedings Twenty-Fifth Annual Meeting Association
Computational Linguistics (ACL).
Hirschberg, J., & Litman, D. (1993). Empirical studies disambiguation cue phrases.
Computational Linguistics, 19 (3), 501{530.
Holte, R. C. (1993). simple classification rules perform well commonly used
datasets. Machine Learning, 11 (1), 63{90.
Litman, D., & Hirschberg, J. (1990). Disambiguating cue phrases text speech.
Proceedings Thirteenth International Conference Computational Linguistics
(COLING).
Litman, D. J. (1994). Classifying cue phrases text speech using machine learning.
Proceedings Twelfth National Conference Artificial Intelligence (AAAI).
Litman, D. J., & Allen, J. F. (1987). plan recognition model subdialogues conversation. Cognitive Science, 11, 163{200.
Litman, D. J., & Passonneau, R. J. (1995). Combining multiple knowledge sources
discourse segmentation. Proceedings Thirty-Third Annual Meeting
Association Computational Linguistics (ACL).
McCarthy, J. F., & Lehnert, W. G. (1995). Using decision trees coreference resolution.
Proceedings Fourteenth International Joint Conference Artificial Intelligence
(IJCAI).
Moser, M., & Moore, J. D. (1995). Investigating cue selection placement tutorial
discourse. Proceedings Thirty-Third Annual Meeting Association
Computational Linguistics (ACL).
Ostendorf, M., & Ross, K. (in press). multi-level model recognition intonation labels.
Y. Sagisaka, N. C., & Higuchi, N. (Eds.), Computing Prosody. Springer-Verlag.
Passonneau, R. J., & Litman, D. J. (in press). Discourse segmentation human
automated means. Computational Linguistics, 23.
93

fiLitman

Pierrehumbert, J. B. (1980). Phonology Phonetics English Intonation. Ph.D.
thesis, Massachusetts Institute Technology. Distributed Indiana University
Linguistics Club.
Pitrelli, J., Beckman, M., & Hirschberg, J. (1994). Evaluation prosodic transcription
labeling reliability ToBI framework. Proceedings International Conference Spoken Language Processing (ICSLP).
Quinlan, J. R. (1993). C4.5 : Programs Machine Learning. San Mateo, CA: Morgan
Kaufmann.
Reichman, R. (1985). Getting Computers Talk Like Me: Discourse Context,
Focus, Semantics. Cambridge, MA: MIT Press.
Siegel, E. V. (1994). Competitively evolving decision trees fixed training cases
natural language processing. K. E. Kinnear, J. (Ed.), Advances Genetic
Programming. Cambridge, MA: MIT Press.
Siegel, E. V., & McKeown, K. R. (1994). Emergent linguistic rules automatic
grouping training examples: Disambiguating clue words decision trees.
Proceedings Twelfth National Conference Artificial Intelligence (AAAI).
Soderland, S., & Lehnert, W. (1994). Corpus-driven knowledge acquisition discourse
analysis. Proceedings Twelfth National Conference Artificial Intelligence
(AAAI).
Sti eman, L. J. (1995). discourse analysis approach structured speech. Working
Notes AAAI Spring Symposium Series: Empirical Methods Discourse Interpretation Generation.
Weiss, S. M., & Kulikowski, C. (1991). Computer Systems Learn: Classification
Prediction Methods Statistics, Neural Nets, Machine Learning, Expert
Systems. San Mateo, CA: Morgan Kaufmann.
Wermter, S., Riloff, E., & Scheler, G. (1996). Connectionist, Statistical Symbolic Approaches Learning Natural Language Processing. Berlin, Germany: SpringerVerlag.
Wightman, C. W., & Ostendorf, M. (1994). Automatic labeling prosodic patterns. IEEE
Transactions Speech Audio Processing, 2 (4), 469{481.
Zuckerman, I., & Pearl, J. (1986). Comprehension-driven generation meta-technical
utterances math tutoring. Proceedings Fifth National Conference
Artificial Intelligence (AAAI).

94

fiJournal Artificial Intelligence Research 5 (1996) 163{238

Submitted 5/94; published 10/96

Mechanisms Automated Negotiation
State Oriented Domains
Gilad Zlotkin

giladz@agentsoft.com

AgentSoft Ltd.
P.O. Box 53047
Jerusalem, Israel

Jeffrey S. Rosenschein

jeff@cs.huji.ac.il

Institute Computer Science
Hebrew University
Givat Ram, Jerusalem, Israel

Abstract

paper lays part groundwork domain theory negotiation, is,
way classifying interactions clear, given domain, negotiation
mechanisms strategies appropriate. define State Oriented Domains, general
category interaction. Necessary sucient conditions cooperation outlined.
use notion worth altered definition utility, thus enabling agreements
wider class joint-goal reachable situations. approach offered con ict resolution,
shown even con ict situation, partial cooperative steps taken
interacting agents (that is, agents fundamental con ict might still agree cooperate
certain point).
Unified Negotiation Protocol (UNP) developed used types
encounters. shown certain borderline cooperative situations, partial cooperative agreement (i.e., one achieve agents' goals) might preferred
agents, even though exists rational agreement would achieve goals.
Finally, analyze cases agents incomplete information goals
worth agents. First consider case agents' goals private information, analyze goal declaration strategies agents might adopt increase
utility. Then, consider situation agents' goals (and therefore standalone costs) common knowledge, worth attach goals private
information. introduce two mechanisms, one \strict," \tolerant," analyze affects stability eciency negotiation outcomes.

1. Introduction
Negotiation major research topic distributed artificial intelligence (DAI)
community (Smith, 1978; Malone, Fikes, Grant, & Howard, 1988; Kuwabara & Lesser,
1989; Conry, Meyer, & Lesser, 1988; Kreifelts & von Martial, 1991). term negotiation,
however, used variety different ways. researchers, negotiation
serves important mechanism assigning tasks agents, resource allocation,
deciding problem-solving tasks undertake. systems, generally
notion global utility system trying maximize.
c 1996 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiZlotkin & Rosenschein

researchers focused negotiation might take place among agents
serve interests truly distinct parties (Rosenschein & Genesereth, 1985; Sycara, 1988;
Kraus & Wilkenfeld, 1990; Zlotkin & Rosenschein, 1989). agents autonomous
sense utility functions, global notion utility (not
even implicit one) plays role design. Negotiation used share work
associated carrying joint plan, resolve outright con ict arising limited
resources.
Despite varied use terminology, clear DAI community whole
operation interacting agents would enhanced able exchange
information reach mutually beneficial agreements.
work described paper follows general direction previous research
authors (Rosenschein & Genesereth, 1985; Zlotkin & Rosenschein, 1989) treating
negotiation spirit game theory. focus research analyze existence
properties certain kinds deals protocols among agents.
examining computational issues arise discovering deals, though design
ecient, possibly domain-specific, algorithms constitute important future phase
research. Initial work building domain theory negotiation previously
undertaken (Zlotkin & Rosenschein, 1993a), expanded generalized current
paper. analysis serves critical step applying theory negotiation realworld applications.

1.1 Applying Game Theory Tools Protocol Design Automated Agents

ongoing research motivated one, focused premise: problem
get computers interact effectively heterogeneous systems tackled
use game theory tools.
concern computer systems made machines programmed
different entities pursue differing goals. One approach achieving coordination
circumstances establish mutually accepted protocols machines use
coming agreements.
perspective research one use game theory tools design
evaluate high-level protocols. intend, paper, make contributions
game theory itself. defining new notions equilibria, providing
new mathematical tools used general game theory. taking
game theory approach, tools, solve specific problems high-level
protocol design.
game theory makes contributions understanding many different fields,
particularly serendipitous match game theory heterogeneous computer systems. Computers, pre-programmed behavior, make concrete
notion \strategy" plays central role game theory|the idea player
adopts rules behavior starting play given game, rules entirely
control responses game. idealized player imperfect model human
behavior, one quite appropriate computers.
first apply game theoretic ideas computer science,
using tools new way. others used game theory answer question,
164

fiMechanisms Automated Negotiation

\How one program computer act given specific interaction?" addressing question design rules interaction automated
agents. approach taken paper is, therefore, strongly based previous work
game theory, primarily known \Nash's Bargaining Problem" (Nash, 1950;
Luce & Raiffa, 1957) \Nash's Model Bargaining" (Roth, 1979), \mechanism design"
\implementation theory" (Binmore, 1992; Fudenberg & Tirole, 1992), \correlated
equilibrium theory" (Aumann, 1974, 1987; Myerson, 1991; Forges, 1993). short overview
game theory results used referred paper found Section 9.1.

1.2 Overview Paper
previous work, began laying groundwork domain theory negotiation,
is, way classifying interactions clear, given domain, negotiation
mechanisms strategies appropriate. Previously, considered Task Oriented Domains (Zlotkin & Rosenschein, 1989, 1993a), restricted category interactions.
paper, define State Oriented Domains, general category interaction.
Section 4.4 examine scenarios interacting agents State Oriented Domains
find cooperative, compromise, con ict encounters. con ict situations, agents' goals cannot simultaneously achieved. joint-goal reachable situation
(i.e., agents' goals simultaneously achieved) cooperative compromise, depending cost reaching state satisfies agents compared
cost agent (alone) achieving stand-alone goal.
Section 4.1, necessary sucient conditions cooperation outlined. Cooperative situations lend mixed-joint-plan-based negotiation mechanisms. However,
compromise situations require special treatment. propose using notion worth
altered definition utility, thereby enabling agreements wider class joint-goal
reachable situations. approach offered con ict resolution, shown
even con ict situation, partial cooperative steps taken interacting agents
(that is, agents fundamental con ict might still agree cooperate certain point).
Unified Negotiation Protocol (UNP) developed Section 5.4 used
types encounters. shown certain borderline cooperative situations, partial
cooperative agreement (i.e., one achieve agents' goals) might preferred
agents, even though exists rational agreement would achieve
goals.
UNP enhanced Section 6 deal case agents
assigned unlimited worth goals fact common knowledge. solution
depends concept \cleaning yourself," tidiness, new method
evaluating agent utility. show two tidy agents able reach agreements
joint-goal reachable situations State Oriented Domains.
Section 7 analyze cases agents incomplete information goals
worth agents. First, consider case agents' goals private
information, consider goal declaration strategies agents might adopt
increase utility.
consider, Section 8, situation agents' goals (and therefore
stand-alone costs) common knowledge, worth attach goals
165

fiZlotkin & Rosenschein

private information. many situations agent's goals might known,
worth private. example, two cars approaching intersection may know
other's goals (because lanes located). worth
associates passing intersection target lane, however, private. Goal
recognition techniques suitable discovering agent's intentions; worth,
however, harder discern short-term external evidence.
agents declare, ,1-phase, worths, used baseline
utility calculation (and thus affect negotiation outcome). concerned
analyzing worth declaration strategies agents might adopt increase utility.
introduce two mechanisms, one \strict," \tolerant," analyze affects
stability eciency negotiation outcomes. strict mechanism turns
stable, tolerant mechanism ecient.

2. Negotiation State Oriented Domains
machines decide share resources, machine give way
proceeds? Negotiation compromise necessary, build
machines things? designers separate machines decide
techniques agreement enable mutually beneficial behavior? techniques
appropriate? make definite statements techniques' properties?
way address questions synthesize ideas artificial intelligence
tools game theory. Assuming automated agents, built separate, self-interested
designers, interact, interested designing protocols specific domains
get agents interact useful ways.
word \protocol" means different things different people. use word
protocol, mean rules agents come agreements. specifies kinds
deals make, well sequence offers counter-offers allowed.
Protocols intimately connected domains, mean environment
agents operate. Automated agents control telecommunications networks
operating different domain (in formal sense) robots moving boxes. Much
research focused relationship different kinds domains, protocols
suitable each.
Given protocol, need consider agent strategy appropriate. strategy
way agent behaves interaction. protocol specifies rules
interaction, exact deals agent proposes result strategy
designer put him. analogy, protocol like rules governing movement
pieces game chess. strategy way chess player decides
next move.

2.1 Attributes Standards
attributes might interest protocol designers? set attributes,
relative importance, ultimately affect choice interaction rules.
considered several attributes might important system designers.
166

fiMechanisms Automated Negotiation

1.

2.

3.

4.
5.

Eciency: agents squander resources come agree-

ment; wasted utility agreement reached. example,
makes sense agreements satisfy requirement Pareto Optimality
(no agent could derive different agreement, without agent
deriving less alternate agreement). Another consideration might Global
Optimality, achieved sum agents' benefits maximized.
Global Optimality implies Pareto Optimality, vice versa. Since speaking self-motivated agents (who care utilities, sum
system-wide utilities|no agent general would willing accept lower utility
increase system's sum), Pareto Optimality plays primary role eciency
evaluation. Among Pareto Optimal solutions, however, might also consider
secondary criterion solutions increase sum system-wide utilities.
Stability: agent incentive deviate agreed-upon strategies.
strategy agents adopt proposed part interaction environment
design. strategies proposed, however, want individual
designers (e.g., companies) incentive go back build agents
different, manipulative, strategies.
Simplicity: desirable overall interaction environment make low
computational demands agents, require little communication overhead.
related eciency stability: interaction mechanism
simple, increases eciency system, fewer resources used carrying
negotiation itself. Similarly, stable mechanisms, resources need
spent outguessing opponent, trying discover optimal choices.
optimal behavior publicly revealed, nothing better
carry out.
Distribution: Preferably, interaction rules require central decision
maker, obvious reasons. want distributed system
performance bottleneck, collapse due single failure special node.
Symmetry: may want agents play different roles interaction scenario. simplifies overall mechanism, removes question agent
play role interaction gets way.

attributes need universally accepted. fact, sometimes tradeoffs one attribute another (for example, eciency stability sometimes
con ict one another; see Section 8). protocols designed, specific
classes domains, satisfy attributes. Ultimately,
kinds criteria rate acceptability one interaction mechanism another.
one example, attribute stability assumes particular importance consider open systems, new agents constantly entering leaving community
interacting machines. Here, might want maintain stability face new agents
bring new goals potentially new strategies well. mechanism
\self-perpetuating," benefit society whole follow
rules, also benefit individual member, social behavior remains
167

fiZlotkin & Rosenschein

stable even society's members change dynamically. interaction rules
create environment particular strategy optimal, beneficial social behavior
resistant outside invasion.

2.2 Side Effects Encounters
Various kinds encounters among agents, various types domains, possible. previous work (Zlotkin & Rosenschein, 1989, 1993a, 1994, 1996b) examined Task Oriented
Domains (TODs), encompass certain kinds encounters among agents. State
Oriented Domains (SODs) describe larger class scenarios multiagent encounters
TODs. fact, see below, set Task Oriented Domains actually
proper subset State Oriented Domains. classical domains Artificial Intelligence
instances State Oriented Domains.
main attribute general SODs agents' actions side effects. Task
Oriented Domains, side effects exist general common resources unrestricted.
Thus, agent achieves set tasks TOD positive negative
effects agent whatsoever. hinder agent achieving
goal, never satisfies agent's goals \by accident." enable another agent
carry task, example Postmen Domain (Zlotkin & Rosenschein,
1989), necessary explicitly declare existence letter, hand over,
delivered. absence side effects rules positive negative
interactions among agent goals. positive interactions remain
explicitly coordinated agents.
general State Oriented Domains, side effects exist, agents unintentionally
achieve one another's goals, thus benefit one another's actions. ip side
side effects, however, negative interactions goals also exist. Thus,
SOD domain (unlike TODs) necessarily cooperative, action
side effects. SODs, agents deal goal con ict interference, well
possibility unintended cooperation.1
example, consider Blocks World situation Figure 1. simplest plan
achieve On(White; Gray) side effect achieving Clear(Black).

Figure 1: Side Effects State Oriented Domains
1. interesting discussions issue con ict role human encounters, see (Schelling, 1963,
1984).

168

fiMechanisms Automated Negotiation

2.3 Domain Definition
Consider group agents co-exist environment. agent goal
interested achieving. mean achieve goal? State Oriented Domains,
classic AI notion goal achievement: means carry sequence actions
(a plan) results transformation environment state goal
satisfied.
Imagine, example, person interested getting work. goal
work; current state, work. plan sequence actions
get work (driving car, calling taxi, walking, riding bicycle,. . . ).
final, goal, state, may differ depending plan executed (e.g.,
car is, bicycle is). states work, however, satisfy goal.
Let's assume optimal plan (from time point view) involves driving car
work.
specification goal states may implicit. fact needs true
(the goal) may given. situation fact true, i.e., goal satisfied,
acceptable. State Oriented Domain, goal described set states
satisfy it.
imagine person's wife interested place work.
states satisfy husband's wife's goals, plans
achieve state (e.g., one takes car, calls taxi). However,
certain plans suitable either spouse isolation, cannot
coexist. example, husband taking car perfectly good plan (and optimal)
alone world. Similarly, wife's taking car good plan (and optimal)
alone. Together, another plan may suitable (husband drives wife
work, continues car work). case, extra work required
husband's point view, wife present world; certain burden
coordination.
example above, agents carry sequence activities, suitably synchronized, reach goal state satisfying both. husband wife enter car,
husband drives particular location, wife exits, on. environment, primitive operations agent alone do. operations
combined coherent sequence actions specifying agents (and
order done), say agents executing joint plan.
joint plan general transforms world initial state goal state satisfying
agents (when possible). plan transforms world initial state
husband wife home goal state (satisfying agents)
wife work, car husband place work. final state,
one many goal states.
Task Oriented Domains cost coordinated plan need never worse
stand-alone plan|at worst, agent achieves set tasks.
husband/wife sharing one car example, however, coordinated plan may worse
one agents stand-alone plans. example one attribute
State Oriented Domains, namely negative interactions, sometimes called
169

fiZlotkin & Rosenschein

\deleted-condition interactions" (Gupta & Nau, 1992). taking car
side effect depriving agent car.
Imagine new situation, arises weekend. husband interested
carpentry garage (currently occupied car). wife interested
taking car baseball game. themselves, agent optimal plan reach
goal state (e.g., husband moves car garage, parks outside,
carpentry). However, wife takes car game, executing stand-alone
optimal plan, husband benefits side effect car moved, namely,
garage emptied. example another typical attribute State Oriented
Domains|accidental achievement goals, \enabling-condition interactions" (Gupta &
Nau, 1992) \favor relations" (von Martial, 1990) among goals.
agents carry joint plan, one plays \role." theory assumes
way assessing cost role. measure cost essential
agent evaluates given joint plan. Among joint plans achieve goal,
prefer role lower cost.
express intuitive ideas precise definition below.

Definition 1 State Oriented Domain (SOD) tuple < ; A; J ; c > where:
1. set possible world states;

2. = fA1; A2; : : :A g ordered list agents;
n

3. J set possible joint (i.e., n-agent) plans. joint plan J 2 J moves
world one state another. actions taken agent k called k's role
J , written J . also write J (J1; J2; : : :; J );
k

n

4. c function c: J ! (IR+ ) : joint plan J J , c(J ) vector n positive
real numbers, cost agent's role joint plan. c(J ) i-th element
cost vector, i.e., cost i-th role J . agent plays role
J , cost 0.
n



use term joint plan differs uses AI literature (Levesque &
Cohen, 1990; Cohen & Levesque, 1991). There, term joint plan implies joint goal,
mutual commitment agents full implementation plan (e.g., one agent
dropped suddenly, would still continue). use term, agents
committed goal part combined plan. may
part plan different reasons, different goal achieve.
one agent drop out, agent may may continue, depending whether
suited goal.
details description joint plans J critical overall theory.
minimal requirement must possible evaluate cost joint plan
agent (i.e., cost role). many domains, joint plan sequence
actions agent associated schedule (partial order) constraining actions'
parallel execution.
Note also cost function relates joint plan not,
example, initial state world. fact, cost function could altered
170

fiMechanisms Automated Negotiation

include parameters (like initial state world), without affecting discussion
below. model sensitive details cost function definition,
requirement cost role agents. called symmetric
abilities assumption (see below, Section 2.4).

Definition 2 encounter within SOD < ; A; J ; c > tuple < s; (G1; G2; : : :; G ) >

2 initial state world, k 2 f1 : : :ng; G set
acceptable final world states agent . G also called 's goal.
n

k

k

k

k

agent's goal fixed, pre-determined, set states. agent will, conclusion
joint plan, either achieve goal achieve goal. Goals cannot partially
achieved. Domains goals partially achieved called Worth Oriented
Domains (WODs) discussed detail elsewhere (Zlotkin & Rosenschein, 1991c,
1996a).
One thing specifically ruling SODs one agent goal
makes reference another agent's (as yet) unknown goal. example, specification
\Agent 1's goal make sure Agent 2's goal achieved, whatever
latter's goal is" cannot constitute part description encounter State
Oriented Domain, cannot described static set goal states. However,
meta-goal might exist within agent, give rise well-defined set states
specific encounter (e.g., given G2, G1 complement). Similarly, one agent might
goal another agent specific goal G2|the first agent wants world
state agent specific goal G2.
consider sets goal states specified finite way, either
set finite, infinite set specified closed formula
first-order logic (i.e., free variables; states satisfy formula,
states, goal set). example, agent might goal \There exists
block x block B x."
also consider restrictions kind goals agents may have.
example, consider domains agents' goals restricted sets
grounded predicates (i.e., variables) rather closed formula.
2.3.1 Reachability

may case exist goal states satisfy agents' goals,
constraints reachability states. example, may case
state satisfying goal reached agent alone, state satisfying
combined goal cannot reached agent alone. generally, reaching
state might require n agents working together, unreachable fewer n agents
involved (we call n \parallelism factor" goal). goal
intersection cannot reached number agents working parallel, say
parallelism factor infinite. parallelism factor particularly appropriate concept
multiagent actions possible required domain (e.g., carrying
heavy table).
171

fiZlotkin & Rosenschein

2.4 Assumptions

Throughout paper, making number simplifying assumptions enable
us lay foundation theory mechanism design automated agents.
Here, present assumptions.
1.
2.

3.
4.
5.

6.

Expected Utility Maximizer: Designers design agents maximize expected utility. example, assume designer build agent prefer
51% chance getting $100, rather sure $50.
Isolated Negotiation: agent cannot commit part current negotiation behavior future negotiation, expect current
behavior way affect future negotiation. Similarly, agent cannot expect
others behave particular way based previous interaction history,
act differently past behavior. negotiation stands
alone.
Interagent Comparison Utility: designers means transforming
utilities held different agents common utility units.
Symmetric Abilities: agents able perform set operations
world, cost operation independent agent carrying out.
Binding Commitments: Designers design agents keep explicit public
commitments. assume nothing relationship private preferences
public behavior, public commitment followed public performance
commitment. monitored, necessary, enforced.
Explicit Utility Transfer: Although agents compare respective utilities, way explicitly transferring utility units one other.
is, example, \money" used compensate one agent
disadvantageous agreement. Utility transfer occur, however, implicitly.
implicit transfer utility forms basis agreement among agents.

3. Examples State Oriented Domains

section, present several examples State Oriented Domains. specific
examples illustrate nuances describing class domains.

3.1 Blocks Domain

Blocks Domain, table unlimited size, set blocks. block
table block, limit height stack
blocks. One state domain seen Figure 2.
World States Goals: basic predicates make world states goals are:

On(x; y): x blocks; meaning block x (directly)
block .

172

fiMechanisms Automated Negotiation

Figure 2: State Blocks Domain

1

2

3

Figure 3: State Slotted Blocks Domain

On(x; Table): x block; meaning block x (directly)

table.
Clear(x): x block; meaning block x, i.e.,
Clear(x) :9y On(y; x).
SOD, goals sets world states. world states expressed
first order closed formula predicates. Sample goals are:

:Clear(R) | Block R clear.
9xOn(R; x) | Block R table.
8xOn(x; Table) | blocks table (and therefore, implicitly, blocks
also Clear).

Atomic Operation: one operation world: Move(x; ). operation moves
clear block x onto top another clear block .
Cost: move operation cost 2.

3.2 Slotted Blocks Domain

domain Blocks Domain above. However, table
bounded number slots blocks placed. One state domain
seen Figure 3.
World States Goals: basic predicates make world states goals are:

On(x; y): x blocks; meaning block x (directly)
block .

173

fiZlotkin & Rosenschein

At(x; n): x block n slot name; meaning block

x (directly) table slot n.
Clear(x): x block; meaning block
x, i.e., Clear(x) :9y On(y; x).
Atomic Operations: two operations Slotted Blocks Domain:

PickUp(i) | Pick top block slot (can executed whenever slot

empty);
PutDown(i) | Put block currently held slot i.
agent hold one block time.
Cost: operation cost one.

Slotted Blocks Domain different Blocks Domain two ways:
1. table unlimited size replaced bounded table distinguishable locations call \slots."
2. atomic \Move" operation broken two sub-operations PickUp PutDown.
allows cooperation among agents. example, want swap
blocks slot 1 Figure 3 would take one agents minimally total
4 Move operations, i.e., block (Black White) touched twice. However,
allow agents use PickUp PutDown operations two agents
swap two PickUp two PutDown operations (which equivalent two
move operations), i.e., block touched once. finer granularity
operations allows exibility scheduling within joint plan.

3.3 Delivery Domain Bounded Storage Space

Delivery Domain, weighted graph G = G(V; E ). v 2 V represents
warehouse, e 2 E represents road. weight function w: E ! IR+ length
given road. edge e 2 E , w(e) length e \cost" e.
agent deliver containers one warehouse another. deliveries, agents
rent trucks, unlimited supply available rental every node.
truck carry 5 containers. warehouse also limited capacity holding
containers.
Atomic Operations: operations domain are:

Load(c; t) | loads container c onto truck t. preconditions are:

{ Container c truck warehouse h;
{ Truck less 5 containers board, 5 capacity limit

truck.
results operation are:
{ Warehouse h one container less;
174

fiMechanisms Automated Negotiation

{ Truck one container more.

Load operation costs 1.
Unload(c; t) | unloads container c truck t. preconditions are:
{ Container c truck t;
{ Truck warehouse h;
{ Warehouse h full.
results operation are:
{ Warehouse h one container more;
{ Truck one container less.
Unload operation costs 1.
Drive(t; h) | Truck drives warehouse h. preconditions
operation. result truck warehouse h. cost operation
equal distance (i.e., minimal weighted path) current
position truck warehouse h.
World States Goals: full description world state includes location
container (either warehouse truck) location truck
(either warehouse road). However, restrict goals
specify containers need warehouses.

3.4 Restricted Usage Shared Resource Domain

domain, set agents able use shared resource (such
communication line, shared memory device, road, bridge. . . ). restriction
1 agents use resource time (m denotes
maximal capacity resource).
Atomic Operations: atomic operations Shared Resource Domain are:

Use | agent using shared resource one time unit. Use operation

costs 0.
Wait | agent waiting use shared resource one time unit.
operation costs 1, i.e., waiting one time unit access shared resource
costs 1.
NOP | agent need resource therefore neither uses
waits it. operation costs 0.
objective find schedule time unit
agents performing Use operation.
World States Goals: world state describes current activity agents
accumulated resource usage since time 0 (i.e., accumulated cost). goal
agent state accumulated target number time units
using resource, currently NOP operation. Formally, state
175

fiZlotkin & Rosenschein




e

A1

Joint Plan
A2

A3

A1

0 Use Use Wait
1 Use Use Wait
2 NOP Use Use
3 NOP NOP Use
4 NOP NOP NOP

World States

(Use,0)
(Use,1)
(NOP,2)
(NOP,2)
(NOP,2)

A2

(Use,0)
(Use,1)
(Use,2)
(NOP,3)
(NOP,3)

A3

(Wait,0)
(Wait,0)
(Use,0)
(Use,1)
(NOP,2)

Figure 4: Joint Plan States Restricted Usage Shared Resource Domain

n-element vector, one element agent, element pair consisting

agent's current operation accumulated number time units using
resource (i.e., set states (fWait,Use,NOPg IN) ).
Assume, example, three agents, one resource maximal
capacity two. Agents 1 3 need two units resource, agent 2 needs three
units resource. joint plan seen left side Figure 4, described
matrix. time agent , entry column row agent 's action
time t. resulting world state time unit joint plan seen
right side Figure 4. final state satisfies agents' goals.
n





4. Deals, Utility, Negotiation Mechanisms

defined characteristics State Oriented Domain, looked
simple examples, turn attention agents SOD reach agreement
joint plan brings agreed-upon final state. Hopefully, final state
satisfy agents' goals. However, isn't always possible. three
cases:
1. might case doesn't exist state satisfies agents' goals
(i.e., goals contradict one another);
2. might case exists state satisfies both, cannot
reached primitive operations domain (see Section 2.3.1 above);
3. might case exists reachable state satisfies both,
expensive get agents unwilling expend required
effort.

4.1 Negotiation Mechanism

start presenting simple mechanism suitable cases exists
reachable final state (that is, reachable suciently inexpensive plan) satisfies
agents' goals. call cooperative situation. Later, enhance mechanism
handle possible encounters State Oriented Domains, i.e.,
handle con ict resolution.
176

fiMechanisms Automated Negotiation

Definition 3 Given SOD < ; A; J ; c >, define:
P J set one-agent plans, i.e., joint plans one agent
active role.

cost c(P ) one-agent plan agent k active role, P 2 P ,
vector one non-zero element, position k.
likelihood confusion, use c(P ) stand k-th element (i.e., c(P ) ),
rather entire vector.
k

Definition 4 Best Plans

! f minimal cost one-agent plan P agent k plays active role
moves world state state f .
plan like exist ! f stand constant plan ./
k

k

k

costs infinity agent k 0 agents.

= f ! f stand empty plan costs 0 agents.
! F (where world state F set world states) minimal cost
one-agent plan P agent k plays active role moves world
k

k

state one states F :

c(s ! F ) = min
c(s ! f ):
2
k

k

f

F

mentioned above, moment restricting attention encounters
exist one states satisfy agents' goals.
one state exists? state agents choose reach?
one joint plan reach states? joint plan agents
choose?
example, let's say two states satisfy agents' goals. State 1
two possible roles, one roles costing 6 costing 3. State 2
two roles also, costing 5. State 1 cheaper overall reach, State
2 seems allow fairer division labor among agents.
Assuming agents want agreement ecient, decide reach
State 1. agent role costs 6, role
costs 3? approach allow agree \lottery" equalize
benefit derive joint plan. Although eventually one agent
other, expected benefit two agents identical (prior holding
lottery). plans include probabilistic component called mixed joint plans.
Throughout paper, limit bulk discussion mechanisms twoagent encounters. Initial work generalization techniques encounters among
two agents found elsewhere (Zlotkin & Rosenschein, 1994). research
considers issues coalition formation n-agent Task Oriented Domains.

Definition 5 Deals Given encounter two-agent SOD < s; (G1; G2) >:
177

fiZlotkin & Rosenschein

define Pure Deal joint plan J 2 J moves world state
state G1 \ G2.
define Deal mixed joint plan J : p; 0 p 1 2 IR J Pure
Deal.

semantics Deal agents perform joint plan (J1; J2)
probability p, symmetric joint plan (J2 ; J1) probability 1 , p (where agents
switched roles J ). symmetric abilities assumption Section 2.4,
agents able execute parts joint plan, cost role
independent agent executes it.

Definition 6

= (J : p) Deal, Cost () defined pc(J ) + (1 , p)c(J ) (where k


i's opponent).



k

Deal, Utility () defined c(s ! G ) , Cost ():






utility (or benefit) agent deal simply difference
cost achieving goal alone expected part deal. Note write (for
example) c(s ! G ) rather c(s ! G ); since cost plan independent
agent executing it.
k





Definition 7

Deal individual rational if, i, Utility () 0:
Deal pareto optimal exist another Deal dominates it|


exist another Deal better one agents worse
other.

negotiation set NS set deals individual rational
pareto optimal.

necessary condition negotiation set empty contradiction two agents' goals, i.e., G1 \ G2 6= ;. states exist
intersection agents' goal sets might, course, reachable given domain
actions agents disposal. condition reachability sucient
NS empty, however, even contradiction
agents' goals, may still cooperative solution them. situation,
joint plan satisfies union goals cost one agent (or both)
would spent achieving goal isolation (that is, deal individual rational).
example Slotted Blocks Domain, consider following encounter.
initial state seen left Figure 5. A1's goal \The White block slot 2
table" A2 's goal \The Black block slot 1 table."
achieve goal alone, agent execute one PickUp one PutDown;
c(s ! G ) = 2. two goals contradict one another, exists state


178

fiMechanisms Automated Negotiation

world satisfies (where White Black blocks placed
Gray block). exist joint plan moves world initial
state state satisfies two goals total cost less eight2 |that is, deal
individual rational.
Initial State

1

A1s
goal

2

3

1

.
.
.

2

3

Joint plan

1

A2s
goal

2

.
.
.

1

2

3

1

2

3

Figure 5: Con ict Exists Even Though Union Goals Achievable
existence joint plan moves world initial state mutuallydesired state G1 \ G2 necessary (but sucient) condition negotiation set
non-empty. agents agree joint plan, individual rational.
means sum roles agents play exceed sum
individual stand-alone costs (otherwise, least one agents would get positive
utility, i.e., work stand-alone plan). even condition
sucient guarantee individual rational deal, since case minimal
role joint plan still expensive agent minimum stand-alone cost.
Even probabilistic mixture two roles reduce expected cost
agent cost minimal role (and thus role individual rational
him).
show, however, combination conditions necessary sucient negotiation set empty.

Theorem 1 necessary sucient condition negotiation set empty
existence joint plan moves world initial state state G1 \ G2
also satisfies following two conditions (the sum condition min condition):

joint plan J satisfies sum condition

X2 c(s ! G ) X2 c(J ) :


=1



=1





2. One agent lifts white block, agent rearranges blocks suitably (by picking
putting block once), whereupon white block put down. best plan
block picked put once.

179

fiZlotkin & Rosenschein

joint plan J satisfies min condition
2

2

min
c(s ! G ) min
c(J ) :
=1
=1








Proof:

NS 6= ;; let J : p mixed joint plan NS; thus, individual rational.
8i 2 f1; 2g
Utility (J : p) 0
c(s ! G ) , Cost (J : p) 0
c(s ! G ) Cost (J : p)
c(s ! G ) pc(J ) + (1 , p)c(J )
min 2f1 2gc(J )
c(s ! G )
c (J )










X

X



k

;

l



2f1 2g

;



;

min c(s ! G ) min c(J )

2f1 2g





l

2f1 2g





2f1 2g



;





;

Let J minimal total cost joint plan moves world state state
G1 \ G2 ; also satisfies sum min conditions. show NS =
6 ;;
sucient show exists deal individual rational pareto
optimal. Without loss generality, assume c(s ! G2) c(s ! G1 )
c(J )2 c(J )1: min condition, see c(s ! G1) c(J )1:
two cases:

{ c(s ! G2) c(J )2; deal J : 1 individual rational.
{ c(s ! G2) < c(J )2; deal J : p (where p = 1 ,
individual rational.

( ! 1 ), ( )1 )
( )2 , ( )1

c

c J

G

c J

c J



J : p also pareto optimal, another deal J 0 : q dominates J : p
J 0 : q also individual rational therefore satisfies min sum conditions

(see proof, above, initial half theorem).
Since J 0 : q dominates J : p also implies

X



2f1 2g

Utility (J 0 : q ) >


;

X Utility (J : p):

X

true

2f1 2g



;

X c(J ) :

c(J 0) <


;



2f1 2g



2f1 2g





;

contradicts fact J minimal total cost joint plan satisfies
sum min conditions.
180

fiMechanisms Automated Negotiation

sum condition states sum roles exceed sum individual
agents' stand-alone costs. min condition states minimal role joint plan
less minimum stand-alone cost.
conditions Theorem 1 true, say encounters cooperative. encounters, agents use negotiation mechanism mixed joint
plans. question next examine kind negotiation mechanism
use.

4.2 Mechanisms Maximize Product Utilities

general would like negotiation mechanism symmetrically distributed,
would also like negotiation strategy (for mechanism)
equilibrium itself. symmetrically distributed mechanism one agents
play according rules, e.g., special agents different responsibility negotiation process. asymmetric negotiation mechanisms used,
problem responsibility assignment needs resolved first (e.g.,
coordinator agent). would need special mechanism responsibility assignment negotiation. mechanism also asymmetric need another mechanism,
on. Therefore, better symmetric negotiation mechanism start with.
Among symmetric mechanisms, prefer symmetric negotiation strategy equilibrium. Given negotiation mechanism , say
negotiation strategy equilibrium if, assumption
agents using strategy using , (or agent) cannot better using
negotiation strategy different .
Among symmetrically distributed negotiation mechanisms symmetric
negotiation strategy equilibrium, prefer maximize product
agents' utilities. means agents play equilibrium strategy,
agree deal maximizes product utilities. one
product-maximizing deal, agree deal (among product maximizers)
maximizes sum utilities. one sum-maximizing product
maximizer, protocol choose among deals arbitrary probability.
definition implies individual rationality pareto optimality agreed-upon
deals.
Note maximization product utilities decision agents
assumed making run-time; property negotiation mechanism agreed
upon agent designers (i.e., exploring happens protocol designers
would agree property). classic game theory terms (see Section 9.1),
protocol acts kind \mediator," recommending \maximization product
utilities" cases.
call class mechanisms Product Maximizing Mechanisms, PMMs.
previous work TODs (Zlotkin & Rosenschein, 1989, 1993a) presented Monotonic
Concession Protocol One-Step Protocol, PMMs. mentioned
above, paper examine computational issues arise discovering deals.
number existing approaches bargaining problem game theory.
One earliest popular Nash's axiomatic approach (Nash, 1950; Luce
181

fiZlotkin & Rosenschein

& Raiffa, 1957). Nash trying axiomatically define \fair" solution bargaining
situation. listed following criteria ones fair solution would satisfy:
1. Individual rationality (it would fair participant get less would
anyway without agreement);
2. Pareto Optimality (a fair solution specify agreement could improved
one participant without harming other);
3. Symmetry (if situation symmetric, i.e., agents would get utility
without agreement, every possible deal, symmetric deal also possible,
fair solution also symmetric, i.e., give participants
utility);
4. Invariance respect linear utility transformations. example, imagine two
agents negotiating divide $100. one agent measures utility
dollars measures cents, uence fair solution.
Similarly, one agent already $10 bank, evaluates deal gives
x dollars utility 10 + x evaluates deal
utility x, uence fair solution (i.e., change origin doesn't affect
solution);
5. Independence irrelevant alternatives. Imagine two agents negotiating
divide 10,000 cents. Nash solution 5,000 cents each, due
symmetry assumption above. imagine agents negotiating
$100. Even though deals can't reach (for example,
one one agent gets $49.99, gets $50.01), solution
same, original solution 5,000 cents still found new
deal space.
Nash showed product maximizing solution satisfies criteria,
solution satisfies them. first four criteria explicitly
implicitly assumed approach (in fact, example, version fourth
assumption restrictive Nash's). fifth criteria assumed
work, turns true cases anyway. use Nash solution,
general, reasonable bargaining outcome, applicable. Nash, however,
assumptions space deals have. example,
Nash bargaining problem assumes bounded, convex, continuous, closed region
negotiation. agent negotiations, assume space deals convex,
continuous.

4.3 Worth Goal

encounter cooperative, agents use PMM mixed joint plans.
mechanism guarantees fair ecient cooperative agreement. question now,
however, done non-cooperative encounters?
Consider encounter Restricted Usage Shared Resource Domain
three agents, one resource maximal capacity two. Agents 1
182

fiMechanisms Automated Negotiation




e

A1

Agents
A2

A3

0 Use Use Wait
1 Use Use Wait
2 NOP Use Use
3 NOP NOP Use
4 NOP NOP NOP

0
1
2
3
4
5

A1

Agents
A2

A3

Use Wait Use
Use Wait Use
NOP Use NOP
NOP Use NOP
NOP Use NOP
NOP NOP NOP

Figure 6: Two Joint Plans Restricted Usage Shared Resource Domain
3 need two units resource agent 2 needs 3 units resource.
agent, alone world, could achieve goal cost (i.e., without waiting
resource). However, since maximal capacity resource two, three
agents together cannot achieve combined goal without agent wait.
Two possible joint plans achieve agents' goals seen Figure 6. left
joint plan gives agents 1 2 utility 0, giving agent 3 utility ,2. right joint
plan gives agents 1 3 utility 0, giving agent 2 utility ,2. Globally, plan
left finishes sooner. perspective individual agents, two plans
really comparable|in one, agent 3 suffers waiting two time units, other,
agent 2 suffers exactly amount. assumed, however, agents
concerned global aspects resource utilization, concerned
local cost. addition, plans Pareto Optimal, neither
individual rational (because one agent gets negative utility).
exists joint plan J brings world state satisfies agents'
goals, either min condition sum condition true, agents
cooperatively bring world state satisfies agents' goals, least one
alone world achieved
goals. either one agree extra work? depends important
goal agent i, i.e., much willing pay bring world state G .
example, Shared Resource encounter above, agent 2 3 might willing
wait two time units get turn resource. Although could
done better alone world, must cope presence
agents. original definition utility, deal achieves agents' goals
individual rational|someone wait, thus get negative utility.
utility definition, agent willing wait. agents fail reach
agreement, one achieve goal. utility calculated
difference cost agent's plan alone world cost
role joint plan agents.
However, agents use stand-alone cost baseline determining
utility? may case agents willing, presence agents,
admit need pay extra cost, sort \coordination overhead." fact
agents around necessarily make irrational more.


183

fiZlotkin & Rosenschein

Task Oriented Domains (Zlotkin & Rosenschein, 1989, 1993a, 1994), reasonable
use stand-alone cost utility baseline since never coordination overhead.
worst case, agent could always achieve goal stand-alone price,
coordination could improve situation. State Oriented Domains, however,
makes sense consider altering utility baseline, agents rationally coordinate
even exists coordination overhead. One way assume
agent upper bound cost willing bear achieve goal.
Then, agent's utility measured relative upper bound. call upper
bound worth agent's goal.
Even TODs, one conceive stand-alone cost worth agent assigns
achieving goal. stand-alone cost maximum agent willing
expend. TOD, maximum need never violated, it's reasonable worth value
use.
upper bound exist, i.e., agent willing achieve goal
cost, techniques used (see Section 6 below).

Definition 8 Given encounter two-agent SOD < s; (G1; G2) >, let w maxi

imum expected cost agent willing pay order achieve goal G . w
called worth goal G agent i. denote enhanced encounter
< s; (G1; G2); (w1; w2) > :






definition Utility usefully altered follows:

Definition 9 Given encounter < s; (G1; G2); (w1; w2) >; deal, i.e., mixed
joint plan satisfying agents' goals, Utility ( ) defined w , Cost ( ):






utility agent deal difference worth goal
achieved, cost role agreed-upon joint plan. agent achieves
goal alone, utility difference worth goal cost
pays achieve goal. point is, agent might better alone still
derive positive utility joint plan, use worth utility baseline.
new definition utility, may rational compromise.

Theorem 2 Theorem 1 change every occurrence c(s ! G ) w ,


theorem still true.



Proof: Substitute w every occurrence c(s ! G ) proof Theorem 1.




introducing worth concept definition encounter, enlarged
number encounters non-empty negotiation set. Cooperative behavior
enhanced. negotiation mechanism, makes use product maximizing protocol,
becomes applicable SOD encounters.

4.4 Interaction Types

discussion above, begun see emerging different kinds encounters
agents. TOD meetings, agents really benefit coordination. SODs,
184

fiMechanisms Automated Negotiation

isn't necessarily case. Sometimes agents benefit, sometimes called upon
bear coordination overhead everyone achieve goals. even extreme
situations, agents' goals may simply con ict, might impossible satisfy
time, coordination overhead may exceed willingness
agents bear required burden.
four possible interactions, point view individual agent:

symmetric cooperative situation one exists deal negotiation

set preferred agents achieving goals alone. Here, agents
welcome existence agent.
symmetric compromise situation one individual rational deals
agents. However, agents would prefer alone world,
accomplish goals alone. Since agent forced cope presence
other, would prefer agree reasonable deal. deals NS
better agents leaving world initial state s.
non-symmetric cooperative/compromise situation one one agent views
interaction cooperative (he welcomes existence agent),
second views interaction compromise (he would prefer alone
world).
con ict situation one negotiation set empty|no individual rational
deals exist.
general SOD, four types interaction arise. TOD, symmetric
cooperative situation ever exists.



u





@@
@@
@@@@
@R

G1

G2

Figure 7: Symmetric Cooperative Situation
situations visualized informally using diagrams. symmetric
cooperative situation seen Figure 7, symmetric compromise situation Figure 8, non-symmetric cooperative/compromise situation Figure 9, con ict
situation Figure 10. point plane represents state world. oval
represents collection world states satisfies agent's goal. initial state
world. triple lines emanating represent joint plan moves world
final state. agents share carrying joint plan.
185

fiZlotkin & Rosenschein



u


@
@@
@@

@@@R G1

G2

Figure 8: Symmetric Compromise Situation



u


@
@@ G
@@@@ 2
@R

G1

Figure 9: Non-Symmetric Cooperative/Compromise Situation
overlap ovals represents final states satisfy goals agents A1
A2 . Informally, distance either oval represents cost associated
single-agent plan transforms world state satisfying agent's goal.
Note Figure 8, distance either agent's oval less distance
overlap ovals. represents situation would easier
agent simply satisfy goal, alone world. Figure 7, agent
actually benefits existence other, since share work joint

u





-

q

G1

?

G2

Figure 10: Con ict Situation
186

fiMechanisms Automated Negotiation

plan. Note Figure 9, one agent benefits existence other,
would prefer alone world.
Let's consider simple examples slotted blocks world domain cooperative,
compromise, con ict situations. initial situation depicted Figure 11, white
block slot 1 black block slot 2. Agent A1 wants white block alone
slot 2, agent A2 wants black block alone slot 1. either agents alone
world, would cost 4 pickup/putdown operations achieve goal.
example, A1 would pick black block slot 2 move slot 3,
pick white block slot 1 move slot 2. two agents together, however,
able achieve goals total cost 4. execute joint plan
simultaneously pick blocks, put appropriate places.
role joint plan costs 2, agent derives utility 2 reaching
agreement other. cooperative situation. Coordination results actual
benefit agents.

Initial State

1

2

A1s goal

3

1

A2s goal

2

Joint plan
1

2

1

2

3

3

1

2

3

Figure 11: Cooperative Situation
let's consider complicated, compromise, situation. initial state shown
Figure 12, white block slot 1, black block slot 2, two gray blocks
slot 3. Agent A1 's goal white block somewhere slot 2,
table. Similarly, agent A2 's goal black block somewhere slot 1,
table. Alone world, agent A1 would one pickup one putdown
operation, moving white block onto black block slot 2. way,
agent A2 alone world achieve goal two operations. since
(in stand-alone plan) using other's block base, achievement state
satisfies agents' goals requires additional blocks operations.
best plan achieving agents' goals requires moving one gray block slot
3 slot 1 gray block slot 2 act bases white
black blocks. block needs picked put least once; best plan
187

fiZlotkin & Rosenschein

block moving total cost 8. Obviously, one agents need
extra work (greater stand-alone situation) bring mutually
satisfying state.
Initial State

1

2

A1s
goal
3

1
1

.
.
.

2

3

Joint plan

A2s
goal

2

.
.
.

1

2

3

1

2

3

Figure 12: Compromise Situation
best plan two roles, one requiring 6 operations one requiring 2 operations.
One agent lift black (or white) block, agent rearranges
blocks appropriately. first agent put black (or white) block,
completing plan. agents' worths satisfy min sum conditions (meaning,
here, sum worths greater equal 8, worth greater
equal 2), reach agreement gives positive utility
(using worth new baseline evaluating utility).
example, let's say agent A1 assigned worth 3 achieving goal,
agent A2 assigned worth 6 achieving goal. Since one role best joint plan
costs 2 costs 6, one unit utility shared agents.
mechanism maximizes product utilities split one unit equally
agents. done case? one deal negotiation set
gives agents expected utility 21 , namely mixed joint plan
agent A1 cost-2 role probability 78 , cost-6 role probability
1
A2 course assumes complementary role. Agent A1 's expected utility
8 . Agent
7
3 , 2( 8 ) , 6( 18 ) = 12 ; equal agent A2 's expected utility 6 , 2( 18 ) , 6( 78 ) = 12 :
division utility maximizes product expected utility among agents.
interesting phenomenon note deal. agents apparently
symmetric situation, apart internal attitude towards achieving goals
(i.e., much willing pay). seen above,
willing pay, pay. agent worth 3 ends
less expected work agent worth 6. gives agents incentive
misrepresent true worth values, pretending worth values smaller
really are, agents' positions within negotiation strengthened.
agent feign indifference, claim really doesn't care much achieving
188

fiMechanisms Automated Negotiation

goal, come better negotiation (with lower expected cost). examine
question greater detail Section 8.
final example con ict situation, shown Figure 13. Again, white
block slot 1 black block slot 2|the initial state
cooperative compromise examples. cooperative example, agents wanted
blocks moved another, empty slot. compromise example, agents wanted
blocks moved specific non-empty slot. Here, con ict example, agents want
blocks moved onto specific block specific slot. Agent A1 wants white
block top black block slot 2; agent A2 wants black block top white
block slot 1. Here, real contradiction two agents' goals.
exists world state satisfies both. next section, discuss
kinds coordination mechanisms used con ict situation.
Initial State

1

2

A1s
goal
3

1

A2s
goal
1

2

1

3

1

?

2

3

2

3

2

Figure 13: Con ict Situation
negotiation set empty, distinguish compromise
cooperative situations particular agent using following algorithm:
1. w c(s ! G ); agent cooperative situation.
2. w > c(s ! G ); agent might cooperative compromise situation.
way distinguish follows:
(a) Set w = c(s ! G ); leave agent's worths unchanged.
(b) resulting NS empty, agent compromise situation.
(c) Otherwise, agent cooperative situation.












5. Con ict Resolution Cooperation

seen cooperative compromise encounters exist deals
individual rational agents. Agents negotiate deals
reached, one. What, however, done agents
189

fiZlotkin & Rosenschein

con ict situation, i.e., individual rational deals? Here, agents true
con ict needs resolved, merely choosing among mutually acceptable
outcomes.

5.1 Con ict Resolution

simple approach con ict resolution would agents ip coin decide
going achieve goal going disappointed. See Figure 14.
case negotiate probabilities (weightings) coin toss. run
con ict negotiation (fail agree coin toss weighting), world
stay initial state s.3
Initial State

1

2

A1s Goal

3

1

2

3

Flip coin
A2s Goal
1

2

1

2

3

1

2

3

Figure 14: Con ict Resolution
deal visualized graphically Figure 15. Single lines represent one agent
plans.
con ict situations agents use utility product maximizing protocol
decide weighting coin. However, turns case probability
12 always results maximum product two agents' utilities. agents
maximize utility product, always agree symmetric coin.
exception initial state already satisfies one agent's goal. Then, agent
simply cause negotiation fail, rather risk moving away goal-satisfying
state. Nevertheless, even here, product maximizing deal would agents ip
symmetric coin.
symmetric coin going maximize product agent utilities? simple
mathematics shows reason. Assume agent A1 worth w1, cost
achieving goal alone c1 . A1 wins coin toss, utility w1 , c1.
utility deal coin weighting p p(w1 , c1). opponent's utility
3. special case initial state already satisfies one agent's goals, let's say agent
1 (s cannot satisfy goals since would con ict situation). case,
agreement reached leave world state s. Agent 1 agree deal
cause negotiation fail.

190

fiMechanisms Automated Negotiation

u





-

q

G

?



G

b

Figure 15: Con ict Situation
deal (1 , p)(w2 , c2). product two agents' utilities
(p , p2 )(w1 , c1)(w2 , c2). function p maximized p equals 21 values
w1; w2; c1; c2 (simply take derivative function set equal zero).
may seem like \fair" solution, certainly ecient one.
maximizing product agents' utilities, maximize sum. sum
utilities maximized simply agent larger w , c achieve
goal. This, hand, certainly fair solution.
might able fair ecient agents able transfer utility one
another. case, one agent could achieve goal share part utility
agent. negotiation would center much utility
transferred! product maximizing mechanism used resolve question transfer
half gained utility agent, constant sum game, dividing
utility equally maximizes utility product.
entire subject explicit utility transfer side payments complicated one
treated length game theory community. intention
examine questions paper. Even utility explicitly transferable, agents
make commitments perform future actions, effect transfer utility
promises. Again, many complicated issues involved assessing value
promises, believed, discount factors, limits amount
promising debts agent accrue. agents accumulate debt indefinitely,
possible always pay previous commitments making additional
commitments others. Here, too, leaving issues aside, returning
assumptions interaction stands own, explicit side payments
possible.




5.2 Cooperation Con ict Resolution
cooperative compromise situations, agents implicitly able transfer utility
single encounter actions joint plan. agent
work joint plan relieves agent, increasing latter's utility.
thought kind utility transfer. Here, see similar kind implicit utility
transfer possible even con ict situations.
191

fiZlotkin & Rosenschein

agents may find that, instead simply ipping coin con ict situation,
better cooperatively reach new world state (not satisfying either
goals) ip coin decide whose goal ultimately satisfied.
Consider following example. One agent wants block currently slot 2
slot 3; agent wants slot 1. addition, agents share goal
swapping two blocks currently slot 4 (i.e., reverse stack's order). See Figure 16.
Assume W1 = W2 = 12. cost agent achieving goal alone 10.
agents decide ip coin initial state, agree weighting 21 ,
brings utility 1 (i.e., 12 (12 , 10)). If, hand, decide swap
cooperatively (at cost 2 each), ip coin, still agree weighting
12 , brings overall utility 4 (i.e., 12 (12 , 2 , 2)).
Initial State

1

2

3

A1s goal
4

1

2

3

4

Semi-cooperative
deal

A2s goal

2

1

1

2

3

4

1

2

3

4

Figure 16: Cooperation Certain Point
fact agents, even con ict situation, get utility first cooperatively working together, ipping coin, exploited defining new
kind deal, called Semi-Cooperative Deal. want agents able negotiate
agree deal allows mixed cooperative/con ict resolution interaction.
Changing deal type enough make possible. ends increasing expected
utility agents derive encounter.

Definition 10 Semi-Cooperative Deal tuple (t; J; q) world state, J

mixed joint plan moves world initial state intermediate state t,
0 q 1 2 IR weighting coin toss|the probability agent A1 achieve
goal.

semantics kind deal two agents perform mixed joint
plan J , bring world intermediate state t. Then, state t, ip
coin weighting q decide continues plan towards goal. allows
agents handle con ict goals, still cooperating certain
point.
192

fiMechanisms Automated Negotiation

utility semi-cooperative deal agent defined follows. loses
coin toss intermediate state t, simply negative expected utility equal
expected cost role joint plan reached state t. wins coin toss
intermediate state t, expected utility difference worth goal
costs role joint plan reached well stand-alone cost
moving goal state. written formally follows:

Definition 11
Utility (t; J; q ) = q (w , c(J ) , c(t ! G ) ) , (1 , q )c(J )
= q (w , c(t ! G ) ) , c(J )


























assumes, course, agents' goals con ict|the state satisfies
one agent worth other.
Semi-Cooperative Deal visualized graphically Figure 17. figure
similar spirit figures presented Section 4.4, represented cooperative,
compromise, con ict encounters. Again, triple line represents joint plan
single line represents one-agent plan.

u
u





@@
@@@R

q

- G1

?

G2

Figure 17: Semi-Cooperative Deal

5.3 Semi-Cooperative Deals Non-Con ict Situations

cooperative compromise situations, agents negotiate deals mixed
joint plans, J : p (cooperative deals). con ict situation, agents negotiate deals
form (t; J; q ) (semi-cooperative deals).
Even though semi-cooperative deals intended used con ict situations,
also used cooperative compromise situations (with minor generalization
definition utility, discussed below). question is, kinds agreements
agents non-con ict situation reach, negotiating semi-cooperative deals?
better using standard cooperative (mixed joint plan) deals?
worse?
cooperative deal mixed joint plan J : p also represented (J (s); J : p; 0)
J (s) final world state resulting joint plan J initial state s.
words, mixed deals proper subset semi-cooperative deals, mixed
193

fiZlotkin & Rosenschein

deal represented semi-cooperative deal special form. intermediate state
taken final state agents' cooperative joint plan. Since final state
satisfies agents' goals, result coin ip irrelevant|neither agents
wants change world state anyway.
Therefore, agents non-con ict situation negotiate semi-cooperative
deals, enlarging space agreements. deal reached
negotiating subset (i.e., mixed joint plans) also reached negotiating
larger set (i.e., semi-cooperative plans). agents non-con ict situation
certainly worse, using semi-cooperative deals. better?
two potential ways agents could better. first would
agents find cheaper way achieve goals. turns impossible|
semi-cooperative deals uncover ecient way achieving agents' goals.
However, surprising way agents benefit semi-cooperative
deals. Agents benefit always achieving goals. using semi-cooperative
deals, give guaranteed goal satisfaction, gain expected utility.
see mean, consider following example Slotted Blocks World.
initial situation Figure 18 consists 5 duplications example Figure 5, slots
1 15. addition, two slots (16 17) contain stack 2 blocks. Agent A1 's goal
\White blocks slots 2; 5; 8; 11 14 table; blocks slots 16
swapped, blocks slot 17 swapped (i.e., tower reversed)." Agent
A2's goal \Black blocks slots 1; 4; 7; 10 13 table; blocks
slot 16 swapped, blocks slot 17 swapped."
Initial State

1

2

...

3

13

14

15

16

17

15

16

17

A1s goal
.
1

2

.
3

...

13

14

A2s goal
.
1

.
2

3

...

13

14

15

16

17

Figure 18: Semi-Cooperative Agreement Cooperative Situation
stand-alone cost agents is: c(s ! G ) = 26 = (5 2)+(2 8). Let's assume
w = 26 also worth goal. minimal cost joint plan achieves
agents' goals 7 parts:




Cooperative swap slot 17 agent one pickup one putdown;
swap slot 16;
194

fiMechanisms Automated Negotiation

Five duplications joint plan Example 5. joint plans
role costs 6 role costs 2.

Thus average cost agent's role joint plan 24, namely (2 2) +
(5 12 (6 + 2)): Since stand-alone cost 26, situation cooperative|each agent
welcomes existence other. agents, expected utility joint plan
2 (i.e., 26 , 24). cooperative deal achieves agents' goals.
find semi-cooperative deal better? agents cooperated
swapping blocks slots 16 17, tossed coin see gets fulfill
goal (leaving other's goal unsatisfied)? semi-cooperative deal actually turns
better agents.
Let intermediate state state blocks slots 16 17 swapped,
slots unchanged. agent invests 4 operations part two
swaps. chance 12 continuing achieve goal, chance
12 losing coin toss wasted initial investment. wins coin toss,
additional 10 operations (5 2), achieve goal worth 26. Overall
utility 26 , 10 , 4; i.e., 12. loses coin toss, wasted initial
investment 4, utility ,4. expected utility average two cases,
i.e., 4. better utility 2 agents got using cooperative deal!
words, case, agents would prefer guarantee
goal, take gamble semi-cooperative deal. expected utility doubles,
willing take risk. even cooperative situation, agents benefit
negotiating semi-cooperative deals.
Now, turns borderline situation, brought w low.
long w high enough, semi-cooperative deal agents agree cooperative
situation equivalent cooperative deal. achieving goal isn't worth much
(your profit margin small), might willing forgo guaranteed achievement
exchange higher expected utility.
semi-cooperative deals, used non-con ict situation, sometimes result better
agreements (when forgoing guaranteed goal achievement beneficial), never result
worse agreements. Clearly, worthwhile agents negotiate semi-cooperative
deals, regardless whether cooperative, compromise, con ict situations.




5.4 Unified Negotiation Protocols (UNP)

section, make necessary generalizations agents use semicooperative deals types encounters. call product maximizing mechanisms
based semi-cooperative deals \Unified Negotiation Protocols (UNP)," since
used con ict resolution, well cooperative agreements.4
mentioned above, need generalize previous definition utility
semi-cooperative deal, enable UNPs. Before, assumed (since con ict
situation) final state would benefit agent lost coin toss.
4. earlier version subsection next two appeared (Zlotkin & Rosenschein, 1991a).
current treatment incorporates new material multi-plan deals, recasts protocols context
domain theory, alters notation correspond general domain framework.

195

fiZlotkin & Rosenschein

Now, even though semi-cooperative deal used, final state might still satisfy
agents' goals, goal agent wins coin toss.
(t; J; q ) semi-cooperative deal, we'll define f final state world
agent wins coin toss state t. f = (t ! G )(t) 2 G . worth agent
state r, write W (r), goal worth w r goal state,
0 otherwise. Now, revise definition utility semi-cooperative deals:












Definition 12 Utility (t; J; q) = q (w , c(t ! G ) ) + (1 , q )w (f ) , c(J )












j



utility semi-cooperative deal (t; J; q ) agent defined
expected worth final state minus expected cost. worth expected final
state, course, depends weighting coin, whether possible final
states (or one) goal states agent. Similarly, expected cost depends
weighting coin (whether agent participates first, joint, plan,
also continues second, lone, plan).
definition utility given completely consistent earlier definition
utility cooperative deals, viewed generalization earlier
definition. words, cooperative deal (a mixed joint plan) mapped
semi-cooperative deal (t; J; q ) using transformation discussed above, definition
utility mixed joint plan (Definition 9) definition utility (Definition 12)
semi-cooperative deal yield number.
sucient condition negotiation set non-empty semi-cooperative
deals agents' worths high enough, agent would able achieve
goal alone:

Theorem 3 agent worth goal greater equal standalone cost (i.e., 8i w c(s ! G )), negotiation set semi-cooperative deals
empty.




Proof: show NS 6= ;; sucient show individual rational

semi-cooperative deal. existence pareto-optimal deals among individual rational
deals due compactness deal space (since finite number
agent operations, worth agent goals bounded). (s; ; q ); empty
joint deal, individual rational q:
condition sucient, necessary, negotiation set nonempty. example, consider situation given Figure 16, agents'
worths equal 8 (instead 12). Neither agent achieve goal alone, thus
conditions theorem satisfied. However, perfectly good
semi-cooperative deal gives agents positive utility|they perform joint plan
swaps blocks slot 4, ip coin see whether block slot 2 goes slot 1
3. mixed deal gives agent expected utility 1. negotiation set
empty.
turns semi-cooperative deal negotiation set, one
agents, winning coin toss, bring world state satisfies agents'
goals, exists another deal negotiation set utility
agents intermediate state already satisfies agents' goals.
196

fiMechanisms Automated Negotiation

Theorem 4 semi-cooperative deal (t; J; q) 2 NS, exists f 2
G1 \ G2, semi-cooperative deal equivalent cooperative deal.
Proof: two cases: final states, one final state, G1 \ G2:
f1; f2 2 G1 \ G2; view last step performing mixed joint plan
moves world state state G1 \ G2 .
c(t ! G1) = c(t ! G1 \ G2) = c(t ! G2 );
X (t ! )(t) 2 X; c(t ! X ) = c(t ! ): f1 ; f2
necessarily state, deal equivalent deal f1 = f2 :
look concatenation two mixed joint plans (the first J
t, second ! G1 \ G2 ), mixed joint plan P G1 \ G2 : P
cooperative deal equivalent (t; J; q );
Utility (t; J; q ) = q (w , c(t ! G )) + (1 , q )(w ) , c(J )
= w , (q c(t ! G ) + c(J ) )
= w , c(P )
= Utility (P ):






























f1 2 G1 \ G2 f2 62 G1 \ G2; agent 2 would prefer lose coin toss
state let agent 1 achieve goal without spending more.
deal (t; J; 1) better 1 better 2 well, dominates
(t; J; q ); (t; J; q ) 2 NS; equivalent. (t; J; 1) equivalent mixed
joint plan P agents perform joint plan J t; agent 1
performs one-agent plan ! G1 \ G2: P cooperative deal.

words, exists semi-cooperative deal negotiation set sometimes satisfies agents' goals (depending wins coin toss), also
exists another semi-cooperative deal negotiation set always satisfies agents'
goals (equivalent cooperative deal). Even though semi-cooperative deals constitute
superset cooperative deals, extra utility derived using semi-cooperative deals
agreement preserves mutual satisfaction agents (i.e., it's equivalent
cooperative deal).
cooperative situation, agents cannot extract utility semi-cooperative
deal, unless willing agree deal never satisfy agents' goals.
example (Section 5.3) prototype situation. Agents increase
utility using semi-cooperative deal cooperative situation. forgoing
guaranteed mutual satisfaction. theorem implies way
increase utility semi-cooperative deals.

5.5 Multi-Plan Deals

semi-cooperative deals, assume agents cooperate, ip coin, winner
proceeds alone achieve goal. arrangement requires agents engage
197

fiZlotkin & Rosenschein

\pre- ip cooperation." agents willing (or required) also engage
\post- ip cooperation"? Then, entirely new dimension agreements would opened
up. section, consider kind deal exploits cooperation coin toss.
illustrate potential new kind deal, consider following encounter,
shown Figure 19.
A1s
Goal

Initial
State
1

2

3

1

2
1

3

?

2

A2s
Goal
1

2

3

1

2

3

Figure 19: Post-Flip Cooperation Helpful
initial state world seen Figure 19. A1 's goal swap position
blocks slot 3, leave blocks slot 2 initial position. A2 's goal
swap position blocks slot 2, leave blocks slot 3 initial
position.
achieve goal alone, agent needs least 8 pickup putdown operations.
Apparently, little room cooperation. final state
satisfies agents' goals, intermediate state (other initial state)
agents cooperatively bring world, tossing coin (as semicooperative deal).
Negotiating semi-cooperative deals, agents agree ip coin initial
state, whoever wins coin toss bring world goal state
(at cost 8). Assume worth agent's goal 10. negotiating
semi-cooperative deals brings agent expected utility 1. compromise
situation (alone world, agent would utility 2).
agents could reach following agreement (as shown Figure 20):
ip coin initial state. Whoever wins toss gets goal satisfied. However,
matter wins, agents commit work together joint plan achieve
chosen goal.
either swap jointly costs total 4 two agents (2 each). agent
wins coin toss gets utility 10 , 2 (his goal satisfied expends 2
joint plan). agent loses gets utility ,2 (he expends 2 joint plan
achieves opponent's goal). agent equal chance winning coin
toss, expected utility 3. better semi-cooperative deal gave
198

fiMechanisms Automated Negotiation

2

1
1

1

2

2
3
1

2

3

Multi-plan deal
1

2

1

2

3

Figure 20: Multi-Plan Deal
agents utility 1. It's even better stand-alone utility 2
agents could get alone! Suddenly, situation become cooperative.
agents welcome other's existence, even though goals nothing common.
goal state satisfies agents; subgoals agents
common; positive interactions agents' stand-alone plans.
goals completely decoupled, yet situation cooperative.
agreement above, course, requires \post- ip cooperation." semi-cooperative
deals, \pre- ip cooperation" contributed potentially either agents' benefit|either
agent might win coin toss exploit early work. new deal type, even
agent loses coin toss required expend effort, knowing
benefit agent.
agents commit post- ip cooperation, new deal type
possible. Agents could negotiate deals pairs mixed joint plans.
call new deals multi-plan deals. committing post- ip cooperation, agents
enlarge space agreements, potentially improves expected utility.

Definition 13

Multi-Plan Deal (1; 2; q); mixed joint plan moves
world state satisfies i's goal. 0 q 1 2 IR probability agents
perform 1 (they perform 2 probability 1 , q ).
Assuming j i's opponent, Utility (1; 2; q) = q(w , Cost ( )) , (1 ,




q )Cost ( ).








j

multi-plan deal agents agreeing two joint plans, deciding execute tossing coin. deal visualized informally Figure 21, Section 4.4
above. triple line represents joint plan, carried multiple agents.
Note symmetric abilities assumption Section 2.4 may essential
(i.e., multi-plan deal type agents may need able perform
199

fiZlotkin & Rosenschein

u





-

q

G1

?

G2

Figure 21: Multi-Plan Deal

plans equivalent cost). two mixed joint plans comprise multi-plan deal might
pure (i.e., p 0 1) without overly restricting agents' ability divide
utility accurately, since agents additional q probability adjust.
semi-cooperative deals used cooperative situations, multi-plan deals
also used cooperative situations (since, see below, generalization
semi-cooperative deals). needed enhance definition multi-plan deal
utility appropriately, done semi-cooperative deals (Definition 12).
Consider following example, shows increased utility available agents
share negotiate multi-plan deals instead mixed joint plans.

2

1
1

1

2

2
3
1

2

3

Multi-plan deal
1

2

1

2

3

Figure 22: Relationship Multi-Plan Deal Type Mixed Joint Plans
initial state world seen Figure 22. A1 's goal swap position
blocks slot 3, leave blocks slot 2 initial position (there
one state satisfies goal; call f1 ). A2 's goal swap position blocks
slot 2, leave blocks slot 3 initial position (f2 ).
achieve goal alone, agent needs least 8 pickup putdown operations
(each cost 1). Assume A1 's worth function assigns 10 f1 0
states, A2 's worth function assigns 10 f2 0 states. case,
200

fiMechanisms Automated Negotiation

negotiation set includes deals (s ! f1 ; ): 1 (; ! f2 ): 0. Using protocol
mentioned above, agents break symmetry situation ipping coin.
utility agent deal 1 = 12 (10 , 8).
Negotiation multi-plan deal type cause agents agree (1 ; 2): 12 ,
mixed joint plan agents cooperatively achieve i's goal.
best joint plan swap one slots costs 2 pickup/putdown operations
agent. utility agent deal 3 = ( 12 (10 , 2) + 21 (,2)).
negotiating using multi-plan deal type instead mixed joint plans, utility
agents share, 6 instead 2.


5.6 Hierarchy Deal Types | Summary

exists ordering relationship among various kinds deals agents
considered; call relationship \deal hierarchy." bottom
hierarchy pure deals mixed deals. first two types deals hierarchy
used cooperative situations. negotiation general non-cooperative domains,
additional types deals needed.
Next hierarchy come semi-cooperative deals. shown, semi-cooperative
deals superset mixed deals. Even cooperative situations, may
semi-cooperative deals achieve goals, dominate mixed
joint plans achieve agents' goals.
Finally, top hierarchy, come multi-plan deals, superset semicooperative deals. general deal type deal hierarchy. deal type
also serve foundation class Unified Negotiation Protocols.
summary, hierarchy looks follows:

fJ g fJ : pg ft; ; qg f(1; 2): qg
Pure Deals Mixed Deals Semi-Cooperative Deals Multi-Plan Deals

6. Unbounded Worth Goal|Tidy Agents

Section 4.3, assumed agent assigns finite worth achieving goal,
upper bound cost willing spend achieve goal.
upper bound exist? may situations domains
limit cost agent willing pay order achieve goal|he would
willing pay cost. Similarly, may situations agent simply unable,
design, evaluate worth goal. However, even though worth unbounded
unevaluable, agent still interested expending minimum necessary achieve
goal. agent gets utility spends less, determine ordinal
ranking possible deals, even though diculty assigning cardinal values
utility derived deals.
Nevertheless, really interested cardinal values used
negotiation mechanisms. whole approach negotiation founded existence
inter-agent comparable cardinal utility functions. worth unbounded
agents, seem deprived tool depended.
201

fiZlotkin & Rosenschein

would like identify different baseline define concept utility.
Originally, above, used baseline \stand-alone cost," c(s ! G ), taking utility
deal agent difference cost achieving goal alone
agent's part deal. Then, used baseline \worth" similar manner,
linearly transforming utility calculation. Utility deal agent
difference maximum cost willing pay agent's part
deal. worth unbounded, however, linear transformation obviously cannot
used.
work (Zlotkin & Rosenschein, 1993b), present alternative baseline
satisfy desire symmetry, fairness, simplicity, stability, eciency. turns
constitute minimum sucient baseline agents reach agreements.
minimum cost agent must offer bear compromise encounter,
neither agent upper bound worth, leaves agent
less cost latter's stand-alone cost. words, first agent offer
\clean himself," carry sucient portion joint plan achieves
goals agent's remaining part joint plan cost less
stand-alone cost. call agent willing clean tidy
agent; formal definition appears elsewhere (Zlotkin & Rosenschein, 1993b). shown
joint-goal reachable encounter (i.e., exists joint plan achieves
agents' goals), agents tidy, negotiation set empty.


7. Negotiation Incomplete Information
mechanisms considered sections straightforwardly implemented
agents full information other's goals worths. many
situations, won't case, section examine happens
negotiating mechanisms State Oriented Domains agents don't necessarily full
information other.
consider incomplete information goals, incomplete information
worths, two separate issues. agent, example, might particular information
worth, goals, vice versa. thus four possible cases,
worths known known, combined goals known known.
previous sections, considered case goals worth known.
section consider two three situations, neither goals worth
known, goals known worth not. analyze situations
worth known goals not.
general conclusion strategic player gain benefit pretending
worth lower actually is. done directly, declaring low worth (in
certain mechanisms), declaring cheaper goal (in case stand-alone cost
taken implicit worth baseline).
first section, consider space lies available different types
interactions, different types mechanisms.
several frameworks dealing incomplete information, incremental goal recognition techniques (Allen, Kautz, Pelavin, & Tenenberg, 1991),
framework explore \,1 negotiation phase" agents simultane202

fiMechanisms Automated Negotiation

ously declare private information beginning negotiation (this also introduced
elsewhere (Zlotkin & Rosenschein, 1989, 1993a) case TODs). negotiation
proceeds revealed information true. TOD case, analyzed
strategy agent adopt playing extended negotiation game,
particular, whether agent benefit declaring something true goal.
Here, take similar approach, consider ,1-phase game State Oriented
Domains. agents benefit lying private information? kinds
mechanisms devised give agents compelling incentive tell
truth?5
negotiation mechanism gives agents compelling incentive tell truth
called (in game theory) incentive compatible. Although able construct
incentive compatible mechanism used worths unknown, unable
construct mechanism State Oriented Domains used other's goals
unknown.

7.1 Worth Goal Role Lies
assume agents associate worth achievement particular goal.
Sometimes, worth exactly equal would cost agent achieve goal
himself. times, worth goal agent exceeds cost goal
agent. worth goal baseline calculating utility deal
agent; section, always assume worth bounded.
worth goal intimately connected specific deals agents agree on.
First, agent agree deal costs worth (he would
negative utility deal). Second, since agents agree deal maximizes
product utilities, agent lower worth, ultimately reduce
amount work part deal. Thus, one might expect agent A1 wants
less work, try fool agent A2 thinking that, particular goal, A1's
worth lower really is. strategy, fact, often turns beneficial,
seen below.
Let's consider following example Slotted Blocks World.
initial state seen left Figure 23. G1 \The Black block
Gray block table slot 2" G2 \The White block Gray block
table slot 1".
achieve goal alone, agent execute four PickUp four PutDown
operations cost (in total) 8. two goals contradict other,
exists state world satisfies both. also exists joint plan moves
world initial state state satisfies goals total cost 8|one
agent lifts black block, agent rearranges blocks suitably (by
picking putting block once), whereupon black block put down.
agents agree split joint plan probability 12 , leaving expected
utility 4.
5. issues, everyday human contexts, explored (Bok, 1978). immediate motivation
discouraging lies among agents negotiation mechanisms ecient.

203

fiZlotkin & Rosenschein

Initial State

1

2

A1s
goal
3

1

2

3

Joint plan

1

A2s
goal
1

2

2

3

1

2

3

Figure 23: Agents Work Together Equally

7.2 Beneficial Lies Mixed Deals

agent A1 lies true goal above, claiming wants black block
block slot 2? See Figure 24. agent A1 alone world, could
apparently satisfy relaxed goal cost 2. Assuming agent A2 reveals true goal,
agents agree one plan: agent A1 lift block (either white black
one), agent A2 rest work. apparent utility agent A1
0 (still individual rational), agent A2 utility 2. reality, agent A1
actual utility 6. Agent A1 's lie benefited him.

...
1

2

3

1

1

2

2

3

3

1

2

1

2

3

Figure 24: Agent A1 Relaxes Goal
works agent A1 able reduce apparent cost carrying
goal alone (which ultimately causes carry less burden final plan),
compromising ultimate achievement real goal. reason real goal
204

fiMechanisms Automated Negotiation

\accidentally" satisfied one state satisfies agent A2 's real goal
agent A1's apparent goal, coincidentally state satisfies real
goals.
lie agent A1 's beneficial lie example. agent A1
claimed goal \Slot 3 empty Black block clear"? See Figure 25.
Interestingly, goal quite different real goal. agent A1 alone
world, could apparently satisfy variant goal cost 4. agents forced
agree deal above: A1 two operations, apparent utility 2,
agent A2 six operations, utility 2. Again, agent A1's actual utility 6.


1

2

3

1



2

1

2

3

3

1

2

1

2

3

Figure 25: Agent A1 Makes Entirely New Goal
Task Oriented Domains (Zlotkin & Rosenschein, 1989, 1993a), also saw something
similar lying goal. There, example, agent could hide task, lower
apparent cost stand-alone plan. Similarly, first lie agent
Blocks World relaxed true goal, lowered apparent cost stand-alone plan
(and thus worth). set states satisfy relaxed goal superset
set states satisfying true goal.
However, major difference lying SODs lying TODs:
latter, never \accidental" achievement hidden goals. lying agent
always find necessary carry hidden goal himself, main
reason subadditive TODs hiding goals beneficial. SODs, hidden goal
might achieved one's opponent, carries actions side effects. Thus,
even hide goal, may fortuitously find goal satisfied front
eyes.
situation visualized informally Figure 26, SOD interactions
Section 4.4 above. figure, agent A1 's expanded apparent goal states represented
thicker oval labeled G01. Note expansion goal states toward
initial state s. meaning lowering one's apparent cost, necessary
beneficial lie.
205

fiZlotkin & Rosenschein



u



@
@@
@@@
@@R

G01
G1

G2

Figure 26: Expanding Apparent Goal States Lie
Alternatively, agent manufacture totally different goal purposes
reducing apparent cost, saw Figure 25. Agent A1 said
wanted slot 3 empty Black block clear. Consider Figure 27, agent A1's
altered apparent goal states represented thick outline labeled G01.
Note again, expansion goal states toward initial state s.



u



@
@@
@@@@
R

G01

G1

G2

Figure 27: Altering Apparent Goal States Lie
agent needs make sure intersection apparent goal states
true goal states empty. Although necessary precondition successful
lie, course sucient precondition successful lie. lies
example useful agent A1 regardless negotiation protocol
used: pure deal, mixed deal, semi-cooperative deal, multi-plan deal.

7.3 Beneficial Lies Semi-Cooperative Deals

might seem agents con ict situation, potential beneficial lies
reduced. fact, beneficial lying exist con ict situations.
\Con ict" agents' goals means exist mixed joint plan
achieves goals also individual rational. either state
exist, joint plan costly individual rational. Even
con ict exists goals, might common subgoals, therefore beneficial
lie may exist.
206

fiMechanisms Automated Negotiation

Taking Advantage Common Subgoal Con ict Situation: Let initial

state world Figure 28. One agent wants block currently slot 2
slot 1; agent wants slot 3. addition, agents share goal
swapping two blocks currently slot 4 (i.e., reverse stack's order).
cost agent achieving goal alone 10. Negotiating true goals
using semi-cooperative deals would lead agents agree swap cooperatively
(at cost 2 each), ip coin, weighting 12 , decide whose goal
individually satisfied. deal brings overall expected utility 2 (i.e.,
1
2 (10 , 2) , 2).

1

2

3

..

4

1

2

3

2

. ..

.

1

2

3

4

4

1

1

2

3

4

Figure 28: Taking Advantage Common Subgoal
agent A1 lies tells agent A2 goal is: \The Black block clear
slot 1 White block Gray block"? Agent A1 thus hides fact
real goal stack blocks slot 4, claims really care
stack slot 2, 3 4. cost agent A1 achieving apparent goal 6,
supposedly build reversed stack slot 3 cost 4. Assuming
agent A2 reveals true goal, agents still agree swap cooperatively,
weighting coin 47 . deal would give agent A1 apparent utility
1 37 (i.e., 47 (8 , 2) , 2) also A2 's real utility (i.e., 73 (10 , 2) , 2). A1's real utility,
however, 2 74 = 47 (10 , 2) , 2. lie beneficial A1 .
situation illustrated Figure 29, agent A1 's lie modifies apparent goal
states closer initial state, plan still ends bringing
world one real goal states.
example above, existence common subgoal agents allowed
one agent exploit common subgoals (assuming, course, lying agent knew
opponent's goals). lying agent relaxes true goal claiming common
subgoal mainly opponent's demand|as far concerned (he claims), would
satisfied much cheaper subgoal. really necessary achieve expensive
subgoal (he claims), burden must fall opponent.
207

fiZlotkin & Rosenschein




u
u








G0

@@
@@@R



- G1

q

?

G2

Figure 29: Lying Con ict Situation

One might think absence common subgoal, would
opportunity one agent beneficially lie other. This, however, true,
see below.

7.4 Beneficial Lies Multi-Plan Deals
Another Example Beneficial Lying Con ict Situation: initial state

seen Figure 30, similar example used Section 5.5 above. A1 's goal
reverse blocks slot 2, leave blocks slot 1 initial position.
A2 's goal reverse blocks slot 1, leave blocks slot 2 initial
position. achieve goal alone, agent needs least 8 PickUp/PutDown
operations. con ict situation.



1

2

3

1

2

3

1
1

2

2

3

3

2

1

1

2

3

Figure 30: Example Interference Decoy Lie
Negotiation multi-plan deals cause agents agree (1 ; 2): 21 ,
mixed joint plan agents cooperatively achieve i's goal. best joint
plan reverse either one slots costs 2 PickUp/PutDown operations
agent. agent's utility deal 2 = ( 12 (8 , 2) , 21 (2)).


208

fiMechanisms Automated Negotiation

Agent A1 might lie claim goal reverse blocks slot 1 leave
blocks slot 2 initial position (his real goal) white block alone
slot 2. costs A1 6 achieve apparent goal alone. reverse alone would
cost 8, thus achieve imaginary part goal cheaper. agreement
(1; 2 ): 47 , mixed joint plan agents cooperatively
achieve i's goal. turns cheaper agents cooperatively carry
A1's real goal cope A1 's imaginary alternative. A1's apparent utility
1 37 = 47 (6 , 2) , 37 (2). also A2 's utility. A1 's actual utility, however,
2 47 = 47 (8 , 2) , 73 (2), greater unvarnished utility 2 A1 would get
without lying. even without common subgoal, A1 beneficial lie.
introduced new type lie, kind \interference decoy," used even
agents' common subgoals.


8. Incomplete Information Worth Goals
Consider situation two agents encounter one another shared environment.
individual goals commonly known (because prior knowledge type
agent, goal recognition process, etc.), well cost achieving goals,
agent alone world. addition, con ict goals.
exists non-empty set states satisfies agents' goals.
agents upper bounds worth, (in contrast public goals)
upper bound private information, known agent. common
situation; agents queue access common resource, goals often selfevident. example, two agents approaching narrow bridge opposite ends may
know wants cross, know crossing worth
(e.g., long willing wait). agents need agree deal (for example,
go first, wait).
One simple way design negotiation mechanism handles lack information
agents exchange private information prior actual negotiation process.
pre-negotiation exchange information another variant ,1-phase game mentioned
above. current case, agents exchange private information worth. section,
consider situation agents negotiating mixed joint plans.
One question, then, agents play ,1-phase game best advantage?
mentioned Sections 4.4 7.2, agent generally incentive
misrepresent worth goal lowering it|the less agent willing pay,
less pay utility product maximizing mechanism (PMM). However,
everyone lowers worth may able reach agreement all, whereas
declared true worth agreement would reached. Agents might lower
worth much driven inecient outcome. instance
free rider problem. Every agent individually motivated lower worth,
someone else carry burden. group whole stands suffer, particularly
agreements reached otherwise would been.
exert control tendency lower one's apparent worth careful design
post-exchange part negotiation mechanism. interested designing
mechanism satisfies desire ecient, symmetric, simple, stable outcomes.
209

fiZlotkin & Rosenschein

research TODs, managed (in certain cases) provide post-exchange mechanism
satisfied attributes, also found incentive compatible|the agents'
best strategy declare true goals. section, introduce two mechanisms
private-worth SODs, one \strict," \tolerant," analyze affects
stability eciency negotiation outcomes. strict mechanism turns
stable, tolerant mechanism ecient.

8.1 Strict Tolerant Mechanisms

several cases need addressed mechanism, treated
differently different mechanisms. example, happen one agent declares
worth lower stand-alone cost (i.e., apparently would achieve
goal alone, worth him)? agent still
allowed offer deal, negotiation considered failed point?
mechanisms present start way. agents simultaneously
declare worth value, claimed worth assign achievement goal.

goals apparently achievable alone: agents declare worth

greater stand-alone cost (which commonly known), negotiation proceeds worth declarations true. agents use product
maximizing mechanism negotiation set mixed joint plans, declared worths baseline utility calculations. result equal
division apparent available utility them.
one agent's goal apparently achievable alone: one agent declares
worth greater stand-alone cost, doesn't, former agent
free decide do. either propose take-it-or-leave-it deal
agent (if it's refused, he'll carry goal alone), simply bypass
offer carry goal. Since declared worth greater
stand-alone cost, rational accomplish goal himself.
agents' goals apparently unachievable alone: agents declare
worths lower stand-alone costs, two mechanisms differ
situation handled:

{ Strict Mechanism: con ict, actions carried out.
{

agents derive utility con ict deal.
Tolerant Mechanism: agents continue negotiation first
case (i.e., use mixed joint plans, divide apparent available
utility them). Even though agents claim unwilling achieve
goals alone, may certainly case together, carry
rational joint plan achieving goals.

tolerant mechanism gives agents \second chance" complete negotiation
successfully reach rational agreement, whereas strict mechanism forgive
low worth declarations, \punishes" causing con ict. course,
agents' true worths really lower stand-alone costs, strict mechanism
210

fiMechanisms Automated Negotiation

causes unnecessary failure (and thus inecient), tolerant mechanism still
allows reach deal possible. see below, however, tolerance
sometimes lead instability.
approach rest section consider various relationships
among two agents' worth values, cost values, interaction types, joint
plans achieve agents' goals. relationship, we'll analyze strategies
available agents. mentioned above, considering situations
agents' goals achievable two-agent mixed joint plans (e.g., reachable
states satisfy agents' goals).
idea tidy agents agent cleaning himself, introduced
Section 6, used situations agents willing pay price achieve
goals|their worths unbounded. There, worth could used baseline
utility calculation. Instead, found \minimal sucient" value
utility baseline gave rise ecient fair mechanism. similar idea also
useful analysis below. tidy agent baseline, explored above, also serves
minimal sucient declaration point worths private information.

8.2 Variables Interest
general, agent would like declare low worth possible, without risking
con ict. lower declaration worth, smaller share joint plan be.
Unfortunately agent, declared worth low, may eliminate possibility
reaching agreement. necessary sucient condition negotiation set
empty sum min conditions, Section 4.1, hold (given
declarations worth). Since assume joint plan achieves
agents' goals, agreement still possible among plans least one
satisfies sum min conditions.
several variables play role analysis below. First, agent
stand-alone cost (known all, dependent goal), denoted c .
Second, agent true worth (privately known) assigns achievement
goal, denoted w . total cost minimal (total cost) joint plan
achieves agents' goals. cost minimal role among joint plans
cost . Below, analyze possible configurations variables.
analysis presented according interaction type con ict, i.e., symmetric cooperative, non-symmetric cooperative/compromise, symmetric compromise.
type, consider three subcases depend relationships c ,
w , , .




r





r

8.3 Symmetric Cooperative Situation
symmetric cooperative situations, one strategy agent use declare
worth minimum true worth, maximum stand-alone cost
minimal role joint plan:
Min-Sucient Strategy min(w ; max(c ; )):


211



r

fiZlotkin & Rosenschein

motivation agent wants declare minimal worth sucient
agreement. Declaring c satisfies sum condition, make sure
also satisfies min condition, agent must declare max(c ; ). make sure
declaration individual rational, must make declaration greater true
worth, w ; thus, takes minimum w (c ; ) maximum.
Min-Sucient Strategy one possible strategy might adopted. However, agents adopt it, strategy equilibrium (in cases),
agreement guaranteed. analyze characteristics strategy six
cases.










r

r

8.3.1 Goals Achievable Alone

situation (as shown Figure 31), agents would able achieve positive
utility agent around, achieved stand-alone goal
themselves.

Equilibrium Point
W1

conflict
C1

A1 decides

Mr

Negotiation
A2 decides
Mr

C2

W2

Figure 31: Goals Achievable Alone
diagram Figure 31 describes, sense, game normal form. agent
declare worth number 0 infinity. outcome depends two
numbers declared; every point plain possible result. colors regions
denote types outcomes.
Note, example, agent A1 declares less c1 , agent A2 declares
c2 , outcome A2 decide (offering A1 take-it-or-leave-it deal,
going alone). A1 A2 offer little (so sum less ),
reach con ict. assume agents rational, consider areas
plain framed w1 w2 (rational agents would declare worth greater
true worths).
difference Strict Tolerant mechanisms mentioned color
triangle lower left c1=c2 point. Strict mechanism, would
white (con ict), Tolerant mechanism still region allows subsequent
negotiation occur. point equilibrium mechanisms c1 =c2
point, reached Min-Sucient Strategy given above. Thus, strategy
stable ecient Strict Tolerant mechanisms situation.
212

fiMechanisms Automated Negotiation

8.3.2 One Goal Achievable Alone

Assume situation shown Figure 32, one agent would able
achieve positive utility agent around (though ultimately
benefit other's existence, one other).


Equilibrium Point

W1
conflict
C1

A1 decides

Mr

Negotiation
A2 decides
Mr

W2 C2



Figure 32: One Goal Achievable Alone
phenomenon similar Section 8.3.1. negotiation triangle
lower left c1 =w2 white (con ict) Strict mechanism negotiable
Tolerant mechanism. mechanisms, c1=w2 point equilibrium,
point results agents play Min-Sucient Strategy. Again, strategy
stable ecient Strict Tolerant mechanisms situation.
8.3.3 Goals Achievable Alone

consider situation shown Figure 33, neither agent could achieve positive
utility alone world|the way achieve goals cooperating.

Resulting
Non-equilibrium Point

conflict
C1
W1

A1 decides

Mr

Negotiation
A2 decides
Mr

W2 C2



Figure 33: Goals Achievable Alone
Again, negotiation triangle lower left w1=w2 white (con ict)
Strict mechanism, agreement reached situation (the whole plain is,
fact, white). Though Min-Sucient Strategy ecient Strict mechanism,
213

fiZlotkin & Rosenschein

stable. Tolerant mechanism, Min-Sucient Strategy ecient (it results
w1=w2 point), unfortunately stable|assuming one agent declares
w1, agent benefit declaring , w1 instead w2 .
fact, agents actually know situation (the one Figure 32
Figure 33), guaranteed beneficial divergence equilibrium point would really
require total knowledge situation opponent playing. Thus, although
Min-Sucient Strategy stable, agents may unlikely diverge
real-world constraints knowledge.

8.4 Non-Symmetric Cooperative/Compromise Situation
section continue analysis situations one agent, situation
cooperative, other, compromise situation. continue analyze
case agents use Min-Sucient Strategy. Agreement reached
compromising agent contributes stand-alone cost joint plan;
minimal role greater stand-alone cost. way
agents reach agreement compromising agent willing
stand-alone cost|otherwise, con ict.
8.4.1 Compromise Sufficient

situation described Figure 34, true worth compromising agent (w2)
greater minimal role c2.
Equilibrium Point

W1
C1

conflict
A1 decides
Mr

Negotiation
A2 decides
C2 Mr

W2



Figure 34: Compromise Sucient
sucient compromising agent declare true worth. declared
less that, agent declared c1, reach con ict;
declaring , guarantees goal achieved. diagram
Strict Tolerant Mechanisms. Min-Sucient Strategy brings agents
c1=M point, stable ecient result (for mechanisms).
r

r

r

214

fiMechanisms Automated Negotiation

8.4.2 Compromise, Enough

Consider situation, portrayed Figure 35, w2 less ,
rational agent A2 compromise declare worth greater w2. MinSucient Strategy brings agents c1=w2 point, con ict.
r


W1
C1

conflict
A1 decides
Negotiation

Mr

A2 decides
C2 W2 Mr



Figure 35: Compromise, Enough
picture identical Strict Tolerant mechanisms. agents
use Min-Sucient Strategy, resulting point (c1=w2) ecient, even though
stable.6 However, enhanced mechanism con ict-resolution techniques,
allowed agents negotiate multi-plan deals Section 5.5 (or even semicooperative deals Section 5.3), conjecture result c1 =w2 would
stable ecient. enhancement, however, beyond scope work described
paper.
8.4.3 Reason Compromise

situation shown Figure 36, non-compromising agent A1 cannot achieve
goal alone. Min-Sucient Strategy declare something less c1 (either
w1 ), result agent A2 option decide
do|and reasonable decision A2 achieve goal alone (there
reason compromise).
result ecient stable, Strict Tolerant mechanisms.
r

8.5 Symmetric Compromise Situation
section continue analysis situations agents,
compromise situation. agents stand-alone costs
order achieve goals.
6. Con ict ecient result one agent achieves goal, rather agents
nothing, would ecient.

215

fiZlotkin & Rosenschein



Equilibrium Point

C1
W1

conflict
A1 decides
Mr
Negotiation
A2 decides
C2

Mr

W2



Figure 36: Reason Compromise
section, propose another strategy agents could use, namely
Min-Concession Strategy:
Min-Concession Strategy min(w ; (c + , (c21 + c2 ) )):




situation, agent choosing propose (as true worth)
stand-alone cost, ensure agreement reached. However, would like
propose minimal sucient concession, enough enable agreement. MinConcession Strategy agents make concession. overall strategy
analyzing (and covers cases section) use Min-Concession Strategy
symmetric compromise situations, otherwise use Min-Sucient Strategy (as
presented above). Agents know kind situation (and thus strategy
use) stand-alone costs common knowledge.
8.5.1 Agents Compromise Equally

agents situation compromise equally (as shown Figure 37),
use Min-Concession Strategy, end point (c1 +)=(c2 +)
(where = (T , c1 , c2)=2). point ecient stable, Strict
Tolerant mechanisms.
8.5.2 Non-Symmetric Compromise, Goals Achieved

agents symmetric compromise situation, one one agent needs
compromise (as Figure 38), use Min-Concession Strategy
results point (c1 +)=w2. point con ict, unfortunately neither stable
ecient.
result stable A1 could make greater compromise benefit
it. result ecient even one agent could achieve goal,
would superior con ict outcome. dicult imagine strategies
would lead agents ecient solutions (e.g., declare , c agent i, Tidy
Agent would Section 6), would stable, either. hand,
j

216

fiMechanisms Automated Negotiation



Equilibrium Point

W1

conflict
C1+

A1 decides

C1
Negotiation

Mr

A2 decides
Mr

C2 C2+

W2

Figure 37: Agents Compromise Equally



W1

conflict
C1+
C1

A1 decides

Mr

Negotiation
A2 decides
Mr

C2 W2 C2+



Figure 38: Non-Symmetric Compromise, Goals Achieved

217

fiZlotkin & Rosenschein

negotiation mechanism enhanced con ict-resolution techniques (such multiplan deals semi-cooperative deals), conjecture Min-Concession Strategy
stable ecient. enhancement, however, also beyond scope
work described paper.
8.5.3 One Agent Cannot Compromise

Consider situation one agent cannot compromise (because could even
achieve goal alone), shown Figure 39. case, agents use MinConcession Strategy, result (c1 + )=w2. Agent 1 choose achieve
goal alone (and compromise). outcome stable ecient.

Equilibrium Point
W1

conflict
C1+
C1

A1 decides

Mr

Negotiation
A2 decides
Mr

W2 C2 C2+



Figure 39: One Agent Cannot Compromise

8.6 Summary Strict Tolerant Mechanisms

results analysis summarized Figure 40. tradeoff
eciency stability apparent symmetric cooperative case, neither
agent able achieve goal alone. strict mechanism, con ict caused simply
agent declare worth higher stand-alone cost, thus
bring immediate con ict. tolerant mechanism gives agents second chance
reach agreement, unstable (as described above).
mechanism incentive compatible. agents incentive
declare true worths; rather, use Min-Sucient Strategy decide
optimal declaration is.

9. Related Work Game Theory DAI

section review research game theory distributed artificial intelligence
related work.

9.1 Related Work Game Theory

mentioned beginning paper, research relies heavily existing game
theory tools use design evaluate protocols automated agents. Here,
218

fiMechanisms Automated Negotiation

Strict
Efficient

Stable

Tolerant
Efficient

Stable

Symmetric Cooperation
boals achievable alone
One goal achievable alone
goals arent achievable alone

Non-Symmetric Cooperation/Compromise
Compromise sufficient
Compromise insufficient
reason compromise

Symmetric Compromise
Agents compromise equally
Agents cant compromise equally
One agent cant compromise

Figure 40: Summary Strict Tolerant Mechanisms
review game theory work Bargaining Theory, Mechanism Design Implementation
Theory, Correlated Equilibria.
9.1.1 Bargaining Theory

Classic game theory (Nash, 1950; Zeuthen, 1930; Harsanyi, 1956; Roth, 1979; Luce & Raiffa,
1957) talks players reaching \deals," defined vectors utilities (one
player). bargaining game end possible outcome (i.e., \deal").
player full preference order set possible outcomes; preference order
expressed utility function. deal, utility vector
list utilities deal every participant. special utility vector called
\con ict" (or sometimes \status quo point") utility player assigns
con ict (that is, lack final agreement). Classic game theory deals following
question: given set utility vectors, utility vector players
agree (under particular assumptions)? words, classic bargaining theory
focused prediction outcomes, certain assumptions players
outcomes themselves.
Nash (Nash, 1950, 1953) showed rational behavior assumptions (i.e.,
individual rational pareto optimal behavior), symmetry assumptions, players
219

fiZlotkin & Rosenschein

reach agreement deal maximizes product players' utility (see Section 4.2 complete discussion).
alternative approach negotiation, looks upon dynamic, iterative process, discussed work Rubinstein Osborne (Rubinstein, 1982, 1985; Osborne
& Rubinstein, 1990).
Game theory work negotiation assumes negotiation game welldefined. assumes set possible deals players evaluating using
certain utility functions. Therefore, deals players' utility functions induce set
utility vectors forms basis negotiation game.
contrast analysis given, well-defined negotiation encounter, exploring design space negotiation games. Given multiagent encounter (involving,
example, task redistribution), design assortment negotiation games, formulating
various sets possible deals various kinds utility functions agents may have.
given negotiation game, use game theory approaches analyze
evaluate negotiation mechanisms propose.
Game theorists usually concerned games played,
descriptive normative point view. essentially constructive point view;
since game theory tells us, given game, played, endeavor design
games good properties played game theory predicts.
9.1.2 Equilibrium

Game solutions game theory consist strategies equilibrium; somehow social
behavior reaches equilibrium, agent incentive diverge equilibrium
behavior. equilibrium considered solution game. may one
(or no) strategies equilibrium, also different notions equilibrium
game theory literature.
Three levels equilibrium commonly used game theory Nash equilibrium,
perfect equilibrium, dominant equilibrium (Binmore, 1990; Rasmusen, 1989). level
equilibrium enumerated stronger previous one. Two strategies S;
Nash equilibrium if, assuming one agent using , agent cannot better
using strategy , vice versa. Perfect equilibrium means
game multiple steps, one player using , exists state game
player better sticking strategy . exist
situations strategies might Nash equilibrium, perfect equilibrium;
case, although strategy best start game, game unfolds
would better diverge . Dominant strategy equilibrium means matter
strategy opponent chooses, cannot better play strategy ; strategies
dominant strategy equilibrium dominant strategy one
player, dominant strategy other.
work, generally use Nash equilibrium (the weakest equilibrium concept)
requirement solution; provides us widest range interaction solutions.
times, solution inherently perfect equilibrium, introduced
additional rules interaction, compel agents follow particular Nash equilibrium
220

fiMechanisms Automated Negotiation

strategies game progresses (such introducing penalty mechanism breaking
public commitment).
provides interesting example power wield designers game.
First, would normally require perfect equilibria multiagent encounters,
adopt Nash equilibria sucient needs, impose rules keep agents
deviating Nash equilibrium strategies. Second, strong requirement
dominant equilibrium, might desirable two arbitrary agents play given
game, needed recommended strategies commonly known|Nash equilibrium sucient.
9.1.3 Mechanism Design Implementation Theory

also groups game theorists consider problem design games
certain attributes. area mechanism design closest
concerns, design protocols automated agents.
Mechanism design also known game theory literature implementation
problem. implementation question (Binmore, 1992; Fudenberg & Tirole, 1992) asks
whether mechanism (also called game form ) distinguishable equilibrium
point (dominant strategy, perfect, merely Nash) social profile (i.e.,
group behavior) associated, players follow equilibrium strategies,
desired outcome.
words, assumed group agents, utility
function preferences possible social outcomes. also social welfare function
rates possible social outcomes (e.g., socially ecient agreement may
rated higher non-ecient one) (Arrow, 1963). question then, one design
game unique solution (equilibrium strategies),
individual agent behaves according equilibrium strategy, social behavior
maximize social welfare function. game designed, said
game implements social welfare function.
example social welfare function, consider minimization pollution.
everyone may interested lowering pollution levels, everyone interested others
bearing associated costs. mechanism implement social welfare function might
include, example, taxes polluting industries tax credits given purchase
electric cars. precisely kind mechanism would cause agents, following
equilibrium strategy, minimize pollution.
Given negotiation game designed (i.e., set deals utility functions),
also design actual negotiation mechanism. One important attributes
negotiation mechanism eciency, i.e., maximization total group's utility.
social welfare function trying implement. assume
agents incomplete information one another's utility function, basically
(negotiation) mechanism design problem.
However, unlike classic mechanism design game theory, satisfied (negotiation) mechanism Nash equilibrium point implements eciency.
need uniqueness, need stronger notion equilibrium (i.e., dominant equilibrium). negotiation mechanism design intended suggestion community
221

fiZlotkin & Rosenschein

agents' designers, along negotiation strategy. negotiation mechanism
strategy part suggested standard. make standard self-enforcing
sucient strategy part standard Nash equilibrium.
9.1.4 Correlated Equilibrium

Players sometime communicate prior actually playing game. communicating,
players coordinate strategies even sign binding contracts strategies
use. Contracts various types. agent commit
playing pure strategy agent commits playing another pure strategy. Agents
also commit contract ip coin play strategy
according coin.
contract thus seen agreement players correlate
strategies. correlated strategy general case probability distribution
possible joint activities (i.e., strategy combinations) players. order players
play according correlated strategy, mediator conduct
lottery, choose joint activity according agreed probabilities, suggest
strategy players. cases mediator assumed release player
information player's action (strategy) chosen joint action,
player's action.
Contracts players binding; however, cannot assume contracts
binding cases. Even contracts binding, selfenforcing. contract self-enforcing player signs contract cannot
better following contract, assumption agents following
contract. mediator's communications observable players,
self-enforcing non-binding contracts randomize among Nash
equilibria original game ((Myerson, 1991), pp. 251).
Self-enforcing contracts correlated strategy called correlated equilibria. Aumann
introduced term correlated equilibrium (Aumann, 1974); defined correlated equilibrium given game Nash equilibrium extension game,
players receive private signals original game actually played. Aumann also
showed (Aumann, 1987) correlated equilibrium defined terms Bayesian
rationality. Forges extended approach games incomplete information (Forges,
1993).
Myerson showed correlated equilibrium specific case general concept equilibrium, called communication equilibrium, games incomplete
information (Myerson, 1982, 1991).
deal types defined involve coin ipping. is,
course, directly related notion correlated strategies. correlated equilibrium theory, also assume agents able agree deals (i.e., contracts)
involve jointly observed random process (e.g., coin toss). However, unlike correlated
equilibrium theory, assume contracts binding. Therefore, assume
agents follow contract (whatever result coin ip) even
longer rational agent so. Relaxation binding agreement assumption,
222

fiMechanisms Automated Negotiation

designing negotiation mechanisms based self-enforcing correlated strategies,
part future research plans.

9.2 Related Work Distributed Artificial Intelligence

several streams research Distributed Artificial Intelligence (DAI)
approached problem multiagent coordination different ways.
brie review work, categorizing general areas multiagent planning,
negotiation, social laws, economic approaches.
9.2.1 Multiagent Planning

One focus DAI research \planning multiple agents," considers
issues inherent centrally directed multiagent execution. Smith's Contract Net (Smith,
1978, 1980) falls category, DAI work (Fox, Allen, & Strohm, 1982;
Rosenschein, 1982; Pednault, 1987; Katz & Rosenschein, 1993). second focus research
\distributed planning," multiple agents participate coordinating
deciding upon actions (Konolige & Nilsson, 1980; Corkill, 1982; Rosenschein & Genesereth, 1985; Rosenschein, 1986; Durfee, Lesser, & Corkill, 1987; Zlotkin & Rosenschein,
1991b; Ephrati & Rosenschein, 1991; Pollack, 1992; Pope, Conry, & Mayer, 1992).
question whether group activity fashioned centrally distributed
manner one axis comparison. Another important issue distinguishes
various DAI research efforts whether goals need adjusted, is,
whether may fundamental con icts among different agents' goals. Thus,
example, Georgeff's early work multiagent planning assumed basic
con ict among agent goals, coordination necessary guarantee
success (Georgeff, 1983, 1984; Stuart, 1985). Similarly, planning context Lesser,
Corkill, Durfee, Decker's research (Decker & Lesser, 1992, 1993b, 1993a) often involves
coordination activities (e.g., sensor network computations) among agents
inherent con ict one another (though surface con ict may exist). \Planning"
means avoidance redundant distracting activity, ecient exploration search
space, etc.
Another important issue relationship agents one another, e.g.,
degree willing compromise goals one another (assuming
compromise necessary). Benevolent Agents that, design, willing
accommodate one another (Rosenschein & Genesereth, 1985); built
cooperative, share information, coordinate pursuit (at least implicit)
notion global utility. contrast, Multiagent System agents cooperate
best interests (Genesereth, Ginsberg, & Rosenschein, 1986). Still
another potential relationship among agents modified master-slave relationship, called
\supervisor-supervised" relationship, non-absolute control exerted one agent
another (Ephrati & Rosenschein, 1992a, 1992b).
synthesis, synchronization, adjustment process multiple agent plans thus constitute (varied) foci DAI planning research. Synchronization con ict
avoidance (Georgeff, 1983, 1984; Stuart, 1985), distribution single-agent planner among
multiple agents (Corkill, 1979), use centralized multiagent planner (Rosenschein,
223

fiZlotkin & Rosenschein

1982), use consensus mechanisms aggregating subplans produced multiple agents (Ephrati & Rosenschein, 1993b), explored, well related
issues (Cohen & Perrault, 1979; Morgenstern, 1987; von Martial, 1992a, 1992b; Kreifelts
& von Martial, 1991; Kamel & Syed, 1989; Grosz & Sidner, 1990; Kinny, Ljungberg, Rao,
Sonenberg, Tidhar, & Werner, 1992; Ferber & Drogoul, 1992; Kosoresow, 1993).
paper, dealing classical problems planning research
(e.g., construction sequences actions accomplish goals). Instead, taken
given agents capable deriving joint plans domain, considered might choose among alternative joint plans satisfy potentially
con icting notions utility. help agents bridge con icts, introduced frameworks plan execution (such ipping coin decide two joint plans
carried out), actual base planning mechanism subject work.
9.2.2 Axiomatic Approaches Group Activity

exists large growing body work within artificial intelligence attempts
capture notions rational behavior logical axiomatization (Cohen & Levesque,
1990, 1991; Rao, Georgeff, & Sonenberg, 1991; Rao & Georgeff, 1991, 1993; Georgeff &
Lansky, 1987; Georgeff, 1987; Belegrinos & Georgeff, 1991; Grosz & Kraus, 1993; Konolige,
1982; Morgenstern, 1990, 1986; Kinny & Georgeff, 1991). approach usually centers
formalized model agent's beliefs, desires, intentions (the so-called \BDI
model") (Hughes & Cresswell, 1968; Konolige, 1986). purpose formal model
characterize precisely constitutes rational behavior, intent impose
rational behavior automated agent. formal axioms might used run-time
directly constrain agent's decision process, (more likely) could used
compile-time produce ecient executable module.
focus research, coming single-agent artificial intelligence
perspective, architecture single automated agent. example, Cohen
Levesque explored relationship choice, commitment, intention (Cohen
& Levesque, 1987, 1990)|an agent commit certain plans action,
remain loyal plans long appropriate (for example, agent discovers
plan infeasible, plan dropped).
Even looking multiagent systems, researchers examined member group designed|again, looking design individual agent
productive group member. example, certain work (Kinny et al., 1992)
axioms proposed cause agent, discovers fail fulfill
role joint plan, notify members group. Axiomatizations, however,
might need deal groups agents could joint commitment accomplishing goal (Cohen & Levesque, 1991), agent make interpersonal
commitments without use notions (Grosz & Kraus, 1993). Another use
BDI abstractions allow one agent reason agents, relativize one's
intentions terms beliefs agents' intentions beliefs.
Axiomatic approaches tend closely link definitions behavior internal agent
architecture. Thus, definition commitment explored Cohen Levesque intended constrain design agent, behave certain way.
224

fiMechanisms Automated Negotiation

work, hand, takes arms-length approach question constraining
agents' public behavior. rules encounter really specification domain
(not agent), agent designer free build agent internally however
sees fit. rules themselves, however, induce rational designers build agents
behave certain ways, independent agents' internal architectures.
9.2.3 Social Laws Multiple Agents

Various researchers Distributed Artificial Intelligence suggested would
worthwhile isolate \aspects cooperative behavior," general rules would cause
agents act ways conducive cooperation. hypothesis agents act
certain ways (e.g., share information, act predictable ways, defer globally constraining
choices), easier carry effective joint action (Steeb, Cammarata,
Hayes-Roth, & Wesson, 1980; Cammarata, McArthur, & Steeb, 1983; McArthur, Steeb, &
Cammarata, 1982).
Moses, Shoham, Tennenholtz (Tennenholtz & Moses, 1989; Moses & Tennenholtz,
1990; Shoham & Tennenholtz, 1992b, 1992a; Moses & Tennenholtz, 1993; Shoham & Tennenholtz, 1995), example, suggested applying society metaphor artificial
systems improve performance agents operating system. issues
dealt analyzing multiagent environment concern synchronization, coordination agents' activities, cooperative ways achieve tasks, safety
fairness constraints system guaranteed. propose coordinating agent
activity avoid con icts; system structured agents arrive
potential con ict situations.
Thus social laws seen method avoid necessity costly coordination
techniques, like planning negotiation. agents following appropriate social laws,
need run-time coordination reduced. important, although
agent designers may willing invest large amount effort design time building
effective multiagent systems, often critical run-time overhead low
possible.
similarity use pre-compiled, highly structured social laws,
development pre-defined interaction protocols. However, social law approach
assumes designers laws full control agents; agents assumed follow social laws simply designed to,
individually benefit social laws. Obeying social laws may \stable";
assuming everyone else obeys laws, agent might better breaking them.
approach concerned social conventions stable, suitable
individually motivated agents.
9.2.4 Decision Theoretic Approaches

related work Artificial Intelligence addresses reasoning process single
agent decision-theoretic terms. certain work (Horvitz, 1988; Horvitz, Cooper, & Heckerma, 1989; Russell & Wefald, 1989), decision-theoretic approaches used optimize
value computation uncertain varying resource limitations. Etzioni considered
using decision-theoretic architecture, learning capabilities, control problem solving
225

fiZlotkin & Rosenschein

search (Etzioni, 1991). introductory treatment decision theory itself, see Raiffa's
classic text subject (Raiffa, 1968).
Classical decision theory research considers agent \playing nature,"
trying maximize utility uncertain circumstances. key assumption \nature's"
behavior independent decision made agent. course, assumption
hold multiagent encounter.
concept \rationality," usually expressed decision-theoretic terms,
used model agent activity multiagent encounters (Rosenschein & Genesereth, 1985;
Genesereth et al., 1986). Here, axioms defining different types rationality, along
assumptions rationality others, led agents particular choices action.
contrast work, research employs standard game theory notions equilibrium
rationality. discussions use rationality general reasoning found
Doyle's research (Doyle, 1985, 1992).
Another decision theoretic approach, taken Gmytrasiewicz Durfee,
used model multiagent interactions (Gmytrasiewicz, Durfee, & Wehe, 1991a, 1991b;
Gmytrasiewicz & Durfee, 1992, 1993). assumes predefined protocol structure
interaction (in marked contrast research protocol design). research uses
decision-theoretic method coordinating activities autonomous agents called
Recursive Modeling Method. agent models agents recursive manner,
allowing evaluation expected utility attached potential actions communication.
9.2.5 Economic Approaches

several attempts consider market mechanisms way eciently
allocating resources distributed system. Among AI work Smith's Contract
Net (Smith, 1978, 1980; Sandholm, 1993), Malone's Enterprise system (Malone et al., 1988),
Wellman's WALRAS system (Wellman, 1992).
Contract Net high-level communication protocol Distributed Problem
Solving system. enables distribution tasks among nodes operate
system. contract two nodes established tasks executed;
node net act either manager contractor. task
assigned node decomposed contractor. contract established
bidding scheme includes announcement task manager, bids
sent potential contractors.
Enterprise (Malone et al., 1988) system built using variation Contract Net protocol. Distributed Scheduling Protocol locates best available machine
perform task. protocol similar Contract Net, makes use
well-defined assignment criteria.
Another system (Wellman, 1992) takes economic approach solving distributed problem use price mechanism explored Wellman.
Wellman uses consumer/producer metaphor establish market pricing-based mechanism task redistribution ensures stability eciency. agents act
consumers producers. distinct good auction associated it, agents
get good submitting bids auction good. system developed
Wellman, WALRAS, computes market equilibrium price.
226

fiMechanisms Automated Negotiation

two main differences economic approaches work
mechanism design. First, underlying assumption economic approach
utility explicitly transferable (e.g., money used). work involve
need explicit utility transfer. Instead, exploit various methods implicit utility
transfer, example, sharing work joint plan, tossing coin, etc. course,
constrains available coordination mechanism, removes assumption (that is,
existence money) may suitable certain multiagent environments. Second,
economic models deal n agents market, work deals
two-agent encounters; however, work deals n-agent negotiation
coalition formation problem (Zlotkin & Rosenschein, 1994).
9.2.6 Negotiation

Negotiation subject central interest DAI, economics
political science (Raiffa, 1982). word used variety ways, though
general refers communication processes coordination (Smith, 1978; Lesser
& Corkill, 1981; Kuwabara & Lesser, 1989; Conry et al., 1988; Kreifelts & von Martial,
1991; Kraus, Ephrati, & Lehmann, 1991). negotiating procedures included
exchange Partial Global Plans (Durfee, 1988; Durfee & Lesser, 1989), communication
information intended alter agents' goals (Sycara, 1988, 1989), use
incremental suggestions leading joint plans action (Kraus & Wilkenfeld, 1991).
Interagent collaboration Distributed Problem Solving systems explored
ongoing research Lesser, Durfee, colleagues. Much work focused
implementation analysis data fusion experiments, systems distributed
sensors absorb interpret data, ultimately arriving group conclusion (Durfee &
Lesser, 1987; Decker & Lesser, 1993a; L^aasri, L^aasri, & Lesser, 1990). Agents exchange
partial solutions various levels detail construct global solutions; much work
examined effective strategies communication data hypotheses among agents,
particular kinds relationships among nodes aid effective group analysis.
example, different organizations, different methods focusing node activity,
help system whole far ecient.
two main distinctions work work Lesser
colleagues. First, underlying assumption bulk Lesser's work agents
designed implemented part unified system, work towards global goal.
agents, hand, motivated achieve individual goals. Second, unlike
formal approach mechanism design, Lesser's work historically heuristic
experimental, although recent work explored theoretical basis
system-level phenomena (Decker & Lesser, 1992, 1993a, 1993b).
Sycara examined model negotiation combines case-based reasoning
optimization multi-attribute utilities (Sycara, 1988, 1989). particular, assume
agents' goals fixed negotiation, Sycara specifically interested
agents uence one another change goals process negotiation
(information transfer, etc.).
Kraus colleagues explored negotiation negotiation time
issue (Kraus & Wilkenfeld, 1991; Kraus, 1993; Kraus, Wilkenfeld, & Zlotkin, 1995). Agents
227

fiZlotkin & Rosenschein

may lose value negotiation drags long, different agents asymmetric
regard cost negotiation time. Agents' attitudes towards negotiation time
directly uences kinds agreements reach. Interestingly, however,
agreements reached without delay. avoidable ineciency delaying
agreement. work, contrast, assumes agent utility remains constant throughout
negotiation process, negotiation time uence agreement.
Kraus' work also assumes explicit utility transfer (while work, mentioned above,
not).
Gasser explored social aspects agent knowledge action multiagent
systems (\communities programs") (Gasser, 1991, 1993). Social mechanisms dynamically emerge; communities programs generate, modify, codify
local languages interaction. Gasser's approach may effective agents
interacting unstructured domains, domains structure continuously
changing. research present, hand, exploits pre-designed social layer
multiagent systems.
work focuses organizational aspects societies agents exists (Fox,
1981; Malone, 1986).
Ephrati Rosenschein used Clarke Tax voting procedure consensus mechanism, essence avoid need classical negotiation (Ephrati & Rosenschein, 1991,
1992c, 1993a). mechanism assumes ability transfer utility explicitly. Clarke
Tax technique assumes (and requires) agents able transfer utility
system (taxes paid agents). utility transferred system
actually wasted, reduces eciency overall mechanism. This, however,
price needs paid ensure stability. Again, work present paper
assume explicit transfer utility. Also, negotiation mechanism ensures
stability without ineciency transferring utility system. However, voting
mechanisms like Clarke Tax deal n-agent agreement (not two-agent agreement research), also demonstrates kind dominant equilibrium (in contrast
weaker notion Nash equilibrium).

10. Conclusions
paper explored State Oriented Domains (SODs). State Oriented Domains
current description world modeled state, operators cause world
move one state another. goal agent transform world
one collection target states. SODs, real con ict possible agents,
general, agents may find four possible types interactions, symmetric
cooperative, symmetric compromise, non-symmetric cooperative/compromise, con ict.
Agents negotiate different deal types kinds interactions;
particular, introduced semi-cooperative deal, multi-plan deals, use con ict situations. Unified Negotiation Protocols, product maximizing mechanisms based
either semi-cooperative deals multi-plan deals, provide suitable basis con ict
resolution, well reaching cooperative agreements.
Strategic manipulation possible SODs. State Oriented Domain, agent might
misrepresent goals, worth function, gain advantage negotiation.
228

fiMechanisms Automated Negotiation

general approach deceitful agent would pretend worth lower
actually is. done directly, declaring low worth (in certain mechanisms),
declaring cheaper goal (in case stand-alone cost taken implicit
worth baseline). able construct incentive compatible mechanisms used
worths unknown, unable SODs goals unknown.

Acknowledgements
paper submitted Gilad Zlotkin aliated Center Coordination Science, Sloan School Management, MIT. research began Zlotkin
aliated Institute Computer Science Hebrew University Jerusalem,
supported Leibniz Center Research Computer Science. material
paper appeared preliminary form AAAI, IJCAI, ICICIS conference
papers (Zlotkin & Rosenschein, 1990, 1991b; Rosenschein, 1993; Zlotkin & Rosenschein,
1993c) journal article (Zlotkin & Rosenschein, 1991a) (earlier version material
UNP protocol). research partially supported Israeli Ministry
Science Technology (Grant 032-8284) Israel Science Foundation (Grant
032-7517). would like thank anonymous reviewers contributed improvement paper.

References

Allen, J. F., Kautz, H. A., Pelavin, R. N., & Tenenberg, J. D. (1991). Reasoning
Plans. Morgan Kaufmann Publishers, Inc., San Mateo, California.
Arrow, K. J. (1963). Social Choice Individual Values. John Wiley, New York.
Aumann, R. (1987). Correlated equilibrium expression bayesian rationality. Econometrica, 55, 1{18.
Aumann, R. J. (1974). Subjectivity correlation randomized strategies. Journal
Mathematical Economics, 1, 67{96.
Belegrinos, P., & Georgeff, M. P. (1991). model events processes. Proceedings
Twelfth International Joint Conference Artificial Intelligence, pp. 506{511
Sydney, Australia.
Binmore, K. (1990). Essays Foundations Game Theory. Basil Blackwell, Cambridge, Massachusetts.
Binmore, K. (1992). Fun Games, Text Game Theory. D. C. Heath Company,
Lexington, Massachusetts.
Bok, S. (1978). Lying: Moral Choice Public Private Life. Vintage Books, New York.
Cammarata, S., McArthur, D., & Steeb, R. (1983). Strategies cooperation distributed
problem solving. Proceedings Eighth International Joint Conference Artificial Intelligence, pp. 767{770 Karlsruhe, West Germany.
229

fiZlotkin & Rosenschein

Cohen, P. R., & Levesque, H. J. (1987). Intention = choice + commitment. Proceedings Sixth National Conference Artificial Intelligence, pp. 410{415 Seattle,
Washington.
Cohen, P. R., & Levesque, H. J. (1990). Intention choice commitment. Artificial
Intelligence, 42 (2{3), 213{261.
Cohen, P. R., & Levesque, H. J. (1991). Teamwork. Technote 503, SRI International, Menlo
Park, California.
Cohen, P. R., & Perrault, C. R. (1979). Elements plan-based theory speech acts.
Cognitive Science, 3, 177{212.
Conry, S. E., Meyer, R. A., & Lesser, V. R. (1988). Multistage negotiation distributed
planning. Bond, A., & Gasser, L. (Eds.), Readings Distributed Artificial Intelligence, pp. 367{384. Morgan Kaufmann Publishers, Inc., San Mateo.
Corkill, D. D. (1979). Hierarchical planning distributed environment. Proceedings
Sixth International Joint Conference Artificial Intelligence, pp. 168{175 Tokyo.
Corkill, D. D. (1982). Framework Organizational Self-Design Distributed Problem
Solving Networks. Ph.D. thesis, University Massachusetts, Amherst, MA.
Decker, K. S., & Lesser, V. R. (1992). Generalizing partial global planning algorithm.
International Journal Intelligent Cooperative Information Systems, 1(2), 319{346.
Decker, K. S., & Lesser, V. R. (1993a). approach analyzing need meta-level
communication. Proceedings Thirteenth International Joint Conference
Artificial Intelligence, pp. 360{366 Chambery, France.
Decker, K. S., & Lesser, V. R. (1993b). one-shot dynamic coordination algorithm
distributed sensor networks. Proceedings Eleventh National Conference
Artificial Intelligence, pp. 210{216 Washington, DC.
Doyle, J. (1985). Reasoned assumptions pareto optimality. Proceedings
Ninth International Joint Conference Artificial Intelligence, pp. 87{90 Los Angeles,
California.
Doyle, J. (1992). Rationality roles reasoning. Computational Intelligence, 8 (2),
376{409.
Durfee, E. H. (1988). Coordination Distributed Problem Solvers. Kluwer Academic
Publishers, Boston.
Durfee, E. H., & Lesser, V. R. (1987). Using partial global plans coordinate distributed
problem solvers. Proceedings Tenth International Joint Conference Artificial Intelligence, pp. 875{883 Milan.
Durfee, E. H., & Lesser, V. R. (1989). Negotiating task decomposition allocation using
partial global planning. Gasser, L., & Huhns, M. N. (Eds.), Distributed Artificial
Intelligence, Vol. II, pp. 229{243. Morgan Kaufmann, San Mateo, California.
230

fiMechanisms Automated Negotiation

Durfee, E. H., Lesser, V. R., & Corkill, D. D. (1987). Cooperation communication
distributed problem solving network. Huhns, M. N. (Ed.), Distributed Artificial Intelligence, chap. 2, pp. 29{58. Morgan Kaufmann Publishers, Inc., Los Altos,
California.
Ephrati, E., & Rosenschein, J. S. (1991). Clarke Tax consensus mechanism among
automated agents. Proceedings Ninth National Conference Artificial
Intelligence, pp. 173{178 Anaheim, California.
Ephrati, E., & Rosenschein, J. S. (1992a). Constrained intelligent action: Planning
uence master agent. Proceedings Tenth National Conference
Artificial Intelligence, pp. 263{268 San Jose, California.
Ephrati, E., & Rosenschein, J. S. (1992b). Planning please: Planning constrained
master agent. Proceedings Eleventh International Workshop Distributed
Artificial Intelligence, pp. 77{94 Glen Arbor, Michigan.
Ephrati, E., & Rosenschein, J. S. (1992c). Reaching agreement partial revelation preferences. Proceedings Tenth European Conference Artificial
Intelligence, pp. 229{233 Vienna, Austria.
Ephrati, E., & Rosenschein, J. S. (1993a). Distributed consensus mechanisms selfinterested heterogeneous agents. First International Conference Intelligent
Cooperative Information Systems, pp. 71{79 Rotterdam.
Ephrati, E., & Rosenschein, J. S. (1993b). Multi-agent planning dynamic search
social consensus. Proceedings Thirteenth International Joint Conference
Artificial Intelligence, pp. 423{429 Chambery, France.
Etzioni, O. (1991). Embedding decision-analytic control learning architecture. Artificial
Intelligence, 49, 129{159.
Ferber, J., & Drogoul, A. (1992). Using reactive multi-agent systems simulation problem solving. Avouris, N. M., & Gasser, L. (Eds.), Distributed Artificial Intelligence:
Theory Praxis, pp. 53{80. Kluwer Academic Press.
Forges, F. (1993). Five legitimate definitions correlated equilibrium games incomplete information. Theory Decision, 35, 277{310.
Fox, M. S. (1981). organizational view distributed systems. IEEE Transactions
Systems, Man, Cybernetics, SMC-11 (1), 70{80.
Fox, M. S., Allen, B., & Strohm, G. (1982). Job-shop scheduling: investigation
constraint-directed reasoning. Proceedings National Conference Artificial
Intelligence, pp. 155{158 Pittsburgh, Pennsylvania.
Fudenberg, D., & Tirole, J. (1992). Game Theory. MIT Press, Cambridge, Massachusetts.
231

fiZlotkin & Rosenschein

Gasser, L. (1991). Social conceptions knowledge action: DAI foundations open
systems semantics. Artificial Intelligence, 47 (1{3), 107{138.
Gasser, L. (1993). Social knowledge social action. Proceedings Thirteenth International Joint Conference Artificial Intelligence, pp. 751{757 Chambery, France.
Genesereth, M. R., Ginsberg, M. L., & Rosenschein, J. S. (1986). Cooperation without
communication. Proceedings National Conference Artificial Intelligence,
pp. 51{57 Philadelphia, Pennsylvania.
Georgeff, M. P. (1983). Communication interaction multi-agent planning. Proceedings National Conference Artificial Intelligence, pp. 125{129 Washington,
D.C.
Georgeff, M. P. (1984). theory action multi-agent planning. Proceedings
National Conference Artificial Intelligence, pp. 121{125 Austin, Texas.
Georgeff, M. P. (1987). Actions, processes, causality. Georgeff, M. P., & Lansky, A. L.
(Eds.), Reasoning Actions & Plans, pp. 99{122. Morgan Kaufmann Publishers,
Inc., Los Altos, California.
Georgeff, M. P., & Lansky, A. L. (1987). Reactive reasoning planning. Proceedings Sixth National Conference Artificial Intelligence, pp. 677{682 Seatle,
Washington.
Gmytrasiewicz, P. J., & Durfee, E. H. (1992). logic knowledge belief recursive
modeling: Preliminary report. Proceedings Tenth National Conference
Artificial Intelligence, pp. 628{634 San Jose, California.
Gmytrasiewicz, P. J., & Durfee, E. H. (1993). Elements utilitarian theory knowledge action. Proceedings Thirteenth International Joint Conference
Artificial Intelligence, pp. 396{402 Chambery, France.
Gmytrasiewicz, P. J., Durfee, E. H., & Wehe, D. K. (1991a). decision theoretic approach
coordinating multiagent interaction. Proceedings Twelfth International
Joint Conference Artificial Intelligence, pp. 62{68 Sydney, Australia.
Gmytrasiewicz, P. J., Durfee, E. H., & Wehe, D. K. (1991b). utility communication
coordinating intelligent agents. Proceedings Ninth National Conference
Artificial Intelligence, pp. 166{172.
Grosz, B. J., & Kraus, S. (1993). Collaborative plans group activities. Proceedings
Thirteenth International Joint Conference Artificial Intelligence, pp. 367{373
Chambery, France.
Grosz, B. J., & Sidner, C. (1990). Plans discourse. Cohen, P. R., Morgan, J., &
Pollack, M. E. (Eds.), Intentions Communication. MIT Press.
Gupta, N., & Nau, D. S. (1992). complexity blocks-world planning. Artificial
Intelligence, 56 (2{3), 223{254.
232

fiMechanisms Automated Negotiation

Harsanyi, J. C. (1956). Approaches bargaining problem theory
games: critical discussion Zeuthen's, Hick's Nash theories. Econometrica,
pp. 144{157.
Horvitz, E., Cooper, G., & Heckerma, D. (1989). ection action scare resources:
Theoretical principles empirical study. Proceedings Eleventh International Joint Conference Artificial Intelligence, pp. 1121{1127 Detroit, Michigan.
Horvitz, E. J. (1988). Reasoning varying uncertain resource constraints.
Proceedings Seventh National Conference Artificial Intelligence, pp. 111{
116.
Hughes, G. E., & Cresswell, J. M. (1968). Introduction Modal Logic. Methuen
Co. Ltd.
Kamel, M., & Syed, A. (1989). object-oriented multiple agent planning system.
Gasser, L., & Huhns, M. N. (Eds.), Distributed Artificial Intelligence, Volume II, pp.
259{290. Pitman Publishing/Morgan Kaufmann Publishers, San Mateo, CA.
Katz, M. J., & Rosenschein, J. S. (1993). Verifying plans multiple agents. Journal
Experimental Theoretical Artificial Intelligence, 5, 39{56.
Kinny, D., Ljungberg, M., Rao, A., Sonenberg, E., Tidhar, G., & Werner, E. (1992). Planned
team activity. Pre-Proceedings Fourth European Workshop Modeling
Autonomous Agents Multi-Agent World Rome, Italy.
Kinny, D. N., & Georgeff, M. P. (1991). Commitment effectiveness situated agents.
Proceedings Twelfth International Joint Conference Artificial Intelligence,
pp. 82{88 Sydney, Australia.
Konolige, K. (1982). first-order formalization knowledge action multi-agent
planning system. Machine Intelligence, 10.
Konolige, K. (1986). Deduction Model Belief. Pitman Publishers/Morgan Kaufmann,
San Matheo, CA.
Konolige, K., & Nilsson, N. J. (1980). Multiple-agent planning systems. Proceedings
First Annual National Conference Artificial Intelligence, pp. 138{142 Stanford,
California.
Kosoresow, A. P. (1993). fast first-cut protocol agent coordination. Proceedings
Eleventh National Conference Artificial Intelligence, pp. 237{242 Washington,
DC.
Kraus, S. (1993). Agents contracting tasks non-collaborative environments. Proceedings
Eleventh National Conference Artificial Intelligence, pp. 243{248.
Kraus, S., Ephrati, E., & Lehmann, D. (1991). Negotiation non-cooperative environment. Journal Experimental Theoretical Artificial Intelligence, 3 (4), 255{282.
233

fiZlotkin & Rosenschein

Kraus, S., & Wilkenfeld, J. (1990). function time cooperative negotiations: Extended abstract. Proceedings Tenth Workshop Distributed Artificial Intelligence Bandera, Texas.
Kraus, S., & Wilkenfeld, J. (1991). Negotiations time multi-agent environment:
Preliminary report. Proceedings Twelfth International Joint Conference
Artificial Intelligence, pp. 56{61 Sydney.
Kraus, S., Wilkenfeld, J., & Zlotkin, G. (1995). Multiagent negotiation time constraints. Artificial Intelligence, 75 (2), 297{345.
Kreifelts, T., & von Martial, F. (1991). negotiation framework autonomous agents.
Demazeau, Y., & Muller, J.-P. (Eds.), Decentralized A. I. 2, Proceedings Second
European Workshop Modelling Autonomous Agents Multi-Agent World, pp.
71{88. North-Holland, Amsterdam.
Kuwabara, K., & Lesser, V. R. (1989). Extended protocol multistage negotiation.
Proceedings Ninth Workshop Distributed Artificial Intelligence, pp. 129{161
Rosario, Washington.
L^aasri, B., L^aasri, H., & Lesser, V. R. (1990). Negotiation role cooperative distributed problem problem solving. Proceedings Tenth International Workshop
Distributed Artificial Intelligence Bandera, Texas. Chapter 8.
Lesser, V. R., & Corkill, D. D. (1981). Functionally-accurate, cooperative distributed systems. IEEE Transactions Systems, Man, Cybernetics, SMC-11 (1), 81{96.
Levesque, H. J., & Cohen, P. R. (1990). acting together. Proceedings Eighth
National Conference Artificial Intelligence, pp. 94{99 Boston, Massachusetts.
Luce, R. D., & Raiffa, H. (1957). Games Decisions. John Wiley & Sons, Inc., New
York.
Malone, T. W. (1986). Organizing information processing systems: Parallels human
organizations computer systems. Zacharai, W., Robertson, S., & Black, J.
(Eds.), Cognition, Computation, Cooperation. Ablex Publishing Corp., Norwood,
NJ.
Malone, T. W., Fikes, R. E., Grant, K. R., & Howard, M. T. (1988). Enterprise:
market-like task scheduler distributed computing environments. Huberman,
B. A. (Ed.), Ecology Computation, pp. 177{205. North-Holland Publishing
Company, Amsterdam.
McArthur, D., Steeb, R., & Cammarata, S. (1982). framework distributed problem
solving. Proceedings National Conference Artificial Intelligence, pp.
181{184 Pittsburgh, Pennsylvania.
Morgenstern, L. (1986). first order theory planning, knowledge, action. Halpern,
J. Y. (Ed.), Theoretical Aspects Reasoning Knowledge, pp. 99{114. Morgan
Kaufmann, Los Altos.
234

fiMechanisms Automated Negotiation

Morgenstern, L. (1987). Knowledge preconditions actions plans. Proceedings
Tenth International Joint Conference Artificial Intelligence, pp. 867{874
Milan, Italy.
Morgenstern, L. (1990). formal theory multiple agent nonmonotonic reasoning.
Proceedings Eighth National Conference Artificial Intelligence, pp. 538{544
Boston, Massachusetts.
Moses, Y., & Tennenholtz, M. (1990). Artificial social systems part 1: Basic principles.
Tech. rep. CS90-12, Weizmann Institute.
Moses, Y., & Tennenholtz, M. (1993). Off-line reasoning on-line eciency. Proceedings
Thirteenth International Joint Conference Artificial Intelligence, pp. 490{
495 Chambery, France.
Myerson, R. (1982). Optimal coordination mechanisms generalized principal-agent problems. Journal Mathematical Economics, 10, 67{81.
Myerson, R. (1991). Game Theory: Analysis Con ict. Harvard University Press, Cambridge, Massachusetts.
Nash, J. F. (1950). bargaining problem. Econometrica, 28, 155{162.
Nash, J. F. (1953). Two-person cooperative games. Econometrica, 21, 128{140.
Osborne, M. J., & Rubinstein, A. (1990). Bargaining Markets. Academic Press Inc.,
San Diego, California.
Pednault, E. P. D. (1987). Formulating multiagent dynamic-world problems classical
planning framework. Georgeff, M. P., & Lansky, A. L. (Eds.), Reasoning Actions Plans: Proceedings 1986 Workshop, pp. 47{82 San Mateo, California.
Morgan Kaufmann.
Pollack, M. E. (1992). uses plans. Artificial Intelligence, 57 (1).
Pope, R. P., Conry, S. E., & Mayer, R. A. (1992). Distributing planning process
dynamic environment. Proceedings Eleventh International Workshop
Distributed Artificial Intelligence, pp. 317{331 Glen Arbor, Michigan.
Raiffa, H. (1968). Decision Analysis, Introductory Lectures Choices Uncertainty.
Addison-Wesley Publishing Company, Reading, Massachusetts.
Raiffa, H. (1982). Art Science Negotiation. Belknap Press Harvard
University Press, Cambridge, Massachusetts.
Rao, A. S., & Georgeff, M. P. (1991). Asymmetry thesis side-effect problems lineartime branching-time intention logics. Proceedings Twelfth International
Joint Conference Artificial Intelligence, pp. 498{504 Sydney, Australia.
235

fiZlotkin & Rosenschein

Rao, A. S., & Georgeff, M. P. (1993). model-theoretic approach verification
situated reasoning systems. Proceedings Thirteenth International Joint
Conference Artificial Intelligence, pp. 318{324 Chambery, France.
Rao, A. S., Georgeff, M. P., & Sonenberg, E. (1991). Social plans: preliminary report.
Pre-Proceedings Third European Workshop Modeling Autonomous Agents
Multi-Agent Worlds Germany.
Rasmusen, E. (1989). Games Information, Introduction Game Theory. Basil
Blackwell, Cambridge, Massachusetts.
Rosenschein, J. S. (1982). Synchronization multi-agent plans. Proceedings
National Conference Artificial Intelligence, pp. 115{119 Pittsburgh, Pennsylvania.
Rosenschein, J. S. (1986). Rational Interaction: Cooperation Among Intelligent Agents.
Ph.D. thesis, Stanford University.
Rosenschein, J. S. (1993). Consenting agents: Negotiation mechanisms multi-agent
systems. Proceedings Thirteenth International Joint Conference Artificial
Intelligence, pp. 792{799 Chambery, France.
Rosenschein, J. S., & Genesereth, M. R. (1985). Deals among rational agents. Proceedings
Ninth International Joint Conference Artificial Intelligence, pp. 91{99 Los
Angeles, California.
Roth, A. E. (1979). Axiomatic Models Bargaining. Springer-Verlag, Berlin.
Rubinstein, A. (1982). Perfect equilibrium bargaining model. Econometrica, 50 (1),
97{109.
Rubinstein, A. (1985). Choice conjectures bargaining game incomplete information. Roth, A. E. (Ed.), Game-theoretic models bargaining, pp. 99{114.
Cambridge University Press, Cambridge, New York.
Russell, S., & Wefald, E. (1989). Principles metareasoning. Proceedings First
International Conference Principles Knowledge Representation Reasoning,
pp. 400{411. Morgan Kaufmann.
Sandholm, T. (1993). implementation contract net protocol based marginal
calculations. Proceedings Eleventh National Conference Artificial Intelligence, pp. 256{262.
Schelling, T. C. (1963). Strategy Con ict. Oxford University Press, New York.
Schelling, T. C. (1984). Choice Consequence. Harvard University Press, Cambridge,
Massachusetts.
Shoham, Y., & Tennenholtz, M. (1992a). Emergent conventions multi-agent systems:
initial experimental results observations (preliminary report). Principles
knowledge representation reasoning: Proceedings Third International Conference Cambridge, Massachusetts.
236

fiMechanisms Automated Negotiation

Shoham, Y., & Tennenholtz, M. (1992b). synthesis useful social laws artificial
agent societies (preliminary report). Proceedings National Conference
Artificial Intelligence San Jose, California.
Shoham, Y., & Tennenholtz, M. (1995). social laws artificial agent societies: Off-line
design. Artificial Intelligence. appear.
Smith, R. G. (1978). Framework Problem Solving Distributed Processing Environment. Ph.D. thesis, Stanford University.
Smith, R. G. (1980). contract net protocol: High-level communication control
distributed problem solver. IEEE Transactions Computers, C-29 (12), 1104{1113.
Steeb, R., Cammarata, S., Hayes-Roth, F., & Wesson, R. (1980). Distributed intelligence
air eet control. Tech. rep. WD-839-ARPA, Rand Corporation.
Stuart, C. J. (1985). implementation multi-agent plan synchronizer. Proceedings
Ninth International Joint Conference Artificial Intelligence, pp. 1031{1035
Los Angeles, California.
Sycara, K. P. (1988). Resolving goal con icts via negotiation. Proceedings Seventh
National Conference Artificial Intelligence, pp. 245{250 St. Paul, Minnesota.
Sycara, K. P. (1989). Argumentation: Planning agents' plans. Proceedings
Eleventh International Joint Conference Artificial Intelligence, pp. 517{523
Detroit.
Tennenholtz, M., & Moses, Y. (1989). cooperation multi-entity model (preliminary
report). Proceedings Eleventh International Joint Conference Artificial
Intelligence, pp. 918{923 Detroit, Michigan.
von Martial, F. (1990). Coordination plans multiagent worlds taking advantage
favor relation. Proceedings Tenth International Workshop Distributed
Artificial Intelligence Bandera, Texas.
von Martial, F. (1992a). Coordinating Plans Autonomous Agents. No. 610 Lecture
Notes Artificial Intelligence. Springer Verlag, Heidelberg, Germany.
von Martial, F. (1992b). Coordination negotiation based connection dialogue
states actions. Proceedings Eleventh International Workshop Distributed Artificial Intelligence, pp. 227{246 Glen Arbor, Michigan.
Wellman, M. P. (1992). general equilibrium approach distributed transportation planning. Proceedings Tenth National Conference Artificial Intelligence San
Jose, California.
Zeuthen, F. (1930). Problems Monopoly Economic Walfare. G. Routledge & Sons,
London.
237

fiZlotkin & Rosenschein

Zlotkin, G., & Rosenschein, J. S. (1989). Negotiation task sharing among autonomous
agents cooperative domains. Proceedings Eleventh International Joint
Conference Artificial Intelligence, pp. 912{917 Detroit, Michigan.
Zlotkin, G., & Rosenschein, J. S. (1990). Negotiation con ict resolution noncooperative domains. Proceedings Eighth National Conference Artificial
Intelligence, pp. 100{105 Boston, Massachusetts.
Zlotkin, G., & Rosenschein, J. S. (1991a). Cooperation con ict resolution via negotiation among autonomous agents noncooperative domains. IEEE Transactions
Systems, Man, Cybernetics, 21 (6), 1317{1324.
Zlotkin, G., & Rosenschein, J. S. (1991b). Incomplete information deception multiagent negotiation. Proceedings Twelfth International Joint Conference
Artificial Intelligence, pp. 225{231 Sydney, Australia.
Zlotkin, G., & Rosenschein, J. S. (1991c). Negotiation goal relaxation. Demazeau,
Y., & Muller, J.-P. (Eds.), Decentralized A. I. 2, Proceedings Second European
Workshop Modelling Autonomous Agents Multi-Agent World, pp. 273{286.
North-Holland, Amsterdam.
Zlotkin, G., & Rosenschein, J. S. (1993a). domain theory task oriented negotiation.
Proceedings Thirteenth International Joint Conference Artificial Intelligence,
pp. 416{422 Chambery, France.
Zlotkin, G., & Rosenschein, J. S. (1993b). extent cooperation state-oriented domains: Negotiation among tidy agents. Computers Artificial Intelligence, 12 (2),
105{122.
Zlotkin, G., & Rosenschein, J. S. (1993c). Negotiation incomplete information
worth: Strict versus tolerant mechanisms. Proceedings First International
Conference Intelligent Cooperative Information Systems, pp. 175{184 Rotterdam, Netherlands.
Zlotkin, G., & Rosenschein, J. S. (1994). Coalition, cryptography, stability: Mechanisms coalition formation task oriented domains. Proceedings National
Conference Artificial Intelligence, pp. 432{437 Seattle, Washington.
Zlotkin, G., & Rosenschein, J. S. (1996a). Compromise negotiation: Exploiting worth
functions states. Artificial Intelligence, 84 (1{2), 151{176.
Zlotkin, G., & Rosenschein, J. S. (1996b). Mechanism design automated negotiation,
application task oriented domains. Artificial Intelligence. appear.

238

fiJournal Artificial Intelligence Research 5 (1996) 289-300

Submitted 6/96; published 12/96

Research Note

Characterizations Decomposable Dependency Models

Luis M. de Campos

Departamento de Ciencias de la Computacion e I.A.
E.T.S. Ingeniera Informatica, Universidad de Granada
18071 - Granada SPAIN

lci@decsai.ugr.es

Abstract

Decomposable dependency models possess number interesting useful properties. paper presents new characterizations decomposable models terms independence relationships, obtained adding single axiom well-known
set characterizing dependency models isomorphic undirected graphs. also
brie discuss potential application results problem learning graphical
models data.

1. Introduction

Graphical models knowledge representation tools commonly used increasing number researchers, particularly Artificial Intelligence Statistics communities.
reason success graphical models capacity represent handle
independence relationships, proved crucial ecient management
storage information (Pearl, 1988).
different kinds graphical models, although particularly interested
undirected directed graphs (which, probabilistic context, usually called
Markov networks Bayesian networks, respectively). one merits
shortcomings, neither two representations expressive power
other: independence relationships represented means directed
graphs (using d-separation criterion) cannot represented using undirected ones
(through separation criterion), reciprocally. However, class models
represented means directed undirected graphs, precisely
class decomposable models (Haberman, 1974; Pearl, 1988). Decomposable models also
possess important properties, relative factorization parameter estimation,
make quite useful. So, models studied characterized many
different ways (Beeri, Fagin, Maier, & Yannakakis, 1983; Haberman, 1974; Lauritzen, Speed,
& Vijayan, 1984; Pearl, 1988; Wermuth & Lauritzen, 1983; Whittaker, 1991). example,
decomposable models characterized kind dependency models isomorphic
chordal graphs (Lauritzen et al., 1984; Whittaker, 1991).
However, know characterization decomposable models terms
kind independence relationships capable representing. somewhat
surprising, seems quite natural us characterize type object using
terms used define it; case, object special type dependency
model, i.e., collection conditional independence statements set variables
given domain knowledge, therefore able describe terms
c 1996 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiDe Campos

properties independence relationships. objective paper precisely
obtain characterization decomposable models.
approach problem based identifying set properties axioms
collection independence relationships must satisfy, order representable
chordal graph. approach successfully used study kinds
dependency models: Pearl Paz (1985) identified set properties characterizing
models isomorphic undirected graphs, de Campos (1996) determined axioms
characterize models isomorphic undirected directed singly connected graphs
(i.e., trees polytrees, respectively).
rest paper organized follows. Section 2 brie describe several
concepts basic subsequent development. Section 3 introduces decomposable
models representation using chordal graphs. Section 4 prove two characterizations decomposable models. characterizations turn surprisingly
simple: add single property set axioms characterizing dependency
models isomorphic undirected graphs. Section 5 discusses relationships
results Lauritzen's characterization chordal graphs. Finally, Section 6 contains
concluding remarks proposals future work, include application
results developed problem learning graphical models data.

2. Preliminaries

section, going describe notation well basic concepts
results used throughout paper.
Dependency Model (Pearl, 1988) pair = (U; ), U finite set elements variables, (:; :j:) rule assigns truth values three place predicate
whose arguments disjoint subsets U . Single elements U denoted standard
Greek lowercase letters, whereas subsets U represented capital letters.
interpretation conditional independence assertion (X; jZ ) observed
Z , additional information X could obtained also observing . example, probabilistic model (Dawid, 1979; Lauritzen, Dawid, Larsen, & Leimer, 1990),
(X; jZ ) holds

P (xjz; y) = P (xjz) whenever P (z; y) > 0;
every instantiation x, z sets variables X , Z . However, dependency
models applicable many situations far beyond probabilistic models (de Campos, 1995;
Pearl, 1988; Shenoy, 1992).
graphical representation dependency model = (U; ) direct correspondence
elements U set nodes given graph, G, topology
G ects properties . topological property selected represent independence
assertions depends type graph use: separation undirected graphs dseparation (Pearl, 1988; Verma & Pearl, 1990) directed acyclic graphs (dags):

Separation: Given undirected graph G, two subsets nodes, X , said
separated set nodes Z , denoted hX; jZ iG , Z intercepts
chains nodes X .
290

fiCharacterizations Decomposable Dependency Models

d-separation: Given dag G, chain C (a chain directed graph sequence
adjacent nodes, direction arrows matter) node ff node fi
said blocked set nodes Z , vertex 2 C that, either
{ 2 Z arrows C meet head head ,
{ 62 Z , descendants Z , arrows C meet head
head .
Two subsets nodes, X , said d-separated Z , also
denoted hX; jZ iG , chains nodes X nodes
blocked Z . exists criterion equivalent d-separation, based
separation X Z moral graph smallest ancestral set containing
X [ [ Z (Lauritzen et al., 1990).
Given dependency model, , say undirected graph (a dag, respectively), G,
I-map every separation (d-separation, respectively) G implies independence
: hX; jZ iG ) (X; jZ ). hand, undirected graph (a dag, resp.),
G, called D-map every independence relation model implies separation (dseparation resp.) graph: (X; jZ ) ) hX; jZ iG . graph, G, Perfect map
I-map D-map. said graph-isomorphic graph exists
perfect map .

class dependency models isomorphic undirected graphs completely
characterized (Pearl & Paz, 1985) terms five properties axioms satisfied
independence relationships within model:
(C1) Symmetry:
(I (X; jZ ) ) (Y; X jZ )) 8X; Y; Z U:
(C2) Decomposition:
(I (X; [ W jZ ) ) (X; jZ )) 8X; Y; W; Z U:
(C3) Strong Union:
(I (X; jZ ) ) (X; jZ [ W )) 8X; Y; W; Z U:
(C4) Intersection:
(I (X; jZ [ W ) (X; W jZ [ ) ) (X; [ W jZ )) 8X; Y; W; Z U:
(C5) Transitivity:
(I (X; jZ ) ) (X; jZ ) ( ; jZ ) 8 2 U n (X [ [ Z )) 8X; Y; Z U:
Pearl Paz also tacitly assumed additional, trivial, axiom holds, namely (X; ;jZ )
8X; Z U . also assumed sets X; Y; Z; W involved axioms
pairwise disjoint.

Theorem 1 (Pearl Paz, 1985) dependency model isomorphic undirected graph if, if, satisfies axioms C1{C5.

graph associated dependency model , conditional independence
equivalent separation graph, GM = (U; EM ), set edges
291

fiDe Campos

EM

EM = fff{fi j ff; fi 2 U; :I (ff; fi jU n fff; fi g)g:

hand, class dependency models isomorphic dags considerably
dicult characterize. suggested (Geiger, 1987; Pearl, 1988)
number axioms required complete characterization d-separation dags
probably unbounded. However, restricted models, namely polytree-isomorphic
models, fully characterized using finite number axioms (de Campos, 1996).
Graphical models convenient means expressing conditional independence
statements given domain knowledge, also convey information necessary
decisions inference, form numerical parameters quantifying strength
link. assignment numerical parameters graphical model also quite different
undirected directed graphs (here restrict discussion probabilistic models).
case directed acyclic graphs, simple matter: assign
variable xi dag conditional probability distribution every instantiation
variables form parent set xi , (xi). product local distributions
constitutes complete consistent specification, i.e., joint probability distribution
(which also preserves independence relationships displayed dag):

P (x1 ; x2; : : :; xn) =

Yn P (xij(xi))

i=1

However, case undirected graphs different: constructing complete consistent
quantitative specification preserving dependence structure arbitrary undirected graph done using method Gibb's potentials (Lauritzen, 1982) (which
assigns compatibility functions cliques graph), considerably
complicated, terms computational effort meaningfulness parameters,
simple method used dags.

3. Decomposable Models Chordal Graphs
dependency models representable means special class undirected graphs
present quantification problem described above. called decomposable models, also exhibit number important useful additional properties.
several ways defining decomposable models. appropriate
interests, mainly lie graphical modelling, based graph-theoretic concept:
chordal graphs, also called triangulated graphs (Rose, 1970).

Definition 1 undirected graph said chordal every cycle length four
chord, i.e., edge linking two non-adjacent nodes cycle.

simplest example non-chordal graph diamond-shaped graph displayed
Figure 1 (a).

Definition 2 dependency model decomposable isomorphic chordal graph.
292

fiCharacterizations Decomposable Dependency Models

fi


@
,
,

fi


@
,
,
@
@
,
,
@
@
@fi
@fi fi
fi
fi
,
,

ff
fi
ff






Z
Z
,
,
,
,
Z
Z
Z fi,
Z fi,
Z
Z
fi ,
,


(a)

(b)

Figure 1: (a) simplest example non-chordal graph (b) Non-chordal graph satisfiying
C1{C5 C7
One important property satisfied every chordal graph G, fact characterizes
chordal graphs (Beeri et al., 1983), edges G directed acyclically
every pair converging arrows emanates two adjacent nodes. property,
deduced (Pearl, 1988) class dependency models may represented
dag undirected graph precisely class decomposable models (note
non-chordal graphs, matter direct arrows, always pair
nonadjacent parents sharing common child, configuration causes separation
undirected graphs produce d-separation dags).
Another crucial property chordal graphs cliques (i.e., largest subgraphs whose nodes adjacent other) joined form tree , called
join tree, two cliques containing node ff either adjacent
connected chain made entirely cliques contain ff (Beeri et al., 1983) (an
example depicted Figure 2).

,
,
,

yl

, Z
Z
,
,
Z

xl

zl

@
%
%
@
@ %

, @
,
@
@
,
w

tl

(a)

ul

vl

l

ffyzt


ffxy bbbffuzt




,
ffuv,, ffuwAA



(b)

Figure 2: Chordal graph (a) join tree (b)
result important consequences probabilistic modelling: joint probability
distribution factorises product marginal distributions cliques (Lauritzen et al.,
1984; Pearl, 1988; Whittaker, 1991); moreover, maximum likelihood estimates model
directly calculable (Whittaker, 1991). consequence compatibility functions
293

fiDe Campos

used quantitatively specify model, clear meaning easily estimated.
Additionally, tree structure cliques chordal graph facilitates recursive updating probabilities. fact, one important algorithms propagation (i.e.,
updating using local computations) probabilities dags, based transformation
given dag chordal graph, moralising next triangulating dag (Lauritzen
& Spiegelhalter, 1988).

4. Characterizing Decomposable Models

purpose find characterization decomposable models (or equivalently, chordal
graphs) terms properties independence relationships. carried
adding single property set axioms, C1{C5, characterizing dependency models
isomorphic undirected graphs.
Let us consider following axiom:
(C6) Strong Chordality:
(I (ff; fi jZ [ [ ) ( ; jU nf ; g) ) (ff; fi jZ [ ) (ff; fi jZ [ )) 8ff; fi; ; 2 U 8Z

U n fff; fi; ; g:

axiom establishes condition allows us reduce size conditioning
set separating two variables ff fi , namely two variables set
conditionally independent. going demonstrate adding axiom strong
chordality axioms found Pearl Paz, C1{C5, associated graph necessarily
becomes chordal graph vice versa. Therefore, shall obtain characterization
decomposable models. Pearl (1988) proposed axiom slightly different C6,
necessary, though sucient condition chordality. called axiom chordality:
(C7) Chordality:
(I (ff; fi j [ ) ( ; jff [ fi ) ) (ff; fi j ) (ff; fi j )) 8ff; fi; ; 2 U:
Observe context, i.e., assuming C1{C5 hold, C6 implies C7:
(ff; fij [ ) ( ; jff [ fi ), strong union (C3) guarantees ( ; jU n f ; g)
implied ( ; jW ) W U nf ; g (in particular W = fff; fi g), applying
C6 Z = ;, obtain (ff; fi j ) (ff; fi j ). However, set axioms C1{C5
C7 constitute characterization chordal graphs, graph depicted Figure
1 (b) shows: graph chordal, satisfies C1{C5 C7. using C6 instead
C7 shall obtain desired result.

Theorem 2 dependency model isomorphic chordal graph if, if,
satisfies axioms C1{C6.

Proof: First, let us prove sucient condition. Using Pearl Paz result, C1{

C5 deduce isomorphic associated graph G, therefore independence
equivalent separation G. prove G chordal.
Let us suppose G chordal. Then, G, cycle t1 t2 : : :tn,1 tn t1 , n 4,
without chord, i.e., 8i; j s.t. 1 < + 1 < j n, edges ti {tj belong EM
(except edge t1 {tn ).
294

fiCharacterizations Decomposable Dependency Models

Let us consider nodes t1 tn,1 , set nodes Z = U n ft1 ; : : :; tn g. First,
going prove independence statement (t1; tn,1 jZ [ t2 [ tn )
true: :I (t1 ; tn,1 jZ [ t2 [ tn ) could find chain linking t1 tn,1
containing nodes Z [ t2 [ tn , i.e., chain linking t1 tn,1 containing nodes
ft3 ; : : :; tn,2 g; case would edge linking t1 node tj ,
3 j n , 2, contradicts assumption cycle chord. Therefore,
(t1; tn,1 jZ [ t2 [ tn ).
hand, nodes t2 tn connected edge (once
cycle chord), separated U nft2 ; tn g, therefore
(t2 ; tn jU nft2 ; tn g). Now, using C6, deduce either (t1; tn,1 jZ [ t2 ) (t1; tn,1 jZ [
tn ). either case chain linking t1 tn,1 blocked separating
set: first case chain t1 tn tn,1 , second case t1 t2 : : :tn,2 tn,1 .
Therefore, obtain contradiction, hence graph G chordal.
Now, let us prove necessary condition. using Pearl Paz's result,
isomorphic graph G, properties C1{C5 hold.
Let us suppose C6 hold. Then, find nodes ff; fi; ; subset
nodes Z (ff; fi jZ [ [ ), ( ; jU n f ; g), :I (ff; fi jZ [ ) :I (ff; fi jZ [ ).
:I (ff; fi jZ [ ) deduce chain fft1 : : :tn fi exists G, ti 62 Z [
8i, i.e., ft1 : : :tng \ (Z [ ) = ;. However, (ff; fijZ [ [ ) know every chain
linking ff fi must contain node Z [ [ . particular, previously
found chain, ft1 : : :tn g \ (Z [ [ ) 6= ;. Therefore, node tk
tk = . Let us consider node tk,1 : (ff; fi jZ [ [ ) transitivity (C5),
obtain (ff; tk,1jZ [ [ ) (tk,1 ; fi jZ [ [ ). first independence assertion
cannot true, chain fft1 : : :tk,2 tk,1 contain node Z [ [ .
Therefore, (tk,1 ; fi jZ [ [ ). (tk,1 ; fi jZ [ ), then, transitivity,
would obtain (ff; tk,1jZ [ ) (ff; fi jZ [ ), statements false, first
one existence chain fft1 : : :tk,2 tk,1 second one
hypothesis. So, :I (tk,1 ; fi jZ [ ). reasoning allows us assert
:I (ff; fijZ [ ) :I (tk,1; fijZ [ ). So, found node tk,1 adjacent = tk
satisfying properties ff. completely analogous reasoning applied node tk+1
proves (tk,1 ; tk+1 jZ [ [ ), :I (tk,1 ; tk+1 jZ [ ), :I (tk,1 ; tk+1 jZ [ ). So,
replaced nodes ff fi two nodes adjacent satisfying properties. Note
case one tk,1 tk+1 ff fi matter
subsequent argument.
Now, :I (tk,1 ; tk+1 jZ [ ) (tk,1 ; tk+1 jZ [ [ ) deduce
chain tk,1 s1 : : :sm tk+1 G si 62 Z [ 8i node sh , sh = .
simplify notation, let us call s0 = tk,1 , sm+1 = tk+1 . assume 8i; j
0 < + 1 < j h, edge linking si sj (if case,
simply replace subchain si si+1 : : :sj ,1 sj single edge si {sj , i.e., consider
shortest subchain tk,1 sh ). reason, also suppose
8p; q h < p + 1 < q + 1, edge linking sp sq .
found cycle s0 s1 : : :sh,1 sh+1 : : :sm sm+1 G. Now, let sf sg two
nodes satisfying f < h < g , sf sg adjacent adjacent sj
j s.t. f < j < g j 6= h (note always find two nodes, starting
f = 0 g = + 1). still cycle sf : : :sh,1 sh+1 : : :sg length four more,
295

fiDe Campos

that, according hypothesis, cycle must chord. However, taking
account cycle constructed, possible chords edge {
edge linking node si , f < < h, node sp , h < p < g . first possibility
contradicts hypothesis ( ; jU nf ; g), second one implies existence
chain tk,1 s1 : : :sf : : :si sp : : :sg : : :sm tk+1 linking tk,1 tk+1 , contain
node Z [ [ , contradiction statement (tk,1 ; tk+1 jZ [ [ ). Therefore,
property C6 true.
establish another interesting characterization chordal graphs, also adding
one axiom Pearl Paz. new axiom following:
(C8) Clique-separability:
(I (ff; fi jU n fff; fi g) ) 9W U n fff; fi g (ff; fi jW ) either jW j 1
:I ( ; jU n f ; g) 8 ; 2 W ) 8ff; fi 2 U .
Axiom C8 asserts whenever two nodes ff fi adjacent (are independent),
find separating set whose nodes adjacent other, i.e., complete
separating set.

Theorem 3 dependency model isomorphic chordal graph if, if,
satisfies axioms C1{C5 C8.

Proof: Let us prove necessary condition. graph G associated chordal,

Theorem 2 know properties C1{C5 C6 hold.
Let us suppose C8 hold. Then, ff fi , (ff; fi jU n
fff; fig) W U n fff; fig either :I (ff; fijW ), jW j > 1 9 ; 2 W
( ; jU n f ; g).
Let W0 separating set minimal size ff fi , i.e., (ff; fi jW0) :I (ff; fi jS )
8S W0 (we know least one separating set type exist,
(ff; fijU n fff; fig) holds). Then, deduce jW0j > 1 9 ; 2 W0
( ; jU n f ; g). Let us define Z = W0 n f ; g. Thus, (ff; fi jZ [ [ )
( ; jU n f ; g) and, applying C6, obtain either (ff; fi jZ [ ) (ff; fi jZ [ ), i.e.,
(ff; fijW0 n fg) (ff; fijW0 n f g), contradicts minimality W0 . Therefore,
C8 true.
prove sucient condition, let us suppose G chordal. Then,
cycle t1 t2 : : :tn,1 tn t1 , n 4, without chord. So, nodes t1 tn,1 adjacent,
hence separated, let W separating set t1 tn,1 , i.e., satisfying
(t1; tn,1 jW ). tn 2 W ft2; : : :; tn,2 g \ W 6= ;, otherwise could find chain
linking t1 tn,1 would blocked W , thus contradicting (t1 ; tn,1 jW ).
So, every separating set W contains tn ti ; 2 n , 2, hence jW j > 1. Now,
applying C8, deduce :I (tn ; tijU n ftn ; ti g), i.e., tn ti adjacent nodes,
contradicts assumption cycle chord. Then, conclusion
graph chordal.
296

fiCharacterizations Decomposable Dependency Models

5. Relationships Characterizations Decomposable Models
characterization decomposable models1 (Lauritzen, 1989) quite related
ours: undirected graph chordal if, if, every subset nodes separates
two nodes ff fi minimal complete.
order rewrite result using notation, let us consider following axiom:
(C9) Completeness:
(I (ff; fi jZ ) :I (ff; fi jS ) 8S Z ) jZ j 1 :I ( ; jU n f ; g) 8 ; 2 Z ) 8ff; fi 2
U 8Z U n fff; fig.
Axiom C9 says exactly minimal separator ff fi complete.
equivalent formulation axiom reads: separator ff fi complete
cannot minimal. symbols:
(C9') Completeness:
(I (ff; fi jZ [ [ ) ( ; jU nf ; g) ) 9W Z [ [ (ff; fi jW )) 8ff; fi; ; 2

U 8Z U n fff; fi; ; g:

Then, Lauritzen's result reformulated follows: dependency model
isomorphic chordal graph if, if, satisfies axioms C1{C5 either C9
C9'.
Note similarity C9 C8 C9' C6. Taking account
Theorems 2 3, deduce axioms, C6, C8, C9 C9', equivalent
among (assuming C1{C5 hold). However, equivalence evident,
spite similarities among axioms: clear C6 implies C9' C9 implies C8,
opposite implications obvious. fact, strong chordality clique-separability
seem stronger weaker, respectively, completeness. becomes clearer
express axioms following way: Assuming two nodes ff fi separated:

Completeness (C9 C9'): separator ff fi minimal, complete;
or, equivalently, separator ff fi complete, proper subset
still separator ff fi .
Clique-separability (C8): exists separator ff fi complete.
Strong chordality (C6): separator ff fi complete, proper
subset still separator ff fi ; moreover, find subset
removing, initial separator, one nodes causing incompleteness.

Observe C6 C9' share antecedent, consequent C9'
says exists separator, whereas consequent C6 gives information
identity separator. Note also C8 C9 assert existence
complete separator, C9 requires previous condition (minimality) C8 not.
1. existence result pointed reviewer.

297

fiDe Campos

6. Concluding Remarks
found two new characterizations class decomposable dependency models,
terms properties independence relationships. believe results
theoretically interesting, provide new perspective important well
studied class graphical models. Moreover, results quite concise, since one
property added set properties characterizing independence relationships
undirected graphs. could also useful proving results models
sort.
practical point view, axiomatic characterizations create desiderata
could drive automated construction chordal graphs data. already
commented, practical use graphical models and, particularly, bayesian networks, requires dag representing model transformed chordal graph.
perspective learning models data, may interesting estimate directly
chordal graph available data, instead first learning dag converting chordal graph. believe basic independence properties chordal
graphs identified theoretical study, C6 C8, could guide us design efficient algorithms learning chordal graphs. known problem learning
bayesian networks data computationally complex. example, algorithms (Spirtes, Glymour, & Scheines, 1993) start complete undirected graph,
try remove edges testing conditional independence linked nodes,
using conditioning sets small possible (thus reducing complexity increasing
reliability). context, rewrite property C6 following way:

:I (ff; fijZ [ ) :I (ff; fijZ [ ) (ff; fijZ [ [ ) ) :I ( ; jU n f ; g);
could use rule simultaneously allows us remove edge ff{fi
current graph, fix edge { true edge graph.
Similarly, property C8 could give rise following rule: trying remove
edge ff{fi current graph, testing conditional independence statements like
(ff; fijW ), discard candidate separating sets sets W whose nodes
adjacent other.
topic designing ecient algorithms learning chordal graphs object
future research.

Acknowledgements
work supported Spanish Comision Interministerial de Ciencia Tecnologa (CICYT) Project n. TIC96-0781. would like thank Milan Studeny
three anonymous reviewers helpful comments suggestions. particularly grateful reviewer pointed existence Lauritzen's characterization
chordal graphs.
298

fiCharacterizations Decomposable Dependency Models

References

Beeri, C., Fagin, R., Maier, D., & Yannakakis, M. (1983). desirability acyclic
database schemes. JACM, 30, 479{513.
Dawid, A. P. (1979). Conditional independence statistical theory. J.R. Statist. Soc. Ser.
B, 41, 1{31.
de Campos, L. M. (1995). Independence relationships possibility theory application learning belief networks. Della Riccia, G., Kruse, R., & Viertl, R.
(Eds.), Mathematical Statistical Methods Artificial Intelligence, CISM Courses
Lectures 363, pp. 119{130. Wien: Springer Verlag.
de Campos, L. M. (1996). Independency relationships learning algorithms singly
connected networks. Tech. rep. DECSAI 960204, University Granada.
Geiger, D. (1987). non-axiomatizability dependencies directed acyclic graphs.
Tech. rep. R-83, Cognitive Systems Laboratory, UCLA.
Haberman, S. J. (1974). Analysis Frequency Data. Chicago: University Chicago
Press.
Lauritzen, S. L. (1982). Lectures Contingency Tables (2nd ed.). Aalborg: University
Aalborg Press.
Lauritzen, S. L. (1989). Mixed graphical association models. Scand. J. Statist., 16, 273{306.
Lauritzen, S. L., Dawid, A. P., Larsen, B. N., & Leimer, H. G. (1990). Independence
properties directed markov fields. Networks, 20, 491{505.
Lauritzen, S. L., Speed, T. P., & Vijayan, K. (1984). Decomposable graphs hypergraphs.
J. Autral. Math. Soc. A, 36, 12{29.
Lauritzen, S. L., & Spiegelhalter, D. J. (1988). Local computations probabilities
graphical structures application expert systems. J.R. Statist. Soc. Ser.
B, 50, 157{224.
Pearl, J. (1988). Probabilistic Reasoning Intelligent Systems: Networks Plausible
Inference. San Mateo: Morgan Kaufmann.
Pearl, J., & Paz, A. (1985). Graphoids: graph-based logic reasoning relevance
relations. Tech. rep. 850038 (R-53-L), Cognitive Systems Laboratory, UCLA.
Rose, D. J. (1970). Triangulated graphs elimination process. Journal Mathematical Analysis Applications, 32, 597{609.
Shenoy, P. P. (1992). Conditional independence uncertainty theories. Dubois, D.,
Wellman, M. P., D'Ambrosio, B., & Smets, P. (Eds.), Proceedings Eighth Conference Uncertainty Artificial Intelligence, pp. 284{291. San Mateo: Morgan
Kaufmann.
299

fiDe Campos

Spirtes, P., Glymour, C., & Scheines, R. (1993). Causation, Prediction Search. Lecture
Notes Statistics 81. New York: Springer Verlag.
Verma, T., & Pearl, J. (1990). Causal networks: Semantics expressiveness. Shachter,
R. D., Levitt, T. S., Kanal, L. N., & Lemmer, J. (Eds.), Uncertainty Artificial
Intelligence, 4, pp. 69{76. Amsterdam: North-Holland.
Wermuth, N., & Lauritzen, S. L. (1983). Graphical recursive models contingency
tables. Biometrika, 70, 537{552.
Whittaker, J. (1991). Graphical Models Applied Multivariate Statistics. Chichester:
Wiley.

300

fiJournal Artificial Intelligence Research 5 (1996) 95{137

Submitted 3/96; published 9/96

Accelerating Partial-Order Planners: Techniques
Effective Search Control Pruning
Alfonso Gerevini

gerevini@ing.unibs.it

Lenhart Schubert

schubert@cs.rochester.edu

Dipartimento di Elettronica per l'Automazione, Universita di Brescia
Via Branze 38, I-25123 Brescia, Italy
Department Computer Science, University Rochester
Rochester, NY 14627-0226, USA

Abstract

propose domain-independent techniques bringing well-founded partialorder planners closer practicality. first two techniques aimed improving
search control keeping overhead costs low. One based simple adjustment
default A* heuristic used ucpop select plans refinement. based
preferring \zero commitment" (forced) plan refinements whenever possible, using
LIFO prioritization otherwise. radical technique use operator parameter
domains prune search. domains initially computed definitions
operators initial goal conditions, using polynomial-time algorithm
propagates sets constants operator graph, starting initial conditions.
planning, parameter domains used prune nonviable operator instances
remove spurious clobbering threats. experiments based modifications ucpop,
improved plan goal selection strategies gave speedups factors ranging 5
1000 variety problems nontrivial unmodified version.
Crucially, hardest problems gave greatest improvements. pruning technique
based parameter domains often gave speedups order magnitude
dicult problems, default ucpop search strategy improved
strategy. Lisp code techniques test problems provided on-line
appendices.

1. Introduction

concerned improving performance \well-founded" domain-independent planners { planners permit proofs soundness, completeness, desirable
theoretical properties. state-of-the-art example planner ucpop (Barrett
et al., 1994; Penberthy & Weld, 1992), whose intellectual ancestry includes strips (Fikes &
Nilsson, 1971), tweak (Chapman, 1987), snlp (McAllester & Rosenblitt, 1991).
planners unfortunately perform well present, comparison practically
oriented planners sipe (Wilkins, 1988), prs (Georgeff & Lansky, 1987), O-Plan
(Currie & Tate, 1991).
However, appear ample opportunities bringing well-founded planners
closer practicality. following, begin suggesting improvements
search control planning, based carefully formulated strategies selecting partial
plans refinement, choosing open conditions selected partial plan. plan c 1996 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiGerevini & Schubert
selection strategy uses S+OC { number steps plan plus number open
conditions still established { heuristic measure ucpop's A* search
plan space. (Addition attenuated term ecting number threats \unsafe
conditions" UC, 0.1UC, sometimes advantageous.)1 aw-selection strategy,
term ZLIFO, prefers \zero commitment" plan refinements others, otherwise
uses LIFO (stack) discipline. Zero commitment refinements logically necessary ones:
either eliminate plan altogether contains irremediable aw, add
unique step unique causal link (from initial state) establish open condition
cannot established way. strategy closely related ones proposed
Peot & Smith (1993) Joslin & Pollack (1994) generally appears perform better
either.
describe two classes techniques Section 2 below, Section 3
report experimental results based slightly modified versions ucpop.2
dicult problems taken available ucpop test suite elsewhere, obtain
improvements factors ranging 5 1000, hardest problems
giving greatest improvements.
turn proposal using computed operator parameter domains
planning. particular, Section 4 motivate describe method precomputing parameter domains based propagating sets constants forward initial
conditions.3 process iterative, algorithm runs within time bound
polynomial size problem specification. provide details algorithm,
along theorems correctness tractability, Sections 4.2{4.3 Online
Appendix 1.
Section 5 show use parameter domain information ucpop-style planner. planning, parameter domains used prune operator instances whose
parameter domains inconsistent binding constraints, eliminate spurious
threats cannot, fact, realized without violating domain constraints. illustrate
effectiveness technique examples drawn ucpop test suite well
trains transportation planning world developed Rochester (Allen & Schubert,
1991; Allen et al., 1995). tests, apply parameter domain information
context default ucpop search strategy. demonstrate significant gains
problems, particularly challenging ones (e.g., speedups order
magnitude several problems strips world, 900-fold speedup
trains problem).
another set tests trains world, use improved search strategies
baseline, i.e., ask whether additional speedups obtainable use parameter
1. search strategy described \A* IDA*" search (Penberthy & Weld, 1992); code
ucpop 2.0 described generally best-first, since arbitrary ranking functions, necessarily
corresponding A* heuristics, may plugged in. choices like S+OC S+OC+UC
plan-ranking heuristic (as discussed Section 2.2), natural view strategy A* strategy.
2. techniques describe applicable planners, focus ucpop
well-known Lisp code readily available. system obtained via anonymous ftp
cs.washington.edu.
3. hope notion parameter domain, set admissible bindings (constants), cause
confusion notion planning domain, specified set operators, along constraints
admissible initial conditions goal conditions.

96

fiAccelerating Partial-Order Planners
domains, obtainable S+OC ZLIFO search strategies. experimental results show speedups factor 10 use parameter
domains, top obtained improved search strategies (the combined speedup
2000).
evidence effectiveness using parameter domains combination
search strategy dependent peculiarity latter, also include
results ucpop's default strategy, Joslin Pollack's \least cost aw repair" (LCFR)
strategy (Joslin & Pollack, 1994) Peot Smith's \least commitment" (LC) open
condition selection strategy (Peot & Smith, 1993) Section 5.
Section 6, state conclusions, comment related work mention
possible extensions techniques.

2. Plan Selection Goal Selection

basing discussion experiments ucpop, algorithm exemplifying
state art well-founded partial-order planning. Thus begin sketch
algorithm, referring reader (Barrett et al., 1994; Penberthy & Weld, 1992) details.
next two subsections motivate describe improved plan-selection
goal-selection strategies.

2.1 UCPOP

ucpop uses strips-like operators, positive negative preconditions positive

negative effects. initial state consists positive predications constant arguments
(if any), ground predications false default. Unlike strips, ucpop also
allows conditional effects, expressed 2-part when-clauses specifying (possibly complex)
extra condition needed effect (possibly complex) effect itself. instance,
action PUTON(?x ?y ?z) (\put ?x ?y ?z") might conditional effects stating
?y table, clear end action, z
table, clear end action. \U" ucpop indicates
universally quantified conditions effects permitted well. instance,
permissible precondition PICKUP(?x) action says ?y, (not
(on ?y ?x)) holds. Universal statements handled explicit substitution domain
constants need concern us point.
essence, ucpop explores space partially specified plans, paired
agenda goals still satisfied threats still averted. initial plan contains
dummy *start* action whose effects given initial conditions, dummy
*end* action whose preconditions given goals. Thus goals uniformly viewed
action preconditions, uniformly achieved effects actions, including
*start* action.
plans consist collection steps (i.e., actions obtained instantiating available operators), along set causal links, set binding constraints,
set ordering constraints. open goal (precondition) selected
agenda, established (if possible) either adding step effect unifies
goal, using existing step effect unifies goal. (In
latter case, must consistent current ordering constraints place existing
97

fiGerevini & Schubert
step goal, i.e., step whose preconditions generated goal.)
new existing step used establish goal way, several side effects:
causal link (S ; Q; ) also added, indicates step \producing"
goal condition Q indicates step \consuming" Q. causal link serves
protect intended effect added (or reused) step interference
steps.
Binding constraints added, corresponding unifier action effect
question goal (precondition) achieves.
ordering constraint added, placing step question step whose
precondition achieves.
action question new, preconditions added agenda new
goals (except EQ/NEQ conditions integrated binding constraints { see
below).
New threats (unsafe conditions) determined. new step causal link,
steps threaten causal link effects unifiable condition
protected causal link (and effects occur temporally causal
link); effects new step may similarly threaten causal links.
either case, new threats placed agenda. useful distinguish definite
threats potential threats: former unification
confirmed threat involved new binding variables.
Binding constraints assert identity (EQ) nonidentity (NEQ) two variables variable
constant. EQ-constraints arise unifying open goals action effects, NEQconstraints arise (i) NEQ-preconditions newly instantiated actions, (ii) matching
negative goals containing variables initial state, (iii) averting threats
\separation", i.e., forcing non-equality two variables variable constant
unified threat detection. NEQ-constraints may disjunctive, handled simply
generating separate plans disjunct.
overall control loop ucpop consists selecting plan current list
plans (initially single plan based *start* *end*), selecting goal threat
agenda, replacing plan corresponding refined plans. agenda item
goal, refined plans corresponding ways establishing goal using
new existing step. agenda item definite threat causal link (S ; Q; ),
three refined plans. Two constrain threatening step
step (demotion) step (promotion), thus averting threat.
third possibility arises effect threatening (S ; Q; ) conditional effect
threatening action. conditional threat averted creating goal denying
precondition needed conditional effect.
ucpop \delay separation" switch, *d-sep*, turned on,
definite threats dealt with. Note potential threats may become definite result
added binding constraints. (They may also \expire" result added binding
ordering constraints, i.e., threatening effect may longer unify threatened
condition may forced occur threatened causal link. Expired
p

c

p

c

p

p

c

p

98

c

c

fiAccelerating Partial-Order Planners
threats removed agenda selected.) *d-sep* off, potential threats
well definite ones averted, separation additional method
besides three methods above.
Inconsistencies binding constraints ordering constraints detected
first occur (as result adding new constraint) corresponding plans eliminated. Planning fails plans remain. success condition creation plan
consistent binding ordering constraints empty agenda.
allowance conditional effects universal conditions effects causes
minor perturbations operation ucpop. instance, conditional effects lead
multiple matches operators given goal, match generating different
preconditions. (Of course, multiple matches even without conditional effects,
predicates occur effects.)
key issues us right strategic ones: plans selected
current set plans (discussed Section 2.2), goals selected given plan
(discussed Section 2.3).

2.2 Trouble Counting Unsafe Conditions

choice next plan refine ucpop system based A* best-first
search. Recall A* uses heuristic estimate f (p) overall solution cost consisting
part g (p) = cost current partial solution (plan) p part h(p) = estimate
additional cost best complete solution extends p. current context
helpful think f (p) measure plan complexity, i.e., \good" plans simple
(low-complexity) plans.
two points reader reminded. First, order A*
guarantee discovery optimal plan (i.e., \admissibility" condition), h(p)
overestimate remaining solution cost (Nilsson, 1980). Second, aim
necessarily find optimal solution find satisfactory solution quickly, f (p)
augmented include term estimates remaining cost finding solution.
One common way use term proportional h(p) well, i.e.,
emphasize h-component f relative g -component. reasonable
extent plans nearly complete (indicated low h-value) likely
take least effort complete. Thus prefer pursue plan p0 seems closer
complete plan p completion, even though overall complexity
estimate p0 may greater p (Nilsson, 1980) (pages 87{88). Alternatively,
could add heuristic estimate remaining cost finding solution f (p)
less independent estimate h(p).
considerations mind, evaluate advisability including
various terms ucpop's function guiding A* search, namely
S, OC, CL, UC,
number steps partial plan, OC number open conditions
(unsatisfied goals preconditions), CL number causal links, UC
number unsafe conditions (the number pairs steps causal links step
99

fiGerevini & Schubert
threatens causal link). default combination used ucpop S+OC+UC.4
becomes S+OC+UC+F special open conditions called \facts" present.
conditions state-dependent (e.g., numerical relation like (add-one ?x ?y),
geometrical one like (loc-in-room ?x ?y ?room)) established Lisp functions
(Barrett et al., 1994). Since test problems involved facts, discuss
F term except say followed ucpop default strategy including
term relevant (see TileWorld problems Section 3.2 also remarks
Section 5.2 connection parameter-domain experiments).
2.2.1 S: number steps currently plan

naturally viewed comprising g (p), plan complexity far. Intuitively,
plan complex extent contains many steps. domains might
want make distinctions among costs different kinds steps, simple step count
seems like reasonable generic complexity measure.
2.2.2 OC: number open conditions

viewed playing role h(p), since remaining open condition must
established step. catch may possible use existing steps
plan (including *start*, i.e., initial conditions) establish remaining open conditions.
Thus OC overestimate number steps still added, forfeiting admissibility.
Despite criticism, several considerations favor retention OC term. First,
better estimator residual plan complexity seems hard come by. Perhaps one could
modify OC discounting open conditions matched existing actions,
presumes open conditions actually achieved action re-use,
improbable remaining threats, remaining goals requiring new steps.5 Second,
possibility OC overestimate residual plan complexity rarely actualized, since typically steps still need added achieve goals,
steps typically introduce open conditions requiring new steps. Finally, extent OC times overestimate residual plan complexity,
viewed emphasizing h(p) term f (p), thus promoting faster problem-solving
explained above.
2.2.3 CL: number causal links

One might motivate inclusion term arguing numerous causal links
indicative complex plan. such, CL appears alternative step-counting.
4. way \recommended" strategy. ucpop implementation makes available various
options controlling search, used discretion experimenters. present work
prompted incorporation particular strategies option ucpop 4.0.
5. Note threats remaining goals impose constraints may consistent seemingly
possible instances action re-use. clear enough threats, often imply temporal ordering
constraints inconsistent re-use action. also fairly clear remaining goals. instance,
Towers Hanoi small disk D1 initially medium disk D2, turn big disk
D3, D3 peg P1. goal move tower third peg P3, seems ucpop initially
(on D1 D2) (on D2 D3) could achieved \re-use" *start*. However, third goal (on
D3 P3) implies various actions must added plan inconsistent two
seemingly possible instances action re-use.

100

fiAccelerating Partial-Order Planners
However, note CL general larger S, since every step plan establishes
least one open condition thus introduces least one causal link. larger CL
relative S, subgoals achieved action re-use. Hence, use CL instead
(or addition to) g (p) term, would effect saying achieving multiple
subgoals single step undesirable; would tend search ways achieving
multiple goals multiple steps, even achieved single step.
clearly good idea, justifies exclusion CL f (p).
2.2.4 UC: number unsafe conditions

note first clearly g -measure. number threats
tend increase establish subgoals without curtailing threats, threats
elements plan constructed contribute
complexity. fact, plan done threats gone.
UC viewed h-measure? One argument sorts armative
following. partial plans expandable complete plans, high value
UC makes likely partial plan contains irresolvable con icts. regard
impossible plans infinite cost, inclusion term increasing UC part
h-measure reasonable. carries serious risk, though, since case
partial plan consistent completion (despite high UC-count), inclusion
term greatly overestimate residual plan complexity.
Another possible armative argument conditional threats sometimes resolved
\confrontation", introduces new goal denying condition required threatening conditional effect. new goal may turn require new steps achievement,
adding plan complexity. However, link complexity tenuous. first
place, many ucpop test domains involve conditional effects, threat removal
promotion, demotion separation adds steps. Even conditional effects
present, many unconditional well conditional threats averted methods.
Furthermore, UC could swamp terms since threats may appear expire
groups size O(n), n number steps plan. instance, consider
partial plan involves moves robot R locations L1, ..., Ln,
n causal links labeled (at R L1), ..., (at R Ln). new move location L
added, initially indefinite point departure ?x, produces effects (at
R L) (not (at R ?x)). latter threaten n causal links,
least new move first temporally unordered relative n existing moves.
new action subsequently happens demoted precede first move (or
promoted follow last), ?x becomes bound constant distinct
L1, ..., Ln, n threats expire. Keeping mind different steps plan may
similar effects, see half steps could threaten causal links
others. case could O(n2 ) unsafe conditions, destined expire result
O(n) promotions/demotions. fact even single new binding constraint may cause
O(n2 ) threats expire. instance, n=2 effects (not (P ?x)) threatening
n=2 causal links labeled (P ?y), binding constraint (NEQ ?x ?y) added, n2 =4
threats expire. Recall expired threats selected agenda ucpop,
recognized discarded without action.
101

fiGerevini & Schubert
conclusion would mistake include UC full general h-measure,
though increasing function UC remains small enough mask OC may
worth including h.
Finally, UC regarded measure remaining cost finding solution?
Here, similar arguments apply. armative side, argue
high value UC indicates may facing combinatorially explosive, timeconsuming search set promotions demotions produce con ict-free step
ordering. words, high value UC may indicate high residual problem-solving
cost. (And end search, may still lack solution, viable step
ordering exists.) hand, already noted unsafe conditions include
many possible con icts may expire result subsequent partial ordering choices
variable binding choices specifically aimed removing con icts. counting
unsafe conditions arbitrarily overestimate number genuine refinement steps,
hence problem-solving effort, still needed complete plan.
UC scarcely trustworthy measure residual planning cost
measure residual plan cost.
Thus conclude promising general heuristic measure plan selection
S+OC, possibly augmented attenuated form UC term dominate
S+OC component. (For instance, one might add small fraction term,
UC/10, subtly { avoid swamping quadratic component { term proportional
UC 5.)
:

2.3 Goal Selection Strategy

important opportunity improving planning performance independently domain
lies identifying forced refinements, i.e., refinements made deterministically.
Specifically, considering possible refinements given partial plan, makes sense
give top priority open conditions cannot achieved; preferring open
conditions achieved one way { either addition action
yet plan, unique match initial conditions.
argument giving top priority unachievable goals plan containing
goals eliminated once. Thus prevent allocation effort refinement
doomed plans, generation refinement doomed successor plans.
argument preferring open conditions achieved one way
equally apparent. Since every open condition must eventually established
action, follows action unique, must part every possible completion
partial plan consideration. So, adding action \zero-commitment"
refinement, involving choices guesswork. time, adding refinement
general narrows search space adding binding constraints, ordering constraints
threats, constrain existing steps subsequently added steps. unique
refinements narrowing-down monotonic, never needing revocation. example,
suppose refinement happens add constraints eliminate certain action instance
possible way achieving certain open condition C . refinement unique,
assured completion plan contains way establishing C .
unique, assurance, since alternative refinement may
102

fiAccelerating Partial-Order Planners
compatible use achieve C . short, zero-commitment strategy cuts
search space without loss access viable solutions.
Peot Smith (1993) studied strategy preferring forced threats unforced
threats, also used \least commitment" (LC) strategy handling open conditions.
Least commitment always selects open condition generates fewest refined
plans. Thus entails priorities unachievable uniquely achievable goals
(while also entailing certain prioritization nonuniquely achievable goals). Joslin
Pollack (1994) studied uniform application strategy threats open
conditions ucpop, terming strategy \least cost aw repair" (LCFR). Combining
ucpop's default plan selection strategy, obtained significant search reductions
(though less significant running time reductions, mainly implementation reasons,
also intrinsic overhead computing \repair costs") majority
problems ucpop test suite.
Joslin & Pollack (1994) subsequently Srinivasan & Howe (1995) proposed
variants LCFR designed reduce overhead incurred LCFR aw selection.
strategies employ various assumptions aw repair costs, allowing
arduous forms cost estimation (requiring look-ahead generation plans) confined
subset aws plan, rest approximation used
significantly increase overhead. teams obtained quite significant reductions
overhead costs many cases, e.g., factors ranging 3 20
dicult problems. However, overall performance sometimes adversely affected.
Joslin Pollack found variant (QLCFR) solved fewer problems LCFR,
increase number plans generated cases. Srinivasan &
Howe's four strategies slightly better LCFR 10 problem domains
significantly worse others. terms plans examined search, best
overall strategy, uses similar action instances similar aws, slightly better
4 domains, slightly worse 4, significantly worse 2 (and cases
number plans examined also factor 20 default ucpop).
unmodified form ucpop, goals selected agenda according
LIFO (last-in first-out, i.e., stack) discipline. Based experience search processes
AI general, strategy much recommend it, simple default.
first place, overhead cost low compared strategies use heuristic evaluation
lookahead prioritize goals. well, tend maintain focus achievement
particular higher-level goal regression { much Prolog goal chaining { rather
attempting achieve multiple goals breadth-first fashion.
Maintaining focus single goal advantageous least
goals achieved independent. instance, suppose two goals G1 G2
achieved various ways, choosing particular method achieving G1
rule methods achieving G2. maintain focus G1
solved, attempting G2, total cost solving goals sum
costs solving individually. switch back forth, solutions
goals involve searches encounter many dead ends, combined cost
much larger. tend search unsolvable subtree G1 search
tree repeatedly, combination various alternatives G2 search tree (and vice
versa). argument still validity even G1 G2 entirely
103

fiGerevini & Schubert
independent; i.e., long G1 gives rise subproblems tend fail
way regardless choices made attempt solve G2 (or vice versa), shifting
attention G1 G2 tend generate set partial plans unnecessarily
\cross-multiplies" alternatives.
therefore chosen stay ucpop's LIFO strategy whenever
zero commitment choices. led substantial improvements LCFR
experiments.
Thus strategy, term ZLIFO (\zero-commitment last-in first-out"), chooses
next aw according following preferences:
1. definite threat (*d-sep* turned on), using LIFO pick among these;
2. open condition cannot established way;
3. open condition resolved one way, preferring open conditions
established introducing new action established
using *start*;6
4. open condition, using LIFO pick among these.
Hence overhead incurred ZLIFO aw selection limited open conditions, lower overhead incurred LCFR. Furthermore,
also significantly lower practice overhead incurred LC, testing
whether OC zero-commitment choice (i.e., whether established
one way) less expensive computing total number ways achieve it.
Online Appendix 1 give pseudocode ZLIFO selection open
condition (preferences 2{4). recently implementation also packaged
ucpop 4.0, new version ucpop available anonymous ftp cs.washington.edu.

3. Experiments Using UCPOP

order test ideas modified version 2.0 ucpop (Barrett et al., 1994), replacing default plan-selection strategy (S+OC+UC) goal-selection strategy (LIFO)
incorporate strategies discussed previous sections.
tested modified planner several problems ucpop suite, emphasizing
proved challenging previous strategies, artificial problems
due Kambhampati et al. (1995), trains transportation domain developed
Rochester (Allen & Schubert, 1991; Allen et al., 1995), Joslin & Pollack's TileWorld
domain (Joslin & Pollack, 1994). brie describe test problems platforms
parameter settings used, present experimental results improved
search strategies.
6. 2. 3. zero-commitment choices. experiments, described next section,
sub-preference 3. gave improvements context Russell's tire changing domain (in particular
Fix3), without significant deterioration performance domains.

104

fiAccelerating Partial-Order Planners

3.1 Test Problems Experimental Settings

ucpop problems include Towers Hanoi (T H), Fixa, Fix3, Fixit, Tower-Invert4,
Test-Ferry, Sussman-Anomaly. case H, added 3-operator version
ucpop single-operator version, since H particularly hard problem ucpop
diculty long known sensitive formalization (e.g., (Green,
1969)). Fixa problem Dan Weld's \fridge domain", compressor
fridge exchanged, requiring unscrewing several screws, stopping fridge,
removing backplane, making exchange. Fix3 Stuart Russell's \ tire
domain", new wheel mounted lowered ground (the old wheel
jacked already nuts loosened); requires unscrewing nuts holding
old wheel, removing wheel, putting new wheel, screwing nuts, jacking
hub, tightening nuts. Fixit complicated, wheel yet
jacked initially nuts yet loosened, spare tire needs ated,
jack, wrench pump need taken trunk stowed
end. Tower-Invert4 problem blocks world, requiring topmost block stack
four blocks made bottom-most. Test-Ferry simple problem requiring two cars
moved B using one-car ferry, boarding, sailing, unboarding
car.
artificial problems correspond two parameter settings ART-# -# , one
two artificial domains served testbed Kambhampati et al.'s extensive
study behavior various planning strategies function problem parameters
(Kambhampati et al., 1995). ART-# -# provides two layers 10 operators each,
layer 1 achieve preconditions layer 2, operator
layer 2 achieves one 10 goals. However, operators layer establish
clobber preconditions neighbors, force operators used
certain order.
version trains domain encoded involves four cities (Avon, Bath,
Corning, Dansville) connected four tracks diamond pattern, fifth city (Elmira)
connected Corning fifth track. available resources, located various
cities, consist banana warehouse, orange warehouse, orange juice factory, three
train engines (not coupled cars), 4 boxcars (suitable transporting oranges
bananas), tanker car (suitable transporting orange juice). Goals typically
deliver oranges, bananas, orange juice city, requiring engine-car coupling, car
loading unloading, engine driving, possibly OJ-manufacture.
TileWorld domain consists grid holes tiles scattered. given
tile may may fit particular hole. goals fill one holes
using three possible actions: picking tile, going x-y location grid,
dropping tile hole. agent carry four tiles time.
Formalizations domains terms ucpop's language provided Online
Appendix 2. experiments problems except Fixit, trains problems
TileWorld problems conducted sun 10 using Lucid Common Lisp 4.0.0,
rest (Tables X{XI next subsection) conducted sun 20 using Allegro
Common Lisp 4.2. Judging repeated experiments, think
est

est

clob

105

clob

fiGerevini & Schubert

Goal-selection Plan-selection CPU sec
LIFO
LIFO
ZLIFO
ZLIFO

S+OC+UC
S+OC
S+OC+UC
S+OC

204.51
0.97
6.90
0.54

Plans

160,911/107,649
751/511
1816/1291
253/184

Table I: Performance plan/goal selection strategies T-of-H1
differences platforms significantly impact performance improvements.7 Among
search control functions provided ucpop, used default bestf-search
problem solvable within search limit 40,000 plans generated, used
function id-bf-search (an implementation linear-space best-first search algorithm
given Korf, 1992), limit exceeded.8 experiments delayseparation switch, *d-sep*, on, except using LCFR strategy.

3.2 Experimental Results ZLIFO S+OC

Tables I{XI show CPU time (seconds) number plans created/explored
ucpop twelve problems domains described above: Towers Hanoi three
disks either one operator (T-of-H1) three operators (T-of-H3), fridge domain
(Fixa), tire changing domain (Fix3 Fixit), blocks world (Tower-Invert4
Sussman-anomaly), ferry domain (Test-Ferry), artificial domain ART-# -#
(specifically, ART-3-6 ART-6-3), trains domain (Trains1, Trains2 Trains3)
TileWorld domain (tw-1, ..., tw-6). number plans created/explored
CPU time important performance measures. number plans, indicates
search space size, stable measure sense depends search
algorithm, implementation.9 time still interest since improvement
search may purchased price time-consuming evaluation
alternatives. turns pay price overhead substitute
strategies defaults (factors ranging 1.2 1.9, rarely higher, per plan
created). may due slightly greater inherent complexity ZLIFO versus LIFO,
think differences could reduced substituting modified data structures
ucpop { committed altering these.
Tables II show H plan selection strategy S+OC gives dramatic
improvements default S+OC+UC strategy. (In tests default LIFO goal
selection strategy used.) fact, ucpop solved T-of-H1 0.97 seconds using S+OC
versus 204.5 seconds using S+OC+UC. T-of-H3 proved harder solve T-of-H1, reest

clob

7. differences result available different times locales course
nearly two years experimentation.
8. choice motivated observation problem relatively easy solve
bestf-search appears ecient id-bf-search, hard problems
inecient considerable amount space used run time CPU time spent
garbage collection, cases made Lisp crash, reporting internal error.
9. also worth noting number plans created implicitly takes account plan size, since
addition step plan counted creation new plan ucpop.

106

fiAccelerating Partial-Order Planners

Goal-selection Plan-selection CPU sec Plans
LIFO
S+OC+UC
> 600 > 500,000
LIFO
ZLIFO
ZLIFO

S+OC
S+OC+UC
S+OC

8.54

> 600
1.24

5506/3415
> 500,000
641/420

Table II: Performance plan/goal selection strategies T-of-H3

Goal-selection Plan-selection CPU sec
LIFO
LIFO
ZLIFO
ZLIFO

S+OC+UC
S+OC
S+OC+UC
S+OC

2.45
2.48
0.33
0.33

Plans

2131/1903
2131/1903
96/74
96/74

Table III: Performance plan/goal selection strategies Fixa
quiring 8.5 seconds using S+OC unknown time excess 600 CPU seconds using
S+OC+UC.
ZLIFO goal-selection strategy significantly accelerate planning compared
simple LIFO strategy. particular, ZLIFO combined S+OC planselection strategy solving H, reduced number plans generated
factor 3 T-of-H1 factor 8 T-of-H3. overall performance improvement
T-of-H1 thus factor 636 terms plans created factor 379 terms
CPU time (from 204.5 0.54 seconds).
Tables III{VIII provide data problems easier H, still challenging ucpop operating default strategy, namely Fixa (Table III), Fix3 (Table IV),
Tower-Invert4 (Table V), Test-Ferry (Table VI) artificial domain ART-# -#
# = 3 # = 6 (Table VII) # = 6 # = 3 (Table VII).
results show combination S+OC ZLIFO substantially improves
performance ucpop comparison performance using S+OC+UC LIFO.
number plans generated dropped factor 22 Fixa, factor 5.9
est

est

clob

est

Goal-selection Plan-selection CPU sec
LIFO
LIFO
ZLIFO
ZLIFO

S+OC+UC
S+OC
S+OC+UC
S+OC

6.50
0.43
1.12
1.53

clob

Plans

3396/2071
351/215
357/221
574/373

Table IV: Performance plan/goal selection strategies Fix3

107

clob

fiGerevini & Schubert

Goal-selection Plan-selection CPU sec Plans
LIFO
LIFO
ZLIFO
ZLIFO

S+OC+UC
S+OC
S+OC+UC
S+OC

1.35
0.19
2.81
0.36

808/540
148/105
571/378
142/96

Table V: Performance plan/goal selection strategies Tower-Invert4

Goal-selection Plan-selection CPU sec Plans
LIFO
LIFO
ZLIFO
ZLIFO

S+OC+UC
S+OC
S+OC+UC
S+OC

0.63
0.32
0.24
0.22

718/457
441/301
136/91
140/93

Table VI: Performance plan/goal selection strategies Test-Ferry

Goal-selection Plan-selection CPU sec
LIFO
LIFO
ZLIFO
ZLIFO

S+OC+UC
S+OC
S+OC+UC
S+OC

.67
1.36
0.16
0.18

Plans

568/392
1299/840
72/49
79/54

Table VII: Performance plan/goal selection strategies ART-# -#
# = 6 (averaged 100 problems)
est

clob

# = 3
est

clob

Goal-selection Plan-selection CPU sec
LIFO
LIFO
ZLIFO
ZLIFO

S+OC+UC
S+OC
S+OC+UC
S+OC

1.32
2.08
0.14
0.14

Plans

985/653
1743/1043
57/37
57/37

Table VIII: Performance plan/goal selection strategies ART-# -#
# = 3 (averaged 100 problems)
est

clob

# = 6

clob

Goal-selection Plan-selection CPU sec Plans
LIFO
LIFO
ZLIFO
ZLIFO

S+OC+UC
S+OC
S+OC+UC
S+OC

0.06
0.04
0.12
0.07

44/26
36/21
67/43
41/25

Table IX: Performance plan/goal selection strategies Sussman-anomaly
108

est

fiAccelerating Partial-Order Planners

1000

Fixit
Trains1
2

T-of-H1 2

Performance
Improvement

2

100

2
ART-6-3 2 Fixa
2 Search space reduction
ART-3-6 222
2 Fix3
Speedup
Tower-invert4
Test-ferry
Sussman-anomaly
2
1e+07
100
1000
10000 100000 1e+06
Problem size

10
1
10

Figure 1: Performance improvement due ZLIFO S+OC, relative number
plans generated LIFO S+OC+UC (log-log scale). improvements
problems ucpop unable solve even high search limit
(Trains2, Trains3, T-of-H3) included.
Fix3, factor 5.7 Tower-Invert4, factor 5.1 Test-Ferry, factor 7
ART-3-6, factor 17 ART-6-3.
Concerning ART-# -# , note performance obtained unenhanced
ucpop (568 plans generated ART-3-6 985 ART-6-3) much
(just marginally better than) reported Kambhampati et al. (1995) best planners
considered (700 { 1500 plans generated ART-3-6, 1000-2000 ART-6-3).
expected, since ucpop generalization earlier partial-order planners.
Relative standard ucpop predecessors, \accelerated" planner thus order
magnitude faster. Interestingly, entire improvement ascribed ZLIFO
(rather S+OC plan selection, actually little worse S+OC+UC).
probably due unusual arrangement operators ART-# -# \clobbering chain" (A , 1 clobbers , ,1 1 's preconditions, ..., A1 1 clobbers A0 1's preconditions;
similarly 2 ), makes immediate attention new unsafe conditions unusually
good strategy.
experimenting various combinatorially trivial problems unmodified ucpop
handles ease, found S+OC ZLIFO strategy neither beneficial
harmful general; may slight improvement slight degradation performance. Results Sussman anomaly Table IX provide illustrative example.
summarize results Tables I{X Figure 1, showing performance improvements obtained combined ZLIFO goal selection strategy S+OC plan selection
est

clob

est

n

;

n

;

;

i;

109

clob
;

fiGerevini & Schubert

ZLIFO &
S+OC
LC &
S+OC
LCFR &
S+OC
LIFO &
S+OC+UC

Trains1

Trains2

Trains3

Fixit

Plans
4097/2019
17,482/10,907 31,957/19,282
5885/3685
Time
13.7
80.6
189.8
32.5
Plans
438/242
34,805/24,000 253,861/168,852
71,154/46,791
Time
2.6
368.9
1879.9
547.8
Plans
1093/597
>1,000,000
>1,000,000
190,095/117,914
Time
10.65
>10,905
>9918
4412.36
Plans 1,071,479/432,881 > 10,000,000
> 1,000,000 8,090,014/4,436,204
Time
3050.15
> 37,879
> 2539
27,584.9

Table X: Performance plan selection strategy S+OC combination goal
selection strategies ZLIFO, LCFR LC solving problems
hard default strategies ucpop (S+OC+UC/LIFO). (The CPU seconds
include Lisp garbage collection. number plans generated LCFR
include created order estimate repair cost aws.)

Problem
ZLIFO*
LCFR
name CPU time Plans CPU time Plans
tw-1
tw-2
tw-3
tw-4
tw-5
tw-6

0.09
0.61
2.55
7.80
19.41
42.57

26/15
72/39
138/71
224/111
330/159
456/215

0.10
0.66
3.17
10.97
30.17
71.10

26/15
72/39
139/72
227/114
336/165
466/225

Table XI: Performance UCPOP TileWorld domain using ZLIFO* LCFR
goal selection, S+OC+F+0.1UC plan selection
strategy function problem diculty (as indicated number plans generated
default LIFO plus S+OC+UC strategy). trend toward greater speedups
complex problems (though somewhat dependent problem type) quite apparent
log-log plot.
direct comparison Joslin Pollack's LCFR strategy Peot Smith's
LC strategy, implemented strategies applied several problems.
well (sometimes better ZLIFO) problems lower end diculty
spectrum, poorly harder problems. (For problems ran, LC
*d-sep* switch performed better LCFR terms plans explored CPU
time required.) T-of-H1 LCFR combination default S+OC+UC plan
selection strategy, S+OC plan strategy find solution within search
limit 200,000 plans generated (cf. 253 ZLIFO S+OC, 751 ZLIFO
S+OC+UC), requiring unknown CPU time excess 4254 seconds S+OC+UC,
110

fiAccelerating Partial-Order Planners
excess 4834 seconds S+OC (cf. 0.54 seconds ZLIFO S+OC).10
LC performed much better LCFR still considerably worse ZLIFO, solving
T-of-H1 generating/exploring 8313/6874 plans S+OC 8699/6441 plans
S+OC+UC, requiring 44.4 CPU secs. 48.95 CPU secs. respectively. T-ofH3, LC found solution generating/exploring 21,429/15,199 plans S+OC+UC
17,539/14,419 plans S+OC, requiring 145.18 CPU secs. 77.84 CPU secs.
respectively.
Table X shows results plan strategy S+OC, goal strategies ZLIFO,
LCFR LC, applied three problems (Trains1, Trains2 Fixit). shown data
table hard default strategies ucpop (LIFO & S+OC+UC),
become relatively easy S+OC used combination either ZLIFO, LCFR
LC. LCFR LC slightly better ZLIFO Trains1 (the easiest
problems), performed quite poorly Fixit, Trains2 Trains3 (the hardest
problems) compared ZLIFO.
Joslin Pollack (1994) tested LCFR strategy six problems TileWorld
(tw-1, ..., tw-6), five hard default ucpop, easy ucpop using
LCFR.11 tested ZLIFO strategy TileWorld using six problems.
ZLIFO well tw-1{4, tw-5 tw-6 performance dropped well
LCFR. raised question whether particular problems crucial
minimize \repair cost" aw selection uniformly, rather certain special cases
(ZLIFO minimize repair cost threat aw list, least one zerocommitment open condition present). However, experiments aimed answering
question suggested poor choices made ZLIFO TileWorld problems
due selection \high cost" \low cost" aws. Instead two factors appear
crucial improving ZLIFO: (a) emphasizing zero-commitment open conditions giving
higher priority threats; (b) zero-commitment open conditions,
resolving threats soon enter agenda. (We realized relevance (b)
observing performance modified versions LCFR, *d-sep* switch
implicitly forced on, dramatically degraded tw-6 slightly different formulation
TileWorld.)
extended ZLIFO strategy include (a) (b), brie tested
resulting variant ZLIFO (ZLIFO*). Table XI shows results ZLIFO* together
plan selection strategy S+OC+0.1UC+F, discussed Section 2.3 included
attenuated form UC term (UC/10), F term equal number facts
since TileWorld uses facts track number tiles carried agent.12 ZLIFO*
10. *d-sep* turned off, implicit setting LCFR (Joslin, 1995). experiments
also tested variant LCFR, switch forced on. resulting goal strategy
combination plan strategy S+OC performed significantly better T-of-H1, solving problem
generating/exploring 7423/6065 plans, using 110.45 CPU seconds. Note also comparison
implementation LCFR Joslin & Pollack's implementation used experiments discussed
(Joslin & Pollack, 1994) showed implementation considerably faster (Joslin, 1995).
11. experiments tw-2, easiest among tw-2{6, solved ucpop even allowed run
eight hours. hand, ucpop using LCFR solves tw-6, hardest problem, without
ever reaching dead-end node search tree.
12. ZLIFO* experiments refined plans generated resolving threat added aw list
following order: first plan generated promotion, plan generated demotion,
finally plan generated confrontation separation.

111

fiGerevini & Schubert
performed eciently six TileWorld problems, fact little better LCFR.
Note problems ZLIFO* ecient LCFR terms CPU time,
even though number plans generated/explored two strategies approximately
same. overhead selecting next aw handled higher
LCFR ZLIFO* (and ZLIFO). fact, LCFR needs compute \repair
cost" aw (including threats) current plan, ZLIFO* (ZLIFO) needs
check presence zero-commitment open conditions, without processing threats.
Additional experiments indicated average performance ZLIFO* comparable
ZLIFO problems used experiments, terms
plans created/explored. However, CPU time tends increase since overhead
computing goal selection function higher ZLIFO* ZLIFO,
extra agenda-management costs. overhead, regard ZLIFO*
generally preferable ZLIFO. However, TileWorld experiments underscored us
worlds refinements ZLIFO advantageous.
Finally, another possible variant ZLIFO, suggested us David Smith,
based following preferences next aw handled: (i) threat cannot
resolved; (ii) open condition cannot established; (iii) threat
one possible resolution; (iv) open condition established one way; (v)
threats; (vi) open conditions (using LIFO pick among these). observe
strategy could give savings terms plans created/explored,
also imposes additional overhead respect ZLIFO ZLIFO* could
degrade performance terms CPU time.

4. Precomputing Parameter Domains

Even speedups obtained improved search, ucpop-like algorithm remains
severely limited complexity problems solve. believe significant
progress requires fuller use global properties search space, determined
structure operators, initial conditions, goals. One way would
in-depth analysis alternatives search, lead high
overhead costs. Another precompute constraints search space, use
planning prune search. parameter domain method motivate
describe latter type.

4.1 Parameter Domains Help?

previous experimentation ucpop strategies, found ucpop goal regression often hypothesized steps doomed abandoned eventually,
stipulated impossible parameter bindings. clear example occurred Molgen
domain, encoded ucpop test suite. goal \Rat-insulin" test problem
(and (bacterium ?b) (molecule ?m)
(contains IG ?m) (contains ?m ?b) (pure ?b))

,

?b ?m existentially quantified variables. means wish
create purified bacterial culture ?b, ?b contains molecule ?m (necessarily
112

fiAccelerating Partial-Order Planners
exosome, turns out), molecule turn contains insulin gene, IG.
using abbreviations IG, EE, JE, L insulin-gene, e-coli-exosome, junk-exosome,
linker; E, J, A1 e-coli, junk, antibiotic-1. Roughly speaking, solution
involves processing initially given mRNA form insulin gene produce
form insulin DNA spliced e-coli-exosome, using ligate operator.
turn, exosome inserted e-coli bacterium using transform operator,
bacterial culture purified using screen operator, antibiotic-1. (The junk
bacterium exosome merely serve complicate task { nearly, quite,
substitutable e-coli bacterium exosome; junk exosome, unlike e-coli-exosome,
resistant antibiotic-1, violating precondition screen.)
Now, initial regression goals (bacterium ?b) (molecule ?m)
established *start* operator, i.e., initial conditions, thus
instantiated bizarre values. (The initial conditions supply E J
instances bacterium, IG, EE, JE, L instances molecule.)
hand, remaining goals turn match effects various instances
ligate, transform, screen operators Molgen, follows:
(contains IG ?m): (ligate IG ?m), (transform IG ?m)
(contains ?m ?b): (ligate ?m ?b) (transform ?m ?b)
(pure ?b):
(screen ?b ?y ?z)

,

ucpop happily regress actions. Yet two them,

(transform IG ?m)
doomed fail, perhaps great deal effort expended
trying satisfy preconditions. particular, examination constants
\ ow into" transform operator initial conditions Molgen operators
shows first argument restricted domain fEE, JEg, i.e., must one
given exosomes, second restricted fE, Jg, i.e., must one
given bacteria. Consequently instance (transform IG ?m) unrealizable, first
argument IG fEE, JEg. (Note distinct constants denote distinct entities
according unique-names assumption made ucpop.) (ligate ?m ?b) action
doomed slightly subtle reasons. result match (contains ?m
?b) \when-clause" (conditional effect) ligate operator, whose preconditions
reached second parameter ?b lies set molecules fIG, JE, EEg;
yet ?b also restricted set bacteria fE, Jg, result goal condition
(bacterium ?b). fact sets disjoint allow us eliminate
(transform IG ?m) action.
Note elimination action candidates increases number zero commitment plan refinements made. example, left exactly one
action three goals, ZLIFO LCFR strategies prefer
regress goals rather regressing (bacterium ?b) (molecule ?m) {
would prematurely make arbitrary choices ?b ?m initial state.
(ligate ?m ?b),

4.2 Description Algorithm

completed plan, precondition action must instantiated effect
earlier action. values parameters action values
113

fiGerevini & Schubert
\produced" earlier actions, starting initial action, *start*. Moreover,
suppose parameter x certain action occurs preconditions P1, ..., Pk.
constant c possible value x earlier actions instantiate x c
P1, ..., Pk.
algorithm find-parameter-domains based observations. Beginning
initial state, propagates positive atomic predications possible operator preconditions. propagated ground atom, atom matches operator precondition,
algorithm adds constants ground atom individual domains
parameters unified with. individual domains particular specific preconditions. instance, individual domain ?x operator preconditions
(on ?x ?y), (clear ?x) general distinct two preconditions.
soon nonempty individual domains parameters preconditions
operator, form intersection individual domains parameter
operator. example, (on ?x ?y) (so far) matched (on B)
(on B C), (clear ?x) (so far) matched (clear A) (clear Table),
individual domain x fA,Bg first precondition fA,Tableg
second. Thus (assuming preconditions) intersected domain
?x fAg point. later (clear B) also matched (clear ?x),
intersected domain ?x grow fA,Bg. ?x ?y nonempty
intersected domains, effects (postconditions) operator turn propagated,
?x ?y \bound" intersected domains.
propagated effects matched possible operator preconditions,
variable \bound" intersected domain successfully unified variable precondition, passes intersected domain individual domain
precondition-variable (via union operation). lead growth intersected domains operator whose precondition matched, effects operator
may propagated, on. individual domains intersected domains grow
monotonically propagation process, end represent desired parameter domains operators.
illustrate process example. Consider simple planning problem
depicted Figure 2 \operator graph" (Smith & Peot, 1993) used describe
logical dependencies among operators, iterative computation parameter
domains graphically illustrated \domain-propagation graph" operator
graph.
initial conditions (P A) (P B) unify precondition (P ?x) op1. So,
individual domain ?x relative precondition P op1 fA,Bg.
hand, precondition (Q ?x) op1 cannot satisfied initial state,
individual domain ?x relative Q initially empty set. Hence intersected domain
?x op1 also empty set.
op2 different situation, since one precondition
established initial state. Therefore, individual domain ?y relative
precondition R op2 set constants fB,Cg, intersected domain ?y
op2 set (because R precondition op2 involving ?y). Since
intersected domain ?y enlarged (initially empty), propagated
individual domains operators effect (Q ?y) op2. particular,
114

fiAccelerating Partial-Order Planners

(P ?x)

indicates bundle edges
op1

(Q ?x)
(T B)

*start*
(R ?y)

*end*

op2
Init state: (P A),(P B),(R B),(R C),(S C)
(S ?z)

op1:

preconds: (P ?x),(Q ?x)

Goal: (T B)

op3
op2:

preconds: (R ?y)

op3:

preconds: (S ?z)
effects: (T ?z)

effects: (Q ?y)

effects: (S ?x)

(P A)
(P ?x)
(Q ?x)

id(?x)={B}

id(?x)={}
op1

(P B)

(Q ?x)

op1
ID(P,?x)={A,B}
ID(Q,?x)={B,C}

ID(P,?x)={A,B}
ID(Q,?x)={}
(Q ?y)
id(?y)={B,C}

(R B)
(R ?y)
(R C)

(S ?x)

op2
ID(R,?y)={B,C}

id(?z)={A}
S(A)

(S ?z)

id(?z)={A,B}

op3

(S ?z)

ID(S,?z)={A}

op3
ID(S,?z)={A,B}

Figure 2: Operator domain-propagation graphs simple planning problem.
ID(?x,P) indicates individual domain parameter ?x relative precondition P; id(?x) indicates intersected domain parameter ?x; final
intersected domains indicated using bold fonts.
matches precondition (Q ?x) op1. So, individual domain ?x relative
precondition Q op1 updated adding constants intersected domain ?y
it. Thus intersected domain ?x enlarged fBg, propagated
effect (S ?x) op1.
Similarly, propagation (S ?x) enlarge individual domain ?z op3,
also intersected domain, set fA,Bg. Therefore, final intersected domains
are: fBg ?x op1; fB,Cg ?y op2; fA,Bg ?z op3.
presenting algorithm little formally, note parameter domains sometimes \too large", including values would found impossible
(Q ?y)

115

fiGerevini & Schubert
detailed state space exploration conducted. However, required
soundness use domains \too small" (i.e.,
contain parameter values actually occur problem consideration).
course, practical use parameter domains operator exclude
constants occurring problem specification, particularly
intuitively obvious wrong sort fill particular argument slots
operator. turned case problem domains far
experimented with.
preceding sketch method oversimplification since preconditions
effects ucpop operators may particular when-clause. case compute
individual domains intersected domains separately when-clause. example,
consider following schematic representation operator:
(define (operator op1)
:parameters (?x ?y)
:precondition (and P1 P2)
:effect (and E1 E2
(when 0 0)
(when " ") )),

PE
P E

conditions starting P E denote atomic formulas may involve ?x ?y.
think operator consisting primary when-clause whose preconditions
P1 P2 must always satisfied whose effects E1 E2 always asserted,
two secondary when-clauses whose respective preconditions P 0 P " may may
satisfied, are, corresponding effects E 0 E " asserted.
algorithm would maintain individual domains ?x ?y preconditions
P1, P2, P 0 , P ", would maintain intersected domains ?x ?y
primary when-clause two secondary clauses. intersected domains
secondary clauses would based individual domains ?x ?y
relative P 0 P ", also relative P1 P2, since (as noted) primary
preconditions must hold operator effects, including conditional
effects.
complications arise ucpop operators contain universally quantified preconditions effects, disjunctive preconditions, facts (mentioned Section 2.2).
Rather dealing complications directly, assume operators occur input algorithm. Later describe semi-automated way
handling operators containing additional constructs.
algorithm outlined (a detailed description given Online Appendix 1). W list (names of) when-clauses whose effects propagated.
Individual parameter domains initially nil, intersected parameter domains initially either nil (where universal domain). intersected domain
parameter, relative given when-clause, case parameter occurs neither
preconditions when-clause primary preconditions. (In case
successful instantiation when-clause clearly independent choice value
parameter question.) Unification step 2(a) usual, except
effect variable v unified constant c precondition, unification succeeds,
116

fiAccelerating Partial-Order Planners
unifier v = c, case c element intersected domain v (for relevant when-clause). given inits (initial conditions) goals (which may omitted,
i.e., nil) treated operator *start* preconditions operator *end*
effects. Variables goals treated like operator parameters. use terms
\parameters" \variables" interchangeably here.
Algorithm: find-parameter-domains(operators,inits,goals)
1. Initialize W initial conditions, contains (primary) when-clause
*start*.
2. Repeat steps (a{c) W = nil:
(a) Unify positive effects when-clauses W possible operator
preconditions, mark preconditions successfully matched way
\matched". (This marking permanent.) Augment individual domain
matched precondition variable certain set C constants, defined
follows. precondition variable unified constant c, C = fcg;
unified effect variable, C intersected domain
effect variable (relative when-clause effect belongs).
(b) Mark when-clauses \propagation candidates" preconditions (including corresponding primary preconditions) marked \matched"
involve least one variable relevant individual domain
augmented step (a).
(c) Reset W nil. when-clauses propagation candidates, compute
new intersected domains variables. intersected domain whenclause thereby enlarged, intersected domains when-clause
nonempty, add when-clause W.
3. restrict intersected domains using equative preconditions form (EQ u v),
i.e., form common intersected domain u v variables. u
constant v variable, reduce intersected domain v intersecting
fug; similarly u variable v constant. equation belongs
primary when-clause, use reduce intersected domains u v (whichever
variables) secondary clauses well.
4. Return intersected domains parameter domains, producing sequence
lists list form
(op (x1 a1 b1 c1 :::) (x2 a2 b2 c2 :::) :::),
operator op appears least once. op k conditional effects,
k + 1 successive lists headed op, first provides parameter
domains primary effects op rest provide parameter domains
conditional effects (in order appearance ucpop definition op).
Note match propagate negative conditions. problem negative
conditions large number may implicit initial conditions, given
117

fiGerevini & Schubert
use Closed World Assumption ucpop. instance, world n blocks,
O(n) on-relations (assuming block one block),
necessarily O(n2 ) implicit (not (on ...)) relations. fact, individual variable
domains negative preconditions goals really infinitely large. instance, given
empty initial state (paint-red ?x) operation precondition (not (red ?x))
effect (red ?x), achieve (red c) infinitely many constants c. Perhaps
negative conditions could effectively dealt maintaining anti-domains them,
explored since practice ignoring negative conditions seems cause
minimal \domain bloating". (We proved actual domain elements
lost neglect preconditions.)
use EQ-conditions could refined making use propagation
process, NEQ-conditions could also used. However, would probably
marginal impact.
final comment, note output format specified step 4 algorithm
actually generalized implementation report inaccessible preconditions
goals. inaccessible conditions simply appended list parameter
domains appropriate when-clause appropriate operator. instance,
preconditions (oj ?oj) (at ?oj ?city) ld-oj (\load orange juice") operator
trains world (see Online Appendix 2) unreachable (say, oranges
producing orange juice provided), parameter domain list (unique)
when-clause ld-oj appearance
(ld-oj (?oj ...) (?car ...) (?city ...) (oj ?oj) (at ?oj ?city)).
feature turns useful debugging operator specifications detecting
unreachable goals.

4.3 Correctness Tractability

keeping remarks previous section, call algorithm computing
parameter domains correct domains computes subsume possible parameter values
actually occur (in given primary secondary when-clause) consider
possible sequences operator applications starting given initial state.
point property maintain soundness planning algorithm
uses precomputed parameter domains prune impossible actions (as well spurious
threats) partially constructed plan. assert following:

Theorem 1 find-parameter-domains algorithm correct computing parameter

domains ucpop-style sets operators (without quantification, disjunction, facts),
initial conditions, (possibly) goal conditions.
proof given Appendix A. preliminary step establish termination, using
monotonic growth domains finiteness set constants involved. Correctness
established showing exists valid sequence A0 A1 :::A actions
(operator instances) starting A0 = *start*, instance operator
Op, bindings parameters Op received instance eventually added
relevant intersected domains Op (where \relevant" refers when-clauses Op
whose preconditions satisfied beginning ). proved induction n.
n

n

n

n

118

fiAccelerating Partial-Order Planners
indicate deal universally quantified preconditions effects,
disjunctive preconditions, facts. make simple changes operator definitions
hand preparation parameter domain precomputation, use domains
computed find-parameter-domains, together original operators, running
planner. steps preparing operator parameter domain precomputation
follows:
Delete disjunctive preconditions, fact-preconditions,13 universally quantified preconditions (this includes universally quantified goals; would also include universally
quantified sentences embedded within antecedents when-clauses, e.g.,
manner (:when (:forall (?x) ) ), though occur problem
domains seen).
Drop universal quantifiers occurring positively operator effects, i.e., occurring
top level embedded one :and's. example, effect
(:and (at robot ?to)
(:not (at robot ?from))
(:forall (?x)
(:when (:and (grasping ?x) (object ?x))
(:and (at ?x ?to) (:not (at ?x ?from))) )))

would become

(:and (at robot ?to)
(:not (at robot ?from))
(:when (:and (grasping ?x) (object ?x))
(:and (at ?x ?to) (:not (at ?x ?from))) )))

Note universally quantified variable renamed, necessary,
distinct variables operator parameters.
example universally quantified variable unrestricted.
quantified variable includes type restriction, (:forall (object ?x) ),
type restriction needs become antecedent matrix sentence .
example hand, rewritten equivalent (:when (object ?x)
). Since often when-clause, done adding (object ?x)
conjunct antecedent when-clause. cases conjunction
when-clauses, case quantifier restriction added
when-clause antecedent.
Drop existential quantifiers preconditions goals, adding restrictions
quantified variables conjuncts matrix sentence. example, goal
(:exists (bacterium ?y)
(:exists (molecule ?x)
(:and (contains IG ?x)
(contains ?x ?y)
(pure ?y) )))

13. E.g., strips-world would drop (fact
given coordinates lie given room.

(loc-in-room ?x ?y ?room)),

119

checks whether

fiGerevini & Schubert
becomes
(:and (bacterium ?y) (molecule ?x) (contains IG ?x)
(contains ?x ?y) (pure ?y) )

(Actually, :and dropped well, supplying goals find-parameterdomains.)
reductions, find-parameter-domains compute correct parameter
domains operators goals. see this, note first dropping preconditions (in initial step above) forfeit correctness, since
weaken constraints admissible parameter values, thus add constants
domains. effect dropping universal quantifier, perspective
find-parameter-domains, introduce new parameter place universal variable. (The operator normalization subroutine detects variables operator preconditions
effects listed parameters, treats additional parameters.)
course drastic change meaning operator, preserves correctness parameter domain calculation. domain new parameter
certainly contain constants (and hence, Closed World Assumption, objects) quantified variable ranges. example, ?x treated parameter
rather universally quantified variable conditional effect
(:forall (?x) (:when (object ?x) (in ?x box))),
domain ?x when-clause consist everything object,
state operator applied. Thus effect (in ?x box) also propagated objects, required. Finally, elimination existential quantifiers
preconditions goals seen preserve meaning preconditions
goals, hence preserves correctness parameter domain calculation.
Next formally state tractability claim algorithm, follows (with
tacit assumptions, mentioned proof).
Theorem 2 Algorithm find-parameter-domains implemented run O(mn n (n +
n )) time O(mn ) space worst case, number constants
problem specification, n combined number preconditions operators (and
goals, included), n combined number operator effects (including
*start*).
proof Appendix A. time complexity find-parameter-domains
determined sum (1) cost unifications performed, (2) costs
individual domain updates attempted, (3) cost intersected domain
updates attempted. space complexity bound easily derived assuming
fixed upper bound number arguments predicate (in precondition
effect) have, fact when-clause O(m) constants
stored.
adding additional data structures find-parameter-domains obtain
version algorithm whose worst-case time complexity slightly improved. fact,
step 2.(c) instead propagating effects when-clause enlarged
p

e

p

p

e

120

e

p

fiAccelerating Partial-Order Planners
intersected domain (i.e., adding when-clause list W), sucient propagate
effects when-clause involve enlarged intersected-domain. could
done setting when-clause table maps parameter list
effects (of when-clause) involving parameter.
improved algorithm use W store list effects (instead list whenclauses) propagated next cycle algorithm, steps 1, 2
find-parameter-domains modified following way:
10. Initialize W list effects *start*.
20. Repeat steps (a{c) W = nil:
(a0) Unify positive effects W possible operator preconditions, mark
preconditions successfully matched way \matched" ...
0
(b ) 2.(b).
(c0) Reset W nil. when-clauses propagation candidates, compute new intersected domains variables. intersected domain
when-clause thereby enlarged, intersected domains when-clause
nonempty, add W subset effects when-clause
involving least one parameter whose intersected domain enlarged.
Note worst-case time complexity revised algorithm improved,
effect when-clause propagated O(m) times. decreases upper
bound number unifications performed, reducing complexity estimated step
(1) proof Theorem 2 O(mn n ). Hence proved following corollary.
e

p

Corollary 1 exists improved version find-parameter-domains
implemented run O(mn2 n ) time worst case.
p

e

5. Using Parameter Domains Accelerating Planner

already used example Molgen motivate use precomputed parameter
domains planning, showing domains may allow us prune non-viable actions
partial plan.
fundamentally, used time planner needs unify two predications involving parameter, either goal regression threat detection. (In
either case, one predication (sub)goal effect action
initial condition.) unifier inconsistent parameter domain, count
failure even consistent binding constraints current (partial)
plan. inconsistency, use unifier intersect thus refine
domains parameters equated unifier.
example, suppose G = (at ?x ?y) precondition step current
plan, E = (at ?w ?z) effect another (possibly new) step, ?x, ?y,
?w ?z parameters (or, case ?w ?z, existentially quantified variables)
binding constraints associated current plan. Assume also
domains parameters are:
121

fiGerevini & Schubert
?x : {Agent1, Agent2, Agent3}
?w : {Agent1, Agent2}

?y : {City1, City2}
?z : {City3, City4}

unification G E gives binding constraints f?x = ?w, ?y = ?zg,
viable parameter domains ?y ?z empty intersection.
hand, domain ?z fCity2, City3, City4g, unification G E would judged viable, domains parameters would
refined to:
?x : {Agent1, Agent2}
?w : {Agent1, Agent2}

?y : {City2}
?z : {City2}

Thus parameter domains incrementally refined planning search progresses;
narrower become, often lead pruning.

5.1 Incorporating Parameter Domains UCPOP

preceding consistency checks domain refinements used partial-order,
causal-link planner like ucpop follows. Given goal (open condition) G selected
ucpop next aw repaired,
(1) restrict set new operator instances ucpop would use establishing G;
instance operator effect E (matching G) disallowed precomputed
parameter domains relevant E incompatible current parameter domains binding constraints relevant G; (note current parameter domains
associated G may refinements initial domains);
(2) restrict set existing steps ucpop would reuse establishing G; reusing
step effect E (matching G) disallowed current parameter domains relevant
E incompatible current parameter domains binding constraints
relevant G.
Moreover, given potential threat effect Q protected condition P, inspection
relevant parameter domains may reveal threat actually spurious.
happens unifier P Q violates (possibly refined) domain constraints
parameter P Q. Thus often
(3) reduce number threats generated planner new causal
link introduced plan (this happens open condition established
either reusing step introducing new one);
(4) recognize threat list aws processed redundant, allowing
elimination. (Note since parameter domains incrementally refined
planning, even use (3) generation threats, still possible
threat becomes spurious added aw list).
four uses parameter domains cut search space without loss viable
solutions, since options eliminated cannot lead correct, complete plan.
122

fiAccelerating Partial-Order Planners
Note (3) (4) useful even planner deals definite
threats (i.e., *d-sep* switch turned on) least three reasons. First, determining
threat definite threat *d-sep* incurs overhead cost. So,
earlier elimination spurious threat could lead considerable savings threat
delayed many times search. second reason relates plan-selection
strategies adopted. one uses function includes (attenuated) term corresponding
number threats currently aw list, eliminating spurious threats
advance give accurate measure \badness" plan. Finally, parameter
domains could used threat processing prune search even *dsep*
on. particular, suppose modify notion definite threat,
parameter domains, e.g., (P ?x) (not (P ?y)) comprise definite threat
parameter domains associated ?x ?y c. case, even
d-sep* on, may discover early threat become definite { case might
also forced threat, i.e., choice promotion demotion may dictated
ordering constraints; prune search space. However, current
implementation exploit third point.
incorporated techniques ucpop (version 2.0), along earlier
improvements plan goal selection strategies. Parameter domains handled
extension \varset" data structure (Weld, 1994) include domains
variables (parameters), extending unification process implement
filtering discussed above.14 describe experiments enhanced system.

5.2 Experimental Results Using Parameter Domains

main goal show overhead determined computing parameter domains significant (both preprocessing time planning time), exploitation parameter domains planning significantly prune search.
experiments used version find-parameter-domains described Section
4.2 Online Appendix 1. Note domains complex ones
considered might worthwhile use improved version algorithm discussed
Section 4.3. (However, remains seen whether problems significantly complex
consider solved ucpop-style planner.)
CPU times needed implementation find-parameter-domains negligible problems looked at. 10 msec less many problems
ucpop test suite (when running compiled Allegro CL 4.2 sun 20), 20 msec
two problems (Fixa fridge repair domain Fixit tire domain),
30msec trains world problems described below.
first set tests, relied search strategy used default ucpop.
function used A* plan selection thus S+OC+UC+F (allowing problems
involve \facts"), goals selected agenda according pure LIFO
discipline.15
14. current implementation new threats filtered protected condition established
step already plan.
15. experiments *d-sep* switch on. default delay-separation strategy selecting unsafe
conditions slightly modified version ucpop using parameter domains. particular,

123

fiGerevini & Schubert
began experimenting variety problems ucpop's test suite, comparing performance without use parameter domains. relatively easy
problems Sussman-anomaly, Fixa, Test-ferry, Tower-invert4 showed improvement use parameter domains, problems { particularly harder
ones { solved easily parameter domains. example, Rat-insulin
problem Molgen domain solved nearly twice fast, strips-world
problems (Move-boxes variants)16 Towers Hanoi (T-of-H1) solved
10 times fast. Note strips-world problems involve facts universally
quantified conditional effects. Two problems oce world, Oce5 Oce6,
knew readily solvable improved search strategy, remained dicult (in case Oce6, unsolvable) default ucpop strategy, despite use
parameter domains.17 experiments revealed source ineciency
default plan-selection strategy ucpop. fact, using S+OC+F strategy
instead S+OC+UC+F, without parameter domains Oce5 Oce6 solved generating/exploring 3058/2175 8770/6940 plans respectively; using parameter
domains plans numbered 1531/1055 2954/2204 respectively.
initial experiments suggested us promising application computed parameter domains would nontrivial problems involved variety types
entities relationships, significant amounts goal chaining (i.e., successive
action establishing preconditions next). perspective, trains world
struck us natural choice experimentation, additional advantage
design independently motivated research Rochester mixed-initiative
problem solving natural-language interaction. (Refer formalization
Online Appendix 2.) Recall Table X Trains1 problem extremely hard
unmodified ucpop, requiring 50 minutes generating million plans.
Running problem parameter domains produced solution 3.3 seconds
(with 1207 plans generated), i.e., 927 times faster.
Intuitively, use parameter domains constrain planning analogous using
type constraints parameters (although parameter domains also take account initial
conditions). interest see whether adding type constraints provide similar
eciency gains use parameter domains. first set experiments therefore
included T-Trains1, \typed" version Trains1; operators slightly changed
adding new preconditions stating types parameters involved. example,
operator uncouple augmented preconditions (engine ?eng)
(car ?car). problem also extremely hard unmodified ucpop, exceeding
search limit 1,000,000 plans generated requiring 2600 seconds.
parameter domains, solution obtained one second.
threats resolved separation recognized redundant use
parameter domains selected eliminated.
16. Move-boxes-2 differs slightly Move-boxes problem ucpop suite, goal (in-room
box2 rclk); Move-boxes-a differs slightly Move-boxes-2, initial state contains two
boxes.
17. Oce5 directly ucpop's test suite Oce6 minor variant Oce5. Oce5, persons
furnished checks made them, using check printer oce briefcase
picking checks bringing home. \Sam" \Sue" given persons, Oce6
added (person Alan) (person Smith) initial conditions.

124

fiAccelerating Partial-Order Planners

Problems

without domains
domains
Domain
Plans
CPU sec
Plans
CPU sec ratio
Trains1
1,071,479/432,881 3050.15
1207/824
3.29
0.425
T-Trains1
> 1,000,000
> 2335
404/296
0.98
0.425
Move-boxes
608,231/167,418 1024.04
5746/3253
18.8
0.705
Move-boxes-1
> 1,000,000
> 6165
1264/645
3.59
0.705
Move-boxes-2
13,816/3927
45.05
1175/587
2.66
0.705
Move-boxes-a
13,805/3918
46.11
1175/587
2.54
0.702
T-of-H1
160,911/107,649 204.51 17,603/12,250
37.5
0.722
Rat-insulin
364/262
0.36
196/129
0.19
0.714
Monkey-test1
96/62
0.12
75/46
0.11
0.733
Monkey-test2
415/262
0.61
247/149
0.50
0.529
Fix3
3395/2070
5.77
3103/1983
6.02
0.532
Oce5
809,345/500,578 1927.4 575,224/358,523 1556.8
0.625
Oce6
> 1,000,000
> 2730
> 1,000,000
> 2640 0.667
Tower-invert4
806/538
1.55
806/538
1.59
0.733
Sussman-anomaly
44/26
0.05
44/26
0.06
0.917
Fixa
2131/1903
2.2
2131/1903
2.34
1
Test-ferry
718/457
0.65
718/457
0.71
1

Table XII: Plans generated/visited CPU time (secs) standard ucpop
without parameter domains. ( result obtained sun 10
Lucid Common Lisp; others sun 20 Allegro Common Lisp.)
results indicate adding type constraints operator specifications
nearly effective use parameter domains boosting planning eciency.
discuss point context second set tests (below).
Table XII summarizes experimental results experiments used
default ucpop search strategy. table gives number plans generated/visited
planner CPU time (seconds) required solve problems.18 Note
use parameter domains gave dramatic improvements trains domain, also strips-world domain. rightmost column supplies \domain ratio"
data, metric hoped would predict likely effectiveness using parameter
domains. idea parameter domains effective extent
filter many parameter bindings reached chaining back individual
preconditions operator initial state. bindings found using
variant algorithm propagating intersected domains instead propagates unions
individual domains, comparing union domains intersected domains.19
18. systems compiled Allegro CL 4.2, settings (space 0) (speed 3) (safety 1) (debug
0), run sun 20. CPU time includes Lisp garbage collection (it time given
output ucpop).
19. Actually, need explicitly propagate union domains, propagate (partial) bindings
one predication time, starting initial conditions. match predication possible
preconditions, adding constant arguments contains union domains matched operator

125

fiGerevini & Schubert

trains
without domains
domains
Domain
problems
Plans
CPU sec
Plans
CPU sec ratio
Trains1
4097/2019
13.7
297/238
1.4
0.425
Trains2 17,482/10,907 80.6 1312/1065 7.16
0.425
Trains3 31,957/19,282 189.8 3885/3175 25.1
0.411
Table XIII: Plans generated/visited CPU time (secs) ucpop without
parameter domains trains domain using ZLIFO strategy.

trains without domains
domains
Domain
problems Plans CPU sec Plans CPU sec ratio
Trains1 1093/597
8.1
265/194
2.3
0.425
Trains2 >50,000 >607 >50,000 >534
0.425
Trains3 >50,000 >655 >50,000 >564
0.411
Table XIV: Plans generated/visited CPU time (secs) ucpop without
parameter domains trains domain using LCFR strategy.
\domain ratio" provides comparison, dividing average union domain size
average intersected domain size, averages taken parameters when-clauses
operators.
largest speedups (e.g., trains problems) tend correlate
smallest domain ratios, smallest speedups largest domain ratio (unity {
see last rows). However, seen table problem diculty (as
measured plans CPU time) much useful domain ratio predictor
speedups expected using parameter domains. Problems generate
order million plans standard ucpop tend produce speedups 3 orders
magnitude, whereas domain ratio problems (e.g., Move-boxes-1)
better (or even worse) problems much smaller speedups (e.g., Move-boxesa, Rat-insulin, Monkey-test1, Monkey-test2). much lower diculty problems
predicts reduced speedup. complicate matters, dicult problems give
high speedups (see T-of-H1 especially Oce5); know subtleties
problem structure account unusual cases.
second round experiments, tested effectiveness parameter domain
technique combination improved search strategy, i.e., S+OC/ZLIFO. addition, combined S+OC LCFR (least cost aw selection) (Joslin & Pollack, 1994),
(or when-clause). find corresponding (partially bound) effects, add new effects
list predications still propagated. partially bound effect (P ?x ?y) new
identical similar predication (P ?u ?v) among previously propagated predications
among still propagated.

126

fiAccelerating Partial-Order Planners

t-trains

without domains
domains
Domain
problems
Plans
CPU sec
Plans
CPU sec ratio
T-Trains1 3134/2183
17.2
505/416
3.4
0.425
T-Trains2 5739/4325
37.3
3482/2749
27.3
0.425
T-Trains3 17,931/13,134 130.4 11,962/9401 105.1
0.425

Table XV: Plans generated/visited CPU time (secs) ucpop without parameter domains \typed" trains domain using ZLIFO strategy.

t-trains

without domains
domains
Domain
problems
Plans
CPU sec
Plans
CPU sec ratio
T-Trains1 3138/2412 31.5 1429/1157 14.5
0.425
T-Trains2 >50,000 >1035 >50,000 >1136
0.425
T-Trains3 >50,000
>976
>50,000
>962
0.425

Table XVI: Plans generated/visited CPU time (secs) ucpop without
parameter domains \typed" trains domain using LCFR strategy.
test possible sensitivity parameter-domains technique precise strategy
used. present set tests used search limit 50,000 plans generated.
began sampling problems ucpop test suite,
initial trials yielded results quite analogous default ucpop strategy.
obtained improvements several easier problems significant improvements
harder ones (e.g., close factor 2 Rat-insulin). Noteworthy members
latter category Oce5 Oce6 { recall Oce5 shown little speedup
standard ucpop Oce6 unsolvable. However, view computational
expense testing ZLIFO LCFR, decided narrow focus
trains world. mentioned, advantages world inherent interest
relative complexity.
Tables XIII-XVI provide experimental results trains domain S+OC/
ZLIFO strategy S+OC/LCFR strategy, case without parameter
domains.
results Tables XIII XIV show using parameter domains still give
significant improvements performance, obtained use
better search strategies. example, use parameter domains provided 11-fold
speedup Trains2, S+OC/ZLIFO strategy. particular problem speedup
(on metrics) result pruning 1482 plans (more half generated)
search., recognizing 305 unsafe conditions redundant. Evidently,
effect pruning amplified order magnitude overall performance,
futile searches cut short. Note speedups Trains1-3
127

fiGerevini & Schubert
roughly comparable (within factor 2) obtained problems previous set
comparable initial diculty (e.g., see Move-boxes-2 Move-boxes-a Table XII).
points rather consistent correlation problem diculty speedups
obtainable using parameter domains. constant domain ratios also compatible
less invariant speedups here, though little import, given earlier
results. S+OC/LCFR gains appear less, though single result showing
3.5-fold speedup provides anecdotal evidence conclusion. Trains2
Trains3 remained dicult solution LCFR. Similar gains observed
S+OC/LC strategies best observed gain Trains domain 1.7-fold
speedup Trains2. case, results confirm effectiveness parameterdomains technique.
Tables XV XVI \typed" version trains. case parameter
typing gave modest improvements absence parameter-domains, (in contrast
results Trains1 default search strategy) significant deterioration
presence. know account results detail, seems
clear contrary effects involved. one hand, typing tend help
tends limit choices parameter values \sensible" ones. example, precondition
(engine ?eng) satisfiable use *start*, initial state thus
constrain ?eng assume sensible values. hand, adding type-preconditions
tend broaden search space, adding open conditions aw list.
lesson \typed" experiments appears best supply
explicit type constraints operator parameters, instead using automated method
calculating updating domains constrain parameter bindings.

6. Conclusions Work

began exploring simple, domain-independent improvements search strategies
partial order planning, described method using precomputed parameter domains prune search space. summarize conclusions techniques
point promising directions work.

6.1 Improving Search

proposed improvements search strategies based one hand carefully
considered choice terms A* heuristic plan selection,
preference choosing open conditions cannot achieved achieved
one way (with default LIFO prioritization open conditions). Since
plan refinements corresponding uniquely achievable goals logically necessary,
termed latter strategy zero-commitment strategy. One advantage technique
similar strategies incurs lower computational overhead.
experiments based modifications ucpop indicate strategies give
large improvements planning performance, especially problems hard
ucpop (and \relatives") begin with. best performance achieved
strategies plan selection goal selection used combination. practical terms,
able solve nearly every problem tried ucpop test suite fraction
second (except Fixit, required 38.2 seconds), problems
128

fiAccelerating Partial-Order Planners
previously required minutes unsolvable machine. included
sucient variety problems indicate techniques broad potential utility.
Further, results suggest zero-commitment best supplemented LIFO
strategy open conditions achievable multiple ways, rather generalization
zero-commitment favoring goals fewest children. somewhat surprising result
might thought due way designer domain orders
preconditions operators; i.e., \natural" ordering preconditions may correlate
best planning order, giving fortuitous advantage LIFO strategy relative
strategy like LC.20
However, preliminary experiments performed randomized preconditions
T-of-H1 Trains1 indicate otherwise. 5 randomizations preconditions
T-of-H1, LC ZLIFO slowed somewhat, average factors 2.2 (2)
3.3 (4.2) terms plans expanded (CPU time used) respectively. (In cases,
S+OC used plan search.) still left ZLIFO performance advantage
factor 22 terms plans created 39 terms CPU time. Trains1
performance LC greatly deteriorated 2 5 cases (by factor close 70 terms
plans time), ZLIFO actually improved marginally. left
ZLIFO average performance advantage LC (whereas slightly slower
unrandomized case) { factor 3.3 terms plans 6.7 terms CPU time
(though values unreliable, view fact standard deviations
order means).
Despite results believe satisfactory understanding dependence
aw-selection strategies order operator preconditions require extensive
experimental investigation. currently undertaking work.

6.2 Using Parameter Domains

described implemented, tractable algorithm precomputing parameter domains
planning operators, relative given initial conditions. showed use precomputed domains planning process prune non-viable actions bogus threats,
update dynamically maximum effect.
idea using precomputed parameter domains constrain planning apparently
first proposed technical report Goldszmidt et al. (1994). contains essential
idea accumulating domains forward propagation initial conditions. Though
report sketches single-sweep propagation process initial conditions
goals, implemented Rockwell Planner (RNLP) handles cyclic operator graphs,
repeatedly propagating bindings quiescence, much algorithm. algorithm
deals additional complexities conditional effects equalities (and semiautomated fashion quantification) appears ecient (Smith, 1996).
distinctive features work method incrementally refining domains
20. suggested us David Smith well Mike Williamson. Williamson tried ZLIFO 5
randomized versions T-of-H1, reported large performance degradation (Williamson & Hanks,
1996). recently ran versions using implementation, obtaining far favorable results
(three five versions easier solve original version T-of-H1, two
versions slowed ZLIFO factor 1.84 4.86 terms plans explored.)

129

fiGerevini & Schubert
planning, theoretical analysis algorithm, systematic experimental
tests.
Another closely related study Yang Chan (1994), used hand-supplied
parameter domains planning much use precomputed domains. interesting
aspect work direct use sets constants variable bindings. instance,
establishing precondition (P ?x) using initial state containing (P a), (P b)
(P c), would bind ?x fa, b, cg rather specific constant. refine
\noncommittal" bindings planning much refine variable domains,
periodically use constraint satisfaction methods check consistency current
EQ/NEQ constraints. conclude delaying variable bindings works best problems
low solution densities (while degrading performance problems high
solution densities), optimal frequency making consistency checks depends
whether dead ends tend occur high low search tree. work distinguished
method precomputing parameter domains, use specific bindings
matching initial conditions OCs, use parameter domains threat detection
resolution, handling enriched syntax ucpop operators compared
snlp operators.
Judging examples experimented with, techniques well-suited
nontrivial problems involve diverse types objects, relations actions, significant logical interdependencies among steps needed solve problem. used
conjunction default search strategy ucpop, method gave significant speedups
nontrivial problems, reaching speedup factor 927 trains transportation planning domain, 1717 hardest strips-world problem tried .
combined S+OC ZLIFO search strategies, parameter domain technique
still gave speedups factor around 10 trains problems. Though implementation aimed ucpop-style planner, essentially techniques would
applicable many planners.
also found parameter domain precomputations useful debugging
aid. fact, domain precomputation initial formulation trains world
immediately revealed several errors. instance, domain ?eng parameter
mv-engine turned contain oranges, bananas, OJ factory, indicating need
type constraint ?eng. (Without this, transportation problems would
solvable without benefit engines trains!) Another immediately apparent problem
revealed parameter domains ?city1 ?city2 mv-engine: domain
?city1 excluded Elmira, ?city2 excluded Avon. obvious diagnosis
neglected assert (connected c1 c2) (connected c2 c1)
track connecting two cities. Furthermore, parameter domains quickly identify
unreachable operators goals cases. instance, without make-oj operator,
computed domains show ld-oj operator unreachable, goal like
(and (oj ?oj) (at ?oj Bath)) (getting orange juice Bath) unattainable (the
parameter domain ?oj empty).
course, running planner also used debugging formalization,
planning general far time-consuming form preprocessing (especially
goal pose happens unachievable formalization!), trace
130

fiAccelerating Partial-Order Planners
anomalous planning attempt quite hard interpret, compared listing
parameter domains, obtained fraction second.

6.3 work

First all, additional experimentation would interest, assess
perhaps refine search strategies. experimentation might focus threathandling strategies, including best general form attenuated UC-term plan
selection, best way combine threat selection open condition selection.
preference definite threats open conditions used ZLIFO appear
good default according experience, TileWorld experiments indicated
re-ordering priorities threats open conditions sometimes desirable. Concerning choice UC-related term inclusion heuristic plan selection,
mention brie tried using S+OC+UC , UC number
definite threats, obtain significant uniform improvements.
One promising direction development search strategy make
zero-commitment strategy apply often finding ways identifying false options
early possible. is, possible action instance (obtained matching open
condition available operators well existing actions) easily recognizable inconsistent current plan, elimination may leave us single
remaining match hence opportunity apply zero-commitment strategy.
One way implementing strategy would check once, accepting
matched action possible way attain open condition, whether temporal
constraints action force violate causal link, alternatively, force causal
link violated. case action could immediately eliminated, perhaps
leaving one (or even no) alternative. could perhaps made even effective
broadening definition threats preconditions well effects actions
threaten causal links, hence bring light inconsistencies sooner. Note
precondition action inconsistent causal link, established
another action whose effects violate causal link; precondition really poses
threat outset.
Two possible extensions parameter domain techniques (i) fully automated
handling universally quantified preconditions effects, disjunctions facts
preprocessing algorithm; (ii) \intelligent" calculation domains, applying
constraint propagation process sets ground predications matched
preconditions operator; shown yield tighter domains, though
computational expense. Blum Furst (1995) recently explored similar idea, rather
computing parameter domains, directly stored sets ground atoms could
generated one operator application (starting initial state), two successive operator
applications, on, used sets atoms (and exclusivity relations among
atoms actions connecting them) guide regressive search plan.
algorithm describe allow conditional effects, though generalization
appears entirely possible. examples used tests, obtained dramatic
speedups.


131



fiGerevini & Schubert
Finally, also working another preprocessing technique, namely inference
state constraints operator specifications. One useful form constraint implicational (e.g., (implies (on ?x ?y) (not (clear ?y)))), another single-valuedness
conditions (e.g., (on ?x ?y) may single-valued ?x ?y). conjecture
constraints tractably inferred used large speedups domainindependent, well-founded planning.
view results presented possibilities speedups
mentioned, think plausible well-founded, domain-independent planners may
yet become competitive pragmatically designed planners.

Acknowledgements

work amalgamates extends two conference papers improving search (Schubert
& Gerevini, 1995) using computed parameter domains (Gerevini & Schubert, 1996)
accelerate partial-order planners. research supported part Rome Lab contract F30602-91-C-0010 NATO Collaborative Research Grant CRG951285.
work AG carried IRST, 38050 Povo (TN), Italy, CS Department
University Rochester, Rochester NY USA. helpful comments perceptive
questions Marc Friedman, David Joslin, Rao Kambhampati, Colm O'Riain, Martha Pollack, David Smith, Dan Weld, Mike Williamson, Associate Editor Michael Wellman
anonymous reviewers gratefully acknowledged.

Appendix (Proofs Theorems)
Theorem 1 find-parameter-domains algorithm correct computing parameter

domains ucpop-style sets operators (without quantification, disjunction, facts),
initial conditions, (possibly) goal conditions.
Proof. preliminary observation, intersected parameter domains computed iteratively algorithm eventually stabilize, since grow monotonically
finitely many constants occur initial conditions operator effects.
Thus algorithm terminates.
order prove correctness need show exists valid sequence
A0 A1 :::A actions (operator instances) starting A0 = *start*,
instance operator Op, bindings parameters Op received instance
eventually added relevant intersected domains Op (where \relevant" refers
when-clauses Op whose preconditions satisfied beginning ).
prove induction n.
n = 0, = A0 = *start*, parameters claim trivially
true.
assume claim holds n = 1; 2; :::; k. consider operator instance
+1 validly follow A0 A1 :::A , i.e., +1 instance operator
Op whose primary preconditions, possibly along secondary ones, satisfied
end A0 A1 :::A . Let p precondition, write instance +1
(P c1 c2 ..). (P c1 c2 ..) must effect , 0 k. = 0
n

n

n

n

n

k

k

k

k

k



132

fiAccelerating Partial-Order Planners
(P c1 c2 ..) holds initial state, hence predication propagated
successfully matched p initial propagation phase find-parameter-domains.
> 0, instance operator Op' (P c1 c2 ..) corresponding
instance effect (P t1 t2 ..) Op', either parameter Op'
equal cj. Diagrammatically,


j

A0 . . .
j



. . .



+1
j

k

k

Op'

Op

effect (P t1 t2 ..) ,,,,! precond p
(P c1 c2 .. )

(P c1 c2 .. )

induction assumption, bindings parameters eventually added
relevant intersected domains Op'. also implies intersected domains
Op' become nonempty, effect (P t1 t2 ..) eventually propagated,
variables among corresponding constant cj relevant intersected
domain. Consequently, much case = 0, effect (P t1 t2 ..) successfully matched
precondition p Op stage propagation. Given observations,
clear = 0 > 0, p marked \matched" Op eventually,
furthermore parameters Op occur p bindings resulting
unification (P c1 c2 ..) added appropriate individual domains associated
p.
argument applies preconditions Op satisfied instance +1 , particular primary preconditions. Since marked \matched", algorithm
compute intersected domains Op-parameters occur them. view
individual domain updates confirmed, since individual domains grow monotonically, intersected domains eventually contain parameter bindings +1 .
instance, parameter ?x Op occurs primary precondition bound
c +1 , shown c eventually added intersected domain
?x associated primary when-clause Op. parameter occur
primary preconditions Op, intersected domain set outset,
implicitly contains whatever binding parameter +1 .
similar argument made secondary when-clause Op whose preconditions also satisfied +1 . Again, preconditions secondary clause,
well primary preconditions, marked \matched", parameter
occurring combined preconditions, intersected domain (relative secondary
clause) updated include binding +1 . parameters Op occurring
preconditions, intersected domains set initially,
implicitly contains possible binding. Finally, note since intersected
domains relative primary secondary when-clauses grow monotonically, augmentations intersected domains confirmed permanent. (In case
T-domains, remain T.)
leave additional details concerned ultimate use EQ-preconditions
find-parameter-domains reader. 2


j

k

k

k

k

k

k

133

fiGerevini & Schubert

Theorem 2 Algorithm find-parameter-domains implemented run O(mn n (n +
n )) time O(mn ) space worst case, number constants
problem specification, n combined number preconditions operators (and
goals, included), n combined number operator effects (including
p

e

e

p

p

p

e

*start*).

Proof. time complexity find-parameter-domains determined sum
(1) cost unifications performed, (2) costs individual domain
updates attempted, (3) cost intersected domain updates attempted.
estimate upper bound terms following assumptions:

(a) unification operator effect operator precondition requires constant
time;
(b) fixed upper bound number arguments predicate (in
precondition effect) have. follows O(n ) upper bound total
number intersected domains;21
(c) individual domains intersected domains stored hash tables (indexed
constants domain). So, check whether element belongs particular
(individual intersected) domain, possibly add domain essentially
constant time. Furthermore individual intersected domain, appropriate
data structures used keep track (possibly empty) set new elements
added domain last update attempt.
(1) particular intersected domain particular operator,
updates domain. update causes effects whenclause intersected domain belongs propagated. upper bound
number n . propagated effect may unified O(n ) preconditions. Thus
O(m) updates intersected domain may cause O(mn n ) unifications. Hence
(b), overall number unifications caused propagation intersected domains
individual domains O(mn2 n ). unifications add
initially performed effects *start* preconditions operators.
O(mn ) unifications, increase previous upper bound
number unifications. Thus, (a), cost unifications performed
algorithm O(mn2 n ).
(2) unification potentially followed attempt update individual
domain(s) relevant parameter(s). However, assumption (c) number
attempts limited set new elements intersected domain(s)
unifying effect (are) empty. Furthermore, attempt update
individual domain performing union relevant intersected domain ,
subset new elements need added (if already
there). Thus, since intersected domain grows monotonically, (b) (c)
overall cost update attempts one particular individual domain caused
e

e

p

e

e

p

p

p

e

p











21. Note parameter appears precondition when-clause, none effects,
intersected domain parameter propagated algorithm. Hence implementing
algorithm ignore parameters.

134

fiAccelerating Partial-Order Planners
one particular effect O(m). worst case one effect unify
O(n ) preconditions operators, yielding overall bound attempts
update individual domains O(mn n ).
(3) attempt update particular intersected domain relevant
individual domain update, relevant individual domain updated O(m) times
(because domains grow monotonically). Therefore (b) O(mn )
attempts update one intersected domain. (c) total cost attempts
O(mn2 ), checking whether new element individual domain belongs
O(n ) relevant individual domains takes O(n ) time. So, since (b)
O(n ) intersected domains, total cost incurred algorithm
updating intersected domains O(mn n2 ).
follows time complexity find-parameter-domains is:
O(mn2n ) + O(mn n ) + O(mn n2) = O(mn n (n + n )).
space complexity bound easily derived (b), fact
when-clause O(m) constants stored. 2
p

e

p

p

p

p

p

e

e

p

e

p

References

e

p

e

p

p

e

p

e

Allen, J., & Schubert, L. (1991). TRAINS project. Tech. rep. 382, Dept. Computer
Science, Univ. Rochester, Rochester, NY. Also slightly revised Language
discourse TRAINS project, A. Ortony, J. Slack, O. Stock (eds.), Communication Artificial Intelligence Perspective: Theoretical Springer-Verlag,
Heidelberg, pp. 91-120.
Allen, J., Schubert, L., Ferguson, G., Heeman, P., Hwang, C., Kato, T., Light, M., Martin,
N., Miller, B., Poesio, M., & Traum, B. (1995). TRAINS project: case study
building conversational planning agent. Experimental Theoretical Artificial
Intelligence, 7, 7{48.
Barrett, A., Golden, K., Penberthy, S., & Weld, D. (1994). UCPOP user's manual. Tech.
rep. 93-09-06, Dept. Computer Science Engineering, University Washington,
Seattle, WA 98105.
Blum, A., & Furst, M. (1995). Fast planning planning graph analysis. Proceedings
Fourteenth International Joint Conference Artificial Intelligence (IJCAI-95),
pp. 1636{1642 Montreal, CA. Morgan Kaufmann.
Chapman, D. (1987). Planning conjunctive goals. Artificial Intelligence, 32 (3), 333{377.
Currie, K., & Tate, A. (1991). O-Plan: open planning architecture. Artificial Intelligence, 51 (1).
Fikes, R., & Nilsson, N. (1971). STRIPS: new approach application theorem
proving problem solving. Artificial Intelligence, 2, 189{208.
Georgeff, M., & Lansky, A. (1987). Reactive reasoning planning. Proceedings
Sixth National Conference American Association Artificial Intelligence, pp.
677{682 Seattle, WA. Morgan Kaufmann.
135

fiGerevini & Schubert
Gerevini, A., & Schubert, L.K. (1995). Computing parameter domains aid planning.
Proc. 3rd Int. Conf. Artificial Intelligence Planning Systems (AIPS-96),
pp. 94{101 Menlo Park, CA. AAAI Press.
Goldszmidt, M., Darwiche, A., Chavez, T., Smith, D., & White, J. (1994). Decision-theory
crisis management. Tech. rep. RL-TR-94-235, Rome Laboratory.
Green, C. (1969). Application theorem proving problem solving. Proceedings
First International Joint Conference Artificial Intelligence (IJCAI-69), pp.
219{239.
Joslin, D. (1995). Personal communication.
Joslin, D., & Pollack, M. (1994). Least-cost aw repair: plan refinement strategy
partial-order planning. Proceedings Twelfth National Conference
American Association Artificial Intelligence (AAAI-94), pp. 1004{1009 Seattle,
WA. Morgan Kaufmann.
Kambhampati, S., Knoblock, C. A., & Yang, Q. (1995). Planning refinement search:
unified framework evaluating design tradeoff partial-order planning. Artificial
Intelligence. Special Issue Planning Scheduling, 76 (1-2).
Korf, R. (1992). Linear-space best-first search: Summary results. Proceedings
Tenth National Conference American Association Artificial Intelligence
(AAAI-92), pp. 533{538.
McAllester, D., & Rosenblitt, D. (1991). Systematic nonlinear planning. Proceedings
Ninth National Conference Artificial Intelligence (AAAI-91), pp. 634{639
Anheim, Los Angeles, CA. Morgan Kaufmann.
Nilsson, N. (1980). Principles Artificial Intelligence. Tioga Pub. Co., Palo Alto, CA.
Penberthy, J., & Weld, D. (1992). UCPOP: sound, complete, partial order planner
ADL. Nebel, B., Rich, C., & Swartout, W. (Eds.), Proceedings Third
International Conference Principles Knowledge Representation Reasoning
(KR92), pp. 103{114 Boston, MA. Morgan Kaufmann.
Peot, M. A., & Smith, D. E. (1993). Threat-removal strategies partial-order planning.
Proceedings Eleventh National Conference American Association
Artificial Intelligence (AAAI-93), pp. 492{499 Washington, D.C. Morgan Kaufmann.
Schubert, L., & Gerevini, A. (1995). Accelerating partial order planners improving
plan goal choices. Proc. 7th IEEE Int. Conf. Tools Artificial
Intelligence, pp. 442{450 Herndon, Virginia. IEEE Computer Society Press.
Smith, D. E., & Peot, M. A. (1993). Postponing threats partial-order planning.
Proceedings Eleventh National Conference American Association Artificial Intelligence (AAAI-93), pp. 500-506 Washington, D.C. Morgan Kaufmann.
Smith, D. E. (1996). Personal communication.
136

fiAccelerating Partial-Order Planners
Srinivasan, R., & Howe, A. (1995). Comparison methods improving search eciency
partial-order planner. Proceedings Fourteenth International Joint Conference Artificial Intelligence (IJCAI-95), pp. 1620{1626.
Weld, D. (1994). introduction least commitment planning. AI Magazine, 15 (4),
27{62.
Wilkins, D. (1988). Practical Planning: Extending Classical AI Planning Paradigm.
Morgan Kaufmann, San Mateo, CA.
Williamson, M., & Hanks, S. (1995). Flaw selection strategies value-directed planning.
Proceedings Third International Conference Artificial Intelligence Planning
Systems, pp. 237{244.
Yang, Q., & Chan, A.Y.M. (1994). Delaying variable binding commitments planning.
Proceedings Second International Conference Artificial Intelligence Planning
Systems, pp. 182{187.

137

fiJournal Artificial Intelligence Research 5 (1996) 27-52

Submitted 9/95; published 8/96

Hierarchy Tractable Subsets
Computing Stable Models
Rachel Ben-Eliyahu

rachel@cs.bgu.ac.il

Mathematics Computer Science Department
Ben-Gurion University Negev
P.O.B. 653, Beer-Sheva 84105, Israel

Abstract

Finding stable models knowledge base significant computational problem
artificial intelligence. task computational heart truth maintenance
systems, autoepistemic logic, default logic. Unfortunately, NP-hard.
paper present hierarchy classes knowledge bases,
1
2 , following
properties: first,
1 class stratified knowledge bases; second, knowledge
base
, stable models, may found time
( ), length knowledge base number atoms ; third,
arbitrary knowledge base , find minimum belongs

time polynomialSin1 size ; and, last, K class knowledge bases,
case =1
= K, is, every knowledge base belongs class
hierarchy.
;

k

k

lnk

; :::

l

n

k



k



1. Introduction
task computing stable models knowledge base lies heart three
fundamental systems Artificial Intelligence (AI): truth maintenance systems (TMSs),
default logic, autoepistemic logic. Yet, task intractable (Elkan, 1990; Kautz &
Selman, 1991; Marek & Truszczynski, 1991). paper, introduce hierarchy
classes knowledge bases achieves task polynomial time. Membership
certain class hierarchy testable polynomial time. Hence, given knowledge base,
cost computing stable models bounded prior actual computation (if
algorithms hierarchy based used).
First, let us elaborate relevance computing stable models AI tasks. define
knowledge base set rules form

C ,A1 ; :::; Am; B1; :::; Bn

(1)

C , As, B atoms propositional language. Substantial efforts
give meaning, semantics, knowledge base made logic programming
community (Przymusinska & Przymusinski, 1990). One successful semantics
knowledge bases stable model semantics (Bidoit & Froidevaux, 1987; Gelfond & Lifschitz,
1988; Fine, 1989), associates knowledge base (possibly empty) set
models called stable models. Intuitively, stable model represents set coherent
c 1996


AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiBen-Eliyahu
conclusions one might deduce knowledge base. turns stable models
play central role major deductive systems AI. 1

1.1 Stable Models TMSs

TMSs (Doyle, 1979) inference systems nonmonotonic reasoning default assumptions. TMS manages set nodes set justifications, node
represents piece information justifications rules state dependencies
nodes. TMS computes grounded set nodes assigns set
information believed true given point time. Intuitively, set believed
nodes grounded satisfies rules, node believed true solely basis
circular chain justifications. Elkan (1990) pointed nodes TMS
viewed propositional atoms, set justifications knowledge base.
showed task computing grounded interpretations set TMS justifications corresponds exactly task computing stable models knowledge base
represented set TMS justifications.

1.2 Stable Models Autoepistemic Logic

Autoepistemic logic invented Moore (1985) order formalize process
agent reasoning beliefs. language autoepistemic logic propositional
language augmented modal operator L. Given theory (a set formulas)
autoepistemic logic, theory E called stable expansion iff
E = (T SfLF jF 2 E gSf:LF jF 2= E g)
denotes logical closure . restrict subset
autoepistemic logic formula form
A1 ^ ::: ^ ^ :LB1 ^ ::: ^ :LBn ,!C
(2)
C , As, B propositional atoms. call subset
class autoepistemic programs. Every autoepistemic program translated
knowledge base representing formula (2) knowledge base rule (1). Elkan
(1990) shown stable model iff expansion E
set positive atoms E . Thus, algorithms computing stable models
may used computing expansions autoepistemic programs. relationship
stable model semantics autoepistemic logic also explored Gelfond (1987)
Gelfond Lifschitz (1988, 1991).

1.3 Stable Models Default Logic

Default logic formalism developed Reiter (1980) reasoning default assumptions. default theory viewed set defaults, default defined
expression form
ff : fi1; :::; fin
(3)



1. logic programming terminology, knowledge bases discussed paper called normal logic
programs.

28

fiA Hierarchy Tractable Subsets
ff; , fi1 ; :::; fin formulas first-order language. According Reiter, E
extension default theory iff E coincides one minimal deductively
closed sets sentences E 0 satisfying condition2 grounded instance
default (3) , ff 2 E 0 :fi1 ; :::; :fin 2= E , 2 E 0.
consider subset default theories call default programs. default
program set defaults form

A1 ^ ::: ^ : :B1; :::; :Bn
(4)
C
C , As, B atoms propositional language.

default program associated knowledge base replacing
default form (4) rule (1).
Gelfond Lifschitz (1991) shown logical closure set atoms E
extension iff E stable model . Algorithms computing stable models
thus used computing extensions Reiter's default theories.


paper organized follows. next section, define terminology.
Section 3 presents two algorithms computing stable models knowledge base.
complexity first algorithms depends number atoms appearing
negatively knowledge base, complexity algorithm depends
number rules negative atoms bodies. Section 4, present
main algorithm paper, called algorithm AAS. Algorithm AAS works
bottom superstructure dependency graph knowledge base uses
two algorithms presented Section 3 subroutines. Section 5 explains AAS
algorithm generalized handle knowledge bases first-order language. Finally,
Sections 6 7, discuss related work make concluding remarks.

2. Preliminary Definitions
Recall knowledge base defined set rules form

C ,A1 ; :::; Am; B1; :::; Bn

(5)

C , As, B propositional atoms. expression
left , called head rule, expression right , called
body rule. said appear positive rule, and, accordingly,
B said appear negative rule. Rule (5) said C . rule
empty body called unit rule. Sometimes treat truth assignment (in
words, interpretation) propositional logic set atoms | set atoms
assigned true interpretation. Given interpretation set atoms A, IA
denotes projection A. Given two interpretations, J , sets atoms
2. Note appearance E condition.

29

fiBen-Eliyahu
B , respectively, interpretation + J defined follows:
8>
P 2 n B
>< IJ((PP))
P 2 BTn
+ J (P ) = > (P )
P 2 B (P ) = J (P )

>:
undefined otherwise

(P ) = J (P ) every P 2 B , say J consistent.

partial interpretation truth assignment subset atoms. Hence, partial
interpretation represented consistent set literals: positive literals represent
atoms true, negative literals atoms false, rest unknown.
knowledge base called Horn rules Horn. model theory (set
clauses) propositional logic truth assignment satisfies clauses. one
looks knowledge base theory propositional logic, Horn knowledge base
unique minimal model (recall model minimal among set models iff
model m0 2 m0 m).
Given knowledge base set atoms m, Gelfond Lifschitz defined
called Gelfond-Lifschitz (GL) transform w.r.t. m, knowledge base
obtained deleting rule negative literal P body
P 2 deleting negative literals bodies remaining rules. Note
Horn knowledge base. model stable model knowledge base iff
unique minimal model (Gelfond & Lifschitz, 1988).
Example 2.1 Consider following knowledge base 0, used one
canonical examples throughout paper:
(6)
warm blooded , mammal
live land , mammal; ab1
(7)
female , mammal; male
(8)
male , mammal; female
(9)
mammal , dolphin
(10)
ab1 , dolphin
(11)
mammal , lion
(12)
lion ,
(13)
= flion; mammal; warm blooded; live land; femaleg stable model 0 . Indeed,
0m (the GL transform 0 w.r.t. m)

,
,
,
,
,
,
,

warm blooded
live land
female
mammal
ab1
mammal
lion

30

mammal
mammal
mammal
dolphin
dolphin
lion

fiA Hierarchy Tractable Subsets
minimal model 0m .
set atoms satisfies body rule iff atom appears positive
body atom appears negative body . set
atoms satisfies rule iff either satisfy body, satisfies body
atom appears head belongs .
proof atom sequence rules atom derived. Formally,
recursively define atom P proof w.r.t. set atoms
knowledge base :
unit rule P , , P proof w.r.t. .
rule P ,A1; :::; Am; B1; :::; Bn , every = 1; :::; n Bi
, every = 1; :::; Ai already proof w.r.t. , P
proof w.r.t. .
Theorem 2.2 (Elkan, 1990; Ben-Eliyahu & Dechter, 1994) set atoms stable
model knowledge base iff
1. satisfies rule ,
2. atom P , proof P w.r.t .
simple matter show following lemma true.
Lemma 2.3 Let knowledge base, let set atoms. Define:
1. S0 = ;,

2. Si+1 = Si fP jP ,A1 ; :::; Am; B1 ; :::; Bn ;
A's belong Si none B 's belong g.
S.
stable model iff = 1
0
Observe although every stable model minimal model knowledge base
viewed propositional theory, every minimal model stable model.
Example 2.4 Consider knowledge base
b ,
fag fbg minimal models knowledge base above, fbg stable
model knowledge base.
Note knowledge base may one stable models, stable model all.
knowledge base least one stable model, say consistent.
dependency graph knowledge base directed graph atom
node positive edge directed P Q iff rule Q
P appears positive body. Accordingly, negative edge
P Q iff rule Q P appears negative body. Recall
source directed graph node incoming edges, sink node
outgoing edges. Given directed graph G node G, subgraph rooted
subgraph G nodes path directed G.
children G nodes arc directed G.
31

fiBen-Eliyahu

Example 2.5 dependency graph 0 shown Figure 1. Negative edges
marked \not." children mammal lion dolphin. subgraph rooted
land subgraph include nodes lion, mammal, dolphin, ab1, land.

male

warm_blood
female



on_land
mammal

lion



ab1
dolphin

Figure 1: dependency graph 0
knowledge base stratified iff assign atom C positive integer iC
every rule form (5) above, As, iA iC ,
B s, iB < iC . readily demonstrated knowledge base stratified iff
dependency graph directed cycles going negative edges. well
known logic programming community stratified knowledge base unique
stable model found linear time (Gelfond & Lifschitz, 1988; Apt, Blair, &
Walker, 1988).

Example 2.6 0 stratified knowledge base. following knowledge base, 1,

stratified (we assign ab2 penguin number 1, atoms
number 2):

live land
fly
bird
ab2

,
,
,
,
32

bird
bird; ab2
penguin
penguin

fiA Hierarchy Tractable Subsets
strongly connected components directed graph G make partition
set nodes that, subset partition x; 2 ,
directed paths x x G. strongly connected components
identifiable linear time (Tarjan, 1972).

male




female
warm_blood

on_land
mammal

lion



ab1
dolphin

Figure 2: super dependency graph 0
super dependency graph knowledge base , denoted G , superstructure
dependency graph . is, G directed graph built making strongly
connected component dependency graph node G . arc exists
node node v iff arc one atoms one atoms v
dependency graph . Note G acyclic graph.

Example 2.7 super dependency graph 0 shown Figure 2. nodes

square grouped single node.

3. Two Algorithms Computing Stable Models
main contribution paper presentation algorithm whose eciency
depends \distance" knowledge base stratified knowledge base.
distance measured precisely Section 4. first describe two algorithms
computing stable models. two algorithms take account level
\stratifiability" knowledge base, is, still work exponential time
stratified knowledge bases. main algorithm use two algorithms procedures.
33

fiBen-Eliyahu
Given truth assignment knowledge base, verify polynomial time whether
stable model using Lemma 2.3. Therefore, straightforward algorithm computing stable models simply check possible truth assignments determine whether
stable model. time complexity straightforward procedure
exponential number atoms used knowledge base. Below, present two
algorithms often function eciently straightforward procedure.

3.1 Algorithm Depends Number Negative Atoms
Knowledge Base
Algorithm All-Stable1 (Figure 3) enables us find stable models time expo-

nential number atoms appear negative knowledge base.
algorithm follows work abductive extensions logic programming
stable models characterized terms sets hypotheses drawn additional information (Eshghi & Kowalski, 1989; Dung, 1991; Kakas & Mancarella, 1991).
done making negative atoms abductible imposing appropriate denials
disjunctions integrity constraints. work Eshghi Kowalski (1989), Dung
(1991), Kakas Mancarella (1991) implies following.
Theorem 3.1 Let knowledge base, let H set atoms appear negated
. stable model iff interpretation H
1. every atom P 2 H , P 2 , P 2 0 ,
2. 0 consistent,
3. = +M 0 ,
0 unique stable model .
Proof: proof follows directly definition stable models. Suppose
stable model knowledge base , let H set atoms appear negative
. Then, definition, stable model . note = MH . Hence,
conditions Theorem 3.1 hold , taking 0 = = MH . Now, suppose
knowledge base = 0 + , 0 Theorem 3.1. Observe
= and, hence, since 0 stable model , 0 stable model .
show stable model . First, note condition 1, 0 . Thus,
satisfies rules and, atom P proof w. r. t. 0 ,
also proof w. r. t. . So, Theorem 2.2, stable model and,
definition, stable model .
Theorem 3.1 implies algorithm All-Stable1 (Figure 3), computes stable
models knowledge base . Hence, following complexity analysis.
Proposition 3.2 knowledge base k atoms appear negated
2k stable models found time O(nl2k ), l size
knowledge base n number atoms used knowledge base.
Proof: Follows fact computing computing unique stable model
positive knowledge base O(nl).
34

fiA Hierarchy Tractable Subsets

All-Stable1()

Input: knowledge base .
Output: set stable models .
1. := ;;
2. possible interpretation set atoms appear negative ,
do:
(a) Compute 0 , unique stable model ;

(b) 0 consistent, let := fM 0 + g;
3. Return M;
Figure 3: Algorithm All-Stable1

3.2 Algorithm Depends Number Non-Horn Rules
Algorithm All-Stable2 (Figure 4) depends number rules

negated atoms. gets input knowledge base , and, outputs set stable
models . algorithm based upon observation stable model
built attempting possible means satisfying negated atoms bodies nonHorn rules. Two procedures called All-Stable2: UnitInst, shown Figure 5;
NegUnitInst, shown Figure 6. Procedure UnitInst gets input knowledge base
partial interpretation m. UnitInst looks recursively unit rules . unit rule
P , , P assigned false m, follows cannot part model ,
procedure returns false. P false m, procedure instantiates P true
interpretation deletes positive appearances P body rule.
also deletes rules P rules P appears negative.
Procedure NegUnitInst receives input knowledge base , partial interpretation
m, set atoms Neg. first instantiates atom Neg false updates
knowledge base ect instantiation. instantiations recorded m.
case con ict, namely, procedure tries instantiate true atom
already set false, procedure returns false; otherwise, returns true.

Proposition 3.3 Algorithm All-Stable2 correct, is, stable model
knowledge base iff generated All-Stable2().
Proof: Suppose stable model knowledge base . Then, Theorem 2.2, every
atom set true proof w. r. t. . Let set non-Horn
rules whose bodies satisfied m. Clearly, point checked step 3
algorithm All-Stable2. happens, atoms proof w. r. t.
set true procedure NegUnitInst (as proved induction
length proof). Hence, generated.
Suppose generated All-Stable2(). Obviously, every rule satisfied
(step 3.c.ii), every atom set true NegUnitInst proof w. r. t.
35

fiBen-Eliyahu

All-Stable2()
Input: knowledge base .
Output: set stable models .
1. := ;;
2. Let set non-Horn rules .
3. subset , do:
(a) Neg = fP jnot P body rule g;
(b) 0 := ; := ;;
(c) NegUnitInst(0 ; Neg; m),
i. P m[P ] = null, let m[P ] := false;

ii. satisfies rules , := fmg;
4. EndFor;
5. Return ;
Figure 4: Algorithm All-Stable2
UnitInst(; m)
Input: knowledge base partial interpretation m.
Output: Updates using unit rules . Returns false con ict
unit rule value assigned atom m; otherwise, returns true .
1. unit rules, do:
(a) Let P , unit rule ;
(b) m[P ] = false, return false;
(c) m[P ] := true;
(d) Erase P body rule ;
(e) Erase rules P ;
(f) Erase rules P appears negative;
2. EndWhile;
3. Return true;
Figure 5: Procedure UnitInst
36

fiA Hierarchy Tractable Subsets
NegUnitInst(; Neg; m)
Input: knowledge base , set atoms Neg , partial interpretation m.
Output: Updates assuming atoms Neg false. Returns false inconsistency
detected; otherwise, returns true.
1. atom P Neg
(a) m[P ] := false;
(b) Delete body rule occurrence P ;
(c) Delete rule P appears positive body;
2. EndFor;
3. Return UnitInst(; m);
Figure 6: Procedure NegUnitInst



1
2

lion dolphin ab1 mammal warm b land male female


F

F







F





F

F









F

Table 1: Models generated Algorithm All-Stable2
(as readily observable way NegUnitInst works). Hence, Theorem 2.2,
stable model .

Proposition 3.4 knowledge base c non-Horn rules 2c stable models

found time O(nl2c), l size knowledge base
n number atoms used knowledge base.

Proof: Straightforward, induction c.
Example 3.5 Suppose call All-Stable2 0 input knowledge base.
step 2, set rules (7), (8), (9). subsets include rules
(8) (9) considered step 3, NegUnitInst return false UnitInst

detect inconsistency. subset containing rules (7) (8) considered,
stable model 1 Table 1 generated. subset containing rules (7)
(9) considered, stable model 2 Table 1 generated.
subsets contain rules (8) (9) tested step 3, generated
satisfy rules and, hence, appear output.
Algorithms All-Stable1 All-Stable2 take account structure
knowledge base. example, polynomial class stratified
knowledge bases. present next algorithm exploits structure knowledge
base.
37

fiBen-Eliyahu

4. Hierarchy Tractable Subsets Based Level Stratifiability
Knowledge Base

Algorithm Acyclic-All-Stable (AAS) Figure 7 exploits structure knowledge
base ected super dependency graph knowledge base. computes
stable models traversing super dependency graph bottom up, using
algorithms computing stable models presented previous section subroutines.
Let knowledge base. node G (the super dependency graph
), associate , , Ms . subset containing rules
atoms s, set atoms subgraph G rooted s, Ms set
stable models associated subset knowledge base contains rules
atoms . Initially, Ms empty every s. algorithm traverses G
bottom up. node s, first combines submodels children
single set models Mc(s) . source, Mc(s) set f;g3. Next,
model Mc(s) , AAS converts knowledge base sm using GL transform
transformations depend atoms m; then, finds stable models
sm combines m. set Ms obtained repeating operation
Mc(s) . AAS uses procedure CartesProd (Figure 8), receives input
several sets models returns consistent portion Cartesian product. one
sets models CartesProd gets input empty set, CartesProd
output empty set models. procedure Convert gets input knowledge base ,
model m, set atoms s, performs following: atom P m,
positive occurrence P deleted body rule ; rule ,
P body rule P 2 m, rule deleted ; P
body rule P 2= m, then, P 2= s, P deleted body.
procedure All-Stable called AAS may one procedures previously presented
(All-Stable1 All-Stable2) may procedure generates stable
models.

Example 4.1 Suppose AAS called compute stable models 0. Suppose

algorithm traverses super dependency graph Figure 2 order flion,
dolphin, mammal, ab1, land, warm blooded, female-maleg (recall nodes inside square make one node calling female-male or, short, FM).
visiting nodes except last, Mlion = ffliongg, Mdolphin = f;g,
Mmammal = fflion; mammalgg, Mon land = fflion; mammal; onlandgg, Mwarm blooded =
fflion; mammal; warm bloodedgg. visiting node FM, step 1.c
Mc(FM ) = Mmammal . step 1.d loops once, = flion; mammalg. Recall
FM knowledge base

female
male

, mammal; male
, mammal; female

3. Note difference f;g, set one model - model assigns
atoms, ;, set contains models.

38

false



fiA Hierarchy Tractable Subsets

Acyclic-All-Stable()

Input: knowledge base .
Output: set stable models .
1. Traverse G bottom up. node s, do:
(a) Ms := ;;
(b) Let s1 ; :::; sj children s.
(c) j = 0, Mc(s) := f;g;
else Mc(s) := CartesProd(fMs1 ; :::; Msj g);
(d) 2 Mc(s) , do:
i. sm := Convert(s ; m; s);
ii. := All-Stable(sm );

iii. 6= ;, Ms := Ms CartesProd(ffmg; g);
2. Output CartesProd(fMs1 ; :::; Msk g), s1 ; :::; sk sinks G .
Figure 7: Algorithm Acyclic-All-Stable (AAS)
CartesProd(M)
Input: set sets models M.
Output: set models consistent portion Cartesian product
sets M.
1. single element fE g, return E ;
2. := ;;
3. Let 0 2 M;
4. := CartesProd(M n fM 0g);
5. D, do:
(a) 0 , do:

consistent, := fm + dg;
(b) EndFor;
6. EndFor;
7. Return ;
Figure 8: Procedure CartesProd
39

fiBen-Eliyahu
executing step 1.d.i, FM set

female
male

, male
, female

knowledge base two stable models: ffemaleg fmaleg. Cartesian
product set flion; mammalg yields MFM = fflion; mammal; femaleg;
flion; mammal; malegg. step 2, Cartesian product Mwarm blooded , Mon land,
MFM taken. Thus, algorithm outputs fflion; mammal; land; warm blooded; femaleg,
flion; mammal; land; warm blooded; malegg, indeed two stable models
0 . Note algorithm AAS ecient either All-Stable1 All-Stable2
knowledge base 0 .

Theorem 4.2 Algorithm AAS correct, is, stable model knowledge base
iff generated AAS applied .
Proof: Let s0; s1; :::; sn ordering nodes super dependency graph

algorithm executed. show induction AAS, node
si, generates stable models portion knowledge base composed
rules use atoms Asi .
case = 0: case, step 1.d.ii AAS, sm = s; thus, claim follows
correctness algorithm All-Stable called step 1.d.ii.
case > 0: Showing every model generated stable straightforward, induction hypothesis Theorem 2.2. direction is: suppose stable model
; show generated. Clearly, child si , projection
onto stable model part knowledge base uses atoms
As. induction, mc , projection onto union every
child si , must belong Mc(si ) computed step 1.c. Therefore, show
generated, need show m0 = , mc stable model simc .
easily done using Theorem 2.2.
analyze complexity AAS. First, given knowledge base
set atoms s, define ^ knowledge base obtained deleting
negative occurrence atom belong body every rule.
example, = fa ,not b; c ,not d; ag = fbg, ^ = fa ,not b; c ,ag.
visiting node execution AAS, compute step 1.d.ii
stable models knowledge base sm . Using either All-Stable1 All-Stable2,
estimated time required find stable models sm shorter equal
time required find stable models ^ . occurs number negative
atoms number rules negative atoms bodies ^ higher
equal number negative atoms number rules negative atoms
bodies sm , regardless is. Thus, ^ Horn knowledge base,
find stable model ^ , hence sm , polynomial time, matter is.
40

fiA Hierarchy Tractable Subsets
^ positive, find stable models ^ , hence sm , time
min(ln 2k ; ln 2c ), l length ^ , n number atoms used ^ , c
number rules ^ contain negative atoms, k number atoms appear
negatively ^ .
Then, knowledge base , associate number follows. Associate
number vs every node G . ^ Horn knowledge base, vs 1; else, vs
min(2k ; 2c), c number rules ^ contain negative atoms s,
k number atoms appear negatively ^ . associate number ts
every node s. leaf node, ts = vs . children s1 ; :::; sj G ,
ts = vs ts1 ::: tsj . Define ts1 ::: tsk , s1 ; :::; sk sink nodes
G .
Definition 4.3 knowledge base belongs
j = j .
Theorem 4.4 knowledge base belongs
j j , j stable
models computed time O(lnj ).
Proof: induction j . dependency graph super dependency graph
built time linear size knowledge base. may consider
time takes compute stable models super dependency graph given.
case j = 1: 2
1 means every node G, ^ Horn knowledge base.
words, stratified, therefore exactly one stable model.
n nodes graph. node, loop step 1.d executed
once, one model generated every node. Procedure Convert runs
time O(ls), ls length (we assume stored array
access atom constant time). Since, every node s, ^
Horn knowledge base, sm computed time O(lsn). Thus, overall complexity
O(ln).
case j > 1: induction n, number nodes super dependency graph .
case n = 1: Let single node G . Thus, j = vs. Using algorithms
Section 3, stable models = found time O(lnvs ),
vs models.
case n > 1: Assume without loss generality G single sink (to get
single sink, add program rule P , s1 ; ::; sk, s1 ; :::; sk
sinks P new atom). Let c1 ; :::; ck children s.
child ci , (ci ), part knowledge base corresponds subgraph
rooted ci, must belong
ti ti j . induction n,
child node ci, stable models (ci ) computed time O(lnti ),
(ci) ti stable models. let us observe happens AAS
visiting node s. First, Cartesian product models computed
child nodes taken. executed time O(n t1 ::: tk), yields
t1 ::: tk models Mc(s) . every 2 Mc(s) , call Convert (O(ln))
compute stable models sm (O(lnvs)). combine
using CartesProd (O(nvs )). Thus, overall complexity computing Ms ,
is, computing stable models , O(lnt1 ::: tk vs ) = O(lnj ).
41

fiBen-Eliyahu

Note stratified knowledge bases belong
1 , knowledge
base looks stratified, ecient algorithm AAS be.
Given knowledge base , easy find minimum j belongs
j .
follows building G finding c k every node G polynomialtime tasks. Hence,
Theorem 4.5 Given knowledge base , find minimum j belongs

j polynomial time.
Example 4.6 nodes G0 except FM, vs =1. vFM = 2. Thus, 0 2
2. 1
stratified knowledge base therefore belongs
1.



male


female
warm_blood

on_land
mammal

lion

fly




ab1
dolphin

bird

ab2

penguin



Figure 9: super dependency graph 0 1
next example shows step 5 procedure CartesProd necessary.
Example 4.7 Consider knowledge base 4:
, b
b ,

c

e
f

,
,
,
,

42


b
c;
c

fiA Hierarchy Tractable Subsets

f

e

c







b


Figure 10: Super dependency graph 4





c

c








b

b





(1)

(2)

Figure 11: Dependency graph (1) super dependency graph (2) 2
43

fiBen-Eliyahu
super dependency graph 4 shown Figure 10. run algorithm AAS,
Mab (the set models computed node fa; bg) set ffa; :bg; f:a; bgg. AAS
visits nodes c d, get Mc = ffa; :b; cg; f:a; bgg, Md = ff:a; b; dg; fa; :bgg.
AAS visits node e, CartesProd called input fMc ; Mdg, yielding output =
ffa; :b; cg; f:a; b; dgg. Note CartesProd output model c
true, models fa; :b; cg f:a; b; dg inconsistent CartesProd
checks consistency step 5. visiting node f , get Mf = ffa; :b; c; f g; f:a; bgg.
AAS returns CartesProd(fMe; Mf g), ffa; :b; c; f g; f:a; b; dgg.
next example demonstrates models generated nodes super dependency graph run AAS may later deleted, since cannot
completed stable model whole knowledge base.

Example 4.8 Consider knowledge base 2:

b
c

, b
,
, a; c

dependency graph super dependency graph 2 shown Figure 11.
run algorithm AAS, Mab (the set models computed node fa; bg)
set ffag; fbgg. However, fbg stable model 2 .
Despite deficiency illustrated Example 4.8, algorithm AAS desirable
features. First, AAS enables us compute stable models modular fashion. use
G structure store stable models. knowledge base changed,
need resume computation nodes affected change. example,
suppose computing stable models knowledge base 0 , add toS 0
knowledge base 1 Example 2.6, gives us new knowledge base, 3 = 0 1.
super dependency graph new knowledge base 3 shown Figure 9.
need compute stable models nodes penguin, bird, ab2, y, land
combine models generated sinks. re-compute
stable models nodes well.
Second, using AAS algorithm, always compute stable models
root node. queried atom somewhere middle
graph, often enough compute models subgraph rooted
node represents atom. example, suppose given knowledge base
2 asked mammal true every stable model 2 . run AAS
nodes dolphin, lion, mammal | stop. mammal true stable
models computed node mammal (i.e., models Mmammal ), answer
\yes", otherwise, must continue computation.
Third, AAS algorithm useful computing labeling TMS subject
nogoods. set nodes TMS declared nogood, means acceptable
labeling assign false least one node nogood set.4 stable models
terminology, means handling nogoods, look stable models
4. logic programming terminology nogoods simply integrity constraints.

44

fiA Hierarchy Tractable Subsets
least one atom nogood false. straightforward approach would first
compute stable models choose ones comply nogood
constraints. since AAS algorithm modular works bottom up,
many cases prevent generation unwanted stable models early stage.
computation, exclude submodels comply nogood
constraints erase submodels Ms node super
dependency graph includes members certain nogood.

5. Computing Stable Models First-Order Knowledge Bases
section, show generalize algorithm AAS find stable
models knowledge base first-order language function symbols. new
algorithm called First-Acyclic-All-Stable (FAAS).
refer knowledge base set rules form

C ,A1; A2; :::; Am; B1; :::; Bn

(14)

As, B s, C atoms first-order language function symbols.
definitions head, body, positive negative appearances atom
propositional case. expression p(X1; :::; Xn), p called predicate name.
propositional case, every knowledge base associated directed graph
called dependency graph , (a) predicate name node, (b)
positive arc directed node p node q iff rule
p predicate name one Ai q predicate name head, (c)
negative arc directed node p node q iff rule
p predicate name one Bi q predicate name head. super
dependency graph, G , defined analogous manner. define stratified knowledge
base knowledge base cycles negative edges
dependency graph knowledge base.
knowledge base called safe iff rules safe. rule safe iff
variables appearing head rule predicates appearing negative rule
also appear positive predicates body rule. section, assume
knowledge bases safe. Herbrand base knowledge base set atoms
constructed using predicate names constants knowledge base. set
ground instances rule set rules obtained consistently substituting variables
rule constants appear knowledge base possible ways.
ground instance knowledge base union ground instances rules. Note
ground instance first-order knowledge base viewed propositional
knowledge base.
model knowledge base subset knowledge base's Herbrand base.
subset property every rule grounded knowledge base,
atoms appear positive body rule belong atoms
appear negative body rule belong , atom head
rule belongs . stable model first-order knowledge base Herbrand
model , also stable model grounded version .
45

fiBen-Eliyahu

First-Acyclic-All-Stable()

Input: first-order knowledge base .
Output: stable models .
1. Traverse G bottom up. node s, do:
(a) Ms := ;;
(b) Let s1 ; :::; sj children s;
(c) Mc(s) := CartesProd(fMs1 ; :::; Msj g);
(d) 2 Mc(s)
Ms := MsSall-stable(s SfP ,jP 2 mg)
2. Output CartesProd(fMs1 ; :::; Msk g), s1 ; :::; sk sinks G .
Figure 12: Algorithm First-Acyclic-All-Stable (FAAS)
present FAAS, algorithm computes stable models first-order
knowledge base. Let first-order knowledge base. propositional case,
node G (the super dependency graph ), associate , , Ms .
subset containing rules predicates whose names s.
set predicate names P appear subgraph G rooted s. Ms
stable models associated sub{knowledge base contains rules
predicates whose names . Initially, Ms empty every s. Algorithm FAAS
traverses G bottom up. node s, algorithm first combines
submodels children single set models, Mc(s) . Then, model
Mc(s), calls procedure finds stable models union set
unit clauses P , P 2 m. procedure All-Stable called FAAS
procedure computes stable models first-order knowledge base.
procedure All-Stable computes stable models parts knowledge base,
may take advantage fractions knowledge base stratified
property simplifies computation stable models fraction.

Theorem 5.1 Algorithm FAAS correct, is, stable model knowledge base
iff one models output applying FAAS .

Proof: proof Theorem 4.2.

Note knowledge base appears stratified, ecient algorithm
FAAS becomes.

Example 5.2 Consider knowledge base 5:
warm blooded(X )
live land(X )
female(X )

, mammal(X )
, mammal(X ); ab1(X )
, mammal(X ); male(X )
46

fiA Hierarchy Tractable Subsets
male(X )
mammal(X )
ab1(X )
mammal(X )
dolphin(flipper)

,
,
,
,
,

mammal(X ); female(X )
dolphin(X )
dolphin(X )
lion(X )

, bird(X )
, bird(X ); ab2(X )
, penguin(X )
, penguin(X )
,
super dependency graph 5 , G5 , super dependency graph
live land(X )
fly (X )
bird(X )
ab2(X )
bird(bigbird)

knowledge base 2 (see Figure 9). Observe node mammal, example,

step 1.d algorithm looks stable models knowledge base 0 = mammal
f ,dolphin(flipper)g, mammal =fmammal(X ) ,dolphin(X ); mammal(X ) ,lion(X )g.
0 stratified knowledge base unique stable model found eciently.
Hence, algorithm FAAS saves us ground rules knowledge base
starting calculate models, take advantage parts knowledge
base stratified.

6. Related Work

recent years, quite algorithms developed reasoning stable models.
Nonetheless, far know, work presented original sense
provides partition set knowledge bases hierarchy tractable
classes. partition based structure dependency graph. Intuitively,
task computing stable models knowledge base using algorithm AAS becomes
increasingly complex \distance" knowledge base stratified becomes
larger. Next, summarize work seems us relevant.
Algorithm AAS based idea appears work Lifschitz Turner
(1994), show many cases logic program divided two parts,
one part, \bottom" part, refer predicates defined \top"
part. explain task computing stable models program
simplified program split parts. Algorithm AAS, using superstructure
dependency graph, exploits specific method splitting program.
Bell et al. (1994) Subrahmanian et al. (1995) implement linear integer programming techniques order compute stable models (among nonmonotonic logics). However, dicult assess merits approaches terms complexity.
Ben-Eliyahu Dechter (1991) illustrate knowledge base translated
propositional theory model latter corresponds stable model
former. follows problem finding stable models
knowledge base corresponds problem finding models propositional
theory. Satoh Iwayama (1991) provide nondeterministic procedure computing
47

fiBen-Eliyahu
stable models logic programs integrity constraints. Junker Konolige (1990)
present algorithm computing TMS' labels. Antoniou Langetepe (1994) introduce
method representing classes default theories normal logic programs
way SLDNF-resolution used compute extensions. Pimentel Cuadrado
(1989) develop label-propagation algorithm uses data structures called compressible
semantic trees order implement TMS; algorithm based stable model semantics. algorithms developed Marek Truszczynski (1993) autoepistemic
logic also adopted computing stable models. procedures Marek
Truszczynski (1993), Antoniou Langetepe (1994), Pimentel Cuadrado (1989), BenEliyahu Dechter (1991), Satoh Iwayama (1991), Bell et al. (1994), Subrahmanian
et al. (1995), Junker Konolige (1990) take advantage structure
knowledge base ected dependency graph, therefore ecient
stratified knowledge bases.
Sacca Zaniolo (1990) present backtracking fixpoint algorithm constructing one
stable model first-order knowledge base. algorithm similar algorithm AllStable2 presented Section 3 complexity worse complexity
All-Stable2. show backtracking fixpoint algorithm modified
handle stratified knowledge bases ecient manner, algorithm needs
adjustments deal eciently knowledge bases close
stratified. Leone et al. (1993) present improved backtracking fixpoint algorithm
computing one stable model Datalog: program discuss improved algorithm
implemented. One procedures called improved algorithm based
backtracking fixpoint algorithm Sacca Zaniolo (1990). Like backtracking
fixpoint algorithm, improved algorithm take advantage structure
program, i.e., ecient programs close stratified.
Several tractable subclasses computing extensions default theories (and, hence,
computing stable models) known (Kautz & Selman, 1991; Papadimitriou & Sideri,
1994; Palopoli & Zaniolo, 1996; Dimopoulos & Magirou, 1994; Ben-Eliyahu & Dechter,
1996). tractable subclasses characterized using graph ects
dependencies program atoms rules. algorithms presented
papers complete subclass knowledge bases, however. Algorithms
computing extensions stratified default theories extensions default theories
odd cycles (in precise sense) given Papadimitriou Sideri (1994)
Cholewinski (1995a, 1995b).
Algorithms handling TMS nogoods developed AI community Doyle (1979) Charniak et al. (1980). But, Elkan (1990) points out,
algorithms always faithful semantics TMS complexities
analyzed. Dechter Dechter (1994) provide algorithms manipulating TMS
represented constraint network. eciency algorithms depends
structure constraint network representing TMS, structure
employ differs dependency graph knowledge base.
48

fiA Hierarchy Tractable Subsets

7. Conclusion
task computing stable models heart several systems central AI,
including TMSs, autoepistemic logic, default logic. task shown
NP-hard. paper, present partition set knowledge bases classes

1 ;
2; :::, knowledge base
k , k stable models,
may found time O(lnk), l length knowledge base
n number atoms . Moreover, arbitrary knowledge base , find
minimum k belongs
k time linear size . Intuitively,
knowledge base stratified, ecient algorithm becomes. believe
beyond stratified knowledge bases, expressive knowledge base (i.e.
rules nonstratified negation knowledge base), less likely needed.
Hence, analysis quite useful. addition, show algorithm AAS
several advantages dynamically changing knowledge base, provide applications
answering queries implementing TMS's nogood strategies. also illustrate
generalization algorithm AAS class first-order knowledge bases.
Algorithm AAS easily adjusted find one stable model knowledge
base. traversing super dependency graph, generate one model
node. arrive node cannot generate model based
computed far, backtrack recent node several models available
choose take next model yet chosen. worst-case time
complexity algorithm equal worst-case time complexity algorithm
finding stable models may exhaust possible ways generating
stable model finding certain knowledge base stable model
all. Nevertheless, believe average case, finding one model
easier finding all. similar modification AAS algorithm required
interested finding one model one particular atom gets value true.
work another attempt bridge gap declarative systems (e.g.,
default logic, autoepistemic logic) procedural systems (e.g., ATMs, Prolog)
nonmonotonic reasoning community. argued declarative methods
sound, impractical since computationally expensive, procedural methods ecient, dicult completely understand performance
evaluate correctness. work presented illustrates declarative
procedural approaches combined yield ecient yet formally supported
nonmonotonic system.

Acknowledgments
Thanks Luigi Palopoli useful comments earlier draft paper Michelle
Bonnice Gadi Dechter editing parts manuscript. Many thanks
anonymous referees useful comments.
work done author visiting Cognitive Systems Laboratory, Computer Science Department, University California, Los Angeles, California,
USA. work partially supported NSF grant IRI-9420306 Air Force Oce
Scientific Research grant #F49620-94-1-0173.
49

fiBen-Eliyahu

References

Antoniou, G., & Langetepe, E. (1994). Soundness completeness logic programming
approach default logic. AAAI-94: Proceedings 12th national conference
artificial intelligence, pp. 934{939. AAAI Press, Menlo Park, Calif.
Apt, K., Blair, H., & Walker, A. (1988). Towards theory declarative knowledge.
Minker, J. (Ed.), Foundations deductive databases logic programs, pp. 89{148.
Morgan Kaufmann.
Bell, C., Nerode, A., Ng, R., & Subrahmanian, V. (1994). Mixed integer programming
methods computing non-monotonic deductive databases. Journal ACM,
41 (6), 1178{1215.
Ben-Eliyahu, R., & Dechter, R. (1994). Propositional semantics disjunctive logic programs. Annals Mathematics Artificial Intelligence, 12, 53{87. short version
appears JICSLP-92: Proceedings 1992 joint international conference
symposium logic programming.
Ben-Eliyahu, R., & Dechter, R. (1996). Default reasoning using classical logic. Artificial
Intelligence, 84 (1-2), 113{150.
Bidoit, N., & Froidevaux, C. (1987). Minimalism subsumes default logic circumscription
stratified logic programming. LICS-87: Proceedings IEEE symposium
logic computer science, pp. 89{97. IEEE Computer Science Press, Los Alamitos,
Calif.
Charniak, E., Riesbeck, C. K., & McDermott, D. V. (1980). Artificial Intelligence Programming, chap. 16. Lawrence Erlbaum, Hillsdale, NJ.
Cholewinski, P. (1995a). Reasoning stratified default theories. Marek, W. V.,
Nerode, A., & Truszczynski, M. (Eds.), Logic programming nonmonotonic reasoning: proceedings 3rd international conference, pp. 273{286. Lecture notes
computer science, 928. Springer-Verlag, Berlin.
Cholewinski, P. (1995b). Stratified default theories. Pacholski, L., & Tiuryn, A. (Eds.),
Computer science logic: 8th workshop, CSL'94: Selected papers, pp. 456{470. Lecture
notes computer science, 933. Springer-Verlag, Berlin.
Dechter, R., & Dechter, A. (1996). Structure-driven algorithms truth maintenance.
Artificial Intelligence, 82 (1-2), 1{20.
Dimopoulos, Y., & Magirou, V. (1994). graph-theoretic approach default logic. Journal
Information Computation, 112, 239{256.
Doyle, J. (1979). truth-maintenance system. Artificial Intelligence, 12, 231{272.
Dung, P. M. (1991). Negation hypothesis: abductive foundation logic programming. Furukawa, K. (Ed.), ICLP-91: Proceedings 8th international conference
logic programming, pp. 3{17. MIT Press.
50

fiA Hierarchy Tractable Subsets
Elkan, C. (1990). rational reconstruction nonmonotonic truth maintenance systems.
Artificial Intelligence, 43, 219{234.
Eshghi, K., & Kowalski, R. A. (1989). Abduction compared negation failure. Levi,
G., & Martelli, M. (Eds.), ICLP-89: Proceedings 6th international conference
logic programming, pp. 234{254. MIT Press.
Fine, K. (1989). justification negation failure. Logic, Methodology Philosophy
Science, 8, 263{301.
Gelfond, M. (1987). stratified autoepistemic theories. AAAI-87: Proceedings
5th national conference artificial intelligence, pp. 207{211. Morgan Kaufmann.
Gelfond, M., & Lifschitz, V. (1988). stable model semantics logic programming.
Kowalski, R. A., & Bowen, K. A. (Eds.), Logic Programming: Proceedings 5th
international conference, pp. 1070{1080. MIT Press.
Gelfond, M., & Lifschitz, V. (1991). Classical negation logic programs disjunctive
databases. New Generation Computing, 9, 365{385.
Junker, U., & Konolige, K. (1990). Computing extensions autoepistemic default logics TMS. AAAI-90: Proceedings 8th national conference
artificial intelligence, pp. 278{283. AAAI Press.
Kakas, A. C., & Mancarella, P. (1991). Stable theories logic programs. Saraswat,
V., & Udea, K. (Eds.), ISLP-91: Proceedings 1991 international symposium
logic programming, pp. 85{100. MIT Press.
Kautz, H. A., & Selman, B. (1991). Hard problems simple default logics. Artificial
Intelligence, 49, 243{279.
Leone, N., Romeo, N., Rullo, M., & Sacca, D. (1993). Effective implementation negation
database logic query languages. Atzeni, P. (Ed.), LOGIDATA+: Deductive
database complex objects, pp. 159{175. Lecture notes computer science, 701.
Springer-Verlag, Berlin.
Lifschitz, V., & Turner, H. (1994). Splitting logic program. Van Hentenryck, P. (Ed.),
ICLP-94: Proceedings 11th international conference logic programming, pp.
23{37. MIT Press.
Marek, V. W., & Truszczynski, M. (1993). Nonmonotonic logic: Context-dependent reasoning. Springer Verlag, Berlin.
Marek, W., & Truszczynski, M. (1991). Autoepistemic logic. Journal ACM, 38,
588{619.
Moore, R. C. (1985). Semantical consideration nonmonotonic logic. Artificial Intelligence, 25, 75{94.
Palopoli, L., & Zaniolo, C. (1996). Polynomial-time computable stable models.. Annals
Mathematics Artificial Intelligence, press.
51

fiBen-Eliyahu
Papadimitriou, C. H., & Sideri, M. (1994). Default theories always extensions.
Artificial Intelligence, 69, 347{357.
Pimentel, S. G., & Cuadrado, J. L. (1989). truth maintenance system based stable
models. Lusk, E. L., & Overbeek, R. A. (Eds.), ICLP-89: Proceedings 1989
North American conference logic programming, pp. 274{290. MIT Press.
Przymusinska, H., & Przymusinski, T. (1990). Semantic issues deductive databases
logic programs. Banerji, R. B. (Ed.), Formal techniques artificial intelligence:
sourcebook, pp. 321{367. North-Holland, New York.
Reiter, R. (1980). logic default reasoning. Artificial Intelligence, 13, 81{132.
Sacca, D., & Zaniolo, C. (1990). Stable models non-determinism logic programs
negation. PODS-90: Proceedings 9th ACM SIGACT-SIGMOD-SIGART
symposium principles database systems, pp. 205{217. ACM Press.
Satoh, K., & Iwayama, N. (1991). Computing abduction using TMS. Furukawa, K.
(Ed.), ICLP-91: Proceedings 8th international conference logic programming,
pp. 505{518. MIT Press.
Subrahmanian, V., Nau, D., & Vago, C. (1995). WFS + branch bound = stable models.
IEEE Transactions Knowledge Data Engineering, 7 (3), 362{377.
Tarjan, R. (1972). Depth-first search linear graph algorithms. SIAM Journal
Computing, 1, 146{160.

52

fi
