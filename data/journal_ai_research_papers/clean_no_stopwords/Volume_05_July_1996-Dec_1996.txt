Journal Artificial Intelligence Research 5 (1996) 139-161Submitted 4/96; published 10/96Learning First-Order Definitions FunctionsJ. R. Quinlanquinlan@cs.su.oz.auBasser Department Computer ScienceUniversity SydneySydney 2006 AustraliaAbstractFirst-order learning involves finding clause-form definition relation examplesrelation relevant background information. paper, particular first-orderlearning system modified customize finding definitions functional relations.restriction leads faster learning times and, cases, definitionshigher predictive accuracy. first-order learning systems might benefit similarspecialization.1. IntroductionEmpirical learning subfield AI develops algorithms constructing theoriesdata. classification research area used attribute-value formalism,data represented vectors values fixed set attributes labelledone small number discrete classes. learning system develops mappingattribute values classes used classify unseen data.Despite well-documented successes algorithms developed paradigm (e.g.,Michie, Spiegelhalter, Taylor, 1994; Langley Simon, 1995), potentialapplications learning fit within it. Data may concern objects observationsarbitrarily complex structure cannot captured values predeterminedset attributes. Similarly, propositional theory language employed attribute-valuelearners may inadequate express patterns structured data. Instead, maynecessary describe learning input relations, relation set tuplesconstants, represent learned first-order language. Four examplespractical learning tasks kind are:Speeding logic programs (Zelle Mooney, 1993). idea learnguard nondeterministic clause inhibits execution unless leadsolution. Input learner consists Prolog program oneexecution traces. one example Dolphin, system cited above, transformedprogram complexity O(n!) O(n2 ).Learning search control heuristics (Leckie Zukerman, 1993). Formulation pref-erence criteria improve eciency planning applications similar avor.One task investigated familiar `blocks world' varying numbersblocks must rearranged robot manipulator. input learning concernsparticular situation search includes complete description current planning state goals. amount information increasesc 1996 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiQuinlannumber blocks inter-relationships, cannot encoded fixed setvalues.Recovering software specifications. Cohen (1994) describes application basedsoftware system consisting million lines C code. Part system implements virtual relations compute projections joins underlying baserelations, goal reconstruct definitions. Input learning consistsqueries, responses, traces showing base relations accessed answering queries. output logical description virtual relation; sinceinvolves quantified variables, lies beyond scope propositional attribute-valuelanguages.Learning properties organic molecules (Muggleton, King, Sternberg, 1992;Srinivasan, Muggleton, Sternberg, King, 1996). approach learningpapers based representing structure moleculesaddition properties molecules molecule segments. latter paper notesdiscovery useful indicator mutagenicity expressed terms structure.development learning methods based powerful relational formalismsometimes called inductive logic programming (Muggleton, 1992; Lavrac Dzeroski,1994; De Raedt, 1996). Input typically consists tuples belong, belong,target relation, together relevant information expressed set backgroundrelations. learning task formulate definition target relation termsbackground relations.relational learning task described detail following section. Severalalgorithms relational learning developed recently, Section 3 introducesone system called foil (Quinlan, 1990). foil used relationskind, one particularly common use relations represent functions. Changesfoil effect customize learning functional relations outlined Section 4.Several comparative studies, presented Section 5, show specialization leadsmuch shorter learning times and, cases, accurate definitions. Related worklearning functional relations discussed Section 6, paper endsconclusions study directions development.2. Relational Learningn-ary relation consists set n-tuples ground terms (here constants).constants ith position tuples belong type, types may differentiated constants may taken belong single universal type.alternative extensional definition (possibly infinite) set, relationspecified intensionally via n-argument predicate RI defined Prolog program.hc1 ; c2 ; :::cn 2 RI (c1 ; c2 ; :::; cn ) trueconstants fci g, intensional extensional definitions equivalent.convenience, subscripts RI omitted R used denoteeither set tuples predicate.140fiLearning First-Order Definitions FunctionsInput relational learning task consists extensional information targetrelation R extensional intensional definitions collection background relations.Examples tuples known belong target relation provided and, cases,examples tuples known belong R. goal learn Prolog programR covers tuples known belong R tuples known belong Ror, words, program agrees extensional information providedR.Many relations interest infinite. alternative selecting examples belongbelong R define finite vocabulary V specify relations respectvocabulary. is, R represented finite set tuples, constantsbelong V . Since specification R complete vocabulary, tuplesbelong R inferred closed world assumption complementtuples R.function f (X1 ; X2 ; :::; Xk ) k arguments represented k+1-ary relationF (X1 ; X2 ; :::; Xk ; Xk+1 ) where, tuple F , value last argumentresult applying f first k arguments. (Rouveirol (1994) proves atteningused remove non-constant function symbols first-order language.)functional relations additional property constants fc1 ; c2 ; ::; ck gexactly one value ck+1 hc1 ; c2 ; :::; ck+1 belongs F .example, consider three-argument predicate append(A,B,C) whose meaningresult appending list list B list C.1 corresponding relation appendinfinite, restricted vocabulary defined lists containing elementsf1,2,3g whose length less equal 3. 40 lists[ ], [1], [2], [3], [1,2], ...., [3,3,2], [3,3,3]64,000 3-tuples lists. respect vocabulary, append consists 1423-tuples, viz.:h[ ],[ ],[ ]i, h[ ],[1],[1]i, ..., h[2],[1,3],[2,1,3]i, ..., h[3,3,3],[ ],[3,3,3]i.also background relation components, components(A,B,C) means listhead B tail C. goal learn intensional definition append givenbackground relation components. suitable result might expressedappend([ ],A,A).append(A,B,C) :- components(A,D,E), append(E,B,F), components(C,D,F).recognizable Prolog definition append.1. Prolog, append invoked combination arguments bound find possiblevalues unbound arguments. Section 5.1, however, append treated functionfirst two arguments third.141fiQuinlanInitialization:definition := null programremaining := tuples belonging target relation Rremaining empty/* Grow new clause */clause := R(A; B; :::) :While clause covers tuples known belong R/* Specialize clause */Find appropriate literal(s) LAdd L body clauseRemove remaining tuples R covered clauseAdd clause definitionFigure 1: Outline foil3. Description foilcommon many first-order learning systems, foil requires background relations also defined extensionally sets tuples constants.2 Although intensionaldefinition learned particular set examples, intended executableProlog program background relations may also specified intensionallydefinitions rather sets ground tuples. instance, although append definitionmight learned particular examples lists, correctly appendarbitrary lists, provided components specified suitable clausal definition. (Theapplicability learned definitions unseen examples cannot guaranteed, however; BellWeber (1993) call open domain assumption.)language foil expresses theories restricted form Prolog omitscuts, fail, disjunctive goals, functions constants, allows negated literalsnot(L(...)). essentially Datalog language specified Ullman (1988), exceptrequirement variables negated literal appear also headanother unnegated literal; foil interprets using negation failure (Bratko, 1990).3.1 Broad-brush overviewoutlined Figure 1, foil uses separate-and-conquer method, iteratively learningclause removing tuples target relation R covered clause noneremain. clause grown repeated specialization, starting general clause2. Prominent exceptions include focl (Pazzani Kibler, 1992), filp (Bergadano Gunetti, 1993),Foidl (Mooney Califf, 1995), allow background relations defined extensionally,Progol (Muggleton, 1995), information relations non-ground form.142fiLearning First-Order Definitions Functionshead adding literals body clause cover tuples knownbelong R.Literals appear body clause restricted requirementprograms function-free, constants appearing equalities. possibleliteral forms foil considers are:Q(X1 ; X2 ; :::; Xk ) (Q(X1 ; X2 ; :::; Xk )), Q relation Xi's de-note known variables bound earlier clause new variables.least one variable must bound earlier partial clause, eitherhead literal body.Xi =Xj Xi 6=Xj , known variables Xi Xj type.Xi =c Xi6=c, Xi known variable c constant appropriatetype. constants designated suitable appear definitionconsidered { reasonable definition append might reference null list [ ]arbitrary list [1,2].Xi Xj , Xi > Xj , Xi t, Xi > t, Xi Xj known variablesnumeric values threshold chosen foil.learned definition must pure Prolog, negated literal forms (Q(:::)) Xi 6=...excluded option.Clause construction guided different possible bindings variables partialclause satisfy clause body. clause contains k variables, binding k-tupleconstants specifies value variables sequence. possible bindinglabelled according whether tuple values variables clause headbelong target relation.illustration, consider tiny task constructing definition plus(A,B,C),meaning A+B = C, using background relation dec(A,B), denoting B = A,1.vocabulary restricted integers 0, 1, 2, plus consists tuplesh0,0,0i, h1,0,1i, h2,0,2i, h0,1,1i, h1,1,2i, h0,2,2idec contains h1,0i h2,1i.initial clause consists headplus(A,B,C) :-variable unique. labelled bindings corresponding initial partialclause tuples belong, belong, target relation, i.e.:h0,0,0ih0,0,1ih1,0,0ih1,2,2ih2,2,0ih1,0,1ih0,0,2ih1,0,2ih2,0,0ih2,2,1ih2,0,2ih0,1,0ih1,1,0ih2,0,1ih2,2,2ih0,1,1ih0,1,2ih1,1,1ih2,1,0i143h1,1,2ih0,2,0ih1,2,0ih2,1,1ih0,2,2ih0,2,1ih1,2,1ih2,1,2i.fiQuinlanfoil repeatedly tries construct clause covers tuples target relationR tuples definitely R. restated finding clausebindings bindings, one reason adding literal clausemove direction increasing relative proportion bindings. gainfulliterals evaluated using information-based heuristic. Let numberbindings partial clause n n respectively. average information provideddiscovery one bindings label!n(n ; n ) = , log2 n + n bits.literal L added, bindings may excluded rest giverise one bindings new partial clause. Suppose k n bindingsexcluded L, numbers bindings new partial clauserespectively. L chosen increase proportion bindings, totalinformation gained adding Lk (I (n; n ) , (m ; )) bits.Consider result specializing clause addition literal A=0.nine bindings eliminated corresponding values variablessatisfy new partial clause. bindings reducedh0,0,0i h0,1,1i h0,2,2ih0,0,1i h0,0,2i h0,1,0i h0,1,2i h0,2,0i h0,2,1iproportion bindings increased 6/27 3/9. informationgained adding literal therefore 3 (I (6; 21) , (3; 6)) 2 bits. Addingliteral B=C excludes bindings, giving complete first clauseplus(A,B,C) :- A=0, B=C.or, would commonly written,plus(0,B,B).clause covers three tuples plus removed set tuplescovered subsequent clauses. commencement search second clause,head plus(A,B,C) bindingsh1,0,1ih0,0,1ih1,0,0ih1,2,2ih2,2,0ih2,0,2ih0,0,2ih1,0,2ih2,0,0ih2,2,1ih1,1,2ih0,1,0i h0,1,2i h0,2,0i h0,2,1ih1,1,0i h1,1,1i h1,2,0i h1,2,1ih2,0,1i h2,1,0i h2,1,1i h2,1,2ih2,2,2i.literals added body first clause gain information. quite different justification adding literal introduce new variablesmay needed final clause. Determinate literals based idea introduced144fiLearning First-Order Definitions FunctionsGolem (Muggleton Feng, 1992). determinate literal one introduces newvariables new partial clause exactly one binding bindingcurrent clause, one binding binding. Determinate literals useful introduce new variables, neither reduce potential coverageclause increase number bindings.bindings include A=0, literal dec(A,D) determinatebecause, value A, one value satisfies literal. Similarly, sincebindings contain none C=0, literal dec(C,E) also determinate.Figure 1, literals L added foil stepliteral greatest gain, gain near maximum possible(namely n (n ; n )) ; otherwisedeterminate literals found; otherwiseliteral highest positive gain; otherwisefirst literal investigated introduces new variable.start second clause, literal near-maximum gain determinateliterals added clause body. partial clauseplus(A,B,C) :- dec(A,D), dec(C,E),five variables bindings satisfyh1,0,1,0,0i h2,0,2,1,1i h1,1,2,0,1ih1,0,2,0,1i h1,1,1,0,0i h2,0,1,1,0i h2,1,1,1,0i h2,1,2,1,1iliteral plus(B,D,E), uses newly-introduced variables, satisfiedthree bindings none bindings, giving complete second clauseplus(A,B,C) :- dec(A,D), dec(C,E), plus(B,D,E).tuples plus covered one clauses, constitute completeintensional definition target relation.3.2 Details omittedfoil good deal complex overview would suggest. Sinceimportant paper, matters following discussed here,covered (Quinlan Cameron-Jones, 1993; 1995):Recursive soundness. goal able execute learned definitionsordinary Prolog programs, important terminate. foil elaboratemechanism ensure recursive literal (such plus(B,D,E) above)added clause body cause problems respect, least groundqueries.145fiQuinlanPruning. practical applications numerous background relations, numberpossible literals L could added step grows exponentiallynumber variables partial clause. foil employs heuristics limitspace, Golem's bound depth variable (Muggleton Feng,1992). importantly, regions literal space pruned withoutexamination shown contain neither determinate literals,literals higher gain best gainful literal found far.complete search. presented above, foil straightforward greedy hillclimbing algorithm. fact, foil sometimes reach impassesearch clause, contains limited non-chronological backtracking facilityallow recover situations.Simplifying definitions. addition partial clause determinate literalsfound may seem excessive. However, clause completed, foil examinesliteral clause body see whether could discarded without causingsimpler clause match tuples target relation R. Similarly,definition complete, clause checked see whether could omittedwithout leaving tuples R uncovered. also heuristics aimmake clauses understandable substituting simpler literals (such variableequalities) literals based complex relations.Recognizing boundaries closed worlds. literals appear discriminatebindings consequence boundary effects attributablelimited vocabulary.3 definition including literals executed largervocabularies, open domain assumption mentioned may violated. foilcontains optional mechanism describing literals might satisfiedbindings outside closed world, allowing literals unpredictable behaviorexcluded.Quinlan (1990) Quinlan Cameron-Jones (1995) summarize several applicationssuccessfully addressed foil, also discussed Section 5.4. Learning Functional Relationslearning approach used foil makes assumptions form targetrelation R. However, append plus above, relation often used representfunction { tuple constants satisfies R, last constant uniquely determinedothers. Bergadano Gunetti (1993) show property exploitedmake learning task tractable.4.1 Functional relations foilAlthough foil learn definitions functional relations, handicapped two ways:Ground queries: foil's approach recursive soundness assumes groundqueries made learned definition. is, definition R(X1 ; X2 ; :::; Xn )3. example arises Section 5.1.146fiLearning First-Order Definitions Functionsused provide true-false answers queries form R(c1 ; c2 ; :::; cn )?ci 's constants. R functional relation, however, sensible querywould seem R(c1 ; c2 ; :::; cn,1 ; X )? determine value functionspecified ground arguments. case plus, instance, would expect ask plus(1,1,2)? (\is 1+1=2?"), rather plus(1,1,X)? (\what 1+1?").R(c1 ; c2 ; :::; cn,1 ; X )? called standard query functional relations.Negative examples: foil needs tuples belong target relationleast not. common ILP systems Golem (MuggletonFeng, 1992), latter used detect partial clause still general.specified foil directly or, commonly, derivedclosed world assumption that, respect vocabulary, tuples Rgiven. second mechanism often lead large collections tuplesR; nearly 64,000 append illustration earlier. Everytuple belonging R results binding start clause,uncomfortably many bindings must maintained tested stageclause development.4 However, functional relations need explicit counterexamples, even set tuples belonging R complete respectvocabulary { knowing hc1 ; c2 ; :::; cn belongs R impliesconstant c0n hc1 ; c2 ; :::; c0n R.problematic aspects foil vis vis functional relations suggest modificationsaddress them. alterations lead new system, ffoil, still close spiritprogenitor.4.2 Description ffoilSince last argument functional relation special role, referredoutput argument relation. Similarly, variable corresponding argumenthead clause called output variable.fundamental change ffoil concerns bindings partial clausesway labelled. new constant 2 introduced indicate undeterminedvalue output variable binding. Bindings labelled according valueoutput variable, namely value correct (given value earlierconstants), value incorrect, fi value undetermined.outline ffoil (Figure 2) similar Figure 1, differenceshighlighted. start clause one binding every remaining tupletarget relation. output variable value 2 bindings valuechanged subsequent literal assigns value variable. smallplus example Section 3.1, initial bindings first clauseh0,0,2i fi h1,0,2i fi h2,0,2i fi h0,1,2i fi h1,1,2i fi h0,2,2i fiLike ancestor, ffoil also assesses potential literals adding clause bodygainful determinate, although concepts must adjusted accommodate newlabel fi. Suppose r distinct constants range target function.4. reason, foil includes option sample bindings instead using them.147fiQuinlanInitialization:definition := null programremaining := tuples belonging target relation Rremaining empty/* Grow new clause */clause := R(A; B; :::) :While clause fi bindings/* Specialize clause */Find appropriate literal(s) LAdd L body clauseRemove remaining tuples R covered clauseAdd clause definitionSimplify final definitionAdd default clauseFigure 2: Outline ffoilfi binding converted binding changing 2 correct valuefunction, binding changing 2 r , 1 incorrect values.computing information gain, ffoil thus counts fi binding 1 binding r , 1bindings. determinate literal one introduces one variables that,new partial clause, exactly one binding current fi bindingone binding current binding. ffoil uses preference criterionadding literals L: literal near-maximum gain, determinate literals,gainful literal, finally non-determinate literal introduces new variable.first literal chosen foil Section 3.1 A=0 since increases concentration bindings 9 64 3 9 (with corresponding information gain).ffoil's perspective, however, literal simply reduces six fi bindings three givesgain; range plus set f0,1,2g, r = 3, putative concentrationbindings would alter 6 18 3 9. literal A=C, hand, causesvalue output variable determined results bindingsh0,0,0i h1,0,1i h2,0,2ih0,1,0i h1,1,1i h0,2,0i .corresponds increase concentration bindings notional 6 183 6, information gain 2 bits. literal addedclause body, ffoil finds literal B=0 eliminates bindings, giving148fiLearning First-Order Definitions Functionscomplete clauseplus(A,B,C) :- A=C, B=0.remaining tuples plus give bindingsh0,1,2i fi h1,1,2i fi h0,2,2i fistart second clause. literals dec(B,D) dec(E,A) determinateand, added clause, bindings becomeh0,1,2,0,1i fi h1,1,2,0,2i fi h0,2,2,1,1i fioutput variable still undetermined. partial clause specializedadding literal plus(E,D,C), new bindingsh0,1,1,0,1i h1,1,2,0,2i h0,2,2,1,1igive correct value C case. Since fi bindings, clausealso complete.One important consequence new way bindings initialized startclause easily overlooked. foil, one binding tuplebelong R; since clause excludes bindings, discriminates tuplesR tuples R. reason learned clauses regardedset executed order without changing set answers query.ffoil, however, initial bindings concern remaining tuples R, learnedclause depends context established earlier clauses. example, suppose targetrelation background relation defined= fhv,1i, hw,1i, hx,1i, hy,0i, hz,0ig= fhvi, hwi, hxig .first clause learned ffoil mightS(A,1) :- T(A).remaining bindings fhy,0i, hz,0ig could covered clauseS(A,0).latter clause clearly correct standard queries coveredfirst clause. example illustrates, learned clauses must interpreted orderlearned, clause must ended cut `!' protect laterclauses giving possibly incorrect answers query. Since target relation Rfunctional, one correct response standard query defined above,use cuts safe cannot rule correct answer.foil ffoil tend give easily learning definitions explain noisydata. result over-specialized clauses cover target relation partially.tasks definition learned ffoil incomplete, final global simplification149fiQuinlanphase invoked. Clauses definition generalized removing literals longtotal number errors target relation increase. way, accuracyindividual clauses balanced accuracy definition whole; simplifyingclause removing literal may increase number errors made clause,offset reduction number uncovered bindings consequentlylower global error rate. clauses simplified much possible, entireclauses contribute nothing accuracy definition removed.final step Figure 2, target relation assumed represent total function,consequence response must always returned standard query.safeguard, ffoil adds default clauseR(X1 ; X2 ; :::; Xn,1 ; c):c common value function.5 common value outputargument plus 2, complete definition example, normal Prolog notation,becomesplus(A,0,A) :- !.plus(A,B,C) :- dec(B,D), dec(E,A), plus(E,D,C), !.plus(A,B,2).4.3 Advantages disadvantages ffoilAlthough definitions plus Sections 3.1 4.2 superficially similar,considerable differences learning processes constructedoperational characteristics used.ffoil generally needs maintain fewer bindings learns quickly. Whereasfoil keeps 27 bindings learning definition plus, ffoil never uses6.output variable guaranteed bound every clause learned ffoil.necessarily case foil, since requirement every variableappearing head must also appear clause body.Definitions found ffoil often execute eciently foil counterparts.Firstly, ffoil definitions, use cuts, exploit fact cannotone correct answer standard query. Secondly, clause bodies constructedffoil tend use output variable bound, lessbacktracking evaluation. illustration, foil definition Section3.1 evaluates 81 goals answering query plus(1,1,X)?, many sixevaluations needed ffoil definition query.also entries side ledger:5. default clause added value function occurs once.150fiLearning First-Order Definitions FunctionsTaskBkgdRelnsappendlast elementreverseleft shifttranslate23101214Length 3BindingsTimefoil ffoil142 63,8583.039810.040 15602.639 15610.540 3120 817.9Length 4BindingsTimefoil ffoil0.5 1593 396,502 22.40.0 34010240.50.3 341 115,940 195.90.3 340 115,940 26.61.1 341 115,940 495.910.90.39.06.828.0Table 1: Results tasks (Bratko, 1990).foil applicable learning tasks ffoil, limited learningdefinitions functional relations.implementation ffoil complex foil. example, manyheuristics pruning literal search space checking recursive soundnessrequire special cases constant 2 fi bindings.5. Empirical Trialssection performance ffoil variety learning tasks summarizedcompared foil (release 6.4). Since systems similar respects,comparison highlights consequences restricting target relation function.Times DEC AXP 3000/900 workstation. learned definitions firstthree subsections may found Appendix.5.1 Small list manipulation programsQuinlan Cameron-Jones (1993) report results applying foil 16 tasks takenBratko's (1990) well-known Prolog text. list-processing examples exercisesChapter 3 attempted sequence, background information taskincludes previously-encountered relations (even though irrelevanttask hand). Two different vocabularies used: 40 lists length 3three elements 341 lists length 4 four elements.Table 1 describes five functional relations set presents performancefoil ffoil them. learned definitions correct arbitrary lists,one exception { foil's definition reverse learned larger vocabulary includesclausereverse(A,A) :- append(A,A,C), del(D,E,C).exploits bounded length lists.6 times reveal considerable advantage6. C twice length E one element longer C still length 4,length must 0 1. case reverse.151fiQuinlanTaskfoil ffoilquicksort4.72.2bubblesort 7.30.4Table 2: Times (sec) learning sort.[3,3]0.70.8Golem 4.8Progol 43.0ffoilfoilTime (secs)Ratio [3,3][3,4] [4,4][4,5] [3,4] [4,4][4,5]1.54.515.0 2.16.421.44.311.9146.3 5.4 14.9182.914.659.6>395 3.0 12.4 >82.3447.9 5271.9 >76575 10.4 122.6 >1780.8Table 3: Comparative times quicksort task.ffoil tasks except second. fact, first last task largervocabulary, times understate ffoil's advantage. total number bindingsappend 3413 , 40 million, foil option used sample 1%bindings prevent foil exceeding available memory. possible run foilbindings, time required learn definition would considerablylonger. Similarly, foil exhausted available memory translation task 232,221possible bindings used, results obtained using sample 50%bindings.5.2 Learning quicksort bubblesorttasks concern learning sort lists examples sorted lists. first,target relation qsort(A,B) means B sorted form A. Three backgroundrelations provided: components append before, partition(A,B,C,D), meaningpartitioning list B value gives list C elements less listelements greater A. second task, background relations learningbsort(A,B) components lt(A,B), meaning A<B. vocabulary used taskslists length 4 non-repeated elements drawn f1,2,3,4g.thus 65 4160 bindings task.foil ffoil learn \standard" definition quicksort. Times shown Table2 comparable, mainly ffoil learns super uous over-specialized clauselater discarded favor general recursive clause. outcome bubblesortquite different { ffoil learns twenty times faster foil definitionverbose.quicksort task provides opportunity compare ffoil two wellknown relational learning systems. Like ffoil foil, Golem (Muggleton152fiLearning First-Order Definitions FunctionsTaskfoil ffoilAckermann's function12.30.2greatest common divisor 237.51.2Table 4: Times (sec) arithmetic functions.Feng, 1992) Progol (release 4.1) (Muggleton, 1995) implemented C,timing comparisons meaningful. Furthermore, systems include quicksort amongdemonstration learning tasks, reasonable assume parameterscontrol systems set appropriate values.four learning systems evaluated using four sets training examples, obtainedvarying maximum length lists size alphabet nonrepeating elements appear lists, (Quinlan, 1991). Denoting setpair [S ,A], four datasets [3,3], [3,4], [4,4], [4,5]. total numberspossible bindings tasks, 256, 1681, 4225, 42,436 respectively, span two ordersmagnitude. Table 3 summarizes execution times7 required systemsdatasets. Neither Golem Progol completed last task; Golem exhausted availableswap space 60Mb, Progol terminated using nearly day cpu time.table also shows ratio execution time latter three simplest dataset[3,3]. growth ffoil's execution time far slower systems,primarily ffoil needs tuples others use tuples.Golem's execution time seems grow slightly slower foil's, Progol's growthrate much higher.5.3 Arithmetic functionssystems also used learn definitions complex functions arithmetic.Ackermann's function8>= 0< n+1f (m; n) = > f (m , 1; 1)n = 0: f (m , 1; f (m; n , 1)) otherwiseprovides testing example recursion control; background relation succ(A,B) represents B=A+1. Finding greatest common divisor two numbers another interestingtask; background relation plus. tasks vocabulary consists integers0 20 1 20 respectively, giving 51 tuples Ackermann(A,B,C) A, BC less equal 20, 400 tuples gcd(A,B,C).shown Table 4, ffoil 60 times faster foil learning definitionAckermann 200 times faster gcd. due solely ffoil's smallernumbers bindings. gcd, example, foil starts 203 8,000 bindings whereasffoil never uses 400 bindings.7. Diculties experienced running Golem AXP 3000/900, times tableDECstation 5000/260.153fiQuinlanfoil ffoil learn exactly program Ackermann's functionmirrors definition above. case gcd, however, definitions highlightpotential simplification achievable ordered clauses. definition found foilgcd(A,A,A).gcd(A,B,C) :- plus(B,D,A), gcd(B,A,C).gcd(A,B,C) :- plus(A,D,B), gcd(A,D,C).learned ffoil (omitting default clause)gcd(A,A,A) :- !.gcd(A,B,C) :- plus(A,D,B), gcd(A,D,C), !.gcd(A,B,C) :- gcd(B,A,C), !.last clause exploits fact cases less equal Bfiltered first two clauses.5.4 Finding past tense English verbsprevious examples concerned tasks compact, correct definitionknown exist. application, learning change English verb phoneticnotation present past tense, real-world avor totally correctdefinition would extremely complex. considerable literature built aroundtask, starting connectionist community, moving symbolic learningwork Ling (1994), relational learning (Quinlan, 1994; Mooney Califf, 1995).Quinlan (1994) proposes representing task relation past(A,B,C), interpretedpast tense verb formed stripping ending B adding string C.single background relation split(A,B,C) shows ways word split twonon-empty substrings B C. Following experiment reported (Ling, 1994), corpus1391 verbs used generate ten randomly-selected learning tasks, containing 500verbs definition learned 500 different verbs used test definition.Prolog interpreter used evaluate definitions learned foil, unseen wordw mapped test query past(w,X,Y)?. result query judged correctX bound proper strings. multiple responsesquery, first used { disadvantages foil somewhat, since systemattempt reorder learned clauses maximum accuracy single-response queries.average accuracy definitions found foil 83.7%.apply ffoil task, relation past(A,B,C) must factored two functionalrelations delete(A,B) add(A,C) since ffoil currently learn functionssingle output variable. training test sets verbs used, giving risetwo separate learning tasks, test judged correct delete addgive correct results unseen verb. definitions learned ffoil higheraverage accuracy 88.9%; ten trials, ffoil outperforms foil nine inferiorone, difference significant 1% level using one-tailed sign test.average time required ffoil learn pair definitions, approximately 7.5 minutes,somewhat less time taken foil learn single definition.154fiLearning First-Order Definitions FunctionsObject EdgesBCETotal5442285796277CorrectTime (sec)foil ffoil mfoil Golem fors foil ffoil16212217222.5915129121.78119583.31022611162.416541010294.759123595287 14.6(21%) (44%) (21%) (19%) (31%)9.111.09.711.15.946.8Table 5: Cross-validation results finite element mesh data.5.5 Finite element mesh designapplication, first discussed Dolsak Muggleton (1992), concerns divisionobject appropriate number regions finite element simulation. edgeobject cut number intervals task learn determine suitablenumber { fine division requires excessive computation simulation,coarse partitioning results poor approximation object's true behavior.data concern five objects total 277 edges. target relation mesh(A,B)specifies edge number intervals B recommended expert, ranging1 12. Thirty background relations describe properties edge, shapetopological relationship edges object. Five trials conducted,information one object withheld, definition learned edgesremaining objects, definition tested edges omitted object.Table 5 shows, trial, number edges definitions learnedfoil ffoil predict number intervals specified expert. Table 5 also showspublished results mesh task three relational learning systems. numbersedges mfoil Golem predict correct number intervals taken(Lavrac Dzeroski, 1994). general relational learning systems like foil,fors (Karalic, 1995), like ffoil, specialized learning functional relationskind. Since general relational learning systems could return multiple answersquery mesh(e,X)? edge e, first answer used; puts disadvantagerespect foil fors accounts least part lower accuracy. Usingone-tailed sign test 5% level, ffoil's accuracy significantly higherachieved foil Golem, differences significant.time required ffoil domain approximately three times usedfoil. turnabout caused ffoil's global pruning phase, requires many literaleliminations order maximize overall accuracy training data. one plycross-validation, instance, initial definition, consisting 30 clauses containing 64body literals, fails cover 146 249 given tuples target relation mesh.global pruning, however, final definition 9 clauses 15 body literals,makes 101 errors training data.155fiQuinlan6. Related ResearchMooney Califf's (1995) recent system Foidl strong uence development ffoil. Three features together distinguish Foidl earlier systems likefoil are:Following example focl (Pazzani Kibler, 1992), background relationsdefined intensionally programs rather extensionally tuple sets.eliminates problem applications complete extensional definitionbackground relations would impossibly large.Examples tuples belong target relation needed. Instead,argument target relation mode Foidl assumes outputcompleteness, i.e., tuples relation show valid outputs inputsappear.learned definition ordered every clause ends cut.Output completeness weaker restriction functionality since may severalcorrect answers standard query R(c1 ; c2 ; :::; cn,1 ; X )?. However, factclause ends cut reduces exibility somewhat, since answers query mustgenerated single clause.Although Foidl ffoil learn ordered clauses cuts,different ways. ffoil learns clause, sequence clauses cover remainingtuples, first clause definition first clause learned. Foidl insteadfollows Webb Brkic (1993) learning last clause first, prepending sequenceclauses filter exceptions learned clause. strategy advantagegeneral rules learned first still act defaults clauses coverspecialized situations.principal differences Foidl ffoil thus use intensional versusextensional background knowledge order clauses learned.subsidiary differences { example, Foidl never manipulates bindings explicitlyestimates number syntactically. However, many ways ffoil may viewedintermediate system lying mid-way foil Foidl.Foidl motivated past tense task described Section 5.4, performsextremely well it. formulation task Foidl uses relation past(A,B)indicate B past tense verb A, together intensional backgroundrelation split(S,H,T) denote possible ways dividing string substrings HT. Definitions learned Foidl compact intelligible, slightly higheraccuracy (89.3%) ffoil's using ten sets training test examples.interesting see systems compare applications.Bergadano Gunetti (1993) first pointed advantages learning systemsrestricting relations functions. filp system assumes relations, targetbackground, functional, although allow functions multiple outputs.assumption greatly reduces number literals considered specializing clause,leading shorter learning times. (On hand, many tasks discussedprevious section involve non-functional background relations would satisfy filp's156fiLearning First-Order Definitions Functionsfunctionality assumption.) theory, filp also requires oracle answer non-groundqueries regarding unspecified tuples target background relations, althoughwould required relevant tuples provided initially. filp guaranteeslearned definition completely consistent given examples, inappropriatenoisy domains discussed Sections 5.4 5.5.contrast ffoil Foidl, definitions learned filp consist unorderedsets clauses, despite fact target relation known functional.prevents clause exploiting context established earlier clauses. gcd task(Section 5.3), definition learned filp would require bodies secondthird clauses include literal plus(...,...,...). domains past tense task,complexity definitions learned ffoil Foidl would greatly increasedconstrained unordered clauses.7. Conclusionstudy, mature relational learning system modified customizefunctional relations. fact specialized ffoil performs much bettergeneral foil relations kind lends support Bergadano Gunetti's(1993) thesis functional relations easier learn. interesting speculatesimilar improvement might well obtainable customizing general first-ordersystems Progol (Muggleton, 1995) learning functional relations.Results quicksort experiments suggest ffoil scales better generalfirst-order systems learning functional relations, past tensemesh design experiments demonstrate effectiveness noisy domains.Nevertheless, hoped improve ffoil several ways. systemextended multifunctions one output variable, permittedfilp Foidl. Secondly, many real-world tasks Sections 5.4 5.5result definitions output variable usually bound equatedconstant rather appearing body literal. applications, ffoil heavilybiased towards constructing next clause cover frequent function valueremaining tuples, binding tends highest gain. timeclause specialized exclude exceptions, however, end coveringtuples relation. special cases could filtered first, clauses likewould simpler would cover tuples target relation. better learningstrategy situations would seem grow new clause every function valueuncovered tuples, retain one greatest coverage discard rest.would involve increase computation lead better, concisedefinitions.Although conceptual changes moving foil ffoil relatively slight,effects code level substantial (with three 19 files makefoil escaping modification). result decided preserve separatesystems, rather incorporating ffoil option foil. available (foracademic research purposes) anonymous ftp ftp.cs.su.oz.au, directory pub, file namesfoil6.sh ffoil2.sh.157fiQuinlanAcknowledgementsresearch made possible grant Australian Research Council. ThanksWilliam Cohen, Ray Mooney, Michael Pazzani, anonymous reviewers comments helped improve paper.Appendix: Learned Definitionsdefinition learned foil appears left ffoil right.latter's default clauses irrelevant tasks, omitted.List processing functions (Section 5.1)(a) Using lists length 3:append([ ],B,B).append(A,B,C) :- components(A,D,E),components(C,D,F), append(E,B,F).last(A,B) :- components(A,B,[ ]).last(A,B) :- components(A,C,D), last(D,B).reverse(A,A) :- append(A,C,D),components(D,E,A).reverse(A,B) :- last(A,C), last(B,D),components(A,D,E),components(B,C,F), reverse(E,G),del(D,B,G).shift(A,B) :- components(A,C,D), del(C,B,D),append(D,E,B).translate([ ],[ ]).translate(A,B) :- components(A,C,D),components(B,E,F), translate(D,F),means(C,E).append([ ],B,B) :- !.append(A,B,C) :- components(A,D,E),append(E,B,F), components(C,D,F), !.last(A,B) :- components(A,C,D), last(D,B), !.last(A,B) :- member(B,A), !.reverse(A,A) :- append(A,C,D),components(D,E,A), !.reverse(A,B) :- components(A,C,D),reverse(D,E), append(F,D,A),append(E,F,B).append([ ],B,B).append(A,B,C) :- components(A,D,E),components(C,D,F), append(E,B,F).last(A,B) :- components(A,B,[ ]).last(A,B) :- components(A,C,D), last(D,B).reverse(A,A) :- append(A,A,C), del(D,E,C).reverse(A,B) :- components(A,C,D),reverse(D,E), append(F,D,A),append(E,F,B).append([ ],B,B) :- !.append(A,B,C) :- components(A,D,E),append(E,B,F), components(C,D,F), !.last(A,B) :- components(A,C,D), last(D,B), !.last(A,B) :- member(B,A), !.reverse(A,A) :- append(A,C,D),components(D,E,A), !.reverse(A,B) :- components(A,C,D),reverse(D,E), append(F,D,A),append(E,F,B).shift(A,B) :- components(A,C,D),append(E,D,A), append(D,E,B).shift(A,B) :- components(A,C,D),append(E,D,A), append(D,E,B).translate([ ],[ ]) :- !.translate(A,B) :- components(A,C,D),translate(D,E), means(C,F),components(B,F,E).(b) Using lists length 4:shift(A,B) :- components(A,C,D), del(C,B,D),append(D,E,B).158fiLearning First-Order Definitions Functionstranslate([ ],[ ]).translate(A,B) :- components(A,C,D),components(B,E,F), translate(D,F),means(C,E).translate([ ],[ ]) :- !.translate(A,B) :- components(A,C,D),translate(D,E), means(C,F),components(B,F,E).Quicksort bubblesort (Section 5.2)qsort([ ],[ ]).qsort(A,B) :- components(A,C,D),partition(C,D,E,F), qsort(E,G),qsort(F,H), components(I,C,H),append(G,I,B).bsort([ ],[ ]).bsort(A,A) :- components(A,C,[ ]).bsort(A,B) :- components(A,C,D),components(B,C,E), bsort(D,E),components(E,F,G), lt(C,F).bsort(A,B) :- components(A,C,D),components(B,E,F), bsort(D,G),components(G,E,H), lt(E,C),components(I,C,H), bsort(I,F).qsort([ ],[ ]) :- !.qsort(A,B) :- components(A,C,D),partition(C,D,E,F), qsort(E,G),qsort(F,H), components(I,C,H),append(G,I,B), !.bsort([ ],[ ]) :- !.bsort(A,A) :- components(A,C,[ ]), !.bsort(A,B) :- components(A,C,D), bsort(D,E),components(E,F,G),components(B,C,E), lt(C,F), !.bsort(A,B) :- components(A,C,D), bsort(D,E),components(E,F,G),components(D,H,I),components(J,C,I), bsort(J,K),components(B,F,K), !.bsort(A,B) :- components(A,C,D), bsort(D,E),components(F,C,E), bsort(F,B), !.Arithmetic functions (Section 5.3)Ackermann(0,B,C) :- succ(B,C).Ackermann(A,0,C) :- succ(D,A),Ackermann(D,1,C).Ackermann(A,B,C) :- succ(D,A), succ(E,B),Ackermann(A,E,F),Ackermann(D,F,C).gcd(A,A,A).gcd(A,B,C) :- plus(B,D,A), gcd(B,A,C).gcd(A,B,C) :- plus(A,D,B), gcd(A,D,C).Ackermann(0,B,C) :- succ(B,C), !.Ackermann(A,0,C) :- succ(0,D), succ(E,A),Ackermann(E,D,C), !.Ackermann(A,B,C) :- succ(D,A), succ(E,B),Ackermann(A,E,F),Ackermann(D,F,C), !.gcd(A,A,A) :- !.gcd(A,B,C) :- plus(A,D,B), gcd(A,D,C), !.gcd(A,B,C) :- gcd(B,A,C), !.ReferencesBell, S., & Weber, S. (1993). close logical relationship foil frameworks Helft Plotkin. Proceedings Third International Workshop InductiveLogic Programming, Bled, Slovenia, pp. 127{147.Bergadano, F., & Gunetti, D. (1993). interactive system learn functional logic programs. Proceedings Thirteenth International Joint Conference Artificial Intelligence, Chambery, France, pp. 1044{1049. San Francisco: Morgan Kaufmann.Bratko, I. (1990). Prolog Programming Artificial Intelligence (2nd edition). Wokingham,UK: Addison-Wesley.159fiQuinlanCameron-Jones, R. M., & Quinlan, J. R. (1994). Ecient top-down induction logicprograms. SIGART, 5, 33{42.De Raedt, L. (Ed.). (1996). Advances Inductive Logic Programming. Amsterdam: IOSPress.Dolsak, B., & Muggleton, S. (1992). application inductive logic programmingfinite element mesh design. Muggleton, S. (Ed.), Inductive Logic Programming, pp.453{472. London: Academic Press.Karalic, A. (1995). First Order Regression. Ph.D. thesis, Faculty Electrical EngineeringComputer Science, University Ljubljana, Slovenia.Langley, P., & Simon, H. A. (1995). Applications machine learning rule induction.Communications ACM, 38 (11), 55{64.Lavrac, N., & Dzeroski, S. (1994). Inductive Logic Programming. London: Ellis Horwood.Ling, C. X. (1994). Learning past tense english verbs: symbolic pattern associatorversus connectionist models. Journal Artificial Intelligence Research, 1, 209{229.Michie, D., Spiegelhalter, D. J., & Taylor, C. C. (Eds.). (1994). Machine Learning, NeuralStatistical Classification. Hertfordshire, UK: Ellis Horwood.Mooney, R. J., & Califf, M. E. (1995). Induction first-order decision lists: resultslearning past tense english verbs. Journal Artificial Intelligence Research, 3,1{24.Muggleton, S. (Ed.). (1992). Inductive Logic Programming. London: Academic Press.Muggleton, S. (1995). Inverse entailment progol. New Generation Computing, 13,245{286.Muggleton, S., & Feng, C. (1992). Ecient induction logic programs. Muggleton, S.(Ed.), Inductive Logic Programming, pp. 281{298. London: Academic Press.Muggleton, S., King, R. D., & Sternberg, M. J. (1992). Protein secondary structure prediction using logic-based machine learning. Protein Engineering, 5, 646{657.Pazzani, M. J., & Kibler, D. (1992). utility knowledge inductive learning. MachineLearning, 9, 57{94.Quinlan, J. R. (1990). Learning logical definitions relations. Machine Learning, 5,239{266.Quinlan, J. R. (1991). Determinate literals inductive logic programming. ProceedingsTwelfth International Joint Conference Artificial Intelligence, Sydney, pp. 746{750.San Francisco: Morgan Kaufmann.Quinlan, J. R. (1994). Past tenses verbs first-order learning. Proceedings AI'94Seventh Australian Joint Conference Artificial Intelligence, Armidale, Australia,pp. 13{20. Singapore: World Scientific.160fiLearning First-Order Definitions FunctionsQuinlan, J. R., & Cameron-Jones, R. M. (1993). Foil: midterm report. Proceedings European Conference Machine Learning, Vienna, pp. 3{20. Berlin: Springer-Verlag.Quinlan, J. R., & Cameron-Jones, R. M. (1995). Induction logic programs: foilrelated systems. New Generation Computing, 13, 287{312.Rouveirol, C. (1994). Flattening saturation: two representation changes generalization. Machine Learning, 14, 219{232.Srinivasan, A., Muggleton, S. H., Sternberg, M. J. E., & King, R. D. (1996). Theoriesmutagenicity: study first-order feature-based induction. Artificial Intelligence, 84, 277{299.Ullman, J. D. (1988). Principles Database Knowledge-Base Systems. Rockville, MD:Computer Science Press.Webb, G. I., & Brkic, N. (1993). Learning decision lists prepending inferred rules. Proceedings Australian Workshop Machine Learning Hybrid Systems, Melbourne,Australia, pp. 6{10.Zelle, J. M., & Mooney, R. J. (1993). Combining foil ebg speed-up logic programs.Proceedings Thirteenth International Joint Conference Artificial Intelligence,Chambery, France, pp. 1106{1111. San Francisco: Morgan Kaufmann.161fiJournal Artificial Intelligence Research 5 (1996) 329349Submitted 5/96; published 12/96Quantitative Results Comparing Three Intelligent InterfacesInformation Capture: Case Study Adding Name InformationElectronic Personal OrganizerJeffrey C. SchlimmerSchool Electrical Engineering & Computer ScienceWashington State University, Pullman, WA 99164-2752, U.S.A.Patricia Crane WellsAllPen Software, Inc.16795 Lark Avenue, Suite 200, Los Gatos, CA 95030, U.S.A.SCHLIMME@EECS.WSU.EDUPATRICIA@ALLPEN.COMAbstractEfficiently entering information computer key enjoying benefitscomputing. paper describes three intelligent user interfaces: handwriting recognition,adaptive menus, predictive fillin. context adding persons name addresselectronic organizer, tests show handwriting recognition slower typingon-screen, soft keyboard, adaptive menus predictive fillin twice fast.paper also presents strategies applying three interfaces informationcollection domains.1. Introductionmeet someone new, often wish get name phone number. maywrite small notebook personal organizer. takes minutes do,put business card small slip paper organizer, promising copylater time.1 later time comes, face tedious task finding nowseveral names go organizer recopying information.comfortable computers, may use electronic organizer (a small computerincludes software managing names appointments). Looking someones phonenumber faster devices, adding tedious, owning costly.concession reality, devices often include pockets holding queued slipspaper.solutions could propose eliminate procrastination? adding personsname2 organizer fun (say choice inspirational message, gratuitousviolence, lottery ticket), might add names readily. Avoiding whimsy,could get desired effect making faster add persons name. reasonpaper organizers use index tabs; electronic organizers use automatic filing. faster still,organizer could read card handwritten note (via optical character handwriting1. friend places rubber band around organizer ensure paper slips dont escapetime.2. brevity, well refer persons name, address, phone numbers, e-mail, etc. name. Whetheraggregate information persons first last name intended clear context.1996 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiS CHLIMMER & W ELLSrecognition). Applying artificial intelligence ideas, could even imagine organizerpredicts need write you.paper describes electronic organizer almost fast slip paper,certainly much faster previous organizers. uses commercial hardware (Newton,described Section 2). software three interface components designed speedadding persons name (described Section 3): handwriting recognition, adaptive menusrecent values, predictive fillin. primary contributions paper detailedevaluations benefits three components (described Section 4).Adding persons name organizer special case capturing organizinginformation. ubiquitous task. Big businesses institute careful procedurescustom forms databases, billions smaller, one-or-two-person taskscould done efficiently accurately getting information computereasier. Even small gains would repeated many times whenever someone neededcollect information make decision, monitor process, investigate something new.secondary contributions paper consideration three components mayapplied broadly (described Section 5).three interface components robust familiar. Whether intelligentarguable. advocate behavior-based definition may also apply here, i.e.,question whether device intelligence answered examiningbehavior rather internal processes representations (e.g., Agre & Chapman, 1987;Horswill & Brooks, 1988). Even not, goal address questionmuch intelligence, agency, support one wants interface (Lee, 1990; Rissland, 1984).assert: much speed users performance task. Furthermore, muchresearch directed automatically learning hard-code study (e.g.,Dent, Boticario, McDermott, Mitchell, & Zabowski, 1992; Hermens & Schlimmer, 1994;Schlimmer & Hermens, 1993; Yoshida, 1994). Even learning works perfectly, resultworthwhile? claim answer found empirical study usefulnessvarious user interface components.2. NewtonNewton operating system introduced Apple Computer, Inc. 1993. designedsingle-user, highly-portable computer. Frames central data structure Newton.stored persistent object databases maintained RAM (Smith, 1994).Newton computer includes pressure-sensitive, bitmapped displayuser writes, draws, taps enter information (Culbert, 1994). small enough holdone hand weigh around one US pound. Battery life one days worthcontinuous use. thorough overview hardware software context current pencomputers, reader may wish consult (Meyer, 1995).lowest levels, Newton supports recognition. handwriting recognitionhighly publicized first introduced. recognizer allows free-form inputprinted cursive writing.3 uses on-line recognition convert writing Unicode4 text.recognizer uses contextual information limit types characters within specificfields combinations characters within words. latter relies heavily3. Throughout paper references handwriting also refer handprinting. distinction required,latter term used explicitly.4. character encoding similar ASCII two-bytes per character languages larger charactersets.330fiT HREE NTERFACES NORMATION C APTURE: C ASE TUDY DDING N AME NFORMATIONdictionaryonly words appearing dictionary recognized. user typesnew word using on-screen soft keyboard,5 Newton volunteers add dictionaryfuture recognition. Optionally, user invoke secondary recognizeruse dictionary attempts recognize written letter letter; Section 4describes accuracy option. Application developers customize handwritingrecognition providing special purpose dictionaries regular expression describingsyntax words recognized.Newton computers include several applications ROM serveelectronic organizer. Relevant point paper, Newton computers dateinclude application called Names storing retrieving peoples names, addresses,etc.; Figure 1 depicts application. Section 4 describes experiments using standardenhanced version Names application add peoples names.Figure 1: Names application included Newton computers depicted onequarter life size Apple Newton MessagePad 100 used experiments.user taps field, expands ease writing. picture, First Name fieldexpanded. folder tab button top screen displaying namesone eleven user-defined folders. left right, buttons bottomapplication screen showing time battery state (labeled clockface), changing display name (labeled Show), adding new name(labeled New), refiling name (labeled file folder picture), printing/faxing/infrared beaming/mailing/duplicating/deleting name (labeledenvelope picture), closing application (labeled large X).universal buttons visible applications. left right, provide accessNames application, calendar application, storage placeapplications, scrolling buttons, undo, find, natural language recognition.3. Names++Newton computers built-in Names application includes one three componentssuggested Section 1 speed adding new persons name. recognizes handwriting,5. Throughout paper references typing refer tapping on-screen soft keyboard.331fiS CHLIMMER & W ELLSrecognition dictionary expanded needed. Names++ extended versionNames wrote include two components.3.1Adaptive MenusNames++ extends Names adding adaptive menu 9 Names 17 fields: 7 menusconsisting 4 recently entered values 2 menus 4 recently entered values prependedfixed choices. word user needs menu, choose rather writeout. Figure 2 depicts Names++ menu open City field. choicesFigure 2: Names++ application. picture, user tapped wordCity opened menu recently used city names. user chooses onecities, copied City field name. CompareFigure 1. Note Names++ includes features Names relevant adding newname.menu four recently entered values specific field. (Each fieldseparate menu.) may convenient user series related namesadd, perhaps people company city. course, user addsfour unusual values row, common choices inadvertently dropped menu.sophisticated approach would list number recent valuesnumber common; Names++ doesnt explore sake simplicityspeed. menus adaptive, users use linear search examinechoices cannot rely muscle-level memory choice locations. menus includechoices, cost search likely dominate Fitts law effect.6Two Names fields already menu. Honorific field offered user Ms.,Mrs., Mr., Dr.; Country field offered menu thirteen countries.completeness, Names++ prepends four recent values fields menus.Technically split menus.7 Mitchell Shneiderman (1989) compared largestatically ordered menus (unsplit) also prepended most-recently-used choices6. Fitts law states time move given distance target width W proportional log D/W.7. confused splitting menu choices across multiple menus (Witten, Cleary, & Greenberg, 1984).332fiT HREE NTERFACES NORMATION C APTURE: C ASE TUDY DDING N AME NFORMATION(split, exactly condition). Static faster split menus one task;difference another. Sears Shneiderman (1994) later found evidence favor splitmenus including 1758% improvement selection time compared unsplit menus.also compared alternative organizations split part recommend limitingnumber split choices four less (which Names++ does) sorting split choicesfrequency (which Names++ approximates most-recently-used). context menuhierarchies, Snowberry, Parkinson, Sisson (1985) found adding items containingupcoming selections resulted greater accuracy faster search times. resultconfirmed (Kreigh, Pesot, Halcomb, 1990) may much effectpreventing users getting lost menu hierarchies assisting makingselections per se. test adaptive (split) menus Names++ understand relativecontribution compared interfaces data entry task.four Phone Number fields menus, give user way categorizephone number rather enter number itself. category menus (Norman,1991). phone menus include choices Phone, Home, Work, Fax, Car,Beeper, Mobile, Other. phone fields identical menus. Names++modify them. menus provided First Name, Last Name, Birthday fields.Section 5 describes input fields menus.understand computational space time demands adaptive menus, noteNames++ stores menus single object object database. size objectlinear number fields menus (f) number choices menu(c), fc. menu implemented circular queue, time update objectwould constant menu, f. Names++ uses slightly slower arrayimplementation menus takes fc time. practice works slightlyone half second nine fields four choices.3.2Predictive FillinNames++ also extends Names automatically filling 11 empty fields new namepredicted values. treats previous names case base (Kolodner, 1993) copiesinformation relevant case. Specifically, user adds company new namematches previous names company, Names++ copies addressprevious name new one. Values copied verbatim two address linesCity, State, Zip Code, Country fields. user ID electronic mail addressdropped e-mail address copied new name. (The remaining componentse-mail address likely people company.) lastword Phone Number values dropped; area code prefix copiednew name typical area code-prefix-extension phone number. user writeschooses another value Company, replacing value field, predictive fillinrecopies dependent values previous name. Figure 3 illustrates sequence eventsusers perspective.Names++ behaves similarly user adds city state matches previousname, copies less information matching company found. valuecopied predictive fillin incorrect, user write choose correct valuemanually. Table 1 summarizes fields menus predictive fillin. structurepredictive fillin fixed design Names++. work attempts learn comparablestructure examples (e.g., Dent et al., 1992; Hermens & Schlimmer, 1994; Schlimmer &333fiS CHLIMMER & W ELLSFigure 3: Names++ application user adds company new name.left panel, application finds previous name matching company, displaysdialog, fills remaining fields predicted information copiedprevious name. center panel shows much information filled. rightpanel shows completed name. example user written fouradditional words complete name.Hermens, 1993; Yoshida, 1994). goal determine whether end resultlearning worthwhile.one previous name matches company, city, state new name,Names++ fills fields values recent name. Values second-mostrecent occurrence name added menus. gives user chance selectalternate addresses company alternate zip codes city.terms computational requirements, Names++ needs additional storagepredictive fillin; object database previously added names reused case base.Matching new names company, city, state previous name implementedNewton primitive; informal study depicted Figure 4 indicates Newtons proprietaryalgorithm appears run time linear number names match foundlogarithmic matches found.Names++ source code on-line Appendix A.4. Experimentshypothesize recognition, adaptive menus, predictive fillin speed adding newname. find extent, conducted experimentsubjects added names using different combinations three interface components.4.1MethodFive computer science students ages 18 35 years age participatedsubjects experiments. Prior experiments used Newton computerleast six months familiar Newtons handwriting recognition QWERTYlayout Newtons on-screen keyboard.experiment used within-subject design subject participatedsix conditions summarized Table 2. Conditions designed assess contribution334fiTime SecondsHREE NTERFACES NORMATION C APTURE: C ASE TUDY DDING N AME NFORMATIONJ5.2J1.6BJBJ0.1 BJBJ0.710EJBGBB640Number Names200Figure 4: Time find matching name using Newton function numbernames database match exists (circles upper line) several matchesexist (squares lower line). axes linear scale. upper line linear fit;lower line logarithmic. comparison experiment, interpolated values200 names shown open symbols.interface component separately collectively. control, Typed condition,subject types values without using components. Null condition,subject writes words using remedial recognition steps (to described) types wordsrecognizable. subject add words Newtons dictionaryasked assistance either adaptive menus predictive fillin.condition extends Null requiring subject add words Newtons dictionaryasked. condition extends Null adding adaptive menus. PF condition extendsNull adding predictive fillin. condition combines extensions D, AM,PF.used pair Apple Newton MessagePad 100 computers (running Newton OSversion 1.3) experiment three versions Names++ application. One versioninterface components disabled used Typed, Null, conditions.second version adaptive menus used AM. third version adaptive menuspredictive fillin used PF All.set 448 name records experiments donated development officerWashington State University. job involves contacting alumni others solicitsupport university programs. Almost records include first last name, fullmailing address, one three phone numbers. include honorific, country, email address. Informal tests indicated MessagePads could hold 250 namesNames++ installed, selected random set 200 records.335fiS CHLIMMER & W ELLSMenu ChoicesFieldHonorificPredictive FillinBuilt-in Adaptive4CompanyCityStateNotesMs., Mrs., Mr., Dr.4First NameLast NameTitle4Company4Address (1)4Address (2)Yeslabel tap menu.YesCity4YesState4YesYesZip Code4YesYes4YesYes4YesCountry13E-MailPhone 18Phone 28Phone 38Phone 48Area CodePrefixYesUser ID removed.Category menu used selecttype phone number ratherphone number itself. Choicesinclude Phone, Home,Work, Fax, Car, Beeper,Mobile, Other.Area CodeBirthdateTable 1: Name++ fields adaptive menus predictive fillin.ConditionWritingAdd DictionaryAdaptive MenusPredictive FillinTypedNullYesYesYesPFYesYesYesYesYesYesYesYesTable 2: Experimental conditions, one row per condition. Columns indicateuser interface components used. Blank cells represent No.simulate worst case recognition, adaptive menus, predictive fillin, chose5 names (listed below) residual 248 names companypreload set 200 names. (To preserve anonymity here, first last names swappedphone numbers replaced artificial values. Actual first last name pairs phonenumbers used experiment.)336fiT HREE NTERFACES NORMATION C APTURE: C ASE TUDY DDING N AME NFORMATIONRobert AndersonAccount Marketing RepIBMW 201 N River DriveSpokane, WA 99201509 555 0000509 555 1111Eric BriceDirector EngineeringRAIMA Corp3245 146th Place SEBellevue, WA 98007206 555 2222206 555 3333205 555 4444Peter FriedmanPresidentNOVA Information Systems12277 134th Court NESuite 203Redmond, WA 98052206 555 7777Thomas LelandStaffing ManagerAldus Corporation411 First Ave SouthSeattle WA 98104 2871206 555 8888206 555 9999Mike CarlsonVP Engineering & EstimatingGeneral Construction2111 N Northgate WaySuite 305Seattle, WA 98133206 555 5555206 555 6666score words names entered total time, used sheetFigure 5. Fictitious data corresponding subjects entering second namecondition also depicted.Figure 5: Scoring sheet used time name added. 1 center rightcolumns indicates first word field value entered using recognition(cf. Figure 6), adaptive menu (cf. Figure 2), predictive fillin (cf. Figure 3). 2indicates second word, on. highest digit row correspondsnumber words fields value.facilitate setting condition, constructed backup images MessagePadscorrectly configured six conditions. images, 200 namesappropriate version Names++ installed. images All, addedFirst, Last, Company names dictionary using built-in feature Newton.initialize adaptive menus images All, used special purposeapplication. Prior use MessagePads completely erased restoredbackup image appropriate condition tested.337fiS CHLIMMER & W ELLStask subject enter five names twice sixconditions. first time name entered condition simulates worst-case scenario;second time, best.4.2ProcedureSubjects given listing one five names MessagePad initialized onesix experimental conditions. subject entered name condition; name/condition pairs randomly ordered subject counteract subject learningeffects. instructed enter names quickly. Subjects made mistakes.instructed correct finishing. Times reported include time correctmistakes.Subjects given precise script follow entering name. donepartially bias results hypotheses partially minimize individual variation.Specifically, subject instructed enter values field order, topbottom, completing one going next (cf. Figure 1). conditions involvinghandwriting, word correctly recognized, subject check menualternate recognitions (depicted left panel Figure 6). intended wordFigure 6: Remedial steps handwritten word correctly recognized.example, subject wrote Brice misrecognized Brian.subject double-taps word, menu alternative recognitions appears (leftpanel). none correct, subject requests recognition withoutdictionary (or letter letter). Another double-tap word generates secondmenu alternatives (middle panel). none correct, subject enteredword tapping buttons on-screen keyboard (right panel).list, select Try letters attempts recognition without dictionary.result correct, check second menu alternativerecognitions (depicted center panel Figure 6). intended wordsecond menu, tap button keyboard picture, type word usingon-screen keyboard, close keyboard. word already partdictionary, Newton asked would like add (depicted right panel Figure 6).Note recognition menus, original handwriting shown near338fiT HREE NTERFACES NORMATION C APTURE: C ASE TUDY DDING N AME NFORMATIONbottom. first choice Newtons best guess, second choice best guessdifferent capitalization. subject instructed ensure words correctlycapitalized.Typed, subject instructed enter data using Newtons on-screen softkeyboard. Null, subject enter data handwriting. All,subject instructed add words Newtons dictionary asked. All,subject instructed check fields menu (if one) writing data.special instructions required PF beyond default adding wordsdictionary.stopwatch started subject tapped New button stoppedlast field value correctly entered. Choosing manual timing method simplifieddevelopment experimental software. method word fieldentered recorded scoring sheet indicated Figure 5.experiment took three five hours subject spreadtwo sessions approximately two hours within week. Subjects took shortbreaks adding name minimize fatigue.subject completed experiment, asked rank favoritemethods entering names least.4.3ResultsTable 3 summarizes median standard deviation subjects time enter namesix conditions. Times include user input, predictive fillin computation, timecorrect errors (if any). first row reports time add novel name, simulationworst case. second row reports time repeat name, simulation best case.ANOVA reveals significant main effect condition F(5, 21.07) < 0.001. interactionnumber times name entered condition also significant F(5, 19.61) < 0.001.Comparing worst cases across conditions, post-hoc multiple comparisons test usingTukeys HSD indicates Typed significantly different (faster)conditions. (All p < 0.05.) Comparing worst best cases within condition, D, AM,PF, significantly faster. Comparing best cases across conditions, Typed, AM,PF significantly faster Null; significantly faster Typed, PF, D,Null. pairwise comparisons significant.TypedNullPFWorst2.72 (0.86)4.25 (1.31)4.50 (1.45)4.32 (1.70)4.07 (1.26)4.15 (1.13)Best2.52 (0.60)3.65 (1.24)3.30 (1.09)1.37 (0.51)2.02 (0.45)1.08 (0.24)Table 3: Median time minutes add new name five names five subjects(25 samples per cell, standard deviation parentheses). Columns list sixexperimental conditions.difference within D, AM, PF across worst best cases confirmshypothesis interfaces speed entering names, 29%, 210%, 110% comparedNull, respectively. surprised find predictive fillin fastadaptive menus (though difference statistically significant). designing dataentry system one might tempted implement adaptive menus given algorithmicsimplicity, especially compared sophisticated methods machine learningproposed predictive fillin. However, latter suffer recency effects imposed339fiS CHLIMMER & W ELLSlimited size adaptive menus; entering new data related distantpast, predictive fillin would little difficulty providing assistance adaptive menuscould not. Adaptive menus could refined use frequency frequency-recencycombination, performance suggests implementing adaptive menuspredictive fillin. Combined adding words dictionary, speed entering names294%. practical terms, interfaces could make entering name electronicorganizer faster writing paper certainly fast enough captureinformation phone conversation.Prior work confirms difference Typed conditions. WardBlesser (1986) state normal writing speed rarely greater 69 characters per minute(cpm) single line text. Using fact mean number characters per nameexperiment 98.2, subjects achieved 30 cpm. MacKenzie, Nonnecke, Riddersma,McQueen, Meltz (1994) compare four interfaces entering numeric text datapen-based computers, including hand printing using on-screen keyboard. (Thetwo interfaces experimental gesture-based techniques entering single characters.)numeric entry conditions, found on-screen keyboard 30 words perminute (wpm) 1.2% error whereas hand printing 18.5 wpm 10.4% error.text entry conditions, keyboard 23 wpm 1.1% error whereas hand printing16 wpm 8.1% error. Using fact mean number words per nameexperiment 20.8, subjects achieved 8.3 wpm typing 6.3 wpm handwritingmixed numeric/text input. key point comparison studiesfound using stylus tap on-screen keyboard faster handwriting printing.Differences speed studies likely result differencesexperimental procedures (theirs versus ours): single versus multiple field fillin, copyinginformation memory screen versus paper, block comb-type (letter) versusopen (word) interface.Figure 7 presents Box plot summaries time data. interest reductionvariance time adaptive menus predictive fillin best case (right plot).Differences individual performance reduced interface components.left half Table 4 lists recognition accuracy field conditions,subjects, names. first row indicates 94% first names writtencorrectly recognized immediately. checking first menu alternate recognitions,accuracy rises 95%. Similarly, second row indicates 59% second nameswritten correctly recognized immediately. rate rose 74% letter-by-letterrecognition invoked 79% checking second menu alternaterecognitions. Phone numbers enjoyed second highest recognition rate first names.reference, Cesar Shinghal (1990) report 90% recognition rate handprinted, Canadian postal codes {letter, digit, letter, space, digit, letter, digit}.comparable observed rates first names, second address lines, phonenumbers.right half Table 4 lists percentage words entered using typing, adaptivemenus, predictive fillin field conditions, subjects, names. first rowindicates 5% first names typed. row State indicates 32% statenames typed, 20% chosen adaptive menu, 39% predictivelyfilled in. (Note numbers row total 100% left halftable lists percentages words written right half lists percentageswords.)340fiTime MinutesHREE NTERFACES NORMATION C APTURE: C ASE TUDY DDING N AME NFORMATION*1010*****5***5*Worst CaseFillinMenuDictionaryNull0Typed*FillinMenuDictionaryTyped0Null*Best CaseExperimental ConditionFigure 7: Box plots time enter name condition worst best cases.box summarizes 25 values. Values outside inner fences plottedasterisks. Values outside outer fences plotted circles (Wilkinson, Hill,Vang, 1992).Combining left right halves Table 4 reveal many difficult-torecognize fields considerable assistance adaptive menus predictive fillin.accentuates speed improvements providing help needed. Figure 8depicts relationship fields, recognition accuracy,adaptive menus predictive fillin. Several fields near perfect recognition accuracy;recognized without resorting typing. instance, numeric fields easierrecognize; Phone Number fields recognized nearly 90% even though areacode, prefix, suffix varied name name. First Last name fields alsohigh recognition accuracy. first names built-in dictionary. twolast names were, others often recognized letter letter. Recognitionpoorer Company Address fields. Words full capitals (e.g., RAIMA) wordscombination numbers letters (e.g., 146th) difficult recognize.low recognition accuracy State field apparently due oversight Newtonsdictionary. WA included many two-letter abbreviations US states are.compensate low accuracy, Names++ includes adaptive menu and/or predictive fillindifficult-to-recognize fields.Table 5 summarizes subjects preference condition enter name. lists frequencyranking five subjects. Subjects partitioned conditions non-overlappinggroups (Typed, Null), (D, AM, PF), (ALL). (The authors know suitable statisticasserting differences.) results contradict MacKenzie et al. (1994)found subjects preferred typing handwriting, mildly text entry341fiS CHLIMMER & W ELLS100XFirst NameGPhoneGAddress (2)XLast Name75TitleRecognition (%)CityCompanyAddress (1)Zip Code50XG25StateRecognitionAdaptive MenusPredictive Fillin00200400600800Number Words10001200Figure 8: Recognition rate function number total words enteredconditions subjects names. Fields adaptive menus predictive fillin(or both) marked. Note every field less 75% accuracy eitheradaptive menu predictive fillin (or both).strongly numeric entry. restricted hand printing input block comb-typeinterface; unnaturalness may account dispreference toward handwriting.Writing stylus advantages. Meyer (1995) points out, keyboardsfaster linear text entry, pen input device natural, handle textgraphic input, jump quickly point point. Writing pen also supportsheads writing, allowing user visually attend aspects task hand.Typing on-screen keyboard requires heads entry.One subject experimented Names++ outside experimental setting offerednumber observations. First, adaptive menus short, sometimes menuswould useless matter long were. wished City Companyfields menus longer (especially City). frustrating one commoncity names large metropolitan region bumped short list. contrast, Titlefields menu rarely useful, see point maintaining it. principlesoutlined Section 5 suggest similar revisions.342fiT HREE NTERFACES NORMATION C APTURE: C ASE TUDY DDING N AME NFORMATIONFieldCumulative Recognition AccuracyLetterCorrect1st Menu2nd MenuLetterPercent Words EnteredAdaptive PredictiveTypedMenuFillinFirst Name949595955SecondName5959748021Title526266682620Company424959613120Address486062672310Address 28185878710City62626771191220State22222222322039Zip51525859291020Phone8689898910202015Table 4: left columns list cumulative recognition accuracy field wordswritten conditions, names subjects. right columns listpercentage words field entered typing, adaptive menus, predictivefillin. 5190 values total. Blank cells represent 0.5th6thTyped14Null41Condition1st2nd3rd14122PF324th5Table 5: Subjects frequency ranking preference different conditionsmeans enter name. 30 values total. Blanks cells represent 0.Second, found predictive fillin helpful. Sometimes filled didntexpect to. also noted predictive fillin copies many fields,encourages user add complete name. may advantage harriedsetting.5. Design RecommendationsGiven experimental results, configure handwriting recognition,adaptive menus, predictive fillin another application (or redesigned Names++)?handwritten input, recognition use dictionaries specific type field: numbersnumeric fields, lists domain terms text fields.5.1Adaptive Menusadaptive menus, add menu field might repeated values.accidentally added adaptive menu field never value twice,343fiS CHLIMMER & W ELLSLast NameJohnJimBobJerryPaulDavidSteveRonBillTomRobertJackDennisRobinRichJulieJamesEdmundDaveTitlePresidentExecutive DirectorVice President - Human ResourcesVice PresidentTravel ConsultantStaffing SpecialistSales RepresentativeProgram OfficerPrincipalManagerIndustrial Research Marketing ManagerHuman Resources ManagerHuman ResourcesGeneral ManagerChairAccount Managerconsultant Seattle Govt. RelationsWestern Regional Sales ManagerVice President/Managing PrincipalVice President, Finance & Administra0%25%50%75%100%Percent ValuesBrownWoodSmithLeeBakerThomasSchroederRayNelsonJonesJohnsonHoffmanHandFrostEvansEricksonDalpiazAndersonAdamsZippBoeingHewlett-Packard CompanyTektronix, Inc.BattelleFluke CorporationMicrosoft CorporationMentor Graphics CorporationELDEC CorporationPuget Sound Power & LightMotorola Inc.ARCO Products CompanyUniversity WashingtonSundstrandSandia National LaboratoriesHoneywellWashington Technology CenterIntel CorporationAsymetrix CorporationOregon State UniversityDigital Equipment Corporation0%25%50%75%CompanyFirst Namemistake would harmless. user would surely notice choices uselessavoid checking menu. menu appropriate, user would save timechoosing common values it.long menu be? Long enough include common valuesshort enough checked quickly. make sure menu long enough, study oftenfields values repeat. Names++, Figures 9a 9b depict frequency histogram100%Figure 9a: Frequency values First Name, Last Name, Title, Companyfields 448 names used Section 4. plot histogram 20common values. Dark lines indicate percent values could chosendifferent sized menus. menu includes choices top verticalposition, would allow user choose percentage field values indicatedhorizontal position.344fiP.O. Box 3707P.O. Box 3999Pacific Northwest LaboratoriesP.O. Box 999P.O. Box 500One Microsoft WayP.O. Box C9090P.O. Box 1008005 S.W. Boeckman Road160520 Microsoft BVUEP.O. Box 97034Cherry Point RefineryBoeing Commercial Airplane CompanyPost Office Box 8100P.O. Box 97001Battelle BoulevardTAF C-34P.O. Box 9090P.O. Box 1970FJ-15CityAddressHREE NTERFACES NORMATION C APTURE: C ASE TUDY DDING N AME NFORMATIONWAStateIDTXILNYAZUTOHNMMNMIKSFLBritish ColumbiaVirginiaVATexas0%25%50%75%Percent Values9935298124-220798124-24999922098206981959812498052-63999800998046-0100980069933698206-909098073-9701980049707797070-77779916397070984770%25%Zip CodeCASeattleBellevueRichlandRedmondSpokaneEverettBeavertonHillsboroWilsonvilleLynnwoodVancouverPullmanKennewickTacomaSan FranciscoPortlandBlaineSan RamonKirklandCorvallis100%50%75%100%Figure 9b: Frequency values Address, City, State, Zip Code fields448 names used Section 4.20 common values 8 fields drawn 448 name records usedexperiments. Overlaid plot line indicating percent field values couldchosen particular size menu. instance, First Name field Figure 9a,histogram almost flat. menu including John would allow user choosevalue field less 5% time. menu included 20 first namesshown, user could choose value 25% time. field menulong enough include common values would take longcheck. (Also, Newton computer used Section 4 limits menus 23 choicesscreen size.) contrast, Company field Figure 9a, menu including345fiS CHLIMMER & W ELLSBoeing would allow user choose value 10% time. included20 values shown, user could choose value 50% time.Studying histograms aiming menus include 50% fields values,might re-engineer Names++ menus size 20 Company Field, size 10City field, size 5 State field. fields flat histograms wouldneed large menus include high percentage field values. Recall Section 4 reportsone subjects frustration Title field. President seems repeatedfield 448 names used.5.2Predictive fillinSet predictive fillin field functionally dependent (Ullman, 1988) another.functional dependency related artificial intelligence idea determination(Russell, 1989). Intuitively, one field R, range, functionally depends another field D,domain, if, given value D, compute unique value R. predictive fillinfind previous entry value new entry, copiesprevious entrys value R new entry. Names++, Company fielddomain Address field range functional dependency.Predictive fillin functionally dependent fields probably strictstrategy. functional dependencies useful predictive fillindomain values unique database. so, predictive fillin cannot findpreviously matching entry cannot copy relevant information. instance, UScitizens address functionally dependent Social Security number. applicationlike Names++ dont expect see Social Security number twice, predictivefillin would never opportunity help user filling address. Functionaldependencies repeated domain values database, dense functionaldependencies, used set predictive fillin.Conversely, non-functional dependencies may close enough functionaluseful predictive fillin. Technically, dependency functional unless one valuerange computed every value domain. values rangecomputed values domain, dependency might still useful (Raju &Majumdar, 1988, Russell, 1989, Ziarko, 1992). instance, companies singleoffice address, may one. still quite useful fill addressfields Names++ finds previous name matching Company field. userinterface strategies compensate possible range values arise;instance, Names++ puts alternate addresses Address fields adaptive menu.Therefore, dense dependencies functional nearly so, dense approximatelyfunctional dependencies, used set predictive fillin.determine dense approximately-functional dependencies hold newapplication area, may necessary repeat type empirical domain analysisdescribed adaptive menus. Names++, used common sense knowledgepeople, companies, addresses set predictive fillin. Recall goaldiscover end result automatic learning worthwhile (e.g., Dent et al., 1992;Hermens & Schlimmer, 1994; Schlimmer & Hermens, 1993; Yoshida, 1994). recommendconsidering field number logical components dependencies may existparts rather whole fields. instance, person company may sharecommon telephone number area code prefix, likely different346fiT HREE NTERFACES NORMATION C APTURE: C ASE TUDY DDING N AME NFORMATIONextensions. predictively filling last component phone number, Names++fills much without adding poor quality information.6. Related WorkThough interested different tasks, researchers studied using intelligent userinterfaces speed information capture. instance, Hermens Schlimmer (1994) builtelectronic form filler tried provide default values every field form.field form decision tree calculate default value. Like Names++,calculations used previously entered information generate defaults predictively fillfields. Unlike Names++, calculations constructed run-time usingmachine learning method. (Names++ alter predictive fillin run-time. cf. Table 1.)field tested system single electronic form filled several hundred timeseight month period. report 87% reduction keystrokes; loosely translatingspeedup yields 669% speedup approximately 3 times 210% speedupobserved entering name.Studying text prediction without field boundaries, Pomerleau (1995) built typingcompletion aid. Without relying note-taking properties, system predicts completioncurrent word typed (presumably editor). connectionist networkestimates probability number possible completions current word;likely, threshold, offered user. Pomerleau tested system pairsubjects two-week period reports increase typing speed 2% Englishtext 1318% computer program code. modest gain may due inefficiencieslearning method, lack redundancy task, limitations userinterface itself.complement earlier research, paper reports individual collectiveaccuracy three user interface components. reports user task time showingcomponents significantly improve efficiency. paper also clarifies issue confoundedearlier work. learning interface less effective expected, due inherentlimitation interface itself, learning method perform inadequately?answer second question, work compares two learning methods.paper, hand-built predictive fillin structures (cf. Table 1) able assessquality predictive fillin interface directly.7. Conclusionpaper makes two main contributions. First, presents study impact threeuser interface components time enter information computer: handwritingrecognition, adaptive menus, predictive fillin. Handwriting recognition slowertyping preferred users. Advances handwriting recognition may make faster,recognition would still much slower choosing value menu predictivefillin. three components work well together preferred users.Second, paper discusses principles applying adaptive menus predictive fillinnew application areas. Fields few, frequently repeated values candidatesadaptive menus; functional dependencies indicate candidates predictive fillin. Whethercharacteristics learned run-time topic future research.347fiS CHLIMMER & W ELLSAcknowledgmentsKerry Hersh Raghavendra provided names used Section 4. Apple Computer developedsupports Newton Newton ToolKit programming environment. Newton AIgroup WSU provided many useful comments earlier draft paper. Geoff Allen,Karl Hakimian, Mike Kibler, EECS staff provided consistent reliablecomputing environment. Anonymous reviewers earlier draft paper providedmany (many) valuable suggestions. work supported part NASA grantnumber NCC 2-794.ReferencesAgre, P. E., & Chapman, D. (1987). Pengi: implementation theory activity.Proceedings Sixth National Conference Artificial Intelligence (pp. 268272).Seattle, WA: AAAI Press.Cesar, M., & Shinghal, R. (1990). algorithm segmenting handwriting postal codes.Int. J. Man-Machine Studies, 33, 6380.Culbert, M. (1994). Low power hardware high performance PDA. Proceedings1994 IEEE Computer Conference. San Francisco, CA: IEEE.Dent, L., Boticario, J., McDermott, J., Mitchell, T., & Zabowski, D. (1992). personallearning apprentice. Proceedings Tenth National Conference ArtificialIntelligence (pp. 96103). San Jose, CA: AAAI Press.Hermens, L. A., & Schlimmer, J. C. (1994). machine learning apprenticecompletion repetitive forms. IEEE Expert, 9, 1, 2833.Horswill, I. D., & Brooks, R. A. (1988). Situated vision dynamic world: Chasing objects.Proceedings Seventh National Conference Artificial Intelligence (pp. 796800).St. Paul, MN: AAAI Press.Kolodner, J. (1993). Case-based reasoning. San Francisco, CA: Morgan Kaufmann.Kreigh, R. J., Pesot, J. F., & Halcomb, C. G. (1990). evaluation look-ahead help fieldsvarious types menu hierarchies. Int. J. Man-Machine Studies, 32, 649661.Lee, J. (1990). Intelligent interfaces UIMS. D. A. Duce, M. R. Gomes, F. R. A.Hopgood, & J. R. Lee (Eds.), User interface management design. NY: SpringerVerlag.MacKenzie, S. I., Nonnecke, B., Riddersma, S., McQueen, C., & Meltz, M. (1994).Alphanumeric entry pen-based computers. Int. J. Human-Computer Studies, 41,755792.Meyer, A. (1995). Pen computing: technology overview vision. SIGCHI Bulletin, 27,3, 4690.Mitchell, J., & Shneiderman, B. (1989). Dynamic versus static menus: exploratorycomparison. SIGCHI Bulletin, 20, 4, 33-37.348fiT HREE NTERFACES NORMATION C APTURE: C ASE TUDY DDING N AME NFORMATIONNorman, K. L. (1991). psychology menu selection: Designing cognitive controlhuman/computer interface. Norwood, NJ: Ablex.Pomerleau, D. A. (1995). connectionist technique accelerated textual input: Lettingnetwork typing. Advances Neural Information Processing Systems 7.Cambridge, MA: MIT Press.Rissland, E. L. (1984). Ingredients intelligent user interfaces. Int. J. Man-MachineStudies, 21, 377388.Raju, K. V. S. V. N., & Majumdar, A. K. (1988). Fuzzy functional dependencies losslessjoin decomposition fuzzy relational database systems. ACM Trans. Database Syst. 13,2, 129166.Russell, S. J. (1989). use knowledge analogy induction. San Francisco, CA:Morgan Kaufmann.Schlimmer, J. C., & Hermens, L. A. (1993). Software agents: Completing patternsconstructing interfaces. Journal Artificial Intelligence Research, 1, 6189.Sears, A. & Shneiderman, B. (1994). Split menus: Effectively using selection frequencyorganize menus. ACM Trans. Computer-Human Interaction, 1, 1, 2751.Smith, W. R. (1994). Newton application architecture. Proceedings 1994 IEEEComputer Conference. San Francisco, CA: IEEE.Snowberry, K., Parkinson, S., & Sisson, N. (1985). Effects help fields navigatinghierarchical menu structures. Int. J. Man-Machine Studies, 22, 479491.Ullman, J. D. (1988). Principles database knowledge-base systems: Volume 1.Rockville, MD: Computer Science Press.Ward, J. R., & Blesser, B. (1986). Interactive recognition handprinted characterscomputer input. SIGCHI Bulletin, 18, 1, 4457.Wilkinson, L., Hill, M., & Vang, E. (1992). SYSTAT: Graphics, Version 5.2 Edition.Evanston, IL: SYSTAT, Inc.Witten, I. H., Cleary, J. G., & Greenberg, S. (1984). frequency-based menu-splittingalgorithms. Int. J. Man-Machine Studies, 21, 135-148.Yoshida, K. (1994). User command prediction graph-based induction. Sixth IEEEInternational Conference Tools Artificial Intelligence (pp. 732735). NewOrleans, LA: IEEE.Ziarko, W. (1992). discovery, analysis, representation data dependencies.Piatetsky-Shapiro, G., & Frawley, W. (Eds.), Knowledge discovery databases. PaloAlto, CA: AAAI Press.349fiJournal Artificial Intelligence Research 5 (1996) 239-288Submitted 3/96; published 11/96MUSE CSP: ExtensionConstraint Satisfaction ProblemRandall A. HelzermanMary P. HarperSchool Electrical Computer Engineering1285 Electrical Engineering BuildingPurdue UniversityWest Lafayette, 47907-1285 USAhelz@ecn.purdue.eduharper@ecn.purdue.eduAbstractpaper describes extension constraint satisfaction problem (CSP) calledMUSE CSP (MU ltiply SE gmented C onstraint atisfaction P roblem). extensionespecially useful problems segment multiple sets partially sharedvariables. problems arise naturally signal processing applications including computer vision, speech processing, handwriting recognition. applications,often dicult segment data one way given low-level information utilizedsegmentation algorithms. MUSE CSP used compactly represent severalsimilar instances constraint satisfaction problem. multiple instances CSPcommon variables domains constraints,combined single instance MUSE CSP, reducing work required applyconstraints. introduce concepts MUSE node consistency, MUSE arc consistency,MUSE path consistency. demonstrate MUSE CSP used compactly represent lexically ambiguous sentences multiple sentence hypothesesoften generated speech recognition algorithms grammar constraintsused provide parses syntactically correct sentences. Algorithms MUSE arcpath consistency provided. Finally, discuss create MUSE CSPset CSPs labeled indicate variable sharedsingle CSP.1. Introductionpaper describes extension constraint satisfaction problem (CSP) called MUSECSP (MU ltiply SE gmented C onstraint atisfaction P roblem). extension especiallyuseful problems segment multiple sets partially shared variables.First, describe constraint satisfaction problem define extension.1.1 Constraint Satisfaction ProblemConstraint satisfaction problems (CSP) rich history Artificial Intelligence (Davis& Rosenfeld, 1981; Dechter, Meiri, & Pearl, 1991; Dechter & Pearl, 1988; Freuder, 1989,1990; Mackworth, 1977; Mackworth & Freuder, 1985; Villain & Kautz, 1986; Waltz, 1975)(for general reference, see Tsang, 1993). Constraint satisfaction provides convenient wayrepresent solve certain types problems. general, problemssolved assigning mutually compatible values predetermined number variablesc 1996AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiHelzerman & Harperset constraints. approach used variety disciplines includingmachine vision, belief maintenance, temporal reasoning, graph theory, circuit design,diagnostic reasoning. using CSP approach (e.g., Figure 1), variables typically depicted vertices nodes, node associated finite set possiblevalues, constraints imposed variables depicted using arcs. arc loopingnode represents unary constraint (a constraint single variable),arc two nodes represents binary constraint (a constraint two variables).classic example CSP map coloring problem (e.g., Figure 1), color mustassigned country two neighboring countries color.variable represents country's color, constraint arc two variables indicatestwo joined countries adjacent assigned color.Formally, CSP (Mackworth, 1977) defined Definition 1.Definition 1 (Constraint Satisfaction Problem)N = fi; j; : : :g set nodes (or variables), jN j = n,L = fa; b; : : :g set labels, jLj = l,Li = faja 2 L (i; a) admissibleg,R1 unary constraint, (i; a) admissible R1 (i; a),R2 binary constraint, (i; a) , (j; b) admissible R2 (i; a; j; b).CSP network contains n-tuples Ln satisfy R1 R2 . Sincelabels associated node may incompatible labels assigned nodes,desirable, constraints suciently tight (van Beek, 1994), eliminatemany labels possible enforcing local consistency conditions globallyconsistent solution extracted (Dechter, 1992). Node arc consistency definedDefinitions 2 3, respectively. addition, may desirable eliminate many labelpairs possible using path consistency, defined Definition 4.Definition 2 (Node Consistency) instance CSP said node consistentnode's domain contains labels unary constraint R1 holds, i.e.:8i 2 N : 8a 2 Li : R1 (i; a)Definition 3 (Arc Consistency) instance CSP said arc consistentevery pair nodes j , element Li (the domain i) least one element Ljbinary constraint R2 holds, i.e.:8i; j 2 N : 8a 2 Li : 9b 2 Lj : R2 (i; a; j; b){red, green, blue}DifferentColor123{red, green, blue}DifferentColor123{red, green, blue}DifferentColorFigure 1: map coloring problem example CSP.240fiMUSE CSP: Extension Constraint Satisfaction ProblemDefinition 4 (Path Consistency) instance CSP said path consistent if:8i; j 2 N : 6= j ) (8a 2 Li : 8b 2 Lj : 8k 2 N : k 6= ^ k 6= j ^ P ath(i; k; j ) )(R2(i,a,j,b)) 9c 2 Lk : R2 (i; a; k; c) ^ R2 (k; c; j; b)))Path(i; k; j ) indicates path arcs length two connecting jgoes k.Node consistency easily enforced operation Li = Li \ fxjR1 (i; x)g, requiringO(nl) time (where n number variables l maximum domain size). Arcconsistency enforced ensuring every label node supported least onelabel node shares binary constraint (Mackworth, 1977; Mackworth& Freuder, 1985; Mohr & Henderson, 1986). arc consistency algorithm AC-4 (Mohr& Henderson, 1986) worst-case running time (el2) (where e numberconstraint arcs). AC-3 (Mackworth & Freuder, 1985) often performs better AC-4practice, though slower running time worst case. AC-6 (Bessiere, 1994)worst-case running time AC-4 faster AC-3 AC-4 practice.Path consistency ensures pair labelings (i; a) , (j; b) allowed (i; j ) arcdirectly also allowed arc paths j . Montanari proven ensurepath consistency complete graph, suces check every arc path length two(Montanari, 1974). path consistency algorithm PC-4 (Han & Lee, 1988) worstcase running time O(n3 l3) time (where n number variables CSP).1.2 Multiply Segmented Constraint Satisfaction Problemmany types problems solved using CSP less directfashion. also problems might benefit CSP approach,dicult represent single CSP. class problems paper addresses.example, suppose map represented Figure 1 scanned noisy computervision system, resulting uncertainty whether line regions 1 2really border artifact noise. situation would yield two CSP problemsdepicted Figure 2. brute-force approach would solve problems,would reasonable scenes containing ambiguous borders. However,number ambiguous borders increases, number CSP networks would growcombinatorially explosive fashion. case ambiguous segmentation,ecient merge constraint networks single network would compactlyrepresent instances simultaneously, shown Figure 3. Notice CSPinstances combined directed acyclic graph paths DAGstart end correspond CSPs combined. paper, developextension CSP called MUSE CSP (MU ltiply SE gmented C onstraint atisfactionP roblem), represents multiple instances CSP problem DAG.multiple, similar instances CSP, separately applying constraintsinstance result much duplicated work. avoid duplication,provided way combine multiple instances CSP MUSE CSP,241fiHelzerman & Harper{red, green, blue}{red, green, blue}113DifferentColor31{red, green, blue}231DifferentColor1DifferentColor23{red, green, blue}{red, green, blue}32DifferentColorFigure 2: ambiguous map yields two CSP problems.start{red, green, blue}DifferentColorDifferentColor1{red, green, blue}3{red, green, blue}DifferentColor1{red, green,blue}DifferentColorDifferentColor13223end{red, green, blue}{red, green, blue}{red, green, blue}DifferentColor{red, green, blue}DifferentColorFigure 3: two CSP problems Figure 2 captured single instanceMUSE CSP. directed edges form DAG directed pathsDAG correspond instances CSPs combined.242fiMUSE CSP: Extension Constraint Satisfaction Problemdeveloped concepts MUSE node consistency, MUSE arc consistency, MUSE pathconsistency. Formally, define MUSE CSP follows:Definition 5 (MUSE CSP)N = fi; j; : : :g set nodes (or variables), jN j = n,2N set segments jj = s,L = fa; b; : : :g set labels, jLj = l,Li = faja 2 L (i; a) admissible least one segmentg,R1 unary constraint, (i; a) admissible R1 (i; a),R2 binary constraint, (i; a) , (j; b) admissible R2 (i; a; j; b).segments different sets nodes representing CSP instancescombined form MUSE CSP. solution MUSE CSP defined solutionone segments:Definition 6 (Solution MUSE CSP) solution MUSE CSP assignment ffsegment = fi1; : : :; ip g 2 ff 2 Li1 Lip R1(ix ; ff(ix )) holdsevery node ix 2 , R2(ix ; ff(ix); iy ; ff(iy )) holds every pair nodes ix ; iy 2 ,ix 6= iy .Depending application, solution MUSE CSP could also setconsistent labels single path MUSE CSP, single set labelspaths (or CSPs), compatible sets labels paths.MUSE CSP solved modified backtracking algorithm findsconsistent label assignment segment. However, constraints sucientlytight, search space pruned enforcing local consistency conditions, node,arc, path consistency. gain eciency resulting enforcing local consistencyconditions backtracking, node, arc, path consistency must modified MUSECSP. definitions MUSE CSP node consistency, arc consistency, path consistencyappear Definitions 7, 8, 9, respectively.Definition 7 (MUSE Node Consistency) instance MUSE CSP said node consistentnode's domain Li contains labels unary constraint R1 holds,i.e.:8i 2 N : 8a 2 Li : R1 (i; a)Definition 8 (MUSE Arc Consistency) instance MUSE CSP said MUSE arc consis-tent every label domain Li least one segment whose nodes'domains contain least one label b binary constraint R2 holds, i.e.:8i 2 N : 8a 2 Li : 9 2 : 2 ^ 8j 2 : j 6= ) 9b 2 Lj : R2 (i; a; j; b)Definition 9 (MUSE Path Consistency) instance MUSE CSP said path consistentif:8i; j 2 N : 6= j ) (8a 2 Li : 8b 2 Lj : 9 2 : i; j 2 ^ 8k 2 : k 6= ^ k 6= j ^ P ath(i; k; j ) )(R2 (i; a; j; b) ) 9c 2 Lk : R2 (i; a; k; c) ^ R2 (k; c; j; b)))243fiHelzerman & Harpera.b.3{c,d}start1{e}3{e}{d}end2{a,b}e 1be 1ce 0 1be 0 1startend21{b}44{f}{f}c1 0b 0 1bf 1 1cf 0 1b1bf 1f1Figure 4: a. MUSE CSP MUSE arc consistency achieved; b. MUSE CSPMUSE arc consistency achieved.MUSE CSP node consistent segments node consistent. Unfortunately,MUSE CSP arc consistency requires attention. enforcing arc consistencyCSP, label 2 Li eliminated node whenever domain Ljlabels together satisfy binary constraints. However, MUSE CSP,label eliminated node, must unsupported arcs everysegment appears, required definition MUSE arc consistency shownDefinition 8. Notice Definition 8 reduces Definition 3 number segmentsone.demonstrate MUSE arc consistency applies MUSE CSP, consider MUSECSP Figure 4a. Notice label c 2 L2 supported labels L3L4 , receive support labels L1. label consideredMUSE arc consistent? answer node 2 member pathsDAG contain node 3 node 4, neither support labelc. segment nodes label supportsc, c eliminated L2. c eliminated L2, also eliminatedL1 . elimination c L2 causes loose support node2. Since node 2 member every path, segment provides support a.MUSE arc consistent DAG depicted Figure 4b. Note MUSE arc consistencyensure individual segments arc consistent CSPs. example, Figure5 MUSE arc consistent even though segments CSP arc consistent.c receives arc support (which local computation) arcs leastone paths. cannot ensure values support labelmutually consistent considering MUSE arc consistency alone. case, MUSE pathconsistency together MUSE arc consistency would needed eliminate illegallabels c a.enforcing path consistency CSP, R2 (i; a; j; b) becomes false if, thirdnode k, label c 2 Lk R2 (i; a; k; c) R2 (k; c; j; b) true.244fiMUSE CSP: Extension Constraint Satisfaction Problemce 1 1be 0 13{c,d}start1{e}end2{a,b}4{f}c1 0b 0 1bf 1 1cf 0 1Figure 5: MUSE CSP MUSE arc consistent, arc consistentsegment.MUSE CSP, binary constraint becomes path inconsistent one segment, could stillallowed another. Therefore, definition MUSE path consistency modifiedshown Definition 9.Enforcement MUSE arc path consistency requires modification traditionalCSP algorithms. algorithms described introduce several applicationsMUSE CSP proven useful.2. MUSE CSP Constraint-based Parsingdesirable represent MUSE CSP directed acyclic graph (DAG)directed paths DAG correspond instances CSP problems. ofteneasy determine variables shared construct DAG.application presented section one MUSE CSP useful. parsingproblem naturally represented DAG presence ambiguity. manycases, word multiple parts speech; convenient representwords nodes MUSE CSP. speech recognition systems, identificationcorrect words sentence improved using syntactic constraints. However, wordrecognition algorithm often produces lattice word candidates. Clearly, individuallyparsing sentences lattice inecient.2.1 Parsing Constraint Dependency GrammarMaruyama developed new grammar called Constraint Dependency Grammar (CDG)(Maruyama, 1990a, 1990b, 1990c). showed CDG parsing castCSP finite domain, constraints used rule ungrammatical sentences.CDG four-tuple, h; R; L; C i, where:245fiHelzerman & Harper= finite set preterminal symbols, lexical categories.R = finite set uniquely named roles (or role-ids) = fr1; : : :; rp g.L = finite set labels = fl1 ; : : :; lq g.C = finite set constraints assignment must satisfy.sentence = w1 w2w3 : : :wn 2 string length n. word wi 2sentence s, must keep track p different roles (or variables). role variabletakes role values form <l; m>, l 2 L 2 fnil; 1; 2; : : :ng. Role valuesdenoted examples label-modifiee. parsing, label L indicates differentsyntactic function. value role value <l; m>, assigned particularrole wi, specifies position word wi modifying takesfunction specified label, l (e.g., subj-3 indicates word labelsubject modifies third word sentence). sentence saidgenerated grammar G exists assignment maps role valuen p roles constraint set C (described next paragraph)satisfied.constraint set logical formula form: 8x1 ; x2; : : :; xa (and P1 P2 : : : Pm ),xi ranges role values roles word s.subformula Pi C must form: (if Antecedent Consequent), AntecedentConsequent predicates predicates joined logical connectives.basic components used express constraints.Variables: x1 , x2, : : : xa (a = 2 (Maruyama, 1990a)).Constants: elements subsets [ L [ R [ fnil, 1, 2, : : :, ng, n correspondsnumber words sentence.Functions:(pos x) returns position word role value x.(rid x) returns role-id role value x.(lab x) returns label role value x.(mod x) returns position modifiee role value x.(cat y) returns category (i.e., element ) word position y.Predicates: =, >, <1 .Logical Connectives: and, or, not.subformula Pi called unary constraint contains one variable binary constraint contains two. CDG grammar two associated parameters, degreearity. degree grammar G number roles. arity grammar, a,corresponds maximum number variables subformulas C .Consider example grammar, G1 , defined using following four-tuple:h1 = fdet; noun; verbg; R1 = fgovernorg, L1 = fdet; root; subjg, C1 (see constraintsFigure 6)i. G1 degree one arity two. illustrate process parsing1. Note 1 > nil 1 < nil false, nil integer. MUSE networks, relate positionintervals using <, >, =.246fiMUSE CSP: Extension Constraint Satisfaction Problemconstraint satisfaction, Figure 6 shows steps parsing sentence dogeats. simplify presentation example, grammar uses single role,governor role, denoted G constraint network Figure 6. governorrole indicates function word fills sentence governed head word.word called head phrase forms basis phrase (e.g., verbhead sentence). useful grammars, would also include several needs roles(e.g, need1, need2) make certain head word constituents needscomplete (e.g., singular count noun needs determiner complete noun phrase).determine whether sentence, dog eats, generated grammar, CDGparser must able assign least one role value n p roles satisfiesgrammar constraints (n = 3 sentence length, p = 1 number roles).values role selected finite set L1 fnil, 1, 2, 3g, CDG parsingviewed constraint satisfaction problem finite domain. Therefore, constraintsatisfaction used determine possible parses sentence.Initially, word, possible role values assigned governor role.assume word must either modify another word (other itself) modifyword (m=nil). Nothing gained CDG word modify itself. Next unaryconstraints applied role values constraint network. role valueincompatible unary constraint satisfies antecedent,consequent. Notice Figure 6 role values associated governor rolefirst word (the) satisfy antecedent first unary constraint, det-nil, subjnil, subj-2, subj-3, root-nil, root-2, root-3 satisfy consequent,incompatible constraint. role value violates unary constraint, nodeconsistency eliminates role values role never participateparse sentence. unary constraints applied top constraintnetwork Figure 6, second network produced.Next, binary constraints applied. Binary constraints determine pairs rolevalues legally coexist. keep track pairs role values, arcs constructed connecting role roles network, arc associated arc matrix,whose row column indices role values associated two roles connects.entries arc matrix either 1 (indicating two role values indexingentry compatible) 0 (indicating role values cannot simultaneously exist). Initially, entries matrix set 1, indicating pair role valuesindexing entry initially compatible (because constraints applied).example, single binary constraint (shown Figure 6) applied pairsrole values indexing entries matrices. example, x=det-3y=root-nil eats, consequent binary constraint fails; hence, role valuesincompatible. indicated replacing entry 1 0.Following binary constraints, roles constraint network still containrole values incompatible parse sentence. Role valuessupported binary constraints eliminated achieving arc consistency.example, det-3 supported remaining role value eats thusdeleted role.arc consistency, example sentence single parse onevalue per role sentence. parse sentence consists assignment role values247fiHelzerman & Harperdet1dogeatsnoun2verb3GG{detnil, det2, det3,subjnil, subj2, subj3,rootnil, root2, root3}G{detnil, det1, det3,subjnil, subj1, subj3,rootnil, root1, root3}{detnil, det1, det2,subjnil, subj1, subj2,rootnil, root1, root2}1. (if (= (cat (pos x)) det)2. (if (= (cat (pos x)) noun)(and (= (lab x) det)(and (= (lab x) subj)(< (pos x) (mod x))))(< (pos x) (mod x))))Apply Unary ConstraintsEnforce Node Consistency:3. (if (= (cat (pos x)) verb)(and (= (lab x) root)(= (mod x) nil)))det1dogeatsnoun2verb3GGG{subj3}{det2, det3}{rootnil}rootnilsubj3det21det31subj31rootnildet21det31(if (and (= (lab x) det)(= (mod x) (pos y)))(= (cat (pos y)) noun))Apply Binary Constraints:det1dogeatsnoun2Gverb3GG{subj3}{det2, det3}{rootnil}rootnilsubj3det21det31subj31rootnildet21det30Enforce Arc Consistency:det1dogeatsnoun2verb3GG{det2}{subj3}G{rootnil}Figure 6: Using constraints parse sentence: dog eats.248fiMUSE CSP: Extension Constraint Satisfaction Problemroles unary binary constraints satisfied assignment.general, one parse sentence; hence, oneassignment values roles sentence. Note assignment examplesentence is:pos word cat governor role's value1 detdet-22 dog nounsubj-33 eats verbroot-nilone possible sentence part speech wordsknown advance, parsing problem cast CSP. However,ambiguity present written spoken sentences handled uniformly requires useMUSE CSP.2.2 Processing Lexically Ambiguous Sentences CDGOne shortcoming Maruyama's constraint-based parser requires wordsingle part speech; however, many words English language onelexical category. assumption captured way Maruyama writes constraintsinvolving category information; category determined based positionword sentence. However, even simple example, word dog couldeither noun verb prior propagation syntactic constraints. Since parsingused lexically disambiguate sentence, ideally, parsing algorithmrequire part speech words known prior parsing.Lexically ambiguous words easily accommodated creating CSPpossible combination lexical categories; however, would combinatorially explosive.contrast, using MUSE CSP, create separate word node legal partspeech word, sharing words ambiguous across segments. Sinceposition uniquely define category word, must allow category informationaccessed role value rather position word sentence(i.e., use (cat x) rather (cat (pos x))). associate category informationrole value, could instead create role values lexical category wordstore values single word node. However, representationconvenient MUSE CSP representation problem. lexically augmentedCSP, one role per word (this usually case), role valuesassociated one lexical category one role cannot support role values associatedanother lexical category another role word. Additional constraintsmust propagated enforce requirement. MUSE CSP representationsuffer problem. using separate node part speech, MUSE CSPdirectly represents independence alternative lexical categories given word.space requirements arc matrices MUSE representation lowerlexicalized CSP arc roles different lexical categoriesword MUSE representation. Note MUSE arc consistency equivalentperforming arc consistency lexically augmented CSP (after additional constraints249fiHelzerman & Harperpropagated)2. importantly, MUSE CSP represent lattices cannotcombined single CSP.technique creating separate nodes different instances word alsoused handle feature analysis (like number person) parsing (Harper & Helzerman,1995b). Since words multiple feature values, often ecient createsingle node set feature values, apply syntactic constraints, split nodeset nodes single feature value prior applying constraints pertainingfeature type. Node splitting also used support use context-specificconstraints (Harper & Helzerman, 1995b).2.3 Lattice ExampleMuch motivation extending CSP comes work spoken language parsing(Harper & Helzerman, 1995a; Harper, Jamieson, Zoltowski, & Helzerman, 1992; Zoltowski,Harper, Jamieson, & Helzerman, 1992). output hidden-Markov-model-basedspeech recognizer thought lattice word candidates. Unfortunately,lattice contains many word candidates never appear sentence coveringduration speech utterance. converting lattice word graph, many wordcandidates lattice eliminated. Figure 7 depicts word graph constructedsimple lattice. Notice word tour eliminated word graphconstructed. order accommodate words occur time intervals mayoverlap, word's position lattice represented tuple (b; e)b < e. positional relations defined constraints easily modified operatetuples (Harper & Helzerman, 1995a).construction, word graph often contains spurious sentence hypothesespruned using variety constraints (e.g., syntactic, semantic, etc.).apply constraints individual sentences rule ungrammatical; however,individually processing sentence hypothesis inecient since many high degreesimilarity. spoken language parsing problem structured MUSE CSP problem,constraints used parse individual sentences would applied word graphsentence hypotheses, eliminating consideration many hypothesesungrammatical.developed MUSE CSP constraint-based parser, PARSEC (Harper & Helzerman, 1995a, 1995b; Harper et al., 1992; Zoltowski et al., 1992), capable parsingword graphs containing multiple sentences produced speech recognition module.developed syntactic semantic constraints parsing single sentences,applied word graph, eliminate hypotheses syntactically semanticallyincorrect. MUSE CSP used parser thought parse forestpruned using constraints. applying constraints wide variety knowledgesources, parser prunes composite structure many role values associatedrole, well word nodes remaining role values. Several experiments(Harper et al., 1992; Zoltowski et al., 1992) considered effective syntactic2. simple demonstration, consider merging nodes 3 4 Figure 5 single nodevalue e f keep track fact type 3 4, respectively. circumstances,CSP arc consistency give results MUSE CSP arc consistency; even though c appearsolutions, eliminated. Note example uses one role per node.250fiMUSE CSP: Extension Constraint Satisfaction Problemtourwreckhard1nicebeachrecognizes2345wreck(4,6)(1,2)hardstart(1,2)6(2,3)speech78nice(6,7)(7,8)9beach(8,9)(3,4)endrecognizes(4,8)speech(8,9)Figure 7: Multiple sentence hypotheses parsed simultaneously applying constraints word graph rather individual sentences extractedlattice.semantic constraints pruning word nodes appear sentence hypothesis.work speech processing, MUSE arc consistency algorithm effectivepruning role values composite structure never appear parsesentence (i.e., individual CSP). Constraints usually tight enough MUSEarc consistency eliminates role values participate least one parserepresented sentences.MUSE CSP useful way process multiple sentences arc consistencyalgorithm effective eliminating role values cannot appear sentence parses.Several factors contribute effectiveness arc consistency algorithmproblem. First, syntactic constraints fairly tight constraints. Second, rolevalues contain segmental information constrain problem. Consider wordgraph Figure 8. value s-(3,4) associated role marked N wordcannot support values role marked G word dogs position (3,5),legal segment involving position (3,5). figure, markentries value associated one role segmentally incompatible valuesanother N. entries equivalent 0. Third, many times constraintscreate symmetric dependencies words sentence. example, one constraintmight indicate verb needs subject left, another subject mustgoverned verb right.2.4 Demonstration Utility MUSE CSP Parsingdemonstrate utility MUSE CSP simultaneously parsing multiple CSP instances,consider problem determining strings length 3n consisting a's, b's, c's251fiHelzerman & Harperobj(1,2) obj(2,3)s(3,4)NNs(3,5)01{obj(1,2),obj(2,3)}{rootnil}GstartNGNN {npnil}Gdogs(3,5){s(3,4),s(3,5)}end{blanknil}{subj(2,3),subj(3,4),subj(3,5)}(1,2)(2,3){obj(1,2),obj(2,3)}GN {np(1,2),np(2,3)}dog(3,4)obj(1,2) obj(2,3)s(3,4)01s(3,5)NNFigure 8: parsing word graphs, values assigned roles contain segmentalinformation make incompatible values associatedroles. example, s-(3,4) cannot support values associatedG N roles word dogs.language bn cn . value n = 3, problem representedsingle MUSE CSP problem shown Figure 9 (the roles role values depictedsimplify figure). devised constraints language (see Figure 10)eliminate role values sentences language well ungrammaticalrole values sentence language. constraints applied followedMUSE arc consistency lattice like Figure 9 length divisible three,grammatical sentence remain single parse. lattices containingsentences lengths divisible three, role values eliminatedMUSE arc consistency (there grammatical sentence). Hence, searchrequired extract parse one. n = 3 case Figure 9, parse appearsFigure 11. single parse result regardless n chosen. Note modifieesrole values parse used ensure a, correspondingc; b, corresponding a; c, corresponding b. Figure12 examines time needed extract parse sentences language bn cnMUSE CSPs representing strings length 3n, 1 n 7, containing a, b, c.time perform MUSE AC-1 extract solution compared time extractsolution without preprocessing. time perform MUSE AC-1 extractparse stable sentence length grows, time extract parse grows quicklysentence lengths greater 15 MUSE arc consistency used.previous example involves grammar one parse singlesentence lattice; however, simple matter provide similar demonstrations252fiMUSE CSP: Extension Constraint Satisfaction Problemstart(1,2)(2,3)(3,4)(4,5)(5,6)(6,7)(7,8)(8.9)(9,10)bbbbbbbbb(1,2)(2,3)(3,4)(4,5)(5,6)(6,7)(7,8)(8.9)(9,10)cccccc(1,2)(2,3)(3,4)(4,5)(5,6)(6,7)ccc(7,8)(8.9)(9,10)endFigure 9: single MUSE CSP simultaneously test possible orderings a's, b's,c's membership language anbncn , n = 3.2= fa, b, cg= fgovernorgL2 = fa, b, cgC2 = see below:R2; 3 Unary Constraints(if (and (=(=(and (=(>(cat(rid(lab(modx)x)x)x)a)governor))a)(pos x))))(if (and (=(=(and (=(<(cat(rid(lab(modx)x)x)x)c)governor))c)(pos x))))(if (and (=(=(and (=(<(cat(rid(lab(modx)x)x)x)b)governor))b)(pos x)))); 8 Binary Constraints(if (and (= (lab x) a)(or (= (lab y) b)(= (lab y) c)))(< (pos x) (pos y)))(if (and (= (lab x) b)(= (lab y) c))(< (pos x) (pos y)))(if (and (=(=(>(< (mod(lab x)(lab y)(pos x)x) (moda)a)(pos y)))y)))(if (and (=(=(=(= (lab(if (and (=(=(>(< (mod(lab x)(lab y)(pos x)x) (modb)b)(pos y)))y)))(if (and (= (lab x) b)(= (mod x) (pos y))(= (rid y) governor))(= (lab y) a))(if (and (=(=(>(< (mod(lab x)(lab y)(pos x)x) (modc)c)(pos y)))y)))(if (and (=(=(=(= (lab(lab x) a)(mod x) (pos y))(rid y) governor))y) c))(lab x) c)(mod x) (pos y))(rid y) governor))y) b))Figure 10: G2 = h2; R2; L2; C2i accepts language bn cn , n 0.253fiHelzerman & Harperpos(1,2)(2,3)(3,4)(4,5)(5,6)(6,7)(7,8)(8,9)(9,10)cat governor role's valuebbbccca-(9,10)a-(8,9)a-(7,8)b-(3,4)b-(2,3)b-(1,2)c-(6,7)c-(5,6)c-(4,5)Figure 11: single parse remaining network depicted Figure 9 applyingconstraints G2 enforcing MUSE arc consistency.2500CPU Time seconds2000Extract without MUSE AC115001000500Extract plus MUSE AC102468101214Lattice Length16182022Figure 12: graph depicts time extract parse language bn cnMUSE CSP representing sentences length 3n, n varies 17. time extract parse without MUSE arc consistency comparedtime perform MUSE AC-1 extract parse.254fiMUSE CSP: Extension Constraint Satisfaction Problem3= fa, b, cg= fgovernorgL3 = fw1, w2gC3 = see below:R3; 2 Unary Constraints(if (= (lab x) w1)(< (pos x) (mod y)))(if (= (lab x) w2)(> (pos x) (mod y))); 6 Binary Constraints(if (and (= (lab x) w1)(= (lab y) w2))(< (pos x) (pos y)))(if (and (=(=(>(> (mod(lab x)(lab y)(pos x)x) (modw1)w1)(pos y)))y)))(if (and (=(=(and (=(=(lab(mod(lab(catw1)(pos y)))w2)(cat y))))x)x)y)x)(if (and (= (lab x) w1)(= (lab y) w2))(> (mod x) (mod y)))(if (and (= (lab x) w2)(= (lab y) w2)(> (pos x) (pos y)))(< (mod x) (mod y)))(if (and (= (lab x) w2)(= (mod x) (pos y)))(= (lab y) w1))Figure 13: G3 = h3 ; R3; L3; C3i accepts language ww.complex cases. example, constraint grammar shown Figure 13parse possible sentences given length language ww, wfa; b; cg+. Consider MUSE CSP Figure 14 (the roles role valuesdepicted simplify figure). applying constraints performing MUSE arcconsistency MUSE CSP, precisely 81 strings ww,parses compactly represented constraint network. constraints plus MUSEarc consistency eliminate every value cannot appear parse. lattices containingodd length sentences, role values remain MUSE arc consistency. Figure 15 showstime needed extract parses sentences language wwMUSE CSPs vary length w 1 8. time perform MUSE AC-1extract parses grows slowly sentence length increases number parsesincreases sentence length; however, grows slowly time extractparses MUSE arc consistency used.Similar results also obtained grammars used parse word graphs constructed spoken sentences resource management ATIS domains (Harperet al., 1992; Zoltowski et al., 1992; Harper & Helzerman, 1995a).3. MUSE CSP Arc Consistency Algorithmsection, introduce algorithm, MUSE AC-1, achieve MUSE CSP arc consistency. algorithm builds upon AC-4 algorithm (Mohr & Henderson, 1986),present algorithm first comparison purposes.255fiHelzerman & Harperstart(1,2)(2,3)(3,4)(4,5)(5,6)(6,7)(7,8)(8.9)bbbbbbbb(1,2)(2,3)(3,4)(4,5)(5,6)(6,7)(7,8)(8.9)cccccc(1,2)(2,3)(3,4)(4,5)(5,6)(6,7)cc(7,8)(8.9)endFigure 14: single MUSE CSP simultaneously test possible orderings a's, b's,c's membership language ww jwj = 4 .3000CPU Time seconds25002000Extract without MUSE AC115001000500Extract plus MUSE AC10246810Lattice Length121416Figure 15: graph depicts time extract parses language wwMUSE CSP representing sentences length 2 16 w 2 fa; b; cg+.time extract parses without MUSE arc consistency comparedtime perform MUSE AC-1 extract parses.256fiMUSE CSP: Extension Constraint Satisfaction ProblemNotationMeaningordered pair nodes.node pairs (i; j ). (i; j ) 2 E , (j; i) 2 E .Eordered pair node label 2 Li .(i; a)faja 2 L (i; a) permitted constraints (i.e., admissible)gLiR2 (i; a; j; b) = 1 indicates admissibility 2 Li b 2 Lj givenR2 (i; a; j; b)binary constraints.Counter[(i; j ); a] number labels Lj compatible 2 Li .(j; b) 2 [i; a] means 2 Li b 2 Lj simultaneously[i; a]admissible. implies supports b.[i; a] = 1 indicates label admissible (and[i; a]already eliminated from) node i.queue arc support deleted.List(i; j )Figure 16: Data structures notation arc consistency algorithm, AC-4.3.1 CSP Arc Consistency: AC-4AC-4 builds maintains several data structures, described Figure 16, alloweciently achieve arc consistency CSP. Note modified notationslightly eliminate subscripts (which become quite cumbersome path consistencyalgorithm). Figure 17 shows code initializing data structures, Figure 18contains algorithm eliminating inconsistent labels domains. algorithmrequires (el2) time, e number constraint arcs, l domain size (Mohr& Henderson, 1986).AC-4, label 2 Li compatible b 2 Lj , supports b (and viceversa). keep track much support label has, number labels Ljcompatible Li counted total stored Counter[(i; j ); a]algorithm Figure 17. Counter[(i; j ); a] zero, removed Li(because cannot appear solution), ordered pair (i; a) placed List,M[i; a] set 1 (to avoid removing element Li once). algorithmmust also keep track labels label supports using S[i; a], set arclabel pairs. example, S[i; a] = f(j; b); (j; c)g means Li supports b c Lj .ever removed Li , b c loose support.preprocessing step Figure 17, algorithm Figure 18 loops Listbecomes empty, point CSP arc consistent. (i; a) popped Listprocedure, element (j; b) S[i; a], Counter[(j; i); b] decremented.Counter[(j; i); b] becomes zero, b would removed Lj , (j; b) placed List,M[j; b] set 1.257fiHelzerman & Harper1. List := ;2. 2 N3.2 Li f4.[i; a] := ;5.[i; a] := 0; g6. (i; j ) 2 E7.2 Li f8.Total := 0;9.b 2 Lj10.R2 (i; a; j; b) f11.Total := Total+1;12.[j; b] := [j; b] [ f(i; a)g; g13.Total = 0 f14.Li := Li , fag;15.List := List [ f(i; a)g;16.[i; a] := 1; g17.Counter[(i; j ); a] := Total; gFigure 17: Initialization data structures AC-4.1. List 6= f2.pop (i; a) List;3.(j; b) 2 S[i; a] f4.Counter[(j; i); b] := Counter[(j; i); b] , 1;5.Counter[(j; i); b] = 0 ^ [j; b] = 0 f6.Lj := Lj , fbg;7.List := List [ f(j; b)g;8.[j; b] := 1; g g gFigure 18: Eliminating inconsistent labels domains AC-4.258fiMUSE CSP: Extension Constraint Satisfaction ProblemNext, describe MUSE arc consistency algorithm MUSE CSP, called MUSEAC-1. purposely keep notation presentation MUSE AC-1 close possibleAC-4 reader benefit similarity two algorithms.3.2 MUSE AC-1MUSE arc consistency enforced removing labels Li violate conditions Definition 8. MUSE AC-1 builds maintains several data structures, describedFigure 19, allow eciently perform operation. Many data structuresborrowed AC-4, others exploit DAG representation MUSE CSPdetermine values incompatible segments. Figure 22 showscode initializing data structures, Figures 23 24 contain algorithmeliminating inconsistent labels domains.MUSE AC-1 AC-4, label node compatible label b node j ,supports b. keep track much support label has, number labels Ljcompatible Li counted, total stored Counter[(i; j ); a].CSP arc consistency, Counter[(i; j ); a] zero, would immediately removedLi, would mean could never appear solution. However, MUSEarc consistency, may case, even though participatesolution segments contain j , could another segmentwould perfectly legal. label cannot become globally inadmissibleincompatible every segment. Hence, MUSE CSP, Counter[(i; j ); a] zero,algorithm simply places [(i; j ); a] List records fact setting M[(i; j ); a] 1.placing [(i; j ); a] List, algorithm indicating segments containingj support label a.MUSE AC-1 must also keep track labels j label Li supportsusing S[(i; j ); a], set node-label pairs. example, S[(i; j ); a] = f(j; b); (j; c)g meansLi supports b c Lj . ever invalid Li , b c loosesupport.DAG, MUSE AC-1 able use properties DAG identifylocal (and hence eciently computable) conditions labels become globallyinadmissible. Segments defined paths MUSE CSP start end.value associated variable supported variables precedefollow it, way value used segment,deleted arc consistency algorithm. addition, value variable's domainsupported constraints values associated second variable, secondvariable preceded followed variables values supporting value,solution involves path variables MUSE DAG, value cannotsupported segment involving two variables. two ideas provide basisremaining data structures used MUSE AC-1.Consider Figure 20, shows nodes adjacent node DAG.every segment DAG contains node represented directed pathDAG going node i, either node j node k must every segment containingi. Hence, label remain Li, must compatible least one labeleither Lj Lk . Also, either n must contained every segment containing259fiHelzerman & HarperNotationMeaning(i; j )ordered pair nodes.node pairs (i; j ) exists path directed edges Gj . (i; j ) 2 E , (j; i) 2 E .ordered pair node label 2 Li .E(i; a)[(i; j ); a]ordered pair node pair (i; j ) label 2 Li .faja 2 L (i; a) permitted constraints (i.e., admissible)gLi2 (i; a; j; b)RCounter[(i; j ); a]S[(i; j ); a]M[(i; j ); a]ListGNext-EdgeiPrev-EdgeiLocal-Prev-Support(i; a)Local-Next-Support(i; a)Prev-Support[(i; j ); a]Next-Support[(i; j ); a]2 (i; a; j; b) = 1 indicates admissibility 2 Li b 2 Lj givenbinary constraints.number labels Lj compatible 2 Li .(j; b) 2 [(i; j ); a] means 2 Li b 2 Lj simultaneouslyadmissible. implies supports b.M[(i; j ); a] = 1 indicates label admissible (andalready eliminated from) segments containing j .queue arc support deleted.G set node pairs (i; j ) exists directededge j .Next-Edgei contains node pairs (i; j ) existsdirected edge (i; j ) 2 G. also contains (i; end) last nodesegment.Prev-Edgei contains node pairs (j; i) existsdirected edge (j; i) 2 G. also contains (start; i) first nodesegment.set elements (i; j ) (j; i) 2 Prev-Edgei , j 6= start,must compatible least one j 's labels.Local-Prev-Support(i; a) becomes empty, longer admissible.set elements (i; j ) (i; j ) 2 Next-Edgei , j 6= end,must compatible least one j 's labels.Local-Next-Support(i; a) becomes empty, longer admissible.(i; k) 2 Prev-Support[(i; j ); a] implies (k; j ) 2 Prev-Edgej ,k 6= start, 2 Li compatible least one j 'sone k's labels. Prev-Support[(i; j ); a] becomes empty,longer admissible segments containing j .(i; k) 2 Next-Support[(i; j ); a] implies (j; k) 2 Next-Edgej ,k 6= end, 2 Li compatible least one j 'sone k's labels. Next-Support[(i; j ); a] becomes empty,longer admissible segments containing j .RFigure 19: Data structures notation MUSE AC-1.260fiMUSE CSP: Extension Constraint Satisfaction Problemnjk{...,a,...}LocalPrevSupport(i,a) = {(i,n),(i,m)}LocalNextSupport(i,a) = {(i,j)}Figure 20: Local-Prev-Support Local-Next-Support example DAG. sets indicate label allowed every segment contains n, m, j ,disallowed every segment contains k. solid directed linesmembers G, solid undirected lines represent members E .i, label remain Li, must also compatible least one label eitherLn Lm .order track dependency, two sets maintained label node i,Local-Next-Support(i; a) Local-Prev-Support(i; a). Local-Next-Support(i; a) setordered node pairs (i; j ) (i; j ) 2 Next-Edgei , (i; j ) 2 E , least onelabel b 2 Lj compatible a. Local-Prev-Support(i; a) set ordered pairs(i; j ) (j; i) 2 Prev-Edgei , (i; j ) 2 E , least one label b 2 Ljcompatible a. Dummy ordered pairs also created handle cases nodebeginning end network: (start; i) 2 Prev-Edgei , (i; start) addedLocal-Prev-Support(i; a), (i; end) 2 Next-Edgei , (i; end) added Local-NextSupport(i; a). prevent label ruled nodes precedefollow DAG. Whenever one i's adjacent nodes, j , longer labels bdomain compatible a, (i; j ) removed Local-PrevSupport(i; a) Local-Next-Support(i; a), depending whether edge jj , respectively. either Local-Prev-Support(i; a) Local-Next-Support(i; a)becomes empty, longer part MUSE arc consistent instance,eliminated Li . Figure 20, label admissible segments containingj , segments containing k. constraints,labels j become inconsistent i, (i; j ) would eliminated Local-NextSupport(a; i), leaving empty set. case, would longer supportedsegment.algorithm utilize similar conditions nodes directly connectedNext-Edgei Prev-Edgei . Consider Figure 21. Suppose label nodecompatible label Lj , incompatible labels Lx Ly ,reasonable eliminate segments containing j , segmentswould include either node x . determine whether label admissibleset segments containing j , calculate Prev-Support[(i; j ); a] NextSupport[(i; j ); a] sets. Next-Support[(i; j ); a] includes (i; k) arcs support261fiHelzerman & Harperz{...,a,...}xjwFigure 21: Next-Edgej = f(j; x); (j; )g; Counter[(i; x); a] = 0, Counter[(i; ); a] = 0,inadmissible every segment containing j . solid directed lines members G, solid undirected lines represent membersE .given directed edge j k, (i; j ) supports a. Prev-Support[(i; j ); a]includes (i; k) arcs support given directed edge kj , (i; j ) supports a. Note Prev-Support[(i; j ); a] contain ordered pair(i; j ) (i; j ) 2 Prev-Edgej , Next-Support[(i; j ); a] contain ordered pair (i; j )(j; i) 2 Next-Edgej . elements included edge nodesj sucient allow j 's labels support segment containing j . Dummyordered pairs also created handle cases node beginning endnetwork: (start; j ) 2 Prev-Edgej , (i; start) added Prev-Support[(i; j ); a],(j; end) 2 Next-Edgej , (i; end) added Next-Support[(i; j ); a]. preventlabel ruled nodes precede follow DAG.Figure 22 shows Prev-Support, Next-Support, Local-Next-Support, Local-PrevSupport sets initialization algorithm creates simple example DAG.initialization step, sets contain node pairs allowed based connectivity G. Later, consistency step node pairs supportassociated label eliminated set.illustrate data structures used second step MUSE AC-1 shownFigure 23, consider happens initially [(1; 3); a] 2 List MUSE CSP depictedFigure 22. [(1; 3); a] placed List indicate label L1 supportedlabels associated node 3. value popped List, necessary(3; x) 2 S[(1; 3); a] decrement Counter[(3; 1); x] one. Counter[(3; 1); x]becomes 0, [(3; 1); x] already placed List, added futureprocessing. done, necessary remove [(1; 3); a]'s uence MUSEDAG. handle this, examine two sets Prev-Support[(1; 3); a] = f(1; 2); (1; 3)g262fiMUSE CSP: Extension Constraint Satisfaction Problem1.2.3.4.5.6.7.8.9.10.11.12.13.14.15.16.17.18.19.20.21.22.23.List := ;E := f(i; j )j9 2 : i; j 2 ^ 6= j ^ i; j 2 N g;(i; j) 2 E2 Li fS[(i; j ); a] := ;M[(i; j ); a] := 0;Local-Prev-Support(i; a) := ; Local-Next-Support(i; a) := ;Prev-Support[(i; j ); a] := ; Next-Support[(i; j ); a] := ; g(i; j) 2 E2 Li fTotal := 0;b 2 LjR2 (i; a; j; b) fTotal := Total+1;S[(j; i); b] := S[(j; i); b] [ f(i; a)g; gTotal=0 fList := List [ f[(i; j ); a]g;M[(i; j ); a] := 1; gCounter[(i; j ); a] := Total;Prev-Support[(i; j ); a] := f(i; x)j(i; x) 2 E ^ (x; j ) 2 Prev-Edgej g[ f(i; j )j(i; j ) 2 Prev-Edgej g[ f(i; start)j(start; j ) 2 Prev-Edgej g;Next-Support[(i; j ); a] := f(i; x)j(i; x) 2 E ^ (j; x) 2 Next-Edgej g[ f(i; j )j(j; i) 2 Next-Edgej g[ f(i; end)j(j; end) 2 Next-Edgej g;Local-Prev-Support(i; a) := f(i; x)j(i; x) 2 E ^ (x; i) 2 Prev-Edgei g[ f(i; start)j(start; i) 2 Prev-Edgei g;Local-Next-Support(i; a) := f(i; x)j(i; x) 2 E ^ (i; x) 2 Next-Edgei g[ f(i; end)j(i; end) 2 Next-Edgei g; g{c}2start13{a,b}end{d}Prev-Support[(1; 2);a] = f(1; 2)gPrev-Support[(1; 3);a] = f(1; 2); (1; 3)gPrev-Support[(1; 2);b] = f(1; 2)gPrev-Support[(1; 3);b] = f(1; 2); (1; 3)gPrev-Support[(2; 1);c] = f(2; start)gPrev-Support[(2; 3);c] = f(2; 3); (2; 1)gPrev-Support[(3; 1);d] = f(3; start)gPrev-Support[(3; 2);d] = f(3; 1)gLocal-Prev-Support(1;a) = f(1; start)gLocal-Prev-Support(1;b) = f(1; start)gLocal-Prev-Support(2;c) = f(2; 1)gLocal-Prev-Support(3;d) = f(3; 1); (3; 2)gNext-Support[(1; 2);a] = f(1; 3)gNext-Support[(1; 3);a] = f(1; end)gNext-Support[(1; 2);b] = f(1; 3)gNext-Support[(1; 3);b] = f(1; end)gNext-Support[(2; 1);c] = f(2; 1); (2; 3)gNext-Support[(2; 3);c] = f(2; end)gNext-Support[(3; 1);d] = f(3; 1); (3; 2)gNext-Support[(3; 2);d] = f(3; 2)gLocal-Next-Support(1;a) = f(1; 2); (1; 3)gLocal-Next-Support(1;b) = f(1; 2); (1; 3)gLocal-Next-Support(2;c) = f(2; 3)gLocal-Next-Support(3;d) = f(3; end)gFigure 22: Initialization data structures MUSE AC-1 along simple example.263fiHelzerman & Harper1. List 6= f2.Pop [(i; j ); a] List;3.(j; b) 2 S[(i; j ); a] f4.Counter[(j; i); b] := Counter[(j; i); b] , 1;5.Counter[(j; i); b] = 0 ^ M[(j; i); b] = 0 f6.List := List [ f[(j; i); b]g;7.M[(j; i); b] := 1; g g8.Update-Support-Sets([(i; j ); a]); (see Figure 24) gFigure 23: Eliminating inconsistent labels domains MUSE AC-1.Update-Support-Sets ([(i; j ); a]) f1. (i; x) 2 Prev-Support[(i; j ); a] ^ x 6= j ^ x 6= start f2.Prev-Support[(i; j ); a] := Prev-Support[(i; j ); a] , f(i; x)g ;3.Next-Support[(i; x); a] := Next-Support[(i; x); a] , f(i; j )g;4.Next-Support[(i; x); a] = ^ M[(i; x); a] = 0 f5.List := List [ f[(i; x); a]g;6.M[(i; x); a] := 1; g g7. (i; x) 2 Next-Support[(i; j ); a] ^ x 6= j ^ x 6= end f8.Next-Support[(i; j ); a] := Next-Support[(i; j ); a] , f(i; x)g;9.Prev-Support[(i; x); a] := Prev-Support[(i; x); a] , f(i; j )g;10.Prev-Support[(i; x); a] = ^ M[(i; x); a] = 0 f11.List := List [ f[(i; x); a]g;12.M[(i; x); a] := 1; g g13. (j; i) 2 Prev-Edgei14. Local-Prev-Support(i; a) := Local-Prev-Support(i; a) , f(i; j )g;15. Local-Prev-Support(i; a) = f16. Li := Li , fag;17. (i; x) 2 Local-Next-Support(i; a) ^ x 6= j ^ x 6= end f18.Local-Next-Support(i; a) := Local-Next-Support(i; a) , f(i; x)g;19.M[(i; x); a] = 0 f20.List := List [ f[(i; x); a]g;21.M[(i; x); a] := 1; g g g22. (i; j ) 2 Next-Edgei23. Local-Next-Support(i; a) := Local-Next-Support(i; a) , f(i; j )g;24. Local-Next-Support(i; a) = f25. Li := Li , fag;26. (i; x) 2 Local-Prev-Support(i; a) ^ x 6= j ^ x 6= start f27.Local-Prev-Support(i; a) := Local-Prev-Support(i; a) , f(i; x)g;28.M[(i; x); a] = 0 f29.List := List [ f[(i; x); a]g;30.M[(i; x); a] := 1; g g g gFigure 24: function Update-Support-Sets([(i; j ); a]) MUSE AC-1.264fiMUSE CSP: Extension Constraint Satisfaction ProblemNext-Support[(1; 3); a] = f(1; end)g. Note value (1; end) Next-Support[(1; 3); a]value (1; 3) Prev-Support[(1; 3); a], require actiondummy values. However, value (1; 2) Prev-Support[(1; 3); a] indicates (1; 3)member Next-Support[(1; 2); a], since admissible (1; 3), (1; 3)removed Next-Support[(1; 2); a], leaving empty set. Note NextSupport[(1; 2); a] empty, assuming M[(1; 2); a] = 0, [(1; 2); a] added Listprocessing. Next, (1; 3) removed Local-Next-Support(1; a), leaving setf(1; 2)g. next iteration loop [(1; 2); a] popped List.Prev-Support[(1; 2); a] Next-Support[(1; 2); a] processed, Next-Support[(1; 2); a] =Prev-Support[(1; 2); a] contains dummy, requiring action. Finally, (1; 2)removed Local-Next-Support(1; a), set becomes empty, longer compatible segment containing node 1 eliminated considerationpossible label node 1. eliminated node 1, also necessary removesupport 2 L1 labels nodes precede node 1, nodes x(1; x) 2 Local-Prev-Support(1; a). Since Local-Prev-Support(1; a) = f(1; start)g,start dummy node, work done.contrast, consider happens initially [(1; 2); a] 2 List MUSE CSPFigure 22. case, Prev-Support[(1; 2); a] contains (1; 2) requires additionalwork; whereas, Next-Support[(1; 2); a] contains (1; 3), indicating (1; 2) must removedPrev-Support[(1; 3); a]'s set. removal, Prev-Support[(1; 3); a] non-empty,segment containing nodes 1 3 still supports label L1. reasontwo cases provide different results constraint arc nodes 1 3contained every segment; whereas, constraint arc nodes 1 2 foundone them.3.3 Running Time Space Complexity MUSE AC-1worst-case running time routine initialize MUSE AC-1 data structures(in Figure 22) O(n2 l2 + n3 l), n number nodes MUSE CSP lnumber labels. Given number (i; j ) elements E O(n2 )domain size O(l), size Counter arrays O(n2 l). determinenumber supporters given arc-label pair requires O(l) work; hence, initializingCounter arrays requires O(n2 l2) time. However, O(n2 l) Prev-SupportNext-Support sets, Prev-Support[(i; j ); a] Next-Support[(i; j ); a] requiresO(n) time compute, time calculate Prev-Support Next-Support setsO(n3 l). Finally, time needed calculate Local-Next-Support Local-PrevSupport sets O(n2 l) O(nl) sets O(n) elements per set.worst-case running time algorithm prunes labels MUSEarc consistent (in Figures 23 24) also operates O(n2 l2 + n3 l) time. ClearlyCounter array contains O(n2 l) entries (a similar argument made array)keep track algorithm. Counter[(i; j ); a] l magnitude,never become negative, maximum running time line 4 Figure 23(given elements appear List M) O(n2 l2).O(n2 l) Next-Support Prev-Support lists, O(n) size, maximumrunning time required lines 3 9 Figure 24 O(n3 l). Finally, since O(nl)265fiHelzerman & HarperApproachCSPsMUSE CSPNodesDegreeNumberNumberper Path Node splitting Constraint Networks Nodesnnknkk1nknAsymptoticTimekn n2 l22(kn) l2 + (kn)3 lTable 1: Comparison space time complexity MUSE arc consistencyMUSE CSP arc consistency multiple CSPs representing node splittingproblem (e.g., lexical ambiguity parsing).Local-Prev-Support Local-Next-Support sets eliminate O(n) elements,maximum running time lines 14 23 Figure 24 O(n2 l). Hence, maximumrunning time MUSE CSP arc consistency algorithm O(n2 l2 + n3 l).space complexity MUSE CSP AC-1 also O(n2 l2 + n3 l) arraysCounter contain O(n2 l) elements, O(n2 l) sets, containing O(l)items; O(n2 l) Prev-Support Next-Support sets, containing O(n) items; O(nl)Local-Next-Support Local-Prev-Support sets, containing O(n) items.comparison, worst-case running time space complexity CSP arc consistency O(n2 l2), assuming n2 constraint arcs. Note applicationsl = n, worst-case running times algorithms order (thistrue parsing spoken language MUSE CSP). Also, representable planarDAG (in terms Prev-Edge Next-Edge, E), running times twoalgorithms order average number values Prev-SupportNext-Support would constant. hand, compare MUSE CSPuse multiple CSPs problems k alternative variables particularvariable CSP, MUSE CSP AC-1 asymptotically attractive, shownTable 1.3.4 Correctness MUSE AC-1Next prove correctness MUSE AC-1.Theorem 1 label eliminated Li MUSE AC-1 labelunsupported arcs (i; x) every segment.Proof:1. must show label eliminated, inadmissible every segment.label eliminated domain MUSE AC-1 (see lines 16 25 Figure 24)Local-Prev-Support set Local-Next-Support set becomes empty(see lines 15 24 Figure 24). either case, label eliminatedmake MUSE CSP instance MUSE arc consistent. prove label'slocal support sets become empty, label cannot participate MUSE arcconsistent instance MUSE CSP. proven Local-Next-Support (LocalPrev-Support follows symmetry.) Observe 2 Li , unsupported266fiMUSE CSP: Extension Constraint Satisfaction Problemnodes immediately follow DAG, cannot participateMUSE arc consistent instance MUSE CSP. line 23 Figure 24, (i; j )removed Local-Next-Support(i; a) set [(i; j ); a] must poppedList. removal (i; j ) Local-Next-Support(i; a) indicates that,segment containing j , 2 Li inadmissible. remains shown[(i; j ); a] put List 2 Li unsupported every segment containsj . proven induction number iterations loopFigure 23.Base case: initialization routine puts [(i; j ); a] List 2 Li incompatible every label Lj (line 17 Figure 22). Therefore, 2 Li unsupportedsegments containing j .Induction step: Assume start kth iteration loop[(x; ); c] ever put List indicate c 2 Lx inadmissibleevery segment contains x . remains show kthiteration, [(i; j ); a] put List, 2 Li unsupported every segmentcontains j . several ways new [(i; j ); a] putList:(a) labels Lj compatible 2 Li eliminated.item could placed List either initialization (see line 17Figure 22) previous iteration loop (see line 6 Figure23)), CSP AC-4 algorithm. obvious that, case, 2 Liinadmissible every segment containing j .(b) Prev-Support[(i; j ); a] = (see line 10 Figure 24) indicating 2 Liincompatible nodes k (k; j ) 2 Prev-Edgej . way[(i; j ); a] placed List reason (at line 11) tuplesform [(i; k); a] (where (k; j ) 2 Prev-Edgej ) already put List.induction hypothesis, [(i; k); a] items placed List2 Li inadmissible segments containing k DAG.supported node immediately precedes j DAG,unsupported every segment contains j . Therefore, correctput [(i; j ); a] List.(c) Next-Support[(i; j ); a] = (see line 4 Figure 24) indicating 2 Liincompatible nodes k (j; k) 2 Next-Edgej . way [(i; j ); a]placed List (at line 5) reason tuples form[(i; k); a] (where (j; k) 2 Next-Edgej ) already put List. inductionhypothesis, [(i; k); a] items placed List 2 Li inadmissible segments containing k DAG. supportednode immediately follows j DAG, inadmissibleevery segment contains j . Therefore, correct put [(i; j ); a] List.(d) Local-Next-Support(i; a) = (see line 24 Figure 24) indicating 2 Liincompatible nodes k (i; k) 2 Next-Edgei . way[(i; j ); a] placed List (at line 29) reason nodefollows DAG supports a, pairs (i; k) legally removed267fiHelzerman & Harper1...1...c...b...Local_Prev_Support(i,a) = {(i,j),...}Local_Next_Support(i,a) = {(i,k},...}jk{b,...}Prev_Support[(i,j),a] nonempty{c,...}{a,...}cPrev_Support[(i,k),a] = {(i,k),...}...Next_Support[(i,k),a] nonempty1b...Next_Support[(i,j),a] = {(i,j),...}1Figure 25: 2 Li MUSE AC-1, must preceded node j followednode k support a.Local-Next-Support(i; a) previous iterations.segment containing supports a, follows segment containingj supports label.(e) Local-Prev-Support(i; a) = (see line 15 Figure 24) indicating 2 Liincompatible nodes k (k; i) 2 Prev-Edgei . way[(i; j ); a] placed List (at line 20) reason nodeprecedes DAG supports a, pairs (i; k) legallyremoved Local-Prev-Support(i; a) previous iterations.segment containing supports a, follows segment containingj supports label.beginning (k + 1)th iteration loop, every [(x; ); c] Listimplies c supported segment contains x . Therefore,induction, true iterations loop Figure 23. Hence,label's local support sets become empty, label cannot participate MUSE arcconsistent instance MUSE CSP.2. must also show eliminated Li MUSE arc consistencyalgorithm, must MUSE arc consistent. MUSE arc consistent,must exist least one path start end goes nodenodes n path contain least one label compatible2 Li . deleted MUSE AC-1, Local-Next-Support(i; a) 6=Local-Prev-Support(i; a) 6= . Hence, must preceded followed leastone node supports 2 Li ; otherwise, would deleted. depictedFigure 25, know must node j precedes that,start, must contain least one label b supports a, NextSupport[(i; j ); a] Prev-Support[(i; j ); a] must non-empty. Similarly, mustnode k follows that, end, must contain least onelabel c supports a, Next-Support[(i; k); a] Prev-Support[(i; k); a] mustnon-empty.268fiMUSE CSP: Extension Constraint Satisfaction Problemshow path DAG, must show path beginningstart reaches nodes along path support 2 Li ,path beginning reaches end nodes alongpath support 2 Li . show necessity path endnodes along path support 2 Li given remains MUSE AC-1;necessity path start shown similar way.Base case: 2 Li MUSE AC-1, must exist least one nodefollows i, say k, [(i; k); a] never placed List. Hence,R2 (i; a; k; c) = 1 least one c 2 Lk Next-Support[(i; k); a] PrevSupport[(i; k); a] must non-empty.Induction Step: Assume path n nodes follows supports2 Li, none nodes end node. implies nnodes contains least one label compatible Next-Support[(i; n); a]Prev-Support[(i; n); a] must non-empty n nodes.Next, show path length (n + 1) must also support 2 Li ; otherwise,label would deleted MUSE AC-1. already notednth node path induction step, Next-Support[(i; n); a] mustnon-empty; hence, must exist least one node, say n0 , follows nthnode path length n supports 2 Li . n0 end node,case. n0 end, way (i; n0) memberNext-Support[(i; n); a] [(i; n0); a] placed List. hasn't,R2 (i; a; n0; l) = 1 least one l 2 Ln Next-Support[(i; n0); a] PrevSupport[(i; n0); a] must non-empty. case, (i; n0) wouldremoved Next-Support[(i; n); a], n would longer support 2 Li .Hence, 2 Li MUSE AC-1, must path nodes endnode n end node, R2 (i; a; n; l) = 1 least one l 2 LnNext-Support[(i; n); a] Prev-Support[(i; n); a] must non-empty. HenceMUSE arc consistent.02theorem, may conclude MUSE AC-1 builds largest MUSE arcconsistent structure. MUSE arc consistency takes account segments,single CSP selected MUSE CSP MUSE arc consistency enforced,CSP arc consistency could eliminate additional labels.3.5 Profile MUSE AC-1Given fact MUSE AC-1 operates composite data structure, benefitsusing algorithm high payoff individually processing CSPs. section 2.4,provided several examples payoff obvious. gain insight factorsuencing effectiveness MUSE CSP, conducted experimentrandomly generate MUSE CSP instances two different graph topologies. treetopology characterized two parameters: branching factor (how many nodes follownon-leaf node tree) path length (how many nodes pathroot node leaf node). lattice topology characteristic MUSE CSP269fiHelzerman & Harperproduced hidden-Markov-model-based spoken language recognition systemconstraint-based parser. Lattices also characterized lengthbranching factor.experiment, examined trees path length four branchingfactor two three, lattices path length four branching factortwo three. initialized variable either 3 6 labels. randomlygenerated constraints network, varying probability R2 (i; a; j; b) = 10.05 .95 steps 0.05. probability, 6 instances generated. lowerprobability R2 (i; a; j; b) = 1, tighter constraints. Note probabilityconstraint two nodes understood probability constrainttwo nodes given constraint allowed them. example, nodeslevel tree topology different segments, constraintscannot occur them.results experiment displayed Figures 26 27. fourpanels figure, four curves displayed. MUSE AC-1 appears curvesdisplaying average number labels remaining MUSE AC-1 applied instancesMUSE CSP probability constraint varies. curves labeled Solutionindicate average number labels remaining MUSE AC-1 usedsolution. CSP AC associated curves display number labels remainleast one segment segment extracted MUSE CSP CSParc consistency applied. Unused indicates difference number labelsremain MUSE AC-1 number CSP arc consistent least onesegment.topologies, probability R2 (i; a; j; b) = 1 low (e.g., .1) high(e.g., .8), MUSE AC-1 tracks performance arc consistency performedindividual instances either topology. However, topology impact rangelow high probabilities true. constraints randomly generated,MUSE AC-1 performed, tree topology fewer remaining values latticetopology CSP arc consistent. results suggest MUSE CSP AC-1 mayeffective topologies others. However, tree topologyrandomly generated constraints values two variables independentprobabilities generated. case lattice; pair variablesset randomly generated constraints, shared paths lattice.Notice increasing number values domain seems impacttree increasing branching factor, probably branching factorincreases, number independent nodes.experiment show problem tightly constrained, MUSE AC-1effectively used eliminate values unsupported constraints. Clearly,case parsing problems presented section 2.4. small set syntacticconstraints effectively eliminates values never used parse sentence,even lattice branching factor three arbitrarily long paths.270fiMUSE CSP: Extension Constraint Satisfaction Problema. Tree branching factor 2, path length 4, 3 labels per variable, 15 variables.b. Tree branching factor 3, path length 4, 3 labels per variable, 90 variables.3Average number role values per role 3Average number role values per role 332.5MUSE AC12CSP AC1.5Solution10.52.5MUSE AC12CSP AC1.5Solution10.5UnusedUnused000.10.20.30.40.50.60.7Probability R2(i,a,j,b)=10.80.9001c. Tree branching factor 2, path length 4, 6 labels per variable, 15 variables.0.20.30.80.91Average number role values per role 665MUSE AC14CSP AC32Solution154MUSE AC1CSP AC3Solution21Unused000.40.50.60.7Probability R2(i,a,j,b)=1d. Tree branching factor 3, path length 4, 6 labels per variable, 90 variables.6Average number role values per role 60.10.10.20.30.40.50.60.7Probability R2(i,a,j,b)=1Unused0.80.90010.10.20.30.40.50.60.7Probability R2(i,a,j,b)=10.80.91Figure 26: Simulation results trees path length 4, branching factor 23, 3 6 labels per variable.271fiHelzerman & Harpera. Lattice branching factor 2, path length 4, 3 labels per variable, 8 variables.b. Lattice branching factor 3, path length 4, 3 labels per variable, 12 variables.33MUSE AC1Average number role values per role 3Average number role values per role 3CSP ACMUSE AC12.52Solution1.510.5Unused000.10.20.30.40.50.60.7Probability R2(i,a,j,b)=10.80.92Solution1.51Unused0.5001c. Lattice branching factor 2, path length 4, 6 labels per variable, 8 variables.0.10.20.30.40.50.60.7Probability R2(i,a,j,b)=10.80.91d. Lattice branching factor 3, path length 4, 6 labels per variable, 12 variables.66MUSE AC1MUSE AC1Average number role values per role 6Average number role values per role 6CSP AC2.5CSP AC54Solution3215CSP AC4Solution32Unused1Unused000.10.20.30.40.50.60.7Probability R2(i,a,j,b)=10.80.90010.10.20.30.40.50.60.7Probability R2(i,a,j,b)=10.80.91Figure 27: Simulation results lattices path length 4, branching factor 23, 3 6 labels per variable.272fiMUSE CSP: Extension Constraint Satisfaction ProblemLocal-Next-Support(B, b1) = {(B, E)}Local-Next-Support(B, b2) = {(B, C), (B, E)}Local-Next-Support(B, b3) = {(B, C)}Next-Support[(B, C), b3] = {(B, D)}Next-Support[(B, C), b2] = {(B, F)}C{c1}start{a1}{d1}Bend{b1, b2, b3}{e1}{f1}EFFigure 28: Using MUSE arc consistency data structures guide backtracking search.3.6 Extracting Solutions MUSE CSP MUSE AC-1Solutions regular CSP problems typically generated using backtracking (or fanciersearch algorithms) assemble set labels, one node, consistentlyadmissible. Extracting solutions MUSE CSPs done similar way,desirable make modifications search algorithms take advantageextra information contained MUSE AC-1 data structures.Consider example shown Figure 28. figure presents simple MUSE CSP.Suppose interested solutions segment highlighted: fA, B, C,Dg. Suppose also one solution segment: a1 A, b3 B, c1C, d1 D. wish find solution depth-first search.begin assigning a1 A. However, domain B, addition desiredlabel b3, also contains labels b1 b2, valid segments.initially (and naively) choose b1 B continue depth-first search, wouldwaste lot time backtracking. Fortunately, enforcing MUSE arc consistency,MUSE data structures contain useful information concerning segmentslabels valid. case, backtracking algorithm check Local-Next-Support(B,b1) determine outgoing nodes b1 compatible with. Since (B, C)element Local-Next-Support(B, b1), smart search algorithm would choose b1label B.However, looking local support sets might enough. searchalgorithm rejected b1 label B, would go consider b2. Local-NextSupport(B, b2) indicates b2 valid label segments containC, fails tell us b2 valid segment examining. Despitethis, search algorithm still eliminate b2 looking Next-Support[(B, C), b2],indicates b2 compatible segments containing node F. Clearly,type information effectively guide search solution along certainpath. Improved search strategies MUSE CSPs focus future research efforts.273fiHelzerman & Harper4. MUSE CSP Path Consistency Algorithmsection, introduce algorithm achieve MUSE CSP path consistency, MUSEPC-1, builds upon PC-4 algorithm (Han & Lee, 1988).4.1 MUSE PC-1MUSE path consistency enforced setting R2 (i; a; j; b) false violatesconditions Definition 9. MUSE PC-1 builds maintains several data structures comparable data structures defined MUSE AC-1, described Figure 29, alloweciently perform operation. Figure 32 shows code initializing data structures, Figures 33 34 contain algorithm eliminating MUSE path inconsistentbinary constraints.MUSE PC-1 must keep track labels Lk support R2 (i; a; j; b). keep trackmuch path support R2 (i; a; j; b) has, number labels Lk satisfyR2 (i; a; k; c) R2 (k; c; j; b) counted using Counter[(i; j ); k; a; b]. Additionally,algorithm must keep track set S[(i; j ); k; a; b], contains members form(k; c) R2 (i; a; k; c) R2 (k; c; j; b) supported R2 (i; a; j; b). R2 (i; a; j; b)ever becomes false segment containing i, j , k, R2 (i; a; k; c) R2 (k; c; j; b)loose support. MUSE PC-1 also uses Local-Next-Support, Local-PrevSupport, Prev-Support, Next-Support sets similar MUSE AC-1.MUSE PC-1 able use properties DAG identify local (and henceeciently computable) conditions binary constraints fail lack pathsupport. Consider Figure 30, shows nodes adjacent node jDAG. every segment DAG contains node j representeddirected path DAG going node node j , node must precedefollow nodes j R2 (i; a; j; b) hold. order track dependency, two setsmaintained [(i; j ); a; b] tuple: Local-Prev-Support[(i; j ); a; b] Local-NextSupport[(i; j ); a; b]. Note distinguish Local-Prev-Support[(i; j ); a; b] LocalPrev-Support[(j; i); b; a] separately keep track elements directly precedingdirectly preceding j . also distinguish Local-Next-Support[(i; j ); a; b] LocalNext-Support[(j; i); b; a]. sets become empty, (i; j ) arclonger support R2 (i; a; j; b). Local-Prev-Support[(i; j ); a; b] set ordered node pairs(i; x) (x; i) 2 Prev-Edgei , (i; x) 2 E , least one label 2 Lxcompatible R2 (i; a; j; b). Local-Next-Support[(i; j ); a; b] set orderednode pairs (i; x) (i; x) 2 Next-Edgei , (i; x) 2 E , least one label2 Lx compatible R2 (i; a; j; b). Dummy ordered pairs also createdhandle cases node beginning end network: (start; i) 2 PrevEdgei , (i; start) added Local-Prev-Support[(i; j ); a; b], (i; end) 2 Next-Edgei ,(i; end) added Local-Next-support[(i; j ); a; b].algorithm utilize similar conditions nodes may directly connected j . Consider Figure 31. Suppose R2 (i; a; j; b) compatiblelabel Lk , incompatible labels Lx Ly , R2 (i; a; j; b)R2 (j; b; i; a) false segments containing i, j , k segments wouldinclude either node x . determine whether constraint admissibleset segments containing i, j , k, calculate Prev-Support[(i; j ); k; a; b], Prev274fiMUSE CSP: Extension Constraint Satisfaction ProblemNotationMeaningordered pair nodes.(i; j )node pairs (i; j ) exists path directed edges Gj . (i; j ) 2 E , (j; i) 2 E .ordered quadruple node pair (i; j ), node k, labels2 Li b 2 Lj .E[(i; j ); k; a; b]faja 2 L (i; a) permitted constraints (i.e., admissible)gLi2 (i; a; j; b) = 1 indicates admissibility 2 Li b 2 Lj givenbinary constraints.2 (i; a; j; b)RRCounter[(i; j ); k; a; b]S[(i; j ); k; a; b]M[(i; j ); k; a; b]ListGNext-EdgeiPrev-EdgeiLocal-Prev-Support[(i; j ); a; b]Local-Next-Support[(i; j ); a; b]Prev-Support[(i; j ); k; a; b]Next-Support[(i; j ); k; a; b]number labels Lk compatible R2 (i; a; j; b).(k; c) 2 [(i; j ); k; a; b] means c 2 Lk compatibleR2 (i; a; j; b).M[(i; j ); k; a; b] = 1 indicates R2 (i; a; j; b) false pathsincluding i, j , k.queue path support deleted.G set node pairs (i; j ) exists directededge j .Next-Edgei contains node pairs (i; j ) existsdirected edge (i; j ) 2 G. also contains (i; end) lastnode segment.Prev-Edgei contains node pairs (j; i) existsdirected edge (j; i) 2 G. also contains (start; i) firstnode segment.set elements (i; k) (k; i) 2 Prev-Edgei , k 6= start,R2 (i; a; j; b) must compatible one k 's labels.Local-Prev-Support[(i; j ); a; b] becomes empty, R2 (i; a; j; b) becomes false.set elements (i; k) (i; k) 2 Next-Edgei , k 6= end,R2 (i; a; j; b) must compatible one k 's labels.Local-Next-Support[(i; j ); a; b] becomes empty, R2 (i; a; j; b) becomes false.(i; x) 2 Prev-Support[(i; j ); k; a; b] implies (x; k) 2 Prev-Edgek ,x 6= start, R2 (i; a; j; b) compatible least one k'sone x's labels. Prev-Support[(i; j ); k; a; b] becomes empty,R2 (i; a; j; b) longer true segments containing i, j , k .(i; x) 2 Next-Support[(i; j ); k; a; b] means (k; x) 2 Next-Edgek ,x 6= end, R2 (i; a; j; b) compatible least one k'sone x's labels. Next-Support[(i; j ); k; a; b] becomes empty,R2 (i; a; j; b) longer true segments containing i, j , k .Figure 29: Data structures notation MUSE PC-1.275fiHelzerman & Harperl{...,a,...} nprjq{...,b,...}LocalPrevSupport[(i,j), a, b] = {(i,l), (i,m)}LocalPrevSupport[(j,i), b, a] = {(j,p), (j,q)}LocalNextSupport[(i,j), a, b] = {(i,n), (i,o)}LocalNextSupport[(j,i), b, a] = {(j,r), (j,s)}Figure 30: Local-Prev-Support Local-Next-Support path consistency example DAG. solid directed lines members G, solid undirectedline represents (i; j ) (j; i) members E .Support[(j; i); k; b; a], Next-Support[(i; j ); k; a; b], Next-Support[(j; i); k; b; a] sets. NextSupport[(i; j ); k; a; b] includes (i; x) arcs support R2 (i; a; j; b) givendirected edge k x, R2 (i; a; j; b) = 1, R2 (i; a; k; c) = 1, R2 (k; c; j; b) = 1 (NextSupport[(j; i); k; b; a] defined similarly). Prev-Support[(i; j ); k; a; b] includes (i; x) arcssupport R2 (i; a; j; b) given directed edge x k, R2 (i; a; j; b) = 1,R2 (i; a; k; c) = 1, R2 (k; c; j; b) = 1 (Prev-Support[(j; i); k; b; a] defined similarly).Note Prev-Support[(i; j ); k; a; b] contain ordered pair (i; k) (i; k) 2 PrevEdgek , (i; j ) (j; k) 2 Prev-Edgek . Next-Support[(i; j ); k; a; b] contain orderedpair (i; k) (k; i) 2 Next-Edgek (i; j ) (k; j ) 2 Next-Edgek . elements included edge nodes sucient allow support. Dummyordered pairs also created handle cases node beginning endnetwork: (start; k) 2 Prev-Edgek , (i; start) added Prev-Support[(i; j ); k; a; b],(k; end) 2 Next-Edgek , (i; end) added Next-Support[(i; j ); k; a; b].4.2 Running Time, Space Complexity, Correctness MUSE PC-1worst-case running time routine initialize MUSE PC-1 data structures (inFigure 32) O(n3 l3 + n4 l2), n number nodes MUSE CSP lnumber labels. Given number (i; j ) elements E O(n2 ) domain sizeO(l), O(n3 l2) entries Counter array determine numbersupporters, requiring O(l) work; hence, initializing Counter array requires O(n3 l3)time. Additionally, O(n3 l2) sets determine, O(l) values,time required initialize O(n3 l3). Determining Prev-Support[(i; j ); k; a; b]276fiMUSE CSP: Extension Constraint Satisfaction Problemzx{...,c,...}{...,a,...}kwj {...,b,...}Figure 31: found Next-Edgek = f(k; x); (k; )g; Counter[(i; j ); x; a; b] =0; Counter[(i; j ); y; a; b] = 0, R2 (i; a; j; b) ruled every segment containing i, j , k. solid directed lines members G,solid undirected lines represent members E .277fiHelzerman & Harper1.2.3.4.5.6.7.8.9.10.11.12.13.14.15.16.17.18.19.20.21.22.23.24.25.26.27.List := ;E := f(i; j )j9 2 : i; j 2 ^ 6= j ^ i; j 2 N g;(i; j) 2 E2 Lib 2 Lj fLocal-Prev-Support[(i; j ); a; b] := ; Local-Next-Support[(i; j ); a; b] := ;k 2 N (i; k) 2 E ^ (j; k) 2 E fS[(i; j ); k; a; b] := ;M[(i; j ); k; a; b] := 0;Prev-Support[(i; j ); k; a; b] := ; Next-Support[(i; j ); k; a; b] := ; g g(i; j) 2 E2 Lib 2 Lj R2 (i; a; j; b) fk 2 N (i; k) 2 E ^ (j; k) 2 E fTotal := 0;c 2 LkR2 (i; a; k; c) R2 (k; c; j; b) fTotal := Total+1;S[(i; k); j; a; c] := S[(i; k); j; a; c] [ f(j; b)g; gTotal = 0 fList := List [ f[(i; j ); k; a; b]g;M[(i; j ); k; a; b] := 1; gCounter[(i; j ); k; a; b] := Total;Prev-Support[(i; j ); k; a; b] :=f(i; x)j(i; x) 2 E ^ (x = j _ (j; x) 2 E ) ^ (x; k) 2 Prev-Edgek g[ f(i; k)j(i; k) 2 Prev-Edgek g[ f(i; start)j(start; k) 2 Prev-Edgek g;Next-Support[(i; j ); k; a; b] :=f(i; x)j(i; x) 2 E ^ (x = j _ (j; x) 2 E ) ^ (k; x) 2 Next-Edgek g[ f(i; k)j(k; i) 2 Next-Edgek g[ f(i; end)j(k; end) 2 Next-Edgek g; gLocal-Prev-Support[(i; j ); a; b] :=f(i; x)j(i; x) 2 E ^ (x = j _ (j; x) 2 E ) ^ (x; i) 2 Prev-Edge ig[ f(i; start)j(start; i) 2 Prev-Edgei g;Local-Next-Support[(i; j ); a; b] :=f(i; x)j(i; x) 2 E ^ (x = j _ (j; x) 2 E ) ^ (i; x) 2 Next-Edgei g[ f(i; end)j(i; end) 2 Next-Edgeig; gFigure 32: Initialization data structures MUSE PC-1.278fiMUSE CSP: Extension Constraint Satisfaction Problem1. List 6=2.Pop [(i; j ); k; a; b] List;3.(k; c) 2 S[(i; j ); k; a; b] f4.Counter[(i; k); j; a; c] := Counter[(i; k); j; a; c] , 1;5.Counter[(k; i); j; c; a] := Counter[(k; i); j; c; a] , 1;6.Counter[(i; k); j; a; c] = 0 ^ M[(i; k); j; a; c] = 0 f7.List := List [ f[(i; k); j; a; c]; [(k; i); j; c; a]g;8.M[(i; k); j; a; c] := 1; M[(k; i); j; c; a] := 1; g g9.Update-Support-Sets([(i; j ); k; a; b]); (see Figure 34) gFigure 33: Eliminating inconsistent binary constraints MUSE PC-1.Update-Support-Sets ([(i; j ); k; a; b])f1. (i; x) 2 Prev-Support[(i; j ); k; a; b] ^ x 6= j ^ x 6= k ^ x 6= start f2.Prev-Support[(i; j ); k; a; b] := Prev-Support[(i; j ); k; a; b] , f(i; x)g;3.Next-Support[(i; j ); x; a; b] := Next-Support[(i; j ); x; a; b] , f(i; k)g;4.Next-Support[(i; j); x; a; b] = ^ M[(i; j ); x; a; b] = 0 f5.List := List [ f[(i; j ); x; a; b]; [(j; i); x; b; a]g;6.M[(i; j ); x; a; b] := 1; M[(j; i); x; b; a] := 1; g g7. (i; x) 2 Next-Support[(i; j ); k; a; b] ^ x 6= j ^ x 6= k ^ x 6= end f8.Next-Support[(i; j ); k; a; b] := Next-Support[(i; j ); k; a; b] , f(i; x)g;9.Prev-Support[(i; j ); x; a; b] := Prev-Support[(i; j ); x; a; b] , f(i; k)g;10.Prev-Support[(i; j); x; a; b] = ^ M[(i; j ); x; a; b] = 0 f11.List := List [ f[(i; j ); x; a; b]; [(j; i); x; a; b]g;12.M[(i; j ); x; a; b] := 1; M[(j; i); x; b; a] := 1; g g13. (k; i) 2 Prev-Edgei14. Local-Prev-Support[(i; j ); a; b] := Local-Prev-Support[(i; j ); a; b] , f(i; k)g;15. Local-Prev-Support[(i; j ); a; b] = f16. R2 (i; a; j; b) := 0; R2 (j; b; i; a) := 0;17. (i; x) 2 Local-Next-Support[(i; j ); a; b] ^ x 6= j ^ x 6= k ^ x 6= end f18.Local-Next-Support[(i; j ); a; b] := Local-Next-Support[(i; j ); a; b] , f(i; x)g;19.M[(i; j ); x; a; b] = 0 f20.List := List [ f[(i; j ); x; a; b]; [(j; i); x; b; a]g;21.M[(i; j ); x; a; b] := 1; M[(j; i); x; b; a] := 1; g g g22. (i; k) 2 Next-Edgei23. Local-Next-Support[(i; j ); a; b] := Local-Next-Support[(i; j ); a; b] , f(i; k)g;24. Local-Next-Support[(i; j ); a; b] = f25. R2 (i; a; j; b) := 0; R2 (j; b; i; a) := 0;26. (i; x) 2 Local-Prev-Support[(i; j ); a; b] ^ x 6= j ^ x 6= k ^ x 6= start dof27.Local-Prev-Support[(i; j ); a; b] := Local-Prev-Support[(i; j ); a; b] , f(i; x)g;28.M[(i; j ); x; a; b] = 0 f29.List := List [ f[(i; j ); x; a; b]; [(j; i); x; b; a]g;30.M[(i; j ); x; a; b] := 1; M[(j; i); x; b; a] := 1; g g g gFigure 34: function Update-Support-Sets([(i; j ); k; a; b]) MUSE PC-1.279fiHelzerman & HarperApproachCSPsMUSE CSPNodesDegreeNumberNumberper Path Node splitting Constraint Networks Nodesnnknkk1nknAsymptoticTimeknn3 l33(kn) l3 + (kn)4 l2Table 2: Comparison space time complexity MUSE path consistencyMUSE CSP path consistency multiple CSPs representing node splittingproblem (e.g., lexical ambiguity parsing).Next-Support[(i; j ); k; a; b] requires O(n) time, time required calculatePrev-Support Next-Support sets O(n4 l2). Finally, time needed calculateLocal-Next-Support Local-Prev-Support sets O(n3 l2) O(n2 l2) setsO(n) elements per set.worst-case running time algorithm enforces MUSE path consistency(in Figures 33 34) also operates O(n3 l3 + n4 l2) time. Clearly O(n3 l2)entries Counter array keep track algorithm. Counter[(i; j ); k; a; b]l magnitude, never become negative, maximum runningtime lines 4 5 Figure 33 (given elements, M, appear listonce) O(n3 l3). O(n3 l2) Prev-Support Next-Support lists,O(n) size, maximum running time required eliminate O(n) elementssupport sets O(n4 l2). Finally, since O(n2 l2) Local-Next-SupportLocal-Prev-Support sets eliminate O(n) elements, worst-case timeeliminate items local sets O(n3 l2). Hence, worst-case running timeMUSE CSP path consistency algorithm O(n3 l3 + n4 l2).space complexity MUSE CSP PC-1 also O(n3 l3 + n4 l2 ) arraysCounter contain O(n3 l2) elements O(n3 l2) sets, containingO(l) items; O(n3 l2) Prev-Support Next-Support sets, containing O(n) items;O(n2 l2) Local-Next-Support Local-Prev-Support sets, containing O(n) items.comparison, worst-case running time space complexity CSP path consistency, PC-4, O(n3 l3). Note applications representable planar DAGl = n, worst-case running times algorithms order. compareMUSE CSP use multiple CSPs problems k alternative variablesparticular variable CSP, MUSE CSP path consistency asymptoticallyattractive, shown Table 2.proof correctness MUSE PC-1 similar proof MUSE AC-1,brie outline proof here. binary constraint looses support MUSEPC-1 (see lines 16 25 Figure 34) Local-Prev-Support set Local-NextSupport set becomes empty (see lines 15 24 Figure 34, respectively). either case,inadmissible MUSE path consistent instance. prove constraint's localsupport sets become empty cannot participate MUSE path consistentinstance MUSE CSP. proven Local-Next-Support (Local-Prev-Support followssymmetry). Observe R2 (i; a; j; b) = 1, nodes immediately280fiMUSE CSP: Extension Constraint Satisfaction Problem2 = f 1j, 2j, 3jg1 = f 4j, 5jg123startend45Figure 35: example set CSP problems would good candidate MUSECSP lack node sharing.follow (and similarly j ) DAG incompatible truth constraint,cannot participate MUSE path consistent instance. line 23 Figure 34,(i; k) removed Local-Next-Support[(i; j ); a; b] [(i; j ); k; a; b]popped List. removal (i; k) Local-Next-Support[(i; j ); a; b] indicatessegment containing i, j , k support R2 (i; a; j; b). remains shown[(i; j ); k; a; b] put List R2 (i; a; j; b) must false every segmentcontains i, j , k. proven induction number iterationsloop Figure 33 (much like proof MUSE AC-1). must also showR2 (i; a; j; b) = 1 MUSE PC-1, MUSE path consistent. R2 (i; a; j; b)MUSE path consistent, must exist least one path start endgoes nodes j nodes n path contain least one labelconsistent constraint. proof would similar second half proofMUSE AC-1 correctness. this, may conclude MUSE PC-1 buildslargest MUSE path consistent structure.5. Combining CSPs MUSE CSPProblems inherent lattice structure problems solvednode splitting approach natural areas application MUSE CSP,exponential number CSPs replaced single instance MUSE CSP, DAGrepresentation inherent problem. section discuss DAG constructionapplication areas would benefit MUSE CSP approach,obvious construct DAG. set CSP problemsused segments MUSE CSP. example, Figure 35 illustrates two instancesCSP combined single MUSE CSP. However, using MUSE CSPexample would right choice; node sharing cannot offset cost usingextra MUSE AC-1 data structures.Multiple nodes name various CSPs potentially representedsingle node MUSE CSP. assume two nodes, k1 k2 givenname (say k) two instances CSP, domain obeyconstraints, i.e.:1. Lk1 = Lk2 (i.e., domains equal.)2. R1(k1; a) = R1(k2; a) every 2 Lk1 ; Lk2 (i.e., unary constraintssame.)281fiHelzerman & Harper1 = f 1j, 2jg2 = f 1j, 3jg3 = f 2j, 3jg12startend132startend23Figure 36: example maximal node sharing leads spurious segments.first DAG contains two paths, f1,2,3g f2g, correspond nonesegments. second DAG presents preferred sharing createdCreate-DAG routine.3. R2(k1; a; i; b) = R2(k2; a; i; b) labels 2 Lk1 ; Lk2 b 2 Li ,segments (i.e., binary constraints same.)However, illustrated Figure 36, much sharing common nodes introduceadditional segments appear original list CSPs. extrasegments cause extra work done, often desirable create DAGshares nodes without introducing extra segments. algorithm Create-DAG, shownFigure 38 takes arbitrary set CSP problems input (a list segments), outputsDAG representation CSPs shares nodes without introducing spurioussegments. Create-DAG calls auxiliary procedure Order-Sigma defined Figure 39.data structures used two routines defined Figure 37.hold individual segments , routine Create-DAG uses special datastructure ordered sets supports useful operations. segment ninteger, [n] node position n . [0] always start node,[j j , 1] always end node. [k::m] ordered subset consistingnodes positions k m. addition, ordered set allows us insert nodeimmediately node j already set. node [pos] structurename field next-set field, set names nodes follownode [pos] set segments.Create-DAG begins adding special purpose start end nodes segment.calls routine Order-Sigma shown Figure 39 order nodessegment. Order-Sigma orders nodes segment onescommon tend occur earlier set. order elements, uses operator> (i.e., larger than) defined nodes. Note start node defined\largest" node, end node \smallest" node. addition, > j means eitherappears segments j does, appear numbersegments, lower ordinal number j . Thus operator > induces totalordering nodes N .Order-Sigma first called Create-DAG selects largest nodesmaller start node. constructs set , set segmentscontaining i. point, segments ordered start node firstsecond. calls Order-Sigma order nodes smaller i.recursive call done, segments considered (i.e., Z ). Note282fiMUSE CSP: Extension Constraint Satisfaction ProblemNotationMeaningset node sets. node set represents CSP.node set segment . set modified includebegin end nodes Create-DAG algorithm workproperly. Note [0] always start node, [jj , 1]always end node. node [pos] structure namenext-set (names nodes follow node DAG).G set node pairs (i; j ) existsdirected edge j DAG created Create-DAG.N set nodes placed DAGCreate-DAG.Z set segments order respect node jOrder-Sigma.node j used Order-Sigma order remainingelements smaller node.U set nodes already considered current callOrder-Sigma.R set nodes Z Order-Sigma.node largest node smaller j R , U(if non-empty) R Order-Sigma.Order-Sigma, set segments Z contain node i.GNZjURFigure 37: Data structures used Create-DAG Order-Sigma.283fiHelzerman & HarperCreate-DAG () f1.2.3.4.5.6.7.8.9.10.11.12.13.14.15.16.17.18.19.20.21.22.23.24.25.26.27.28.29.30.31.32.33.34.Add start first node end last node every segment ;Order-Sigma(, start);pos := 1 maximum segment length f:= copy();2 ^ jj , 1 > pos f[pos].name = end fG := G [ f([pos , 1], [pos])g; g00else fEDGE SET := f1j 1[pos , 1].name = [pos , 1].name ^1[pos].name = [pos].nameg;next-set := f[pos + 1].name j 2 EDGE SETg;:= , EDGE SET;node [pos].name N fN := N [ [pos];[pos].next := next-set;G := G [ f([pos , 1], [pos])g; g00else fnode := get node N name [pos].name;node.next = next-set fG := G [ f([pos , 1]; [pos])g; gelse fnew-node : = Create new node;new-node.name := concatenate([pos].name, ');node := get node N named new-node.name (if one);node && node.next !=next-set fnew-node.name := concatenate(new-node.name, ');node := get node N named new-node.name (if one); g(node = NULL)N := N [ new-node;else new-node := node;new-node.next := next-set;Replace [pos].name new-node.name [pos , 1].next;G := G [ f([pos , 1]; new-node)g;Replace every occurance [pos] pos new-nodesegments EDGE SET; g g g g gEliminate start end G 2 ; gFigure 38: Routine create DAG represent .284fiMUSE CSP: Extension Constraint Satisfaction ProblemOrder-Sigma (Z; j ) f1. U := ;2. Z 6= f3.R :=;[4.5.6.7.8.9.10.11.12.13.14.2ZR , U 6=:= \largest" node R , U less j ;else:= \largest" node R less j ;:= fj 2 Z ^ 2 g ;Z := Z , ;=6 end f2 fPut j ;U := U [ ; gOrder-Sigma(S; i) g g gFigure 39: routine arrange nodes within segments convenient merging.first iteration loop, preference select largest nodecontained segments ordered recursive call Order-Sigma.items independent ordered segments, create spurious pathsplaced early DAG; however, items occur already ordered segments,placed earlier items occur ordered segments would tend introducespurious paths. loop continues segments ordered. worstcase running time Order-Sigma O(n2 ), n sum cardinalitiessegments .Order-Sigma orders nodes segments, Create-DAG begins construct DAG, represented set nodes N set directed edges G.DAG constructed going segment beginning positionsecond element (the position start). loop line 3 looks nodes leftright order, one position time, elements segment addedG. node certain name already placed N (i.e., set nodesalready DAG created) adding node graph (as well directededge [pos , 1] [pos] G) cannot create spurious paths DAG.hand, node name [pos] already placed N ,possible current segment could add paths DAG correspondsegments . avoid adding spurious segments, deal segmentsone time share previous node node namecurrent position. basic idea add edge keep track nodesfollow node DAG. this, easily determine whethernode used occurs another segment later position. nodeused followed precisely set next nodes follownode already placed graph; otherwise, second node would renamedavoid adding spurious segments. event, create new name node.285fiHelzerman & HarperNote DAG complete, eliminate start end nodes G(and corresponding outgoing incoming edges) make G consistent useMUSE arc consistency MUSE path consistency algorithms. running timeCreate-DAG also O(n2 ), n sum cardinalities segments .Even though DAGs produced routine Create-DAG nice properties,routine probably used starting point custom combining routinesspecific intended application area. believe domain-specific information play important role MUSE combination. example domain specificcombining algorithm presented (Harper et al., 1992), describes spoken-languageparsing system uses MUSE CSP. distinguishing feature application's combining algorithm instead avoiding creation extra segments, allows controlledintroduction extra segments extra segments often represent sentencesN-Best sentence spoken language recognition system would miss.6. Conclusionconclusion, MUSE CSP used eciently represent several similar instancesconstraint satisfaction problem simultaneously. multiple instances CSPcommon variables domains compatible constraints,combined single instance MUSE CSP, much work required enforcenode, arc, path consistency need duplicated across instances, especiallyconstraints suciently tight.developed MUSE CSP constraint-based parser, PARSEC (Harper & Helzerman, 1995a; Harper et al., 1992; Zoltowski et al., 1992), capable parsing wordgraphs containing multiple sentence hypotheses. developed syntactic semanticconstraints parsing sentences, applied word graph, eliminate hypotheses syntactically semantically incorrect. work speech processing,MUSE arc consistency algorithm effective pruning incompatible labelsindividual CSPs represented composite structure. extractingparses sentences remaining MUSE CSP MUSE AC-1, usually unnecessary enforce arc consistency CSP represented directed pathnetwork tightness syntactic semantic constraints.Speech processing area segmenting signal higher-levelchunks problematic. Vision systems handwriting analysis systems comparableproblems. addition, problems allow parallel alternative choices typevariable, parsing lexically ambiguous sentences, also excellent candidatesMUSE CSP.C++ implementations algorithms described paper available following location: ftp://transform.ecn.purdue.edu/pub/speech/harper code/. directorycontains README file file called muse csp.tar.Z.286fiMUSE CSP: Extension Constraint Satisfaction ProblemAcknowledgementswork supported part Purdue Research Foundation grantIntel Research Council. would like thank anonymous reviewers insightfulrecommendations improving paper.ReferencesBessiere, C. (1994). Arc-consistency arc-consistency again. Artificial Intelligence, 65,170{190.Davis, A. L., & Rosenfeld, A. (1981). Cooperating processes low-level vision: survey.Artificial Intelligence, 17, 245{263.Dechter, R. (1992). local global consistency. Artificial Intelligence, 55, 87{107.Dechter, R., Meiri, I., & Pearl, J. (1991). Temporal constraint networks. Artificial Intelligence, 49, 61{95.Dechter, R., & Pearl, J. (1988). Network-based heuristics constraint-satisfaction problems. Artificial Intelligence, 34, 1{38.Freuder, E. (1989). Partial constraint satisfaction. Proceedings International JointConference Artificial Intelligence, pp. 278{283.Freuder, E. (1990). Complexity K-tree-structured constraint-satisfaction problems.Proceedings Eighth National Conference Artificial Intelligence, pp. 4{9.Han, C., & Lee, C. (1988). Comments Mohr Henderson's path consistency algorithm.Artificial Intelligence, 36, 125{130.Harper, M. P., & Helzerman, R. A. (1995a). Extensions constraint dependency parsingspoken language processing. Computer Speech Language, 9 (3), 187{234.Harper, M. P., & Helzerman, R. A. (1995b). Managing multiple knowledge sourcesconstraint-based parsing spoken language. Fundamenta Informaticae, 23 (2,3,4),303{353.Harper, M. P., Jamieson, L. H., Zoltowski, C. B., & Helzerman, R. (1992). Semanticsconstraint parsing word graphs. Proceedings International ConferenceAcoustics, Speech, Signal Processing, pp. II{63{II{66.Mackworth, A. K. (1977). Consistency networks relations. Artificial Intelligence, 8 (1),99{118.Mackworth, A. K., & Freuder, E. (1985). complexity polynomial networkconsistency algorithms constraint-satisfaction problems. Artificial Intelligence, 25,65{74.287fiHelzerman & HarperMaruyama, H. (1990a). Constraint dependency grammar. Tech. rep. #RT0044, IBM,Tokyo, Japan.Maruyama, H. (1990b). Constraint dependency grammar weak generative capacity.Computer Software.Maruyama, H. (1990c). Structural disambiguation constraint propagation.Proceedings Annual Meeting ACL, pp. 31{38.Mohr, R., & Henderson, T. C. (1986). Arc path consistency revisited. Artificial Intelligence, 28, 225{233.Montanari, U. (1974). Networks constraints: Fundamental properties applicationspicture processing. Information Science, 7, 95{132.van Beek, P. (1994). inherent level local consistency constraint networks.Proceedings Twelfth National Conference Artificial Intelligence, pp. 368{373.Villain, M., & Kautz, H. (1986). Constraint-propagation algorithms temporal reasoning.Proceedings Fifth National Conference Artificial Intelligence, pp. 377{382.Waltz, D. L. (1975). Understanding line drawings scenes shadows. Winston, P.(Ed.), Psychology Computer Vision. McGraw Hill, New York.Zoltowski, C. B., Harper, M. P., Jamieson, L. H., & Helzerman, R. (1992). PARSEC:constraint-based framework spoken language understanding. ProceedingsInternational Conference Spoken Language Understanding, pp. 249{252.288fiJournal Artificial Intelligence Research 5 (1996) 1-26Submitted 12/95; published 8/96Spatial Aggregation: Theory ApplicationsKenneth YipMIT Artificial Intelligence Laboratory, 545 Technology SquareCambridge, 02139 USAyip@martigny.ai.mit.eduFeng Zhaofz@cis.ohio-state.eduDepartment Computer Information Science, Ohio State UniversityColumbus, OH 43210 USAAbstractVisual thinking plays important role scientific reasoning. Based researchautomating diverse reasoning tasks dynamical systems, nonlinear controllers, kinematic mechanisms, uid motion, identified style visual thinking, imagisticreasoning. Imagistic reasoning organizes computations around image-like, analogue representations perceptual symbolic operations brought bear inferstructure behavior. Programs incorporating imagistic reasoning shownperform expert level domains defy current analytic numerical methods.developed computational paradigm, spatial aggregation, unify description class imagistic problem solvers. program written paradigmfollowing properties. takes continuous field optional objective functions input,produces high-level descriptions structure, behavior, control actions. computesmulti-layer intermediate representations, called spatial aggregates, forming equivalence classes adjacency relations. employs small set generic operatorsaggregation, classification, localization perform bidirectional mappinginformation-rich field successively abstract spatial aggregates. uses datastructure, neighborhood graph, common interface modularize computations.illustrate theory, describe computational structure three implementedproblem solvers { kam, maps, hipair | terms spatial aggregation genericoperators mixing matching library commonly used routines.1. Introductioncommonly believed two styles scientific thinking: analytical, logicalchain symbolic reasoning premises conclusions, visual, holding imagistic, analogue representations problem one's mind perceptual symbolicoperations brought bear make inferences. Neither style preferredpriori other. However, problems whose complexity precludes direct analyticalapproach, certain amount qualitative visual imagination needed providenecessary \feel" \understanding" physical phenomena. picture clear,analytical mathematics take lead eciently logical conclusions.\feel physical understanding" often considered informal, imprecise,apparently unteachable, necessary scientists engineers.believe part ability visualize imagine must consist skills generateimages, discover structures relations images, transform structures, predictstructures respond internal dynamics external forcing.c 1996 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiYip & ZhaoAI work visual reasoning focused diagrams rolecontrolling search, recent years seen development class problemsolvers imagistic, i.e., problem solvers derive power primarilyuse visual apparatus secondarily search analytical methods.problem solvers designed perform tasks many different domains: controlinterpretation numerical experiments (Yip, 1991; Nishida & et al., 1991; Zhao,1994), kinematics analysis mechanisms (Joskowicz & Sacks, 1991), design controllers(Zhao, 1995; Bradley, 1992), analysis seismic data (Junker & Braunschweug, 1995),reasoning uid motion (Yip, 1995). However, important commonalitiesunderlying them. paper, present framework provide unified descriptionclass problem solvers. framework consists three ideas:field ontology: input field, mapping one continuum another.image-like analogue representation. field assumed metricmeaningful talk closeness continuity.1Structure discovery: central problem solved transformationinformation-rich input abstractions well-suited concise structural behavioraldescriptions. transformation thought successive mappingsinput space abstract spaces hide details group similar objectsequivalence classes.Multi-layer spatial aggregates: propose (1) representation neighborhoodgraph encode explicitly adjacency relations among objects one level abstraction,(2) building blocks computational processes small set generic operatorsconstruct, transform, classify, search neighborhood graph. operatorsrecursively used implement task-specific applications. multi-layer theorytwo advantages: (1) nonlocal property lower layer redescribedlocal property higher layer, (2) layer neighborhood graphprovides common interface support identical modular computations.field mapping one continuum (say Rm ) another (say Rn ). concretely,one visualize m-dimensional space n-vector attached point space.Fields commonplace science engineering applications. used describephysical quantities vary space time. Temperature room threedimensional scalar field. Weather data described 4D-spacetime field 6vector attached point: velocity (three components) air ow, temperature (scalar),pressure (scalar), density (scalar). examples fields include brightnessintensity array vision, configuration space mechanism analysis, phasespace (vector field) dynamical systems.actual computer representations, often approximate field grid. gridmay uniform non-uniform. field reconstructed numerical simulation1. Forbus et al. (1991) proposed general methodology qualitative spatial reasoning: Metric Diagram/Place Vocabulary (MD/PV). generally agree methodology. paper inspiredus look refined framework unify class problem solvers integrate visualsymbolic reasoning.2fiSpatial Aggregation: Theory Applicationsmeasurements. field contain symbolic abstractions; completelynumerical. Fields composable. One extend dimension underlying spaceand/or number components vector attached point space.representation physical systems, field two distinguishing characteristics.First, information-rich sense Shannon-Weaver measurement information.instantaneous field 1283 -grid ow simulation may contain order 108 bitsinformation. Second, pictorial sense structures relationsimplicitly represented field.consequence information-richness pictorial quality, arguereasoning fields central computational problem ecient transformation pointwise field description physical system economical symbolic abstractions well suited explaining structure behavior system.2 Figure 1 illustratesfield ontology relates commonly used ontologies Qualitative Physics:device (DeKleer & Brown, 1984), process (Forbus, 1984), constraint (Kuipers, 1986).useful, symbolic descriptions must impose conceptual structure systemcomplexity system understood terms well-defined partssubparts interactions among them. relevant parts interactions often abstract global properties field. abstract property property whose supportlarge nonlocal, whereas support property defined subset fieldproperty depends. hand, computational complexity reasonsprefer build recognition procedures basic routines local independent task-level information much possible. considerations lead usadopt architecture pointwise description final symbolic descriptionsmediated layers equivalence classes objects explicit adjacency relations.call layer objects spatial aggregate.spatial aggregates come from? real field, tend continuitiesproperties (such intensity temperature pressure) field dividedequivalence classes, i.e., open regions particular property varies approximatelyuniform way. continuities achieve economy description focusingopen regions boundaries instead pointwise field. Higher-order continuities,i.e., continuities properties defined open regions, similarly used buildabstract spatial aggregates.formation equivalence classes presupposes existence continuity. bringsus methodological point. important clearly identify source continuitiesfield equivalently physical system field represents. discovery validgeneral continuities physical system much scientific contributionsubsequent computational use form articulated conceptual model explainstructure behavior.motivation paper comes desire understand computationalstructures shared class automatic problem solvers integrate visual, symbolic,numerical methods. would like make computational structure explicitcomparisons generalizations made. goal develop way organizing2. Inferring structural descriptions field ill-posed problem (e.g., recovering 3D shapes2D images). avoid diculties, assume structure-recovery problem well-posedmain concerns computational eciency appropriate abstractions.3fiYip & ZhaomodelingHARD!analytical methodsdifferentialequationsnumericalsimulationphysicalsystemmeasurementmodelingfieldinterpretequivalenceclass clusteringstructuraldescriptiondevicemodelingprocessmodelingconstraintanalyticalfunctionsqualitativebehavioraldescriptionenvisionmentincremental analysisprocess inferencequalitative simulationFigure 1: Field ontological abstraction reasoning physical systems.diagram depicts relationships among different ontologies used QualitativePhysics. central computational problem field reasoning recoveryeconomical structural descriptions qualitative behavior description explanation. key step structural recovery formation equivalenceclasses. Identifying general valid continuities useful equivalenceclass relations based important scientific contribution.programs around image-like analogue representations, appropriate language makeprograms written style clear.next section develops theory spatial aggregation detail. Section 3 describeslanguage support programs organized around neighborhood graphs. Section 4illustrates usefulness language describing succinctly computation structurethree implemented programs { kam, maps, hipair. choose programsillustrations largely familiarity them. Section 5 shows programspatial aggregation language, using example image analysis. planinvestigate applicability framework several programs,constructed Kuipers Levitt (1988), Forbus et al. (1991), Gelsey (1995), JunkerBraunschweug (1995).4fiSpatial Aggregation: Theory Applications2. Spatial Aggregation TheoryGiven field, spectrum reasoning tasks defined. following list roughlyorder increasing complexity:Infer structural descriptions. Find objects, any, exist field.shapes, sizes, locations? distributed?created? evolve parameter (say time) varied?Classify. Assign semantic labels objects configurations.Infer correlations. Determine geometry distribution one typeobjects correlate another type?Check consistency. Given two objects configurations, test equivalentpairwise consistent.Infer incremental behavior. Given instantaneous configuration, predictpossible short-term behaviors.Infer behavioral descriptions. Explain summarize evolution objectsset domain-specific interaction rules.2.1 Requirements imagistic reasoningPartly motivated Ullman's theory visual analysis (Ullman, 1984), find desirablefollowing general requirements imagistic reasoning:Abstractness. problem solver able find objects defined abstractglobal properties.Open-endedness. problem solver architecture applicable varietydomains ( uid motion, seismic data, weather data, phase space, configurationspace). requirement implies basic recognition routines must modularcomposable. Task-specific knowledge affects choice orderingroutines.Eciency. \building blocks" recognition machinery must localnon-goal-specific. \Non-goal-specific" means operations building blocksdepend interpretation objects manipulate. requirementimplies basic routines local supports principle runparallel.Soundness. structural behavioral descriptions must consistentknown physical mathematical principles.Succinctness. structural behavioral descriptions contain qualitatively important distinctions relevant high-level tasks hand.5fiYip & Zhao2.2 Theorytheory imagistic reasoning postulates existence multi-layers spatial aggregates. Figure 2 shows layers spatial aggregates computations organized aroundthem. primitive aggregate defined equivalence class subsets pointwisefield representation. aggregate composed equivalence classes primitive aggregates. field assumed task-dependent metric. metric induces topologyspace hence meaningful talk adjacency. data structurespatial aggregate neighborhood graph whose nodes represent objects edges represent adjacency relations among objects. input field sampled form lowestlayer abstraction; field also affected control actions higher-levelabstraction layers.stream construct scheme programming language provides commoninterface organizing signal processing computations, neighborhood graph conceptual glue piecing together operations manipulate fields. like visualizenodes neighborhood graph open sets (in topology) appropriate space. Twonodes adjacent respective open sets contiguous.3topological notion adjacency amazingly useful reasoning physical systems. grouping objects equivalence classes, cluster tends give rise connectedcomponent neighborhood graph. reasoning kinematics, neighborhoodgraph provides essential connectivity information among free space regions. finding\interesting" structures, pairwise consistency adjacent nodes localizes search regions. isolating bifurcation patterns, mismatch adjacent objects provides hintanalysis. constraint propagation path search, adjacency structureimposes locality increase computational eciency. Prevalence simplicity { twoaspects neighborhood graph make powerful data structure unifying manyspatial computations.theory revolves around computation neighborhood graph natureprocesses construct, filter, transform, compare neighborhood graphs.isolate set generic operators aggregate, classify, re-describe, search correspondimportant conceptual pieces common class imagistic problem solverskam (Yip, 1991), maps (Zhao, 1994), hipair (Joskowicz & Sacks, 1991).next section discusses operators detail. Section 4 illustrates useoperators rational reconstruction three implemented computer programs.3. Language Spatial Aggregationpresent language describing computational processes organized around spatialaggregates. language provides small set operators construct manipulateneighborhood graphs. operators make conceptual structure several implementedprograms clear.3. Let B two open sets. B contiguous either \ B 6= ; B \ 6= ;closure set A. particular, B overlap, contiguous.6fiSpatial Aggregation: Theory ApplicationsModelclassifysearchaggregateStructuraldescriptionN-graphconsistent?primitiveobjectsfiltermapincrementalanalyzere-describeBehavioraldescriptionlocalizeclassifysearchaggregateStructuraldescriptionN-graphconsistent?primitiveobjectsfiltermapincrementalanalyzeBehavioraldescriptioncontrolsampleFIELDFigure 2: schematic representation computational structure analysis fieldontology. multi-layers spatial abstraction. abstraction level defined neighborhood graph, data structure representing spatial aggregatesadjacency relations. input field fed lowest abstraction layer.Note identical computational structure layer. aggregate operatorcomputes adjacency relations based task-specific metric. neighborhoodgraph common interface map filter routines. remaining operations correspond generic analysis tasks. repertoire task-independentgeometric manipulation routines (which shown) accessiblegeneric operators.7fiYip & Zhao3.1 Task-level operatorstask-level generic operators consist aggregate, classify, re-describe, localize,search, incremental-analyze, together predicates pairwise-consistent?consistent?. neighborhood graph \conceptual glue": allows computationhierarchical structural descriptions organized uniform manner. followingbox summarizes language provides user needs supply orderwrite programs spatial aggregation.Language FeaturesUser interface functions:aggregate, classify, re-describe, localize, search,incremental-analyze, pairwise-consistent?, consistent?user must specify neighborhood relation, field metric, equivalencerelation operators.Data types:{ N-graph constructors, accessors, modifiers.Examples N-graph include 4-adjacency arrays, minimal spanning tree,Voronoi diagram.{ Fields:bitmap, vector field, etc.Libraries:{ Geometric utilities:intrinsic-geometry, contain?, intersect, @ , .{ Numerical image processing routines:FFT, convolution, integrator, linear system solver, vector/matrix algebra.1.2.aggregate(objects combiner)aggregate operator assembles collection objects spatial structureusing combiner procedure explicates spatial relations among objectsterms neighborhood graph.4 operator returns neighborhood graph(N-graph). N-graph lazily built.example, recognize trajectory phase space, aggregate operator mightgiven set discrete points combiner procedure (such minimal spanningtree) establish adjacency relations. combiner procedure might use metrictopological properties underlying space.classify(N-graph cluster-proc class-rules)4. Recall nodes neighborhood graph objects edges adjacency relations.8fiSpatial Aggregation: Theory Applicationsclassify operator forms equivalence classes according equivalence relation(using cluster-proc), assigns semantic label equivalence class |subgraph input N-graph | according classification rules. example,orbit clustering procedure groups orbits ow pipes.5 classification rulesset production rules. operator returns labeled N-graph.catalog classification labels domain-specific. classification labelsserve indices storage retrieval shared class properties methodsinstantiating them.3.re-describe(N-graph desc-type)4.localize(N-graph select-proc enumerate-proc)5.6.re-describe operator changes representation primitive object. Likelambda abstraction scheme, operator allows compound object (say subsetN-graph) treated primitive.Given classified object, description-type procedure instantiates additional properties specific class objects. example, point set classifiedspace curve, becomes sensible compute additional geometric properties likelength, curvature, torsion.localize operator systematically enumerates members equivalence class(nodes N-graph) selects according select procedure. operator\opens up" abstraction allow individual members equivalence classsingled out.search(N-graph initial-states goal-p combiner)search operator returns paths starting initial-states satisfyinggoal-p predicate. combiner procedure controls order graphtraversed.incremental-analyze(N-graph state-desc delta)Given N-graph description states constituent laws, incrementalanalyze operator computes infinitesimal change qualitative state duesmall perturbation. perturbation delta might temporal, state,parameter space.predicates pairwise-consistent? consistent?:pairwise-consistent?(obj1 obj2 consistency-rules)consistent?(obj consistency-rules)pairwise-consistent? predicate decides two objects consistent accordingconsistency-rules. objects primitive objects nodesN-graph N-graphs themselves.Consistent?tests object well-formed according consistency-rules.5. ow pipe class orbits continuously deformed other. examplehomotopy equivalence class.9fiYip & Zhao3.2 Generic data structure routinesneighborhood graph constructedN-graph-constructor(objects neighbor-p)map(N-graph proc)filter(N-graph mask)N-graph-constructor takes set primitive objects neighborhood predicatearguments, returns neighborhood graph. example neighborhood graph Voronoi diagram. predicate neighbor-p tests two nodesneighbors.set task-independent routines operate objects neighborhood graphssupport task-level operations.map routine transforms neighborhood graph using prespecified procedure.filter selects subset neighborhood graph processing.addition generic operators, language provides routines perform commongeometric manipulation. following routines especially useful:1.2.3.4.5.6.computes intrinsic geometric propertiesobjects (e.g., area, curvature, surface normal).contain?(obj1 obj2) checks obj2 inside obj1.intersect(obj1 obj2) computes intersection two objects.@(object) boundary operator returns boundary object.dimension boundary co-dimension 1.(object) co-boundary operator returns new object whose boundaryobject. dimension new object one higher object.convolve(object mask) performs pointwise convolution given mask.intrinsic-geometry(obj properties)4. Examples Spatial Aggregationsection, describe architecture three implemented systems kam (Yip, 1991),maps (Zhao, 1994), hipair (Joskowicz & Sacks, 1991) terms spatial aggregationframework. Although programs designed different tasks, computationsshare strikingly similar pattern: programs construct spatial objects, interpretvia multi-layers abstraction object aggregation, classification, re-description.Composite objects lower level labeled manipulated primitive unitsnext higher level.Despite fact authors two programs, structural similarities among programs apparent us carefully reconstructed10fiSpatial Aggregation: Theory Applicationsprograms defining appropriate neighborhood graphs generic operators. Analyzing programs common framework help us understandprograms do, also greatly enhance ability construct future programsspatial aggregation operators.4.1 KAMtask kam explore dynamics Hamiltonian systems produce high-levelsummaries qualitative behaviors.Given state equations Hamiltonian system, kam derives symbolic descriptionqualitative behavior | terms orbit types,6 orbit bundles, phase portraits,bifurcation patterns | collection point sets representing orbits (or trajectories)phase space (see Figure 3). point sets obtained numerical simulationmeasurements. provide useful interpretation point set, kam decide (1)look interesting orbits, (2) group orbits larger structures.Kam proceeds via sequence intermediate representations allow gradual recoveryorbit structures eventually global dynamical properties system. Kamable view object multiple levels abstraction. example, orbitviewed points phase space curve part orbit bundle.computations kam organized four layers (as shown Figure 4): (1) orbit,(2) orbit bundle, (3) phase portrait, (4) bifurcation pattern. walkfirst level sucient detail illustrate computation synthesizedspatial aggregation operators neighborhood graph. Details remaining levelsdescribed Yip (1991).input point set. aggregate operator imposes adjacency relationpoint set constructing minimal spanning tree (MST). Two points adjacentneighbors connected edge MST. Although MST appropriateorbit interpretation, applications might require different adjacency relations (suchVoronoi diagrams k-nearest neighbors). output aggregate operatorneighborhood graph encodes edges MST.consistent? predicate checks inconsistent edges, i.e., edgessignificantly longer nearby edges, neighborhood graph. Deletinginconsistent edge partition graph subgraphs represents clusteroriginal point set.Next, classify operator assigns label, orbit type, neighborhood graphaccording shape MST number clusters. assignment unsuccessful, kam assumes input point set contain enough points revealstructure orbit. Kam request points repeat aggregation step.assignment successful, re-describe operator takes labeled neighborhoodgraph fills information relevant particular orbit type. example,orbit periodic orbit, period orbit determined. fillingdetails, re-describe operator packages orbit primitive object passes6. introduce useful terminology here. dynamical system smooth vector field. orbitintegral curve vector field. orbit bundle collection adjacent orbitsqualitative behavior. phase portrait collection orbits fill phase space. bifurcationpattern characteristic change structure phase portrait system parameters vary.11fiYip & Zhao(a)(b-1)(b-2)Figure 3: Top: (a) phase portrait Hamiltonian system. geometric structuresphase portrait vary drastically system parameter changes.Like expert dynamicist, kam explores dynamics nonlinear Hamiltoniansystem finding interesting structures phase space. decides initialconditions parameter values try. interprets finds usesstructures draws guide exploration.Bottom: (b-1) minimal spanning tree representation point set. (b-2)Magnifying boxed region | crosses () inconsistent edges. Kam imposesadjacency relations point set representing trajectory phase space.structure minimal spanning tree reveals type trajectory.12fiSpatial Aggregation: Theory Applicationsbifurcationconsistencyrulesphaseportraitsconsistent?aggregateN-graphportraitconsistencyrulesbifurcation propertiesbifurcation classification rulesconsistent?aggregateredescribeN-graphphaseportraitportrait propertiesclassifywavefrontpropagationorbit bundleconsistencyrulesorbitsbifurcationpatternclassifynearestneighborsorbitbundlesredescribeportrait classification rulesconsistent?aggregateredescribeN-graphorbitbundleorbit bundle propertiesclassifywavefrontpropagationtreeconsistencyrulespointsetorbit bundle classification rulesconsistent?aggregateredescribeN-graphMSTalgorithmorbitorbit propertiesclassifyorbit classification rulesFigure 4: computational structure kam viewed spatial aggregation operators acting neighborhood graphs. four layers abstraction: orbit, orbit bundle,phase portrait, bifurcation pattern. computation organized aroundneighborhood graphs. structural similarities among layers apparent.13fiYip & Zhaoforce controlswitchedcontrol u 1flow pipeRegion R projectedonto initial phase plane.control u 2GRFigure 5: Left: Buckling beam due axial load.Right: Phase spaces buckling beam (upper) locally controlled beam(lower). stabilize buckling beam far unbuckled state |unstable equilibrium G, maps (1) finds ow pipe, group qualitatively similartrajectories, reaches G, (2) deforms trajectory emanating initialstate via force control trajectory close G, (3) switchesconventional linear controller achieve desired stabilization. Let region Rlower phase plane linearly controllable region control u2 . Startinginitial state initial control u1 , system evolves along trajectorywithin ow pipe close projection region R. forcecontrol u1 turned deform trajectory system movesregion R linear controller drives system desired unbuckledstate G.next level abstraction, orbit bundle level, process aggregation,consistency checks, classification, re-description repeated.4.2 MAPSMaps' task analyze qualitative phase-space structures dissipative systemsuse analysis results guide synthesis control laws.Like kam, maps extracts high-level dynamical information phase space structures. maps goes beyond kam two important aspects: (1) maps deals threedimensional structures explicitly (whereas kam reasons cross-sections three-dimensionalstructures), (2) maps uses phase space structures synthesize nonlinear controlactions.Maps synthesizes global control path geometrically (see Figure 5). Given initialstate desired state system control, maps searches path phasespace connects initial desired state. goal directly reachableinitial state, maps pieces together multiple path segments varying controlactions. brute-force search individual control paths continuum clearly infeasible.Maps partitions continuous phase space manageable discrete set objects |14fiSpatial Aggregation: Theory Applicationsow pipes | defining appropriate equivalence relations, searches ow pipesgood control paths.computations maps organized four layers (as shown Figure 6): (1) stability region, (2) ow pipe, (3) phase portrait, (4) ow pipe graph. inputfixed points dynamical system7 . Two fixed points adjacent connectedsaddle trajectories. adjacency relation represented neighborhoodgraph. trajectories passing saddles classified equivalence classesassigned stability region boundary labels. re-describe operator computes regions delimited stability region boundaries represents polyhedra.stability regions fed next layer.second layer, stability region triangulated Delaunay method.aggregate operator constructs neighborhood graph triangulation using adjacency relation defined Voronoi diagram, dual Delaunay triangulation.triangulated sub-regions classified equivalence classes according topological criterion states two adjacent sub-regions equivalent trajectoriespassing connected consistent manner. Equivalence classessub-regions classified ow pipes. Recall ow pipe coarse representationset trajectories qualitative properties. use ow pipes simplifiesconsiderably control path planning problem.third layer aggregates ow pipes form phase portrait.fourth layer control decisions made. Flow pipes different phaseportraits aggregated form larger structure, ow pipe graph, fundamental data structure supporting path planning phase space. Two ow pipesadjacent phase space regions covered ow pipes overlap. Intuitively, oneswitch one ow pipe adjacent one setting appropriate control parametersgenerate phase portraits question. Given initial desired state, searchoperator searches ow pipe graph solution paths.Information also passed abstraction layer. connected sequenceow paths found satisfy control objective, individual trajectory segments withinow pipe found localize operator using shooting method.4.3 HIPAIRHipair performs kinematic analysis fixed-axes mechanisms built rigid parts. Givendescription shapes motion types (such translation rotation) parts,hipair derives realizable configurations mechanism.Hipair derives realizable configurations mechanism constructing manipulating configuration space mechanism (see Figure 7). configuration spacespace positions orientations parts make mechanism. hipairpartitions configuration space free space regions parts overlap,blocked space regions overlap. configurations correspond freespace regions realizable. boundaries free space regions determined7. Fixed points, equilibrium points, critical points phase space velocity vectorvanishes. Fixed points classified three types according behavior nearby trajectories.fixed point attractor nearby trajectories move towards it. repellormove away it. saddle move towards move away it.15fiYip & Zhaoflow pipe graphconsistencyrulesphaseportraitsaggregateN-graphportraitconsistencyrulessearchconsistent?aggregateN-graphclassifylocalizeshootingmethodredescribephaseportraitportrait propertiesclassifywavefrontpropagationsub-regionconsistencyrulesstabilityregionsflowpipegraphreachability rulesflow pipe region overlapflowpipesredescribeconsistent?portrait classification rulesconsistent?aggregateredescribeN-graphflowpipesflow pipe propertiesclassifyVoronoi diagramflow pipe classification rulesstability regionconsistencyrulesfixedpointsconsistent?aggregateredescribeN-graphstabilityregionsstability region propertiesclassifysaddle trajectoriesstability region classification rulesFigure 6: computational structure maps viewed spatial aggregation operatorsacting neighborhood graphs. four layers abstraction: stability regions,ow pipes, phase portrait, ow pipe graph. Note structural similaritieskam maps. Control synthesis implemented searchlocalize operators acting neighborhood graph representing ow pipegraph.16fiSpatial Aggregation: Theory Applicationsx5camxfollower5Figure 7: Left: 3-finger cam-follower. Right: configuration space camfollower. cam rotation. x follower displacement. shadedregions blocked space, indicating parts overlap. free spaceregions realizable configurations cam-follower. boundariesfree space regions determined contact relations camfingers follower.contact relations among parts touch other. region diagram graph whosenodes free space regions edges specify region adjacencies. region diagrammechanism composed regions diagrams pairwise interacting parts.example, region diagram mechanism 10 parts constructed regiondiagrams 45 possibly interacting pairs.computations hipair organized three layers (as shown Figure 8): (1)free space region, (2) subassembly region diagram, (3) mechanism region diagram.input shapes parts motion types. Hipair first considers pair interacting parts. looks equations contact curves, i.e., curves configurationspace pair corresponding configurations two parts touch,pre-compiled table common contact curves. contact curve partitioned segmentsintersection points curve either another contact curve boundariesconfiguration space. Two segments adjacent share endpoint. aggregateoperator assembles segments adjacency relations neighborhood graph.search operator traverses neighborhood graph find closed chains segments,closed chain segments sequence segments intersect itself. closedchain segment encloses free space region. consistent? predicate discards closedchains lie inside closed chains. classify operator assigns labelclosed chain, re-describe operator computes free space regions delimitedclosed chains. free space region subdivided convex regions.input second layer free space regions. aggregated neighborhood graph. Two free space regions adjacent (or neighbors) touch. Giveninitial configuration S0 interacting pair, search operator finds free spaceregions reachable S0 depth first search. neighborhood graph re-describedsubassembly region diagram.17fiYip & Zhaosub-regionconsistencyrulesconsistent?subassemblyaggregateregiondaigramsregion adjacencysub-regionconsistencyrulesfreespaceregionsaggregatemechanismregiondiagramN-graph region diagram propertiesclassifysearchconsistent?mechanism classification rulesredescribeN-graphsubassemblyregiondiagramregion diagram propertiesclassifyregion adjacencyclosed chainconsistencyrulescontactcurvesegmentsredescribesearchconsistent?aggregateregion diagram classification rulesfreespaceregionsfree space propertiesredescribeN-graphclassifyshared endpointsearchfree space classification rulesFigure 8: computational structure hipair viewed spatial aggregation operatorsacting neighborhood graphs. three layers abstraction: free spaceregions, subassembly region diagram, mechanism region diagram. Notestructural similarities hipair, kam, maps. search operatordetermines reachability conditions three layers.third layer, hipair combines subassembly region diagrams mechanism region diagram. mechanism region diagram neighborhood graph whose nodesrealizable sets free space regions edges specify adjacency free space regions.set free space regions realizable intersections non-empty. example,let M0 = fR0 ; S0 ; T0 g set free space regions containing initial configurationmechanism three parts P1 ; P2 ; P3 , R0 , S0 , T0 free spaceregions subassembly region diagrams pairs fP1 ; P2 g; fP1 ; P3 g, fP2 ; P3 grespectively. Suppose R0 one neighbor R1 , S0 one neighbor S1 , T0 none.three candidate neighbors M0 given by:M1 = fR1 ; S0 ; T0 g18fiSpatial Aggregation: Theory Applications= fR0 ; S1 ; T0 g= fR1 ; S1 ; T0 gM2M3consistent? predicate checks candidate neighbors discards unrealizable ones.5. Illustrationsection, show like program spatial aggregation language.example boundary tracer line drawings.8 pick example imageanalysis routines quite naturally written spatial aggregation style.Boundary tracing basic operation image analysis.9 operation might usedidentify group boundary segments object. example, considerline drawing overlapping 2D objects (see Figure 9). group boundary segments,one might first decompose figure segments, junctions. tracing processjoins colinear segments.input boundary tracing program bitmap:00000000000000111111100000010000010000001001111111100100100100010010010010001001111111000100000100000010000010000001000001000000100000100000010000010000001000001111111100000000000000bitmap rendered Figure 10(a). Figure 11 illustrates output Figure 10(b) (c) computed input bitmap, using spatial aggregation operators.first define neighborhood relation pixels 4-adjacency (namely,neighbors pixel pixels immediate north, east, south, west).often ecient way construct N-graphs directly neighborhood relations,define explicit N-graph neighborhood constructor finds 4-adjacency neighborsgiven pixel.Next aggregate operator assembles pixels N-graph N-graphconstructor. Pixels N-graph considered similar neighbors neitherjunction, junction defined pixel whose value onetwo one-value neighbors. classify operator groups pixels equivalence8. details interpretor language, implemented scheme, discussed elsewhere (BaileyKellogg, Zhao, & Yip, 1996).9. Jim Mahoney introduced us unified description high-level operations images.19fiYip & ZhaoFigure 9: line drawing two overlapping objects.(a)(b)(c)Figure 10: Boundary tracing operation image analysis: (a) Pixels boundaries twooverlapping objects; (b) Pixels grouped boundary segments; (b) Boundary segments grouped distinct object contours.classes using similarity threshold returns foreground equivalence classes, shownFigure 10(b).foreground equivalence classes re-described higher-level objects, boundary segments, turn aggregated new N-graph using different neighborhood relation. Specifically two boundary segments neighbors minimum separation distance less specified separation. Next, adjacent boundary segmentscolinear grouped equivalence classes, called contours. contour representscomplete boundary object. Figure 10(c) shows result grouping.might want check impossible contours. contour legal closedself-intersecting. conditions expressed standard pattern language. Pairwiseconsistency rules likewise defined.program written spatial aggregation language shown Figure 12Figure 13.1010. actual implementation language described Kellogg, Zhao, Yip (1996), syntaxoperators differs slightly Section 3.20fiSpatial Aggregation: Theory Applicationscontourconsistencyrulesboundarysegmentsconsistent?aggregateredescribesegmentN-graphnearnessneighborhoodobjectcontoursboundary segment classesclassifycolinearity,thresholdredescribepixelsaggregatepixelN-graph4-adjacencyneighborhoodboundarysegmentspixel classesclassifypixel similarity,thresholdFigure 11: Boundary tracing operation: data ow spatial aggregation implementation.6. Related Workliterature visual spatial reasoning enormous (e.g., Kosslyn, 1994; Glasgow,1993). section, discuss computationally oriented approaches.first line work investigates diagram-like representations aid heuristic search.Gelernter (1963) used diagrams geometry theorem prover prune goalsobviously false. Nevins' geometry theorem prover constrained forward deduction conclude facts objects explicitly depicted diagrams (Nevins, 1975). StallmanSussman (1977) exploited connectivity locality lumped-parameter modelguide forward reasoning implement symbolic constraint propagation. similarspirit, Larkin Simon (1987) showed elementary mechanics problem diagrammatic representation reduce search diagram provides convenient indicesclustering objects relations.second line work concerns analogue simulations naive physics. Funt's whisperprogram first AI program uses primarily perceptual primitives predict dynamical events simple blocks world (Funt, 1980). Arguing commonsense predictionssolid uid behavior cannot possibly depend solution complicated equations,Gardin Meltzer (1989) proposed \molecular" simulation strings uids.body uid, example, decomposed macro-molecules interactingaccording small set local rules. Chandrasekaran Narayanan (1990) proposeddirect analogue simulation motion sliding block inclined plane.21fiYip & Zhao;; 4-adjacency pixel neighborhood:;; neighbors pixels one unit away using nearness ngraph(define image-ngraph-fac(ngraph-near/instantiate image-field-fac 1));; Form neighborhood graph pixels(define image-ngraph(aggregate pixels image-ngraph-fac));; Pixel classifier: two adjacent nodes equivalent;; value neither junction.(define pixel/classify(classify-standard/instantiateimage-ngraph-fac(lambda (n1 n2)(if (and (not (is-junction? n1))(not (is-junction? n2))(= (pixel/value n1) (pixel/value n2)))0 1))));; Form equivalence classes foreground pixels(define pixel-classes(filter(lambda (cl) (= (pixel/value (car cl)) 1))(pixel/classify image-ngraph pixels *threshold1*)));;; Form boundary segments(define segments(redescribe pixel-classes segment/create))Figure 12: Boundary tracing operation program (part 1): group pixels boundary segments.objective develop cognitive architecture visual perception mental imagery.direct representation scene propose consists hierarchical, multi-resolutionsymbol structure encoding spatial relations among objects, linked analogicalrepresentation scene (image). major challenge analogue simulationprovide reliable simulation without incorporating extensive physics geometricalmodeling.third line work consists spatial reasoning research qualitative physics.Kuipers Levitt (1988) described approach spatial reasoning robot navigationmapping large-scale spaces. proposed four-level hierarchical representationincorporating topological metric descriptions terms entities places, paths,distances, angles. Forbus et al. (1991) developed Metric Diagram/Place Vocabularytheory. metric diagram contains numerical symbolic descriptions scene,22fiSpatial Aggregation: Theory Applications;; Boundary segment neighborhood defined separation distance(define segment-ngraph-fac(ngraph-near/instantiate segment-field-fac separation));; Form neighborhood graph boundary segments(define segment-ngraph(aggregate segments segment-ngraph-fac));; Boundary segments classifier: two adjacent segments;; equivalent colinear. Two thresholds used;; determining colinearity: delta threshold separation;; distance two end-points epsilon angle;; tangent vectors end-points.(define segment/classify(classify-standard/instantiatesegment-ngraph-fac(lambda (s1 s2)(if (and (> (length (segment/points s1)) 1)(> (length (segment/points s2)) 1)(segment/colinear s1 s2 delta epsilon))0 1))));; Form contours, i.e., equivalence classes boundary segments(define segment-classes(segment/classify segment-ngraph segments *threshold2*));; Contour consistency check: closed self-intersecting(define contour-consistency-rules'(if (and (closed? ?c)(not (self-intersecting? ?c)))#t #f))Figure 13: Boundary tracing operation program (part 2): group boundary segmentsdistinct object contours.place vocabulary quantization space according task-specific criteria (see also footnote 1). Comparing spatial aggregation framework MD/PVframework, note two major differences. First, whereas metric diagram mixedsymbolic/quantitative representation, field purely numerical encodestructures explicitly. Second, theory postulates multi-layer spatial aggregates identical computational structure layer. focusing field ontology,thought special class metric diagrams, able emphasize importancestructure-recovery problem, commonalities underlying several implementedprograms.23fiYip & Zhao7. Conclusiondeveloped spatial aggregation paradigm realization imagistic reasoning.paradigm systematizes important task interpreting time-varying information-richfields. paradigm consists three ideas: (1) field ontology, image-like analoguerepresentation, input, (2) structural discovery { ecient transformation pointwise field representation economical symbolic descriptions { central computationalproblem, (3) multi-layer neighborhood graph common interface smallset generic operators { aggregate, classify, redescribe, search { building blockscomputational processes derive symbolic abstractions analogue representation. paradigm relies important observations physical constraintsreal field (such continuity conservation) provide useful equivalence relationseconomical descriptions, nonlocal property lower layer often redescribedlocal property higher layer.spatial aggregation paradigm supports recovery abstract properties viamulti-layer neighborhood graphs. produces concise descriptions manipulating equivalence classes objects primitives. constructs modular programs generic operators mixing matching library commonly used routines. expresses task-specificknowledge terms field metric, adjacency relations, consistency predicates, classificationrules, redescription properties.illustrate theory, examine computational structure three implementedprograms { kam, maps, hipair { integrate symbolic, numerical, visual reasoning. show small set generic operators construct, transform, filter, classify,search neighborhood graphs capture commonalities programs. developlanguage, way organizing programs around neighborhood graphs, make programswritten style clear.currently developing toolkit support problem solving using genericoperators spatial aggregation paradigm. Many research questions still open.operators interfaced computational geometry numerical analysisbuild robust, ecient programs? scientific problems solved spatialaggregation?Imagistic reasoning powerful strategy mapping analog signals generatedphysical systems discrete, symbolic representations systems. Spatial aggregation one many realizations. believe reasoning methods derivepower primarily perceptual operations analog representations secondarily search analytical methods might prove effective automating commonsensereasoning well.Acknowledgementsthank Chris Bailey-Kellogg help implementing spatial aggregation language, following people helpful discussions comments earlier draftspaper: Harold Abelson, Andy Berlin, B. Chandrasekaran, Gregor Kiczales, JohnLamping, Shiou Loh, Jim Mahoney, Jeff May, Neal McDonald, Pandurang Nayak, ToyoakiNishida, Elisha Sacks, Brian Smith, Jack Smith, Gerry Sussman, Brian Williams.24fiSpatial Aggregation: Theory ApplicationsKY supported NSF National Young Investigator Award ECS-935777. FZsupported NSF National Young Investigator Award CCR-9457802, Alfred P. SloanFoundation Research Fellowship, grant Xerox Palo Alto Research Center, grantAT&T Foundation, NSF grant CCR-9308639.ReferencesBailey-Kellogg, C., Zhao, F., & Yip, K. (1996). Spatial aggregation: language applications. Proceedings AAAI. appear.Bradley, E. (1992). Taming chaotic circuits. Tech. rep. AI-TR-1388, MIT Artificial Intelligence Lab.Chandrasekaran, B., & Narayanan, N. (1990). Towards theory commonsense visualreasoning. Nori, K., & Madhavan, C. (Eds.), Foundations Software TechnologyTheoretical Computer Science. Springer.DeKleer, J., & Brown, J. (1984). qualitative physics based con uences. ArtificialIntelligence, 24.Forbus, K. (1984). Qualitative process theory. Artificial Intelligence, 24.Forbus, K., Nielsen, P., & Faltings, B. (1991). Qualitative spatial reasoning: CLOCKproject. Artificial Intelligence, 51.Funt, B. (1980). Problem solving diagrammatic representations. Artificial Intelligence,13.Gardin, F., & Meltzer, B. (1989). Analogical representations naive physics. ArtificialIntelligence, 38.Gelernter, H. (1963). Realization geometry-theorem proving machine. ComputersThought. McGraw-Hill.Gelsey, A. (1995). Automated reasoning machines. Artificial Intelligence, 74.Glasgow, J. (1993). imagery debate revisited: computational perspective. Computational Intelligence.Joskowicz, L., & Sacks, E. (1991). Computational kinematics. Artificial Intelligence, 51,381{416.Junker, U., & Braunschweug, B. (1995). History-based interpretation finite elementsimulations seismic wave fields. Proceedings IJCAI.Kosslyn, S. M. (1994). Image Brain: resolution imagery debate. MIT Press.Kuipers, B. (1986). Qualitative simulation. Artificial Intelligence, 29.Kuipers, B., & Levitt, T. (1988). Navigation mapping large-scale space. AI Magazine,9(2).25fiYip & ZhaoLarkin, J., & Simon, H. (1987). diagram (sometimes) worth ten thousand words.Cognitive Science, 11.Nevins, A. (1975). Plane geometry theorem proving using forward chaining. ArtificialIntelligence, 6.Nishida, T., & et al. (1991). Automated phase portrait analysis integrating qualitativequantitative analysis. Proceedings AAAI.Stallman, R., & Sussman, G. J. (1977). Forward reasoning dependency-directed backtracking system computer-aided circuit analysis. Artificial Intelligence, 9.Ullman, S. (1984). Visual routines. Cognition, 18.Yip, K. M. (1991). KAM: system intelligently guiding numerical experimentationcomputer. MIT Press.Yip, K. M. (1995). Reasoning uid motion: finding structures. ProceedingsIJCAI.Zhao, F. (1994). Extracting representing qualitative behaviors complex systemsphase spaces. Artificial Intelligence, 69(1-2), 51{92.Zhao, F. (1995). Intelligent simulation designing complex dynamical control systems.Tzafestas, & Verbruggen (Eds.), Artificial intelligence industrial decision making,control, automation. Kluwer Academic Publishers.26fiJournal Artificial Intelligence Research 5 (1996) 301-328Submitted 4/96; published 12/96Exploiting Causal Independence Bayesian Network InferenceNevin Lianwen ZhangLZHANG @ CS . UST. HKDepartment Computer Science,University Science & Technology, Hong KongDavid PoolePOOLE @ CS . UBC . CADepartment Computer Science, University British Columbia,2366 Main Mall, Vancouver, B.C., Canada V6T 1Z4Abstractnew method proposed exploiting causal independencies exact Bayesian network inference. Bayesian network viewed representing factorization joint probabilitymultiplication set conditional probabilities. present notion causal independence enables one factorize conditional probabilities combination evensmaller factors consequently obtain finer-grain factorization joint probability. newformulation causal independence lets us specify conditional probability variable givenparents terms associative commutative operator, or, sum max,contribution parent. start simple algorithm Bayesian network inferencethat, given evidence query variable, uses factorization find posterior distributionquery. show algorithm extended exploit causal independence. Empiricalstudies, based CPCS networks medical diagnosis, show method efficientprevious methods allows inference larger networks previous algorithms.1. IntroductionReasoning uncertain knowledge beliefs long recognized important researchissue AI (Shortliffe & Buchanan, 1975; Duda et al., 1976). Several methodologiesproposed, including certainty factors, fuzzy sets, Dempster-Shafer theory, probability theory.probabilistic approach far popular among alternatives, mainly dueknowledge representation framework called Bayesian networks belief networks (Pearl, 1988;Howard & Matheson, 1981).Bayesian networks graphical representation (in)dependencies amongst random variables.Bayesian network (BN) DAG nodes representing random variables, arcs representingdirect influence. independence encoded Bayesian network variableindependent non-descendents given parents.Bayesian networks aid knowledge acquisition specifying probabilities needed.network structure sparse, number probabilities required much lessnumber required independencies. structure exploited computationallymake inference faster (Pearl, 1988; Lauritzen & Spiegelhalter, 1988; Jensen et al., 1990; Shafer &Shenoy, 1990).definition Bayesian network constrain variable depends parents.Often, however, much structure probability functions exploited knowledge acquisition inference. One case dependencies depend particularvalues variables; dependencies stated rules (Poole, 1993), trees (Boutilierc 1996 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiZ HANG & P OOLEet al., 1996) multinets (Geiger & Heckerman, 1996). Another functiondescribed using binary operator applied values parent variables.latter, known causal independencies, seek exploit paper.Causal independence refers situation multiple causes contribute independentlycommon effect. well-known example noisy OR-gate model (Good, 1961). Knowledgeengineers using specific causal independence models simplifying knowledge acquisition (Henrion, 1987; Olesen et al., 1989; Olesen & Andreassen, 1993). Heckerman (1993)first formalize general concept causal independence. formalization later refinedHeckerman Breese (1994).Kim Pearl (1983) showed use noisy OR-gate speed inference specialkind BNs known polytrees; DAmbrosio (1994, 1995) showed two level BNsbinary variables. general BNs, Olesen et al. (1989) Heckerman (1993) proposed two waysusing causal independencies transform network structures. Inference transformednetworks efficient original networks (see Section 9).paper proposes new method exploiting special type causal independence (see Section 4) still covers common causal independence models noisy OR-gates, noisy MAXgates, noisy AND-gates, noisy adders special cases. method based followingobservation. BN viewed representing factorization joint probability multiplication list conditional probabilities (Shachter et al., 1990; Zhang & Poole, 1994; Li &DAmbrosio, 1994). type causal independence studied paper leads factorization conditional probabilities (Section 5). finer-grain factorization joint probabilityobtained result. propose extend exact inference algorithms exploit conditionalindependencies also make use finer-grain factorization provided causal independence.state-of-art exact inference algorithm called clique tree propagation (CTP) (Lauritzen &Spiegelhalter, 1988; Jensen et al., 1990; Shafer & Shenoy, 1990). paper proposes another algorithm called variable elimination (VE ) (Section 3), related SPI (Shachter et al., 1990; Li& DAmbrosio, 1994), extends make use finer-grain factorization (see Sections 6, 7,8). Rather compiling secondary structure finding posterior probabilityvariable, query-oriented; needs part network relevant query givenobservations, work necessary answer query. chose instead CTPsimplicity carry inference large networks CTP cannotdeal with.Experiments (Section 10) performed two CPCS networks provided Pradhan.networks consist 364 421 nodes respectively contain abundant causal independencies. paper, best one could terms exact inference would firsttransform networks using Jensen et al.s Heckermans technique apply CTP.experiments, computer ran memory constructing clique trees transformednetworks. occurs one cannot answer query all. However, extended algorithm able answer almost randomly generated queries twenty less observations(findings) networks.One might propose first perform Jensen et al.s Heckermans transformation apply. experiments show significantly less efficient extended algorithm.begin brief review concept Bayesian network issue inference.302fiE XPLOITING C AUSAL NDEPENDENCEB AYESIAN N ETWORK NFERENCE2. Bayesian Networksassume problem domain characterized set random variables. Beliefs represented Bayesian network (BN) annotated directed acyclic graph, nodes representrandom variables, arcs represent probabilistic dependencies amongst variables. useterms node variable interchangeably. Associated node conditional probability variable given parents.addition explicitly represented conditional probabilities, BN also implicitly representsconditional independence assertions. Let x1 , x2 , ..., xn enumeration nodes BNnode appears children, let xi set parents node xi .Bayesian network represents following independence assertion:variable xi conditionallyindependent variables fx1 ; x2; : : :; xi,1 g givenvalues parents.conditional independence assertions conditional probabilities together entail joint probability variables. chain rule, have:P (x1; x2; : : :; xn)==ni=1ni=1P (xi jx1; x2; : : :; xi,1)P (xi jx );(1)second equation true conditional independence assertions. conditional probabilities P (xi jxi ) given specification BN. Consequently, one can,theory, arbitrary probabilistic reasoning BN.2.1 InferenceInference refers process computing posterior probability P (X jY =Y0 ) set Xquery variables obtaining observations =Y0 . list observed variablesY0 corresponding list observed values. Often, X consists one query variable.theory, P (X jY =Y0 ) obtained marginal probability P (X; ), turncomputed joint probability P (x1 ; x2; : : :; xn) summing variables outsideX [Y one one. practice, viable summing variable joint probability requires exponential number additions.key efficient inference lies concept factorization. factorization jointprobability list factors (functions) one construct joint probability.factor function set variables number. say factor contains variable factor function variable; say factor variables depends.Suppose f1 f2 factors, f1 factor contains variables x1 ; : : :; xi; y1; : : :; yjwrite f1 (x1 ; : : :; xi; y1; : : :; yj ) f2 factor variables y1 ; : : :; yj ; z1; : : :; zk ,y1 ; : : :; yj variables common f1 f2 . product f1 f2 factorfunction union variables, namely x1 ; : : :; xi; y1; : : :; yj ; z1; : : :; zk , defined by:f1 f2)(x1; : : :; xi; y1; : : :; yj ; z1; : : :; zk) = f1(x1; : : :; xi; y1; : : :; yj )f2(y1; : : :; yj ; z1; : : :; zk )(303fiZ HANG & P OOLEcbee21e3Figure 1: Bayesian network.Let f (x1 ; : : :; xi ) function variable x1; : : :; xi . Setting, say x1 f (x1 ; : : :; xi) particularvalue ff yields f (x1 =ff; x2; : : :; xi), function variables x2 ; : : :; xi.f (x1; : : :; xi) factor, sum variable, say x1 , resulting factor variablesx2 ; : : :; xi, definedX(x1f )(x2; : : :; xi) = f (x1 =ff1 ; x2; : : :; xi) + + f (x1=ffm; x2; : : :; xi)ff1 ; : : :; ffm possible values variable x1.equation (1), BN viewed representing factorization joint probability.example, Bayesian network Figure 1 factorizes joint probability P (a; b; c; e1; e2; e3)following list factors:P (a); P (b); P (c); P (e1ja; b; c); P (e2ja; b; c); P (e3je1; e2 ):Multiplying factors yields joint probability.Suppose joint probability P (z1 ; z2; : : :; zm ) factorized multiplication list factors f1 , f2 , ..., fm . obtaining P (z2 ; : : :; zm ) summing z1 P (z1 ; z2; : : :; zm ) requires exponential number additions, obtaining factorization P (z2 ; : : :; zm ) oftendone much less computation. Consider following procedure:Procedure sum-out(F ; z ):Inputs: F list factors; z variable.Output: list factors.1. Remove F factors, say f1 , ..., fk , contain z ,2. Add new factorP Qk f F return F .z i=1Theorem 1 Suppose joint probability P (z1 ; z2; : : :; zm) factorized multiplicationlist F factors. sum-out(F ; z1 ) returns list factors whose multiplicationis P (z2 ; : : :; zm ).304fiE XPLOITING C AUSAL NDEPENDENCEB AYESIAN N ETWORK NFERENCEProof: Suppose F consists factors f1 , f2 , ..., fm suppose z1 appears factorsf1, f2, ..., fk .P (z2 ; : : :; zm)==Xz1P (z1 ; z2; : : :; zm )XYz1 i=1fi = [kXYz1 i=1fi ][i=k+1fi ]:theorem follows. 2variables appear factors f1 , f2 , ..., fk participated computation sum-out(F ; z1 ),often small portion variables. inference BNtractable many cases, even general problem NP-hard (Cooper, 1990).3. Variable Elimination AlgorithmBased discussions previous section, present simple algorithm computing P (X jY =Y0 ).algorithm based intuitions underlying DAmbrosios symbolic probabilistic inference(SPI) (Shachter et al., 1990; Li & DAmbrosio, 1994), first appeared Zhang Poole (1994).essentially Dechter (1996)s bucket elimination algorithm belief assessment.algorithm called variable elimination (VE ) sums variables listfactors one one. ordering variables outside X [Y summed requiredinput. called elimination ordering.Procedure (F ; X; Y; Y0; )Inputs: F list conditional probabilities BN;X list query variables;list observed variables;Y0 corresponding list observed values;elimination ordering variables outside X [Y .Output: P (X jY =Y0 ).1. Set observed variables factors corresponding observed values.2. empty,(a) Remove first variable z ,(b) Call sum-out(F ; z ). Endwhile3. Set h = multiplication factors F ./* h function variables X . */4. Return h(X )=P h(X ). /* Renormalization */XTheorem 2 output VE(F ; X; Y; Y0; ) indeed P (X jY =Y0 ).Proof: Consider following modifications procedure. First remove step 1. factorh produced step 3 function variables X . Add new step step 3 setsobserved variables h observed values.305fiZ HANG & P OOLELet f (y; A) function variable variables A. use f (y; A)jy=ff denotef (y=ff; A). Let f (y; ,), g (y; ,), h(y; z; ,) three functions variables.evidentf (y; ,)g (y; ,)jy=ff = f (y; ,)jy=ff g(y; ,)jy=ff;XX[h(y; z; ,)]jy=ff = [h(y; z; ,)jy=ff ]:zzConsequently, modifications change output procedure.According Theorem 1, modifications factor produced step 3 simply marginalprobability P (X; ). Consequently, output exactly P (X jY =Y0 ). 2complexity measured number numerical multiplications numerical summations performs. optimal elimination ordering one results least complexity. problem finding optimal elimination ordering NP-complete (Arnborg et al., 1987).Commonly used heuristics include minimum deficiency search (Bertele & Brioschi, 1972) maximum cardinality search (Tarjan & Yannakakis, 1984). Kjrulff (1990) empirically shownminimum deficiency search best existing heuristic. use minimum deficiency searchexperiments also found better maximum cardinality search.3.1versus Clique Tree PropagationClique tree propagation (Lauritzen & Spiegelhalter, 1988; Jensen et al., 1990; Shafer & Shenoy,1990) compilation step transforms BN secondary structure called clique treejunction tree. secondary structure allows CTP compute answers queries onequery variable fixed set observations twice time needed answer one queryclique tree. many applications desirable property since user might want compareposterior probabilities different variables.CTP takes work build secondary structure observations received.Bayesian network reused, cost building secondary structure amortizedmany cases. observation entails propagation though network.Given observations, processes one query time. user wants posteriorprobabilities several variables, sequence observations, needs runvariables observation sets.cost, terms number summations multiplications, answering single queryobservations using order magnitude using CTP. particular cliquetree propagation sequence encodes elimination ordering; using elimination ordering results approximately summations multiplications factors CTP (therediscrepancy, actually form marginals cliques, works conditional probabilities directly). Observations make simpler (the observed variables eliminatedstart algorithm), observation CTP requires propagation evidence.query oriented, prune nodes irrelevant specific queries (Geiger et al., 1990;Lauritzen et al., 1990; Baker & Boult, 1990). CTP, hand, clique tree structurekept static run time, hence allow pruning irrelevant nodes.CTP encodes particular space-time tradeoff, another. CTP particularly suitedcase observations arrive incrementally, want posterior probability node,306fiE XPLOITING C AUSAL NDEPENDENCEB AYESIAN N ETWORK NFERENCEcost building clique tree amortized many cases. suitedone-off queries, single query variable observations given once.Unfortunately, large real-world networks CTP cannot deal due timespace complexities (see Section 10 two examples). networks, still answerpossible queries permits pruning irrelevant variables.4. Causal IndependenceBayesian networks place restriction node depends parents. Unfortunatelymeans general case need specify exponential (in number parents)number conditional probabilities node. many cases structureprobability tables exploited acquisition inference. One caseinvestigate paper known causal independence.one interpretation, arcs BN represent causal relationships; parents c1; c2; : : :; cmvariable e viewed causes jointly bear effect e. Causal independence referssituation causes c1 ; c2; : : :; cm contribute independently effect e.precisely, c1; c2; : : :; cm said causally independent w.r.t. effect e existrandom variables 1; 2; : : :; frame, i.e., set possible values, e1. i, probabilistically depends ci conditionally independent cjj given ci ,2. exists commutative associative binary operatore = 1 2 : : : .Using independence notion Pearl (1988), letgiven Z , first condition is:frame e(X; jZ ) mean X independent(1; fc2; : : :; cm; 2; : : :; mgjc1)similarly variables. entails (1; cj jc1) (1; j jc1) cj jj 6= 1.refer contribution ci e. less technical terms, causes causally independent w.r.t. common effect individual contributions different causes independenttotal influence effect combination individual contributions.call variable e convergent variable independent contributions different sources collected combined (and lack better name). Non-convergent variablessimply called regular variables. call base combination operator e.definition causal independence given slightly different given Heckerman Breese (1994) Srinivas (1993). However, still covers common causal independencemodels noisy OR-gates (Good, 1961; Pearl, 1988), noisy MAX-gates (Dez, 1993), noisyAND-gates, noisy adders (Dagum & Galper, 1993) special cases. One see following examples.Example 1 (Lottery) Buying lotteries affects wealth. amounts money spendbuying different kinds lotteries affect wealth independently. words, causally307fiZ HANG & P OOLEindependent w.r.t. change wealth. Let c1; : : :; ck denote amounts money spendbuying k types lottery tickets. Let 1; : : :; k changes wealth due buyingdifferent types lottery tickets respectively. Then, depends probabilistically ciconditionally independent cj j given ci . Let e total change wealthdue lottery buying. e=1 + +k . Hence c1 ; : : :; ck causally independent w.r.t. e.base combination operator e numerical addition. example instance causal independence model called noisy adders.c1 ; : : :; ck amounts money spend buying lottery tickets lottery,c1 ; : : :; ck causally independent w.r.t. e, winning one ticket reduceschance winning other. Thus, 1 conditionally independent 2 given c1. However,ci represent expected change wealth buying tickets lottery, wouldcausally independent, probabilistically independent (there would arcs ci s).Example 2 (Alarm) Consider following scenario. different motion sensorsconnected burglary alarm. one sensor activates, alarm rings. Differentsensors could different reliability. treat activation sensor random variable.reliability sensor reflected . assume sensors fail independently1.Assume alarm caused sensor activation2. alarm=1 _ _m ;base combination operator logical operator. example instance causalindependence model called noisy OR-gate.following example instance causal independence models know:Example 3 (Contract renewal) Faculty members university evaluated teaching, research,service purpose contract renewal. faculty members contract renewed, renewed without pay raise, renewed pay raise, renewed double pay raise dependingwhether performance evaluated unacceptable least one three areas, acceptableareas, excellent one area, excellent least two areas.Let c1 , c2, c3 fractions time faculty member spends teaching, research,service respectively. Let represent evaluation gets ith area. take values 0, 1,2 depending whether evaluation unacceptable, acceptable, excellent. variabledepends probabilistically ci. reasonable assume conditionally independentcj j given ci .Let e represent contract renewal result. variable take values 0, 1, 2, 3 dependingwhether contract renewed, renewed pay raise, renewed pay raise,renewed double pay raise. e=1 23, base combination operator givenfollowing table:0123000001012320233303331. called exception independence assumption Pearl (1988).2. called accountability assumption Pearl (1988). assumption always satisfied introducingnode represent causes (Henrion, 1987).308fiE XPLOITING C AUSAL NDEPENDENCEB AYESIAN N ETWORK NFERENCESo, fractions time faculty member spends three areas causally independentw.r.t. contract renewal result.traditional formulation Bayesian network need specify exponential,number parents, number conditional probabilities variable. causal independence,number conditional probabilities P (i jci ) linear m. causal independencereduce complexity knowledge acquisition (Henrion, 1987; Pearl, 1988; Olesen et al., 1989;Olesen & Andreassen, 1993). following sections show causal independence alsoexploited computational gain.4.1 Conditional Probabilities Convergent Variablesallows us exploit structure Bayesian network providing factorization joint probability distribution. section show causal independence used factorizejoint distributioneven further. initial factors algorithm form P (ejc1; : : :; cm).want break simpler factors need table exponential m.following proposition shows causal independence used this:Proposition 1 Let e node BN let c1 ; c2; : : :; cm parents e. c1; c2; : : :; cmcausally independent w.r.t. e, conditional probability P (ejc1; : : :; cm) obtainedconditional probabilities P (i jci)P (e=ffjc1; : : :; cm) =Xff1 :::ffk =ffP (1 =ff1 jc1): : :P (m =ffmjcm );(2)value ff e. base combination operator e.Proof:3 definition causal independence entails independence assertions(1; fc2; : : :; cmgjc1) (1; 2jc1):axiom weak union (Pearl, 1988, p. 84), (1; 2jfc1; : : :; cmg). Thusmutually independent given fc1; : : :; cmg.Also have, definition causal independence (1; fc2; : : :; cm gjc1),P (1jfc1; c2; : : :; cmg) = P (1jc1)Thus have:P (e=ffjc1; : : :; cm)= P (1 =ffjc1; : : :; cm)X=P (1=ff1 ; : : :; m=ffm jc1; : : :; cm)ff1 :::ff =ffX=P (1=ff1 jc1; : : :; cm )P (2=ff2 jc1; : : :; cm) P (m=ffm jc1; : : :; cm)ff1 :::ff =ffX=P (1=ff1 jc1)P (2=ff2jc2) P (m =ffm jcm)ff1 :::ff =ff2kkknext four sections develop algorithm exploiting causal independence inference.3. Thanks anonymous reviewer helping us simplify proof.309fiZ HANG & P OOLE5. Causal Independence Heterogeneous Factorizationssection, shall first introduce operator combining factors contain convergentvariables. operator basic ingredient algorithm developed next three sections. Using operator, shall rewrite equation (2) form convenient useinference introduce concept heterogeneous factorization.Consider two factors f g . Let e1 , ..., ek convergent variables appear fg , let list regular variables appear f g , let B list variablesappear f , let C list variables appear g . B C containconvergent variables, well regular variables. Suppose base combination operatorei. Then, combination fg f g function variables e1, ..., ek variablesA, B , C . defined by:4fg (e1=Xff1 ; : : :; ek =ffkX; A; B; C )=:::f (e1=ff11; : : :; ek =ffk1 ; A; B)ff11 1 ff12 =ff1ffk1 k ffk2 =ffkg (e1=ff12; : : :; ek=ffk2; A; C );(3)value ffi ei . shall sometimes write fg f (e1 ; : : :; ek ; A; B )g (e1; : : :; ek ; A; C )make explicit arguments f g .Note base combination operators different convergent variables different.following proposition exhibits basic properties combination operator.Proposition 2 1. f g share convergent variables, fg simply multiplication f g . 2. operatorcommutative associative.Proof: first item obvious. commutativityfollows readily commutativitymultiplication base combination operators. shall prove associativityspecialcase. general case proved following line reasoning.Suppose f , g , h three factors contain one variable e variable convergent. need show (fg )h=f(gh). Let base combination operator e.associativity , have, value ff e,fg )h(e=ff)(====Xfg (e=ff4)h(e=ff3)XX[f (e=ff1 )g(e=ff2)]h(e=ff3 )ff4 ff3 =ff ff1 ff2 =ff4Xf (e=ff1)g (e=ff2 )h(e=ff3 )ff1 ff2 ff3 =ffXXf (e=ff1)[g (e=ff2 )h(e=ff3)]ff4 ff3 =ffff1 ff4 =ffff2ff3 =ff44. Note base combination operators summations indexed. convergent variable associated operator, always use binary operator associated corresponding convergent variable.examples, ease exposition, use one base combination operator. one typebase combination operator (e.g., may use or, sum max different variables network),keep track operators associated convergent variables. will, however, complicatedescription.310fiE XPLOITING C AUSAL NDEPENDENCEX=ff1 ff4 =ffB AYESIAN N ETWORK NFERENCEf (e=ff1)gh(e=ff4)f(gh)(e=ff):=proposition hence proved.2following propositions give propertiescorrespond operationsexploited algorithm . proofs straight forward omitted.Proposition 3 Suppose f g factors variable z appears f g ,XXzzXfg)=(fg )=(((zXzf )g;f )g:Proposition 4 Suppose f , g h factors g h share convergent variables,g (fh) = (gf )h:(4)5.1 Rewriting Equation 2Noticing contribution variable possible values e, define functionsfi(e; ci)fi(e=ff; ci ) = P (i =ffjci);value ff e. shall refer fi contributing factor ci e.using operator, rewrite equation (2) followsP (ejc1; : : :; cm) =mi=1 fi (e; ci):(5)interesting notice similarity equation (1) equation (5). equation (1)conditional independence allows one factorize joint probability factors involve lessvariables, equation (5) causal independence allows one factorize conditional probabilityfactors involve less variables. However, ways factors combineddifferent two equations.5.2 Heterogeneous FactorizationsConsider Bayesian network Figure 1. factorizes joint probability P (a; b; c; e1; e2; e3)following list factors:P (a); P (b); P (c); P (e1ja; b; c); P (e2ja; b; c); P (e3je1; e2 ):say factorization homogeneous factors combined way,i.e., multiplication.suppose ei convergent variables. conditional probabilities factorized follows:P (e1ja; b; c)P (e2ja; b; c)P (e3 je1 ; e2)===f11 (e1; a)f12 (e1 ; b)f13 (e1; c);f21 (e2; a)f22 (e2 ; b)f23 (e2; c);f31 (e3; e1)f32 (e3; e2 );311fiZ HANG & P OOLEfactor f11(e1 ; a), instance, contributing factor e1 .say following list factorsf11(e1 ; a); f12(e1; b); f13(e1; c); f21(e2 ; a); f22(e2 ; b); f23(e2 ; c); f31(e3 ; e1); f32(e3 ; e2);P (a); P (b); P (c)(6)constitute heterogeneous factorization P (a; b; c; e1; e2; e3) joint probabilityobtained combining factors proper order using either multiplication operator.word heterogeneous signify fact different factor pairs might combined different ways. call fij heterogeneous factor needs combinedfik operatorcombined factors multiplication. contrast,call factors P (a), P (b), P (c) homogeneous factors.shall refer heterogeneous factorization heterogeneous factorization representedBN Figure 1. obvious heterogeneous factorization finer grainhomogeneous factorization represented BN.6. Flexible Heterogeneous Factorizations Deputationpaper extends exploit finer-grain factorization. compute answer querysumming variables one one factorization .correctness guaranteed fact factors homogeneous factorizationcombined (by multiplication) order distributivity multiplication summations (see proof Theorem 1).According Proposition 3, operatordistributive summations. However, factorsheterogeneous factorization cannot combined arbitrary order. example, consider heterogeneous factorization (6). correct combine f11(e1 ; a) f12 (e1; b) using,combine f31 (e3; e1 ) f32 (e3; e2 ) using, correct combine f11 (e1; a) f31 (e3; e1). want combine latter two multiplication, combined sibling heterogeneous factors.overcome difficulty, transformation called deputation performed BN.transformation change answers queries. heterogeneous factorizationrepresented transformed BN flexible following sense:heterogeneous factorization joint probability flexible if:joint probability=multiplication homogeneous factorscombination (by) heterogeneous factors:(7)property allows us carry multiplication homogeneous factors arbitrary order,sinceassociative commutative, combination heterogeneous factors arbitrary order. conditions Proposition 4 satisfied, also exchange multiplicationcombination. guarantee conditions Proposition 4, elimination ordering needsconstrained (Sections 7 8).heterogeneous factorization P (a; b; c; e1; e2; e3) given end previous sectionflexible. Consider combining heterogeneous factors. Since operatorcommutative312fiE XPLOITING C AUSAL NDEPENDENCEB AYESIAN N ETWORK NFERENCEcbe1e2e1e2e3e3Figure 2: BN Figure 1 deputation convergent variables.associative, one first combine, i, fik s, obtaining conditional probabilityei , combine resulting conditional probabilities. combinationP (e1 ja; b; c)P (e2 ja; b; c)P (e3je1 ; e2)multiplicationP (e1 ja; b; c)P (e2ja; b; c)P (e3je1; e2)convergent variables e1 e2 appear one factor. Consequently, equation(7) hold factorization flexible. problem arises convergent variable shared two factors siblings. example, want combinef11 (e1; a) f31 (e3 ; e1) using. order tackle problem introduce new deputationvariable heterogeneous factor contains single convergent variable.Deputation transformation one apply BN make heterogeneous factorization represented BN flexible. Let e convergent variable. depute e make copye0 e, make parents e parents e0 , replace e e0 contributing factors e, makee0 parent e, set conditional probability P (eje0 ) follows:P (eje0 ) =(10e = e0otherwise(8)shall call e0 deputy e. deputy variable e0 convergent variable definition.variable e, convergent deputation, becomes regular variable deputation.shall refer new regular variable. contrast, shall refer variables regulardeputation old regular variables. conditional probability P (e0 je) homogeneousfactor definition. sometimes called deputing function written (e0; e) sinceensures e0 e always take value.deputation BN obtained BN deputing convergent variables. deputationBN, deputy variables convergent variables deputy variables convergent variables.313fiZ HANG & P OOLEFigure 2 shows deputation BN Figure 1. factorizes joint probabilityP (a; b; c; e1; e01; e2; e02; e3; e03)homogeneous factorsP (a); P (b); P (c); I1(e01; e1); I2(e02; e2); I3(e03; e3);heterogeneous factorsf11(e01 ; a); f12(e01; b); f13(e01 ; c); f21(e02 ; a); f22(e02; b); f23(e02; c); f31(e03; e1); f32(e03; e2):factorization three important properties.1. heterogeneous factor contains one one convergent variable. (Recall eilonger convergent variables deputies are.)2. convergent variable e0 appears one one homogeneous factor, namelydeputing function (e0; e).3. Except deputing functions, none homogeneous factors contain convergentvariables.properties shared factorization represented deputation BN.Proposition 5 heterogeneous factorization represented deputation BN flexible.Proof: Consider combination,, heterogeneous factors deputation BN. Sincecombination operatorcommutative associative, carry combination following two steps. First convergent (deputy) variable e0 , combine heterogeneous factors contain e0 , yielding conditional probability P (e0 je ) e0 . combine resultingconditional probabilities. follows first property mentioned different convergent variables e01 e02, P (e01 je1 ) P (e02 je2 ) share convergent variables. Hencecombination P (e0 je )s multiplication them. Consequently, combination,, heterogeneous factors deputation BN multiplication conditionalprobabilities convergent variables. Therefore,0000joint probability variables deputation BN= multiplication conditional probabilities variables=multiplication conditional probabilities regular variables=multiplication homogeneous factorsmultiplication conditional probabilities convergent variablescombination (by) heterogeneous factors:proposition hence proved. 2Deputation change answer query. precisely,Proposition 6 posterior probability P (X jY =Y0 ) BN deputation.314fiE XPLOITING C AUSAL NDEPENDENCEB AYESIAN N ETWORK NFERENCEProof: Let R, E , E 0 lists old regular, new regular, deputy variables deputation BN respectively. suffices show P (R; E ) original BNdeputation BN. new regular variable e, let e0 deputy. easy see quantityP (e0; e)P (e0j ) deputation BN P (ej ) original BN. Hence,eee00P (R; EX) deputation BN=P (R; E; E 0)EX=P (rjr ) [P (eje)P (e0 je )]E r2R2EeX=P (rjr ) [ (e0; e)P (e0je )]r2Re2E e=P (rjr ) P (eje )00000r2R=proposition proved.2e2 EP (R; E ) original BN:7. Tidy Heterogeneous Factorizationsfar, encountered heterogeneous factorizations correspond Bayesian networks.following algorithm, intermediate heterogeneous factorizations necessarily correspond BNs. property combine form appropriate marginal probabilities. general intuition heterogeneous factors must combine sibling heterogeneous factors multiplied factors containing original convergent variable.previous section, mentioned three properties heterogeneous factorization represented deputation BN, used first property show factorization flexible.two properties qualify factorization tidy heterogeneous factorization, defined below.Let z1 , z2 , ..., zk list variables deputation BN convergent (deputy)variable e0 fz1; z2 ; : : :; zk g, corresponding new regular variable e. flexible heterogeneous factorization P (z1 ; z2; : : :; zk ) said tidy1. convergent (deputy) variable e02fz1; z2; : : :; zk g, factorization contains deputing function (e0; e) homogeneous factor involves e0 .2. Except deputing functions, none homogeneous factors contain convergentvariables.stated earlier, heterogeneous factorization represented deputation BN tidy.certain conditions, given Theorem 3, one obtain tidy factorization P (z2 ; : : :; zk )summing z1 tidy factorization P (z1 ; z2; : : :; zk ) using following procedure.Procedure sum-out1(F1 ; F2; z )Inputs: F1 list homogeneous factors,F2 list heterogeneous factors,z variable.315fiZ HANG & P OOLEOutput: list heterogeneous factors list homogeneous factors.1. Remove F1 factors contain z , multiply resulting in, say, f .factors, set f =nil.2. Remove F2 factors contain z , combine usingresultingin, say, g . factors, set g =nil.P f F .1zPElse add new (heterogeneous) factor z fg F2.Return (F1; F2).3. g =nil, add new (homogeneous) factor4.5.Theorem 3 Suppose list homogeneous factors F1 list heterogeneous factors F2 constitute tidy factorization P (z1 ; z2; : : :; zk ). z1 either convergent variable, old regularvariable, new regular variable whose deputy list fz2; : : :; zk g, proceduresum-out1(F1 ; F2; z1) returns tidy heterogeneous factorization P (z2 ; : : :; zk ).proof theorem quite long hence given appendix.8. Causal Independence Inferencetask compute P (X jY =Y0 ) BN. According Proposition 6,deputation BN.elimination ordering consisting variables outside X [Y legitimate deputyvariable e0 appears corresponding new regular variable e. ordering foundusing, minor adaptations, minimum deficiency search maximum cardinality search.following algorithm computes P (X jY =Y0 ) deputation BN. called 1extension .Procedure 1 (F1; F2; X; Y; Y0; )Inputs: F1 list homogeneous factorsdeputation BN;F2 list heterogeneous factorsdeputation BN;X list query variables;list observed variables;Y0 corresponding list observed values;legitimate elimination ordering.Output: P (X jY =Y0 ).1. Set observed variables factors observed values.2. empty,Remove first variable z .(F1; F2) = sum-out1(F1; F2; z). Endwhile316fiE XPLOITING C AUSAL NDEPENDENCEB AYESIAN N ETWORK NFERENCE3. Set h=multiplication factors F1combination (by) factors F2./* h function variables X . */4. Return h(X )=P h(X ). /* renormalization */XTheorem 4 output 1 (F1; F2; X; Y; Y0; ) indeed P (X jY =Y0 ).Proof: Consider following modifications algorithm. First remove step 1. factorh produced step 3 function variables X . Add new step step 3 setsobserved variables h observed values. shall first show modificationschange output algorithm show output modified algorithmP (X jY =Y0 ).Let f (y; ,), g (y; ,), h(y; z; ,) three functions variables. evidentf (y; ,)g (y; ,)jy=ff = f (y; ,)jy=ff g(y; ,)jy=ff;XX[h(y; z; ,)]jy=ff = [h(y; z; ,)jy=ff ]:zzregular variable, alsof (y; ,)g (y; ,)jy=ff = f (y; ,)jy=ffg (y; ,)jy=ff :Consequently, modifications change output procedure.Since elimination ordering legitimate, always case deputy variable e0summed out, neither corresponding new regular variable e. Let z1 , ..., zk remaining variables time execution algorithm. Then, e0 2fz1 ; : : :; zk g implies e2fz1 ; : : :; zk g. fact factorization represented deputation BN tidyenable us repeatedly apply Theorem 3 conclude that, modifications, factor createdstep 3 simply marginal probability P (X; ). Consequently, output P (X jY =Y0 ). 28.1 Examplesubsection illustrates 1 walking example. Consider computing P (e2 je3=0)deputation Bayesian network shown Figure 2. Suppose elimination ordering is: a, b,c, e01, e02, e1, e03 . first step VE1 ,F1 = fP (a); P (b); P (c); I1(e01; e1); I2(e02; e2); I3(e03; e3=0)g;F2 = ff11(e01; a); f12(e01; b); f13(e01; c); f21(e02; a); f22(e02; b); f23(e02; c); f31(e03; e1); f32(e03; e2)g:procedure enters while-loop sums variables one one.summing a,F1 = fP (b); P (c); I1(e01; e1); I2(e02; e2); I3(e03; e3=0)g;F2 = ff12(e01; b); f13P(e01; c); f22(e02; b); f23(e02; c); f31(e03; e1); f32(e03; e2); 1(e01; e02)g;1 (e01; e02) = P (a)f11(e01 ; a)f21(e02 ; a).summing b,F1 = fP (c); I1(e01; e1); I2(e02; e2); I3(e03; e3=0)g;F2 = ff13(e01; c); f23P(e02; c); f31(e03; e1); f32(e03; e2); 1(e01; e02); 2(e01; e02)g;2 (e01; e02) = b P (b)f12(e01 ; b)f22(e02; b).317fiZ HANG & P OOLEsumming c,F1 = fI1(e01; e1); I2(e02; e2); I3(e03; e3=0)g;F2 = ff31(e03; e1); fP32(e03 ; e2); 1(e01 ; e02); 2(e01 ; e02); 3(e01 ; e02)g;003 (e1; e2) = c P (c)f23 (e02; c)f13(e01 ; c).summing e01 ,F1 = fI2(e02; e2); I3(e03; e3=0)g;F2 = ff31(e03; e1); fP32(e03 ; e2); 4(e1 ; e02)g;4 (e1; e02) = e I1(e01 ; e1)[ 1(e01; e02)2 (e01; e02)3 (e01; e03)].1summing e02 ,F1 = fI3(e03; e3=0)g;F2 = ff31(e03; e1); fP32(e03 ; e2); 5(e1 ; e2)g;5 (e1; e2) = e I2(e02 ; e2) 4(e1 ; e02).2summing e1 ,F1 = fI3(e03; e3=0)g;F2 = ff32(e03; e2); P6(e03; e2)g;6 (e03; e2) = e1 f31(e03 ; e1) 5(e1 ; e2).Finally, summing e03 ,F 1 = ;;F2 = f 7(e2)g; P7 (e2) = e I3(e03 ; e3=0)[f32(e03; e2 )6(e03; e2 )]. procedure enters step 3,3Pnothing example. Finally, procedure returns 7(e2 )= e2 7(e2 ),P (e2je3 =0), required probability.0008.2 Comparing 1comparing 1 , notice summing variable, combinefactors contain variable. However, factorization latter worksfiner grain factorization used former. running example, latter worksfactorization initially consists factors contain two variables; factorization former uses initially include factors contain five variables. hand, latteruses operatorexpensive multiplication. Consider, instance, calculatingf (e; a)g(e; b). Suppose e convergent variable variables binary. operation requires 24 numerical multiplications 24 , 23 numerical summations. hand,multiplying f (e; a) g (e; b) requires 23 numerical multiplications.Despite expensiveness operator, 1 efficient . shall provideempirical evidence support claim Section 10. see simple example true,consider BN Figure 3(1), e convergent variable. Suppose variables binary.Then, computing P (e) using elimination ordering c1 , c2, c3, c4 requires 25 + 24 +23 + 22=60 numerical multiplications (25 , 24) + (24 , 23 ) + (23 , 22 ) + (22 , 2)=30numerical additions. hand, computing P (e) deputation BN shown Figure 3(2)1 using elimination ordering c1, c2, c3 , c4, e0 requires 22 + 22 + 22 + 22 +(322 + 22)=32 numerical multiplications 2 + 2 + 2 + 2 + (32 + 2)=16 numerical additions.Note summing e0 requires 322 + 22 numerical multiplications summingci s, four heterogeneous factors, containing argument e0 . Combining318fiE XPLOITING C AUSAL NDEPENDENCEc1c3c2B AYESIAN N ETWORK NFERENCEc1c4c3c2c4eee(1)c1(2)c3c2e1c4e2c1c2c3c4e1e2ee3e(4)(3)Figure 3: BN, deputation transformations.pairwise requires 322 multiplications. resultant factor needs multiplied deputingfactor (e0; e), requires 22 numerical multiplications.9. Previous MethodsTwo methods proposed previously exploiting causal independence speed inference general BNs (Olesen et al., 1989; Heckerman, 1993). use causal independencetransform topology BN. transformation, conventional algorithms CTPused inference.shall illustrate methods using BN Figure 3(1). Let base combinationoperator e, let denote contribution ci e, let fi (e; ci) contributing factor cie.parent-divorcing method (Olesen et al., 1989) transforms BN one Figure 3(3).transformation, variables regular new variables e1 e2possible values e. conditional probabilities e1 e2 givenP (e1 jc1; c2)=f1(e; c1)f2 (e; c2);P (e2 jc3; c4)=f3(e; c3)f4 (e; c4):conditional probability e givenP (e=ffje1=ff1; e2=ff2 ) = 1 ff=ff1 ff2,value ff e, ff1 e1 , ff2 e2 . shall use PD refer algorithm firstperforms parent-divorcing transformation uses inference.319fiZ HANG & P OOLEtemporal transformation Heckerman (1993) converts BN one Figure 3(4).variables regular transformation newly introduced variablespossible values e. conditional probability e1 givenP (e1=ffjc1) = f1(1=ff; c1);value ff e1 . i=2; 3; 4, conditional probability ei (e4 stands e) givenP (ei =ffjei,1 =ff1 ; ci) =Xff1 ff2 =fffi(e=ff2; ci);possible value ff ei ff1 ei,1 . shall use TT refer algorithm firstperforms temporal transformation uses inference.factorization represented original BN includes factor contain five variables,factors transformed BNs contain three variables. general, transformations lead finer-grain factorizations joint probabilities. PD TTefficient .However, PD TT efficient 1 . shall provide empirical evidence supportclaim next section. illustrate considering calculating P (e).Figure 3(3) using elimination ordering c1, c2, c3 , c4, e1 , e2 would require 23 + 22 +23 + 22 + 23 + 22 =36 numerical multiplications 18 numerical additions.5Figure 3(4) using elimination ordering c1 , e1 , c2, e2 , c3, e3 , c4 would require 22 + 23 + 22 +23 + 22 + 23 + 22 =40 numerical multiplications 20 numerical additions. cases,numerical multiplications additions performed 1 . differences drasticcomplex networks, shown next section.saving example may seem marginal. may reasonable conjecture that,Olesons method produces families three elements, marginal saving hopefor; producing factors two elements rather cliques three elements. However, interactingcausal variables make difference extreme. example, use Olesonsmethod BN Figure 1, produce6 network Figure 4. triangulationnetwork least one clique four elements, yet 1 produce factortwo elements.Note far computing P (e) networks shown Figure 3 concerned, 1efficient PD, PD efficient TT, TT efficient . experimentsshow true general.5. exactly number operations required determine P (e) using clique-tree propagationnetwork. clique tree Figure 3(3) three cliques, one containing fc1 ; c2 ; e1 g, one containing fc3 ; c4 ; e2 g,containing fe1 ; e2 ; eg. first clique contains 8 elements; construct requires 22 + 23 = 12 multiplications.message needs sent third clique marginal e1 obtained summing c1c2 . Similarly second clique. third clique 8 elements requires 12 multiplications construct.order extract P (e) clique, need sum e1 e2 . shown one reason 1efficient CTP VE; 1 never constructs factor three variables example. Note however,advantage CTP cost building cliques amortized many queries.6. Note need produce two variables represent noisy b. need two variables noiseapplied case independent. Note noise network e1 = b cneed create one variable, also e1 e2 would variable (or least perfectly correlated).case would need complicated example show point.320fiE XPLOITING C AUSAL NDEPENDENCEB AYESIAN N ETWORK NFERENCEbec11e21ee21e3Figure 4: result Applying Olesons method BN Figure 1.10. ExperimentsCPCS networks multi-level, multi-valued BNs medicine. created Pradhanet al. (1994) based Computer-based Patient Case Simulation system (CPCS-PM) developedParker Miller (1987). Two CPCS networks7 used experiments. Oneconsists 422 nodes 867 arcs, contains 364 nodes. among largestBNs use present time.CPCS networks contain abundant causal independencies. matter fact, non-rootvariable convergent variable base combination operator MAX. good test casesinference algorithms exploit causal independencies.10.1 CTP-based Approaches versus -based Approachesseen previous section, one kind approach exploiting causal independenciesuse transform BNs. Thereafter, inference algorithms, including CTP ,used inference.found coupling network transformation techniques CTP able carryinference two CPCS networks used experiments. computer ran memoryconstructing clique trees transformed networks. reported next subsection, however, combination network transformation techniques able answermany queries.paper proposed new method exploiting causal independencies. observedcausal independencies lead factorization joint probability finer-grainfactorization entailed conditional independencies alone. One extend inference algorithms, including CTP , exploit finer-grain factorization. paper extendedobtained algorithm called 1 . 1 able answer almost queries twoCPCS networks. conjecture, however, extension CTP would able carryinference two CPCS networks all. resources 1 takes answerquery BN extension CTP would take construct clique tree7. Obtained ftp://camis.stanford.edu/pub/pradhan.V1.0.txt CPCS-networks/std1.08.5.321file names CPCS-LM-SM-K0-fi50454035302520151050Number queriesNumber queriesZ HANG & P OOLE"5ve1""5pd""5tt""5ve"Number queries0 1 2 3 4 5 6 7 8 9CPU time seconds50454035302520151050"10ve1""10pd""10tt""10ve"0 1 2 3 4 5 6 7 8 9CPU time seconds50454035302520151050"15ve1""15pd""15tt"0 1 2 3 4 5 6 7 8 9 10CPU time secondsFigure 5: Comparisons 364-node BN.BN are, seen next subsection, queries two CPCS networks1 able answer.summary, CTP based approaches would able deal two CPCSnetworks, -based approaches (to different extents).10.2 Comparisons -based Approachessubsection provides experimental data compare -based approaches namely PD, TT,1 . also compare approaches determine much gainedexploiting causal independencies.364-node network, three types queries one query variable five, ten, fifteenobservations respectively considered. Fifty queries randomly generated querytype. query passed algorithms nodes irrelevant pruned. general, observations mean less irrelevant nodes hence greater difficulty answer query.CPU times algorithms spent answering queries recorded.order get statistics algorithms, CPU time consumption limited ten secondsmemory consumption limited ten megabytes.statistics shown Figure 5. charts, curve 5ve1, instance, displaystime statistics 1 queries five observations. Points X-axis represent CPU times322fi50454035302520151050B AYESIAN N ETWORK NFERENCENumber queriesNumber queriesE XPLOITING C AUSAL NDEPENDENCE"5ve1""5pd""5tt""5ve"0 1 2 3 4 5 6 7 8 9CPU time seconds4035302520151050"10ve1""10pd""10tt"0 1 2 3 4 5 6 7 8 9 10CPU time secondsFigure 6: Comparisons 422-node BN.seconds. time point, corresponding point Y-axis represents number fiveobservation queries answered within time 1 .see 1 able answer queries, PD TT able answerten-observation fifteen-observation queries. able answer majorityqueries.get feeling average performances algorithms, regard curves representing functions , instead x. integration, along -axis, curve 10PD, instance,roughly total amount time PD took answer ten-observation queries PDable answer. Dividing total number queries answered, one gets average time PDtook answer ten-observation query.clear average, 1 performed significantly better PD TT, turnperformed much better . average performance PD five- ten-observation queriesroughly TT, slightly better fifteen-observation queries.422-node network, two types queries five ten observations consideredfifty queries generated type. space time limits imposed364-node networks. Moreover, approximations made; real numbers smaller 0.00001regarded zero. Since approximations algorithms, comparisonsfair.statistics shown Figure 6. curves 5ve1 10ve1 hardly visibleclose -axis.see average, 1 performed significantly better PD, PD performed significantly better TT, TT performed much better .One might notice TT able answer thirty nine ten-observation queries,1 PD able to. due limit memory consumption. seenext subsection, memory consumption limit increased twenty megabytes, 1 ableanswer forty five ten-observation queries exactly ten seconds.10.3 Effectiveness 1established 1 efficient -based algorithm exploiting causalindependencies. section investigate effective 1 is.323fiZ HANG & P OOLE422-node BNNumber queriesNumber queries364-node BN50454035302520151050"5ve1""10ve1""15ve1""20ve1"0 1 2 3 4 5 6 7 8 9 10CPU time seconds50454035302520151050"5ve1""10ve1""15ve1"05 10 15 20 25 30 35 40CPU time secondsFigure 7: Time statistics 1 .Experiments carried two CPCS networks answer question.364-node network, four types queries one query variable five, ten, fifteen, twentyobservations respectively considered. Fifty queries randomly generated querytype. statistics times 1 took answer queries given left chart Figure7. collecting statistics, ten MB memory limit ten second CPU time limitimposed guide excessive resource demands. see fifty five-observation queriesnetwork answered less half second. Forty eight ten-observation queries,forty five fifteen-observation queries, forty twenty-observation queries answered onesecond. is, however, one twenty-observation query 1 able answer withintime memory limits.364-node network, three types queries one query variable five, ten, fifteen,observations respectively considered. Fifty queries randomly generated querytype. Unlike previous section, approximations made. twenty MB memory limitforty-second CPU time limit imposed. time statistics shown right hand sidechart. see 1 able answer queries majority queriesanswered little time. are, however, three fifteen-observation queries 1 ableanswer.11. Conclusionspaper concerned exploit causal independence exact BN inference. Previous approaches (Olesen et al., 1989; Heckerman, 1993) use causal independencies transformBNs. Efficiency gained inference easier transformed BNs originalBNs.new method proposed paper. basic idea. Bayesian networkviewed representing factorization joint probability multiplication listconditional probabilities. studied notion causal independence enables onefactorize conditional probabilities combination even smaller factors consequentlyobtain finer-grain factorization joint probability.propose extend inference algorithms make use finer-grain factorization.paper extended algorithm called . Experiments shown extended algo324fiE XPLOITING C AUSAL NDEPENDENCEB AYESIAN N ETWORK NFERENCErithm, 1 , significantly efficient one first performs Olesen et al.s Heckermanstransformation apply .choice instead widely known CTP algorithm due ability worknetworks CTP cannot deal with. matter fact, CTP able deal networksused experiments, even Olesen et al.s Heckermans transformation. hand,1 able answer almost randomly generated queries majority queriesanswered little time. would interesting extend CTP make use finer-grainfactorization mentioned above.seen previous section, queries, especially 422-node network,took 1 long time answer. also queries 1 able answer.queries, approximation must. employed approximation technique comparingalgorithms 422-node network. technique captures, extent, heuristic ignoringminor distinctions. future work, developing way bound error techniqueanytime algorithm based technique.Acknowledgementsgrateful Malcolm Pradhan Gregory Provan sharing us CPCS networks.also thank Jack Breese, Bruce DAmbrosio, Mike Horsch, Runping Qi, Glenn Shafervaluable discussions, Ronen Brafman, Chris Geib, Mike Horsch anonymous reviewers helpful comments. Mr. Tak Yin Chan great help experimentations.Research supported NSERC Grant OGPOO44121, Institute Robotics IntelligentSystems, Hong Kong Research Council grant HKUST658/95E Sino Software Research Centergrant SSRC95/96.EG01.Appendix A. Proof Theorem 3Theorem 3 Suppose list homogeneous factors F1 list heterogeneous factors F2 constitute tidy factorization P (z1 ; z2; : : :; zk ). z1 either convergent variable, old regularvariable, new regular variable whose deputy list fz2 ; : : :; zk g, proceduresum-out1(F1 ; F2; z1) returns tidy heterogeneous factorization P (z2 ; : : :; zk ).Proof: Suppose f1 , ..., fr heterogeneous factors g1, ..., gs homogeneousfactors. Also suppose f1 , ..., fl , g1, ..., gm factors contain z1 .P (z2 ; : : :; zk )====XP (z1 ; z2; : : :; zk)z1Xz1rj=1fjXi=1gilj=1fj )(rj=l+1 fj )]gii=1 i=m+1X l[(j =1 fjgi)(rj=l+1 fj )]giz1i=1i=m+1z1[(325gi(9)fiZ HANG & P OOLE=Xlr[(j=1 fj gi)(j=l+1fj )]gi ;z1i=1i=m+1(10)equation (10) due Proposition 3. Equation (9) follows Proposition 4. matterQ g duefact, z1 convergent variable, convergent variablei=1first condition tidiness. condition Proposition 4 satisfied z1 appearfl+1 , ..., fr . hand, z1 old regular variable new regular variable whoseQ g contains convergent variables duedeputy appear list z2 , ..., zk ,i=1second condition tidiness. condition Proposition 4 satisfied. thus provedsum-out1(F1 ; F2; z1) yields flexible heterogeneous factorization P (z2 ; : : :; zk ).Let e0 convergent variable list z2 , ..., zk . z1 cannot corresponding new regular variable e. Hence factor (e0; e) touched sum-out1(F1 ; F2; z1). Consequently,show new factor created sum-out1(F1 ; F2; z1) either heterogeneous factorhomogeneous factor contain convergent variable, factorization returned tidy.Suppose sum-out1(F1 ; F2; z1) create new homogeneous factor. heterogeneous factors F1 contain z1 . z1 convergent variable, say e0, (e0; e) homoPgeneous factor contain e0 . new factor e (e0; e), contain convergentvariables. z1 old regular variable new regular variable whose deputy list z2 ,..., zk , factors contain z1 contain convergent variables. Hence new factorcontain convergent variables. theorem thus proved. 20ReferencesArnborg, S., Corneil, D. G., & Proskurowski, A. (1987). Complexity finding embeddingk-tree. SIAM J. Alg. Disc. Meth., 8(2), 277284.Baker, M., & Boult, T. (1990). Pruning Bayesian networks efficient computation. Proc. SixthConf. Uncertainty Artificial Intelligence, pp. 257264 Cambridge, Mass.Bertele, U., & Brioschi, F. (1972). Nonserial dynamic programming, Vol. 91 MathematicsScience Engineering. Academic Press.Boutilier, C., Friedman, N., Goldszmidt, M., & Koller, D. (1996). Context-specific independenceBayesian networks. E. Horvitz F. Jensen (Ed.), Proc. Twelthth Conf. UncertaintyArtificial Intelligence, pp. 115123 Portland, Oregon.Cooper, G. F. (1990). computational complexity probabilistic inference using Bayesian beliefnetworks. Artificial Intelligence, 42(2-3), 393405.Dagum, P., & Galper, A. (1993). Additive belief-network models. D. Heckerman A. Mamdani(Ed.), Proc. Ninth Conf. Uncertainty Artificial Intelligence, pp. 9198 Washington D.C.DAmbrosio (1995). Local expression languages probabilistic dependence. International Journal Approximate Reasoning, 13(1), 6181.DAmbrosio, B. (1994). Symbolic probabilistic inference large BN2O networks. R. Lopez deMantaras D. Poole (Ed.), Proc. Tenth Conf. Uncertainty Artificial Intelligence, pp.128135 Seattle.326fiE XPLOITING C AUSAL NDEPENDENCEB AYESIAN N ETWORK NFERENCEDechter, R. (1996). Bucket elimination: unifying framework probabilistic inference. E.Horvits F. Jensen (Ed.), Proc. Twelthth Conf. Uncertainty Artificial Intelligence, pp.211219 Portland, Oregon.Dez, F. J. (1993). Parameter adjustment bayes networks. generalized noisy or-gate. D.Heckerman A. Mamdani (Ed.), Proc. Ninth Conf. Uncertainty Artificial Intelligence,pp. 99105 Washington D.C.Duda, R. O., Hart, P. E., & Nilsson, N. J. (1976). Subjective Bayesian methods rule-based inference systems. Proc. AFIPS Nat. Comp. Conf., pp. 10751082.Geiger, D., & Heckerman, D. (1996). Knowledge representation inference similarity networksBayesian multinets. Artificial Intelligence, 82, 4574.Geiger, D., Verma, T., & Pearl, J. (1990). d-separation: theorems algorithms. M. Henrionet. al. (Ed.), Uncertainty Artificial Intelligence 5, pp. 139148. North Holland, New York.Good, I. (1961). causal calculus (i). British Journal Philosophy Science, 11, 305318.Heckerman, D. (1993). Causal independence knowledge acquisition inference. Proc.Ninth Conference Uncertainty Artificial Intelligence, pp. 122127.Heckerman, D., & Breese, J. (1994). new look causal independence. Proc. TenthConference Uncertainty Artificial Ingelligence, pp. 286292.Henrion, M. (1987). practical issues constructing belief networks. L. Kanal T. LevittJ. Lemmer (Ed.), Uncertainty Artificial Intelligence, pp. 161174. North-Holland.Howard, R. A., & Matheson, J. E. (1981). Influence diagrams. Howard, R. A., & Matheson,J. (Eds.), Principles Applications Decision Analysis, pp. 720762. Strategic Decisions Group, CA.Jensen, F. V., Lauritzen, S. L., & Olesen, K. G. (1990). Bayesian updating causal probabilisticnetworks local computations. Computational Statistics Quaterly, 4, 269282.Kim, J., & Pearl, J. (1983). computational model causal diagnostic reasoning inferenceengines. Proc. Eighth International Joint Conference Artificial Intelligence, pp.190193 Karlsruhe, Germany.Kjrulff, U. (1990). Triangulation graphs - algorithms giving small total state space. Tech. rep.R 90-09, Department Mathematics Computer Science, Strandvejen, DK 9000 Aalborg,Denmark.Lauritzen, S. L., Dawid, A. P., Larsen, B. N., & Leimer, H. G. (1990). Independence propertiesdirected markov fields. Networks, 20, 491506.Lauritzen, S. L., & Spiegelhalter, D. J. (1988). Local computations probabilities graphicalstructures application expert systems. Journal Royal Statistical Society,Series B, 50(2), 157224.327fiZ HANG & P OOLELi, Z., & DAmbrosio, B. (1994). Efficient inference Bayes networks combinatorial optimization problem. International Journal Approximate Reasoning, 11(1), 5581.Olesen, K. G., & Andreassen, S. (1993). Specification models large expert systems basedcausal probabilistic networks. Artificial Intelligence Medicine, 5, 269281.Olesen, K. G., Kjrulff, U., Jensen, F., Falck, B., Andreassen, S., & Andersen, S. K. (1989).munin network median nerve - case study loops. Applied Artificial Intelligence,3, 384403.Parker, R., & Miller, R. (1987). Using causal knowledge creat simulated patient cases: CPSCproject extension Internist-1. Proc. 11th Symp. Comp. Appl. Medical Care, pp.473480 Los Alamitos, CA. IEEE Comp Soc Press.Pearl, J. (1988). Probabilistic Reasoning Intelligent Systems: Networks Plausible Inference.Morgan Kaufmann, San Mateo, CA.Poole, D. (1993). Probabilistic Horn abduction Bayesian networks. Artificial Intelligence, 64(1),81129.Pradhan, M., Provan, G., Middleton, B., & Henrion, M. (1994). Knowledge engineering largebelief networks. R. Lopez de Mantaras D. Poole (Ed.), Proc. Tenth Conf. UncertaintyArtificial Intelligence, pp. 484490 Seattle.Shachter, R. D., DAmbrosio, B. D., & Del Favero, B. D. (1990). Symbolic probabilistic inferencebelief networks. Proc. 8th National Conference Artificial Intelligence, pp. 126131Boston. MIT Press.Shafer, G., & Shenoy, P. (1990). Probability propagation. Annals Mathematics ArtificialIntelligence, 2, 327352.Shortliffe, E., & Buchanan, G. B. (1975). model inexact reasoning medicine. Math. Biosci.,23, 351379.Srinivas, S. (1993). generalization noisy-or model. Proc. Ninth Conference Uncertainty Artificial Intelligence, pp. 208215.Tarjan, R. E., & Yannakakis, M. (1984). Simple linear time algorithm test chordality graphs,test acyclicity hypergraphs, selectively reduce acyclic hypergraphs. SIAM J. Comput.,13, 566579.Zhang, N. L., & Poole, D. (1994). simple approach Bayesian network computations. Proc.Tenth Canadian Conference Artificial Intelligence, pp. 171178.328fiJournal Artificial Intelligence Research 5 (1996) 53-94Submitted 3/95; published 9/96Cue Phrase Classification Using Machine LearningDiane J. LitmanAT&T Labs - Research, 600 Mountain AvenueMurray Hill, NJ 07974 USAdiane@research.att.comAbstractCue phrases may used discourse sense explicitly signal discourse structure,also sentential sense convey semantic rather structural information. Correctlyclassifying cue phrases discourse sentential critical natural language processingsystems exploit discourse structure, e.g., performing tasks anaphora resolution plan recognition. paper explores use machine learning classifyingcue phrases discourse sentential. Two machine learning programs (cgrendelC4.5) used induce classification models sets pre-classified cue phrasesfeatures text speech. Machine learning shown effective techniqueautomating generation classification models, also improvingupon previous results. compared manually derived classification models alreadyliterature, learned models often perform higher accuracy contain newlinguistic insights data. addition, ability automatically construct classification models makes easier comparatively analyze utility alternative featurerepresentations data. Finally, ease retraining makes learning approachscalable exible manual methods.1. IntroductionCue phrases words phrases may sometimes used explicitly signal discoursestructure text speech. particular, used discourse sense, cuephrase explicitly conveys structural information. used sentential sense, cuephrase instead conveys semantic rather structural information. following examples(taken spoken language corpus described Section 2) illustrate samplediscourse sentential usages cue phrases \say" \further":Discourse\: : : might concept say researcher worked fifteen yearscertain project : : : "\Further, crucial AI probably expert databases well : : : "Sentential\: : : let say bears strong resemblance much work that'sdone semantic nets even frames."\: : : place even stranger away : : : "example, used discourse sense, cue phrase \say" conveys structuralinformation example beginning. used sentential sense, \say"convey structural information instead functions verb.c 1996 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiLitmanability correctly classify cue phrases discourse sentential criticalnatural language processing systems need recognize convey discourse structure,tasks improving anaphora resolution (Grosz & Sidner, 1986; Reichman, 1985).Consider following example, taken corpus describedSection 21 :system attempts hold rules, say expert database expert system,expect hold rules fact apply usappropriate situations.example, cue phrases \say" \then" discourse usages, explicitlysignal boundaries intervening subtopic discourse structure. Furthermore,referents noun phrases \the system," \an expert database," \an expertsystem" possible referents pronoun \it." structural informationconveyed cue phrases, system determine \the system" relevantinterpreting pronoun \it," \an expert database" \an expert system"occur within embedded (and concluded) subtopic. Without cue phrases,reasoning required determine referent \the system" intended referent\it" would much complex.Correctly classifying cue phrases discourse sentential important naturallanguage processing tasks well. discourse/sentential distinction usedimprove naturalness synthetic speech text-to-speech systems (Hirschberg, 1990).Text-to-speech systems generate synthesized speech unrestricted text. cue phraseclassified discourse sentential using features input text,synthesized using different intonational models discourse sentential usages.addition, explicitly identifying rhetorical relationships, discourse usages cuephrases used improve coherence multisentential texts natural languagegeneration systems (Zuckerman & Pearl, 1986; Moser & Moore, 1995). Cue phrasesalso used reduce complexity discourse processing areas argumentunderstanding (Cohen, 1984) plan recognition (Litman & Allen, 1987; Grosz & Sidner,1986).problem cue phrase classification often noted (Grosz & Sidner,1986), recently, models classifying cue phrases neither developed evaluatedbased careful empirical analyses. Even though literature suggests featuresmight useful cue phrase classification, quantitative analyses actualclassification algorithms use features (nor suggestions different typesfeatures might combined). systems recognize generate cue phrases simplyassume discourse uses utterance clause initial (Reichman, 1985; Zuckerman &Pearl, 1986). empirical studies showing intonational prominencecertain word classes varies respect discourse function (Halliday & Hassan, 1976;Altenberg, 1987), studies investigate cue phrases per se.address limitations, Hirschberg Litman (1993) conducted several empiricalstudies specifically addressing cue phrase classification text speech. HirschbergLitman pre-classified set naturally occurring cue phrases, described cue phraseterms prosodic textual features (the features posited literature easy1. example also described detail Hirschberg Litman (1993).54fiCue Phrase Classification Using Machine Learningautomatically code), manually examined data construct classification modelsbest predicted classifications feature values.paper examines utility machine learning automating constructionmodels classifying cue phrases empirical data. set experimentsdescribed use two machine learning programs, cgrendel (Cohen, 1992, 1993)C4.5 (Quinlan, 1993), induce classification models sets pre-classified cue phrasesfeatures. features, classes training examples used studiesHirschberg Litman (1993), well additional features, classes training examples, given input machine learning programs. results evaluatedquantitatively qualitatively, comparing error rates contentmanually derived learned classification models. experimental results showmachine learning indeed effective technique, automating generationclassification models, also improving upon previous results. accuracylearned classification models often higher accuracy manually derivedmodels, learned models often contain new linguistic implications. learningparadigm also makes easier compare utility different knowledge sources,update model given new features, classes, training data.next section summarizes previous work cue phrase classification. Section 3describes machine learning approach cue phrase classification takenpaper. particular, section describes four sets experiments use machinelearning automatically induce cue phrase classification models. types inputsoutputs machine learning programs presented, methodologiesused evaluate results. Section 4 presents discusses experimental results,highlights many benefits machine learning approach. Section 5 discussespractical utility results paper. Finally, Section 6 discusses use machinelearning studies discourse, Section 7 concludes.2. Previous Work Classifying Cue Phrasessection summarizes Hirschberg's Litman's empirical studies classificationcue phrases speech text (Hirschberg & Litman, 1987, 1993; Litman & Hirschberg,1990). Hirschberg's Litman's data (cue phrases taken corpora recordedtranscribed speech, classified discourse sentential, coded using speech-basedtext-based features) used create input machine learning experiments. Hirschberg's Litman's results (performance figures manually developed cuephrase classification models) used benchmark evaluating performanceclassification models produced machine learning.first study Hirschberg Litman investigated usage cue phrase \now"multiple speakers radio call-in show (Hirschberg & Litman, 1987). classificationmodel based prosodic features developed based manual analysis \training"set 48 examples \now", evaluated previously unseen test set 52 examples\now". follow-up study (Hirschberg & Litman, 1993), Hirschberg Litman testedclassification model larger set cue phrases, namely single word cue phrasestechnical keynote address single speaker. corpus yielded 953 instances 3455fiLitmanProsodic Model:composition intermediate phrase = aloneelseif composition intermediate phrase = :aloneposition intermediate phrase = firstaccent = deaccentedelseif accent = L*elseif accent = H*elseif accent = complexelseif position intermediate phrase = :firstdiscoursediscoursediscoursesententialsententialsentential(1)(2)(3)(4)(5)(6)(7)(8)Textual Model:preceding orthography = trueelseif preceding orthography = false(9)(10)discoursesententialFigure 1: Decision tree representation manually derived classification modelsHirschberg Litman.different single word cue phrases derived literature.2 Hirschberg Litman alsoused cue phrases first 17 minutes corpus develop complementary cuephrase classification model based textual features (Litman & Hirschberg, 1990),tested full corpus (Hirschberg & Litman, 1993). first studyreferred \now" study, follow-up study \multiple cue phrase" study.Note term \multiple" means 34 different single word cue phrases (as opposedcue phrase \now") considered, cue phrases consisting multiplewords (e.g. \by way") considered.method Hirschberg Litman used develop prosodic textual classification models follows. first separately classified example cue phrasedata discourse, sentential ambiguous listening recording readingtranscription.3 example also described set prosodic textual features.4Previous observations literature correlating discourse structure prosodic information, discourse usages cue phrases initial position clause, contributedchoice features. set classified described examples examinedorder manually develop classification models shown Figure 1. modelsshown using decision trees ease comparison results C4.5explained below.Prosody described using Pierrehumbert's theory English intonation (Pierrehumbert, 1980). Pierrehumbert's theory, intonational contours described sequenceslow (L) high (H) tones fundamental frequency (F0) contour (the physical2. Figure 2 contains list 34 cue phrases. Hirschberg Litman (1993) provide full details regardingdistribution cue phrases. frequent cue phrase \and", occurs 320 times.next frequent cue phrase \now", occurs 69 times. \But," \like," \or" \so" alsooccur fifty times. four least frequent cue phrases { \essentially," \otherwise," \since"\therefore" { occur 2 times.3. class ambiguous introduced multiple cue phrase study (Hirschberg & Litman, 1993;Litman & Hirschberg, 1990).4. Although limited set textual features noted \now" data, analysis \now" datayield textual classification model.56fiCue Phrase Classification Using Machine Learningcorrelate pitch). Intonational contours domain intonational phrase.finite-state grammar describes set tonal sequences intonational phrase.well-formed intonational phrase consists one intermediate phrases followedboundary tone. well-formed intermediate phrase one pitch accents followedphrase accent. Boundary tones phrase accents consist single tone,pitch accents consist either single tone pair tones. two simple pitchaccents (H* L*) four complex accents (L*+H, L+H*, H*+L, H+L*).* indicates tone aligned stressed syllable associated lexical item.Note every stressed syllable accented. Lexical items bear pitch accentscalled accented, called deaccented.Prosody manually transcribed Hirschberg examining fundamental frequency (F0) contour, listening recording. transcription processperformed separately process discourse/sentential classification. produceF0 contour, recording corpus digitized pitch-tracked using speech analysis software. resulted display F0 x-axis represented timey-axis represented frequency Hz. Various phrase final characteristics (e.g., phrase accents,boundary tones, well pauses syllable lengthening) helped identify intermediateintonational phrases, peaks valleys display F0 contour helpedidentify pitch accents. Similar manual transcriptions prosodic phrasing accentshown reliable across coders (Pitrelli, Beckman, & Hirschberg, 1994).prosody coded, Hirschberg Litman represented every cue phrase termsfollowing prosodic features.5 Accent corresponded pitch accent (if any)associated cue phrase. intonational intermediate phrasescontaining cue phrase, feature composition phrase represented whethercue phrase alone phrase (the phrase contained cue phrase,cue phrase cue phrases). Position phrase represented whether cuephrase first (the first lexical item prosodic phrase unit { possibly precededcue phrases) not.textual features used multiple cue phrase study (Hirschberg & Litman, 1993;Litman & Hirschberg, 1990) extracted automatically transcript. partspeech cue phrase obtained running program tagging words oneapproximately 80 parts speech (Church, 1988) transcript.6 Several characteristicscue phrase's immediate context also noted, particular, whether immediately preceded succeeded orthography (punctuation paragraph boundary),whether immediately preceded succeeded lexical item correspondinganother cue phrase.background, classification models shown Figure 1 explained.prosodic model uniquely classifies cue phrase using features compositionintermediate phrase, position intermediate phrase, accent. cue phraseuttered single intermediate phrase { possibly cue phrases (i.e., line (1)Figure 1), larger intermediate phrase initial position (possibly preceded5. features used Figure 1 discussed here.6. Another syntactic feature - dominating constituent - obtained running parser Fidditch (Hindle,1989) transcript. However, since feature appear models manually derivedtraining data (Litman & Hirschberg, 1990), feature pursued.57fiLitmanModelClassifiable Cue Phrases (N=878) Classifiable Non-Conjuncts (N=495)Prosodic24.6 3.014.7 3.2Textual19.9 2.816.1 3.4Default Class38.8 3.240.8 4.4Table 1: 95% confidence intervals error rates (%) manually derived classification models Hirschberg Litman, testing data (multiple cue phrase corpus).cue phrases) L* accent deaccented, classified discourse. partlarger intermediate phrase either initial position H* complex accent,non-initial position, sentential. textual model classifies cue phrases usingsingle feature preceding orthography.7 cue phrase preceded typeorthography, classified discourse; otherwise, cue phrase classified sentential.prosodic model used classify cue phrase training data, i.e.,100 examples \now" model developed, error rate 2.0%.8error rate textual model training examples multiple cue phrasecorpus 10.6% (Litman & Hirschberg, 1990).prosodic textual models evaluated quantifying performancecorrectly classifying example cue phrases two test sets data, shown rowslabeled \Prosodic" \Textual" Table 1. test set subset 953 examplesmultiple cue phrase corpus. first test set (878 examples) consistsclassifiable cue phrases, i.e., cue phrases Hirschberg Litman classifieddiscourse classified sentential. Note cue phrases HirschbergLitman classified ambiguous unable agree upon includedclassifiable subset. (These cue phrases considered learning experimentsdescribed Section 4.4, however.) second test set, classifiable non-conjuncts(495 examples), created classifiable cue phrases removing instances\and", \or" \but". subset considered particularly reliable since 97.2% nonconjuncts classifiable compared 92.1% example cue phrases. error rateprosodic model 24.6% classifiable cue phrases 14.7% classifiablenon-conjuncts (Hirschberg & Litman, 1993). error rate textual model 19.9%classifiable cue phrases 16.1% classifiable non-conjuncts (Hirschberg &Litman, 1993). last row table shows error rates simple \Default Class"baseline model always predicts frequent class corpus (sentential).rates 38.8% classifiable cue phrases 40.8% classifiable non-conjuncts.7. classification model based part-of-speech also developed (Litman & Hirschberg, 1990;Hirschberg & Litman, 1993); however, perform well model based orthography(the error rate part-of-speech model 36.1% larger test set, opposed 19.9%orthographic model). Furthermore, model combined orthography part-of-speech performedcomparably simpler orthographic model (Hirschberg & Litman, 1993). Hirschberg Litmanalso preliminary observations suggesting adjacency cue phrases might prove useful.8. Following Hirschberg Litman (1993), original 48- 52-example sets (Hirschberg & Litman,1987) combined.58fiCue Phrase Classification Using Machine LearningAlthough computed Hirschberg Litman, Table 1 also associates margins errors error percentage, used compute confidence intervals (Freedman,Pisani, & Purves, 1978). (The margin error 2 standard errors 95% confidenceinterval using normal table.) lower bound confidence interval computedsubtracting margin error error rate, upper bound computedadding margin error. Thus, 95% confidence interval prosodic modelclassifiable cue phrase test set (21.6%, 27.6%). Analysis confidence intervalsindicates improvement prosodic textual models defaultmodel significant. example, upper bounds error rates prosodictextual models classifiable cue phrase test set - 27.6% 22.7% - lowerlower bound default class error rate - 35.6%. methodology using statistical inference determine whether differences error rates significant discussedfully Section 3.3.3. Experiments using Machine Learningsection describes experiments use machine learning programs C4.5 (Quinlan,1993) cgrendel (Cohen, 1992, 1993) automatically induce cue phrase classificationmodels. cgrendel C4.5 similar learning methodsneural networks cart (Brieman, Friedman, Olshen, & Stone, 1984) induceclassification models preclassified examples. program takes following inputs:names classes learned, names possible values fixed set features,training data (i.e., set examples class feature values specified).output program classification model, expressed C4.5 decision treecgrendel ordered set if-then rules. cgrendel C4.5 learnclassification models using greedy search guided \information gain" metric.first group machine learning experiments replicate training testing conditions used Hirschberg Litman (1993) (reviewed previous section), supportdirect comparison manual machine learning approaches. second groupexperiments evaluate utility training larger amounts data feasiblemanual analysis Hirschberg Litman. third set experiments allowmachine learning algorithms distinguish among 34 cue phrases, evaluate utility developing classification models specialized particular cue phrases. fourth setexperiments consider examples multiple cue phrase corpus,classifiable cue phrases. set experiments attempt predict third classificationunknown, well classifications discourse sentential. Finally, withinfour sets experiments, individual experiment learns classification model usingdifferent feature representation training data. experiments consider featuresisolation, comparatively evaluate utility individual feature classification.experiments consider linguistically motivated sets features, gain insightfeature interactions.3.1 Machine Learning Inputssection describes inputs machine learning programs, namely,names classifications learned, names possible values fixed set59fiLitmanClassificationJudge1/Judge2Cue PhrasesNon-ConjunctsTotal953509Classifiable Cue PhrasesDiscourse SententialD/DS/S341537202293Unknown?/? D/S S/D D/? S/? ?/D ?/S5950005611100002Table 2: Determining classification cue phrases.features, training data specifying class feature values exampletraining set.3.1.1 Classificationsfirst input learning program specifies names fixed set classifications.Hirschberg Litman's 3-way classification cue phrases 2 judges (Hirschberg &Litman, 1993) transformed classifications used machine learning programsshown Table 2. Recall Section 2 judge classified cue phrasediscourse, sentential, ambiguous; classifications shown D, S, ? Table 2.discussed Section 2, classifiable cue phrases cue phrases judgesclassified either discourse sentential usages. Thus, machine learningexperiments, cue phrase assigned classification discourse judges classifieddiscourse (D/D, shown column 3 Table 2). Similarly, cue phrase assignedclassification sentential judges classified sentential (S/S, shown column4). 878 (92.1%) 953 examples full corpus classifiable, 495 (97.2%)509 non-conjuncts classifiable.machine learning experiments, third cue phrase classification alsoconsidered. particular, cue phrase assigned classification unknownHirschberg Litman classified ambiguous (?/?, shown column 5),unable agree upon classification (D/S, S/D, D/?, S/?, ?/D, ?/S, showncolumns 6-11). full corpus, 59 cue phrases (6.2%) judged ambiguousjudges (?/?). 5 cases (.5%) true disagreement (D/S). 11 cue phrases(1.2%) judged ambiguous first judge classified second judge (?/D?/S). conjunctions \and," \or" \but" removed corpus,11 examples (2.2%) judged ambiguous judges: 3 instances \actually,"2 instances \because" \essentially," 1 instance \generally," \indeed,"\like" \now." 1 case (.2%) true disagreement (an instance \like").2 cue phrases (.4%) - instance \like" \otherwise" - judged ambiguousfirst judge.3.1.2 Featuressecond component input learning program specifies names potentialvalues fixed set features. set primitive features considered learningexperiments shown Figure 2. Feature values either numeric value onefixed set user-defined symbolic values. feature representation shown followsrepresentation Hirschberg Litman except noted. Length intonational phrase (P60fiCue Phrase Classification Using Machine LearningProsodic Features{ length intonational phrase (P-L): integer.{ position intonational phrase (P-P): integer.{ length intermediate phrase (I-L): integer.{ position intermediate phrase (I-P): integer.{ composition intermediate phrase (I-C): only, cue phrases, other.{ accent (A): H*, L*, L*+H, L+H*, H*+L, H+L*, deaccented, ambiguous.{ accent* (A*): H*, L*, complex, deaccented, ambiguous.Textual Features{ preceding cue phrase (C-P): true, false, NA.{ succeeding cue phrase (C-S): true, false, NA.{ preceding orthography (O-P): comma, dash, period, paragraph, false, NA.{ preceding orthography* (O-P*): true, false, NA.{ succeeding orthography (O-S): comma, dash, period, false, NA.{ succeeding orthography* (O-S*): true, false, NA.{ part-of-speech (POS): article, coordinating conjunction, cardinal numeral, subordinating conjunction,preposition, adjective, singular mass noun, singular proper noun, intensifier, adverb, verb base form,NA.Lexical Feature{ token (T): actually, also, although, and, basically, because, but, essentially, except, finally, first, further,generally, however, indeed, like, look, next, no, now, ok, or, otherwise, right, say, second, see, similarly,since, so, then, therefore, well, yes.Figure 2: Representation features, use C4.5 cgrendel.L) length intermediate phrase (I-L) represent number words intonationalintermediate phrases containing cue phrase, respectively. feature coded\now" data, coded (although used) later multiple cue phrasedata. Position intonational phrase (P-P) position intermediate phrase (I-P) usenumeric values rather earlier symbolic values (e.g., first Figure 1). Compositionintermediate phrase (I-C) replaces value alone (meaning phrase containedexample cue phrase, example plus cue phrases) Figure 1primitive values cue phrases (whose disjunction equivalentalone); I-C also uses value rather :alone (as used Figure 1). Accent(A) uses value ambiguous represent cases prosodic analysis yieldsdisjunction (e.g., \H*+L H*"). Accent* (A*) re-represents symbolic valuesfeature accent (A) using abstract level description. particular, L*+H,L+H*, H*+L, H+L* represented separate values single value {superclass complex { A*. useful abstractions often result learningprocess, A* explicitly represented advance prosodic feature representationpotential automated (see Section 5).textual features, value NA (not applicable) ects fact 39 recordedexamples included transcription, done independently61fiLitmanstudies performed Hirschberg Litman (1993). coding used HirschbergLitman, preceding cue phrase (C-P) succeeding cue phrase (C-S) represented actualcue phrase (e.g., \and") preceding succeeding cue phrase; valuetrue encodes cases. prosodic feature set A*, preceding orthography*(O-P*) succeeding orthography* (O-S*) re-represent symbolic valuespreceding orthography (O-P) succeeding orthography (O-S), respectively, usingabstract level description (e.g., comma, dash, period represented separate valuesO-S single value true O-S*). done reliability codingdetailed transcriptions orthography known. Part-of-speech (POS) representspart speech assigned cue phrase Church's program tagging part speechunrestricted text (Church, 1988); program assign approximately 80 differentvalues, subset values actually assigned cue phrasestranscripts corpora shown figure. Finally, lexical feature token (T)new study, represents actual cue phrase described.3.1.3 Training Datafinal input learning program training data, i.e., set examplesclass feature values specified. Consider following utterance, takenmultiple cue phrase corpus (Hirschberg & Litman, 1993):Example 1 [(Now) (now welcomed here)] it's time getbusiness conference.utterance contains two cue phrases, corresponding two instances \now".brackets parentheses illustrate intonational intermediate phrases, respectively,contain example cue phrases. Note single intonational phrase containsexamples, example uttered different intermediate phrase.interested feature length intonational phrase (P-L), two examples wouldrepresented training data follows:P-L Class9 discourse9 sententialfirst column indicates value assigned feature P-L, second columnindicates example classified. Thus, length intonational phrasecontaining first instance \now" 9 words, example cue phrase classifieddiscourse usage. interested feature composition intermediatephrase (I-C), two examples would instead represented training data follows:I-C Classdiscoursesententialis, intermediate phrase containing first instance \now" containscue phrase \now", intermediate phrase containing second instance \now"contains \now" well 7 lexical items cue phrases. Notevalue P-L examples, value I-C different.62fiCue Phrase Classification Using Machine Learning3.2 Machine Learning Outputsoutput machine learning programs classification models. C4.5 modelexpressed decision tree, consists either leaf node (a class assignment),decision node (a test feature, one branch subtree possible outcometest). following example illustrates non-graphical representation decisionnode testing feature n possible values:test1 : : ::::elseif testn:::Tests form \feature operator value"9 . \Feature" name feature (e.g.accent), \value" valid value feature (e.g., deaccented). featuressymbolic values (e.g., accent), one branch symbolic value, operator\=" used. features numeric values (e.g., length intonational phrase),two branches, comparing numeric value threshold value; operators\" \>" used. Given decision tree, cue phrase classified startingroot tree following appropriate branches leaf reached. Section 4shows example decision trees produced C4.5.cgrendel classification model expressed ordered set if-then rulesfollowing form:test1 ^ : : : ^ testk class\if" part rule conjunction tests values (varying) features,tests form \feature operator value." C4.5, \feature" namefeature, \value" valid value feature. Unlike C4.5, operators = =6used features symbolic values, used features numericvalues. \then" part rule specifies class assignment (e.g, discourse). Given setif-then rules, cue phrase classified using rule whose \if" part satisfied.two rules rules disagree class example, cgrendelapplies one two con ict resolution strategies (chosen user): choose first rule,choose rule accurate data. experiments reported usesecond strategy. rules, cgrendel assigns default class. Section 4shows example rules produced cgrendel.C4.5 cgrendel learn classification models using greedy search guided\information gain" metric. C4.5 uses divide conquer process: training examplesrecursively divided subsets (using tests discussed above), subsetsbelong single class. test chosen divide examples maximizesmetric called gain ratio (a local measure progress, considersubsequent tests); metric based information theory discussed detailQuinlan (1993). test selected, backtracking. Ideally, set chosentests result small final decision tree. cgrendel generates set if-then rulesusing method called separate conquer (to highlight similarity divideconquer):9. additional type test may invoked C4.5 option.63fiLitmanMany rule learning systems generate hypotheses using greedy strategyrules added rule set one one effort form small coverpositive examples; rule, turn created adding one conditionanother antecedent rule consistent negativedata. (Cohen, 1993)Although cgrendel claimed two advantages C4.5, advantagescome play experiments reported here. First, if-then rules appear easierpeople understand decision trees (Quinlan, 1993). However, cue phraseclassification task, decision trees produced C4.5 quite compact thus easilyunderstood. Furthermore, rule representation derived C4.5 decision trees,using program C4.5rules. Second, cgrendel allows users exploit prior knowledgelearning problem, constraining syntax rules learned. However,prior knowledge exploited cue phrase experiments. main reason usingC4.5 cgrendel increase reliability comparisons machinelearning manual results. particular, comparable results obtained usingC4.5 cgrendel, performance differences learned manuallyderived classification models less likely due specifics particular learningprogram, likely ect learned/manual distinction.3.3 Evaluationoutput machine learning experiment classification modellearned training data. learned models qualitatively evaluated examining linguistic content, comparing manually derived modelsFigure 1. learned models also quantitatively evaluated examining errorrates testing data comparing error rates errorrates shown Table 1. error rate classification model computed usingmodel predict classifications set examples classifications alreadyknown, comparing predicted known classifications. cue phrase domain,error rate computed summing number discourse examples misclassifiedsentential number sentential examples misclassified discourse, dividingtotal number examples.error rates learned classification models estimated using two methodologies. Train-and-test error rate estimation (Weiss & Kulikowski, 1991) \holds out" testset examples, seen training completed. is, modeldeveloped examining training examples; error model estimatedusing model classify test examples. evaluation method usedHirschberg Litman. resampling method cross-validation (Weiss & Kulikowski,1991) estimates error rate using multiple train-and-test experiments. example, 10fold cross-validation, instead dividing examples training test sets once, 10 runslearning program performed. total set examples randomly divided 10disjoint test sets; run thus uses 90% examples test set trainingremaining 10% testing. Note iteration cross-validation,learning process begins scratch; thus new classification model learnedtraining sample. estimated error rate obtained averaging error rate test64fiCue Phrase Classification Using Machine Learninging portion data 10 runs. method make sensehumans, computers truly ignore previous iterations. sample sizes hundreds(the classifiable subset multiple cue phrase sample classifiable non-conjunctsubset provide 878 495 examples, respectively) 10-fold cross-validation often providesbetter performance estimate hold-out method (Weiss & Kulikowski, 1991).major advantage cross-validation examples eventually used testing,almost examples used given training run.best performing learned models identified comparing error rateserror rates learned models manually derived error rates.determine whether fact error rate E1 lower another error rate E2also significant, statistical inference used. particular, confidence intervals twoerror rates computed, 95% confidence level. error rate estimated usingsingle error rate test set (i.e., train-and-test methodology), confidenceinterval computed using normal approximation binomial distribution (Freedmanet al., 1978). error rate estimated using average multiple errorrates (i.e., cross-validation methodology), confidence interval computed usingt-Table (Freedman et al., 1978). upper bound 95% confidence interval E1lower lower bound 95% confidence interval error rate E2,difference E1 E2 assumed significant.103.4 Experimental Conditionssection describes conditions used set machine learning experiments.experiments differ use training testing corpora, methods estimating errorrates, features classifications used. actual results experimentspresented Section 4.3.4.1 Four Sets Experimentslearning experiments conceptually divided four sets. experimentfirst set estimates error rate using train-and-test method, trainingtesting samples used Hirschberg Litman (1993) (the \now" datatwo subsets multiple cue phrase corpus, respectively). allows direct comparisonmanual machine learning approaches. However, prosodic experimentsconducted Hirschberg Litman (1993) replicated. textual training testingconditions replicated original training corpus (the first 17 minutesmultiple cue phrase corpus) (Litman & Hirschberg, 1990) subset of, rather disjointfrom, test corpus (the full 75 minutes multiple cue phrase corpus) (Hirschberg &Litman, 1993).contrast, experiment second set uses cross-validation estimate errorrate. Furthermore, training testing samples taken multiple cuephrase corpus. experiment uses 90% examples multiple cue phrasedata training, remaining 10% testing. Thus experiment secondset trains much larger amounts data (790 classifiable examples, 445 classifiable10. Thanks William Cohen suggesting methodology.65fiLitmanprosodyhl93featuresphrasinglengthpositionintonationalintermediatetextadjacencyorthographyprecedingsucceedingspeech-textP-LXXXXP-P I-L I-PX X XXX X XXXXXX XI-C A*X X XX X XXXC-PXXXXXXXXXXXC-S O-PXXXXO-P* O-SO-S* POSXXXXXXXXXXXXXXXXXXTable 3: Multiple feature sets components.non-conjuncts) experiment first set (100 \nows"). reliabilitytesting compromised due use cross-validation (Weiss & Kulikowski, 1991).experiment third set replicates experiment second set, exception learning program allowed distinguish cue phrases.done adding feature representing cue phrase (the feature token Figure 2)experiment second set. Since potential use lexical featurenoted used Hirschberg Litman (1993), experiments provide qualitatively new linguistic insights data. example, features mayused differently predict classifications different cue phrases sets cue phrases.Finally, experiment fourth set replicates experiment first, second,third set, exception 953 examples multiple cue phrase corpusconsidered. practice, learned cue phrase classification modellikely used classify cue phrases, even dicult human judgesclassify. experiments fourth set allow learning programs attemptlearn class unknown, addition classes discourse sentential.3.4.2 Feature Representations within Experiment SetsWithin four sets experiments, individual experiment representsdata using different subset available features. First, data represented14 single feature sets, corresponding prosodic textual feature shownFigure 2. experiments comparatively evaluate utility individual featureclassification. representations Example 1 shown illustrate datarepresented using single feature set P-L, using single feature set I-C.Second, data represented 13 multiple feature sets shown Table 3.sets contains linguistically motivated subset least 2 14 features.first 7 sets use prosodic features. Prosody considers prosodic featurescoded example cue phrase. Hl93features considers coded featuresalso used model shown Figure 1. Phrasing considers featuresintonational intermediate phrases containing example cue phrase (i.e., length66fiCue Phrase Classification Using Machine LearningExample 1 [() (now welcomed here)] it's time get business conference.P-P I-L I-P I-CA*C-P C-S O-P O-P* O-S O-S* POS Class111 H*+L complex fpar.ffadv. disc.281 H*H*fffffadv. sent.P-L99Figure 3: Representation Example 1 feature set speech-text.phrase, position example phrase, composition phrase). Length positionconsider one features, respect intonationalintermediate phrase. Conversely, intonational intermediate consider one typephrase, consider features. next 5 sets use textual features. Textconsiders textual features. Adjacency orthography consider single textualfeature, consider preceding succeeding immediate context. Precedingsucceeding consider contextual features relating orthography cue phrases,limit context. last set, speech-text, uses prosodic textual features.Figure 3 illustrates two example cue phrases Example 1 would representedusing speech-text. Consider feature values first example cue phrase. Sinceexample first lexical item intonational intermediate phrasescontain it, position phrases (P-P I-P) 1. Since intermediate phrasecontaining cue phrase contains lexical items, length (I-L) 1 wordcomposition (I-C) cue phrase. values A* indicateintonational phrase described sequence tones, complex pitch accent H*+Lassociated cue phrase. respect textual features, utterancetranscribed began new paragraph. Thus example cue phrasepreceded another cue phrase (C-P), preceded form orthography (O-PO-P*). Since example cue phrase immediately followed another instance\now" transcription, cue phrase succeeded another cue phrase (C-S)succeeded orthography (O-S O-S*). Finally, output partspeech tagging program run transcript corpus yields value adverbcue phrase's part speech (POS).first set experiments replicate prosodic experiments conductedHirschberg Litman (1993); cue phrases represented using subset feature sets consist prosodic features. second set experiments, examplesrepresented using 27 different feature sets (the 14 single feature sets 13multiple feature sets). third set experiments, examples represented using 27tokenized feature sets, constructed adding lexical feature token Figure 2 (thecue phrase described) 14 single 13 multiple feature setssecond set experiments. tokenized feature sets referred using namessingle multiple feature sets, concatenated \+". following illustratestwo cue phrases Example 1 would represented using P-L+:P-LClass9 discourse9 sentential67fiLitmanrepresentation similar P-L representation shown earlier, except secondcolumn indicates value assigned feature token (T).4. Resultssection examines results running two learning programs { C4.5 cgrendel { four sets cue phrase classification experiments described above. learnedclassification models compared classification models shown Figure 1,error rates learned classification models compared errorrates shown Table 1 error rates learned models.seen, results suggest machine learning useful automating generationlinguistically viable classification classification models, generating classification modelsperform lower error rates manually developed hypotheses, addingbody linguistic knowledge regarding cue phrases.4.1 Experiment Set 1: Replicating Hirschberg Litmanfirst group experiments replicate training, testing, evaluation conditionsused Hirschberg Litman (1993), order investigate well machine learningperforms comparison manual development cue phrase classification models.Figure 4 shows best performing prosodic classification models learned twomachine learning programs; top figure replicates manually derived prosodicmodel Figure 1 ease comparison. prosodic features usedrepresent 100 training examples \now" (i.e., example represented usingfeature set prosody Table 3)11, classification models learned shownmanually derived model top Figure 4. Note using learningprograms, decision tree also learned smaller feature sets phrasingposition used represent \now" data. bottom portion figure showsclassification models learned examples represented usingsingle prosodic feature position intonational phrase (P-P); model alsolearned examples represented using multiple feature set intonational.Recall C4.5 represents learned classification model decision tree.level tree (shown indentation) specifies test single feature, branchevery possible outcome test. branch either lead assignment class,another test. example, C4.5 classification model learned prosody classifiescue phrases using two features position intonational phrase (P-P) positionintermediate phrase (I-P). Note available features prosody (recallTable 3) used decision tree. tree initially branches based valuefeature position intonational phrase.12 first branch leads class assignmentdiscourse. second branch leads test feature position intermediate phrase.first branch test leads class assignment discourse, second branchleads sentential. C4.5 produces unsimplified pruned decision trees. goal11. Experiment Set 1, feature set prosody contain features P-L I-L. Recallphrasal length coded later multiple cue phrase study.12. ease comparison Figure 1, original symbolic representation feature value usedrather integer representation shown Figure 2.68fiCue Phrase Classification Using Machine LearningManually derived prosodic model (repeated Figure 1):composition intermediate phrase = aloneelseif composition intermediate phrase = :aloneposition intermediate phrase = firstaccent = deaccentedelseif accent = L*elseif accent = H*elseif accent = complexelseif position intermediate phrase = :firstdiscoursediscoursediscoursesententialsententialsentential(1)(2)(3)(4)(5)(6)(7)(8)Decision tree learned prosody, phrasing, position using C4.5:position intonational phrase = firstelseif position intonational phrase = :firstposition intermediate phrase = firstelseif position intermediate phrase = :firstdiscoursediscoursesententialRuleset learned prosody, phrasing, position using CGRENDEL:(position intonational phrase 6= first) ^ (position intermediate phrase 6= first)default discoursesententialDecision tree learned P-P intonational using C4.5:position intonational phrase = firstelseif position intonational phrase = :firstdiscoursesententialRuleset learned P-P intonational using CGRENDEL:position intonational phrase 6= firstdefault discoursesententialFigure 4: Example C4.5 cgrendel classification models learned different prosodicfeature representations \now" data.69fiLitmanModelClassifiable Cue Phrases (N=878) Classifiable Non-Conjuncts (N=495)P-P18.3 2.616.6 3.4prosody27.3 3.017.8 3.4phrasing27.3 3.017.8 3.4position27.3 3.017.8 3.4intonational18.3 2.616.6 3.4manual prosodic24.6 3.014.7 3.2Table 4: 95%-confidence intervals error rates (%) best performing cgrendelprosodic classification models, testing data. (Training data \now" corpus;testing data multiple cue phrase corpus.)pruning process take complex decision tree may also overfittedtraining data, produce tree comprehensible whose accuracycomprised (Quinlan, 1993). Since almost trees improved pruning (Quinlan,1993), simplified decision trees considered paper.contrast, cgrendel represents learned classification model set if-thenrules. rule specifies conjunction tests various features, resultsassignment class. example, cgrendel ruleset learned prosody classifiescue phrases using two features position intonational phrase (P-P) positionintermediate phrase (I-P) (the two features used C4.5 decision tree).values features first, if-then rule applies cue phrase classifiedsentential. value either feature first, default applies cue phraseclassified discourse.examination learned classification models Figure 4 showscomparable content portion manually derived model classifies cuephrases solely phrasal position (line (8)). particular, classification modelssay cue phrase initial phrasal position classify sentential.hand, manually derived model also assigns class sentential giveninitial phrasal position conjunction certain combinations phrasal compositionaccent; learned classification models instead classify cue phrase discoursecases. shown, discrimination manually obtained modelsignificantly improve performance compared learned classificationmodels, fact one case significantly degrades performance.error rates learned classification models \now" training datadeveloped follows: 6% models learned prosody, phrasingposition, 9% models learned P-P intonational. RecallSection 2 error rate manually developed prosodic model Figure 1training data 2%.Table 4 presents 95% confidence intervals error rates best performingcgrendel prosodic classification models. ease comparison, row labeled \manualprosodic" presents error rates manually developed prosodic model Figure 1two test sets, originally shown Table 1. table includescgrendel models whose performance matches exceeds manual performance.70fiCue Phrase Classification Using Machine LearningComparison error rates learned manually developed models suggestsmachine learning effective technique automating development cue phraseclassification models. particular, within test set, 95% confidence intervalerror rate classification models learned multiple feature sets prosody,phrasing, position overlaps confidence interval error ratemanual prosodic model. also true error rates P-P intonationalclassifiable non-conjunct test set. Thus, machine learning supports automatic construction variety cue phrase classification models achieve similar performancemanually constructed models.results P-P intonational classifiable cue phrase test setshown italics, suggest machine learning may also useful improvingperformance. Although simple classification model learned P-P intonational performs worse manually derived model training data, testedclassifiable cue phrases, learned model (with upper bound error rate 20.9%)outperforms manually developed model (with lower bound error rate 21.6%).suggests manually derived model might overfitted training data,i.e., prosodic feature set useful classifying \now" generalizecue phrases. noted above, use simplified learned classification models helpsguard overfitting learning approach. ease inducing classificationmodels many different sets features using machine learning supports generationevaluation wide variety hypotheses (e.g. P-P, high performingoptimal performing model training data).Note manual prosodic manual performs significantly better smaller testset (which contain cue phrases \and", \or", \but"). contrast,performance improvement P-P intonational smaller test set significant.also suggests manually derived model generalize well learnedmodels.Finally, feature sets shown Table 4, decision trees produced C4.5 performerror rates rulesets produced cgrendel, test sets. RecallFigure 4 C4.5 decision trees cgrendel rules fact semanticallyequivalent feature set. fact comparable results obtained using C4.5cgrendel adds extra degree reliability experiments. particular,duplication results suggests ability match perhaps even improveupon manual performance using machine learning due specifics eitherlearning program.4.2 Experiment Set 2: Using Different Training Setssecond group experiments evaluate utility training larger amountsdata. done using 10-fold cross-validation estimate error, run90% examples sample used training (and 10 runs,examples used testing). addition, experiments second set taketraining testing data multiple-cue phrase corpus, contrast previousset experiments training data taken \now" corpus.seen, changes improve results, learned classification models71fiLitmanModelClassifiable Cue Phrases (N=878) Classifiable Non-Conjuncts (N=495)P-L33.0 5.9(33.2 1.9)P-P16.1 3.518.8 4.2I-L25.5 3.7(25.6 2.8)I-P25.9 4.919.4 3.1I-C(36.5 5.4)(35.2 3.4)28.6 3.6(30.2 3.1)A*28.3 4.3(28.4 1.7)prosody15.5 2.617.2 3.1hl93features29.4 3.318.2 4.2phrasing16.1 3.419.6 3.9length26.1 3.8(27.4 3.4)position18.2 2.319.4 2.8intonational17.0 4.020.6 3.6intermediate21.9 2.319.4 5.7manual prosodic24.6 3.014.7 3.2Table 5: 95%-confidence intervals error rates (%) cgrendel prosodic classification models, testing data. (Training testing done multiplecue phrase corpus using cross-validation.)perform lower comparable error rates compared manually developedmodels.4.2.1 Prosodic ModelsTable 5 presents error rates classification models learned cgrendel,28 different prosodic experiments. (For Experiment Sets 2 3, C4.5 error ratespresented Appendix A.) numeric cell shows 95% confidence intervalerror rate, equal error percentage obtained cross-validation marginerror ( 2.26 standard errors, using t-Table). top portion table considersmodels learned single prosodic feature sets (Figure 2), middle portionconsiders models learned multiple feature sets (Table 3), last rowconsiders manually developed prosodic model. error rates shown italics indicateperformance learned classification model exceeds performancemanual model (given test set). error rates shown parentheses indicateopposite case - performance manual model exceeds performancelearned model. cases omitted Table 4.Experiment Set 1, comparison error rates learned manuallydeveloped models suggests machine learning effective techniqueautomating development cue phrase classification models, also improvingperformance. evaluated classifiable cue phrase test set, five learned modelsimproved performance compared manual model; models except I-Cperform least comparably manual model. Note Experiment Set 1, twolearned models outperformed manual model, five learned models performedleast comparably. ability use large training sets thus appears advantageautomated approach.72fiCue Phrase Classification Using Machine LearningManually derived prosodic model (repeated Figure 1):composition intermediate phrase = aloneelseif composition intermediate phrase = :aloneposition intermediate phrase = firstaccent = deaccentedelseif accent = L*elseif accent = H*elseif accent = complexelseif position intermediate phrase = :firstdiscoursediscoursediscoursesententialsententialsentential(1)(2)(3)(4)(5)(6)(7)(8)Decision tree learned P-P using C4.5:position intonational phrase 1elseif position intonational phrase > 1discoursesententialRuleset learned P-P using CGRENDEL:position intonational phrase 2default discoursesententialDecision tree learned prosody using C4.5:position intonational phrase 1position intermediate phrase 1elseif position intermediate phrase > 1elseif position intonational phrase > 1length intermediate phrase 1elseif length intermediate phrase > 1discoursesententialdiscoursesententialRuleset learned prosody using CGRENDEL:(position intonational phrase 2) ^ (length intermediate phrase 2)(7 position intonational phrase 4) ^ (length intonational phrase 10)(length intermediate phrase 2) ^ (length intonational phrase 7) ^ (accent = H*)(length intermediate phrase 2) ^ (length intonational phrase 9) ^ (accent = H*+L)(length intermediate phrase 2) ^ (accent = deaccented)(length intermediate phrase 8) ^ (length intonational phrase 9) ^ (accent = L*)sententialsententialsententialsententialsententialsententialdefault discourseFigure 5: Example C4.5 cgrendel classification models learned different prosodicfeature representations classifiable cue phrases multiple cue phrasecorpus.tested classifiable non-conjuncts (where error rate manuallyderived model decreases), machine learning useful automating improvingperformance. might ect fact manually derived theories already achieveoptimal performance respect examined features less noisy subcorpus,and/or automatically derived theory subcorpus based smallertraining set used larger subcorpus.examination best performing learned classification models showsquite comparable content relevant portions prosodic model Figure 1,often contain linguistic insights. Consider classification model learnedsingle feature position intonational phrase (P-P), shown near top Figure 5.73fiLitmanlearned classification models say cue phrase initialposition intonational phrase, classify sentential; otherwise classify discourse.Note correspondence line (8) manually derived prosodic model. Also noteclassification models comparable13 P-P classification models learnedExperiment Set 1 (shown Figure 4), despite differences training data.fact single prosodic feature position intonational phrase (P-P) classify cuephrases least well complicated manual multiple feature learned modelsnew result learning experiments.Figure 5 also illustrates complex classification models learned using prosody,largest prosodic feature set. C4.5 model similar lines (1) (8) manualmodel. (The length value 1 equivalent composition value alone.) rulesetinduced prosody cgrendel, first 2 if-then rules correlate sentential status(among things) non-initial position14 , second 2 rules H* H*+Laccents; rules similar lines (6)-(8) Figure 1. However, last 2 if-then rulesruleset also correlate accent L* sentential status phrasecertain length, lines (4) (5) Figure 1 provide different interpretationtake length account. Recall length coded Hirschberg Litmantest data. Length thus never used generate revise prosodic model.utility length new result experiment set.Although shown, models learned phrasing, position, intonational alsooutperform manual model. seen Table 3, models correspondfeature sets supersets P-P subsets prosody.4.2.2 Textual ModelsTable 6 presents error rates classification models learned cgrendel,24 different textual experiments. Unlike experiments involving prosodic feature sets,none learned textual models perform significantly better manually derivedmodel. However, results suggest machine learning still effective techniqueautomating development cue phrase classification models. particular, fivelearned models (O-P, O-P*, text, orthography, preceding) perform comparablymanually derived model, test sets. Note five models learnedfive textual feature sets include either feature O-P O-P* (recall Figure 2Table 3). models perform significantly better remaining learnedtextual models.Figure 6 shows best performing learned textual models. Note similaritymanually derived model. prosodic results, best performing single featuremodels perform comparably learned multiple features. fact, cgrendel,rulesets learned multiple feature sets orthography preceding identicalrulesets learned single features O-P O-P*, even though featuresavailable use. (The corresponding error rates Table 6 identical due13. different feature values two figures ect fact phrasal position represented\now" corpus using symbolic values (as Figure 1), multiple cue phrase corpus usingintegers (as Figure 2).14. Tests \feature x" \feature y" merged figure simplicity, e.g., \y featurex."74fiCue Phrase Classification Using Machine LearningModelClassifiable Cue Phrases (N=878) Classifiable Non-Conjuncts (N=495)C-P(40.7 6.2)(40.2 4.5)C-S(41.3 5.9)(39.8 4.2)O-P20.6 5.717.6 3.3O-P*18.4 3.717.2 2.4O-S(34.1 6.3)(30.2 1.8)O-S*(35.2 5.5)(32.6 3.0)POS(37.7 4.1)(38.2 4.6)text18.8 4.219.0 3.6adjacency(39.7 5.7)(40.2 3.4)orthography18.9 3.418.8 3.0preceding18.8 3.817.6 3.2succeeding(33.9 6.0)(30.0 2.7)manual textual19.9 2.816.1 3.4Table 6: 95%-confidence intervals error rates (%) cgrendel textual classification models, testing data. (Training testing done multiplecue phrase corpus using cross-validation.)Manually derived textual model (repeated Figure 1):preceding orthography = true discourseelseif preceding orthography = false sententialDecision tree learned O-P*, text, orthography, preceding using C4.5:preceding orthography* = NAelseif preceding orthography* = falseelseif preceding orthography* = truediscoursesententialdiscourseRuleset learned O-P, O-P*, orthography, preceding using CGRENDEL:preceding orthography* = falsedefault discoursesententialRuleset learned text using CGRENDEL:preceding orthography* = falsepart-of-speech = articledefault discoursesententialsententialFigure 6: Example C4.5 cgrendel classification models learned different textualfeature representations classifiable cue phrases multiple cue phrasecorpus.estimation using cross-validation.) cgrendel model text also incorporates featurepart-of-speech. C4.5, models text, orthography preceding identical O-P*.4.2.3 Prosodic/Textual ModelsTable 7 presents error rates classification models learned cgrendeldata represented using speech-text, complete set prosodic textual features (recall75fiLitmanModelClassifiable Cue Phrases (N=878) Classifiable Non-Conjuncts (N=495)speech-text15.9 3.214.6 4.6manual prosodic24.6 3.014.7 3.2manual textual19.9 2.816.1 3.4Table 7: 95%-confidence intervals error rates (%) cgrendel prosodic/textualclassification model, testing data. (Training testing done multiple cue phrase corpus using cross-validation.)Table 3). Since Hirschberg Litman develop similar classification modelcombined types features, comparison last two rows show error ratesseparate prosodic textual models. learned model comparedmanual prosodic model, using classifiable cue phrases testing, learning resultsignificant performance improvement. consistent results discussed above,several learned prosodic models performed better manually derived prosodicmodel test set. performance speech-text significantly better worseperformance either best prosodic textual learned models (Tables 5 6,respectively).Figure 7 shows C4.5 cgrendel hypotheses learned speech-text. C4.5model classifies cue phrases using prosodic textual features performed bestisolation (position intonational phrase preceding orthography*, discussed above),conjunction additional feature length intermediate phrase (which also appearsmodel learned prosody Figure 5). Like line (9) manually derivedtextual model, learned model associates presence preceding orthographyclass discourse. Unlike line (10), however, cue phrases preceded orthographymay classified either discourse sentential, based prosodic feature values (whichavailable use textual model). branch learned decision treecorresponding last three lines also similar lines (1), (2), (8) manuallyderived prosodic model. (Recall length value 1 equivalent composition valuealone.)cgrendel model uses similar features used C4.5 well prosodicfeature accent (also used prosody Figure 5), textual features part-of-speech(also used text Figure 6) preceding cue phrase. Like C4.5, unlike line (10)manually derived textual model, cgrendel model classifies cue phrases lackingpreceding orthography sentential conjunction certain feature values.Unlike line (9) manual model, learned model also classifies cue phrasespreceding orthography sentential (if orthography comma, feature valuespresent). Finally, third fifth learned rules elaborate line (6) additionalprosodic well textual features, first last learned rules elaborate line (8).4.3 Experiment Set 3: Adding Feature tokenexperiment third group replicates experiment second group,exception data representation also includes lexical feature token76fiCue Phrase Classification Using Machine LearningManually derived prosodic model (repeated Figure 1):composition intermediate phrase = aloneelseif composition intermediate phrase = :aloneposition intermediate phrase = firstaccent = deaccentedelseif accent = L*elseif accent = H*elseif accent = complexelseif position intermediate phrase = :firstdiscoursediscoursediscoursesententialsententialsententialManually derived textual model (repeated Figure 1):preceding orthography = trueelseif preceding orthography = false(1)(2)(3)(4)(5)(6)(7)(8)(9)(10)discoursesententialDecision tree learned speech-text using C4.5:position intonational phrase 1preceding orthography* = NAelseif preceding orthography* = trueelseif preceding orthography* = falselength intermediate phrase > 12elseif length intermediate phrase 12length intermediate phrase 1elseif length intermediate phrase > 1elseif position intonational phrase > 1length intermediate phrase 1elseif length intermediate phrase > 1discoursediscoursediscoursediscoursesententialdiscoursesententialRuleset learned speech-text using CGRENDEL:(preceding orthography = false) ^ (4 position intonational phrase 6) ^(preceding orthography = false) ^ (length intermediate phrase 2)(preceding orthography = false) ^ (length intonational phrase 7) ^ (preceding cue phrase = NA)^ (accent = H*)(preceding orthography = comma) ^ (length intermediate phrase 5) ^ (length intonational phrase 17)^ (part-of-speech = adverb)(preceding orthography = comma) ^ (3 length intonational phrase 8) ^ (accent = H*)(preceding orthography = comma) ^ (3 length intermediate phrase 8)^ (length intonational phrase 15)(position intonational phrase 2) ^ (length intermediate phrase 2)^ (preceding cue phrase = NA)sententialsententialsententialsententialsententialsententialdefault discoursesententialFigure 7: C4.5 cgrendel classification models learned prosodic/textual feature representation classifiable cue phrases multiple cue phrase corpus.77fiLitmanModelClassifiable Cue Phrases (N=878) Classifiable Non-Conjuncts (N=495)P-L+21.8 4.617.4 2.7P-P+16.7 2.814.8 5.0I-L+20.3 3.416.0 3.3I-P+25.1 4.117.0 3.6I-C+27.0 3.618.4 3.4A+19.8 3.212.8 3.1A*+18.6 3.815.4 2.8prosody+16.7 2.915.8 3.1hl93features+24.0 4.517.4 4.3phrasing+14.5 3.312.6 3.3length+18.6 2.016.2 3.5position+15.6 3.313.0 3.9intonational+15.1 2.216.6 4.6intermediate+18.5 3.716.6 4.0manual prosodic24.6 3.014.7 3.2Table 8: 95%-confidence intervals error rates (%) cgrendel prosodic, tokenized classification models, testing data. (Training testing donemultiple cue phrase corpus using cross-validation.)Figure 2. experiments investigate performance changes classification models allowed treat different cue phrases differently. seen, learningtokenized feature sets often improves performance learned classificationmodels. addition, classification models contain new linguistic information regarding particular tokens (e.g., \so").4.3.1 Prosodic ModelsTable 8 presents error learned classification models test setsmultiple cue phrase corpus, tokenized prosodic feature sets. Again, errorrates italics indicate performance learned classification model meaningfullyexceeds performance \manual prosodic" model (which consider featuretoken).One way improvement obtained adding feature token seencomparing performance learned manually derived models. Table 8, sixcgrendel classification models lower (italicized) error rates manual model.Table 5, five models italicized. Thus, adding feature token resultsadditional learned model - length+ - outperforming manually derived model.Conversely, Table 8, learned models perform significantly worse manuallyderived manual. contrast, Table 5, several non-tokenized models perform worsemanual model (I-C larger test set, P-L, I-L, I-C, A, A*, lengthnon-conjunct test set).improvement obtained adding feature token also seen comparingperformance tokenized (Table 8) non-tokenized (Table 5) versionsmodel other. convenience, cases tokenization yields improvementhighlighted Table 9. table shows error rate tokenized versionsfeature sets significantly lower error non-tokenized versions, P-L, I-C,78fiCue Phrase Classification Using Machine LearningModelP-LI-LI-CA*lengthClassifiable Cue Phrases (N=878)Non-Tokenized Tokenized (+)33.0 5.921.8 4.636.5 5.427.0 3.628.6 3.619.8 3.228.3 4.318.6 3.826.1 3.818.6 2.0Classifiable Non-Conjuncts (N=495)Non-TokenizedTokenized (+)33.2 1.917.4 2.725.6 2.816.0 3.335.2 3.418.4 3.430.2 3.112.8 3.128.4 1.715.4 2.827.4 3.416.2 3.5Table 9: Cases adding feature token improves performance prosodicmodel.A, A*, length test sets, I-L non-conjunct test set. Noteoverlap feature sets Table 9 discussed previous paragraph.Figure 8 shows several tokenized single feature prosodic classification models. firstcgrendel model figure shows ruleset learned P-L+, reduces33.2% 1.9% error rate P-L (length intonational phrase) 17.4% 2.7%,trained tested using classifiable non-conjuncts (Table 9). Note first ruleuses prosodic feature (like rules Experiment Sets 1 2), factsimilar line (1) manual model. (Recall length value 1 equivalentcomposition value alone.) However, unlike rules previous experiment sets,next 5 rules use prosodic feature lexical feature token. Also unlikerules previous experiment sets, remaining rules classify cue phrases usingfeature token. Examination learned rulesets Figures 8 9 showscue phrases often appear last type rule. cue phrases,example, \finally", \however", \ok", fact always discourse usages multiplecue phrase corpus. cue phrases, classifying cue phrases using tokencorresponds classifying cue phrases using default class (the frequent typeusage multiple cue phrase corpus). Recall use non-tokenized default classmodel Table 1.second example shows ruleset learned I-C+ (composition intermediatephrase+). first rule corresponds line (1) manually derived model.15next six rules classify particular cue phrases discourse, independently value I-C.Note although model cue phrase \say" classified using token,previous model sophisticated strategy classifying \say" could found.third example shows cgrendel ruleset learned A+ (accent+). firstrule corresponds line (5) manually derived prosodic model. contrast line(4), however, cgrendel uses deaccenting predict discourse tokens \say"\so." token \finally", \however", \now" \ok", discourse assigned (foraccents). deaccented cases, sentential assigned (using default). Similarly,contrast line (7), complex accent L+H* predicts discourse cue phrases\further" \indeed" (and also \finally", \however", \now" \ok"), sententialotherwise.15. discussed relation Figure 2, I-C values cue phrases multiple cue phrasecorpus replace value alone \now" corpus.79fiLitmanManually derived prosodic model (repeated Figure 1):composition intermediate phrase = aloneelseif composition intermediate phrase = :aloneposition intermediate phrase = firstaccent = deaccentedelseif accent = L*elseif accent = H*elseif accent = complexelseif position intermediate phrase = :first(1)(2)(3)(4)(5)(6)(7)(8)discoursediscoursediscoursesententialsententialsententialRuleset learned P-L+ using CGRENDEL:length intonational phrase 1(7 length intonational phrase 11) ^ (token = although)(9 length intonational phrase 16) ^ (token = indeed)(length intonational phrase 20) ^ (token = say)(11 length intonational phrase 13) ^ (token = then)(length intonational phrase = 5) ^ (token = well)token = finallytoken =token = howevertoken =token = oktoken = otherwisetoken =discoursediscoursediscoursediscoursediscoursediscoursediscoursediscoursediscoursediscoursediscoursediscoursediscoursedefault sententialRuleset learned I-C+ using CGRENDEL:composition intermediate phrase =token = finallytoken = howevertoken =token = oktoken = saytoken =discoursediscoursediscoursediscoursediscoursediscoursediscoursedefault sententialRuleset learned A+ using CGRENDEL:accent = L*(accent = deaccented) ^ (token = say)(accent = deaccented) ^ (token = so)(accent = L+H*) ^ (token = further)(accent = L+H*) ^ (token = indeed)token = finallytoken = howevertoken =token = okdiscoursediscoursediscoursediscoursediscoursediscoursediscoursediscoursediscoursedefault sententialFigure 8: Example cgrendel classification models learned different tokenized,prosodic feature representations classifiable non-conjuncts multiplecue phrase corpus.80fiCue Phrase Classification Using Machine LearningModelClassifiable Cue Phrases (N=878) Classifiable Non-Conjuncts (N=495)C-P+(28.2 3.9)16.4 4.6C-S+(28.9 3.6)17.2 4.0O-P+17.5 4.410.0 3.1O-P*+17.7 2.912.2 2.9O-S+26.9 4.718.4 3.9O-S*+(27.3 3.5)16.0 3.2POS+(27.4 3.6)17.2 3.9text+18.4 3.012.0 2.6adjacency+(28.6 4.1)15.2 3.1orthography+17.6 3.013.6 3.9preceding+17.0 4.113.6 2.6succeeding+25.6 3.918.0 4.5manual textual19.9 2.816.1 3.4Table 10: 95%-confidence intervals error rates (%) cgrendel textual, tokenized classification models, testing data. (Training testing donemultiple cue phrase corpus using cross-validation.)summarize, new prosodic results Experiment Set 3 features relatinglength, composition, accent, useful (in isolation) predicting classification cue phrases, fact quite useful predicting class individual cuephrases subsets cue phrases. (Recall result Experiment Sets 1 2without token, prosodic feature position intonational phrase usefulisolation.)4.3.2 Textual ModelsTable 10 presents error learned classification models test setsmultiple cue phrase corpus, tokenized textual feature sets. Experiment Set 2 (Table 6), none cgrendel classification models lower (italicized)error rates manual model. However, adding feature token improveperformance many learned rulesets, following models (unlikenon-tokenized counterparts) longer outperformed manual model: O-S+succeeding+ larger test set, C-P+, C-S+, O-S+, O-S*+, POS+, adjacency+,succeeding+ non-conjunct test set.improvement obtained adding feature token also seen comparingperformance tokenized (Table 10) non-tokenized (Table 6) versionsmodel other, shown Table 11. table shows error ratestokenized versions feature sets significantly lower error nontokenized versions, C-P, C-S, POS, adjacency test sets, O-P, O-S,O-S*, text, succeeding non-conjunct test set. Note overlap featuresets Table 11 discussed previous paragraph.Figure 9 shows several tokenized single textual feature classification models. firstcgrendel model shows ruleset learned C-P+ (preceding cue phrase+),reduces 40.2% 4.5% error rate C-P 16.4% 4.6% trained tested usingclassifiable non-conjuncts (Table 11). ruleset correlates preceding cue phrasesdiscourse usages \indeed", omitted transcriptions \further", \now", \so"81fiLitmanManually derived textual model (repeated Figure 1):preceding orthography = trueelseif preceding orthography = falsediscoursesententialRuleset learned C-P+ using CGRENDEL:(preceding cue phrase = true) ^ (token = indeed)(preceding cue phrase = NA) ^ (token = further)(preceding cue phrase = NA) ^ (token = now)(preceding cue phrase = NA) ^ (token = so)token = althoughtoken = finallytoken = howevertoken = oktoken = saytoken = similarlydiscoursediscoursediscoursediscoursediscoursediscoursediscoursediscoursediscoursedefault sententialdiscourseRuleset learned O-P+ using CGRENDEL:preceding orthography = false(preceding orthography = comma) ^ (token = then)sententialdefault discoursesententialRuleset learned O-S+ using CGRENDEL:succeeding orthography = comma(succeeding orthography = false) ^ (token = so)succeeding orthography = NAtoken = althoughtoken = finallytoken =token = oktoken = saydiscoursediscoursediscoursediscoursediscoursediscoursediscoursediscoursedefault sententialRuleset learned POS+ using CGRENDEL:(part-of-speech = adverb) ^ (token = finally)(part-of-speech = singular proper noun) ^ (token = further)(part-of-speech = adverb) ^ (token = however)(part-of-speech = adverb) ^ (token = indeed)(part-of-speech = subordinating conjunction) ^ (token = so)token = althoughtoken =token = saytoken = okdiscoursediscoursediscoursediscoursediscoursediscoursediscoursediscoursediscoursedefault sententialFigure 9: Example cgrendel classification models learned different tokenized, textualfeature representations classifiable non-conjuncts multiple cue phrasecorpus.82fiCue Phrase Classification Using Machine LearningModelC-PC-SO-PO-SO-S*POStextadjacencysucceedingClassifiable Cue Phrases (N=878)Non-Tokenized Tokenized (+)40.7 6.228.2 3.941.3 5.928.9 3.637.7 4.127.4 3.639.7 5.728.6 4.1-Classifiable Non-Conjuncts (N=495)Non-TokenizedTokenized (+)40.2 4.516.4 4.639.8 4.217.2 4.017.6 3.310.0 3.130.2 1.818.4 3.932.6 3.016.0 3.238.2 4.617.2 3.919.0 3.612.0 2.640.2 3.415.2 3.130.0 2.718.0 4.5Table 11: Cases adding feature token improves performance textualmodel.discourse usages. classifications rest cue phrases predicted usingfeature token.second example shows cgrendel ruleset learned O-P+ (preceding orthography+). ruleset correlates preceding orthography sentential usages cuephrases (as manually derived model learned models ExperimentSet 2). Unlike models, however, cue phrase \then" also classified sentential,even preceded orthography (namely, comma).third example shows cgrendel ruleset learned O-S+ (succeeding orthography). ruleset correlates presence succeeding commas discourse usagescue phrases, except cue phrase \so", classified discourse usage withoutsucceeding orthography. model also correlates cue phrases omittedtranscript discourse usages. classifications rest cue phrasespredicted using feature token.last example shows cgrendel ruleset learned POS+ (part-of-speech+).ruleset classifies certain cue phrases discourse usages depending part-ofspeech token, well independently part-of-speech.Finally, Figure 10 shows classification model learned text+, largest tokenized textual feature set. Note three four features used tokenized, singletextual feature models Figure 9 incorporated tokenized, multiple textualfeature model.summarize, new textual results Experiment Set 3 features based adjacent cue phrases, succeeding orthography, part-of-speech, useful (in isolation)predicting classification cue phrases, fact quite useful conjunctionfeature token. (Recall result Experiment Set 2 without token,textual features preceding orthography preceding orthography* usefulisolation.)4.3.3 Prosodic/Textual ModelsTable 12 presents error rates classification models learned cgrendeldata represented using speech-text+, complete set prosodic textual83fiLitmanRuleset learned text+ using CGRENDEL:preceding orthography = false(preceding orthography = comma) ^ (token = although)(preceding orthography = comma) ^ (token = no)(preceding orthography = comma) ^ (token = then)(succeeding orthography = false) ^ (preceding cue phrase = NA) ^ (token = similarly)token = actuallytoken = firsttoken = sincetoken = yessententialsententialsententialsententialsententialsententialsententialsententialsententialdefault discourseFigure 10: cgrendel classification model learned tokenized, multiple textual featurerepresentation classifiable non-conjuncts multiple cue phrase corpus.ModelClassifiable Cue Phrases (N=878) Classifiable Non-Conjuncts (N=495)speech-text+16.9 3.416.6 4.1manual prosodic24.6 3.014.7 3.2manual textual19.9 2.816.1 3.4Table 12: 95%-confidence intervals error rates (%) cgrendelprosodic/textual, tokenized classification models, testing data. (Trainingtesting done multiple cue phrase corpus using cross-validation.)features. Experiment Set 2, performance speech-text+ betterperformance either best learned (tokenized) prosodic textual models (Tables 810, respectively).Comparison Tables 7 12 also shows feature set speech-text, tokenization improve performance. contrast prosodic textual featuresets, tokenization improves performance many learned models (namelyshown Tables 9 11).4.4 Experiment Set 4: Adding Classification ambiguouspractice, cue phrase classification model classify cue phrasesrecording text, \classifiable." experiments fourth setreplicate experiments Experiment Sets 1, 2, 3, exception 953 cuephrases multiple cue phrase corpus used. means cue phrasesclassified discourse, sentential, well unknown (defined Table 2). ExperimentSet 4 investigates whether machine learning explicitly recognize new class unknown.Recall studies Hirschberg Litman attempt predict classunknown, occur \now" training corpus. Thus Experiment Set 1,class unknown similarly learned training data. However, unknownexamples added testing data Experiment Set 1. Obviously performancedegrade, models must incorrectly classify unknown example either discourse84fiCue Phrase Classification Using Machine Learningsentential. example, tested full corpus 953 example cue phrases,95% confidence intervals error rates P-P intonational 24.8% 2.8%;recall tested subset corpus corresponding 878 classifiable cuephrases, error 18.3% 2.6% (Table 4).Unfortunately, results rerunning Experiment Sets 2 3 show promisingresults classifying cue phrases unknown. Despite presence 75 examplesunknown, learned models still classify unknown cue phrases discoursesentential. example, cgrendel used learning, 2 possible 27 nontokenized models16 (phrasing speech-text) contain rules predict class unknown.Furthermore, models contains one rule unknown,rules applies 2 possible 953 examples! Similarly, four possible 27tokenized models (length+, phrasing+, prosody+, speech-text+) contain least one ruleclass unknown. compared training testing using classifiablecue phrases corpus, error rate full corpus typically (but always)significantly higher. best performing model Experiment Set 4 speech-text+,22.4% 4.1% error rate (95% confidence interval).sum, Experiment Set 4 addressed problem previously unexploredliterature - ability develop classification models predict discoursesentential usages cue phrases, also usages human judges find dicult classify.Unfortunately, results experiments suggest learning classify cuephrases unknown dicult problem. Perhaps training data (recall75 examples unknown) additional features better results couldobtained.4.5 Discussionexperimental results suggest machine learning useful tool automatinggeneration classification models improving upon manually derived results.Experiment Sets 1 2 performance many learned classification modelscomparable performance manually derived models. addition, testedclassifiable cue phrases, several learned prosodic classification models (as welllearned prosodic/textual model) outperform Hirschberg Litman's manually derivedprosodic model. Experiment Set 3 shows learning tokenized feature sets evenimproves performance, especially non-conjunct test set. tokenizednon-tokenized learned models perform least well manually derived models.Many tokenized learned models also outperform non-tokenized counterparts.textual classification models outperform better prosodic classification models, advantage textual feature values obtained directlytranscript, determining values prosodic features requires manual analysis. (See, however, Section 5 discussion feasibility automating prosodicanalysis. addition, transcript may always available.) hand, almosthigh performing textual models dependent orthography. manual tran16. Recall Experiment Sets 2 3 constructed 14 prosodic models, 12 textual models, 1prosodic/textual model.85fiLitmanscriptions prosodic features shown reliable across coders (Pitrelli et al.,1994), corresponding results reliability orthography.Examination best performing learned models shows often comparable content relevant portions manually derived models. Examinationmodels also provides new contributions cue phrase literature. example,Experiment Sets 1 2 demonstrate utility classifying cue phrases basedsingle prosodic feature - phrasal position.17 Experiment Set 2 also demonstrates utilityprosodic feature length textual feature preceding cue phrase classifyingcue phrases - conjunction prosodic textual features. Finally, resultsExperiment Set 3 demonstrate even though many features usefulclassifying cue phrases, may nonetheless informative tokenizedform. true prosodic features based phrasal length, phrasal composition,accent, textual features based adjacent cue phrases, succeeding position,part-of-speech.185. Utilityresults machine learning experiments quite promising, comparedmanually derived classification models already literature, learned classificationmodels often perform comparable higher accuracy. Thus, machine learningappears effective technique automating generation classification models.However, given experiments reported still rely manually created trainingdata, discussion practical utility results order.Even given manually created training data, results established HirschbergLitman (1993) - obtained using even less automation experiments paper- already practical import. particular, manually derived cue phraseclassification models used improve naturalness synthetic speech text-tospeech system (Hirschberg, 1990). Using text-based model, text-to-speech systemclassifies cue phrase text synthesized either discourse sententialusage. Using prosodic model, system conveys usage synthesizingcue phrase appropriate type intonation. speech synthesis couldimproved (and output made varied) using one higher performinglearned prosodic models presented paper.results paper could also directly applied area text generation.example, Moser Moore (1995) concerned implementation cue selection placement strategies natural language generation systems. systems couldenhanced using text-based models cue phrase classification (particularly17. empirical studies performed Holte (1993) show many datasets, accuracysingle feature rules decision trees often competitive accuracy complex learnedmodels.18. contrast, prosodic features phrasal composition accent previously known usefulconjunction phrasal position (Hirschberg & Litman, 1993), part-ofspeech known useful conjunction orthography (Hirschberg & Litman, 1993).Length, adjacent cue phrases, succeeding position used either manually derivedmodels (Hirschberg & Litman, 1993) (although length adjacent cue phrases shown useful- conjunction prosodic textual features - Experiment Set 2).86fiCue Phrase Classification Using Machine Learningtokenized models) additionally specify preceding succeeding orthography, part-ofspeech, adjacent cue phrases appropriate discourse usages.Finally, results paper could fully automated, could also usednatural language understanding systems, enhancing ability recognize discoursestructure. results obtained Litman Passonneau (1995) PassonneauLitman (in press) suggest algorithms use cue phrases (in conjunctionfeatures) predict discourse structure outperform algorithms take cue phrasesaccount. particular, Litman Passonneau develop several algorithms explorefeatures cue phrases, prosody referential noun phrases best combinedpredict discourse structure. Quantitative evaluations results show bestperforming algorithms incorporate use discourse usages cue phrases (where cuephrases classified discourse using phrasal position). discussed Section 1,discourse structure useful performing tasks anaphora resolution planrecognition. Recent work also shown discourse structure recognized,used improve retrieval text (Hearst, 1994) speech (Sti eman, 1995).Although prosodic features manually labeled Hirschberg Litman,recent results suggesting least aspects prosody automaticallylabeled directly speech. example, Wightman Ostendorf (1994) developalgorithm able automatically recognize prosodic phrasing 85-86% accuracy(measured comparing automatically derived labels hand-marked labels); accuracy slightly less human-human accuracy. Recall experimental resultspaper show models learned single feature position intonationalphrase - could automatically computed given automatic prosodic phrasing algorithm - perform least well learned prosodic model. Similarly,accenting versus deaccenting automatically labeled 88% accuracy (Wightman& Ostendorf, 1994), sophisticated labeling scheme distinguishesfour types accent classes (and somewhat similar prosodic feature accent* usedpaper) labeled 85% accuracy (Ostendorf & Ross, press). RecallExperiment Set 3 tokenized models learned using accent* also classify cue phrasesgood results.Although textual features automatically extracted transcript, transcript manually created. Many natural language understanding systemsdeal speech all, thus begin textual representations. spoken language systems transcription process typically automated using speech recognitionsystem (although introduces sources error).6. Related Workpaper compared results obtained using machine learning previouslyexisting manually-obtained results, also used machine learning tool developing theories given new linguistic data (as models resulting Experiment Set 3,new feature token considered). Siegel (1994) similarly uses machine learning(in particular, genetic learning algorithm) classify cue phrases previously unstudied set textual features: feature corresponding token, well textual featurescontaining lexical orthographic item immediately left 4 positions87fiLitmanright example. Siegel's input consists one judge's non-ambiguous examplestaken data used Hirschberg Litman (1993) well additional examples;output form decision trees. Siegel reports 21% estimated error rate,half corpus used training half testing. Siegel McKeown (1994) alsopropose method developing linguistically viable rulesets, based partitioningtraining data produced induction.Machine learning also used several areas discourse analysis. example, learning used develop rules structuring discourse multi-utterancesegments. Grosz Hirschberg (1992) use classification regression tree systemcart (Brieman et al., 1984) construct decision trees classifying aspects discoursestructure intonational feature values. Litman Passonneau (1995) PassonneauLitman (in press) use system C4.5 construct decision trees classifying utterances discourse segment boundaries, using features relating prosody, referential nounphrases, cue phrases. addition, C4.5 used develop anaphora resolutionalgorithms, training corpora tagged appropriate discourse information (Aone &Bennett, 1995). Similarly, McCarthy Lehnert (1995) use C4.5 learn decision treesclassify pairs phrases coreferent not. Soderland Lehnert (1994) usemachine learning program ID3 (a predecessor C4.5) support corpus-driven knowledgeacquisition information extraction. Machine learning often results algorithmsoutperform manually derived alternatives (Litman & Passonneau, 1995; Passonneau & Litman, press; Aone & Bennett, 1995; McCarthy & Lehnert, 1995), although statisticalinference always used evaluate significance performance differences.Finally, machine learning also used great success many areasnatural language processing. discussed above, work researchers discourseanalysis concentrated direct application existing symbolic learning approaches(e.g., C4.5), comparison learning manual methods. researchersareas natural language processing also addressed issues,addition applied much wider variety learning approaches, concerneddevelopment learning methods particularly designed language processing.recent survey learning natural language (Wermter, Riloff, & Scheler, 1996) illustratestype learning approaches used modified (in particular,symbolic, connectionist, statistical, hybrid approaches), well scopeproblems proved amenable use learning techniques (e.g., grammaticalinference, syntactic disambiguation, word sense disambiguation).7. Conclusionpaper demonstrated utility machine learning techniques cue phraseclassification. Machine learning supports automatic generation linguistically viableclassification models. compared manually derived models already literature,many learned models contain new linguistic insights perform leasthigh (if higher) accuracy. addition, ability automatically construct classification models makes easier comparatively analyze utility alternative featurerepresentations data. Finally, ease retraining makes learning approachscalable extensible manual methods.88fiCue Phrase Classification Using Machine Learningfirst set experiments presented used machine learning programscgrendel (Cohen, 1992, 1993) C4.5 (Quinlan, 1993) induce classification modelspreclassified cue phrases features used training dataHirschberg Litman (1993). results evaluated testing datamethodology used Hirschberg Litman (1993). second group experimentsused method cross-validation train test testing data usedHirschberg Litman (1993). third set experiments induced classification modelsusing new feature token. fourth set experiments induced classification modelsusing new classification unknown.experimental results indicate several learned classification models (includingextremely simple one feature models) significantly lower error rates modelsdeveloped Hirschberg Litman (1993). One possible explanation handbuilt classification models derived using small training sets; new data becameavailable, data used testing updating original models. contrast, machine learning conjunction cross-validation (Experiment Set 2) supportedbuilding classification models using much larger amount data training.Even learned models derived using small training set (ExperimentSet 1), results showed learning approach helped guard overfittingtraining data.prosodic classification model developed Hirschberg Litman demonstrated utility combining phrasal position phrasal composition accent,best performing prosodic models Experiment Sets 1 2 demonstrated phrasalposition fact even useful predicting cue phrases used itself.high performing classification models Experiment Set 2 also demonstrated utility classifying cue phrases based prosodic feature length textual featurepreceding cue phrase, combination features.machine learning approach made easy retrain new training examples became available (Experiment Set 2), machine learning also made easy retrainnew features become available. particular, value feature tokenadded representations Experiment Set 2, trivial relearnmodels (Experiment Set 3). Allowing learning programs treat cue phrases individually improved accuracy learned classification models, addedbody linguistic knowledge regarding cue phrases. Experiment Set 3 demonstrateduseful classifying cue phrases, prosodic features basedphrasal length, phrasal composition, accent, textual features based adjacentcue phrases, succeeding position, part-of-speech, fact useful usedconjunction feature token.final advantage machine learning approach ease inducing classification models many different sets features supports exploration comparativeutility different knowledge sources. especially useful understanding tradeoffs accuracy model set features considered.example, might worth effort code feature automatically obtainableexpensive automatically obtain adding feature results significantimprovement performance.89fiLitmansum, results paper suggest machine learning useful toolcue phrase classification, amount data precludes effective human analysis,exibility afforded easy retraining needed (e.g., due additional trainingexamples, new features, new classifications), and/or analysis goal gain betterunderstanding different aspects data.Several areas future work remain. First, still room performance improvement. error rates best performing learned models, even though outperformmanually derived models, perform error rates teens. Notefeatures coded discussed Hirschberg Litman (1993) consideredpaper. may possible lower error rates considering new typesprosodic textual features (e.g., contextual textual features (Siegel, 1994),features proposed connection general topic discoursestructure), and/or using different kinds learning methods. Second, Experiment Set4 (and previous literature) show yet, models predictingcue phrase usage classified unknown, rather discourse sentential.Again, may possible improve performance existing learned modelsconsidering new features and/or learning methods, perhaps performance could improved providing training data. Finally, currently open question whethertextual models developed here, based transcripts speech, applicablewritten texts. Textual models thus need developed using written texts trainingdata. Machine learning continue useful tool helping addressissues.Appendix A. C4.5 Results Experiment Sets 2 3Tables 13, 14 15 present C4.5 error rates Experiment Sets 2 3. C4.5results Experiment Set 2 shown \Non-Tokenized" columns. comparisonTables 13 5 shows except larger test set, C4.5 prosodic error ratesfall within cgrendel confidence intervals. similar comparison Tables 14 6shows except O-P larger test set, C4.5 textual error rates fall withincgrendel confidence intervals. Finally, comparison Tables 15 7 showsC4.5 error rate speech-text falls within cgrendel confidence interval. factcomparable cgrendel C4.5 results generally obtained suggests abilityautomate well improve upon manual performance due specificseither learning program.C4.5 results Experiment Set 3 shown \Tokenized" columns Tables 13, 14 15. Comparison Tables 8, 10 12 shows error rates C4.5cgrendel similar Experiment Set 2. However, error rates reportedtables use default C4.5 cgrendel options running learning programs. Comparable performance two learning programs fact generallyachieved overriding one default C4.5 options. detailed Quinlan (1993),default C4.5 approach { creates separate subtree possible feature value{ might appropriate many values feature. situation characterizes feature token. C4.5 default option changed allow feature valuesgrouped one branch decision tree, problematic C4.5 error rates90fiCue Phrase Classification Using Machine LearningModelP-LP-PI-LI-PI-CA*prosodyhl93featuresphrasinglengthpositionintonationalintermediateClassifiable Cue Phrases (N=878)Non-Tokenized Tokenized (+)32.531.716.218.425.626.825.926.336.536.640.740.728.326.716.015.230.229.015.915.224.824.418.118.016.816.621.222.3Classifiable Non-Conjuncts (N=495)Non-TokenizedTokenized (+)32.231.418.819.025.625.619.418.835.832.829.629.228.831.219.416.018.818.818.017.426.224.219.617.618.819.821.618.4Table 13: Error rates (%) C4.5 prosodic classification models, testing data. (Trainingtesting done multiple cue phrase corpus using cross-validation.)ModelC-PC-SO-PO-P*O-SO-S*POStextadjacencyorthographyprecedingsucceedingClassifiable Cue Phrases (N=878)Non-Tokenized Tokenized (+)40.739.340.739.940.735.718.420.335.031.634.432.540.734.719.020.640.939.418.919.318.719.334.132.9Classifiable Non-Conjuncts (N=495)Non-TokenizedTokenized (+)39.233.639.239.218.614.617.215.031.831.831.032.441.831.820.015.040.643.617.818.019.216.030.031.8Table 14: Error rates (%) C4.5 textual classification models, testing data. (Trainingtesting done multiple cue phrase corpus using cross-validation.)indeed improve. example, A+ error rate classifiable non-conjuncts changes29.2% (Table 13) 11%, within 12.8% 3.1% cgrendel confidenceinterval (Table 8).Acknowledgementswould like thank William Cohen Jason Catlett helpful comments regardinguse cgrendel C4.5, Sandra Carberry, Rebecca Passonneau, threeanonymous JAIR reviewers helpful comments paper. would also like91fiLitmanModelspeech-textClassifiable Cue Phrases (N=878)Non-Tokenized Tokenized (+)15.313.6Classifiable Non-Conjuncts (N=495)Non-TokenizedTokenized (+)16.817.6Table 15: Error rates (%) C4.5 prosodic/textual classification model, testing data.(Training testing done multiple cue phrase corpus using crossvalidation.)thank William Cohen, Ido Dagan, Julia Hirschberg, Eric Siegel commentspreliminary version paper (Litman, 1994).ReferencesAltenberg, B. (1987). Prosodic Patterns Spoken English: Studies CorrelationProsody Grammar Text-to-Speech Conversion, Vol. 76 Lund StudiesEnglish. Lund University Press, Lund.Aone, C., & Bennett, S. W. (1995). Evaluating automated manual acquisitionanaphora resolution strategies. Proceedings Thirty-Third Annual MeetingAssociation Computational Linguistics (ACL).Brieman, L., Friedman, J., Olshen, R., & Stone, C. (1984). Classification RegressionTrees. Monterey, CA: Wadsworth Brooks.Church, K. W. (1988). stochastic parts program noun phrase parser unrestrictedtext. Proceedings Second Conference Applied Natural Language Processing.Cohen, R. (1984). computational theory function clue words argument understanding. Proceedings Tenth International Conference ComputationalLinguistics (COLING).Cohen, W. W. (1992). Compiling knowledge explicit bias. ProceedingsNinth International Conference Machine Learning.Cohen, W. W. (1993). Ecient pruning methods separate-and-conquer rule learningsystems. Proceedings Thirteenth International Joint Conference ArtificialIntelligence (IJCAI).Freedman, D., Pisani, R., & Purves, R. (1978). Statistics. W. W. Norton Company.Grosz, B., & Hirschberg, J. (1992). intonational characteristics discourse structure. Proceedings International Conference Spoken Language Processing(ICSLP).Grosz, B. J., & Sidner, C. L. (1986). Attention, intentions, structure discourse.Computational Linguistics, 12 (3), 175{204.92fiCue Phrase Classification Using Machine LearningHalliday, M. A. K., & Hassan, R. (1976). Cohesion English. Longman.Hearst, M. A. (1994). Multi-paragraph segmentation expository text. ProceedingsThirty-Second Annual Meeting Association Computational Linguistics(ACL).Hindle, D. M. (1989). Acquiring disambiguation rules text. ProceedingsTwenty-Seventh Annual Meeting Association Computational Linguistics(ACL).Hirschberg, J. (1990). Accent discourse context: Assigning pitch accent syntheticspeech. Proceedings Eighth National Conference Artificial Intelligence(AAAI).Hirschberg, J., & Litman, D. (1987). let's talk \now": Identifying cue phrasesintonationally. Proceedings Twenty-Fifth Annual Meeting AssociationComputational Linguistics (ACL).Hirschberg, J., & Litman, D. (1993). Empirical studies disambiguation cue phrases.Computational Linguistics, 19 (3), 501{530.Holte, R. C. (1993). simple classification rules perform well commonly useddatasets. Machine Learning, 11 (1), 63{90.Litman, D., & Hirschberg, J. (1990). Disambiguating cue phrases text speech.Proceedings Thirteenth International Conference Computational Linguistics(COLING).Litman, D. J. (1994). Classifying cue phrases text speech using machine learning.Proceedings Twelfth National Conference Artificial Intelligence (AAAI).Litman, D. J., & Allen, J. F. (1987). plan recognition model subdialogues conversation. Cognitive Science, 11, 163{200.Litman, D. J., & Passonneau, R. J. (1995). Combining multiple knowledge sourcesdiscourse segmentation. Proceedings Thirty-Third Annual MeetingAssociation Computational Linguistics (ACL).McCarthy, J. F., & Lehnert, W. G. (1995). Using decision trees coreference resolution.Proceedings Fourteenth International Joint Conference Artificial Intelligence(IJCAI).Moser, M., & Moore, J. D. (1995). Investigating cue selection placement tutorialdiscourse. Proceedings Thirty-Third Annual Meeting AssociationComputational Linguistics (ACL).Ostendorf, M., & Ross, K. (in press). multi-level model recognition intonation labels.Y. Sagisaka, N. C., & Higuchi, N. (Eds.), Computing Prosody. Springer-Verlag.Passonneau, R. J., & Litman, D. J. (in press). Discourse segmentation humanautomated means. Computational Linguistics, 23.93fiLitmanPierrehumbert, J. B. (1980). Phonology Phonetics English Intonation. Ph.D.thesis, Massachusetts Institute Technology. Distributed Indiana UniversityLinguistics Club.Pitrelli, J., Beckman, M., & Hirschberg, J. (1994). Evaluation prosodic transcriptionlabeling reliability ToBI framework. Proceedings International Conference Spoken Language Processing (ICSLP).Quinlan, J. R. (1993). C4.5 : Programs Machine Learning. San Mateo, CA: MorganKaufmann.Reichman, R. (1985). Getting Computers Talk Like Me: Discourse Context,Focus, Semantics. Cambridge, MA: MIT Press.Siegel, E. V. (1994). Competitively evolving decision trees fixed training casesnatural language processing. K. E. Kinnear, J. (Ed.), Advances GeneticProgramming. Cambridge, MA: MIT Press.Siegel, E. V., & McKeown, K. R. (1994). Emergent linguistic rules automaticgrouping training examples: Disambiguating clue words decision trees.Proceedings Twelfth National Conference Artificial Intelligence (AAAI).Soderland, S., & Lehnert, W. (1994). Corpus-driven knowledge acquisition discourseanalysis. Proceedings Twelfth National Conference Artificial Intelligence(AAAI).Sti eman, L. J. (1995). discourse analysis approach structured speech. WorkingNotes AAAI Spring Symposium Series: Empirical Methods Discourse Interpretation Generation.Weiss, S. M., & Kulikowski, C. (1991). Computer Systems Learn: ClassificationPrediction Methods Statistics, Neural Nets, Machine Learning, ExpertSystems. San Mateo, CA: Morgan Kaufmann.Wermter, S., Riloff, E., & Scheler, G. (1996). Connectionist, Statistical Symbolic Approaches Learning Natural Language Processing. Berlin, Germany: SpringerVerlag.Wightman, C. W., & Ostendorf, M. (1994). Automatic labeling prosodic patterns. IEEETransactions Speech Audio Processing, 2 (4), 469{481.Zuckerman, I., & Pearl, J. (1986). Comprehension-driven generation meta-technicalutterances math tutoring. Proceedings Fifth National ConferenceArtificial Intelligence (AAAI).94fiJournal Artificial Intelligence Research 5 (1996) 163{238Submitted 5/94; published 10/96Mechanisms Automated NegotiationState Oriented DomainsGilad Zlotkingiladz@agentsoft.comAgentSoft Ltd.P.O. Box 53047Jerusalem, IsraelJeffrey S. Rosenscheinjeff@cs.huji.ac.ilInstitute Computer ScienceHebrew UniversityGivat Ram, Jerusalem, IsraelAbstractpaper lays part groundwork domain theory negotiation, is,way classifying interactions clear, given domain, negotiationmechanisms strategies appropriate. define State Oriented Domains, generalcategory interaction. Necessary sucient conditions cooperation outlined.use notion worth altered definition utility, thus enabling agreementswider class joint-goal reachable situations. approach offered con ict resolution,shown even con ict situation, partial cooperative steps takeninteracting agents (that is, agents fundamental con ict might still agree cooperatecertain point).Unified Negotiation Protocol (UNP) developed used typesencounters. shown certain borderline cooperative situations, partial cooperative agreement (i.e., one achieve agents' goals) might preferredagents, even though exists rational agreement would achieve goals.Finally, analyze cases agents incomplete information goalsworth agents. First consider case agents' goals private information, analyze goal declaration strategies agents might adopt increaseutility. Then, consider situation agents' goals (and therefore standalone costs) common knowledge, worth attach goals privateinformation. introduce two mechanisms, one \strict," \tolerant," analyze affects stability eciency negotiation outcomes.1. IntroductionNegotiation major research topic distributed artificial intelligence (DAI)community (Smith, 1978; Malone, Fikes, Grant, & Howard, 1988; Kuwabara & Lesser,1989; Conry, Meyer, & Lesser, 1988; Kreifelts & von Martial, 1991). term negotiation,however, used variety different ways. researchers, negotiationserves important mechanism assigning tasks agents, resource allocation,deciding problem-solving tasks undertake. systems, generallynotion global utility system trying maximize.c 1996 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiZlotkin & Rosenscheinresearchers focused negotiation might take place among agentsserve interests truly distinct parties (Rosenschein & Genesereth, 1985; Sycara, 1988;Kraus & Wilkenfeld, 1990; Zlotkin & Rosenschein, 1989). agents autonomoussense utility functions, global notion utility (noteven implicit one) plays role design. Negotiation used share workassociated carrying joint plan, resolve outright con ict arising limitedresources.Despite varied use terminology, clear DAI community wholeoperation interacting agents would enhanced able exchangeinformation reach mutually beneficial agreements.work described paper follows general direction previous researchauthors (Rosenschein & Genesereth, 1985; Zlotkin & Rosenschein, 1989) treatingnegotiation spirit game theory. focus research analyze existenceproperties certain kinds deals protocols among agents.examining computational issues arise discovering deals, though designecient, possibly domain-specific, algorithms constitute important future phaseresearch. Initial work building domain theory negotiation previouslyundertaken (Zlotkin & Rosenschein, 1993a), expanded generalized currentpaper. analysis serves critical step applying theory negotiation realworld applications.1.1 Applying Game Theory Tools Protocol Design Automated Agentsongoing research motivated one, focused premise: problemget computers interact effectively heterogeneous systems tackleduse game theory tools.concern computer systems made machines programmeddifferent entities pursue differing goals. One approach achieving coordinationcircumstances establish mutually accepted protocols machines usecoming agreements.perspective research one use game theory tools designevaluate high-level protocols. intend, paper, make contributionsgame theory itself. defining new notions equilibria, providingnew mathematical tools used general game theory. takinggame theory approach, tools, solve specific problems high-levelprotocol design.game theory makes contributions understanding many different fields,particularly serendipitous match game theory heterogeneous computer systems. Computers, pre-programmed behavior, make concretenotion \strategy" plays central role game theory|the idea playeradopts rules behavior starting play given game, rules entirelycontrol responses game. idealized player imperfect model humanbehavior, one quite appropriate computers.first apply game theoretic ideas computer science,using tools new way. others used game theory answer question,164fiMechanisms Automated Negotiation\How one program computer act given specific interaction?" addressing question design rules interaction automatedagents. approach taken paper is, therefore, strongly based previous workgame theory, primarily known \Nash's Bargaining Problem" (Nash, 1950;Luce & Raiffa, 1957) \Nash's Model Bargaining" (Roth, 1979), \mechanism design"\implementation theory" (Binmore, 1992; Fudenberg & Tirole, 1992), \correlatedequilibrium theory" (Aumann, 1974, 1987; Myerson, 1991; Forges, 1993). short overviewgame theory results used referred paper found Section 9.1.1.2 Overview Paperprevious work, began laying groundwork domain theory negotiation,is, way classifying interactions clear, given domain, negotiationmechanisms strategies appropriate. Previously, considered Task Oriented Domains (Zlotkin & Rosenschein, 1989, 1993a), restricted category interactions.paper, define State Oriented Domains, general category interaction.Section 4.4 examine scenarios interacting agents State Oriented Domainsfind cooperative, compromise, con ict encounters. con ict situations, agents' goals cannot simultaneously achieved. joint-goal reachable situation(i.e., agents' goals simultaneously achieved) cooperative compromise, depending cost reaching state satisfies agents comparedcost agent (alone) achieving stand-alone goal.Section 4.1, necessary sucient conditions cooperation outlined. Cooperative situations lend mixed-joint-plan-based negotiation mechanisms. However,compromise situations require special treatment. propose using notion worthaltered definition utility, thereby enabling agreements wider class joint-goalreachable situations. approach offered con ict resolution, showneven con ict situation, partial cooperative steps taken interacting agents(that is, agents fundamental con ict might still agree cooperate certain point).Unified Negotiation Protocol (UNP) developed Section 5.4 usedtypes encounters. shown certain borderline cooperative situations, partialcooperative agreement (i.e., one achieve agents' goals) might preferredagents, even though exists rational agreement would achievegoals.UNP enhanced Section 6 deal case agentsassigned unlimited worth goals fact common knowledge. solutiondepends concept \cleaning yourself," tidiness, new methodevaluating agent utility. show two tidy agents able reach agreementsjoint-goal reachable situations State Oriented Domains.Section 7 analyze cases agents incomplete information goalsworth agents. First, consider case agents' goals privateinformation, consider goal declaration strategies agents might adoptincrease utility.consider, Section 8, situation agents' goals (and thereforestand-alone costs) common knowledge, worth attach goals165fiZlotkin & Rosenscheinprivate information. many situations agent's goals might known,worth private. example, two cars approaching intersection may knowother's goals (because lanes located). worthassociates passing intersection target lane, however, private. Goalrecognition techniques suitable discovering agent's intentions; worth,however, harder discern short-term external evidence.agents declare, ,1-phase, worths, used baselineutility calculation (and thus affect negotiation outcome). concernedanalyzing worth declaration strategies agents might adopt increase utility.introduce two mechanisms, one \strict," \tolerant," analyze affectsstability eciency negotiation outcomes. strict mechanism turnsstable, tolerant mechanism ecient.2. Negotiation State Oriented Domainsmachines decide share resources, machine give wayproceeds? Negotiation compromise necessary, buildmachines things? designers separate machines decidetechniques agreement enable mutually beneficial behavior? techniquesappropriate? make definite statements techniques' properties?way address questions synthesize ideas artificial intelligencetools game theory. Assuming automated agents, built separate, self-interesteddesigners, interact, interested designing protocols specific domainsget agents interact useful ways.word \protocol" means different things different people. use wordprotocol, mean rules agents come agreements. specifies kindsdeals make, well sequence offers counter-offers allowed.Protocols intimately connected domains, mean environmentagents operate. Automated agents control telecommunications networksoperating different domain (in formal sense) robots moving boxes. Muchresearch focused relationship different kinds domains, protocolssuitable each.Given protocol, need consider agent strategy appropriate. strategyway agent behaves interaction. protocol specifies rulesinteraction, exact deals agent proposes result strategydesigner put him. analogy, protocol like rules governing movementpieces game chess. strategy way chess player decidesnext move.2.1 Attributes Standardsattributes might interest protocol designers? set attributes,relative importance, ultimately affect choice interaction rules.considered several attributes might important system designers.166fiMechanisms Automated Negotiation1.2.3.4.5.Eciency: agents squander resources come agree-ment; wasted utility agreement reached. example,makes sense agreements satisfy requirement Pareto Optimality(no agent could derive different agreement, without agentderiving less alternate agreement). Another consideration might GlobalOptimality, achieved sum agents' benefits maximized.Global Optimality implies Pareto Optimality, vice versa. Since speaking self-motivated agents (who care utilities, sumsystem-wide utilities|no agent general would willing accept lower utilityincrease system's sum), Pareto Optimality plays primary role eciencyevaluation. Among Pareto Optimal solutions, however, might also considersecondary criterion solutions increase sum system-wide utilities.Stability: agent incentive deviate agreed-upon strategies.strategy agents adopt proposed part interaction environmentdesign. strategies proposed, however, want individualdesigners (e.g., companies) incentive go back build agentsdifferent, manipulative, strategies.Simplicity: desirable overall interaction environment make lowcomputational demands agents, require little communication overhead.related eciency stability: interaction mechanismsimple, increases eciency system, fewer resources used carryingnegotiation itself. Similarly, stable mechanisms, resources needspent outguessing opponent, trying discover optimal choices.optimal behavior publicly revealed, nothing bettercarry out.Distribution: Preferably, interaction rules require central decisionmaker, obvious reasons. want distributed systemperformance bottleneck, collapse due single failure special node.Symmetry: may want agents play different roles interaction scenario. simplifies overall mechanism, removes question agentplay role interaction gets way.attributes need universally accepted. fact, sometimes tradeoffs one attribute another (for example, eciency stability sometimescon ict one another; see Section 8). protocols designed, specificclasses domains, satisfy attributes. Ultimately,kinds criteria rate acceptability one interaction mechanism another.one example, attribute stability assumes particular importance consider open systems, new agents constantly entering leaving communityinteracting machines. Here, might want maintain stability face new agentsbring new goals potentially new strategies well. mechanism\self-perpetuating," benefit society whole followrules, also benefit individual member, social behavior remains167fiZlotkin & Rosenscheinstable even society's members change dynamically. interaction rulescreate environment particular strategy optimal, beneficial social behaviorresistant outside invasion.2.2 Side Effects EncountersVarious kinds encounters among agents, various types domains, possible. previous work (Zlotkin & Rosenschein, 1989, 1993a, 1994, 1996b) examined Task OrientedDomains (TODs), encompass certain kinds encounters among agents. StateOriented Domains (SODs) describe larger class scenarios multiagent encountersTODs. fact, see below, set Task Oriented Domains actuallyproper subset State Oriented Domains. classical domains Artificial Intelligenceinstances State Oriented Domains.main attribute general SODs agents' actions side effects. TaskOriented Domains, side effects exist general common resources unrestricted.Thus, agent achieves set tasks TOD positive negativeeffects agent whatsoever. hinder agent achievinggoal, never satisfies agent's goals \by accident." enable another agentcarry task, example Postmen Domain (Zlotkin & Rosenschein,1989), necessary explicitly declare existence letter, hand over,delivered. absence side effects rules positive negativeinteractions among agent goals. positive interactions remainexplicitly coordinated agents.general State Oriented Domains, side effects exist, agents unintentionallyachieve one another's goals, thus benefit one another's actions. ip sideside effects, however, negative interactions goals also exist. Thus,SOD domain (unlike TODs) necessarily cooperative, actionside effects. SODs, agents deal goal con ict interference, wellpossibility unintended cooperation.1example, consider Blocks World situation Figure 1. simplest planachieve On(White; Gray) side effect achieving Clear(Black).Figure 1: Side Effects State Oriented Domains1. interesting discussions issue con ict role human encounters, see (Schelling, 1963,1984).168fiMechanisms Automated Negotiation2.3 Domain DefinitionConsider group agents co-exist environment. agent goalinterested achieving. mean achieve goal? State Oriented Domains,classic AI notion goal achievement: means carry sequence actions(a plan) results transformation environment state goalsatisfied.Imagine, example, person interested getting work. goalwork; current state, work. plan sequence actionsget work (driving car, calling taxi, walking, riding bicycle,. . . ).final, goal, state, may differ depending plan executed (e.g.,car is, bicycle is). states work, however, satisfy goal.Let's assume optimal plan (from time point view) involves driving carwork.specification goal states may implicit. fact needs true(the goal) may given. situation fact true, i.e., goal satisfied,acceptable. State Oriented Domain, goal described set statessatisfy it.imagine person's wife interested place work.states satisfy husband's wife's goals, plansachieve state (e.g., one takes car, calls taxi). However,certain plans suitable either spouse isolation, cannotcoexist. example, husband taking car perfectly good plan (and optimal)alone world. Similarly, wife's taking car good plan (and optimal)alone. Together, another plan may suitable (husband drives wifework, continues car work). case, extra work requiredhusband's point view, wife present world; certain burdencoordination.example above, agents carry sequence activities, suitably synchronized, reach goal state satisfying both. husband wife enter car,husband drives particular location, wife exits, on. environment, primitive operations agent alone do. operationscombined coherent sequence actions specifying agents (andorder done), say agents executing joint plan.joint plan general transforms world initial state goal state satisfyingagents (when possible). plan transforms world initial statehusband wife home goal state (satisfying agents)wife work, car husband place work. final state,one many goal states.Task Oriented Domains cost coordinated plan need never worsestand-alone plan|at worst, agent achieves set tasks.husband/wife sharing one car example, however, coordinated plan may worseone agents stand-alone plans. example one attributeState Oriented Domains, namely negative interactions, sometimes called169fiZlotkin & Rosenschein\deleted-condition interactions" (Gupta & Nau, 1992). taking carside effect depriving agent car.Imagine new situation, arises weekend. husband interestedcarpentry garage (currently occupied car). wife interestedtaking car baseball game. themselves, agent optimal plan reachgoal state (e.g., husband moves car garage, parks outside,carpentry). However, wife takes car game, executing stand-aloneoptimal plan, husband benefits side effect car moved, namely,garage emptied. example another typical attribute State OrientedDomains|accidental achievement goals, \enabling-condition interactions" (Gupta &Nau, 1992) \favor relations" (von Martial, 1990) among goals.agents carry joint plan, one plays \role." theory assumesway assessing cost role. measure cost essentialagent evaluates given joint plan. Among joint plans achieve goal,prefer role lower cost.express intuitive ideas precise definition below.Definition 1 State Oriented Domain (SOD) tuple < ; A; J ; c > where:1. set possible world states;2. = fA1; A2; : : :A g ordered list agents;n3. J set possible joint (i.e., n-agent) plans. joint plan J 2 J movesworld one state another. actions taken agent k called k's roleJ , written J . also write J (J1; J2; : : :; J );kn4. c function c: J ! (IR+ ) : joint plan J J , c(J ) vector n positivereal numbers, cost agent's role joint plan. c(J ) i-th elementcost vector, i.e., cost i-th role J . agent plays roleJ , cost 0.nuse term joint plan differs uses AI literature (Levesque &Cohen, 1990; Cohen & Levesque, 1991). There, term joint plan implies joint goal,mutual commitment agents full implementation plan (e.g., one agentdropped suddenly, would still continue). use term, agentscommitted goal part combined plan. maypart plan different reasons, different goal achieve.one agent drop out, agent may may continue, depending whethersuited goal.details description joint plans J critical overall theory.minimal requirement must possible evaluate cost joint planagent (i.e., cost role). many domains, joint plan sequenceactions agent associated schedule (partial order) constraining actions'parallel execution.Note also cost function relates joint plan not,example, initial state world. fact, cost function could altered170fiMechanisms Automated Negotiationinclude parameters (like initial state world), without affecting discussionbelow. model sensitive details cost function definition,requirement cost role agents. called symmetricabilities assumption (see below, Section 2.4).Definition 2 encounter within SOD < ; A; J ; c > tuple < s; (G1; G2; : : :; G ) >2 initial state world, k 2 f1 : : :ng; G setacceptable final world states agent . G also called 's goal.nkkkkagent's goal fixed, pre-determined, set states. agent will, conclusionjoint plan, either achieve goal achieve goal. Goals cannot partiallyachieved. Domains goals partially achieved called Worth OrientedDomains (WODs) discussed detail elsewhere (Zlotkin & Rosenschein, 1991c,1996a).One thing specifically ruling SODs one agent goalmakes reference another agent's (as yet) unknown goal. example, specification\Agent 1's goal make sure Agent 2's goal achieved, whateverlatter's goal is" cannot constitute part description encounter StateOriented Domain, cannot described static set goal states. However,meta-goal might exist within agent, give rise well-defined set statesspecific encounter (e.g., given G2, G1 complement). Similarly, one agent mightgoal another agent specific goal G2|the first agent wants worldstate agent specific goal G2.consider sets goal states specified finite way, eitherset finite, infinite set specified closed formulafirst-order logic (i.e., free variables; states satisfy formula,states, goal set). example, agent might goal \There existsblock x block B x."also consider restrictions kind goals agents may have.example, consider domains agents' goals restricted setsgrounded predicates (i.e., variables) rather closed formula.2.3.1 Reachabilitymay case exist goal states satisfy agents' goals,constraints reachability states. example, may casestate satisfying goal reached agent alone, state satisfyingcombined goal cannot reached agent alone. generally, reachingstate might require n agents working together, unreachable fewer n agentsinvolved (we call n \parallelism factor" goal). goalintersection cannot reached number agents working parallel, sayparallelism factor infinite. parallelism factor particularly appropriate conceptmultiagent actions possible required domain (e.g., carryingheavy table).171fiZlotkin & Rosenschein2.4 AssumptionsThroughout paper, making number simplifying assumptions enableus lay foundation theory mechanism design automated agents.Here, present assumptions.1.2.3.4.5.6.Expected Utility Maximizer: Designers design agents maximize expected utility. example, assume designer build agent prefer51% chance getting $100, rather sure $50.Isolated Negotiation: agent cannot commit part current negotiation behavior future negotiation, expect currentbehavior way affect future negotiation. Similarly, agent cannot expectothers behave particular way based previous interaction history,act differently past behavior. negotiation standsalone.Interagent Comparison Utility: designers means transformingutilities held different agents common utility units.Symmetric Abilities: agents able perform set operationsworld, cost operation independent agent carrying out.Binding Commitments: Designers design agents keep explicit publiccommitments. assume nothing relationship private preferencespublic behavior, public commitment followed public performancecommitment. monitored, necessary, enforced.Explicit Utility Transfer: Although agents compare respective utilities, way explicitly transferring utility units one other.is, example, \money" used compensate one agentdisadvantageous agreement. Utility transfer occur, however, implicitly.implicit transfer utility forms basis agreement among agents.3. Examples State Oriented Domainssection, present several examples State Oriented Domains. specificexamples illustrate nuances describing class domains.3.1 Blocks DomainBlocks Domain, table unlimited size, set blocks. blocktable block, limit height stackblocks. One state domain seen Figure 2.World States Goals: basic predicates make world states goals are:On(x; y): x blocks; meaning block x (directly)block .172fiMechanisms Automated NegotiationFigure 2: State Blocks Domain123Figure 3: State Slotted Blocks DomainOn(x; Table): x block; meaning block x (directly)table.Clear(x): x block; meaning block x, i.e.,Clear(x) :9y On(y; x).SOD, goals sets world states. world states expressedfirst order closed formula predicates. Sample goals are::Clear(R) | Block R clear.9xOn(R; x) | Block R table.8xOn(x; Table) | blocks table (and therefore, implicitly, blocksalso Clear).Atomic Operation: one operation world: Move(x; ). operation movesclear block x onto top another clear block .Cost: move operation cost 2.3.2 Slotted Blocks Domaindomain Blocks Domain above. However, tablebounded number slots blocks placed. One state domainseen Figure 3.World States Goals: basic predicates make world states goals are:On(x; y): x blocks; meaning block x (directly)block .173fiZlotkin & RosenscheinAt(x; n): x block n slot name; meaning blockx (directly) table slot n.Clear(x): x block; meaning blockx, i.e., Clear(x) :9y On(y; x).Atomic Operations: two operations Slotted Blocks Domain:PickUp(i) | Pick top block slot (can executed whenever slotempty);PutDown(i) | Put block currently held slot i.agent hold one block time.Cost: operation cost one.Slotted Blocks Domain different Blocks Domain two ways:1. table unlimited size replaced bounded table distinguishable locations call \slots."2. atomic \Move" operation broken two sub-operations PickUp PutDown.allows cooperation among agents. example, want swapblocks slot 1 Figure 3 would take one agents minimally total4 Move operations, i.e., block (Black White) touched twice. However,allow agents use PickUp PutDown operations two agentsswap two PickUp two PutDown operations (which equivalent twomove operations), i.e., block touched once. finer granularityoperations allows exibility scheduling within joint plan.3.3 Delivery Domain Bounded Storage SpaceDelivery Domain, weighted graph G = G(V; E ). v 2 V representswarehouse, e 2 E represents road. weight function w: E ! IR+ lengthgiven road. edge e 2 E , w(e) length e \cost" e.agent deliver containers one warehouse another. deliveries, agentsrent trucks, unlimited supply available rental every node.truck carry 5 containers. warehouse also limited capacity holdingcontainers.Atomic Operations: operations domain are:Load(c; t) | loads container c onto truck t. preconditions are:{ Container c truck warehouse h;{ Truck less 5 containers board, 5 capacity limittruck.results operation are:{ Warehouse h one container less;174fiMechanisms Automated Negotiation{ Truck one container more.Load operation costs 1.Unload(c; t) | unloads container c truck t. preconditions are:{ Container c truck t;{ Truck warehouse h;{ Warehouse h full.results operation are:{ Warehouse h one container more;{ Truck one container less.Unload operation costs 1.Drive(t; h) | Truck drives warehouse h. preconditionsoperation. result truck warehouse h. cost operationequal distance (i.e., minimal weighted path) currentposition truck warehouse h.World States Goals: full description world state includes locationcontainer (either warehouse truck) location truck(either warehouse road). However, restrict goalsspecify containers need warehouses.3.4 Restricted Usage Shared Resource Domaindomain, set agents able use shared resource (suchcommunication line, shared memory device, road, bridge. . . ). restriction1 agents use resource time (m denotesmaximal capacity resource).Atomic Operations: atomic operations Shared Resource Domain are:Use | agent using shared resource one time unit. Use operationcosts 0.Wait | agent waiting use shared resource one time unit.operation costs 1, i.e., waiting one time unit access shared resourcecosts 1.NOP | agent need resource therefore neither useswaits it. operation costs 0.objective find schedule time unitagents performing Use operation.World States Goals: world state describes current activity agentsaccumulated resource usage since time 0 (i.e., accumulated cost). goalagent state accumulated target number time unitsusing resource, currently NOP operation. Formally, state175fiZlotkin & RosenscheineA1Joint PlanA2A3A10 Use Use Wait1 Use Use Wait2 NOP Use Use3 NOP NOP Use4 NOP NOP NOPWorld States(Use,0)(Use,1)(NOP,2)(NOP,2)(NOP,2)A2(Use,0)(Use,1)(Use,2)(NOP,3)(NOP,3)A3(Wait,0)(Wait,0)(Use,0)(Use,1)(NOP,2)Figure 4: Joint Plan States Restricted Usage Shared Resource Domainn-element vector, one element agent, element pair consistingagent's current operation accumulated number time units usingresource (i.e., set states (fWait,Use,NOPg IN) ).Assume, example, three agents, one resource maximalcapacity two. Agents 1 3 need two units resource, agent 2 needs threeunits resource. joint plan seen left side Figure 4, describedmatrix. time agent , entry column row agent 's actiontime t. resulting world state time unit joint plan seenright side Figure 4. final state satisfies agents' goals.n4. Deals, Utility, Negotiation Mechanismsdefined characteristics State Oriented Domain, lookedsimple examples, turn attention agents SOD reach agreementjoint plan brings agreed-upon final state. Hopefully, final statesatisfy agents' goals. However, isn't always possible. threecases:1. might case doesn't exist state satisfies agents' goals(i.e., goals contradict one another);2. might case exists state satisfies both, cannotreached primitive operations domain (see Section 2.3.1 above);3. might case exists reachable state satisfies both,expensive get agents unwilling expend requiredeffort.4.1 Negotiation Mechanismstart presenting simple mechanism suitable cases existsreachable final state (that is, reachable suciently inexpensive plan) satisfiesagents' goals. call cooperative situation. Later, enhance mechanismhandle possible encounters State Oriented Domains, i.e.,handle con ict resolution.176fiMechanisms Automated NegotiationDefinition 3 Given SOD < ; A; J ; c >, define:P J set one-agent plans, i.e., joint plans one agentactive role.cost c(P ) one-agent plan agent k active role, P 2 P ,vector one non-zero element, position k.likelihood confusion, use c(P ) stand k-th element (i.e., c(P ) ),rather entire vector.kDefinition 4 Best Plans! f minimal cost one-agent plan P agent k plays active rolemoves world state state f .plan like exist ! f stand constant plan ./kkkcosts infinity agent k 0 agents.= f ! f stand empty plan costs 0 agents.! F (where world state F set world states) minimal costone-agent plan P agent k plays active role moves worldkkstate one states F :c(s ! F ) = minc(s ! f ):2kkfFmentioned above, moment restricting attention encountersexist one states satisfy agents' goals.one state exists? state agents choose reach?one joint plan reach states? joint plan agentschoose?example, let's say two states satisfy agents' goals. State 1two possible roles, one roles costing 6 costing 3. State 2two roles also, costing 5. State 1 cheaper overall reach, State2 seems allow fairer division labor among agents.Assuming agents want agreement ecient, decide reachState 1. agent role costs 6, rolecosts 3? approach allow agree \lottery" equalizebenefit derive joint plan. Although eventually one agentother, expected benefit two agents identical (prior holdinglottery). plans include probabilistic component called mixed joint plans.Throughout paper, limit bulk discussion mechanisms twoagent encounters. Initial work generalization techniques encounters amongtwo agents found elsewhere (Zlotkin & Rosenschein, 1994). researchconsiders issues coalition formation n-agent Task Oriented Domains.Definition 5 Deals Given encounter two-agent SOD < s; (G1; G2) >:177fiZlotkin & Rosenscheindefine Pure Deal joint plan J 2 J moves world statestate G1 \ G2.define Deal mixed joint plan J : p; 0 p 1 2 IR J PureDeal.semantics Deal agents perform joint plan (J1; J2)probability p, symmetric joint plan (J2 ; J1) probability 1 , p (where agentsswitched roles J ). symmetric abilities assumption Section 2.4,agents able execute parts joint plan, cost roleindependent agent executes it.Definition 6= (J : p) Deal, Cost () defined pc(J ) + (1 , p)c(J ) (where ki's opponent).kDeal, Utility () defined c(s ! G ) , Cost ():utility (or benefit) agent deal simply differencecost achieving goal alone expected part deal. Note write (forexample) c(s ! G ) rather c(s ! G ); since cost plan independentagent executing it.kDefinition 7Deal individual rational if, i, Utility () 0:Deal pareto optimal exist another Deal dominates it|exist another Deal better one agents worseother.negotiation set NS set deals individual rationalpareto optimal.necessary condition negotiation set empty contradiction two agents' goals, i.e., G1 \ G2 6= ;. states existintersection agents' goal sets might, course, reachable given domainactions agents disposal. condition reachability sucientNS empty, however, even contradictionagents' goals, may still cooperative solution them. situation,joint plan satisfies union goals cost one agent (or both)would spent achieving goal isolation (that is, deal individual rational).example Slotted Blocks Domain, consider following encounter.initial state seen left Figure 5. A1's goal \The White block slot 2table" A2 's goal \The Black block slot 1 table."achieve goal alone, agent execute one PickUp one PutDown;c(s ! G ) = 2. two goals contradict one another, exists state178fiMechanisms Automated Negotiationworld satisfies (where White Black blocks placedGray block). exist joint plan moves world initialstate state satisfies two goals total cost less eight2 |that is, dealindividual rational.Initial State1A1sgoal231...23Joint plan1A2sgoal2...123123Figure 5: Con ict Exists Even Though Union Goals Achievableexistence joint plan moves world initial state mutuallydesired state G1 \ G2 necessary (but sucient) condition negotiation setnon-empty. agents agree joint plan, individual rational.means sum roles agents play exceed sumindividual stand-alone costs (otherwise, least one agents would get positiveutility, i.e., work stand-alone plan). even conditionsucient guarantee individual rational deal, since case minimalrole joint plan still expensive agent minimum stand-alone cost.Even probabilistic mixture two roles reduce expected costagent cost minimal role (and thus role individual rationalhim).show, however, combination conditions necessary sucient negotiation set empty.Theorem 1 necessary sucient condition negotiation set emptyexistence joint plan moves world initial state state G1 \ G2also satisfies following two conditions (the sum condition min condition):joint plan J satisfies sum conditionX2 c(s ! G ) X2 c(J ) :=1=12. One agent lifts white block, agent rearranges blocks suitably (by pickingputting block once), whereupon white block put down. best planblock picked put once.179fiZlotkin & Rosenscheinjoint plan J satisfies min condition22minc(s ! G ) minc(J ) :=1=1Proof:NS 6= ;; let J : p mixed joint plan NS; thus, individual rational.8i 2 f1; 2gUtility (J : p) 0c(s ! G ) , Cost (J : p) 0c(s ! G ) Cost (J : p)c(s ! G ) pc(J ) + (1 , p)c(J )min 2f1 2gc(J )c(s ! G )c (J )XXk;l2f1 2g;;min c(s ! G ) min c(J )2f1 2gl2f1 2g2f1 2g;;Let J minimal total cost joint plan moves world state stateG1 \ G2 ; also satisfies sum min conditions. show NS =6 ;;sucient show exists deal individual rational paretooptimal. Without loss generality, assume c(s ! G2) c(s ! G1 )c(J )2 c(J )1: min condition, see c(s ! G1) c(J )1:two cases:{ c(s ! G2) c(J )2; deal J : 1 individual rational.{ c(s ! G2) < c(J )2; deal J : p (where p = 1 ,individual rational.( ! 1 ), ( )1 )( )2 , ( )1cc JGc Jc JJ : p also pareto optimal, another deal J 0 : q dominates J : pJ 0 : q also individual rational therefore satisfies min sum conditions(see proof, above, initial half theorem).Since J 0 : q dominates J : p also impliesX2f1 2gUtility (J 0 : q ) >;X Utility (J : p):Xtrue2f1 2g;X c(J ) :c(J 0) <;2f1 2g2f1 2g;contradicts fact J minimal total cost joint plan satisfiessum min conditions.180fiMechanisms Automated Negotiationsum condition states sum roles exceed sum individualagents' stand-alone costs. min condition states minimal role joint planless minimum stand-alone cost.conditions Theorem 1 true, say encounters cooperative. encounters, agents use negotiation mechanism mixed jointplans. question next examine kind negotiation mechanismuse.4.2 Mechanisms Maximize Product Utilitiesgeneral would like negotiation mechanism symmetrically distributed,would also like negotiation strategy (for mechanism)equilibrium itself. symmetrically distributed mechanism one agentsplay according rules, e.g., special agents different responsibility negotiation process. asymmetric negotiation mechanisms used,problem responsibility assignment needs resolved first (e.g.,coordinator agent). would need special mechanism responsibility assignment negotiation. mechanism also asymmetric need another mechanism,on. Therefore, better symmetric negotiation mechanism start with.Among symmetric mechanisms, prefer symmetric negotiation strategy equilibrium. Given negotiation mechanism , saynegotiation strategy equilibrium if, assumptionagents using strategy using , (or agent) cannot better usingnegotiation strategy different .Among symmetrically distributed negotiation mechanisms symmetricnegotiation strategy equilibrium, prefer maximize productagents' utilities. means agents play equilibrium strategy,agree deal maximizes product utilities. oneproduct-maximizing deal, agree deal (among product maximizers)maximizes sum utilities. one sum-maximizing productmaximizer, protocol choose among deals arbitrary probability.definition implies individual rationality pareto optimality agreed-upondeals.Note maximization product utilities decision agentsassumed making run-time; property negotiation mechanism agreedupon agent designers (i.e., exploring happens protocol designerswould agree property). classic game theory terms (see Section 9.1),protocol acts kind \mediator," recommending \maximization productutilities" cases.call class mechanisms Product Maximizing Mechanisms, PMMs.previous work TODs (Zlotkin & Rosenschein, 1989, 1993a) presented MonotonicConcession Protocol One-Step Protocol, PMMs. mentionedabove, paper examine computational issues arise discovering deals.number existing approaches bargaining problem game theory.One earliest popular Nash's axiomatic approach (Nash, 1950; Luce181fiZlotkin & Rosenschein& Raiffa, 1957). Nash trying axiomatically define \fair" solution bargainingsituation. listed following criteria ones fair solution would satisfy:1. Individual rationality (it would fair participant get less wouldanyway without agreement);2. Pareto Optimality (a fair solution specify agreement could improvedone participant without harming other);3. Symmetry (if situation symmetric, i.e., agents would get utilitywithout agreement, every possible deal, symmetric deal also possible,fair solution also symmetric, i.e., give participantsutility);4. Invariance respect linear utility transformations. example, imagine twoagents negotiating divide $100. one agent measures utilitydollars measures cents, uence fair solution.Similarly, one agent already $10 bank, evaluates deal givesx dollars utility 10 + x evaluates dealutility x, uence fair solution (i.e., change origin doesn't affectsolution);5. Independence irrelevant alternatives. Imagine two agents negotiatingdivide 10,000 cents. Nash solution 5,000 cents each, duesymmetry assumption above. imagine agents negotiating$100. Even though deals can't reach (for example,one one agent gets $49.99, gets $50.01), solutionsame, original solution 5,000 cents still found newdeal space.Nash showed product maximizing solution satisfies criteria,solution satisfies them. first four criteria explicitlyimplicitly assumed approach (in fact, example, version fourthassumption restrictive Nash's). fifth criteria assumedwork, turns true cases anyway. use Nash solution,general, reasonable bargaining outcome, applicable. Nash, however,assumptions space deals have. example,Nash bargaining problem assumes bounded, convex, continuous, closed regionnegotiation. agent negotiations, assume space deals convex,continuous.4.3 Worth Goalencounter cooperative, agents use PMM mixed joint plans.mechanism guarantees fair ecient cooperative agreement. question now,however, done non-cooperative encounters?Consider encounter Restricted Usage Shared Resource Domainthree agents, one resource maximal capacity two. Agents 1182fiMechanisms Automated NegotiationeA1AgentsA2A30 Use Use Wait1 Use Use Wait2 NOP Use Use3 NOP NOP Use4 NOP NOP NOP012345A1AgentsA2A3Use Wait UseUse Wait UseNOP Use NOPNOP Use NOPNOP Use NOPNOP NOP NOPFigure 6: Two Joint Plans Restricted Usage Shared Resource Domain3 need two units resource agent 2 needs 3 units resource.agent, alone world, could achieve goal cost (i.e., without waitingresource). However, since maximal capacity resource two, threeagents together cannot achieve combined goal without agent wait.Two possible joint plans achieve agents' goals seen Figure 6. leftjoint plan gives agents 1 2 utility 0, giving agent 3 utility ,2. right jointplan gives agents 1 3 utility 0, giving agent 2 utility ,2. Globally, planleft finishes sooner. perspective individual agents, two plansreally comparable|in one, agent 3 suffers waiting two time units, other,agent 2 suffers exactly amount. assumed, however, agentsconcerned global aspects resource utilization, concernedlocal cost. addition, plans Pareto Optimal, neitherindividual rational (because one agent gets negative utility).exists joint plan J brings world state satisfies agents'goals, either min condition sum condition true, agentscooperatively bring world state satisfies agents' goals, least onealone world achievedgoals. either one agree extra work? depends importantgoal agent i, i.e., much willing pay bring world state G .example, Shared Resource encounter above, agent 2 3 might willingwait two time units get turn resource. Although coulddone better alone world, must cope presenceagents. original definition utility, deal achieves agents' goalsindividual rational|someone wait, thus get negative utility.utility definition, agent willing wait. agents fail reachagreement, one achieve goal. utility calculateddifference cost agent's plan alone world costrole joint plan agents.However, agents use stand-alone cost baseline determiningutility? may case agents willing, presence agents,admit need pay extra cost, sort \coordination overhead." factagents around necessarily make irrational more.183fiZlotkin & RosenscheinTask Oriented Domains (Zlotkin & Rosenschein, 1989, 1993a, 1994), reasonableuse stand-alone cost utility baseline since never coordination overhead.worst case, agent could always achieve goal stand-alone price,coordination could improve situation. State Oriented Domains, however,makes sense consider altering utility baseline, agents rationally coordinateeven exists coordination overhead. One way assumeagent upper bound cost willing bear achieve goal.Then, agent's utility measured relative upper bound. call upperbound worth agent's goal.Even TODs, one conceive stand-alone cost worth agent assignsachieving goal. stand-alone cost maximum agent willingexpend. TOD, maximum need never violated, it's reasonable worth valueuse.upper bound exist, i.e., agent willing achieve goalcost, techniques used (see Section 6 below).Definition 8 Given encounter two-agent SOD < s; (G1; G2) >, let w maxiimum expected cost agent willing pay order achieve goal G . wcalled worth goal G agent i. denote enhanced encounter< s; (G1; G2); (w1; w2) > :definition Utility usefully altered follows:Definition 9 Given encounter < s; (G1; G2); (w1; w2) >; deal, i.e., mixedjoint plan satisfying agents' goals, Utility ( ) defined w , Cost ( ):utility agent deal difference worth goalachieved, cost role agreed-upon joint plan. agent achievesgoal alone, utility difference worth goal costpays achieve goal. point is, agent might better alone stillderive positive utility joint plan, use worth utility baseline.new definition utility, may rational compromise.Theorem 2 Theorem 1 change every occurrence c(s ! G ) w ,theorem still true.Proof: Substitute w every occurrence c(s ! G ) proof Theorem 1.introducing worth concept definition encounter, enlargednumber encounters non-empty negotiation set. Cooperative behaviorenhanced. negotiation mechanism, makes use product maximizing protocol,becomes applicable SOD encounters.4.4 Interaction Typesdiscussion above, begun see emerging different kinds encountersagents. TOD meetings, agents really benefit coordination. SODs,184fiMechanisms Automated Negotiationisn't necessarily case. Sometimes agents benefit, sometimes called uponbear coordination overhead everyone achieve goals. even extremesituations, agents' goals may simply con ict, might impossible satisfytime, coordination overhead may exceed willingnessagents bear required burden.four possible interactions, point view individual agent:symmetric cooperative situation one exists deal negotiationset preferred agents achieving goals alone. Here, agentswelcome existence agent.symmetric compromise situation one individual rational dealsagents. However, agents would prefer alone world,accomplish goals alone. Since agent forced cope presenceother, would prefer agree reasonable deal. deals NSbetter agents leaving world initial state s.non-symmetric cooperative/compromise situation one one agent viewsinteraction cooperative (he welcomes existence agent),second views interaction compromise (he would prefer aloneworld).con ict situation one negotiation set empty|no individual rationaldeals exist.general SOD, four types interaction arise. TOD, symmetriccooperative situation ever exists.u@@@@@@@@@RG1G2Figure 7: Symmetric Cooperative Situationsituations visualized informally using diagrams. symmetriccooperative situation seen Figure 7, symmetric compromise situation Figure 8, non-symmetric cooperative/compromise situation Figure 9, con ictsituation Figure 10. point plane represents state world. ovalrepresents collection world states satisfies agent's goal. initial stateworld. triple lines emanating represent joint plan moves worldfinal state. agents share carrying joint plan.185fiZlotkin & Rosenscheinu@@@@@@@@R G1G2Figure 8: Symmetric Compromise Situationu@@@ G@@@@ 2@RG1Figure 9: Non-Symmetric Cooperative/Compromise Situationoverlap ovals represents final states satisfy goals agents A1A2 . Informally, distance either oval represents cost associatedsingle-agent plan transforms world state satisfying agent's goal.Note Figure 8, distance either agent's oval less distanceoverlap ovals. represents situation would easieragent simply satisfy goal, alone world. Figure 7, agentactually benefits existence other, since share work jointu-qG1?G2Figure 10: Con ict Situation186fiMechanisms Automated Negotiationplan. Note Figure 9, one agent benefits existence other,would prefer alone world.Let's consider simple examples slotted blocks world domain cooperative,compromise, con ict situations. initial situation depicted Figure 11, whiteblock slot 1 black block slot 2. Agent A1 wants white block aloneslot 2, agent A2 wants black block alone slot 1. either agents aloneworld, would cost 4 pickup/putdown operations achieve goal.example, A1 would pick black block slot 2 move slot 3,pick white block slot 1 move slot 2. two agents together, however,able achieve goals total cost 4. execute joint plansimultaneously pick blocks, put appropriate places.role joint plan costs 2, agent derives utility 2 reachingagreement other. cooperative situation. Coordination results actualbenefit agents.Initial State12A1s goal31A2s goal2Joint plan121233123Figure 11: Cooperative Situationlet's consider complicated, compromise, situation. initial state shownFigure 12, white block slot 1, black block slot 2, two gray blocksslot 3. Agent A1 's goal white block somewhere slot 2,table. Similarly, agent A2 's goal black block somewhere slot 1,table. Alone world, agent A1 would one pickup one putdownoperation, moving white block onto black block slot 2. way,agent A2 alone world achieve goal two operations. since(in stand-alone plan) using other's block base, achievement statesatisfies agents' goals requires additional blocks operations.best plan achieving agents' goals requires moving one gray block slot3 slot 1 gray block slot 2 act bases whiteblack blocks. block needs picked put least once; best plan187fiZlotkin & Rosenscheinblock moving total cost 8. Obviously, one agents needextra work (greater stand-alone situation) bring mutuallysatisfying state.Initial State12A1sgoal311...23Joint planA2sgoal2...123123Figure 12: Compromise Situationbest plan two roles, one requiring 6 operations one requiring 2 operations.One agent lift black (or white) block, agent rearrangesblocks appropriately. first agent put black (or white) block,completing plan. agents' worths satisfy min sum conditions (meaning,here, sum worths greater equal 8, worth greaterequal 2), reach agreement gives positive utility(using worth new baseline evaluating utility).example, let's say agent A1 assigned worth 3 achieving goal,agent A2 assigned worth 6 achieving goal. Since one role best joint plancosts 2 costs 6, one unit utility shared agents.mechanism maximizes product utilities split one unit equallyagents. done case? one deal negotiation setgives agents expected utility 21 , namely mixed joint planagent A1 cost-2 role probability 78 , cost-6 role probability1A2 course assumes complementary role. Agent A1 's expected utility8 . Agent73 , 2( 8 ) , 6( 18 ) = 12 ; equal agent A2 's expected utility 6 , 2( 18 ) , 6( 78 ) = 12 :division utility maximizes product expected utility among agents.interesting phenomenon note deal. agents apparentlysymmetric situation, apart internal attitude towards achieving goals(i.e., much willing pay). seen above,willing pay, pay. agent worth 3 endsless expected work agent worth 6. gives agents incentivemisrepresent true worth values, pretending worth values smallerreally are, agents' positions within negotiation strengthened.agent feign indifference, claim really doesn't care much achieving188fiMechanisms Automated Negotiationgoal, come better negotiation (with lower expected cost). examinequestion greater detail Section 8.final example con ict situation, shown Figure 13. Again, whiteblock slot 1 black block slot 2|the initial statecooperative compromise examples. cooperative example, agents wantedblocks moved another, empty slot. compromise example, agents wantedblocks moved specific non-empty slot. Here, con ict example, agents wantblocks moved onto specific block specific slot. Agent A1 wants whiteblock top black block slot 2; agent A2 wants black block top whiteblock slot 1. Here, real contradiction two agents' goals.exists world state satisfies both. next section, discusskinds coordination mechanisms used con ict situation.Initial State12A1sgoal31A2sgoal12131?23232Figure 13: Con ict Situationnegotiation set empty, distinguish compromisecooperative situations particular agent using following algorithm:1. w c(s ! G ); agent cooperative situation.2. w > c(s ! G ); agent might cooperative compromise situation.way distinguish follows:(a) Set w = c(s ! G ); leave agent's worths unchanged.(b) resulting NS empty, agent compromise situation.(c) Otherwise, agent cooperative situation.5. Con ict Resolution Cooperationseen cooperative compromise encounters exist dealsindividual rational agents. Agents negotiate dealsreached, one. What, however, done agents189fiZlotkin & Rosenscheincon ict situation, i.e., individual rational deals? Here, agents truecon ict needs resolved, merely choosing among mutually acceptableoutcomes.5.1 Con ict Resolutionsimple approach con ict resolution would agents ip coin decidegoing achieve goal going disappointed. See Figure 14.case negotiate probabilities (weightings) coin toss. runcon ict negotiation (fail agree coin toss weighting), worldstay initial state s.3Initial State12A1s Goal3123Flip coinA2s Goal12123123Figure 14: Con ict Resolutiondeal visualized graphically Figure 15. Single lines represent one agentplans.con ict situations agents use utility product maximizing protocoldecide weighting coin. However, turns case probability12 always results maximum product two agents' utilities. agentsmaximize utility product, always agree symmetric coin.exception initial state already satisfies one agent's goal. Then, agentsimply cause negotiation fail, rather risk moving away goal-satisfyingstate. Nevertheless, even here, product maximizing deal would agents ipsymmetric coin.symmetric coin going maximize product agent utilities? simplemathematics shows reason. Assume agent A1 worth w1, costachieving goal alone c1 . A1 wins coin toss, utility w1 , c1.utility deal coin weighting p p(w1 , c1). opponent's utility3. special case initial state already satisfies one agent's goals, let's say agent1 (s cannot satisfy goals since would con ict situation). case,agreement reached leave world state s. Agent 1 agree dealcause negotiation fail.190fiMechanisms Automated Negotiationu-qG?GbFigure 15: Con ict Situationdeal (1 , p)(w2 , c2). product two agents' utilities(p , p2 )(w1 , c1)(w2 , c2). function p maximized p equals 21 valuesw1; w2; c1; c2 (simply take derivative function set equal zero).may seem like \fair" solution, certainly ecient one.maximizing product agents' utilities, maximize sum. sumutilities maximized simply agent larger w , c achievegoal. This, hand, certainly fair solution.might able fair ecient agents able transfer utility oneanother. case, one agent could achieve goal share part utilityagent. negotiation would center much utilitytransferred! product maximizing mechanism used resolve question transferhalf gained utility agent, constant sum game, dividingutility equally maximizes utility product.entire subject explicit utility transfer side payments complicated onetreated length game theory community. intentionexamine questions paper. Even utility explicitly transferable, agentsmake commitments perform future actions, effect transfer utilitypromises. Again, many complicated issues involved assessing valuepromises, believed, discount factors, limits amountpromising debts agent accrue. agents accumulate debt indefinitely,possible always pay previous commitments making additionalcommitments others. Here, too, leaving issues aside, returningassumptions interaction stands own, explicit side paymentspossible.5.2 Cooperation Con ict Resolutioncooperative compromise situations, agents implicitly able transfer utilitysingle encounter actions joint plan. agentwork joint plan relieves agent, increasing latter's utility.thought kind utility transfer. Here, see similar kind implicit utilitytransfer possible even con ict situations.191fiZlotkin & Rosenscheinagents may find that, instead simply ipping coin con ict situation,better cooperatively reach new world state (not satisfying eithergoals) ip coin decide whose goal ultimately satisfied.Consider following example. One agent wants block currently slot 2slot 3; agent wants slot 1. addition, agents share goalswapping two blocks currently slot 4 (i.e., reverse stack's order). See Figure 16.Assume W1 = W2 = 12. cost agent achieving goal alone 10.agents decide ip coin initial state, agree weighting 21 ,brings utility 1 (i.e., 12 (12 , 10)). If, hand, decide swapcooperatively (at cost 2 each), ip coin, still agree weighting12 , brings overall utility 4 (i.e., 12 (12 , 2 , 2)).Initial State123A1s goal41234Semi-cooperativedealA2s goal2112341234Figure 16: Cooperation Certain Pointfact agents, even con ict situation, get utility first cooperatively working together, ipping coin, exploited defining newkind deal, called Semi-Cooperative Deal. want agents able negotiateagree deal allows mixed cooperative/con ict resolution interaction.Changing deal type enough make possible. ends increasing expectedutility agents derive encounter.Definition 10 Semi-Cooperative Deal tuple (t; J; q) world state, Jmixed joint plan moves world initial state intermediate state t,0 q 1 2 IR weighting coin toss|the probability agent A1 achievegoal.semantics kind deal two agents perform mixed jointplan J , bring world intermediate state t. Then, state t, ipcoin weighting q decide continues plan towards goal. allowsagents handle con ict goals, still cooperating certainpoint.192fiMechanisms Automated Negotiationutility semi-cooperative deal agent defined follows. losescoin toss intermediate state t, simply negative expected utility equalexpected cost role joint plan reached state t. wins coin tossintermediate state t, expected utility difference worth goalcosts role joint plan reached well stand-alone costmoving goal state. written formally follows:Definition 11Utility (t; J; q ) = q (w , c(J ) , c(t ! G ) ) , (1 , q )c(J )= q (w , c(t ! G ) ) , c(J )assumes, course, agents' goals con ict|the state satisfiesone agent worth other.Semi-Cooperative Deal visualized graphically Figure 17. figuresimilar spirit figures presented Section 4.4, represented cooperative,compromise, con ict encounters. Again, triple line represents joint plansingle line represents one-agent plan.uu@@@@@Rq- G1?G2Figure 17: Semi-Cooperative Deal5.3 Semi-Cooperative Deals Non-Con ict Situationscooperative compromise situations, agents negotiate deals mixedjoint plans, J : p (cooperative deals). con ict situation, agents negotiate dealsform (t; J; q ) (semi-cooperative deals).Even though semi-cooperative deals intended used con ict situations,also used cooperative compromise situations (with minor generalizationdefinition utility, discussed below). question is, kinds agreementsagents non-con ict situation reach, negotiating semi-cooperative deals?better using standard cooperative (mixed joint plan) deals?worse?cooperative deal mixed joint plan J : p also represented (J (s); J : p; 0)J (s) final world state resulting joint plan J initial state s.words, mixed deals proper subset semi-cooperative deals, mixed193fiZlotkin & Rosenscheindeal represented semi-cooperative deal special form. intermediate statetaken final state agents' cooperative joint plan. Since final statesatisfies agents' goals, result coin ip irrelevant|neither agentswants change world state anyway.Therefore, agents non-con ict situation negotiate semi-cooperativedeals, enlarging space agreements. deal reachednegotiating subset (i.e., mixed joint plans) also reached negotiatinglarger set (i.e., semi-cooperative plans). agents non-con ict situationcertainly worse, using semi-cooperative deals. better?two potential ways agents could better. first wouldagents find cheaper way achieve goals. turns impossible|semi-cooperative deals uncover ecient way achieving agents' goals.However, surprising way agents benefit semi-cooperativedeals. Agents benefit always achieving goals. using semi-cooperativedeals, give guaranteed goal satisfaction, gain expected utility.see mean, consider following example Slotted Blocks World.initial situation Figure 18 consists 5 duplications example Figure 5, slots1 15. addition, two slots (16 17) contain stack 2 blocks. Agent A1 's goal\White blocks slots 2; 5; 8; 11 14 table; blocks slots 16swapped, blocks slot 17 swapped (i.e., tower reversed)." AgentA2's goal \Black blocks slots 1; 4; 7; 10 13 table; blocksslot 16 swapped, blocks slot 17 swapped."Initial State12...31314151617151617A1s goal.12.3...1314A2s goal.1.23...1314151617Figure 18: Semi-Cooperative Agreement Cooperative Situationstand-alone cost agents is: c(s ! G ) = 26 = (5 2)+(2 8). Let's assumew = 26 also worth goal. minimal cost joint plan achievesagents' goals 7 parts:Cooperative swap slot 17 agent one pickup one putdown;swap slot 16;194fiMechanisms Automated NegotiationFive duplications joint plan Example 5. joint plansrole costs 6 role costs 2.Thus average cost agent's role joint plan 24, namely (2 2) +(5 12 (6 + 2)): Since stand-alone cost 26, situation cooperative|each agentwelcomes existence other. agents, expected utility joint plan2 (i.e., 26 , 24). cooperative deal achieves agents' goals.find semi-cooperative deal better? agents cooperatedswapping blocks slots 16 17, tossed coin see gets fulfillgoal (leaving other's goal unsatisfied)? semi-cooperative deal actually turnsbetter agents.Let intermediate state state blocks slots 16 17 swapped,slots unchanged. agent invests 4 operations part twoswaps. chance 12 continuing achieve goal, chance12 losing coin toss wasted initial investment. wins coin toss,additional 10 operations (5 2), achieve goal worth 26. Overallutility 26 , 10 , 4; i.e., 12. loses coin toss, wasted initialinvestment 4, utility ,4. expected utility average two cases,i.e., 4. better utility 2 agents got using cooperative deal!words, case, agents would prefer guaranteegoal, take gamble semi-cooperative deal. expected utility doubles,willing take risk. even cooperative situation, agents benefitnegotiating semi-cooperative deals.Now, turns borderline situation, brought w low.long w high enough, semi-cooperative deal agents agree cooperativesituation equivalent cooperative deal. achieving goal isn't worth much(your profit margin small), might willing forgo guaranteed achievementexchange higher expected utility.semi-cooperative deals, used non-con ict situation, sometimes result betteragreements (when forgoing guaranteed goal achievement beneficial), never resultworse agreements. Clearly, worthwhile agents negotiate semi-cooperativedeals, regardless whether cooperative, compromise, con ict situations.5.4 Unified Negotiation Protocols (UNP)section, make necessary generalizations agents use semicooperative deals types encounters. call product maximizing mechanismsbased semi-cooperative deals \Unified Negotiation Protocols (UNP)," sinceused con ict resolution, well cooperative agreements.4mentioned above, need generalize previous definition utilitysemi-cooperative deal, enable UNPs. Before, assumed (since con ictsituation) final state would benefit agent lost coin toss.4. earlier version subsection next two appeared (Zlotkin & Rosenschein, 1991a).current treatment incorporates new material multi-plan deals, recasts protocols contextdomain theory, alters notation correspond general domain framework.195fiZlotkin & RosenscheinNow, even though semi-cooperative deal used, final state might still satisfyagents' goals, goal agent wins coin toss.(t; J; q ) semi-cooperative deal, we'll define f final state worldagent wins coin toss state t. f = (t ! G )(t) 2 G . worth agentstate r, write W (r), goal worth w r goal state,0 otherwise. Now, revise definition utility semi-cooperative deals:Definition 12 Utility (t; J; q) = q (w , c(t ! G ) ) + (1 , q )w (f ) , c(J )jutility semi-cooperative deal (t; J; q ) agent definedexpected worth final state minus expected cost. worth expected finalstate, course, depends weighting coin, whether possible finalstates (or one) goal states agent. Similarly, expected cost dependsweighting coin (whether agent participates first, joint, plan,also continues second, lone, plan).definition utility given completely consistent earlier definitionutility cooperative deals, viewed generalization earlierdefinition. words, cooperative deal (a mixed joint plan) mappedsemi-cooperative deal (t; J; q ) using transformation discussed above, definitionutility mixed joint plan (Definition 9) definition utility (Definition 12)semi-cooperative deal yield number.sucient condition negotiation set non-empty semi-cooperativedeals agents' worths high enough, agent would able achievegoal alone:Theorem 3 agent worth goal greater equal standalone cost (i.e., 8i w c(s ! G )), negotiation set semi-cooperative dealsempty.Proof: show NS 6= ;; sucient show individual rationalsemi-cooperative deal. existence pareto-optimal deals among individual rationaldeals due compactness deal space (since finite numberagent operations, worth agent goals bounded). (s; ; q ); emptyjoint deal, individual rational q:condition sucient, necessary, negotiation set nonempty. example, consider situation given Figure 16, agents'worths equal 8 (instead 12). Neither agent achieve goal alone, thusconditions theorem satisfied. However, perfectly goodsemi-cooperative deal gives agents positive utility|they perform joint planswaps blocks slot 4, ip coin see whether block slot 2 goes slot 13. mixed deal gives agent expected utility 1. negotiation setempty.turns semi-cooperative deal negotiation set, oneagents, winning coin toss, bring world state satisfies agents'goals, exists another deal negotiation set utilityagents intermediate state already satisfies agents' goals.196fiMechanisms Automated NegotiationTheorem 4 semi-cooperative deal (t; J; q) 2 NS, exists f 2G1 \ G2, semi-cooperative deal equivalent cooperative deal.Proof: two cases: final states, one final state, G1 \ G2:f1; f2 2 G1 \ G2; view last step performing mixed joint planmoves world state state G1 \ G2 .c(t ! G1) = c(t ! G1 \ G2) = c(t ! G2 );X (t ! )(t) 2 X; c(t ! X ) = c(t ! ): f1 ; f2necessarily state, deal equivalent deal f1 = f2 :look concatenation two mixed joint plans (the first Jt, second ! G1 \ G2 ), mixed joint plan P G1 \ G2 : Pcooperative deal equivalent (t; J; q );Utility (t; J; q ) = q (w , c(t ! G )) + (1 , q )(w ) , c(J )= w , (q c(t ! G ) + c(J ) )= w , c(P )= Utility (P ):f1 2 G1 \ G2 f2 62 G1 \ G2; agent 2 would prefer lose coin tossstate let agent 1 achieve goal without spending more.deal (t; J; 1) better 1 better 2 well, dominates(t; J; q ); (t; J; q ) 2 NS; equivalent. (t; J; 1) equivalent mixedjoint plan P agents perform joint plan J t; agent 1performs one-agent plan ! G1 \ G2: P cooperative deal.words, exists semi-cooperative deal negotiation set sometimes satisfies agents' goals (depending wins coin toss), alsoexists another semi-cooperative deal negotiation set always satisfies agents'goals (equivalent cooperative deal). Even though semi-cooperative deals constitutesuperset cooperative deals, extra utility derived using semi-cooperative dealsagreement preserves mutual satisfaction agents (i.e., it's equivalentcooperative deal).cooperative situation, agents cannot extract utility semi-cooperativedeal, unless willing agree deal never satisfy agents' goals.example (Section 5.3) prototype situation. Agents increaseutility using semi-cooperative deal cooperative situation. forgoingguaranteed mutual satisfaction. theorem implies wayincrease utility semi-cooperative deals.5.5 Multi-Plan Dealssemi-cooperative deals, assume agents cooperate, ip coin, winnerproceeds alone achieve goal. arrangement requires agents engage197fiZlotkin & Rosenschein\pre- ip cooperation." agents willing (or required) also engage\post- ip cooperation"? Then, entirely new dimension agreements would openedup. section, consider kind deal exploits cooperation coin toss.illustrate potential new kind deal, consider following encounter,shown Figure 19.A1sGoalInitialState1231213?2A2sGoal123123Figure 19: Post-Flip Cooperation Helpfulinitial state world seen Figure 19. A1 's goal swap positionblocks slot 3, leave blocks slot 2 initial position. A2 's goalswap position blocks slot 2, leave blocks slot 3 initialposition.achieve goal alone, agent needs least 8 pickup putdown operations.Apparently, little room cooperation. final statesatisfies agents' goals, intermediate state (other initial state)agents cooperatively bring world, tossing coin (as semicooperative deal).Negotiating semi-cooperative deals, agents agree ip coin initialstate, whoever wins coin toss bring world goal state(at cost 8). Assume worth agent's goal 10. negotiatingsemi-cooperative deals brings agent expected utility 1. compromisesituation (alone world, agent would utility 2).agents could reach following agreement (as shown Figure 20):ip coin initial state. Whoever wins toss gets goal satisfied. However,matter wins, agents commit work together joint plan achievechosen goal.either swap jointly costs total 4 two agents (2 each). agentwins coin toss gets utility 10 , 2 (his goal satisfied expends 2joint plan). agent loses gets utility ,2 (he expends 2 joint planachieves opponent's goal). agent equal chance winning cointoss, expected utility 3. better semi-cooperative deal gave198fiMechanisms Automated Negotiation2111223123Multi-plan deal12123Figure 20: Multi-Plan Dealagents utility 1. It's even better stand-alone utility 2agents could get alone! Suddenly, situation become cooperative.agents welcome other's existence, even though goals nothing common.goal state satisfies agents; subgoals agentscommon; positive interactions agents' stand-alone plans.goals completely decoupled, yet situation cooperative.agreement above, course, requires \post- ip cooperation." semi-cooperativedeals, \pre- ip cooperation" contributed potentially either agents' benefit|eitheragent might win coin toss exploit early work. new deal type, evenagent loses coin toss required expend effort, knowingbenefit agent.agents commit post- ip cooperation, new deal typepossible. Agents could negotiate deals pairs mixed joint plans.call new deals multi-plan deals. committing post- ip cooperation, agentsenlarge space agreements, potentially improves expected utility.Definition 13Multi-Plan Deal (1; 2; q); mixed joint plan movesworld state satisfies i's goal. 0 q 1 2 IR probability agentsperform 1 (they perform 2 probability 1 , q ).Assuming j i's opponent, Utility (1; 2; q) = q(w , Cost ( )) , (1 ,q )Cost ( ).jmulti-plan deal agents agreeing two joint plans, deciding execute tossing coin. deal visualized informally Figure 21, Section 4.4above. triple line represents joint plan, carried multiple agents.Note symmetric abilities assumption Section 2.4 may essential(i.e., multi-plan deal type agents may need able perform199fiZlotkin & Rosenscheinu-qG1?G2Figure 21: Multi-Plan Dealplans equivalent cost). two mixed joint plans comprise multi-plan deal mightpure (i.e., p 0 1) without overly restricting agents' ability divideutility accurately, since agents additional q probability adjust.semi-cooperative deals used cooperative situations, multi-plan dealsalso used cooperative situations (since, see below, generalizationsemi-cooperative deals). needed enhance definition multi-plan dealutility appropriately, done semi-cooperative deals (Definition 12).Consider following example, shows increased utility available agentsshare negotiate multi-plan deals instead mixed joint plans.2111223123Multi-plan deal12123Figure 22: Relationship Multi-Plan Deal Type Mixed Joint Plansinitial state world seen Figure 22. A1 's goal swap positionblocks slot 3, leave blocks slot 2 initial position (thereone state satisfies goal; call f1 ). A2 's goal swap position blocksslot 2, leave blocks slot 3 initial position (f2 ).achieve goal alone, agent needs least 8 pickup putdown operations(each cost 1). Assume A1 's worth function assigns 10 f1 0states, A2 's worth function assigns 10 f2 0 states. case,200fiMechanisms Automated Negotiationnegotiation set includes deals (s ! f1 ; ): 1 (; ! f2 ): 0. Using protocolmentioned above, agents break symmetry situation ipping coin.utility agent deal 1 = 12 (10 , 8).Negotiation multi-plan deal type cause agents agree (1 ; 2): 12 ,mixed joint plan agents cooperatively achieve i's goal.best joint plan swap one slots costs 2 pickup/putdown operationsagent. utility agent deal 3 = ( 12 (10 , 2) + 21 (,2)).negotiating using multi-plan deal type instead mixed joint plans, utilityagents share, 6 instead 2.5.6 Hierarchy Deal Types | Summaryexists ordering relationship among various kinds deals agentsconsidered; call relationship \deal hierarchy." bottomhierarchy pure deals mixed deals. first two types deals hierarchyused cooperative situations. negotiation general non-cooperative domains,additional types deals needed.Next hierarchy come semi-cooperative deals. shown, semi-cooperativedeals superset mixed deals. Even cooperative situations, maysemi-cooperative deals achieve goals, dominate mixedjoint plans achieve agents' goals.Finally, top hierarchy, come multi-plan deals, superset semicooperative deals. general deal type deal hierarchy. deal typealso serve foundation class Unified Negotiation Protocols.summary, hierarchy looks follows:fJ g fJ : pg ft; ; qg f(1; 2): qgPure Deals Mixed Deals Semi-Cooperative Deals Multi-Plan Deals6. Unbounded Worth Goal|Tidy AgentsSection 4.3, assumed agent assigns finite worth achieving goal,upper bound cost willing spend achieve goal.upper bound exist? may situations domainslimit cost agent willing pay order achieve goal|he wouldwilling pay cost. Similarly, may situations agent simply unable,design, evaluate worth goal. However, even though worth unboundedunevaluable, agent still interested expending minimum necessary achievegoal. agent gets utility spends less, determine ordinalranking possible deals, even though diculty assigning cardinal valuesutility derived deals.Nevertheless, really interested cardinal values usednegotiation mechanisms. whole approach negotiation founded existenceinter-agent comparable cardinal utility functions. worth unboundedagents, seem deprived tool depended.201fiZlotkin & Rosenscheinwould like identify different baseline define concept utility.Originally, above, used baseline \stand-alone cost," c(s ! G ), taking utilitydeal agent difference cost achieving goal aloneagent's part deal. Then, used baseline \worth" similar manner,linearly transforming utility calculation. Utility deal agentdifference maximum cost willing pay agent's partdeal. worth unbounded, however, linear transformation obviously cannotused.work (Zlotkin & Rosenschein, 1993b), present alternative baselinesatisfy desire symmetry, fairness, simplicity, stability, eciency. turnsconstitute minimum sucient baseline agents reach agreements.minimum cost agent must offer bear compromise encounter,neither agent upper bound worth, leaves agentless cost latter's stand-alone cost. words, first agent offer\clean himself," carry sucient portion joint plan achievesgoals agent's remaining part joint plan cost lessstand-alone cost. call agent willing clean tidyagent; formal definition appears elsewhere (Zlotkin & Rosenschein, 1993b). shownjoint-goal reachable encounter (i.e., exists joint plan achievesagents' goals), agents tidy, negotiation set empty.7. Negotiation Incomplete Informationmechanisms considered sections straightforwardly implementedagents full information other's goals worths. manysituations, won't case, section examine happensnegotiating mechanisms State Oriented Domains agents don't necessarily fullinformation other.consider incomplete information goals, incomplete informationworths, two separate issues. agent, example, might particular informationworth, goals, vice versa. thus four possible cases,worths known known, combined goals known known.previous sections, considered case goals worth known.section consider two three situations, neither goals worthknown, goals known worth not. analyze situationsworth known goals not.general conclusion strategic player gain benefit pretendingworth lower actually is. done directly, declaring low worth (incertain mechanisms), declaring cheaper goal (in case stand-alone costtaken implicit worth baseline).first section, consider space lies available different typesinteractions, different types mechanisms.several frameworks dealing incomplete information, incremental goal recognition techniques (Allen, Kautz, Pelavin, & Tenenberg, 1991),framework explore \,1 negotiation phase" agents simultane202fiMechanisms Automated Negotiationously declare private information beginning negotiation (this also introducedelsewhere (Zlotkin & Rosenschein, 1989, 1993a) case TODs). negotiationproceeds revealed information true. TOD case, analyzedstrategy agent adopt playing extended negotiation game,particular, whether agent benefit declaring something true goal.Here, take similar approach, consider ,1-phase game State OrientedDomains. agents benefit lying private information? kindsmechanisms devised give agents compelling incentive telltruth?5negotiation mechanism gives agents compelling incentive tell truthcalled (in game theory) incentive compatible. Although able constructincentive compatible mechanism used worths unknown, unableconstruct mechanism State Oriented Domains used other's goalsunknown.7.1 Worth Goal Role Liesassume agents associate worth achievement particular goal.Sometimes, worth exactly equal would cost agent achieve goalhimself. times, worth goal agent exceeds cost goalagent. worth goal baseline calculating utility dealagent; section, always assume worth bounded.worth goal intimately connected specific deals agents agree on.First, agent agree deal costs worth (he wouldnegative utility deal). Second, since agents agree deal maximizesproduct utilities, agent lower worth, ultimately reduceamount work part deal. Thus, one might expect agent A1 wantsless work, try fool agent A2 thinking that, particular goal, A1'sworth lower really is. strategy, fact, often turns beneficial,seen below.Let's consider following example Slotted Blocks World.initial state seen left Figure 23. G1 \The Black blockGray block table slot 2" G2 \The White block Gray blocktable slot 1".achieve goal alone, agent execute four PickUp four PutDownoperations cost (in total) 8. two goals contradict other,exists state world satisfies both. also exists joint plan movesworld initial state state satisfies goals total cost 8|oneagent lifts black block, agent rearranges blocks suitably (bypicking putting block once), whereupon black block put down.agents agree split joint plan probability 12 , leaving expectedutility 4.5. issues, everyday human contexts, explored (Bok, 1978). immediate motivationdiscouraging lies among agents negotiation mechanisms ecient.203fiZlotkin & RosenscheinInitial State12A1sgoal3123Joint plan1A2sgoal1223123Figure 23: Agents Work Together Equally7.2 Beneficial Lies Mixed Dealsagent A1 lies true goal above, claiming wants black blockblock slot 2? See Figure 24. agent A1 alone world, couldapparently satisfy relaxed goal cost 2. Assuming agent A2 reveals true goal,agents agree one plan: agent A1 lift block (either white blackone), agent A2 rest work. apparent utility agent A10 (still individual rational), agent A2 utility 2. reality, agent A1actual utility 6. Agent A1 's lie benefited him....12311223312123Figure 24: Agent A1 Relaxes Goalworks agent A1 able reduce apparent cost carryinggoal alone (which ultimately causes carry less burden final plan),compromising ultimate achievement real goal. reason real goal204fiMechanisms Automated Negotiation\accidentally" satisfied one state satisfies agent A2 's real goalagent A1's apparent goal, coincidentally state satisfies realgoals.lie agent A1 's beneficial lie example. agent A1claimed goal \Slot 3 empty Black block clear"? See Figure 25.Interestingly, goal quite different real goal. agent A1 aloneworld, could apparently satisfy variant goal cost 4. agents forcedagree deal above: A1 two operations, apparent utility 2,agent A2 six operations, utility 2. Again, agent A1's actual utility 6.12312123312123Figure 25: Agent A1 Makes Entirely New GoalTask Oriented Domains (Zlotkin & Rosenschein, 1989, 1993a), also saw somethingsimilar lying goal. There, example, agent could hide task, lowerapparent cost stand-alone plan. Similarly, first lie agentBlocks World relaxed true goal, lowered apparent cost stand-alone plan(and thus worth). set states satisfy relaxed goal supersetset states satisfying true goal.However, major difference lying SODs lying TODs:latter, never \accidental" achievement hidden goals. lying agentalways find necessary carry hidden goal himself, mainreason subadditive TODs hiding goals beneficial. SODs, hidden goalmight achieved one's opponent, carries actions side effects. Thus,even hide goal, may fortuitously find goal satisfied fronteyes.situation visualized informally Figure 26, SOD interactionsSection 4.4 above. figure, agent A1 's expanded apparent goal states representedthicker oval labeled G01. Note expansion goal states towardinitial state s. meaning lowering one's apparent cost, necessarybeneficial lie.205fiZlotkin & Rosenscheinu@@@@@@@@RG01G1G2Figure 26: Expanding Apparent Goal States LieAlternatively, agent manufacture totally different goal purposesreducing apparent cost, saw Figure 25. Agent A1 saidwanted slot 3 empty Black block clear. Consider Figure 27, agent A1'saltered apparent goal states represented thick outline labeled G01.Note again, expansion goal states toward initial state s.u@@@@@@@RG01G1G2Figure 27: Altering Apparent Goal States Lieagent needs make sure intersection apparent goal statestrue goal states empty. Although necessary precondition successfullie, course sucient precondition successful lie. liesexample useful agent A1 regardless negotiation protocolused: pure deal, mixed deal, semi-cooperative deal, multi-plan deal.7.3 Beneficial Lies Semi-Cooperative Dealsmight seem agents con ict situation, potential beneficial liesreduced. fact, beneficial lying exist con ict situations.\Con ict" agents' goals means exist mixed joint planachieves goals also individual rational. either stateexist, joint plan costly individual rational. Evencon ict exists goals, might common subgoals, therefore beneficiallie may exist.206fiMechanisms Automated NegotiationTaking Advantage Common Subgoal Con ict Situation: Let initialstate world Figure 28. One agent wants block currently slot 2slot 1; agent wants slot 3. addition, agents share goalswapping two blocks currently slot 4 (i.e., reverse stack's order).cost agent achieving goal alone 10. Negotiating true goalsusing semi-cooperative deals would lead agents agree swap cooperatively(at cost 2 each), ip coin, weighting 12 , decide whose goalindividually satisfied. deal brings overall expected utility 2 (i.e.,12 (10 , 2) , 2).123..41232. ...1234411234Figure 28: Taking Advantage Common Subgoalagent A1 lies tells agent A2 goal is: \The Black block clearslot 1 White block Gray block"? Agent A1 thus hides factreal goal stack blocks slot 4, claims really carestack slot 2, 3 4. cost agent A1 achieving apparent goal 6,supposedly build reversed stack slot 3 cost 4. Assumingagent A2 reveals true goal, agents still agree swap cooperatively,weighting coin 47 . deal would give agent A1 apparent utility1 37 (i.e., 47 (8 , 2) , 2) also A2 's real utility (i.e., 73 (10 , 2) , 2). A1's real utility,however, 2 74 = 47 (10 , 2) , 2. lie beneficial A1 .situation illustrated Figure 29, agent A1 's lie modifies apparent goalstates closer initial state, plan still ends bringingworld one real goal states.example above, existence common subgoal agents allowedone agent exploit common subgoals (assuming, course, lying agent knewopponent's goals). lying agent relaxes true goal claiming commonsubgoal mainly opponent's demand|as far concerned (he claims), wouldsatisfied much cheaper subgoal. really necessary achieve expensivesubgoal (he claims), burden must fall opponent.207fiZlotkin & RosenscheinuuG0@@@@@R- G1q?G2Figure 29: Lying Con ict SituationOne might think absence common subgoal, wouldopportunity one agent beneficially lie other. This, however, true,see below.7.4 Beneficial Lies Multi-Plan DealsAnother Example Beneficial Lying Con ict Situation: initial stateseen Figure 30, similar example used Section 5.5 above. A1 's goalreverse blocks slot 2, leave blocks slot 1 initial position.A2 's goal reverse blocks slot 1, leave blocks slot 2 initialposition. achieve goal alone, agent needs least 8 PickUp/PutDownoperations. con ict situation.12312311223321123Figure 30: Example Interference Decoy LieNegotiation multi-plan deals cause agents agree (1 ; 2): 21 ,mixed joint plan agents cooperatively achieve i's goal. best jointplan reverse either one slots costs 2 PickUp/PutDown operationsagent. agent's utility deal 2 = ( 12 (8 , 2) , 21 (2)).208fiMechanisms Automated NegotiationAgent A1 might lie claim goal reverse blocks slot 1 leaveblocks slot 2 initial position (his real goal) white block aloneslot 2. costs A1 6 achieve apparent goal alone. reverse alone wouldcost 8, thus achieve imaginary part goal cheaper. agreement(1; 2 ): 47 , mixed joint plan agents cooperativelyachieve i's goal. turns cheaper agents cooperatively carryA1's real goal cope A1 's imaginary alternative. A1's apparent utility1 37 = 47 (6 , 2) , 37 (2). also A2 's utility. A1 's actual utility, however,2 47 = 47 (8 , 2) , 73 (2), greater unvarnished utility 2 A1 would getwithout lying. even without common subgoal, A1 beneficial lie.introduced new type lie, kind \interference decoy," used evenagents' common subgoals.8. Incomplete Information Worth GoalsConsider situation two agents encounter one another shared environment.individual goals commonly known (because prior knowledge typeagent, goal recognition process, etc.), well cost achieving goals,agent alone world. addition, con ict goals.exists non-empty set states satisfies agents' goals.agents upper bounds worth, (in contrast public goals)upper bound private information, known agent. commonsituation; agents queue access common resource, goals often selfevident. example, two agents approaching narrow bridge opposite ends mayknow wants cross, know crossing worth(e.g., long willing wait). agents need agree deal (for example,go first, wait).One simple way design negotiation mechanism handles lack informationagents exchange private information prior actual negotiation process.pre-negotiation exchange information another variant ,1-phase game mentionedabove. current case, agents exchange private information worth. section,consider situation agents negotiating mixed joint plans.One question, then, agents play ,1-phase game best advantage?mentioned Sections 4.4 7.2, agent generally incentivemisrepresent worth goal lowering it|the less agent willing pay,less pay utility product maximizing mechanism (PMM). However,everyone lowers worth may able reach agreement all, whereasdeclared true worth agreement would reached. Agents might lowerworth much driven inecient outcome. instancefree rider problem. Every agent individually motivated lower worth,someone else carry burden. group whole stands suffer, particularlyagreements reached otherwise would been.exert control tendency lower one's apparent worth careful designpost-exchange part negotiation mechanism. interested designingmechanism satisfies desire ecient, symmetric, simple, stable outcomes.209fiZlotkin & Rosenscheinresearch TODs, managed (in certain cases) provide post-exchange mechanismsatisfied attributes, also found incentive compatible|the agents'best strategy declare true goals. section, introduce two mechanismsprivate-worth SODs, one \strict," \tolerant," analyze affectsstability eciency negotiation outcomes. strict mechanism turnsstable, tolerant mechanism ecient.8.1 Strict Tolerant Mechanismsseveral cases need addressed mechanism, treateddifferently different mechanisms. example, happen one agent declaresworth lower stand-alone cost (i.e., apparently would achievegoal alone, worth him)? agent stillallowed offer deal, negotiation considered failed point?mechanisms present start way. agents simultaneouslydeclare worth value, claimed worth assign achievement goal.goals apparently achievable alone: agents declare worthgreater stand-alone cost (which commonly known), negotiation proceeds worth declarations true. agents use productmaximizing mechanism negotiation set mixed joint plans, declared worths baseline utility calculations. result equaldivision apparent available utility them.one agent's goal apparently achievable alone: one agent declaresworth greater stand-alone cost, doesn't, former agentfree decide do. either propose take-it-or-leave-it dealagent (if it's refused, he'll carry goal alone), simply bypassoffer carry goal. Since declared worth greaterstand-alone cost, rational accomplish goal himself.agents' goals apparently unachievable alone: agents declareworths lower stand-alone costs, two mechanisms differsituation handled:{ Strict Mechanism: con ict, actions carried out.{agents derive utility con ict deal.Tolerant Mechanism: agents continue negotiation firstcase (i.e., use mixed joint plans, divide apparent availableutility them). Even though agents claim unwilling achievegoals alone, may certainly case together, carryrational joint plan achieving goals.tolerant mechanism gives agents \second chance" complete negotiationsuccessfully reach rational agreement, whereas strict mechanism forgivelow worth declarations, \punishes" causing con ict. course,agents' true worths really lower stand-alone costs, strict mechanism210fiMechanisms Automated Negotiationcauses unnecessary failure (and thus inecient), tolerant mechanism stillallows reach deal possible. see below, however, tolerancesometimes lead instability.approach rest section consider various relationshipsamong two agents' worth values, cost values, interaction types, jointplans achieve agents' goals. relationship, we'll analyze strategiesavailable agents. mentioned above, considering situationsagents' goals achievable two-agent mixed joint plans (e.g., reachablestates satisfy agents' goals).idea tidy agents agent cleaning himself, introducedSection 6, used situations agents willing pay price achievegoals|their worths unbounded. There, worth could used baselineutility calculation. Instead, found \minimal sucient" valueutility baseline gave rise ecient fair mechanism. similar idea alsouseful analysis below. tidy agent baseline, explored above, also servesminimal sucient declaration point worths private information.8.2 Variables Interestgeneral, agent would like declare low worth possible, without riskingcon ict. lower declaration worth, smaller share joint plan be.Unfortunately agent, declared worth low, may eliminate possibilityreaching agreement. necessary sucient condition negotiation setempty sum min conditions, Section 4.1, hold (givendeclarations worth). Since assume joint plan achievesagents' goals, agreement still possible among plans least onesatisfies sum min conditions.several variables play role analysis below. First, agentstand-alone cost (known all, dependent goal), denoted c .Second, agent true worth (privately known) assigns achievementgoal, denoted w . total cost minimal (total cost) joint planachieves agents' goals. cost minimal role among joint planscost . Below, analyze possible configurations variables.analysis presented according interaction type con ict, i.e., symmetric cooperative, non-symmetric cooperative/compromise, symmetric compromise.type, consider three subcases depend relationships c ,w , , .rr8.3 Symmetric Cooperative Situationsymmetric cooperative situations, one strategy agent use declareworth minimum true worth, maximum stand-alone costminimal role joint plan:Min-Sucient Strategy min(w ; max(c ; )):211rfiZlotkin & Rosenscheinmotivation agent wants declare minimal worth sucientagreement. Declaring c satisfies sum condition, make surealso satisfies min condition, agent must declare max(c ; ). make suredeclaration individual rational, must make declaration greater trueworth, w ; thus, takes minimum w (c ; ) maximum.Min-Sucient Strategy one possible strategy might adopted. However, agents adopt it, strategy equilibrium (in cases),agreement guaranteed. analyze characteristics strategy sixcases.rr8.3.1 Goals Achievable Alonesituation (as shown Figure 31), agents would able achieve positiveutility agent around, achieved stand-alone goalthemselves.Equilibrium PointW1conflictC1A1 decidesMrNegotiationA2 decidesMrC2W2Figure 31: Goals Achievable Alonediagram Figure 31 describes, sense, game normal form. agentdeclare worth number 0 infinity. outcome depends twonumbers declared; every point plain possible result. colors regionsdenote types outcomes.Note, example, agent A1 declares less c1 , agent A2 declaresc2 , outcome A2 decide (offering A1 take-it-or-leave-it deal,going alone). A1 A2 offer little (so sum less ),reach con ict. assume agents rational, consider areasplain framed w1 w2 (rational agents would declare worth greatertrue worths).difference Strict Tolerant mechanisms mentioned colortriangle lower left c1=c2 point. Strict mechanism, wouldwhite (con ict), Tolerant mechanism still region allows subsequentnegotiation occur. point equilibrium mechanisms c1 =c2point, reached Min-Sucient Strategy given above. Thus, strategystable ecient Strict Tolerant mechanisms situation.212fiMechanisms Automated Negotiation8.3.2 One Goal Achievable AloneAssume situation shown Figure 32, one agent would ableachieve positive utility agent around (though ultimatelybenefit other's existence, one other).Equilibrium PointW1conflictC1A1 decidesMrNegotiationA2 decidesMrW2 C2Figure 32: One Goal Achievable Alonephenomenon similar Section 8.3.1. negotiation trianglelower left c1 =w2 white (con ict) Strict mechanism negotiableTolerant mechanism. mechanisms, c1=w2 point equilibrium,point results agents play Min-Sucient Strategy. Again, strategystable ecient Strict Tolerant mechanisms situation.8.3.3 Goals Achievable Aloneconsider situation shown Figure 33, neither agent could achieve positiveutility alone world|the way achieve goals cooperating.ResultingNon-equilibrium PointconflictC1W1A1 decidesMrNegotiationA2 decidesMrW2 C2Figure 33: Goals Achievable AloneAgain, negotiation triangle lower left w1=w2 white (con ict)Strict mechanism, agreement reached situation (the whole plain is,fact, white). Though Min-Sucient Strategy ecient Strict mechanism,213fiZlotkin & Rosenscheinstable. Tolerant mechanism, Min-Sucient Strategy ecient (it resultsw1=w2 point), unfortunately stable|assuming one agent declaresw1, agent benefit declaring , w1 instead w2 .fact, agents actually know situation (the one Figure 32Figure 33), guaranteed beneficial divergence equilibrium point would reallyrequire total knowledge situation opponent playing. Thus, althoughMin-Sucient Strategy stable, agents may unlikely divergereal-world constraints knowledge.8.4 Non-Symmetric Cooperative/Compromise Situationsection continue analysis situations one agent, situationcooperative, other, compromise situation. continue analyzecase agents use Min-Sucient Strategy. Agreement reachedcompromising agent contributes stand-alone cost joint plan;minimal role greater stand-alone cost. wayagents reach agreement compromising agent willingstand-alone cost|otherwise, con ict.8.4.1 Compromise Sufficientsituation described Figure 34, true worth compromising agent (w2)greater minimal role c2.Equilibrium PointW1C1conflictA1 decidesMrNegotiationA2 decidesC2 MrW2Figure 34: Compromise Sucientsucient compromising agent declare true worth. declaredless that, agent declared c1, reach con ict;declaring , guarantees goal achieved. diagramStrict Tolerant Mechanisms. Min-Sucient Strategy brings agentsc1=M point, stable ecient result (for mechanisms).rrr214fiMechanisms Automated Negotiation8.4.2 Compromise, EnoughConsider situation, portrayed Figure 35, w2 less ,rational agent A2 compromise declare worth greater w2. MinSucient Strategy brings agents c1=w2 point, con ict.rW1C1conflictA1 decidesNegotiationMrA2 decidesC2 W2 MrFigure 35: Compromise, Enoughpicture identical Strict Tolerant mechanisms. agentsuse Min-Sucient Strategy, resulting point (c1=w2) ecient, even thoughstable.6 However, enhanced mechanism con ict-resolution techniques,allowed agents negotiate multi-plan deals Section 5.5 (or even semicooperative deals Section 5.3), conjecture result c1 =w2 wouldstable ecient. enhancement, however, beyond scope work describedpaper.8.4.3 Reason Compromisesituation shown Figure 36, non-compromising agent A1 cannot achievegoal alone. Min-Sucient Strategy declare something less c1 (eitherw1 ), result agent A2 option decidedo|and reasonable decision A2 achieve goal alone (therereason compromise).result ecient stable, Strict Tolerant mechanisms.r8.5 Symmetric Compromise Situationsection continue analysis situations agents,compromise situation. agents stand-alone costsorder achieve goals.6. Con ict ecient result one agent achieves goal, rather agentsnothing, would ecient.215fiZlotkin & RosenscheinEquilibrium PointC1W1conflictA1 decidesMrNegotiationA2 decidesC2MrW2Figure 36: Reason Compromisesection, propose another strategy agents could use, namelyMin-Concession Strategy:Min-Concession Strategy min(w ; (c + , (c21 + c2 ) )):situation, agent choosing propose (as true worth)stand-alone cost, ensure agreement reached. However, would likepropose minimal sucient concession, enough enable agreement. MinConcession Strategy agents make concession. overall strategyanalyzing (and covers cases section) use Min-Concession Strategysymmetric compromise situations, otherwise use Min-Sucient Strategy (aspresented above). Agents know kind situation (and thus strategyuse) stand-alone costs common knowledge.8.5.1 Agents Compromise Equallyagents situation compromise equally (as shown Figure 37),use Min-Concession Strategy, end point (c1 +)=(c2 +)(where = (T , c1 , c2)=2). point ecient stable, StrictTolerant mechanisms.8.5.2 Non-Symmetric Compromise, Goals Achievedagents symmetric compromise situation, one one agent needscompromise (as Figure 38), use Min-Concession Strategyresults point (c1 +)=w2. point con ict, unfortunately neither stableecient.result stable A1 could make greater compromise benefitit. result ecient even one agent could achieve goal,would superior con ict outcome. dicult imagine strategieswould lead agents ecient solutions (e.g., declare , c agent i, TidyAgent would Section 6), would stable, either. hand,j216fiMechanisms Automated NegotiationEquilibrium PointW1conflictC1+A1 decidesC1NegotiationMrA2 decidesMrC2 C2+W2Figure 37: Agents Compromise EquallyW1conflictC1+C1A1 decidesMrNegotiationA2 decidesMrC2 W2 C2+Figure 38: Non-Symmetric Compromise, Goals Achieved217fiZlotkin & Rosenscheinnegotiation mechanism enhanced con ict-resolution techniques (such multiplan deals semi-cooperative deals), conjecture Min-Concession Strategystable ecient. enhancement, however, also beyond scopework described paper.8.5.3 One Agent Cannot CompromiseConsider situation one agent cannot compromise (because could evenachieve goal alone), shown Figure 39. case, agents use MinConcession Strategy, result (c1 + )=w2. Agent 1 choose achievegoal alone (and compromise). outcome stable ecient.Equilibrium PointW1conflictC1+C1A1 decidesMrNegotiationA2 decidesMrW2 C2 C2+Figure 39: One Agent Cannot Compromise8.6 Summary Strict Tolerant Mechanismsresults analysis summarized Figure 40. tradeoffeciency stability apparent symmetric cooperative case, neitheragent able achieve goal alone. strict mechanism, con ict caused simplyagent declare worth higher stand-alone cost, thusbring immediate con ict. tolerant mechanism gives agents second chancereach agreement, unstable (as described above).mechanism incentive compatible. agents incentivedeclare true worths; rather, use Min-Sucient Strategy decideoptimal declaration is.9. Related Work Game Theory DAIsection review research game theory distributed artificial intelligencerelated work.9.1 Related Work Game Theorymentioned beginning paper, research relies heavily existing gametheory tools use design evaluate protocols automated agents. Here,218fiMechanisms Automated NegotiationStrictEfficientStableTolerantEfficientStableSymmetric Cooperationboals achievable aloneOne goal achievable alonegoals arent achievable aloneNon-Symmetric Cooperation/CompromiseCompromise sufficientCompromise insufficientreason compromiseSymmetric CompromiseAgents compromise equallyAgents cant compromise equallyOne agent cant compromiseFigure 40: Summary Strict Tolerant Mechanismsreview game theory work Bargaining Theory, Mechanism Design ImplementationTheory, Correlated Equilibria.9.1.1 Bargaining TheoryClassic game theory (Nash, 1950; Zeuthen, 1930; Harsanyi, 1956; Roth, 1979; Luce & Raiffa,1957) talks players reaching \deals," defined vectors utilities (oneplayer). bargaining game end possible outcome (i.e., \deal").player full preference order set possible outcomes; preference orderexpressed utility function. deal, utility vectorlist utilities deal every participant. special utility vector called\con ict" (or sometimes \status quo point") utility player assignscon ict (that is, lack final agreement). Classic game theory deals followingquestion: given set utility vectors, utility vector playersagree (under particular assumptions)? words, classic bargaining theoryfocused prediction outcomes, certain assumptions playersoutcomes themselves.Nash (Nash, 1950, 1953) showed rational behavior assumptions (i.e.,individual rational pareto optimal behavior), symmetry assumptions, players219fiZlotkin & Rosenscheinreach agreement deal maximizes product players' utility (see Section 4.2 complete discussion).alternative approach negotiation, looks upon dynamic, iterative process, discussed work Rubinstein Osborne (Rubinstein, 1982, 1985; Osborne& Rubinstein, 1990).Game theory work negotiation assumes negotiation game welldefined. assumes set possible deals players evaluating usingcertain utility functions. Therefore, deals players' utility functions induce setutility vectors forms basis negotiation game.contrast analysis given, well-defined negotiation encounter, exploring design space negotiation games. Given multiagent encounter (involving,example, task redistribution), design assortment negotiation games, formulatingvarious sets possible deals various kinds utility functions agents may have.given negotiation game, use game theory approaches analyzeevaluate negotiation mechanisms propose.Game theorists usually concerned games played,descriptive normative point view. essentially constructive point view;since game theory tells us, given game, played, endeavor designgames good properties played game theory predicts.9.1.2 EquilibriumGame solutions game theory consist strategies equilibrium; somehow socialbehavior reaches equilibrium, agent incentive diverge equilibriumbehavior. equilibrium considered solution game. may one(or no) strategies equilibrium, also different notions equilibriumgame theory literature.Three levels equilibrium commonly used game theory Nash equilibrium,perfect equilibrium, dominant equilibrium (Binmore, 1990; Rasmusen, 1989). levelequilibrium enumerated stronger previous one. Two strategies S;Nash equilibrium if, assuming one agent using , agent cannot betterusing strategy , vice versa. Perfect equilibrium meansgame multiple steps, one player using , exists state gameplayer better sticking strategy . existsituations strategies might Nash equilibrium, perfect equilibrium;case, although strategy best start game, game unfoldswould better diverge . Dominant strategy equilibrium means matterstrategy opponent chooses, cannot better play strategy ; strategiesdominant strategy equilibrium dominant strategy oneplayer, dominant strategy other.work, generally use Nash equilibrium (the weakest equilibrium concept)requirement solution; provides us widest range interaction solutions.times, solution inherently perfect equilibrium, introducedadditional rules interaction, compel agents follow particular Nash equilibrium220fiMechanisms Automated Negotiationstrategies game progresses (such introducing penalty mechanism breakingpublic commitment).provides interesting example power wield designers game.First, would normally require perfect equilibria multiagent encounters,adopt Nash equilibria sucient needs, impose rules keep agentsdeviating Nash equilibrium strategies. Second, strong requirementdominant equilibrium, might desirable two arbitrary agents play givengame, needed recommended strategies commonly known|Nash equilibrium sucient.9.1.3 Mechanism Design Implementation Theoryalso groups game theorists consider problem design gamescertain attributes. area mechanism design closestconcerns, design protocols automated agents.Mechanism design also known game theory literature implementationproblem. implementation question (Binmore, 1992; Fudenberg & Tirole, 1992) askswhether mechanism (also called game form ) distinguishable equilibriumpoint (dominant strategy, perfect, merely Nash) social profile (i.e.,group behavior) associated, players follow equilibrium strategies,desired outcome.words, assumed group agents, utilityfunction preferences possible social outcomes. also social welfare functionrates possible social outcomes (e.g., socially ecient agreement mayrated higher non-ecient one) (Arrow, 1963). question then, one designgame unique solution (equilibrium strategies),individual agent behaves according equilibrium strategy, social behaviormaximize social welfare function. game designed, saidgame implements social welfare function.example social welfare function, consider minimization pollution.everyone may interested lowering pollution levels, everyone interested othersbearing associated costs. mechanism implement social welfare function mightinclude, example, taxes polluting industries tax credits given purchaseelectric cars. precisely kind mechanism would cause agents, followingequilibrium strategy, minimize pollution.Given negotiation game designed (i.e., set deals utility functions),also design actual negotiation mechanism. One important attributesnegotiation mechanism eciency, i.e., maximization total group's utility.social welfare function trying implement. assumeagents incomplete information one another's utility function, basically(negotiation) mechanism design problem.However, unlike classic mechanism design game theory, satisfied (negotiation) mechanism Nash equilibrium point implements eciency.need uniqueness, need stronger notion equilibrium (i.e., dominant equilibrium). negotiation mechanism design intended suggestion community221fiZlotkin & Rosenscheinagents' designers, along negotiation strategy. negotiation mechanismstrategy part suggested standard. make standard self-enforcingsucient strategy part standard Nash equilibrium.9.1.4 Correlated EquilibriumPlayers sometime communicate prior actually playing game. communicating,players coordinate strategies even sign binding contracts strategiesuse. Contracts various types. agent commitplaying pure strategy agent commits playing another pure strategy. Agentsalso commit contract ip coin play strategyaccording coin.contract thus seen agreement players correlatestrategies. correlated strategy general case probability distributionpossible joint activities (i.e., strategy combinations) players. order playersplay according correlated strategy, mediator conductlottery, choose joint activity according agreed probabilities, suggeststrategy players. cases mediator assumed release playerinformation player's action (strategy) chosen joint action,player's action.Contracts players binding; however, cannot assume contractsbinding cases. Even contracts binding, selfenforcing. contract self-enforcing player signs contract cannotbetter following contract, assumption agents followingcontract. mediator's communications observable players,self-enforcing non-binding contracts randomize among Nashequilibria original game ((Myerson, 1991), pp. 251).Self-enforcing contracts correlated strategy called correlated equilibria. Aumannintroduced term correlated equilibrium (Aumann, 1974); defined correlated equilibrium given game Nash equilibrium extension game,players receive private signals original game actually played. Aumann alsoshowed (Aumann, 1987) correlated equilibrium defined terms Bayesianrationality. Forges extended approach games incomplete information (Forges,1993).Myerson showed correlated equilibrium specific case general concept equilibrium, called communication equilibrium, games incompleteinformation (Myerson, 1982, 1991).deal types defined involve coin ipping. is,course, directly related notion correlated strategies. correlated equilibrium theory, also assume agents able agree deals (i.e., contracts)involve jointly observed random process (e.g., coin toss). However, unlike correlatedequilibrium theory, assume contracts binding. Therefore, assumeagents follow contract (whatever result coin ip) evenlonger rational agent so. Relaxation binding agreement assumption,222fiMechanisms Automated Negotiationdesigning negotiation mechanisms based self-enforcing correlated strategies,part future research plans.9.2 Related Work Distributed Artificial Intelligenceseveral streams research Distributed Artificial Intelligence (DAI)approached problem multiagent coordination different ways.brie review work, categorizing general areas multiagent planning,negotiation, social laws, economic approaches.9.2.1 Multiagent PlanningOne focus DAI research \planning multiple agents," considersissues inherent centrally directed multiagent execution. Smith's Contract Net (Smith,1978, 1980) falls category, DAI work (Fox, Allen, & Strohm, 1982;Rosenschein, 1982; Pednault, 1987; Katz & Rosenschein, 1993). second focus research\distributed planning," multiple agents participate coordinatingdeciding upon actions (Konolige & Nilsson, 1980; Corkill, 1982; Rosenschein & Genesereth, 1985; Rosenschein, 1986; Durfee, Lesser, & Corkill, 1987; Zlotkin & Rosenschein,1991b; Ephrati & Rosenschein, 1991; Pollack, 1992; Pope, Conry, & Mayer, 1992).question whether group activity fashioned centrally distributedmanner one axis comparison. Another important issue distinguishesvarious DAI research efforts whether goals need adjusted, is,whether may fundamental con icts among different agents' goals. Thus,example, Georgeff's early work multiagent planning assumed basiccon ict among agent goals, coordination necessary guaranteesuccess (Georgeff, 1983, 1984; Stuart, 1985). Similarly, planning context Lesser,Corkill, Durfee, Decker's research (Decker & Lesser, 1992, 1993b, 1993a) often involvescoordination activities (e.g., sensor network computations) among agentsinherent con ict one another (though surface con ict may exist). \Planning"means avoidance redundant distracting activity, ecient exploration searchspace, etc.Another important issue relationship agents one another, e.g.,degree willing compromise goals one another (assumingcompromise necessary). Benevolent Agents that, design, willingaccommodate one another (Rosenschein & Genesereth, 1985); builtcooperative, share information, coordinate pursuit (at least implicit)notion global utility. contrast, Multiagent System agents cooperatebest interests (Genesereth, Ginsberg, & Rosenschein, 1986). Stillanother potential relationship among agents modified master-slave relationship, called\supervisor-supervised" relationship, non-absolute control exerted one agentanother (Ephrati & Rosenschein, 1992a, 1992b).synthesis, synchronization, adjustment process multiple agent plans thus constitute (varied) foci DAI planning research. Synchronization con ictavoidance (Georgeff, 1983, 1984; Stuart, 1985), distribution single-agent planner amongmultiple agents (Corkill, 1979), use centralized multiagent planner (Rosenschein,223fiZlotkin & Rosenschein1982), use consensus mechanisms aggregating subplans produced multiple agents (Ephrati & Rosenschein, 1993b), explored, well relatedissues (Cohen & Perrault, 1979; Morgenstern, 1987; von Martial, 1992a, 1992b; Kreifelts& von Martial, 1991; Kamel & Syed, 1989; Grosz & Sidner, 1990; Kinny, Ljungberg, Rao,Sonenberg, Tidhar, & Werner, 1992; Ferber & Drogoul, 1992; Kosoresow, 1993).paper, dealing classical problems planning research(e.g., construction sequences actions accomplish goals). Instead, takengiven agents capable deriving joint plans domain, considered might choose among alternative joint plans satisfy potentiallycon icting notions utility. help agents bridge con icts, introduced frameworks plan execution (such ipping coin decide two joint planscarried out), actual base planning mechanism subject work.9.2.2 Axiomatic Approaches Group Activityexists large growing body work within artificial intelligence attemptscapture notions rational behavior logical axiomatization (Cohen & Levesque,1990, 1991; Rao, Georgeff, & Sonenberg, 1991; Rao & Georgeff, 1991, 1993; Georgeff &Lansky, 1987; Georgeff, 1987; Belegrinos & Georgeff, 1991; Grosz & Kraus, 1993; Konolige,1982; Morgenstern, 1990, 1986; Kinny & Georgeff, 1991). approach usually centersformalized model agent's beliefs, desires, intentions (the so-called \BDImodel") (Hughes & Cresswell, 1968; Konolige, 1986). purpose formal modelcharacterize precisely constitutes rational behavior, intent imposerational behavior automated agent. formal axioms might used run-timedirectly constrain agent's decision process, (more likely) could usedcompile-time produce ecient executable module.focus research, coming single-agent artificial intelligenceperspective, architecture single automated agent. example, CohenLevesque explored relationship choice, commitment, intention (Cohen& Levesque, 1987, 1990)|an agent commit certain plans action,remain loyal plans long appropriate (for example, agent discoversplan infeasible, plan dropped).Even looking multiagent systems, researchers examined member group designed|again, looking design individual agentproductive group member. example, certain work (Kinny et al., 1992)axioms proposed cause agent, discovers fail fulfillrole joint plan, notify members group. Axiomatizations, however,might need deal groups agents could joint commitment accomplishing goal (Cohen & Levesque, 1991), agent make interpersonalcommitments without use notions (Grosz & Kraus, 1993). Another useBDI abstractions allow one agent reason agents, relativize one'sintentions terms beliefs agents' intentions beliefs.Axiomatic approaches tend closely link definitions behavior internal agentarchitecture. Thus, definition commitment explored Cohen Levesque intended constrain design agent, behave certain way.224fiMechanisms Automated Negotiationwork, hand, takes arms-length approach question constrainingagents' public behavior. rules encounter really specification domain(not agent), agent designer free build agent internally howeversees fit. rules themselves, however, induce rational designers build agentsbehave certain ways, independent agents' internal architectures.9.2.3 Social Laws Multiple AgentsVarious researchers Distributed Artificial Intelligence suggested wouldworthwhile isolate \aspects cooperative behavior," general rules would causeagents act ways conducive cooperation. hypothesis agents actcertain ways (e.g., share information, act predictable ways, defer globally constrainingchoices), easier carry effective joint action (Steeb, Cammarata,Hayes-Roth, & Wesson, 1980; Cammarata, McArthur, & Steeb, 1983; McArthur, Steeb, &Cammarata, 1982).Moses, Shoham, Tennenholtz (Tennenholtz & Moses, 1989; Moses & Tennenholtz,1990; Shoham & Tennenholtz, 1992b, 1992a; Moses & Tennenholtz, 1993; Shoham & Tennenholtz, 1995), example, suggested applying society metaphor artificialsystems improve performance agents operating system. issuesdealt analyzing multiagent environment concern synchronization, coordination agents' activities, cooperative ways achieve tasks, safetyfairness constraints system guaranteed. propose coordinating agentactivity avoid con icts; system structured agents arrivepotential con ict situations.Thus social laws seen method avoid necessity costly coordinationtechniques, like planning negotiation. agents following appropriate social laws,need run-time coordination reduced. important, althoughagent designers may willing invest large amount effort design time buildingeffective multiagent systems, often critical run-time overhead lowpossible.similarity use pre-compiled, highly structured social laws,development pre-defined interaction protocols. However, social law approachassumes designers laws full control agents; agents assumed follow social laws simply designed to,individually benefit social laws. Obeying social laws may \stable";assuming everyone else obeys laws, agent might better breaking them.approach concerned social conventions stable, suitableindividually motivated agents.9.2.4 Decision Theoretic Approachesrelated work Artificial Intelligence addresses reasoning process singleagent decision-theoretic terms. certain work (Horvitz, 1988; Horvitz, Cooper, & Heckerma, 1989; Russell & Wefald, 1989), decision-theoretic approaches used optimizevalue computation uncertain varying resource limitations. Etzioni consideredusing decision-theoretic architecture, learning capabilities, control problem solving225fiZlotkin & Rosenscheinsearch (Etzioni, 1991). introductory treatment decision theory itself, see Raiffa'sclassic text subject (Raiffa, 1968).Classical decision theory research considers agent \playing nature,"trying maximize utility uncertain circumstances. key assumption \nature's"behavior independent decision made agent. course, assumptionhold multiagent encounter.concept \rationality," usually expressed decision-theoretic terms,used model agent activity multiagent encounters (Rosenschein & Genesereth, 1985;Genesereth et al., 1986). Here, axioms defining different types rationality, alongassumptions rationality others, led agents particular choices action.contrast work, research employs standard game theory notions equilibriumrationality. discussions use rationality general reasoning foundDoyle's research (Doyle, 1985, 1992).Another decision theoretic approach, taken Gmytrasiewicz Durfee,used model multiagent interactions (Gmytrasiewicz, Durfee, & Wehe, 1991a, 1991b;Gmytrasiewicz & Durfee, 1992, 1993). assumes predefined protocol structureinteraction (in marked contrast research protocol design). research usesdecision-theoretic method coordinating activities autonomous agents calledRecursive Modeling Method. agent models agents recursive manner,allowing evaluation expected utility attached potential actions communication.9.2.5 Economic Approachesseveral attempts consider market mechanisms way ecientlyallocating resources distributed system. Among AI work Smith's ContractNet (Smith, 1978, 1980; Sandholm, 1993), Malone's Enterprise system (Malone et al., 1988),Wellman's WALRAS system (Wellman, 1992).Contract Net high-level communication protocol Distributed ProblemSolving system. enables distribution tasks among nodes operatesystem. contract two nodes established tasks executed;node net act either manager contractor. taskassigned node decomposed contractor. contract establishedbidding scheme includes announcement task manager, bidssent potential contractors.Enterprise (Malone et al., 1988) system built using variation Contract Net protocol. Distributed Scheduling Protocol locates best available machineperform task. protocol similar Contract Net, makes usewell-defined assignment criteria.Another system (Wellman, 1992) takes economic approach solving distributed problem use price mechanism explored Wellman.Wellman uses consumer/producer metaphor establish market pricing-based mechanism task redistribution ensures stability eciency. agents actconsumers producers. distinct good auction associated it, agentsget good submitting bids auction good. system developedWellman, WALRAS, computes market equilibrium price.226fiMechanisms Automated Negotiationtwo main differences economic approaches workmechanism design. First, underlying assumption economic approachutility explicitly transferable (e.g., money used). work involveneed explicit utility transfer. Instead, exploit various methods implicit utilitytransfer, example, sharing work joint plan, tossing coin, etc. course,constrains available coordination mechanism, removes assumption (that is,existence money) may suitable certain multiagent environments. Second,economic models deal n agents market, work dealstwo-agent encounters; however, work deals n-agent negotiationcoalition formation problem (Zlotkin & Rosenschein, 1994).9.2.6 NegotiationNegotiation subject central interest DAI, economicspolitical science (Raiffa, 1982). word used variety ways, thoughgeneral refers communication processes coordination (Smith, 1978; Lesser& Corkill, 1981; Kuwabara & Lesser, 1989; Conry et al., 1988; Kreifelts & von Martial,1991; Kraus, Ephrati, & Lehmann, 1991). negotiating procedures includedexchange Partial Global Plans (Durfee, 1988; Durfee & Lesser, 1989), communicationinformation intended alter agents' goals (Sycara, 1988, 1989), useincremental suggestions leading joint plans action (Kraus & Wilkenfeld, 1991).Interagent collaboration Distributed Problem Solving systems exploredongoing research Lesser, Durfee, colleagues. Much work focusedimplementation analysis data fusion experiments, systems distributedsensors absorb interpret data, ultimately arriving group conclusion (Durfee &Lesser, 1987; Decker & Lesser, 1993a; L^aasri, L^aasri, & Lesser, 1990). Agents exchangepartial solutions various levels detail construct global solutions; much workexamined effective strategies communication data hypotheses among agents,particular kinds relationships among nodes aid effective group analysis.example, different organizations, different methods focusing node activity,help system whole far ecient.two main distinctions work work Lessercolleagues. First, underlying assumption bulk Lesser's work agentsdesigned implemented part unified system, work towards global goal.agents, hand, motivated achieve individual goals. Second, unlikeformal approach mechanism design, Lesser's work historically heuristicexperimental, although recent work explored theoretical basissystem-level phenomena (Decker & Lesser, 1992, 1993a, 1993b).Sycara examined model negotiation combines case-based reasoningoptimization multi-attribute utilities (Sycara, 1988, 1989). particular, assumeagents' goals fixed negotiation, Sycara specifically interestedagents uence one another change goals process negotiation(information transfer, etc.).Kraus colleagues explored negotiation negotiation timeissue (Kraus & Wilkenfeld, 1991; Kraus, 1993; Kraus, Wilkenfeld, & Zlotkin, 1995). Agents227fiZlotkin & Rosenscheinmay lose value negotiation drags long, different agents asymmetricregard cost negotiation time. Agents' attitudes towards negotiation timedirectly uences kinds agreements reach. Interestingly, however,agreements reached without delay. avoidable ineciency delayingagreement. work, contrast, assumes agent utility remains constant throughoutnegotiation process, negotiation time uence agreement.Kraus' work also assumes explicit utility transfer (while work, mentioned above,not).Gasser explored social aspects agent knowledge action multiagentsystems (\communities programs") (Gasser, 1991, 1993). Social mechanisms dynamically emerge; communities programs generate, modify, codifylocal languages interaction. Gasser's approach may effective agentsinteracting unstructured domains, domains structure continuouslychanging. research present, hand, exploits pre-designed social layermultiagent systems.work focuses organizational aspects societies agents exists (Fox,1981; Malone, 1986).Ephrati Rosenschein used Clarke Tax voting procedure consensus mechanism, essence avoid need classical negotiation (Ephrati & Rosenschein, 1991,1992c, 1993a). mechanism assumes ability transfer utility explicitly. ClarkeTax technique assumes (and requires) agents able transfer utilitysystem (taxes paid agents). utility transferred systemactually wasted, reduces eciency overall mechanism. This, however,price needs paid ensure stability. Again, work present paperassume explicit transfer utility. Also, negotiation mechanism ensuresstability without ineciency transferring utility system. However, votingmechanisms like Clarke Tax deal n-agent agreement (not two-agent agreement research), also demonstrates kind dominant equilibrium (in contrastweaker notion Nash equilibrium).10. Conclusionspaper explored State Oriented Domains (SODs). State Oriented Domainscurrent description world modeled state, operators cause worldmove one state another. goal agent transform worldone collection target states. SODs, real con ict possible agents,general, agents may find four possible types interactions, symmetriccooperative, symmetric compromise, non-symmetric cooperative/compromise, con ict.Agents negotiate different deal types kinds interactions;particular, introduced semi-cooperative deal, multi-plan deals, use con ict situations. Unified Negotiation Protocols, product maximizing mechanisms basedeither semi-cooperative deals multi-plan deals, provide suitable basis con ictresolution, well reaching cooperative agreements.Strategic manipulation possible SODs. State Oriented Domain, agent mightmisrepresent goals, worth function, gain advantage negotiation.228fiMechanisms Automated Negotiationgeneral approach deceitful agent would pretend worth loweractually is. done directly, declaring low worth (in certain mechanisms),declaring cheaper goal (in case stand-alone cost taken implicitworth baseline). able construct incentive compatible mechanisms usedworths unknown, unable SODs goals unknown.Acknowledgementspaper submitted Gilad Zlotkin aliated Center Coordination Science, Sloan School Management, MIT. research began Zlotkinaliated Institute Computer Science Hebrew University Jerusalem,supported Leibniz Center Research Computer Science. materialpaper appeared preliminary form AAAI, IJCAI, ICICIS conferencepapers (Zlotkin & Rosenschein, 1990, 1991b; Rosenschein, 1993; Zlotkin & Rosenschein,1993c) journal article (Zlotkin & Rosenschein, 1991a) (earlier version materialUNP protocol). research partially supported Israeli MinistryScience Technology (Grant 032-8284) Israel Science Foundation (Grant032-7517). would like thank anonymous reviewers contributed improvement paper.ReferencesAllen, J. F., Kautz, H. A., Pelavin, R. N., & Tenenberg, J. D. (1991). ReasoningPlans. Morgan Kaufmann Publishers, Inc., San Mateo, California.Arrow, K. J. (1963). Social Choice Individual Values. John Wiley, New York.Aumann, R. (1987). Correlated equilibrium expression bayesian rationality. Econometrica, 55, 1{18.Aumann, R. J. (1974). Subjectivity correlation randomized strategies. JournalMathematical Economics, 1, 67{96.Belegrinos, P., & Georgeff, M. P. (1991). model events processes. ProceedingsTwelfth International Joint Conference Artificial Intelligence, pp. 506{511Sydney, Australia.Binmore, K. (1990). Essays Foundations Game Theory. Basil Blackwell, Cambridge, Massachusetts.Binmore, K. (1992). Fun Games, Text Game Theory. D. C. Heath Company,Lexington, Massachusetts.Bok, S. (1978). Lying: Moral Choice Public Private Life. Vintage Books, New York.Cammarata, S., McArthur, D., & Steeb, R. (1983). Strategies cooperation distributedproblem solving. Proceedings Eighth International Joint Conference Artificial Intelligence, pp. 767{770 Karlsruhe, West Germany.229fiZlotkin & RosenscheinCohen, P. R., & Levesque, H. J. (1987). Intention = choice + commitment. Proceedings Sixth National Conference Artificial Intelligence, pp. 410{415 Seattle,Washington.Cohen, P. R., & Levesque, H. J. (1990). Intention choice commitment. ArtificialIntelligence, 42 (2{3), 213{261.Cohen, P. R., & Levesque, H. J. (1991). Teamwork. Technote 503, SRI International, MenloPark, California.Cohen, P. R., & Perrault, C. R. (1979). Elements plan-based theory speech acts.Cognitive Science, 3, 177{212.Conry, S. E., Meyer, R. A., & Lesser, V. R. (1988). Multistage negotiation distributedplanning. Bond, A., & Gasser, L. (Eds.), Readings Distributed Artificial Intelligence, pp. 367{384. Morgan Kaufmann Publishers, Inc., San Mateo.Corkill, D. D. (1979). Hierarchical planning distributed environment. ProceedingsSixth International Joint Conference Artificial Intelligence, pp. 168{175 Tokyo.Corkill, D. D. (1982). Framework Organizational Self-Design Distributed ProblemSolving Networks. Ph.D. thesis, University Massachusetts, Amherst, MA.Decker, K. S., & Lesser, V. R. (1992). Generalizing partial global planning algorithm.International Journal Intelligent Cooperative Information Systems, 1(2), 319{346.Decker, K. S., & Lesser, V. R. (1993a). approach analyzing need meta-levelcommunication. Proceedings Thirteenth International Joint ConferenceArtificial Intelligence, pp. 360{366 Chambery, France.Decker, K. S., & Lesser, V. R. (1993b). one-shot dynamic coordination algorithmdistributed sensor networks. Proceedings Eleventh National ConferenceArtificial Intelligence, pp. 210{216 Washington, DC.Doyle, J. (1985). Reasoned assumptions pareto optimality. ProceedingsNinth International Joint Conference Artificial Intelligence, pp. 87{90 Los Angeles,California.Doyle, J. (1992). Rationality roles reasoning. Computational Intelligence, 8 (2),376{409.Durfee, E. H. (1988). Coordination Distributed Problem Solvers. Kluwer AcademicPublishers, Boston.Durfee, E. H., & Lesser, V. R. (1987). Using partial global plans coordinate distributedproblem solvers. Proceedings Tenth International Joint Conference Artificial Intelligence, pp. 875{883 Milan.Durfee, E. H., & Lesser, V. R. (1989). Negotiating task decomposition allocation usingpartial global planning. Gasser, L., & Huhns, M. N. (Eds.), Distributed ArtificialIntelligence, Vol. II, pp. 229{243. Morgan Kaufmann, San Mateo, California.230fiMechanisms Automated NegotiationDurfee, E. H., Lesser, V. R., & Corkill, D. D. (1987). Cooperation communicationdistributed problem solving network. Huhns, M. N. (Ed.), Distributed Artificial Intelligence, chap. 2, pp. 29{58. Morgan Kaufmann Publishers, Inc., Los Altos,California.Ephrati, E., & Rosenschein, J. S. (1991). Clarke Tax consensus mechanism amongautomated agents. Proceedings Ninth National Conference ArtificialIntelligence, pp. 173{178 Anaheim, California.Ephrati, E., & Rosenschein, J. S. (1992a). Constrained intelligent action: Planninguence master agent. Proceedings Tenth National ConferenceArtificial Intelligence, pp. 263{268 San Jose, California.Ephrati, E., & Rosenschein, J. S. (1992b). Planning please: Planning constrainedmaster agent. Proceedings Eleventh International Workshop DistributedArtificial Intelligence, pp. 77{94 Glen Arbor, Michigan.Ephrati, E., & Rosenschein, J. S. (1992c). Reaching agreement partial revelation preferences. Proceedings Tenth European Conference ArtificialIntelligence, pp. 229{233 Vienna, Austria.Ephrati, E., & Rosenschein, J. S. (1993a). Distributed consensus mechanisms selfinterested heterogeneous agents. First International Conference IntelligentCooperative Information Systems, pp. 71{79 Rotterdam.Ephrati, E., & Rosenschein, J. S. (1993b). Multi-agent planning dynamic searchsocial consensus. Proceedings Thirteenth International Joint ConferenceArtificial Intelligence, pp. 423{429 Chambery, France.Etzioni, O. (1991). Embedding decision-analytic control learning architecture. ArtificialIntelligence, 49, 129{159.Ferber, J., & Drogoul, A. (1992). Using reactive multi-agent systems simulation problem solving. Avouris, N. M., & Gasser, L. (Eds.), Distributed Artificial Intelligence:Theory Praxis, pp. 53{80. Kluwer Academic Press.Forges, F. (1993). Five legitimate definitions correlated equilibrium games incomplete information. Theory Decision, 35, 277{310.Fox, M. S. (1981). organizational view distributed systems. IEEE TransactionsSystems, Man, Cybernetics, SMC-11 (1), 70{80.Fox, M. S., Allen, B., & Strohm, G. (1982). Job-shop scheduling: investigationconstraint-directed reasoning. Proceedings National Conference ArtificialIntelligence, pp. 155{158 Pittsburgh, Pennsylvania.Fudenberg, D., & Tirole, J. (1992). Game Theory. MIT Press, Cambridge, Massachusetts.231fiZlotkin & RosenscheinGasser, L. (1991). Social conceptions knowledge action: DAI foundations opensystems semantics. Artificial Intelligence, 47 (1{3), 107{138.Gasser, L. (1993). Social knowledge social action. Proceedings Thirteenth International Joint Conference Artificial Intelligence, pp. 751{757 Chambery, France.Genesereth, M. R., Ginsberg, M. L., & Rosenschein, J. S. (1986). Cooperation withoutcommunication. Proceedings National Conference Artificial Intelligence,pp. 51{57 Philadelphia, Pennsylvania.Georgeff, M. P. (1983). Communication interaction multi-agent planning. Proceedings National Conference Artificial Intelligence, pp. 125{129 Washington,D.C.Georgeff, M. P. (1984). theory action multi-agent planning. ProceedingsNational Conference Artificial Intelligence, pp. 121{125 Austin, Texas.Georgeff, M. P. (1987). Actions, processes, causality. Georgeff, M. P., & Lansky, A. L.(Eds.), Reasoning Actions & Plans, pp. 99{122. Morgan Kaufmann Publishers,Inc., Los Altos, California.Georgeff, M. P., & Lansky, A. L. (1987). Reactive reasoning planning. Proceedings Sixth National Conference Artificial Intelligence, pp. 677{682 Seatle,Washington.Gmytrasiewicz, P. J., & Durfee, E. H. (1992). logic knowledge belief recursivemodeling: Preliminary report. Proceedings Tenth National ConferenceArtificial Intelligence, pp. 628{634 San Jose, California.Gmytrasiewicz, P. J., & Durfee, E. H. (1993). Elements utilitarian theory knowledge action. Proceedings Thirteenth International Joint ConferenceArtificial Intelligence, pp. 396{402 Chambery, France.Gmytrasiewicz, P. J., Durfee, E. H., & Wehe, D. K. (1991a). decision theoretic approachcoordinating multiagent interaction. Proceedings Twelfth InternationalJoint Conference Artificial Intelligence, pp. 62{68 Sydney, Australia.Gmytrasiewicz, P. J., Durfee, E. H., & Wehe, D. K. (1991b). utility communicationcoordinating intelligent agents. Proceedings Ninth National ConferenceArtificial Intelligence, pp. 166{172.Grosz, B. J., & Kraus, S. (1993). Collaborative plans group activities. ProceedingsThirteenth International Joint Conference Artificial Intelligence, pp. 367{373Chambery, France.Grosz, B. J., & Sidner, C. (1990). Plans discourse. Cohen, P. R., Morgan, J., &Pollack, M. E. (Eds.), Intentions Communication. MIT Press.Gupta, N., & Nau, D. S. (1992). complexity blocks-world planning. ArtificialIntelligence, 56 (2{3), 223{254.232fiMechanisms Automated NegotiationHarsanyi, J. C. (1956). Approaches bargaining problem theorygames: critical discussion Zeuthen's, Hick's Nash theories. Econometrica,pp. 144{157.Horvitz, E., Cooper, G., & Heckerma, D. (1989). ection action scare resources:Theoretical principles empirical study. Proceedings Eleventh International Joint Conference Artificial Intelligence, pp. 1121{1127 Detroit, Michigan.Horvitz, E. J. (1988). Reasoning varying uncertain resource constraints.Proceedings Seventh National Conference Artificial Intelligence, pp. 111{116.Hughes, G. E., & Cresswell, J. M. (1968). Introduction Modal Logic. MethuenCo. Ltd.Kamel, M., & Syed, A. (1989). object-oriented multiple agent planning system.Gasser, L., & Huhns, M. N. (Eds.), Distributed Artificial Intelligence, Volume II, pp.259{290. Pitman Publishing/Morgan Kaufmann Publishers, San Mateo, CA.Katz, M. J., & Rosenschein, J. S. (1993). Verifying plans multiple agents. JournalExperimental Theoretical Artificial Intelligence, 5, 39{56.Kinny, D., Ljungberg, M., Rao, A., Sonenberg, E., Tidhar, G., & Werner, E. (1992). Plannedteam activity. Pre-Proceedings Fourth European Workshop ModelingAutonomous Agents Multi-Agent World Rome, Italy.Kinny, D. N., & Georgeff, M. P. (1991). Commitment effectiveness situated agents.Proceedings Twelfth International Joint Conference Artificial Intelligence,pp. 82{88 Sydney, Australia.Konolige, K. (1982). first-order formalization knowledge action multi-agentplanning system. Machine Intelligence, 10.Konolige, K. (1986). Deduction Model Belief. Pitman Publishers/Morgan Kaufmann,San Matheo, CA.Konolige, K., & Nilsson, N. J. (1980). Multiple-agent planning systems. ProceedingsFirst Annual National Conference Artificial Intelligence, pp. 138{142 Stanford,California.Kosoresow, A. P. (1993). fast first-cut protocol agent coordination. ProceedingsEleventh National Conference Artificial Intelligence, pp. 237{242 Washington,DC.Kraus, S. (1993). Agents contracting tasks non-collaborative environments. ProceedingsEleventh National Conference Artificial Intelligence, pp. 243{248.Kraus, S., Ephrati, E., & Lehmann, D. (1991). Negotiation non-cooperative environment. Journal Experimental Theoretical Artificial Intelligence, 3 (4), 255{282.233fiZlotkin & RosenscheinKraus, S., & Wilkenfeld, J. (1990). function time cooperative negotiations: Extended abstract. Proceedings Tenth Workshop Distributed Artificial Intelligence Bandera, Texas.Kraus, S., & Wilkenfeld, J. (1991). Negotiations time multi-agent environment:Preliminary report. Proceedings Twelfth International Joint ConferenceArtificial Intelligence, pp. 56{61 Sydney.Kraus, S., Wilkenfeld, J., & Zlotkin, G. (1995). Multiagent negotiation time constraints. Artificial Intelligence, 75 (2), 297{345.Kreifelts, T., & von Martial, F. (1991). negotiation framework autonomous agents.Demazeau, Y., & Muller, J.-P. (Eds.), Decentralized A. I. 2, Proceedings SecondEuropean Workshop Modelling Autonomous Agents Multi-Agent World, pp.71{88. North-Holland, Amsterdam.Kuwabara, K., & Lesser, V. R. (1989). Extended protocol multistage negotiation.Proceedings Ninth Workshop Distributed Artificial Intelligence, pp. 129{161Rosario, Washington.L^aasri, B., L^aasri, H., & Lesser, V. R. (1990). Negotiation role cooperative distributed problem problem solving. Proceedings Tenth International WorkshopDistributed Artificial Intelligence Bandera, Texas. Chapter 8.Lesser, V. R., & Corkill, D. D. (1981). Functionally-accurate, cooperative distributed systems. IEEE Transactions Systems, Man, Cybernetics, SMC-11 (1), 81{96.Levesque, H. J., & Cohen, P. R. (1990). acting together. Proceedings EighthNational Conference Artificial Intelligence, pp. 94{99 Boston, Massachusetts.Luce, R. D., & Raiffa, H. (1957). Games Decisions. John Wiley & Sons, Inc., NewYork.Malone, T. W. (1986). Organizing information processing systems: Parallels humanorganizations computer systems. Zacharai, W., Robertson, S., & Black, J.(Eds.), Cognition, Computation, Cooperation. Ablex Publishing Corp., Norwood,NJ.Malone, T. W., Fikes, R. E., Grant, K. R., & Howard, M. T. (1988). Enterprise:market-like task scheduler distributed computing environments. Huberman,B. A. (Ed.), Ecology Computation, pp. 177{205. North-Holland PublishingCompany, Amsterdam.McArthur, D., Steeb, R., & Cammarata, S. (1982). framework distributed problemsolving. Proceedings National Conference Artificial Intelligence, pp.181{184 Pittsburgh, Pennsylvania.Morgenstern, L. (1986). first order theory planning, knowledge, action. Halpern,J. Y. (Ed.), Theoretical Aspects Reasoning Knowledge, pp. 99{114. MorganKaufmann, Los Altos.234fiMechanisms Automated NegotiationMorgenstern, L. (1987). Knowledge preconditions actions plans. ProceedingsTenth International Joint Conference Artificial Intelligence, pp. 867{874Milan, Italy.Morgenstern, L. (1990). formal theory multiple agent nonmonotonic reasoning.Proceedings Eighth National Conference Artificial Intelligence, pp. 538{544Boston, Massachusetts.Moses, Y., & Tennenholtz, M. (1990). Artificial social systems part 1: Basic principles.Tech. rep. CS90-12, Weizmann Institute.Moses, Y., & Tennenholtz, M. (1993). Off-line reasoning on-line eciency. ProceedingsThirteenth International Joint Conference Artificial Intelligence, pp. 490{495 Chambery, France.Myerson, R. (1982). Optimal coordination mechanisms generalized principal-agent problems. Journal Mathematical Economics, 10, 67{81.Myerson, R. (1991). Game Theory: Analysis Con ict. Harvard University Press, Cambridge, Massachusetts.Nash, J. F. (1950). bargaining problem. Econometrica, 28, 155{162.Nash, J. F. (1953). Two-person cooperative games. Econometrica, 21, 128{140.Osborne, M. J., & Rubinstein, A. (1990). Bargaining Markets. Academic Press Inc.,San Diego, California.Pednault, E. P. D. (1987). Formulating multiagent dynamic-world problems classicalplanning framework. Georgeff, M. P., & Lansky, A. L. (Eds.), Reasoning Actions Plans: Proceedings 1986 Workshop, pp. 47{82 San Mateo, California.Morgan Kaufmann.Pollack, M. E. (1992). uses plans. Artificial Intelligence, 57 (1).Pope, R. P., Conry, S. E., & Mayer, R. A. (1992). Distributing planning processdynamic environment. Proceedings Eleventh International WorkshopDistributed Artificial Intelligence, pp. 317{331 Glen Arbor, Michigan.Raiffa, H. (1968). Decision Analysis, Introductory Lectures Choices Uncertainty.Addison-Wesley Publishing Company, Reading, Massachusetts.Raiffa, H. (1982). Art Science Negotiation. Belknap Press HarvardUniversity Press, Cambridge, Massachusetts.Rao, A. S., & Georgeff, M. P. (1991). Asymmetry thesis side-effect problems lineartime branching-time intention logics. Proceedings Twelfth InternationalJoint Conference Artificial Intelligence, pp. 498{504 Sydney, Australia.235fiZlotkin & RosenscheinRao, A. S., & Georgeff, M. P. (1993). model-theoretic approach verificationsituated reasoning systems. Proceedings Thirteenth International JointConference Artificial Intelligence, pp. 318{324 Chambery, France.Rao, A. S., Georgeff, M. P., & Sonenberg, E. (1991). Social plans: preliminary report.Pre-Proceedings Third European Workshop Modeling Autonomous AgentsMulti-Agent Worlds Germany.Rasmusen, E. (1989). Games Information, Introduction Game Theory. BasilBlackwell, Cambridge, Massachusetts.Rosenschein, J. S. (1982). Synchronization multi-agent plans. ProceedingsNational Conference Artificial Intelligence, pp. 115{119 Pittsburgh, Pennsylvania.Rosenschein, J. S. (1986). Rational Interaction: Cooperation Among Intelligent Agents.Ph.D. thesis, Stanford University.Rosenschein, J. S. (1993). Consenting agents: Negotiation mechanisms multi-agentsystems. Proceedings Thirteenth International Joint Conference ArtificialIntelligence, pp. 792{799 Chambery, France.Rosenschein, J. S., & Genesereth, M. R. (1985). Deals among rational agents. ProceedingsNinth International Joint Conference Artificial Intelligence, pp. 91{99 LosAngeles, California.Roth, A. E. (1979). Axiomatic Models Bargaining. Springer-Verlag, Berlin.Rubinstein, A. (1982). Perfect equilibrium bargaining model. Econometrica, 50 (1),97{109.Rubinstein, A. (1985). Choice conjectures bargaining game incomplete information. Roth, A. E. (Ed.), Game-theoretic models bargaining, pp. 99{114.Cambridge University Press, Cambridge, New York.Russell, S., & Wefald, E. (1989). Principles metareasoning. Proceedings FirstInternational Conference Principles Knowledge Representation Reasoning,pp. 400{411. Morgan Kaufmann.Sandholm, T. (1993). implementation contract net protocol based marginalcalculations. Proceedings Eleventh National Conference Artificial Intelligence, pp. 256{262.Schelling, T. C. (1963). Strategy Con ict. Oxford University Press, New York.Schelling, T. C. (1984). Choice Consequence. Harvard University Press, Cambridge,Massachusetts.Shoham, Y., & Tennenholtz, M. (1992a). Emergent conventions multi-agent systems:initial experimental results observations (preliminary report). Principlesknowledge representation reasoning: Proceedings Third International Conference Cambridge, Massachusetts.236fiMechanisms Automated NegotiationShoham, Y., & Tennenholtz, M. (1992b). synthesis useful social laws artificialagent societies (preliminary report). Proceedings National ConferenceArtificial Intelligence San Jose, California.Shoham, Y., & Tennenholtz, M. (1995). social laws artificial agent societies: Off-linedesign. Artificial Intelligence. appear.Smith, R. G. (1978). Framework Problem Solving Distributed Processing Environment. Ph.D. thesis, Stanford University.Smith, R. G. (1980). contract net protocol: High-level communication controldistributed problem solver. IEEE Transactions Computers, C-29 (12), 1104{1113.Steeb, R., Cammarata, S., Hayes-Roth, F., & Wesson, R. (1980). Distributed intelligenceair eet control. Tech. rep. WD-839-ARPA, Rand Corporation.Stuart, C. J. (1985). implementation multi-agent plan synchronizer. ProceedingsNinth International Joint Conference Artificial Intelligence, pp. 1031{1035Los Angeles, California.Sycara, K. P. (1988). Resolving goal con icts via negotiation. Proceedings SeventhNational Conference Artificial Intelligence, pp. 245{250 St. Paul, Minnesota.Sycara, K. P. (1989). Argumentation: Planning agents' plans. ProceedingsEleventh International Joint Conference Artificial Intelligence, pp. 517{523Detroit.Tennenholtz, M., & Moses, Y. (1989). cooperation multi-entity model (preliminaryreport). Proceedings Eleventh International Joint Conference ArtificialIntelligence, pp. 918{923 Detroit, Michigan.von Martial, F. (1990). Coordination plans multiagent worlds taking advantagefavor relation. Proceedings Tenth International Workshop DistributedArtificial Intelligence Bandera, Texas.von Martial, F. (1992a). Coordinating Plans Autonomous Agents. No. 610 LectureNotes Artificial Intelligence. Springer Verlag, Heidelberg, Germany.von Martial, F. (1992b). Coordination negotiation based connection dialoguestates actions. Proceedings Eleventh International Workshop Distributed Artificial Intelligence, pp. 227{246 Glen Arbor, Michigan.Wellman, M. P. (1992). general equilibrium approach distributed transportation planning. Proceedings Tenth National Conference Artificial Intelligence SanJose, California.Zeuthen, F. (1930). Problems Monopoly Economic Walfare. G. Routledge & Sons,London.237fiZlotkin & RosenscheinZlotkin, G., & Rosenschein, J. S. (1989). Negotiation task sharing among autonomousagents cooperative domains. Proceedings Eleventh International JointConference Artificial Intelligence, pp. 912{917 Detroit, Michigan.Zlotkin, G., & Rosenschein, J. S. (1990). Negotiation con ict resolution noncooperative domains. Proceedings Eighth National Conference ArtificialIntelligence, pp. 100{105 Boston, Massachusetts.Zlotkin, G., & Rosenschein, J. S. (1991a). Cooperation con ict resolution via negotiation among autonomous agents noncooperative domains. IEEE TransactionsSystems, Man, Cybernetics, 21 (6), 1317{1324.Zlotkin, G., & Rosenschein, J. S. (1991b). Incomplete information deception multiagent negotiation. Proceedings Twelfth International Joint ConferenceArtificial Intelligence, pp. 225{231 Sydney, Australia.Zlotkin, G., & Rosenschein, J. S. (1991c). Negotiation goal relaxation. Demazeau,Y., & Muller, J.-P. (Eds.), Decentralized A. I. 2, Proceedings Second EuropeanWorkshop Modelling Autonomous Agents Multi-Agent World, pp. 273{286.North-Holland, Amsterdam.Zlotkin, G., & Rosenschein, J. S. (1993a). domain theory task oriented negotiation.Proceedings Thirteenth International Joint Conference Artificial Intelligence,pp. 416{422 Chambery, France.Zlotkin, G., & Rosenschein, J. S. (1993b). extent cooperation state-oriented domains: Negotiation among tidy agents. Computers Artificial Intelligence, 12 (2),105{122.Zlotkin, G., & Rosenschein, J. S. (1993c). Negotiation incomplete informationworth: Strict versus tolerant mechanisms. Proceedings First InternationalConference Intelligent Cooperative Information Systems, pp. 175{184 Rotterdam, Netherlands.Zlotkin, G., & Rosenschein, J. S. (1994). Coalition, cryptography, stability: Mechanisms coalition formation task oriented domains. Proceedings NationalConference Artificial Intelligence, pp. 432{437 Seattle, Washington.Zlotkin, G., & Rosenschein, J. S. (1996a). Compromise negotiation: Exploiting worthfunctions states. Artificial Intelligence, 84 (1{2), 151{176.Zlotkin, G., & Rosenschein, J. S. (1996b). Mechanism design automated negotiation,application task oriented domains. Artificial Intelligence. appear.238fiJournal Artificial Intelligence Research 5 (1996) 289-300Submitted 6/96; published 12/96Research NoteCharacterizations Decomposable Dependency ModelsLuis M. de CamposDepartamento de Ciencias de la Computacion e I.A.E.T.S. Ingeniera Informatica, Universidad de Granada18071 - Granada SPAINlci@decsai.ugr.esAbstractDecomposable dependency models possess number interesting useful properties. paper presents new characterizations decomposable models terms independence relationships, obtained adding single axiom well-knownset characterizing dependency models isomorphic undirected graphs. alsobrie discuss potential application results problem learning graphicalmodels data.1. IntroductionGraphical models knowledge representation tools commonly used increasing number researchers, particularly Artificial Intelligence Statistics communities.reason success graphical models capacity represent handleindependence relationships, proved crucial ecient managementstorage information (Pearl, 1988).different kinds graphical models, although particularly interestedundirected directed graphs (which, probabilistic context, usually calledMarkov networks Bayesian networks, respectively). one meritsshortcomings, neither two representations expressive powerother: independence relationships represented means directedgraphs (using d-separation criterion) cannot represented using undirected ones(through separation criterion), reciprocally. However, class modelsrepresented means directed undirected graphs, preciselyclass decomposable models (Haberman, 1974; Pearl, 1988). Decomposable models alsopossess important properties, relative factorization parameter estimation,make quite useful. So, models studied characterized manydifferent ways (Beeri, Fagin, Maier, & Yannakakis, 1983; Haberman, 1974; Lauritzen, Speed,& Vijayan, 1984; Pearl, 1988; Wermuth & Lauritzen, 1983; Whittaker, 1991). example,decomposable models characterized kind dependency models isomorphicchordal graphs (Lauritzen et al., 1984; Whittaker, 1991).However, know characterization decomposable models termskind independence relationships capable representing. somewhatsurprising, seems quite natural us characterize type object usingterms used define it; case, object special type dependencymodel, i.e., collection conditional independence statements set variablesgiven domain knowledge, therefore able describe termsc 1996 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiDe Camposproperties independence relationships. objective paper preciselyobtain characterization decomposable models.approach problem based identifying set properties axiomscollection independence relationships must satisfy, order representablechordal graph. approach successfully used study kindsdependency models: Pearl Paz (1985) identified set properties characterizingmodels isomorphic undirected graphs, de Campos (1996) determined axiomscharacterize models isomorphic undirected directed singly connected graphs(i.e., trees polytrees, respectively).rest paper organized follows. Section 2 brie describe severalconcepts basic subsequent development. Section 3 introduces decomposablemodels representation using chordal graphs. Section 4 prove two characterizations decomposable models. characterizations turn surprisinglysimple: add single property set axioms characterizing dependencymodels isomorphic undirected graphs. Section 5 discusses relationshipsresults Lauritzen's characterization chordal graphs. Finally, Section 6 containsconcluding remarks proposals future work, include applicationresults developed problem learning graphical models data.2. Preliminariessection, going describe notation well basic conceptsresults used throughout paper.Dependency Model (Pearl, 1988) pair = (U; ), U finite set elements variables, (:; :j:) rule assigns truth values three place predicatewhose arguments disjoint subsets U . Single elements U denoted standardGreek lowercase letters, whereas subsets U represented capital letters.interpretation conditional independence assertion (X; jZ ) observedZ , additional information X could obtained also observing . example, probabilistic model (Dawid, 1979; Lauritzen, Dawid, Larsen, & Leimer, 1990),(X; jZ ) holdsP (xjz; y) = P (xjz) whenever P (z; y) > 0;every instantiation x, z sets variables X , Z . However, dependencymodels applicable many situations far beyond probabilistic models (de Campos, 1995;Pearl, 1988; Shenoy, 1992).graphical representation dependency model = (U; ) direct correspondenceelements U set nodes given graph, G, topologyG ects properties . topological property selected represent independenceassertions depends type graph use: separation undirected graphs dseparation (Pearl, 1988; Verma & Pearl, 1990) directed acyclic graphs (dags):Separation: Given undirected graph G, two subsets nodes, X , saidseparated set nodes Z , denoted hX; jZ iG , Z interceptschains nodes X .290fiCharacterizations Decomposable Dependency Modelsd-separation: Given dag G, chain C (a chain directed graph sequenceadjacent nodes, direction arrows matter) node ff node fisaid blocked set nodes Z , vertex 2 C that, either{ 2 Z arrows C meet head head ,{ 62 Z , descendants Z , arrows C meet headhead .Two subsets nodes, X , said d-separated Z , alsodenoted hX; jZ iG , chains nodes X nodesblocked Z . exists criterion equivalent d-separation, basedseparation X Z moral graph smallest ancestral set containingX [ [ Z (Lauritzen et al., 1990).Given dependency model, , say undirected graph (a dag, respectively), G,I-map every separation (d-separation, respectively) G implies independence: hX; jZ iG ) (X; jZ ). hand, undirected graph (a dag, resp.),G, called D-map every independence relation model implies separation (dseparation resp.) graph: (X; jZ ) ) hX; jZ iG . graph, G, Perfect mapI-map D-map. said graph-isomorphic graph existsperfect map .class dependency models isomorphic undirected graphs completelycharacterized (Pearl & Paz, 1985) terms five properties axioms satisfiedindependence relationships within model:(C1) Symmetry:(I (X; jZ ) ) (Y; X jZ )) 8X; Y; Z U:(C2) Decomposition:(I (X; [ W jZ ) ) (X; jZ )) 8X; Y; W; Z U:(C3) Strong Union:(I (X; jZ ) ) (X; jZ [ W )) 8X; Y; W; Z U:(C4) Intersection:(I (X; jZ [ W ) (X; W jZ [ ) ) (X; [ W jZ )) 8X; Y; W; Z U:(C5) Transitivity:(I (X; jZ ) ) (X; jZ ) ( ; jZ ) 8 2 U n (X [ [ Z )) 8X; Y; Z U:Pearl Paz also tacitly assumed additional, trivial, axiom holds, namely (X; ;jZ )8X; Z U . also assumed sets X; Y; Z; W involved axiomspairwise disjoint.Theorem 1 (Pearl Paz, 1985) dependency model isomorphic undirected graph if, if, satisfies axioms C1{C5.graph associated dependency model , conditional independenceequivalent separation graph, GM = (U; EM ), set edges291fiDe CamposEMEM = fff{fi j ff; fi 2 U; :I (ff; fi jU n fff; fi g)g:hand, class dependency models isomorphic dags considerablydicult characterize. suggested (Geiger, 1987; Pearl, 1988)number axioms required complete characterization d-separation dagsprobably unbounded. However, restricted models, namely polytree-isomorphicmodels, fully characterized using finite number axioms (de Campos, 1996).Graphical models convenient means expressing conditional independencestatements given domain knowledge, also convey information necessarydecisions inference, form numerical parameters quantifying strengthlink. assignment numerical parameters graphical model also quite differentundirected directed graphs (here restrict discussion probabilistic models).case directed acyclic graphs, simple matter: assignvariable xi dag conditional probability distribution every instantiationvariables form parent set xi , (xi). product local distributionsconstitutes complete consistent specification, i.e., joint probability distribution(which also preserves independence relationships displayed dag):P (x1 ; x2; : : :; xn) =Yn P (xij(xi))i=1However, case undirected graphs different: constructing complete consistentquantitative specification preserving dependence structure arbitrary undirected graph done using method Gibb's potentials (Lauritzen, 1982) (whichassigns compatibility functions cliques graph), considerablycomplicated, terms computational effort meaningfulness parameters,simple method used dags.3. Decomposable Models Chordal Graphsdependency models representable means special class undirected graphspresent quantification problem described above. called decomposable models, also exhibit number important useful additional properties.several ways defining decomposable models. appropriateinterests, mainly lie graphical modelling, based graph-theoretic concept:chordal graphs, also called triangulated graphs (Rose, 1970).Definition 1 undirected graph said chordal every cycle length fourchord, i.e., edge linking two non-adjacent nodes cycle.simplest example non-chordal graph diamond-shaped graph displayedFigure 1 (a).Definition 2 dependency model decomposable isomorphic chordal graph.292fiCharacterizations Decomposable Dependency Modelsfi@,,fi@,,@@,,@@@fi@fi fififi,,fffiffZZ,,,,ZZZ fi,Z fi,ZZfi ,,(a)(b)Figure 1: (a) simplest example non-chordal graph (b) Non-chordal graph satisfiyingC1{C5 C7One important property satisfied every chordal graph G, fact characterizeschordal graphs (Beeri et al., 1983), edges G directed acyclicallyevery pair converging arrows emanates two adjacent nodes. property,deduced (Pearl, 1988) class dependency models may representeddag undirected graph precisely class decomposable models (notenon-chordal graphs, matter direct arrows, always pairnonadjacent parents sharing common child, configuration causes separationundirected graphs produce d-separation dags).Another crucial property chordal graphs cliques (i.e., largest subgraphs whose nodes adjacent other) joined form tree , calledjoin tree, two cliques containing node ff either adjacentconnected chain made entirely cliques contain ff (Beeri et al., 1983) (anexample depicted Figure 2).,,,yl, ZZ,,Zxlzl@%%@@ %, @,@@,wtl(a)ulvllffyztffxy bbbffuzt,ffuv,, ffuwAA(b)Figure 2: Chordal graph (a) join tree (b)result important consequences probabilistic modelling: joint probabilitydistribution factorises product marginal distributions cliques (Lauritzen et al.,1984; Pearl, 1988; Whittaker, 1991); moreover, maximum likelihood estimates modeldirectly calculable (Whittaker, 1991). consequence compatibility functions293fiDe Camposused quantitatively specify model, clear meaning easily estimated.Additionally, tree structure cliques chordal graph facilitates recursive updating probabilities. fact, one important algorithms propagation (i.e.,updating using local computations) probabilities dags, based transformationgiven dag chordal graph, moralising next triangulating dag (Lauritzen& Spiegelhalter, 1988).4. Characterizing Decomposable Modelspurpose find characterization decomposable models (or equivalently, chordalgraphs) terms properties independence relationships. carriedadding single property set axioms, C1{C5, characterizing dependency modelsisomorphic undirected graphs.Let us consider following axiom:(C6) Strong Chordality:(I (ff; fi jZ [ [ ) ( ; jU nf ; g) ) (ff; fi jZ [ ) (ff; fi jZ [ )) 8ff; fi; ; 2 U 8ZU n fff; fi; ; g:axiom establishes condition allows us reduce size conditioningset separating two variables ff fi , namely two variables setconditionally independent. going demonstrate adding axiom strongchordality axioms found Pearl Paz, C1{C5, associated graph necessarilybecomes chordal graph vice versa. Therefore, shall obtain characterizationdecomposable models. Pearl (1988) proposed axiom slightly different C6,necessary, though sucient condition chordality. called axiom chordality:(C7) Chordality:(I (ff; fi j [ ) ( ; jff [ fi ) ) (ff; fi j ) (ff; fi j )) 8ff; fi; ; 2 U:Observe context, i.e., assuming C1{C5 hold, C6 implies C7:(ff; fij [ ) ( ; jff [ fi ), strong union (C3) guarantees ( ; jU n f ; g)implied ( ; jW ) W U nf ; g (in particular W = fff; fi g), applyingC6 Z = ;, obtain (ff; fi j ) (ff; fi j ). However, set axioms C1{C5C7 constitute characterization chordal graphs, graph depicted Figure1 (b) shows: graph chordal, satisfies C1{C5 C7. using C6 insteadC7 shall obtain desired result.Theorem 2 dependency model isomorphic chordal graph if, if,satisfies axioms C1{C6.Proof: First, let us prove sucient condition. Using Pearl Paz result, C1{C5 deduce isomorphic associated graph G, therefore independenceequivalent separation G. prove G chordal.Let us suppose G chordal. Then, G, cycle t1 t2 : : :tn,1 tn t1 , n 4,without chord, i.e., 8i; j s.t. 1 < + 1 < j n, edges ti {tj belong EM(except edge t1 {tn ).294fiCharacterizations Decomposable Dependency ModelsLet us consider nodes t1 tn,1 , set nodes Z = U n ft1 ; : : :; tn g. First,going prove independence statement (t1; tn,1 jZ [ t2 [ tn )true: :I (t1 ; tn,1 jZ [ t2 [ tn ) could find chain linking t1 tn,1containing nodes Z [ t2 [ tn , i.e., chain linking t1 tn,1 containing nodesft3 ; : : :; tn,2 g; case would edge linking t1 node tj ,3 j n , 2, contradicts assumption cycle chord. Therefore,(t1; tn,1 jZ [ t2 [ tn ).hand, nodes t2 tn connected edge (oncecycle chord), separated U nft2 ; tn g, therefore(t2 ; tn jU nft2 ; tn g). Now, using C6, deduce either (t1; tn,1 jZ [ t2 ) (t1; tn,1 jZ [tn ). either case chain linking t1 tn,1 blocked separatingset: first case chain t1 tn tn,1 , second case t1 t2 : : :tn,2 tn,1 .Therefore, obtain contradiction, hence graph G chordal.Now, let us prove necessary condition. using Pearl Paz's result,isomorphic graph G, properties C1{C5 hold.Let us suppose C6 hold. Then, find nodes ff; fi; ; subsetnodes Z (ff; fi jZ [ [ ), ( ; jU n f ; g), :I (ff; fi jZ [ ) :I (ff; fi jZ [ ).:I (ff; fi jZ [ ) deduce chain fft1 : : :tn fi exists G, ti 62 Z [8i, i.e., ft1 : : :tng \ (Z [ ) = ;. However, (ff; fijZ [ [ ) know every chainlinking ff fi must contain node Z [ [ . particular, previouslyfound chain, ft1 : : :tn g \ (Z [ [ ) 6= ;. Therefore, node tktk = . Let us consider node tk,1 : (ff; fi jZ [ [ ) transitivity (C5),obtain (ff; tk,1jZ [ [ ) (tk,1 ; fi jZ [ [ ). first independence assertioncannot true, chain fft1 : : :tk,2 tk,1 contain node Z [ [ .Therefore, (tk,1 ; fi jZ [ [ ). (tk,1 ; fi jZ [ ), then, transitivity,would obtain (ff; tk,1jZ [ ) (ff; fi jZ [ ), statements false, firstone existence chain fft1 : : :tk,2 tk,1 second onehypothesis. So, :I (tk,1 ; fi jZ [ ). reasoning allows us assert:I (ff; fijZ [ ) :I (tk,1; fijZ [ ). So, found node tk,1 adjacent = tksatisfying properties ff. completely analogous reasoning applied node tk+1proves (tk,1 ; tk+1 jZ [ [ ), :I (tk,1 ; tk+1 jZ [ ), :I (tk,1 ; tk+1 jZ [ ). So,replaced nodes ff fi two nodes adjacent satisfying properties. Notecase one tk,1 tk+1 ff fi mattersubsequent argument.Now, :I (tk,1 ; tk+1 jZ [ ) (tk,1 ; tk+1 jZ [ [ ) deducechain tk,1 s1 : : :sm tk+1 G si 62 Z [ 8i node sh , sh = .simplify notation, let us call s0 = tk,1 , sm+1 = tk+1 . assume 8i; j0 < + 1 < j h, edge linking si sj (if case,simply replace subchain si si+1 : : :sj ,1 sj single edge si {sj , i.e., considershortest subchain tk,1 sh ). reason, also suppose8p; q h < p + 1 < q + 1, edge linking sp sq .found cycle s0 s1 : : :sh,1 sh+1 : : :sm sm+1 G. Now, let sf sg twonodes satisfying f < h < g , sf sg adjacent adjacent sjj s.t. f < j < g j 6= h (note always find two nodes, startingf = 0 g = + 1). still cycle sf : : :sh,1 sh+1 : : :sg length four more,295fiDe Camposthat, according hypothesis, cycle must chord. However, takingaccount cycle constructed, possible chords edge {edge linking node si , f < < h, node sp , h < p < g . first possibilitycontradicts hypothesis ( ; jU nf ; g), second one implies existencechain tk,1 s1 : : :sf : : :si sp : : :sg : : :sm tk+1 linking tk,1 tk+1 , containnode Z [ [ , contradiction statement (tk,1 ; tk+1 jZ [ [ ). Therefore,property C6 true.establish another interesting characterization chordal graphs, also addingone axiom Pearl Paz. new axiom following:(C8) Clique-separability:(I (ff; fi jU n fff; fi g) ) 9W U n fff; fi g (ff; fi jW ) either jW j 1:I ( ; jU n f ; g) 8 ; 2 W ) 8ff; fi 2 U .Axiom C8 asserts whenever two nodes ff fi adjacent (are independent),find separating set whose nodes adjacent other, i.e., completeseparating set.Theorem 3 dependency model isomorphic chordal graph if, if,satisfies axioms C1{C5 C8.Proof: Let us prove necessary condition. graph G associated chordal,Theorem 2 know properties C1{C5 C6 hold.Let us suppose C8 hold. Then, ff fi , (ff; fi jU nfff; fig) W U n fff; fig either :I (ff; fijW ), jW j > 1 9 ; 2 W( ; jU n f ; g).Let W0 separating set minimal size ff fi , i.e., (ff; fi jW0) :I (ff; fi jS )8S W0 (we know least one separating set type exist,(ff; fijU n fff; fig) holds). Then, deduce jW0j > 1 9 ; 2 W0( ; jU n f ; g). Let us define Z = W0 n f ; g. Thus, (ff; fi jZ [ [ )( ; jU n f ; g) and, applying C6, obtain either (ff; fi jZ [ ) (ff; fi jZ [ ), i.e.,(ff; fijW0 n fg) (ff; fijW0 n f g), contradicts minimality W0 . Therefore,C8 true.prove sucient condition, let us suppose G chordal. Then,cycle t1 t2 : : :tn,1 tn t1 , n 4, without chord. So, nodes t1 tn,1 adjacent,hence separated, let W separating set t1 tn,1 , i.e., satisfying(t1; tn,1 jW ). tn 2 W ft2; : : :; tn,2 g \ W 6= ;, otherwise could find chainlinking t1 tn,1 would blocked W , thus contradicting (t1 ; tn,1 jW ).So, every separating set W contains tn ti ; 2 n , 2, hence jW j > 1. Now,applying C8, deduce :I (tn ; tijU n ftn ; ti g), i.e., tn ti adjacent nodes,contradicts assumption cycle chord. Then, conclusiongraph chordal.296fiCharacterizations Decomposable Dependency Models5. Relationships Characterizations Decomposable Modelscharacterization decomposable models1 (Lauritzen, 1989) quite relatedours: undirected graph chordal if, if, every subset nodes separatestwo nodes ff fi minimal complete.order rewrite result using notation, let us consider following axiom:(C9) Completeness:(I (ff; fi jZ ) :I (ff; fi jS ) 8S Z ) jZ j 1 :I ( ; jU n f ; g) 8 ; 2 Z ) 8ff; fi 2U 8Z U n fff; fig.Axiom C9 says exactly minimal separator ff fi complete.equivalent formulation axiom reads: separator ff fi completecannot minimal. symbols:(C9') Completeness:(I (ff; fi jZ [ [ ) ( ; jU nf ; g) ) 9W Z [ [ (ff; fi jW )) 8ff; fi; ; 2U 8Z U n fff; fi; ; g:Then, Lauritzen's result reformulated follows: dependency modelisomorphic chordal graph if, if, satisfies axioms C1{C5 either C9C9'.Note similarity C9 C8 C9' C6. Taking accountTheorems 2 3, deduce axioms, C6, C8, C9 C9', equivalentamong (assuming C1{C5 hold). However, equivalence evident,spite similarities among axioms: clear C6 implies C9' C9 implies C8,opposite implications obvious. fact, strong chordality clique-separabilityseem stronger weaker, respectively, completeness. becomes clearerexpress axioms following way: Assuming two nodes ff fi separated:Completeness (C9 C9'): separator ff fi minimal, complete;or, equivalently, separator ff fi complete, proper subsetstill separator ff fi .Clique-separability (C8): exists separator ff fi complete.Strong chordality (C6): separator ff fi complete, propersubset still separator ff fi ; moreover, find subsetremoving, initial separator, one nodes causing incompleteness.Observe C6 C9' share antecedent, consequent C9'says exists separator, whereas consequent C6 gives informationidentity separator. Note also C8 C9 assert existencecomplete separator, C9 requires previous condition (minimality) C8 not.1. existence result pointed reviewer.297fiDe Campos6. Concluding Remarksfound two new characterizations class decomposable dependency models,terms properties independence relationships. believe resultstheoretically interesting, provide new perspective important wellstudied class graphical models. Moreover, results quite concise, since oneproperty added set properties characterizing independence relationshipsundirected graphs. could also useful proving results modelssort.practical point view, axiomatic characterizations create desideratacould drive automated construction chordal graphs data. alreadycommented, practical use graphical models and, particularly, bayesian networks, requires dag representing model transformed chordal graph.perspective learning models data, may interesting estimate directlychordal graph available data, instead first learning dag converting chordal graph. believe basic independence properties chordalgraphs identified theoretical study, C6 C8, could guide us design efficient algorithms learning chordal graphs. known problem learningbayesian networks data computationally complex. example, algorithms (Spirtes, Glymour, & Scheines, 1993) start complete undirected graph,try remove edges testing conditional independence linked nodes,using conditioning sets small possible (thus reducing complexity increasingreliability). context, rewrite property C6 following way::I (ff; fijZ [ ) :I (ff; fijZ [ ) (ff; fijZ [ [ ) ) :I ( ; jU n f ; g);could use rule simultaneously allows us remove edge ff{ficurrent graph, fix edge { true edge graph.Similarly, property C8 could give rise following rule: trying removeedge ff{fi current graph, testing conditional independence statements like(ff; fijW ), discard candidate separating sets sets W whose nodesadjacent other.topic designing ecient algorithms learning chordal graphs objectfuture research.Acknowledgementswork supported Spanish Comision Interministerial de Ciencia Tecnologa (CICYT) Project n. TIC96-0781. would like thank Milan Studenythree anonymous reviewers helpful comments suggestions. particularly grateful reviewer pointed existence Lauritzen's characterizationchordal graphs.298fiCharacterizations Decomposable Dependency ModelsReferencesBeeri, C., Fagin, R., Maier, D., & Yannakakis, M. (1983). desirability acyclicdatabase schemes. JACM, 30, 479{513.Dawid, A. P. (1979). Conditional independence statistical theory. J.R. Statist. Soc. Ser.B, 41, 1{31.de Campos, L. M. (1995). Independence relationships possibility theory application learning belief networks. Della Riccia, G., Kruse, R., & Viertl, R.(Eds.), Mathematical Statistical Methods Artificial Intelligence, CISM CoursesLectures 363, pp. 119{130. Wien: Springer Verlag.de Campos, L. M. (1996). Independency relationships learning algorithms singlyconnected networks. Tech. rep. DECSAI 960204, University Granada.Geiger, D. (1987). non-axiomatizability dependencies directed acyclic graphs.Tech. rep. R-83, Cognitive Systems Laboratory, UCLA.Haberman, S. J. (1974). Analysis Frequency Data. Chicago: University ChicagoPress.Lauritzen, S. L. (1982). Lectures Contingency Tables (2nd ed.). Aalborg: UniversityAalborg Press.Lauritzen, S. L. (1989). Mixed graphical association models. Scand. J. Statist., 16, 273{306.Lauritzen, S. L., Dawid, A. P., Larsen, B. N., & Leimer, H. G. (1990). Independenceproperties directed markov fields. Networks, 20, 491{505.Lauritzen, S. L., Speed, T. P., & Vijayan, K. (1984). Decomposable graphs hypergraphs.J. Autral. Math. Soc. A, 36, 12{29.Lauritzen, S. L., & Spiegelhalter, D. J. (1988). Local computations probabilitiesgraphical structures application expert systems. J.R. Statist. Soc. Ser.B, 50, 157{224.Pearl, J. (1988). Probabilistic Reasoning Intelligent Systems: Networks PlausibleInference. San Mateo: Morgan Kaufmann.Pearl, J., & Paz, A. (1985). Graphoids: graph-based logic reasoning relevancerelations. Tech. rep. 850038 (R-53-L), Cognitive Systems Laboratory, UCLA.Rose, D. J. (1970). Triangulated graphs elimination process. Journal Mathematical Analysis Applications, 32, 597{609.Shenoy, P. P. (1992). Conditional independence uncertainty theories. Dubois, D.,Wellman, M. P., D'Ambrosio, B., & Smets, P. (Eds.), Proceedings Eighth Conference Uncertainty Artificial Intelligence, pp. 284{291. San Mateo: MorganKaufmann.299fiDe CamposSpirtes, P., Glymour, C., & Scheines, R. (1993). Causation, Prediction Search. LectureNotes Statistics 81. New York: Springer Verlag.Verma, T., & Pearl, J. (1990). Causal networks: Semantics expressiveness. Shachter,R. D., Levitt, T. S., Kanal, L. N., & Lemmer, J. (Eds.), Uncertainty ArtificialIntelligence, 4, pp. 69{76. Amsterdam: North-Holland.Wermuth, N., & Lauritzen, S. L. (1983). Graphical recursive models contingencytables. Biometrika, 70, 537{552.Whittaker, J. (1991). Graphical Models Applied Multivariate Statistics. Chichester:Wiley.300fiJournal Artificial Intelligence Research 5 (1996) 95{137Submitted 3/96; published 9/96Accelerating Partial-Order Planners: TechniquesEffective Search Control PruningAlfonso Gerevinigerevini@ing.unibs.itLenhart Schubertschubert@cs.rochester.eduDipartimento di Elettronica per l'Automazione, Universita di BresciaVia Branze 38, I-25123 Brescia, ItalyDepartment Computer Science, University RochesterRochester, NY 14627-0226, USAAbstractpropose domain-independent techniques bringing well-founded partialorder planners closer practicality. first two techniques aimed improvingsearch control keeping overhead costs low. One based simple adjustmentdefault A* heuristic used ucpop select plans refinement. basedpreferring \zero commitment" (forced) plan refinements whenever possible, usingLIFO prioritization otherwise. radical technique use operator parameterdomains prune search. domains initially computed definitionsoperators initial goal conditions, using polynomial-time algorithmpropagates sets constants operator graph, starting initial conditions.planning, parameter domains used prune nonviable operator instancesremove spurious clobbering threats. experiments based modifications ucpop,improved plan goal selection strategies gave speedups factors ranging 51000 variety problems nontrivial unmodified version.Crucially, hardest problems gave greatest improvements. pruning techniquebased parameter domains often gave speedups order magnitudedicult problems, default ucpop search strategy improvedstrategy. Lisp code techniques test problems provided on-lineappendices.1. Introductionconcerned improving performance \well-founded" domain-independent planners { planners permit proofs soundness, completeness, desirabletheoretical properties. state-of-the-art example planner ucpop (Barrettet al., 1994; Penberthy & Weld, 1992), whose intellectual ancestry includes strips (Fikes &Nilsson, 1971), tweak (Chapman, 1987), snlp (McAllester & Rosenblitt, 1991).planners unfortunately perform well present, comparison practicallyoriented planners sipe (Wilkins, 1988), prs (Georgeff & Lansky, 1987), O-Plan(Currie & Tate, 1991).However, appear ample opportunities bringing well-founded plannerscloser practicality. following, begin suggesting improvementssearch control planning, based carefully formulated strategies selecting partialplans refinement, choosing open conditions selected partial plan. plan c 1996 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiGerevini & Schubertselection strategy uses S+OC { number steps plan plus number openconditions still established { heuristic measure ucpop's A* searchplan space. (Addition attenuated term ecting number threats \unsafeconditions" UC, 0.1UC, sometimes advantageous.)1 aw-selection strategy,term ZLIFO, prefers \zero commitment" plan refinements others, otherwiseuses LIFO (stack) discipline. Zero commitment refinements logically necessary ones:either eliminate plan altogether contains irremediable aw, addunique step unique causal link (from initial state) establish open conditioncannot established way. strategy closely related ones proposedPeot & Smith (1993) Joslin & Pollack (1994) generally appears perform bettereither.describe two classes techniques Section 2 below, Section 3report experimental results based slightly modified versions ucpop.2dicult problems taken available ucpop test suite elsewhere, obtainimprovements factors ranging 5 1000, hardest problemsgiving greatest improvements.turn proposal using computed operator parameter domainsplanning. particular, Section 4 motivate describe method precomputing parameter domains based propagating sets constants forward initialconditions.3 process iterative, algorithm runs within time boundpolynomial size problem specification. provide details algorithm,along theorems correctness tractability, Sections 4.2{4.3 OnlineAppendix 1.Section 5 show use parameter domain information ucpop-style planner. planning, parameter domains used prune operator instances whoseparameter domains inconsistent binding constraints, eliminate spuriousthreats cannot, fact, realized without violating domain constraints. illustrateeffectiveness technique examples drawn ucpop test suite welltrains transportation planning world developed Rochester (Allen & Schubert,1991; Allen et al., 1995). tests, apply parameter domain informationcontext default ucpop search strategy. demonstrate significant gainsproblems, particularly challenging ones (e.g., speedups ordermagnitude several problems strips world, 900-fold speeduptrains problem).another set tests trains world, use improved search strategiesbaseline, i.e., ask whether additional speedups obtainable use parameter1. search strategy described \A* IDA*" search (Penberthy & Weld, 1992); codeucpop 2.0 described generally best-first, since arbitrary ranking functions, necessarilycorresponding A* heuristics, may plugged in. choices like S+OC S+OC+UCplan-ranking heuristic (as discussed Section 2.2), natural view strategy A* strategy.2. techniques describe applicable planners, focus ucpopwell-known Lisp code readily available. system obtained via anonymous ftpcs.washington.edu.3. hope notion parameter domain, set admissible bindings (constants), causeconfusion notion planning domain, specified set operators, along constraintsadmissible initial conditions goal conditions.96fiAccelerating Partial-Order Plannersdomains, obtainable S+OC ZLIFO search strategies. experimental results show speedups factor 10 use parameterdomains, top obtained improved search strategies (the combined speedup2000).evidence effectiveness using parameter domains combinationsearch strategy dependent peculiarity latter, also includeresults ucpop's default strategy, Joslin Pollack's \least cost aw repair" (LCFR)strategy (Joslin & Pollack, 1994) Peot Smith's \least commitment" (LC) opencondition selection strategy (Peot & Smith, 1993) Section 5.Section 6, state conclusions, comment related work mentionpossible extensions techniques.2. Plan Selection Goal Selectionbasing discussion experiments ucpop, algorithm exemplifyingstate art well-founded partial-order planning. Thus begin sketchalgorithm, referring reader (Barrett et al., 1994; Penberthy & Weld, 1992) details.next two subsections motivate describe improved plan-selectiongoal-selection strategies.2.1 UCPOPucpop uses strips-like operators, positive negative preconditions positivenegative effects. initial state consists positive predications constant arguments(if any), ground predications false default. Unlike strips, ucpop alsoallows conditional effects, expressed 2-part when-clauses specifying (possibly complex)extra condition needed effect (possibly complex) effect itself. instance,action PUTON(?x ?y ?z) (\put ?x ?y ?z") might conditional effects stating?y table, clear end action, ztable, clear end action. \U" ucpop indicatesuniversally quantified conditions effects permitted well. instance,permissible precondition PICKUP(?x) action says ?y, (not(on ?y ?x)) holds. Universal statements handled explicit substitution domainconstants need concern us point.essence, ucpop explores space partially specified plans, pairedagenda goals still satisfied threats still averted. initial plan containsdummy *start* action whose effects given initial conditions, dummy*end* action whose preconditions given goals. Thus goals uniformly viewedaction preconditions, uniformly achieved effects actions, including*start* action.plans consist collection steps (i.e., actions obtained instantiating available operators), along set causal links, set binding constraints,set ordering constraints. open goal (precondition) selectedagenda, established (if possible) either adding step effect unifiesgoal, using existing step effect unifies goal. (Inlatter case, must consistent current ordering constraints place existing97fiGerevini & Schubertstep goal, i.e., step whose preconditions generated goal.)new existing step used establish goal way, several side effects:causal link (S ; Q; ) also added, indicates step \producing"goal condition Q indicates step \consuming" Q. causal link servesprotect intended effect added (or reused) step interferencesteps.Binding constraints added, corresponding unifier action effectquestion goal (precondition) achieves.ordering constraint added, placing step question step whoseprecondition achieves.action question new, preconditions added agenda newgoals (except EQ/NEQ conditions integrated binding constraints { seebelow).New threats (unsafe conditions) determined. new step causal link,steps threaten causal link effects unifiable conditionprotected causal link (and effects occur temporally causallink); effects new step may similarly threaten causal links.either case, new threats placed agenda. useful distinguish definitethreats potential threats: former unificationconfirmed threat involved new binding variables.Binding constraints assert identity (EQ) nonidentity (NEQ) two variables variableconstant. EQ-constraints arise unifying open goals action effects, NEQconstraints arise (i) NEQ-preconditions newly instantiated actions, (ii) matchingnegative goals containing variables initial state, (iii) averting threats\separation", i.e., forcing non-equality two variables variable constantunified threat detection. NEQ-constraints may disjunctive, handled simplygenerating separate plans disjunct.overall control loop ucpop consists selecting plan current listplans (initially single plan based *start* *end*), selecting goal threatagenda, replacing plan corresponding refined plans. agenda itemgoal, refined plans corresponding ways establishing goal usingnew existing step. agenda item definite threat causal link (S ; Q; ),three refined plans. Two constrain threatening stepstep (demotion) step (promotion), thus averting threat.third possibility arises effect threatening (S ; Q; ) conditional effectthreatening action. conditional threat averted creating goal denyingprecondition needed conditional effect.ucpop \delay separation" switch, *d-sep*, turned on,definite threats dealt with. Note potential threats may become definite resultadded binding constraints. (They may also \expire" result added bindingordering constraints, i.e., threatening effect may longer unify threatenedcondition may forced occur threatened causal link. Expiredpcpcppcp98ccfiAccelerating Partial-Order Plannersthreats removed agenda selected.) *d-sep* off, potential threatswell definite ones averted, separation additional methodbesides three methods above.Inconsistencies binding constraints ordering constraints detectedfirst occur (as result adding new constraint) corresponding plans eliminated. Planning fails plans remain. success condition creation planconsistent binding ordering constraints empty agenda.allowance conditional effects universal conditions effects causesminor perturbations operation ucpop. instance, conditional effects leadmultiple matches operators given goal, match generating differentpreconditions. (Of course, multiple matches even without conditional effects,predicates occur effects.)key issues us right strategic ones: plans selectedcurrent set plans (discussed Section 2.2), goals selected given plan(discussed Section 2.3).2.2 Trouble Counting Unsafe Conditionschoice next plan refine ucpop system based A* best-firstsearch. Recall A* uses heuristic estimate f (p) overall solution cost consistingpart g (p) = cost current partial solution (plan) p part h(p) = estimateadditional cost best complete solution extends p. current contexthelpful think f (p) measure plan complexity, i.e., \good" plans simple(low-complexity) plans.two points reader reminded. First, order A*guarantee discovery optimal plan (i.e., \admissibility" condition), h(p)overestimate remaining solution cost (Nilsson, 1980). Second, aimnecessarily find optimal solution find satisfactory solution quickly, f (p)augmented include term estimates remaining cost finding solution.One common way use term proportional h(p) well, i.e.,emphasize h-component f relative g -component. reasonableextent plans nearly complete (indicated low h-value) likelytake least effort complete. Thus prefer pursue plan p0 seems closercomplete plan p completion, even though overall complexityestimate p0 may greater p (Nilsson, 1980) (pages 87{88). Alternatively,could add heuristic estimate remaining cost finding solution f (p)less independent estimate h(p).considerations mind, evaluate advisability includingvarious terms ucpop's function guiding A* search, namelyS, OC, CL, UC,number steps partial plan, OC number open conditions(unsatisfied goals preconditions), CL number causal links, UCnumber unsafe conditions (the number pairs steps causal links step99fiGerevini & Schubertthreatens causal link). default combination used ucpop S+OC+UC.4becomes S+OC+UC+F special open conditions called \facts" present.conditions state-dependent (e.g., numerical relation like (add-one ?x ?y),geometrical one like (loc-in-room ?x ?y ?room)) established Lisp functions(Barrett et al., 1994). Since test problems involved facts, discussF term except say followed ucpop default strategy includingterm relevant (see TileWorld problems Section 3.2 also remarksSection 5.2 connection parameter-domain experiments).2.2.1 S: number steps currently plannaturally viewed comprising g (p), plan complexity far. Intuitively,plan complex extent contains many steps. domains mightwant make distinctions among costs different kinds steps, simple step countseems like reasonable generic complexity measure.2.2.2 OC: number open conditionsviewed playing role h(p), since remaining open condition mustestablished step. catch may possible use existing stepsplan (including *start*, i.e., initial conditions) establish remaining open conditions.Thus OC overestimate number steps still added, forfeiting admissibility.Despite criticism, several considerations favor retention OC term. First,better estimator residual plan complexity seems hard come by. Perhaps one couldmodify OC discounting open conditions matched existing actions,presumes open conditions actually achieved action re-use,improbable remaining threats, remaining goals requiring new steps.5 Second,possibility OC overestimate residual plan complexity rarely actualized, since typically steps still need added achieve goals,steps typically introduce open conditions requiring new steps. Finally, extent OC times overestimate residual plan complexity,viewed emphasizing h(p) term f (p), thus promoting faster problem-solvingexplained above.2.2.3 CL: number causal linksOne might motivate inclusion term arguing numerous causal linksindicative complex plan. such, CL appears alternative step-counting.4. way \recommended" strategy. ucpop implementation makes available variousoptions controlling search, used discretion experimenters. present workprompted incorporation particular strategies option ucpop 4.0.5. Note threats remaining goals impose constraints may consistent seeminglypossible instances action re-use. clear enough threats, often imply temporal orderingconstraints inconsistent re-use action. also fairly clear remaining goals. instance,Towers Hanoi small disk D1 initially medium disk D2, turn big diskD3, D3 peg P1. goal move tower third peg P3, seems ucpop initially(on D1 D2) (on D2 D3) could achieved \re-use" *start*. However, third goal (onD3 P3) implies various actions must added plan inconsistent twoseemingly possible instances action re-use.100fiAccelerating Partial-Order PlannersHowever, note CL general larger S, since every step plan establishesleast one open condition thus introduces least one causal link. larger CLrelative S, subgoals achieved action re-use. Hence, use CL instead(or addition to) g (p) term, would effect saying achieving multiplesubgoals single step undesirable; would tend search ways achievingmultiple goals multiple steps, even achieved single step.clearly good idea, justifies exclusion CL f (p).2.2.4 UC: number unsafe conditionsnote first clearly g -measure. number threatstend increase establish subgoals without curtailing threats, threatselements plan constructed contributecomplexity. fact, plan done threats gone.UC viewed h-measure? One argument sorts armativefollowing. partial plans expandable complete plans, high valueUC makes likely partial plan contains irresolvable con icts. regardimpossible plans infinite cost, inclusion term increasing UC parth-measure reasonable. carries serious risk, though, since casepartial plan consistent completion (despite high UC-count), inclusionterm greatly overestimate residual plan complexity.Another possible armative argument conditional threats sometimes resolved\confrontation", introduces new goal denying condition required threatening conditional effect. new goal may turn require new steps achievement,adding plan complexity. However, link complexity tenuous. firstplace, many ucpop test domains involve conditional effects, threat removalpromotion, demotion separation adds steps. Even conditional effectspresent, many unconditional well conditional threats averted methods.Furthermore, UC could swamp terms since threats may appear expiregroups size O(n), n number steps plan. instance, considerpartial plan involves moves robot R locations L1, ..., Ln,n causal links labeled (at R L1), ..., (at R Ln). new move location Ladded, initially indefinite point departure ?x, produces effects (atR L) (not (at R ?x)). latter threaten n causal links,least new move first temporally unordered relative n existing moves.new action subsequently happens demoted precede first move (orpromoted follow last), ?x becomes bound constant distinctL1, ..., Ln, n threats expire. Keeping mind different steps plan maysimilar effects, see half steps could threaten causal linksothers. case could O(n2 ) unsafe conditions, destined expire resultO(n) promotions/demotions. fact even single new binding constraint may causeO(n2 ) threats expire. instance, n=2 effects (not (P ?x)) threateningn=2 causal links labeled (P ?y), binding constraint (NEQ ?x ?y) added, n2 =4threats expire. Recall expired threats selected agenda ucpop,recognized discarded without action.101fiGerevini & Schubertconclusion would mistake include UC full general h-measure,though increasing function UC remains small enough mask OC mayworth including h.Finally, UC regarded measure remaining cost finding solution?Here, similar arguments apply. armative side, arguehigh value UC indicates may facing combinatorially explosive, timeconsuming search set promotions demotions produce con ict-free stepordering. words, high value UC may indicate high residual problem-solvingcost. (And end search, may still lack solution, viable stepordering exists.) hand, already noted unsafe conditions includemany possible con icts may expire result subsequent partial ordering choicesvariable binding choices specifically aimed removing con icts. countingunsafe conditions arbitrarily overestimate number genuine refinement steps,hence problem-solving effort, still needed complete plan.UC scarcely trustworthy measure residual planning costmeasure residual plan cost.Thus conclude promising general heuristic measure plan selectionS+OC, possibly augmented attenuated form UC term dominateS+OC component. (For instance, one might add small fraction term,UC/10, subtly { avoid swamping quadratic component { term proportionalUC 5.):2.3 Goal Selection Strategyimportant opportunity improving planning performance independently domainlies identifying forced refinements, i.e., refinements made deterministically.Specifically, considering possible refinements given partial plan, makes sensegive top priority open conditions cannot achieved; preferring openconditions achieved one way { either addition actionyet plan, unique match initial conditions.argument giving top priority unachievable goals plan containinggoals eliminated once. Thus prevent allocation effort refinementdoomed plans, generation refinement doomed successor plans.argument preferring open conditions achieved one wayequally apparent. Since every open condition must eventually establishedaction, follows action unique, must part every possible completionpartial plan consideration. So, adding action \zero-commitment"refinement, involving choices guesswork. time, adding refinementgeneral narrows search space adding binding constraints, ordering constraintsthreats, constrain existing steps subsequently added steps. uniquerefinements narrowing-down monotonic, never needing revocation. example,suppose refinement happens add constraints eliminate certain action instancepossible way achieving certain open condition C . refinement unique,assured completion plan contains way establishing C .unique, assurance, since alternative refinement may102fiAccelerating Partial-Order Plannerscompatible use achieve C . short, zero-commitment strategy cutssearch space without loss access viable solutions.Peot Smith (1993) studied strategy preferring forced threats unforcedthreats, also used \least commitment" (LC) strategy handling open conditions.Least commitment always selects open condition generates fewest refinedplans. Thus entails priorities unachievable uniquely achievable goals(while also entailing certain prioritization nonuniquely achievable goals). JoslinPollack (1994) studied uniform application strategy threats openconditions ucpop, terming strategy \least cost aw repair" (LCFR). Combiningucpop's default plan selection strategy, obtained significant search reductions(though less significant running time reductions, mainly implementation reasons,also intrinsic overhead computing \repair costs") majorityproblems ucpop test suite.Joslin & Pollack (1994) subsequently Srinivasan & Howe (1995) proposedvariants LCFR designed reduce overhead incurred LCFR aw selection.strategies employ various assumptions aw repair costs, allowingarduous forms cost estimation (requiring look-ahead generation plans) confinedsubset aws plan, rest approximation usedsignificantly increase overhead. teams obtained quite significant reductionsoverhead costs many cases, e.g., factors ranging 3 20dicult problems. However, overall performance sometimes adversely affected.Joslin Pollack found variant (QLCFR) solved fewer problems LCFR,increase number plans generated cases. Srinivasan &Howe's four strategies slightly better LCFR 10 problem domainssignificantly worse others. terms plans examined search, bestoverall strategy, uses similar action instances similar aws, slightly better4 domains, slightly worse 4, significantly worse 2 (and casesnumber plans examined also factor 20 default ucpop).unmodified form ucpop, goals selected agenda accordingLIFO (last-in first-out, i.e., stack) discipline. Based experience search processesAI general, strategy much recommend it, simple default.first place, overhead cost low compared strategies use heuristic evaluationlookahead prioritize goals. well, tend maintain focus achievementparticular higher-level goal regression { much Prolog goal chaining { ratherattempting achieve multiple goals breadth-first fashion.Maintaining focus single goal advantageous leastgoals achieved independent. instance, suppose two goals G1 G2achieved various ways, choosing particular method achieving G1rule methods achieving G2. maintain focus G1solved, attempting G2, total cost solving goals sumcosts solving individually. switch back forth, solutionsgoals involve searches encounter many dead ends, combined costmuch larger. tend search unsolvable subtree G1 searchtree repeatedly, combination various alternatives G2 search tree (and viceversa). argument still validity even G1 G2 entirely103fiGerevini & Schubertindependent; i.e., long G1 gives rise subproblems tend failway regardless choices made attempt solve G2 (or vice versa), shiftingattention G1 G2 tend generate set partial plans unnecessarily\cross-multiplies" alternatives.therefore chosen stay ucpop's LIFO strategy wheneverzero commitment choices. led substantial improvements LCFRexperiments.Thus strategy, term ZLIFO (\zero-commitment last-in first-out"), choosesnext aw according following preferences:1. definite threat (*d-sep* turned on), using LIFO pick among these;2. open condition cannot established way;3. open condition resolved one way, preferring open conditionsestablished introducing new action establishedusing *start*;64. open condition, using LIFO pick among these.Hence overhead incurred ZLIFO aw selection limited open conditions, lower overhead incurred LCFR. Furthermore,also significantly lower practice overhead incurred LC, testingwhether OC zero-commitment choice (i.e., whether establishedone way) less expensive computing total number ways achieve it.Online Appendix 1 give pseudocode ZLIFO selection opencondition (preferences 2{4). recently implementation also packageducpop 4.0, new version ucpop available anonymous ftp cs.washington.edu.3. Experiments Using UCPOPorder test ideas modified version 2.0 ucpop (Barrett et al., 1994), replacing default plan-selection strategy (S+OC+UC) goal-selection strategy (LIFO)incorporate strategies discussed previous sections.tested modified planner several problems ucpop suite, emphasizingproved challenging previous strategies, artificial problemsdue Kambhampati et al. (1995), trains transportation domain developedRochester (Allen & Schubert, 1991; Allen et al., 1995), Joslin & Pollack's TileWorlddomain (Joslin & Pollack, 1994). brie describe test problems platformsparameter settings used, present experimental results improvedsearch strategies.6. 2. 3. zero-commitment choices. experiments, described next section,sub-preference 3. gave improvements context Russell's tire changing domain (in particularFix3), without significant deterioration performance domains.104fiAccelerating Partial-Order Planners3.1 Test Problems Experimental Settingsucpop problems include Towers Hanoi (T H), Fixa, Fix3, Fixit, Tower-Invert4,Test-Ferry, Sussman-Anomaly. case H, added 3-operator versionucpop single-operator version, since H particularly hard problem ucpopdiculty long known sensitive formalization (e.g., (Green,1969)). Fixa problem Dan Weld's \fridge domain", compressorfridge exchanged, requiring unscrewing several screws, stopping fridge,removing backplane, making exchange. Fix3 Stuart Russell's \ tiredomain", new wheel mounted lowered ground (the old wheeljacked already nuts loosened); requires unscrewing nuts holdingold wheel, removing wheel, putting new wheel, screwing nuts, jackinghub, tightening nuts. Fixit complicated, wheel yetjacked initially nuts yet loosened, spare tire needs ated,jack, wrench pump need taken trunk stowedend. Tower-Invert4 problem blocks world, requiring topmost block stackfour blocks made bottom-most. Test-Ferry simple problem requiring two carsmoved B using one-car ferry, boarding, sailing, unboardingcar.artificial problems correspond two parameter settings ART-# -# , onetwo artificial domains served testbed Kambhampati et al.'s extensivestudy behavior various planning strategies function problem parameters(Kambhampati et al., 1995). ART-# -# provides two layers 10 operators each,layer 1 achieve preconditions layer 2, operatorlayer 2 achieves one 10 goals. However, operators layer establishclobber preconditions neighbors, force operators usedcertain order.version trains domain encoded involves four cities (Avon, Bath,Corning, Dansville) connected four tracks diamond pattern, fifth city (Elmira)connected Corning fifth track. available resources, located variouscities, consist banana warehouse, orange warehouse, orange juice factory, threetrain engines (not coupled cars), 4 boxcars (suitable transporting orangesbananas), tanker car (suitable transporting orange juice). Goals typicallydeliver oranges, bananas, orange juice city, requiring engine-car coupling, carloading unloading, engine driving, possibly OJ-manufacture.TileWorld domain consists grid holes tiles scattered. giventile may may fit particular hole. goals fill one holesusing three possible actions: picking tile, going x-y location grid,dropping tile hole. agent carry four tiles time.Formalizations domains terms ucpop's language provided OnlineAppendix 2. experiments problems except Fixit, trains problemsTileWorld problems conducted sun 10 using Lucid Common Lisp 4.0.0,rest (Tables X{XI next subsection) conducted sun 20 using AllegroCommon Lisp 4.2. Judging repeated experiments, thinkestestclob105clobfiGerevini & SchubertGoal-selection Plan-selection CPU secLIFOLIFOZLIFOZLIFOS+OC+UCS+OCS+OC+UCS+OC204.510.976.900.54Plans160,911/107,649751/5111816/1291253/184Table I: Performance plan/goal selection strategies T-of-H1differences platforms significantly impact performance improvements.7 Amongsearch control functions provided ucpop, used default bestf-searchproblem solvable within search limit 40,000 plans generated, usedfunction id-bf-search (an implementation linear-space best-first search algorithmgiven Korf, 1992), limit exceeded.8 experiments delayseparation switch, *d-sep*, on, except using LCFR strategy.3.2 Experimental Results ZLIFO S+OCTables I{XI show CPU time (seconds) number plans created/exploreducpop twelve problems domains described above: Towers Hanoi threedisks either one operator (T-of-H1) three operators (T-of-H3), fridge domain(Fixa), tire changing domain (Fix3 Fixit), blocks world (Tower-Invert4Sussman-anomaly), ferry domain (Test-Ferry), artificial domain ART-# -#(specifically, ART-3-6 ART-6-3), trains domain (Trains1, Trains2 Trains3)TileWorld domain (tw-1, ..., tw-6). number plans created/exploredCPU time important performance measures. number plans, indicatessearch space size, stable measure sense depends searchalgorithm, implementation.9 time still interest since improvementsearch may purchased price time-consuming evaluationalternatives. turns pay price overhead substitutestrategies defaults (factors ranging 1.2 1.9, rarely higher, per plancreated). may due slightly greater inherent complexity ZLIFO versus LIFO,think differences could reduced substituting modified data structuresucpop { committed altering these.Tables II show H plan selection strategy S+OC gives dramaticimprovements default S+OC+UC strategy. (In tests default LIFO goalselection strategy used.) fact, ucpop solved T-of-H1 0.97 seconds using S+OCversus 204.5 seconds using S+OC+UC. T-of-H3 proved harder solve T-of-H1, reestclob7. differences result available different times locales coursenearly two years experimentation.8. choice motivated observation problem relatively easy solvebestf-search appears ecient id-bf-search, hard problemsinecient considerable amount space used run time CPU time spentgarbage collection, cases made Lisp crash, reporting internal error.9. also worth noting number plans created implicitly takes account plan size, sinceaddition step plan counted creation new plan ucpop.106fiAccelerating Partial-Order PlannersGoal-selection Plan-selection CPU sec PlansLIFOS+OC+UC> 600 > 500,000LIFOZLIFOZLIFOS+OCS+OC+UCS+OC8.54> 6001.245506/3415> 500,000641/420Table II: Performance plan/goal selection strategies T-of-H3Goal-selection Plan-selection CPU secLIFOLIFOZLIFOZLIFOS+OC+UCS+OCS+OC+UCS+OC2.452.480.330.33Plans2131/19032131/190396/7496/74Table III: Performance plan/goal selection strategies Fixaquiring 8.5 seconds using S+OC unknown time excess 600 CPU seconds usingS+OC+UC.ZLIFO goal-selection strategy significantly accelerate planning comparedsimple LIFO strategy. particular, ZLIFO combined S+OC planselection strategy solving H, reduced number plans generatedfactor 3 T-of-H1 factor 8 T-of-H3. overall performance improvementT-of-H1 thus factor 636 terms plans created factor 379 termsCPU time (from 204.5 0.54 seconds).Tables III{VIII provide data problems easier H, still challenging ucpop operating default strategy, namely Fixa (Table III), Fix3 (Table IV),Tower-Invert4 (Table V), Test-Ferry (Table VI) artificial domain ART-# -## = 3 # = 6 (Table VII) # = 6 # = 3 (Table VII).results show combination S+OC ZLIFO substantially improvesperformance ucpop comparison performance using S+OC+UC LIFO.number plans generated dropped factor 22 Fixa, factor 5.9estestclobestGoal-selection Plan-selection CPU secLIFOLIFOZLIFOZLIFOS+OC+UCS+OCS+OC+UCS+OC6.500.431.121.53clobPlans3396/2071351/215357/221574/373Table IV: Performance plan/goal selection strategies Fix3107clobfiGerevini & SchubertGoal-selection Plan-selection CPU sec PlansLIFOLIFOZLIFOZLIFOS+OC+UCS+OCS+OC+UCS+OC1.350.192.810.36808/540148/105571/378142/96Table V: Performance plan/goal selection strategies Tower-Invert4Goal-selection Plan-selection CPU sec PlansLIFOLIFOZLIFOZLIFOS+OC+UCS+OCS+OC+UCS+OC0.630.320.240.22718/457441/301136/91140/93Table VI: Performance plan/goal selection strategies Test-FerryGoal-selection Plan-selection CPU secLIFOLIFOZLIFOZLIFOS+OC+UCS+OCS+OC+UCS+OC.671.360.160.18Plans568/3921299/84072/4979/54Table VII: Performance plan/goal selection strategies ART-# -## = 6 (averaged 100 problems)estclob# = 3estclobGoal-selection Plan-selection CPU secLIFOLIFOZLIFOZLIFOS+OC+UCS+OCS+OC+UCS+OC1.322.080.140.14Plans985/6531743/104357/3757/37Table VIII: Performance plan/goal selection strategies ART-# -## = 3 (averaged 100 problems)estclob# = 6clobGoal-selection Plan-selection CPU sec PlansLIFOLIFOZLIFOZLIFOS+OC+UCS+OCS+OC+UCS+OC0.060.040.120.0744/2636/2167/4341/25Table IX: Performance plan/goal selection strategies Sussman-anomaly108estfiAccelerating Partial-Order Planners1000FixitTrains12T-of-H1 2PerformanceImprovement21002ART-6-3 2 Fixa2 Search space reductionART-3-6 2222 Fix3SpeedupTower-invert4Test-ferrySussman-anomaly21e+07100100010000 100000 1e+06Problem size10110Figure 1: Performance improvement due ZLIFO S+OC, relative numberplans generated LIFO S+OC+UC (log-log scale). improvementsproblems ucpop unable solve even high search limit(Trains2, Trains3, T-of-H3) included.Fix3, factor 5.7 Tower-Invert4, factor 5.1 Test-Ferry, factor 7ART-3-6, factor 17 ART-6-3.Concerning ART-# -# , note performance obtained unenhanceducpop (568 plans generated ART-3-6 985 ART-6-3) much(just marginally better than) reported Kambhampati et al. (1995) best plannersconsidered (700 { 1500 plans generated ART-3-6, 1000-2000 ART-6-3).expected, since ucpop generalization earlier partial-order planners.Relative standard ucpop predecessors, \accelerated" planner thus ordermagnitude faster. Interestingly, entire improvement ascribed ZLIFO(rather S+OC plan selection, actually little worse S+OC+UC).probably due unusual arrangement operators ART-# -# \clobbering chain" (A , 1 clobbers , ,1 1 's preconditions, ..., A1 1 clobbers A0 1's preconditions;similarly 2 ), makes immediate attention new unsafe conditions unusuallygood strategy.experimenting various combinatorially trivial problems unmodified ucpophandles ease, found S+OC ZLIFO strategy neither beneficialharmful general; may slight improvement slight degradation performance. Results Sussman anomaly Table IX provide illustrative example.summarize results Tables I{X Figure 1, showing performance improvements obtained combined ZLIFO goal selection strategy S+OC plan selectionestclobestn;n;;i;109clob;fiGerevini & SchubertZLIFO &S+OCLC &S+OCLCFR &S+OCLIFO &S+OC+UCTrains1Trains2Trains3FixitPlans4097/201917,482/10,907 31,957/19,2825885/3685Time13.780.6189.832.5Plans438/24234,805/24,000 253,861/168,85271,154/46,791Time2.6368.91879.9547.8Plans1093/597>1,000,000>1,000,000190,095/117,914Time10.65>10,905>99184412.36Plans 1,071,479/432,881 > 10,000,000> 1,000,000 8,090,014/4,436,204Time3050.15> 37,879> 253927,584.9Table X: Performance plan selection strategy S+OC combination goalselection strategies ZLIFO, LCFR LC solving problemshard default strategies ucpop (S+OC+UC/LIFO). (The CPU secondsinclude Lisp garbage collection. number plans generated LCFRinclude created order estimate repair cost aws.)ProblemZLIFO*LCFRname CPU time Plans CPU time Planstw-1tw-2tw-3tw-4tw-5tw-60.090.612.557.8019.4142.5726/1572/39138/71224/111330/159456/2150.100.663.1710.9730.1771.1026/1572/39139/72227/114336/165466/225Table XI: Performance UCPOP TileWorld domain using ZLIFO* LCFRgoal selection, S+OC+F+0.1UC plan selectionstrategy function problem diculty (as indicated number plans generateddefault LIFO plus S+OC+UC strategy). trend toward greater speedupscomplex problems (though somewhat dependent problem type) quite apparentlog-log plot.direct comparison Joslin Pollack's LCFR strategy Peot Smith'sLC strategy, implemented strategies applied several problems.well (sometimes better ZLIFO) problems lower end dicultyspectrum, poorly harder problems. (For problems ran, LC*d-sep* switch performed better LCFR terms plans explored CPUtime required.) T-of-H1 LCFR combination default S+OC+UC planselection strategy, S+OC plan strategy find solution within searchlimit 200,000 plans generated (cf. 253 ZLIFO S+OC, 751 ZLIFOS+OC+UC), requiring unknown CPU time excess 4254 seconds S+OC+UC,110fiAccelerating Partial-Order Plannersexcess 4834 seconds S+OC (cf. 0.54 seconds ZLIFO S+OC).10LC performed much better LCFR still considerably worse ZLIFO, solvingT-of-H1 generating/exploring 8313/6874 plans S+OC 8699/6441 plansS+OC+UC, requiring 44.4 CPU secs. 48.95 CPU secs. respectively. T-ofH3, LC found solution generating/exploring 21,429/15,199 plans S+OC+UC17,539/14,419 plans S+OC, requiring 145.18 CPU secs. 77.84 CPU secs.respectively.Table X shows results plan strategy S+OC, goal strategies ZLIFO,LCFR LC, applied three problems (Trains1, Trains2 Fixit). shown datatable hard default strategies ucpop (LIFO & S+OC+UC),become relatively easy S+OC used combination either ZLIFO, LCFRLC. LCFR LC slightly better ZLIFO Trains1 (the easiestproblems), performed quite poorly Fixit, Trains2 Trains3 (the hardestproblems) compared ZLIFO.Joslin Pollack (1994) tested LCFR strategy six problems TileWorld(tw-1, ..., tw-6), five hard default ucpop, easy ucpop usingLCFR.11 tested ZLIFO strategy TileWorld using six problems.ZLIFO well tw-1{4, tw-5 tw-6 performance dropped wellLCFR. raised question whether particular problems crucialminimize \repair cost" aw selection uniformly, rather certain special cases(ZLIFO minimize repair cost threat aw list, least one zerocommitment open condition present). However, experiments aimed answeringquestion suggested poor choices made ZLIFO TileWorld problemsdue selection \high cost" \low cost" aws. Instead two factors appearcrucial improving ZLIFO: (a) emphasizing zero-commitment open conditions givinghigher priority threats; (b) zero-commitment open conditions,resolving threats soon enter agenda. (We realized relevance (b)observing performance modified versions LCFR, *d-sep* switchimplicitly forced on, dramatically degraded tw-6 slightly different formulationTileWorld.)extended ZLIFO strategy include (a) (b), brie testedresulting variant ZLIFO (ZLIFO*). Table XI shows results ZLIFO* togetherplan selection strategy S+OC+0.1UC+F, discussed Section 2.3 includedattenuated form UC term (UC/10), F term equal number factssince TileWorld uses facts track number tiles carried agent.12 ZLIFO*10. *d-sep* turned off, implicit setting LCFR (Joslin, 1995). experimentsalso tested variant LCFR, switch forced on. resulting goal strategycombination plan strategy S+OC performed significantly better T-of-H1, solving problemgenerating/exploring 7423/6065 plans, using 110.45 CPU seconds. Note also comparisonimplementation LCFR Joslin & Pollack's implementation used experiments discussed(Joslin & Pollack, 1994) showed implementation considerably faster (Joslin, 1995).11. experiments tw-2, easiest among tw-2{6, solved ucpop even allowed runeight hours. hand, ucpop using LCFR solves tw-6, hardest problem, withoutever reaching dead-end node search tree.12. ZLIFO* experiments refined plans generated resolving threat added aw listfollowing order: first plan generated promotion, plan generated demotion,finally plan generated confrontation separation.111fiGerevini & Schubertperformed eciently six TileWorld problems, fact little better LCFR.Note problems ZLIFO* ecient LCFR terms CPU time,even though number plans generated/explored two strategies approximatelysame. overhead selecting next aw handled higherLCFR ZLIFO* (and ZLIFO). fact, LCFR needs compute \repaircost" aw (including threats) current plan, ZLIFO* (ZLIFO) needscheck presence zero-commitment open conditions, without processing threats.Additional experiments indicated average performance ZLIFO* comparableZLIFO problems used experiments, termsplans created/explored. However, CPU time tends increase since overheadcomputing goal selection function higher ZLIFO* ZLIFO,extra agenda-management costs. overhead, regard ZLIFO*generally preferable ZLIFO. However, TileWorld experiments underscored usworlds refinements ZLIFO advantageous.Finally, another possible variant ZLIFO, suggested us David Smith,based following preferences next aw handled: (i) threat cannotresolved; (ii) open condition cannot established; (iii) threatone possible resolution; (iv) open condition established one way; (v)threats; (vi) open conditions (using LIFO pick among these). observestrategy could give savings terms plans created/explored,also imposes additional overhead respect ZLIFO ZLIFO* coulddegrade performance terms CPU time.4. Precomputing Parameter DomainsEven speedups obtained improved search, ucpop-like algorithm remainsseverely limited complexity problems solve. believe significantprogress requires fuller use global properties search space, determinedstructure operators, initial conditions, goals. One way wouldin-depth analysis alternatives search, lead highoverhead costs. Another precompute constraints search space, useplanning prune search. parameter domain method motivatedescribe latter type.4.1 Parameter Domains Help?previous experimentation ucpop strategies, found ucpop goal regression often hypothesized steps doomed abandoned eventually,stipulated impossible parameter bindings. clear example occurred Molgendomain, encoded ucpop test suite. goal \Rat-insulin" test problem(and (bacterium ?b) (molecule ?m)(contains IG ?m) (contains ?m ?b) (pure ?b)),?b ?m existentially quantified variables. means wishcreate purified bacterial culture ?b, ?b contains molecule ?m (necessarily112fiAccelerating Partial-Order Plannersexosome, turns out), molecule turn contains insulin gene, IG.using abbreviations IG, EE, JE, L insulin-gene, e-coli-exosome, junk-exosome,linker; E, J, A1 e-coli, junk, antibiotic-1. Roughly speaking, solutioninvolves processing initially given mRNA form insulin gene produceform insulin DNA spliced e-coli-exosome, using ligate operator.turn, exosome inserted e-coli bacterium using transform operator,bacterial culture purified using screen operator, antibiotic-1. (The junkbacterium exosome merely serve complicate task { nearly, quite,substitutable e-coli bacterium exosome; junk exosome, unlike e-coli-exosome,resistant antibiotic-1, violating precondition screen.)Now, initial regression goals (bacterium ?b) (molecule ?m)established *start* operator, i.e., initial conditions, thusinstantiated bizarre values. (The initial conditions supply E Jinstances bacterium, IG, EE, JE, L instances molecule.)hand, remaining goals turn match effects various instancesligate, transform, screen operators Molgen, follows:(contains IG ?m): (ligate IG ?m), (transform IG ?m)(contains ?m ?b): (ligate ?m ?b) (transform ?m ?b)(pure ?b):(screen ?b ?y ?z),ucpop happily regress actions. Yet two them,(transform IG ?m)doomed fail, perhaps great deal effort expendedtrying satisfy preconditions. particular, examination constants\ ow into" transform operator initial conditions Molgen operatorsshows first argument restricted domain fEE, JEg, i.e., must onegiven exosomes, second restricted fE, Jg, i.e., must onegiven bacteria. Consequently instance (transform IG ?m) unrealizable, firstargument IG fEE, JEg. (Note distinct constants denote distinct entitiesaccording unique-names assumption made ucpop.) (ligate ?m ?b) actiondoomed slightly subtle reasons. result match (contains ?m?b) \when-clause" (conditional effect) ligate operator, whose preconditionsreached second parameter ?b lies set molecules fIG, JE, EEg;yet ?b also restricted set bacteria fE, Jg, result goal condition(bacterium ?b). fact sets disjoint allow us eliminate(transform IG ?m) action.Note elimination action candidates increases number zero commitment plan refinements made. example, left exactly oneaction three goals, ZLIFO LCFR strategies preferregress goals rather regressing (bacterium ?b) (molecule ?m) {would prematurely make arbitrary choices ?b ?m initial state.(ligate ?m ?b),4.2 Description Algorithmcompleted plan, precondition action must instantiated effectearlier action. values parameters action values113fiGerevini & Schubert\produced" earlier actions, starting initial action, *start*. Moreover,suppose parameter x certain action occurs preconditions P1, ..., Pk.constant c possible value x earlier actions instantiate x cP1, ..., Pk.algorithm find-parameter-domains based observations. Beginninginitial state, propagates positive atomic predications possible operator preconditions. propagated ground atom, atom matches operator precondition,algorithm adds constants ground atom individual domainsparameters unified with. individual domains particular specific preconditions. instance, individual domain ?x operator preconditions(on ?x ?y), (clear ?x) general distinct two preconditions.soon nonempty individual domains parameters preconditionsoperator, form intersection individual domains parameteroperator. example, (on ?x ?y) (so far) matched (on B)(on B C), (clear ?x) (so far) matched (clear A) (clear Table),individual domain x fA,Bg first precondition fA,Tablegsecond. Thus (assuming preconditions) intersected domain?x fAg point. later (clear B) also matched (clear ?x),intersected domain ?x grow fA,Bg. ?x ?y nonemptyintersected domains, effects (postconditions) operator turn propagated,?x ?y \bound" intersected domains.propagated effects matched possible operator preconditions,variable \bound" intersected domain successfully unified variable precondition, passes intersected domain individual domainprecondition-variable (via union operation). lead growth intersected domains operator whose precondition matched, effects operatormay propagated, on. individual domains intersected domains growmonotonically propagation process, end represent desired parameter domains operators.illustrate process example. Consider simple planning problemdepicted Figure 2 \operator graph" (Smith & Peot, 1993) used describelogical dependencies among operators, iterative computation parameterdomains graphically illustrated \domain-propagation graph" operatorgraph.initial conditions (P A) (P B) unify precondition (P ?x) op1. So,individual domain ?x relative precondition P op1 fA,Bg.hand, precondition (Q ?x) op1 cannot satisfied initial state,individual domain ?x relative Q initially empty set. Hence intersected domain?x op1 also empty set.op2 different situation, since one preconditionestablished initial state. Therefore, individual domain ?y relativeprecondition R op2 set constants fB,Cg, intersected domain ?yop2 set (because R precondition op2 involving ?y). Sinceintersected domain ?y enlarged (initially empty), propagatedindividual domains operators effect (Q ?y) op2. particular,114fiAccelerating Partial-Order Planners(P ?x)indicates bundle edgesop1(Q ?x)(T B)*start*(R ?y)*end*op2Init state: (P A),(P B),(R B),(R C),(S C)(S ?z)op1:preconds: (P ?x),(Q ?x)Goal: (T B)op3op2:preconds: (R ?y)op3:preconds: (S ?z)effects: (T ?z)effects: (Q ?y)effects: (S ?x)(P A)(P ?x)(Q ?x)id(?x)={B}id(?x)={}op1(P B)(Q ?x)op1ID(P,?x)={A,B}ID(Q,?x)={B,C}ID(P,?x)={A,B}ID(Q,?x)={}(Q ?y)id(?y)={B,C}(R B)(R ?y)(R C)(S ?x)op2ID(R,?y)={B,C}id(?z)={A}S(A)(S ?z)id(?z)={A,B}op3(S ?z)ID(S,?z)={A}op3ID(S,?z)={A,B}Figure 2: Operator domain-propagation graphs simple planning problem.ID(?x,P) indicates individual domain parameter ?x relative precondition P; id(?x) indicates intersected domain parameter ?x; finalintersected domains indicated using bold fonts.matches precondition (Q ?x) op1. So, individual domain ?x relativeprecondition Q op1 updated adding constants intersected domain ?yit. Thus intersected domain ?x enlarged fBg, propagatedeffect (S ?x) op1.Similarly, propagation (S ?x) enlarge individual domain ?z op3,also intersected domain, set fA,Bg. Therefore, final intersected domainsare: fBg ?x op1; fB,Cg ?y op2; fA,Bg ?z op3.presenting algorithm little formally, note parameter domains sometimes \too large", including values would found impossible(Q ?y)115fiGerevini & Schubertdetailed state space exploration conducted. However, requiredsoundness use domains \too small" (i.e.,contain parameter values actually occur problem consideration).course, practical use parameter domains operator excludeconstants occurring problem specification, particularlyintuitively obvious wrong sort fill particular argument slotsoperator. turned case problem domains farexperimented with.preceding sketch method oversimplification since preconditionseffects ucpop operators may particular when-clause. case computeindividual domains intersected domains separately when-clause. example,consider following schematic representation operator:(define (operator op1):parameters (?x ?y):precondition (and P1 P2):effect (and E1 E2(when 0 0)(when " ") )),PEP Econditions starting P E denote atomic formulas may involve ?x ?y.think operator consisting primary when-clause whose preconditionsP1 P2 must always satisfied whose effects E1 E2 always asserted,two secondary when-clauses whose respective preconditions P 0 P " may maysatisfied, are, corresponding effects E 0 E " asserted.algorithm would maintain individual domains ?x ?y preconditionsP1, P2, P 0 , P ", would maintain intersected domains ?x ?yprimary when-clause two secondary clauses. intersected domainssecondary clauses would based individual domains ?x ?yrelative P 0 P ", also relative P1 P2, since (as noted) primarypreconditions must hold operator effects, including conditionaleffects.complications arise ucpop operators contain universally quantified preconditions effects, disjunctive preconditions, facts (mentioned Section 2.2).Rather dealing complications directly, assume operators occur input algorithm. Later describe semi-automated wayhandling operators containing additional constructs.algorithm outlined (a detailed description given Online Appendix 1). W list (names of) when-clauses whose effects propagated.Individual parameter domains initially nil, intersected parameter domains initially either nil (where universal domain). intersected domainparameter, relative given when-clause, case parameter occurs neitherpreconditions when-clause primary preconditions. (In casesuccessful instantiation when-clause clearly independent choice valueparameter question.) Unification step 2(a) usual, excepteffect variable v unified constant c precondition, unification succeeds,116fiAccelerating Partial-Order Plannersunifier v = c, case c element intersected domain v (for relevant when-clause). given inits (initial conditions) goals (which may omitted,i.e., nil) treated operator *start* preconditions operator *end*effects. Variables goals treated like operator parameters. use terms\parameters" \variables" interchangeably here.Algorithm: find-parameter-domains(operators,inits,goals)1. Initialize W initial conditions, contains (primary) when-clause*start*.2. Repeat steps (a{c) W = nil:(a) Unify positive effects when-clauses W possible operatorpreconditions, mark preconditions successfully matched way\matched". (This marking permanent.) Augment individual domainmatched precondition variable certain set C constants, definedfollows. precondition variable unified constant c, C = fcg;unified effect variable, C intersected domaineffect variable (relative when-clause effect belongs).(b) Mark when-clauses \propagation candidates" preconditions (including corresponding primary preconditions) marked \matched"involve least one variable relevant individual domainaugmented step (a).(c) Reset W nil. when-clauses propagation candidates, computenew intersected domains variables. intersected domain whenclause thereby enlarged, intersected domains when-clausenonempty, add when-clause W.3. restrict intersected domains using equative preconditions form (EQ u v),i.e., form common intersected domain u v variables. uconstant v variable, reduce intersected domain v intersectingfug; similarly u variable v constant. equation belongsprimary when-clause, use reduce intersected domains u v (whichevervariables) secondary clauses well.4. Return intersected domains parameter domains, producing sequencelists list form(op (x1 a1 b1 c1 :::) (x2 a2 b2 c2 :::) :::),operator op appears least once. op k conditional effects,k + 1 successive lists headed op, first provides parameterdomains primary effects op rest provide parameter domainsconditional effects (in order appearance ucpop definition op).Note match propagate negative conditions. problem negativeconditions large number may implicit initial conditions, given117fiGerevini & Schubertuse Closed World Assumption ucpop. instance, world n blocks,O(n) on-relations (assuming block one block),necessarily O(n2 ) implicit (not (on ...)) relations. fact, individual variabledomains negative preconditions goals really infinitely large. instance, givenempty initial state (paint-red ?x) operation precondition (not (red ?x))effect (red ?x), achieve (red c) infinitely many constants c. Perhapsnegative conditions could effectively dealt maintaining anti-domains them,explored since practice ignoring negative conditions seems causeminimal \domain bloating". (We proved actual domain elementslost neglect preconditions.)use EQ-conditions could refined making use propagationprocess, NEQ-conditions could also used. However, would probablymarginal impact.final comment, note output format specified step 4 algorithmactually generalized implementation report inaccessible preconditionsgoals. inaccessible conditions simply appended list parameterdomains appropriate when-clause appropriate operator. instance,preconditions (oj ?oj) (at ?oj ?city) ld-oj (\load orange juice") operatortrains world (see Online Appendix 2) unreachable (say, orangesproducing orange juice provided), parameter domain list (unique)when-clause ld-oj appearance(ld-oj (?oj ...) (?car ...) (?city ...) (oj ?oj) (at ?oj ?city)).feature turns useful debugging operator specifications detectingunreachable goals.4.3 Correctness Tractabilitykeeping remarks previous section, call algorithm computingparameter domains correct domains computes subsume possible parameter valuesactually occur (in given primary secondary when-clause) considerpossible sequences operator applications starting given initial state.point property maintain soundness planning algorithmuses precomputed parameter domains prune impossible actions (as well spuriousthreats) partially constructed plan. assert following:Theorem 1 find-parameter-domains algorithm correct computing parameterdomains ucpop-style sets operators (without quantification, disjunction, facts),initial conditions, (possibly) goal conditions.proof given Appendix A. preliminary step establish termination, usingmonotonic growth domains finiteness set constants involved. Correctnessestablished showing exists valid sequence A0 A1 :::A actions(operator instances) starting A0 = *start*, instance operatorOp, bindings parameters Op received instance eventually addedrelevant intersected domains Op (where \relevant" refers when-clauses Opwhose preconditions satisfied beginning ). proved induction n.nnnn118fiAccelerating Partial-Order Plannersindicate deal universally quantified preconditions effects,disjunctive preconditions, facts. make simple changes operator definitionshand preparation parameter domain precomputation, use domainscomputed find-parameter-domains, together original operators, runningplanner. steps preparing operator parameter domain precomputationfollows:Delete disjunctive preconditions, fact-preconditions,13 universally quantified preconditions (this includes universally quantified goals; would also include universallyquantified sentences embedded within antecedents when-clauses, e.g.,manner (:when (:forall (?x) ) ), though occur problemdomains seen).Drop universal quantifiers occurring positively operator effects, i.e., occurringtop level embedded one :and's. example, effect(:and (at robot ?to)(:not (at robot ?from))(:forall (?x)(:when (:and (grasping ?x) (object ?x))(:and (at ?x ?to) (:not (at ?x ?from))) )))would become(:and (at robot ?to)(:not (at robot ?from))(:when (:and (grasping ?x) (object ?x))(:and (at ?x ?to) (:not (at ?x ?from))) )))Note universally quantified variable renamed, necessary,distinct variables operator parameters.example universally quantified variable unrestricted.quantified variable includes type restriction, (:forall (object ?x) ),type restriction needs become antecedent matrix sentence .example hand, rewritten equivalent (:when (object ?x)). Since often when-clause, done adding (object ?x)conjunct antecedent when-clause. cases conjunctionwhen-clauses, case quantifier restriction addedwhen-clause antecedent.Drop existential quantifiers preconditions goals, adding restrictionsquantified variables conjuncts matrix sentence. example, goal(:exists (bacterium ?y)(:exists (molecule ?x)(:and (contains IG ?x)(contains ?x ?y)(pure ?y) )))13. E.g., strips-world would drop (factgiven coordinates lie given room.(loc-in-room ?x ?y ?room)),119checks whetherfiGerevini & Schubertbecomes(:and (bacterium ?y) (molecule ?x) (contains IG ?x)(contains ?x ?y) (pure ?y) )(Actually, :and dropped well, supplying goals find-parameterdomains.)reductions, find-parameter-domains compute correct parameterdomains operators goals. see this, note first dropping preconditions (in initial step above) forfeit correctness, sinceweaken constraints admissible parameter values, thus add constantsdomains. effect dropping universal quantifier, perspectivefind-parameter-domains, introduce new parameter place universal variable. (The operator normalization subroutine detects variables operator preconditionseffects listed parameters, treats additional parameters.)course drastic change meaning operator, preserves correctness parameter domain calculation. domain new parametercertainly contain constants (and hence, Closed World Assumption, objects) quantified variable ranges. example, ?x treated parameterrather universally quantified variable conditional effect(:forall (?x) (:when (object ?x) (in ?x box))),domain ?x when-clause consist everything object,state operator applied. Thus effect (in ?x box) also propagated objects, required. Finally, elimination existential quantifierspreconditions goals seen preserve meaning preconditionsgoals, hence preserves correctness parameter domain calculation.Next formally state tractability claim algorithm, follows (withtacit assumptions, mentioned proof).Theorem 2 Algorithm find-parameter-domains implemented run O(mn n (n +n )) time O(mn ) space worst case, number constantsproblem specification, n combined number preconditions operators (andgoals, included), n combined number operator effects (including*start*).proof Appendix A. time complexity find-parameter-domainsdetermined sum (1) cost unifications performed, (2) costsindividual domain updates attempted, (3) cost intersected domainupdates attempted. space complexity bound easily derived assumingfixed upper bound number arguments predicate (in preconditioneffect) have, fact when-clause O(m) constantsstored.adding additional data structures find-parameter-domains obtainversion algorithm whose worst-case time complexity slightly improved. fact,step 2.(c) instead propagating effects when-clause enlargedpeppe120epfiAccelerating Partial-Order Plannersintersected domain (i.e., adding when-clause list W), sucient propagateeffects when-clause involve enlarged intersected-domain. coulddone setting when-clause table maps parameter listeffects (of when-clause) involving parameter.improved algorithm use W store list effects (instead list whenclauses) propagated next cycle algorithm, steps 1, 2find-parameter-domains modified following way:10. Initialize W list effects *start*.20. Repeat steps (a{c) W = nil:(a0) Unify positive effects W possible operator preconditions, markpreconditions successfully matched way \matched" ...0(b ) 2.(b).(c0) Reset W nil. when-clauses propagation candidates, compute new intersected domains variables. intersected domainwhen-clause thereby enlarged, intersected domains when-clausenonempty, add W subset effects when-clauseinvolving least one parameter whose intersected domain enlarged.Note worst-case time complexity revised algorithm improved,effect when-clause propagated O(m) times. decreases upperbound number unifications performed, reducing complexity estimated step(1) proof Theorem 2 O(mn n ). Hence proved following corollary.epCorollary 1 exists improved version find-parameter-domainsimplemented run O(mn2 n ) time worst case.pe5. Using Parameter Domains Accelerating Planneralready used example Molgen motivate use precomputed parameterdomains planning, showing domains may allow us prune non-viable actionspartial plan.fundamentally, used time planner needs unify two predications involving parameter, either goal regression threat detection. (Ineither case, one predication (sub)goal effect actioninitial condition.) unifier inconsistent parameter domain, countfailure even consistent binding constraints current (partial)plan. inconsistency, use unifier intersect thus refinedomains parameters equated unifier.example, suppose G = (at ?x ?y) precondition step currentplan, E = (at ?w ?z) effect another (possibly new) step, ?x, ?y,?w ?z parameters (or, case ?w ?z, existentially quantified variables)binding constraints associated current plan. Assume alsodomains parameters are:121fiGerevini & Schubert?x : {Agent1, Agent2, Agent3}?w : {Agent1, Agent2}?y : {City1, City2}?z : {City3, City4}unification G E gives binding constraints f?x = ?w, ?y = ?zg,viable parameter domains ?y ?z empty intersection.hand, domain ?z fCity2, City3, City4g, unification G E would judged viable, domains parameters wouldrefined to:?x : {Agent1, Agent2}?w : {Agent1, Agent2}?y : {City2}?z : {City2}Thus parameter domains incrementally refined planning search progresses;narrower become, often lead pruning.5.1 Incorporating Parameter Domains UCPOPpreceding consistency checks domain refinements used partial-order,causal-link planner like ucpop follows. Given goal (open condition) G selecteducpop next aw repaired,(1) restrict set new operator instances ucpop would use establishing G;instance operator effect E (matching G) disallowed precomputedparameter domains relevant E incompatible current parameter domains binding constraints relevant G; (note current parameter domainsassociated G may refinements initial domains);(2) restrict set existing steps ucpop would reuse establishing G; reusingstep effect E (matching G) disallowed current parameter domains relevantE incompatible current parameter domains binding constraintsrelevant G.Moreover, given potential threat effect Q protected condition P, inspectionrelevant parameter domains may reveal threat actually spurious.happens unifier P Q violates (possibly refined) domain constraintsparameter P Q. Thus often(3) reduce number threats generated planner new causallink introduced plan (this happens open condition establishedeither reusing step introducing new one);(4) recognize threat list aws processed redundant, allowingelimination. (Note since parameter domains incrementally refinedplanning, even use (3) generation threats, still possiblethreat becomes spurious added aw list).four uses parameter domains cut search space without loss viablesolutions, since options eliminated cannot lead correct, complete plan.122fiAccelerating Partial-Order PlannersNote (3) (4) useful even planner deals definitethreats (i.e., *d-sep* switch turned on) least three reasons. First, determiningthreat definite threat *d-sep* incurs overhead cost. So,earlier elimination spurious threat could lead considerable savings threatdelayed many times search. second reason relates plan-selectionstrategies adopted. one uses function includes (attenuated) term correspondingnumber threats currently aw list, eliminating spurious threatsadvance give accurate measure \badness" plan. Finally, parameterdomains could used threat processing prune search even *dsep*on. particular, suppose modify notion definite threat,parameter domains, e.g., (P ?x) (not (P ?y)) comprise definite threatparameter domains associated ?x ?y c. case, evend-sep* on, may discover early threat become definite { case mightalso forced threat, i.e., choice promotion demotion may dictatedordering constraints; prune search space. However, currentimplementation exploit third point.incorporated techniques ucpop (version 2.0), along earlierimprovements plan goal selection strategies. Parameter domains handledextension \varset" data structure (Weld, 1994) include domainsvariables (parameters), extending unification process implementfiltering discussed above.14 describe experiments enhanced system.5.2 Experimental Results Using Parameter Domainsmain goal show overhead determined computing parameter domains significant (both preprocessing time planning time), exploitation parameter domains planning significantly prune search.experiments used version find-parameter-domains described Section4.2 Online Appendix 1. Note domains complex onesconsidered might worthwhile use improved version algorithm discussedSection 4.3. (However, remains seen whether problems significantly complexconsider solved ucpop-style planner.)CPU times needed implementation find-parameter-domains negligible problems looked at. 10 msec less many problemsucpop test suite (when running compiled Allegro CL 4.2 sun 20), 20 msectwo problems (Fixa fridge repair domain Fixit tire domain),30msec trains world problems described below.first set tests, relied search strategy used default ucpop.function used A* plan selection thus S+OC+UC+F (allowing problemsinvolve \facts"), goals selected agenda according pure LIFOdiscipline.1514. current implementation new threats filtered protected condition establishedstep already plan.15. experiments *d-sep* switch on. default delay-separation strategy selecting unsafeconditions slightly modified version ucpop using parameter domains. particular,123fiGerevini & Schubertbegan experimenting variety problems ucpop's test suite, comparing performance without use parameter domains. relatively easyproblems Sussman-anomaly, Fixa, Test-ferry, Tower-invert4 showed improvement use parameter domains, problems { particularly harderones { solved easily parameter domains. example, Rat-insulinproblem Molgen domain solved nearly twice fast, strips-worldproblems (Move-boxes variants)16 Towers Hanoi (T-of-H1) solved10 times fast. Note strips-world problems involve facts universallyquantified conditional effects. Two problems oce world, Oce5 Oce6,knew readily solvable improved search strategy, remained dicult (in case Oce6, unsolvable) default ucpop strategy, despite useparameter domains.17 experiments revealed source ineciencydefault plan-selection strategy ucpop. fact, using S+OC+F strategyinstead S+OC+UC+F, without parameter domains Oce5 Oce6 solved generating/exploring 3058/2175 8770/6940 plans respectively; using parameterdomains plans numbered 1531/1055 2954/2204 respectively.initial experiments suggested us promising application computed parameter domains would nontrivial problems involved variety typesentities relationships, significant amounts goal chaining (i.e., successiveaction establishing preconditions next). perspective, trains worldstruck us natural choice experimentation, additional advantagedesign independently motivated research Rochester mixed-initiativeproblem solving natural-language interaction. (Refer formalizationOnline Appendix 2.) Recall Table X Trains1 problem extremely hardunmodified ucpop, requiring 50 minutes generating million plans.Running problem parameter domains produced solution 3.3 seconds(with 1207 plans generated), i.e., 927 times faster.Intuitively, use parameter domains constrain planning analogous usingtype constraints parameters (although parameter domains also take account initialconditions). interest see whether adding type constraints provide similareciency gains use parameter domains. first set experiments thereforeincluded T-Trains1, \typed" version Trains1; operators slightly changedadding new preconditions stating types parameters involved. example,operator uncouple augmented preconditions (engine ?eng)(car ?car). problem also extremely hard unmodified ucpop, exceedingsearch limit 1,000,000 plans generated requiring 2600 seconds.parameter domains, solution obtained one second.threats resolved separation recognized redundant useparameter domains selected eliminated.16. Move-boxes-2 differs slightly Move-boxes problem ucpop suite, goal (in-roombox2 rclk); Move-boxes-a differs slightly Move-boxes-2, initial state contains twoboxes.17. Oce5 directly ucpop's test suite Oce6 minor variant Oce5. Oce5, personsfurnished checks made them, using check printer oce briefcasepicking checks bringing home. \Sam" \Sue" given persons, Oce6added (person Alan) (person Smith) initial conditions.124fiAccelerating Partial-Order PlannersProblemswithout domainsdomainsDomainPlansCPU secPlansCPU sec ratioTrains11,071,479/432,881 3050.151207/8243.290.425T-Trains1> 1,000,000> 2335404/2960.980.425Move-boxes608,231/167,418 1024.045746/325318.80.705Move-boxes-1> 1,000,000> 61651264/6453.590.705Move-boxes-213,816/392745.051175/5872.660.705Move-boxes-a13,805/391846.111175/5872.540.702T-of-H1160,911/107,649 204.51 17,603/12,25037.50.722Rat-insulin364/2620.36196/1290.190.714Monkey-test196/620.1275/460.110.733Monkey-test2415/2620.61247/1490.500.529Fix33395/20705.773103/19836.020.532Oce5809,345/500,578 1927.4 575,224/358,523 1556.80.625Oce6> 1,000,000> 2730> 1,000,000> 2640 0.667Tower-invert4806/5381.55806/5381.590.733Sussman-anomaly44/260.0544/260.060.917Fixa2131/19032.22131/19032.341Test-ferry718/4570.65718/4570.711Table XII: Plans generated/visited CPU time (secs) standard ucpopwithout parameter domains. ( result obtained sun 10Lucid Common Lisp; others sun 20 Allegro Common Lisp.)results indicate adding type constraints operator specificationsnearly effective use parameter domains boosting planning eciency.discuss point context second set tests (below).Table XII summarizes experimental results experiments useddefault ucpop search strategy. table gives number plans generated/visitedplanner CPU time (seconds) required solve problems.18 Noteuse parameter domains gave dramatic improvements trains domain, also strips-world domain. rightmost column supplies \domain ratio"data, metric hoped would predict likely effectiveness using parameterdomains. idea parameter domains effective extentfilter many parameter bindings reached chaining back individualpreconditions operator initial state. bindings found usingvariant algorithm propagating intersected domains instead propagates unionsindividual domains, comparing union domains intersected domains.1918. systems compiled Allegro CL 4.2, settings (space 0) (speed 3) (safety 1) (debug0), run sun 20. CPU time includes Lisp garbage collection (it time givenoutput ucpop).19. Actually, need explicitly propagate union domains, propagate (partial) bindingsone predication time, starting initial conditions. match predication possiblepreconditions, adding constant arguments contains union domains matched operator125fiGerevini & Schuberttrainswithout domainsdomainsDomainproblemsPlansCPU secPlansCPU sec ratioTrains14097/201913.7297/2381.40.425Trains2 17,482/10,907 80.6 1312/1065 7.160.425Trains3 31,957/19,282 189.8 3885/3175 25.10.411Table XIII: Plans generated/visited CPU time (secs) ucpop withoutparameter domains trains domain using ZLIFO strategy.trains without domainsdomainsDomainproblems Plans CPU sec Plans CPU sec ratioTrains1 1093/5978.1265/1942.30.425Trains2 >50,000 >607 >50,000 >5340.425Trains3 >50,000 >655 >50,000 >5640.411Table XIV: Plans generated/visited CPU time (secs) ucpop withoutparameter domains trains domain using LCFR strategy.\domain ratio" provides comparison, dividing average union domain sizeaverage intersected domain size, averages taken parameters when-clausesoperators.largest speedups (e.g., trains problems) tend correlatesmallest domain ratios, smallest speedups largest domain ratio (unity {see last rows). However, seen table problem diculty (asmeasured plans CPU time) much useful domain ratio predictorspeedups expected using parameter domains. Problems generateorder million plans standard ucpop tend produce speedups 3 ordersmagnitude, whereas domain ratio problems (e.g., Move-boxes-1)better (or even worse) problems much smaller speedups (e.g., Move-boxesa, Rat-insulin, Monkey-test1, Monkey-test2). much lower diculty problemspredicts reduced speedup. complicate matters, dicult problems givehigh speedups (see T-of-H1 especially Oce5); know subtletiesproblem structure account unusual cases.second round experiments, tested effectiveness parameter domaintechnique combination improved search strategy, i.e., S+OC/ZLIFO. addition, combined S+OC LCFR (least cost aw selection) (Joslin & Pollack, 1994),(or when-clause). find corresponding (partially bound) effects, add new effectslist predications still propagated. partially bound effect (P ?x ?y) newidentical similar predication (P ?u ?v) among previously propagated predicationsamong still propagated.126fiAccelerating Partial-Order Plannerst-trainswithout domainsdomainsDomainproblemsPlansCPU secPlansCPU sec ratioT-Trains1 3134/218317.2505/4163.40.425T-Trains2 5739/432537.33482/274927.30.425T-Trains3 17,931/13,134 130.4 11,962/9401 105.10.425Table XV: Plans generated/visited CPU time (secs) ucpop without parameter domains \typed" trains domain using ZLIFO strategy.t-trainswithout domainsdomainsDomainproblemsPlansCPU secPlansCPU sec ratioT-Trains1 3138/2412 31.5 1429/1157 14.50.425T-Trains2 >50,000 >1035 >50,000 >11360.425T-Trains3 >50,000>976>50,000>9620.425Table XVI: Plans generated/visited CPU time (secs) ucpop withoutparameter domains \typed" trains domain using LCFR strategy.test possible sensitivity parameter-domains technique precise strategyused. present set tests used search limit 50,000 plans generated.began sampling problems ucpop test suite,initial trials yielded results quite analogous default ucpop strategy.obtained improvements several easier problems significant improvementsharder ones (e.g., close factor 2 Rat-insulin). Noteworthy memberslatter category Oce5 Oce6 { recall Oce5 shown little speedupstandard ucpop Oce6 unsolvable. However, view computationalexpense testing ZLIFO LCFR, decided narrow focustrains world. mentioned, advantages world inherent interestrelative complexity.Tables XIII-XVI provide experimental results trains domain S+OC/ZLIFO strategy S+OC/LCFR strategy, case without parameterdomains.results Tables XIII XIV show using parameter domains still givesignificant improvements performance, obtained usebetter search strategies. example, use parameter domains provided 11-foldspeedup Trains2, S+OC/ZLIFO strategy. particular problem speedup(on metrics) result pruning 1482 plans (more half generated)search., recognizing 305 unsafe conditions redundant. Evidently,effect pruning amplified order magnitude overall performance,futile searches cut short. Note speedups Trains1-3127fiGerevini & Schubertroughly comparable (within factor 2) obtained problems previous setcomparable initial diculty (e.g., see Move-boxes-2 Move-boxes-a Table XII).points rather consistent correlation problem diculty speedupsobtainable using parameter domains. constant domain ratios also compatibleless invariant speedups here, though little import, given earlierresults. S+OC/LCFR gains appear less, though single result showing3.5-fold speedup provides anecdotal evidence conclusion. Trains2Trains3 remained dicult solution LCFR. Similar gains observedS+OC/LC strategies best observed gain Trains domain 1.7-foldspeedup Trains2. case, results confirm effectiveness parameterdomains technique.Tables XV XVI \typed" version trains. case parametertyping gave modest improvements absence parameter-domains, (in contrastresults Trains1 default search strategy) significant deteriorationpresence. know account results detail, seemsclear contrary effects involved. one hand, typing tend helptends limit choices parameter values \sensible" ones. example, precondition(engine ?eng) satisfiable use *start*, initial state thusconstrain ?eng assume sensible values. hand, adding type-preconditionstend broaden search space, adding open conditions aw list.lesson \typed" experiments appears best supplyexplicit type constraints operator parameters, instead using automated methodcalculating updating domains constrain parameter bindings.6. Conclusions Workbegan exploring simple, domain-independent improvements search strategiespartial order planning, described method using precomputed parameter domains prune search space. summarize conclusions techniquespoint promising directions work.6.1 Improving Searchproposed improvements search strategies based one hand carefullyconsidered choice terms A* heuristic plan selection,preference choosing open conditions cannot achieved achievedone way (with default LIFO prioritization open conditions). Sinceplan refinements corresponding uniquely achievable goals logically necessary,termed latter strategy zero-commitment strategy. One advantage techniquesimilar strategies incurs lower computational overhead.experiments based modifications ucpop indicate strategies givelarge improvements planning performance, especially problems harducpop (and \relatives") begin with. best performance achievedstrategies plan selection goal selection used combination. practical terms,able solve nearly every problem tried ucpop test suite fractionsecond (except Fixit, required 38.2 seconds), problems128fiAccelerating Partial-Order Plannerspreviously required minutes unsolvable machine. includedsucient variety problems indicate techniques broad potential utility.Further, results suggest zero-commitment best supplemented LIFOstrategy open conditions achievable multiple ways, rather generalizationzero-commitment favoring goals fewest children. somewhat surprising resultmight thought due way designer domain orderspreconditions operators; i.e., \natural" ordering preconditions may correlatebest planning order, giving fortuitous advantage LIFO strategy relativestrategy like LC.20However, preliminary experiments performed randomized preconditionsT-of-H1 Trains1 indicate otherwise. 5 randomizations preconditionsT-of-H1, LC ZLIFO slowed somewhat, average factors 2.2 (2)3.3 (4.2) terms plans expanded (CPU time used) respectively. (In cases,S+OC used plan search.) still left ZLIFO performance advantagefactor 22 terms plans created 39 terms CPU time. Trains1performance LC greatly deteriorated 2 5 cases (by factor close 70 termsplans time), ZLIFO actually improved marginally. leftZLIFO average performance advantage LC (whereas slightly slowerunrandomized case) { factor 3.3 terms plans 6.7 terms CPU time(though values unreliable, view fact standard deviationsorder means).Despite results believe satisfactory understanding dependenceaw-selection strategies order operator preconditions require extensiveexperimental investigation. currently undertaking work.6.2 Using Parameter Domainsdescribed implemented, tractable algorithm precomputing parameter domainsplanning operators, relative given initial conditions. showed use precomputed domains planning process prune non-viable actions bogus threats,update dynamically maximum effect.idea using precomputed parameter domains constrain planning apparentlyfirst proposed technical report Goldszmidt et al. (1994). contains essentialidea accumulating domains forward propagation initial conditions. Thoughreport sketches single-sweep propagation process initial conditionsgoals, implemented Rockwell Planner (RNLP) handles cyclic operator graphs,repeatedly propagating bindings quiescence, much algorithm. algorithmdeals additional complexities conditional effects equalities (and semiautomated fashion quantification) appears ecient (Smith, 1996).distinctive features work method incrementally refining domains20. suggested us David Smith well Mike Williamson. Williamson tried ZLIFO 5randomized versions T-of-H1, reported large performance degradation (Williamson & Hanks,1996). recently ran versions using implementation, obtaining far favorable results(three five versions easier solve original version T-of-H1, twoversions slowed ZLIFO factor 1.84 4.86 terms plans explored.)129fiGerevini & Schubertplanning, theoretical analysis algorithm, systematic experimentaltests.Another closely related study Yang Chan (1994), used hand-suppliedparameter domains planning much use precomputed domains. interestingaspect work direct use sets constants variable bindings. instance,establishing precondition (P ?x) using initial state containing (P a), (P b)(P c), would bind ?x fa, b, cg rather specific constant. refine\noncommittal" bindings planning much refine variable domains,periodically use constraint satisfaction methods check consistency currentEQ/NEQ constraints. conclude delaying variable bindings works best problemslow solution densities (while degrading performance problems highsolution densities), optimal frequency making consistency checks dependswhether dead ends tend occur high low search tree. work distinguishedmethod precomputing parameter domains, use specific bindingsmatching initial conditions OCs, use parameter domains threat detectionresolution, handling enriched syntax ucpop operators comparedsnlp operators.Judging examples experimented with, techniques well-suitednontrivial problems involve diverse types objects, relations actions, significant logical interdependencies among steps needed solve problem. usedconjunction default search strategy ucpop, method gave significant speedupsnontrivial problems, reaching speedup factor 927 trains transportation planning domain, 1717 hardest strips-world problem tried .combined S+OC ZLIFO search strategies, parameter domain techniquestill gave speedups factor around 10 trains problems. Though implementation aimed ucpop-style planner, essentially techniques wouldapplicable many planners.also found parameter domain precomputations useful debuggingaid. fact, domain precomputation initial formulation trains worldimmediately revealed several errors. instance, domain ?eng parametermv-engine turned contain oranges, bananas, OJ factory, indicating needtype constraint ?eng. (Without this, transportation problems wouldsolvable without benefit engines trains!) Another immediately apparent problemrevealed parameter domains ?city1 ?city2 mv-engine: domain?city1 excluded Elmira, ?city2 excluded Avon. obvious diagnosisneglected assert (connected c1 c2) (connected c2 c1)track connecting two cities. Furthermore, parameter domains quickly identifyunreachable operators goals cases. instance, without make-oj operator,computed domains show ld-oj operator unreachable, goal like(and (oj ?oj) (at ?oj Bath)) (getting orange juice Bath) unattainable (theparameter domain ?oj empty).course, running planner also used debugging formalization,planning general far time-consuming form preprocessing (especiallygoal pose happens unachievable formalization!), trace130fiAccelerating Partial-Order Plannersanomalous planning attempt quite hard interpret, compared listingparameter domains, obtained fraction second.6.3 workFirst all, additional experimentation would interest, assessperhaps refine search strategies. experimentation might focus threathandling strategies, including best general form attenuated UC-term planselection, best way combine threat selection open condition selection.preference definite threats open conditions used ZLIFO appeargood default according experience, TileWorld experiments indicatedre-ordering priorities threats open conditions sometimes desirable. Concerning choice UC-related term inclusion heuristic plan selection,mention brie tried using S+OC+UC , UC numberdefinite threats, obtain significant uniform improvements.One promising direction development search strategy makezero-commitment strategy apply often finding ways identifying false optionsearly possible. is, possible action instance (obtained matching opencondition available operators well existing actions) easily recognizable inconsistent current plan, elimination may leave us singleremaining match hence opportunity apply zero-commitment strategy.One way implementing strategy would check once, acceptingmatched action possible way attain open condition, whether temporalconstraints action force violate causal link, alternatively, force causallink violated. case action could immediately eliminated, perhapsleaving one (or even no) alternative. could perhaps made even effectivebroadening definition threats preconditions well effects actionsthreaten causal links, hence bring light inconsistencies sooner. Noteprecondition action inconsistent causal link, establishedanother action whose effects violate causal link; precondition really posesthreat outset.Two possible extensions parameter domain techniques (i) fully automatedhandling universally quantified preconditions effects, disjunctions factspreprocessing algorithm; (ii) \intelligent" calculation domains, applyingconstraint propagation process sets ground predications matchedpreconditions operator; shown yield tighter domains, thoughcomputational expense. Blum Furst (1995) recently explored similar idea, rathercomputing parameter domains, directly stored sets ground atoms couldgenerated one operator application (starting initial state), two successive operatorapplications, on, used sets atoms (and exclusivity relations amongatoms actions connecting them) guide regressive search plan.algorithm describe allow conditional effects, though generalizationappears entirely possible. examples used tests, obtained dramaticspeedups.131fiGerevini & SchubertFinally, also working another preprocessing technique, namely inferencestate constraints operator specifications. One useful form constraint implicational (e.g., (implies (on ?x ?y) (not (clear ?y)))), another single-valuednessconditions (e.g., (on ?x ?y) may single-valued ?x ?y). conjectureconstraints tractably inferred used large speedups domainindependent, well-founded planning.view results presented possibilities speedupsmentioned, think plausible well-founded, domain-independent planners mayyet become competitive pragmatically designed planners.Acknowledgementswork amalgamates extends two conference papers improving search (Schubert& Gerevini, 1995) using computed parameter domains (Gerevini & Schubert, 1996)accelerate partial-order planners. research supported part Rome Lab contract F30602-91-C-0010 NATO Collaborative Research Grant CRG951285.work AG carried IRST, 38050 Povo (TN), Italy, CS DepartmentUniversity Rochester, Rochester NY USA. helpful comments perceptivequestions Marc Friedman, David Joslin, Rao Kambhampati, Colm O'Riain, Martha Pollack, David Smith, Dan Weld, Mike Williamson, Associate Editor Michael Wellmananonymous reviewers gratefully acknowledged.Appendix (Proofs Theorems)Theorem 1 find-parameter-domains algorithm correct computing parameterdomains ucpop-style sets operators (without quantification, disjunction, facts),initial conditions, (possibly) goal conditions.Proof. preliminary observation, intersected parameter domains computed iteratively algorithm eventually stabilize, since grow monotonicallyfinitely many constants occur initial conditions operator effects.Thus algorithm terminates.order prove correctness need show exists valid sequenceA0 A1 :::A actions (operator instances) starting A0 = *start*,instance operator Op, bindings parameters Op received instanceeventually added relevant intersected domains Op (where \relevant" referswhen-clauses Op whose preconditions satisfied beginning ).prove induction n.n = 0, = A0 = *start*, parameters claim triviallytrue.assume claim holds n = 1; 2; :::; k. consider operator instance+1 validly follow A0 A1 :::A , i.e., +1 instance operatorOp whose primary preconditions, possibly along secondary ones, satisfiedend A0 A1 :::A . Let p precondition, write instance +1(P c1 c2 ..). (P c1 c2 ..) must effect , 0 k. = 0nnnnnkkkkk132fiAccelerating Partial-Order Planners(P c1 c2 ..) holds initial state, hence predication propagatedsuccessfully matched p initial propagation phase find-parameter-domains.> 0, instance operator Op' (P c1 c2 ..) correspondinginstance effect (P t1 t2 ..) Op', either parameter Op'equal cj. Diagrammatically,jA0 . . .j. . .+1jkkOp'Opeffect (P t1 t2 ..) ,,,,! precond p(P c1 c2 .. )(P c1 c2 .. )induction assumption, bindings parameters eventually addedrelevant intersected domains Op'. also implies intersected domainsOp' become nonempty, effect (P t1 t2 ..) eventually propagated,variables among corresponding constant cj relevant intersecteddomain. Consequently, much case = 0, effect (P t1 t2 ..) successfully matchedprecondition p Op stage propagation. Given observations,clear = 0 > 0, p marked \matched" Op eventually,furthermore parameters Op occur p bindings resultingunification (P c1 c2 ..) added appropriate individual domains associatedp.argument applies preconditions Op satisfied instance +1 , particular primary preconditions. Since marked \matched", algorithmcompute intersected domains Op-parameters occur them. viewindividual domain updates confirmed, since individual domains grow monotonically, intersected domains eventually contain parameter bindings +1 .instance, parameter ?x Op occurs primary precondition boundc +1 , shown c eventually added intersected domain?x associated primary when-clause Op. parameter occurprimary preconditions Op, intersected domain set outset,implicitly contains whatever binding parameter +1 .similar argument made secondary when-clause Op whose preconditions also satisfied +1 . Again, preconditions secondary clause,well primary preconditions, marked \matched", parameteroccurring combined preconditions, intersected domain (relative secondaryclause) updated include binding +1 . parameters Op occurringpreconditions, intersected domains set initially,implicitly contains possible binding. Finally, note since intersecteddomains relative primary secondary when-clauses grow monotonically, augmentations intersected domains confirmed permanent. (In caseT-domains, remain T.)leave additional details concerned ultimate use EQ-preconditionsfind-parameter-domains reader. 2jkkkkkk133fiGerevini & SchubertTheorem 2 Algorithm find-parameter-domains implemented run O(mn n (n +n )) time O(mn ) space worst case, number constantsproblem specification, n combined number preconditions operators (andgoals, included), n combined number operator effects (includingpeepppe*start*).Proof. time complexity find-parameter-domains determined sum(1) cost unifications performed, (2) costs individual domainupdates attempted, (3) cost intersected domain updates attempted.estimate upper bound terms following assumptions:(a) unification operator effect operator precondition requires constanttime;(b) fixed upper bound number arguments predicate (inprecondition effect) have. follows O(n ) upper bound totalnumber intersected domains;21(c) individual domains intersected domains stored hash tables (indexedconstants domain). So, check whether element belongs particular(individual intersected) domain, possibly add domain essentiallyconstant time. Furthermore individual intersected domain, appropriatedata structures used keep track (possibly empty) set new elementsadded domain last update attempt.(1) particular intersected domain particular operator,updates domain. update causes effects whenclause intersected domain belongs propagated. upper boundnumber n . propagated effect may unified O(n ) preconditions. ThusO(m) updates intersected domain may cause O(mn n ) unifications. Hence(b), overall number unifications caused propagation intersected domainsindividual domains O(mn2 n ). unifications addinitially performed effects *start* preconditions operators.O(mn ) unifications, increase previous upper boundnumber unifications. Thus, (a), cost unifications performedalgorithm O(mn2 n ).(2) unification potentially followed attempt update individualdomain(s) relevant parameter(s). However, assumption (c) numberattempts limited set new elements intersected domain(s)unifying effect (are) empty. Furthermore, attempt updateindividual domain performing union relevant intersected domain ,subset new elements need added (if alreadythere). Thus, since intersected domain grows monotonically, (b) (c)overall cost update attempts one particular individual domain causedeepeepppep21. Note parameter appears precondition when-clause, none effects,intersected domain parameter propagated algorithm. Hence implementingalgorithm ignore parameters.134fiAccelerating Partial-Order Plannersone particular effect O(m). worst case one effect unifyO(n ) preconditions operators, yielding overall bound attemptsupdate individual domains O(mn n ).(3) attempt update particular intersected domain relevantindividual domain update, relevant individual domain updated O(m) times(because domains grow monotonically). Therefore (b) O(mn )attempts update one intersected domain. (c) total cost attemptsO(mn2 ), checking whether new element individual domain belongsO(n ) relevant individual domains takes O(n ) time. So, since (b)O(n ) intersected domains, total cost incurred algorithmupdating intersected domains O(mn n2 ).follows time complexity find-parameter-domains is:O(mn2n ) + O(mn n ) + O(mn n2) = O(mn n (n + n )).space complexity bound easily derived (b), factwhen-clause O(m) constants stored. 2pepppppeepepReferencesepeppepeAllen, J., & Schubert, L. (1991). TRAINS project. Tech. rep. 382, Dept. ComputerScience, Univ. Rochester, Rochester, NY. Also slightly revised Languagediscourse TRAINS project, A. Ortony, J. Slack, O. Stock (eds.), Communication Artificial Intelligence Perspective: Theoretical Springer-Verlag,Heidelberg, pp. 91-120.Allen, J., Schubert, L., Ferguson, G., Heeman, P., Hwang, C., Kato, T., Light, M., Martin,N., Miller, B., Poesio, M., & Traum, B. (1995). TRAINS project: case studybuilding conversational planning agent. Experimental Theoretical ArtificialIntelligence, 7, 7{48.Barrett, A., Golden, K., Penberthy, S., & Weld, D. (1994). UCPOP user's manual. Tech.rep. 93-09-06, Dept. Computer Science Engineering, University Washington,Seattle, WA 98105.Blum, A., & Furst, M. (1995). Fast planning planning graph analysis. ProceedingsFourteenth International Joint Conference Artificial Intelligence (IJCAI-95),pp. 1636{1642 Montreal, CA. Morgan Kaufmann.Chapman, D. (1987). Planning conjunctive goals. Artificial Intelligence, 32 (3), 333{377.Currie, K., & Tate, A. (1991). O-Plan: open planning architecture. Artificial Intelligence, 51 (1).Fikes, R., & Nilsson, N. (1971). STRIPS: new approach application theoremproving problem solving. Artificial Intelligence, 2, 189{208.Georgeff, M., & Lansky, A. (1987). Reactive reasoning planning. ProceedingsSixth National Conference American Association Artificial Intelligence, pp.677{682 Seattle, WA. Morgan Kaufmann.135fiGerevini & SchubertGerevini, A., & Schubert, L.K. (1995). Computing parameter domains aid planning.Proc. 3rd Int. Conf. Artificial Intelligence Planning Systems (AIPS-96),pp. 94{101 Menlo Park, CA. AAAI Press.Goldszmidt, M., Darwiche, A., Chavez, T., Smith, D., & White, J. (1994). Decision-theorycrisis management. Tech. rep. RL-TR-94-235, Rome Laboratory.Green, C. (1969). Application theorem proving problem solving. ProceedingsFirst International Joint Conference Artificial Intelligence (IJCAI-69), pp.219{239.Joslin, D. (1995). Personal communication.Joslin, D., & Pollack, M. (1994). Least-cost aw repair: plan refinement strategypartial-order planning. Proceedings Twelfth National ConferenceAmerican Association Artificial Intelligence (AAAI-94), pp. 1004{1009 Seattle,WA. Morgan Kaufmann.Kambhampati, S., Knoblock, C. A., & Yang, Q. (1995). Planning refinement search:unified framework evaluating design tradeoff partial-order planning. ArtificialIntelligence. Special Issue Planning Scheduling, 76 (1-2).Korf, R. (1992). Linear-space best-first search: Summary results. ProceedingsTenth National Conference American Association Artificial Intelligence(AAAI-92), pp. 533{538.McAllester, D., & Rosenblitt, D. (1991). Systematic nonlinear planning. ProceedingsNinth National Conference Artificial Intelligence (AAAI-91), pp. 634{639Anheim, Los Angeles, CA. Morgan Kaufmann.Nilsson, N. (1980). Principles Artificial Intelligence. Tioga Pub. Co., Palo Alto, CA.Penberthy, J., & Weld, D. (1992). UCPOP: sound, complete, partial order plannerADL. Nebel, B., Rich, C., & Swartout, W. (Eds.), Proceedings ThirdInternational Conference Principles Knowledge Representation Reasoning(KR92), pp. 103{114 Boston, MA. Morgan Kaufmann.Peot, M. A., & Smith, D. E. (1993). Threat-removal strategies partial-order planning.Proceedings Eleventh National Conference American AssociationArtificial Intelligence (AAAI-93), pp. 492{499 Washington, D.C. Morgan Kaufmann.Schubert, L., & Gerevini, A. (1995). Accelerating partial order planners improvingplan goal choices. Proc. 7th IEEE Int. Conf. Tools ArtificialIntelligence, pp. 442{450 Herndon, Virginia. IEEE Computer Society Press.Smith, D. E., & Peot, M. A. (1993). Postponing threats partial-order planning.Proceedings Eleventh National Conference American Association Artificial Intelligence (AAAI-93), pp. 500-506 Washington, D.C. Morgan Kaufmann.Smith, D. E. (1996). Personal communication.136fiAccelerating Partial-Order PlannersSrinivasan, R., & Howe, A. (1995). Comparison methods improving search eciencypartial-order planner. Proceedings Fourteenth International Joint Conference Artificial Intelligence (IJCAI-95), pp. 1620{1626.Weld, D. (1994). introduction least commitment planning. AI Magazine, 15 (4),27{62.Wilkins, D. (1988). Practical Planning: Extending Classical AI Planning Paradigm.Morgan Kaufmann, San Mateo, CA.Williamson, M., & Hanks, S. (1995). Flaw selection strategies value-directed planning.Proceedings Third International Conference Artificial Intelligence PlanningSystems, pp. 237{244.Yang, Q., & Chan, A.Y.M. (1994). Delaying variable binding commitments planning.Proceedings Second International Conference Artificial Intelligence PlanningSystems, pp. 182{187.137fiJournal Artificial Intelligence Research 5 (1996) 27-52Submitted 9/95; published 8/96Hierarchy Tractable SubsetsComputing Stable ModelsRachel Ben-Eliyahurachel@cs.bgu.ac.ilMathematics Computer Science DepartmentBen-Gurion University NegevP.O.B. 653, Beer-Sheva 84105, IsraelAbstractFinding stable models knowledge base significant computational problemartificial intelligence. task computational heart truth maintenancesystems, autoepistemic logic, default logic. Unfortunately, NP-hard.paper present hierarchy classes knowledge bases,12 , followingproperties: first,1 class stratified knowledge bases; second, knowledgebase, stable models, may found time( ), length knowledge base number atoms ; third,arbitrary knowledge base , find minimum belongstime polynomialSin1 size ; and, last, K class knowledge bases,case =1= K, is, every knowledge base belongs classhierarchy.;kklnk; :::lnkk1. Introductiontask computing stable models knowledge base lies heart threefundamental systems Artificial Intelligence (AI): truth maintenance systems (TMSs),default logic, autoepistemic logic. Yet, task intractable (Elkan, 1990; Kautz &Selman, 1991; Marek & Truszczynski, 1991). paper, introduce hierarchyclasses knowledge bases achieves task polynomial time. Membershipcertain class hierarchy testable polynomial time. Hence, given knowledge base,cost computing stable models bounded prior actual computation (ifalgorithms hierarchy based used).First, let us elaborate relevance computing stable models AI tasks. defineknowledge base set rules formC ,A1 ; :::; Am; B1; :::; Bn(1)C , As, B atoms propositional language. Substantial effortsgive meaning, semantics, knowledge base made logic programmingcommunity (Przymusinska & Przymusinski, 1990). One successful semanticsknowledge bases stable model semantics (Bidoit & Froidevaux, 1987; Gelfond & Lifschitz,1988; Fine, 1989), associates knowledge base (possibly empty) setmodels called stable models. Intuitively, stable model represents set coherentc 1996AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiBen-Eliyahuconclusions one might deduce knowledge base. turns stable modelsplay central role major deductive systems AI. 11.1 Stable Models TMSsTMSs (Doyle, 1979) inference systems nonmonotonic reasoning default assumptions. TMS manages set nodes set justifications, noderepresents piece information justifications rules state dependenciesnodes. TMS computes grounded set nodes assigns setinformation believed true given point time. Intuitively, set believednodes grounded satisfies rules, node believed true solely basiscircular chain justifications. Elkan (1990) pointed nodes TMSviewed propositional atoms, set justifications knowledge base.showed task computing grounded interpretations set TMS justifications corresponds exactly task computing stable models knowledge baserepresented set TMS justifications.1.2 Stable Models Autoepistemic LogicAutoepistemic logic invented Moore (1985) order formalize processagent reasoning beliefs. language autoepistemic logic propositionallanguage augmented modal operator L. Given theory (a set formulas)autoepistemic logic, theory E called stable expansion iffE = (T SfLF jF 2 E gSf:LF jF 2= E g)denotes logical closure . restrict subsetautoepistemic logic formula formA1 ^ ::: ^ ^ :LB1 ^ ::: ^ :LBn ,!C(2)C , As, B propositional atoms. call subsetclass autoepistemic programs. Every autoepistemic program translatedknowledge base representing formula (2) knowledge base rule (1). Elkan(1990) shown stable model iff expansion Eset positive atoms E . Thus, algorithms computing stable modelsmay used computing expansions autoepistemic programs. relationshipstable model semantics autoepistemic logic also explored Gelfond (1987)Gelfond Lifschitz (1988, 1991).1.3 Stable Models Default LogicDefault logic formalism developed Reiter (1980) reasoning default assumptions. default theory viewed set defaults, default definedexpression formff : fi1; :::; fin(3)1. logic programming terminology, knowledge bases discussed paper called normal logicprograms.28fiA Hierarchy Tractable Subsetsff; , fi1 ; :::; fin formulas first-order language. According Reiter, Eextension default theory iff E coincides one minimal deductivelyclosed sets sentences E 0 satisfying condition2 grounded instancedefault (3) , ff 2 E 0 :fi1 ; :::; :fin 2= E , 2 E 0.consider subset default theories call default programs. defaultprogram set defaults formA1 ^ ::: ^ : :B1; :::; :Bn(4)CC , As, B atoms propositional language.default program associated knowledge base replacingdefault form (4) rule (1).Gelfond Lifschitz (1991) shown logical closure set atoms Eextension iff E stable model . Algorithms computing stable modelsthus used computing extensions Reiter's default theories.paper organized follows. next section, define terminology.Section 3 presents two algorithms computing stable models knowledge base.complexity first algorithms depends number atoms appearingnegatively knowledge base, complexity algorithm dependsnumber rules negative atoms bodies. Section 4, presentmain algorithm paper, called algorithm AAS. Algorithm AAS worksbottom superstructure dependency graph knowledge base usestwo algorithms presented Section 3 subroutines. Section 5 explains AASalgorithm generalized handle knowledge bases first-order language. Finally,Sections 6 7, discuss related work make concluding remarks.2. Preliminary DefinitionsRecall knowledge base defined set rules formC ,A1 ; :::; Am; B1; :::; Bn(5)C , As, B propositional atoms. expressionleft , called head rule, expression right , calledbody rule. said appear positive rule, and, accordingly,B said appear negative rule. Rule (5) said C . ruleempty body called unit rule. Sometimes treat truth assignment (inwords, interpretation) propositional logic set atoms | set atomsassigned true interpretation. Given interpretation set atoms A, IAdenotes projection A. Given two interpretations, J , sets atoms2. Note appearance E condition.29fiBen-EliyahuB , respectively, interpretation + J defined follows:8>P 2 n B>< IJ((PP))P 2 BTn+ J (P ) = > (P )P 2 B (P ) = J (P )>:undefined otherwise(P ) = J (P ) every P 2 B , say J consistent.partial interpretation truth assignment subset atoms. Hence, partialinterpretation represented consistent set literals: positive literals representatoms true, negative literals atoms false, rest unknown.knowledge base called Horn rules Horn. model theory (setclauses) propositional logic truth assignment satisfies clauses. onelooks knowledge base theory propositional logic, Horn knowledge baseunique minimal model (recall model minimal among set models iffmodel m0 2 m0 m).Given knowledge base set atoms m, Gelfond Lifschitz definedcalled Gelfond-Lifschitz (GL) transform w.r.t. m, knowledge baseobtained deleting rule negative literal P bodyP 2 deleting negative literals bodies remaining rules. NoteHorn knowledge base. model stable model knowledge base iffunique minimal model (Gelfond & Lifschitz, 1988).Example 2.1 Consider following knowledge base 0, used onecanonical examples throughout paper:(6)warm blooded , mammallive land , mammal; ab1(7)female , mammal; male(8)male , mammal; female(9)mammal , dolphin(10)ab1 , dolphin(11)mammal , lion(12)lion ,(13)= flion; mammal; warm blooded; live land; femaleg stable model 0 . Indeed,0m (the GL transform 0 w.r.t. m),,,,,,,warm bloodedlive landfemalemammalab1mammallion30mammalmammalmammaldolphindolphinlionfiA Hierarchy Tractable Subsetsminimal model 0m .set atoms satisfies body rule iff atom appears positivebody atom appears negative body . setatoms satisfies rule iff either satisfy body, satisfies bodyatom appears head belongs .proof atom sequence rules atom derived. Formally,recursively define atom P proof w.r.t. set atomsknowledge base :unit rule P , , P proof w.r.t. .rule P ,A1; :::; Am; B1; :::; Bn , every = 1; :::; n Bi, every = 1; :::; Ai already proof w.r.t. , Pproof w.r.t. .Theorem 2.2 (Elkan, 1990; Ben-Eliyahu & Dechter, 1994) set atoms stablemodel knowledge base iff1. satisfies rule ,2. atom P , proof P w.r.t .simple matter show following lemma true.Lemma 2.3 Let knowledge base, let set atoms. Define:1. S0 = ;,2. Si+1 = Si fP jP ,A1 ; :::; Am; B1 ; :::; Bn ;A's belong Si none B 's belong g.S.stable model iff = 10Observe although every stable model minimal model knowledge baseviewed propositional theory, every minimal model stable model.Example 2.4 Consider knowledge baseb ,fag fbg minimal models knowledge base above, fbg stablemodel knowledge base.Note knowledge base may one stable models, stable model all.knowledge base least one stable model, say consistent.dependency graph knowledge base directed graph atomnode positive edge directed P Q iff rule QP appears positive body. Accordingly, negative edgeP Q iff rule Q P appears negative body. Recallsource directed graph node incoming edges, sink nodeoutgoing edges. Given directed graph G node G, subgraph rootedsubgraph G nodes path directed G.children G nodes arc directed G.31fiBen-EliyahuExample 2.5 dependency graph 0 shown Figure 1. Negative edgesmarked \not." children mammal lion dolphin. subgraph rootedland subgraph include nodes lion, mammal, dolphin, ab1, land.malewarm_bloodfemaleon_landmammallionab1dolphinFigure 1: dependency graph 0knowledge base stratified iff assign atom C positive integer iCevery rule form (5) above, As, iA iC ,B s, iB < iC . readily demonstrated knowledge base stratified iffdependency graph directed cycles going negative edges. wellknown logic programming community stratified knowledge base uniquestable model found linear time (Gelfond & Lifschitz, 1988; Apt, Blair, &Walker, 1988).Example 2.6 0 stratified knowledge base. following knowledge base, 1,stratified (we assign ab2 penguin number 1, atomsnumber 2):live landflybirdab2,,,,32birdbird; ab2penguinpenguinfiA Hierarchy Tractable Subsetsstrongly connected components directed graph G make partitionset nodes that, subset partition x; 2 ,directed paths x x G. strongly connected componentsidentifiable linear time (Tarjan, 1972).malefemalewarm_bloodon_landmammallionab1dolphinFigure 2: super dependency graph 0super dependency graph knowledge base , denoted G , superstructuredependency graph . is, G directed graph built making stronglyconnected component dependency graph node G . arc existsnode node v iff arc one atoms one atoms vdependency graph . Note G acyclic graph.Example 2.7 super dependency graph 0 shown Figure 2. nodessquare grouped single node.3. Two Algorithms Computing Stable Modelsmain contribution paper presentation algorithm whose eciencydepends \distance" knowledge base stratified knowledge base.distance measured precisely Section 4. first describe two algorithmscomputing stable models. two algorithms take account level\stratifiability" knowledge base, is, still work exponential timestratified knowledge bases. main algorithm use two algorithms procedures.33fiBen-EliyahuGiven truth assignment knowledge base, verify polynomial time whetherstable model using Lemma 2.3. Therefore, straightforward algorithm computing stable models simply check possible truth assignments determine whetherstable model. time complexity straightforward procedureexponential number atoms used knowledge base. Below, present twoalgorithms often function eciently straightforward procedure.3.1 Algorithm Depends Number Negative AtomsKnowledge BaseAlgorithm All-Stable1 (Figure 3) enables us find stable models time expo-nential number atoms appear negative knowledge base.algorithm follows work abductive extensions logic programmingstable models characterized terms sets hypotheses drawn additional information (Eshghi & Kowalski, 1989; Dung, 1991; Kakas & Mancarella, 1991).done making negative atoms abductible imposing appropriate denialsdisjunctions integrity constraints. work Eshghi Kowalski (1989), Dung(1991), Kakas Mancarella (1991) implies following.Theorem 3.1 Let knowledge base, let H set atoms appear negated. stable model iff interpretation H1. every atom P 2 H , P 2 , P 2 0 ,2. 0 consistent,3. = +M 0 ,0 unique stable model .Proof: proof follows directly definition stable models. Supposestable model knowledge base , let H set atoms appear negative. Then, definition, stable model . note = MH . Hence,conditions Theorem 3.1 hold , taking 0 = = MH . Now, supposeknowledge base = 0 + , 0 Theorem 3.1. Observe= and, hence, since 0 stable model , 0 stable model .show stable model . First, note condition 1, 0 . Thus,satisfies rules and, atom P proof w. r. t. 0 ,also proof w. r. t. . So, Theorem 2.2, stable model and,definition, stable model .Theorem 3.1 implies algorithm All-Stable1 (Figure 3), computes stablemodels knowledge base . Hence, following complexity analysis.Proposition 3.2 knowledge base k atoms appear negated2k stable models found time O(nl2k ), l sizeknowledge base n number atoms used knowledge base.Proof: Follows fact computing computing unique stable modelpositive knowledge base O(nl).34fiA Hierarchy Tractable SubsetsAll-Stable1()Input: knowledge base .Output: set stable models .1. := ;;2. possible interpretation set atoms appear negative ,do:(a) Compute 0 , unique stable model ;(b) 0 consistent, let := fM 0 + g;3. Return M;Figure 3: Algorithm All-Stable13.2 Algorithm Depends Number Non-Horn RulesAlgorithm All-Stable2 (Figure 4) depends number rulesnegated atoms. gets input knowledge base , and, outputs set stablemodels . algorithm based upon observation stable modelbuilt attempting possible means satisfying negated atoms bodies nonHorn rules. Two procedures called All-Stable2: UnitInst, shown Figure 5;NegUnitInst, shown Figure 6. Procedure UnitInst gets input knowledge basepartial interpretation m. UnitInst looks recursively unit rules . unit ruleP , , P assigned false m, follows cannot part model ,procedure returns false. P false m, procedure instantiates P trueinterpretation deletes positive appearances P body rule.also deletes rules P rules P appears negative.Procedure NegUnitInst receives input knowledge base , partial interpretationm, set atoms Neg. first instantiates atom Neg false updatesknowledge base ect instantiation. instantiations recorded m.case con ict, namely, procedure tries instantiate true atomalready set false, procedure returns false; otherwise, returns true.Proposition 3.3 Algorithm All-Stable2 correct, is, stable modelknowledge base iff generated All-Stable2().Proof: Suppose stable model knowledge base . Then, Theorem 2.2, everyatom set true proof w. r. t. . Let set non-Hornrules whose bodies satisfied m. Clearly, point checked step 3algorithm All-Stable2. happens, atoms proof w. r. t.set true procedure NegUnitInst (as proved inductionlength proof). Hence, generated.Suppose generated All-Stable2(). Obviously, every rule satisfied(step 3.c.ii), every atom set true NegUnitInst proof w. r. t.35fiBen-EliyahuAll-Stable2()Input: knowledge base .Output: set stable models .1. := ;;2. Let set non-Horn rules .3. subset , do:(a) Neg = fP jnot P body rule g;(b) 0 := ; := ;;(c) NegUnitInst(0 ; Neg; m),i. P m[P ] = null, let m[P ] := false;ii. satisfies rules , := fmg;4. EndFor;5. Return ;Figure 4: Algorithm All-Stable2UnitInst(; m)Input: knowledge base partial interpretation m.Output: Updates using unit rules . Returns false con ictunit rule value assigned atom m; otherwise, returns true .1. unit rules, do:(a) Let P , unit rule ;(b) m[P ] = false, return false;(c) m[P ] := true;(d) Erase P body rule ;(e) Erase rules P ;(f) Erase rules P appears negative;2. EndWhile;3. Return true;Figure 5: Procedure UnitInst36fiA Hierarchy Tractable SubsetsNegUnitInst(; Neg; m)Input: knowledge base , set atoms Neg , partial interpretation m.Output: Updates assuming atoms Neg false. Returns false inconsistencydetected; otherwise, returns true.1. atom P Neg(a) m[P ] := false;(b) Delete body rule occurrence P ;(c) Delete rule P appears positive body;2. EndFor;3. Return UnitInst(; m);Figure 6: Procedure NegUnitInst12lion dolphin ab1 mammal warm b land male femaleFFFFFFTable 1: Models generated Algorithm All-Stable2(as readily observable way NegUnitInst works). Hence, Theorem 2.2,stable model .Proposition 3.4 knowledge base c non-Horn rules 2c stable modelsfound time O(nl2c), l size knowledge basen number atoms used knowledge base.Proof: Straightforward, induction c.Example 3.5 Suppose call All-Stable2 0 input knowledge base.step 2, set rules (7), (8), (9). subsets include rules(8) (9) considered step 3, NegUnitInst return false UnitInstdetect inconsistency. subset containing rules (7) (8) considered,stable model 1 Table 1 generated. subset containing rules (7)(9) considered, stable model 2 Table 1 generated.subsets contain rules (8) (9) tested step 3, generatedsatisfy rules and, hence, appear output.Algorithms All-Stable1 All-Stable2 take account structureknowledge base. example, polynomial class stratifiedknowledge bases. present next algorithm exploits structure knowledgebase.37fiBen-Eliyahu4. Hierarchy Tractable Subsets Based Level StratifiabilityKnowledge BaseAlgorithm Acyclic-All-Stable (AAS) Figure 7 exploits structure knowledgebase ected super dependency graph knowledge base. computesstable models traversing super dependency graph bottom up, usingalgorithms computing stable models presented previous section subroutines.Let knowledge base. node G (the super dependency graph), associate , , Ms . subset containing rulesatoms s, set atoms subgraph G rooted s, Ms setstable models associated subset knowledge base contains rulesatoms . Initially, Ms empty every s. algorithm traverses Gbottom up. node s, first combines submodels childrensingle set models Mc(s) . source, Mc(s) set f;g3. Next,model Mc(s) , AAS converts knowledge base sm using GL transformtransformations depend atoms m; then, finds stable modelssm combines m. set Ms obtained repeating operationMc(s) . AAS uses procedure CartesProd (Figure 8), receives inputseveral sets models returns consistent portion Cartesian product. onesets models CartesProd gets input empty set, CartesProdoutput empty set models. procedure Convert gets input knowledge base ,model m, set atoms s, performs following: atom P m,positive occurrence P deleted body rule ; rule ,P body rule P 2 m, rule deleted ; Pbody rule P 2= m, then, P 2= s, P deleted body.procedure All-Stable called AAS may one procedures previously presented(All-Stable1 All-Stable2) may procedure generates stablemodels.Example 4.1 Suppose AAS called compute stable models 0. Supposealgorithm traverses super dependency graph Figure 2 order flion,dolphin, mammal, ab1, land, warm blooded, female-maleg (recall nodes inside square make one node calling female-male or, short, FM).visiting nodes except last, Mlion = ffliongg, Mdolphin = f;g,Mmammal = fflion; mammalgg, Mon land = fflion; mammal; onlandgg, Mwarm blooded =fflion; mammal; warm bloodedgg. visiting node FM, step 1.cMc(FM ) = Mmammal . step 1.d loops once, = flion; mammalg. RecallFM knowledge basefemalemale, mammal; male, mammal; female3. Note difference f;g, set one model - model assignsatoms, ;, set contains models.38falsefiA Hierarchy Tractable SubsetsAcyclic-All-Stable()Input: knowledge base .Output: set stable models .1. Traverse G bottom up. node s, do:(a) Ms := ;;(b) Let s1 ; :::; sj children s.(c) j = 0, Mc(s) := f;g;else Mc(s) := CartesProd(fMs1 ; :::; Msj g);(d) 2 Mc(s) , do:i. sm := Convert(s ; m; s);ii. := All-Stable(sm );iii. 6= ;, Ms := Ms CartesProd(ffmg; g);2. Output CartesProd(fMs1 ; :::; Msk g), s1 ; :::; sk sinks G .Figure 7: Algorithm Acyclic-All-Stable (AAS)CartesProd(M)Input: set sets models M.Output: set models consistent portion Cartesian productsets M.1. single element fE g, return E ;2. := ;;3. Let 0 2 M;4. := CartesProd(M n fM 0g);5. D, do:(a) 0 , do:consistent, := fm + dg;(b) EndFor;6. EndFor;7. Return ;Figure 8: Procedure CartesProd39fiBen-Eliyahuexecuting step 1.d.i, FM setfemalemale, male, femaleknowledge base two stable models: ffemaleg fmaleg. Cartesianproduct set flion; mammalg yields MFM = fflion; mammal; femaleg;flion; mammal; malegg. step 2, Cartesian product Mwarm blooded , Mon land,MFM taken. Thus, algorithm outputs fflion; mammal; land; warm blooded; femaleg,flion; mammal; land; warm blooded; malegg, indeed two stable models0 . Note algorithm AAS ecient either All-Stable1 All-Stable2knowledge base 0 .Theorem 4.2 Algorithm AAS correct, is, stable model knowledge baseiff generated AAS applied .Proof: Let s0; s1; :::; sn ordering nodes super dependency graphalgorithm executed. show induction AAS, nodesi, generates stable models portion knowledge base composedrules use atoms Asi .case = 0: case, step 1.d.ii AAS, sm = s; thus, claim followscorrectness algorithm All-Stable called step 1.d.ii.case > 0: Showing every model generated stable straightforward, induction hypothesis Theorem 2.2. direction is: suppose stable model; show generated. Clearly, child si , projectiononto stable model part knowledge base uses atomsAs. induction, mc , projection onto union everychild si , must belong Mc(si ) computed step 1.c. Therefore, showgenerated, need show m0 = , mc stable model simc .easily done using Theorem 2.2.analyze complexity AAS. First, given knowledge baseset atoms s, define ^ knowledge base obtained deletingnegative occurrence atom belong body every rule.example, = fa ,not b; c ,not d; ag = fbg, ^ = fa ,not b; c ,ag.visiting node execution AAS, compute step 1.d.iistable models knowledge base sm . Using either All-Stable1 All-Stable2,estimated time required find stable models sm shorter equaltime required find stable models ^ . occurs number negativeatoms number rules negative atoms bodies ^ higherequal number negative atoms number rules negative atomsbodies sm , regardless is. Thus, ^ Horn knowledge base,find stable model ^ , hence sm , polynomial time, matter is.40fiA Hierarchy Tractable Subsets^ positive, find stable models ^ , hence sm , timemin(ln 2k ; ln 2c ), l length ^ , n number atoms used ^ , cnumber rules ^ contain negative atoms, k number atoms appearnegatively ^ .Then, knowledge base , associate number follows. Associatenumber vs every node G . ^ Horn knowledge base, vs 1; else, vsmin(2k ; 2c), c number rules ^ contain negative atoms s,k number atoms appear negatively ^ . associate number tsevery node s. leaf node, ts = vs . children s1 ; :::; sj G ,ts = vs ts1 ::: tsj . Define ts1 ::: tsk , s1 ; :::; sk sink nodesG .Definition 4.3 knowledge base belongsj = j .Theorem 4.4 knowledge base belongsj j , j stablemodels computed time O(lnj ).Proof: induction j . dependency graph super dependency graphbuilt time linear size knowledge base. may considertime takes compute stable models super dependency graph given.case j = 1: 21 means every node G, ^ Horn knowledge base.words, stratified, therefore exactly one stable model.n nodes graph. node, loop step 1.d executedonce, one model generated every node. Procedure Convert runstime O(ls), ls length (we assume stored arrayaccess atom constant time). Since, every node s, ^Horn knowledge base, sm computed time O(lsn). Thus, overall complexityO(ln).case j > 1: induction n, number nodes super dependency graph .case n = 1: Let single node G . Thus, j = vs. Using algorithmsSection 3, stable models = found time O(lnvs ),vs models.case n > 1: Assume without loss generality G single sink (to getsingle sink, add program rule P , s1 ; ::; sk, s1 ; :::; sksinks P new atom). Let c1 ; :::; ck children s.child ci , (ci ), part knowledge base corresponds subgraphrooted ci, must belongti ti j . induction n,child node ci, stable models (ci ) computed time O(lnti ),(ci) ti stable models. let us observe happens AASvisiting node s. First, Cartesian product models computedchild nodes taken. executed time O(n t1 ::: tk), yieldst1 ::: tk models Mc(s) . every 2 Mc(s) , call Convert (O(ln))compute stable models sm (O(lnvs)). combineusing CartesProd (O(nvs )). Thus, overall complexity computing Ms ,is, computing stable models , O(lnt1 ::: tk vs ) = O(lnj ).41fiBen-EliyahuNote stratified knowledge bases belong1 , knowledgebase looks stratified, ecient algorithm AAS be.Given knowledge base , easy find minimum j belongsj .follows building G finding c k every node G polynomialtime tasks. Hence,Theorem 4.5 Given knowledge base , find minimum j belongsj polynomial time.Example 4.6 nodes G0 except FM, vs =1. vFM = 2. Thus, 0 22. 1stratified knowledge base therefore belongs1.malefemalewarm_bloodon_landmammallionflyab1dolphinbirdab2penguinFigure 9: super dependency graph 0 1next example shows step 5 procedure CartesProd necessary.Example 4.7 Consider knowledge base 4:, bb ,cef,,,,42bc;cfiA Hierarchy Tractable SubsetsfecbFigure 10: Super dependency graph 4ccbb(1)(2)Figure 11: Dependency graph (1) super dependency graph (2) 243fiBen-Eliyahusuper dependency graph 4 shown Figure 10. run algorithm AAS,Mab (the set models computed node fa; bg) set ffa; :bg; f:a; bgg. AASvisits nodes c d, get Mc = ffa; :b; cg; f:a; bgg, Md = ff:a; b; dg; fa; :bgg.AAS visits node e, CartesProd called input fMc ; Mdg, yielding output =ffa; :b; cg; f:a; b; dgg. Note CartesProd output model ctrue, models fa; :b; cg f:a; b; dg inconsistent CartesProdchecks consistency step 5. visiting node f , get Mf = ffa; :b; c; f g; f:a; bgg.AAS returns CartesProd(fMe; Mf g), ffa; :b; c; f g; f:a; b; dgg.next example demonstrates models generated nodes super dependency graph run AAS may later deleted, since cannotcompleted stable model whole knowledge base.Example 4.8 Consider knowledge base 2:bc, b,, a; cdependency graph super dependency graph 2 shown Figure 11.run algorithm AAS, Mab (the set models computed node fa; bg)set ffag; fbgg. However, fbg stable model 2 .Despite deficiency illustrated Example 4.8, algorithm AAS desirablefeatures. First, AAS enables us compute stable models modular fashion. useG structure store stable models. knowledge base changed,need resume computation nodes affected change. example,suppose computing stable models knowledge base 0 , add toS 0knowledge base 1 Example 2.6, gives us new knowledge base, 3 = 0 1.super dependency graph new knowledge base 3 shown Figure 9.need compute stable models nodes penguin, bird, ab2, y, landcombine models generated sinks. re-computestable models nodes well.Second, using AAS algorithm, always compute stable modelsroot node. queried atom somewhere middlegraph, often enough compute models subgraph rootednode represents atom. example, suppose given knowledge base2 asked mammal true every stable model 2 . run AASnodes dolphin, lion, mammal | stop. mammal true stablemodels computed node mammal (i.e., models Mmammal ), answer\yes", otherwise, must continue computation.Third, AAS algorithm useful computing labeling TMS subjectnogoods. set nodes TMS declared nogood, means acceptablelabeling assign false least one node nogood set.4 stable modelsterminology, means handling nogoods, look stable models4. logic programming terminology nogoods simply integrity constraints.44fiA Hierarchy Tractable Subsetsleast one atom nogood false. straightforward approach would firstcompute stable models choose ones comply nogoodconstraints. since AAS algorithm modular works bottom up,many cases prevent generation unwanted stable models early stage.computation, exclude submodels comply nogoodconstraints erase submodels Ms node superdependency graph includes members certain nogood.5. Computing Stable Models First-Order Knowledge Basessection, show generalize algorithm AAS find stablemodels knowledge base first-order language function symbols. newalgorithm called First-Acyclic-All-Stable (FAAS).refer knowledge base set rules formC ,A1; A2; :::; Am; B1; :::; Bn(14)As, B s, C atoms first-order language function symbols.definitions head, body, positive negative appearances atompropositional case. expression p(X1; :::; Xn), p called predicate name.propositional case, every knowledge base associated directed graphcalled dependency graph , (a) predicate name node, (b)positive arc directed node p node q iff rulep predicate name one Ai q predicate name head, (c)negative arc directed node p node q iff rulep predicate name one Bi q predicate name head. superdependency graph, G , defined analogous manner. define stratified knowledgebase knowledge base cycles negative edgesdependency graph knowledge base.knowledge base called safe iff rules safe. rule safe iffvariables appearing head rule predicates appearing negative rulealso appear positive predicates body rule. section, assumeknowledge bases safe. Herbrand base knowledge base set atomsconstructed using predicate names constants knowledge base. setground instances rule set rules obtained consistently substituting variablesrule constants appear knowledge base possible ways.ground instance knowledge base union ground instances rules. Noteground instance first-order knowledge base viewed propositionalknowledge base.model knowledge base subset knowledge base's Herbrand base.subset property every rule grounded knowledge base,atoms appear positive body rule belong atomsappear negative body rule belong , atom headrule belongs . stable model first-order knowledge base Herbrandmodel , also stable model grounded version .45fiBen-EliyahuFirst-Acyclic-All-Stable()Input: first-order knowledge base .Output: stable models .1. Traverse G bottom up. node s, do:(a) Ms := ;;(b) Let s1 ; :::; sj children s;(c) Mc(s) := CartesProd(fMs1 ; :::; Msj g);(d) 2 Mc(s)Ms := MsSall-stable(s SfP ,jP 2 mg)2. Output CartesProd(fMs1 ; :::; Msk g), s1 ; :::; sk sinks G .Figure 12: Algorithm First-Acyclic-All-Stable (FAAS)present FAAS, algorithm computes stable models first-orderknowledge base. Let first-order knowledge base. propositional case,node G (the super dependency graph ), associate , , Ms .subset containing rules predicates whose names s.set predicate names P appear subgraph G rooted s. Msstable models associated sub{knowledge base contains rulespredicates whose names . Initially, Ms empty every s. Algorithm FAAStraverses G bottom up. node s, algorithm first combinessubmodels children single set models, Mc(s) . Then, modelMc(s), calls procedure finds stable models union setunit clauses P , P 2 m. procedure All-Stable called FAASprocedure computes stable models first-order knowledge base.procedure All-Stable computes stable models parts knowledge base,may take advantage fractions knowledge base stratifiedproperty simplifies computation stable models fraction.Theorem 5.1 Algorithm FAAS correct, is, stable model knowledge baseiff one models output applying FAAS .Proof: proof Theorem 4.2.Note knowledge base appears stratified, ecient algorithmFAAS becomes.Example 5.2 Consider knowledge base 5:warm blooded(X )live land(X )female(X ), mammal(X ), mammal(X ); ab1(X ), mammal(X ); male(X )46fiA Hierarchy Tractable Subsetsmale(X )mammal(X )ab1(X )mammal(X )dolphin(flipper),,,,,mammal(X ); female(X )dolphin(X )dolphin(X )lion(X ), bird(X ), bird(X ); ab2(X ), penguin(X ), penguin(X ),super dependency graph 5 , G5 , super dependency graphlive land(X )fly (X )bird(X )ab2(X )bird(bigbird)knowledge base 2 (see Figure 9). Observe node mammal, example,step 1.d algorithm looks stable models knowledge base 0 = mammalf ,dolphin(flipper)g, mammal =fmammal(X ) ,dolphin(X ); mammal(X ) ,lion(X )g.0 stratified knowledge base unique stable model found eciently.Hence, algorithm FAAS saves us ground rules knowledge basestarting calculate models, take advantage parts knowledgebase stratified.6. Related Workrecent years, quite algorithms developed reasoning stable models.Nonetheless, far know, work presented original senseprovides partition set knowledge bases hierarchy tractableclasses. partition based structure dependency graph. Intuitively,task computing stable models knowledge base using algorithm AAS becomesincreasingly complex \distance" knowledge base stratified becomeslarger. Next, summarize work seems us relevant.Algorithm AAS based idea appears work Lifschitz Turner(1994), show many cases logic program divided two parts,one part, \bottom" part, refer predicates defined \top"part. explain task computing stable models programsimplified program split parts. Algorithm AAS, using superstructuredependency graph, exploits specific method splitting program.Bell et al. (1994) Subrahmanian et al. (1995) implement linear integer programming techniques order compute stable models (among nonmonotonic logics). However, dicult assess merits approaches terms complexity.Ben-Eliyahu Dechter (1991) illustrate knowledge base translatedpropositional theory model latter corresponds stable modelformer. follows problem finding stable modelsknowledge base corresponds problem finding models propositionaltheory. Satoh Iwayama (1991) provide nondeterministic procedure computing47fiBen-Eliyahustable models logic programs integrity constraints. Junker Konolige (1990)present algorithm computing TMS' labels. Antoniou Langetepe (1994) introducemethod representing classes default theories normal logic programsway SLDNF-resolution used compute extensions. Pimentel Cuadrado(1989) develop label-propagation algorithm uses data structures called compressiblesemantic trees order implement TMS; algorithm based stable model semantics. algorithms developed Marek Truszczynski (1993) autoepistemiclogic also adopted computing stable models. procedures MarekTruszczynski (1993), Antoniou Langetepe (1994), Pimentel Cuadrado (1989), BenEliyahu Dechter (1991), Satoh Iwayama (1991), Bell et al. (1994), Subrahmanianet al. (1995), Junker Konolige (1990) take advantage structureknowledge base ected dependency graph, therefore ecientstratified knowledge bases.Sacca Zaniolo (1990) present backtracking fixpoint algorithm constructing onestable model first-order knowledge base. algorithm similar algorithm AllStable2 presented Section 3 complexity worse complexityAll-Stable2. show backtracking fixpoint algorithm modifiedhandle stratified knowledge bases ecient manner, algorithm needsadjustments deal eciently knowledge bases closestratified. Leone et al. (1993) present improved backtracking fixpoint algorithmcomputing one stable model Datalog: program discuss improved algorithmimplemented. One procedures called improved algorithm basedbacktracking fixpoint algorithm Sacca Zaniolo (1990). Like backtrackingfixpoint algorithm, improved algorithm take advantage structureprogram, i.e., ecient programs close stratified.Several tractable subclasses computing extensions default theories (and, hence,computing stable models) known (Kautz & Selman, 1991; Papadimitriou & Sideri,1994; Palopoli & Zaniolo, 1996; Dimopoulos & Magirou, 1994; Ben-Eliyahu & Dechter,1996). tractable subclasses characterized using graph ectsdependencies program atoms rules. algorithms presentedpapers complete subclass knowledge bases, however. Algorithmscomputing extensions stratified default theories extensions default theoriesodd cycles (in precise sense) given Papadimitriou Sideri (1994)Cholewinski (1995a, 1995b).Algorithms handling TMS nogoods developed AI community Doyle (1979) Charniak et al. (1980). But, Elkan (1990) points out,algorithms always faithful semantics TMS complexitiesanalyzed. Dechter Dechter (1994) provide algorithms manipulating TMSrepresented constraint network. eciency algorithms dependsstructure constraint network representing TMS, structureemploy differs dependency graph knowledge base.48fiA Hierarchy Tractable Subsets7. Conclusiontask computing stable models heart several systems central AI,including TMSs, autoepistemic logic, default logic. task shownNP-hard. paper, present partition set knowledge bases classes1 ;2; :::, knowledge basek , k stable models,may found time O(lnk), l length knowledge basen number atoms . Moreover, arbitrary knowledge base , findminimum k belongsk time linear size . Intuitively,knowledge base stratified, ecient algorithm becomes. believebeyond stratified knowledge bases, expressive knowledge base (i.e.rules nonstratified negation knowledge base), less likely needed.Hence, analysis quite useful. addition, show algorithm AASseveral advantages dynamically changing knowledge base, provide applicationsanswering queries implementing TMS's nogood strategies. also illustrategeneralization algorithm AAS class first-order knowledge bases.Algorithm AAS easily adjusted find one stable model knowledgebase. traversing super dependency graph, generate one modelnode. arrive node cannot generate model basedcomputed far, backtrack recent node several models availablechoose take next model yet chosen. worst-case timecomplexity algorithm equal worst-case time complexity algorithmfinding stable models may exhaust possible ways generatingstable model finding certain knowledge base stable modelall. Nevertheless, believe average case, finding one modeleasier finding all. similar modification AAS algorithm requiredinterested finding one model one particular atom gets value true.work another attempt bridge gap declarative systems (e.g.,default logic, autoepistemic logic) procedural systems (e.g., ATMs, Prolog)nonmonotonic reasoning community. argued declarative methodssound, impractical since computationally expensive, procedural methods ecient, dicult completely understand performanceevaluate correctness. work presented illustrates declarativeprocedural approaches combined yield ecient yet formally supportednonmonotonic system.AcknowledgmentsThanks Luigi Palopoli useful comments earlier draft paper MichelleBonnice Gadi Dechter editing parts manuscript. Many thanksanonymous referees useful comments.work done author visiting Cognitive Systems Laboratory, Computer Science Department, University California, Los Angeles, California,USA. work partially supported NSF grant IRI-9420306 Air Force OceScientific Research grant #F49620-94-1-0173.49fiBen-EliyahuReferencesAntoniou, G., & Langetepe, E. (1994). Soundness completeness logic programmingapproach default logic. AAAI-94: Proceedings 12th national conferenceartificial intelligence, pp. 934{939. AAAI Press, Menlo Park, Calif.Apt, K., Blair, H., & Walker, A. (1988). Towards theory declarative knowledge.Minker, J. (Ed.), Foundations deductive databases logic programs, pp. 89{148.Morgan Kaufmann.Bell, C., Nerode, A., Ng, R., & Subrahmanian, V. (1994). Mixed integer programmingmethods computing non-monotonic deductive databases. Journal ACM,41 (6), 1178{1215.Ben-Eliyahu, R., & Dechter, R. (1994). Propositional semantics disjunctive logic programs. Annals Mathematics Artificial Intelligence, 12, 53{87. short versionappears JICSLP-92: Proceedings 1992 joint international conferencesymposium logic programming.Ben-Eliyahu, R., & Dechter, R. (1996). Default reasoning using classical logic. ArtificialIntelligence, 84 (1-2), 113{150.Bidoit, N., & Froidevaux, C. (1987). Minimalism subsumes default logic circumscriptionstratified logic programming. LICS-87: Proceedings IEEE symposiumlogic computer science, pp. 89{97. IEEE Computer Science Press, Los Alamitos,Calif.Charniak, E., Riesbeck, C. K., & McDermott, D. V. (1980). Artificial Intelligence Programming, chap. 16. Lawrence Erlbaum, Hillsdale, NJ.Cholewinski, P. (1995a). Reasoning stratified default theories. Marek, W. V.,Nerode, A., & Truszczynski, M. (Eds.), Logic programming nonmonotonic reasoning: proceedings 3rd international conference, pp. 273{286. Lecture notescomputer science, 928. Springer-Verlag, Berlin.Cholewinski, P. (1995b). Stratified default theories. Pacholski, L., & Tiuryn, A. (Eds.),Computer science logic: 8th workshop, CSL'94: Selected papers, pp. 456{470. Lecturenotes computer science, 933. Springer-Verlag, Berlin.Dechter, R., & Dechter, A. (1996). Structure-driven algorithms truth maintenance.Artificial Intelligence, 82 (1-2), 1{20.Dimopoulos, Y., & Magirou, V. (1994). graph-theoretic approach default logic. JournalInformation Computation, 112, 239{256.Doyle, J. (1979). truth-maintenance system. Artificial Intelligence, 12, 231{272.Dung, P. M. (1991). Negation hypothesis: abductive foundation logic programming. Furukawa, K. (Ed.), ICLP-91: Proceedings 8th international conferencelogic programming, pp. 3{17. MIT Press.50fiA Hierarchy Tractable SubsetsElkan, C. (1990). rational reconstruction nonmonotonic truth maintenance systems.Artificial Intelligence, 43, 219{234.Eshghi, K., & Kowalski, R. A. (1989). Abduction compared negation failure. Levi,G., & Martelli, M. (Eds.), ICLP-89: Proceedings 6th international conferencelogic programming, pp. 234{254. MIT Press.Fine, K. (1989). justification negation failure. Logic, Methodology PhilosophyScience, 8, 263{301.Gelfond, M. (1987). stratified autoepistemic theories. AAAI-87: Proceedings5th national conference artificial intelligence, pp. 207{211. Morgan Kaufmann.Gelfond, M., & Lifschitz, V. (1988). stable model semantics logic programming.Kowalski, R. A., & Bowen, K. A. (Eds.), Logic Programming: Proceedings 5thinternational conference, pp. 1070{1080. MIT Press.Gelfond, M., & Lifschitz, V. (1991). Classical negation logic programs disjunctivedatabases. New Generation Computing, 9, 365{385.Junker, U., & Konolige, K. (1990). Computing extensions autoepistemic default logics TMS. AAAI-90: Proceedings 8th national conferenceartificial intelligence, pp. 278{283. AAAI Press.Kakas, A. C., & Mancarella, P. (1991). Stable theories logic programs. Saraswat,V., & Udea, K. (Eds.), ISLP-91: Proceedings 1991 international symposiumlogic programming, pp. 85{100. MIT Press.Kautz, H. A., & Selman, B. (1991). Hard problems simple default logics. ArtificialIntelligence, 49, 243{279.Leone, N., Romeo, N., Rullo, M., & Sacca, D. (1993). Effective implementation negationdatabase logic query languages. Atzeni, P. (Ed.), LOGIDATA+: Deductivedatabase complex objects, pp. 159{175. Lecture notes computer science, 701.Springer-Verlag, Berlin.Lifschitz, V., & Turner, H. (1994). Splitting logic program. Van Hentenryck, P. (Ed.),ICLP-94: Proceedings 11th international conference logic programming, pp.23{37. MIT Press.Marek, V. W., & Truszczynski, M. (1993). Nonmonotonic logic: Context-dependent reasoning. Springer Verlag, Berlin.Marek, W., & Truszczynski, M. (1991). Autoepistemic logic. Journal ACM, 38,588{619.Moore, R. C. (1985). Semantical consideration nonmonotonic logic. Artificial Intelligence, 25, 75{94.Palopoli, L., & Zaniolo, C. (1996). Polynomial-time computable stable models.. AnnalsMathematics Artificial Intelligence, press.51fiBen-EliyahuPapadimitriou, C. H., & Sideri, M. (1994). Default theories always extensions.Artificial Intelligence, 69, 347{357.Pimentel, S. G., & Cuadrado, J. L. (1989). truth maintenance system based stablemodels. Lusk, E. L., & Overbeek, R. A. (Eds.), ICLP-89: Proceedings 1989North American conference logic programming, pp. 274{290. MIT Press.Przymusinska, H., & Przymusinski, T. (1990). Semantic issues deductive databaseslogic programs. Banerji, R. B. (Ed.), Formal techniques artificial intelligence:sourcebook, pp. 321{367. North-Holland, New York.Reiter, R. (1980). logic default reasoning. Artificial Intelligence, 13, 81{132.Sacca, D., & Zaniolo, C. (1990). Stable models non-determinism logic programsnegation. PODS-90: Proceedings 9th ACM SIGACT-SIGMOD-SIGARTsymposium principles database systems, pp. 205{217. ACM Press.Satoh, K., & Iwayama, N. (1991). Computing abduction using TMS. Furukawa, K.(Ed.), ICLP-91: Proceedings 8th international conference logic programming,pp. 505{518. MIT Press.Subrahmanian, V., Nau, D., & Vago, C. (1995). WFS + branch bound = stable models.IEEE Transactions Knowledge Data Engineering, 7 (3), 362{377.Tarjan, R. (1972). Depth-first search linear graph algorithms. SIAM JournalComputing, 1, 146{160.52fi