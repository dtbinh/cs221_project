Journal Artificial Intelligence Research 3 (1995) 405-430Submitted 6/95; published 12/95Decision-Theoretic Foundations Causal ReasoningDavid Heckermanheckerma@microsoft.comMicrosoft Research, One Microsoft WayRedmond, WA 98052-6399 USARoss Shachtershachter@camis.stanford.eduStanford UniversityStanford, CA 94305-4025 USAAbstractpresent definition cause effect terms decision-theoretic primitivesthereby provide principled foundation causal reasoning. definition departstraditional view causation causal assertions may vary set decisionsavailable. argue approach provides added clarity notion cause. Alsopaper, examine encoding causal relationships directed acyclic graphs.describe special class uence diagrams, canonical form, showrelationship Pearl's representation cause effect. Finally, show canonicalform facilitates counterfactual reasoning.1. IntroductionKnowledge cause effect crucial modeling affects actions. example,observe statistical correlation smoking lung cancer, concludeobservation alone chances getting lung cancer change stopsmoking. If, however, also believe smoking cause lung cancer,conclude choice whether continue quit smoking affect whether getlung cancer.Work artificial intelligence researchers, statisticians, philosophers emphasized importance identifying causal relationships purposes modeling effectsactions. example, Simon (1977), Robins (1986), Spirtes et al. (1993), Pearl (1993,1995) developed graphical models cause effect, demonstratedmodels important reasoning effects actions. addition, Robins (1986),Rubin (1978), Pearl Verma (1991), Spirtes et al. (1993) developed approachesembrace causality learning effects actions data.One useful framework causal reasoning Pearl (1993, 1995)|herein Pearl.Using framework, construct causal graph G. nodes G correspond setvariables U wish model. variable set mutually exclusivecollectively exhaustive values instances. arcs G represent (informal) assertionscause|in particular, parents x 2 U direct causes x. Pearl gives informalassertions cause operational meaning introducing special class actionsvariables U describing affects actions using structure causalgraph. Specifically, posits that, every variable x 2 U , exists another variable x^,call atomic intervention x. variable x^ instance set(x) everyinstance x x, instance idle. instance set(x) corresponds actionc 1995 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiHeckerman & Shachterforces x take instance x indirectly affects variables changex. instance idle corresponds action nothing.1 Pearl assertseffects atomic interventions variables U determined structuralequationsx = fx (PaG (x); x^; x)x 2 U , (1) PaG (x) parents x G|that is, direct causes x, (2)variables x exogenous mutually independent random disturbances, (3)function fx property x = x x^ =set(x) regardless values PaG (x)x . Following Pearl, call framework defining cause structural-equationmodel.Another useful framework causal reasoning, closely related Pearl's,Spirtes et al. (1993)|herein SGS.Despite important advances reasoning cause effect, foundations approaches lacking. framework causal reasoning, importantconsider concepts primitive|that is, assumed self evident useddefine concepts. much possible, primitives simple universal meanings claims causation empirically tested causal inferencestrusted. Unfortunately, primitives used Pearl, SGS, researchersideal respect.example, SGS take cause primitive. Given controversies statisticsdisciplines concerning meaning cause, believe better primitivefound. Pearl takes random disturbance, exogenous variable, atomic interventionprimitives. One problem approach need understanding causeeffect identify intervention atomic. illustrate problem, supposewish model causal relationship binary variables w h representingwhether person considers wealthy happy, respectively. Further,suppose give person large sum stolen money along knowledgemoney stolen. ask question: action instance atomicintervention w? person care becomes wealthy,answer \yes." person typical, however, answer \no,"action would affect w h directly. Thus, must first determine whetheraction direct cause h determine whether action instanceatomic intervention.paper, provide principled foundation causal reasoning. particular,explicate set primitives decision theory, use primitives defineconcepts cause atomic intervention well random disturbanceexogenous variable. primitives simple understand used uniformly acrossmany disciplines.basic idea behind definition cause follows. Following paradigmdecision theory, focus person|the decision maker|who one decisionsmake. variable wish model considering decisions, distinguish1. adopt variant Pearl's notation instances atomic intervention. addition, whereasPearl calls action set(x) atomic intervention, find convenient use phrase referentire variable x^.406fiDecision-Theoretic Foundations Causal Reasoningvariable either decision variable chance variable. decision variablevariable whose instances correspond possible actions among person choose.chance variable variable. framework similar Pearl's, chancevariables correspond variables U decision variables correspond interventions.differences (1) require decision variable everychance variable, (2) decision variables need atomic interventions.Now, simplicity, suppose model consisting one decision variableset chance variables U . Imagine choose one instancessubsequently observe x 2 U . believe x different different choices, then,definition, say cause x. example, suppose decision variablerepresents decision whether continue smoking chance variable lrepresents whether get lung cancer. believe get lung cancercontinue smoking may get lung cancer quit, saycause l.definition related notion counterfactual: hypothetical statementquestion verified answered observation (Lewis, 1973; Holland,1986). smoking example, ask question \Will deciding differently possiblychange health outcome?" question answered observation, must either quit continue smoke; both. Using counterfactuals,Rubin (1978) defines notion causal effect closely related definitioncause.problem definitions cause based interventionallow chance variables causes chance variables. Consider variables gc representing person's gender birth whether person gets breastcancer, respectively. Although g chance variable (we cannot choose gender),often hear people say natural discourse g causes c. general, would likeaccommodate assertions.definition cause present indeed permit chance variables causes.is, however, one catch. Namely, assert set chance variables Xcause chance variable , must also specify decision decisions bringpossible changes X . breast-cancer problem, assert g causesc, must explicate decision possibly leads change gender breastcancer. example, say g causes c respect decision variable d,represents decision whether perform genetic surgery conception.including decision context assertions cause, definition departstraditional view causation. Nonetheless, departure makes causal assertionsprecise. example, consider another decision likely lead change gender:decision whether sex-change operation birth. case, mayreasonable assert g cause c respect o. Thus, causal relationshipsamong chance variables may depend decisions available intervention;definition accommodates dependence.paper organized four parts. part 1 (Sections 2 3), developdefinition cause, using decision-theoretic primitives Savage (1954). Section 2,introduce simpler relation cause, call limited unresponsiveness.Section 3, define cause terms limited unresponsiveness.407fiHeckerman & Shachterpart 2 (Sections 4 7), address graphical representation cause.Section 4, review directed-acyclic-graph (DAG) representation, known uencediagram, used two decades decision analysts model effectsdecisions (Howard Matheson, 1981). demonstrate inadequacies uence diagram representation cause. following three sections, developspecial condition uence diagram, known canonical form, improvesrepresentation cause.part 3 (Section 8), use definitions cause, atomic intervention, mappingvariable, along canonical form build correspondence (and thus foundationfor) Pearl's causal framework.part 4 (Section 9), demonstrate important use canonical form. Namely,show use uence diagrams canonical form general counterfactual reasoning.present framework traditional decision-analytic paradigm \one shot"decision. particular, consider experimental studies, variables measured repeatedly. Nonetheless, one easily extend framework situationsintroducing assumption exchangeability (de Finetti, 1937). Bayesian methodslearning models cause based approach discussed Angrist et al.(1995) Heckerman (1995).2. Unresponsivenesssection, introduce notion limited unresponsiveness, fundamental relationuse define cause. define limited unresponsiveness using primitivesdecision theory explicated (for example) Savage (1954).begin description primitives act, consequence, possible stateworld. Savage describes illustrates concepts follows:say decision made say one actschosen, decided on. deciding act, account must takenpossible states world, also consequences implicit actpossible state world. consequence anything may happenperson.Consider example. wife broken five good eggs bowlcome volunteer finish making omelet. sixth egg,reason must either used omelet wasted altogether, liesunbroken beside bowl. must decide unbrokenegg. Perhaps great oversimplification say mustdecide among three acts only, namely, break bowl containingfive, break saucer inspection, throw away withoutinspection. Depending state egg, three actsconsequence concern you, say indicated Table 1.purposes discussion, two points emphasize Savage's exposition. First, important distinguish choose|namely,acts|and choose|namely, consequences. Second, chooseact, consequence occurs logically determined state world.408fiDecision-Theoretic Foundations Causal Reasoningstateworldbreak bowlgood egg six-egg omeletbad eggactbreak saucerthrow awaysix-egg omelet five-egg omelet onesaucer washgood egg destroyedomelet five good five-egg omelet five-egg omeleteggs destroyedsaucer washTable 1: example illustrating acts, possible states world, consequences.(Taken Savage [1954].)is, consequence deterministic function act state world.course, consequence (and usually is) uncertain, uncertainty captureduncertainty state world. concepts act, consequence, stateworld, together deterministic mapping act state worldconsequence primitives.2omelet story, possible states world readily come mind givendescription problem. Furthermore, observe state world (i.e.,condition egg). many situations, however, state worldunobservable. is, assertion \the state world x" counterfactual.situations, bring possible states mind thinking actsconsequences. example, suppose decision continue smoking quit,model consequences getting cancer not. acts consequences bringmind four possible states world, shown Table 2. possible statesfamiliar names; simply label numbers. actual state worldobservable, because, decide quit, won't know sure wouldhappened continued, vice versa.acts consequences problem may actually bring mind four|even infinite number|of states world. example, state world maycorrespond degree susceptibility lung tissue tar measured biochemicalassay. Nonetheless, given discrete acts consequences chosen modelproblem, four states Table 2 suciently detailed. Savage recognizesissue detail definition state world: \a description world, leavingrelevant aspect undescribed." general, decision problem c consequencesacts, ca possible states world need distinguished.3idea state world may observable traced Neyman(1923), derived statistical methods estimating differences yields differentcrops planted plot land, circumstances one crop actuallyplanted plot. Rubin (1978) Howard (1990) formalized idea.2. Savage (1954) defines act \a function attaching consequence state world."contrast, take act primitive, many decision analysts (e.g., Howard, 1990).3. acts consequences continuous, specification complicated. paper,address situations acts consequences discrete.409fiHeckerman & Shachterstateworld1234actcontinuequitcancercancercancer cancercancercancercancer cancerTable 2: four possible states world decision continue quit smoking.practice, often cumbersome impossible reason monolithic setacts, possible states world, consequences. Therefore, typically describeitems terms set variables take two values instances.call variable describing set consequences chance variable. example,omelet story, describe consequences terms three chance variables: (1)number eggs omelet?4 (o) instances zero, five, six, (2) numbergood eggs destroyed? (g ) instances zero, one, five, (3) saucer wash? (s)instances yes. is, every consequence corresponds assignmentinstance chance variable.call variable describing set acts decision variable (or decision, short).example, suppose set possible acts going dresswork. case, describe acts terms decision variables shirt (plainstriped), pants (jeans corduroy), shoes (tennis shoes loafers).example general, every act corresponds choice instance decisionvariable.description possible states world terms component variables bitcomplicated, needed explication unresponsiveness limitedunresponsiveness. defer discussion issue Section 6.matter notation, use denote set decisions describe actsdecision problem, lower-case letters (e.g., d; e; f ) denote individual decisionsset D. Also, use U denote set chance variables describe consequences,lower-case letters (e.g., x; y; z ) denote individual chance variables U . addition,use variable denote state world (the instances correspondpossible states world).5 Thus, given decision problem|or domain,sometimes call it|is described variables U , D, .6introduction, discuss concept limited unresponsiveness.illustrate concept, consider following decision problem adapted Angrist et al.(1995). Suppose physician decide whether recommendparticular treatment. Given recommendation, patient may may actually4. emphasize distinction chance decision variables, put question mark endnames chance variables.5. use uppercase \S " denote single variable, later decompose setvariables.6. Sometimes, simplicity, leave implicit specification decision problem.410fiDecision-Theoretic Foundations Causal Reasoningr (recommendation)takedon't take(taken?) c (cured?) (taken?) c (cured?)1: complier, helpedyesyes2: complier, hurtyesyes3: complier, always curedyesyesyes4: complier, never curedyes5: defier, helpedyesyes6: defier, hurtyesyes7: defier, always curedyesyesyes8: defier, never curedyes9: always taker, curedyesyesyesyes10: always taker, curedyesyes11: never taker, cured12: never taker, curedyesyes13: (impossible)yesyesyes14: (impossible)yesyesyes15: (impossible)yes16: (impossible)yes(state world)Table 3: decision problem recommending medical treatment.accept treatment, may may cured result. Here, use singledecision variable recommendation (r) represent acts (i.e., = frg), two chancevariables taken? (t) cured? (c) represent whether patient actually acceptstreatment whether patient cured, respectively (i.e., U = ft; cg).possible states world problem shown Table 3. example,consider first row table. Here, patient accept treatmentrecommend it, cured takes treatment. describestate saying patient complier helped treatment. discussdescription states detail Section 6.indicated table, suppose believe last four states worldimpossible (i.e., probability zero). last four states share propertytakes instance acts, whereas c not. Thus, decision problemsatisfies following property: states world possible,two acts, c also same. say c unresponsive r stateslimited t.general, suppose decision problem described variables U , D, .Let X subset U , subset U [ D. say X unresponsivestates limited believe that, possible states world,assumes instance two acts X must also assume instanceacts. describe notion limited unresponsiveness earlier work terms411fiHeckerman & Shachterconditional fixed set (Heckerman Shachter, 1994). Angrist et al. (1995) discussinstance limited unresponsiveness, call exclusion restriction.formal, let X [S; D] instance X assumes (with certainty) givenstate world act D. example, omelet story, stateworld egg good, act throw away, o[S; D] (the numbereggs omelet) assumes instance five. Then, following definition.Definition 1 (Limited (Un)responsiveness) Given decision problem describedchance variables U , decision variables D, state world , variable sets X U[ U , X said unresponsive states limited , denoted X 6 -Y D,believe8 2 S; D1 2 D; D2 2 : [S; D1] = [S; D2] =) X [S; D1] = X [S; D2]X said responsive states limited , denoted X -Y D,case X unresponsive states limited |that is, believe9 2 S; D1 2 D; D2 2 s:t: [S; D1] = [S; D2] X [S; D1] =6 X [S; D2]X (un)responsive states limited = ;, simply say X(un)responsive D. notion unresponsiveness significantly simplerlimited unresponsiveness. is, = ;, equalities left-hand-sideimplications Definition 1 trivially satisfied. Thus, X unresponsive believethat, possible state world, X assumes instance acts; Xresponsive possible state world X differs two differentacts.examples responsive variables, consider omelet story. Let denote stateegg good, D1 D2 denote acts break bowl throw away,respectively. Then, variable (number eggs omelet?), o[S; D1] =sixo[S; D2] =five. Consequently, responsive D.7 similar manner, concludeg (number good eggs destroyed?), (saucer wash?) responsive D.Note chance variable x responsive D, then|to degree|itcontrol decision maker. Consequently, decision maker observe x priorchoosing act D. example, omelet story, observeresponsive variables o, g , choosing act.8example unresponsive variable, suppose include (the state world)variable U . (E.g., omelet story, take U fS; o; g; sg.) Savage'sdefinition , must unresponsive D. Note including U creates newstates world.discussed, notions unresponsiveness limited unresponsivenessclosely related concepts counterfactual reasoning. determine whether7. Technically, say fog responsive D. simplicity, however, usually drop setnotation singletons.8. precise, variable represents number eggs omelet choose actD. variable confused another variable{say |corresponding numbereggs omelet choose D. Whereas responsive cannot observedchoosing act, unresponsive observed choosing D.00412fiDecision-Theoretic Foundations Causal Reasoningchance variable x unresponsive decisions D, essentially answer query \Willoutcome x matter choose D?" Furthermore, determinewhether x unresponsive states limited , answer query \Ifchange result choice D, outcome x same?" Onefundamental assumptions work presented counterfactualqueries easily answered. experience, found decision makersindeed comfortable answering restricted counterfactual queries.concepts responsiveness probabilistic independence related, illustratedfollowing theorem.Theorem 1 set chance variables X unresponsive set decision variables D,X probabilistically independent D.Proof: definition unresponsiveness, X assumes instance actspossible state world. Consequently, learn X observing ,observing D. 2Nonetheless, two concepts identical. particular, converse Theorem 1hold. example, let us consider simple decision whether bet headstails outcome coin ip. Assume coin fair (i.e., probabilitiesheads tails 1/2) person ips coin knowbet. Here, possible outcomes coin toss correspond possible statesworld. Further, let decision variable b denote bet, chance variable w describepossible consequences win not. situation, w responsive b,possible states world, w different different bets. Nonetheless,probability w 1/2, whether bet heads tails. is, w b probabilisticallyindependent.Limited unresponsiveness conditional independence less closely relatedunqualified counterparts. Namely, limited unresponsiveness imply conditionalindependence. example, medical-treatment story, c (cured?) unresponsive r(recommendation) states limited (taken?), reasonable us believec r independent given t, perhaps factor that|partiallycompletely|determines person reacts recommendations treatment.derive several interesting properties limited unresponsiveness definition.1. X 6 -Y () 8x 2 X; x 6 -Y2. X 6 -W () X [ W 6 -W3. X 6 -D4. X 6 -Y =) X 6 -Y [Z5. X 6 -Y [Z 6 -Z =) X 6 -Z6. X -Z W 6 -Z =) X -W [Z413fiHeckerman & Shachterset decision variables domain, X W arbitrary sets chancevariables U , Z arbitrary sets variables U [ D.proofs properties straightforward. example, consider property 5.Given X 6 -Y [Z D,8 2 S; D1 2 D; D2 2 : [S; D1] = [S; D2] Z [S; D1] = Z [S; D2]Given 6 -Z D,=) X [S; D1] = X [S; D2]8 2 S; D1 2 D; D2 2 : Z [S; D1] = Z [S; D2] =) [S; D1] = [S; D2]Consequently, obtain8 2 S; D1 2 D; D2 2 : Z [S; D1] = Z [S; D2] =) X [S; D1] = X [S; D2]is, X 6 -Z D.properties follow these. example, true trivially ; 6 -Y D.Consequently, Property 2, know 6 -Y D. another example, special caseProperty 4 whenever X unresponsive D, X unresponsivestates limited Z . Also, Properties 4 5 imply limited unresponsivenesstransitive: X 6 -Y 6 -Z imply X 6 -Z D.closing section, note definition limited unresponsivenessgeneralized several ways. one generalization, define means X Uunresponsive states world limited , set instances . Namely,say X unresponsive states limited if, possible states worldS, two acts D1 D2 , [S; D1] = [S; D2] 2 implies X [S; D1] = X [S; D2].second generalization, define means set chance variablesunresponsive subset decisions. particular, given domain describedU D, say X U unresponsive D0 states limitedX 6 -Y [(DnD ) D.03. Definition CauseGiven notion limited unresponsiveness, formalize definition cause.Definition 2 (Causes Respect Decisions) Given decision problem describedU D, variable x 2 U , variables C [ U n fxg said causesx respect C minimal set variables x 6 -C D.framework, decision variables caused,control decision maker. Consequently, define causes chance variables only.Also, discussed, definition extension existing intervention-baseddefinitions cause (e.g., Rubin [1978]) allow causes include chance variables.addition, definition cause departs traditional usage term causeeffect assertions may vary set decisions available. discuss advantagesdeparture shortly.414fiDecision-Theoretic Foundations Causal Reasoningexample definition, consider decision continue quit smoking,described decision variable (smoke) chance variable l (lung cancer?).believe l probabilistically dependent, then, Theorem 1, mustl - s. Furthermore, Property 3, know l 6 -s s. Consequently, Definition 2,cause l respect s.another example, consider medical-treatment story. c (cured?)responsive r (recommendation), (among reasons) first rowTable 3, patient cured recommend treatment. Furthermore,discussed previous section, c unresponsive r states limited (taken?).Consequently, cause c respect r.advantage defining cause relative decisions made clear breast-cancerexample given introduction. Let g c denote chance variables gender?breast cancer?, respectively. Now, imagine two decisions available alter gender: o,decision sex-change operation birth, d, decision change chromosomesconception microsurgery. possible someone believe c 6 - yetc - c 6 -g d. is, possible someone believe gender causebreast cancer respect chromosome change respect sex-changeoperation. situation, make sense make unqualified statement\gender cause breast cancer." general, decision-based definition providesadded clarity.Several consequences Definition 2 worth mentioning. First, although causeirre exive definition, always asymmetric. example, storycoin toss, consider another variable represents whether outcomecoin toss matches bet b. story told it, deterministic functionw (win?), vice versa. Consequently, w 6 -m b 6 -w b; causew w cause respect b. Note hint uncertainty destroyssymmetry. example, possibility person tossing coin cheat(so may lose even match), conclude cause w,vice versa. symmetry would also destroyed decision controlling wunresponsive.Second, cause transitive single variables. particular, x causecause z respect D, z -D (by transitivity unresponsiveness)z 6 -x D. Consequently, x cause z respect D. Note transitivitynecessarily hold causes containing sets variables, minimality conditionDefinition 2 may satisfied.Third, C = ; set causes x respect x unresponsiveD.Fourth, following theorem, follows Definition 2 severalproperties limited unresponsiveness given Section 2.Theorem 2 Given x 2 U , C set causes x respect D, w 2 C \U ,w must responsive D.Proof: chance variable w 2 C , let C 0 = C n fwg. minimality conditiondefinition,x -C(1)0415fiHeckerman & ShachterSuppose w 6 - D. Then, Property 4,w 6 -C0(2)Applying Equations 1 2 Property 6, x -C D, contradictsC set causes x respect D. 2illustrate use theorem, let us extend medical-treatment exampleimagining gene affects person reacts recommendation therapy. situation, reasonable us assert variable g(genotype?) unresponsive r. Thus, Theorem 2, g among causesvariable.consequence definition may seem unappealing. Intuitively, would likeable say (in sense) g cause c. Indeed, definition precludeability make assertions. Namely, reason require decisionsimplementable practice all. want think whetherpatient's genotype cause cure, imagine action alterone's genetic makeup|for example, retroviral therapy (v ). case, reasonableconclude fr; g g cause respect decisions fr; v g. Nonetheless,discussed, must clear action(s) alter genotype makestatement cause precise.Finally, generalize definition means set variables causex definition means set instances cause x. Namely, sayC , set instances C , cause x 2= C respect C minimal setvariables x unresponsive states limited C . is, C causex respect replace definition cause weaker requirementx unresponsive states limited C .4. uence Diagramsfollowing three sections, examine graphical representation causewithin framework. study useful right, also help relateframework Pearl's structural equation model. begin, section, reviewuence-diagram representation.uence diagram (1) acyclic directed graph G containing decision chancenodes corresponding decision chance variables, information relevance arcs,representing known time decision probabilistic dependence, respectively, (2) set probability distributions associated chance node, optionally(3) utility node corresponding set utilities (Howard Matheson, 1981).information arc one points decision node. information arc chancedecision node decision node indicates variable known decisionmade. (We shall use notation refer variable correspondingnode diagram.) relevance arc one points chance node. absencepossible relevance arc represents conditional independence. identify relevance arcs,start ordering variables U = (x1; : : :; xn ). Then, variable xiorder, ask decision maker identify set PaG (xi ) fx1; : : :; xi,1 ; Dg renders416fiDecision-Theoretic Foundations Causal Reasoningxi fx1; : : :; xi,1; Dg conditionally independent. is,p(xijx1; : : :; xi,1; D; ) = p(xijPaG (xi ); )(3)p(X jY; ) denotes probability distribution X given decision makerbackground information . every variable z PaG (xi ), place relevance arcz xi graph G uence diagram. is, nodes PaG (xi) parentsxi G.Associated chance node xi uence diagram probability distributions p(xijPaG (xi ); ). chain rule probability, knownp(x1; : : :; xn jD; ) = p(xijx1; : : :; xi,1; D; )i=1(4)Combining Equations 3 4, see uence diagram U [ uniquelydetermines joint probability distribution U given D. is,p(x1; : : :; xnjD; ) =Yn p(xijPaG(xi); )i=1(5)uence diagrams may also contain special chance nodes. deterministic node corresponds variable deterministic function parents. utility node encodespreferences decision maker. Finally, uence diagram unambiguousdecision nodes totally ordered|that is, directed path uencediagram traverses decisions. total order corresponds orderdecisions made.paper, concern neither ordering decision nodesobservation chance variables making decisions. Therefore, concernedinformation arcs. Likewise, although new concepts apply models includeutility nodes, illustrate concepts models containing chance, deterministic, decision variables.Figure 1a contains uence diagram omelet story. illustratedfigure, use ovals, double ovals, squares represent chance, deterministic,decision nodes, respectively. Among possible relevance arcs uence diagram,several missing. example, arc , representing independence(which follows assertion unresponsive D). Figures 1b1c contain uence diagrams medical-treatment example. chance variable g(genotype?) explicitly modeled Figure 1c.ordinary uence diagram designed representation conditional independence. Furthermore, discussed, concepts conditional independencelimited unresponsiveness loosely related. Consequently, uence diagraminadequate representation causal dependence, least definition cause.particular, uence diagram may contain arc node x node , eventhough x among set causes . example, uence diagram Figure 1barcs r c due dependencies domain. Nonetheless,established singleton ftg cause c respect r.417fiHeckerman & Shachterdecisionstateworld (egg)number eggsomelet?recommendationrrtreatment?number goodeggs destroyed?gsaucer wash?genotype?gcured?(a)c(b)c(c)Figure 1: uence diagrams (a) omelet story, (b,c) medical-treatment example.Furthermore, uence diagram may contain arc x , even though xcause . example, consider coin example, illustrated uence diagramFigure 2a. believe coin fair, bother model variablec explicitly (as shown Figure 2b), need place arc w,probability winning 1=2, regardless choice d. Nonetheless, b causew respect b, definition.Despite limitations, uence diagram adequate purposes making decisions uncertainty. introduction, argued causal information neededpredicting effects actions. Thus, question arises: \Why need anythinguence diagram representation effects actions?" giveanswer question Section 9, discuss counterfactual reasoning. There,show ordinary uence diagram inadequate purposes counterfactualreasoning unless canonical form|a form accurately ects cause.5. Direct Atomic Interventionsorder define canonical form, need concept mapping variable. Likewise,order define mapping variable, need concept atomic intervention. alsoneed concept atomic intervention explicate Pearl's structural-equation model.section, define atomic intervention along general concept called directintervention.Roughly speaking, say set decisions direct intervention setchance variables X effects chance variables mediatedeffects X . SGS, take cause primitive, provide formal definitiondirect intervention (which call direct manipulation) consistentnotion. find simpler define direct intervention terms limited unresponsiveness.418fiDecision-Theoretic Foundations Causal Reasoningbetbbetcoincwinbwinww(a)(b)Figure 2: uence diagrams betting coin ip.Definition 3 (Direct Intervention) Given domain described U D, setdecisions said direct intervention X U respect (1)x 2 X , x - , (2) 2 U , 6 -X .example, medical-treatment story, r direct intervention t,- r c 6 -t r. another example, suppose physician additional decisionp whether pay patient take treatment. reasonable expect- p. Furthermore, amount payment small, reasonable c 6 -t p.Consequently, p qualifies direct intervention t. Nonetheless, amount paymentsuciently large, patient may use money improve health care. Thus,c -t p; p satisfy condition 2 direct intervention t.Given notion direct intervention, define atomic intervention.Definition 4 (Atomic Intervention) Given domain described U D, decisionx^ 2 said atomic intervention x 2 U respect (1) fx^g directintervention fxg respect D, (2) x^ precisely instances (a) idle,corresponds instance nothing x, (b) set(x) every instance x x,x = x whenever x^ =set(x).discussed introduction, Pearl takes concept atomic interventionprimitive. Whether decision direct (or atomic) intervention, however,depends underlying causal relationships domain. medical-treatmentstory, suppose physician decision k whether administer treatment(a drug) without patient's knowledge. believe treatment truly effectiveplacebo effect, assert k direct intervention t. If,however, believe treatment placebo effect, k directintervention t, k also directly affect c. Thus, notions directatomic intervention require definitions, lest meaning cause would hiddenprimitives.note that, bi-directional causal relationships among variables U ,always possible every chance variable atomic intervention.example, consider adiabatic system consisting cylindrical chamber moveable419fiHeckerman & Shachterinstance t(r)1: complier2: defier3: always taker4: never takerr =take r =don't take=yes=no=no=yes=yes=yes=no=noTable 4: mapping variable t(r).top, model variables pressure? (p) volume? (v ).9 allowtop chamber move freely, placing various weights top chamberconstitutes atomic intervention p; p cause v respectp^. contrast, fixing top chamber particular locations constitutes atomicintervention v ; v cause p respect v^. lawsphysics, however, decisions p^ v^ available simultaneously.6. Mapping Variablesunderstand concept mapping variable, let us reexamine Savage's basic formulation decision problem. Recall chance variables U deterministic functiondecision variables state world . effect, possible stateworld defines mapping decisions chance variables U . Thus, representspossible mappings U . characterize mapping variable Ufunction D, use suggestive notation U (D) denote mapping variable.general, given domain described U , D, , set decision variables D,set chance variables X U , mapping variable X (Y ) variable representspossible mappings X .example, consider medical-treatment story. mapping variable t(r) represents possible mappings decision variable r (recommendation) chancevariable (taken?). example, instances t(r), shown Table 4, naturalinterpretation. particular, instance patient accepts treatmentrecommend represents patient complies recommendation; instancepatient accepts treatment recommend representspatient defies recommendation; on.notion mapping variable discussed Heckerman Shachter (1994),Balke Pearl (1994) name \response function." related counterfactualvariable described Neyman (1923), Rubin (1978), Howard (1990). discusswould denote X (Y = Y): variable X choose instance .important property concerning mapping variables that, given variables X; Y;X (Y ), always write X deterministic function X (Y ). example,deterministic function r t(r); U deterministic function U (D) .9. example appropriate technically, uses continuous variables. Nonetheless, exampleillustrates point.420fiDecision-Theoretic Foundations Causal Reasoningdiscussions follow, useful extend definition mapping variableinclude chance variables arguments. example, medical-treatment story, seemsreasonable define mapping variable c(t) instances helped, hurt, always cured,never cured. Together, mapping variables t(r) c(t) describe possible statesworld U (D) . (E.g., t(r) =complier c(t) =helped corresponds state 1Table 3.) shall see, decomposition U (D) facilitates graphical representationcausal relationships.Unfortunately, defining mapping variables chance-variable arguments alwayspossible. medical-treatment domain, patient always taker (states 1011 Table 3), t=yes regardless r. Consequently, tell whether c(t)helped always cured|that is, c(t) uniquely identified. Savage's decisiontheoretic framework requires state world act uniquely determineinstance c(t) (a consequence), instance c(t) well defined. Nonetheless, c(t)well defined whenever includes atomic intervention (t^), guaranteeingtake instances (as t^ varies) every state world.general, following definition mapping variable.Definition 5 (Mapping Variable) Given domain described U D, chance variables X , variables that, every 2 \ U , exists atomic interventiony^ 2 D,10 mapping variable X (Y ) chance variable represents possiblemappings X .several important points made mapping variablesdefined them. First, specific case, X always deterministic functionX (Y ).Second, additional probability assessments typically required introducingmapping variable probabilistic model. example, two independent assessmentsneeded quantify relationship r medical-treatment story;whereas three independent assessments required node t(r). general, manyadditional assessments required. X c instances instances,X (Y ) many ca instances. real-world domains, however, reasonable assertionsindependence decrease number required assessments. cases, additionalassessments necessary (see, e.g., Heckerman et al., 1994).Third, following theorem, follows immediately definitionslimited unresponsiveness mapping variable. subsequent theoremsmention mapping variables, assume atomic interventions required properdefinition mapping variables included D.Theorem 3 (Mapping Variable) Given decision problem described U D, variables X U , U [ D, X 6 -Y X (Y ) 6 - D.example, medical treatment domain includes atomic intervention t^,c 6 -t fr; ^tg c(t) 6 - fr; ^tg. Roughly speaking, Theorem 3 says Xunresponsive states limited way X dependsdepend D. equivalence provides us alternative set conditions cause.10. Recall Section 5 always possible atomic interventions every 2 .421fiHeckerman & ShachterCorollary 4 (Causes Respect Decisions) Given decision problem describedU D, chance variable x 2 U , variables C [ U n fxg causes xrespect C minimal set variables x(C ) 6 - D.C causes x respect D, call x(C ) causal mapping variablerespect D. Thus, following consequence Theorem 3.Corollary 5 (Causal Mapping Variable) x(C ) causal mapping variable xrespect D, x(C ) unresponsive D.7. Canonical Form uence Diagramsdefine means uence diagram canonical form.Definition 6 (Canonical Form) uence diagram decision problem describedU said canonical form (1) chance nodes responsivedescendants one decision nodes (2) chance nodes descendantsone decision nodes deterministic nodes.immediate consequence definition chance node descendantdecision node must unresponsive D.construct uence diagram canonical form given problem includinguence diagram causal mapping variable every variable responsivedecisions. so, make every responsive variable deterministic functionmapping variable corresponding set causes. example, consider medicaltreatment story depicted uence diagram Figure 3a. variables cresponsive r, corresponding nodes deterministic. Consequently,uence diagram canonical form. construct canonical form uence diagram,introduce mapping variables t(r) c(r), shown Figure 3b. responsivevariables deterministic; mapping variables unresponsive decision.example illustrates important point: Mapping variables may probabilisticallydependent. return issue Section 8.general, construct uence diagram canonical form decisionproblem characterized U follows.Algorithm 1 (Canonical Form)1. Add node diagram corresponding variable U [2. Order variables x1; : : :; xn U variables unresponsive come first422fiDecision-Theoretic Foundations Causal Reasoningrrcct(r)c(r)(a)(b)Figure 3: (a) uence diagram medical-treatment story. (b) correspondinguence diagram canonical form.3. variable xi 2 U responsive D,(a) Add causal-mapping-variable chance node xi (Ci) diagram,Ci [ fx1; : : :; xi,1g(b) Make xi deterministic node parents Ci xi (Ci )4. Assess independencies among variables unresponsive D11algorithm well defined, always possible find set Ci satisfyingcondition step 3a. particular, xi 6 -D Property 3. Consequently, evencontains atomic intervention, always create causal mapping variable everyresponsive variable U .Also, structure uence diagram constructed using Algorithm 1 valid.Namely, Corollary 5, causal mapping variables added step 3 unresponsiveD. Thus, suppose identify relevance arcs deterministic nodes accordingEquation 3 using variable ordering nodes followedunresponsive nodes (including causal mapping variables), turn followedresponsive nodes order specified step 2. Then, (1) would add arcsunresponsive nodes Theorem 1 (and algorithm adds none); (2) wouldadd arcs among unresponsive nodes described step 4; (3) every responsivevariable xi , would make xi deterministic node (as described step 3b) definitionmapping variable.addition, structure results Algorithm 1 canonical form.particular, arcs unresponsive nodes, responsivevariables descendants D. Also, Theorem 2, know every responsivenode descendant D, (by construction) deterministic node.11. mapping variables random variables, assessment dependencies among unresponsivevariables is, principle, different assessing dependencies among ordinary randomvariables. Nonetheless, counterfactual nature variables confusing. Howard (1990)describes method probability assessment addresses concern.423fiHeckerman & Shachterrrt(r, )ggc(t)cc(a)(b)Figure 4: (a) Another uence diagram medical-treatment story. (b) corresponding uence diagram canonical form.Furthermore, construction, every responsive variable xi 2 U one set causesexplicitly encoded diagram (Ci).illustrate algorithm, consider medical-treatment story depicteduence diagram Figure 4a, variable g (genotype?) represented explicitly,c 6 -t fr; ^tg g 6 - fr; ^tg. construct uence diagram canonicalform problem, first add variables fr; ^t; g; t; cg diagram chooseordering (g; t; c). c responsive = fr; ^tg, causes fr; ^tgt, respectively. Consequently, add causal mapping variables t(r; ^t) c(t)new diagram, make deterministic function r, t^, t(r; ^t) c deterministicfunction c(t). Finally, assess dependencies among unresponsive variablesfg; t(r; ^t); c(t)g, adding arcs g t(r; ^t) c(t) assumption causalmapping variables conditionally independent given g . resulting canonical formuence diagram shown Figure 4b.Canonical form generalization Howard Canonical Form, developedHoward (1990) facilitate computation value information.12 makingimportant decisions, decision analysts investigate useful gather additional information. investigation typically done computing extra value decisionmaker would obtain observing earlier one chance variables domain.decision maker expect observe chance variable x prior making decision d,value information x extra value would obtain able observechance variable x making decision d. value information never negative,serves bound value experiment: would never worthwhilespend value information x obtain (possibly imperfect)observation x making decision d.Given ordinary uence diagram, compute value informationvariables responsive D, variables observed decisionsmade. contrast, always compute value information mapping12. uence diagrams HCF allow mapping variables whose arguments contain chance variables.424fiDecision-Theoretic Foundations Causal Reasoningvariables corresponding responsive variables canonical form uence diagram, variables unresponsive definition. example, consider decisioncontinue quit smoking described decision variable (smoke) chance variablesl (lung cancer?) l(s). Although cannot compute value information lresponsive D, compute value information l(s).first glance, may seem pointless determine value informationvariable cannot observed (such l(s)). Nonetheless, often learn somethingmapping variable. example, imagine test measures susceptibilitysomeone's lung tissue lung cancer presence tobacco smoke. Learning resulttest may well update probability distribution l(s). computingvalue information l(s), obtain upper bound would willingpay undergo test.8. Pearl's Causal Frameworkdemonstrate relationship Pearl's causal framework ours.mentioned, Pearl's framework similar SGS (see background notes SGSdiscussion). Thus, many remarks section apply SGS's model causewell. notable exception SGS formally define direct intervention.following theorem outlines relationship.Theorem 6 Given chance variables U , suppose set decision variables containsunique atomic intervention x^ every x 2 U decisions. Given graph G,directed acyclic graph nodes corresponding variables U , suppose that,x 2 U , PaG (x) [ fx^g causes x respect D.13 Then, relationships amongvariables U [ expressed set simultaneous equationsx = fx (PaG (x); x^; x(PaG (x); x^))x 2 U , fx deterministic function x = x x^ =set(x).Proof: theorem follows applying Algorithm 1 using ordering U consistentgraph G. 2Thus, see Pearl's structural-equation model specialization canonical formidentify (1) Pearl's domain variables chance variables U , (2) Pearl's atomicinterventions atomic interventions D, (3) Pearl's causal graph graph G,(4) Pearl's random disturbance x causal mapping variable x(PaG (x); x^).correspondence permits several clarifications Pearl's framework. First,precise definition atomic intervention. Unlike Pearl's model, concept atomicintervention primitive, framework provides way verify interventionsindeed atomic.Second, see means random disturbances exogenous. Namely,random variables unresponsive decisions D.13. dicult show condition consistent condition that, x 2 U , x^atomic intervention x.425fiHeckerman & ShachterThird, precise definition random disturbance terms causal mappingvariable. Consequently, means assessing joint probability distributionvariables, and|in particular|a means assessing independencies among variables. fact, whereas Pearl requires random disturbances marginally independent,definition imposes requirement.Theorem 6 shows structural-equation model encoded uencediagram canonical form. converse also true|that is, uence diagramcanonical form encoded structural-equation model. result may seem surprising, Pearl's model every domain variable must atomic intervention,decision variables must atomic interventions, random disturbances must independent. Given uence diagram canonical form, however, encode chancedecision variables structural equation model. Specifically, chance variable xencoded variable pair fx; x^g x^ instantiated idle, decision variableencoded variable pair fd; d^g act idle forbidden. addition,noted Pearl, remove dependencies among mapping variables (at least practice)introducing hidden common causes.14Nonetheless, hidden common causes sometimes need introduced, Pearl'sstructural-equation model less ecient representation canonical form.example, represent relationships Figure 4b, would use structual-equationmodel disturbance variables corresponding g (^g), t(r; g; ^t), c(t; g; ^c). Assumingr; g; c binary variables, disturbance variables 2, 16, 16 instances,respectively.15 Assuming disturbance variables independent, joint probabilitydistribution variables contain 31 probabilities. contrast, mapping variablesFigure 4b four instances. Consequently, joint probability distributionunresponsive variables canonical-form representation contain 13 probabilities.note Balke Pearl (1994) relax assumption mapping variablesindependent. Nonetheless, generalization structural-equation model,call functional model, still less ecient canonical form. ineciencycomes fact canonical form encodes joint probability distribution amongunresponsive variables (possibly including domain mapping variables), whereasfunctional model encodes joint probability distribution among mapping variables only.example, canonical-form uence diagram Figure 4b encodes assertiont(r; ^t) c(t) independent given g. assertion encoded BalkePearl representation. represent relationships Figure 4b using functionalmodel, include variable g , case obtain 31-probability modeldescribed previous paragraph. Alternatively, exclude variable gmodel, encode dependency mapping variables t(r; ^t) c(t; c^)14. assumption mapping variables independent convenient consequencegraph G interpreted Bayesian network traditional sense. is, variables Xd-separated Z G, X conditionally independent given Z accordingstructural-equation model corresponding G. (See Pearl, 1988, definition d-separation.) SGS(p. 54) refer association causal Markov condition.15. Note mapping variable x(Y; x^) number instances mapping variablex(Y ).426fiDecision-Theoretic Foundations Causal Reasoningarc two variables. resulting Balke-Pearl model 15 probabilitiescontrast 13 required canonical form.9. Counterfactual Reasoningnoted, ordinary uence diagram adequate making decisionsuncertainty, inadequate counterfactual reasoning. section, examineform reasoning suggest facilitated uence diagrams canonicalform.Given domain described U X; Y; Z U , counterfactual reasoningaddresses questions form: choose = D1 observe X = X,probability = choose = D2 observe Z = Z? example,medical-treatment domain, may wish know: recommend treatmentpatient takes drug cured, probability patient curedrecommend treatment? reasoning often important realworld|for example, legal argument (Ginsberg, 1986; Balke Pearl, 1994; GoldszmidtDarwiche, 1994; Heckerman et al., 1994).answer queries using uence diagrams canonical form. illustrateapproach, consider medical-treatment question previous paragraph. answerquery, begin uence diagram canonical form shown Figure 4b.Then, duplicate decision variables chance variables responsivedecisions, shown Figure 5. original variables represent act r =take, t^=idleconsequences. duplicate variables (denoted primes) represent act r0 =don'ttake, t^=idle consequences. need duplicate unresponsive variables(including causal mapping variables) because, definition, affecteddecisions.16 Next, copy deterministic function associated originalvariable primed counterpart. Then, instantiate decision chance variablesdescribed query (r =take, t^=idle, =taken, c =cured, r0 =don't take,t^0 =idle). Finally, use standard Bayesian-network inference method computeprobability variable(s) interest (c0 example).canonical form uence diagram natural representation counterfactualreasoning two reasons. One, deterministic relationships responsive chancevariable parents remains choice D. Two, instances assumedunresponsive variables unaltered decisions. ordinary uence diagramoffers neither guarantees.approach, described Heckerman Shachter (1994), similar BalkePearl (1994). main difference two approaches Balke Pearluse functional model base representation, making approach less ecientours. Goldszmidt Darwiche (1994) describe graphical language modelingevolution real-world systems time. Although approach explicitlyaddress counterfactual reasoning, adapted do, yielding alternativeapproach.16. general, need duplicate (1) decision variables change query (2)chance variables responsive decisions change.427fiHeckerman & Shachtergrt(r)rc(t)ccFigure 5: use canonical form compute counterfactual query. Shaded variablesinstantiated.10. Conclusionspresented definition cause effect terms decision-theoretic primitives act, state world, consequence determined act state world,shown definition provides foundation causal reasoning. definition departs traditional view causation causal assertions maderelative set decisions. Consequently, argued, definition allowsprecise specification causal relationships.addition, shown definition provides basis graphical representation cause. described special class uence diagrams,canonical form, shown equally expressive ecient Pearl'sstructural-equation model. Finally, shown uence diagrams canonicalform, unlike ordinary uence diagrams, used counterfactual reasoning.Acknowledgmentsthank Jack Breese, Tom Chavez, Max Chickering, Eric Horvitz, Ron Howard, Christopher Meek, Judea Pearl, Mark Peot, Glenn Shafer, Peter Spirtes, Patrick Suppes,anonymous reviewers useful comments.ReferencesAngrist, J., Imbens, G., & Rubin, D. (1995). Identification causal effects using instrumental variables. Journal American Statistical Association, press.Balke, A., & Pearl, J. (1994). Probabilistic evaluation counterfactual queries. Proceedings Tenth Conference Uncertainty Artificial Intelligence, Seattle, WA,pp. 46{54. Morgan Kaufmann.428fiDecision-Theoretic Foundations Causal Reasoningde Finetti, B. (1937). La prevision: See lois logiques, ses sources subjectives. Annales del'Institut Henri Poincare, 7, 1{68. Translated Kyburg Smokler, 1964.Ginsberg, M. (1986). Counterfactuals. Artificial Intelligence, 30, 35{79.Goldszmidt, M., & Darwiche, A. (1994). Action networks: framework reasoningactions change uncertainty. Proceedings Tenth ConferenceUncertainty Artificial Intelligence, Seattle, WA, pp. 136{144. Morgan Kaufmann.Heckerman, D. (1995). Bayesian approach learning causal networks. ProceedingsEleventh Conference Uncertainty Artificial Intelligence, Montreal, QU, pp.285{295. Morgan Kaufmann.Heckerman, D., Breese, J., & Rommelse, K. (1994). Sequential troubleshooting uncertainty. Proceedings Fifth International Workshop Principles Diagnosis,New Paltz, NY, pp. 121{130.Heckerman, D., & Shachter, R. (1994). decision-based view causality. ProceedingsTenth Conference Uncertainty Artificial Intelligence, Seattle, WA, pp. 302{310.Morgan Kaufmann.Holland, P. (1986). Statistics causal inference. Journal American StatisticalAssociation, 81, 945{968.Howard, R. (1990). uence relevance knowledge. Oliver, R., & Smith, J.(Eds.), uence Diagrams, Belief Nets, Decision Analysis, chap. 1. WileySons, New York.Howard, R., & Matheson, J. (1981). uence diagrams. Howard, R., & Matheson, J.(Eds.), Readings Principles Applications Decision Analysis, Vol. II, pp.721{762. Strategic Decisions Group, Menlo Park, CA.Lewis, D. (1973). Counterfactuals. Harvard University Press, Cambridge, MA.Neyman, J. (1923). application probability theory agricultural experiments.Translated Statistical Science, 5:465-480 (1990).Pearl, J. (1988). Probabilistic Reasoning Intelligent Systems: Networks PlausibleInference. Morgan Kaufmann, San Mateo, CA.Pearl, J. (1993). Comment: Graphical models, causality, intervention. StatisticalScience, 8, 266{269.Pearl, J. (1995). Causal diagrams empirical research. Biometrika, press.Pearl, J., & Verma, T. (1991). theory inferred causation. Allen, J., Fikes, R., &Sandewall, E. (Eds.), Knowledge Representation Reasoning: ProceedingsSecond International Conference, pp. 441{452. Morgan Kaufmann, New York.Robins, J. (1986). new approach causal interence mortality studies sustainedexposure results. Mathematical Modelling, 7, 1393{1512.429fiHeckerman & ShachterRubin, D. (1978). Bayesian inference causal effects: role randomization. AnnalsStatistics, 6, 34{58.Simon, H. (1977). Modles Discovery Topics Methods Science. D.Reidel, Dordrecht, Holland.Spirtes, P., Glymour, C., & Scheines, R. (1993). Causation, Prediction, Search.Springer-Verlag, New York.430fiJournal Artificial Intelligence Research 3 (1995) 147-185Submitted 8/94; published 8/95Integrated Framework Learning ReasoningChristophe G. Giraud-CarrierDepartment Computer Science, University BristolBristol, BS8 1TR U.K.cgc@compsci.bristol.ac.ukTony R. MartinezDepartment Computer Science, Brigham Young UniversityProvo, UT 84602 U.S.A.martinez@cs.byu.eduAbstractLearning reasoning aspects considered intelligence.studies within AI separated historically, learning topic machinelearning neural networks, reasoning falling classical (or symbolic) AI. However, learning reasoning many ways interdependent. paper discussesnature interdependencies proposes general framework called FLARE,combines inductive learning using prior knowledge together reasoning propositional setting. Several examples test framework presented, including classicalinduction, many important reasoning protocols two simple expert systems.1. IntroductionInduction deduction underlying processes intelligent agents. Induction \involves intellectual leaps particular general" (D'Ignazio & Wold, 1984).plays important part knowledge acquisition learning. D'Ignazio Wold (1984)claim indeed, \All laws nature discovered inductive reasoning." Deduction form reasoning acquired knowledge. typically resultgeneration new facts, rather establishes cause-effect relationships existing facts. Deduction may applied forward seeking consequences certain existinghypotheses backward discover necessary conditions achievement certaingoals. Despite differences, induction deduction strongly interrelated.ability reason domain knowledge often based rules domain,must acquired somehow; ability reason often guide acquisitionnew knowledge learning.Inductive learning subject much research leading designvariety algorithms (e.g., Clark & Niblett, 1989; Michalski, 1983; Quinlan, 1986; Salzberg,1991). general, inductive learning systems generate classification rules examples.Typically, system first presented set examples (objects, situations, etc.), alsoknown training set. Examples usually expressed attribute-value languagerepresent recorded instances attribute-value pairs together correspondingclassification. system's goal discover sets sucient critical features rulesproperly classify examples training set (convergence) adequately extendpreviously unseen examples (generalization).Though machines still far cry matching human qualitative inductive leaps,inductive learning systems proven useful wide range applications medicinec 1995 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiGiraud-Carrier & Martinez(breast cancer, hepatitis detection), banking (credit screening), defense (mine-rock discrimination), botany (iris variety identification, venomous mushroom detection) others(Murphy & Aha, 1992).study deductive reasoning goes least far back early Greek philosophers, Socrates Aristotle. formalization given rise variety logics,propositional first-order predicate logic default logic several non-monotonicextensions. Many logics successfully implemented artificial systems(e.g., PROLOG, expert systems). typically consist pre-encoded knowledge rulebase, given set facts (identified either causes consequences) inferenceengine. inference engine carries deductive process using rules rulebase facts provided. Several systems successfully usedvarious domains, medical diagnosis (Clancey & Shortliffe, 1984) geology (Duda& Reboh, 1984).One greatest challenges current deductive systems knowledge acquisition,is, construction rule base. Typically, rule base generated domainknowledge extracted human experts carefully engineered rules. Knowledgeacquisition tedious task presents many diculties practically theoretically.suciently rich training set obtained, inductive learning may usedeffectively complement traditional approach knowledge acquisition. Indeed,system's knowledge base constructed rules encoded priori rulesgenerated inductively examples. words, rules examples needmutually exclusive. strong knowledge principle (Waterman, 1986) early workbias (Mitchell, 1980) suggest need prior knowledge. Rules supplied priori onesimple form prior knowledge used successfully several inductive systems(e.g., Giraud-Carrier & Martinez, 1993; Ourston & Mooney, 1990). Similarly, proposalsmade enhance deductive systems learning capabilities (e.g., Haas &Hendrix, 1983; Rychener, 1983).authors' contention study interdependencies learning reasoning subsequent integration induction deduction unifiedframeworks may lead development powerful models. paper describessystem, called FLARE (Framework Learning REasoning), attempts combineinductive learning using prior knowledge together reasoning. Induction deductionFLARE carried within confines non-recursive, propositional logic. Learning effected incrementally system continually adapts new information. Priorknowledge given teacher form rules. Within context particularinductive task, rules may serve produce useful learning biases. Simple defaultscombined learning capabilities enable FLARE exhibit reasoning normallyconsidered non-monotonic.paper organized follows. Section 2 presents FLARE argues validityunified framework. FLARE's representation language described algorithmsemployed learning reasoning detailed. Section 3 reports experimental resultsclassical datasets, number \well-designed" reasoning protocols severalapplications, including two simple expert systems. limitations systemalso described. Section 4 discusses related work induction deduction. Finally,section 5 concludes paper summarizing results discussing research.148fiAn Integrated Framework Learning Reasoning2. FLARE - Framework Learning Reasoningsection, FLARE's learning reasoning mechanisms detailed. descriptiondiscussion FLARE's representation language given first Section 2.1, alonguseful definitions simple, practical example serve runningexample throughout paper. Sections 2.2 2.5 follow top-down approachdescription FLARE.2.1 FLARE's Representation LanguageFLARE's representation language instance attribute-value language (AVL).FLARE, attributes may range nominal domains bounded linear domains, includingclosed intervals continuous numeric values. basic elements knowledge AVLvectors defined cross-product domains attributes. componentsvector specify value attribute. following simple extension made AVL.attribute domain A, takes values [ f?; ?g.special symbols ? ? stand don't-care don't-know, respectively.semantics associated ? ? different. attribute whose value ?one known (or assumed) irrelevant current context, attributewhose value ? may relevant actual value currently unknown. ? symbolallows encoding rules, ? symbol accounts missing attribute valuesreal-world observations.2.1.1 First-Order Attribute-Value TranslationSince learning reasoning tasks often expressed English simple, direct counterparts classical first-order logic language (FOL), necessary FLAREtranslate FOL clauses AVL equivalent. AVL clearly expressive FOL,FLARE inherent limitations. purposes discussion, let predicates form p(x) p(x; C ) C constant called avl-predicates. Then,FOL clauses translated AVL two kinds:ground facts: p(C ) :p(C ) C constant (e.g., block(A)).2. simple implications: (8x)P (x) ) q (x) P (x) conjunction avl-predicates1.q (x) is, without loss generality, single, possibly negated avl-predicate (e.g.,block(x) ^ weight(x; heavy ) ) :on table(x)).clauses involve one universally quantified variable thus essentially nonrecursive, propositional clauses. Despite restricted language, FLARE effectively handlessignificant range applications. Moreover, AVL accounts simple, ecient matchingmechanisms lends naturally many inductive learning problems witnesseduse many successful learning systems (Clark & Niblett, 1989; Michalski, 1983;Quinlan, 1986).FOL statements aforementioned forms translated straightforward wayequivalent symbolic-valued AVL representation, shown Figure 1. similartransformation proposed context ILP (Dzeroski, Muggleton, & Russell,1993). Like FLARE, ILP systems, LINUS (Lavrac, Dzeroski, & Grobelnik,149fiGiraud-Carrier & Martinez1. Attribute definition: avl-predicate, create matching Boolean (for p(x)) multi-valued(for p(x; C )) attribute. ground facts, create multi-valued attribute, called label, whosevalues constants.2. Vector definition: implication, create matching vector attributes correspondingpremise conclusion appropriate value attributes set ?.ground fact, create matching vector value label constantattribute corresponding predicate appropriate value. Tag attribute correspondingconclusion.Figure 1: FOL AVL TransformationFOLAVLRep (b) Qua (b) Pac (b)Republican(x)) :Pacifist(x)1?0TQuaker(x))Pacifist(x)?11TTable 1: Nixon Diamond (Reiter & Griscuolo, 1981)1991), first map ILP problems propositional learning problems rely attributebased learning.creation attribute label step 2 stems fact ground facts formp(C ) rewritten simple implications form label(x; C ) ) p(x). Noticeattributes whose values ? vector correspond exactly predicatesappear premise corresponding FOL clause. attribute correspondingq (x) different usages. functions conclusion forward chainingtarget classification inductive learning. cases, also used goal.avoid unnecessary confusion, attribute corresponding q (x) simply referredtarget-attribute. values target-attribute subsequently taggedsubscript . translation FOL AVL currently performed manually.clear number predicates increases, size vectors. Sincevectors size many may values set relativelysmall number attributes, may result large memory requirements, wellincrease execution time operations vectors. predicatesqualify different values concept (e.g., red(x), yellow(x), color), possiblelimit size vectors translating predicates single multi-valuedattribute (e.g., color(x; V ), V constant: red, yellow, etc.). particularlyuseful conclusion part q (x) corresponds classification x.Tables 1 4 contain four simple examples demonstrate transformation.derived attribute AVL column followed type (b Boolean,multi-valued). Table 1 shows Nixon Diamond, classical example con icting defaults. Informally, Nixon Diamond states Republicans typically pacifistQuakers typically pacifist. con ict arises one asserts NixonRepublican Quaker. Table 2 contains assertions animals abilityy. states animals normally y, birds typically ying animals penguins birds y. Table 3 shows statements regarding eyes fitnesslenses. Finally, Table 4 contains facts simple blocks world.150fiAn Integrated Framework Learning ReasoningFOLAVLAni (b) Bir (b) Pen (b) Fly (b)Animal(x)) :Fly(x)1??0TBird(x))Animal(x)1T1??Bird(x))Fly(x)?1?1TPenguin(x))Bird(x)?1T1?Penguin(x)) :Fly(x)??10TTable 2: Flying Flying (Lifschitz, 1988)FOLAVLTpr (m) Eye (m) Fit (b)Tear-prod-rate(x,low))Eyes(x,dry)lowdryT?Eyes(x,dry)) :Fit(x)?dry0TTable 3: Fitting Lenses2.1.2 Examples vs. Precepts vs. RulesInformally, problem supervised learning may described follows. Given (1) setcategories, (2) category, set instances \objects" category (3)optional prior knowledge, produce set rules sucient place objects correctcategory. AVL, instances consist sets attribute-value pairs vectors, describingcharacteristics objects represent, together object's category.context, category target-attribute.example vector attributes set either ? one possiblevalues. rule vector attributes become ? resultgeneralization inductive learning. precept similar rule but, unlike rule,induced examples. Precepts either given teacher deducedgeneral knowledge relevant domain study. context given ruleprecept, ? attributes effect value category. Precepts rulesthus represent several examples. instance, let p = (?; 1; 0; 0T ) precept,attributes range set f0,1,2g. p represents three examples: (0; 1; 0; 0T ),(1; 1; 0; 0T ) (2; 1; 0; 0T ).distinction rules precepts limited learning. reasoning,vectors (including examples generalize) rules. FLARE, rules formeddropping conditions (Michalski, 1983), is, certain circumstances (see Section2.4.2), one attribute set ?. Precepts, hand, rules encoded priori.ect high-level knowledge (or common sense) real-world. precept\suggests something advisory obligatory communicated typically teaching"(Webster's Dictionary).2.1.3 Running Exampleillustrate definitions algorithms following sections, final exampletransformation constructed, based mediadv knowledge base (Harmon &King, 1985). purposely simple example serve running example throughout151fiGiraud-Carrier & MartinezFOLAVLLab (m) Blk (b) Hvy (b) OnT (b)block(A)1T??block(B)B1T??heavy(A)?1T?heavy(B)B?1T?block(x) ^ heavy(x) ) table(x)?111T:on table(A)??0TTable 4: Simple Blocks World, adapted (Lifschitz, 1988)paper. discussion complete mediadv knowledge base Section 3.5. Here,two conditions (i.e., instructional feedback presentation modification) leftoriginal rules used. Table 5 contains informal English versionknowledge used (with reference rules mediadv generatedapplicable) corresponding translation AVL vectors.Let KB resulting set vectors. attributes given order: situation,stimulus-situation, response, appropriate-response, stimulus-duration, training-budgetmedia. Note attributes nominal. symbolic values used English statements transformed equivalent nominal values vectors. Hence,example, first statement gives rise vector attribute situation set0 (the corresponding nominal value schematics attribute), targetattribute stimulus-situation set 0 (the corresponding nominal value symbolicattribute).top goal system suggest effective media training, basedfour conditions: situation, response, stimulus-duration, training-budget. Noteattributes stimulus-situation appropriate-response used subgoals reachingfinal conclusion. Vectors v13 v17 examples since conditions setvalues. part original mediadv knowledge base added exerciseimportant features algorithms. KB given, vectors KB conditionattributes set ? precepts rather rules. instance, v7 v12 precepts.Then, term rule applies new generalizations, induced FLARE KB .instance, v80 (see Section 2.4.3) rule.2.2 Algorithmic OverviewFLARE self-adaptive, incremental system. uses domain knowledge empiricalevidence construct maintain knowledge base. FLARE's knowledge base interpreted \best far" set rules coping current application.sense, FLARE follows scientific approach theory formation/revision: available priorknowledge experience produce \theory" updated refined continually newevidence.FLARE involves three main functions whose definitions high-level algorithmic interactions given Figure 2. details function's implementation givenfollowing sections. intuitive overview presented here.152fiAn Integrated Framework Learning ReasoningEnglish Statementssituation = schematics(Rule3)stimulus-situation = symbolicsituation = conversation(Rule4)stimulus-situation = verbalsituation = photograph(Rule2)stimulus-situation = pictorialresponse = observing(Rule5)response = thinkingappropriate-response = covertresponse = emoting(Rule10)appropriate-response = affectivestimulus-situation = verbal (Rule13)appropriate-response = covertstimulus-duration = briefmedia = lecturestimulus-situation = verbal (Rule14)stimulus-situation = symbolicstimulus-situation = pictorialappropriate-response = covertstimulus duration = brieftraining-budget = mediummedia = lecture-with-slidesstimulus-situation = verbal (Rule16)stimulus-duration = briefmedia = role-play-w/verbal-feedbackstimulus-situation = verbal (Rule17)appropriate-response = affectivemedia = role-play-w/video-feedbacksituation = conversationresponse = observingresponse = thinkingstimulus-duration = brieftraining budget = mediummedia = lecturesituation = photographresponse = emotingstimulus-duration = persistenttraining-budget = smallmedia = role-play-w/verbal-feedbacksituation = photographresponse = emotingstimulus-duration = persistenttraining-budget = smallmedia = lecturesituation = photographresponse = emotingstimulus-duration = persistenttraining-budget = smallmedia = role-play-w/verbal-feedbackv1Equivalent AVL Vectors= 0 0T ? ? ? ? ?v2= 1 1T ? ?? ? ?v3= 2 2T ? ?? ? ?v4v5= ? ?= ? ?0 0T ? ? ?1 0T ? ? ?v6= ? ?2 1T ? ? ?v7= ? 1? 00 ? 2Tv8 = ? 1v9 = ? 0v10 = ? 2? 0? 0? 00 1 3T0 1 3T0 1 3Tv11 = ? 1pty = 1? ?0 ? 0Tv12 = ? 1pty = 3? 1? ? 1Tv13 = 1 ?v14 = 1 ?0 ?1 ?0 1 2T0 1 2Tv15 = 2 ?2 ?1 0 0Tv16 = 2 ?2 ?1 0 2Tv17 = 2 ?2 ?1 0 0TTable 5: Simple KB Running Example153fiGiraud-Carrier & MartinezDEFINITIONFunction: Generate-Precepts{ Input: set general rules, set facts one designated target-attribute.{ Output: one precepts.Function: Reasoning{ Input: current knowledge base, set facts encoded vector v, one designated target-attribute optionally, target value target-attribute.{ Output: vector v+ equal v together facts deduced v, including derivedvalue target-attribute.Function: Adapting{ Input: current knowledge base, vector v+ output function Reasoning targetvalue target-attribute.{ Output: updated knowledge base.IMPLEMENTATION1. Preprocessing: Perform Generate-Precepts2. Main loop: vector presented system(a) Perform Reasoning(b) target value target-attribute, perform AdaptingFigure 2: FLARE - Algorithmic OverviewConceptually, FLARE's execution consists two phases. preprocessing phase,FLARE uses prior knowledge form general rules may viewed encoding\commonsense" knowledge. Using deduction given facts, domain-specific preceptsgenerated instantiation general knowledge domain hand. Section 2.5details Generate-Precepts function. need generating explicitly encodingprecepts individual vectors preprocessing phase arises FLARE's inductive mechanisms take place vector level. Thus, even though always possiblededuce general knowledge, precepts useful inductionmade explicit.normal processing, FLARE executes an, least conceptually, infinite loop. Steps (a)(b) executed every time new information (in form AVL vectors) presentedsystem. step (a), FLARE reasons \facts" provided input vectorrules found current knowledge base. Rule-based reasoning similaritybased reasoning combined discussed Section 2.3 derive value targetattribute, well attributes along forward chain conclusion. step(b), FLARE adapts current knowledge base. FLARE supervised learner,adapt target value target-attribute explicitly given partinformation presented. combination steps (a) (b) referred learning.Section 2.4 details Adapting function.154fiAn Integrated Framework Learning ReasoningNote reasoning based upon available knowledge prior adapting plausible.Even available information insucient and/or incomplete, humans often attemptmake tentative decision get corrected necessary. one time, decisionmade represents kind \best guess" given currently available information.(correct) information becomes available, accurate decisions become.2.3 FLARE's ReasoningFLARE implements simple form rule-based reasoning combined similarity-basedreasoning, similar CONSYDERR (Sun, 1992). Sun argued combinationeffectively decreases system's susceptibility brittleness (Sun, 1992). particular,absence applicable rules information incomplete, FLARE relies similarity previously encountered situations make useful predictions. Others alsoargued analogy necessary condition commonsense reasoning subsequentovercoming brittleness (Minsky & Riecken, 1994; Wollowski, 1994). Section 2.3.1 showsnotion Clark's completion (1978) applied inductively learned rulesexploited similarity-based reasoning generate new rules. Sections 2.3.2 2.3.7describe illustrate FLARE's reasoning mechanisms.2.3.1 CompletionInductively learned rules form (8x)P (x) ) q (x), P conjunction avlpredicates, essentially classification rules definitions establish relationships features, captured P (x), concepts, expressed q (x). keepingclassical assumption known learning system false default, inductively generated rules lend naturally completion principle proposedClark (1978). is, classification rules become \if if" statements, i.e.,P (x) , q(x). Hence, completion, q (x) known true, possibleconclude P (x) true.Clearly, completion apply rules. Inductively learned rules inherentlydefinitional essentially encode concept's description terms set features.rules, relating concepts relative cognitive level,definitional. example, given birds animals x animal,follow x bird. Note that, addition inductively learned rules,definitions may given FLARE prior knowledge.completion principle particularly useful interacts similarity-basedreasoning generate new rules, shown following derivation.Hypotheses:1.2.3.4.(8x)P(x) ) q(x), may completed.(8x)P (x) ) q (x).P \ P 6= ; (i.e., P P attributes common).q(x) true.0000Derivation:1. q(x) hypothesis 4.155fiGiraud-Carrier & Martinez2. P(x) completion applied hypothesis 1.3. q (x) similarity-based reasoning using hypotheses 2 3.0new implication concepts, namely q (x) ) q 0(x), thus generated. ThoughFLARE capable deriving q 0(x) q (x), actually store new implicationknowledge base.following example adapted (Collins & Michalski, 1989) illustrates usederivation. Assume system learned description Chaco areaterms set G geographical conditions (i.e., G(x) )area(x; theChaco)). Furthermore,assume system knows rule encodes set conditions C sucientraising cattle (i.e., C (x) )raise(x; cattle)) C C G share numberconditions. system told area interest Chaco, first deducescompletion conditions G met then, taking advantage similarityG C , system concludes cattle may raised Chaco. Notelevel confidence conclusion depends upon amount similarity.FLARE, representation extended definition indicator taggedstatements may completed (i.e., prior definitions, inductively learned classifications).Note that, though somewhat cumbersome, extension needed since FLAREphysically separate concepts features used describe them. CONSYDERRhand provides natural support dichotomy. FLARE's representationmakes learning readily applicable preserves consistency previously developedmodels. point, issue achieving dichotomy easy learning remainsopen.2.3.2 FLARE's Reasoning FunctionDeduction FLARE applied forward. Hence, facts must provided initiatereasoning. facts coded vector attributes whose values knownaccordingly set, attributes ? (i.e., don't-know). One attributedesignated target-attribute and, known, value also provided. FLAREuses rules knowledge base facts derive value target-attribute.Reasoning function shown Figure 3. Note discussion, currentknowledge base assumed non-empty. knowledge base empty, systemcannot deduce anything ?.Step (1) applies completion first. FLARE finds asserted (i.e., neither ? ?) attributes v target-attributes definitions current knowledge base.attribute found, them, completion applied \copying" vasserted attributes corresponding definitions ? v . following two issuesmust addressed FLARE implementing completion.1. Since attributes may involved definitions one targetattribute concept, follows may one values copiedgiven attribute completing definitions.2. Since FLARE's concepts rules consist sets vectors, vectorconjunction vectors sharing target-attribute form disjunction,follows definitions may disjunctive well.156fiAn Integrated Framework Learning ReasoningDEFINITIONInput: current knowledge base, set facts encoded vector v, one designated target-attributeoptionally, target value target-attribute.Output: vector v+ equal v together facts deduced v, including valuetarget-attribute.IMPLEMENTATION1. Completion: asserted attribute v target-attribute, targetattribute definition values equal, copy asserted attributes ?v, v.2. Forward chaining: v's target-attribute asserted(a) Repeat new attribute v assertedi. Let w = v.(* create temporary copy v *)ii. non-asserted attribute v target-attribute, ruleapplied v assert a, apply asserting w.(* based v, assert possible attributes (other target-attribute) w *)iii. Let v = w.(* copy result back v next level inference *)(b) rule applied assert v's target-attribute, apply it. Otherwise, performsimilarity-based assertion.Figure 3: Function Reasoningcurrent implementation resolves two issues follows. first case, potentialcon icts resolved simply giving precedence first copy made (which dependsupon order asserted attributes processed). second case, FLAREsimply chooses one defining conjunctions random applies completion it.mechanisms (e.g., apply all, select winner based criteria, etc.)topic research.Completion causes information (in form asserted attributes) gained,thus improving chance reaching goal. Indeed, purpose step (1) two-fold.First, completion allows system reach goals otherwise achievableexisting rules. Second, even top goal achieved directly completion,reasoning achieve enhanced described Section 2.3.1.target-attribute asserted completion, step (2) pursuesreasoning process using forward chaining. mentioned above, v single targetattribute, corresponding final goal achieve. However, given time,one (yet) non-asserted1 attributes v may designated subgoal may1. either ? ?. ? precepts rules differing premises conclusionsused. cases, clear reasoning whether true don't-cares don't-knows.157fiGiraud-Carrier & Martinezuseful (or necessary) reaching final conclusion. Step (2)(a) heartreasoning process. execution step (2)(a)(ii) corresponds achievementpossible subgoals given depth inference process. iteration uses knowledgeacquired previous iteration attempt derive new conclusions using existingrules. Step (2)(b) concludes reasoning phase asserting target-attribute.Notice target-attribute always asserted, either rule application similaritybased assertion. Hence, FLARE always reaches conclusion. worst case,information target-attribute current knowledge base, value derived conclusion must clearly ?. cases, validity accuracyderived conclusion depend upon available information. accuracy confidence levelmay computed variety ways information static priorities, dynamicpriorities, covers counters (see Section 2.4).two complementary mechanisms used asserting target-attribute (i.e., ruleapplication similarity-based assertion) described next two sections.apply sequentially. rule exists applied, applied. Otherwise,similarity-based reasoning takes effect.Finally, note information regarding way goal achieved could displayedFLARE purpose human examination inspection. Currently, FLAREnon-interactive, is, cannot query user values missing attributes mayhelp improve accuracy result.2.3.3 Rule ApplicationLet val(a; x) denote value attribute vector x. state knowledge represented vector v , rule may applied covers v . vector x said covervector if:1. x target-attribute2. remaining attributes x, either val(a; x) = ? val(a; x) = val(a; ).example, KB , v11 covers v7 v8 v11 cover v9 v12. Ignoring attributeswhose value ?, second condition states set remaining attribute-value pairsx proper subset set remaining attribute-value pairs . Intuitively, x coverssatisfies premises x.accommodate real-valued attributes, notion equality slightly extended.Given probability two real values equal extremely small, coverrelation, condition 2, would essentially never hold. following extension,borrowed ILA (Giraud-Carrier & Martinez, 1995), suggested. Two linear values x1x2 equal jx1 , x2 j , > 0. Hence, vector (?, 1.2, 3.52,?, 0T ) covers vector (2, 1.3, 3.48, ?, 0T ) = 0:5. current implementation,fraction range possible values attribute.2.3.4 Similarity-Based Assertionnotion similarity FLARE captured non-symmetric distance function defined(n-dimensional) vectors. vector x stored knowledge base vector158fiAn Integrated Framework Learning Reasoningpresented system reason about, distance x given by:Xn d(xi; yi)D(x; ) = numi=1asserted(x)where, x+i ; yi+ denote values attribute ? ?,d(?; yi)d(?; yi)d(x+i ; ?)d(x+i ; ?)d(x+i ; yi+)d(x+i ; yi+)======00:50:50:5(x+i 6= yi+ ) attribute nominaljx+i , yi+j attribute linearrange(i)range(i) range values attribute num asserted(x) numberattributes ? x. equations consistent semantics? ? defined Section 2.1.D(x; ) meaningful x target-attribute targetattribute left computation. example, D(v11; v8) = 0, D(v13; v14) = 1=4,D(v7; v16) = 2=3, D(v16; v7) = 5=8 D(v1; v4) undefined. detailed discussionjustification definition found elsewhere (Giraud-Carrier & Martinez,1994a). Since every ordered set one-to-one correspondence subset naturalnumbers, well defined. eliminate effects statistical outliers range(i),dataset must ridden vectors whose attributes irregular values.extension similarity function defined IBL (Aha, Kibler, & Albert, 1991),inductive learning algorithms use and/or create general rules. appliesnominal linear domains, relies corresponding notion distancevalues. particular, handles continuous values directly, without need discretization.Currently, treats attribute equally. Existing methods assigning weightsattribute-wise distance (Salzberg, 1991; Stanfill & Waltz, 1986; Wettschereck & Dietterich,1994) may incorporated D.Similarity-based assertion consists asserting target-attribute vector vvalue attribute v 's closest match given D. Note (since symmetric)x covers D(x; y) = 0. Hence, since 0 minimum distance function,used apply reasoning mechanisms correct order (i.e., rules first,similarity next), computing distance rules current knowledge basev simply selecting rule minimizes D. possible onerule minimizes D, priority scheme devised choose winner. con ict resolutionprocedure relies partially FLARE's ability learn outlined Section 2.3.5.2.3.5 Conflict ResolutionAlong vector, FLARE also stores following information:static priority value (static priority),159fiGiraud-Carrier & Martinezdynamic priority value (dynamic priority)number vectors covered (num covers).value static priority set 0 default may changed teachervalue priori (e.g., v11 v12 KB ). Static priorities provide means whereby rulesmay prioritized according externally provided information meta-knowledge.value dynamic priority initialized 0. value changed teacher,however, evolves time intended resolve con icting defaults extensionally.Con icting defaults, Nixon Diamond Table 1 may encoded prioriprecepts induced examples. either case, identified reasoningphase FLARE discovers two rules apply equally well input vector. Formally,two rules R con ict vector v following conditions hold.1.2.3.4.5.D(R; v ) = D(S; v) = 0R specificityR static priorityR different target-attribute's valueR overlap (i.e., sets possible vectors covers intersect)Two vectors said concordant target-attribute targetattribute's value vectors. reasoning vector v comingupon con icting defaults, FLARE simply increments 1 value dynamic prioritydefault concordant v . none defaults concordant v ,change made. value dynamic priority ects number times particulardefault supported evidence drawn environment. thus evidence,rather meta-knowledge, responsible emerging ordering defaultsdynamic priority. Note target value must given target-attributeupdate take place dynamic priority result combination learningreasoning. Notice also dynamic priority evolves time system'sresponse changes based accumulated evidence.value num covers also result combination learning reasoning.records number vectors seen system far concordantcovered vector. kind confidence level vector, essentiallycounts number times rule represented vector confirmed empiricalevidence.one rule minimizes (i.e., selected application), winnerchosen according following priority scheme, subsequent conditioninvoked tie exists previous level.1. specific2. Highest static priority3. Highest dynamic priority160fiAn Integrated Framework Learning Reasoning4. Greatest coverSpecificity defined number attributes, target-attribute, whosevalue ?. vector x specific vector specificity(x)> specificity(y ).example, KB , v7 specificity 3, v8 specificity 4 v13 specificity 4,v8 v13 specific v7 .Giving priority first specific vector allows FLARE handle exceptionscancellation inheritance. Using static priorities next makes possible handle con icting defaults defined teacher, dynamic priorities account epistemologicalinconsistencies may resolved time information becomes availablesupport one belief other. Finally, selecting vector greatest cover allowsevidence gathered experience guide final selection. Note current schemegives precedence teacher-provided information. ordering schemes easilydefined. example, static priorities could given simple form initial biasevidence gathered learning (e.g., dynamic priority cover) could usedconfirm modify priorities.2.3.6 IllustrationConsider KB assume vector v = (1; ?; 1; ?; 0; 0; ?T ) input reasoning function. Execution proceeds follows. Step (1) essentially skipped none attributesv meet looping condition. Then, two loops forward chaintarget-attribute set.Execution Trace(1) (a) Let w = v(b) (i) Designate second attribute first subgoal(ii) Apply rule v2 : result w = (1; 1; 1; ?; 0; 0; ?T )(i) Designate fourth attribute second subgoal(ii) Apply rule v5 : result w = (1; 1; 1; 0; 0; 0; ?T )(c) Let v = w(2) Two con icting rules exist: D(v7; v ) = D(v11; v ) = 0Apply v7 (more specific): result v = (1; 1; 1; 0; 0; 0; 2T )2.3.7 Approximate ReasoningNotice that, forward chaining, assertion attributes subgoalsinvolve similarity-based assertion results rule application only. result,accuracy final goal increased ability perform approximate reasoningreduced. possible relax restriction thus potentially achieving subgoalsreducing confidence final result. example, condition step (2)(a)(ii)could modified allow rules (which perfect matches, i.e., = 0) alsomatches deemed \close enough." measure closeness implemented viathreshold value TD , placed D. is, current condition replaced with:Let D0 = distance closest matchD0 = 0 perform rule applicationElse D0 TD perform similarity-based assertion161fiGiraud-Carrier & Martinezvalue TD offers simple mechanism increase level approximate reasoning. particularly useful cases Chaco example (Section 2.3.1), where,completion, reasoning based amount similarity concepts. Notice condition functionally equivalent current oneTD = 0.2.4 FLARE's Learningsection addresses construction FLARE's knowledge base incremental,supervised learning. FLARE learns continually adapting information receives.Indeed, training vectors assumed become available one time, time and,inherent nature, vectors may noisy others may encounteredonce. Moreover, FLARE extends inductive learning examples prior knowledgeform precepts. Sections 2.4.1 2.4.3 describe illustrate FLARE's learningmechanisms Section 2.4.4 highlights advantages combining extensionintension learning.2.4.1 FLARE's Adapting Functiontime, FLARE presented sequence examples precepts usedupdate current knowledge base. set examples, rules precepts sharetarget-attribute viewed partial function mapping instancesgoal-space. context, example maps single instance value goal-space,precepts rules hyperplanes map points correspondinginstances value goal-space.Learning follows form nearest-hyperplane learning. mentioned Section2.2, consists first applying reasoning scheme, making adjustmentscurrent knowledge base ect newly acquired information. reasonalgorithm said nearest-hyperplane reasoning phase essentially identifiesclosest match input vector. closest match either rule (i.e., true hyperplane)stored example (i.e., point degenerated hyperplane).prior application reasoning allows system predict value targetattribute based information current knowledge base. Also, missingattributes input vector knowledge base contains rules appliedassert attributes, rules applied many missing attributespossible asserted final goal predicted. Hence, accuracyprediction increased generalization potentially enhanced, thus enabling FLAREeffectively adapt knowledge base.system starts empty knowledge base. adapts new vector v ,v either precept example. v first vector, closestmatch v automatically stored current knowledge base. sense,first learned vector represents yet another bias learning system. v firstvector, reasoning takes place producing v + . closest match, say m, also foundknowledge base adapts based relationship v + m, shownFigure 4. Note closest given current available information can, indeed,\far" v + . Hence, order training takes place impacts outcome.162fiAn Integrated Framework Learning ReasoningDEFINITIONInput: current knowledge base, vector v+ output function Reasoning target valuetarget-attribute.Output: updated knowledge base.IMPLEMENTATION1. Let vector current knowledge base D(m;v+ ) smallest (i.e., v+ 'sclosest match current knowledge base).2. attributes equal values v+ m, add 1 m.counters[v+ .target-attribute'svalue](* identical prototype v+ , then: store v+ , update m's counters *)3. Else covers v+ v+ concordant, add 1 m.num covers(* subsumes generalization v+ , then: store v+ , increase m's confidence *)4. Else v+ covers v+ concordant, add 1 v+ .num covers, deleteknowledge base add v knowledge base(* v+ subsumes generalization m, then: replace v+ , increase v+ 's confidence *)5. Else v+ produce generalization,(* possibility generalization *)v+ specific one non ? attribute, drop conditionset m.static priority maxfm.static priority, v+ .static priorityg(* general v+ dropping condition possible, then: store v+ , dropcondition m, update static priority *)Else v+ one non ? attribute, drop condition v+ , set v.static prioritymaxfm.static priority, v+ .static priorityg, set v+ .num covers m.num covers, deleteknowledge base add v+ knowledge base(* v+ general dropping condition possible, then: drop condition v+ ,replace v+ , update parameters *)Else add v+ knowledge base(* dropping condition impossible, then: store v+ knowledge base *)6. Else add v+ knowledge base(* default case: store v+ knowledge base *)Figure 4: Function Adaptingarray counters contains entry possible value target-attributealso stored vector. counters initialized 0, except onecorresponding vector's target-attribute value initialized 1. countersevolve time used handle noise. vector p current knowledgebase, exactly one counter value incremented (by 1) time new vector presented,163fiGiraud-Carrier & Martinezwhose attributes' values equal p. value incremented correspondsnew vector's target-attribute value. counter value highest representsstatistically \most probable" target-attribute value. effect, target-attribute valuevector always one highest count. Note value may change time,new information becomes available.best match first identified, changes knowledge base localizedguided kinds possible relationships v + m. relationshipssummarized below.v+ equal (i.e., noise duplicates)v+ subsumed (i.e., v+ special case m)v+ subsumes (i.e., v+ general case m)v+ produce generalizationcases (e.g., v+ exception m, v+ far apart, etc.)first case, v + (or prototype m) already knowledge basecounters need updated. Note extension notion equality discussedSection 2.3.3 enables part algorithm, conjunction counters, producegeneralization linear attributes. effect, vector retained knowledge baseacts \prototype," target-attribute's value one probable among-close neighbors. second case, need store v + current knowledgebase sucient information correctly predict v + 's target value. third case, v +stored removed v + general thus accounts it. fourthcase captures possibility generalization dropping conditions (see Section 2.4.2details). generalization takes place, one v+ generalized stored.values static priority num covers also reset generalization inheritsmaximum static priority value current value num covers. Finally, fifthcase, v + must added current knowledge base either produce correcttarget value v + (e.g., exceptions) deemed reliable enough properly accountv + .Notice adaptation phase takes place regardless target value predictedreasoning phase. possible alternative would adapt predictedtarget value differs actual target value. found empirically, however,much useful information lost approach due incrementalitysystem sensitivity ordering. possibly viable alternative would make usememory. Vectors currently accounted could saved memory presented latersystem. may done times period learning time eithervectors must stored knowledge base (due changes knowledge base)discarded system gained enough confidence ability accountthem.2.4.2 GeneralizationTwo vectors target-attribute's value produce generalizationfollowing five conditions hold.164fiAn Integrated Framework Learning Reasoning1. differ value exactly one attributes.2. attribute differ nominal.3. concordant.4. number attributes equal ? differ 1.5. least one one non ? attribute.Generalization consists setting ? attribute two vectors differ,vector general, long vector one non ? attribute.example, vectors v8 v9 KB satisfy conditions would generalizeproduce vector, say v8+9 = (?; ?; ?; 0; 0; 1; 3T ). value 1 fourth conditionbased upon empirical evidence.Choosing general vector maximizes generalization conditionnumber non ? attributes guarantees rule generated would cover everyvector. version dropping-the-condition rule (Michalski, 1983) appliednominal attributes makes little sense linear (especially real-valued) domains.linear attributes, generalization achieved artifact due extended notionequality discussed above.Let v w two vectors representing n n examples, respectively. Furthermore, let v 0 generalization obtained v w dropping p-valued attributev . v 0 represents pn examples. Since v w represent 2n examples, generalization causes least (p , 2)n new examples represented. p increases,value also increases and, large values p, could lead generalization twovalues given attribute suce predict outcome values current context.However, potential generalizations partially offset system's abilityidentify, retain give precedence exceptions.still drawbacks FLARE's generalization scheme. Given set vectorsform vi = SxiTk fixed, target-attribute xi 6= xj6= j , pair concordant (i.e., k) vectors satisfy generalization condition, yetfirst pair generalize. vectors become either subsumedgeneralization exceptions it. exceptions, leads storagevectors needed, especially large domains various subsets values giverise different target-attribute's values. Moreover, outcome depends upon orderingvectors. Also, exists con icts involving one (or more) value x,system end giving unfounded precedence exceptions (being specific) and,again, depend ordering. Support internal disjunction complexgeneralization scheme may help alleviate problems. topicfuture research.2.4.3 Illustrationsection shows evolution FLARE's knowledge base vectors KB (seeSection 2.1.3) presented inputs. highlights several interesting featuresreasoning adaptation. Let KB 0 denote current knowledge base FLARE.165fiGiraud-Carrier & Martinezdiscussed above, FLARE starts KB 0 = ;. vector presented FLAREorder appears KB .1. Presentation v1 . KB 0 = ;. v1 simply added KB 0 .2. Presentation v2. KB 0 = fv1g. v1 closest match. v1 v2 concordant,v2 added KB 0 .3. Presentation v3. KB 0 = fv1; v2g. either v1 v2 . v3added KB 0 .4. Presentation v4. KB 0 = fv1; v2; v3g. winner found since nonevectors KB 0 target-attribute v4 . v4 added KB 0 .earlier KB 0 information single concept (i.e., stimulus-situation), newKB0 provides FLARE knowledge new concept, namely appropriateresponse. \partitioning" vectors along target-attribute, FLARE naturallysupports multiple concept learning.5. Presentation v5 . KB 0 = fv1 ; v2; v3; v4g. v4 (and hence closest) matchsince none vectors KB 0 target-attribute v5 . v4v5 satisfy conditions 1-4 generalization violate condition 5, v5 addedKB0 .6. Presentation v6 . KB 0 = fv1 ; v2; v3; v4; v5g. Similar step 3 v4 v5 . v6added KB 0 .7. Presentation v7 . KB 0 = fv1; v2; v3; v4; v5; v6g. Note v7 precept. winnerfound since none vectors KB 0 target-attribute v7.v7 added KB 0 . third concept, namely media, available.8. Presentation v8. KB 0 = fv1; v2; v3; v4; v5; v6; v7g. v7 (and hence closest)match since none vectors KB 0 target-attribute v8.v8 exception v7 since v7 covers v8 concordant. Hence, v8added KB 0 . Though v7 suggests use lecture media, added conditiontraining-budget found v8 causes suggestion change lecture slides.9. Presentation v9 . KB 0 = fv1; v2; v3; v4; v5; v6; v7; v8g. v7 v8 may compete.D(v7; v9) = 1=3 D(v8; v9) = 1=4. Hence, v8 wins. v8 v9 satisfy fiveconditions generalization. second attribute dropped (i.e., replaced ?)either one, say v8 , produce v80 = (?; ?; ?; 0; 0; 0; 3T ). v80 added KB 0 .attributes v8 v9 value, except stimulus-situation.sucient FLARE hypothesize value stimulus-situation criticalattribute may thus ignored. words, FLARE decides valuestimulus-situation needed predicting lecture slides.10. Presentation v10. KB 0 = fv1; v2; v3; v4; v5; v6; v7; v80 g. v7 v80 may compete.D(v7; v10) = 1=3 D(v80 ; v10) = 0. Hence, v80 wins. v80 covers v10concordant, FLARE adds 1 num covers(v80 ). v10 need added KB 0 . v10one many special cases handled new generalization v80 .166fiAn Integrated Framework Learning Reasoning11. Presentation v11 . KB 0 = fv1 ; v2; v3; v4; v5; v6; v7; v80 g. Notice v11 alsoprecept, precepts may given time learning. v7v80 may compete. D(v7; v11) = 1=6 D(v80 ; v11) = 1=3. Hence, v7 wins. Neitherone covers other; equal; cannot produce generalization (violatecondition 3). Thus, v11 added KB 0 . Note v11 static priority 1.12. Presentation v12. KB 0 = fv1 ; v2; v3; v4; v5; v6; v7; v80 ; v11g. v7, v80 v11 compete.D(v7; v12) = 1=2, D(v80 ; v12) = 2=3 D(v11; v12) = 1=4. Hence, v11 wins. Neitherone covers other; equal; cannot produce generalization (violatecondition 3). Thus, v12 added KB 0 . Note v12 static priority 3.Since v11 v12 overlap, precedence would given v12 case con ict.13. Presentation v13. KB 0 = fv1 ; v2; v3; v4; v5; v6; v7; v80 ; v11; v12g. case,non-asserted attributes v13 may asserted reasoning, targetattribute. Rules v2 v4 applied assert second fourth attributes0 = (1; 1; 0; 0; 0; 1; 2T ). v7, v80 , v11 v12 competerespectively. result v130 ) = 0, D(v80 ; v130 ) = 0, D(v11; v130 ) = 0,assert target-attribute. D(v7; v130 ) = 1=2. v7 v80 win v11 since specific. However,D(v12; v13v7 v80 specificity. fact, satisfy five conditionsidentify con icting defaults current context. Hence, FLARE adds 10 concordant. Reasoning proceeds,dynamic priority(v7 ) since v7 v130 concordant, v130 needgiving precedence v7 . Since v7 covers v13added KB 0 .14. Presentation v14. KB 0 = fv1 ; v2; v3; v4; v5; v6; v7; v80 ; v11; v12g. non-assertedattributes v14 may asserted reasoning, target-attribute. Rulesv2 v5 applied assert second fourth attributes respectively. result0 = (1; 1; 1; 0; 0; 1; 2T ). rest identical step 13. Now, dynamic priority(v7)v140 added KB0.= 2 v1415. Presentation v15. KB 0 = fv1 ; v2; v3; v4; v5; v6; v7; v80 ; v11; v12g. non-assertedattributes v15 may asserted reasoning, target-attribute. Rulesv3 v6 applied assert second fourth attributes respectively. result0 = (2; 2; 2; 1; 1; 0; 0T ). v7, v80 , v11 v12 compete assert target-attribute.v150 ) = 1, D(v80 ; v150 ) = 1, D(v11; v150 ) = 1, D(v12; v150 ) = 1=2. Hence,D(v7; v15v12 wins. Neither one covers other; equal; cannot produce0 added KB0.generalization (violate condition 3). Thus, v150 g.16. Presentation v16 v17 . KB 0 = fv1 ; v2; v3; v4; v5; v6; v7; v80 ; v11; v12; v1500equal v15. Neither v16 v17 need added KB appropriate0 . result counters[0] = 2, counters[1] =counter values incremented v1500, counters[2] = 1 counters[3] = 0. Thus, target-attribute's value v15currently 0.resulting KB 0 , processing KB shown Figure 5. variables p, c dpstand static priority, cover number dynamic priority, respectively. intuitivelevel, FLARE used learning reasoning mechanisms deal KB . Induction167fiGiraud-Carrier & Martinezv1v2v3v4v5v6v7v8v11v12v1500===========012???????20T1T2T???1?112???012????2???0T0T1T00?11??????000?1???????1??0??????2T3T0T1T0TFigure 5: KB 0(p = c = dp = 0)(p = c = dp = 0)(p = c = dp = 0)(p = c = dp = 0)(p = c = dp = 0)(p = c = dp = 0)(p = c = 0; dp = 2)(p = 0; c = 1; dp = 0)(p = 1; c = dp = 0)(p = 3; c = dp = 0)(p = c = dp = 0)(on vectors v8; v9; v10) allowed system decide stimulus-situationirrelevant predicting use lecture-with-slides. Deduction empirical evidenceprovided vectors v13 v14 caused FLARE break \tie" rules v7 v80favor v7. Prior knowledge relative vectors v11 v12 encoded static priorities,thus giving precedence v12 case con icts. Hence, vector v = (1; ?; 0:?; 0; 1; ?T )presented FLARE KB 0 acquired, second fourth attributes firstasserted previously discussed produce v 0 = (1; 1; 0; 0; 0; 1; ?T ). Then, v7 , v80 v11compete. v7 v80 win due specificity. v7 v80 also static prioritiesv7 wins due dynamic priority result (1; 1; 0; 0; 0; 1; 2T ). Now, vector(1; ?; 2; ?; 0; 0; ?T ) presented, similar situation arises v11 v12 . con ictresolved static priorities.2.4.4 Extensionality Intensionalityable use prior knowledge form precepts together raw examples,FLARE effectively combines intensional approach (based features, expressedprecepts) extensional approach (based instances, expressed examples)learning reasoning. combination, FLARE resolve con icting defaults,Nixon Diamond (Reiter & Griscuolo, 1981), either told explicitlydefault prevails (e.g., religious conviction important political aliation)computing relative dynamic priorities (see Section 2.3.5) examples RepublicanQuakers.inductive learning systems purely extensional, reasoning systemspurely intensional. therefore authors' contention that, induction deductionintegrated, combination two approaches desirable. also clearcombination increases exibility. one hand, extensionality accountssystem's ability adapt current environment, i.e., autonomous.hand, intensionality provides mechanism system taughtthus unnecessarily suffer poor atypical learning environments.context reasoning, precepts provide useful medium encode certain firstorder language statements (e.g., rule base expert system) can, turn,learned FLARE (in usual way) later used reasoning purposes.168fiAn Integrated Framework Learning ReasoningDEFINITIONInput: set general rules, set facts one designated target-attributeOutput: one preceptsIMPLEMENTATION1. Learning general knowledge: Perform Learning set general rules.2. Reason facts: Perform Reasoning vector encoding given facts designatedtarget-attribute.Figure 6: Function Generate-Precepts2.5 FLARE's Automatic Generation PreceptsSection 2.1.2 introduced notion precepts generalized AVL vectorsattributes special value ? (i.e., don't-care). Precepts may encoded directlyteacher deduced automatically general knowledge. FLARE provides simple(off-line) mechanism automatic generation precepts preprocessing phasedescribed Section 2.2.FLARE uses prior knowledge form general rules may viewed encoding\commonsense" knowledge involving attributes application domain.appropriate setting deduction, FLARE generate domain-specific preceptsused biases inductive learning reasoning specificdomain apply.Consider example Table 3 Section 2.1.1. Assume systeminductively learn rules regarding suitability lenses patients set exampleswhose attributes include patient's tear-production rate (tpr). statements Table3 capture general knowledge eyes. Informally, state that:1. Low tear-production rate causes dryness eyes.2. Dry eyes fit lenses.provided fact target-attribute system fittinglenses, general knowledge may used produce domain-dependent preceptstates that, patient low tear-production rate, he/she fitted lenses.precept, turn, provides useful bias system inductionexamples.process generating precepts described essentially one acquiringgeneral knowledge (or rules) reasoning described Figure 6. generalrules available, function Generate-Precepts always invoked prior workFLARE.function Generate-Precepts actually makes use functions FLARE.step (1), constructs knowledge base general rules using learning describedSection 2.4. step (2), reasons, described Section 2.3, using acquiredknowledge facts enabling general knowledge applied domain.169fiGiraud-Carrier & Martinezfacts encoded vector attributes found general knowledge setappropriate values others set ?. Since precepts mostly used learning biases,designated target-attribute typically target concept inductive application.lenses example Table 3, appropriate setting obtained creating vectorattribute Tpr set low attribute Fit designated target-attribute.incorporated two rules knowledge base step (1), FLARE wouldeasily deduce precept form: Tpr low Fit false, independentdon't-care conditions.Though function Generate-Precepts automated, setting relevant attributes interpretation result rely teacher. automatic mechanismsmay considered, system could try combination learning problem'sattributes values instantiate general knowledge. Then, instantiation causestarget-attribute become asserted potential precept. However, process wouldexponential would probably lead useful conclusion.3. Experimental Results Demonstrationsset classical commonsense benchmark problems proposed Lifschitz (1988)UCI repository (Murphy & Aha, 1992) contains many useful training setsinductive learning. section reports results obtained FLARE severaldatasets. Results number uses framework, including two expert systems,also presented. Finally, limitations system described.One artifact implementation that, since variables cannot added dynamically,attributes must defined priori. attributes appear rules, examplesprecepts set don't-care. consistent semantics don't-careinterfere algorithm since distance essentially treats learned don't-caresneutral values.3.1 Inductive Learning Prior Knowledgeorder test predictive accuracy FLARE, standard training set/test set approach used. value v 's target-attribute provided usedreasoning. Rather, system reasons based current knowledge baseasserted attributes v . reasoning completed, \computed" target valuecompared \actual" target value.Several datasets UCI repository (Murphy & Aha, 1992) chosen.represent wide variety situations, shown Table 6. column labelled \Size"indicates total number examples dataset. column labelled \Attributes"records number type (L linear, N nominal) attributes,target (or output) attribute. column labelled \Output" shows number outputclasses.FLARE's results gathered applications, using 10-way crossvalidation. dataset randomly broken 10 sets approximately equal size. Then,turn, one sets used testing, remaining 9 used learning.process repeated 10 times, one test set, every item datatest set once. FLARE's outcome dependent upon ordering170fiAn Integrated Framework Learning ReasoningApplicationlensesvoting-84tic-tac-toehepatitiszooirissoybean-smallsegmentationglassbreast-cancersonarSize Attributes Output244N343516N29589N2155 6L&13N29016N71504L347 4L&31N442019L72149L76999L220860L2Table 6: Selected ApplicationsApplication PA IR ID3 CN2lenses79.0 .43 65.0 83.3voting-8492.9 .63 95.4 93.8tic-tac-toe81.5 1.0 85.6 98.0hepatitis80.0 .94 77.9 76.1zoo97.4 .36 97.8 93.3iris94.0 .13 94.0 93.3soybean-small 100 .98 98.0 100segmentation 94.0 .99 96.9 94.1glass71.8 .22 67.7 62.7breast-cancer 96.6 .47 95.1 95.1sonar83.8 .77 77.4 44.3Averages88.3 .63 86.4 84.9Table 7: FLARE: InductionBP76.796.096.697.897.310038.099.787.8data learning, turn repeated 10 times new random orderingtraining set. predictive accuracy given turn average 10 correspondingtrials predictive accuracy dataset average 10 turns.Results shown Table 7. first number (PA) represents predictive accuracy(in %) test set training second number (IR) inductive ratio,defined ratio size (in number rules) final knowledge basenumber instances used learning. IR another measure generalization powerFLARE, well indication FLARE's memory requirements. Results PA ID3(Quinlan, 1986), ordered CN2 (Clark & Niblett, 1989) Backpropagation (Rumelhart &McClelland, 1986) also included comparison. also obtained using 10-waycross-validation reported Zarndt (1995).set selected applications, FLARE's performance generalization comparesfavorably ID3, CN2 Backpropagation, well inductive171fiGiraud-Carrier & MartinezApplicationlensesvoting-84tic-tac-toehepatitiszooAveragesprec.79.0 - .4392.9 - .6381.5 - 1.080.0 - .9497.4 - .3686.2 - .67w/prec.80.5 - .3394.5 - .2588.5 - .7281.2 - .6897.4 - .3288.4 - .46Table 8: FLARE: Induction Prior Knowledgelearning algorithms (e.g., see Aha et al., 1991; Wettschereck & Dietterich, 1994; Zarndt,1995). addition, knowledge base maintained FLARE generally significantlysmaller set training vectors.first five applications selected illustrate effect prior knowledgepredictive accuracy inductive ratio. application, experimentalprocedure repeated set training examples augmented precepts givenpriori (i.e., training set presented). Results reported Table 8.column shows PA IR. Here, precepts obtained domain knowledgeprovided application (voting-84) generated authors common sense (zoo,lenses, hepatitis, tic-tac-toe). serve learning biases. results precepts showaverage increase 2.6% predictive accuracy decrease 31.3% inductiveratio. decrease IR demonstrates prior knowledge allows pruning partsinput space learning. Indeed, starting number training vectors,FLARE ends knowledge base containing one-third less vectorsprecepts used. Hence, precepts increase generalization performance,also reduce memory requirements.lenses application also used demonstrate precepts may generatedautomatically deducing domain-dependent information general knowledge, discussed Section 2.5. example Table 3 Section 2.1.1 implemented (asdescribed Section 2.5) precept stating that, Tpr attribute set low,lenses prescribed generated. precept was, turn, used priorperforming inductive learning described above.process inductive learning automatically generated prior knowledge twophase, phases perform operations different pieces information.first phase, general knowledge expressed rules (and translated AVL) learnedFLARE. FLARE reasons based instantiation links general knowledgecurrent domain. result reasoning phase one (or more) precept containingdomain-dependent information. second phase, FLARE learns generatedprecepts available examples. result set inductively generatedrules.3.2 Classical Reasoning ProtocolsSeveral problems set Benchmark Problems Formal Nonmonotonic Reasoning(Lifschitz, 1988), presented FLARE. problems first translated172fiAn Integrated Framework Learning Reasoningcorresponding AVL representation. FLARE able properly incorporate premisescorrectly derive expected conclusions following classes problems(Lifschitz, 1988):A1 - basic default reasoning.A2 - default reasoning irrelevant informationA3 - default reasoning several defaultsA5 - default reasoning open domainA9 - priority defaultsB1 - linear inheritance (top-down)B2 - tree-structured inheritanceB3 - one-step multiple inheritanceB4 - multiple inheritanceProblem A4 involves disabled default problems A6 A8 deal unknownexceptions. problems cannot represented FLARE. Problems A10 A11 dealinstances defaults reasoning priority. Though directly representableFLARE, effectively solved via use static (A10) dynamic (A11) priorities.classes problems defined Lifschitz (1988) (i.e., reasoning actions,uniqueness names autoepistemic reasoning) beyond current scope FLARE.Note that, order work properly, problems require added processing. particular, problems A1, A2, A3 A5 involve classes objectsparticular instances classes. Problem A1, example, given follows: blocksB heavy, heavy blocks normally located table, table.Translating AVL gives: 1T ?, B 1T ?, ? 1 1T ? 0T , first attributemulti-valued attribute representing objects universe second thirdattributes Boolean, encoding predicate heavy ont able respectively. Now,? ?T shown, 1 ?T derived first vector match ?1 1T ? 0T exactly. seems reasonable priority given latersince involves (an instance) explicitly. solve problem, vectors involving explicitreferences instances objects static priority set 1 vectorsstatic priority set 0. is, course, artifact encoding. alternativewrite facts relative given instance definition whose target-attributeinstance value. completion would guarantee correct outcome.problems characteristics important forms human patterns reasoning. However, artificial manufactured explicitly intentisolating one salient feature nonmonotonic reasoning, independent others.investigate properties FLARE combination learning reasoning,\real-world" applications must designed experimented with. Section 3.5presents preliminary applications. next two sections present simple applicationsexercise FLARE's ability learn incrementally combine learningreasoning useful ways.173fiGiraud-Carrier & Martinez3.3 Nixon DiamondNixon Diamond (Reiter & Griscuolo, 1981), reproduced Table 1 Section 2.1.1,important prototype class interesting problems involving con icting defaults.used demonstrate FLARE's mechanisms handle con icts intensionallyextensionally.FLARE's static priorities offer simple way resolving Nixon Diamond intensionally, based externally provided information (e.g., religious convictions supersedepolitical aliations). case, defaults given along appropriate staticpriority.Another alternative consists providing defaults without priority. corresponds possibly natural situation system really don't-knowstate comes deciding Nixon's dispositions. Yet, don't-know statesuncomfortable authors' contention kind information may allowdecision made used. Hence, simple epistemological approach adopted,con ict arises due beliefs rather facts. case, possibleattempt resolve con ict observing instances Republican-Quaker. relativenumber pacifists non-pacifists serve evidence lean towards one decisionother. words, system's observation seems commonenvironment creates belief. unlike way humans deal manysimilar situations.final approach, combines inductive learning reasoning, consistsproviding system default. Rather, examples Republicans, QuakersRepublican-Quakers shown system automatically comes defaults (through induction) relative priorities.three experiments run FLARE results expected.third case, actual knowledge base depends upon ordering. consists onevector Republicans Quakers one vector Quakers Republicans, one default vector Quakers Republicans one vector Republican-Quakers.target value vector Republican-Quakers via dynamic priorityvia counters. Functionally, however, result identical.3.4 Birds Typically Fly?Incremental learning one FLARE's important features. incrementality, systemself-adaptive sense current knowledge base representative experienceenvironment far. knowledge base continually updated newinformation becomes available. exercise incrementality simple example bottom-upinheritance involving birds designed.application four attributes, two correspond Ostrich Bird.two (undetermined) attributes birds (e.g., Feather). target-attributeBoolean characterizes ability y. first, system exposed mostlyostrich-birds (maybe experiment started Australia). asked whether birdstypically (i.e., Bird attribute asserted inputs don't-know),FLARE concludes birds y, consistent current experience\world." However, new instances ying birds (i.e., ostriches174fiAn Integrated Framework Learning Reasoningpenguins) encountered, FLARE adapts knowledge asked again, concludesbirds y. Correct knowledge ostrich-birds also preserved. is,system shown ostrich, still conclude ostrich y.course, precept may also given system given time, statingbirds typically y. idea FLARE offers options naturally. system maytaught suffer poor atypical learning environments (e.g., Australiabirds' ying ability prediction), may left adapt environment. researchautonomous agents continues, later ability becomes important.Note example also illustrates one FLARE's limitations. systemeither concludes birds not. mechanism representing middle ground way FLARE could reason meta-level.Decisions made presence con icts also \crisp" demonstrated simple,rigid con ict resolution mechanism discussed Section 2.3.5. Even though, system mayable produce fuzzy-like results associating decision confidencelevel, would still able reason meta-level.3.5 Learning Expert Systemsorder better assess FLARE's reasoning mechanisms, two expert system knowledgebases used. One called mediadv (Harmon & King, 1985) intended helpdesigners committees choose appropriate media deliver training program.consists 20 rules chains inference length 2 most. called health(Sawyer & Foster, 1986) intended predict longevity patients basedvariety factors (e.g., weight, personality, etc.). much larger contains 77 rulescomplex involves longer chains inference. Five rules left oneredundant (i.e., rule 17 identical rule 14) four needed interactivesetting original system described. Hence, 72 rules considered.sets rules translated AVL. 20 rules mediadv produce 99 vectors72 rules health produce 72 vectors. number vectors mediadv muchlarger original number rules many rules contain internal disjunctions. AVL, new vector must constructed possible combination arisingdisjunctions. example, rule: ((A=1 A=2 A=5) (B=2.9 B=7.8))C, gives rise 6 vectors corresponding equivalent set rules: ((A=1)(B=2.9)) C, ((A=1) (B=7.8)) C, ((A=2) (B=2.9)) C, etc.sets vectors corresponding original knowledge bases encodedFLARE. Rather, presented system learned. Hence, generalizationmay take place. fact, final number vectors (after learning) mediadv 71,health 65.mediadv example clearly simple presents little interest termsdeduction. However, purpose show system's current knowledge basemay updated learning. particular interest case con icts arisetwo rules may apply given situation, implying different goalvalues. mediadv, con ict exists rules 13 14 rules 1617. Rules 13 14 used illustration. Let X fixed conjunction conditionsshown. Then:175fiGiraud-Carrier & Martinezrule 13: (X) (training budget = small training budget = medium)media consider = lecturerule 14: (X) (training budget = medium) media consider = lecturewith-slidesclear that, cases, rules con ict. important issue dicult avoid occurrences large knowledge bases elicited experts. FLAREsupports learning, possible, however, look various (historical) situationstraining budget medium check media used then. information can,turn, used give precedence one rule other. Moreover, precedenceneed fixed many examples considered. Indeed, may evolvetime even change radically depending circumstances.example, using several additional instances [(X) (training budget = medium)]together target value media consider, implemented. instances usedcaused value dynamic priority rule 13 greater rule 14, thuseffectively giving (evidential) precedence rule 13.experiments health knowledge base demonstrate FLARE's ability perform deduction. experiments conducted involve chains inference reasonable lengthsfairly intuitive. Results summarized Table 9. first column containslist attributes used knowledge base. Then, pair (setting, result) columnsrepresents experiment reasoning knowledge base. setting column contains data FLARE starts with. Unknown conditions (or attributes) initializeddon't-knows (i.e., ?). result column shows state knowledge reasoning.derived piece information italicized subscripted depth inferencederived.Starting facts setting column, FLARE successively infers new conclusionsreaches value top goal, longevity. Details inference process givenfirst setting only. easily extended settings. first settingcorresponds average adult female Asian race, little vices excessesreasonable diet. FLARE first infers that:relative weight normal (absolute weight < 110 lbs small frame).personality type A, aggressive.blood pressure average (normal fat salt intake).base longevity average, namely 67 (range 48-84).chances living longer (i.e., add years base-longevity) good.then, based added information, infers risk actually high thoughchances living longer good, actual value added base-longevity 0 (i.e.,factor = none). Finally, one would expected, woman's longevity predictedaverage (i.e., 67).settings illustrate FLARE's ability perform forward chaining.second setting corresponds unhealthy older male whose longevity accordingly176fiAn Integrated Framework Learning Reasoningsetting 1 result 1setting 2result 2rel. weight?normal1?obese1val?yes2??heart-dis-risk???> average1hddanger????startyesyesyesyesage25-5525-55>55>55genderFFbase-longevity?671?601weight<110<110>170>170framesmallsmallsmallsmallcholesterol??highhighfat intakenormalnormalhighhighsalt intakenormalnormalhighhighblood-pressure?average1?> average1calcium????osteoporo-risk????smokeryesyesoutlook???bleak2raceasianasiancaucasian caucasianorigin??medit.medit.risk?high2?high2personalityaggressive aggressive aggressive aggressiveperson. type?type a1?type a1alcohol cons.moderate moderate excessive excessiveadd?good1?poor1factor?none3?minus 123longevity?674?484setting 3????yes<25F?110-170largelownormalnormal?normal??caucasiann-amer.unknowndocile?none???result 3normal1yes2average1low2yes<25F721110-170largelownormalnormalaverage1normalaverage1fair3caucasiann-amer.unknowndociletype b1nonefair1plus 124845Table 9: Health Knowledge Basepredicted low third setting describes young healthy female whose lifeexpectedly predicted quite long. Note though results may seem impressive,experiments \anecdotal."Note classical expert systems, identification closest match reasoning could used extend FLARE may query user missing informationwell justify queries decisions made.3.6 Limitationsapplications serve demonstrate FLARE holds promise. However, FLAREmany important limitations, several mentioned throughout paper.summarized here.FLARE's use AVL representation language limits applicability relativelysimple problems. Induction deduction carried within confines nonrecursive, propositional logic. restriction makes combination learningreasoning accessible since much research taken place within context. However,177fiGiraud-Carrier & Martinezfirst-order predicate logic seems minimum requirement system claiming reasoningabilities.Although FLARE produces good results, applications tested relativelysimple. example, many databases UCI repository low complexityrelatively unsophisticated learning methods perform well them. explainsFLARE's extremely coarse generalization scheme seems sucient attain reasonable predictive accuracy. Similarly, reasoning problems presented somewhat straightforward.follows simple mechanisms static priorities counting devices usedFLARE sucient.FLARE meta-level abilities. system unable reasonknowledge subsequently unable produce meaningful middle ground solutions. Yet, work Cyc (Guha & Lenat, 1994) strongly suggests meta-knowledgeindispensable carrying uncertain reasoning.clear FLARE \scratches surface" problem effectivelyeciently combining induction deduction. Work ILP (Muggleton, 1992) may shedlight issue bringing systems like FLARE first-order logic level.4. Related WorkFLARE follows tradition PDL2 (Giraud-Carrier & Martinez, 1994b) ILA(Giraud-Carrier & Martinez, 1995), attempts combine inductive learning usingprior knowledge together reasoning. Unlike PDL2 ILA whose prior knowledgemust pre-encoded whose reasoning power limited classification (i.e. 1-step forward inferences only), FLARE supports automatic generation precepts forwardchaining arbitrary depth. Whereas PDL2's actual operation tends decouple learning reasoning (i.e., system essentially uses distinct mechanisms perform eitherone), ILA implements inherently incremental approach combining2-phase algorithm always reasons first adapts accordingly. FLAREextends ILA providing natural transformation constrained first-order clausesattribute-value vectors accurate characterization con icting defaults.attempting construct unified framework learning reasoning, FLAREfollows synergistic approach, similar (at least concept) taken SOAR (Laird,Newell, & Rosenbloom, 1987) NARS (Wang, 1993) example. alsovariety inductive learning models reasoning systems bear similaritycorresponding components FLARE. discussed here.Induction FLARE carried much way NGE (Salzberg, 1991).However, generalization effected setting attribute(s) don't-care,produced generalizations generalized exemplars (Salzberg, 1991), hyperplanes,rather hyperrectangles, input space. Hence, FLARE implements nearesthyperplane learning algorithm. FLARE also uses static dynamic priorities breakties equidistant generalizations. Moreover, shown overlappinghyperrectangles may hinder performance (Wettschereck & Dietterich, 1994), FLARE allowsoverlapping hyperplanes purposes dealing con icting defaults.case generalizations constructed training examples, FLAREdegenerates restricted form MBR (Stanfill & Waltz, 1986). distance metric178fiAn Integrated Framework Learning Reasoningused similar IBL's metric (Aha et al., 1991) also handles don't-care attributes(which non-existent instance-based learners) treats missing attributes somewhatdifferently. IBL considers missing attributes complete mismatches, FLAREchooses middle-ground approach may better capture inherent notionmissing \don't-know" attributes.Learning FLARE contrasts algorithms CN2 (Clark & Niblett, 1989),training examples must available priori. Rather, FLARE follows incremental approach similar argued Elman (1991), except knowledgeevolved, rather system's structure. Moreover, learning FLAREeffected continually. time example precept presented targetoutput known, FLARE adapt.Prior knowledge may take variety forms, discussed Mitchell(1980) Buntine (1990). form relevant FLARE consists domain-specificinference rules, either pre-encoded deduced general rules. Systems explicitly combine inductive learning kind prior knowledge include PDLA (GiraudCarrier & Martinez, 1993), ScNets (Hall & Romaniuk, 1990), ASOCS (Martinez, 1986)ILP (Muggleton, 1992; Muggleton & De Raedt, 1994). ScNets hybrid symbolic, connectionist models aim providing alternative knowledge acquisition experts.Known rules may pre-encoded new rules learned inductively examples.representation lends rule generation constructed networks complexgeneralization appear trivial. ASOCS PDLA dynamic, self-organizingnetworks learn, incrementally, examples rules. ASOCS, order matters con icts simply solved giving priority recent rules. PDLAless order-dependent provides evidence-driven mechanisms handling con icts.ScNets, prior knowledge ASOCS PDLA takes form explicitly encoded,domain-specific rules. FLARE's approach exible. system reason,domain-specific rules (or precepts) deduced automatically general rules.ILP models offer exibility. intersection logic programming inductive learning, ILP takes advantage full expressiveness first-order predicate logiclearn first-order theories background theories examples. FLARE's representationlanguage, though capable handling nominal linear (including continuousnumerical) data, expressive non-recursive, propositional clauses. However,simpler setting, FLARE supports evidential reasoning prioritization rules.FLARE's use rules similarity reasoning similar CONSYDERR's (Sun,1992). However, CONSYDERR strictly concerned connectionist approach concept representation commonsense reasoning. resulting model elegant. consiststwo-level architecture naturally captures dichotomy conceptsfeatures used describe them. However, address problem learning (howskill could incorporated also unclear) currently limited reasoningconcepts. FLARE's representation elegant model effectively reasonconcepts features. CONSYDERR deals Boolean featuresconcept's representation limited single conjunction features. FLARE's conceptsgenerally consist several conjunctions features, representing partial complementary definitions concept. Also, since domain features restricted,FLARE uses general distance metric CONSYDERR's similarity measure based179fiGiraud-Carrier & Martinezfeature overlap. However, FLARE currently mechanisms individual weightingfeatures, may cause performance degradation increased memory requirementspresence large number irrelevant features.FLARE's ability evolve knowledge base time similar foundtheory-refinement systems RTLS (Ginsberg, 1990), EITHER (Ourston & Mooney,1990, 1994) KBANN (Towell, Shavlik, & Noordewier, 1990; Towell & Shavlik, 1994).RTLS implements 3-phase algorithm refinement. first reduces current theoryform suitable inductive learning, performs learning and, finally, retranslatesresult new theory. process potentially costly. FLARE, languagetheory language induction, is, theory alwaysreduced form. Though language rich, allows revision take place ecientlynew example, incrementally. EITHER similar FLARE assumesapproximate theory allows correction overly-general overly-specific rules.mechanisms revision different. EITHER may add/remove antecedents rules,FLARE may remove antecedents add rules exceptions. EITHER currentlyhandles Boolean attributes, FLARE restriction. However, EITHERuses explanation-based learning inductive learning revision, FLAREstrictly inductive. KBANN, like EITHER, deals propositional, non-recursiveHorn clauses. Prior knowledge expressed identically FLARE's pre-encoded precepts(i.e., domain-specific inference rules form Prolog-like clauses). KBANN translatesgiven knowledge base equivalent artificial neural network (ANN) mayperturb learn using backpropagation algorithm. FLARE, ANN;knowledge base simply stored individual rules. Overall, FLARE provides slightlygeneral synergistic approach. New evidence constantly used revise currentstate knowledge. currently mechanisms FLARE deal explicitlyfuzzy rules. However, several mechanisms exist handle inconsistencies con icts.FLARE always makes decision based available evidence. confidence level alsoproduced characterize \goodness" decision.FLARE's limited handling non-monotonicity differs approach taken logic.Non-monotonic logics typically extend first-order predicate logic added \machinery," circumscription (McCarthy, 1980), semi-normal defaults (Reiter & Griscuolo,1981) hierarchical theories (Konolige, 1988), essentially preserving consistency.FLARE's approach consists tolerating inconsistencies knowledge base providing reasoning mechanisms ensure inconsistent conclusions ever reached.essentially consists using normal defaults inheritance external criterioncancellation (Vilain, Koton, & Chase, 1990). current criterion relies mostly simplecounting argument (for dynamic priorities covers). Though approach provensucient simple propositional examples described here, likely breaksophisticated examples domains.5. Conclusionpaper highlights interdependencies learning reasoningdetails system, called FLARE, combines inductive learning using prior knowledge180fiAn Integrated Framework Learning Reasoningtogether reasoning within confines non-recursive, propositional logic. Severalimportant positive conclusions may drawn results research. particular,Performance induction improved terms memory requirementgeneralization prior knowledge used.Induction examples used effectively resolve con icting defaults extensionally.Combining rule-based similarity-based reasoning provides useful means performing approximate reasoning tends reduce brittleness.Induction offers valuable complement classical knowledge acquisition techniquesexperts.Experiments FLARE variety applications demonstrate promise. However,much work still remains done achieve complete meaningful integrationlearning reasoning. Areas future work include following:Designing mechanisms use reasoning guide learning.Possibly incorporating backward chaining.Attempting overcome (or appropriately use) order-dependency.Providing support internal disjunction.Improving use inductively learned rules reasoning (the support availableinduction may produce useful rules).Translating system's knowledge base back AVL FOL.experimenting larger applications.Extending language first-order.Acknowledgementswork supported part grants Novell Inc. WordPerfect Corp. Manythanks also reviewers helpful constructive comments.ReferencesAha, D., Kibler, D., & Albert, M. (1991). Instance-based learning algorithms. MachineLearning, 6, 37{66.Buntine, W. (1990). Theory Learning Classification Rules. Ph.D. thesis, UniversityTechnology, School Computing Science, Sidney, Australia.181fiGiraud-Carrier & MartinezClancey, B., & Shortliffe, E. (Eds.). (1984). Readings Medical Artificial Intelligence:First Decade. Reading, MA: Addison-Wesley Publishing Company.Clark, K. (1978). Negation failure. Gallaire, H., & Minker, J. (Eds.), LogicDatabases, pp. 293{322. Plenum Press.Clark, P., & Niblett, T. (1989). CN2 induction algorithm. Machine Learning, 3,261{283.Collins, A., & Michalski, R. (1989). logic plausible reasoning: core theory. Cognitive Science, 13, 1{49.D'Ignazio, F., & Wold, A. (1984). Science Artificial Intelligence, p. 13. FranklinWatts Library Edition.Duda, R., & Reboh, R. (1984). AI decision making: PROSPECTOR experience.Reitman, W. (Ed.), Artificial Intelligence Applications Business. Norwood, NJ:Ablex Publishing Corp.Dzeroski, S., Muggleton, S., & Russell, S. (1993). Learnability constrained logic programs.Proceedings European Conference Machine Learning (ECML'93), LNAI667, pp. 342{347.Elman, J. (1991). Incremental learning, importance starting small. Tech. rep.CRL 9101, University California, San Diego, Center Research Language, LaJolla, CA.Ginsberg, A. (1990). Theory reduction, theory revision, retranslation. ProccedingsEighth National Conference Artificial Intelligence (AAAI'90), pp. 777{782.Giraud-Carrier, C., & Martinez, T. (1995). ILA: Combining inductive learning priorknowledge reasoning. Tech. rep. CSTR-95-03, University Bristol, DepartmentComputer Science, Bristol, UK.Giraud-Carrier, C., & Martinez, T. (1993). Using precepts augment training set learning.Proceedings First New Zealand International Two-Stream ConferenceArtificial Neural Networks Expert Systems (ANNES'93), pp. 46{51.Giraud-Carrier, C., & Martinez, T. (1994a). ecient metric heterogeneous inductivelearning applications attribute-value language. Proceedings ThirdGolden West International Conference Intelligent Systems (GWIC'94), Vol. 1, pp.341{350. Kluwer Academic Publishers.Giraud-Carrier, C., & Martinez, T. (1994b). incremental learning model commonsense reasoning. Proceedings Seventh International Symposium ArtificialIntelligence (ISAI'94), pp. 134{141.Guha, R., & Lenat, D. (1994). Enabling agents work together. CommunicationsACM, 37 (7), 126{142.182fiAn Integrated Framework Learning ReasoningHaas, N., & Hendrix, G. (1983). Learning told: Acquiring knowledge information management. Michalski, R., Carbonell, J., & Mitchell, T. (Eds.), MachineLearning: Artificial Intelligence Approach, Vol. I, chap. 13. Morgan KaufmannPublishers, Inc.Hall, L., & Romaniuk, S. (1990). hybrid connectionist, symbolic learning system.Proceedings Eighth National Conference Artificial Intelligence (AAAI'90),pp. 783{788.Harmon, P., & King, D. (1985). Expert Systems. John Wiley & Sons, Inc.Konolige, K. (1988). Hierarchic autoepistemic theories nonmonotonic reasoning.Proceedings Seventh National Conference Artificial Intelligence (AAAI'88),pp. 439{443.Laird, J., Newell, A., & Rosenbloom, P. (1987). SOAR: architecture general intelligence. Artificial Intelligence, 33, 1{64.Lavrac, N., Dzeroski, S., & Grobelnik, M. (1991). Learning nonrecursive definitions relations LINUS. Proceedings Fifth European Working Session Learning,pp. 265{281.Lifschitz, V. (1988). Benchmark problems formal nonmonotonic reasoning. Proceedings Second International Workshop Non-Monotonic Reasoning, LNCS 346,pp. 202{219.Martinez, T. (1986). Adaptive Self-Organizing Networks. Ph.D. thesis, University California, Los Angeles. Tech. rep. CSD 860093.McCarthy, J. (1980). Circumscription: form nonmonotonic reasoning. Artificial Intelligence, 13, 27{39.Michalski, R. (1983). theory methodology inductive learning. Artificial Intelligence,20, 111{161.Minsky, M., & Riecken, D. (1994). conversation Marvin Minsky agents.Communications ACM, 37 (7), 22{29.Mitchell, T. (1980). need biases learning generalizations. Tech. rep. CBM-TR5-110, Rutgers University, New Brunswick, NJ.Muggleton, S. (Ed.). (1992). Inductive Logic Programming. Academic Press.Muggleton, S., & De Raedt, L. (1994). Inductive logic programming: Theory methods.Journal Logic Programming, 19,20, 629{676.Murphy, P., & Aha, D. (1992). UCI repository machine learning databases. Tech. rep.,University California, Irvine, Department Information Computer Science.183fiGiraud-Carrier & MartinezOurston, D., & Mooney, R. (1990). Changing rules: comprehensive approachtheory refinement. Proceedings Eighth National Conference ArtificialIntelligence (AAAI'90), pp. 815{820.Ourston, D., & Mooney, R. (1994). Theory refinement combining analytical empiricalmethods. Artificial Intelligence, 66 (2), 273{309.Quinlan, J. (1986). Inductive learning decision trees. Machine Learning, 1, 81{106.Reiter, R., & Griscuolo, G. (1981). interacting defaults. Proceedings SeventhInternational Joint Conference Artificial Intelligence (IJCAI'81), pp. 270{276.Rumelhart, D., & McClelland, J. (1986). Parallel Distributed Processing: ExplorationsMicrostructure Cognition, Vol. 1. MIT Press.Rychener, M. (1983). instructible production system: retrospective analysis.Michalski, R., Carbonell, J., & Mitchell, T. (Eds.), Machine Learning: ArtificialIntelligence Approach, Vol. I, chap. 14. Morgan Kaufmann Publishers, Inc.Salzberg, S. (1991). nearest hyperrectangle learning method. Machine Learning, 6,251{276.Sawyer, B., & Foster, D. (1986). Programming Expert Systems Pascal. John Wiley &Sons, Inc.Stanfill, C., & Waltz, D. (1986). Toward memory-based reasoning. CommunicationsACM, 29 (12), 1213{1228.Sun, R. (1992). connectionist model commonsense reasoning incorporating rulessimilarities. Knowledge Acquisition, 4, 293{321.Towell, G., & Shavlik, J. (1994). Knowledge-based artificial neural networks. ArtificialIntelligence, 70 (1-2), 119{165.Towell, G., Shavlik, J., & Noordewier, M. (1990). Refinement approximate domaintheories knowledge-based neural networks. Proceedings Eighth NationalConference Artificial Intelligence (AAAI'90), pp. 861{866.Vilain, M., Koton, P., & Chase, M. (1990). analytical similarity-based classification.Proceedings Eighth National Conference Artificial Intelligence (AAAI'90),pp. 867{874.Wang, P. (1993). Non-axiomatic reasoning system (version 2.2). Tech. rep. 75, IndianaUniversity, Center Research Concepts Cognition, Bloomington, IN.Waterman, D. (1986). Guide Expert Systems. Addison Wesley.Wettschereck, D., & Dietterich, T. (1994). experimental comparison nearestneighbor nearest-hyperrectangle algorithms. Machine Learning, 19, 5{28.184fiAn Integrated Framework Learning ReasoningWollowski, M. (1994). Case-based reasoning means overcome frame problem.Proceedings Seventh Florida AI Research Symposium (FLAIRS'94), pp. 241{244.Zarndt, F. (1995). comprehensive case study: examination connectionistmachine learning algorithms. Master's thesis, Brigham Young University, DepartmentComputer Science.185fiff fi!"$#%$&('*),+--/.01'2-43'65789:;<%$=>.9?-/.6@A:#& =<+7?-6.BDCFEHGJILK/ENMPOGJQSRUT*MWVXTNTYG[Z]\HCPG_^`TNabCLTcIdTYGeMFENMPO/\fGJIEHGJghMPiJTYO/CkjliJEYCFEnm<MFTNCPO/IoMPO/mqp\rgbTYK/IsbtLuwvYxDydz"{}|LtFu~WWWnW"} WW~ W~W<N *" 9Fn" ,99%6 4rl DWD( d!P $$,Nr eJ$! !6W $ 9 % ( $6"<!P9J$ <r$P1nPn$ 9 1c$N! <f/ $r!$ P L N $ 6dF$ 4% $n$ $H<P$ c4 Pd $1bf% $"1P1H1$$ 6(9$ $ nrN $,1$ ($N1$N < 9nP( ,$ P1 w$,$6d< <!($9(14 r1 r eF $n $ /(1J$1r$$ P$ ,$ r$b r1!r,o/! 1/F!b$n$ U$r N$ J$! 1/$U}6$1,$1n 9}Le6, e<1 9(n9r 9dP *<!9$r L% <H 9J< $$"J$b, 9b $ e$$ }!$ $ $* FP<}1<< ,$P9/H 1( 1, 1r*>f% P< ,$ e! r, $rF <"dFP < 9 W P $, rNF/<b* H}!$ b$1 9F $ !H!/,P$e$ b$e 9}H6F <*(!NWN/1141" l"W94 !WffN, fi *, wP9W fW1!cfi!"#$% c9&')(H !"*"fi+ ,nWUcW,}-61.9/.1.e0215b76o6$26!,ff18:962rX,"4/11;n34!%<=WW,>?.9,!1, U"@6o!1 6," AB=WCBH .'ED 62F !""#% BH"/! G'H9N1F !""ffI+ 8.4 F.$,," !%1W!WffN, fi nW96, J6<"& "4K!%?6.<,L !6LWM NO&PQPNRTSQKUVWRTUXNMYZ[S\]V8JN!^/,.(W! ,ff6oWW1!_(".6T!n 1},. !,6?8`"K!%a.$,;bW!61}}/",N,WHb9"/6^bW!6c" WGdW;W99ff !wJ/<!, e6&bW!6rKi!1J6!,6Wo&$,, "* 34!%cF,,W !%jn!*(Y! fi.6nW9WW1Wn !%9WWffN, fi U1rW 8gf!,h9"/6!^"ff"N2,bWJ!,"W6,<W!/41k9"/69ab !68Wl9"/6abW!6m(Y !%P"1 @6on4WoYr 6op.6T!q8*NW*(,r*2b! fi.6412 1,s.$,J9!a!"=6fi.6, 0t6"u" b Jt"/!W%2b,n!,.$, !%Y vwbrx(e/ABffWCx82 !""#fi+ 8py_WWr!6=! 1!0.;9"/69^b !6"u6o2 1,!1 6," ,> znW r!%{6" }/1 ,M*nW J!Wffn0BH"6! n'|9N F !""#fi+ 8k(Y.6!W dW41nWW W0K}n9,4/9/.$%h(Y44!%,9,L "66<bW!6+--6.FfioWfi"$## = =aN9@dff;(@1:#& #x fi%&# #T=ff~fip,ff.g.?{fiu?--?fi2tL?,a;4fi343fi-L=.ff?2G3fi2&pJTu@5/@.ffKK??? fiKWL3@j.ff.,=/4p?jff_2fiLK22fiF.Jfi2Lfffi2JJ.. 3.fi?22?3.K.fi2.fiG50fffiKJfit03?p022ff3?3.KpffpJ?<.2?affFK_=fi2lfiafi/s.an?3./tK.fi3&3{:ff?x@F ff3{x2@ fio.=0.K3fifi?ff?2ff.225/Ffffi?xFfiLkj3fio2pfi/:?JffKn32fiJLff.ff5/T7?tff3.ffLK???fiKn2&-K32.=MKfi2.t2H;;fi3;fiL=.ff?20fi2& Tu.K ?fi&5=?2,L&3??2ff2u;ff;K.5.KL0fffft23ff{Kff5/.4ffLff.?H?ffp<2G4K.fffi2t.ff. u.ffLfiFfffi.JF,fiL3ppK3?..fi.K.?JpK2.0=.>_.K?2. .fi.3/c{ff.K?.fi.K;.?J3.ffLK55?fiKff.fft?Kff?2F;Jtfi/ff2&0??2ffL=.ff?2.?J.K5/.fi..fi.32ff.uM?3tKff?2. .p?.2K3 ?xff,F.=ff2FLffM=Fff.fffi:-2.J23?2F@u?2:22Ffipff.^K2offfi^ 3Mfi2ffKff5/.lffKff.? fffi)-2.fiLFfi2 fia.ff.pfifi@K.J3pfi2Mb20 ffLff.5fiM2Ffi?uffF?fi2La5&< fft. 2.ff?2K20fi?22.J?fi2Lb20ffLff.5p.2G3Mff.fffi?2fi2o2.K ;^fifi?T;&?3?K2jff^F;pffJfiJ.ffpMffJ? 5fi/KJ K/fi2J2-?5/fffit?fi2La2h=Lff.?3=.0J2G2fi2ufiffqc 0 -.ff.0? |?fi2Lpff3 ?fi,pfi3?=/{5?2Gpfi3GpaG.02Gu=.t2G{=Lff.?{fiM2F.TH7pF,7k,^.-/fifi.K<fi2Mu2??2A;ffAK_ff<fi/t&?3J?.uff3?2{fi3LffKffL3L=2hgo2t2`o=hfi3p^2^0K.tKffkfiff.0p&ffJ2fiu-ff2Gfitu=2ffJ20K.?Lo/fiLJ-_ ^ a_Lu-0K2;ff.<2-p3M20.?0tfi3fip3KK2hK.?3L2._Lff.^_Lffp-?fi.ffffa2fi2t&^2@K.fffi2?Lff.b2fi=?2FpJfiba3M2.?T<fifi?22M^fiff,@K.?L2fi25?2FT 5.7fiffKfi?L3/<fiff5/ fififf,Ax4K.fffi20JJfit?Ku.ffL&ff.<KT -Kk b ^K&JuJfi<qFuJfiuL@ff&g?2:3o2..ff.<-Kn32&-Tpp30K32.l2M2ffK..3&ff=.G3K4K.32.fi3.ffp2u-p2fi2A&u72.ff?2G=&3;^;3;3t/<fiff5/Kff?27fi;fiK32.;p`3;fiKff?;gfiKpffeoff< <fiK@ffl=GK2ff oo/.=;K3.mL^0nfi3fi7pJff2fi2;.?JfiKzff kff.3,F&F-fffiM=fi&Jff?Tfi@G-K_ff<fi/ . fiKfiff oL_W_fffififfW_ffW_fffffiff?2fiK.7ff2ffp3{2fiLJfi uoo/u/t&K3?..2ff2L,ff.J Jfi. 3? 00^ff3G -fiT.ff3K/_2Lk3{fi4=fiKuMfi"!$#%&'()(+*,-(/.0132..5476'&*8(96*,4;:<=0-'&>?(@-ACBDAFE9GIH,J?E9K&A&L=A)M5NPO&QAFQRTSUJVHWSXQfiR9YACQZ[I@PAFEO]\$BVJ?ETSUJ]@7H^A_`LaJ?Q-bcR+YAFE9A)\dODE9AR+Y7SU_ffNE9O5e)Ab7ZE+ACfgShHiHjQO&R@-AkA)l<e+SXAFQRmn YApoDZA_qRqSXO&QrJ?ETSU_TA_cR9YAFE9A)\O&E9A&LgfYAFR9YAFEfiR+YAFE9AsSU_fiJt_T[uJHhH/_TZ@-_qAFRfiO?\v[wOb7A)H,_fifY7S,e+Yx_qRqShHhHK&Z-J?E)J?QR+AFA_e)O&E9E9Ae)RyE9A_qZ7HXRz_yfYAFQ{Z-_qAbfifgSXR9YsR9YAv[|O5b7A)H}e9YAe+~DS^QKcNE9Oe)Ab7ZE9A&mC&Z-e+YJ|_qZ@-_qAFRySU_eFJHhHXAbcR9YAC_qAFR}O?\gF&q&)XF8C&O?\J?Q-bSXRz_3A)MS,_qR+AFQ-e)ACY-J&_@PAFAFQfiNE9O?B&AbcCJ?ZR+AFRgJHmXL&D Y-J?Ezb7O&QgO&R9YWL &? mQsO&ZEA)M-J?[wN7HXAvR9Y7S,__TAFRgS,_FF-7 q r?&)?D?FF?DF&F&F&?&]_qOsSXRISXQ-e+HXZ-b7A_fifiO&ZRIO?\R+YA & [wOb7A)H,_IO?\msOb7A)He9YAe+~&SXQKfffS^R+YtR9Y7S,__TAFRIS,_vKDZ-J?EzJ?Q7R9AFAbR9OwNE+O5b7Z-e)Awe)O&E9E+Ae)RE9A_TZ7H^R)_g\O&EJ?Q7GfY7S,e+YS,_JuyO&E9QfiA)MNE9A_9_S^ODQWLWJ?Q-bfiZ-_SXQKJw_HiSXK&Y7RqHXG[|O&E9Ae)O&[wN7HhS,eFJ?R9AbtJVH^KDO&EqSXR9Y[ODQA<eFJ?QtJ?Q-_qfgAFEIe)O&E9E9Ae)RqHXGs\O&EvAFB&AFE+GpCJ?ZR9cAFRJHmXL D&7 m|QO&ZEA)M-J?[wN7HXA&L7SXRgS,_gAJ&_qG|R9Owe9YAe+~uR+Y-J?R FI S,_gAFBVJHXZ-J?R+AbfiR9O)R9E+ZR9Y-CO&QJVHiHWR9YAvJD_9_SXK&Q[wAFQ7Rz_SXQF-7 J]Q-bfiR9Y-J?R S,_3\JVHU_Si-Abs@7G =n YAvZRqShHhSXRGsO?\R9YA_qAvE+AFNE9A_qAFQ7RzJ?RqSXO&Q-_FLPO&E+QA)MNE9A_9_SXO&Q-_CJ?Q-bse9Y-J]EzJ&e)R9AFEqS,_qRTSUe/[wOb7A)HU_`LS,_yQO&Re)O&[wN-J]EzJ?@7HXA&m}}JDe9YwO]\R+YA_qAE+AFNE9A_qAFQ7RzJ?RqSXO&Q-_3Y-J&_S^R)_JDb7BVJ?Q7RzJ?K&A_O?B&AFE}R9YAyO&R9YAFEmSXEz_qRLDR9YAC_SXFAO?\gR9YA_qAwE9AFNE+A_qAFQR)J?RqSXO&Q-_S,_S^Q-e)OD[wN-J?EzJ?@7HXA&m n YAFE9AuJ?E+A_TYO&E9RvyO&E9QA)MNE9A_9_SXO&Q-_\dODECfY7S,e9YR9YA_qAFRgO?\$e+Y-J?EzJ&e)R9AFETSU_TRqS,e[wO5b7A)H,_S,_gO?\WA)MN-O&QAFQ7RqS,JH_SXFA&L-J]Q-bwBDS,e)ACB&AFEz_9JLDR9YAFE9ACJ?E9ACJH,_qOvA)MN-ODQAFQRqS,JH_SXFAyO&E9QA)MNE9A_9_SXO&Q-_<\dO&EcfY7S,e+YrR9YA_qAFRfiO?\we9Y-J?E)J&e)R9AFEqS,_qRqS,es[wOb7A)H,_cS,__q[cJHhHwCJ?ZR9sAFRJHmXL&D7 n YAuE9AFNE+A_qAFQR)J?RqSXO&Q-_vJVHU_TOpbDShWAFEkSXQR9YAc_qAFE9BDSUe)A_fY7S,e9YR9YAFG_qZNNPO&E9RmsQO&QAcY-J?Q-bLyO&E9QA)MNE9A_9_SXO&Q-_|J?E9Aw[wODE9Aue)O&[wNE+AFYAFQ-_SX@7H^A&mQR9YAwODR9YAFEvY-J?Q-be+Y-J?EzJ&e)R9AFETSU_TRqS,ew[wOb7A)H,_IJ?E9AJ&b7B?J?QR)J?K&AFO&Z-_SXQwR9Y-J?RjR9YAFGwJHhHXOVf\O&EjA)l<e+SXAFQRgJHXK&O&EqSXR9Y[c_\dO&EJ?@b7Z-e)RqSXO&QuJ?Q-bwb7A)\J?Z7HXRE9AJ&_TO&Q7SXQK-mQfiR+Y7SU_ffN-J?N-AFEfgAvJ?E+AJ&_T~&SXQKwYO?fY-J?EzbSXRgS,_gR9OIR9EzJ?Q-_HUJ]R9A@PAFRqfAFAFQfiR+YA_qACE9AFNE9A_qAFQ7RzJ?RTS^ODQ-_FL_qOwJ&_R9OwAFQ?qO?GuR+YAC@-AFQA)-Rz_yO?\@-O&R9YWm- 8I5$U-?-jQR9Y7S,_cN-J?NPAFEfifgA_qR9Z-b7GR9YAe)O&[wN7HXA)M7S^RqGO?\vR9YA{R9EzJ?Q-_HUJ]RqSXO&QNE9OD@7H^AF[c_{J?Q-b&qImO&ER9YA_qAcNE9O&@7HXAF[u_`L}R9YAcO&ZR9NZRI[uJG{@-AfiA)MN-ODQAFQRqS,JHhHXGH,J?E9K&AFEIR9Y-J]QR9YAcSXQNZRm n YAFE9A)\dODE9A&LjSXRkSU_J?NNE9ODNEqS,J?R9AR9OJ&_T~fyYAFR9YAFEgR9YAFE9ACJ?E9AJHXK&ODEqSXR9Y[u_fyY7SUe+YeFJ?QcN-AFEq\O&E9[R9YACJ?@-O?B&AR)J&_q~_jSXQfiRqSX[wAfY7S,e+YS,_kN-O?HXG7QO&[IS,JHgSXQ@PO&R9YR9YAISXQNZRu_SXFAfiJ?Q-b{R9YAcO&ZR9NZRI_SXFA&m n YA_qAfiJ?E9AceFJHhH^AbODZR9NZRN-O]H^G7QO&[IS,JH}JHXK&O&ETS^R+Y[u_FmA)\O&E9Au_TRzJ?E9RqSXQKfiO&ZE/SXQB&A_TRqSXKJ?RqSXO&QfgAwQODR9AwR9Y-J?RSXRIY-J&_@PAFAFQ_qYO?fQCJ?ZR9wAFRIJHmXL &&7R9Y-J?RZ-_SXQKfiR9YAI_qAFRO]\e9Y-J?E)J&e)R9AFEqS,_qRqS,ek[wOb7A)H,_O&QAweFJ?QJ?Q-_TfAFECJ?@b7Z-e)RqSXO&QoDZAFEqSXA_E9A)H,J?R9AbsR9OfiSXQuNPO?HXGQOD[IS,JHaRqSX[wA&L7fY7ShHXAK?SXB&AFQwR9YAg\O&E9[IZ7H,JvSXRS,_gJ]EzbkR9OvNPAFEq\dODE9[J?@ab7Z-e)RTS^ODQ9&A)HX[uJ]QAFB&A_9oDZA&L &&7 n Y7S,_YO?fAFBDAFEb7O7A_QO&RyS^[|N7H^G"R9Y-J?RCe)O&[wNZRqSXQKfiR9YAw_qAFRO?\ffe+Y-J?EzJDe)R9AFEqS,_qRqS,e[wOb7A)H,_ySU_CJ?Ezbs_SXQ-e)AwR9YAIe)O&Q-_qR9E9Z-e)RTS^ODQSXQ{R9YAkNE9OO]\}G&SXA)H,b_vJcODE9Qfi\O&E9[IZ7H,JwfyYO_qA_TAFRO?\e+Y-J?EzJ&e)R9AFETSU_TRqS,eC[wOb7A)H,_gS,_gO?\A)MN-O&QAFQ7RqS,JH}_SXFA&mZE|[uJSXQE9A_TZ7H^Rfi_9JG_vR+Y-J?RfiJ?Q-b&qJ?E9AfiAoDZ7SXBVJHXAFQ7RfiR9OAJ&e+YtO&R9YAFELgJ?Q-btJ?E+AJH,_qOAoDZ7S^B?JHXAFQR|R9OfiR9YAue)O&E+E9A_qN-ODQ-bDS^QKb7Ae+S,_SXO&QtNE9OD@7H^AF[sm n YAuNE9OD@7H^AF[O?\C}Y-J?EzJDe)R9AFEqS,_qRqS,ewsOb7A)HU_b7AFQ7RqShaeFJ?RqSXO&Q+s L=S,_vR+YAwNE9O&@7HXAF[O?\ffb7Ae+S,bDSXQK-L3K?SXB&AFQJsO&E+QA)M5NE+A_9_SXO&QJ?Q-b"J_qAFRCO?\[wOb7A)H,_wLDfYAFR9YAFE FP mA_TYOVfR9Y-J?RyL&qIL5J]Q-bfisJ?E9AAo&Z7SXB?JHXAFQRZQ-b7AFEN-O]H^G7QO&[IS,JHgE9Ab7Z-e)RqSXO&Q-_FmwJ?[wA)HXG&LR9YAwR9EzJ]Q-_H,J?RqSXO&Q{NE9O&@7HXAF[u_kJ?E9Aw_qO?HXBVJ]@7H^A|SXQN-O]H^G7QO&[IS,JHgRqSX[wASh\J?Q-b{O&Q7HXG{Sh\R9YAub7Ae+S,_SXO&QtNE9OD@7H^AF[S,__TO?HXBVJ?@7HXA|S^QN-O]H^G7QO&[IS,JHgRqSX[wA&m n YA_qAuJ]E9AIQAFfE+A_qZ7HXRz_fY7S,e+YY-JB&ASX[w[wAbDS,J?R9AIe)O&E9O?HhH,J?EqSXA_ffSXQR9YAIbJ?RzJ?@-J&_TAb7O&[cJSXQWm"AR9YAFQw_qYO?fJe+HXO_qAgE9A)H,J?RqSXO&Q-_TY7S^NI@PAFRfgAFAFQkR9YA_qA}NE+O&@7HXAF[u_$J]Q-bCR9YAgG7N-AFE9KDEzJ?NY n EzJ?Q-_TB&AFE9_9JHWE9OD@7H^AF[ n m=SXB&AFQfiJCY7GNPAFE9K&EzJ?NYfiJCR9EzJ]Q-_qB&AFEz_9JVH-O?\S^R)_Ab7K&A_S,_gJv_qAFR3O?\WQO5b7A_3fY7S,e+Y&fifffi fft !t #"%$'&( )*+, -./01 23#4 3/fi 94+- C :;F'<=+/+9>*; 2>*.?<@^4'ffff$B C"%$'&D 2)*1+EF*&G<9ff82 H>*7I+J<Kffq4 ?;EL'.M ff0EN H;) ff?<O4+-'4QP@R+-*ffS9T%@*1-4+7 ; U0)V); :2.;ffXWY&QZX ff5=[ff\2]^_5`a +7?; # b1+7:+-*J.7cGTd$'e fEWY&Q4X hgji%-kX*ff5d[>\]^_56E"X>R+9?;%W;klff H22m2'FnH*om5[ff\\pq_rLXms0:*a;4*t4*.? ff; 9) bmT; .%+-q4*.u 90ff%*G ?)2;w vWYeE J*.Ggw&'> 5'[>\]x_5=y?*ff34+-*4R^; 5Q2.q ;)ff;q+9cWYP@X :g{znD9; *)5@[ff\\ [_4'TM4+-| 9q }<} ff;/ 2)*1+Xmff;7 ff)CPrX-~zn&+; *)3W4[ff\\ _4s"%$'&(.->*.; ff8 HH*17c { )*+<l>*Zff?; v<'+-2 & ty?a*ff4R ff|5?L'.mk7<+wvL'.vLQ9 ffbfiX/$Q.? )*+#52ff8ff34|*.?; -)`F; Lc lQnE-il%E ff;4 ?;=0<+7 &< );$B h4+-*4RXY E<}U"%$'& )*+2')`Iq 2ffE)`4<K-WYff+9Ggjk%15[ff\\0 P@XlgjznD9; *)56[ff\\`qkl> H2.XFl>*!5[ff\\2p_d.%q; J*J*St2s82 ffq; u }G*.c< 2)*1+%L'.I0#"n$X&N4+-*Ffft2%)I4 ffEq 2ffWYPrXg(znD9; *)56[ff\\_O$Q.'*.?*1ff%+a7 )*+9?<+j H0;' *J.?; Eff?L'./ff82 H>*7"%$'&(W! fi* +/.>*ff);4_ u { /& l{ h )*+m)0)*1 &-%=Z;d+7*1FI&Qff47; *5' ff+3k%a0W[ff\2\ _'> ff;7 ffv; ) Z4R 7; .>*d`=H3; +-:>*2;X+<g :"%$'& )*+#Qq'; L ?} % )*+'e{.Q?? *ffqQ?-Q"%$'&l y?I ?d LQ%+-ffc ?J< 7.-/0*1 +/.>*n>*2;X +<K'Qe-.-0I :0*1 +/.>*>*b^+j<K2n"n$X&l$Q.XQ)Eq ? fft't`# 2)*1+)kl> H2.XFff d>*!QW4[ff\\p_45L' } ffG#Y1+U*.7 fffiff;*Xfi</fYi/=y?&G0 fffiff;*XfiI)`H*^ ?; 4*; ff)a#4+/) 9Xff;*XBs ? 0);C #WYPrX ng(znD9; *)5[ff\2\ayS Gg!)02o5[ff\\p_d7XX4*.?; / ' 2)*1+lWYk%0tFn>*!5[ff\\_4t4|.; LQ:4*mHR?b 12d0<$ ff;Y*m]; 9 )*+9d$Q Xq? .Q4|.;ff 79"X4Rq ff|/L'.347 >2. "Xv b1+7-+-*J.? ffU<K2U} v4R ZffY12$B h2n 0<'fYi.4<hH*^ ffs -)| h;F%<>*J*d ;+-fi+-*J.? ff5@|+/J*.;*{fi :<''Qe*1ff/>*J*} fi ;+-/+-*J.? ff1ff}<B7+/+9>*; )bFff?.'; L'c ?? fi .';`ff.>*r;5`f;i/5Xe5at"%$'&%ff8 >*%'0*1 +/.>*ff);A$B 4<K25-UH*12;X + ff;7 ff})a#ff+9G}k%a0IW4[ff\\ _Q#)`;ff| hb* :Xe5tf;ic; +-l S2H ?$Q.dff;*XB09)`>*X ?; 4*9; ff7<+ff;*Xfi <K )b 12>*ff7ve#Tlk<K+W;P@X -gwz%&9; *)5Q[ff\2\ [_ #; LLQ g?' % +-7Q >*Jffc*m0Q<!+/J*t<rZ!82|r"Xt4R ffY12$B :;ff44*.>R?;ff: 2)*1+{<S42+- ; H**j l ;+-l+-*J.7B<K%:01 2"X4Rq ff|I$Q.fi.-}4*.>R?; <:Xe|4t|;+-+-*Jm0U #4+-4) ;.q; . +- 4*mAw!7 ffqb 1 0*15k v>*;X +<K2s"%$'&WY ff+gk%a5d[>\\ _0s)`9ff u.c )*+#5ff;*X; sE>*;X +wLQX "; +--4+-Z*4RaX; #`='.fi; L'5 LQ ff5P ?l)`&E4*.>R?;l &l 4*EI;* 2 fi / >*bff'<'eEf;iN v74Rq` b mH*ra0=s h|fi<$ /4ff;`2 9 ff;7 ?;q; *56LQh4Ym:74*.?ff} 2)*1+}5 &ffEP u n56LXm}.l-+/ l+7q2JV?; E<'e7fYi/$Q.@ )*+(.=; L'Il)n42Z!nSZ;d+-*F d$Bm?; ffj n*J7Bb+-<g -2t4*^; }E2 {/4R):42+-*4RaX; E< l )*+9fiTM H0;.fi<} .lff;*Xff 5'H*1ff# ff0ff7/ ? )b'*JX ? -Wz%&9; *)tg 1) 25=[ff\\q_ff567.'ff82fffffffi'a4. c I? q .co-NP-CompleteEOCunknownCMIHTR-CompleteSIDCCMSID(all PIs)HTRCCM(all PIs)sub-exponentialexact complexity unknown92d 79Qd-41;#Qffb14ff;E; -90;ff12 IQXav0: 9Umt.4ff6Q fi 3.%4!%=;d71'Q : 21}?.n-bff.>d;:0S nV07mff21>altY(E'QI`Q : 21w%'.%-;`ffmH;:0}Q.XffHH1}Yj' l /ff;;.4;E0n -X}4q ff|E.% ff;ff}t -;d>JO ;-c17.ffB -ff;l' 7cmca01ffXJH%tff4;vt4 ff/04;.;bmU-q4.ff4;`ff';-% 4Q `;ffhK9>J94 ffQ % 9S# ffb;Qff4;t2.4;ff? Q4.b12-;Q'JYU '4ff;`2 hff.| #Qff4b12-2.4;ffB n4m0;9: n%'~ #SG'4;dff;4Jmbt n0 ff?ff;ff 74|.fi /YQ-4mHb12%-ab12 ffGfiff4;t; n' .l4!nS!n06}ff4;E-4ff%QE-; -90fiffQ.dbff4;-ffQ X|.'4;0fiaq4ff?;> ?ff;S'.;ff1} l`ff>!#"$>aQ Q4-h Bb%&('!)*)!)+,&/>JffG;.ff.-l| -X/>U 2ff}a0&132(346587!9;:=<=>+?@&BAB 2ffl /%l?} :| 7aC&- 4>.'4 lfiHbm01&=D%Y? Hff}/aY1b12J>EAO2@14@ a; &=D1?Y% ;?J1>E- m0;'.=l2.G;F 4;J>. /fi%/.%.':42FY 4;t0.bffd 2d4-H?@&'BI &J*AKH?@&LMI &'NIO&P@.Q/%}/.QE;Q.;ffA.-Mmlt42YF 4; =J1>.O0stl%/.Umfi92.G;F 4;O9= 24-Q?@&'MK &J*AIR?@&LSK &'MKT&=P!=.'/l%E/.fiQt;Qh9MN- %/.%.Q'-JOU.b%17Qd?-a;? %a|;XJ>!3- /.%.Q74|. dfffi 4; EJ>Jr lJ>.%l `ff'}0laY1b12nQ -|:0'nv0sl% ffba0;U!V!UfiWYXZ[\]^_a`cbd+e!`gf(e!h,ig_kje,lkmb1i+ne#oqprHs(ecd.tuShvlawp`xe!`.woyzi+neOoprHsecd.tu%i+ecdvrT`_ko0i+neHd+ecfd+e!`gecoi3wig_kto1{}|~eyecoti+e.smR0#@Ni+neH`fi_kceOtui+neO`grRw*lle!`xi.8~dvecfd+e!`gecoi3wig_ktoRuEtdCM{o~w`+`fi_korQecoqi.//!!`vwig_a`fie!`._uYN@Y{Hph+n~wo~w`v`fi_korecoiO_a`#w*la`gthcwllke!ywrQtye,ltuM{%mc_krfl_e!`byecotive!y 1b1eRre!wo~ivnwiOecjecdvmrQtye,ltuC/_a`Hw*la`gtwRrtye,l%tu1{Ond+tpntpi.i+neHfwfecd*bYneco~ot6h,touEp`fi_ktohcwo~wdx_`xebe#_ayecoig_u;mwRtqtle!wouEpoh,ig_ktoTR_ki+nivne`xeci%tu(_i,`rtye,la`cbowrQe,lmN*33{Ys`gecdvjei+nwii+neCh,tooe!h,ig_kjev_krfl_ke!`+.p`ge!ys(ecigececo~ttlke!wouEpoh,ig_kto`}_a`Ye!p_kjw*lkecoiOi+tQi+neh,tooe!h,ix_je`gps`geci8tdCe!pw*la38p`ge!yu;tdY`gps`xeci3`Ytu%* {%nwi_`b~ _uwoyRtolkmR_uz/B{i+ecd+r_a`#woa}G3(MtuwQu;poh,ix_toMb_u M{ i+ecd+r}_`#wH3GHa}G3(1tuYwuEpoh,ig_kto6Mb_uS_`}woR_krfl_hcwoqi8tu0woyRi+neOh,to@poh,ig_ktotuSwomfd+tfecdC`gps`xeciYtui+ne8l_ki+ecd3wl`_ko6_a`otiCwoR_rQfl_ahcwoi.tu%M{hvlwp`ge#_a`YwoG}a,EYtuwu;poh,ig_kto0Mb_u%~ ({ hvlawp`geO#_a`Yw3GHHa}G3EtuwuEpoh,ig_ktoMb_u#_a`8woR_krfl_hcwi+eHtuS0woyRivney_a`Ggpoh,ig_kto6tu%womTfdvtfecdC`xps`geciCtui+ne8l_ki+ecd3wl`_ko_a`YotiYwoR_krfl_ahcwi+eHtu%M{fii_`e,ll1ot}oTi+nwi!bqw#rH_ko_krTw*l.8d+ecfd+e!`gecoi3wig_ktoRtu_a`YwHy_`;@poh,ig_ktoztu`gtreCtu1_ki3`fdg_kre8_krfl_ahcwoi3`c{ r_o_krTwl%80d+ecfd+e!`gecoi3wix_toTtuR_a`wh,to@poh,ig_ktotuN`xtre8tu_i,`%fdx_rQe_krfl_ahcwi+e!`c{uQ_a`rtoti+toebivneco_kinw`w.po_ape.rH_ko_rRw*l.80d+ecfd+e!`gecoi3wix_to6p`@_ow*lli+neCfdx_rQe_krfl_ahcwoqi,`,3bwoywHpo_apeHrH_ko_krTw*l8~dvecfd+e!`gecoi3wig_ktop`fi_koTw*ll1_ki3`}fdg_kre._krfl_ahcwi+e!`3{E*cGc!G011aneH_aye!wztuYp`fi_kohvnwd3wh,i+ecdg_a`gig_ahQrtye,la`Hw`.wqotlke!yeRd+ecfd+e!`gecoi3wix_to~Yw`}_koqi+dvtyph,e!ysqm.wpi+Reci!{6wl{3!3{%nwd3wh,i+ecdg_a`gix_hQrtye,la`Oecd+e`gi+py_ke!y_ko H@8e!hvni+ecdMe!wdglb*.w*jqjwy_aw`Reciw*l{kbO!Y8nwd3ytoti+n1b.!=woypoyecd6wy_1ecd+ecoirTwo_uEe!`gi3wig_kto_koywi3wsw`ge.i+nectdvm@ececdg_eciCwl{b1!(q0woo_lawTYw_nw=b!(Ctiviglkts_s_ko1b!=_ki+ecd8ti+iglkts1b!b!3{1n_a`M`ge!h,ig_ktoHye,oe!`h+nwd,wh,i+ecdg_a`gig_ahMrtye,la`woy8i+ne,_kdMsw`fi_ahfd+tfecdvig_ke!`c{=td%1,0! beCye,oeCivneGE*+c3*Ea.tuBwoy#i+tOs(eCi+ne8w`+`fi_korecoiYH0*`gphvn6i+nwiM8_uSwoytolkmR_uS=MOwoy*MHE_{e{bqivneOs_kig_a`ge.lkt_ahcw*lwoytu%6woyz{,{=td.w`geci.tuw`+`fi_korecoi3` b( fffiff,+ _`i+neTw`v`fi_korecoi.eHeci.sm_koi+ecd3`ge!h,ix_ow*lli+neOw`+`fi_korecoi3`_k{M|~eO`+w*mTivnw~_a`.g q (_u%i+necdve.e q_a`gi3`}6wo`gphvni+nwiYwoy6!("fiffff,v 3{Yi+necdv_a`g#e _`#% $@g &' (E{neO!( qgt)u =! byecoti+e!*(+-,.fi*'/ %3b*_a`ye,oe!yTw`%ivneC`grTw*llke!`giY`gecih,toqi,w*_ko_oivnwi_`8hvlktq`ge!ypoyecdY_koi+ecd3`ge!h,ig_kto1{Nt_llkp`gi+d,wi+e0i+ne!`ge0ye,o_ix_to`6h,to`fi_ayecdzi+ne`gec10 $q*!!+c{nec20 _`ot%o Ed+e!ypoywoqi!3b ( fffiff,+" 0 !bwo4(+-, fi!" 0 q!!*+c+c=c!q{Bec65s(e8w 7}td+oze fd+e!`v`fi_kto1{.ne`geciCtu%i+n*e 9,~; :qg!E*3cEaH ! Yt<u 5/byecotive!ynecd+1e (='>?" 5Y_a`Hye,oe!y w`i+ne`xecituCrtye,l`#t@u 5 i+nwiwd+eotiivne_koi+ecd3`ge!h,ig_ktotuti+necdrtye,la`YtAu 5/{Ytive.i+nwB(='>?" 5_a`}ot%o Ed+e!ypoywoi!{%=td+rTwllkmbz45(=>C"5=4(+-, fi*'"5ED}CF3tdYe=wrflkeb'(='>?+q!=!!3!3!1 q*!!+!*q{fii_`e,llotYoRi+nwii+neO`geciYturtye,l`tGu 7}td+oe fd+e!`+`fi_kto`_a`8hvlktq`ge!yRpoyecd_koi+ecd3`ge!h,ig_kto1{n_a`8d+e!`gplki8_a`8ypeivt0hc}_ko`gecm~,!q,bYntRfd+tje!yQ_ki8u;td.wRh,ecd+i3w*_kohvlaw`v`8tud3`giYtd3yecd`xec%oi+ecoh,e!`c{ lu;d+e!H7Ytdvo3!=h,to`fi_ayecd+e!yRw8rtdveecoecd3w*lhvlaw`+`Mtu1`gecoi+ecoh,e!`c{@BecrrTJw IYsK7}td+oLffM(NfiOBP%Q%RST%U&Q%VCWW/XYP%R'W[Z%R%\^]`_%Z%Q%Zba?c%V&Q%XdWc%XYafegPh\'V&i Wjkfflm%k npo?qffrsYtvuxwyzyz%qx{%|}&{'}?t~wy w}&'rsp(r&t q&)qff/zCy/q(|Gr 'oHqffr | s'jkl&l&?n3{%|qfft q(?yAr %}&yz%q(|{%|}?} '-}&|yz%q{%|}&{}Ct~wy w}&'rs<(rt q&n}&|q(} &q(|pt~w'q8/z'r |ryq(| wYt wY#}%o?qsYt(r {%y/%|q#rssAyz%qJw?-}&|*r w}&r }&%yByz%q/s}Ct %|/q&'yz%q(1rsYt }8(r{%y%|qKr.ssyz%qw?}&|/8r w}&4r }&%yByz%qB}|1qb{%|/qfftt~w}&3?p'2f3p(*?'~-A?'33*b'(%?' C3@'/@&1(/p (d&dCg!(- ff j (C jnnpdp(3p?p3#p'' (% Y;ffYbdz%q#}&%}y}&%qy/z%q(}&|4uBr&twCy/|}bo?'qffo?xt z%}&%yjkffl&l&bn'r 'ouBr&tsryq(|'tqffo}|6rHyz%q(}&|-}&|#}bo?qs-'r&tqffo|qffr&t}&?w%j"z'r |o?}x}&yzkffl&l hnz?wYt8tqffy w}&qb{?s}&|/qfft#yz%q*|qsYr w}&'t'q(y uxq(q(4y/z%q@#}&%}&y}%qyz%q(}|gr'o4/z'r |r&yq(|wty wY#}bo?qsYt('t'rsA{'r |y wYrs}&|o?q(|*<ff(# %1*&'&-8;1dCkCH C&` &.% k 4 '*&'#fiffff'.% k #< &'1'# !"#$&%-@ff 'd?&&Y-d&(ffC ) 1J(&#dC*,+ &'*&H ,-&.01/&@& &2Cy/?wywqs&hw!3ff yz8?wy wYtxyz%q@%}&|*rsp}&|o?q(|54w k&6 7h}&|Bq'r #{?sq k k 898:8:8B k & %r 'oyz%q(1y/z%q}&|o?q(|B|qsYr w}&1}&1y/z%qyz%qJ}&|o?q(|B|qsYr yw}1wYtB|/q(&q(|t qffor 'o1uxq@z'r&qy/z'r y@kk kz%q; q@%} u o?q ='%q?>/ 8:8:8:`8 k&k <&&-&'H(.-%(Y4 @ .%k>CED,- @?GF&&-&'H(.-%(Y4 Huwy/z1|qfft {'qffyy} >z%qBj Hnz%qt q(yuxwyz1|qfft {qffyy/}Bj @?nd?&Kd'C1(HdC#& &(ddC*--YJ.% kff?}wBj Hn8:8:8:8HLKff 1d'M& &ff'd 3Huxwyz|qfft {'qffy7%}|Bqhr#{?sqR q(y&HCIDJ&- @2UT VjOT(Vnj@ @ Hj k k n8:8:8:8y}>,N"?N H @ +/ P G F'(2. k k && k k %& &jk&k & nr 'oQF2 k&k &% k &h k &%& &HH n8:8:898 jBnxyz%q(wyz%qt q(y8%}yr w}&. k k & k k &h&& % k&k % k & C@ HGFz%qt q(ywk&k &% k kC)r 'o8:898:8 Bj Hn2 k&k &% k kC&r'o*yz%qKt q(yXW9W:W 8 jBHn 2. k k Csqffr| s&}|Kq(q(|^r&tt"w%#q(Cy & % k H[Z j\Hn}&|q(} &q(|3w ] / Hvyz%q( 0 /H nxj"t~w'q wYt yz%qt 8rssqfft y@r&tt~w&%Hq(CyBuwy/z1|qfft {'qffyy}#y/z%q@}&|o?q(| n z%q(|q}|q?>jBwH^`_?a cW b 89d:eBj Hn f^:_?g hBj HnFji%qfft w}&HwYt`wGuxq@(r =''o1rt *rsstq(y<}%q(Cr w&q@q'r #{?sqfft(%r 'o*'tqwyxy}|q({%|/qfft q(CyHr&tz%qr }.q&k5l5lfimnopqsrt1000101110011010110000001101111000010100111100110101011000100111uwvyx?z{:|!}~?z\vyxO!vyX9BwLX&BwOy5[I'X5MLc5syX?`v?{E , `C\PcG5M? jMyj&:c?'?wMGQX?JjOBw9Lc?5L`vyx:QvQ| XQvy\vy?s|#x?|cLy:|c{:XLv|#{:|c{:|5\|cQL\vy?O?{zX \vy?X&`LBwPS`LBQB}Qv s\y5vGL,:XL:|\|c#L(ECL5| vyx?G BLGJvOX?`v{3LQ?{:uEzX \vy?#u?{| XLQy| ?X`vQ|c{#:|{:| {:|5:`vy?( BcJ:BcU:BcJv: zX:\|5vy9|vQ:{:QzX \vy?|5cP:XL:|.9L\v`?vyx?9`vyx?|cQL {:|?~& QBP[C???J??J?:L5:c?J:c?c5?Lc?Q?c55Qc??Q5L5L5L?L?(|PX?|P: ?Uz:|:||cs!vyB Q{!|c{:| [G???5??c?c?c5Q?:?LLG?:|#:XLv #9L\v`X|5:|cv BwP CQ X& Bw U:XvcJ \9ff sPLfi|c{:| ?{:|?Q!vy \G??LG?LXU!vyc\PQ?5LQ|#.9 z:|:|3|cL!vyQvO?:`vyx?|cQ3vG(Q{vyx,:| ?{:{9|5\X?Xvyx,L:\v |5'LX?\vyx,:|{:| L\vy?X:|c{:|?Euwvyx?z{:|}\L':|OL:\v |&vy:${9|5\X|5 9],fJ???fi|9L\v`?vyxI?9`vyx?|cQL L{:|!L{:|5Ovy(X ? |?fi|!!vyQvO?:`vyx?U|cG#{:|jzXQ|c{\vy|5sLX\|jL:|?{Q|c{P{9| \vy?XcQQv:O\L$:XLP:|{9|5\PLfi9|?:`vyx?U|cGP{:|?P!vyQvyL{:|Q{fiw?z9|# \|#X?|:?&G&?:`vyx?U|cGQv9&vLXL?|#9|#!vyQvO:`vyx?|cQcfiQvOvO{:?|5G:|IQ?9:|5Evy|5,Qv: C 9XL?LX??IL{9|vy B`vyx$:|&Xx?z{9||,?X\|c{:?|,:XLvB &G???J5?:?J Gfi|,?:|c{&\|cOL{:|!vy B [G???5?5Gc5G?LXO!vy B PG???55?c5Q5QQ`vGL&:X:|j`v c|'L:|X?`v?{'zX \vy?vX?zXQ|5G9|j`v c|#Lvyu{:|c{:|5|cG\vy?fiX9XL?{|c|c{:#:|`v c|!L!vys:\v?zXQ|5Q&:|`v c|!LPvy #u{:|c{:|5|cG\vy?uJ?{LQzX \vy?LX,\|cLP?:`vyx?|cQ y|c5~! !vy Bw#" `C C!!vy Bw:G$%&fi')(+*+,.-/+01*+243356(+,7398+,+:<;>=+8+*+8@?BA+21*+5C3A+56?EDF(:721GH3IKJ+LNMOHPQPOSRUTWV+XZYJ+L[O1\L[]^XHT_1L`NaHVbacPYL[\V7aHYTW_dL RUacefYOhgBLi7V+Lkj[lm4ndoffp.qrsutvBwxcv7y{z}|~t7xHww7Ht 4+ZK^Z 1<[6d.4c j[l7mBndoffp.q)O1V4YTWVBBTV+X<YJ+La7OH_1LL7aH]fBPLRKTYJYJ+LM+V7YTO1Vo[jqoffj[cqoff[jmqRKLbO1V7P7gBLbYJ7aYj[lm4ndoffqfS1++Sc[1+H[+[1[1+[1[+1[dSdH4r `uYJ+LZMOHPQPOSRUTWV+XYJ+L[O1\L[]`J+OHR`>YJ+Lk`L[Y)OHMJ7aH\a1YL[\T6`YT6 ]fO+gBLP6`[aV7L7`LgYOhaV7`RKL[\UgBLgB7YTWOdVd+L[\TL`[rsutvBwxcv7y|~E[vB7.47~t7xHwfwHt4+< pfcfpf[[C1C4c pf pf 1h1Qf [116 j[l7mBndoffpfqpfo q1YuT6`f7`LMBP YOJ7ac_1LYJ+L \L[+\L`L[VBYaHYTO1VOHMkaM+V7YTO1VrM9T`XHT_1L[VTWVTY`Z\L[+\L`L[V4YaYTO1VYJ+L[VTYuT6`uLa1`eYOO1]f++YLYJ+LF`L[YhoffqMO1\faHVBe<Hr<>a1JYL[\]TWVYJ+LN\L[+\L`L[VBYaHYTWOdV<[aHVO1V4Y\T++YL k OdV+LFa1``TX1V+]fL[VBY]uTV7oqR)J+L[\LZYJ+LZ_SaH\TaBPWL`YJ7aHYKaH+7La\TVhYJ+LYL[\]aH\LUi+@LgZaHV7guYJ+LNO1YJ+L[\`aH\LN`L[YYOYJ+LT\K]uTVBTW]ZacP_SacP+L1rIKJBT6`T6`>Y\+L`TV7LM\Od]L[_1L[\eO1YJ+L[\k`aHYT`ffMedTV+Xad``TX1V+]fL[VBYOHM)YJ+LYL[\]RKLh[aVR)acPgBOSRVYJ+LPaYYT6LYOHR)aH\g+`KYJBT` ad``TX1V+]fL[VBYO1Vaf7aHYJOd]f7O4`LgbOM`aHYT6`Me1TV+Xba1``TX1V+]fL[VBY`[r +O1\LaH]BPWL1YJ+L]uTVBT]hacPad``TX1V+]fL[VBYMO1\uYJ+LYL[\]f + RKTYJ\L`LYfYOYJ+LZ7a1`T6`uLPL[]fL[VBYhd+11T6`u]uTV7oqu41+4rIUJ+LFa1``TX1V+]fL[VBYFd1 R)JBT6JaSP`O`aHYT6`i7L`uNT6`uV+O1Yu]uTVBT]hacP `TV7L1 d+ 11r +\YJ+L[\>O1V7LRKLJ7ac_1LO1V+Lba1``TX1V+]fL[VBYuM\O1]La1JYL[\]bTYT6`La1`e]haH1L`+\LYJ7aYhYJ+L`L[YfT6`EV+O1V \LgB+V7g+aHVBYbBeJ+LdTV+XR)JBT6JOHMkYJ+La1``TX1V+]fL[VBY`X1L[V+L[\aYLgT6`>TVYJ+LNTV4YL[\`LYTO1VbOMYJ+L O1YJ+L[\`[r L RKO1BP6gZ7`L YJBT6`)acPX1O1\TWYJ+] P6aHYL[\>TV`O1]LOHMO1+\)\LgB7YTO1V7`[r.Lk`aceYJ7aHYNauM+V7YTO1V T6` ]fO1V+O1YOdV+L TQMTYNT`N]O1V+O1YO1V+Lad[O1\gdTV+XYOZYJ+LO1\gBL[\\LP6aHYTWOdVg ff) YJ+L[V<fio q 1rZ)O1YTLZYJ7aHYNTQMRKLf\L[V7aH]fL[rZaH]LPWe1TQMR)J+L[V+L[_dL[\ko q haHV7YJ+Lf_HaH\T6aHBPL4e TY`V+L[X4aHYTWOdVMO1\ La1J )`7JYJ7aHYk EoTr L1rfRJ+L[\LhYJ+LfO1\gBL[\ \LP6aHYTWOdVT6`Z\L[_1L[\`Lgq)YJ+L[VLO1]fL`Z]fOdV+O1YO1V+L1rIKJ+L[\LMO1\L1) ]O1V+O1YO1V+LEM+V7YTWOdV7`ZL[V ffOHe`ffTW]T P6aH\+\O1L[\YTL`[r+Od\La]fBPL1HYJ+L[eJ7ac_1L+VBT6d+LK]uTVBTW]ZacP NaHV7g Z\L[+\L`L[VBYaHYTO1V7`[rV+OdYJ+L[\+\O1L[\YeuT6`KYJ7aHYKYJ+L ]TWVBT]haSPa1``TX1V+]L[V4Y)RJBTJbO1\\L`7O1V7g+`UYOuL[_1L[\eZYL[\] T6`>TV7gBL[Lg7aH\YKOHMYJ+L`L[Y]uTVoffqru17d17>4C1 C4u 1|~t7xHw fwHt)B71 17#[@11C4Ck6Q 1C 1hCBucu6 oq "!1uc $#% '&[1 (cu 6C4u66u1*)+!,[[1C1Nd C4H[.-d7uuC oq Cu6 offq%0/ & u6 offqd2 14365offq.L ROdBPg acP6`OZ7`LYJ+LV+O1YTO1V OHMaPLa1`Y)++L[\ 7O1+V7g OHMa87>OBOHPLaHV +V7YTO1V.o:91LP]haHV ;< aH+Y:1= ?>$>+Hq1R)JBT6J[aHV`O1]fL[YT]fL`U7LkJ7aH\adYL[\T@=[LgBehYJ+L ]fO1V+O1YOdV+L J+L[O1\e1rvCBD?w|FEv4G4HJIKIv+xL:Mw,N FO PQHb Q)1Q14C1+SR)T(cJNUu[1fC41WV OX H[Y[ d@uC4 117Qf 6Z V1C4u[ \ bC41Z [D]V^?_?`fiacbdefhgijkhlnmpolqsrutFvwkpxoyWmDz|{~}8mk,\rDK:$8c$F$\? $6$8J.F$ hc?$$n? $*YT '@c4Dn?K ? $F8\XfiFX$?:$n+Y2 ? X0' W*$,:8'C:,"$:6'?:0@$?C8c":'?::@?$$hfi:8C$:$:C:$J$fi:?$F:$jkhlnmpolqtFlCklo{,lnxoYnpKvxhplnxX\pDvwkpxoyWmDz{}mkY\rWD? ?s 'c$F$nTCpW\?J 2D? W:C n 2D?$,*nJ$0Tn:@$ff fi*@$ : ?+K'$:0@$8nFcC $c$c$$C"$??? *?$?$ $$$': C: 2?pj kplmWq pxmDzhxo?m Klq!finT ?@$6@'@n?8nn@@$ $''$n@4CT:: ?6@ :nT? "$#4%& :?:fiCff "$:P$:6@4\ # @F 'F$: T8nTfi:F0T@$J:$n@4,$0Tn:?6'$('*) % $@ % FC:TT$+ nT,8"$: %-& #ff:? :,n #.0/ 1)32 ::::4,n\ 5p@$ % $8 c$'76:?:0@$,8 c$'0@$8nF8Y:?X8cC: %& 9#''8 \ #: j}7) "n:$;fiWFCF:T < .=? C>+ $C:$$6:?:fiC,$$:$ %& ff'?:0@$;?:?X8$$'$ < & P:?:0@$1@: :?BAC@fin?'T0@$6:$n@4,CT::?h(' / ) % FC:TT4+ nTD,finnEp@$,8"$: %-& #ffJ8GF 'T0$@J$:0@$8nFH#ff:?HIY?EJn # > F& $:$Kfi+$C@@$T L$n@nc:M#ON F $ ?:nTJT:(F n #PRQ S) 6 \\, % @\ :,8"$: %-& #ffTF $'0@$8nF:?HIY?$n@U#ON FV TC':,:,@ \c % +W,' / S) % $:TT4+ nD,finnEp@$6@: % $\'c*8n@(,8"$: %-& #ffTF :T0 C@ C:0@$8nFK#:?,4?n # X F :ff$:IY? :'T$$: & n@ $n:8n@(YWZ7?\ # [ F8\]^fi_`babcedgfbhiabjlkknmo`bckRpbcbqsrutbpbabpwvyxbjiabmzk{xbmov}|~`qjikEG K 09K7g94 0bK0004UlibT-b{Myb$ii{bUnnybiMogffnS{-{$nbib{bb>ffb{Go {TnSb4ff n(${7Myyi0Gn{i7>{youo{bGiyS3{}T{iibTGG{bT--3{blDynoE71iyyw5iMoibi{b7b{b4b{bb>b{iyo-byob;yb $n{T7i{boib{bb4lbMoffi{bXEuMi4*i{n71 Dyn1oGybiMou{b$gffbbbXib{bbUffyffo-{bMi4-{7G41b{bWib{bb(b{yobibyobyb T-1ioy7{bb{{nMo{y ib{bbTKUbbb4 KM{ {T;iinboTb{bbybiMoiinbiT5uXTi{{1 $DynoGlbig1{b(M3ffbbbS{b4$ggeTbinT{UiDi{bGib{bbuo-bi-byoib7yb{b{obbybMMySg{bnliiDi{bieUyblbMownyi0ffn${gnT4inDi0-K-0bbG{ynyEEo{4{(ibi0 yyn b{iy-oHw5iMoizE$ilEU{$Rb{iyUX53{b{o7ib{bb7lbMoi{b{7i7D1biBi{}{ b{bbybiMo4bb{ibb}i ub yX ybiMoTib i9nbS{bbyb 4{bbb{bbififfff fi!"ff#$%'&(")*+ff{yoUiGb9{K{b-b{iySffyiMWiWn{-yybyybiMo3{yi ,T ibin{ob{iySG{4yRWybiMoKEiyE>nb(i{nibynoi1b{iy -7HoTy47lbMo>iy/.10#2 ulE43565798;:<>=8?579<@8i57A<B5si$DCyFEiEgyHwiEiMziHGiyzi*3JI$ "KDL -bb{yboKyEobMS43 S3 noyU-b9{UWnNWOMiPMWnT7n$-7MQMW{GbnRMBybinSnoGybiMoE{yny {U TWV SX V Sb* VY" VVZM{ii[ C]\^0_2 DlE157A<B5C`3-biEiMzioE iyE$ 2 DlE1579<aIb i{-b{ybM{bb{y0ioy-bC45o-{yuoU{yiK{bT{yE5b{iy {X{~Bibi03yw,Tib ynoi1b{byb{4iTnoyEE1{ in{T7i{b*{-b{oibS{ib yu5Ub4Dclo-ibbldDegfihkjJl@mfimkl!npo>hkl@qsrJtDhFuvtDrJw_x_jHuvyjxfilzqBt{rBt|hfi}BwkljJl@mkl~omkl6kl@r}J-l@mohFuvt|rxfiuvhkj6t>nvrBt|upongqBlnpoorJql?r}B-l?mFo>hFuvtDrxfiuvhkjuvrJy@mkl@{l@rhonzt>nvrBt|uponqJl!npo@;uvhkl@m6it|hkhFnvtDidDa!e4#jJl@wkl6mkl@}uvmklhkjoh-hkjJlOonv|tDmFuvhkjJxfiunngy@tD-J}JhklhkjJllnvl@-l@rhkwt>uvhkwt|}BhkJ}BhztDrJl6oh~o-hFuv-lDUorJqsmkl@wkhkmFuvy@hhkjJlhFuv-lqJl!npo@4l@hFxgl@l@rsy@t|rBwkl@y?}BhFuv|lt|}BhkJ}Bhkw@egFrJy@mkl@-l?rhon*tnvrJtDupo@n"qBl!npo@onnvt>x_w#hkjJlqJl!npo@hktqJl@l@rJqstDrOhkjBlzBmkt|Hnvl@'wFuv@lo>rBqOtDr6hkjBlr}Jl?m#t>*l!nvl?-l@rhkwiy?tD-J}Bhkl?qwkt;o>m@e"tnvrJtDupongqBl!npo@6uvw#wkhkmFuvy?hkl@mfiuvrhkjohfiuvh_mkl@}Huvmkl?wiqJl@l@rJqBl?rBy@ltDrnvt|rhkjJlJmktDnvl@'wFuv@lDe_"tDhkjt>*hkjJl@wklrJtDhFuvtDrJwo>mkliwkhkmFuvy@hkl?m#hkjorst|}BhkJ}Jh#tnvrJtDupo@n_o@nvDtDmFuvhkjJ-wzwFuvrBy@lhkjJlinpohkhkl@m_6o@x_o@uvhonvtDrJhFuv-ll!`t|mkl-y@t|-B}JhFuvrJuvhkw#mkwkhtD}JhkB}Jh@e_rHtDmkhk}Jro>hkl!nvD*-t|wkhit>fit|}Bmzmkl@qB}Jy@hFuvt|rBwDuvl!nvqt|}BhkJ}Bht>nvrBt|upon#onvDt|mFuvhkjB{w@UorJqsxfily>orJrJtDhi|}o>morhkl@lhkjoh_hkjBlwkhkmkt|rB|l@mirJtDhFuvt|rBwzjBt>nvqeHe"_johuvw@oitnvrJtDupo@nuvr6hkjJliquv-l@rJwFuvtDr4tXhkjBlzBmkt|Hnvl@`hkjJlir}Jl@m_tU|omFupo>Hnvl@w!hkjJl#uvrJJ}BhzwFuv@lDorJqhkjJlt|}BhkJ}BhzwFuv@lDeJJfi6***fi*-"B-k>;6J"s"_-U*W"fi`_;i>@;!g("@Js>*-J;!`*>XDJ*>"">"*J46*D@;>""s>@;!`*4>!`*Uiki`Ji"z-6;@*"@`>*>">`D;`*k>;s-`>W'JH*4k>;ss;>@;!g"`#"O@;!k`*>!`*i`6;>*iN*#W->*>*6J;!`*>XDJ*6~>*4"@--;-J->*-s*>"O"6@;!k`*$!`*-`6;>] N*ki>*O"@--4>*!`"D4;->@;!g`"@"BO4@;!k`*>!`*U6;]D`>*-k*"]@*"@@`>*@`6;W"DUJ6>*D;@>"D{>?`*R!`*Ji6{s"Bs>>JD*|4-`>9>;-*>*DJ*>4D`;pk4`>**U@6-"B>*-DX*J>!`$?#{B>?6;s;z@;!g`_""4>@;!k`*s>!`*U_-@*"@`>*>{N>-z @B>? D|">*A>*J;!`W*>*DJ*>6*"@--;6J_">*>Dk>s-DU*-`>W*DXs@*"@*>>> W4**J;!`(*>XDJ*UB`__">*"@-;s"*>D>{D"`"$"s-4"@4@*"@*>$`"@J]{*-;-`D* W>*AD@`U*>"">"66"@->?*J]"B`>>*--""*4>@;!k`*>!`*UON*(4-;9`>"@>*>>@;A*>4-Jfi;`Ws$s*D"-4**6@k>>;O*"@@`>*@`9*>XDJ*J!`U>>*D`J>H"->*s*U@*O@>`*$!`;4"*Bfi `|@"@->"--"J{s@`ik9D-*>Dk>g>*O"@-_;Ji--"B4**>`Afi-W!``W"@-sJs*>` @;@J`W*@6*>>*"@-"i>;-@9i;"*UR>B`*"**ff9fi "{*;D*>D>$p`-4|***s9 N"]@`>*>$@`9D*W>*D`***J"" >`J6J->`$J6>*-;@s-O*'>"->*OD`|" ( {Ws*J>""@"XD~">>*>`s->*s***69fi"!;i"|@>*-J?|@s"""`*" !#"%$'&%(?* )B>*O>!`*;,+.-0/#132447k6>*65 N !#"%$'&38(?D9 JBz>*s@*"@@`>*@`@;>k>"*""@O"- s!`;O@*"@; :@`]->*<-!``]"@k> >*@*"@@`>*W>D**>J>?W= _"k-OU?>,996;>>HiN>4->*4 = iW4;B`P>"->*>;6-`>*J>k|-`>] p"`p*>;O-`>*J>k@== -;-k`O-k>>*D6>"W !#"%$'&38(?"] "`AW !#"%$B&%( = |_@4"J`4AW !#"%$'&38(?D@">"-*iC )pED3 F(B%$'(J Ffi GDU"HIAGW>*HJiX">*D!#"%$'&38(J = |W !#"%$'&38( = {>*]A!#"%$B&%(?|--*>Dk>{*>s;-`>*JO9-`>]>*9{s]>JD6>;D-$*J@U*-`>KL= =`***6;`-p>BR*|*-J*O-ks**6!A>;s9DU`]>*`U*>>' N`>J`J@s*D`OG PH ***s-4"B*k>@`]]>*4>*sD`UD-*>Dk>-A*"@k> >*>JD*|!``>*6*>A@*"@*@`'4 1>' N`>Jfi(`|D*s>;s*` "!`*A*4k`-`*`>|*>*DJ*>]J@|4->>>*>]*>@;`>]4BD>->*DX@`J>D@`J4@*"@*@`*Rk>*4"{"@QDU-49*>*DJ>*s*DXO|B R@"@-D>k`*@`*$>J|-k6>*6*JSD|>*"@--;6JOBSD*>*9{s*TVUXWBY'Z#[#\']^Z#_`Z#]*a[#\']cbedf`g#]^h<ij`Z#_k`*lB]Mbfimfilh']^Zonfp] YBgonfl'qff[#\']c_ `l'`[#`l'][#\']^`Z#rQs0tu\%mfiZ#hB`*l,vxwy`[#\Ca;zfi{{fi|}JhB`]^gl'`[~g#]^]^_k[#`%].Y'g#]ijYdjU''fi;;L~;C;0;;;xc;;;;C;ofi;0C%fi%#C,'Cfi0@;C,fi'jCA8Bj;e%'ufi;;jfi;'fijfiQKCc^fi;Cjfij,jfi;'fi0fffi;<C;,CfijCj;fiB~fi;Q%%^0%j'<fifi;fifi;Q;'fiA8;B%'fi^jC''fi;Q%38Q^;^^jfi;^jCVXCcfi;,C;fi%jQ%c fifiCfi;<C^fi^jC,jc0 j'%fi ~#8B%%^,*B;;fi;fi'jfi0<fiQxk3LJI,8fi<fi0Q^fiC;C<Cj^jCx;;VC;;^;C'u%jL^xfiQk3'%B'fiM*;kj'%^jk;C,^;CCfi;0^ #%'3%%*?y@IJfi;kjOe3B%''fiM~ *3%jC.Q;Kfi;BQCc;fi00ACfi*C0^jCJjjkfi;0C^,fi;kfi;BjCC;#Cff *jCCj'fi%;fi<8%'ffC03Q^fiCj^^?Bj*Bjj;jfi;'fiL;@fi;,;fi%j;fi;;^jC@ ,fiBfi;;'^'jAfi;fifi;^jCJ'Bfi%3 8C;'*;'C'C;%'''%'C'%'CC%C%C;%^;;3^Q%^I ffC; 8C';'BC;C' C'%;C'8CCB~%0yB;;fffi;; ;B;CJLfi; ~C@*%y;j<'c;C.jjByfi;%*Cfi^0;0<%^* ce*fifi;;fi%IQ?^%*fiQ^;^^jfi;C;ff#C'C8^0%j;^^jfi;fi'fiCcC0fi;^;^jfi;^jCE 0,0;fffi ;*%fi6'BC;B'';''C%Cy;fi^fi?% Afi%fi;8%^0%jA,CQ^;^jfi;fi'yAfi;%j ;<C;fffi%fffi;fi0QC;fi<%jefi;CjC; CB;0jC;;ff;Cjx#%'% <*X;fifi<jQ%^* '%^j;,C;BjCC;jfiCu#CfiCM8 Jfi;#Cfi%^jC,#fiC fi;Cfi;^;^^jfi;fi%.fi;C0fi'jB%C;Q;<;<^fiJfi;<;;<^fiQ^;^jfi;fi?fi'C%M3*%*3cMC0*^;^;^;^jC#C30Cj0;^, %8'BC;*B';*'C%;;j;@ fi0<Bj,,Cfi;<%^.'V jE#%'% <McC0;%fi;<^;^;^jC#C.0cCj0;~%'BCCB'CB%;;j; JCcBjc C.fi;% ^jCBCff0ffC;fi%j%*.Qfi;fi#Cfi<';*^<Cfi08Bj;Cfi;A;*%^jCfi ^;^^jfi;^jC%O#C%Cj0 fi;%^.'<%fi;fi#Cfi<Q^;^jfi;fiQ,fiICfiCfi;8C;fi%jE;'Cj;kfi0%jAj0'^fik^Afi%;Pj;8;fi;;j;^jA%,fi;fi'^jC jjfi,3^j;kfi;%fifi^j;;fi'I#C0fi''fi;%^.';'^A%fifi;;'QBCfi@Cfi;8Bj;xfi;y EIBxEfi% fi;8^0%j'C;ffC;C%Ifi';*<C?;* %Cj0;; % .0fi'jfi'CjAB0fffi *!#"%$'&)(*,+.-)/102(43ff56879;:<*=->02?A@->39CBD0C02?E+.(GF>H)I49J/K02(MLN-LO&)(*P+Q-/102(R3S7 TVUWVX4YPY[ZG\%fi%jC%C;fi;;ff%j;C,0BM^jBjC^jfi; #CCQ],y%I;C,0B;ACAj*fffi;;j;A^jfi%V~;C,0Bcjxfi;,;,Q 8^0%j'uyfi;;;;;^CJ%fi;QC;;;; ^%*_jC* Cj;;;fffi *;Q; CA;^~j<^fiCff%C;fi;;<8`yC<;^.j<';j*ffI3C;@e'^'<fifi;; ^% L*ff;V^C^ff ;'a ;fi; E ` e0<C;ffj%j;C,0BJ^j,Q ]ff%j;Ebc_<B j'R d>ef;fiM%A%^<CC*j;%jCffeAfi;,^'CAC^g;% fi%;Qfi'BhCfi;;fi'fi0Cfi'^C;fi 00%fiC%K%fi;fi#Cfi<Q%^iRj>kfilm=n=o=pPq=rsut=vxw=yaz)z{[zf{[| t=v<}=vG~|;v1EyGR'z>}gw=y v1DzD[y vR.;|;}GzDEw==||.;z>}[A);vRy };}=g| t=v1z>y >}| tC{Nyv1xzDy {J=}[G|.;z>}A=4R A=RfECEtC=v1}{Ny z>#;vRy }=v1y| t[|Et[>| zv1w=y z=[Gv;|)8D1GvR ;}=Gv1ya|4;}GzDy>a;vR =cv1Mv1y.t;wD=v1y 842;z | t=v;vRy }=v1y| z>.{Nz>y| t=v4;=vVz{| t=v{N=}[G|.;z>}8z>}8Gv1y |4;}8wz;})|4Dx';R'M4E 4 G)RRG>.>4>[4NC>gAR =RDM>4[>NGQ D!>.>R2O)>)R,.11R[NGEOOARR#Q4N)G= Q}vRD;A4;v1}[Gv>=v1ya42;z | t=v;vRya}=v1y| z![}[z>=|t=v1| t=v1y8t)wz>| t=vRCt=vt[>vRD4;v1})|| zz>y}=z>|R}1>.vg;|}=z>|vR>;AAv1}|R| t=vg;vRy }=v1yCV=w=w;vR<;| tGz>=}| v1yvG~[Ew;v>Dx';R'GRC4>2RRRG>.>R21>81[RNO>=R A=4>V>4[>NGQ ;>8DQDR2VO)D)4,.11RNOO)a>O)K8A=RfRVA=Rf>'Q4N)G=[K#gO)41MO.4N)G=D[>[N41>,2V18O)DQP P.P!v[.vy vR.;||at[|t[><v1v1}8z>=|G4;}=vR;}8| tCu{JyGEv1<z>y P,4[#'Nfiff )V1 ')4.;<>>>>GCO O>')4!DC4R>GK<NQx>Q ,)4.!ug)O>>4#">GK ,.K1CD='=CNC >2[DMO>OOE[E 4.VR>GO)121VD[OOV1% $. xD[>) P)OE&">G1a,.1GO>(' )O1;GRC4>2R[NE))a=>O)11POO)> >>GOO)*) >G1G11 NQ ;VDDRV">G1 PQK1O>,s<t=v J{ z2;z<;}=;v1E=>}[| t=vxQC|.;z>}g;}g;|'w=yaz)z{ v;Ew2Ca;|;}w=y v1DzD[xzDy ,+vR t| v1y-/. vRfy.,fi00123=|54v1|4;'6008723D;}=v1} -/9 }=}2C='600;:==ff(>?'),.)124A@B5C<D>C>O2E.D)4JKgNO),.)124ED FGBfiDx<V4PHJIfi!vEy v;>v1}=K>;}=w==|V| zML>,+P}[w[zf}=z>C4|vADz>y.;| t=ON{Nz>yQP 9 5PR =y4;>z>y.;| t=u2Vy =}|at=v4;>z>y|at=S {Jyaz> s<t=v1z>yav1UT}[}[.<v1yE| t=v}[D=v1y.;vR| t[fV| w=yavR.v1})|G1W ;>v1}ARR{Nz>y | t=v4;>z>y.;| t=| vR.|t=v1| t=v1yEYX[Z]\_^fi`acbd Ks<tC1}!vz>}=vV|avR.|.;}=Vt=v1|at=v1yxgCvRD[4[| z|at=v<;})| v1yG.vRG|.;z>}Ez{42[vG;v1Ev1}|f e;g} K [ tE|at[f| e#hW ;>v1}Mjiz>y }gvG~w=y vRa;z>}Eg{JzDy | t=v<| t=v1z>y v1>[yf})| v1vR| t[|| t=v<t)w[z>|at=vRCk iz>y }vG~=w=y vR ;z>}PD<vxt[4>v<| z|avR.|t=v1| t=v1ylX[Z]\c^6`a_bf, KGP!v<[y.||avR.|t=v1| t=v1fy X[Z]\c^6`acb, KntCat!CgvR>;4;v1})|| Gz X[Z]\c^6`a_bf, K!'8s<t=v1zDy v1p7| z>Dv1| t=v1yV<;| ts<t=v1z>y v1pq;Ew;| t[|2{| t=v}[.<v1yQrz'| t=v1}{Nz>yV.zDEvsK'PQ =(L>[atf}CGz>=})|av1yVvG~[Ew;vE{Nz>y| t=vvRD;A4;v1}[Gv!>=v1ya>}[| t=v| vR.|1}vw[v1y.{Nz>y vR;Ew;)v1A4;[|}=zD}42 | t=v> QD}=Ev1})|G;t} KEu{ X[Z]\c^6`acbf, Ku '}[EvG;842| t=vM>a;>}=Ev1}|<;*} K a|.C{N[<vVw=yavR.v1})|'J Kc>u}=w==|| zg| t=v 4;>z>y|at=vN{Nz>y| t=vw=y z>;v1wP 9 5 P)s<t=v<;}=w==||a#z P 9 5 PC;v1)A x N 4E}[.<v1xy yvR1EvR};}==X1 zaDQPjm/K'tCat;Ew2vRsm{X[Z]\c^6`a_bf, KG}| tCV1>.vxv}[.<v1jy yvRg| z| t=vvRD4;v1}[GvD=v1y > R | t=v1y u|v N 4=} rz8}[8.=w=w2;vRVGz>=}| v1yvG~[Ew;vE=X1 za>.P ~}KEL;}[Gv K{m<v>v1|<8 ~X[Z]\_^fi`acbd K f}[| t=v1y vG{Nz>y v<v 1}Ew[>az>}DVGzD=})| v1yvG~fEw;v| zE|at=vvR>;AAv1}[Gv>=v1y >66fi}Jx5c=jJJ8[V5j[O}s=d[fiE Gk_8#dJfi!]k,[6EfiJ=u;5fc[c85c8fi_8d5{] u6ccfi8x5d#5c[Qcfi(5j[}cccdc6V5kj[c55j[c[=GJ/5MuM5==d jd58VcMjjd JJ[6kj&#5=566Jj5(5[#c|Q=5|d[dJ#;5E; ccu[[J8cd6J8[du(c/5;!d[ccJ5[%dj#J}c Ec5[}cG/c[5J85jcd[wd[fiE} _8#dJfi!]k,[6EG6us=fiJ}[sU]#ucfid5?8gG5J5jJ[#[cd=Jfiff[c(65[6c685c55##65[Jcd#5uM5=#MY5j[ k[lc8J5[ddd#J}5&u5j# }J}#fi5}5;J5[dd%x#JuM= cd[ 6["*8J6juM5 % cfixk#[5[=[!c J5[#[fif;fifi 5[ V85d}}5[[s55[Q5c J5c|%_5 856([5$!#%'&(*)+-,.+ /103241576"2598;:<=+3>?@>0A<)B(C>0A6DFEG+ >HDI0A/JD5d6Jd=#6cd5#5Jc85M5#[5;5Jcd[fin[G(=Jddc 5c}k5[gj;5!c6djcG8j=[J8[j,#J%_c8}cKCL=MN OYc&}uLdJ%_c8|J8[56c[56d[cd'K5J565,8[}(6fi 5d##%[;56[L !d6J5JficdtJ8[VJ8#dg&#[cJ d6#; cJ5[%d#J%xP 5#c56d}J%_c8 [!dQ _#dS]R J8[dfifig[ Vdc}c[[65c5Q5Jficd}#8}J(G5j8[[fin[56dkcJ[dfi cG[c 5J56d8(5[6d[Jcd[GTVU WYX[Z&]\_^a`cbd7e9b[gfWhZL Q5[iKCL=MYkJ6*}J#(OjCk5[56d[c8k#kJ8c[*lCkY]5GjQ6dM5G[55cQ5kj8$ _fi[#5GJ#=MlCk5[56[;dM&5J8=c[**jOjCk G=#[c=#=Jc5;m con [cd&5=[&G58[]55G[[Y=t[cY5[5J]5Gd#5ck5k]jKLpM kc[=J5[OjCkj(kSkq 5[jJ d[5ccd%5cQ5[c*5#ccdc6#6Q!c5#58[MrL [JVg5[;##[[5_;dc[cdMc#J85[Jj[[5sS5 sSt 8u[f5$ __[}58[Ac5;cdg[du[[M]Jdk}c5Q#585*56d6JVg5J[V5Jc8gu=vxw=g[_ Vd*]Jd(]zdy ]86{L QdJ}J;dz]R #85]JdQfilCk 5[56d[c8Qs}lfiVccdc6(c5[c56%#d6fi[d(chK 5J565[|VK fi8(6dd[5ccd[5Jjdu&5[5[g]cc/fi#d}#&68%;5J]5A5Jd[c[(5J56d8[J[d[[G|g_J[#[J}cd#& zR[c6Jd6Y fi}L ; c*56dk[[sc56*Qc=[=5[~ fic8[6 fi}Fjfi=SSSASAffF }7p@ #SI3HFV*CAffp'FA A3!FzHzSVjSSxffz=l-A[ cIHzSVSSxffzC=j7[*FrS !|SzSSS|c!ffzVSHS{lCG! .=!fflxSSCzp!VSShjC-Scz@S= J#ff ! JzS_#IplpS!9S!SSxSjrHz ff! !jxSh!xCh{S |!lxSYx !HSff*FS.ff*CzSSxjSx !xCSff#Sffff{Sz S! {HSShxShjxVIzS{FzzSS [SS ffHz !SSxjSh@fffi cz[Szffjc=ff-!zffzFx .S*ffhx#cz*1S SSxhxS !ffzVSHSjC- ]SxJz!#"$%&(' *,$.+/201=ffz=)SxS!xSFzxScz!x'Fzj=ffx. !!ffx !=SSS!H{! xShj;VS=! x !Hj]ff#Cx3 _HlxSjzhffz ff* 5 4ff JzS_#Iff !=S= Jffcff*!x!S7 6!'Sj ff#CSJz hVI8 !9:<; =|, >7?H@z], >7?2ABz Cx, >7?!E DFHHG<I97h Sff{xS !3J4=ff z@3SS j !C K4=ffz*SL4I!!ffz= MJ!!!SCzSSSpB N" O" Shx!JVzSxJzSff=!QPRP(P2MPRPS(5PSSPSPJP2SPS!! -SS THffx9jCB]SxJz N" !SrFzHzShSSx{S!x !#Sff#| ffHCSPS(PSSP2KP(P25P(PffJ]H cjlVU . !QWYXZG x CPSS PP ( MPSK P[ASx=ffx H3 S'*S PS !! YSx =ffH3 S'\j! z ffj=SjzffjC- ]SxJz@] JzShxS=SxSSSc!. 4|JzffzSff!AV'SV!zIS|S=ffx=Ixff{ SJ 4*Y^jK 4_4!Hp'F1S `(`RaffAffF cbBdMegf_hih2fj9klfmj[nNfoqpsrut_b bvxw{7F *@ #']H!3hFVffFyz|{SH !j3.Sxj![3ffff -.ffzffS.ffCzS!c;,} x!~Cz@|S`(`J jK`(`S(Q_zS~1 !c1S`R`(aff! JzSS!3J4.HSSTHff7 4!Fz z{SHff*zrSc! jxS, ^C !ff{CF1z@S `(`RffJkV-F9okf2nmCS4HzS SFzSS. !ffSx*ffzzS.S4z {SS1z@j- !SITSz#=SSC=c {( !x'HC=jSffffSz{zCS ffz z!S=SxffzH#x AS! Hz H!ffzlHff#YzffzhSSV ]3S#I7IHzS VSSffzffz=Sj xhff H H@3hVS A!lSI-S !Az'S!S7zC xF_[ SI|S! 4H !Sj!zSz{SFzSffF*S ]3S#IGzzSjHSFff#ffz= =Ixff3SFzSShS!c jffFz., } x~xz@AS `(`S!=Sz CcVS z Flff ff xz!* z 3 ^H |H#x AY=ShcSff!S! 4! pSF. 6xjS!S cc jz cff!S!S 'xS1!z!8 ffq HJ p{ SSJz Cff U S{3!hp@SSf2nSkxfi2292(2_|222u222[2(252g(JZ#J5l[J5K#5225R[7<(g5|2 J5(SE(525S|Z.(s(s2.( .5S(J8Z.2!Y<KOE(5 225S5Z.(q|[l(\52\25([.(JF(2[M5F(F2272YK952\(|x27*N.F[J5SLJ9|2L2.(g[_S[2REK(5\(F225E528J9|JM(5lF2[uJ.(|2uJ9K2.FE.F[J5SEMJ525J*K9225S5Z.(Q([Q52.J.2YJF[.\5F.5M5\52\2(.(7 5[N22qS.(8(2Z[Y52s2.( # K5, K| L [MB25ZR.2(5Z.(2*_M*J J5J(((2((2R52(252JS2RSJ2(([_uJ52|JM(|F[YJ|![R,(R2(M(S2(((([_2J( 5Q E [5 M9J5JN52SFJ|F52([.(2R..(K(|Y2.FN.F[J5SLJ8(FEx5[FS.(( 2N2|2Q.\S(Z.\5 (F225<52Y5J(5*F2[lM5.2N.5F52 R[.K.[2|S5Z.( #,V K5, K5 [5 2 5 2((52R2S.(2|2L7ELS(Z.L5R2522|2Q2J.\J52L5JN\\.[.K2S2SFJ|Q5KJ.(EJ85225([.NZ.(J K.((.52 s(N(BNK.JSYF(|Q.F\5(F22|8.M R2522S(J* lOJ.(\F(5O.[(|J.(FJF(|7*8s(i.M(F22M.(E(5 25S|Z.(52Z.252 F(2(|(2Y52(5|25S[MJ.(fffiRJ.( ff 5[2J#5Jffff [SK5J!#"$&%2S'(.([ff$ *),+.-H_J[2(|[0/2143u65,785,+9i52(5,7R2F_.5:9 1 5<;5J<K(52[.M5<(2JF[ />=3 52Q(5Z.(2*_N ' Z(2JF[.\ /2=3 R(((2JY /4?@3 H(((fiA52uJ |JS5J85uKZS*_F />143 (J.CB 1 [2(5|28J2RJ(JK1CDL 225S5Z.(u.5|JSs5(E1 9ZR2J*[7(.5\s(28JJJ[.SJMJM S|JS.FA ? <S*SRQJMJM\(2_J.(L.5MKNJY<(V_Z..(.5MKqJ N 8%:G?22N, fi%:A ? Kfi%:A ?2(5IH\.F[.SL5J#KJMLON ff RK5\52N.S(22L(2Jfig.FB 1PDLJF.(52E._5S.(K9|lSu.:1 [5J|.F[.S_68L2!Q8R ff 795\N|2J2.F7*[J|SLJ.5Y|SSL5 />143 82(|K.TQ8R ffU7#V%:A1WF J XZY\[ ]G ZY^_LZ.2F5[E2(MJ7RYNRSlKJ4L`N ffjfceb/Mgih 143kH2J.2F(m||2QJF[.2NK(ZSQ8R ,M[Q8R ,SJQ8R , [Q8R ,[Q8R ,@H2[| [5[| [,V K5,K5 [ | N[| N552(DE(5\552*J5..( J52F2.F\.F[J5SJn 2(QRK,7[S\ZJ5[JSi52J[.sF(2(|(227*<7*[J|Sq2s( 9 ? 9joLp0R 9 ' L.\F2.FY.F[J5Jqrsfitnuwvwxwy\zw{|d}w}~|d84p~Z~|8ffn~i!fij|d4Z&ffP@~U>j8@j|P~|d~UZ}^~@w~<wjUM4^m6j024KwZ@Zw~8wjU4ZjPfij|d4Zkw@~U>8jnwd@~UZV}j^~<@w~m|dj~nd@w~PwjU4Zw|djmw~nZwZmZw~P@w~Z@<@~U>jw@!~UZ}^~nmw~@j||ZU@~~Uw~~<Zj~@d|d4Zj4~|Z@@w~8d>4dP4w6@w~@~:\T0j^^VT^i20n.!^K^]KdT460d:K^.<Kn\2KUZUfi42dZZK>U0Z>j|0>&\K*w~Zm~.j~|d|d^MVZwZ@Zw~wjU4Z0\jU 4Zj~@~6@j|!@w~@~jU4Z&4nmj|Z8|ww~6#Z@.@~}w@~~|d4Z<|dV~UM.@w~6|0>4~!|dj.@w~<|d@~m~}w@~~|d4Zj8|d@~<@w~@|~84Fm8|Z~Z 4}>4~@j|d#@w~!}w@M~m~6|04j|nj|dU|Z n 4@8}j~m|0fi|Z~ZZP@w~!@w~4@~U4ZP~8jn}j|dm44Z@w~4w}ww#4^@V@w~~Un8jjU|dj@w~.j~|}w@wU~w@~Z n 4~@@|dj|dm~~|@~@| @~}w@~~^|4Z w~FjffMw|04P~@|j|d@~@w~ ~Uw}w@~@4Z@6mw~6~dfi446|0n|Z@4ZwV~^i w~U@jm|0}jM<@j|d<C~j|0Z~ m~}w@~~|d4ZjZ@w~wjU4ZjK4ff U|d@w~@j|d#4}>4~!mj|d~|@]@~@4@w~~@~}wm~~^U|d4Zj#8@~}w@~~@~||d]~U4~~84ff|j]@w~@~UZ@~@w~m~jU4Z]}d4^wZ|~6|0:~!Z~dP@w~~UM~V~^*4ffZ@~@j|ZjU~Zwww|dP^.4~iwn@2>}d4^w|0k><Zw~Uj|d}4~ZdP~Z~@w~24dP4wff8j fip8j fip0d8j fip#-4>|d4.C~~P~Uw}w@~@4Zj|dj@w~U4@U|dj|d4Z84@*|@4Zw~8j fipU8j fipmw@@w~ff'wZZ!wZwZ"$%ZZ" &()*+,ZZZZ"\T0jj^8\ff>/.10328C^0K^ZOTn0^K&4 0| >n2dZZK>U0Z>j *0\jUZ TKKn\2KUZUfi4w~}w@d<4>|d!@mw~}wm^dPdCmw~}w@~Mj@w~Zm~:w~j|w~@8d>4dw~Z@~65wZn@w~<Z@w~4@~U4Z|Z@w~!P~!~*|Z4w}ww!|6~7|dj.|dF|04Z4@w98@ZZ #~PjUfi}j|dm44Z:4^@~'|ZUZ4w@!M46|24P4@@~}~Ufi@024ff#Z@~P@j|d@w~~P|dm~nwZn<;ffM>w~6P~8j~ |04n@@U|djZ@,~|Zm=4@|! ~Uw}w@~@4ZZ@w~wjU4Z.Zn~|Zm:jmF~U}w@~m4Z]C~mw:@w~<}w@U~wm?~ 8 @6U}ww@~4> U4 @~}w@~~^|4ZA@ Zj|4Z]ff@w~84@~~UMjP4@m~}j~U8@@d@w~~~Uw}w@~@4Zjn@w~!#Z@~Uw}w@~@ffM:P~w~~\]@w~!~Uj|d}4~ZP~4}4(|d@nMmFmw~~7|dj.j~<@w~@|d~<~Zj|dMj|Z|jdZ~Zd4w4.@w~!Zmw~4@~UM@ZE@w~!|jdZ~Pmw~Z@~6PP~Z~P@w~24dP4wUZ@d>|d@ZBff\CDCFEjGK^ 0E ^T^i20<nZU|0>U0Z>j *Z4H.10328!^K ZUJI@TiFTj4dTKpK#T>UZiZZ>djZKZK2&U0Z>jKZ14 ZwZ>djZKZ>K"L"LfiMONQPQRTSVUQWPQXZYY\[DNQRY,]QRQ^`_'aQ]QPQ]cbdQXPQ[<Y3dQ[Dbfe=Ng^XhiYjlkQmnm"o!pqsrituvmwxmzyi{}|O|~twqvw*3kqD 1m"x\qDtu,xt! mktmmwy m3r!m"m{y3mfqvw3kQm}Qti&tt m}y:tqvwH%mqvZ!q~tiwQwquFtgVQqsriti3m}xy}pQwqDxti qvyww{t!x)3kqD%usm"p3y3kQm3m" puv&fyi{3kqDnm"x qvyw)mwZ qvywQm"tiyirmtqvquFt\m" puv{y\muFt qvywtu?Qti&tt m"qF3m1y33m"H*qv3m:tw7y!3 uvy&"Q%kQm3m3kQmn\m" 3 qDx qvywqFxtuusm"3kQm~{y3{y{pQwx qvywtum1mwmwx\qsmiAF"icJ"<i"F:jkQm1yiuvZwQyqFtulm"o!pqvrtuvmwxm3y3kQm}Q\yuvmjO)1qv}uqvm"3kQmmqF3mwxmyi{7 pQQmQywQmw qDtu71>>\)tuvy! qv3kQ{y\kQm" m}Q3yuvm:OkqDx\k:tnktrm:y}mQ&txqFxtuOqv}uqFxt qvywOyimrm"t\kQm{yiuuvyiqvwQzmti}uvm kQyi7ywQmnxtwQwQy:tiQuvTqs3yyiuvrm3kQm'mwQm&tuxt myi{\kQmAQ3yuvmOqvmw 3mqvwtiwqv3&"!QQ3m" mwA y}m{pQwx qvywqv3kqvw3m3m" qswQQ3y1m3 qvm":jlkQm" m{pQwx qvywxtiwm:tiwqvQpuDti3m"T3ynx3m"ti3mmti}uvm"qv3k3kQm,{yiuuvyiqvwQnQ3y!m3 qvm"ilkt7t kQy\%y3wmcQ3m"\qvywc!!qD :tuu3kQmwpQ?1m7y{Oy!3w`Q qv}m,qsuqDxti\m"3qDmc1ywQmw qDtuwti3qFxpuDti'1'n""Jkt\kQm" mAQ3y!m3 qvm"jkQmg)n""Jngyi{QQ qv}mqsuqDxti\m"qswx\uvpm7tuuQ3kQmA!qD< pQwx qvyw'"OkQm3m Q"ZTmkQyxt! m:tiwtuvQqD)3kt)3kQm} m)yi{lx\kti&t!x3m qD qDx}yQmuD,qF):tuum3r!m}3ktiqvwnymO3y:3t qD{V1tiuvm"t Oy!wQmyi{V\kQm?Qrt qDtiuvm"Op O1m?t\qvwQm"nQQtiw\ktiq{Q3kQmw"p 7tuD ym?t!3qvwQm"ng|'ywqDm& \kQm: mqsw=%y qDxm3kti,q{3{y!? ymVtiw`tuu3kQmy3kQmriti qDtiuvm":t3m=m?\y`\kQmw*HqD}3tiqFm"`jkqD}xyw3 qvQpQ3m"mtx uv3yqvw&gytiwrtiqFtusmy&m qvwQnfft\qvwQ}mw&3kqD,qvmuDQ)3kQm}t\qvwQ}mw&QQ1"Q"gQ"Qfi|'ywqDmwQmcqvwq{Q&ti}muv\kQm:tqFmuvm}mwqsw%kqFx\k*Q,Qjyz3tiqF{zf3kQmw"p mQVtiwHt,m{y3m}mxtiw` mtuuy3kQmrtiqFtusm"3y`{%g3kQmwz\kQm3m}p )mtiwQy3kQmrti qDtiuvmfijkQm3m{y3m)qsw3qvwfiuvxywqFmqvwOkqDx3kqD m3yngwz3kqDxt m}p tuD ymQ&&'7timus3kQmtqDmuvm}mwOqvwOkqDx3kVQO m3r!m)3kti7qD7twZ qv}y!wQy3ywQm%qvw37timus1iqvrmwntiw3ti qD{qvwQt3qvwQmwZOlqs\kn"!QZQqvQqvwQn"3y}mm)tiwQy3kQm)3tiqF{!qvwQnt3qvwQ}mw"OkqDx\kqD) :tuuvm)3ktiw3kQmyqsqswtutxxy!&!qvwQn3yfiAjlkQm3m{y!3mQm):t:t3pQ}m)3kti7Q{Q3kQmwnmxtiwn mtuuy\kQmOrtiqFtusm"3yn!{gV)3kQmwn\kQm3mp O1m?tiwQy!3kQmOrt qDtiuvm7gAjkqDOt3qs!wQ}mwZlqFqv&7tOt{3y!"qvw3kqDxt m3yZy1wy!pQAmti}uvm)qv3kQQtiwzQ"Q%uv3ym\kQm7m!m}mw&'{3y$#ff021 340:1c<Q"F% &(')+*,gqDwQy7p=x\qvmwZ%{y!7 yiuvr!qswQkquvmmxywxmwZ\&ti3m%qvw:3kqDtmywOy\w:mQQ3m"3qvywJZmwQy3m3kti653kQm3ti}mti\pQ}mw&tiwQ3yyi{kQyiuDqvw3kQm}y!3m)mwQm&tuxt m)yi{7jkQm" mzti\mnmQQ3m"3qvywqvw|{y3opt!q%y3wnmQQ3m"3qsy!w&= 6? @'A5mqvkZJ*85"9!:<;C*EDGH F ;OkQm3mqvwmrm3x\uDtip m3kQm3mti3mt:}yuqv3m&tuD yH3ktiOy\w*mQQ3m"3qvywti\m`o!ptq%y3wmcQ\m"3qvyw&Qit\qvwQ}mw&Qm%m3kQm7t3qs!wQ}mwZ7Q"Q!\kQm)& y}3ypQtiwiwQmt!3qvwQAjkqD%}m"tiw\kti7ti3qv3ti3mwZpQ}mti qvyw\kQmuFt! 7tiwf3kQm3m{y3m:1Z!yi{3kQm)Q qv}m,qsuqDxti\m"Q{y7tiqvrmw m%yi{V}yQmuD-/.!twqs%qDqvwqv:tuzm)m6Qtiw:\t"t3qvwQ}mw&l{\y7OkqDx\kqD7m73y}Q1tiw3kQm\m{y\mtuDB517qDttqD'{yjkQmzo!ptqV%y3w}mQQ3m"3qsy!wtiwIKJKLyZqsqsr!m>=xtiwn m3rmtfiM!NPQERTUVWXVYT[Z]\<^U2_]`a_4^aTVY`XbcWXTXbc^7d$ZeVafcWg\hZ4`!ikjXl7U2_]`meZ4n"oqp[Z4TUGrEsKtut]vwmx<y[UV7z4VYnVY`m_fffb{YVKeA|4VY`mWbZ4n2WgZ]\}!}B~ _]n2e%4X@r!UVYnA`VKWXT`Xbc^aTVKeCTZ$UZ]fce_ffff`bdVbd$fbc^Y_]TVKW_]`VWTXbf fVK4b|>_>fVYnTTZ7y!px(GKKE]h8ffcE2KWd$VYnTXbZ4nVKe_]2Z]|4V4rz]b|4VYn_A+`VY`VKWXVYnTa_]TXbZ4n\Z4`i[V^Y_nVK_4W&b f^aZud$TV$TUVCWXVYTZ]\^U2_]`m_4^aTVY`bWTXbc^d$ZeVafcWYx!!nVd@bz4UT+TUVY`Va\Z4`VT`CTZ$WXZ]f|4V }}B~ 2`mWXT!T`m_]n2Wfc_]TXbnzCTUVZ4`nVa`VKWWbZ4nAbnTZ8_C+Va`VKWW&bZun_n2e"TUVYn%^aZ4d$TXbnz"TUV@^U2_]`a_4^aTVY`XbcWXTXbc^d$ZeVafcW\h`Z4dTUbcWWXVYTKx nZ4TUVY`!ZWWbfV`Vaf_>_]TbZun$bcW[TZ2`mWXT!^aZ4d$TV_ffffTUV+`Xbd$V7bd$fbc^Y_]nTmWZ]\TUV\n2^aTbZun_]n2eTUVYnCTZVaT`m_4^aT[_7%`VY`VKWVYnTm_TXbZ4n$\h`Z4dbTKxkV^aZun2WbceVY`BTUbW`Z4fVYd(UVY`V4x67_]d$Vaf4r[V^aZun2WbceVY`!TUV`Z4fVYdZ\VYndVY`m_]TXbnz"44TUV`Xbd$V7bd$fbc^Y_]nTmWZ]\_@!Zu`nVa`VKWW&bZunGr2_]n2ebTmW!_]fbc^Y_]TXbZ4nA\hZ4`!TUVWZ]fTXbZ4nZ]\ }!}B~ xUbfVk[V%U2_K|uVnZuTC\Z4n2e_z4VYnVY`m_fff`VKe2^aTXbZ4n\h`Z4dTUbW`Z4fVYdTZ7y!pr7_Wbd$fV_4e_]TbZunZ]\7TUV8_>fzuZ4`XbTUd\hZ4`$7y!pj&`VKedC_]nol7U2_4^Ub_]nGr!sKtut]vw!ubVafceWC_]nbn2^a`VYd$VYnTa_fff<X] _>fzuZ4`XbTUd\Z4`TUbcW!`ZufVYdAx+Z>[VY|4VY`ffr2_4W[[VeubcW^a2WW72VafZ]r2VYnd$VY`m_TXbZ4n%Z]\`bdVbd$fbc^Y_]nTaW7Z]\B_$Z4`nVa`VKWW&bZun"bcW7nZ4T+WX"^bVYnT\Z4`WXZ]f|ubnz }!}[~ xy[UV`ZufVYdbnkWX2^U%_]n_]fbc^Y_]TXbZ4nAbcW+_n"VaZ4nVYnTb_>fz_]CbnTUVWb{YVKWZ]\TUVKWXV`VY`VKWXVYnTm_]TbZun2WYxZ4`^aZ4d$fVYTVYnVKWWBV$WXuVYTm^UATUV@d_ffbn%bceVK_4W7Z]\[TUV@VYndVY`m_]TXbZ4nk_fffz4Z4`bTUdUVY`V4xEVYT@2V@_$Z4`n"Va`VKWWbZ4nGrE_]n2efVYT2VTUV7Va`VKWWbZ4nk^aZ4d$2ZWXVKeCZ]\<TUV`Xbd$Vbd$fbc^Y_]nTmWVYnd$VY`m_]TVKeWXZ\_]`ffx8yUV_fffz4Z4`XbTUd/2n2eW@_]n_uWWbz4nd$VYnT$k!Ubc^UW_]TXbcW2VKW@_]n2eeZVKWnZ4TW_]TbW&\kAx7WbnzbTbcWVK_uWX%TZC2n2e_CnVY`Xbd$Vbdf bc^Y_]nT$Z]\!xy[UV_>fzuZ4`XbTUdTZC2n2e2WVKW@TUV\Z]ffZ][bnz^aZudbn2_]TZ4`Xbc_fff[\_u^aTjX`VKed_nol7U2_4^Ub_]nGrsKtut]vwm@VabTUVY`$TUVY`VCbcW$_|>_`Xbc_]fV!TU2_T_2VK_]`mWbn [bTUUbz4U\h`VKuVYn2^a4r6Zu`TUVCVa`VKWWbZ4n U2_4W"Y_fZ4TmZ]\6W_]TXbcW\hubnzC_4WWbz4nd$VYnTmWYxn"TUV72`mWXT+^Y_uWXV4rZ4nV^Y_]n"`VK^a`mW&b|uVafWZ]f|4V+TX[Z$WXh`Z4fVYdW_]``b|uVKe_TWX2WTXbTTXbnz ) r4_n2e G sgbn@TUV[Va`VKWWbZ4n2Wg_]n2e@xn$TUVWVK^aZ4n2e@^Y_4WXVbT7bcW7VK_4WX"TZ2n2e%_]n_4WWbz4nd$VYnTjV4xz2x[W_]df bnzwaxyUVWZ]fTXbZ4n%Z]\6TUV`VK^a`mWbZ4n%4bVafceWTUV@WXTm_]TVKeCTbdV2Z4n2eEx!Z4`+^aZ4d$fVYTV@eVYTm_ffbfcW7[V`Va\VY`7TUV`VK_ueVY`+TZTUV_]`TXbc^fV@"`VKed_]n_]n2eAl7U2_4^Ub_nkjmsKtut]vwmxUbfV@TUV@_]n2_fffWbcW!TUVY`VbcW+W2VK^bc_fffb{YVKeA\Zu`!d$Z4nZ4TZ4nV7\n2^aTbZun2WbTbWVK_4WXCTZ$VaTVYn2eAjTUV72`mWXT!2_]`T!Z]\KwbT[\hZ4`+Z4`n"Va`VKWWbZ4n2WX4xKE]EK]c]KG< 7VYnZ4TV[$7]jXiGwGTUV!nd@VY`<Z]\`Xbd$Vbdf bc^Y_]nTmWgZ]\GixUbfVTUV$`VY`VKWXVYnTm_]TXbZ4n2Wjms]w+<`bdVd$fb^Y_nTmWj&&Wawar<j&w+7`VY`VKWXVYnTa_]TXbZ4nGr_n2ej&w } U2_`m_4^aTVY`XbcWXTb^d$ZeVafcWYr<W_]TXbcW\h%TUV@bnVK42_>f bTXbVKW7]j&iwj&iw ff4jXiGwY fi rEVK_4^UkZ]\!TUVbnVK42_>f bTXbVKWd_ff_ffffZ>\hZ4`!_]nVa2Z4nVYnTXbc_fffz_]Gx6y[UV7\hn2^aTXbZ4nj ff wff"j ! wj&l7U2_]`aeZ4no p[ZuTUGrGsKt4tvwWXUZ]+W_@z_]"VYT&[VYVYn%j&w_n2e%j&waxyUV7\n2^aTXbZ4n& "# $% $%& " $ "j b{YVYn2WXTVabnobTTKrgsKt4t 'w!WXUZ]+W_z_]%2VYTX[VYVYnjms]w+_n2ej&wmxj&yZ"Z42WXVY`|uVTU2_]TKrGnZuTXbc^aV$TUVWbd@bfc_]`XbTXVYTXBVYVYni _n2ekTUV"e2_fff[Z]\+TUV\n2^aTbZunk\h`Z4d/TUV`VY|4bZ42W$WWXVK^aTXbZ4nGx)w (gZ4TU\hn2^aTXbZ4n2W_]`V!Zu`n jh\Zu`i dfTXbfubnzZ4T"[VWXVYVkTU2_TVY|4VY` ^fc_]2WVk\hZ4`i bWA!Zu`nGr* +-,./%021234/517686:9156;</=91234/%6:>?6@150BADCE/%FEG8/H.IJ!/HK@176LFE.MONKLFEJ!/FEJPNCQFE0515.6:G?12RS6:/HKUTVFEGU1HCEK:/517WXY/[ZIFE3412CE/[.6%6:>]\Y+^ 9FEG_0217.a`/W>D./UI GLFE.Mcbd0[>D.G:/H. G:IG:e?>DN/[K@176LFE>D.GHf;g9FE0@9a0217.aM4/H./HK@176:/=1HCQCff6:9/NKLFEJ!/FEJ!NCQFE0515.6:G!hji_FEkH/H.G:6:/BFE.lnm FE6:6Hfffo5p4pDq4rstufiv?wxy{z8|}x~D7wy y%xff~xL5w ~j5j4Y?5D57Bja5] 5 HP2O7 4D7HHHYffDHD ffjc27 ]ff4Hjn=HjSffff4Y SD7Sff?:5ff 7j5c5 4D5HH2affDaHa: DHj8&@ )g=B5ff?HDHj!cH5 ?7D55ffj?ff5aYj?HPP H]D@]H=ffj5= 5cffD ffjHj=!OaSa=Uj25P5!]VV H]7Bjff4?5U!P ffj= : [4j 74ffg5 DHPP V!Oc7 O5HYO5ffj5V5j 7j ffffj5HBjn5Bjff4] ffY ffj5:S!j5ff DHj{:O]?ffjO5]DffSDffjHUP !HHg g[S5Hffj%S5]4 Haff j U4S]5Hj jjDffD< fffi !#"$%'&)(+*,-.0/21435/*5%6"$7809: ;<= 5ffj 7Hj jnjD@] B5#5Bjff?># #5@ B+ >DCE=: H54FHj4! Dff5?!O5ff DD@5H GH 5!Oa 5. GH 5 5IKJ HggLff?7c5ffj =5HB-ffjH!Pa{7ffPS?ff5j&57 2@G j54 DS7& c5j54 5 BjHj@! c7Hn7 H5?5j54 75 @!]H 7 7 HHj:54n NQP RTSj H4 D?5O GH ?5U P ff5cD0 V[ D2S?57 H]D0 V[ D2S&ffHj:5c7 HX W{c54 B5aj]75Oj HD Dc=!Oa[Z]\_^a`0b c5dMe2f<^7 P 4)_j4H!&7 j 5 7&7ff DHj Sff @ 55Bj P O5!]! P aV:5ffjnff7n =5cHffjc5c5<n57D7 ?Hj55VcV2S:5Pa :5ff ffajffj7 P5g!!a !j=j ]75Hff4Hjg=55!DHjO Z%Hj5 ]5524Hj P SD]B- g ffffh fjiUHj?7O 7 2!jkPW{c 7 j 5 +NO52[-ffjc? ffj]ml : h Z4?O5HY 42]5 H NO5HB-ffS j. >nCoS[RpP ffajffjO5 H >nCn q>rCl P Yj P c5g7ffDY]?7 D2S 57jH{ ffYSff542DHj 5 ]!Y5>nCl : P 4 Bj DsZTt P >nCl :h Z4 7D7ul:h ZD?57 j5DHjn7Hml): h Z4< j. > n7Bjff H 75>vC# q>[C#l : h Z4+W{O5 + >rCvSc Bj Dff 5 5xwP :h ZU!O .>qCl P ! >yCzS[ROP zN]5HB-ffjDff:5c O5ff DHjD Bffa5a D2SN) {4| }~| 5 }~|| 5 {4| |p5h {4|O}|ff: DHj!-P74 B5jff5c {| }| 5 }| | 4 % D2S P { | { }7HB:jn5Bj4 P 5 4 5 - nZ # { P4Bff57Bjffs >V ?ff7 5HB N8Uj2S~ >V5HB Vg {757 %S!!j57jH7O Zfi <~UO 2a 56? a-X0j0# XjX0 X.;-# -# # -8~ )0?-O0 -q0 .5 hXO-06 . #-q ?? -; #6-.#05 s0j+# #0 -# 6-k 0 + #O #. #U;.0-a-r00;) 00#M0 -n # #XO#0v0a0?o08# X##U # #0 -5s#0h0 )# 0?X _aO0#X+;. -M .? 0;?--hM + -#O#6O;-z60X . X0a0M -#Ov0 0-#+. #X2 #_0- ; -00 #s050;-#a- -#X)?-)0a0 - v-,- #k- -YU-;-#q-# #X40-#O #~? ~ 4 #~00# X? 8540-#O6 a-n;4; . 0O+- 60 -U# X##? ~ -#O0 6#0 ?0 #;5 -#4+_H.M0a0 -q #q+0TMU0q0 $#0 --? #.-#p0kn0 0.M)<T 6k04-T# #;6v0h040- ~0j54+00-O. ;_# +Xo 0j),0-0;-#ns --T0?-r 00.a-?-p - O68+# ?#0 - -?j$#0)#0 0#4p-#H M8+v 0Ma-$0 -# ?#0 - ? -?j$#0O;A MTp-#M8qh4 -4XT -# )-? $#0 -z y24~ 5j#X .?-- M-#0U0~ + -#Oy#y-k- U?O) U - #n-r#?#0rM ;- nx #--0 5 #;a- + X-#4# X##.4O 40 -~0# ?4#U-TU?0-0#h4z#+;2-60X## 4 020Ma- -O0+ + -6sM?.#a--+j- M05 0U0X04D-8)X#M -#O~,-?4j 8 # ; - z + -#O5-) $$~s2)2)0<~5z250ffOX U-#;6-q0 $0+0kM8 .??#X-nz ?j0 ? --v.#U4X oz0 q U0 ?+8##+6?j# --? 0X 5 #0 - 06-- 54#0_~ -- 08- +0#X + 0U8X#X y5##X8X2$-#5#OX #4+ 6)+ 020 )256##- .--< 4-00$$- z05h O;<88#0fiff ff4 0- - -#o!D-~; <- s0 -~6?0 #"# ff$ %ff& fi'0()#*+(## 24-540)<5v-~0- +- 0U0 5+. ( r z U0)4O0 -8X8 -;###-#/01 2305476& fi8:9;k<fi0fi(*,=>?fi@BACDFE3GHCIfiJJLKAD%JNMDOQPSRMCMUTVICK&JWVKTYXZA[O%I\ J]_^a`UbLcdfe[gad;hjilk%m nm o.^pdfqg_rstt.uvg"w-`.xzy{a|}fi^a~Q`+B^|#fi~^'b#m ~5^`.m %%m{^am ~^a``+y%`fi^~5^.|]-`` {a|m "%b~^a`%#gzq|bLcgnW|#ygad;nmx:%B^a|#nl^a~d`~W~L|#nm xg:q`m+yy%|m nN^Fip`nWxm ~^a`m %wS`xzy~m ~5^`.g]c`~dfigfigrst.tuvg%}[m.b~{|m+nW^a.^m~Wc|xz``~W`.|B~Wc|#`nWgipYf&fi+f&fiWS-' $fi&"z-%dyygu!Uuss;m{a`zB{a~W`dw-:g|bLcfi~W|#ndUNgad%h|m+n{pd%egrsttvg_~WnW%b~WnL|^|#fi~5^'b#m+~^a`^nW|{m ~^a`%m{;m ~mg-N f%d d%uU#U![g` {^a%d%ggad%hm!{{^a|#ndeggrst vgB'^|m+nW~^axz|zm{a`n^a~Wcx`nB~L|~^aWm ~^l'm+k^{^a~`ynW`y%`l^a~^a`%m{`nW`nWx:{m |g. :dd%.#U+%g^a~W|#nd'qgdUh`~L~{a`kdg$rstts+vgi|#~^.^a~Wc|7x:^a^axm{;~Wnm+%|#nWm!{` fm:cfiy|#nWnm yc"m %nW|{m ~W|ynW`k{a|#x#gq|bLcgnW|#ygwfpqpts fisdw-cn^~^m `.yy{|#nBm+k%`nm+~W`nW`nf}Uy|#nW~U~L|#x#dqBB^a|#%md%5~Wn^mg^a~W|#nd'qgdUh`~L~{a`kdg$rstt [vgi|#~^.^a~Wc|7x:^a^axm{;~Wnm+%|#nWm!{` fm:cfiy|#nWnm yc"m %nW|{m ~W|ynW`k{a|#xgz%z 7&&-gnL|xm dgadShc%m.bWc^afim d;grst.t vgB~Lc|b`xzy{a|}^a~` %m!{^am ~5^`.` x``~W`|.^%b~^a|`nWxm!{%`nWx#gq|bLcgnW|#yg%wpqBp[dU|#y%m+nW~Wxz|#~-` Sw-`xzy~W|#nfibL^a|#%b|d~W|#nB^a|#n^~gm+nW|#dQgdUhe+`c%`d%:grst!tvg-S-L7%.fi& +B:&fi%#ggg%nW|#|#xm dfim [nm %bL^Wb`%g`.~W~{a`kd:gadh'^ko.^ad'_grstt.vgip|~^afim ~5^`.%`nWx~WnW`nW|{m ~^a`%#d|#y%|#%|#%b^a|#nL|#%b|d%m %|}%bL{a%|Y%b~^a`%m!{|#y%|#%|#%bL^a|#gL%drp[vd%u!fifig`nWdSgSrst.s vgB|#fi~L|#%b|zBc^bLcm nL|~WnW|`.^anW|b~z^a`%` 7m{a|#knmgB'W&.drs vds# U[sg~Wd7gd|m nW%dgadBh|{axm d]grsttUvg`nWm yynW`}fi^axm+~^a`%` 7|#xzy^an^b#m{zm ~mgf.%%&.dWds.t's#fi[gmfi m.^m#d:gad;m y%m.^ax:^a~Wn^a`dwgadh ^|#n^pd'grsttuvg$BZ`nW|#fi.|{`.y%|m %cfiy%|#nW.nm yc~Wnm %.|#nWm{#gil%&%.! &"&&.%SBfi.:Sdyyg%uttfig[yn^a|#nW;|#n{m %gwfN gc%m n`.d-gad-"m ^{md-gad-h`~Lcd-:g;rsttvg|m`^a^~Lc|}[m xy{| ;nL`y%`fi^~5^`.%m{`nLx{m |m %m ~m k%m.||#y|#%|#%bL^a|#gBq|bLcgnW|#ygqBWs+ptdB^ao|#"wS`xzy~m ~5^`.Zm+kgadnL!m n^a|#nl^a~gc%m n`.d3gadh`.~Wcd:grstt+vg|m`.^^a~Wcxz`|{#gip 7z&fi.%:qBpspt-##%. f.&.%dyyg;ss#'ss.ug7{{|#nl^a`%d^o.|#w-`xzy~m+~^a`Zm kgad%m nW n^.|#nl^a~d'em+fi%m nLst.t %gc%m n`.dfgdh`~Wcd:g-rsttvg|pm {a~WnW|m5`^aQ^a~Wcx`U|{#gip&fi z&%.%B-.##N f$%d yyg%ust!Uugfififf!#"%$&')(*$,+-.0/21 1&34057668:92;'=<>$&?:='@A8:,BCD9&@@AE,BC?F9 ,$2(HG'6,,G',BIJ7@A8:9 <8:C(*$&?F9 ,JLK,MONCP PQ0N RDSUTVKXWYQ0MZR[Q2\AS*]CN ^H_`M aPcbY\AQ2RDdc]2S*Q2T,]CQ75e68IC(f<D,$&8Igh 80Ji9 %9&@j?:k6,$&6,8l$m66,$&8:Gnpo:qjrts#/1 1 u"%$&')(*$fi+vwyxfi$2k,$fiDwfi.0/21 z {'40|r7Ji} ~'g|C;$&<6'(= 57$&66'()B$m?F9 9&@578:<J?:8:9 }8:C(*$&?F9 ,JjM b'R0TN ^MF>_wM aPcb'\AQR-N T,dc2\AQad]SUQT,]CQ X.[u'40X/u {2c/3,/"%B2q$&8:?IkYg &Z.0/1 z!40 H8:9Z} 80$&<Jj?:kBC9 <<9 J,JF 'o>RFM]CQCQ0 SUTYmwMFfi\UWYQjdaPM&SUb'a#M T\UW'QQC]WYN TSN \ASUM T>MFKWYMZbmWY\RFM]CQCQH9&(,/ Z66 !z&3,&l$m?F9 ,$2(cHk'gJi*B$2($m~,9 80$m?:9 8:gxj68FY?IGDO"O,JF'gfJ`.G)4`dcQaDN T\AS*]0TM RCaDN \ASUM T>RFM]CQCS*T' "o[sH8:JIJC.0/1 {Zz'4023Y 23Y 1'5(J9>=hxt`80$ BIk<$&p$&,G+v JI E xj$ZGZ=}'J=h79&j(G'} xj68:JY?0$m?F9/1 z"%B2q$&8:?IkYg H`+7$2g Jw`.0/1 {Z1'40| 9 <>6k')(9YJF9 6k'*B$2(v68:9Z~'(=<>J-@8I9 <?:knJ?0$&,G'6,9m='?9&@$&8:?F)cBI*$2(fi'?:C()(f} ,BC o"C(?:8j7Hy"BIk' firD`.[wGJ=40`N ]WYS*TQO0T\AQ^U^)SfZQT,]CQDwGZY~E8I} k' 80Ji?FgpH8:JIJ"%B,JFg fijql`ql.0/1&3Y!40hsjkpG'BI*Ji9 68:9 ~'(<@9 8JF9Z<nBI(*$ JIJFJ9m@JF'?:,BCJ=?Ik9 E?E,$&'?F),8jM b'R0TN ^MF-dc&a:MZ^fSU]tMC SU].F'40{/C,&{xjC?:8xt.C/1 z' 4C5?:k9 8:g9m@GZ*$&} 9'Ji*Jj@A8:9 <,80JF?68F,BI=6'(JfiR0\AS ]2S*N ^0T,\AQ2^*^)S) QT]0Q2 X.0/&40xjC?:8fixwyr7p(8fi.0/1 z! 40h9ZE,G$&?F9 ,J9&@$ZJ:JFE<6?F9 A~,$ZJFG|?:8:E?:k<>$2Y?:,$m,BCJFg!J?:<Jo#jR[M2]0QCQC S*T'&OMF\UW'QhtN \ASUM T,N ^-_wM TQ2RFQT,]CQpMZTtRC\AS j]SUN ^j0T\AQ^U^fS) Q2T,]CQ`66/z 2c/2z zC(<$&H7t$&E?: +-H.C/1 1/&4C79&j(G'} OBC9 <6')(*$&?F9 |E,Ji}h+fi9 8I$m668:92;Y<$&?=9Z,JoiRFM]CQ0QC SUTYmM\UWYQ-tN \AS*MZT,N ^H_`M TQRFQT]0Q-M TOtRC\AS j]SUN ^0T,\AQ2^*^)S) QT]0Q2&66,1 &3m!1 1C(<$&'l J:ZE +vZ.0/1Z1 '40&57~cG'E,BC?F fi$&,GDG'C@$&E'(?H8:$ JF9Z'=}5BC9 <6E?C$&?F9 ,$2(!BC9Z8:o%RFM2]0QCQ0ZS*T'&lMFD\UWYQ-NZ\AS*M TN ^H_wMZTQRFQT]0QtM TOtRC\AS ]SUN ^CT,\AQ^U^)SfZQT]0Q2&66,&3Y2&3YzfiJournal Artificial Intelligence Research 3 (1995) 431-465Submitted 9/95; published 12/95OPUS: Efficient Admissible AlgorithmUnordered SearchGeoffrey I. Webbwebb@deakin.edu.auDeakin University, School Computing MathematicsGeelong, Vic, 3217, Australia.AbstractOPUS branch bound search algorithm enables efficient admissible searchspaces order search operator application significant.algorithms search efficiency demonstrated respect large machine learningsearch spaces. use admissible search potential value machine learningcommunity means exact learning biases employed complex learningtasks precisely specified manipulated. OPUS also potential applicationareas artificial intelligence, notably, truth maintenance.1. IntroductionMany artificial intelligence problems involve search. Consequently, developmentappropriate search algorithms central advancement field. Due complexity search spaces involved, heuristic search often employed. However, heuristicalgorithms cannot guarantee find targets seek. contrast, admissible search algorithm one guaranteed uncover nominated target,exists (Nilsson, 1971). greater utility usually obtained significant computationalcost.paper describes OPUS (Optimized Pruning Unordered Search) familysearch algorithms. algorithms provide efficient admissible search search spacesorder application search operators significant. search efficiencyachieved use branch bound techniques employ domain specific pruningrules provide tightly focused traversal search space.algorithms wide applicability, within beyond scopeartificial intelligence, paper focuses application classification learning.particular significance, demonstrated algorithms efficiently process manycommon classification learning problems. contrasts seemingly widespreadassumption sizes search spaces involved machine learning require useheuristic search.use admissible search potential value machine learning enables betterexperimental evaluation alternative learning biases. Search used machine learningattempt uncover classifiers satisfy learning bias. heuristic searchused difficult determine whether search technique introduces additional implicitbiases cannot properly identified. implicit biases may confound experimentalresults. contrast, admissible search employed experimenter assuredc1995AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiWebbsearch technique introducing confounding unidentified implicit biasesexperimental situation.use OPUS admissible search already led developments machinelearning may otherwise possible. particular, Webb (1993) comparedclassifiers developed true optimization Laplace accuracy estimate obtained heuristic search sought failed optimize measure. general,latter proved higher predictive accuracy former. surprising result,could obtained without use admissible search, led QuinlanCameron-Jones (1995) develop theory oversearching.paper offers two distinct contributions fields computing, artificial intelligence machine learning. First, offers new efficient admissible search algorithmunordered search. Second, demonstrates admissible search possible rangemachine learning tasks previously thought susceptible efficient explorationnon-admissible heuristic search.2. Unordered Search Spacessearch problems, order operators applied significant.example, attempting stack blocks matters whether red block placedblue block blue block placed green. attempting navigatepoint point B, possible move point C point B movingpoint C. However, search problems, order operators appliedsignificant. example, searching space logical expressions, effectconjoining expression expression B conjoining result expressionC identical result obtained conjoining C followed B. sequencesoperations result expressions equivalent meaning. general, search spaceunordered sequence operator applications state S, statesreached permutation identical. type search problem,search unordered search spaces, subject investigation.Special cases search unordered search spaces provided subsetselection (Narendra & Fukunaga, 1977) minimum test-set (Moret & Shapiro, 1985)search problems. Subset selection involves selection subset objects maximizesevaluation criterion. minimum test-set problem involves selection settests maximizes evaluation criterion. search problems encountered manydomains including machine learning, truth maintenance pattern recognition. Rymon(1992) demonstrated Reiters (1987) de Kleer, Mackworth, Reiters (1990)approaches diagnosis recast subset selection problems.OPUS algorithms traverse search space using search tree. rootsearch tree initial state. Branches denote application search operatorsnodes lead denote states result application operators.Different variants OPUS suited optimization search satisficing search.optimization search, goal state optimal solution. satisficing search, goalstate acceptable solution. possible search space may include multiple goalstates.432fiAn Efficient Admissible Algorithm Unordered SearchOPUS algorithms take advantage properties unordered search spacesoptimize effect pruning search tree may occur. particular,expanding node n search tree, OPUS algorithms seek identify search operatorsexcluded consideration search tree descending n withoutexcluding sole goal node search tree. OPUS algorithms differprevious admissible search algorithms employed machine learning (Clearwater & Provost,1990; Murphy & Pazzani, 1994; Rymon, 1992; Segal & Etzioni, 1994; Webb, 1990)operators identified, removed consideration branchessearch tree descend current node. contrast, algorithmsremove single branch time without altering operators considered siblingbranches, thereby pruning fewer nodes search space.possible apply operator path searchspace, search unordered operators considered subset selection problemselect subset operators whose application (in order) leads goal state. singleoperator may applied multiple times single path search space, searchunordered operators considered sub-multiset selection problemselectmultiset operators whose application leads desired result.search tree traverses unordered search space multiple applicationssingle operator allowed may envisioned Figure 1. example includesfour search operators, named a, b, c d. node search tree labeledset operators reached. Thus, initial state labeled emptyset. depth one sets containing single operator, depth two sets containingtwo operators on, depth four. two nodes identical labels representequivalent states.considerable duplication nodes search tree (the label {a, b, c, d} occurs24 times). Figure 1 (and following figures), number unique nodes listeddepth search tree. number derived numbercombinations considered, derivation also indicated.common search prune regions search tree basis investigations determine goal state cannot lie within regions. Figure 2 showssearch tree sub-tree {c} pruned. Note that, due duplication inherentsearch tree, number unique nodes remaining tree identicalunpruned tree. However, deemed node descending {c}may goal, nodes elsewhere search tree identical labels (arereached via identical sets operator applications) nodes occur prunedregion tree could also pruned. Figure 3 shows search tree remainingnodes {c} duplicates deleted. seen numberunique nodes remaining search tree (the tree depths 2, 3 4) prunedhalf. Similar results obtained case multiple applicationssingle operator allowed nodes consequently labeled multisets.OPUS algorithms provide pruning rulesmechanisms identifying sectionssearch tree may pruned. Rather, take pruning rules input seekoptimize effect pruning action results application rules.OPUS algorithms designed use admissible pruning rules.used solely admissible pruning rules algorithms admissible. is,433fiWebb{ a, b }{a}{ a, c }{ a, }{ a, b }{b}{ b, c }{ b,d }{ a, b, c }{ a, b, c, }{ a, b, }{ a, b, c, }{ a, b, c }{ a, b, c, }{ a, c, }{ a, b, c, }{ a, b, }{ a, b, c, }{ a, c, }{ a, b, c, }{ a, b, c }{ a, b, c, }{ a, b, }{ a, b, c, }{ a, b, c }{ a, b, c, }{ b, c, }{ a, b, c, }{ a, b, }{ a, b, c, }{ c, b, }{ a, b, c, }{ a, b, c }{ a, b, c, }{ a, c, }{ a, b, c, }{ a, b, c }{ a, b, c, }{ b, c, }{ a, b, c, }{ a, c, }{ a, b, c, }{}{ a, c }{c}{ b, c }{ c, }{ a, }{d}{ b, }{ c, }4C =104C =414C =62{ b, c, }{ a, b, c, }{ a, b, }{ a, b, c, }{ a, c, }{ a, b, c, }{ a, b, }{ a, b, c, }{ b, c, }{ a, b, c, }{ a, c, }{ a, b, c, }{ b, c, }{ a, b, c, }4C =434C =14Figure 1: Simple unordered operator search treeguaranteed find goal state one exists search space. However, algorithmsmay also used non-admissible pruning heuristics obtain efficient non-admissiblesearch.OPUS algorithms admissible (when used admissible pruningrules), systematic (Pearl, 1984). is, addition guaranteeing goalfound one exists, algorithms guarantee state visitedsearch (so long possible reach single node applicationdifferent sets operators).3. Fixed-order Searchnumber recent machine learning algorithms performed restricted admissible search(Clearwater & Provost, 1990; Rymon, 1993; Schlimmer, 1993; Segal & Etzioni, 1994; Webb,1990). algorithms based organization search tree, that,considering search problem illustrated Figures 1 3, traverse search spacemanner depicted Figure 4. organization achieved arranging operatorspredefined order, applying node operators higherorder operator appears path leading node. strategy434fiAn Efficient Admissible Algorithm Unordered Search{ a, b }{ a}{ a, c }{ a, }{ a, b }{ b}{ b, c }{ b, }{ a, b , c }{ a, b , c, }{ a, b , }{ a, b , c, }{ a, b , c }{ a, b , c, }{ a, c, }{ a, b , c, }{ a, b , }{ a, b , c, }{ a, c, }{ a, b , c, }{ a, b , c }{ a, b , c, }{ a, b , }{ a, b , c, }{ a, b , c }{ a, b , c, }{ b, c, }{ a, b , c, }{ a, b , }{ a, b , c, }{ c, b, }{ a, b , c, }{ a, b , }{ a, b , c, }{ a, c, }{ a, b , c, }{ a, b , }{ a, b , c, }{ b, c, }{ a, b , c, }{ a, c, }{ a, b , c, }{ b, c, }{ a, b , c, }{}{c}{ a, }{ d}{ b, }{ c, }4C =104C =414C =624C =434C =14Figure 2: Simple unordered operator search tree pruning beyond application operator ccalled fixed-order search. (Fixed-order search also used non-admissible search,example, Buchanan, Feigenbaum, & Lederberg, 1971).Figure 5 illustrates effect pruning sub-tree descending operator c,fixed-order search. seen, substantially less effective optimizedpruning illustrated Figure 3. Schlimmer (1993) ensures pruning effect illustratedFigure 3 obtained within efficient search tree organization illustrated Figure 4,maintaining explicit representation nodes pruned. resulting search treedepicted Figure 6. approach requires considerable computational overheadidentifying marking pruned states following every pruning action, restrictivestorage overhead maintaining representation. (One search problems tackledcontains 2162 states. represent whether state pruned requires single bit.Thus, 2162 bits would required represent required information problem,requirement well beyond capacity computational machinery foreseeablefuture.) Further, open debate whether approach truly prune identifiednodes search space. Nodes pruned still needgenerated encountered previously unexplored regions search tree order435fiWebb{ a, b }{ a, b , }{ a}{ a, b , }{ a, }{ a, b }{ a, b , }{ b}{ a, b , }{ b, }{}{c}{ a, b , }{ a, }{ a, b , }{ d}4C =104C =41{ b, }3C =323C =133C =04Figure 3: Simple unordered operator search tree maximal pruning beyond applicationoperator c{ a, b }{ a, b, c }{ a, b , c, }{ a, b, }{ a}{ a, c }{ a, c, }{ a, }{ b, c }{}{ b, c, }{ b}{ b ,d }{c}{ c, }{ d}4C =104 C =414C =624C =434C =14Figure 4: Static search tree organization used fixed-order search436fiAn Efficient Admissible Algorithm Unordered Search{ a, b, c }{ a, b }{ a}{ a, c }{ a, b , c, }{ a, b, }{ a, c, }{ a, }{}{ b}{ b, c }{ b, c, }{ b ,d }{c}{ d}4C =104 C =414C =4354C =14Figure 5: Effect pruning fixed-order search{ a, b }{ a, b, }{a}{ a, }{}{b}{ b,d }{c}{d}4C =104 C =413 C =323 C =133C =04Figure 6: Optimal pruning fixed-order searchchecked list pruned nodes. Consider, example, node labeled {a}Figure 5. expanding node necessary generate node labeled {a,c}, even node marked pruned. generated possibleidentify node pruned. node could principle prunedanyway application variant technique identified prunablefirst place. Viewed light, argued Schlimmers (1993) approachreduce number nodes must generated fixed-order search.saves computational cost determining nodes whetherrequire pruning not. (This assumes optimistic pruning mechanism abledetermine node n search space pruned node nalso pruned, irrespective n encountered search tree. optimisticpruning mechanism deficient cannot this, Schlimmers (1993) approachincrease amount true pruning performed extent overcomesdeficiency.)4. Feature Subset Selection AlgorithmFixed-order search traverses search space naive mannerthe topology searchtree determined advance takes account efficiency resulting search.contrast, Feature Subset Selection (FSS) algorithm (Narendra & Fukunaga, 1977)performs branch bound search unordered search spaces, traversing search space437fiWebb{c}{ ,b }{ a,b, }{ a}{}{ ,d }{ b}{ b, }{ d}4C =104 C =414C =624C =434C =14Figure 7: Pruning FSS-like searchvisit state dynamically organizing search treemaximize proportion search space placed unpromising operators.viewed form fixed-order search order altered nodesearch tree manipulate topology search tree sake searchefficiency. Unlike Schlimmer (1993), pruning mechanism ensures nodesidentified prunable generated.power measure illustrated Figure 7. figure, fixed-order searchperformed simple example problem illustrated Figures 1 6, orderchanged operator pruned, c, placed first. seen, achievesamount pruning achieved optimal pruning. effect achievednegligible computational storage overhead.However, FSS severely limited applicabilityrestricted optimization search;restricted tasks operator may applied (subsetselection);restricted search single solution;requires values states search space monotonically decreasing.is, value state cannot increase result operator application;form pruning supports optimistic pruning.5. OPUS AlgorithmsOPUS algorithms generalize idea search space reorganization FSS. Twovariations OPUS defined. OPUSs variant satisficing search (searchqualified object sought). OPUSo variant optimization search (searchobject optimizes evaluation function sought). Whereas FSS uses node valuespruning, OPUSo uses optimistic evaluation search space node.removes requirement values states search space monotonicallydecreasing opens possibility performing types pruning additionoptimistic pruning.438fiAn Efficient Admissible Algorithm Unordered Searchanalysis follow, comments apply equally variants nameOPUS employed. comment applies one variant algorithm,distinguished respective superscript.OPUS uses branch bound (Lawler & Wood, 1966) search strategy traversessearch space manner similar illustrated Figure 4 guaranteetwo equivalent nodes search space visited. However, organizessearch tree optimize effect pruning, achieving effect illustratedFigure 6 without significant computational storage overhead.Rather maintaining operator order, OPUS maintains node, n, setoperators n.active applied search space n. nodeexpanded, operators n.active examined determine pruned.operators pruned removed n.active. New nodes createdoperators remaining n.active sets active operators initializedensure every combination operators considered one nodesearch tree.kept mind possible many states search space maygoal states. satisficing search states satisfy given criteria goal states.optimization search, states optimize evaluation criteria goal states.efficiency sake, OPUS algorithms allow sections search space pruned evencontain goal state, long remain goal states remaining searchspace.5.1 OPUSsOPUSs algorithm presented Figure 8. description OPUSs followsconventions employed search algorithm descriptions provided Pearl (1984).definition OPUSs assumes single operator cannot appliedalong single path search space. operator may applied multipletimes, order Steps 8a 8b reversed. Unless otherwise specified,following discussion OPUS assumes operator may appliedalong single path.desired obtain solutions satisfy search criterion,Step 2 altered exit successfully, returning set solutions;Step 6b altered exit, rather add current node setsolutions;domain specific pruning mechanisms employed Step 7 also modifiedgoal state may pruned search space.form search could used assumption-based truth maintenance system findset maximally general consistent assumptions. would provide efficient searchwithout need maintain search explicit database inconsistent assumptionsATMS no-good set (de Kleer et al., 1990). Unless otherwise specified,discussion OPUS assumes single solution sought.algorithm specify order nodes selected expansionStep 3. Nodes may selected random, domain specific selection function,439fiWebbData structure:node, n, search tree associated three items information:n.state state search space associated node;n.active set operators explored sub-tree descending node;n.mostRecentOperator operator applied parent nodes state create current nodes state.Algorithm:1. Initialize list called OP EN unexpanded nodes follows,(a) Set OP EN contain one node, start node s.(b) Set s.active set operators, {o1 , o2 , ...on }(c) Set s.state start state.2. OP EN empty, exit failure; goal state exists.3. Remove OP EN node n, next node expanded.4. Initialize n.active set containing operators yet examined, calledRemainingOperators.5. Initialize {} set nodes, called N ewN odes, contain descendants npruned.6. Generate children n performing following steps every operator n.active,(a) Generate n0 , node n0 .state set state formed applicationn.state.(b) n0 .state goal state, exit successfully goal represented n0 .(c) Set n0 .mostRecentOperator o.(d) Add n0 N ewN odes.7. node n0 N ewN odes pruning rules determine sole remaining goal state accessible n0 using operators RemainingOperators, prunenodes search tree n0 search tree n follows,(a) Remove n0 N ewN odes.(b) Remove n0 .mostRecentOperator RemainingOperators.8. Allocate remaining operators remaining nodes processing node n0N ewN odes turn follows,(a) Remove n0 .mostRecentOperator RemainingOperators.(b) Set n0 .active RemainingOperators.9. Add nodes N ewN odes OP EN .10. Go Step 2.Figure 8: OPUSs Algorithm440fiAn Efficient Admissible Algorithm Unordered Searchorder nodes placed OP EN . First-in-first-out node selection resultsbreadth-first search last-in-first-out node selection results depth-first search.order processing also unspecified Steps 7, 8 9. Depending upondomain, practical advantage may obtained specific orderings steps.OPUSs used machine learning context search space generalizations may formed deletion conjuncts highly specific classificationrule. goal search uncover set general rules coveridentical objects training data covered original rule (Webb, 1994a).5.2 OPUSonumber changes warranted OPUS applied optimization search.following definition OPUSo, variant OPUS optimization search, assumestwo domain specific functions available. first functions, value(n), returnsvalue state node n, higher value returned, higherpreference state1 . second function, optimisticV alue(n, o) returns valueexists node, b, created application combinationoperators set operators state node n, b represents best solution(maximizes value search space), optimisticV alue(n, o) less value(b).used pruning sections search tree. general, lower values returnedoptimisticV alue, greater efficiency pruning. time, possible prunenode optimistic value less equal best value nodeexplored date.OPUSo able take advantage presence optimistic values optimizeeffect pruning beyond obtained solely maximizing proportionsearch space placed nodes immediately pruned. Generalizing heuristicused FSS, nodes lower optimistic values given active operators thusgreater proportions search space placed beneath nodes higheroptimistic values. achieved order processing Step 9. rationalestrategy lower optimistic value higher probabilitynode associated search tree pruned expanded. Maximizingproportion search space located nodes low optimistic value maximizesproportion search space pruned thus explicitly explored.Figure 9 illustrates effect respect simple machine learning tasksearchpropositional expression describes target examples non-targetexamples. seven search operators represent conjunction specific propositionmale, f emale, single, married, young, mid old, respectively. Search startsexpression anything. total 128 expressions may formed conjunctioncombination expressions. Twelve objects defined:male, single, young, TARGETmale, single, mid, TARGETmale, single, old, TARGETmale, married, young, NON-TARGET1. ease exposition, assumed optimization means maximization value. wouldtrivial transform algorithm discussion accommodate forms optimization.441fiWebbmale, married, mid, NON-TARGETmale, married, old, NON-TARGETfemale, single, young, NON-TARGETfemale, single, mid, NON-TARGETfemale, single, old, NON-TARGETfemale, married, young, NON-TARGETfemale, married, mid, NON-TARGETfemale, married, old, NON-TARGET.objects, first three distinguished targets. value expressiondetermined two functions, negCover posCover. negCover expressionnumber non-target objects matches. posCover expressionnumber target objects matches. expression anything matches objects.value expression negCover equal zero. Otherwise value equalsposCover. preference function avoids expressions cover negative objectsfavors, expressions cover negative objects, expressions coverpositive objects. optimistic value node equals posCover nodesexpression.Figure 9 depicts nine nodes considered OPUSo search task.node following listed:expression;number target number non target objects matched (cover);value;potential value;operators placed nodes set active operators hence includedsearch tree node.search space traversed follows. first node, anything, expanded, producing seven children values optimistic values determined. nodepruned potential values greater best value far encountered.active operators distributed, maximizing proportion search spaceplaced nodes low optimistic values. two nodes highest optimisticvalues, male single, one receives active operator receives firstsole active operator. One expanded. one activeoperators, single, nodes generated. other, male, expanded, generating single node, male single, value 3. Immediately node generated,remaining open nodes pruned none optimistic value greaternew maximum value, 3.Note nodes pruned node malesingle considered as,point, node encountered lower optimistic value best actualvalue. Consequently, search tree distributed accord potential value,set active operators node male would {f emale, single, married, young, mid, old}.Instead considering single node male expanded, would necessary442fiAn Efficient Admissible Algorithm Unordered SearchmaleCover=3/3Value=infinityPotVal=3AO={single}male singleCover=3/0Value=3PotVal=3AO={}femaleCover=0/6Value=infinityPotVal=0AO={male, married,single, young, mid old }singleCover=3/3Value=infinityPotVal=3AO={}anythingCover=3/9Value=infinityPotVal=3AO={male, female,married, single,young, mid, old}marriedCover=0/6Value=infinityPotVal=0AO={male, single, young,mid, old }youngCover=2/2Value=infinityPotVal=2AO={male, single,mid, old}midCover=2/2Value=infinityPotVal=2AO={male, single, old}oldCover=2/2Value=infinityPotVal=2AO={male, single}Figure 9: Effect pruning search tree ordered optimistic value443fiWebbconsider six nodes. search space complex continued depth threebeyond, would commensurate increase proportion search spaceexplored unnecessarily.Note also search example terminate goal node firstencountered, system cannot determine goal node nodesmight higher values explored pruned.5.2.1 OPUSo AlgorithmOPUSo, algorithm achieving effect, defined Figure 10. Noteoptimistic pruning need performed Step 8 performed Step 10a,irrespective.definition OPUSo assumes single operator cannot appliedalong single path search space. allow multiple applications singleoperator, order Steps 9a 9b reversed.algorithm could also modified identify return maximal solutionsmodification similar outlined allow OPUSs return solutions.possible improve performance OPUSo lower limitacceptable solution. Then, objective search find highest valued nodelong value greater pre-specified minimum. case, nodes whosepotential value less equal minimum may also pruned Step 10a.Like OPUSs, OPUSo specify order nodes OPENexpanded (Step 4). Selection node highest optimistic value minimizesize search tree. single node n optimizes optimistic value,search cannot terminate n expanded. node loweroptimistic value may yield solution value higher optimistic value n.However, expansion n may yield solution value higher candidates optimistic values, allowing candidates discarded without expansion.Thus, selecting single node highest optimistic value optimal respectnumber nodes expanded maximizes number nodes may prunedwithout expansion. multiple nodes maximize optimistic value, least onemust expanded search terminate (and searchterminate expansion node leads node value equal optimisticvalue.)many cases important consider number nodes exploredalgorithm, rather number nodes expanded. node explored evaluated.Every time node expanded, children explored. Many childrenmay pruned, however, never expanded. addition minimizing numbernodes expanded, form best-first search also minimize number nodesexplored (within constraint nodes equal optimistic valuespossible anticipate one select order minimize number nodes explored).due strategy algorithm employs distribute operators beneath nodes.nodes OPUSo expands best-first search highest optimisticvalue. OPUSo always allocates fewer active operators node higher optimistic valuenode lower optimistic value. number nodes examined node444fiAn Efficient Admissible Algorithm Unordered SearchAlgorithm:1. Initialize list called OP EN unexpanded nodes follows,(a) Set OP EN contain one node, start node s.(b) Set s.active set operators, {o1 , o2 , ...on }(c) Set s.state start state.2. Initialize BEST , best node examined far, s.3. OP EN empty, exit successfully solution represented BEST .4. Remove OP EN node n, next node expanded.5. Initialize n.active set containing operators yet examined, calledRemainingOperators.6. Initialize {} set nodes, called N ewN odes, contain descendants npruned.7. Generate children n performing following steps every operator n.active,(a) Generate n0 , node n0 .state set state formed applicationn.state.(b) value(n0 ) greater value(BEST )i. Set BEST n0 .ii. Prune search tree removing OP EN nodes xoptimisticV alue(x, x.active) less value(BEST ).(c) Add n0 N ewN odes.(d) Set n0 .mostRecentOperator o.8. node n0 N ewN odes pruning rules determine sole remaining goal state accessible n0 using operators RemainingOperators, prunenodes search tree n0 search tree n follows,(a) Remove n0 N ewN odes.(b) Remove n0 .mostRecentOperator RemainingOperators.9. Allocate remaining operators remaining nodes processing node n0N ewN odes turn follows, time selecting previously unselected node minimizes optimisticV alue(n0 , RemainingOperators),(a) Remove n0 .mostRecentOperator RemainingOperators.(b) Set n0 .active RemainingOperators.10. Perform optimistic pruning adding remaining nodes OP EN processingnode n0 N ewN odes turn follows,(a) optimisticV alue(n0 , n0 .active) greater value(BEST ),i. Add n0 OP EN .11. Go Step 3.Figure 10: OPUSo algorithm445fiWebbn expanded equals number active operators n. Hence, number nodesexamined nodes expanded minimized (within constraints useinformation derived current state operatorsactive state).However, best-first approach minimizes number nodes expanded, maystorage optimal due large potential storage overheads. storage overheadconcern, depth-first rather best-first traversal may employed, costpotential increase number nodes must expanded. depth-first searchemployed, nodes added OP EN order optimistic value Step 10.ensure nodes open single depth expanded best-first manner,benefits outlined above.5.2.2 Relation Previous Search AlgorithmsOPUSo viewed amalgamation FSS (Narendra & Fukunaga, 1977) A*(Hart, Nilsson, & Raphael, 1968). FSS performs branch bound search unorderedsearch spaces, traversing search space visit state dynamically organizing search tree maximize proportion search space placedunpromising operators. However, FSS requires values states searchspace monotonically decreasing. is, value state cannot increase resultoperator application. OPUSo generalizes FSS employing actualvalues states optimistic evaluation nodes search tree, manner similarA*. consequence, two minor constraints upon values statesoptimistic values nodes search spaces OPUSo search.requirementsleast one goal state g node n, g lies node n searchtree, optimistic value n lower value g;states maximal value goal states.follows OPUSo wider applicability FSS.OPUSo also differs FSS integrating pruning mechanisms optimisticpruning search process. facility crucial searching large search spacesencountered machine learning.innovation OPUS algorithms use restricted set operatorsavailable node search tree enable focused pruning would otherwisecase. may circumstances would possible reach goalstate node n, application operators activen. pruning rules able take account active operators provide pruningcontextpruning would otherwise possible. Similarly, set activeoperators used calculate concise estimate optimistic valuewould otherwise possible.OPUSo differs A* manner dynamically organizes search treemaximize proportion search space placed unpromising operators.also differs A* A* relies upon value node equivalent446fiAn Efficient Admissible Algorithm Unordered Searchsum costs operations lead node, whereas OPUS allows methoddetermining nodes value.Rymon (1993) discusses dynamic organization search tree admissible searchunordered search spaces purpose altering topology data structure (SE-tree) produced. contrasts use dynamic organization searchtree OPUSo increase search efficiency.5.3 OPUS Non-admissible Searchpointed above, although OPUS algorithms designed admissiblesearch, applied non-admissible pruning rules may also usednon-admissible search. may useful efficient heuristic search required.non-admissible heuristic search strategies embed heuristics search technique.example, beam search relies upon use fixed maximum number alternative optionsconsidered stage search. heuristic prunen best solutions stage search. precise implications heuristicparticular search task may difficult evaluate. contrast, use OPUSnon-admissible pruning rules places non-admissible heuristic clearly defined rulemay manipulated suit circumstances particular search problem.Another feature OPUSo stages available best solution encountered date search. means search terminatedtime. terminated prematurely, current best solution would returnedunderstanding solution may optimal. algorithm employedcontext, may desirable employ best-first search, opening nodes highestactual (as opposed optimistic) value first, assumption leadearly investigation high valued nodes.5.4 Complexity Efficiency ConsiderationsOPUS ensures state examined (unless identical statesformed different combinations operator applications), using similar search tree organization strategy fixed-order search. differs, however, instead placinglargest subsection search space highest ordered operator, secondlargest subsection second highest ordered operator, on, whenever pruningoccurs, largest possible proportion search space placed pruned node,hence immediately pruned.n operators active node e expanded, search treeincluding node contain every combination number operators (theapplication none operators results e). Thus, search tree includinge contain 2n nodes. Exactly half these, 2n1 , label including singleoperator o. OPUS ensures operator pruned node e expanded,nodes containing removed search tree e never examined(except, course, node reached single application must examinedorder determine pruned). Thus, search tree node almostexactly halved single operator pruned. subsequent operator prunednode reduces remaining search tree proportion. Thus, size447fiWebbremaining search tree divided almost exactly 2p , p number operatorspruned.contrast, number nodes pruned fixed-order search depends uponranking operator within fixed operator ranking scheme. highestranked operator proportion search tree pruned OPUS.general, operator pruned, nodes whose labels include operatorcombination exclusively lower ranked operators pruned. effect illustratedFigure 5 pruning {c} removes {c, d} search tree. Thus,2nr 1, nodes immediately pruned search tree, n numberoperators active node expanded r ranking within operatorsoperator pruned, highest rank 1. contrasts 2n1 1nodes pruned OPUS.However, difference number nodes explored two strategiesquite great analysis might suggest, (assuming availability reasonableoptimistic pruning mechanism) fixed-order search also prune operator every timeexamined deeper search tree combination higher ranked operators.Thus, Figure 5, eventually examined, pruning would occur nodes{a, b, c}, {a, c} {b, c}. Thus, {a, b, c, d}, {a, c, d} {b, c, d} would also prunedsearch tree. words, fixed-order search, operator prunedconsidered combination lower ranked operator, consideredevery combination number higher ranked operators. 2r1 combinationshigher ranked operator. follows fixed-order search considers many nodesOPUS single operator pruned. Thus, operator prunednode n, OPUS explores 2r1 less nodes n fixed-order search.rank order operators pruned tend grow number operatorsgrows, follows that, average case, advantage accrued use OPUSgrow exponentially number operators grows. OPUS tend greatestrelative advantage largest search spaces.Note OPUS always able guarantee maximal possible pruningoccurs result single pruning action. example, OPUS usedsearch space subsets set items, determined supersetset node may solution, items active currentnode, supersets contain items active may explored elsewheresearch tree. algorithm could prune supersets could performpruning OPUS. might claimed Schlimmers (1993) search methodperforms pruning, recalled prevent pruned nodesgenerated elsewhere tree, rather, ensures nodes prunedgenerated. OPUS, armed suitable pruning rules, also able prunenodes encountered. OPUS maximizes pruning performed within constraintslocalized information access.However, constraint provided active operators prevents OPUSperforming pruning, also enables perform pruning would otherwise possible. necessary considering whether prunenode determine whether nodes reached active operators may containsolution. Thus, continue example subset search, even supersets set448fiAn Efficient Admissible Algorithm Unordered Searchcurrent node n potential solutions, still possible prune search treen supersets potential solutions contain items activen. Schlimmers (1993) approach allow pruning context.illustrate effect, let us revisit search space examined Figures 1 7. Eventhough search space {c} pruned, optimal pruning cannot takeaccount optimistic evaluations nodes mechanisminformation communicated optimistic evaluation function (otheractually exploring space node evaluated, defeats purposeoptimistic evaluation). example, evaluating optimistic value node {a},optimistic evaluation function cannot return different value would case{c} pruned. contrast, optimistic evaluation function employedOPUSo take account taking active operators current nodeconsideration. optimistic evaluation function described Section 6.1 below.often possible use information particular operators availablesearch tree node substantially improve quality optimistic evaluationnode.also noted algorithm employ backtracking guarantee minimize number nodes expanded depth-first search.poor node chosen expansion depth-first search, system stuckexplore search space node return explore alternatives.algorithm guarantee poor selection unless optimistic evaluation functionhigh enough accuracy prevent need backtracking. follows algorithmrequires backtracking guarantee minimize number nodesexpanded. Thus, OPUS heuristic respect minimizing computational complexitydepth-first search.storage requirements OPUS depend upon whether depth, breadth bestfirst search employed. depth-first search employed, maximum storage requirementless maximum depth search tree multiplied maximum branching factor. However, breadth best-first search employed, worst case, storagerequirement exponential. stage search, storage requirementstoring frontier nodes search. number frontier nodes cannot exceednumber leaf nodes complete search tree. search operator mayapplied (subset selection), pruning, number leaf nodes2n1 , n number operators. assertion justified follows.order operators considered invariant, nodes reached via last operator considered leaf node. search admissible, last operator mustconsidered every combination operators. 2n1 , combinationsoperators. order operators considered alter numberleaf nodes absence pruning. search limit numberapplications single operator (sub-multiset selection) upper limitpotential storage requirements.Irrespective storage requirements, worst case OPUS exploreevery node search space. occur pruning possible search.operators applied per solution, number nodes search spaceequal 2n , n number operators. Thus, worst case computational449fiWebbcomplexity OPUS exponential, irrespective whether depth, breadth best-firstsearch employed.OPUS clearly inappropriate, terms computational and, using breadthbest-first search, storage requirements, search problems substantial proportions search space cannot pruned. domains substantial pruningpossible, however, average case complexity (computational and/or storage) may turnpolynomial. Experimental evidence indeed case machinelearning tasks presented Section 6.3.5.5 Search Efficiency OPUS Might Improvednoted Section 5.4, OPUS algorithms always able guaranteemaximum possible amount pruning performed. noted, one restriction uponamount pruning performed localization inherent use active operators.localization allows pruning would otherwise possible, alsopotential restrict number supersets set operators prunednode also pruned. may value developing mechanisms enablepruning propagated beyond node pruning action occurssub-tree node.Another aspect algorithms positive negative aspects typeinformation returned pruning mechanisms. mechanisms allow pruningbranch search tree long least one goal branch.contrasts alternative strategy pruning branches leadgoal. strategy used beneficial, maximizes amount pruningperformed. However, always possible branch containing goal couldfound little exploration pruned favor branch containing goalrequires extensive exploration uncover. potential gain augmentingcurrent pruning mechanisms means estimating search cost uncoveringgoal beneath branch tree.6. Evaluating Effectiveness OPUS AlgorithmsTheoretical analysis demonstrated OPUS explore fewer nodes fixed-ordersearch magnitude advantage increase size searchspace increases. However, precise magnitude gain depend upon extentdistribution within search tree pruning actions. interest,number distinct elements OPUS algorithms, includingoptimistic pruning;pruning (pruning addition optimistic pruning); dynamic reorganizationsearch tree; maximization proportion search space placed nodeslow optimistic value. following experiments evaluate magnitude advantageOPUS obtained real world search tasks explore relative contributiondistinct elements OPUS algorithms.end, OPUSo applied class real search tasksfinding pure conjunctiveexpressions maximize Laplace accuracy estimate respect training setpreclassified example objects. is, example, search task CN2 purportsheuristically approximate (Clark & Niblett, 1989) forming disjuncts disjunc450fiAn Efficient Admissible Algorithm Unordered Searchtive classifier. Machine learning systems employed OPUSo manner developrules inclusion sets decision rules (Webb, 1993) decision lists (Webb,1994b). (The current experiments performed using Cover learning system, which,default, performs repeated search pure conjunctive classifiers within CN2-like covering algorithm develops disjunctive rules. extended search disjunctiverules used experiments, makes difficult compare alternative searchalgorithms. because, two alternative algorithms find different pure conjunctiverules first disjunct, subsequent search explore different search spaces.)Numerous efficient admissible search algorithms exist developing classifiersconsistent training set examples. two classic algorithms purposeleast generalization algorithm (Plotkin, 1970) version space algorithm (Mitchell,1977). least generalization algorithm finds specialized class descriptioncovers objects training set containing positive examples. version space algorithm finds class descriptions complete consistent respect trainingset positive negative examples. Hirsh (1994) generalized version spacealgorithm find class descriptions complete consistent within definedbounds training examples. least generalization version space algorithmsusually require strong inductive bias class description language (restrictiontypes class descriptions considered) find useful class descriptions(Mitchell, 1980). SE-tree-based learning (Rymon, 1993) demonstrates admissible searchset consistent class descriptions within complex class description languagesmay usefully employed least generalization version space algorithms. Oblow(1992) describes algorithm employs admissible search pure conjunctive termswithin heuristic outer search k-DNF class descriptions consistenttraining set.However, many learning tasks desirable consider class descriptionsinconsistent training set. One reason training set may containnoise (examples inaccurate). Another reason may possible accurately describe target class available language expressing class descriptions.case necessary consider approximations target class. reasontraining set may contain insufficient information reliably determine exactclass description. case, best solution may approximation knownincorrect strong evidence level error low.Clearwater Provost (1990) Segal Etzioni (1994) use admissible fixedorder search explore classifiers inconsistent training set. However,admissible search Clearwater Provost (1990) computationally feasible largesearch spaces. Segal Etzioni (1994) bound depth search space consideredorder maintain computational tractability. Smyth Goodman (1992) use optimisticpruning search optimal rules, structure search ensure statessearched multiple times. previous admissible search algorithmemployed machine learning find classifiers inconsistent trainingset maximize arbitrary preference function. following experiments seekdemonstrate search feasible using OPUS.allowed class description may inconsistent training set,helpful employ explicit preference function. function applied451fiWebbclass description returns measure desirability. evaluation usually takeaccount well description fits training set may also include bias towardparticular types class descriptions, example, preference syntactic simplicity.preference function expresses inductive bias (Mitchell, 1980).OPUSo may employed admissible search contexts, provided search spacedefined may traversed finite number unordered search operators.example, OPUSo may employed search class description languagepure-conjunctive descriptions examining search space starting generalpossible class description true employing search operators, effectconjoining specific clause current description. search may performedarbitrary preference function, provided appropriate optimistic evaluation functionsdefined.next section describes experiments OPUSo applied manner.6.1 Search Taskpure conjunctive expressions consisted conjunctions clauses form attribute 6=value. attributes two values, language expressivelanguage allowing conjunctions clauses form attribute = value. Indeed,equivalent expressiveness language supports internal disjunction. example, respect attribute values x, z, language restrictedconjunctions equality expressions cannot express 6= x, whereas language restrictedconjunctions inequality expressions express = x using expression 6= 6= z.internal disjunctive (Michalski, 1984) terms, 6= x equivalent = z.notedattributes two values search space conjunctions inequality expressions far larger search space conjunctions equalityexpressions. attribute, size search space multiplied 2nformer n + 1 latter, n number values attribute.software employed experimentation also used search smallersearch spaces equality expressions effects demonstratedfollowing experiments.Search starts general expression, true. operator performs conjunction current expression term 6= v, attribute vsingle value attribute.Laplace (Clark & Boswell, 1991) preference function used determine goalsearch. function provides conservative estimate predictive accuracyclass description, e. definedvalue(e) =posCover(e) + 1posCover(e) + negCover(e) + noOf ClassesposCover(e) number positive objects covered e; negCover(e)number negative objects covered e; noOf Classes number classeslearning task.452fiAn Efficient Admissible Algorithm Unordered SearchLaplace preference function trades-off accuracy generality. favors classdescriptions cover positive objects class descriptions cover fewer,favors class descriptions lower proportion cover negativehigher. following study, Laplace preference function employedpruning mechanism Step 10a OPUSo algorithm pruned sectionssearch space optimistic values less equal value class descriptioncovered objects. solution value higher obtainedclass description covered objects, rule developed class.optimistic value function derived observation cover specializations expression must subsets cover expression. Thus, specializationsexpression may cover positive objects, may cover fewer negative objectscovered original expression. Laplace preference function maximized positive cover maximized negative cover minimized, specializationexpression node may higher value obtained positivecover expression smallest negative cover within sub-tree node.smallest negative cover within sub-tree node n obtained expressionformed applying operators active n expression n.pruning performed application cannotImprove(n1 , n2 ),boolean function true two nodes n1 n2 search tree n2either child sibling n1 specialization n2 may higher valuehighest value search tree n1 inclusive excluding search treen2 . function may definedcannotImprove(x, y) neg(x) neg(y) pos(x) pos(y)neg(n) denotes set negative objects covered description node npos(n) denotes set positive objects covered description node n.cannotImprove(n1 , n2 ) search n2 cannot lead higher valued resultobtained search specializations n1 excluding nodes search spacen2 . shown n1 parent n2 child node follows.n1 parent n2 expression n2 must specialization expressionn1 operators available n2 must available n1 . expression gspecialization, s, neg(g) neg(s) neg(g) = neg(s) (as specializationdecrease cover). follows specialization n2 , n3 , obtainedapplications operators O, must specialization n1 obtained applicationoperators O, n4 , generalization n3 identical negative covern3 . n4 generalization n3 , must cover positive objects covered n3 .Therefore, n4 must equal greater positive cover equal negative cover n3consequently must equal greater value. follows must possiblereach n1 node least great value greatest valued node n2without applying operator led n1 n2 .Next consider case n1 n2 siblings. follows definitioncannotImprove neg(n1 ) neg(n2 ) pos(n1 ) pos(n2 ). Let operators o1o2 led parent node p n1 n2 , respectively. followso2 cannot exclude negative objects expressions p also excluded o1o1 cannot exclude positive objects expressions p also excluded453fiWebbTable 1: Summary experimental data setsDomainAudiologyHouse Votes 84LensesLymphographyMonk 1Monk 2Monk 3Multiplexor (F11)MushroomPrimary TumorSlovenian Breast CancerSoybean LargeTic Tac ToeWisconsin Breast CancerDescriptionMedical diagnosisPredict US Senators politicalaffiliation voting record.Spectacle lens prescription.Medical diagnosis.Artificial data.Artificial data.Artificial data.Artificial data, requiring disjunctive concept description.Identify poison mushrooms.Medical diagnosis.Medical prognosis.Botanical diagnosis.Identify lost positions.Medical diagnosis.#Values16248#Objects226435#Classes242960171717222414855660155450034222212642571352791812433928630795869922221922o2 . Therefore, application o2 n1 effect negative coverexpression may reduce positive cover. expression e reached n2sequence operator applications O, application n1 cannot result expressionlower positive higher negative cover e.cannotImprove function employed prune nodes Step 8 OPUSoalgorithm.6.2 Experimental Methodsearch performed fourteen data sets UCI repository machine learningdatabases (Murphy & Aha, 1993). data sets repositoryresearcher could time experiments identify capable readily expressedcategorical attribute-value learning tasks. fourteen data sets describedTable 1. number attribute values (presented column 3) treats missing valuesdistinct values. space class descriptions OPUS considers domain (andhence size search space examined pure conjunctive rule developed)2n , n number attribute values. Thus, Audiology domain,class description developed, search space size 2162 . Columns 4 5 presentnumber objects number classes represented data set, respectively.search repeated class data set. search,objects belonging class question treated positive objectsobjects data set treated negative objects. search performed using454fiAn Efficient Admissible Algorithm Unordered Searchfollowing search methodsOPUSo; OPUSo without optimistic pruning; OPUSowithout pruning; OPUSo without optimistic reordering; fixed-order search,performed Clearwater Provost (1990), Rymon (1993), Schlimmer (1993), SegalEtzioni (1994) Webb (1990).Optimistic pruning disabled removing condition Step 10a OPUSoalgorithm. words, Step 10(a)i always performed.pruning disabled removing Step 8 OPUSo algorithm.Optimistic reordering disabled changing Step 9 process node predetermined fixed-order, rather order optimistic value. treatment,topology search tree organized fixed-order, operators prunednode removed consideration entire subtree node.Fixed-order search emulated disabling Step 8b disabling optimistic reordering, described above.algorithms extent under-specified. OPUSo, optimistic pruningpruning leave unspecified order operators leading nodesequal optimistic values considered Step 9. ambiguities resolvedfollowing experiments ordering operators leading nodes higher actualvalues first. two operators tied optimistic actual values, operatormentioned first names file describes data selected first.optimistic reordering fixed-order search leave unspecified fixed-orderemployed traversing search space. fixed-order search representative previous approaches unordered search employed machine learning, thusimportant obtain realistic evaluation performance, ten alternative randomorders generated employed fixed-order search task. While, duehigh variability performance different orderings, would desirableexplore ten alternative orderings, infeasible due tremendouscomputational demands algorithm. comparison optimistic reorderingconsidered less crucial, used solely evaluate effectiveness one aspectOPUSo algorithm, thus, due tremendous computational expensealgorithm, single fixed ordering used, employing order attribute valuesmentioned names file.algorithms leave unspecified order nodes equal optimisticvalues selected OP EN best-first search, directly expandeddepth-first search. best first search nodes equal optimistic values removedOP EN last-in-first-off order. depth-first search, nodes equal optimisticvalue expanded order employed allocating operators Step 9.Note fixed-order search OPUSo disabled optimistic reordering conditions used optimistic pruning. Note also fixed-order searchordered topology search tree manner depicted Figure 4, exploredtree either best depth-first manner.6.3 Experimental ResultsTables 2 3 present number nodes examined search experiment.data set total number nodes explored condition indicated.455fiWebbTable 2: Number nodes explored best-first searchData setAudiologyHouse Votes 84LensesLymphographyMonk 1Monk 2Monk 3Multiplexor (F11)MushroomPrimary TumorSlovenian B. C.Soybean LargeTic Tac ToeWisconsin B. C.OPUSo7,044533411,1423574,3262812,76939110,89217,4188,3042,894447,786optimisticpruning6611761,1439,1566,57825,77596,37139210,8934,810,12983384,222,641pruning24,199554411,6843714,3352812,76978813,13732,96521,4182,9021,159,011optimisticreordering355,04038658,33592510,0126824,932233,5794,242,97821,551,43616,559Fixed-order(mean)1,319,911642,251,6527885,8956564,94829,914,84042,669,82216,471Execution terminated exceeding virtual memory limit 250 megabytes.one ten runs completed.fixed-order search, mean ten runs presented. Tables 4 5 presentfixed-order search number runs completed successfully, minimum numbernodes examined successful run, mean number nodes examined successful runs(repeated Tables 2 3) standard deviations runs. Every nodegenerated Step 7a counted tally number nodes explored. hyphen() indicates search could completed number open nodes madesystem exceed predefined virtual memory limit 250 megabytes. asterisk (*)indicates search terminated due exceeding pre-specified compute timelimit twenty-four CPU hours. (For comparison, longest CPU time taken dataset OPUSo sixty-seven CPU seconds Wisconsin Breast Cancer datadepth-first search.)noted one pure conjunctive rule developed class.separate search performed rule, number searches performed equalsnumber classes. Thus, Audiology data using best-first search OPUSo explored7,044 nodes perform 24 admissible searches 2162 node search space.two search tasks OPUSo best-first search explore nodesalternative. Lenses data, OPUSo explores 41 nodes optimistic reorderingexplores 38. Monk 2 data, OPUSo explores 4,326 nodes best ten fixedorder runs different random fixed orders explores 4,283 nodes. possibleoutcomes arisen situations two sibling nodes share optimisticvalue. case, two approaches select different nodes expand first, one456fiAn Efficient Admissible Algorithm Unordered SearchTable 3: Number nodes explored depth-first searchData setAudiologyHouse Votes 84LensesLymphographyMonk 1Monk 2Monk 3Multiplexor (F11)MushroomPrimary TumorSlovenian B. C.Soybean LargeTic Tac ToeWisconsin B. C.OPUSo7,011568381,20036416,3452892,91438618,20930,6479,5623,876465,058optimisticpruning*17,067,30251339,063,30354,21885,42563,057188,120*34,325,234172,073,241*11,496,736*pruning17,191596381,82537816,4272892,91476123,66861,39123,8604,0101,211,211optimisticreordering3,502,47510,04638728,27698012,8795886,9611,562,0063,814,422271,328,08017,138,46793,521*Fixed-order(mean)*3,674,4186622,225,7451,34812,7911,2366,130132,107,51331,107,648308,209,464*110,664** Execution terminated exceeding 24 CPU hour limit.three ten runs completed.Table 4: Number nodes explored best-first fixed-order searchData setAudiologyHouse Votes 84LensesLymphographyMonk 1Monk 2Monk 3Multiplexor (F11)MushroomPrimary TumorSlovenian B. C.Soybean LargeTic Tac ToeWisconsin B. C.Runs01010101010101001010100Minimum451,03851597,8424634,2835274,21010,552,12942,669,8228,046Meansd1,319,911642,251,6527885,8956564,94829,914,84042,669,82216,471624,95791,454,58322593111036412,390,14605,300Execution terminated ten runs exceedingvirtual memory limit 250 megabytes.457fiWebbTable 5: Number nodes explored depth-first fixed-order searchData setAudiologyHouse Votes 84LensesLymphographyMonk 1Monk 2Monk 3Multiplexor (F11)MushroomPrimary TumorSlovenian B. C.Soybean LargeTic Tac ToeWisconsin B. C.Runs010101010101010310100100Minimum*1,592,39150484,6945539,2746274,467105,859,32010,458,421110,101,761*49,328*Meansd*3,674,4186622,225,7451,34812,7911,2366,130132,107,51331,107,648308,209,464*110,664**2,086,1591227,250,8349222,6868911,16422,749,21114,907,744303,800,659*65,809** Execution terminated ten runs exceeding24 CPU hour limit.may turn better choice other, leading exploration fewernodes. test plausibility explanation, OPUSo run Lensesdata set Step 8 altered ensure two siblings equal optimistic valueordered order employed optimistic reordering.resulted exploration 36 nodes, fewer alternative. OPUSofixed-order run fixed-order using order attribute declaration datafile determine operator order OPUSo using order order siblingsequal optimistic values, numbers nodes explored Monk 2 data 4,302OPUSo 8,812 fixed-order search.notable effect apparent small search spaces.significant suggests effect small magnitude resultingpoor choice node expand two nodes equal optimistic value.expected. Consider case two nodes n1 n2 equal highestoptimistic value, v, n1 leads goal whereas n2 not. n2 expanded first,long child n2 optimistic value greater equal v, next nodeexpanded n1 , n1 node highest optimistic value. (Ifchild n2 optimistic value greater v, optimistic evaluation function cannotgood, fact n2 optimistic value v means node n2value greater v.) Thus, number unnecessary node expansions dueeffect never exceed number times nodes equal highest optimisticvalues encountered search.contrast case best-first search, discussed Section 5.4, OPUSheuristic respect minimizing number nodes expanded depth-first search.458fiAn Efficient Admissible Algorithm Unordered SearchNonetheless, one search task, Monk 2 data set, OPUSo explorenodes depth-first search (16,345) alternative (both optimistic reorderingfixed-order search explore 12,879 12,791 nodes respectively). resultsdemonstrate heuristic optimal data. noted, however,single exception depth-first search occurs relatively small searchspace. suggests efficient exploration search space poor choicenode much minimize damage done poor choice, evenbacktracking case depth-first search.five data sets (House Votes 84, Lymphography, Mushroom, Primary TumorSoybean Large), disabling optimistic pruning little effect best-first search. Disabling optimistic pruning always large effect depth-first search. best-firstsearch smallest increase caused disabling optimistic pruning increaseone node Lymphography Mushroom data sets. data setspossible complete search without optimistic pruning, biggest effectalmost 1,500 fold increase number nodes explored Tic Tac Toedata. depth-first search, data sets processing could completedwithout optimistic pruning, smallest increase five-fold increase Monk 2data largest increase 30,000 fold increase Lymphography data.seven data sets (House Votes 84, Lenses, Monk 1, Monk 2, Monk 3, F11 Multiplexor,Tic Tac Toe) disabling pruning little effect best-first depth-firstsearch. largest effects 2.5 fold increases Soybean Large WisconsinBreast Cancer data sets best-first search Audiology, Soybean LargeWisconsin Breast Cancer data sets depth-first search.results apparent data setspruning technique little effect (so long also employed), alsodata sets pruning halves amount search space exploreddata sets optimistic pruning reduces amount search space exploredthousandths would otherwise explored.effect optimistic reordering also highly variable. two search tasks (bestfirst search Lenses data set depth-first search Monk 2 data set) useactually resulted slight increase number nodes explored. discussedabove. many cases, however, effect disabling optimistic reordering far greaterdisabling optimistic pruning. Processing could completed withoutoptimistic reordering three best-first search tasks one depth-first searchtasks. tasks search could completed, largest effect best-firstsearch 2,500 fold increase number nodes explored Soybean Large data.depth-first search, tasks search could completed, largesteffect 8,000 fold increase Slovenian Beast Cancer data. woulddesirable evaluate effect alternative fixed-orderings operators results,seems optimistic reordering critical general success algorithm.one data set (the Monk 2 data depth-first search), fixed-order searchaverage explores substantially nodes OPUSo. asserted Section 5.4average case advantage use OPUSo opposed fixed-order searchtend grow exponentially number search operators increases. numbersearch operators search tasks equal number attribute values459fiLog AdvantageWebb20191817161514131211109876543210-1best-first searchdepth-first search10 20 30 40 50 60 70 80 90 100 110 120 130 140Search Space SizeFigure 11: Plot difference nodes explored fixed-order OPUSo searchsearch space size.corresponding data sets. Analysis Tables 2 3 reveals relative advantageOPUSo data sets fewest attribute values (Lenses, Monk 1, 2 3,F11 Multiplexor) approximately two-fold reduction number nodes examined.number attribute values increases, relative advantage. fourdata sets greatest number attribute values (Audiology, Mushroom, SoybeanLarge Wisconsin Breast Cancer) one case (depth-first search Mushroomdata) fixed-order search terminate. one case, OPUSo enjoys 350,000-foldadvantage. results lend credibility claim OPUSos average case advantagefixed-order search exponential respect size search space.illustrated Figure 11. figure, searches fixed-order search terminatedwithin resource constraints, size search space plotted log2 (f /o)f number nodes explored fixed-order search number nodesexplored OPUSo.seems clear results admissible fixed-order search practicalmany search tasks within scope current technology.interesting observe best-first search, four artificial datasets (Monk 1, Monk 2, Monk 3 F11 Multiplexor) fixed-order search often exploresslightly fewer nodes OPUSo optimistic reordering disabled. difference two types search latter deletes pruned operators setsactive operators higher ordered operators whereas former not. Thuslatter prunes nodes search tree pruning operation. seems460fiAn Efficient Admissible Algorithm Unordered Searchcounter-intuitive increased pruning sometimes lead explorationnodes. understand effect necessary recall pruning prunesolutions search tree long alternative solutions available.artificial data sets question, retaining alternative solutions search tree casesleads slight increase search efficiency alternative encountered earlierfirst solution. Despite minor advantage number artificial data setsfixed-order search OPUSo optimistic reordering disabled, latter enjoys largeadvantage data sets processing could completed. HouseVotes 84 data, fixed-order search explores 3.5 times many nodes best-firstsearch 350 times many depth-first search.seen reason believe average case numbernodes explored OPUSo polynomial respect search space sizemachine learning search tasks. numbers nodes explored three largestsearch spaces certainly suggestive exponential explosion numbersnodes examined (Audiology2162 nodes search space: 7,044 7,011 nodes examined. Soybean Large2135 nodes search space: 8,304 9,562 nodes examined.Mushroom2126 nodes search space: 391 386 nodes examined.)interesting little difference number nodes explored OPUSousing either best depth-first search data sets. Surprisingly, slightly fewer nodesexplored depth-first search three data sets (Audiology, Lenses Mushroom). similar reasons presented context occasional slight advantage enjoyed fixed-order search OPUSo optimistic reorderingdisabled. cases depth-first search fortuitously encounters alternative solutionsfound best-first search. evaluate plausibility explanation, OPUSorun three data sets question using fixed-order ordering order operatorsequal optimistic values. resulting numbers nodes explored Audiology:6678, Lenses: 36 Mushroom: 385. seen, numbers cases lowernumbers nodes explored depth-first search. case OPUSooutperformed best-first strategies, effect appears small magnitudethus significant small numbers nodes need explored. fourdata sets depth-first search explores substantially nodes best-first search(Slovenian Breast Cancer, 75%; Monk 2, 275%; Primary Tumor, 67%; Tic Tac Toe,33%).6.4 Summary Experimental Resultsexperiments demonstrate admissible search pure conjunctive classifiers feasible using OPUSo types learning task contained UCI repository.also support theoretical findings OPUSo general explore fewernodes fixed-order search magnitude advantage tend growexponentially respect size search space.Optimistic pruning pruning demonstrated individually providelarge decreases number nodes explored search spaces littleeffect others. Optimistic reordering demonstrated large impact uponnumber nodes explored.461fiWebbresults respect search largest search spaces suggestaverage case complexity algorithm less exponential respect searchspace size.7. Summary Future ResearchOPUS algorithms potential application many areas endeavor.used replace admissible search algorithms unordered search spaces maintainexplicit lists pruned nodes, currently used ATMS (de Kleer, 1986).may also support admissible search number application domains, learningclassifiers inconsistent training set, previously tackledheuristic search.addition applications admissible search, OPUS algorithms may alsoused efficient non-admissible search application non-admissible pruningrules. OPUSo algorithm also able return solution prematurely terminatedtime, although solution may non-optimal.availability admissible search important step forward machine learningresearch. studies paper employed OPUSo optimize Laplacepreference function, algorithm could used optimize learning bias. meansfirst time possible isolate effect explicit learning biasimplicit learning bias might introduced heuristic search algorithminteraction explicit bias.application OPUSo provide admissible search machine learning alreadyproved productive. Webb (1993) used OPUSo demonstrate heuristic searchfails optimize Laplace accuracy estimate within covering algorithm frequentlyresults inference better classifiers found admissible search optimize preference function. explain result Quinlan Cameron-Jones(1995) developed theory oversearching.research reported herein demonstrated OPUS provide efficient admissible search pure conjunctive classifiers categorical attribute-value data setsUCI repository. would interesting see techniques extendedpowerful machine learning paradigms continuous attribute-value first-order logicdomains.research also demonstrated power pruning. issue givenscant attention context search machine learning. Although presentedcontext admissible search, pruning rules presented equally applicableheuristic search. development pruning rules may prove importantmachine learning tackles ever complex search spaces.OPUS provides efficient admissible search unordered search spaces. creatingmachine learning system necessary consider search (theexplicit learning biases) also search (appropriate search algorithms).assumed previously algorithms must necessarily heuristic techniquesapproximating desired explicit biases. Admissible search decouples two issuesremoving confounding factors may introduced search algorithm.guaranteeing search uncovers defined target, admissible search makes possible462fiAn Efficient Admissible Algorithm Unordered Searchsystematically study explicit learning biases. supporting efficient admissible search,OPUS first time brings machine learning ability clearly explicitlymanipulate precise inductive bias employed complex machine learning task.Acknowledgementsresearch supported Australian Research Council. gratefulRiichiro Mizoguchi pointing potential application OPUS truth maintenance. also grateful Mike Cameron-Jones, Jon Patrick, Ron Rymon, RichardSegal, Jason Wells, Leslie Wells Simon Yip numerous helpful comments previousdrafts paper. especially indebted anonymous reviewers whose insightful,extensive detailed comments greatly improved quality paper.Breast Cancer, Lymphography Primary Tumor data sets providedLjubljana Oncology Institute, Slovenia. Thanks UCI Repository, maintainers,Patrick Murphy David Aha, donors, providing access data sets usedherein.ReferencesBuchanan, B. G., Feigenbaum, E. A., & Lederberg, J. (1971). heuristic programmingstudy theory formation science. IJCAI-71, pp. 4050.Clark, P., & Boswell, R. (1991). Rule induction CN2: recent improvements.Proceedings Fifth European Working Session Learning, pp. 151163.Clark, P., & Niblett, T. (1989). CN2 induction algorithm. Machine Learning, 3,261284.Clearwater, S. H., & Provost, F. J. (1990). RL4: tool knowledge-based induction.Proceedings Second Intl. IEEE Conf. Tools AI, pp. 2430 Los Alamitos, CA.IEEE Computer Society Pres.de Kleer, J. (1986). assumption-based TMS. Artificial Intelligence, 28, 127162.de Kleer, J., Mackworth, A. K., & Reiter, R. (1990). Characterizing diagnoses. Proceedings AAAI-90, pp. 324330 Boston, MA.Hart, P., Nilsson, N., & Raphael, B. (1968). formal basis heuristic determinationminimum cost paths. IEEE Transactions System Sciences Cybernetics,SSC-4 (2), 100107.Hirsh, H. (1994). Generalizing version spaces. Artificial Intelligence, 17, 546.Lawler, E. L., & Wood, D. E. (1966). Branch bound methods: survey. OperationsResearch, 149, 699719.Michalski, R. S. (1984). theory methodology inductive learning. Michalski,R. S., Carbonell, J. G., & Mitchell, T. M. (Eds.), Machine Learning: ArtificialIntelligence Approach, pp. 83129. Springer-Verlag, Berlin.463fiWebbMitchell, T. M. (1977). Version spaces: candidate elimination approach rule learning.Proceedings Fifth International Joint Conference Artificial Intelligence,pp. 305310.Mitchell, T. M. (1980). need biases learning generalizations. Technical reportCBM-TR-117, Rutgers University, Department Computer Science, New Brunswick,NJ.Moret, B. M. E., & Shapiro, H. D. (1985). minimizing set tests. SIAM JournalScientific Statistical Computing, 6 (4), 9831003.Murphy, P., & Aha, D. (1993). UCI repository machine learning databases. [Machinereadable data repository]. University California, Department InformationComputer Science, Irvine, CA.Murphy, P., & Pazzani, M. (1994). Exploring decision forest: empirical investigationOccams Razor decision tree induction. Journal Artificial Intelligence Research,1, 257275.Narendra, P., & Fukunaga, K. (1977). branch bound algorithm feature subsetselection. IEEE Transactions Computers, C-26, 917922.Nilsson, N. J. (1971). Problem-solving Methods Artificial Intelligence. McGraw-Hill, NewYork.Oblow, E. M. (1992). Implementing Valiants learnability theory using random sets. Machine Learning, 8, 4573.Pearl, J. (1984). Heuristics: Intelligent Search Strategies Computer Problem Solving.Addison-Wesley, Reading, Mass.Plotkin, G. D. (1970). note inductive generalisation. Meltzer, B., & Mitchie, D.(Eds.), Machine Intelligence 5, pp. 153163. Edinburgh University Press, Edinburgh.Quinlan, J. R., & Cameron-Jones, R. M. (1995). Oversearching layered searchempirical learning. IJCAI95, pp. 10191024 Montreal. Morgan Kaufmann.Reiter, R. (1987). theory diagnosis first principles. Artificial Intelligence, 32,5795.Rymon, R. (1992). Search systematic set enumeration. Proceedings KR-92, pp.268275 Cambridge, MA.Rymon, R. (1993). SE-tree based characterization induction problem. Proceedings 1993 International Conference Machine Learning San Mateo, Ca.Morgan Kaufmann.Schlimmer, J. C. (1993). Efficiently inducing determinations: complete systematicsearch algorithm uses optimal pruning. Proceedings 1993 InternationalConference Machine Learning, pp. 284290 San Mateo, Ca. Morgan Kaufmann.464fiAn Efficient Admissible Algorithm Unordered SearchSegal, R., & Etzioni, O. (1994). Learning decision lists using homogeneous rules. AAAI94.Smyth, P., & Goodman, R. M. (1992). information theoretic approach rule inductiondatabases. IEEE Transactions Knowledge Data Engineering, 4 (2), 301316.Webb, G. I. (1990). Techniques efficient empirical induction. Barter, C. J., &Brooks, M. J. (Eds.), AI88 Proceedings Third Australian Joint ConferenceArtificial Intelligence, pp. 225239 Adelaide. Springer-Verlag.Webb, G. I. (1993). Systematic search categorical attribute-value data-driven machinelearning. Rowles, C., Liu, H., & Foo, N. (Eds.), AI93 Proceedings SixthAustralian Joint Conference Artificial Intelligence, pp. 342347 Melbourne. WorldScientific.Webb, G. I. (1994a). Generality significant complexity: Toward alternativesOccams Razor. Zhang, C., Debenham, J., & Lukose, D. (Eds.), AI94 Proceedings Seventh Australian Joint Conference Artificial Intelligence, pp. 6067Armidale. World Scientific.Webb, G. I. (1994b). Recent progress learning decision lists prepending inferredrules. SPICIS94: Proceedings Second Singapore International ConferenceIntelligent Systems, pp. B280B285 Singapore.465fiJournal Artificial Intelligence Research 3 (1995) 325-348Submitted 5/95; published 12/95Vision-Based Road Detection Automotive Systems:Real-Time Expectation-Driven ApproachAlberto BroggiSimona BerteDipartimento di Ingegneria dell'InformazioneUniversita di ParmaViale delle ScienzeI-43100 Parma, Italybroggi@ce.unipr.itsimona@ce.unipr.itAbstractmain aim work development vision-based road detection systemfast enough cope dicult real-time constraints imposed moving vehicleapplications. hardware platform, special-purpose massively parallel system,chosen minimize system production operational costs.paper presents novel approach expectation-driven low-level image segmentation, mapped naturally onto mesh-connected massively parallel Simd architectures capable handling hierarchical data structures. input image assumedcontain distorted version given template; multiresolution stretching process usedreshape original template accordance acquired image content, minimizingpotential function. distorted template process output.1. Introductionwork discussed paper forms part Eureka Prometheus activities, aimedimproved road trac safety. Since processing images fundamental importanceautomotive applications, current work aimed developmentembedded low-cost computer vision system. Due special field application,vision system must able process data produce results real-time. thereforenecessary consider data structures, processing techniques, computer architecturescapable reducing response time system whole.system considered currently integrated Mob-Lab land vehicle (Adorni,Broggi, Conte, & D'Andrea, 1995). MOBile LABoratory, result Italian workwithin Prometheus project (see Figure 1.a), comprises camera acquisitiondigitization images, pipelines data on-board massively parallel computerprocessing. illustrated Figure 2, current output configuration comprises setwarnings driver, displayed means set Leds control-panel (shownFigure 1.b). But, due high performance levels achieved, possible replaceoutput device heads-up display showing enhanced features superimposedonto original image.paper presents move toward use top-down control (the following featureextraction mechanism based model-driven approach), instead traditional datadriven approach, generally used data-parallel algorithms.c 1995 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiAlberto Broggi, Simona BerteFigure 1: (a) Mob-Lab land vehicle; (b) control panel used output displayprocessing resultsHeads-upDisplay(a)LED-basedControl Panel(b)Road DetectionSystemCameraInputProcessingOutputFigure 2: Block diagram complete system: (a) planned heads-up display output(b) current Led-based outputStarting experience gained development different approach (Broggi,1995c) based parallel detection image edges pointing Focus Expansion,work presents model-driven low-level processing technique aimed road detectionenhancement road (or lane) image acquired moving vehicle. modelcontains a-priori knowledge feature extracted (road lane) encodedtraditional data structure handled low-level processing: two-dimensional array.case, binary image representing two different regions (road off-road) chosen.Hereinafter image referred Synthetic Image. obvious differentsynthetic images must used according different acquisition conditions (camera position,orientation, optics, etc., fixed) environment (number lanes, one way twoway trac, etc., may change run-time). final system implementation326fiVision-Based Road Detectiona-priori world knowledge enables correct synthetic model selection. example,Figure 3 presents several different synthetic images different conditions.(a)(b)Figure 3: Synthetic images used road models for: (a) different camera positions and/ororientations (b) different number lanes (assuming driving right)following Section presents survey vision-based lane detection systems; Section3 explains choice multiresolution approach; Section 4 presents detailscomplete algorithm; Section 5 discusses performances current implementationPaprica system; Section 6 presents results critical analysis approachleads present development; finally Section 7 presents concluding remarks.2. Comparison Related SystemsMany different vision-based road detection systems developed worldwide,relying various characteristics different road models (two three dimensional),acquisition devices (color monochromatic camera, using mono stereo vision), hardware systems (special- general-purpose, serial parallel), computational techniques(template matching, neural networks, etc.).Scarf system (tested Navlab vehicle Carnegie Mellon University)uses two color cameras color-based image segmentation; different regionsclassified grouped together form larger areas; finally Hough-like transformused vote different binary model candidates. Due extremely high amountdata processed, two incoming color images (480 512) reduced60 64 pixel. Nevertheless, high performance computer architecture, 10 cellWarp (Crisman & Webb, 1991; Hamey, Web, & Wu, 1988; Annaratone, Arnould,T.Gross, H.Kung, & J.Webb, 1987), chosen speed-up processing.system, capable detecting even unstructured roads, reaches processing rate1 Hz (Crisman & Thorpe, 1993, 1991, 1990; Thorpe, 1989). addition heavy3computational load, main problems approach found implicitmodels assumed: road curves sharply changes width, assumed shapemodel becomes invalid detection fails (Kluge & Thorpe, 1990).Vits system (tested Alv vehicle developed Martin Marietta) alsorelies two color cameras. uses combination red blue color bandssegment image, effort reduce artifacts caused shadows. Informationvehicle motion also used aid segmentation process. Tested successfully327fiAlberto Broggi, Simona Bertestraight, single lane roads, runs faster Scarf, sacrificing general capabilityspeed (Turk, Morgenthaler, Gremban, & Marra, 1988).Alvinn (tested Navlab, Cmu) neural network based 30 32 video retinadesigned, like Scarf, detect unstructured roads, roadmodel: learns associations visual patterns steering wheel angles, without considering road location. also implemented Warp system,reaching processing rate 10 Hz (Jochem, Pomerleau, & Thorpe, 1993;Pomerleau, 1993, 1990).different neural approach developed Cmu tested Navlab:256 256 color image segmented 16k processor MasPar MP-2 (MasParComputer Corporation, 1990). trapezoidal road model used, road widthassumed constant throughout sequence: means althoughtrapezoid may skewed left right, top bottom edges maintainconstant length. high performance offered powerful hardware platformlimited low I/O bandwidth; therefore simpler reduced version (processing128 128 images) implemented, working rate 2.5 Hz (Jochem &Baluja, 1993).Due high amount data (2 color images) complex operations involved (segmentation, clustering, Hough transform, etc.) system discussed, even implemented extremely powerful hardware machines, achieve low processing rate. Manydifferent methods considered speed-up processing, including processingmonochromatic images use windowing techniques (Turk et al., 1988) processregions interest, thus implementing Focus Attention mechanism (Wolfe &Cave, 1990; Neumann & Stiehl, 1990).example, VaMoRs (developed Universitat der Bundeswehr, Munchen)monochromatic images processed custom hardware, focusing regionsinterest (Graefe & Kuhnert, 1991). windowing techniques supportedstrong road vehicles models predict features incoming images (Dickmans &Mysliwetz, 1992). case, vehicle driven high speeds (up 100 kph)German autobahns, constant lane width, road specificshapes: straight, constant curvature, clothoidal. use single monochromaticcamera together simple road models allows fast processing basedsimple edge detection; match structured road model used discardanomalous edges. approach disturbed shadow conditions, overallillumination changes, road imperfections found (Kluge & Thorpe, 1990).Lanelok system (developed General Motors) also relies strong road models:estimates location lane boundaries curve fitting method (Kenue &Bajpayee, 1993; Kenue, 1991, 1990), using quadratic equation model. additiondisturbed presence vehicles close road markings, lane detectiongenerally fails shadow conditions. extension correct interpretationshadows therefore introduced (Kenue, 1994); unfortunately techniquerelies fixed brightness thresholds far robust generalapproach.328fiVision-Based Road Detectionmain aim approach discussed paper, hand, buildlow-cost system capable achieving real-time performance detection structured roads (with painted lane markings), robust enough tolerate severe illuminationchanges shadows. Limitation analysis structured environments allowsuse simple road models which, together processing monocular monochromaticimages special-purpose hardware allows achievement low-cost high performances.use high performance general-purpose architecture, 10 cell Warp16k MasPar MP-2 (as case Carnegie Mellon's Navlab), involves high costscompatible widespread large-scale use. reason executionlow-level computations (eciently performed massively parallel systems) usuallyimplemented general purpose processors, case VaMoRs. designimplementation special-purpose application-oriented architectures (like Paprica,Broggi, Conte, Gregoretti, Sansoe, & Reyneri, 1995, 1994), hand, keepproduction costs down, delivering high performance levels. generally,features enable integration architecture generic vehicle are:(a) low production cost,(b) low operational cost,(c) small physical size.2.1 Computing ArchitectureAdditional considerations power consumption show mobile computing movingdirection massively parallel architectures comprising large number relativelyslow-clocked processing elements. power consumption dynamic systemsconsidered proportional CfV 2 , C represents capacitance circuit, fclock frequency, V voltage swing. Power saved three different ways(Forman & Zahorjan, 1994), minimizing C , f , V respectively:using greater level Vlsi integration, thus reducing capacitance C ;trading computer speed (with lower clock frequency f ) lower power consumption(already implemented many portable PCs);reducing supply voltage VDD .Recently, new technological solutions exploited reduce IC supply voltage5 V 3.3 V. Unfortunately, speed penalty pay reduction:Cmos gate (Shoji, 1988), device delay Td (following first order approximation)VDD 2 , shows reduction VDD determines quasiproportional(VDD , VT )linear increment (until device threshold value VT ) circuit delay Td .hand, reduction VDD determines quadratic reduction power consumption.Thus, power saving reasons, desirable operate lowest possible speed, but,order maintain overall system performance, compensation increased delaysrequired.use lower power supply voltage investigated different architectural solutions considered overcome undesired side effects causedreduction VDD (Courtois, 1993; Chandrakasan, Sheng, & Brodersen, 1992).329fiAlberto Broggi, Simona Bertereduction power consumption, maintaining computational power, achievedusing low cost Simd computer architectures, comprising large number extremelysimple relatively slow-clocked processing elements. systems, using slower devicespeeds, provide effective mechanism trading power consumption silicon area,maintaining computational power unchanged. 4 major drawbacks approachare:solution based hardware replication increases silicon area, thussuitable designs extreme area constraints;parallelism must accompanied extra-routing, requiring extra-power; issuemust carefully considered optimized;use parallel computer architectures involves redesigning algorithmsdifferent computational model;since number processing units must high, system size constraintsprocessing elements must extremely simple, performing simple basic operations.paper investigates novel approach real-time road following based uselow-cost massively parallel systems data-parallel algorithms.3. Multiresolution Approachimage encoding model (Synthetic Image) image camera (NaturalImage) cannot directly compared local computations, latter containsmuch detail former. known methods used decreasepresence details, necessary choose one decrease strengthfeature extracted. purpose, low-pass filter, 3 3 neighborhoodbased anisotropic average filter, would reduce presence details, alsosharpness road boundaries, rendering detection dicult. Since roadboundaries exploit long-distance correlation, subsampling naturalsynthetic image would lead comparison less dependent detail content.generally, much easier detect large objects low resolution,main characteristics present, high resolution, detailsspecific represented object make detection dicult. complete recognitiondescription process, hand, take place high resolutions,possible detect even small details preliminary results obtainedcoarse resolution.considerations lead use pyramidal data structure (Rosenfeld, 1984;Ballard & Brown, 1982; Tanimoto & Kilger, 1980), comprising image differentresolutions. Many different architectures developed recently support computational paradigm (Cantoni & Ferretti, 1993; Cantoni, Ferretti, & Savini, 1990; Fountain,1987; Cantoni & Levialdi, 1986): computing architecture contains numberprocessing elements smaller number image pixels external processor virtualization mechanism (Broggi, 1994) used. useful side effect due resolutionreduction decrease number computations performed. Thus, choice330fiOutput imageInput imageSynthetic imageVision-Based Road Detection1256X25611128X128undersampling8256X256888average...132X32832X32128X128888average...undersampling81256X256DBS11oversampling1undersamplingundersampling811181128X12811oversamplingDBS...1DBSFigure 4: Block diagram whole algorithm; step depth every imageshown (in bit/pixel)pyramidal computational paradigm, addition supported theory, offersadvantage terms computational eciency.4. Algorithm Structureshown Figure 4, subsampling natural image filtered. waypossible decrease uence noise redundant details, distortion duealiasing (Pratt, 1978) introduced subsampling process. image partitionednon-overlapping square subsets 2 2 pixels each; filter comprises simple averagepixels values given subset, reduces signal bandwidth. setresulting values forms subsampled image.stretching synthetic image performed iterative algorithm(Driven Binary Stretching, Dbs), much simpler morphological (Haralick, Sternberg,& Zhuang, 1987; Serra, 1982) version \snake" technique (Blake & Yuille, 1993; Cohen & Cohen, 1993; Cohen, 1991; Kass, Witkin, & Terzopolous, 1987). resultoversampled, improved using Dbs algorithm, original resolution reached. boundary stretched template represents final resultprocess.4.1 DBS Filterpurpose Dbs filter, illustrated Figure 5, stretch binary input modelaccordance data encoded grey-tone natural image produce reshapedversion synthetic model output.Usually boundary generic object represented brightness discontinuitiesimage reproducing it, therefore, first version, first step Dbs filtercomprises extremely fast simple gradient-based filter computed 3 3 neighborhood pixel. Then, shown Figure 5, threshold applied gradientimage, order keep significant edges. threshold value fixed,automatic tuning based median filtering currently tested (Folli, 1994).331fiAlberto Broggi, Simona Berteprecisely, two different threshold values computed left right halvesimage, order detect road boundaries even different illuminationconditions.8811gradientDBS8thresholdthresholdvalue1DT811iterative algorithmFigure 5: Block diagram Dbs filterSince 2D mesh-connected massively parallel architecture used, iterative algorithmmust performed order stretch synthetic model toward positions encodedthresholded image. advantage pyramidal approach numberiterations required successful stretching low coarse resolution since imagesize small; again, iterations required high-resolution refinement,due initial coarse low-resolution stretching. border pixel synthetic imageattracted towards position nearest foreground pixel thresholded image,shown Figure 6.ModelsectionThreshold(a)(b)Figure 6: attraction boundary pixels model (in grey) toward thresholded image (the rectangular contour): (a) two-dimensional case; (b) monodimensional sectionpurpose, scalar field V defined E 2. Field V : E 2 ! E , links positionpixel p 2 E 2 scalar value V (p) 2 E , represents potential associatedpixel itself. set values encoded potential image. differenceV (p) , V (q) represents cost moving pixel p toward position q. scalar fielddefined way negative cost corresponds movement toward nearest332fiVision-Based Road Detectionposition foreground pixels ti thresholded image. consequence, iterativeprocess designed explicitly enable pixel movements associated negative cost.Thus, value V (p) depends minimum distance pixel p pixels ti :V (p) = , min(1)d(p; ti) ;: E 2 E 2 ! E represents distance two pixels, measured respectgiven metric. case, due special simplicity implementation, cityblock (Manhattan distance) metric chosen (see Figure 7).4323432123210123212343234Figure 7: City block Manhattan distance central pixelecient method computation potential image using 2D mesh-connectedarchitectures based iterative application morphological dilations (Haralick et al.,1987; Serra, 1982):1. scalar counter initialized 0; parallel architectures cannot runfragment scalar code, counter associated every pixel image, thusconstituting \parallel" counter;2. counter decremented;3. binary input image dilated using 4-connected structuring element N , formedfollowing elements:nN = (0; 1); (0; ,1); (0; 0); (1; 0); (,1; 0) = "! ;(2)4. value counter assigned potential image positionspixel, due previous dilation, changes state background foreground.5. process repeated step 2, output morphological dilationequal input.shows potential image generated application DistanceTransform, DT (Borgefors, 1986) binary thresholded image. Due ecientimplementation-dependent data handling, final version potential image DTobtained adding constant every coecient, work positivevalues: represents maximum value allowed grey-tone images1. Thus newdefinition scalar field V is:V (p) = , min(3)d(p; ti) :1. specific case, since 8-bit images considered, = 255.333fiAlberto Broggi, Simona BerteLinear profileinput image[8 bit/pixel]threshold valueGradient[8 bit/pixel]Threshold[1 bit/pixel]DistanceTransform (DT)[8 bit/pixel]Syntheticinput image[1 bit/pixel]Syntheticoutput image[1 bit-pixel]Figure 8: Example 4 iterations Dbs algorithm (monodimensional case)Furthermore, since `distance' information used pixels belongingborder synthetic image neighbors, iterative process stoppedDT computed pixels, producing noticeable performance improvement.already mentioned, crux algorithm iterative process whose purposemove edge pixels synthetic image directions DT gradientmaximum. Figure 8 shows example monodimensional stretching. shownAppendix A, strength approach lies fact stretching algorithmexpressed simply sequence morphological operations, thereforemapped eciently mesh-connected massively parallel architectures, achieving higherperformance levels approaches (Cohen & Cohen, 1993; Cohen, 1991; Kass et al.,1987).order describe Dbs algorithm, let us introduce definitions using Mathematical Morphology operators (Haralick et al., 1987; Serra, 1982) dilation (),erosion ( ), complement (). two-dimensional binary image representedsubset E 2, whose elements correspond foreground pixels image:n= 2 E 2 = (x; y); x; 2 E ;(4)vector (x; ) represents coordinates generic element s.334fiVision-Based Road Detectionexternal edge defined set elements representing differencedilation 4-connected structuring element N shown expression (2):(5)Be(S ) = (S N ) \ :similar way, set elements representing difference erosionusing structuring element N defined internal edge :Bi(S ) = (S N ) \ :(6)4.1.1 Iterative Rulesset elements B(S ) = (S ) [ Bi (S ) elements insertedremoved set application single iteration Dbs algorithm.precisely, two different rules applied two edges: first, applied externaledge (S ), determines elements included set ; second, appliedinternal edge Bi (S ), determines elements removed set .Rule external edge:{ pixel external edge computes minimum value DTassociated 4-connected neighbors belonging set ;{ pixels, whose associated DT greater value previously computed, inserted set .application rule effect expanding synthetic image towardsforeground pixels ti included synthetic model (see righthand side Figure 6.b).Rule internal edge:{ pixel internal edge computes minimum value DTassociated 4-connected neighbors belonging set ;{ pixels, whose associated DT greater value previously computed, removed set .application rule effect shrinking synthetic image (seeleft hand side Figure 6.b).Note rule 2 inverse rule 1: latter tends stretch foreground ontobackground, former acts opposite way, using complementsynthetic image.4.1.2 Flat HandlingFigure 8 refers monodimensional stretching. Unfortunately, dealing 2D datastructures, DT image present strictly increasing decreasing behavior, evenlocally. Thus, extension previous rules must considered correct at-handling2D space.335fiAlberto Broggi, Simona Berte212345432101221234543210122123454321012101234321000110123432100011012343210001012344321011201234432101120123443210112101234321012310123432101231012343210123101234321012310123432101231012343210123101234321012310123432101231012343210123101234432101210123443210121012344321012210123443210121012344321012101234432101210123443210121012344321012101234432101321234554321232123455432123212345543212a) Input imageb) Stretching without flat-handlingc) Stretching flat-handlingFigure 9: Two-dimensional stretching: different square markings represent different statesinput binary image; dark grey areas represent stretching areaFigure 9.a shows modulus DT coecients (in case = 0), togetherinput binary image (shown grey). output iterative Dbs algorithmpresented Figure 9.b.Since movement generic pixel towards positions holding equal DT coecient expressly disabled, resulting binary image completely follow shapeencoded DT image. minor revision definition rule 1 thus required.Figure 9.c obtained following rule applied external edge.Rule external edge, including handling:{ pixel external edge computes minimum value DTassociated 4-connected neighbors belonging set ;{ pixels, whose associated DT greater value previously computed, pixels belonging thresholded image, whose associated DT equal value previously computed inserted set .specific requirement pixels moving toward region, belongingthresholded image, ensures binary image follow DT chain maxima.requirement, specific case Figure 9, maxima upper-righthand area included resulting binary image.5. Performance Analysis Current ImplementationSince final aim work integrate road detection system mobilevehicle, main requirement achieve real-time performance. choice specialpurpose massively parallel architecture already justified Section 1; moreover,algorithm discussed paper maps naturally onto single-bit mesh-connected Simdmachine, whole computation eciently expressed sequence binarymorphological operators, shown Appendix (which presents morphology-baseddescription whole Dbs algorithm).complete processing, first tested Connection Machine CM-2 (Hillis, 1985),implemented special-purpose massively parallel Simd architecture Paprica.336fiVision-Based Road DetectionPaprica system (PArallel PRocessor Image Checking Analysis), based hierarchical morphology computational model, designed specialized coprocessorattached general purpose host workstation: current implementation, consisting 16 16 square array processing units, connected Sparc-based workstationvia Vme bus, installed Mob-Lab. current hardware board (a single 6U Vmeboard integrating Processor Array, Image Program Memories, framegrabber device direct acquisition images Paprica Image Memory)result full reengineering first Paprica prototype extensivelyanalyzed tested (Gregoretti, Reyneri, Sansoe, Broggi, & Conte, 1993) several years.Paprica architecture developed explicitly meet specific requirements real-time image processing applications (Broggi, 1995c, 1995b; Adorni, Broggi,Conte, & D'Andrea, 1993); specific processor virtualization mechanism utilized Paprica architecture allows handling pyramidal data structures without additionaloverhead equipment.shown Figure 2, output device be:(a) heads-up display road (or lane) boundaries highlighted;(b) set Leds indicating relative position road (or lane) vehicle.Starting 256 256 grey-tone images resolution reduction process,first case (a) initial resolution must recovered order superimpose result ontooriginal image. second case (b), hand, due high quantizationoutput device, processing stopped low resolution (e.g., 64 64),stripe resulting image analyzed drive Leds. Table 1 presentscomputational time required step algorithm (considering 5 DT iterations5 Dbs iterations pyramid level).OperationImage sizeTime [ms]Resolution Reduction2562!322149.7022DT, Dbs & Oversampling32 !6418.55DT, Dbs & Oversampling642!128269.13DT, Dbs & Oversampling1282!2562296.87Total (Led output)2562!322 !642168.25222Total (heads-up display output) 256 !32 !256534.25Table 1: Performance Paprica system; numbers refer 5 iterations DTprocess 5 iterations Dbs filter pyramid level.current Mob-Lab configuration, output device (shown Figure 1.b) consistsset 5 Leds: Table 1 shows 2562 ! 322 ! 642 filtering single frame takes150180 ms (depending number iterations required), allowing acquisitionprocessing 6 frames per second.Moreover, due high correlation two consecutive sequence frames,final stretched template used input model stretched processingfollowing frame. conditions lower number Dbs DT iterations337fiAlberto Broggi, Simona BertebcebcebceFigure 10: detection road markings removal perspective effectthree different conditions: straight road shadows, curved road shadows, junction. (a) input image; (b) reorganized image, obtained non-uniformresampling (a); (c) result line-wise detection black-white-black transitions horizontal direction; (d) reintroduction perspective effect,grey areas represent portion image shown (c); (e) superimposition (d) onto brighter version original image (a).needed complete template reshaping, thus producing noticeable performanceimprovement. reduction time required process single frame also increasescorrelation current following frame sequence, thus allowingreduction computation time2 .Images acquired many different conditions environments usedextensive experimentation, performed first off-line functional simulatorimplemented 8k processor Connection Machine CM-2 (Hillis, 1985) realtime Paprica hardware Mob-Lab. complete system demonstratedfinal Prometheus project meeting Paris, October 1994: Mob-Lab landvehicle driven around two-lane track Mortefontaine, different conditions(straight curved roads, shadows changing illumination conditionsvehicles path).2. processing highly correlated sequences (namely road conditions change slowlyoff-line slow-motion tape playback laboratory) computational time required processingsingle frame reach minimum value 150 ms.338fiVision-Based Road Detectionperformances obtained demonstration allowed main limitationssystem detected enabled critical analysis approach, thus leadingproposals development.6. Critical Analysis Evolutionapproach discussed achieves good performances terms output qualitymodel matches (or suciently similar to) road conditions, namely road markingspainted road surface (on structured roads, see Figures 11.a 12.a) inducingsuciently high luminance gradient. approach successful road laneboundaries extracted input image gradient thresholding operation(see Figures 11.b 12.b). Unfortunately, always possible, exampleroad region patch shadow sunlight, Figure 13.a. case computationDT starting thresholded image (see Figure 13.b) longer significant:different method must devised determination binary image usedinput Distance Transform.bceFigure 11: Lane detection straight road: (a) input image; (b) image obtainedthresholding gradient image; (c) image obtained perspective-basedfilter; (d) stretched template; (e) superimposition edges stretchedtemplate onto original image. case thresholded gradient (b)perspective-based filtered (c) images used input DT.bceFigure 12: Lane detection curved road: also case thresholded gradient(b) perspective-based filtered (c) images used inputDT.recent work (Broggi, 1995a) approach based removal perspectiveeffect presented performances discussed. transform, non-uniform resamplingsimilar happens human visual system (Zavidovique & Fiorini, 1994; Wolfe &339fiAlberto Broggi, Simona BerteCave, 1990), applied input image (Figures 10.a); assuming road, every pixelresampled image (Figures 10.b) represent portion road3. Dueconstant width within overall image, road markings easily enhancedextracted extremely simple morphological filters (Broggi, 1995a) (Figures 10.c).Finally perspective effect reintroduced (Figures 10.d).bceFigure 13: Lane detection straight road shadows: case thresholded gradient (b) cannot used determine DT image due noisecaused shadows. hand, perspective-based processing ablefilter shadows extract road markings: DT factdetermined using image (c) instead (b).bceFigure 14: Lane detection straight road vehicle path:case Dbs algorithm cannot stretch binary model successfully,due presence vehicle occluding road markings. usepair stereo cameras remove problem currently investigated.Due high effectiveness filter, test version system currentlyoperational laboratory, Dbs filter improved replacing gradientthresholding perspective-based filter. extended version Dbs filtershown Figure 15.Since removal (and reintroduction) perspective effect reducedmere image resampling filter based simple morphological operators (Broggi,1995a), implementation Paprica system straightforward. preliminaryresults obtained current test version system encouragingoutput quality (the problems caused shadows resolved) computation3. Note that, due perspective effect, pixels lower part original image (Figures 10.a)represent cm2 road region, central pixels represent tens cm2 . nonuniform resampling original image explicitly designed homogeneous distributioninformation among pixels image.340fiVision-Based Road Detection881extendedDBSpersp. eff.removal18morph.filter1persp. eff.reintrod.1DT811iterative algorithmFigure 15: Diagram extended Dbs filter including perspective-based filteringtime: single frame processed less 100 ms, thus allowing processing10 frames per second. improvement Dbs process means perspectivebased filter, addition allowing correct road (or lane) detection presence shadows,implemented extremely eciently Paprica system, taking advantagespecific hardware extension designed explicitly purpose (non uniform-resampling)(Broggi, 1995a).Figures 11, 12, 13, 14 show results processing different conditions:straight curved road, shadows vehicles path, respectively4 .last case lane cannot detected successfully due presence obstacleuse pair stereo images currently investigated overcomeproblem: removal perspective effect stereo images would leadimage iff road at, namely obstacles found vehicle path.difference two reorganized images (namely obstacle detected) would causealgorithm stop lane detection warn driver.general nature presented approach enables detection sucientlylarge-sized features: example, using different synthetic models possible detectroad lane boundaries, shown Figure 16.7. Conclusionspaper novel approach detection road (or lane) boundaries visionbased systems presented. multiresolution approach, together top-downcontrol, allows achievement remarkable performances terms computation time(when mapped massively parallel architectures) output quality.4. sequences MPEG format (200 1000 frames respectively) available via World WideWeb http://WWW.CE.UniPR.IT/computer vision, showing lane detection particularly challengingconditions. images shown Figures 11, 12, 13, 14, 16 part sequences availablepreviously mentioned WWW page.341fiAlberto Broggi, Simona BertebceFigure 16: (a) input image; (b) synthetic model used lane detection; (c) superimpositionedges stretched model onto original input image; (d) syntheticmodel used road detection; (e) superimposition edged stretchedmodel onto original input image.perspective-based filter introduced improve system performance shadowconditions. However, even perspective-based filter alone able extract roadmarkings high degree confidence, hierarchical application Dbs filter(and extension handling image sequences) basic importance since allowsexploitation temporal correlation successive sequence frames (performingsolution tracking).presence obstacle vehicle path still open problem, currentlyapproached using stereo vision (Broggi, 1995a).algorithm implemented Paprica system, massively parallel lowcost Simd architecture; specific hardware features, Paprica capableprocessing 10 frames per second.Appendix A. Morphological Implementation DBS Filterappendix, rule external edge considered, assuming step niterative process. Recalling Mathematical Morphology notations used identifygrey-tone two-dimensional image, DT image subset E 3:DT = fd 2 E 3 j = (u; v); v = V (u); 8 u 2 E 2g ;(7)u represents position element E 2, v represents value.pixelwise masking operation binary grey-tone image definedfunctionfi : E2 E3 ! E3(8)fi B represents subset B containing elements b = (u; v ) whoseposition vector u 2 E 2 also belongs A:fi B = fx 2 E 3 j x = (u; v) 2 B; u 2 Ag(9)order compute minimum value DT specified neighborhood, let usconsider image Ke(n)Ke(n) = Se(n) fi DT [ Se(n) fi L ;(10)342fiVision-Based Road DetectionSe(n) represents binary image step n, subscript e indicates ruleexternal edge considered, finallyL = fl 2 E 3 j l = (u; ); 8 u 2 E 2g :(11)shown (Haralick et al., 1987), order compute minimum value grey-toneimage Ke(n) 4-connected neighborhood, following grey-scale morphological erosionused:Me(n) = Ke(n) Q ;(12)Q = f(1; 0; 0); (,1; 0; 0); (0; 1; 0); (0; ,1; 0)g ;(13)shown Figure 17.0000zQ = { (1, 0, 0) ; (0, 1, 0) ; (-1, 0, 0) ; (0, -1, 0) }xFigure 17: Structuring element Qorder determine set elements Me(n) value smaller DT ,new function required:: E3 E3 ! E2 :(14)function definedM(A; B) = fx 2 E 2 j V (A; x) < V (B; x)g ;(15)V : E 3 E 2 ! E definedV (A; x) =(9 2 E j (x; a) 2 (A) :,1 otherwise(16)equation (16), (A) represents top (Haralick et al., 1987), defined(A) = ft 2 A; = (u; v) j 6 9 t0 = (x; v0) 2 v0 > vg :(17)set elements included set Se(n+1) given logical intersectionM(Me(n); DT ) set elements belonging external edge Se(n) :Ee(n) = Me(n); DT \ Se(n) :343(18)fiAlberto Broggi, Simona BerteDistanceTransform (DT)[8 bit/pixel]DistanceTransform (DT)[8 bit/pixel]Inputimage[1 bit/pixel]Inputimage[1 bit/pixel]Synthetic imagecomplemented[1 bit/pixel]Maskedimage K[8 bit/pixel]Maskedimage K[8 bit/pixel]DTDTErodedimage[8 bit/pixel]Dilatedimage[8 bit/pixel](M,DT)[1 bit/pixel](M,DT)[1 bit/pixel]External edge[1 bit/pixel]Internal edge[1 bit/pixel]Output image[1 bit/pixel]Output image[1 bit/pixel]Figure 18: Monodimensional stretching case external edge (left) internal edge(right)Thus, final result iteration n givenSe(n+1) = Se(n) [ Ee(n) :(19)Figure 18.a shows execution individual iteration rule 1 monodimensionalimage profile.Following similar steps, possible formalize rule 2. order computemaximum value DT specified neighborhood, let us consider image Ki(n)Ki(n) = Si(n) fi DT ;(20)subscript indicates rule internal edge considered.shown above, order compute maximum value grey-tone image Ki(n)4-connected neighborhood, following morphological dilation used:Mi(n) = Ki(n) Q ;(21)Q shown Figure 17.set elements removed set Si(n+1) given logical intersection M(Mi(n); DT ) set elements belonging internal edge Si(n) :Ei(n) = Mi(n); DT \ Bi Si(n) :(22)344fiVision-Based Road DetectionThus, final result iteration n givenSi(n+1) = Si(n) [ Ei(n) = Si(n) \ Ei(n) :(23)Figure 18b shows execution individual iteration rule 2 monodimensionalprofile image.Acknowledgementswork partially supported Italian Cnr within framework EurekaPrometheus Project { Progetto Finalizzato Trasporti contracts n. 93.01813.PF7494.01371.PF74.authors indebted Gianni Conte valuable constructive discussionscontinuous support throughout project.ReferencesAdorni, G., Broggi, A., Conte, G., & D'Andrea, V. (1993). self-tuning system realtime Optical Flow detection. Proceedings IEEE System, Man, CyberneticsConf, Vol. 3, pp. 7{12.Adorni, G., Broggi, A., Conte, G., & D'Andrea, V. (1995). Real-Time Image ProcessingAutomotive Applications. Laplante, P. A., & Stoyenko, A. D. (Eds.), Real-Time Image Processing: Theory, Techniques Applications. IEEE SPIE Press. press.Annaratone, M., Arnould, E., T.Gross, H.Kung, & J.Webb (1987). Warp Computer: Architecture, Implementation Performance. IEEE Trans Computers,C-36 (12), 1523{1538.Ballard, D. H., & Brown, C. M. (1982). Computer Vision. Prentice Hall.Blake, A., & Yuille, A. (1993). Active Vision. MIT Press.Borgefors, G. (1986). Distance Transformations Digital Images. Computer Vision,Graphics Image Processing, Vol. 34, pp. 344{371.Broggi, A. (1994). Performance Optimization Low-Cost Cellular Array Processors.Proceedings IEEE Intl Conf Massively Parallel Computing Systems, pp. 334{338.Broggi, A. (1995a). Massively Parallel Approach Real-Time Vision-Based Road Markings Detection. Masaky, I. (Ed.), Proceedings IEEE Intelligent Vehicles'95, pp.84{89.Broggi, A. (1995b). Novel Approach Lossy Real-Time Image Compression: HierarchicalData Reorganization Low-Cost Massively Parallel System. Real-Time ImagingJournal, 1 (2).Broggi, A. (1995c). Parallel Local Feature Extraction: Real-Time Approach RoadBoundary Detection. IEEE Trans Image Processing, 4 (2), 217{223.Broggi, A., Conte, G., Gregoretti, F., Sansoe, C., & Reyneri, L. M. (1995). EvolutionPAPRICA System. Integrated Computer-Aided Engineering Journal - SpecialIssue Massively Parallel Computing. press.345fiAlberto Broggi, Simona BerteBroggi, A., Conte, G., Gregoretti, F., Sansoe, C., & Reyneri, L. M. (1994). PAPRICAMassively Parallel Processor. Proceedings IEEE Intl Conf Massively ParallelComputing Systems, pp. 16{30.Cantoni, V., & Ferretti, M. (1993). Pyramidal Architectures Computer Vision. PlenumPress, London.Cantoni, V., Ferretti, M., & Savini, M. (1990). Compact Pyramidal Architectures. Tou,J., & Balchen, J. (Eds.), Highly Redundant Sensing Robotic Systems, Vol. 58, pp.157{174. NATO ASI Series F.Cantoni, V., & Levialdi, S. (1986). Pyramidal Systems Computer Vision. SpringerVerlag, Berlin.Chandrakasan, A., Sheng, S., & Brodersen, R. (1992). Low-Power CMOS Digital Design.IEEE Journal Solid-State Circuits, 27 (4), 473{484.Cohen, L. D. (1991). Note Active Contour Models Balloons. CGVIP: Image Understanding, 53 (2), 211{218.Cohen, L. D., & Cohen, I. (1993). Finite-Element Methods Active Contour ModelsBalloons 2-D 3-D Images. IEEE Trans PAMI, 15 (11), 1131{1147.Courtois, B. (1993). CAD Testing ICs systems: going?. Tech.rep., TIMA & CMP.Crisman, J., & Thorpe, C. (1990). Color Vision Road Following. Thorpe, C. E. (Ed.),Vision Navigation. Carnegie Mellon Navlab, pp. 9{24. Kluwer AcademicPublishers.Crisman, J., & Thorpe, C. (1991). UNSCARF, Color Vision System DetectionUnstructured Roads. Proceedings IEEE Intl Conf Robotics Automation,pp. 2496{2501.Crisman, J., & Thorpe, C. (1993). SCARF: Color Vision System Tracks RoadsIntersections. IEEE Trans Robotics Automation, 9 (1), 49{58.Crisman, J. D., & Webb, J. A. (1991). Warp Machine Navlab. IEEE TransPAMI, 13 (5), 451{465.Dickmans, E. D., & Mysliwetz, B. D. (1992). Recursive 3-D Road Relative Ego-StateRecognition. IEEE Trans PAMI, 14, 199{213.Folli, A. (1994). Elaborazione parallela di immagini per applicazioni tempo reale suautoveicolo. Master's thesis, Universita degli Studi di Parma, Facolta di Ingegneria.Forman, G. H., & Zahorjan, J. (1994). Challenge Mobile Computing. Computer,27 (4), 38{47.Fountain, T. (1987). Processor Arrays: Architectures applications. Academic-Press,London.Graefe, V., & Kuhnert, K.-D. (1991). Vision-based Autonomous Road Vehicles. Masaki,I. (Ed.), Vision-based Vehicle Guidance, pp. 1{29. Springer Verlag.Gregoretti, F., Reyneri, L. M., Sansoe, C., Broggi, A., & Conte, G. (1993). PAPRICASIMD array: critical reviews perspectives. Dadda, L., & Wah, B. (Eds.),Proceedings ASAP'93 - IEEE Intl Conf Application Specific Array Processors, pp.309{320 Venezia, Italy.346fiVision-Based Road DetectionHamey, L. G. C., Web, J. A., & Wu, I. (1988). Low-level vision Warp ApplyProgramming Model. Kowalik, J. S. (Ed.), Parallel Computations ComputersArtificial Intelligence, pp. 185{200. Kluwer Academic Publishers.Haralick, R. M., Sternberg, S. R., & Zhuang, X. (1987). Image Analysis Using MathematicalMorphology. IEEE Trans PAMI, 9 (4), 532{550.Hillis, W. D. (1985). Connection Machine. MIT Press, Cambridge, Ma.Jochem, T. M., & Baluja, S. (1993). Massively Parallel Road Follower. Bayoumi,M. A., Davis, L. S., & Valavanis, K. P. (Eds.), Proceedings Computer ArchitecturesMachine Perception '93, pp. 2{12.Jochem, T. M., Pomerleau, D. A., & Thorpe, C. E. (1993). MANIAC: Next Generation Neurally Based Autonomous Road Follower. Proceedings Intl ConfIntelligent Autonomous Systems: IAS -3 Pittsburgh, Pennsylvania, USA.Kass, M., Witkin, A., & Terzopolous, D. (1987). Snakes: Active Contour Models. IntlJournal Computer Vision, 1, 321{331.Kenue, S. K. (1990). LANELOK: detection lane boundaries vehicle tracking usingimage-processing techniques. Proceedings SPIE - Mobile Robots IV, Vol. 1195,pp. 221{233.Kenue, S. K. (1991). LANELOK: Algorithm Extending Lane Sensing OperatingRange 100 Feet. Proceedings SPIE - Mobile Robots V, Vol. 1388, pp. 222{233.Kenue, S. K. (1994). Correction Shadow Artifacts Vision-based Vehicle Guidance.Proceedings SPIE - Mobile Robots VIII, Vol. 2058, pp. 12{26.Kenue, S. K., & Bajpayee, S. (1993). LANELOK: Robust Line Curvature FittingLane Boundaries. Proceedings SPIE - Mobile Robots VII, Vol. 1831, pp. 491{503.Kluge, K., & Thorpe, C. E. (1990). Explicit Models Robot Road Following. Thorpe,C. E. (Ed.), Vision Navigation. Carnegie Mellon Navlab, pp. 25{38. KluwerAcademic Publishers.Kluge, K. (1994). Extracting Road Curvature Orientation Image Edge Pointswithout Perceptual Grouping Features. Proceedings IEEE Intelligent Vehicles'94.MasPar Computer Corporation, Sunnyvale, California (1990). MP-1 Family Data-ParallelComputers.Neumann, H., & Stiehl, H. (1990). Toward computational architecture monocularpreattentive segmentation. G.Hartmann, R., & G.Hauske (Eds.), Parallel Processing Neural Systems Computers. Elsevier (North Holland).Newman, W. M., & Sproull, R. F. (1981). Principles Interactive Computer Graphics.McGraw-Hill, Tokyo.Pomerleau, D. A. (1990). Neural Network Based Autonomous Navigation. Thorpe,C. E. (Ed.), Vision Navigation. Carnegie Mellon Navlab, pp. 83{93. KluwerAcademic Publishers.Pomerleau, D. A. (1993). Neural Network Perception Mobile Robot Guidance. KluwerAcademic Publishers, Boston.Pratt, W. K. (1978). Digital Image Processing. John Wiley & Sons.347fiAlberto Broggi, Simona BerteRosenfeld, A. (1984). Multiresolution Image Processing Analysis. Springer Verlag,Berlin.Serra, J. (1982). Image Analysis Mathematical Morphology. Academic Press, London.Shoji, M. (1988). CMOS Digital Circuit Technology. Prentice Hall.Tanimoto, S. L., & Kilger, K. (1980). Structured Computer Vision: Machine Perceptiontrough Hierarchical Compuation Structures. Academic Press, NY.Thorpe, C. (1989). Outdoor Visual Navigation Autonomous Robots. Kanada, T.,Groen, F. C. A., & Hertzberger, L. O. (Eds.), Intelligent Autonomous Systems, Vol. 2,pp. 530{544.Tsai, R. (1986). Ecient Accurate Camera Calibration Technique 3D MachineVision. Proceedings IEEE Intl Conf Computer Vision Pattern Recognition,pp. 364{374.Turk, M. A., Morgenthaler, D. G., Gremban, K. D., & Marra, M. (1988). VITS - VisionSystem Autonomous Land Vehicle Navigation. IEEE Trans PAMI, 10 (3).Wolfe, J. M., & Cave, K. R. (1990). Deploying visual attention: guided model. AIeye, pp. 79{103. A.Blake T.Troscianko.Zavidovique, B., & Fiorini, P. (1994). Control View Vision Architectures. Cantoni,V. (Ed.), Human Machine Vision: Analogies Divergencies, pp. 13{56. PlenumPress.348fiJournal Artificial Intelligence Research 3 (1995) 223-248Submitted 6/94; published 10/95Improving Connectionist Energy MinimizationGadi Pinkaspinkas@cs.wustl.eduRina Dechterdechter@ics.uci.eduCenter Optimization Semantic Control, Washington UniversityAMDOCS Inc, 1611 Des Peres Rd., St Louis, MO 63131 USADepartment Information Computer ScienceUniversity California, Irvine, CA 92717, USAAbstractSymmetric networks designed energy minimization Boltzman machinesHopfield nets frequently investigated use optimization, constraint satisfactionapproximation NP-hard problems. Nevertheless, finding global solution (i.e.,global minimum energy function) guaranteed even local solution maytake exponential number steps. propose improvement standard localactivation function used networks. improved algorithm guaranteesglobal minimum found linear time tree-like subnetworks. algorithm, calledactivate, uniform assume network tree-like. identifytree-like subnetworks even cyclic topologies (arbitrary networks) avoid local minimaalong trees. acyclic networks, algorithm guaranteed convergeglobal minimum initial state system (self-stabilization) remains correctvarious types schedulers. negative side, show presencecycles, uniform algorithm exists guarantees optimality even sequentialasynchronous scheduler. asynchronous scheduler activate one unit timesynchronous scheduler activate number units single time step.addition, uniform algorithm exists optimize even acyclic networks schedulersynchronous. Finally, show algorithm improved using cycle-cutsetscheme. general algorithm, called activate-with-cutset improves activateperformance guarantees related size network's cycle-cutset.1. IntroductionSymmetric networks Hopfield networks, Boltzmann machines, mean-field Harmony networks frequently investigated use optimization, constraint satisfactionapproximation NP-hard problems (Hopfield, 1982, 1984; Hinton & Sejnowski, 1986;Peterson & Hartman, 1989; Smolensky, 1986; Brandt, Wang, Laub, & Mitra, 1988).models characterized symmetric matrix weights quadratic energy function minimized. Usually, unit computes gradient energyfunction updates activation value free energy decreases gradually.Convergence local minimum guaranteed although worst case exponentialnumber units (Kasif, Banerjee, Delcher, & Sullivan, 1989; Papadimitriou, Shaffer,& Yannakakis, 1990).many cases problem hand formulated minimization problembest solutions (sometimes solutions) global minima (Hopfield & Tank, 1985;Ballard, Gardner, & Srinivas, 1986; Pinkas, 1991). desired algorithm therefore onec 1995 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiPinkas Dechtermanages reduce impact shallow local minima, thus improving chancesfinding global minimum. models Boltzmann machines Harmonynets use simulated annealing escape local minima. models asymptoticallyconverge global minimum, meaning annealing schedule slow enough,global minimum found. Nevertheless, schedule hard find therefore,practice, networks guaranteed find global minimum even exponentialtime.paper look topology symmetric neural networks. presentalgorithm finds global minimum acyclic networks otherwise optimizes treelike subnetworks linear time. extend general topologies dividingnetwork fictitious tree-like subnetworks using cycle-cutset scheme.algorithm based method nonserial dynamic programming methods(Bertele & Brioschi, 1972), also used constraint optimization (Dechter,Dechter, & Pearl, 1990). task divided precompilationtree structure via tree-clustering algorithm run-time optimization tree.adaptation connectionist style; i.e., algorithm stated simple,uniform activation function (Rumelhart, Hinton, & McClelland, 1986; Feldman & Ballard,1982) executed parallel architectures using synchronous asynchronousscheduling policies. assume desired topology (acyclic) performs worsestandard local algorithms topologies. fact, may integrated manystandard algorithms way new algorithm out-performs standardalgorithms avoiding certain class local minima (along tree-like subnetworks).algorithm also applicable emerging class greedy algorithms called localrepair algorithms. local repair techniques, problem hand usually formulatedminimization function measures distance current state goalstate (the solution). algorithm picks setting variables repeatedlychanges variables cause maximal decrease distance function.example, commonly used distance function constraint satisfaction problemsnumber violated constraints. local repair algorithm may viewed energyminimization network distance function plays role energy. Local repairalgorithms sequential though, use greedy scheduling policy; next nodeactivated one leading largest change distance (i.e., energy). Recently,local repair algorithms successfully used various large-scale hard problems3-SAT, n-queen, scheduling constraint satisfaction (Minton, Johnson, & Phillips,1990; Selman, Levesque, & Mitchell, 1992). Since local repair algorithms may viewedsequential variations energy minimization paradigm, reasonable assumeimprovements energy minimization also applicable local-repair algorithms.negative side, show presence cycles, uniform algorithmexists guarantees optimality even sequential asynchronous scheduler.asynchronous scheduler activate one unit time synchronous scheduleractivate number units single time step. addition, uniform algorithmexists optimize even acyclic networks scheduler synchronous. negativeresults involve conditions parallel model execution therefore applicableparallel versions local repair.224fiImproving Connectionist Energy Minimizationpaper organized follows: Section 2 discusses connectionist energy minimization.Section 3 presents new algorithm activate gives example out-performsstandard local algorithms. Section 4 discusses negative results, convergence various schedulers self-stabilization. Section 5 extends approach general topologiesalgorithm activate-with-cutset suggests future research. Section 6 summarizesdiscusses applications.2. Connectionist Energy MinimizationGiven quadratic energy function form:nnXXE (X1; :::; Xn) = , wi;j Xi Xj , +i Xi:i<jvariables Xi may value zero one called activation value,task find zero/one assignment variables X1; :::Xn minimizesenergy function. avoid confusion signs, consider equivalent problemmaximizing goodness function:XXG(X1; :::; Xn) = ,E (X1; :::; Xn) = wi;j XiXj + Xi(1)i<jconnectionist approaches, look network generated assigning node(i) every variable (Xi) function, creating weighted arc (with weight wi;j )node node j , every term wi;j Xi Xj . Similarly, bias given unit i,term Xi function. example, Figure 1 shows network correspondsgoodness function E (X1; :::; X5) = 3X2X3 , X1 X3 +2X3X4 , 2X4X5 , 3X3 , X2 +2X1.nodes assigned processing unit network collectively searchesassignment maximizes goodness. algorithm repeatedly executedunit/node called activation function. algorithm uniform executedunits.42-3-2351-1-13221Figure 1: example networkgive examples two popular activation functions connectionistenergy minimization: discrete Hopfield network (Hopfield, 1982) Boltzmann225fiPinkas Dechtermachine (Hinton & Sejnowski, 1986). discrete Hopfield model, unit computesactivation value using formula:(P w X ,1j i;j jXi = 0 otherwiseBoltzmann machines determination activation value stochasticprobability set activation value unit one is:PP (Xi = 1) = 1=(1 + e,( w X + )=T );ji;jjannealing temperature. approaches may integratedtopology-based algorithm; i.e., nodes cannot identified parts tree-like topology use one standard local algorithms.3. Algorithmassume model communication neighboring nodes shared memory,multi-reader, single-writer model. also assume (for now) scheduling donecentral scheduler (asynchronous) execution fair. shared memory, multireader, single-writer unit shared register called activation register. unitmay read content registers neighbors write own. Centralscheduler means units activated one time arbitrary order.1execution said fair every unit activated infinitely often. require selfstabilization initially. Namely, algorithms may initialization step relyinitial values. Later relax assumptions examine conditionsalgorithm also self-stabilized.algorithm identifies parts network cycles (tree-like subnetworks),optimizes free energy subnetworks. tree identified, optimizedusing dynamic programming method propagates values leaves rootback.Let us assume first network acyclic; network may directedrooted tree. algorithm based observation given activation value (0/1)node tree, optimal assignments adjacent nodes independentother. particular, optimal assignment node's descendants independentassignments ancestors. Therefore, node tree may compute twovalues: G1i maximal goodness contribution subtree rooted i, includingconnection i's parent whose activation one. Similarly, G0i maximal goodnesssubtree, including connection i's parent whose activation value zero.acyclicity property allow us compute node's G1i G0i simple functionchildren's values, implemented propagation algorithm initiated leaves.Knowing activation value parent values G0j ; G1j children,node compute maximal goodness subtree. information reaches1. Standard algorithms need assume condition order guarantee convergence localminimum (Hopfield, 1982). condition relaxed restricting adjacent nodesactivated time (mutual exclusion).226fiImproving Connectionist Energy Minimizationroot, assign value (0/1) maximizes goodness whole network.assignment information propagates toward leaves. Knowing activation valueparent, node compute preferred activation value itself. termination (atstable state), tree optimized. algorithm 3 basic steps:1.Directing tree: knowledge propagated leaves toward centerlinear number steps, every unit tree knows parent children.2. Propagation goodness values: values (G1i G0i ), propagatedleaves root. termination, every node knows maximal goodnesssubtree appropriate activation value assign given parent.particular, root decide activation value maximizewhole tree.3. Propagation activation values: starting root, node turn determines activation value. O(depth tree) steps, units stablestate globally maximizes goodness.unit's activation register consists following fields: Xi: activation value;0Gi G1i : maximal goodness values; (Pi1 ; ::; Pij ): bit j neighborsindicates i's parent.3.1 Directing treegoal algorithm inform every node role network childparent relationships. Nodes single neighbor identify leaves firstidentify neighbor parent (point it). node identifies rootneighbors point toward it. node's neighbors one point toward it, nodeselects one parent. Finally, node least two neighbors pointingtoward it, identifies outside tree.problem directing tree related problem selecting leaderdistributed network, selecting center tree (Korach, Rotem, & Santoro, 1984).problem differs (from general leader selection problems) network tree.addition, require algorithms self-stabilized. related self-stabilizing algorithmappeared earlier (Collin, Dechter, & Katz, 1991). algorithm based finding centertree root node therefore creates balanced trees. advantagealgorithm presented space ecient requiring O(logd) space,maximum number neighbors node has. contrast, algorithm Collinet al. requires O(logn), n network size.algorithm present, unit uses one bit per neighbor keep pointinginformation: Pij = 1 indicates node sees j th neighbor parent. lookingPji , node knows whether j pointing it.Identifying tree-like subnetworks general network may done algorithmFigure 2.Figure 3a, see acyclic network tree directing phase. numbersedges represent values Pij bits. Figure 3b, tree-like subnetwork227fiPinkas DechterTree Directing (for unit i):1. Initialization: first time, neighbors j : Pij = 0; /* Start clearpointers (step needed acyclic nets almost uniform versions)2. single neighbor (j ) Pji = 0, Pij = 1; /* leaf selectsneighbor parent neighbor doesn't point */3. else, one one neighbor (k) point (Pki = 0),Pik = 1, rest neighbors: Pij = 0. /* k parent */4. else, neighbors j : Pij = 0. /* Node either root outside tree */Figure 2: Tree directing algorithmidentified inside cyclic network. Note node 5 root since neighborspointing toward it.7070005 1560561 4403011041303011112214035 001122(a)(b)Figure 3: Directing tree: a) tree b) cyclic network tree-like subnetwork.3.2 Propagation goodness valuesphase every node computes goodness values G1i G0i , propagatingtwo values leaves root (see Figure 4).Given node Xi , parent Xk children, children(i) tree, shown,based energy function (1), goodness values obey following recurrence:XGXi = maxX 2f0;1gfGXj + wi;k Xi Xk + Xi gkj 2children(i)Consequently nonleaf node computes goodness values using goodness valueschildrenfollows: Xk = 0, must decide Psetting Xi = 0, obtainingP0goodness j Gj , setting Xi = 1, obtaining goodness j G1j + . yields:XXG0i = maxfG0j ;G1j + gj 2children(i)228j 2children(i)fiImproving Connectionist Energy MinimizationG0 = 24G1 = 34X4 = 0430G =231G =23131320G =1511G 21 = 2X3 = 052G0 = 00422G1 = 2351G =05X5 = 121G1 = 121X2 = 0X1 = 1(b)(a)Figure 4: a) Propagating goodness values. b) Propagating activation values.Similarly, Xk = 1, choice Xi = 0 Xi = 1, yields:XXG1i = maxfG0j ;G1j + wi;k + gj 2children(i)j 2children(i)initial goodness values leaf nodes obtained (no children).Thus, G0i = maxf0; ig, G1i = maxf0; wik + g.example, unit 3 Figure 4 zero maximal goodness contributednode 1 G01 = maxX1 2f0;1gf2X1g = 2 obtained X1 = 1. Unit 2 (whenX3 = 0) contributes G02 = maxX2 2f0;1gf,X2 g = 0 obtained X2 = 0, G12 =maxX2 2f0;1gf3X2 , X2g = 2 obtained X2 =P1. nonleaf nodes, X4 = 0,X3 = 0, goodnessPcontribution k G0k = 2 + 0 = 2, X3 = 1,contribution ,3 + k G1k = ,3 + 1 + 2 = 0. maximal contribution G03 = 2achieved X3 = 0.Goodness values may computed every node children's goodnessvalues ready; however, self-stabilization (to discussed later) simplicity,nodes may compute goodness values repeatedly without synchronizationchildren.3.3 Propagation activation valuesnode assigned activation value, children activatemaximize goodness subtrees control. value chosen node,children evaluate activation values, process continues wholetree assigned.two kinds nodes may start process: root chooseactivation value optimize entire tree, non-tree node uses standardactivation function.Proot Xi identified,Pif maximal goodness j G0j , chooses value\0." maximal goodness j G1j + , chooses \1." summary, root choosesvalue according to:(P G1 + P G01j jj jXi = 0 otherwise229fiPinkas DechterFigure 4 example, G15 + G13 + 0 = 2 < G05 + G03 = 3 therefore X4 = 0. Pinternal node whose parent k chooses activationvalue maximizes Pj Gxj +Pwi;k XiXk + Xi. choice therefore, j G0j (when Xi = 0) j G1j +wi;k Xk + (when Xi = 1), yielding:(P G1 + w X + P G0i;k kj jj jXi = 10 ifotherwisespecial case, leaf chooses Xi = 1 wi;k Xk ,i , exactly discreteHopfield activation function node single neighbor. example, Figure 4,X5 = 1 since w4;5X4 = 0 > ,5 = ,1, X3 = 0 since G11 + G12 +2X4 + 3 = 1+2+0 , 3 =0 < G02 + G01 = 2. Figure 4b shows activation values obtained propagatingroot leaves.3.4 complete activation functionInterleaving three algorithms described earlier achieves goal identifying tree-likesubnetworks maximizes goodness. subsection present completealgorithm, combining three phases simplifying computation. algorithmintegrated discrete Hopfield activation function demonstrating similarformulas are.steps algorithm interleaved freely; i.e., scheduler might executestep nodes steps given node (or combinations). stepscomputed repeatedly synchronization node's neighbors.2 Algorithmactivate executed unit (when j denotes non-parent neighbor k denotesparent i) given Figure 5. Algorithm activate improves arbitrary local searchconnectionist algorithm following sense:3.1 a1 local minimum generated \activate" a2 local minimumgenerated local-search method (e.g., Hopfield), a1 a2 activationvalues non-tree nodes, G(a1) G(a2).TheoremProof: Follows immediately fact activate generates global minimumtree-subnetworks. 2Additional properties algorithm discussed Section 4.3.5 exampleexample illustrated Figure 6 demonstrates case local minimumstandard algorithms avoided. Standard algorithms may enter local minimumstay stable state clearly wrong.example variation Harmony network example (Smolensky, 1986) (page259), (McClelland, Rumelhart, & Hinton, 1986) (page 22). task networkidentify words low-level line segments. Certain patterns line segments excite2. see later, amount parallelism limited somewhat, time timetwo neighboring nodes execute tree-directing step time.230fiImproving Connectionist Energy MinimizationAlgorithm activate: Optimizing Tree-like Subnetworks (unit i):1. Initialization: first time, (8j ) Pij = 0; /*Clear pointers (cyclic nets)*/2. Tree directing: exists single neighbor k, Pki = 0,Pik = 1 neighbors j , Pij = 0;else, neighbors Pij = 0;3. Computing Pgoodness values: P0Gi = maxf j2neighbors(i) G0j Pji ; j 2neighbors(i) G1j Pji + g;G1i = maxfPj2neighbors(i) G0j Pji ; Pj 2neighbors(i)(G1j Pji + wi;j Pij ) + g;4. Assigning activation values:least( two neighborspointing i, /*Not tree: use Hopfield*/P w Xarenot1,j i;j jXi = 0 otherwiseelse, /*root leaves) */( Node inPa tree1 (including0)P + wi;j Xj P j ) ,i1((G,Gj jj jXi = 0 otherwiseFigure 5: Algorithm activate unitunits represent characters, certain patterns characters excite units representwords. line strokes used draw characters input units: L1,..., L5.units \N," \S," \A" \T" represent characters. units \able," \nose," \time"\cart" represent words, Hn, Hs, Ha, Ht, H1,... H4 hidden units requiredHarmony model. example, given line segments character S, unit L4 activated(input), causes units Hs \S" activated. Since \NOSE" wordcontains character \S," H2 unit \nose" also activatedword \NOSE" identified.network feedback cycles (symmetric weights) ambiguity among characters line-segments may resolved result identifying word. example, assumeline segments required recognize word \NOSE" appear, character\N" input blurred therefore setting unit L2 ambiguous. Givenrest line segments (e.g., character \S"), network identifies word\NOSE" activates units \nose" H2. cause unit \N" linesegments activated. Thus, ambiguity L2 resolved.network designed global minimum L2, Hn, \N," H2 \nose"activated. However, standard connectionist algorithms may fall local minimumunits zero, generating goodness 5 , 4 = 1. correct setting (globalminimum) found tree-optimization algorithm (with goodness: 3-1+3-1+3-1+5-14+3-1+5=13). thick arcs upper network Figure 6 mark arcs tree-likesubnetwork. tree-like subnetwork drawn pointers weights lowerpart figure. Node \S" part tree activation value set one231fiPinkas DechterHnHsHaHtH1NL1L2L4L3LinesegmentsableCharacters4Hn1H23H3H4L513H2HsnosetimeWordscartcyclic subnetwork3511L2N11noseFigure 6: Harmony network recognizing words: local minima along subtreesavoided.line-segments \S" activated. \S" set, units along treeoptimized (by setting one) local minimum avoided.4. Feasibility, Convergence, Self-Stabilizationfar shown enhance performance connectionist energy minimizationnetworks without losing much simplicity standard approaches. simplealgorithm presented limited three ways, however. First, assumes unrealisticallycentral scheduler used; i.e., scheduler activates units oneasynchronously. results obtained steps algorithm executesone atomic operation neighbors mutually excluded. would like networkwork correctly distributed (synchronous) scheduler, subset unitsmay activated execution time synchronously. Second, algorithmguarantees convergence global optima tree-like subnetworks. would likefind algorithm converges correct solutions even cycles introduced. Finally,would like algorithm self-stabilizing. converge legal, stable stategiven enough time, even noisy uctuations cause units execute arbitraryprogram states registers arbitrary content. Formally, algorithm selfstabilizing fair execution, starting input configuration programstate (of units), system reaches valid stable configuration.section, illustrate two negative results regarding first two problems; i.e.,feasible build uniform algorithms trees distributed scheduler,algorithm feasible cyclic networks even central scheduler.232fiImproving Connectionist Energy Minimizationshow weaken conditions convergence guaranteed (for tree-likesubnetworks) realistic environments self-stabilization obtained.scheduler generate specific schedule consistent definition. Thus,central scheduler viewed specific case distributed scheduler. sayproblem impossible scheduler every possible algorithm existsfair execution generated scheduler find solution problem.Since specific schedules generated central scheduler also generateddistributed scheduler, impossible central scheduler also impossibledistributed scheduler.4.1 Negative results uniform algorithmsFollowing Dijkstra (1974), negative results presented regarding feasibility distributed constraint satisfaction (Collin et al., 1991). Since constraint satisfaction problemsformulated energy minimization problems, feasibility results apply alsocomputing global minimum energy functions. completeness adaptresults connectionist computation energy minimization.Theorem 4.1 deterministic3 uniform algorithm exists guarantees global minimum distributed scheduler, even simple chain-like trees, assumingalgorithm needs insensitive initial conditions.Proof (By counter example): Consider network Figure 7. two global minimapossible : (11:::1101:::1) (11:::1011:::1) (when four centered digits assignedunits, , 1; i; + 1; + 2). network initialized unitsregister values, units start program state, exists fairexecution distributed scheduler every step units activated.units left center (1; 2; 3; :::i) \see" input units right center(2i; 2i , 1; 2i , 2; :::; + 1) respectively. uniformity determinism,units pair (i; + 1); (i , 1; + 2); :::; (1; 2i) must transfer programstate produce output activation register. Thus, every stepexecution, units + 1 always activation value globalminimum (where two units different values) never obtained. 2negative result discourage us practice since relies obscureinfinite sequence executions unlikely occur random scheduler. Despitenegative result, one show algorithm activate optimize energy treelike subnetworks distributed scheduler least one following cases holds(see next section details):1. step 2 algorithm activate Section 3.4 atomic; i.e., neighbor mayexecute step 2 time.2. every node every neighbor j , node executed without j infinitely often(fair exclusion);3. one node unique acts root, is, execute step 2 (an almostuniform algorithm);3. proof theorem assumes determinism apply stochastic activation functions.233fiPinkas Dechter111111211i111511i+11i+212iGlobal Minima: 11...1101...111...1011...1Figure 7: uniform algorithm exists optimize chains distributed schedulers.4. network cyclic (one node acting root).4Another negative result similar (Collin et al., 1991) given following theorem.Theorem 4.2 network cyclic, deterministic uniform algorithm exists guarantees global minimum, even central scheduler, assuming algorithm needsinsensitive initial conditions.Proof (by counter example): may proved even cyclic networks simple rings.Figure 8 see ring-like network whose global minima (010101) (101010).Consider fair execution central scheduler activates units 1,4,2,5,3,6order repeats order indefinitely. Starting program stateinputs, two units every pair (1,4), (2,5), (3,6) \see" input, thereforeoutput transfer program state. result, units neveroutput different values global minimum obtained. 2Note tree-like subnetwork cyclic network optimized evendistributed scheduler (since nodes part cycle identified rootsalgorithm acts almost uniform algorithm).4.2 Convergence self-stabilizationprevious subsection proved pure distributed schedulerhope uniform network algorithm. addition, easily show algorithmself-stabilizing cycles introduced. example, consider configurationpointers ring Figure 9. stable state although clearly validtree.5subsection weaken requirements allowing algorithm converge correct solutions self-stabilizing realistically weaker distributed schedulers.use notion pure distributed scheduler; instead, ask distributedscheduler fair exclusion property.4. Global solutions guaranteed found tree-like subnetworks optimized.5. configuration never occur units start starting point; i.e., clearing bits P .may happen due noise hardware uctuations.234fiImproving Connectionist Energy Minimization114353133163Global Minima: 01010110101032131Schedule: 1, 4, 2, 5, 3, 6, 1, 4, 2, 5,......1Figure 8: uniform algorithm exists guarantees optimize rings even centralscheduler.1710601 05Figure 9: uniform algorithm self-stabilizing cyclic networks.Definition 4.1 scheduler fair exclusion property every two neighbors, oneexecuted without infinitely often.Intuitively, distributed scheduler fair exclusion longer generate infinite sequences pathological execution schedules used previous subsection provenegative results. Instead, guaranteed time time, every two neighboringunits execute together.alternative, might weaken requirement uniformity algorithm(that nodes execute procedure). almost uniform algorithmnodes perform procedure except one node marked unique.almost uniform version algorithm activate, root tree marked executesprocedure Section 3.4 neighbors pointing it; i.e., constantly setsPij zero.4.3 Algorithm activate Section 3.4 following properties: 1. converges global minimum self-stabilizing6 networks tree-like topologiesdistributed scheduler fair exclusion. 2. algorithm also converges tree-like subnetworks (but self-stabilizing) network cycles. 3. self-stabilizingtopology almost uniform algorithm applied, even pure distributedscheduler.Theorem6. initialization step algorithm omitted self-stabilizing version.235fiPinkas Dechterproof see appendix.5. Extensions Arbitrary Networksalgorithm presented Section 3 limited restricted nodes tree-likesubnetworks only. Nodes part cycle execute traditional activation functionmay lead known drawbacks local energy minima slow convergence.section discuss generalizations algorithm nodes part cycles,work well near-tree networks. full account extension deferredfuture work.well known scheme extending tree algorithms non-tree networks, cycle-cutsetdecomposition (Dechter, 1990), used Bayes networks constraint networks. Cyclecutset decomposition based fact instantiated variable cuts owinformation path lies therefore changes effective connectivitynetwork. Consequently, group instantiated variables cuts cyclesgraph, (e.g., cycle-cutset), remaining network viewed cycle-freesolved tree algorithm. complexity cycle-cutset method boundedexponentially size cutset connected component graph (Dechter,1992). next show improve energy minimization algorithm, activate usingcycle-cutset idea.Recall energy minimization task find zero/one assignment variables X = fX1; :::; Xng maximizes goodness function. Define Gmax(X1; :::; Xn) =maxX1;:::;X G(X1; :::; Xn). task find activation level X1; :::; Xn satisfyingXXGmax(X1; :::Xn) = maxX1 ;:::;X ( wi;j XiXj + Xi):(2)nni<jLet = fY1 ; :::; Ykg subset variables X = fX1; :::; Xng. maximumcomputed two steps. First compute maximum goodness conditioned fixedassignment = , maximize resulting function possible assignments .Let Gmax(X jY = ), maximum goodness value G conditioned = . Clearly,Gmax(X ) = maxY =y Gmax(X jY = ) = maxY =y maxfX =xjx =yg fG(X )g;where, xY zero/one value assignments instantiation x restrictedvariable subset . variables form cycle-cutset, conditionalmaxima Gmax(X jY = ) computed eciently using tree algorithm. overallmaxima may achieved subsequently enumerating possible assignments .Obviously, scheme effective cycle-cutset small. next discusssteps towards implementing idea distributed environment.Given network set nodes X = fX1; :::; Xng, subset cutset variables= fY1; :::; Ykg, presumably cycle-cutset, assuming fixed, unchangeable assignment= y, cutset variables behave like leaf nodes, namely, select neighborsparent neighbor point them. Thus, cutset variable may severalparents zero child nodes.Considering example network Figure 3b assuming node (7) cutsetvariable, tree-directing may change node (7) points (5) (6),236fiImproving Connectionist Energy Minimization(6) points (5) (5) remains root. Note modification arcsdirected resulting graph acyclic directed graph. graph directed,regular non-cutset node exactly view before. one parent (orparent) perhaps set child nodes, may cutset nodes.computes goodness values activation values almost before.algorithm along lines compute maximum energy conditioned = ,cycle-cutset. Note however assignment guaranteed convergelocal maxima original (Hopfield) activation function. cutset nodesmay unstable relative function.Enumerating conditional maxima get global maxima cannot done distributedly, unless cutset size small. cutset small, computationdone parallel, yielding practical distributed solution networks, follows.tree-directing part accomplished, node computes collection goodness values,indexed conditioning assignment = . goodness values nodeassociated cutset assignment = computed using goodness valueschild nodes also associated assignment = . maximumnumber goodness values node may need carry exponential cutset size.Upon convergence, roots trees select assignment = maximize overall goodness value propagate information tree nodesswitch values accordingly. algorithm certainly connectionistspirit practically limited small cutsets. advantage finds true globaloptimum.following subsection, modify cutset approach towards connectionist spirit integrating cutset scheme standard energy minimizing activationfunction. yields connectionist-style algorithm simple activation functionlimited memory requirements identity cycle-cutset nodes known.determine cutset variables initially using centralized algorithm computing smallcutset (Becker & Geiger, 1994). Although guaranteed find global solution, newactivation function powerful standard approaches cyclic topologies.5.1 Local search cycle cutsetAlgorithm activate-with-cutset Figure 10 assumes cutset nodes knownpriori; time however, values changing using standard local techniques (e.g.,Hopfield). algorithm well-defined also cutset nodes cut cyclescutset minimal. However, likely work best cutset smallcuts cycles.Note goodness value computation cutset nodes (step 4) performingmaximization operation two possible activation values cutset variablessince activation value cutset nodes fixed far tree algorithm concerned.Intuitively, performed sequentially algorithm would iterate followingtwo steps: 1. finding local maximum using Hopfield activation function cutsetvariables; 2. finding global maximum conditioned cutset values determinedprevious step via tree algorithm. connectionist framework two stepssynchronized. Nevertheless, algorithm converge local maxima relative237fiPinkas DechterAlgorithm activate-with-cutset (unit i)Assumption: cutset nodes given priori.1. Initialization: first time, (8j ) Pij = 0;2. Tree directing:cutset node, every neighbor (j ), Pji = 0, Pij = 1;(neighbors become parents unless already point it)else (not cutset node), exists single neighbor k, Pki = 0,(part tree root) Pik = 1 neighbors j , Pij = 0;else (root non-tree node), neighbors Pij = 0;3. Assigning activation values:neighborsofPi point except maybe one (i.e., part tree) then,(j10j ((Gj , Gj )Pj + wi;j Xj Pi ) ,iXi = 10 ifotherwiseelse (a cutset( nodePor node yet part tree), Compute Hopfield:j wi;j Xj ,iXi = 10 ifotherwise4. Computing goodness values: (only nodes trees need goodness values)cutset node, neighbor j ,G0i = Xi ,Gji 1 = Xi (i + wij ) (G0i ; Gji 1 goodness values neighbor j ).else (a regular Ptree node),0Gi = maxf j2neighbors(i) G0j Pji ; Pj 2neighbors(i) G1j Pji + ig;G1i = maxfPj2neighbors(i) G0j Pji ; Pj 2neighbors(i)(G1j Pji + wi;j Pij ) + g;Figure 10: Algorithm activate-with-cutset238fiImproving Connectionist Energy MinimizationHopfield algorithm well conditional global maxima relative cutset variables.Convergence follows fact tree directing algorithm guaranteed convergegiven fixed cutset variables. does, node ips value either result Hopfieldstep order optimize tree. steps energy increase.7Example5.1 following example demonstrates algorithm finds better min-imum found standard Hopfield algorithm cycles. Consider energy function: energy = 50AB , 200BC , 100AC , 3AD , 3DE , 3AE +0:1A + 0:1B + 0:1C + 4E + 4D. associated network consists two cycles: A; B; CA; D; E . select node cutset node, network would cuttwo acyclic (tree-like) subnetworks. Assume network starts setting zeros(A; B; C; D; E = 0). local minimum (energy = 0) Hopfield algorithm.activate-with-cutset algorithm breaks local minimum optimizing acyclicsubnetwork A; B; C conditioned = 0. result optimization assignment= 0; B = 1; C = 1; = 0; E = 0 energy = ,199:7. stable stateobtains excitatory sum inputs (50) therefore ips value = 1 usingHopfield activation algorithm. new state A; B; C = 1; D; E = 0 also local minimum Hopfield paradigm (energy = ,249:7). However, since nodes A; D; E formtree, activate-with-cutset algorithm also manages break local minimum.finds global solution conditioned = 1 happens global minimumA; B; C; D; E = 1 energy = ,250:97. new algorithm capable findingglobal minimum energy function managed escape two local minimatrapped Hopfield algorithm.easy see algorithm activate-with-cutset improves activate followingsense:Theorem 5.1 a1 local minimum generated activate a2 local minimumgenerated activate-with-cutset, a1 a2 activation valuenon-tree nodes then, G(a2) G(a1).5.2 Local search changing cutset variablesimagine extension cutset scheme idea improve resulting energy level conditioning optimizing relative many cutsets.sequential implementation algorithm move one cutset next,improvement. process guaranteed monotonically reduce energy.unclear however tour among cutsets implemented connectionistenvironment. clear even identify one cutset distributedly. Since findingminimal cycle-cutset NP-complete distributed algorithm problem unlikelyexist. Nevertheless, could many brute-force distributed algorithms may findgood cutset practice. Alternatively, cutset nodes may selected processrandomly designates node cutset node.7. Fluctuations temporarily increase energy may occur time time tree propagation completely stabilized. example, node may use goodness values childrengoodness values ready (but point node).239fiPinkas Dechterfollowing paragraphs outline ideas uniform connectionist algorithmallows exploration cutset space. propose use random functioncontrol identity cutset nodes. random process node becomescutset node switch cutset node regular node may governed randomheuristic function f (). non-tree node may turn cutset node probabilityP = f (). cutset node may turn non-cutset node becomes part treerandom process probability P = g (). function f () designedway assign high probabilities nodes potential become \good" cutsetnodes. probability de-selecting cutset node may defined g () = 1 , f ().Algorithm activate-with-cutset augmented cutset selection functionrunning parallel three procedures (tree-directing, assigning activationvalues goodness computing). Thus, may add forth procedure selects (orde-selects) node cutset node probability P = f (). Note randomlyselected cutset perfect might many cutset nodes.long cycles, cutset nodes selected. time, nodesfunctioning long cutset nodes de-selected thus reducing chancesredundant cutset nodes continuously exploring space possible cutsets.One way implement heuristic function f base following ideas: 1.Increase probability non-tree nodes cutset nodes long time. 2.Increase probability nodes ipped value long time. 3. Increaseprobability nodes high connectivity.Note de-selected cutset node may cause chain reaction undirecting nodes.Nodes lost tree-pointers become not-part-of-tree thus potentialbecome cutset nodes. network may continue tour cutset space indefinitelymay never become static. selection-de-selection process may never converge. Nevertheless, function f designed allow enough time convergence cutsetchanges whole process, energy tends decrease. Temporary uctuations may sometimes cause energy increase node relies yet stableneighbors.8 conjecture heuristic function f constructed allowtrees stabilized distroyed de-selection. Formalizing algorithm'sproperties investigation experimentation left future research.6. Conclusionsmain contributions paper are:1. provide connectionist activation function (algorithm activate, Figure 5),self-stabilizing guaranteed converge global minima linear timetree-like networks. general networks algorithm generate global minimatree subnetworks rest network coincide regular localgradient activation functions (e.g., Hopfield). algorithm dominates arbitrarylocal search connectionist algorithm following sense: a1 local minimumgenerated activate a2 local minimum generated corresponding localsearch method, a1 a2 activation values non-tree nodes8. example, temporarily relying old goodness values de-selected node.240fiImproving Connectionist Energy Minimization(if tree set empty), energy a1 smaller equalenergy a2.2. showed activate extended using cycle-cutset idea.extended algorithm called activate-with-cutset (Figure 10) guaranteed convergegenerate solutions least good normally better algorithmactivate. algorithm converges conditional global minima relative valuescutset variables. a1 local minima generated activate a2 localminima generated activate-with-cutset a1 a2 activationvalues cutset variables (if tree, cutset empty) energya2 smaller equal energy a1 . Therefore activate-with-cutset betteractivate turn better regular energy-minimization connectionistalgorithm sense. third variation algorithm sketchedfuture investigation. idea cutset nodes randomly continuouslyselected, thus allowing exploration cutset space.3. stated two negative results: 1) pure distributed scheduler uniformalgorithm exists globally optimize even simple chain-like networks. 2) uniformalgorithm exists globally optimize simple cyclic networks (rings) evencentral scheduler. conjecture negative results significantpractical importance since realistic schedulers probability infinitepathological scheduling scenarios approaches zero. showed algorithmconverges correctly (on tree-like subnetworks) demand pure distributedschedulers somewhat relaxed; i.e., adding either fair exclusion, almost uniformitycycles. Similarly, self-stabilization obtained acyclic networksrequirement uniform algorithm relaxed (almost uniformity).negative results apply connectionist algorithms well parallel versionslocal repair search techniques. positive results suggest improvements connectionist activation functions local repair techniques.conclude discussion two domains likely produce sparse, neartree networks thus benefit algorithms presented: inheritance networksdiagnosis.Inheritance straightforward example application translations symbolic rules energy terms form networks mostly cycle free. arcinheritance network, ISA B B modeled energy term , AB .connectionist network represents complete inheritance graph obtainedsumming energy terms correspond ISA relationshipsgraph. Nonmonotonicity expressed add penalties arcs use semanticsdiscussed Pinkas (1991b, 1995). Nonmonotonic relationships may cause cyclesinheritance graph connectionist network (e.g. Penguin ISA Bird; Bird ISAFlyingAnimal; Penguin ISA not(FlyingAnimal)). Multiple inheritance may cause cycleswell, even rules monotonic (e.g., Dolphin ISA Fish; Dolphin ISA Mammal;Fish ISA Animal; Mammal ISA Animal). Arbitrary constraints nodes graphmay introduced model. Constraints may represented proposition logic formulas translated energy terms (Pinkas, 1991) potentially causing cycles.241fiPinkas Dechter\pure" inheritance network multiple inherited nodes nonmonotonic relationships, network cycle-free processed eciently various algorithms.allow multiple inheritance, nonmonotonicity, arbitrary propositional constraints,may introduce cycles network generated. Nevertheless, reasonableassume large practical inheritance domains cycles (multiple inheritance, nonmonotonicity arbitrary constraints) scarcely introduced exist mayhandled extension using cycle-cutset idea.Another potential application generate mostly cycle-free subnetworks diagnosis. possible formulation diagnosis framework. Let X1; X2; :::XnTrue(1)/false(0) propositions represent symptoms hypotheses. diagnosisapplication may diagnosis rules form: (ff1X 1; ff2X2 ; :::; ffmXm ! fiX ).rules announce symptoms X1; :::; Xm importance factors ff1 ; :::; ffm,suggest hypothesis X sensitivity fi . subset symptoms may enoughsuggest hypothesis sum importance factors active symptomslarger sensitivity fi . Intuitively, larger sum factors, largerthePsupport thePhypothesis. corresponding energy function diagnosis rulemi ,ffi Xi X + mi ffi Xi + fiX . addition, arbitrary propositional constraints mayalso added, like (X ! Xi) i.e., hypothesis X holds, symptom Xi.(X1 ! (:X2 ^ :X3 ) ^ X2 ! (:X1 ^ :X3) ^ X3 ! (:X1 ^ :X2)) i.e., onepropositions X1 ; X2; X3 true (mutual exclusion). propositional logic formulaallowed nonmonotonicity may expressed using con icting constraints (augmentedimportance factors). Quadratic energy functions may generated arbitrarypropositional constraints introducing hidden variables (Pinkas, 1991).Sparseness networks emerges result assuming conditional independencysymptoms relative hypothesis. Independency assumptions kind (that makescomputation tractable) quite common actual implementations Bayes networks,uence diagrams (Pearl, 1988), certainty propagation rule-based expert systems(Shortliffe, 1976). knowledge base consists diagnosis rules (and maybecorresponding X ! Xi rules) symptoms independent other,cycles network, tree algorithm converges global maximumlinear time. add dependent symptoms affect hypothesisone path; e.g., X1 ! X , X1 ! X2 ! ::: ! X , start adding arbitraryconstraints, cycles added. dependent symptoms arbitrary constraintsscarcely added, network generated likely lend ecientlyactivate-with-cutset algorithm.Abandonment ecient algorithms exists inheritance diagnosistractable forms. algorithm offers solve eciently tractable versions problem approximate intractable versions massively parallel, simple implementmethods. eciency suggested process depends \closeness" problemideal, tractable form.A. AppendixProof sketch theorem 4.3: second third phases algorithm adaptationsexisting dynamic programming algorithm (Bertele & Brioschi, 1972), cor242fiImproving Connectionist Energy Minimizationrectness therefore proved here. self-stabilization steps obviousvariables initialized. proof therefore dependent convergence treedirecting phase.Let us first assume scheduler distributed fair exclusionnetwork tree. first part theorem proved points 1-4. want showtree-directing algorithm converges, self-stabilizing final stableresult pointers Pij represent tree. Points 5 6 prove parts 2 3theorem. node called legal either root (i.e., neighbors legal, pointdoesn't point them), intermediate node (i.e., points oneneighbors rest neighbors legal point back). node calledcandidate illegal node neighbors one pointing it. wouldlike show that:1. property legal stable; i.e., node becomes legal stay legal.2. state number illegal nodes k > 0, leads state numberillegal nodes less k; i.e., number illegal nodes decreases eventuallynodes turn legal.3. nodes legal graph marked tree.4. algorithm self-stabilizing trees.5. algorithm converges even graph cycles (part 2 theorem).6. algorithm self-stabilizing arbitrary networks almost uniform versionused, even distributed scheduler (part 3 theorem).prove points.1. Show legal state stable. Assume legal node becomes illegal. eitherroot node one children became illegal, intermediate node whose onechildren became illegal (it cannot parent suddenly pointsone children stopped pointing still legal). Therefore, mustchain i1 ; i2; :::; ik nodes became illegal. Since cycles, mustleaf legal turned illegal. cannot occur since leafchildren; leading contradiction.2. Show illegal nodes, number reduced. prove claimneed three steps:(a) Show eventually, illegals, also candidates.fair exclusion, eventually state reached nodeexecuted least once. Assume least one node illegal,illegal nodes candidates. node illegal candidate,either root-type (all point it) least one childrenillegal, least two neighbors illegal. Supposeroot-type illegal nodes. illegal nodes least two243fiPinkas Dechterillegal neighbors. Therefore must cycle connects illegal nodes(contradiction). Therefore, one illegal nodes must root-type. Supposeroot-type illegal node. must neighbor j illegal. Considersubtree j include i: must contain illegal nodes.root-type illegal nodes get contradiction again. However,root-type node, eliminate look subtree illegal j 0include j . Eventually, since network finite, obtain subtreeroot-like illegal nodes includes illegal nodes. leadscontradiction. conclusion must candidatesillegal nodes.(b) Show candidate stable unless becomes legal.node candidate, legal children remain legal. threetypes candidate nodes (node j illegal neighbor i):i. node j points i;ii. pointer goes directions;iii. pointer j vice-versa.possible changes pointers Pij Pji cause remain candidateturn legal (the rest pointers changed).(c) Show every candidate node eventually turn legal: Assume j illegalneighbor candidate i. next execution without j (fair exclusion),Pji = 0 becomes legal pointing j ; otherwise, becomes root-typecandidate (all neighbors point it) j illegal. proveillegal node j points eventually state reached eitherj legal Pji = 0, proposition stable holds.statement true executed eventually, j legal i0neighbors legal therefore turns legal. j illegal Pji = 0,point (Pij = 1) making legal.next prove j illegal node pointing stateeither j legal Pji = 0, state stable. prove inductionsize subtree j include i.Base step: j leaf j points time j executed (withouti) Pij = 0, node j points becomes legal; otherwise, j updates Pji = 0.status stable legal state stable since leaf pointnode turns legal.Induction step: Assume hypothesis True trees size less n. Suppose jillegal neighbor i. Node j points j1 ; :::; jk neighbors.assume nodes executed least one time, since j pointsassume last execution j neighbors j1 ; :::; jkpointed j . subtrees rooted jl (not including j ) size less ntherefore hypothesis state nodes j1 ; :::; jkeither legal Pjj = 0. state stable, eventually j executed,either point turning legal (if j1; :::; jk pointing it),make Pji = 0 (if neighbors point it). Since statusl244fiImproving Connectionist Energy Minimizationj1; :::; jk stable point, whenever j executed either become legal3.4.5.6.pointers become zero.Show nodes legal graph marked tree: nodelegal, children legal point it. Therefore node representssubtree (if leaf) one parent most. showone root make following argument. several roots exist,connectivity, one node shared least two subtreestherefore two parents (contradiction).algorithm self-stabilizing cycle-free networks since initialization needed(in proof haven't use first initialization step; i.e., Pij = 0). casecycles exist need step. pointers get initial valuesalgorithm still converges.algorithm (with Pij = 0 initialization) converges even graph cycles.Since nodes start zero pointers, (pseudo) root tree-like subnetworknever point toward neighbors (since part cycleneighbors one must legal).Show algorithm self-stabilizing arbitrary networks almost uniformversion used, even distributed scheduler. need show candidateeventually turn legal even neighbors executed time.Suppose node candidate node j illegal neighbor:(a) j root, never point i, therefore eventually turnlegal pointing j .(b) root, Pij = 0, j becomes legal point makinglegal. Node j turn eventually legal using following induction (on sizesubtree j ):Hypothesis: subtree without node acts root, illegal nodeseventually turn legal.Base step: j leaf, point eventually neighbor turnmake j legal Pij = 0.Induction step: j1 ; :::; jk neighbors j , eventuallyturn legal (induction hypothesis) pointing j . Eventually j executedalso turns legal.(c) Suppose neither j roots, one part cycle (andtherefore part subtree include node marked root).Using induction, nodes subtree eventually turn legal.result either j eventually turns legal, therefore eventuallyturn legal well.2245fiPinkas Dechter7. Acknowledgementwork supported part NSF grant IRI-9157636, Air Force Oce ScientificResearch, AFOSR 900136, Toshiba America Xerox grant. would alsolike thank Kalev Kask commenting latest version manuscript, KaoruMulvihill drawing figures, Lynn Haris editing anonymous reviewershelped improve final version paper. shorter version paper appearsearlier (Pinkas & Dechter, 1992).ReferencesBallard, D. H., Gardner, P. C., & Srinivas, M. A. (1986). Graph problems connectionistarchitectures. Tech. rep. 167, University Rochester.Becker, A., & Geiger, D. (1994). Approximation algorithms loop cutset problems.Proceedings 10th conference Uncertainty Artificial Intelligence (UAI-94),pp. 60{68 Seattle, Washington.Bertele, U., & Brioschi, F. (1972). Nonserial Dynamic Programming. Academic Press, NewYork.Brandt, R. D., Wang, Y., Laub, A. J., & Mitra, S. K. (1988). Alternative networkssolving traveling salesman problem list-matching problem. IEEE International Conference Neural Networks, 2, 333{340.Collin, Z., Dechter, R., & Katz, S. (1991). feasibility distributed constraintsatisfaction. Proceedings IJCAI Sydney.Dechter, R. (1990). Enhancement schemes constraint processing: Backjumping, learningcutset decomposition. Artificial Intelligence, 41(3), 273{312.Dechter, R. (1992). Constraint networks. Encyclopedia Artificial Intelligence, 2nd ed.,pp. 276{285. John Wiley & Sons, Inc.Dechter, R., Dechter, A., & Pearl, J. (1990). Optimization constraint networks.R.M. Oliver, J. S. (Ed.), uence diagrams, belief nets decision analysis. JohnWiley Sons.Feldman, J. A., & Ballard, D. H. (1982). Connectionist models properties. Cognitive Science 6.Hinton, G., & Sejnowski, T. (1986). Learning re-learning boltzmann machines.Parallel Distributed Processing: Explorations Microstructure Cognition I,J. L. McClelland D. E. Rumelhart, pp. 282{317. MIT Press, Cambridge, MA.Hopfield, J. J. (1982). Neural networks physical systems emergent collectivecomputational abilities. Proceedings National Academy Sciences 79, pp.2554{2558.246fiImproving Connectionist Energy MinimizationHopfield, J. J. (1984). Neurons graded response collective computational properties like two-state neurons. Proceedings National AcademySciences 81, pp. 3088{3092.Hopfield, J. J., & Tank, D. W. (1985). Neural computation decisions optimizationproblems. Biological Cybernetics, 52, 144{152.Kasif, S., Banerjee, S., Delcher, A., & Sullivan, G. (1989). results computational complexity symmetric connectionist networks. Tech. rep. JHU/CS-89/10,Department Computer Science, John Hopkins University.Korach, K., Rotem, D., & Santoro, N. (1984). Distributed algorithms finding centersmedians networks. ACM Transactions Programming Languages Systems,6(3), 380{401.McClelland, J. L., Rumelhart, D. E., & Hinton, G. (1986). appeal pdp. J. L.McClelland D. E. Rumelhart, Parallel Distributed Processing: ExplorationsMicrostructure Cognition I. MIT Press, Cambridge, MA.Minton, S., Johnson, M. D., & Phillips, A. B. (1990). Solving large scale constraint satisfaction scheduling problems using heuristic repair method. ProceedingsEighth Conference Artificial Intelligence, pp. 17{24.Papadimitriou, C., Shaffer, A., & Yannakakis, M. (1990). complexity local search.ACM Symposium Theory Computation, 438{445.Pearl, J. (1988). Probabilistic Reasoning Intelligent Systems: Networks PlausibleInference. Morgan Kaufmann Publishers, San Mateo, California.Peterson, C., & Hartman, E. (1989). Explorations mean field theory learning algorithm.Neural Networks 2, 6.Pinkas, G. (1991). Energy minimization satisfiability propositional calculus.Neural Computation 3, 2.Pinkas, G., & Dechter, R. (1992). new improved activation function energy minimization. Proceedings Tenth National Conference Artificial Intelligence(AAAI), pp. 434{439 San Jose.Rumelhart, D. E., Hinton, G. E., & McClelland, J. L. (1986). general frameworkparallel distributed processing. J. L. McClelland D. E. Rumelhart, ParallelDistributed Processing: Explorations Microstructure Cognition I. MIT Press,Cambridge, MA.Selman, B., Levesque, H., & Mitchell, D. (1992). new method solving hard satisfiabilityproblems. Proceedings Tenth National Conference Artificial Intelligence,pp. 440{446.Shortliffe, E. H. (1976). Computer-Based Medical Consultation, Mycin. Elsevier, New York.247fiPinkas DechterSmolensky, P. (1986). Information processing dynamical systems: Foundations harmony theory. J. L. McClelland D. E. Rumelhart, Parallel Distributed Processing: Explorations Microstructure Cognition I. MIT Press, Cambridge,MA.248fiJournal Artificial Intelligence Research 3 (1995) 383-403Submitted 6/95; published 12/95Rule-based Machine Learning Methods FunctionalPredictionSholom M. Weissweiss@cs.rutgers.eduNitin Indurkhyanitin@cs.usyd.edu.auDepartment Computer Science, Rutgers UniversityNew Brunswick, New Jersey 08903, USADepartment Computer Science, University SydneySydney, NSW 2006, AUSTRALIAAbstractdescribe machine learning method predicting value real-valued function, given values multiple input variables. method induces solutionssamples form ordered disjunctive normal form (DNF) decision rules. centralobjective method representation induction compact, easily interpretablesolutions. rule-based decision model extended search eciently similar cases prior approximating function values. Experimental results real-world datademonstrate new techniques competitive existing machine learningstatistical methods sometimes yield superior regression performance.1. Introductionproblem approximating values continuous variable described statistical literature regression. Given samples output (response) variable input(predictor) variables x = fx1 :::xn g, regression task find mapping = f(x). Relative space possibilities, finite samples far complete, predefinedmodel needed concisely map x y. Accuracy prediction, i.e. generalization newcases, primary concern. Regression differs classification output variable regression problems continuous, whereas classification strictly categorical.perspective, classification thought subcategory regression.machine learning researchers emphasized connection describing regression\learning classify among continuous classes" (Quinlan, 1993).traditional approach problem classical linear least-squares regression(Scheffe, 1959). Developed refined many years, linear regression proven quiteeffective many real-world applications. Clearly elegant computationally simple linear model limits, complex models may fit data better.increasing computational power computers larger volumes data, interest grown pursuing alternative nonlinear regression methods. Nonlinear regressionmodels explored statistics research community many new effectivemethods emerged (Efron, 1988), including projection pursuit (Friedman & Stuetzle,1981) MARS (Friedman, 1991). Methods nonlinear regression also developed outside mainstream statistics research community. neural network trainedback-propagation (McClelland & Rumelhart, 1988) one model. modelsc 1995 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiWeiss & Indurkhyafound numerical analysis (Girosi & Poggio, 1990). overview many differentregression models, application classification, available literature (Ripley,1993). methods produce solutions terms weighted models.real-world, classification problems commonly encountered regression problems. accounts greater attention paid classification regression. many important problems real world regression type.instance, problems involving time-series usually involve prediction real values. Besidesfact regression problems important own, another reason needfocus regression regression methods used solve classification problems.example, neural networks often applied classification problems.issue interpretable solutions important consideration leadingdevelopment \symbolic learning methods." popular format interpretable solutionsdisjunctive normal form (DNF) model (Weiss & Indurkhya, 1993a). Decision treesrules examples DNF models. Decision rules similar characteristics decisiontrees, also potential advantages: (a) stronger model (b) often betterexplanatory capabilities. Unlike trees, DNF rules need mutually exclusive. Thus,solution space includes tree solutions. rules potentially compactpredictive trees. Decision rules may also offer greater explanatory capabilitiestrees tree grows size, interpretability diminishes.Among symbolic learning methods, decision tree induction, using recursive partitioning, highly developed. Many methods developed within machine learningcommunity, ID3 decision tree induction (Quinlan, 1986), applied exclusively classification tasks. Less widely known decision trees also effectiveregression. CART program, developed statistical research community, induces classification regression trees (Breiman, Friedman, Olshen, & Stone, 1984).regression trees strictly binary trees, representation naturally followsintensive modeling using continuous variables.1terms performance, regression trees often competitive performanceregression methods (Breiman et al., 1984). Regression trees noted particularlystrong many higher order dependencies among input variables (Friedman,1991). advantages regression tree model similar advantages enjoyedclassification trees models. Two principal advantages cited: (a) dynamicfeature selection (b) explanatory capabilities. Tree induction methods extremelyeffective finding key attributes high dimensional applications. applications,key features small subset original feature set. Another characteristicdecision trees often cited capability explanation terms acceptablepeople. negative side, decision trees cannot represent compactly many simplefunctions, example linear functions. second weakness regression treemodel discrete, yet predicts continuous variable. function approximation,expectation smooth continuous function, decision tree provides discrete regionsdiscontinuous boundaries. though, regression trees often producestrong results, many applications advantages strongly outweigh potentialdisadvantages.1. comparative study (Fayyad & Irani, 1992) suggests binary classification trees somewhatpredictive even categorical variables.384fiRule-based Functional Predictionpaper describe new method inducing regression rules. methodtakes advantage close relationship classification regression providesuniform general model dealing problems. Additional gains obtainedextending method manner preserves strengths partitioningschemes compensating weaknesses. Rules used searchrelevant cases, subset cases help determine function value. Thus,model's interpretability traded better performance. Empiricalresults suggest methods effective induce solutions oftensuperior decision trees.2. Measuring Performanceobjective regression minimize distance sample output values,yi predicted values yi . Two measures distance commonly used. classicalregression measure equation 1, average squared distance yi yi , i.e.variance. leads elegant formulation linear least squares model. meanabsolute distance (deviation) equation 2 used least absolute deviation regression,perhaps intuitive measure.mean absolute distance (deviation) equation 2 used studies.measure average error prediction yi n cases.00Xn (yi , yi)2i=1nXMAD = 1 jyi , yi jV ariance = n10(1)(2)n i=1regression problem sometimes described signal noise problem. modelextended include stochastic component equation 3. Thus, true function mayproduce zero error distance. contrast classification labels assumedcorrect, regression predicted values could explained number factorsincluding random noise component, , signal, y.0= f (x1 : : : xn) +(3)prediction primary concern, estimates based training cases aloneinadequate. principles predicting performance new cases analogousclassification, mean absolute distance used error rate. bestestimate true performance model error rate large set independent testcases. large samples data unavailable, process train test simulatedrandom resampling. experiments, used (10-fold) cross-validationestimate predictive performance.3. Regression Tree Inductionsection, contrast regression tree induction classification tree induction. Likeclassification trees, regression trees induced recursive partitioning. solution takes385fiWeiss & Indurkhyaform equation 4, Ri disjoint regions, ki constant values, yji refersy-values training cases fall within region Ri .x Ri f (x) = ki = medianfyji g(4)Regression trees representation classification trees except terminal nodes. decision terminal node assign case constant value.single best constant value median training cases falling terminal nodepartition, median minimizer mean absolute distance. Figure 1example binary regression tree. cases reaching shaded terminal node 1 (x13)assigned constant value y=10.1x1<=3x1>312y=10x2<=1x2>123y=2y=5Figure 1: Example Regression TreeTree induction methods usually proceed (a) finding covering set trainingcases (b) pruning tree best size. Although classification treeswidely studied, similar approach applied regression trees. assumereader familiar classification trees, cite differences binarytree induction (Breiman et al., 1984; Quinlan, 1986; Weiss & Kulikowski, 1991). manyrespects, regression tree induction straightforward. classification trees, errorrate poor choice node splitting, alternative functions entropy giniemployed. regression tree induction, minimized function, i.e. absolute distance,satisfactory. node, single best split minimizes mean absolutedistance selected. Splitting continues fewer minimum number casescovered node, cases within node identical value y.goal find tree generalizes best new cases, oftenfull covering tree, particularly presence noise weak features. pruning strategiesemployed classification trees equally valid regression trees. Like coveringprocedures, substantial difference error rate measured termsmean absolute distance. One popular method weakest-link pruning strategy (Breimanet al., 1984). weakest-link pruning, tree recursively pruned ratio delta/nminimized, n number pruned nodes delta increase error.386fiRule-based Functional Predictionx13 ! y=10x21 ! y=2Otherwise y=5Figure 2: Example Regression RulesWeakest link pruning several desirable characteristics: (a) prunes training casesonly, remaining test cases relatively independent (b) compatibleresampling.4. Regression Rule Inductiontree rule induction models find solutions disjunctive normal form, modelequation 4 applicable both. rule rule-set represents single partitionregion Ri . However, unlike tree regions, regions rules need disjoint.non-disjoint regions, several rules may satisfied single sample. mechanismneeded resolve con icts ki , constant values assigned, multiple rules,Ri regions, invoked. One standard model (Weiss & Indurkhya, 1993a) orderrules. ordered rule-sets also referred decision lists. first rulesatisfied selected, equation 5.< j x Ri Rj f (x) = ki(5)Figure 2 example ordered rule-set corresponding tree Figure 1.cases satisfying rule 3, rules 1 2, assigned value y=5.Given model regression rule sets, problem find procedures effectivelyinduce solutions. rule-based regression, covering strategy analogous classification tree strategy could specified. rule could induced adding single componenttime, added component single best minimizer distance. usual,constant value ki median region formed current rule. ruleextended, fewer cases covered. fewer minimal number cases covered,rule extension terminates. covered cases removed rule induction continueremaining cases. also regression analogue rule induction proceduresclassification (Michalski, Mozetic, Hong, & Lavrac, 1986; Clark & Niblett, 1989).However, instead approach, propose novel strategy mapping regressioncovering problem classification problem.4.1 Reformulation Regression Problemmotivation mapping regression classification based number factorsrelated extra information given regression problem: natural ordering yimagnitude: > j yi > yj .Let fCi g set consisting arbitrary number classes, class containingapproximately equal values fyi g. solve classification problem, expectclasses different other, patterns found distinguish387fiWeiss & Indurkhya1. Generate set Pseudo-classes using P-class algorithm (Figure 4).2. Generate covering rule-set transformed classificationproblem using rule induction method Swap-1(Weiss & Indurkhya, 1993a).3. Initialize current rule set covering rule set save it.4. current rule set pruned, iteratively following:a) Prune current rule set.b) Optimize pruned rule set (Figure 5) save it.c) Make pruned rule set new current rule set.5. Use test cases cross-validation pick best saved rule sets.Figure 3: Overview Method Learning Regression Rulesclasses. expect classes formed ordering fyi g reasonable classification problem? numbers reasons answer yes, particularlyrule induction procedure.obvious situation classical linear relationship. instance,definition, ordering fx1i . . . xni g corresponds ordering yi . Although classicalmethods strong compactly determining linear functions, interest modernmethods centers around potential finding nonlinear relationships. nonlinearfunctions, know usually ordering fx1i . . . xni g correspondingfyig. Still, expect true function smooth, local region orderingrelationship hold. terms classification, know class Cj similar valuesquite different class Ck much lower values y. nonlinear functionwithin class similar values y, similar values fx1i . . . xni g.correspond local region function. However, also trueidentical values different fx1i . . . xni g multiple clustersfound within class. rule induction methods cover class singlerule, expectation multiple patterns found cover clusters.cases assigned (pseudo-)classes, classification problemsolved following stages: (a) find covering set (b) prune rule setappropriate size, improved results achieved additional technique considered:(c) refine optimize rule set. overall method outlined Figure 3.4.2 Generating Pseudo-classesprevious section, described motivation pseudo-classes. specificationclasses use information beyond ordering y. assumptionstrue nature underlying function made. Within environment,goal make values within one class similar values across classesdissimilar. wish assign values classes overall distanceyi class mean minimum.388fiRule-based Functional PredictionInput: fyi g set output valuesInitialize n := number cases, k := number classesClassiClassi := next n/k cases list sorted valuesend-forCompute ErrnewRepeatErrold = ErrnewCasejClassi1. Dist[Casej , Mean(Classi,1 )] < Dist[Casej , Mean(Classi )]Move Casej Classi,12. Dist[Casej , Mean(Classi+1 )] < Dist[Casej , Mean(Classi )]Move Casej Classi+1Next CasejCompute ErrnewErrnew less ErroldFigure 4: Composing Pseudo-Classes (P-Class)Figure 4 describes algorithm (P-Class) assigning values fyi g k classes. Essentially algorithm following: (a) sorts values; (b) assigns approximatelyequal numbers contiguous sorted yi class; (c) moves yi contiguous classreduces global distance Err yi mean assigned class.Classes identical means merged. P-Class variation k-means clustering, statistical method minimizes distance measure (Hartigan & Wong, 1979).Alternative methods depend distance measures (Lebowitz, 1985) may alsoused.Given fixed number k classes, procedure relatively quickly assign yiclasses overall distances minimized. underlying functionunknown, critical global minimum assignment yi. procedurematches well stated goals ordering yi values. obvious remaining questiondetermine k, number classes? Unfortunately, direct answer,experimentation necessary. However, shall see Section 7, empiricalevidence suggesting results quite similar within local neighborhood valuesk. Moreover, relatively large values k, entail increased computational complexityrule induction, typically necessary noise-free functions modeledexactly. Analogous comparisons neural nets increasing numbers hidden units,trends increasing numbers partitions become evident experimentation.One additional variation classification theme arises rule induction schemescover one class time. classes must ordered, last class typically389fiWeiss & Indurkhyabecomes default class cover situations rule classes satisfied.regression, one default partition class unlikely best covering solution,instead remaining cases last class repeatedly partitioned (by P-Class)2 classes fewer cases remain.interesting characteristic transformation regression problemuniform general model relates classificationregression. yi values discrete categorical, P-Class merely restates standardclassification problem. example, values yi either 0 1, resultP-Class 2 non-empty classes.4.3 Covering Rule Settransformation, rule induction algorithms classification applied.consider induction methods fully cover class moving inducerules next class. step covering algorithm, problem consideredbinary classification problem current class Ci versus Cj j > i, i.e.current class versus remaining classes. rule induced, corresponding casesremoved remaining cases considered. class covered,next class considered. example covering algorithm used Swap-1(Weiss & Indurkhya, 1993a), procedure used paper. coveringmethod identical classification regression. However, one distinctionregression classes transient labels replaced median valuescases covered induced rule. rules ordered multiple rulesmay satisfied, medians derived instances rulefirst satisfied.Although procedure may yield good, compact covering sets, additional proceduresnecessary complete solution.4.4 Pruning Rule SetTypical real-world applications noisy features fully predictive. coveringset, particularly one composed many continuous variables, far over-specializedproduce best results. classification, relatively classes specified advance.regression, expect many smaller groups values yi likely quitedifferent.noted earlier regression trees usual classification pruning techniquesapplied substitution mean absolute distance classification error rate.weakest-link tree pruning, ratio delta/n recursively minimizedweakest-link rule pruning. intuitive rationale remove parts rule setleast impact increasing error. Pruning rule sets usually accomplishedeither deleting complete rules single rule components (Quinlan, 1987; Weiss & Indurkhya,1993a). general, rule pruning (for classification regression) less naturalfar computationally expensive tree pruning. Tree pruning natural owset subset. Thus tree pruned bottom up, typically consideringeffect removing subtree. Non-disjoint rules natural pruning order,390fiRule-based Functional Predictionexample every component rule candidate pruning may affect rulesfollow specified rule order.major difference pruning regression rules vs. classification rules.classification, deleting rule rule component effect class labels.regression, pruning change median-values regions. Even deletionrule affect region medians rules ordered multiple rules maysatisfied. characteristic rule pruning regression adds substantial complexitytask. However, assuming median-values remain unchangedevaluation candidate rules prune, pruning procedure achieve reasonablecomputational eciency expense loss accuracy evaluation.best rule component deletion selected, medians regionsre-evaluated.Even classification rules, rule pruning inherent weaknesses. example,rule deletion often create gap coverage. classification rules though, quitefeasible develop additional procedure refine optimize rule set. largeextent, overcomes cited weakness pruned rules sets. similar refinementoptimization procedure developed regression described next.4.5 Rule Refinement OptimizationGiven rule set RSi , improved? question applies rule set, althoughmostly motivated trying improve pruned rules sets fRSo . . . RSi . . . RSng.combinatorial optimization problem. Using error measure Err(RS), improveRSi without changing size, i.e. number rules components? Figure 5 describesalgorithm minimizes Err(RS), MAD model prediction sample cases,local swapping, i.e. replacing single rule component best alternative.variation techniques used Swap-1 (Weiss & Indurkhya, 1993a).central theme hold model configuration constant make single localimprovement configuration. Local modifications made improvements possible. Making local changes configuration widely-used optimizationtechnique approximate global optimum applied quite successfully,example find near-optimum solutions traveling salesman problems (Lin & Kernighan,1973). analogous local optimization technique, called backfitting, usedcontext nonlinear statistical regression (Hastie & Tibshirani, 1990).Variations selection next improvement move could include:1. First local improvement encountered (such backfitting)2. Best local improvement (such Swap-1)experiments rule induction methods, results consistently better(2); (1) ecient, (pruned) rule induction environment mostly stablerelatively local improvements prior convergence. less stable environment,large numbers possible configuration changes, (2) may feasible even better.pruned rule set environment, covering procedure effective, prunedsolution relatively close local minimum solution. Weakest-link pruning391fiWeiss & IndurkhyaInput: RS rule set consisting rules Ri ,set training cases:= TRUE(D TRUE)RSnew := RS single best replacementcomponent RS reduces Err(RS)cases using current Median(Ri )replacement found:= FALSEelseRS := RSnew ; recompute Medians(Ri )endwhilereturn rule set RSFigure 5: Optimization Rule Component Swappingresults series pruned rule sets RSi number far fewer sets wouldresult single prune rule rule component. RSi optimized priorcontinuing pruning process. However, rule set optimization usually suspendedsubstantial segments covering set already pruned.(1) used, either sequentially ordered evaluations (as backfitting) stochastic evaluations considered. Empirical evidence optimization literature supports superiority stochastic evaluation (Jacoby, Kowalik, & Pizzo, 1972).improvements may obtained occasionally making random changes configuration(Kirpatrick, Gelatt, & Vecchi, 1983). general combinatorial optimization techniques must substantially reworked fit specific problem type. expectedapplied throughout problem solving.result pruning covering rule set, RSo , series progressively smaller rulesets fRSo . . . RSi . . . RSn g. objective pick best one, usually formerror estimation. Model complexity future performance highly related.complex simple model yield poor results, objective findright size model. Independent test cases resampling cross-validation effectiveestimating future performance. absence estimates, approximations,GCV (Craven & Wahba, 1979; Friedman, 1991), described equation 6,used statistics literature estimate performance2. measures training errormodel complexity used estimates. C(M), measure model complexityexpressed terms parameters estimated (such number weights neural net)tests performed, C(M) assumed less n, number cases.2. GCV acronym generalized cross-validation, apparent error training cases usedtrue cross-validation resampling.392fiRule-based Functional PredictionXnGCV (M ) =jy ,y j0nC(M)i=1 1 , n(6)experiments used cross-validated estimates guide final model selectionprocess, measures GCV may also used.4.6 Potential Problems Rule-based RegressionRegression rules, like trees, induced recursive partitioning methods approximate function constant-value regions. relatively strong dynamic featureselection high-dimensional applications, sometimes using highly predictivefeatures. essential weakness methods approximation partitionregion constant value. continuous function even moderately sized sample,approximation lead increased error.deal limitation, instead constant-value functions, linear functionssubstituted partition (Quinlan, 1993). However, linear function obviousweakness true function may far linear even restricted contextsingle region. general, use linearity compromises highly non-parametricnature DNF model. better strategy might examine alternative non-linearmethods.5. Alternative Rules: k-Nearest Neighborsk-nearest neighbor method one simplest regression methods, relying tablelookup. classify unknown case x, k cases closest new casefound sample data base stored cases. predicted y(x) equation 7 meanvalues k-nearest neighbors. nearest neighbors found distancemetric euclidean distance (usually feature normalization). methodnon-parametric highly non-linear natureyknn(x) = K1XK yk K nearest neighbours xk=1(7)major problem approach limit effect irrelevant features.limited forms feature selection sometimes employed preprocessing stage,method cannot determine features weighted others.result, procedure sensitive distance measure used. high-dimensionalfeature space, k-nearest neighbor methods may perform poorly. limitationsprecisely partitioning methods address. Thus, theory, two methodspotentially complement one another.6. Model Combinationpractice, one learning model always superior others, learning strategyexamines results different models may better. Moreover, combining393fiWeiss & Indurkhyadifferent models, enhanced results may achieved. general approach combininglearning models scheme referred stacking (Wolpert, 1992). Additional studiesperformed applying scheme regression problems (Breiman, 1993; LeBlanc &Tibshirani, 1993). Using small training samples simulated data, linear combinationsregression methods, improved results reported. Let Mi i-th model trainedsample, wi , weight given Mi .3 new case vectorx, predictions different models combined Equation 8 produceestimate y. models may use representation, k-nearest neighborsvariable-size k, perhaps variable-size decision trees. models could also completelydifferent, combining decision trees linear regression models. Different modelsapplied independently find solutions, later weighted vote taken reachcombined solution. method model combination contrast usual approachevaluation different models, single best performing model selected.y=XK wkMk(x)k=1(8)stacking shown give improved results simulated data, majordrawback properties combined models retained. Thus interpretable models combined, result may interpretable all. alsopossible compensate weaknesses one model introducing another modelcontrolled fashion.suggested earlier, partitioning regression methods k-nearest neighbor regressionmethods complementary. Hence one might expect suitably combining twomethods, one might obtain better performance. one recent study (Quinlan, 1993), modeltrees (i.e., regression trees linear combinations leaf nodes) nearest neighbormethods also combined. combination method described equation 9,N (x)k one K nearest neighbors x, V(x) y-value stored instancex, T(x) result applying model tree x.= K1XK V (N (x)k) , (T (N (x)k) , (x))k=1(9)k-nearest neighbors found independently induced regression tree (resultsreported K=3). sense, approach similar combination methodequation 8. k-nearest neighbors passed tree, results usedrefine nearest neighbor answer. Thus, combination model formedindependently computing global solution, later combining results.However, strong reasons determining global nearest neighbor solution independently. While, limit, large samples, non-parametric k-nearestneighbor methods correctly fit function, practice though, weaknessessubstantial. Finding effective global distance measure may easy, particularlypresence many noisy features. Hence different technique combining twomethods needed.3. weights obtained minimize least squared error constraints (Breiman,1993).394fiRule-based Functional Prediction6.1 Integrating Rules Table-lookupConsider following strategy: determine y-value case x falls region Ri ,instead assigning single constant value ki region Ri , ki determined(x), mean k-nearestmedian value training cases region, assign yknn(training set) instances x region Ri . Thus regression trees, equation10. regression rules, also equation 11.(x)x Ri f (x) = yknn(10)(x)< j x Ri Rj f (x) = yknn(11)interesting aspect strategy k-nearest neighbor results needconsidered cases covered particular partition. increases interaction models eliminates independent computation two models,model rationale and, shall show, empirical results, supportiveapproach.representation potentially alleviates weakness partitionsassigned single constant values. Moreover, global distance measure difficulties k-nn methods may also relieved table lookup reducedpartitioned related groupings.rationale hybrid partition k-nn scheme. Note unlike stacking,hybrid models independently determined, interact strongly oneanother. However, must demonstrated methods fact complementary,preserving strengths partitioning schemes compensating weaknesseswould introduced constant values used region. respect modelcombination, two principal questions need addressed empirical experimentation:results improved relative using model alone?methods competitive alternative regression methods?7. ResultsExperiments conducted assess competitiveness rule-based regression comparedprocedures (including less interpretable ones), well evaluate performance integrated partition k-nn regression method. Experiments performedusing seven datasets, six described previous studies (Quinlan, 1993). addition six datasets, new experiments done large telecommunicationsapplication, labeled pole. seven datasets, one continuousreal-valued response variable. Experimental results reported terms MAD,measured using 10-fold cross-validation. pole, 5,000 cases used training10,000 independent testing. features different datasets mixturecontinuous categorical features. pole, 48 features continuous. Descriptions395fiWeiss & IndurkhyaDataset Cases Varspriceservocpumpgpeptidehousingpole1591672093924315061500016196131281348Table 1: Dataset Characteristicsdatasets found literature (Quinlan, 1993).4 Table 1 summarizeskey characteristics datasets used study.Table 2 summarizes original results reported (Quinlan, 1993). include modeltrees (MT), regression trees linear fits terminal nodes; neural nets(NNET); 3-nearest neighbors (3-nn); combined results model-trees 3-nearestneighbors (MT/3-nn).5Table 3 summarizes additional results obtained. include CARTregression tree (RT); 5-nearest neighbors euclidean distance (5-nn); rule regressionusing Swap-1; rule regression 5-nn applied rule region (Rule/5-nn); MARS.5-nn used expectation nearest neighbor method incrementallyimproves constant-value region region moderately large sample neighborsaverage.rule-based method, parameter m, number pseudo-classes, mustdetermined. found using cross-validation independent test cases (inexperiments, cross-validation used). Figure 6 represents typical plot relativeerror vs. number pseudo-classes (Weiss & Indurkhya, 1993b). numberpartitions increases, results improve reach relative plateau deterioratesomewhat. Similar complexity plots found models, example neural nets(Weiss & Kapouleas, 1989).MARS procedure several adjustable parameters.6 parameter mi, valuestried 1 (additive modeling), 2, 3, 4 number inputs. df, default value3.0 tried well optimal value estimated cross-validation. parameter nkvaried 20 100 steps 10. Lastly, piece-wise linear well piece-wise cubicsolutions tried. setting parameters, cross-validatedaccuracy monitored, value best MARS model reported.method, besides MAD, relative error also reported. relativeerror simply estimated true mean absolute distance (measured cross-validation)normalized initial mean absolute distance median. Analogous classifi4. peptide dataset slightly modified version one Quinlan refers lhrh-att paper.version used experiments, cases missing values removed.5. peptide slightly modified version lhrh-att dataset, result listed oneprovided Quinlan personal communication.6. particular program used MARS 3.5.396fiRule-based Functional PredictionRelative Error0.650.60.550.50.450.40.350.3234567Number Pseudo-Classes8910Figure 6: Prototypical Performance Varying Pseudo-ClassesDataset MT NNET 3-nn MT/3-nnprice 1562servo.45cpu28.9mpg2.11peptide .95housing 2.451833.3028.72.022.291689.5234.02.722.901386.3028.12.182.32Table 2: Previous Resultscation, predictions must fewer errors simply predicting largest class,regression must better average distance medianmeaningful results.comparing performance two methods dataset, standard errormethod independently estimated, larger one used comparisons.difference performance greater 2 standard errors, differenceconsidered statistically significant. significance test, one must also consideroverall pattern performance relative advantages competing solutions (Weiss& Indurkhya, 1994).dataset, Figure 7 plots relative best error found ratio bestreported result model's result. relative best error 1 indicates resultbest reported result regression model. model results comparedbest results regression rules, 5-nn, mixed model. graph indicates397fiWeiss & IndurkhyaDatasetRT5-nnRuleRule/5-nnMARSMAD Error MAD Error MAD Error MAD Error MAD Errorprice1660 .40 1643 .40 1335 .32 1306 .31 1559 .38servo.195 .21 .582 .63 .235 .25 .227 .24 .212 .23cpu30.5 .39 29.4 .38 27.62 .35 26.32 .34 27.29 .35mpg2.28 .35 2.14 .33 2.17 .33 2.04 .31 1.94 .30peptide .97.46.95.45.86.40.86.40.98.46housing 2.74 .42 2.77 .42 2.51 .38 2.35 .36 2.24 .34pole4.10 .14 5.91 .20 3.76 .13 3.70 .12 7.41 .25Table 3: Performance Additional MethodsRelative Best Erate1.25-nnrule1rule/5-nn0.80.60.40.20servohousempgcpupricepeptidepoleFigure 7: Relative Best Erates 5-nn, Rules, Rule/5-nntrends across datasets helps assess overall pattern performance. respect,Rule Rule/5nn exhibit excellent performance across many applications.empirical results allow us consider several relevant questions regarding rulebased regression:1. rule-based regression perform compared tree-based regression? Comparingresults Rule RT, one see except servo, Rule consistentlybetter RT remaining six datasets. difference performance also398fiRule-based Functional Predictiontests significant. results significance tests, general trend (whichseen visually Figure 7) leads us conclude rule-based regressiondefinitely competitive trees often yields superior performance.2. integrating 5nn rules lead improved performance relative usingmodel alone? comparison Rule/5nn 5nn shows datasets, Rule/5nnsignificantly better. comparing Rule/5nn Rule, results indicatethree datasets (mpg, pole housing), Rule/5nn significantly better Rule,remaining three datasets same. overall patternperformance also appears favor Rule/5nn Rule. Thus empirical resultsindicate method improved results relative using model alone.general trend seen Figure 7.3. new methods competitive alternative regression methods? Among previous reported results, MT/3nn best performer. alternatives considerare: Regression Trees (RT) MARS. None three methods significantlybetter Rule/5nn datasets consideration except RTsignificantly better servo. Furthermore, Rule/5nn significantly betterMT/3nn three five datasets (servo, cpu mpg) comparison possible. overall trend also favor Rule/5nn. Comparing RT Rule/5nn,find except servo, Rule/5nn significantly better RT remaining datasets. Comparing MARS Rule/5nn, find three datasets(price, peptide pole), Rule/5nn significantly better. Hence empirical results overwhelmingly suggest new method competitive alternativeregression methods, hints superiority methods.8. Discussionconsidered new model rule-based regression provided comparisonstree-based regression. many applications, strong explanatory capabilities high dimensional feature selection make DNF model quite advantageous. particularlytrue knowledge-based applications, example equipment repair medical diagnosis,contrast pure pattern recognition applications speech recognition.rules similar trees, rule representation potentially compactrules mutually exclusive. potential finding compactsolution particularly important problems model interpretation crucial.Note space rules includes space trees. Thus, tree solutionbest, theoretically rule induction procedure potential find it.experiments, regression rules generally outperformed regression trees.Fewer constant regions required estimated error rates generally lower.Finding DNF regions substantially computationally expensive regression rules regression trees. regression rules, fairly complex optimizationtechniques necessary. addition, experiments must performed find appropriate number pseudo-classes. matter scale: scale applicationversus scale available computing. Excluding telecommunications application,none cited applications takes 15 minutes cpu time SS-20 sin399fiWeiss & Indurkhyagle pseudo-classification problem full cross-validation.7 computing power increasestiming distinction less important. Even small percentage gain quite valuable appropriate application (Apte, Damerau, & Weiss, 1994) computationalrequirements secondary factor.provided results several real-world datasets. Mostly, involve nonlinear relationships. One may wonder rule-based method would perform dataobvious linear relationships. earlier experiments data exhibiting linearrelationships (for example, drug study data (Efron, 1988)), rule-based solutionsslightly better trees. However, true test real-world data which, often involvecomplex non-linear relationships. Comparisons alternative models help assesseffectiveness new techniques.Looking Figure 7 Tables 2 3, see pure rule-based solutionscompetitive models. Additional gains made rules usedobtaining function values directly, instead used find relevant casesused compute function value. results experiments supportview strategy combining different methods improve predictive performance.Strategies similar applied classification problems (Ting, 1994;Widmer, 1993) similar conclusions drawn results. results indicatestrategy useful regression context too. empirical results also supportcontention regression, partitioning methods nearest neighbor methodscomplementary. solution found partitioning alone, incrementalimprovement observed substituting average k-nearest neighborsmedian partition. perspective nearest neighbor regression methods,sample cases compartmentalized, simplifying table lookup new case.conclusive, hints combination strategy effectivesmall moderate samples: likely sample size grows large, increasednumbers partitions, terms rules terminal nodes, compensate singleconstant-valued regions. conjecture supported large-sample pole application,incremental gain addition k-nn small.8experiments used k-nn k=5. Depending application, differentvalue k might produce better results. optimal value might estimated crossvalidation strategy systematically varies k picks value gives bestresults overall. However, unclear whether increased computational effort resultsignificant performance gain.Another practical issue large samples storage requirement: cases muststored. serious drawback real-world applications limited memory.However, tried experiments cases associated partition replacedfewer number \typical cases". results considerable savings terms storagerequirements. Results slightly weaker (though significantly different).would appear gains might obtained restricting k-nn considerfeatures appear path leaf node examination. mightseem like good idea attempts ensure features relevant7. 10-fold cross-validation requires solving problem essentially 11 times: training cases10 times group test cases.8. Although small, difference tests significant sample large.400fiRule-based Functional Predictioncases node, used distance calculations. However, found resultsweaker.number regression techniques presented others demonstrateadvantages combined models. combine methods independentlyinvoked. Instead typical election one winner, alternative modelscombined weighted. combination techniques advantageoutputs different models treated independent variables. combinedform post-processing, model outputs available.way contradict value alternative combination techniques.approaches show improved results various applications. conclude, however,advantages complex regression procedures dynamically mixalternative models. procedures may particularly strong fundamental rationale choice methods partitioning methods, propertiescombined models must preserved.presented regression problem one output variable. classical form linear models regression trees. issue multiple outputsdirectly addressed although extensions feasible. issue experimentation await future work. model regression provide basis efforts,leveraging current strong methods classification rule induction.ReferencesApte, C., Damerau, F., & Weiss, S. (1994). Automated Learning Decison Rules TextCategorization. ACM Transactions Oce Information Systems, 12 (3), 233{251.Breiman, L. (1993). Stacked regression. Tech. rep., U. CA. Berkeley.Breiman, L., Friedman, J., Olshen, R., & Stone, C. (1984). Classification RegressionTress. Wadsworth, Monterrey, Ca.Clark, P., & Niblett, T. (1989). CN2 induction algorithm. Machine Learning, 3,261{283.Craven, P., & Wahba, G. (1979). Smoothing noisy data spline functions. estimatingcorrect degree smoothing method generalized cross-validation. Numer.Math., 31, 317{403.Efron, B. (1988). Computer-intensive methods statistical regression. SIAM Review,30 (3), 421{449.Fayyad, U., & Irani, K. (1992). attribute selection problem decision tree generation.Proceedings AAAI-92, pp. 104{110 San Jose.Friedman, J. (1991). Multivariate adaptive regression splines. Annals Statistics, 19 (1),1{141.Friedman, J., & Stuetzle, W. (1981). Projection pursuit regression. J. Amer. Stat. Assoc.,76, 817{823.401fiWeiss & IndurkhyaGirosi, F., & Poggio, T. (1990). Networks best approximation property. BiologicalCybernetics, 63, 169{176.Hartigan, J., & Wong, M. (1979). k-means clustering algorithm, ALGORITHM 136.Applied Statistics, 28 (1).Hastie, T., & Tibshirani, R. (1990). Generalized Additive Models. Chapman Hall.Jacoby, S., Kowalik, J., & Pizzo, J. (1972). Iterative Methods Non-linear OptimizationProblems. Prentice-Hall, New Jersey.Kirpatrick, S., Gelatt, C., & Vecchi, M. (1983). Optimization simulated annealing.Science, 220, 671.LeBlanc, M., & Tibshirani, R. (1993). Combining estimates regression classification.Tech. rep., Department Statistics, U. Toronto.Lebowitz, M. (1985). Categorizing numeric information generalization. Cognitive Science, 9, 285{308.Lin, S., & Kernighan, B. (1973). ecient heuristic traveling salesman problem.Operations Research, 21 (2), 498{516.McClelland, J., & Rumelhart, D. (1988). Explorations Parallel Distributed Processing.MIT Press, Cambridge, Ma.Michalski, R., Mozetic, I., Hong, J., & Lavrac, N. (1986). multi-purpose incremental learning system AQ15 testing application three medical domains.Proceedings AAAI-86, pp. 1041{1045 Philadelphia, Pa.Quinlan, J. (1986). Induction decision trees. Machine Learning, 1, 81{106.Quinlan, J. (1987). Simplifying decision trees. International Journal Man-MachineStudies, 27, 221{234.Quinlan, J. (1993). Combining instance-based model-based learning. InternationalConference Machine Learning, pp. 236{243.Ripley, B. (1993). Statistical aspects neural networks. Proceedings Seminair Europeen de Statistique London. Chapman Hall.Scheffe, H. (1959). Analysis Variance. Wiley, New York.Ting, K. (1994). problem small disjuncts: remedy decision trees. Proceedings10th Canadian Conference Artificial Intelligence, pp. 91{97.Weiss, S., & Indurkhya, N. (1993a). Optimized Rule Induction. IEEE Expert, 8 (6), 61{69.Weiss, S., & Indurkhya, N. (1993b). Rule-based regression. Proceedings 13thInternational Joint Conference Artificial Intelligence, pp. 1072{1078.402fiRule-based Functional PredictionWeiss, S., & Indurkhya, N. (1994). Decision tree pruning: Biased optimal?. ProceedingsAAAI-94, pp. 626{632.Weiss, S., & Kapouleas, I. (1989). empirical comparison pattern recognition, neuralnets, machine learning classification methods. International Joint ConferenceArtificial Intelligence, pp. 781{787 Detroit, Michigan.Weiss, S., & Kulikowski, C. (1991). Computer Systems Learn: Classification Prediction Methods Statistics, Neural Nets, Machine Learning, Expert Systems.Morgan Kaufmann.Widmer, G. (1993). Combining knowledge-based instance-based learning exploitqualitative knowledge. Informatica, 17, 371{385.Wolpert, D. (1992). Stacked generalization. Neural Networks, 5, 241{259.403fiJournal Artificial Intelligence Research 3 (1995) 1-24Submitted 1/95; published 6/95Induction First-Order Decision Lists:Results Learning Past Tense English VerbsRaymond J. MooneyMary Elaine CaliffDepartment Computer Sciences, University TexasAustin, TX 78712-1188mooney@cs.utexas.edumecaliff@cs.utexas.eduAbstractpaper presents method inducing logic programs examples learnsnew class concepts called first-order decision lists, defined ordered lists clausesending cut. method, called Foidl, based Foil (Quinlan, 1990)employs intensional background knowledge avoids need explicit negative examples. particularly useful problems involve rules specific exceptions,learning past-tense English verbs, task widely studied contextsymbolic/connectionist debate. Foidl able learn concise, accurate programsproblem significantly fewer examples previous methods (both connectionistsymbolic).1. IntroductionInductive logic programming (ILP) growing subtopic machine learning studiesinduction Prolog programs examples presence background knowledge(Muggleton, 1992; Lavrac & Dzeroski, 1994). Due expressiveness first-order logic,ILP methods learn relational recursive concepts cannot representedattribute/value representations assumed machine-learning algorithms. ILP methods successfully induced small programs sorting list manipulation (Shapiro,1983; Sammut & Banerji, 1986; Muggleton & Buntine, 1988; Quinlan & Cameron-Jones,1993) well produced encouraging results important applications predicting protein secondary structure (Muggleton, King, & Sternberg, 1992) automatingconstruction natural-language parsers (Zelle & Mooney, 1994b).However, current ILP techniques make important assumptions restrict application. three common assumptions:1. Background knowledge provided extensional form set ground literals.2. Explicit negative examples target predicate available.3. target program expressed \pure" Prolog clause-order irrelevantprocedural operators cut (!) disallowed.currently well-known successful ILP systems, Golem (Muggleton & Feng,1990) Foil (Quinlan, 1990), make three assumptions. However,assumptions brings significant limitations since:1. adequate extensional representation background knowledge frequently infiniteintractably large.c 1995 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiMooney & Califf2. Explicit negative examples frequently unavailable adequate set negativeexamples computed using closed-world assumption infinite intractably large.3. Concise representation many concepts requires use clause-ordering and/orcuts (Bergadano, Gunetti, & Trinchero, 1993).paper presents new ILP method called Foidl (First-Order Induction Decision Lists) helps overcome limitations incorporating followingproperties:1. Background knowledge represented intensionally logic program.2. explicit negative examples need supplied constructed. assumptionoutput completeness used instead implicitly determine hypothesizedclause overly-general and, so, quantify degree over-generality simplyestimating number negative examples covered.3. learned program represented first-order decision list, ordered setclauses ending cut. representation useful problemsbest represented general rules specific exceptions.name implies, Foidl closely related Foil follows similar top-down,greedy specialization guided information-gain heuristic. However, algorithmsubstantially modified address three advantages listed above. use intensionalbackground knowledge fairly straightforward incorporated previous Foilderivatives (Lavrac & Dzeroski, 1994; Pazzani & Kibler, 1992; Zelle & Mooney, 1994b),development Foidl motivated failure observed applying existing ILP methods particular problem, learning past tense Englishverbs. problem studied fairly extensively using connectionist symbolic methods (Rumelhart & McClelland, 1986; MacWhinney & Leinbach, 1991; Ling,1994); however, previous efforts used specially-designed feature-based encodings impose fixed limit length words fail capture position-independenceunderlying transformation. believed representing problem constructing logic program predicate past(X,Y) X words representedlists letters (e.g past([a,c,t], [a,c,t,e,d]), past([a,c,h,e], [a,c,h,e,d]),past([a,r,i,s,e], [a,r,o,s,e])) would produce much better results. However, duelimitations mentioned above, unable get reasonable results either FoilGolem. However, overcoming limitations, Foidl able learn highly accurate programs past-tense problem many fewer examples requiredprevious methods.remainder paper organized follows. Section 2 provides important background material Foil past-tense learning problem. Section 3 presentsFoidl algorithm details incorporates three advantages discussed above. Section 4 presents results learning past-tense English verbs demonstratingFoidl out-performs previous methods problem. Section 5 reviews related work,Section 6 discusses limitations future directions, Section 7 summarizes presentsconclusions.2fiInduction First-Order Decision Lists: Learning English Past Tense2. BackgroundSince Foidl based Foil, section presents brief review important ILP system; Quinlan (1990), Quinlan Cameron-Jones (1993), Cameron-Jones Quinlan(1994) provide complete description. section also presents brief reviewprevious work English past tense problem.2.1 FOILFoil learns function-free, first-order, Horn-clause definition target predicate termsbackground predicates. input consists extensional definitionspredicates tuples constants specified types. example, input appropriatelearning definition list membership is:member(Elt,Lst): { <a,[a]>, <a,[a,b]>, <b,[a,b]>, <a,[a,b,c]>, ...}components(Lst,Elt,Lst): { <[a],a,[]>, <[a,b],a,[b]>, <[a,b,c],a,[b,c]> ...}Elt type denoting possible elements includes a,b,c, d; Lsttype defined consisting lists containing three elements;components(A,B,C) background predicate true iff list whose first element B whose rest list C (this must provided place functionlist construction). Foil also requires negative examples target concept,supplied directly computed using closed-world assumption. example,closed-world assumption would produce pairs form <Elt,Lst> explicitly provided positive examples (e.g., <b,[a]>).Given input, Foil learns program one clause time using greedy-coveringalgorithm summarized follows:Let positives-to-cover = positive examples.positives-to-cover emptyFind clause, C , covers preferably large subset positives-to-covercovers negative examples.Add C developing definition.Remove examples covered C positives-to-cover.example, clause might learned member one iteration loop is:member(A,B) :- components(B,A,C).since covers positive examples element first one listcover negatives. clause could learned cover remaining examples is:member(A,B) :- components(B,C,D), member(A,D).Together two clauses constitute correct program member.\find clause" step implemented general-to-specific hill-climbing searchadds antecedents developing clause one time. step, evaluates possibleliterals might added selects one maximizes information-gain heuristic.algorithm maintains set tuples satisfy current clause includes bindingsnew variables introduced body. following pseudocode summarizesprocedure:3fiMooney & CaliffInitialize C R(V1; V2; :::; Vk) :-. R target predicate arity k.Initialize contain positive tuples positives-to-cover negative tuples.contains negative tuplesFind best literal L add clause.Form new training set containing tuple satisfies L,tuples form b (t b concatenated) b set bindingsnew variables introduced L literal satisfied(i.e., matches tuple extensional definition predicate).Replace .Foil considers adding literals possible variablizations predicate longtype restrictions satisfied least one arguments existing variablebound head previous literal body. Literals evaluated basednumber positive negative tuples covered, preferring literals cover many positivesnegatives. Let T+ denote number positive tuples set define:(T ) = , log2 (T+ =jT j):(1)chosen literal one maximizes:gain(L) = (I (T ) , (T ));(2)number tuples extensions (i.e., number currentpositive tuples covered L).Foil also includes many additional features as: heuristics pruning spaceliterals searched, methods including equality, negation failure, useful literalsimmediately provide gain (determinate literals), pre-pruning post-pruningclauses prevent over-fitting, methods ensuring induced programsterminate. papers referenced consulted detailsfeatures.00002.2 Learning Past Tense English VerbsRumelhart McClelland (1986) first build computational model pasttense learning using classic perceptron algorithm special phonemic encodingwords employing so-called Wickelphones Wickelfeatures. general goal showconnectionist models could account interesting language-learning behaviorpreviously thought require explicit rules. model heavily criticized opponentsconnectionist approach language acquisition relatively poor results achievedheavily-engineered representations training techniques employed (Pinker &Prince, 1988; Lachter & Bever, 1988). MacWhinney Leinbach (1991) attemptedaddress criticisms using standard multi-layer backpropagation learningalgorithm simpler UNIBET encoding phonemes (in 36 phonemesencoded single ASCII character).Ling Marinov (1993) Ling (1994) criticize current connectionist models past-tense acquisition heavily-engineered representations poor experimentalmethodology. present systematic results system called SPA (Symbolic Pattern Associator) uses slightly modified version C4.5 (Quinlan, 1993) build4fiInduction First-Order Decision Lists: Learning English Past Tenseforest decision trees maps fixed-length input pattern fixed-length output pattern. Ling's (1994) head-to-head results show SPA generalizes significantly betterbackpropagation number variations problem employing different phonemicencodings (e.g., 76% vs. 56% given 500 training examples).However, previous work encodes problem fixed-length pattern association fails capture generativity position-independence true transformation. example, use 15-letter patterns like:a,c,t,_,_,_,_,_,_,_,_,_,_,_,_ => a,c,t,e,d,_,_,_,_,_,_,_,_,_,_UNIBET phonemic encoding:&,k,t,_,_,_,_,_,_,_,_,_,_,_,_ => &,k,t,I,d,_,_,_,_,_,_,_,_,_,_separate decision tree output unit used predict character outputpattern input characters. Therefore, learning general rules, \add`ed'," must repeated position word end, words longer 15characters cannot handled. Also, best results SPA exploit highly-engineeredfeature template modified version C4.5's default leaf-labeling strategy tailorstring transformation problems.Although ILP methods seem appropriate problem, initial attemptsapply Foil Golem past-tense learning gave disappointing results (Califf,1994). Below, discuss three problems listed introduction contributediculty applying current ILP methods problem.principle, background predicate append sucient constructing accuratepast-tense programs incorporated ability include constants argumentsor, equivalently, ability add literals bind variables specific constants (calledtheory constants Foil). However, background predicate allow appendingempty list appropriate. use predicate called split(A, B, C)splits list two non-empty sublists B C. intensional definition split is:split([X, | Z], [X] , [Y | Z]).split([X | Y], [X | W], Z) :- split(Y,W,Z).Using split, \add `ed"' rule represented as:past(A,B) :- split(B,A,[e,d]).which, Foil, learned form:past(A,B) :- split(B,A,C), C = [e,d].Providing extensional definition split includes possible strings 15 fewercharacters (at least 1021 strings) clearly intractable. However, providing partial definition includes possible splits strings actually appear training corpuspossible generally sucient. Therefore, providing adequate extensional backgroundknowledge cumbersome requires careful engineering; however, majorproblem.Supplying appropriate set negative examples problematic. Using closedworld assumption produce pairs words training set secondpast-tense first feasible useful. case, clause:5fiMooney & Califfpast(A,B) :- split(B,A,C).likely learned since covers positives (if any)negatives since unlikely word prefix another word pasttense. However, clause useless producing past tense novel verbs, and,domain, accuracy must measured ability actually generate correct outputnovel inputs, rather ability classify pre-supplied tuples arguments positivenegative. obvious solution supplying strings 15 characters lessnegative examples past tense word clearly intractable. Providing speciallyconstructed \near-miss" negative examples past([a,c,h,e],[a,c,h,e,e,d]),helpful, requires careful engineering exploits detailed prior knowledgeproblem.order address problem negative examples, Quinlan (1994) appliedFoil problem, employed different target predicate representing pasttense transformation.1 used three-place predicate past(X,Y,Z) true iffinput word X transformed past-tense form removing current endingsubstituting ending Z; example: past([a,c,t], [], [e,d]), past([a,r,i,s,e],[i,s,e], [o,s,e]). simple preprocessor map data two-place predicateform. Since sample 500 verb pairs contains 30-40 different end fragments,results manageable number closed-world negatives, approximately 1000every positive example training set. Using approach UNIBET phonemicencodings, Quinlan obtained slightly better results Ling's best SPA results exploited highly-engineered feature template (83.3% vs. 82.8% 500 training examples)significantly better SPA's normal results (76.3%). Although three-place target predicate incorporates knowledge desired transformation, arguablyrequires less representation engineering previous methods.However, Quinlan (1994) notes results still hampered Foil's inabilityexploit clause order. example, using normal alphabetic encoding, Foil quicklylearns clause sucient regular verbs:past(A,B,C) :- B=[], C=[e,d].However, since clause still covers fair number negative examples due manyirregular verbs, continues add literals. result, Foil creates number specializedversions clause together still fail capture generality underlyingdefault rule. problem compounded Foil's inability add constraints\does end `e'." Since Foil separates addition literals containing variablesbinding variables constants using literals form V = c, cannot learn clauseslike:past(A,B,C) :- B=[], C=[e,d], not(split(A,D,[e])).Since word split several ways, clearly equivalent learnableclause:past(A,B,C) :- B=[], C=[e,d], not(split(A,D,E)), E /= [e].1. Quinlan's work problem motivated early attempts use Foil.6fiInduction First-Order Decision Lists: Learning English Past TenseConsequently, must approximate true rule learning many clauses form:past(A,B,C) :- B=[], C=[e,d], split(A,D,E), E = [b].past(A,B,C) :- B=[], C=[e,d], split(A,D,E), E = [d]....result, Foil generated overly-complex programs containing 40 clausesphonemic alphabetic versions problem.However, experienced Prolog programmer would exploit clause order cutswrite concise program first handles most-specific exceptions fallsmore-general default rules exceptions fail apply. example, program:past(A,B)past(A,B)past(A,B)past(A,B)::::-split(A,C,[e,e,p]), split(B,C,[e,p,t]), !.split(A,C,[y]), split(B,C,[i,e,d]), !.split(A,C,[e]), split(B,A,[d]), !.split(B,A,[e,d]).summarized as:word ends \eep," replace \eep" \ept" (e.g., sleep, slept),else, word ends \y," replace \y" \ied"else, word ends \e," add \d"else, add \ed."Foidl directly learn programs form, i.e., ordered sets clauses endingcut. call programs first-order decision lists due similarity propositionaldecision lists introduced Rivest (1987). Foidl uses normal binary target predicaterequires explicit negative examples. Therefore, believe requires significantlyless representation engineering previous work area.3. FOIDL Induction Algorithmstated introduction, Foidl adds three major features Foil: 1) Intensionalspecification background knowledge, 2) Output completeness substitute explicitnegative examples, 3) Support learning first-order decision lists. followingsubsections describe modifications made incorporate features.3.1 Intensional Backgrounddescribed above, Foil assumes background predicates provided extensionaldefinitions; however, burdensome frequently intractable. Providing intensional definition form general Prolog clauses generally preferable. example,instead providing numerous tuples components predicates, easier giveintensional definition:components([A | B], A, B).Intentional background definitions restricted function-free pure Prologexploit features language.7fiMooney & CaliffModifying Foil use intensional background straightforward. Instead matchingliteral set tuples determine whether covers example,Prolog interpreter used attempt prove literal satisfied usingintensional definitions. Unlike Foil, expanded tuples maintained positivenegative examples target concept reproved alternative specializationdeveloping clause. Therefore, pseudocode learning clause simply:Initialize C R(V1; V2; :::; Vk) :-. R target predicate arity k.Initialize contain examples positives-to-cover negative examples.contains negative tuplesFind best literal L add clause.Let subset examples still proved instancestarget concept using specialized clause.ReplaceSince expanded tuples produced, information-gain heuristic picking bestliteral simply:gain(L) = jT j (I (T ) , (T )):(3)00003.2 Output Completeness Implicit Negativesorder overcome need explicit negative examples, mode declarationtarget concept must provided (i.e., specification whether argument input (+)output (-)). assumption output completeness made, indicatingevery unique input pattern training set, training set includes correctoutput patterns. Therefore, output program produces given inputassumed represent negative example. require positiveexamples part training set, unique input pattern trainingset, positive examples input pattern (if any) must also trainingset. assumption trivially met predicate represents function singleunique output input.example, assumption output completeness mode declaration past(+,-)indicates correct past-tense forms included input wordtraining set. predicates representing functions, past, impliesoutput example unique outputs implicitly represent negative examples. However, output completeness also applied non-functional casesappend(-,-,+), indicating possible pairs lists appendedtogether produce list included training set (e.g., append([],[a,b],[a,b]),append([a],[b],[a,b]), append([a,b],[],[a,b])).Given output completeness assumption, determining clause overly-generalstraightforward. positive example, output query made determineoutputs given input (e.g., past([a,c,t], X)). outputs generatedpositive examples, clause still covers negative examples requiresspecialization. Note intensional interpretation learned clauses required orderanswer output queries.addition, order compute gain alternative literals specialization,negative coverage clause needs quantified. incorrect answer output8fiInduction First-Order Decision Lists: Learning English Past Tensequery ground (i.e., contains variables) clearly counts single negative example (e.g., past([a,c,h,e], [a,c,h,e,e,d])). However, output queries frequentlyproduce answers universally quantified variables. example, given overly-generalclause past(A,B) :- split(A,C,D)., query past([a,c,t], X) generates answerpast([a,c,t], Y). implicitly represents coverage infinite number negativeexamples. order quantify negative coverage, Foidl uses parameter u representbound number possible terms. Since set possible terms (the Herbranduniverse background knowledge together examples) generally infinite, umeant represent heuristic estimate finite number terms everactually occur practice (e.g., number distinct words English). negative coverage represented non-ground answer output query estimated uv , p,v number variable arguments answer p number positiveexamples answer unifies. uv term stands number uniqueground outputs represented answer (e.g., answer append(X,Y,[a,b]) stands2u different ground outputs) p term stands number representpositive examples. allows Foidl quantify coverage large numbers implicitnegative examples without ever explicitly constructing them. generally sucientestimate u fairly large constant (e.g., 1000), empirically methodsensitive exact value long significantly greater number groundoutputs ever generated clause.Unfortunately, estimate sensitive enough. example, clausespast(A,B) :- split(A,C,D).past(A,B) :- split(B,A,C).cover u implicit negative examples output query past([a,c,t], X) since firstproduces answer past([a,c,t], Y) second produces answer past([a,c,t],[a,c,t | Y]). However, second clause clearly better since least requires output input sux added. Since presumably wordswords start \a-c-t" (assuming total number words finite),first clause considered cover negative examples. Therefore, argumentspartially instantiated, [a,c,t | Y], counted fractionvariable calculating v . Specifically, partially instantiated output argument scoredfraction subterms variables, e.g., [a,c,t | Y] counts 1=4variable argument. Therefore, first clause scored covering u implicit negatives second covering u1=4. Given reasonable values u numberpositives covered clause, literal split(B,A,C) preferred.revised specialization algorithm incorporates implicit negatives is:Initialize C R(V1; V2; :::; Vk) :-. R target predicate arity k.Initialize contain examples positives-to-cover output queriespositive examples.contains output queriesFind best literal L add clause.Let subset positive examples still proved instancestarget concept using specialized clause, plus output queries09fiMooney & Califfstill produce incorrect answers.Replace .0Literals scored described previous section except jT j computednumber positive examples plus sum number implicit negatives coveredoutput query .3.3 First-Order Decision Listsdescribed above, first-order decision lists ordered sets clauses endingcut. answering output query, cuts simply eliminate first answerproduced trying clauses order. Therefore, representation similarpropositional decision lists (Rivest, 1987), ordered lists pairs (rules)form (ti ; ci) test ti conjunction features ci category labelexample assigned category first pair whose test satisfies.original algorithm Rivest (1987) CN2 (Clark & Niblett, 1989), ruleslearned order appear final decision list (i.e., new rules appendedend list learned). However, Webb Brkic (1993) argue learningdecision lists reverse order since preference functions tend learn generalrules first, best positioned default cases towards end. introducealgorithm, prepend, learns decision lists reverse order present results indicatingcases learns simpler decision lists superior predictive accuracy. Foidlseen generalizing prepend first-order case target predicates representingfunctions. learns ordered sequence clauses reverse order, resulting programproduces first output generated first satisfied clause.basic operation algorithm best illustrated concrete example.alphabetic past-tense, current algorithm easily learns partial clause:past(A,B) :- split(B,A,C), C = [e,d].However, discussed section 2.2, clause still covers negative examples due irregular verbs. However, produces correct ground output subset examples (i.e.,regular verbs).2 indication best terminate clause handleexamples, add earlier clauses decision list handle remaining examples.fact produces incorrect answers output queries safely ignoreddecision-list framework since handled earlier clauses. Therefore,examples correctly covered clause removed positives-to-cover newclause begun. literals provide best gain are:past(A,B) :- split(B,A,C), C = [d].since many irregulars add \d" (since end \e"). clausealso produces correct ground output subset examples; however,complete since produces incorrect output examples correctly covered previouslylearned clause (e.g., past([a,c,t], [a,c,t,d])). Therefore, specialization continuescases also eliminated. results clause:2. Note untrue literals added initially empty clause.10fiInduction First-Order Decision Lists: Learning English Past Tensepast(A,B) :- split(B,A,C), C = [d], split(A,D,E), E = [e].added front decision list examples covers removedpositives-to-cover. approach ensures every new clause produces correct outputsnew subset examples doesn't result incorrect output examples alreadycorrectly covered previously learned clauses. process continues adding clausesfront decision list exceptions handled positives-to-coverempty.resulting clause-specialization algorithm summarized follows:Initialize C R(V1; V2; :::; Vk) :-. R target predicate arity k.Initialize contain examples positives-to-cover output queriespositive examples.contains output queriesFind best literal L add clause.Let subset positive examples whose output query still producesfirst answer unifies correct answer, plus output querieseither1) Produce non-ground first answer unifies correct answer,2) Produce incorrect answer produce correct answer usingpreviously learned clause.Replace .00many cases, algorithm able learn accurate, compact, first-order decision listspast tense, like \expert" program shown section 2.2. However, due highly irregular verbs, algorithm encounter local-minima unable find literalsprovide positive gain still covering required minimum number examples.3originally handled terminating search memorizing remaining uncovered examples specific exceptions top decision list (e.g., past([a,r,i,s,e],[a,r,o,s,e]) :- !.). However, result premature termination preventsalgorithm finding low-frequency regularities. example, alphabetic version, system get stuck trying learn complex rule double finalconsonant (e.g., grab ! grabbed) fail learn rule changing \y" \ied" sinceactually less frequent.current version, like Foil, tests learned clause meets minimum-accuracythreshold; however, unlike Foil, counting errors incorrect outputs queries correctly answered previously learned clauses. meet threshold, clausethrown positive examples covers memorized top decisionlist. algorithm continues learn clauses remaining positive examples.allows Foidl memorize dicult irregularities, consonant doubling,still continue learn rules changing \y" \ied."minimum-accuracy threshold met, decision-list property exploitedfinal attempt still learn completely accurate program. negatives coveredclause examples correctly covered previously learned clauses, Foidl3. Like Foil, Foidl includes parameter minimum number examples clause must cover(normally set 2).11fiMooney & Califftreats \exceptions exception rule" returns positives-tocover covered correctly subsequently learned clauses. example, Foidlfrequently learns clause:past(A, B) :- split(A, C, [y]), split(B, C, [i, e, d]).changing \y" \ied." However, clause incorrectly covers examplescorrectly covered previously learned \add `ed"' rule (e.g., bay ! bayed; delay !delayed). Since exceptions \y" \ied" rule small percentage wordsend \y," system keeps rule returns examples add \ed"positives-to-cover. Subsequently, rules as:past(A, B) :- split(B, A, [e, d]), split(A, D, [a, y]).learned recover examples, resulting program completely consistenttraining data. setting minimum clause-accuracy threshold 50%, Foidlapplies uncovering technique results covering examplesuncovers, thereby guaranteeing progress towards fitting training examples.3.4 Algorithmic Implementation Detailssection brie discusses additional details Foidl algorithm implementation. includes discussion use modes, types, weak literals, theoryconstants. current version Foil includes features basicallyform.Foidl makes use types modes limit space literals searched. argument predicate typed literals whose previously-bound argumentscorrect type tested specializing clause. example, split giventypes split(word,prefix,suffix), preventing system splitting prefixessuxes exploring arbitrary substrings word regularities. predicatealso given mode declaration, literals whose input arguments previouslybound variables tested. example, split given mode split(+,-,-), preventingclause creating new strings appending together previously generated prefixessuxes.case literal provides positive information gain, Foidl gives small bonus literalsintroduce new variables. However, number weak literals addedrow limited user parameter (normally set 1). example, allowssystem split word possible prefixes suxes, even though may providegain substrings constrained subsequent literals.Theory constants provided type, literals tested bindingexisting variable constant appropriate type. example, literal X=[e,d]generated X type suffix. runs past-tense, theory constants includedevery prefix sux occurs least two words training data. helpscontrol training time limiting number literals searched, affectliterals actually chosen since minimum-clause-coverage test prevents Foidlchoosing literals don't cover least two examples anyway.12fiInduction First-Order Decision Lists: Learning English Past TenseFoidl currently implemented Common Lisp Quintus Prolog. Unlikecurrent Prolog version, Common Lisp version supports learning recursive clauses4output-completeness non-functional target predicates. However, Common Lispversion significantly slower since relies un-optimized Prolog interpretercompiler written Lisp (from Norvig, 1992). Consequently, presented resultsProlog version running Sun SPARCstation 2.54. Experimental Resultstest Foidl's performance English past tense task, ran experiments usingdata Ling (1994) made available appendix.4.1 Experimental Designdata used consist 6939 English verb forms normal alphabetic formUNIBET phoneme representation along label indicating verb form (base, pasttense, past participle, etc), label indicating whether form regular irregular,Francis-Kucera frequency verb. data include 1390 distinct pairs basepast tense verb forms. ran three different experiments. one used phoneticforms verbs. second used phonetic forms regular verbs only,easiest form task problemLing provides learning curves. Finally, ran trials using alphabetic forms verbs.training testing followed standard paradigm splitting data testingtraining sets training progressively larger samples training set. resultsaveraged 10 trials, testing set trial contained 500 verbs.order better separate contribution using implicit negatives contribution decision list representation, also ran experiments IFoil, variantsystem uses intensional background output completeness assumption,build decision lists.ran experiments Foil, Foidl, IFoil comparedresults Ling. Foil experiments run using Quinlan's representation describedsection 2.2. Quinlan (1994), negative examples provided using randomlyselected 25% could generated using closed world assumption.6experiments Foidl IFoil used standard default values various numericparameters (term universe size, 1000; minimum clause coverage, 2; weak literal limit, 1).differences among Foil, IFoil, Foidl tested significance using twotailed paired t-test.4. Handling intensional interpretation recursive clauses target predicate requires additionalcomplexities discussed paper since relevant decision-lists,generally recursive.5. versions available anonymous FTP net.cs.utexas.edu directorypub/mooney/foidl.6. replicated Quinlan's approach since memory limitations prevented us using 100% generated negatives larger training sets.13fiMooney & Califf10080Accuracy6040FOIDLIFOILFOILSPANeural Network2000100200300Training Examples400500Figure 1: Accuracy phonetic past tense task using verbs4.2 Resultsresults phonetic task using regular irregular verbs presentedFigure 1. graph shows results Foil, IFoil, Foidl alongbest results Ling, provide learning curve task. expected,Foidl out-performed systems task, surpassing Ling's best results 500examples 100 examples. IFoil performed quite poorly, barely beating neuralnetwork results despite effectively 100% negatives opposed Foil's 25%.poor performance due least part overfitting training data, IFoillacks noise-handling techniques Foil6. Foil also advantage three-placepredicate, gives bias toward learning suxes. IFoil's poor performancetask shows implicit negatives sucient,bias decision lists three-place predicate noise-handling needed.differences Foil Foidl significant 0.01 level. FoidlIFoil significant 0.001 level. differences Foil IFoilsignificant 100 training examples less, significant 0.001 level250 500 examples.Figure 2 presents accuracy results phonetic task using regulars only. curvesSPA neural net results reported Ling. again, Foidl outperformed systems. particular task demonstrated one problemsusing closed-world negatives. regular past tense task, second argument Quinlan's 3-place predicate always same: empty list. Therefore, constantsgenerated positive examples, Foil never produce rules ground second argument, since cannot create negative examples constants secondargument. prevents system learning rule generate past tense. order14fiInduction First-Order Decision Lists: Learning English Past Tense10080Accuracy6040FOIDLIFOILFOILSPANeural Network200050100150200250300Training Examples350400450500Figure 2: Accuracy phonetic past tense task using regularsobtain results reported here, introduced extra constants second argument(specifically constants third argument), enabling closed world assumptiongenerate appropriate negatives. task, IFoil seem gain advantageFoil able effectively use negatives. regularity dataallows IFoil Foil achieve 90% accuracy 500 examples. differencesFoil Foidl significant 0.001 level, IFoilFoidl. differences IFoil Foil significant 25 examples,significant 0.02 level 500 examples, significant 0.001 level50-250 training examples.Results alphabetic version appear Figure 3. tasktypically considered literature, interest concernedincorporating morphology natural language understanding systems dealtext. also dicult task, primarily consonant doubling.results Foidl, IFoil, Foil. alphabetic task evenirregular full phonetic task, IFoil overfits data performs quite poorly.differences Foil Foidl significant 0.001 level 25, 50, 250,500 examples, 0.1 level 100 examples. differencesIFoil Foidl significant 0.001 level. Foil IFoilsignificant 25 training examples significant 0.01 level 50training examples, significant 0.001 level 100 examples.three tasks, Foidl clearly outperforms systems, demonstratingfirst order decision list bias good one learning task. sucient setnegatives necessary, five systems provide way: neuralnetwork SPA learn multiple-class classification tasks (which phoneme belongsposition); Foil uses three-place predicate closed world negatives; IFoil15fiMooney & Califf908070Accuracy60504030FOIDLIFOILFOIL20100050100150200250300Training Examples350400450500Figure 3: Accuracy alphabetic past tense taskFoidl, course, use output completeness assumption. primary importanceimplicit negatives provide advantage propositionalneural network systems, enable first order systems perform taskall. Without them, knowledge task required. Foidl's decision lists givesignificant added advantage, though advantage less apparent regular phonetictask, exceptions.Clearly, Foidl produces accurate rules systems, another consideration complexity rule sets. ILP systems, two good measurescomplexity number rules number literals generated. Figure 4 showsnumber rules generated Foil, IFoil, Foidl phonetic task using verbs.number literals generated appears Figure 5. Since interested generalization since Foil attempt fit training data, resultsinclude rules Foidl IFoil add order memorize individual exceptions.7 Although numbers comparable examples, increasing numbersexamples, programs Foil IFoil generate grow much faster Foidl's programs.large number rules/literals learned IFoil show tendency overfit data.Foidl also generates comprehensible programs. following example program generated alphabetic version task using 250 examples (again excludingmemorized examples).past(A,B) :- split(A,C,[e,p]), split(B,C,[p,t]),!.past(A,B) :- split(A,C,[y]), split(B,C,[i,e,d]), split(A,D,[r,y]),!.past(A,B) :- split(A,C,[y]), split(B,C,[i,e,d]), split(A,D,[l,y]),!.7. large number irregular pasts English, Foidl memorizes average 38 verbs pertrial 500 examples.16fiInduction First-Order Decision Lists: Learning English Past Tense8070FOIDLIFOILFOILNumber Rules6050403020100050100150200250300Training Examples350400450500Figure 4: Number rules created phonetic past tense task350300FOIDLIFOILFOILNumber Literals250200150100500050100150200250300Training Examples350400450500Figure 5: Number literals created phonetic past tense task17fiMooney & Califfpast(A,B)past(A,B)past(A,B)past(A,B)::::-split(B,A,[m,e,d]), split(A,C,[m]), split(A,[s],D),!.split(B,A,[r,e,d]), split(A,C,[u,r]),!.split(B,A,[d]), split(A,C,[e]),!.split(B,A,[e,d]),!.training times various systems considered research dicultcompare. Ling provide timing results, though probably assume basedresearch comparing symbolic neural learning algorithms (Shavlik, Mooney, & Towell,1991) SPA runs fairly quickly since based C4.5 backpropagation tookconsiderably longer. tests Foil Foidl directly comparablerun different architectures. Foil runs done Sparc 5.500 examples, Foil averaged 48 minutes phonetic task verbs. Foidlexperiments ran Sparc 2 averaged 1071 minutes task. Even allowingdifferences speed two machines (about factor two), Foidl quitebit slower, probably due largely cost using intentional background partimplementation Prolog opposed C.5. Related Work5.1 Related Work ILPAlthough three features mentioned introduction distinguishes Foidlwork Inductive Logic Programming, number related pieces researchmentioned. use intensional background knowledge least distinguishing featuresince number ILP systems also incorporate aspect. Focl (Pazzani & Kibler,1992), mFoil (Lavrac & Dzeroski, 1994), Grendel (Cohen, 1992), Forte (Richards &Mooney, 1995), Chillin (Zelle & Mooney, 1994a) use intensional backgrounddegree context Foil-like algorithm. ILP systems employintensional background include early ones Shapiro (1983) Sammut Banerji (1986)recent ones Bergadano et al. (1993) Stahl, Tausend, Wirth (1993).use implicit negatives significantly novel. described section 3.2,approach considerably different explicit construction using closed-world assumption, therefore employed explicit construction sucient negative examples intractable. Bergadano et al. (1993) allows user supply intensional definitionnegative examples covers large set ground instances (e.g (past([a,c,t],X),not(equal(X,[a,c,t,e,d])))); however, equivalent output completeness, userwould explicitly provide separate intensional negative definition positiveexample. non-monotonic semantics used eliminate need negative examplesClaudien (De Raedt & Bruynooghe, 1993) effect output completenessassumption case arguments target relation outputs. However,output completeness permits exibility allowing arguments specifiedinputs counting negative examples extra outputs generated specificinputs training set. Flip (Bergadano, 1993) provides method learning functional programs without negative examples making assumption equivalent outputcompleteness functional case. Output completeness general permits learning non-functional programs well. Also, unlike Foidl, none previous18fiInduction First-Order Decision Lists: Learning English Past Tensemethods provide way quantifying implicit negative coverage context heuristictop-down specialization algorithm.notion first-order decision list unique Foidl. ILP systemattempts learn programs exploit clause-order cuts Bergadano et al.(1993). paper discusses many problems learning arbitrary programs cuts,brute-force search used approach intractable realistic problems.Instead addressing general problem learning arbitrary programs cuts, Foidltailored specific problem learning first-order decision lists, use cutsstylized manner particularly useful functional problems involve rulesexceptions. Bain Muggleton (1992) Bain (1992) discuss technique usesnegation failure handle exceptions. However, using negation failure significantlydifferent decision lists since simply prevents clause covering exceptions ratherlearning additional clause over-rides existing clause specifiescorrect output set exceptions.5.2 Related Work Past-Tense Learningshortcomings previous work past-tense learning reviewed section 2.2,results section 4 clearly demonstrate generalization advantage Foidl exhibitsproblem. However, couple issues deserve additional discussion.previous work problem concerned modelling variouspsychological phenomenon, U-shaped learning curve children exhibitirregular verbs acquiring language. paper addressed issue psychological validity, rather focused performance accuracy exposure fixednumber training examples. Therefore, make specific psychological claims basedcurrent results.However, humans obviously produce correct past tense arbitrarily-long novelwords, Foidl easily model fixed-length feature-based representations clearlycannot. Ling also developed version SPA eliminates position dependence fixedword-length (Ling, 1995) using sliding window like used NETtalk (Sejnowski& Rosenberg, 1987). large window used includes 15 letters either sidecurrent position (padded blanks necessary) order always include entireword examples corpus. results approach significantly betternormal SPA still inferior Foidl's results. Also, approach still requiresfixed-sized input window prevents handling arbitrary-length irregular verbs.Recurrent neural networks could also used avoid word-length restrictions (Cotrell &Plunkett, 1991), although appears one yet applied standardpresent-tense past-tense mapping problem. However, believe diculty trainingrecurrent networks relatively poor ability maintain state information arbitrarilylong would limit performance task.Another issue comprehensibility transparency learned result.Foidl's programs past-tense short, concise, readable; unlike complicated networks, decision forests, pure logic programs generated previous approaches.Ling Marinov (1993) discusses possibility transforming SPA's decision forest19fiMooney & Califfcomprehensible first-order rules; however, approach directly learning first-orderrules data seems clearly preferable.6. Future WorkOne obvious topic future research Foidl's cognitive modelling abilities contextpast-tense task. Incorporating over-fitting avoidance methods may allow systemmodel U-shaped learning curve manner analogous demonstrated LingMarinov (1993). ability model human results generating past tensenovel psuedo-verbs (e.g., spling ! splang) could also examined compared SPA(Ling & Marinov, 1993) connectionist methods.Although first-order decision lists represent fairly general class programs, currentlyconvincing experimental results past-tense problem. Many realisticproblems consist rules exceptions, experimental results additional applications needed support general utility representation.Despite advantages, use intensional background knowledge ILP incurssignificant performance cost, since examples must continually reproved testingalternative literals specialization. computation accounts trainingtime Foidl. One approach improving computational eciency would maintainpartial proofs examples incrementally update proofs additional literalsadded clause. approach would like Foil's approach maintainingtuples, would require using meta-interpreter Prolog, incurs significantoverhead. Ecient use intensional knowledge ILP could greatly benefit workrapid incremental compilation logic programs, i.e., incrementally updating compiled codeaccount small changes definition predicate.Foidl could potentially benefit methods handling noisy data preventingover-fitting. Pruning methods employed Foil related systems (Quinlan, 1990; Lavrac& Dzeroski, 1994) could easily incorporated. decision list framework, alternativesimply ignoring incorrectly covered examples noise treat exceptionshandled subsequently learned clauses (as uncovering technique discussedsection 3.3).Theoretical results learnability restricted classes first-order decision listsanother interesting area research. Given results PAC-learnability propositional decision lists (Rivest, 1987) restricted classes ILP problems (Dzeroski, Muggleton, & Russell, 1992; Cohen, 1994), appropriately restricted class first-order decisionlists PAC-learnable.7. Conclusionspaper addressed two main issues: appropriateness first-order learnerpopular past-tense problem, problems previous ILP systems handlingfunctional tasks whose best representation rules exceptions. results clearlydemonstrate ILP system outperforms decision-tree neural-networksystems previously applied past-tense task. important sinceresults showing first-order learner performs significantly better apply20fiInduction First-Order Decision Lists: Learning English Past Tenseing propositional learners best feature-based encoding problem. researchalso demonstrates ecient effective algorithm learning concise,comprehensible symbolic programs small interesting subproblem language acquisition. Finally, work also shows possible eciently learn logic programsinvolve cuts exploit clause order particular class problems, demonstrates usefulness intensional background implicit negatives. Solutions manypractical problems seem require general default rules characterizable exceptions,therefore may best learned using first-order decision lists.Acknowledgementsbasic research paper conducted first author leaveUniversity Sydney supported grant Prof. J.R. Quinlan AustralianResearch Council. Thanks Ross Quinlan providing enjoyable productiveopportunity Ross Mike Cameron-Jones important discussionspointers greatly aided development Foidl. Thanks also Ross aiding usrunning Foil experiments. Discussions John Zelle Cindi ThompsonUniversity Texas also uenced work. Partial support also providedgrant IRI-9310819 National Science Foundation MCD fellowshipUniversity Texas awarded second author.ReferencesBain, M. (1992). Experiments non-monotonic first-order induction. Muggleton, S.(Ed.), Inductive Logic Programming, pp. 423{435. Academic Press, New York, NY.Bain, M., & Muggleton, S. (1992). Non-monotonic learning. Muggleton, S. (Ed.), Inductive Logic Programming, pp. 145{162. Academic Press, New York, NY.Bergadano, F. (1993). interactive system learn functional logic programs. Proceedings Thirteenth International Joint Conference Artificial intelligence, pp.1044{1049 Chambery, France.Bergadano, F., Gunetti, D., & Trinchero, U. (1993). diculties learning logic programs cut. Journal Artificial Intelligence Research, 1, 91{107.Califf, M. E. (1994). Learning past tense English verbs: inductive logic programming approach. Unpublished project report.Cameron-Jones, R. M., & Quinlan, J. R. (1994). Ecient top-down induction logicprograms. SIGART Bulletin, 5 (1), 33{42.Clark, P., & Niblett, T. (1989). CN2 induction algorithm. Machine Learning, 3,261{284.Cohen, W. W. (1994). Pac-learning nondeterminate clauses. Proceedings TwelfthNational Conference Artificial Intelligence, pp. 676{681 Seattle, WA.21fiMooney & CaliffCohen, W. (1992). Compiling prior knowledge explicit bias. ProceedingsNinth International Conference Machine Learning, pp. 102{110 Aberdeen,Scotland.Cotrell, G., & Plunkett, K. (1991). Learning past tense recurrent network: Acquiring mapping meaning sounds. Proceedings Thirteenth AnnualConference Cognitive Science Society, pp. 328{333 Chicago, IL.De Raedt, L., & Bruynooghe, M. (1993). theory clausal discovery. ProceedingsThirteenth International Joint Conference Artificial intelligence, pp. 1058{1063Chambery, France.Dzeroski, S., Muggleton, S., & Russell, S. (1992). Pac-learnability determinate logicprograms.. Proceedings 1992 Workshop Computational Learning TheoryPittsburgh, PA.Lachter, J., & Bever, T. (1988). relation linguistic structure associativetheories language learning: constructive critique connectionist learningmodels. Pinker, S., & Mehler, J. (Eds.), Connections Symbols, pp. 195{247.MIT Press, Cambridge, MA.Lavrac, N., & Dzeroski, S. (Eds.). (1994). Inductive Logic Programming: TechniquesApplications. Ellis Horwood.Ling, C. X. (1994). Learning past tense English verbs: symbolic pattern associator vs. connectionist models. Journal Artificial Intelligence Research, 1, 209{229.Ling, C. X. (1995). Personal communication.Ling, C. X., & Marinov, M. (1993). Answering connectionist challenge: symbolicmodel learning past tense English verbs. Cognition, 49 (3), 235{290.MacWhinney, B., & Leinbach, J. (1991). Implementations conceptualizations: Revising verb model. Cognition, 40, 291{296.Muggleton, S., & Buntine, W. (1988). Machine invention first-order predicates inverting resolution. Proceedings Fifth International Conference MachineLearning, pp. 339{352 Ann Arbor, MI.Muggleton, S., & Feng, C. (1990). Ecient induction logic programs. ProceedingsFirst Conference Algorithmic Learning Theory Tokyo, Japan. Ohmsha.Muggleton, S., King, R., & Sternberg, M. (1992). Protein secondary structure predictionusing logic-based machine learning. Protein Engineering, 5 (7), 647{657.Muggleton, S. H. (Ed.). (1992). Inductive Logic Programming. Academic Press, New York,NY.Norvig, P. (1992). Paradigms Artificial Intelligence Programming: Case Studies Common Lisp. Morgan Kaufmann, San Mateo, CA.22fiInduction First-Order Decision Lists: Learning English Past TensePazzani, M., & Kibler, D. (1992). utility background knowledge inductive learning.Machine Learning, 9, 57{94.Pinker, S., & Prince, A. (1988). language connectionism: Analysis paralleldistributed model language acquisition. Pinker, S., & Mehler, J. (Eds.), Connections Symbols, pp. 73{193. MIT Press, Cambridge, MA.Quinlan, J. R. (1993). C4.5: Programs Machine Learning. Morgan Kaufmann, SanMateo,CA.Quinlan, J. R. (1994). Past tenses verbs first-order learning. Zhang, C., Debenham,J., & Lukose, D. (Eds.), Proceedings Seventh Australian Joint ConferenceArtificial Intelligence, pp. 13{20 Singapore. World Scientific.Quinlan, J. R., & Cameron-Jones, R. M. (1993). FOIL: midterm report. ProceedingsEuropean Conference Machine Learning, pp. 3{20 Vienna.Quinlan, J. (1990). Learning logical definitions relations. Machine Learning, 5 (3),239{266.Richards, B. L., & Mooney, R. J. (1995). Automated refinement first-order Horn-clausedomain theories. Machine Learning, press.Rivest, R. L. . (1987). Learning decision lists. Machine Learning, 2 (3), 229{246.Rumelhart, D. E., & McClelland, J. (1986). learning past tense English verbs.Rumelhart, D. E., & McClelland, J. L. (Eds.), Parallel Distributed Processing, Vol.II, pp. 216{271. MIT Press, Cambridge, MA.Sammut, C., & Banerji, R. B. (1986). Learning concepts asking questions. Michalski,R. S., Carbonell, J. G., & Mitchell, T. M. (Eds.), Machine Learning: AI Approach,Vol. II, pp. 167{191. Morgan Kaufman.Sejnowski, T. J., & Rosenberg, C. (1987). Parallel networks learn pronounce Englishtext. Complex Systems, 1, 145{168.Shapiro, E. (1983). Algorithmic Program Debugging. MIT Press, Cambridge, MA.Shavlik, J. W., Mooney, R. J., & Towell, G. G. (1991). Symbolic neural learningalgorithms: experimental comparison. Machine Learning, 6, 111{143.Stahl, I., Tausend, B., & Wirth, R. (1993). Two methods improving inductive logicprogramming systems. Machine Learning: ECML-93, pp. 41{55 Vienna.Webb, G. I., & Brkic, N. (1993). Learning decision lists prepending inferred rules.Proceedings Australian Workshop Machine Learning Hybrid Systems,pp. 6{10 Melbourne, Australia.Zelle, J. M., & Mooney, R. J. (1994a). Combining top-down bottom-up methodsinductive logic programming. Proceedings Eleventh International ConferenceMachine Learning New Brunswick, NJ.23fiMooney & CaliffZelle, J. M., & Mooney, R. J. (1994b). Inducing deterministic Prolog parsers treebanks:machine learning approach. Proceedings Twelfth National ConferenceArtificial Intelligence, pp. 748{753 Seattle, WA.24fiff fi!"$#&%(')*),+-/.*02143(.*5*)6,798$:;<+=),+2>@?97!:"A;B'*C*=),+DFEHGIEKJMLONP,QRLKS<PTUGVTXWZY[N,L]\_^`Ea^b\cG_dcEaJfehgjikN,Pl$LKS<PTUGmXn/o nqpsrut<nqv2o wxzy{}|xz~M<vuoX,Buu/uUK]<9RA@OuXqu4a@@4,@,u94@A , _X@, q@ARA//`qc9,s&q q9_,/` **@9,9Ac_9A4 qk/q9q/A9RqqAX,}A} A(*9M(*9A $,*}*q9X*c**X(/@h***@9@Au$, AX_A/a,9/qKR q q,9/q9*: A/429A9X//c*(9A,/A/, U9(*9A $R_9,A_Mq*Ka*u$qH<,/(A, **@9 **@9,9A$qR/ /B/ $ *$/(*$2**<A/429Aq *M/ K / /(9M: 29R,a(9*,$q(9 q,/A_M/&q9(< A@9q9 A(A 4,A&<(*9A***(9*$q ,(9AqU&*: X qa/ *$: 9 /(* u*9,<99 ,$(IB ,(9***(9*,Ms/uq: **kq/OR(9*]*_ U,HA**@9$ **@9,9A *<*9A *@__, /, qA**@9, /a *H(* _9(9X **@9,9A<q *<,/A9 $qa*9 q9A9(9AMA*u*KuzA<**A @9A A(*9q(/a* &X< *q9A $$(,Oq9I*9A**@, q *</(*}9O(9, ,XA**@, q *R `a q9AqM_fiff ff! #"$ #%&'(ff ") *%+$, -(.0/123!4( "5ff6% 72% #89&":ff(; =<>"$?@+ff6BA5 DCE F 8G8GB"IHJ<KCLFMNHPO+% #ff "E.Q-RRQ.SQ-RRT5MVU3<KCLFW("X7 ( #"Yff$ !&"5ff # (#ff "3 ZB"?@+$#ff&A5 8[B"!% ("B"I"$?\- 8G2+ffff6 "%0% U]<>"^&"$?_+$#ff&A58N2&"$ `% -6"2&"$Gff$ * %aSff G?2 #A5 #% bff (2"c5+$ (dP ZB"?@+$#&"$[5e_ ff$ ( (d 8f #g28G2% (HP 7#Aff6 "VMVUihjeY+$6B"ff$ Z[, ( #"kff,ff "lP 8N%B8m a- 8G2+ffff6 "%E% nHP#%+$ (VMp5e_ ff- (q"$?Y g8G2% -(.<rCEFD-"* (A5 ,- 8N jff6$ %&&8s&ffff6 "p t%(%28N2&"$ j% ("2&"$#2, -, "5ffff6 "u(.E+$bi? -# "vff ( (H>w1+B"%"E.Q-Rxy5MVUhqel+&"$b!#%+%, ( "5ff,ff "X/z *$-A5 Gffs7B%&Bff>eff !% -6"I%B%ff>e_ - z5e@ ff6$ ( -?2 (#&7$7% !&"I{2,ff|> ,?2 #[% k.a&";$6ff+%Nff$ NB8G ff,"kffG#%, (+&A5 !5e@ ff6$ ( ((U} "$ ff6$ #!?@Ak"kff, ~ Z+$6B";~#%+%Z #2, - #"5ffff6 "3ff6$ffv%+$%Sff6$ ( -v (eIff8N"2&2+2%ff iP j8N2&"$ i% ("2&"$n% 6Bff628N(Up?_+$ Sff =ffff"$ (jff `#%+%tff- 6e75eD?2?@&"$b ?2 #% #ff&"$#%+$ (` =%B&ff #%d-A5 G% (`"?~&8s% n (ff,` "Dff#"$ #%&Bff>eff0ff6$ ( e@Uj$ S, -? #o # (?[ff, ff/z &"kff6 _?@+ff6 "0ff, <KCLFp.5 "$ Z2 ( #"5ff (?[75e[O+$% #ff ""$?G= (?@ff0HQ-RR5M."?s "i7keYCL-A_Z"?s*'( , @aH6Q-RR5MVUjCL-A_2="$?Y= -?_ff0HQ-RR5M2, -, "5ff= (- #"5ff=+26A5 ev <KCLF, -, -,US+$ iff6$ Zo %&% (/iB"*?2 #{2"Bff6 " &"$?@+ff6 "EU } ff- 6eDH72, +2"?v_"$ (/i% -? Mj`.2 #ff&ff&A5 g8G2% -q'S-((- "$?Y= ff t"-ff6BA5 #g8s% (q*'0(-(# `Zff #ff( "$( ffS Z&A5 "EUj$ #"!`5e_ ff0-SP ff0ff, #ffS( "$( ffiq"~PuVKoV#->=&"$? "%BeNB')*),+Mfi2KJfi !! 9 ;*: ; K* `ff8R9 /7!"A! fi"! ! *;fikVtKS2Vb(([)]fi0(-[ [ ]fiZ(-5[ [ ]*fi`Yz26$[6B6B5Ns(2I$*[(i($,-5$#$(!S[-6$kk22zZ-u--5$#$(St-6,6$#i&*6$i5_$((2$Y$Z$(&5#2G2*$DY[ (j($, -5$#$(s q6$ ( $fi6$*5@6$((NZ&$N$,#2, -,56 (- 0`$D Z (( d`#Sp#((Y2jzS($(#k6,`G$Z22#&YB@$#&5Z(B*$@&$*$,`#$#&(4i#z&&5s#2G2((z(a$@&$D#$]fib(-[!6#2&4B5#(,-\BI-6*,Z,B($(SB-v5#I#$#&-6z!#dz#-==![#$#&-64qn(`#$#z#$#&(Iq2#=#-a,PSS(#$#t#$#&-6GBY,[#$q#2,-#5zB,B-6(-z#$##$#&-6b($#5Si&[6$=$(&5`#2G2-i5#i,#@1($6,5=#$#&(*[S~65o,VI=o,B(IZBG2&-6E6B-&2@6=2#2-~&D#N`q-q($(5$#$(s6@&D$-#&(4 -5 -5_(25$No6$G-G24(#$#1,B-6Yi#-2$Y!,(B->62$62G2S#fi0(b((2(fi*B5,,-LBSZ#D$(&$,-LBG2&($&$(0&i(zY-G2kZ-z5#(2,`*@&##$(`>z-#>$s]^&sB(i\N6BN(`($(*$#$#&-6[2,B-\56 @& (25$,*`-5#>#$#&-6t=i&!,-(#i*&sB-6E2#S$=o&(i&$G$(i&!i2`(S$$((-,S26fffi_ 5fffi_ 55fffi_ _ 6fi_ kp 5 6pfifi__ kk"" !! 6fifi__$$ #!0#$ j`(#$#a,B(!22#Z>22G26$ %'&(&d E $!$!$Gd#zz`(z,#$#&(22#&B6fi")%*&&SZ#(SZ66BN,6$D22#`>$s;v$&sB-6E i1*#-i6$ 0z[,d2V*BvY2#22&D$62,5*(!,-#2,B5n$(($,B(l$Z>$sz$i5#v2(kku&B&$6,-\-5k^[2&&B>Ib-6^,-#2,&5$(**#Kq6B-[,-#2,X$6 =2,f 6$#YZ2,N(I(6 zG2(6BN$N[BG,5,-62&G--#B~#$#&(X$>$s $~(#kY6$(#-&B^@;0,B-64$2#YBG2&-6E(6 zz2(#5b~(25$D;(@-DBG2&-6\I>$s3$(]&k6_@6E&B,,,+BB&@_i(B,((s2,$p(s#_B>G$[2626[,@# $,-!&!(#-Z2Nid,-i,So GB&qi&N$Z$6Z$6$[$S&.%L=-0 /5 $ 1 N0z$(#(@&$v $3-0/0G24%L-k -5 5 &=B&#(65 G BY" %(2798:fi;<>=<>?A@CBDFEG@0HADJIK=.IKLNMOB@PQ<>QRP=Sff<T?UVOW>BDJX>@0HADJIK=[Y Z]\_^C`O^Ca>bKcde bfffTdg`hgKi3jkcbKlOmn^Cmoprqtsuvnwxuyv{zn|(opff}~ffqt>u_z0nF,wz0nwxvnN]pr"o,qtsu|Jwvn.uznw|znw0upffuwvnFyvnqFznphzn|Jvn~ffxuG}u>uFznKuG}{>,FznqApG>n RG>ARG>AGv>,sv0Kuyup{v0yGznw}uy}~ffxsp>qxuwxuyqyopqs JxuGqFznpu} uGxwKuqsF.|Fwxvnuznw JxsJNv0xuy}znpvwxuFvnqFznppffzGpv0.n~ ~ ] qFznpvnpff} qsu(.z0q]Kznwtqxvnp>qRwxuy~qxyznppffuGqxuy}qts qypffGu0upuwxvnJyvnqFznp ~pff}uwn~ ~ ] qFznp F)pffznqt~NFupTq|znw0upffuwvnFyvnqFznp zn|wxuy~ wx>uJvn~ffxuGv0Nszyppqtsup>qtwxzA}~qFznp*u Rqt~}Aqsffuqsuyznwzn|*0upuwxvnFGvnqtJznp~ p} uw] FGvnqtJznp)upffznqxuqsffvnqNFGvnqznp.KuquyupFvn~xuyF~ p}uyJ} vnFu0vnpff}]uRKqsffuwu|"znwxupTqtwxzA}~ffGukvwxuyqtwFquG}|znwtzn|)NJyvnqFznpCGvnFuG}$NFGvnqtJznpK. A$>AnC''A nx '9C>O'J9C Jvn~ffxu4AGGA]Ov*Jvn~ffxu} upffznqxuy} rT|[vnp}znp3|KqsffuwuuFqv~ qtqt~qFznp Rt~xsqsffvnq*r[zFvn~uGvnp}vnwxuG09GAKTGAG G9}upznquG}h|,vnp}znp.|'vnpff}r]n~ ~ ] qFznp4JNwxuu>uvnpff}qwxvnpffq>u0zJvn~ffxuG vGKuuG>~0vnFup>q ~ p} uw_n~ ~ ] qFznpqsffzn~qKupN0vnwFvnp>qxy*zkFvn~uGvnp}vnwu 999A$}upznqxuy}h|'qsffuvnwxu*uy>~vn~ qxz0vnwtJvn JuwxupvnNpffff znpffJ} uwRqtsu|znJzypff]Fvn~xuyy44[$C A$ff fi> fi xC4n["C A$tC A$ xC' Cvnp}9[$C A$ t'usvy>u tpffGu fi n !"# $pffGu(% &'n( #k$]ffvnpff}qts>~$kuvnFxzsvG>)u r *upffGuT +vnpff}q[ +, ]sffuGznwutqxvnqxuyOqsvnqn~ ~ ] qFznp]Kuquyup]Fvn~xuyJO}uyJ} vnFu0,sF'v0/ .wqszyp>% 0Rzn pffxznpG2 1 3Affffv005u 40>687 :9 < ;A' $$J = ff > nx '9C OT ?A;A 2 @BA[] 9rC J9TE DFGffGffI H0$ C 9t.> C > JrKup>qtJznpffuG} p qsffup>qwxzA}~ffqtJznp'Ku*vnwuffvnwqF~Fvnwp>qxuwxuyqxuy}pJuyv0qR0upuwxvn0upuwvnJyvnqFznpysu.vnp wxuyv0xznpFqsvnq(vJuyv0q0upuwxvnO0upuwxvnJyvnqFznpp~}uyRqsffup |znwvnqFznpzn|vnyznptJqup>q0upuwxvnJyvnqFznpy>O'J9C Fvn~xuJkMv L>K9 N9A>AG G9zn|v_xuqNzn|Jvn~ffxuGQ PR2ESESx T#|(vnp} znp||"znw u>uwtVUXWYU[Z \ 0upuwxvnJyvnqFznp~pff}uwn~ ~ ] qFznp{zn]| PrFv_Jy] L>K9^ L>K9 N9KTGAGGA9" _)_>Rzn`| P|vnp}znp |A|"znwu>uw0upffuwvnFyvnqFznp~ p} uwn~ ~ ] qFznpb znc| PAb akff znpffJ} uwRqtsu|znJzypff]Fvn~xuyy4 [dc e4[f e e gA$C4 [`/A e vnpff}h4 [/A e gAf fi>iznqtsFvn~uGjvnpk} hvnwxu* _b_0zn| ) x% #>lnm&ofipqrts uwvyxcz|{~}xc(s uf2Ifj)k5ff fft`2Ej V%Q(S 2S &8ffQIkfQ!S O2ffStc!<O25Ej!E 'E ff22Q 25I<]Kb"5/ !O5j ffSS8'ffwjw ff]k tgI: cO!`w `ntwIEffEI"I2O"n" ]j%b"58~ffSjSt%c!<O%ff2]S!(SE 'E j2Oj!ffS`j2!! O"Q~ffYE2I5Qt&t~EQ!O<(ffO( '&ff'y'SMt'fE!Vb!ff%2bI"ffI !` +282ffOE!BVOff'ffOE!OffffE`ff~SffS(<ff%S(jEQ2/j ~(2SO8 &cny b ffkyffSK'O/kO% '("</&fffi `%SbffE< 2nOE'' &|nffIEKkOffkfff`OO<Ejk!ffjOSff<O bIffOO t`8SS(S O<~QOS]!ff(E O2 ~"fQ!jV/ ~!ff"OSjffSff g" !$#&%'#)( +*,g- %.#(/#0! #yff1ff g" !2#0%'#(t3 *4g5 (/#0!$#&%' 6%`ffE )7OffS8]5S SjOYIOffffk 5SO9 E%jOYIO9 :)5E 54< ; kffffk k=> ;f2(SOS5OSfffkSt2t`ffEEScE2 2 5~jIffk2Ejtk!ffQ5(E t5ff8(SKffS~5O~kQOE)ff?X'E58ffSES!Of!ff!fO'ffSj$!ffQOSQ!O`S !(f`E+ffS!fffff@ wffcffwyBA gI n CQntwIE+D FEGc(2OIH%2b(ES E |EI E2JH2/ff22%'&?K~!OE!K(fSMffIE~!OffS5ffE2j ff2(E EL'Q'M L<ffE22225J N8'ffwPO &QY'<SR/T8V/<nyRctU<'ffS'2gI n jn2w EWEI5b"y & n'I]!?V "X~O!YE22 5ff2OS !ffOE!M(f`EE85S2VS~2jI~(SYS EkI(" YK E~!<9 Z /2ff'fE2 2O+kE22I~2IS$ffQQOSb"OS~8! /Kb"[]\_^fi`badc.adegfih_jlkmfJngjpoqcroqsutvh_f.w.xadxyw.c.z'a{e|5}v~dh_jpdfJngjpoqcrdvp]ifi7l .&Ildm]p5 gd55 r& ?p '&m7_Jmm&/ .I /M" d1 J') lm 0p S'Sulm 0p F 9 lp_9dm]/dq)]_V]rgdV_V]"80 .MS d0J.& p l /./ lm 0p v3..2'I9 'p/y0. p'l .&V"/34-SV{5v,5V"i0="g .VVd+,5d2'l .)l 0 .Gl 8 0d 3.r-l .)yl80l0? &J.& +. .u8-l .) q S./ p l ././5 ./ l $ .8/S. .S/.'')fi ffgl& I8 yd/S&& yl .&p03 G & /pm3d.r l lq53m l .&p/./mp/ SlJlp ' GJ')89l. S) Sl-I9 J ]i.&lm 0pq53mp '&m?puS./mlS Sl{3.&d) g.I) .Jp l p3- p l $Sl& lr/mlS Slq53mp '&m Vup?m lmlm 0p G0'mulS S'mGS/)& & S')0r 5G )m)d& 0p3.&0.. 0p ' .0& .u& 3l .)m" !$#d p .00Sl $ ' )0 &8 3&&p '&mrdvp]i2%qp '&J dmm .&b 2J 0p /pS .&B&b &?,++'0.rS0 q8)( '3" yy v p *)J-. .& . -M mm-/0/rdvp]i2 13q4 '/l 2 p '&{ Jmm .& J l Sly /0'r/&b 2l .&. .r'8)3 2lS.lg5q p+gmS0. 76 .&1l8;: pmfim; <)pJV]" 9 . /? = + mm ; + / 1 ') mm9& l. .) {)2 .?> Jmm .@rdvp]i2 _ mm&. q8& l .)m0.&0. Jmm& .d8.J 0p /p? $qBqr& +l .& 1?4 '/l .r& )0r 3.Cl8 0)2 _]m0. dD19 . /?dE 1pbF!$#d p4 '/l " _]m0. 'iGpH SS& ..'S $&? . S)0rygmS0.u _ m0. 15I =lK Jd. &'&u &? .4 /&?gmS0. _]m0. 1'?p_J&/." '0m 2d&1rdvp]iI2= ' ql .& .Lr)0) _ dM1 .S. & QP 'v 'SR '3" y0 ) 1 3p '& .V))T Sg UJ pmg3gd 55 -'S. )mWV PX .v ' Sv PX. PX ') 3l&&y &dY[Z]\fi^`_ba]cTd,e(fhgjilkfhmn4opcTdqsrtvuwtyx;zt9tyxbuD{4u|4}~t~r}rsE~94~pKzt~r}~p5~}b{4uufi}b{4u}]t3rltyx;uDvxbr~=uDrstyxbuD]$rpufiy;yt~t4ty~pr}?w}Ltx;uFrprK2~}b~GHuFvz=tyx;ztzfipz;vu9E~94~puKzDfipz;u7~tyxbr4tu~pfi~tyDytzty~};*bHu*u=z}*tx;zt0E~F~pu=0 = t=z59~}~wztvuyvufitsr2.$2qsrtvutyxbzt~hE~94~u=0 = t=z79~}~wztvuyufitsrhtx;u}ME~F~puKl0 = t=z}$Dtvuyvutlr3bEr};~{ufityxbu rr=~}b*zbvu=z}b{C3b4;ty~ty4t~r}"ufitsrhtvuywlWz};{Mvutrzbvu=GE0ITWR`R(R("fiWR`]yGR"fi&.b$?.(TRTT v$z};{E0Il,RRyERfi,R 4R`Ryfi,Rb]4R` 4R$Exbufi}M%~pz*F~}4~wztvuyufitrI.&7$M0 = t=.5$z}b{DH0ylI~pstyx;u5~};ytz};=u*vutr0 = t=bILu0x;zK$u tx;ztIE0I 9z};{Dtx]bC32qsrtvu tx;zt03z}b{3tx;zt3~$uM~94~=zty~pr}H~94~=zty~pr}A~p*vu;u~$u]44tD}4~$u~94~=zty~pr}H~94~=zty~pr}A~p};rt9tyz};y~ty~$u{4u=ytvz9lw]~t=sKz$TAEx;u&ufipzty~pr};x4~AufitHuKu}?~94~=zty~pr}?z};{?E~F~pKzt~r}b{uKvy~u={~}Errpzy5ur=0brprKlpvrIuyvz}b{tyxbuKrufiCE(rsz54vrrrsuy4z};{tyx;u=rvutx;uvu=z{4uI~pEufiufivu={3tr7z5rr*$DGx;z};9z};{DRuKu7yK$(;zu .fi}Dr4lvrrhrhErvrpzyD5HuIbvutx;u}brty~pr}rtyxbu=rFu*u}$tErz7pz;vu]$h"[(Wut&K==KvI s=K==I47uMzfipz;vu]2zufitr5fipz;uK=sz};{*. K==fivb[4]5z9]$rpufiy4byty~tyty~pr}Lr . t.lEx;u}Dtyxbu vutsrhvr};{4}4~tzbvuK7$` =K=.=` j= jK==.= jRF~pItx;uCT[IK r $C0 = t=;fi.fi ;s,fi 4 "!#$&l% ')(*!#+!,.-/!0(1!#'2-/!435'768- %9');:) =<>- %?A@BC$ff,fi 4&$D*-/!+A!E'03FB-/GH(!#'2-/!43I'J6K!#+,LH&%KM)C)(;:N-4!+G')+$! &% ')(*!#+!O-PQ,0Rfi.Tfi8UWV$XF[(Y"h]+Z7AP[$[(; ]\ [$(?_^$G`');:6+ 8/')(7!#$!8RbaY@BBc'd- H% WQwe,% fCK,! [KGCe!#$&%I.&QA@B9Whg5');:6id- H% W`A@BjA@B8C$k+D)-/!+A!E'EG8C l!#+&I% .!8;( $@jA@B'mQnRo_fi, p$qQz$5`tyxbufi}BE0IC 9G2x;uvu&~ztvuy vut9r .$ . t..5$Dsufi}bKu]H0ylFr ts "x;uvu ~tx;uwKr94pufiwu}]t0r$LvuGMEx;u=rvuxw.55r "z}b{&tyx$;sWD(h tx;u}Q.50r;x;uvu ~tx;u5=rFuwufi}$trh$DC0 = t=R.5$Ex;u}$ExbuKrufizwtx;uvuDu~pyt5z3tufivut5r0.&Dybvxtx;zt7E0I?r {z}b{tyx$;H0yls ?FExbufi}&${4u|4}4~ty~pr}MWQw3}|~)fiJ J8*QF J9 B7nFJJ*O4f89]fIf$ffBfffIA/mffmfm8fjffffGT/fG.*1fT$8/fGff>/mffJ. BBh8fBTm$GxmIAQT/8fGfffG/Gf *O$ffn58f $89Bf/QT/mff0I ]Pf/m0BTfQT>/B$fm_G f/ fff $O/QT/m?NfBOtBnT85 f9 mm8$f/IAQT/Q0YB PffIfB9G HPf/m0Bf m9NTfBhNf h$9fjIHyfi4G9ti+yfi4G0tiHyy#4+T5}A+4 + f+4JIB/ mNOh$8$fJJfff0tmf/J8G/f tOf/ Gf mfIBK$5f$GF5_QjfT$Gt5fN>TOBf0B8B$KG >0 f>54]9TNiBf/JhfhBfN54]9.`f G7BhN>85JjHI5;$4++;7AT$]G jIA]&0 N f hGJ >y N8.5IB8.Bf?/>f fTBTj8 HfB0G WfHIA/mYvIJ5IA/mffkG/58fJk$ff58.fB8] ff fvfB8yTmfT//nf IA/8fGfj58nfB8_ fffi !#""5$% &(')"+*-,0h/.10 ,F3246578E9._ :;<bi5=2{ G QH GGTGfG fEO?>WvA@H ffNfEhhJCB ] m0bJI .IQ mJv]DB3E 54]9 hfn mJODBF>}GBf J EOD BH2IBbIBJKJ $f*GfML]DBzIB&ODB GB+IfBON7BJ/54]9BBfBhBJh( PT/fyhRQ[ /]V^ `_aA 6bc7; Sed ]JV fff_ ghffij]P7kl8V#mnBoIpq8!D""SUT V #TXWZY\j>U%8&8'$"n*r,Kh/.Isl578f657 &tuvw"6"xy&*z!/&n%*f# v{g|v ,5h?.:;<K?QBOT8PTGff IA/QT/mffh5KB8J>54]9 IBn0B$O"0k 9f_{J}Bk bJEkB8JQ f_IA]&KKOh$]fIf$fTBf mOfBGB]hfffB*kIJ /HPf/m9Kf G NTmTf//if*f8fFmf $ NJ mffnT$f*/f f0*fBf>IA/8fGf08TfT7Q6 JV ffkl^ Sed ]J/ ff~:4 `m*>* fF* f/mffT ]IA/mff@e_K?9(P mnQ/f5Qf9@eHf f?@eH+[gff@Y]efff 7fm8mmGxbh$Hf5f mmYf j`Hf] mffJ?IB 9G/8 &vwz-v{*j!Vg8&Gs%v 'yv{z-v{*Hf] m/fBnfT//&TPfJGKeC yxG *B$f8 fGfn T]IAQT/8fGff] mW0z"g 8&g 8&vwz-v{*9!Vg8&?sl\v 'yvO-v*h@A_99fn ] 5f fT/v/&4fkJG* f/m ffTBT>IAQT/8fGfjHBf] m1H H N10B$K0;k/T/jfT9fzfi{7#ff-q:il7a U7`(q%| wO7I8\OO{`1o6i{#8({ff%RV{{ggl7q(\+fA|a jg/7c:%jfA7cfe|Ca jgaAH%8wcf\|: 8w%%te`iwO|3R1( 1I`\ gj%7(j8/\UCe|q8g(%i`\(q( O} D8Ug9\f(%iwD8O17c8w}7I%8\98/\zG w+KOI`8\je|8g(%ji`t\8`6\iDD 187\ ze7OI`8\|Aq``cOjggj%8D88\w %9i7i8|6Giw %l:jCAK\8U|(\Oz z9\8 (e7( U&?'CGw#1(g8G88\wj`8q6wGiwO #(ff "!#!%$*(C+O)|cff fi(qI8\e%89|8 %, `(7\U7t\8qa:Dwwgtw\8\q 77 - 7U\8ODwgw(w 7q wO7ei:DwD+:O8`\Og cgf% .0/213 V7DD.2.04g5768fifi)98: fi<;ST1X,Y+VUWQG[iC}]\'^con=>f,=>OO \,%?BffGH-Z+@ _B7`aG)OXE8>%h-n?,%?-GffGLKMBffD2ff>N2ObBffaQBffD2E8EcBE8>p T%q ffB kQObB @EcrB:GIHJsOEJBr`G)O7E8BJGffGLKMB:DFff>NffOPB:IQBffD2E80RRB:yN0GQkBffzO{8BuiOP:G|EjD'GH0kY$}K~O zOPBuiOP:G-A@ #BC0B:DFE8#B:GIHRyklRiR\fOOedgf OO dihBj0klmE8>VU)t WuEE0O @ w vO G0`G)ObxE8>R$}UWQGVUWE8>s(q6fn?QBffDFE8>E0R5768fiIfi)>l8:|7ecVwc:`(`Ka(wZo&%t\8\qi\O/O\i7(%HVU:x/O(`%7 w7c87\ tw7 \O:O(%g8wg 7(Co ? n79\(D%`OOi\O/O\K`8VU:UV 8i%ww987\Ow ( +` |c\8e1D88\wOt`i8twI`O}1A7(lgZ\:Dw /G7`(`iw9l``I`oYC&7c7qcVf`(`t87\q r(7 x&? n iiw\U7tfVfi8iI8\ew (:9 7\u #7(gw (ti`t\8qa87\ z@=>edMf dih[iC}]\)\BffGH$}K~O wObBeiObffGY8\ BE8>C T_q BffkQObB @>EcR kQRcoE0D)>UVUWBuE%B%N'QG0k>BffwO{8BeiObffGjDLGHQk6A n E0D)>UYVUWBu OEBKR$}UWQGYVUWQk>2OEVEBffGY"!#!B0BffDFE8>cB%0klE8>R kQRiRBE8>CN0GQkBffzO{8BuiOP:GD'GIHF0k_$}K~O wObBeiObffG@ v#QBffD2E8EcnfRyklRiR* f OO \ *' g98 f OO ~' \fDi(6`ii7w`Oe18g(%e| 1AG(g8 .% /1Og + G +M*F 7(l7(e8/je|e3 1A 7ID%`86i`\U`%%i|8f OO 7\c7OF8g(% .# `A *5768fiIfi)>l81A nRff0fi)Le02LII_e))Q))WFPe2L}Q*eW8:g:0uu0~7:i7&:WgWlZry%g%e*'l=0uue~*'QF)u_*2Q)Qg:u:g:|W|QVj0::Y:X e eI*=r)0e*'l=0uu0~*'uZ o&:XQlC %uy<%F=]Wl}& :Ql:))%e*:=uu08%8uJ &e*'>=0uue~*'Q~:I2gg:%u*FW0%820uul~8X:~*2::QV|~g)gfffi"!$#&%(' *)+-,/.0#&1324+252617,89:87#; <#&%('=!*8>#&?&@%BAC?&#&D/EF#G)/.0+25EH%,+A&I IJAK%#&%('L.M+ N)+O#OP/D/IQ24+RATS U)6V XWYHD/YMZY P! Y\[HS ]_^ #&%('`! _^ a:876%cbd!\ ^ eYf5g4hBh7ijlk ^R!\ ^/no!qpo!;!P!rbd!7bd!@syxzbR!utv cwut{bd!@s l|xv uw BxxC!@sCxmv }w~x:!lxffbd!/ncbd!\ ^ Xfih7g4 }~H4"GJh7iqGh{H4Cq 3y z)+@# %7EMP~24qATS%BAK%ZP#&1PAK.0A+&EF,+#&.,/.0#&1242+q#&%(' #P/D/I24ATS ~Y 876%9:8>/D-&E02+:2#9,+A&I{.0+Pl =cAZS mWYHD/YMZY @Yf5g4hBh7ij9nq=b l + >bny= n6l +-n@+C_q++qn+ l@nlb lb6/nC^`;6(fih7g4 \~H4"G`h>i5q )+ #%7EMP524ATS ,/.0#&1324+2+~#&%(' #CP/D/I24ATS ~Y 876%9:8>/D-&E02+:2#&% =cAZS UWYHD/YMZY @Yf5g4hBh7ij !Ge!c !^ ! 9kk5/6figg:)uarCW0e*8l=u0ue~*:urygpVg]rFWuryg:)~ )QF2Q)Q~:0::|W|Q#*7e*'>=0uue~*'Q:)V_|0:::aYX e eL*eC7e%P:)ry%g"e:0uu0~:Wr|X:)_r=lWg*I_L|Q :'l)y:ry%g":ry2pQ)u*Jy:lQgXa*L|Q) :a*Z:)r gp %&a}QCffu0uu J7ar)Q__IXCL|Q y:ryjC'l= :#rgWlgWlF| |:ry%gpglVgerWl} :#lQgX *J_W:#C'l= :#r&y:7>::)rrr)Q% :uXgW:lgWlglW:)_g)g *&:)gWl| ||g:ZX"*'l)y:%Xr:)~ FWl'j}QeM2u0uQi*eW20u0u~*IX~Qr:|2::uu):)e:gWp I2~g|* |>eo~Q::L2Q)Q~:u:g:)|W|QarV_|u:g:X:% e eu*'gW7~Q)ry2 JP:QlVV2 X #ff * uuF"ff Xl0u0w7:>a}Qj2Q)Q~:u:g:)|Q%gW~VgW:u7 :Ql|>*~Qr:}Q:W~uuaF)u2 agWl> L~::)7:VXXg)~A):])Q)QlryF X)0WF:g:|0Au:_:}]g)ury2 XP2 Xl0uuz||~F=lWl~Q):7)X2::u:~:gWl~:)AV"*=l_||~F)#~Q|~FV_|0:::r% u uW*e0u0w)QAg)~le:~V:0u0' X_:):0u0w|~Fu0w~Au:)> )QgQ:W~2:QlQlgW| ||g:~:I2::p:Lr7r_gW0r02Q)Q~:u:g:)|QrV_|u:g:_:=% u uF*&|W|Q#V_|0:::% e eL*:)> )Qgia:)FWr:Iu2 :QQgWl}=l_r0:_|l>p]}QI>:|~:2:A:)AgWJy:QlQ:W~_2lWl>:u:g:|W|QX% u u}#}Q*2Q)Q~:0::*)] :Qg|Wgggg: :)Q_&a:)PQlQ:)~J~:~:2:agWllQgYl:)>&IC)_~QX:Q:W~uX:|>:W0~:V_|u:g::rVju:g:]:X e e#}:)ZlQg>:|~:2:Zp:Ylu:g):#Ql2Q)Q~:u:g:Z|)l%|W|QX% u uW*:W~ )QggWl>X Lg~:Wl}a :r7#:% u u|#"C#:FY~Qu'):~:~:2:uuPVju:g::% u uW:~C2Q)Q~:0::ar)u:~Q#:r&;gWl>C Lg>p:]#:% u uW*fiF>+4{ZKB+{3BKz{3r3u/KKr3>K@3>KffKK7y7MeM0ffKKR>KyKy7Ky3/7/KM0ffKK7y>/yK>eK y9Kff 7K3/7/KM0ffKK7@7=MJ6KP0K (0Jff>6 MJffKK@K>eP0K lJffKCB3 GffCffMfi GPM7 / 0:ffKMP0K" 0 ffP0K q ~Mff/MBJ9ff G7 oKMff G/P>`6KK73ffK_K:MP>Kc MK0; ~MKMG7ffP77KP0K_ 7K>K /0K>6 ~edKP0ffff~Kyffd ff>P0KMJffKKRCK7JK!#"%$'&()(+*,fi(%-.(ff/102(3(+* 46587 - 587:9<; /$!=*?>@*ACB 9D;FE $!,ff>/$!=*6/KHGI GOP7J qff P7KL K oKJ P 0K K QRNS=7K>6Kfi G/Ty>6ff >KR3/7/KM0ffKK7979eM6KP0KP7KeKR>KJ3/7/KM6KP0K>d>/RK7JKUF oKJ 0K ffMJfiWV=KKYX[ZJ\^]fi_^`C7Ke> aB>6B/b ffK7JKK>dMJ6KP0K`KRffK7ffP7yK 3KG/0K>ffc >3~ 7ffBJ @jklJm!nejeo'prqts(u K7KP7/r B3M G5MM/Kw vyxzK K7"(fid.*:$'/e$!=f*hg /0K>i K07ff3K GMK: {|xzK 77K} vUK>~ { 7c G>K9~ffffK [BK> 9<;wE ( >5/0K>K XXffXt``.Xb ` +Xt``K 3KGl>6X X+`[`K>~fX+`>JG5P7@Kd~ff6K[BK:TyJq G/cfKU0 7Kff/PuGP>6=7/P7/.X+`7KXb ` 7 Ki~ M` KKy X Xt``+8) = ; = 5 $'/$!=f*y3 psFKl1pj~ro'je^8pjeqNRjzqeq jeklrm!n^jeopJqsro'je^8pJPpJqK|MNm 2jeqeq@om KQNPKB3MK|ZO73RBffzc G6mfiV=KK|X[ZJ\^]fi_5>33WZ^ZJfi`+% HKMJ% KKB3MKu>KeK:ViV=K7K:VV= yK7ffcM7/>M7OK ff3 K797KK 3KG/K7ff >Kc u 3K/;73K/KX[ZJ\^\fiG^`~73Mff GffP03K67@/0KP0K>MB/b ff6KMP0K K7MJffKKB/ qffU/K7ffffyTyff/MB6dP7>eP0KUP7ffK/ X"ffff iZJ\^fi_^`JMPd9ffKMP0K K>Ku GffyffKKMK[KBKy>/0KP0K>MBb q6/K>eP0K K7MJMffKKJB/b ff9/0K>6; oK7Kfi70. HKP KKR B>>eP0K97ffK/h ff~K/~K73 B6/d>ffJfiZ6KJ g G X[ZJ\^\^3ff ZJ\^\^3fi `1>3Bff7c ~dB ~K>0/G+7/7K7O2Ku X[ZJ\^\fi^`5>J GdK G/6KG/r Ke ~0L7c >K >7JK7ffK/oK~MffKMK6q7Kyr G97KR97@BffK"ff3 ~7/=>ffK7/ffR/ /0K>6q6KGK>KdK>/K7F /J WyK GlP7yffKff/ HKP KK>7JK7ffK/h +~0R>36K7 (PRffKMP0KXK>K wZJ\^fi^`q@m pr oK MC/ MK0 K>Kue0="(fid.*:$'/e$!=f*Lg P7PMP0Kce0yhM7KK g 7/C% HK r<k1sfiprqprjeowq@m pJ2X9Kf ` oK uu lK7Kuu HKCff3u >} .O> ~C7PPP0K 7P7K uKRdK w7/P K0~i jfi1s FKC"(fid.*:$'/e$!=f* "/ K B=CK7ff @K K>%efifi@fifJ^'.@@rfi@@ffPb.fi'fi^'fi.:'e!fL @6H'}S18eeJ: %r'6Jfiff~6| [ @~' ^ }P !^ 6 }P@ fi @ ^ ' 'c J' 6 6 ~%f' @r@6ir'6J6J ert J ff8 Ffi.:'e!fTS. 4U 0 ~6. r'6c3 I/J) 7VhXWL18YRffHZe%1U +63 G[]\?^U_'`Ft. aL P^3 %('b[]cd?^Ue'gfhU4+ +0 'g[\i?^U_'bfj[\(kld?^U_'7D#;nm&C<$ffpo][\(kld?^U_'~'*6c6 2fi. (} + #ff,= qsrTt!Iw8 x y{z}|`~78x! vw! x1{ U1P N8 POrQ NR^811 Ne }N > NRff'` ZO`Neu5vOrQ NRff8. F7WrUpmfZ Ne ~e@Y :Z }X WJ dZ1N,OJQ NRff8 ffoF[]\+?Ue'L ROWX WNb ff}e8 1 qsTtJ)3 ()Jc. g3 J)J 6L@3 2fi 0 J. 6c6. (63 0 . fi + b +9+ K?>Ld(d'`P 0 # P#~9d9. 6 ?Ld(d'I_J)@. 6'6. 3 c^ e3 . 6. c ['. 7!6 !. >tJ 6 C [ 0 5fi'd 9 b95SJK ?Ldd('z @ 0 3 ?>L(t('`Ib 6 ( J L % _ fi 6 0 . 6c6 ' (2fi 2fiLc 6-+ 6 ' r@66({ @c>@5@ ' gq>#6c6u! [ ?L fi. 3Iir'6 >@ q>6c6u! [ %L fi. b^ 0 c 0 6 @3 ]Q 6@ Q 9 @6. r@6c 0 qCA#6c6' 3fi.:'e!fFKU 0 i6. wr'6c3 I)J)@.@zX W18eY R^H Ze~Q Nffr U4 t. @ L fi \ ?^Ue'P t. aL P^3 %'P l ?^Ue'gfhU4(0 'g \ ?Ue'gf;meU'. 6c6 2fi. ( o#*?Ue'.ffoV(?^U_'P _ j*fqCA#d{5/=i qsrdIw XwLy|>Lx (!fs.ff` 23+FJ 5787 ,w8{ ci X e!f 7 1 NOrQ NRff8 NeffNe> NR^e' dZO`Ne7 OrQ NR^8L 7Wr5ffZ CN e@Y *Z X W@J Z'1C N-OJ NRff8g o# \ ?H;&='L ROWX W+Nffne8 1 qsu h&uL _ ^6 6J)J 6L!0 6. 2^ ' 3i. 2fi. fiqdr'6\ ?^Ue' D'6:ofi[ \ ?^U_'`I-J)+'}J u fi6r'}@ @ 6t'c [ 0 J.r'6J3 ff+ 2ff'. (]6D?c 6 0 @ [ }6r QX6c6 ' + h"b[ 0 [! 6-![ I~9d9. 6?Ld(d'g@^ ({@cL ,>@e @ ' ~ L . 6 + -6 6 r'6c c Q c [ @ + ]9^.. 6Q c[ @ r'6c4 P@. 6% @J J6 2fi3 B >B 6z6r 2fic3 I,r'3 }!6c6 (t. a+ 'b>@c6 + 6r 63 ?c @c !6*6z{ aL sCI 3I 3IEc J. 5 t. a+ ' 1[ 0[! 6-![ ,J 6FIfi.:'e!f%W @6e ff#. q:X WM J ir@6eff . 2^ ' ( } @s\i?;&5='?@q&'`I663 ] sqX Wz1 ff/IF @6C ff BZ Z!` O1 qX Wff!#"$# &%(')* + ,ff-* . ff/0 '1#ff# 32 4 52 066 78').###ff-'1",6:9 );&*< 5=(8')>-??@:AB;&C='EDF?@ff:AG;&-=''H"!IJ)K#ffL :M+NPO QNR*I&fi+`8iHe^`).5.Q+$] E>.$*.{^)5.Q+$$+^)>fiff1. CQ$5L]>QP#8! .g#"e4.Q+$e$}-L.%ff).P &).$}Q`+.'()@*+,).V# ] .- ,Q$$3]>^P`+./ ,8071%23547689;: +Q!e>QPff 5< .^$3=?>A@CBD@FED@HG+IJI%KLBD@G+IINMO>A@)BD@PEQR@G+ISITKUBD@G+IINMA>V@CBD@FEXWY@HGISIZK[BD@HGIIM\ >A@CBD@FEQR@H]^ISI_K`BD@H]^IMXBD@PabIINM!+c >A@CBD@G+ITKUBD@PabIDId& +.Q+$ ^)*L3]{_f!e +,4!,$eg h)& +.Q+$ ^)^$*,L.)$3L+-{e \e3 ^b5L3$ep$[i)j k+" k:l L \ :d.PQ1\\{ $3.*$3L+/{e735n- poibq(.r7sOtue.Q+$ c Qs+{ $3v>$ $$. wek" +4V3$4L.e$$e^PL.e$& $Ls+5,.Q+$5xl^L>.*^Xj $dQu< ^L.^$4,$3F>*>^^4L.*{51+]+^$Re ^fi(y zdq ^( { fi1ff N(q .e $#$3F>5,.^$QC{ $3.|>,$e$):l3z} 3sQZ:l $e @S:l z(q umFl^3^~" F1ff L.j^L537" ]!L$.z" 3ds3)l;"^je$.Xj $3$ ^i)j^"^l^ ~^S <d>>kl sL)l!$ !, id<zq(L*+5# $)"!Q]{1;}!jX<d< ..$ 3 ^5!.;i)j ^" ^l^ { +LREe $" )" ^$!}~d< ..$ 3 ^*!!zl^L>Q$)ff CQ*3L#*L$!y +*$5Y(q .$3$ >Q(x.+ 9) g 9fg9fi+8) ( fiN C0(D.;1ff SBGYq(. X<fi$3$ ^Tzl]> 3>Q!LB>$)"^bl e3>+>5<$.^$;< z(q .F>5$3$z(q (*+F>+$.(5.Q+$$@H#X<u<^.$7.g(tfiuu^Ze k(q .' Xd< .etfiuu^_je|tfiuu^T#5<u<Q.$e'tfiuu^T{e^l])lgl5!etfiu^tum3$)ljFe xl$y !Q>e+tfiuY5e ^(q $etfiuYuIN ) .Qff)ff |Pff !L$.z" +fiff JXj (>${i.$^3"4+$L#-3>+CPff1$.(4.Q+$3K^$)l!*Lxq(.( ! .}+f"*^Le,>QPff 5< .^$*L$z(q .f=#>#@J@@ /$70)I@g$70)IJIi^MffP+]^*#d.$ege,^*,@d- e/Dehh+7,Q*7l$< fi0vM gY4$3N$.(4.^$3+4pl z:l d< +F 1&. )ff *>^#Q.'De$i" Nl^" >>^0ePff ^$,3L+e$5:d$^l^,+)+*+$(^^fiqd>Q)!" Q3)d" L.,!+_L$ >QsVfe->(%1ff K+fi(q />_>^^$5Q.P?~0>70YeXPff ^$sL>$3!/d$kl>Q#>3d$# $.$f ^. $3" #^$)lf h)& + )ff(qA>0*O> YMff +~PL!Q" fi( $.$4e1ff $3>fi +# $)" +LQ)l(" Sj>${+>QG+ v0fiYXY+0fiu((_0XXbY'XX5RF_Y0Yu(%57;Z)5S^N'JX/)z%x5gb)X?ACDFRH^S_`DPDH^S5DH^)XA)DPRkJ DPDH^S%`DH^)PkJ`H^Z5b)5fi )X`)X)*NYN)X%)fiffZ5( Yk^ YXr^XX)bYN)X*fifi)(X*fi *fiX kz)S) *XS ^S) ffZk/)zYbSp)v k u)NYpb)X" !SXu#z JX$^k; (Y%!)'kS5N*p)k (b|x5zN|*)*" ff'&+)'( $k k'SXN)X*)?ACDFD+ *+J%LD, *+% k* (N|zXzb*fi)X*)|). -!+)Xz/ FS XS / ()S )X0ff1_(uSzS)324SX'JX)SX|b)Fpb)5fi k*)x5fi65)^Zk^ YX|)x6 YbSJx5)X)zkJ)~|u)fi)z 5 " Yk u)bY*SX)S)zX)N)X% ff7F81_ (uSzS)92:z//SX%S5)|); zYSN)~)h)Xzzb)%;ubXb)*fi^k< R5p)'z6 YNJSzX)5*fi)zkJ)= ff>#?A@XB@DCAEFEG@IHKJMLONQPSRTVUP-WYX(ZW\[^]AP-W\_a`cbOWZedRfP(gWZehfii=jkP_Ylmcnpoqlmrlmbsn trl b/n^nMh>#?A@u@DvSwxRzXzy{|r3lmbsng)X}zy~9rl bsn6! Z;5z~9rlmbsng)58z~9r3l b/n6ffZ5N65Y1h* (uSzS)!rlmb/n/)XqrYl b/n6ffBZYXlmn lmrlmb/n rl b/n^n6ffZ5b)5U; ) YNY)p qrlmbsn)Xqr}l b/n6ffZ5N657)^XXg)'*fi*)x^S) !YXbRJ 5M!Tlmn#oqlmr0lmb/n rl bsn^n6fflmrlmbsn r0l bn^n lmn6ffZZ)X">#?A@XB@DCAEFEG@IHKJMONQPSR W\_a`UPcXZW\[%]APS] W\_a`WfigSPS]A\Ze\P_RB W\_a`0hi=jkP(_R,jkP(gSPPS^d]R,]WZedRfPgSW\Z6bq][DXSjYR,jkW"R r0lmb/n0W\_a` trl bsnMh>#?A@u@DvSw 5JXp^ ^kzS)~)_;) YNY/Z/XJH# lmn r lmn J %5N*$~ub)) !s#$~ub))#! A)X0!p - %5N*8r lmn !)X)$) H)3lm n6ffbb p!)5S5N{rlmb/n H0 lmn r SzX9rl bsn [S#p -ff bX # # r lmn )Xlmn r !^)5 fi)5 YXbYS 5 trlmbsn)Xfiy JH#trl bsn6ff(hgC"@+,F\EG@IH=C u9?E,HkFA?m@uQ\F\EG@IHZ5*fi^k<R5)x6YbSJx5)X'*fi)zkJ)) (|ubXb)z;p*fi^k<R5)x6YbSSzX"R5N5fi))zkJ)5uZH)xfi" ff'ZXbu HI M?"FE,H={ FElmrlmb"nrl bmn^n%5N*/ _b)X%)5bh|zx*N*)!R*N_)+Fb)5fi k JX%b)X/ )z'65)5)zkJ)=ffsxYx)S5M!YJXFN*lmrlmbmnrlmb n rlmb"nrl b n rl b"n^n )Xlmrlmbmn rl b"nrlmb n rl bmnrl b n^n%5N* b)5%)5b)Xb )%zzb)" !)%*N*h)+Jk*fi|b)5fi k )z'65F *fi)zkJ)5"ff7P SXv'5M!H)|)Yb zx*N*)bm!b)Xb'^!5YpJ$$(N*NYb%)D)^|N)X `%kH)xfi'/ 65S^)zkJ)5" !)X ;) ff.'z(SX/b%)*); zYS*+fi S5b)5cfiff\mfik%AIBBu<6BT\GI|Qu3<DSD98"%kkpSSmD(8( <D"Y<0TD Y.;k\SfGSm\D/fiffmckff ff ff!" #$ ff !% & pDY !('#*)+)*)+#,!.-/#,!012/D(6<#(=(<D"4 3,6;SMI"VK56!('#+)*)+)*#,!0-7QD8:9G;=<?>/@ACBGDk;fD G*2//E(<D"*GFH1IKJMLN4%OPFHMLN?Q#' fi7FH1I/JRLS$Q#KFHTIVURLS$WO:FHMLN?X#fi7FH1I/JRLS$.OPFHTIVURLS$Q#KFHMLN?X#UYZ'= FHTI/J[RLS$Q#KFHTIVU7RLS$Q#KFHTIHMLN(OPFHMLN?X#kkFHTI/J[RLS$Q#KFHTIVU7RLS$.OPFHTIHRLS$Q#VFHRLSHQ)UkSfi(k"\ff]'#$<c4,3 6;SMD"S ^ FH1I U MLN411DfD(-/(<D"UffYZ'#$Y .<43,%fMI""fi<_]Q' \ FH1I?RLS$T (DS6D(6;`\fD(=<DSWff #,YZ'#$YUUU</43,6;Ma"0<VK5 FHTI U MLN4Q#KFHTIHRLS$TafDXbdcu*e6&D(kf]'/<c"`e66pHYZ'sDY DY~<'-SSe6(6g]'UD\DD"%k6f[9B(;`e^/<:ff#,YZ'G#,Y Sf='D (B(<D"UUU4 3,6;SMI"8< <DSc/<&E<06`e^<6p;D (<Dk<fD+2s0fD-+<+2/KE;kSX~ fhi KjAS@lkKmon,;qpHrTtsK>/BGHu%vAgjmxwxj+s/>M\GIKyBKj*z,IjAV{Wr?u^GI.|Z}qASBpt\&AQfiffm [\SfGSm\D%(S7+tA ~+ AQ(D(u-ef7 6!%'#*)+)*)#$!.-]? (jAuKyDcSM/<#Y;DY;<DD(;<.]a;k<8u D"8fD=3;k;S(6;k#;kSXfDckb"./$3,6fMI"S { p(D"cffm 6*Af5f/, .uDS k" Q `vfKq .?Zfiffm S2/D(fi#/$3,6fMI"S { !('#*)+)*)+#,!(Q=(.09 ?\D(YQ ' gff ffff!%Q ' #,ff !(Q ' &uDSf8fKZx"X =<4,3 %fMI""S6!%'#*)+)*)*#$!(#,!%Q ' .v.Suc ^;;<+N72 k+6e ffff!(Q ' #,ff !(Q ' & ffD"D"6D(%f3?Q '?%%fD#DD(;<xuc ;kf"mff;6k#?Q ' fimff 6Pa3(;<\2fi;D*2"0fD p<qcu^;<ce6(;-k-";<8$ 3,6;SMI(;<DSSfi(*22;k+2fDY<vcu^S;Se6(;8"6D(D"0 "fk4 3,6;SMIf"%kkT(<"BS@@5>kfi} \a Y~ t\AQ ffm"'#*)+)*)#f-K AfiYt\&AQQu ff]'#+)*)*)+#,v-/AS#+`\SGm\"(S7 %D \am\ \ \\= =.v$? ( (S^` R\At\ffYZ'&#+)*)*)X#,Y"-K \Gm\Dq(S7 =D mm\^(0 g Y"$jAuKyQ%vauf;S4 (<D/ff]'7#*)+)*)#$v- 6 D(d2D*e6fv %+S(pB(<(afk\ff]'&#*)+)*)#$v- <43,6;SMI"8<0%D" 0v$k;kSb;S;k;;;;<5.;D;D*C_(.6k:Y\D;kS-Xb<;/;D;fff8;k;k%kZ2ck+e6M%R _MY%Xk"DS6D(6;` 8*MY%=(qY" Yd(3D2k+e6-=gY";7fi"Kx+&xt0KKqKK/10t&xtG Q fffiGfi ff! #"%$'&)( *( + -, *./ 012fi #34+656 +8797: +<; 9-(*(=8 +(>@?A3 *( + , *Bfi CD? EF( *(= GC4HI>J$K G9L-MNPO=QSRUT-VWV<XY[Z]\_^a`V<bBRUc[Q%d-Q0bfe<dgO9Q bfe<dgY`he<c!Yji=kWl9` dmY[V<inV<iAoqpGrsd:ZmO=V<lUc[k\!Q#i=V<d6QhkdmO9e<de<i9kt3vuUYjidmO=QwZmd6e<d-Q%bQ id#V<XxdmO=QydmO=QV<T-Q%bzu{YidgO9QSRFT6V{V<X|e<T6QSYi9kFQ%}FQhk\^aop~ hG .Q $ g9%|^AdmO9QBkUQ UiFYjdgYV<iIV<XPo!dmOnT6QhZ6V<clUdmY[V<ic[e^_Q Tw]<#"S yu)e<i9kzdgO_l9Z ? ypQPO9eh_Q:dmO9e<d3 < Y[ZV<Tm*Yi_dmT-VWk{l`QhkfX[T6V<b \^dmO9Q0Q bBRUds^.Z6Qhl=Q%i=`Q0V<XcYd6Q T6e<c[ZP spQ%i=`QuUXV<T ?A3 dgO9Q T6QwQ }WY[Zmd-Z:e2`%c[e<l9Z6Q ? Zml=`6OAdmO9e<d H p!7<9s<(U-= *K( g9#6V<TQ _Q Tm^DtudmO=Q%T-QQ }WY[Zmd-ZeZ6Q dV<Xw` c[e<l9Z6QhZA3!wV<TmYidgT6V{kWl=`QhkXT-V<b \_^Z6V<bQfZ-Q_l9Q i9`hQtV<X#cYd6Q T6e<c[Z|w <hh 0Zml9`6OdmO=e<dfXV<TfQhe`6O>@?A3!dgO9Q T6Q.Q }WY[Zmd-Z:e.`%c[e<l9Z-QyC@?Zml9`6OAdgO9e<dCDH>2p!7<9s<Q $ Dg9#{t ]^dmO=QzkFQ%FiUYdmY[V<i V<Xyo!dmOT6QhZ6V<cjlFdmY[V<ic[e^_Q Thu / YZBeT6QhZ6V<c_Q%i_dV<XZ6V<bQJ` ce<l=Z6QhZ ? #"/e<i=k ff ? 0"2Zml9`6OdmO=e<dfu e<i9kBIp.NPO9Q iz\_^nT6V<R!VZmYdmY[V<iFudmO=Q%T-QJQ }WY[Zmd-ZSeBcjYd6Q T6e<c|Zml=`6OzdgO9e<d H / : 8e<i9k ff H / ] p]^ndmO=QfYi9kWl=`%dgYV<iO_^WR!V<dgO9QhZmY[Zhu]dmO9Q T6QaQ%}{YZgd6Z.etZ6Q dwV<X` ce<l=Z6QZ23 V<Tm*Yi_dmT-VWk{l9`hQkXT6V<b \_^Z6V<bQ.Z6Qhl=Q%i=`QBV<XPcYjd-Q%T-e<cZ/ 8hhh |Zml=`6OdmO=e<dwXV<T/Qe`6O>?3 dgO9Q T6QfQ }{YZmd-Zwe` ce<l=Z6QAC? Zml9`6OdmO=e<dCH>2pNPO=Q%i\_^)Q bJbeA{uPdmO9Q T6QtQ }WY[Zmd-Z/eZ6Q dJV<X` ce<l=Z6QhZJ3GV<Tm*Yi_dmT-VWk{l`QhkXT-V<b / 8 \_^BZ6V<bQ:Z6Qhl=Q%i=`QV<XcjYd6Q T6e<c[Zv| # # Zml=`6OfdgO9e<dXV<TQhe`6OA>y?A3x dgO9Q T6QwQ }W Y[Zmd-Z:e2`%c[e<l9Z6QC@?Zml9`6OAdgO9e<dC@HI>y p hh]^2dgO9QSYi9k{l9` dmY[V<itO^{R!V<dmO=QZgYZhudmO9Q T6Qffe<cZ-V.Q%}{YZgd6ZPe.Z-Q%dV<X`%c[e<l9Z-QZ3 V<Tm*Yi_dmT6V{kWl=`QhktXT6V<b ff \_^Z6V<bQ]Z-Q_l9Q i9`hQ:V<XcYjd-Q%T-e<cZv <hh =Zml9`6O2dgO9e<d|XV<TQhe`6OJ>@?A3 dmO=Q%T-Q0Q%}{Y[Zmd6Ze`%c[e<l9Z-QCD? Zml=`6OdmO=e<d0C@HI>2pNPO9Q if\_^Q%bBbeS{uUdmO=Q%T-QyQ }WY[Zmd-Z:e.Z6Q d:V<Xx` c[e<l9Z6QhZ03 V<Tg*Yji_dgT6V{kWl9`hQhkXT-V<b / \_^Z6V<bQ#Z-Q_l9Q i9`hQSV<XGcjYd6Q T6e<c[Z0| w hh ff )Zml=`6OdmO=e<d0XV<T0Qhe`6OA>y?A3GdmO=Q%T-QwQ }WY[Zmd6qZ e/` c[e< l9Z6QffCD? Zml9`6OAdgO9e<dC@HI>ypNPO=Q%i2YdqXV<cjc[V#ZqX[T6V<bdgO9QkUQ UiFYjdgYV<iaV<XV<Tg*Yji_dgT6V{kWl` dmY[VidmO=e<d03 3 3 Y[ZeyZ6Q dV<X)` c[e<l9Z6QhZV<Tm*Yi_dmT-VWk{l`QhkXT-V<b / \^ hhh hh pqPV<i=Z6Q_l9Q i_dmc^_uUdmO=Q%T-QSQ }{YZmd-ZefZ-Q%dV<Xv`%c[e<l9Z-QZ3 V<Tg*Yji_dmT-VWk{l9`hQkX[T6V<b / Zml=`6OzdgO9e<dXV<TffQe`6On>?3 dgO9Q T6Q2Q }WY[Zmd6Ze` ce<l=Z6QyCD? Zml=`6OdmO=e<dSC4HI>2p!:x ?G 9Lff ?*[rsidmO=QfZ6Qh` dmY[V<iFpYdyveZwkUQhZ6` TmY\!QkO=VeT-Qk{l9` dmY[V<iV<XQ%i=Q%T-e<cjY[e<dgYV<i`he<i\!QBe`6OUY[Q%_Qhk\_^T6Q RUc[e` Yji=ze` c[e<l9Z6QB\^eAZ6Q dwV<X`%c[e<l9Z6QhZhp Q%T-QvQBZmO9VhO9VhdmOUY[ZwZ6Q dwV<X#`%c[e<l9Z6QhZwQhlFYje<cQ i_dmc^`he<i'\!QkUQhZ6`%TgYj\!Qhkt\^teBZmYi9<c[Qw` ce<l=Z6QuOUY[`6O'vQw`he<cjcGe<inQ%}{R9e<i=ZmYV<iV<XdmO=Q.V<TmY[<Yji=e<c]` c[e<l9Z6Qp#]^kUQ UiFYjdgYV<i)uvYXe` ce<l=Z6QC<sZglU\9ZglUbQZBQ%_Q Tm^I`%c[e<l9Z6QYjienZ6Q%d2V<X` ce<l=Z6QhZJ3vuqdgO9Q iCYjcc:e<c[Z6V<sZmlF\9ZmlFbfQe<iGySffV<X3vpGNvOUY[ZPcQhekUZ|l9ZPd-V.V<lUT0kFQ%FiUYdmY[V<itV<XxQ }WR=e<i9ZmY[V<itV<Xx` c[e<l9Z6QhZhpqNPO=Q0YkFQeV<XQ }WR=e<i9ZmY[V<inV<X` ce<l=Z6QZvPeZ:FT6Zmd0RFT6QhZ6Q%i_d-QkA\_^Ar1kUQhZmd6e<bBs0cjblFYZgd0g`8"%p_0 gt7)Q \!Q:eff`%c[e<l9Z6Q0e<i=kfeffZ6Q_l9Q i9`hQ0V<XcjYd6Q T6e<c[ZhpGNvO9Q ifeff`%c[e<l9Z6Q0>Y[Ze<,=<UV<X \_^AYXe<i9kAV<iFcj^YjXG>4Y[Z:e<iAxffSwV<Xqe/Z-Q%dV<X`%c[e<l9Z-QZ0V<Tg*Yji_dmT-VWk{l`hQktXT-V<b \^'p?xKGSlKo4*[*RHG[*R7^?RH/+QRGC?&70H? QG/ / Q QGQGxQ/ QGfi= 0<!U[:)=fffi!"$#%&'(*),+.-/+102+4365ff5879-/+4365:5<;)>+.-/+10 ?@+BA5ff5C7D-/+BA525<;==FE)>+.-/+10 ?@+BA5ff5G7H-/+I0KJL+4AM55<;-/+BA525;=)>+.-/+10 ?@+BA5ff5;-/+10KJL+4AM55<;-/+I0/+BA57D-/+BA525;J=)>+.-/+10 ?@+BA5ff5;-/+10KJL+4AM55N7D-/+I0/+BA5ff5;K-/+BA525; # fi?)>+-/+I0/+4365ff5;K-/+I0 ?P+BA5ff5C79-/+4AM5;-/+4365:5<QR ST/" #% &VUW=FE ; =; =JOe$V#gf:hihkj/UW=FE ; =J; =/ffY4Z&[fi@% \fiF$&]*C$#%&G=*^P_!` -/+I0KJa+BA5ff5;$-/+102+4AM55cbcd #fi?.XT\mP%"Pff_ Oe$V#gn[o# ff$!p=>^P_q` -/+I0KJZ+4AM55<;T-/+10/+BA5ff5Ib?.XPlrs&gff #]toM$\#u#av^pw&fi@% \fix&yjY1ff%^ff%]!off$zwff{n#]toM$F#^p|P#|PU6 9=[. /:M/Z=lxW[\[\ @L6TL[\IL=yg2 \gO*=yk.pTN_ufffiM"MMff$sn[o# ff/W6Nv/TV=<g" LZ.T8LKOLg@ \Dff #gff"&"n[ffTv#u&F$#%T\g>ffYZ&[fi@% \fi &]=^P_%&q#O#qf:hihkjvSN_{ff vfiM"MG#yf:hhj#a&RP%iUWOlk#|Pv=H}lq}(*~=# fi (= ^%Min[o# ffuOV=9s#\|P (lGn@o #ff$#v^pV&a#&fi\fig#a:#&#ff]{#ff$g&&MmP% ffS"n[o#K#$#%T$$#_mP%M|a# "P&ff v" #% &&TlX)^P_qG&opaffff$yg=~~=N_{R \T] #|PUW=llR"^Z_STopafful&mZ% Pff_ O*=Xk~lR"q^P_qff fiM"MwV#fhhj #\|Pv=lBk#a&#fiT\mP%"Pff_yOs#a&e#filD$\*oMT\|Pv#s"|P_a T#$#ff$%M fiM"k]toM#ff$G#t$#%&iff"&"n[ffT#wn[o# ffNg$#%TF%&#iffta""&##ff$x%M fiM"v]!o$\#u$T\fi[%\fiTq#a""&##ff$y%MfijY1ff%^ff%]!off$Ul*[. M&t@S2a6*g(<\ Z.LK{=x4$ [KWj&.2:.KL[ZL TL1<" LZ.!\<x4TL[\ILgO=\T{4W(#a&2.6Gt/T=y/\4\Tq<L<4LOtk.pT!N_w&$#ff_W "&tn[&#$#%&g=!_)G2K2.42e(~5 %&#=!=vT]XN_{R&"]a "&v"n@$ffT#&"V" #% &s:KY4P&[fi@%fi T]=!Kff% &qff #l::#|P(R"kB$\ T]f2"]!]{#t[ff #vff T!"n@$ffT#Til" #% &\ffY4Z&[fi@% \fix T]=ff% &#si#a&R y$sO^p9 #\|P (l#xfhhj8 # fiffP% #x"n@o #ff$z= #fiu#|P (OD^P_tfiM"M#f:hihkjV + U (,lB:xpHvPW2.6hk""&#$\#%fig]!o$\##y$#%T!#x^pg&fi@%fiTya T#$\#F%fitjYff%^ff%]!off$#x"n@o #ff$"$#%&!#T!o #ffff$"%M$#ff_zP&"&ffT\fizx"n@o #ff$l{}"$#%&ff% &xff #"|P_a""&##ff$z%M fiM"]toM$\#u&fi@% \fix&q#a""&#$\#%M fiM"jY1ff%M^ ff%M]toMu:#o#ff$% #i"n@o #ff$LWllfiPWffPa[ p8PP[6W$\a[ pptGW " Zfi ff!"$#&%(')#+*,-/.0#+102435#+14(6870#+1,:9);+1<;+= 4>@?BA(13C9ff,D#EGFHIKJffLNMOLPLGQGI0R+SUTWVXFS;+=YZ9[=@#+12\;+1]'[^_9[=:.]=;+`a(b(`:^\%(')#+*,-$cd.Ucfeg3ihDA(1(b`ackjl4>o%W#+'p'OA#+P#+1q(6870#+1,:9);+1r;+=B#%('ff#+*0,-P9),s#_%')#+*,-/.t#+12:A*,$uU1U9p-/>wv4*0xyx+'ff(-;+1z#+12|{Y#yxyn}:~Wyy ./70#yxy ~Wy A#y, ,:A0;Wh1OA#+%o;+7]'ff(-B67#+10,:9ff;+10,o./hA]9ff%-AOA(^%W#+'p'Uu]1U9p-,N'p=ff,-#+O*U`N#+:9);+1,o.2U;10;+a69ff,O=;+`a#+'p'%')#+*,-o,o>U5-\K- ( Ut tt/t0L(GL\LNQyVpTGM$S"F+SUMOR/MOF+JffFGVXEGRJE(JffR/TLNT@FsUVXEG&M0LWNLPLGQVpTGMSKF_EGF+HIKJffLNMOL$LNQIRSTWVXFSTW?A041;+1U(69ff,:N10%Wz;+=%o;+7]'ff(-(6870#+1,:9);+1,_9ff,_28*-;rOA#+_=;+`4,-;+_\%('ff#+*0,-o,:A0`N|#+`N9p1UuU1]9[N'p^<#+1^429ff,:O9[10%wxy10`N#+'[9)o#+:9);+1,P*U102U(`P9p7]'[9)%W#+O9ff;+1t>$BW%o#+*,N;+=OAU9),shBP:*U`O1|N;:A07U`N;+U');+=$`-o28*%(9p1xb(`:^xy(1(`-#+'p9ffo#+:9);+1*U102U(`?9[7U'p9)%W#+O9ff;+1-;r#zxy10`N#+'[9)W#+O9ff;+1*]12]`,:*],:*]7]:9);+1;+=@#,:9[10x+'ff$67#+10,:9);+1>fi ff|a"P#d%')#+*,-/.35#+1<(6870#+1,:9);+1|;+= #+124#&N`O,-(a;+=B>D?A01<3C9),#GEGFHIKJffLNMOLLNQIRSTWVXFS;+=Bh$> `> >Ki9p=#+12q;+1U'p^49[=:."=;+`(b(`:^<%')#+*,N&c.ce3hA010b(`cjz>t0Y ;+10,:9ff2]`nOA=;+'p'ff;oh9[10x%(')#+*,-o,ocncn!33}+}X}:Z}KG}+}X }:}8G}}0/}UOZ}]t}+}X }:G}X08}UO }]G} #+102}+}X}OGK} }8OG}X08}UO@}]G}G}G?A0%('ff#+*0,-W,c #+12c #+`-_7U`-;+7"(`d9[10289p`-o%`N;8;+N,d;+=n4. ,:*%-ArOA#+c jz#+12c jz>q?A0\%('ff#+*0,-\3 9),#+167#+10,:9);+1;+=/^ } }]: .#+123 9ff,#+1(6870#+1,:9);+1;+=s^}X }UOG}X0/}UOG}X}]: >?A0s(6870#+1,:9);+1<3 9ff,#d?%o;+7U')N(67#+1,O9ff;+1U*]a3 9ff,10;+o>1:A(6]#+7]'ffP#+";obP:A0&?B%W;+7U')NP(6870#+1,:9);+1|3 ;+=9ff,a#+'),-;#_%W;+7U')(-P(6870#+1,:9);+1+; =a>za;WhBb(`o.9p1%W;+1O`-#y,:_-;<%W;+7U')N(6870#+1,:9);+1,.B?%o;+7U')N\67#+10,:9);+1,69ff,O=;+`#+'['1;+1]-#+*]-;+');yx9)%o#+'%(')#+*,-o,o>U5- ]t N/Kz@ / t0tt/LNMUGLRDSKFSMOR+/MOFJffFNVEGR+JUEWJpR/TLRSKaRMOL((HTLNMDF\8t0L(S_M0LWNLPLGQVpTGMTwRGEGFHIKJffLNMOLLNQGI0RSTWVXFSd3F (pMU$"Nq^r?A0W;+`N ~W .OA(`-69),:-,#q%W;+7U')Ns?;+=$\4h$> `> >>(1%o/.@=;+`(b`O^%')#+*,-c.09p= c5jz:A01qcZe>s^\:A02U(uU1]9[O9ff;+1z;+=#_%W;+7U')(-Ps?.hBA#objz_.U#+12OA(1\^\B;+`-;+'p'ff#+`O^ .j>^&OAo;+`-( .U:A0`N(689),:N,#+1\(67#+1,O9ff;+13;+=,O*%-A<:A#+!e3d>?A*0,o.K=;+`(b`O^%')#+*,-wcd.]9p= cfjr:A(1qce3d."#+12%W;+10,-o/*01:'p^3i9),#d?%o;+7]'ff(-(6870#+1,:9);+1;+=YZh$> `> >]>=hB%o#+1%W;+7U*]-?B%W;+7U')N(6870#+1,:9);+1,;+= #d,-(n;+= %')#+*,NW,OA(1hB%o#+1\*0,-P{ 'ff;+O89p1,+# ')xy;+`:9p:AUl=;+`%o;+7]*UO9[10x4#+1| -;%W;+7U*]-#+1q?>K`N;+:A0w7]`-;;+=;+=B?Ao;+`-(l9pn=;+'p'ff;ohn,n:A#+:A0P%o#+1289)2U#+N,Na;+=Y'p9[N`N#+'ff,a-;d"*0,-W2\N;%o;+7]*UNP#?B%W;+7U')N(6870#+1,:9);+19),Du]1U9p-/>&9[10%W(6870#+1,:9);+1|9),aW*U9pby#+')10%W7]`-o,-`Ob89p1x\hB%o;+*U')2,O9[7U'p^\-o,:#+'p' 289p"`N1hB#W^],-;(6870#+12#d%')#+*,-$/^,-W*(1%oo,n;+=Y'[9p-(`-#+'),n=ff`-;+:A]9ff,a%o#+1289)2U#+Nd,-.0#+1029p1\OAU9),DhB#W^;+U-#+9p1#r?%o;+7U')N(67#+1,O9ff;+1t>?A]9ff,9ff,;+=P%o;+*U`N,-|#+16:`N_'p^%o;+7]'ff(67U`N;8%oW,N,o.U*]4#+')o#y,::A0W;+`NO9ff%o#+'p'[^8.K?%o;+7]'ff(-(6870#+1,:9);+1,#+124s?D,#+`NP%W;+7U*]-#+]'ff/>fiX0/G fffi)G"!#%$ff&(')*,+.-0/21(+43656708:9;+28<5=->+@? ACBDFEG+IHJBKMLN+IO>+IAC/EP9GQR/569;BOSBKMTIEG/703C+R3RUWVOX3C+2TI569;BOZY\[^]_+8F+23CTIA69PDff+R8<56-0+KGA`/HW+I]_BA6aKbBA_LN+cO0+cA`/Ed9;QR/569;BOeBKTcE;/7>3C+R3f8 +I1(+cE;B?ff+28D(g@hiE;B56a\9dOkj=l2m(noF[pl2m(n\lcD^[ql2m(n\l2/(rc[F]M-F9GTC-9;3D>/N3`+284BOWst367FD>367FH?F569;BOUuVH?FEd9;T2/5=9GBO9;3i5=->+vHWBN3=5O>/567FAC/EwD0/N369;3xKbBAf9PO>8:70Tc5=9d1(+yLN+cO0+cA`/Ed9;QR/569;BOUVOe3C+RTc5=9GBO"Y\[ ]_+z56-0+cA`+cK{BAC+|/E;3CB3656708:9;+28}5=->+~5=->+RBA6geBKiLN+cO0+cA`/Ed9;Q2/5=9GBO"7FO>8 +IAv9dH@? EP9;T2/5=9GBO^Uu-0+~TRBO(5C+IO5`3zBKi3C+2TI569;BO"Y|TR/O}Dff+~367FHH4/A69;QR+28@/N3uKbBEPE;B2]3RlNUV5_9G3M8F+2TI9;8 /D E;+~]M-0+c5=->+IA/|TcE;/7>3C+yst367 D0367 H4+R3/O>B56-0+cATIEG/703C+UY\Uu->+IAC+_+c\9G3=5C3w/ME;+2/N3=5LN+cO0+cA`/E>LN+IO>+IAC/EP9GQR/569;BO@7 O>8F+cAst3=7 D>3=7 H@? 569;BOkj{~zs(rBK>+I1(+cA=g~ OF9d5`+3C+c5BKTIEG/703C+23UUV5_9G3u7FO>8F+2TI9G8F/D E;+]M->+I56-0+cA/|TIEG/703C+z9PH@? EP9G+R3u/O0B56->+IATcE;/7>3`+NUUV5f9G3_/O}B?ff+IOW?FACBD E;+IH]M-0+c5=->+IAM56-0+cA`+~+I:9;365`3u/E;+2/N365_LN+IO>+IAC/EwLN+IO>+IAC/EP9;Q2/5=9GBOe7FO>8 +IA9PH?FEd9PtT2/5=9GBO,jwyzV=ruBK+I1(+cA=gW OF9d5`+3C+I5MBKTIE;/7>3C+R3RUUut9dH@? EP9;T2/5=9GBOS9;3/,3656A=9GTI56EPg3=56ACBO0LN+cAAC+IEG/5=9GBODff+c5]_+2+IO%TIEG/703C+R356-0/O9PH?FEd9;TR/569;BO[M/O>83656A=9GTI56EPg]_+2/a(+IA}5=->/Ost367 D0367 H@? 5=9GBO^[y/O08ut9PH?FEd9;T2/5=9GBOT2/ODff+2TRBHW+"/O/A=D 9P56A`/A69PEdgLNB:B\8}/? ?FACBR:9PHW/5=9GBOBKw9PH@? EP9GTR/569;BOWD(ge+I:5`+cO08:9PO>L56-0+T2BO0369;8 +IAC+R85`+cA=H3C+c5UUV5_9G3M8F+2TI9;8 /D E;+~]M-0+c5=->+IA/|TcE;/7>3C+yut9PH?FEd9;+23_/O>B5=->+IAzTIE;/7>3C+Un\Uu->+IAC+M+I\9G365`3/E;+R/N365LN+cO0+cA`/EffLN+cO0+cA`/Ed9;QR/569;BO7FO>8 +IA_ut9dH@? EP9;T2/5=9GBOjw~r^BKff+I1(+cA=g OF9d5`+3C+c5BKTIEG/703C+23UV O~3`+2TI569;BO []u+365=7>8\9G+R8~56-0+x8\9dff+IAC+IO>TR+xDff+I5]u+R+IOst367FD>367FH?F569;BO/O>8z9PH@? EP9GTR/569;BO~BO.TcE;/7>3`+23RU*,+.?FAC+R3C+IO5`+28ZB7FA/?F? ACBN/NTC-Z5`B} O08/EdELN+IO>+IAC/EP9;Q2/5=9GBO03.7FO>8F+cA9PH@? EP9GTR/569;BO[^D(gkA`+28\7>TI9dO0Le9dH@t? EP9;T2/5=9GBO,5CB}st367FD>367FH?F569;BOUu-F9G3TR/ODff+|/NTC-F9G+I1(+28D(gk9PO(1(+cA=569PO>L"3C+IEdK;tAC+R3CBEP7 569;BO[/O>8"]u+|8F+ct3CTIA69PDff+28Z/}5`+2TC-FO 9;70+}KbBA|9PO(1(+cA=569PO>LA`+23`BEd7F569;BOD0/N3C+R8ZBOZBA6t9PO(56ACB\8:7qTc5=9GBOBKMEd9P5C+IAC/E;3RUk*,+W/E;3CB8 +R3CTIA69PDff+28X+c\?>/O0369GBOBKMTIEG/703C+23[]M-F9GTC-X367 H@HW/A=9GQR+R3B7FA9;8 +R/eBKuAC+R8:70Tc5=9GBOSBK_9dH@? EP9;T2/5=9GBO5CBst367FD>367FH?F569;BOUu-0+~TRBO(5C+IO5`3zBKi3C+2TI569;BO TR/O}Dff+~367FHH4/A69;QR+28@/N3uKbBEPE;B2]3RlNUOk+c\?>/O0369GBO,BK/@TcE;/7>3C+9;3/O"wyzsBKf/3C+c5vBKfTIEG/703C+R3BDF5C/9PO>+R8kD(g"BA=t9dO(56A`B:8\7TI569;BOKGACBH56-0+~TIEG/703C+UY\UBAx+I1(+IA6gLN+IO>+IAC/EP9GQR/569;BO}7 O08 +IAu9PH?FEd9;TR/569;BOBK^/TcE;/7>3`+M56->+IAC++I:9;365C3/O4+c\?>/O0369;BO}BKff56-0+TcE;/7>3C+[FE;BNL9;T2/EPEdg+2(7 9P1N/E;+cO(5v5CB56-0+TIEG/703C+N[ff367>TC-"56-0/5v56->+.LN+cO0+cA`/Ed9;Q2/5=9GBO7 O08 +IAz9PH@? EP9GTR/t569;BO}9G3_AC+R8:7>TR+R85`B/|LN+cO0+cA`/Ed9;Q2/5=9GBO7 O08 +IAst367 D0367 H@? 5=9GBO^UUu->+IAC+e+I:9;365O>BOFt5C/7F5CBE;BNL9GTR/E|TIEG/703C+23KbBA@]M-F9GTC-S56-0+cA`++I\9G365|O0BTRBH?FEG+I5C+}+I\?>/O>3=9GBO03R[]M- 9;TC-H4+R/O>3|56-0/5W56-0+cA`+"/AC+eO>B+I\?>/O>3=9GBO03}BKz5=->+"TIEG/703C+23@3670TC-5=->/5}+I1(+IA6gLN+cO0+cA`/Edt9GQR/569;BO7FO>8F+cAy9dH@? EP9GTR/569;BO9G3AC+R8:70T2+R8<5`B}/WLN+IO>+IAC/EP9GQR/569;BO7FO>8 +IAst3=7 D>3=7 H@? 569;BOZBKf56-0++c\?>/O0369GBO03RUUBA+R/NTC-O>BOFt5C/7 5`BEGBNL9;TR/EvTIE;/7>3C+@56->+IAC+4+c\9;365C3/e_tT2BH@? E;+c5`++I\?>/O>3=9GBO^[i]M- 9;TC-H4+2/O0356->/5_+I1(+cA=gLN+IO>+IAC/EP9;Q2/5=9GBO}7FO>8F+cAut9dH@? EP9;T2/5=9GBO4BKff56->+vTIEG/703C+M9;3iA`+28\7>TR+28@5CB/yLN+cO0+cA`/Ed9;Q2/t569;BO}7 O08 +IAzst3=7 D>3=7 H@? 569;BOBKw56-0+~+I:?0/O>369;BOU2fi(>(\;2N\GffWff@>>I(>>0"(G(N\Gffv>`2"dCRI6;F\puRFGIC.c\>06G0~0~zMCRF CFGq F60C2@ FC6;GI:=CIWIP}RN66P(u ;M;06 = 6;6P>}=d02FvGC4Iu=ebNc0c`d@;2=GF>Fc|PFd;R6;<;z>N`2X>I\CI> G=:Pz;C4c_6,b|NI>ICP;2=G0 Iv6 06 @ =G^0MFGCePCRN:6 ffICM;CRFGI:PFCFGIWiNc0c`ww~~CIfc;>CRWR|CR%I:ff0c(6;Pd@d|=>( |ffIuIG0CRiP6>vCI{e>N;IC}I>F>2NN(cii(Iwy`2\>R2 0 Iu6F>6FF6;:MFGC420^60uP Pd`c`G=>C`2\ >F(F>Fc6 06 @ =Ge`CIWR(2p(42C2c\ff>I(6;dP@d@60(F|ffc_IG0C2{v;c`N2NN(P>R<I:0>6;f4c;>C|;v<~fWCIu=d(=C\:>RRIG0C260uRF `6;>RN6w0|I:0>6;CRc\ff>I(6;dPP~=>x(F|ffcFdPCIC;>`2@d46>y6P(6C\:0c`GMW60zR@ `6;"w_2@ ;c`vc\>06G"yG`N( |ffIPd`c`G42ffWR>6; ICRffM>ZR>`2(>I(6P=>CS"2@ FC=GS_ ;Xff4c\6`c4IdRN66P(2_I(cFP60>i;6\PxG`WI_6@bNI>ICPGR6;e 0 Iv6 06 @ =GG_2@FC=G0dPc\ffc06P(N0P>NMffRIeMGFcPW0CReN=>RCI6;2;C4c_6p__>IeCW(Pu `Nc=GRq( |ffI:PffICIv`26=6;c=G0z460~IG0C^;>0NN~>NMffRck206GFc`2pb.cF@ ;|GN ICI6@d0Nc{e0NGICZ I>Ff2NN(,}6PPG_2"_|>ffCWF>CR6=6;c=G0M >Fc ;CWFM>IC `2`c(CR}G`WI_6@bMNI>ICP;2=GeF> IMPFd;R6;R}ffzFCNI6;2Pd>CIGFR6C@d4( ;662NN^2NNN(0NW RCI6Pff2<`2CF ;0k`c@IGI(6PS2@ FC"CR6=6;c`2Sb=vNc0c`d;R6;>WF> I@d@ PGR6;S2Rc(=d:xe>N;c`0NFCRCc(`2>=>IF CNNC,>NCR""Nc0c`6P>e|( |ffIc;>CRRq`Rd;Re6 FC6FC\CRwM ;CC20:; CRbffId0P>\d`2IC\CR:060cCR6=d0M0c=>I6>I|`uCv>e>N;cC^p2N(NciuFGf FCNNCe@G(ffz_2CW`c@IGI(6P2@ FCC4MNI>ICPGR6;>0 Id@ PGR6;:4f `NNC>Rx`;R6|CRI C=d(MFcF P6;>z;CRI C=d(u;N;x `NC4("Nc0c`d;R6;< 0 IzP@ PGR6;e>R(ff2I" CRCI(CRS{ffd(`kMP2N(\^>F^ffP(CupP>FikMP2NNFu R6C@d4( ;6R_2N(Nu>RCWF `NNC>RWC4>NCR%=660c= `>P 6;}y6>P(ccFFGRRM k26>RCI6;RdPff RCI6Pff2PG`WI_6p660:Z(Su0c=2N(Fz2N(q|6>4GR60 PdP`2I `6P(}GN;W `NC4|>N`c\;>6P}ffRc}FCRCI`2eP}6FG=>f}= ;660:}Pu_N6>RM}=>v|CRcFC6P(~;NG`NC R>6;66P>Zy>eR>=C(6Fc>` ICI6@d0C"c;NCR(6SCRI C=d(c;>`e>>|R>=C(6FcFCZ ICI6@P>C|0 CRI C=d(@c;>`~Gvx;2=>FG|P(c"NF:P6;>6>N`cRNC|CNI; FqMFGCFc`c=P>RPffN6d=d(.cFFGGvR2(ICRk(}=>0 CRI C=d(>N`I;>C|f60`CNI~ `NCJG0N|v_N~;CW=>2<60NI>ICPGIP>}6FGyc;NC;2= P><FC ;I dZ06FCvuR;2NF.`<"RF C=G0dP:P@cFd|FC ;I"Zu ;CR6FdM`cP;u>u=>`|c@IGI(6PW;2=}W`v2@ ;c`2I `6d((:ff=>RC2vC4vc\6`|dFb646;60C@N= ;u4:Fc;_{vGIC`ffc2N(N CN` CRcFC6;4CC>IWRf @bIPP;CC2NN(Gu02R Rffu0xR(6=dF C;>_>6FGw0ffc`i= CRIb;ff d`6Ru>R(u6F6`c46;2PP`c\;c_2.>:;CI>C`2"60R>RI CyCIGIN(~`WNI>ICPGR6;P<@ C=6CFc`c=6P>F\2R>p_~>R(P=C\:02RWuP@ PGR6;N=6C0Ncfb= P@ PGR6;MFGC|;w RIGF ;uffc_2I@c;>`2RuFd`ff^u02(G =60cFc(IGffRFCI:;>yu=f60 604{ R6`PW( ;6R2NNN4c\CI>\d0;6\d^ fGC4Iu={MNI>ICPGR6;e 0 I6F>6FF6;}CNI>ICP;2=G0 Ivd@ PGR6;fifffi !"$#&%'(*),+.-0/21436570895:;5-=<>?A@BDC!EGFH@2I!JLKNM'OH@PFQIRFH@C!S&TU?VI!JHT,BXWNY2JQC!SZ\[B SU]^I!J_M`S,abC!WcE2C!dGWeBf@2BXW`gUhiI!S2hiBXJHS&McS2jkFH@BDKlI!JHTPI!SU?AmMcnDgGW`M'hC!FoMeI!S=pD?A@2BLC!EGFH@2I!JLC!W'OQIqKrMeOH@*FsIRFH@2C!SGTUt,@2C!S&m6u KlB\Mlv MeBXS&@,EGw&OHmyxz@2BXS2jG{}| I!S2C!W'~~GB_I!Wc]C!S2~FH@BC!SI!SwnI!E2OqJsB\aMeBXKlB\JsOD]I!JCS,E&n_d$BXJRI!]FH@2I!Ej!@,FH]eEW_hI!nfnB\S,FQOLC!S~OHEjbjbBOHFoMeI!SOI!]McnDgGJQIa,BXnB\S,FQOp?A@GMeOKlI!JHT@2CbO.d$BiB\S_OoE&g&g$I!JoFQBi~d,wFo@2BrtKlB~MeOH@L| BiOQBiC!JQhQ@fxAI!EGS2hXM`W]I!JS2j!McS2BiB\JoM`Sjth\M'B\ShBiO?rY.|}C!S2~RFo@2BE&JsI!g$BC!SkxlI!nDn_EGS&McFwltz| ?A| b,!fS~Eh\FoM`a,B_Ibj!Meh0JsIbj!JQC!nfnDMcS2jGp*52Q5,5-)&5>@2CG{._pp`{=C!g$I!McS,FQB{Atpc{VMcS2jG{xpp`{*C!F6KNMcS9{tp Hbb p*S,a,BXJHFHMcS2jkM`nfg&WcM'hC!FoMeI!SPKNM`Fo@OHnqC!WcW=FoJQC!McS&McS2jOQBXFQOp6Szfi_y29fiX&zs!UAfis_fi*k,s&$!X2^!p&t,g&JHMcS2jbBXJHmzBXJHW'CbjpAC!McS9{p`{E2jbj!W'BXFQI!S9{ztp Hb b\pfvI!SGmnqI!SI!FQI!S&M'hDW'BiC!JHS&McS2jGpq6SE2jbj!W'BXFQI!S9{tp z~$p{.\!2s^fi fiAsfifi__!p,hiCb~&BXnfMehJQBiOQOi{2=I!S2~GI!S9px}@C!S2jG{xpc{2=BiB{G|p H,! \pfiD! sbfisfi2fi2fiXAsfi^!p.hiCb~&BXnfMeh0JsBOQO{I!S2~GI!S9pxAI!@B\S={p Hb, C,p.Cbh\mW'BC!JoS&McS2j_JQBihXE&JQOoM`a,BWeIbj!M'h g&JsIbj!JQC!nOi}0fhXMeBXS,FAC!W'jbI!JHMcFH@GnqOpNfiXfiyAfi&XoX^e,X$rrsfis{${ &!b pxAI!@B\S={0p Hb, dp.Cbh\mW'BC!JoS&McS2j*JQBih\EGJQOHMca,BqW'Ibj!Mehfg&JsIbj!JQC!nOiDvBjbC!FoM`a,BfJQBiOHE&WcFQOipfiXfiAyAfi&XoX^e,X$rrsfis{${ !G&b! pC!WcWcMeBXJi{AGpVup Hb ,\p sb fiAfioXD9X6X9fi,fi bofiD=fiszfifipuC!Jog$B\J | IKE&dGW`M'OH@B\JsOipI!FoFHW'I!d9{ p Hb, \ptE&dOHE&nfg&FoMeI!SPC!S2~*McnDgGW`M'hC!FoMeI!S=pXfiXDi6!As^ soQX{ b\{bb puC!nD]^B\WcFi{2p`{2v McWeOsOQI!S9{$&pYlp obb p6S2~E2hXFHMca,BnqBXFQC!W'Ibj!M'hg&JsIbj!JQC!nfnDMcS2jGpA6SPAsfi&y2 9fisL\oXfifiA4fiskfif\fi2sb sbrAsfifi__!p BiOQBXW`W'OQhQ@2C!]'FA]E& JC!Fo@2BXnqC!FoM`TfE&S~C!FsB\S,a,BXJQC!Jod$B\McFHE2SjRn_d2u{&ACb~RuI!SGS2BX]!AI!SGS9{ B\JonqC!S,wpuB\Wc]eF{rvp ob, pS~Eh\FoM`a,BPjbB\SB\JsC!W`M'ZC!FoMeI!S=W'Ibj!M'hC!W]eJsC!nqBXKlI!JHTpSAsfi&R9fiAs2fi4fisfi&9s6!fi fiX2fipGt,Mej!nC_JQBiOQOi{&McW`nOHW'IK{S2j!W'C!S2~pu E&nBb{pc{tC!nDn_EGFi{xp HbG \pOHMcS2jM`S,a,BXJQOQBLJQBiOQI!WcE&FHM'I!SUFQIRW'BiC!JHSJsB\W'C!FHM'I!S2O]'JQI!nBXg$BXJHmM`nB\S,FsOip6SzfiLyAc,R\&oXXfifi4fiQsfik& !X2^!pI!JsjbC!S*C!EG]enC!S&S=py~&BiOHFQC!nfm6 W`nEGMeOoFi{fi0p ob bp==BiC!JHSGM`SjnDM'OQOHMcS2jhXWeC!EOQBiOVd,w_McS,a,B\JsOQB JQBiOQI!W`EGFHM'I!S9p=6SRAfi0VXoXXfifiAfisX$}fi0 sDXsfiqAfibo$ioXA&,!pbr@GnqOo@2C0EGd&WcMeOH@B\JsOi{?VI!Tw,IGpfifir,2,$ fffiX2,,$!#"%$'& ()*+&-,/.102"!3547698#:<;;=$>?6A@CBEDffBEFHGJILKNMOGPQKSRJDTRUWVIGJX/YOBHYE6Z4\[]6_^`6a"#[b<20!3c^dfeb$'g#"#&-Eh/"ji'kl i'&me1."Hfgd$'honp#"Hf&-CnrqE0fhbq<!!3]n/"Hirq%s[i'*N&uth0NvfgH#0N"Sp$'hbWwi!p$'*7h#"20+"2."% i'kxy!q%[(hi'*iz'p6!#"%$'& ()*+&-,/.102"!3{476|8#:<;;='}~>f6EhEg%$'*N0!$'"#0i'h.h1fg0N&me1*+0q<$'"20i'h}/pgH<qE.gH#0Nv$'h/"20+(.h0Nq!$'"#0i'h65h5FHRO?B?B?JKDYRQUPbBmBEDPfDP2B<FEDGPQKSRJDGJIVR'D!UBEF?BED?BdRJD-oGHKDBB?GJFEDKD'6i'g%z$'hd$'.k& $'h1h6!#"%$'& ()*+&-,/.102"!347682:<;;=q>f61dfhbfgH$'*+0!$'"#0i'h.h1fg0N&me1*+0q!$'"#0i'h}p.b#0NhzCi'g#(0Nh"#g%i.~qE"#0i'h6bhF?R?B?B?JKDOYCRU9PbBKP5XrF?RHbB?GJDV5RJD<UBEF?BED?BCRJD-oGHKDffB9B?GJFEDKDJ6n/eg20+hbzfg2(fg2*$z16!#"%$'& ()*+&-,/.102"!3r4\68#:<;;>f6\\ qE0Eh"0Nh.qE"#0i'hi'k]gH<qE.gH#0+vdEh10+"20i'hb}/p-#"2g#.qE"#.1g%$'*$'hb$'*+(p#0i'k%$'"#.1g%$'"20i'hb!6h|5FHR?B?B?JKDY`RQUPbB\K UHP EDP2BEFEDGPQKSRJDGJIjR'FHOY?R?RJDfDJXHPQKBRHJKd5F?RHJF?GJKD'6~^Ee$'g2"#&-fh"i'k l i'& e.1"%EgnrqE0fhbq</3d$'"#[bi'*+0Esmth0NvEg%#0N"%E0+"]E.(vfh]31f*z'0+.1&6C0E"%/3a16 (t678#:<;;=>?6 )q!i'& e$'g%$'"20+v #"2.rp|i'kc2"#g#.bqf"2.gH$'*c& i2"2eff<qE0+bqzfhbfgH$'*+0<$'"20i'hb.%!0+h&-$q%[0Nh*<$'g2h0Nhz16h|j.bzz'*E"%i'h]3an678ff6>?35FHR?B?B?JKDY`RQUPbBjKFHEDP2BEFEDGPQKSRJDGJIjR'FHOY?R?|RJD EDJX1?PQKJBR?JKS5FHRHFHGJKDJ616bn"%Ek$'hoShb#"#0N"#.1"%/3.}*Q$'hb$13]n/*i<vEh0$16C0E"%/316 (t6N3bog%i'}ffE*Q3]n~678#:<;;>f6 l i'h"#gHi'*+*N0+hbz"#[bq<i'& e*f0N"Spji'k*!$'g#h10+hbz 0+h*iz'0q"#[1g%i'.z'[#prh"H$qf"20qC$'h"%$2sr(i'g20Eh"%!& iE*6bh .zz'*E"%i'h3~n~6~86>f3fDJXHPQKB9RHKS55FHRHFHGJKD'6)Cq!$E&m0q4\gH<H!3bn$'h^0!zi13 l $'*N0Nki'g#h10$16di<$'*#s0Q3w6782:<;'>?6 x5[q!$%ki'g.#0Nhz!,/.b$'*+0N"p$'0i'& C0+h|$'."Hi'& $'"20q E&-i'h#"2g%$'"#0i'h6 h'RY<KXR'D|CXP2RJmGPQKS BEmRJDY?PQF?G!PQKR'DB??PQXrF?B-DRP2BHYjKD{G!PbB<mG!PQKHY?bR'ILC6n/eg20+hbzfg2(fg2*$z16]$'effi'0Nh"%/3n~6N3O$'"c0+h]3rn~68#:<;;>f6n.}(.1h0Nq!$'"%0i'h)"%ii'*rki'gf qE0Eh"]0Nh.qE"#0i'hmi'kbg%!qf.1g%#0Nveg%iz'gH$'& 61h 5FHRO?B?B?'KDY9RUPBKDPfDP2BEFEDGPQKSRJDGJIbVR'D!UBEF?BED?BcRJDoGHKDffBB?G'FEDKD'6i'gHz$'h$'.1k&-$'hh]6]$!vrgH$q/ 3\6+3^dw$!r"!3y682:<;;>?6mhr.bqf"20+v *iz'0qegHiz'g%$'& &m0Nhz1)#.1g#vEpi'k.g%i'eff!$'hg%!%<$'gHq%[6c`V5RJXDKS?GPQKSRJDYE382:>?3b=O~:<;16]$!vrgH$q/ 36N3^! fgHi#s03n682:<;;>?6fDJXHPQKBRHKS5FHR?JFHGJKDJffB??DKSEXBHYGJD~ILKS?GPQKSRJDYE6a*+*N05Ci'g#iriff6]!/3 l6 8#:<;>f69V5RJINB?P2BEDB?Y?Y]bB?RJFHBEGJD-GV5RJXP2B<F5F?RHJF?GJTURJF\KDJKD]bB?RJFHB<YBEFEKJG<INBaUEFHRJ@9KJB<D CJKSRJYE674\[]6_^`6r"#[!#0!3bth10+vEg%#0N"pi'k l $'*N0Nki'g#h10$13ff5Eg#sE*Ep6*i<p1ff3ff166]82:<;>?6RJXrDff/GPQKSRJDY`RURHJK95FHR?JFHGJKD'6yn/e1g#0NhzEg#(fg2*$zb6nr!q<i'hb<0+"20i'h]6$'g%qE0+h1si<2sr0Q3c6N3aA47$q%[i'*#s03658#:<;;>f6th1<qE01$'}0N*+0N"pi'k"#[b[i'g#hqE*$'.b% 0N&me1*+0q!$'"#0i'heg%i'}1*E&W6ah5FHRO?B?B?'KDYRUPbBm]KFHPQ!PKF?DDXGJI~H\'RY<KXRJD-RJXrDGPQKSRJDYRQUVR'X/P2BEF9<KSBED?BE3e1e6~='Or=`40+"2"%#}1.gHz1347fh1h#p*+v/$'h0$16.zz'*f"Hi'h35n658#:<;;>f6WShbr.bqf"20+v*iz'0qegHiz'g%$'& &m0Nhz16ShF?R?B?B?JKDOY RU`PbBjRJF%OY?bRHRJDIRJFEKNPKScB?G'FEDKD]bB?RJFEO69[1& #[b$4\.1}*N02[Eg%!3xai'srpi16JfiSb/?O~Q'ff?'fH' fffiSrE %G IHJ-KJLNMBO ffP!"!#+b $&%ff')(*%,+-%ff. /021435+768359;:-<fi021=+?>A@B35<C.+D/EF'fH'QR fffiJKfiSTSJ,#U+bVW!#Xff'U'YZ\[8.^3 ]S%S%S_1I+C>`A3ba"0dc%"e%S]S35+-_Af,+C0U%,.,+-/021435+-/5Eg 3. h^`Sc3S:i3+jf+-_5<] 021=kfi%8l3 >51m]n[8.S3 >5.S/59o9o1=+C>ffUpQq*rTryNts?XN'ff,!-t'?!urcwv fiffPJKC'fH'ox fffifiOJyE z?% !"!#N {}|dUW~' 'N#ff!ff % ffi' sb# v< !#+bfi NS[8. 3]S%S%S_51=+?>`3bai0dc%we-10dc\8<B.S3S:%S/5+6835+ffa%ff. %ff+-]S%3+z/J] c?1=+-%wl%S/.,+1I+C>~?U+b Uvd 2'fH'DD fffiJLfi~,tHEtNW!-fR'%'2$&%,'(*%,+-%ff.~/021435+68359;:-<~021=+C>j@B35<C.+D/EF'fH'8-W N~n fffiPfiPJfits +b"NJf 'Q? # v , %NBXff'HffoJVN?v2 NHff %'NU 'Y[n.S3]S%S%S_51=+C>^`o3ba0dc%&1 0dcf+C0U%ff.,+-/021435+-/5E6835+ffa%ff. %,+D]S%o3+z/J] c?1=+D%l%S/.,+1I+C>r %fi 'x'?X!'1'fH'?|QNr? fffifiHJE Q %@B35<C.+D/E3ba;l3 >fi14];[8. 3S>5. /59o9o1=+?> ?4? JK^MBJ!"!#+b {r8sb<U"'"!-fUsC?N'fH'Y-W-~fb -p* fffifiJR",fQNE '{y&?% !Z[8. 3]S%S%S_51=+?>`&3ba0dc% g 3. h^`Sc3S:3+#*E>J35.,10dc?9o14]Rl%S/5.,+1=+C>Yc%S3.,^qs?!A so? 1WX sb N-ryC'fH'Qfi|j8UfffifiHJSrEW*t'2? ''Z*, +HwfX'HffN7\[8. 3]S%S%S_51=+?>`A3ba0dc%35<B. 0dcf+C0U%ff.,+-/021435+-/5E g 35. h`Sc3S:z35+#f+-_5<] 021=kfi%Rl3 >fi14]R[8.S3 >5.S/59o9o1=+C>JN %E+Xtts8S?'U s, !'U Ww|'HfJ, tUff N#b!o?8fiC'1, d5'1Yd U!'JBW1E# r fffiPfiPJS#2B-fb 'WXff'U'wN XQ?Ht!ANw[8.S3]S%S%S_51=+C>^`*3baR0dc%jYc?1=.S_n<C. 3S:%S/+ g 35. h51I+C>e%S`S`ff1435+3+il%S/5.,+1=+C>5?N !A'E?s ? vbpnsE - vmC1;|'W &UfffiJLfiSrsx#?#?!#U'Us!%,!N#+rE?% !"!#N {"fiE to' 7I' +Xfi, NN \[8. 3]S%S%S_51=+?>`#3ba"0dc%j1 0dcf+?0U%,.,+-/021435+-/5E g 35. h`Sc3S:Z35+f,+-_5< ]S021=k5%l3S>514];[8.S3 >5.S/59o9o1=+C>Bd| ,# U! ECn5p !# HxC E! fi' Us ' ,W ,tU+ HN ]9E? ED5EN ?!'UBNo|jUffJJSw'%-'VNE fb 'WXN' '{E+ <,N* wts ~|oIn?NSDz/J] c?1=+-%;f,+C0U%,EIEF1>J%,+D]S%~'mLC??LO^MfffiO -C+J1?%sZ? N4Hfft'UBN?j5|j? ffJCffJ*<fi0U359"/0214]Qz% 0dc3^_N`3banf+D_<] 021Ik5%8f+ffa%ff. %ff+-]S%sY|jOUsN XNBC+J1?%sW ,tU+ mB9'UBNJo|oJ ffJC-S?2 s,'%'NrfUWE,t'Xff'U'YfNt!5WwXts?fi|oDIn?z/J] c?1=+D%Rf+C0U%ffE=E1>J%ff+-]S%B'2C ?YYff SMKH -nBN J ?H sVW ,t N mw% NtN? NX' ~& fffiPfiJSrfU'j1ff,X 'U%!ffNz/J] c?1=+-%8l%S/5.,+1=+C>@C3<C.,+-/5EF US?P SMfffi?NH'?J fffiJLfiSY\!fits +bvUE%N X8fi%ff ' sQHffH'+1 '?U+~Q@C35<B.,+-/5E32a;0dc%R6w ~ SDKO^MBH fi5fiRJJCXfffiCDD#,J~mJJfiCD?J,t2* fffiJfiiB QJJ }QtNt? X? WXNVtUN TN" , X4ifi,tYQ8d fffifffiff fi!#"*Nfi?,"X%$ ff NC'&;Xfffi8W=U?X?J,t2*)(*$fi,N + ,.- ff/fiJS0"UW#?XQt?U#=WJJ, fft?UYm12334fi5!36798:<;=:>?!@<;BA2!ffC=EDBffFfi5GIH?ff66Jfi.KLM fi5!5G $Bt "XBN,bBttN7 ff//JSo4#?XffUzXtN*??NX?O ~QPR;=fffiSUT:C#)NMH?MfiJ#W VGX /ZY\[? ]~XfiXfi0+ &W *^W(_^YNfi-&*W`xUff]fiJSj" ,t,Nt* Nt,A;It,A~UtNtW XW fftJ aJ,NM ,<b?CW- mcffdfi!36e98B<;=1>ffi5ff6I!NJ\fi.Shg!fi5!TJ83MM#iLj:fffi kJfiSGM!NMSSlfimZM?tfionx?A?Y# ^Yfip"Rtfi8=q\WU &Uff/fiJSj" , #fiX? fitArOJWJJ,tto fft?UYms23fi5!d6 98h<;=>?tff<;uA!ffC EDBffFfi5!7H?ff66JfiKLM fi5!5 !$vw3xfiJournal Artificial Intelligence Research 3 (1995) 271-324Submitted 2/95; published 11/95Flexibly Instructable AgentsScott B. HuffmanPrice Waterhouse Technology Centre, 68 Willow RoadMenlo Park, CA 94025 USAJohn E. LairdArtificial Intelligence LaboratoryUniversity Michigan, 1101 Beal Ave.Ann Arbor, MI 48109{2110 USAhuffman@tc.pw.comlaird@eecs.umich.eduAbstractpaper presents approach learning situated, interactive tutorial instruction within ongoing agent. Tutorial instruction exible (and thus powerful)paradigm teaching tasks allows instructor communicate whatever typesknowledge agent might need whatever situations might arise. support exibility, however, agent must able learn multiple kinds knowledge broadrange instructional interactions. approach, called situated explanation, achieveslearning combination analytic inductive techniques. combinesform explanation-based learning situated instruction full suitecontextually guided responses incomplete explanations. approach implementedagent called Instructo-Soar learns hierarchies new tasks domain knowledge interactive natural language instructions. Instructo-Soar meetsthree key requirements exible instructability distinguish previous systems:(1) take known unknown commands instruction point; (2) handleinstructions apply either current situation hypothetical situation specified language (as in, instance, conditional instructions); (3) learn,instructions, class knowledge uses perform tasks.1. Introductionintelligent, autonomous agents future called upon perform widevarying range tasks, wide range circumstances, courselifetimes. Performing tasks requires knowledge. number possible taskscircumstances large variable time (as general agent), becomesnearly impossible preprogram knowledge required. Thus, knowledge mustadded agent's lifetime. Unfortunately, knowledge cannot addedcurrent intelligent systems perform; must shut programmednew task.work examines alternative: intelligent agents taught perform taskstutorial instruction, part ongoing performance. Tutorial instructionhighly interactive dialogue focuses specific task(s) performed.working tasks, student may receive instruction needed complete tasksunderstand aspects domain previous instructions. situated, interactiveform instruction produces strong human learning (Bloom, 1984). Althoughc 1995 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiHuffman & Lairdreceived little attention AI, potential powerful knowledge sourceartificial agents well.Much tutorial instruction's power comes communicative exibility: instructor communicate whatever type knowledge student may need whateversituation needed. challenge designing tutorable agent supportbreadth interaction learning abilities required exible communication.paper, present theory learning tutorial instruction within ongoingagent. developing theory, given special attention supporting communicative exibility instructor (the human user). began identifying propertiestutorial instruction instructor's perspective. properties,derived set requirements instructable agent must meet support exible instructability. requirements drove development theory evaluation.Finally, implemented theory instructable agent called Instructo-Soar(Huffman, 1994; Huffman & Laird, 1993, 1994), evaluated performance.1Identifying requirements exible instructability provides target { set evaluationcriteria { instructable agents. requirements encompass ways agent interactsinstructor, comprehends instructions, learns them. generalrequirements common interactive learning systems; e.g., agent expectedlearn general knowledge instructions, learn quickly (with minimal numberexamples), integrate learned previous knowledge, etc. requirementsspecific tutorial instruction.theory learning tutorial instruction specifies analytic inductivelearning techniques combined within agent meet requirements, producinggeneral learning wide range instructional interactions. present learningframework called situated explanation utilizes situation instruction applieslarger instructional context (the instruction's type place current dialogue)guide learning process. Situated explanation combines form explanation-basedlearning (DeJong & Mooney, 1986; Mitchell, Keller, & Kedar-Cabelli, 1986) situated individual instruction, full suite contextually guided responsesincomplete explanations. responses include delaying explanation information available, inducing knowledge complete explanations, completing explanationsinstruction, abandoning explanation favor weaker learning methods.Previous explanation-based learning systems employed one cases staticsequence options, chosen dynamically among options basedcontext example. dynamic selection required exible instructability. learning framework cast within computational model general intelligentbehavior called problem space computational model.Instructo-Soar implemented agent embodies theory. interactive natural language instructions, Instructo-Soar learns perform new tasks, extendsknown tasks apply new situations, acquires variety types domainknowledge. allows exible instruction previous instructable systems (e.g.,learning apprentice systems, Mitchell, Mahadevan, & Steinberg, 1990) meeting three1. work inspired human students, also taken cues psychological effectsappropriate. theory's potential cognitive model discussed elsewhere (Huffman, 1994;Huffman, Miller, & Laird, 1993).272fiFlexibly Instructable AgentsPush green button.Thats new one. that?Move grey table.Ok. next?Move green button.that?Move arm up.Oh, see! next?Move down.Ok. next?operator finished.turn light, push button.mean pushing buttoncauses light come on?Yes....Never grasp red blocks.not?Red blocks explosive.light turn on....Figure 1: example tutorial instruction.key requirements tutorial instruction: (1) take known unknown commandsinstruction point; (2) handle instructions apply either current situation hypothetical situation specified language (as in, instance, conditionalinstructions); (3) learn, instructions, class knowledge usesperform tasks.follows, first discuss properties requirements tutorial instruction.Then, present approach implementation Instructo-Soar, includingseries examples illustrating instructional capabilities supported. concludediscussion limitations areas research.2. Properties Tutorial InstructionTutorial instruction situated, interactive instruction given agent attemptsperform tasks. situated applies particular task situations arisedomain. interactive agent may request instruction needed. typeinstruction common task-oriented dialogues experts apprentices (Grosz,1977). example tutorial instruction given Instructo-Soar robotic domainshown Figure 1.Tutorial instruction number properties make exible easyinstructor produce:P1. Situation specificity. Instructions given particular tasks particular situations. teach task, instructor need provide suggestions specificsituation hand, rather producing global procedure includes general conditions applicability step, handles possible contingencies, etc.situation also help disambiguate otherwise ambiguous instruction. number authors discussed advantages situation-specific knowledge elicitation(e.g., Davis, 1979; Gruber, 1989).P2. Situation specification needed. Although instructions typically applysituation hand, instructor free specify situations needed;instance, specifying contingencies using conditional instructions.P3. Incremental as-needed elicitation. Knowledge elicited incrementally partagent's ongoing performance. Instructions given agent unable273fiHuffman & Lairdperform task; thus, directly address points agent's knowledgelacking.P4. Task structuring instructor. instructor structure larger taskssmaller subtasks way desired. instance, task requiring ten primitive stepsmay taught simple sequence ten steps, two subtasks five stepseach, etc. agent know instructed action subtask is,perform situation hand, ask instruction.P5. Knowledge-level interaction. instructor provides knowledge agentknowledge level (Newell, 1981). is, instructions refer objectsactions world, symbol-level structures (e.g., data structures) withinagent. interaction occurs natural language, language instructoruses talk task, rather requiring artificial terminology syntaxspecify agent's internal data processes.Tutorial instructions provide knowledge applicable agent's current situationclosely related one. Thus, type instruction appropriate taskslocal control structure, control decisions made based presently availableinformation. Local control structure characteristic constructive synthesis tasks,primitive steps composed one another form complete solution.work focuses type task.23. Requirements Instructable AgentAlthough easing instructor's burden providing knowledge, properties tutorialinstruction described place severe requirements instructable agent. general,agent must solve three conceptually distinct problems: must (1) comprehend individual instructions produce behavior, (2) support exible dialogue instructor,(3) produce general learning interaction. properties tutorial instruction described previous section place requirements solutionsproblems. follows, identify key requirements problem turn.3.1 Comprehending Instructions: Mapping Problemmapping problem involves comprehending instructions given natural language transforming information contain agent's internal representation2. contrast, problem solving methods like constraint satisfaction heuristic classification involve globalcontrol strategies. strategies either follow fixed global regime require aggregationinformation multiple problem solving states make control decisions. possible produceglobal control strategy using combination local decisions (Yost & Newell, 1989). However, teachingglobal method casting purely sequence local decisions may dicult. typesinstruction, beyond scope work, required teach global methods natural way.acquire knowledge tasks involve known global control strategy, may ecient usemethod-based knowledge acquisition tool (e.g., Birmingham & Klinker, 1993; Birmingham & Siewiorek,1989; Eshelman, Ehret, McDermott, & Tan, 1987; Marcus & McDermott, 1989; Musen, 1989)control strategy built in.274fiFlexibly Instructable Agentslanguage. required agent apply information communicated instructionsknowledge level (property P5, above) internal processing.Solving mapping problem general involves complexities natural language comprehension. Carpenter (1976) point out, instructions linguistically complex dicult interpret independent diculty taskinstructed. Even linguistically simple instructions, actions objects often incompletely specified, requiring use context domain knowledge produce completeinterpretation (Chapman, 1990; DiEugenio & Webber, 1992; Frederking, 1988; Martin &Firby, 1991).general requirement mapping problem tutorable agent straightforward:M1 . tutorable agent must able comprehend map aspects instructionfall within scope information possibly represent.agent cannot expected interpret aspects fall outside representation abilities (these abilities may augmented instruction, occurs buildingexisting abilities). detailed analysis could break general requirementset specific ones.work focused mapping problem. Rather, agent implemented uses fairly standard natural language processing techniques handle instructionsexpress sucient range actions situations demonstrate capabilities.concentrated efforts interaction transfer problems.3.2 Supporting Interactive Dialogue: Interaction Probleminteraction problem problem supporting exible dialogue instructor.properties tutorial instruction indicate dialogue occurs agent'songoing performance address lacks knowledge (property P3); within dialogue,agent must handle instructions apply different kinds situations (propertiesP1 P2) structure tasks different ways (property P4).instructable agent moves toward solving interaction problem degreesupports properties. work, concentrate instructor's utteranceswithin dialogue, since exibility instructor goal. consideredpotential complexity agent's utterances (e.g., give instructor various kindsfeedback) much detail.properties exible interaction specified terms individual instructionevents, instruction event utterance single instruction particularpoint discourse. support truly exible dialogue, instructable agent mustable handle instruction event coherent current discourse point.instruction event initiated either student teacher, carries knowledgetype applied particular task situation. Thus, exible tutorable agentsupport instruction events with:I1. Flexible initiation. Instruction events initiated agent instructor.275fiHuffman & LairdI2. Flexibility knowledge content. knowledge carried instruction eventpiece types knowledge agent uses applicableway within ongoing task discourse context.I3. Situation exibility. instruction event apply either current tasksituation specified hypothetical situation.following sections discuss requirements detail.3.2.1 Flexible Initiationhuman tutorial dialogues, initiation instruction mixed student teacher.One study indicates teacher initiation prevalent early instruction; studentinitiation increases student learns more, drops studentmasters task (Emihovich & Miller, 1988).Instructor-initiated instruction dicult support instruction eventsinterrupt agent's ongoing processing. Upon interrupting agent, instruction eventmay alter agent's knowledge way could change invalidate reasoningagent previously engaged. diculties, instructable systemsdate fully supported instructor-initiated instruction.3 Likewise, InstructoSoar handle instructor-initiated instruction.Agent-initiated instruction directed (at least) two possible ways: verificationimpasses. learning apprentice systems, LEAP (Mitchell et al., 1990)DISCIPLE (Kodratoff & Tecuci, 1987b) ask instructor verify alter reasoningstep. advantage approach step examined instructor;disadvantage, course, step must examined. alternative approachdrive instruction requests impasses agent's task performance (Golding, Rosenbloom, & Laird, 1987; Laird, Hucka, Yager, & Tuck, 1990). approach usedInstructo-Soar. impasse indicates agent's knowledge lacking needsinstruction. advantage approach agent learns, becomesautonomous; need instruction decreases time. disadvantagelacks knowledge recognized reaching impasses; e.g., impasse occurperformance correct inecient.3.2.2 Flexibility Knowledge Contentexible tutorable agent must handle instruction events involving knowledgeapplicable way within ongoing task discourse context. requirementdicult meet general, wide range knowledge may relevantparticular situation. requires robust ability relate utterance ongoingdiscourse task situation. instructable systems met requirement fully.However, define constrained form requirement, limited instructions command actions (i.e., imperatives). Imperative commands especiallyprevalent tutorial instruction procedures. Supporting exible knowledge content3. systems learned purely observing expert (e.g., Dent, Boticario, McDermott, Mitchell &Zabowski, 1992; Redmond, 1992). Observation type instructor-initiatedness, instructioninteractive dialogue.276fiFlexibly Instructable Agentscommands means allowing instructor give relevant command pointdialogue teaching task. call ability command exibility.command given, three possibilities: (1) commanded actionknown, agent performs it; (2) commanded action known, agentknow perform current situation (extra, unknown steps needed);(3) commanded action unknown. Thus, command exibility allows instructorteaching procedure skip steps (2) command subtask unknown (3)point. cases, agent asks instruction. interaction patternresults, procedures commanded taught needed,observed human instruction. Wertsch (1979) notes \...adults spontaneously followcommunication strategy use directives children understandguide children behaviors necessary carry directives."Command exibility gives instructor great exibility teaching set tasks instructions hierarchically structure tasks whatever way instructorwishes. mathematical analysis (Huffman, 1994) revealed number possiblesequences instructions used teach given procedure grows exponentiallynumber actions procedure. procedure 6 primitive actions,100 possible instruction sequences; 7, 400.3.2.3 Situation Flexibilityexible tutorable agent must handle instructions apply either current tasksituation hypothetical situation instructor specifies. Instructors makefrequent use options. instance, analysis protocol studenttaught use ight simulator revealed 119 508 instructions (23%) involvedhypothetical situations, remainder applying current situation timegiven.Instructions apply current situation, imperative commands (e.g.,\Move yellow table"), called implicitly situated (Huffman & Laird, 1992). Sinceinstruction says nothing situation applied,current situation (the task performed current state) implied.contrast, instructions specify elements situation meantapply explicitly situated (Huffman & Laird, 1992). agent meant carryinstructions immediately (as implicitly situated instruction), rathersituation arises like one specified. Examples include conditionals instructionspurpose clauses (DiEugenio, 1993), following:4using chocolate chips, add coconut mixture pressingpie pan.restart this, hit R shift-R.get interval want, center joystick again.4. examples taken protocol tutorial instruction written source instruction (acookbook).277fiHuffman & Lairdnumber researchers pointed (Ford & Thompson, 1986; Haiman, 1978;Johnson-Laird, 1986), conditional clauses introduce shared reference speakerhearer forms explicit background interpreting evaluating consequent.5Here, clauses italics indicate hypothetical situation commandremainder instruction meant apply. cases, situation partiallyspecified, remainder drawn current situation, \When using chocolatechips [and cooking recipe, current point process]..."general, hypothetical situation may created referred across multipleutterances. agent presented handles implicitly single explicitly situatedinstructions, deal hypothetical situations exist multipleinstructions.3.3 Producing General Learning: Transfer Problemtransfer problem problem learning generally applicable knowledge instructions, transfer appropriate situations future. general learningbased instructions apply specific situations (property P1, above). Many typesknowledge may learned, since instructions provide type knowledgeagent lacking (property P3).Solving problem involves simply memorizing instructions future use;rather, conditions applying instruction must determined situation.Consider, example, following exchange instructor agent:Block open oce door.that?Pick red block.Now, drop here, next door.proper conditions performing \pick up" action? Simple memorization yields poor learning; e.g., whenever blocking open office door, pickred block. However, block's color, even fact block, irrelevant case. Rather, fact block weighs (say) five pounds,giving enough friction oor hold open door, crucial. Thus, properlearning might be:trying block open door,object obj picked up,obj weighs 5 poundspropose picking obj.Here, original instruction generalized (color red isa block drop out)specialized (weight > 5 added).transfer problem places number demands tutorable agent:T1. General learning specific cases. agent instructed particularsituation, expected learn general knowledge apply sucientlysimilar situations.5. types conditionals follow pattern (Akatsuka, 1986), relevanttutorial instruction.278fiFlexibly Instructable AgentsT2. Fast learning. instructable agent expected learn new procedures quickly.T3.T4.T5.T6.Typically, task taught once.Maximal use prior knowledge. agent must apply prior knowledgelearning instruction. maxim machine learning systems general (ifknowledge, use it), particularly relevant learning instructionlearning expected happen quickly.Incremental learning. agent must able continually increase knowledgeinstruction. New knowledge must smoothly integrated agent'sexisting knowledge part ongoing performance.Knowledge-type exibility. Since type knowledge (e.g., control knowledge,causal knowledge, etc.) might communicated instructions, exible tutorableagent must able learn type knowledge uses. make testablecriterion laying types knowledge agent based particularcomputational model.Dealing incorrect knowledge. agent's knowledge clearly incomplete(otherwise, would need instruction); may also incorrect. general tutorable agent must able perform learn effectively despite incorrect knowledge.T7. Learning instruction coexisting learning sources.addition instruction, complete agent able learnsources knowledge available. might include learning observation/demonstrations, experimentation environment, analogy, etc.theory learning tutorial instruction presented focuses extendingincomplete knowledge instruction { requirements T1 T5 list. Handling incorrect knowledge (T6) learning sources (T7) planned extensionsprogress.Table 1 summarizes requirements must met instructable agent support exible tutorial instruction, indicates requirements targeted InstructoSoar. made two simplifications using requirements evaluate InstructoSoar. First, treat requirement binary; is, either completely metunmet. reality, requirements could broken finer-grained pieces evaluated separately. Second, treat requirement independently. table indicatesInstructo-Soar's performance requirement alone, account potential interactions them. interactions complex; instance,pursuing fast learning (T2), agent may sacrifice good general learning (T1)bases generalizations examples. addressed tradeoffsevaluation Instructo-Soar.4. Related WorkAlthough extensive research agents learn tutorial instruction per se, learning instruction-like input long-time goal AI (Carbonell,279fiHuffman & LairdProblem RequirementMapping M1 Mapping representableinformationInteraction I1 Flexible initiation instructionI2 Flexibility instructional knowledgecontentI3 Situation exibilityimplicitly situatedexplicitly situated single utteranceexplicitly situated multiple utteranceTransfer T1 General learning specific casesT2T3T4T5T6T7Instructo-Soar?(as needed showcapabilities)(only agent-initiated)partial (command exibility)partialyesyesyes(via situated explanation)Fast learningyes(new procedurestaught once)Maximal use prior knowledgeyesIncremental learningyesKnowledge-type exibilityyes(learns PSCMknowledge types)Ability deal incorrect knowledge(only extending incomplete knowledge)Learning instruction coexisting(not demonstrated)learning sourcesTable 1: requirements exible tutorable agent, Instructo-Soar's performance them.Michalski, & Mitchell, 1983; McCarthy, 1968; Rychener, 1983). Early non-interactive systems learned declarative, ontological knowledge language (Haas & Hendrix, 1983; Lindsay, 1963), simple tasks unsituated descriptions (Lewis, Newell, & Polk, 1989; Simon,1977; Simon & Hayes, 1976), task heuristics non-operational advice (Hayes-Roth,Klahr, & Mostow, 1981; Mostow, 1983).work concentrated behaving based interactive natural language instructions. SHRDLU (Winograd, 1972) performed natural language commands smallamount rote learning { e.g., learning new goal specifications directly transformingsentences state descriptions. recent systems act response language(concentrating mapping problem) minimal learning include SONJA(Chapman, 1990), AnimNL (DiEugenio & Webber, 1992), Homer (Vere & Bickmore,1990).recent work focused learning situated natural language instructions. Martin Firby (1991) discuss approach interpreting learningelliptical instructions (e.g., \Use shovel") matching instruction expectationsgenerated task execution failure. Alterman et al.'s FLOBN (Alterman, Zito-Wolf, &Carpenter, 1991; Carpenter & Alterman, 1994) searches instructions environment280fiFlexibly Instructable Agentsorder operate devices. FLOBN learns relating device's instructions knownprocedures operating similar devices. systems target learning exibleinteractive instructions types instructions imperatives, however.bulk work learning instruction-like input rubriclearning apprentice systems (LASs), closely related programming-by-demonstration(PbD) systems (Cypher, 1993) { employed, instance, recent work learningwithin software agents (Dent et al., 1992; Maes, 1994; Maes & Kozierok, 1993; Mitchell,Caruana, Freitag, McDermott, & Zabowski, 1994). systems learn interactingexpert; either observing expert solving problems (Cypher, 1993; Donoho & Wilkins,1994; Mitchell et al., 1990; Redmond, 1992; Segre, 1987; VanLehn, 1987; Wilkins, 1990),attempting solve problems allowing expert guide critique decisionsmade (Golding et al., 1987; Gruber, 1989; Kodratoff & Tecuci, 1987b; Lairdet al., 1990; Porter, Bareiss, & Holte, 1990; Porter & Kibler, 1986). LAS learnedparticular types knowledge: e.g., operator implementations (Mitchell et al., 1990), goaldecomposition rules (Kodratoff & Tecuci, 1987b), operational versions functional goals(Segre, 1987), control knowledge control features (Gruber, 1989), procedure schemas (acombination goal decomposition control knowledge) (VanLehn, 1987), useful macrooperations (Cypher, 1993), heuristic classification knowledge (Porter et al., 1990; Wilkins,1990), etc.Tutorial instruction exible type instruction supported pastLASs, three reasons. First, instructor may command unknown tasks tasksunachieved preconditions agent instruction point (command exibility). PastLASs limit input particular commands/observations particular times (e.g., commanding observing directly executable actions) typically allow unknowncommands all. Second, tutorial instruction allows use explicitly situated instructions (situation exibility), teach contingencies may presentcurrent situation; past LASs not. Third, tutorial instruction requires typestask knowledge learned (knowledge-type exibility). Past LASs learn subsettypes knowledge use perform tasks.5. Theory Learning Tutorial Instructiontheory learning tutorial instruction consists learning framework, situatedexplanation, placed within computational model general agenthood, problem spacecomputational model. first describe computational model learningframework.5.1 Problem Space Computational Modelcomputational model (CM) \a set operations entities interpretedcomputational terms" (Newell et al., 1990, p. 6). computational model generalinstructable agent must meet two requirements:1. Support general computation/agenthood.2. Close correspondence knowledge level. tutorial instructionsprovide knowledge knowledge level (Newell, 1981), CM com281fiHuffman & Lairdponents knowledge level, dicult mapping learninginstructions be. addition, close correspondence knowledge levelallow us use CM identify types knowledge agent uses.Many potential CMs ruled requirements. Standard programming languages (e.g., Lisp) theoretical CMs like Turing machines push-down automatasupport general computation, operations constructs symbol level,without direct correspondence knowledge level. Similarly, connectionist neuralnetwork models computation (e.g., Rumelhart & McClelland, 1986) employ (by design)computational operations entities level far knowledge level. Thus,models appropriate top-level CM instructable agent. However, higher levels description computational system implemented lower levels(Newell, 1990), CMs might used implementation substrate higherlevel CM instructable agent.Another alternative logic, entities well matched knowledgelevel (e.g., propositions, well-formed formulas). Logics specify set legal operations(e.g., modus ponens), thus defining space possibly computed. However,logic provides notion computed; is, logics alone specifycontrol logical operations' application. desirable CM instructableagent include control knowledge, control knowledge crucial type knowledgegeneral agenthood, communicated instructions.Since one goals identify agent's knowledge types, might appearselecting theory knowledge representation would appropriate selectingcomputational model. theories define functions structures used represent knowledge (e.g., KL-ONE, Brachman, 1980); also define possible contentstructures (e.g., conceptual dependency theory, Schank, 1975; CYC, Guha & Lenat,1990). However, computational structure must added theories produce working agents. Thus, rather alternative specifying computational model, theoryknowledge representation addition. content theory knowledge representation would provide fine-grained breakdown knowledge learnedinstructable agent within category knowledge specified CM.employed particular content theory work thus far, however.computational model adopted called problem space computational model(PSCM) (Newell et al., 1990; Yost, 1993). PSCM general formulation computation knowledge-level agent, many applications built within (Rosenbloom, Laird, & Newell, 1993a). specifies agent terms computation withinproblem spaces, without reference symbol level structures used implementation.components approximate knowledge level (Newell et al., 1990), PSCMapt choice identifying agent's knowledge types. Soar (Laird, Newell, & Rosenbloom, 1987) symbol level implementation PSCM.schematic PSCM agent shown Figure 2. Perception motor modulesconnect agent external environment. PSCM agent reaches goal movingsequence states problem space. progresses toward goals sequentiallyapplying operators current state. Operators transform state, may producemotor commands. PSCM, operators powerful simple STRIPS operators(Fikes, Hart, & Nilsson, 1972), perform arbitrary computation (e.g.,282fiFlexibly Instructable Agentsexternal environmentperceptual modulesmotor modulesFigure 2: processing PSCM-based agent. Triangles represent problem spaces;squares, states; arrows, operators; ovals, impasses.include conditional effects, multiple substeps, reactivity different situations, etc.).PSCM agent reaches impasse immediately available knowledgesucient either select fully apply operator. occurs, another problemspace context { subgoal { created, goal resolving impasse. secondcontext may impasse well, causing third context arise, on.computational entities PSCM mediated agent's knowledgestates operators. small set basic PSCM-level operations entitiesagent performs:1. State inference. Simple monotonic inferences always appliedmade without using PSCM operator. inferences augment agent's representation state inferring state properties based state properties(including delivered perception). instance, agent might knowblock held gripper closed positioned directly block.2. Operator selection. agent must select operator apply, given currentstate. process involves two types knowledge:2.1. Proposal knowledge: Indicates operators deemed appropriate current situation. knowledge similar \precondition" knowledge simple STRIPSoperators.2.2. Control knowledge: Orders proposed operators; e.g., \A better B"; \Cbest"; \D rejected."283fiHuffman & Laird3. Operator application. selected, operator may applied directly,indirectly via subgoal:3.1. Operator effects. operator applied directly current problem space.agent knowledge effects operator state motorcommands produced (if any).3.2. Sub-operator selection. operator applied reaching impasse selecting operators subgoal. Here, knowledge apply operator selectionknowledge (2, above) sub-operators.4. Operator termination. operator must terminated applicationcompleted. termination conditions, goal concept (Mitchell et al., 1986),operator indicate state conditions operator meant achieve.example, termination conditions pick-up(blk) might blk heldarm raised.6functions performed agent using knowledge; thus, define setknowledge types present within PSCM agent. knowledge types (five types total)summarized Table 2. Soar implementation PSCM, knowledgewithin Soar agents types.Soar's implementation PSCM, learning occurs whenever results returnedsubgoal resolve impasses. learning process, called chunking, creates rules(called chunks) summarize processing subgoal leading creationresult. Depending type result, chunks may correspond five typesPSCM knowledge. similar situations arise future, chunks allow impassecaused original subgoal avoided producing results directly. Chunkingform explanation-based learning (Rosenbloom & Laird, 1986). Althoughsummarization mechanism, taking inductive deductive steps subgoals,chunking produce inductive deductive learning (Miller, 1993; Rosenbloom& Aasman, 1990). Chunking occurs continuously, making learning part ongoingactivity Soar/PSCM agent.PSCM clarifies task instructable agent: must able learnfive types PSCM knowledge instruction. next section discusses learningprocess itself.5.2 Learning Instructions Situated ExplanationLearning instruction involves analytic learning (learning based prior knowledge) inductive learning (going beyond prior knowledge). Analytic learning neededagent must learn instructions combine known elements { e.g., learning pick objects combining known steps pick particular object. agent'sprior knowledge elements used produce better faster learning. Inductive learning needed agent must learn new task goals domain knowledge6. PSCM operators explicit termination knowledge string conditionaleffects take place time, respond (or wait for) external environment, etc.STRIPS operators, contrast, need explicit termination knowledge, definedsingle list effects, \terminated" definition applying effects.284fiFlexibly Instructable AgentsEntity Knowledge type Examplestateinferencegripper closed & directly obj ! holding obj.operator proposalgoal pick obj table-x, docked tablex, propose moving table-x.operator controlgoal pick small metal obj table-x, prefer moving table-x fetching magnet.operator effectseffect operator move table-x robotbecomes docked table-x.operator terminationTermination conditions pick obj gripperraised & holding obj.Table 2: five types knowledge PSCM agents.beyond scope prior knowledge. goal research producepowerful analytic inductive techniques, rather specify techniquescome together produce variety learning variety instructional situations facedinstructable agent. resulting approach called situated explanation.Instruction requirements T1 T3 specify general learning (T1) must occursingle, specific examples (T2), making maximal use prior knowledge (T3).requirements bode strongly learning approach based explanation. useexplanation produce general learning common theme machine learning (e.g.,DeJong & Mooney, 1986; Fikes et al., 1972; Minton, Carbonell, Knoblock, Kuokka, Etzioni,& Gil, 1989; Rosenbloom, Laird, & Newell, 1988; Schank & Leake, 1989; many others)cognitive science (Anderson, 1983; Chi, Bassok, Lewis, Reimann, & Glaser, 1989; Lewis,1988; Rosenbloom & Newell, 1986). Forming explanations enables general learningspecific cases (requirement T1) explanation indicates features caseimportant generalized. Learning explaining typically requiressingle example (requirement T2) prior knowledge employed constructexplanation (requirement T3) provides strong bias allows fast learning.Thus, use explanation-based method core learning instruction approach, fall back inductive methods explanation fails. standardexplanation-based learning, explaining reasoning step involves forming \proof" (usingprior knowledge) step leads current state reasoning toward currentgoal. proof path reasoning current state goal, stepexplained, diagrammed Figure 3. General learning produced formingrule includes causally required features state, goal, step appearingproof; features appear generalized away.Figure 3 indicates three key elements explanation: step explained,endpoints explanation (a state goal G reached), stepsrequired complete explanation. form elements explanation takesituated explanation instruction?Step explained. situated explanation, step explained individualinstruction given agent.285fiHuffman & Lairdreasoning stepexplained(indicated instruction I)steps, agents knowledge...G(Mk )Figure 3: Caricature explanation reasoning step applies situation startingstate , goal G achieved.Alternatively, entire instruction episode { e.g., full sequence instructionsnew procedure { could explained once. Applying explanation single stepsresults knowledge applicable step (as Golding et al., 1987; Laird et al.,1990); explaining full sequences reasoning steps results learning schemasencode whole reasoning episode (as Mooney, 1990; Schank & Leake, 1989; VanLehn, 1987). Learning factored pieces knowledge rather monolithic schemasallows reactive behavior, since knowledge accessed locally based current situation (Drummond, 1989; Laird & Rosenbloom, 1990). meshesPSCM's local control structure. Explaining individual instructions also supportedpsychological results self-explanation effect, shown subjectsself-explain instructional examples re-deriving individual lines example. \Students virtually never ect overall solution try recognizeplan spans lines" (VanLehn Jones, 1991, p. 111).Endpoints explanation. endpoints explanation { state goal Gachieved { correspond situation instruction applies to. Situationexibility (requirement I3 ) stipulates situation may either currentstate world goal pursued hypothetical situation specified explicitly instruction. instruction specify situationalfeatures implicitly situated, applies agent's current situation. Alternatively, instruction specify features G, making two kinds explicitlysituated instructions. example, \If light on, push button" indicateshypothetical state light on; \To turn machine, ip switch" indicateshypothetical goal turning machine. situation [S; G] producedinstruction, based current task situation situation featuresinstruction specifies.required steps. complete explanation instruction, agent mustbring prior knowledge bear complete path instructionachievement situation goal. PSCM agent's knowledge applies currentsituation select apply operators make inferences. explaininginstruction , knowledge applied internally situation [S; G] associated. is, explanation takes form forward internal projection withinsituation. depicted Figure 3, agent \imagines" state ,runs forward, applying instructed step knowledgesubsequent states/operators. knowledge includes normally used286fiFlexibly Instructable Agentsexternal world knowledge operators' expected effects usedproduce effects projected world. G reached within projection,projected path , step instructed , G comprisesexplanation . indicating features , , G causally requiredsuccess, explanation allows agent learn general knowledge (asstandard EBL, realized agent Soar's chunking mechanism, Rosenbloom &Laird, 1986). However, agent's prior knowledge may insucient, causingincomplete explanation, described below.Combining elements produces approach learning tutorial instructionconceptually quite simple. instruction received, agent firstdetermines situation meant apply to, attempts explainstep indicated leads goal achievement situation (or prohibits it, negativeinstructions). explanation made, produces general learning knowledgeIK indicating key features situation instruction cause success.explanation cannot completed, indicates agent missing onepieces prior knowledge MK (of PSCM type) needed explain instruction.Missing knowledge (in Figure 3, missing arrows) causes incomplete explanation precluding achievement G projection. instance, agent may know keyeffect operator, crucial state inference, needed reach G. radically,action commanded may completely unknown thus inexplicable.shown Figure 4, four general options learning agent might followcannot complete explanation. (O1) could delay explanation later,hope missing knowledge (MK ) learned meantime. Alternatively,(O2-O3) could try complete explanation somehow learning missingknowledge. missing knowledge could learned (O2) inductively (e.g., inducing\gap" explanation, described VanLehn, Jones & Chi, 1992, manyothers), or, (O3) instructable agent's case, instruction. Finally, (O4)could abandon explanation altogether try learn desired knowledge anotherway instead.Given incomplete explanation, would dicult choose optionfollow. Identifying missing knowledge MK general case dicult credit assignment problem (with algorithmic solution), nothing incompleteexplanation predicts whether MK learned later explanation delayed. Thus, past machine learning systems responded incomplete explanationseither single way, multiple ways, tried fixed sequence.Many authors (Bergadano & Giordana, 1988; Hall, 1988; VanLehn, 1987; VanLehn, Jones,& Chi, 1992; Widmer, 1989), instance, describe systems make inductions complete incomplete explanations (option O2). diculty determining missingknowledge, systems either base induction multiple examples, and/or biasinduction underlying theory teacher's help. SIERRA (VanLehn, 1987),example, induces multiple partially explained examples, constrains inductionrequiring examples unexplainable piece missing knowledge (the disjunct, SIERRA's terminology). SWALE (Schank & Leake,1989) uses underlying theory \anomalies" explanations complete incomplete explanations events. OCCAM (Pazzani, 1991b) uses options O2 O4 static order:287fiHuffman & Lairddelay explanation Mk learnedO1delay:instructioncontextGincomplete explanation(missing knowledge Mk)kGlearn Mk inductively complete explanationO2kk?induceGklearn Mk instruction complete explanationO3kGGabandon explanation (learn another way)O4kGFigure 4: Options faced incomplete explanation missing knowledgeMK .first attempts fill gaps incomplete explanation inductively, biasednaive theory; fails, abandons explanation falls back correlational learningmethods. PET (Porter & Kibler, 1986) example system delays explanationreasoning step learns knowledge (option O1).However, indicated Figure 4, instructable agent additional informationavailable besides incomplete explanation itself. Namely, instructional context(that is, type instruction place within dialogue) often indicatesoption appropriate given incomplete explanation. Thus, situated explanation includes four options dynamically selects basedinstructional context. situated explanation instruction situation [S; G],missing knowledge MK precludes completing explanation learn knowledge IK ,options O1-O4 take following form:O1. Delay explanation later. instructional context indicate likelihood missing knowledge MK learned later. instance, instructiongiven teaching new procedure cannot immediately explained re-maining steps procedure unknown, known later (assuminginstructor completes teaching procedure). cases, agent discardscurrent, incomplete explanation simply memorizes 's use [S; G] (rote learning). Later, MK learned, recalled explained [S; G], causing IKlearned.288fiFlexibly Instructable AgentsGiven instruction knowledge IK learned:Determine situation [S; G] (current hypothetical) appliesExplain [S; G] forward projecting !; ; G! Success (G met): learn IK complete explanation ( EBL).! Failure: missing knowledge MK . Options:O1. Delay explanation later.O2. Induce MK , completing explanation.O3. Take instruction learn MK , completing explanation.O4. Abandon explanation; instead, learn IK inductively.Table 3: Situated explanation.O2. Induce MK , completing explanation. cases, instructional contextlocalizes missing knowledge MK part particular operator. instance,purpose clause instruction (\To X, Y") suggests single operatorcause X occur. localization tightly constrains \gap"incomplete explanation, agent use heuristics induce strong guessMK needed span gap. Inducing MK allows explanationcompleted IK learned.O3. Take instruction learn MK , completing explanation. default response agent (when options deemed appropriate) askinstructor explain further. instruction teach agent MK .Again, learning MK allows explanation completed IK learned.O4. Abandon explanation learn IK another way. instructionalcontext indicate missing knowledge MK would dicult learn.occurs either instructor refuses give information askedto, agent projected multiple operators may missing piecesknowledge (multiple potential MK s). Since unknown whether MK everacquired, agent abandons explanation altogether. Instead, attemptslearn IK directly (using inductive heuristics), without explanation baselearning on.options made clearer examples presented following sections.Situated explanation summarized Table 3. Unlike knowledge acquisition approaches, include explicit check consistency newly learned knowledgeadded agent's knowledge base. Kodratoff Tecuci (1987a) point out, techniques like situated explanation biased toward consistency acquirenew knowledge current knowledge insucient, use current knowledgederiving new knowledge. However, domains, explicit consistency checks (suchused Wilkins' (1990) ODYSSEUS) may required.Situated explanation meets requirement learning incremental (T4)occurs ongoing processing agent adds new pieces knowledge289fiHuffman & LairdT1T2T3T4T5I2I3General learning specific casesFast learning (each task instructed once)Maximal use prior knowledgeIncremental learningKnowledge-type exibilitya. state inferenceb. operator proposalc. operator controld. operator effectse. operator terminationCommand exibilitya. known commandb. skipped stepsc. unknown commandSituation exibilitya. implicitly situatedb. explicitly situated: hypothetical statehypothetical goalTable 4: Expanded requirements tutorial instruction met Instructo-Soar.agent's memory modular way. local control structure PSCM allows newknowledge added independent current knowledge. con ictpieces knowledge (for example, proposing two different operators situation),impasse arise reasoned resolved instruction.6.Instructo-SoarInstructo-Soar instructable agent built within Soar { thus, PSCM {uses situated explanation learn tutorial instruction.7 Instructo-Soar engagesinteractive dialogue instructor, receiving natural language instructionslearning perform tasks extend knowledge domain. sectionnext describe Instructo-Soar meets targeted requirements tutorial instruction,shown expanded form Table 4. section describes system's basicperformance learning new procedures, extending procedures new situations,imperative commands (implicitly situated instructions); next describes learningtypes knowledge handling explicitly situated instructions.7. overview Soar, systems built within it, see (Rosenbloom, Laird, & Newell, 1993b).290fiFlexibly Instructable AgentsFigure 5: robotic domain Instructo-Soar applied.6.1 Domain Agent's Initial Knowledgeprimary domain Instructo-Soar applied simulated roboticworld shown Figure 5.8 agent simulated Hero robot, room tables,buttons, blocks different sizes materials, electromagnet, light. magnettoggled closing gripper around it. red button toggles light off; greenbutton toggles dim bright, on.Instructo-Soar consists set problem spaces within Soar contain threemain categories knowledge: natural language processing knowledge, originally developedNL-Soar (Lewis, 1993); knowledge obtaining using instruction; knowledge task domain itself. task knowledge extended learninginstruction. Instructo-Soar expand natural language capabilities per setakes instruction, although learn sentences map onto new operatorslearns. complete, noiseless perception world, recognize set basicobject properties (e.g., type, color, size) relationships (e.g., robot docked-at table,8. techniques also applied limited way ight domain (Pearson, Huffman, Willis,Laird, & Jones, 1993), Soar controls ight simulator instructions given taking off.291fiHuffman & LairdPick red block.Move yellow table.Move arm red block.Move up.Move down.Close hand.Move up.operator finished.Figure 6: Instructions given Instructo-Soar teach pick block.gripper holding object, objects above, directly-above, left-of, right-of one another).set properties relations extended instruction, described below.agent begins knowledge set primitive operators mapnatural language sentences, execute. include moving tables, openingclosing hand, moving arm up, down, above, left of, right things.agent also internally project operators. However, effectsvarious conditions unknown. instance, agent know operatorsaffect light magnet, magnet attract metal objects. Also, agentbegins knowledge complex operators (that involve combinations primitiveoperators), picking arranging objects, pushing buttons, etc.6.2 Learning New Procedures Delayed ExplanationInstructo-Soar learns new procedures (PSCM operators) instructions likeshown Figure 6, picking block. Since \pick up" known procedureinitially, told \Pick red block," agent realizes must learn newoperator.perform PSCM operator, operator must selected, implemented, terminated. select operator future based command requires knowledgeoperator's argument structure (a template), natural language mapsstructure. Thus, learn new operator, agent must learn four things:1. Template: Knowledge operator's arguments instantiated.picking blocks, agent acquires new operator single argument,object picked up.2. Mapping natural language: mapping natural language semanticstructures instantiation new operator, operator selectedcommanded future. picking blocks, agent learns mapsemantic object \Pick ..." single argument new operator template.3. Implementation: perform operator. New operators performedexecuting sequence smaller operators. implementation takes formselection knowledge sub-operators (e.g., move proper table, movearm, etc.)292fiFlexibly Instructable Agents4. Termination conditions: Knowledge recognize new operator achieved{ goal concept new operator. \pick up," termination conditionsinclude holding desired block, arm raised.Requirement T2 (\fast learning") stipulates first execution new procedure, agent must able perform least task without re-instructed.Thus, agent must learn, form, four parts new operatorfirst execution.general implementation new operator learned situated explanationsteps. first execution new operator, though, instructionsperforming cannot explained, agent yet know goaloperator (e.g., agent know termination conditions \pick up")steps following current one reach goal. However, instructional context{ explaining instructed steps procedure learned { clear missingknowledge remaining steps procedure's goal acquired later,instructor expected teach procedure completion. Thus, agent delaysexplanation (option O1) memorizes implementation instruction rote,episodic form. end first execution new procedure, agent inducesprocedure's goal { termination conditions { using set simple inductive heuristics.later executions procedure, original instructions recalled explainedlearn general implementation.describe details process using \pick up" example.6.2.1 First Executionexample, shown Figure 6, begins instruction \Pick red block."agent comprehends instruction, producing semantic structure resolving \the redblock" block environment. However, semantic structure correspondknown operator, indicating agent must learn new operator (whichcalls, say, new-op14). learn template new operator, agent simply assumesargument structure command used request operator requiredargument structure operator itself. case, template new operatorgenerated argument structure directly corresponds semantic arguments\pick up" command (here, one argument, object). agent learns mappingsemantic structure new operator's template, used presentedsimilar requests future. simple approach learning templates mappingssucient imperative sentences direct arguments, fail commandscomplex arguments, path constraints (\Move dynamite room,keeping far heater possible").Next, new operator selected execution. Since implementation unknown,agent immediately reaches impasse asks instructions. instructionFigure 6 given, comprehended executed turn. instructions provideimplementation new operator. implicitly situated { appliescurrent situation agent finds itself.point, agent may given another command cannot directly completed { one requests either another unknown procedure known procedure293fiHuffman & Lairdinstructionexplainedsteps...???G?Figure 7: Instructions teaching new operator cannot explained terminationconditions new operator learned.agent know perform current situation due skipped steps.command exibility (requirement I2). example, within instructions \pick up,"command \Move red block" cannot completed skipped step(the arm must raised move something). impasse arises instructorindicates needed step (\move up"), continues instructing \pick up."Ultimately, implementation new operator learned proper levelgenerality explaining instructed step. However, illustrated Figure 7,initial execution forming explanation impossible, goal newoperator steps (further instructions) needed reach yet known.Since missing pieces explanation expected available later, agentdelays explanation resorts rote learning instructed step.Instructo-Soar, rote learning occurs side effect language comprehension.reading sentence, agent learns set rules encode sentence'ssemantic features. rules allow NL-Soar resolve referents later sentences, implementing simple version Grosz's focus space mechanism (Grosz, 1977). rules recordinstruction, indexed goal applies place instructionsequence. result essentially episodic case records specific, lock-step sequence instructions given perform new operator. instance, recorded\to pick-up (that is, new-op14) red block, rb1, first told move yellow table, yt1." course, information contained within case could generalized,point generalization would purely heuristic, agent cannotexplain steps episode. Thus, Instructo-Soar takes conservative approachleaving case rote form.Finally, agent told \The operator finished," indicating goalnew operator achieved. instruction triggers agent learn terminationconditions new operator. Learning termination conditions inductive conceptformation problem: agent must induce features hold currentstate imply positive instance new operator's goal achieved. Standard conceptlearning approaches may used here, long produce strong hypothesis withinsmall number examples (due \fast learning" requirement, T2). Instructo-Soaruses simple heuristic strongly bias induction: hypothesizes everythingchanged initial state new operator requested currentstate part new operator's termination conditions. case, changesrobot docked table, holding block, block gripperair.294fiFlexibly Instructable Agentsheuristic gives reasonable guess, clearly simple. Conditionschanged may matter; e.g., perhaps doesn't matter picking blocksrobot ends table. Unchanged conditions may matter; e.g., learning build\stoplight," block colors important although change. Thus, agentpresents induced set termination conditions instructor possible alterationverification. instructor add remove conditions. example, \pickup" case instructor might say \The robot need docked yellow table"remove condition deemed unnecessary, verifying termination conditions.Instructo-Soar performs induction EBL (chunking) overgeneral theorymake inductive leaps (similar to, e.g., Miller, 1993; Rosenbloom & Aasman, 1990;VanLehn, Ball, & Kowalski, 1990). type inductive learning advantageagent alter bias ect available knowledge. case, agentuses instruction (the instructor's indications features add remove) alterinduction. knowledge sources could employed (but currentimplementation) include analogy known operators (e.g., pick actionsdomains), domain-specific heuristics, etc.first execution new operator, then, agent:Carries sequence instructions achieving new operator.Learns operator template new operator.Learns mapping natural language new operator.Learns rote execution sequence new operator.Learns termination conditions new operator.Since agent learned necessary parts operator, ableperform task without instruction. However, since implementationoperator rote, perform exact task. learned generallypick things yet.6.2.2 Generalizing New Operator's Implementationagent knows goal concept full (though rote) implementation sequencenew operator. Thus, information needs explain instructionimplementation sequence leads goal achievement, provided underlying domainknowledge sucient.instruction explained recalling episodic memory internally projecting effects rest path achievement termination conditionsnew operator. projection \proof" instructed operator leadgoal achievement situation. Soar's chunking mechanism essentially computesweakest preconditions situation instruction required success (similarstandard EBL) form general rule proposing instructed operator. rule learnedinstruction \Move yellow table" shown Figure 8. rule generalizesoriginal instruction dropping table's color, specializes adding factstable object sitting object small (only small objects295fiHuffman & Lairdgoal new-op-14(?obj),?obj table ?t, small(?obj),robot docked ?t,gripper status(open),propose operator move-to-table(?t).Figure 8: general operator proposal rule learned instruction \Moveyellow table" (new-op-14 newly learned \pick up" operator).grasped gripper). rule also tests gripper open,condition important grasping block instructed case.9learning general proposal rules step instruction sequence, agentperform task without reference rote case. instance, asked \Pickgreen block," agent selects new-op14, instantiated green block. Then,general sub-operator proposal rules like one Figure 8 fire one one, matchcurrent situation, implement operator. performing implementationsteps, agent recognizes termination conditions met (the gripper raisedholding green block), new-op14 terminated.Since general proposal rules implementing task directly conditionalstate, agent perform task starting state along implementationpath react unexpected conditions (e.g., another robot stealing block).contrast, rote implementation initially learned applied startingoriginal starting state, reactive steps conditionalcurrent state.6.3 Recall Strategiesdescribed agent recalls explains step new operator's implementation sequence, operator's termination conditions induced.still two open issues: (A) point learning termination conditionsagent perform recall/projection?, (B) many steps recalledprojected sequence time?investigate issues, implemented two different recall/project strategies:1. Immediate/complete recall. agent recalls attempts explain fullsequence instructions new operator immediately learning newoperator's termination conditions.2. Lazy/single-step recall. agent recalls attempts explain single instructions sequence asked perform operator startinginitial state. is, point execution operator, agent9. technical details Soar's chunking mechanism forms rules found (Huffman,1994; Laird, Congdon, Altmann, & Doorenbos, 1993).296fiFlexibly Instructable Agentsrecalls next instruction, attempts explain forward projecting it. However, projection result path goal achievement withoutinstructions recalled, rather recalling next instructionsequence continue forward projection, agent gives explaininginstruction simply executes external world.strategies represent extremes continuum strategies.10 strategyuse parameter agent; dynamically select strategiesrunning. possible extension would reason time pressure differentsituations select appropriate strategy. Next, brie describe implicationsrecall strategy.6.3.1 Immediate/Complete Recall StrategyImmediate/complete recall explanation involves internally projecting multiple operators(the full instruction sequence) immediately first execution new operator.projection begins state agent new operator first suggested.projection successfully achieves termination conditions new operator,agent learns general implementation rules every step. advantage strategyagent learns general implementation new operator immediatelyfirst execution (e.g., agent pick objects right away).strategy three important disadvantages. First, requires agent reconstruct initial state commanded perform new operator.reconstruction may dicult amount information state large (althoughsmall robotic domain used here).Second, recall projection entire sequence instructed steps time-consuming,requiring time proportional length instruction sequence. process,agent's performance tasks hand suspended. suspension could awkwardagent pressure act quickly.Third, illustrated Figure 9, multiple step projections susceptible compounding errors underlying domain knowledge. projection successive operatorbegins state ects agent's knowledge effects prior operatorssequence. knowledge incomplete incorrect, state moveecting actual effects prior operators. Minor domain knowledge problems knowledge individual operators, alone would produce errorsingle step explanation, may combine within projection cause error.lead incomplete explanations (more rarely) spuriously successful explanations (e.g.,reaching success early instruction sequence).6.3.2 Lazy/Single-Step Recall Strategylazy/single-step recall strategy, agent waits recall explain instructionsasked perform new operator second time initial state. addition,agent recalls single instruction internally project time. recalled10. also implemented lazy/complete recall strategy, described (see Huffman,1994, details).297fiHuffman & LairdopXop1S1op1op2S2S2op3S3...G tcopXInternally projected path(reflecting agents incorrectknowledge operator effects)Sxstates reflectingactual operator effectsSxstates reflectingprojected operator effectsG tcstate meetstermination conditionscurrent goalop2S3op3... Sn (= G )tcCorrect path (reflectingactual operator effects)Figure 9: Multiple step projections result incomplete explanations due compounding errors domain knowledge.operator projected, agent applies whatever general knowledge restimplementation new operator. general knowledge, however,include rote memories past instructions. is, agent knowrest path complete new operator using general knowledge, recallinstructions sequence rote memories. Rather, internal projectionterminated single recalled operator applied external world.strategy addresses three disadvantages immediate/complete strategy.First, require reconstruction original instruction state; rather, waitssimilar state occur again.Second, recalling projecting single instruction time require timeconsuming introspection suspends agent's ongoing activity. \pick up,"instance, Table 5 shows longest time agent's external action (movementsinstruction requests) suspended using strategy (as measured Soar decision cycles,last 35 milliseconds Instructo-Soar SGI R4400 Indigo).immediate/complete strategy external actions 304 decision cycles (about11 seconds Indigo) immediately following first execution, order recallexplain complete instruction sequence. Using lazy/single-step strategy,one instruction ever recalled/explained time action taken world;thus, longest time without action 75 decision cycles (about 2 seconds).total recall/explanation time proportional length instruction sequencecases (304 vs. 294 decision cycles), lazy/single-step strategy, timeinterleaved execution instructions rather fully taken firstexecution.Third, lazy/single-step strategy overcomes problem compounding domaintheory errors beginning projection instruction current stateworld external execution previous instructions. Thus, beginning stateprojection correctly ects effects previous operators implementationsequence.major disadvantage strategy requires number executionsnew operator equal length instruction sequence order learn whole298fiFlexibly Instructable AgentsImmediate/complete Lazy/single-stepLargest time without external action 30475Largest total recall/explanation time 304 (end 1st exec'n) 294 (during 2nd exec'n.)executionDecision cycles (log scale)Table 5: Timing comparison, Soar decision cycles, learning \pick up" using immediate/complete lazy/single-step recall strategies.1000(r = 0.98)(r = 0.98)100010010010110Execution number (log scale), "pick up"(a)110Execution number (log scale), "move left of"(b)Figure 10: Decision cycles versus execution number learn (a) pick (b) moveobjects left one another, using lazy/single-step strategy.general implementation. limiting recall single step allows singlesub-operator per execution generalized. disadvantage, however, leads twointeresting learning characteristics:Back-to-front generalization. Generalized learning starts end implementation sequence moves towards beginning. second executionnew operator, path goal known last instruction sequence(it leads directly goal completion), general proposal instructionlearned. third execution, second last instruction projected,proposal learned previously last operator applies, leading goal achievementallowing general proposal second last instruction learned.pattern continues back entire sequence full implementationlearned generally. Figure 10 shows, resulting learning curves closely approximate power law practice (Rosenbloom & Newell, 1986) (r = 0:98 (a)(b)).Effectiveness hierarchical instruction. Due back-to-front effect,agent learns new procedure quickly steps taught using hierarchical organization taught sequence. Figure 11 depictsat, nine-step instruction sequence teaching Instructo-Soar move one block299fiHuffman & Laird1move left of(block, block2)642move armmove table (table)3graphical10moveleftof(arm,block2)75move (block)Figure 11:8move armclose gripperviewmove armmove table (table)move-left-of(block,block2).open gripper9instructionsequence1move left of(block, block2)2119moveleftof(arm,block2)pick (block)put (block)10move table (table)34move table (table)865move (block)Figure 12:12move armgrasp (block)graphicalmove arm13open gripper7move armviewclose gripperhierarchical instruction sequencemove-left-of(block,block2). New operators shown bold.left another; Figure 12 depicts hierarchical instruction sequence procedure, contains 13 instructed steps, maximum 3 subsequence.breaking instruction sequence shorter subsequences, hierarchical organization allows multiple subtrees hierarchy generalized execution.General learning N step operator takes N executions usinginstructionHpN subtaskssequence. Taught hierarchicallyH-levelhierarchypsubsequence, H H N executions required full generalization. hierarchy Figure 12 irregular structure, results apspeeduplength every subsequence small (in case, smaller N ). Empirically,sequence Figure 11 takes nine (N ) executions generalize, whereas hierarchical sequence takes six. Hierarchical organization additional advantageoperators learned used future instructions.300fiFlexibly Instructable Agents6.4 Supporting Command FlexibilityCommand exibility (requirement I2 ) stipulates instructor may request eitherunknown procedure, known procedure agent know performcurrent state (skipping steps), point. lead multiple levels embeddedinstruction. seen, Instructo-Soar learns completely new proceduresinstructions unknown commands. addition, agent asked performknown procedure unfamiliar situation { one agent knowstep take { learns extend knowledge procedure situation.example contained instructions \Pick red block," agentasked \Move red block." agent knows perform operatorarm raised. However, case arm lowered, agent reachesimpasse asks instruction.11 told \Move up," agent internallyprojects raising arm, allows achieve moving red block.projection learns general rule: move arm trying move objecttable agent docked at. rule extends \move above" procedurecover situation.operator { even one previously learned instruction { may require extensionapply new situation. agent learns general implementationnew operator, reason possible situations operatormight performed, limits explanations series situations arisesactual execution new operator learned.Newly learned operators may included instructions later operators, leadinglearning operator hierarchies. One hierarchy operators learned Instructo-Soarshown Figure 13. Learning procedural hierarchies identified fundamentalcomponent children's skill acquisition tutorial instruction (Wood, Bruner, & Ross,1976). learning hierarchy Figure 13, Instructo-Soar learned four new operators, extension known operator (move above), extension new operator(extending \pick up" work robot already holding block). commandexibility, hierarchy taught exponentially many different ways (Huffman, 1994). instance, new operators appear sub-operators (e.g., grasp)taught either teaching higher operators (e.g., pick up).6.5 Abandoning Explanation Domain Knowledge Incompletegeneral operator implementation learning described thus far depends explaininginstructions using prior domain knowledge (as opposed learning operator termination conditions, inductive). domain knowledge incomplete, makingexplanation impossible? sequences multiple operators, pinpointing knowledgemissing extremely dicult credit assignment problem (sequences known containone operator, however, constrained case, described next section).11. Another option would search; i.e., apply weak method means-ends analysis.example, search would easy; cases, could costly. event, since goalInstructo-Soar investigate use instruction, agent always asks instructionsreaches impasse task performance. Nothing Instructo-Soar precludes use searchknowledge sources, however.301fiHuffman & Lairdlineup(block1,block2,block3)move left of(block2,block1)pick (block)move armmoveleftof(arm,block1)move table (table)grasp (block)put (blockX)move left of(block3,block2)put (block)move arm(lg. metal)open grippergrasp (magnet)move (block)move arm(small)move table (table)move (blk/mag)move armclose grippermove armFigure 13: hierarchy operators learned Instructo-Soar. Primitive operatorslight print; learned operators bold.general, explanation failure detected end projection instruction sequence could caused missing knowledge operator sequence.Thus, faced incomplete explanation sequence multiple instructions,Instructo-Soar abandons explanation instead tries induce knowledge directlyinstructions (option O4).example, consider case Instructo-Soar's knowledge secondary operator effects (frame axiom type knowledge) removed teaching procedure. example, although agent knows closing hand causesstatus closed, longer knows closing hand around block causes blockheld. Now, agent taught new procedure, pick red block.first execution, agent attempts recall explain instructions usual,fails missing knowledge. is, block pickedprojection instructions, since agent's knowledge indicate held.agent records fact procedure's instructions cannot explained.Later, agent asked perform procedure, recalls instructions. However, also recalls explaining instructions failed past. Thus,abandons explanation instead attempts induce general proposal rule directlyinstruction.1212. Since incomplete explanation procedure may indicate effect(s) operatorinstruction sequence unknown, another alternative (not yet implemented Instructo-Soar) wouldagent observe effects operator sequence performed, comparingobservations effects predicted domain knowledge. differences would allow agent302fiFlexibly Instructable AgentsG: newop14 ("pick up")object: <redblock><redblock> <yellowtable>OP: movetotabledestination: <yellowtable>Figure 14: use OP-to-G-path heuristic, OP \move yellow table,"G \pick red block."\pick up" example, agent first recalls command move yellowtable. learn proposal rule operator (call OP ), agent must induce setconditions state performing OP contribute achieving \pickup" goal (call G). Instructo-Soar uses two simple heuristics induce stateconditions:OP-to-G-path. object Obj 1 filling slot OP , object Obj 2attached G, include shortest existing path (heuristically length lessthree) relationships Obj 1 Obj 2 set induced conditions.heuristic captures intuition operator involves object,relationship objects relevant goal probably important. Figure 14shows operation \move yellow table." figure indicates,path G's object, red block, destination OP , yellow table,relationship block table.OP-features-unachieved. termination condition (essentially, primaryeffect) OP achieved state OP performed consideredimportant condition.heuristic captures intuition primary effects OP probablyimportant; therefore, matters achieved OP selected.example, OP 's primary effect robot ends docked table; thus,fact robot initially docked table added inferred setconditions proposing OP .heuristics implemented Soar operators compute appropriate conditions. set conditions induced, presented instructor, addremove conditions verifying them. Upon verification, rule learned proposing OP(e.g., move-to-table(?t)) induced conditions hold (e.g., goal pick-up(?b),?b isa block, on(?b,?t)). rule similar rule learned explanation (Figure 8), applies picking block (overspecific), stipulatelearn new operator effects could complete explanation procedure. Learning effectsoperators observation explored number researchers (Carbonell & Gil, 1987;Pazzani, 1991b; Shen, 1993; Sutton & Pinette, 1985; Thrun & Mitchell, 1993).303fiHuffman & Lairdobject must small (overgeneral). similar induction occurs step \pick up,"agent learns general implementation full \pick up" operator. However,unless corrections made instructor, induced implementation correctone learned explanation; instance, applies (wrongly) block insteadsmall object. complex domain, inferring implementation rules wouldeven less successful. surprisingly, psychological research shows human subjects'learning procedural instructions also degrades lack domain knowledge (Kieras& Bovair, 1984).Returning targeted instruction requirements Table 4, Instructo-Soar's learning procedures illustrates (T1) general learning specific instructions, (T2) fast learning (because procedure need instructed once) (T3) using prior domainknowledge construct explanations, (T4) incremental learning agent's ongoing performance. Two types PSCM knowledge learned: (T5(b)) operator proposalssub-operators procedure, (T5(e)) procedure's termination conditions.learning involves either delayed explanation, domain knowledge inadequate,abandoning explanation favor simple induction. instructions (I3 (a)) implicitly situated imperative commands, either (I2(a)) known procedures, (I2(b)) knownprocedures steps skipped, (I2(c)) unknown procedures.7. Beyond Imperative CommandsNext, turn learning remaining types PSCM knowledge (T5(a,c,d)) variouskinds explicitly situated instructions (I3(b)). explicitly situated instruction,Instructo-Soar constructs hypothetical situation (goal state) includesobjects, properties, relationships mentioned explicitly instruction wellfeatures current situation needed carry instruction.13hypothetical situation used context situated explanation instruction.7.1 Hypothetical Goals Learning Effects Operatorsgoal explicitly specified instruction purpose clause (DiEugenio, 1993): \ToX, Y." basic knowledge learned instruction operatorproposal rule goal achieve X.Consider example Instructo-Soar's domain:> turn light, push red button.agent taught push buttons, know red button'seffect light. purpose clause instruction like example, agent createshypothetical situation goal stated purpose clause (here, \turn light"),state like current state, goal achieved (here, light off).Within situation, agent attempts explain instruction forward projectingaction pushing red button.agent knew pushing red button toggles light, projection,light would come on. Thus, explanation would succeed, general operator13. See (Huffman, 1994) details features determined.304fiFlexibly Instructable Agentsproposal rule would learned, proposed pushing red button lightgoal turn on.However, since actuality agent missing knowledge (MK ) pushingbutton affects light, light come within projection. explanationincomplete.Instructo-Soar's explanation sequence operators fails, agenttry induce missing knowledge needed complete explanation,could associated multiple operators. Rather, explanation simplyabandoned, described Section 6.5. However, case, unexplainable sequencecontains one operator. addition, form instruction gives agentstrong expectation operator's intended effect. Based purpose clause,agent expects specified action (pushing button) cause achievementspecified goal (turning light). DiEugenio (1993) found empirically typeexpectation holds 95% naturally occurring purpose clauses.expectation constrains \gap" incomplete explanation: statepushing button state light on, one action performedproduce effect. Based constrained gap, agent attempts induce missingknowledge MK order complete explanation (option O2). straightforwardinference MK simply unknown effect single action produceexpected goal conditions { e.g., pushing button cause light come on.instructor asked verify inference.14verified, Instructo-Soar heuristically guesses state conditionseffect occur. uses OP-to-G-path heuristic naive causalitytheory (Pazzani, 1991a) guess causes inferred operator effect. Here, OP-toG-path notices light red button table. addition,agent includes fact inferred effect hold (the light off)operator caused it. result presented instructor:think push button causes:lightfollowing conditions:light currently on, light table, button tableright conditions?Here, heuristics recognized matters button pushed (the redone). instructor add condition saying ``The button must red.''instructor verifies conditions, agent adds new piece operator effectknowledge memory:projecting push-button(?b),?l isa light status off, table ?t,?b isa button color red, table ?t,light ?l status on.14. inference rejected, agent abandons explanation directly induces proposal rulepushing button instruction, described Section 6.5.305fiHuffman & LairdImmediately learned, rule applies light forward projectioncurrent instruction. light comes on, completing instruction's explanationachieving goal. explanation, agent learns proposal rule proposespushing red button goal turn light. Thus, agent acquirednew knowledge multiple levels; inferring unknown effect operator supportedlearning proposal operator.example illustrates (I3 (b)) use hypothetical goal instructions useoption O2 dealing incomplete explanations { inferring missing knowledge {learn new operator effects (T5(d)), thus extending domain knowledge.7.2 Hypothetical States Learn ContingenciesInstructors use instructions hypothetical states (e.g., conditionals: \If [state conditions], ...") either teach general policies (\If lights leaveroom, turn off.") teach contingencies performing task. InstructoSoar handles these; here, describe latter.contingency instruction indicates course action followed currenttask performed future situation different current situation. Instructorsoften use contingency instructions teach situations differ currentone crucial way alter agent's behavior. Contingency instructionscommon human instruction; Ford Thompson (1986) found 79%conditional statements instruction manual communicated contingency optionsstudent.Consider interaction:> Grasp blue block.That's new one me. that?> blue block metal, pick magnet.blue block made metal, instructor communicating were,different course action would required.conditional instruction \If blue block metal, pick magnet,"agent needs learn operator proposal rule picking magnet appropriate conditions. agent begins constructing hypothetical situation\pick magnet" applies. \If blue block metal" indicates hypothetical statevariant current state blue block material metal.current goal (\Grasp blue block") also goal hypothetical situation.Within situation, agent projects picking magnet explainallow block grasped. However, agent missing much knowledge neededcomplete explanation. know goal concept \Grasp" yet, restinstructions reach goal.Since instruction explained contingency, rest instructionsagent given \Grasp blue block" may (and case, not) applycontingent situation, block metal. normal grasp sequence,instance, agent learns close hand around grasped object, graspingmetal object, hand closed around magnet. Since knowledge complete306fiFlexibly Instructable Agentsgrasping metal object needed explain contingency instruction, agentknow might learn missing knowledge, abandons explanation(option O4). Instead, uses heuristics described Section 6.5 directly induceoperator proposal rule \Grasp magnet." addition conditions generatedheuristics, conditions indicated antecedent instruction included.result presented instructor alteration verification:I'm guessing conditions \pick magnet"goal \grasp block" are:block metalright?> Right.interaction agent learns rule proposes picking magnetgoal grasp metal block. learning completed, since agent yetfinished grasping blue block, continues receive instruction task.contingencies indicated point. Learning contingencies illustrates (I3(b))handling hypothetical state instructions.7.3 Learning Reject Operatorsfinal examples illustrate learning reject operator { type operator controlknowledge PSCM. examples also detail remaining option dealingincomplete explanations: (O3) completing explanation instruction.Consider instructions:> Never grasp green blocks.Why?(a) > Trust me.(b) > Green blocks explosive.negative imperative prohibits step applying hypothetical situationmight apply. Thus, Instructo-Soar creates hypothetical situationprohibited action might executed; case, state graspable green block.Since goal specified instruction, current goal, defaultgoal \maintaining happiness" (which always considered one agent's current goals)used. hypothetical situation, agent internally projects \grasp" action,expecting \unhappy" result. However, resulting state, agent graspinggreen block, acceptable according agent's knowledge. Thus, projectionexplain action prohibited.agent deals incomplete explanation asking instruction,attempt learn MK complete explanation. However, instructor declinegive information saying (a) Trust me. Although instructor provide MK , prohibition single operator (grasping green block)explained, agent induce plausible MK complete explanation (optionO2). Since agent knows final state prohibited operator meant\unhappy", simply induces state avoided. converse learning recognize desired goal reached (learning operator's termination307fiHuffman & Lairdconditions). agent conservatively guesses features hypotheticalstate (here, green block held), taken together, make stateavoided. inference conservative, current implementationinstructor even asked verify it. state inference rule results follows:goal ``happiness'',?b isa block color green,holding(gripper,?b),state fails achieve ``happiness''.rule applies final state projection \Never grasp..." state's failureachieve happiness completes agent's explanation \Never grasp...,"learns rule rejects proposed operator grasping green block.Alternatively, instructor could provide instruction, (b) Green blocksexplosive. instruction provide missing knowledge MK needed complete incomplete explanation (option O3). (b), agent learns state inferencerule: blocks color green explosiveness high. Instructo-Soar learns stateinferences simple statements like (b), conditionals (e.g., \If magnetpowered directly metal block, magnet stuck block") essentially translating utterance directly rule.15 state inference instructionsused introduce new features extend agent's representation vocabulary(e.g, stuck-to).rule learned \Green blocks explosive" adds explosiveness highblock agent simulated grasping hypothetical situation. agent knowstouching explosive object may cause explosion { negative result. negativeresult completes explanation \Never grasp...," agent learns avoidgrasping objects explosiveness high.Completing explanation instruction (as (b)) producegeneral learning heuristically inferring missing knowledge (as (a)). (b),agent later told Blue blocks explosive, avoid grasping well.general, multiple levels instruction lead higher quality learning single levellearning based explanation composed strong lower-level knowledge(MK ) rather inductive heuristics alone. MK (here, state inference rule) alsoavailable future use.agent learned reject \grasp" operator recognizebad state performing would lead to, agent recognize bad statereached another path. instance, agent led individualsteps grasping explosive block without instructor ever mentioning \grasp."agent finally asked \Close gripper" around explosive object, so,immediately recognizes undesirable state arrived reversesclose-gripper action. process, learns reject close-gripper handaround explosive object, future reach undesirable statepath.15. translation occurs chunking, uninteresting way. Instructo-Soar use explanation learn state inferences. extension would try explain inference holds usingdeeper causal theory.308fiFlexibly Instructable AgentsNotice effect situated nature Instructo-Soar's learning. agentlearns avoid operators lead bad state arise agent'sperformance. initial learning bad state recognitional rather predictive.Alternatively, agent first learns bad state, could extensive reasoningdetermine every possible operator could lead state, every possibleprevious state, learn reject operators appropriate times. unsituatedreasoning would expensive; agent would reason huge numberpossible situations. addition, whenever new operators learned, agent wouldreason possible situations could arise, learncould ever led bad state. Rather costly reasoning, Instructo-Soar simplylearns situations arise.Another alternative completely avoiding bad states would thinkeffects every action taking it, see bad state result. highly cautiousexecution strategy would appropriate dangerous situations, appropriatesafer situations agent time pressure. (Moving lesscautious execution strategies currently implemented Instructo-Soar.)\Never grasp..." examples illustrated agent's learning one typeoperator control knowledge, namely operator rejection (T5(c)), learning state inferences(T5(a)), use instruction complete incomplete explanations (option O3).final category learning discuss second type operator control knowledge.7.4 Learning Operator Comparison KnowledgeAnother type control knowledge besides operator rejection rules operator comparisonrules, compare two operators express preference one givensituation. Instructo-Soar learns operator comparison rules asking instructor'sfeedback multiple operators proposed point achieve particulargoal. Multiple operators proposed, instance, agent taught twodifferent methods achieving goal (e.g., pick metal block either usingmagnet directly gripper). instructor asked either select oneproposed operators indicate action appropriate. Selecting oneproposed choices causes agent learn rule prefers selected operatorproposed operators situations like current situation. Alternatively,instructor indicates operator outside set proposed operators,Instructo-Soar attempts explain operator usual way, learn generalrule proposing it. addition, agent learns rules preferring instructed operatorcurrently proposed operators.two weaknesses Instructo-Soar's learning operator comparison rules.First, instructor required indicate preference step needed complete procedure, rather simply choosing overall methods. is,instructor cannot say \Use method grab block gripper, insteadusing magnet," must indicate preference individual step methodemploying gripper. PSCM, knowledge steps procedureaccessed independently, separate proposal rules, rather aggregate method.Independent access improves exibility reactivity { agent combine steps309fiHuffman & Lairddifferent methods needed based current situation { higher level groupingsteps would simplify instruction selecting complete methods.second weakness although agent uses situated explanation explainselection instructor makes, explain selection betterpossibilities. Preferences viable operators often based global considerations;e.g., \Prefer actions lead overall faster/cheaper goal achievement." Learning basedtype global preference (which turn may learned instruction)point research.8. Discussion Resultsshown Instructo-Soar learns various kinds instructions. Althoughdomain used demonstrate behavior simple, enough complexity exhibitvariety different types instructional interactions occur tutorial instruction.11 requirements tutorial instruction places instructable agent (listedTable 1), Instructo-Soar meets 7 (listed expanded form Table 4) either fully partially. Three particular distinguish Instructo-Soar previous instructablesystems:Command exibility: instructor give command taskinstruction point, whether agent knows task performcurrent situation.Situation exibility: agent learn implicitly situated instructionsexplicitly situated instructions specifying either hypothetical goals states.Knowledge-type exibility: agent able learn types knowledge uses task performance (the five PSCM types) instruction.Earlier, claimed handling tutorial instruction's exibility requires breadthlearning interaction capabilities. Combining command, situation, knowledge-typeexibility, Instructo-Soar displays 18 distinct instructional capabilities, listed Table 6. variety instructional behavior require 18 different learning techniques,arises one general technique, situated explanation PSCM-based agent, appliedrange instructional situations.series examples illustrated situated explanation uses instruction'ssituation context learning process. First, situation instruction applies provides endpoints attempting explain instruction. Second,instructional context indicate option follow explanation cannotcompleted. context learning new procedure indicates delaying explanation(option O1) best, since full procedure eventually taught. step cannotexplained previously taught procedure, missing knowledge could anywhereprocedure, best abandon explanation (option O4) learn another way. Instructions provide explicit context, purpose clause, localize missingknowledge giving strong expectations single operator achieve singlegoal. localization makes plausible induce missing knowledge complete310fiFlexibly Instructable Agents1.2.3.4.5.6.7.Instructional capabilityLearning completely new proceduresExtending procedure apply new situationHierarchical instruction: handling instructionsprocedure embedded instruction othersAltering induced knowledge basedinstructionLearning procedures inductively domainknowledge incompleteLearning avoid prohibited actionsgeneral learning due instruction8. Learning avoid indirect achievement badstate9. Inferences simple specific statements10. Inferences simple generic statements11. Inferences conditionals12. Learning operator perform hypotheticalgoal13. Learning operator perform hypotheticalstate: general policy (active times)14. Learning operator perform hypotheticalstate: contingency within particular procedure15. Learning operator effects16. Learning non-perceivable operator effects associated inferences recognize17. Learning control knowledge: learning setoperators prefer18. Learning control knowledge: learning operatorsindifferentExamplepickmove moveteaching pick within lineremoving docked-at pickup's termination conditionslearning secondary operatoreffects knowledge removed\Never grasp red blocks."Avoid grasping \Redblocks explosive."closing hand around explosiveblock\The grey block metal."\White magnets powered."\if condition [and condition]*concluded state feature"\To turn light, pushred button."\If light bright, dimlight."\If block metal, graspmagnet" pickpushing red button turnslightmagnet becomes stuck-tometal block movedtwo ways grasp small metalblocktwo ways grasp small metalblockTable 6: Instructional capabilities demonstrated Instructo-Soar.311fiHuffman & Lairdexplanation (option O2). cases, default ask instruction missingknowledge complete explanation (option O3).8.1 Empirical Evaluationempirical evaluations machine learning systems take one four forms, appropriate addressing different evaluation questions:A. Comparison systems. technique useful evaluating overallperformance compares state art. usedsystems available learning task.B. Comparison altered version system. technique evaluatesimpact component system overall performance. Typically,system compared version without key component (sometimes called\lesion study").C. Measuring performance systematically generated series problems. technique evaluates method affected different dimensions input (e.g.,noise training data).D. Measuring performance known hard problems. Known hard problems provideevaluation overall performance extreme conditions. instance, conceptlearners' performance often measured standard, dicult datasets.evaluation techniques applied limited ways Instructo-Soar.dicult apply great depth two reasons. First, whereas machinelearning efforts concentrate depth single type learning single type input,tutorial instruction requires breadth learning range instructional interactions. Whereas depth measured quantitative performance, breadth measured(possibly qualitative) coverage { here, coverage 7 11 instructability requirements. Second, tutorial instruction extensively studied machine learning,battery standard systems problems available. Nonetheless, evaluationtechniques (B), (C), (D) applied Instructo-Soar address specificevaluation questions:B. Comparison altered version: removed frame-axiom knowledge illustrateeffect prior knowledge agent's performance, described Section 6.5.Without prior knowledge, agent unable explain instructions must resortinductive methods. Thus, removing frame-axiom knowledge increased amountinstruction required reduced learning quality. also compared versionsagent use different instruction recall strategies (Section 6.3).C. Performance systematically varied input: examined effects varying threedimensions instructions given agent. First, compared learning curvesinstruction sequences different lengths (Section 6.2). graphs Figure 10show, Instructo-Soar's execution time instructed procedure variesnumber instructions sequence used teach it. Total execution time drops312fiFlexibly Instructable Agentstime procedure executed, according power law function, procedure learned general form. Second, compared teaching procedurehierarchical subtasks versus using instruction sequence. Basedpower law result, predicted hierarchical instruction would allow faster generallearning instruction. prediction confirmed empirically. Third,examined number instruction orderings used teach given procedure Instructo-Soar order measure value supporting commandexibility. Rather experimental measurement, performed mathematicalanalysis. analysis showed due command exibility, number instruction sequences used teach given procedure large, growingexponentially number primitive steps procedure (Huffman, 1994).D. Performance known hard problem: Since learning tutorial instructionextensively studied machine learning, standard, dicultproblems. created comprehensive instruction scenario crossing commandexibility, situation exibility, knowledge-type exibility requirements. scenario, described detail (Huffman, 1994), contains 100 instructions demonstrates 17 Instructo-Soar's 18 instructional capabilities Table 6 (itinclude learning indifference selecting two operators). agent learns4,700 chunks scenario, including examples type PSCMknowledge, extend agent's domain knowledge significantly.9. Limitations Researchwork's limitations fall three major categories: limitations tutorial instructionteaching technique, limitations agent's general capabilities, limitationsincomplete solutions mapping, interaction, transfer problems. discussturn.9.1 Limitations Tutorial InstructionTutorial instruction highly interactive situated. However, much humaninstruction either non-interactive unsituated (or both), considered work. non-interactive instruction, content ow informationstudent controlled primarily information source. Examples include classroomlectures, instruction manuals, textbooks. One issue using type instructionlocating extracting information needed particular problems (Carpenter& Alterman, 1994). Non-interactive instruction contain situated information (e.g.,worked-out example problems, Chi et al., 1989; VanLehn, 1987) unsituated information(e.g., general expository text).Unsituated instruction conveys general abstract knowledge appliedlarge number different situations. general-purpose knowledge often described\declarative" (Singley & Anderson, 1989). example, physics class, studentstaught F = a; general equation applies specific ways great varietysituations. advantage unsituated instruction precisely ability compactlycommunicate abstract knowledge broadly applicable (Sandberg & Wielinga, 1991).313fiHuffman & LairdHowever, use abstract knowledge, students must learn applies specificsituations (Singley & Anderson, 1989).9.2 Limitations Agentagent's inherent limitations constrain taught. developedtheory learning tutorial instruction within particular computational modelagents (the PSCM), within computational model, implemented agentparticular set capabilities demonstrate theory. Thus, weaknessescomputational model specific implemented agent must examined.9.2.1 Computational Modelproblem space computational model well suited situated instructionelements' close correspondence knowledge level (facilitating mappinginstructions elements), inherently local control structure. However,PSCM's local application knowledge makes dicult learn global control regimesinstruction, must translated series local decisionsresult local learning.second weakness PSCM provides theory functional typesknowledge used intelligent agent, gives indication possible contentknowledge. content theory knowledge would allow finer grained analysisagent's instructability, within larger-grained knowledge types analysis providedPSCM.9.2.2 Implemented Agent's CapabilitiesProducing definitive agent goal work. Rather, InstructoSoar agent's capabilities developed needed demonstrate instructional learning capabilities. Thus, limited number ways.16 instance,performs simple actions serially static world. would sucient dynamicdomain ying airplane, multiple goals multiple levels granularity,involving achievement and/or maintenance conditions environment, mayactive (Pearson et al., 1993). Instructo-Soar's procedures implementedseries locally decided steps, precluding instruction containing procedure-wide (i.e., nonlocal) path constraints (e.g., \Go room, don't walk carpeting!").single agent world, precluding instructions involve cooperationagents (e.g., two robots carrying couch) instructions require reasoningagents' potential actions (e.g., \Don't go alley, enemymay block in.")agent complete perception (clearly unrealistic real physical domains),never told look, asked notice feature overlooked. contrast, instruction protocols show human students often told attendfeatures notice. Instructo-Soar's world noise-free, agent need16. limitations particular agent implemented here, Soar, usedbuild powerful agents (e.g., Jones et al., 1993; Pearson et al., 1993).314fiFlexibly Instructable Agentsreason receive instruction failed actions. complete perceptionnoise-free environment, agent explicitly reason uncertaintyperceptions actions, demonstrated handling instructions explicitlydescribe uncertain probabalistic outcomes.17 agent also reason time(as, e.g., Vere Bickmore's (1990) Homer does), cannot taught perform taskstime-dependent way. keep track states seen actions performs(other episodic instruction memory), cannot asked \dobefore." Similarly, cannot learn procedures defined particular sequenceactions, rather set state conditions achieve. example, cannot taughtdance, dancing result net change external world. Finally, whenever agent know next, asks instruction.never tries determine solution search weak methods means-endsanalysis. Adding capability would decrease need instruction.addition agent's capabilities, Instructo-Soar limited solutionsmapping, interaction, transfer problems incomplete various ways.limitations discussed next.9.3 Mapping ProblemInstructo-Soar employs straightforward approach mapping instructionsagent's internal language, leaves problems mapping dicult natural language constructions unaddressed. relevant problems include reference resolution, incompleteness, use domain knowledge comprehension. Mappingeven require instruction, interaction resolve referent:> Grab explosive block.one that?> red one.type interaction supported Instructo-Soar.addition general linguistic problems, Instructo-Soar makes limiteduse semantic information learning new operators. example, first reads\Move red block left yellow block," creates new operator, makeuse semantic information communicated \Move...to left of." completeagent would try glean information could semantics unfamiliarcommand.9.4 Interaction Problemagent's shortcomings interaction problem center around three requirements:(I1) exible initiation instruction, (I2) full exibility knowledge content, (I3)situation exibility. (I1 ): Instructo-Soar, instruction initiated agent.17. instruction protocols analyzed, instructions incomplete (missing conditions likeInstructo-Soar learns), rarely described uncertainty explicitly.315fiHuffman & Lairdlimits instructor's ability drive interaction interrupt agent's actionsinstruction: \No! Don't push button!"18(I2): Instructo-Soar provides exibility commands, instructionscommunicate kinds information. Similar notion discourse coherence (Mann& Thompson, 1988), fully exible tutorable agent needs support instruction eventknowledge coherence; is, instruction event delivering knowledge makessense current context. great variety knowledge could relevantpoint makes requirement dicult.(I3): Instructo-Soar provides situation exibility handling implicitlyexplicitly situated instructions, hypothetical situations referred withinsingle instruction. Human tutors often refer one hypothetical situation coursemultiple instructions.9.5 Transfer Problemwork focused primarily transfer problem { producing general learningtutorial instruction { requirements met. However, inductiveheuristics Instructo-Soar uses powerful.addition, two transfer problem requirements achieved. First, (T7)Instructo-Soar yet demonstrated instructional learning coexistence learning knowledge sources. Nothing Instructo-Soar's theory precludes coexistence, however. Learning knowledge sources could invoked possiblyenhanced instruction. instance, instructor might invoke learning observation pointing set objects saying \This tower"; similarly, instructioncontaining metaphor could invoke analogical learning. One application instructioncould potentially enhance learning mechanisms within \personal assistant" softwareagents learn observing users (e.g., Maes, 1994; Mitchell et al., 1994). Addingability learn verbal instructions addition observations would allow usersexplicitly train agents situations learning observation alone maydicult slow.Second, (T6) Instructo-Soar cannot recover incorrect knowledge leadseither invalid explanations incorrect external performance. incorrect knowledgemay part agent's initial domain theory, may learned faultyinstruction. Inability recover incorrect knowledge precludes instruction generalcase exceptions; instance, \Never grasp red blocks," later, \It's okgrasp ones safety signs them." order avoid learning anything incorrect,whenever Instructo-Soar attempts induce new knowledge, asks instructor'sverification adding knowledge long-term memory. Human studentsask much verification; appear jump conclusions, alter laterprove incorrect based information.Rather always verifying knowledge learned, next generation instructableagents learn reasonable inferences without verification (although may askverifications extreme cases). recently produced agent (Pearson &18. recently added simple interruptability capability new version Instructo-Soarincorporates recovery incorrect knowledge (Pearson & Huffman, 1995).316fiFlexibly Instructable AgentsHuffman, 1995) incorporates current research incremental recovery incorrectknowledge (Pearson & Laird, 1995). agent learns correct overgeneral knowledgeinfers completing explanations instructions. correction process triggeredusing overgeneral knowledge results incorrect performance (e.g., actionagent expects succeed not). long run, believe work could pushresearch incremental theory revision error recovery, instructable agentstaught many types knowledge may need revision.10. ConclusionAlthough much work machine learning aims depth particular kind learning,Instructo-Soar demonstrates breadth { interaction instructor learn varietytypes knowledge { arising one underlying technique. kind breadthcrucial building instructable agent great variety instructionsvariety knowledge communicate. instructable agents beginbasic knowledge domain, Instructo-Soar uses analytic, explanationbased approach learn instructions, makes use knowledge.instructions may either implicitly explicitly situated, Instructo-Soar situatesexplanations instruction within situation indicated instruction. Finally,agent's knowledge often deficient explaining instructions, InstructoSoar employs four different options dealing incomplete explanations, selectsoptions dynamically depending instructional context.availability effectiveness, tutorial instruction potentially powerful knowledge source intelligent agents. Instructo-Soar illustrates simpledomain. Realizing instruction's potential fielded applications require linguistically able agents incorporate robust techniques acquiring knowledgeinstruction, also refining knowledge needed based performanceinstruction.Acknowledgementswork performed first author graduate student UniversityMichigan. sponsored NASA/ONR contract NCC 2-517, UniversityMichigan Predoctoral Fellowship. Thanks Paul Rosenbloom, Randy Jones,anonymous reviewers helpful comments earlier drafts.ReferencesAkatsuka, N. (1986). Conditionals discourse-bound. Traugott, E. C. (Ed.),Conditionals, pp. 333{51. Cambridge Univ. Press, Cambridge.Alterman, R., Zito-Wolf, R., & Carpenter, T. (1991). Interaction, comprehension,instruction usage. Journal Learning Sciences, 1 (3&4), 273{318.Anderson, J. R. (1983). architecture cognition. Harvard University Press, Cambridge,MA.317fiHuffman & LairdBergadano, F., & Giordana, A. (1988). knowledge intensive approach concept induction. Proceedings International Conference Machine Learning, pp.305{317.Birmingham, W., & Klinker, G. (1993). Knowledge acquisition tools explicit problemsolving methods. Knowledge Engineering Review, 8 (1).Birmingham, W., & Siewiorek, D. (1989). Automated knowledge acquisition computerhardware synthesis system. Knowledge Acquisition, 1, 321{340.Bloom, B. S. (1984). 2 sigma problem: search methods group instructioneffective one-to-one tutoring. Educational Researcher, 13 (6), 4{16.Brachman, R. J. (1980). introduction KL-ONE. Brachman, R. J. (Ed.), ResearchNatural Language Understanding, pp. 13{46. Bolt, Beranek Newman Inc.,Cambridge, MA.Carbonell, J. G., & Gil, Y. (1987). Learning experimentation. ProceedingsInternational Workshop Machine Learning, pp. 256{265.Carbonell, J. G., Michalski, R. S., & Mitchell, T. M. (1983). overview machinelearning. Michalski, R. S., Carbonell, J. G., & Mitchell, T. M. (Eds.), MachineLearning: artificial intelligence approach. Morgan Kaufmann.Carpenter, T., & Alterman, R. (1994). reading agent. Proceedings TwelfthNational Conference Artificial Intelligence Seattle, WA.Chapman, D. (1990). Vision, Instruction, Action. Ph.D. thesis, Massachusetts InstituteTechnology, Artificial Intelligence Laboratory.Chi, M. T. H., Bassok, M., Lewis, M. W., Reimann, P., & Glaser, R. (1989). Selfexplanations: students study use examples learning solve problems.Cognitive Science, 13, 145{182.Cypher, A. (Ed.). (1993). Watch do: Programming demonstration. MIT Press,Cambridge, Mass.Davis, R. (1979). Interactive transfer expertise: Acquisition new inference rules.Artificial Intelligence, 12 (2), 409{427.DeJong, G. F., & Mooney, R. J. (1986). Explanation-based learning: alternative view.Machine Learning, 1 (2), 145{176.Dent, L., Boticario, J., McDermott, J., Mitchell, T., & Zabowski, D. (1992). personallearning apprentice. Proceedings International Joint Conference ArtificialIntelligence.DiEugenio, B. (1993). Understanding natural language instructions: computational approach purpose clauses. Ph.D. thesis, University Pennsylvania. IRCS Report93-52.318fiFlexibly Instructable AgentsDiEugenio, B., & Webber, B. (1992). Plan recognition understanding instructions.Hendler, J. (Ed.), Proceedings First International Conference Artificial Intelligence Planning Systems, pp. 52{61 College Park, MD.Donoho, S. K., & Wilkins, D. C. (1994). Exploiting ordering observed problem-solvingsteps knowledge ase refinement: apprenticeship approach. Proceedings12th National Conference Artifical Intelligence Seattle, WA.Drummond, M. (1989). Situated control rules. Proceedings First International Conference Principles Knowledge Representation Toronto, Canada. Morgan Kaufmann.Emihovich, C., & Miller, G. E. (1988). Talking turtle: discourse analysis Logoinstruction. Discourse Processes, 11, 183{201.Eshelman, L., Ehret, D., McDermott, J., & Tan, M. (1987). MOLE: tenacious knowledgeacquisition tool. International Journal Man-Machine Studies, 26 (1), 41{54.Fikes, R. E., Hart, P. E., & Nilsson, N. J. (1972). Learning executing generalized robotplans. Artificial Intelligence, 3, 251{288.Ford, C. A., & Thompson, S. A. (1986). Conditionals discourse: text-based studyEnglish. Traugott, E. C. (Ed.), Conditionals, pp. 353{72. CambridgeUniv. Press, Cambridge.Frederking, R. E. (1988). Integrated natural language dialogue: computational model.Kluwer Academic Press, Boston.Golding, A., Rosenbloom, P. S., & Laird, J. E. (1987). Learning search control outsideguidance. Proceedings Tenth International Joint Conference ArtificialIntelligence, pp. 334{337.Grosz, B. J. (1977). Representation use focus dialogue understanding. Ph.D.thesis, University California, Berkeley.Gruber, T. (1989). Automated knowledge acquisition strategic knowledge. MachineLearning, 4 (3-4), 293{336.Guha, R. V., & Lenat, D. B. (1990). Cyc: mid-term report. AI Magazine, 11 (3), 32{59.Haas, N., & Hendrix, G. G. (1983). Learning told: Acquiring knowledgeinformation management. Michalski, R. S., Carbonell, J. G., & Mitchell, T. M.(Eds.), Machine Learning: artificial intelligence approach. Morgan Kaufmann.Haiman, J. (1978). Conditionals topics. Language, 54, 564{89.Hall, R. J. (1988). Learning failing explain. Machine Learning, 3 (1), 45{77.Hayes-Roth, F., Klahr, P., & Mostow, D. J. (1981). Advice taking knowledge refinement:iterative view skill acquisition. Anderson, J. R. (Ed.), Cognitive skillsacquisition, pp. 231{253. Lawrence Erlbaum Associates, Hillsdale, NJ.319fiHuffman & LairdHuffman, S. B. (1994). Instructable autonomous agents. Ph.D. thesis, University Michigan, Dept. Electrical Engineering Computer Science.Huffman, S. B., & Laird, J. E. (1992). Dimensions complexity learning interactiveinstruction. Erickson, J. (Ed.), Proceedings Cooperative Intelligent RoboticsSpace III, SPIE Volume 1829.Huffman, S. B., & Laird, J. E. (1993). Learning procedures interactive natural language instructions. Utgoff, P. (Ed.), Machine Learning: Proceedings TenthInternational Conference.Huffman, S. B., & Laird, J. E. (1994). Learning highly exible tutorial instruction.Proceedings 12th National Conference Artificial Intelligence (AAAI-94)Seattle, WA.Huffman, S. B., Miller, C. S., & Laird, J. E. (1993). Learning instruction: knowledgelevel capability within unified theory cognition. Proceedings FifteenthAnnual Conference Cognitive Science Society, pp. 114{119.Johnson-Laird, P. N. (1986). Conditionals mental models. Traugott, E. C. (Ed.),Conditionals. Cambridge Univ. Press, Cambridge.Jones, R. M., Tambe, M., Laird, J. E., & Rosenbloom, P. S. (1993). Intelligent automated agents ight training simulators. Proceedings Third ConferenceComputer Generated Forces, pp. 33{42 Orlando, FL.Just, M. A., & Carpenter, P. A. (1976). Verbal comprehension instructional situations.Klahr, D. (Ed.), Cognition Instruction. Lawrence Erlbaum Associates, Hillsdale,NJ.Kieras, D. E., & Bovair, S. (1984). role mental model learning operatedevice. Cognitive Science, 8, 255{273.Kodratoff, Y., & Tecuci, G. (1987a). DISCIPLE-1: Interactive apprentice system weaktheory fields. Proceedings Tenth International Joint Conference ArtificialIntelligence, pp. 271{273.Kodratoff, Y., & Tecuci, G. (1987b). Techniques design DISCIPLE learning apprentice. International Journal Expert Systems, 1 (1), 39{66.Laird, J. E., Congdon, C. B., Altmann, E., & Doorenbos, R. (1993). Soar user's manual,version 6..Laird, J. E., Hucka, M., Yager, E. S., & Tuck, C. M. (1990). Correcting extendingdomain knowledge using outside guidance. Proceedings Seventh InternationalConference Machine Learning.Laird, J. E., Newell, A., & Rosenbloom, P. S. (1987). Soar: architecture generalintelligence. Artificial Intelligence, 33 (1), 1{64.320fiFlexibly Instructable AgentsLaird, J. E., & Rosenbloom, P. S. (1990). Integrating execution, planning, learningSoar external environments. Proceedings Eighth National ConferenceArtificial Intelligence, pp. 1022{1029. AAAI Press.Lewis, C. (1988). learn why: Analysis-based generalization procedures.Cognitive Science, 12, 211{256.Lewis, R. L. (1993). Architecturally-Based Theory Human Sentence Comprehension.Ph.D. thesis, Carnegie Mellon University, School Computer Science.Lewis, R. L., Newell, A., & Polk, T. A. (1989). Toward Soar theory taking instructions immediate reasoning tasks. Proceedings Annual ConferenceCognitive Science Society.Lindsay, R. K. (1963). Inferential memory basis machines understand naturallanguage. Feigenbaum, E. A., & Feldman, J. (Eds.), Computers Thought, pp.217{233. R. Oldenbourg KG.Maes, P. (1994). Agents reduce work information overload. CommunicationsACM, 37 (7).Maes, P., & Kozierok, R. (1993). Learning interface agents. Proceedings NationalConference Artificial Intelligence, pp. 459{465.Mann, W. C., & Thompson, S. A. (1988). Rhetorical structure theory: Toward functionaltheory text organization. Text, 8 (3), 243{281.Marcus, S., & McDermott, J. (1989). SALT: knowledge acquisition language proposeand-revise systems. Artificial Intelligence, 39 (1), 1{37.Martin, C. E., & Firby, R. J. (1991). Generating natural language expectationsreactive execution system. Proceedings Thirteenth Annual ConferenceCognitive Science Society, pp. 811{815.McCarthy, J. (1968). advice taker. Minsky, M. (Ed.), Semantic Information Processing, pp. 403{410. MIT Press, Cambridge, Mass.Miller, C. M. (1993). model concept acquisition context unified theorycognition. Ph.D. thesis, University Michigan, Dept. Computer ScienceElectrical Engineering.Minton, S., Carbonell, J. G., Knoblock, C. A., Kuokka, D. R., Etzioni, O., & Gil, Y. (1989).Explanation-based learning: problem-solving perspective. Artificial Intelligence, 40,63{118.Mitchell, T., Caruana, R., Freitag, D., McDermott, J., & Zabowski, D. (1994). Experiencelearning personal assistant. Communications ACM, 37 (7).Mitchell, T. M., Keller, R. M., & Kedar-Cabelli, S. T. (1986). Explanation-based generalization: unifying view. Machine Learning, 1.321fiHuffman & LairdMitchell, T. M., Mahadevan, S., & Steinberg, L. I. (1990). LEAP: learning apprenticesystem VLSI design. Kodratoff, Y., & Michalski, R. S. (Eds.), Machine Learning:artificial intelligence approach, Vol. III. Morgan Kaufmann.Mooney, R. J. (1990). Learning plan schemata observation: Explanation-based learning plan recognition. Cognitive Science, 14, 483{509.Mostow, D. J. (1983). Learning told: Machine transformation adviceheuristic search procedure. Michalski, R. S., Carbonell, J. G., & Mitchell, T. M.(Eds.), Machine Learning: artificial intelligence approach. Morgan Kaufmann.Musen, M. A. (1989). Automated support building extending expert models. Machine Learning, 4 (3-4), 347{376.Newell, A. (1981). knowledge level. AI Magazine, 2 (2), 1{20.Newell, A. (1990). Unified Theories Cognition. Harvard University Press, Cambridge,Massachusetts.Newell, A., Yost, G., Laird, J. E., Rosenbloom, P. S., & Altmann, E. (1990). Formulatingproblem space computational model. Proceedings 25th AnniversarySymposium, School Computer Science, Carnegie Mellon University.Pazzani, M. (1991a). computational theory learning causal relationships. CognitiveScience, 15, 401{424.Pazzani, M. (1991b). Learning predict explain: integration similarity-based,theory driven, explanation-based learning. Journal Learning Sciences, 1 (2),153{199.Pearson, D. J., & Huffman, S. B. (1995). Combining learning instruction recoveryincorrect knowledge. Gordon, D., & Shavlik, J. (Eds.), Proceedings 1995Machine Learning Workshop Agents Learn Agents.Pearson, D. J., Huffman, S. B., Willis, M. B., Laird, J. E., & Jones, R. M. (1993).symbolic solution intelligent real-time control. IEEE Robotics AutonomousSystems, 11, 279{291.Pearson, D. J., & Laird, J. E. (1995). Toward incremental knowledge correction agentscomplex environments. Muggleton, S., Michie, D., & Furukawa, K. (Eds.), MachineIntelligence, Vol. 15. Oxford University Press.Porter, B. W., Bareiss, R., & Holte, R. C. (1990). Concept learning heuristic classification weak-theory domains. Artificial Intelligence, 45 (3), 229{263.Porter, B. W., & Kibler, D. F. (1986). Experimental goal regression: method learningproblem-solving heuristics. Machine Learning, 1, 249{286.Redmond, M. A. (1992). Learning observing understanding expert problem solving.Ph.D. thesis, Georgia Institute Technology.322fiFlexibly Instructable AgentsRosenbloom, P. S., & Aasman, J. (1990). Knowledge level inductive uses chunking(EBL). Proceedings National Conference Artificial Intelligence.Rosenbloom, P. S., & Laird, J. E. (1986). Mapping explanation-based generalization ontoSoar. Proceedings National Conference Artificial Intelligence, pp. 561{567.Rosenbloom, P. S., Laird, J. E., & Newell, A. (1988). chunking skill knowledge.Bouma, H., & Elsendoorn, A. G. (Eds.), Working Models Human Perception,pp. 391{410. Academic Press, London, England.Rosenbloom, P. S., Laird, J. E., & Newell, A. (Eds.). (1993a). Soar Papers: Researchintegrated intelligence. MIT Press, Cambridge, Mass.Rosenbloom, P. S., Laird, J. E., & Newell, A. (Eds.). (1993b). Soar Papers: Researchintegrated intelligence. MIT Press, Cambridge, Mass.Rosenbloom, P. S., & Newell, A. (1986). chunking goal hierarchies: generalizedmodel practice. Michalski, R. S., Carbonell, J. G., & Mitchell, T. M. (Eds.),Machine Learning: artificial intelligence approach, Volume II. Morgan Kaufmann.Rumelhart, D. E., & McClelland, J. L. (Eds.). (1986). Parallel distributed processing: Explorations microstructure cognition. MIT Press, Cambridge, MA.Rychener, M. D. (1983). instructible production system: retrospective analysis.Michalski, R. S., Carbonell, J. G., & Mitchell, T. M. (Eds.), Machine Learning:artificial intelligence approach, pp. 429{460. Morgan Kaufmann.Sandberg, J., & Wielinga, B. (1991). situated cognition?. ProceedingsInternational Joint Conference Artificial Intelligence, pp. 341{346.Schank, R. C. (1975). Conceptual Information Processing. American Elsevier, New York.Schank, R. C., & Leake, D. B. (1989). Creativity learning case-based explainer.Artificial Intelligence, 40, 353{385.Segre, A. M. (1987). learning apprentice system mechanical assembly. Third IEEEConference Artificial Intelligence Applications, pp. 112{117.Shen, W. (1993). Discovery autonomous learning environment. Machine Learning, 12, 143{165.Simon, H. A. (1977). Artificial intelligence systems understand. ProceedingsFifth International Joint Conference Artificial Intelligence, pp. 1059{1073.Simon, H. A., & Hayes, J. R. (1976). Understanding complex task instructions. Klahr,D. (Ed.), Cognition Instruction. Lawrence Erlbaum Associates, Hillsdale, NJ.Singley, M. K., & Anderson, J. R. (1989). transfer cognitive skill. Harvard UniversityPress.323fiHuffman & LairdSutton, R. S., & Pinette, B. (1985). learning world models connectionist networks.Proceedings Seventh Annual Conference Cognitive Science Society, pp.54{64.Thrun, S. B., & Mitchell, T. M. (1993). Integrating inductive neural network learningexplanation-based learning. Proceedings International Joint ConferenceArtificial Intelligence, pp. 930{936.VanLehn, K. (1987). Learning one subprocedure per lesson. Artificial Intelligence, 31 (1),1{40.VanLehn, K., Ball, W., & Kowalski, B. (1990). Explanation-based learning correctness:Towards model self-explanation effect. Proceedings 12th AnnualConference Cognitive Science Society, pp. 717{724.VanLehn, K., & Jones, R. (1991). Learning physics via explanation-based learning correctness analogical search control. Proceedings International MachineLearning Workshop.VanLehn, K., Jones, R. M., & Chi, M. T. H. (1992). model self-explanation effect.Journal Learning Sciences, 2 (1), 1{59.Vere, S., & Bickmore, T. (1990). basic agent. Computational Intelligence, 6, 41{60.Wertsch, J. V. (1979). social interaction higher psychological processes: clarification application Vygotsky's theory. Human Development, 22, 1{22.Widmer, G. (1989). tight integration deductive inductive learning. ProceedingsInternational Workshop Machine Learning, pp. 11{13.Wilkins, D. C. (1990). Knowledge base refinement improving incomplete incorrectdomain theory. Kodratoff, Y., & Michalski, R. S. (Eds.), Machine Learning:Artificial Intelligence Approach, Volume III, pp. 493{514. Morgan Kaufmann.Winograd, T. (1972). Understanding Natural Language. Academic Press, New York.Wood, D., Bruner, J. S., & Ross, G. (1976). role tutoring problem solving. JournalChild Psychology Psychiatry, 17, 89{100.Yost, G. R. (1993). Acquiring knowledge Soar. IEEE Expert, 8 (3), 26{34.Yost, G. R., & Newell, A. (1989). problem space approach expert system specification.Proceedings International Joint Conference Artificial Intelligence, pp.621{7.324fiJournal Artificial Intelligence Research 3 (1995) 53-118Submitted 3/95; published 7/95Building Refining Abstract Planning CasesChange Representation LanguageRalph BergmannWolfgang Wilkebergmann@informatik.uni-kl.dewilke@informatik.uni-kl.deCentre Learning Systems Applications (LSA)University Kaiserslautern, P.O.-Box 3049, D-67653 Kaiserslautern, GermanyAbstractAbstraction one promising approaches improve performance problemsolvers. several domains abstraction dropping sentences domain description {used hierarchical planners { proven useful. paper present examplesillustrate significant drawbacks abstraction dropping sentences. overcomedrawbacks, propose general view abstraction involving changerepresentation language. developed new abstraction methodology relatedsound complete learning algorithm allows complete change representationlanguage planning cases concrete abstract. However, achieve powerfulchange representation language, abstract language well rulesdescribe admissible ways abstracting states must provided domain model.new abstraction approach core Paris (Plan Abstraction RefinementIntegrated System), system abstract planning cases automaticallylearned given concrete cases. empirical study domain process planningmechanical engineering shows significant advantages proposed reasoningabstract cases classical hierarchical planning.1. IntroductionAbstraction one challenging also promising approaches improve complexproblem solving inspired way humans seem solve problems. first, lessrelevant details given problem ignored abstracted problemsolved easily. Then, step step, details added solution takingincreasingly detailed look problem. Thereby, abstract solution constructedfirst refined towards concrete solution. One typical characteristic workhierarchical problem solving abstraction mostly performed dropping sentencesdomain description (Sacerdoti, 1974, 1977; Tenenberg, 1988; Unruh & Rosenbloom,1989; Yang & Tenenberg, 1990; Knoblock, 1989, 1994; Bacchus & Yang, 1994). secondcommon characteristic hierarchical problem solver usually derives abstractsolution scratch, without using experience previous problem solving episodes.Giunchiglia Walsh (1992) presented comprehensive formal frameworkabstraction comparison different abstraction approaches theorem proving(Plaisted, 1981, 1986; Tenenberg, 1987), planning (Newell & Simon, 1972; Sacerdoti, 1974,1977; Tenenberg, 1988; Unruh & Rosenbloom, 1989; Yang & Tenenberg, 1990; Knoblock,1989, 1994), model based diagnosis (Mozetic, 1990). hierarchical planning, Korf'smodel abstraction problem solving (Korf, 1987) allows analysis reductionsc 1995 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiBergmann & Wilkesearch caused single multiple levels abstraction. shown optimalcase, abstraction reduce expected search time exponential linear. Knoblockdeveloped approach construct hierarchy abstraction spaces automaticallygiven concrete-level problem solving domain (Knoblock, 1990, 1993, 1994).called ordered monotonic abstraction hierarchies (Knoblock, Tenenberg, & Yang, 1991b)proven useful many domains. Recently, Bacchus Yang (1994) presentedimproved method automatically generating abstraction hierarchies baseddetailed model search costs.abstraction methods, however, rely abstraction dropping sentencesdomain description kind homomorphic abstraction (Holte et al., 1994,1995). shown kinds abstractions highly representation dependent (Holte et al., 1994, 1995). two classical planning domains, different \natural\representations analyzed turns several representationsclassical abstraction techniques lead significantly improved problemsolvers (Knoblock, 1994; Holte et al., 1995). However, well known normally manydifferent representations domain exist already pointed Korf (1980),theory representation developed. particular,theory representation hierarchical problem solving dropping sentences.knowledge-engineering perspective, many different aspects simplicity,understandability, maintainability must considered developing domain representation. Therefore, assume representations domains given knowledgeengineers rely representations consider \natural" certain kindsproblems. demonstrate two simple example problems related representations,usual use abstraction problem solving lead improvement.first example, improvement achieved abstraction restricteddropping sentences domain. second example, abstract solution computedscratch decompose original problem consequently cutsearch space next detailed level. want argue examplesnever represented way standard hierarchical problem solving works well.However, think would require large effort knowledge engineer developappropriate representation believe often impossible develop representation appropriate knowledge-engineering perspective also allowsecient hierarchical problem solving based dropping sentences.take observations motivation develop general model abstraction problem solving. already pointed Michalski (1994), abstraction,general, seen switching completely new representation languagelevel detail reduced. problem solving, new abstract representation languagemust consist completely new sentences operators subsetsentences operators concrete language. knowledge, Sipe (Wilkins, 1988)planning system currently allows change representation languageacross different levels abstraction. However, general abstraction methodologyallows ecient algorithms abstraction refinement yet developed.want propose method abstraction allows complete change representation language problem solution concrete abstract vice versa,concrete abstract language given. Additionally, propose use experience54fiBuilding Refining Abstract Planning Casespreviously solved problems, usually available set cases, come abstractsolutions. use experience already proven useful various approaches speedup learning explanation-based learning (Mitchell, Keller, & Kedar-Cabelli, 1986;DeJong & Mooney, 1986; Rosenbloom & Laird, 1986; Minton, 1988; Minton, Carbonell,Knoblock, Kuokka, Etzioni, & Gil, 1989; Shavlik & O'Rorke, 1993; Etzioni, 1993; Minton& Zweben, 1993; Langley & Allen, 1993; Kambhampati & Kedar, 1994), analogicalcase-based reasoning (Carbonell, 1986; Kambhampati & Hendler, 1992; Veloso & Carbonell,1993; Veloso, 1994).main contribution paper, present abstraction methodologyrelated learning method beneficial abstract planning cases automatically derivedgiven concrete cases. Based given concrete abstract language, learningapproach allows complete change representation case concreteabstract level. However, achieve unconstrained kind abstraction,set admissible abstractions must implicitly predefined generic abstraction theory.Compared approaches abstraction hierarchies generated automatically,effort required specify abstract language, feel pricepay make planning tractable certain situations.approach fully implemented Paris (Plan Abstraction RefinementIntegrated System), system abstract cases learned organized casebase. novel problem solving, case-base searched suitable abstract caserefined concrete solution current problem.presentation approach organized follows. next section presentsanalysis hierarchical problem solving shortcomings current approachesillustrated simple examples. Section three argues powerful case abstractionrefinement method overcome identified problems. Furthermore, presentParis approach informally, using simple example. next three sections paperformalize general abstraction approach. introducing basic terminology, Section 5 defines new formal model case abstraction. Section 6 contains detaileddescription correct complete learning algorithm case abstraction. Section 7explains refinement cases solving new problems. Section 8 gives detailed description domain process planning mechanical engineering productionrotary-symmetric workpieces lathe demonstrates proposed approach examples domain. Section 9 reports detailed experimental evaluation Parisdescribed domain. Finally, discuss presented approach relation similarwork field. appendix article contains formal proofs propertiesabstraction approach related learning algorithm. Additionally, detailedrepresentation mechanical engineering domain used experimental evaluationgiven Online Appendix 1.2. Analysis Hierarchical Problem Solvingbasic intuition behind abstraction follows. first ignoring less relevant featuresproblem description, abstraction allows problems solved coarse fashionless effort. Then, derived abstract (skeletal) solution serves problem decompositionoriginal, detailed problem. Korf (1987) shown hierarchical problem55fiBergmann & Wilkesolving reduce required search space significantly. Assume problem requiressolution length n furthermore assume average branching factor b,i.e., average number states reached given state applyingsingle operator. worst-case time complexity finding required solution searchO(bn ). Now, suppose problem decomposed abstract solutionk subproblems, require solution length n1; : : : ; nk , respectively,n1 + n2 + + nk = n. situation, worst-case time complexity findingcomplete solution O(bn1 + bn2 + + bnk ) O(bmax(n1;n2 ;:::;nk ) ). Please notesignificant reduction search time complexity. particular, easily seereduction maximal subproblems similar size, i.e., n1 n2 nk .However, achieve significant search reduction, computed abstract solution mustsolution abstracted problem, must additionally fulfill certainrequirement presupposed analysis. subproblems introduced abstractsolution must independent, i.e., must solvable without interactionsubproblems. avoids backtracking solution subproblemconsequently cuts necessary overall search space. Even restrictioncompletely fulfilled, i.e., backtracking still required cases, several empirical studies(especially Knoblock, 1991, 1993, 1994) shown abstraction nevertheless leadperformance improvements.Unfortunately, also domains representations domains (Holte et al., 1994,1995) way abstraction used hierarchical problem solving cannot improveproblem solving derived abstract solutions don't fulfill mentionedrequirement all. following, show two examples domainsdemonstrate two general drawbacks hierarchical problem solving. Please noteexamples, particular representation assumed. feel representationssomehow \natural" likely used knowledge engineer developing domain. However, might representations domains traditionalhierarchical planning works. assume representations dicult find,especially domain representation also fulfill additional knowledge-engineeringrequirements.2.1 Abstraction Dropping Sentenceshierarchical problem solving, abstraction mostly1 achieved dropping sentencesproblem description preconditions and/or effects operators (Sacerdoti, 1974,1977; Tenenberg, 1988; Unruh & Rosenbloom, 1989; Yang & Tenenberg, 1990; Knoblock,1989, 1994). assumption justifies kind abstraction less relevantdetails problem description expressed isolated sentences representationaddressed relevant sentences established. Ignoringsentences assumed lead abstract solution useful reduce searchconcrete planning levels.However, assumption hold domains. example, many real worlddomains, certain events need counted, e.g., transporting certain number1. Tenenberg's (1988) abstraction analogical mappings planning system Sipe (Wilkins,1988) contains first approaches allow change representation language.56fiBuilding Refining Abstract Planning Casescontainers one location another. Imagine domain which, addition severaloperators, increment operator described follows:Operator: incPrecondition: value(X )Delete: value(X )Add: value(X + 1)representation, integer value increased represented single sentence. state consists single sentence, also operator containsone single sentence.2 think representation \natural" likelychosen knowledge engineer. domain, incrementing value(0) value(8)requires sequential plan composed 8 inc-operators, leading state sequence:value(0),value(1),: : : ,value(8). example, however, abstraction dropping sentences work because, single sentence would dropped, nothing would remain operator description whole counting problem would droppedcompletely. empty problem abstract level, empty plangoing solve it. Unfortunately, empty plan cannot cause complexity reductionsolving problem concrete level. Consequently, abstraction dropping sentencescompletely fails improve problem solving situation.However, adequately cope counting problem abstractingquantitative value expressed sentence towards qualitative representation (e.g.,low=f0; 1; 2; 3g, medium = f4; 5; 6; 7g, high = f8; 9; 10; 11g). qualitative representation would result abstract plan composed two operators (subproblems)increase value low medium high. abstract plan defines twoindependently refinable subproblems. solve first subproblem concrete level,problem solver search sequence inc-operators increment value0 medium value (any value set f4; 5; 6; 7g). subproblemsolved sequence 4 inc-operators leading concrete state value 4. Similarly, second subproblem concrete level find sequence operatorschange value 4 final value 8. Also second subproblem solvedsequence 4 inc-operators. see complete problem requiressequence 8 concrete operators divided 2 subproblems subproblemsolved 4-step plan. exponential nature search space, two4-step problems together solved much less search 8-step problemwhole. Following Korf's analysis sketched before, time complexity reduced O(b8)O(b4)3 . Please note particular abstraction leads two subproblemscentral achieving complexity reduction. important point problemdecomposed one subproblem. kind abstraction achievedintroducing new abstract representation language consists qualitative valuescorresponding abstract increment operator.2. However, might assume term X + 1 modeled separate predicate precondition.Unfortunately, change described situation all.3. assume many operators besides inc-operator, b 1 holds.57fiBergmann & Wilkeeven generalize specific example presented above. problemdropping condition approach possible abstract information (e.g.,value example) coded single sentence representation.particularly problem required solution contains long sequence statesdiffer single sentence. Dropping particular sentence leads droppingwhole problem, dropping sentence lead abstraction.really required abstract information encoded single sentence obviouslyrequires dropping complete information.summarize, seen abstraction dropping sentences workparticular kind problems shown. general, abstraction requires changing complete representation language concrete abstract usually involvesintroduction completely new abstract terms (sentences operators). Withingeneral view, dropping sentences special case abstraction. reason dropping sentences widely used hierarchical planning due simplicity,refinement easy abstract states directly used goalsdetailed levels. Another important property abstraction dropping sentencesuseful hierarchies abstraction spaces constructed automatically domaindescriptions (Knoblock, 1990, 1993, 1994; Bacchus & Yang, 1994).2.2 Generating Abstract Solutions ScratchAnother limiting factor classical hierarchical problem solving way abstract solutions computed. pointed Korf, good abstract solution must lead mostlyindependent subproblems equal size. classical problem solving, abstract solutionfound breadth-first depth-first search using linear (e.g., Alpine, Knoblock, 1993)non-linear (e.g., Abtweak, Yang & Tenenberg, 1990) problem solvers. problem solvers, upward-solution property (Tenenberg, 1988) usually holds, meansabstract solution exists concrete-level solution exists. Usually, problemsolvers find arbitrary abstract solution (e.g., shortest possible solution). Unfortunately, way guarantee computed solutions refinable leadmostly independent subproblems suciently equal size, even solution exists.general, even heuristics try guide problem solving towardsaspired kind useful abstractions. problem illustrated following example,additionally shows limitation abstraction dropping sentences.Imagine large (or even infinite) state space includes least 8 distinct statesshown left Figure 1. 8 states described presence absencethree sentences E 1, E 2, E 3 state description. 3-bit-vector shown Figure1, "0" indicates absence sentence "1" represents presence sentence.8 different states described three sentences arranged 3-dimensionalcube, using one dimension sentence. arrows diagram show possible statetransitions available operators domain.4 operator manipulates (addsdeletes) exactly one sentence state description, certain conditionssentences fulfilled. representation two operators shown right4. dashed lines represent operators introduced make shape cubeeasy see.58fiBuilding Refining Abstract Planning CasesZ011111Two example operators:010110X Z001E2X000101E3E1100O100->101 :Precondition:E1(not E2)(not E3)O101->100 :Precondition:E1(not E2)E3Add: E3Delete: E3Figure 1: State space example domain representation two operatorsside figure. subscript operator name relates respective transitionstate diagram. general, seeE 1 manipulated, E 2 E 3 holds,E 2 manipulated, E 1 E 3 holds,E 3 manipulated, E 1 _ E 2 holds.Furthermore, assume many operators connect statesdomain, shown diagram, 8 depicted states. Consequently,must assume branching factor b 1 state, makes search spaceproblem solving quite large. Besides description domain, Figure 1 also showsthree example problems: X ! X 0, ! 0 Z ! Z 0 . example, solutionproblem X ! X 0 5-step path 000 ! 010 ! 110 ! 111 ! 101 ! 001.Now, let's consider abstract solutions correspond concrete solutionsthree problems. problem, want examine three possible waysabstraction dropping one sentences. purpose, geometric arrangementstates turns useful abstraction simply viewedprojecting 3-dimensional state space onto plane defined sentencesdropped abstraction. left part Figure 2 shows three possible abstractstate spaces result dropping one sentences. importantsee abstract state space, every sentence modified unconditionallyindependent sentences. However, one sentence modifiedoperator. Thereby, constraints exist concrete level relaxed.abstraction concrete solution three problems (X ! X 0, ! 0Z ! Z 0) respect three possible ways dropping conditions shown59fiBergmann & WilkeState spacesdropping conditionsX->XY->YE24E212123E122E1E3Z->Z311E3431E14E2 2132E231321 E323E131E323Figure 2: Abstract state spaces dropping conditionsright side Figure 2. nine possible abstract solutions consists threefour abstract operators. sequence applied indicatednumbers mark operators. also see whatever sentencedrop problems, appropriate abstract solution exists decomposesoriginal problem independent refinable subproblems suciently equal size.main point example none abstract solutions foundhierarchical problem solver! reason abstracted problemsalso exists 0-step 1-step solution addition nine 3-step 4-step solutionsindicated depicted paths. However, short solution completely uselessreducing search next concrete level original problemdecomposed all. central problem problem solvers findshorter useless solutions first, try refine them. Consequently, searchspace concrete level reduced performance improvement achievedall. However, might representations example domainhierarchical problem solver comes useful abstract solution. think, however,representation shown quite natural represents 8 different statesminimal number binary sentences.summarize, presented example useful abstract solution foundhierarchical planning although exists. reason planners usually tryfind shortest solutions, good strategy ground level, mayappropriate abstract level. Neither desirable search longestsolutions might cause unnecessarily long concrete plans.3. Case Abstraction Refinementway problem, propose use experience given form concreteplanning cases abstract experience reuse new situations. Therefore,need powerful abstraction methodology allows introduction completelynew abstract terminology abstract level. makes possible useful abstractsolutions expressed domains abstraction dropping conditionssucient. particular, methodology must serve means analyzedifferent abstraction approaches, must allow ecient algorithms abstractingrefining problems solutions.60fiBuilding Refining Abstract Planning Cases3.1 Basic Ideaintroduce approach achieves case abstraction refinement changingrepresentation language. prerequisite, approach requires abstractlanguage (state description operators) given domain expert additionconcrete level description. also require set admissible ways abstractingstates implicitly predefined generic abstraction theory. course additionalknowledge engineering requirement, feel price payenhance power hierarchical problem solving. Recent research knowledge acquisitionalready describes approaches tools acquisition concrete level abstract leveloperators real-world domains (Schmidt & Zickwolff, 1992; Schmidt, 1994). abstractlanguage given user additional advantage abstracted casesexpressed language user familiar. Consequently, understandabilityexplainability, always important issues applying system, achievedeasily.source learning, assume set concrete planning cases,consists problem statement together related solution. case Prodigy(Minton et al., 1989), consider sequential plans, i.e., plans totally orderedoperators. planning cases assume include problem solving trace example problem solving cases Prodigy/Analogy (Veloso, 1992; Veloso & Carbonell,1993; Veloso, 1994). real-world applications, domain expert's solutions previousproblems usually recorded company's filing cabinet database. casesseen collection company's experience, want draw power.learning phase, set abstract planning cases generated availableconcrete case. abstract planning case consists abstracted problem descriptiontogether abstracted solution. case abstraction procedure guaranteesabstract solution contained abstract case always refined become solutionconcrete problem contained concrete case became abstracted. Differentabstract cases may situated different levels abstraction may abstractionsaccording different abstraction aspects. Different abstract cases different utilityreduce search space concrete level different ways. also happenseveral concrete cases share abstraction. set abstract planning caseslearned organized case-base ecient retrieval problem solving.problem solving phase, case base searched abstract casefound applied current problem hand. abstract case applicablecurrent problem abstracted problem contained abstract planning caseabstraction current problem. However, cannot guarantee abstractsolution contained selected abstract case really refined become solutioncurrent problem. least known abstract solution case basealready useful solving one previous problems, i.e., problems containedconcrete cases abstract case learned. Since new problemsimilar previous problems abstracted way,least high chance abstract solution also useful solving new problem.new problem solved refinement new concrete case arisesused learning.61fiBergmann & WilkeLearningPARIS-SystemEvaluation/IndexingCase BaseGeneralizationAbstractionProblem SolvingRetrievalDomain DescriptionConcrete Domain,Abstract Domain,Generic Abstraction TheoryNew ProblemSpecializationRefinementSolved ProblemTraining CasesFigure 3: components Paris System3.2 PARIS ArchitectureParis (Plan Abstraction Refinement Integrated System) follows basic ap-proach described. Figure 3 shows overview whole system components.Besides case abstraction refinement, Paris also includes explanation-based approachgeneralizing cases learning specializing problem solving. Furthermore, system also includes additional mechanisms evaluating different abstractcases generalizations derived explanation-based component. evaluationcomponent measures reduction search time caused abstract plan solving concrete problems case base abstract plan applicable.Based evaluation, several different indexing retrieval mechanisms developed. retrieval procedures abstract cases preferred causedreduction search previous problem solving episodes. particular, abstract cases turn useless many concrete problems may even becomecompletely removed case-base. spectrum developed retrieval approachesranges simple sequential search, via hierarchical clustering sophisticated approach balancing hierarchy abstract cases according statistical distributioncases within problem space evaluated utility. details generalization procedure found (Bergmann, 1992a), evaluation retrievalmechanisms reported (Bergmann & Wilke, 1994; Wilke, 1994). whole multistrategy system including various interactions described componentstopic forthcoming article, first ideas already found (Bergmann, 1992b,1993). However, target paper concentrate core Paris, namelyapproach abstraction refinement.62fiBuilding Refining Abstract Planning CasesState AbstractionsAbstract PlanA3011111A2010110001A1100A1A2A3A4000011010110111001101100ChangingRepresentration101A4000Figure 4: example case abstraction3.3 Informal Description Abstraction Approachfirst give informal description abstraction approach Paris, basedsmall example shown Figure 1 enhance understanding subsequent formalsections. Suppose solution problem X ! X 0 available concrete problem solving experience. task learn abstract case beneficiallyused solve future problems ! 0 Z ! Z 0 . learning task mustachieved within abstraction approach stronger dropping sentences.look Figure 4, becomes obvious changing representation single abstractcase learned useful three concrete problems. abstract plan shownindicates concrete states abstracted towards single abstract state,single abstract plan exists useful three problems.3.3.1 Abstract Language Generic Abstraction Theoryachieve kind abstraction, approach requires abstract language (statesoperators), well generic abstraction theory provided user. example Figure 4, abstract language must contain new abstract sentences A1 ; : : : ; A4three abstract operators allow respective state transitions. abstractoperators, called Oai (i 2 f1; : : : ; 3g), defined follows:Operator: OaiPrecondition: AiDelete: AiAdd: Ai+1new abstract sentence, user must provide set generic abstraction rulesdescribe sentence defined terms available sentences con63fiBergmann & Wilkecrete language. generic abstraction theory defined rules specifies setadmissible state abstractions. example, generic abstraction theory must contain following two rules define new abstract sentence A1 : :E 1 ^ E 2 ! A1:E 1 ^ :E 2 ^ :E 3 ! A1. general, definition generic abstraction theoryrequire state abstractions noted explicitly. Abstract states derivedimplicitly application combination several rules generic abstractiontheory.Besides kind abstraction described above, user may also want specifydifferent type abstraction she/he also considers useful. example,assume abstraction dropping sentence E 1 also realized. case,abstract language must contain copy two sentences dropped, i.e.,sentences E 2 E 3. Therefore, user5 may define two abstract sentences A5A6 following rules generic abstraction theory: E 2 ! A5 E 3 ! A6.course, respective abstract operators must also specified.Since domain expert knowledge engineer must provide abstract languagegeneric abstraction theory, she/he must already one particular kindsabstraction mind. She/he must know kind details omitted solvingproblem abstract fashion. approach, knowledge-engineer givenpower express kind abstraction she/he considers useful.3.3.2 Model Case AbstractionBased given abstract language generic abstraction theory, abstractionplanning case formally described two abstraction mappings: state abstractionmapping sequence abstraction mapping. two mappings describe two dimensionsreducing level detail case. state abstraction mapping reduces leveldetail state description changing representation language. caseabstraction indicated Figure 4, state abstraction mapping must map concretestates 000, 011 010 onto abstract state described new sentence A1,simultaneously must map concrete states occurring plan onto respectiveabstract states described new sentences A2 , A3 , A4 . sequence abstractionmapping reduces level detail number states consideredabstract level relating concrete states concrete case abstractstates abstract case. concrete states skipped, abstractstate must result particular concrete state. example, Figure 4, abstractionplan 000 ! 010 ! 110 ! 111 ! 101 ! 001 requires sequence abstraction mappingrelates first abstract state described A1 first concrete state 000,second abstract state described A2 third concrete state 110, forth.example, second fifth concrete states skipped.3.3.3 Learning Abstract Planning Casesprocedure learning abstract planning cases given concrete planning casedecomposed four separate phases. simple example, phases shown5. Please note abstraction dropping sentences, also consider ALPINE-like algorithmgenerates required abstract language generic abstraction theory automatically.64fiBuilding Refining Abstract Planning CasesA5A6A5Ca 2Phase-IVCa 1 A1Oa 1Phase-IIIA2Oa 2Oa 3A3A4Oa 3Oa 2Oa 1A6Oa 1Oa 3Phase-IIA11 A52 A53 A5 A64 A64 A6Phase-I000010110111101001Figure 5: four phases case abstraction solution problem X ! X 0Figure 5. phase-I, states result execution plan containedconcrete case determined. Therefore, operator contained plan (startingfirst operator) applied successor state computed. process startsinitial state contained case leads final state, goal statecontained case. phase-II, derive admissible abstractions concretestate computed first phase. purpose, generic abstraction theory useddetermine abstract sentences derived respective concrete stateapplying rules generic abstraction theory. Figure 5 shows abstract sentencesderived generic abstraction theory sketched above. example,see second concrete state abstract description derived containstwo abstract sentences: abstract sentence A1 required achieve type abstractionshown Figure 4 additionally abstract sentences A5 required abstractiondropping sentences. Please note process, representation language stateschanged concrete abstract. next two phases deal abstract operators.already stated, abstract operators given abstract language provideduser. However, assume operator abstraction rules associate abstractoperator single concrete operator sequence concrete operators. reasonoperator abstraction rules extremely hard acquire even harderkeep complete. next two phases case abstraction, search transitionsabstract states based available abstract operators. phase-III, acyclic directedgraph constructed. edge leads abstract state successor abstract statej (not necessarily next abstract state), abstract operator applicable stateapplication leads state j . definition abstract operatorsused process. available abstract operators determine transitionsincluded graph. Figure 5 shows resulting graph, provided abstractoperators sketched Section 3.3.1 contained abstract language. graph65fiBergmann & Wilketransitions shown plain line style result operators Oai , transitionsshown dashed line style result operators required abstraction droppingconditions.phase-IV graph searched consistent paths initial abstract statefinal abstract state. paths must consistent sense resultingpath (i.e., abstract plan) every abstract operator correctly applicable stateresults previous operator. Moreover, state abstraction requiredabstract plan must change within plan. Figure 5 two paths kindshown. lower path represents abstract planning case Ca1 (abstract initial finalstate together operator sequence) results kind abstraction shownFigure 4. upper path represents abstract planning case Ca2 resultsabstraction dropping sentence E 1. abstract plan shown Figure2 problem X ! X 0. Together two plans, abstract state descriptionsresult operator application shown. Please note state descriptionsalways subset description derived generic abstraction theory.example, description fourth abstract state derived phase-II, containssentences A3 ; A5; A6. abstract state occurs abstract cases computedphase-IV. case Ca2 , respective state described sentences A5A6 sentences result application operatorsstarting abstract initial state. case Ca1, abstract state describedsentence A3 sentence results application operator Oa2.example see abstract operators two functions. firstfunction select concrete states become abstracted. example,abstract case Ca1, second concrete state skipped, even first secondconcrete states abstracted different abstract descriptions phase-II. reasonabstract operator a) leads first abstracted statesecond abstracted state b) also consistent operatorsrest path. second function abstract operators selectabstract sentences considered abstract planning case. example,abstract case Ca1 , sentences A1 ; : : : ; A4 considered sentences A5 A6left out. reason abstract operators Oa1 ; Oa2; Oa3 occurplan don't use A5 A6 precondition don't manipulate sentences.phase-IV finished, set abstract planning cases available. planningcases stored case-base used problem solving.3.3.4 Selecting Refining Abstract Casesproblem solving, abstract case must selected case-base, abstractplan contained case must refined become solution current problem.case retrieval must search abstract case applicable, i.e., containsproblem description abstraction current problem. example, assumeproblem ! 0 solved case X ! X 0 presented learning.situation case-base contains two abstract cases Ca1 Ca2 shown phaseIV Figure 5. abstract case Ca1 used solving new problem,initial state 000 new problem abstracted A1 applying generic66fiBuilding Refining Abstract Planning CasesSelected abstract case:A1Defined search spaces:000Refined solution:000Oa 1010A2Oa 2A3??110111Oa 3A4100101100Figure 6: Refinement abstract case solution problem ! 0abstraction theory. Similarly, final state 100 abstracted A4 . However,abstract case Ca2 applicable final abstract state cannot abstractedA6. Consequently, lower abstract case must used. plan refinementrefine abstract operators sequentially left right shown Figure 6. Therebyabstract operator defines abstract goal state, i.e., state resultsexecution operator. example, abstract operator Oa1 defines abstract goalA2. refine abstract operator, search concrete operator sequence, startingcurrent concrete state (i.e., initial state first operator), concretestate reached abstracted desired goal state. state foundused starting state refinement next abstract operator.solution problem ! 0 , refinement abstract operator Oa1achieved sequence two concrete operators leading concrete state 110.concrete state used starting state refine next abstract operator Oa2.refinement procedure finishes last abstract operator refined wayfinal concrete state achieved. Please note type refinement operatorsused directly, instead sequence states resultsexecution used. Alternatively, could also stored abstract case sequenceabstracted states. experience, storing sequence operators requires lessspace storing sequence states. become obvious lookingdomain introduced Section 8. Besides abstract operators playimportant role learning phase.3.4 Relations Skeletal Planssimilar experience-based case-based variant finding abstract solutionfound early paper Friedland Iwasaki (1985) concept skeletalplans introduced. skeletal plan "[...] sequence generalized steps, which,instantiated specific operations specific problem context solve given problem[p.161]. [...] Skeletal plans exist many levels generality. general level,basic plans, used `fall-backs', specific, easierrefine plans cannot found. [p. 164]." Skeletal plans solutions planning problemsdifferent levels detail consequently abstract plans. problem solving67fiBergmann & Wilkerecalled library refined towards concrete solution. approachseen early idea integrating abstraction case-based reasoning. However,several differences skeletal plan approach Paris approach.skeletal plan approach model operators (neither concrete abstract) useddescribe preconditions effects operators done Paris. explicitnotion states abstraction refinement states. Instead, plan refinementachieved stepping hierarchy operators, guided heuristic rules operatorselection. particular, approach supports automatic acquisition skeletalplans provided. Unfortunately, skeletal plan approach yet investigatedmuch detail current work field speedup-learning. neither formalmodel skeletal planning empirical evaluations.rest paper introduce investigate Paris approachformally.4. Basic Terminologysection want introduce basic formal terminology used throughout restpaper. Therefore define formal representation problem solving domains.want assume problem solving general viewed transforming initialstate final state using sequence operators (Newell & Simon, 1972). FollowingStrips-oriented representation (Fikes & Nilsson, 1971), domain problem solving= hL; E ; O; Ri described first-order language6 L, set essential atomic sentencesE L (Lifschitz, 1987), set operators related descriptions, additionally,set rules (Horn clauses) R L. essential sentences (which must atomic)sentences used describe state. state 2 describes dynamicpart situation domain consists finite subset ground instances essentialsentences E . symbol , denote set possible states descriptionsdomain, defined = 2E , E = fe je 2 E substitutione groundg. addition, Horn clauses R allow representation static propertiestrue situations. Horn clauses must contain essential sentencehead clause.operator o(x1; : : : ; xn) 2 described triple hPreo ; Addo; Deloi,precondition Preo conjunction atoms L, add-list Addo deletelist Delo finite sets (possibly instantiated) essential sentences E . Furthermore,variables occuring operator descriptions must follow following restrictions:fx1; : : : ; xng V ar(Preo) V ar(Delo) fx1; : : : ; xng V ar(Addo).7instantiated operator expression form o(t1; : : : ; tn ), ti groundterms L. term ti describes instantiation variable xi operator description. notational convenience define instantiated precondition well instantiated add-list delete-list instantiated operator follows: Preo(t1 ;:::;tn ) := Preo ,Addo(t1;:::;tn) := fa ja 2 Addog, Delo(t1;:::;tn) := fd jd 2 Delo g, hPreo ; Addo; Deloi6. basic language first order, deductive rules given Horn logic subsetfull first-order language used.7. restrictions however relaxed fx1 ; : : : ; xn g V ar(Preo ) required.introduced restriction simplifies subsequent presentation.68fiBuilding Refining Abstract Planning Casesdescription (uninstantiated) operator o(x1; : : : ; xn), = fx1 =t1 ; : : : ; xn =tn gcorresponding instantiation.instantiated operator applicable state s, [ R ` Preholds.8instantiated operator transforms state s1 state s2 (we write: s1 ,! s2 )applicable s1 s2 = (s1 n Delo ) [ Addo . problem description p = hsI ; sGconsists initial state sI together final state sG . problem solving taskfind sequence instantiated operators (a plan) = (o1; : : : ; ol ) transformsolo1initial state final state (sI ,!,!sG ). case C = hp; oi problemdescription p together plan solves p.introduced Strips-oriented formalism defining problem solving domainsimilar form expressiveness representations typically used general problemsolving planning. state described finite set ground atomsfunctions also used. Full Horn logic available describe static rules. restriction Horn clauses advantage powerful allowing ecient proofconstruction using well known SLD-refutation procedures (Lloyd, 1984). ComparedProdigy Description Language (PDL) (Minton, 1988; Blythe et al., 1992) language provide explicit quantification specific syntactic construct, similarexpressiveness reached implicit quantification Horn clauses. Moreover,language provide kind type specification constants variablesPDL think major disadvantage. Besides points languagequite similar PDL.5. Formal Model Case Abstractionsection present new formal model case abstraction provides theorychanging representation language case concrete abstract. alreadystated assume addition concrete language abstract language supplieddomain expert. Following introduced formalism, assume concrete levelproblem solving defined concrete problem solving domain Dc = hLc ; Ec; Oc ; Rciabstract level (case-based) problem solving represented abstract problem solving domain Da = hLa ; Ea; Oa; Rai. reasons simplicity, assumedomains share symbols9 . condition always achieved renaming symbols. remainder paper states operators concretedomain denoted sc oc respectively, states operators abstractdomain denoted sa oa respectively. problem case abstractiondescribed transforming case concrete domain Dc case abstractdomain Da (see Figure 7). transformation formally decomposed twoindependent mappings: state abstraction mapping ff, sequence abstraction mappingfi (Bergmann, 1992c). state abstraction mapping transforms selection concretestate descriptions occur solution problem abstract state descriptions,8. following, simply omit parameters operators instantiated operators caseunambiguous relevant.9. Otherwise, symbol (or sentence) could become ambiguous would problem applyinggeneric abstraction theory. would unclear whether generic abstraction rule refers concreteabstract sentence69fiBergmann & Wilkeabstractdomain:DaO1s01aconcretedomain:Dcc0O2OjjaOc1(0) = 0c1Oc2cs2Oc3cs3(1) = 3j+1OmOci+1OcnOc4Ocici(j) =cn(m) = nFigure 7: General idea abstractionsequence abstraction mapping specifies concrete states mappedskipped.5.1 State Abstractionstate abstraction mapping translates states concrete world abstract world.Definition 1 (State Abstraction Mapping) state abstraction mapping ff : Sc ! Samapping Sc , set states concrete domain, Sa, set statesabstract domain. particular, ff must effective total function.general definition state abstraction mapping impose restrictionskind abstraction besides fact mapping must total many-toone function. However, restrict set possible state abstractions setabstractions user considers useful, assume additional domain knowledgeabstract state relates concrete state provided. knowledgemust expressed terms domain specific generic abstraction theory (Giordana,Roverso, & Saitta, 1991).Definition 2 (Generic Abstraction Theory) generic abstraction theory set Hornclauses form ea a1 ; : : : ; ak . rules ea abstract essential sentence,i.e., ea = Ea Ea 2 Ea substitution . body generic abstraction ruleconsists set sentences concrete abstract language, i.e., ai atomsLc [ La .Based generic abstraction theory, restrict set possible state abstractionmappings deductively justified generic abstraction theory.Definition 3 (Deductively Justified State Abstraction Mapping) state abstraction mapping ff deductively justified generic abstraction theory A, following conditionshold sc 2 Sc :2 ff(sc ) sc [ Rc [ `2 ff(sc ) s~c s~c [ Rc [ ` holds, 2 ff(~sc ) also fulfilled.70fiBuilding Refining Abstract Planning Casesdefinition first condition assures every abstract sentence reachedmapping justified abstraction theory. Additionally, second requirementguarantees abstract sentence used describe abstraction one state,must also used describe abstraction states, abstract sentencederived generic abstraction theory. Please note deductively justified stateabstraction mapping completely induced set ff Ea respect genericabstraction theory follows: ff(sc ) := f 2 ff jsc [ Rc [ ` g. Unless otherwise statedalways assume deductively justified state abstraction mappings. summarize,state abstraction mapping transforms concrete state description abstract statedescription thereby changes representation state concrete abstract.Please note deductively justified state abstraction mappings need defineduser. determined automatically learning algorithmpresented Section 6.5.2 Sequence Abstractionsolution problem consists sequence operators corresponding sequencestates. relate abstract solution concrete solution, relationshipabstract states (or operators) concrete states (or operators) must captured.abstract state must corresponding concrete state every concrete statemust associated abstract state. due fact abstraction alwaysreduction level detail (Michalski & Kodratoff, 1990), situation, reductionnumber states. selection concrete states correspondingabstraction, sequence abstraction mapping defined follows:Definition 4 (Sequence Abstraction Mapping) sequence abstraction mapping fi : N ! Nrelates abstract state sequence (sa0 ; : : : ; sam ) concrete state sequence (sc0; : : : ; scn )mapping indices j 2 f1; : : : ; mg abstract states saj indices 2 f1; : : : ; ngconcrete states sci , following properties hold:fi(0) = 0 fi(m) = n: initial state goal state abstract sequencemust correspond initial goal state respective concrete state sequence.fi(u) < fi(v) u < v: order states defined concretestate sequence must maintained abstract state sequence.Note defined sequence abstraction mapping formally maps indices abstractdomain concrete domain. abstraction mapping better map indicesconcrete domain indices abstract domain, inverse mappingfi ,1 does. However, mapping inconvenient handle formally sincerange definition fi ,1 must always considered. Therefore stick presenteddefinition.5.3 Case AbstractionBased two abstraction functions introduced, intuition case abstractioncaptured following definition.71fiBergmann & WilkeHierarchies abstraction spacesDlDifferent kinds abstractionsD2DaDa1DcDaD1Da2D0D0DcFigure 8: Different kinds abstractions (a) abstraction hierarchies (b)Definition 5 (Case Abstraction) case Ca = hhsa0 ; sami; (oa1; : : : ; oam)i abstractioncase Cc = hhsc0; scn i; (oc1; : : : ; ocn)i respect domain descriptions (Dc ; Da)oajoci csci,1 ,!si 2 f1; : : : ; ng saj,1 ,!sj j 2 f1; : : : ; mgexists state abstraction mapping ff sequence abstraction mapping fi , that:saj = ff(scfi(j)) holds j 2 f0; : : : ; mg.definition case abstraction demonstrated Figure 7. concrete space showssequence n operations together resulting state sequence. Selected statesmapped ff states abstract space. mapping fi maps indicesabstract states back corresponding concrete states.5.4 Generality Case Abstraction Methodologyfollowing, brie discuss generality presented case abstraction methodology. see hierarchies abstraction spaces well different kinds abstractions represented simultaneously using presented methodology.5.4.1 Different kinds Abstractionsgeneral, one possible abstraction object world.Abstraction performed many different ways. example two different abstractions case already shown example Figure 5. example,two different abstractions (see abstract cases Ca1 Ca2) derivedconcrete case. abstraction methodology able cope different abstractionscase specified user. Assume given one concrete domain Dctwo different abstract domains Da1 Da2 , represents two different kindsabstraction. Furthermore, assume abstract domains sharesymbols10 . always define single abstract domain Da joining individualabstract domains includes kinds abstractions (see Figure 8 (a)).property formally captured following simple lemma.10. abstract domains disjoint, symbols simply renamed achieve property.72fiBuilding Refining Abstract Planning CasesLemma 6 (Joining different abstractions) concrete domain Dc two disjoint abstract domains Da1 Da2 given, joint abstract domain Da = Da1 [ Da2defined follows: Let Da1 = (La1; Ea1; Oa1; Ra1) let Da2 = (La2; Ea2; Oa2; Ra2).Da = Da1 [ Da2 = (La1 [ La2 ; Ea1 [ Ea2 ; Oa1 [ Oa2 ; Ra1 [ Ra2). joint abstract domainDa fulfills following property: Ca abstraction Cc respect (Dc, Da1)respect (Dc , Da2), Ca also abstraction Cc respect (Dc ; Da).5.4.2 Hierarchy Abstraction Spaceswork hierarchical problem solving assume multi-level hierarchy abstractionspaces problem solving (e.g., Sacerdoti, 1974; Knoblock, 1989). Even presentedapproach contains two domain descriptions, hierarchy abstract domains simplymapped onto presented two-level model shown Figure 8 (b). Assumehierarchy disjoint domain descriptions (D0; : : : ; Dl) given. particular, domainD+1 assumed abstract domain . multi-level hierarchyabstraction spaces, case C abstraction level abstraction case C0,exists sequence cases (C1 ; : : : ; C ,1 ) Ci domain Di Ci+1abstraction Ci respect (Di ; Di+1) 2 f0; : : : ; , 1g. multilevel hierarchy domain descriptions always reduced two-level description.abstract domain two-level description contains union levelsmulti-level hierarchy. property formally captured following lemma.Lemma 7 (Multi-Level Hierarchy) Let (D0; : : : ; Dl) arbitrary multi-levelhierarchyldomain descriptions. two-level description (Dc , Da ) Da = =1Dc = D0 holds that: Ca abstraction Cc respect (D0; : : : ; Dl) Caalso abstraction Cc respect (Dc , Da ).Since shown different kinds abstractions well hierarchies abstraction spaces directly represented within two-level case abstraction methodology,restrict exactly two levels.6. Computing Case Abstractionspresent Pabs algorithm (Bergmann, 1992c; Wilke, 1993) automaticallylearning set abstract cases given concrete case. Thereby, assumeconcrete domain Dc abstract domain Da given together generic abstractiontheory A. use functional notation Ca 2 PABS(hDc ; Da; Ai; Cc) denote Caelement set abstract cases returned Pabs algorithm.algorithm consists four separate phases introduced Section 3.following present phases detail.first three phases, require procedure determining whether conjunctiveformula consequence set Horn clauses. purpose, use SLD-refutationprocedure (Lloyd, 1984) given set Horn clauses (a logic program) C togetherconjunctive formula G (a goal clause). refutation procedure determines setanswer substitutionsC ` G holds 2. write= SLD(C; G).SLD-refutation procedure performs kind backward-chaining works73fiBergmann & Wilkefollows. selects literal goal clause G (i.e., left literal) searchesHorn clause logic program C contains literal head unifiesselected goal literal. selected literal removed G body (if empty)applied clause added beginning goal clause. generalunifier goal literal head clause applied whole new goal clause.resulting goal clause called resolvent. process continues goal clausebecomes empty resolvents built. former case, goalproven answer substitution computed composing substitutions usedresolution. Backtracking used look possible selections applicableHorn rules determine alternative answer substitutions. set answer substitutionsreturned set. whole space possible applications available Horn rulessearched unsuccessfully, goal clause consequence logic programC SLD-refutation procedure terminates without answer substitution (= ;).must confused situation empty substitution returned(= f;g), variables occur G. phase-III Pabs algorithm, also requirederivation trees addition answer substitutions. write = SLD(C; G)assume set pairs (; ), answer substitutionderivation C ` G .order assure termination SLD-refutation procedure requireabstract domain generic abstraction theory designed accordingfollowing principles11 :concrete state sc 2 Sc concrete operator oc 2 Oc ocdescribed hPreoc ; Addoc ; Deloc i, SLD(sc [ Rc ; Preoc ) must lead finite setground substitutions variables occur Preoc .state abstract sa 2 Sa abstract operator oa 2 Oa oadescribed hPreoa ; Addoa ; Deloa i, SLD(sa [ Ra; Preoa ) must lead finite setground substitutions variables occur Preoa .state sc 2 Sc abstract essential sentence E 2 Ea, SLD(sc [Rc [A; E )must lead finite set ground substitutions variables occur E .following four phases Pabs algorithm explained detail.6.1 Phase-I: Computing Concrete State Sequenceinput case abstraction algorithm, assume concrete case Cc =hhscI ; scGi; (oc1; : : : ; ocn)i. Note (oc1; : : : ; ocn) totally ordered sequence instantiated operators similar plans Prodigy (Minton, 1988; Minton et al., 1989; Veloso& Carbonell, 1993). first phase, state sequence results simulationproblem solution computed follows:11. first glance, restrictions seem bit hard achieve take closer look seestandard requirement (terminating) logic program (i.e., Prolog program).74fiBuilding Refining Abstract Planning CasesAlgorithm 1 (Phase-I: Computing concrete state sequence)sc0 := scI:= 1 nSLD(sci,1 [ Rc; Preoci ) = ; STOP \Failure: Operator applicable"sci := (sci,1 n Deloci ) [ AddociendscG 6 scn STOP \Failure: Goal state reached"ocalgorithm, states sci computed, sci,1 ,!sci holds2 f1; : : : ; ng. failure occurs given plan valid, i.e., solve givenproblem.6.2 Phase-II: Deriving Abstract Essential SentencesUsing derived concrete state sequence input, following algorithm computessequence abstract state descriptions (sai ) applying generic abstraction theoryseparately concrete state.Algorithm 2 (Phase-II: State abstraction):= 0 nsai := ;E 2 Ea:= SLD(sci [ Rc [ A; E )2sai := sai [ fE gendendendPlease note claimed domain theories designed wayfinite contains ground substitution variables E . Therefore, everydescription sai consists ground atoms consequently valid abstract statedescription. Within introduced model case abstraction computedsuperset outcome possible state abstraction mappings. deductively justifiedstate abstraction mapping ff restricted ff(sci ) sai = fe 2 Sa jsci [ Rc [ ` eg2 f1; : : : ; ng. Consequently, determined abstract sentences abstractcase might require.6.3 Phase-III: Computing Possible Abstract State Transitionsnext phase algorithm, search instantiated abstract operatorstransform abstract state s~ai sai subsequent abstract state s~aj saj (i < j ).Therefore, preconditions instantiated operator must least fulfilledstate s~ai consequently also sai . Furthermore, added effects operator musttrue s~aj consequently also saj .75fiBergmann & WilkeAlgorithm 3 (Phase-III: Abstract state transitions)G := ;:= 0 n , 1j := + 1 no(x1; : : : ; xu) 2 Oalet hPreo ; Delo; Addoi description o(x1; : : : ; xu):= SLD(sai [ Ra ; Preo)h; 2letAdd0o = faja 2 Addog(* Compute possible instantiations *)(* added sentences hold saj *):= f;g(* set possible substitutions *)(* initially empty substitution. *)2 Add0o0 := ;2e 2 sajsubstitution = e 0 := 0 [ fgendend:= 0end(* Now, contains set possible substitutions *)(* added sentences contained saj *)2G := G [ fhi; j; o(x1; : : : ; xu ); igendendendendendset possible operator transitions collected directed edges graphvertices represent abstract states. algorithm, set G edges acyclicdirected graph constructed. pair states (sai,saj ) < j checkedwhether exists operator o(x1; : : : ; xu ) applicable sai . purpose,SLD-refutation procedure computes set possible answer substitutionsprecondition operator fulfilled sai . derivation belongsanswer substitution stored together operator graph sincerequired next phase case abstraction. derivation \and-tree"inner-node ects resolution goal literal head clauseleaf-node represents resolution fact. Note proving preconditionabstract operator inner nodes tree always refer clauses Horn rule setRa, leave-nodes represent facts stated Ra essential sentences contained76fiBuilding Refining Abstract Planning Casessai . answer substitution applied add-list operator leadingpartially instantiated add-list Add0o. Note still variables Add0ooperator may contain variables contained precondition mayoccur add-list. Therefore, set possible substitutions incrementallyconstructed 2 saj holds 2 Add0o. completely instantiated operatorderived thereby finally included directed edge (from j ) graph G.algorithm guaranteed (instantiated) operator leads saisaj applicable sai essential sentences added operator containedsaj . Furthermore, applied SLD-refutation procedure complete (it always findsanswer substitutions), every instantiated operator applicable saiessential sentences added operator contained saj also containedoaigraph. follows immediately ff(scfi (i,1)) ,!ff(scfi(i) ) holds arbitrarydeductively justified state abstraction mapping ff sequence abstraction mapping fi ,hfi (i , 1); fi (i); oai; 2 G also holds.6.4 Phase-IV: Determining Sound PathsBased state abstractions sai derived phase-II graph G computedprevious phase, phase-IV selects set sound paths initial abstract statefinal abstract state. set significant abstract sentences ff sequence abstractionmapping fi also determined construction path.Algorithm 4 (Phase-IV: Searching sound paths)12Paths := fh(); ;; (fi(0) = 0)igexists h(oa1; : : : ; oak); ff; fii 2 Paths fi(k) < nPaths := Paths n h(oa1 ; : : : ; oak ); ff; fiihi; j; oa; 2 G = fi(k)let E set essential sentences contained derivationlet ff0 = E [ Addoa [ ff2 f1; :a: : ; kg holds:(safi ( ,1) \ ff0 ) ,!(sfi ( ) \ ff0 )(sa \ ff0 )(safi (k) \ ff0 ) ,!jPaths := Paths [ fh(oa1 ; : : : ; oak; oa); ff0; fi [ ffi(k + 1) = j gi gendendCasesAbs := ;h(oa1 ; : : : ; oak); ff; fii 2 Paths fi(k) = nCasesAbs := CasesAbs [ fhhsa0 \ ff ; san \ ff i; (oa1 ; : : : ; oak)igendreturn CasesAbsconstruction sequence abstraction mapping obvious, set ff represents image state abstraction mapping ff thereby determines set sentences12. Please note h(oa1 ; : : : ; oak ); ff; fi matches fh(); ;; (fi (0) = 0)ig k = 0. operator n denotesset difference.77fiBergmann & Wilkereached order assure applicability constructed operator sequence. Note ff state abstraction mapping ff directly determinedfollows: ff(sci ) = fe 2 ff jsci [ Rc [ ` eg. idea algorithm startempty path. path extended operator G iteration algorithmpath leads final state index n. New essential sentences ff0 mayoccur proof precondition added effects new operator. pathconstructed far must still consistent according extension state descriptionand, addition, new operator must transform sentences ff correctly.result, phase-IV returns cases abstractions given concrete inputcase respect concrete abstract domain definitions generic abstractiontheory. Depending domain theory, single abstract case learnedsingle concrete case already shown Figure 5.6.5 Correctness Completeness PABS AlgorithmFinally, want state strong connection formal model caseabstraction presented algorithm. algorithm terminates domain descriptions generic abstraction theory formulated required beginningsection, SLD-resolution procedure always terminates. algorithm correct,every abstract case computed Pabs algorithm case abstraction accordingintroduced model. SLD-refutation procedure applied Pabs complete everycase abstraction according Definition 5 returned Pabs. propertycaptured following theorem.Theorem 8 (Correctness completeness PABS algorithm) complete SLDrefutation procedure used Pabs algorithm, Case Ca abstraction case Ccrespect (Dc ; Da) generic theory A, Ca 2 PABS(hDc ; Da; Ai; Cc).6.6 Complexity Algorithmcomplexity algorithm mainly determined phases III IV. worstcase complexity phase-III O(n2 C1 C2) n length concrete planC1 C2 dependent domain theories follows: C1 = jOa j jj C2 =jAddOa j (jEajjj)jAddOaj. Thereby, jOaj represents number abstract operators, jjmaximum number substitutions found SLD-refutation procedure, jAddOa jmaximum number added sentences abstract operator, jEaj numberabstract essential sentences. complexity phase-IV determined O(n 2(n,1)C1). assume constant domain theories overall complexity Pabs algorithmsummarized O(n 2(n,1) ). exponential factor comes possibly exponentialnumber paths directed acyclic graph n nodes every state connectedevery successor state. Whether graph kind appears much dependentabstract domain theory, determines transitions abstract statespossible. exponential nature lead time complexity problem domainsused. Additionally, want make clear computational effort mustspent learning problem solving. time required learninglong, learning phase executed off-line.78fiBuilding Refining Abstract Planning Casesspace complexity algorithm mainly determined phase-IIIderivations proofs abstract operators' preconditions must stored.sum n2 C1 C2 derivations worst case. turn problemdomains used derivation short (in cases3 inferences static Horn rules). reason derivations relateabstract operators likely contain less preconditions concrete operators.7. Refinement Abstract Casesprevious section described abstract cases automatically learnedconcrete cases. assume case-base contains set abstract cases.want show abstract cases used solve problems concrete level.Furthermore, discuss impact specific form abstract problem solvingdomain improvement problem solving achieved.7.1 Applicability Refinability Abstract Casesgiven abstract case concrete problem description, question arisessituations abstract case refined solve concrete problem. kindrefinability a-posterior definition easily given follows.Definition 9 (Refinability abstract case) abstract case Ca refined solveconcrete problem p exists solution oc p, Ca abstractionhp; oci.Obviously, refinability property undecidable general since otherwise planningwould decidable. However, define applicability abstract casedecidable necessary property refinability follows.Definition 10 (Applicability abstract case) abstract case Ca = hhsa0 ; sami,(oa1 ; : : : ; oam)i applied solve concrete problem p = hscI ; scG exists stateabstraction mapping ff sai 2 Im(ff) 2 f0; : : : ; mg ff(scI ) = sa0ff(scG ) = sam . Thereby, Im(ff) denotes image state abstraction mapping ff, i.e.,abstract states reached.applicable abstract case, least guaranteed concrete initial goalstates map abstract ones concrete intermediate states existsabstracted required abstract case.Even applicability necessary precondition refinability formallyguarantee refinability, since downward solution property (Tenenberg, 1988), statesevery abstract solution refined, strong requirement hold generalabstraction methodology. However, indeed guaranteed abstract casecontained case-base already abstraction one previous concrete casesdue correctness Pabs algorithm used learning. one problemscontained concrete cases solved guaranteed learnedabstract case refined solve problem. Consequently, abstract casecase-base least refined solve one problem occurred past.79fiBergmann & WilkeAbstract solutions useless never refined solve concreteproblem never case-base consequently never tried solving problem.Therefore, expect abstract case case-base high chancealso refinable new similar problems applied.7.2 Selecting Applicable Abstract Casedecide whether abstract case applied solve concrete problem P ,determine suitable state abstraction mapping. assume deductivelyjustified state abstraction mappings,required state abstraction mapping ff alwaysinduced set ff = i=0 si shown Section 5.1. Consequently, Ca applicableproblem p = hscI ; scG sa0 = f 2 ff j scI [ Rc [ ` g sam = f 2ff j scG [Rc [A ` g. Since every abstract case use solving new problemlearned another concrete case, known abstract state sai mustleast one concrete state (from previous concrete state) abstracted viaff sai . Consequently, sai 2 Im(ff) holds. Together introduced restrictionsdefinition Rc respect complete SLD-refutation procedure (see Section6), applicability abstract case decidable. Algorithm 5 describes selectionapplicable abstract case problem p = hscI ; scG detail.Algorithm 5 (Selection applicable abstract case)saI := saG := ;E 2 Ea:= SLD(SscI [ Rc [ A; E )sI := sI [ 2EE 2 Ea:= SLD(sScG [ Rc [ A; E )saG := saG [ 2ErepeatrepeatSelect new case Ca = hhsa0 ; sam i; (oa1; : : : ; oam)i case basesa0 saI sam saGcases availablerefineDFID (scI ; (); ;; scG)return result refineDFID:=Sm1 , 1 sai := (sai,1 n Deloai ) [ Addoaiff := i=0 sai(saI \ ff) = sa0 (saG \ ff) = samrefineDFID (scI ; (sa1; : : : ; sam,1 ); ff; scG)refineDFID returns success(p)return success(p)first, initial final concrete states problem abstracted usinggeneric abstraction theory. Thereby, abstract problem description hsaI ; saG determined.Then, pre-selection step, abstract case chosen form case base.abstract sentences contained initial final abstract state case must80fiBuilding Refining Abstract Planning Casescontained abstracted problem description hsaI ; saG i. condition, however,guarantee selected case applicable respect Definition 10. set ffabstract sentences inducing respective state abstraction mapping computedapplicability condition checked test whether selected case applicable.selected case applicable, new case must retrieved. applicable abstractcase determined refinement algorithm refineDFID (see following section)executed. algorithm uses sequence intermediate abstract states (sa1 ; : : : ; sam,1 ),previously determined abstract plan case, guide search concretelevel. operators contained abstract plan used anymore. refinementprocedure returns success(p), refinement succeeds solution plan p.refinement fails (the procedure returns failure), another case selected. casesavailable problem solved pure search without guidance abstractplan.7.3 Refining Abstract Planrefinement selected abstract case starts concrete initial stateproblem statement. search proceeds sequence concrete operations foundleads concrete state sc , sa1 = f 2 ff j sc [ Rc [ ` g holds.applicability condition abstract case guarantees state exists (sai 2 Im(ff))guaranteed required concrete operator sequence exists too. Therefore,search task may fail causes whole refinement process fail also. firstabstract operator refined successfully new concrete state found. statetaken starting state refine next abstract operator manner.refinement fails backtrack refinement previous operator tryfind alternative refinement. whole refinement process reaches final abstractoperator must directly search operator sequence leads concrete goalstate scG . concrete goal state reached concatenation concrete partialsolutions leads complete solution original problem.refinement demands search procedure allows abstract goal specification. kinds forward-directed search depth-first iterative-deepening (Korf,1985b) best-first search (Korf, 1993) procedures used purposestates explicitly constructed search. states tested seeabstracted towards desired goal. Paris use depth-first iterative-deepeningsearch described Algorithm 6. algorithm consists two recursive procedures.top-level procedure refineDFID receives concrete initial state scI , concrete final statescG , sequence intermediate abstract states = (sa1 ; : : : ; sak) derived abstractcase, well set ff induces state abstraction mapping. procedureincrements maximum depth depth-first search procedure searchboundedmaximum DeepMax. procedure searchbounded performs actual search. goalsearch either abstract state, i.e., first abstract state , concretegoal state scG abstract state already visited. procedure performsdepth-first search applying available concrete operators recursively callingsearch procedure concrete state scnew results operator application.81fiBergmann & Wilkeabstract goal state reached removed list refinementcontinues next abstract state first one list.Algorithm 6 (Refinement depth-first iterative-deepening (DFID) search)procedure refineDFID (scI ; a; ff; scG)Deep := 0repeatsearchbounded (scI ; a; ff; scG; Deep)searchbounded returns success(p) return success(p)Deep := Deep + 1 (* Search unsuccessful: Increment search deepness *)Deep = DeepMaxreturn failureprocedure searchbounded (scI ; a; ff; scG; Deep)= () (* abstract goals: Test concrete final goal *)scI = scG return success(())= (sa1; : : : ; sak) (* least one abstract goal *)e 2 sa1 holds: SLD(scI [ Rc [ A; e) =6 ;e 2 ff n sa1 holds: SLD(scI [ Rc [ A; e) = ;(* Abstract state reached: Refine next abstract operator *)refineDFID (scI ; (sa2 ; : : : ; sak ); ff; scG)refineDFID returns success(p) return success(p)Deep = 0 return failure (* Maximum depth reached *)(* Apply operators: Create successor states *)oc 2 Oc= SLD(scI [ Rc; Preoc ) (*set possible operator instantiations *)2scnew := (scI n (Deloc )) [ (Addoc ) (* Create successor state *)searchbounded (scnew ; a; ff; scG ; Deep , 1) (* Continue search new state *)searchbounded returns success(p) return success((oc) p))return failurePlease note kind refinement different standard notion refinement hierarchical problem solving (Knoblock et al., 1991b).strong correspondence abstract operator possible concrete operator.Moreover, justification structure refined abstract plan completely differentjustification structure abstract plan completely independentdefinition abstract concrete operators. Even disadvantage comparedusual refinement procedure used hierarchical problem solving, main computationaladvantage abstraction caused decomposition original problem smallersubproblems maintained.7.4 Alternative Search Procedures RefinementBesides forward-directed search procedure currently used Paris backward-directedsearch used means-end analysis (Fikes & Nilsson, 1971) nonlinear partial-ordered82fiBuilding Refining Abstract Planning Casesplanning (McAllester & Rosenblitt, 1991) also applied refinement certaincircumstances. Therefore, would either require state concretion functionturn rules generic abstraction theory virtual concrete operators.state concretion function must able determine single state finite setconcrete states given abstract state together concrete problem description.Thereby, concrete problem description may help reduce number possible concrete states. derived state concretions used concrete goal statesbackward directed search may start.Alternatively, turn process state concretion directly search procedure representing rule generic abstraction theory virtual abstractoperator. precondition rule generic abstraction theory becomes precondition virtual operator conclusion rule becomes positive effectoperator. using virtual concrete operators together operatorsconcrete domain, backward-directed planner use abstract state directlygoal search. part plan resulting solution consists concrete operators (and virtual operators) taken refinement abstractoperator.7.5 Criteria Developing Abstract Problem Solving Domainabstract problem solving domain generic abstraction theory used important impact improvement problem solving achieved. Therefore,desirable set criteria state \good\ abstract domain definition look. Strong criteria allowing quantitative predictions resulting speedupshardly developed. hierarchical planners criteria don't exist either.However, give set factors determine success approach.overall problem solving time uenced mainly following four factors: independent refinability abstract operators, goal distance abstract operators, concrete scopeapplicability abstract operators, complexity generic abstraction theory.7.5.1 Independent Refinability Abstract OperatorsFollowing Korf's analysis hierarchical problem solving (Korf, 1987) introduced2, plan refinement approach reduces overall search space bnPSectionb(fi (i),fi (i,1)). Thereby, b average branching factor, n length coni=1crete solution, fi sequence abstraction mapping used abstractionconcrete case abstract case. already mentioned, cannot guaranteeabstract plan applicable problem really refined. Furthermore, Korf'sanalysis assumes backtracking refinement individual abstractoperators required cannot guaranteed. computational advantageabstraction lost either two cases.However, abstract operators occurring abstract problem solving domainfulfill strong requirement independent refinability, guaranteed everyapplicable abstract case refined without backtracking. abstract operator oaindependently refinable sc , s~c 2 Sc every state abstraction mapping ff83fiBergmann & Wilkeff(sc ) ,!ff(~sc ) holds,exists sequence concrete operators (oc1; : : : ; ock )ccok co1sc ,!: : : ,!s~ holds.problem requirement seems much hard develop abstractproblem solving domain operators fulfill requirement. Although cannotexpect operators abstract problem solving domain independently refinable,knowledge engineer developing abstract domain still try define abstractoperators independently refined situations, i.e., sc , s~c 2 Scstate abstraction mapping ff applicable abstract operator refinedconcrete operator sequence. Although notion mostly independent refinabilityformal feel practically useful developing abstract domain definition.abstract operators refined independently many situations,higher chance abstract plan composed operators also refinable.7.5.2 Goal Distance Abstract Operatorsgoal distance (cf. subgoal distance, Korf, 1987) maximum length sequenceconcrete operators required refine particular abstract operator. longer goaldistance larger search space required refine abstract operator. particular,complexity search required refine complete abstract plan determinedlargest goal distance abstract operators occur abstract plan.Hence good reason keep goal distance short. However, goal distancenegatively interacts next factor, namely concrete scope applicabilityabstract operators.7.5.3 Concrete Scope Applicability Abstract Operatorsconcrete scope applicability abstract operator specifies many concretestates abstracted abstract state abstract operator applicable,many concrete states abstracted abstract state reachedabstract operator. scope determined definition abstract operatorgeneric abstraction theory responsible specifying admissible stateabstractions. concrete scope applicability abstract operators determinesapplicability abstract plans learned. abstract plan applicable concrete problems limited use domains problemssolved vary much. Hence, concrete scope applicability abstract operators large possible. Unfortunately, according experience, abstractoperators large scope usually also larger goal distance operatorsshort goal distance don't large scope applicability. Therefore, compromisetwo contradicting issues must found.7.5.4 Complexity Generic Abstraction Theoryfourth factor uences problem solving time complexity genericabstraction theory. theory must applied time new concrete state createdconcrete level search. complex generic abstraction theory,time required compute state abstractions. Hence, generic abstraction theory84fiBuilding Refining Abstract Planning Casesrequire complicated inferences avoid backtracking within SLD-refutationprocedure.Although four factors don't allow precise prediction expected problemsolving behavior resulting system, provide focus considerdesigning abstract problem solving domain related generic abstraction theory.8. Example Domain: Process Planning Mechanical EngineeringParis approach successfully tested toy-domains familiartowers Hanoi (Simon, 1975). domains, hierarchical problem solvers usedropping sentence approach also proven useful (Knoblock, 1994).section presents new example domain selected field process planning mechanical engineering really requires stronger abstractionapproach.13 selected goal generating process plan productionrotary-symmetric workpiece lathe. problem description, may derivedCAD-drawing, contains complete specification (especially geometry)desired workpiece (goal state) together specification piece raw material(called mold) produced (initial state).left side Figure 9 shows example rotary-symmetric workpiecemanufactured cylindrical mold.14 Rotary parts manufactured puttingmold fixture (chuck) lathe. chucking fixture, together attachedmold, rotated longitudinal axis mold rotation center.mold rotated cutting tool moves along contour thereby removes certain partsmold desired goal workpiece produced. Within processhard determine sequence specific parts workpieceremoved cutting tools used. workpiece chucked certain areaworkpiece covered chucking tool cannot processed cutting tool.Moreover, workpiece chucked area used chucking plain.Otherwise fixation would suciently stable. Hence, many workpieces usuallyprocessed first chucking workpiece one side processing accessible area.workpiece chucked opposite side area previously coveredprocessed. Processing example workpiece shown Figure 9 requiresworkpiece first chucked left side right side processed. processedright side used chuck workpiece area plain allows stablefixing. Hence, left side workpiece including small groove processed.explain representation domain detail. complete definitiondomain found Online Appendix 1. Several simplifications realdomain required order obtain domain definition could eciently handledlarge set experiments. One restriction represent workpiecesright-angled contour elements. example, conical contour cannot represented.Many different cutting chucking tools available real-life process planning.13. domain adapted CaPlan-System (Paulokat & Wess, 1994), developed University Kaiserslautern.14. Note figure shows 2-dimensional drawing 3-dimensional workpiece. measure 1 in.equals 25.4 mm.85fiBergmann & WilkeExample WorkpieceGrid Representation example workpiece2 mm18 mm40 mm165 mmRawMaterialWorkpiece10 mm54328 mm12mm(4,2)(1,1)1 234x6 mm8 mmFigure 9: example workpieces grid representationrestricted single chucking tool three different cutting tools.specification tools also simplified. example, rotationspeed workpiece feed cutting tool also parameters playrole processing workpiece. impact parameters also neglected.Despite simplifications remaining part real-world domain trivialrepresents substantial subset critical problems domain.8.1 Concrete Domainexplain concrete problem solving domain giving detailed descriptionstates operators.8.1.1 State Descriptionrepresentation domain concrete level, exact geometryworkpiece must represented state, including specific measures detailcontour. However, complete workpiece always divided atomic areasalways processed whole. Therefore state representation organizedusing grid divides entire workpiece several disjoint rectangular areasdifferent sizes (see right side Figure 9). Together grid coordinate specificposition size corresponding rectangular area represented. grid usedstatic part state description change planning. Howeverdifferent problems require different grids. specific shape workpiece planningrepresented specifying status grid rectangle. Table 1 predicatesused represent workpiece described detail.Besides description workpiece, state representation also contains information workpiece chucked kind cutting tool currently used.Table 2 describes predicates used purpose.86fiBuilding Refining Abstract Planning CasesPredicate Descriptionxpos max predicates xpos max(xgrid ) ypos max(ygrid ) specify sizeypos max grid direction x-coordinate y-coordinate respectively.state consists exactly one instance predicates, e.g.,xpos max(4) ypos max(5) example shown Figure 9.grid xposgrid ypospredicates grid xpos(xgrid ; xstart; xsize ) grid ypos(ygrid ; ystart; ysize )specify geometrical position size grid areas directionx-coordinate y-coordinate respectively. first argumentpredicates specifies coordinate grid areas, second argumentdeclares geometrical starting position, third argument specifiessize grid areas. state consists exactly one instancepredicates different x-coordinate y-coordinate.example above, grid xpos(1,0,18), grid xpos(2,18,2), grid xpos(3,20,165),grid xpos(4,185,40) specify grid x-direction grid ypos(1,0,8), : : : ,grid ypos(5,26,8) specify grid y-direction.matpredicate mat(xgrid ; ygrid; status) describes status particulargrid area specified coordinates (xgrid ; ygrid). argument statusinstantiated one three constants raw, workpiece, none.constant raw indicates specified area still consists raw material must removed cutting operators. constantworkpiece specifies area consists material belongsgoal workpiece. constant none specifies area containmaterial, i.e., material present mold materialalready removed previous cutting operations. One instancemat predicate required grid area specify current state.previously mentioned predicates change execution plan, mat predicate changed cutting operator.particular, initial state goal state problem differs status assigned grid areas must become removed. example,initial state example shown above, sentence mat(4,2,raw)present final state contains sentence mat(4,2,none).Table 1: Essential sentences representation workpiece8.1.2 Operatorsprocess plan manufacture certain workpiece consists sequence operators.total order operators problem domain manufacturingsteps also executed sequentially lathe.15 chosen four different operators15. However, also new brands lathe machine also allow parallel processing.87fiBergmann & WilkePredicatechuck posDescriptionpredicate chuck pos(side) describes whether workpiece currentlychucked either side. parameter side instantiated onethree constants none, right, left. constant none specifiesworkpiece chucked constants right left specifyworkpiece chucked respective side. state containsexactly one instance predicate.coveredpredicate covered(xmin ; xmax) specifies areas workpiececurrently covered chucking tool. predicate declaresareas x-coordinate lying within interval [xmin ; xmax]covered. Covered areas cannot processed cutting tool. stateconsist exactly one instance predicate workpiece chucked.cut toolpredicates cut tool(id) cut direction(dir) specify unique identicut direction fication (id) cutting tool currently used areaprocessed direction (dir) cutting tool moves. parameter id symbol specifies legal cutting tool describedpredicates included static rules Rc concrete domain description. parameter dir instantiated one three constantsleft, right center. value left specifies cutting tool movesleft right, right specifies cutting tool moves rightleft, center specifies cutting tool move outside towardscenter workpiece.Table 2: Essential sentences representation chucking cutting toolsrepresent chucking workpiece, selection cutting tool, cuttingprocess itself. operators described Table 3.Manufacturing workpiece shown Figure 9 requires 15-step plan shownFigure 10. first, workpiece chucked left side. cutting tool selectedallows cutting right left. tool indicated grid areas removed.Please note left side workpiece cannot processed since coveredchucking tool. (see right side Figure 10), workpiece unchuckedchucked right side. tool allows processing left right, upperpart mold removed. Finally, specific tool used manufacture small groove.8.2 Abstract Domainexample see small groove considered detailprocessed basic contour workpiece established. importantcharacteristic example right part workpiece processedleft side workpiece. sequence crucial success plan. groove88fiBuilding Refining Abstract Planning CasesOperatorchuckDescriptionoperator chuck(side) specifies workpiece chuckedspecified side. side parameter instantiated constantsleft right. Chucking allowed workpiece chucked already surface used chucking plain. effect chuckingoperation, respective instances predicate chuck pos coveredincluded state description.unchuckoperator unchuck specifies chucking workpiece removed. operation executed workpiece chucked already. effect operation, parameter predicate chuck poschanged none predicate covered deleted.use tooloperator use tool(dir; id) specifies tool selected subsequent cutting operators direction cutting tool moves.workpiece must chucked tool chosen. effectoperator respective instantiations predicates cut toolcut direction added state. parameters use tooloperator definition respective predicates.cutoperator cut(xgrid ; ygrid) specifies raw material gridarea indicated coordinates (xgrid; ygrid ) removed. effectoperator predicate mat specifies statusparticular area changed status raw status none. However,apply operator several preconditions must fulfilled. workpiecemust chucked chucking tool must cover specified areaarea must accessible cutting tool. Moreover, cuttingtool allows processing selected area must alreadyselected. cutting tool imposes certain constraints geometricalsize area processed it. details, see fulldescription domain Online Appendix 1.Table 3: Concrete operatorswould processed first workpiece could never chucked left sideprocessing right side would consequently impossible. Domain experts told ussituation specific example shown. general importancemany cases. fact allows us select parts problem description solutionconsidered details abstract. Parts \essential"must maintained abstract case. found abstractdetailed shape workpiece long distinguish processing leftright side workpiece. Furthermore, important distinguishrough contour workpiece small details grooves. developed89fiBergmann & Wilke1. chuck(left)7.-8. unchuck, chuck(right)2.-6. use_tool(right, t2), cut(4,5),...,cut(4,2)9.-12. use_tool(left,t1),cut(1,5),..,cut(3,5)13.-15. use_tool(center,t3), cut(2,4), unchuckFigure 10: plan manufacturing workpieceabstract domain definition containing new language describing states operatorsbased abstraction idea.8.2.1 State Descriptionintroduce new abstract grid divides workpiece left, middle,right area abstract specific location concrete grid area. areascalled complex processing areas. area assigned particular status. Furthermore,abstract state contains information whether complex processing area containssmall contour elements (such grooves), grooves exactly look like.abstract detailed conditions chucking workpiece, abstract statecontains approximation conditions, stating workpiece cannot chuckedparticular side, side contains small contour elements alreadyprocessed. predicates used represent abstract state described detailTable 4.8.2.2 Operatorsconsider abstract operator completely processes one complex areaworkpiece, operator processes complex area roughly, operatorprocesses small grooves complex area. also consider abstract chuckingoperator chucking strong impact overall plan. Table 5 showsavailable abstract operators.8.3 Generic Abstraction Theorygeneric abstraction theory defines sentences used describe abstract state (seeTable 4) terms sentences concrete state (see Tables 1 2) setHorn rules. definition abstract sentence explained detail Table 6.90fiBuilding Refining Abstract Planning CasesPredicateabs area stateDescriptionpredicate abs area state(area; status) describes statusthree complex processing areas. argument areaspecifies one complex processing areas left, middle, right.argument status describes status respective area.status either todo, rough, ready. status todospecifies area needs processing large contour elements, rough area small contour elementsgrooves need processed. status ready specifiesarea completed. abstract initial state usually containsone complex processing areas status todo,abstract goal state complex processing areas statusready.abs small partspredicate abs small parts(area) specifies complex processing area (area) contains small contour elements needmanufactured.abs chuck pospredicate abs chuck pos(side) describes whether workpiececurrently chucked either side. parameter sideinstantiated one three constants none, right, left.predicate exactly meaning chuck pos predicateconcrete level. predicate abstractedrenamed.abs chuckable wppredicate abs chuckable wp(side) describes whether workpiece chucked left right side sidecompletely processed.Table 4: Essential sentences describing abstract statestrongly considered factors uence quality domain (see Section 7.5) development abstract problem solving domain genericabstraction theory. Although none defined abstract operators independently refinable, mostly independently refinable. preconditions abstractoperator still contains approximations conditions must fulfilled order assure concrete operator sequence exist refines abstract operator. example,predicate abs chuckable wp(side) approximation detailed condition (a plainsurface) required chucking. goal distance operator quite differentstrongly depends problem solved. goal distance set fixationoperators two (possibly one unchuck operator followed chuck operator)goal distances abstract operators different. example, goal distance process ready operator depends number concrete grid areas belonging91fiBergmann & WilkeOperatorset fixationDescriptionoperator set fixation(side) specifies workpiece chuckedspecified side. side parameter instantiatedconstants left, right none. constant none specifieschucking removed. Compared concrete operator chuckpreconditions chucking side simplified. effectoperator predicate abs chuck pos modified.process roughoperator process rough(area) specifies complex processingarea (area) processed completely small contour elements. parameter area either left, middle, right.precondition operator requires workpiece chuckeddifferent side area. effect operator predicate abs area state modified.process fineoperator process fine(area) specifies small contour elementscomplex processing area (area) processed. parameter area either left, middle, right. preconditionoperator requires large contour elements sideworkpiece already processed workpiece chuckeddifferent side. effect operator predicateabs area state modified.process readyoperator process ready(area) specifies indicated complexarea workpiece completely processed, including largesmall contour elements. effect operator predicateabs area state modified.Table 5: Abstract operatorsrespective abstract area containing material needs removed.goal distance number gird areas, say c, plus number required use tooloperations (less equal c). Hence, goal distance c 2c.goal distance become long complex problems, two operatorsprocess rough process fine introduced. cover processing smalllarge grid areas respectively consequently smaller goal distanceprocess ready operator. goal distance two operators smallersmaller concrete scope applicability process ready operator. exampleprocess ready operator applied state arbitrary areas needprocessed, process fine applied states large grid areasalready processed.Although developed simplified version whole domain production planning mechanical engineering rotary symmetrical workpieces feel92fiBuilding Refining Abstract Planning CasesAbstract Predicate Description terms predicates concrete domainabs area statepredicate abs area state(area; status) describes statusthree complex processing areas. left processing areaconsists areas concrete grid covered,workpiece chucked left side. Similarly, right processingarea consists concrete grid areas coveredworkpiece chucked right side. middle processing areaconsists areas never covered chuckingtool. status complex processing area todo, existsconcrete large grid area belongs complex processingarea needs processed. grid area consideredlarge size direction x-coordinate larger 3mm. status complex processing area rough, largegrid areas complex processing area already processedexists concrete small grid area belongscomplex processing area needs processed. girdarea considered small size direction x-coordinatesmaller equal 3 mm. status complex processingarea ready concrete grid areas belong complexprocessing area processed.abs small partssentence abs small parts(area) holds exists small concrete grid area (size smaller equal 3 mm) belongscomplex processing area needs processed.abs chuck possentence abs chuck pos(side) holds concretesentence chuck pos(side) holds.abs chuckable wppredicate abs chuckable wp(side) describes whether workpiece still chucked left right side sidecompletely processed. sentence holds part desiredworkpiece belongs respective side completely plain.is, concrete grid areas status workpiece rangey-coordinate.Table 6: Generic abstraction theorydomain expert together knowledge engineer able define abstractdomain representation generic abstraction theory complete domain. particular, model-based interactive knowledge acquisition tools like MIKADO (Schmidt, 1994;Schmidt & Zickwolff, 1992) make complete modeling task much feasible.93fiBergmann & WilkeCase C1Initial stateGoal StateSolution1. chuck(left)8.chuck(right)13. use_tool(center, t3)2. use_tool(right,t2) 9.use_tool(left,t1) 14. cut(2,4)3.-6. cut(4,5),..., cut(4,2) 10.-12. cut(1,5),..., cut(3,5) 15. unchuck7. unchuckProblemAbstraction1.2.- 6.7.- 8.9.- 12.I.II.III.IV.13.- 14.15.ProblemAbstractionAbstractionV.VI.Abstract Case CaAbstract initial stateabs_area_state(left, todo)abs_area_state(right,todo)abs_small_parts(left)abs_chuckable_wp(right)ProblemAbstractionAbstract SolutionI. set_fixation(left)II. process_ready(right)III. set_fixation(right)Abstract goal stateIV. process_rough(left)V. process_fine(left)VI. set_fixation(none)I.II.III.1.2.- 3.4.- 5.IV.V.VI.11.- 14.15.abs_area_state(left, ready)abs_area_state(right,ready)abs_chuckable_wp(right)Refinement6.- 11.New Case C2Initial stateSolution Solution1. chuck(left)2. use_tool(right,t2)3. cut(7,3)4. unchuckProblemAbstractionGoal State5.chuck(right),12. use_tool(center, t3)6.use_tool(left,t1), 13. cut(2,2)7.-11. cut(1,3),...,cut(5,3), 14. cut(4,2)15. unchuckFigure 11: Abstracting Refining Example Case8.4 Abstracting Refining Process Planning Caseexplain example case shown Figure 9 abstractedabstract case reused solve different planning problem. processdemonstrated Figure 11. top figure shows concrete planning case C1already presented Figure 9. case abstracted Pabs algorithm presentedSection 6. algorithm returns 6 different abstract cases16. One abstract casesshown center figure. abstract solution plan consists sequence 6abstract operators. sequence operators plan indicated Romannumerals. particular abstraction indicated concrete abstract casedenotes sequence concrete operators turned abstract operator.16. 5 abstract cases differ shown abstract case two aspects: shown abstractsolution additional abstract step set fixation(none) inserted steps II III.abstract step V also replaced abstract step process ready, abstract steps IV Vtogether replaced abstract step process ready.94fiBuilding Refining Abstract Planning Caseslearned abstract case used solve new problem C2 whose initialfinal concrete states shown bottom figure. Even concrete workpiecelooks quite different workpiece case C1 abstract case used solveproblem. reason new workpiece also requires leftright side must processed. particular right side must also processedleft side processed left side contains two small grooves preventworkpiece chucked side processed. However, seeabstract operators (in particular operators II, VI, V) refined completelydifferent sequences concrete operators abstracted.already mentioned, abstract operators used independently refinablemostly independently refinable. Consequently, happen applicable abstract case cannot refined. Figure 12 shows example concrete planning problemabstract case shown Figure 11 applicable refinable. reasonlocation small abstract part left side workpiece. smallpart consists concrete grid area (1,3) raw material must removed. However, specific situation, small part must removed large parts,left side workpiece contains (the grid areas (2,3), (3,3), (2,2)), removed.reason without removing small part, larger parts located rightsmall part cannot accessed cutting tool able cut areas (2,3)(3,3). Consequently problem solved plan shown rightside Figure 12. Unfortunately, plan refinement abstract plan shownFigure 11, abstract plans requires large parts must removedsmall parts removed. Hence, refinement operator process rough(left) fails.situation problem solver must select different abstract plan.9. Empirical Evaluation Resultssection presents results empirical study Paris mechanical engineering domain already introduced. evaluation performed fully implementedParis system using abstraction abilities system. generalization component switched-off purpose. designed experiments allow usjudge performance improvements caused various abstract cases derived Pabs.Furthermore, analyzed average speed-up behavior system respectlarge set randomly selected training test cases.9.1 Planning Casesempirical evaluation 100 concrete cases randomly generated. caserequires 100-300 sentences describe initial final state,instances mat predicate. length solution plans ranges 6 18operators. Even generated cases represent simple problems comparedproblems real domain expert needs solve, search space required solve sampleproblems already quite large. due fact branching factor b1:7 6:6, depending complexity problem. Hence, 18-step solutioncomplete search space consists 3:7 1015 states.95fiBergmann & WilkeSolutionNew Problem2 mm322mm1Workpiece8 mm1. chuck(left)2. use_tool(right,t2)3. cut(4,3)4. cut(4,2)5. unchuck6. chuck(right)7. use_tool(left,t1)8. cut(1,3)9. cut(2,3)10. cut(3,3)11. use_tool(center, t3)12. cut(2,2)13. unchuck18 mmabs_small_parts(left)1 234xFigure 12: Example Case refinement abstract plan shown Figure11 fails.case generation procedure leads solutions optimal nearly optimal.solutions require less 10 steps optimal solutions senseknown shortest solution problem solve. solutions longer10 steps manually checked see whether contain stepsobviously redundant. redundant steps removed. Although solutionsnecessarily shortest solutions, nevertheless acceptably short.9.2 Evaluating Abstraction Dropping Sentencesfirst used recent version Alpine (Knoblock, 1993) together Prodigy4 (Blythe et al., 1992) check whether abstraction dropping sentences improveproblem solving domain represented described Section 8. Therefore, usedconcrete problem solving domain domain theory Prodigy. Unfortunately,representation, Alpine able generate ordered monotonic abstractionhierarchy. reason Alpine distinguish different groupsliterals different literal names (and argument types) usedproblem space. example, Alpine cannot distinguish different sentencesdescribed mat grid xpos predicate. importantabstraction. would like drop parts grid represent small rectanglesgrooves. However, would require examination measures associatedgrid area (as argument) also relation surrounding grid areas. Therefore, sentence drop (or criticalities assign) cannot decided staticallyname predicate type arguments. hierarchical planners including96fiBuilding Refining Abstract Planning CasesProdigy Alpine highly dependent representation used, particularstrategy restricted dropping sentences (Holte et al., 1994, 1995). However, mightanother representation domain hierarchical planners improveperformance think representation quite "natural" domain.first trial conclude application domain representationchosen following experiments Paris really require droppingsentences achieve improvement abstraction.9.3 Evaluating PARIS Approachfirst experiment Paris designed evaluate hypotheses domainneed (I) changing representation language abstraction, (II)reusing abstract cases instead generating abstract solutions scratch. testhypotheses rely time solving randomly generated problems using differentmodes Paris system.9.3.1 Experimental Settingexperiment used Paris system solve 100 problems randomlygenerated cases. Thereby goal abstraction improve concrete-level problemsolver, performs brute-force search depth-first iterative-deepening searchstrategy (Korf, 1985a) introduced Section 7.3. improvement determinedterms problem solving time required solve single problem. Paris used solve100 problems three different modes:Pure search: problem solver used solve problem pure search withoutuse abstraction.Hierarchical planning: mode Paris uses introduced abstract domain. How-ever, abstract cases recalled case library computed automatically search standard hierarchical planning, using new abstraction language. So, problem solver first tries search solution originalproblem abstract domain tries refine solution.hierarchical problem solving, backtracking two levels abstractionsubproblem occur. Thereby, used hierarchical planningnew abstraction methodology instead dropping sentences.Reasoning abstract cases: mode first used Paris learn abstractcases come 100 concrete cases. problem, abstract casesexists according abstraction methodology available oneproblems solved. problem solving measured time requiredsolving problem using every applicable abstract cases. Then, problem,three abstract cases determined: a) best abstract case, i.e., case leadsshortest solution time, b) worst abstract case (longest solution time)abstraction aspired solution case, c) worst applicable abstractcase determined. difference b) c) relates differenceapplicable refinable abstract cases introduced Section 7.1. abstract case97fiBergmann & Wilkeselected c) applicable current problem, might abstractioncase problem taken. b) abstract cases selectedindeed abstractions current problem, i.e., abstract casespreviously learned case problem taken. threedifferent cases selected figure impact case selection (whichaddressed paper) proposed method.Although every problem theoretically solved brute-force search procedure,exponential nature search space avoids solution complex problems withinreasonable time. Therefore, time-bound 200 CPU seconds Sun Sparc-ELCcomputer introduced three modes described above. limit-boundexceeded problem remains unsolved. Increasing time-bound would increasenumber solvable problems three modes.9.3.2 Resultsdetermined solution time 100 problems describedmodes. average solution time well number problems could solvedwithin time limit shown Table 7. determined values reasoningabstract cases separately three types abstract cases. significancespeedup results investigated using maximally conservative sign test(Etzioni & Etzioni, 1994). Unfortunately turned speedup hierarchicalplanning pure search significant. also couldn't find significant speedupreasoning abstract cases using always worst applicable abstract case (c)pure search. due large number doubly censored data (both problemsolvers cannot solve problem within time limit), countedspeedup hypothesis. However, improvements pure search reasoning refinableabstract cases significant (p < 0:000001) using best refinable case (a)using worst refinable case (b). Furthermore, turned speedupreasoning refinable cases hierarchical planning also significant upperbound p-value 0:001. mentioned p-value standard value used statisticalhypothesis tests. probability, assuming hypothesis hold,encountering data favors hypothesis much observed dataexperiment (Etzioni & Etzioni, 1994). Therefore result significantp-value smaller. analysis, clearly see, two basic hypothesessupported experimental data. Even significant see moderateimprovement problem solving time number solved problems usinghierarchical planning changing representation language. Please rememberhierarchical planning dropping conditions lead improvement (seeSection 9.2). Obviously, changing representation language abstraction requiredimprove problem solving domain stated first hypothesis (I).strong support second hypothesis (II) also found presenteddata. see significant speedups reasoning abstract cases pure searcheven hierarchical planning. worst abstract case used problemsolved, speedup significant problem solving behavior slightlyworse hierarchical planning. Please note situations extremely unlikely98fiBuilding Refining Abstract Planning CasesProblem solving modeAverage solution time (sec.) Solved problemsPure search15629Hierarchical planning10750Reasoning abstract cases(a) Best refinable case3594(b) Worst refinable case6379(c) Worst applicable case11745Table 7: Comparison average solution time per problem number solvedproblems within time-bound 200 seconds. table compares pure search(depth-first iterative deepening), hierarchical planning using abstract problem solving domain, reasoning abstract cases differently selectedabstract cases.happen all. sophisticated indexing retrieval abstract cases situationavoided part.9.4 Evaluating Impact Different Training Setsone respect previous experiment based optimistic assumption. alwaysassume abstract cases required solving problem learned advance.situation realistic scenario application. Usually, one set casesavailable training system different set problems needs solved.cannot assume good applicable abstract cases always available solve newproblem. Furthermore, presented example also shows problem solving timevary lot different abstract cases selected problem solving. Therefore,designed new experiment evaluate improvements caused Paris approachrealistic scenario.9.4.1 Experimental Settingrandomly chosen 10 training sets 5 cases 10 training sets 10 cases100 available cases. training sets selected independently other.Then, 20 training sets used separate experiment. 20experiments, 100 cases used particular training setused evaluate performance resulting system. Training set test setcompletely independent procedure. problem solving task,determine problem solving behavior applicable abstract cases, usedsimple automatic mechanism retrieve one (hopefully good) applicable abstract caseproblem. Therefore, cases organized linearly cases base, sortedlength abstract plan contained case. case base sequentially searchedlonger shorter plans applicable case found. heuristic basedassumption longer abstract plan specific shorter abstract plan99fiBergmann & WilkeSize training sets(cases)510Number abstract casesminimummaximumaverage7159.182514.2Table 8: Comparison number learned abstract cases a) 10 training setsconsists 5 concrete cases b) 10 training setsconsists 10 concrete cases. table shows minimum, maximum,average number abstract cases learned 10 training setsrespective size.Size training sets(cases)510Average problem solving time (sec.)best setworst setaverage438959357656Table 9: Comparison problem solving time required reasoning abstract casesseparate training a) 10 training sets consists 5concrete cases b) 10 training sets consists 10 concretecases. table shows average problem solving time per problem best,worst average training set 10 training sets size.divides actual problem more, smaller subproblems. Consequently longestapplicable plan lead best improvement.9.4.2 Resultsstatistically evaluated second experiment. Table 8 shows number abstractcases could learned different training sets. minimum, maximumaverage number abstract cases could learned 10 training setssize indicated. Note altogether 42 abstract cases learned 100cases would used training previous experiment. 10 trainingsets contained 5 cases each, 7 15 abstract cases could learned.expected, size training set increased abstract cases learned.Table 9 shows average problem solving time learning different sets.table also shows minimum, maximum average problem solving time10 different training sets two sizes. see best training sets leadsproblem solving time similar slightly worse optimum shownTable 7. Even average case, considerable improvements pure searchhierarchical problem solving (compare Table 7 Table 9) discovered.100fiBuilding Refining Abstract Planning CasesSize training sets(cases)510Percentage Solved Problemsbest setworst setaverage916883947486Table 10: Comparison percentage solved problems separate traininga) 10 training sets consists 5 concrete cases b) 10training sets consists 10 concrete cases. table showspercentage solved problems best, worst average trainingset 10 training sets size.Size training sets(cases)510Number training sets significant speedupspure searchhierarchical planningp < 0:0005p < 0:0005p < 0:059481057Table 11: Comparison significance (p-value) speedup results pure searchhierarchical planning separate training a) 10 training setsconsists 5 concrete cases b) 10 training setsconsists 10 concrete cases. table shows number training setscause significant speedups different p-values.positive results also identified looking percentage solved problems,shown Table 10. also see best training sets number solvedproblems close maximum achieved approach. Even worsttraining set considerably problems could solved pure search hierarchicalplanning.Additionally mentioned speedup results analyzed maximally conservative sign test described (Etzioni & Etzioni, 1994). Table 11 summarizessignificance results speeding pure search hierarchical problem solver.turned 19 20 training sets lead highly significant speedups (p < 0:0005)pure search. hard upper bound p-values half trainingsets lead significant differences reasoning abstract cases hierarchicalplanning. slightly higher upper bound p < 0:05, 3=4 training setscaused significantly better performance hierarchical planning.Altogether, reported experiment showed even small number training cases(i.e., 5% 10%) already lead strong improvements problem solving.see abstract cases must present, first experiment, successful.Furthermore, experiment shown even simple retrieval mechanism (sequential101fiBergmann & WilkeSize training sets(cases)510Average percentage solutionsshorter/equal/longer solution lengthshorterequallonger205426225028Table 12: Comparison length solutions created reasoning learnedabstract cases solutions available concrete cases. table showsaverage percentage solutions shorter/equal/longer solution lengthseparate training a) 10 training sets consists 5concrete cases b) 10 training sets consists 10 concretecases.search) select beneficial abstract cases library. Neither training situationssecond experiment lead results worse worst case shown Table7.9.5 Quality Produced SolutionsAlthough main purpose approach improve performance problemsolver, quality produced solutions also important practical system.solution length used simple criterion determine qualitysolution. However, general quality solution ect execution costsplan, plans robustness, certain user preferences (Perez & Carbonell, 1993).quality measures dicult assess, particular manufacturingdomain, rely simple criterion also used evaluating quality solutionsProdigy/Analogy (Veloso, 1992).9.5.1 Experimental Settinganalyzed solutions computed previous set experiments assessquality solutions produced Paris. Therefore, length solutions derivedproblem solving, learning 20 training sets, comparedlength nearly optimal solutions contained concrete cases.9.5.2 Resultstraining set length solution derived corresponding testing phasecompared length solution noted concrete case. percentagesolutions shorter, equal, longer solution length determined training setseparately, average 10 training sets equal size determined. Table12 shows result evaluation.turned big difference quality results 20training sets. particular, size training sets strong uence102fiBuilding Refining Abstract Planning Casesresults. Table 12 see 72% (22% + 50%) 74% (20% + 54%)solutions produced equal better quality solutions containedconcrete cases. Please note concrete cases used testing always differentcases used training. Additionally, solutions compareresults produced Paris already nearly optimal solutions due case generationprocedure.17 Taking account, results already fairly good.9.6 Impact Abstract Problem Solving Domainexperiments reported conducted concrete abstract domainrepresentation presented Section 8 Online Appendix 1. final experimentimpact specific choice abstract problem solving domain investigated.9.6.1 Experimental Settingcreated new abstract problem solving domain less constrained oneused before. purpose one operator completely removed certain conditionsremaining operators removed also. particular, set fixation operatorremoved conditions abs chuck pos, abs chuckable wp, chuck comp removedpreconditions three remaining operators. Hence, fact chuckingworkpiece impact production plan neglected abstract level.However, concrete problem solving domain generic abstraction theorymodified all. Consequently, chucking still plays important role concrete level.set experiments described Section 9.4 repeated less constrainedabstract problem solving domain using training testing sets before.9.6.2 ResultsTable 13 14 summarize results experiments. Table 13 shows averageproblem solving time occurs learning different training sets. turnstraining sets, learning improves concrete level problem solver,speedup much smaller using original abstract problem solving domain(cf. Table 7 9). particular, none resulting speedups concrete level problemsolving significant. similar result observed comparing percentagesolved problems (see Figure 14). still slight improvement numberproblems could solved learning improvement much smallerusing original abstract problem solving domain (cf. Table 7 10).17. cases one, shorter solutions produced Paris one step shorter solutioncontained concrete case.103fiBergmann & WilkeSize training sets(cases)510Average problem solving time (sec.)best setworst setaverage114118117107112110Table 13: Using less constrained abstract problem solving domain: Comparisonproblem solving time required reasoning abstract cases separatetraining a) 10 training sets consists 5 concrete casesb) 10 training sets consists 10 concrete cases. tableshows average problem solving time per problem best, worstaverage training set 10 training sets size.Size training sets(cases)510Percentage Solved Problemsbest setworst setaverage555253585456Table 14: Using less constrained abstract problem solving domain: Comparisonpercentage solved problems separate training a) 10 training setsconsists 5 concrete cases b) 10 training setsconsists 10 concrete cases. table shows percentage solved problemsbest, worst average training set 10 training setssize.experiment supported general intuition abstract problem solving domain significant impact improvement problem solving achievedreasoning abstract cases. reason less constrained domain leadsworse results original abstract domain explained respectcriteria explained Section 7.5. Since important preconditions abstract operatorsremoved many situations new operators cannot refined.holds particularly situations workpiece cannot chucked performrequired cutting operations. new abstract operators mostly independentlyrefinable. Moreover, since abstract operator set fixation removed concrete chuckunchuck operator must introduced refinement remaining abstractoperators. Consequently, goal distance abstract operators increased.two factors reason worse results using less constrained abstract domaintheory.104fiBuilding Refining Abstract Planning Cases10. Discussionpaper shown detail hierarchical problem solving (Sacerdoti, 1974;Tenenberg, 1988; Unruh & Rosenbloom, 1989; Yang & Tenenberg, 1990; Knoblock, 1990)limited view abstraction dropping sentences well strategyabstract solutions computed lead poor behavior various relevant situations.observation supported comprehensive artificial examples (see Section 2.1 2.2)real-world example domain mechanical engineering (see Section 8),supported experiment (see Section 9.2). recent results reported (Holte et al.,1995) support observations well.general, abstraction task transforming problem solution concrete representation different abstract representation, reducing leveldetail (Michalski & Kodratoff, 1990; Giunchiglia & Walsh, 1992; Michalski, 1994). However, hierarchical problem solvers, much limited view abstractiondropping sentences shown reason ecient ways abstracting problemsolution impossible (e.g., see Section 2.1 Figure 4). second weaknesshierarchical problem solvers usually compute arbitrary abstract solutions solutions high chance refinable next concretelevel. Although upward solution property (Tenenberg, 1988) guarantees refinable abstract solution exists, guaranteed problem solver finds abstractsolution (e.g., see Section 2.2). Problem solvers even heuristically guided towardsrefinable abstract solutions.Paris approach present new formal abstraction methodology problemsolving (see Section 5) allows abstraction changing whole representation language concrete abstract. Together formal model, correct completelearning algorithm abstracting concrete problem solving cases (see Section 6) given.abstract solutions determined procedure useful solving new concreteproblems, high chance refinable.detailed experimental evaluation fully implemented Paris systemdomain mechanical engineering strongly demonstrates Paris significantly improve problem solving situations hierarchical problem solver using droppingsentences fails show advantage (see Table 7 11).10.1 Related Workdiscuss Paris approach relation relevant work field.10.1.1 Theory AbstractionWithin Giunchiglia Walsh's (1992) theory abstraction, Paris approachclassified follows: formal system ground space 1 given concreteproblem solving domain Dc using situation calculus (Green, 1969) representation.language abstract formal system 2 given language abstractproblem solving domain Da . However, operators Da turned axioms2 . Instead, abstract cases build axioms 2 . Moreover, generic abstractiontheory defines abstraction mapping f : 1 ) 2 . Within framework, view105fiBergmann & WilkeParis system learns useful axioms abstract system, composing severalsmaller elementary axioms (the operators). However, prove formula (the existencesolution) abstract system, exactly one axiom (case) selected. deductivemachinery abstract system restricted respect ground space. Dependinglearned abstract cases abstractions Paris either theory decreasing (TD)theory increasing (TI). case-base abstract cases completely emptydomain axiom available resulting abstractions consequently TD. casebase contains maximally abstract case hhtrue; truei(nop)i18 (and generic abstractiontheory contains clause ! true), case applied every concrete problemresulting abstraction consequently TI. Even maximally abstract caseimprove ground level problem solving, always included case-baseensure TI property, loosing completeness. case retrieval mechanismmust however guarantee, maximally abstract case chosen refinementapplicable case available. Note, fulfilled retrieval mechanism(sequential search longer shorter plans) used experiments.10.1.2 Skeletal Plansalready mentioned Section 3.4 Paris approach inspired idea skeletalplans (Friedland & Iwasaki, 1985). abstract cases seen skeletal plan,learning algorithm means learn skeletal plans automatically concreteplans. Even idea skeletal plans intuitively appealing, knowledge,paper contains first comprehensive experimental support usefulness planningskeletal plans. Since shown skeletal plans acquired automatically,planning method applied easily.purpose, Anderson Farley (1988) Kramer Unger (1992) proposed approaches plan abstraction go direction Paris algorithm.However, approach automatically forms abstract operators generalization, mostlybased dropping sentences. Moreover, abstracted plan, every concrete operatorabstracted, number operators reduced abstraction. Therebyabstraction approach less powerful Paris style abstractions.10.1.3 Alpine's Ordered Monotonic Abstraction HierarchiesAlpine (Knoblock, 1989, 1990, 1993, 1994) automatically learns hierarchies abstractionspaces given domain description domain description together planning problem. mentioned several times before, Alpine relies abstraction droppingsentences. However, enables Alpine generate abstraction hierarchies automatically.stronger abstraction framework one follow Paris, automaticgeneration abstraction hierarchies (or abstract domain descriptions) seemrealistic due large (infinite) space possible abstract spaces. use powerful abstraction methodology, feel pay price losing abilityautomatically construct abstraction hierarchy.Another point specific property ordered monotonic abstraction hierarchiesgenerated Alpine, allows ecient plan refinement. refinement, ab18. nop 'no operation' operator always applicable change abstract state.106fiBuilding Refining Abstract Planning Casesstract plan expanded successively lower levels inserting operators. Furthermore,already established conditions plan guaranteed violated anymore refinement. Unfortunately, kind refinement cannot performed Paris-styleabstractions. Especially, direct correspondence abstract operatorsconcrete operators. Consequently, abstract plan cannot extended becomeconcrete plan. However, main function abstract plan maintained, namelyoriginal problem decomposed several smaller subproblems causes mainreduction search.10.1.4 Explanation-based Learning, Case-based Reasoning Analogypresented Paris approach uses experience improve problem solving, similar severalapproaches machine learning, mostly explanation-based learning (Mitchell et al.,1986; DeJong & Mooney, 1986), case-based reasoning (Kolodner, 1980; Schank, 1982; Althoff & Wess, 1992; Kolodner, 1993) analogical problem solving (Carbonell, 1986; Veloso& Carbonell, 1988). basic ideas behind explanation-based learning case-basedanalogical reasoning much related. common goal approachesavoid problem solving scratch situations already occurred past.Explanations (i.e., proofs justifications) constructed successful solutions alreadyknown system. explanation-based approaches, explanations mostly coverwhole problem solving process (Fikes, Hart, & Nilsson, 1972; Mooney, 1988; Kambhampati& Kedar, 1994), also relate problem solving chunks (Rosenbloom & Laird,1986; Laird, Rosenbloom, & Newell, 1986) smaller size even single decisionswithin problem solving process (Minton, 1988; Minton et al., 1989). Explanation-basedapproaches generalize constructed explanations learning extensive useavailable domain knowledge store result control rule (Minton, 1988) schema(Mooney & DeJong, 1985). case-based reasoning systems like Priar (Kambhampati& Hendler, 1992) Prodigy/Analogy (Veloso & Carbonell, 1993; Veloso, 1994) casesusually explicitly generalized advance. kept fully instantiatedcase library, annotated created explanations. Unlike cases Parisproblem-solution-pairs, cases complete problem solving episodes containing detailed information decision taken problem solving. problemsolving, cases retrieved contain explanations applicable current problem (Kambhampati & Hendler, 1992; Veloso & Carbonell, 1993; Veloso, 1994). detaileddecisions recorded cases replayed modified become solutioncurrent problem. approaches use kind generalization experience,none approaches use idea abstraction speedup problem solving basedexperience. already noted (Michalski & Kodratoff, 1990; Michalski, 1994), abstraction generalization must confused. generalization transforms descriptionalong set-superset dimension, abstraction transforms description along level-of-detaildimension.exception given (Knoblock, Minton, & Etzioni, 1991a) Alpine'sabstractions combined EBL component Prodigy. Thereby, control ruleslearned refer ground space problem solving also abstractspaces. control rules speedup problem solving abstract level. However,107fiBergmann & Wilkecontrol rules guide problem solver abstract level finds solutions fastermanner finds refinable abstract solutions. Althoughexperience kind integration abstraction explanation-based learning,assume control rules generated EBL component also guide problemsolver towards short abstract solutions cause much reduction searchseveral circumstances.10.2 Requirements Limitations PARISfollowing, summarize requirements limitations Parisapproach. main requirements availability good abstract domain descriptionavailability concrete cases.10.2.1 Abstract Domainimportant prerequisite method availability required background knowledge, namely concrete world description, abstract world description,generic abstraction theory. construction planning system, concreteworld descriptions must acquired anyway, since specify \language\ problem description (essential sentences) problem solution (operators). abstractworld generic abstraction theory must also acquired. feel indeedprice pay make planning tractable certain practical situations.Nevertheless, formulation adequate abstract domain theory crucialsuccess approach. abstract operators missing required expressuseful abstract plan, speedup achieved. need mostly independentlyrefinable abstract operators. operators exist, simply representedabstract domain using whole representational power. hierarchical planningdropping conditions, abstract domain must also implicitly contained concretedomain way abstract domain remains, certain literals concrete domainremoved (see Section 2.1). feel kind modeling much harderachieve modeling abstract view domain explicitly distinct planning spaceParis. Additionally, requirement abstract domain given useralso advantage learned abstract cases expressed terms userfamiliar with. Thereby, user understand abstract case easily. openadditional opportunity involve user planning process, exampleselection abstract cases she/he favors.Research knowledge acquisition shown human experts employ lotabstract knowledge cope complexity real-world planning problems. Specific knowledge acquisition tools developed comfortably acquire abstractknowledge different sources. Especially, acquisition planning operators addressed much detail (Schmidt & Zickwolff, 1992; Schmidt, 1994).10.2.2 Availability Casessecond prerequisite, Paris approach needs concrete planning cases (problem-solution pairs). real-world scenario cases usually available company'sfiling cabinet database. According requirement share general view108fiBuilding Refining Abstract Planning Casesmachine learning use kind experience promising way copehighly intractable problems. Paris approach available cases mustsomehow representative future problem solving tasks. known cases must similarenough new problems abstract cases really reused. experimentsgive strong indications even small set concrete cases training leads highimprovements problem solving (see Table 9 11).10.3 Generality Achieved Resultsreported experiments performed specific base-level problem solverperforms depth-first iterative-deepening search strategy (Korf, 1985a). However,strongly believe Paris abstractions also beneficial problem solversusing backward-chaining, means-end analysis nonlinear partial-order planning. shown(Veloso & Blythe, 1994), one optimal planning strategy. Different planningstrategies usually rely different commitments search. strategy usefulone domain may worse others. However, search strategies, lengthshortest possible solution usually determines amount search required.Paris, whole search problem decomposed several subproblems allowshort solutions. Consequently, kind problem decomposition usesearch strategies.Moreover, think idea reasoning abstract cases, formulatedcompletely new terminology ground space also useful kindsproblem solving design model-based diagnosis. model-based diagnosis,developed approach (Pews & Wess, 1993; Bergmann, Pews, & Wilke, 1994) similarParis. domain descriptions consist model technical systemdiagnosis found. describes behavior elementary composedcomponent system different levels abstraction. model-based diagnosis,behavior technical system simulated possible faulty component searchedcause observed symptoms. Using abstract cases, search reducedfocused onto components already defective (in similar machines)consequently likely defective new situations.10.4 Future WorkFuture research investigate goal-directed procedures refinement backwarddirected search non-linear partial order planners (see Section 7.4). Additionally,experience must gained additional domains different representations them.Furthermore, address development highly ecient retrieval algorithmsabstract cases. Table 7 shows, retrieval mechanism strong uenceachieved speedup. Even linear retrieval presented turned prettygood, expect utility problem (Minton, 1990) occur size casebase grows. Furthermore, good selection procedure abstract cases also usefeedback problem solver evaluate learned abstract cases basedspeedup cause. would eliminate unbeneficial cases abstract operatorscase-base abstract problem solving domain. Experiments different indexingretrieval mechanisms recently indicated possible.109fiBergmann & WilkeFurthermore, speedup caused combination different approachesabstraction explanation-based learning addressed. Within Paris systemexplanation-based component case generalization still present (see Figure 3),used experiments plain abstraction evaluated.experiments, abstraction, explanation-based learning integrationaddressed comprehensively. hopefully lead better understandingdifferent strengths methods have.long-term research goal, Paris-like approaches developedevaluated kinds problem solving tasks configuration design or,already started, model-based diagnosis.Appendix A. Proofssection contains proofs various lemma theorems.Lemma 6 (Joining different abstractions) concrete domain Dc two disjoint abstract domains Da1 Da2 given, joint abstract domain Da = Da1 [ Da2defined follows: Let Da1 = (La1; Ea1; Oa1; Ra1) let Da2 = (La2; Ea2; Oa2; Ra2).Da = Da1 [ Da2 = (La1 [ La2 ; Ea1 [ Ea2 ; Oa1 [ Oa2 ; Ra1 [ Ra2). joint abstract domainDa fulfills following property: Ca abstraction Cc respect (Dc, Da1)respect (Dc , Da2), Ca also abstraction Cc respect (Dc ; Da).Proof: proof lemma quite simple. Ca abstraction Cc respect(Dc , Dai), exists sequence abstraction mapping ff sequence abstractionmapping fi required Definition 5. easy see, abstraction mappingsalso lead respective case abstraction (Dc ; Da). 2Lemma 7 (Multi-Level Hierarchy) Let (D0; : : : ; Dl) arbitrary multi-levelhierarchydomain descriptions. two-level description (Dc , Da ) Da = l =1Dc = D0 holds that: Ca abstraction Cc respect (D0; : : : ; Dl) Caalso abstraction Cc respect (Dc , Da ).Proof: Let C = hhs0 ; smi; case domain (intermediate state denotedsj ), let C0 = hhs00 ; s0n i; o0i case domain D0 (intermediate state denoted s0i ),let C abstraction case C0 respect (D0; : : : ; ). sequencecases (C1 ; : : : ; C ,1 ) exists Ci domain Di Ci+1 abstractioncase Ci respect (Di ; Di+1) 2 f0; : : : ; , 1g. proof inductionC also abstraction C0 respect (Dc , Da ) (see figure 13). basis( = 1) obvious: C1 abstraction C0 respect (D0 ; D1) consequently alsoabstraction respect (Dc , Da ). Now, assume lemma holds casesdomain ,1 . follows immediately C ,1 abstraction C0 respect(Dc , Da ). Let C ,1 = hhs00; s0k i; o0i let intermediate states denoted s0r .Definition 5 follows, state abstraction mapping ff sequence abstraction mappingfi exists, ff(scfi(r)) = s0r r 2 f0; : : : ; kg. C abstraction C ,1110fiBuilding Refining Abstract Planning Cases1D0Figure 13: Abstraction mappings hierarchies abstraction spacesrespect (D ,1 ; ), also exists state abstraction mapping ff0 sequenceabstraction mapping fi 0 ff0 (s0fi 0 (j ) ) = sj j 2 f0; : : : ; mg. Now,define state abstraction mapping ff00(s) = ff0 (ff(s)) sequence abstraction mappingfi 00(j ) = fi(fi0(j )). easy see, ff00 well defined state abstraction mapping(s s0 ) ff(s) ff(s0) ) ff0 (ff(s)) ff0 (ff(s0 ))) fi 00 well defined sequenceabstraction mapping (fi (fi 0 (0)) = 0 ; fi (fi 0(m)) = fi (k) = n ; u < v , fi 0(u) < fi 0 (v ) ,fi (fi 0 (u)) < fi(fi0(v))). Furthermore follows ff00(scfi 00 (j ) ) = ff0 (ff(scfi (fi 0(j )))) = ff0 (s0fi0(j ) ) = saj ,leading conclusion C abstraction C0 respect (Dc , Da ). 2Theorem 8 (Correctness completeness Pabs algorithm) complete SLDrefutation procedure used Pabs algorithm, Case Ca abstraction case Ccrespect (Dc ; Da) generic theory A, Ca 2 PABS(hDc ; Da; Ai; Cc).Proof:Correctness (\"): Ca returned Pabs, h(oa1 ; : : : ; oak); ff; fi 2 Paths holds 19phase-IV. define state abstraction mapping ff(s) := fe 2 ff jRc [ [ ` eg,which, together sequence abstraction mapping fi lead desired conclusion.every operator oai, know construction phase-IV, hfi (i , 1); fi (i); oai; 2 Gholds. construction phase-III, conclude safi (i,1) [ Ra ` Preoai holdsconsequently E [Ra ` Preoai also holds respective execution bodywhile-loop phase-IV. Since E ff0 ff holds ` monotonic derivation operator,obvious ff(scfi (i)) [ Ra ` Preoai . Furthermore, `if all'-test, executedoaiextension path, ensures (safi (i,1) \ ff ) ,!(safi (i) \ ff ) holds. Togetheroaifulfillment precondition operator ff(scfi (i,1)) ,!ff(scfi(i)).Thus, shown, Ca correct abstraction respect Definition 5.Completeness (\"): Assume, case Ca = hhsa0 ; sam i; (oa1; : : : ; oam)i abstraction Ccbased deductively justified state abstraction mapping. exists state ab19. Note ff refers set finally constructed termination while-loop. use ffdenote respective set construction loop.111fiBergmann & Wilkeoaff(scfi(i))straction mapping ff sequence abstraction mapping fi ff(scfi (i,1)) ,!holds 2 f1; : : : ; mg. Since ff deductively justified A, follows constructionphase-II, ff(sci,1 ) sai,1 . Since ` monotonic derivation operator, preconditon oai also fulfilled safi (i,1) . Furthermore, addlist operator fulfilledff(scfi (i)) consequently also fulfilled sai . construction phase-III,guaranteed, hfi (i , 1); fi (i); oai; 2 G. Now, would like show, phase-IV:exists sequence assignments variable Paths, h(); fi0; ff0i 2Paths, h(oa1 ); fi1; ff1 2 Paths, : : : , h(oa1 ; : : : ; oam); fim; ffm 2 Paths ,fik ( ) = fi( ) 2 f0; : : : ; kg(ffk \ sal) ff(scl) l 2 f1; : : : ; ngffk Skl=1 Addoal .proof induction i. induction basis obvious due initializationPaths variable. Now, assume h(oa1 ; : : : ; oak); fik ; ffk 2 Paths (with k < m)state execution phase-IV. Since, hfi (k); fi (k + 1); oak+1; 2 G holdsargued before, fi (k) = fik (k) induction hypothesis, selected operator sequencetried extended oa = oak+1 body while-loop. Additionally,know, E contains exactly sentences required proof preconditionoak+1 . Note, since SLD-resolution procedure assumed completeoak+1 applicable ff(sck ), E required proof preconditition oaE ff(scfi(k) ). Since ff deductively justified, 8e 2 E ; 8l 2 f1; : : : ; mg holds: e 2 ff(scfi (l))scfi (l) [ Rc [ ` e. construction sal , 8e 2 E ; 8l 2 f1; : : : ; mg holds: e 2 ff(scfi (l))e 2 sal . Consequently, E \ sal ff(scl ) l 2 f1; : : : ; mg. hand,also know oak+1 leads ff(scfi (k+1) ). Consequently, Addoak+1 ff(scfi (k+1)). Followingargumentation above, conclude (Addoak+1 \ sal ) ff(scl )l 2 f1; : : : ; mg. Consequently, ff0 = ffk [ E [ Addoak+1 holds ff0 \ sal ff(scl ). Now,oaconclude Paths extended oak+1 follows. Since ff(scfi ( ,1) ) ,!ff(scfi ( ))holds Addoa 2 ff0 (ff0 \ safi ( ) ) ff(scfi ( ) ), immediately followoa(ff0 \ safi ( ,1) ) ,!(ff0 \ safi ( ) ). Consequently, h(oa1 ; : : : ; oak; oak+1 ); ffk+1; fik+1 2 Pathsffk+1 = ff0 fik+1 ( ) = fik ( ) = fi ( ) 2 f1; : : : ; kg fik+1(k + 1) = fi(k). So,induction hypothesis fulfilled k + 1. Thereby, shown Ca returnedPabs. 2Acknowledgementsauthors want thank Agnar Aamodt, Jaime Carbonell, Padraig Cunningham, Subbarao Kambhampati, Michael M. Richter, Manuela Veloso, well membersresearch group many helpful discussions remarks earlier versions paper. Particularly, want thank Padraig Cunningham carefully proof-reading112fiBuilding Refining Abstract Planning Casesrecent version paper. also greatly indebted anonymous JAIR reviewers helped significantly improve paper. research partially supportedGerman \Sonderforschungsbereich" SFB-314 Commission EuropeanCommunities (ESPRIT contract P6322, Inreca project). partners InrecaAcknoSoft (prime contractor, France), tecInno (Germany), Irish Medical Systems (Ireland)University Kaiserslautern (Germany).ReferencesAlthoff, K. D., & Wess, S. (1992). Case-based reasoning expert system development.Schmalhofer, F., Strube, G., & Wetter, T. (Eds.), Contemporary Knowledge Engineering amd Cognition. Springer, Heidelberg.Anderson, J. S., & Farly, A. M. (1988). Plan abstraction based operator generalization.Proceedings 7th International Conference Artifical Intelligence, pp. 100{104San Mateo. Morgan Kaufmann.Bacchus, F., & Yang, Q. (1994). Downward refinement eciency hierarchical problemsolving. Artificial Intelligence, 71, 43{100.Bergmann, R. (1992a). Knowledge acquisition generating skeletal plans. Schmalhofer, F., Strube, G., & Wetter, T. (Eds.), Contemporary Knowledge EngineeringCognition, pp. 125{133 Heidelberg. Springer.Bergmann, R. (1992b). Learning abstract plans speed hierarchical planning.Tadepalli, P. (Ed.), Proceedings ML92 Workshop Knowledge CompilationSpeedup Learning. University Aberdeen, Scotland.Bergmann, R. (1992c). Learning plan abstractions. Ohlbach, H. (Ed.), GWAI-92 16thGerman Workshop Artificial Intelligence, Vol. 671 Springer Lecture NotesAI, pp. 187{198.Bergmann, R. (1993). Integrating abstraction, explanation-based learning multipleexamples hierarchical clustering performance component planning.Plaza, E. (Ed.), Proceedings ECML-93 Workshop Integrated LearningArchitectures (ILA-93) Vienna, Austria.Bergmann, R., Pews, G., & Wilke, W. (1994). Explanation-based similarity: unifyingapproach integrating domain knowledge case-based reasoning. Richter, M.,Wess, S., Althoff, K., & Maurer, F. (Eds.), Topics Case-Based Reasoning, Vol. 837Lecture Notes Artificial Intelligence, pp. 182{196. Springer.Bergmann, R., & Wilke, W. (1994). Inkrementelles Lernen von Abstraktionshierarchienaus maschinell abstrahierten Planen. Fensel, D., & Nakhaeizadeh, G. (Eds.),Proceedings Workshop Maschinelles Lernen: Theoretische Ansatze und Anwendungsaspekte, No. 291. Institut fur angewandte Informatik und formale Beschreibungsverfahren, University Karlsruhe, Germany.113fiBergmann & WilkeBlythe, J., Etzioni, O., & et al. (1992). Prodigy4.0: manual tutorial. Tech. rep.CMU-CS-92-150, Carnegie Mellon University, Pittsburgh, PA.Carbonell, J. G. (1986). Derivational analogy: theory reconstructive problem solvingexpertise aquisition. Michalski, R. S., Carbonell, J. G., & Mitchell, T. M.(Eds.), Machine learning: artificial intelligence approach, Vol. 2, chap. 14, pp.371{392. Morgan Kaufmann, Los Altos, CA.DeJong, G., & Mooney, R. (1986). Explanation-based learning: alternative view. Machine Learning, 1 (2), 145{176.Etzioni, O. (1993). structural theory explanation-based learning. Artificial Intelligence,60, 93{139.Etzioni, O., & Etzioni, R. (1994). Statistical methods analyzing speedup learning.Machine Learning, 14, 333{347.Fikes, R. E., Hart, P. E., & Nilsson, N. J. (1972). Learning executing generalized robotplans. Artificial Intelligence, 3, 251{288.Fikes, R. E., & Nilsson, N. J. (1971). Strips: new approach application theoremproving problem solving. Artificial Intelligence, 2, 189{208.Friedland, P. E., & Iwasaki, Y. (1985). concept implementation skeletal plans.Journal Automated Reasoning, 1 (2), 161{208.Giordana, A., Roverso, D., & Saitta, L. (1991). Abstracting background knowledgeconcept learning. Kodratoff, Y. (Ed.), Proceedings European Working SessionLearning (EWSL-91), Lecture Notes Artificial Intelligence, pp. 1{13 Berlin.Springer.Giunchiglia, F., & Walsh, T. (1992). theory abstraction. Artificial Intelligence, 57,323{389.Green, C. (1969). Application theorem proving problem solving. ProceedingsIJCAI-69, pp. 219{239 Washington, DC.Holte, R., Drummond, C., Perez, M., Zimmer, R., & MacDonald, A. (1994). Searchingabstractions: unifying framework new high-performance algorithm.Proceedings 10th Canadian Conference Artificial Intelligence, pp. 263{270.Morgan Kaufmann Publishers.Holte, R., Mkadmi, T., Zimmer, R., & MacDonald, A. (1995). Speeding problem solvingabstraction: graph-oriented approach. Tech. rep. TR-95-07, Computer ScienceDept., University Ottawa, Ontario, Canada.Kambhampati, S., & Hendler, J. A. (1992). validation-structure-based theory planmodification reuse. Artificial Intelligence, 55, 193{258.114fiBuilding Refining Abstract Planning CasesKambhampati, S., & Kedar, S. (1994). unified framework explanation-based generalization partially ordered partially instantiated plans. Artificial Intelligence, 67,29{70.Knoblock, C. A. (1989). theory abstraction hierachical planning. ProceedingsWorkshop Change Representation Inductive Bias, pp. 81{104 Boston,MA. Kluwer.Knoblock, C. A. (1990). Learning abstraction hierarchies problem solving. ProceedingsEighth National Conference Artificial Intelligence, Vol. 2, pp. 923{928 London.MIT Press.Knoblock, C. A. (1991). Search reduction hierarchical problem solving. Proceedings9th National Conference Artificial Intelligence, Vol. 2, pp. 686{691 Anaheim,CA.Knoblock, C. A. (1993). Generating abstraction hierarchies: automated approachreducing search planning. Kluwer Academic Publishers.Knoblock, C. A. (1994). Automatically generating abstractions planning. ArtificialIntelligence, 68, 243{302.Knoblock, C. A., Minton, S., & Etzioni, O. (1991a). Integrating abstractionexplanation-based learning PRODIGY. Proceedings 9th National Conference Artificial Intelligence, Vol. 2, pp. 541{546 Anaheim, CA.Knoblock, C. A., Tenenberg, J. D., & Yang, Q. (1991b). Characterizing abstraction hierarchies planning. Proceedings 9th National Conference ArtificialIntelligence, Vol. 2, pp. 692{697 Anaheim, CA.Kolodner, J. L. (1980). Retrieval Organizational Strategies Conceptual Memory.Ph.D. thesis, Yale University.Kolodner, J. L. (1993). Case-based reasoning. Morgan Kaufmann.Korf, R. E. (1980). Toward model representation changes. Artifical Intelligence, 14,41{78.Korf, R. E. (1985a). Depth-first iterative-deepening: optimal admissible tree search.Artifical Intelligence, 27, 97{109.Korf, R. E. (1985b). Macro-operators: weak method learning. Artifical Intelligence,26, 35{77.Korf, R. E. (1987). Planning search: quantitative approach. Artifical Intelligence, 33,65{88.Korf, R. E. (1993). Linear-space best-first search. Artifical Intelligence, 62, 41{78.115fiBergmann & WilkeKramer, M., & Unger, C. (1992). Abstracting operators hierarchical planning.Hendler, J. (Ed.), Proceedings International Conference AI Planning, pp.287{288. Morgan Kaufmann.Laird, J., Rosenbloom, P., & Newell, A. (1986). Universal Subgoaling Chunking:Automatic Generation Learning Goal Hierarchies. Kluwer Academic Publishers, Norwell, MA.Langley, P., & Allen, J. (1993). unified framework planning learning. Minton,S. (Ed.), Machine Learning Methods Planning, chap. 10, pp. 317{350. MorganKaufmann.Lifschitz, V. (1987). semantics STRIPS. Reasoning Actions Plans:Proceedings 1986 Workshop, pp. 1{9 Timberline, Oregon.Lloyd, J. (1984). Foundations Logic Programming. Springer.McAllester, D., & Rosenblitt, D. (1991). Systematic nonlinear planning. Proceedings9th National Conference Artificial Intelligence, pp. 634{639.Michalski, R. S. (1994). Inferential theory learning conceptual basis multistrategylearning. Michalski, R., & Tecuci, G. (Eds.), Machine Learning: MultistrategyApproach, No. 11, chap. 1, pp. 3{62. Morgan Kaufmann.Michalski, R. S., & Kodratoff, Y. (1990). Research machine learning: Recent progress,classification methods, future directions. Kodratoff, Y., & Michalski, R. S.(Eds.), Machine learning: Artificial Intelligence Approach, Vol. 3, chap. 1, pp.3{30. Morgan Kaufmann, San Mateo, CA.Minton, S. (1988). Learning Search Control Knowledge: Explanation-Based Approach.Kluwer, Boston, MA.Minton, S. (1990). Quantitativ results concerning utility explanation-based learning.Artifical Intelligence, 42, 363{391.Minton, S., Carbonell, J. G., Knoblock, C., Kuokka, D. R., Etzioni, O., & Gil, Y. (1989).Explanation-based learning: problem solving perspective. Artificial Intelligence,40, 63{118.Minton, S., & Zweben, M. (1993). Learning, planning scheduling: overview.Minton, S. (Ed.), Machine Learning Methods Planning, chap. 1, pp. 1{30. MorganKaufmann.Mitchell, T. M., Keller, R. M., & Kedar-Cabelli, S. T. (1986). Explanation-based generalization: unifying view. Machine Learning, 1 (1), 47{80.Mooney, R. J. (1988). Generalizing order operators macro-operators. Laird,J. (Ed.), Proceedings 5th International Conference Machine Learning, pp.270{283 San Mateo, CA. Morgan Kaufmann.116fiBuilding Refining Abstract Planning CasesMooney, R. J., & DeJong, G. F. (1985). Learning schemata natural language processing.Proceedings IJCAI, pp. 681{687 Los Angeles, CA.Mozetic, I. (1990). Abstraction model-based diagnosis. AAAI Workshop AutomaticGeneration Approximations Abstractions, pp. 64{75 Boston, MA.Newell, A., & Simon, H. (1972). Human Problem Solving. Prentice-Hall Englewood Cliffs,NJ.Paulokat, J., & Wess, S. (1994). Planning machining workpieces partial-order,nonlinear planner. AAAI-Fall Symposium Planning Learning: RealApplications.Perez, M., & Carbonell, J. (1993). Automated acquisition control knowledge improvequality plans. Tech. rep. CMU-CS-93-142, Carnegie Mellon University.Pews, G., & Wess, S. (1993). Combining model-based approaches case-based reasoningsimilarity assessment case adaptation diagnositc applications. Richter,M. M., Wess, S., Althoff, K., & Maurer, F. (Eds.), Preprints First EuropeanWorkshop Case-Based Reasoning (EWCBR-93), Vol. II, pp. 325{328. UniversityKaiserslautern, Germany.Plaisted, D. (1981). Theorem proving abstraction. Artifical Intelligence, 16, 47{108.Plaisted, D. (1986). Abstraction using generalization functions. Proceedings 8thConference Automated Deduction, Vol. 16, pp. 365{376.Rosenbloom, P., & Laird, J. (1986). Mapping explanation-based learning onto SOAR.Proceedings National Conference Artificial Intelligence, Vol. 2 Philadelphia, PA.Sacerdoti, E. (1974). Planning hierarchy abstraction spaces. Artificial Intelligence,5, 115{135.Sacerdoti, E. (1977). Structure Plans Behavior, Vol. 5. American-Elsevier, NewYork.Schank, R. C. (1982). Dynamic Memory: Theory Learning Computers People.Cambridge University Press, New York.Schmidt, G. (1994). Modellbasierte, interaktive Wissensakquisition und Dokumentation vonDomaenenwissen. Ph.D. thesis, University Kaiserslautern, Germany.Schmidt, G., & Zickwolff, M. (1992). Cases, models integrated knowledge acquisitionformalize operators manufacturing. Proceedings 7th Knowledge AcquisitionKnowledge-based Systems Workshop (Banff).Shavlik, J., & O'Rorke, P. (1993). Empirically evluation EBL. Investigating ExplanationBased Learning, Vol. 5, chap. 7, pp. 222{294. Kluwer Academic Publishers.Simon, H. (1975). functional equivalence problem solving skills. Cognitive Psychology,7, 268{288.117fiBergmann & WilkeTenenberg, J. (1987). Preserving consistency across abstraction mappings. McDermott,J. (Ed.), Proceedings 10th International Conference Artifical Intelligence,pp. 1011{1014 Los Altos, CA. Morgan Kaufmann.Tenenberg, J. (1988). Abstraction Planning. Ph.D. thesis, Computer Science Department,University Rochester, New York.Unruh, A., & Rosenbloom, P. (1989). Abstraction problem solving learning.Proceedings International Joint Conference Artifical Intelligence-89, pp.590{595 Detroit, MI. Morgan Kaufmann.Veloso, M. M. (1992). Learning analogical reasoning general problem solving. Ph.D.thesis, Carnegie Mellon University, Pittsburgh, PA.Veloso, M. M. (1994). PRODIGY/ANALOGY: Analogical reasoning general problemsolving. Richer, M., Wess, S., Althoff, K., & Maurer, F. (Eds.), Topics CaseBased Reasoning, pp. 33{52. Lecture Notes AI, Vol. 837, Springer.Veloso, M. M., & Blythe, J. (1994). Linkability: Examining causal link commitmentspartial-order planning. Proceedings 2nd International ConferencePlanning AI Systems AIPS-94.Veloso, M. M., & Carbonell, J. G. (1988). Integrating derivational analogy generalproblem solving architecture. Minton, S. (Ed.), Proceedings First WorkshopCase-Based Reasoning. Morgan Kaufmann.Veloso, M. M., & Carbonell, J. G. (1993). Towards scaling machine learning: casestudy derivational analogy PRODIGY. Minton, S. (Ed.), Machine LearningMethods Planning, chap. 8, pp. 233{272. Morgan Kaufmann.Wilke, W. (1993). Entwurf und Implementierung eines Algorithmus zum wissensintensivenLernen von Planabstraktionen nach der PABS-Methode. Projektarbeit, UniversitatKaiserslautern.Wilke, W. (1994). Entwurf, Implementierung und experimentelle Bewertung vonAuswahlverfahren fur abstrakte Plane im fallbasierten Planungssystem PARIS. Master's thesis, University Kaiserslautern, Germany.Wilkins, D. (1988). Practical Planning: Extending classical AI planning paradigm.Morgan Kaufmann.Yang, Q., & Tenenberg, J. (1990). Abtweak: Abstracting nonlinear, least commitmentplanner. Proceedings 8th National Conference Aritificial Intelligence, pp.204{209 Boston, MA.118fiJournal Artificial Intelligence Research 3 (1995) 187-222Submitted 5/95; published 10/95Learning Membership FunctionsFunction-Based Object Recognition SystemKevin Woodswoods@bigpine.csee.usf.eduComputer Science & EngineeringUniversity South FloridaTampa, FL 33620-5399Diane Cookcook@centauri.uta.eduComputer Science & EngineeringUniversity Texas ArlingtonArlington, TX 76019Lawrence HallKevin Bowyerhall@waterfall.csee.usf.edukwb@bigpine.csee.usf.eduComputer Science & EngineeringUniversity South FloridaTampa, FL 33620-5399Louise Starkstark@napa.eng.uop.eduElectrical Computer EngineeringUniversity PacificStockton, CA 95211AbstractFunctionality-based recognition systems recognize objects category level reasoning well objects support expected function. systems naturallyassociate \measure goodness" \membership value" recognized object.measure goodness result combining individual measures, membership values,potentially many primitive evaluations different properties object's shape.membership function used compute membership value evaluating primitiveparticular physical property object. previous versions recognition system known Gruff, membership function primitive evaluationshand-crafted system designer. paper, provide learning componentGruff system, called Omlet, automatically learns membership functions givenset example objects labeled desired category measure. learning algorithmgenerally applicable problem low-level membership values combinedand-or tree structure give final overall membership value.1. Introductioncomputer vision (CV) application involving recognition detection \objects", descriptions types objects recognized required. Object descriptionsexplicitly supplied human \expert". Alternatively, machine learning techniquesused derive descriptions example objects.advantages learning object descriptions examples ratherdirect specification expert. Specifically, may dicult personc 1995 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiWoods, Cook, Hall, Bowyer, & Starkprovide CV system accurate description object general enoughcover possible variations visual appearance different instances object.example, two tumors medical images look exactly same. Similarly, wouldcumbersome human provide CV system ranges possible valuesdifferent physical aspects chairs (i.e., possible surface areasseating surface chair? seating surface supported?). Considerable\tweaking" object description parameters may required human expertorder achieve satisfactory system performance. Machine learning techniquesused generate concepts consistent observed examples. exampleslearning systems include C4.5 (Quinlan, 1992), AQ (Michalski, 1983). Systemperformance affected ratio number training examples numberfeatures used describe examples, accuracy examples represent\real-world" objects CV system may encounter.function-based object recognition system example CV systemmachine learning techniques useful development object descriptions.function-based object recognition system recognizes object classifying onegeneric object categories describe function object might serve(Bogoni & Bajcsy, 1993; Brand, 1993; Di Manzo, Trucco, Giunchiglia, & Ricci, 1989; Kise,Hattori, Kitahashi, & Fukunaga, 1993; Rivlin, Rosenfeld, & Perlis, 1993; Stark & Bowyer,1991, 1994; Sutton, Stark, & Bowyer, 1993; Vaina & Jaulent, 1991). object categorydefined terms functionality required object belongs category.example, object category might defined as:straight back chair ::= provides sittable surface & provides stability &provides back supportindicating object classified straight back chair degreesatisfies conjunction three functional properties.functional properties defined terms primitive evaluationsdifferent aspects object's shape. example, candidate surfaces may checkedprovides sittable surface evaluating whether appropriate width, depthheight support plane. many cases, unique ideal valuegiven aspect object's shape, instead range values consideredequivalent terms \goodness". example, anything 0.45 0.55 metersmight equally acceptable height seating surface. However, particular shapemeasurement becomes small large, evaluation measure reduced.Fuzzy set theory provides mathematical framework handling \goodness fit"concept. case, fuzzy membership function transforms physical measurement (i.e.,height object's surface ground) membership value interval [0,1].membership value, evaluation measure, denotes degree object (orportion object) fits primitive physical concept (i.e., well heightsurface matches seating surface height typical chairs). Thus, separate measuregoodness produced primitive evaluation. measures combinedproduce final aggregate measure goodness object.Gruff system (Stark & Bowyer, 1991) function-based object recognition systemutilizes fuzzy logic, manner described, evaluate 3-D shapes. previous188fiLearning Membership Functions Object Recognitionversions Gruff, fuzzy membership functions embedded systemcollectively hand-crafted refined produce best results large set exampleshapes. membership functions ideal candidates learned examples usingmachine learning approach.paper, present method automatically learning collection fuzzymembership functions set labeled example shapes. Due system constraintsimposed Gruff, general-purpose machine learning algorithms, neural networks,genetic algorithms, decision trees, readily applicable. Thus, new special-purposelearning component, called Omlet, developed. Omlet tested syntheticdata two different object categories (chairs cups), data collectedhuman evaluations physical chairs. Results presented show (a) learningmembership functions way provides level recognition performance equivalentobtained \hand-tweaked" Gruff, (b) learning method compatiblehuman interpretation shapes. approach generally applicablesystem set primitive evaluation measures combined produceoverall measure goodness final result.paper organized follows. Section 2 discusses related work, justifies need develop special-purpose learning component. Section 3 introducesGruff object recognition system. Section 4 presents new learning component, calledOmlet. point, state material Section 3 previouslypublished, presented facilitate understanding new learning component. Although Omlet specifically \tailored" add-on learning componentGruff system, applies data structure used systems.general, Omlet described system learning context fuzzyAnd/Or categorization tree. point reader questions concerning Gruff'sobject recognition paradigm references provided. Section 5 describes experimental design data sets utilized. Section 6 documents experimental resultsgives analysis them. Finally, Section 7 summary paper givenconclusions drawn.2. Related Worktwo ways learning might used ease construction systemsGruff. first rules (or proof tree) make Gruff could builtinductive learning system. C4.5, decision tree learner (Quinlan, 1992), good exampleclass learning systems. However, types inductive classification systemscannot adequately replace functionality Gruff/Omlet system. Omlet allowsexamples less perfect membership class used training.direct way accomplish system C4.5. decision-tree based systemwould probably require different trees trained parent child categories.functional concepts (provides sittable surface, example) would get lost trainingprocess individual features chair directly used. could train seriestrees learn functional concepts individually, train decision tree combineresults. approach parameters membership functions learnedpaper would learned implicitly construction decision tree functional189fiWoods, Cook, Hall, Bowyer, & Starkconcept resulting rules. Replacing Gruff/Omlet decision treegeneral-purpose rule learner possible, would require extensive work preserveidea functional object recognition.Omlet aimed second area Gruff-like system could benefitlearning, tuning membership functions. knowledge primitive mightsittable surface. Given measurements specific surface object specific orientation, necessary develop representation acceptable bounds measurementsdetermine whether surface area sittable.Techniques areas machine learning used represent learnprobabilistic fuzzy membership functions. example, belief networks provide mechanism representing probabilistic relationships features domain. Individualfeature probabilities combined generate probability complex conceptpropagating belief values constraints network. Adaptive probabilistic networks kind belief nets learn individual probability values distributions using gradient descent (Pearl, 1988; Cooper & Herskovits, 1992; Spiegelhalter, Dawid,Lauritzen, & Cowell, 1993). structure belief nets update algorithmssimilar approaches found Omlet. However, Omlet incorporates symbolic theorem proving, feature fundamental performing function-based object recognition,well value propagation.Similar research performed learn fuzzy membership functions using adaptive techniques genetic algorithms classifier systems (Parido & Bonelli, 1993;Valenzuela-Rendon, 1991). Much work used learn individual membership functions cannot handle combinations input. again, little workdirected learning fuzzy memberships context rule-based system. Additional refinement techniques reinforcement learning (Mahadevan & Connell, 1991;Watkins, 1989), neural networks, statistical learning techniques also usedrefine confidence values.project represents new direction computer vision machine learning research; namely, integration machine learning computer vision methods learnfuzzy membership functions function-based object recognition system. Although learning functions rule-based context novel effort, similar research performed area refining certainty factors intelligent rule bases. example,Mahoney Mooney (1993) Lacher et al. (1992) use backpropagation algorithmsadjust certainty factors existing rules order improve classification given settraining examples. contrast Omlet's approach, systems refine valuesrepresent measure belief given result adjusted according combinationfunctions certainty factors. Omlet's measures represent degrees fuzzy membershipobject class, refinement method propagates error And/Or tree.work Wilkins (1994) focuses revising probabilistic rules classification expert system. Probabilistic weights applied rule, indicating strengthevidence supplied rule. However, refinements rule occur formmodifying applicability rule generalizing, specializing, deleting addingrules, instead automatically refining weight rule. authors avoid automaticrefinement weights resulting rule base may interpretable experts.190fiLearning Membership Functions Object RecognitionTowell Shavlik (1993) convert set rules representation suitableneural net, train network re-extract refined rules. initial networkset chain rules. extracted rules necessarily clearfunctional meaning approach aims preserving.several new approaches learning tuning fuzzy rules (Ishibuchi, Nozaki,& Yamamoto, 1993; Berenji & Khedkar, 1992; Jang, 1993; Jang & Sun, 1995) usegenetic algorithms specialized kinds neural networks, making use reinforcementlearning. approaches might provide alternative way learn membership valuesprovided initial functional rules given fuzzy rules. However, modificationslearning approaches would needed normally work domains without rulechaining hierarchies rules Gruff/Omlet.3. Gruff Object Recognition SystemGruff acronym stands Generic Representation Using Form Function (Stark& Bowyer, 1991). Gruff recognition system takes 3-D shape description input,reasons whether shape could belong object categories knownGruff, outputs interpretation category object could belong.\interpretation" specified orientation labeling parts shapeidentified satisfying functional properties. See Figure 1 exampleinterpretation.GRUFF InputGRUFF OutputProvidesSittableSurfaceProvidesStableSupportFigure 1: Gruff interpretation 3-D shape category conventional chair. Elements shape labeled functional property provide.191fiWoods, Cook, Hall, Bowyer, & Stark3.1 Knowledge PrimitivesGruff's reasoning shape performed using \low level" procedural knowledgeimplemented set knowledge primitives . knowledge primitive representsprimitive physical property concerning shape, physics, causation. knowledgeprimitive takes (specified portions a) 3-D shape description input, alongvalues parameters primitive, returns evaluation measure 01. evaluation measure represents well shape element satisfies particularinvocation primitive.knowledge primitives used Gruff recognize chairs (Stark & Bowyer, 1991,1994; Sutton et al., 1993):1. relative orientation (normal one, normal two, range parameters)primitive determines angle normals two surfaces (normal one normal two) falls within desired range.2. dimensions ( shape element, dimension type, range parameters )primitive used determine dimension (e.g. width depth)surface lies within specified range.3. proximity ( proximity type, shape element one, shape element two )primitive used check qualitative relations shape elements,, close .4. clearance ( object description, clearance volume )primitive used check specified volume unobstructed free spacelocation relative particular part shape.5. stability ( shape, orientation, applied force )primitive used check given shape stable placedsupporting plane given orientation (possibly zero) force applied.first two knowledge primitives include four range parameters: z 1 (stands1st zero point), n1 (1st normal point), n2 (2nd normal point), z 2 (2nd zero point).parameters used define trapezoidal fuzzy membership function, Figure 2,calculating evaluation measure invocation primitive. last threeknowledge primitives range parameters. return evaluation measure1 0 depending whether primitive physical property satisfied.Trapezoidal membership functions ect desire name (categorize) objectsmanner compatible human naming. typically non-trivial range\ideal" value many physical properties related functionality. example,unique value mean sittable surface area population chairs, valueone would rate perfect \1.0" sittability. Reasonable deviationsresult decrease sittability. sittable surface area falls outside idealrange (i.e., z 1 n1, n2 z 2 Figure 2), evaluation measurereduced, indicating surface provides less perfect (but still functional) sittable192fiLearning Membership Functions Object Recognition1.0EvaluationMeasure0.0z1 = leastz2 = greatestn1 = low ideal n2 = high idealPhysical Measurement Particular PropertyFigure 2: Fuzzy membership function returns evaluation measure primitive physicalproperty.area. Finally, area falls outside range values (less z 1, greaterz 2 Figure 2), surface longer function sittable portion chair,evaluation measure 0 returned.3.2 Category Definition TreeGruff's knowledge different object categories implemented category definitiontree , leaves represent invocations knowledge primitives. categorydefinition tree chair category illustrated Figure 3.node category definition tree may two subtrees. One subtree givesdefinition category terms list functional properties. chair example,object must satisfy functional properties stability provides sittable surface orderconsidered member category conventional chair. functional propertymay defined terms multiple primitives. evaluation measures individualprimitives combined (in manner discussed shortly) determine wellfunctional properties satisfied. functional property measurescombined arrive overall evaluation measure category node.subtree defines subcategory. subcategory specialization parent(or superordinate) category, thus provides detailed elaboration definitionparent. subcategory node subtree functional properties requiredaddition parent category. example, Figure 3, subcategorystraightback chair specialization conventional chair additional functionalrequirement provides back support. overall evaluation measure subcategory nodecombination parent category evaluation measure evaluation measureassociated additional functional properties. Figure 3, overall measuresubcategory straightback chair combination measures conventional193fiWoods, Cook, Hall, Bowyer, & StarkName: CHAIRNode(SUB)CATEGORYType:Funtional SubcategoryDefinitionTreesName: CONVENTIONALCHAIRNodeType:(SUB)CATEGORYName:NodeType:(SUB)CATEGORYFuntional SubcategoryDefinitionTreesName: PROVIDESSITTABLE SURFACENodeFUNCTIONALType:PROPERTYPROVIDESName:STABLE SUPPORTNodeFUNCTIONALType:PROPERTYName:NodeType:Funtional SubcategoryDefinitionTreesName: PROVIDESSTABLE SUPPORTNodeFUNCTIONALType:PROPERTYName: STRAIGHTBACKCHAIRNodeType:(SUB)CATEGORYFuntional SubcategoryDefinitionTreesPROVIDESBACK SUPPORTFUNCTIONALPROPERTYLOUNGECHAIRPROVIDESName:LOUNGING SITTABLE SURFACENodeType:RECLINERNodeType: (SUB)CATEGORYFuntionalDefinitionSubcategoryTreesFUNCTIONALPROPERTYName: PROVIDESLOUNGING BACK SUPPORTNodeFUNCTIONALType:PROPERTYName: ARMCHAIRName:Name: PROVIDESLOUNGING ARM SUPPORTNodeType:FUNCTIONALPROPERTYNodeType:(SUB)CATEGORYFuntional SubcategoryDefinitionTreesName: PROVIDESARM SUPPORTNodeType:FUNCTIONALPROPERTYFigure 3: Category definition tree basic level category chair.chair node provides back support subtree. Note subcategory measurementscontribute cumulative measure parent category. may multiple levelssubcategories, conventional chair, straightback chair, armchair Figure 3.Category nodes associated functional properties (such root nodechair Figure 3) associated evaluation measures. nodes usedset control structure function-based definition. However, providecategory definition since object member subcategory automaticallymember predecessor categories. example, Figure 3, object belongssubcategory straightback chair also belongs categories conventional chairchair. superordinate category furniture could added chair category (Stark& Bowyer, 1994).194fiLearning Membership Functions Object Recognition3.3 Combination Evidenceevaluation measures returned primitive invocations functional propertynode combined using T-norm:(a; b) = bb measures combined. T-norm commonly referredprobabilistic (Pand) function (Bonissone & Decker, 1986). immediate parentcategory node directly receives associated measure combining measuresfunctional property nodes using T-norm.example, functional property provides sittable surface defined six primitives. simplicity, we'll denote evaluation measures returned six primitivesp1 p6. functional property stability defined single primitive,also returns evaluation measure (p7). determine overall evaluation measureshape category conventional chair computeconventional chair ::= provides sittable surface Pand stabilityprovides sittable surface ::= p1 Pand p2 Pand p3 Pand p4 Pand p5 Pand p6stability := p7Since definition (sub)category conjunction required functional properties, cumulative measure dominated \weakest link" individualprimitive evaluation measures, property Pand function. So, evaluation measure0 one primitive physical property result cumulative evaluation measure0. evaluation measure 1 indicates primitive physical propertyideally satisfied, shape may belong object category. final result dependsevaluation primitive physical properties.would seem category could simply defined knowledge primitives without using notion functional properties. functional property levelintroduced representation hierarchy two reasons. First, subgroupingsfunctional properties intuitively follow levels named categorization typical humanconcepts function. Secondly, functional property evaluations result labelingfunctional elements object (i.e., portions structure) fulfillfunctional requirement.Since subcategory definition represents increasingly specialized definition, evidence belonging subcategory result increased measure objectbelonging subcategory opposed parent category. combinationfunctional property measurement subcategory node, a, parent node'sevaluation measure, b, computed using T-conorm:(a; b) = + b , b195fiWoods, Cook, Hall, Bowyer, & StarkT-conorm commonly referred probabilistic (Por) function (Bonissone& Decker, 1986). T-conorm used combine measures subcategory node,final subcategory evaluation measure actually computed as:(> T;Esubcategory = 0S;(a; b); ifotherwise:user defined threshold. Thus, functional property measurementsubcategory node, a, must greater minimum order shape receivenon-zero evaluation measure subcategory. purposes work, value= 0 assumed, indicating shape assigned subcategory longnon-zero evidence meets additional functional requirements associatedsubcategory. practice, final classification decision might require much strongerevidence, say = 0:7, shape assigned subcategory.example, determine overall evaluation measure shape categorystraightback chair, first compute overall evaluation measure category conventional chair, previously described. functional property provides back support defined 8 primitives. Denoting measurements returned 8 primitives p8p15, overall evaluation measure (assuming measure provides back support > )category straightback chair computed as:straightback chair ::= conventional chair Por provides back supportprovides back support ::= p8 Pand p9 Pand p10 Pand p11 Pand p12Pand p13 Pand p14 Pand p15object function straightback chair also definition functionconventional chair. T-conorm give object higher evaluation measuresubcategory straightback chair since evidence addition \minimal"amount evidence required shape belong parent category conventionalchair. Thus, Gruff performs recognition shape selecting (sub)categoryhighest overall evaluation measure. correspond specific applicablesubcategory. One exception occurs parent category evaluation measure1 non-zero evidence supporting subcategory functional requirements.case, T-conorm assigns evaluation measure 1 categorysubcategory.particular T-norm/T-conorm pair utilized paper chosen amongrepresentative T-norm/T-conorm possibilities (including non-probabilistic formulations) described Bonissone Decker (1986) analyzing performance conjunctionGruff across set example shapes (Stark, Hall, & Bowyer, 1993a).4. OMLET Learning Systemsection, describe Omlet learning (sub)system. Omlet learns fuzzy membership functions, located leaves And/Or categorization tree, sets196fiLearning Membership Functions Object Recognitiontraining examples. Omlet works together Gruff automatically learn objectcategory definitions use definitions recognize new objects.training mode, Omlet uses examples learn fuzzy ranges primitivemeasurements. training example consists object description coupleddesired overall evaluation measure. testing mode, Omlet uses previously learnedranges act function-based object recognition system. Knowledge primitives formbuilding blocks Omlet system, rules make representation language.rules, fixed, derived Gruff's category definition tree. indicate1) knowledge primitives combined define functional properties, 2)functional properties combined give function-based definition objectcategory.Given training example, Omlet uses rules construct general proof treeexample's given object category. proof tree simply data structure mimicsway Gruff combines primitive evaluation measures. proof tree also maintainsprimitive ranges modified learning algorithm. example proof treegenerated rules define object conventional chair category shownFigure 4. proof trees contain knowledge primitives defined usingrange parameters. knowledge primitives return 0/1 measures,primitive membership function learn. training example must satisfy\binary", necessary, functional properties return evaluation measures 1order example member given category. example, Figure 4,left branch top Pand node represents functional property provides stable support.functional property defined single knowledge primitive rangeparameters. Therefore, input Pand node fixed always return 1.Omlet obtain overall evaluation measure example object, physicalmeasurements shape elements object input primitive fuzzy membership functions leaves proof tree. output leaf node representsevaluation measure individual functional property. evaluation measurescombined internal nodes tree using probabilistic T-norm/T-conormcombiners described Section 2.3. overall evaluation measure input exampleoutput root node (see Figure 4).Input Omlet consists set goals specific examples object (sub)categories.goal includes example's (sub)category, elements 3-D shape fulfillfunctional properties, overall desired evaluation measure greater 0(otherwise object example object category). Figure 5 shows examplegoal conventional chair object.Using training examples, Omlet attempts learn ranges used trapezoidalmembership functions associated knowledge primitive definitions (see Figure 2).training example presented, Omlet attempts prove via rule baseobject member specified category. Here, check make sure physicalelements object listed goal satisfy binary, necessary, functional properties.So, conventional chair training example, Omlet checks given orientationstable, given seating surface accessible (clearance front above) meetsminimum width depth ratio. necessary functional properties satisfied,proof tree constructed. actual overall evaluation measure calculated197fiWoods, Cook, Hall, Bowyer, & StarkRules Conventional ChairConventional ChairEvaluation Measure= 0.572PAND(conventional_chair ?a ?b ?c) ::=(provides_sittable_surface ?a ?b ?c) PAND(provides_stable_support ?a)(provides_sittable_surface ?a ?b ?c) ::=(dimensions AREA range_parameters ?b) PAND(WIDTH/DEPTH 1.0 ?b) PAND(dimensions CONTIGOUS SURFACE range_parameters ?b) PAND(dimensions HEIGHT range_parameters ?b) PAND(clearance ?a ?b) PAND(clearance IN_FRONT ?a ?c)(provides_stable_support ?a) ::=(stability SELF ?a)1.00.572Binary functional property"provides stable support"fixed always return 1?b?cPAND?a0.7631.0Height = 0.670.750ContiguousSurface = 1.0Area = 0.116Knowledge primitives ranges usedcompute evaluation measures functionalproperty "provides sittable surface".Figure 4: simplified proof tree constructed learning example categoryconventional chair. ?a, ?b, ?c symbols rules represent physicalaspects shape used rules. orientation shape, facesittable surface, front edge sittable surface substituted?a, ?b, ?c, respectively. way Omlet knows elementsshape \measured" evaluated knowledge primitives.198fiLearning Membership Functions Object Recognition( conventional_chair mchair.00.orientation2 mchair.00.face2 mchair.00.edge1-8 )Object CategoryObject OrientationSittable SurfaceFront EdgeSittable Surface0.9808DesiredEvaluationMeasureFunctional PropertiesFigure 5: Training goal input Omlet conventional chair object.manner described above. actual evaluation measure suciently differentdesired evaluation measure, primitive fuzzy membership functionsincluded definition need adjusted.Primitive membership functions adjusted propagating overall errortraining sample nodes proof tree way attempts giveleaf node (i.e., range) portion error. range parameters (z 1, n1, n2,z 2) define fuzzy membership trapezoids adjusted attemptreduce total error examples training set. next subsections providedetails Omlet learning algorithm. First, discuss method calculatingerror value propagating proof tree. Next, present methodmaking initial estimates parameters membership function. describe errorpropagation first utilized initialization phase. describeOmlet makes adjustments membership functions attempt reduce errorentire training set. last subsection describes general learning paradigmprovides theoretical justification implementation.4.1 Error Propagationerror training example defined difference desired evaluationmeasure actual evaluation measure computed current state Omletsystem. fraction error (defined \learning rate") propagated prooftree Pand Por nodes. Error propagation Pand Por nodeshandled differently. error three element Pand node E , threeelements receive portion error equal cube root E (i.e., inversePand function). Por node, full amount error, rather equal share,propagated link. rationale treatment error become clearSection 4.4.noted desired evaluation measure fed root treepropagated leaves, error directly computable since actualprojected desired values always known node. actual values nodecomputed physical measurements object shape fed leaf199fiWoods, Cook, Hall, Bowyer, & StarkDesired = 0.6PANDActual = 0.35Desired = .795Desired = .754PANDPANDActual = .612Actual = .571Actual = .85Actual = .72Desired = .959Desired = .829Actual = .81Actual = .85Actual = .83Desired = .891 Desired = .911 Desired = .931Figure 6: Example error propagation Pand tree. Actual values foundoverall evaluation measure computed object. Desired valuespropagated tree, error computed Desired , Actual.nodes combined produce overall evaluation measure root. projecteddesired values proof tree obtained propagating desired evaluation measureroot node leaves. example, given two input Pand nodeactual inputs a1 a2, actual output a1 a2 (from T-norm section2.3). desired output node D, compute desired inputsnode d1 d2 solving following set equations:a1 a2 , d1 d2 = ,a1 , d1 = a2 , d2(1)(2)first equation computes error Pand node1, second equation assuresequal portions error assigned input. Figure 6 shows exampledesired values computed via Equations 1 2 every node proof tree. figure,known desired overall measure = 0:6 top Pand node, actualmeasure = 0:35 computed Pand actual node inputs, a1 = 0:612a2 = 0:571. Using Equations 1 2, easily compute two unknown desiredinputs d1 d2 top Pand node (which also desired outputs bottom1. equivalent simpler equation d1 d2 = could substituted here.200fiLearning Membership Functions Object Recognitiontwo Pand nodes) 0:795 0:754, respectively. three inputs Pand node,solve set three linear equations derive desired inputs.three inputs Pand node, divide set inputs recursively groupstwo three solve set two three linear equations, respectively.Since Por nodes used combine single parent category measure singleaggregate measure subcategory's functional properties, never2 inputs type node. Therefore, full amount error propagatedPor node simply solving independent equations:a2 + d1 , a2 d1 =(3)a1 + d2 , a1 d2 =(4)Eventually, portion overall error propagated ranges definedtrapezoid membership functions. error reaches individual rangestraining example, input primitive membership function (i.e., x axis value)desired primitive evaluation measure (the axis value) define pointlie somewhere trapezoid. also note leg trapezoid point belongsto, based side normal portion range [n1,n2] x value lies.set desired points leg used make adjustments trapezoidattempt reduce error. Omlet collects desired points legmembership function propagating error training examplesproof trees. trapezoid/range parameters (z 1,n1,n2,z 2) adjusted endtraining epoch. Training continues fixed number epochs satisfactorylevel performance, defined minimal classification error rate averaged trainingset, achieved.4.2 Initial Estimate Measurement FunctionsOmlet's learning algorithm begins making reasonable initial estimates fuzzy trape-zoid membership functions physical measurements. accomplished assigning actual values 0 membership functions training example propagating errors (which case would equal desired evaluation measures)ranges leaf nodes proof trees. collections desiredpoints, make initial estimate trapezoidal membership function.important stage place edges constructed normal range (the n1 n2range parameters) somewhere within actual normal range. learning algorithmmake adjustments n1 n2 points subsequent training epochs. Additionally,Omlet may set minimum maximum limits values range parameters(more shortly).training example desired evaluation measure 1 considered \perfect"example object given category. Perfect training examples desirabletraining set primitive measurements perfect examples known fallrange [n1,n2]. example, conventional chair training example desiredevaluation measure 1, know membership functions prooftree (see Figure 4) must return values 1. result Pand functiongreater minimum input.201fiWoods, Cook, Hall, Bowyer, & StarkOmlet examines set desired points propagated rangedefinition tree determines \limit" points. defined follows.two desired points values (memberships) 1, least segment normalrange [n1,n2] known. n1 range parameter set minimum x value desiredpoints values 1. Similarly, n2 parameter set maximum x valuedesired points values 1. Note one desired point foundn1 n2 set value, membership function initially triangular.Since portion normal range known correct, upper limit setn1 value lower limit set n2 value assure known segmentnormal range reduced subsequent training. Since training examplesdesired membership values greater 0, know x input values must liez 1 z 2. Omlet uses minimum maximum x values setdesired points set limits z 1 z 2 range parameters. z 1 range parameternever permitted increase minimum x value training. Similarly, z 2value may never decrease maximum x value set desired points. Figure 7shows range parameters (limit points) Omlet sets initialization phase givenset 10 examples.p4p5p61.0p3p7p8p2p90.0p1Maximumz1 valueAllowedMaximumn1 valueAllowedMinimumn2 valueAllowedp10Minimumz2 valueAllowedFigure 7: Range parameter limits may set initializing range parameters.limits range parameters serve several purposes. First, limits assureperfect training examples assigned evaluation measures less 1,training examples evaluation measures greater 0. importantly,limiting changes made range parameters, better approximationsdesired membership functions learned. subsequent learning, errorpropagated proof tree assumption equal amounts error comeinput node. assumption always valid, waydirectly determine portion error belongs input. error propagatedmembership function would cause change one range parameters(z 1,n1,n2,z 2) moves parameter past set limit, portion overall errorassumed caused membership function correctly estimated.202fiLearning Membership Functions Object Recognitionoccurs parameter set equal limit, effectively reducing degreechanges membership function would compensate overall error.allow learning algorithm find good solution case different membershipfunctions contribute different amounts error.segment normal range known membership function, initialization range parameters straight-forward. n1 n2 values alreadyset. z 1 value set simply making left leg trapezoid passpoint (n1,1.0) point set desired points minimum x value.Similarly, z 2 value set making right leg trapezoid pass point(n2,1.0) desired point maximum x value. pointsleft (right) n1 (n2) point, membership function assumed one-legged(as CONTIGUOUS SURFACE Figure 4) parameters n1 z 1 (n2 z 2)extended large negative (positive) value permitted changetraining.portion normal range membership function determined,attempt fit trapezoid set desired points. First, two desired pointsmaximum values found. assume normal range lies somewherethem. best-fit trapezoid determined varying n1 n2 range parametersassumed normal range, selecting normal range [n1,n2] produces lowesterror set desired points. error sum absolute valuesdifference desired value actual value found point. z 1(z 2) range parameter set manner before, left (right) trapezoidleg forced pass desired point minimum (maximum) x value.n1 value varied leftmost point assumed normal range rightmostpoint small increments. different value n1, n2 value varied n1rightmost point assumed normal range small increments. So, simplytesting range possible trapezoids (with degree accuracy, number trapezoidstested, defined increments n1 n2 varied) normal range[n1,n2] somewhere within assumed normal range. select set rangeparameters minimize total error set training examples. usebest-fit trapezoid approach helpful, initial way accurately associateerror given trapezoid.4.3 Adjusting Membership Functionsmake adjustments membership trapezoid, leg trapezoid fit setdesired points using least squares line fit. Recall every training epochset desired points leg trapezoid. new z 1 (z 2) valuetrapezoid set point left (right) leg intersects 0. new n1 (n2)value set midway old n1 (n2) value value left (right)leg fitted line intersects = 1. new n1 n2 values directly setfitted trapezoid legs intersect 1 overestimating normal range [n1,n2]eliminate desired points used least squares line fittrapezoid leg. Desired points normal [n1,n2] range definition fallleg trapezoid, used adjusting trapezoid legs. Therefore,normal range overestimated, points truly belong trapezoid leg used203fiWoods, Cook, Hall, Bowyer, & Starkadjust leg. gradually moving normal points n1 n2, Omlet better ableconverge appropriate solution. new range parameter values (z 1,n1,n2,z 2)determined, Omlet checks make sure none lie outside limitsmay set initialization phase. Restrictions new range parametersassure membership functions remain trapezoidal (or triangular n1 = n2). First,z 1 must less equal n1. Similarly z 2 must greater equal n2.z 1 (z 2) greater (less) n1 (n2) z 1 (z 2) set equal n1 (n2). Also, n1 mustless equal n2. case single point set desiredpoints trapezoid leg, leg defined normal point leg (n1 leftleg n2 right leg) single desired point.training data may provide target points portion trapezoidranges. Omlet capable detecting situation observing slopefitted line, adjusting membership function appropriately. slope lefttrapezoid leg positive slope right leg negative.slope fitted trapezoid leg nearly horizontal (close 0.0), sign slopeopposite expected, normal point leg moved (again, n1left leg n2 right leg) outward. adjustment allows Omlet learnone-legged membership functions, handle (as well possible) situationsenough training data available.method escaping local minima empirically found useful. Normally Omletallow trapezoid leg change change causes increase total errortraining set. So, possible zero, one trapezoid legs rangeget adjusted epoch. learning slows suciently, Omlet temporarilyallow trapezoid leg changes cause increase overall error hopes escapingpossible local minima. precisely, total training set error one epoch decreasesless specified threshold, range changes cause increase overall errorpermitted next training epoch.4.4 Training Approachorder learn various subcategories defined category definition tree,utilize machine learning approach based assumption human learningknown one disjunct per lesson (Lehn, 1990). Perhaps easiest understandmechanics learning approach explain one-disjunct-per-lesson assumptionterminology cognitive science. Since many terms machine learningderived cognitive sciences, dicult show similaritiesalgorithm characterization human learning. also examinecomputational characteristics learning algorithm support choiceapproach.4.4.1 One Disjunct Per LessonVan Lehn (1990) tells us effective way teaching complicated conceptsbuild simple subconcepts, opposed \all-at-once" approach.purposes, disjunct considered one simple subconcepts. lesson consistsuninterrupted sequence demonstrations, examples, exercises. lengthlesson varies. Thus, might expect human better understand concept204fiLearning Membership Functions Object Recognitionarmchair presenting series lessons, introduces single new subconceptbuilds upon previous subconcepts. example, first lesson teaches conceptconventional chair requires stable sittable surface correct orientation.learn constitutes straightback chair, build upon concept conventionalchair introducing subconcept back support second lesson. So, secondlesson broadens notion chairs, general. Finally, third lesson builds uponunderstanding straightback chair introducing subconcept arm support.contrast, all-at-once approach may try explain armchair provides stablesittable surface correct orientation back arm support. Here,trying teach three subconcepts one time, show three subconceptstogether form complex concept armchair. Indeed, Van Lehn (1990) citeslaboratory studies indicate learning task dicultone disjunct (subconcept) taught per lesson.chosen utilize machine learning algorithm underpinnings similarVan Lehn's one-disjunct-per-lesson assumption. case, concepts subconceptsrepresented categories subcategories. lesson algorithm consistsnumerous epochs training examples one (sub)category. Thus, lessonviewed uninterrupted sequence positive examples \teach" functionalrequirements single (sub)category. length, number training epochs,lessons may vary depending subcategory learned. learn rangescategory definition tree, begin learning simplest concepts first. learnadditional complex subconcepts building upon notion simple concept. example simplified proof tree Figure 8, parent category conventionalchair learned attempting learn subcategory (specialization) straightbackchair. Since subcategory straightback chair parent category, learnedattempting learn even complex subcategory armchair. remaindersubsection discusses implementation finer detail.implementation standpoint, simplest concepts functional propertiesassociated categories directly linked root node categorydefinition tree provides sittable surface provides stable support categoryconventional chair. first lesson, use positive examples \first level" (orparent) categories learn membership functions associated categories.first level categories learned, membership functions \frozen"permitted change subsequent lessons.second lesson, membership functions \second level" categories(i.e., subcategories first level categories definition tree) learned.Figure 8, membership functions belong node provides back support subcategory straightback chair. learned \simple" functional concept associatedparent category, values computed parent category node assumedreasonably accurate. example, actual values proof tree computedstraightback chair training example, actual values emanating parent categorynode conventional chair accurate since concepts associated nodealready learned. is, evaluation measures functional propertiesprovides sittable surface provides stable support straightback chair example assumed correct. implies membership functions making functional205fiWoods, Cook, Hall, Bowyer, & Starkarm_chairPORExample subcategorylearnedparent categoryprovides_arm_supportPANDstraight_back_chairPOR...Example"parent category"conventional_chairPANDprovides_back_supportPAND......Figure 8: Simplified proof tree armchair object.requirement subtree (i.e., provides back support) responsible entire errorsubcategory training example. (This explains Equations 3 4 used propagateerror Por nodes.) Hence, error propagated modifiable leavesfunctional requirement node Pand subtree learning continues before.lessons continue parent category learned subcategories learned, subcategories learned. freezing parent categorymembership functions learned, applying one-subconceptper-lesson strategy. Figure 8 learning straightback chair, membership functions branch frozen armchair subcategory learned modifyingmembership functions provides arm support branch proof tree.Omlet begins learning evaluating rule base order determine subcategorydependencies assigns (sub)category definition tree level learninghierarchy. example, Omlet determines category conventional chair parent category membership functions learned immediately (level 1). However,evaluation measure subcategory straightback chair dependent parentcategory conventional chair. straightback chair subcategory assigned learninglevel 2. Subcategory armchair dependent parent category straightback chair,therefore assigned learning level 3.206fiLearning Membership Functions Object Recognition4.4.2 Practical Justificationorder understand taken one-disjunct-per-lesson approach ratherall-at-once approach, let's make observations concerning accurately blameassignment error determined typical training example.Recall error propagation proof tree involves projecting desired node inputvalues known node output value. Consider Pand node known desired output0.9, two unknown inputs. know inputs must least 0.9.means inputs Pand node fall within relatively small range [0.9,1.0].However, desired output two input Por node 0.9, sureinputs fall range [0,0.9]. known output Pand Por nodelow, say 0.1, opposite effect. is, unknown inputsPor node would lie relatively small range [0.0,0.1], unknown inputsPand node would fall somewhere much larger range [0.1,1.0]. observationssuggest blame assignment error propagated Pand nodereasonable accuracy examples relatively good, say 0.7 above. However,high evaluation measures, error value cannot reliably propagated Pornode.Since subcategory evaluation measure computed Por parent categoryevaluation measure combination additional functional requirements, Pornodes proof tree two inputs. Por nodes (in proof trees) least 1connecting node consists parent (or general) category whose membershipcalculation involves Pand connectives. structure proof trees permitsmembership functions contribute evaluation measure parent categoryaccurately learned prior learning defined additional functional requirementssubcategories. is, determine one inputs Por nodeattempt propagate error node. one input desired outputPor node known, calculation unknown input trivial. Thus, learningapproach eliminates reliability problems associated propagating blame assignmenterror Por nodes. verified Section 6 experimental resultssubcategories straightback chair armchair.mechanics learning algorithm suggests Omlet's performance dependsaccurately blame assignment propagated Pand nodes proof tree.Earlier, observed blame assignment less reliably propagated Pand nodes\bad" training examples. surprisingly, suggests quality trainingdata effect system performance. mean \bad" examplesobject (sub)category cannot, not, included training set. Sinceuse least squares line fit adjust fuzzy membership functions, use \bad"training examples (for blame may inaccurately distributed amongfuzzy membership functions) dramatically affect overall reliabilitylearned system parameters. Rather, desirable train system examplesthat, part, good examples labeled object category. However,unreasonable might expect machine (or human matter) betterlearn constitutes chair observing good examples chairs.207fiWoods, Cook, Hall, Bowyer, & Stark5. Experimental SetupUpon reading rule base, knowledge primitive measurements training examples, training example goals, Omlet begins learning membership functionslevel 1 categories. first learning epoch used make initial estimatesmembership functions, Omlet iterates 1000 additional training epochs.learning rate 0.15 used 1000 training epochs, 15 percent actual error training example propagated adjustable ranges epoch.1000 training epochs, best range parameters (those resulted lowestoverall error) level 1 categories restored frozen. 1000 training epochsrepeated level 2 categories, followed level 3 categories,ranges category definition tree learned2.performance task Omlet system evaluated well trained systemrecognizes objects used training phase. One measurement systemperformance error observed test examples. error test examplecomputed absolute value difference desired actual evaluationmeasures. Training/Test sets configured two ways: random partitioning labeleddata training test sets, leave-one-out testing. first case, givensize training set, 10 train/test set pairs created randomly partitioning labeleddata. error single test set average error test examples. resultsgiven size training set reported average error 10 partitions. leave-oneout testing, one example data set used test remaining samples formtraining set. repeated using example data test set, resultsreported average error test examples. average error per example versustraining set size plotted training sets 10, 20, 30, ... , N-1 samples. pointN-1 training examples represents leave-one-out test results.5.1 Test Gruff Chair Databaseevaluations Gruff (Stark & Bowyer, 1991), large database 3-D shapesspecified polyhedral boundary representations built up. Figure 9 shows 52 chairshapes. number 52 shapes belong one category functionone stable orientation. results total 110 training examples.78 labeled instances category conventional chair. 28 instancesadditionally satisfy function straightback chair, 4 instances satisfy functionarmchair. shape, evaluation measure shape's membershipdifferent object categories, computed Gruff hand-crafted functionsprimitive evaluation measures. set shapes evaluation measures makefirst set training examples.first set experiments help determine well Omlet learns set membership functions minimize overall error, also closely learned membershipfunctions approximate original functions hand-crafted expert Gruff.question great practical importance vision researchers whether machine learning2. preliminary experiments, Omlet converged low overall error level categoriesanywhere 200 900 training epochs. Hence decision train 1000 epochs per categorylevel. learning rate also determined empirically.208fiLearning Membership Functions Object RecognitionFigure 9: 52 object chair database.technique derive set system parameters equivalent hand-crafted resultssystem designer. so, manual effort system construction could greatly eased.learning task formulated duplicating Gruff measures, trainingdata experiments effectively \noiseless". (Noiseless sense desiredevaluation measures used input Omlet derived mannerset hand-crafted fuzzy membership functions.)5.2 Test Synthetic Cup Databasedefinition recognition cups task visited frequently machinelearning research (Mitchell, Keller, & Kedar-Cabelli, 1986; Winston, Binford, Katz, &Lowry, 1983). Winston (1983) observes, hard tell vision systems cupslook like. much easier talk purpose function cup.convey description cup providing functional definition. particular, cupdescribed object hold liquid, stable, liftable, useddrink liquids. physical identification made using functional definition.particular, synthetic set objects created here, functional propertiesbroken 19 knowledge primitives, 17 range parameters.generated database 200 synthetic cup examples, measurementsknowledge primitives randomly distributed. Hand-crafted range parameters(z 1,n1,n2,z 2) supplied 17 ranges cup functional definition. generate209fiWoods, Cook, Hall, Bowyer, & Starkcup example, primitive measurement randomly selected range. Approximately80% time primitive measurement randomly chosen n1 n2.20% time measurement randomly chosen outside n1 n2, insidez 1 z 2. cup generator program provides us capability create largenumber cup examples without time-consuming process creating actual 3-D CADmodels example.5.3 Learning Human Evaluation Measuresobject recognition important test system real objects, possible, numberreasons. First, see whether system approximate human judgment. Second,important observe system performance presence noise, real-world datainevitably contain. Finally, using real-world data alleviate need completelyhand-craft system synthetic data. actually useful guide scenario\vision system engineer" gives system set human-labeled examples,lets system learn parameters. test Omlet, used set 37 actualobjects human ratings well might serve chair. Figure 10 showsobjects used experiments.Figure 10: examples chair objects used human evaluation tests.order determine well Omlet learn recognize set real chair-likeobjects, objects collected together single room object placedorientation would likely recognized chair. actual chairs,simply orientation chair would typically used. metal trash210fiLearning Membership Functions Object Recognitionwould \upside down" orientation, etc. group 32 undergraduatestudents Artificial Intelligence class given following instructions:asked rate thirty-seven objects according degree\chair-ness" ected 3-D shape. purposes, \chair-ness"measures object could used chair. consider3-D shape making rating. assume object madeappropriate materials, factor ratings.consider suitability object shape orientationsee it, rather orientation. Examples factorsconsider rating \chair-ness" shape height, width, depth, area,relative orientation apparent stability.asked rate shape requirements three differentaspects \chair-ness". first aspect solely ability provide stableseating surface. second aspect solely ability provide back supportcompatible seating surface. third aspect solely abilityprovide arm support compatible seat back. aspectjudged independently scale 1 5, 1 means abilityprovide required function 5 means seems ideal providedesired function. may mark halfway two numbers wish.ratings aspect \chair-ness" averaged, normalized roundednearest multiple 0.02 result values range [0,1]. overall evaluationmeasures objects conventional chair category taken normalizedevaluation measures first aspect \chair-ness", object's ability providestable seating surface. Overall evaluation measures categories straightback chairarmchair computed using probabilistic T-conorm combine three aspects\chair-ness" manner described Subsection 3.3. Hence, comfortable, sturdychair would value close 1 \chair-ness", upside-down trashconsiderably lower value (approx. 0.5).objects rated, measurements taken primitivesdescribing chair Gruff system. measurements requiredOmlet rules, clearance ground, area sittable surface,height sittable surface, etc. Complete Omlet examples describing objectscreated, including aggregate evaluation measure objects categoriesconventional chair, straightback chair, armchair. resulted 37 objectsconventional chair category, 22 objects straightback chair category (15 objectsback support all), 12 objects armchair category (10 objectsback support arm support). least two sources noiseexperimental data: 1) human evaluations, 2) actual measurementsphysical properties objects. example, standard deviations normalizedhuman evaluations 37 objects conventional chair category 0.12,12%, average. results leave-one-out testing 37 real-world objectspresented next section.211fiWoods, Cook, Hall, Bowyer, & Stark6. Experimental Resultsleast four factors may affect performance Omlet system: 1)number training epochs, 2) number training samples category, 3)number ranges learned category, 4) quality training datacategory. Histograms desired evaluation measures training data usedconvey concept training set \quality". shown Figure 11 Gruffchair data. height histogram bin number training samples desiredevaluation measures fall within particular range. So, histogram \good" settraining data would skewed towards higher evaluation measures. Similarly,histogram representing \bad" training data would skewed towards lower evaluationmeasures.Figure 11: Histograms desired evaluation measures Gruff chair training sets.histogram parent category, conventional chair cup, representsdistribution overall desired evaluation measures (which goal measuresexamples data set provided input Omlet). However, histograms subcategories, straightback chair armchair, represent distributions desiredevaluation measures associated additional functional requirements defined212fiLearning Membership Functions Object Recognitionsubcategory. example, histogram straightback chair category representsquality provides back support portion straightback chair examples dataset, overall desired evaluation measures. Recall ranges associatedparent category conventional chair frozen (and presumably accurate)learning begins category straightback chair. So, Omlet uses straightback chairexamples learn ranges associated provides back support functional property.Thus, learning ranges category straightback chair, want observequality back supports training examples. Similarly, want observequality arm supports armchair examples, overall desired evaluationmeasures.A) Effect Training Time GRUFF ObjectsB) Effect Training Time Synthetic CupsTraining 77 GRUFFLabeled Conventional ChairsTraining 200Synthetic CupsTraining 27 GRUFFLabeled Straightback ChairsC) Effect Training Time Real ObjectsTraining 36 HumanLabeled Conventional ChairsTraining 21 HumanLabeled Straightback ChairsFigure 12: Average training sample error versus number training epochs A) Gruffchair objects, B) synthetic cups, C) real chair objects. plotssingle leave-one-out test run.Figure 12 shows examples average training sample error plotted functionnumber training epochs three data sets (Gruff objects, syntheticcups, real objects). plots, see 1000 training epochssucient categories three data sets. Training could likely213fiWoods, Cook, Hall, Bowyer, & Starkstopped 400 epochs categories without degradation systemperformance. Since number training epochs categories,shown sucient, eliminate factor possible cause differentlevels performance among categories. experiments addition describedSection 5 run examine effect performance factors.6.1 Gruff Chair DatabaseFigure 13: Omlet results test samples Gruff chair database.Figure 13 shows plot average error per sample versus training set size examples conventional chair category, separate plot examplesstraightback chair category. Since 28 straightback chair examples, 3 different training set sizes (6,12,18) evaluated addition leave-one-out testing.78 conventional chair examples used train ranges associated conventional chair category ranges straightback chair category trained.testing done subcategory armchair since four training samplesavailable. plot shows increasing number training samples generally leadsreduction average error. 20 training examples used,actual evaluation measures test examples within approximately 1% desiredevaluation measures conventional chair straightback chair categories.note errors overall evaluation measures found categoriesdifferent learning levels directly comparable. So, plot error ratestraightback chair category directly comparable plot conventionalchair category (Figure 13). example, consider object desired overall evaluation measure 0.85 category conventional chair. Omlet computes actual214fiLearning Membership Functions Object Recognitionevaluation measure 0.86, error example 0.01. Let's assume provides back support portion object desired evaluation measure 0.75.overall desired evaluation measure example category straightback chair would0.9625 (Por 0.85 0.75). Now, suppose Omlet finds actual evaluation measure back support object 0.76, error 0.01. case,actual overall evaluation measure example category straightback chair would0.9664 (Por 0.86 0.76). result, error 0.01 attributed provides back support portion object manifested much smaller error 0.0039overall evaluation measure object.original range parameters (z 1,n1,n2,z 2) hand-crafted expert threeranges conventional chair definition (see Figure 4) are:AREA (0.057599 0.135 0.22 0.546699)CONTIGUOUS SURFACE (0.0 1.0 1.0 1.0)HEIGHT (0.275 0.4 0.6 1.1)range values used Gruff determine desired evaluation measuresgoals provided Omlet. typical example range parameters learnedOmlet is:AREA (0.057599 0.135002 0.219992 0.546706)CONTIGUOUS SURFACE (7.45591e-06 0.999995 10000 10000)HEIGHT (0.275 0.400002 0.6 1.10009)Omlet able determine CONTIGUOUS SURFACE range one-leggedmembership function, n2 z 2 values (i.e., leg exist) setarbitrarily large values. results show Omlet system capable usinglabeled examples automatically determine range parameters similarwould hand-crafted expert. facilitate constructionobject category definitions.Figure 13, see number training samples indeed affecterror rate test samples. 20 training samples, error ratesconventional chair straightback chair categories begin level off. So,number training samples becomes less factor affecting system performancesucient number used. constitutes sucient number training samplescategory may depend number ranges learned quality trainingdata. 3 ranges must learned category conventional chair, 5ranges must learned category straightback chair. histograms desiredevaluation measures Gruff conventional chairs back supports Gruffstraightback chairs Figure 11 B, respectively, ect quality trainingdata used leave-one-out tests.isolate effect quality training data additional experiments utilizing two separate data sets Gruff conventional chair examples. number215fiWoods, Cook, Hall, Bowyer, & Starktraining epochs, number training samples, number ranges learnedidentical data set. One data set 38 \bad" examples contains conventional chair examples desired evaluation measures less 0.6. second data set\good" examples created selecting 38 remaining conventional chair examples.histograms desired evaluation measures examples used \good"\bad" data sets shown Figure 11 C D, respectively. Leave-one-out testing (37training examples) resulted average error 0.0001 examples \good"data set, 0.1869 examples \bad" data set. Thus, would seemquality training data considerable effect performance learningalgorithm.Using set 38 \good" conventional chair examples train Omlet, averageerror found using 38 \bad" examples test drops 0.013 (compared averageerror 0.1869 37 \bad" examples used train). closer examinationresults reveals one \bad" example contributes relatively high error 0.5average. single example excluded test results, average errorremaining 37 \bad" examples 0.00067. 38 \bad" examples used trainOmlet, average error found using 38 \good" examples test 0.242.results indicate Omlet inherently biased produce accurate test results\good" examples since able achieve low error rate \bad" examples\good" training data used. Rather, results emphasize importancecontrolling quality data used train Omlet.6.2 Synthetic Cups DatabaseFigure 14: Omlet results test samples Gruff cup database.216fiLearning Membership Functions Object RecognitionFigure 14 shows plot average error per sample versus training set size examplesrandomly generated cup category. before, Omlet's performance generallyimproves number training samples increased. comparison error plotsconventional chair data cup data reveals average errorcups higher number training samples, error rate decreaseserratically. comparison error rates two categories valid sincelevel learning hierarchy. before, two performancefactors could cause different error rates. considerablyranges need learned cup category Gruff conventional chaircategory (17 versus 3). Also, Figure 15 A, see data set createdcup generator program poor quality. Thus, due random nature syntheticcup generator program, system trained shapes that, average,good examples cups. Regardless poor training data, 150 trainingsamples used, actual evaluation measures cup test examples withinapproximately 4% desired evaluation measures. light \bad" set shapesused training examples large number ranges must learned, higheraverage error cups seems reasonable.Figure 15: Histograms desired evaluation measures synthetic cup training sets.additional test, generated set 78 synthetic cups manner(see Section 5.2). However, required distribution desired evaluationmeasures synthetic cups similar distribution Gruff conventionalchair examples (shown Figure 11 A). Figure 15 B shows histogram desired evaluation measures examples second synthetic cup data set. Since numbertraining epochs, number training examples, quality training datafirst test using Gruff conventional chair examples, experimentisolates effect number ranges must learned. Performing leave-one-outtest (77 training examples), average error per sample found approximately0.08. Figure 13, leave-one-out results 78 Gruff conventional chair examples217fiWoods, Cook, Hall, Bowyer, & Stark(Sub)CategoryConventionalChairStraightbackChairArmchairNumberAverage Desired Average ErrorTraining Samples Evaluation Measure per Sample360.84470.0715373210.99270.0066456110.99730.0022430Table 1: Leave-one-out test results real-object database evaluation measures derived human ratings objects.show average error less 0.01 per sample. Thus, would seem numberranges learned affects system performance considerably.Finally, created set 200 synthetic cups similar distribution Gruffconventional chair examples. histogram desired evaluation measures examplesthird synthetic cup data set would look similar histograms Figure 11 A,Figure 15 B. Performing leave-one-out test (199 training examples), average error persample found approximately 0.023. Compared error rate original 200synthetic cups (approximately 0.04), note \better" training data improvedsystem performance considerably. Compared error rate 78 synthetic cup dataset (approximately 0.08), similar quality, see increased number trainingsamples significantly improved system performance. error rate third syntheticcup data set 200 examples still higher error rate Gruff data set78 conventional chair objects (less 0.01), similar quality distribution.Consider Gruff data set used 77 training examples learn 3 rangesconventional chair category, synthetic cup data set, used 199 trainingexamples learn 17 ranges cup category.6.3 Chair Database Human EvaluationLeave-one-out test results real-object database evaluation measures derivedhuman ratings objects listed Table 1. Recall error ratesdirectly comparable among three categories. actual evaluation measuresconventional chairs objects within approximately 7% human evaluation measures.average error 6% greater average error Gruff datasimilar number training samples. histogram Figure 16 shows data setreal conventional chair objects contains mostly \good" examples. Thus, higher averageerror probably attributed \noise" associated real-object evaluationmeasures. Considering average standard deviation 12% human evaluationsconventional chair objects, 7% average error per sample Omlet resultsseem unreasonable. actual evaluation measures real-object straightback chairsarmchairs differ average less 1% desired measures. before,conventional chair examples used train ranges associated conventional218fiLearning Membership Functions Object Recognitionchair category ranges straightback chair category trained.histograms desired evaluation measures back support real straightbackchair objects arm support real armchair objects shown Figure 16 BC, respectively.Figure 16: Histograms desired evaluation measures real-object training sets.7. Summary Discussionpresented system (Omlet) uses labeled training examples learn fuzzymembership functions embedded function-based object recognition system. fuzzymembership functions used provide evaluation measures determine wellshape fits functional description object category. Omlet system exampleusing machine learning techniques aid development computer vision system.shown possible accurately automatically learn system parameterswould otherwise provided human expert. Omlet may used aidconstruction object categories Gruff object recognition system.expert need concentrate \hand-tweaking" range parameters improvesystem performance, rather providing good set example objects \show"Omlet. intuitively appealing deriving descriptions objects would219fiWoods, Cook, Hall, Bowyer, & Starklike Gruff recognize providing examples object category. Additionally,able demonstrate performance learning algorithm affectednumber quality training examples.possible learning approach described paper appliedsystems measurements (or values) combined tree structure.cases covered approach, except case 2 leaves leading directly Pornode. However, generalization method treating Por nodes may developedhandle situation. tree structure CV system composed entirelyprobabilistic probabilistic nodes, used combine measurements.possible similar approach applicable tree structures typesnodes (T-norms T-conorms) used.Omlet system make easier adapt Gruff system new objectdomains. Early versions Gruff performed object recognition starting complete3-D shape descriptions (Stark & Bowyer, 1991, 1994; Sutton et al., 1993) ratherreal sensory data. task reliably extracting accurate object shape descriptionsnormal intensity images beyond current state art computer vision. Althoughwork in, example, binocular stereo, steadily progressing, accurate models objectshape readily extracted range imagery. Whereas normal imagery pixelvalue represents intensity ected light, range imagery pixel value representsdistance point scene. version Gruff developed attemptsrecognize object functionality shape model extracted single rangeimage (Stark, Hoover, Goldgof, & Bowyer, 1993b). major diculty is, course,single range image yield complete model 3-D shape object.\back half" object shape unseen (Hoover, Goldgof, & Bowyer, 1995).accumulation complete 3-D shape model sequence range images topiccurrent research. problem solved, conceivable Omlet trainingexample might consist sequence range images along operator annotationsidentify portions images correspond functionally important partsobject (seating surface, back support surface, etc.).Acknowledgementsresearch supported Air Force Oce Scientific Research grant F49620-92-J0223 National Science Foundation grant IRI-91-20895.ReferencesBerenji, H., & Khedkar, P. (1992). \Learning Tuning Fuzzy Logic ControllersReinforcements". IEEE Transactions Neural Networks, 3, 724{740.Bogoni, L., & Bajcsy (1993). \An Active Approach Characterization RecognitionFunctionality Functional Properties". AAAI-93 Workshop ReasoningFunction, pp. 201{202 Washington, D.C.220fiLearning Membership Functions Object RecognitionBonissone, P. P., & Decker, K. S. (1986). \Selecting Uncertainty Calculi Granularity:Experiment Trading-off Precision Complexity". Kanal, L., & Lemmer, J.(Eds.), Uncertainty Artificial Intelligence, pp. 217{247. North-Holland PublishingCompany.Brand, M. (1993). \Vision Systems See Terms Function". AAAI-93 WorkshopReasoning Function, pp. 17{22 Washington, D.C.Cooper, G., & Herskovits, E. (1992). \A Bayesian Method Induction ProbabalisticNetworks Data". Machine Learning, 9, 309{347.Di Manzo, M., Trucco, E., Giunchiglia, F., & Ricci, F. (1989). \FUR: UnderstandingFUnctional Reasoning". International Journal Intelligent Systems, 4, 431{457.Hoover, A., Goldgof, D., & Bowyer, K. (1995). Extracting valid boundary representationsegmented range image. IEEE Transactions Pattern Analysis MachineIntelligence. Accepted appear.Ishibuchi, H., Nozaki, K., & Yamamoto, N. (1993). \Selecting Fuzzy Rules GeneticAlgorithm Classification Problems". 2nd IEEE International ConferenceFuzzy Systems, pp. 1119{1124.Jang, J. S. R. (1993). \ANFIS: Adaptive-Network-based Fuzzy Inference Systems". IEEETransactions Systems, Man Cybernetics, 23 (3), 665{685.Jang, J. S. R., & Sun, C. T. (1995). \Neuro-Fuzzy Modeling Control". ProceedingsIEEE, 378{406.Kise, K., Hattori, H., Kitahashi, T., & Fukunaga, K. (1993). \Representing RecognizingSimple Hand-tools Based Functions". Asian Conference ComputerVision, pp. 656{659 Osaka, Japan.Lehn, K. V. (1990). Mind Bugs: Origins Procedural Misconceptions. MIT Press,Cambridge, Massachusetts.Mahadevan, S., & Connell, J. (1991). \Automatic Programming Behavoir-Based RobotsUsing Reinforcement Learning". AAAI, pp. 768{773.Michalski, R. S. (1983). \A theory methodology inductive learning". Michalski,R. S., Carbonell, J. G., & Mitchell, T. M. (Eds.), Machine Learning: ArtificialIntelligence Approach. Tioga Publishing Company, Palo Alto, CA.Mitchell, T. M., Keller, R. M., & Kedar-Cabelli, S. T. (1986). \Explanation-Based Generalization: Unifying View". Machine Learning, 1, 47{80.Parido, A., & Bonelli, P. (1993). \A New Approach Fuzzy Classifier Systems".Proceedings Fifth International Conference Genetic Algorithms, pp. 223{230.Pearl, J. (1988). Probabilistic Reasoning Intelligent Systems: Networks PlausibleInference. Morgan Kaufmann.221fiWoods, Cook, Hall, Bowyer, & StarkQuinlan, J. R. (1992). C4.5: Programs Machine Learning. Morgan Kaufmann.Rivlin, E., Rosenfeld, A., & Perlis, D. (1993). \Recognition Object FunctionalityGoal-Directed Robotics". AAAI-93 Workshop Reasoning Function, pp.126{130 Washington, D.C.Spiegelhalter, D., Dawid, P., Lauritzen, S., & Cowell, R. (1993). \Bayesian AnalysisExpert Systems". Statistical Science, 8, 219{282.Stark, L., & Bowyer, K. W. (1991). \Achieving generalized object recognitionreasoning association function structure". IEEE Transactions PatternAnalysis Machine Intelligence, 3 (10), 1097{1104.Stark, L., & Bowyer, K. W. (1994). \Function-based recognition multiple object categories". Image Understanding, 59 (10), 1{21.Stark, L., Hall, L. O., & Bowyer, K. W. (1993a). \An investigation methods combiningfunctional evidence 3-D object recognition". Int. J. Pattern RecognitionArtificial Intelligence, 7 (3), 573{594.Stark, L., Hoover, A. W., Goldgof, D. B., & Bowyer, K. W. (1993b). \Function-basedrecognition incomplete knowledge shape". IEEE Workshop QualitativeVision, pp. 11{22 New York, New York.Sutton, M., Stark, L., & Bowyer, K. W. (1993). \Function-based generic recognitionmultiple object categories". Jain, A. K., & Flynn, P. J. (Eds.), Three-dimensionalObject Recognition Systems, pp. 447{470. Elsevier Science Publishers.Vaina, L., & Jaulent, M. (1991). \Object structure action requirements: compatibilitymodel functional recognition". Int. J. Intelligent Systems, 6, 313{336.Valenzuela-Rendon, M. (1991). \The Fuzzy Classifier System: Classifier System Continuously Varying Variables". Proceedings Fourth International ConferenceGenetic Algorithms, pp. 346{353.Watkins, C. J. (1989). Models Delayed Reinforcement Learning. Ph.D. thesis, CambridgeUniversity.Winston, P. H., Binford, T. O., Katz, B., & Lowry, M. (1983). \Learning physical descriptions functional definitions, examples, precedents". National ConferenceArtificial Intelligence, 433{439.222fiJournal Artificial Intelligence Research 3 (1995) 373-382Submitted 7/95; published 12/95Statistical Feature CombinationEvaluation Game PositionsMichael BuroNEC Research Institute4 Independence WayPrinceton NJ 08540 U.S.A.mic@research.nj.nec.comAbstractarticle describes application three well{known statistical methods fieldgame{tree search: using large number classified Othello positions, feature weightsevaluation functions game{phase{independent meaning estimated meanslogistic regression, Fisher's linear discriminant, quadratic discriminant functionnormally distributed features. Thereafter, playing strengths compared meanstournaments resulting versions world{class Othello program.application, logistic regression | used first time context gameplaying | leads better results approaches.1. IntroductionPrograms playing games like chess, draughts, Othello use evaluation functions estimateplayers' winning chances positions leaves game{trees. valuespropagated root according NegaMax principle order choose moveroot position leads highest score. Normally, evaluation functions combinefeatures measure properties position correlated winning chance,material chess mobility Othello. popular quickly computable linear featurecombinations. early days game programming, feature weights chosenintuitively improved manual hill{climbing process programmer's patiencegave out. technique laborious. Samuel (1959,1967) first describe methodautomatic improvement evaluation function parameters. Since many approachesinvestigated. Two main strategies distinguished:Move adaptation: Evaluation function parameters tuned maximize frequencysearches yield moves occur lists moves belonging trainingpositions. idea get program mimic experts' moves.Value adaptation: Given set labelled example positions, parameters determinedevaluation function fits specific model. instance, evaluation functionsconstructed way predict final game result.move adaptation, proposed instance Marsland (1985), v.d. Meulen (1989),Mysliwietz (1994), linear feature combination two degrees freedom: multiplied positive constant constant added without changing movedecision. evaluation function depends game phase, positions differentphases compared (for example within framework selective extensions openingbook play), constants must chosen suitably. evaluation functions optimizedc 1995 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiBuromove adaptation moment global interpretation, solution problemobvious. Schaeffer et al. (1992) presented ad hoc game{specific approach.respect, value adaptation promising. Here, evaluations differentphases comparable example position labels phase{independent meaning.Mitchell (1984) labelled Othello positions occurring game final game resultform disc differential tried approximate values using linearcombination features. Since regression used determine weights, alsopossible investigate features' statistical relevance. Another statistical approachvalue adaptation used Lee & Mahajan (1988): example positions classifiedwin loss side move | assuming features multivariate normal |quadratic discriminant function used predict winning probability. techniqueensures desired comparability applies also games without win degrees, i.e.know wins, draws, losses.Besides classical approaches heavily rely given feature sets, recentyears artificial neural networks (ANNs) trained evaluating game positions.instance, Moriarty & Miikkulainen (1993) used genetic algorithms evolve topologyweights ANNs order learn Othello concepts means tournamentsfixed programs. discovering concept mobility, best 1{ply ANN{playerable win 70% games 3{ply brute{force program used evaluationfunction without mobility features. important contribution fieldTesauro (1992,1994,1995). Using temporal difference learning (Sutton, 1988) updatingweights, ANNs learned evaluate backgammon positions master level meansself{play. Tesauro conjectured stochastic nature backgammon responsiblesuccess approach. Though several researchers obtained encouraging preliminaryresults applying Tesauro's learning procedure deterministic games, work yetled strong tournament programs tactical games Awari, draughts, Othello,chess, allow deep searches powerful quickly computable evaluationfunctions known. might due tactics games knowledgeableslower evaluation functions necessarily accurate relatively simplefaster evaluation functions conjunction deeper searches.follows, three well{known statistical models | namely quadratic discrimination function normally distributed features, Fisher's linear discriminant, logisticregression | described evaluation game positions context valueadaptation. Thereafter, shown example positions parameter estimationgenerated. Finally, playing strengths three versions world{class Othello program1| LOGISTELLO | equipped resulting evaluation functions compared orderdetermine strongest tournament player. turns quadratic feature combinations necessarily lead stronger programs linear combinations, logisticregression gives best results application.2. Statistical Feature Combinationformal basis statistical feature combination position evaluation statedfollows:1. Since appearance October 1993 twelve 14 international tournaments played.374fiStatistical Feature Combinationset positions evaluate.:! fL; Wg classifies positions loss win player move,assuming optimal play sides. Draws handled manneroutlined Section 4.X1; : : :; X :! IR features.evaluation position ! 2x = (X1; : : :; X )(!) conditional winning probabilitynnV ( ! ) = P (Y= W j (X1; : : :; X ) = x) =: P (W j x):nN classified example positions !1; : : :; ! 2availableNx = (X1; : : :; X )(! ) = (! ).nfollowing subsections models express P (W j x) function linear quadratic feature combinations brie introduced way sucient practicalpurposes. Good introductions theoretical details given instance Duda& Hart (1973), Hand (1981), Agresti (1990), McCullagh & Nelder (1989). Fisher'sclassical method logistic regression used model P (W j x) first time;quadratic discriminant function used Lee & Mahajan (1988), however, withoutconsidering Fisher's discriminant first.2.1 Discriminant Functions Normally Distributed FeaturesBayes' rule givesj W )P (W )= p(x j pW(x))P (W ) = p(x j W p)P(x(W) + p(x j L)P (L),1= 1 + pp((xxj jWL))PP ((LW)) ;p(x j C ) features' conditional density function P (C ) priori probabilityclass C 2 fL; Wg. case priori probablities equal, featuresmultivariate normally distributed within class, i.e.P (W j x )p(x j C ) = (2 ), 2j j,1 2 expn=C=n, 21 (x , ),1(x , )0CCCmean vector covariance matrix C 2 fW ; Lg, follows1P (W j x) =;1 + exp(,f (x))f following quadratic discriminant function:Cf (x)Cn= , 21 x ,W1 , ,L 1 x0 + L ,L 1 , W ,W1 x0 +1 ,1 0 , ,1 0 + log jW j , log jL j :WWLLWL2375fiBuro1.0................................................................................................................................................................................................................................................................... ................ ...... .................................................................................... ......... .............................................................................................................................................................................................................................................................................................................................................................................................................................................................................0.50.0LxWFigure 1: Conditional densities winning probabilitycovariance matrices equal (=), expression simplified linear function:f (x) = (W , L ),1 fx , (L + W )=2g0:Interestingly, function also solution problem finding linear transformationmaximizes ratio squared sample mean distance sum within{classsample variances transformation. Therefore, good separator properties evenfeatures normally distributed. called Fisher's linear discriminant. Figure 1illustrates relation conditional densities winning probability.maximum likelihood (ML) parameter estimates1 Xx^ =CjI jC^ = jI1 j2CXCC2C(x , ^ )0(x , ^ )CC= fi j = C g. covariance matrices equal,X X^ = jI j 1+ jI j(x , ^ )0(x , ^ ):WL 2fL Wg 2 CCC;CC2.2 Logistic Regressionlogistic regression conditional winning probability P (W j x) depends linearcombination x . Here, X1 1 assumed order able model constant offsets.simple approach P (W j x) = xfi using parameter column vector fi unusablexfi 2 [0;1] cannot guaranteed generally. requirement fulfilled meanslink{function g : (0;1) ! IR according g (P (W j x)) = xfi . Figure 2 shows typicalnonlinear relation winning probability one feature. Since probabilityusually monotone increasing function features, g satisfy lim !0+ g (x) = ,1lim !1, g (x) = +1. link{function g (t) = logit(t) := log(t=(1 , t))properties. Using g = logit, since g ,1(x) = f1 + exp(,x)g,1 , follows1P (W j x) =1 + exp(,xfi ) :xx376fiStatistical Feature CombinationHence, winning probability shape discriminant analysis. logisticregression require features multivariate normal; even usediscrete features possible.parameter vector fi estimated using ML approach. Unfortunately,case necessary solve system nonlinear equations. follows, knownsolving approach brie described (cf. Agresti, 1990; McCullagh & Nelder, 1989).order ensure convergence iterative algorithm given below, necessaryslightlyvariableP generalize model: observed value random,1=,:!f0;1gmean=f1+exp(,xfi)g=1stochastically independent. definition includes old model (n = 1 2 f0; 1g).likelihood function L(fi), probability density, measures likelysee realization stochastically independent random variables , fi trueparameter vector. order maximize L, suces consider log(L):nji;ji;jlog(L(fi)) = logN=1XX=nj=1(1 , )ni ,yiN=1yxijfi,jXN=1XN=h=1log + (n , ) log(1 , )log 1 + expnXnj=1x fiijj:function twice differentiable, strictly concave rare border cases,unique maximum location 0 < < n (cf. Wedderburn, 1976)iteratively found using Newton{Raphson method follows:( +1)fi^= (X 0( )X ),1 X 0( ) z ( )(N n){matrix X built x ,( ) = diag[n ^ ( )(1 , ^( ))]; ^( ) = 1 + exp ,nnj^ ( ), n ^ ( )()z = log+:1 , ^ ( ) n ^ ( )(1 , ^ ( ))=1x fi^( )ijo,1jX1.0P (W j x) 0.50.0...............................................................................................................................................................................................................................................................................................................................................xFigure 2: Typical shape winning probability377;fiBuroStarting ^ (0) = (y +1=2)=(n +1), ML estimate fi^ may usually computed highaccuracy within steps since method quadratically convergent relatively robustrespect choice starting vector. Unfortunately, = 0= n estimates might converge. original model approximated,instance, setting n = 100 = 1 99, depending whether positionquestion lost won.3. Generation Classification Example PositionsValue adaptation requires labelled example positions. Here, problems arise. Firstall, nontrivial games endgame positions classified correctly won,drawn, lost; opening midgame positions optimal play reach duelack game knowledge time constraints. Furthermore, example positionscontain significant feature variance since otherwise discrimination possible. Hence,problematic use high level games | might first idea | since goodplayers programs know relevant features try maximize game.Therefore, features tend constant time statistical methods wouldassign small weights them. final diculty, estimating parameters accuratelydifferent game phases requires many positions.pragmatic \solution" problems indicated Figure 3: periodtwo years, 60,000 Othello games2 played early versions LOGISTELLO- urd-anovic's program REV.3 Feature variance ensured examining openingsIgorlength seven led mostly unbalanced starting positions. Since early programversions used 5{10 minutes thinking time, games, though wellplayed time, error free. cases even big mistakes occurredwhich, example, one side fell corner losing trap4 caused lack look{ahead.without errors, reasonable weight estimation principal features (such cornerpossession Othello) possible explained above. Following Lee & Mahajan (1988),positions classified final game results. approach problematicclassification reliability decreases endgame opening phase due playermistakes. reduce effect, early outcome searches performed solving Othellopositions 20 moves game end. Furthermore, time time game databasesearched \obvious" errors using new program versions longer searches correctgames. Since process many lines play repeated, misclassificationrate reduced propagating game results leaves rootgame{tree, built games according NegaMax principle.way classification position depends examined successorstherefore reliable.proposed classification method relatively fast allows us label many positionsreasonable time (on average 42 new positions 10{20 minutes). addition2. game file obtained via anonymous ftp.(ftp.uni-paderborn.de/unix/othello/misc/database.zip)3. brief description programs given help pages Internet Othello Server.(telnet faust.uni-paderborn.de 5000)4. implications compared losing material nothing chess.378fiStatistical Feature Combination......................................................................................................................................................................................................................................................................................................................................................................................................................................Database consistingca. 60,000 gamesLWLWW xWx L xD xWx xW x............... ............................................. ............................ .................... ........ ............................ .................................................... ....... .......................... ......................................................................................................................................................................................................................................................................................................................................... ....... ........ ......... .... .....................................Game tree..................................................................................................................................2.5 Millionclassified positionsFigure 3: classification processensuring accurate parameter estimation even different game phases (which indicatedsmall parameter confidence intervals), method enabled us develop new patternfeatures Othello based estimating winning probability conditioned upon occurrencesub{configurations, like edge diagonal instances, board.54. Parameter Estimation Playing Strength ComparisonAlthough 5% example positions labelled drawn, decideduse parameter estimation since positions give exact informationfeature balancing. natural way handle drawn positions within statistical evaluationframework considered define winning probability 1=2 case.extension logistic regression parameters easily determined setting = n =2case draw. Alternatively, doubling lost positions incorporating drawnpositions lost leads estimate log likelihoodfunctions equal constant factor. latter technique used fittingmodels.Previous experiments showed parameters depend game phase,disc count adequate measure Othello. example positions grouped according number discs board, adjacent groups used parameterestimation order smooth data ensure almost equal numbers lostpositions.success Othello program BILL described Lee & Mahajan (1990) showsOthello table{based features quite effective. instance, important edgestructure quickly evaluated adding four pre{computed edge evaluationsstored table. 13 features used LOGISTELLO table{based. falltwo groups: first group pattern instances including horizontal, vertical,diagonal lines board evaluated second group two mobility measurescomputed.5parameter estimation three described models, tournaments players QUAD (which uses quadratic discriminant function normally distributed features),5. Details given Buro (1994). postscript file thesis obtained via anonymous ftp.379fiBuroPairingLOG , QUADFISHER , QUADLOG , FISHERLOG , FISHERLOG , QUADFISHER , QUADLOG , QUADTime per gameResultWinning(Minutes)(Win,Draw,Loss) Percentage30 , 3030 , 3030 , 3030 , 3630 , 3830 , 3830 , 45116 , 15 , 69112 , 15 , 7393 , 35 , 7286 , 24 , 9093 , 33 , 7484 , 30 , 8688 , 26 , 8661.8%59.8%55.3%49.0%54.8%49.5%50.5%Table 1: Tournament resultsFISHER, LOG played order determine best tournament player. Starting100 nearly even opening positions 14 discs (i.e. move 11) LOGISTELLO's opening book, game return game colours reversed played.6opening midgame phase program versions performed usual iterative deepening NegaScout searches (Reinefeld, 1983) selective corner quiescence search extension.Endgame positions 22 empty squares solved win{draw{loss searches.pattern learning tournaments, facility think opponent's time turned order speed tournaments run parallelseven SUN SPARC{10 workstations.Applying conservative statistical test5 seen results listed Table 1stating winning percentage greater 59% statistically significant 5% level.first two results show clear advantage linear combinations normal tournamentconditions (30 minutes per player per game). Furthermore, since LOG outperforms FISHERfeatures would seem even approximately normally distributed. liesadvantage logistic regression: even discrete features like castling status chessparity Othello used.tournaments played time weaker players FISHERQUAD order determine time factors lead equal playing strength.shown Table 1 FISHER reaches LOG's strength given 20% time,QUAD needs 50% time compete LOG. LOGISTELLO's optimizedimplementation, search speed using quadratic combination still 20%slower linear combination. Thus, giving QUAD 25% time (1=(1 ,0:2) = 1:25) balances total number nodes searched game. eventiming, LOG stronger QUAD, FISHER still compete it. all,quadratic combination slower linear combination, alsobetter discrimination properties. Indeed, look estimated covariance matrices6. LOG's 11{ply evaluation positions lies range [,0:4; +0:4] corresponds winningprobabilities range [0:4; 0:6]. nearly even starting positions used compareprograms similar playing strength since clear positions colour determines winnerwinning percentage would 50% even one player stronger. 100 starting positions sixalways led game pairs balanced score.380fiStatistical Feature Combinationclass revealed almost equal, therefore better evaluation qualityFisher's linear discriminant could expected.5. Discussionpaper three statistical approaches modelling evaluation functions game{phase{independent meaning presented compared empirically using world{class Othello program. Quadratic feature combinations necessarily lead strongerprograms linear combinations since evaluation speed drop significantly.course, effect depends number features used evaluation speed:features used takes long time evaluate them, playing strengthdifferences cannot explained different speeds case evaluation timesalmost equal. case, using quadratic combinations covariance matricescompared; (almost) equal, quadratic terms omittedFisher's linear discriminant used. Therefore, motivations Lee & Mahajan (1988)need refinement, since existing feature correlation necessarily justify usenonlinear combinations. Generally, possibly accurate nonlinear feature combinations(such ANNs) compared simpler faster approaches practice, sinceuse always guarantee greater playing strength.Besides linear regression discriminant analysis, logistic regression provensuitable tool construction evaluation functions global interpretation.drawback, parameter estimation system nonlinear equations solved,compensated higher quality evaluation function comparisonapproaches, since application parameters determinedonce. current tournament version LOGISTELLO uses feature weights estimatedmeans logistic regression profits comparability evaluations differentgame phases ensured use value adaptation. result possibleperform selective searches values different game phases compared;moreover, values opening compared even late midgame values orderfind promising move alternatives program's opening book (Buro 1994,1995).sense, value comparability cornerstone LOGISTELLO's strength.Acknowledgementswish thank wife Karen competently answering many statistical questions.- urd-anovic many fruitful discussions ledalso thank colleague Igorconsiderable improvements Othello programs. Furthermore, grateful ColinSpringer, Richard E. Korf, anonymous referees useful suggestions earlierversions paper, helped improve presentation contents.ReferencesAgresti, A. (1990). Categorical Data Analysis. Wiley.Buro, M. (1994). Techniken fur die Bewertung von Spielsituationen anhand von Beispielen.Ph.D. thesis, University Paderborn, Germany.(ftp.uni-paderborn.de/unix/othello/ps-files/mics_dis.ps.gz)381fiBuroBuro, M. (1995). L'apprentissage des ouvertures chez Logistello. Magazine de la FederationFrancaise d'Othello FFORUM 37, 18{20.Duda, R., Hart, P. (1973). Pattern Classification Scene Analysis. Wiley.Hand, D.J. (1981). Discrimination Classification. Wiley.Lee, K.F., Mahajan, S. (1988). Pattern Classification Approach Evaluation FunctionLearning. Artificial Intelligence 36, 1{25.Lee, K.F., Mahajan, S. (1990). Development World Class Othello Program. ArtificialIntelligence 43, 21{36.Marsland, T.A. (1985). Evaluation Function Factors. ICCA Journal 8(2).McCullagh, P., Nelder, J.A. (1989). Generalized Linear Models. Chapman & Hall.van den Meulen, M. (1989). Weight Assesment Evaluation Functions. In: D.F. Beal(Editor), Advances Computer Chess 5, Elsevier Science Publishers.Mitchell, D.H. (1984). Using Features Evaluate Positions Experts' Novices' OthelloGames. Master Thesis, Northwestern University, Evanston Illinois U.S.A.Moriarty, D., Miikkulainen, R. (1993). Evolving Complex Othello Strategies Using Marker{Based Genetic Encoding Neural Networks. Tech. rep. AI93{206, DepartmentComputer Sciences, University Texas Austin.Mysliwietz, P. (1994). Konstruktion und Optimierung von Bewertungsfunktionen beimSchach. Ph.D. thesis, University Paderborn, Germany.Reinefeld, A. (1983). Improvement Scout Tree Search Algorithm. ICCA Journal6(4), 4{14.Samuel, A.L. (1959). Studies Machine Learning Using Game Checkers. IBMJournal Research Development 3, 210{229.Samuel, A.L. (1967). Studies Machine Learning Using Game Checkers II.IBM Journal Research Development 11, 601{617.Schaeffer, J., Culberson, J., Treloar, N., Knight, B., Lu, P., Szafron, D. (1992). WorldChampionship Caliber Checkers Program. Artificial Intelligence 53, 273{289.Sutton, R.S. (1988). Learning Predict Methods Temporal Differences. MachineLearning 3, 9{44.Tesauro, G. (1992). Practical Issues Temporal Difference Learning. Machine Learning 8,257{277.Tesauro, G. (1994). TD{Gammon, Self{Teaching Backgammon Program, AchievesMaster{Level Play. Neural Computation 6, 215{219.Tesauro, G. (1995). Temporal Difference Learning TD{Gammon. CommunicationsACM 38(3), 58{68.Wedderburn, R.W.M. (1976). Existence Uniqueness Maximum LikelihoodEstimates Certain Generalized Linear Models. Biometrika 63, 27{32.382fiff fi"!$#&%'(()*+,(.-+0/1<>=?A@CBD=EGFHEJILKMEGFONQP&RSNUTJFCV=Fa`2345$68739()3:;4!6&'19(3)KMWQPXVY=N[Z\FCIEJW^]_TXN^=EGFTbWQcJE&de=TJFf`jSkmlonQprqtsguvrwmxkEgVePihByz {|}~Qb}~8 X~{zb&Xr 3.. br$$Q Xr"Jqkmk8qlokQvQx~~\b~8 }{| {}} }b Xr3Ori0Jbr 3..^33YGS3833Or$ 0Q " X "$beg$ e X0 $C 0 ^J Xbb3 Q $ Q gDg X >0goC800 0S0 b U03$e0 bCQO Sff fi0^8 [8 Sm g0 8 0e$ X"gC0S JS 00S ff$ ^ 8 JJ3O ^S$ g33 $ $ $!#"%$&'!(*),+.-0/21ff3545+768/21ff9):0;<:0=>+.:@?1ff3AB+0)97/*CB+0397;<:04Dff9:E-B14;2=.:0;GFHDff9:I?/2JLK0;M:0CB1ff),1NCL-J>?OK01PAB) 1N4Q1ff:0DN1+765/+0:0=7R'?1ff)3SCB1ffAT1ff:0CB1ff:0DN;1N4U;M:V?WK01X?W)9Y;M:0;<:0=ZCH97?W9B[]\^41N_B`01ff:0DN1>+76)9:0CB+.3Sa79) ;<9-0/21N4Lbc1[d=H[fe9g41N_h`01ff:0DN15+76*+0-041ff) ai9Y?;2+.:045jffkkknkpo#q.erCB1ff:0+?1NCsk;244W9Y;CX?+g1NuhK0;<-0;2?v/2+.:0=7R'?Q1ff)3'Nl +7lmffmlffmmffm'HtCB1ffAB1ff:0CB1ff:0DN;21N4;G6w?WK01xai9) ;<9-0/21N4%k n 97?y9z=I;aI1ff:v?Q;M3{1}|~9) 1*4Q;=0:0;FHDff9I:?/2JCB1ffAT1ff:0CB1ff:?%+.:?WK01xai9),;M9I-0/1N4k n<97?35`0DNK>1ff9),/;21ff)5?Q;M3{1N4||W[X':U?WK01N41Dff9741N4ffe#94QJ.4?Q1ff3?O)97;<:01NC+0:X?WK0;24CH97?W9Ebc1[d=H[fe?+135+0CB1N/x;?Q4CB;24?W) ;<-B`0?;2+.:wex+.)539I71DN/<974Q4;GFHDff97?;2+.:04+.)5AB) 1NCB;2DN?;2+.:04KB974g?+>-B1s9-0/21?+X4?+0) 16+.)9)-0;2?W)Q9) ;2/2J/2+.:0=vCH`B)9Y?;2+.:04}-0;2?4%+76;M:I6+.)3g97?;2+.:5;<:g;?Q4*4?W9Y?1xai9) ;<9-0/21e0Dff97/2/21NCs n K01ff),1[y:=I1ff:01ff)97/e?WK01 CB;Dff`0/? JZ;4:0+?+0:0/J?Q+) 1ffAB) 1N41ff:I??WK01N41s/2+.:0=YR'?1ff)3^CB1ffAT1ff:0CB1ff:0DN;14ffe-B`0?P9Y/4Q+?+ZOO>9) 1ffAB) 1N4Q1ff:?W9Y?;2+.:X+768AB974?OrNi8K0;2DKU?W971N4?OK01ff3;<:?Q+97DNDN+.`B:I?ff[}Off0W ffrH. #rff#Qffb`B3{1N/MKB9I) ?ffex;<:I?+.:wex;2/2/2;<9354ffeffIB%;2/2/2;<9354sw;<A041ff)NezffIep6+0)v1NuB93A0/21eKB9a19:;<:?Q1ff):B97/~4?W97?19:0CX9) ;2DNK1NuBAB) 1N44;2a15AB+7x1ff)?OKB97?AB) +7a.;2CB15?WK01ff3;2?WK?WK01:01NDN1N4Q4W9) J/2+.:0=7R'?Q1ff)3351ff35+0) JDff9IAB9-0;2/;2?;21N4ff[\z/2=+.) ;2?WKB3{4*?WKB97?#DN+0`0/C1ODN;21ff:I?/2J/21ff9):5?+v),1ffAB) 1N41ff:I?*/2+.:0=7R'?1ff)Q3]DN+.:I?1Nu0?#}+0`0/C-B1z`041O6`0/r;<:39:IJ9) 1ff974x+76\) ?;GFHDN;<97/:?1N/2/2;2=1ff:0DN1[xH+0)#1NuB93A0/21eB?WK01NJ5DN+.`0/2Cs-B1v9IABA0/;21NC ?+39I:JAB) +.-0/21ff354;<:L:B97?O`B)97/x/<9:0=.`B97=1sAB),+.DN1N44Q;M:0=re-B+?WK9Y??OK014Jh35-T+/2;D /21Na1N/{b1[d=H[<e~/21ff9):0;<:0=E=.)933g9) 49:0C/<9:0=.`B97=I135+0CB1N/244JB:?OK01N4;24[ew9:0Cs4W`B-04QJh35-B+I/;2D/21Na1N/bc1[d=r[<eH35+0CB1N/2;M:0=sAB),+4+0CBJ6+.)4WAB1N1NDNKX) 1NDN+=.:0;2?;2+.:+.):+.) CB1ff)x?Q+?O)97;<:?WK01/21ff9):0;<:0=4J.4Q?1ff3eBK0+7}1NaI1ff)NeB9:1O1NDN?;2a1v351NDNKB9:0;24W3+Y6Dff) 1NCB;2?9Y44;2=.:IR351ff:I?8?OKB) +.`0=.K?;<3515;4v:01N1NCB1NC[+DKB9I:0=1v?WK01AB9)Q9351N?1ff) 4+76*?WK0154J04?1ff3;M: +.),CB1ff)?+DNKB9:0=1?WK01x;<:?Q1ff):B97/H4Q?W97?1%+76?WK01x4J04?1ff3]9Y?#?;<351|WeI4+v974#?+;<3AB) +7a1N?OK01};<:I?1ff):B97/r4?W97?Q1*+76w?WK01x4J.4Q?1ff3'((3)QfifiB6 Q 6%X0 #r 3ff5$ #4!'fi!3c67gfi#HrUBHOBBB<7ff<W0Nh0ff0Nw00vff NffB 2N2B,.B7.7Qff NB28.ff 0x<I.Q72. B7I B<Z<5Lr.gNhg0xO0xB'>N2N72. 2WB.XXxB}~NW,000N8>N2ff%ffTwN.<00wy0<0ffN#0.0H0xffz0>O0{BYYB .B7072. WB .00X<572.,OB. NffB ffIv0ffB7x0N }0B5N<B Nv7<*ffI N2X.XW0N>I<07ffB 2.wzB5ff 00v.YBffI 'BNNffIBYN72.,OB5vBBNffEB .BINX.z20M0 W0ff NB287Q2.B5ffIB,.02ff5xM,NffB ffI0N x.IdH<0B5N<B xN7<wffT22<5<0ffN#N#NNQff N0ff B0B0B7NQffYBff022N5<sO7<0<0s NffB ffI0N x.I*5Bff.W7WI*<802NW0zffT.7rN.I<0ff0N2N8B NffIxMO0<BB07.0WB0NB0ff0NNOBE2.0<Iff 772@%ff02Hx0< xQ7N.0zfffiffH%X NffNzffT}x0xffNffff.N%ff02N*78 ffff.B72 0B0W0N. NQffYH ff7.0~.~W02xBff02 {I0B 7NX0N.72 NW025.B5NO 2BBB52ff7Q.Qff5v2WX0.I'2<0ffgW7Q>0N.,'W7NffB,ff0NfiW22vB M0ff,ff7<02Bff0 >WQ7<W0NL70ff2W.YBffIvBNQNff7W0HBQ72.X7W0BffBff0Bff0N2NTffI0WB NEM0ff,ff7Nffs N"!#$%&('*) + 21 g7WI%,&('*-/.) 0ff7QffY}B720257W0B .02ff^O0iWB7ffpBffBff0B<00XW00.43563 7W07.7N00MI7O 28*.0Y8 }N00BQ00 2N<UW0NE.Qff5ff 0ff93:32;IO0BhB{N57W0vYW 27*B <7wBff 2iY2N7#W0W7Q0N0 'W7QzB0N2.wW0v0N x.Y27N2MI0 .,v0Q7#MI.g72.g.02WQ HBY2.0ffBNff2WB0B0BNs<BB0v02H07xNffN0.YBffIO NWBNNzff,.x782ffQM{ffiII2WNBB00ff<722'77x.0vB,.B7.7QN}O0ffB7N <<52<W0W0ffxB0Bz0ff3:3"=I.7B2ffI*ff?>H7LB7N 0B0*W0.Qff]2x2.ff722B0W020ffB0x N2<020 027}<I.7Q0.2.0<55%ff02sNv7 ffff.O0ixN>07O05.B,W02ff0<0sY*007'ffBffBff0Bff0N2NIsB0<0NBB.0ffI<7225. xN0z.O0<@>0ff0N78O0. 'ffQBffTff0Bff0N2Nc<EN.BI 2.UX007'ff^BffTff0Bff0N2NW7ffW0.7B2ffI7}gNx'B0N2. 2WX NWTNN8QWQ7<B02{BI5Nff,ff6A0{IB70N072,NW02B022Ns0.I'2<0ff5BI5Nff B NNEBhB{ffY*0ff5O0>Yv5v NffBQ ff50N }0B0502<0ffvB,.B022Q2s5.BN2W0U7v02BBff>>Yi50BN2PXONCA0N5.BN25WTNNMY*ff757x.BzB N.2.05 NW02v<Xz0NXW0DU0.QE3:63IBNff0gW027O 2GFHI(JK"LfiFMHNOJvYW 2pd<g7W 2QP7xW0QQ0>B .B02222NRPS!#UTVXWY3:80ff O0vWY87 <02[#ffO7]\020B5Bff7y77<0NffUZ'NA0PYMEN0W,MB0Q0E7O0BTff52W0ff O. sI>N0ff02.E7zW0s0N.72s,NW02.B0LE*ff0IUN{YL,fffiff. sO0ff7Q7C^QL@_a`fiIb(NOLcedfI(ghiF#z0NE<0N<0BsWI0HXxBjN7<%ffTwN0<0.ENYf*ffI7vxN2}Yi <7Q00YXXW0U7BB0k <0WB0XX j <XXWs%ff02YN.0fflIBN*0L#,<72m<0Qff i02>77onNN22.V* 0NNN>p<zqnvW0.0B<HffTffTVrB 2WwNZ>\0WB75<Eff0ffY%B0ff005ff0.E78Bs02.7N.QN.0ff NB27Q0B5ff#H0XW0ff 0B2N2 7#W0vWQ022.sB,.B022 X7W 2NNffrBBff,TWO0 ffB NQffWY2.s0 W02ff0<07y2.0Y'ffN.IN0<W0v02BBff WYi,MI0%Os0.5Iff0N.0v0>0.I0.{ff0N.0z>770MIs50BN2 N.02Bff NutvI@dIxw/h,yczhkI{@F80ff 5ff0WBY8W05WQ022.XB .B02222N57*W05>775.BN*I vN.0QWI87ff<5O| ~}vI@c[yK"IdfIaw/hczhkI{@F 5ff0WB7zW0NO022.>B,.B022QN 722ixN>QsBBGcff ffz.ff7NsQM{QffwwdH<w7gB0NQ0sY N0ffB7~<BB0vWB7sBgBff ffIv7ff7N5<5Qffw j gW080.5Iff0N.0*ffYcdr<7W0HI XXWN7W0N50BN2xff52ffgW0B2W <B02.~~7.0OB0#Nh0ff0NNYI{Y0NMY<0v5.0WB0#B2O G( (akzfiaY2:$Ofikx/(( afixOV(x(YOVUx:(fikx' kYO6(OfiOkfi ''-". x( '*-/.[ 'O((fififizaO[qqR[[z"[*[ezfi["aB/fO: x$(fififi" fik"p[Ba(aSafiafi"B$ ]"V"/@"/f@("/"(fiaa"aBaB/G"/"["[Ba["aB/"C@/"[BaB/[fi/[["a["("BfiV"af"[fiaB/"k""C6([["v"G/"["Vx"(""C(afi SQ 2("Bafix/"6 /"""CB(x"?qf"[6fi$"u/"[BaB/[fi[Ba["aB/ fi"B(G["aqaR("a/"["a"("f $"(q[["x"("B$@@(fia["("R/ aaB/q/Sfiaa z(fix"VBo([a (C"/ff@ qk"(afifi"/"[p( [( S[B2( "a a/@["aCVB"[[(a/"V@aV"V/" ~aR["BBQk"MG?/[["$fiBaauaBv[ /[(x"("SO[Ba(fiaB/"q"[(Vx ! "?# "~[Ba/[@aok[ fi"k[V[[fi[([("[]/G"fikaB/fi("~/"a( 8""["Ca["(" ""~aafia [Ba["aB/ $"~afia' af[fik"x"("~fiaB/"(fiC"ok"x"("~fi6[["aa% $x/& (o)fi *Vq v"+ fafB@] k"[(z[fik" vf/"a"Bf"""/@"/?("B& fip" ,fifiR[fi $ k"CBBfiV"zz][fiB"xk"C?Cff [f[ .a~[("af"]a"("u[fi/kB$ka"aBaB/q[/[@"BBaB( [["a" Vq C"fifiaB/"//fi *"p"/fiaB"Ba[a(@aCk"[( [ ["BB("BVaB(a""CfiB/ k[f2 ["( /k"(/afi[B(@[fiaG/"a" fi"0 fiB/B[ ("ax(1YfiY 3f "(fiaB/ fiB/B[f$"BMo # q/G/xfiz[fiB @"QBa(xfiaB 8f"[4 "" /@a/"""fi"[a@fa(O"ofix"aBaB/q[/["BBBaB(/[@afa( $fiVu["x"q/["a"G"a[/[@"BBaB "[(a""af "fB(a""~(Ba(B/5687:9<;=?><@A9<;BDC9FEHG8I>JEKBD@ABKL?9FIBK>JMNOa/( fffifi"@f/[[P"of[Ba(xCaVakfiaRQ/SUTUT+TVW"z[/[@"BB[aB~a"aBaB/Q["aB/ OakfiafaQ"X"akfia "8 [ /["BBxaB/"["["aB/Oxfiafa"C[Ba( afafia] @" (fi]fi"ZQ/SUT+TUTV[W?$(fix?Caa( /\/"["VBBp$ x^]/_ `"V"fB(f(@ SDa fi6fik ]]]Yb ]]cT+TUT&] /Vk"^V<dfeR[fi(fi]]"e ] b _ `V""B(f(@R SKa fi?] b " 2 ""(( /@"z"aB/x Vq ("8 "("k[Y( /[aBk(("C"[aBaBffi"(g*hiffj!klUmfhnf"[([("[("fix["aB/u"Bk[fip"aaV@"B[u ""[fiaffi$k"Ra["(" :<pUS+TUT+TffSqF : qFN""(?"[(("[("ofi["x"/"("aaV V"B[[(["Vf/"k["pYB6""a(Y"B[fipk"V[Ba["aB/fipVaf(r2[/"V[(("q/"@"($[aV@"B$$"(G B( "fiaka"aaB/"Vfi2afRrp+ f[([(" ""s"S([a(@6[["/ SQ /2"([a(@VfiaB/fi "( CBBaG@at/Yfi *Vq tVqx"aBaB/fik u] [P "o] _ ` ffi$?, qFpS, w v$"(*v B o@a/ffi!$ "ak"B [@afa( 9"Q"/?("/"~(fia"qx"aBaB/fik BV/"a@(@ ] ] "v[@afa( xvG"("[fiB[a~[(@a zqVB"B(f(@afik"a"aBaB/Gfi#y]"k["(fBaaB/"[([(" /Z "e"[a(@akfiapfifzo"""["fiBau(fiBq(fBax" [Ba["x"Q S, ffz "VB[xfa(Hz /2X u" p"fffifiV[fiB"/f@("/""]"/"["Yfifi"p[B/"a$"Bafi[[[( [[B&k{["(~k"[a@fa(Hz ([]BBaqG8{uVqfik u|u}|s~ _Ufi.J<ZJPRwHffXUX( tUyRUU,!ffXt!XX&8ffwsffw&ff8f ? JRUXyU!ffU84 *UX8U!ffUy&U&X,UffXAw^X%8/U&fftff!,w!ff(R#sffXXXffX)!XXyff^#,w&ff*8Uxtff!-ffw!ffXw!ff!?,XffX&X&AXw,ffXffU&U[(uJXcXX!ff*#,%Rffw!ffUYUw,w!ff*RU*&XU&ffXA%XXff!(P&Xffw!ffy .Zff))U+U&w[u%XX&*ffwtff!Hffw&ff8w ffP})Y8U%cfft,ffUF cwUcwUtUUff%ffX!XX&cff*wffw&ff*8f X , ffP!ffRwffffffUX,wff!X)&PUP&PJ8H<ff(X(&!ffffX!ffXffyw8ffP!ffXs!?w8)ff%yX!FK)&ffUX[w8&&8 3X A/Y#Xffw,!Xff8XU&8 ?wU&RR8X&ff,}fiff ff[YtUff)XX,#8!ffUZff)8!Xtwtw!X 84 t.wy&Y!X)UwR 8f[ P? tXU&X8&ffXs!w(ffXffU&H!.wX YyU%XX8wXYw!. %#&w Uw4ff !Rwwwffffff#&Xt&tff8*UFJwtU!ff!"Y** #HXY!F% $'&'(* )FXfftXY!F% $+',* -/UX% $'+$.H/ .0"Y**( #U21 ff!ffX4[% $'$'3s#,Uff!ffXU<Y!XP(ws!X/wUxU&ffU&)fwX!sw&#U&w!ff!ffcX&HXU)wywffXUXcwyXff&XX8X4#HX%4*% $+'5Xw!!ffXc*,8,!U&%ffX)ffU!,#!&wt.&XwYX8w!ff^!wYff%#UH!}PUffU&ffU&Ywy&XwXX?ffwX},PffU&+K%#<!}PXffU%ffXUPYUff!#P UK4ff&JXffPw,ffff&#&8!w#XX8 #U21 ff!,X% $'$'3J% $$'3XwXt!:4 Uw A-P w.A84 P Aff, = <?>A@ > 7 f 6 > 86798 ;&UB 798 ;:f A,ff . < > @ 7 > f. C ff8f C ;D&,9 C E B > 8 CU&RP(!Uff!Fw/#!X)sw!X&Ps}!ffffffU F84 , .;G 6 7987I8wtUffcU&ffU&B 798 JLK wUSB 78 R JTK KcffUff!H ffyw!8JNM'OQP RJNM OQP U8!P&XXUHRUy&ffVVXW @ZY [N[%[ W @ZY]\ ;@Y WH [%[N[ @ W \VU& _^ 6 8 U+ 6a` 8 9 b \ _^cB 8 U+d B ` 8 9 b eWH.(!!8!P&t!U^#,ff*&ffX8f u ff,D) ywZg f9hcX#U^Uw:Y8!P&i@/8Xw!tw)w,ffff&#ffXR!Hff0jw @/D 7lk ;:s8P Offff.&wFX. URU!ffU JXw!wRX!Xw%ff@0m n 8 p q@Yo nL@/o nrC [%[%[ @/ @Y,JXff-!}8%w&XX s.U(YffXff/XffU&YP tXX-!wH#,w&ff!JwHffw%ff?o nn p!,^ujD.swffw&ff!P.ffw!ff?%ffujwvjK' F@ 7lm k 8 ;:sXx nxOffff n PJPyTz{|~}/co29|oL/9w%Nd/%d9}/909NN|'|99|%|u%d|%cc9Qo%< ao/9o/z%%fior9o2xA'w%*'wQgar2XQLwL''Q'Lw%'Q*wLgg%%?do%%LxQ*d%r%A%%LgLLwQgqr%%%roeL*QrQ*go %ALL*~eQQldL*Qro*L~*eLLQrLQ'% ALL*~L2*e' *o%%%0 ?d%E%rL%4/eLLrQ*e='0Qr~Qr%rLg'?o%%rLN/gQworLLrQ*Erwo'*Lr*~r'%rQ%r'Q*roLLrw*LrQ'QLL%9fifffiff!#"%$'&)(*"%+,$'-,/.0213(4#"%+5$fi6C2D > $ E GFIHJC2DLKNM=OQPSR$fi.).7#$98:"%<;= L*rQ'?>A@ +5$9"%"%BU.V$'"%$9&B QLL'0L?ro~Qo'Q'W27X r%rQ*=0wQQQrQr C2Y % KNM=OQP ZFIHC2YZFIHfiff [N"%B-7\]?.7"%$'-*(4#"%+5$'-,/.0*1^#_SQ]#"%$'&`.7ab!#+_*(4#"%+5$ 6 cedgfihf $ .j-,k9kl58rrLrrQ Q#m+ .7$9(ZnNklo r*Lrg $'p"'\]$ .qniVni+0r$ Es H=f tu GFIHwvyx^KNMvzx|{{B{}~{fiff'1Jk'k @ ];7kl(4#"%+5$9-57.Q01S#SQ]"%$9&B(*"%+,$ 6A$fi..V$98A"%; L'olQ g $ EjB&B+,og+_ @) -5#klb!(*/J.Vb!($ .n?.7$9"%$'&R 1J QQw'Q (4#"%+5$fi6r$ .j;=#"'\+_ @ #S8-,#klb!(4#k'kl @ ];7kl R*LrQ'l X%e0rrLorLeroLLLrrQrQ*r'4L*rroG'Lo4w $9-$'8#-,m(4#"%+,$ 6 L*rL*or'Q'%*L*rQ'0lXQ4 x l X0*L'~%oLogA'rQrQ'w%QL '~ x uwoLQ%LEXQ0LLLrQ*Q2l XLrLA*o0r'4fi~LrALLLrL%E%L*~Q'%Q2*A%rQL0 ~Lr%oLSo%r~04 "%5n#kl=!odQLLl X L*rL*er8#/.;9wQQuQr2rrrL ~Ll fi o2''= o'2*LoLfiffL,+5+58#b!-$%;7klq#"%+,$'-57.Q0w1S#!#"%$9&B }} (4#"%+,$ 6 fi$ .q.7#$'8*"%4;= orLLoQ$ EEV#+`&B+5omni#$'+ M=OQP _Ej$98#$'-,/. > v M=OQP n?.V$'"%$'&4$9"%!+Z. R " R Z FIH2DSRl X Q2orLLoQS*Q r*LorL!*r'SQ .V"%+_#]klo-,SS5-"%58 9c'o%7X*Qrr~eALL%''o0wrrL M=OQP L +_,8#b!-$%;7kl lXQ*0Q~'FlFGD 9c'o%~Qe?4Q%'Ad* * r2QrLLLorLLoQ'2:%c%Q%gQL n+5$9B8 uo7 X l Q0*%rLwL*~gQr*~9c' 'rjFlF~2D 9c'o%E'g2w Q%'p*QL=# #Lr'oxowQv L /'?orLLoQE XguogLLN'~'~%Eg Q g%QQL niB+,$'8l XZ A%Q*el X~gc' Q%'gLLQLo0rrLorLrrQrQ**r'e7 X'Q%EgQl Xe4%EgA~QQQorrrL'e*r'uuQ*Egrro~d* *~u~rrL'LroerQ'E04Q%'#**~rQrQ'orL'%mfiff: +5$9(4$'"%$9&Bg(4#"%+5$fi601#_SQ]#"%$'&4(4#"%+5$fi6`2DSR76?$fi.7"'.J`ni?.7$9"%$'&4$'S"%Q]B+ . R " R$ .j.7#$98"%; o~QrQ' $ Eg"'\]B+_fi#S9eS5G!_5%]_# fi]=#Z5A7]_7,!!!A_fi4l=l#g?5_lN ]!g#AUGB!JN!?,?l!#,]?=q,=]*p7_7#qr!!7#!I,!_j7!l==j?,?l!#5p7_7!!7q#!S,!*#_4?l=?,!m?l!#5`#jL7=# fiG,!4#?l]7l?j|qGlm7]!=l,g?5_l77%#!7]_7,!!!),!]#!,`!lVL#_p_fi4l=l##Z#=j5?fi=_7S!7fi!lpg?,lJ7l,!J_l]lg]m_fi4l=l##fiSU_l!27#!,?g_fi4l=l#`==!VU==l*gU,_lgl!777,#_ll?ll?G#!l#Nfi^NAmB N=~~S44!NBSql]7l##77=]`?`g?,#!g5!7 7]=_75]!fi!47l##??fi!7rB#q,!q%#llZ!_]_=l7g'=7|7l# fffiS%]G4]]7l#U!74#!7l##77=]_57==4fi#]!_l5!J=l_pg?,S#!% #fi"! !#Z#=m,?|!`==!VU==ljg?,)( $( ,!m_#7=q7l#?fi!g?G!]=#!!l7#rJ,!??q%#ll?G&%7=fi!r':#_]gU!qJ]!,U( (( (( (+** "! ** , -! ( ( , "! , ff! *!*****.Z!7p?l5!r7l#?fi!7rB* #!]= l* 7=g]/i?q=)#0%7g!*5N!5!r#77]J?m]!71 32fiff4547676684B:9<;fiGm!_=5;G!#=7,!,#!,=p?S?>!fi!7@ 1 1 25N!l=l]?==!7?==ljg?5_l77JlJ#7l##??fi!g#! 1 lm7]_7,!!!_l]G7l##77=]7Z!%#ll?Gfi!j,!7]GlS!=5!fi4V=?7=_B7A fi!*!!4##!7]!]S!7=|?S==!7?8C=l*?,_l77*%UfiD."E0E ,7I~H=_]5C#J_]!fi!gG!7]g$KML NffNPO QSR$UTVQXWffYZ[=Z\YOffY]^Y_R#`aWffbT<c RdNMe:T<fgThbT<c RfgWffbe:TjiffklnmoR YpbhmoR e8RqR irTVQSbhQW5YsR Tt`aR7Y_c7WffuBLaRwv$QLox mpbhmoWffb#y4!NBSGFz kv{TjQe8R|W5u}WffY~NO)QSThbT<c Rkv{x|W5YsRqW)Q|QO7x T<WffbR:~$T<bhm$QSbe:Thx7buBNO)QSThbT<c RguRISbWffY~$e:Tt`5mobR7T`oR7Y_c7R:x7bOffeQ:( (v5kv SOffedWffYR7T`oR7Y_c7WffuBLaR0kdbhmoRgR7T`oR7Y_c7R:x7bOffeQW Q|QO7x T<W5bR|~$T<bhmv{Wffe8RLaYTh7LaRgbO{x|O5YPQbWffYbfgLaubTNMuBRQ7k( (( (kj ,\, W5Y~\TjQgWffYR Tt`aR7Yc WffuBLoRO8 g bhmoR , vPkg0Offe8R|O5c7R7e v0Thf-NMuBT<R Qgkkv{TjQW$QT<f-NMuBRge8O7OffbO8bhmoRx moWffe8Wffx7bR e|TVQbT<xgR:7LaWffbT<O5Yr7=4fi#Uv ]k7fij hP0j0XPPaPVP@fftaP8a j{|agPaoX5{a7a|P}75PffP"ao87ffjffj8noaPa7a)|a&n78o5#MoP7ajan|ao87ooP & |8B}Bn|a78:o8|affBBr-a_7<V 5 qVgM:<gh< 7 <$gff:jff0no7<hBffho S7o ffBoVXff_sha78{jff_Bpff_X:ff:^ #Pff5<5s:t5o7o7_7:7ff j :}a|ha7:q5^fiff5<ffho ta7 ffBo 5^gB:hoff <Dg7ffaBff7+ 5 Maa0 &aP B | |a wpff ffffM)n|agBff7 r jaP ff&g ajaBno P 5ffn"oa a#8o|a&n78a5#M8o7aja&"ao87|PBw|ajff8ff"Bff7 jaff B"|aPaBag aj Bff7 ffo 5 B}ff|a7Bff7 r jaff:apa ogBo$"BB B7aX|a$oaPa7a |aBo8ffBjff8 !s|a w5a7a|#"7ffP $ -|aoa )qaff-|P BoP Pa |h75< "B|$P78B% o:a7 P % 57 ja ajagwaBSDff8|a % oaB p8aff- ff&('*)+,.-(/103240657d|aBa"ffP B98|a7 &) P8jgB:ff "|5aBBog |8: nB ':a57a7 a7"B|D)#7 B |ff_ffh:ff 8:#a 78ja{ |aq)|8:{j ;" PB <$ =j5|87ha7ffh7hg| ?> 7h7_h j$o 7 g7 |Pw|a A@X7aB8Xj75ajaBoa #7 77 7aG QJSRNoJ UTVK NRVWX E6GYELE[ZNJB DCFE?GI'H J4KL dKJNMPO F: Bo58 a8"ff ffPaBB7 Bo w:an7o5#M8aP7ajag|ao87 ff |a{ aj o8ffjff80Bw5\57{j{|affBB "jaX|aa87{]^ JaMJG`_bacX jp M:<gh< 0S o)Sh0q5|Vffho )*d#e fgff hie kj Pl a78mjVX|5<B:phoDo_ n o$ffhffff:p5j|?oahff pc$ho;q0ffsr ff{aff< o{8ff{pcX:5M87ff =jo:ffg7:hrtaP8a j{|agPaoX5{a7a|P}75PffP"ao87ut wPv-a5|aBBo0P7aj :aP8o) jaB08Ba$|aI)"|P "a7p)|8: Bw:ff 70{78|)P 7 x nBBga: B7ffp|ff)qBgBff7r jap|a:ffgXr7Pff 77ff8BB7&)|a57 jaffBgoPP &poa$j=g aja70"a78:o8ffn|aBff7r ja{ waBSff8$X|P5 {ff8p)a) a7ffy8 78Bff7r ja$ xz e{f &-aoaBXBff7r jawaBS affo5 78ffy8 78Xff8|affwwa5g aaBff"a78dBoaBpoad|aSDBff7r jajD|ad7 )P8jgB:ff aP Bq |8:|" oj|ad57ff $ {:a7 )P78B )|8Bw) 78B }% B7a Brd|a7ff8oaB{Bff7r jawa5g aaBdff waBpffff oa|a %~ 8aff" Pa8ff= q87 Bn|P ":a ffP)X)|8: Bw|a jg7aBo0 &:aBja7ff|Pa|P g|P5Pa5p|aBff7ff a8 ff o8|Pa $|aXaPgP7)Bja7ff8Bj 7P7 758 "#h"ffjPa$ aa|aX :8: aa| ja 5p|aP8 9j 8ff o8P 5Pffoa|):a{ffB "ja0#8o "ao87{v BXP \5 ff"|a7Bj h h 785:8:waff{Bff7r )ap58)p 7a odoa{Bff7r )a }h" "B|o8|PaBff7ff $ ffjP|a5P$ :aP8 awaff 7ff"{ffPa0g7ffa":P "B8 ""ff8fi(S F44444 pkkps:k4k!sk4s\;*p:4pkkps:k4::p|:9::s}p44::[9? ?4[pA *6 XF 3:?:: <4<9y4:sp[49s:k! 9ysss[I3 49k4::[9449494:s49\9#*? [ F9ss(.[9ps19::(:\[9sss[(:k4<4<9:9(4pk9(<9Ps94k4p[:s:yss94s:P*p:49;s9:;kp9s*p44::[4*? V [ 3499(49mkp k. 93 4k[p(6914(k9<?kpp[!s[1S? fi?[* <F9}9s4::!\syk9s49999p:;9p?kp4\;:;I4w9\s|94:k93s{4949\gs49s[9s[9}!9k999i `:m4p[:s:;9s:s:k*p:N; s499![p99p94::;9#:s[;999s\994< \:(49:s4\9s<9kp9Ns999k999k4:i93 !91(9:.k*k94.9s:k;(ks9[k*s:k[;9kp 94 ! 44s:k9?fffi!#"%$ff&' ()+*U#s94m4pk9<9k9ks:**p:<99:s(?kss:km4k9[9\(ss[},4[9?4ps:9[p:[*9<9k9k9k9(sfi:\S4.-9<p*0/p21903(([ps[pk994(4ps:4:s94pskp65#9798: 05;2<.7=;w1 > [ 5?715fi@7B s4(s91k(?p?((9<<9 : 05 ; 9<+7 ; DC : E5 ; <+7 ; 94SF(G4fi?[949:k[9*9 \[9k4ssk(Xs9skH5 ; 9I7 ; 4p[99KJs:ML ?kp4[9s*944p4\4\9N OHff)ffQPSR [,99TVUks\99#:!W.X<?.Y iS#Zp[1k? \ (]:9#Z]2]:(^(`_a]:?[ibY0c* !?yp dkfepMg? \?ih:W.X<?( > kml a4n k 0: 5 0; 95 ; <+<+77 ;;j jipo qk4s99U<9#:W%r?.Y4?dk?i?ibY[EcS*((] ]:(^hW%r?<( * >t su wv u v u xAkR yW.XX9zW%r<:\{ep.e4y 1k 030/S?[S9 49i4pkps:4-ps\ff|C}WF?<DC 9k94:F4~WF?(|w9m99\A4<:4s:p?99p?kp#! 99#:spk4::p;4sA?;9* 1k03**\N4?[N<4ssP1.9P*p:*kps*s#;4p9skp#WF? r 6fCWF? r ,WF6!9F(G*9p?kp4:s9s|[9#99s\9N.9s*9#:s:s49::!s*44w?;9 64pk9 p:kps#s#mff9"ff&9ff z#"T T#b r> 2 49 +^(fepk9ss94ss:*p: r <!%<%? .Npk 94k4p\HW.X9W%rAWF6 6(< |*9:[ ~ WF? r,> 2?|4S?[N:[ ~ r,> 214P#!9\4s:pD}(p94\:pm#4p99*\:<9m4.-9![ss4pkp94:9#:W}9;!W X k=W r kp[9*I|#8fiDTT, #I###)#(THff)fft%y+D `2%20z`fM%(`% M~0a`T02(0.2.!b. 26(M!D(y[(# (I( (9(2{T=}ffE , 0= MM H (# , +, # ,!# . , fi ff ( , , ` , `% ff%= , 2 ~( (MyM%(`% M! (0 "y( ( # {(0+ . $ `%% , )& +TT `%( (I( ( # 2y+(( 02( ( y` fi ')D) 2, + .-6H[ $( *=@?8A? B + {T=}H0T M# ! . 2 0I0bM. +0 ( 0(0942 :3 6655 387 >/ 10;<243 : 387C4D ff# ff F EG#H!E JIK K K ML N,,` # J # ,` Q P `#,` ffS R DT U R 6,x V , , E ,W= # 6 % XY ~. 2 # (D y,, # R DD(9 (# [Z \ 6 H ]= ^+ {, ff @0M(` `%(2_U`ba&cffff dce=!dTgf h))ffgc\ ikj6!i% dmlnocf hp ` ,U R 6ff =M6 , ff ff # x .(!+(m(+.(f @ 02 EoG#H!E # ` ff q ^r ? !s ? u twv|o|| |o|| Fyz rzz,U R # `^r}||||||zzr r ~ff qzzx zzz ||| s^~< |o||kQ## (zs^~<ff q||||||]{[}|o||||o|!M rV?H @s ? ff q(M ,M ff r]? ff ` #M ,UR { ? ff ` #(M # #B ,M `#H 9 9 ff VM ffff!= fi! .T ( &r sff q #Q M, 0M(#( w = ,` , } fi @ `#M , vB fi * , r ? ? ]Z[y F 6 , = ( J` ( J * (, R ` UI = x f ffE % XY Q ^M# \ x Z[ u ` , BffQ]M\ B[]r ? ,UR H ! = E ,I , !ff ( ,9 , ,` ff#J y, ~ [ ,_j6!i% dmlnocf hp #8] D, 96 , TJ , #Q # # fi9B, =, , 9 ` , `#w ff [I ? fffi,#%!!!!Primitive setsu&B#!&oPeriodic sets&J&Transient set&,UJ!F#*#fiUUJgfi#!J6!Jfi!fi6fiuqfiJfiU^!fi!#fi#F#u!qFUF!Fqu6!fiJFfi!fiw&6ufik!!6FUVB]F]#fik@!UJQ&]fi#Fq qF]*J@6fi!!!FUJq&#FqfiFUU F!Fq6#fififiFfi J]6, J 6,]#fiV<,qfiUUJfi]#Jfi6 !fiJFJ!u#!fi fiU!6fi#Fq&FU2201031354,fi!Ffiff!FUfi!U J!FU#nQFUJ ^fiu!!fiUJJ]U6u64fi "!$#%#%&('$)$*!,+$-'$#.&/!10234$56879,:%9;<>=,5?7@"A4156B79C:$7D(E,F9,DHGIJLKMN<ODPQRE15?S>=,9TUQWVYX,5Q,5Z<>P$[]\^_$\`<>=$Pa<<>PGb7Q,c(de4$6B9,:f,DZ<9;4$56B79,:$7DRghP<>6B7DZ5ZSiT7<>=%<j=,5kS>Pgl5l7Q,DZ7:$5Q,DZ5RgkP<>687m%PQ,:n4156B79C:.deo,75ZF:$SkPeE,F9,DHGapL:$7Pc9CQ$PFgkP<j6B7m(TU=,9bS 5fidqE,F9CDZGS?Pb6B5?4$6B7gl7< 7r5KUst=Cf,SiPk4$6B9,:f,DZ<UIhuv-w>x v"yz6B5Z<>Pa7{Q,St7{Qb;N9C6 ghP< 79CQRPbE$9Cf,<O<>=,57Q,7< 7PF|E,F9,DHG7{Q}TU=,7DZ=W~ v-w TPaSKUt9T|5Zrb56Z[$;N9C6t5Zr56BoeS>f,DZ=%E,F9CDZG}9;zS 7Z5e\[7Qb;9C6gkP< 79CQT7FFE$5cC6 P:f$PaFFoeF9S <OPE$9Cf,<t<>=,5i5ZmPaDZ<7:$5Q< 7<Boe9;<>=,5iS <>Pa< 5fi""C"q<>=$P<E,F9CDZGKst=,7Sl7S(E15ZS <k:$5gl9CQ,S<>6 P< 5Z:<>=$6B9Cf,cC=P}S 7gk4,F5R5Zm$Pgk4,F5KW9CQ,S7:$56<>=,5(7Q,DZ7:$5Q,DZ5WgkP<>687m6B54$6B5ZS5Q< 5Z:.Ebo<j=,5kcC6 P4$=9;7c,f$6B5/1K/MY<fi=$PSl4$56B79,:RPQ,:<>=,5(9,Q,FoQ,9CQbpL:$5Z< 56 gl7Q,7S < 7D<>6 PbQ,S 7< 79CQi7S;L6B9CgS<>P< 5\[TU=,7DH=DPQOoC75ZF:l7Q< 9O5Z7<>=,569CQ,59;$<T9F9C9,4,SK]=,5QighPQoOS < 9,DZ=$PS < 7DgkP<j6B7DZ5ZSiT7<>=}<>=,7SicC6 P4$=%P6B5lglf,F<7{4,F75Z:< 9c5Z<>=,56[7Qb;N9C6 gkP<79,QPbE$9Cf,<k"CqjR7Q}TU=,7DZ=%<>=,57Q,7< 7PFUS<>P< 5kTPSl7SkcC6P:f$PFFonF9S <RV"7NK5K-[7;<>=,5q7Q,7< 7PFUS<>P< 5qTPSfi}9C6l$[<j=,7Sh7{Qb;N9C6 ghP< 79CQ7ScC6 Pa:f$PFFo%F9S <j`ZK?=$P<i7Sl6B5Z<>P7Q,5Z:W7S?<j=,5?CZ?7Qb;N9C6 gkP<79,Q[7NK5K[7Q%TU=,7DZ=nE,F9,DHG.V,C[C\C[9C6$[`9;|PkDZo,DZF7DkDH=$Pa7{Q}TPS<j=,5?7Q,7< 7PFzS <jP< 5Ks=,7SiS>f,ccb5ZS < S<>=$Pa<U7<OT7FFzE15l5PS oe< 9kF5P6QPE19Cf,<l<>=,5k<Bo415(9a;U9Cf,<>4$f,< SlPS 9,DZ7P< 5Z:< 9R5PaDH=E,F9CDZGW9a;tP}DZo,DZF7DeDZ=$P7Q[zE$f,<l7<lT7FFOE$5e=$P6B:< 9}F5Pb6 QnPbQo,<>=,7Q,cR5ZFS 5KRX$f$4$419S 5eQ,9T<>=$P<<>=,5kS 5Z$f,5Q,DZ5ZSk< 9RE15/g9C:$5ZF5Z:P6B5hS F7c,=< Fong9C6B5DZ9Cgk4,F7DP< 5Z:[6B5Zf,76B7Q,cePQh5ZmC<>6PiF9C9,4%Bz$j?l7Q,S < 5Pa:(9;$[$PSz7Qq7cCf$6B5?$KMQk<>=$Pa<|DPaS 57S4$687{g7<7rb5|PFF7Qb;N9C6 gkPa< 79CQePE$9,f,<<>=,5?7Q,7< 7PF]S <>P<5UT7FFE$5?c,6 P:f$PFFoeF9S <Kk%LzOzUZU(a1P 5Z:q9CQh<>=,5PbQ$PFoCS 7S9a;<>=,5i4$6B5ZrC79Cf,SS 5ZDZ<79,Q[$TU=,7DH=ePb4$4,FoqE$9<>=q<j=,5=,9Cg9c5Q,5Z9Cf,SPQ,:RQ,9CQbp=,9Cgl9bc5Q,5Z9Cf,SlDPS 5ZS[]T5lQ,:.7Q<>=,7SfiS5ZDZ< 79CQ<>=$P<7{Q9C6B:$56< 9%PE,S 9Ff,< 5ZFo.Pr97:nPFF:$7f,S79,Q9;DZ9CQb< 5ZmC<OPQ,:eD6B5Z:$7<U7Qb;N9C6 gkPa< 79CQWVNE$9b<>=Wj>bPbQ,:nBBBHN"ODZ9CQ<5ZmC<>`[C<j=,5?<>6 PbQ,S 7< 79CQ,SS>=,9Cf,F:%E$5i:$5Z< 56 g7{Q,7S <7DRVN9C6O\?4$689CE$PE,7F7<Bo$`ZK9C6%%S[,<>=,7SUf$Qb;N9C6B<>f$Q$P<5ZFoeDZ9,6 6B5ZS>419CQ,:$S< 9POS o,S < 5g<>=$P<]DPQl9CQ,Fokgl9,:$5ZFDZo,DZF5ZS?VNPbQ,:fi7S<>=,56B5j;N9C6B5UQ,9<rb56Bofif,S 5j;Lf,F$;N9C6gl9bS <zP4$4,F7DP< 79CQ,S>`ZK9<>=OF5P6 Q,7Q,c?PQ,:l6B54$6B5ZS 5Qb< 7Q,cODZ9CQ<5ZmC<P6B5z=,f$6B<Eboi<>=,5zSjPgl556Bc9,:$7DZ7<o?4$=,5Q,9,gl5Q,9CQlE$5ZDPf,S5<>=,5OS <>P<5U< 9lQ,5ZmC<tS <>P< 5t<>6 PQ,SB;N9C6 ghP< 79CQl7SF7Q,5P6Z[$7NK5K-[,;9,6BTP6B:(PQ,:eE$PDZGTP68:/4$6B9,4$PcCP< 79CQhP6B5o$gkgl5Z<>687DPaFK5:$7S Df,SSR<>=,5n4$6PDZ< 7DPFi7gk4$PDZ<}9;fi<>=,7Se56Bcb9C:$7DZ7<Bo4$6B9CE,F5g;N9C6h7Q,D6B5gl5Qb<>PF?F5P6Q,7{Q,cPFc9C687<j=$glSfiV"S>f,DZ=ePSUPQ,:ecC6 P:$75Qb<UPS DZ5Qb<7QeF7G5ZF7=,9C9,:`ZKNCbN bq$]$ne",Z-s9RE$5Z< < 56if$Q,:$568S <>PQ,:%<>=,5(4$689CE,F5ge[7<?7Si7Q< 5685ZS < 7Q,cR< 9qF9C9,GPa<Pe4$P68< 7Df,F{Pb6O7{Q,S<>PQ,DZ5k9;<>=,5PFc9,6B7<>=$g;N9C6q%%S[gl9C6B5eSj4$5ZDZ7DPFFoC[?P<qP};9,6 g9a;<>=,5%f$4$:P<56f,F5;9,6k<>6PQ,S 7< 79CQ4$6B9CE$PbE,7F7< 75ZS[J/V `JOJ/TU=,56B57S?<j=,5kF7{Ga5ZF7=,9,9C: 9;|<j=,5k<>6 P7Q,7Q,cRS5Zf,5Q,DZ5ZSKqW5qgl7cC=<T9CQ,:$56O7;8[]S <>Pb6B< 7Q,cq;Y689Cg P4$9bS 7< 7r5S < 9,DH=$PS< 7D|gkP<j6B7m[<>=,5F5P6 Q,7Q,c?PFc9C6B7<>=$g DZ9Cf,F:lF5P6 Q<>=,5z<9C4$9F9cbo[7K 5K[6854,F{PaDZ5|S9Cgl5<>6 PbQ,S 7< 79CQl4$6B9CE$PE,7F7< 75ZSEbo?Z5689C5ZSKX,<>Pb6B< 7Q,cO;Y689Cg J OT5DZ9Cf,F:k9CE,<jP7QfiPiQ,5ZT J t9CQ,Fo7; Z $[$7NK5K[$9,QRPlF9,DPF ghPmC7glf$g 9; <j=,5?F7G5ZF7{=,9,9,:tK|s=,f,SO<>=,5?<j6 P7Q,7Q,c/PFc9,6B7<>=$gZT7FFzQ,9<?fi ffN 9CE,<>P7QeZ5689/4$6B9,E$PE,7F7< 75ZSKis]6 PQ,S 7< 79CQ%4$6B9,E$PE,7F7< 75ZSlgl7cC=<i=,9T5Zr56ijfi ffZ$Klf$6B<>=,56 gl9,6B5[9CQ,DZ5( J =$PS<>PG5Q%PeQ,5P6pLZ5689RrPaF{f,5[]7<?Tt7FF< 5Q,:W< 9R6B5ghP7Q%S>gkPFFNK(st=,7SS>f,ccb5ZS < S?<j=$P<fi4$6B79C6lG,Q,9TF5Z:$c5V9C6i7Q,7< 7PFrPFf,5ZSfi9a;U<>=,5e4$P6 Pgl5Z<56BS>`Z[]6 P<>=,56<>=$PQ%F5P6 Q,7Q,c[fifi"!$#%'&$$$(*),+.-,/1032$45-,(6470"8:9<;>=$+?(@(@9A2,/14fi8B@+C0$47B@4D@EF9HG,4IB*),4J9AEJ=$+,DKB*LfiG?BM47/14EN4GfiB6(O+P;QB*),4JB6+.=$+fi/1+fiR?Sfi8:LfiG,0T;+.D47(@B*L?2,/91(*),9AG,RCB*),4M/1+.G,RPUVB@4D@EWDK47/ALXB69+,G,(Y2Z47B\[]474G^47/4EF4GfiB@(_+X;:B'),4`+.2,(@4Dbafi470C(@47c$-,4G,d747(ef B`91(OLP/(6+g9AGfiB64DK47(@B@9AG,RgB6+hLX(*i^9AGj[>),91d7)jd7+,G,0$9B69+,G,(O[]45L?DK4NR.-$LfiD@LfiG?B@47470jB')$LXBMB*),4DK4J[k9/1/]G,+fiB2$4gL?GfiST0$9<l:-,(@91+.Gnmo+X;>9AG?pq-,4G,d74r9HGsB'),4J;+.DK[tLfiDK0j=$)$LX(64fi8uLfiG,0sdDK470$91BJ9AGsB*),4v2$LPdwi?[tLfiDK0x=$)$LX(645+X;B*D@LP9HG,9AG,R.ye f B]DK47cz-,9ADK47(]B*)$LPBuLX/1/+X;"B*),4t4791Rfi4G?a{LP/H-,47(_)$La?4>L`G,+.D6E|B*)$LXBu91(_}fie~t),91(QdL?GJ2$4MLXd7),947a?470[t91B*)J=Z4DK91+.0$91d`EJLPB*DK91d747(um+X;=Z4DK91+.0C.y8X[>),91dw))$Lafi4tM4791Rfi4G?a{LX/A-,47(tB*)$LPBuLfiDK4]B*),4>NDK+,+fiB@(+X;u}]+.GB*),4d7+.EJ=,/147h-$G,91B_d79HDbd7/4fieM~+5Lafi+fi910hL?GfiS/1+fi(@(_+X;u9AG?;+.D6EJLXB@91+.GrLX/1(@+vDb47cz-,9ADK47(_B*)$LXBtN>|2$4NB*),4910$4GfiB69BKSfi8?(@9AG,d74>LfiG?SM0$9HLPRfi+.G$LX/2,/1+,dwi+X;q[t91B*)(@9174>EN+,DK4uB*)$L?G5}[t91/1/q2$DK9AG,R`L_/1+fi(@(+X;9HG?;+.D@EILXB@91+.Gm2Z47dLfi-,(@4M+X;"4DKRfi+,0$91d791B\S+X;=$Db9HEF9B69a?4`EJLXB*DK91d747(*ye~k),9(kdLfiG52Z4>R?4G,4D@LX/1917470gB@+JDK470-,d79A2,/14OEJLPB*DK91d747([>),+fi(64MdLfiG,+.G,91dLX/;+.D6E91(_d7+.EJ=Z+fi(@470C+X;u=$4DK91+,0$91dF2,/1+,dwi?(_t:[k9B')Cne~k),4Cd7+.G,0$91B@91+.G[Q4TLfiDK4C0$47(@dDb9H2,9AG,RLXd7B'-$LX/1/Sd7+.D@DK47('=$+.G,0$(JB6+xLxEILXB*DK91s[t91B*)3+.G,/1Sn}fi(5LfiG,0k(e+.DB*),91(>BKS$=$4`+P;EJLPB*DK91q8ZB*),4M9AG,d790$4G,d74CEJLXB'DK91+X; 9(_47c$-$LX/"B@+JB'),4OEJLXB'DK91 k 91B@(@47/<;be~t),4DK4';+.DK4fi8Z[>),4G91(_,470"8B*),4jLfiD@iX+XaJd7)$LX9AGC91(`LX/1(@+5),+,EN+fiRfi4G,47+.-,(e f B>Lfi=$=Z4LfiDK(_B*)$LXB>EILfiGfiS9AGfiB64DK47(@B@9AG,RMd7+.EJ=$-,B'LXB@91+.G,(dLfiG$G,+fiB2$4tLXd7),9147afi470N[t91B*)(*-,d7)`d7+,G,(@B*D@LX9AG?B@(tmo9e4fieA8+.G,/1SFLP//1+X[t9AG,RM+.G,4+.DEN+.Db4Qd7S,d7/147(u+X;B*),4t(*L?EN4t=$4DK91+,0vLfiG,0JL=$-$DK47/1SO0$47B64D@EN9AG,91(@B@91dYL?G,05),+.EN+fiR?4G,47+.-,(jLfiD@iX+XaMd7)$LX9AG$y7eq-$DbB*),4D@EN+.Db4fi8fi9<;:B*),4>=$L?D@LfiEN47B@4Db(u+X;"B*),4t(6S.(@B64EL?DK4tB*),4tB'D@LfiG,(@91B@91+.G=$DK+.2$Lfi2,91/191B@9147(>B'),4EN(@47/1afi47(`mLX(9AGM+.Db0$9HG$L?DKS`tTT(*y78(*-,dw)_(6+fi/A-,B@91+.G,(:d7+,D@DK47(*=Z+.G,0`B@+_L](*-$2,(@47B"+P;zB*),4d7+.D@G,4DK(+X;zB'),4U*}u)?Sz=Z4DKd-$2$49AG5=$L?D@LfiEN47B@4D(*=$LXd74fie_[tLS`;VDK+.EB*),+fi(@4k(@+fi/A-,B@91+.G,(8,/14LfiD@G,9AG,RJ91(tEN+fi(@B6/SI9HG?pq-,4G,d7470T2fiS'.fi'u*0$4=$4G,0$4G,d79147(8$2Z47dLfi-,(@4u+P;z0$9<l:-,(@91+.GM+P;zdDK470$91Be-$DKB*),4D@EN+,DK4fi8LX("(6474GM9AGM47c$-$LXB@91+.GJm?y78LX/1Rfi+.Db9B')$EN(/19AiX45[t91//B64G,0hB6+5(@B'LSgG,4L?D>Ld7+.D6G,4Dt+.G,d74N91BM91(`Lfi=$=$DK+.LPdw),470"eM~t),91(`('-,RfiRfi47(@B@(_B*)$LXBNfiwK'qoNA7fiofiTLX/1Rfi+.DK91B*)$EN(8D6LXB*),4DMd7+,GfiB@9AG,-,+.-,(`/1+,dLX/tLX/1Rfi+.DK91B*)$EF(8:EJLSj2$4CEN+.Db4FL?=$=$DK+.=$DK9ALXB@4B@+47$=,/+,DK4`B*),45m/47R,LX/Aytd7+.D6G,4DK(t+X;:B'),9(M)?Sz=Z4DKd-$2$4fiezL?EJ=,/147(O+P;B6+gB*),91(JLfi=$=$DK+.LPdw)jL?DK4N;+.-$G,0x9AGB*),4CLfiDK4LC+P;R,D@LfiEJEJL?D_9HG?;4DK4G,d74;+.D`G$LPB*-$D@LX//ALfiG,R.-$LXR?4OEN+,0$47/19HG,Rjmo4fieReA8,a{LfiDK9ALfi2,/14JEN4EN+,DKS5/14G,RfiB')CjLfiD@iX+XaJEN+,0$47/1(8q+.GC47B>LP/e8"}fiX8.+,D]d7+.G?U(@B*D6-,d7B@91afi4gLX/1Rfi+.DK91B*)$EF(N;+,DN/14LfiD@G,9AG,Rxd7+,GfiB@47,BKU;VDK474CR.D@L?EJEJLfiDK(8u"LfiDK9_+.-$G,R8_}fi 8,B@+fi/1dwiP4hEN+.),-$G,0DK+8}fi?fiy7et~t),4J=$DK+.2,/14E+X;0$9<l:-,(@91+.GT(@B*-,0$91470j),4DK4JLfi=$=,/19147(`+.G,/1SrB@+5LX/1Rfi+.Db9B')$EN(MB*)$LXB-,(@4JR,D@LX0$914GfiB9AG?;+.D6EJLXB@91+.Gm(*-,dw)TLX(MB'),45]Lfi-$EUVj47/1d7)xLfiG,0R.D@LX0$914G?BKU\2$LX(@470xLP/R?+.DK91B*)$EN(*yML?G,0xLR.D@LP0-$LX/tEN+.0$9<dLXB69+,Gs+X;>B*D@L?G,(@91B@91+.G3=$DK+.2$Lfi2,91/191B@9147(ef BJ[]+.-,/102$4C9AGfiB64DK47(@B@9AG,RjB@+T47aXLX/A-$LXB@4g),+X[(*-,d7)jd7+,G,(@B*D@-,d7B@91afi4CLfiG,0j0$91(@dDb47B@4C(@4LfiDKd7)jLX/1Rfi+,DK91B*)$EN(J=$4D;+.D@E[>),4Gs=$DK+.=$4Db/Ss(@+fi/1a,9AG,RhB'),45B*LP(*iDK47c$-,9ADK47(MB@+J/14LfiD@GrB@+CDK4=$DK47(64GfiB_/1+.G,RXUVB@4D@Ed7+.G?B@47,Be GrB*),4O2$LX(69(_+X;uB*),4NDK47(*-,/1B@(M+X;B*),91(`=$Lfi=Z4D78),+X[]47afi4D78[Q4J2Z47/9147afi4IB*)$LXBM9AGr+.DK0$4D_B@+(*-,d7d747(@(K;V-,/1/1Sj/14LfiD@Gr/1+.G,RXUVB@4D@E0$4=Z4G,0$4G,d79147(8(*-,d7)TLX/1Rfi+XUDK91B*)$EN((*),+.-,/10J/1+,+.ik;+.D"a?4DKSM(*=$LfiDK(64uB@+.=Z+fi/1+fiRfi9147(tmo+.Dafi4DKSM0$47B@4D@EF9HG,91(@B69d_EN+.0$47/1(*yek+fiB@4B*)$LXB"(6+.EN4+X;tB*),4CLX/ADK4LX0$Sx=$Db+.=$+fi(6470Lfi=$=$Db+.LXd7),47(^m]+.GT47BJLX/eA8]}fiP.yMLfiDK4/19HEF9B647039HGsB'),4JBKSz=Z45+X;_d7+.GfiB647.BB*)$LXBdL?G52Z4>DK4=$DK47(@4G?B@470jmo4fieRe8fiG,+`/1+.+,=,(Q9AGIB*),4tR.D6Lfi=$)JLfiG,0JB'),4td7+.G,(@B*D6LX9AGfiBB*)$LXBuLX/1/9AG?B@4D@EN470$9ALXB64+.2,(@4Dba{LXB@91+.G,(`2Z47BK[Q474GrB@9AEN47(MOLfiG,0T>EN-,(@BM2$4JDK4=$Db47(@4GfiB64702?SgB'),4`(@B*LPB@4`aXLfiDK9ALfi2,/14J9AGr+.DK0$4D_B@+EN+,0$47/"B*),4M9AG?pq-,4G,d74J+X;:o+.G y7eCHtAOzAj4])$La?4QLX/ADK4LX0$S_;+.-$G,0JLfi2Z+{a?4uB*)$LXB47.d74=,B9AGMB'),4Q('=$47d79ALX/$dLX(@4+X;+.D}B*D@LfiG,(@91B@91+.G=$DK+.2$Lfi2,91/191B@9147(8B*),4t(6B*LXB@4]a{L?DK9ALfi2,/14`2$47d7+.EN47(]EN+.DK4_LfiG,05EN+.Db4t9AG,0$4=$4G,0$4G?Bt+X;:DK4EN+fiB64>=$LX(@B(@B'LXB@47(>mLfiG,0IB*),4DK4';+.DK4+X;YDb4EN+fiB@45=$LP(@BN9HG$=$-,B6(5LfiG,03+.-,B*=$-,B6(*y7eT,9HG,d74rB*),91(5=$DK47afi4G?B@(JDK+.2$-,(6B@/1SxDK4=$DK47(@4G?B@9AG,Rj/1+.G,RXUVB64D@Ed7+.G?B@47,B8$/14LfiD@G,9AG,RC(*-,d7)TLN/1+.G,RXUVB@4D@Ed7+.G?B@47,Bt91(`LX/1(@+vEILX0$4OEN+,DK4`LfiG,0hEF+.DK4`0$9<5d-,/1B_;+.Dk/+,G,Rfi4DB@4D@E0$4=$4G,0$4G,d79147(efi]AXX@o$TAT5$$,$$3vZfiXkX]7fi7"1J1NAfi6K7@@A,j@r7.,@1$J,X*,Kfi,$71st*,5'fi,@1@1.$Kff, fi1X'K j$AK77fi 776`*,*,.KfiKX??KTX6,, ff!"o6#$K$P$X@J7,fi@,NA%. X6,&.b?K'?,(X)?fiK*!+,@7rHfi1,fi@,A,(fi1fi.K1* t-,7.X0/213fi,o fi1174fi5!.P$?]$7@7?,687VfiK6, fi9fifi17,k7.,@1$]*,;:M$$,*,AIKfi,$177.=<7?t*,7@X'K '$K,*,7@,6?>Hb@fi170@BADCFEGAIHJAKLK,KEMNH+M$*,OLP @*AI!+QOLP IEGAI! OLP RH+AS!TK,KLK OLP EMD! OLP RH+MN!8CUV,WOLP RH V ! OLP IE V !IXff!Yjgfi(fiAK,P3@73*PP EAI!(Z\[($ fi17@*,r*fi,@1@1.$b$ff, fi167]fiK(fi fi0^..[ff6L_] Zt*Pt*,` 6@1.]$K$ff, fi11 X*K .H1_$`Pfi.fiI6+abfi5,A,C*,`$=cq,1@1.rVX@1.$!@eN$9Xfi.fiX*K.fg,]$,PHPOLP If!2C[gfhRi jFk,lh hNmfhnjloFlfhnjJmfjpj[ClqfhRi jrklh hloslfjpjlqt1*&t+uC v wxt,K=.KfiP RH !2C[hyi j k-zR{l}|CFt~4 !>,17g1_*,fi4XfiMu*,KQfi9fiK?7@>R{ozl|Cv ~ !qt1*&t+uC v ~6@1.]$K$ff, fi11@17X_*,1>6`@@,N6xk,K=,Kfi>,*,u*4fi,@1@1.$b$ff, fi1678?KQ,fifi fi$^t,2[fiH*,u,P@$$6K7@]$,-,@ P RH !GQF[fifi,s*,Kfi,$71 s7.=<571?Jt*, X*b5 $K.*,7e@BAtAsX@1.IXff!M7,fifibfi7`@^XA,K,P@7,68kfi@_*X]*,1$K,*,7tfi1fi7]*,M.P$?] hRi Mhk'5K7=$77t@e ji AVKJ%70gfiS6 [,%Xff^*7,A,@.r70fiI6A[,ff%ff!+XX@1.[L!fi,g1,@7rAg',/213fi1fi,K1*]fi fi8X>Ar.P$?X67gfi?.K1*[,ff%u,?.>q4X@7.,D[,%ffff!6>."I]K1fi1fi8[Lffff^*,fi1N:M1T.KB>2fi9 eLffZfifi1fiAC',M,X@M8fi1,fi@,A,K1@K1.(k>,K9$D_CF@BAw,wLw#6,A,7@ 1.,@73@$K$P$X@K7$1'P)?fiK$LLff,_*Xfi1.,gV@K7$1M_.P*fi fi5fi1fi@0X_1>1$KX$X@7,fi1*,Cfi77@.;1@_7.fi?Kfi,7`6v?([Xfifib$,"*,k.X$1?u*,fi1,fi@,A,NK1@K1.It1*JK7=$77u6fi fi*,0P@@-X678$77 7fi$I6 ffA67.?fiK?7t@e 1fi @9 fi N9[ff~L[ff~,wLww~,[ 6Lx ,C7.fi6H ,k$,1@@1.,C,X6g1 .KC$n5< , 1fi ($7,ff,6h',g$,@1R{AeCt4~2AI!zl|,fi]1fi ,,fi fi ZJ.K,X6_*fiT.,ff6tx ,"ffZXfi5K7- 1fi ,fiT@@ fi fiJZ5 ,-XA,7jn>]JK7@*K17$$*,M-X@6fi@1.@M',Q,P@7uAN>,17N*,0$b.*,7*,fi9fiK?7@ 1@@1.$K$ff, fi11@17X,X7N@fi JAe$4X7@17ff68V7 *,],X6t>,K]11Q,fi2$$$,$7",]fi@fi 9X@@,1JZ$$,$7"fi_,7N1u',7.LK77-$KM*Pt*,M-YK7= fi_,fi.Z`$,-PH,7(%7.,@1$KA,C@,fi17g6@1.($Kff, fi1X'K177,t1*"@,gfiA,pX7@,8A*X1[t>,',> 1@6,.$K$ff, fi111fi17@]*fi[fifi,CFt~4R{! fi*,Kk6ff6'7@@A, CE H KLK,KE H 2fi1*,$,,T*,hzl}|Xfififi .P$?]t1*CK7-Z77t@efi "fi *,P@]@-X@7],fiI.KX fi&fi`?Kfi"IX+ A,K,X@7=!7*XM1.[,*,Jfi^A]@65fi fi7.fi?Kfi7_@[fiNfi,j*,Nfi77@,+fifi9fiKfi,!fi1@9 fi1N9[ff~,[%~,www~L[6,ffCfi1@C7.?fiKfi7M6'IZfi@@9 fifi2ff*ByD*=weakinfluencestronginfluenceeremotepasteventnearpasteventetcurrenteventtime2 $; ,+$ , -= $p,4,,, .` - e $ gp,,,,%,(g +-9(G]]0 -' , LG+ff,-49 ` .G5 8$$ff ]$$,5,g5 5 np$945 ;$ $,b $ ff,G,,,, ,+$ 45,925+%,ff0R$,49 'G9b% ((R ,9 'gJ4`. ),% 5,-ffDff -ffe= ,effe 9%,9 ff.%,ffb ,9 `+,SS}ff9Nff,%0 - $ "9% , - 04-ff9ff 9029$,844,8N$ -98 29,0 +$,+- bff,g5B9% , 4-++9+$= 0 9 9 $- $ -b9-(,ff 4"- ., $,$,,2ff,ff 4$g5,%+ffb"4ffff- ,= 09% , b9%,ff, 9 ff,%S-9 .- ffG$,`- $ "=I$b8G5 )&- ff,2-%e- b9% ,- ,$ff$= 55,fffiff G+$+.9 ,,g,!!"$#&%('*)+"-,fi#&./0'1%2"4365879#:.<;=#2>?34;-@BA'-5DC$'+ ,ff ]eff4545%"e-ER$4-` .4"p ffp$4$ffG`545%ffG$ ;9$,G ,ff $ p,,,, ,2++$ ] `g4'Lffeeff%GF,ff;9- ee-HE.-% $"$ff 545"S0 ).* G-$ ,$N*+$%4(ff&- 0IE,9,%e,99KJ $KL]ff 5 9 -492 $ML%*N;%I$-45ff?- eff, ,-ffPO= RQ:ST UPVIW8ffff9;$$ $ffN8"4 ,Dff, $G#],S$IEffe e-)ff$ $INffYXfiZ [ Z]\1^Gff 9 ,XfiZ [ Z%8ff9$ *ff-4 -(`ff ``_+IaXfiZbZ Lff85 e$ff ' ,L 5- "$ $ffNdc0 ` 4-949925BeB9-)ff$ $$4,-,ff 9 895 *+-4b5 =5$E$L$2IE$, b - 9$ ,e,e,4,ff-g $ $ p4,$%IE J = ,=S % ,ff (%"- G]ff 4545 .$%ff 0+,$8D-g8,,%9$ ,;9eb,=9$%IE$+ff ,ffp$IE 0 ;`%-]*=G+ff,B`-;,&- ]-5 ff.ffbgfV V fiSffg.I0 ,ff4 ` $ b9$%9 .p ,, e8%,ff;- ]hfiifihfijPkl&l&m$nokp-q?kq?rBs-t-u$pWv-k<s-qKrwp]x$y z&n|fixed priorisentencesnounverbcat{{wordsdoggphonemessubphonemicLearningmeaning stateslevel}~H-$R4fi oW~WG&fi-Iofib&o~Hd&I IR~M-III*II W~Ho~H???~H1W~Hfi&HHH~~IGoa-0- --fiW~W~G9-WWfi~HWfiHI I!fi-Ifi 0o~HW IW&ofi-~HWW&HI- bWMW - obIofi 9&ofiIoo~&IGo~WHI&WIfi-ofiWIa&o~Hoo~HIfi-WWfiI9W-fiW4WIHfi&Hfi W~W?Bfi-Iofib&o~Hg&PI IR~HWfi~H-IMbGWW o~W~HRWa-&o~HR&-~HRWW:I-bW Wfi-~IIo~H&IofibWWH]B~fiWaG~WIWo-&ooB-~WaWW:I-b~HHfi oW~W?I- WHIfi-fi WH~KG*-&o~WH~$IBWG-WHfi0Hfi W~WWIRHW0ofio-fi]fiW-fiWI~HIfi*-fi-ofibIfi IM~W~Ha-~IIo~H~H-&oIWH~-fi&Wo~WWHo~ofi0afi-Iofib&o~H4Wo&o& ~ WHa~HP-II] oIG~ fio&-b&oI: ~bWIW oIo~ g-W$WI~9I1-0oWWHgo&a:b~ WHfiI!fi&I]fio&o~WG&2-~!fifi Ro~ofi&H RW-~W~0o-Wo~Hd~H-&RWW&ofioIboI~H-afi-IofiboIMoH&ao&oR: ~ WHIfi]W~HGWo-~WofiW~~baoW-II~Hoo~~W&fibofiW~H0H&W--&0o~H9&!IbWfiI-~ YHfi oW~W& fiYHWa$-o0o~HW-WW?W W~HWfiIbIo&& ~ WHIfiMDG~-boBWIowWHo~WHB~Bofi0IWWfi~ $WI9IWo&~ oWobWo~Ho~HM-W- W~H~Ho~HIfi4Wd-&PW- 0$-- W~HH~&$I- W ~Wa& bo~Poofi4oH:& ~ WHIa&HWbWfiWW$&-Wo~H9~H-&YWobWo~Ho~H--bW~H~Ho~HIfi 2-P&IoI~ofio06WIW-~Ho~H-&T-bo&-- W~HH~Ho~HI&fi&IGo~9ofi&H ~H figWWHo&o aIII-9-&Wb1] WIo~Ha-fiW~WW~WHo~ofi&HgooWI-G~G --W-~&o-&-&H*I1WfiWI?Hfi oW~W&bW- W]fiWoIfifiWIK&Wfi $T!-$---9T -Dfffi fffi fifffi! "# %$& '()ff +*, -&fi ff$! .fiff&fi/021fififf fifi 3WHoIIoHP-bbMWIWIHaIb]&W]fibfiWI?BHHoWIMooWGRWIGWYPB&oH& HII]?Wfi8P- -fiH--fiWIHI9$IH46587:9<;>=?A@B; CDFEHGI?KJMLN ;POQ'RTSA;JU?ARVQW;VC3D3@>ff YX82[Z\ ^] `_ 3 '&Baff# %$ 3#&fi !H&ffbfi3 c)e Hfi<fBa ff#a $ 0g,_-.h ^]ffffi$# /jkZl mnfiofi3p/qZlHfi r sa $ u fivX w)ff yxzff$fi>#Zp{Z|l fi r %a $ }. fi ra ffff_ u# ufiofi ~X 8 V xz }.$fi ZpeZ zm<e' fffi) $#16# %$% %$ % r}$fi $*3&ffff$#BHfi%$ %$ % rfidfi$ fi $ ra- $ ! H rfifio# %$nfifi,&ffH bfi % fio)e% bfi/ `ff.. fi %&r z X:krqff{eZ-iHfi)) ^ ff . /WHHIIPI- fi&oaW-WW -fiWIfiWI9o&]H--HH-HHWPIWWP &oPIofibW&PIW ofi&-H&boWWaH&P&0 HIIWoHoH&-W-adW-oW&KWPHoWGH06W-0 HIIWW-HoMI-WIIo-WHb- ]fifiWI9&0ooH&oHW - 02H-W9WI -fiWI&o9W?W9I-WIo 4ooWao&o9] H-Y-HoW&-IH MIW BIHfib $RWIGW- ! fibIWb-HI gI BIHfib]IIo-PW & b W- Hb&WRHaoW Wo&& HII- ! fibHb0-PWW&KHW9-fiWIHI&K&HWP WI WoHH-W-fiWH0HgI-WIIoW&HRo-0W HWoH465|NBQ';8D3;D6mKLN;JMLD'W@*fi2]&ff$'r fifi3ff$ b}$-.#&fi $ mgIgfi $3 < $ H* .<$fib< <16 -fiH. fi8*Hfi $r fifi (.#fi2 ff- .. fi ff}qI3&&X8 q' 8/ qZ&X ' 8/ Z)fi2anfi ^ dfi $AXs^Z\fi #$XtZ8 \ ry^#Z fifi $I $fiwIX%keZ'ffd$0fffi $ i+X k -k#Z> B$ff/q< 2] ffi$ fffi <fffi> k# r$ b *$&HI&#aH H. (X8'q# ZB <fi >_ fi& o$ ^1fi wX8X%ZK,XkZZ'XtZBkB X%Z&fi $fi >_ fi ffi$`&r fffiff sfiX s$ 'Z` fimfi _ fi -fi$ .dfi >_ fi d$$<gIgrd'ffw mgg fifiX &1fi|. i. $ ffZdms$ H. fffffi M#oH H'Bff#'B U,$ fi X%k :k 'Z$ H. ff|Hfi $)r&ff fi># %$ *#16 &r /}fi $ $U rff fiff#%&BI fffi$fi&fi H3&B .ff.fi fi#fio s$ .fi B&* &HfigIg,{B'/^n^ff^r^8|i'ni d8tr %%i%n%"^n %`\[ &' ff n8ff Kd^0 ff^Tnr`\8d/ nni%diuB^Bff8B&oW&WHdW- -fi-WoH0W-fiWIHIWIWIWofi R W&WWfiWIIRP- WHIo gfiWH&bfiW&o?o9oI YI&oHW]fi PWfiWIIG WI WIbo WHIHGW9o2WH-- -fiR &I HIWH:-fiWIHIHfiH*I- fi&W] -WIW&&Y -WIbG`]Ioo PWbMWfiWIWIIIoWHbW]WHGIHB?WWfiWIIH 0 WWHHfiW]WW HoHI9 &IH GH0oHWHIWWWHHfiWWWg-WoWoWK WWfiWfiWIHW-WWWoWHI-HaP` W-&W& HWWgo &bo&WoHIP2WHW&WoMWIWWa=G WW $ bH 0 WWYWfi9H&oRW&W- KIHW- W&bIW- ! fibaH 0 WWH6 &oIHa?PWoH?oGo&G&0W9WIW-WIIo] ao &I PW &o&-HIWo - WIIIoHRoRWoIWbWoHoHgfiWI-H G&WoHoHWfiWI-& WGo &oI?I-WIIoWo9WgWbo HIMW?a]fi| 'I I'VU'#fiff ff$50-5fi ! "-10-15(%'&-20fffi fi-25fiffff-30-35-40051015202530)+*-,".$/021$35476"89:0;/,:0;8<=0>6 ? @A6"B$/C.DE*F8GHDI<=6"0JK<=*L0;8MONPDQ0=0R@A0S8*-MC*-6"8UT:VW*X8UY$/6Z.<=M76 ? DCMC6<=E$[ DCMC*-<\ [ M]/^*L<=0=D5[ DCDC6<=*X[ MC0=Z_MQ6`86"8a!E6 \ 6,:0;80=6".D5bc[/Cd 6 9e<=E$[ *X8DA<=6"8DCM]/C[f*F80=ZgB:hUZ$*jik0;/0;8MM]/C[:8DQ*LMQ*L68l,"/C[Y$ED;monIE0Up[fMCMC0;8*X8,l6 ?AM]E0qB$6:MCMQ6 \ <;.$/9:0r*-DUZ.0_MC6sM]E0_t-* \ *-MCDU6 ?8". \ 0;/*-<;[ Y$/0=<=*-DC*-6"8r*X8UM]E0A<=6 \ Y$.MC0;/70=u$Y$0;/* \ 0;8MCD;mt=1t=2t=3t=4)+*-,".$/02T$35v+9:6tF.MQ*L68A6 ? \ [ M]/^*Lu2Y$/^6"Z.<=MCD+wyxzC{ |P}?~6"/k[ \ 6"Z$0=t$E$[9"*X8,A[7?.t-t-h2<=6"8$80=<=MC0=ZM]/Q[:8DC*-MC*-6"8,"/C[:Y$Embq[ M]/^*LuK0=t-0 \ 0;8MCDNM]/C[:8DC*-MC*-6"8UY$/^6"B$[:B*-t-*LMQ*L0=DVA[:/0A9*LD.$[ t-*L=0=ZgI*-M]E,"/C[het-0=9:0=t-D;m;;fi+:k$$$$0123123004254567+-"$2$5A;;CfCX`Igl$R$;RXrC]fCR=X=-=A$;:Q2C]fCRX$-==;"$$;^I"IC] Q=X=-=$;:Q]$+C$O:-;+I->gI C=C5:;;C C7]7]Q XF]y~"7]A=$$;X;C5]$ee-==_XU+-"$2100Correct topology givenRandomly connected,24 states% Converged80Fully connected,40 states6040Fully connected,16 states2000.11Fully connected,24 states10Span1001000+-"$2$5;=;] :efR=":;:;=KCr:CFQLoP :;2:]X -]y~"ff:-"C;^L==$$;^F;:Ce Ae]$:gf$;$;$;=-e-OX;;fC=:rF;^; CXg]eC=jP]C:QLQL2$"$L--C-=fC C= 5:O= IW] ]>="C-CQ+F$=LXC=;==:;;C Q=_:K]2>$;-=C=gXU+-"$2;;fi7X CP$gXg`$$$$l:CX=e"^eC] Q=2]$:]K:;;C QFq>g:Q:$"=$==C-"e7;K;; C=sI-]:: "$:---!:>+-"$O] II] ;C :A"$;I +=" :;:=r]X -" ]=C2$ k;;=I >gC L:-=;UfL ; C=I]2$$;7]===Cff ]X -RC -$-U >Cfi=;$="eC"XI :-L=K]X - $ ff -;7 C C=A:5 ]7:;;Q CX> :K]$ --=" C= ~': ]=CeCFQLO$ 'A] ]`$=F$XqeC $;=X:Q ==$:eQ =C;K]_$-C]^F$QL]rC$O:-;e]r; A]rC ;=:~U-UXC;=CCX CC_]$f_Igg`>L :: "gC] Q=`]$ ===C] $U C="$==C -! ; ~"C= =l$=CC; !W -; -- Rr :^C;"C s="C= "$eCqgX:^:;=# "`=-;: ;:$-=L%$~ 5 &"; - '=sFc+L$()R- g -- IA-" *C;C $ ;$;=-=C`2 =C;C=g:U-;:C=q"5; C--:+ :];>X:Q;=CCXK"C;ff C-"r-R]$fIX ::U;fC= ]2]Q XFK;$ff ::=R]$^"""A"7,:;-f X Q;:;.$= X C;I="-A & X X=q:K]A$ C-" ^"-;0/]_=X Q1 _"Cf$L;eI-] = ==`CgC :C:=C;-2:;^] -3$P]e]_ -:-]$$ ;:5C`$C4 5)=6I=C X Q;:A;:_==":;^`C;^L "-;5;_=F>C-$ =5"$;^L;f ==-C-"r"7]=X>-;:]U$=== $$f== ]:-:78:92;<>=@?BA>CED;<GF< HGIAKJA>LMONP;LQ-"A7"R "_^=;$C; =7"R 3$TSW;:-U=A ~ UVVWX)77O$$$ 5~">]=C"-X;:5$$$:-; :Q:=C;fi==rC"QC; f" CXe;=$-5:;W]A-"`Q;C 7X*=" fCXL5I-] CC"^FAX~"CefC-" ~"]>LOQ;CUS7 QL;fL-$>Le;"e"*-X;:-$PX:;e7=-"CZ )CCC"r-"*C;C ="C &`"$CQL >"C $-;CU$ 4* f" C=l]$^""CXff:-]rC -$-:[UL ; $72$\ :2 -C]"$_= C :O^=]-CR==;CX`] *=C;] QL`: L;CXe -" *Q;C ="C & $$]=K $ -`Cq:R Fe$=L7]=K>g ^AIggA",_>^5a`b_ ;">]=C`"$=-~"$q]$f :]g]e ^=C;: C-":qe-;:CXg -" *Q;C="C &AX "Qe C-"qC-=C:=];=g:;;C ]=q:$]e$:]7;:$-=Le]I]CC-C-" "$L--ee ] &0$P"]$$ef]-== -Z )= > 6*:; 5;2C:C-C-" ^"$:--LQL=I:^=-:CIQ3UI: X ~"CefC-";:$7CC"^=b~" ]-"eC;QPcdfeA;=$-I;U$ ^ " Q=` :;W]A-"eQ;CUg A"$>'$X:~"7=;$C;=7"R ]-]:=CC+]$f+] "-; -;:CX-" *C;Q $ ;$;=-=5-"X "7-h feikj4l\mon\pTn2 CX fi; C-" "-;Uq~e $ ;:$ "`;-~"A-; 7L;CX -:"-]$ ]=sr ">"C $-;A$=C=;2CK-;:Cg QF C:C-C-" "$L--C-=`;:U" ~':k C`-;:Q]UC :-:: 75L-r] FsX:Q =="$e-" *C;Q$ ;$;=-;sI-K]"- ;="$Q :=C; "U -C;C$fC :t$P$-C;^=C )RfL"-]$7$-C= :;X_IgC :-::u$P= ==FfL-q~"=Q;:CXrL *C;C =":Q &"Z )v] A]:C :C=s:q.C:-4 f2wx^A"$%$ffUVV):uy7"r=2 ~2$zUVVWX) {^A$A=]-CA::=C5]$ 5]=fL"-]$A]LC] :CK$-C= :;:^CIC :-::-= "W X:CW$=C;CX-CC-2$=-;IR"$;C ^=C;:Q=;5:I=CQ; *CX --:r $ --; C-"r =C]L-]=qef];e C-; =]-CA"Kq:R fE K=$ XRC ] L;7L;CX_-"UC;C $ ;$;=-=eXq":;=" " *!":;="2>g;I=C:$;:Q+;^R -C2 $ "Q= & ;X;:QI"e:^C '=Ff ]| :C]$X] ;";+$ QLU +;=$- U]A="C= "$XK$} "K;LrF]C XX`>g>CL;CU-" *Q;C$ ;$;=-=;^AIgg$TSW;:-~w Q C="T UVVWfUVV(:@ )>:u_ ^5q`b_+3$."$ fUV@UV:@ fI$^Lz *e: 6UVV )A:K" *!":;="ff:X:C R>g ~': ] ]C:C-C-" "$L--C-=U:$=C-"r]X$k~"[^AIggZ )5">]Of=C-"%$k{_>^5a`b_ Z )I 5; =rCX],Ie# *fif@f#@@@Z5R[Z5{@@Z5R#@[Z505Xo5X 5X5[uRE5: X@X5a|3@RZ5R!0X ,RZ@155Z[2ff@ffRR5~51R550155BRR5R5>fXZ5~ 55|Xzh5:ZR5RRXq@ffX@5RbR2|35]X,RR[Z5bR5RRRtX@XffRR5~@55X @05a@oXP5R#B5X@5#RX5Bq@RRZ5b 5Z@Z5@5@ff5h5 @@@ RZR5RX R,@[ 5@2Z5551|[@RR 5RRX]510@R 5RR~B,qzX52Zff5,BffX0@R 51R0XR]Z5~RX@ X5BRR@@5@5T>5RX5T[@qX [qqbZ555RZRffR#ffR[Z5b 5@R]R535{54ff,5[ff:ffRR5f,@@5R535@ ff5|ff RZ5RZ@5R5, Xff 5@@ ZRZ@5RZzf[Z Z@zRbX@515fffff5,#5b@5RXq@ffX506,5Z5ffRRZ5:R~@:RRXR1 {5#5,R@55 [R@ @t@z15b55E1@2\ffRXRfkRX5T@,Xz5uh5Tf55f@:@,@5R~b5X,X5:RX@15XX 55bZ|fEo@ffXff55[@b[Z:5h5:BffX@5635b#5@XR6@ffRR5ff6ff[R,5Xzh5 5Z5@@ffX,R,5h5X5BRx@|5@51Z@[55RRRhq@5@5a5Rz45 ff@zR#RX:Z5bZR5 u|~45%aZff5f55uRRZ@BRZ2ff5 {5R2ffRRO@ff5f5XRzZ@X5@>R,Z5[XRGRZR>4Z5[Z@BRZR6Eff5[b5@R{ ,@ffR :RZ5531[5uff@a@ffX@XR ,X5qR]@XRZ@5TX,X Z5REff5q |~BZ5@b>5 [Rb[Z]Z5{f5RRXR @@ffZ >5,T[h@u 551qR:Z@@0 X RRXtX53~5R#B5XR,5Z5R15550Z5 @>6,@65aBB~@@:B@5@5t5[TX6Z@@|Xffq5Zff @65T@25X5@ qff, zv{u5 @a 5Z@TXR15~RRXY5@@quR0 X@@R Rff56Z@uffX5RX,B@@ff56@05[#ff 5551\Xk uR fff\fffi5h1RX R@55X@zh5h Z50RZRRR{@15R:@zX@51R~B@5RX5:, Ru@5 ffff k" !#\ $ fi|>h]f,fffffi%&('$)ff*+$'ff,'-.&/01ff243 4ff52@RXaR\6o1TXf>5f 5,6a5ffTE,kh @k765@,fzffv,X@5X5R RX{5@5o6Xo5@@] R3 5@@@ff98:8;8=<>&?."@ff$'ff"A'ff,BC$*+&(ff2B1C DE'ff&GF$Hff@>5f RRX5Tff\ 6[ff@bRX@ {Z@zX5X0hffI6{RR@R,R0@4@ffX@XRXX6[ J5 Z@zfE] {Z|RX fT@ K)ffL ff%C@MNOB1C *P&(ff2/ @Q@'ff&%RS.N'ffTM&?' /CU/@ffVW3 C RWSX@qXffXY6,B@Z$[$\fi]M^`_J_Jab9^c"de^`defYg"h"ic+j"^g"dkflcnmoffpJbq:r$s+tffu4vwffx-y`wffz|{}G~J9@vPs+uwPy( ffffff~ffUyffu+9u4vPs-vJ>$}(r@"u4;u`s-~ff}9JvJ+u`~ffs-v+"r@4$y>sr@/~ff"}(vwffy`wvP"}r@9$ffffwny>y`wzK4/"r@@9v+}@wy"$y@w"Kff ff%@NT$+(ff>/Uff%-ffffT($%@%ffWO@yn=;}r@9$yq:r$s+tffu4vw>x-y`wz{>}9~J9@vPs+uwyE($ffff."@yAsTus""+%JvP+/"+e~ff}(@+u49r@@/"}(rffyser@/~."}(vw>y`wvP"}r@9$ffffwny>y`wzK4/"r@@9v+}@wy"$y@w"Kff ff%@NT$+(ff>/Uff%-ffffT($%@%ffWO@yn=;}r@9$yq:r$s+tffu4vwx-y`w+u`~ff}(wy`wz{>}9~J9@v+s+uwyS$ffJPUy>r$~ff}9s+u`s+t4vPs+tJ9r$}G"r$"r$s+"r$s+@u4r@Au4/tP}9~J"u4r$s.A"r@9@r$s.Au4"uY$+4$y9;:>?."@ff$ff"KffT1 P(ff>$E.9 wffUw ff $."yqM}(u4"4rffwffyP$ffffffUy$K`""~ffs+r@9$~A}(r@$"}9}(r$s.:s+r$"}9~J$s+r@(MvP}9K~ff}(@+u49r@@/"}(rEAu4/W~A+u4""r$s-~ff}9JvJ-vP"r@us.9r$}9"}r@/~J9u4vPs>y . %/U;ff--+/ffffw($Uw. ff"y"~ff++u`s>wx-y`wzqM~J4"uwy($.ffff@yAu4""r$sT~ff}9JvJY-v+"r@4v/+rWtJ?"}(vffGr@us.@v+"+r@}(r@@r$+GvP}~ffOu4ffyM"ff+/ff(;ff +ffffffAN.G w> ff /ff%y"}(u4/~ffs>wEy$ffffffUy=Mr@u`s.vP}@r$-r$sff4r$~ff}Gs+us+t|Au4/"r$}(@r$+%"~J~J4u`~J9u`s+tkA+r"r$}(@r$+%"~J"uG9u`s+@9u4vPs+Y~ff""}(v+~J>yskM? /%%ffN.ff-(l+JffffffffK;.@@$($/./ N./ N4P$/ wff">y$ff $ff"yr$+9Gr$}@w$-yJyw ~u}wffy@ky`wJz "+us>w+y$qKyP$ffffffUy$~J+u`S"Su`Jr@4u`+v+vP}vPu`s+@vP+4r@9r~J/~WPu`~/+rE~J4tffv+}(u4/"yM"ff+/ff(M ff ff/. $ N Aw+Jw%."y{}G~J9@vPs+uw"y`wPvP}(uwffky`w.~tfftffu`s+uwPky`wffz+v+~"w"y($.JP@y>s+ur@u`s.9r@tP}9~JGuv+s-vJr@"+4u@u4}G+r@~ffs+ 4r$~ff}Gs+us+tk. r@"~ff+4ru`s }(r@$"}G}(r$sffs+r@(MvP}9.$y9:; >(ff"@ff NffnffffM%@+ff1.,ff+N/ /ff+w>ff@w"J+ JPny~ff}uw-y`w+z=xEv+"s+twP>y($.ffff@y+rr@9Gu~J9u4vPs-vJ9GvP@"~J99u4K@vPs.9r@P}(r@rtP}9~ff~ff}(;+9u`s+t-/+rus+Gu"r%v++99u4"r~J4tffvP}(u4/"y;ff +$ . %/UYff.ffP+@+$w "wff ff"y>r@rffw-y {Ay$ffffffUy+ff-ff . %/U%%9PNfffiffMP-ff$ $4 - ;P K9 @$-yK.Mr$}MK$~J"r$-u4;"+y>r@+u`s+9vPs>w>y>Ay`w>A~ff+u`s+r$}@wEyy`wz+vPs++uwky"kyE($ffff.@y;su`s./}(v++@9u4vPse9v/+rS~ff"+4u4$~9u4vPs,vJE/+r/+r@vP}(,vJ"}vP"~ff+u44uG9u4-"s+@Guv+s+vJE~-~ff}9JvJY"}(v+@r@9AGvO~.+9vP~JGu%"r@r@@}(r@@vfftPs+u49u4vPs>yMA N > >/UP%ff""ff+/ff4w +@w$ff. $ffyevff@r$}@w ky y"($.ffff@yffA+rMu`s++@9u4vPs-vS+49u49$~r9r$"v+}9~J+9/}9+@/"}rffysWv+v+"ffwJy`wJ~ffs+GvPs>w>y`wPz>u`"~.s"s>wyE" y@wPKff ff%@KN 1 P(ff/Uff%-ffffM? /U/@ff W "w"">yffff .ff"~ffs,~JGr@vw Synv+}(tP~ff~ff.~ffs"s>yA~ff+u`s+r$}@w:EyyM($ff.ff@y- /+GvP}(u`~JEvPs+u4""r$s~ff}9v OvP"r@4Y~ffs+ 9r@4r@@9r@ ~."+u4$~JGuv+s+u`s/"r@r@@}(r@@v.tPs+u49u4vPs>yM( /%/.N.ff(-PW9;:wEff>ff@w"ff. ffffnyMvP.Mr$}@wyE($.JP@y;+r9u`-rW"uOr$s+9u4vPsTvJs+r$"}G~Js+r@(MvP}9-vP"r@4$yK- Pff%:+ N.Pw.@w"ff PffyMvPs>w+y`w++u`s+tffr$}@w+xSywzMu4/+ffffw"Wy( ffJP@y>A+rnvJr$}:vJ~ffs+r@9u`~"ys vJA~ffs>wJy+y`w+r@%~ff"}(vwy`wffzK4/"r@@GvP}@w+yE"$yUwff.$ff/U,1 P(ffn/@@ff%S.Nff,M($%@%ff > Jw+">y$ff ff"~ffs,~JGr@vw Synv+}(tP~ff~ff.~ffs"s>yfi"!$#&%('*)+,.-#!/0132547689;:<=?>7<A@B7CD:FEGCfi<H>7<JILKMBN4O4OB7813P<Q/R>QSUTVWXDY5>[Zfi28D9FC\B7C\]^B7C:F29_C8`49U2a9;25PF2C:.8`:FBOEGC\P?bc29F9UEG9Ra9UE\a8`]G8`:FBOEGCfi>edfCg/01h254i68D9U:<=?>7<*ILjlkmQ4O254O4i8DC\n*<o>QSqpnPr>sY5<tQuvUuwxwNyrwzR{7|5}qv.{~G}qy.tvU.y5|.|{x\<`E4q>JTD<Gk568afi>W<aafi>fiTWX>Dj^d9U25PFP<m813b9UBOn]2>2C\25:8<"p>JSUTrVWTY5>DyfGuD}q{$ryRuD}qv{xy|uDuDvF`Gu{x|5> a9UB7C\]295<fi25E\9F>EGC\nB7"<Jp>S;TVY>6\2E\a\:FB71?8`4k5EGCD:9UE4AE`a89;:FB78`4O4NclEGb\P_29U8b\4O2j^89F`E`ea9UEGk525P_PF25PE`29:6\2C\BN:_26\EG9UBO5EGCfi>AyvUu}q{x|Ry5|5y.uvU5G<fi`<ATT.fiTWW>EGC\nB7"<Jp>S;TVWY>6\2E\a\:FB71?8`4k5EGCD:9UE4AE`a89;:FB78`4O4NclEGb\P_29U8b\4O2j^89F`E`ea9UEGk525P_PF25PE`29:6\2BiC C\BO:F2?6\EG9;BN5E\CfinBOPFk5EG0CD:F25nk8`P_2>RAyrvuD}q{$|Ry|y.uvU5G<fiG<Wr`>:FE4Ok5`2<3>7<IR13EG6\0C\n9UE< >ASUTVVDY5>J@BOnn2Cej^89F`E`?13E\n254*B7C\n0\k5:FBOEGClbceQ8rc25PFB78Ce13E\n2541329U]B7C\]>RdCl@8C\PFEGCfi< >fio">7<mE8Cfi<"o>fi=?>7<fiIHRBO4O25P<*mR>fiZ>SqpnP>sY5<fiu"y|{$yrGvUuw55v.uD}q{$tQvry||5{xr|}qyr|`<aafi>*TTTW 8Cj^8`:F25E<mQ3>jlEG9U]\8C[R8D0D1?8DCCfi>KMBO4N4OB7813Pr</R><IfiB7a\PF295<R=?>S;TVWVY>(4O289FC\B7C\]8`4O]EG9UBO:61qEG9k5EGC:_BiC\08`4O4Oc9F0CC\B7C\]0\4O4Oc9U25k09F9U2CD:C\209F8`4AC\25:QEG9_P>yrGvUuw\}qu}q{$D<`<W>fiJournal Artificial Intelligence Research 3 (1995) 119-145Submitted 3/95; published 8/95Using Qualitative Hypotheses Identify Inaccurate Dataqi-zhao@is.aist-nara.ac.jpnishida@is.aist-nara.ac.jpQi ZhaoToyoaki NishidaGraduate School Information ScienceNara Institute Science Technology8916-5, Takayama-cho, Ikoma-shi, Nara 630-01, JapanAbstractIdentifying inaccurate data long regarded significant dicult problem AI. paper, present new method identifying inaccurate databasis qualitative correlations among related data. First, introduce definitionsrelated data qualitative correlations among related data. put forward newconcept called support coecient function (SCF ). SCF used extract, represent,calculate qualitative correlations among related data within dataset. proposeapproach determining dynamic shift intervals inaccurate data, approachcalculating possibility identifying inaccurate data, respectively. approachesbased SCF . Finally present algorithm identifying inaccurate datausing qualitative correlations among related data confirmatory disconfirmatory evidence. developed practical system interpreting infrared spectra applyingmethod, fully tested system several hundred real spectra.experimental results show method significantly better conventionalmethods used many similar systems.1. Introductionmany problems artificial intelligence, inferences drawn basis interpretationanalysis measured data. However, measured data inaccurate, interpretinganalyzing dicult. diagnosis signal analysis, example, generalreasoning method compare measured data reference values (Reiter, 1987; Shortliffe& Buchanan, 1975). measured data accurate due noise unforeseenreasons, comparison measured data reference values leaduseful conclusion. rule like \if strong peak 3000 cm01 - 3100 cm01infrared spectrum unknown compound, unknown compound may containleast one benzene-ring" may work ideal cases. However, rule work generalcases. example, spectral data inaccurate, e.g., measured peak 3000cm01 - 3100 cm01 strong peak medium one, measured strong peakexactly located 3000 cm01 - 3100 cm01 slightly shifted, rule mayapplied.practical problems, especially data rich problems diagnosis interpretation, measured data often inaccurate. One reason measuring methodserror-prone. example, patient's temperature blood-pressure may inaccuratelymeasured entered, witness may inaccurately describe features criminal.reason real data noise-free. example, among receivedc 1995 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiZhao & Nishidasignals, may noise mixed up, worse, infrared spectral data (peaks)may noisy, i.e., peaks may affected noise factors.Identifying inaccurate data long regarded significant dicult problemAI. Many methods proposed deal problem. Fuzzy logic providesmathematical framework representation calculation inaccurate data (Zadeh,1978). fuzzy logic, reference value x0 associated fuzzy interval 4x.measured data item falls [x0 0 4x; x0 + 4x], identified referencevalue corresponding membership degree. Probability theory possibility theoryalso widely used handling inaccuracy uncertainty (Dempster, 1968; Duda, Hart,& Nilsson, 1976; Pearl, 1987; Shafer, 1976; Shortliffe & Buchanan, 1975).methods commonly used AI systems. way applying them, however, dependsnature domain problems, yet standard generally acceptedmethod thus far.present method identifying inaccurate data basis qualitative correlations among related data. method based essential considerationdata items within dataset qualitatively dependent: set data may describephenomenon, refer behavior. example, patient's temperature, bloodpressure symptomatic data ect patient's disease, couple peaksinfrared spectrum indicate presence partial component. call dependencyamong data within dataset qualitative correlations among related data1 . consideringqualitative correlations among related data, obtain confirmatory disconfirmatoryevidence identify inaccurate data. general, related data simultaneouslypresent absent, related data completely identified, dataenhance identification rest. example, benzene-ring create manypeaks besides strong peak 3000 cm01 - 3100 cm01 . peaks createdbenzene-ring related data qualitative correlations. peaks except3000 cm01- 3100 cm01 completely identified, benzene-ring quitelikely contained unknown compound. Therefore, inaccurate peak around3000 cm01 - 3100 cm01 may still identified. fact, spectroscopists frequently usefollowing knowledge addition rules given beginning section:strong peak around 3000 cm01 - 3100 cm01 , spectrum maypartially created benzene-rings |{ check peaks around 1650 cm01 , 1550cm01 700 cm01 - 900 cm01 make sure benzene-ring maypeaks time.central idea method find evidence identifying inaccurate dataconsidering qualitative correlations among related data. idea common humanthinking. data except blood pressure patient show patientcertain disease, would naturally suspect blood pressure patientinaccurately entered. Similarly, peaks except one indicate partialcomponent present, would naturally suspect unmatched peak inaccuratelymeasured peak affected noise something else. acceptable solutionsmade assuming inaccurate data item reference value based qualitative1. Detailed definitions given later.120fiUsing Qualitative Hypotheses Identify Inaccurate Datacorrelations data item related data, inaccurate data item maycompensated hence identified.contributions include: (1) method assumes inaccurate data itemcertain reference value based qualitative correlations inaccurate dataitem related data, (2) algorithm crystallizes method, (3)practical system uses algorithm interpret infrared spectra.key point new concept called support coecient function (SCF ) extracting,representing, calculating qualitative correlations among related data. measureddata inaccurate, qualitative correlations among related data provide evidenceconfirming disconfirming hypothesis measured datareference values. approach determining dynamic shift intervals inaccurate data,approach calculating possibility identifying inaccurate data, algorithmidentifying inaccurate data proposed basis SCF , respectively.method requires assumptions advance, avoid inconsistency knowledge data bases. method identifies inaccurate data considering qualitative correlations among related data, quite effective ecient, especially caseproblems dependencies among data apparently exist. general, qualitative correlations among data always, less, extracted. worst casequalitative correlations known priori, method degenerates conventionalfuzzy method2 .developed practical system interpreting infrared spectra usingmethod (Zhao & Nishida, 1994). primary task system identify unknowncompounds interpreting infrared spectra. fully tested systemseveral hundred real spectra. experimental results show method significantlybetter traditional methods used many similar systems. rate correctness(RC ) rate identification (RI ) two important standards evaluatingsolutions infrared spectrum interpretation near 74% 90% respectively,former highest among known systems.following sections, first describe problem identifying inaccurate dataSection 2. Section 3 give definitions including concept support coecientfunction (SCF ) concepts based SCF . Section 4 introduce methodidentifying inaccurate data considering qualitative correlations among related data.Section 5 demonstrates application method knowledge-based systeminfrared spectrum identification, shows experimental results system. Relatedwork discussed Section 6. Conclusions addressed Section 7.2. Problem Descriptionpractical problems, measured data represented finite set:2. refer fuzzy methods use empirical fuzzy interval inaccurate data itemconventional fuzzy methods.121fiZhao & Nishida= fd1 ; d2 ; :::; dn g;reference values also represented finite set:RV = fr1 ; r2 ; :::; rN g:Suppose interpreting analyzing measured data carried basis so-called\if-then" rules premises comparisons RV like \if di = rj...", \if (ri 2 MD) ^ (rj 2 D) ...". accurate, mainoperation implied premises usually find corresponding reference valueRV data item D. However, inaccurate, operation becomescomplicated. case, dicult determine reference value inaccuratedata item corresponds to, e.g., measured data reference value may simplyidentified, others one may available.example, received signals known accurate, expected signal (reference value) found signal series (measured data), concludeexpected signal appear. However, received signals inaccurate,expected signal identified signal series, hard decide whetherexpected signal appear appears looks different due inaccuracy.currently known approaches dealing inaccurate data fuzzy logicprobabilistic reasoning mainly based quantitative similarity closenessmeasured data reference values. cases, however, identity qualitativefeatures effective reliable quantitative similarity closeness.Consider signal analysis again. inaccurate signal qualitative featuresexpected one interval frequency, signal may still identified eventhough quantitative features slightly different expected onestrength etc.; conversely, inaccurate signal may identified quantitativelysimilar expected signal qualitative features expectedone.discussed following points Section 1, (1) data items within datasetqualitatively dependent (i.e., related data), (2) qualitative correlationsamong related data, (3) qualitative correlations among related data enable us confirmdisconfirm identity qualitative features.Therefore, RV be, explicitly implicitly, divided finite groupsbasis qualitative dependencies among data, data group relatedother. example, RV divided R1 , R2 , ... Rk :RV = R1 [ R2 [ ::: [ Rk ;Rj = frjl j rjl2 RV; 1 l mg:qualitative correlations among related data Rj include: (1) data Rjsimultaneously present absent means reference values Rj122fiUsing Qualitative Hypotheses Identify Inaccurate Datacorresponding data MD, (2) presence rjp may enhance presence rjq ,absence rjp may depress presence rjq . Considering qualitative correlationsamong related data lead evidence identification inaccurate data.problem interpreting/analyzing inaccurate data make qualitative hypothesesD, words, find subset RV MD, corresponding D:(M D);(IN (MD) RV ):problem brie represented following predicate calculus:8di8Rj ((di @Rj ) ^ (Rj @M D) ! Rj (M D))3 ;\di@Rj " \Rj @MD" two essential qualitative predicates methodrepresent di possibly (qualitatively) belongs Rj (i.e., ? di 2 Rj ), Rj possibly(qualitatively) belongs MD (i.e., ? Rj D), respectively. Determining \A@B "based qualitative correlations among related data. work presented papermainly concentrated determining \di @Rj " \Rj @M D", realizingpredicate calculus.3. Preliminariesintroducing method, first put forward explain several new conceptssection.3.1 Qualitative Correlations among Related DataDefinition 3.1 Related data: data d1 , d2 , ..., dm describe common phenomenon,refer behavior simultaneously, treated related data.example, patient's temperature, blood pressure symptomatic datarelated data, features describing criminal also related data. phenomenon data within dataset related data apparent engineering.instance, two types related data infrared spectrum interpretationshown Figure 1. First, far single peak concerned, frequency (position) fi ,strength (height) si , width (shape) wi peak related data. Second, partialcomponent may create numerous peaks time. consider peakspartial component may create, peaks related data.Definition 3.2 Qualitative correlations among related data: di dj two related dataitems, presence di enhances presence dj , absence di depressespresence dj . kind effect called qualitative correlations among related data.3. Con icts (overlaps) (MD ) eliminated. discuss con ict-resolvingpaper, concentrate method identifying inaccurate data, i.e., ? di @Rj ? Rj @MD.Interested readers may refer paper Zhao (1994) specific discussion concerning problemcon ict resolution.123fiZhao & NishidafiwiFigure 1: Example related data spectrum interpretationConsider example spectrum interpretation again. spectral data inaccurate (i.e., measured peaks look like exactly referencepeaks), considering qualitative correlations among related data may lead qualitative evidence identification inaccurate data. example, suppose frequencypeak slightly different reference value, strength widthpeak reference values. frequency peak may stillidentified since related data support it. Similarly, peaks low frequency sections inaccurate, considering related peaks high frequency sections may help identifypeaks, vice versa.3.2 Support Coecient FunctionDefinition 3.3 Support coecient function (SCF): 0 1 data related di,support coecient function di calculates total effects related dataconsidering qualitative correlations di related data.Suppose (di ; dj ) represents qualitative correlation di dj ,support coecient function di defined as:SCFi = fi (Xj =1;j 6=i(di; dj ); m):SCFi directly depend many much related data support di .SCFi greater certain value given domain experts, related data tendsupport di ; otherwise, related data tend depress di .3.3 Evidence Based SCFSection 2, used \di @Rj " express di qualitatively identified Rj .Realizing \di @Rj " requires definition shift interval 4 Rj as:124fiUsing Qualitative Hypotheses Identify Inaccurate DataRj 6 4 = f(rjl 6 4) j l = 1; 2; :::; mg;definition possibility \di 2 Rj 6 4".formula similar fuzzy logic, contains completely differentmeanings. primary difference shift intervals dynamically determinedSCFi , fuzzy logic, fuzzy intervals usually provided domain expertsadvance calculated quantitative criteria.Definition 3.4 Shift interval: Shift interval dynamic region inaccurate data. Givenstandard fuzzy interval inaccurate data, shift interval di varies aroundstandard fuzzy interval basis SCFi . SCFi shows related datasupport di , shift interval di becomes wider standard fuzzy interval.hand, SCFi shows related data support di , shift intervaldi becomes narrower standard fuzzy interval.Definition 3.5 Evidence based SCFi : SCFi determines shift interval di , is,SCFi determines widely di allowed shift. wider shift interval,easily di identified. Therefore, SCFi provides confirmatory disconfirmatory evidenceidentifying di .4. Making Qualitative Hypotheses Inaccurate Datasection, introduce analyze method identifying inaccurate data.first discuss processes realizing two essential predicates method, \di @Rj "\Rj @MD" respectively. Then, present algorithm making qualitative hypothesesinaccurate data (i.e., realizing predicate calculus described Section 2).4.1 Predicate \di @Rj "di accurate, \di@Rj " equal \di 2 Rj ". reference value Rjcorresponds di (i.e., rjp 2 Rj rjp = di), di @Rj = . referencevalue corresponding di , di@Rj = F . di inaccurate, however, surewhether rjp corresponds di . case, \di@Rj " means di possibly (qualitatively)belongs Rj , words, rjp possibly (qualitatively) corresponds di . value\di @Rj " F , possibility \rjp = di " \di 2 Rj ".discussed Section 2 cases identity qualitative featuresrobust reliable quantitative similarity closeness. also discussedqualitative correlations among related data lead evidence identity qualitative features diagnosis interpretation. rjp (rjp 2 Rj ) assumed corresponddi, 0 1 reference values (rj1 , rj2 , ..., rjp01 , rjp+1 , ..., rjm ) related rjp ,0 1 reference values correspond certain data item MD,0 1 data items also related other. Therefore, qualitative correlationsdi 0 1 related data items MD considered.method first determines possibility \rjp = di " calculating similaritycloseness rjp di like conventional fuzzy methods, considers qualitative125fiZhao & Nishidacorrelations among related data obtain evidence updating possibility.qualitative correlations show related data support \rjp = di ", possibility\rjp = di " increase. qualitative correlations show related datasupport \rjp = di ", possibility decrease.4.1.1 Defining Support Coefficient FunctionSuppose rjq (rjq 2 Rj ) corresponds dt . rjq related rjp , dt related di .discussed, qualitative correlation di dt means dt exists,di enhanced; otherwise, di depressed.first define qualitative correlation two related data items, di dt , as:ci (dt ) =(1 dt found MD satisfies: rjq 0 dt rjq +0 dt found satisfies: rjq 0 dt rjq +standard fuzzy interval inaccurate data, ci(dt) expresses qualitativecorrelation di dt . ci (dt )=1 means di enhanced since related dataitem dt found measured dataset, ci (dt )=0 means di depressedsince related data item dt found measured dataset. definitionci (dt ) simply based consideration data item identified, dataitem support related data items (i.e., coexisting data items).reference values Rj , define support coecient functionSCFi di based ci(dt) (t = 1; 2; :::; m; 6= i):SCFi =1+Pmt=1;t6=i ci (dt )0 < SCFi 1, SCFi expresses total qualitative correlations direlated data. words, SCFi ects support coecient rjpcorresponding di .= 1, SCFi = 1. > 1, SCFi direct ratio numberrelated data may identified D.4.1.2 Determining Dynamic Shift IntervalSuppose standard fuzzy interval inaccurate data, define dynamic shiftinterval di based SCFi as:0 1)do 2 SCF4di = (2m0 < 4di < 2do , 4di direct ratio SCFi .= 1, SCFi = 1, 4di = . words, qualitative correlationsamong data known priori, SCFi = 1 4di = . case, methoddegenerates conventional fuzzy method.126fiUsing Qualitative Hypotheses Identify Inaccurate Datafixed, related data identified, greater SCFi is, thereforegreater 4di is. SCFi fixed, 4di depends number related data.Table 1 shows relation among 4di , SCFi .4di1////10.8SCFi 0.50.30.1101.9000do1.5200do0.9500do0.5700do0.1900do501.9800do1.5840do0.9900do0.5940do0.1980do1001.9900do1.5920do0.9950do0.5970do0.1990do5001.9980do1.5984do0.9990do0.5994do0.1998do10001.9990do1.5992do0.9995do0.5997do0.1999doTable 1: Relation among 4di , SCFidraw following properties formulas.Property 1: m, related data identified, greater SCFiis; otherwise, smaller SCFi is.Property 2: m, greater SCFi , greater 4di . words,related data support di , widely di allowed shift.Property 3: SCFi, greater m, less 4di varies along m.words, greater number related data, less single related data itemaffect di .Property 2 Property 3 illustrated Figure 2.2doSCFi = 1diSCFi = 0.5SCFi = 0.1SCFi = 0.30Figure 2:4di versus different SCFiProperty 4: 4di linear relation SCFi . slope equal to, greater 1.5,means 4di heavily depends SCFi .127fiZhao & NishidaProperty 5: Along increase m, slope increases slightly.words, 4di depends number related data support di , rathertotal number related data.Property 4 Property 5 illustrated Figure 3.2dm=100dim=2m=1000Figure 3:1SCFi4di versus SCFi different4.1.3 Calculating Value Predicate \di @Rj "value \di @Rj " equal possibility \rjp = di " calculatedusing following formula:= 1 0j di 0 rj j4dip1.glance, representation looks like membership degree \rjp 0 4didi rjp + 4di" fuzzy logic. However, meaning completely different, 4dineither provided domain experts determined quantitative similarity closeness.4di determined basis qualitative correlations among related data.qualitative correlations among related data considered, 4di , possibilityjd 0r j1 0 jp . consideration qualitative correlations, possibility updated.Two new properties drawn formula calculating .Property 6: di, greater 4di , greater . words,wider dynamic shift interval, greater value \di @Rj ". Formally, 4d00i4d0i 4di , 00i 0i .Property 7: SCFi provides qualitative evidence accepting rejecting di rjp sincedirect ratio 4di, 4di direct ratio SCFi.128fiUsing Qualitative Hypotheses Identify Inaccurate DataProperty 6 Property 7 illustrated Figure 4.1uiuiui0rjpdidididiFigure 4: Value \di@Rj " versus various 4diprocess realizing \di @Rj " calculating value \di @Rj "expressed following procedure.Procedure di@Rjselect rjp f rom Rj ;SCFi = 0;di = rjp fSCFi = 1;= 1;gelsefrjl 2 Rj (l = 1; :::; m; l 6= p)fcalculate ci (dt )4 ;SCFi = SCFi + ci (dt );ggSCFi = (1 + SCFi )=m;4di = 2 SCFi 2 (2m 0 1)=m;= 10 j di 0 rjp j =4di;4. dt stands data item MD corresponds rjl .129fiZhao & Nishida> 0return i;elsereturn N ILend proceduredi identified certain possibility (i.e., > 0), procedure returns(i.e., value i); otherwise, procedure returns F .4.2 Predicate \Rj @M D"accurate, \Rj @M D" equal \Rj D". reference valuesRj identified MD, Rj @MD = ; otherwise Rj @M = F .inaccurate, however, \Rj @M D" means Rj possibly (qualitatively) subset D.value \Rj @MD" F , possibility reference valuesRj identified D.l > 0 (l = 1; 2; :::; m), Rj regarded subset certainpossibility. Let s1 , s2 , ..., sm priorities reference values Rj ,value \Rj @MD" calculated based 1 , 2 , ..., using followingformula:Pm 2l=1 lRj @MD = lP;l=1 ll > 0;l > 0:Suppose calculated using procedure di @Rj , process realizing\Rj @MD" calculating value \Rj @M D" expressed simple procedure.Procedure Rj @MP = si 2 ;= si ;f l = 1 (l 6= p)fl = dt @Rj ;l > 0fP = P + sl 2 l ;= + sl ;gelsefggP = 0;exit;P > 0return P=S ;elsereturn N ILend procedure130fiUsing Qualitative Hypotheses Identify Inaccurate DataRj identified subset certain possibility (i.e., P=S ),procedure returns (i.e., value P=S ); otherwise, procedure returns F .4.3 Algorithm Making Qualitative Hypotheses Inaccurate Datagive following algorithm interpreting/analyzing measured data based procedure di @Rj procedure Rj @MD. measured data accurate,algorithm identify inaccurate data items considering qualitative correlations amongrelated data.Algorithm aking -Qualitative-Hypotheses(MD) = ;;f = 1 n fj = 1 k fP (Rj ) = 0;di @Rj (i:e:; Procedure di @Rj )Rj @M (i:e:; Procedure Rj @M D) fRj ! (MD);P (Rj ) = Rj @MD;gggendendendend fend algorithmalgorithm, P (Rj ) represents value \Rj @MD". algorithm actuallyrealization predicate calculus: 8di8Rj ((di @Rj ) ^ (Rj @M D) ! Rj (MD)).measured data item fd1 , d2 , ..., dn g, algorithm searches fR1 , R2 , ...,Rk g once. Rj (Rj = frj1 ; rj2 ; :::; rjm g), algorithm checks n 0 1 measureddata items times, 0 1 reference values n times. Therefore, blindsearch, number operations (at worst): n 2 k 2 [m 2 (n 0 1) + n 2 (m 0 1)] =2 2 k 2 2 n2 0 k 2 n2 0 k 2 2 n. Since k two constants, complexityalgorithm O(n2 ).5. Application Infrared Spectrum Interpretationdeveloped knowledge-based system interpreting infrared spectra applyingproposed method, fully tested system several hundred real spectra.experimental results show proposed method significantly betterconventional methods used many similar systems.131fiZhao & Nishida5.1 Infrared Spectrum Interpretationprimary task infrared spectrum interpretation identify unknown objectsinterpreting infrared spectra. paper, limit problem interpretationinfrared spectra compounds determine composition unknown compounds withoutloss generality.Selecting infrared spectrum interpretation domain applicationfollowing reasons:1. Interpreting infrared spectra significant problem academic researchindustrial application. example, chemical science engineering, interpreting infrared spectra compounds effective way identify unknowncompounds, analyze composition purity compounds (Colthup, Daly,& Wiberley, 1990).2. Interpreting infrared spectra dicult problem. First, spectral data hugequantity, complex representation. Second, symbolic reasoningnumerical analysis needed interpret infrared spectral data (Puskar, Levine, &Lowry, 1986; Sadtler, 1988).3. Interpreting infrared spectra typical problem dealing inaccurate data sincespectral data often inaccurate. often shift theoretical values duevarious reasons. example, following assertion spectrum interpretation:high frequency peak partial component P Cff located Fi .practice, however, peak P Cff may irregularly shift around Fi due noiseunforeseen reasons. assertion used identify real spectra,uncertainty arises.5.2 Applying Proposed Method Infrared Spectrum InterpretationInterpreting infrared spectra special problem diagnosis. Suppose infrared spectrum unknown compound thresholded represented finite set peaks(i.e., measured dataset MD):Sp = fp1 ; p2 ; :::; pn g;every peak consists frequency (position) f , strength (height) s, width(shape) w, respectively:pi = (fi; si ; wi )= 1; 2; :::; n:fi , si wi refer peak pi , related data. firstkind related data infrared spectrum interpretation.132fiUsing Qualitative Hypotheses Identify Inaccurate DataSuppose finite partial components (i.e., reference values RV ):P C = fP C1 ; P C2 ; :::; P Ck g= ffpj1 ; pj2 ; :::; pjm g j j = 1; 2; :::; kg= ff(fjp ; sjp ; wjp ) j p = 1; 2; :::; mg j j = 1; 2; :::; kg.fjp , sjp wjp also refer reference peak pjp , first kindrelated data well.spectroscopic knowledge interpreting infrared spectra usually expressed \ifpi equal pjp , pi may created partial component P Cj ". \pi equalpjp " represents fi , si, wi equal fjp , sjp , wjp respectively.first kind related data following qualitative correlations:1. fi , si wi identified simultaneously, is,fi fjp , si sjp wi wjp ,si sjp , fi fjp wi wjp ,wi wjp , fi fjp si sjp .2. related data support other. example, fi si identified,enhance identification wi . Conversely, fi siidentified, weaken identification wi .method identifying fi , si wi based qualitative correlations amongformalized following predicate calculi, respectively:8fi 8pj ((fi @pj ) ^ (pj @pi ) ! pi created P Cj ),8si 8pj ((si@pj ) ^ (pj @pi ) ! pi created P Cj ),8wi 8pj ((wi @pj ) ^ (pj @pi ) ! pi created P Cj ),ppppppppp\pi created P Cj " means fi , si wi qualitatively identifiedfjp , sjp wjp .general, partial component may create finite peaks time. picreated P Cj , Sp partially created P Cj ; Sp partially created P Cj ,peaks P Cj may create contained Sp simultaneously. Therefore,peaks created partial component also related data. second kindrelated data infrared spectrum interpretation.second kind related data following qualitative correlations:1. peaks partial component identified simultaneously, is,pi pjp , pjl2 Sp(l = 1; 2; :::; m; l 6= p).2. peaks created partial component support other. example,peaks partial component identified, peaksenhance identification rest peaks. Conversely, peakspartial component identified, identification rest peaksdepressed.133fiZhao & Nishidamethod identifying related peaks based qualitative correlationsformalized following predicate calculus:8pi 8P Cj ((pi @P Cj ) ^ (P Cj @Sp) ! P Cj (Sp)).5.3 System Interpreting Infrared Spectrasystem implemented C MS-WINDOWS. Figure 5 shows data owdiagram system.KnowledgeBasespectroscopicknowledgeinputHC HHsolutionINFERENCE ENGINEreferencevaluesSp: Unknown Infrared SpectrumDataBasePCaPCbCOCPCcIN(Sp): Interpretation SpFigure 5: Data ow diagram systeminput data system infrared spectra unknown compounds,solutions partial components input spectra may contain. inferencesbased qualitative features spectral data qualitative correlations among relateddata, system gain high correct interpretation performance noisy spectral data.mentioned before, two types related data infrared spectrum interpretation: features single peak (i.e., fi , si wi pi), peakssingle partial component (i.e., p1 , p2 , ... pm ). inference engine systememploys proposed method types related data inaccuracy arises.5.4 Examplediscuss performance system following example. Figure 6 showsinfrared spectrum unknown compound. spectrum hard interpretsince peak arrow (named p1 ) shifts substantially. system correctly identifiesp1 created partial component benzene-ring.contrast, many similar systems correctly identify peak (Clerc, Pretsch,& Zurcher, 1986; Hasenoehrl, Perkins, & Griths, 1992; Wythoff, Buck, & Tomellini,1989) since peak benzene-ring frequency position (named pb1 )strong peak (i.e., sb1 > 1:000) according spectroscopic knowledge, medium one(s1 = 0:510) case example. Systems based conventional fuzzy methodsusually assume fuzzy interval inaccurate peak, determine membershipdegree inaccurate peak fuzzy interval. Suppose reference valuestrong peak 1:000, fuzzy interval strong peak 0:300 (Colthup, Daly,134fiUsing Qualitative Hypotheses Identify Inaccurate Data& Wiberley, 1990), peaks strength 1 6 0:300 regarded strongpeaks. Obviously, conventional fuzzy methods, possibility p1 strong peakzero, i.e., benzene0ring (s1 ) = 0.Inferring basis qualitative correlations among related data, system makescorrect interpretation spectrum. following two cases, introduceinference process system, time demonstrate use methodidentifying inaccurate data.Strength (Absorbance)0.0001.2004000Frequency(cm1)600Figure 6: example infrared spectrum5.4.1 Case I: Considering First Kind Related Datafrequency (position) width (shape) p1benzene-ring, possibility f1 identified fb1 100% (i.e., benzene0ring (f1 ) = 1),possibility w1 identified wb1 also 100% (i.e., benzene0ring (w1 ) = 15 .discussed before, f1 , s1 w1 related data, obtain confirmevidence identifying s1 considering qualitative correlations among s1 , f1 w1 :benzene0ring (f1 ) = 1,so, cs1 (f1 ) = 1 (cs1 (f1 ) represents qualitative correlation s1 f1 ),benzene0ring (w1 ) = 1,so, cs1 (w1 ) = 1 (cs1 (w1 ) represents qualitative correlation s1 w1 )so, SCFs1 =1+23= 1,4s1 = (601)23 0:300 2 1 = 0:500,:510 = 0:02.s1 @pb1 = 1 0 100:05005. 3 (d) means possibility identified conventional fuzzy methods, i.e., SCFconsidered.135fiZhao & Nishidaconsidering SCFs1 , possibility p1 regarded strong peak benzenering increases 0 0:02. possibility, 0:02 may different 0:04 0:06,0:02 significantly different 0. Many near-misses may handled negligiblepossibility. example, systems based fuzzy methods (Clerc, Pretsch,& Zurcher, 1986), impossible identify p1 \strong" (i.e., benzene0ring (s1 ) = 0),considering qualitative correlations among related data makes possible althoughpossibility 0:02.mentioned before, f1 w1 reference values, f1 @pb1 = 1,w1 @pb1 = 1.Suppose priorities f1 , s1 w1 2, 1 1 respectively, possibilityp1 identified pb1 is:1 = pb1 @p1 =2 2 1 + 0:02 + 1= 0:755:45.4.2 Case II: Considering Second Kind Related Dataprocess considering second kind related data quite similar.got possibility p1 created benzene-ring 1 (1 = 0:755).Suppose benzene-ring create peaks: fpb1 , pb2 , ..., pbm g, peaksrelated other. p1 created benzene-ring, Sp partially createdbenzene-ring, i.e., benzene-ring contained unknown spectrum; Sppartially created benzene-ring, 0 1 peaks benzene-ringalso identified.using procedure obtaining 1 , get 2 , 3 , ... well.According method, qualitative correlation two related peaks, pi pj ,defined as:ci (pj ) =(j 0:5j < 0:5:10SCFi =1+Pmj =1;j 6=i ci (pj );0 < SCFi 1:Let = 1,4di = 2mm0 1 2 SCFi ;0 < 4di < 2;pi @benzene 0 ring = 1 01 04di ;136pi @benzene 0 ring 1:fiUsing Qualitative Hypotheses Identify Inaccurate DataRoughly, SCFi > 0:5, related peaks tend support pi . related peakssupport pi , 4di > 1. 4di > 1, pi @benzene 0 ring > .Table 2 shows relation among pi @benzene 0 ring, 4di .pi @benzene 0 ring4di1.31.110.90.71111110.80.8460.8180.80.7780.7140.50.6150.5450.50.4440.2860.30.4620.3640.30.222000.2310.0910-0.111-0.429Table 2: Relation among pi @benzene 0 ring, 4diexample, SCF1 = 0:850, 4d1 = 1:658,p1 @benzene 0 ring = 1 01 0 0:755= 0:852:1:658Therefore, possibility p1 identified pb1 increases 0:755 0:852 duequalitative correlations among related peaks. process similar probabilitypropagation probabilistic reasoning. identifying p1 hypothesis, qualitativecorrelations among related data p1 pieces evidence.peaks benzene-ring identified, possibility benzenering contained Sp finally calculated employing method describedSection 5.4.1.5.5 Analysis Experimental Resultscompare two methods experiments. first method (called \AF ") conventional fuzzy method used similar systems (Clerc, Pretsch, & Zurcher, 1986;Wythoff, Buck, & Tomellini, 1989). use AF , reference value must associatedfuzzy interval dealing inaccuracy. reference values fuzzy intervalsempirically determined (Colthup, Daly, & Wiberley, 1990).Table 3 lists reference values fuzzy intervals used AF .137fiZhao & Nishida2960 6 15cm012870 6 15cm011450 6 10cm01...benzene 0 ring 3055 6 25cm011645 6 10cm011550 6 30cm011450 6 3cm01...0CH2 0 OH 3635 6 5cm013550 6 25cm01...CH3strong 6 0:3sharp 6 1strong 6 0:3sharp 6 1medium 6 0:3 sharp 6 0:5strong 6 0:3medium 6 0:3medium 6 0:3medium 6 0:3sharp 6 1:5sharp 6 0:5sharp 6 1sharp 6 0strong 6 0:3strong 6 0:3broad 6 1sharp 6 1Table 3: reference values fuzzy intervalsmembership function AF is:r (d) = maxf0; 1 0j 0 r j g;4dmeasured data item, r reference value, 4d fuzzy interval r,0 r (d) 1.second method (called \AF 3 ") proposed method. AF 3 uses reference values fuzzy intervals AF , fuzzy intervals AF 3 usedstandard fuzzy intervals based dynamic shift intervals determined considering qualitative correlations among related data.AF AF 3 use reference values empirical fuzzy intervals. formulacalculating membership degrees AF (i.e., r (d) = maxf0; 1 0 jd40drj g) also similarjd 0r jformula calculating possibility AF 3 (i.e., = 1 0 i4dijp ). However, AF , 4dsimply empirical fuzzy interval, AF 3 , 4di dynamic shift interval basedqualitative correlations among related data.tested system several hundred real infrared spectra organiccompounds. experimental results show AF 3 significantly better AF .Table 4 lists part experimental results first column indicatessolutions obtained AF ; second column indicates solutions obtained AF 3 ;third column shows correct solutions.138fiUsing Qualitative Hypotheses Identify Inaccurate DataAF (Without SCF)2/3CH2CH3CH2CAF* (With SCF)[CH2]nCH2CH3[CH2]nCH2CH3 [CH2]nCH2CH3CCH2CH3CH3CH2CH3CH3CH2CHCH3CH3CH2CH3CH3CH2CCH3CH2CHCH3CH21/3>C=CH4/5C=CHCH2CH3>C=CH1/23/4CH2CClClCH3NH2CH3CH3CH3>C=CH2/2CH2CH3CH32/3CH2CH3CH2CH32/3CH3>C=CHCH3>C=CH[CH2]nC=CHCH2CH3CH3CH3C=CCNH2>C=CHCH2CH3>C=CH>C=CHCH[CH3]2CH2CH3CCHCH3CH[CH3]2CH[CH3]22/3CH2CH2CH2CHCH3[CH2]n C=CH>C=CHCH3CH3CH3CH3[CH2]nCCHCH3CH32/3CH2CH3CH33/4CHCCH3CH3CH32/3Correct SolutionsClCH2CH3C=CCClCCH3ClClCNH2: identified PC set PC set correct solution(in case, RI=1)n: identified PC set PC set correct solution(the number indicates RI)Table 4: Experimental results AF AF 3139fiZhao & Nishidatwo important standard metrics evaluating solutions infrared spectruminterpretation:Definition 5.1 Rate correctness (RC): rate identified partial component setexactly partial component set correct solutions.Definition 5.2 Rate identification (RI): rate partial componentscorrect solutions identified.Table 5 shows comparison AF AF 3 two standard metrics.RC (error-rate) RI (error-rate)AF0.455(0.545)0.812(0.188)AF 30.736(0.264)0.894(0.106)Table 5: Evaluation AF & AF 3 RC RITable 5 demonstrates RC RI increase integrating SCF ,RC increases significantly. reason although AF identify partialcomponents unknown compounds, rate identify partial componentsunknown compounds low always partial components whosemeasured peaks seriously shift reference values.5.6 Comparison Related SystemsRelated systems mainly fall following four categories: (1) Systems based Y/Nclassification, (2) Systems based fuzzy logic, (3) Systems based pattern recognition,(4) Systems based neural networks.5.6.1 Systems Based Yes/No Classificationmethod commonly used spectroscopists practice numerical analysis (Colthup,Daly, & Wiberley, 1990). Numerical analysis primarily based comparison spectral data reference values. Reference values usually regions like f requency :3615 6 5cm01 strength : 1:000 6 0:300. spectral data certain regions, answerclassification yes; otherwise, answer no.systems interpreting infrared spectra use method (Hasenoehrl, Perkins, &Griths, 1992; Puskar, Levine, & Lowry, 1986; Wythoff, Buck, & Tomellini, 1989).example, Wythoff's system, rules comparing spectral data following forms.PEAK(S)FREQUENCY:1700-1707WIDTH:SHARP BROADSTRENGTH:0.7-1.0ANSWER -YESACTION - ***advantage systems easy developdirectly use spectroscopic knowledge, need computation. However,problem systems applicable class compounds,pure compounds case seriously inaccurate spectral data, referencevalues (regions) ect inaccuracy. example, Hasenoehrl's system140fiUsing Qualitative Hypotheses Identify Inaccurate Datadistinguishing compounds containing least one carbonyl functionalitycompounds, although RI system 98% (naturally, RC available),Puskar's system identifying hazardous substances.fact, spectroscopists also use qualitative analysis specific cases additionformal spectroscopic knowledge, \if peaks 600 cm01 - 900 cm01 look likepeaks benzene-rings, peaks 3000 cm01 - 3100 cm01 quite likelycreated benzene-ring". Unfortunately, qualitative analysis hardly appliedsystems since used usual ways. contrast, system successfullyuse qualitative analysis like spectroscopists. way using method proposedpaper. result, system applicable compounds exhibit highperformance respect correctness.5.6.2 Systems Based Fuzzy LogicSince spectral data always inaccurate, representation spectroscopic knowledgequite like fuzzy logic, systems naturally use fuzzy logic techniquessimilar fuzzy logic (Clerc, Pretsch, & Zurcher, 1986). systems, fuzzy intervalssimilar regions described Section 5.6.1 given reference values,memberships inaccurate data calculated basis degreesinaccurate data fuzzy intervals. systems better describedSection 5.6.1 cases, degrees inaccurate data fuzzy intervalsnecessarily ect possibility inaccurate data reference values.example, Figure 7, dicult determine peak closer reference valueconsidering degrees peak peak b fuzzy interval.peakpeak breference value(fuzzy interval)Figure 7: Two peaks fuzzy intervalHowever, applying method proposed paper, problemeasily solved. discussed Section 5.6.1, practice spectroscopists also frequentlyuse knowledge correlations among peaks addition formalizable spectroscopicknowledge. kind knowledge essential method enables us usequalitative correlations among related data evidence identification inaccuratedata.compared fuzzy method used systems method Section5.5. far know, RC system highest among similar systems,RI system higher systems.5.6.3 Systems Based Pattern Recognitionsystems use pattern recognition techniques interpret infrared spectra (Jalsovszky &Holly, 1988; Sadtler, 1988), Sadtler popular commercial system.141fiZhao & Nishidasystem compares known patterns unknown ones, determines possibilityunknown pattern known one calculating quantitative similarity closenesstwo patterns.Unlike fuzzy techniques, pattern recognition considers group data (i.e., pattern)time. However, pattern recognition primarily based quantitative analysis.discussed many cases especially inaccuracy spectral dataslight, qualitative features spectral data much important quantitative ones.example, Figure 8 shows two simple cases. difference two patterns(a) smaller (b). viewpoint Sadtler, two patterns (a)closer (b). However, two patterns (b) maycases, two patterns (a) may case. reasonqualitative features (frequency positions peaks) two patterns (a) different.pattern 2differencepattern 1pattern 2pattern 1(a)difference(b)Figure 8: Quantitative differences patternsquantitative similarity closeness always sound, systems basedpattern recognition including Sadtler give concrete solutions. general,solutions systems series candidates users finallydecide possible one themselves. dicult compare systemssolutions systems quite loose, neither RC RIavailable. Sadtler, example, usually gives list known patterns associatedvalues quantitative differences unknown patterns knownones.5.6.4 Systems Based Neural NetworksRecently, neural networks applied infrared spectrum interpreting systems(Anand, Mehrotra, Mohan, & Ranka, 1991; Robb & Munk, 1990). Anand's system,neural network approach used analyze presence amino acids protein molecules.specific classification, RI Anand's system 87%, RCavailable. Robb's system, linear neural network model developed interpretinginfrared spectra. system general purpose like system. Without prior inputspectrum-structure correlations, RC Robb's system equal 53.3%.Although RC RI system higher two systems,still think using neural networks promising, especially model trainingsystem learning must. research concerning applying neural networkssystem left future.142fiUsing Qualitative Hypotheses Identify Inaccurate Data6. Related Work DiscussionIdentifying inaccurate data long regarded significant dicult problemAI. Many methods techniques proposed.Fuzzy logic provides mathematical fundamentals representation calculationinaccurate data (Bowen, Lai, & Bahler, 1992; Negoita & Ralescu, 1987; Zadeh, 1978).method primarily based fuzzy theory. compared conventional fuzzytechniques, advantages method include: (1) fuzzy intervals inaccurate datadynamically determined dynamic information used; (2) fuzzy intervalsbased qualitative features data qualitative correlations among related datasolutions robust. limitation method qualitativecorrelations among related data known advance, method degeneratesconventional fuzzy method. instance, SCF unavailable, two methods describedSection 5.5 become same.Pattern recognition provides techniques interpreting measured data group(Jalsovszky & Holly, 1988). pattern recognition methods, related data connectionsamong data considered. However, two preconditions must satisfiedcomplex data analysis pattern recognition successful. first preconditionobtain adequate data bases derive patternsneed recognize, second precondition demonstratesuitable metrics similarity patterns. patterns explicitly exist,measured patterns seriously noisy (e.g., fingerprint recognition), pattern recognitionmethods effective. However, patterns explicit, patterns change irregularlyimplies stable metrics determining similaritypatterns (e.g., spectrum interpretation), method practical robust.identifying inaccurate data, roles \di @Rj " \Rj @M D" quite similarrole subjective statements prior probabilities systems (Duda, Hart,& Nilsson, 1976; Shortliffe & Buchanan, 1975). However, essential differencemethod dynamically calculates values \di @Rj " \Rj @MD" qualitativecorrelations among related data need many assumptions beforehand,avoid inconsistency knowledge data bases. method also handlepossibility propagation among inference networks. Readers may noticedprocess considering second kind related data spectrum interpretation (see Section5.4.2).statistical samples sucient, subjective statements consistently obtained, probabilistic reasoning methods applied inaccurate data identification.statistical samples inaccurate data enough consistent subjective statements available, method effective.ongoing research related probabilistic reasoning consider interactionamong identified partial components. discussed before, spectroscopists frequentlyuse knowledge \if C6 H6 coexists CH3 , peaks CH3 around2900 cm01 may shift", \if -C-O-C- identified, strength peaksCH3 may change". Therefore, possible update possibilities identified partialcomponents considering interaction among them. Using probabilistic reasoninganalyze effects among identified partial components would help us identify143fiZhao & Nishidainaccurate data, also provide us reason data inaccurate.research experiments subject sequel paper.7. Conclusionspaper, presented new method identifying inaccurate databasis qualitative correlations among related data. first introduced new conceptcalled support coecient function (SCF ). Then, proposed approach determiningdynamic shift intervals inaccurate data based SCF , approach calculatingpossibility identifying inaccurate data, respectively. also presented algorithmusing qualitative correlations among related data confirmatory disconfirmatoryevidence identification inaccurate data. developed practical systeminterpreting infrared spectra applying proposed method, fully testedsystem several hundred real spectra. experimental results showproposed method significantly better conventional methods used many similarsystems. paper also described system experimental results.Brie y, novel work includes:1. method assumes inaccurate data item certain reference valuebasis qualitative correlations inaccurate data itemrelated data.2. algorithm crystallizes method.3. practical system uses algorithm interpret infrared spectra.AcknowledgmentsThanks editors anonymous reviewers JAIR helpful commentssuggestions, Chunling Sui Mitchell Bradt proofreading manuscript.research partially supported Horiba Ltd., Kyoto, Japan, first author wishesthank ASTEM Research Institute, Kyoto, Japan, worked researcher1991 - 1994.ReferencesAnand, R., Mehrotra, K., Mohan, C. K., & Ranka, S. (1991). Analyzing Images ContainingMultiple Sparse Patterns Neural Networks. Proceedings IJCAI-91, pp. 838-843.Bowen, J., Lai, R., & Bahler, D. (1992). Lexical Imprecision Fuzzy Constraint Networks.Proceedings AAAI-92, pp. 616-621.Clerc, J. T., Pretsch, E., & Zurcher, M. (1986). Performance Analysis Infrared LibrarySearch Systems. Mikrochim. Acta [Wien], II, pp. 217-242.Colthup, L., Daly, H., & Wiberley, S. E. (1990). Introduction Infrared Raman Spectroscopy. Academic Press.144fiUsing Qualitative Hypotheses Identify Inaccurate DataDempster, A. P. (1968). Generalization Bayesian Inference. Journal Royal Sta-tistical Society, B-30, pp. 205-247.Duda, R. O., Hart, P. E., & Nilsson, N. J. (1976). Subjective Bayesian Methods RuleBased Inference Systems. Proceedings National Computer Conference, pp. 1075-1082.Hasenoehrl, E. J., Perkins, J. H., & Griths, P. R. (1992). Expert System Based Principal Components Analysis Identification Molecular Structures VaporPhase Infrared Spectra. Journal Anal. Chem., 64, pp. 656-663.Jalsovszky, G. & Holly, G. (1988). Pattern Recognition Applied Vapour-Phase InfraredSpectra: Characteristics vOH Bands. Journal Molecular Structure, 175, pp.263-270.Negoita, C. V. & Ralescu, D. (1987). Simulation, Knowledge-Based Computing, FuzzyStatistics. Van Nostrand Reinhold Company.Pearl, J. (1988). Probabilistic Reasoning Intelligent Systems: Networks Plausible Inference. Morgan Kaufmann Publishers.Puskar, M. A., Levine, S. P., & Lowry, S. R. (1986). Computerized Infrared Spectral Identification Compounds Frequently Found Hazardous Waste Sites. Journal Anal.Chem., 58, pp. 1156-1162.Reiter, R. (1987). Theory Diagnosis First Principles. Artificial Intelligence, (87)32, pp. 57-95.Robb, E. W. & Munk, M. E. (1990). Neural Network Approach Infrared SpectrumInterpretation. Mikrochim. Acta [Wien], I, pp. 131-155.Sadtler Research Laboratories. (1988). Sadtler PC Spectral Search Libraries, Product Introduction & User's Manual.Shafer, G. (1976). Mathematical Theory Evidence. Princeton Uni. Press.Shortliffe, E. H. & Buchanan, B. G. (1975). Model Inexact Reasoning Medicine.Mathematical Biosciences, 23, pp. 351-379.Wythoff, B. J., Buck, C. F., & Tomellini, S. A. (1989). Descriptive Interactive ComputerAssisted Interpretation Infrared Spectra. Analytica Chimica Acta, 217, pp. 203-216.Zadeh, L. A. (1978). Fuzzy Set Basis Theory Possibility. Fuzzy Sets Syst., 1,pp. 3-28.Zhao, Q. (1994). Ecient Method Solving Constraint Satisfaction Problems IRSpectrum Interpretation. Proceedings 2nd International Conference ExpertSystems Development, pp. 165-170.Zhao, Q. & Nishida, T. (1994). Knowledge Model Infrared Spectrum Processing.Proceedings International Symposium Information Theory Applications, pp. 781-786.145fiJournal Artificial Intelligence Research 3 (1995) 25-52Submitted 8/94; published 6/95FLECS: Planning Flexible Commitment StrategyManuela VelosoPeter StoneDepartment Computer Science, Carnegie Mellon UniversityPittsburgh, PA 15213-3891 USAveloso@cs.cmu.edupstone@cs.cmu.eduAbstractevidence least-commitment planners eciently handle planningproblems involve dicult goal interactions. evidence led common beliefdelayed-commitment \best" possible planning strategy. However, recentlyfound evidence eager-commitment planners handle variety planning problemseciently, particular dicult operator choices. Resigned futilitytrying find universally successful planning strategy, devised plannerused study domains problems best planning strategies.article introduce new planning algorithm, flecs, uses FLExibleCommitment Strategy respect plan-step orderings. able use strategydelayed-commitment eager-commitment. combination delayed eageroperator-ordering commitments allows flecs take advantage benefits explicitlyusing simulated execution state reasoning planning constraints. flecs varycommitment strategy across different problems domains, also coursesingle planning problem. flecs represents novel contribution planningexplicitly provides choice commitment strategy use planning. flecsprovides framework investigate mapping planning domains problemsecient planning strategies.1. IntroductionGeneral-purpose planning long history research Artificial Intelligence. Severaldifferent planning algorithms developed ranging pioneering GPS (Ernst& Newell, 1969) variety recent algorithms SNLP (McAllester & Rosenblitt,1991) family. basic level, purpose planning find sequenceactions change initial state state satisfies goal statement. Planners useactions provided domain representations try achieve goal. Howeverdifferent planners use different means end.Faced variety different planning algorithms, planning researchers, including authors, increasingly curious compare different planning methodologies. Although general-purpose planning known undecidable (Chapman, 1987),common belief least-commitment planning \best," i.e., efficient planning strategy planning problems. belief based evidenceleast-commitment planners eciently handle planning problems involve dicultplan step interactions (Barrett & Weld, 1994; Kambhampati, 1994; Minton, Bresina, &Drummond, 1991). Delayed commitments, particular step orderings, allow planc 1995 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiVeloso & Stonesteps remain unordered interactions visible.1 similar situations, eagercommitment planners may encounter severe eciency problems early commitmentsincorrect orderings.Recently engaged investigation sorts planning problems wouldhandled eciently planning strategies. Since planning driven heuristics,identified different sets heuristics correspond different planning methods.designed sets planning domains problems test different planning strategies.studying impact different strategies different kinds planning problems,came across evidence eager-commitment planners eciently handle varietyplanning problems, particular dicult operator choices (Stone, Veloso,& Blythe, 1994). up-to-date state allows make informed planning choices,particularly terms operator alternatives available. similar situations, delayedcommitment planners may need backtrack incorrect operator choices (Veloso &Blythe, 1994). came believe planner consistently better othersacross different domains problems.Resigned futility trying find universally successful planning strategy,felt need study domains problems best suited planningmethods.2 order so, devised implemented planner useoperator-ordering commitment strategy along continuum between, one extremedelayed commitment, other, eager commitment. planner completelyexible along one dimension planning heuristics: operator-ordering commitments.main contribution paper completely describe planning algorithmput forth tool studying mapping heuristics domains problems.Rather risking possibility planner might get overlookedrelegated \architecture" section future paper, present flecs underlyingphilosophy contribution right.continuum heuristics explored planning algorithm liesoperator-ordering commitment strategies delayed-commitment eager-commitmentbackward-chaining planners, situate within broad range planningproblem solving methods. One possible planning strategy search possible statesreached initial state find one satisfies goal. method,called progression forward-chaining, impractical. often manyaccessible states world eciently search complete state space. alternative, several planners constrain search using regression, backward-chaining.Rather considering possible actions could executed initial statesearching recursively forward state space, search backwards goal.search driven set actions directly achieve goal.two main ways performing backward-chaining. Several planners regression searching space possible plans. Planners, noah, tweak, snlp,1. Least-commitment planners really delay commitments plan step orderings variable bindings.Throughout article use term delayed commitment contrast eager commitmentcontext step orderings.2. Similar concerns regarding different constraint satisfaction algorithms led recently designMulti-Tac architecture (Minton, 1993). system investigates given problem findcombination heuristics collection available ones solve problem ecient way.26fiflecs: Planning Flexible Commitment Strategydescendants (Chapman, 1987; McAllester & Rosenblitt, 1991; McDermott, 1978;Sacerdoti, 1977; Tate, 1977; Wilkins, 1984) plan-space planners use delayedcommitment strategy. particular, delay decision ordering operators longpossible. Consequently, planner reasons initial state setconstraints regressed goal. hand, planners gps,strips, prodigy family (Carbonell, Knoblock, & Minton, 1990; Fikes & Nilsson,1971; Rosenbloom, Newell, & Laird, 1990) use eager-commitment strategy.3 usebackward-chaining select plan steps relevant goals. eager-commitment planners make explicit use internal representation state world (their internalstate) order operators possible reason updated versionstate. trade risk eager commitment benefits using explicitupdated planning state.article introduce planning algorithm, flecs, uses FLExible Commitment Strategy respect operator orderings. flecs designed provide usplanning researchers framework investigate mapping domainsproblems ecient planning strategies. algorithm represents novel contributionplanning introduces explicitly choice commitment strategy.ability change commitment strategy makes useful studying tradeoffsdelayed eager commitments. flecs descendant prodigy4.0 currentimplementation directly top prodigy4.0. extends prodigy4.0 reasoningexplicitly ordering alternatives ability change commitmentstrategy across different problems domains, also course singleplanning problem.4article gradually introduces flecs. Section 2 gives top-level view algorithmdescribes different ways flecs makes use uniquely specified stateworld. Section 3 introduces concepts used flecs algorithm. provideannotated example illustrate details planning concepts defined. Section 4presents flecs's planning algorithm full detail explains algorithm step step.discuss different heuristics guide flecs's choices, particular exible choicecommitment strategy. analyze advantages disadvantages delayed eagerplan step ordering commitments. Section 5 shows specific examples planning domainsproblems devised, support need use flecs's exible commitmentstrategy. performed empirical analysis planning performance domains.corresponding empirical results demonstrate tradeoffs discussed show evidenceexible commitment necessary. Finally Section 6 draws conclusions work.3. Planners prodigy family include prodigy2.0 (Minton, Knoblock, Kuokka, Gil, Joseph, & Carbonell, 1989), NoLimit (Veloso, 1989), prodigy4.0 (Carbonell, Blythe, Etzioni, Gil, Joseph, Kahn,Knoblock, Minton, Perez, Reilly, Veloso, & Wang, 1992). NoLimit prodigy4.0, opposedprodigy2.0, require linearity assumption goal independence search spacescomplete (Fink & Veloso, 1994). also control commitment choices opposedearlier total-order planners.4. found needed new name algorithm flecs represents significant changephilosophy implementation prodigy4.0.27fiVeloso & Stone2. Top-Level View flecsprodigy4.0 flecs differ significantly state-of-the-art planning systemssearch solution planning problem combining backward-chaining (orregression) simulation plan execution (Fink & Veloso, 1994). back-chaining,commit total-ordering plan steps make use uniquely specifiedworld state. planners maintain internal representation state updatesimulating execution operators found relevant goal backward-chaining. Notesimulating execution planning differs interleaving planning execution,since option \un-simulating," rolling back, must remain open. Interleaved planningexecution generally done separate modules planning, monitoring, executing,replanning (Ambros-Ingerson & Steel, 1988). flecs either delay eagerly carryplan simulation. way, planning algorithm exibilityable delay operator-ordering commitments able use effects previouslyselected operators help determine goals plan next operatorsuse achieve goals. short, emulate delayed-commitment plannerseager-commitment planners.Table 1 shows top-level view flecs algorithm.1. Initialize.2. Terminate goal statement satisfied.3. Compute pending goals applicable operators.Pending goals yet-to-be-achieved preconditions operatorsselected plan.Applicable operators preconditions satisfiedcurrent state.5. Choose subgoal apply: (backtrack point)subgoal, go step 6.apply, go step 7.6. Select pending goal (no backtrack point) operator achieve (backtrack point); go step 3.7. Change state specified applicable operator (backtrack point); go step 2.Table 1: top-level view flecs. step numbers made correspondstep numbers detailed version algorithm presented Table 2(Section 4), refines steps adds additional necessary step 4.terms used table fully described along detailed versionalgorithm Section 4. section focus two main characteristics algorithm,namely use internal state exibility respect commitment strategies.28fiflecs: Planning Flexible Commitment Strategy2.1 Use Simulated Planning Stateflecs uses internal state least four purposes. First, terminates every goalgiven problem satisfied current version state (the current state):point, complete plan (the sequence operators transformed initial statecurrent state) created planning process stop. Second, everycycle, algorithm uses internal state determine goals need plannedalready achieved following means-ends analysis strategy. Unlikeplanners analyze possible effects operators maychanged initial state, flecs simply checks particular goal true currentstate.5 Third, planner uses state determine operators may applied:i.e., whose preconditions true state. Fourth, flecs use statechoose operator bindings likely achieve particular goalminimum planning effort (Blythe & Veloso, 1992). summary, referencealgorithm Table 1, flecs uses state determine:goal statement satisfied (step 2);goals still need achieved (step 3);operators applicable (step 3);operators try first planning (step 6).planners keep internal state, four steps require considerableplanning effort even attempted all. contrast, flecs performsteps sub-quadratic time. Furthermore, planners particularmethods choosing among possible operators achieve goal. particular usestate shown provide significant eciency gains prodigy4.0 (Veloso & Blythe,1994).Since flecs use state, makes big difference whether chooseschange state (apply operator) given time. advantage applying operatorinformed planning results four steps. However,choice apply operator involves commitment order operator operators yet applied. commitment temporary since planfound operator position, operator \un-applied" simplychanging internal state back previous status. One may argue requirement operators applied explicit order opens possibility exponentialbacktracking. However argument vacuous, planning undecidable (Chapman,1987). Due use state, flecs reduce likelihood requiring backtrackingoperator choice point. doing, may increase likelihood backtrackingoperator-ordering choice point. However, exibility able comeeither side tradeoff.5. Note since goal state fully instantiated, matching accomplishedconstant time goal using hash table literals.29fiVeloso & Stone2.2 Choice Commitment Strategiesorder control tradeoff eager delayed state changes, flecstoggle determines whether algorithm prefers subgoaling applying operatorstep 5. option flecs considers first may affect path search spaceconsequently planning eciency. ability accommodate different typessearch novel part algorithm. significance lies differencesubgoaling applying.difference subgoaling applying illustrated Figure 1. Subgoalingbest understood regressing one goal, backward chaining, using means-endsanalysis. includes choices goal plan operator achieve goal.seen Section 2.1, choices affected flecs's internal state. Thus,subgoaling without ever updating internal state (applying operator) leaduninformed planning decisions. hand, subgoaling extensively, flecsselect large set operators appear plan deciding orderapply them. flecs takes account con icts, \threats," among operatorsorders appropriately applying them.xCzGxxzCGCzGSubgoalingApplyingOperator achieves preconditionoperator true state C.preconditions operator x true state C.Applying x changes state C.Figure 1: diagram (Fink & Veloso, 1994) illustrates difference subgoaling applying. search node consisting \head-plan" \tailplan." head-plan contains operators already appliedchanged initial state \I" current state \C." tail-plan consistsoperators selected achieve goals goal statement \G"operators selected achieve preconditions operators,etc. figure shows planner could either subgoal apply givensearch node.Applying operator flecs's way changing current internal statefuture subgoaling decisions informed. However, applying operator commitment (temporary since backtracking possible) operator executed30fiflecs: Planning Flexible Commitment Strategyother. essential tradeoff eagerly subgoaling eagerlyapplying: eagerly subgoaling delays ordering commitments (delayed commitment),eagerly applying facilitates informed subgoaling (eager commitment).flecs switch (toggle) change behavior eager subgoalingeager applying vice versa time. feature significant improvement flecs prodigy4.0 predecessors. Since saw evidence neither delayed-commitment eager-commitment search strategies consistently effective (Stone et al., 1994), felt need provide flecs toggle. Thus, flecscombine advantages delayed commitments eager commitments.63. Illustrative Examplesection present example illustrates detail planning situationsarise general planning problem. Although planning may well understoodgeneral, past descriptions planning algorithms directly addressedsituations full detail. flecs algorithm designed handle situations.order describe flecs completely, need define several variablesmaintained algorithm proceeds. Since much easier understand algorithmone familiar concepts variables denote, present annotatedexample Figures 2 9 formally presenting flecs. recommendfollowing variables functions C , G , P , O, A, a, c change throughoutannotated example, according definitions:C represents current internal state planner. uses summarizedSection 2.1.G set goals subgoals planner aiming achieve.goals fringe subgoal tree. Goals G may goalsyet planned for, goals achieved (perhaps trivially) yetused operator needs one preconditions (i.e., operatorapplied yet).P set pending goals: goals G may need planned currentstate.stands set instantiated operators selected achieve goalssubgoals.set applicable operators: operators whose preconditions satisfiedcurrent state needed current state achieve goal.goal G, a(G) set ancestor goal sets { sequences goalscaused G become member G . Trivially, goal ancestorpreconditions operator selected achieve goal. a(G) set setsG different sets ancestors. concept become clearerexample.6. Section 5 discuss different heuristics guide choice discuss view toggleperfect focus learning.31fiVeloso & Stoneoperator O, c(O) set goals selected achieve { causes.Applying establishes member c(O). illustrated below, functionsc needed determine goals pending operatorsapplicable. analogous causal links used determine threatsplanners (Chapman, 1987; McAllester & Rosenblitt, 1991).sequence planning decisions example (Figure 2 Figure 9) designed illustrate uses flecs's variables functions. recommendbecoming familiar spending time carefully tracing values returning definitions throughout example. Note figures showtail-plan mention applied operators state changes text. Goalscircles: solid circles true dashed circles true currentstate. Operators boxes arrows pointing goals \produce,"i.e., goals operators selected achieve (their causes). turn,preconditions operators goals arrows pointing operators\consume" them. Operators applicable current state appear bold boxes.Changes functions c underlined captions.present example. Figure 2 shows initial planning situation,consider planning problem three literals goal statement, G1 , G2, G3 , i.e.,G = fG1; G2; G3g. one literal initial state, G7, i.e., C = fG7g. nonegoals true initial state, P = G . operators selected, i.e., = ;,therefore also operators applicable, i.e., = ;. point, sincetop-level goals, none goals ancestors: a(G1) = a(G2) = a(G3) = ;.applicable operators, next step must subgoal one pending goals.C = fG7gG = fG1; G2; G3gO=;P = fG1; G2; G3gA=;GGG123Figure 2: example: initial specification planning situation.Figure 3 shows planning situation flecs subgoals G1 G2 . Supposeoperator O1 , preconditions G6 G7 , selected achieve G1, O2 chosenachieve G2 indicated below. Note operators' preconditions replacecauses set fringe goals G ; since G7 true current state, includedset pending goals P . G1 cause O1, c(O1) = fG1g; similarly,32fiflecs: Planning Flexible Commitment Strategyc(O2) = fG2g. new goals nonempty ancestor sets: a(G6) = a(G7) = ffG1gg,a(G4) = ffG2gg. still applicable operators: O1 cannot appliedG6 62 C O2 cannot applied G4 62 C . Therefore, flecs subgoals again.C = fG7gG = fG3; G6; G7; G4g= fO1; O2gP = fG3; G6; G4gA=;GGG76412GGG123Figure 3: Resulting planning situation subgoaling G1 G2 .Figure 4 shows planning situation flecs subgoals G3 . Supposeoperator selected achieve G3 preconditions G4 G5 . c(O3) = fG3 g,a(G5) = ffG3gg. causes operators O1 O2 change, c(O1) = fG1gc(O2) = fG2g previous step. Similarly, a(G6 ) a(G7) remain unchanged.However, G4 two sets ancestor goals: a(G4) = ffG2g; fG3gg. understandneed keep ancestor sets, consider possibility G2 could achievedunexpectedly side-effect unrelated operator instead achieved O2planned for. case, G4 would remain pending goal since would neededachieve G3. Again, since applicable operators, flecs must subgoal onepending goals, i.e., G6, G4, G5.C = fG7gG = fG6; G7; G4; G5g= fO1; O2; O3gP = fG6; G4; G5gA=;G7GGG645123Figure 4: Resulting planning situation subgoaling G3 .33GGG123fiVeloso & StoneFigure 5 shows planning situation flecs subgoals G4 . Suppose O4| operator precondition G7 | selected achieve G4 . Since G7 truecurrent state, O4 first applicable operator. Note necessarily orderedO2 O3 since cause precondition operators. usual, causenew operator stored: c(O4) = fG4 g. addition, ancestors G7 must augmentedinclude two new ancestor sets: a(G7) = ffG1g; fG4; G2g; fG4; G3gg. Althoughapplicable operator, let us assume flecs chooses delay commitmentorder O4 first step plan subgoals pending goal.C = fG7gG = fG6; G7; G5g= fO1; O2; O3; O4gP = fG6; G5g= fO4gG7G4GG645G1G2G3123Figure 5: Resulting planning situation subgoaling G4 .Figure 6 shows planning situation flecs subgoals G5 . Suppose operator O4 also achieve G5 selected so. need updatecauses operator ancestors precondition: c(O4) = fG4; G5ga(G7) = ffG1g; fG4; G2g, fG4; G3g; fG5; G3gg. rather subgoaling last remaining pending goal (G6), let us apply O4 . Note decision corresponds earlycommitment terms ordering operators O1 , O4, operators later selectedachieve G6 unordered current planning constraints. flecs changesdelayed-commitment strategy eager-commitment strategy.C = fG7gG = fG6; G7gG6G= fO1; O2; O3; O4g11P = fG6g= fO4gG74GG4523GGFigure 6: Resulting planning situation subgoaling G5 .3423fiflecs: Planning Flexible Commitment StrategyFigure 7 shows planning situation flecs applied O4 . Since operator O4applied order achieve goals G4 G5, true current stateback fringe goal tree, i.e., C G . Notice stay Geventually \consumed" O2 O3. However, since truecurrent state, pending goals. Since G7 preconditionone selected operator, a(G7) = ffG1gg before. O2 O3 applicablepreconditions true current state thanks O4. Let us assumeflecs maintains eager-commitment strategy continues applying applicable operators. flecs orders O2 O3, since O3 deletes precondition O2 (effectsshown).C = fG7; G4; G5gG = fG6; G7; G4; G5gG= fO1; O2; O3g6G11P = fG6g= fO2; O3gG7GG4523GG23Figure 7: Resulting planning situation applying O4 Figure 6.Figure 8 shows planning situation flecs applied O2. Suppose that, althoughselected so, operator O2 achieves G1 side-effect. Perhaps O2conditional effect visible planner, perhaps O1 simply lookedpromising O2 operator achieve G1 time selected.C = fG7; G4; G5; G1; G2gG = fG6; G7; G4; G5; G2g= fO1; O3gP=;= fO3gG7GGG61G45G3G123Figure 8: Resulting planning situation applying O2 Figure 7.35fiVeloso & Stonecase, G1 C planning done longer needed: G6 longerpending goal, since sole ancestor already C . fortuitous achievement goalreason need use functions c adjust sets pending goalsP applicable operators A: would wasted effort flecs plan achieve G6.Note G6 precondition O3 well O1, would pending goal sincewould still relevant achieving G3 . point, ancestors G4 mustreset: a(G4) = ffG3gg. Since pending goals, flecs must applylast remaining applicable operator, O3.Figure 9 shows final planning situation flecs applied O3 . pointtop level goals true current state. Despite fact planningtree remains, flecs recognizes work done terminates.final plan O4, O2, O3 , sequence operators applied head-plan (notshown) corresponding steps Figures 7, 8, 9. posteriori algorithm (Veloso,Perez, & Carbonell, 1990) convert sequence partially ordered plan capturingdependencies: O4 ; fO2; O3g.C = fG7; G4; G5; G1; G2; G3gG = fG6; G7; G2; G3g= fO1gP=;A=;GG61GG7G123Figure 9: Final planning situation applying O3 Figure 8.4. FLECS: Detailed DescriptionAside variables functions introduced preceding section, needdefine four things presenting complete algorithm. First, Initial StateGoal Statement corresponding ground literals problem definition. Second, given operator O, pre(O), add(O), del(O) instantiated preconditions,add-list, delete-list respectively. flecs takes values straight domain representation, may include disjunctions, negations, existentially universally quantified preconditions effects, conditional effects (Carbonell et al., 1992).conditional effects, add(O) del(O) determined dynamically, using statetime applied. Third, \relevant instantiated operators could achieve G"(step 6) instantiated operators (operators fully-specified bindings)36fiflecs: Planning Flexible Commitment StrategyG 2 add(O) G positive goal G 2 del(O) G negative goal. Fourth, togglevariable determines avor search, described later.4.1 Planning Algorithmpresent flecs planning algorithm full detail Table 2.7 examining algorithm, notice fringe goals G , selected operators O, ancestor function a(G),cause function c(O), current state C maintained incrementally.hand, pending goals P , applicable operators A, toggle recomputed everypass algorithm.Step 1 initializes variables. beginning planning process,goals G goal statement, current state C initialstate, since operators yet selected, empty. ancestor functioncause function c initialized constant function maps everything ;.practice, domain set goals domain c set operatorsappear problem. However, since goals operatorsdetermined algorithm first called, must initialize functionsunrestricted domains.Step 2 termination condition. called time new operatorapplied. algorithm terminates successfully every goal G goal statement true,satisfied, current state C , i.e., G 2 C .step 3, sets pending goals applicable operators computed basedcurrent state. Pending goals goals planner may need plan for. Initially,pending goals fringe goals currently true trueinitial state.8 applicable operators selected operators whose preconditionstrue state.Then, step 4 computes pending goals P applicable operators activecurrent state. pending goal active long fringe subgoal treestill needs planned for. goal longer active every one ancestor setsleast one goal already achieved: purposes goalselected longer exist (as case G6 Figure 8). applicable operatoractive current state long would achieve goal still useful plan.applicable operator longer active causes either true currentstate longer active.Step 5 novel part algorithm. allows exible search strategywithin single planning algorithm. Since step, flecs yet terminated,must either active pending goals active applicable operators, i.e., P mustnon-empty. However, one other, choicemade. If, hand, P non-empty, either proceedstep 6 step 7. sake completeness, must keep options open;option flecs considers first may affect amount search required. changing7. detail algorithm allows reader carefully study re-implement flecs.8. Since planner cannot backtrack beyond initial state, must keep goals initial statepending goals sake completeness.37fiVeloso & Stone1. Initialize:C : current statea. G = Goal Statement.G : fringe goalsb. C = Initial State.P : pending goalsc. = ;.: instantiated operatorsd. 8G:a(G) = ;.: applicable operatorse. 8O:c(O) = ;.a: ancestor goal setsc: causes2. Terminate Goal Statement C .3. Compute applicable operators pending goals P :a. P = fG 2 G j G 62 C _ G 2 Initial Stateg.b. = fA 2 j pre(A) Cg.4. Adjust P contain active members:a. P = P , fP 2 P j 8S 2 a(P ):9G 2 s.t. G 2 Cg.b. = , fA 2 j 8G 2 c(A):[(G 2 C ) _ (8S 2 a(G):9G 2 s.t. G 2 C )]g.5. Subgoal Apply:a. Set reset toggle sub app, i.e. Set default delayed eager commitment.b. = ;, go step 6.c. P = ;, go step 7.d. Choose apply subgoal (backtrack point):toggle = sub ^ P 6 C , subgoal first: go step 6.toggle = app, apply first: go step 7.6. Choose goal P P (not backtrack point).Choose goal true Current State using means-ends analysis.a. Get set R relevant instantiated operators could achieve P .b. R = ;i. P = P , fP g.ii. P = ; fail (i.e., backtrack).iii. Go step 6.c. Choose operator R (backtrack point).Choose operator minimum conspiracy number, i.e. operatorappears achievable least amount planning.d. = [ fOg.e. G = (G , fP g) [ pre(O).f. c(O) = c(O) [ fP g.g. 8G 2 pre(O):a(G) = a(G) [ ffP g [ j 2 a(P )g.h. Go step 3.7. Choose operator (backtrack point interactions).Use heuristic find operators fewer interactions { similar one usedSABA heuristic.a. Apply A: C = (C [ add(A)) , del(A)b. = , fAg.c. 8G 2 pre(A):a(G) = a(G) , fS 2 a(G) j \ c(A) 6= ;g.d. G = (G [ c(A)) , fG 2 pre(A) j a(G) = ;g.e. c(A) = ;.f. Go step 2.0Table 2: full description flecs.380fiflecs: Planning Flexible Commitment Strategyvalue toggle, done pass loop, flecs changetype search works problem.pass body algorithm visits either step 6 step 7.subgoaling (step 6), active pending goal P chosen P . Note unlikecorresponding choice step 7, choice subgoals backtrack point. However,operators could achieve goal, another goal chosen (step 6b).Means-ends analysis used heuristic prefer subgoaling goals currentlytrue. Next, operator chosen could achieve chosen goal (step 6c).either new operator existing one Figure 6 (O4, alreadyselected achieve G4, also selected achieve G5). choice operator backtrackpoint. Unless heuristic provided, minimum conspiracy number heuristicused determine operator tried first (Blythe & Veloso, 1992). short,heuristic selects instantiated operator appears achievable leastamount planning.returning top loop, affected variables updated. First,added using set union operator never appears twice (step 6d).Second, O's preconditions added G , P removed (step 6e): Poperator selected achieve it, longer fringe subgoal tree. Third,cause augmented include P (step 6f). Fourth, ancestor sets O's preconditionsaugmented include sets goals comprised P ancestors (step 6g).explained Figure 4, ancestor sets must included. Finally, since statechanged all, termination condition cannot met. algorithm returns step 3.applying operator (step 7), applicable operator chosen A.heuristic analyzes applicable operators used choose best possible operator. One heuristic analyzes interactions operators identifyingnegative threats, similarly saba heuristic (Stone et al., 1994). short,heuristic prefers operators delete preconditions of, whose effectsdeleted by, operators. choice applicable operator backtrack pointorderings interacting applicable operators considered. Different orderingscompletely independent operators need considered. Completely independent operators interactions neither among ancestorsets. Since application one operator make difference applicationanother, need consider one ordering operators.chosen, promptly applied (step 7a). application involves changingcurrent state prescribed A. Note conditional effects, expandedpoint. Next, relevant variables updated. First, updating involves removingset selected operators (step 7b). Second, ancestors A's preconditionsancestor sets include (step 7c): needplanning. Figure 7 shows example precondition (G7) stillancestor remaining. Third, since applied, preconditions goalsreason longer fringe, causes (step 7d):unachieved must re-achieved. Fourth, case ever selected operatorachieve goal, c(A) reset ; (step 7e). Finally, since current statealtered, algorithm returns step 2 termination condition checked.39fiVeloso & Stone4.2 Discussion: Backtracking, Heuristics, PropertiesOne pay close attention placement backtrack points algorithm.particular, three: subgoal/apply choice step 5, choice operatorachieve goal step 6, choice applicable operator step 7. However,choice goal subgoal step 6, backtrack point prodigyalgorithm, backtrack point here. flecs need backtrack pointchoice apply apply operator given time left open step 5significantly different orders applying applicable operators considered step 7.explained previous subsection, different orderings completely independent operators considered. Nevertheless, orderings could lead solutionconsidered. Therefore, backtracking choice subgoal would cause redundantsearch. elimination backtrack point significant improvement flecsprevious implementations, namely NoLimit prodigy4.0. Note new backtrackpoints added offset eliminated backtrack point.flecs's explicit failure point step 6 occurs algorithm chosensubgoal, none pending goals relevant operators. failuresimplicit. is, backtrack point, choices unsuccessfully triedalgorithm backtracks. presented, algorithm terminates unsuccessfullyentire search space exhausted. causes failure, goal loops,state loops, depth bounds, time limits, incorporated mannerprodigy4.0 (Carbonell et al., 1992).choice point, heuristic determine branch try (first).step 6, goal chosen using means-ends analysis, operator minimumconspiracy number chosen achieve goal. step 7, choice mechanismsaba heuristic used determine applicable operator try first. step 5,toggle, changed time, determines whether default commitmentstrategy eager subgoaling eager applying. Note pending goalstrue Current State (or pending goals), planner may applyapplicable operator regardless value toggle. Similarly, applicableoperators, planner must subgoal even toggle indicates prefer applying. togglenew variable guide heuristic search existing choice point branching factortwo: represent addition new backtrack point. discussed throughout,provides flecs ability change commitment strategy. suggestedname, toggle one two values: sub app indicating eager subgoaling eagerapplying respectively.describe domain-independent heuristic could used guide changesvalue toggle. heuristic allow eager commitments reasonbelieve need backtrack resulting operator linearization.case, setting toggle app increase planning eciency convertingpartially-ordered set operators sequence leads single possible state,used guide subsequent planning. process equivalent starting newsmaller planning problem previous choices embedded state.situation described similar arises alpine systemconstructs ecient abstraction hierarchies (Knoblock, 1994). alpine guarantee40fiflecs: Planning Flexible Commitment Strategyplanning hierarchically using generated abstraction hierarchies lead backtracking across refinement spaces. Figure 10 illustrates flecs use abstractionplanning information control value toggle. toggle changes app particular abstract planning step completely refined abstraction hierarchies preservealpine's ordered monotonicity property, need backtrackresulting operator ordering. toggle change back sub, flecs continueplanning updated state information.Abstraction level1. Begintoggle=sub.S03. Continue planning:toggle=sub.Build partialorder planfirst stepabstract planS05. Continuedone...S12. Set toggle=app.Commit orderingcompute new state.S1S24. anotherstep abstractplan, commit again:toggle=app.Figure 10: Using abstraction information guide changes toggle.abstraction-driven heuristic one method exploiting choice point. Similarly,minimum conspiracy number heuristic saba heuristic waysguide choices instantiated operator applicable operator respectively.heuristics used always changed, claim ones providedefaults best possible: heuristic work time.planning algorithm present sound complete searches entiresearch space, using technique iterative deepening (Korf, 1985). flecs soundterminates reached goal statement result applyingoperators. is, application operator sequence returned final planentirely simulated time planner terminates. Thus preconditionsoperator true time operator executed, operatorsexecuted, goal statement satisfied. Consequently, flecs sound.Since step algorithm prunes search space, flecs iterativelyincreasing depth bound also complete: solution planning problem, flecsfind one. insure property, need show flecs consider possibleoperators may achieve goal well orderings interacting applicable operators.flecs maintaining backtracking points choice operator (step 6c)points operator ordering could affected: choice applicableoperator (step 7) choice whether subgoal apply (step 5d). Selecting41fiVeloso & Stone\apply" commits ordering operators currently applicable leastone currently applicable operators. Note completeness achieved even withoutmaintaining choice goals subgoal backtrack point (step 6), since regardlessorder operators chosen, applied according possibleinteractions (i.e., similarly resolving negative threats). Thus flecs's search spacesignificantly reduced prodigy4.0, still preserving completeness. (SeeAppendix formal proofs flecs's soundness completeness.)5. Empirical Analysis Heuristics Control Commitment Strategyseen, flecs introduces notion exible choice point delayedeager operator-ordering commitments. appreciate need exibility, considertwo extreme heuristics: always eagerly subgoaling (delaying commitment) alwayseagerly applying (eager commitment). former heuristic chooses subgoal longleast one active pending goal (Subgoal Always Applying saba);latter chooses apply long active applicable operators (SubgoaleVery Try Apply savta). section show empirical results demonstrateextremes lead highly sub-optimal search particular domains.Indeed, believe single domain-independent search heuristic perform welldomains (Stone et al., 1994). reason equipped flecsability use either extreme domain-independent heuristic moderateheuristic \in between" two: every iteration algorithm,opportunity change eagerly subgoaling eagerly applying vice versa. One coulddefine different heuristics guide choice, one could leave choice userinteractively.exibility search method provides algorithm ability search sensibly wide variety domains. algorithm exible susceptiblecoming across domains cannot handle eciently (Barrett & Weld, 1994; Veloso &Blythe, 1994; Kambhampati, 1994). flecs's exibility makes possible studyheuristics work best situations. addition, exible choice perfect learningopportunity. Since single search method solve planning problems, uselearning techniques help us determine experience search strategies try.illustrate need different search strategies, provide one real world situationeagerly subgoaling leads directly optimal solution, one eagerlyapplying so, one intermediate policy best. examplesintended exhaustive demonstration flecs's capabilities. Rather, examplesintended illustrate need consider problems traditional goal orderingproblems motivate potential impact flecs.5.1 Eagerly Subgoaling BetterFirst, consider class tasks following true: operators initiallyexecutable, must performed specific order operator deletespreconditions operators supposed executed earlier. instance,suppose single paint brush several objects need painteddifferent colors. paint brush washed fairly well, never comes completely42fiflecs: Planning Flexible Commitment Strategyclean. reason, ever use lighter paint darker paint, darkerpaint show painted object whole project ruined. Perhapsshade red darker shade green. paint chair red seatgreen legs, better paint legs first.Consider range colors ordered light dark: white, yellow, green, : : : ,black. Initially, could paint object color. However, start paintingsomething black, paint used. order represent situationplanner, created domain operators shown Table 3.Operator:preconds:adds:deletes:paint-white <obj>(usable white)(white <obj>)paint-yellow <obj>(usable yellow)(yellow <obj>)(usable white)...paint-black <obj>(usable black)(black <obj>)(usable white)(usable yellow)...(usable brown)Table 3: Example domain delayed step-ordering commitment results ecientplanning.Assume colors usable initial state. Since painting object certaincolor deletes precondition painting object lighter color, since precondition cannot re-achieved (no operator adds predicate \usable"), colors mustused specific order.painting domain real-world interpretation artificial domain Dm 1 introduced (Barrett & Weld, 1994). operators Dm 1 look like:Operator:preconds: fI gadds: fG gdeletes: fI jj < igSince operator deletes preconditions operators numerically it,operators applied increasing numerical order. Thus, A1 correspondsoperator paint-white, A2 corresponds paint-yellow, etc. used domainexperiments, run SPARC station. generated random problemsone fifteen goals: ten problems number goals. used150 problems test extreme heuristics. get data points, averagedresults ten problems number goals. raw datacontained online appendix. graph average time flecs took solveproblems versus number goals.shown (Stone et al., 1994),9 eagerly applying leads exponential behavior (asfunction number goals) domain, eagerly subgoaling, usingj9. began study new planning algorithm | named flecs| prodigy4.0. considerversion prodigy used (Stone et al., 1994) preliminary implementation flecs.43fiVeloso & Stoneoperator choice heuristic study, leads approximately linear behaviorbacktracking. problem eagerly applying that, example, goal G7solved G4, flecs immediately apply A7 backtrackunsuccessfully tries apply A4 . Eagerly subgoaling allows flecs build setoperators need apply order appropriately selectingapplication order avoids con icts threats. Figure 11 shows graphic comparisontwo different behaviors.Eager SubgoalingEager ApplyingTime: msec250020001500100050000246810 12Number Goals1416Figure 11: flecs's performance different heuristics domains Dm 1. Eager subgoaling applying correspond delayed commitments eager commitmentsrespectively.5.2 Eagerly Applying BetterNext, consider class tasks following true: several operators couldused achieve goal, operator used once. use similarexample, suppose trying paint different parts single object different colors.However, suppose using multiple brushes never come clean:use brush one color, never safely use again. instance, paintedgreen parts using brush1, would need use brush2 (or brush besides brush1)paint red parts. Table 4 represents operators new domain.Operator:paint-with-brush1<parts> <color>preconds: (unused brush1)adds: (painted <parts> <color>)deletes: (unused brush1): : : paint-with-brush8<parts> <color>(unused brush8)(painted <parts> <color>)(unused brush8)Table 4: Example domain eager step-ordering commitment use stateresults ecient planning.Note operator used color, since deletes precondition,used once. capture essential features domain artificialdomain called D1 -use-once. operators D1-use-once look like:44fiflecs: Planning Flexible Commitment StrategyfI gf< g >gfI gOperator:preconds:adds:deletes:operator achieve goal, since operator deletes precondition,used once. operator corresponds painting different brush.domain, better eagerly apply eagerly subgoal. Eagerlysubgoaling causes flecs select operator achieve goals.deterministic method selecting operators (such minimum conspiracy numberorder appearance domain specification tie-breaker), selects operator A1achieve two different goals. However, since could apply A1 once, would needbacktrack select different operator one goals. shown Figure 12, eagerlyapplying outperforms eagerly subgoaling case. generated resultsway results previous subsection.Eager SubgoalingEager ApplyingTime: msec5000400030002000100000246810 12Number Goals1416Figure 12: flecs's performance different heuristics domains D1-use-once.5.3 Intermediate Heuristicalways possible find good solutions either always eagerly subgoaling,first example, always eagerly applying, second, would needinclude variable toggle flecs: could simply eager-subgoal modeeager-apply mode. However, cases neither alternatives suces.Instead, need eagerly subgoal portions search eagerly applyothers. One heuristic changing commitment strategy abstraction-drivenmethod described Section 4.2. present domain use formheuristic.time consider class tasks following true: top-level goals takeleast three operators achieve, one irreversible, executed limitednumber times, restricts bindings operators. One representativeclass one-way rocket domain introduced (Veloso & Carbonell, 1993).sake consistency, however, present representative class domainspainting context. Suppose painting walls rollers. paint wall45fiVeloso & Stoneneed first \ready" wall, purpose example means decidewall needs painted designate color roller paint wall. Nextmust fill selected roller appropriately colored paint. paintwall. Unfortunately, limited supply rollers never become cleanfilled paint, must clean selected paint wall.reason, must ready walls want paint rollerfill roller paint. reader familiar one-way rocket domain,\fill-roller" operator analogous \move-rocket" operator domain:executed due limited supply fuel, must executedfully loaded. Table 5 shows possible set operators painting domain.Operator:designate-rollerfill-rollerpaint-wall<wall> <roller> <color> <roller> <color> <wall> <roller> <color>preconds: (clean <roller>)(clean <roller>)(ready(needs-painting <wall>)(chosen<wall> <roller> <color>)<roller> <color>) (filled-with-paint<roller> <color>)adds: (ready(filled-with-paint(painted <wall> <color>)<wall> <roller> <color>) <roller> <color>)(chosen <roller> <color>)deletes:(clean <roller>)(ready<wall> <roller> <color>)(needs-painting <wall>)Table 5: Example domain exibility commitments results ecient planning.given domain representation, flecs dicult time apparently simple problems uses search strategy throughout entire search.example, consider problem five walls two rollers (equivalent problemone-way rocket domain five objects two destinations):Initial State(needs-painting wallA)(needs-painting wallB)(needs-painting wallC)(needs-painting wallD)(needs-painting wallE)(clean roller1)(clean roller2)Goal Statement(painted wallA red)(painted wallB red)(painted wallC red)(painted wallD green)(painted wallE green)46Optimal Solution<Designate-Roller wallA roller1 red><Designate-Roller wallB roller1 red><Designate-Roller wallC roller1 red><Fill-Roller roller1 red><Paint-Wall wallA roller1 red><Paint-Wall wallB roller1 red><Paint-Wall wallC roller1 red><Designate-Roller wallD roller2 green><Designate-Roller wallE roller2 green><Fill-Roller roller2 green><Paint-Wall wallD roller2 green><Paint-Wall wallE roller2 green>fiflecs: Planning Flexible Commitment Strategyflecs directly find solution always eagerly subgoaling alwayseagerly applying. search eciently, must subgoal considered wallsneed painted color; must apply applicable operatorscontinuing. explicit information domain telling use one roller redone roller green.10 reason, flecs eagerly subgoals, initially selectsroller paint walls. extensively backtracks finding correctbindings. flecs also realize \ready" walls goingpainted color filling roller. Thus, flecs eagerly appliesoperators, tries filling roller soon one wall \readied." Note planningvariables would solve problem since planner would still need makebinding selections subgoaling beyond \paint-wall," hence facing problems.flecs tries solve problem using either strategy described,succeed reasonable amount time. Since flecs complete, would certainlysucceed eventually, eventually long time away dealing NP-hardproblem: neither commitment strategies leads solution problem500 seconds search time. lost. changing value toggleappropriate times, flecs easily find solution problem. fact,4 seconds toggle manually changed appropriate times.time(sec) solutioneager applying500eager subgoaling500variable strategy4yesflecs eagerly subgoals decided paint wallA, wallB, wallCroller1, begin eagerly applying. three walls painted red, flecsbegin subgoaling without danger preparing walls wrongroller: roller2 still clean. example change state allowsminimum conspiracy number heuristic select correct instantiated operator.general heuristic toggle set sub walls needpainted color considered. toggle set appapplicable operators applied. toggle set back subprocess continues. way, flecs need little backtrackingquickly reach solution. heuristic corresponds using abstraction hierarchydeal separately interactions different colors different walls.6. Conclusionpresented planner intended studying correspondence planning problems search heuristics suited problems. flecsability eagerly subgoal, thus delaying operator-ordering commitments; eagerly apply,thus maximizing advantages maintaining internal state; exibly interleavetwo strategies. Thus operate point continuum operator-orderingheuristics { one important dimension planning.10. problem common planning often syntactically correct way restrict bindingsdomain representation maintaining intended exibility generality domain.47fiVeloso & Stonepaper, explained advantages disadvantages delayed eagercommitments. presented flecs algorithm full detail, carefully motivatingconcepts illustrating clear examples. discussed different heuristicsguide flecs choice points discussed properties. showed examplesspecific planning tasks corresponding empirical results support positiongeneral-purpose planner must able use exible commitment strategy. Althoughplanning problems solvable complete planners, flecs may solveproblems eciently planners ability changecommitment strategy may fall worst case unique commitment strategy.flecs provides framework study characteristics different planning strategiesmapping planning domains problems. flecs represents viewdomain-independent planning strategy uniformly ecient across different domains problems. flecs addresses particular operator-ordering choiceexible planning decision. allows combination delayed eager operator-orderingcommitments take advantage benefits explicitly using simulated executionstate reasoning planning constraints.currently continuing work understanding tradeoffs among differentplanning strategies along different dimensions. plan study effects eager versusdelayed commitments point operator instantiations. also investigatingeffects combining real execution flecs. Finally, plan use machine learningtechniques flecs's choice points gain possibly automated understandingmapping ecient planning methods planning domains problems.Appendix A. Proofsprove flecs sound iterative deepening complete. Considerflecs algorithm presented Table 2. planning problem determinedinitial state, goal statement, set operators available domain. plan(totally-ordered) sequence instantiated operators. returned plan generatedflecs planning problem sequence applied operators upon termination.solution planning problem plan whose operators applied problem'sinitial state reach state satisfies Goal Statement. justified solutionsolution subsequence operators solution also solution. flecsterminates successfully termination condition met (step 2).Theorem 1.flecs sound.show flecs algorithm sound; is, algorithm terminates suc-cessfully, returned plan indeed solution given planning problem.Assume flecs terminates successfully = O1 ; O2; :::On returnedplan. flecs applies operator preconditions operator satisfiedCurrent State C (step 7). Hence, construction, operators O1 ; O2; : : :Okk < n applied, preconditions operator Ok+1 satisfied C .point termination, Current State C satisfies Goal Statement (step 2). Creached initial state applying operators . Therefore solution.QED.48fiflecs: Planning Flexible Commitment StrategyTheorem 2.flecs iterative deepening complete.Recall completeness, informally, means solution particularproblem, algorithm find it. show flecs's search space completeflecs's search algorithm complete long explores branches searchspace, example using iterative deepening (Korf, 1985).11 Iterative deepening involvessearching bound number search steps may performedparticular search path suspended expansion; solution foundparticular depth bound, search repeated larger depth bound.planning problem, assume = O1; O2; :::On justified solution.show flecs searches iterative deepening, find solution.flecs algorithm four choice points. Three choice points backtrackpoints: choice subgoaling applying (step 5d), choice operatoruse achieve goal (step 6c), choice applicable operator apply(step 7). One choice point backtrack point: choice goal subgoal(step 6).prove completeness, must show backtrack point, possiblechoice lead flecs towards finding plan , matter choices flecs makesnon-backtrack choice point. flecs explores branches search spacesearching iterative deepening, must eventually find unless findssolution (of length n) first.proof involves constructing oracles tell flecs choices makebacktrack points find . matter choices makes choicepoint, finds solution plan .Consider point search operators O1; O2; O3; : : :; Ok k (andothers) already applied. let oracles backtrack pointsoperate follows.choice subgoaling applying (step 5d), first oracle makes flecs chooseapply Ok+1 applicable (i.e., A); otherwise makes flecs subgoal.flecs chooses apply (Ok+1 2 A), reaches another choice point, namely choiceoperator apply (step 7). Another oracle makes flecs select precisely step Ok+1 .flecs chooses subgoal (Ok+1 62 A), let flecs choose goal Pset pending goals P (step 6). Since step 6 backtrack point, cannotoracle determine choice point. Instead show that, independentlychoice made point, flecs still find solution . find solutionconsequence construction next oracle controls final choice point(below). oracle guarantees P selected must either member goalstatement precondition operator .final choice point selection operator achieve P (step 6c). thirdoracle makes flecs choose operator achieve P . Since solutionplanning problem since P either member Goal Statement preconditionoperator , must operator achieves P .one operator, one chosen. Since operators selected,11. opposed breadth first search, iterative deepening harm eciency. combines eciencysearching depth first completeness searching breadth first.49fiVeloso & Stonecondition pending goals Goal Statement preconditionsoperators maintained.three oracles lead flecs justified solution . Since justified, everyoperator necessary achieve either goal goal statement precondition another operator. Consequently, since third oracle chooses operators, every operator eventually chosen applied prescribedfirst two oracles. every operator applied, termination conditionmet (since solution) flecs terminate successfully. QED.Acknowledgementswould like recognize particular contributions Jim Blythe Eugene Finkresearch. Jim Blythe highly responsible current implementation prodigy4.0upon flecs based. Eugene Fink helped formalization algorithmsproofs. thank Eugene Fink, Karen Haigh, Gary Pelton, Alicia Perez, Xuemei Wang,anonymous reviewers comments article.research sponsored Wright Laboratory, Aeronautical Systems Center, AirForce Materiel Command, USAF, Advanced Research Projects Agency (ARPA)grant number F33615-93-1-1330. views conclusions contained document authors interpreted necessarily representingocial policies endorsements, either expressed implied, Wright LaboratoryU. S. Government.ReferencesAmbros-Ingerson, J., & Steel, S. (1988). Integrating planning, execution, monitoring.Proceedings Seventh National Conference Artificial Intelligence, pp. 83{88St. Paul, MN.Barrett, A., & Weld, D. S. (1994). Partial-order planning: Evaluating possible eciencygains. Artificial Intelligence, 67, 71{112.Blythe, J., & Veloso, M. M. (1992). analysis search techniques totally-orderednonlinear planner. Proceedings First International Conference AI Planning Systems, pp. 13{19 College Park, MD.Carbonell, J. G., Blythe, J., Etzioni, O., Gil, Y., Joseph, R., Kahn, D., Knoblock, C.,Minton, S., Perez, A., Reilly, S., Veloso, M., & Wang, X. (1992). PRODIGY4.0:manual tutorial. Tech. rep. CMU-CS-92-150, Department Computer Science,Carnegie Mellon University.Carbonell, J. G., Knoblock, C. A., & Minton, S. (1990). Prodigy: integrated architecture planning learning. VanLehn, K. (Ed.), Architectures Intelligence.Erlbaum, Hillsdale, NJ. Also Technical Report CMU-CS-89-189.Chapman, D. (1987). Planning conjunctive goals. Artificial Intelligence, 32, 333{378.50fiflecs: Planning Flexible Commitment StrategyErnst, G. W., & Newell, A. (1969). GPS: Case Study Generality Problem Solving.ACM Monograph Series. Academic Press, New York, NY.Fikes, R. E., & Nilsson, N. J. (1971). Strips: new approach application theoremproving problem solving. Artificial Intelligence, 2, 189{208.Fink, E., & Veloso, M. (1994). PRODIGY planning algorithm. Technical report CMU-CS94-123, School Computer Science, Carnegie Mellon University.Kambhampati, S. (1994). Desing tradeoffs partial order (plan space) planning. Proceedings Second International Conference AI Planning Systems, AIPS-94,pp. 92{97 Chicago, IL.Knoblock, C. A. (1994). Automatically generating abstractions planning. ArtificialIntelligence, 68.Korf, R. E. (1985). Depth-first iterative-deepening: optimal admissible tree search.Artificial Intelligence, 27 (1), 97{109.McAllester, D., & Rosenblitt, D. (1991). Systematic nonlinear planning. ProceedingsNinth National Conference Artificial Intelligence, pp. 634{639.McDermott, D. V. (1978). Planning acting. Cognitive Science, 2-2, 71{109.Minton, S. (1993). Integrating heuristics constraint satisfaction problems: case study.Proceedings Eleventh National Conference Artificial Intelligence, pp. 120{126.Minton, S., Bresina, J., & Drummond, M. (1991). Commitment strategies planning:comparative analysis. Proceedings Twelfth International Joint ConferenceArtificial Intelligence, pp. 259{265.Minton, S., Knoblock, C. A., Kuokka, D. R., Gil, Y., Joseph, R. L., & Carbonell, J. G.(1989). prodigy 2.0: manual tutorial. Technical report CMU-CS-89-146,School Computer Science, Carnegie Mellon University.Rosenbloom, P. S., Newell, A., & Laird, J. E. (1990). Towards knowledge levelSOAR: role architecture use knowledge. VanLehn, K. (Ed.),Architectures Intelligence. Erlbaum, Hillsdale, NJ.Sacerdoti, E. D. (1977). Structure Plans Behavior. American Elsevier, New York.Stone, P., Veloso, M., & Blythe, J. (1994). need different domain-independentheuristics. Proceedings Second International Conference AI PlanningSystems, pp. 164{169.Tate, A. (1977). Generating project networks. Proceedings Fifth InternationalJoint Conference Artificial Intelligence, pp. 888{900.51fiVeloso & StoneVeloso, M., & Blythe, J. (1994). Linkability: Examining causal link commitments partialorder planning. Proceedings Second International Conference AI PlanningSystems, pp. 170{175.Veloso, M. M. (1989). Nonlinear problem solving using intelligent casual-commitment.Technical report CMU-CS-89-210, School Computer Science, Carnegie Mellon University.Veloso, M. M., & Carbonell, J. G. (1993). Derivational analogy prodigy: Automatingcase acquisition, storage, utilization. Machine Learning, 10, 249{278.Veloso, M. M., Perez, M. A., & Carbonell, J. G. (1990). Nonlinear planning parallelresource allocation. Proceedings DARPA Workshop Innovative ApproachesPlanning, Scheduling, Control, pp. 207{212 San Diego, CA. Morgan Kaufmann.Wilkins, D. E. (1984). Domain-independent planning: Representation plan generation.Artificial Intelligence, 22, 269{301.52fi