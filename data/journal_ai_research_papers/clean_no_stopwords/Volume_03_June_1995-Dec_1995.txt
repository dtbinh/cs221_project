Journal Artificial Intelligence Research 3 (1995) 405-430

Submitted 6/95; published 12/95

Decision-Theoretic Foundations Causal Reasoning

David Heckerman

heckerma@microsoft.com

Microsoft Research, One Microsoft Way
Redmond, WA 98052-6399 USA

Ross Shachter

shachter@camis.stanford.edu

Stanford University
Stanford, CA 94305-4025 USA

Abstract

present definition cause effect terms decision-theoretic primitives
thereby provide principled foundation causal reasoning. definition departs
traditional view causation causal assertions may vary set decisions
available. argue approach provides added clarity notion cause. Also
paper, examine encoding causal relationships directed acyclic graphs.
describe special class uence diagrams, canonical form, show
relationship Pearl's representation cause effect. Finally, show canonical
form facilitates counterfactual reasoning.

1. Introduction

Knowledge cause effect crucial modeling affects actions. example,
observe statistical correlation smoking lung cancer, conclude
observation alone chances getting lung cancer change stop
smoking. If, however, also believe smoking cause lung cancer,
conclude choice whether continue quit smoking affect whether get
lung cancer.
Work artificial intelligence researchers, statisticians, philosophers emphasized importance identifying causal relationships purposes modeling effects
actions. example, Simon (1977), Robins (1986), Spirtes et al. (1993), Pearl (1993,
1995) developed graphical models cause effect, demonstrated
models important reasoning effects actions. addition, Robins (1986),
Rubin (1978), Pearl Verma (1991), Spirtes et al. (1993) developed approaches
embrace causality learning effects actions data.
One useful framework causal reasoning Pearl (1993, 1995)|herein Pearl.
Using framework, construct causal graph G. nodes G correspond set
variables U wish model. variable set mutually exclusive
collectively exhaustive values instances. arcs G represent (informal) assertions
cause|in particular, parents x 2 U direct causes x. Pearl gives informal
assertions cause operational meaning introducing special class actions
variables U describing affects actions using structure causal
graph. Specifically, posits that, every variable x 2 U , exists another variable x^,
call atomic intervention x. variable x^ instance set(x) every
instance x x, instance idle. instance set(x) corresponds action
c 1995 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiHeckerman & Shachter

forces x take instance x indirectly affects variables change
x. instance idle corresponds action nothing.1 Pearl asserts
effects atomic interventions variables U determined structural
equations
x = fx (PaG (x); x^; x)
x 2 U , (1) PaG (x) parents x G|that is, direct causes x, (2)
variables x exogenous mutually independent random disturbances, (3)
function fx property x = x x^ =set(x) regardless values PaG (x)
x . Following Pearl, call framework defining cause structural-equation
model.
Another useful framework causal reasoning, closely related Pearl's,
Spirtes et al. (1993)|herein SGS.
Despite important advances reasoning cause effect, foundations approaches lacking. framework causal reasoning, important
consider concepts primitive|that is, assumed self evident used
define concepts. much possible, primitives simple universal meanings claims causation empirically tested causal inferences
trusted. Unfortunately, primitives used Pearl, SGS, researchers
ideal respect.
example, SGS take cause primitive. Given controversies statistics
disciplines concerning meaning cause, believe better primitive
found. Pearl takes random disturbance, exogenous variable, atomic intervention
primitives. One problem approach need understanding cause
effect identify intervention atomic. illustrate problem, suppose
wish model causal relationship binary variables w h representing
whether person considers wealthy happy, respectively. Further,
suppose give person large sum stolen money along knowledge
money stolen. ask question: action instance atomic
intervention w? person care becomes wealthy,
answer \yes." person typical, however, answer \no,"
action would affect w h directly. Thus, must first determine whether
action direct cause h determine whether action instance
atomic intervention.
paper, provide principled foundation causal reasoning. particular,
explicate set primitives decision theory, use primitives define
concepts cause atomic intervention well random disturbance
exogenous variable. primitives simple understand used uniformly across
many disciplines.
basic idea behind definition cause follows. Following paradigm
decision theory, focus person|the decision maker|who one decisions
make. variable wish model considering decisions, distinguish
1. adopt variant Pearl's notation instances atomic intervention. addition, whereas
Pearl calls action set(x) atomic intervention, find convenient use phrase refer
entire variable x^.

406

fiDecision-Theoretic Foundations Causal Reasoning

variable either decision variable chance variable. decision variable
variable whose instances correspond possible actions among person choose.
chance variable variable. framework similar Pearl's, chance
variables correspond variables U decision variables correspond interventions.
differences (1) require decision variable every
chance variable, (2) decision variables need atomic interventions.
Now, simplicity, suppose model consisting one decision variable
set chance variables U . Imagine choose one instances
subsequently observe x 2 U . believe x different different choices, then,
definition, say cause x. example, suppose decision variable
represents decision whether continue smoking chance variable l
represents whether get lung cancer. believe get lung cancer
continue smoking may get lung cancer quit, say
cause l.
definition related notion counterfactual: hypothetical statement
question verified answered observation (Lewis, 1973; Holland,
1986). smoking example, ask question \Will deciding differently possibly
change health outcome?" question answered observation, must either quit continue smoke; both. Using counterfactuals,
Rubin (1978) defines notion causal effect closely related definition
cause.
problem definitions cause based intervention
allow chance variables causes chance variables. Consider variables g
c representing person's gender birth whether person gets breast
cancer, respectively. Although g chance variable (we cannot choose gender),
often hear people say natural discourse g causes c. general, would like
accommodate assertions.
definition cause present indeed permit chance variables causes.
is, however, one catch. Namely, assert set chance variables X
cause chance variable , must also specify decision decisions bring
possible changes X . breast-cancer problem, assert g causes
c, must explicate decision possibly leads change gender breast
cancer. example, say g causes c respect decision variable d,
represents decision whether perform genetic surgery conception.
including decision context assertions cause, definition departs
traditional view causation. Nonetheless, departure makes causal assertions
precise. example, consider another decision likely lead change gender:
decision whether sex-change operation birth. case, may
reasonable assert g cause c respect o. Thus, causal relationships
among chance variables may depend decisions available intervention;
definition accommodates dependence.
paper organized four parts. part 1 (Sections 2 3), develop
definition cause, using decision-theoretic primitives Savage (1954). Section 2,
introduce simpler relation cause, call limited unresponsiveness.
Section 3, define cause terms limited unresponsiveness.
407

fiHeckerman & Shachter

part 2 (Sections 4 7), address graphical representation cause.
Section 4, review directed-acyclic-graph (DAG) representation, known uence
diagram, used two decades decision analysts model effects
decisions (Howard Matheson, 1981). demonstrate inadequacies uence diagram representation cause. following three sections, develop
special condition uence diagram, known canonical form, improves
representation cause.
part 3 (Section 8), use definitions cause, atomic intervention, mapping
variable, along canonical form build correspondence (and thus foundation
for) Pearl's causal framework.
part 4 (Section 9), demonstrate important use canonical form. Namely,
show use uence diagrams canonical form general counterfactual reasoning.
present framework traditional decision-analytic paradigm \one shot"
decision. particular, consider experimental studies, variables measured repeatedly. Nonetheless, one easily extend framework situations
introducing assumption exchangeability (de Finetti, 1937). Bayesian methods
learning models cause based approach discussed Angrist et al.
(1995) Heckerman (1995).

2. Unresponsiveness

section, introduce notion limited unresponsiveness, fundamental relation
use define cause. define limited unresponsiveness using primitives
decision theory explicated (for example) Savage (1954).
begin description primitives act, consequence, possible state
world. Savage describes illustrates concepts follows:
say decision made say one acts
chosen, decided on. deciding act, account must taken
possible states world, also consequences implicit act
possible state world. consequence anything may happen
person.
Consider example. wife broken five good eggs bowl
come volunteer finish making omelet. sixth egg,
reason must either used omelet wasted altogether, lies
unbroken beside bowl. must decide unbroken
egg. Perhaps great oversimplification say must
decide among three acts only, namely, break bowl containing
five, break saucer inspection, throw away without
inspection. Depending state egg, three acts
consequence concern you, say indicated Table 1.
purposes discussion, two points emphasize Savage's exposition. First, important distinguish choose|namely,
acts|and choose|namely, consequences. Second, choose
act, consequence occurs logically determined state world.
408

fiDecision-Theoretic Foundations Causal Reasoning

state
world
break bowl
good egg six-egg omelet
bad egg

act
break saucer
throw away
six-egg omelet five-egg omelet one
saucer wash
good egg destroyed
omelet five good five-egg omelet five-egg omelet
eggs destroyed
saucer wash

Table 1: example illustrating acts, possible states world, consequences.
(Taken Savage [1954].)
is, consequence deterministic function act state world.
course, consequence (and usually is) uncertain, uncertainty captured
uncertainty state world. concepts act, consequence, state
world, together deterministic mapping act state world
consequence primitives.2
omelet story, possible states world readily come mind given
description problem. Furthermore, observe state world (i.e.,
condition egg). many situations, however, state world
unobservable. is, assertion \the state world x" counterfactual.
situations, bring possible states mind thinking acts
consequences. example, suppose decision continue smoking quit,
model consequences getting cancer not. acts consequences bring
mind four possible states world, shown Table 2. possible states
familiar names; simply label numbers. actual state world
observable, because, decide quit, won't know sure would
happened continued, vice versa.
acts consequences problem may actually bring mind four|
even infinite number|of states world. example, state world may
correspond degree susceptibility lung tissue tar measured biochemical
assay. Nonetheless, given discrete acts consequences chosen model
problem, four states Table 2 suciently detailed. Savage recognizes
issue detail definition state world: \a description world, leaving
relevant aspect undescribed." general, decision problem c consequences
acts, ca possible states world need distinguished.3
idea state world may observable traced Neyman
(1923), derived statistical methods estimating differences yields different
crops planted plot land, circumstances one crop actually
planted plot. Rubin (1978) Howard (1990) formalized idea.
2. Savage (1954) defines act \a function attaching consequence state world."
contrast, take act primitive, many decision analysts (e.g., Howard, 1990).
3. acts consequences continuous, specification complicated. paper,
address situations acts consequences discrete.

409

fiHeckerman & Shachter

state
world
1
2
3
4

act
continue
quit
cancer
cancer
cancer cancer
cancer
cancer
cancer cancer

Table 2: four possible states world decision continue quit smoking.
practice, often cumbersome impossible reason monolithic set
acts, possible states world, consequences. Therefore, typically describe
items terms set variables take two values instances.
call variable describing set consequences chance variable. example,
omelet story, describe consequences terms three chance variables: (1)
number eggs omelet?4 (o) instances zero, five, six, (2) number
good eggs destroyed? (g ) instances zero, one, five, (3) saucer wash? (s)
instances yes. is, every consequence corresponds assignment
instance chance variable.
call variable describing set acts decision variable (or decision, short).
example, suppose set possible acts going dress
work. case, describe acts terms decision variables shirt (plain
striped), pants (jeans corduroy), shoes (tennis shoes loafers).
example general, every act corresponds choice instance decision
variable.
description possible states world terms component variables bit
complicated, needed explication unresponsiveness limited
unresponsiveness. defer discussion issue Section 6.
matter notation, use denote set decisions describe acts
decision problem, lower-case letters (e.g., d; e; f ) denote individual decisions
set D. Also, use U denote set chance variables describe consequences,
lower-case letters (e.g., x; y; z ) denote individual chance variables U . addition,
use variable denote state world (the instances correspond
possible states world).5 Thus, given decision problem|or domain,
sometimes call it|is described variables U , D, .6
introduction, discuss concept limited unresponsiveness.
illustrate concept, consider following decision problem adapted Angrist et al.
(1995). Suppose physician decide whether recommend
particular treatment. Given recommendation, patient may may actually
4. emphasize distinction chance decision variables, put question mark end
names chance variables.
5. use uppercase \S " denote single variable, later decompose set
variables.
6. Sometimes, simplicity, leave implicit specification decision problem.

410

fiDecision-Theoretic Foundations Causal Reasoning

r (recommendation)
take
don't take
(taken?) c (cured?) (taken?) c (cured?)
1: complier, helped
yes
yes


2: complier, hurt
yes


yes
3: complier, always cured
yes
yes

yes
4: complier, never cured
yes



5: defier, helped


yes
yes
6: defier, hurt

yes
yes

7: defier, always cured

yes
yes
yes
8: defier, never cured


yes

9: always taker, cured
yes
yes
yes
yes
10: always taker, cured
yes

yes

11: never taker, cured




12: never taker, cured

yes

yes
13: (impossible)
yes
yes
yes

14: (impossible)
yes

yes
yes
15: (impossible)



yes
16: (impossible)

yes


(state world)

Table 3: decision problem recommending medical treatment.
accept treatment, may may cured result. Here, use single
decision variable recommendation (r) represent acts (i.e., = frg), two chance
variables taken? (t) cured? (c) represent whether patient actually accepts
treatment whether patient cured, respectively (i.e., U = ft; cg).
possible states world problem shown Table 3. example,
consider first row table. Here, patient accept treatment
recommend it, cured takes treatment. describe
state saying patient complier helped treatment. discuss
description states detail Section 6.
indicated table, suppose believe last four states world
impossible (i.e., probability zero). last four states share property
takes instance acts, whereas c not. Thus, decision problem
satisfies following property: states world possible,
two acts, c also same. say c unresponsive r states
limited t.
general, suppose decision problem described variables U , D, .
Let X subset U , subset U [ D. say X unresponsive
states limited believe that, possible states world,
assumes instance two acts X must also assume instance
acts. describe notion limited unresponsiveness earlier work terms
411

fiHeckerman & Shachter

conditional fixed set (Heckerman Shachter, 1994). Angrist et al. (1995) discuss
instance limited unresponsiveness, call exclusion restriction.
formal, let X [S; D] instance X assumes (with certainty) given
state world act D. example, omelet story, state
world egg good, act throw away, o[S; D] (the number
eggs omelet) assumes instance five. Then, following definition.

Definition 1 (Limited (Un)responsiveness) Given decision problem described
chance variables U , decision variables D, state world , variable sets X U
[ U , X said unresponsive states limited , denoted X 6 -Y D,
believe

8 2 S; D1 2 D; D2 2 : [S; D1] = [S; D2] =) X [S; D1] = X [S; D2]
X said responsive states limited , denoted X -Y D,
case X unresponsive states limited |that is, believe
9 2 S; D1 2 D; D2 2 s:t: [S; D1] = [S; D2] X [S; D1] =6 X [S; D2]
X (un)responsive states limited = ;, simply say X
(un)responsive D. notion unresponsiveness significantly simpler
limited unresponsiveness. is, = ;, equalities left-hand-side
implications Definition 1 trivially satisfied. Thus, X unresponsive believe
that, possible state world, X assumes instance acts; X
responsive possible state world X differs two different
acts.
examples responsive variables, consider omelet story. Let denote state
egg good, D1 D2 denote acts break bowl throw away,
respectively. Then, variable (number eggs omelet?), o[S; D1] =six
o[S; D2] =five. Consequently, responsive D.7 similar manner, conclude
g (number good eggs destroyed?), (saucer wash?) responsive D.
Note chance variable x responsive D, then|to degree|it
control decision maker. Consequently, decision maker observe x prior
choosing act D. example, omelet story, observe
responsive variables o, g , choosing act.8
example unresponsive variable, suppose include (the state world)
variable U . (E.g., omelet story, take U fS; o; g; sg.) Savage's
definition , must unresponsive D. Note including U creates new
states world.
discussed, notions unresponsiveness limited unresponsiveness
closely related concepts counterfactual reasoning. determine whether
7. Technically, say fog responsive D. simplicity, however, usually drop set
notation singletons.
8. precise, variable represents number eggs omelet choose act
D. variable confused another variable{say |corresponding number
eggs omelet choose D. Whereas responsive cannot observed
choosing act, unresponsive observed choosing D.
0

0

412

fiDecision-Theoretic Foundations Causal Reasoning

chance variable x unresponsive decisions D, essentially answer query \Will
outcome x matter choose D?" Furthermore, determine
whether x unresponsive states limited , answer query \If
change result choice D, outcome x same?" One
fundamental assumptions work presented counterfactual
queries easily answered. experience, found decision makers
indeed comfortable answering restricted counterfactual queries.
concepts responsiveness probabilistic independence related, illustrated
following theorem.

Theorem 1 set chance variables X unresponsive set decision variables D,
X probabilistically independent D.

Proof: definition unresponsiveness, X assumes instance acts
possible state world. Consequently, learn X observing ,
observing D. 2
Nonetheless, two concepts identical. particular, converse Theorem 1
hold. example, let us consider simple decision whether bet heads
tails outcome coin ip. Assume coin fair (i.e., probabilities
heads tails 1/2) person ips coin know
bet. Here, possible outcomes coin toss correspond possible states
world. Further, let decision variable b denote bet, chance variable w describe
possible consequences win not. situation, w responsive b,
possible states world, w different different bets. Nonetheless,
probability w 1/2, whether bet heads tails. is, w b probabilistically
independent.
Limited unresponsiveness conditional independence less closely related
unqualified counterparts. Namely, limited unresponsiveness imply conditional
independence. example, medical-treatment story, c (cured?) unresponsive r
(recommendation) states limited (taken?), reasonable us believe
c r independent given t, perhaps factor that|partially
completely|determines person reacts recommendations treatment.
derive several interesting properties limited unresponsiveness definition.
1. X 6 -Y () 8x 2 X; x 6 -Y
2. X 6 -W () X [ W 6 -W
3. X 6 -D
4. X 6 -Y =) X 6 -Y [Z
5. X 6 -Y [Z 6 -Z =) X 6 -Z
6. X -Z W 6 -Z =) X -W [Z
413

fiHeckerman & Shachter

set decision variables domain, X W arbitrary sets chance
variables U , Z arbitrary sets variables U [ D.
proofs properties straightforward. example, consider property 5.
Given X 6 -Y [Z D,

8 2 S; D1 2 D; D2 2 : [S; D1] = [S; D2] Z [S; D1] = Z [S; D2]
Given 6 -Z D,

=) X [S; D1] = X [S; D2]

8 2 S; D1 2 D; D2 2 : Z [S; D1] = Z [S; D2] =) [S; D1] = [S; D2]
Consequently, obtain

8 2 S; D1 2 D; D2 2 : Z [S; D1] = Z [S; D2] =) X [S; D1] = X [S; D2]
is, X 6 -Z D.
properties follow these. example, true trivially ; 6 -Y D.
Consequently, Property 2, know 6 -Y D. another example, special case
Property 4 whenever X unresponsive D, X unresponsive
states limited Z . Also, Properties 4 5 imply limited unresponsiveness
transitive: X 6 -Y 6 -Z imply X 6 -Z D.

closing section, note definition limited unresponsiveness
generalized several ways. one generalization, define means X U
unresponsive states world limited , set instances . Namely,
say X unresponsive states limited if, possible states world
S, two acts D1 D2 , [S; D1] = [S; D2] 2 implies X [S; D1] = X [S; D2].
second generalization, define means set chance variables
unresponsive subset decisions. particular, given domain described
U D, say X U unresponsive D0 states limited
X 6 -Y [(DnD ) D.
0

3. Definition Cause

Given notion limited unresponsiveness, formalize definition cause.

Definition 2 (Causes Respect Decisions) Given decision problem described
U D, variable x 2 U , variables C [ U n fxg said causes
x respect C minimal set variables x 6 -C D.
framework, decision variables caused,
control decision maker. Consequently, define causes chance variables only.
Also, discussed, definition extension existing intervention-based
definitions cause (e.g., Rubin [1978]) allow causes include chance variables.
addition, definition cause departs traditional usage term causeeffect assertions may vary set decisions available. discuss advantages
departure shortly.
414

fiDecision-Theoretic Foundations Causal Reasoning

example definition, consider decision continue quit smoking,
described decision variable (smoke) chance variable l (lung cancer?).
believe l probabilistically dependent, then, Theorem 1, must
l - s. Furthermore, Property 3, know l 6 -s s. Consequently, Definition 2,
cause l respect s.
another example, consider medical-treatment story. c (cured?)
responsive r (recommendation), (among reasons) first row
Table 3, patient cured recommend treatment. Furthermore,
discussed previous section, c unresponsive r states limited (taken?).
Consequently, cause c respect r.
advantage defining cause relative decisions made clear breast-cancer
example given introduction. Let g c denote chance variables gender?
breast cancer?, respectively. Now, imagine two decisions available alter gender: o,
decision sex-change operation birth, d, decision change chromosomes
conception microsurgery. possible someone believe c 6 - yet
c - c 6 -g d. is, possible someone believe gender cause
breast cancer respect chromosome change respect sex-change
operation. situation, make sense make unqualified statement
\gender cause breast cancer." general, decision-based definition provides
added clarity.
Several consequences Definition 2 worth mentioning. First, although cause
irre exive definition, always asymmetric. example, story
coin toss, consider another variable represents whether outcome
coin toss matches bet b. story told it, deterministic function
w (win?), vice versa. Consequently, w 6 -m b 6 -w b; cause
w w cause respect b. Note hint uncertainty destroys
symmetry. example, possibility person tossing coin cheat
(so may lose even match), conclude cause w,
vice versa. symmetry would also destroyed decision controlling w
unresponsive.
Second, cause transitive single variables. particular, x cause
cause z respect D, z -D (by transitivity unresponsiveness)
z 6 -x D. Consequently, x cause z respect D. Note transitivity
necessarily hold causes containing sets variables, minimality condition
Definition 2 may satisfied.
Third, C = ; set causes x respect x unresponsive
D.
Fourth, following theorem, follows Definition 2 several
properties limited unresponsiveness given Section 2.
Theorem 2 Given x 2 U , C set causes x respect D, w 2 C \U ,
w must responsive D.
Proof: chance variable w 2 C , let C 0 = C n fwg. minimality condition
definition,
x -C
(1)
0

415

fiHeckerman & Shachter

Suppose w 6 - D. Then, Property 4,

w 6 -C
0

(2)

Applying Equations 1 2 Property 6, x -C D, contradicts
C set causes x respect D. 2
illustrate use theorem, let us extend medical-treatment example
imagining gene affects person reacts recommendation therapy. situation, reasonable us assert variable g
(genotype?) unresponsive r. Thus, Theorem 2, g among causes
variable.
consequence definition may seem unappealing. Intuitively, would like
able say (in sense) g cause c. Indeed, definition preclude
ability make assertions. Namely, reason require decisions
implementable practice all. want think whether
patient's genotype cause cure, imagine action alter
one's genetic makeup|for example, retroviral therapy (v ). case, reasonable
conclude fr; g g cause respect decisions fr; v g. Nonetheless,
discussed, must clear action(s) alter genotype make
statement cause precise.
Finally, generalize definition means set variables cause
x definition means set instances cause x. Namely, say
C , set instances C , cause x 2= C respect C minimal set
variables x unresponsive states limited C . is, C cause
x respect replace definition cause weaker requirement
x unresponsive states limited C .

4. uence Diagrams
following three sections, examine graphical representation cause
within framework. study useful right, also help relate
framework Pearl's structural equation model. begin, section, review
uence-diagram representation.
uence diagram (1) acyclic directed graph G containing decision chance
nodes corresponding decision chance variables, information relevance arcs,
representing known time decision probabilistic dependence, respectively, (2) set probability distributions associated chance node, optionally
(3) utility node corresponding set utilities (Howard Matheson, 1981).
information arc one points decision node. information arc chance
decision node decision node indicates variable known decision
made. (We shall use notation refer variable corresponding
node diagram.) relevance arc one points chance node. absence
possible relevance arc represents conditional independence. identify relevance arcs,
start ordering variables U = (x1; : : :; xn ). Then, variable xi
order, ask decision maker identify set PaG (xi ) fx1; : : :; xi,1 ; Dg renders
416

fiDecision-Theoretic Foundations Causal Reasoning

xi fx1; : : :; xi,1; Dg conditionally independent. is,
p(xijx1; : : :; xi,1; D; ) = p(xijPaG (xi ); )

(3)

p(X jY; ) denotes probability distribution X given decision maker
background information . every variable z PaG (xi ), place relevance arc
z xi graph G uence diagram. is, nodes PaG (xi) parents
xi G.
Associated chance node xi uence diagram probability distributions p(xijPaG (xi ); ). chain rule probability, know
n

p(x1; : : :; xn jD; ) = p(xijx1; : : :; xi,1; D; )
i=1

(4)

Combining Equations 3 4, see uence diagram U [ uniquely
determines joint probability distribution U given D. is,

p(x1; : : :; xnjD; ) =

Yn p(xijPaG(xi); )

i=1

(5)

uence diagrams may also contain special chance nodes. deterministic node corresponds variable deterministic function parents. utility node encodes
preferences decision maker. Finally, uence diagram unambiguous
decision nodes totally ordered|that is, directed path uence
diagram traverses decisions. total order corresponds order
decisions made.
paper, concern neither ordering decision nodes
observation chance variables making decisions. Therefore, concerned
information arcs. Likewise, although new concepts apply models include
utility nodes, illustrate concepts models containing chance, deterministic, decision variables.
Figure 1a contains uence diagram omelet story. illustrated
figure, use ovals, double ovals, squares represent chance, deterministic,
decision nodes, respectively. Among possible relevance arcs uence diagram,
several missing. example, arc , representing independence
(which follows assertion unresponsive D). Figures 1b
1c contain uence diagrams medical-treatment example. chance variable g
(genotype?) explicitly modeled Figure 1c.
ordinary uence diagram designed representation conditional independence. Furthermore, discussed, concepts conditional independence
limited unresponsiveness loosely related. Consequently, uence diagram
inadequate representation causal dependence, least definition cause.
particular, uence diagram may contain arc node x node , even
though x among set causes . example, uence diagram Figure 1b
arcs r c due dependencies domain. Nonetheless,
established singleton ftg cause c respect r.
417

fiHeckerman & Shachter

decision



state
world (egg)

number eggs
omelet?



recommendation

r

r

treatment?







number good
eggs destroyed?

g

saucer wash?



genotype?
g

cured?

(a)

c

(b)

c

(c)

Figure 1: uence diagrams (a) omelet story, (b,c) medical-treatment example.
Furthermore, uence diagram may contain arc x , even though x
cause . example, consider coin example, illustrated uence diagram
Figure 2a. believe coin fair, bother model variable
c explicitly (as shown Figure 2b), need place arc w,
probability winning 1=2, regardless choice d. Nonetheless, b cause
w respect b, definition.
Despite limitations, uence diagram adequate purposes making decisions uncertainty. introduction, argued causal information needed
predicting effects actions. Thus, question arises: \Why need anything
uence diagram representation effects actions?" give
answer question Section 9, discuss counterfactual reasoning. There,
show ordinary uence diagram inadequate purposes counterfactual
reasoning unless canonical form|a form accurately ects cause.

5. Direct Atomic Interventions
order define canonical form, need concept mapping variable. Likewise,
order define mapping variable, need concept atomic intervention. also
need concept atomic intervention explicate Pearl's structural-equation model.
section, define atomic intervention along general concept called direct
intervention.
Roughly speaking, say set decisions direct intervention set
chance variables X effects chance variables mediated
effects X . SGS, take cause primitive, provide formal definition
direct intervention (which call direct manipulation) consistent
notion. find simpler define direct intervention terms limited unresponsiveness.
418

fiDecision-Theoretic Foundations Causal Reasoning

bet

b

bet
coin
c

win

b

win

w

w

(a)

(b)

Figure 2: uence diagrams betting coin ip.

Definition 3 (Direct Intervention) Given domain described U D, set
decisions said direct intervention X U respect (1)
x 2 X , x - , (2) 2 U , 6 -X .
example, medical-treatment story, r direct intervention t,
- r c 6 -t r. another example, suppose physician additional decision
p whether pay patient take treatment. reasonable expect
- p. Furthermore, amount payment small, reasonable c 6 -t p.
Consequently, p qualifies direct intervention t. Nonetheless, amount payment
suciently large, patient may use money improve health care. Thus,
c -t p; p satisfy condition 2 direct intervention t.
Given notion direct intervention, define atomic intervention.

Definition 4 (Atomic Intervention) Given domain described U D, decision
x^ 2 said atomic intervention x 2 U respect (1) fx^g direct
intervention fxg respect D, (2) x^ precisely instances (a) idle,
corresponds instance nothing x, (b) set(x) every instance x x,
x = x whenever x^ =set(x).
discussed introduction, Pearl takes concept atomic intervention
primitive. Whether decision direct (or atomic) intervention, however,
depends underlying causal relationships domain. medical-treatment
story, suppose physician decision k whether administer treatment
(a drug) without patient's knowledge. believe treatment truly effective
placebo effect, assert k direct intervention t. If,
however, believe treatment placebo effect, k direct
intervention t, k also directly affect c. Thus, notions direct
atomic intervention require definitions, lest meaning cause would hidden
primitives.
note that, bi-directional causal relationships among variables U ,
always possible every chance variable atomic intervention.
example, consider adiabatic system consisting cylindrical chamber moveable
419

fiHeckerman & Shachter

instance t(r)
1: complier
2: defier
3: always taker
4: never taker

r =take r =don't take
=yes
=no
=no
=yes
=yes
=yes
=no
=no

Table 4: mapping variable t(r).
top, model variables pressure? (p) volume? (v ).9 allow
top chamber move freely, placing various weights top chamber
constitutes atomic intervention p; p cause v respect
p^. contrast, fixing top chamber particular locations constitutes atomic
intervention v ; v cause p respect v^. laws
physics, however, decisions p^ v^ available simultaneously.

6. Mapping Variables
understand concept mapping variable, let us reexamine Savage's basic formulation decision problem. Recall chance variables U deterministic function
decision variables state world . effect, possible state
world defines mapping decisions chance variables U . Thus, represents
possible mappings U . characterize mapping variable U
function D, use suggestive notation U (D) denote mapping variable.
general, given domain described U , D, , set decision variables D,
set chance variables X U , mapping variable X (Y ) variable represents
possible mappings X .
example, consider medical-treatment story. mapping variable t(r) represents possible mappings decision variable r (recommendation) chance
variable (taken?). example, instances t(r), shown Table 4, natural
interpretation. particular, instance patient accepts treatment
recommend represents patient complies recommendation; instance
patient accepts treatment recommend represents
patient defies recommendation; on.
notion mapping variable discussed Heckerman Shachter (1994),
Balke Pearl (1994) name \response function." related counterfactual
variable described Neyman (1923), Rubin (1978), Howard (1990). discuss
would denote X (Y = Y): variable X choose instance .
important property concerning mapping variables that, given variables X; Y;
X (Y ), always write X deterministic function X (Y ). example,
deterministic function r t(r); U deterministic function U (D) .
9. example appropriate technically, uses continuous variables. Nonetheless, example
illustrates point.

420

fiDecision-Theoretic Foundations Causal Reasoning

discussions follow, useful extend definition mapping variable
include chance variables arguments. example, medical-treatment story, seems
reasonable define mapping variable c(t) instances helped, hurt, always cured,
never cured. Together, mapping variables t(r) c(t) describe possible states
world U (D) . (E.g., t(r) =complier c(t) =helped corresponds state 1
Table 3.) shall see, decomposition U (D) facilitates graphical representation
causal relationships.
Unfortunately, defining mapping variables chance-variable arguments always
possible. medical-treatment domain, patient always taker (states 10
11 Table 3), t=yes regardless r. Consequently, tell whether c(t)
helped always cured|that is, c(t) uniquely identified. Savage's decisiontheoretic framework requires state world act uniquely determine
instance c(t) (a consequence), instance c(t) well defined. Nonetheless, c(t)
well defined whenever includes atomic intervention (t^), guaranteeing
take instances (as t^ varies) every state world.
general, following definition mapping variable.

Definition 5 (Mapping Variable) Given domain described U D, chance variables X , variables that, every 2 \ U , exists atomic intervention
y^ 2 D,10 mapping variable X (Y ) chance variable represents possible
mappings X .

several important points made mapping variables
defined them. First, specific case, X always deterministic function
X (Y ).
Second, additional probability assessments typically required introducing
mapping variable probabilistic model. example, two independent assessments
needed quantify relationship r medical-treatment story;
whereas three independent assessments required node t(r). general, many
additional assessments required. X c instances instances,
X (Y ) many ca instances. real-world domains, however, reasonable assertions
independence decrease number required assessments. cases, additional
assessments necessary (see, e.g., Heckerman et al., 1994).
Third, following theorem, follows immediately definitions
limited unresponsiveness mapping variable. subsequent theorems
mention mapping variables, assume atomic interventions required proper
definition mapping variables included D.

Theorem 3 (Mapping Variable) Given decision problem described U D, variables X U , U [ D, X 6 -Y X (Y ) 6 - D.
example, medical treatment domain includes atomic intervention t^,
c 6 -t fr; ^tg c(t) 6 - fr; ^tg. Roughly speaking, Theorem 3 says X
unresponsive states limited way X depends
depend D. equivalence provides us alternative set conditions cause.
10. Recall Section 5 always possible atomic interventions every 2 .

421

fiHeckerman & Shachter

Corollary 4 (Causes Respect Decisions) Given decision problem described
U D, chance variable x 2 U , variables C [ U n fxg causes x
respect C minimal set variables x(C ) 6 - D.
C causes x respect D, call x(C ) causal mapping variable
respect D. Thus, following consequence Theorem 3.

Corollary 5 (Causal Mapping Variable) x(C ) causal mapping variable x
respect D, x(C ) unresponsive D.

7. Canonical Form uence Diagrams
define means uence diagram canonical form.

Definition 6 (Canonical Form) uence diagram decision problem described
U said canonical form (1) chance nodes responsive
descendants one decision nodes (2) chance nodes descendants
one decision nodes deterministic nodes.
immediate consequence definition chance node descendant
decision node must unresponsive D.
construct uence diagram canonical form given problem including
uence diagram causal mapping variable every variable responsive
decisions. so, make every responsive variable deterministic function
mapping variable corresponding set causes. example, consider medicaltreatment story depicted uence diagram Figure 3a. variables c
responsive r, corresponding nodes deterministic. Consequently,
uence diagram canonical form. construct canonical form uence diagram,
introduce mapping variables t(r) c(r), shown Figure 3b. responsive
variables deterministic; mapping variables unresponsive decision.
example illustrates important point: Mapping variables may probabilistically
dependent. return issue Section 8.
general, construct uence diagram canonical form decision
problem characterized U follows.

Algorithm 1 (Canonical Form)
1. Add node diagram corresponding variable U [
2. Order variables x1; : : :; xn U variables unresponsive come first
422

fiDecision-Theoretic Foundations Causal Reasoning

r

r





c

c

t(r)

c(r)

(a)

(b)

Figure 3: (a) uence diagram medical-treatment story. (b) corresponding
uence diagram canonical form.
3. variable xi 2 U responsive D,
(a) Add causal-mapping-variable chance node xi (Ci) diagram,
Ci [ fx1; : : :; xi,1g
(b) Make xi deterministic node parents Ci xi (Ci )
4. Assess independencies among variables unresponsive D11

algorithm well defined, always possible find set Ci satisfying
condition step 3a. particular, xi 6 -D Property 3. Consequently, even
contains atomic intervention, always create causal mapping variable every
responsive variable U .
Also, structure uence diagram constructed using Algorithm 1 valid.
Namely, Corollary 5, causal mapping variables added step 3 unresponsive
D. Thus, suppose identify relevance arcs deterministic nodes according
Equation 3 using variable ordering nodes followed
unresponsive nodes (including causal mapping variables), turn followed
responsive nodes order specified step 2. Then, (1) would add arcs
unresponsive nodes Theorem 1 (and algorithm adds none); (2) would
add arcs among unresponsive nodes described step 4; (3) every responsive
variable xi , would make xi deterministic node (as described step 3b) definition
mapping variable.
addition, structure results Algorithm 1 canonical form.
particular, arcs unresponsive nodes, responsive
variables descendants D. Also, Theorem 2, know every responsive
node descendant D, (by construction) deterministic node.
11. mapping variables random variables, assessment dependencies among unresponsive
variables is, principle, different assessing dependencies among ordinary random
variables. Nonetheless, counterfactual nature variables confusing. Howard (1990)
describes method probability assessment addresses concern.

423

fiHeckerman & Shachter

r

r




t(r, )




g

g
c(t)
c

c

(a)

(b)

Figure 4: (a) Another uence diagram medical-treatment story. (b) corresponding uence diagram canonical form.
Furthermore, construction, every responsive variable xi 2 U one set causes
explicitly encoded diagram (Ci).
illustrate algorithm, consider medical-treatment story depicted
uence diagram Figure 4a, variable g (genotype?) represented explicitly,
c 6 -t fr; ^tg g 6 - fr; ^tg. construct uence diagram canonical
form problem, first add variables fr; ^t; g; t; cg diagram choose
ordering (g; t; c). c responsive = fr; ^tg, causes fr; ^tg
t, respectively. Consequently, add causal mapping variables t(r; ^t) c(t)
new diagram, make deterministic function r, t^, t(r; ^t) c deterministic
function c(t). Finally, assess dependencies among unresponsive variables
fg; t(r; ^t); c(t)g, adding arcs g t(r; ^t) c(t) assumption causal
mapping variables conditionally independent given g . resulting canonical form
uence diagram shown Figure 4b.
Canonical form generalization Howard Canonical Form, developed
Howard (1990) facilitate computation value information.12 making
important decisions, decision analysts investigate useful gather additional information. investigation typically done computing extra value decision
maker would obtain observing earlier one chance variables domain.
decision maker expect observe chance variable x prior making decision d,
value information x extra value would obtain able observe
chance variable x making decision d. value information never negative,
serves bound value experiment: would never worthwhile
spend value information x obtain (possibly imperfect)
observation x making decision d.
Given ordinary uence diagram, compute value information
variables responsive D, variables observed decisions
made. contrast, always compute value information mapping
12. uence diagrams HCF allow mapping variables whose arguments contain chance variables.

424

fiDecision-Theoretic Foundations Causal Reasoning

variables corresponding responsive variables canonical form uence diagram, variables unresponsive definition. example, consider decision
continue quit smoking described decision variable (smoke) chance variables
l (lung cancer?) l(s). Although cannot compute value information l
responsive D, compute value information l(s).
first glance, may seem pointless determine value information
variable cannot observed (such l(s)). Nonetheless, often learn something
mapping variable. example, imagine test measures susceptibility
someone's lung tissue lung cancer presence tobacco smoke. Learning result
test may well update probability distribution l(s). computing
value information l(s), obtain upper bound would willing
pay undergo test.

8. Pearl's Causal Framework

demonstrate relationship Pearl's causal framework ours.
mentioned, Pearl's framework similar SGS (see background notes SGS
discussion). Thus, many remarks section apply SGS's model cause
well. notable exception SGS formally define direct intervention.
following theorem outlines relationship.

Theorem 6 Given chance variables U , suppose set decision variables contains
unique atomic intervention x^ every x 2 U decisions. Given graph G,

directed acyclic graph nodes corresponding variables U , suppose that,
x 2 U , PaG (x) [ fx^g causes x respect D.13 Then, relationships among
variables U [ expressed set simultaneous equations

x = fx (PaG (x); x^; x(PaG (x); x^))
x 2 U , fx deterministic function x = x x^ =set(x).

Proof: theorem follows applying Algorithm 1 using ordering U consistent
graph G. 2
Thus, see Pearl's structural-equation model specialization canonical form
identify (1) Pearl's domain variables chance variables U , (2) Pearl's atomic
interventions atomic interventions D, (3) Pearl's causal graph graph G,
(4) Pearl's random disturbance x causal mapping variable x(PaG (x); x^).
correspondence permits several clarifications Pearl's framework. First,
precise definition atomic intervention. Unlike Pearl's model, concept atomic
intervention primitive, framework provides way verify interventions
indeed atomic.
Second, see means random disturbances exogenous. Namely,
random variables unresponsive decisions D.
13. dicult show condition consistent condition that, x 2 U , x^
atomic intervention x.

425

fiHeckerman & Shachter

Third, precise definition random disturbance terms causal mapping
variable. Consequently, means assessing joint probability distribution
variables, and|in particular|a means assessing independencies among variables. fact, whereas Pearl requires random disturbances marginally independent,
definition imposes requirement.
Theorem 6 shows structural-equation model encoded uence
diagram canonical form. converse also true|that is, uence diagram
canonical form encoded structural-equation model. result may seem surprising, Pearl's model every domain variable must atomic intervention,
decision variables must atomic interventions, random disturbances must independent. Given uence diagram canonical form, however, encode chance
decision variables structural equation model. Specifically, chance variable x
encoded variable pair fx; x^g x^ instantiated idle, decision variable
encoded variable pair fd; d^g act idle forbidden. addition,
noted Pearl, remove dependencies among mapping variables (at least practice)
introducing hidden common causes.14
Nonetheless, hidden common causes sometimes need introduced, Pearl's
structural-equation model less ecient representation canonical form.
example, represent relationships Figure 4b, would use structual-equation
model disturbance variables corresponding g (^g), t(r; g; ^t), c(t; g; ^c). Assuming
r; g; c binary variables, disturbance variables 2, 16, 16 instances,
respectively.15 Assuming disturbance variables independent, joint probability
distribution variables contain 31 probabilities. contrast, mapping variables
Figure 4b four instances. Consequently, joint probability distribution
unresponsive variables canonical-form representation contain 13 probabilities.
note Balke Pearl (1994) relax assumption mapping variables
independent. Nonetheless, generalization structural-equation model,
call functional model, still less ecient canonical form. ineciency
comes fact canonical form encodes joint probability distribution among
unresponsive variables (possibly including domain mapping variables), whereas
functional model encodes joint probability distribution among mapping variables only.
example, canonical-form uence diagram Figure 4b encodes assertion
t(r; ^t) c(t) independent given g. assertion encoded BalkePearl representation. represent relationships Figure 4b using functional
model, include variable g , case obtain 31-probability model
described previous paragraph. Alternatively, exclude variable g
model, encode dependency mapping variables t(r; ^t) c(t; c^)
14. assumption mapping variables independent convenient consequence
graph G interpreted Bayesian network traditional sense. is, variables X
d-separated Z G, X conditionally independent given Z according
structural-equation model corresponding G. (See Pearl, 1988, definition d-separation.) SGS
(p. 54) refer association causal Markov condition.
15. Note mapping variable x(Y; x^) number instances mapping variable
x(Y ).

426

fiDecision-Theoretic Foundations Causal Reasoning

arc two variables. resulting Balke-Pearl model 15 probabilities
contrast 13 required canonical form.

9. Counterfactual Reasoning
noted, ordinary uence diagram adequate making decisions
uncertainty, inadequate counterfactual reasoning. section, examine
form reasoning suggest facilitated uence diagrams canonical
form.
Given domain described U X; Y; Z U , counterfactual reasoning
addresses questions form: choose = D1 observe X = X,
probability = choose = D2 observe Z = Z? example,
medical-treatment domain, may wish know: recommend treatment
patient takes drug cured, probability patient cured
recommend treatment? reasoning often important realworld|for example, legal argument (Ginsberg, 1986; Balke Pearl, 1994; Goldszmidt
Darwiche, 1994; Heckerman et al., 1994).
answer queries using uence diagrams canonical form. illustrate
approach, consider medical-treatment question previous paragraph. answer
query, begin uence diagram canonical form shown Figure 4b.
Then, duplicate decision variables chance variables responsive
decisions, shown Figure 5. original variables represent act r =take, t^=idle
consequences. duplicate variables (denoted primes) represent act r0 =don't
take, t^=idle consequences. need duplicate unresponsive variables
(including causal mapping variables) because, definition, affected
decisions.16 Next, copy deterministic function associated original
variable primed counterpart. Then, instantiate decision chance variables
described query (r =take, t^=idle, =taken, c =cured, r0 =don't take,
t^0 =idle). Finally, use standard Bayesian-network inference method compute
probability variable(s) interest (c0 example).
canonical form uence diagram natural representation counterfactual
reasoning two reasons. One, deterministic relationships responsive chance
variable parents remains choice D. Two, instances assumed
unresponsive variables unaltered decisions. ordinary uence diagram
offers neither guarantees.
approach, described Heckerman Shachter (1994), similar Balke
Pearl (1994). main difference two approaches Balke Pearl
use functional model base representation, making approach less ecient
ours. Goldszmidt Darwiche (1994) describe graphical language modeling
evolution real-world systems time. Although approach explicitly
address counterfactual reasoning, adapted do, yielding alternative
approach.
16. general, need duplicate (1) decision variables change query (2)
chance variables responsive decisions change.

427

fiHeckerman & Shachter

g

r


t(r)

r


c(t)





c

c

Figure 5: use canonical form compute counterfactual query. Shaded variables
instantiated.

10. Conclusions
presented definition cause effect terms decision-theoretic primitives act, state world, consequence determined act state world,
shown definition provides foundation causal reasoning. definition departs traditional view causation causal assertions made
relative set decisions. Consequently, argued, definition allows
precise specification causal relationships.
addition, shown definition provides basis graphical representation cause. described special class uence diagrams,
canonical form, shown equally expressive ecient Pearl's
structural-equation model. Finally, shown uence diagrams canonical
form, unlike ordinary uence diagrams, used counterfactual reasoning.

Acknowledgments
thank Jack Breese, Tom Chavez, Max Chickering, Eric Horvitz, Ron Howard, Christopher Meek, Judea Pearl, Mark Peot, Glenn Shafer, Peter Spirtes, Patrick Suppes,
anonymous reviewers useful comments.

References
Angrist, J., Imbens, G., & Rubin, D. (1995). Identification causal effects using instrumental variables. Journal American Statistical Association, press.
Balke, A., & Pearl, J. (1994). Probabilistic evaluation counterfactual queries. Proceedings Tenth Conference Uncertainty Artificial Intelligence, Seattle, WA,
pp. 46{54. Morgan Kaufmann.
428

fiDecision-Theoretic Foundations Causal Reasoning

de Finetti, B. (1937). La prevision: See lois logiques, ses sources subjectives. Annales de
l'Institut Henri Poincare, 7, 1{68. Translated Kyburg Smokler, 1964.
Ginsberg, M. (1986). Counterfactuals. Artificial Intelligence, 30, 35{79.
Goldszmidt, M., & Darwiche, A. (1994). Action networks: framework reasoning
actions change uncertainty. Proceedings Tenth Conference
Uncertainty Artificial Intelligence, Seattle, WA, pp. 136{144. Morgan Kaufmann.
Heckerman, D. (1995). Bayesian approach learning causal networks. Proceedings
Eleventh Conference Uncertainty Artificial Intelligence, Montreal, QU, pp.
285{295. Morgan Kaufmann.
Heckerman, D., Breese, J., & Rommelse, K. (1994). Sequential troubleshooting uncertainty. Proceedings Fifth International Workshop Principles Diagnosis,
New Paltz, NY, pp. 121{130.
Heckerman, D., & Shachter, R. (1994). decision-based view causality. Proceedings
Tenth Conference Uncertainty Artificial Intelligence, Seattle, WA, pp. 302{310.
Morgan Kaufmann.
Holland, P. (1986). Statistics causal inference. Journal American Statistical
Association, 81, 945{968.
Howard, R. (1990). uence relevance knowledge. Oliver, R., & Smith, J.
(Eds.), uence Diagrams, Belief Nets, Decision Analysis, chap. 1. Wiley
Sons, New York.
Howard, R., & Matheson, J. (1981). uence diagrams. Howard, R., & Matheson, J.
(Eds.), Readings Principles Applications Decision Analysis, Vol. II, pp.
721{762. Strategic Decisions Group, Menlo Park, CA.
Lewis, D. (1973). Counterfactuals. Harvard University Press, Cambridge, MA.
Neyman, J. (1923). application probability theory agricultural experiments.
Translated Statistical Science, 5:465-480 (1990).
Pearl, J. (1988). Probabilistic Reasoning Intelligent Systems: Networks Plausible
Inference. Morgan Kaufmann, San Mateo, CA.
Pearl, J. (1993). Comment: Graphical models, causality, intervention. Statistical
Science, 8, 266{269.
Pearl, J. (1995). Causal diagrams empirical research. Biometrika, press.
Pearl, J., & Verma, T. (1991). theory inferred causation. Allen, J., Fikes, R., &
Sandewall, E. (Eds.), Knowledge Representation Reasoning: Proceedings
Second International Conference, pp. 441{452. Morgan Kaufmann, New York.
Robins, J. (1986). new approach causal interence mortality studies sustained
exposure results. Mathematical Modelling, 7, 1393{1512.
429

fiHeckerman & Shachter

Rubin, D. (1978). Bayesian inference causal effects: role randomization. Annals
Statistics, 6, 34{58.
Simon, H. (1977). Modles Discovery Topics Methods Science. D.
Reidel, Dordrecht, Holland.
Spirtes, P., Glymour, C., & Scheines, R. (1993). Causation, Prediction, Search.
Springer-Verlag, New York.

430

fiJournal Artificial Intelligence Research 3 (1995) 147-185

Submitted 8/94; published 8/95

Integrated Framework Learning Reasoning
Christophe G. Giraud-Carrier

Department Computer Science, University Bristol
Bristol, BS8 1TR U.K.

cgc@compsci.bristol.ac.uk

Tony R. Martinez

Department Computer Science, Brigham Young University
Provo, UT 84602 U.S.A.

martinez@cs.byu.edu

Abstract

Learning reasoning aspects considered intelligence.
studies within AI separated historically, learning topic machine
learning neural networks, reasoning falling classical (or symbolic) AI. However, learning reasoning many ways interdependent. paper discusses
nature interdependencies proposes general framework called FLARE,
combines inductive learning using prior knowledge together reasoning propositional setting. Several examples test framework presented, including classical
induction, many important reasoning protocols two simple expert systems.

1. Introduction

Induction deduction underlying processes intelligent agents. Induction \involves intellectual leaps particular general" (D'Ignazio & Wold, 1984).
plays important part knowledge acquisition learning. D'Ignazio Wold (1984)
claim indeed, \All laws nature discovered inductive reasoning." Deduction form reasoning acquired knowledge. typically result
generation new facts, rather establishes cause-effect relationships existing facts. Deduction may applied forward seeking consequences certain existing
hypotheses backward discover necessary conditions achievement certain
goals. Despite differences, induction deduction strongly interrelated.
ability reason domain knowledge often based rules domain,
must acquired somehow; ability reason often guide acquisition
new knowledge learning.
Inductive learning subject much research leading design
variety algorithms (e.g., Clark & Niblett, 1989; Michalski, 1983; Quinlan, 1986; Salzberg,
1991). general, inductive learning systems generate classification rules examples.
Typically, system first presented set examples (objects, situations, etc.), also
known training set. Examples usually expressed attribute-value language
represent recorded instances attribute-value pairs together corresponding
classification. system's goal discover sets sucient critical features rules
properly classify examples training set (convergence) adequately extend
previously unseen examples (generalization).
Though machines still far cry matching human qualitative inductive leaps,
inductive learning systems proven useful wide range applications medicine

c 1995 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiGiraud-Carrier & Martinez

(breast cancer, hepatitis detection), banking (credit screening), defense (mine-rock discrimination), botany (iris variety identification, venomous mushroom detection) others
(Murphy & Aha, 1992).
study deductive reasoning goes least far back early Greek philosophers, Socrates Aristotle. formalization given rise variety logics,
propositional first-order predicate logic default logic several non-monotonic
extensions. Many logics successfully implemented artificial systems
(e.g., PROLOG, expert systems). typically consist pre-encoded knowledge rule
base, given set facts (identified either causes consequences) inference
engine. inference engine carries deductive process using rules rule
base facts provided. Several systems successfully used
various domains, medical diagnosis (Clancey & Shortliffe, 1984) geology (Duda
& Reboh, 1984).
One greatest challenges current deductive systems knowledge acquisition,
is, construction rule base. Typically, rule base generated domain
knowledge extracted human experts carefully engineered rules. Knowledge
acquisition tedious task presents many diculties practically theoretically.
suciently rich training set obtained, inductive learning may used
effectively complement traditional approach knowledge acquisition. Indeed,
system's knowledge base constructed rules encoded priori rules
generated inductively examples. words, rules examples need
mutually exclusive. strong knowledge principle (Waterman, 1986) early work
bias (Mitchell, 1980) suggest need prior knowledge. Rules supplied priori one
simple form prior knowledge used successfully several inductive systems
(e.g., Giraud-Carrier & Martinez, 1993; Ourston & Mooney, 1990). Similarly, proposals
made enhance deductive systems learning capabilities (e.g., Haas &
Hendrix, 1983; Rychener, 1983).
authors' contention study interdependencies learning reasoning subsequent integration induction deduction unified
frameworks may lead development powerful models. paper describes
system, called FLARE (Framework Learning REasoning), attempts combine
inductive learning using prior knowledge together reasoning. Induction deduction
FLARE carried within confines non-recursive, propositional logic. Learning effected incrementally system continually adapts new information. Prior
knowledge given teacher form rules. Within context particular
inductive task, rules may serve produce useful learning biases. Simple defaults
combined learning capabilities enable FLARE exhibit reasoning normally
considered non-monotonic.
paper organized follows. Section 2 presents FLARE argues validity
unified framework. FLARE's representation language described algorithms
employed learning reasoning detailed. Section 3 reports experimental results
classical datasets, number \well-designed" reasoning protocols several
applications, including two simple expert systems. limitations system
also described. Section 4 discusses related work induction deduction. Finally,
section 5 concludes paper summarizing results discussing research.
148

fiAn Integrated Framework Learning Reasoning

2. FLARE - Framework Learning Reasoning

section, FLARE's learning reasoning mechanisms detailed. description
discussion FLARE's representation language given first Section 2.1, along
useful definitions simple, practical example serve running
example throughout paper. Sections 2.2 2.5 follow top-down approach
description FLARE.

2.1 FLARE's Representation Language

FLARE's representation language instance attribute-value language (AVL).
FLARE, attributes may range nominal domains bounded linear domains, including
closed intervals continuous numeric values. basic elements knowledge AVL
vectors defined cross-product domains attributes. components
vector specify value attribute. following simple extension made AVL.
attribute domain A, takes values [ f?; ?g.
special symbols ? ? stand don't-care don't-know, respectively.
semantics associated ? ? different. attribute whose value ?
one known (or assumed) irrelevant current context, attribute
whose value ? may relevant actual value currently unknown. ? symbol
allows encoding rules, ? symbol accounts missing attribute values
real-world observations.
2.1.1 First-Order Attribute-Value Translation

Since learning reasoning tasks often expressed English simple, direct counterparts classical first-order logic language (FOL), necessary FLARE
translate FOL clauses AVL equivalent. AVL clearly expressive FOL,
FLARE inherent limitations. purposes discussion, let predicates form p(x) p(x; C ) C constant called avl-predicates. Then,
FOL clauses translated AVL two kinds:

ground facts: p(C ) :p(C ) C constant (e.g., block(A)).
2. simple implications: (8x)P (x) ) q (x) P (x) conjunction avl-predicates

1.

q (x) is, without loss generality, single, possibly negated avl-predicate (e.g.,
block(x) ^ weight(x; heavy ) ) :on table(x)).

clauses involve one universally quantified variable thus essentially nonrecursive, propositional clauses. Despite restricted language, FLARE effectively handles
significant range applications. Moreover, AVL accounts simple, ecient matching
mechanisms lends naturally many inductive learning problems witnessed
use many successful learning systems (Clark & Niblett, 1989; Michalski, 1983;
Quinlan, 1986).
FOL statements aforementioned forms translated straightforward way
equivalent symbolic-valued AVL representation, shown Figure 1. similar
transformation proposed context ILP (Dzeroski, Muggleton, & Russell,
1993). Like FLARE, ILP systems, LINUS (Lavrac, Dzeroski, & Grobelnik,
149

fiGiraud-Carrier & Martinez

1. Attribute definition: avl-predicate, create matching Boolean (for p(x)) multi-valued
(for p(x; C )) attribute. ground facts, create multi-valued attribute, called label, whose
values constants.
2. Vector definition: implication, create matching vector attributes corresponding
premise conclusion appropriate value attributes set ?.
ground fact, create matching vector value label constant
attribute corresponding predicate appropriate value. Tag attribute corresponding
conclusion.

Figure 1: FOL AVL Transformation
FOL

AVL
Rep (b) Qua (b) Pac (b)
Republican(x)) :Pacifist(x)
1
?
0T
Quaker(x))Pacifist(x)
?
1
1T

Table 1: Nixon Diamond (Reiter & Griscuolo, 1981)
1991), first map ILP problems propositional learning problems rely attributebased learning.
creation attribute label step 2 stems fact ground facts form
p(C ) rewritten simple implications form label(x; C ) ) p(x). Notice
attributes whose values ? vector correspond exactly predicates
appear premise corresponding FOL clause. attribute corresponding
q (x) different usages. functions conclusion forward chaining
target classification inductive learning. cases, also used goal.
avoid unnecessary confusion, attribute corresponding q (x) simply referred
target-attribute. values target-attribute subsequently tagged
subscript . translation FOL AVL currently performed manually.
clear number predicates increases, size vectors. Since
vectors size many may values set relatively
small number attributes, may result large memory requirements, well
increase execution time operations vectors. predicates
qualify different values concept (e.g., red(x), yellow(x), color), possible
limit size vectors translating predicates single multi-valued
attribute (e.g., color(x; V ), V constant: red, yellow, etc.). particularly
useful conclusion part q (x) corresponds classification x.
Tables 1 4 contain four simple examples demonstrate transformation.
derived attribute AVL column followed type (b Boolean,
multi-valued). Table 1 shows Nixon Diamond, classical example con icting defaults. Informally, Nixon Diamond states Republicans typically pacifist
Quakers typically pacifist. con ict arises one asserts Nixon
Republican Quaker. Table 2 contains assertions animals ability
y. states animals normally y, birds typically ying animals penguins birds y. Table 3 shows statements regarding eyes fitness
lenses. Finally, Table 4 contains facts simple blocks world.
150

fiAn Integrated Framework Learning Reasoning

FOL

AVL
Ani (b) Bir (b) Pen (b) Fly (b)
Animal(x)) :Fly(x)
1
?
?
0T
Bird(x))Animal(x)
1T
1
?
?
Bird(x))Fly(x)
?
1
?
1T
Penguin(x))Bird(x)
?
1T
1
?
Penguin(x)) :Fly(x)
?
?
1
0T

Table 2: Flying Flying (Lifschitz, 1988)
FOL

AVL
Tpr (m) Eye (m) Fit (b)
Tear-prod-rate(x,low))Eyes(x,dry)
low
dryT
?
Eyes(x,dry)) :Fit(x)
?
dry
0T

Table 3: Fitting Lenses
2.1.2 Examples vs. Precepts vs. Rules

Informally, problem supervised learning may described follows. Given (1) set
categories, (2) category, set instances \objects" category (3)
optional prior knowledge, produce set rules sucient place objects correct
category. AVL, instances consist sets attribute-value pairs vectors, describing
characteristics objects represent, together object's category.
context, category target-attribute.
example vector attributes set either ? one possible
values. rule vector attributes become ? result
generalization inductive learning. precept similar rule but, unlike rule,
induced examples. Precepts either given teacher deduced
general knowledge relevant domain study. context given rule
precept, ? attributes effect value category. Precepts rules
thus represent several examples. instance, let p = (?; 1; 0; 0T ) precept,
attributes range set f0,1,2g. p represents three examples: (0; 1; 0; 0T ),
(1; 1; 0; 0T ) (2; 1; 0; 0T ).
distinction rules precepts limited learning. reasoning,
vectors (including examples generalize) rules. FLARE, rules formed
dropping conditions (Michalski, 1983), is, certain circumstances (see Section
2.4.2), one attribute set ?. Precepts, hand, rules encoded priori.
ect high-level knowledge (or common sense) real-world. precept
\suggests something advisory obligatory communicated typically teaching"
(Webster's Dictionary).
2.1.3 Running Example

illustrate definitions algorithms following sections, final example
transformation constructed, based mediadv knowledge base (Harmon &
King, 1985). purposely simple example serve running example throughout
151

fiGiraud-Carrier & Martinez

FOL

AVL
Lab (m) Blk (b) Hvy (b) OnT (b)
block(A)

1T
?
?
block(B)
B
1T
?
?
heavy(A)

?
1T
?
heavy(B)
B
?
1T
?
block(x) ^ heavy(x) ) table(x)
?
1
1
1T
:on table(A)

?
?
0T

Table 4: Simple Blocks World, adapted (Lifschitz, 1988)
paper. discussion complete mediadv knowledge base Section 3.5. Here,
two conditions (i.e., instructional feedback presentation modification) left
original rules used. Table 5 contains informal English version
knowledge used (with reference rules mediadv generated
applicable) corresponding translation AVL vectors.
Let KB resulting set vectors. attributes given order: situation,
stimulus-situation, response, appropriate-response, stimulus-duration, training-budget
media. Note attributes nominal. symbolic values used English statements transformed equivalent nominal values vectors. Hence,
example, first statement gives rise vector attribute situation set
0 (the corresponding nominal value schematics attribute), targetattribute stimulus-situation set 0 (the corresponding nominal value symbolic
attribute).
top goal system suggest effective media training, based
four conditions: situation, response, stimulus-duration, training-budget. Note
attributes stimulus-situation appropriate-response used subgoals reaching
final conclusion. Vectors v13 v17 examples since conditions set
values. part original mediadv knowledge base added exercise
important features algorithms. KB given, vectors KB condition
attributes set ? precepts rather rules. instance, v7 v12 precepts.
Then, term rule applies new generalizations, induced FLARE KB .
instance, v80 (see Section 2.4.3) rule.

2.2 Algorithmic Overview
FLARE self-adaptive, incremental system. uses domain knowledge empirical
evidence construct maintain knowledge base. FLARE's knowledge base interpreted \best far" set rules coping current application.
sense, FLARE follows scientific approach theory formation/revision: available prior
knowledge experience produce \theory" updated refined continually new
evidence.
FLARE involves three main functions whose definitions high-level algorithmic interactions given Figure 2. details function's implementation given
following sections. intuitive overview presented here.
152

fiAn Integrated Framework Learning Reasoning






























English Statements
situation = schematics
(Rule3)
stimulus-situation = symbolic
situation = conversation
(Rule4)
stimulus-situation = verbal
situation = photograph
(Rule2)
stimulus-situation = pictorial
response = observing
(Rule5)
response = thinking
appropriate-response = covert
response = emoting
(Rule10)
appropriate-response = affective
stimulus-situation = verbal (Rule13)
appropriate-response = covert
stimulus-duration = brief
media = lecture
stimulus-situation = verbal (Rule14)
stimulus-situation = symbolic
stimulus-situation = pictorial
appropriate-response = covert
stimulus duration = brief
training-budget = medium
media = lecture-with-slides
stimulus-situation = verbal (Rule16)
stimulus-duration = brief
media = role-play-w/verbal-feedback
stimulus-situation = verbal (Rule17)
appropriate-response = affective
media = role-play-w/video-feedback
situation = conversation
response = observing
response = thinking
stimulus-duration = brief
training budget = medium
media = lecture
situation = photograph
response = emoting
stimulus-duration = persistent
training-budget = small
media = role-play-w/verbal-feedback
situation = photograph
response = emoting
stimulus-duration = persistent
training-budget = small
media = lecture
situation = photograph
response = emoting
stimulus-duration = persistent
training-budget = small
media = role-play-w/verbal-feedback

v1

Equivalent AVL Vectors
= 0 0T ? ? ? ? ?

v2

= 1 1T ? ?

? ? ?

v3

= 2 2T ? ?

? ? ?

v4
v5

= ? ?
= ? ?

0 0T ? ? ?
1 0T ? ? ?

v6

= ? ?

2 1T ? ? ?

v7

= ? 1

? 0

0 ? 2T

v8 = ? 1
v9 = ? 0
v10 = ? 2

? 0
? 0
? 0

0 1 3T
0 1 3T
0 1 3T

v11 = ? 1
pty = 1

? ?

0 ? 0T

v12 = ? 1
pty = 3

? 1

? ? 1T

v13 = 1 ?
v14 = 1 ?

0 ?
1 ?

0 1 2T
0 1 2T

v15 = 2 ?

2 ?

1 0 0T

v16 = 2 ?

2 ?

1 0 2T

v17 = 2 ?

2 ?

1 0 0T

Table 5: Simple KB Running Example
153

fiGiraud-Carrier & Martinez

DEFINITION






Function: Generate-Precepts
{ Input: set general rules, set facts one designated target-attribute.
{ Output: one precepts.
Function: Reasoning
{ Input: current knowledge base, set facts encoded vector v, one designated target-

attribute optionally, target value target-attribute.
{ Output: vector v+ equal v together facts deduced v, including derived
value target-attribute.
Function: Adapting
{ Input: current knowledge base, vector v+ output function Reasoning target
value target-attribute.
{ Output: updated knowledge base.

IMPLEMENTATION
1. Preprocessing: Perform Generate-Precepts
2. Main loop: vector presented system
(a) Perform Reasoning
(b) target value target-attribute, perform Adapting

Figure 2: FLARE - Algorithmic Overview
Conceptually, FLARE's execution consists two phases. preprocessing phase,
FLARE uses prior knowledge form general rules may viewed encoding
\commonsense" knowledge. Using deduction given facts, domain-specific precepts
generated instantiation general knowledge domain hand. Section 2.5
details Generate-Precepts function. need generating explicitly encoding
precepts individual vectors preprocessing phase arises FLARE's inductive mechanisms take place vector level. Thus, even though always possible
deduce general knowledge, precepts useful induction
made explicit.
normal processing, FLARE executes an, least conceptually, infinite loop. Steps (a)
(b) executed every time new information (in form AVL vectors) presented
system. step (a), FLARE reasons \facts" provided input vector
rules found current knowledge base. Rule-based reasoning similaritybased reasoning combined discussed Section 2.3 derive value targetattribute, well attributes along forward chain conclusion. step
(b), FLARE adapts current knowledge base. FLARE supervised learner,
adapt target value target-attribute explicitly given part
information presented. combination steps (a) (b) referred learning.
Section 2.4 details Adapting function.
154

fiAn Integrated Framework Learning Reasoning

Note reasoning based upon available knowledge prior adapting plausible.
Even available information insucient and/or incomplete, humans often attempt
make tentative decision get corrected necessary. one time, decision
made represents kind \best guess" given currently available information.
(correct) information becomes available, accurate decisions become.

2.3 FLARE's Reasoning

FLARE implements simple form rule-based reasoning combined similarity-based
reasoning, similar CONSYDERR (Sun, 1992). Sun argued combination
effectively decreases system's susceptibility brittleness (Sun, 1992). particular,
absence applicable rules information incomplete, FLARE relies similarity previously encountered situations make useful predictions. Others also
argued analogy necessary condition commonsense reasoning subsequent
overcoming brittleness (Minsky & Riecken, 1994; Wollowski, 1994). Section 2.3.1 shows
notion Clark's completion (1978) applied inductively learned rules
exploited similarity-based reasoning generate new rules. Sections 2.3.2 2.3.7
describe illustrate FLARE's reasoning mechanisms.
2.3.1 Completion

Inductively learned rules form (8x)P (x) ) q (x), P conjunction avlpredicates, essentially classification rules definitions establish relationships features, captured P (x), concepts, expressed q (x). keeping
classical assumption known learning system false default, inductively generated rules lend naturally completion principle proposed
Clark (1978). is, classification rules become \if if" statements, i.e.,
P (x) , q(x). Hence, completion, q (x) known true, possible
conclude P (x) true.
Clearly, completion apply rules. Inductively learned rules inherently
definitional essentially encode concept's description terms set features.
rules, relating concepts relative cognitive level,
definitional. example, given birds animals x animal,
follow x bird. Note that, addition inductively learned rules,
definitions may given FLARE prior knowledge.
completion principle particularly useful interacts similarity-based
reasoning generate new rules, shown following derivation.


Hypotheses:

1.
2.
3.
4.


(8x)P(x) ) q(x), may completed.
(8x)P (x) ) q (x).
P \ P 6= ; (i.e., P P attributes common).
q(x) true.
0

0

0

0

Derivation:

1. q(x) hypothesis 4.
155

fiGiraud-Carrier & Martinez

2. P(x) completion applied hypothesis 1.
3. q (x) similarity-based reasoning using hypotheses 2 3.
0

new implication concepts, namely q (x) ) q 0(x), thus generated. Though
FLARE capable deriving q 0(x) q (x), actually store new implication
knowledge base.
following example adapted (Collins & Michalski, 1989) illustrates use
derivation. Assume system learned description Chaco area
terms set G geographical conditions (i.e., G(x) )area(x; theChaco)). Furthermore,
assume system knows rule encodes set conditions C sucient
raising cattle (i.e., C (x) )raise(x; cattle)) C C G share number
conditions. system told area interest Chaco, first deduces
completion conditions G met then, taking advantage similarity
G C , system concludes cattle may raised Chaco. Note
level confidence conclusion depends upon amount similarity.
FLARE, representation extended definition indicator tagged
statements may completed (i.e., prior definitions, inductively learned classifications).
Note that, though somewhat cumbersome, extension needed since FLARE
physically separate concepts features used describe them. CONSYDERR
hand provides natural support dichotomy. FLARE's representation
makes learning readily applicable preserves consistency previously developed
models. point, issue achieving dichotomy easy learning remains
open.
2.3.2 FLARE's Reasoning Function

Deduction FLARE applied forward. Hence, facts must provided initiate
reasoning. facts coded vector attributes whose values known
accordingly set, attributes ? (i.e., don't-know). One attribute
designated target-attribute and, known, value also provided. FLARE
uses rules knowledge base facts derive value target-attribute.
Reasoning function shown Figure 3. Note discussion, current
knowledge base assumed non-empty. knowledge base empty, system
cannot deduce anything ?.
Step (1) applies completion first. FLARE finds asserted (i.e., neither ? ?) attributes v target-attributes definitions current knowledge base.
attribute found, them, completion applied \copying" v
asserted attributes corresponding definitions ? v . following two issues
must addressed FLARE implementing completion.
1. Since attributes may involved definitions one targetattribute concept, follows may one values copied
given attribute completing definitions.
2. Since FLARE's concepts rules consist sets vectors, vector
conjunction vectors sharing target-attribute form disjunction,
follows definitions may disjunctive well.
156

fiAn Integrated Framework Learning Reasoning

DEFINITION



Input: current knowledge base, set facts encoded vector v, one designated target-attribute
optionally, target value target-attribute.
Output: vector v+ equal v together facts deduced v, including value
target-attribute.

IMPLEMENTATION
1. Completion: asserted attribute v target-attribute, targetattribute definition values equal, copy asserted attributes ?
v, v.
2. Forward chaining: v's target-attribute asserted
(a) Repeat new attribute v asserted
i. Let w = v.
(* create temporary copy v *)
ii. non-asserted attribute v target-attribute, rule
applied v assert a, apply asserting w.
(* based v, assert possible attributes (other target-attribute) w *)
iii. Let v = w.
(* copy result back v next level inference *)
(b) rule applied assert v's target-attribute, apply it. Otherwise, perform
similarity-based assertion.

Figure 3: Function Reasoning
current implementation resolves two issues follows. first case, potential
con icts resolved simply giving precedence first copy made (which depends
upon order asserted attributes processed). second case, FLARE
simply chooses one defining conjunctions random applies completion it.
mechanisms (e.g., apply all, select winner based criteria, etc.)
topic research.
Completion causes information (in form asserted attributes) gained,
thus improving chance reaching goal. Indeed, purpose step (1) two-fold.
First, completion allows system reach goals otherwise achievable
existing rules. Second, even top goal achieved directly completion,
reasoning achieve enhanced described Section 2.3.1.
target-attribute asserted completion, step (2) pursues
reasoning process using forward chaining. mentioned above, v single targetattribute, corresponding final goal achieve. However, given time,
one (yet) non-asserted1 attributes v may designated subgoal may
1. either ? ?. ? precepts rules differing premises conclusions
used. cases, clear reasoning whether true don't-cares don't-knows.

157

fiGiraud-Carrier & Martinez

useful (or necessary) reaching final conclusion. Step (2)(a) heart
reasoning process. execution step (2)(a)(ii) corresponds achievement
possible subgoals given depth inference process. iteration uses knowledge
acquired previous iteration attempt derive new conclusions using existing
rules. Step (2)(b) concludes reasoning phase asserting target-attribute.
Notice target-attribute always asserted, either rule application similaritybased assertion. Hence, FLARE always reaches conclusion. worst case,
information target-attribute current knowledge base, value derived conclusion must clearly ?. cases, validity accuracy
derived conclusion depend upon available information. accuracy confidence level
may computed variety ways information static priorities, dynamic
priorities, covers counters (see Section 2.4).
two complementary mechanisms used asserting target-attribute (i.e., rule
application similarity-based assertion) described next two sections.
apply sequentially. rule exists applied, applied. Otherwise,
similarity-based reasoning takes effect.
Finally, note information regarding way goal achieved could displayed
FLARE purpose human examination inspection. Currently, FLARE
non-interactive, is, cannot query user values missing attributes may
help improve accuracy result.
2.3.3 Rule Application

Let val(a; x) denote value attribute vector x. state knowledge represented vector v , rule may applied covers v . vector x said cover
vector if:
1. x target-attribute
2. remaining attributes x, either val(a; x) = ? val(a; x) = val(a; ).
example, KB , v11 covers v7 v8 v11 cover v9 v12. Ignoring attributes
whose value ?, second condition states set remaining attribute-value pairs
x proper subset set remaining attribute-value pairs . Intuitively, x covers
satisfies premises x.
accommodate real-valued attributes, notion equality slightly extended.
Given probability two real values equal extremely small, cover
relation, condition 2, would essentially never hold. following extension,
borrowed ILA (Giraud-Carrier & Martinez, 1995), suggested. Two linear values x1
x2 equal jx1 , x2 j , > 0. Hence, vector (?, 1.2, 3.52,
?, 0T ) covers vector (2, 1.3, 3.48, ?, 0T ) = 0:5. current implementation,
fraction range possible values attribute.
2.3.4 Similarity-Based Assertion

notion similarity FLARE captured non-symmetric distance function defined
(n-dimensional) vectors. vector x stored knowledge base vector
158

fiAn Integrated Framework Learning Reasoning

presented system reason about, distance x given by:

Xn d(xi; yi)

D(x; ) = numi=1asserted(x)
where, x+i ; yi+ denote values attribute ? ?,

d(?; yi)
d(?; yi)
d(x+i ; ?)
d(x+i ; ?)
d(x+i ; yi+)
d(x+i ; yi+)

=
=
=
=
=
=

0
0:5
0:5
0:5
(x+i 6= yi+ ) attribute nominal
jx+i , yi+j attribute linear
range(i)
range(i) range values attribute num asserted(x) number
attributes ? x. equations consistent semantics
? ? defined Section 2.1.
D(x; ) meaningful x target-attribute targetattribute left computation. example, D(v11; v8) = 0, D(v13; v14) = 1=4,
D(v7; v16) = 2=3, D(v16; v7) = 5=8 D(v1; v4) undefined. detailed discussion
justification definition found elsewhere (Giraud-Carrier & Martinez,
1994a). Since every ordered set one-to-one correspondence subset natural
numbers, well defined. eliminate effects statistical outliers range(i),
dataset must ridden vectors whose attributes irregular values.
extension similarity function defined IBL (Aha, Kibler, & Albert, 1991),
inductive learning algorithms use and/or create general rules. applies
nominal linear domains, relies corresponding notion distance
values. particular, handles continuous values directly, without need discretization.
Currently, treats attribute equally. Existing methods assigning weights
attribute-wise distance (Salzberg, 1991; Stanfill & Waltz, 1986; Wettschereck & Dietterich,
1994) may incorporated D.
Similarity-based assertion consists asserting target-attribute vector v
value attribute v 's closest match given D. Note (since symmetric)
x covers D(x; y) = 0. Hence, since 0 minimum distance function,
used apply reasoning mechanisms correct order (i.e., rules first,
similarity next), computing distance rules current knowledge base
v simply selecting rule minimizes D. possible one
rule minimizes D, priority scheme devised choose winner. con ict resolution
procedure relies partially FLARE's ability learn outlined Section 2.3.5.
2.3.5 Conflict Resolution

Along vector, FLARE also stores following information:
static priority value (static priority),
159

fiGiraud-Carrier & Martinez

dynamic priority value (dynamic priority)
number vectors covered (num covers).
value static priority set 0 default may changed teacher
value priori (e.g., v11 v12 KB ). Static priorities provide means whereby rules
may prioritized according externally provided information meta-knowledge.
value dynamic priority initialized 0. value changed teacher,
however, evolves time intended resolve con icting defaults extensionally.
Con icting defaults, Nixon Diamond Table 1 may encoded priori
precepts induced examples. either case, identified reasoning
phase FLARE discovers two rules apply equally well input vector. Formally,
two rules R con ict vector v following conditions hold.
1.
2.
3.
4.
5.

D(R; v ) = D(S; v) = 0
R specificity
R static priority
R different target-attribute's value
R overlap (i.e., sets possible vectors covers intersect)

Two vectors said concordant target-attribute targetattribute's value vectors. reasoning vector v coming
upon con icting defaults, FLARE simply increments 1 value dynamic priority
default concordant v . none defaults concordant v ,
change made. value dynamic priority ects number times particular
default supported evidence drawn environment. thus evidence,
rather meta-knowledge, responsible emerging ordering defaults
dynamic priority. Note target value must given target-attribute
update take place dynamic priority result combination learning
reasoning. Notice also dynamic priority evolves time system's
response changes based accumulated evidence.
value num covers also result combination learning reasoning.
records number vectors seen system far concordant
covered vector. kind confidence level vector, essentially
counts number times rule represented vector confirmed empirical
evidence.
one rule minimizes (i.e., selected application), winner
chosen according following priority scheme, subsequent condition
invoked tie exists previous level.
1. specific
2. Highest static priority
3. Highest dynamic priority
160

fiAn Integrated Framework Learning Reasoning

4. Greatest cover
Specificity defined number attributes, target-attribute, whose
value ?. vector x specific vector specificity(x)> specificity(y ).
example, KB , v7 specificity 3, v8 specificity 4 v13 specificity 4,
v8 v13 specific v7 .
Giving priority first specific vector allows FLARE handle exceptions
cancellation inheritance. Using static priorities next makes possible handle con icting defaults defined teacher, dynamic priorities account epistemological
inconsistencies may resolved time information becomes available
support one belief other. Finally, selecting vector greatest cover allows
evidence gathered experience guide final selection. Note current scheme
gives precedence teacher-provided information. ordering schemes easily
defined. example, static priorities could given simple form initial bias
evidence gathered learning (e.g., dynamic priority cover) could used
confirm modify priorities.
2.3.6 Illustration

Consider KB assume vector v = (1; ?; 1; ?; 0; 0; ?T ) input reasoning function. Execution proceeds follows. Step (1) essentially skipped none attributes
v meet looping condition. Then, two loops forward chain
target-attribute set.
Execution Trace
(1) (a) Let w = v
(b) (i) Designate second attribute first subgoal
(ii) Apply rule v2 : result w = (1; 1; 1; ?; 0; 0; ?T )
(i) Designate fourth attribute second subgoal
(ii) Apply rule v5 : result w = (1; 1; 1; 0; 0; 0; ?T )
(c) Let v = w
(2) Two con icting rules exist: D(v7; v ) = D(v11; v ) = 0
Apply v7 (more specific): result v = (1; 1; 1; 0; 0; 0; 2T )
2.3.7 Approximate Reasoning

Notice that, forward chaining, assertion attributes subgoals
involve similarity-based assertion results rule application only. result,
accuracy final goal increased ability perform approximate reasoning
reduced. possible relax restriction thus potentially achieving subgoals
reducing confidence final result. example, condition step (2)(a)(ii)
could modified allow rules (which perfect matches, i.e., = 0) also
matches deemed \close enough." measure closeness implemented via
threshold value TD , placed D. is, current condition replaced with:
Let D0 = distance closest match
D0 = 0 perform rule application
Else D0 TD perform similarity-based assertion
161

fiGiraud-Carrier & Martinez

value TD offers simple mechanism increase level approximate reasoning. particularly useful cases Chaco example (Section 2.3.1), where,
completion, reasoning based amount similarity concepts. Notice condition functionally equivalent current one
TD = 0.

2.4 FLARE's Learning

section addresses construction FLARE's knowledge base incremental,
supervised learning. FLARE learns continually adapting information receives.
Indeed, training vectors assumed become available one time, time and,
inherent nature, vectors may noisy others may encountered
once. Moreover, FLARE extends inductive learning examples prior knowledge
form precepts. Sections 2.4.1 2.4.3 describe illustrate FLARE's learning
mechanisms Section 2.4.4 highlights advantages combining extension
intension learning.
2.4.1 FLARE's Adapting Function

time, FLARE presented sequence examples precepts used
update current knowledge base. set examples, rules precepts share
target-attribute viewed partial function mapping instances
goal-space. context, example maps single instance value goal-space,
precepts rules hyperplanes map points corresponding
instances value goal-space.
Learning follows form nearest-hyperplane learning. mentioned Section
2.2, consists first applying reasoning scheme, making adjustments
current knowledge base ect newly acquired information. reason
algorithm said nearest-hyperplane reasoning phase essentially identifies
closest match input vector. closest match either rule (i.e., true hyperplane)
stored example (i.e., point degenerated hyperplane).
prior application reasoning allows system predict value targetattribute based information current knowledge base. Also, missing
attributes input vector knowledge base contains rules applied
assert attributes, rules applied many missing attributes
possible asserted final goal predicted. Hence, accuracy
prediction increased generalization potentially enhanced, thus enabling FLARE
effectively adapt knowledge base.
system starts empty knowledge base. adapts new vector v ,
v either precept example. v first vector, closest
match v automatically stored current knowledge base. sense,
first learned vector represents yet another bias learning system. v first
vector, reasoning takes place producing v + . closest match, say m, also found
knowledge base adapts based relationship v + m, shown
Figure 4. Note closest given current available information can, indeed,
\far" v + . Hence, order training takes place impacts outcome.
162

fiAn Integrated Framework Learning Reasoning

DEFINITION



Input: current knowledge base, vector v+ output function Reasoning target value
target-attribute.
Output: updated knowledge base.

IMPLEMENTATION
1. Let vector current knowledge base D(m;v+ ) smallest (i.e., v+ 's
closest match current knowledge base).
2. attributes equal values v+ m, add 1 m.counters[v+ .target-attribute's
value]
(* identical prototype v+ , then: store v+ , update m's counters *)
3. Else covers v+ v+ concordant, add 1 m.num covers
(* subsumes generalization v+ , then: store v+ , increase m's confidence *)
4. Else v+ covers v+ concordant, add 1 v+ .num covers, delete
knowledge base add v knowledge base
(* v+ subsumes generalization m, then: replace v+ , increase v+ 's confidence *)
5. Else v+ produce generalization,
(* possibility generalization *)
v+ specific one non ? attribute, drop condition
set m.static priority maxfm.static priority, v+ .static priorityg
(* general v+ dropping condition possible, then: store v+ , drop
condition m, update static priority *)




Else v+ one non ? attribute, drop condition v+ , set v.static priority
maxfm.static priority, v+ .static priorityg, set v+ .num covers m.num covers, delete
knowledge base add v+ knowledge base
(* v+ general dropping condition possible, then: drop condition v+ ,
replace v+ , update parameters *)
Else add v+ knowledge base
(* dropping condition impossible, then: store v+ knowledge base *)

6. Else add v+ knowledge base
(* default case: store v+ knowledge base *)

Figure 4: Function Adapting
array counters contains entry possible value target-attribute
also stored vector. counters initialized 0, except one
corresponding vector's target-attribute value initialized 1. counters
evolve time used handle noise. vector p current knowledge
base, exactly one counter value incremented (by 1) time new vector presented,
163

fiGiraud-Carrier & Martinez

whose attributes' values equal p. value incremented corresponds
new vector's target-attribute value. counter value highest represents
statistically \most probable" target-attribute value. effect, target-attribute value
vector always one highest count. Note value may change time,
new information becomes available.
best match first identified, changes knowledge base localized
guided kinds possible relationships v + m. relationships
summarized below.
v+ equal (i.e., noise duplicates)
v+ subsumed (i.e., v+ special case m)
v+ subsumes (i.e., v+ general case m)
v+ produce generalization
cases (e.g., v+ exception m, v+ far apart, etc.)
first case, v + (or prototype m) already knowledge base
counters need updated. Note extension notion equality discussed
Section 2.3.3 enables part algorithm, conjunction counters, produce
generalization linear attributes. effect, vector retained knowledge base
acts \prototype," target-attribute's value one probable among
-close neighbors. second case, need store v + current knowledge
base sucient information correctly predict v + 's target value. third case, v +
stored removed v + general thus accounts it. fourth
case captures possibility generalization dropping conditions (see Section 2.4.2
details). generalization takes place, one v+ generalized stored.
values static priority num covers also reset generalization inherits
maximum static priority value current value num covers. Finally, fifth
case, v + must added current knowledge base either produce correct
target value v + (e.g., exceptions) deemed reliable enough properly account
v + .
Notice adaptation phase takes place regardless target value predicted
reasoning phase. possible alternative would adapt predicted
target value differs actual target value. found empirically, however,
much useful information lost approach due incrementality
system sensitivity ordering. possibly viable alternative would make use
memory. Vectors currently accounted could saved memory presented later
system. may done times period learning time either
vectors must stored knowledge base (due changes knowledge base)
discarded system gained enough confidence ability account
them.
2.4.2 Generalization

Two vectors target-attribute's value produce generalization
following five conditions hold.
164

fiAn Integrated Framework Learning Reasoning

1. differ value exactly one attributes.
2. attribute differ nominal.
3. concordant.
4. number attributes equal ? differ 1.
5. least one one non ? attribute.
Generalization consists setting ? attribute two vectors differ,
vector general, long vector one non ? attribute.
example, vectors v8 v9 KB satisfy conditions would generalize
produce vector, say v8+9 = (?; ?; ?; 0; 0; 1; 3T ). value 1 fourth condition
based upon empirical evidence.
Choosing general vector maximizes generalization condition
number non ? attributes guarantees rule generated would cover every
vector. version dropping-the-condition rule (Michalski, 1983) applied
nominal attributes makes little sense linear (especially real-valued) domains.
linear attributes, generalization achieved artifact due extended notion
equality discussed above.
Let v w two vectors representing n n examples, respectively. Furthermore, let v 0 generalization obtained v w dropping p-valued attribute
v . v 0 represents pn examples. Since v w represent 2n examples, generalization causes least (p , 2)n new examples represented. p increases,
value also increases and, large values p, could lead generalization two
values given attribute suce predict outcome values current context.
However, potential generalizations partially offset system's ability
identify, retain give precedence exceptions.
still drawbacks FLARE's generalization scheme. Given set vectors
form vi = SxiTk fixed, target-attribute xi 6= xj
6= j , pair concordant (i.e., k) vectors satisfy generalization condition, yet
first pair generalize. vectors become either subsumed
generalization exceptions it. exceptions, leads storage
vectors needed, especially large domains various subsets values give
rise different target-attribute's values. Moreover, outcome depends upon ordering
vectors. Also, exists con icts involving one (or more) value x,
system end giving unfounded precedence exceptions (being specific) and,
again, depend ordering. Support internal disjunction complex
generalization scheme may help alleviate problems. topic
future research.
2.4.3 Illustration

section shows evolution FLARE's knowledge base vectors KB (see
Section 2.1.3) presented inputs. highlights several interesting features
reasoning adaptation. Let KB 0 denote current knowledge base FLARE.
165

fiGiraud-Carrier & Martinez

discussed above, FLARE starts KB 0 = ;. vector presented FLARE
order appears KB .
1. Presentation v1 . KB 0 = ;. v1 simply added KB 0 .
2. Presentation v2. KB 0 = fv1g. v1 closest match. v1 v2 concordant,
v2 added KB 0 .
3. Presentation v3. KB 0 = fv1; v2g. either v1 v2 . v3
added KB 0 .
4. Presentation v4. KB 0 = fv1; v2; v3g. winner found since none
vectors KB 0 target-attribute v4 . v4 added KB 0 .
earlier KB 0 information single concept (i.e., stimulus-situation), new
KB0 provides FLARE knowledge new concept, namely appropriateresponse. \partitioning" vectors along target-attribute, FLARE naturally
supports multiple concept learning.
5. Presentation v5 . KB 0 = fv1 ; v2; v3; v4g. v4 (and hence closest) match
since none vectors KB 0 target-attribute v5 . v4
v5 satisfy conditions 1-4 generalization violate condition 5, v5 added
KB0 .
6. Presentation v6 . KB 0 = fv1 ; v2; v3; v4; v5g. Similar step 3 v4 v5 . v6
added KB 0 .
7. Presentation v7 . KB 0 = fv1; v2; v3; v4; v5; v6g. Note v7 precept. winner
found since none vectors KB 0 target-attribute v7.
v7 added KB 0 . third concept, namely media, available.
8. Presentation v8. KB 0 = fv1; v2; v3; v4; v5; v6; v7g. v7 (and hence closest)
match since none vectors KB 0 target-attribute v8.
v8 exception v7 since v7 covers v8 concordant. Hence, v8
added KB 0 . Though v7 suggests use lecture media, added condition
training-budget found v8 causes suggestion change lecture slides.
9. Presentation v9 . KB 0 = fv1; v2; v3; v4; v5; v6; v7; v8g. v7 v8 may compete.
D(v7; v9) = 1=3 D(v8; v9) = 1=4. Hence, v8 wins. v8 v9 satisfy five
conditions generalization. second attribute dropped (i.e., replaced ?)
either one, say v8 , produce v80 = (?; ?; ?; 0; 0; 0; 3T ). v80 added KB 0 .
attributes v8 v9 value, except stimulus-situation.
sucient FLARE hypothesize value stimulus-situation critical
attribute may thus ignored. words, FLARE decides value
stimulus-situation needed predicting lecture slides.
10. Presentation v10. KB 0 = fv1; v2; v3; v4; v5; v6; v7; v80 g. v7 v80 may compete.
D(v7; v10) = 1=3 D(v80 ; v10) = 0. Hence, v80 wins. v80 covers v10
concordant, FLARE adds 1 num covers(v80 ). v10 need added KB 0 . v10
one many special cases handled new generalization v80 .
166

fiAn Integrated Framework Learning Reasoning

11. Presentation v11 . KB 0 = fv1 ; v2; v3; v4; v5; v6; v7; v80 g. Notice v11 also
precept, precepts may given time learning. v7
v80 may compete. D(v7; v11) = 1=6 D(v80 ; v11) = 1=3. Hence, v7 wins. Neither
one covers other; equal; cannot produce generalization (violate
condition 3). Thus, v11 added KB 0 . Note v11 static priority 1.

12. Presentation v12. KB 0 = fv1 ; v2; v3; v4; v5; v6; v7; v80 ; v11g. v7, v80 v11 compete.
D(v7; v12) = 1=2, D(v80 ; v12) = 2=3 D(v11; v12) = 1=4. Hence, v11 wins. Neither
one covers other; equal; cannot produce generalization (violate
condition 3). Thus, v12 added KB 0 . Note v12 static priority 3.
Since v11 v12 overlap, precedence would given v12 case con ict.

13. Presentation v13. KB 0 = fv1 ; v2; v3; v4; v5; v6; v7; v80 ; v11; v12g. case,
non-asserted attributes v13 may asserted reasoning, targetattribute. Rules v2 v4 applied assert second fourth attributes
0 = (1; 1; 0; 0; 0; 1; 2T ). v7, v80 , v11 v12 compete
respectively. result v13
0 ) = 0, D(v80 ; v130 ) = 0, D(v11; v130 ) = 0,
assert target-attribute. D(v7; v13
0 ) = 1=2. v7 v80 win v11 since specific. However,
D(v12; v13
v7 v80 specificity. fact, satisfy five conditions
identify con icting defaults current context. Hence, FLARE adds 1
0 concordant. Reasoning proceeds,
dynamic priority(v7 ) since v7 v13
0 concordant, v130 need
giving precedence v7 . Since v7 covers v13
added KB 0 .
14. Presentation v14. KB 0 = fv1 ; v2; v3; v4; v5; v6; v7; v80 ; v11; v12g. non-asserted
attributes v14 may asserted reasoning, target-attribute. Rules
v2 v5 applied assert second fourth attributes respectively. result
0 = (1; 1; 1; 0; 0; 1; 2T ). rest identical step 13. Now, dynamic priority(v7)
v14
0 added KB0.
= 2 v14

15. Presentation v15. KB 0 = fv1 ; v2; v3; v4; v5; v6; v7; v80 ; v11; v12g. non-asserted
attributes v15 may asserted reasoning, target-attribute. Rules
v3 v6 applied assert second fourth attributes respectively. result
0 = (2; 2; 2; 1; 1; 0; 0T ). v7, v80 , v11 v12 compete assert target-attribute.
v15
0 ) = 1, D(v80 ; v150 ) = 1, D(v11; v150 ) = 1, D(v12; v150 ) = 1=2. Hence,
D(v7; v15
v12 wins. Neither one covers other; equal; cannot produce
0 added KB0.
generalization (violate condition 3). Thus, v15

0 g.
16. Presentation v16 v17 . KB 0 = fv1 ; v2; v3; v4; v5; v6; v7; v80 ; v11; v12; v15
0
0
equal v15. Neither v16 v17 need added KB appropriate
0 . result counters[0] = 2, counters[1] =
counter values incremented v15
0
0, counters[2] = 1 counters[3] = 0. Thus, target-attribute's value v15
currently 0.

resulting KB 0 , processing KB shown Figure 5. variables p, c dp
stand static priority, cover number dynamic priority, respectively. intuitive
level, FLARE used learning reasoning mechanisms deal KB . Induction
167

fiGiraud-Carrier & Martinez

v1
v2
v3
v4
v5
v6
v7
v8
v11
v12
v15
0

0

=
=
=
=
=
=
=
=
=
=
=

0
1
2
?
?
?
?
?
?
?
2

0T
1T
2T
?
?
?
1
?
1
1
2

?
?
?
0
1
2
?
?
?
?
2

?
?
?
0T
0T
1T
0
0
?
1
1

?
?
?
?
?
?
0
0
0
?
1

?
?
?
?
?
?
?
1
?
?
0

?
?
?
?
?
?
2T
3T
0T
1T
0T

Figure 5: KB 0

(p = c = dp = 0)
(p = c = dp = 0)
(p = c = dp = 0)
(p = c = dp = 0)
(p = c = dp = 0)
(p = c = dp = 0)
(p = c = 0; dp = 2)
(p = 0; c = 1; dp = 0)
(p = 1; c = dp = 0)
(p = 3; c = dp = 0)
(p = c = dp = 0)

(on vectors v8; v9; v10) allowed system decide stimulus-situation
irrelevant predicting use lecture-with-slides. Deduction empirical evidence
provided vectors v13 v14 caused FLARE break \tie" rules v7 v80
favor v7. Prior knowledge relative vectors v11 v12 encoded static priorities,
thus giving precedence v12 case con icts. Hence, vector v = (1; ?; 0:?; 0; 1; ?T )
presented FLARE KB 0 acquired, second fourth attributes first
asserted previously discussed produce v 0 = (1; 1; 0; 0; 0; 1; ?T ). Then, v7 , v80 v11
compete. v7 v80 win due specificity. v7 v80 also static priorities
v7 wins due dynamic priority result (1; 1; 0; 0; 0; 1; 2T ). Now, vector
(1; ?; 2; ?; 0; 0; ?T ) presented, similar situation arises v11 v12 . con ict
resolved static priorities.
2.4.4 Extensionality Intensionality

able use prior knowledge form precepts together raw examples,
FLARE effectively combines intensional approach (based features, expressed
precepts) extensional approach (based instances, expressed examples)
learning reasoning. combination, FLARE resolve con icting defaults,
Nixon Diamond (Reiter & Griscuolo, 1981), either told explicitly
default prevails (e.g., religious conviction important political aliation)
computing relative dynamic priorities (see Section 2.3.5) examples RepublicanQuakers.
inductive learning systems purely extensional, reasoning systems
purely intensional. therefore authors' contention that, induction deduction
integrated, combination two approaches desirable. also clear
combination increases exibility. one hand, extensionality accounts
system's ability adapt current environment, i.e., autonomous.
hand, intensionality provides mechanism system taught
thus unnecessarily suffer poor atypical learning environments.
context reasoning, precepts provide useful medium encode certain firstorder language statements (e.g., rule base expert system) can, turn,
learned FLARE (in usual way) later used reasoning purposes.
168

fiAn Integrated Framework Learning Reasoning

DEFINITION



Input: set general rules, set facts one designated target-attribute
Output: one precepts

IMPLEMENTATION
1. Learning general knowledge: Perform Learning set general rules.
2. Reason facts: Perform Reasoning vector encoding given facts designated
target-attribute.

Figure 6: Function Generate-Precepts

2.5 FLARE's Automatic Generation Precepts

Section 2.1.2 introduced notion precepts generalized AVL vectors
attributes special value ? (i.e., don't-care). Precepts may encoded directly
teacher deduced automatically general knowledge. FLARE provides simple
(off-line) mechanism automatic generation precepts preprocessing phase
described Section 2.2.
FLARE uses prior knowledge form general rules may viewed encoding
\commonsense" knowledge involving attributes application domain.
appropriate setting deduction, FLARE generate domain-specific precepts
used biases inductive learning reasoning specific
domain apply.
Consider example Table 3 Section 2.1.1. Assume system
inductively learn rules regarding suitability lenses patients set examples
whose attributes include patient's tear-production rate (tpr). statements Table
3 capture general knowledge eyes. Informally, state that:
1. Low tear-production rate causes dryness eyes.
2. Dry eyes fit lenses.
provided fact target-attribute system fitting
lenses, general knowledge may used produce domain-dependent precept
states that, patient low tear-production rate, he/she fitted lenses.
precept, turn, provides useful bias system induction
examples.
process generating precepts described essentially one acquiring
general knowledge (or rules) reasoning described Figure 6. general
rules available, function Generate-Precepts always invoked prior work
FLARE.
function Generate-Precepts actually makes use functions FLARE.
step (1), constructs knowledge base general rules using learning described
Section 2.4. step (2), reasons, described Section 2.3, using acquired
knowledge facts enabling general knowledge applied domain.
169

fiGiraud-Carrier & Martinez

facts encoded vector attributes found general knowledge set
appropriate values others set ?. Since precepts mostly used learning biases,
designated target-attribute typically target concept inductive application.
lenses example Table 3, appropriate setting obtained creating vector
attribute Tpr set low attribute Fit designated target-attribute.
incorporated two rules knowledge base step (1), FLARE would
easily deduce precept form: Tpr low Fit false, independent
don't-care conditions.
Though function Generate-Precepts automated, setting relevant attributes interpretation result rely teacher. automatic mechanisms
may considered, system could try combination learning problem's
attributes values instantiate general knowledge. Then, instantiation causes
target-attribute become asserted potential precept. However, process would
exponential would probably lead useful conclusion.

3. Experimental Results Demonstrations

set classical commonsense benchmark problems proposed Lifschitz (1988)
UCI repository (Murphy & Aha, 1992) contains many useful training sets
inductive learning. section reports results obtained FLARE several
datasets. Results number uses framework, including two expert systems,
also presented. Finally, limitations system described.
One artifact implementation that, since variables cannot added dynamically,
attributes must defined priori. attributes appear rules, examples
precepts set don't-care. consistent semantics don't-care
interfere algorithm since distance essentially treats learned don't-cares
neutral values.

3.1 Inductive Learning Prior Knowledge

order test predictive accuracy FLARE, standard training set/test set approach used. value v 's target-attribute provided used
reasoning. Rather, system reasons based current knowledge base
asserted attributes v . reasoning completed, \computed" target value
compared \actual" target value.
Several datasets UCI repository (Murphy & Aha, 1992) chosen.
represent wide variety situations, shown Table 6. column labelled \Size"
indicates total number examples dataset. column labelled \Attributes"
records number type (L linear, N nominal) attributes,
target (or output) attribute. column labelled \Output" shows number output
classes.
FLARE's results gathered applications, using 10-way crossvalidation. dataset randomly broken 10 sets approximately equal size. Then,
turn, one sets used testing, remaining 9 used learning.
process repeated 10 times, one test set, every item data
test set once. FLARE's outcome dependent upon ordering
170

fiAn Integrated Framework Learning Reasoning

Application
lenses
voting-84
tic-tac-toe
hepatitis
zoo
iris
soybean-small
segmentation
glass
breast-cancer
sonar

Size Attributes Output
24
4N
3
435
16N
2
958
9N
2
155 6L&13N
2
90
16N
7
150
4L
3
47 4L&31N
4
420
19L
7
214
9L
7
699
9L
2
208
60L
2

Table 6: Selected Applications
Application PA IR ID3 CN2
lenses
79.0 .43 65.0 83.3
voting-84
92.9 .63 95.4 93.8
tic-tac-toe
81.5 1.0 85.6 98.0
hepatitis
80.0 .94 77.9 76.1
zoo
97.4 .36 97.8 93.3
iris
94.0 .13 94.0 93.3
soybean-small 100 .98 98.0 100
segmentation 94.0 .99 96.9 94.1
glass
71.8 .22 67.7 62.7
breast-cancer 96.6 .47 95.1 95.1
sonar
83.8 .77 77.4 44.3
Averages
88.3 .63 86.4 84.9
Table 7: FLARE: Induction

BP
76.7
96.0
96.6
97.8
97.3
100
38.0
99.7
87.8

data learning, turn repeated 10 times new random ordering
training set. predictive accuracy given turn average 10 corresponding
trials predictive accuracy dataset average 10 turns.
Results shown Table 7. first number (PA) represents predictive accuracy
(in %) test set training second number (IR) inductive ratio,
defined ratio size (in number rules) final knowledge base
number instances used learning. IR another measure generalization power
FLARE, well indication FLARE's memory requirements. Results PA ID3
(Quinlan, 1986), ordered CN2 (Clark & Niblett, 1989) Backpropagation (Rumelhart &
McClelland, 1986) also included comparison. also obtained using 10-way
cross-validation reported Zarndt (1995).
set selected applications, FLARE's performance generalization compares
favorably ID3, CN2 Backpropagation, well inductive
171

fiGiraud-Carrier & Martinez

Application
lenses
voting-84
tic-tac-toe
hepatitis
zoo
Averages

prec.
79.0 - .43
92.9 - .63
81.5 - 1.0
80.0 - .94
97.4 - .36
86.2 - .67

w/prec.
80.5 - .33
94.5 - .25
88.5 - .72
81.2 - .68
97.4 - .32
88.4 - .46

Table 8: FLARE: Induction Prior Knowledge
learning algorithms (e.g., see Aha et al., 1991; Wettschereck & Dietterich, 1994; Zarndt,
1995). addition, knowledge base maintained FLARE generally significantly
smaller set training vectors.
first five applications selected illustrate effect prior knowledge
predictive accuracy inductive ratio. application, experimental
procedure repeated set training examples augmented precepts given
priori (i.e., training set presented). Results reported Table 8.
column shows PA IR. Here, precepts obtained domain knowledge
provided application (voting-84) generated authors common sense (zoo,
lenses, hepatitis, tic-tac-toe). serve learning biases. results precepts show
average increase 2.6% predictive accuracy decrease 31.3% inductive
ratio. decrease IR demonstrates prior knowledge allows pruning parts
input space learning. Indeed, starting number training vectors,
FLARE ends knowledge base containing one-third less vectors
precepts used. Hence, precepts increase generalization performance,
also reduce memory requirements.
lenses application also used demonstrate precepts may generated
automatically deducing domain-dependent information general knowledge, discussed Section 2.5. example Table 3 Section 2.1.1 implemented (as
described Section 2.5) precept stating that, Tpr attribute set low,
lenses prescribed generated. precept was, turn, used prior
performing inductive learning described above.
process inductive learning automatically generated prior knowledge twophase, phases perform operations different pieces information.
first phase, general knowledge expressed rules (and translated AVL) learned
FLARE. FLARE reasons based instantiation links general knowledge
current domain. result reasoning phase one (or more) precept containing
domain-dependent information. second phase, FLARE learns generated
precepts available examples. result set inductively generated
rules.

3.2 Classical Reasoning Protocols

Several problems set Benchmark Problems Formal Nonmonotonic Reasoning
(Lifschitz, 1988), presented FLARE. problems first translated
172

fiAn Integrated Framework Learning Reasoning

corresponding AVL representation. FLARE able properly incorporate premises
correctly derive expected conclusions following classes problems
(Lifschitz, 1988):
A1 - basic default reasoning.
A2 - default reasoning irrelevant information
A3 - default reasoning several defaults
A5 - default reasoning open domain
A9 - priority defaults
B1 - linear inheritance (top-down)
B2 - tree-structured inheritance
B3 - one-step multiple inheritance
B4 - multiple inheritance
Problem A4 involves disabled default problems A6 A8 deal unknown
exceptions. problems cannot represented FLARE. Problems A10 A11 deal
instances defaults reasoning priority. Though directly representable
FLARE, effectively solved via use static (A10) dynamic (A11) priorities.
classes problems defined Lifschitz (1988) (i.e., reasoning actions,
uniqueness names autoepistemic reasoning) beyond current scope FLARE.
Note that, order work properly, problems require added processing. particular, problems A1, A2, A3 A5 involve classes objects
particular instances classes. Problem A1, example, given follows: blocks
B heavy, heavy blocks normally located table, table.
Translating AVL gives: 1T ?, B 1T ?, ? 1 1T ? 0T , first attribute
multi-valued attribute representing objects universe second third
attributes Boolean, encoding predicate heavy ont able respectively. Now,
? ?T shown, 1 ?T derived first vector match ?
1 1T ? 0T exactly. seems reasonable priority given later
since involves (an instance) explicitly. solve problem, vectors involving explicit
references instances objects static priority set 1 vectors
static priority set 0. is, course, artifact encoding. alternative
write facts relative given instance definition whose target-attribute
instance value. completion would guarantee correct outcome.
problems characteristics important forms human patterns reasoning. However, artificial manufactured explicitly intent
isolating one salient feature nonmonotonic reasoning, independent others.
investigate properties FLARE combination learning reasoning,
\real-world" applications must designed experimented with. Section 3.5
presents preliminary applications. next two sections present simple applications
exercise FLARE's ability learn incrementally combine learning
reasoning useful ways.
173

fiGiraud-Carrier & Martinez

3.3 Nixon Diamond

Nixon Diamond (Reiter & Griscuolo, 1981), reproduced Table 1 Section 2.1.1,
important prototype class interesting problems involving con icting defaults.
used demonstrate FLARE's mechanisms handle con icts intensionally
extensionally.
FLARE's static priorities offer simple way resolving Nixon Diamond intensionally, based externally provided information (e.g., religious convictions supersede
political aliations). case, defaults given along appropriate static
priority.
Another alternative consists providing defaults without priority. corresponds possibly natural situation system really don't-know
state comes deciding Nixon's dispositions. Yet, don't-know states
uncomfortable authors' contention kind information may allow
decision made used. Hence, simple epistemological approach adopted,
con ict arises due beliefs rather facts. case, possible
attempt resolve con ict observing instances Republican-Quaker. relative
number pacifists non-pacifists serve evidence lean towards one decision
other. words, system's observation seems common
environment creates belief. unlike way humans deal many
similar situations.
final approach, combines inductive learning reasoning, consists
providing system default. Rather, examples Republicans, Quakers
Republican-Quakers shown system automatically comes defaults (through induction) relative priorities.
three experiments run FLARE results expected.
third case, actual knowledge base depends upon ordering. consists one
vector Republicans Quakers one vector Quakers Republicans, one default vector Quakers Republicans one vector Republican-Quakers.
target value vector Republican-Quakers via dynamic priority
via counters. Functionally, however, result identical.

3.4 Birds Typically Fly?

Incremental learning one FLARE's important features. incrementality, system
self-adaptive sense current knowledge base representative experience
environment far. knowledge base continually updated new
information becomes available. exercise incrementality simple example bottom-up
inheritance involving birds designed.
application four attributes, two correspond Ostrich Bird.
two (undetermined) attributes birds (e.g., Feather). target-attribute
Boolean characterizes ability y. first, system exposed mostly
ostrich-birds (maybe experiment started Australia). asked whether birds
typically (i.e., Bird attribute asserted inputs don't-know),
FLARE concludes birds y, consistent current experience
\world." However, new instances ying birds (i.e., ostriches
174

fiAn Integrated Framework Learning Reasoning

penguins) encountered, FLARE adapts knowledge asked again, concludes
birds y. Correct knowledge ostrich-birds also preserved. is,
system shown ostrich, still conclude ostrich y.
course, precept may also given system given time, stating
birds typically y. idea FLARE offers options naturally. system may
taught suffer poor atypical learning environments (e.g., Australia
birds' ying ability prediction), may left adapt environment. research
autonomous agents continues, later ability becomes important.
Note example also illustrates one FLARE's limitations. system
either concludes birds not. mechanism representing middle ground way FLARE could reason meta-level.
Decisions made presence con icts also \crisp" demonstrated simple,
rigid con ict resolution mechanism discussed Section 2.3.5. Even though, system may
able produce fuzzy-like results associating decision confidence
level, would still able reason meta-level.

3.5 Learning Expert Systems
order better assess FLARE's reasoning mechanisms, two expert system knowledge
bases used. One called mediadv (Harmon & King, 1985) intended help
designers committees choose appropriate media deliver training program.
consists 20 rules chains inference length 2 most. called health
(Sawyer & Foster, 1986) intended predict longevity patients based
variety factors (e.g., weight, personality, etc.). much larger contains 77 rules
complex involves longer chains inference. Five rules left one
redundant (i.e., rule 17 identical rule 14) four needed interactive
setting original system described. Hence, 72 rules considered.
sets rules translated AVL. 20 rules mediadv produce 99 vectors
72 rules health produce 72 vectors. number vectors mediadv much
larger original number rules many rules contain internal disjunctions. AVL, new vector must constructed possible combination arising
disjunctions. example, rule: ((A=1 A=2 A=5) (B=2.9 B=7.8))
C, gives rise 6 vectors corresponding equivalent set rules: ((A=1)
(B=2.9)) C, ((A=1) (B=7.8)) C, ((A=2) (B=2.9)) C, etc.
sets vectors corresponding original knowledge bases encoded
FLARE. Rather, presented system learned. Hence, generalization
may take place. fact, final number vectors (after learning) mediadv 71,
health 65.
mediadv example clearly simple presents little interest terms
deduction. However, purpose show system's current knowledge base
may updated learning. particular interest case con icts arise
two rules may apply given situation, implying different goal
values. mediadv, con ict exists rules 13 14 rules 16
17. Rules 13 14 used illustration. Let X fixed conjunction conditions
shown. Then:
175

fiGiraud-Carrier & Martinez

rule 13: (X) (training budget = small training budget = medium)

media consider = lecture
rule 14: (X) (training budget = medium) media consider = lecturewith-slides
clear that, cases, rules con ict. important issue dicult avoid occurrences large knowledge bases elicited experts. FLARE
supports learning, possible, however, look various (historical) situations
training budget medium check media used then. information can,
turn, used give precedence one rule other. Moreover, precedence
need fixed many examples considered. Indeed, may evolve
time even change radically depending circumstances.
example, using several additional instances [(X) (training budget = medium)]
together target value media consider, implemented. instances used
caused value dynamic priority rule 13 greater rule 14, thus
effectively giving (evidential) precedence rule 13.
experiments health knowledge base demonstrate FLARE's ability perform deduction. experiments conducted involve chains inference reasonable lengths
fairly intuitive. Results summarized Table 9. first column contains
list attributes used knowledge base. Then, pair (setting, result) columns
represents experiment reasoning knowledge base. setting column contains data FLARE starts with. Unknown conditions (or attributes) initialized
don't-knows (i.e., ?). result column shows state knowledge reasoning.
derived piece information italicized subscripted depth inference
derived.
Starting facts setting column, FLARE successively infers new conclusions
reaches value top goal, longevity. Details inference process given
first setting only. easily extended settings. first setting
corresponds average adult female Asian race, little vices excesses
reasonable diet. FLARE first infers that:
relative weight normal (absolute weight < 110 lbs small frame).
personality type A, aggressive.
blood pressure average (normal fat salt intake).
base longevity average, namely 67 (range 48-84).
chances living longer (i.e., add years base-longevity) good.
then, based added information, infers risk actually high though
chances living longer good, actual value added base-longevity 0 (i.e.,
factor = none). Finally, one would expected, woman's longevity predicted
average (i.e., 67).
settings illustrate FLARE's ability perform forward chaining.
second setting corresponds unhealthy older male whose longevity accordingly
176

fiAn Integrated Framework Learning Reasoning

setting 1 result 1
setting 2
result 2
rel. weight
?
normal1
?
obese1
val
?
yes2
?
?
heart-dis-risk
?
?
?
> average1
hddanger
?
?
?
?
start
yes
yes
yes
yes
age
25-55
25-55
>55
>55
gender
F
F


base-longevity
?
671
?
601
weight
<110
<110
>170
>170
frame
small
small
small
small
cholesterol
?
?
high
high
fat intake
normal
normal
high
high
salt intake
normal
normal
high
high
blood-pressure
?
average1
?
> average1
calcium
?
?
?
?
osteoporo-risk
?
?
?
?
smoker


yes
yes
outlook
?
?
?
bleak2
race
asian
asian
caucasian caucasian
origin
?
?
medit.
medit.
risk
?
high2
?
high2
personality
aggressive aggressive aggressive aggressive
person. type
?
type a1
?
type a1
alcohol cons.
moderate moderate excessive excessive
add
?
good1
?
poor1
factor
?
none3
?
minus 123
longevity
?
674
?
484

setting 3
?
?
?
?
yes
<25
F
?
110-170
large
low
normal
normal
?
normal
?

?
caucasian
n-amer.
unknown
docile
?
none
?
?
?

result 3
normal1
yes2
average1
low2
yes
<25
F
721
110-170
large
low
normal
normal
average1
normal
average1

fair3
caucasian
n-amer.
unknown
docile
type b1
none
fair1
plus 124
845

Table 9: Health Knowledge Base
predicted low third setting describes young healthy female whose life
expectedly predicted quite long. Note though results may seem impressive,
experiments \anecdotal."
Note classical expert systems, identification closest match reasoning could used extend FLARE may query user missing information
well justify queries decisions made.

3.6 Limitations
applications serve demonstrate FLARE holds promise. However, FLARE
many important limitations, several mentioned throughout paper.
summarized here.
FLARE's use AVL representation language limits applicability relatively
simple problems. Induction deduction carried within confines nonrecursive, propositional logic. restriction makes combination learning
reasoning accessible since much research taken place within context. However,
177

fiGiraud-Carrier & Martinez

first-order predicate logic seems minimum requirement system claiming reasoning
abilities.
Although FLARE produces good results, applications tested relatively
simple. example, many databases UCI repository low complexity
relatively unsophisticated learning methods perform well them. explains
FLARE's extremely coarse generalization scheme seems sucient attain reasonable predictive accuracy. Similarly, reasoning problems presented somewhat straightforward.
follows simple mechanisms static priorities counting devices used
FLARE sucient.
FLARE meta-level abilities. system unable reason
knowledge subsequently unable produce meaningful middle ground solutions. Yet, work Cyc (Guha & Lenat, 1994) strongly suggests meta-knowledge
indispensable carrying uncertain reasoning.
clear FLARE \scratches surface" problem effectively
eciently combining induction deduction. Work ILP (Muggleton, 1992) may shed
light issue bringing systems like FLARE first-order logic level.

4. Related Work
FLARE follows tradition PDL2 (Giraud-Carrier & Martinez, 1994b) ILA
(Giraud-Carrier & Martinez, 1995), attempts combine inductive learning using
prior knowledge together reasoning. Unlike PDL2 ILA whose prior knowledge
must pre-encoded whose reasoning power limited classification (i.e. 1-step forward inferences only), FLARE supports automatic generation precepts forward
chaining arbitrary depth. Whereas PDL2's actual operation tends decouple learning reasoning (i.e., system essentially uses distinct mechanisms perform either
one), ILA implements inherently incremental approach combining
2-phase algorithm always reasons first adapts accordingly. FLARE
extends ILA providing natural transformation constrained first-order clauses
attribute-value vectors accurate characterization con icting defaults.
attempting construct unified framework learning reasoning, FLARE
follows synergistic approach, similar (at least concept) taken SOAR (Laird,
Newell, & Rosenbloom, 1987) NARS (Wang, 1993) example. also
variety inductive learning models reasoning systems bear similarity
corresponding components FLARE. discussed here.
Induction FLARE carried much way NGE (Salzberg, 1991).
However, generalization effected setting attribute(s) don't-care,
produced generalizations generalized exemplars (Salzberg, 1991), hyperplanes,
rather hyperrectangles, input space. Hence, FLARE implements nearesthyperplane learning algorithm. FLARE also uses static dynamic priorities break
ties equidistant generalizations. Moreover, shown overlapping
hyperrectangles may hinder performance (Wettschereck & Dietterich, 1994), FLARE allows
overlapping hyperplanes purposes dealing con icting defaults.
case generalizations constructed training examples, FLARE
degenerates restricted form MBR (Stanfill & Waltz, 1986). distance metric
178

fiAn Integrated Framework Learning Reasoning

used similar IBL's metric (Aha et al., 1991) also handles don't-care attributes
(which non-existent instance-based learners) treats missing attributes somewhat
differently. IBL considers missing attributes complete mismatches, FLARE
chooses middle-ground approach may better capture inherent notion
missing \don't-know" attributes.
Learning FLARE contrasts algorithms CN2 (Clark & Niblett, 1989),
training examples must available priori. Rather, FLARE follows incremental approach similar argued Elman (1991), except knowledge
evolved, rather system's structure. Moreover, learning FLARE
effected continually. time example precept presented target
output known, FLARE adapt.
Prior knowledge may take variety forms, discussed Mitchell
(1980) Buntine (1990). form relevant FLARE consists domain-specific
inference rules, either pre-encoded deduced general rules. Systems explicitly combine inductive learning kind prior knowledge include PDLA (GiraudCarrier & Martinez, 1993), ScNets (Hall & Romaniuk, 1990), ASOCS (Martinez, 1986)
ILP (Muggleton, 1992; Muggleton & De Raedt, 1994). ScNets hybrid symbolic, connectionist models aim providing alternative knowledge acquisition experts.
Known rules may pre-encoded new rules learned inductively examples.
representation lends rule generation constructed networks complex
generalization appear trivial. ASOCS PDLA dynamic, self-organizing
networks learn, incrementally, examples rules. ASOCS, order matters con icts simply solved giving priority recent rules. PDLA
less order-dependent provides evidence-driven mechanisms handling con icts.
ScNets, prior knowledge ASOCS PDLA takes form explicitly encoded,
domain-specific rules. FLARE's approach exible. system reason,
domain-specific rules (or precepts) deduced automatically general rules.
ILP models offer exibility. intersection logic programming inductive learning, ILP takes advantage full expressiveness first-order predicate logic
learn first-order theories background theories examples. FLARE's representation
language, though capable handling nominal linear (including continuous
numerical) data, expressive non-recursive, propositional clauses. However,
simpler setting, FLARE supports evidential reasoning prioritization rules.
FLARE's use rules similarity reasoning similar CONSYDERR's (Sun,
1992). However, CONSYDERR strictly concerned connectionist approach concept representation commonsense reasoning. resulting model elegant. consists
two-level architecture naturally captures dichotomy concepts
features used describe them. However, address problem learning (how
skill could incorporated also unclear) currently limited reasoning
concepts. FLARE's representation elegant model effectively reason
concepts features. CONSYDERR deals Boolean features
concept's representation limited single conjunction features. FLARE's concepts
generally consist several conjunctions features, representing partial complementary definitions concept. Also, since domain features restricted,
FLARE uses general distance metric CONSYDERR's similarity measure based
179

fiGiraud-Carrier & Martinez

feature overlap. However, FLARE currently mechanisms individual weighting
features, may cause performance degradation increased memory requirements
presence large number irrelevant features.
FLARE's ability evolve knowledge base time similar found
theory-refinement systems RTLS (Ginsberg, 1990), EITHER (Ourston & Mooney,
1990, 1994) KBANN (Towell, Shavlik, & Noordewier, 1990; Towell & Shavlik, 1994).
RTLS implements 3-phase algorithm refinement. first reduces current theory
form suitable inductive learning, performs learning and, finally, retranslates
result new theory. process potentially costly. FLARE, language
theory language induction, is, theory always
reduced form. Though language rich, allows revision take place eciently
new example, incrementally. EITHER similar FLARE assumes
approximate theory allows correction overly-general overly-specific rules.
mechanisms revision different. EITHER may add/remove antecedents rules,
FLARE may remove antecedents add rules exceptions. EITHER currently
handles Boolean attributes, FLARE restriction. However, EITHER
uses explanation-based learning inductive learning revision, FLARE
strictly inductive. KBANN, like EITHER, deals propositional, non-recursive
Horn clauses. Prior knowledge expressed identically FLARE's pre-encoded precepts
(i.e., domain-specific inference rules form Prolog-like clauses). KBANN translates
given knowledge base equivalent artificial neural network (ANN) may
perturb learn using backpropagation algorithm. FLARE, ANN;
knowledge base simply stored individual rules. Overall, FLARE provides slightly
general synergistic approach. New evidence constantly used revise current
state knowledge. currently mechanisms FLARE deal explicitly
fuzzy rules. However, several mechanisms exist handle inconsistencies con icts.
FLARE always makes decision based available evidence. confidence level also
produced characterize \goodness" decision.
FLARE's limited handling non-monotonicity differs approach taken logic.
Non-monotonic logics typically extend first-order predicate logic added \machinery," circumscription (McCarthy, 1980), semi-normal defaults (Reiter & Griscuolo,
1981) hierarchical theories (Konolige, 1988), essentially preserving consistency.
FLARE's approach consists tolerating inconsistencies knowledge base providing reasoning mechanisms ensure inconsistent conclusions ever reached.
essentially consists using normal defaults inheritance external criterion
cancellation (Vilain, Koton, & Chase, 1990). current criterion relies mostly simple
counting argument (for dynamic priorities covers). Though approach proven
sucient simple propositional examples described here, likely break
sophisticated examples domains.

5. Conclusion
paper highlights interdependencies learning reasoning
details system, called FLARE, combines inductive learning using prior knowledge
180

fiAn Integrated Framework Learning Reasoning

together reasoning within confines non-recursive, propositional logic. Several
important positive conclusions may drawn results research. particular,

Performance induction improved terms memory requirement
generalization prior knowledge used.

Induction examples used effectively resolve con icting defaults extensionally.

Combining rule-based similarity-based reasoning provides useful means performing approximate reasoning tends reduce brittleness.

Induction offers valuable complement classical knowledge acquisition techniques
experts.

Experiments FLARE variety applications demonstrate promise. However,
much work still remains done achieve complete meaningful integration
learning reasoning. Areas future work include following:






Designing mechanisms use reasoning guide learning.






Possibly incorporating backward chaining.

Attempting overcome (or appropriately use) order-dependency.
Providing support internal disjunction.
Improving use inductively learned rules reasoning (the support available
induction may produce useful rules).
Translating system's knowledge base back AVL FOL.
experimenting larger applications.
Extending language first-order.

Acknowledgements
work supported part grants Novell Inc. WordPerfect Corp. Many
thanks also reviewers helpful constructive comments.

References

Aha, D., Kibler, D., & Albert, M. (1991). Instance-based learning algorithms. Machine
Learning, 6, 37{66.
Buntine, W. (1990). Theory Learning Classification Rules. Ph.D. thesis, University
Technology, School Computing Science, Sidney, Australia.
181

fiGiraud-Carrier & Martinez

Clancey, B., & Shortliffe, E. (Eds.). (1984). Readings Medical Artificial Intelligence:
First Decade. Reading, MA: Addison-Wesley Publishing Company.
Clark, K. (1978). Negation failure. Gallaire, H., & Minker, J. (Eds.), Logic
Databases, pp. 293{322. Plenum Press.
Clark, P., & Niblett, T. (1989). CN2 induction algorithm. Machine Learning, 3,
261{283.
Collins, A., & Michalski, R. (1989). logic plausible reasoning: core theory. Cognitive Science, 13, 1{49.
D'Ignazio, F., & Wold, A. (1984). Science Artificial Intelligence, p. 13. Franklin
Watts Library Edition.
Duda, R., & Reboh, R. (1984). AI decision making: PROSPECTOR experience.
Reitman, W. (Ed.), Artificial Intelligence Applications Business. Norwood, NJ:
Ablex Publishing Corp.
Dzeroski, S., Muggleton, S., & Russell, S. (1993). Learnability constrained logic programs.
Proceedings European Conference Machine Learning (ECML'93), LNAI
667, pp. 342{347.
Elman, J. (1991). Incremental learning, importance starting small. Tech. rep.
CRL 9101, University California, San Diego, Center Research Language, La
Jolla, CA.
Ginsberg, A. (1990). Theory reduction, theory revision, retranslation. Proccedings
Eighth National Conference Artificial Intelligence (AAAI'90), pp. 777{782.
Giraud-Carrier, C., & Martinez, T. (1995). ILA: Combining inductive learning prior
knowledge reasoning. Tech. rep. CSTR-95-03, University Bristol, Department
Computer Science, Bristol, UK.
Giraud-Carrier, C., & Martinez, T. (1993). Using precepts augment training set learning.
Proceedings First New Zealand International Two-Stream Conference
Artificial Neural Networks Expert Systems (ANNES'93), pp. 46{51.
Giraud-Carrier, C., & Martinez, T. (1994a). ecient metric heterogeneous inductive
learning applications attribute-value language. Proceedings Third
Golden West International Conference Intelligent Systems (GWIC'94), Vol. 1, pp.
341{350. Kluwer Academic Publishers.
Giraud-Carrier, C., & Martinez, T. (1994b). incremental learning model commonsense reasoning. Proceedings Seventh International Symposium Artificial
Intelligence (ISAI'94), pp. 134{141.
Guha, R., & Lenat, D. (1994). Enabling agents work together. Communications
ACM, 37 (7), 126{142.
182

fiAn Integrated Framework Learning Reasoning

Haas, N., & Hendrix, G. (1983). Learning told: Acquiring knowledge information management. Michalski, R., Carbonell, J., & Mitchell, T. (Eds.), Machine
Learning: Artificial Intelligence Approach, Vol. I, chap. 13. Morgan Kaufmann
Publishers, Inc.
Hall, L., & Romaniuk, S. (1990). hybrid connectionist, symbolic learning system.
Proceedings Eighth National Conference Artificial Intelligence (AAAI'90),
pp. 783{788.
Harmon, P., & King, D. (1985). Expert Systems. John Wiley & Sons, Inc.
Konolige, K. (1988). Hierarchic autoepistemic theories nonmonotonic reasoning.
Proceedings Seventh National Conference Artificial Intelligence (AAAI'88),
pp. 439{443.
Laird, J., Newell, A., & Rosenbloom, P. (1987). SOAR: architecture general intelligence. Artificial Intelligence, 33, 1{64.
Lavrac, N., Dzeroski, S., & Grobelnik, M. (1991). Learning nonrecursive definitions relations LINUS. Proceedings Fifth European Working Session Learning,
pp. 265{281.
Lifschitz, V. (1988). Benchmark problems formal nonmonotonic reasoning. Proceedings Second International Workshop Non-Monotonic Reasoning, LNCS 346,
pp. 202{219.
Martinez, T. (1986). Adaptive Self-Organizing Networks. Ph.D. thesis, University California, Los Angeles. Tech. rep. CSD 860093.
McCarthy, J. (1980). Circumscription: form nonmonotonic reasoning. Artificial Intelligence, 13, 27{39.
Michalski, R. (1983). theory methodology inductive learning. Artificial Intelligence,
20, 111{161.
Minsky, M., & Riecken, D. (1994). conversation Marvin Minsky agents.
Communications ACM, 37 (7), 22{29.
Mitchell, T. (1980). need biases learning generalizations. Tech. rep. CBM-TR
5-110, Rutgers University, New Brunswick, NJ.
Muggleton, S. (Ed.). (1992). Inductive Logic Programming. Academic Press.
Muggleton, S., & De Raedt, L. (1994). Inductive logic programming: Theory methods.
Journal Logic Programming, 19,20, 629{676.
Murphy, P., & Aha, D. (1992). UCI repository machine learning databases. Tech. rep.,
University California, Irvine, Department Information Computer Science.
183

fiGiraud-Carrier & Martinez

Ourston, D., & Mooney, R. (1990). Changing rules: comprehensive approach
theory refinement. Proceedings Eighth National Conference Artificial
Intelligence (AAAI'90), pp. 815{820.
Ourston, D., & Mooney, R. (1994). Theory refinement combining analytical empirical
methods. Artificial Intelligence, 66 (2), 273{309.
Quinlan, J. (1986). Inductive learning decision trees. Machine Learning, 1, 81{106.
Reiter, R., & Griscuolo, G. (1981). interacting defaults. Proceedings Seventh
International Joint Conference Artificial Intelligence (IJCAI'81), pp. 270{276.
Rumelhart, D., & McClelland, J. (1986). Parallel Distributed Processing: Explorations
Microstructure Cognition, Vol. 1. MIT Press.
Rychener, M. (1983). instructible production system: retrospective analysis.
Michalski, R., Carbonell, J., & Mitchell, T. (Eds.), Machine Learning: Artificial
Intelligence Approach, Vol. I, chap. 14. Morgan Kaufmann Publishers, Inc.
Salzberg, S. (1991). nearest hyperrectangle learning method. Machine Learning, 6,
251{276.
Sawyer, B., & Foster, D. (1986). Programming Expert Systems Pascal. John Wiley &
Sons, Inc.
Stanfill, C., & Waltz, D. (1986). Toward memory-based reasoning. Communications
ACM, 29 (12), 1213{1228.
Sun, R. (1992). connectionist model commonsense reasoning incorporating rules
similarities. Knowledge Acquisition, 4, 293{321.
Towell, G., & Shavlik, J. (1994). Knowledge-based artificial neural networks. Artificial
Intelligence, 70 (1-2), 119{165.
Towell, G., Shavlik, J., & Noordewier, M. (1990). Refinement approximate domain
theories knowledge-based neural networks. Proceedings Eighth National
Conference Artificial Intelligence (AAAI'90), pp. 861{866.
Vilain, M., Koton, P., & Chase, M. (1990). analytical similarity-based classification.
Proceedings Eighth National Conference Artificial Intelligence (AAAI'90),
pp. 867{874.
Wang, P. (1993). Non-axiomatic reasoning system (version 2.2). Tech. rep. 75, Indiana
University, Center Research Concepts Cognition, Bloomington, IN.
Waterman, D. (1986). Guide Expert Systems. Addison Wesley.
Wettschereck, D., & Dietterich, T. (1994). experimental comparison nearestneighbor nearest-hyperrectangle algorithms. Machine Learning, 19, 5{28.
184

fiAn Integrated Framework Learning Reasoning

Wollowski, M. (1994). Case-based reasoning means overcome frame problem.
Proceedings Seventh Florida AI Research Symposium (FLAIRS'94), pp. 241{
244.
Zarndt, F. (1995). comprehensive case study: examination connectionist
machine learning algorithms. Master's thesis, Brigham Young University, Department
Computer Science.

185

fi
ff fi


!"$#%$&('*),+--/.01'2-43'657

89:;<%$=>.9?-/.6@A:
#& =<+7?-6.

BDCFEHGJILK/ENMPOGJQSRUT*MWVXTNTYG[Z]\HCPG_^`TNabCLTcIdTYGeMFENMPO/\fGJI
EHGJghMPiJTYO/CkjliJEYCFEnm<MFTNCPO/IoMPO/mqp

\rgbTYK/I

sbtLuwvYxDydz"{}|LtFu

~WWWnW"} WW~ W~W<

N *" 9Fn" ,9
9%6 4rl DW

D( d!
P $$,Nr eJ$! !6W $ 9 % ( $
6"<!P9J$ <r$P1nPn$ 9 1c$N! <f/ $r!
$ P L N $ 6dF$ 4% $n$ $H<P$ c4 Pd $
1bf% $"1P1H1$$ 6(9$ $ nrN $,
1$ ($N1$N < 9nP( ,$ P1 w$,$
6d< <!($9(14 r1 r eF $n $ /
(1J$1r$$ P$ ,$ r$b r1!
r,o/! 1/F!b$n$ U$r N$ J$! 1/$U
}6$1,$1n 9}Le6, e<1 9(n9r 9dP *<
!9$r L% <H 9J< $$"
J$b, 9b $ e$$ }!$ $ $* FP<}1<
< ,$P9/H 1( 1, 1r*>f% P< ,$ e! r, $r
F <"dFP < 9 W P $, rNF/<
b* H}!$ b$1 9F $ !H!/,P$e$ b$e 9}
H6


F <*(!
NWN/1141" l"W94 !Wff
N, fi *, wP9W fW1!cfi

!"#$% c9&')(H !"*"fi+ ,
nWUcW,}-61.9/.1.e021
5b

76o

6$26!,



ff18:962rX,"4/11;
n

34!%



<=WW,>?.9

,!1, U"@6o!1 6," AB=WCBH .'ED 62F !""#% BH"/! G'H9N1F !""ffI+ 8

.4 F.$,," !%1W!Wff
N, fi nW96, J6<"& "4K!%
?6.<,L !6LWM NO&PQPNRTSQKUVWRTUXNMYZ[S\]V8JN!^/,.(W! ,
ff6oWW1!_("

.6T!n 1},. !,

6?8`"K!%a.$,;bW!6

1}}/",
N,WHb9"/6^bW!6c" W
GdW;W99





ff !wJ/<!, e6&

bW!6rKi!1J6!,6Wo&$,, "* 34!%cF,
,W !%j
n!*(Y

! fi.6
nW9WW1Wn !%

9WWff
N, fi U1rW 8gf

!,h9"/6

!^"ff"
N2,bWJ!,



"W6,<W!/41k9"/69ab !68

Wl9"/6abW!6m(Y !%P"1 @6on4Wo
Yr 6op.6T!q8*NW*(,r
*2b! fi.641

2 1,s.$,J9!a!"=6fi.6, 0t6"u" b Jt"/!W%

2b,
n!,.$, !%Y vwbrx(e/ABffWCx82 !""#fi+ 8py_WW
r!6=! 1!0.;9"/69^b !6"u6o

2 1,

!1 6," ,> z
nW r

!%{6" }/1 ,M*nW J!Wff
n0BH"6! n'|9N F !""#fi+ 8k(Y.6!W dW41

nWW W0

K}n9,4/

9/.$%h(Y

44

!%,9,L "66<bW!6

+--6.FfioWfi"$## = =aN9@dff;(@1:
#& #x fi

%&# #T=ff
~

fip,

ff.g.?{fiu?--?fi2tL?,a;4fi343fi-L=.ff?2G3fi2&pJ
Tu@5/@.ffKK??? fiKWL

3@j.ff.,=/4p?jff_2fiLK22fiF.Jfi2Lfffi2JJ.. 3.fi?22

?3.K.fi2.fiG50fffiKJfit03?p022ff3
?3.KpffpJ?<.2?affFK_=fi2lfiafi/s.an?3./tK.fi
3&3{:ff?x@F ff3{x2@ fio

.=0.K3fifi?ff?2

ff.225/Ffffi?xFfiLkj3fio2pfi/:?JffKn32fiJLff.ff5/T
7?tff3.ffLK???fiKn2&-K32.=MKfi2.t2H;;fi3;fi
L=.ff?20fi2& Tu.K ?fi&5=?2,L
&3??2ff2u;ff;K.5.KL0fffft23ff{Kff5/.4ffLff.?H
?ffp<2G4K.fffi2t.ff. u.ffLfiFfffi.JF,fiL3ppK3?..fi.K
.?JpK2.0=.>_.K?2. .fi.3/c{ff.K?.fi.K;.?J
3.ffLK55?fiKff.fft?Kff?2F;Jtfi/ff2&0??2ffL=.ff?2
.?J.K5/.fi..fi.32ff.uM?3tKff?2. .p?.2K3 ?x
ff,F.=ff2FLffM=Fff.fffi:-2.J23?2F@u?2
:22Ffipff.^K2offfi^ 3Mfi2ffKff5/.lffKff.? fffi)-2.
fiLFfi2 fia.ff.pfifi@K.J3pfi2Mb20 ffLff.5fiM2Ffi?uffF
?fi2La5&< fft. 2.ff?2K20fi?22.J?fi2Lb20ffLff.5p
.2G3Mff.fffi?2fi2o2.K ;^fifi?T;&?3?K2jff^F;pffJ
fiJ.ffpMffJ? 5fi/KJ K/fi2J2-?5/fffit?fi2La2h=Lff.?
3=.0J2G2fi2ufiffqc 0 -.ff.0? |?fi2Lpff3 ?fi,pfi3
?=/{5?2Gpfi3GpaG.02Gu=.t2G{=Lff.?{fiM2F
.TH7pF,7k
,^.-/fifi.K<fi2Mu2??2A;ffAK_ff<fi/t&?3J?.u
ff3?2{fi3LffKffL3L=2hgo2t2`o=hfi3p^2^0K.t
Kffkfiff.0p&ffJ2fiu-ff2Gfitu=2ffJ20K.?Lo/fiL

J



-_ ^ a_L



u-0K2;ff.<2-p3M20.?0tfi3fip3KK2hK.?3L2.
_Lff.
^_Lffp-?fi.ff
ffa2fi2t&^2@K.fffi2


?Lff.b2fi=?2FpJfiba3M2.?T<fifi?22M^fiff,@K.?L2fi

25?2FT 5.7fiffKfi?L3/<fiff5/ fififf,Ax4K.fffi20J
Jfit?Ku.ff
L&ff.<KT -Kk b ^K&JuJfi<qF

uJfiuL@ff&g
?

2:3o2..ff.<-Kn32&-Tpp30K32.
l2M2ffK

..3&ff=.G3K4K.32.fi3.ffp2u-p2fi2A&

u72.ff?2G=&3;^;3;3t/<fiff5/Kff?27fi;fiK32.;
p

`3;fiKff
?;gfiKpff



eoff< <fiK@ffl=GK2
ff oo/.=;K3.mL^0nfi3fi
7
p
Jff2fi2;.?JfiKzff kff.3,F&F-
fffiM=fi&Jff?Tfi@
G-K_ff<fi/ . fiK
fiff oL_W_fffififfW_ffW_ffff
fiff?2fiK.7ff2ff

p3{2fiLJfi uoo/u/t&K3?..2ff2L,ff.J Jfi





. 3? 00^ff3G -fiT.ff3K/_2Lk3{fi4=fiKuM





fi"!$#%&'()(+*,-(/.0
132..5476'&*8(96*,4;:<=0-'&>?(
@-ACBDAFE9GIH,J?E9K&A&L=A)M5NPO&QAFQRTSUJVHWSXQfiR9YACQZ[I@PAFEO]\$BVJ?ETSUJ]@7H^A_`LaJ?Q-bcR+YAFE9A)\dODE9AR+Y7SU_ffNE9O5e)Ab7ZE+ACfgShHiHjQO&R
@-AkA)l<e+SXAFQRm
n YApoDZA_qRqSXO&QrJ?ETSU_TA_cR9YAFE9A)\O&E9A&LgfYAFR9YAFEfiR+YAFE9AsSU_fiJt_T[uJHhH/_TZ@-_qAFRfiO?\v[wOb7A)H,_fifY7S,e+Yx_qRqShHhH
K&Z-J?E)J?QR+AFA_e)O&E9E9Ae)RyE9A_qZ7HXRz_yfYAFQ{Z-_qAbfifgSXR9YsR9YAv[|O5b7A)H}e9YAe+~DS^QKcNE9Oe)Ab7ZE9A&mC&Z-e+YJ|_qZ@-_qAFRySU_
eFJHhHXAbcR9YAC_qAFR}O?\gF&q&)XF8C&O?\J?Q-bSXRz_3A)MS,_qR+AFQ-e)ACY-J&_@PAFAFQfiNE9O?B&AbcCJ?ZR+AFRgJHmXL
&D Y-J?Ezb7O&QgO&R9YWL &? mQsO&ZEA)M-J?[wN7HXAvR9Y7S,__TAFRgS,_F
F-7 q r?&)?D?FF?DF&F&F&?&]
_qOsSXRISXQ-e+HXZ-b7A_fifiO&ZRIO?\R+YA & [wOb7A)H,_IO?\m
sOb7A)He9YAe+~&SXQKfffS^R+YtR9Y7S,__TAFRIS,_vKDZ-J?EzJ?Q7R9AFAb
R9OwNE+O5b7Z-e)Awe)O&E9E+Ae)RE9A_TZ7H^R)_g\O&EJ?Q7GfY7S,e+YS,_JuyO&E9QfiA)MNE9A_9_S^ODQWLWJ?Q-bfiZ-_SXQKJw_HiSXK&Y7RqHXG[|O&E9A
e)O&[wN7HhS,eFJ?R9AbtJVH^KDO&EqSXR9Y[ODQA<eFJ?QtJ?Q-_qfgAFEIe)O&E9E9Ae)RqHXGs\O&EvAFB&AFE+GpCJ?ZR9cAFRJHmXL D&7 m|QO&ZE
A)M-J?[wN7HXA&L7SXRgS,_gAJ&_qG|R9Owe9YAe+~uR+Y-J?R FI S,_gAFBVJHXZ-J?R+AbfiR9O)R9E+ZR9Y-CO&QJVHiHWR9YAvJD_9_SXK&Q[wAFQ7Rz_SXQ
F-7 J]Q-bfiR9Y-J?R S,_3\JVHU_Si-Abs@7G =
n YAvZRqShHhSXRGsO?\R9YA_qAvE+AFNE9A_qAFQ7RzJ?RqSXO&Q-_FLPO&E+QA)MNE9A_9_SXO&Q-_CJ?Q-bse9Y-J]EzJ&e)R9AFEqS,_qRTSUe/[wOb7A)HU_`LS,_yQO&R
e)O&[wN-J]EzJ?@7HXA&m}}JDe9YwO]\R+YA_qAE+AFNE9A_qAFQ7RzJ?RqSXO&Q-_3Y-J&_S^R)_JDb7BVJ?Q7RzJ?K&A_O?B&AFE}R9YAyO&R9YAFEmSXEz_qRLDR9YAC_SXFA
O?\gR9YA_qAwE9AFNE+A_qAFQR)J?RqSXO&Q-_S,_S^Q-e)OD[wN-J?EzJ?@7HXA&m n YAFE9AuJ?E+A_TYO&E9RvyO&E9QA)MNE9A_9_SXO&Q-_\dODECfY7S,e9YR9YA
_qAFRgO?\$e+Y-J?EzJ&e)R9AFETSU_TRqS,e[wO5b7A)H,_S,_gO?\WA)MN-O&QAFQ7RqS,JH_SXFA&L-J]Q-bwBDS,e)ACB&AFEz_9JLDR9YAFE9ACJ?E9ACJH,_qOvA)MN-ODQAFQRqS,JH
_SXFA
yO&E9QA)MNE9A_9_SXO&Q-_<\dO&EcfY7S,e+YrR9YA_qAFRfiO?\we9Y-J?E)J&e)R9AFEqS,_qRqS,es[wOb7A)H,_cS,__q[cJHhHwCJ?ZR9sAFRJHmXL
&D7 n YAuE9AFNE+A_qAFQR)J?RqSXO&Q-_vJVHU_TOpbDShWAFEkSXQ
R9YAc_qAFE9BDSUe)A_fY7S,e9YR9YAFG
_qZNNPO&E9RmsQO&QAcY-J?Q-bL
yO&E9QA)MNE9A_9_SXO&Q-_|J?E9Aw[wODE9Aue)O&[wNE+AFYAFQ-_SX@7H^A&mQR9YAwODR9YAFEvY-J?Q-be+Y-J?EzJ&e)R9AFETSU_TRqS,ew[wOb7A)H,_IJ?E9A
J&b7B?J?QR)J?K&AFO&Z-_SXQwR9Y-J?RjR9YAFGwJHhHXOVf\O&EjA)l<e+SXAFQRgJHXK&O&EqSXR9Y[c_\dO&EJ?@b7Z-e)RqSXO&QuJ?Q-bwb7A)\J?Z7HXRE9AJ&_TO&Q7SXQK-m
QfiR+Y7SU_ffN-J?N-AFEfgAvJ?E+AJ&_T~&SXQKwYO?fY-J?EzbSXRgS,_gR9OIR9EzJ?Q-_HUJ]R9A@PAFRqfAFAFQfiR+YA_qACE9AFNE9A_qAFQ7RzJ?RTS^ODQ-_FL_qOwJ&_
R9OwAFQ?qO?GuR+YAC@-AFQA)-Rz_yO?\@-O&R9YWm
- 8I5$U-?-j
QR9Y7S,_cN-J?NPAFEfifgA_qR9Z-b7GR9YAe)O&[wN7HXA)M7S^RqGO?\vR9YA{R9EzJ?Q-_HUJ]RqSXO&QNE9OD@7H^AF[c_{J?Q-b&qImO&E
R9YA_qAcNE9O&@7HXAF[u_`L}R9YAcO&ZR9NZRI[uJG{@-AfiA)MN-ODQAFQRqS,JHhHXGH,J?E9K&AFEIR9Y-J]Q
R9YAcSXQNZRm n YAFE9A)\dODE9A&LjSXRkSU_
J?NNE9ODNEqS,J?R9AR9OJ&_T~fyYAFR9YAFEgR9YAFE9ACJ?E9AJHXK&ODEqSXR9Y[u_fyY7SUe+YeFJ?QcN-AFEq\O&E9[R9YACJ?@-O?B&AR)J&_q~_jSXQfiRqSX[wA
fY7S,e+YS,_kN-O?HXG7QO&[IS,JHgSXQ
@PO&R9YR9YAISXQNZRu_SXFAfiJ?Q-b{R9YAcO&ZR9NZRI_SXFA&m n YA_qAfiJ?E9AceFJHhH^AbODZR9NZR
N-O]H^G7QO&[IS,JH}JHXK&O&ETS^R+Y[u_Fm
A)\O&E9Au_TRzJ?E9RqSXQKfiO&ZE/SXQB&A_TRqSXKJ?RqSXO&QfgAwQODR9AwR9Y-J?RSXRIY-J&_@PAFAFQ_qYO?fQCJ?ZR9wAFRIJHmXL &&7
R9Y-J?RZ-_SXQKfiR9YAI_qAFRO]\e9Y-J?E)J&e)R9AFEqS,_qRqS,ek[wOb7A)H,_O&QAweFJ?QJ?Q-_TfAFECJ?@b7Z-e)RqSXO&Q
oDZAFEqSXA_E9A)H,J?R9AbsR9Ofi
SXQuNPO?HXGQOD[IS,JHaRqSX[wA&L7fY7ShHXAK?SXB&AFQwR9YAg\O&E9[IZ7H,JvSXRS,_gJ]EzbkR9OvNPAFEq\dODE9[J?@ab7Z-e)RTS^ODQ9&A)HX[uJ]Q
AFB&A_9oDZA&L &&7 n Y7S,_YO?fAFBDAFEb7O7A_QO&RyS^[|N7H^G"R9Y-J?RCe)O&[wNZRqSXQKfiR9YAw_qAFRO?\ffe+Y-J?EzJDe)R9AFEqS,_qRqS,e
[wOb7A)H,_ySU_CJ?Ezbs_SXQ-e)AwR9YAIe)O&Q-_qR9E9Z-e)RTS^ODQSXQ{R9YAkNE9OO]\}G&SXA)H,b_vJcODE9Qfi\O&E9[IZ7H,JwfyYO_qA_TAFRO?\
e+Y-J?EzJ&e)R9AFETSU_TRqS,eC[wOb7A)H,_gS,_gO?\A)MN-O&QAFQ7RqS,JH}_SXFA&m
ZE|[uJSXQE9A_TZ7H^Rfi_9JG_vR+Y-J?RfiJ?Q-b&qJ?E9AfiAoDZ7SXBVJHXAFQ7RfiR9OAJ&e+YtO&R9YAFELgJ?Q-btJ?E+AJH,_qO
AoDZ7S^B?JHXAFQR|R9OfiR9YAue)O&E+E9A_qN-ODQ-bDS^QKb7Ae+S,_SXO&QtNE9OD@7H^AF[sm n YAuNE9OD@7H^AF[O?\C}Y-J?EzJDe)R9AFEqS,_qRqS,ewsOb7A)HU_
b7AFQ7RqShaeFJ?RqSXO&Q+s L=S,_vR+YAwNE9O&@7HXAF[O?\ffb7Ae+S,bDSXQK-L3K?SXB&AFQ
JsO&E+QA)M5NE+A_9_SXO&Q
J?Q-b"J_qAFRCO?\
[wOb7A)H,_wLDfYAFR9YAFE FP mA_TYOVfR9Y-J?RyL&qIL5J]Q-bfisJ?E9AAo&Z7SXB?JHXAFQRZQ-b7AFE
N-O]H^G7QO&[IS,JHgE9Ab7Z-e)RqSXO&Q-_FmwJ?[wA)HXG&LR9YAwR9EzJ]Q-_H,J?RqSXO&Q{NE9O&@7HXAF[u_kJ?E9Aw_qO?HXBVJ]@7H^A|SXQN-O]H^G7QO&[IS,JHgRqSX[wA
Sh\J?Q-b{O&Q7HXG{Sh\R9YAub7Ae+S,_SXO&QtNE9OD@7H^AF[S,__TO?HXBVJ?@7HXA|S^QN-O]H^G7QO&[IS,JHgRqSX[wA&m n YA_qAuJ]E9AIQAFfE+A_qZ7HXRz_
fY7S,e+YY-JB&ASX[w[wAbDS,J?R9AIe)O&E9O?HhH,J?EqSXA_ffSXQR9YAIbJ?RzJ?@-J&_TAb7O&[cJSXQWm
"AR9YAFQw_qYO?f
Je+HXO_qAgE9A)H,J?RqSXO&Q-_TY7S^NI@PAFRfgAFAFQkR9YA_qA}NE+O&@7HXAF[u_$J]Q-bCR9YAgG7N-AFE9KDEzJ?NY n EzJ?Q-_TB&AFE9
_9JHWE9OD@7H^AF[ n m=SXB&AFQfiJCY7GNPAFE9K&EzJ?NYfiJCR9EzJ]Q-_qB&AFEz_9JVH-O?\S^R)_Ab7K&A_S,_gJv_qAFR3O?\WQO5b7A_3fY7S,e+Y
&

fi
ff
fi fft !t #"%$'&( )*+, -.
/01 23#4 3
/

fi 94+- C :
;F'<=+/+9>*
; 2
>*.
?<@^4
'ffff

$B C"%$'&D 2)*1+

EF*&G<9ff82 H>*7I
+J<Kff
q4 ?;
EL'.M ff0EN H;

) ff
?<O4+-
'
4QP@R+-*ff
S9T%@*1-4+7 ; U0)V); :2.
;ff
XWY&QZ
X ff5=[ff\2]^_5`a +7?; # b1+7:+-*J.7

cGTd$'e fEWY&Q4X hgji%-kX*ff5d[>\]^_56E"X
>R+9?;
%W;klff H22m2
'Fn
H*om5[ff\\pq_rLXms0:*a
;4*t4*.? ff; 9) bm
T; .%+-q4*.

u 90ff
%*G ?
)2
;w vWYeE J*.Ggw&'> 5'[>\]x_5=y?*ff34+-*4R^; 5Q
2.
q ;)
ff
;q
+9
cWYP@X :g{znD9; *)5@[ff\\ [_4'TM4+-
| 9
q }<} ff
;/ 2)*1+
Xm

ff
;7 ff)CPrX
-~zn&+; *)3W4[ff\\ _4s"%$'&(.
->*.
; ff8 HH*17c { )*+<l>*Z
ff?; v<'+-2 & ty?a*ff4R ff

|
5?L'.m
k
7<+wvL'.vLQ9 ff
bfi
X/

$Q.
? )*+#52ff8ff
3
4
|*.?; -)`F; Lc lQnE-il%E ff
;4 ?;
=0<+7 &
< );

$B h4+-*4RXY E<}
U"%$'& )*+2
')`I
q 2ffE)`4<K-WYff+9Ggjk%15
[ff\\0 P@X
lgjznD9; *)56[ff\\`qkl> H2.
XFl
>*!5[ff\\2p_d.
%
q; J*J*St2s82 ff
q; u }
G*.

c< 2)*1+
%L'.I0#"n$X&N4+-*F
fft2
%)I4 ffE
q 2ffWYPrX
g(znD9; *)56[ff\\_O$Q.
'*.

?*1ff
%+a7 )*+9
?<+j H0;
' *J.?; Eff
?L'.
/ff82 H>*7
"%$'&(W! fi* +/.>*ff);
4_ u { /& l{ h )*+m

)0)*1 &-%=Z;d+7*1F
I&Qff47; *5' ff+3k%a0W[ff\2\ _'> ff
;7 ffv

; ) Z4R 7; .>*d`=H3; +-:>*2;X
+<g :"%$'& )*+#
Q
q'

; L ?} % )*+'e{.
Q?? *ff
qQ
?-
Q"%$'&l y?I ?d LQ%+-ffc ?
J< 7.
-
/
0*1 +/.>*n>*2;X +<K'Qe
-.
-0I :
0*1 +/.>*
>*b^
+j<K2n"n$X&l$Q.
X
Q)E
q ? fft
't`# 2)*1+)kl> H2.
XFff d>*!QW4[ff\\p_45
L' } ffG#
Y1+U*.7 ff

fiff
;*Xfi
</fYi/=y?&G0 ff

fiff
;*X
fiI)`H*^ ?; 4*
; ff)a#4+/) 9
Xff
;*X

Bs ? 0)
;C #WYPrX ng(znD9; *)5[ff\2\ayS Gg
!)02o5[ff\\p_d7X

X4*.?; / ' 2)*1+
lWYk%0tFn
>*!5[ff\\_4

t4
|.; LQ:4*mHR?b 12
d0<$ ff
;
Y*m]; 9 )*+9
d$Q X
q? .
Q4
|.;
ff 79
"X4Rq ff

|
/L'.347 >2. "Xv b1+7-+-*J.? ff
U<K2U} v4R Z
ff

Y12$B h2
n 0<'fYi.
4<hH*^ ffs -)| h
;F%
<>*J*d ;+-fi+-*J.? ff
5@

|+/J*.;*{
fi :
<''Qe*1ff
/>*J*} fi ;+-/+-*J.? ff
1
ff}<B7+/+9>*
; )
bFff
?
.
'
; L'c ?? fi .
'
;`ff.>*r
;5`f;i/5Xe5at"%$'&%ff8 >*%
'0*1 +/.>*
ff);
A$B 4<K25-
UH*12;X + ff
;7 ff})a#ff+9G}k%a0IW4[ff\\ _Q#)`

;ff| h
b* :Xe5tf;ic; +-l S2H ?$Q.
dff
;*XB
09)`>*X ?; 4*9; ff7<+
ff
;*X

fi <K )b 12>*ff
7ve#Tlk<K+W;P@X -gwz%&9; *)5Q[ff\2\ [_ #
; L
LQ g
?' % +-7Q >*Jff
c*m0Q<!+/J*t<rZ!82
|r"Xt4R ff

Y12

$B :
;ff44*.>R?;
ff
: 2)*1+{<S42+- ; H**j l ;+-l+-*J.7
B<K%:01 2
"X4Rq ff

|I$Q.
fi.
-}4*.>R?; <:Xe
|4t
|
;+-+-*Jm0
U #
4+-

4) ;.
q; . +- 4*m
Aw!7 ff
qb 1 0*15k v>*;X +<K2s"%$'&WY ff+g
k%a5d[>\\ _0s)`9
ff u.
c )*+#5ff
;*X; sE>*;X +wLQX "; +--4+-Z
*4RaX; #`=
'
.
fi
; L'5 LQ ff5P ?l
)`&E4*.>R?;
l &l 4*EI
;* 2 fi / >*
bff
'<
'eEf;iN v
74Rq` b mH*ra0
=s h
|fi<$ /4ff
;`2 9 ff
;7 ?;


q; *56LQh4
Ym:74*.?
ff} 2)*1+}5 &ffEP u n56LXm}.
l-+/ l+7q2JV?; E<
'e7fYi/$Q.
@ )*+(.
=
; L'I
l)n42Z!nSZ;d+-*F d$Bm
?
; ff
j n*J7B
b+-
<g -2t4*^; }E2 {
/4R):
42+-*4RaX; E< l )*+9
fiTM H0;.fi
<} .
lff
;*Xff 5


'H*1ff# ff0ff7
/ ? )
b'*JX ? -Wz%&9; *)tg 1) 25=[ff\\q_
ff567.
'ff82ff

ffff

fi'

a4. c I? q .

co-NP-Complete

EOC

unknown
CMI

HTR-Complete

SID

CCM

SID(all PIs)

HTR

CCM(all PIs)

sub-exponential
exact complexity unknown

92d 79Qd-41;#Qffb14

ff;E; -90;ff12 IQX

av0: 9Umt.4ff6

Q fi 3.%4!%=;d71'Q : 21}?.n-bff.>d;:0S nV07m
ff21>altY(E'QI`Q : 21w%'.%-;`ffmH;:0}Q.XffHH1
}Yj

' l /ff;;.4;E0n -X}4q ff|E.% ff;ff}t -;

d>JO ;-c17.ff
B -ff;l' 7cmca01ffXJH%tff4;vt4 ff/04;.;bmU-q4.
ff4;`ff';-% 4Q `;ffhK9>J94 ffQ % 9S# ffb;Qff4;t
2.4;ff? Q4.b12-;Q'JYU '4ff;`2 hff.| #Qff4b12-
2.4;ffB n4m0;9: n%'~ #SG'4;dff;4Jmbt n0 ff?ff;ff 7
4|.fi /YQ-4mHb12%-ab12 ffGfiff4;t; n' .l4!nS!n06
}ff4;E-4ff%QE-; -90


fiff




Q.dbff4;-ffQ X|.'4;0fiaq4ff?;> ?ff;S'.
;ff1} l`ff

>!#"$>aQ Q4-h Bb%&('!)*)!)+,&
/>JffG;.ff.-l| -X/>
U 2ff}a0&132(346587!9;:=<=>+?@&BAB 2ff
l /%l?} :| 7aC
&
- 4>.'4 lfiHbm01&=D%Y? Hff}/aY1b12
J>EAO2@14@ a; &=D1?Y% ;?J1>E

- m0;'.=l2.G;F 4;J>. /fi%
/.%.':42FY 4;t0.bffd 2d4-H?@&'BI &J*AKH?@&LMI &'NIO&P@
.Q/%}/.
QE;Q.;ffA.-Mmlt42YF 4; =J1>.O0stl%/.Umfi92.G;F 4;
O9= 24-Q?@&'MK &J*AIR?@&LSK &'MKT&=P!=
.'/l%E/.fiQt;Qh9MN
- %
/.%.Q'-JOU.b%17Qd?-a;? %a|;XJ>!3
- /.%.Q7




4|. dfffi 4; E

J>Jr lJ>.%l `ff'}0laY1b12nQ -|:0'nv0sl% ffba0;

U!V!U

fiWYXZ[\]^
_a`cbd+e!`gf(e!h,ig_kje,lkmb1i+ne#oqprHs(ecd.tuShvlawp`xe!`.woyzi+neOoprHsecd.tu%i+ecdvrT`_ko0i+neHd+ecfd+e!`gecoi3wig_kto1{}|~e
yecoti+e.smR0#@Ni+neH`fi_kceOtui+neO`grRw*lle!`xi.8~dvecfd+e!`gecoi3wig_ktoRuEtdCM{
o~w`+`fi_korQecoqi.//!!`vwig_a`fie!`._uYN@Y{Hph+n~wo~w`v`fi_korecoiO_a`#w*la`gthcwllke!y
wrQtye,ltuM{%mc_krfl_e!`byecotive!y 1b1eRre!wo~ivnwiOecjecdvmrQtye,ltuC/_a`Hw*la`gt
wRrtye,l%tu1{Ond+tpntpi.i+neHfwfecd*bYneco~ot6h,touEp`fi_ktohcwo~wdx_`xebe#_ayecoig_u;mwRtqtle!wo
uEpoh,ig_ktoTR_ki+nivne`xeci%tu(_i,`rtye,la`cbowrQe,lmN*33{Ys`gecdvjei+nwii+neCh,tooe!h,ig_kjev_krfl_ke!`+
.p`ge!ys(ecigececo~ttlke!wouEpoh,ig_kto`}_a`Ye!p_kjw*lkecoiOi+tQi+neh,tooe!h,ix_je`gps`geci8tdCe!pw*la38
p`ge!yu;tdY`gps`xeci3`Ytu%* {%nwi_`b~ _uwoyRtolkmR_uz/B{
i+ecd+r_a`#woa}G3(MtuwQu;poh,ix_toMb_u M{ i+ecd+r}_`#wH3GHa}G3(1tuYw
uEpoh,ig_kto6Mb_uS_`}woR_krfl_hcwoqi8tu0woyRi+neOh,to@poh,ig_ktotuSwomfd+tfecdC`gps`xeciYtui+ne8l_ki+ecd3wl`
_ko6_a`otiCwoR_rQfl_ahcwoi.tu%M{
hvlwp`ge#_a`YwoG}a,EYtuwu;poh,ig_kto0Mb_u%~ ({ hvlawp`geO#_a`Yw3GHHa}G3Etuw
uEpoh,ig_ktoMb_u#_a`8woR_krfl_hcwi+eHtuS0woyRivney_a`Ggpoh,ig_kto6tu%womTfdvtfecdC`xps`geciCtui+ne8l_ki+ecd3wl`
_ko_a`YotiYwoR_krfl_ahcwi+eHtu%M{
fii_`e,ll1ot}oTi+nwi!bqw#rH_ko_krTw*l.8d+ecfd+e!`gecoi3wig_ktoRtu_a`YwHy_`;@poh,ig_ktoztu`gtreCtu1_ki3`
fdg_kre8_krfl_ahcwoi3`c{ r_o_krTwl%80d+ecfd+e!`gecoi3wix_toTtuR_a`wh,to@poh,ig_ktotuN`xtre8tu_i,`%fdx_rQe
_krfl_ahcwi+e!`c{
uQ_a`rtoti+toebivneco_kinw`w.po_ape.rH_ko_rRw*l.80d+ecfd+e!`gecoi3wix_to6
p`@_ow*lli+neCfdx_rQe
_krfl_ahcwoqi,`,3bwoywHpo_apeHrH_ko_krTw*l8~dvecfd+e!`gecoi3wig_kto
p`fi_koTw*ll1_ki3`}fdg_kre._krfl_ahcwi+e!`3{
E*cGc!G011a
neH_aye!wztuYp`fi_kohvnwd3wh,i+ecdg_a`gig_ahQrtye,la`Hw`.wqotlke!yeRd+ecfd+e!`gecoi3wix_to~Yw`}_koqi+dvtyph,e!ysqm
.wpi+Reci!{6wl{3!3{%nwd3wh,i+ecdg_a`gix_hQrtye,la`Oecd+e`gi+py_ke!y_ko H@8e!hvni+ecdMe!wdgl
b*
.w*jqjwy_aw`Reciw*l
{kbO!Y8nwd3ytoti+n1b.!=woypoyecd6wy_1ecd+ecoirTwo_uEe!`gi3wig_kto_ko
ywi3wsw`ge.i+nectdvm@ececdg_eciCwl{b1!(q0woo_lawTYw_nw=b!(Ctiviglkts_s_ko1b!=_ki+ecd
8ti+iglkts1b!b!3{1n_a`M`ge!h,ig_ktoHye,oe!`h+nwd,wh,i+ecdg_a`gig_ahMrtye,la`woy8i+ne,_kdMsw`fi_ahfd+tfecdvig_ke!`c{
=td%1,0! beCye,oeCivneGE*+c3*Ea.tuBwoy#i+tOs(eCi+ne8w`+`fi_korecoiYH0*
`gphvn6i+nwiM8_uSwoytolkmR_uS=MOwoy*MHE_
{e{bqivneOs_kig_a`ge.lkt_ahcw*l
woytu%6woyz{,{
=td.w`geci.tuw`+`fi_korecoi3
` b
( ff
fiff,+ _`i+neTw`v`fi_korecoi.eHeci.sm_koi+ecd3`ge!h,ix_o
w*lli+neOw`+`fi_korecoi3`_k
{M|~eO`+w*mTivnw
~_a`.g q (_u%i+necdve.e q_a`gi3`}6
wo

`gphvn
i+nwiY
woy6!
("
fiffff,v 3{Yi+necdv_a`g#
e _`#% $@g &' (E{
neO!( qgt)
u =! byecoti+e!*
(+-,.fi*'
/ %3b*_a`ye,oe!yTw`%ivneC`grTw*llke!`giY`gecih,toqi,w*_ko_o
ivnwi_`8hvlktq`ge!ypoyecdY_koi+ecd3`ge!h,ig_kto1{
Nt_llkp`gi+d,wi+e0i+ne!`ge0ye,o_ix_to`6h,to`fi_ayecdzi+ne`gec1
0 $q*!!+c{nec2
0 _`
ot%o Ed+e!ypoywoqi!3b ( ff
fiff,+" 0 !bwo4
(+-, fi!
" 0 q!!*+c+c=c!q{
Bec6
5s(e8
w 7}td+oze fd+e!`v`fi_kto1{.ne`geciCtu%i+n*
e 9,~; :qg!E*3cEaH ! Yt<
u 5/byecotive!y
necd+1
e (='>?
" 5Y_a`Hye,oe!y w`i+ne`xecituCrtye,l`#t@
u 5 i+nwiwd+eotiivne_koi+ecd3`ge!h,ig_ktotuti+necd
rtye,la`YtA
u 5/{Ytive.i+nwB
(='>?
" 5_a`}ot%o Ed+e!ypoywoi!{%=td+rTwllkmb
z45

(=>C
"5

=4

(+-, fi*'
"5ED}CF

3

tdYe=wrflkeb'(='>?
+q!=!!3!3!1 q*!!+!*q{
fii_`e,llotYoRi+nwii+neO`geciYturtye,l`tG
u 7}td+oe fd+e!`+`fi_kto`_a`8hvlktq`ge!yRpoyecd_koi+ecd3`ge!h,ig_kto1{
n_a`8d+e!`gplki8_a`8ypeivt0hc}_ko`gecm~,!q,bYntRfd+tje!yQ_ki8u;td.wRh,ecd+i3w*_kohvlaw`v`8tud3`giYtd3yecd`xec%o
i+ecoh,e!`c{ lu;d+e!H
7Ytdvo3!=h,to`fi_ayecd+e!yRw8rtdveecoecd3w*lhvlaw`+`Mtu1`gecoi+ecoh,e!`c{@BecrrTJ
w IYsK
7}td+o
LffM(N

fiOBP%Q%R

ST%U&Q%VCWW/XYP%R'W[Z%R%\^]`_%Z%Q%Zba?c%V&Q%XdWc%XYafegPh\'V&i W

jkfflm%k npo?qffrsYtvuxwyzyz%qx{%|}&{'}?t~wy w}&'rsp(r&t q&)qff/zCy/q(|Gr 'oHqffr | s'jkl&l&?n3{%|qfft q(?yAr %}&yz%q(|{%|}?} '-}&|
yz%q{%|}&{}Ct~wy w}&'rs<(rt q&n}&|q(} &q(|pt~w'q8/z'r |ryq(| wYt wY#}%o?qsYt(r {%y/%|q#rssAyz%qJw?-}&|*r w}&
r }&%yByz%q/s}Ct %|/q&'yz%q(1rsYt }8(r{%y%|qKr.ssyz%qw?}&|/8r w}&4r }&%yByz%qB}|1qb{%|/qfftt~w}&

3?p'2f3p(*?'~-A?'33*b'(%?' C3@'/@&1(/p (d&
dCg!(- ff j (C j

nn

pdp(3p?p3#p'' (% Y;ffYbd
z%q#}&%}y}&%qy/z%q(}&|4uBr&twCy/|}bo?'qffo?xt z%}&%y


jkffl&l&bn'r 'ouBr&tsryq(|'tqffo}|6rHyz%q(}&|

-}&|#}bo?qs-'r&tqffo|qffr&t}&?w%j"z'r |o?}x}&yzkffl&l hn

z?wYt8tqffy w}&qb{?s}&|/qfft#yz%q*|qsYr w}&'t


'q(y uxq(q(4y/z%q@#}&%}&y}%qyz%q(}|gr'o4/z'r |r&yq(|wty wY#}bo?qsYt(

't'rsA{'r |y wYrs}&|o?q(|

*<ff(# %1*&'&-8;1dC



kCH C&` &
.% k 4 '*&'#
fiff
ff'.% k #< &'1'# !"#$&%-@ff 'd?
&&Y-d&(
ffC ) 1J(&#dC*,+ &'*&H ,-&.01
/

&@& &

2

Cy/?wywqs&hw

!

3ff yz8?wy wYtxyz%q@%}&|*rsp}&|o?q(|54w k&
6 7h}&|Bq'r #{?sq k k 898:8:8B k & %r 'o

yz%q(1y/z%q}&|o?q(|B|qsYr w}&1}&1y/z%q

yz%qJ}&|o?q(|B|qsYr yw}1wYtB|/q(&q(|t qffor 'o1uxq@z'r&qy/z'r y@k
k k
z%q

; q@%} u o?q ='%q?>

/ 8:8:8:`
8 k&k <
&&-&'H(.-%(Y4 @ .%

k

>

CED,- @?GF



&&-&'H(.-%(Y4 Huwy/z1|qfft {'qffyy} >

z%q

Bj Hn


z%qt q(y




uxwyz1|qfft {qffyy/}

Bj @?n




d?

&Kd'C1(HdC#& &

(d



dC*--YJ.% kff?

}

w

Bj Hn



8:8:8:8





H


LK

ff 1

d'M& &ff'd 3Huxwyz|qfft {'qffy

7%}|Bqhr#{?sq

R q(y&H

CIDJ&- @

2

UT V

j

OT(V

nj

@ @ H



j k k n

8:8:8:8



y}

>

,N"?N H @ +
/ P G F

'(

2. k k && k k %& &

jk&k & n



r 'o

QF

2 k&k &% k &h k &%& &

H
H n
8:8:898 jB

nxyz%q(wyz%qt q(y8%}yr w}&

. k k & k k &h&& % k&k % k & C

@ HGF

z%qt q(y

w



k&k &% k kC)r 'o



8:898:8 Bj Hn


2 k&k &% k kC&r'o*yz%qKt q(y

XW9W:W 8 jBHn 2. k k C
sqffr| s&}|Kq(q(|^r&tt"w%#q(Cy & % k H[Z j\Hn}&|q(} &q(|3w ] / Hvyz%q( 0 /
H nxj"t~w'q wYt yz%qt 8rssqfft y@r&tt~w&%Hq(CyBuwy/z1|qfft {'qffyy}#y/z%q@}&|o?q(| n z%q(|q}|q?>
jB

w



H



^
`_?a cW b 89d:e

Bj Hn f^
:_?g h

Bj HnF

ji%qfft w}&HwYt`wGuxq@(r =''o1rt *rsstq(y<}%q(Cr w&q@q'r #{?sqfft(%r 'o*'tqwyxy}|q({%|/qfft q(CyHr&t

z%q


r }.q&

k5l5l

fimnopqsrt

1000

1011

1001

1010

1100

0000

1101

1110

0001

0100

1111

0011

0101

0110

0010

0111

uwvyx?z{:|!}~?z\vyxO!vyX9BwLX&Bw
Oy5[I'X5MLc5syX?`v?{
E , `C
\PcG5M? jM
yj&:c?'?wMGQX?JjO

Bw9Lc?5L

`vyx:QvQ| XQvy\vy?s
|#x?|cLy:|c{:XLv|#{:|c{:|5\|cQL\vy?O?{
zX \vy?X
&
`L

BwPS
`L

BQ
B}Q
v s\y5
vGL,:XL:|\|c#L(ECL5
| vyx?G BLGJvOX?`v{3LQ?{:
uEzX \vy?#u?{| XLQy| ?X`vQ|c{#:|{:| {:|5:`vy?( BcJ:BcU:BcJ
v: zX:\|5vy9|vQ:{:QzX \vy?

|5cP:XL
:|.9L\v`?vyx?9`vyx?|cQ
L {:|?~
& QBP[C???J??J?:L5:c?J:c?c5?Lc?Q?c55Qc??Q5L5L5L?L?
(|PX?|P: ?Uz:|:||cs!vy

B Q{!|c{:| [G???5??c?c?c5Q?:?LLG
?:|#:XLv #9L\v`X|5:|cv BwP CQ X& Bw U:Xvc
J \9ff sPL
fi
|c{:| ?{:|?Q!vy \G??LG?LXU!vy
c\PQ?5LQ|#.9 z:|:|3|c
L
!vyQvO?:`vyx?|cQ3vG(Q{
vyx,:| ?{:{9|5\X?Xvyx,L:\v |5'LX?\vyx,:|{:| L\vy?X
:|c{:|?Euwvyx?z{:|}\L':|OL:\v |&
vy:${9|5\X|5 9],fJ???
fi
|9L\v`?vyxI?9`vyx?|cQ
L L{:|!L{:|5Ovy(X ? |?
fi
|!!vyQvO?:`vyx?U|cG#{:|jzXQ|c{\vy|5sLX\|jL
:|
?{Q|c{P{9| \vy?XcQQv:O\L$:XLP:|{9|5\PLfi9|?:`vyx?U|cGP{:|?P!vyQvyL{:|Q{
fiw
?z9|# \
|#X?|:?&G&?:`vyx?U|cGQv9&vLXL?|#9|#!vyQvO:`vyx?|cQc
fi
QvOvO{:?|5G:|IQ?9:|5Evy|5,Qv: C 9XL?LX??IL{9|vy B
`vyx$:|&Xx?z{9|
|,?X\|c{:?|,:XLv
B &G???J5?:?J G
fi
|,?:|c{&\|cOL{:|
!vy B [G???5?5Gc5G?LXO!vy B PG???55?c5Q5QQ
`vGL&:X:|j`v c|'L:|X?`v?{'zX \vy?vX?zXQ|5G9|j`v c|#Lvyu
{:|c{:|5|cG\vy?fiX9XL
?{|c|c{:#:|`v c|!L!vys:\v?zXQ|5Q&:|`v c|!LPvy #u
{:|c{:|5|cG\vy?
uJ?{LQzX \vy?LX,\|cLP?:`vyx?|cQ y|c5~

! !vy Bw#
" `C C!!vy Bw:G
$%&

fi')(+*+,.-/+01*+243356(+,7398+,+:<;>=+8+*+8@?BA+21*+5C3A+56?EDF(:721GH3

IKJ+LNMOHPQPOSRUTWV+XZYJ+L[O1\L[]^XHT_1L`NaHVbacPYL[\V7aHYTW_dL RUacefYOhgBLi7V+Lkj[lm4ndoffp.qr
sutvBw
xcv7y{z}|~t
7xHww7Ht 4+ZK^Z 1<
[6d
.4c j[l7mBndoffp.q)


O1V4YTWVBBTV+X<YJ+La7OH_1LL7aH]fBPLRKTYJYJ+LM+V7YTO1V
o[j
qoffj[
cqoff[j
mq
RKLbO1V7P7gBLbYJ7aYj[lm4ndoffqfS1++Sc[1+H[+[1[1+[1[+1[dSdH4r `uYJ+LZMOHPQPOSRUTWV+X
YJ+L[O1\L[]`J+OHR`>YJ+Lk`L[Y)OHMJ7aH\a1YL[\T6`YT6 ]fO+gBLP6`[aV7L7`LgYOhaV7`RKL[\UgBLgB7YTWOdVd+L[\TL`[r
sutvBw
xcv7y|~E
[vB7.47
~t
7xHw
fwHt4+< pfcfpf
[
[C1C4c pf pf 1h1Qf [116 j[l7mBndoffpfqpfo q

1

YuT6`f7`LMBP YOJ7ac_1LYJ+L \L[+\L`L[VBYaHYTO1VOHMkaM+V7YTO1VrM9T`XHT_1L[VTWVTY`Z
\L[+\L`L[V4YaYTO1VYJ+L[VTYuT6`uLa1`eYOO1]f++YLYJ+LF`L[YhoffqMO1\faHVBe<Hr<>a1JYL[\]TWVYJ+L
N\L[+\L`L[VBYaHYTWOdV<[aHVO1V4Y\T++YL k OdV+LFa1``TX1V+]fL[VBY]uTV7oqR)J+L[\LZYJ+LZ_SaH\TaBPWL`
YJ7aHYKaH+7La\TVhYJ+LYL[\]aH\LUi+@LgZaHV7guYJ+LNO1YJ+L[\`aH\LN`L[YYOYJ+LT\K]uTVBTW]ZacP_SacP+L1rIKJBT6`T6`>Y\+L
`TV7LM\Od]L[_1L[\eO1YJ+L[\k`aHYT`ffMedTV+Xad``TX1V+]fL[VBYOHM)YJ+LYL[\]RKLh[aVR)acPgBOSRVYJ+LPaYYT6L
YOHR)aH\g+`KYJBT` ad``TX1V+]fL[VBYO1Vaf7aHYJOd]f7O4`LgbOM`aHYT6`Me1TV+Xba1``TX1V+]fL[VBY`[r +O1\LaH]BPWL1YJ+L
]uTVBT]hacPad``TX1V+]fL[VBYMO1\uYJ+LYL[\]f + RKTYJ\L`LYfYOYJ+LZ7a1`T6`uLPL[]fL[VBYhd+11
T6`u]uTV7oqu41+4rIUJ+LFa1``TX1V+]fL[VBYFd1 R)JBT6JaSP`O`aHYT6`i7L`uNT6`uV+O1Yu]uTVBT]hacP `TV7L
1 d+ 11r +\YJ+L[\>O1V7LRKLJ7ac_1LO1V+Lba1``TX1V+]fL[VBYuM\O1]La1JYL[\]bTY
T6`La1`e]haH1L`+\LYJ7aYhYJ+L`L[YfT6`EV+O1
V \LgB+V7g+aHVBYbBeJ+LdTV+XR)JBT6JOHMkYJ+La1``TX1V+]fL[VBY`
X1L[V+L[\aYLgT6`>TVYJ+LNTV4YL[\`LYTO1VbOMYJ+L O1YJ+L[\`[
r L RKO1BP6gZ7`L YJBT6`)acPX1O1\TWYJ+] P6aHYL[\>TV`O1]LOHM
O1+\)\LgB7YTO1V7`[r
.Lk`aceYJ7aHYNauM+V7YTO1V T6` ]fO1V+O1YOdV+L TQMTYNT`N]O1V+O1YO1V+Lad[O1\gdTV+XYOZYJ+LO1\gBL[\\LP6aHYTWOdV
g ff
) YJ+L[V<fio q 1rZ)O1YTLZYJ7aHYNTQMRKLf\L[V7aH]fL
[rZaH]LPWe1TQMR)J+L[V+L[_dL[\ko q haHV7
YJ+Lf_HaH\T6aHBPL
4e TY`V+L[X4aHYTWOdVMO1\ La1J )`7JYJ7aHYk EoTr L1rfRJ+L[\LhYJ+LfO1\gBL[\ \LP6aHYTWOdV
T6`Z\L[_1L[\`Lgq)YJ+L[VLO1]fL`Z]fOdV+O1YO1V+L1rIKJ+L[\LMO1\L1) ]O1V+O1YO1V+LEM+V7YTWOdV7`ZL[
V ffOHe`ffTW]T P6aH\
+\O1L[\YTL`[r+Od\La]fBPL1HYJ+L[eJ7ac_1L+VBT6d+LK]uTVBTW]ZacP NaHV7g Z\L[+\L`L[VBYaHYTO1V7`[rV+OdYJ+L[\
+\O1L[\YeuT6`KYJ7aHYKYJ+L ]TWVBT]haSPa1``TX1V+]L[V4Y)RJBTJbO1\\L`7O1V7g+`UYOuL[_1L[\eZYL[\] T6`>TV7gBL[Lg7aH\YKOHM
YJ+L`L[Y]uTV
offqr



u17d17>4C1 C4u 1
|~t7xHw fwHt)B71 17
#
[@11C4
Ck6
Q 1C 1hCBucu6 oq "!1uc $#
% '&[1 (cu 6C4u66u1*
)+!,
[[1C1Nd C4H[.-d7uuC oq C
u6 offq
%0/ & u6 offqd2 14365offq

.L ROdBPg acP6`OZ7`LYJ+LV+O1YTO1V OHMaPLa1`Y)++L[\ 7O1+V7g OHMa87>OBOHPLaHV +V7YTO1V.o:91LP]haHV ;
< aH+Y:1= ?>$>+Hq1R)JBT6J[aHV`O1]fL[YT]fL`U7LkJ7aH\adYL[\T@=[LgBehYJ+L ]fO1V+O1YOdV+L J+L[O1\e1r
vCBD?w|FEv4G4HJIKIv+xL:Mw,N FO PQHb Q)1Q14C1+SR)T(c
JNU
u[1fC41W
V OX H[Y[ d@uC4 117Qf 6Z V1C4u
[ \ bC41
Z [D]
V
^?_?`

fiacbdefhgi

jkhlnmpolqsrutFvwkpxoyWmDz|{~}8mk,\rDK:$8c$F$\? $6$8J.F
$ hc?$$n? $*YT '@c4Dn?K ? $F8
\XfiFX$?:$n+Y

2 ? X
0

' W

*$,:8'C:,"$:6'?:0@$?C8c":'?::@?$$h
fi:8C$:$:C:$J$fi:?$F:$
jkhlnmpolqtFlCklo{,lnxoYnpKvxhplnxX\pDvwkpxoyWmDz{}mkY\rW
D? ?s 'c$F$nTCpW\?J 2D? W:C n 2D?

$,*nJ$0Tn:@$
ff fi
*
@$ : ?+K'$:0@$8nFcC $c$c$$C"$?
?? *?$?$ $$$': C: 2?
p

j kplmWq pxmDzhxo?m Klq!

finT ?@$6@'@n?8nn@@$ $''$n@4CT:: ?6@ :nT? "$#4
%& :?:fiCff "$:P$:6@4\ # @F 'F$: T8nTfi
:F0T@$J:$n@4,$0Tn:?6'$
('*) % $@ % FC:TT$+ nT

,8"$: %-& #ff
:? :,n #

.0/ 1)32 ::::4,n\ 5p@$ % $8 c$'76:?:0@$
,8 c$'0@$8nF8Y
:?X8cC: %& 9#''8 \ #

: j}7) "n:$;fiWFCF:T < .=? C>+ $C:$$6:?:fiC
,$$:$ %& ff'?:0@$;?
:?X8$$'$ < & P:?:0@$1@
: :?BAC@
fin?'T0@$6:$n@4,CT::?h

(' / ) % FC:TT4+ nTD,finnEp@$
,8"$: %-& #ffJ8GF 'T0$@J$:0@$8nFH#ff
:?HIY?EJn # > F
& $:$Kfi+$C@@$T L$n@nc:M#ON F $ ?:nTJT:(F n #
PRQ S) 6 \\, % @\ :
,8"$: %-& #ffTF $'0@$8nF
:?HIY?$n@U#ON F
V TC':,:,@ \c % +W,
' / S) % $:TT4+ nD,finnEp@$6@: % $\'c*8n@
(
,8"$: %-& #ffTF :T0 C@ C:0@$8nFK#
:?
,4?n # X F :ff$:
IY? :'T$$: & n@ $n:
8n@(YWZ7?\ # [ F8
\]^

fi_`babcedgfbhiabjlkknmo`bckRpbcbqsrutbpbabpwvyxbjiabmzk{xbmov}|~`qjik

EG K 09K
7g94 0bK000
4UlibT-b{Myb$ii{bUnnybiMogffnS{-{$nb
ib{bb>ffb{Go {TnSb4ff n(${7Myyi0Gn{i7>{youo{bG
iyS3{}T{iibTGG{bT--3{blDynoE71iyy
w5iMoibi{b7
b{b4b{bb>b{iyo-byob;yb $n{T7i{bo
ib{bb4lbMoffi{bXEuMi4*i{n71 Dyn1oGybiMou
{b$
gffbbbXib{bbUffyffo-{bMi4-{7G41
b{bWib{bb(b{yobibyobyb T-1ioy7{bb{{
nMo{y ib{bbTKUbbb4 KM{ {T;iinboTb{bbybiMo
iinbiT5uXTi{{1 $DynoGlbig1{b(M3ffbbb
S{b4$ggeTbinT{UiDi{bGib{bbuo-bi-byoib7yb
{b{
obbybMMySg{bnliiDi{bi
eUyblbMownyi0ffn${gnT4inDi0-K-0bbG{ynyEEo
{4{(ibi0 yyn b{iy-oHw5iMoizE$ilEU{$Rb{iyUX53{b{
o7ib{bb7lbMoi{b{7i7D1biBi{}{ b{bb
ybiMo4bb{ibb}i ub yX ybiMoTib i9nbS{bbyb 4{b
bb{bbi


fiff
ff fi!"ff#$
%'&(")*+ff
{yoUiGb9{K{b-b{iySffyiMWiWn{-yyby
ybiMo3{yi ,T ibin{ob{iySG{4yRWybiMoK
EiyE>nb(i{nibynoi1b{iy -7HoTy47lbMo>i
y/.10#2 ulE43565798;:<>=8?579<@8i57A<B5si$DCyFEiEgyHwiEiMziHG
iyzi*3JI

$ "KDL -bb{yboKyEobMS43 S3 noyU-b9{UWnN
WOMiPMWnT7n$-7MQMW{GbnRMBybinSnoGybiMoE
{yny {U TW
V SX V Sb* V
Y" V
V
ZM{ii

[ C]\^0_2 DlE157A<B5C`3-biEiMzioE iyE$ 2 DlE1579<aI
b i{-b{ybM{bb{y0ioy-bC45o-{yuoU{yiK{bT{yE5
b{iy {X{~Bibi03yw,Tib ynoi1b{byb{4iTnoyEE1

{ in{T7i{b*{-b{oibS{ib yu5Ub4Dclo-ibbl
dDegfihkjJl@mfimkl!npo>hkl@qsrJtDhFuvtDrJw_x_jHuvyjxfilzqBt{rBt|hfi}BwkljJl@mkl~omkl6kl@r}J-l@mohFuvt|rxfiuvhkj6t>nvrBt|upongqBlnpoorJql?r}B-l?mF
o>hFuvtDrxfiuvhkjuvrJy@mkl@{l@rhonzt>nvrBt|uponqJl!npo@;uvhkl@m6it|hkhFnvtD
idDa!e4#jJl@wkl6mkl@}uvmklhkjoh-hkjJlOonv|tDmFuvhkjJ
xfiunngy@tD-J}JhklhkjJllnvl@-l@rhkwt>uvhkwt|}BhkJ}BhztDrJl6oh~o-hFuv-lDUorJqsmkl@wkhkmFuvy@hhkjJlhFuv-lqJl!npo@4l@hFxgl@l@rsy@t|rBwkl@y?}BhFuv|l
t|}BhkJ}Bhkw@egFrJy@mkl@-l?rhon*tnvrJtDupo@n"qBl!npo@onnvt>x_w#hkjJlqJl!npo@hktqJl@l@rJqstDrOhkjBlzBmkt|Hnvl@'wFuv@lo>rBqOtDr6hkjBlr}J
l?m#t>*l!nvl?-l@rhkwiy?tD-J}Bhkl?qwkt;o>m@e"tnvrJtDupongqBl!npo@6uvw#wkhkmFuvy?hkl@mfiuvrhkjohfiuvh_mkl@}Huvmkl?wiqJl@l@rJqBl?rBy@ltDrnvt|rhkjJl
JmktDnvl@'wFuv@lDe_"tDhkjt>*hkjJl@wklrJtDhFuvtDrJwo>mkliwkhkmFuvy@hkl?m#hkjorst|}BhkJ}Jh#tnvrJtDupo@n_o@nvDtDmFuvhkjJ-wzwFuvrBy@lhkjJlinpohkhkl@m_6o@
x_o@uvhonvtDrJhFuv-ll!`t|mkl-y@t|-B}JhFuvrJuvhkw#mkwkhtD}JhkB}Jh@e_rHtDmkhk}Jro>hkl!nvD*-t|wkhit>fit|}Bmzmkl@qB}Jy@hFuvt|rBwDuvl!nvqt|}BhkJ}Bh
t>nvrBt|upon#onvDt|mFuvhkjB{w@UorJqsxfily>orJrJtDhi|}o>morhkl@lhkjoh_hkjBlwkhkmkt|rB|l@mirJtDhFuvt|rBwzjBt>nvqe
He"_johuvw@oitnvrJtDupo@nuvr6hkjJliquv-l@rJwFuvtDr4tXhkjBlzBmkt|Hnvl@`hkjJlir}Jl@m_tU|omFupo>Hnvl@w!
hkjJl#uvrJJ}BhzwFuv@lDorJqhkjJl
t|}BhkJ}BhzwFuv@lDe
JJ

fi6***fi*
-"B
-k
>;6J"s"_-U*W"fi`_;i>@;!g
("@Js>*-J;!`
*>XDJ*
>"">"*J46*D
@;>""s>@;!`*4
>!`
*Uik
i`Ji"z-6;@*"@`>*>
">
`D;`*k
>;s-`>W'JH*4k
>;ss;>@;!g
"
`#"
O@;!k
`*>!`
*i`6;>*iN*#W->*>*6J;!`
*>XDJ*6

~>*4"@--;-J->*-s*>"O"
6@;!k
`*$
!`
*-`6;>] N*
ki>*O"@--4>*!`"D4;->@;!g
`"@"B
O4@;!k
`*
>!`
*U6;

]D`>*
-k
*"]@*"@@`>*@`

6;W
"DUJ6>*D;@>"D{
>?`*R
!`
*Ji6{s"B
s>>JD*|4-`>9>;-*>*DJ*>4


D`;pk4`>

**U@6-"B
>*-DX*J>!`
$?#{B>?
6;s;z@;!g`
_""4>@;!k
`*s
>!`
*U_-@*"@`>*>{N>-
z @B>? D|
">*A>*J;!`
W*>*DJ*>
6*"@--;6J_">*>Dk
>s-D
U*-`>
W*DXs@*"@*>>
> W4**J;!`
(*>XDJ*UB`__"
>*"@-;s"*>D>{D
"`"$"s-4"@4@*"@*>$`"@J
]{*
-;-`D* W>*AD
@`U*>"">"66"@-
>?*J]"B`>

>*--
""*4>@;!k
`*
>!`
*UON*

(4-
;9`
>"@>*>>@;A*>
4-
Jfi;`
W
s$s*D"
-4**
6@k
>>;O*"@@`>*@`
9*>XDJ*
J
!`U
>>*D`J>H"
->*s*U@*O
@
>`*$!`;4"
*

Bfi `|@
"@
->"--"J{s@`
ik
9D
-*>Dk
>g>*O"@-_;Ji--"B

4
**>
`Afi-W!``W"@-sJs*>
` @;@J`W*@6*>>*"@-
"i>;-
@

9i;"*UR>B`*"**ff
9fi "{*;D
*>D


>$p`
-4

|
***s
9 N"]
@`>*
>$@`

9D*W>*



D`***J"" >`J6J->`$J6>*-;@s-O*'>"->*OD`|

" ( {Ws*J>""@"XD~">>*>`s
->*s
***6
9fi

"!;i"|@>*-J
?|
@s"""`*
" !#"%$'&%(?* )B>*O>!`
*;,
+.-0/#13244
7
k
6>*

65 N !#"%$'&38(?D
9 JBz>*s@*"@@`>*@`
@;>k>
"

*"
"@
O"
- s!`;O@*"@; :
@`
]-
>*
<
-!``]"@k
> >*@*"@@`>*W>
D**>J>?
W= _"k

-O
U?
>,996;>
>HiN>4
->*4 = iW4;B`P>"->*>;6-`>*J>k

|-`>] p"
`p*>;O-`>*J>k
@
=
= -;-k`O-k>
>*D6>"
W !#"%$'&38(?"] "
`A

W !#"%$B&%( = |_@4"J`4A
W !#"%$'&38(?D
@">"-*iC )pE
D3 F(B%$'(J Ffi GDU"
HIAGW>*
HJiX">*D

!#"%$'&38(J = |

W !#"%$'&38( = {>*]A
!#"%$B&%(?|--*>Dk
>
{*>s;-`>*JO9-`>]
>*9{s]>JD6>;
D-$*J@U*
-`>K
L= =
`***
6;`-p>BR*|
*-
J*
O-
k
s**6!A>;s
9DU`]>*`U*>>' N
`>J
`J
@s
*D`O
G P
H ***s-4"B
*k
>@`
]
]>*4>*sD`UD
-*>Dk
>-A*"@k
> >*>JD*|!`
`>*
6*>A@*"@*@`
'4 1
>' N`>Jfi
(`|D*
s>;s*
` "!`*A*4k`-`*`>|*>*DJ*>
]J
@|
4-
>>>*>]
*
>@;`>]

4B
D>-
>*DX@`J>D@`J
4
@*"@*@`*R
k>*4"{"
@
Q
DU-49*>*DJ>*s*DXO|

B R@"@

-D>k`
*@`*$>J|-k
6>*6*JS
D|>*"@--;6JOBS
D*>*9{s*
TVUXWBY'Z#[#\']^Z#_`Z#]*a[#\']cbedf`g#]^h<ij`Z#_k`*lB]Mbfimfil
h']^Zonfp] YBgonfl'qff[#\']c_ `l'`[#`l'][#\']^`Z#rQs0tu\%mfiZ#hB`*l,vxwy`[#\Ca;zfi{{fi|}JhB`]^g
l'`[~g#]^]^_k[#`%].Y'g#]ijYdjU
''

fi;;L~;C;0;;;xc;;;;C;ofi;0C%

fi%
#C,'Cfi0@;C,fi'jCA8Bj;e%'ufi;;jfi;'fi
jfiQKCc^
fi;
Cjfij,jfi;'fi0fffi;<C;,CfijCj;fiB~fi;Q%%^0%j'<fifi;fifi;Q;'fi
A8;B%'fi^jC''fi;Q%38Q^;^^jfi;^jCVXCcfi;,C;fi%jQ%c fi
fiCfi;<C^fi^jC,jc0 j'%fi ~#8B%%^,*B;;fi;fi'jfi
0<fiQxk3LJI,8fi<fi0Q^fiC;C<Cj^jCx;;VC;;^;C'u%
jL^xfiQk3'%B'fiM*;kj'%^jk
;C,^;C
Cfi;0^ #%'3%%*?y@IJfi;kjOe3B%''fiM~ *3
%jC.Q;
Kfi;BQCc;fi0
0ACfi*C0^jCJjjkfi;0C^,fi;kfi;
BjCC;#Cff *jCCj'fi%;fi<8%'ffC03Q^fiCj^^
?Bj*Bjj;jfi;'fi
L;@fi;,;fi%j;fi;;^jC@ ,fiBfi
;;'^'
jAfi;
fifi;^jCJ'Bfi%3 8C;'*;'C'C;%'''%'C'%'CC%C%C;%
^;;3^Q%^I ffC; 8C';'BC;C' C'%;C'8CCB~%0yB;;fffi;
; ;B;CJLfi; ~C@*%y;j<'c;C.jjByfi;%*Cfi^0;
0<%^* ce*fi
fi;;fi%I
Q?
^%*fiQ^;^^jfi;
C;ff#C'C8^0%j;^^jfi;fi'fiC
cC0fi;^;^jfi;^jCE 0,0;ff

fi ;*%fi
6


'BC;B'';''C%Cy;fi^fi?% Afi%
fi;8%^0%jA,CQ^;^jfi;fi'yAfi;

%j ;<C;fffi%fffi;fi
0QC;fi<%jefi;CjC; CB;
0j
C


;;ff;Cjx#%'% <
*X;fifi<jQ%^* '%^j;,C;
BjCC;jfiCu#CfiCM8 Jfi;#Cfi%^jC,#fiC fi;Cfi;^;^^jfi;fi%.fi
;C0fi'jB%C;Q;<;<^fiJ
fi;<;;<^fiQ^;^jfi;fi?fi'C%M3*%*3cMC0
*^;^;^;^jC#C3
0
Cj0;

^, %

8'BC;*B';*'C%
;;j;@ fi0<Bj,,C
fi;<%^
.'V j
E#%'% <
McC0;%fi;<^;^;^jC#C.0cCj0;

~%

'BCCB'CB%
;;j; JCcBjc C.fi;% ^j
CBCff0ffC;fi%j%*.Qfi;fi#Cfi<';*^<Cfi08Bj;C
fi;A;*%^jCfi ^;^^jfi;^jC%O#C%Cj0 fi;%^
.'<%
fi;fi#Cfi<Q^;^jfi;fiQ,fiICfiCfi;
8C;fi%j
E;'C
j;kfi0%jAj0'^fik^Afi%;Pj;8;fi;;j;^jA%,fi;
fi'^jC jjfi,3^j;kfi;%fifi^j;;fi'I#C0fi''fi;%^
.'
;'^A%fifi;;'QBCfi@Cfi;8Bj;xfi;y EIBxEfi% fi;
8^0%j'C;ffC;C%Ifi';*<C?;
* %Cj0;; % .0fi'jfi'Cj
AB0fffi *

!#"%$'&)(*,+.-)/102(43ff56879;:<*=->02?A@->39CBD0C02?E+.(GF>H)I49J/K02(MLN-LO&)(*P+Q-/102(R3S7 TVU
WVX4YPY[ZG\

%fi
%jC%C;fi;;ff%j;C,0BM^jBjC^jfi; #C
CQ],y%I;C,0B

;ACAj*fffi;;j;A^jfi%V~;C,0Bcjxfi;,;,Q 8^0%j'uyfi;;;;
;^CJ%fi;QC;;;; ^%*
_jC* Cj;;;fffi *;Q; CA;^~j<^fiCff%
C;fi;;<8
`yC<;^.j<';j*ffI3C;@e'^'<fifi;; ^% L*ff;V
^
C^ff ;'a ;fi; E ` e0<C;ffj%j;C,0BJ^j,Q ]ff%j;E
bc_<B j'
R d>ef;fiM%A%^<CC*j;%jCffeAfi;,^'CAC^
g
;% fi%;Qfi'B
hCfi;;fi'fi
0Cfi'^C;fi 00%fiC%K%fi;fi#Cfi<Q%^

iRj>k

film=n=o=pPq=r
sut=vxw=yaz)z{[zf{[| t=v<}=vG~|;v1EyGR'z>}gw=y v1DzD[y vR.;|;}GzDEw==||.;z>}[A);vRy };}=g| t=v1z>y >
}| tC{Nyv1xzDy {J=}[G|.;z>}A=4R A=RfECEtC=v1}{Ny z>#;vRy }=v1y| t[|Et[>| z
v1w=y z=[Gv;|)8D1GvR ;}=Gv1ya|4;}GzDy>a;vR =cv1Mv1y.t;wD=v1y 842;z | t=v;vRy }=v1y| z>.
{Nz>y| t=v4;=vVz{| t=v{N=}[G|.;z>}8z>}8Gv1y |4;}8wz;})|4
Dx';R'M4E 4 G)RRG>.>4>[4NC>gAR =RDM>4[>NG
Q D!>.>R2O)>)R,.11R[NGEOOARR#Q4N)G= Q
}vRD;A4;v1}[Gv>=v1ya42;z | t=v;vRya}=v1y| z![}[z>=|t=v1| t=v1y8t)wz>| t=vRCt=vt[>
vRD4;v1})|| zz>y}=z>|R}1>.vg;|}=z>|vR>;AAv1}|R| t=vg;vRy }=v1yCV=w=w;vR<;| tGz>=}| v1y
vG~[Ew;v>
Dx';R'GRC4>2RRRG>.>R21>81[RNO>=R A=4>V>4[>NG
Q ;>8DQDR2VO)D)4,.11RNOO)a>O)K8A=RfRVA=Rf>'Q4N)G=[K
#gO)41MO.4N)G=D[>[N41>,2V18O)DQP P.P
!v[.vy vR.;||at[|t[><v1v1}8z>=|G4;}=vR;}8| tCu{JyGEv1<z>y P
,4[#'N
fiff )V1 ')4.;<>>>>GCO O>')4!DC4R
>GK<NQx>Q ,)4.!ug)O>>4#">GK ,.K1CD='=CNC >2[DMO>
OOE[E 4.VR>GO)121VD[OOV1% $. xD[>) P)OE&
">G1a,.1GO>(
' )O1;
GRC4>2R[NE
))a=>O)11POO)> >>GOO)*
) >G1G11 NQ ;VDDRV
">G1 PQK1O>,
s<t=v J{ z2;z<;}=;v1E=>}[| t=vxQC|.;z>}g;}g;|'w=yaz)z{ v;Ew2Ca;|;}w=y v1DzD[xzDy ,+vR t| v1y
-/. vRfy.,fi00123=|54v1|4;'6008723D;}=v1} -/9 }=}2C='600;:=
=ff(>?'),.)124A@B5C<D>C>O2E.D)4JKgNO),.)124ED FGBfiDx
<

V4PHJIfi!vEy v;>v1}=K>;}=w==|V| zML>,+P}[w[zf}=z>C4|vADz>y.;| t=ON{Nz>yQP 9 5P
R =y4;>z>y.;| t=
u2Vy =}|at=v4;>z>y|at=S {Jyaz> s<t=v1z>yav1UT}[}[.<v1yE| t=v}[
D=v1y.;vR| t[fV| w=yavR.v1})|G1
W ;>v1}ARR{Nz>y | t=v4;>z>y.;| t=| vR.|t=v1| t=v1yEY
X[Z]\_^fi`acbd Ks<tC1}!v
z>}=vV|avR.|.;}=Vt=v1|at=v1yxgCvRD[4[| z|at=v<;})| v1yG.vRG|.;z>}Ez{42[vG;v1Ev1}|f e;g
} K [ tE|at[f| e#h
W ;>v1}Mj
iz>y }gvG~w=y vRa;z>}Eg{JzDy | t=v<| t=v1z>y v1>[yf})| v1vR| t[|| t=v<t)w[z>|at=vRCk iz>y }
vG~=w=y vR ;z>}PD<vxt[4>v<| z|avR.|t=v1| t=v1yl
X[Z]\c^6`a_bf, KGP!v<[y.||avR.|t=v1| t=v1fy X[Z]\c^6`acb, Kn
tCat!CgvR>;4;v1})|| G
z X[Z]\c^6`a_bf, K!
'8s<t=v1zDy v1p
7| z>Dv1| t=v1yV<;| ts<t=v1z>y v1p
q;Ew;| t[|
2{| t=v}[.<v1yQ
rz'| t=v1}{Nz>yV.zDEvs
K'PQ =(
L>[atf}CGz>=})|av1yVvG~[Ew;vE{Nz>y
| t=vvRD;A4;v1}[Gv!>=v1ya>}[| t=v| vR.|1}vw[v1y.{Nz>y vR;Ew;)v1A4;[|}=zD}42 | t=v
> QD}=Ev1})|G;t
} KE
u{ X[Z]\c^6`acbf, Ku '}[EvG;842| t=vM>a;>}=Ev1}|<;*
} K a|.C{N[<vVw=yavR.v1})|'J Kc>u}=w==|
| zg| t=v 4;>z>y|at=v
N{Nz>y| t=vw=y z>;v1w
P 9 5 P)s<t=v<;}=w==||a#
z P 9 5 PC;v1)A x N 4E}[.<v1xy yvR1
EvR};}==
X1 zaDQPj
m/K'tCat;Ew2vRs
m{X[Z]\c^6`a_bf, KG}| tCV1>.vxv}[.<v1jy yvRg| z| t=v
vRD4;v1}[GvD=v1y > R | t=v1y u|
v N 4=} rz8}[8.=w=w2;vRVGz>=}| v1yvG~[Ew;vE=
X1 za>.P ~}KE
L;}[G
v K{m<v>v1|<8 ~X[Z]\_^fi`acbd K f}[| t=v1y vG{Nz>y v<v 1}Ew[>az>}DVGzD=})| v1yvG~fEw;v
| zE|at=vvR>;AAv1}[Gv>=v1y >


66

fi}Jx5c

=jJJ8[V5j[O}
s=d[fiE Gk_8#dJfi!]k,[6E
fiJ=u;5fc[c85c8fi_8d5{] u6ccfi8
x5d#5c[Qcfi(5j[}cccdc6V5kj[c
55j[c[=GJ/5MuM5==d jd58VcM
jjd JJ[6kj&#5=566Jj5(5[#c|Q=5|d[d
J#;5E; ccu[[J8cd6J8[du(c/5;!d[c



cJ5[%dj#J}c Ec5[}cG/c[5J85jcd[

wd[fiE} _8#dJfi!]k,[6EG6u

s=

fiJ
}[sU]#ucfid5?8gG
5J5jJ[#[c
d=J

fi

ff


[c(65[6c685

c55#
#65[Jcd#5uM5=#MY5j[ k[lc8J5[ddd
#J}5&u5j# }J}#fi5}5;J5[dd%x#JuM= cd[ 6[




"



*8J6juM5 % cfixk#[5[=[!c J5[#[fif;fi
fi 5[ V85d
}}5[[s55[Q5c J
5c|%_
5 856([5

$





!

#

%'&(*)+-,.+ /103241576"2598;:<=+3>?@>0A<)B(C>0A6DFEG+ >HDI0A/JD
5d6Jd=#6cd5#5Jc85M5#[5;5Jcd[fin[G(=Jd
dc 5c}k5[gj;5!c6djcG8
j=[J8[j,#J%_c8}c

KCL=M
N OYc&}uLdJ%_c8|J8[56c[56d[cd'K5J565,8[
}(6fi 5d##%[;56[
L !d6J5JficdtJ8[VJ8#dg&
#[cJ d6#; cJ5[%d#J%x
P 5#c56d}J%_c8 [!dQ _#dS]R J8[dfi
fig[ Vdc}c[[65c5Q5Jficd}#8}J(G5j8[[fin[

56dkcJ[dfi cG[c 5J56d8(5[6d[Jcd[

GTVU WYX[Z&]\_^a`cbd7e9b[gfWhZ
L Q5[iKCL=MYkJ6*}J#(OjCk5[56d[c8k#kJ8

c[*lCkY]5GjQ6dM5G[55cQ5kj8
$ _fi[#5GJ#=MlCk
5[56[;dM&5J8=c[**jOjCk G=#[c=#=Jc
5;m con [cd&5=[&G58[
]5
5G[[Y=t[cY5[5J]5Gd#
5ck5k]jKLpM kc[=J5[OjCkj(kSk
q 5[jJ d[5ccd%
5cQ5[c*5#ccdc6#6Q!c5#58[Mr
L [JVg5[;##[[5
_;dc[cdMc#J85[Jj[[5sS
5 sSt 8u[f5$ __[}58[Ac
5;cdg[du[[M]Jdk}c5Q#585*56d6JVg5J[V5Jc8gu=vx
w
=g[_ Vd*]Jd(]zdy ]86{
L QdJ}J;dz]R #85]JdQfi
lCk 5[56d[c8Qs}lfiVccdc6(c5[c56%#d6fi[d(ch
K 5
J565[|V
K fi8(6dd[5ccd[5Jjdu&5[5[g]cc/fi#d}#&68%;5J
]5A5Jd[c[(5J56d8[J[d[[G|g_J[#[J}cd#& zR
[c6Jd6Y fi}
L ; c*56dk[[sc56*Qc=[=5[
~ fic8[6 fi}F
j




fi=SSSAS
AffF }7p@ #SI3HFV*CAffp'
FA A3!FzHzSVjSSxffz=l-A[ cIHzSV
SSxffzC=j7[*FrS !|SzSSS|c!ffzVSHS{lCG! .
=!fflxSSCzp!VSShjC-Scz@
S= J#ff ! JzS_#IplpS!9S!SSxSjrHz ff
! !jxSh!xCh{S |!lxSYx !HSff*FS.ff*Cz
SSxjSx !xCSff#Sffff{Sz S! {HSShxShj
xVIzS{FzzSS [SS ffHz !
SSxjSh@
ff

fi cz[Szffjc=ff-!
zffzFx .S*ffhx#cz
*
1S SSxhxS !ffzVSHS
jC- ]SxJz!
#"$%&(' *
,
$
.
+

/
2
0

1


=

ff






z

=










)
SxS!xSFzxScz!x'Fzj=ffx. !!ffx !=S
SS!H{! xShj;VS=! x !Hj]ff#Cx
3 _HlxSjzhffz ff* 5 4ff JzS_#Iff !=S= Jffcff*!x
!S7 6!'Sj ff#CSJz hVI8 !9
:<; =|, >7?
H@

z], >7?
2AB
z Cx, >7?

!

E DF
HH
G<I9
7h Sff{xS !3J4=ff z@3SS j !C K4=ffz*SL4I!!ffz= MJ!!
!SCzSSSpB N" O" Shx!JVzSxJzSff=!QPRP(P2MPRPS(5PSSPSPJP2SPS!
! -SS THffx9jCB]SxJz N" !SrFzHzShSSx{S!
x !#Sff#| ffHC
SPS(PSSP2KP(P25P(PffJ]H cjlVU . !QWYXZG x C
PSS P
P ( MPSK P[ASx=ffx H3 S'*S PS !! YSx =ffH3 S'\
j! z ffj=SjzffjC- ]SxJz@
] JzShxS=SxSSSc!. 4|JzffzSff!AV'SV!zIS|S=ffx
=Ixff{ SJ 4*Y
^jK 4_4!Hp'F1S `(`Raff
AffF cbBdMegf_hih2fj9klfmj[nNfoqpsrut_b bvxw{7F *@ #']H!3hFVff

Fyz|{
SH !j3.Sxj![3ffff -.ffzffS.ffCzS!c
;
,} x!~Cz@|S`(`J jK`(`S(Q_zS~1 !c1S`R`(aff! JzSS!3J4.HS
STHff7 4!Fz z{SHff*zrSc! jxS, ^C !ff{CF1z@S `(`Rff
JkV-F9okf2nm
CS4HzS SFzSS. !ffSx*ffzzS.S4z {SS1z@j- !SITSz#
=SSC=c {( !x'HC=jSffffSz{zCS ffz z!
S=SxffzH#x AS! Hz H!ffzlHff#YzffzhSSV ]3S#I7IHzS V
SSffzffz=Sj xhff H H@3hVS A!lSI-S !Az'S!S7zC xF
_[ SI|S! 4H !Sj!zSz{SFzSffF*S ]3S#IGz
zSjHSF
ff#ffz= =Ixff3SFzSShS!c jffFz., } x
~xz@AS `(`S!
=Sz CcVS z Flff ff xz!* z 3 ^H |H#x AY
=ShcS
ff!S! 4! pSF. 6xjS!S cc jz cff!S!S 'xS1!z
!8 ffq HJ p{ SSJz Cff U S{3!h
p@SSf2nSkx



fi2292(2_|222u222[2(252g(J

Z#J5l[J5K#5225R[7<(g5|2 J5(SE(525S|Z.(s(
s2.( .5S(J8Z.2!Y<KOE(5 225S5Z.(q|[l(\52\25([.(JF(2[M
5F(F2272YK952\(|x27*N.F[J5SLJ9|2L2.(g[_S[2RE
K(5\(F225E528J9|JM(5lF2[uJ.(|2uJ9K2.FE.F[J5SEMJ52
5J*K9225S5Z.(
Q([Q52.J.2YJF[.\5F.5M5\52\2(.(7 5[N22qS.(8(2
Z[Y52s2.( # K5, K| L [MB25ZR.2(5Z.(2*_M*J J5
J(((2((2R52(252JS2RSJ2(([_uJ52|JM(|F[YJ|![R,
(R2(M(S2(((([_2J( 5Q E [5 M9J5JN52SFJ|F52
([.(2R..(K(|Y2.FN.F[J5SLJ8
(FEx5[FS.(( 2N2|2Q.\S(Z.\5 (F225<52Y5J(5*F2[l
M5.2N.5F52 R[.K.[2|S5Z.( #,V K5, K5 [5 2 5 2((52
R2S.(2|2L7ELS(Z.L5R2522|2Q2J.\J52L5J
N\\.[.K2S
2SFJ|Q5KJ.(EJ85225([.NZ.(J K.((.52 s(N(BNK.JSYF(|Q.F\5
(F22|8.M R2522S(J* lOJ.(\F(5O.[(|J.(FJF(|7*8s(i.M(F22M.(

E(5 25S|Z.(52Z.252 F(2(|(2Y52(5|25S[MJ.(ff
fiRJ
.( ff 5
[2J#5J

ff
ff [
SK5J!#"$&%

2S'(.([ff$ *),+.-H_J[2(|[0/2143u65,785,+9i52
(5,7R2F_.5:9 1 5<;5J<K(52[.M5<(2JF[ />=3 52Q(5Z.(2*_N ' Z
(2JF[.\ /2=3 R(((2JY /4?@3 H(((
fiA
52uJ |JS5J85uKZS*_F />143 (J.C
B 1 [2(5|28J2RJ(JK
1
CDL 225S5Z.(u.5|JSs5(E
1 9ZR2J*[7(.5\s(28JJJ[.SJMJM S|JS
.FA ? <S*SRQJMJM\(2_J.(L.5MKNJY<(V_Z..(.5MKqJ N 8
%:
G

?
22N, fi
%:A ? Kfi
%:A ?
2(5I
H\.F[.SL5J#
KJMLON ff RK5\52N.S(22L(2Jfi
g.F
B 1P
DLJF.(
52E._5S.(K9|lSu.:
1 [5J|.F[.S_6
8L2!
Q8R ff 795\N|2J
2.F7*[J|SLJ
.5Y|SSL5 />143 82(|K.T

Q8R ffU7

#V%:A
1

WF J XZY\[ ]G ZY^

_LZ.2F5[E2(MJ7RYNRS


l

KJ4L`N ff



j


f
c
e
b
/Mgih 143

kH2

J.2F(m||2QJF[.2NK(ZS
Q8R ,M[
Q8R ,SJ
Q8R , [
Q8R ,[
Q8R ,@H2

[| [5
[| [
,V K5,K5 [ | N
[| N
552(

DE(5\552*J5..( J52F2.F\.F[J5SJn 2(QRK,7[S\ZJ5[JSi52
J[.sF(2(|(227*<7*[J|Sq2s( 9 ? 9joLp0R 9 ' L.\F2.FY.F[J5J
qrs

fitnuwvwxwy\zw{

|d}w}~|d84p~Z~|8ffn~i!fij|d4Z&ffP@~U>j8@j|P~|d~UZ}^~@w~<wjUM
4^m6j024KwZ@Zw~8wjU4ZjPfij|d4Zkw@~U>8jnwd@~UZV}j^~<@w~m|dj~nd
@w~PwjU4Zw|djmw~nZwZmZw~P@w~Z@<@~U>jw@!~UZ}^~nmw~@j||ZU@~~U
w~~<Zj~@d|d4Zj4~|Z@@w~8d>4dP4w6@w~@~:
\T0j^^VT^i20n.!^K^]KdT460d:K^.<
Kn\2KUZUfi42dZZK>U0Z>j


|0>

&\K

*


w~Zm~.j~|d|d^MVZwZ@Zw~wjU4Z

0\jU 4Zj~@~6@j|!@w~@~jU4Z&4

nmj|Z8|ww~6#Z@.@~}w@~~|d4Z<|dV~UM.@w~6|0>4~!|dj.@w~<|d@~m~}w@~~|d
4Zj8|d@~<@w~@|~84Fm8|Z~Z 4}>4~@j|d#@w~!}w@M~m~6|04j|nj|dU|Z n 4
@8}j~m|0fi|Z~Z
ZP@w~!@w~4@~U4ZP~8jn}j|dm44Z@w~4w}ww#4^@V@w~~Un8jjU|dj@w~.j~
|}w@wU~w@~Z n 4~@@|dj|dm~~|@~@| @~}w@~~^|4Z w~FjffMw
|04P~@|j|d@~@w~ ~Uw}w@~@4Z@6mw~6~dfi446|0n|Z@4ZwV~^i w
~U@jm|0
}jM<@j|d<C~j|0Z~ m~}w@~~|d4ZjZ@w~wjU4ZjK4ff U|d@w~@j|d
#4}>4~!mj|d~|@]@~@

4@w~~

@~}wm~~^U|d4Zj#8@~}w@~~@~||d]~U4~~84

ff

|j]@w~@~UZ@~@w~m~jU4Z]}d4^wZ|
~6|0:~!Z~dP@w~~UM~V~^*4

ff

Z@~@j|ZjU~Zwww|dP^.4~iwn@2>}d4^w|0k>

<Zw~Uj|d}4~ZdP~Z~@w~24dP4w
ff

8j fip




8j fip0d





8j fip#

-

4>|d4.C~~P

~Uw}w@~@4Zj|dj@w~U4@U|dj|d4Z84@*|@4Zw~







8j fipU


8j fipmw

@@w~

ff







'

wZZ









!wZwZ"





$%

ZZ" &



()*
+,

ZZ

ZZ"



\T0jj

^8\ff>/.10328C^0K^ZOTn0^K&4 0
| >n
2dZZK>U0Z>j *


0\jU

Z TKKn\2KUZUfi4

w~}w@d<4>|d!@mw~}wm^dPdCmw~}w@~Mj@w~Zm~:

w~j|w~@8d>4d

w~Z@~6

5w
Zn@w~<Z@w~4@~U4Z|Z@w~!P~!~*|Z4w}ww!|6~7|dj.|dF|04Z4@w98

@Z

Z #

~PjUfi}j|dm44Z:4^@~'

|ZUZ4w@!M46|24P4@@~}~Ufi@024ff#Z@~P@j|d@w~


~P|dm~nwZn<;ffM>
w~6P~8j~ |04n@@U|djZ@,~|Zm=
4@|! ~Uw}w@~@4ZZ



@w~wjU4Z.
Zn~|Zm:jmF
~U}w@~m4Z]C~mw:@w~<}w@U~wm?
~ 8 @6U}ww@~
4> U
4 @~}w@~~^|4ZA@ Zj|4Z]ff@w~84@~~UMjP4@m~}j~U8@@d@w~~
~Uw}w@~@4Zjn@w~!#Z@~Uw}w@~@ffM:P~w~~\
]@w~!~Uj|d}4~ZP~4}4(|d@nMmFmw~~7
|dj.j~<@w~@|d~<~Zj|dMj|Z|jdZ~


Zd4w4.@w~!Zmw~4@~UM
@ZE@w~!|jdZ~Pmw~Z@~6PP~Z~P@w~24dP4wUZ@d>|d@Z
B

ff

\CDCFEjG
K^ 0

E ^T^i20<n
ZU

|0>
U0Z>j *

Z4H.10328!^K ZUJI@TiFTj4d
TKpK#T>UZiZZ>djZKZK2&U0Z>jKZ14 ZwZ>djZKZ>

K"L"L



fiMONQPQRTSVUQWPQXZYY\[DNQRY,]QRQ^`_'aQ]QPQ]cbdQXPQ[<Y3dQ[Dbfe=Ng^XhiY

jlkQmnm"o!pqsrituvmwxmzyi{}|O|~twqvw*3kqD 1m"x\qDtu,xt! mktmmwy m3r!m"m{y3mfqvw
3kQm}Qti&tt m}y:tqvwH%mqvZ!q~tiwQwquFtgVQqsriti3m}xy}pQwqDxti qvyww{t!x)3kqD%usm"p3y3kQm
3m" puv&fyi{3kqDnm"x qvyw

)mwZ qvywQm"tiyirmtqvquFt\m" puv{y\muFt qvywtu?Qti&tt m"qF

3m1y33m"H*qv3m:tw7y!3 uvy&"Q%kQm3m3kQmn\m" 3 qDx qvywqFxtuusm"3kQm~{y3{y
{pQwx qvywtum1mwmwx\qsmi
AF
"icJ"<i"F

:jkQm1yiuvZwQyqFtulm"o!pqvrtuvmwxm3y3kQm}Q\yuvmjO)1qv}uqvm"3kQm

mqF3mwxmyi{7 pQQmQywQmw qDtu71>>\)tuvy! qv3kQ{y\kQm" m}Q3yuvm:OkqDx\k:tnktrm:y}m
Q&txqFxtuOqv}uqFxt qvywOyimrm"t\kQm{yiuuvyiqvwQzmti}uvm kQyi7ywQmnxtwQwQy:tiQuvTqs3y
yiuvrm3kQm'mwQm&tuxt myi{\kQmAQ3yuvmOqvmw 3mqvwtiwqv3&"!QQ3m" mwA y}m{pQwx qvyw
qv3kqvw3m3m" qswQQ3y1m3 qvm":jlkQm" m{pQwx qvywxtiwm:tiwqvQpuDti3m"T3ynx3m"ti3mmti}uvm"qv3k
3kQm,{yiuuvyiqvwQnQ3y!m3 qvm"ilkt7t kQy\%y3wmcQ3m"\qvyw

c!!qD :tuu
3kQm

wpQ?1m7y{Oy!3w`Q qv}m,qsuqDxti\m"3qDmc1ywQmw qDtu

wti3qFxpuDti

'

1'n""J

kt\kQm" mAQ3y!m3 qvm"jkQm

g)







n""Jng



yi{QQ qv}mqsuqDxti\m"qswx\uvpm7tuuQ3kQmA!qD< pQwx qvyw'"

OkQm3m Q
"Z
TmkQyxt! m:tiwtuvQqD)3kt)3kQm} m)yi{lx\kti&t!x3m qD qDx}yQmuD,qF):tuu
m3r!m}3kti
qvwnymO3y:3t qD{V1tiuvm"t Oy!wQmyi{V\kQm?Qrt qDtiuvm"Op O1m?t\qvwQm"nQQtiw\ktiq{Q
3kQmw"p 7tuD ym?t!3qvwQm"ng
|'ywqDm& \kQm: mqsw








=%y qDxm3kti,q{3{y!? ym

V









tiw`tuu3kQm

y3kQmriti qDtiuvm":t3m=m?\y`\kQmw*HqD}3tiqFm"`jkqD}xyw3 qvQpQ3m"mtx uv
3yqvw



&




gy

tiwrtiqFtusmy&m qvwQn








ff

t\qvwQ}mw&

3kqD,qvmuDQ)3kQm}t\qvwQ}mw&

QQ1"Q"gQ"Q

fi

|'ywqDmwQmcqvw
q{Q

&ti}muv\kQm:tqFmuvm}mwqsw%kqFx\k*Q,

Qj

yz3tiqF{z

f3kQmw"p mQVtiwHt,m{y3m}mxtiw` mtuuy3kQmrtiqFtusm"3y`{%g

3kQmwz\kQm3m}p )mtiwQy3kQmrti qDtiuvm

fi

jkQm3m{y3m)qsw

3



qvw

fi

uvxywqFmqvw






OkqDx3kqD m3yng
wz3kqDxt m}





p tuD ymQ

&

&'7timus3kQmtqDmuvm}mwOqvwOkqDx3kVQO m3r!m)3kti7



qD7twZ qv}y!wQy3ywQm%qvw37timus1iqvrmwntiw3ti qD{qvwQt3qvwQmwZOlqs\kn"

!QZ

QqvQqvwQn"

3y}mm)tiwQy3kQm)3tiqF{!qvwQnt3qvwQ}mw"OkqDx\kqD) :tuuvm)3ktiw3kQmyqsqswtutxxy!&!qvwQn3y

fi

AjlkQm3m{y!3mQm):t:t3pQ}m)3kti7Q{Q3kQmwnmxtiwn mtuuy\kQmOrtiqFtusm"

3yn!{gV





)3kQmwn\kQm3mp O1m?tiwQy!3kQmOrt qDtiuvm





7gAjkqDOt3qs!wQ}mwZlqFqv&7tOt{3y!

"

qvw3kqDxt m3yZy1


wy!pQAmti}uvm)qv3k

QQtiwzQ"Q



%uv3ym\kQm7m!m
}mw&'{3y



$#

ff021 340

:1c

<

Q"F

% &('

)

+*

,

gqDwQy7p

=x\qvmwZ%{y!7 yiuvr!qswQ

kquvmmxywxmwZ\&ti3m%qvw:3kqDtmywOy\w:mQQ3m"3qvywJZmwQy3m3kti

65

3kQm3ti}mti\pQ}mw&tiwQ3yyi{
kQyiuDqvw3kQm}y!3m)mwQm&tuxt m)yi{

7

jkQm" mzti\mnmQQ3m"3qvywqvw

|

{y3


opt!q%y3wnmQQ3m"3qsy!w

&= 6? @'A5

mqvkZJ

*

85
"9!:<;
C*EDGH F ;

OkQm3mqvwmrm3x\uDtip m3kQm3mti3mt:}y

uqv3m&tuD yH3ktiOy\w*mQQ3m"3qvywti\m`
o!ptq%y3wmcQ\m"3qvyw&
Qi

t\qvwQ}mw&

Qm%m3kQm7t3qs!wQ}mwZ7Q"Q!

\kQm)& y}3ypQtiw

iwQmt!3qvwQ

AjkqD%}m"tiw\kti7ti3qv3ti3mwZpQ}mti qvyw

\kQmuFt! 7tiwf3kQm3m{y3m:1Z!

yi{3kQm)Q qv}m,qsuqDxti\m"Q{y7tiqvrmw m%yi{V}yQmuD

-/.

!

twqs%qDqvwqv:tu
zm)m

6Qtiw:\t"

t3qvwQ}mw&l{\y

7OkqDx\kqD7m73y}Q1tiw3kQm\m{y\mtuD

B5

17qDttqD'{y

jkQmz


o!ptqV%y3w}mQQ3m"3qsy!wtiw

IKJKL

yZqsqsr!m

>=





xtiwn m3rmt

fiM!N

P
QER

TU
VWXVYT[Z]\<^U2_]`a_4^aTVY`XbcWXTXbc^7d$Z
eVafcWg\hZ4`!ikjXl7U2_]`meZ4n"oqp[Z4TUGrEsKtut]v
wmx<y[U
V7z4VYn
VY`m_fffb{YVKeA|4VY`mWbZ4n2WgZ]\
}!}B~ _]n2e%4X@r
!U
VYnA`VKWXT`Xbc^aTVKeCTZ$U
Z]fce_ffff
`bdVbd$fbc^Y_]TVKW_]`VWTXbf fVK4b|>_>fVYnTTZ7y!px
(G
K
KE]h8ffcE2K
Wd$VYnTXbZ4n
VKe_]2Z]|4V4rz]b|4VYn_A+`VY
`VKWXVYnTa_]TXbZ4n\Z4`i[V^Y_nVK_4W&b f^aZud$

TV$TU
VCWXVYTZ]\
^U2_]`m_4^aTVY`bWTXbc^d$Z
eVafcWYx!!n
Vd@bz4UT+TU
VY`Va\Z4`VT`CTZ$WXZ]f|4V }}B~ 2`mWXT!T`m_]n2Wfc_]TXbn
zCTU
VZ4`n
Va

`VKWWbZ4nAbnTZ8_C+Va

`VKWW&bZun_n2e"TU
VYn%^aZ4d$

TXbn
z"TU
V@^U2_]`a_4^aTVY`XbcWXTXbc^d$ZeVafcW\h`Z4dTUbcW
WXVYTKx n
Z4TU
VY`!ZWWbfV`Vaf_>_]TbZun$bcW[TZ2`mWXT!^aZ4d$

TV_ffffTU
V+
`Xbd$V7bd$fbc^Y_]nTmWZ]\TU
V\
n2^aTbZun
_]n2eTU
VYnCTZVa
T`m_4^aT[_7%`VY
`VKWVYnTm_TXbZ4n$\h`Z4dbTKxkV^aZun2WbceVY`BTUbW
`Z4fVYd(U
VY`V4x67_]d$Vaf4r
[V^aZun2WbceVY`!TU
V
`Z4fVYdZ\VYn
dVY`m_]TXbn
z"44TU
V
`Xbd$V7bd$fbc^Y_]nTmWZ]\_@!Zu`nVa

`VKWW&bZunGr2_]n2e
bTmW!_]
fbc^Y_]TXbZ4nA\hZ4`!TU
VWZ]f
TXbZ4nZ]\ }!}B~ x
UbfVk[V%U2_K|uVn
ZuTC\Z4
n2e_z4VYn
VY`m_fff`VKe2^aTXbZ4n\h`Z4dTUbW
`Z4fVYdTZ7y!pr7_Wbd$fV
_4e
_]
TbZunZ]\7TU
V8_>fzuZ4`XbTU
d\hZ4`$7y!pj&
`VKedC_]nol7U2_4^Ub_]nGr!sKtut]v
w!ubVafce
WC_]nbn2^a`VYd$VYnTa_fff
<X] _>fzuZ4`XbTU
d\Z4`TUbcW!
`ZufVYdAx+Z>[VY|4VY`ffr2_4W[[VeubcW^a2WW72VafZ]r2VYn
d$VY`m_TXbZ4n%Z]\
`bdV
bd$fbc^Y_]nTaW7Z]\B_$Z4`nVa

`VKWW&bZun"bcW7n
Z4T+WX"^bVYnT\Z4`WXZ]f|ubn
z }!}[~ xy[U
V
`ZufVYdbnkWX2^U%_]n
_]
fbc^Y_]TXbZ4nAbcW+_n"VaZ4n
VYnTb_>fz_]CbnTU
VWb{YVKWZ]\TU
VKWXV`VY
`VKWXVYnTm_]TbZun2WYx
Z4`^aZ4d$fVYTVYn
VKWWBV$WXuVYTm^UATU
V@d_ffbn%bceVK_4W7Z]\[TU
V@VYn
dVY`m_]TXbZ4nk_fffz4Z4`bTU
dU
VY`V4xEVYT@
2V@_$Z4`n"Va

`VKWWbZ4nGrE_]n2efVYT2VTU
V7Va
`VKWWbZ4nk^aZ4d$2ZWXVKeCZ]\<TU
V
`Xbd$Vbd$fbc^Y_]nTmW
VYn
d$VY`m_]TVKeWXZ\_]`ffx8yU
V_fffz4Z4`XbTU
d/2n2e
W@_]n_uWWbz4n
d$VYnT$k!Ubc^UW_]TXbcW2VKW@_]n2eeZVKWn
Z4T
W_]TbW&\kAx7Wbn
zbTbcWVK_uWX%TZC2n2e_Cn
VY
`Xbd$Vbdf bc^Y_]nT$Z]\!xy[U
V_>fzuZ4`XbTU
dTZC2n2e
2WVKW@TU
V\Z]ffZ][bn
z^aZudbn2_]TZ4`Xbc_fff[\_u^aTjX
`VKed_nol7U2_4^Ub_]nGrsKtut]v
wm@VabTU
VY`$TU
VY`VCbcW$_
|>_`Xbc_]fV
!TU2_T_
2VK_]`mWbn [bTUUbz4U\h`VKu
VYn2^a4r6Zu`TU
VCVa
`VKWWbZ4n U2_4W"Y_
fZ4TmZ]\6W_]TXbcW\hubn
zC_4WWbz4n
d$VYnTmWYxn"TU
V72`mWXT+^Y_uWXV4rZ4n
V^Y_]n"`VK^a
`mW&b|uVafWZ]f|4V+TX[Z$WX

h
`Z4fVYdW
_]``b|uVKe_TWX
2WTXbT
TXbn
z ) r4_n2e G sgbn@TU
V[Va

`VKWWbZ4n2Wg_]n2e@xn$TU
VWVK^aZ4n2e@^Y_4WXV
bT7bcW7VK_4WX"TZ2n2e%_]n_4WWbz4n
d$VYnTjV4xz2x[W_]df bn
z
waxyU
VWZ]f
TXbZ4n%Z]\6TU
V`VK^a
`mWbZ4n%4bVafce
W
TU
V@WXTm_]TVKeCTbdV2Z4
n2eEx!Z4`+^aZ4d$fVYTV@eVYTm_ffbfcW7[V`Va\VY`7TU
V`VK_ueVY`+TZTU
V_]`TXbc^fV@"
`VKed_]n
_]n2eAl7U2_4^Ub_nkjmsKtut]v
wmxUbfV@TU
V@_]n2_fff
WbcW!TU
VY`VbcW+W2VK^bc_fffb{YVKeA\Zu`!d$Z4n
Z4TZ4n
V7\
n2^aTbZun2WbTbW
VK_4WXCTZ$Va
TVYn2eAjTU
V72`mWXT!2_]`T!Z]\KwbT[\hZ4`+Z4`n"Va

`VKWWbZ4n2WX4x
KE]EK]c]KG< 7VYn
Z4TV[$7
]jXiGwGTU
V!n
d@VY`<Z]\
`Xbd$Vbdf bc^Y_]nTmWgZ]\GixUbfV
TU
V$`VY
`VKWXVYnTm_]TXbZ4n2Wjms]w+<`bdVd$fb^Y_nTmWj&&Wawar<j&w+7`VY
`VKWXVYnTa_]TXbZ4nGr_n2ej&w } U2_`m_4^a
TVY`XbcWXTb^d$Z
eVafcWYr<W_]TXbcW\h%TU
V@bn
VK42_>f bTXbVKW7
]j&iw
j&iw ff
4jXiGwY fi rEVK_4^UkZ]\!TU
V
bn
VK42_>f bTXbVKWd_ff_ffffZ>\hZ4`!_]nVa
2Z4n
VYnTXbc_fffz_]Gx6y[U
V7\h
n2^aTXbZ4n
j ff w
ff"j ! w
j&l7U2_]`aeZ4no p[ZuTUGrGsKt4tv
wWXU
Z]+W_@z_]"VYT&[VYVYn%j&w_n2e%j&waxyU
V7\
n2^aTXbZ4n
& "# $% $%& " $ "
j b{YVYn2WXTVabnobTTKrgsKt4t 'w!WXU
Z]+W_z_]%2VYTX[VYVYnjms]w+_n2ej&wmxj&yZ"Z42WXVY`|uVTU2_]TKrGn
ZuTXbc^aV$TU
V
Wbd@bfc_]`XbTXVYTXBVYVYni _n2ekTU
V"e2_fff[Z]\+TU
V\
n2^aTbZunk\h`Z4d/TU
V
`VY|4bZ42W$W

WXVK^aTXbZ4nGx)
w (gZ4TU
\h
n2^aTXbZ4n2W_]`V!Zu`n jh\Zu`i dfTXbfubn
zZ4
T"[VWXVYVkTU2_TVY|4VY` ^fc_]2WVk\hZ4`i bWA!Zu`nGr

* +-,./%021234/517686:9156;</=91234/%6:>?6@150BADCE/%FEG8/H.IJ!/HK@176LFE.MONKLFEJ!/FEJPNCQFE0515.6:G?12RS6:/HKUTVFEGU1HCEK:/517WXY/[ZIFE3412CE/[.6%6:>]\Y+
^ 9FEG_0217.a`/W>D./UI GLFE.Mcbd0[>D.G:/H. G:IG:e?>DN/[K@176LFE>D.GHf;g9FE0@9a0217.aM4/H./HK@176:/=1HCQCff6:9/NKLFEJ!/FEJ!NCQFE0515.6:G!hji_FEkH/H.G:6:/BFE.
lnm FE6:6Hfffo5p4pDq4r
stu

fiv?wxy{z8|}x~D7wy y%xff~xL5w ~
j5j4Y?5D57Bja5] 5 HP2O7 4D7HHHYffD
HD ffjc27 ]ff4Hjn=HjSffff4Y SD7Sff?:
5ff 7j5c5 4D5HH2affDaHa: DHj
8&@ )g=B
5ff?HDHj!cH5 ?7D55ffj?ff5aYj?HPP H
]D@]H=ffj5= 5cffD ffjHj=!Oa
Sa=Uj25
P5!]VV H]7Bjff4
?5U!P ffj= : [4
j 74ffg5 DHPP V!Oc7 O5HYO5ffj5V5
j 7j ffffj5HBjn5Bjff4] ffY ffj5:S!j5ff DHj{:O]
?ffjO5]DffSDffjHUP !HHg g[S5Hffj%S5]4 Haff j U
4S]5Hj jjDffD
< ff
fi !#"$%'&)(+*,-.0/21435/*5%6"$7809
: ;<= 5ffj 7Hj jnjD@] B5#5Bjff?
># #5
@ B+ >DC
E=: H54
F
Hj4! Dff5?!O5ff DD@5H GH 5!Oa 5. GH 5 5
IKJ Hgg
Lff?7c5ffj =5HB-ffjH!Pa{7ffPS?ff5j&57 2
@
G j54 DS7& c5j54 5 BjHj@! c7Hn7 H5
?5j54 75 @!]H 7 7 HHj:54n NQ
P RTS
j H4 D?5O GH ?5U P ff5cD0 V[ D2S?57 H

]D0 V[ D2S&ffHj:5c7 HX W{c54 B5aj]75Oj HD Dc=!Oa

[
Z]
\_^a`0b c5dMe2f<^7 P 4)_j4H!&7 j 5 7&7ff DHj Sff @ 55
Bj P O5!]! P aV:5ffjnff7n =5cHffjc5c5<
n57D7 ?Hj55VcV2S:5Pa :5ff ffajffj7 P
5g!!a !j=j ]75Hff4Hjg=55!DHjO Z%Hj5 ]
5524Hj P SD]B- g ffffh fjiUHj?7O 7 2!jk
P
W{c 7 j 5 +
NO52[-ffjc? ffj]m
l : h Z4?O5HY 42]5 H N
O5HB-ffS j. >nCoS[RpP ffajffjO5 H >nCn q
>rCl P Yj P c5g
7ffDY]?7 D2S 57jH{ ffYSff542DHj 5 ]!Y5
>nC
l : P 4 Bj Ds
ZTt P >nCl :h Z4 7D7u
l:h ZD
?57 j5DHjn7Hm
l): h Z4< j. > n7Bjff H 75
>vC# q
>[C#
l : h Z4+
W{O5 + >rCvSc Bj Dff 5 5x
w
P :h ZU!O .
>qCl P ! >yCzS[ROP z
N]5HB-ffj
Dff:5c O5ff DHjD Bffa5a D2S
N) {4| }~| 5 }~|
| 5 {4| |p5h {4|O}|
ff: DHj!-P74 B5jff5c {| }| 5 }| | 4 % D2S P { | { }
7HB:jn5Bj4 P 5 4 5 - n
Z # { P
4
Bff57Bjffs >V ?ff7 5HB N8Uj2S~ >V5HB Vg {
757 %S!!j57jH7O Z


fi <

~UO 2a 5
6? a-X0j0# XjX0 X.;-# -# # -8~ )0?
-O0 -q0 .5 hXO-06 . #-q ?? -; #6-.#0
5 s0j+# #0 -# 6-k 0 + #O #. #U;.0-
a-r00;) 00#M0 -n # #XO#0v0a0?o0
8# X##U # #0 -5s#0h0 )# 0?X _aO0#
X+;. -M .? 0;?--hM + -#O#
6O;-z60X . X0a0M -#Ov0 0-#+
. #X2 #_0- ; -00 #s050;-#
a- -#X)?-)0a0 - v-,- #k- -YU-;-#q-
# #X40-#O #~? ~ 4 #~00# X? 8540-#O6 a-
n;4; . 0O+- 60 -U# X##? ~ -#O0 6#0 ?0 #
;5 -#4+_H.M0a0 -q #q+0TMU0q0 $#0 --
? #.-#p0kn0 0.M)<T 6k04-T# #;6v0h
040- ~0j54+00-O. ;_# +Xo 0j),0-0;-#
ns --T0?-r 00.a-?-p - O68+# ?#0 - -?j
$#0)#0 0#4p-#H M8+v 0Ma-$0 -# ?#0 - ? -?j
$#0O;A MTp-#M8qh4 -4XT -# )-
? $#0 -z y24~ 5j#X .?-- M-#0U0~ + -#O
y#y-k- U
?O) U - #n-r#?#0rM ;- nx #--
0 5 #;a- + X-#4# X##.4O 40 -~0# ?
4#U-TU?0-0#h4z#+;2-60X## 4 020M
a- -O0+ + -6sM?.#a--
+j- M05 0U0X04D-8)X#M -#O~,-?4
j 8 # ; - z + -#O5-) $$~s2)2)0<
~5z25
0ffOX U-#;6-q0 $0+0kM8 .??#X

-nz ?j0 ? --v.#U4X oz0 q U0 ?+8##+6
?j# --? 0X 5 #0 - 06-- 54#0_~ -- 08
- +0#X + 0U8X#X y5##X8X2$-#5
#OX #4+ 6)+ 020 )2
5
6##- .-

-< 4-00$$- z05h O;<88#
0


fiff ff

4 0- - -#o!D-~; <- s0 -~6?0 #"# ff
$ %ff& fi'
0
()#*+(
## 24-540)<5v-~0- +- 0U0 5+. ( r z U0)4O
0 -8X8 -;###-#/01 2305476& fi8:9;k<fi0fi(*
,

=>?

fi@BACDFE3GHCIfiJJLKAD%JNMDOQPSRMCMUTVICK&JWVKTYXZA[O%I\ J

]_^a`UbLcdfe[gad;hjilk%m nm o.^pdfqg_rstt.uvg"w-`.xzy{a|}fi^a~Q`+B^|#fi~^'b#m ~5^`.m %%m{^am ~^a``+y%`fi^~5^.|
]-`` {a|m "%b~^a`%#gzq|bLcgnW|#ygad;nmx:%B^a|#nl^a~d`~W~L|#nm xg:q`m+yy%|m nN^Fip`nW
xm ~^a`m %wS`xzy~m ~5^`.g
]c`~dfigfigrst.tuvg%}[m.b~{|m+nW^a.^m~Wc|xz``~W`.|B~Wc|#`nWgipYf&fi+f&fiWS-
' $

fi&"z-





%dyygu!Uuss;m{a`zB{a~W`dw-:g

|bLcfi~W|#ndUNgad%h|m+n{pd%egrsttvg_~WnW%b~WnL|^|#fi~5^'b#m+~^a`^nW|{m ~^a`%m{;m ~mg-N f
%d d%uU#U![g
` {^a%d%ggad%hm!{{^a|#ndeggrst vgB'^|m+nW~^axz|zm{a`n^a~Wcx`nB~L|~^aWm ~^l'm+k^{^a~`
ynW`y%`l^a~^a`%m{`nW`nWx:{m |g. :

dd%.#U+%g

^a~W|#nd'qgdUh`~L~{a`kdg$rstts+vgi|#~^.^a~Wc|7x:^a^axm{;~Wnm+%|#nWm!{` fm:cfiy|#nWnm yc"m %
nW|{m ~W|ynW`k{a|#x#gq|bLcgnW|#ygwfpqpts fisdw-cn^~^m `.yy{|#nBm+k%`nm+~W`nW`nf}Uy|#nW~
U~L|#x#dqBB^a|#%md%5~Wn^mg
^a~W|#nd'qgdUh`~L~{a`kdg$rstt [vgi|#~^.^a~Wc|7x:^a^axm{;~Wnm+%|#nWm!{` fm:cfiy|#nWnm yc"m %
nW|{m ~W|ynW`k{a|#x
gz%z 7&



&

-

g

nL|xm dgadShc%m.bWc^afim d;grst.t vgB~Lc|b`xzy{a|}^a~` %m!{^am ~5^`.` x``~W`|
.^%b~^a|`nWxm!{%`nWx#gq|bLcgnW|#yg%wpqBp[dU|#y%m+nW~Wxz|#~-` Sw-`xzy~W|#nfibL^a|#%b|d
~W|#nB^a|#n^~g
m+nW|#dQgdUhe+`c%`d%:grst!tvg-
S-

L7%.fi
& +

B:&fi



%
#ggg%nW|#|#xm dfim [nm %bL^Wb`%g

`.~W~{a`kd:gadh'^ko.^ad'_grstt.vgip|~^afim ~5^`.%`nWx~WnW`nW|{m ~^a`%#d|#y%|#%|#%b^a|#nL
|#%b|d%m %|}%bL{a%|Y%b~^a`%m!{|#y%|#%|#%bL^a|#g

L%drp[vd%u!fifig

`nWdSgSrst.s vgB|#fi~L|#%b|zBc^bLcm nL|~WnW|`.^anW|b~z^a`%` 7m{a|#knm
gB
'

W&.drs vds# U[sg

~Wd7gd|m nW%
dgadBh|{axm d]grsttUvg`nWm yynW`}fi^axm+~^a`%` 7|#xzy^an^b#m{zm ~mg
f.%%&.dWds.t's#fi[g
mfi m.^m#d:gad;m y%m.^ax:^a~Wn^a`dwgadh ^|#n^pd'grsttuvg$BZ`nW|#fi.|{`.y%|m %cfiy%|#nW.nm yc
~Wnm %.|#nWm{#gil%&%.

! &

"&&

.%S

B

fi.



:Sd

yyg%uttfig[yn^a|#nW;|#n{m %gwfN g



c%m n`.d-gad-"m ^{md-gad-h`~Lcd-:g;rsttvg|m`^a^~Lc|}[m xy{| ;nL`y%`fi^~5^`.%m{
`nLx{m |m %m ~m k%m.||#y|#%|#%bL^a|#gBq|bLcgnW|#ygqBWs+ptdB^ao|#"wS`xzy~m ~5^`.Zm+kgad
nL!m n^a|#nl^a~g
c%m n`.d3gadh

`.~Wcd:grstt+vg|m`.^^a~Wcxz`|{#gip 7z&fi.%

:qBps
pt

-##%. f.&.%dyyg;ss#'ss.ug7{{|#nl^a`

%d^o.|#

w-`xzy~m+~^a`Zm kgad%m nW n^.|#nl^a~d'em+fi%m nLst.t %g
c%m n`.dfgdh

`~Wcd:g-rsttvg|pm {a~WnW|m5`^aQ^a~Wcx`U|{#gip&fi z&

%.%B-.##N f$%d yyg%ust!Uug



fi
fiff

!#"%$&')(*$,+-.0/21 1&34057668:92;'=<>$&?:='@A8:,BCD9&@@AE,BC?F9 ,$2(HG'6,,G',BIJ7@A8:9 <
8:C(*$&?F9 ,JLK,MONCP PQ0N RDSUTVKXWYQ0MZR[Q2\AS*]CN ^H_`M aPcbY\AQ2RDdc]2S*Q2T,]CQ75e68IC(f<D,$&8Igh 80Ji9 %9&@j?:k
6,$&6,8l$m66,$&8:Gnpo:qjrts#/1 1 u
"%$&')(*$fi+vwyxfi$2k,$fiDwfi.0/21 z {'40|r7Ji} ~'g|C;$&<6'(= 57$&66'()B$m?F9 9&@578:<J?:8:9 }
8:C(*$&?F9 ,JjM b'R0TN ^MF>_wM aPcb'\AQR-N T,dc2\AQad]SUQT,]CQ X.[u'40X/u {2c/3,/
"%B2q$&8:?IkYg &Z.0/1 z!40 H8:9Z} 80$&<Jj?:kBC9 <<9 J,JF 'o>RFM]CQCQ0 SUTYmwMFfi\UWYQjdaPM&SUb'a#M T\UW'Q
QC]WYN TSN \ASUM T>MFKWYMZbmWY\RFM]CQCQH9&(,/ Z66 !z&3,&l$m?F9 ,$2(cHk'gJi*B$2($m~,9 80$m?:9 8:g
xj68FY?IGDO"O,JF'gfJ`.G)4`dcQaDN T\AS*]0TM RCaDN \ASUM T>RFM]CQCS*T' "o[sH8:JIJC.0/1 {Zz'4023Y 2
3Y 1'5(J9>=hxt`80$ BIk<$&p$&,G+v JI E xj$ZGZ=}'J=h79&j(G'} xj68:JY?0$m?F9
/1 z
"%B2q$&8:?IkYg H`+7$2g Jw`.0/1 {Z1'40| 9 <>6k')(9YJF9 6k'*B$2(v68:9Z~'(=<>J-@8I9 <?:knJ?0$&,G'6,9m='?9&@
$&8:?F)cBI*$2(fi'?:C()(f} ,BC o"C(?:8j7Hy"BIk' firD`.[wGJ=40`N ]WYS*TQO0T\AQ^U^)SfZQT,]CQD
wGZY~E8I} k' 80Ji?FgpH8:JIJ
"%B,JFg fijql`ql.0/1&3Y!40hsjkpG'BI*Ji9 68:9 ~'(<@9 8JF9Z<nBI(*$ JIJFJ9m@JF'?:,BCJ=?Ik9 E?
E,$&'?F),8jM b'R0TN ^MF-dc&a:MZ^fSU]tMC SU].F'40{/C,&{
xjC?:8xt.C/1 z' 4C5?:k9 8:g9m@GZ*$&} 9'Ji*Jj@A8:9 <,80JF?68F,BI=6'(JfiR0\AS ]2S*N ^0T,\AQ2^*^)S) QT]0Q2 X.0/&40
xjC?:8fixwyr7p(8fi.0/1 z! 40h9ZE,G$&?F9 ,J9&@$ZJ:JFE<6?F9 A~,$ZJFG|?:8:E?:k<>$2Y?:,$m,BC
JFg!J?:<Jo#jR[M2]0QCQC S*T'&OMF\UW'QhtN \ASUM T,N ^-_wM TQ2RFQT,]CQpMZTtRC\AS j]SUN ^j0T\AQ^U^fS) Q2T,]CQ`66
/z 2c/2z z
C(<$&H7t$&E?: +-H.C/1 1/&4C79&j(G'} OBC9 <6')(*$&?F9 |E,Ji}h+fi9 8I$m668:92;Y<$&?=9Z,Joi
RFM]CQ0QC SUTYmM\UWYQ-tN \AS*MZT,N ^H_`M TQRFQT]0Q-M TOtRC\AS j]SUN ^0T,\AQ2^*^)S) QT]0Q2&66,1 &3m!1 1
C(<$&'l J:ZE +vZ.0/1Z1 '40&57~cG'E,BC?F fi$&,GDG'C@$&E'(?H8:$ JF9Z'=}5BC9 <6E?C$&?F9 ,$2(!BC9Z8:
o%RFM2]0QCQ0ZS*T'&lMFD\UWYQ-NZ\AS*M TN ^H_wMZTQRFQT]0QtM TOtRC\AS ]SUN ^CT,\AQ^U^)SfZQT]0Q2&66,&3Y2&3Yz



fiJournal Artificial Intelligence Research 3 (1995) 431-465

Submitted 9/95; published 12/95

OPUS: Efficient Admissible Algorithm
Unordered Search
Geoffrey I. Webb

webb@deakin.edu.au

Deakin University, School Computing Mathematics
Geelong, Vic, 3217, Australia.

Abstract
OPUS branch bound search algorithm enables efficient admissible search
spaces order search operator application significant.
algorithms search efficiency demonstrated respect large machine learning
search spaces. use admissible search potential value machine learning
community means exact learning biases employed complex learning
tasks precisely specified manipulated. OPUS also potential application
areas artificial intelligence, notably, truth maintenance.

1. Introduction
Many artificial intelligence problems involve search. Consequently, development
appropriate search algorithms central advancement field. Due complexity search spaces involved, heuristic search often employed. However, heuristic
algorithms cannot guarantee find targets seek. contrast, admissible search algorithm one guaranteed uncover nominated target,
exists (Nilsson, 1971). greater utility usually obtained significant computational
cost.
paper describes OPUS (Optimized Pruning Unordered Search) family
search algorithms. algorithms provide efficient admissible search search spaces
order application search operators significant. search efficiency
achieved use branch bound techniques employ domain specific pruning
rules provide tightly focused traversal search space.
algorithms wide applicability, within beyond scope
artificial intelligence, paper focuses application classification learning.
particular significance, demonstrated algorithms efficiently process many
common classification learning problems. contrasts seemingly widespread
assumption sizes search spaces involved machine learning require use
heuristic search.
use admissible search potential value machine learning enables better
experimental evaluation alternative learning biases. Search used machine learning
attempt uncover classifiers satisfy learning bias. heuristic search
used difficult determine whether search technique introduces additional implicit
biases cannot properly identified. implicit biases may confound experimental
results. contrast, admissible search employed experimenter assured
c
1995
AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiWebb

search technique introducing confounding unidentified implicit biases
experimental situation.
use OPUS admissible search already led developments machine
learning may otherwise possible. particular, Webb (1993) compared
classifiers developed true optimization Laplace accuracy estimate obtained heuristic search sought failed optimize measure. general,
latter proved higher predictive accuracy former. surprising result,
could obtained without use admissible search, led Quinlan
Cameron-Jones (1995) develop theory oversearching.
paper offers two distinct contributions fields computing, artificial intelligence machine learning. First, offers new efficient admissible search algorithm
unordered search. Second, demonstrates admissible search possible range
machine learning tasks previously thought susceptible efficient exploration
non-admissible heuristic search.

2. Unordered Search Spaces
search problems, order operators applied significant.
example, attempting stack blocks matters whether red block placed
blue block blue block placed green. attempting navigate
point point B, possible move point C point B moving
point C. However, search problems, order operators applied
significant. example, searching space logical expressions, effect
conjoining expression expression B conjoining result expression
C identical result obtained conjoining C followed B. sequences
operations result expressions equivalent meaning. general, search space
unordered sequence operator applications state S, states
reached permutation identical. type search problem,
search unordered search spaces, subject investigation.
Special cases search unordered search spaces provided subset
selection (Narendra & Fukunaga, 1977) minimum test-set (Moret & Shapiro, 1985)
search problems. Subset selection involves selection subset objects maximizes
evaluation criterion. minimum test-set problem involves selection set
tests maximizes evaluation criterion. search problems encountered many
domains including machine learning, truth maintenance pattern recognition. Rymon
(1992) demonstrated Reiters (1987) de Kleer, Mackworth, Reiters (1990)
approaches diagnosis recast subset selection problems.
OPUS algorithms traverse search space using search tree. root
search tree initial state. Branches denote application search operators
nodes lead denote states result application operators.
Different variants OPUS suited optimization search satisficing search.
optimization search, goal state optimal solution. satisficing search, goal
state acceptable solution. possible search space may include multiple goal
states.
432

fiAn Efficient Admissible Algorithm Unordered Search

OPUS algorithms take advantage properties unordered search spaces
optimize effect pruning search tree may occur. particular,
expanding node n search tree, OPUS algorithms seek identify search operators
excluded consideration search tree descending n without
excluding sole goal node search tree. OPUS algorithms differ
previous admissible search algorithms employed machine learning (Clearwater & Provost,
1990; Murphy & Pazzani, 1994; Rymon, 1992; Segal & Etzioni, 1994; Webb, 1990)
operators identified, removed consideration branches
search tree descend current node. contrast, algorithms
remove single branch time without altering operators considered sibling
branches, thereby pruning fewer nodes search space.
possible apply operator path search
space, search unordered operators considered subset selection problem
select subset operators whose application (in order) leads goal state. single
operator may applied multiple times single path search space, search
unordered operators considered sub-multiset selection problemselect
multiset operators whose application leads desired result.
search tree traverses unordered search space multiple applications
single operator allowed may envisioned Figure 1. example includes
four search operators, named a, b, c d. node search tree labeled
set operators reached. Thus, initial state labeled empty
set. depth one sets containing single operator, depth two sets containing
two operators on, depth four. two nodes identical labels represent
equivalent states.
considerable duplication nodes search tree (the label {a, b, c, d} occurs
24 times). Figure 1 (and following figures), number unique nodes listed
depth search tree. number derived number
combinations considered, derivation also indicated.
common search prune regions search tree basis investigations determine goal state cannot lie within regions. Figure 2 shows
search tree sub-tree {c} pruned. Note that, due duplication inherent
search tree, number unique nodes remaining tree identical
unpruned tree. However, deemed node descending {c}
may goal, nodes elsewhere search tree identical labels (are
reached via identical sets operator applications) nodes occur pruned
region tree could also pruned. Figure 3 shows search tree remaining
nodes {c} duplicates deleted. seen number
unique nodes remaining search tree (the tree depths 2, 3 4) pruned
half. Similar results obtained case multiple applications
single operator allowed nodes consequently labeled multisets.
OPUS algorithms provide pruning rulesmechanisms identifying sections
search tree may pruned. Rather, take pruning rules input seek
optimize effect pruning action results application rules.
OPUS algorithms designed use admissible pruning rules.
used solely admissible pruning rules algorithms admissible. is,
433

fiWebb

{ a, b }

{a}

{ a, c }

{ a, }

{ a, b }

{b}

{ b, c }

{ b,d }

{ a, b, c }

{ a, b, c, }

{ a, b, }

{ a, b, c, }

{ a, b, c }

{ a, b, c, }

{ a, c, }

{ a, b, c, }

{ a, b, }

{ a, b, c, }

{ a, c, }

{ a, b, c, }

{ a, b, c }

{ a, b, c, }

{ a, b, }

{ a, b, c, }

{ a, b, c }

{ a, b, c, }

{ b, c, }

{ a, b, c, }

{ a, b, }

{ a, b, c, }

{ c, b, }

{ a, b, c, }

{ a, b, c }

{ a, b, c, }

{ a, c, }

{ a, b, c, }

{ a, b, c }

{ a, b, c, }

{ b, c, }

{ a, b, c, }

{ a, c, }

{ a, b, c, }

{}
{ a, c }

{c}

{ b, c }

{ c, }

{ a, }

{d}

{ b, }

{ c, }
4C =1
0

4C =4
1

4C =6
2

{ b, c, }

{ a, b, c, }

{ a, b, }

{ a, b, c, }

{ a, c, }

{ a, b, c, }

{ a, b, }

{ a, b, c, }

{ b, c, }

{ a, b, c, }

{ a, c, }

{ a, b, c, }

{ b, c, }

{ a, b, c, }

4C =4
3

4C =1
4

Figure 1: Simple unordered operator search tree
guaranteed find goal state one exists search space. However, algorithms
may also used non-admissible pruning heuristics obtain efficient non-admissible
search.
OPUS algorithms admissible (when used admissible pruning
rules), systematic (Pearl, 1984). is, addition guaranteeing goal
found one exists, algorithms guarantee state visited
search (so long possible reach single node application
different sets operators).

3. Fixed-order Search
number recent machine learning algorithms performed restricted admissible search
(Clearwater & Provost, 1990; Rymon, 1993; Schlimmer, 1993; Segal & Etzioni, 1994; Webb,
1990). algorithms based organization search tree, that,
considering search problem illustrated Figures 1 3, traverse search space
manner depicted Figure 4. organization achieved arranging operators
predefined order, applying node operators higher
order operator appears path leading node. strategy
434

fiAn Efficient Admissible Algorithm Unordered Search

{ a, b }

{ a}

{ a, c }

{ a, }

{ a, b }

{ b}

{ b, c }

{ b, }

{ a, b , c }

{ a, b , c, }

{ a, b , }

{ a, b , c, }

{ a, b , c }

{ a, b , c, }

{ a, c, }

{ a, b , c, }

{ a, b , }

{ a, b , c, }

{ a, c, }

{ a, b , c, }

{ a, b , c }

{ a, b , c, }

{ a, b , }

{ a, b , c, }

{ a, b , c }

{ a, b , c, }

{ b, c, }

{ a, b , c, }

{ a, b , }

{ a, b , c, }

{ c, b, }

{ a, b , c, }

{ a, b , }

{ a, b , c, }

{ a, c, }

{ a, b , c, }

{ a, b , }

{ a, b , c, }

{ b, c, }

{ a, b , c, }

{ a, c, }

{ a, b , c, }

{ b, c, }

{ a, b , c, }

{}

{c}

{ a, }

{ d}

{ b, }

{ c, }
4C =1
0

4C =4
1

4C =6
2

4C =4
3

4C =1
4

Figure 2: Simple unordered operator search tree pruning beyond application operator c

called fixed-order search. (Fixed-order search also used non-admissible search,
example, Buchanan, Feigenbaum, & Lederberg, 1971).
Figure 5 illustrates effect pruning sub-tree descending operator c,
fixed-order search. seen, substantially less effective optimized
pruning illustrated Figure 3. Schlimmer (1993) ensures pruning effect illustrated
Figure 3 obtained within efficient search tree organization illustrated Figure 4,
maintaining explicit representation nodes pruned. resulting search tree
depicted Figure 6. approach requires considerable computational overhead
identifying marking pruned states following every pruning action, restrictive
storage overhead maintaining representation. (One search problems tackled
contains 2162 states. represent whether state pruned requires single bit.
Thus, 2162 bits would required represent required information problem,
requirement well beyond capacity computational machinery foreseeable
future.) Further, open debate whether approach truly prune identified
nodes search space. Nodes pruned still need
generated encountered previously unexplored regions search tree order
435

fiWebb

{ a, b }

{ a, b , }

{ a}
{ a, b , }
{ a, }

{ a, b }

{ a, b , }

{ b}
{ a, b , }
{ b, }
{}

{c}

{ a, b , }
{ a, }
{ a, b , }
{ d}

4C =1
0

4C =4
1

{ b, }

3C =3
2

3C =1
3

3C =0
4

Figure 3: Simple unordered operator search tree maximal pruning beyond application
operator c

{ a, b }

{ a, b, c }

{ a, b , c, }

{ a, b, }
{ a}

{ a, c }

{ a, c, }

{ a, }
{ b, c }
{}

{ b, c, }

{ b}
{ b ,d }
{c}

{ c, }

{ d}
4C =1
0

4 C =4
1

4C =6
2

4C =4
3

4C =1
4

Figure 4: Static search tree organization used fixed-order search

436

fiAn Efficient Admissible Algorithm Unordered Search

{ a, b, c }
{ a, b }
{ a}

{ a, c }

{ a, b , c, }

{ a, b, }
{ a, c, }

{ a, }
{}

{ b}

{ b, c }

{ b, c, }

{ b ,d }
{c}
{ d}

4C =1
0

4 C =4
1

4C =4
3

5

4C =1
4

Figure 5: Effect pruning fixed-order search
{ a, b }

{ a, b, }

{a}
{ a, }
{}

{b}

{ b,d }

{c}
{d}
4C =1
0

4 C =4
1

3 C =3
2

3 C =1
3

3C =0
4

Figure 6: Optimal pruning fixed-order search
checked list pruned nodes. Consider, example, node labeled {a}
Figure 5. expanding node necessary generate node labeled {a,
c}, even node marked pruned. generated possible
identify node pruned. node could principle pruned
anyway application variant technique identified prunable
first place. Viewed light, argued Schlimmers (1993) approach
reduce number nodes must generated fixed-order search.
saves computational cost determining nodes whether
require pruning not. (This assumes optimistic pruning mechanism able
determine node n search space pruned node n
also pruned, irrespective n encountered search tree. optimistic
pruning mechanism deficient cannot this, Schlimmers (1993) approach
increase amount true pruning performed extent overcomes
deficiency.)

4. Feature Subset Selection Algorithm
Fixed-order search traverses search space naive mannerthe topology search
tree determined advance takes account efficiency resulting search.
contrast, Feature Subset Selection (FSS) algorithm (Narendra & Fukunaga, 1977)
performs branch bound search unordered search spaces, traversing search space
437

fiWebb

{c}

{ ,b }

{ a,b, }

{ a}

{}

{ ,d }
{ b}

{ b, }

{ d}
4C =1
0

4 C =4
1

4C =6
2

4C =4
3

4C =1
4

Figure 7: Pruning FSS-like search
visit state dynamically organizing search tree
maximize proportion search space placed unpromising operators.
viewed form fixed-order search order altered node
search tree manipulate topology search tree sake search
efficiency. Unlike Schlimmer (1993), pruning mechanism ensures nodes
identified prunable generated.
power measure illustrated Figure 7. figure, fixed-order search
performed simple example problem illustrated Figures 1 6, order
changed operator pruned, c, placed first. seen, achieves
amount pruning achieved optimal pruning. effect achieved
negligible computational storage overhead.
However, FSS severely limited applicability
restricted optimization search;
restricted tasks operator may applied (subset
selection);
restricted search single solution;
requires values states search space monotonically decreasing.
is, value state cannot increase result operator application;

form pruning supports optimistic pruning.

5. OPUS Algorithms
OPUS algorithms generalize idea search space reorganization FSS. Two
variations OPUS defined. OPUSs variant satisficing search (search
qualified object sought). OPUSo variant optimization search (search
object optimizes evaluation function sought). Whereas FSS uses node values
pruning, OPUSo uses optimistic evaluation search space node.
removes requirement values states search space monotonically
decreasing opens possibility performing types pruning addition
optimistic pruning.
438

fiAn Efficient Admissible Algorithm Unordered Search

analysis follow, comments apply equally variants name
OPUS employed. comment applies one variant algorithm,
distinguished respective superscript.
OPUS uses branch bound (Lawler & Wood, 1966) search strategy traverses
search space manner similar illustrated Figure 4 guarantee
two equivalent nodes search space visited. However, organizes
search tree optimize effect pruning, achieving effect illustrated
Figure 6 without significant computational storage overhead.
Rather maintaining operator order, OPUS maintains node, n, set
operators n.active applied search space n. node
expanded, operators n.active examined determine pruned.
operators pruned removed n.active. New nodes created
operators remaining n.active sets active operators initialized
ensure every combination operators considered one node
search tree.
kept mind possible many states search space may
goal states. satisficing search states satisfy given criteria goal states.
optimization search, states optimize evaluation criteria goal states.
efficiency sake, OPUS algorithms allow sections search space pruned even
contain goal state, long remain goal states remaining search
space.
5.1 OPUSs
OPUSs algorithm presented Figure 8. description OPUSs follows
conventions employed search algorithm descriptions provided Pearl (1984).
definition OPUSs assumes single operator cannot applied
along single path search space. operator may applied multiple
times, order Steps 8a 8b reversed. Unless otherwise specified,
following discussion OPUS assumes operator may applied
along single path.
desired obtain solutions satisfy search criterion,
Step 2 altered exit successfully, returning set solutions;
Step 6b altered exit, rather add current node set
solutions;
domain specific pruning mechanisms employed Step 7 also modified
goal state may pruned search space.
form search could used assumption-based truth maintenance system find
set maximally general consistent assumptions. would provide efficient search
without need maintain search explicit database inconsistent assumptions
ATMS no-good set (de Kleer et al., 1990). Unless otherwise specified,
discussion OPUS assumes single solution sought.
algorithm specify order nodes selected expansion
Step 3. Nodes may selected random, domain specific selection function,
439

fiWebb

Data structure:
node, n, search tree associated three items information:
n.state state search space associated node;
n.active set operators explored sub-tree descending node;
n.mostRecentOperator operator applied parent nodes state create current nodes state.
Algorithm:
1. Initialize list called OP EN unexpanded nodes follows,
(a) Set OP EN contain one node, start node s.
(b) Set s.active set operators, {o1 , o2 , ...on }
(c) Set s.state start state.
2. OP EN empty, exit failure; goal state exists.
3. Remove OP EN node n, next node expanded.
4. Initialize n.active set containing operators yet examined, called
RemainingOperators.
5. Initialize {} set nodes, called N ewN odes, contain descendants n
pruned.
6. Generate children n performing following steps every operator n.active,
(a) Generate n0 , node n0 .state set state formed application
n.state.
(b) n0 .state goal state, exit successfully goal represented n0 .
(c) Set n0 .mostRecentOperator o.
(d) Add n0 N ewN odes.
7. node n0 N ewN odes pruning rules determine sole remaining goal state accessible n0 using operators RemainingOperators, prune
nodes search tree n0 search tree n follows,
(a) Remove n0 N ewN odes.
(b) Remove n0 .mostRecentOperator RemainingOperators.
8. Allocate remaining operators remaining nodes processing node n0
N ewN odes turn follows,
(a) Remove n0 .mostRecentOperator RemainingOperators.
(b) Set n0 .active RemainingOperators.
9. Add nodes N ewN odes OP EN .
10. Go Step 2.

Figure 8: OPUSs Algorithm
440

fiAn Efficient Admissible Algorithm Unordered Search

order nodes placed OP EN . First-in-first-out node selection results
breadth-first search last-in-first-out node selection results depth-first search.
order processing also unspecified Steps 7, 8 9. Depending upon
domain, practical advantage may obtained specific orderings steps.
OPUSs used machine learning context search space generalizations may formed deletion conjuncts highly specific classification
rule. goal search uncover set general rules cover
identical objects training data covered original rule (Webb, 1994a).
5.2 OPUSo
number changes warranted OPUS applied optimization search.
following definition OPUSo, variant OPUS optimization search, assumes
two domain specific functions available. first functions, value(n), returns
value state node n, higher value returned, higher
preference state1 . second function, optimisticV alue(n, o) returns value
exists node, b, created application combination
operators set operators state node n, b represents best solution
(maximizes value search space), optimisticV alue(n, o) less value(b).
used pruning sections search tree. general, lower values returned
optimisticV alue, greater efficiency pruning. time, possible prune
node optimistic value less equal best value node
explored date.
OPUSo able take advantage presence optimistic values optimize
effect pruning beyond obtained solely maximizing proportion
search space placed nodes immediately pruned. Generalizing heuristic
used FSS, nodes lower optimistic values given active operators thus
greater proportions search space placed beneath nodes higher
optimistic values. achieved order processing Step 9. rationale
strategy lower optimistic value higher probability
node associated search tree pruned expanded. Maximizing
proportion search space located nodes low optimistic value maximizes
proportion search space pruned thus explicitly explored.
Figure 9 illustrates effect respect simple machine learning tasksearch
propositional expression describes target examples non-target
examples. seven search operators represent conjunction specific proposition
male, f emale, single, married, young, mid old, respectively. Search starts
expression anything. total 128 expressions may formed conjunction
combination expressions. Twelve objects defined:
male, single, young, TARGET
male, single, mid, TARGET
male, single, old, TARGET
male, married, young, NON-TARGET
1. ease exposition, assumed optimization means maximization value. would
trivial transform algorithm discussion accommodate forms optimization.

441

fiWebb

male, married, mid, NON-TARGET
male, married, old, NON-TARGET
female, single, young, NON-TARGET
female, single, mid, NON-TARGET
female, single, old, NON-TARGET
female, married, young, NON-TARGET
female, married, mid, NON-TARGET
female, married, old, NON-TARGET.
objects, first three distinguished targets. value expression
determined two functions, negCover posCover. negCover expression
number non-target objects matches. posCover expression
number target objects matches. expression anything matches objects.
value expression negCover equal zero. Otherwise value equals
posCover. preference function avoids expressions cover negative objects
favors, expressions cover negative objects, expressions cover
positive objects. optimistic value node equals posCover nodes
expression.
Figure 9 depicts nine nodes considered OPUSo search task.
node following listed:
expression;
number target number non target objects matched (cover);
value;
potential value;
operators placed nodes set active operators hence included
search tree node.
search space traversed follows. first node, anything, expanded, producing seven children values optimistic values determined. node
pruned potential values greater best value far encountered.
active operators distributed, maximizing proportion search space
placed nodes low optimistic values. two nodes highest optimistic
values, male single, one receives active operator receives first
sole active operator. One expanded. one active
operators, single, nodes generated. other, male, expanded, generating single node, male single, value 3. Immediately node generated,
remaining open nodes pruned none optimistic value greater
new maximum value, 3.
Note nodes pruned node malesingle considered as,
point, node encountered lower optimistic value best actual
value. Consequently, search tree distributed accord potential value,
set active operators node male would {f emale, single, married, young, mid, old}.
Instead considering single node male expanded, would necessary
442

fiAn Efficient Admissible Algorithm Unordered Search

male
Cover=3/3
Value=infinity
PotVal=3
AO={single}

male single
Cover=3/0
Value=3
PotVal=3
AO={}

female
Cover=0/6
Value=infinity
PotVal=0
AO={male, married,
single, young, mid old }
single
Cover=3/3
Value=infinity
PotVal=3
AO={}
anything
Cover=3/9
Value=infinity
PotVal=3
AO={male, female,
married, single,
young, mid, old}

married
Cover=0/6
Value=infinity
PotVal=0
AO={male, single, young,
mid, old }
young
Cover=2/2
Value=infinity
PotVal=2
AO={male, single,
mid, old}
mid
Cover=2/2
Value=infinity
PotVal=2
AO={male, single, old}
old
Cover=2/2
Value=infinity
PotVal=2
AO={male, single}

Figure 9: Effect pruning search tree ordered optimistic value

443

fiWebb

consider six nodes. search space complex continued depth three
beyond, would commensurate increase proportion search space
explored unnecessarily.
Note also search example terminate goal node first
encountered, system cannot determine goal node nodes
might higher values explored pruned.
5.2.1 OPUSo Algorithm
OPUSo, algorithm achieving effect, defined Figure 10. Note
optimistic pruning need performed Step 8 performed Step 10a,
irrespective.
definition OPUSo assumes single operator cannot applied
along single path search space. allow multiple applications single
operator, order Steps 9a 9b reversed.
algorithm could also modified identify return maximal solutions
modification similar outlined allow OPUSs return solutions.
possible improve performance OPUSo lower limit
acceptable solution. Then, objective search find highest valued node
long value greater pre-specified minimum. case, nodes whose
potential value less equal minimum may also pruned Step 10a.
Like OPUSs, OPUSo specify order nodes OPEN
expanded (Step 4). Selection node highest optimistic value minimize
size search tree. single node n optimizes optimistic value,
search cannot terminate n expanded. node lower
optimistic value may yield solution value higher optimistic value n.
However, expansion n may yield solution value higher candidates optimistic values, allowing candidates discarded without expansion.
Thus, selecting single node highest optimistic value optimal respect
number nodes expanded maximizes number nodes may pruned
without expansion. multiple nodes maximize optimistic value, least one
must expanded search terminate (and search
terminate expansion node leads node value equal optimistic
value.)
many cases important consider number nodes explored
algorithm, rather number nodes expanded. node explored evaluated.
Every time node expanded, children explored. Many children
may pruned, however, never expanded. addition minimizing number
nodes expanded, form best-first search also minimize number nodes
explored (within constraint nodes equal optimistic values
possible anticipate one select order minimize number nodes explored).
due strategy algorithm employs distribute operators beneath nodes.
nodes OPUSo expands best-first search highest optimistic
value. OPUSo always allocates fewer active operators node higher optimistic value
node lower optimistic value. number nodes examined node
444

fiAn Efficient Admissible Algorithm Unordered Search

Algorithm:
1. Initialize list called OP EN unexpanded nodes follows,
(a) Set OP EN contain one node, start node s.
(b) Set s.active set operators, {o1 , o2 , ...on }
(c) Set s.state start state.
2. Initialize BEST , best node examined far, s.
3. OP EN empty, exit successfully solution represented BEST .
4. Remove OP EN node n, next node expanded.
5. Initialize n.active set containing operators yet examined, called
RemainingOperators.
6. Initialize {} set nodes, called N ewN odes, contain descendants n
pruned.
7. Generate children n performing following steps every operator n.active,
(a) Generate n0 , node n0 .state set state formed application
n.state.
(b) value(n0 ) greater value(BEST )
i. Set BEST n0 .
ii. Prune search tree removing OP EN nodes x
optimisticV alue(x, x.active) less value(BEST ).
(c) Add n0 N ewN odes.
(d) Set n0 .mostRecentOperator o.
8. node n0 N ewN odes pruning rules determine sole remaining goal state accessible n0 using operators RemainingOperators, prune
nodes search tree n0 search tree n follows,
(a) Remove n0 N ewN odes.
(b) Remove n0 .mostRecentOperator RemainingOperators.
9. Allocate remaining operators remaining nodes processing node n0
N ewN odes turn follows, time selecting previously unselected node minimizes optimisticV alue(n0 , RemainingOperators),
(a) Remove n0 .mostRecentOperator RemainingOperators.
(b) Set n0 .active RemainingOperators.
10. Perform optimistic pruning adding remaining nodes OP EN processing
node n0 N ewN odes turn follows,
(a) optimisticV alue(n0 , n0 .active) greater value(BEST ),
i. Add n0 OP EN .
11. Go Step 3.

Figure 10: OPUSo algorithm

445

fiWebb

n expanded equals number active operators n. Hence, number nodes
examined nodes expanded minimized (within constraints use
information derived current state operators
active state).
However, best-first approach minimizes number nodes expanded, may
storage optimal due large potential storage overheads. storage overhead
concern, depth-first rather best-first traversal may employed, cost
potential increase number nodes must expanded. depth-first search
employed, nodes added OP EN order optimistic value Step 10.
ensure nodes open single depth expanded best-first manner,
benefits outlined above.
5.2.2 Relation Previous Search Algorithms
OPUSo viewed amalgamation FSS (Narendra & Fukunaga, 1977) A*
(Hart, Nilsson, & Raphael, 1968). FSS performs branch bound search unordered
search spaces, traversing search space visit state dynamically organizing search tree maximize proportion search space placed
unpromising operators. However, FSS requires values states search
space monotonically decreasing. is, value state cannot increase result
operator application. OPUSo generalizes FSS employing actual
values states optimistic evaluation nodes search tree, manner similar
A*. consequence, two minor constraints upon values states
optimistic values nodes search spaces OPUSo search.
requirements
least one goal state g node n, g lies node n search
tree, optimistic value n lower value g;
states maximal value goal states.
follows OPUSo wider applicability FSS.
OPUSo also differs FSS integrating pruning mechanisms optimistic
pruning search process. facility crucial searching large search spaces
encountered machine learning.
innovation OPUS algorithms use restricted set operators
available node search tree enable focused pruning would otherwise
case. may circumstances would possible reach goal
state node n, application operators active
n. pruning rules able take account active operators provide pruning
contextpruning would otherwise possible. Similarly, set active
operators used calculate concise estimate optimistic value
would otherwise possible.
OPUSo differs A* manner dynamically organizes search tree
maximize proportion search space placed unpromising operators.
also differs A* A* relies upon value node equivalent
446

fiAn Efficient Admissible Algorithm Unordered Search

sum costs operations lead node, whereas OPUS allows method
determining nodes value.
Rymon (1993) discusses dynamic organization search tree admissible search
unordered search spaces purpose altering topology data structure (SE-tree) produced. contrasts use dynamic organization search
tree OPUSo increase search efficiency.
5.3 OPUS Non-admissible Search
pointed above, although OPUS algorithms designed admissible
search, applied non-admissible pruning rules may also used
non-admissible search. may useful efficient heuristic search required.
non-admissible heuristic search strategies embed heuristics search technique.
example, beam search relies upon use fixed maximum number alternative options
considered stage search. heuristic prune
n best solutions stage search. precise implications heuristic
particular search task may difficult evaluate. contrast, use OPUS
non-admissible pruning rules places non-admissible heuristic clearly defined rule
may manipulated suit circumstances particular search problem.
Another feature OPUSo stages available best solution encountered date search. means search terminated
time. terminated prematurely, current best solution would returned
understanding solution may optimal. algorithm employed
context, may desirable employ best-first search, opening nodes highest
actual (as opposed optimistic) value first, assumption lead
early investigation high valued nodes.
5.4 Complexity Efficiency Considerations
OPUS ensures state examined (unless identical states
formed different combinations operator applications), using similar search tree organization strategy fixed-order search. differs, however, instead placing
largest subsection search space highest ordered operator, second
largest subsection second highest ordered operator, on, whenever pruning
occurs, largest possible proportion search space placed pruned node,
hence immediately pruned.
n operators active node e expanded, search tree
including node contain every combination number operators (the
application none operators results e). Thus, search tree including
e contain 2n nodes. Exactly half these, 2n1 , label including single
operator o. OPUS ensures operator pruned node e expanded,
nodes containing removed search tree e never examined
(except, course, node reached single application must examined
order determine pruned). Thus, search tree node almost
exactly halved single operator pruned. subsequent operator pruned
node reduces remaining search tree proportion. Thus, size
447

fiWebb

remaining search tree divided almost exactly 2p , p number operators
pruned.
contrast, number nodes pruned fixed-order search depends upon
ranking operator within fixed operator ranking scheme. highest
ranked operator proportion search tree pruned OPUS.
general, operator pruned, nodes whose labels include operator
combination exclusively lower ranked operators pruned. effect illustrated
Figure 5 pruning {c} removes {c, d} search tree. Thus,
2nr 1, nodes immediately pruned search tree, n number
operators active node expanded r ranking within operators
operator pruned, highest rank 1. contrasts 2n1 1
nodes pruned OPUS.
However, difference number nodes explored two strategies
quite great analysis might suggest, (assuming availability reasonable
optimistic pruning mechanism) fixed-order search also prune operator every time
examined deeper search tree combination higher ranked operators.
Thus, Figure 5, eventually examined, pruning would occur nodes
{a, b, c}, {a, c} {b, c}. Thus, {a, b, c, d}, {a, c, d} {b, c, d} would also pruned
search tree. words, fixed-order search, operator pruned
considered combination lower ranked operator, considered
every combination number higher ranked operators. 2r1 combinations
higher ranked operator. follows fixed-order search considers many nodes
OPUS single operator pruned. Thus, operator pruned
node n, OPUS explores 2r1 less nodes n fixed-order search.
rank order operators pruned tend grow number operators
grows, follows that, average case, advantage accrued use OPUS
grow exponentially number operators grows. OPUS tend greatest
relative advantage largest search spaces.
Note OPUS always able guarantee maximal possible pruning
occurs result single pruning action. example, OPUS used
search space subsets set items, determined superset
set node may solution, items active current
node, supersets contain items active may explored elsewhere
search tree. algorithm could prune supersets could perform
pruning OPUS. might claimed Schlimmers (1993) search method
performs pruning, recalled prevent pruned nodes
generated elsewhere tree, rather, ensures nodes pruned
generated. OPUS, armed suitable pruning rules, also able prune
nodes encountered. OPUS maximizes pruning performed within constraints
localized information access.
However, constraint provided active operators prevents OPUS
performing pruning, also enables perform pruning would otherwise possible. necessary considering whether prune
node determine whether nodes reached active operators may contain
solution. Thus, continue example subset search, even supersets set
448

fiAn Efficient Admissible Algorithm Unordered Search

current node n potential solutions, still possible prune search tree
n supersets potential solutions contain items active
n. Schlimmers (1993) approach allow pruning context.
illustrate effect, let us revisit search space examined Figures 1 7. Even
though search space {c} pruned, optimal pruning cannot take
account optimistic evaluations nodes mechanism
information communicated optimistic evaluation function (other
actually exploring space node evaluated, defeats purpose
optimistic evaluation). example, evaluating optimistic value node {a},
optimistic evaluation function cannot return different value would case
{c} pruned. contrast, optimistic evaluation function employed
OPUSo take account taking active operators current node
consideration. optimistic evaluation function described Section 6.1 below.
often possible use information particular operators available
search tree node substantially improve quality optimistic evaluation
node.
also noted algorithm employ backtracking guarantee minimize number nodes expanded depth-first search.
poor node chosen expansion depth-first search, system stuck
explore search space node return explore alternatives.
algorithm guarantee poor selection unless optimistic evaluation function
high enough accuracy prevent need backtracking. follows algorithm
requires backtracking guarantee minimize number nodes
expanded. Thus, OPUS heuristic respect minimizing computational complexity
depth-first search.
storage requirements OPUS depend upon whether depth, breadth bestfirst search employed. depth-first search employed, maximum storage requirement
less maximum depth search tree multiplied maximum branching factor. However, breadth best-first search employed, worst case, storage
requirement exponential. stage search, storage requirement
storing frontier nodes search. number frontier nodes cannot exceed
number leaf nodes complete search tree. search operator may
applied (subset selection), pruning, number leaf nodes
2n1 , n number operators. assertion justified follows.
order operators considered invariant, nodes reached via last operator considered leaf node. search admissible, last operator must
considered every combination operators. 2n1 , combinations
operators. order operators considered alter number
leaf nodes absence pruning. search limit number
applications single operator (sub-multiset selection) upper limit
potential storage requirements.
Irrespective storage requirements, worst case OPUS explore
every node search space. occur pruning possible search.
operators applied per solution, number nodes search space
equal 2n , n number operators. Thus, worst case computational
449

fiWebb

complexity OPUS exponential, irrespective whether depth, breadth best-first
search employed.
OPUS clearly inappropriate, terms computational and, using breadth
best-first search, storage requirements, search problems substantial proportions search space cannot pruned. domains substantial pruning
possible, however, average case complexity (computational and/or storage) may turn
polynomial. Experimental evidence indeed case machine
learning tasks presented Section 6.3.
5.5 Search Efficiency OPUS Might Improved
noted Section 5.4, OPUS algorithms always able guarantee
maximum possible amount pruning performed. noted, one restriction upon
amount pruning performed localization inherent use active operators.
localization allows pruning would otherwise possible, also
potential restrict number supersets set operators pruned
node also pruned. may value developing mechanisms enable
pruning propagated beyond node pruning action occurs
sub-tree node.
Another aspect algorithms positive negative aspects type
information returned pruning mechanisms. mechanisms allow pruning
branch search tree long least one goal branch.
contrasts alternative strategy pruning branches lead
goal. strategy used beneficial, maximizes amount pruning
performed. However, always possible branch containing goal could
found little exploration pruned favor branch containing goal
requires extensive exploration uncover. potential gain augmenting
current pruning mechanisms means estimating search cost uncovering
goal beneath branch tree.

6. Evaluating Effectiveness OPUS Algorithms
Theoretical analysis demonstrated OPUS explore fewer nodes fixed-order
search magnitude advantage increase size search
space increases. However, precise magnitude gain depend upon extent
distribution within search tree pruning actions. interest,
number distinct elements OPUS algorithms, includingoptimistic pruning;
pruning (pruning addition optimistic pruning); dynamic reorganization
search tree; maximization proportion search space placed nodes
low optimistic value. following experiments evaluate magnitude advantage
OPUS obtained real world search tasks explore relative contribution
distinct elements OPUS algorithms.
end, OPUSo applied class real search tasksfinding pure conjunctive
expressions maximize Laplace accuracy estimate respect training set
preclassified example objects. is, example, search task CN2 purports
heuristically approximate (Clark & Niblett, 1989) forming disjuncts disjunc450

fiAn Efficient Admissible Algorithm Unordered Search

tive classifier. Machine learning systems employed OPUSo manner develop
rules inclusion sets decision rules (Webb, 1993) decision lists (Webb,
1994b). (The current experiments performed using Cover learning system, which,
default, performs repeated search pure conjunctive classifiers within CN2-like covering algorithm develops disjunctive rules. extended search disjunctive
rules used experiments, makes difficult compare alternative search
algorithms. because, two alternative algorithms find different pure conjunctive
rules first disjunct, subsequent search explore different search spaces.)
Numerous efficient admissible search algorithms exist developing classifiers
consistent training set examples. two classic algorithms purpose
least generalization algorithm (Plotkin, 1970) version space algorithm (Mitchell,
1977). least generalization algorithm finds specialized class description
covers objects training set containing positive examples. version space algorithm finds class descriptions complete consistent respect training
set positive negative examples. Hirsh (1994) generalized version space
algorithm find class descriptions complete consistent within defined
bounds training examples. least generalization version space algorithms
usually require strong inductive bias class description language (restriction
types class descriptions considered) find useful class descriptions
(Mitchell, 1980). SE-tree-based learning (Rymon, 1993) demonstrates admissible search
set consistent class descriptions within complex class description languages
may usefully employed least generalization version space algorithms. Oblow
(1992) describes algorithm employs admissible search pure conjunctive terms
within heuristic outer search k-DNF class descriptions consistent
training set.
However, many learning tasks desirable consider class descriptions
inconsistent training set. One reason training set may contain
noise (examples inaccurate). Another reason may possible accurately describe target class available language expressing class descriptions.
case necessary consider approximations target class. reason
training set may contain insufficient information reliably determine exact
class description. case, best solution may approximation known
incorrect strong evidence level error low.
Clearwater Provost (1990) Segal Etzioni (1994) use admissible fixedorder search explore classifiers inconsistent training set. However,
admissible search Clearwater Provost (1990) computationally feasible large
search spaces. Segal Etzioni (1994) bound depth search space considered
order maintain computational tractability. Smyth Goodman (1992) use optimistic
pruning search optimal rules, structure search ensure states
searched multiple times. previous admissible search algorithm
employed machine learning find classifiers inconsistent training
set maximize arbitrary preference function. following experiments seek
demonstrate search feasible using OPUS.
allowed class description may inconsistent training set,
helpful employ explicit preference function. function applied
451

fiWebb

class description returns measure desirability. evaluation usually take
account well description fits training set may also include bias toward
particular types class descriptions, example, preference syntactic simplicity.
preference function expresses inductive bias (Mitchell, 1980).
OPUSo may employed admissible search contexts, provided search space
defined may traversed finite number unordered search operators.
example, OPUSo may employed search class description language
pure-conjunctive descriptions examining search space starting general
possible class description true employing search operators, effect
conjoining specific clause current description. search may performed
arbitrary preference function, provided appropriate optimistic evaluation functions
defined.
next section describes experiments OPUSo applied manner.
6.1 Search Task
pure conjunctive expressions consisted conjunctions clauses form attribute 6=
value. attributes two values, language expressive
language allowing conjunctions clauses form attribute = value. Indeed,
equivalent expressiveness language supports internal disjunction. example, respect attribute values x, z, language restricted
conjunctions equality expressions cannot express 6= x, whereas language restricted
conjunctions inequality expressions express = x using expression 6= 6= z.
internal disjunctive (Michalski, 1984) terms, 6= x equivalent = z.
noted
attributes two values search space conjunctions inequality expressions far larger search space conjunctions equality
expressions. attribute, size search space multiplied 2n
former n + 1 latter, n number values attribute.
software employed experimentation also used search smaller
search spaces equality expressions effects demonstrated
following experiments.
Search starts general expression, true. operator performs conjunction current expression term 6= v, attribute v
single value attribute.
Laplace (Clark & Boswell, 1991) preference function used determine goal
search. function provides conservative estimate predictive accuracy
class description, e. defined
value(e) =

posCover(e) + 1
posCover(e) + negCover(e) + noOf Classes

posCover(e) number positive objects covered e; negCover(e)
number negative objects covered e; noOf Classes number classes
learning task.
452

fiAn Efficient Admissible Algorithm Unordered Search

Laplace preference function trades-off accuracy generality. favors class
descriptions cover positive objects class descriptions cover fewer,
favors class descriptions lower proportion cover negative
higher. following study, Laplace preference function employed
pruning mechanism Step 10a OPUSo algorithm pruned sections
search space optimistic values less equal value class description
covered objects. solution value higher obtained
class description covered objects, rule developed class.
optimistic value function derived observation cover specializations expression must subsets cover expression. Thus, specializations
expression may cover positive objects, may cover fewer negative objects
covered original expression. Laplace preference function maximized positive cover maximized negative cover minimized, specialization
expression node may higher value obtained positive
cover expression smallest negative cover within sub-tree node.
smallest negative cover within sub-tree node n obtained expression
formed applying operators active n expression n.
pruning performed application cannotImprove(n1 , n2 ),
boolean function true two nodes n1 n2 search tree n2
either child sibling n1 specialization n2 may higher value
highest value search tree n1 inclusive excluding search tree
n2 . function may defined
cannotImprove(x, y) neg(x) neg(y) pos(x) pos(y)
neg(n) denotes set negative objects covered description node n
pos(n) denotes set positive objects covered description node n.
cannotImprove(n1 , n2 ) search n2 cannot lead higher valued result
obtained search specializations n1 excluding nodes search space
n2 . shown n1 parent n2 child node follows.
n1 parent n2 expression n2 must specialization expression
n1 operators available n2 must available n1 . expression g
specialization, s, neg(g) neg(s) neg(g) = neg(s) (as specialization
decrease cover). follows specialization n2 , n3 , obtained
applications operators O, must specialization n1 obtained application
operators O, n4 , generalization n3 identical negative cover
n3 . n4 generalization n3 , must cover positive objects covered n3 .
Therefore, n4 must equal greater positive cover equal negative cover n3
consequently must equal greater value. follows must possible
reach n1 node least great value greatest valued node n2
without applying operator led n1 n2 .
Next consider case n1 n2 siblings. follows definition
cannotImprove neg(n1 ) neg(n2 ) pos(n1 ) pos(n2 ). Let operators o1
o2 led parent node p n1 n2 , respectively. follows
o2 cannot exclude negative objects expressions p also excluded o1
o1 cannot exclude positive objects expressions p also excluded
453

fiWebb

Table 1: Summary experimental data sets

Domain
Audiology
House Votes 84
Lenses
Lymphography
Monk 1
Monk 2
Monk 3
Multiplexor (F11)
Mushroom
Primary Tumor
Slovenian Breast Cancer
Soybean Large
Tic Tac Toe
Wisconsin Breast Cancer

Description
Medical diagnosis
Predict US Senators political
affiliation voting record.
Spectacle lens prescription.
Medical diagnosis.
Artificial data.
Artificial data.
Artificial data.
Artificial data, requiring disjunctive concept description.
Identify poison mushrooms.
Medical diagnosis.
Medical prognosis.
Botanical diagnosis.
Identify lost positions.
Medical diagnosis.

#
Values
162
48

#
Objects
226
435

#
Classes
24
2

9
60
17
17
17
22

24
148
556
601
554
500

3
4
2
2
2
2

126
42
57
135
27
91

8124
339
286
307
958
699

2
22
2
19
2
2

o2 . Therefore, application o2 n1 effect negative cover
expression may reduce positive cover. expression e reached n2
sequence operator applications O, application n1 cannot result expression
lower positive higher negative cover e.
cannotImprove function employed prune nodes Step 8 OPUSo
algorithm.
6.2 Experimental Method
search performed fourteen data sets UCI repository machine learning
databases (Murphy & Aha, 1993). data sets repository
researcher could time experiments identify capable readily expressed
categorical attribute-value learning tasks. fourteen data sets described
Table 1. number attribute values (presented column 3) treats missing values
distinct values. space class descriptions OPUS considers domain (and
hence size search space examined pure conjunctive rule developed)
2n , n number attribute values. Thus, Audiology domain,
class description developed, search space size 2162 . Columns 4 5 present
number objects number classes represented data set, respectively.
search repeated class data set. search,
objects belonging class question treated positive objects
objects data set treated negative objects. search performed using
454

fiAn Efficient Admissible Algorithm Unordered Search

following search methodsOPUSo; OPUSo without optimistic pruning; OPUSo
without pruning; OPUSo without optimistic reordering; fixed-order search,
performed Clearwater Provost (1990), Rymon (1993), Schlimmer (1993), Segal
Etzioni (1994) Webb (1990).
Optimistic pruning disabled removing condition Step 10a OPUSo
algorithm. words, Step 10(a)i always performed.
pruning disabled removing Step 8 OPUSo algorithm.
Optimistic reordering disabled changing Step 9 process node predetermined fixed-order, rather order optimistic value. treatment,
topology search tree organized fixed-order, operators pruned
node removed consideration entire subtree node.
Fixed-order search emulated disabling Step 8b disabling optimistic reordering, described above.
algorithms extent under-specified. OPUSo, optimistic pruning
pruning leave unspecified order operators leading nodes
equal optimistic values considered Step 9. ambiguities resolved
following experiments ordering operators leading nodes higher actual
values first. two operators tied optimistic actual values, operator
mentioned first names file describes data selected first.
optimistic reordering fixed-order search leave unspecified fixed-order
employed traversing search space. fixed-order search representative previous approaches unordered search employed machine learning, thus
important obtain realistic evaluation performance, ten alternative random
orders generated employed fixed-order search task. While, due
high variability performance different orderings, would desirable
explore ten alternative orderings, infeasible due tremendous
computational demands algorithm. comparison optimistic reordering
considered less crucial, used solely evaluate effectiveness one aspect
OPUSo algorithm, thus, due tremendous computational expense
algorithm, single fixed ordering used, employing order attribute values
mentioned names file.
algorithms leave unspecified order nodes equal optimistic
values selected OP EN best-first search, directly expanded
depth-first search. best first search nodes equal optimistic values removed
OP EN last-in-first-off order. depth-first search, nodes equal optimistic
value expanded order employed allocating operators Step 9.
Note fixed-order search OPUSo disabled optimistic reordering conditions used optimistic pruning. Note also fixed-order search
ordered topology search tree manner depicted Figure 4, explored
tree either best depth-first manner.
6.3 Experimental Results
Tables 2 3 present number nodes examined search experiment.
data set total number nodes explored condition indicated.
455

fiWebb

Table 2: Number nodes explored best-first search

Data set
Audiology
House Votes 84
Lenses
Lymphography
Monk 1
Monk 2
Monk 3
Multiplexor (F11)
Mushroom
Primary Tumor
Slovenian B. C.
Soybean Large
Tic Tac Toe
Wisconsin B. C.

OPUSo
7,044
533
41
1,142
357
4,326
281
2,769
391
10,892
17,418
8,304
2,894
447,786


optimistic
pruning

661
176
1,143
9,156
6,578
25,775
96,371
392
10,893
4,810,129
8338
4,222,641




pruning
24,199
554
41
1,684
371
4,335
281
2,769
788
13,137
32,965
21,418
2,902
1,159,011


optimistic
reordering

355,040
38
658,335
925
10,012
682
4,932
233,579
4,242,978

21,551,436
16,559


Fixed-order
(mean)

1,319,911
64
2,251,652
788
5,895
656
4,948

29,914,840
42,669,822

16,471


Execution terminated exceeding virtual memory limit 250 megabytes.
one ten runs completed.

fixed-order search, mean ten runs presented. Tables 4 5 present
fixed-order search number runs completed successfully, minimum number
nodes examined successful run, mean number nodes examined successful runs
(repeated Tables 2 3) standard deviations runs. Every node
generated Step 7a counted tally number nodes explored. hyphen
() indicates search could completed number open nodes made
system exceed predefined virtual memory limit 250 megabytes. asterisk (*)
indicates search terminated due exceeding pre-specified compute time
limit twenty-four CPU hours. (For comparison, longest CPU time taken data
set OPUSo sixty-seven CPU seconds Wisconsin Breast Cancer data
depth-first search.)
noted one pure conjunctive rule developed class.
separate search performed rule, number searches performed equals
number classes. Thus, Audiology data using best-first search OPUSo explored
7,044 nodes perform 24 admissible searches 2162 node search space.
two search tasks OPUSo best-first search explore nodes
alternative. Lenses data, OPUSo explores 41 nodes optimistic reordering
explores 38. Monk 2 data, OPUSo explores 4,326 nodes best ten fixedorder runs different random fixed orders explores 4,283 nodes. possible
outcomes arisen situations two sibling nodes share optimistic
value. case, two approaches select different nodes expand first, one
456

fiAn Efficient Admissible Algorithm Unordered Search

Table 3: Number nodes explored depth-first search

Data set
Audiology
House Votes 84
Lenses
Lymphography
Monk 1
Monk 2
Monk 3
Multiplexor (F11)
Mushroom
Primary Tumor
Slovenian B. C.
Soybean Large
Tic Tac Toe
Wisconsin B. C.

OPUSo
7,011
568
38
1,200
364
16,345
289
2,914
386
18,209
30,647
9,562
3,876
465,058


optimistic
pruning
*
17,067,302
513
39,063,303
54,218
85,425
63,057
188,120
*
34,325,234
172,073,241
*
11,496,736
*



pruning
17,191
596
38
1,825
378
16,427
289
2,914
761
23,668
61,391
23,860
4,010
1,211,211


optimistic
reordering
3,502,475
10,046
38
728,276
980
12,879
588
6,961
1,562,006
3,814,422
271,328,080
17,138,467
93,521
*

Fixed-order
(mean)
*
3,674,418
66
22,225,745
1,348
12,791
1,236
6,130
132,107,513
31,107,648
308,209,464
*
110,664
*

* Execution terminated exceeding 24 CPU hour limit.
three ten runs completed.

Table 4: Number nodes explored best-first fixed-order search
Data set
Audiology
House Votes 84
Lenses
Lymphography
Monk 1
Monk 2
Monk 3
Multiplexor (F11)
Mushroom
Primary Tumor
Slovenian B. C.
Soybean Large
Tic Tac Toe
Wisconsin B. C.

Runs
0
10
10
10
10
10
10
10
0
10
1
0
10
0

Minimum

451,038
51
597,842
463
4,283
527
4,210

10,552,129
42,669,822

8,046


Mean

sd


1,319,911
64
2,251,652
788
5,895
656
4,948

29,914,840
42,669,822

16,471



624,957
9
1,454,583
225
931
110
364

12,390,146
0

5,300


Execution terminated ten runs exceeding
virtual memory limit 250 megabytes.

457

fiWebb

Table 5: Number nodes explored depth-first fixed-order search
Data set
Audiology
House Votes 84
Lenses
Lymphography
Monk 1
Monk 2
Monk 3
Multiplexor (F11)
Mushroom
Primary Tumor
Slovenian B. C.
Soybean Large
Tic Tac Toe
Wisconsin B. C.

Runs
0
10
10
10
10
10
10
10
3
10
10
0
10
0

Minimum
*
1,592,391
50
484,694
553
9,274
627
4,467
105,859,320
10,458,421
110,101,761
*
49,328
*

Mean

sd

*
3,674,418
66
22,225,745
1,348
12,791
1,236
6,130
132,107,513
31,107,648
308,209,464
*
110,664
*

*
2,086,159
12
27,250,834
922
2,686
891
1,164
22,749,211
14,907,744
303,800,659
*
65,809
*

* Execution terminated ten runs exceeding
24 CPU hour limit.

may turn better choice other, leading exploration fewer
nodes. test plausibility explanation, OPUSo run Lenses
data set Step 8 altered ensure two siblings equal optimistic value
ordered order employed optimistic reordering.
resulted exploration 36 nodes, fewer alternative. OPUSo
fixed-order run fixed-order using order attribute declaration data
file determine operator order OPUSo using order order siblings
equal optimistic values, numbers nodes explored Monk 2 data 4,302
OPUSo 8,812 fixed-order search.
notable effect apparent small search spaces.
significant suggests effect small magnitude resulting
poor choice node expand two nodes equal optimistic value.
expected. Consider case two nodes n1 n2 equal highest
optimistic value, v, n1 leads goal whereas n2 not. n2 expanded first,
long child n2 optimistic value greater equal v, next node
expanded n1 , n1 node highest optimistic value. (If
child n2 optimistic value greater v, optimistic evaluation function cannot
good, fact n2 optimistic value v means node n2
value greater v.) Thus, number unnecessary node expansions due
effect never exceed number times nodes equal highest optimistic
values encountered search.
contrast case best-first search, discussed Section 5.4, OPUS
heuristic respect minimizing number nodes expanded depth-first search.
458

fiAn Efficient Admissible Algorithm Unordered Search

Nonetheless, one search task, Monk 2 data set, OPUSo explore
nodes depth-first search (16,345) alternative (both optimistic reordering
fixed-order search explore 12,879 12,791 nodes respectively). results
demonstrate heuristic optimal data. noted, however,
single exception depth-first search occurs relatively small search
space. suggests efficient exploration search space poor choice
node much minimize damage done poor choice, even
backtracking case depth-first search.
five data sets (House Votes 84, Lymphography, Mushroom, Primary Tumor
Soybean Large), disabling optimistic pruning little effect best-first search. Disabling optimistic pruning always large effect depth-first search. best-first
search smallest increase caused disabling optimistic pruning increase
one node Lymphography Mushroom data sets. data sets
possible complete search without optimistic pruning, biggest effect
almost 1,500 fold increase number nodes explored Tic Tac Toe
data. depth-first search, data sets processing could completed
without optimistic pruning, smallest increase five-fold increase Monk 2
data largest increase 30,000 fold increase Lymphography data.
seven data sets (House Votes 84, Lenses, Monk 1, Monk 2, Monk 3, F11 Multiplexor,
Tic Tac Toe) disabling pruning little effect best-first depth-first
search. largest effects 2.5 fold increases Soybean Large Wisconsin
Breast Cancer data sets best-first search Audiology, Soybean Large
Wisconsin Breast Cancer data sets depth-first search.
results apparent data sets
pruning technique little effect (so long also employed), also
data sets pruning halves amount search space explored
data sets optimistic pruning reduces amount search space explored
thousandths would otherwise explored.
effect optimistic reordering also highly variable. two search tasks (bestfirst search Lenses data set depth-first search Monk 2 data set) use
actually resulted slight increase number nodes explored. discussed
above. many cases, however, effect disabling optimistic reordering far greater
disabling optimistic pruning. Processing could completed without
optimistic reordering three best-first search tasks one depth-first search
tasks. tasks search could completed, largest effect best-first
search 2,500 fold increase number nodes explored Soybean Large data.
depth-first search, tasks search could completed, largest
effect 8,000 fold increase Slovenian Beast Cancer data. would
desirable evaluate effect alternative fixed-orderings operators results,
seems optimistic reordering critical general success algorithm.
one data set (the Monk 2 data depth-first search), fixed-order search
average explores substantially nodes OPUSo. asserted Section 5.4
average case advantage use OPUSo opposed fixed-order search
tend grow exponentially number search operators increases. number
search operators search tasks equal number attribute values
459

fiLog Advantage

Webb

20
19
18
17
16
15
14
13
12
11
10
9
8
7
6
5
4
3
2
1
0
-1













best-first search
depth-first search





10 20 30 40 50 60 70 80 90 100 110 120 130 140
Search Space Size

Figure 11: Plot difference nodes explored fixed-order OPUSo search
search space size.

corresponding data sets. Analysis Tables 2 3 reveals relative advantage
OPUSo data sets fewest attribute values (Lenses, Monk 1, 2 3,
F11 Multiplexor) approximately two-fold reduction number nodes examined.
number attribute values increases, relative advantage. four
data sets greatest number attribute values (Audiology, Mushroom, Soybean
Large Wisconsin Breast Cancer) one case (depth-first search Mushroom
data) fixed-order search terminate. one case, OPUSo enjoys 350,000-fold
advantage. results lend credibility claim OPUSos average case advantage
fixed-order search exponential respect size search space.
illustrated Figure 11. figure, searches fixed-order search terminated
within resource constraints, size search space plotted log2 (f /o)
f number nodes explored fixed-order search number nodes
explored OPUSo.
seems clear results admissible fixed-order search practical
many search tasks within scope current technology.
interesting observe best-first search, four artificial data
sets (Monk 1, Monk 2, Monk 3 F11 Multiplexor) fixed-order search often explores
slightly fewer nodes OPUSo optimistic reordering disabled. difference two types search latter deletes pruned operators sets
active operators higher ordered operators whereas former not. Thus
latter prunes nodes search tree pruning operation. seems
460

fiAn Efficient Admissible Algorithm Unordered Search

counter-intuitive increased pruning sometimes lead exploration
nodes. understand effect necessary recall pruning prune
solutions search tree long alternative solutions available.
artificial data sets question, retaining alternative solutions search tree cases
leads slight increase search efficiency alternative encountered earlier
first solution. Despite minor advantage number artificial data sets
fixed-order search OPUSo optimistic reordering disabled, latter enjoys large
advantage data sets processing could completed. House
Votes 84 data, fixed-order search explores 3.5 times many nodes best-first
search 350 times many depth-first search.
seen reason believe average case number
nodes explored OPUSo polynomial respect search space size
machine learning search tasks. numbers nodes explored three largest
search spaces certainly suggestive exponential explosion numbers
nodes examined (Audiology2162 nodes search space: 7,044 7,011 nodes examined. Soybean Large2135 nodes search space: 8,304 9,562 nodes examined.
Mushroom2126 nodes search space: 391 386 nodes examined.)
interesting little difference number nodes explored OPUSo
using either best depth-first search data sets. Surprisingly, slightly fewer nodes
explored depth-first search three data sets (Audiology, Lenses Mushroom). similar reasons presented context occasional slight advantage enjoyed fixed-order search OPUSo optimistic reordering
disabled. cases depth-first search fortuitously encounters alternative solutions
found best-first search. evaluate plausibility explanation, OPUSo
run three data sets question using fixed-order ordering order operators
equal optimistic values. resulting numbers nodes explored Audiology:
6678, Lenses: 36 Mushroom: 385. seen, numbers cases lower
numbers nodes explored depth-first search. case OPUSo
outperformed best-first strategies, effect appears small magnitude
thus significant small numbers nodes need explored. four
data sets depth-first search explores substantially nodes best-first search
(Slovenian Breast Cancer, 75%; Monk 2, 275%; Primary Tumor, 67%; Tic Tac Toe,
33%).
6.4 Summary Experimental Results
experiments demonstrate admissible search pure conjunctive classifiers feasible using OPUSo types learning task contained UCI repository.
also support theoretical findings OPUSo general explore fewer
nodes fixed-order search magnitude advantage tend grow
exponentially respect size search space.
Optimistic pruning pruning demonstrated individually provide
large decreases number nodes explored search spaces little
effect others. Optimistic reordering demonstrated large impact upon
number nodes explored.
461

fiWebb

results respect search largest search spaces suggest
average case complexity algorithm less exponential respect search
space size.

7. Summary Future Research
OPUS algorithms potential application many areas endeavor.
used replace admissible search algorithms unordered search spaces maintain
explicit lists pruned nodes, currently used ATMS (de Kleer, 1986).
may also support admissible search number application domains, learning
classifiers inconsistent training set, previously tackled
heuristic search.
addition applications admissible search, OPUS algorithms may also
used efficient non-admissible search application non-admissible pruning
rules. OPUSo algorithm also able return solution prematurely terminated
time, although solution may non-optimal.
availability admissible search important step forward machine learning
research. studies paper employed OPUSo optimize Laplace
preference function, algorithm could used optimize learning bias. means
first time possible isolate effect explicit learning bias
implicit learning bias might introduced heuristic search algorithm
interaction explicit bias.
application OPUSo provide admissible search machine learning already
proved productive. Webb (1993) used OPUSo demonstrate heuristic search
fails optimize Laplace accuracy estimate within covering algorithm frequently
results inference better classifiers found admissible search optimize preference function. explain result Quinlan Cameron-Jones
(1995) developed theory oversearching.
research reported herein demonstrated OPUS provide efficient admissible search pure conjunctive classifiers categorical attribute-value data sets
UCI repository. would interesting see techniques extended
powerful machine learning paradigms continuous attribute-value first-order logic
domains.
research also demonstrated power pruning. issue given
scant attention context search machine learning. Although presented
context admissible search, pruning rules presented equally applicable
heuristic search. development pruning rules may prove important
machine learning tackles ever complex search spaces.
OPUS provides efficient admissible search unordered search spaces. creating
machine learning system necessary consider search (the
explicit learning biases) also search (appropriate search algorithms).
assumed previously algorithms must necessarily heuristic techniques
approximating desired explicit biases. Admissible search decouples two issues
removing confounding factors may introduced search algorithm.
guaranteeing search uncovers defined target, admissible search makes possible
462

fiAn Efficient Admissible Algorithm Unordered Search

systematically study explicit learning biases. supporting efficient admissible search,
OPUS first time brings machine learning ability clearly explicitly
manipulate precise inductive bias employed complex machine learning task.

Acknowledgements
research supported Australian Research Council. grateful
Riichiro Mizoguchi pointing potential application OPUS truth maintenance. also grateful Mike Cameron-Jones, Jon Patrick, Ron Rymon, Richard
Segal, Jason Wells, Leslie Wells Simon Yip numerous helpful comments previous
drafts paper. especially indebted anonymous reviewers whose insightful,
extensive detailed comments greatly improved quality paper.
Breast Cancer, Lymphography Primary Tumor data sets provided
Ljubljana Oncology Institute, Slovenia. Thanks UCI Repository, maintainers,
Patrick Murphy David Aha, donors, providing access data sets used
herein.

References
Buchanan, B. G., Feigenbaum, E. A., & Lederberg, J. (1971). heuristic programming
study theory formation science. IJCAI-71, pp. 4050.
Clark, P., & Boswell, R. (1991). Rule induction CN2: recent improvements.
Proceedings Fifth European Working Session Learning, pp. 151163.
Clark, P., & Niblett, T. (1989). CN2 induction algorithm. Machine Learning, 3,
261284.
Clearwater, S. H., & Provost, F. J. (1990). RL4: tool knowledge-based induction.
Proceedings Second Intl. IEEE Conf. Tools AI, pp. 2430 Los Alamitos, CA.
IEEE Computer Society Pres.
de Kleer, J. (1986). assumption-based TMS. Artificial Intelligence, 28, 127162.
de Kleer, J., Mackworth, A. K., & Reiter, R. (1990). Characterizing diagnoses. Proceedings AAAI-90, pp. 324330 Boston, MA.
Hart, P., Nilsson, N., & Raphael, B. (1968). formal basis heuristic determination
minimum cost paths. IEEE Transactions System Sciences Cybernetics,
SSC-4 (2), 100107.
Hirsh, H. (1994). Generalizing version spaces. Artificial Intelligence, 17, 546.
Lawler, E. L., & Wood, D. E. (1966). Branch bound methods: survey. Operations
Research, 149, 699719.
Michalski, R. S. (1984). theory methodology inductive learning. Michalski,
R. S., Carbonell, J. G., & Mitchell, T. M. (Eds.), Machine Learning: Artificial
Intelligence Approach, pp. 83129. Springer-Verlag, Berlin.
463

fiWebb

Mitchell, T. M. (1977). Version spaces: candidate elimination approach rule learning.
Proceedings Fifth International Joint Conference Artificial Intelligence,
pp. 305310.
Mitchell, T. M. (1980). need biases learning generalizations. Technical report
CBM-TR-117, Rutgers University, Department Computer Science, New Brunswick,
NJ.
Moret, B. M. E., & Shapiro, H. D. (1985). minimizing set tests. SIAM Journal
Scientific Statistical Computing, 6 (4), 9831003.
Murphy, P., & Aha, D. (1993). UCI repository machine learning databases. [Machinereadable data repository]. University California, Department Information
Computer Science, Irvine, CA.
Murphy, P., & Pazzani, M. (1994). Exploring decision forest: empirical investigation
Occams Razor decision tree induction. Journal Artificial Intelligence Research,
1, 257275.
Narendra, P., & Fukunaga, K. (1977). branch bound algorithm feature subset
selection. IEEE Transactions Computers, C-26, 917922.
Nilsson, N. J. (1971). Problem-solving Methods Artificial Intelligence. McGraw-Hill, New
York.
Oblow, E. M. (1992). Implementing Valiants learnability theory using random sets. Machine Learning, 8, 4573.
Pearl, J. (1984). Heuristics: Intelligent Search Strategies Computer Problem Solving.
Addison-Wesley, Reading, Mass.
Plotkin, G. D. (1970). note inductive generalisation. Meltzer, B., & Mitchie, D.
(Eds.), Machine Intelligence 5, pp. 153163. Edinburgh University Press, Edinburgh.
Quinlan, J. R., & Cameron-Jones, R. M. (1995). Oversearching layered search
empirical learning. IJCAI95, pp. 10191024 Montreal. Morgan Kaufmann.
Reiter, R. (1987). theory diagnosis first principles. Artificial Intelligence, 32,
5795.
Rymon, R. (1992). Search systematic set enumeration. Proceedings KR-92, pp.
268275 Cambridge, MA.
Rymon, R. (1993). SE-tree based characterization induction problem. Proceedings 1993 International Conference Machine Learning San Mateo, Ca.
Morgan Kaufmann.
Schlimmer, J. C. (1993). Efficiently inducing determinations: complete systematic
search algorithm uses optimal pruning. Proceedings 1993 International
Conference Machine Learning, pp. 284290 San Mateo, Ca. Morgan Kaufmann.
464

fiAn Efficient Admissible Algorithm Unordered Search

Segal, R., & Etzioni, O. (1994). Learning decision lists using homogeneous rules. AAAI94.
Smyth, P., & Goodman, R. M. (1992). information theoretic approach rule induction
databases. IEEE Transactions Knowledge Data Engineering, 4 (2), 301
316.
Webb, G. I. (1990). Techniques efficient empirical induction. Barter, C. J., &
Brooks, M. J. (Eds.), AI88 Proceedings Third Australian Joint Conference
Artificial Intelligence, pp. 225239 Adelaide. Springer-Verlag.
Webb, G. I. (1993). Systematic search categorical attribute-value data-driven machine
learning. Rowles, C., Liu, H., & Foo, N. (Eds.), AI93 Proceedings Sixth
Australian Joint Conference Artificial Intelligence, pp. 342347 Melbourne. World
Scientific.
Webb, G. I. (1994a). Generality significant complexity: Toward alternatives
Occams Razor. Zhang, C., Debenham, J., & Lukose, D. (Eds.), AI94 Proceedings Seventh Australian Joint Conference Artificial Intelligence, pp. 6067
Armidale. World Scientific.
Webb, G. I. (1994b). Recent progress learning decision lists prepending inferred
rules. SPICIS94: Proceedings Second Singapore International Conference
Intelligent Systems, pp. B280B285 Singapore.

465

fiJournal Artificial Intelligence Research 3 (1995) 325-348

Submitted 5/95; published 12/95

Vision-Based Road Detection Automotive Systems:
Real-Time Expectation-Driven Approach
Alberto Broggi
Simona Berte

Dipartimento di Ingegneria dell'Informazione
Universita di Parma
Viale delle Scienze
I-43100 Parma, Italy

broggi@ce.unipr.it
simona@ce.unipr.it

Abstract

main aim work development vision-based road detection system
fast enough cope dicult real-time constraints imposed moving vehicle
applications. hardware platform, special-purpose massively parallel system,
chosen minimize system production operational costs.
paper presents novel approach expectation-driven low-level image segmentation, mapped naturally onto mesh-connected massively parallel Simd architectures capable handling hierarchical data structures. input image assumed
contain distorted version given template; multiresolution stretching process used
reshape original template accordance acquired image content, minimizing
potential function. distorted template process output.

1. Introduction
work discussed paper forms part Eureka Prometheus activities, aimed
improved road trac safety. Since processing images fundamental importance
automotive applications, current work aimed development
embedded low-cost computer vision system. Due special field application,
vision system must able process data produce results real-time. therefore
necessary consider data structures, processing techniques, computer architectures
capable reducing response time system whole.
system considered currently integrated Mob-Lab land vehicle (Adorni,
Broggi, Conte, & D'Andrea, 1995). MOBile LABoratory, result Italian work
within Prometheus project (see Figure 1.a), comprises camera acquisition
digitization images, pipelines data on-board massively parallel computer
processing. illustrated Figure 2, current output configuration comprises set
warnings driver, displayed means set Leds control-panel (shown
Figure 1.b). But, due high performance levels achieved, possible replace
output device heads-up display showing enhanced features superimposed
onto original image.
paper presents move toward use top-down control (the following feature
extraction mechanism based model-driven approach), instead traditional datadriven approach, generally used data-parallel algorithms.

c 1995 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiAlberto Broggi, Simona Berte

Figure 1: (a) Mob-Lab land vehicle; (b) control panel used output display
processing results

Heads-up
Display

(a)

LED-based
Control Panel

(b)

Road Detection
System
Camera

Input

Processing

Output

Figure 2: Block diagram complete system: (a) planned heads-up display output
(b) current Led-based output
Starting experience gained development different approach (Broggi,
1995c) based parallel detection image edges pointing Focus Expansion,
work presents model-driven low-level processing technique aimed road detection
enhancement road (or lane) image acquired moving vehicle. model
contains a-priori knowledge feature extracted (road lane) encoded
traditional data structure handled low-level processing: two-dimensional array.
case, binary image representing two different regions (road off-road) chosen.
Hereinafter image referred Synthetic Image. obvious different
synthetic images must used according different acquisition conditions (camera position,
orientation, optics, etc., fixed) environment (number lanes, one way two
way trac, etc., may change run-time). final system implementation
326

fiVision-Based Road Detection

a-priori world knowledge enables correct synthetic model selection. example,
Figure 3 presents several different synthetic images different conditions.

(a)

(b)

Figure 3: Synthetic images used road models for: (a) different camera positions and/or
orientations (b) different number lanes (assuming driving right)
following Section presents survey vision-based lane detection systems; Section
3 explains choice multiresolution approach; Section 4 presents details
complete algorithm; Section 5 discusses performances current implementation
Paprica system; Section 6 presents results critical analysis approach
leads present development; finally Section 7 presents concluding remarks.

2. Comparison Related Systems
Many different vision-based road detection systems developed worldwide,
relying various characteristics different road models (two three dimensional),
acquisition devices (color monochromatic camera, using mono stereo vision), hardware systems (special- general-purpose, serial parallel), computational techniques
(template matching, neural networks, etc.).

Scarf system (tested Navlab vehicle Carnegie Mellon University)

uses two color cameras color-based image segmentation; different regions
classified grouped together form larger areas; finally Hough-like transform
used vote different binary model candidates. Due extremely high amount
data processed, two incoming color images (480 512) reduced
60 64 pixel. Nevertheless, high performance computer architecture, 10 cell
Warp (Crisman & Webb, 1991; Hamey, Web, & Wu, 1988; Annaratone, Arnould,
T.Gross, H.Kung, & J.Webb, 1987), chosen speed-up processing.
system, capable detecting even unstructured roads, reaches processing rate
1 Hz (Crisman & Thorpe, 1993, 1991, 1990; Thorpe, 1989). addition heavy
3
computational load, main problems approach found implicit
models assumed: road curves sharply changes width, assumed shape
model becomes invalid detection fails (Kluge & Thorpe, 1990).
Vits system (tested Alv vehicle developed Martin Marietta) also
relies two color cameras. uses combination red blue color bands
segment image, effort reduce artifacts caused shadows. Information
vehicle motion also used aid segmentation process. Tested successfully
327

fiAlberto Broggi, Simona Berte

straight, single lane roads, runs faster Scarf, sacrificing general capability
speed (Turk, Morgenthaler, Gremban, & Marra, 1988).
Alvinn (tested Navlab, Cmu) neural network based 30 32 video retina
designed, like Scarf, detect unstructured roads, road
model: learns associations visual patterns steering wheel angles, without considering road location. also implemented Warp system,
reaching processing rate 10 Hz (Jochem, Pomerleau, & Thorpe, 1993;
Pomerleau, 1993, 1990).
different neural approach developed Cmu tested Navlab:
256 256 color image segmented 16k processor MasPar MP-2 (MasPar
Computer Corporation, 1990). trapezoidal road model used, road width
assumed constant throughout sequence: means although
trapezoid may skewed left right, top bottom edges maintain
constant length. high performance offered powerful hardware platform
limited low I/O bandwidth; therefore simpler reduced version (processing
128 128 images) implemented, working rate 2.5 Hz (Jochem &
Baluja, 1993).
Due high amount data (2 color images) complex operations involved (segmentation, clustering, Hough transform, etc.) system discussed, even implemented extremely powerful hardware machines, achieve low processing rate. Many
different methods considered speed-up processing, including processing
monochromatic images use windowing techniques (Turk et al., 1988) process
regions interest, thus implementing Focus Attention mechanism (Wolfe &
Cave, 1990; Neumann & Stiehl, 1990).

example, VaMoRs (developed Universitat der Bundeswehr, Munchen)

monochromatic images processed custom hardware, focusing regions
interest (Graefe & Kuhnert, 1991). windowing techniques supported
strong road vehicles models predict features incoming images (Dickmans &
Mysliwetz, 1992). case, vehicle driven high speeds (up 100 kph)
German autobahns, constant lane width, road specific
shapes: straight, constant curvature, clothoidal. use single monochromatic
camera together simple road models allows fast processing based
simple edge detection; match structured road model used discard
anomalous edges. approach disturbed shadow conditions, overall
illumination changes, road imperfections found (Kluge & Thorpe, 1990).
Lanelok system (developed General Motors) also relies strong road models:
estimates location lane boundaries curve fitting method (Kenue &
Bajpayee, 1993; Kenue, 1991, 1990), using quadratic equation model. addition
disturbed presence vehicles close road markings, lane detection
generally fails shadow conditions. extension correct interpretation
shadows therefore introduced (Kenue, 1994); unfortunately technique
relies fixed brightness thresholds far robust general
approach.
328

fiVision-Based Road Detection

main aim approach discussed paper, hand, build
low-cost system capable achieving real-time performance detection structured roads (with painted lane markings), robust enough tolerate severe illumination
changes shadows. Limitation analysis structured environments allows
use simple road models which, together processing monocular monochromatic
images special-purpose hardware allows achievement low-cost high performances.
use high performance general-purpose architecture, 10 cell Warp
16k MasPar MP-2 (as case Carnegie Mellon's Navlab), involves high costs
compatible widespread large-scale use. reason execution
low-level computations (eciently performed massively parallel systems) usually
implemented general purpose processors, case VaMoRs. design
implementation special-purpose application-oriented architectures (like Paprica,
Broggi, Conte, Gregoretti, Sansoe, & Reyneri, 1995, 1994), hand, keep
production costs down, delivering high performance levels. generally,
features enable integration architecture generic vehicle are:
(a) low production cost,
(b) low operational cost,
(c) small physical size.

2.1 Computing Architecture

Additional considerations power consumption show mobile computing moving
direction massively parallel architectures comprising large number relatively
slow-clocked processing elements. power consumption dynamic systems
considered proportional CfV 2 , C represents capacitance circuit, f
clock frequency, V voltage swing. Power saved three different ways
(Forman & Zahorjan, 1994), minimizing C , f , V respectively:
using greater level Vlsi integration, thus reducing capacitance C ;
trading computer speed (with lower clock frequency f ) lower power consumption
(already implemented many portable PCs);
reducing supply voltage VDD .
Recently, new technological solutions exploited reduce IC supply voltage
5 V 3.3 V. Unfortunately, speed penalty pay reduction:
Cmos gate (Shoji, 1988), device delay Td (following first order approximation)
VDD 2 , shows reduction VDD determines quasiproportional
(VDD , VT )
linear increment (until device threshold value VT ) circuit delay Td .
hand, reduction VDD determines quadratic reduction power consumption.
Thus, power saving reasons, desirable operate lowest possible speed, but,
order maintain overall system performance, compensation increased delays
required.
use lower power supply voltage investigated different architectural solutions considered overcome undesired side effects caused
reduction VDD (Courtois, 1993; Chandrakasan, Sheng, & Brodersen, 1992).
329

fiAlberto Broggi, Simona Berte

reduction power consumption, maintaining computational power, achieved
using low cost Simd computer architectures, comprising large number extremely
simple relatively slow-clocked processing elements. systems, using slower device
speeds, provide effective mechanism trading power consumption silicon area,
maintaining computational power unchanged. 4 major drawbacks approach
are:

solution based hardware replication increases silicon area, thus

suitable designs extreme area constraints;
parallelism must accompanied extra-routing, requiring extra-power; issue
must carefully considered optimized;
use parallel computer architectures involves redesigning algorithms
different computational model;
since number processing units must high, system size constraints
processing elements must extremely simple, performing simple basic operations.

paper investigates novel approach real-time road following based use
low-cost massively parallel systems data-parallel algorithms.

3. Multiresolution Approach
image encoding model (Synthetic Image) image camera (Natural
Image) cannot directly compared local computations, latter contains
much detail former. known methods used decrease
presence details, necessary choose one decrease strength
feature extracted. purpose, low-pass filter, 3 3 neighborhoodbased anisotropic average filter, would reduce presence details, also
sharpness road boundaries, rendering detection dicult. Since road
boundaries exploit long-distance correlation, subsampling natural
synthetic image would lead comparison less dependent detail content.
generally, much easier detect large objects low resolution,
main characteristics present, high resolution, details
specific represented object make detection dicult. complete recognition
description process, hand, take place high resolutions,
possible detect even small details preliminary results obtained
coarse resolution.
considerations lead use pyramidal data structure (Rosenfeld, 1984;
Ballard & Brown, 1982; Tanimoto & Kilger, 1980), comprising image different
resolutions. Many different architectures developed recently support computational paradigm (Cantoni & Ferretti, 1993; Cantoni, Ferretti, & Savini, 1990; Fountain,
1987; Cantoni & Levialdi, 1986): computing architecture contains number
processing elements smaller number image pixels external processor virtualization mechanism (Broggi, 1994) used. useful side effect due resolution
reduction decrease number computations performed. Thus, choice
330

fiOutput image

Input image

Synthetic image

Vision-Based Road Detection

1

256
X
256

1

1

128
X
128

undersampling

8

256
X
256

8

8

8

average

...

1

32
X
32

8

32
X
32

128
X
128

8

8

8

average

...

undersampling

8
1

256
X
256

DBS

1

1

oversampling

1

undersampling

undersampling

8
1

1

1

8
1

128
X
128

1

1

oversampling

DBS

...

1

DBS

Figure 4: Block diagram whole algorithm; step depth every image
shown (in bit/pixel)
pyramidal computational paradigm, addition supported theory, offers
advantage terms computational eciency.

4. Algorithm Structure

shown Figure 4, subsampling natural image filtered. way
possible decrease uence noise redundant details, distortion due
aliasing (Pratt, 1978) introduced subsampling process. image partitioned
non-overlapping square subsets 2 2 pixels each; filter comprises simple average
pixels values given subset, reduces signal bandwidth. set
resulting values forms subsampled image.
stretching synthetic image performed iterative algorithm
(Driven Binary Stretching, Dbs), much simpler morphological (Haralick, Sternberg,
& Zhuang, 1987; Serra, 1982) version \snake" technique (Blake & Yuille, 1993; Cohen & Cohen, 1993; Cohen, 1991; Kass, Witkin, & Terzopolous, 1987). result
oversampled, improved using Dbs algorithm, original resolution reached. boundary stretched template represents final result
process.

4.1 DBS Filter

purpose Dbs filter, illustrated Figure 5, stretch binary input model
accordance data encoded grey-tone natural image produce reshaped
version synthetic model output.
Usually boundary generic object represented brightness discontinuities
image reproducing it, therefore, first version, first step Dbs filter
comprises extremely fast simple gradient-based filter computed 3 3 neighborhood pixel. Then, shown Figure 5, threshold applied gradient
image, order keep significant edges. threshold value fixed,
automatic tuning based median filtering currently tested (Folli, 1994).
331

fiAlberto Broggi, Simona Berte

precisely, two different threshold values computed left right halves
image, order detect road boundaries even different illumination
conditions.
8
8
1

1

gradient

DBS

8

threshold

threshold
value

1

DT
8
1

1

iterative algorithm

Figure 5: Block diagram Dbs filter
Since 2D mesh-connected massively parallel architecture used, iterative algorithm
must performed order stretch synthetic model toward positions encoded
thresholded image. advantage pyramidal approach number
iterations required successful stretching low coarse resolution since image
size small; again, iterations required high-resolution refinement,
due initial coarse low-resolution stretching. border pixel synthetic image
attracted towards position nearest foreground pixel thresholded image,
shown Figure 6.

Model
section

Threshold

(a)

(b)

Figure 6: attraction boundary pixels model (in grey) toward thresholded image (the rectangular contour): (a) two-dimensional case; (b) monodimensional section
purpose, scalar field V defined E 2. Field V : E 2 ! E , links position
pixel p 2 E 2 scalar value V (p) 2 E , represents potential associated
pixel itself. set values encoded potential image. difference
V (p) , V (q) represents cost moving pixel p toward position q. scalar field
defined way negative cost corresponds movement toward nearest
332

fiVision-Based Road Detection

position foreground pixels ti thresholded image. consequence, iterative
process designed explicitly enable pixel movements associated negative cost.
Thus, value V (p) depends minimum distance pixel p pixels ti :
V (p) = , min
(1)
d(p; ti) ;

: E 2 E 2 ! E represents distance two pixels, measured respect
given metric. case, due special simplicity implementation, city
block (Manhattan distance) metric chosen (see Figure 7).
4

3

2

3

4

3

2

1

2

3

2

1

0

1

2

3

2

1

2

3

4

3

2

3

4

Figure 7: City block Manhattan distance central pixel
ecient method computation potential image using 2D mesh-connected
architectures based iterative application morphological dilations (Haralick et al.,
1987; Serra, 1982):
1. scalar counter initialized 0; parallel architectures cannot run
fragment scalar code, counter associated every pixel image, thus
constituting \parallel" counter;
2. counter decremented;
3. binary input image dilated using 4-connected structuring element N , formed
following elements:
n


N = (0; 1); (0; ,1); (0; 0); (1; 0); (,1; 0) = "! ;


(2)

4. value counter assigned potential image positions
pixel, due previous dilation, changes state background foreground.
5. process repeated step 2, output morphological dilation
equal input.
shows potential image generated application Distance
Transform, DT (Borgefors, 1986) binary thresholded image. Due ecient
implementation-dependent data handling, final version potential image DT
obtained adding constant every coecient, work positive
values: represents maximum value allowed grey-tone images1. Thus new
definition scalar field V is:
V (p) = , min
(3)
d(p; ti) :
1. specific case, since 8-bit images considered, = 255.

333

fiAlberto Broggi, Simona Berte

Linear profile
input image
[8 bit/pixel]

threshold value

Gradient
[8 bit/pixel]

Threshold
[1 bit/pixel]

Distance
Transform (DT)
[8 bit/pixel]

Synthetic
input image
[1 bit/pixel]
Synthetic
output image
[1 bit-pixel]

Figure 8: Example 4 iterations Dbs algorithm (monodimensional case)
Furthermore, since `distance' information used pixels belonging
border synthetic image neighbors, iterative process stopped
DT computed pixels, producing noticeable performance improvement.
already mentioned, crux algorithm iterative process whose purpose
move edge pixels synthetic image directions DT gradient
maximum. Figure 8 shows example monodimensional stretching. shown
Appendix A, strength approach lies fact stretching algorithm
expressed simply sequence morphological operations, therefore
mapped eciently mesh-connected massively parallel architectures, achieving higher
performance levels approaches (Cohen & Cohen, 1993; Cohen, 1991; Kass et al.,
1987).
order describe Dbs algorithm, let us introduce definitions using Mathematical Morphology operators (Haralick et al., 1987; Serra, 1982) dilation (),
erosion ( ), complement (). two-dimensional binary image represented
subset E 2, whose elements correspond foreground pixels image:

n

= 2 E 2 = (x; y); x; 2 E ;
(4)
vector (x; ) represents coordinates generic element s.
334

fiVision-Based Road Detection

external edge defined set elements representing difference
dilation 4-connected structuring element N shown expression (2):
(5)
Be(S ) = (S N ) \ :
similar way, set elements representing difference erosion
using structuring element N defined internal edge :

Bi(S ) = (S N ) \ :

(6)

4.1.1 Iterative Rules

set elements B(S ) = (S ) [ Bi (S ) elements inserted
removed set application single iteration Dbs algorithm.
precisely, two different rules applied two edges: first, applied external
edge (S ), determines elements included set ; second, applied
internal edge Bi (S ), determines elements removed set .

Rule external edge:
{ pixel external edge computes minimum value DT
associated 4-connected neighbors belonging set ;
{ pixels, whose associated DT greater value previously computed, inserted set .

application rule effect expanding synthetic image towards
foreground pixels ti included synthetic model (see right
hand side Figure 6.b).

Rule internal edge:
{ pixel internal edge computes minimum value DT
associated 4-connected neighbors belonging set ;
{ pixels, whose associated DT greater value previously computed, removed set .
application rule effect shrinking synthetic image (see
left hand side Figure 6.b).
Note rule 2 inverse rule 1: latter tends stretch foreground onto
background, former acts opposite way, using complement
synthetic image.
4.1.2 Flat Handling

Figure 8 refers monodimensional stretching. Unfortunately, dealing 2D data
structures, DT image present strictly increasing decreasing behavior, even
locally. Thus, extension previous rules must considered correct at-handling
2D space.
335

fiAlberto Broggi, Simona Berte

2

1

2

3

4

5

4

3

2

1

0

1

2

2

1

2

3

4

5

4

3

2

1

0

1

2

2

1

2

3

4

5

4

3

2

1

0

1

2

1

0

1

2

3

4

3

2

1

0

0

0

1

1

0

1

2

3

4

3

2

1

0

0

0

1

1

0

1

2

3

4

3

2

1

0

0

0

1

0

1

2

3

4

4

3

2

1

0

1

1

2

0

1

2

3

4

4

3

2

1

0

1

1

2

0

1

2

3

4

4

3

2

1

0

1

1

2

1

0

1

2

3

4

3

2

1

0

1

2

3

1

0

1

2

3

4

3

2

1

0

1

2

3

1

0

1

2

3

4

3

2

1

0

1

2

3

1

0

1

2

3

4

3

2

1

0

1

2

3

1

0

1

2

3

4

3

2

1

0

1

2

3

1

0

1

2

3

4

3

2

1

0

1

2

3

1

0

1

2

3

4

3

2

1

0

1

2

3

1

0

1

2

3

4

3

2

1

0

1

2

3

1

0

1

2

3

4

3

2

1

0

1

2

3

1

0

1

2

3

4

4

3

2

1

0

1

2

1

0

1

2

3

4

4

3

2

1

0

1

2

1

0

1

2

3

4

4

3

2

1

0

1

2

2

1

0

1

2

3

4

4

3

2

1

0

1

2

1

0

1

2

3

4

4

3

2

1

0

1

2

1

0

1

2

3

4

4

3

2

1

0

1

2

1

0

1

2

3

4

4

3

2

1

0

1

2

1

0

1

2

3

4

4

3

2

1

0

1

2

1

0

1

2

3

4

4

3

2

1

0

1

3

2

1

2

3

4

5

5

4

3

2

1

2

3

2

1

2

3

4

5

5

4

3

2

1

2

3

2

1

2

3

4

5

5

4

3

2

1

2

a) Input image

b) Stretching without flat-handling

c) Stretching flat-handling

Figure 9: Two-dimensional stretching: different square markings represent different states
input binary image; dark grey areas represent stretching area
Figure 9.a shows modulus DT coecients (in case = 0), together
input binary image (shown grey). output iterative Dbs algorithm
presented Figure 9.b.
Since movement generic pixel towards positions holding equal DT coecient expressly disabled, resulting binary image completely follow shape
encoded DT image. minor revision definition rule 1 thus required.
Figure 9.c obtained following rule applied external edge.

Rule external edge, including handling:
{ pixel external edge computes minimum value DT
associated 4-connected neighbors belonging set ;
{ pixels, whose associated DT greater value previously computed, pixels belonging thresholded image, whose associated DT equal value previously computed inserted set .

specific requirement pixels moving toward region, belonging
thresholded image, ensures binary image follow DT chain maxima.
requirement, specific case Figure 9, maxima upper-right
hand area included resulting binary image.

5. Performance Analysis Current Implementation

Since final aim work integrate road detection system mobile
vehicle, main requirement achieve real-time performance. choice specialpurpose massively parallel architecture already justified Section 1; moreover,
algorithm discussed paper maps naturally onto single-bit mesh-connected Simd
machine, whole computation eciently expressed sequence binary
morphological operators, shown Appendix (which presents morphology-based
description whole Dbs algorithm).
complete processing, first tested Connection Machine CM-2 (Hillis, 1985),
implemented special-purpose massively parallel Simd architecture Paprica.
336

fiVision-Based Road Detection

Paprica system (PArallel PRocessor Image Checking Analysis), based hierarchical morphology computational model, designed specialized coprocessor
attached general purpose host workstation: current implementation, consisting 16 16 square array processing units, connected Sparc-based workstation
via Vme bus, installed Mob-Lab. current hardware board (a single 6U Vme
board integrating Processor Array, Image Program Memories, frame
grabber device direct acquisition images Paprica Image Memory)
result full reengineering first Paprica prototype extensively
analyzed tested (Gregoretti, Reyneri, Sansoe, Broggi, & Conte, 1993) several years.
Paprica architecture developed explicitly meet specific requirements real-time image processing applications (Broggi, 1995c, 1995b; Adorni, Broggi,
Conte, & D'Andrea, 1993); specific processor virtualization mechanism utilized Paprica architecture allows handling pyramidal data structures without additional
overhead equipment.
shown Figure 2, output device be:
(a) heads-up display road (or lane) boundaries highlighted;
(b) set Leds indicating relative position road (or lane) vehicle.
Starting 256 256 grey-tone images resolution reduction process,
first case (a) initial resolution must recovered order superimpose result onto
original image. second case (b), hand, due high quantization
output device, processing stopped low resolution (e.g., 64 64),
stripe resulting image analyzed drive Leds. Table 1 presents
computational time required step algorithm (considering 5 DT iterations
5 Dbs iterations pyramid level).
Operation
Image size
Time [ms]
Resolution Reduction
2562!322
149.70
2
2
DT, Dbs & Oversampling
32 !64
18.55
DT, Dbs & Oversampling
642!1282
69.13
DT, Dbs & Oversampling
1282!2562
296.87
Total (Led output)
2562!322 !642
168.25
2
2
2
Total (heads-up display output) 256 !32 !256
534.25
Table 1: Performance Paprica system; numbers refer 5 iterations DT
process 5 iterations Dbs filter pyramid level.
current Mob-Lab configuration, output device (shown Figure 1.b) consists
set 5 Leds: Table 1 shows 2562 ! 322 ! 642 filtering single frame takes
150180 ms (depending number iterations required), allowing acquisition
processing 6 frames per second.
Moreover, due high correlation two consecutive sequence frames,
final stretched template used input model stretched processing
following frame. conditions lower number Dbs DT iterations
337

fiAlberto Broggi, Simona Berte



b

c



e



b

c



e



b

c



e

Figure 10: detection road markings removal perspective effect
three different conditions: straight road shadows, curved road shadows, junction. (a) input image; (b) reorganized image, obtained non-uniform
resampling (a); (c) result line-wise detection black-white-black transitions horizontal direction; (d) reintroduction perspective effect,
grey areas represent portion image shown (c); (e) superimposition (d) onto brighter version original image (a).
needed complete template reshaping, thus producing noticeable performance
improvement. reduction time required process single frame also increases
correlation current following frame sequence, thus allowing
reduction computation time2 .
Images acquired many different conditions environments used
extensive experimentation, performed first off-line functional simulator
implemented 8k processor Connection Machine CM-2 (Hillis, 1985) realtime Paprica hardware Mob-Lab. complete system demonstrated
final Prometheus project meeting Paris, October 1994: Mob-Lab land
vehicle driven around two-lane track Mortefontaine, different conditions
(straight curved roads, shadows changing illumination conditions
vehicles path).
2. processing highly correlated sequences (namely road conditions change slowly
off-line slow-motion tape playback laboratory) computational time required processing
single frame reach minimum value 150 ms.

338

fiVision-Based Road Detection

performances obtained demonstration allowed main limitations
system detected enabled critical analysis approach, thus leading
proposals development.

6. Critical Analysis Evolution

approach discussed achieves good performances terms output quality
model matches (or suciently similar to) road conditions, namely road markings
painted road surface (on structured roads, see Figures 11.a 12.a) inducing
suciently high luminance gradient. approach successful road lane
boundaries extracted input image gradient thresholding operation
(see Figures 11.b 12.b). Unfortunately, always possible, example
road region patch shadow sunlight, Figure 13.a. case computation
DT starting thresholded image (see Figure 13.b) longer significant:
different method must devised determination binary image used
input Distance Transform.



b

c



e

Figure 11: Lane detection straight road: (a) input image; (b) image obtained
thresholding gradient image; (c) image obtained perspective-based
filter; (d) stretched template; (e) superimposition edges stretched
template onto original image. case thresholded gradient (b)
perspective-based filtered (c) images used input DT.



b

c



e

Figure 12: Lane detection curved road: also case thresholded gradient
(b) perspective-based filtered (c) images used input
DT.
recent work (Broggi, 1995a) approach based removal perspective
effect presented performances discussed. transform, non-uniform resampling
similar happens human visual system (Zavidovique & Fiorini, 1994; Wolfe &
339

fiAlberto Broggi, Simona Berte

Cave, 1990), applied input image (Figures 10.a); assuming road, every pixel
resampled image (Figures 10.b) represent portion road3. Due
constant width within overall image, road markings easily enhanced
extracted extremely simple morphological filters (Broggi, 1995a) (Figures 10.c).
Finally perspective effect reintroduced (Figures 10.d).



b

c



e

Figure 13: Lane detection straight road shadows: case thresholded gradient (b) cannot used determine DT image due noise
caused shadows. hand, perspective-based processing able
filter shadows extract road markings: DT fact
determined using image (c) instead (b).



b

c



e

Figure 14: Lane detection straight road vehicle path:
case Dbs algorithm cannot stretch binary model successfully,
due presence vehicle occluding road markings. use
pair stereo cameras remove problem currently investigated.
Due high effectiveness filter, test version system currently
operational laboratory, Dbs filter improved replacing gradient
thresholding perspective-based filter. extended version Dbs filter
shown Figure 15.
Since removal (and reintroduction) perspective effect reduced
mere image resampling filter based simple morphological operators (Broggi,
1995a), implementation Paprica system straightforward. preliminary
results obtained current test version system encouraging
output quality (the problems caused shadows resolved) computation
3. Note that, due perspective effect, pixels lower part original image (Figures 10.a)
represent cm2 road region, central pixels represent tens cm2 . nonuniform resampling original image explicitly designed homogeneous distribution
information among pixels image.

340

fiVision-Based Road Detection

8
8
1

extended
DBS

persp. eff.
removal

1

8

morph.
filter
1

persp. eff.
reintrod.
1

DT
8
1

1

iterative algorithm

Figure 15: Diagram extended Dbs filter including perspective-based filtering
time: single frame processed less 100 ms, thus allowing processing
10 frames per second. improvement Dbs process means perspectivebased filter, addition allowing correct road (or lane) detection presence shadows,
implemented extremely eciently Paprica system, taking advantage
specific hardware extension designed explicitly purpose (non uniform-resampling)
(Broggi, 1995a).
Figures 11, 12, 13, 14 show results processing different conditions:
straight curved road, shadows vehicles path, respectively4 .
last case lane cannot detected successfully due presence obstacle
use pair stereo images currently investigated overcome
problem: removal perspective effect stereo images would lead
image iff road at, namely obstacles found vehicle path.
difference two reorganized images (namely obstacle detected) would cause
algorithm stop lane detection warn driver.
general nature presented approach enables detection suciently
large-sized features: example, using different synthetic models possible detect
road lane boundaries, shown Figure 16.

7. Conclusions
paper novel approach detection road (or lane) boundaries visionbased systems presented. multiresolution approach, together top-down
control, allows achievement remarkable performances terms computation time
(when mapped massively parallel architectures) output quality.
4. sequences MPEG format (200 1000 frames respectively) available via World Wide
Web http://WWW.CE.UniPR.IT/computer vision, showing lane detection particularly challenging
conditions. images shown Figures 11, 12, 13, 14, 16 part sequences available
previously mentioned WWW page.

341

fiAlberto Broggi, Simona Berte



b

c



e

Figure 16: (a) input image; (b) synthetic model used lane detection; (c) superimposition
edges stretched model onto original input image; (d) synthetic
model used road detection; (e) superimposition edged stretched
model onto original input image.
perspective-based filter introduced improve system performance shadow
conditions. However, even perspective-based filter alone able extract road
markings high degree confidence, hierarchical application Dbs filter
(and extension handling image sequences) basic importance since allows
exploitation temporal correlation successive sequence frames (performing
solution tracking).
presence obstacle vehicle path still open problem, currently
approached using stereo vision (Broggi, 1995a).
algorithm implemented Paprica system, massively parallel lowcost Simd architecture; specific hardware features, Paprica capable
processing 10 frames per second.

Appendix A. Morphological Implementation DBS Filter

appendix, rule external edge considered, assuming step n
iterative process. Recalling Mathematical Morphology notations used identify
grey-tone two-dimensional image, DT image subset E 3:

DT = fd 2 E 3 j = (u; v); v = V (u); 8 u 2 E 2g ;

(7)

u represents position element E 2, v represents value.
pixelwise masking operation binary grey-tone image defined
function
fi : E2 E3 ! E3
(8)
fi B represents subset B containing elements b = (u; v ) whose
position vector u 2 E 2 also belongs A:

fi B = fx 2 E 3 j x = (u; v) 2 B; u 2 Ag

(9)

order compute minimum value DT specified neighborhood, let us
consider image Ke(n)



Ke(n) = Se(n) fi DT [ Se(n) fi L ;
(10)
342

fiVision-Based Road Detection

Se(n) represents binary image step n, subscript e indicates rule
external edge considered, finally

L = fl 2 E 3 j l = (u; ); 8 u 2 E 2g :

(11)

shown (Haralick et al., 1987), order compute minimum value grey-tone
image Ke(n) 4-connected neighborhood, following grey-scale morphological erosion
used:
Me(n) = Ke(n) Q ;
(12)

Q = f(1; 0; 0); (,1; 0; 0); (0; 1; 0); (0; ,1; 0)g ;
(13)
shown Figure 17.
0
0

0
0

z


Q = { (1, 0, 0) ; (0, 1, 0) ; (-1, 0, 0) ; (0, -1, 0) }

x

Figure 17: Structuring element Q
order determine set elements Me(n) value smaller DT ,
new function required:
: E3 E3 ! E2 :
(14)
function defined

M(A; B) = fx 2 E 2 j V (A; x) < V (B; x)g ;

(15)

V : E 3 E 2 ! E defined

V (A; x) =

(

9 2 E j (x; a) 2 (A) :
,1 otherwise

(16)

equation (16), (A) represents top (Haralick et al., 1987), defined

(A) = ft 2 A; = (u; v) j 6 9 t0 = (x; v0) 2 v0 > vg :

(17)

set elements included set Se(n+1) given logical intersection
M(Me(n); DT ) set elements belonging external edge Se(n) :








Ee(n) = Me(n); DT \ Se(n) :
343

(18)

fiAlberto Broggi, Simona Berte

Distance
Transform (DT)
[8 bit/pixel]

Distance
Transform (DT)
[8 bit/pixel]
Input
image
[1 bit/pixel]

Input
image
[1 bit/pixel]

Synthetic image
complemented
[1 bit/pixel]

Masked
image K
[8 bit/pixel]

Masked
image K
[8 bit/pixel]

DT

DT
Eroded
image
[8 bit/pixel]

Dilated
image
[8 bit/pixel]

(M,DT)
[1 bit/pixel]

(M,DT)
[1 bit/pixel]

External edge
[1 bit/pixel]

Internal edge
[1 bit/pixel]

Output image
[1 bit/pixel]

Output image
[1 bit/pixel]

Figure 18: Monodimensional stretching case external edge (left) internal edge
(right)
Thus, final result iteration n given
Se(n+1) = Se(n) [ Ee(n) :
(19)
Figure 18.a shows execution individual iteration rule 1 monodimensional
image profile.
Following similar steps, possible formalize rule 2. order compute
maximum value DT specified neighborhood, let us consider image Ki(n)

Ki(n) = Si(n) fi DT ;

(20)
subscript indicates rule internal edge considered.
shown above, order compute maximum value grey-tone image Ki(n)
4-connected neighborhood, following morphological dilation used:
Mi(n) = Ki(n) Q ;
(21)
Q shown Figure 17.
set elements removed set Si(n+1) given logical intersection M(Mi(n); DT ) set elements belonging internal edge Si(n) :




Ei(n) = Mi(n); DT \ Bi Si(n) :
(22)
344

fiVision-Based Road Detection

Thus, final result iteration n given




Si(n+1) = Si(n) [ Ei(n) = Si(n) \ Ei(n) :

(23)

Figure 18b shows execution individual iteration rule 2 monodimensional
profile image.

Acknowledgements
work partially supported Italian Cnr within framework Eureka
Prometheus Project { Progetto Finalizzato Trasporti contracts n. 93.01813.PF74
94.01371.PF74.
authors indebted Gianni Conte valuable constructive discussions
continuous support throughout project.

References

Adorni, G., Broggi, A., Conte, G., & D'Andrea, V. (1993). self-tuning system realtime Optical Flow detection. Proceedings IEEE System, Man, Cybernetics
Conf, Vol. 3, pp. 7{12.
Adorni, G., Broggi, A., Conte, G., & D'Andrea, V. (1995). Real-Time Image Processing
Automotive Applications. Laplante, P. A., & Stoyenko, A. D. (Eds.), Real-Time Image Processing: Theory, Techniques Applications. IEEE SPIE Press. press.
Annaratone, M., Arnould, E., T.Gross, H.Kung, & J.Webb (1987). Warp Computer: Architecture, Implementation Performance. IEEE Trans Computers,
C-36 (12), 1523{1538.
Ballard, D. H., & Brown, C. M. (1982). Computer Vision. Prentice Hall.
Blake, A., & Yuille, A. (1993). Active Vision. MIT Press.
Borgefors, G. (1986). Distance Transformations Digital Images. Computer Vision,
Graphics Image Processing, Vol. 34, pp. 344{371.
Broggi, A. (1994). Performance Optimization Low-Cost Cellular Array Processors.
Proceedings IEEE Intl Conf Massively Parallel Computing Systems, pp. 334{338.
Broggi, A. (1995a). Massively Parallel Approach Real-Time Vision-Based Road Markings Detection. Masaky, I. (Ed.), Proceedings IEEE Intelligent Vehicles'95, pp.
84{89.
Broggi, A. (1995b). Novel Approach Lossy Real-Time Image Compression: Hierarchical
Data Reorganization Low-Cost Massively Parallel System. Real-Time Imaging
Journal, 1 (2).
Broggi, A. (1995c). Parallel Local Feature Extraction: Real-Time Approach Road
Boundary Detection. IEEE Trans Image Processing, 4 (2), 217{223.
Broggi, A., Conte, G., Gregoretti, F., Sansoe, C., & Reyneri, L. M. (1995). Evolution
PAPRICA System. Integrated Computer-Aided Engineering Journal - Special
Issue Massively Parallel Computing. press.
345

fiAlberto Broggi, Simona Berte

Broggi, A., Conte, G., Gregoretti, F., Sansoe, C., & Reyneri, L. M. (1994). PAPRICA
Massively Parallel Processor. Proceedings IEEE Intl Conf Massively Parallel
Computing Systems, pp. 16{30.
Cantoni, V., & Ferretti, M. (1993). Pyramidal Architectures Computer Vision. Plenum
Press, London.
Cantoni, V., Ferretti, M., & Savini, M. (1990). Compact Pyramidal Architectures. Tou,
J., & Balchen, J. (Eds.), Highly Redundant Sensing Robotic Systems, Vol. 58, pp.
157{174. NATO ASI Series F.
Cantoni, V., & Levialdi, S. (1986). Pyramidal Systems Computer Vision. Springer
Verlag, Berlin.
Chandrakasan, A., Sheng, S., & Brodersen, R. (1992). Low-Power CMOS Digital Design.
IEEE Journal Solid-State Circuits, 27 (4), 473{484.
Cohen, L. D. (1991). Note Active Contour Models Balloons. CGVIP: Image Understanding, 53 (2), 211{218.
Cohen, L. D., & Cohen, I. (1993). Finite-Element Methods Active Contour Models
Balloons 2-D 3-D Images. IEEE Trans PAMI, 15 (11), 1131{1147.
Courtois, B. (1993). CAD Testing ICs systems: going?. Tech.
rep., TIMA & CMP.
Crisman, J., & Thorpe, C. (1990). Color Vision Road Following. Thorpe, C. E. (Ed.),
Vision Navigation. Carnegie Mellon Navlab, pp. 9{24. Kluwer Academic
Publishers.
Crisman, J., & Thorpe, C. (1991). UNSCARF, Color Vision System Detection
Unstructured Roads. Proceedings IEEE Intl Conf Robotics Automation,
pp. 2496{2501.
Crisman, J., & Thorpe, C. (1993). SCARF: Color Vision System Tracks Roads
Intersections. IEEE Trans Robotics Automation, 9 (1), 49{58.
Crisman, J. D., & Webb, J. A. (1991). Warp Machine Navlab. IEEE Trans
PAMI, 13 (5), 451{465.
Dickmans, E. D., & Mysliwetz, B. D. (1992). Recursive 3-D Road Relative Ego-State
Recognition. IEEE Trans PAMI, 14, 199{213.
Folli, A. (1994). Elaborazione parallela di immagini per applicazioni tempo reale su
autoveicolo. Master's thesis, Universita degli Studi di Parma, Facolta di Ingegneria.
Forman, G. H., & Zahorjan, J. (1994). Challenge Mobile Computing. Computer,
27 (4), 38{47.
Fountain, T. (1987). Processor Arrays: Architectures applications. Academic-Press,
London.
Graefe, V., & Kuhnert, K.-D. (1991). Vision-based Autonomous Road Vehicles. Masaki,
I. (Ed.), Vision-based Vehicle Guidance, pp. 1{29. Springer Verlag.
Gregoretti, F., Reyneri, L. M., Sansoe, C., Broggi, A., & Conte, G. (1993). PAPRICA
SIMD array: critical reviews perspectives. Dadda, L., & Wah, B. (Eds.),
Proceedings ASAP'93 - IEEE Intl Conf Application Specific Array Processors, pp.
309{320 Venezia, Italy.
346

fiVision-Based Road Detection

Hamey, L. G. C., Web, J. A., & Wu, I. (1988). Low-level vision Warp Apply
Programming Model. Kowalik, J. S. (Ed.), Parallel Computations Computers
Artificial Intelligence, pp. 185{200. Kluwer Academic Publishers.
Haralick, R. M., Sternberg, S. R., & Zhuang, X. (1987). Image Analysis Using Mathematical
Morphology. IEEE Trans PAMI, 9 (4), 532{550.
Hillis, W. D. (1985). Connection Machine. MIT Press, Cambridge, Ma.
Jochem, T. M., & Baluja, S. (1993). Massively Parallel Road Follower. Bayoumi,
M. A., Davis, L. S., & Valavanis, K. P. (Eds.), Proceedings Computer Architectures
Machine Perception '93, pp. 2{12.
Jochem, T. M., Pomerleau, D. A., & Thorpe, C. E. (1993). MANIAC: Next Generation Neurally Based Autonomous Road Follower. Proceedings Intl Conf
Intelligent Autonomous Systems: IAS -3 Pittsburgh, Pennsylvania, USA.
Kass, M., Witkin, A., & Terzopolous, D. (1987). Snakes: Active Contour Models. Intl
Journal Computer Vision, 1, 321{331.
Kenue, S. K. (1990). LANELOK: detection lane boundaries vehicle tracking using
image-processing techniques. Proceedings SPIE - Mobile Robots IV, Vol. 1195,
pp. 221{233.
Kenue, S. K. (1991). LANELOK: Algorithm Extending Lane Sensing Operating
Range 100 Feet. Proceedings SPIE - Mobile Robots V, Vol. 1388, pp. 222{233.
Kenue, S. K. (1994). Correction Shadow Artifacts Vision-based Vehicle Guidance.
Proceedings SPIE - Mobile Robots VIII, Vol. 2058, pp. 12{26.
Kenue, S. K., & Bajpayee, S. (1993). LANELOK: Robust Line Curvature Fitting
Lane Boundaries. Proceedings SPIE - Mobile Robots VII, Vol. 1831, pp. 491{503.
Kluge, K., & Thorpe, C. E. (1990). Explicit Models Robot Road Following. Thorpe,
C. E. (Ed.), Vision Navigation. Carnegie Mellon Navlab, pp. 25{38. Kluwer
Academic Publishers.
Kluge, K. (1994). Extracting Road Curvature Orientation Image Edge Points
without Perceptual Grouping Features. Proceedings IEEE Intelligent Vehicles'94.
MasPar Computer Corporation, Sunnyvale, California (1990). MP-1 Family Data-Parallel
Computers.
Neumann, H., & Stiehl, H. (1990). Toward computational architecture monocular
preattentive segmentation. G.Hartmann, R., & G.Hauske (Eds.), Parallel Processing Neural Systems Computers. Elsevier (North Holland).
Newman, W. M., & Sproull, R. F. (1981). Principles Interactive Computer Graphics.
McGraw-Hill, Tokyo.
Pomerleau, D. A. (1990). Neural Network Based Autonomous Navigation. Thorpe,
C. E. (Ed.), Vision Navigation. Carnegie Mellon Navlab, pp. 83{93. Kluwer
Academic Publishers.
Pomerleau, D. A. (1993). Neural Network Perception Mobile Robot Guidance. Kluwer
Academic Publishers, Boston.
Pratt, W. K. (1978). Digital Image Processing. John Wiley & Sons.
347

fiAlberto Broggi, Simona Berte

Rosenfeld, A. (1984). Multiresolution Image Processing Analysis. Springer Verlag,
Berlin.
Serra, J. (1982). Image Analysis Mathematical Morphology. Academic Press, London.
Shoji, M. (1988). CMOS Digital Circuit Technology. Prentice Hall.
Tanimoto, S. L., & Kilger, K. (1980). Structured Computer Vision: Machine Perception
trough Hierarchical Compuation Structures. Academic Press, NY.
Thorpe, C. (1989). Outdoor Visual Navigation Autonomous Robots. Kanada, T.,
Groen, F. C. A., & Hertzberger, L. O. (Eds.), Intelligent Autonomous Systems, Vol. 2,
pp. 530{544.
Tsai, R. (1986). Ecient Accurate Camera Calibration Technique 3D Machine
Vision. Proceedings IEEE Intl Conf Computer Vision Pattern Recognition,
pp. 364{374.
Turk, M. A., Morgenthaler, D. G., Gremban, K. D., & Marra, M. (1988). VITS - Vision
System Autonomous Land Vehicle Navigation. IEEE Trans PAMI, 10 (3).
Wolfe, J. M., & Cave, K. R. (1990). Deploying visual attention: guided model. AI
eye, pp. 79{103. A.Blake T.Troscianko.
Zavidovique, B., & Fiorini, P. (1994). Control View Vision Architectures. Cantoni,
V. (Ed.), Human Machine Vision: Analogies Divergencies, pp. 13{56. Plenum
Press.

348

fiJournal Artificial Intelligence Research 3 (1995) 223-248

Submitted 6/94; published 10/95

Improving Connectionist Energy Minimization
Gadi Pinkas

pinkas@cs.wustl.edu

Rina Dechter

dechter@ics.uci.edu

Center Optimization Semantic Control, Washington University
AMDOCS Inc, 1611 Des Peres Rd., St Louis, MO 63131 USA
Department Information Computer Science
University California, Irvine, CA 92717, USA

Abstract

Symmetric networks designed energy minimization Boltzman machines
Hopfield nets frequently investigated use optimization, constraint satisfaction
approximation NP-hard problems. Nevertheless, finding global solution (i.e.,
global minimum energy function) guaranteed even local solution may
take exponential number steps. propose improvement standard local
activation function used networks. improved algorithm guarantees
global minimum found linear time tree-like subnetworks. algorithm, called
activate, uniform assume network tree-like. identify
tree-like subnetworks even cyclic topologies (arbitrary networks) avoid local minima
along trees. acyclic networks, algorithm guaranteed converge
global minimum initial state system (self-stabilization) remains correct
various types schedulers. negative side, show presence
cycles, uniform algorithm exists guarantees optimality even sequential
asynchronous scheduler. asynchronous scheduler activate one unit time
synchronous scheduler activate number units single time step.
addition, uniform algorithm exists optimize even acyclic networks scheduler
synchronous. Finally, show algorithm improved using cycle-cutset
scheme. general algorithm, called activate-with-cutset improves activate
performance guarantees related size network's cycle-cutset.

1. Introduction

Symmetric networks Hopfield networks, Boltzmann machines, mean-field Harmony networks frequently investigated use optimization, constraint satisfaction
approximation NP-hard problems (Hopfield, 1982, 1984; Hinton & Sejnowski, 1986;
Peterson & Hartman, 1989; Smolensky, 1986; Brandt, Wang, Laub, & Mitra, 1988).
models characterized symmetric matrix weights quadratic energy function minimized. Usually, unit computes gradient energy
function updates activation value free energy decreases gradually.
Convergence local minimum guaranteed although worst case exponential
number units (Kasif, Banerjee, Delcher, & Sullivan, 1989; Papadimitriou, Shaffer,
& Yannakakis, 1990).
many cases problem hand formulated minimization problem
best solutions (sometimes solutions) global minima (Hopfield & Tank, 1985;
Ballard, Gardner, & Srinivas, 1986; Pinkas, 1991). desired algorithm therefore one
c 1995 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiPinkas Dechter

manages reduce impact shallow local minima, thus improving chances
finding global minimum. models Boltzmann machines Harmony
nets use simulated annealing escape local minima. models asymptotically
converge global minimum, meaning annealing schedule slow enough,
global minimum found. Nevertheless, schedule hard find therefore,
practice, networks guaranteed find global minimum even exponential
time.
paper look topology symmetric neural networks. present
algorithm finds global minimum acyclic networks otherwise optimizes treelike subnetworks linear time. extend general topologies dividing
network fictitious tree-like subnetworks using cycle-cutset scheme.
algorithm based method nonserial dynamic programming methods
(Bertele & Brioschi, 1972), also used constraint optimization (Dechter,
Dechter, & Pearl, 1990). task divided precompilation
tree structure via tree-clustering algorithm run-time optimization tree.
adaptation connectionist style; i.e., algorithm stated simple,
uniform activation function (Rumelhart, Hinton, & McClelland, 1986; Feldman & Ballard,
1982) executed parallel architectures using synchronous asynchronous
scheduling policies. assume desired topology (acyclic) performs worse
standard local algorithms topologies. fact, may integrated many
standard algorithms way new algorithm out-performs standard
algorithms avoiding certain class local minima (along tree-like subnetworks).
algorithm also applicable emerging class greedy algorithms called local
repair algorithms. local repair techniques, problem hand usually formulated
minimization function measures distance current state goal
state (the solution). algorithm picks setting variables repeatedly
changes variables cause maximal decrease distance function.
example, commonly used distance function constraint satisfaction problems
number violated constraints. local repair algorithm may viewed energy
minimization network distance function plays role energy. Local repair
algorithms sequential though, use greedy scheduling policy; next node
activated one leading largest change distance (i.e., energy). Recently,
local repair algorithms successfully used various large-scale hard problems
3-SAT, n-queen, scheduling constraint satisfaction (Minton, Johnson, & Phillips,
1990; Selman, Levesque, & Mitchell, 1992). Since local repair algorithms may viewed
sequential variations energy minimization paradigm, reasonable assume
improvements energy minimization also applicable local-repair algorithms.
negative side, show presence cycles, uniform algorithm
exists guarantees optimality even sequential asynchronous scheduler.
asynchronous scheduler activate one unit time synchronous scheduler
activate number units single time step. addition, uniform algorithm
exists optimize even acyclic networks scheduler synchronous. negative
results involve conditions parallel model execution therefore applicable
parallel versions local repair.
224

fiImproving Connectionist Energy Minimization

paper organized follows: Section 2 discusses connectionist energy minimization.
Section 3 presents new algorithm activate gives example out-performs
standard local algorithms. Section 4 discusses negative results, convergence various schedulers self-stabilization. Section 5 extends approach general topologies
algorithm activate-with-cutset suggests future research. Section 6 summarizes
discusses applications.

2. Connectionist Energy Minimization

Given quadratic energy function form:
n
n
X
X
E (X1; :::; Xn) = , wi;j Xi Xj , +i Xi:
i<j



variables Xi may value zero one called activation value,
task find zero/one assignment variables X1; :::Xn minimizes
energy function. avoid confusion signs, consider equivalent problem
maximizing goodness function:
X
X
G(X1; :::; Xn) = ,E (X1; :::; Xn) = wi;j XiXj + Xi
(1)
i<j



connectionist approaches, look network generated assigning node
(i) every variable (Xi) function, creating weighted arc (with weight wi;j )
node node j , every term wi;j Xi Xj . Similarly, bias given unit i,
term Xi function. example, Figure 1 shows network corresponds
goodness function E (X1; :::; X5) = 3X2X3 , X1 X3 +2X3X4 , 2X4X5 , 3X3 , X2 +2X1.
nodes assigned processing unit network collectively searches
assignment maximizes goodness. algorithm repeatedly executed
unit/node called activation function. algorithm uniform executed
units.
4
2
-3

-2

3

5

1

-1
-1

3
2

2

1

Figure 1: example network
give examples two popular activation functions connectionist
energy minimization: discrete Hopfield network (Hopfield, 1982) Boltzmann
225

fiPinkas Dechter

machine (Hinton & Sejnowski, 1986). discrete Hopfield model, unit computes
activation value using formula:
(
P w X ,
1


j i;j j
Xi = 0 otherwise
Boltzmann machines determination activation value stochastic
probability set activation value unit one is:
P
P (Xi = 1) = 1=(1 + e,( w X + )=T );
j

i;j

j



annealing temperature. approaches may integrated
topology-based algorithm; i.e., nodes cannot identified parts tree-like topology use one standard local algorithms.

3. Algorithm

assume model communication neighboring nodes shared memory,
multi-reader, single-writer model. also assume (for now) scheduling done
central scheduler (asynchronous) execution fair. shared memory, multireader, single-writer unit shared register called activation register. unit
may read content registers neighbors write own. Central
scheduler means units activated one time arbitrary order.1
execution said fair every unit activated infinitely often. require selfstabilization initially. Namely, algorithms may initialization step rely
initial values. Later relax assumptions examine conditions
algorithm also self-stabilized.
algorithm identifies parts network cycles (tree-like subnetworks),
optimizes free energy subnetworks. tree identified, optimized
using dynamic programming method propagates values leaves root
back.
Let us assume first network acyclic; network may directed
rooted tree. algorithm based observation given activation value (0/1)
node tree, optimal assignments adjacent nodes independent
other. particular, optimal assignment node's descendants independent
assignments ancestors. Therefore, node tree may compute two
values: G1i maximal goodness contribution subtree rooted i, including
connection i's parent whose activation one. Similarly, G0i maximal goodness
subtree, including connection i's parent whose activation value zero.
acyclicity property allow us compute node's G1i G0i simple function
children's values, implemented propagation algorithm initiated leaves.
Knowing activation value parent values G0j ; G1j children,
node compute maximal goodness subtree. information reaches
1. Standard algorithms need assume condition order guarantee convergence local
minimum (Hopfield, 1982). condition relaxed restricting adjacent nodes
activated time (mutual exclusion).

226

fiImproving Connectionist Energy Minimization

root, assign value (0/1) maximizes goodness whole network.
assignment information propagates toward leaves. Knowing activation value
parent, node compute preferred activation value itself. termination (at
stable state), tree optimized. algorithm 3 basic steps:
1.

Directing tree: knowledge propagated leaves toward center

linear number steps, every unit tree knows parent children.
2. Propagation goodness values: values (G1i G0i ), propagated
leaves root. termination, every node knows maximal goodness
subtree appropriate activation value assign given parent.
particular, root decide activation value maximize
whole tree.
3. Propagation activation values: starting root, node turn determines activation value. O(depth tree) steps, units stable
state globally maximizes goodness.
unit's activation register consists following fields: Xi: activation value;
0
Gi G1i : maximal goodness values; (Pi1 ; ::; Pij ): bit j neighbors
indicates i's parent.

3.1 Directing tree

goal algorithm inform every node role network childparent relationships. Nodes single neighbor identify leaves first
identify neighbor parent (point it). node identifies root
neighbors point toward it. node's neighbors one point toward it, node
selects one parent. Finally, node least two neighbors pointing
toward it, identifies outside tree.
problem directing tree related problem selecting leader
distributed network, selecting center tree (Korach, Rotem, & Santoro, 1984).
problem differs (from general leader selection problems) network tree.
addition, require algorithms self-stabilized. related self-stabilizing algorithm
appeared earlier (Collin, Dechter, & Katz, 1991). algorithm based finding center
tree root node therefore creates balanced trees. advantage
algorithm presented space ecient requiring O(logd) space,
maximum number neighbors node has. contrast, algorithm Collin
et al. requires O(logn), n network size.
algorithm present, unit uses one bit per neighbor keep pointing
information: Pij = 1 indicates node sees j th neighbor parent. looking
Pji , node knows whether j pointing it.
Identifying tree-like subnetworks general network may done algorithm
Figure 2.
Figure 3a, see acyclic network tree directing phase. numbers
edges represent values Pij bits. Figure 3b, tree-like subnetwork
227

fiPinkas Dechter

Tree Directing (for unit i):

1. Initialization: first time, neighbors j : Pij = 0; /* Start clear
pointers (step needed acyclic nets almost uniform versions)
2. single neighbor (j ) Pji = 0, Pij = 1; /* leaf selects
neighbor parent neighbor doesn't point */
3. else, one one neighbor (k) point (Pki = 0),
Pik = 1, rest neighbors: Pij = 0. /* k parent */

4. else, neighbors j : Pij = 0. /* Node either root outside tree */
Figure 2: Tree directing algorithm

identified inside cyclic network. Note node 5 root since neighbors
pointing toward it.
7

0

7

0
0

0

5 1

5

6

0

5

6

1 4

4

0

3
0
1

1

0

4

1

3

0

3
0
1

1

1

1

2

2

1

4

0

3

5 0

0
1

1

2

2

(a)

(b)

Figure 3: Directing tree: a) tree b) cyclic network tree-like subnetwork.

3.2 Propagation goodness values

phase every node computes goodness values G1i G0i , propagating
two values leaves root (see Figure 4).
Given node Xi , parent Xk children, children(i) tree, shown,
based energy function (1), goodness values obey following recurrence:
X
GXi = maxX 2f0;1gf
GXj + wi;k Xi Xk + Xi g


k



j 2children(i)

Consequently nonleaf node computes goodness values using goodness values
children
follows: Xk = 0, must decide P
setting Xi = 0, obtaining
P
0
goodness j Gj , setting Xi = 1, obtaining goodness j G1j + . yields:
X
X
G0i = maxf
G0j ;
G1j + g
j 2children(i)

228

j 2children(i)

fiImproving Connectionist Energy Minimization

G0 = 2
4

G1 = 3
4

X4 = 0

4

3
0
G =2
3

1
G =2
3

1

3

1

3

2

0
G =1
5

1

1
G 21 = 2

X3 = 0

5

2
G0 = 0

0

4

2

2

G1 = 2

3

5

1
G =0
5

X5 = 1

2
1

G1 = 1

2

1

X2 = 0

X1 = 1
(b)

(a)

Figure 4: a) Propagating goodness values. b) Propagating activation values.
Similarly, Xk = 1, choice Xi = 0 Xi = 1, yields:
X
X
G1i = maxf
G0j ;
G1j + wi;k + g
j 2children(i)

j 2children(i)

initial goodness values leaf nodes obtained (no children).
Thus, G0i = maxf0; ig, G1i = maxf0; wik + g.
example, unit 3 Figure 4 zero maximal goodness contributed
node 1 G01 = maxX1 2f0;1gf2X1g = 2 obtained X1 = 1. Unit 2 (when
X3 = 0) contributes G02 = maxX2 2f0;1gf,X2 g = 0 obtained X2 = 0, G12 =
maxX2 2f0;1gf3X2 , X2g = 2 obtained X2 =P1. nonleaf nodes, X4 = 0,
X3 = 0, goodnessPcontribution k G0k = 2 + 0 = 2, X3 = 1,
contribution ,3 + k G1k = ,3 + 1 + 2 = 0. maximal contribution G03 = 2
achieved X3 = 0.
Goodness values may computed every node children's goodness
values ready; however, self-stabilization (to discussed later) simplicity,
nodes may compute goodness values repeatedly without synchronization
children.

3.3 Propagation activation values

node assigned activation value, children activate
maximize goodness subtrees control. value chosen node,
children evaluate activation values, process continues whole
tree assigned.
two kinds nodes may start process: root choose
activation value optimize entire tree, non-tree node uses standard
activation function.
P
root Xi identified,Pif maximal goodness j G0j , chooses value
\0." maximal goodness j G1j + , chooses \1." summary, root chooses
value according to:
(
P G1 + P G0
1


j j
j j
Xi = 0 otherwise
229

fiPinkas Dechter

Figure 4 example, G15 + G13 + 0 = 2 < G05 + G03 = 3 therefore X4 = 0. P
internal node whose parent k chooses activation
value maximizes Pj Gxj +
P
wi;k XiXk + Xi. choice therefore, j G0j (when Xi = 0) j G1j +
wi;k Xk + (when Xi = 1), yielding:
(
P G1 + w X + P G0
i;k k

j j
j j
Xi = 10 ifotherwise


special case, leaf chooses Xi = 1 wi;k Xk ,i , exactly discrete
Hopfield activation function node single neighbor. example, Figure 4,
X5 = 1 since w4;5X4 = 0 > ,5 = ,1, X3 = 0 since G11 + G12 +2X4 + 3 = 1+2+0 , 3 =
0 < G02 + G01 = 2. Figure 4b shows activation values obtained propagating
root leaves.

3.4 complete activation function

Interleaving three algorithms described earlier achieves goal identifying tree-like
subnetworks maximizes goodness. subsection present complete
algorithm, combining three phases simplifying computation. algorithm
integrated discrete Hopfield activation function demonstrating similar
formulas are.
steps algorithm interleaved freely; i.e., scheduler might execute
step nodes steps given node (or combinations). steps
computed repeatedly synchronization node's neighbors.2 Algorithm
activate executed unit (when j denotes non-parent neighbor k denotes
parent i) given Figure 5. Algorithm activate improves arbitrary local search
connectionist algorithm following sense:

3.1 a1 local minimum generated \activate" a2 local minimum
generated local-search method (e.g., Hopfield), a1 a2 activation
values non-tree nodes, G(a1) G(a2).
Theorem

Proof: Follows immediately fact activate generates global minimum
tree-subnetworks. 2
Additional properties algorithm discussed Section 4.

3.5 example

example illustrated Figure 6 demonstrates case local minimum
standard algorithms avoided. Standard algorithms may enter local minimum
stay stable state clearly wrong.
example variation Harmony network example (Smolensky, 1986) (page
259), (McClelland, Rumelhart, & Hinton, 1986) (page 22). task network
identify words low-level line segments. Certain patterns line segments excite
2. see later, amount parallelism limited somewhat, time time
two neighboring nodes execute tree-directing step time.

230

fiImproving Connectionist Energy Minimization

Algorithm activate: Optimizing Tree-like Subnetworks (unit i):

1. Initialization: first time, (8j ) Pij = 0; /*Clear pointers (cyclic nets)*/
2. Tree directing: exists single neighbor k, Pki = 0,
Pik = 1 neighbors j , Pij = 0;
else, neighbors Pij = 0;
3. Computing P
goodness values: P
0
Gi = maxf j2neighbors(i) G0j Pji ; j 2neighbors(i) G1j Pji + g;
G1i = maxfPj2neighbors(i) G0j Pji ; Pj 2neighbors(i)(G1j Pji + wi;j Pij ) + g;
4. Assigning activation values:
least( two neighbors
pointing i, /*Not tree: use Hopfield*/
P w Xarenot
1

,


j i;j j
Xi = 0 otherwise
else, /*
root leaves) */
( Node inPa tree1 (including
0)P + wi;j Xj P j ) ,i
1

((
G
,
G
j j
j j

Xi = 0 otherwise
Figure 5: Algorithm activate unit

units represent characters, certain patterns characters excite units represent
words. line strokes used draw characters input units: L1,..., L5.
units \N," \S," \A" \T" represent characters. units \able," \nose," \time"
\cart" represent words, Hn, Hs, Ha, Ht, H1,... H4 hidden units required
Harmony model. example, given line segments character S, unit L4 activated
(input), causes units Hs \S" activated. Since \NOSE" word
contains character \S," H2 unit \nose" also activated
word \NOSE" identified.
network feedback cycles (symmetric weights) ambiguity among characters line-segments may resolved result identifying word. example, assume
line segments required recognize word \NOSE" appear, character
\N" input blurred therefore setting unit L2 ambiguous. Given
rest line segments (e.g., character \S"), network identifies word
\NOSE" activates units \nose" H2. cause unit \N" line
segments activated. Thus, ambiguity L2 resolved.
network designed global minimum L2, Hn, \N," H2 \nose"
activated. However, standard connectionist algorithms may fall local minimum
units zero, generating goodness 5 , 4 = 1. correct setting (global
minimum) found tree-optimization algorithm (with goodness: 3-1+3-1+3-1+5-14+3-1+5=13). thick arcs upper network Figure 6 mark arcs tree-like
subnetwork. tree-like subnetwork drawn pointers weights lower
part figure. Node \S" part tree activation value set one
231

fiPinkas Dechter

Hn

Hs

Ha

Ht

H1

N
L1

L2

L4
L3
Linesegments





able
Characters

4
Hn

1

H2
3

H3

H4



L5

1
3

H2

Hs

nose
time
Words

cart

cyclic subnetwork

3
5
1

1
L2

N



1

1

nose

Figure 6: Harmony network recognizing words: local minima along subtrees
avoided.
line-segments \S" activated. \S" set, units along tree
optimized (by setting one) local minimum avoided.

4. Feasibility, Convergence, Self-Stabilization

far shown enhance performance connectionist energy minimization
networks without losing much simplicity standard approaches. simple
algorithm presented limited three ways, however. First, assumes unrealistically
central scheduler used; i.e., scheduler activates units one
asynchronously. results obtained steps algorithm executes
one atomic operation neighbors mutually excluded. would like network
work correctly distributed (synchronous) scheduler, subset units
may activated execution time synchronously. Second, algorithm
guarantees convergence global optima tree-like subnetworks. would like
find algorithm converges correct solutions even cycles introduced. Finally,
would like algorithm self-stabilizing. converge legal, stable state
given enough time, even noisy uctuations cause units execute arbitrary
program states registers arbitrary content. Formally, algorithm selfstabilizing fair execution, starting input configuration program
state (of units), system reaches valid stable configuration.
section, illustrate two negative results regarding first two problems; i.e.,
feasible build uniform algorithms trees distributed scheduler,
algorithm feasible cyclic networks even central scheduler.
232

fiImproving Connectionist Energy Minimization

show weaken conditions convergence guaranteed (for tree-like
subnetworks) realistic environments self-stabilization obtained.
scheduler generate specific schedule consistent definition. Thus,
central scheduler viewed specific case distributed scheduler. say
problem impossible scheduler every possible algorithm exists
fair execution generated scheduler find solution problem.
Since specific schedules generated central scheduler also generated
distributed scheduler, impossible central scheduler also impossible
distributed scheduler.

4.1 Negative results uniform algorithms

Following Dijkstra (1974), negative results presented regarding feasibility distributed constraint satisfaction (Collin et al., 1991). Since constraint satisfaction problems
formulated energy minimization problems, feasibility results apply also
computing global minimum energy functions. completeness adapt
results connectionist computation energy minimization.
Theorem 4.1 deterministic3 uniform algorithm exists guarantees global minimum distributed scheduler, even simple chain-like trees, assuming
algorithm needs insensitive initial conditions.
Proof (By counter example): Consider network Figure 7. two global minima
possible : (11:::1101:::1) (11:::1011:::1) (when four centered digits assigned
units, , 1; i; + 1; + 2). network initialized units
register values, units start program state, exists fair
execution distributed scheduler every step units activated.
units left center (1; 2; 3; :::i) \see" input units right center
(2i; 2i , 1; 2i , 2; :::; + 1) respectively. uniformity determinism,
units pair (i; + 1); (i , 1; + 2); :::; (1; 2i) must transfer program
state produce output activation register. Thus, every step
execution, units + 1 always activation value global
minimum (where two units different values) never obtained. 2
negative result discourage us practice since relies obscure
infinite sequence executions unlikely occur random scheduler. Despite
negative result, one show algorithm activate optimize energy treelike subnetworks distributed scheduler least one following cases holds
(see next section details):
1. step 2 algorithm activate Section 3.4 atomic; i.e., neighbor may
execute step 2 time.
2. every node every neighbor j , node executed without j infinitely often
(fair exclusion);
3. one node unique acts root, is, execute step 2 (an almost
uniform algorithm);
3. proof theorem assumes determinism apply stochastic activation functions.

233

fiPinkas Dechter

1

1
1
1

1
1

2

1
1

i1

1

1
5



1

1
i+1

1

i+2

1
2i

Global Minima: 11...1101...1
11...1011...1

Figure 7: uniform algorithm exists optimize chains distributed schedulers.
4. network cyclic (one node acting root).4
Another negative result similar (Collin et al., 1991) given following theorem.
Theorem 4.2 network cyclic, deterministic uniform algorithm exists guarantees global minimum, even central scheduler, assuming algorithm needs
insensitive initial conditions.
Proof (by counter example): may proved even cyclic networks simple rings.
Figure 8 see ring-like network whose global minima (010101) (101010).
Consider fair execution central scheduler activates units 1,4,2,5,3,6
order repeats order indefinitely. Starting program state
inputs, two units every pair (1,4), (2,5), (3,6) \see" input, therefore
output transfer program state. result, units never
output different values global minimum obtained. 2
Note tree-like subnetwork cyclic network optimized even
distributed scheduler (since nodes part cycle identified roots
algorithm acts almost uniform algorithm).

4.2 Convergence self-stabilization

previous subsection proved pure distributed scheduler
hope uniform network algorithm. addition, easily show algorithm
self-stabilizing cycles introduced. example, consider configuration
pointers ring Figure 9. stable state although clearly valid
tree.5
subsection weaken requirements allowing algorithm converge correct solutions self-stabilizing realistically weaker distributed schedulers.
use notion pure distributed scheduler; instead, ask distributed
scheduler fair exclusion property.
4. Global solutions guaranteed found tree-like subnetworks optimized.
5. configuration never occur units start starting point; i.e., clearing bits P .
may happen due noise hardware uctuations.


234

fiImproving Connectionist Energy Minimization

1

1
4

3
5

3
1

3

3

1

6
3

Global Minima: 010101
101010

3
2

1

3
1

Schedule: 1, 4, 2, 5, 3, 6, 1, 4, 2, 5,......

1

Figure 8: uniform algorithm exists guarantees optimize rings even central
scheduler.

1

7

1

0

6

0

1 0

5

Figure 9: uniform algorithm self-stabilizing cyclic networks.
Definition 4.1 scheduler fair exclusion property every two neighbors, one

executed without infinitely often.
Intuitively, distributed scheduler fair exclusion longer generate infinite sequences pathological execution schedules used previous subsection prove
negative results. Instead, guaranteed time time, every two neighboring
units execute together.
alternative, might weaken requirement uniformity algorithm
(that nodes execute procedure). almost uniform algorithm
nodes perform procedure except one node marked unique.
almost uniform version algorithm activate, root tree marked executes
procedure Section 3.4 neighbors pointing it; i.e., constantly sets
Pij zero.

4.3 Algorithm activate Section 3.4 following properties: 1. converges global minimum self-stabilizing6 networks tree-like topologies
distributed scheduler fair exclusion. 2. algorithm also converges tree-like subnetworks (but self-stabilizing) network cycles. 3. self-stabilizing
topology almost uniform algorithm applied, even pure distributed
scheduler.
Theorem

6. initialization step algorithm omitted self-stabilizing version.

235

fiPinkas Dechter

proof see appendix.

5. Extensions Arbitrary Networks

algorithm presented Section 3 limited restricted nodes tree-like
subnetworks only. Nodes part cycle execute traditional activation function
may lead known drawbacks local energy minima slow convergence.
section discuss generalizations algorithm nodes part cycles,
work well near-tree networks. full account extension deferred
future work.
well known scheme extending tree algorithms non-tree networks, cycle-cutset
decomposition (Dechter, 1990), used Bayes networks constraint networks. Cyclecutset decomposition based fact instantiated variable cuts ow
information path lies therefore changes effective connectivity
network. Consequently, group instantiated variables cuts cycles
graph, (e.g., cycle-cutset), remaining network viewed cycle-free
solved tree algorithm. complexity cycle-cutset method bounded
exponentially size cutset connected component graph (Dechter,
1992). next show improve energy minimization algorithm, activate using
cycle-cutset idea.
Recall energy minimization task find zero/one assignment variables X = fX1; :::; Xng maximizes goodness function. Define Gmax(X1; :::; Xn) =
maxX1;:::;X G(X1; :::; Xn). task find activation level X1; :::; Xn satisfying
X
X
Gmax(X1; :::Xn) = maxX1 ;:::;X ( wi;j XiXj + Xi):
(2)
n

n

i<j



Let = fY1 ; :::; Ykg subset variables X = fX1; :::; Xng. maximum
computed two steps. First compute maximum goodness conditioned fixed
assignment = , maximize resulting function possible assignments .
Let Gmax(X jY = ), maximum goodness value G conditioned = . Clearly,
Gmax(X ) = maxY =y Gmax(X jY = ) = maxY =y maxfX =xjx =yg fG(X )g;


where, xY zero/one value assignments instantiation x restricted
variable subset . variables form cycle-cutset, conditional
maxima Gmax(X jY = ) computed eciently using tree algorithm. overall
maxima may achieved subsequently enumerating possible assignments .
Obviously, scheme effective cycle-cutset small. next discuss
steps towards implementing idea distributed environment.
Given network set nodes X = fX1; :::; Xng, subset cutset variables
= fY1; :::; Ykg, presumably cycle-cutset, assuming fixed, unchangeable assignment
= y, cutset variables behave like leaf nodes, namely, select neighbors
parent neighbor point them. Thus, cutset variable may several
parents zero child nodes.
Considering example network Figure 3b assuming node (7) cutset
variable, tree-directing may change node (7) points (5) (6),
236

fiImproving Connectionist Energy Minimization

(6) points (5) (5) remains root. Note modification arcs
directed resulting graph acyclic directed graph. graph directed,
regular non-cutset node exactly view before. one parent (or
parent) perhaps set child nodes, may cutset nodes.
computes goodness values activation values almost before.
algorithm along lines compute maximum energy conditioned = ,
cycle-cutset. Note however assignment guaranteed converge
local maxima original (Hopfield) activation function. cutset nodes
may unstable relative function.
Enumerating conditional maxima get global maxima cannot done distributedly, unless cutset size small. cutset small, computation
done parallel, yielding practical distributed solution networks, follows.
tree-directing part accomplished, node computes collection goodness values,
indexed conditioning assignment = . goodness values node
associated cutset assignment = computed using goodness values
child nodes also associated assignment = . maximum
number goodness values node may need carry exponential cutset size.
Upon convergence, roots trees select assignment = maximize overall goodness value propagate information tree nodes
switch values accordingly. algorithm certainly connectionist
spirit practically limited small cutsets. advantage finds true global
optimum.
following subsection, modify cutset approach towards connectionist spirit integrating cutset scheme standard energy minimizing activation
function. yields connectionist-style algorithm simple activation function
limited memory requirements identity cycle-cutset nodes known.
determine cutset variables initially using centralized algorithm computing small
cutset (Becker & Geiger, 1994). Although guaranteed find global solution, new
activation function powerful standard approaches cyclic topologies.

5.1 Local search cycle cutset

Algorithm activate-with-cutset Figure 10 assumes cutset nodes known
priori; time however, values changing using standard local techniques (e.g.,
Hopfield). algorithm well-defined also cutset nodes cut cycles
cutset minimal. However, likely work best cutset small
cuts cycles.
Note goodness value computation cutset nodes (step 4) performing
maximization operation two possible activation values cutset variables
since activation value cutset nodes fixed far tree algorithm concerned.
Intuitively, performed sequentially algorithm would iterate following
two steps: 1. finding local maximum using Hopfield activation function cutset
variables; 2. finding global maximum conditioned cutset values determined
previous step via tree algorithm. connectionist framework two steps
synchronized. Nevertheless, algorithm converge local maxima relative
237

fiPinkas Dechter

Algorithm activate-with-cutset (unit i)
Assumption: cutset nodes given priori.
1. Initialization: first time, (8j ) Pij = 0;
2. Tree directing:
cutset node, every neighbor (j ), Pji = 0, Pij = 1;
(neighbors become parents unless already point it)
else (not cutset node), exists single neighbor k, Pki = 0,
(part tree root) Pik = 1 neighbors j , Pij = 0;
else (root non-tree node), neighbors Pij = 0;
3. Assigning activation values:
neighbors
ofPi point except maybe one (i.e., part tree) then,
(
j
1
0
j ((Gj , Gj )Pj + wi;j Xj Pi ) ,i
Xi = 10 ifotherwise
else (a cutset
( nodePor node yet part tree), Compute Hopfield:
j wi;j Xj ,i
Xi = 10 ifotherwise
4. Computing goodness values: (only nodes trees need goodness values)
cutset node, neighbor j ,
G0i = Xi ,
Gji 1 = Xi (i + wij ) (G0i ; Gji 1 goodness values neighbor j ).
else (a regular P
tree node),
0
Gi = maxf j2neighbors(i) G0j Pji ; Pj 2neighbors(i) G1j Pji + ig;
G1i = maxfPj2neighbors(i) G0j Pji ; Pj 2neighbors(i)(G1j Pji + wi;j Pij ) + g;
Figure 10: Algorithm activate-with-cutset

238

fiImproving Connectionist Energy Minimization

Hopfield algorithm well conditional global maxima relative cutset variables.
Convergence follows fact tree directing algorithm guaranteed converge
given fixed cutset variables. does, node ips value either result Hopfield
step order optimize tree. steps energy increase.7
Example

5.1 following example demonstrates algorithm finds better min-

imum found standard Hopfield algorithm cycles. Consider energy function: energy = 50AB , 200BC , 100AC , 3AD , 3DE , 3AE +
0:1A + 0:1B + 0:1C + 4E + 4D. associated network consists two cycles: A; B; C
A; D; E . select node cutset node, network would cut
two acyclic (tree-like) subnetworks. Assume network starts setting zeros
(A; B; C; D; E = 0). local minimum (energy = 0) Hopfield algorithm.
activate-with-cutset algorithm breaks local minimum optimizing acyclic
subnetwork A; B; C conditioned = 0. result optimization assignment
= 0; B = 1; C = 1; = 0; E = 0 energy = ,199:7. stable state
obtains excitatory sum inputs (50) therefore ips value = 1 using
Hopfield activation algorithm. new state A; B; C = 1; D; E = 0 also local minimum Hopfield paradigm (energy = ,249:7). However, since nodes A; D; E form
tree, activate-with-cutset algorithm also manages break local minimum.
finds global solution conditioned = 1 happens global minimum
A; B; C; D; E = 1 energy = ,250:97. new algorithm capable finding
global minimum energy function managed escape two local minima
trapped Hopfield algorithm.
easy see algorithm activate-with-cutset improves activate following
sense:
Theorem 5.1 a1 local minimum generated activate a2 local minimum
generated activate-with-cutset, a1 a2 activation value
non-tree nodes then, G(a2) G(a1).

5.2 Local search changing cutset variables

imagine extension cutset scheme idea improve resulting energy level conditioning optimizing relative many cutsets.
sequential implementation algorithm move one cutset next,
improvement. process guaranteed monotonically reduce energy.
unclear however tour among cutsets implemented connectionist
environment. clear even identify one cutset distributedly. Since finding
minimal cycle-cutset NP-complete distributed algorithm problem unlikely
exist. Nevertheless, could many brute-force distributed algorithms may find
good cutset practice. Alternatively, cutset nodes may selected process
randomly designates node cutset node.
7. Fluctuations temporarily increase energy may occur time time tree propagation completely stabilized. example, node may use goodness values children
goodness values ready (but point node).

239

fiPinkas Dechter

following paragraphs outline ideas uniform connectionist algorithm
allows exploration cutset space. propose use random function
control identity cutset nodes. random process node becomes
cutset node switch cutset node regular node may governed random
heuristic function f (). non-tree node may turn cutset node probability
P = f (). cutset node may turn non-cutset node becomes part tree
random process probability P = g (). function f () designed
way assign high probabilities nodes potential become \good" cutset
nodes. probability de-selecting cutset node may defined g () = 1 , f ().
Algorithm activate-with-cutset augmented cutset selection function
running parallel three procedures (tree-directing, assigning activation
values goodness computing). Thus, may add forth procedure selects (or
de-selects) node cutset node probability P = f (). Note randomly
selected cutset perfect might many cutset nodes.
long cycles, cutset nodes selected. time, nodes
functioning long cutset nodes de-selected thus reducing chances
redundant cutset nodes continuously exploring space possible cutsets.
One way implement heuristic function f base following ideas: 1.
Increase probability non-tree nodes cutset nodes long time. 2.
Increase probability nodes ipped value long time. 3. Increase
probability nodes high connectivity.
Note de-selected cutset node may cause chain reaction undirecting nodes.
Nodes lost tree-pointers become not-part-of-tree thus potential
become cutset nodes. network may continue tour cutset space indefinitely
may never become static. selection-de-selection process may never converge. Nevertheless, function f designed allow enough time convergence cutset
changes whole process, energy tends decrease. Temporary uctuations may sometimes cause energy increase node relies yet stable
neighbors.8 conjecture heuristic function f constructed allow
trees stabilized distroyed de-selection. Formalizing algorithm's
properties investigation experimentation left future research.

6. Conclusions

main contributions paper are:
1. provide connectionist activation function (algorithm activate, Figure 5),
self-stabilizing guaranteed converge global minima linear time
tree-like networks. general networks algorithm generate global minima
tree subnetworks rest network coincide regular local
gradient activation functions (e.g., Hopfield). algorithm dominates arbitrary
local search connectionist algorithm following sense: a1 local minimum
generated activate a2 local minimum generated corresponding localsearch method, a1 a2 activation values non-tree nodes
8. example, temporarily relying old goodness values de-selected node.

240

fiImproving Connectionist Energy Minimization

(if tree set empty), energy a1 smaller equal
energy a2.
2. showed activate extended using cycle-cutset idea.
extended algorithm called activate-with-cutset (Figure 10) guaranteed converge
generate solutions least good normally better algorithm
activate. algorithm converges conditional global minima relative values
cutset variables. a1 local minima generated activate a2 local
minima generated activate-with-cutset a1 a2 activation
values cutset variables (if tree, cutset empty) energy
a2 smaller equal energy a1 . Therefore activate-with-cutset better
activate turn better regular energy-minimization connectionist
algorithm sense. third variation algorithm sketched
future investigation. idea cutset nodes randomly continuously
selected, thus allowing exploration cutset space.
3. stated two negative results: 1) pure distributed scheduler uniform
algorithm exists globally optimize even simple chain-like networks. 2) uniform
algorithm exists globally optimize simple cyclic networks (rings) even
central scheduler. conjecture negative results significant
practical importance since realistic schedulers probability infinite
pathological scheduling scenarios approaches zero. showed algorithm
converges correctly (on tree-like subnetworks) demand pure distributed
schedulers somewhat relaxed; i.e., adding either fair exclusion, almost uniformity
cycles. Similarly, self-stabilization obtained acyclic networks
requirement uniform algorithm relaxed (almost uniformity).
negative results apply connectionist algorithms well parallel versions
local repair search techniques. positive results suggest improvements connectionist activation functions local repair techniques.
conclude discussion two domains likely produce sparse, neartree networks thus benefit algorithms presented: inheritance networks
diagnosis.
Inheritance straightforward example application translations symbolic rules energy terms form networks mostly cycle free. arc
inheritance network, ISA B B modeled energy term , AB .
connectionist network represents complete inheritance graph obtained
summing energy terms correspond ISA relationships
graph. Nonmonotonicity expressed add penalties arcs use semantics
discussed Pinkas (1991b, 1995). Nonmonotonic relationships may cause cycles
inheritance graph connectionist network (e.g. Penguin ISA Bird; Bird ISA
FlyingAnimal; Penguin ISA not(FlyingAnimal)). Multiple inheritance may cause cycles
well, even rules monotonic (e.g., Dolphin ISA Fish; Dolphin ISA Mammal;
Fish ISA Animal; Mammal ISA Animal). Arbitrary constraints nodes graph
may introduced model. Constraints may represented proposition logic formulas translated energy terms (Pinkas, 1991) potentially causing cycles.
241

fiPinkas Dechter

\pure" inheritance network multiple inherited nodes nonmonotonic relationships, network cycle-free processed eciently various algorithms.
allow multiple inheritance, nonmonotonicity, arbitrary propositional constraints,
may introduce cycles network generated. Nevertheless, reasonable
assume large practical inheritance domains cycles (multiple inheritance, nonmonotonicity arbitrary constraints) scarcely introduced exist may
handled extension using cycle-cutset idea.
Another potential application generate mostly cycle-free subnetworks diagnosis. possible formulation diagnosis framework. Let X1; X2; :::Xn
True(1)/false(0) propositions represent symptoms hypotheses. diagnosis
application may diagnosis rules form: (ff1X 1; ff2X2 ; :::; ffmXm ! fiX ).
rules announce symptoms X1; :::; Xm importance factors ff1 ; :::; ffm,
suggest hypothesis X sensitivity fi . subset symptoms may enough
suggest hypothesis sum importance factors active symptoms
larger sensitivity fi . Intuitively, larger sum factors, larger
thePsupport thePhypothesis. corresponding energy function diagnosis rule
mi ,ffi Xi X + mi ffi Xi + fiX . addition, arbitrary propositional constraints may
also added, like (X ! Xi) i.e., hypothesis X holds, symptom Xi.
(X1 ! (:X2 ^ :X3 ) ^ X2 ! (:X1 ^ :X3) ^ X3 ! (:X1 ^ :X2)) i.e., one
propositions X1 ; X2; X3 true (mutual exclusion). propositional logic formula
allowed nonmonotonicity may expressed using con icting constraints (augmented
importance factors). Quadratic energy functions may generated arbitrary
propositional constraints introducing hidden variables (Pinkas, 1991).
Sparseness networks emerges result assuming conditional independency
symptoms relative hypothesis. Independency assumptions kind (that makes
computation tractable) quite common actual implementations Bayes networks,
uence diagrams (Pearl, 1988), certainty propagation rule-based expert systems
(Shortliffe, 1976). knowledge base consists diagnosis rules (and maybe
corresponding X ! Xi rules) symptoms independent other,
cycles network, tree algorithm converges global maximum
linear time. add dependent symptoms affect hypothesis
one path; e.g., X1 ! X , X1 ! X2 ! ::: ! X , start adding arbitrary
constraints, cycles added. dependent symptoms arbitrary constraints
scarcely added, network generated likely lend eciently
activate-with-cutset algorithm.
Abandonment ecient algorithms exists inheritance diagnosis
tractable forms. algorithm offers solve eciently tractable versions problem approximate intractable versions massively parallel, simple implement
methods. eciency suggested process depends \closeness" problem
ideal, tractable form.

A. Appendix

Proof sketch theorem 4.3: second third phases algorithm adaptations
existing dynamic programming algorithm (Bertele & Brioschi, 1972), cor242

fiImproving Connectionist Energy Minimization

rectness therefore proved here. self-stabilization steps obvious
variables initialized. proof therefore dependent convergence tree
directing phase.
Let us first assume scheduler distributed fair exclusion
network tree. first part theorem proved points 1-4. want show
tree-directing algorithm converges, self-stabilizing final stable
result pointers Pij represent tree. Points 5 6 prove parts 2 3
theorem. node called legal either root (i.e., neighbors legal, point
doesn't point them), intermediate node (i.e., points one
neighbors rest neighbors legal point back). node called
candidate illegal node neighbors one pointing it. would
like show that:
1. property legal stable; i.e., node becomes legal stay legal.
2. state number illegal nodes k > 0, leads state number
illegal nodes less k; i.e., number illegal nodes decreases eventually
nodes turn legal.
3. nodes legal graph marked tree.
4. algorithm self-stabilizing trees.
5. algorithm converges even graph cycles (part 2 theorem).
6. algorithm self-stabilizing arbitrary networks almost uniform version
used, even distributed scheduler (part 3 theorem).
prove points.
1. Show legal state stable. Assume legal node becomes illegal. either
root node one children became illegal, intermediate node whose one
children became illegal (it cannot parent suddenly points
one children stopped pointing still legal). Therefore, must
chain i1 ; i2; :::; ik nodes became illegal. Since cycles, must
leaf legal turned illegal. cannot occur since leaf
children; leading contradiction.
2. Show illegal nodes, number reduced. prove claim
need three steps:
(a) Show eventually, illegals, also candidates.
fair exclusion, eventually state reached node
executed least once. Assume least one node illegal,
illegal nodes candidates. node illegal candidate,
either root-type (all point it) least one children
illegal, least two neighbors illegal. Suppose
root-type illegal nodes. illegal nodes least two
243

fiPinkas Dechter

illegal neighbors. Therefore must cycle connects illegal nodes
(contradiction). Therefore, one illegal nodes must root-type. Suppose
root-type illegal node. must neighbor j illegal. Consider
subtree j include i: must contain illegal nodes.
root-type illegal nodes get contradiction again. However,
root-type node, eliminate look subtree illegal j 0
include j . Eventually, since network finite, obtain subtree
root-like illegal nodes includes illegal nodes. leads
contradiction. conclusion must candidates
illegal nodes.
(b) Show candidate stable unless becomes legal.
node candidate, legal children remain legal. three
types candidate nodes (node j illegal neighbor i):
i. node j points i;
ii. pointer goes directions;
iii. pointer j vice-versa.
possible changes pointers Pij Pji cause remain candidate
turn legal (the rest pointers changed).
(c) Show every candidate node eventually turn legal: Assume j illegal
neighbor candidate i. next execution without j (fair exclusion),
Pji = 0 becomes legal pointing j ; otherwise, becomes root-type
candidate (all neighbors point it) j illegal. prove
illegal node j points eventually state reached either
j legal Pji = 0, proposition stable holds.
statement true executed eventually, j legal i0
neighbors legal therefore turns legal. j illegal Pji = 0,
point (Pij = 1) making legal.
next prove j illegal node pointing state
either j legal Pji = 0, state stable. prove induction
size subtree j include i.
Base step: j leaf j points time j executed (without
i) Pij = 0, node j points becomes legal; otherwise, j updates Pji = 0.
status stable legal state stable since leaf point
node turns legal.
Induction step: Assume hypothesis True trees size less n. Suppose j
illegal neighbor i. Node j points j1 ; :::; jk neighbors.
assume nodes executed least one time, since j points
assume last execution j neighbors j1 ; :::; jk
pointed j . subtrees rooted jl (not including j ) size less n
therefore hypothesis state nodes j1 ; :::; jk
either legal Pjj = 0. state stable, eventually j executed,
either point turning legal (if j1; :::; jk pointing it),
make Pji = 0 (if neighbors point it). Since status
l

244

fiImproving Connectionist Energy Minimization

j1; :::; jk stable point, whenever j executed either become legal

3.

4.

5.

6.

pointers become zero.
Show nodes legal graph marked tree: node
legal, children legal point it. Therefore node represents
subtree (if leaf) one parent most. show
one root make following argument. several roots exist,
connectivity, one node shared least two subtrees
therefore two parents (contradiction).
algorithm self-stabilizing cycle-free networks since initialization needed
(in proof haven't use first initialization step; i.e., Pij = 0). case
cycles exist need step. pointers get initial values
algorithm still converges.
algorithm (with Pij = 0 initialization) converges even graph cycles.
Since nodes start zero pointers, (pseudo) root tree-like subnetwork
never point toward neighbors (since part cycle
neighbors one must legal).
Show algorithm self-stabilizing arbitrary networks almost uniform
version used, even distributed scheduler. need show candidate
eventually turn legal even neighbors executed time.
Suppose node candidate node j illegal neighbor:
(a) j root, never point i, therefore eventually turn
legal pointing j .
(b) root, Pij = 0, j becomes legal point making
legal. Node j turn eventually legal using following induction (on size
subtree j ):
Hypothesis: subtree without node acts root, illegal nodes
eventually turn legal.
Base step: j leaf, point eventually neighbor turn
make j legal Pij = 0.
Induction step: j1 ; :::; jk neighbors j , eventually
turn legal (induction hypothesis) pointing j . Eventually j executed
also turns legal.
(c) Suppose neither j roots, one part cycle (and
therefore part subtree include node marked root).
Using induction, nodes subtree eventually turn legal.
result either j eventually turns legal, therefore eventually
turn legal well.

2

245

fiPinkas Dechter

7. Acknowledgement

work supported part NSF grant IRI-9157636, Air Force Oce Scientific
Research, AFOSR 900136, Toshiba America Xerox grant. would also
like thank Kalev Kask commenting latest version manuscript, Kaoru
Mulvihill drawing figures, Lynn Haris editing anonymous reviewers
helped improve final version paper. shorter version paper appears
earlier (Pinkas & Dechter, 1992).

References

Ballard, D. H., Gardner, P. C., & Srinivas, M. A. (1986). Graph problems connectionist
architectures. Tech. rep. 167, University Rochester.
Becker, A., & Geiger, D. (1994). Approximation algorithms loop cutset problems.
Proceedings 10th conference Uncertainty Artificial Intelligence (UAI-94),
pp. 60{68 Seattle, Washington.
Bertele, U., & Brioschi, F. (1972). Nonserial Dynamic Programming. Academic Press, New
York.
Brandt, R. D., Wang, Y., Laub, A. J., & Mitra, S. K. (1988). Alternative networks
solving traveling salesman problem list-matching problem. IEEE International Conference Neural Networks, 2, 333{340.
Collin, Z., Dechter, R., & Katz, S. (1991). feasibility distributed constraint
satisfaction. Proceedings IJCAI Sydney.
Dechter, R. (1990). Enhancement schemes constraint processing: Backjumping, learning
cutset decomposition. Artificial Intelligence, 41(3), 273{312.
Dechter, R. (1992). Constraint networks. Encyclopedia Artificial Intelligence, 2nd ed.,
pp. 276{285. John Wiley & Sons, Inc.
Dechter, R., Dechter, A., & Pearl, J. (1990). Optimization constraint networks.
R.M. Oliver, J. S. (Ed.), uence diagrams, belief nets decision analysis. John
Wiley Sons.
Feldman, J. A., & Ballard, D. H. (1982). Connectionist models properties. Cognitive Science 6.
Hinton, G., & Sejnowski, T. (1986). Learning re-learning boltzmann machines.
Parallel Distributed Processing: Explorations Microstructure Cognition I,
J. L. McClelland D. E. Rumelhart, pp. 282{317. MIT Press, Cambridge, MA.
Hopfield, J. J. (1982). Neural networks physical systems emergent collective
computational abilities. Proceedings National Academy Sciences 79, pp.
2554{2558.
246

fiImproving Connectionist Energy Minimization

Hopfield, J. J. (1984). Neurons graded response collective computational properties like two-state neurons. Proceedings National Academy
Sciences 81, pp. 3088{3092.
Hopfield, J. J., & Tank, D. W. (1985). Neural computation decisions optimization
problems. Biological Cybernetics, 52, 144{152.
Kasif, S., Banerjee, S., Delcher, A., & Sullivan, G. (1989). results computational complexity symmetric connectionist networks. Tech. rep. JHU/CS-89/10,
Department Computer Science, John Hopkins University.
Korach, K., Rotem, D., & Santoro, N. (1984). Distributed algorithms finding centers
medians networks. ACM Transactions Programming Languages Systems,
6(3), 380{401.
McClelland, J. L., Rumelhart, D. E., & Hinton, G. (1986). appeal pdp. J. L.
McClelland D. E. Rumelhart, Parallel Distributed Processing: Explorations
Microstructure Cognition I. MIT Press, Cambridge, MA.
Minton, S., Johnson, M. D., & Phillips, A. B. (1990). Solving large scale constraint satisfaction scheduling problems using heuristic repair method. Proceedings
Eighth Conference Artificial Intelligence, pp. 17{24.
Papadimitriou, C., Shaffer, A., & Yannakakis, M. (1990). complexity local search.
ACM Symposium Theory Computation, 438{445.
Pearl, J. (1988). Probabilistic Reasoning Intelligent Systems: Networks Plausible
Inference. Morgan Kaufmann Publishers, San Mateo, California.
Peterson, C., & Hartman, E. (1989). Explorations mean field theory learning algorithm.
Neural Networks 2, 6.
Pinkas, G. (1991). Energy minimization satisfiability propositional calculus.
Neural Computation 3, 2.
Pinkas, G., & Dechter, R. (1992). new improved activation function energy minimization. Proceedings Tenth National Conference Artificial Intelligence
(AAAI), pp. 434{439 San Jose.
Rumelhart, D. E., Hinton, G. E., & McClelland, J. L. (1986). general framework
parallel distributed processing. J. L. McClelland D. E. Rumelhart, Parallel
Distributed Processing: Explorations Microstructure Cognition I. MIT Press,
Cambridge, MA.
Selman, B., Levesque, H., & Mitchell, D. (1992). new method solving hard satisfiability
problems. Proceedings Tenth National Conference Artificial Intelligence,
pp. 440{446.
Shortliffe, E. H. (1976). Computer-Based Medical Consultation, Mycin. Elsevier, New York.
247

fiPinkas Dechter

Smolensky, P. (1986). Information processing dynamical systems: Foundations harmony theory. J. L. McClelland D. E. Rumelhart, Parallel Distributed Processing: Explorations Microstructure Cognition I. MIT Press, Cambridge,
MA.

248

fiJournal Artificial Intelligence Research 3 (1995) 383-403

Submitted 6/95; published 12/95

Rule-based Machine Learning Methods Functional
Prediction

Sholom M. Weiss

weiss@cs.rutgers.edu

Nitin Indurkhya

nitin@cs.usyd.edu.au

Department Computer Science, Rutgers University
New Brunswick, New Jersey 08903, USA
Department Computer Science, University Sydney
Sydney, NSW 2006, AUSTRALIA

Abstract

describe machine learning method predicting value real-valued function, given values multiple input variables. method induces solutions
samples form ordered disjunctive normal form (DNF) decision rules. central
objective method representation induction compact, easily interpretable
solutions. rule-based decision model extended search eciently similar cases prior approximating function values. Experimental results real-world data
demonstrate new techniques competitive existing machine learning
statistical methods sometimes yield superior regression performance.

1. Introduction
problem approximating values continuous variable described statistical literature regression. Given samples output (response) variable input
(predictor) variables x = fx1 :::xn g, regression task find mapping = f(x). Relative space possibilities, finite samples far complete, predefined
model needed concisely map x y. Accuracy prediction, i.e. generalization new
cases, primary concern. Regression differs classification output variable regression problems continuous, whereas classification strictly categorical.
perspective, classification thought subcategory regression.
machine learning researchers emphasized connection describing regression
\learning classify among continuous classes" (Quinlan, 1993).
traditional approach problem classical linear least-squares regression
(Scheffe, 1959). Developed refined many years, linear regression proven quite
effective many real-world applications. Clearly elegant computationally simple linear model limits, complex models may fit data better.
increasing computational power computers larger volumes data, interest grown pursuing alternative nonlinear regression methods. Nonlinear regression
models explored statistics research community many new effective
methods emerged (Efron, 1988), including projection pursuit (Friedman & Stuetzle,
1981) MARS (Friedman, 1991). Methods nonlinear regression also developed outside mainstream statistics research community. neural network trained
back-propagation (McClelland & Rumelhart, 1988) one model. models
c 1995 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiWeiss & Indurkhya
found numerical analysis (Girosi & Poggio, 1990). overview many different
regression models, application classification, available literature (Ripley,
1993). methods produce solutions terms weighted models.
real-world, classification problems commonly encountered regression problems. accounts greater attention paid classification regression. many important problems real world regression type.
instance, problems involving time-series usually involve prediction real values. Besides
fact regression problems important own, another reason need
focus regression regression methods used solve classification problems.
example, neural networks often applied classification problems.
issue interpretable solutions important consideration leading
development \symbolic learning methods." popular format interpretable solutions
disjunctive normal form (DNF) model (Weiss & Indurkhya, 1993a). Decision trees
rules examples DNF models. Decision rules similar characteristics decision
trees, also potential advantages: (a) stronger model (b) often better
explanatory capabilities. Unlike trees, DNF rules need mutually exclusive. Thus,
solution space includes tree solutions. rules potentially compact
predictive trees. Decision rules may also offer greater explanatory capabilities
trees tree grows size, interpretability diminishes.
Among symbolic learning methods, decision tree induction, using recursive partitioning, highly developed. Many methods developed within machine learning
community, ID3 decision tree induction (Quinlan, 1986), applied exclusively classification tasks. Less widely known decision trees also effective
regression. CART program, developed statistical research community, induces classification regression trees (Breiman, Friedman, Olshen, & Stone, 1984).
regression trees strictly binary trees, representation naturally follows
intensive modeling using continuous variables.1
terms performance, regression trees often competitive performance
regression methods (Breiman et al., 1984). Regression trees noted particularly
strong many higher order dependencies among input variables (Friedman,
1991). advantages regression tree model similar advantages enjoyed
classification trees models. Two principal advantages cited: (a) dynamic
feature selection (b) explanatory capabilities. Tree induction methods extremely
effective finding key attributes high dimensional applications. applications,
key features small subset original feature set. Another characteristic
decision trees often cited capability explanation terms acceptable
people. negative side, decision trees cannot represent compactly many simple
functions, example linear functions. second weakness regression tree
model discrete, yet predicts continuous variable. function approximation,
expectation smooth continuous function, decision tree provides discrete regions
discontinuous boundaries. though, regression trees often produce
strong results, many applications advantages strongly outweigh potential
disadvantages.
1. comparative study (Fayyad & Irani, 1992) suggests binary classification trees somewhat
predictive even categorical variables.

384

fiRule-based Functional Prediction
paper describe new method inducing regression rules. method
takes advantage close relationship classification regression provides
uniform general model dealing problems. Additional gains obtained
extending method manner preserves strengths partitioning
schemes compensating weaknesses. Rules used search
relevant cases, subset cases help determine function value. Thus,
model's interpretability traded better performance. Empirical
results suggest methods effective induce solutions often
superior decision trees.

2. Measuring Performance

objective regression minimize distance sample output values,
yi predicted values yi . Two measures distance commonly used. classical
regression measure equation 1, average squared distance yi yi , i.e.
variance. leads elegant formulation linear least squares model. mean
absolute distance (deviation) equation 2 used least absolute deviation regression,
perhaps intuitive measure.
mean absolute distance (deviation) equation 2 used studies.
measure average error prediction yi n cases.
0

0

Xn (yi , yi)2
i=1
n
X
MAD = 1 jyi , yi j

V ariance = n1

0

(1)

(2)
n i=1
regression problem sometimes described signal noise problem. model
extended include stochastic component equation 3. Thus, true function may
produce zero error distance. contrast classification labels assumed
correct, regression predicted values could explained number factors
including random noise component, , signal, y.
0

= f (x1 : : : xn) +
(3)
prediction primary concern, estimates based training cases alone
inadequate. principles predicting performance new cases analogous
classification, mean absolute distance used error rate. best
estimate true performance model error rate large set independent test
cases. large samples data unavailable, process train test simulated
random resampling. experiments, used (10-fold) cross-validation
estimate predictive performance.

3. Regression Tree Induction

section, contrast regression tree induction classification tree induction. Like
classification trees, regression trees induced recursive partitioning. solution takes
385

fiWeiss & Indurkhya
form equation 4, Ri disjoint regions, ki constant values, yji refers
y-values training cases fall within region Ri .

x Ri f (x) = ki = medianfyji g
(4)
Regression trees representation classification trees except terminal nodes. decision terminal node assign case constant value.
single best constant value median training cases falling terminal node
partition, median minimizer mean absolute distance. Figure 1
example binary regression tree. cases reaching shaded terminal node 1 (x13)
assigned constant value y=10.
1
x1<=3

x1>3

1

2

y=10

x2<=1

x2>1

2

3

y=2

y=5

Figure 1: Example Regression Tree
Tree induction methods usually proceed (a) finding covering set training
cases (b) pruning tree best size. Although classification trees
widely studied, similar approach applied regression trees. assume
reader familiar classification trees, cite differences binary
tree induction (Breiman et al., 1984; Quinlan, 1986; Weiss & Kulikowski, 1991). many
respects, regression tree induction straightforward. classification trees, error
rate poor choice node splitting, alternative functions entropy gini
employed. regression tree induction, minimized function, i.e. absolute distance,
satisfactory. node, single best split minimizes mean absolute
distance selected. Splitting continues fewer minimum number cases
covered node, cases within node identical value y.
goal find tree generalizes best new cases, often
full covering tree, particularly presence noise weak features. pruning strategies
employed classification trees equally valid regression trees. Like covering
procedures, substantial difference error rate measured terms
mean absolute distance. One popular method weakest-link pruning strategy (Breiman
et al., 1984). weakest-link pruning, tree recursively pruned ratio delta/n
minimized, n number pruned nodes delta increase error.
386

fiRule-based Functional Prediction
x13 ! y=10
x21 ! y=2
Otherwise y=5
Figure 2: Example Regression Rules
Weakest link pruning several desirable characteristics: (a) prunes training cases
only, remaining test cases relatively independent (b) compatible
resampling.

4. Regression Rule Induction
tree rule induction models find solutions disjunctive normal form, model
equation 4 applicable both. rule rule-set represents single partition
region Ri . However, unlike tree regions, regions rules need disjoint.
non-disjoint regions, several rules may satisfied single sample. mechanism
needed resolve con icts ki , constant values assigned, multiple rules,
Ri regions, invoked. One standard model (Weiss & Indurkhya, 1993a) order
rules. ordered rule-sets also referred decision lists. first rule
satisfied selected, equation 5.

< j x Ri Rj f (x) = ki
(5)
Figure 2 example ordered rule-set corresponding tree Figure 1.
cases satisfying rule 3, rules 1 2, assigned value y=5.
Given model regression rule sets, problem find procedures effectively
induce solutions. rule-based regression, covering strategy analogous classification tree strategy could specified. rule could induced adding single component
time, added component single best minimizer distance. usual,
constant value ki median region formed current rule. rule
extended, fewer cases covered. fewer minimal number cases covered,
rule extension terminates. covered cases removed rule induction continue
remaining cases. also regression analogue rule induction procedures
classification (Michalski, Mozetic, Hong, & Lavrac, 1986; Clark & Niblett, 1989).
However, instead approach, propose novel strategy mapping regression
covering problem classification problem.

4.1 Reformulation Regression Problem

motivation mapping regression classification based number factors
related extra information given regression problem: natural ordering yi
magnitude: > j yi > yj .
Let fCi g set consisting arbitrary number classes, class containing
approximately equal values fyi g. solve classification problem, expect
classes different other, patterns found distinguish
387

fiWeiss & Indurkhya
1. Generate set Pseudo-classes using P-class algorithm (Figure 4).
2. Generate covering rule-set transformed classification
problem using rule induction method Swap-1
(Weiss & Indurkhya, 1993a).
3. Initialize current rule set covering rule set save it.
4. current rule set pruned, iteratively following:
a) Prune current rule set.
b) Optimize pruned rule set (Figure 5) save it.
c) Make pruned rule set new current rule set.
5. Use test cases cross-validation pick best saved rule sets.
Figure 3: Overview Method Learning Regression Rules
classes. expect classes formed ordering fyi g reasonable classification problem? numbers reasons answer yes, particularly
rule induction procedure.
obvious situation classical linear relationship. instance,
definition, ordering fx1i . . . xni g corresponds ordering yi . Although classical
methods strong compactly determining linear functions, interest modern
methods centers around potential finding nonlinear relationships. nonlinear
functions, know usually ordering fx1i . . . xni g corresponding
fyig. Still, expect true function smooth, local region ordering
relationship hold. terms classification, know class Cj similar values
quite different class Ck much lower values y. nonlinear function
within class similar values y, similar values fx1i . . . xni g.
correspond local region function. However, also true
identical values different fx1i . . . xni g multiple clusters
found within class. rule induction methods cover class single
rule, expectation multiple patterns found cover clusters.
cases assigned (pseudo-)classes, classification problem
solved following stages: (a) find covering set (b) prune rule set
appropriate size, improved results achieved additional technique considered:
(c) refine optimize rule set. overall method outlined Figure 3.

4.2 Generating Pseudo-classes
previous section, described motivation pseudo-classes. specification
classes use information beyond ordering y. assumptions
true nature underlying function made. Within environment,
goal make values within one class similar values across classes
dissimilar. wish assign values classes overall distance
yi class mean minimum.
388

fiRule-based Functional Prediction
Input: fyi g set output values
Initialize n := number cases, k := number classes
Classi
Classi := next n/k cases list sorted values
end-for
Compute Errnew
Repeat
Errold = Errnew
Casej
Classi
1. Dist[Casej , Mean(Classi,1 )] < Dist[Casej , Mean(Classi )]
Move Casej Classi,1
2. Dist[Casej , Mean(Classi+1 )] < Dist[Casej , Mean(Classi )]
Move Casej Classi+1
Next Casej
Compute Errnew
Errnew less Errold
Figure 4: Composing Pseudo-Classes (P-Class)
Figure 4 describes algorithm (P-Class) assigning values fyi g k classes. Essentially algorithm following: (a) sorts values; (b) assigns approximately
equal numbers contiguous sorted yi class; (c) moves yi contiguous class
reduces global distance Err yi mean assigned class.
Classes identical means merged. P-Class variation k-means clustering, statistical method minimizes distance measure (Hartigan & Wong, 1979).
Alternative methods depend distance measures (Lebowitz, 1985) may also
used.
Given fixed number k classes, procedure relatively quickly assign yi
classes overall distances minimized. underlying function
unknown, critical global minimum assignment yi. procedure
matches well stated goals ordering yi values. obvious remaining question
determine k, number classes? Unfortunately, direct answer,
experimentation necessary. However, shall see Section 7, empirical
evidence suggesting results quite similar within local neighborhood values
k. Moreover, relatively large values k, entail increased computational complexity
rule induction, typically necessary noise-free functions modeled
exactly. Analogous comparisons neural nets increasing numbers hidden units,
trends increasing numbers partitions become evident experimentation.
One additional variation classification theme arises rule induction schemes
cover one class time. classes must ordered, last class typically
389

fiWeiss & Indurkhya
becomes default class cover situations rule classes satisfied.
regression, one default partition class unlikely best covering solution,
instead remaining cases last class repeatedly partitioned (by P-Class)
2 classes fewer cases remain.
interesting characteristic transformation regression problem
uniform general model relates classification
regression. yi values discrete categorical, P-Class merely restates standard
classification problem. example, values yi either 0 1, result
P-Class 2 non-empty classes.

4.3 Covering Rule Set
transformation, rule induction algorithms classification applied.
consider induction methods fully cover class moving induce
rules next class. step covering algorithm, problem considered
binary classification problem current class Ci versus Cj j > i, i.e.
current class versus remaining classes. rule induced, corresponding cases
removed remaining cases considered. class covered,
next class considered. example covering algorithm used Swap-1
(Weiss & Indurkhya, 1993a), procedure used paper. covering
method identical classification regression. However, one distinction
regression classes transient labels replaced median values
cases covered induced rule. rules ordered multiple rules
may satisfied, medians derived instances rule
first satisfied.
Although procedure may yield good, compact covering sets, additional procedures
necessary complete solution.

4.4 Pruning Rule Set
Typical real-world applications noisy features fully predictive. covering
set, particularly one composed many continuous variables, far over-specialized
produce best results. classification, relatively classes specified advance.
regression, expect many smaller groups values yi likely quite
different.
noted earlier regression trees usual classification pruning techniques
applied substitution mean absolute distance classification error rate.
weakest-link tree pruning, ratio delta/n recursively minimized
weakest-link rule pruning. intuitive rationale remove parts rule set
least impact increasing error. Pruning rule sets usually accomplished
either deleting complete rules single rule components (Quinlan, 1987; Weiss & Indurkhya,
1993a). general, rule pruning (for classification regression) less natural
far computationally expensive tree pruning. Tree pruning natural ow
set subset. Thus tree pruned bottom up, typically considering
effect removing subtree. Non-disjoint rules natural pruning order,
390

fiRule-based Functional Prediction
example every component rule candidate pruning may affect rules
follow specified rule order.
major difference pruning regression rules vs. classification rules.
classification, deleting rule rule component effect class labels.
regression, pruning change median-values regions. Even deletion
rule affect region medians rules ordered multiple rules may
satisfied. characteristic rule pruning regression adds substantial complexity
task. However, assuming median-values remain unchanged
evaluation candidate rules prune, pruning procedure achieve reasonable
computational eciency expense loss accuracy evaluation.
best rule component deletion selected, medians regions
re-evaluated.
Even classification rules, rule pruning inherent weaknesses. example,
rule deletion often create gap coverage. classification rules though, quite
feasible develop additional procedure refine optimize rule set. large
extent, overcomes cited weakness pruned rules sets. similar refinement
optimization procedure developed regression described next.

4.5 Rule Refinement Optimization

Given rule set RSi , improved? question applies rule set, although
mostly motivated trying improve pruned rules sets fRSo . . . RSi . . . RSng.
combinatorial optimization problem. Using error measure Err(RS), improve
RSi without changing size, i.e. number rules components? Figure 5 describes
algorithm minimizes Err(RS), MAD model prediction sample cases,
local swapping, i.e. replacing single rule component best alternative.
variation techniques used Swap-1 (Weiss & Indurkhya, 1993a).
central theme hold model configuration constant make single local
improvement configuration. Local modifications made improvements possible. Making local changes configuration widely-used optimization
technique approximate global optimum applied quite successfully,
example find near-optimum solutions traveling salesman problems (Lin & Kernighan,
1973). analogous local optimization technique, called backfitting, used
context nonlinear statistical regression (Hastie & Tibshirani, 1990).
Variations selection next improvement move could include:
1. First local improvement encountered (such backfitting)
2. Best local improvement (such Swap-1)
experiments rule induction methods, results consistently better
(2); (1) ecient, (pruned) rule induction environment mostly stable
relatively local improvements prior convergence. less stable environment,
large numbers possible configuration changes, (2) may feasible even better.
pruned rule set environment, covering procedure effective, pruned
solution relatively close local minimum solution. Weakest-link pruning
391

fiWeiss & Indurkhya
Input: RS rule set consisting rules Ri ,
set training cases
:= TRUE
(D TRUE)
RSnew := RS single best replacement
component RS reduces Err(RS)
cases using current Median(Ri )
replacement found
:= FALSE
else
RS := RSnew ; recompute Medians(Ri )
endwhile
return rule set RS
Figure 5: Optimization Rule Component Swapping
results series pruned rule sets RSi number far fewer sets would
result single prune rule rule component. RSi optimized prior
continuing pruning process. However, rule set optimization usually suspended
substantial segments covering set already pruned.
(1) used, either sequentially ordered evaluations (as backfitting) stochastic evaluations considered. Empirical evidence optimization literature supports superiority stochastic evaluation (Jacoby, Kowalik, & Pizzo, 1972).
improvements may obtained occasionally making random changes configuration
(Kirpatrick, Gelatt, & Vecchi, 1983). general combinatorial optimization techniques must substantially reworked fit specific problem type. expected
applied throughout problem solving.
result pruning covering rule set, RSo , series progressively smaller rule
sets fRSo . . . RSi . . . RSn g. objective pick best one, usually form
error estimation. Model complexity future performance highly related.
complex simple model yield poor results, objective find
right size model. Independent test cases resampling cross-validation effective
estimating future performance. absence estimates, approximations,
GCV (Craven & Wahba, 1979; Friedman, 1991), described equation 6,
used statistics literature estimate performance2. measures training error
model complexity used estimates. C(M), measure model complexity
expressed terms parameters estimated (such number weights neural net)
tests performed, C(M) assumed less n, number cases.
2. GCV acronym generalized cross-validation, apparent error training cases used
true cross-validation resampling.

392

fiRule-based Functional Prediction

Xn
GCV (M ) =

jy ,y j
0





n
C(M)
i=1 1 , n

(6)

experiments used cross-validated estimates guide final model selection
process, measures GCV may also used.

4.6 Potential Problems Rule-based Regression

Regression rules, like trees, induced recursive partitioning methods approximate function constant-value regions. relatively strong dynamic feature
selection high-dimensional applications, sometimes using highly predictive
features. essential weakness methods approximation partition
region constant value. continuous function even moderately sized sample,
approximation lead increased error.
deal limitation, instead constant-value functions, linear functions
substituted partition (Quinlan, 1993). However, linear function obvious
weakness true function may far linear even restricted context
single region. general, use linearity compromises highly non-parametric
nature DNF model. better strategy might examine alternative non-linear
methods.

5. Alternative Rules: k-Nearest Neighbors
k-nearest neighbor method one simplest regression methods, relying table
lookup. classify unknown case x, k cases closest new case
found sample data base stored cases. predicted y(x) equation 7 mean
values k-nearest neighbors. nearest neighbors found distance
metric euclidean distance (usually feature normalization). method
non-parametric highly non-linear nature

yknn(x) = K1

XK yk K nearest neighbours x

k=1

(7)

major problem approach limit effect irrelevant features.
limited forms feature selection sometimes employed preprocessing stage,
method cannot determine features weighted others.
result, procedure sensitive distance measure used. high-dimensional
feature space, k-nearest neighbor methods may perform poorly. limitations
precisely partitioning methods address. Thus, theory, two methods
potentially complement one another.

6. Model Combination

practice, one learning model always superior others, learning strategy
examines results different models may better. Moreover, combining
393

fiWeiss & Indurkhya
different models, enhanced results may achieved. general approach combining
learning models scheme referred stacking (Wolpert, 1992). Additional studies
performed applying scheme regression problems (Breiman, 1993; LeBlanc &
Tibshirani, 1993). Using small training samples simulated data, linear combinations
regression methods, improved results reported. Let Mi i-th model trained
sample, wi , weight given Mi .3 new case vector
x, predictions different models combined Equation 8 produce
estimate y. models may use representation, k-nearest neighbors
variable-size k, perhaps variable-size decision trees. models could also completely
different, combining decision trees linear regression models. Different models
applied independently find solutions, later weighted vote taken reach
combined solution. method model combination contrast usual approach
evaluation different models, single best performing model selected.

y=

XK wkMk(x)

k=1

(8)

stacking shown give improved results simulated data, major
drawback properties combined models retained. Thus interpretable models combined, result may interpretable all. also
possible compensate weaknesses one model introducing another model
controlled fashion.
suggested earlier, partitioning regression methods k-nearest neighbor regression
methods complementary. Hence one might expect suitably combining two
methods, one might obtain better performance. one recent study (Quinlan, 1993), model
trees (i.e., regression trees linear combinations leaf nodes) nearest neighbor
methods also combined. combination method described equation 9,
N (x)k one K nearest neighbors x, V(x) y-value stored instance
x, T(x) result applying model tree x.

= K1

XK V (N (x)k) , (T (N (x)k) , (x))

k=1

(9)

k-nearest neighbors found independently induced regression tree (results
reported K=3). sense, approach similar combination method
equation 8. k-nearest neighbors passed tree, results used
refine nearest neighbor answer. Thus, combination model formed
independently computing global solution, later combining results.
However, strong reasons determining global nearest neighbor solution independently. While, limit, large samples, non-parametric k-nearest
neighbor methods correctly fit function, practice though, weaknesses
substantial. Finding effective global distance measure may easy, particularly
presence many noisy features. Hence different technique combining two
methods needed.
3. weights obtained minimize least squared error constraints (Breiman,
1993).

394

fiRule-based Functional Prediction

6.1 Integrating Rules Table-lookup

Consider following strategy: determine y-value case x falls region Ri ,
instead assigning single constant value ki region Ri , ki determined
(x), mean k-nearest
median value training cases region, assign yknn
(training set) instances x region Ri . Thus regression trees, equation
10. regression rules, also equation 11.
(x)
x Ri f (x) = yknn

(10)

(x)
< j x Ri Rj f (x) = yknn

(11)

interesting aspect strategy k-nearest neighbor results need
considered cases covered particular partition. increases interaction models eliminates independent computation two models,
model rationale and, shall show, empirical results, supportive
approach.
representation potentially alleviates weakness partitions
assigned single constant values. Moreover, global distance measure difficulties k-nn methods may also relieved table lookup reduced
partitioned related groupings.
rationale hybrid partition k-nn scheme. Note unlike stacking,
hybrid models independently determined, interact strongly one
another. However, must demonstrated methods fact complementary,
preserving strengths partitioning schemes compensating weaknesses
would introduced constant values used region. respect model
combination, two principal questions need addressed empirical experimentation:

results improved relative using model alone?
methods competitive alternative regression methods?

7. Results
Experiments conducted assess competitiveness rule-based regression compared
procedures (including less interpretable ones), well evaluate performance integrated partition k-nn regression method. Experiments performed
using seven datasets, six described previous studies (Quinlan, 1993). addition six datasets, new experiments done large telecommunications
application, labeled pole. seven datasets, one continuous
real-valued response variable. Experimental results reported terms MAD,
measured using 10-fold cross-validation. pole, 5,000 cases used training
10,000 independent testing. features different datasets mixture
continuous categorical features. pole, 48 features continuous. Descriptions
395

fiWeiss & Indurkhya

Dataset Cases Vars
price
servo
cpu
mpg
peptide
housing
pole

159
167
209
392
431
506
15000

16
19
6
13
128
13
48

Table 1: Dataset Characteristics
datasets found literature (Quinlan, 1993).4 Table 1 summarizes
key characteristics datasets used study.
Table 2 summarizes original results reported (Quinlan, 1993). include modeltrees (MT), regression trees linear fits terminal nodes; neural nets
(NNET); 3-nearest neighbors (3-nn); combined results model-trees 3-nearest
neighbors (MT/3-nn).5
Table 3 summarizes additional results obtained. include CART
regression tree (RT); 5-nearest neighbors euclidean distance (5-nn); rule regression
using Swap-1; rule regression 5-nn applied rule region (Rule/5-nn); MARS.
5-nn used expectation nearest neighbor method incrementally
improves constant-value region region moderately large sample neighbors
average.
rule-based method, parameter m, number pseudo-classes, must
determined. found using cross-validation independent test cases (in
experiments, cross-validation used). Figure 6 represents typical plot relative
error vs. number pseudo-classes (Weiss & Indurkhya, 1993b). number
partitions increases, results improve reach relative plateau deteriorate
somewhat. Similar complexity plots found models, example neural nets
(Weiss & Kapouleas, 1989).
MARS procedure several adjustable parameters.6 parameter mi, values
tried 1 (additive modeling), 2, 3, 4 number inputs. df, default value
3.0 tried well optimal value estimated cross-validation. parameter nk
varied 20 100 steps 10. Lastly, piece-wise linear well piece-wise cubic
solutions tried. setting parameters, cross-validated
accuracy monitored, value best MARS model reported.
method, besides MAD, relative error also reported. relative
error simply estimated true mean absolute distance (measured cross-validation)
normalized initial mean absolute distance median. Analogous classifi4. peptide dataset slightly modified version one Quinlan refers lhrh-att paper.
version used experiments, cases missing values removed.
5. peptide slightly modified version lhrh-att dataset, result listed one
provided Quinlan personal communication.
6. particular program used MARS 3.5.

396

fiRule-based Functional Prediction

Relative Error
0.65

0.6

0.55

0.5

0.45

0.4

0.35

0.3
2

3

4

5
6
7
Number Pseudo-Classes

8

9

10

Figure 6: Prototypical Performance Varying Pseudo-Classes

Dataset MT NNET 3-nn MT/3-nn
price 1562
servo
.45
cpu
28.9
mpg
2.11
peptide .95
housing 2.45

1833
.30
28.7
2.02
2.29

1689
.52
34.0
2.72
2.90

1386
.30
28.1
2.18
2.32

Table 2: Previous Results
cation, predictions must fewer errors simply predicting largest class,
regression must better average distance median
meaningful results.
comparing performance two methods dataset, standard error
method independently estimated, larger one used comparisons.
difference performance greater 2 standard errors, difference
considered statistically significant. significance test, one must also consider
overall pattern performance relative advantages competing solutions (Weiss
& Indurkhya, 1994).
dataset, Figure 7 plots relative best error found ratio best
reported result model's result. relative best error 1 indicates result
best reported result regression model. model results compared
best results regression rules, 5-nn, mixed model. graph indicates
397

fiWeiss & Indurkhya

Dataset

RT

5-nn

Rule

Rule/5-nn

MARS

MAD Error MAD Error MAD Error MAD Error MAD Error
price
1660 .40 1643 .40 1335 .32 1306 .31 1559 .38
servo
.195 .21 .582 .63 .235 .25 .227 .24 .212 .23
cpu
30.5 .39 29.4 .38 27.62 .35 26.32 .34 27.29 .35
mpg
2.28 .35 2.14 .33 2.17 .33 2.04 .31 1.94 .30
peptide .97
.46
.95
.45
.86
.40
.86
.40
.98
.46
housing 2.74 .42 2.77 .42 2.51 .38 2.35 .36 2.24 .34
pole
4.10 .14 5.91 .20 3.76 .13 3.70 .12 7.41 .25
Table 3: Performance Additional Methods
Relative Best Erate
1.2
5-nn
rule
1

rule/5-nn

0.8

0.6

0.4

0.2

0
servo

house

mpg

cpu

price

peptide

pole

Figure 7: Relative Best Erates 5-nn, Rules, Rule/5-nn
trends across datasets helps assess overall pattern performance. respect,
Rule Rule/5nn exhibit excellent performance across many applications.
empirical results allow us consider several relevant questions regarding rulebased regression:
1. rule-based regression perform compared tree-based regression? Comparing
results Rule RT, one see except servo, Rule consistently
better RT remaining six datasets. difference performance also
398

fiRule-based Functional Prediction
tests significant. results significance tests, general trend (which
seen visually Figure 7) leads us conclude rule-based regression
definitely competitive trees often yields superior performance.
2. integrating 5nn rules lead improved performance relative using
model alone? comparison Rule/5nn 5nn shows datasets, Rule/5nn
significantly better. comparing Rule/5nn Rule, results indicate
three datasets (mpg, pole housing), Rule/5nn significantly better Rule,
remaining three datasets same. overall pattern
performance also appears favor Rule/5nn Rule. Thus empirical results
indicate method improved results relative using model alone.
general trend seen Figure 7.
3. new methods competitive alternative regression methods? Among previous reported results, MT/3nn best performer. alternatives consider
are: Regression Trees (RT) MARS. None three methods significantly
better Rule/5nn datasets consideration except RT
significantly better servo. Furthermore, Rule/5nn significantly better
MT/3nn three five datasets (servo, cpu mpg) comparison possible. overall trend also favor Rule/5nn. Comparing RT Rule/5nn,
find except servo, Rule/5nn significantly better RT remaining datasets. Comparing MARS Rule/5nn, find three datasets
(price, peptide pole), Rule/5nn significantly better. Hence empirical results overwhelmingly suggest new method competitive alternative
regression methods, hints superiority methods.

8. Discussion

considered new model rule-based regression provided comparisons
tree-based regression. many applications, strong explanatory capabilities high dimensional feature selection make DNF model quite advantageous. particularly
true knowledge-based applications, example equipment repair medical diagnosis,
contrast pure pattern recognition applications speech recognition.
rules similar trees, rule representation potentially compact
rules mutually exclusive. potential finding compact
solution particularly important problems model interpretation crucial.
Note space rules includes space trees. Thus, tree solution
best, theoretically rule induction procedure potential find it.
experiments, regression rules generally outperformed regression trees.
Fewer constant regions required estimated error rates generally lower.
Finding DNF regions substantially computationally expensive regression rules regression trees. regression rules, fairly complex optimization
techniques necessary. addition, experiments must performed find appropriate number pseudo-classes. matter scale: scale application
versus scale available computing. Excluding telecommunications application,
none cited applications takes 15 minutes cpu time SS-20 sin399

fiWeiss & Indurkhya
gle pseudo-classification problem full cross-validation.7 computing power increases
timing distinction less important. Even small percentage gain quite valuable appropriate application (Apte, Damerau, & Weiss, 1994) computational
requirements secondary factor.
provided results several real-world datasets. Mostly, involve nonlinear relationships. One may wonder rule-based method would perform data
obvious linear relationships. earlier experiments data exhibiting linear
relationships (for example, drug study data (Efron, 1988)), rule-based solutions
slightly better trees. However, true test real-world data which, often involve
complex non-linear relationships. Comparisons alternative models help assess
effectiveness new techniques.
Looking Figure 7 Tables 2 3, see pure rule-based solutions
competitive models. Additional gains made rules used
obtaining function values directly, instead used find relevant cases
used compute function value. results experiments support
view strategy combining different methods improve predictive performance.
Strategies similar applied classification problems (Ting, 1994;
Widmer, 1993) similar conclusions drawn results. results indicate
strategy useful regression context too. empirical results also support
contention regression, partitioning methods nearest neighbor methods
complementary. solution found partitioning alone, incremental
improvement observed substituting average k-nearest neighbors
median partition. perspective nearest neighbor regression methods,
sample cases compartmentalized, simplifying table lookup new case.
conclusive, hints combination strategy effective
small moderate samples: likely sample size grows large, increased
numbers partitions, terms rules terminal nodes, compensate single
constant-valued regions. conjecture supported large-sample pole application,
incremental gain addition k-nn small.8
experiments used k-nn k=5. Depending application, different
value k might produce better results. optimal value might estimated crossvalidation strategy systematically varies k picks value gives best
results overall. However, unclear whether increased computational effort result
significant performance gain.
Another practical issue large samples storage requirement: cases must
stored. serious drawback real-world applications limited memory.
However, tried experiments cases associated partition replaced
fewer number \typical cases". results considerable savings terms storage
requirements. Results slightly weaker (though significantly different).
would appear gains might obtained restricting k-nn consider
features appear path leaf node examination. might
seem like good idea attempts ensure features relevant
7. 10-fold cross-validation requires solving problem essentially 11 times: training cases
10 times group test cases.
8. Although small, difference tests significant sample large.

400

fiRule-based Functional Prediction
cases node, used distance calculations. However, found results
weaker.
number regression techniques presented others demonstrate
advantages combined models. combine methods independently
invoked. Instead typical election one winner, alternative models
combined weighted. combination techniques advantage
outputs different models treated independent variables. combined
form post-processing, model outputs available.
way contradict value alternative combination techniques.
approaches show improved results various applications. conclude, however,
advantages complex regression procedures dynamically mix
alternative models. procedures may particularly strong fundamental rationale choice methods partitioning methods, properties
combined models must preserved.
presented regression problem one output variable. classical form linear models regression trees. issue multiple outputs
directly addressed although extensions feasible. issue experimentation await future work. model regression provide basis efforts,
leveraging current strong methods classification rule induction.

References

Apte, C., Damerau, F., & Weiss, S. (1994). Automated Learning Decison Rules Text
Categorization. ACM Transactions Oce Information Systems, 12 (3), 233{251.
Breiman, L. (1993). Stacked regression. Tech. rep., U. CA. Berkeley.
Breiman, L., Friedman, J., Olshen, R., & Stone, C. (1984). Classification Regression
Tress. Wadsworth, Monterrey, Ca.
Clark, P., & Niblett, T. (1989). CN2 induction algorithm. Machine Learning, 3,
261{283.
Craven, P., & Wahba, G. (1979). Smoothing noisy data spline functions. estimating
correct degree smoothing method generalized cross-validation. Numer.
Math., 31, 317{403.
Efron, B. (1988). Computer-intensive methods statistical regression. SIAM Review,
30 (3), 421{449.
Fayyad, U., & Irani, K. (1992). attribute selection problem decision tree generation.
Proceedings AAAI-92, pp. 104{110 San Jose.
Friedman, J. (1991). Multivariate adaptive regression splines. Annals Statistics, 19 (1),
1{141.
Friedman, J., & Stuetzle, W. (1981). Projection pursuit regression. J. Amer. Stat. Assoc.,
76, 817{823.
401

fiWeiss & Indurkhya
Girosi, F., & Poggio, T. (1990). Networks best approximation property. Biological
Cybernetics, 63, 169{176.
Hartigan, J., & Wong, M. (1979). k-means clustering algorithm, ALGORITHM 136.
Applied Statistics, 28 (1).
Hastie, T., & Tibshirani, R. (1990). Generalized Additive Models. Chapman Hall.
Jacoby, S., Kowalik, J., & Pizzo, J. (1972). Iterative Methods Non-linear Optimization
Problems. Prentice-Hall, New Jersey.
Kirpatrick, S., Gelatt, C., & Vecchi, M. (1983). Optimization simulated annealing.
Science, 220, 671.
LeBlanc, M., & Tibshirani, R. (1993). Combining estimates regression classification.
Tech. rep., Department Statistics, U. Toronto.
Lebowitz, M. (1985). Categorizing numeric information generalization. Cognitive Science, 9, 285{308.
Lin, S., & Kernighan, B. (1973). ecient heuristic traveling salesman problem.
Operations Research, 21 (2), 498{516.
McClelland, J., & Rumelhart, D. (1988). Explorations Parallel Distributed Processing.
MIT Press, Cambridge, Ma.
Michalski, R., Mozetic, I., Hong, J., & Lavrac, N. (1986). multi-purpose incremental learning system AQ15 testing application three medical domains.
Proceedings AAAI-86, pp. 1041{1045 Philadelphia, Pa.
Quinlan, J. (1986). Induction decision trees. Machine Learning, 1, 81{106.
Quinlan, J. (1987). Simplifying decision trees. International Journal Man-Machine
Studies, 27, 221{234.
Quinlan, J. (1993). Combining instance-based model-based learning. International
Conference Machine Learning, pp. 236{243.
Ripley, B. (1993). Statistical aspects neural networks. Proceedings Seminair Europeen de Statistique London. Chapman Hall.
Scheffe, H. (1959). Analysis Variance. Wiley, New York.
Ting, K. (1994). problem small disjuncts: remedy decision trees. Proceedings
10th Canadian Conference Artificial Intelligence, pp. 91{97.
Weiss, S., & Indurkhya, N. (1993a). Optimized Rule Induction. IEEE Expert, 8 (6), 61{69.
Weiss, S., & Indurkhya, N. (1993b). Rule-based regression. Proceedings 13th
International Joint Conference Artificial Intelligence, pp. 1072{1078.
402

fiRule-based Functional Prediction
Weiss, S., & Indurkhya, N. (1994). Decision tree pruning: Biased optimal?. Proceedings
AAAI-94, pp. 626{632.
Weiss, S., & Kapouleas, I. (1989). empirical comparison pattern recognition, neural
nets, machine learning classification methods. International Joint Conference
Artificial Intelligence, pp. 781{787 Detroit, Michigan.
Weiss, S., & Kulikowski, C. (1991). Computer Systems Learn: Classification Prediction Methods Statistics, Neural Nets, Machine Learning, Expert Systems.
Morgan Kaufmann.
Widmer, G. (1993). Combining knowledge-based instance-based learning exploit
qualitative knowledge. Informatica, 17, 371{385.
Wolpert, D. (1992). Stacked generalization. Neural Networks, 5, 241{259.

403

fiJournal Artificial Intelligence Research 3 (1995) 1-24

Submitted 1/95; published 6/95

Induction First-Order Decision Lists:
Results Learning Past Tense English Verbs

Raymond J. Mooney
Mary Elaine Califf

Department Computer Sciences, University Texas
Austin, TX 78712-1188

mooney@cs.utexas.edu
mecaliff@cs.utexas.edu

Abstract

paper presents method inducing logic programs examples learns
new class concepts called first-order decision lists, defined ordered lists clauses
ending cut. method, called Foidl, based Foil (Quinlan, 1990)
employs intensional background knowledge avoids need explicit negative examples. particularly useful problems involve rules specific exceptions,
learning past-tense English verbs, task widely studied context
symbolic/connectionist debate. Foidl able learn concise, accurate programs
problem significantly fewer examples previous methods (both connectionist
symbolic).

1. Introduction

Inductive logic programming (ILP) growing subtopic machine learning studies
induction Prolog programs examples presence background knowledge
(Muggleton, 1992; Lavrac & Dzeroski, 1994). Due expressiveness first-order logic,
ILP methods learn relational recursive concepts cannot represented
attribute/value representations assumed machine-learning algorithms. ILP methods successfully induced small programs sorting list manipulation (Shapiro,
1983; Sammut & Banerji, 1986; Muggleton & Buntine, 1988; Quinlan & Cameron-Jones,
1993) well produced encouraging results important applications predicting protein secondary structure (Muggleton, King, & Sternberg, 1992) automating
construction natural-language parsers (Zelle & Mooney, 1994b).
However, current ILP techniques make important assumptions restrict application. three common assumptions:
1. Background knowledge provided extensional form set ground literals.
2. Explicit negative examples target predicate available.
3. target program expressed \pure" Prolog clause-order irrelevant
procedural operators cut (!) disallowed.
currently well-known successful ILP systems, Golem (Muggleton & Feng,
1990) Foil (Quinlan, 1990), make three assumptions. However,
assumptions brings significant limitations since:
1. adequate extensional representation background knowledge frequently infinite
intractably large.

c 1995 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiMooney & Califf

2. Explicit negative examples frequently unavailable adequate set negative
examples computed using closed-world assumption infinite intractably large.
3. Concise representation many concepts requires use clause-ordering and/or
cuts (Bergadano, Gunetti, & Trinchero, 1993).
paper presents new ILP method called Foidl (First-Order Induction Decision Lists) helps overcome limitations incorporating following
properties:
1. Background knowledge represented intensionally logic program.
2. explicit negative examples need supplied constructed. assumption
output completeness used instead implicitly determine hypothesized
clause overly-general and, so, quantify degree over-generality simply
estimating number negative examples covered.
3. learned program represented first-order decision list, ordered set
clauses ending cut. representation useful problems
best represented general rules specific exceptions.
name implies, Foidl closely related Foil follows similar top-down,
greedy specialization guided information-gain heuristic. However, algorithm
substantially modified address three advantages listed above. use intensional
background knowledge fairly straightforward incorporated previous Foil
derivatives (Lavrac & Dzeroski, 1994; Pazzani & Kibler, 1992; Zelle & Mooney, 1994b),
development Foidl motivated failure observed applying existing ILP methods particular problem, learning past tense English
verbs. problem studied fairly extensively using connectionist symbolic methods (Rumelhart & McClelland, 1986; MacWhinney & Leinbach, 1991; Ling,
1994); however, previous efforts used specially-designed feature-based encodings impose fixed limit length words fail capture position-independence
underlying transformation. believed representing problem constructing logic program predicate past(X,Y) X words represented
lists letters (e.g past([a,c,t], [a,c,t,e,d]), past([a,c,h,e], [a,c,h,e,d]),
past([a,r,i,s,e], [a,r,o,s,e])) would produce much better results. However, due
limitations mentioned above, unable get reasonable results either Foil
Golem. However, overcoming limitations, Foidl able learn highly accurate programs past-tense problem many fewer examples required
previous methods.
remainder paper organized follows. Section 2 provides important background material Foil past-tense learning problem. Section 3 presents
Foidl algorithm details incorporates three advantages discussed above. Section 4 presents results learning past-tense English verbs demonstrating
Foidl out-performs previous methods problem. Section 5 reviews related work,
Section 6 discusses limitations future directions, Section 7 summarizes presents
conclusions.
2

fiInduction First-Order Decision Lists: Learning English Past Tense

2. Background

Since Foidl based Foil, section presents brief review important ILP system; Quinlan (1990), Quinlan Cameron-Jones (1993), Cameron-Jones Quinlan
(1994) provide complete description. section also presents brief review
previous work English past tense problem.

2.1 FOIL

Foil learns function-free, first-order, Horn-clause definition target predicate terms
background predicates. input consists extensional definitions
predicates tuples constants specified types. example, input appropriate
learning definition list membership is:
member(Elt,Lst): { <a,[a]>, <a,[a,b]>, <b,[a,b]>, <a,[a,b,c]>, ...}
components(Lst,Elt,Lst): { <[a],a,[]>, <[a,b],a,[b]>, <[a,b,c],a,[b,c]> ...}

Elt type denoting possible elements includes a,b,c, d; Lst
type defined consisting lists containing three elements;
components(A,B,C) background predicate true iff list whose first element B whose rest list C (this must provided place function
list construction). Foil also requires negative examples target concept,
supplied directly computed using closed-world assumption. example,
closed-world assumption would produce pairs form <Elt,Lst> explicitly provided positive examples (e.g., <b,[a]>).
Given input, Foil learns program one clause time using greedy-covering
algorithm summarized follows:
Let positives-to-cover = positive examples.
positives-to-cover empty
Find clause, C , covers preferably large subset positives-to-cover
covers negative examples.
Add C developing definition.
Remove examples covered C positives-to-cover.
example, clause might learned member one iteration loop is:
member(A,B) :- components(B,A,C).

since covers positive examples element first one list
cover negatives. clause could learned cover remaining examples is:
member(A,B) :- components(B,C,D), member(A,D).

Together two clauses constitute correct program member.
\find clause" step implemented general-to-specific hill-climbing search
adds antecedents developing clause one time. step, evaluates possible
literals might added selects one maximizes information-gain heuristic.
algorithm maintains set tuples satisfy current clause includes bindings
new variables introduced body. following pseudocode summarizes
procedure:
3

fiMooney & Califf

Initialize C R(V1; V2; :::; Vk) :-. R target predicate arity k.
Initialize contain positive tuples positives-to-cover negative tuples.
contains negative tuples
Find best literal L add clause.
Form new training set containing tuple satisfies L,
tuples form b (t b concatenated) b set bindings
new variables introduced L literal satisfied
(i.e., matches tuple extensional definition predicate).
Replace .
Foil considers adding literals possible variablizations predicate long
type restrictions satisfied least one arguments existing variable
bound head previous literal body. Literals evaluated based
number positive negative tuples covered, preferring literals cover many positives
negatives. Let T+ denote number positive tuples set define:
(T ) = , log2 (T+ =jT j):
(1)
chosen literal one maximizes:
gain(L) = (I (T ) , (T ));
(2)
number tuples extensions (i.e., number current
positive tuples covered L).
Foil also includes many additional features as: heuristics pruning space
literals searched, methods including equality, negation failure, useful literals
immediately provide gain (determinate literals), pre-pruning post-pruning
clauses prevent over-fitting, methods ensuring induced programs
terminate. papers referenced consulted details
features.
0

0

0

0

2.2 Learning Past Tense English Verbs

Rumelhart McClelland (1986) first build computational model pasttense learning using classic perceptron algorithm special phonemic encoding
words employing so-called Wickelphones Wickelfeatures. general goal show
connectionist models could account interesting language-learning behavior
previously thought require explicit rules. model heavily criticized opponents
connectionist approach language acquisition relatively poor results achieved
heavily-engineered representations training techniques employed (Pinker &
Prince, 1988; Lachter & Bever, 1988). MacWhinney Leinbach (1991) attempted
address criticisms using standard multi-layer backpropagation learning
algorithm simpler UNIBET encoding phonemes (in 36 phonemes
encoded single ASCII character).
Ling Marinov (1993) Ling (1994) criticize current connectionist models past-tense acquisition heavily-engineered representations poor experimental
methodology. present systematic results system called SPA (Symbolic Pattern Associator) uses slightly modified version C4.5 (Quinlan, 1993) build
4

fiInduction First-Order Decision Lists: Learning English Past Tense

forest decision trees maps fixed-length input pattern fixed-length output pattern. Ling's (1994) head-to-head results show SPA generalizes significantly better
backpropagation number variations problem employing different phonemic
encodings (e.g., 76% vs. 56% given 500 training examples).
However, previous work encodes problem fixed-length pattern association fails capture generativity position-independence true transformation. example, use 15-letter patterns like:
a,c,t,_,_,_,_,_,_,_,_,_,_,_,_ => a,c,t,e,d,_,_,_,_,_,_,_,_,_,_

UNIBET phonemic encoding:
&,k,t,_,_,_,_,_,_,_,_,_,_,_,_ => &,k,t,I,d,_,_,_,_,_,_,_,_,_,_

separate decision tree output unit used predict character output
pattern input characters. Therefore, learning general rules, \add
`ed'," must repeated position word end, words longer 15
characters cannot handled. Also, best results SPA exploit highly-engineered
feature template modified version C4.5's default leaf-labeling strategy tailor
string transformation problems.
Although ILP methods seem appropriate problem, initial attempts
apply Foil Golem past-tense learning gave disappointing results (Califf,
1994). Below, discuss three problems listed introduction contribute
diculty applying current ILP methods problem.
principle, background predicate append sucient constructing accurate
past-tense programs incorporated ability include constants arguments
or, equivalently, ability add literals bind variables specific constants (called
theory constants Foil). However, background predicate allow appending
empty list appropriate. use predicate called split(A, B, C)
splits list two non-empty sublists B C. intensional definition split is:
split([X, | Z], [X] , [Y | Z]).
split([X | Y], [X | W], Z) :- split(Y,W,Z).

Using split, \add `ed"' rule represented as:
past(A,B) :- split(B,A,[e,d]).

which, Foil, learned form:
past(A,B) :- split(B,A,C), C = [e,d].

Providing extensional definition split includes possible strings 15 fewer
characters (at least 1021 strings) clearly intractable. However, providing partial definition includes possible splits strings actually appear training corpus
possible generally sucient. Therefore, providing adequate extensional background
knowledge cumbersome requires careful engineering; however, major
problem.
Supplying appropriate set negative examples problematic. Using closedworld assumption produce pairs words training set second
past-tense first feasible useful. case, clause:
5

fiMooney & Califf

past(A,B) :- split(B,A,C).

likely learned since covers positives (if any)
negatives since unlikely word prefix another word past
tense. However, clause useless producing past tense novel verbs, and,
domain, accuracy must measured ability actually generate correct output
novel inputs, rather ability classify pre-supplied tuples arguments positive
negative. obvious solution supplying strings 15 characters less
negative examples past tense word clearly intractable. Providing specially
constructed \near-miss" negative examples past([a,c,h,e],[a,c,h,e,e,d]),
helpful, requires careful engineering exploits detailed prior knowledge
problem.
order address problem negative examples, Quinlan (1994) applied
Foil problem, employed different target predicate representing pasttense transformation.1 used three-place predicate past(X,Y,Z) true iff
input word X transformed past-tense form removing current ending
substituting ending Z; example: past([a,c,t], [], [e,d]), past([a,r,i,s,e],
[i,s,e], [o,s,e]). simple preprocessor map data two-place predicate
form. Since sample 500 verb pairs contains 30-40 different end fragments,
results manageable number closed-world negatives, approximately 1000
every positive example training set. Using approach UNIBET phonemic
encodings, Quinlan obtained slightly better results Ling's best SPA results exploited highly-engineered feature template (83.3% vs. 82.8% 500 training examples)
significantly better SPA's normal results (76.3%). Although three-place target predicate incorporates knowledge desired transformation, arguably
requires less representation engineering previous methods.
However, Quinlan (1994) notes results still hampered Foil's inability
exploit clause order. example, using normal alphabetic encoding, Foil quickly
learns clause sucient regular verbs:
past(A,B,C) :- B=[], C=[e,d].

However, since clause still covers fair number negative examples due many
irregular verbs, continues add literals. result, Foil creates number specialized
versions clause together still fail capture generality underlying
default rule. problem compounded Foil's inability add constraints
\does end `e'." Since Foil separates addition literals containing variables
binding variables constants using literals form V = c, cannot learn clauses
like:
past(A,B,C) :- B=[], C=[e,d], not(split(A,D,[e])).

Since word split several ways, clearly equivalent learnable
clause:
past(A,B,C) :- B=[], C=[e,d], not(split(A,D,E)), E /= [e].

1. Quinlan's work problem motivated early attempts use Foil.

6

fiInduction First-Order Decision Lists: Learning English Past Tense

Consequently, must approximate true rule learning many clauses form:
past(A,B,C) :- B=[], C=[e,d], split(A,D,E), E = [b].
past(A,B,C) :- B=[], C=[e,d], split(A,D,E), E = [d].
...

result, Foil generated overly-complex programs containing 40 clauses
phonemic alphabetic versions problem.
However, experienced Prolog programmer would exploit clause order cuts
write concise program first handles most-specific exceptions falls
more-general default rules exceptions fail apply. example, program:
past(A,B)
past(A,B)
past(A,B)
past(A,B)

::::-

split(A,C,[e,e,p]), split(B,C,[e,p,t]), !.
split(A,C,[y]), split(B,C,[i,e,d]), !.
split(A,C,[e]), split(B,A,[d]), !.
split(B,A,[e,d]).

summarized as:
word ends \eep," replace \eep" \ept" (e.g., sleep, slept),
else, word ends \y," replace \y" \ied"
else, word ends \e," add \d"
else, add \ed."
Foidl directly learn programs form, i.e., ordered sets clauses ending
cut. call programs first-order decision lists due similarity propositional
decision lists introduced Rivest (1987). Foidl uses normal binary target predicate
requires explicit negative examples. Therefore, believe requires significantly
less representation engineering previous work area.

3. FOIDL Induction Algorithm

stated introduction, Foidl adds three major features Foil: 1) Intensional
specification background knowledge, 2) Output completeness substitute explicit
negative examples, 3) Support learning first-order decision lists. following
subsections describe modifications made incorporate features.

3.1 Intensional Background

described above, Foil assumes background predicates provided extensional
definitions; however, burdensome frequently intractable. Providing intensional definition form general Prolog clauses generally preferable. example,
instead providing numerous tuples components predicates, easier give
intensional definition:
components([A | B], A, B).

Intentional background definitions restricted function-free pure Prolog
exploit features language.
7

fiMooney & Califf

Modifying Foil use intensional background straightforward. Instead matching
literal set tuples determine whether covers example,
Prolog interpreter used attempt prove literal satisfied using
intensional definitions. Unlike Foil, expanded tuples maintained positive
negative examples target concept reproved alternative specialization
developing clause. Therefore, pseudocode learning clause simply:
Initialize C R(V1; V2; :::; Vk) :-. R target predicate arity k.
Initialize contain examples positives-to-cover negative examples.
contains negative tuples
Find best literal L add clause.
Let subset examples still proved instances
target concept using specialized clause.
Replace
Since expanded tuples produced, information-gain heuristic picking best
literal simply:
gain(L) = jT j (I (T ) , (T )):
(3)
0

0

0

0

3.2 Output Completeness Implicit Negatives

order overcome need explicit negative examples, mode declaration
target concept must provided (i.e., specification whether argument input (+)
output (-)). assumption output completeness made, indicating
every unique input pattern training set, training set includes correct
output patterns. Therefore, output program produces given input
assumed represent negative example. require positive
examples part training set, unique input pattern training
set, positive examples input pattern (if any) must also training
set. assumption trivially met predicate represents function single
unique output input.
example, assumption output completeness mode declaration past(+,-)
indicates correct past-tense forms included input word
training set. predicates representing functions, past, implies
output example unique outputs implicitly represent negative examples. However, output completeness also applied non-functional cases
append(-,-,+), indicating possible pairs lists appended
together produce list included training set (e.g., append([],[a,b],[a,b]),
append([a],[b],[a,b]), append([a,b],[],[a,b])).
Given output completeness assumption, determining clause overly-general
straightforward. positive example, output query made determine
outputs given input (e.g., past([a,c,t], X)). outputs generated
positive examples, clause still covers negative examples requires
specialization. Note intensional interpretation learned clauses required order
answer output queries.
addition, order compute gain alternative literals specialization,
negative coverage clause needs quantified. incorrect answer output
8

fiInduction First-Order Decision Lists: Learning English Past Tense

query ground (i.e., contains variables) clearly counts single negative example (e.g., past([a,c,h,e], [a,c,h,e,e,d])). However, output queries frequently
produce answers universally quantified variables. example, given overly-general
clause past(A,B) :- split(A,C,D)., query past([a,c,t], X) generates answer
past([a,c,t], Y). implicitly represents coverage infinite number negative
examples. order quantify negative coverage, Foidl uses parameter u represent
bound number possible terms. Since set possible terms (the Herbrand
universe background knowledge together examples) generally infinite, u
meant represent heuristic estimate finite number terms ever
actually occur practice (e.g., number distinct words English). negative coverage represented non-ground answer output query estimated uv , p,
v number variable arguments answer p number positive
examples answer unifies. uv term stands number unique
ground outputs represented answer (e.g., answer append(X,Y,[a,b]) stands
2
u different ground outputs) p term stands number represent
positive examples. allows Foidl quantify coverage large numbers implicit
negative examples without ever explicitly constructing them. generally sucient
estimate u fairly large constant (e.g., 1000), empirically method
sensitive exact value long significantly greater number ground
outputs ever generated clause.
Unfortunately, estimate sensitive enough. example, clauses
past(A,B) :- split(A,C,D).
past(A,B) :- split(B,A,C).

cover u implicit negative examples output query past([a,c,t], X) since first
produces answer past([a,c,t], Y) second produces answer past([a,c,t],
[a,c,t | Y]). However, second clause clearly better since least requires output input sux added. Since presumably words
words start \a-c-t" (assuming total number words finite),
first clause considered cover negative examples. Therefore, arguments
partially instantiated, [a,c,t | Y], counted fraction
variable calculating v . Specifically, partially instantiated output argument scored
fraction subterms variables, e.g., [a,c,t | Y] counts 1=4
variable argument. Therefore, first clause scored covering u implicit negatives second covering u1=4. Given reasonable values u number
positives covered clause, literal split(B,A,C) preferred.
revised specialization algorithm incorporates implicit negatives is:
Initialize C R(V1; V2; :::; Vk) :-. R target predicate arity k.
Initialize contain examples positives-to-cover output queries
positive examples.
contains output queries
Find best literal L add clause.
Let subset positive examples still proved instances
target concept using specialized clause, plus output queries
0

9

fiMooney & Califf

still produce incorrect answers.
Replace .
0

Literals scored described previous section except jT j computed
number positive examples plus sum number implicit negatives covered
output query .

3.3 First-Order Decision Lists

described above, first-order decision lists ordered sets clauses ending
cut. answering output query, cuts simply eliminate first answer
produced trying clauses order. Therefore, representation similar
propositional decision lists (Rivest, 1987), ordered lists pairs (rules)
form (ti ; ci) test ti conjunction features ci category label
example assigned category first pair whose test satisfies.
original algorithm Rivest (1987) CN2 (Clark & Niblett, 1989), rules
learned order appear final decision list (i.e., new rules appended
end list learned). However, Webb Brkic (1993) argue learning
decision lists reverse order since preference functions tend learn general
rules first, best positioned default cases towards end. introduce
algorithm, prepend, learns decision lists reverse order present results indicating
cases learns simpler decision lists superior predictive accuracy. Foidl
seen generalizing prepend first-order case target predicates representing
functions. learns ordered sequence clauses reverse order, resulting program
produces first output generated first satisfied clause.
basic operation algorithm best illustrated concrete example.
alphabetic past-tense, current algorithm easily learns partial clause:
past(A,B) :- split(B,A,C), C = [e,d].

However, discussed section 2.2, clause still covers negative examples due irregular verbs. However, produces correct ground output subset examples (i.e.,
regular verbs).2 indication best terminate clause handle
examples, add earlier clauses decision list handle remaining examples.
fact produces incorrect answers output queries safely ignored
decision-list framework since handled earlier clauses. Therefore,
examples correctly covered clause removed positives-to-cover new
clause begun. literals provide best gain are:
past(A,B) :- split(B,A,C), C = [d].

since many irregulars add \d" (since end \e"). clause
also produces correct ground output subset examples; however,
complete since produces incorrect output examples correctly covered previously
learned clause (e.g., past([a,c,t], [a,c,t,d])). Therefore, specialization continues
cases also eliminated. results clause:
2. Note untrue literals added initially empty clause.

10

fiInduction First-Order Decision Lists: Learning English Past Tense

past(A,B) :- split(B,A,C), C = [d], split(A,D,E), E = [e].

added front decision list examples covers removed
positives-to-cover. approach ensures every new clause produces correct outputs
new subset examples doesn't result incorrect output examples already
correctly covered previously learned clauses. process continues adding clauses
front decision list exceptions handled positives-to-cover
empty.
resulting clause-specialization algorithm summarized follows:
Initialize C R(V1; V2; :::; Vk) :-. R target predicate arity k.
Initialize contain examples positives-to-cover output queries
positive examples.
contains output queries
Find best literal L add clause.
Let subset positive examples whose output query still produces
first answer unifies correct answer, plus output queries
either
1) Produce non-ground first answer unifies correct answer,
2) Produce incorrect answer produce correct answer using
previously learned clause.
Replace .
0

0

many cases, algorithm able learn accurate, compact, first-order decision lists
past tense, like \expert" program shown section 2.2. However, due highly irregular verbs, algorithm encounter local-minima unable find literals
provide positive gain still covering required minimum number examples.3
originally handled terminating search memorizing remaining uncovered examples specific exceptions top decision list (e.g., past([a,r,i,s,e],
[a,r,o,s,e]) :- !.). However, result premature termination prevents
algorithm finding low-frequency regularities. example, alphabetic version, system get stuck trying learn complex rule double final
consonant (e.g., grab ! grabbed) fail learn rule changing \y" \ied" since
actually less frequent.
current version, like Foil, tests learned clause meets minimum-accuracy
threshold; however, unlike Foil, counting errors incorrect outputs queries correctly answered previously learned clauses. meet threshold, clause
thrown positive examples covers memorized top decision
list. algorithm continues learn clauses remaining positive examples.
allows Foidl memorize dicult irregularities, consonant doubling,
still continue learn rules changing \y" \ied."
minimum-accuracy threshold met, decision-list property exploited
final attempt still learn completely accurate program. negatives covered
clause examples correctly covered previously learned clauses, Foidl
3. Like Foil, Foidl includes parameter minimum number examples clause must cover
(normally set 2).

11

fiMooney & Califf

treats \exceptions exception rule" returns positives-tocover covered correctly subsequently learned clauses. example, Foidl
frequently learns clause:
past(A, B) :- split(A, C, [y]), split(B, C, [i, e, d]).

changing \y" \ied." However, clause incorrectly covers examples
correctly covered previously learned \add `ed"' rule (e.g., bay ! bayed; delay !
delayed). Since exceptions \y" \ied" rule small percentage words
end \y," system keeps rule returns examples add \ed"
positives-to-cover. Subsequently, rules as:
past(A, B) :- split(B, A, [e, d]), split(A, D, [a, y]).

learned recover examples, resulting program completely consistent
training data. setting minimum clause-accuracy threshold 50%, Foidl
applies uncovering technique results covering examples
uncovers, thereby guaranteeing progress towards fitting training examples.

3.4 Algorithmic Implementation Details

section brie discusses additional details Foidl algorithm implementation. includes discussion use modes, types, weak literals, theory
constants. current version Foil includes features basically
form.
Foidl makes use types modes limit space literals searched. argument predicate typed literals whose previously-bound arguments
correct type tested specializing clause. example, split given
types split(word,prefix,suffix), preventing system splitting prefixes
suxes exploring arbitrary substrings word regularities. predicate
also given mode declaration, literals whose input arguments previouslybound variables tested. example, split given mode split(+,-,-), preventing
clause creating new strings appending together previously generated prefixes
suxes.
case literal provides positive information gain, Foidl gives small bonus literals
introduce new variables. However, number weak literals added
row limited user parameter (normally set 1). example, allows
system split word possible prefixes suxes, even though may provide
gain substrings constrained subsequent literals.
Theory constants provided type, literals tested binding
existing variable constant appropriate type. example, literal X=[e,d]
generated X type suffix. runs past-tense, theory constants included
every prefix sux occurs least two words training data. helps
control training time limiting number literals searched, affect
literals actually chosen since minimum-clause-coverage test prevents Foidl
choosing literals don't cover least two examples anyway.
12

fiInduction First-Order Decision Lists: Learning English Past Tense

Foidl currently implemented Common Lisp Quintus Prolog. Unlike
current Prolog version, Common Lisp version supports learning recursive clauses4
output-completeness non-functional target predicates. However, Common Lisp
version significantly slower since relies un-optimized Prolog interpreter
compiler written Lisp (from Norvig, 1992). Consequently, presented results
Prolog version running Sun SPARCstation 2.5

4. Experimental Results
test Foidl's performance English past tense task, ran experiments using
data Ling (1994) made available appendix.

4.1 Experimental Design
data used consist 6939 English verb forms normal alphabetic form
UNIBET phoneme representation along label indicating verb form (base, past
tense, past participle, etc), label indicating whether form regular irregular,
Francis-Kucera frequency verb. data include 1390 distinct pairs base
past tense verb forms. ran three different experiments. one used phonetic
forms verbs. second used phonetic forms regular verbs only,
easiest form task problem
Ling provides learning curves. Finally, ran trials using alphabetic forms verbs.
training testing followed standard paradigm splitting data testing
training sets training progressively larger samples training set. results
averaged 10 trials, testing set trial contained 500 verbs.
order better separate contribution using implicit negatives contribution decision list representation, also ran experiments IFoil, variant
system uses intensional background output completeness assumption,
build decision lists.
ran experiments Foil, Foidl, IFoil compared
results Ling. Foil experiments run using Quinlan's representation described
section 2.2. Quinlan (1994), negative examples provided using randomlyselected 25% could generated using closed world assumption.6
experiments Foidl IFoil used standard default values various numeric
parameters (term universe size, 1000; minimum clause coverage, 2; weak literal limit, 1).
differences among Foil, IFoil, Foidl tested significance using twotailed paired t-test.
4. Handling intensional interpretation recursive clauses target predicate requires additional
complexities discussed paper since relevant decision-lists,
generally recursive.
5. versions available anonymous FTP net.cs.utexas.edu directory
pub/mooney/foidl.
6. replicated Quinlan's approach since memory limitations prevented us using 100% generated negatives larger training sets.

13

fiMooney & Califf

100

80

Accuracy

60

40
FOIDL
IFOIL
FOIL
SPA
Neural Network

20

0
0

100

200

300
Training Examples

400

500

Figure 1: Accuracy phonetic past tense task using verbs

4.2 Results
results phonetic task using regular irregular verbs presented
Figure 1. graph shows results Foil, IFoil, Foidl along
best results Ling, provide learning curve task. expected,
Foidl out-performed systems task, surpassing Ling's best results 500
examples 100 examples. IFoil performed quite poorly, barely beating neural
network results despite effectively 100% negatives opposed Foil's 25%.
poor performance due least part overfitting training data, IFoil
lacks noise-handling techniques Foil6. Foil also advantage three-place
predicate, gives bias toward learning suxes. IFoil's poor performance
task shows implicit negatives sucient,
bias decision lists three-place predicate noise-handling needed.
differences Foil Foidl significant 0.01 level. Foidl
IFoil significant 0.001 level. differences Foil IFoil
significant 100 training examples less, significant 0.001 level
250 500 examples.
Figure 2 presents accuracy results phonetic task using regulars only. curves
SPA neural net results reported Ling. again, Foidl outperformed systems. particular task demonstrated one problems
using closed-world negatives. regular past tense task, second argument Quinlan's 3-place predicate always same: empty list. Therefore, constants
generated positive examples, Foil never produce rules ground second argument, since cannot create negative examples constants second
argument. prevents system learning rule generate past tense. order
14

fiInduction First-Order Decision Lists: Learning English Past Tense

100

80

Accuracy

60

40
FOIDL
IFOIL
FOIL
SPA
Neural Network

20

0
0

50

100

150

200
250
300
Training Examples

350

400

450

500

Figure 2: Accuracy phonetic past tense task using regulars
obtain results reported here, introduced extra constants second argument
(specifically constants third argument), enabling closed world assumption
generate appropriate negatives. task, IFoil seem gain advantage
Foil able effectively use negatives. regularity data
allows IFoil Foil achieve 90% accuracy 500 examples. differences
Foil Foidl significant 0.001 level, IFoil
Foidl. differences IFoil Foil significant 25 examples,
significant 0.02 level 500 examples, significant 0.001 level
50-250 training examples.
Results alphabetic version appear Figure 3. task
typically considered literature, interest concerned
incorporating morphology natural language understanding systems deal
text. also dicult task, primarily consonant doubling.
results Foidl, IFoil, Foil. alphabetic task even
irregular full phonetic task, IFoil overfits data performs quite poorly.
differences Foil Foidl significant 0.001 level 25, 50, 250,
500 examples, 0.1 level 100 examples. differences
IFoil Foidl significant 0.001 level. Foil IFoil
significant 25 training examples significant 0.01 level 50
training examples, significant 0.001 level 100 examples.
three tasks, Foidl clearly outperforms systems, demonstrating
first order decision list bias good one learning task. sucient set
negatives necessary, five systems provide way: neural
network SPA learn multiple-class classification tasks (which phoneme belongs
position); Foil uses three-place predicate closed world negatives; IFoil
15

fiMooney & Califf

90

80

70

Accuracy

60

50

40

30

FOIDL
IFOIL
FOIL

20

10

0
0

50

100

150

200
250
300
Training Examples

350

400

450

500

Figure 3: Accuracy alphabetic past tense task
Foidl, course, use output completeness assumption. primary importance
implicit negatives provide advantage propositional
neural network systems, enable first order systems perform task
all. Without them, knowledge task required. Foidl's decision lists give
significant added advantage, though advantage less apparent regular phonetic
task, exceptions.
Clearly, Foidl produces accurate rules systems, another consideration complexity rule sets. ILP systems, two good measures
complexity number rules number literals generated. Figure 4 shows
number rules generated Foil, IFoil, Foidl phonetic task using verbs.
number literals generated appears Figure 5. Since interested generalization since Foil attempt fit training data, results
include rules Foidl IFoil add order memorize individual exceptions.7 Although numbers comparable examples, increasing numbers
examples, programs Foil IFoil generate grow much faster Foidl's programs.
large number rules/literals learned IFoil show tendency overfit data.
Foidl also generates comprehensible programs. following example program generated alphabetic version task using 250 examples (again excluding
memorized examples).
past(A,B) :- split(A,C,[e,p]), split(B,C,[p,t]),!.
past(A,B) :- split(A,C,[y]), split(B,C,[i,e,d]), split(A,D,[r,y]),!.
past(A,B) :- split(A,C,[y]), split(B,C,[i,e,d]), split(A,D,[l,y]),!.

7. large number irregular pasts English, Foidl memorizes average 38 verbs per
trial 500 examples.

16

fiInduction First-Order Decision Lists: Learning English Past Tense

80

70

FOIDL
IFOIL
FOIL

Number Rules

60

50

40

30

20

10

0
0

50

100

150

200
250
300
Training Examples

350

400

450

500

Figure 4: Number rules created phonetic past tense task

350

300

FOIDL
IFOIL
FOIL

Number Literals

250

200

150

100

50

0
0

50

100

150

200
250
300
Training Examples

350

400

450

500

Figure 5: Number literals created phonetic past tense task
17

fiMooney & Califf

past(A,B)
past(A,B)
past(A,B)
past(A,B)

::::-

split(B,A,[m,e,d]), split(A,C,[m]), split(A,[s],D),!.
split(B,A,[r,e,d]), split(A,C,[u,r]),!.
split(B,A,[d]), split(A,C,[e]),!.
split(B,A,[e,d]),!.

training times various systems considered research dicult
compare. Ling provide timing results, though probably assume based
research comparing symbolic neural learning algorithms (Shavlik, Mooney, & Towell,
1991) SPA runs fairly quickly since based C4.5 backpropagation took
considerably longer. tests Foil Foidl directly comparable
run different architectures. Foil runs done Sparc 5.
500 examples, Foil averaged 48 minutes phonetic task verbs. Foidl
experiments ran Sparc 2 averaged 1071 minutes task. Even allowing
differences speed two machines (about factor two), Foidl quite
bit slower, probably due largely cost using intentional background part
implementation Prolog opposed C.

5. Related Work

5.1 Related Work ILP

Although three features mentioned introduction distinguishes Foidl
work Inductive Logic Programming, number related pieces research
mentioned. use intensional background knowledge least distinguishing feature
since number ILP systems also incorporate aspect. Focl (Pazzani & Kibler,
1992), mFoil (Lavrac & Dzeroski, 1994), Grendel (Cohen, 1992), Forte (Richards &
Mooney, 1995), Chillin (Zelle & Mooney, 1994a) use intensional background
degree context Foil-like algorithm. ILP systems employ
intensional background include early ones Shapiro (1983) Sammut Banerji (1986)
recent ones Bergadano et al. (1993) Stahl, Tausend, Wirth (1993).
use implicit negatives significantly novel. described section 3.2,
approach considerably different explicit construction using closed-world assumption, therefore employed explicit construction sucient negative examples intractable. Bergadano et al. (1993) allows user supply intensional definition
negative examples covers large set ground instances (e.g (past([a,c,t],X),
not(equal(X,[a,c,t,e,d])))); however, equivalent output completeness, user
would explicitly provide separate intensional negative definition positive
example. non-monotonic semantics used eliminate need negative examples
Claudien (De Raedt & Bruynooghe, 1993) effect output completeness
assumption case arguments target relation outputs. However,
output completeness permits exibility allowing arguments specified
inputs counting negative examples extra outputs generated specific
inputs training set. Flip (Bergadano, 1993) provides method learning functional programs without negative examples making assumption equivalent output
completeness functional case. Output completeness general permits learning non-functional programs well. Also, unlike Foidl, none previous
18

fiInduction First-Order Decision Lists: Learning English Past Tense

methods provide way quantifying implicit negative coverage context heuristic
top-down specialization algorithm.
notion first-order decision list unique Foidl. ILP system
attempts learn programs exploit clause-order cuts Bergadano et al.
(1993). paper discusses many problems learning arbitrary programs cuts,
brute-force search used approach intractable realistic problems.
Instead addressing general problem learning arbitrary programs cuts, Foidl
tailored specific problem learning first-order decision lists, use cuts
stylized manner particularly useful functional problems involve rules
exceptions. Bain Muggleton (1992) Bain (1992) discuss technique uses
negation failure handle exceptions. However, using negation failure significantly
different decision lists since simply prevents clause covering exceptions rather
learning additional clause over-rides existing clause specifies
correct output set exceptions.

5.2 Related Work Past-Tense Learning
shortcomings previous work past-tense learning reviewed section 2.2,
results section 4 clearly demonstrate generalization advantage Foidl exhibits
problem. However, couple issues deserve additional discussion.
previous work problem concerned modelling various
psychological phenomenon, U-shaped learning curve children exhibit
irregular verbs acquiring language. paper addressed issue psychological validity, rather focused performance accuracy exposure fixed
number training examples. Therefore, make specific psychological claims based
current results.
However, humans obviously produce correct past tense arbitrarily-long novel
words, Foidl easily model fixed-length feature-based representations clearly
cannot. Ling also developed version SPA eliminates position dependence fixed
word-length (Ling, 1995) using sliding window like used NETtalk (Sejnowski
& Rosenberg, 1987). large window used includes 15 letters either side
current position (padded blanks necessary) order always include entire
word examples corpus. results approach significantly better
normal SPA still inferior Foidl's results. Also, approach still requires
fixed-sized input window prevents handling arbitrary-length irregular verbs.
Recurrent neural networks could also used avoid word-length restrictions (Cotrell &
Plunkett, 1991), although appears one yet applied standard
present-tense past-tense mapping problem. However, believe diculty training
recurrent networks relatively poor ability maintain state information arbitrarily
long would limit performance task.
Another issue comprehensibility transparency learned result.
Foidl's programs past-tense short, concise, readable; unlike complicated networks, decision forests, pure logic programs generated previous approaches.
Ling Marinov (1993) discusses possibility transforming SPA's decision forest
19

fiMooney & Califf

comprehensible first-order rules; however, approach directly learning first-order
rules data seems clearly preferable.

6. Future Work
One obvious topic future research Foidl's cognitive modelling abilities context
past-tense task. Incorporating over-fitting avoidance methods may allow system
model U-shaped learning curve manner analogous demonstrated Ling
Marinov (1993). ability model human results generating past tense
novel psuedo-verbs (e.g., spling ! splang) could also examined compared SPA
(Ling & Marinov, 1993) connectionist methods.
Although first-order decision lists represent fairly general class programs, currently
convincing experimental results past-tense problem. Many realistic
problems consist rules exceptions, experimental results additional applications needed support general utility representation.
Despite advantages, use intensional background knowledge ILP incurs
significant performance cost, since examples must continually reproved testing
alternative literals specialization. computation accounts training
time Foidl. One approach improving computational eciency would maintain
partial proofs examples incrementally update proofs additional literals
added clause. approach would like Foil's approach maintaining
tuples, would require using meta-interpreter Prolog, incurs significant
overhead. Ecient use intensional knowledge ILP could greatly benefit work
rapid incremental compilation logic programs, i.e., incrementally updating compiled code
account small changes definition predicate.
Foidl could potentially benefit methods handling noisy data preventing
over-fitting. Pruning methods employed Foil related systems (Quinlan, 1990; Lavrac
& Dzeroski, 1994) could easily incorporated. decision list framework, alternative
simply ignoring incorrectly covered examples noise treat exceptions
handled subsequently learned clauses (as uncovering technique discussed
section 3.3).
Theoretical results learnability restricted classes first-order decision lists
another interesting area research. Given results PAC-learnability propositional decision lists (Rivest, 1987) restricted classes ILP problems (Dzeroski, Muggleton, & Russell, 1992; Cohen, 1994), appropriately restricted class first-order decision
lists PAC-learnable.

7. Conclusions
paper addressed two main issues: appropriateness first-order learner
popular past-tense problem, problems previous ILP systems handling
functional tasks whose best representation rules exceptions. results clearly
demonstrate ILP system outperforms decision-tree neural-network
systems previously applied past-tense task. important since
results showing first-order learner performs significantly better apply20

fiInduction First-Order Decision Lists: Learning English Past Tense

ing propositional learners best feature-based encoding problem. research
also demonstrates ecient effective algorithm learning concise,
comprehensible symbolic programs small interesting subproblem language acquisition. Finally, work also shows possible eciently learn logic programs
involve cuts exploit clause order particular class problems, demonstrates usefulness intensional background implicit negatives. Solutions many
practical problems seem require general default rules characterizable exceptions,
therefore may best learned using first-order decision lists.

Acknowledgements
basic research paper conducted first author leave
University Sydney supported grant Prof. J.R. Quinlan Australian
Research Council. Thanks Ross Quinlan providing enjoyable productive
opportunity Ross Mike Cameron-Jones important discussions
pointers greatly aided development Foidl. Thanks also Ross aiding us
running Foil experiments. Discussions John Zelle Cindi Thompson
University Texas also uenced work. Partial support also provided
grant IRI-9310819 National Science Foundation MCD fellowship
University Texas awarded second author.

References

Bain, M. (1992). Experiments non-monotonic first-order induction. Muggleton, S.
(Ed.), Inductive Logic Programming, pp. 423{435. Academic Press, New York, NY.
Bain, M., & Muggleton, S. (1992). Non-monotonic learning. Muggleton, S. (Ed.), Inductive Logic Programming, pp. 145{162. Academic Press, New York, NY.
Bergadano, F. (1993). interactive system learn functional logic programs. Proceedings Thirteenth International Joint Conference Artificial intelligence, pp.
1044{1049 Chambery, France.
Bergadano, F., Gunetti, D., & Trinchero, U. (1993). diculties learning logic programs cut. Journal Artificial Intelligence Research, 1, 91{107.
Califf, M. E. (1994). Learning past tense English verbs: inductive logic programming approach. Unpublished project report.
Cameron-Jones, R. M., & Quinlan, J. R. (1994). Ecient top-down induction logic
programs. SIGART Bulletin, 5 (1), 33{42.
Clark, P., & Niblett, T. (1989). CN2 induction algorithm. Machine Learning, 3,
261{284.
Cohen, W. W. (1994). Pac-learning nondeterminate clauses. Proceedings Twelfth
National Conference Artificial Intelligence, pp. 676{681 Seattle, WA.
21

fiMooney & Califf

Cohen, W. (1992). Compiling prior knowledge explicit bias. Proceedings
Ninth International Conference Machine Learning, pp. 102{110 Aberdeen,
Scotland.
Cotrell, G., & Plunkett, K. (1991). Learning past tense recurrent network: Acquiring mapping meaning sounds. Proceedings Thirteenth Annual
Conference Cognitive Science Society, pp. 328{333 Chicago, IL.
De Raedt, L., & Bruynooghe, M. (1993). theory clausal discovery. Proceedings
Thirteenth International Joint Conference Artificial intelligence, pp. 1058{1063
Chambery, France.
Dzeroski, S., Muggleton, S., & Russell, S. (1992). Pac-learnability determinate logic
programs.. Proceedings 1992 Workshop Computational Learning Theory
Pittsburgh, PA.
Lachter, J., & Bever, T. (1988). relation linguistic structure associative
theories language learning: constructive critique connectionist learning
models. Pinker, S., & Mehler, J. (Eds.), Connections Symbols, pp. 195{247.
MIT Press, Cambridge, MA.
Lavrac, N., & Dzeroski, S. (Eds.). (1994). Inductive Logic Programming: Techniques
Applications. Ellis Horwood.
Ling, C. X. (1994). Learning past tense English verbs: symbolic pattern associator vs. connectionist models. Journal Artificial Intelligence Research, 1, 209{229.
Ling, C. X. (1995). Personal communication.
Ling, C. X., & Marinov, M. (1993). Answering connectionist challenge: symbolic
model learning past tense English verbs. Cognition, 49 (3), 235{290.
MacWhinney, B., & Leinbach, J. (1991). Implementations conceptualizations: Revising verb model. Cognition, 40, 291{296.
Muggleton, S., & Buntine, W. (1988). Machine invention first-order predicates inverting resolution. Proceedings Fifth International Conference Machine
Learning, pp. 339{352 Ann Arbor, MI.
Muggleton, S., & Feng, C. (1990). Ecient induction logic programs. Proceedings
First Conference Algorithmic Learning Theory Tokyo, Japan. Ohmsha.
Muggleton, S., King, R., & Sternberg, M. (1992). Protein secondary structure prediction
using logic-based machine learning. Protein Engineering, 5 (7), 647{657.
Muggleton, S. H. (Ed.). (1992). Inductive Logic Programming. Academic Press, New York,
NY.
Norvig, P. (1992). Paradigms Artificial Intelligence Programming: Case Studies Common Lisp. Morgan Kaufmann, San Mateo, CA.
22

fiInduction First-Order Decision Lists: Learning English Past Tense

Pazzani, M., & Kibler, D. (1992). utility background knowledge inductive learning.
Machine Learning, 9, 57{94.
Pinker, S., & Prince, A. (1988). language connectionism: Analysis parallel
distributed model language acquisition. Pinker, S., & Mehler, J. (Eds.), Connections Symbols, pp. 73{193. MIT Press, Cambridge, MA.
Quinlan, J. R. (1993). C4.5: Programs Machine Learning. Morgan Kaufmann, San
Mateo,CA.
Quinlan, J. R. (1994). Past tenses verbs first-order learning. Zhang, C., Debenham,
J., & Lukose, D. (Eds.), Proceedings Seventh Australian Joint Conference
Artificial Intelligence, pp. 13{20 Singapore. World Scientific.
Quinlan, J. R., & Cameron-Jones, R. M. (1993). FOIL: midterm report. Proceedings
European Conference Machine Learning, pp. 3{20 Vienna.
Quinlan, J. (1990). Learning logical definitions relations. Machine Learning, 5 (3),
239{266.
Richards, B. L., & Mooney, R. J. (1995). Automated refinement first-order Horn-clause
domain theories. Machine Learning, press.
Rivest, R. L. . (1987). Learning decision lists. Machine Learning, 2 (3), 229{246.
Rumelhart, D. E., & McClelland, J. (1986). learning past tense English verbs.
Rumelhart, D. E., & McClelland, J. L. (Eds.), Parallel Distributed Processing, Vol.
II, pp. 216{271. MIT Press, Cambridge, MA.
Sammut, C., & Banerji, R. B. (1986). Learning concepts asking questions. Michalski,
R. S., Carbonell, J. G., & Mitchell, T. M. (Eds.), Machine Learning: AI Approach,
Vol. II, pp. 167{191. Morgan Kaufman.
Sejnowski, T. J., & Rosenberg, C. (1987). Parallel networks learn pronounce English
text. Complex Systems, 1, 145{168.
Shapiro, E. (1983). Algorithmic Program Debugging. MIT Press, Cambridge, MA.
Shavlik, J. W., Mooney, R. J., & Towell, G. G. (1991). Symbolic neural learning
algorithms: experimental comparison. Machine Learning, 6, 111{143.
Stahl, I., Tausend, B., & Wirth, R. (1993). Two methods improving inductive logic
programming systems. Machine Learning: ECML-93, pp. 41{55 Vienna.
Webb, G. I., & Brkic, N. (1993). Learning decision lists prepending inferred rules.
Proceedings Australian Workshop Machine Learning Hybrid Systems,
pp. 6{10 Melbourne, Australia.
Zelle, J. M., & Mooney, R. J. (1994a). Combining top-down bottom-up methods
inductive logic programming. Proceedings Eleventh International Conference
Machine Learning New Brunswick, NJ.
23

fiMooney & Califf

Zelle, J. M., & Mooney, R. J. (1994b). Inducing deterministic Prolog parsers treebanks:
machine learning approach. Proceedings Twelfth National Conference
Artificial Intelligence, pp. 748{753 Seattle, WA.

24

fi
ff fi


!"$#&%(')*),+-/.*02143(.*5*)

6,798$:;<+=),+2>@?97
!:"A;B'*C*=),+

DFEHGIEKJMLONP,QRLKS<PTUGVTXWZY[N,L]\_^`Ea^b\cG_dcEaJfehgjikN,Pl$LKS<PTUG

mXn/o nqpsrut<nqv2o wxzy{}|xz~M<vuo

X,Buu

/uUK]<9RA@OuXqu4a@@4,@,u9
4@A , _X@, q@A

RA//`q
c9,s&q q9_,/` **@9,9Ac_9A4 qk/q9
q/A9RqqAX,}A} A(*9M(*9A $,*}*q9X*c

**X(/@h***@9@Au$, AX_A/a,9/qKR q q
,9/q9*: A/429A9X//c*(9A,/A
/, U9(*9A $R_9,A_Mq*Ka*u$qH<,/(A
, **@9 **@9,9A$qR/ /B/ $ *$/(*
$2**<A/429Aq *M/ K / /(9M: 29R,a(9*,
$q(9 q,/A_M/&q9(< A@9q9 A(A 4,
A&<(*9A***(9*$q ,(9AqU&*: X qa
/ *$: 9 /(* u*9,<99 ,$(IB ,(9***(9*,Ms
/uq: **kq/OR(9*]*_ U,HA**@9$ **@9,9A *
<*9A *@__, /, qA**@9, /a *H(* _9
(9X **@9,9A<q *<,/A9 $qa*9 q9A9
(9AMA*u*KuzA<**A @9A A(*9q(/a* &X< *
q9A $$(,Oq9I*9A**@, q *</(*}9O(9
, ,XA**@, q *R `a q9A

q

M_




fiff ff
! #"$ #%&'(ff ") *%+$, -(.0/123!4( "5ff6% 72% #89&":ff

(; =<>"$?@+
ff6BA5 DCE F 8G8GB"
IHJ<KCLFMNHPO+
% #ff "E.Q-RRQ.SQ-RRT5MVU3<KCLFW("X7 ( #"
Yff$ !&"5ff # (#ff "3 ZB"
?@+$#ff&A5 8[B"
!% ("B"
I"$?\- 8G2+ffff6 "
%0% U]<>"^&"$?_+$#ff&A5
8N2&"$ `% -6"2&"$Gff$ * %aSff G?2 #A5 #% bff (2"c5+$ (dP ZB"
?@+$#&"$[5e_ ff$ ( (d 8f #g28G2% (
HP 7
#Aff6 "
VMVUihjeY+$6B"
ff$ Z[, ( #"kff,ff "lP 8N%B8m a- 8G2+ffff6 "
%E% nHP#%+$ (VM
p5e_ ff
- (q"$?Y g8G2% -(.<rCEFD-"* (A5 ,- 8N jff6$ %&&8s&ffff6 "
p t%(%28N2&"$ j% ("2&"$
#2, -, "5ffff6 "u(.E+$bi? -# "vff ( (H>w1+B"%"E.Q-Rxy5MVU
hqel+
&"$b!#%+
%, ( "5ff,ff "X/z *$-A5 Gff
s7B%&Bff>eff !% -6"I%B%ff>e_ - z5e@ ff6$ ( -
?2 (#&7$7% !&"I{2,ff|> ,?2 #[% k.a&";$6ff+%Nff$ NB8G ff,"kffG#%, (+&A5 !5e@ ff6$ ( ((U
} "$ ff6$ #!?@Ak"kff, ~ Z+$6B"
;~#%+
%Z #2, - #"5ffff6 "3ff6$ffv%+$%Sff6$ ( -v (eIff
8N"2&2+2%ff iP j8N2&"$ i% ("2&"$n% 6Bff628N(Up?_+$ Sff =ff
ff
"$ (jff `#%+
%tff
- 6e
75eD?2?@&"$b ?2 #% #ff&"$#%+$ (` =%B&ff #%d
-A5 G% (`"
?~&8s% n (ff,` "Dff
#"$ #%&Bff>e
ff
0ff6$ ( e@Uj$ S, -? #o # (?[ff, ff/z &"kff6 _?@+
ff6 "
0ff, <KCLFp.5 "$ Z2 ( #"5ff (?[75e[O+$% #ff "
"$?G= (?@ff0HQ-RR5M."
?s "
i7keYCL-A_Z
"
?s*'( , @aH6Q-RR5MVUjCL-A_2=
"$?Y= -?_ff0HQ-RR5M
2, -, "5ff= (- #"5ff=+26A5 ev <KCLF, -, -,U
S+$ iff6$ Zo %&% (/iB"
*?2 #{2"Bff6 " &"$?@+
ff6 "EU } ff
- 6eDH7
2, +2"
?v_"$ (/i% -? Mj`.2 #ff
&ff&A5 g8G2% -q'S
-((- "$?Y= ff t"
-ff6BA5 #g8s% (q*'0
(-(# `
Zff #ff
( "$( ffS Z&A5 "EUj$ #"!`5e_ ff0
-SP ff
0ff, #ffS( "$( ffiq"~PuVKo
V#->=&
"$? "%BeNB
')*),+Mfi

2







K

J

fi !! 9 ;*: ; K* `ff8R9 /7
!"A! fi

"! ! *;

fi
kVtKS2V
b((
[)]fi
0
(-
[ [ ]fi


Z
(-
5[ [ ]*fi
`

Yz26$[6B6B5Ns(
2I$*[(i($,-5$#$(!S
[
-6
$kk22zZ-u-
-5$#$(St

-6,6$#i&*6$i5_$((2$Y$Z$(&5
#2G2*$D
Y[ (j($, -5$#$(s q
6$ ( $fi6$*5@6$((NZ&$N$,

#2, -,56 (- 0`$D Z (( d`#Sp#
((
Y2j
zS($(#k6,`G$Z22#&YB
@$#&5Z(B
*$@&$*$,

`#$#&(4i#z&&5s#2G2((
z(a$@&$D#


$
]fi
b(-


[!
6#2&4B5#(,-\BI-6*
,Z
,B($(SB
-v5#I#$#&-6
z!#dz#
-==![#$#&-64q
n(`#$#z#$#&(Iq2#=
#
-a
,PSS(#$#t#$#&-6GBY,[#$q#2,-#5zB

,B-6
(
-z#$##$#&-6b($#5Si&[6$=$(&5`#2G2-i

5#i
,
#@1($6,5=#$#&(

*[S

~65o,VI
=o
,B(IZBG2&-6E6B
-&2
@
6=2#2
-~&D#N`q-q($(5$#$(s6@&D$-#&(4 -5 -5_
(25$No6$G-G24(#$#1
,B-6
Yi#
-2$Y!,
(B->62$62G2S#fi
0(b((2(fi*
B5,,-L
BSZ#D$(
&$,-LBG2&($&$(0&i(zY-G2kZ-z5#(2
,`*@&##$(`>z-#
>$s]
^&sB(i\N6BN(`($(*$#$#&-6
[2,B
-\5
6 @& (25$,*`-5#>#$#&-6t=i&!,-(#i*&sB-6E

2#S$=o&(i&$G$(i&!i2
`
(S$$((-,S2
6

ff
fi_ 5
ff
fi_ 55
ff
fi_ _ 6
fi_ kp 5 6p


fifi__ kk"" !! 6

fifi__$$ #!


0#$ j`(#$#a
,B(!2
2#Z>2
2G26$ %'&(&d E $!

$!
$G
d#
zz`(z
,#$#&(
2




2

#



&





B






6





fi


"
)
%
*
&
&






SZ#(S
Z66BN
,6$
D2
2#`>$s;
v$
&sB-6E i1*#-i6$ 0z[,d2V*BvY2#22&D$62,5*
(!,-#2,B5n$(($
,B(l$Z>$sz$i5#v2(k
ku
&B&$6,-\-5k^
[2&&B>Ib-6^,-#2,&5$(**#
Kq6B
-[,-#2,X

$6 =2,f 6$#YZ2,N(
I(6 zG2(6BN$N[BG,5,-62&G-
-#B
~#$#&(X$
>$s $~(#kY6$(#-&B^
@;0
,B-64$2#YBG2&-6E
(6 zz2(#5b~(25$D;(@
-DBG2&-6\I>$s3$(]
&k6_@
6E&B,,,
+B
B&@_i(B,(
(s2,$p(s#_B>G$[2626[,
@# $,-!&!(#
-
Z2Ni
d,-i,So GB&qi&N$Z$6Z$6
$[
$S&.%L=
-0 /5 $ 1 N0z$(#(@&$v $
3
-0/0G
24%L-k -5 5 &=B&#(
65 G B
Y" %(2

798:

fi;<>=<>?A@CBDFEG@0HADJIK=.IKLNMOB@PQ<>QRP=Sff<T?UVOW>BDJX>@0HADJIK=
[Y Z]\_^C`O^Ca>bKcde bfffTdg`hgKi3jkcbKlOmn^Cm
oprqtsuvnwxuyv{zn|(opff}~ffqt>u_z0nF,wz0nwxvnN]pr"o,qtsu|Jwvn.uznw|znw0upffuwvnFyvnqFznphzn|
Jvn~ffxuG}u>uFznKuG}{>,FznqApG>n RG>ARG>AGv>,sv0Kuyup{v0yGznw}uy}~ffxsp>qxuwxuyqyop
qs JxuGqFznpu} uGxwKuqsF.|Fwxvnuznw JxsJNv0xuy}znpvwxuFvnqFznppffzGpv0.n
~ ~ ] qFznpvnpff} qsu(.z0q]Kznwtqxvnp>qRwxuy~qxyznppffuGqxuy}qts qy
pffGu0upuwxvnJyvnqFznp ~pff}uwn~ ~ ] qFznp F)pffznqt~NFupTq|znw0upffuwvnFyvnqFznp zn|wxuy~ wx>u
Jvn~ffxuGv0Nszyppqtsup>qtwxzA}~qFznp*u Rqt~}Aqsffuqsuyznwzn|*0upuwxvnFGvnqtJznp~ p} uw
] FGvnqtJznp)upffznqxuqsffvnqNFGvnqznp.KuquyupFvn~xuyF~ p}uyJ} vnFu0vnpff}]uRKqsffuwu|"znwxu
pTqtwxzA}~ffGukvwxuyqtwFquG}|znwtzn|)NJyvnqFznpCGvnFuG}$NFGvnqtJznp
K. A$>AnC''A nx '9C
>O'J9C Jvn~ffxu4AGGA]Ov*Jvn~ffxu} upffznqxuy} rT|[vnp}znp3|KqsffuwuuFqv
~ qtqt~qFznp Rt~xsqsffvnq*r[zFvn~uGvnp}vnwxuG09GAKTGAG G9
}upznquG}h|,vnp}znp.|'vnpff}r]
n~ ~ ] qFznp4JNwxuu>uvnpff}qwxvnpffq>u0zJvn~ffxuG vGKuuG>~0vnFup>q ~ p} uw_n
~ ~ ] qFznpqsffzn~qKupN0vnwFvnp>qxy*zkFvn~uGvnp}vnwu 999A$}upznqxuy}h
|'qsffuvnwxu*uy>~vn~ qxz0vnwtJvn JuwxupvnNpff
ff znpffJ} uwRqtsu|znJzypff]Fvn~xuyy
44[$C A$
ff fi> fi xC
4n["C A$
tC A$ xC' Cvnp}
9[$C A$ t'
usvy>u tpffGu fi n !"# $
pffGu(% &'n( #k$
]ffvnpff}qts>~$
ku
vnFxzsvG>)u r *upffGuT +
vnpff}q[ +
, ]
sffuGznwutqxvnqxuyOqsvnqn~ ~ ] qFznp]Kuquyup]Fvn~xuyJO}uyJ} vnFu0,sF'v0/ .wqszyp
>% 0Rzn pffxznpG2 1 3Affffv005u 40>
687 :
9 < ;A' $$J = ff > nx '9C OT ?A
;A 2 @BA[] 9r

C J9TE DFGff
GffI H0$ C 9t.> C > JrK
up>qtJznpffuG} p qsffup>qwxzA}~ffqtJznp'Ku*vnwuffvnwqF~Fvnwp>qxuwxuyqxuy}pJuyv0qR0upuwxvn0upuw
vnJyvnqFznpysu.vnp wxuyv0xznpFqsvnq(vJuyv0q0upuwxvnO0upuwxvnJyvnqFznpp~}uyRqsffup |znwvnqFznp
zn|vnyznptJqup>q0upuwxvnJyvnqFznpy
>O'J9C Fvn~xuJkM
v L>K9 N9A>AG G9zn|v_xuqNzn|Jvn~ffxuGQ P

R2ESESx T#|(vnp} znp||"znw u>uwtV
UXWYU[Z \ 0upuwxvnJyvnqFznp~pff}uwn
~ ~ ] qFznp{zn]| PrFv_Jy] L>K9^ L>K9 N9KTGAGGA9" _)_>Rzn`| P|
vnp}znp |A|"znwu>uw0upffuwvnFyvnqFznp~ p} uwn~ ~ ] qFznpb znc| PAb ak
ff znpffJ} uwRqtsu|znJzypff]Fvn~xuyy
4 [
dc e
4[f e e gA$C
4 [
`
/A e vnpff}
h4 [

/A e gAf fi>
iznqtsFvn~uGj
vnpk} hvnwxu* _b_0zn| ) x% #>
lnm&o

fipqrts uwvyxcz|{~}xc(s u
f2Ifj)k5ff fft`2Ej V%Q(S 2S &8
ffQIkfQ!S O2ffStc!<O25Ej!E 'E ff22Q 25I
<]Kb"5/ !O5j ffSS
8'ffwjw ff]k tgI: cO!`w `ntwIE
ffEI"I2O
"n
" ]j
%b"58~ffSjSt%c!<O%ff2]S!(SE 'E j2
Oj!ffS`j2!! O"Q~ffYE2I5Qt&t~EQ!O
<(ffO
( '&ff
'y'SM
t'
fE!Vb!ff%2bI"ffI !` +282ffOE!BVOff'ffO
E!OffffE`ff~SffS(<ff%S(jEQ2/j ~(2SO8 &
cny b ff
kyffSK
'O/kO% '(
"</

&

fffi `%Sbff
E< 2nOE'' &|n
ffIEK
kOffk
ff

f`OO
<Ejk!ffjOSff<O bIffOO t`8SS(S O<
~
QOS]!ff(E O2 ~"fQ!
jV/ ~!ff"OSjffS
ff g" !$#&%'#)( +

*,g- %.#(/#0! #yff
1ff g" !2#0%'#(t3 *4g5 (/#0!$#&%' 6
%`ffE )
7OffS8
]5S SjOYIOffffk 5SO
9 E%jOYIO9 :)5E 54
< ; kffffk k=
> ;
f2(SOS5OSfffkSt2t`ff
E
EScE2 2 5~jIffk2Ejtk!ffQ5(E t5ff8(S
KffS~5O~kQOE)ff?X'E58ffSES!Of!ff!
fO
'ffSj$!ffQOSQ!O`S !(f`E+ffS!ff
fff

@ wffcffwyBA gI n CQntwIE+D F
EG

c(2OIH%2b(ES E |EI E2JH2/ff22%'&?K~!

OE!K(fSMffIE~!OffS5ffE2j ff2(E E

L'Q'M L<ffE22225J N
8'ffwPO &QY'<SR/

T8
V/
<nyRctU<'ffS'2gI n jn2w E
W

EI5
b"y & n'I]!?
V "
X~O!YE22 5ff2OS !ffOE!M(f`EE85S2V
S~2jI~(SYS EkI(" YK E~!<9 Z /2ff'fE2 2
O+kE22I~2IS$ffQQOS
b"OS~8
! /Kb"

[]\_^

fi`badc.adegfih_jlkmfJngjpoqcroqsutvh_f.w.xadxyw.c.z'a{e
|5}v~dh_jpdfJngjpoqc
rdvp]ifi7l .&Il
dm]p5 gd55 r& ?p '&m7
_Jmm&/ .I /M" d1 J') lm 0p S'Su
lm 0p F 9 lp_9dm]/dq)]_V]rgdV_V]"80 .
MS d0J.& p l /./ lm 0p v3..
2'I9 'p/y0. p'l .&
V"/34-S
V{5v,5
V"i0="g .
VVd+,5d2
'l .)l 0 .Gl 8 0d 3.r-l .)
yl80l0? &J.& +. .u8-l .) q S./ p l ././
5 ./ l $ .8
/S
. .

S/



.'')fi ffgl& I8 yd
/S&& yl .&p03 G & /p
m3d.r l l
q53m l .&p/./mp/ SlJlp ' GJ')
89l. S) Sl
-I9 J ]i
.&
lm 0p
q53mp '&m?puS./mlS Sl{3.&d) g.I) .J

p l p3- p l $Sl& lr/mlS Sl
q53mp '&m Vup?m lm
lm 0p G0'mulS S'mG
S/)& & S')0r 5G )m)d& 0p
3.&0.. 0p ' .0& .u& 3l .)m" !$#d p .00Sl $ ' )0 &8 3&&
p '&m
rdvp]i
2%
qp '&J dmm .&b 2J 0p /pS .&
B&b &?







,

+














+
'0.rS0 q8)( '3" yy v p *
)J
-. .& . -M mm
-/0
/
rdvp]i2 13q4 '/l 2 p '&{ Jmm .& J l Sly /0'
r/&b 2l .&. .r'8)3 2lS.l
g5
q p+gmS0. 7
6 .&
1l
8;: pmfim; <)pJV]" 9 . /? = + mm ; + / 1 ') mm
9
& l. .) {)2 .?
> Jmm .
@
rdvp]i
2 _ mm&. q8& l .)m0.&0. Jmm& .d8.J 0p /p
? $qB
qr& +l .& 1?4 '/l .
r& )0r 3.C
l8 0
)2 _]m0. dD1
9 . /?
dE 1
pbF
!$#d p4 '/l " _]m0. '
iGpH SS& ..'S $&? . S)0rygmS0.u _ m0. 1
5I =lK Jd. &'&u &? .4 /&?gmS0. _]m0. 1'?
p
_



J









&



/






." '0m 2
d&1

rdvp]iI2= ' ql .& .L
r)0) _ dM1 .





S. & Q
P 'v '
SR '3" y0 ) 1 3p '& .
V)
)T Sg UJ pmg3gd 55 -'S. )mW
V PX .v ' Sv PX
. PX ') 3l&&y &d
Y[Z]\

fi^`_ba]cTd,e(fhgjilkfhmn4opcTd

qsrtvuwtyx;zt9tyxbuD{4u|4}~t~r}rsE~94~pKzt~r}~p5~}b{4uufi}b{4u}]t3rltyx;uDvxbr~=uDrstyxbuD]$rpufi
y;yt~t4ty~pr}?w}Ltx;uFrprK2~}b~GHuFvz=tyx;ztzfipz;vu9E~94~puKzDfipz;u7~tyxbr4t
u~pfi~tyDytzty~};*bHu*u=z}*tx;zt0E~F~pu=0 = t=z59~}~wztvuyvufitsr2.$2qsrtvu
tyxbzt~hE~94~u=0 = t=z79~}~wztvuyufitsrhtx;u}ME~F~puKl0 = t=z}$Dtvuy
vutlr3
bEr};~{ufityxbu rr=~}b*zbvu=z}b{C3b4;ty~ty4t~r}"ufitsrhtvuywlWz};{Mvut

rzbvu=GE0IT
WR`R(R("fi
WR`]yGR"fi
&.b$
?.(TRTT v$z};{
E0Il,RRyERfi
,R 4R`Ryfi
,Rb]4R` 4R$
Exbufi}M%~pz*F~}4~wztvuyufitrI.&7$M0 = t=.5$z}b{DH0ylI~pstyx;u5~};ytz};=u*vutr
0 = t=bILu0x;zK$u tx;ztIE0I 9z};{Dtx]bC32qsrtvu tx;zt03z}b{3tx;zt
3
~$uM~94~=zty~pr}H~94~=zty~pr}A~p*vu;u~$u]44tD}4~$u~94~=zty~pr}H~94~=zty~pr}A~p
};rt9tyz};y~ty~$u{4u=ytvz9lw]~t=sKz$TAEx;u&ufipzty~pr};x4~AufitHuKu}?~94~=zty~pr}?z};{?E
~F~pKzt~r}b{uKvy~u={~}Errpzy5ur=0brprKlpvrIuyvz}b{tyxbuKrufiCE(rsz54vrr
rsuy4z};{tyx;u=rvutx;uvu=z{4uI~pEufiufivu={3tr7z5rr*$DGx;z};9z};{DRuKu7yK$(;zu .fi
}Dr4lvrrhrhErvrpzyD5HuIbvutx;u}brty~pr}rtyxbu=rFu*u}$tErz7pz;vu]
$h"[(Wut&K==KvI s=K==I47uMzfipz;vu]2zufitr5fipz;uK=sz};{
*
. K==fivb[4]5z9]$rpufiy4byty~tyty~pr}Lr . t.lEx;u}Dtyxbu vutsrhvr};{4}4~t
zbvuK7$` =K=.=` j= jK==.= jRF~pItx;uCT[IK r $C
0 = t=;
fi.fi ;s

,fi 4 "!#$
&l
% ')(*!#+!,.-/!0(1!#'2-/!435'768- %9');:) =<>- %?A@BC$
ff
,fi 4&
$D*-/!+A!E'03FB-/GH(!#'2-/!43I'J6K!#+,LH&%KM)C)(;:N-4!+G')+$! &% ')(*!#+!O-PQ,0R
fi.Tfi8UWV$XF[(Y
"h]+Z7AP[$[(; ]\ [$(?_^$G`');:
6+ 8/')(7!#$!8RbaY@BBc
'd- H
% WQwe,% fCK,! [KGCe!#$&%I.&QA@B9Whg5');:
6id- H
% W`A@BjA@B8C$k+D)-/!+A!E'EG8C l!#+
&I
% .!8;( $@jA@B'm
QnR
o_fi, p$qQz$5`

tyxbufi}BE0IC 9G2x;uvu&~ztvuy vut9r .$ . t.
.5$Dsufi}bKu]H0ylFr ts "x;uvu ~tx;uwKr94pufiwu}]t0r$LvuGMEx;u=rvuxw
.55
r "
z}b{&tyx$;sWD
(h tx;u}Q.50
r
;x;uvu ~tx;u5=rFuwufi}$trh$DC0 = t=R.5$Ex;u}
$ExbuKrufiz
wtx;uvuDu~pyt5z3tufivut5r0.&Dybvxtx;zt7E0I?
r {
z}b{tyx$;
H0yls ?FExbufi}&${4u|4}4~ty~pr}MWQw3}
|
~)

fiJ J8*QF J9 B7nFJJ*

O4f89]fIf$ffBfffIA/mffmfm8fjffffGT/fG.*1fT$8
/fGff>/mffJ. BBh8fBTm$GxmIAQT/8fGfffG/
Gf *O$ffn58f $89Bf/QT/mff0I ]Pf/m0BTfQT>/B$fm_G f
/ fff $O/QT/m?NfBOtBnT85 f9 mm8$f/IAQT/Q
0YB PffIfB9G HPf/m0Bf m9NTfBhNf h$9fjIH
yfi4G9ti+
yfi4G0tiH
yy#4+T5}A+4 + f
+4J
IB/ mNOh$8$fJJfff0tmf/J8G/f tOf/ Gf mf
IBK$5f$GF5_QjfT$Gt5fN>TOBf0B8B$KG >0 f>54]9
TNiBf/JhfhBfN54]9.`f G7Bh
N>85JjHI
5;$4++;7AT$]G jIA]&0 N f hGJ >y N
8.5IB8.Bf?/>f fTBTj8 HfB0G WfHIA/mYvIJ
5
IA/mffkG/58fJk$ff58.fB8] ff fvf
B8yTmfT//nf IA/8fGfj58nfB8
_ ff
fi !#""5$% &(')"+*-,0h/.10 ,F3246578E9.
_ :;<bi5=
2{ G QH GGTGfG fEO?>WvA@H ff
NfEhhJCB ] m0bJI .IQ mJv]DB3E 54]9 hfn mJODBF>}GB
f J EOD BH2IBbIBJKJ $f*GfML]DBzIB&ODB GB+IfBON7BJ/
54]9
BBfBhBJh( PT/fyhR
Q
[ /]V
^ `_aA 6bc7; Sed ]JV ff
f_ ghffi
j]P7kl8V#mnBoIpq8!D""
SUT V #TXWZY\j
>U%8&8'$"n*r,Kh/.Isl578f657 &tuvw"6"xy&*z!/&n%*f# v{g|v ,5h?.

:;<K?QBOT8PTGff IA/QT/mffh5KB8J>54]9 IBn0B$O"0k 9f
_
{J}Bk bJEkB8JQ f_IA]&KKOh$]fIf$fTBf mOfBGB]hff
fB*kIJ /HPf/m9Kf G NTmTf//if*f8fFmf $ NJ mffnT$f*/f f0*f
Bf>IA/8fGf08TfT7
Q

6 JV ff
k
l^ Sed ]J/ ff

~:4 `
m*>* fF* f/mffT ]IA/mff@e_K?9(P mnQ/f5Qf9@eH
f f?@eH+


[g
ff
@Y]efff 7fm8mmGxbh$Hf5f mmYf j`Hf
] mffJ?IB 9G/8 &vwz-v{*j!Vg8&Gs%v 'yv{z-v{*H
f
] m/fBnfT//&TPf
JGKeC yxG *B$f8 fGfn T]IAQT/8fGff
] mW0z"
g 8&g 8&vwz-v{*9!Vg8&?sl\v 'yvO-v*h
@A_
99fn ] 5f fT/v/&4fkJG
* f/m ffTBT>IAQT/8fGfjHBf
] m1H H N10B$K0;k/T/jfT

9f

z

fi{7#ff-q:i

l7a U7`(q%| wO7I8\OO
{`1o6i
{#8(
{ff%RV
{{ggl
7q(\+fA|a jg/7c:%jfA7cfe|Ca jga
AH%8wcf\|: 8w%%te`iwO|3R

1( 1I`\ gj%7(j8/\UCe|q8g(%i`\(q( O} D8U
g9\f(%iwD8O17c8w}7I%8\98/\zG w+KOI`8\je|
8g(%ji`t\8`6\iDD 187\ ze7OI`8\|Aq``cOjg
gj%8D88\w %9i7i8|6Giw %l
:jCAK\8U|(\O
z z9\8 (
e7( U


&

?









'

C









G





w







#





1

(

g

8



G



8



8

\



w












j

`





8

q6wGiwO #(
ff "!#!%$
*


(
C
+

O)|

c
ff fi(

qI8\e%89|8 %, `(7\U7t\8qa:Dwwgtw\8\q 77 - 7U\8
ODwgw(w 7q wO7ei:DwD+:O8`\Og cgf% .0/213 V7DD
.2.04g
5768fifi)98
: fi<;
ST









1



X,Y+

VUWQG

[iC}]\'^



con



=>
f


,

=>



OO \

,%?
BffGH



-Z+



@ _B7`aG)OXE8>%
h



-





n

?





,%?

-



GffGLKMBffD2ff
>N2ObBffaQ
BffD2E8Ec



BE8>p T%q ff
B kQObB @
EcrB:GIHJs

OEJBr`G)O7E8



BJGffGLKMB:DFff
>NffOPB:IQ
BffD2E80R

R



B:yN0GQkBffzO
{8BuiOP:G|EjD'GH0kY$}K~O zOPBuiOP:G






-A@ #BC0
B:DFE8#B:GIH



RyklR
iR

\

f




OO



edgf OO dih

Bj0klmE8>

VU)t WuEE0O @ w vO G0`G)O
bxE8>

R$}UWQGVUWE8>s

(q6

f



n



?

Q
BffDFE8>E0R

5768fiIfi)>l8
:|7ecVwc:`(`Ka(wZ
o&%t\8\qi\O/O\
i7(%HVU:x/O(`%7 w7c87\ tw7 \O:O(%g8wg 7(Co ? n

79\(D%`OOi\O/O\K`8VU:UV 8i%ww987\Ow ( +

` |c\8e1D88\w
Ot`i8twI`O}1A7(lgZ\:Dw /
G7`(`iw9l``I`o
YC&
7c7qcVf`(`t87\q r

(7 x&
? n iiw\U7tfVfi8iI8\ew (
:9 7\u #7(gw (
ti`t\8qa87\ z

@
=>
edMf dih

[iC}]\)\
BffGH





$}K~O wObBeiObffGY



8\ BE8>C T_q BffkQObB @
>Ec
R kQR
coE0D)>UVUWBu

E%B%N'QG0k>BffwO{8BeiObffGjDLGHQk


6A n E0D)>UYVUWBu OEB
K



R$}UWQGYVUWQk>2OEVEBffGY"!#!


B0BffDFE8>c



B%0klE8>
R kQRiR



BE8>C



N0GQkBffzO
{8BuiOP:GD'GIHF0k_$}K~O wObBeiObffG

@ v#



Q
BffD2E8Ecn





f





RyklR
iR

* f OO \ *' g98 f OO ~' \fDi(6`ii7w`O
e
18g(%e| 1A
G(g8 .% /1Og + G +M*F 7(l
7(e8/je|e3 1A 7ID%`86i`\U`%%i|8f OO 7\c7O
F
8g(% .# `A *
5768fiIfi)>l8

1A n

R

ff0

fi)Le02L
II_e))Q))WFPe
2L


}Q*eW8:g:0uu0~7:i7&:WgWlZry%g%e*'l=0uue~*'QF)u_*2Q)Qg
:
u:g:|W|Q







Vj0:
:Y:X e eI*=r)0e*'l=0uu0~*'uZ o&:XQl

C %uy<%F=]

Wl}& :Ql



:))%e*:=uu08%8u

J &

e*'>=0uue~*'Q

~:I2gg:

%u

*F

W0%820uul~8X:~*2:
:
QV|~g)g

ff

fi
"!$#&%(' *)+-,/.0#&1324+252617,89:87#; <#&%('=!*8>#&?&@%BAC?&#&D/EF#G)/.0+25EH%,+A&I IJAK%
#&%('L.M+ N)+O#OP/D/IQ24+RATS U)6V XWYHD/YMZY P! Y\[HS ]_^ #&%('`! _^ a:876%
cbd!\ ^ eY
f5g4hBh7ijlk ^
R!\ ^
/n
o!
qp
o!
;!
P!
rbd!
7bd!@s
yx
zbR!
ut
v cw
ut
{bd!@s l|
x
v uw Bx

x
C!@s
Cx
mv }w
~x
:!
lx
ff

bd!
/n
cbd!\ ^ Xfi
h7g4 }~H4"GJh7iqGh{H4Cq 3y z)+@# %7EMP~24qATS%BAK%ZP#&1PAK.0A+&EF,+#&.
,/.0#&1242+q#&%(' #P/D/I24ATS ~Y 876%9:8>/D-&E02+:2#9,+A&I{.0+Pl =cAZS mWYHD/YMZY @Y
f5g4hBh7ij

9

n

q=
b l + >b
n
y= n
6
l +
-n

@
+
C

_

q

+



+



q

n
+ l
@n

lb lb
6

/n


C

^
`

;
6

(

fi
h7g4 \~H4"G`h>i5q )+ #%7EMP524ATS ,/.0#&1324+2+~#&%(' #CP/D/I24
ATS ~Y 876%9:8>/D-&E02+:2#&% =cAZS UWYHD/YMZY @Y
f5g4hBh7ij !
G
e!
c !
^ ! 9k


k
5

/



6



fi

gg:)uarCW0e*8l=u0ue~*:u
rygp



Vg]rFWuryg

:)~ )QF
2Q)Q~:0:
:|W|Q#



*

7

e*'>=0uue~*'Q:)

V_|0:
::aYX e eL*



eC







7e%









P

:)

ry%g"e:0uu0~
:W

r





|X:)_r
=l



Wg*I_L|Q :

'l)y:ry%g":
ry

2

pQ)u*

Jy:lQg

Xa*L|Q) :a

*Z:)r gp %&a}Q

Cffu0uu J7ar)Q_

_IXCL|Q y:ry

jC'l= :#r



gWl

gWlF| |
:ry%gp

gl

V

ger

Wl} :#lQg

X *

J

_
W:#C'l= :#r&y:7>:



:)

r

r

r)Q% :
uXgW:lgWl



glW:)_g)

g *&:)gWl| ||g:Z

X
"*'l)y:%

X

r:)~ FWl'

j




}Q





eM2u0uQi*

eW20u0u~*IX~Qr:

|

2:
:
uu):)

e:

gWp I2~g|* |>eo~Q::L2Q)Q~:
u:g:)|W|QarV_|
u:g:X:% e eu*


'gW7~Q

)

ry2 JP

:Ql

V

V2 X #

ff * uuF
"

ff Xl0u0w7:
>
a}Qj



2Q)Q~:
u:g:)|Q%
gW~

V

gW:u7 :Ql

|>*~Qr:}Q
:W~uuaF)u



2 agWl> L
~:



:)





7

:

V

XXg)~A):

])Q)QlryF X

)0WF:g:|0Au:_:}]

g)ury2 XP

2 Xl0uuz


||~F=l



Wl~Q):7)X2:
:
u:~

:gWl~:)A

V

"*=l_

||~F)#~Q

|~F

V_|0:
::r% u uW*





e0u0w



)QAg)~le:~





V






:0u0

' X_:)

:0u0w


|~F

u0w
~Au:)> )Qg

Q
:W~2

:Ql
Ql

gW| ||g:







~:I2
:

:p:

Lr



7r



_gW0r0

2Q)Q~:
u:g:)|QrV_|
u:g:_:=% u uF*&
|W|Q#

V_|0:
::% e eL*

:)> )Qg

ia:)FWr
:Iu2 :QQg

Wl}=l_




r0:_|l>p





]}Q

I>:|~:2:A:)A

gWJy:QlQ
:W~_

2lWl>:u:g:|W|QX
% u u}#}Q




*2Q)Q~:0:
:

*

)

] :
Q

g|Wgggg: :

)Q



_&a:)

PQlQ:)~
J~:~:2:agWllQgYl:)>

&IC)_~QX:Q
:W~uX:|>:W0~:

V_|
u:g::r



Vju:g:]:X e e#}:)ZlQg>:|~:2:Z
p:Y

lu:g):#Ql2Q)Q~:
u:g:Z|)l%
|W|QX

% u uW*

:W~ )QggWl>X Lg~:

Wl}a :

r7

#:% u u|#

"



C



#:

FY~Qu'):~:~:2:
uu

P

Vju:g::% u uW:~C2Q)Q~:0:
:

ar)u:~Q

#:r

&;

gWl>C L
g>p:]

#:



% u uW*

fiF>+4{ZKB+
{3BKz{3r3u/KKr3
>K@3>KffKK7y7MeM0ffKKR>KyKy7Ky3/7/KM0ffKK7y>/yK>e
K y9Kff 7K3/7/KM0ffKK7@7=MJ6KP0K (0Jff>6 MJffKK
@K>eP0K lJffKCB3 GffCff
Mfi GPM7 / 0:ffKMP0K" 0 ffP0K q ~M
ff/MBJ9ff G7 oKMff G/P>`6KK73ffK_K:MP>Kc MK0; ~M
KMG7ffP77KP0K_ 7K>K /0K>6 ~edKP0ffff~Kyffd ff>P0K
MJffKKRCK7JK
!#"%$'&()(+*,fi(%-.(ff/102(3(+* 46587 - 587:9<; /$!=*?>@*ACB 9D;FE $!,ff>/$!=*
6/KH
GI GOP7J qff P7KL K oKJ P 0K K QRNS=7K>6Kfi G/
Ty>6ff >KR3/7/KM0ffKK7979eM6KP0KP7KeKR>KJ3/7/KM6KP0K>d>/RK
7JKU
F oKJ 0K ffMJfi
WV=KKY
X[ZJ\^]fi_^`C7Ke> aB>6B/b ffK
7JKK>dMJ6KP0K`K
RffK7ffP7yK 3KG/0K>ffc >3~ 7ffBJ @
jklJm!nejeo'prqts(u K7K
P7/r B3M G5MM/Kw vyxzK K7
"(fid.*:$'/e$!=f*hg /0K>i K0
7ff3K GMK: {|xzK 77K} vUK>~ { 7c G>K9~ffffK [
BK
> 9<;wE ( >5/0K>
K XXffXt``.Xb ` +Xt``

K 3KGl>6X X+`[`K>~fX+`>JG5P7@Kd~ff6K[
BK:TyJq G/cfKU0 7K
ff/PuGP>6=7/P7/.X+`7KXb ` 7 Ki~ M` KKy X Xt``+

8) = ; = 5 $'/$!=f*y3 psFKl1pj~ro'je^8pjeqNRjzqeq jeklrm!n^jeopJqsro'je^8pJPpJqK|MNm 2jeq
eq@om KQNP
KB3MK|
ZO73RBffzc G6mfi
V=KK|
X[ZJ\^]fi_5>33W
Z^ZJfi`+
% HKMJ% K
KB3MKu>KeK:ViV=K7K:VV= yK7ffcM7/>M7OK ff3 K797K
K 3KG/K7ff >Kc u 3K/;
73K/K
X[ZJ\^\fiG^`~73Mff GffP03K67@/0KP0K>MB/b ff6KMP0K K7MJffKK
B/ qffU/K7ffffy
Tyff/MB6dP7>eP0KUP7ffK/ X"ffff iZJ\^fi_^`JMPd9
ffKMP0K K>Ku GffyffKKMK[
KBKy>/0KP0K>MBb q6/K>eP0K K7MJM
ffKKJB/b ff9/0K>6; oK7K
fi70. HKP KKR B>>eP0K97ffK/h ff~
K/~K73 B6/d>ffJfi
Z6KJ g G X[ZJ\^\^3ff ZJ\^\^3fi `1>3Bff7c ~dB ~K>
0/G+
7/7K7O2
Ku X[ZJ\^\fi^`5>J GdK G/6KG/r Ke ~0L7c >K >
7JK7ffK/
oK~MffKMK6q7Kyr G97KR97@BffK"ff3 ~7/=>
ffK7/ffR/ /0K>6q6KGK>K
dK>/K7F /J WyK GlP7yffKff/ HKP KK
>7JK7ffK/h +~0R>36K7 (PRffKMP0K
XK>K wZJ\^fi^`
q@m pr oK MC/ MK0 K>Ku
e0=
"(fid.*:$'/e$!=f*Lg P7PMP0Kce0yh
M7KK g 7/C% HK r<
k1sfiprqprjeowq@m pJ2X9Kf ` oK uu lK7Ku
u HKCff3
u >} .O> ~C7PPP0K 7P7K u
KRdK w7/P K0~i jfi1s FKC
"(fid.*:$'/e$!=f* "/ K B=CK7ff @K K>%
e

fifi@fifJ^'.@@rfi@@ffPb.fi'fi^'
fi.:'e!fL @6H'}S18eeJ: %r'6J
fiff
~6
| [ @
~' ^ }
P !^ 6 }
P
@ fi @ ^ ' 'c J
' 6 6 ~

%
f
' @r@6
ir'6J
6J ert J ff8 F
fi.:'e!fT
S. 4U 0 ~6. r'6c3 I/J) 7VhXWL18YRffHZe%1U +63 G[]\
?^U_'`F
t. aL P^3 %
('b[]cd?^Ue'gfhU4+ +
0 'g[\i?^U_'bfj[\(k
ld?^U_'7D#;n
m&C<$ffpo][\(k
ld?^U_'
~'*
6c6 2fi. (} + #ff,= qsrTt!I
w8 x y{z}|`~78x! v
w! x1{ U1P N8 POrQ NR^811 Ne }N > NRff'` ZO`Ne
u5v

OrQ NRff8. F7Wr
UpmfZ Ne ~e@Y :Z }X WJ dZ1
N,OJQ NRff8 ffoF[]\+?Ue'L R
OWX W
Nb ff}e
8 1 qsTt

J)
3 ()Jc. g3 J)J 6L@3 2fi 0 J. 6c6. (63 0 . fi + b +9

+ K?>Ld(d'`
P 0 # P
#~
9d9. 6 ?Ld(d'I_J)@. 6'6. 3 c^ e

3 . 6. c ['. 7!6 !. >t
J 6 C [ 0 5fi'd 9 b
9
5SJK ?Ldd('

z @ 0 3 ?>L(t('`Ib 6 ( J L % _ fi 6 0 . 6c6 ' (2fi 2fiL

c 6-+ 6 ' r@6
6
({ @c
>@5
@ ' gq>#6c6u! [ ?L fi. 3Ii
r'6 >@ q>6c6u! [ %L fi. b^ 0 c 0 6 @3 ]Q 6@ Q 9 @6. r@6c 0 qCA#
6c6
' 3
fi.:'e!fF
KU 0 i6. wr'6c3 I)J)@.
@zX W18eY R^H Ze~Q Nffr U4 t. @ L fi \ ?^Ue'
P t. aL P^3 %
'P l ?^Ue'gfhU4

(
0 'g \ ?Ue'gf;
meU'. 6c6 2fi. ( o#*?Ue'.
ffoV(?^U_'P _ j*fqCA#d{

5/=i qsrdI



w XwLy|>Lx (!fs
.ff` 23+F

J 5787 ,w8{ ci X e!f 7 1 NOrQ NRff8 Ne
ffNe
> NR^e' dZO`Ne7 OrQ NR^8L 7Wr5
ffZ CN e@Y *Z X W@J Z'1C N-OJ NRff8g o# \ ?H;&='
L R
OWX W+N
ffne8 1 qs

u h&uL _ ^6 6J)J 6L!
0 6. 2^ ' 3i. 2fi. fiqd
r'6
\ ?^Ue' D'6:
ofi[ \ ?^U_'`I-J)+'}J u fi6r'}@ @ 6t'c [ 0 J.
r'6J3 ff+ 2ff'. (]6D?c 6 0 @ [ }6r QX6c6 ' + h"b[ 0 [! 6-![ I~
9d9. 6
?Ld(d'g@^ ({
@cL ,>@e @ ' ~ L . 6 + -6 6 r'6c c Q c [ @ + ]9^.
. 6Q c
[ @ r'6c4 P@. 6
% @J J6 2fi3 B >B 6z6r 2fic3 I,r'3 }
!6c6 (
t. a+ '
b>@c6 + 6r 63 ?c @c !6*
6z{ aL sCI 3I 3IEc J. 5 t. a+ ' 1[ 0
[! 6-![ ,J 6FI
fi.:'e!f%W @6e ff#. q:X WM J ir@6e
ff . 2^ ' ( } @
s\i?;&5='?@q&'`I663 ] sqX Wz1 ff/IF @6C ff BZ Z!` O1 qX W


ff!
#"
$# &%
(')
* + ,ff-
* . ff/
0 '1
#ff# 32 4 52 0
66 7
8')
.
#
#

#ff-

'1"
,6:9 );&*< 5=(

8'
)>
-??@:AB;&C='EDF?@ff:AG;&-=''H"!I
J)
K
#ff
L :M+N
PO QNR
*I

&

fi+`8iHe^`


).5.Q+$
] E>
.$*.{^)5.Q+$
$
+^)
>

fiff1. CQ$5L]>
QP#8
! .g#"e4.Q+$e
$}-
L.%
ff).P &)
.$}Q`+.'()@*+,
).
V
# ] .
- ,
Q$$3]>
^P`+./ ,
807
1%23547689;: +Q!e>
QPff 5< .^
$3=
?>A@CBD@FED@HG+IJI%KLBD@G+IINM
O>A@)BD@PEQR@G+ISITKUBD@G+IINM
A>V@CBD@FEXWY@HGISIZK[BD@HGIIM
\ >A@CBD@FEQR@H]^ISI_K`BD@H]^IMXBD@PabIINM!+
c >A@CBD@G+ITKUBD@PabIDId
& +.Q+$ ^)*L3
]{_f!e +,4!,$eg h)& +.Q+$ ^)^$*,
L.
)
$3L+-{e \
e
3 ^b5L3
$ep

$[i)j k+" k:
l L \ :d.PQ1


\
\

{ $3.*$3L+/{
e7
35n- poibq(.r7sOtue
.Q+$ c Qs+{ $3v>
$ $$. wek
" +
4V
3$4
L.e$$e^P


L.e$
& $Ls+5,.Q+$5xl
^L
>
.*
^Xj $dQu< ^L.^
$4,$3F>
*>
^


^4
L.*{51+]+^
$R
e ^fi(y zdq ^( { fi1ff N(q .e $#$3F>
5,.^
$QC

{ $3.|
>,$e$):
l
3z
} 3s
QZ:
l $e @S:
l z(q u
mFl
^3^~" F1ff L.j^
L537" ]!L$.z" 3ds3)l;"
^je$.Xj $3$ ^

i)j^"
^l
^ ~^S <d>>kl sL)l
!$ !, id<zq(L*+5# $)"!Q]{1;}!
j
X<d
< .
.$ 3 ^
5!
.;i)j ^
" ^l
^ { +LREe $" )" ^$!}
~d< .
.$ 3 ^
*!
!
zl
^L>Q$)
ff CQ*
3L#*L$!y +*$5Y(q .$3$ >Q

(x.+ 9) g 9fg9fi+8) ( fiN C0(D

.;1ff SBGYq(. X<fi$3$ ^T

zl]> 3
>Q!LB>

$)"^bl e3
>+>5<


$.^
$;< z(
q .F>
5$3$z(q (*+F>
+
$.(5.Q+$$@H#X<u<^.$7.g(

tfiuu^Ze k(q .' Xd< .etfiuu^_j
e|tfiuu^T#
5<u<Q.$e'tfiuu^T{e^l])lgl5!etfiu^tu
m3$)ljFe xl$y !Q>e+tfiuY5e ^(q $etfiuYuIN ) .Qff)ff |Pff !L$.z" +fi
ff JXj (>${i.$^3
"4+$L#-3
>+CPff1
$.(4.Q+$3K^$)l!
*Lxq(.( ! .}+f"*^
Le

,>
QP
ff 5< .^
$
*L$z(q .
f=
#>#@J@@ /$70)I@g$70)IJIi^M
ffP+]
^*#d.$ege,
^*,@d- e
/Dehh
+7,
Q*7l$< fi
0vM gY
4$3N
$.(4.^
$3
+4pl z:
l d< +F 1&
. )ff *>
^#Q.'De

$i
" Nl
^
" >>^
0ePff ^$,3L
+e$5:d$^l
^,+)+*+$(^^fi
qd>Q)!" Q3)
d" L.,!
+_L$ >QsV
fe
->(
%1ff K+fi(q />
_>
^
^$5Q.P?~0>70YeXP
ff ^$sL>$3

!/d$kl
>Q#>
3d$# $.$f ^

. $3
" #^$)
l
f h)& + )ff
(q
A>0*

O> YM
ff +~
P
L!Q" fi( $.$4
e
1ff $3>
fi +# $)" +LQ)l(" Sj
>${+>QG+ v
0

fiYXY+0fiu((_0XXbY'XX5RF_Y0Yu(
%57;Z)5S^N'JX/)z%x5gb)X
?ACDFRH^S_`DPDH^S5DH^
)X
A)DPRkJ DPDH^S%`DH^


)



P







k

J



`



H

^







Z5b)5fi )X
`)
X)*NYN)X%)
fiff
Z5
( Yk^ YXr
^X
X)bYN)X*fifi)
(X*fi *fiX kz)S) *
XS ^S) ffZk/)zYbSp)v k u)NYpb)X" !SXu#z JX$^k; (Y%!
)'kS5N*p)
k (b|x5zN|*)*" ff'&+)'( $k k'SXN)X*
)?ACDFD+ *+J%LD, *+
% k* (N|zXzb*fi)X*)|). -!+)Xz/ FS XS / ()S )X
0ff
1_
(uSzS)3
24SX'JX)SX|b)Fpb)5fi k*)x5fi
65)^Zk^ YX|)x6 YbSJx5
)X)zkJ)~|u)fi)z 5 " Yk u)bY*SX)S)zX)N)X% ff7F8
1_ (uSzS)9
2:z//SX%
S5)|); zYSN)~)h)Xzzb)%;ubXb)*fi^k< R5p)'z6 YNJSzX)5*fi)zkJ)= ff
>#?A@XB
@DCAEFEG@IHKJMLONQPSRTVUP-WYX(ZW\[^]AP-W\_a`cbOWZedRfP(gWZehfii=jkP_Ylmcnpoqlmrlmbsn trl b/n^nMh
>#?A@u@DvSwxRzX
zy{|r3lmbsng)X}
zy~9rl bsn6! Z;5
z~9rlmbsng)58
z~9r3l b/n6ff
Z5N
65Y1h* (uSzS)
!rlmb/n/)X
qrYl b/n6ffBZYX
lmn lmrlmb/n rl b/n^n6ff
Z5b)5
U; ) YNY)p qrlmbsn)X
qr}l b/n6ffZ5N
657)^XXg)'*fi*)x^S) !
YXbRJ 5M!Tlmn#oqlmr0lmb/n rl bsn^n6ff
lmrlmbsn r0l bn^n lmn6ffZZ)X"
>#?A@XB
@DCAEFEG@IHKJMONQPSR W\_a`UPcXZW\[%]APS] W\_a`WfigSPS]A\Ze\P_RB W\_a`0hi=jkP(_R,jkP(gSPPS^d]R,]
WZedRfPgSW\Z6bq][DXSjYR,jkW"R r0lmb/n0W\_a` trl bsnMh
>#?A@u@DvSw 5JXp^ ^kzS)~)_;) YNY/Z/X
JH# lmn r lmn J %5N*
$~ub)) !s#$~ub))#
! A)X

0!
p - %5N*8
r lmn !)X
)
$) H)3
lm n6ffb
b p!)5S5N{
rlmb/n H
0 lmn r SzX
9rl bsn [S#
p -ff bX # # r lmn )X
lmn r !^)5 fi)5 YXbYS 5 trlmbsn)X
fiy JH#
trl bsn6ff
(
hgC"@+,F\EG@IH=C u9?E,HkFA?m@u
Q\F\EG@IH
Z5*fi^k<R5)x6YbSJx5)X'*fi)zkJ)) (|ubXb)z;p*fi^k<R5)x6YbSSzX
"R5N5fi))zkJ)5uZH)xfi" ff'ZXb
u HI M?"FE,H={ FE

lmrlmb"n

rl bmn^n

%5N*/ _b)X%)5bh|zx*N*)!R*N_)+Fb)5fi k JX%b)X/ )z'
65)5)zkJ)=ffsxYx)S5M!YJXFN*
lmrlmbmnrlmb n rlmb"nrl b n rl b"n^n )X


lmrlmbmn rl b"nrlmb n rl bmnrl b n^n


%5N* b)5%)5
b)X
b )%zzb)" !)%*N*h)+Jk*fi|b)5fi k )z'
65F *fi)zkJ)5"ff7P SXv'5M!H)|)Yb zx*N*)bm!b
)Xb'^!5YpJ$$(N*NY
b%)D)^|N)X `%k
H)xfi'/ 65S^)zkJ)5" !)X ;) ff.'z(SX/b%)*
); zYS*+fi S5b)5c
fiff
\m

fik%AIBBu<

6BT\GI|Qu3<DSD98"%kkpSSmD(8( <D"Y<

0TD Y.;k

\SfGSm\D
/

fiffm
ck



ff ff ff!" #$ ff !% & pDY !('#*)+)*)+#,!.-/#,!012/D(
6<#(=(<D"
4 3,6;SMI"
VK
56!('#+)*)+)*#,!0-7QD8
:9
G

;=<?>/@ACBGDk;fD G*2//E(<D"*
GFH1IKJMLN4%OPFHMLN?Q#

' fi7FH1I/JRLS$Q#KFHTIVURLS$WO:FHMLN?X#

fi7FH1I/JRLS$.OPFHTIVURLS$Q#KFHMLN?X#
U
YZ'= FHTI/J[RLS$Q#KFHTIVU7RLS$Q#KFHTIHMLN(OPFHMLN?X#kk

FHTI/J[RLS$Q#KFHTIVU7RLS$.OPFHTIHRLS$Q#VFHRLSHQ)
U
kSfi(k"\ff]'#$
<c4,3 6;SMD"S ^ FH1I U MLN411


DfD(-/(<D"
U
ffYZ'#$Y .<43,%fMI""fi<_]Q
' \ FH1I?RLS$T (
DS6D(6;`\
fD(=<DSWff #,YZ'#$Y
U
U
U
</43,6;Ma"0<VK5 FHTI U MLN4Q#KFHTIHRLS$T
afDXbdcu*e6&D(kf]'/<c"`e66pHYZ'sDY DY~<'-SSe6(6g]'
U
D\
DD"%k6f[9B(;`e^/<:ff
#,YZ'G#,Y Sf='D (B(<D"
U
U
U
4 3,6;SMI"8< <DSc/<&E<06`e^<6p;D (<Dk<fD+2s0fD-+<+2/KE
;kSX
~ f
hi KjAS@lkKmon,;qpHrTtsK>/BGHu%vAgjmxwxj+s/>M\GIKyBKj*z,IjAV{Wr?u^GI.|Z}
qASBpt\&AQ
fiffm [
\SfGSm\D%(S7+tA ~+ AQ(D(u-ef7 6!%'#*)+)*)#$!.-]? (



jAuK
yD
cSM/<#
Y;D
Y;<
DD(;<
.]a;k<8u D"8fD=3;k
;S(6
;k#;kSXfDc
kb".
/$3,6fMI"S { p(D"cffm 6
*Af5f/, .
uDS k" Q `vfKq .?Zfiffm S2/D(fi#/$3,6fMI"S { !('#*)+)*)+#,!(Q
=(.0
9 ?\

D(YQ ' gff ffff!%Q ' #,ff !(Q ' &
uDSf8fKZx"X =
<
4,3 %fMI""S6!%'#*)+)*)*#$!(#,!%Q ' .v.
Su
c ^;;<+N7
2 k+6
e ffff!(Q ' #,
ff !(Q ' & ff
D"D"6D(%f3
?Q '
?%
%
fD#DD(;<xu
c ;kf"mff

;6k#?Q ' fim
ff 6
P
a3(;<
\2fi;D*
2"0fD p<q
cu^;<c
e6(;-k-";<8
$ 3,6;SMI(;<
DSSfi(*22;k+2fDY<vcu^S;Se6(;8"6D(D"0 "fk
4 3,6;SMIf
"%kkT(<"
BS@

@5>kfi} \a Y~ t\AQ ffm"'#*)+)*)#f-K AfiYt\&AQQu ff]'#+)*)*)+#,v-/
AS#+`\

SGm\"(S7 %D \am\ \ \\= =.v$
? ( (S^
` R\A
t\
ffYZ'&#+)*)*)X#,Y"-K \Gm\Dq(S7 =D mm\^(
0 g Y"$

jAuK
yQ%
vauf;S4 (<D/
ff]'7#*)+)*)#$v- 6 D(d
2D*
e6fv %+S
(pB(<(afk\ff]'&#*)+)*)#$v- <43,6;SMI"8<0%D" 0v$k;kSb;S
;k;;;;<5
.;D;D
*C_(.
6k
:Y\D;kS-X
b<;/;D;fff
8;k
;k
%kZ
2ck+
e6
M%R _MY%Xk"DS6D(6;` 8
*MY%
=(q
Y" Yd(3D
2k+
e6-=
gY";

7

fi"Kx+&xt0KKqKK/10t&xt

G Q ff
fiG

fi ff! #"%$'&)( *( + -, *./ 012
fi #34+656 +879
7: +<; 9
-(*(=
8 +
(>@?A3 *( + , *B
fi CD? EF
( *(= GC4HI>J$
K G9L-MNPO=QSRUT-VWV<XY[Z]\_^a`V<bBRUc[Q%d-Q0bfe<dgO9Q bfe<dgY`he<c!Yji=kWl9` dmY[V<inV<iAoqpGrsd:ZmO=V<lUc[k\!Q#i=V<d6QhkdmO9e<d
e<i9kt3vuUYjidmO=QwZmd6e<d-Q%bQ id#V<XxdmO=QydmO=QV<T-Q%bzu{YidgO9QSRFT6V{V<X|e<T6QSYi9kFQ%}FQhk\^aop
~ hG .Q $ g9%|^AdmO9QBkUQ UiFYjdgYV<iIV<XPo!dmOnT6QhZ6V<clUdmY[V<ic[e^_Q Tw]<#"S yu)e<i9kzdgO_l9Z ? yp
QPO9eh_Q:dmO9e<d3 < Y[ZV<Tm*Yi_dmT-VWk{l`QhkfX[T6V<b \^dmO9Q0Q bBRUds^.Z6Qhl=Q%i=`Q0V<XcYd6Q T6e<c[ZP sp
Q%i=`QuUXV<T ?A3 dgO9Q T6QwQ }WY[Zmd-Z:e2`%c[e<l9Z6Q ? Zml=`6OAdmO9e<d H p
!7<9
s<(U-= *K( g9#6V<TQ _Q Tm^DtudmO=Q%T-QQ }WY[Zmd-ZeZ6Q dV<Xw` c[e<l9Z6QhZA3!wV<Tm
YidgT6V{kWl=`QhkXT-V<b \_^Z6V<bQfZ-Q_l9Q i9`hQtV<X#cYd6Q T6e<c[Z|w <hh 0Zml9`6OdmO=e<dfXV<TfQhe`6O
>@?A3!dgO9Q T6Q.Q }WY[Zmd-Z:e.`%c[e<l9Z-QyC@?Zml9`6OAdgO9e<dCDH>2p
!7<9
s<Q $ Dg9#{t ]^dmO=QzkFQ%FiUYdmY[V<i V<Xyo!dmOT6QhZ6V<cjlFdmY[V<ic[e^_Q Thu / YZBeT6QhZ6V<c_Q%i_d
V<XZ6V<bQJ` ce<l=Z6QhZ ? #"/e<i=k ff ? 0"2Zml9`6OdmO=e<dfu e<i9k
BIp.NPO9Q iz\_^nT6V<R!VZmYdmY[V<iFudmO=Q%T-QJQ }WY[Zmd-ZSeBcjYd6Q T6e<c|Zml=`6OzdgO9e<d H / : 8
e<i9k ff H / ] p
]^ndmO=QfYi9kWl=`%dgYV<iO_^WR!V<dgO9QhZmY[Zhu]dmO9Q T6QaQ%}{YZgd6Z.etZ6Q dwV<X` ce<l=Z6QZ23 V<Tm*Yi_dmT-VWk{l9`hQkXT6V<b \_^
Z6V<bQ.Z6Qhl=Q%i=`QBV<XPcYjd-Q%T-e<cZ/ 8hhh |Zml=`6OdmO=e<dwXV<T/Qe`6O>?3 dgO9Q T6QfQ }{YZmd-Zwe
` ce<l=Z6QAC? Zml9`6OdmO=e<dCH>2pNPO=Q%i\_^)Q bJbeA{uPdmO9Q T6QtQ }WY[Zmd-Z/eZ6Q dJV<X` ce<l=Z6QhZJ3G
V<Tm*Yi_dmT-VWk{l`QhkXT-V<b / 8 \_^BZ6V<bQ:Z6Qhl=Q%i=`QV<XcjYd6Q T6e<c[Zv| # # Zml=`6OfdgO9e<d
XV<TQhe`6OA>y?A3x dgO9Q T6QwQ }W Y[Zmd-Z:e2`%c[e<l9Z6QC@?Zml9`6OAdgO9e<dC@HI>y p hh
]^2dgO9QSYi9k{l9` dmY[V<itO^{R!V<dmO=QZgYZhudmO9Q T6Qffe<cZ-V.Q%}{YZgd6ZPe.Z-Q%dV<X`%c[e<l9Z-QZ3 V<Tm*Yi_dmT6V{kWl=`QhktXT6V<b ff \_^
Z6V<bQ]Z-Q_l9Q i9`hQ:V<XcYjd-Q%T-e<cZv <hh =Zml9`6O2dgO9e<d|XV<TQhe`6OJ>@?A3 dmO=Q%T-Q0Q%}{Y[Zmd6Ze`%c[e<l9Z-Q
CD? Zml=`6OdmO=e<d0C@HI>2pNPO9Q if\_^Q%bBbeS{uUdmO=Q%T-QyQ }WY[Zmd-Z:e.Z6Q d:V<Xx` c[e<l9Z6QhZ03 V<Tg*Yji_dgT6V{kWl9`hQhk
XT-V<b / \_^Z6V<bQ#Z-Q_l9Q i9`hQSV<XGcjYd6Q T6e<c[Z0| w hh ff )Zml=`6OdmO=e<d0XV<T0Qhe`6OA>y?A3G
dmO=Q%T-QwQ }WY[Zmd6qZ e/` c[e< l9Z6QffCD? Zml9`6OAdgO9e<dC@HI>yp
NPO=Q%i2YdqXV<cjc[V#ZqX[T6V<bdgO9QkUQ UiFYjdgYV<iaV<XV<Tg*Yji_dgT6V{kWl` dmY[VidmO=e<d03 3 3 Y[ZeyZ6Q dV<X)` c[e<l9Z6QhZ
V<Tm*Yi_dmT-VWk{l`QhkXT-V<b / \^ hhh hh pqPV<i=Z6Q_l9Q i_dmc^_uUdmO=Q%T-QSQ }{YZmd-Z
efZ-Q%dV<Xv`%c[e<l9Z-QZ3 V<Tg*Yji_dmT-VWk{l9`hQkX[T6V<b / Zml=`6OzdgO9e<dXV<TffQe`6On>?3 dgO9Q T6Q2Q }WY[Zmd6Ze
` ce<l=Z6QyCD? Zml=`6OdmO=e<dSC4HI>2p
!:x ?G 9Lff ?*[
rsidmO=QfZ6Qh` dmY[V<iFpYdyveZwkUQhZ6` TmY\!QkO=VeT-Qk{l9` dmY[V<iV<XQ%i=Q%T-e<cjY[e<dgYV<i`he<i\!QBe`6OUY[Q%_Qhk\_^
T6Q RUc[e` Yji=ze` c[e<l9Z6QB\^eAZ6Q dwV<X`%c[e<l9Z6QhZhp Q%T-QvQBZmO9VhO9VhdmOUY[ZwZ6Q dwV<X#`%c[e<l9Z6QhZwQhlFYje<cQ i_dmc^
`he<i'\!QkUQhZ6`%TgYj\!Qhkt\^teBZmYi9<c[Qw` ce<l=Z6QuOUY[`6O'vQw`he<cjcGe<inQ%}{R9e<i=ZmYV<iV<XdmO=Q.V<TmY[<Yji=e<c]` c[e<l9Z6Qp#]^
kUQ UiFYjdgYV<i)uvYXe` ce<l=Z6QC<sZglU\9ZglUbQZBQ%_Q Tm^I`%c[e<l9Z6QYjienZ6Q%d2V<X` ce<l=Z6QhZJ3vuqdgO9Q iCYjcc:e<c[Z6V
<sZmlF\9ZmlFbfQe<iGySffV<X3vpGNvOUY[ZPcQhekUZ|l9ZPd-V.V<lUT0kFQ%FiUYdmY[V<itV<XxQ }WR=e<i9ZmY[V<itV<Xx` c[e<l9Z6QhZhpqNPO=Q0YkFQe
V<XQ }WR=e<i9ZmY[V<inV<X` ce<l=Z6QZvPeZ:FT6Zmd0RFT6QhZ6Q%i_d-QkA\_^Ar1kUQhZmd6e<bBs0cjblFYZgd0g`8"%p
_0 gt7)Q \!Q:eff`%c[e<l9Z6Q0e<i=kfeffZ6Q_l9Q i9`hQ0V<XcjYd6Q T6e<c[ZhpGNvO9Q ifeff`%c[e<l9Z6Q0>Y[Ze<
,=<U
V<X \_^AYXe<i9kAV<iFcj^YjXG>4Y[Z:e<iAxffSwV<Xqe/Z-Q%dV<X`%c[e<l9Z-QZ0V<Tg*Yji_dmT-VWk{l`hQktXT-V<b \^'p

?xKGSlKo4*[*RHG[*R7^?RH/+QRGC?&70H? Q
G

/ / Q Q
GQ
G
x
Q

/ Q
G



fi= 0<!U[
:)=

ff
fi
!"$#%&'
(*),+.-/+102+4365ff5879-/+4365:5<;
)>+.-/+10 ?@+BA5ff5C7D-/+BA525<;
=
=FE

)>+.-/+10 ?@+BA5ff5G7H-/+I0KJL+4AM55<;-/+BA525;

=

)>+.-/+10 ?@+BA5ff5;-/+10KJL+4AM55<;-/+I0/+BA57D-/+BA525;
J

=

)>+.-/+10 ?@+BA5ff5;-/+10KJL+4AM55N7D-/+I0/+BA5ff5;K-/+BA525; # fi

?


)>+-/+I0/+4365ff5;K-/+I0 ?P+BA5ff5C79-/+4AM5;-/+4365:5<Q

R ST/" #% &VUW=FE ; =

; =
J

Oe
$V#gf:hihkj/UW=FE ; =
J

; =


/ffY4
Z&[fi@% \fiF$&]*C$#%&G=*^P_!` -/+I0KJa+BA5ff5;$-/+102+4AM55cbcd #fi

?.X

T\mP%"Pff_ Oe
$V#gn[o# ff
$!p=>^P_q` -/+I0KJZ+4AM55<;T-/+10/+BA5ff5Ib

?.XPl

rs&gff #
]toM
$\#
u#av^pw&fi@% \fix&yjY1ff%^ff%]!off
$z
wff{n#]toM$F#^p|P
#|P

U

6 9=

[. /:

M/Z

=

l

x

W[\[\ @L6

TL[\IL=yg2 \gO*=y



k.pTN_ufffiM"MM
ff
$sn[o# ff


/W6Nv/TV=<g" LZ.T8LKOL

g@ \Dff #gff"&"n[
ffTv#u&F$#%T\g>ffY


Z&[fi@% \fi &]=^P_%&q#O
#qf:hihkjvS
N_{ff vfiM"M

G#yf:hhj
#a&





RP%iUWO
l

k#|Pv=H
}



lq}

(*~
=# fi (
= ^%Min[o# ff
uOV=9s#\|P (


l
Gn@o #ff
$#v^pV&a#&fi\fig#a:#&#ff]{#ff
$g&&M
mP% ff
S"n[o#
K#$#%T


$
$#_mP%M
|a# "P&ff v" #% &
&T


l



X

)

^P_qG&opaff
ff
$yg=

~





~

=

N_{R \T] #|PUW=
l

l

R"^Z_STopaff

u

l
&mZ% Pff_ O*=

Xk

~




l

R"q^P_qff fiM"M

wV#fhhj #\|Pv=




l

Bk#a&

#fiT\mP%"Pff_yO


s#a&

e





#fi

lD

$\*oMT\|Pv#s"|P_a T#
$#ff
$%M fiM"k
]toM
#ff
$G#t$#%&iff"&"n[
ffT
#wn[o# ff
Ng$#%TF%&#iffta""&#
#ff
$x%M fiM"v
]!o
$\#
u
$T\fi[%\fiTq#
a""&#
#ff
$y%MfijY1ff%^ff%]!off
$

U

l

*



[. M&t@S2a6*g

(

<\ Z.LK{=

x

4$ [KWj&.2:.

KL[ZL TL1<" LZ.!\<x4

TL[\ILgO=\T{4W

(




#a&

2.6Gt/T

=y/\4\Tq<L<4L

Ot

k.pT!N_w&$#ff_W "&tn[
&#$#%&g=!


_)G

2K2.42e

(~

5 %&#=!
=vT]
X
N_{R&"]a "&v"n@
$ffT#&"V" #% &s:KY4
P&[fi@%fi T]=!Kff% &qff #

l





::#|P

(

R"
kB$\ T]f2"]!]{#t[ff #vff T!"n@
$ffT#Ti
l
" #% &\ffY4
Z&[fi@% \fix T]=ff% &#si#a&
R y$sO^p
9 #\|P (

l
#xfhhj8 # fiffP% #x"n@o #ff
$z= #fiu#|P (
OD^P_tfiM"M

#

f:hihkj



V + U (

,



l

B:x

pHv

PW

2.6

hk""&#
$\#
%fig
]!o
$\#
#y$#%T!#x^pg&fi@%fiTya T#
$\#
F%fitjY
ff%^ff%]!off
$#x"n@o #ff
$"$#%&

!#T!o #ffff
$"%M$#ff_z
P&"&ffT\fiz
x"n@o #ff
$
l{}
"$#%&ff% &xff #"|P_a""&#
#ff
$z%M fiM"
]toM
$\#
u
&fi@% \fix&q#a""&#
$\#

%M fiM"jY1ff%M^ ff%M]toM
u:#o#ff
$% #i"n@o #ff
$

LW

l

l

fi

PWff
Pa[ p

8PP[6W$\a[ pptGW " Z

fi ff!"$#&%(')#+*,-/.0#+102435#+14(6870#+1,:9);+1<;+= 4>@?BA(13C9ff,D#EGFHIKJffLNMOLPLGQGI0R+SUTWVXFS
;+=YZ9[=@#+12\;+1]'[^_9[=:.]=;+`a(b(`:^\%(')#+*,-$cd.Ucfeg3ihDA(1(b`ackjl4>
o%W#+'p'OA#+P#+1q(6870#+1,:9);+1r;+=B#%('ff#+*0,-P9),s#_%')#+*,-/.t#+12:A*,$uU1U9p-/>wv4*0xyx+'ff(-;+1z#+12|{Y#yxy
n
}:~Wyy ./70#yxy ~Wy A#y, ,:A0;Wh1OA#+%o;+7]'ff(-B67#+10,:9ff;+10,o./hA]9ff%-AOA(^%W#+'p'Uu]1U9p-,N'p=ff,-#+O*U`N#+:9);+1,o.
2U;10;+a69ff,O=;+`a#+'p'%')#+*,-o,o>
U5-\K- ( Ut tt/t0L(GL\LNQyVpTGM$S"F+SUMOR/MOF+JffFGVXEGRJ
E(JffR/TLNT@FsUVXEG&M0LWNLPLGQVpTGMSKF_EGF+HIKJffLNMOL$LNQIRSTWVXFSTW
?A041;+1U(69ff,:N10%Wz;+=%o;+7]'ff(-(6870#+1,:9);+1,_9ff,_28*-;rOA#+_=;+`4,-;+_\%('ff#+*0,-o,:A0`N|#+`N
9p1UuU1]9[N'p^<#+1^429ff,:O9[10%wxy10`N#+'[9)o#+:9);+1,P*U102U(`P9p7]'[9)%W#+O9ff;+1t>$BW%o#+*,N;+=OAU9),shBP:*U`O1|N;:A0
7U`N;+U');+=$`-o28*%(9p1xb(`:^xy(1(`-#+'p9ffo#+:9);+1*U102U(`?9[7U'p9)%W#+O9ff;+1-;r#zxy10`N#+'[9)W#+O9ff;+1*]12]`
,:*],:*]7]:9);+1;+=@#,:9[10x+'ff$67#+10,:9);+1>
fi ff|a"P#d%')#+*,-/.35#+1<(6870#+1,:9);+1|;+= #+124#&N`O,-(a;+=B>D?A01<3C9),
#GEGFHIKJffLNMOLLNQIRSTWVXFS;+=Bh$> `> >Ki9p=#+12q;+1U'p^49[=:."=;+`(b(`:^<%')#+*,N&c.ce3hA010b(`
cjz>
t0Y ;+10,:9ff2]`nOA=;+'p'ff;oh9[10x%(')#+*,-o,o
cn
cn
!
3
3

}+}X}:Z}KG
}+}X }:}8G
}}0/}UOZ}]t
}+}X }:G}X08}UO }]G} #+102
}+}X}OGK} }8OG}X08}UO@}]G}G}G

?A0%('ff#+*0,-W,c #+12c #+`-_7U`-;+7"(`d9[10289p`-o%`N;8;+N,d;+=n4. ,:*%-ArOA#+c jz#+12c jz
>q?A0\%('ff#+*0,-\3 9),#+167#+10,:9);+1;+=/^ } }]: .#+123 9ff,#+1(6870#+1,:9);+1;+=s^
}X }UOG}X0/}UOG}X}]: >?A0s(6870#+1,:9);+1<3 9ff,#d?%o;+7U')N(67#+1,O9ff;+1U*]a3 9ff,10;+o>
1:A(6]#+7]'ffP#+";obP:A0&?B%W;+7U')NP(6870#+1,:9);+1|3 ;+=9ff,a#+'),-;#_%W;+7U')(-P(6870#+1,:9);+1
+; =a>za;WhBb(`o.9p1%W;+1O`-#y,:_-;<%W;+7U')N(6870#+1,:9);+1,.B?%o;+7U')N\67#+10,:9);+1,69ff,O=;+`#+'['
1;+1]-#+*]-;+');yx9)%o#+'%(')#+*,-o,o>
U5- ]t N/Kz@ / t0tt/LNMUGLRDSKFSMOR+/MOFJffFNVEGR+JUEWJpR/TL
RSKaRMOL((HTLNMDF\8t0L(S_M0LWNLPLGQVpTGMTwRGEGFHIKJffLNMOLLNQGI0RSTWVXFSd3F (pMU$
"Nq^r?A0W;+`N ~W .OA(`-69),:-,#q%W;+7U')Ns?;+=$\4h$> `> >>(1%o/.@=;+`

(b`O^%')#+*,-c.09p= c5jz:A01qcZe>s^\:A02U(uU1]9[O9ff;+1z;+=#_%W;+7U')(-Ps?.hBA#ob
jz_.U#+12OA(1\^\B;+`-;+'p'ff#+`O^ .j>^&OAo;+`-( .U:A0`N(689),:N,#+1\(67#+1,O9ff;+13;+=
,O*%-A<:A#+!e3d>?A*0,o.K=;+`(b`O^%')#+*,-wcd.]9p= cfjr:A(1qce3d."#+12%W;+10,-o/*01:'p^
3i9),#d?%o;+7]'ff(-(6870#+1,:9);+1;+=YZh$> `> >]>
=hB%o#+1%W;+7U*]-?B%W;+7U')N(6870#+1,:9);+1,;+= #d,-(n;+= %')#+*,NW,OA(1hB%o#+1\*0,-P{ 'ff;+O89p1,
+# ')xy;+`:9p:AUl=;+`%o;+7]*UO9[10x4#+1| -;%W;+7U*]-#+1q?>K`N;+:A0w7]`-;;+=;+=B?Ao;+`-(l
9pn=;+'p'ff;ohn,n:A#+:A0P%o#+1289)2U#+N,Na;+=Y'p9[N`N#+'ff,a-;d"*0,-W2\N;%o;+7]*UNP#?B%W;+7U')N(6870#+1,:9);+1
9),Du]1U9p-/>&9[10%W(6870#+1,:9);+1|9),aW*U9pby#+')10%W7]`-o,-`Ob89p1x\hB%o;+*U')2,O9[7U'p^\-o,:#+'p' 289p"`N1hB#W^],
-;(6870#+12#d%')#+*,-$/^,-W*(1%oo,n;+=Y'[9p-(`-#+'),n=ff`-;+:A]9ff,a%o#+1289)2U#+Nd,-.0#+1029p1\OAU9),DhB#W^;+U-#+9p1
#r?%o;+7U')N(67#+1,O9ff;+1t>?A]9ff,9ff,;+=P%o;+*U`N,-|#+16:`N_'p^%o;+7]'ff(67U`N;8%oW,N,o.U*]4#+')o#y,:
:A0W;+`NO9ff%o#+'p'[^8.K?%o;+7]'ff(-(6870#+1,:9);+1,#+124s?D,#+`NP%W;+7U*]-#+]'ff/>


fiX0/G ff
fi)G

"!#%$ff&(')
*,+.-0/21(+43656708:9;+28<5=->+@? ACBDFEG+IHJBKMLN+IO>+IAC/EP9GQR/569;BOSBKMTIEG/703C+R3RUWVOX3C+2TI569;BOZY\[^]_+8F+23CTIA69PDff+R8<56-0+
KGA`/HW+I]_BA6aKbBA_LN+cO0+cA`/Ed9;QR/569;BOeBKTcE;/7>3C+R3f8 +I1(+cE;B?ff+28D(g@hiE;B56a\9dOkj=l2m(noF[pl2m(n\lcD^[ql2m(n\l2/(rc[F]M-F9GTC-9;3
D>/N3`+284BOWst367FD>367FH?F569;BOUuVH?FEd9;T2/5=9GBO9;3i5=->+vHWBN3=5O>/567FAC/EwD0/N369;3xKbBAf9PO>8:70Tc5=9d1(+yLN+cO0+cA`/Ed9;QR/569;BOU
VOe3C+RTc5=9GBO"Y\[ ]_+z56-0+cA`+cK{BAC+|/E;3CB3656708:9;+28}5=->+~5=->+RBA6geBKiLN+cO0+cA`/Ed9;Q2/5=9GBO"7FO>8 +IAv9dH@? EP9;T2/5=9GBO^U
u-0+~TRBO(5C+IO5`3zBKi3C+2TI569;BO"Y|TR/O}Dff+~367FHH4/A69;QR+28@/N3uKbBEPE;B2]3R
lNUV5_9G3M8F+2TI9;8 /D E;+~]M-0+c5=->+IA/|TcE;/7>3C+yst367 D0367 H4+R3/O>B56-0+cATIEG/703C+U
Y\Uu->+IAC+_+c\9G3=5C3w/ME;+2/N3=5LN+cO0+cA`/E>LN+IO>+IAC/EP9GQR/569;BO@7 O>8F+cAst3=7 D>3=7 H@? 569;BOkj{~zs(rBK>+I1(+cA=g~ OF9d5`+
3C+c5BKTIEG/703C+23U
UV5_9G3u7FO>8F+2TI9G8F/D E;+]M->+I56-0+cA/|TIEG/703C+z9PH@? EP9G+R3u/O0B56->+IATcE;/7>3`+NU
UV5f9G3_/O}B?ff+IOW?FACBD E;+IH]M-0+c5=->+IAM56-0+cA`+~+I:9;365`3u/E;+2/N365_LN+IO>+IAC/EwLN+IO>+IAC/EP9;Q2/5=9GBOe7FO>8 +IA9PH?FEd9Pt
T2/5=9GBO,jwyzV=ruBK+I1(+cA=gW OF9d5`+3C+I5MBKTIE;/7>3C+R3RU
Uut9dH@? EP9;T2/5=9GBOS9;3/,3656A=9GTI56EPg3=56ACBO0LN+cAAC+IEG/5=9GBODff+c5]_+2+IO%TIEG/703C+R356-0/O9PH?FEd9;TR/569;BO[M/O>8
3656A=9GTI56EPg]_+2/a(+IA}5=->/Ost367 D0367 H@? 5=9GBO^[y/O08ut9PH?FEd9;T2/5=9GBOT2/ODff+2TRBHW+"/O/A=D 9P56A`/A69PEdg
LNB:B\8}/? ?FACBR:9PHW/5=9GBOBKw9PH@? EP9GTR/569;BOWD(ge+I:5`+cO08:9PO>L56-0+T2BO0369;8 +IAC+R85`+cA=H3C+c5U
UV5_9G3M8F+2TI9;8 /D E;+~]M-0+c5=->+IA/|TcE;/7>3C+yut9PH?FEd9;+23_/O>B5=->+IAzTIE;/7>3C+U
n\Uu->+IAC+M+I\9G365`3/E;+R/N365LN+cO0+cA`/EffLN+cO0+cA`/Ed9;QR/569;BO7FO>8 +IA_ut9dH@? EP9;T2/5=9GBOjw~r^BKff+I1(+cA=g OF9d5`+
3C+c5BKTIEG/703C+23U
V O~3`+2TI569;BO []u+365=7>8\9G+R8~56-0+x8\9dff+IAC+IO>TR+xDff+I5]u+R+IOst367FD>367FH?F569;BO/O>8z9PH@? EP9GTR/569;BO~BO.TcE;/7>3`+23RU
*,+.?FAC+R3C+IO5`+28ZB7FA/?F? ACBN/NTC-Z5`B} O08/EdELN+IO>+IAC/EP9;Q2/5=9GBO03.7FO>8F+cA9PH@? EP9GTR/569;BO[^D(gkA`+28\7>TI9dO0Le9dH@t
? EP9;T2/5=9GBO,5CB}st367FD>367FH?F569;BOUu-F9G3TR/ODff+|/NTC-F9G+I1(+28D(gk9PO(1(+cA=569PO>L"3C+IEdK;tAC+R3CBEP7 569;BO[/O>8"]u+|8F+ct
3CTIA69PDff+28Z/}5`+2TC-FO 9;70+}KbBA|9PO(1(+cA=569PO>LA`+23`BEd7F569;BOD0/N3C+R8ZBOZBA6t9PO(56ACB\8:7qTc5=9GBOBKMEd9P5C+IAC/E;3RUk*,+W/E;3CB
8 +R3CTIA69PDff+28X+c\?>/O0369GBOBKMTIEG/703C+23[]M-F9GTC-X367 H@HW/A=9GQR+R3B7FA9;8 +R/eBKuAC+R8:70Tc5=9GBOSBK_9dH@? EP9;T2/5=9GBO5CB
st367FD>367FH?F569;BOU
u-0+~TRBO(5C+IO5`3zBKi3C+2TI569;BO TR/O}Dff+~367FHH4/A69;QR+28@/N3uKbBEPE;B2]3R
lNUOk+c\?>/O0369GBO,BK/@TcE;/7>3C+9;3/O"wyzsBKf/3C+c5vBKfTIEG/703C+R3BDF5C/9PO>+R8kD(g"BA=t9dO(56A`B:8\7TI569;BO
KGACBH56-0+~TIEG/703C+U
Y\UBAx+I1(+IA6gLN+IO>+IAC/EP9GQR/569;BO}7 O08 +IAu9PH?FEd9;TR/569;BOBK^/TcE;/7>3`+M56->+IAC++I:9;365C3/O4+c\?>/O0369;BO}BKff56-0+
TcE;/7>3C+[FE;BNL9;T2/EPEdg+2(7 9P1N/E;+cO(5v5CB56-0+TIEG/703C+N[ff367>TC-"56-0/5v56->+.LN+cO0+cA`/Ed9;Q2/5=9GBO7 O08 +IAz9PH@? EP9GTR/t
569;BO}9G3_AC+R8:7>TR+R85`B/|LN+cO0+cA`/Ed9;Q2/5=9GBO7 O08 +IAst367 D0367 H@? 5=9GBO^U
Uu->+IAC+e+I:9;365O>BOFt5C/7F5CBE;BNL9GTR/E|TIEG/703C+23KbBA@]M-F9GTC-S56-0+cA`++I\9G365|O0BTRBH?FEG+I5C+}+I\?>/O>3=9GBO03R[
]M- 9;TC-H4+R/O>3|56-0/5W56-0+cA`+"/AC+eO>B+I\?>/O>3=9GBO03}BKz5=->+"TIEG/703C+23@3670TC-5=->/5}+I1(+IA6gLN+cO0+cA`/Edt
9GQR/569;BO7FO>8F+cAy9dH@? EP9GTR/569;BO9G3AC+R8:70T2+R8<5`B}/WLN+IO>+IAC/EP9GQR/569;BO7FO>8 +IAst3=7 D>3=7 H@? 569;BOZBKf56-0+
+c\?>/O0369GBO03RU
UBA+R/NTC-O>BOFt5C/7 5`BEGBNL9;TR/EvTIE;/7>3C+@56->+IAC+4+c\9;365C3/e_tT2BH@? E;+c5`++I\?>/O>3=9GBO^[i]M- 9;TC-H4+2/O03
56->/5_+I1(+cA=gLN+IO>+IAC/EP9;Q2/5=9GBO}7FO>8F+cAut9dH@? EP9;T2/5=9GBO4BKff56->+vTIEG/703C+M9;3iA`+28\7>TR+28@5CB/yLN+cO0+cA`/Ed9;Q2/t
569;BO}7 O08 +IAzst3=7 D>3=7 H@? 569;BOBKw56-0+~+I:?0/O>369;BOU
2

fi(>(\;2N\GffWff@>>I(>>0"(G(N\Gff

v>`2"dCRI6;F\puRFGIC.c\>06G0~0~zMCRF CFGq F60C
2@ FC6;GI:=CIWIP}RN66P(u ;M;06 = 6;6P>}=d02FvGC4Iu=ebNc0c`d
@
;2=GF>Fc|PFd;R6;<;z>N`2X>I\CI> G=:Pz;C4c_6,b|NI>ICP;2=G
0 Iv6 06 @ =G^0MFGCePCRN:6 ffICM;CRFGI:PFCFGIWiNc0c`ww~
~CIfc;>CRWR|CR%I:ff0c(6;Pd@d|=>( |ffIuIG0CRiP6>vCI{e>N;IC}
I>F>2NN(cii(Iwy`2\>R2 0 Iu6F>6FF6;:MFGC420^60uP Pd`c`G=>
C`2\ >F(F>Fc6 06 @ =Ge`CIWR(2p(42C2c\ff>I(6;dP@d@60(F|ffc_
IG0C2{v;c`N2NN(P>R<I:0>6;f4c;>C|;v<~fWCIu=d(=C\:>RR
IG0C260uRF `6;>RN6w0|I:0>6;CRc\ff>I(6;dPP~=>x(F|ffcFdPCIC;
>`2@d46>y6P(6C\:0c`GMW60zR@ `6;"w_2@ ;c`vc\>06G"yG`N( |ffI
Pd`c`G42ffWR>6; ICRffM>ZR>`2(>I(6P=>CS"2@ FC=GS_ ;Xff4c\6`c4Id
RN66P(
2_I(cFP60>i;6\PxG`WI_6@bNI>ICPGR6;e 0 Iv6 06 @ =GG_2@
FC=G0dPc\ffc06P(N0P>NMffRIeMGFcPW0CReN=>RCI6;2;C4c_6p__>IeCW(
Pu `Nc=GRq( |ffI:PffICIv`26=6;c=G0z460~IG0C^;>0NN~>NMffRck206GFc`2p
b.cF@ ;|GN ICI6@d0Nc{e0NGICZ I>Ff2NN(,}6PPG_2"_|>ffCWF>
CR6=6;c=G0M >Fc ;CWFM>IC `2`c(CR}G`WI_6@bMNI>ICP;2=GeF> IMPFd;R6;
R}ffzFCNI6;2Pd>CIGF
R6C@d4( ;662NN^2NNN(0NW RCI6Pff2<`2CF ;0k`c@IGI(6PS2@ FC"
CR6=6;c`2Sb=vNc0c`d;R6;>WF> I@d@ PGR6;S2Rc(=d:xe>N;c`0NFCRCc(`2
>=>IF CNNC,>NCR""Nc0c`6P>e|( |ffIc;>CRRq`Rd;Re6 FC6FC\CRwM ;C
C20:; CRbffId0P>\d`2IC\CR:060cCR6=d0M0c=>I6>I|`uCv>e>N;c
C^p2N(NciuFGf FCNNCe@G(ffz_2CW`c@IGI(6P2@ FCC4MNI>ICPGR6;>
0 Id@ PGR6;:4f `NNC>Rx`;R6|CRI C=d(MFcF P6;>z;CRI C=d(u;N;x `NC4
("Nc0c`d;R6;< 0 IzP@ PGR6;e>R(ff2I" CRCI(CRS{ffd(`kMP2N(\^>F
^ffP(CupP>FikMP2NNFu R6C@d4( ;6R_2N(Nu>RCWF `NNC>RWC4>NCR
%=660c= `>P 6;}y6>P(ccFFGRRM k26>RCI6;RdPff RCI6Pff2P
G`WI_6p
660:Z(Su0c=2N(Fz2N(q|6>4GR60 PdP`2I `6P(}GN;W `NC4|>N
`c\;>6P}ffRc}FCRCI`2eP}6FG
=>f}= ;660:}Pu_N6>RM}=>v|CRcFC6P(~;NG
`NC R>6;66P>Zy>eR>=C(6Fc>` ICI6@d0C"c;NCR
(6SCRI C=d(c;>`e>
>|R>=C(6FcFCZ ICI6@P>C|0 CRI C=d(@c;>`~Gvx;2=>FG|P(c"NF:P6;>
6>N`cRNC|CNI; FqMFGCFc`c=P>RPffN6d=d(.cFFGGvR2(ICRk(}=>0 CRI C=d(
>N`I;>C|f60`CNI~ `NCJG0N|v_N~;CW=>2<60NI>ICPGIP>}6FGyc;NC
;2= P><FC ;I dZ06FCvuR;2NF.`<"RF C=G0dP:P@cFd|FC ;I"Zu ;
CR6FdM`cP;u>u=>`|c@IGI(6PW;2=}W`v2@ ;c`2I `6d((:ff=>RC2vC4vc\6`|dFb6
46;60C@N= ;u4:Fc;_{vGIC
`ffc2N(N CN` CRcFC6;4CC>IWRf @bIP
P;CC2NN(Gu02R Rff

u0xR(6=dF C;>_>6FGw0ffc`i= CRIb;ff d`6Ru>R(u6F6`c46;2PP`c\;c_2.>
:;CI>C`2"60R>RI CyCIGIN(~`WNI>ICPGR6;P<@ C=6CFc`c=6P>F\2R>p_~>R(
P=C\:02RWuP@ PGR6;N=6C0Ncfb= P@ PGR6;MFGC|;w RIGF ;uffc_2I@c;>`2R
uFd`ff^u02(G =60cFc(IGffRFCI:;>yu=f60 604{ R6`PW( ;6R2NNN
4c\CI>\d0;6\d^ fGC4Iu={MNI>ICPGR6;e 0 I6F>6FF6;}CNI>ICP;2=G
0 Ivd@ PGR6;


fiff

fi !"$#&%'
(*),+.-0/21436570895:;5-=<>
?A@BDC!EGFH@2I!JLKNM'OH@PFQIRFH@C!S&TU?VI!JHT,BXWNY2JQC!SZ\[B SU]^I!J_M`S,abC!WcE2C!dGWeBf@2BXW`gUhiI!S2hiBXJHS&McS2jkFH@BDKlI!JHTPI!SU?Am
McnDgGW`M'hC!FoMeI!S=pD?A@2BLC!EGFH@2I!JLC!W'OQIqKrMeOH@*FsIRFH@2C!SGTUt,@2C!S&m6u KlB\Mlv MeBXS&@,EGw&OHmyxz@2BXS2jG{}| I!S2C!W'~~GB_I!Wc]
C!S2~FH@BC!SI!SwnI!E2OqJsB\aMeBXKlB\JsOD]I!JCS,E&n_d$BXJRI!]FH@2I!Ej!@,FH]eEW_hI!nfnB\S,FQOLC!S~OHEjbjbBOHFoMeI!SOI!]
McnDgGJQIa,BXnB\S,FQOp
?A@GMeOKlI!JHT@2CbO.d$BiB\S_OoE&g&g$I!JoFQBi~d,wFo@2BrtKlB~MeOH@L| BiOQBiC!JQhQ@fxAI!EGS2hXM`W]I!JS2j!McS2BiB\JoM`Sjth\M'B\ShBiO
?rY.|}C!S2~RFo@2BE&JsI!g$BC!SkxlI!nDn_EGS&McFwltz| ?A| b,!fS~Eh\FoM`a,B_Ibj!Meh0JsIbj!JQC!nfnDMcS2jGp
*52Q5,5-)&5>
@2CG{._pp`{=C!g$I!McS,FQB{Atpc{VMcS2jG{xpp`{*C!F6KNMcS9{tp Hbb p*S,a,BXJHFHMcS2jkM`nfg&WcM'hC!FoMeI!SPKNM`Fo@
OHnqC!WcW=FoJQC!McS&McS2jOQBXFQOp6Szfi_y29fiX&zs!UAfis_fi*k,s&$
!X2^!p&t,g&JHMcS2jbBXJHmzBXJHW'Cbjp
AC!McS9{p`{E2jbj!W'BXFQI!S9{ztp Hb b\pfvI!SGmnqI!SI!FQI!S&M'hDW'BiC!JHS&McS2jGpq6SE2jbj!W'BXFQI!S9{tp z~$p{.\
!2s^fi fiAsfifi__!p,hiCb~&BXnfMehJQBiOQOi{2=I!S2~GI!S9p
x}@C!S2jG{xpc{2=BiB{G|p H,! \pfiD! sbfisfi2fi2fiXAsfi^!p.hiCb~&BXnfMeh
0JsBOQO{I!S2~GI!S9p
xAI!@B\S={p Hb, C,p.Cbh\mW'BC!JoS&McS2j_JQBihXE&JQOoM`a,BWeIbj!M'h g&JsIbj!JQC!nOi}0fhXMeBXS,FAC!W'jbI!JHMcFH@GnqOpNfiXfiy
Afi&XoX^e,X$rrsfis{${ &!b p
xAI!@B\S={0p Hb, dp.Cbh\mW'BC!JoS&McS2j*JQBih\EGJQOHMca,BqW'Ibj!Mehfg&JsIbj!JQC!nOiDvBjbC!FoM`a,BfJQBiOHE&WcFQOipfiXfiAy
Afi&XoX^e,X$rrsfis{${ !G&b! p
C!WcWcMeBXJi{AGpVup Hb ,\p sb fiAfioXD9X6X9fi,fi bofiD=fis
zfifipuC!Jog$B\J | IKE&dGW`M'OH@B\JsOip
I!FoFHW'I!d9{ p Hb, \ptE&dOHE&nfg&FoMeI!SPC!S2~*McnDgGW`M'hC!FoMeI!S=pXfiXDi6!As^ soQX{ b\{
bb p
uC!nD]^B\WcFi{2p`{2v McWeOsOQI!S9{$&pYlp obb p6S2~E2hXFHMca,BnqBXFQC!W'Ibj!M'hg&JsIbj!JQC!nfnDMcS2jGpA6SPAsfi&y
2 9fisL\oXfifiA4fiskfif\fi2sb sbrAsfifi__!p BiOQBXW`W'OQhQ@2C!]'FA]E& J
C!Fo@2BXnqC!FoM`TfE&S~C!FsB\S,a,BXJQC!Jod$B\McFHE2SjRn_d2u{&ACb~RuI!SGS2BX]!AI!SGS9{ B\JonqC!S,wp
uB\Wc]eF{rvp ob, pS~Eh\FoM`a,BPjbB\SB\JsC!W`M'ZC!FoMeI!S=W'Ibj!M'hC!W]eJsC!nqBXKlI!JHTpSAsfi&R
9fiAs2fi4fisfi&9s6!fi fiX2fipGt,Mej!nC_JQBiOQOi{&McW`nOHW'IK{S2j!W'C!S2~p
u E&nBb{pc{tC!nDn_EGFi{xp HbG \pOHMcS2jM`S,a,BXJQOQBLJQBiOQI!WcE&FHM'I!SUFQIRW'BiC!JHSJsB\W'C!FHM'I!S2O]'JQI!nBXg$BXJHm
M`nB\S,FsOip6SzfiLyAc,R\&oXXfifi4fiQsfik& !X2^!p
I!JsjbC!S*C!EG]enC!S&S=p
y~&BiOHFQC!nfm6 W`nEGMeOoFi{fi0p ob bp==BiC!JHSGM`SjnDM'OQOHMcS2jhXWeC!EOQBiOVd,w_McS,a,B\JsOQB JQBiOQI!W`EGFHM'I!S9p=6SRAfi
0VXoXXfifiAfisX$}fi0 sDXsfiqAfibo$ioXA&,!pbr@GnqOo@2C
0EGd&WcMeOH@B\JsOi{?VI!Tw,IGp
fi

fir,2,$ ff
fiX2,,$

!#"%$'& ()*+&-,/.102"!3547698#:<;;=$>?6A@CBEDffBEFHGJILKNMOGPQKSRJDTRUWVIGJX/YOBHYE6Z4\[]6_^`6a"#[b<20!3c^dfeb$'g#"#&-Eh/"ji'k
l i'&me1."Hfgd$'honp#"Hf&-CnrqE0fhbq<!!3]n/"Hirq%s[i'*N&uth0NvfgH#0N"Sp$'hbWwi!p$'*7h#"20+"2."% i'kxy!q%[(
hi'*iz'p6
!#"%$'& ()*+&-,/.102"!3{476|8#:<;;='}~>f6
EhEg%$'*N0!$'"#0i'h.h1fg0N&me1*+0q<$'"20i'h}/pgH<qE.gH#0Nv$'h/"20+(
.h0Nq!$'"#0i'h65h5FHRO?B?B?JKDYRQUPbBmBEDPfDP2B<FEDGPQKSRJDGJIVR'D!UBEF?BED?BdRJD-oGHKDBB?GJFED
KD'6i'g%z$'hd$'.k& $'h1h6
!#"%$'& ()*+&-,/.102"!347682:<;;=q>f61dfhbfgH$'*+0!$'"#0i'h.h1fg0N&me1*+0q!$'"#0i'h}p.b#0NhzCi'g#(0Nh"#g%i.~qE"#0i'h6bh
F?R?B?B?JKDOYCRU9PbBKP5XrF?RHbB?GJDV5RJD<UBEF?BED?BCRJD-oGHKDffB9B?GJFEDKDJ6n/eg20+hbzfg2(fg2*$z16
!#"%$'& ()*+&-,/.102"!3r4\68#:<;;>f6\\ qE0Eh"0Nh.qE"#0i'hi'k]gH<qE.gH#0+vdEh10+"20i'hb}/p-#"2g#.qE"#.1g%$'*$'hb$'*+(
p#0i'k%$'"#.1g%$'"20i'hb!6h|5FHR?B?B?JKDY`RQUPbB\K UHP EDP2BEFEDGPQKSRJDGJIjR'FHOY?R?RJDfDJXHPQKB
RHJKd5F?RHJF?GJKD'6~^Ee$'g2"#&-fh"i'k l i'& e.1"%EgnrqE0fhbq</3d$'"#[bi'*+0Esmth0NvEg%#0N"%E0+"]E.(
vfh]31f*z'0+.1&6
C0E"%/3a16 (t678#:<;;=>?6 )q!i'& e$'g%$'"20+v #"2.rp|i'kc2"#g#.bqf"2.gH$'*c& i2"2eff<qE0+bqzfhbfgH$'*+0<$'"20i'hb.%!
0+h&-$q%[0Nh*<$'g2h0Nhz16h|j.bzz'*E"%i'h]3an678ff6>?35FHR?B?B?JKDY`RQUPbBjKFHEDP2BEFEDGPQKSRJDGJI
jR'FHOY?R?|RJD EDJX1?PQKJBR?JKS5FHRHFHGJKDJ616bn"%Ek$'hoShb#"#0N"#.1"%/3.}*Q$'hb$13]n/*i<vEh0$16
C0E"%/316 (t6N3bog%i'}ffE*Q3]n~678#:<;;>f6 l i'h"#gHi'*+*N0+hbz"#[bq<i'& e*f0N"Spji'k*!$'g#h10+hbz 0+h*iz'0q"#[1g%i'.z'[
#prh"H$qf"20qC$'h"%$2sr(i'g20Eh"%!& iE*6bh .zz'*E"%i'h3~n~6~86>f3fDJXHPQKB9RHKS55FHRHFHGJ
KD'6)Cq!$E&m0q4\gH<H!3bn$'h^0!zi13 l $'*N0Nki'g#h10$16
di<$'*#s0Q3w6782:<;'>?6 x5[q!$%ki'g.#0Nhz!,/.b$'*+0N"p$'0i'& C0+h|$'."Hi'& $'"20q E&-i'h#"2g%$'"#0i'h6 h
'RY<KXR'D|CXP2RJmGPQKS BEmRJDY?PQF?G!PQKR'DB??PQXrF?B-DRP2BHYjKD{G!PbB<mG!PQKHY?bR'ILC6
n/eg20+hbzfg2(fg2*$z16
]$'effi'0Nh"%/3n~6N3O$'"c0+h]3rn~68#:<;;>f6n.}(.1h0Nq!$'"%0i'h)"%ii'*rki'gf qE0Eh"]0Nh.qE"#0i'hmi'kbg%!qf.1g%#0Nv
eg%iz'gH$'& 61h 5FHRO?B?B?'KDY9RUPBKDPfDP2BEFEDGPQKSRJDGJIbVR'D!UBEF?BED?BcRJDoGHKDffBB?G'FEDKD'6
i'gHz$'h$'.1k&-$'hh]6
]$!vrgH$q/ 3\6+3^dw$!r"!3y682:<;;>?6mhr.bqf"20+v *iz'0qegHiz'g%$'& &m0Nhz1)#.1g#vEpi'k.g%i'eff!$'h
g%!%<$'gHq%[6c`V5RJXDKS?GPQKSRJDYE382:>?3b=O~:<;16
]$!vrgH$q/ 36N3^! fgHi#s03n682:<;;>?6fDJXHPQKBRHKS5FHR?JFHGJKDJffB??DKSEXBHYGJD~ILKS?G
PQKSRJDYE6a*+*N05Ci'g#iriff6
]!/3 l
6 8#:<;>f69V5RJINB?P2BEDB?Y?Y]bB?RJFHBEGJD-GV5RJXP2B<F5F?RHJF?GJTURJF\KDJKD]bB?RJFHB<Y
BEFEKJG<INBaUEFHRJ@9KJB<D CJKSRJYE674\[]6_^`6r"#[!#0!3bth10+vEg%#0N"pi'k l $'*N0Nki'g#h10$13ff5Eg#sE*Ep6
*i<p1ff3ff166]82:<;>?6RJXrDff/GPQKSRJDY`RURHJK95FHR?JFHGJKD'6yn/e1g#0NhzEg#(fg2*$zb6nr!q<i'hb<0+"20i'h]6
$'g%qE0+h1si<2sr0Q3c6N3aA47$q%[i'*#s03658#:<;;>f6th1<qE01$'}0N*+0N"pi'k"#[b[i'g#hqE*$'.b% 0N&me1*+0q!$'"#0i'h
eg%i'}1*E&W6ah5FHRO?B?B?'KDYRUPbBm]KFHPQ!PKF?DDXGJI~H\'RY<KXRJD-RJXrDGPQKSRJDY
RQUVR'X/P2BEF9<KSBED?BE3e1e6~='Or=`40+"2"%#}1.gHz1347fh1h#p*+v/$'h0$16
.zz'*f"Hi'h35n658#:<;;>f6WShbr.bqf"20+v*iz'0qegHiz'g%$'& &m0Nhz16ShF?R?B?B?JKDOY RU`PbBjRJF%OY?bRHRJD
IRJFEKNPKScB?G'FEDKD]bB?RJFEO69[1& #[b$4\.1}*N02[Eg%!3xai'srpi16
J

fiSb/?O~Q'ff?

'fH' ff
fi
SrE %

G IHJ-K
JLNMBO ffP

!"!#+b $&%ff')(*%,+-%ff. /021435+768359;:-<fi021=+?>A@B35<C.+D/EF

'fH'QR ff
fi
JKfiSTSJ,#U+bVW!#Xff'U'YZ\[8.

^3 ]S%S%S_1I+C>`A3ba"0dc%"e%S]S35+-_Af,+C0U%,.,+-/021435+-/5E
g 3. h^`Sc3S:i3+jf+-_5<] 021=kfi%8l3 >51m]n[8.S3 >5.S/59o9o1=+C>ffUpQq*rTryNts?XN'ff,!-t'?!urcwv fiffPJKC

'fH'ox ff
fi
fiOJyE z?% !"!#N {}|dUW~' 'N#ff!ff % ffi' sb# v
< !#+bfi NS
[8. 3]S%S%S_51=+?>`3bai0dc%we-10dc\8<B.S3S:%S/5+6835+ffa%ff. %ff+-]S%3+z/J] c?1=+-%wl%S/.,+1I+C>
~?U+b Uvd 2
'fH'DD ff
fi
JLfi~,tHEtNW!-fR'%'2$&%,'(*%,+-%ff.

~

/021435+68359;:-<~021=+C>j@B35<C.+D/EF

'fH'8-W N~n ff
fiPfiPJfits +b"NJf 'Q? # v , %NBXff'HffoJVN?v
2 N
Hff %'NU 'Y

[n.S3]S%S%S_51=+C>^`o3ba0dc%&1 0dcf+C0U%ff.,+-/021435+-/5E6835+ffa%ff. %,+D]S%o3+z/J] c?1=+D%
l%S/.,+1I+C>r %fi '
x'?
X!'1

'fH'?|QNr? ff
fi
fiHJE Q %

@B35<C.+D/E3ba;l3 >fi14];[8. 3S>5. /59o9o1=+?> ?4? JK
^MBJ


!"!#+b {r8sb<U"'"!-fUsC?N

'fH'Y-W-~fb -p* ff
fi
fiJR",fQNE '{y&?% !Z[8. 3]S%S%S_51=+?>`&3ba
0dc% g 3. h^`Sc3S:3+#*E>J35.,10dc?9o14]Rl%S/5.,+1=+C>Yc%S3.,^qs?!A so? 1WX sb N-ryC
'fH'Qfi|j8Uff
fi
fiHJSrEW*t'2? '
'Z*, +HwfX'HffN7\[8. 3]S%S%S_51=+?>`A3ba
0dc%35<B. 0dcf+C0U%ff.,+-/021435+-/5E g 35. h`Sc3S:z35+#f+-_5<] 021=kfi%Rl3 >fi14]R[8.S3 >5.S/59o9o1=+C>JN %E+Xtts8S?
'U s, !'U W

w|'HfJ
, tUff N#b
!o?8fiC'1, d5'1
Yd U!'J
B

W1E# r ff
fiPfiPJS#2B-fb 'WXff'U'wN XQ?Ht!ANw[8.S3]S%S%S_51=+C>^`*3baR0dc%jYc?1=.S_
n<C. 3S:%S/+ g 35. h51I+C>e%S`S`ff1435+3+il%S/5.,+1=+C>5?N !A'
E?s ? vbpnsE - vmC1;|'W &Uff
fi
JLfiSrsx#?#?!#U'Us!%,!N#+rE
?% !"!#N {"fiE to' 7I' +Xfi, NN \[8. 3]S%S%S_51=+?>`#3ba"0dc%j1 0dcf+?0U%,.,+-/021435+-/5E g 35. h
`Sc3S:Z35+f,+-_5< ]S021=k5%l3S>514];[8.S3 >5.S/59o9o1=+C>Bd
| ,# U
! ECn5
p !# HxC E! fi' Us ' ,
W ,tU+ HN ]
9
E? ED5EN ?!
'UBNo|jUff
JJSw'%-'VNE fb 'WXN' '{E+ <,N* wts ~|o
In?NSDz/J] c?1=+-%;f,+C0U%,EIEF1>J%,+D]S%~'mLC??LO^MfffiO -C+J1?%sZ? N4Hfft
'UBN?j5|j? ff
JCffJ*<fi0U359"/0214]Qz% 0dc3^_N`3banf+D_<] 021Ik5%8f+ffa%ff. %ff+-]S%sY|jOUsN XNBC+J1?%s
W ,tU+ mB
9
'UBNJo|oJ ff
JC-S?2 s,'%'NrfUWE,t'Xff'U'YfNt!5WwXts?fi
|oDIn?z/J] c?1=+D%Rf+C0U%ffE=E1>J%ff+-]S%B'2C ?YYff SMKH -nBN J ?H sV
W ,t N mw% NtN
? NX' ~& ff
fiPfiJSrfU'j1ff,X 'U%!ffNz/J] c?1=+-%8l%S/5.,+1=+C>@C3<C.,+-/5EF US?P SMfffi
?NH'?J ff
fiJLfiSY\!fits +bvUE%N X8fi%ff ' sQHffH'+1 '?U+~Q@C35<B.,+-/5E
32a;0dc%R6w ~ SDKO^MBH fi
5

fiRJJCXfffiCDD#,J~mJJfiCD

?J,t2* fffiJfiiB QJJ }QtNt? X? WXNVtUN TN" , X
4ifi,tYQ8d ff
fifffiff fi!#"*Nfi?,"X%$ ff NC'&;Xfffi
8W=U?X
?J,t2*)(*$fi,N + ,.- ff/fiJS0"UW#?XQt?U#=WJJ, fft?UYm12334
fi5!36798:
<;=:>?!@
<;BA2!ffC=EDBffFfi5GIH?ff66Jfi.KLM fi5!5G $
Bt "XBN,bBttN7 ff//JSo4#?XffUzXtN*??NX?O ~QPR;=ff
fiSUT:C#)
NM
H?MfiJ#W VGX /ZY\[? ]
~XfiXfi0+ &W *^W(_^YNfi-&*W`xUff]fiJSj" ,t,Nt* Nt,A;It,A~U
tNtW XW fftJ aJ,NM ,<b?CW- mc
ffdfi!36e98B
<;=1>ffi5ff6
I!
NJ\
fi.Shg!fi5!

TJ83MM#iLj:ff
fi kJfiSGM!
NMSSlfimZM?tfio
nx?A?Y# ^Yfip
"Rtfi8=

q\WU &Uff/fiJSj" , #fiX? fitArOJWJJ,tto fft?UYms23fi5!d6 98h
<;=
>?tff
<;uA!ffC EDBffFfi5!7H?ff66JfiKLM fi5!5 !$

vw3x

fiJournal Artificial Intelligence Research 3 (1995) 271-324

Submitted 2/95; published 11/95

Flexibly Instructable Agents
Scott B. Huffman

Price Waterhouse Technology Centre, 68 Willow Road
Menlo Park, CA 94025 USA

John E. Laird

Artificial Intelligence Laboratory
University Michigan, 1101 Beal Ave.
Ann Arbor, MI 48109{2110 USA

huffman@tc.pw.com
laird@eecs.umich.edu

Abstract

paper presents approach learning situated, interactive tutorial instruction within ongoing agent. Tutorial instruction exible (and thus powerful)
paradigm teaching tasks allows instructor communicate whatever types
knowledge agent might need whatever situations might arise. support exibility, however, agent must able learn multiple kinds knowledge broad
range instructional interactions. approach, called situated explanation, achieves
learning combination analytic inductive techniques. combines
form explanation-based learning situated instruction full suite
contextually guided responses incomplete explanations. approach implemented
agent called Instructo-Soar learns hierarchies new tasks domain knowledge interactive natural language instructions. Instructo-Soar meets
three key requirements exible instructability distinguish previous systems:
(1) take known unknown commands instruction point; (2) handle
instructions apply either current situation hypothetical situation specified language (as in, instance, conditional instructions); (3) learn,
instructions, class knowledge uses perform tasks.

1. Introduction
intelligent, autonomous agents future called upon perform wide
varying range tasks, wide range circumstances, course
lifetimes. Performing tasks requires knowledge. number possible tasks
circumstances large variable time (as general agent), becomes
nearly impossible preprogram knowledge required. Thus, knowledge must
added agent's lifetime. Unfortunately, knowledge cannot added
current intelligent systems perform; must shut programmed
new task.
work examines alternative: intelligent agents taught perform tasks
tutorial instruction, part ongoing performance. Tutorial instruction
highly interactive dialogue focuses specific task(s) performed.
working tasks, student may receive instruction needed complete tasks
understand aspects domain previous instructions. situated, interactive
form instruction produces strong human learning (Bloom, 1984). Although

c 1995 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiHuffman & Laird

received little attention AI, potential powerful knowledge source
artificial agents well.
Much tutorial instruction's power comes communicative exibility: instructor communicate whatever type knowledge student may need whatever
situation needed. challenge designing tutorable agent support
breadth interaction learning abilities required exible communication.
paper, present theory learning tutorial instruction within ongoing
agent. developing theory, given special attention supporting communicative exibility instructor (the human user). began identifying properties
tutorial instruction instructor's perspective. properties,
derived set requirements instructable agent must meet support exible instructability. requirements drove development theory evaluation.
Finally, implemented theory instructable agent called Instructo-Soar
(Huffman, 1994; Huffman & Laird, 1993, 1994), evaluated performance.1
Identifying requirements exible instructability provides target { set evaluation
criteria { instructable agents. requirements encompass ways agent interacts
instructor, comprehends instructions, learns them. general
requirements common interactive learning systems; e.g., agent expected
learn general knowledge instructions, learn quickly (with minimal number
examples), integrate learned previous knowledge, etc. requirements
specific tutorial instruction.
theory learning tutorial instruction specifies analytic inductive
learning techniques combined within agent meet requirements, producing
general learning wide range instructional interactions. present learning
framework called situated explanation utilizes situation instruction applies
larger instructional context (the instruction's type place current dialogue)
guide learning process. Situated explanation combines form explanation-based
learning (DeJong & Mooney, 1986; Mitchell, Keller, & Kedar-Cabelli, 1986) situated individual instruction, full suite contextually guided responses
incomplete explanations. responses include delaying explanation information available, inducing knowledge complete explanations, completing explanations
instruction, abandoning explanation favor weaker learning methods.
Previous explanation-based learning systems employed one cases static
sequence options, chosen dynamically among options based
context example. dynamic selection required exible instructability. learning framework cast within computational model general intelligent
behavior called problem space computational model.
Instructo-Soar implemented agent embodies theory. interactive natural language instructions, Instructo-Soar learns perform new tasks, extends
known tasks apply new situations, acquires variety types domain
knowledge. allows exible instruction previous instructable systems (e.g.,
learning apprentice systems, Mitchell, Mahadevan, & Steinberg, 1990) meeting three
1. work inspired human students, also taken cues psychological effects
appropriate. theory's potential cognitive model discussed elsewhere (Huffman, 1994;
Huffman, Miller, & Laird, 1993).

272

fiFlexibly Instructable Agents

Push green button.
Thats new one. that?
Move grey table.
Ok. next?
Move green button.
that?
Move arm up.
Oh, see! next?
Move down.
Ok. next?
operator finished.

turn light, push button.
mean pushing button
causes light come on?
Yes.
...
Never grasp red blocks.
not?
Red blocks explosive.
light turn on.
...

Figure 1: example tutorial instruction.
key requirements tutorial instruction: (1) take known unknown commands
instruction point; (2) handle instructions apply either current situation hypothetical situation specified language (as in, instance, conditional
instructions); (3) learn, instructions, class knowledge uses
perform tasks.
follows, first discuss properties requirements tutorial instruction.
Then, present approach implementation Instructo-Soar, including
series examples illustrating instructional capabilities supported. conclude
discussion limitations areas research.

2. Properties Tutorial Instruction
Tutorial instruction situated, interactive instruction given agent attempts
perform tasks. situated applies particular task situations arise
domain. interactive agent may request instruction needed. type
instruction common task-oriented dialogues experts apprentices (Grosz,
1977). example tutorial instruction given Instructo-Soar robotic domain
shown Figure 1.
Tutorial instruction number properties make exible easy
instructor produce:
P1. Situation specificity. Instructions given particular tasks particular situations. teach task, instructor need provide suggestions specific
situation hand, rather producing global procedure includes general conditions applicability step, handles possible contingencies, etc.
situation also help disambiguate otherwise ambiguous instruction. number authors discussed advantages situation-specific knowledge elicitation
(e.g., Davis, 1979; Gruber, 1989).
P2. Situation specification needed. Although instructions typically apply
situation hand, instructor free specify situations needed;
instance, specifying contingencies using conditional instructions.
P3. Incremental as-needed elicitation. Knowledge elicited incrementally part
agent's ongoing performance. Instructions given agent unable
273

fiHuffman & Laird

perform task; thus, directly address points agent's knowledge
lacking.
P4. Task structuring instructor. instructor structure larger tasks
smaller subtasks way desired. instance, task requiring ten primitive steps
may taught simple sequence ten steps, two subtasks five steps
each, etc. agent know instructed action subtask is,
perform situation hand, ask instruction.
P5. Knowledge-level interaction. instructor provides knowledge agent
knowledge level (Newell, 1981). is, instructions refer objects
actions world, symbol-level structures (e.g., data structures) within
agent. interaction occurs natural language, language instructor
uses talk task, rather requiring artificial terminology syntax
specify agent's internal data processes.
Tutorial instructions provide knowledge applicable agent's current situation
closely related one. Thus, type instruction appropriate tasks
local control structure, control decisions made based presently available
information. Local control structure characteristic constructive synthesis tasks,
primitive steps composed one another form complete solution.
work focuses type task.2

3. Requirements Instructable Agent
Although easing instructor's burden providing knowledge, properties tutorial
instruction described place severe requirements instructable agent. general,
agent must solve three conceptually distinct problems: must (1) comprehend individual instructions produce behavior, (2) support exible dialogue instructor,
(3) produce general learning interaction. properties tutorial instruction described previous section place requirements solutions
problems. follows, identify key requirements problem turn.

3.1 Comprehending Instructions: Mapping Problem

mapping problem involves comprehending instructions given natural language transforming information contain agent's internal representation
2. contrast, problem solving methods like constraint satisfaction heuristic classification involve global
control strategies. strategies either follow fixed global regime require aggregation
information multiple problem solving states make control decisions. possible produce
global control strategy using combination local decisions (Yost & Newell, 1989). However, teaching
global method casting purely sequence local decisions may dicult. types
instruction, beyond scope work, required teach global methods natural way.
acquire knowledge tasks involve known global control strategy, may ecient use
method-based knowledge acquisition tool (e.g., Birmingham & Klinker, 1993; Birmingham & Siewiorek,
1989; Eshelman, Ehret, McDermott, & Tan, 1987; Marcus & McDermott, 1989; Musen, 1989)
control strategy built in.

274

fiFlexibly Instructable Agents

language. required agent apply information communicated instructions
knowledge level (property P5, above) internal processing.
Solving mapping problem general involves complexities natural language comprehension. Carpenter (1976) point out, instructions linguistically complex dicult interpret independent diculty task
instructed. Even linguistically simple instructions, actions objects often incompletely specified, requiring use context domain knowledge produce complete
interpretation (Chapman, 1990; DiEugenio & Webber, 1992; Frederking, 1988; Martin &
Firby, 1991).
general requirement mapping problem tutorable agent straightforward:

M1 . tutorable agent must able comprehend map aspects instruction
fall within scope information possibly represent.

agent cannot expected interpret aspects fall outside representation abilities (these abilities may augmented instruction, occurs building
existing abilities). detailed analysis could break general requirement
set specific ones.
work focused mapping problem. Rather, agent implemented uses fairly standard natural language processing techniques handle instructions
express sucient range actions situations demonstrate capabilities.
concentrated efforts interaction transfer problems.

3.2 Supporting Interactive Dialogue: Interaction Problem
interaction problem problem supporting exible dialogue instructor.
properties tutorial instruction indicate dialogue occurs agent's
ongoing performance address lacks knowledge (property P3); within dialogue,
agent must handle instructions apply different kinds situations (properties
P1 P2) structure tasks different ways (property P4).
instructable agent moves toward solving interaction problem degree
supports properties. work, concentrate instructor's utterances
within dialogue, since exibility instructor goal. considered
potential complexity agent's utterances (e.g., give instructor various kinds
feedback) much detail.
properties exible interaction specified terms individual instruction
events, instruction event utterance single instruction particular
point discourse. support truly exible dialogue, instructable agent must
able handle instruction event coherent current discourse point.
instruction event initiated either student teacher, carries knowledge
type applied particular task situation. Thus, exible tutorable agent
support instruction events with:

I1. Flexible initiation. Instruction events initiated agent instructor.
275

fiHuffman & Laird

I2. Flexibility knowledge content. knowledge carried instruction event
piece types knowledge agent uses applicable
way within ongoing task discourse context.

I3. Situation exibility. instruction event apply either current task
situation specified hypothetical situation.

following sections discuss requirements detail.
3.2.1 Flexible Initiation

human tutorial dialogues, initiation instruction mixed student teacher.
One study indicates teacher initiation prevalent early instruction; student
initiation increases student learns more, drops student
masters task (Emihovich & Miller, 1988).
Instructor-initiated instruction dicult support instruction events
interrupt agent's ongoing processing. Upon interrupting agent, instruction event
may alter agent's knowledge way could change invalidate reasoning
agent previously engaged. diculties, instructable systems
date fully supported instructor-initiated instruction.3 Likewise, InstructoSoar handle instructor-initiated instruction.
Agent-initiated instruction directed (at least) two possible ways: verification
impasses. learning apprentice systems, LEAP (Mitchell et al., 1990)
DISCIPLE (Kodratoff & Tecuci, 1987b) ask instructor verify alter reasoning
step. advantage approach step examined instructor;
disadvantage, course, step must examined. alternative approach
drive instruction requests impasses agent's task performance (Golding, Rosenbloom, & Laird, 1987; Laird, Hucka, Yager, & Tuck, 1990). approach used
Instructo-Soar. impasse indicates agent's knowledge lacking needs
instruction. advantage approach agent learns, becomes
autonomous; need instruction decreases time. disadvantage
lacks knowledge recognized reaching impasses; e.g., impasse occur
performance correct inecient.
3.2.2 Flexibility Knowledge Content

exible tutorable agent must handle instruction events involving knowledge
applicable way within ongoing task discourse context. requirement
dicult meet general, wide range knowledge may relevant
particular situation. requires robust ability relate utterance ongoing
discourse task situation. instructable systems met requirement fully.
However, define constrained form requirement, limited instructions command actions (i.e., imperatives). Imperative commands especially
prevalent tutorial instruction procedures. Supporting exible knowledge content
3. systems learned purely observing expert (e.g., Dent, Boticario, McDermott, Mitchell &
Zabowski, 1992; Redmond, 1992). Observation type instructor-initiatedness, instruction
interactive dialogue.

276

fiFlexibly Instructable Agents

commands means allowing instructor give relevant command point
dialogue teaching task. call ability command exibility.
command given, three possibilities: (1) commanded action
known, agent performs it; (2) commanded action known, agent
know perform current situation (extra, unknown steps needed);
(3) commanded action unknown. Thus, command exibility allows instructor
teaching procedure skip steps (2) command subtask unknown (3)
point. cases, agent asks instruction. interaction pattern
results, procedures commanded taught needed,
observed human instruction. Wertsch (1979) notes \...adults spontaneously follow
communication strategy use directives children understand
guide children behaviors necessary carry directives."
Command exibility gives instructor great exibility teaching set tasks instructions hierarchically structure tasks whatever way instructor
wishes. mathematical analysis (Huffman, 1994) revealed number possible
sequences instructions used teach given procedure grows exponentially
number actions procedure. procedure 6 primitive actions,
100 possible instruction sequences; 7, 400.
3.2.3 Situation Flexibility

exible tutorable agent must handle instructions apply either current task
situation hypothetical situation instructor specifies. Instructors make
frequent use options. instance, analysis protocol student
taught use ight simulator revealed 119 508 instructions (23%) involved
hypothetical situations, remainder applying current situation time
given.
Instructions apply current situation, imperative commands (e.g.,
\Move yellow table"), called implicitly situated (Huffman & Laird, 1992). Since
instruction says nothing situation applied,
current situation (the task performed current state) implied.
contrast, instructions specify elements situation meant
apply explicitly situated (Huffman & Laird, 1992). agent meant carry
instructions immediately (as implicitly situated instruction), rather
situation arises like one specified. Examples include conditionals instructions
purpose clauses (DiEugenio, 1993), following:4


using chocolate chips, add coconut mixture pressing
pie pan.



restart this, hit R shift-R.



get interval want, center joystick again.

4. examples taken protocol tutorial instruction written source instruction (a
cookbook).

277

fiHuffman & Laird

number researchers pointed (Ford & Thompson, 1986; Haiman, 1978;
Johnson-Laird, 1986), conditional clauses introduce shared reference speaker
hearer forms explicit background interpreting evaluating consequent.5
Here, clauses italics indicate hypothetical situation command
remainder instruction meant apply. cases, situation partially
specified, remainder drawn current situation, \When using chocolate
chips [and cooking recipe, current point process]..."
general, hypothetical situation may created referred across multiple
utterances. agent presented handles implicitly single explicitly situated
instructions, deal hypothetical situations exist multiple
instructions.

3.3 Producing General Learning: Transfer Problem

transfer problem problem learning generally applicable knowledge instructions, transfer appropriate situations future. general learning
based instructions apply specific situations (property P1, above). Many types
knowledge may learned, since instructions provide type knowledge
agent lacking (property P3).
Solving problem involves simply memorizing instructions future use;
rather, conditions applying instruction must determined situation.
Consider, example, following exchange instructor agent:
Block open oce door.
that?
Pick red block.
Now, drop here, next door.
proper conditions performing \pick up" action? Simple memorization yields poor learning; e.g., whenever blocking open office door, pick
red block. However, block's color, even fact block, irrelevant case. Rather, fact block weighs (say) five pounds,
giving enough friction oor hold open door, crucial. Thus, proper
learning might be:
trying block open door,
object obj picked up,
obj weighs 5 pounds
propose picking obj.
Here, original instruction generalized (color red isa block drop out)
specialized (weight > 5 added).
transfer problem places number demands tutorable agent:
T1. General learning specific cases. agent instructed particular
situation, expected learn general knowledge apply suciently
similar situations.
5. types conditionals follow pattern (Akatsuka, 1986), relevant
tutorial instruction.

278

fiFlexibly Instructable Agents

T2. Fast learning. instructable agent expected learn new procedures quickly.
T3.

T4.
T5.

T6.

Typically, task taught once.
Maximal use prior knowledge. agent must apply prior knowledge
learning instruction. maxim machine learning systems general (if
knowledge, use it), particularly relevant learning instruction
learning expected happen quickly.
Incremental learning. agent must able continually increase knowledge
instruction. New knowledge must smoothly integrated agent's
existing knowledge part ongoing performance.
Knowledge-type exibility. Since type knowledge (e.g., control knowledge,
causal knowledge, etc.) might communicated instructions, exible tutorable
agent must able learn type knowledge uses. make testable
criterion laying types knowledge agent based particular
computational model.
Dealing incorrect knowledge. agent's knowledge clearly incomplete
(otherwise, would need instruction); may also incorrect. general tutorable agent must able perform learn effectively despite incorrect knowledge.

T7. Learning instruction coexisting learning sources.

addition instruction, complete agent able learn
sources knowledge available. might include learning observation/demonstrations, experimentation environment, analogy, etc.
theory learning tutorial instruction presented focuses extending
incomplete knowledge instruction { requirements T1 T5 list. Handling incorrect knowledge (T6) learning sources (T7) planned extensions
progress.
Table 1 summarizes requirements must met instructable agent support exible tutorial instruction, indicates requirements targeted InstructoSoar. made two simplifications using requirements evaluate InstructoSoar. First, treat requirement binary; is, either completely met
unmet. reality, requirements could broken finer-grained pieces evaluated separately. Second, treat requirement independently. table indicates
Instructo-Soar's performance requirement alone, account potential interactions them. interactions complex; instance,
pursuing fast learning (T2), agent may sacrifice good general learning (T1)
bases generalizations examples. addressed tradeoffs
evaluation Instructo-Soar.

4. Related Work

Although extensive research agents learn tutorial instruction per se, learning instruction-like input long-time goal AI (Carbonell,
279

fiHuffman & Laird

Problem Requirement
Mapping M1 Mapping representable
information
Interaction I1 Flexible initiation instruction
I2 Flexibility instructional knowledge
content
I3 Situation exibility
implicitly situated
explicitly situated single utterance
explicitly situated multiple utterance
Transfer T1 General learning specific cases

T2
T3
T4
T5
T6
T7

Instructo-Soar?



(as needed show
capabilities)

(only agent-initiated)
partial (command exibility)

partial
yes
yes

yes
(via situated explanation)
Fast learning
yes
(new procedures
taught once)
Maximal use prior knowledge
yes
Incremental learning
yes
Knowledge-type exibility
yes
(learns PSCM
knowledge types)
Ability deal incorrect knowledge
(only extending incomplete knowledge)
Learning instruction coexisting
(not demonstrated)
learning sources

Table 1: requirements exible tutorable agent, Instructo-Soar's performance them.
Michalski, & Mitchell, 1983; McCarthy, 1968; Rychener, 1983). Early non-interactive systems learned declarative, ontological knowledge language (Haas & Hendrix, 1983; Lindsay, 1963), simple tasks unsituated descriptions (Lewis, Newell, & Polk, 1989; Simon,
1977; Simon & Hayes, 1976), task heuristics non-operational advice (Hayes-Roth,
Klahr, & Mostow, 1981; Mostow, 1983).
work concentrated behaving based interactive natural language instructions. SHRDLU (Winograd, 1972) performed natural language commands small
amount rote learning { e.g., learning new goal specifications directly transforming
sentences state descriptions. recent systems act response language
(concentrating mapping problem) minimal learning include SONJA
(Chapman, 1990), AnimNL (DiEugenio & Webber, 1992), Homer (Vere & Bickmore,
1990).
recent work focused learning situated natural language instructions. Martin Firby (1991) discuss approach interpreting learning
elliptical instructions (e.g., \Use shovel") matching instruction expectations
generated task execution failure. Alterman et al.'s FLOBN (Alterman, Zito-Wolf, &
Carpenter, 1991; Carpenter & Alterman, 1994) searches instructions environment
280

fiFlexibly Instructable Agents

order operate devices. FLOBN learns relating device's instructions known
procedures operating similar devices. systems target learning exible
interactive instructions types instructions imperatives, however.
bulk work learning instruction-like input rubric
learning apprentice systems (LASs), closely related programming-by-demonstration
(PbD) systems (Cypher, 1993) { employed, instance, recent work learning
within software agents (Dent et al., 1992; Maes, 1994; Maes & Kozierok, 1993; Mitchell,
Caruana, Freitag, McDermott, & Zabowski, 1994). systems learn interacting
expert; either observing expert solving problems (Cypher, 1993; Donoho & Wilkins,
1994; Mitchell et al., 1990; Redmond, 1992; Segre, 1987; VanLehn, 1987; Wilkins, 1990),
attempting solve problems allowing expert guide critique decisions
made (Golding et al., 1987; Gruber, 1989; Kodratoff & Tecuci, 1987b; Laird
et al., 1990; Porter, Bareiss, & Holte, 1990; Porter & Kibler, 1986). LAS learned
particular types knowledge: e.g., operator implementations (Mitchell et al., 1990), goal
decomposition rules (Kodratoff & Tecuci, 1987b), operational versions functional goals
(Segre, 1987), control knowledge control features (Gruber, 1989), procedure schemas (a
combination goal decomposition control knowledge) (VanLehn, 1987), useful macrooperations (Cypher, 1993), heuristic classification knowledge (Porter et al., 1990; Wilkins,
1990), etc.
Tutorial instruction exible type instruction supported past
LASs, three reasons. First, instructor may command unknown tasks tasks
unachieved preconditions agent instruction point (command exibility). Past
LASs limit input particular commands/observations particular times (e.g., commanding observing directly executable actions) typically allow unknown
commands all. Second, tutorial instruction allows use explicitly situated instructions (situation exibility), teach contingencies may present
current situation; past LASs not. Third, tutorial instruction requires types
task knowledge learned (knowledge-type exibility). Past LASs learn subset
types knowledge use perform tasks.

5. Theory Learning Tutorial Instruction

theory learning tutorial instruction consists learning framework, situated
explanation, placed within computational model general agenthood, problem space
computational model. first describe computational model learning
framework.

5.1 Problem Space Computational Model

computational model (CM) \a set operations entities interpreted
computational terms" (Newell et al., 1990, p. 6). computational model general
instructable agent must meet two requirements:
1. Support general computation/agenthood.
2. Close correspondence knowledge level. tutorial instructions
provide knowledge knowledge level (Newell, 1981), CM com281

fiHuffman & Laird

ponents knowledge level, dicult mapping learning
instructions be. addition, close correspondence knowledge level
allow us use CM identify types knowledge agent uses.
Many potential CMs ruled requirements. Standard programming languages (e.g., Lisp) theoretical CMs like Turing machines push-down automata
support general computation, operations constructs symbol level,
without direct correspondence knowledge level. Similarly, connectionist neural
network models computation (e.g., Rumelhart & McClelland, 1986) employ (by design)
computational operations entities level far knowledge level. Thus,
models appropriate top-level CM instructable agent. However, higher levels description computational system implemented lower levels
(Newell, 1990), CMs might used implementation substrate higher
level CM instructable agent.
Another alternative logic, entities well matched knowledge
level (e.g., propositions, well-formed formulas). Logics specify set legal operations
(e.g., modus ponens), thus defining space possibly computed. However,
logic provides notion computed; is, logics alone specify
control logical operations' application. desirable CM instructable
agent include control knowledge, control knowledge crucial type knowledge
general agenthood, communicated instructions.
Since one goals identify agent's knowledge types, might appear
selecting theory knowledge representation would appropriate selecting
computational model. theories define functions structures used represent knowledge (e.g., KL-ONE, Brachman, 1980); also define possible content
structures (e.g., conceptual dependency theory, Schank, 1975; CYC, Guha & Lenat,
1990). However, computational structure must added theories produce working agents. Thus, rather alternative specifying computational model, theory
knowledge representation addition. content theory knowledge representation would provide fine-grained breakdown knowledge learned
instructable agent within category knowledge specified CM.
employed particular content theory work thus far, however.
computational model adopted called problem space computational model
(PSCM) (Newell et al., 1990; Yost, 1993). PSCM general formulation computation knowledge-level agent, many applications built within (Rosenbloom, Laird, & Newell, 1993a). specifies agent terms computation within
problem spaces, without reference symbol level structures used implementation.
components approximate knowledge level (Newell et al., 1990), PSCM
apt choice identifying agent's knowledge types. Soar (Laird, Newell, & Rosenbloom, 1987) symbol level implementation PSCM.
schematic PSCM agent shown Figure 2. Perception motor modules
connect agent external environment. PSCM agent reaches goal moving
sequence states problem space. progresses toward goals sequentially
applying operators current state. Operators transform state, may produce
motor commands. PSCM, operators powerful simple STRIPS operators
(Fikes, Hart, & Nilsson, 1972), perform arbitrary computation (e.g.,
282

fiFlexibly Instructable Agents

external environment

perceptual modules

motor modules

Figure 2: processing PSCM-based agent. Triangles represent problem spaces;
squares, states; arrows, operators; ovals, impasses.
include conditional effects, multiple substeps, reactivity different situations, etc.).
PSCM agent reaches impasse immediately available knowledge
sucient either select fully apply operator. occurs, another problem
space context { subgoal { created, goal resolving impasse. second
context may impasse well, causing third context arise, on.
computational entities PSCM mediated agent's knowledge
states operators. small set basic PSCM-level operations entities
agent performs:
1. State inference. Simple monotonic inferences always applied
made without using PSCM operator. inferences augment agent's representation state inferring state properties based state properties
(including delivered perception). instance, agent might know
block held gripper closed positioned directly block.
2. Operator selection. agent must select operator apply, given current
state. process involves two types knowledge:
2.1. Proposal knowledge: Indicates operators deemed appropriate current situation. knowledge similar \precondition" knowledge simple STRIPS
operators.
2.2. Control knowledge: Orders proposed operators; e.g., \A better B"; \C
best"; \D rejected."
283

fiHuffman & Laird

3. Operator application. selected, operator may applied directly,
indirectly via subgoal:
3.1. Operator effects. operator applied directly current problem space.
agent knowledge effects operator state motor
commands produced (if any).
3.2. Sub-operator selection. operator applied reaching impasse selecting operators subgoal. Here, knowledge apply operator selection
knowledge (2, above) sub-operators.
4. Operator termination. operator must terminated application
completed. termination conditions, goal concept (Mitchell et al., 1986),
operator indicate state conditions operator meant achieve.
example, termination conditions pick-up(blk) might blk held
arm raised.6
functions performed agent using knowledge; thus, define set
knowledge types present within PSCM agent. knowledge types (five types total)
summarized Table 2. Soar implementation PSCM, knowledge
within Soar agents types.
Soar's implementation PSCM, learning occurs whenever results returned
subgoal resolve impasses. learning process, called chunking, creates rules
(called chunks) summarize processing subgoal leading creation
result. Depending type result, chunks may correspond five types
PSCM knowledge. similar situations arise future, chunks allow impasse
caused original subgoal avoided producing results directly. Chunking
form explanation-based learning (Rosenbloom & Laird, 1986). Although
summarization mechanism, taking inductive deductive steps subgoals,
chunking produce inductive deductive learning (Miller, 1993; Rosenbloom
& Aasman, 1990). Chunking occurs continuously, making learning part ongoing
activity Soar/PSCM agent.
PSCM clarifies task instructable agent: must able learn
five types PSCM knowledge instruction. next section discusses learning
process itself.

5.2 Learning Instructions Situated Explanation

Learning instruction involves analytic learning (learning based prior knowledge) inductive learning (going beyond prior knowledge). Analytic learning needed
agent must learn instructions combine known elements { e.g., learning pick objects combining known steps pick particular object. agent's
prior knowledge elements used produce better faster learning. Inductive learning needed agent must learn new task goals domain knowledge
6. PSCM operators explicit termination knowledge string conditional
effects take place time, respond (or wait for) external environment, etc.
STRIPS operators, contrast, need explicit termination knowledge, defined
single list effects, \terminated" definition applying effects.

284

fiFlexibly Instructable Agents

Entity Knowledge type Example
state
inference
gripper closed & directly obj ! holding obj.
operator proposal
goal pick obj table-x, docked tablex, propose moving table-x.
operator control
goal pick small metal obj table-x, prefer moving table-x fetching magnet.
operator effects
effect operator move table-x robot
becomes docked table-x.
operator termination
Termination conditions pick obj gripper
raised & holding obj.
Table 2: five types knowledge PSCM agents.
beyond scope prior knowledge. goal research produce
powerful analytic inductive techniques, rather specify techniques
come together produce variety learning variety instructional situations faced
instructable agent. resulting approach called situated explanation.
Instruction requirements T1 T3 specify general learning (T1) must occur
single, specific examples (T2), making maximal use prior knowledge (T3).
requirements bode strongly learning approach based explanation. use
explanation produce general learning common theme machine learning (e.g.,
DeJong & Mooney, 1986; Fikes et al., 1972; Minton, Carbonell, Knoblock, Kuokka, Etzioni,
& Gil, 1989; Rosenbloom, Laird, & Newell, 1988; Schank & Leake, 1989; many others)
cognitive science (Anderson, 1983; Chi, Bassok, Lewis, Reimann, & Glaser, 1989; Lewis,
1988; Rosenbloom & Newell, 1986). Forming explanations enables general learning
specific cases (requirement T1) explanation indicates features case
important generalized. Learning explaining typically requires
single example (requirement T2) prior knowledge employed construct
explanation (requirement T3) provides strong bias allows fast learning.
Thus, use explanation-based method core learning instruction approach, fall back inductive methods explanation fails. standard
explanation-based learning, explaining reasoning step involves forming \proof" (using
prior knowledge) step leads current state reasoning toward current
goal. proof path reasoning current state goal, step
explained, diagrammed Figure 3. General learning produced forming
rule includes causally required features state, goal, step appearing
proof; features appear generalized away.
Figure 3 indicates three key elements explanation: step explained,
endpoints explanation (a state goal G reached), steps
required complete explanation. form elements explanation take
situated explanation instruction?


Step explained. situated explanation, step explained individual
instruction given agent.
285

fiHuffman & Laird

reasoning step
explained
(indicated instruction I)

steps, agents knowledge

...



G

(Mk )

Figure 3: Caricature explanation reasoning step applies situation starting
state , goal G achieved.





Alternatively, entire instruction episode { e.g., full sequence instructions
new procedure { could explained once. Applying explanation single steps
results knowledge applicable step (as Golding et al., 1987; Laird et al.,
1990); explaining full sequences reasoning steps results learning schemas
encode whole reasoning episode (as Mooney, 1990; Schank & Leake, 1989; VanLehn, 1987). Learning factored pieces knowledge rather monolithic schemas
allows reactive behavior, since knowledge accessed locally based current situation (Drummond, 1989; Laird & Rosenbloom, 1990). meshes
PSCM's local control structure. Explaining individual instructions also supported
psychological results self-explanation effect, shown subjects
self-explain instructional examples re-deriving individual lines example. \Students virtually never ect overall solution try recognize
plan spans lines" (VanLehn Jones, 1991, p. 111).
Endpoints explanation. endpoints explanation { state goal G
achieved { correspond situation instruction applies to. Situation
exibility (requirement I3 ) stipulates situation may either current
state world goal pursued hypothetical situation specified explicitly instruction. instruction specify situational
features implicitly situated, applies agent's current situation. Alternatively, instruction specify features G, making two kinds explicitly
situated instructions. example, \If light on, push button" indicates
hypothetical state light on; \To turn machine, ip switch" indicates
hypothetical goal turning machine. situation [S; G] produced
instruction, based current task situation situation features
instruction specifies.
required steps. complete explanation instruction, agent must
bring prior knowledge bear complete path instruction
achievement situation goal. PSCM agent's knowledge applies current
situation select apply operators make inferences. explaining
instruction , knowledge applied internally situation [S; G] associated
. is, explanation takes form forward internal projection within
situation. depicted Figure 3, agent \imagines" state ,
runs forward, applying instructed step knowledge
subsequent states/operators. knowledge includes normally used
286

fiFlexibly Instructable Agents

external world knowledge operators' expected effects used
produce effects projected world. G reached within projection,
projected path , step instructed , G comprises
explanation . indicating features , , G causally required
success, explanation allows agent learn general knowledge (as
standard EBL, realized agent Soar's chunking mechanism, Rosenbloom &
Laird, 1986). However, agent's prior knowledge may insucient, causing
incomplete explanation, described below.
Combining elements produces approach learning tutorial instruction
conceptually quite simple. instruction received, agent first
determines situation meant apply to, attempts explain
step indicated leads goal achievement situation (or prohibits it, negative
instructions). explanation made, produces general learning knowledge
IK indicating key features situation instruction cause success.
explanation cannot completed, indicates agent missing one
pieces prior knowledge MK (of PSCM type) needed explain instruction.
Missing knowledge (in Figure 3, missing arrows) causes incomplete explanation precluding achievement G projection. instance, agent may know key
effect operator, crucial state inference, needed reach G. radically,
action commanded may completely unknown thus inexplicable.
shown Figure 4, four general options learning agent might follow
cannot complete explanation. (O1) could delay explanation later,
hope missing knowledge (MK ) learned meantime. Alternatively,
(O2-O3) could try complete explanation somehow learning missing
knowledge. missing knowledge could learned (O2) inductively (e.g., inducing
\gap" explanation, described VanLehn, Jones & Chi, 1992, many
others), or, (O3) instructable agent's case, instruction. Finally, (O4)
could abandon explanation altogether try learn desired knowledge another
way instead.
Given incomplete explanation, would dicult choose option
follow. Identifying missing knowledge MK general case dicult credit assignment problem (with algorithmic solution), nothing incomplete
explanation predicts whether MK learned later explanation delayed. Thus, past machine learning systems responded incomplete explanations
either single way, multiple ways, tried fixed sequence.
Many authors (Bergadano & Giordana, 1988; Hall, 1988; VanLehn, 1987; VanLehn, Jones,
& Chi, 1992; Widmer, 1989), instance, describe systems make inductions complete incomplete explanations (option O2). diculty determining missing
knowledge, systems either base induction multiple examples, and/or bias
induction underlying theory teacher's help. SIERRA (VanLehn, 1987),
example, induces multiple partially explained examples, constrains induction
requiring examples unexplainable piece missing knowledge (the disjunct, SIERRA's terminology). SWALE (Schank & Leake,
1989) uses underlying theory \anomalies" explanations complete incomplete explanations events. OCCAM (Pazzani, 1991b) uses options O2 O4 static order:
287

fiHuffman & Laird

delay explanation Mk learned

O1

delay:


instruction
context








G

incomplete explanation
(missing knowledge Mk)





k

G

learn Mk inductively complete explanation

O2
k

k

?

induce





G


k

learn Mk instruction complete explanation

O3









k

G



G

abandon explanation (learn another way)

O4







k

G

Figure 4: Options faced incomplete explanation missing knowledge
MK .
first attempts fill gaps incomplete explanation inductively, biased
naive theory; fails, abandons explanation falls back correlational learning
methods. PET (Porter & Kibler, 1986) example system delays explanation
reasoning step learns knowledge (option O1).
However, indicated Figure 4, instructable agent additional information
available besides incomplete explanation itself. Namely, instructional context
(that is, type instruction place within dialogue) often indicates
option appropriate given incomplete explanation. Thus, situated explanation includes four options dynamically selects based
instructional context. situated explanation instruction situation [S; G],
missing knowledge MK precludes completing explanation learn knowledge IK ,
options O1-O4 take following form:

O1. Delay explanation later. instructional context indicate likelihood missing knowledge MK learned later. instance, instruction
given teaching new procedure cannot immediately explained re-

maining steps procedure unknown, known later (assuming
instructor completes teaching procedure). cases, agent discards
current, incomplete explanation simply memorizes 's use [S; G] (rote learning). Later, MK learned, recalled explained [S; G], causing IK
learned.
288

fiFlexibly Instructable Agents

Given instruction knowledge IK learned:
Determine situation [S; G] (current hypothetical) applies

Explain [S; G] forward projecting !; ; G
! Success (G met): learn IK complete explanation ( EBL).
! Failure: missing knowledge MK . Options:
O1. Delay explanation later.
O2. Induce MK , completing explanation.
O3. Take instruction learn MK , completing explanation.
O4. Abandon explanation; instead, learn IK inductively.
Table 3: Situated explanation.

O2. Induce MK , completing explanation. cases, instructional context
localizes missing knowledge MK part particular operator. instance,

purpose clause instruction (\To X, Y") suggests single operator
cause X occur. localization tightly constrains \gap"
incomplete explanation, agent use heuristics induce strong guess
MK needed span gap. Inducing MK allows explanation
completed IK learned.
O3. Take instruction learn MK , completing explanation. default response agent (when options deemed appropriate) ask
instructor explain further. instruction teach agent MK .
Again, learning MK allows explanation completed IK learned.
O4. Abandon explanation learn IK another way. instructional
context indicate missing knowledge MK would dicult learn.
occurs either instructor refuses give information asked
to, agent projected multiple operators may missing pieces
knowledge (multiple potential MK s). Since unknown whether MK ever
acquired, agent abandons explanation altogether. Instead, attempts
learn IK directly (using inductive heuristics), without explanation base
learning on.
options made clearer examples presented following sections.
Situated explanation summarized Table 3. Unlike knowledge acquisition approaches, include explicit check consistency newly learned knowledge
added agent's knowledge base. Kodratoff Tecuci (1987a) point out, techniques like situated explanation biased toward consistency acquire
new knowledge current knowledge insucient, use current knowledge
deriving new knowledge. However, domains, explicit consistency checks (such
used Wilkins' (1990) ODYSSEUS) may required.
Situated explanation meets requirement learning incremental (T4)
occurs ongoing processing agent adds new pieces knowledge
289

fiHuffman & Laird

T1
T2
T3
T4
T5

I2
I3

General learning specific cases
Fast learning (each task instructed once)
Maximal use prior knowledge
Incremental learning
Knowledge-type exibility
a. state inference
b. operator proposal
c. operator control
d. operator effects
e. operator termination
Command exibility
a. known command
b. skipped steps
c. unknown command
Situation exibility
a. implicitly situated
b. explicitly situated: hypothetical state
hypothetical goal

Table 4: Expanded requirements tutorial instruction met Instructo-Soar.
agent's memory modular way. local control structure PSCM allows new
knowledge added independent current knowledge. con ict
pieces knowledge (for example, proposing two different operators situation),
impasse arise reasoned resolved instruction.

6.

Instructo-Soar

Instructo-Soar instructable agent built within Soar { thus, PSCM {
uses situated explanation learn tutorial instruction.7 Instructo-Soar engages

interactive dialogue instructor, receiving natural language instructions
learning perform tasks extend knowledge domain. section
next describe Instructo-Soar meets targeted requirements tutorial instruction,
shown expanded form Table 4. section describes system's basic
performance learning new procedures, extending procedures new situations,
imperative commands (implicitly situated instructions); next describes learning
types knowledge handling explicitly situated instructions.

7. overview Soar, systems built within it, see (Rosenbloom, Laird, & Newell, 1993b).

290

fiFlexibly Instructable Agents

Figure 5: robotic domain Instructo-Soar applied.

6.1 Domain Agent's Initial Knowledge
primary domain Instructo-Soar applied simulated robotic
world shown Figure 5.8 agent simulated Hero robot, room tables,
buttons, blocks different sizes materials, electromagnet, light. magnet
toggled closing gripper around it. red button toggles light off; green
button toggles dim bright, on.
Instructo-Soar consists set problem spaces within Soar contain three
main categories knowledge: natural language processing knowledge, originally developed
NL-Soar (Lewis, 1993); knowledge obtaining using instruction; knowledge task domain itself. task knowledge extended learning
instruction. Instructo-Soar expand natural language capabilities per se
takes instruction, although learn sentences map onto new operators
learns. complete, noiseless perception world, recognize set basic
object properties (e.g., type, color, size) relationships (e.g., robot docked-at table,
8. techniques also applied limited way ight domain (Pearson, Huffman, Willis,
Laird, & Jones, 1993), Soar controls ight simulator instructions given taking off.

291

fiHuffman & Laird

Pick red block.
Move yellow table.
Move arm red block.
Move up.
Move down.
Close hand.
Move up.
operator finished.

Figure 6: Instructions given Instructo-Soar teach pick block.
gripper holding object, objects above, directly-above, left-of, right-of one another).
set properties relations extended instruction, described below.
agent begins knowledge set primitive operators map
natural language sentences, execute. include moving tables, opening
closing hand, moving arm up, down, above, left of, right things.
agent also internally project operators. However, effects
various conditions unknown. instance, agent know operators
affect light magnet, magnet attract metal objects. Also, agent
begins knowledge complex operators (that involve combinations primitive
operators), picking arranging objects, pushing buttons, etc.

6.2 Learning New Procedures Delayed Explanation
Instructo-Soar learns new procedures (PSCM operators) instructions like

shown Figure 6, picking block. Since \pick up" known procedure
initially, told \Pick red block," agent realizes must learn new
operator.
perform PSCM operator, operator must selected, implemented, terminated. select operator future based command requires knowledge
operator's argument structure (a template), natural language maps
structure. Thus, learn new operator, agent must learn four things:
1. Template: Knowledge operator's arguments instantiated.
picking blocks, agent acquires new operator single argument,
object picked up.
2. Mapping natural language: mapping natural language semantic
structures instantiation new operator, operator selected
commanded future. picking blocks, agent learns map
semantic object \Pick ..." single argument new operator template.
3. Implementation: perform operator. New operators performed
executing sequence smaller operators. implementation takes form
selection knowledge sub-operators (e.g., move proper table, move
arm, etc.)
292

fiFlexibly Instructable Agents

4. Termination conditions: Knowledge recognize new operator achieved
{ goal concept new operator. \pick up," termination conditions
include holding desired block, arm raised.
Requirement T2 (\fast learning") stipulates first execution new procedure, agent must able perform least task without re-instructed.
Thus, agent must learn, form, four parts new operator
first execution.
general implementation new operator learned situated explanation
steps. first execution new operator, though, instructions
performing cannot explained, agent yet know goal
operator (e.g., agent know termination conditions \pick up")
steps following current one reach goal. However, instructional context
{ explaining instructed steps procedure learned { clear missing
knowledge remaining steps procedure's goal acquired later,
instructor expected teach procedure completion. Thus, agent delays
explanation (option O1) memorizes implementation instruction rote,
episodic form. end first execution new procedure, agent induces
procedure's goal { termination conditions { using set simple inductive heuristics.
later executions procedure, original instructions recalled explained
learn general implementation.
describe details process using \pick up" example.
6.2.1 First Execution

example, shown Figure 6, begins instruction \Pick red block."
agent comprehends instruction, producing semantic structure resolving \the red
block" block environment. However, semantic structure correspond
known operator, indicating agent must learn new operator (which
calls, say, new-op14). learn template new operator, agent simply assumes
argument structure command used request operator required
argument structure operator itself. case, template new operator
generated argument structure directly corresponds semantic arguments
\pick up" command (here, one argument, object). agent learns mapping
semantic structure new operator's template, used presented
similar requests future. simple approach learning templates mappings
sucient imperative sentences direct arguments, fail commands
complex arguments, path constraints (\Move dynamite room,
keeping far heater possible").
Next, new operator selected execution. Since implementation unknown,
agent immediately reaches impasse asks instructions. instruction
Figure 6 given, comprehended executed turn. instructions provide
implementation new operator. implicitly situated { applies
current situation agent finds itself.
point, agent may given another command cannot directly completed { one requests either another unknown procedure known procedure
293

fiHuffman & Laird

instruction
explained

steps

...



?
?
?

G?

Figure 7: Instructions teaching new operator cannot explained termination
conditions new operator learned.
agent know perform current situation due skipped steps.
command exibility (requirement I2). example, within instructions \pick up,"
command \Move red block" cannot completed skipped step
(the arm must raised move something). impasse arises instructor
indicates needed step (\move up"), continues instructing \pick up."
Ultimately, implementation new operator learned proper level
generality explaining instructed step. However, illustrated Figure 7,
initial execution forming explanation impossible, goal new
operator steps (further instructions) needed reach yet known.
Since missing pieces explanation expected available later, agent
delays explanation resorts rote learning instructed step.
Instructo-Soar, rote learning occurs side effect language comprehension.
reading sentence, agent learns set rules encode sentence's
semantic features. rules allow NL-Soar resolve referents later sentences, implementing simple version Grosz's focus space mechanism (Grosz, 1977). rules record
instruction, indexed goal applies place instruction
sequence. result essentially episodic case records specific, lock-step sequence instructions given perform new operator. instance, recorded
\to pick-up (that is, new-op14) red block, rb1, first told move yellow table, yt1." course, information contained within case could generalized,
point generalization would purely heuristic, agent cannot
explain steps episode. Thus, Instructo-Soar takes conservative approach
leaving case rote form.
Finally, agent told \The operator finished," indicating goal
new operator achieved. instruction triggers agent learn termination
conditions new operator. Learning termination conditions inductive concept
formation problem: agent must induce features hold current
state imply positive instance new operator's goal achieved. Standard concept
learning approaches may used here, long produce strong hypothesis within
small number examples (due \fast learning" requirement, T2). Instructo-Soar
uses simple heuristic strongly bias induction: hypothesizes everything
changed initial state new operator requested current
state part new operator's termination conditions. case, changes
robot docked table, holding block, block gripper
air.
294

fiFlexibly Instructable Agents

heuristic gives reasonable guess, clearly simple. Conditions
changed may matter; e.g., perhaps doesn't matter picking blocks
robot ends table. Unchanged conditions may matter; e.g., learning build
\stoplight," block colors important although change. Thus, agent
presents induced set termination conditions instructor possible alteration
verification. instructor add remove conditions. example, \pick
up" case instructor might say \The robot need docked yellow table"
remove condition deemed unnecessary, verifying termination conditions.
Instructo-Soar performs induction EBL (chunking) overgeneral theory
make inductive leaps (similar to, e.g., Miller, 1993; Rosenbloom & Aasman, 1990;
VanLehn, Ball, & Kowalski, 1990). type inductive learning advantage
agent alter bias ect available knowledge. case, agent
uses instruction (the instructor's indications features add remove) alter
induction. knowledge sources could employed (but current
implementation) include analogy known operators (e.g., pick actions
domains), domain-specific heuristics, etc.
first execution new operator, then, agent:
Carries sequence instructions achieving new operator.
Learns operator template new operator.
Learns mapping natural language new operator.
Learns rote execution sequence new operator.
Learns termination conditions new operator.
Since agent learned necessary parts operator, able
perform task without instruction. However, since implementation
operator rote, perform exact task. learned generally
pick things yet.
6.2.2 Generalizing New Operator's Implementation

agent knows goal concept full (though rote) implementation sequence
new operator. Thus, information needs explain instruction
implementation sequence leads goal achievement, provided underlying domain
knowledge sucient.
instruction explained recalling episodic memory internally projecting effects rest path achievement termination conditions
new operator. projection \proof" instructed operator lead
goal achievement situation. Soar's chunking mechanism essentially computes
weakest preconditions situation instruction required success (similar
standard EBL) form general rule proposing instructed operator. rule learned
instruction \Move yellow table" shown Figure 8. rule generalizes
original instruction dropping table's color, specializes adding facts
table object sitting object small (only small objects
295

fiHuffman & Laird



goal new-op-14(?obj),
?obj table ?t, small(?obj),
robot docked ?t,
gripper status(open),
propose operator move-to-table(?t).
Figure 8: general operator proposal rule learned instruction \Move
yellow table" (new-op-14 newly learned \pick up" operator).
grasped gripper). rule also tests gripper open,
condition important grasping block instructed case.9
learning general proposal rules step instruction sequence, agent
perform task without reference rote case. instance, asked \Pick
green block," agent selects new-op14, instantiated green block. Then,
general sub-operator proposal rules like one Figure 8 fire one one, match
current situation, implement operator. performing implementation
steps, agent recognizes termination conditions met (the gripper raised
holding green block), new-op14 terminated.
Since general proposal rules implementing task directly conditional
state, agent perform task starting state along implementation
path react unexpected conditions (e.g., another robot stealing block).
contrast, rote implementation initially learned applied starting
original starting state, reactive steps conditional
current state.

6.3 Recall Strategies

described agent recalls explains step new operator's implementation sequence, operator's termination conditions induced.
still two open issues: (A) point learning termination conditions
agent perform recall/projection?, (B) many steps recalled
projected sequence time?
investigate issues, implemented two different recall/project strategies:
1. Immediate/complete recall. agent recalls attempts explain full
sequence instructions new operator immediately learning new
operator's termination conditions.
2. Lazy/single-step recall. agent recalls attempts explain single instructions sequence asked perform operator starting
initial state. is, point execution operator, agent
9. technical details Soar's chunking mechanism forms rules found (Huffman,
1994; Laird, Congdon, Altmann, & Doorenbos, 1993).

296

fiFlexibly Instructable Agents

recalls next instruction, attempts explain forward projecting it. However, projection result path goal achievement without
instructions recalled, rather recalling next instruction
sequence continue forward projection, agent gives explaining
instruction simply executes external world.
strategies represent extremes continuum strategies.10 strategy
use parameter agent; dynamically select strategies
running. possible extension would reason time pressure different
situations select appropriate strategy. Next, brie describe implications
recall strategy.
6.3.1 Immediate/Complete Recall Strategy

Immediate/complete recall explanation involves internally projecting multiple operators
(the full instruction sequence) immediately first execution new operator.
projection begins state agent new operator first suggested.
projection successfully achieves termination conditions new operator,
agent learns general implementation rules every step. advantage strategy
agent learns general implementation new operator immediately
first execution (e.g., agent pick objects right away).
strategy three important disadvantages. First, requires agent reconstruct initial state commanded perform new operator.
reconstruction may dicult amount information state large (although
small robotic domain used here).
Second, recall projection entire sequence instructed steps time-consuming,
requiring time proportional length instruction sequence. process,
agent's performance tasks hand suspended. suspension could awkward
agent pressure act quickly.
Third, illustrated Figure 9, multiple step projections susceptible compounding errors underlying domain knowledge. projection successive operator
begins state ects agent's knowledge effects prior operators
sequence. knowledge incomplete incorrect, state move
ecting actual effects prior operators. Minor domain knowledge problems knowledge individual operators, alone would produce error
single step explanation, may combine within projection cause error.
lead incomplete explanations (more rarely) spuriously successful explanations (e.g.,
reaching success early instruction sequence).
6.3.2 Lazy/Single-Step Recall Strategy

lazy/single-step recall strategy, agent waits recall explain instructions
asked perform new operator second time initial state. addition,
agent recalls single instruction internally project time. recalled
10. also implemented lazy/complete recall strategy, described (see Huffman,
1994, details).

297

fiHuffman & Laird

opX
op1

S1

op1

op2

S2
S2

op3

S3

...

G tc

opX

Internally projected path
(reflecting agents incorrect
knowledge operator effects)

Sx

states reflecting
actual operator effects

Sx

states reflecting
projected operator effects

G tc

state meets
termination conditions
current goal

op2

S3
op3

... Sn (= G )
tc

Correct path (reflecting
actual operator effects)

Figure 9: Multiple step projections result incomplete explanations due compounding errors domain knowledge.
operator projected, agent applies whatever general knowledge rest
implementation new operator. general knowledge, however,
include rote memories past instructions. is, agent know
rest path complete new operator using general knowledge, recall
instructions sequence rote memories. Rather, internal projection
terminated single recalled operator applied external world.
strategy addresses three disadvantages immediate/complete strategy.
First, require reconstruction original instruction state; rather, waits
similar state occur again.
Second, recalling projecting single instruction time require timeconsuming introspection suspends agent's ongoing activity. \pick up,"
instance, Table 5 shows longest time agent's external action (movements
instruction requests) suspended using strategy (as measured Soar decision cycles,
last 35 milliseconds Instructo-Soar SGI R4400 Indigo).
immediate/complete strategy external actions 304 decision cycles (about
11 seconds Indigo) immediately following first execution, order recall
explain complete instruction sequence. Using lazy/single-step strategy,
one instruction ever recalled/explained time action taken world;
thus, longest time without action 75 decision cycles (about 2 seconds).
total recall/explanation time proportional length instruction sequence
cases (304 vs. 294 decision cycles), lazy/single-step strategy, time
interleaved execution instructions rather fully taken first
execution.
Third, lazy/single-step strategy overcomes problem compounding domain
theory errors beginning projection instruction current state
world external execution previous instructions. Thus, beginning state
projection correctly ects effects previous operators implementation
sequence.
major disadvantage strategy requires number executions
new operator equal length instruction sequence order learn whole
298

fiFlexibly Instructable Agents

Immediate/complete Lazy/single-step
Largest time without external action 304
75
Largest total recall/explanation time 304 (end 1st exec'n) 294 (during 2nd exec'n.)
execution

Decision cycles (log scale)

Table 5: Timing comparison, Soar decision cycles, learning \pick up" using immediate/complete lazy/single-step recall strategies.
1000

(r = 0.98)
(r = 0.98)

1000

100

100

10
1

10

Execution number (log scale), "pick up"
(a)

1

10

Execution number (log scale), "move left of"
(b)

Figure 10: Decision cycles versus execution number learn (a) pick (b) move
objects left one another, using lazy/single-step strategy.
general implementation. limiting recall single step allows single
sub-operator per execution generalized. disadvantage, however, leads two
interesting learning characteristics:
Back-to-front generalization. Generalized learning starts end implementation sequence moves towards beginning. second execution
new operator, path goal known last instruction sequence
(it leads directly goal completion), general proposal instruction
learned. third execution, second last instruction projected,
proposal learned previously last operator applies, leading goal achievement
allowing general proposal second last instruction learned.
pattern continues back entire sequence full implementation
learned generally. Figure 10 shows, resulting learning curves closely approximate power law practice (Rosenbloom & Newell, 1986) (r = 0:98 (a)
(b)).
Effectiveness hierarchical instruction. Due back-to-front effect,
agent learns new procedure quickly steps taught using hierarchical organization taught sequence. Figure 11 depicts
at, nine-step instruction sequence teaching Instructo-Soar move one block
299

fiHuffman & Laird

1
move left of(block, block2)

6

4

2

move arm

move table (table)
3

graphical

10

moveleftof(arm,block2)

7

5

move (block)

Figure 11:

8

move arm

close gripper

view

move arm

move table (table)





move-left-of(block,block2).

open gripper

9



instruction

sequence



1
move left of(block, block2)

2

11

9
moveleftof(arm,block2)

pick (block)

put (block)

10
move table (table)
3

4
move table (table)

8

6

5
move (block)

Figure 12:

12
move arm

grasp (block)

graphical

move arm

13
open gripper

7
move arm

view

close gripper



hierarchical instruction sequence
move-left-of(block,block2). New operators shown bold.



left another; Figure 12 depicts hierarchical instruction sequence procedure, contains 13 instructed steps, maximum 3 subsequence.
breaking instruction sequence shorter subsequences, hierarchical organization allows multiple subtrees hierarchy generalized execution.
General learning N step operator takes N executions using
instruction
HpN subtasks
sequence. Taught hierarchically


H
-level
hierarchy

p
subsequence, H H N executions required full generalization. hierarchy Figure 12 irregular structure, results apspeedup
length every subsequence small (in case, smaller N ). Empirically,
sequence Figure 11 takes nine (N ) executions generalize, whereas hierarchical sequence takes six. Hierarchical organization additional advantage
operators learned used future instructions.
300

fiFlexibly Instructable Agents

6.4 Supporting Command Flexibility

Command exibility (requirement I2 ) stipulates instructor may request either
unknown procedure, known procedure agent know perform
current state (skipping steps), point. lead multiple levels embedded
instruction. seen, Instructo-Soar learns completely new procedures
instructions unknown commands. addition, agent asked perform
known procedure unfamiliar situation { one agent know
step take { learns extend knowledge procedure situation.
example contained instructions \Pick red block," agent
asked \Move red block." agent knows perform operator
arm raised. However, case arm lowered, agent reaches
impasse asks instruction.11 told \Move up," agent internally
projects raising arm, allows achieve moving red block.
projection learns general rule: move arm trying move object
table agent docked at. rule extends \move above" procedure
cover situation.
operator { even one previously learned instruction { may require extension
apply new situation. agent learns general implementation
new operator, reason possible situations operator
might performed, limits explanations series situations arises
actual execution new operator learned.
Newly learned operators may included instructions later operators, leading
learning operator hierarchies. One hierarchy operators learned Instructo-Soar
shown Figure 13. Learning procedural hierarchies identified fundamental
component children's skill acquisition tutorial instruction (Wood, Bruner, & Ross,
1976). learning hierarchy Figure 13, Instructo-Soar learned four new operators, extension known operator (move above), extension new operator
(extending \pick up" work robot already holding block). command
exibility, hierarchy taught exponentially many different ways (Huffman, 1994). instance, new operators appear sub-operators (e.g., grasp)
taught either teaching higher operators (e.g., pick up).

6.5 Abandoning Explanation Domain Knowledge Incomplete

general operator implementation learning described thus far depends explaining
instructions using prior domain knowledge (as opposed learning operator termination conditions, inductive). domain knowledge incomplete, making
explanation impossible? sequences multiple operators, pinpointing knowledge
missing extremely dicult credit assignment problem (sequences known contain
one operator, however, constrained case, described next section).
11. Another option would search; i.e., apply weak method means-ends analysis.
example, search would easy; cases, could costly. event, since goal
Instructo-Soar investigate use instruction, agent always asks instructions
reaches impasse task performance. Nothing Instructo-Soar precludes use search
knowledge sources, however.

301

fiHuffman & Laird

lineup(block1,block2,block3)

move left of(block2,block1)

pick (block)

move arm

moveleftof(arm,block1)

move table (table)

grasp (block)

put (blockX)

move left of(block3,block2)

put (block)

move arm

(lg. metal)

open gripper
grasp (magnet)

move (block)

move arm

(small)

move table (table)

move (blk/mag)

move arm

close gripper

move arm

Figure 13: hierarchy operators learned Instructo-Soar. Primitive operators
light print; learned operators bold.
general, explanation failure detected end projection instruction sequence could caused missing knowledge operator sequence.
Thus, faced incomplete explanation sequence multiple instructions,
Instructo-Soar abandons explanation instead tries induce knowledge directly
instructions (option O4).
example, consider case Instructo-Soar's knowledge secondary operator effects (frame axiom type knowledge) removed teaching procedure. example, although agent knows closing hand causes
status closed, longer knows closing hand around block causes block
held. Now, agent taught new procedure, pick red block.
first execution, agent attempts recall explain instructions usual,
fails missing knowledge. is, block picked
projection instructions, since agent's knowledge indicate held.
agent records fact procedure's instructions cannot explained.
Later, agent asked perform procedure, recalls instructions. However, also recalls explaining instructions failed past. Thus,
abandons explanation instead attempts induce general proposal rule directly
instruction.12
12. Since incomplete explanation procedure may indicate effect(s) operator
instruction sequence unknown, another alternative (not yet implemented Instructo-Soar) would
agent observe effects operator sequence performed, comparing
observations effects predicted domain knowledge. differences would allow agent

302

fiFlexibly Instructable Agents

G: newop14 ("pick up")
object: <redblock>

<redblock> <yellowtable>

OP: movetotable
destination: <yellowtable>

Figure 14: use OP-to-G-path heuristic, OP \move yellow table,"
G \pick red block."
\pick up" example, agent first recalls command move yellow
table. learn proposal rule operator (call OP ), agent must induce set
conditions state performing OP contribute achieving \pick
up" goal (call G). Instructo-Soar uses two simple heuristics induce state
conditions:
OP-to-G-path. object Obj 1 filling slot OP , object Obj 2
attached G, include shortest existing path (heuristically length less
three) relationships Obj 1 Obj 2 set induced conditions.
heuristic captures intuition operator involves object,
relationship objects relevant goal probably important. Figure 14
shows operation \move yellow table." figure indicates,
path G's object, red block, destination OP , yellow table,
relationship block table.
OP-features-unachieved. termination condition (essentially, primary
effect) OP achieved state OP performed considered
important condition.
heuristic captures intuition primary effects OP probably
important; therefore, matters achieved OP selected.
example, OP 's primary effect robot ends docked table; thus,
fact robot initially docked table added inferred set
conditions proposing OP .
heuristics implemented Soar operators compute appropriate conditions. set conditions induced, presented instructor, add
remove conditions verifying them. Upon verification, rule learned proposing OP
(e.g., move-to-table(?t)) induced conditions hold (e.g., goal pick-up(?b),
?b isa block, on(?b,?t)). rule similar rule learned explanation (Figure 8), applies picking block (overspecific), stipulate
learn new operator effects could complete explanation procedure. Learning effects
operators observation explored number researchers (Carbonell & Gil, 1987;
Pazzani, 1991b; Shen, 1993; Sutton & Pinette, 1985; Thrun & Mitchell, 1993).

303

fiHuffman & Laird

object must small (overgeneral). similar induction occurs step \pick up,"
agent learns general implementation full \pick up" operator. However,
unless corrections made instructor, induced implementation correct
one learned explanation; instance, applies (wrongly) block instead
small object. complex domain, inferring implementation rules would
even less successful. surprisingly, psychological research shows human subjects'
learning procedural instructions also degrades lack domain knowledge (Kieras
& Bovair, 1984).
Returning targeted instruction requirements Table 4, Instructo-Soar's learning procedures illustrates (T1) general learning specific instructions, (T2) fast learning (because procedure need instructed once) (T3) using prior domain
knowledge construct explanations, (T4) incremental learning agent's ongoing performance. Two types PSCM knowledge learned: (T5(b)) operator proposals
sub-operators procedure, (T5(e)) procedure's termination conditions.
learning involves either delayed explanation, domain knowledge inadequate,
abandoning explanation favor simple induction. instructions (I3 (a)) implicitly situated imperative commands, either (I2(a)) known procedures, (I2(b)) known
procedures steps skipped, (I2(c)) unknown procedures.

7. Beyond Imperative Commands

Next, turn learning remaining types PSCM knowledge (T5(a,c,d)) various
kinds explicitly situated instructions (I3(b)). explicitly situated instruction,
Instructo-Soar constructs hypothetical situation (goal state) includes
objects, properties, relationships mentioned explicitly instruction well
features current situation needed carry instruction.13
hypothetical situation used context situated explanation instruction.

7.1 Hypothetical Goals Learning Effects Operators

goal explicitly specified instruction purpose clause (DiEugenio, 1993): \To
X, Y." basic knowledge learned instruction operator
proposal rule goal achieve X.
Consider example Instructo-Soar's domain:
> turn light, push red button.

agent taught push buttons, know red button's
effect light. purpose clause instruction like example, agent creates
hypothetical situation goal stated purpose clause (here, \turn light"),
state like current state, goal achieved (here, light off).
Within situation, agent attempts explain instruction forward projecting
action pushing red button.
agent knew pushing red button toggles light, projection,
light would come on. Thus, explanation would succeed, general operator
13. See (Huffman, 1994) details features determined.

304

fiFlexibly Instructable Agents

proposal rule would learned, proposed pushing red button light
goal turn on.
However, since actuality agent missing knowledge (MK ) pushing
button affects light, light come within projection. explanation
incomplete.
Instructo-Soar's explanation sequence operators fails, agent
try induce missing knowledge needed complete explanation,
could associated multiple operators. Rather, explanation simply
abandoned, described Section 6.5. However, case, unexplainable sequence
contains one operator. addition, form instruction gives agent
strong expectation operator's intended effect. Based purpose clause,
agent expects specified action (pushing button) cause achievement
specified goal (turning light). DiEugenio (1993) found empirically type
expectation holds 95% naturally occurring purpose clauses.
expectation constrains \gap" incomplete explanation: state
pushing button state light on, one action performed
produce effect. Based constrained gap, agent attempts induce missing
knowledge MK order complete explanation (option O2). straightforward
inference MK simply unknown effect single action produce
expected goal conditions { e.g., pushing button cause light come on.
instructor asked verify inference.14
verified, Instructo-Soar heuristically guesses state conditions
effect occur. uses OP-to-G-path heuristic naive causality
theory (Pazzani, 1991a) guess causes inferred operator effect. Here, OP-toG-path notices light red button table. addition,
agent includes fact inferred effect hold (the light off)
operator caused it. result presented instructor:
think push button causes:
light
following conditions:
light currently on, light table, button table
right conditions?
Here, heuristics recognized matters button pushed (the red
one). instructor add condition saying ``The button must red.''
instructor verifies conditions, agent adds new piece operator effect
knowledge memory:


projecting push-button(?b),
?l isa light status off, table ?t,
?b isa button color red, table ?t,
light ?l status on.

14. inference rejected, agent abandons explanation directly induces proposal rule
pushing button instruction, described Section 6.5.

305

fiHuffman & Laird

Immediately learned, rule applies light forward projection
current instruction. light comes on, completing instruction's explanation
achieving goal. explanation, agent learns proposal rule proposes
pushing red button goal turn light. Thus, agent acquired
new knowledge multiple levels; inferring unknown effect operator supported
learning proposal operator.
example illustrates (I3 (b)) use hypothetical goal instructions use
option O2 dealing incomplete explanations { inferring missing knowledge {
learn new operator effects (T5(d)), thus extending domain knowledge.

7.2 Hypothetical States Learn Contingencies

Instructors use instructions hypothetical states (e.g., conditionals: \If [state conditions], ...") either teach general policies (\If lights leave
room, turn off.") teach contingencies performing task. InstructoSoar handles these; here, describe latter.
contingency instruction indicates course action followed current
task performed future situation different current situation. Instructors
often use contingency instructions teach situations differ current
one crucial way alter agent's behavior. Contingency instructions
common human instruction; Ford Thompson (1986) found 79%
conditional statements instruction manual communicated contingency options
student.
Consider interaction:
> Grasp blue block.

That's new one me. that?

> blue block metal, pick magnet.

blue block made metal, instructor communicating were,
different course action would required.
conditional instruction \If blue block metal, pick magnet,"
agent needs learn operator proposal rule picking magnet appropriate conditions. agent begins constructing hypothetical situation
\pick magnet" applies. \If blue block metal" indicates hypothetical state
variant current state blue block material metal.
current goal (\Grasp blue block") also goal hypothetical situation.
Within situation, agent projects picking magnet explain
allow block grasped. However, agent missing much knowledge needed
complete explanation. know goal concept \Grasp" yet, rest
instructions reach goal.
Since instruction explained contingency, rest instructions
agent given \Grasp blue block" may (and case, not) apply
contingent situation, block metal. normal grasp sequence,
instance, agent learns close hand around grasped object, grasping
metal object, hand closed around magnet. Since knowledge complete
306

fiFlexibly Instructable Agents

grasping metal object needed explain contingency instruction, agent
know might learn missing knowledge, abandons explanation
(option O4). Instead, uses heuristics described Section 6.5 directly induce
operator proposal rule \Grasp magnet." addition conditions generated
heuristics, conditions indicated antecedent instruction included.
result presented instructor alteration verification:
I'm guessing conditions \pick magnet"
goal \grasp block" are:
block metal
right?
> Right.

interaction agent learns rule proposes picking magnet
goal grasp metal block. learning completed, since agent yet
finished grasping blue block, continues receive instruction task.
contingencies indicated point. Learning contingencies illustrates (I3(b))
handling hypothetical state instructions.

7.3 Learning Reject Operators

final examples illustrate learning reject operator { type operator control
knowledge PSCM. examples also detail remaining option dealing
incomplete explanations: (O3) completing explanation instruction.
Consider instructions:
> Never grasp green blocks.

Why?
(a) > Trust me.
(b) > Green blocks explosive.
negative imperative prohibits step applying hypothetical situation
might apply. Thus, Instructo-Soar creates hypothetical situation
prohibited action might executed; case, state graspable green block.
Since goal specified instruction, current goal, default
goal \maintaining happiness" (which always considered one agent's current goals)
used. hypothetical situation, agent internally projects \grasp" action,
expecting \unhappy" result. However, resulting state, agent grasping
green block, acceptable according agent's knowledge. Thus, projection
explain action prohibited.
agent deals incomplete explanation asking instruction,
attempt learn MK complete explanation. However, instructor decline
give information saying (a) Trust me. Although instructor provide MK , prohibition single operator (grasping green block)
explained, agent induce plausible MK complete explanation (option
O2). Since agent knows final state prohibited operator meant
\unhappy", simply induces state avoided. converse learning recognize desired goal reached (learning operator's termination
307

fiHuffman & Laird

conditions). agent conservatively guesses features hypothetical
state (here, green block held), taken together, make state
avoided. inference conservative, current implementation
instructor even asked verify it. state inference rule results follows:


goal ``happiness'',
?b isa block color green,
holding(gripper,?b),
state fails achieve ``happiness''.

rule applies final state projection \Never grasp..." state's failure
achieve happiness completes agent's explanation \Never grasp...,"
learns rule rejects proposed operator grasping green block.
Alternatively, instructor could provide instruction, (b) Green blocks
explosive. instruction provide missing knowledge MK needed complete incomplete explanation (option O3). (b), agent learns state inference
rule: blocks color green explosiveness high. Instructo-Soar learns state
inferences simple statements like (b), conditionals (e.g., \If magnet
powered directly metal block, magnet stuck block") essentially translating utterance directly rule.15 state inference instructions
used introduce new features extend agent's representation vocabulary
(e.g, stuck-to).
rule learned \Green blocks explosive" adds explosiveness high
block agent simulated grasping hypothetical situation. agent knows
touching explosive object may cause explosion { negative result. negative
result completes explanation \Never grasp...," agent learns avoid
grasping objects explosiveness high.
Completing explanation instruction (as (b)) produce
general learning heuristically inferring missing knowledge (as (a)). (b),
agent later told Blue blocks explosive, avoid grasping well.
general, multiple levels instruction lead higher quality learning single level
learning based explanation composed strong lower-level knowledge
(MK ) rather inductive heuristics alone. MK (here, state inference rule) also
available future use.
agent learned reject \grasp" operator recognize
bad state performing would lead to, agent recognize bad state
reached another path. instance, agent led individual
steps grasping explosive block without instructor ever mentioning \grasp."
agent finally asked \Close gripper" around explosive object, so,
immediately recognizes undesirable state arrived reverses
close-gripper action. process, learns reject close-gripper hand
around explosive object, future reach undesirable state
path.
15. translation occurs chunking, uninteresting way. Instructo-Soar use explanation learn state inferences. extension would try explain inference holds using
deeper causal theory.

308

fiFlexibly Instructable Agents

Notice effect situated nature Instructo-Soar's learning. agent
learns avoid operators lead bad state arise agent's
performance. initial learning bad state recognitional rather predictive.
Alternatively, agent first learns bad state, could extensive reasoning
determine every possible operator could lead state, every possible
previous state, learn reject operators appropriate times. unsituated
reasoning would expensive; agent would reason huge number
possible situations. addition, whenever new operators learned, agent would
reason possible situations could arise, learn
could ever led bad state. Rather costly reasoning, Instructo-Soar simply
learns situations arise.
Another alternative completely avoiding bad states would think
effects every action taking it, see bad state result. highly cautious
execution strategy would appropriate dangerous situations, appropriate
safer situations agent time pressure. (Moving less
cautious execution strategies currently implemented Instructo-Soar.)
\Never grasp..." examples illustrated agent's learning one type
operator control knowledge, namely operator rejection (T5(c)), learning state inferences
(T5(a)), use instruction complete incomplete explanations (option O3).
final category learning discuss second type operator control knowledge.

7.4 Learning Operator Comparison Knowledge
Another type control knowledge besides operator rejection rules operator comparison
rules, compare two operators express preference one given
situation. Instructo-Soar learns operator comparison rules asking instructor's
feedback multiple operators proposed point achieve particular
goal. Multiple operators proposed, instance, agent taught two
different methods achieving goal (e.g., pick metal block either using
magnet directly gripper). instructor asked either select one
proposed operators indicate action appropriate. Selecting one
proposed choices causes agent learn rule prefers selected operator
proposed operators situations like current situation. Alternatively,
instructor indicates operator outside set proposed operators,
Instructo-Soar attempts explain operator usual way, learn general
rule proposing it. addition, agent learns rules preferring instructed operator
currently proposed operators.
two weaknesses Instructo-Soar's learning operator comparison rules.
First, instructor required indicate preference step needed complete procedure, rather simply choosing overall methods. is,
instructor cannot say \Use method grab block gripper, instead
using magnet," must indicate preference individual step method
employing gripper. PSCM, knowledge steps procedure
accessed independently, separate proposal rules, rather aggregate method.
Independent access improves exibility reactivity { agent combine steps
309

fiHuffman & Laird

different methods needed based current situation { higher level grouping
steps would simplify instruction selecting complete methods.
second weakness although agent uses situated explanation explain
selection instructor makes, explain selection better
possibilities. Preferences viable operators often based global considerations;
e.g., \Prefer actions lead overall faster/cheaper goal achievement." Learning based
type global preference (which turn may learned instruction)
point research.

8. Discussion Results
shown Instructo-Soar learns various kinds instructions. Although
domain used demonstrate behavior simple, enough complexity exhibit
variety different types instructional interactions occur tutorial instruction.
11 requirements tutorial instruction places instructable agent (listed
Table 1), Instructo-Soar meets 7 (listed expanded form Table 4) either fully partially. Three particular distinguish Instructo-Soar previous instructable
systems:






Command exibility: instructor give command task
instruction point, whether agent knows task perform
current situation.

Situation exibility: agent learn implicitly situated instructions
explicitly situated instructions specifying either hypothetical goals states.

Knowledge-type exibility: agent able learn types knowledge uses task performance (the five PSCM types) instruction.

Earlier, claimed handling tutorial instruction's exibility requires breadth
learning interaction capabilities. Combining command, situation, knowledge-type
exibility, Instructo-Soar displays 18 distinct instructional capabilities, listed Table 6. variety instructional behavior require 18 different learning techniques,
arises one general technique, situated explanation PSCM-based agent, applied
range instructional situations.
series examples illustrated situated explanation uses instruction's
situation context learning process. First, situation instruction applies provides endpoints attempting explain instruction. Second,
instructional context indicate option follow explanation cannot
completed. context learning new procedure indicates delaying explanation
(option O1) best, since full procedure eventually taught. step cannot
explained previously taught procedure, missing knowledge could anywhere
procedure, best abandon explanation (option O4) learn another way. Instructions provide explicit context, purpose clause, localize missing
knowledge giving strong expectations single operator achieve single
goal. localization makes plausible induce missing knowledge complete
310

fiFlexibly Instructable Agents

1.
2.
3.
4.
5.
6.
7.

Instructional capability
Learning completely new procedures
Extending procedure apply new situation
Hierarchical instruction: handling instructions
procedure embedded instruction others
Altering induced knowledge based
instruction
Learning procedures inductively domain
knowledge incomplete
Learning avoid prohibited actions
general learning due instruction

8. Learning avoid indirect achievement bad
state
9. Inferences simple specific statements
10. Inferences simple generic statements
11. Inferences conditionals
12. Learning operator perform hypothetical
goal
13. Learning operator perform hypothetical
state: general policy (active times)
14. Learning operator perform hypothetical
state: contingency within particular procedure
15. Learning operator effects
16. Learning non-perceivable operator effects associated inferences recognize
17. Learning control knowledge: learning set
operators prefer
18. Learning control knowledge: learning operators
indifferent

Example
pick

move move
teaching pick within line

removing docked-at pick
up's termination conditions
learning secondary operator
effects knowledge removed
\Never grasp red blocks."
Avoid grasping \Red
blocks explosive."
closing hand around explosive
block
\The grey block metal."
\White magnets powered."
\if condition [and condition]*
concluded state feature"
\To turn light, push
red button."
\If light bright, dim
light."
\If block metal, grasp
magnet" pick
pushing red button turns
light
magnet becomes stuck-to
metal block moved
two ways grasp small metal
block
two ways grasp small metal
block

Table 6: Instructional capabilities demonstrated Instructo-Soar.

311



fiHuffman & Laird

explanation (option O2). cases, default ask instruction missing
knowledge complete explanation (option O3).

8.1 Empirical Evaluation

empirical evaluations machine learning systems take one four forms, appropriate addressing different evaluation questions:
A. Comparison systems. technique useful evaluating overall
performance compares state art. used
systems available learning task.
B. Comparison altered version system. technique evaluates
impact component system overall performance. Typically,
system compared version without key component (sometimes called
\lesion study").
C. Measuring performance systematically generated series problems. technique evaluates method affected different dimensions input (e.g.,
noise training data).
D. Measuring performance known hard problems. Known hard problems provide
evaluation overall performance extreme conditions. instance, concept
learners' performance often measured standard, dicult datasets.
evaluation techniques applied limited ways Instructo-Soar.
dicult apply great depth two reasons. First, whereas machine
learning efforts concentrate depth single type learning single type input,
tutorial instruction requires breadth learning range instructional interactions. Whereas depth measured quantitative performance, breadth measured
(possibly qualitative) coverage { here, coverage 7 11 instructability requirements. Second, tutorial instruction extensively studied machine learning,
battery standard systems problems available. Nonetheless, evaluation
techniques (B), (C), (D) applied Instructo-Soar address specific
evaluation questions:
B. Comparison altered version: removed frame-axiom knowledge illustrate
effect prior knowledge agent's performance, described Section 6.5.
Without prior knowledge, agent unable explain instructions must resort
inductive methods. Thus, removing frame-axiom knowledge increased amount
instruction required reduced learning quality. also compared versions
agent use different instruction recall strategies (Section 6.3).
C. Performance systematically varied input: examined effects varying three
dimensions instructions given agent. First, compared learning curves
instruction sequences different lengths (Section 6.2). graphs Figure 10
show, Instructo-Soar's execution time instructed procedure varies
number instructions sequence used teach it. Total execution time drops
312

fiFlexibly Instructable Agents

time procedure executed, according power law function, procedure learned general form. Second, compared teaching procedure
hierarchical subtasks versus using instruction sequence. Based
power law result, predicted hierarchical instruction would allow faster general
learning instruction. prediction confirmed empirically. Third,
examined number instruction orderings used teach given procedure Instructo-Soar order measure value supporting command
exibility. Rather experimental measurement, performed mathematical
analysis. analysis showed due command exibility, number instruction sequences used teach given procedure large, growing
exponentially number primitive steps procedure (Huffman, 1994).
D. Performance known hard problem: Since learning tutorial instruction
extensively studied machine learning, standard, dicult
problems. created comprehensive instruction scenario crossing command
exibility, situation exibility, knowledge-type exibility requirements. scenario, described detail (Huffman, 1994), contains 100 instructions demonstrates 17 Instructo-Soar's 18 instructional capabilities Table 6 (it
include learning indifference selecting two operators). agent learns
4,700 chunks scenario, including examples type PSCM
knowledge, extend agent's domain knowledge significantly.

9. Limitations Research
work's limitations fall three major categories: limitations tutorial instruction
teaching technique, limitations agent's general capabilities, limitations
incomplete solutions mapping, interaction, transfer problems. discuss
turn.

9.1 Limitations Tutorial Instruction

Tutorial instruction highly interactive situated. However, much human
instruction either non-interactive unsituated (or both), considered work. non-interactive instruction, content ow information
student controlled primarily information source. Examples include classroom
lectures, instruction manuals, textbooks. One issue using type instruction
locating extracting information needed particular problems (Carpenter
& Alterman, 1994). Non-interactive instruction contain situated information (e.g.,
worked-out example problems, Chi et al., 1989; VanLehn, 1987) unsituated information
(e.g., general expository text).
Unsituated instruction conveys general abstract knowledge applied
large number different situations. general-purpose knowledge often described
\declarative" (Singley & Anderson, 1989). example, physics class, students
taught F = a; general equation applies specific ways great variety
situations. advantage unsituated instruction precisely ability compactly
communicate abstract knowledge broadly applicable (Sandberg & Wielinga, 1991).
313

fiHuffman & Laird

However, use abstract knowledge, students must learn applies specific
situations (Singley & Anderson, 1989).

9.2 Limitations Agent

agent's inherent limitations constrain taught. developed
theory learning tutorial instruction within particular computational model
agents (the PSCM), within computational model, implemented agent
particular set capabilities demonstrate theory. Thus, weaknesses
computational model specific implemented agent must examined.
9.2.1 Computational Model

problem space computational model well suited situated instruction
elements' close correspondence knowledge level (facilitating mapping
instructions elements), inherently local control structure. However,
PSCM's local application knowledge makes dicult learn global control regimes
instruction, must translated series local decisions
result local learning.
second weakness PSCM provides theory functional types
knowledge used intelligent agent, gives indication possible content
knowledge. content theory knowledge would allow finer grained analysis
agent's instructability, within larger-grained knowledge types analysis provided
PSCM.
9.2.2 Implemented Agent's Capabilities

Producing definitive agent goal work. Rather, InstructoSoar agent's capabilities developed needed demonstrate instructional learning capabilities. Thus, limited number ways.16 instance,
performs simple actions serially static world. would sucient dynamic
domain ying airplane, multiple goals multiple levels granularity,
involving achievement and/or maintenance conditions environment, may
active (Pearson et al., 1993). Instructo-Soar's procedures implemented
series locally decided steps, precluding instruction containing procedure-wide (i.e., nonlocal) path constraints (e.g., \Go room, don't walk carpeting!").
single agent world, precluding instructions involve cooperation
agents (e.g., two robots carrying couch) instructions require reasoning
agents' potential actions (e.g., \Don't go alley, enemy
may block in.")
agent complete perception (clearly unrealistic real physical domains),
never told look, asked notice feature overlooked. contrast, instruction protocols show human students often told attend
features notice. Instructo-Soar's world noise-free, agent need
16. limitations particular agent implemented here, Soar, used
build powerful agents (e.g., Jones et al., 1993; Pearson et al., 1993).

314

fiFlexibly Instructable Agents

reason receive instruction failed actions. complete perception
noise-free environment, agent explicitly reason uncertainty
perceptions actions, demonstrated handling instructions explicitly
describe uncertain probabalistic outcomes.17 agent also reason time
(as, e.g., Vere Bickmore's (1990) Homer does), cannot taught perform tasks
time-dependent way. keep track states seen actions performs
(other episodic instruction memory), cannot asked \do
before." Similarly, cannot learn procedures defined particular sequence
actions, rather set state conditions achieve. example, cannot taught
dance, dancing result net change external world. Finally, whenever agent know next, asks instruction.
never tries determine solution search weak methods means-ends
analysis. Adding capability would decrease need instruction.
addition agent's capabilities, Instructo-Soar limited solutions
mapping, interaction, transfer problems incomplete various ways.
limitations discussed next.

9.3 Mapping Problem
Instructo-Soar employs straightforward approach mapping instructions

agent's internal language, leaves problems mapping dicult natural language constructions unaddressed. relevant problems include reference resolution, incompleteness, use domain knowledge comprehension. Mapping
even require instruction, interaction resolve referent:
> Grab explosive block.

one that?
> red one.

type interaction supported Instructo-Soar.
addition general linguistic problems, Instructo-Soar makes limited
use semantic information learning new operators. example, first reads
\Move red block left yellow block," creates new operator, make
use semantic information communicated \Move...to left of." complete
agent would try glean information could semantics unfamiliar
command.

9.4 Interaction Problem
agent's shortcomings interaction problem center around three requirements:
(I1) exible initiation instruction, (I2) full exibility knowledge content, (I3)
situation exibility. (I1 ): Instructo-Soar, instruction initiated agent.
17. instruction protocols analyzed, instructions incomplete (missing conditions like
Instructo-Soar learns), rarely described uncertainty explicitly.

315

fiHuffman & Laird

limits instructor's ability drive interaction interrupt agent's actions
instruction: \No! Don't push button!"18
(I2): Instructo-Soar provides exibility commands, instructions
communicate kinds information. Similar notion discourse coherence (Mann
& Thompson, 1988), fully exible tutorable agent needs support instruction event
knowledge coherence; is, instruction event delivering knowledge makes
sense current context. great variety knowledge could relevant
point makes requirement dicult.
(I3): Instructo-Soar provides situation exibility handling implicitly
explicitly situated instructions, hypothetical situations referred within
single instruction. Human tutors often refer one hypothetical situation course
multiple instructions.

9.5 Transfer Problem

work focused primarily transfer problem { producing general learning
tutorial instruction { requirements met. However, inductive
heuristics Instructo-Soar uses powerful.
addition, two transfer problem requirements achieved. First, (T7)
Instructo-Soar yet demonstrated instructional learning coexistence learning knowledge sources. Nothing Instructo-Soar's theory precludes coexistence, however. Learning knowledge sources could invoked possibly
enhanced instruction. instance, instructor might invoke learning observation pointing set objects saying \This tower"; similarly, instruction
containing metaphor could invoke analogical learning. One application instruction
could potentially enhance learning mechanisms within \personal assistant" software
agents learn observing users (e.g., Maes, 1994; Mitchell et al., 1994). Adding
ability learn verbal instructions addition observations would allow users
explicitly train agents situations learning observation alone may
dicult slow.
Second, (T6) Instructo-Soar cannot recover incorrect knowledge leads
either invalid explanations incorrect external performance. incorrect knowledge
may part agent's initial domain theory, may learned faulty
instruction. Inability recover incorrect knowledge precludes instruction general
case exceptions; instance, \Never grasp red blocks," later, \It's ok
grasp ones safety signs them." order avoid learning anything incorrect,
whenever Instructo-Soar attempts induce new knowledge, asks instructor's
verification adding knowledge long-term memory. Human students
ask much verification; appear jump conclusions, alter later
prove incorrect based information.
Rather always verifying knowledge learned, next generation instructable
agents learn reasonable inferences without verification (although may ask
verifications extreme cases). recently produced agent (Pearson &
18. recently added simple interruptability capability new version Instructo-Soar
incorporates recovery incorrect knowledge (Pearson & Huffman, 1995).

316

fiFlexibly Instructable Agents

Huffman, 1995) incorporates current research incremental recovery incorrect
knowledge (Pearson & Laird, 1995). agent learns correct overgeneral knowledge
infers completing explanations instructions. correction process triggered
using overgeneral knowledge results incorrect performance (e.g., action
agent expects succeed not). long run, believe work could push
research incremental theory revision error recovery, instructable agents
taught many types knowledge may need revision.

10. Conclusion

Although much work machine learning aims depth particular kind learning,

Instructo-Soar demonstrates breadth { interaction instructor learn variety

types knowledge { arising one underlying technique. kind breadth
crucial building instructable agent great variety instructions
variety knowledge communicate. instructable agents begin
basic knowledge domain, Instructo-Soar uses analytic, explanationbased approach learn instructions, makes use knowledge.
instructions may either implicitly explicitly situated, Instructo-Soar situates
explanations instruction within situation indicated instruction. Finally,
agent's knowledge often deficient explaining instructions, InstructoSoar employs four different options dealing incomplete explanations, selects
options dynamically depending instructional context.
availability effectiveness, tutorial instruction potentially powerful knowledge source intelligent agents. Instructo-Soar illustrates simple
domain. Realizing instruction's potential fielded applications require linguistically able agents incorporate robust techniques acquiring knowledge
instruction, also refining knowledge needed based performance
instruction.

Acknowledgements
work performed first author graduate student University
Michigan. sponsored NASA/ONR contract NCC 2-517, University
Michigan Predoctoral Fellowship. Thanks Paul Rosenbloom, Randy Jones,
anonymous reviewers helpful comments earlier drafts.

References

Akatsuka, N. (1986). Conditionals discourse-bound. Traugott, E. C. (Ed.),
Conditionals, pp. 333{51. Cambridge Univ. Press, Cambridge.
Alterman, R., Zito-Wolf, R., & Carpenter, T. (1991). Interaction, comprehension,
instruction usage. Journal Learning Sciences, 1 (3&4), 273{318.
Anderson, J. R. (1983). architecture cognition. Harvard University Press, Cambridge,
MA.
317

fiHuffman & Laird

Bergadano, F., & Giordana, A. (1988). knowledge intensive approach concept induction. Proceedings International Conference Machine Learning, pp.
305{317.
Birmingham, W., & Klinker, G. (1993). Knowledge acquisition tools explicit problemsolving methods. Knowledge Engineering Review, 8 (1).
Birmingham, W., & Siewiorek, D. (1989). Automated knowledge acquisition computer
hardware synthesis system. Knowledge Acquisition, 1, 321{340.
Bloom, B. S. (1984). 2 sigma problem: search methods group instruction
effective one-to-one tutoring. Educational Researcher, 13 (6), 4{16.
Brachman, R. J. (1980). introduction KL-ONE. Brachman, R. J. (Ed.), Research
Natural Language Understanding, pp. 13{46. Bolt, Beranek Newman Inc.,
Cambridge, MA.
Carbonell, J. G., & Gil, Y. (1987). Learning experimentation. Proceedings
International Workshop Machine Learning, pp. 256{265.
Carbonell, J. G., Michalski, R. S., & Mitchell, T. M. (1983). overview machine
learning. Michalski, R. S., Carbonell, J. G., & Mitchell, T. M. (Eds.), Machine
Learning: artificial intelligence approach. Morgan Kaufmann.
Carpenter, T., & Alterman, R. (1994). reading agent. Proceedings Twelfth
National Conference Artificial Intelligence Seattle, WA.
Chapman, D. (1990). Vision, Instruction, Action. Ph.D. thesis, Massachusetts Institute
Technology, Artificial Intelligence Laboratory.
Chi, M. T. H., Bassok, M., Lewis, M. W., Reimann, P., & Glaser, R. (1989). Selfexplanations: students study use examples learning solve problems.
Cognitive Science, 13, 145{182.
Cypher, A. (Ed.). (1993). Watch do: Programming demonstration. MIT Press,
Cambridge, Mass.
Davis, R. (1979). Interactive transfer expertise: Acquisition new inference rules.
Artificial Intelligence, 12 (2), 409{427.
DeJong, G. F., & Mooney, R. J. (1986). Explanation-based learning: alternative view.
Machine Learning, 1 (2), 145{176.
Dent, L., Boticario, J., McDermott, J., Mitchell, T., & Zabowski, D. (1992). personal
learning apprentice. Proceedings International Joint Conference Artificial
Intelligence.
DiEugenio, B. (1993). Understanding natural language instructions: computational approach purpose clauses. Ph.D. thesis, University Pennsylvania. IRCS Report
93-52.
318

fiFlexibly Instructable Agents

DiEugenio, B., & Webber, B. (1992). Plan recognition understanding instructions.
Hendler, J. (Ed.), Proceedings First International Conference Artificial Intelligence Planning Systems, pp. 52{61 College Park, MD.
Donoho, S. K., & Wilkins, D. C. (1994). Exploiting ordering observed problem-solving
steps knowledge ase refinement: apprenticeship approach. Proceedings
12th National Conference Artifical Intelligence Seattle, WA.
Drummond, M. (1989). Situated control rules. Proceedings First International Conference Principles Knowledge Representation Toronto, Canada. Morgan Kaufmann.
Emihovich, C., & Miller, G. E. (1988). Talking turtle: discourse analysis Logo
instruction. Discourse Processes, 11, 183{201.
Eshelman, L., Ehret, D., McDermott, J., & Tan, M. (1987). MOLE: tenacious knowledgeacquisition tool. International Journal Man-Machine Studies, 26 (1), 41{54.
Fikes, R. E., Hart, P. E., & Nilsson, N. J. (1972). Learning executing generalized robot
plans. Artificial Intelligence, 3, 251{288.
Ford, C. A., & Thompson, S. A. (1986). Conditionals discourse: text-based study
English. Traugott, E. C. (Ed.), Conditionals, pp. 353{72. Cambridge
Univ. Press, Cambridge.
Frederking, R. E. (1988). Integrated natural language dialogue: computational model.
Kluwer Academic Press, Boston.
Golding, A., Rosenbloom, P. S., & Laird, J. E. (1987). Learning search control outside
guidance. Proceedings Tenth International Joint Conference Artificial
Intelligence, pp. 334{337.
Grosz, B. J. (1977). Representation use focus dialogue understanding. Ph.D.
thesis, University California, Berkeley.
Gruber, T. (1989). Automated knowledge acquisition strategic knowledge. Machine
Learning, 4 (3-4), 293{336.
Guha, R. V., & Lenat, D. B. (1990). Cyc: mid-term report. AI Magazine, 11 (3), 32{59.
Haas, N., & Hendrix, G. G. (1983). Learning told: Acquiring knowledge
information management. Michalski, R. S., Carbonell, J. G., & Mitchell, T. M.
(Eds.), Machine Learning: artificial intelligence approach. Morgan Kaufmann.
Haiman, J. (1978). Conditionals topics. Language, 54, 564{89.
Hall, R. J. (1988). Learning failing explain. Machine Learning, 3 (1), 45{77.
Hayes-Roth, F., Klahr, P., & Mostow, D. J. (1981). Advice taking knowledge refinement:
iterative view skill acquisition. Anderson, J. R. (Ed.), Cognitive skills
acquisition, pp. 231{253. Lawrence Erlbaum Associates, Hillsdale, NJ.
319

fiHuffman & Laird

Huffman, S. B. (1994). Instructable autonomous agents. Ph.D. thesis, University Michigan, Dept. Electrical Engineering Computer Science.
Huffman, S. B., & Laird, J. E. (1992). Dimensions complexity learning interactive
instruction. Erickson, J. (Ed.), Proceedings Cooperative Intelligent Robotics
Space III, SPIE Volume 1829.
Huffman, S. B., & Laird, J. E. (1993). Learning procedures interactive natural language instructions. Utgoff, P. (Ed.), Machine Learning: Proceedings Tenth
International Conference.
Huffman, S. B., & Laird, J. E. (1994). Learning highly exible tutorial instruction.
Proceedings 12th National Conference Artificial Intelligence (AAAI-94)
Seattle, WA.
Huffman, S. B., Miller, C. S., & Laird, J. E. (1993). Learning instruction: knowledgelevel capability within unified theory cognition. Proceedings Fifteenth
Annual Conference Cognitive Science Society, pp. 114{119.
Johnson-Laird, P. N. (1986). Conditionals mental models. Traugott, E. C. (Ed.),
Conditionals. Cambridge Univ. Press, Cambridge.
Jones, R. M., Tambe, M., Laird, J. E., & Rosenbloom, P. S. (1993). Intelligent automated agents ight training simulators. Proceedings Third Conference
Computer Generated Forces, pp. 33{42 Orlando, FL.
Just, M. A., & Carpenter, P. A. (1976). Verbal comprehension instructional situations.
Klahr, D. (Ed.), Cognition Instruction. Lawrence Erlbaum Associates, Hillsdale,
NJ.
Kieras, D. E., & Bovair, S. (1984). role mental model learning operate
device. Cognitive Science, 8, 255{273.
Kodratoff, Y., & Tecuci, G. (1987a). DISCIPLE-1: Interactive apprentice system weak
theory fields. Proceedings Tenth International Joint Conference Artificial
Intelligence, pp. 271{273.
Kodratoff, Y., & Tecuci, G. (1987b). Techniques design DISCIPLE learning apprentice. International Journal Expert Systems, 1 (1), 39{66.
Laird, J. E., Congdon, C. B., Altmann, E., & Doorenbos, R. (1993). Soar user's manual,
version 6..
Laird, J. E., Hucka, M., Yager, E. S., & Tuck, C. M. (1990). Correcting extending
domain knowledge using outside guidance. Proceedings Seventh International
Conference Machine Learning.
Laird, J. E., Newell, A., & Rosenbloom, P. S. (1987). Soar: architecture general
intelligence. Artificial Intelligence, 33 (1), 1{64.
320

fiFlexibly Instructable Agents

Laird, J. E., & Rosenbloom, P. S. (1990). Integrating execution, planning, learning
Soar external environments. Proceedings Eighth National Conference
Artificial Intelligence, pp. 1022{1029. AAAI Press.
Lewis, C. (1988). learn why: Analysis-based generalization procedures.
Cognitive Science, 12, 211{256.
Lewis, R. L. (1993). Architecturally-Based Theory Human Sentence Comprehension.
Ph.D. thesis, Carnegie Mellon University, School Computer Science.
Lewis, R. L., Newell, A., & Polk, T. A. (1989). Toward Soar theory taking instructions immediate reasoning tasks. Proceedings Annual Conference
Cognitive Science Society.
Lindsay, R. K. (1963). Inferential memory basis machines understand natural
language. Feigenbaum, E. A., & Feldman, J. (Eds.), Computers Thought, pp.
217{233. R. Oldenbourg KG.
Maes, P. (1994). Agents reduce work information overload. Communications
ACM, 37 (7).
Maes, P., & Kozierok, R. (1993). Learning interface agents. Proceedings National
Conference Artificial Intelligence, pp. 459{465.
Mann, W. C., & Thompson, S. A. (1988). Rhetorical structure theory: Toward functional
theory text organization. Text, 8 (3), 243{281.
Marcus, S., & McDermott, J. (1989). SALT: knowledge acquisition language proposeand-revise systems. Artificial Intelligence, 39 (1), 1{37.
Martin, C. E., & Firby, R. J. (1991). Generating natural language expectations
reactive execution system. Proceedings Thirteenth Annual Conference
Cognitive Science Society, pp. 811{815.
McCarthy, J. (1968). advice taker. Minsky, M. (Ed.), Semantic Information Processing, pp. 403{410. MIT Press, Cambridge, Mass.
Miller, C. M. (1993). model concept acquisition context unified theory
cognition. Ph.D. thesis, University Michigan, Dept. Computer Science
Electrical Engineering.
Minton, S., Carbonell, J. G., Knoblock, C. A., Kuokka, D. R., Etzioni, O., & Gil, Y. (1989).
Explanation-based learning: problem-solving perspective. Artificial Intelligence, 40,
63{118.
Mitchell, T., Caruana, R., Freitag, D., McDermott, J., & Zabowski, D. (1994). Experience
learning personal assistant. Communications ACM, 37 (7).
Mitchell, T. M., Keller, R. M., & Kedar-Cabelli, S. T. (1986). Explanation-based generalization: unifying view. Machine Learning, 1.
321

fiHuffman & Laird

Mitchell, T. M., Mahadevan, S., & Steinberg, L. I. (1990). LEAP: learning apprentice
system VLSI design. Kodratoff, Y., & Michalski, R. S. (Eds.), Machine Learning:
artificial intelligence approach, Vol. III. Morgan Kaufmann.
Mooney, R. J. (1990). Learning plan schemata observation: Explanation-based learning plan recognition. Cognitive Science, 14, 483{509.
Mostow, D. J. (1983). Learning told: Machine transformation advice
heuristic search procedure. Michalski, R. S., Carbonell, J. G., & Mitchell, T. M.
(Eds.), Machine Learning: artificial intelligence approach. Morgan Kaufmann.
Musen, M. A. (1989). Automated support building extending expert models. Machine Learning, 4 (3-4), 347{376.
Newell, A. (1981). knowledge level. AI Magazine, 2 (2), 1{20.
Newell, A. (1990). Unified Theories Cognition. Harvard University Press, Cambridge,
Massachusetts.
Newell, A., Yost, G., Laird, J. E., Rosenbloom, P. S., & Altmann, E. (1990). Formulating
problem space computational model. Proceedings 25th Anniversary
Symposium, School Computer Science, Carnegie Mellon University.
Pazzani, M. (1991a). computational theory learning causal relationships. Cognitive
Science, 15, 401{424.
Pazzani, M. (1991b). Learning predict explain: integration similarity-based,
theory driven, explanation-based learning. Journal Learning Sciences, 1 (2),
153{199.
Pearson, D. J., & Huffman, S. B. (1995). Combining learning instruction recovery
incorrect knowledge. Gordon, D., & Shavlik, J. (Eds.), Proceedings 1995
Machine Learning Workshop Agents Learn Agents.
Pearson, D. J., Huffman, S. B., Willis, M. B., Laird, J. E., & Jones, R. M. (1993).
symbolic solution intelligent real-time control. IEEE Robotics Autonomous
Systems, 11, 279{291.
Pearson, D. J., & Laird, J. E. (1995). Toward incremental knowledge correction agents
complex environments. Muggleton, S., Michie, D., & Furukawa, K. (Eds.), Machine
Intelligence, Vol. 15. Oxford University Press.
Porter, B. W., Bareiss, R., & Holte, R. C. (1990). Concept learning heuristic classification weak-theory domains. Artificial Intelligence, 45 (3), 229{263.
Porter, B. W., & Kibler, D. F. (1986). Experimental goal regression: method learning
problem-solving heuristics. Machine Learning, 1, 249{286.
Redmond, M. A. (1992). Learning observing understanding expert problem solving.
Ph.D. thesis, Georgia Institute Technology.
322

fiFlexibly Instructable Agents

Rosenbloom, P. S., & Aasman, J. (1990). Knowledge level inductive uses chunking
(EBL). Proceedings National Conference Artificial Intelligence.
Rosenbloom, P. S., & Laird, J. E. (1986). Mapping explanation-based generalization onto
Soar. Proceedings National Conference Artificial Intelligence, pp. 561{567.
Rosenbloom, P. S., Laird, J. E., & Newell, A. (1988). chunking skill knowledge.
Bouma, H., & Elsendoorn, A. G. (Eds.), Working Models Human Perception,
pp. 391{410. Academic Press, London, England.
Rosenbloom, P. S., Laird, J. E., & Newell, A. (Eds.). (1993a). Soar Papers: Research
integrated intelligence. MIT Press, Cambridge, Mass.
Rosenbloom, P. S., Laird, J. E., & Newell, A. (Eds.). (1993b). Soar Papers: Research
integrated intelligence. MIT Press, Cambridge, Mass.
Rosenbloom, P. S., & Newell, A. (1986). chunking goal hierarchies: generalized
model practice. Michalski, R. S., Carbonell, J. G., & Mitchell, T. M. (Eds.),
Machine Learning: artificial intelligence approach, Volume II. Morgan Kaufmann.
Rumelhart, D. E., & McClelland, J. L. (Eds.). (1986). Parallel distributed processing: Explorations microstructure cognition. MIT Press, Cambridge, MA.
Rychener, M. D. (1983). instructible production system: retrospective analysis.
Michalski, R. S., Carbonell, J. G., & Mitchell, T. M. (Eds.), Machine Learning:
artificial intelligence approach, pp. 429{460. Morgan Kaufmann.
Sandberg, J., & Wielinga, B. (1991). situated cognition?. Proceedings
International Joint Conference Artificial Intelligence, pp. 341{346.
Schank, R. C. (1975). Conceptual Information Processing. American Elsevier, New York.
Schank, R. C., & Leake, D. B. (1989). Creativity learning case-based explainer.
Artificial Intelligence, 40, 353{385.
Segre, A. M. (1987). learning apprentice system mechanical assembly. Third IEEE
Conference Artificial Intelligence Applications, pp. 112{117.
Shen, W. (1993). Discovery autonomous learning environment. Machine Learning, 12, 143{165.
Simon, H. A. (1977). Artificial intelligence systems understand. Proceedings
Fifth International Joint Conference Artificial Intelligence, pp. 1059{1073.
Simon, H. A., & Hayes, J. R. (1976). Understanding complex task instructions. Klahr,
D. (Ed.), Cognition Instruction. Lawrence Erlbaum Associates, Hillsdale, NJ.
Singley, M. K., & Anderson, J. R. (1989). transfer cognitive skill. Harvard University
Press.
323

fiHuffman & Laird

Sutton, R. S., & Pinette, B. (1985). learning world models connectionist networks.
Proceedings Seventh Annual Conference Cognitive Science Society, pp.
54{64.
Thrun, S. B., & Mitchell, T. M. (1993). Integrating inductive neural network learning
explanation-based learning. Proceedings International Joint Conference
Artificial Intelligence, pp. 930{936.
VanLehn, K. (1987). Learning one subprocedure per lesson. Artificial Intelligence, 31 (1),
1{40.
VanLehn, K., Ball, W., & Kowalski, B. (1990). Explanation-based learning correctness:
Towards model self-explanation effect. Proceedings 12th Annual
Conference Cognitive Science Society, pp. 717{724.
VanLehn, K., & Jones, R. (1991). Learning physics via explanation-based learning correctness analogical search control. Proceedings International Machine
Learning Workshop.
VanLehn, K., Jones, R. M., & Chi, M. T. H. (1992). model self-explanation effect.
Journal Learning Sciences, 2 (1), 1{59.
Vere, S., & Bickmore, T. (1990). basic agent. Computational Intelligence, 6, 41{60.
Wertsch, J. V. (1979). social interaction higher psychological processes: clarification application Vygotsky's theory. Human Development, 22, 1{22.
Widmer, G. (1989). tight integration deductive inductive learning. Proceedings
International Workshop Machine Learning, pp. 11{13.
Wilkins, D. C. (1990). Knowledge base refinement improving incomplete incorrect
domain theory. Kodratoff, Y., & Michalski, R. S. (Eds.), Machine Learning:
Artificial Intelligence Approach, Volume III, pp. 493{514. Morgan Kaufmann.
Winograd, T. (1972). Understanding Natural Language. Academic Press, New York.
Wood, D., Bruner, J. S., & Ross, G. (1976). role tutoring problem solving. Journal
Child Psychology Psychiatry, 17, 89{100.
Yost, G. R. (1993). Acquiring knowledge Soar. IEEE Expert, 8 (3), 26{34.
Yost, G. R., & Newell, A. (1989). problem space approach expert system specification.
Proceedings International Joint Conference Artificial Intelligence, pp.
621{7.

324

fiJournal Artificial Intelligence Research 3 (1995) 53-118

Submitted 3/95; published 7/95

Building Refining Abstract Planning Cases
Change Representation Language
Ralph Bergmann
Wolfgang Wilke

bergmann@informatik.uni-kl.de
wilke@informatik.uni-kl.de

Centre Learning Systems Applications (LSA)
University Kaiserslautern, P.O.-Box 3049, D-67653 Kaiserslautern, Germany

Abstract

Abstraction one promising approaches improve performance problem
solvers. several domains abstraction dropping sentences domain description {
used hierarchical planners { proven useful. paper present examples
illustrate significant drawbacks abstraction dropping sentences. overcome
drawbacks, propose general view abstraction involving change
representation language. developed new abstraction methodology related
sound complete learning algorithm allows complete change representation
language planning cases concrete abstract. However, achieve powerful
change representation language, abstract language well rules
describe admissible ways abstracting states must provided domain model.
new abstraction approach core Paris (Plan Abstraction Refinement
Integrated System), system abstract planning cases automatically
learned given concrete cases. empirical study domain process planning
mechanical engineering shows significant advantages proposed reasoning
abstract cases classical hierarchical planning.

1. Introduction
Abstraction one challenging also promising approaches improve complex
problem solving inspired way humans seem solve problems. first, less
relevant details given problem ignored abstracted problem
solved easily. Then, step step, details added solution taking
increasingly detailed look problem. Thereby, abstract solution constructed
first refined towards concrete solution. One typical characteristic work
hierarchical problem solving abstraction mostly performed dropping sentences
domain description (Sacerdoti, 1974, 1977; Tenenberg, 1988; Unruh & Rosenbloom,
1989; Yang & Tenenberg, 1990; Knoblock, 1989, 1994; Bacchus & Yang, 1994). second
common characteristic hierarchical problem solver usually derives abstract
solution scratch, without using experience previous problem solving episodes.
Giunchiglia Walsh (1992) presented comprehensive formal framework
abstraction comparison different abstraction approaches theorem proving
(Plaisted, 1981, 1986; Tenenberg, 1987), planning (Newell & Simon, 1972; Sacerdoti, 1974,
1977; Tenenberg, 1988; Unruh & Rosenbloom, 1989; Yang & Tenenberg, 1990; Knoblock,
1989, 1994), model based diagnosis (Mozetic, 1990). hierarchical planning, Korf's
model abstraction problem solving (Korf, 1987) allows analysis reductions
c 1995 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiBergmann & Wilke

search caused single multiple levels abstraction. shown optimal
case, abstraction reduce expected search time exponential linear. Knoblock
developed approach construct hierarchy abstraction spaces automatically
given concrete-level problem solving domain (Knoblock, 1990, 1993, 1994).
called ordered monotonic abstraction hierarchies (Knoblock, Tenenberg, & Yang, 1991b)
proven useful many domains. Recently, Bacchus Yang (1994) presented
improved method automatically generating abstraction hierarchies based
detailed model search costs.
abstraction methods, however, rely abstraction dropping sentences
domain description kind homomorphic abstraction (Holte et al., 1994,
1995). shown kinds abstractions highly representation dependent (Holte et al., 1994, 1995). two classical planning domains, different \natural\
representations analyzed turns several representations
classical abstraction techniques lead significantly improved problem
solvers (Knoblock, 1994; Holte et al., 1995). However, well known normally many
different representations domain exist already pointed Korf (1980),
theory representation developed. particular,
theory representation hierarchical problem solving dropping sentences.
knowledge-engineering perspective, many different aspects simplicity,
understandability, maintainability must considered developing domain representation. Therefore, assume representations domains given knowledge
engineers rely representations consider \natural" certain kinds
problems. demonstrate two simple example problems related representations,
usual use abstraction problem solving lead improvement.
first example, improvement achieved abstraction restricted
dropping sentences domain. second example, abstract solution computed
scratch decompose original problem consequently cut
search space next detailed level. want argue examples
never represented way standard hierarchical problem solving works well.
However, think would require large effort knowledge engineer develop
appropriate representation believe often impossible develop representation appropriate knowledge-engineering perspective also allows
ecient hierarchical problem solving based dropping sentences.
take observations motivation develop general model abstraction problem solving. already pointed Michalski (1994), abstraction,
general, seen switching completely new representation language
level detail reduced. problem solving, new abstract representation language
must consist completely new sentences operators subset
sentences operators concrete language. knowledge, Sipe (Wilkins, 1988)
planning system currently allows change representation language
across different levels abstraction. However, general abstraction methodology
allows ecient algorithms abstraction refinement yet developed.
want propose method abstraction allows complete change representation language problem solution concrete abstract vice versa,
concrete abstract language given. Additionally, propose use experience
54

fiBuilding Refining Abstract Planning Cases

previously solved problems, usually available set cases, come abstract
solutions. use experience already proven useful various approaches speedup learning explanation-based learning (Mitchell, Keller, & Kedar-Cabelli, 1986;
DeJong & Mooney, 1986; Rosenbloom & Laird, 1986; Minton, 1988; Minton, Carbonell,
Knoblock, Kuokka, Etzioni, & Gil, 1989; Shavlik & O'Rorke, 1993; Etzioni, 1993; Minton
& Zweben, 1993; Langley & Allen, 1993; Kambhampati & Kedar, 1994), analogical
case-based reasoning (Carbonell, 1986; Kambhampati & Hendler, 1992; Veloso & Carbonell,
1993; Veloso, 1994).
main contribution paper, present abstraction methodology
related learning method beneficial abstract planning cases automatically derived
given concrete cases. Based given concrete abstract language, learning
approach allows complete change representation case concrete
abstract level. However, achieve unconstrained kind abstraction,
set admissible abstractions must implicitly predefined generic abstraction theory.
Compared approaches abstraction hierarchies generated automatically,
effort required specify abstract language, feel price
pay make planning tractable certain situations.
approach fully implemented Paris (Plan Abstraction Refinement
Integrated System), system abstract cases learned organized case
base. novel problem solving, case-base searched suitable abstract case
refined concrete solution current problem.
presentation approach organized follows. next section presents
analysis hierarchical problem solving shortcomings current approaches
illustrated simple examples. Section three argues powerful case abstraction
refinement method overcome identified problems. Furthermore, present
Paris approach informally, using simple example. next three sections paper
formalize general abstraction approach. introducing basic terminology, Section 5 defines new formal model case abstraction. Section 6 contains detailed
description correct complete learning algorithm case abstraction. Section 7
explains refinement cases solving new problems. Section 8 gives detailed description domain process planning mechanical engineering production
rotary-symmetric workpieces lathe demonstrates proposed approach examples domain. Section 9 reports detailed experimental evaluation Paris
described domain. Finally, discuss presented approach relation similar
work field. appendix article contains formal proofs properties
abstraction approach related learning algorithm. Additionally, detailed
representation mechanical engineering domain used experimental evaluation
given Online Appendix 1.

2. Analysis Hierarchical Problem Solving
basic intuition behind abstraction follows. first ignoring less relevant features
problem description, abstraction allows problems solved coarse fashion
less effort. Then, derived abstract (skeletal) solution serves problem decomposition
original, detailed problem. Korf (1987) shown hierarchical problem
55

fiBergmann & Wilke

solving reduce required search space significantly. Assume problem requires
solution length n furthermore assume average branching factor b,
i.e., average number states reached given state applying
single operator. worst-case time complexity finding required solution search
O(bn ). Now, suppose problem decomposed abstract solution
k subproblems, require solution length n1; : : : ; nk , respectively,
n1 + n2 + + nk = n. situation, worst-case time complexity finding
complete solution O(bn1 + bn2 + + bnk ) O(bmax(n1;n2 ;:::;nk ) ). Please note
significant reduction search time complexity. particular, easily see
reduction maximal subproblems similar size, i.e., n1 n2 nk .
However, achieve significant search reduction, computed abstract solution must
solution abstracted problem, must additionally fulfill certain
requirement presupposed analysis. subproblems introduced abstract
solution must independent, i.e., must solvable without interaction
subproblems. avoids backtracking solution subproblem
consequently cuts necessary overall search space. Even restriction
completely fulfilled, i.e., backtracking still required cases, several empirical studies
(especially Knoblock, 1991, 1993, 1994) shown abstraction nevertheless lead
performance improvements.
Unfortunately, also domains representations domains (Holte et al., 1994,
1995) way abstraction used hierarchical problem solving cannot improve
problem solving derived abstract solutions don't fulfill mentioned
requirement all. following, show two examples domains
demonstrate two general drawbacks hierarchical problem solving. Please note
examples, particular representation assumed. feel representations
somehow \natural" likely used knowledge engineer developing domain. However, might representations domains traditional
hierarchical planning works. assume representations dicult find,
especially domain representation also fulfill additional knowledge-engineering
requirements.

2.1 Abstraction Dropping Sentences

hierarchical problem solving, abstraction mostly1 achieved dropping sentences
problem description preconditions and/or effects operators (Sacerdoti, 1974,
1977; Tenenberg, 1988; Unruh & Rosenbloom, 1989; Yang & Tenenberg, 1990; Knoblock,
1989, 1994). assumption justifies kind abstraction less relevant
details problem description expressed isolated sentences representation
addressed relevant sentences established. Ignoring
sentences assumed lead abstract solution useful reduce search
concrete planning levels.
However, assumption hold domains. example, many real world
domains, certain events need counted, e.g., transporting certain number
1. Tenenberg's (1988) abstraction analogical mappings planning system Sipe (Wilkins,
1988) contains first approaches allow change representation language.

56

fiBuilding Refining Abstract Planning Cases

containers one location another. Imagine domain which, addition several
operators, increment operator described follows:
Operator: inc
Precondition: value(X )
Delete: value(X )
Add: value(X + 1)

representation, integer value increased represented single sentence. state consists single sentence, also operator contains
one single sentence.2 think representation \natural" likely
chosen knowledge engineer. domain, incrementing value(0) value(8)
requires sequential plan composed 8 inc-operators, leading state sequence:
value(0),value(1),: : : ,value(8). example, however, abstraction dropping sentences work because, single sentence would dropped, nothing would remain operator description whole counting problem would dropped
completely. empty problem abstract level, empty plan
going solve it. Unfortunately, empty plan cannot cause complexity reduction
solving problem concrete level. Consequently, abstraction dropping sentences
completely fails improve problem solving situation.
However, adequately cope counting problem abstracting
quantitative value expressed sentence towards qualitative representation (e.g.,
low=f0; 1; 2; 3g, medium = f4; 5; 6; 7g, high = f8; 9; 10; 11g). qualitative representation would result abstract plan composed two operators (subproblems)
increase value low medium high. abstract plan defines two
independently refinable subproblems. solve first subproblem concrete level,
problem solver search sequence inc-operators increment value
0 medium value (any value set f4; 5; 6; 7g). subproblem
solved sequence 4 inc-operators leading concrete state value 4. Similarly, second subproblem concrete level find sequence operators
change value 4 final value 8. Also second subproblem solved
sequence 4 inc-operators. see complete problem requires
sequence 8 concrete operators divided 2 subproblems subproblem
solved 4-step plan. exponential nature search space, two
4-step problems together solved much less search 8-step problem
whole. Following Korf's analysis sketched before, time complexity reduced O(b8)
O(b4)3 . Please note particular abstraction leads two subproblems
central achieving complexity reduction. important point problem
decomposed one subproblem. kind abstraction achieved
introducing new abstract representation language consists qualitative values
corresponding abstract increment operator.
2. However, might assume term X + 1 modeled separate predicate precondition.
Unfortunately, change described situation all.
3. assume many operators besides inc-operator, b 1 holds.

57

fiBergmann & Wilke

even generalize specific example presented above. problem
dropping condition approach possible abstract information (e.g.,
value example) coded single sentence representation.
particularly problem required solution contains long sequence states
differ single sentence. Dropping particular sentence leads dropping
whole problem, dropping sentence lead abstraction.
really required abstract information encoded single sentence obviously
requires dropping complete information.
summarize, seen abstraction dropping sentences work
particular kind problems shown. general, abstraction requires changing complete representation language concrete abstract usually involves
introduction completely new abstract terms (sentences operators). Within
general view, dropping sentences special case abstraction. reason dropping sentences widely used hierarchical planning due simplicity,
refinement easy abstract states directly used goals
detailed levels. Another important property abstraction dropping sentences
useful hierarchies abstraction spaces constructed automatically domain
descriptions (Knoblock, 1990, 1993, 1994; Bacchus & Yang, 1994).

2.2 Generating Abstract Solutions Scratch

Another limiting factor classical hierarchical problem solving way abstract solutions computed. pointed Korf, good abstract solution must lead mostly
independent subproblems equal size. classical problem solving, abstract solution
found breadth-first depth-first search using linear (e.g., Alpine, Knoblock, 1993)
non-linear (e.g., Abtweak, Yang & Tenenberg, 1990) problem solvers. problem solvers, upward-solution property (Tenenberg, 1988) usually holds, means
abstract solution exists concrete-level solution exists. Usually, problem
solvers find arbitrary abstract solution (e.g., shortest possible solution). Unfortunately, way guarantee computed solutions refinable lead
mostly independent subproblems suciently equal size, even solution exists.
general, even heuristics try guide problem solving towards
aspired kind useful abstractions. problem illustrated following example,
additionally shows limitation abstraction dropping sentences.
Imagine large (or even infinite) state space includes least 8 distinct states
shown left Figure 1. 8 states described presence absence
three sentences E 1, E 2, E 3 state description. 3-bit-vector shown Figure
1, "0" indicates absence sentence "1" represents presence sentence.
8 different states described three sentences arranged 3-dimensional
cube, using one dimension sentence. arrows diagram show possible state
transitions available operators domain.4 operator manipulates (adds
deletes) exactly one sentence state description, certain conditions
sentences fulfilled. representation two operators shown right
4. dashed lines represent operators introduced make shape cube
easy see.

58

fiBuilding Refining Abstract Planning Cases

Z

011

111

Two example operators:
010

110

X Z
001

E2

X

000

101

E3
E1

100

O100->101 :
Precondition:
E1
(not E2)
(not E3)

O101->100 :
Precondition:
E1
(not E2)
E3

Add: E3

Delete: E3



Figure 1: State space example domain representation two operators
side figure. subscript operator name relates respective transition
state diagram. general, see

E 1 manipulated, E 2 E 3 holds,
E 2 manipulated, E 1 E 3 holds,
E 3 manipulated, E 1 _ E 2 holds.
Furthermore, assume many operators connect states
domain, shown diagram, 8 depicted states. Consequently,
must assume branching factor b 1 state, makes search space
problem solving quite large. Besides description domain, Figure 1 also shows
three example problems: X ! X 0, ! 0 Z ! Z 0 . example, solution
problem X ! X 0 5-step path 000 ! 010 ! 110 ! 111 ! 101 ! 001.
Now, let's consider abstract solutions correspond concrete solutions
three problems. problem, want examine three possible ways
abstraction dropping one sentences. purpose, geometric arrangement
states turns useful abstraction simply viewed
projecting 3-dimensional state space onto plane defined sentences
dropped abstraction. left part Figure 2 shows three possible abstract
state spaces result dropping one sentences. important
see abstract state space, every sentence modified unconditionally
independent sentences. However, one sentence modified
operator. Thereby, constraints exist concrete level relaxed.
abstraction concrete solution three problems (X ! X 0, ! 0
Z ! Z 0) respect three possible ways dropping conditions shown
59

fiBergmann & Wilke

State spaces
dropping conditions

X->X

Y->Y

E2

4

E2
1

2

1

2
3
E1

2

2

E1
E3

Z->Z

3

1

1

E3
4

3

1

E1
4

E2 2

1
3

2

E2

3

1
3

2
1 E3

2
3

E1

3

1
E3

2

3

Figure 2: Abstract state spaces dropping conditions
right side Figure 2. nine possible abstract solutions consists three
four abstract operators. sequence applied indicated
numbers mark operators. also see whatever sentence
drop problems, appropriate abstract solution exists decomposes
original problem independent refinable subproblems suciently equal size.
main point example none abstract solutions found
hierarchical problem solver! reason abstracted problems
also exists 0-step 1-step solution addition nine 3-step 4-step solutions
indicated depicted paths. However, short solution completely useless
reducing search next concrete level original problem
decomposed all. central problem problem solvers find
shorter useless solutions first, try refine them. Consequently, search
space concrete level reduced performance improvement achieved
all. However, might representations example domain
hierarchical problem solver comes useful abstract solution. think, however,
representation shown quite natural represents 8 different states
minimal number binary sentences.
summarize, presented example useful abstract solution found
hierarchical planning although exists. reason planners usually try
find shortest solutions, good strategy ground level, may
appropriate abstract level. Neither desirable search longest
solutions might cause unnecessarily long concrete plans.

3. Case Abstraction Refinement

way problem, propose use experience given form concrete
planning cases abstract experience reuse new situations. Therefore,
need powerful abstraction methodology allows introduction completely
new abstract terminology abstract level. makes possible useful abstract
solutions expressed domains abstraction dropping conditions
sucient. particular, methodology must serve means analyze
different abstraction approaches, must allow ecient algorithms abstracting
refining problems solutions.
60

fiBuilding Refining Abstract Planning Cases

3.1 Basic Idea
introduce approach achieves case abstraction refinement changing
representation language. prerequisite, approach requires abstract
language (state description operators) given domain expert addition
concrete level description. also require set admissible ways abstracting
states implicitly predefined generic abstraction theory. course additional
knowledge engineering requirement, feel price pay
enhance power hierarchical problem solving. Recent research knowledge acquisition
already describes approaches tools acquisition concrete level abstract level
operators real-world domains (Schmidt & Zickwolff, 1992; Schmidt, 1994). abstract
language given user additional advantage abstracted cases
expressed language user familiar. Consequently, understandability
explainability, always important issues applying system, achieved
easily.
source learning, assume set concrete planning cases,
consists problem statement together related solution. case Prodigy
(Minton et al., 1989), consider sequential plans, i.e., plans totally ordered
operators. planning cases assume include problem solving trace example problem solving cases Prodigy/Analogy (Veloso, 1992; Veloso & Carbonell,
1993; Veloso, 1994). real-world applications, domain expert's solutions previous
problems usually recorded company's filing cabinet database. cases
seen collection company's experience, want draw power.
learning phase, set abstract planning cases generated available
concrete case. abstract planning case consists abstracted problem description
together abstracted solution. case abstraction procedure guarantees
abstract solution contained abstract case always refined become solution
concrete problem contained concrete case became abstracted. Different
abstract cases may situated different levels abstraction may abstractions
according different abstraction aspects. Different abstract cases different utility
reduce search space concrete level different ways. also happen
several concrete cases share abstraction. set abstract planning cases
learned organized case-base ecient retrieval problem solving.
problem solving phase, case base searched abstract case
found applied current problem hand. abstract case applicable
current problem abstracted problem contained abstract planning case
abstraction current problem. However, cannot guarantee abstract
solution contained selected abstract case really refined become solution
current problem. least known abstract solution case base
already useful solving one previous problems, i.e., problems contained
concrete cases abstract case learned. Since new problem
similar previous problems abstracted way,
least high chance abstract solution also useful solving new problem.
new problem solved refinement new concrete case arises
used learning.
61

fiBergmann & Wilke

Learning

PARIS-System

Evaluation/
Indexing

Case Base

Generalization

Abstraction

Problem Solving
Retrieval

Domain Description
Concrete Domain,
Abstract Domain,
Generic Abstraction Theory

New Problem

Specialization

Refinement

Solved Problem

Training Cases

Figure 3: components Paris System

3.2 PARIS Architecture
Paris (Plan Abstraction Refinement Integrated System) follows basic ap-

proach described. Figure 3 shows overview whole system components.
Besides case abstraction refinement, Paris also includes explanation-based approach
generalizing cases learning specializing problem solving. Furthermore, system also includes additional mechanisms evaluating different abstract
cases generalizations derived explanation-based component. evaluation
component measures reduction search time caused abstract plan solving concrete problems case base abstract plan applicable.
Based evaluation, several different indexing retrieval mechanisms developed. retrieval procedures abstract cases preferred caused
reduction search previous problem solving episodes. particular, abstract cases turn useless many concrete problems may even become
completely removed case-base. spectrum developed retrieval approaches
ranges simple sequential search, via hierarchical clustering sophisticated approach balancing hierarchy abstract cases according statistical distribution
cases within problem space evaluated utility. details generalization procedure found (Bergmann, 1992a), evaluation retrieval
mechanisms reported (Bergmann & Wilke, 1994; Wilke, 1994). whole multistrategy system including various interactions described components
topic forthcoming article, first ideas already found (Bergmann, 1992b,
1993). However, target paper concentrate core Paris, namely
approach abstraction refinement.
62

fiBuilding Refining Abstract Planning Cases

State Abstractions
Abstract Plan

A3

011

111

A2
010

110

001

A1

100

A1

A2

A3

A4

000
011
010

110

111

001
101
100

Changing
Representration

101

A4

000

Figure 4: example case abstraction

3.3 Informal Description Abstraction Approach

first give informal description abstraction approach Paris, based
small example shown Figure 1 enhance understanding subsequent formal
sections. Suppose solution problem X ! X 0 available concrete problem solving experience. task learn abstract case beneficially
used solve future problems ! 0 Z ! Z 0 . learning task must
achieved within abstraction approach stronger dropping sentences.
look Figure 4, becomes obvious changing representation single abstract
case learned useful three concrete problems. abstract plan shown
indicates concrete states abstracted towards single abstract state,
single abstract plan exists useful three problems.
3.3.1 Abstract Language Generic Abstraction Theory

achieve kind abstraction, approach requires abstract language (states
operators), well generic abstraction theory provided user. example Figure 4, abstract language must contain new abstract sentences A1 ; : : : ; A4
three abstract operators allow respective state transitions. abstract
operators, called Oai (i 2 f1; : : : ; 3g), defined follows:
Operator: Oai
Precondition: Ai
Delete: Ai
Add: Ai+1

new abstract sentence, user must provide set generic abstraction rules
describe sentence defined terms available sentences con63

fiBergmann & Wilke

crete language. generic abstraction theory defined rules specifies set
admissible state abstractions. example, generic abstraction theory must contain following two rules define new abstract sentence A1 : :E 1 ^ E 2 ! A1
:E 1 ^ :E 2 ^ :E 3 ! A1. general, definition generic abstraction theory
require state abstractions noted explicitly. Abstract states derived
implicitly application combination several rules generic abstraction
theory.
Besides kind abstraction described above, user may also want specify
different type abstraction she/he also considers useful. example,
assume abstraction dropping sentence E 1 also realized. case,
abstract language must contain copy two sentences dropped, i.e.,
sentences E 2 E 3. Therefore, user5 may define two abstract sentences A5
A6 following rules generic abstraction theory: E 2 ! A5 E 3 ! A6.
course, respective abstract operators must also specified.
Since domain expert knowledge engineer must provide abstract language
generic abstraction theory, she/he must already one particular kinds
abstraction mind. She/he must know kind details omitted solving
problem abstract fashion. approach, knowledge-engineer given
power express kind abstraction she/he considers useful.
3.3.2 Model Case Abstraction

Based given abstract language generic abstraction theory, abstraction
planning case formally described two abstraction mappings: state abstraction
mapping sequence abstraction mapping. two mappings describe two dimensions
reducing level detail case. state abstraction mapping reduces level
detail state description changing representation language. case
abstraction indicated Figure 4, state abstraction mapping must map concrete
states 000, 011 010 onto abstract state described new sentence A1,
simultaneously must map concrete states occurring plan onto respective
abstract states described new sentences A2 , A3 , A4 . sequence abstraction
mapping reduces level detail number states considered
abstract level relating concrete states concrete case abstract
states abstract case. concrete states skipped, abstract
state must result particular concrete state. example, Figure 4, abstraction
plan 000 ! 010 ! 110 ! 111 ! 101 ! 001 requires sequence abstraction mapping
relates first abstract state described A1 first concrete state 000,
second abstract state described A2 third concrete state 110, forth.
example, second fifth concrete states skipped.
3.3.3 Learning Abstract Planning Cases

procedure learning abstract planning cases given concrete planning case
decomposed four separate phases. simple example, phases shown
5. Please note abstraction dropping sentences, also consider ALPINE-like algorithm
generates required abstract language generic abstraction theory automatically.

64

fiBuilding Refining Abstract Planning Cases

A5A6

A5

Ca 2
Phase-IV
Ca 1 A1

Oa 1

Phase-III

A2

Oa 2

Oa 3

A3

A4

Oa 3

Oa 2

Oa 1

A6

Oa 1

Oa 3

Phase-II

A1

1 A5

2 A5

3 A5 A6

4 A6

4 A6

Phase-I

000

010

110

111

101

001

Figure 5: four phases case abstraction solution problem X ! X 0
Figure 5. phase-I, states result execution plan contained
concrete case determined. Therefore, operator contained plan (starting
first operator) applied successor state computed. process starts
initial state contained case leads final state, goal state
contained case. phase-II, derive admissible abstractions concrete
state computed first phase. purpose, generic abstraction theory used
determine abstract sentences derived respective concrete state
applying rules generic abstraction theory. Figure 5 shows abstract sentences
derived generic abstraction theory sketched above. example,
see second concrete state abstract description derived contains
two abstract sentences: abstract sentence A1 required achieve type abstraction
shown Figure 4 additionally abstract sentences A5 required abstraction
dropping sentences. Please note process, representation language states
changed concrete abstract. next two phases deal abstract operators.
already stated, abstract operators given abstract language provided
user. However, assume operator abstraction rules associate abstract
operator single concrete operator sequence concrete operators. reason
operator abstraction rules extremely hard acquire even harder
keep complete. next two phases case abstraction, search transitions
abstract states based available abstract operators. phase-III, acyclic directed
graph constructed. edge leads abstract state successor abstract state
j (not necessarily next abstract state), abstract operator applicable state
application leads state j . definition abstract operators
used process. available abstract operators determine transitions
included graph. Figure 5 shows resulting graph, provided abstract
operators sketched Section 3.3.1 contained abstract language. graph
65

fiBergmann & Wilke

transitions shown plain line style result operators Oai , transitions
shown dashed line style result operators required abstraction dropping
conditions.
phase-IV graph searched consistent paths initial abstract state
final abstract state. paths must consistent sense resulting
path (i.e., abstract plan) every abstract operator correctly applicable state
results previous operator. Moreover, state abstraction required
abstract plan must change within plan. Figure 5 two paths kind
shown. lower path represents abstract planning case Ca1 (abstract initial final
state together operator sequence) results kind abstraction shown
Figure 4. upper path represents abstract planning case Ca2 results
abstraction dropping sentence E 1. abstract plan shown Figure
2 problem X ! X 0. Together two plans, abstract state descriptions
result operator application shown. Please note state descriptions
always subset description derived generic abstraction theory.
example, description fourth abstract state derived phase-II, contains
sentences A3 ; A5; A6. abstract state occurs abstract cases computed
phase-IV. case Ca2 , respective state described sentences A5
A6 sentences result application operators
starting abstract initial state. case Ca1, abstract state described
sentence A3 sentence results application operator Oa2.
example see abstract operators two functions. first
function select concrete states become abstracted. example,
abstract case Ca1, second concrete state skipped, even first second
concrete states abstracted different abstract descriptions phase-II. reason
abstract operator a) leads first abstracted state
second abstracted state b) also consistent operators
rest path. second function abstract operators select
abstract sentences considered abstract planning case. example,
abstract case Ca1 , sentences A1 ; : : : ; A4 considered sentences A5 A6
left out. reason abstract operators Oa1 ; Oa2; Oa3 occur
plan don't use A5 A6 precondition don't manipulate sentences.
phase-IV finished, set abstract planning cases available. planning
cases stored case-base used problem solving.
3.3.4 Selecting Refining Abstract Cases

problem solving, abstract case must selected case-base, abstract
plan contained case must refined become solution current problem.
case retrieval must search abstract case applicable, i.e., contains
problem description abstraction current problem. example, assume
problem ! 0 solved case X ! X 0 presented learning.
situation case-base contains two abstract cases Ca1 Ca2 shown phaseIV Figure 5. abstract case Ca1 used solving new problem,
initial state 000 new problem abstracted A1 applying generic
66

fiBuilding Refining Abstract Planning Cases

Selected abstract case:

A1

Defined search spaces:

000

Refined solution:

000

Oa 1

010

A2

Oa 2

A3

?

?

110

111

Oa 3

A4

100

101

100

Figure 6: Refinement abstract case solution problem ! 0
abstraction theory. Similarly, final state 100 abstracted A4 . However,
abstract case Ca2 applicable final abstract state cannot abstracted
A6. Consequently, lower abstract case must used. plan refinement
refine abstract operators sequentially left right shown Figure 6. Thereby
abstract operator defines abstract goal state, i.e., state results
execution operator. example, abstract operator Oa1 defines abstract goal
A2. refine abstract operator, search concrete operator sequence, starting
current concrete state (i.e., initial state first operator), concrete
state reached abstracted desired goal state. state found
used starting state refinement next abstract operator.
solution problem ! 0 , refinement abstract operator Oa1
achieved sequence two concrete operators leading concrete state 110.
concrete state used starting state refine next abstract operator Oa2.
refinement procedure finishes last abstract operator refined way
final concrete state achieved. Please note type refinement operators
used directly, instead sequence states results
execution used. Alternatively, could also stored abstract case sequence
abstracted states. experience, storing sequence operators requires less
space storing sequence states. become obvious looking
domain introduced Section 8. Besides abstract operators play
important role learning phase.

3.4 Relations Skeletal Plans
similar experience-based case-based variant finding abstract solution
found early paper Friedland Iwasaki (1985) concept skeletal
plans introduced. skeletal plan "[...] sequence generalized steps, which,
instantiated specific operations specific problem context solve given problem
[p.161]. [...] Skeletal plans exist many levels generality. general level,
basic plans, used `fall-backs', specific, easier
refine plans cannot found. [p. 164]." Skeletal plans solutions planning problems
different levels detail consequently abstract plans. problem solving
67

fiBergmann & Wilke

recalled library refined towards concrete solution. approach
seen early idea integrating abstraction case-based reasoning. However,
several differences skeletal plan approach Paris approach.
skeletal plan approach model operators (neither concrete abstract) used
describe preconditions effects operators done Paris. explicit
notion states abstraction refinement states. Instead, plan refinement
achieved stepping hierarchy operators, guided heuristic rules operator
selection. particular, approach supports automatic acquisition skeletal
plans provided. Unfortunately, skeletal plan approach yet investigated
much detail current work field speedup-learning. neither formal
model skeletal planning empirical evaluations.
rest paper introduce investigate Paris approach
formally.

4. Basic Terminology
section want introduce basic formal terminology used throughout rest
paper. Therefore define formal representation problem solving domains.
want assume problem solving general viewed transforming initial
state final state using sequence operators (Newell & Simon, 1972). Following
Strips-oriented representation (Fikes & Nilsson, 1971), domain problem solving
= hL; E ; O; Ri described first-order language6 L, set essential atomic sentences
E L (Lifschitz, 1987), set operators related descriptions, additionally,
set rules (Horn clauses) R L. essential sentences (which must atomic)
sentences used describe state. state 2 describes dynamic
part situation domain consists finite subset ground instances essential
sentences E . symbol , denote set possible states descriptions
domain, defined = 2E , E = fe je 2 E substitution
e groundg. addition, Horn clauses R allow representation static properties
true situations. Horn clauses must contain essential sentence
head clause.
operator o(x1; : : : ; xn) 2 described triple hPreo ; Addo; Deloi,
precondition Preo conjunction atoms L, add-list Addo deletelist Delo finite sets (possibly instantiated) essential sentences E . Furthermore,
variables occuring operator descriptions must follow following restrictions:
fx1; : : : ; xng V ar(Preo) V ar(Delo) fx1; : : : ; xng V ar(Addo).7
instantiated operator expression form o(t1; : : : ; tn ), ti ground
terms L. term ti describes instantiation variable xi operator description. notational convenience define instantiated precondition well instantiated add-list delete-list instantiated operator follows: Preo(t1 ;:::;tn ) := Preo ,
Addo(t1;:::;tn) := fa ja 2 Addog, Delo(t1;:::;tn) := fd jd 2 Delo g, hPreo ; Addo; Deloi
6. basic language first order, deductive rules given Horn logic subset
full first-order language used.
7. restrictions however relaxed fx1 ; : : : ; xn g V ar(Preo ) required.
introduced restriction simplifies subsequent presentation.

68

fiBuilding Refining Abstract Planning Cases

description (uninstantiated) operator o(x1; : : : ; xn), = fx1 =t1 ; : : : ; xn =tn g
corresponding instantiation.
instantiated operator applicable state s, [ R ` Pre
holds.8

instantiated operator transforms state s1 state s2 (we write: s1 ,! s2 )
applicable s1 s2 = (s1 n Delo ) [ Addo . problem description p = hsI ; sG
consists initial state sI together final state sG . problem solving task
find sequence instantiated operators (a plan) = (o1; : : : ; ol ) transforms
ol
o1
initial state final state (sI ,!
,!
sG ). case C = hp; oi problem
description p together plan solves p.
introduced Strips-oriented formalism defining problem solving domain
similar form expressiveness representations typically used general problem
solving planning. state described finite set ground atoms
functions also used. Full Horn logic available describe static rules. restriction Horn clauses advantage powerful allowing ecient proof
construction using well known SLD-refutation procedures (Lloyd, 1984). Compared
Prodigy Description Language (PDL) (Minton, 1988; Blythe et al., 1992) language provide explicit quantification specific syntactic construct, similar
expressiveness reached implicit quantification Horn clauses. Moreover,
language provide kind type specification constants variables
PDL think major disadvantage. Besides points language
quite similar PDL.

5. Formal Model Case Abstraction
section present new formal model case abstraction provides theory
changing representation language case concrete abstract. already
stated assume addition concrete language abstract language supplied
domain expert. Following introduced formalism, assume concrete level
problem solving defined concrete problem solving domain Dc = hLc ; Ec; Oc ; Rci
abstract level (case-based) problem solving represented abstract problem solving domain Da = hLa ; Ea; Oa; Rai. reasons simplicity, assume
domains share symbols9 . condition always achieved renaming symbols. remainder paper states operators concrete
domain denoted sc oc respectively, states operators abstract
domain denoted sa oa respectively. problem case abstraction
described transforming case concrete domain Dc case abstract
domain Da (see Figure 7). transformation formally decomposed two
independent mappings: state abstraction mapping ff, sequence abstraction mapping
fi (Bergmann, 1992c). state abstraction mapping transforms selection concrete
state descriptions occur solution problem abstract state descriptions,
8. following, simply omit parameters operators instantiated operators case
unambiguous relevant.
9. Otherwise, symbol (or sentence) could become ambiguous would problem applying
generic abstraction theory. would unclear whether generic abstraction rule refers concrete
abstract sentence

69

fiBergmann & Wilke

abstract
domain:

Da


O1



s0

1a


concrete
domain:

Dc

c0


O2


Oj

ja


Oc1

(0) = 0

c1

Oc2

c

s2

Oc3

c

s3
(1) = 3


j+1


Om

Oci+1

Ocn


Oc4

Oci

ci
(j) =



cn
(m) = n

Figure 7: General idea abstraction
sequence abstraction mapping specifies concrete states mapped
skipped.

5.1 State Abstraction

state abstraction mapping translates states concrete world abstract world.
Definition 1 (State Abstraction Mapping) state abstraction mapping ff : Sc ! Sa
mapping Sc , set states concrete domain, Sa, set states
abstract domain. particular, ff must effective total function.
general definition state abstraction mapping impose restrictions
kind abstraction besides fact mapping must total many-toone function. However, restrict set possible state abstractions set
abstractions user considers useful, assume additional domain knowledge
abstract state relates concrete state provided. knowledge
must expressed terms domain specific generic abstraction theory (Giordana,
Roverso, & Saitta, 1991).

Definition 2 (Generic Abstraction Theory) generic abstraction theory set Horn
clauses form ea a1 ; : : : ; ak . rules ea abstract essential sentence,
i.e., ea = Ea Ea 2 Ea substitution . body generic abstraction rule
consists set sentences concrete abstract language, i.e., ai atoms
Lc [ La .
Based generic abstraction theory, restrict set possible state abstraction
mappings deductively justified generic abstraction theory.

Definition 3 (Deductively Justified State Abstraction Mapping) state abstraction mapping ff deductively justified generic abstraction theory A, following conditions
hold sc 2 Sc :
2 ff(sc ) sc [ Rc [ `
2 ff(sc ) s~c s~c [ Rc [ ` holds, 2 ff(~sc ) also fulfilled.
70

fiBuilding Refining Abstract Planning Cases

definition first condition assures every abstract sentence reached
mapping justified abstraction theory. Additionally, second requirement
guarantees abstract sentence used describe abstraction one state,
must also used describe abstraction states, abstract sentence
derived generic abstraction theory. Please note deductively justified state
abstraction mapping completely induced set ff Ea respect generic
abstraction theory follows: ff(sc ) := f 2 ff jsc [ Rc [ ` g. Unless otherwise stated
always assume deductively justified state abstraction mappings. summarize,
state abstraction mapping transforms concrete state description abstract state
description thereby changes representation state concrete abstract.
Please note deductively justified state abstraction mappings need defined
user. determined automatically learning algorithm
presented Section 6.

5.2 Sequence Abstraction

solution problem consists sequence operators corresponding sequence
states. relate abstract solution concrete solution, relationship
abstract states (or operators) concrete states (or operators) must captured.
abstract state must corresponding concrete state every concrete state
must associated abstract state. due fact abstraction always
reduction level detail (Michalski & Kodratoff, 1990), situation, reduction
number states. selection concrete states corresponding
abstraction, sequence abstraction mapping defined follows:

Definition 4 (Sequence Abstraction Mapping) sequence abstraction mapping fi : N ! N

relates abstract state sequence (sa0 ; : : : ; sam ) concrete state sequence (sc0; : : : ; scn )
mapping indices j 2 f1; : : : ; mg abstract states saj indices 2 f1; : : : ; ng
concrete states sci , following properties hold:

fi(0) = 0 fi(m) = n: initial state goal state abstract sequence

must correspond initial goal state respective concrete state sequence.

fi(u) < fi(v) u < v: order states defined concrete
state sequence must maintained abstract state sequence.

Note defined sequence abstraction mapping formally maps indices abstract
domain concrete domain. abstraction mapping better map indices
concrete domain indices abstract domain, inverse mapping
fi ,1 does. However, mapping inconvenient handle formally since
range definition fi ,1 must always considered. Therefore stick presented
definition.

5.3 Case Abstraction

Based two abstraction functions introduced, intuition case abstraction
captured following definition.
71

fiBergmann & Wilke

Hierarchies abstraction spaces
Dl
Different kinds abstractions
D2

Da
Da1
Dc

Da

D1

Da2
D0

D0

Dc

Figure 8: Different kinds abstractions (a) abstraction hierarchies (b)

Definition 5 (Case Abstraction) case Ca = hhsa0 ; sami; (oa1; : : : ; oam)i abstraction
case Cc = hhsc0; scn i; (oc1; : : : ; ocn)i respect domain descriptions (Dc ; Da)
oaj
oci c
sci,1 ,!
si 2 f1; : : : ; ng saj,1 ,!
sj j 2 f1; : : : ; mg
exists state abstraction mapping ff sequence abstraction mapping fi , that:
saj = ff(scfi(j)) holds j 2 f0; : : : ; mg.

definition case abstraction demonstrated Figure 7. concrete space shows
sequence n operations together resulting state sequence. Selected states
mapped ff states abstract space. mapping fi maps indices
abstract states back corresponding concrete states.

5.4 Generality Case Abstraction Methodology

following, brie discuss generality presented case abstraction methodology. see hierarchies abstraction spaces well different kinds abstractions represented simultaneously using presented methodology.
5.4.1 Different kinds Abstractions

general, one possible abstraction object world.
Abstraction performed many different ways. example two different abstractions case already shown example Figure 5. example,
two different abstractions (see abstract cases Ca1 Ca2) derived
concrete case. abstraction methodology able cope different abstractions
case specified user. Assume given one concrete domain Dc
two different abstract domains Da1 Da2 , represents two different kinds
abstraction. Furthermore, assume abstract domains share
symbols10 . always define single abstract domain Da joining individual
abstract domains includes kinds abstractions (see Figure 8 (a)).
property formally captured following simple lemma.
10. abstract domains disjoint, symbols simply renamed achieve property.

72

fiBuilding Refining Abstract Planning Cases

Lemma 6 (Joining different abstractions) concrete domain Dc two disjoint abstract domains Da1 Da2 given, joint abstract domain Da = Da1 [ Da2
defined follows: Let Da1 = (La1; Ea1; Oa1; Ra1) let Da2 = (La2; Ea2; Oa2; Ra2).
Da = Da1 [ Da2 = (La1 [ La2 ; Ea1 [ Ea2 ; Oa1 [ Oa2 ; Ra1 [ Ra2). joint abstract domain
Da fulfills following property: Ca abstraction Cc respect (Dc, Da1)
respect (Dc , Da2), Ca also abstraction Cc respect (Dc ; Da).
5.4.2 Hierarchy Abstraction Spaces

work hierarchical problem solving assume multi-level hierarchy abstraction
spaces problem solving (e.g., Sacerdoti, 1974; Knoblock, 1989). Even presented
approach contains two domain descriptions, hierarchy abstract domains simply
mapped onto presented two-level model shown Figure 8 (b). Assume
hierarchy disjoint domain descriptions (D0; : : : ; Dl) given. particular, domain
D+1 assumed abstract domain . multi-level hierarchy
abstraction spaces, case C abstraction level abstraction case C0,
exists sequence cases (C1 ; : : : ; C ,1 ) Ci domain Di Ci+1
abstraction Ci respect (Di ; Di+1) 2 f0; : : : ; , 1g. multilevel hierarchy domain descriptions always reduced two-level description.
abstract domain two-level description contains union levels
multi-level hierarchy. property formally captured following lemma.

Lemma 7 (Multi-Level Hierarchy) Let (D0; : : : ; Dl) arbitrary multi-level
hierarchy

l
domain descriptions. two-level description (Dc , Da ) Da = =1
Dc = D0 holds that: Ca abstraction Cc respect (D0; : : : ; Dl) Ca
also abstraction Cc respect (Dc , Da ).
Since shown different kinds abstractions well hierarchies abstraction spaces directly represented within two-level case abstraction methodology,
restrict exactly two levels.

6. Computing Case Abstractions

present Pabs algorithm (Bergmann, 1992c; Wilke, 1993) automatically
learning set abstract cases given concrete case. Thereby, assume
concrete domain Dc abstract domain Da given together generic abstraction
theory A. use functional notation Ca 2 PABS(hDc ; Da; Ai; Cc) denote Ca
element set abstract cases returned Pabs algorithm.
algorithm consists four separate phases introduced Section 3.
following present phases detail.
first three phases, require procedure determining whether conjunctive
formula consequence set Horn clauses. purpose, use SLD-refutation
procedure (Lloyd, 1984) given set Horn clauses (a logic program) C together
conjunctive formula G (a goal clause). refutation procedure determines set
answer substitutions
C ` G holds 2
. write
= SLD(C; G).
SLD-refutation procedure performs kind backward-chaining works
73

fiBergmann & Wilke

follows. selects literal goal clause G (i.e., left literal) searches
Horn clause logic program C contains literal head unifies
selected goal literal. selected literal removed G body (if empty)
applied clause added beginning goal clause. general
unifier goal literal head clause applied whole new goal clause.
resulting goal clause called resolvent. process continues goal clause
becomes empty resolvents built. former case, goal
proven answer substitution computed composing substitutions used
resolution. Backtracking used look possible selections applicable
Horn rules determine alternative answer substitutions. set answer substitutions
returned set
. whole space possible applications available Horn rules
searched unsuccessfully, goal clause consequence logic program
C SLD-refutation procedure terminates without answer substitution (
= ;).
must confused situation empty substitution returned
(
= f;g), variables occur G. phase-III Pabs algorithm, also require
derivation trees addition answer substitutions. write = SLD(C; G)
assume set pairs (; ), answer substitution
derivation C ` G .
order assure termination SLD-refutation procedure require
abstract domain generic abstraction theory designed according
following principles11 :
concrete state sc 2 Sc concrete operator oc 2 Oc oc
described hPreoc ; Addoc ; Deloc i, SLD(sc [ Rc ; Preoc ) must lead finite set
ground substitutions variables occur Preoc .
state abstract sa 2 Sa abstract operator oa 2 Oa oa
described hPreoa ; Addoa ; Deloa i, SLD(sa [ Ra; Preoa ) must lead finite set
ground substitutions variables occur Preoa .
state sc 2 Sc abstract essential sentence E 2 Ea, SLD(sc [Rc [A; E )
must lead finite set ground substitutions variables occur E .
following four phases Pabs algorithm explained detail.

6.1 Phase-I: Computing Concrete State Sequence

input case abstraction algorithm, assume concrete case Cc =
hhscI ; scGi; (oc1; : : : ; ocn)i. Note (oc1; : : : ; ocn) totally ordered sequence instantiated operators similar plans Prodigy (Minton, 1988; Minton et al., 1989; Veloso
& Carbonell, 1993). first phase, state sequence results simulation
problem solution computed follows:

11. first glance, restrictions seem bit hard achieve take closer look see
standard requirement (terminating) logic program (i.e., Prolog program).

74

fiBuilding Refining Abstract Planning Cases

Algorithm 1 (Phase-I: Computing concrete state sequence)
sc0 := scI
:= 1 n
SLD(sci,1 [ Rc; Preoci ) = ; STOP \Failure: Operator applicable"
sci := (sci,1 n Deloci ) [ Addoci

end
scG 6 scn STOP \Failure: Goal state reached"

oc


algorithm, states sci computed, sci,1 ,!
sci holds
2 f1; : : : ; ng. failure occurs given plan valid, i.e., solve given
problem.

6.2 Phase-II: Deriving Abstract Essential Sentences

Using derived concrete state sequence input, following algorithm computes
sequence abstract state descriptions (sai ) applying generic abstraction theory
separately concrete state.

Algorithm 2 (Phase-II: State abstraction)
:= 0 n
sai := ;
E 2 Ea

:= SLD(sci [ Rc [ A; E )
2

sai := sai [ fE g
end
end
end
Please note claimed domain theories designed way

finite contains ground substitution variables E . Therefore, every
description sai consists ground atoms consequently valid abstract state
description. Within introduced model case abstraction computed
superset outcome possible state abstraction mappings. deductively justified
state abstraction mapping ff restricted ff(sci ) sai = fe 2 Sa jsci [ Rc [ ` eg
2 f1; : : : ; ng. Consequently, determined abstract sentences abstract
case might require.

6.3 Phase-III: Computing Possible Abstract State Transitions

next phase algorithm, search instantiated abstract operators
transform abstract state s~ai sai subsequent abstract state s~aj saj (i < j ).
Therefore, preconditions instantiated operator must least fulfilled
state s~ai consequently also sai . Furthermore, added effects operator must
true s~aj consequently also saj .
75

fiBergmann & Wilke

Algorithm 3 (Phase-III: Abstract state transitions)
G := ;
:= 0 n , 1
j := + 1 n
o(x1; : : : ; xu) 2 Oa
let hPreo ; Delo; Addoi description o(x1; : : : ; xu)
:= SLD(sai [ Ra ; Preo)
h; 2
letAdd0o = faja 2 Addog
(* Compute possible instantiations *)
(* added sentences hold saj *)
:= f;g
(* set possible substitutions *)
(* initially empty substitution. *)

2 Add0o
0 := ;
2
e 2 saj
substitution = e 0 := 0 [ fg
end
end
:= 0

end

(* Now, contains set possible substitutions *)
(* added sentences contained saj *)

2
G := G [ fhi; j; o(x1; : : : ; xu ); ig
end
end
end
end
end

set possible operator transitions collected directed edges graph
vertices represent abstract states. algorithm, set G edges acyclic
directed graph constructed. pair states (sai,saj ) < j checked
whether exists operator o(x1; : : : ; xu ) applicable sai . purpose,
SLD-refutation procedure computes set possible answer substitutions
precondition operator fulfilled sai . derivation belongs
answer substitution stored together operator graph since
required next phase case abstraction. derivation \and-tree"
inner-node ects resolution goal literal head clause
leaf-node represents resolution fact. Note proving precondition
abstract operator inner nodes tree always refer clauses Horn rule set
Ra, leave-nodes represent facts stated Ra essential sentences contained
76

fiBuilding Refining Abstract Planning Cases

sai . answer substitution applied add-list operator leading
partially instantiated add-list Add0o. Note still variables Add0o

operator may contain variables contained precondition may
occur add-list. Therefore, set possible substitutions incrementally
constructed 2 saj holds 2 Add0o. completely instantiated operator
derived thereby finally included directed edge (from j ) graph G.
algorithm guaranteed (instantiated) operator leads sai
saj applicable sai essential sentences added operator contained
saj . Furthermore, applied SLD-refutation procedure complete (it always finds
answer substitutions), every instantiated operator applicable sai
essential sentences added operator contained saj also contained
oai
graph. follows immediately ff(scfi (i,1)) ,!
ff(scfi(i) ) holds arbitrary
deductively justified state abstraction mapping ff sequence abstraction mapping fi ,
hfi (i , 1); fi (i); oai; 2 G also holds.

6.4 Phase-IV: Determining Sound Paths

Based state abstractions sai derived phase-II graph G computed
previous phase, phase-IV selects set sound paths initial abstract state
final abstract state. set significant abstract sentences ff sequence abstraction
mapping fi also determined construction path.
Algorithm 4 (Phase-IV: Searching sound paths)12
Paths := fh(); ;; (fi(0) = 0)ig
exists h(oa1; : : : ; oak); ff; fii 2 Paths fi(k) < n
Paths := Paths n h(oa1 ; : : : ; oak ); ff; fii
hi; j; oa; 2 G = fi(k)
let E set essential sentences contained derivation
let ff0 = E [ Addoa [ ff
2 f1; :a: : ; kg holds:

(safi ( ,1) \ ff0 ) ,!
(sfi ( ) \ ff0 )

(sa \ ff0 )
(safi (k) \ ff0 ) ,!
j
Paths := Paths [ fh(oa1 ; : : : ; oak; oa); ff0; fi [ ffi(k + 1) = j gi g

end
end

CasesAbs := ;
h(oa1 ; : : : ; oak); ff; fii 2 Paths fi(k) = n
CasesAbs := CasesAbs [ fhhsa0 \ ff ; san \ ff i; (oa1 ; : : : ; oak)ig

end
return CasesAbs

construction sequence abstraction mapping obvious, set ff represents image state abstraction mapping ff thereby determines set sentences

12. Please note h(oa1 ; : : : ; oak ); ff; fi matches fh(); ;; (fi (0) = 0)ig k = 0. operator n denotes
set difference.

77

fiBergmann & Wilke

reached order assure applicability constructed operator sequence. Note ff state abstraction mapping ff directly determined
follows: ff(sci ) = fe 2 ff jsci [ Rc [ ` eg. idea algorithm start
empty path. path extended operator G iteration algorithm
path leads final state index n. New essential sentences ff0 may
occur proof precondition added effects new operator. path
constructed far must still consistent according extension state description
and, addition, new operator must transform sentences ff correctly.
result, phase-IV returns cases abstractions given concrete input
case respect concrete abstract domain definitions generic abstraction
theory. Depending domain theory, single abstract case learned
single concrete case already shown Figure 5.

6.5 Correctness Completeness PABS Algorithm

Finally, want state strong connection formal model case
abstraction presented algorithm. algorithm terminates domain descriptions generic abstraction theory formulated required beginning
section, SLD-resolution procedure always terminates. algorithm correct,
every abstract case computed Pabs algorithm case abstraction according
introduced model. SLD-refutation procedure applied Pabs complete every
case abstraction according Definition 5 returned Pabs. property
captured following theorem.

Theorem 8 (Correctness completeness PABS algorithm) complete SLDrefutation procedure used Pabs algorithm, Case Ca abstraction case Cc
respect (Dc ; Da) generic theory A, Ca 2 PABS(hDc ; Da; Ai; Cc).

6.6 Complexity Algorithm

complexity algorithm mainly determined phases III IV. worst
case complexity phase-III O(n2 C1 C2) n length concrete plan
C1 C2 dependent domain theories follows: C1 = jOa j j
j C2 =
jAddOa j (jEajj
j)jAddOaj. Thereby, jOaj represents number abstract operators, j
j
maximum number substitutions found SLD-refutation procedure, jAddOa j
maximum number added sentences abstract operator, jEaj number
abstract essential sentences. complexity phase-IV determined O(n 2(n,1)
C1). assume constant domain theories overall complexity Pabs algorithm
summarized O(n 2(n,1) ). exponential factor comes possibly exponential
number paths directed acyclic graph n nodes every state connected
every successor state. Whether graph kind appears much dependent
abstract domain theory, determines transitions abstract states
possible. exponential nature lead time complexity problem domains
used. Additionally, want make clear computational effort must
spent learning problem solving. time required learning
long, learning phase executed off-line.
78

fiBuilding Refining Abstract Planning Cases

space complexity algorithm mainly determined phase-III
derivations proofs abstract operators' preconditions must stored.
sum n2 C1 C2 derivations worst case. turn problem
domains used derivation short (in cases
3 inferences static Horn rules). reason derivations relate
abstract operators likely contain less preconditions concrete operators.

7. Refinement Abstract Cases

previous section described abstract cases automatically learned
concrete cases. assume case-base contains set abstract cases.
want show abstract cases used solve problems concrete level.
Furthermore, discuss impact specific form abstract problem solving
domain improvement problem solving achieved.

7.1 Applicability Refinability Abstract Cases

given abstract case concrete problem description, question arises
situations abstract case refined solve concrete problem. kind
refinability a-posterior definition easily given follows.

Definition 9 (Refinability abstract case) abstract case Ca refined solve
concrete problem p exists solution oc p, Ca abstraction
hp; oci.

Obviously, refinability property undecidable general since otherwise planning
would decidable. However, define applicability abstract case
decidable necessary property refinability follows.

Definition 10 (Applicability abstract case) abstract case Ca = hhsa0 ; sami,
(oa1 ; : : : ; oam)i applied solve concrete problem p = hscI ; scG exists state
abstraction mapping ff sai 2 Im(ff) 2 f0; : : : ; mg ff(scI ) = sa0
ff(scG ) = sam . Thereby, Im(ff) denotes image state abstraction mapping ff, i.e.,

abstract states reached.

applicable abstract case, least guaranteed concrete initial goal
states map abstract ones concrete intermediate states exists
abstracted required abstract case.
Even applicability necessary precondition refinability formally
guarantee refinability, since downward solution property (Tenenberg, 1988), states
every abstract solution refined, strong requirement hold general
abstraction methodology. However, indeed guaranteed abstract case
contained case-base already abstraction one previous concrete cases
due correctness Pabs algorithm used learning. one problems
contained concrete cases solved guaranteed learned
abstract case refined solve problem. Consequently, abstract case
case-base least refined solve one problem occurred past.
79

fiBergmann & Wilke

Abstract solutions useless never refined solve concrete
problem never case-base consequently never tried solving problem.
Therefore, expect abstract case case-base high chance
also refinable new similar problems applied.

7.2 Selecting Applicable Abstract Case

decide whether abstract case applied solve concrete problem P ,
determine suitable state abstraction mapping. assume deductively
justified state abstraction mappings,
required state abstraction mapping ff always




induced set ff = i=0 si shown Section 5.1. Consequently, Ca applicable
problem p = hscI ; scG sa0 = f 2 ff j scI [ Rc [ ` g sam = f 2
ff j scG [Rc [A ` g. Since every abstract case use solving new problem
learned another concrete case, known abstract state sai must
least one concrete state (from previous concrete state) abstracted via
ff sai . Consequently, sai 2 Im(ff) holds. Together introduced restrictions
definition Rc respect complete SLD-refutation procedure (see Section
6), applicability abstract case decidable. Algorithm 5 describes selection
applicable abstract case problem p = hscI ; scG detail.
Algorithm 5 (Selection applicable abstract case)
saI := saG := ;

E 2 Ea

:= SLD(S
scI [ Rc [ A; E )


sI := sI [ 2
E
E 2 Ea

:= SLD(sScG [ Rc [ A; E )
saG := saG [ 2
E
repeat
repeat
Select new case Ca = hhsa0 ; sam i; (oa1; : : : ; oam)i case base
sa0 saI sam saG
cases available
refineDFID (scI ; (); ;; scG)
return result refineDFID
:=Sm1 , 1 sai := (sai,1 n Deloai ) [ Addoai
ff := i=0 sai
(saI \ ff) = sa0 (saG \ ff) = sam
refineDFID (scI ; (sa1; : : : ; sam,1 ); ff; scG)
refineDFID returns success(p)
return success(p)

first, initial final concrete states problem abstracted using
generic abstraction theory. Thereby, abstract problem description hsaI ; saG determined.
Then, pre-selection step, abstract case chosen form case base.
abstract sentences contained initial final abstract state case must
80

fiBuilding Refining Abstract Planning Cases

contained abstracted problem description hsaI ; saG i. condition, however,
guarantee selected case applicable respect Definition 10. set ff
abstract sentences inducing respective state abstraction mapping computed
applicability condition checked test whether selected case applicable.
selected case applicable, new case must retrieved. applicable abstract
case determined refinement algorithm refineDFID (see following section)
executed. algorithm uses sequence intermediate abstract states (sa1 ; : : : ; sam,1 ),
previously determined abstract plan case, guide search concrete
level. operators contained abstract plan used anymore. refinement
procedure returns success(p), refinement succeeds solution plan p.
refinement fails (the procedure returns failure), another case selected. cases
available problem solved pure search without guidance abstract
plan.

7.3 Refining Abstract Plan
refinement selected abstract case starts concrete initial state
problem statement. search proceeds sequence concrete operations found
leads concrete state sc , sa1 = f 2 ff j sc [ Rc [ ` g holds.
applicability condition abstract case guarantees state exists (sai 2 Im(ff))
guaranteed required concrete operator sequence exists too. Therefore,
search task may fail causes whole refinement process fail also. first
abstract operator refined successfully new concrete state found. state
taken starting state refine next abstract operator manner.
refinement fails backtrack refinement previous operator try
find alternative refinement. whole refinement process reaches final abstract
operator must directly search operator sequence leads concrete goal
state scG . concrete goal state reached concatenation concrete partial
solutions leads complete solution original problem.
refinement demands search procedure allows abstract goal specification. kinds forward-directed search depth-first iterative-deepening (Korf,
1985b) best-first search (Korf, 1993) procedures used purpose
states explicitly constructed search. states tested see
abstracted towards desired goal. Paris use depth-first iterative-deepening
search described Algorithm 6. algorithm consists two recursive procedures.
top-level procedure refineDFID receives concrete initial state scI , concrete final state
scG , sequence intermediate abstract states = (sa1 ; : : : ; sak) derived abstract
case, well set ff induces state abstraction mapping. procedure
increments maximum depth depth-first search procedure searchbounded
maximum DeepMax. procedure searchbounded performs actual search. goal
search either abstract state, i.e., first abstract state , concrete
goal state scG abstract state already visited. procedure performs
depth-first search applying available concrete operators recursively calling
search procedure concrete state scnew results operator application.
81

fiBergmann & Wilke

abstract goal state reached removed list refinement
continues next abstract state first one list.
Algorithm 6 (Refinement depth-first iterative-deepening (DFID) search)
procedure refineDFID (scI ; a; ff; scG)
Deep := 0

repeat

searchbounded (scI ; a; ff; scG; Deep)
searchbounded returns success(p) return success(p)
Deep := Deep + 1 (* Search unsuccessful: Increment search deepness *)
Deep = DeepMax

return failure

procedure searchbounded (scI ; a; ff; scG; Deep)
= () (* abstract goals: Test concrete final goal *)
scI = scG return success(())
= (sa1; : : : ; sak) (* least one abstract goal *)
e 2 sa1 holds: SLD(scI [ Rc [ A; e) =6 ;
e 2 ff n sa1 holds: SLD(scI [ Rc [ A; e) = ;
(* Abstract state reached: Refine next abstract operator *)
refineDFID (scI ; (sa2 ; : : : ; sak ); ff; scG)
refineDFID returns success(p) return success(p)
Deep = 0 return failure (* Maximum depth reached *)
(* Apply operators: Create successor states *)

oc 2 Oc

= SLD(scI [ Rc; Preoc ) (*
set possible operator instantiations *)
2

scnew := (scI n (Deloc )) [ (Addoc ) (* Create successor state *)
searchbounded (scnew ; a; ff; scG ; Deep , 1) (* Continue search new state *)
searchbounded returns success(p) return success((oc) p))
return failure
Please note kind refinement different standard notion refinement hierarchical problem solving (Knoblock et al., 1991b).
strong correspondence abstract operator possible concrete operator.
Moreover, justification structure refined abstract plan completely different
justification structure abstract plan completely independent
definition abstract concrete operators. Even disadvantage compared
usual refinement procedure used hierarchical problem solving, main computational
advantage abstraction caused decomposition original problem smaller
subproblems maintained.

7.4 Alternative Search Procedures Refinement

Besides forward-directed search procedure currently used Paris backward-directed
search used means-end analysis (Fikes & Nilsson, 1971) nonlinear partial-ordered
82

fiBuilding Refining Abstract Planning Cases

planning (McAllester & Rosenblitt, 1991) also applied refinement certain
circumstances. Therefore, would either require state concretion function
turn rules generic abstraction theory virtual concrete operators.
state concretion function must able determine single state finite set
concrete states given abstract state together concrete problem description.
Thereby, concrete problem description may help reduce number possible concrete states. derived state concretions used concrete goal states
backward directed search may start.
Alternatively, turn process state concretion directly search procedure representing rule generic abstraction theory virtual abstract
operator. precondition rule generic abstraction theory becomes precondition virtual operator conclusion rule becomes positive effect
operator. using virtual concrete operators together operators
concrete domain, backward-directed planner use abstract state directly
goal search. part plan resulting solution consists concrete operators (and virtual operators) taken refinement abstract
operator.

7.5 Criteria Developing Abstract Problem Solving Domain
abstract problem solving domain generic abstraction theory used important impact improvement problem solving achieved. Therefore,
desirable set criteria state \good\ abstract domain definition look. Strong criteria allowing quantitative predictions resulting speedups
hardly developed. hierarchical planners criteria don't exist either.
However, give set factors determine success approach.
overall problem solving time uenced mainly following four factors: independent refinability abstract operators, goal distance abstract operators, concrete scope
applicability abstract operators, complexity generic abstraction theory.
7.5.1 Independent Refinability Abstract Operators

Following Korf's analysis hierarchical problem solving (Korf, 1987) introduced
2, plan refinement approach reduces overall search space bn
PSection
b(fi (i),fi (i,1)). Thereby, b average branching factor, n length coni=1
crete solution, fi sequence abstraction mapping used abstraction
concrete case abstract case. already mentioned, cannot guarantee
abstract plan applicable problem really refined. Furthermore, Korf's
analysis assumes backtracking refinement individual abstract
operators required cannot guaranteed. computational advantage
abstraction lost either two cases.
However, abstract operators occurring abstract problem solving domain
fulfill strong requirement independent refinability, guaranteed every
applicable abstract case refined without backtracking. abstract operator oa
independently refinable sc , s~c 2 Sc every state abstraction mapping ff
83

fiBergmann & Wilke


ff(sc ) ,!
ff(~sc ) holds,
exists sequence concrete operators (oc1; : : : ; ock )
c
c
ok c
o1
sc ,!
: : : ,!
s~ holds.


problem requirement seems much hard develop abstract
problem solving domain operators fulfill requirement. Although cannot
expect operators abstract problem solving domain independently refinable,
knowledge engineer developing abstract domain still try define abstract
operators independently refined situations, i.e., sc , s~c 2 Sc
state abstraction mapping ff applicable abstract operator refined
concrete operator sequence. Although notion mostly independent refinability
formal feel practically useful developing abstract domain definition.
abstract operators refined independently many situations,
higher chance abstract plan composed operators also refinable.
7.5.2 Goal Distance Abstract Operators

goal distance (cf. subgoal distance, Korf, 1987) maximum length sequence
concrete operators required refine particular abstract operator. longer goal
distance larger search space required refine abstract operator. particular,
complexity search required refine complete abstract plan determined
largest goal distance abstract operators occur abstract plan.
Hence good reason keep goal distance short. However, goal distance
negatively interacts next factor, namely concrete scope applicability
abstract operators.
7.5.3 Concrete Scope Applicability Abstract Operators

concrete scope applicability abstract operator specifies many concrete
states abstracted abstract state abstract operator applicable,
many concrete states abstracted abstract state reached
abstract operator. scope determined definition abstract operator
generic abstraction theory responsible specifying admissible state
abstractions. concrete scope applicability abstract operators determines
applicability abstract plans learned. abstract plan applicable concrete problems limited use domains problems
solved vary much. Hence, concrete scope applicability abstract operators large possible. Unfortunately, according experience, abstract
operators large scope usually also larger goal distance operators
short goal distance don't large scope applicability. Therefore, compromise
two contradicting issues must found.
7.5.4 Complexity Generic Abstraction Theory

fourth factor uences problem solving time complexity generic
abstraction theory. theory must applied time new concrete state created
concrete level search. complex generic abstraction theory,
time required compute state abstractions. Hence, generic abstraction theory
84

fiBuilding Refining Abstract Planning Cases

require complicated inferences avoid backtracking within SLD-refutation
procedure.
Although four factors don't allow precise prediction expected problem
solving behavior resulting system, provide focus consider
designing abstract problem solving domain related generic abstraction theory.

8. Example Domain: Process Planning Mechanical Engineering
Paris approach successfully tested toy-domains familiar
towers Hanoi (Simon, 1975). domains, hierarchical problem solvers use
dropping sentence approach also proven useful (Knoblock, 1994).
section presents new example domain selected field process planning mechanical engineering really requires stronger abstraction
approach.13 selected goal generating process plan production
rotary-symmetric workpiece lathe. problem description, may derived
CAD-drawing, contains complete specification (especially geometry)
desired workpiece (goal state) together specification piece raw material
(called mold) produced (initial state).
left side Figure 9 shows example rotary-symmetric workpiece
manufactured cylindrical mold.14 Rotary parts manufactured putting
mold fixture (chuck) lathe. chucking fixture, together attached
mold, rotated longitudinal axis mold rotation center.
mold rotated cutting tool moves along contour thereby removes certain parts
mold desired goal workpiece produced. Within process
hard determine sequence specific parts workpiece
removed cutting tools used. workpiece chucked certain area
workpiece covered chucking tool cannot processed cutting tool.
Moreover, workpiece chucked area used chucking plain.
Otherwise fixation would suciently stable. Hence, many workpieces usually
processed first chucking workpiece one side processing accessible area.
workpiece chucked opposite side area previously covered
processed. Processing example workpiece shown Figure 9 requires
workpiece first chucked left side right side processed. processed
right side used chuck workpiece area plain allows stable
fixing. Hence, left side workpiece including small groove processed.
explain representation domain detail. complete definition
domain found Online Appendix 1. Several simplifications real
domain required order obtain domain definition could eciently handled
large set experiments. One restriction represent workpieces
right-angled contour elements. example, conical contour cannot represented.
Many different cutting chucking tools available real-life process planning.
13. domain adapted CaPlan-System (Paulokat & Wess, 1994), developed University Kaiserslautern.
14. Note figure shows 2-dimensional drawing 3-dimensional workpiece. measure 1 in.
equals 25.4 mm.

85

fiBergmann & Wilke

Example Workpiece

Grid Representation example workpiece

2 mm
18 mm


40 mm

165 mm

Raw
Material
Workpiece

10 mm

5
4
3
2

8 mm

1

2mm

(4,2)
(1,1)
1 2

3

4

x

6 mm
8 mm

Figure 9: example workpieces grid representation
restricted single chucking tool three different cutting tools.
specification tools also simplified. example, rotation
speed workpiece feed cutting tool also parameters play
role processing workpiece. impact parameters also neglected.
Despite simplifications remaining part real-world domain trivial
represents substantial subset critical problems domain.

8.1 Concrete Domain
explain concrete problem solving domain giving detailed description
states operators.
8.1.1 State Description

representation domain concrete level, exact geometry
workpiece must represented state, including specific measures detail
contour. However, complete workpiece always divided atomic areas
always processed whole. Therefore state representation organized
using grid divides entire workpiece several disjoint rectangular areas
different sizes (see right side Figure 9). Together grid coordinate specific
position size corresponding rectangular area represented. grid used
static part state description change planning. However
different problems require different grids. specific shape workpiece planning
represented specifying status grid rectangle. Table 1 predicates
used represent workpiece described detail.
Besides description workpiece, state representation also contains information workpiece chucked kind cutting tool currently used.
Table 2 describes predicates used purpose.
86

fiBuilding Refining Abstract Planning Cases

Predicate Description
xpos max predicates xpos max(xgrid ) ypos max(ygrid ) specify size
ypos max grid direction x-coordinate y-coordinate respectively.
state consists exactly one instance predicates, e.g.,
xpos max(4) ypos max(5) example shown Figure 9.
grid xpos
grid ypos

predicates grid xpos(xgrid ; xstart; xsize ) grid ypos(ygrid ; ystart; ysize )
specify geometrical position size grid areas direction
x-coordinate y-coordinate respectively. first argument
predicates specifies coordinate grid areas, second argument
declares geometrical starting position, third argument specifies
size grid areas. state consists exactly one instance
predicates different x-coordinate y-coordinate.
example above, grid xpos(1,0,18), grid xpos(2,18,2), grid xpos(3,20,165),
grid xpos(4,185,40) specify grid x-direction grid ypos(1,0,8), : : : ,
grid ypos(5,26,8) specify grid y-direction.

mat

predicate mat(xgrid ; ygrid; status) describes status particular
grid area specified coordinates (xgrid ; ygrid). argument status
instantiated one three constants raw, workpiece, none.
constant raw indicates specified area still consists raw material must removed cutting operators. constant
workpiece specifies area consists material belongs
goal workpiece. constant none specifies area contain
material, i.e., material present mold material
already removed previous cutting operations. One instance
mat predicate required grid area specify current state.
previously mentioned predicates change execution plan, mat predicate changed cutting operator.
particular, initial state goal state problem differs status assigned grid areas must become removed. example,
initial state example shown above, sentence mat(4,2,raw)
present final state contains sentence mat(4,2,none).
Table 1: Essential sentences representation workpiece

8.1.2 Operators

process plan manufacture certain workpiece consists sequence operators.
total order operators problem domain manufacturing
steps also executed sequentially lathe.15 chosen four different operators
15. However, also new brands lathe machine also allow parallel processing.

87

fiBergmann & Wilke

Predicate
chuck pos

Description
predicate chuck pos(side) describes whether workpiece currently
chucked either side. parameter side instantiated one
three constants none, right, left. constant none specifies
workpiece chucked constants right left specify
workpiece chucked respective side. state contains
exactly one instance predicate.

covered

predicate covered(xmin ; xmax) specifies areas workpiece
currently covered chucking tool. predicate declares
areas x-coordinate lying within interval [xmin ; xmax]
covered. Covered areas cannot processed cutting tool. state
consist exactly one instance predicate workpiece chucked.

cut tool
predicates cut tool(id) cut direction(dir) specify unique identicut direction fication (id) cutting tool currently used area
processed direction (dir) cutting tool moves. parameter id symbol specifies legal cutting tool described
predicates included static rules Rc concrete domain description. parameter dir instantiated one three constants
left, right center. value left specifies cutting tool moves
left right, right specifies cutting tool moves right
left, center specifies cutting tool move outside towards
center workpiece.

Table 2: Essential sentences representation chucking cutting tools
represent chucking workpiece, selection cutting tool, cutting
process itself. operators described Table 3.
Manufacturing workpiece shown Figure 9 requires 15-step plan shown
Figure 10. first, workpiece chucked left side. cutting tool selected
allows cutting right left. tool indicated grid areas removed.
Please note left side workpiece cannot processed since covered
chucking tool. (see right side Figure 10), workpiece unchucked
chucked right side. tool allows processing left right, upper
part mold removed. Finally, specific tool used manufacture small groove.

8.2 Abstract Domain

example see small groove considered detail
processed basic contour workpiece established. important
characteristic example right part workpiece processed
left side workpiece. sequence crucial success plan. groove
88

fiBuilding Refining Abstract Planning Cases

Operator
chuck

Description
operator chuck(side) specifies workpiece chucked
specified side. side parameter instantiated constants
left right. Chucking allowed workpiece chucked already surface used chucking plain. effect chucking
operation, respective instances predicate chuck pos covered
included state description.

unchuck

operator unchuck specifies chucking workpiece removed. operation executed workpiece chucked already. effect operation, parameter predicate chuck pos
changed none predicate covered deleted.

use tool

operator use tool(dir; id) specifies tool selected subsequent cutting operators direction cutting tool moves.
workpiece must chucked tool chosen. effect
operator respective instantiations predicates cut tool
cut direction added state. parameters use tool
operator definition respective predicates.

cut

operator cut(xgrid ; ygrid) specifies raw material grid
area indicated coordinates (xgrid; ygrid ) removed. effect
operator predicate mat specifies status
particular area changed status raw status none. However,
apply operator several preconditions must fulfilled. workpiece
must chucked chucking tool must cover specified area
area must accessible cutting tool. Moreover, cutting
tool allows processing selected area must already
selected. cutting tool imposes certain constraints geometrical
size area processed it. details, see full
description domain Online Appendix 1.
Table 3: Concrete operators

would processed first workpiece could never chucked left side
processing right side would consequently impossible. Domain experts told us
situation specific example shown. general importance
many cases. fact allows us select parts problem description solution
considered details abstract. Parts \essential"
must maintained abstract case. found abstract
detailed shape workpiece long distinguish processing left
right side workpiece. Furthermore, important distinguish
rough contour workpiece small details grooves. developed
89

fiBergmann & Wilke

1. chuck(left)

7.-8. unchuck, chuck(right)

2.-6. use_tool(right, t2), cut(4,5),...,cut(4,2)

9.-12. use_tool(left,t1),cut(1,5),..,cut(3,5)
13.-15. use_tool(center,t3), cut(2,4), unchuck

Figure 10: plan manufacturing workpiece
abstract domain definition containing new language describing states operators
based abstraction idea.
8.2.1 State Description

introduce new abstract grid divides workpiece left, middle,
right area abstract specific location concrete grid area. areas
called complex processing areas. area assigned particular status. Furthermore,
abstract state contains information whether complex processing area contains
small contour elements (such grooves), grooves exactly look like.
abstract detailed conditions chucking workpiece, abstract state
contains approximation conditions, stating workpiece cannot chucked
particular side, side contains small contour elements already
processed. predicates used represent abstract state described detail
Table 4.
8.2.2 Operators

consider abstract operator completely processes one complex area
workpiece, operator processes complex area roughly, operator
processes small grooves complex area. also consider abstract chucking
operator chucking strong impact overall plan. Table 5 shows
available abstract operators.

8.3 Generic Abstraction Theory
generic abstraction theory defines sentences used describe abstract state (see
Table 4) terms sentences concrete state (see Tables 1 2) set
Horn rules. definition abstract sentence explained detail Table 6.
90

fiBuilding Refining Abstract Planning Cases

Predicate
abs area state

Description
predicate abs area state(area; status) describes status
three complex processing areas. argument area
specifies one complex processing areas left, middle, right.
argument status describes status respective area.
status either todo, rough, ready. status todo
specifies area needs processing large contour elements, rough area small contour elements
grooves need processed. status ready specifies
area completed. abstract initial state usually contains
one complex processing areas status todo,
abstract goal state complex processing areas status
ready.

abs small parts

predicate abs small parts(area) specifies complex processing area (area) contains small contour elements need
manufactured.

abs chuck pos

predicate abs chuck pos(side) describes whether workpiece
currently chucked either side. parameter side
instantiated one three constants none, right, left.
predicate exactly meaning chuck pos predicate
concrete level. predicate abstracted
renamed.

abs chuckable wp

predicate abs chuckable wp(side) describes whether workpiece chucked left right side side
completely processed.

Table 4: Essential sentences describing abstract state
strongly considered factors uence quality domain (see Section 7.5) development abstract problem solving domain generic
abstraction theory. Although none defined abstract operators independently refinable, mostly independently refinable. preconditions abstract
operator still contains approximations conditions must fulfilled order assure concrete operator sequence exist refines abstract operator. example,
predicate abs chuckable wp(side) approximation detailed condition (a plain
surface) required chucking. goal distance operator quite different
strongly depends problem solved. goal distance set fixation
operators two (possibly one unchuck operator followed chuck operator)
goal distances abstract operators different. example, goal distance process ready operator depends number concrete grid areas belonging
91

fiBergmann & Wilke

Operator
set fixation

Description
operator set fixation(side) specifies workpiece chucked
specified side. side parameter instantiated
constants left, right none. constant none specifies
chucking removed. Compared concrete operator chuck
preconditions chucking side simplified. effect
operator predicate abs chuck pos modified.

process rough

operator process rough(area) specifies complex processing
area (area) processed completely small contour elements. parameter area either left, middle, right.
precondition operator requires workpiece chucked
different side area. effect operator predicate abs area state modified.

process fine

operator process fine(area) specifies small contour elements
complex processing area (area) processed. parameter area either left, middle, right. precondition
operator requires large contour elements side
workpiece already processed workpiece chucked
different side. effect operator predicate
abs area state modified.

process ready

operator process ready(area) specifies indicated complex
area workpiece completely processed, including large
small contour elements. effect operator predicate
abs area state modified.
Table 5: Abstract operators

respective abstract area containing material needs removed.
goal distance number gird areas, say c, plus number required use tool
operations (less equal c). Hence, goal distance c 2c.
goal distance become long complex problems, two operators
process rough process fine introduced. cover processing small
large grid areas respectively consequently smaller goal distance
process ready operator. goal distance two operators smaller
smaller concrete scope applicability process ready operator. example
process ready operator applied state arbitrary areas need
processed, process fine applied states large grid areas
already processed.
Although developed simplified version whole domain production planning mechanical engineering rotary symmetrical workpieces feel
92

fiBuilding Refining Abstract Planning Cases

Abstract Predicate Description terms predicates concrete domain
abs area state
predicate abs area state(area; status) describes status
three complex processing areas. left processing area
consists areas concrete grid covered,
workpiece chucked left side. Similarly, right processing
area consists concrete grid areas covered
workpiece chucked right side. middle processing area
consists areas never covered chucking
tool. status complex processing area todo, exists
concrete large grid area belongs complex processing
area needs processed. grid area considered
large size direction x-coordinate larger 3
mm. status complex processing area rough, large
grid areas complex processing area already processed
exists concrete small grid area belongs
complex processing area needs processed. gird
area considered small size direction x-coordinate
smaller equal 3 mm. status complex processing
area ready concrete grid areas belong complex
processing area processed.
abs small parts

sentence abs small parts(area) holds exists small concrete grid area (size smaller equal 3 mm) belongs
complex processing area needs processed.

abs chuck pos

sentence abs chuck pos(side) holds concrete
sentence chuck pos(side) holds.

abs chuckable wp

predicate abs chuckable wp(side) describes whether workpiece still chucked left right side side
completely processed. sentence holds part desired
workpiece belongs respective side completely plain.
is, concrete grid areas status workpiece range
y-coordinate.
Table 6: Generic abstraction theory

domain expert together knowledge engineer able define abstract
domain representation generic abstraction theory complete domain. particular, model-based interactive knowledge acquisition tools like MIKADO (Schmidt, 1994;
Schmidt & Zickwolff, 1992) make complete modeling task much feasible.
93

fiBergmann & Wilke

Case C1
Initial state

Goal State

Solution
1. chuck(left)
8.
chuck(right)
13. use_tool(center, t3)
2. use_tool(right,t2) 9.
use_tool(left,t1) 14. cut(2,4)
3.-6. cut(4,5),..., cut(4,2) 10.-12. cut(1,5),..., cut(3,5) 15. unchuck
7. unchuck

Problem
Abstraction

1.

2.- 6.

7.- 8.

9.- 12.

I.

II.

III.

IV.

13.- 14.

15.
Problem
Abstraction

Abstraction
V.

VI.

Abstract Case Ca
Abstract initial state
abs_area_state(left, todo)
abs_area_state(right,todo)
abs_small_parts(left)
abs_chuckable_wp(right)

Problem
Abstraction

Abstract Solution
I. set_fixation(left)
II. process_ready(right)
III. set_fixation(right)

Abstract goal state

IV. process_rough(left)
V. process_fine(left)
VI. set_fixation(none)

I.

II.

III.

1.

2.- 3.

4.- 5.

IV.

V.

VI.

11.- 14.

15.

abs_area_state(left, ready)
abs_area_state(right,ready)
abs_chuckable_wp(right)

Refinement
6.- 11.

New Case C2

Initial state

Solution Solution
1. chuck(left)
2. use_tool(right,t2)
3. cut(7,3)
4. unchuck

Problem
Abstraction

Goal State

5.
chuck(right),
12. use_tool(center, t3)
6.
use_tool(left,t1), 13. cut(2,2)
7.-11. cut(1,3),...,cut(5,3), 14. cut(4,2)
15. unchuck

Figure 11: Abstracting Refining Example Case

8.4 Abstracting Refining Process Planning Case

explain example case shown Figure 9 abstracted
abstract case reused solve different planning problem. process
demonstrated Figure 11. top figure shows concrete planning case C1
already presented Figure 9. case abstracted Pabs algorithm presented
Section 6. algorithm returns 6 different abstract cases16. One abstract cases
shown center figure. abstract solution plan consists sequence 6
abstract operators. sequence operators plan indicated Roman
numerals. particular abstraction indicated concrete abstract case
denotes sequence concrete operators turned abstract operator.
16. 5 abstract cases differ shown abstract case two aspects: shown abstract
solution additional abstract step set fixation(none) inserted steps II III.
abstract step V also replaced abstract step process ready, abstract steps IV V
together replaced abstract step process ready.

94

fiBuilding Refining Abstract Planning Cases

learned abstract case used solve new problem C2 whose initial
final concrete states shown bottom figure. Even concrete workpiece
looks quite different workpiece case C1 abstract case used solve
problem. reason new workpiece also requires left
right side must processed. particular right side must also processed
left side processed left side contains two small grooves prevent
workpiece chucked side processed. However, see
abstract operators (in particular operators II, VI, V) refined completely
different sequences concrete operators abstracted.
already mentioned, abstract operators used independently refinable
mostly independently refinable. Consequently, happen applicable abstract case cannot refined. Figure 12 shows example concrete planning problem
abstract case shown Figure 11 applicable refinable. reason
location small abstract part left side workpiece. small
part consists concrete grid area (1,3) raw material must removed. However, specific situation, small part must removed large parts,
left side workpiece contains (the grid areas (2,3), (3,3), (2,2)), removed.
reason without removing small part, larger parts located right
small part cannot accessed cutting tool able cut areas (2,3)
(3,3). Consequently problem solved plan shown right
side Figure 12. Unfortunately, plan refinement abstract plan shown
Figure 11, abstract plans requires large parts must removed
small parts removed. Hence, refinement operator process rough(left) fails.
situation problem solver must select different abstract plan.

9. Empirical Evaluation Results
section presents results empirical study Paris mechanical engineering domain already introduced. evaluation performed fully implemented
Paris system using abstraction abilities system. generalization component switched-off purpose. designed experiments allow us
judge performance improvements caused various abstract cases derived Pabs.
Furthermore, analyzed average speed-up behavior system respect
large set randomly selected training test cases.

9.1 Planning Cases
empirical evaluation 100 concrete cases randomly generated. case
requires 100-300 sentences describe initial final state,
instances mat predicate. length solution plans ranges 6 18
operators. Even generated cases represent simple problems compared
problems real domain expert needs solve, search space required solve sample
problems already quite large. due fact branching factor b
1:7 6:6, depending complexity problem. Hence, 18-step solution
complete search space consists 3:7 1015 states.
95

fiBergmann & Wilke

Solution

New Problem


2 mm
3
2

2mm

1

Workpiece

8 mm

1. chuck(left)
2. use_tool(right,t2)
3. cut(4,3)
4. cut(4,2)
5. unchuck
6. chuck(right)
7. use_tool(left,t1)
8. cut(1,3)
9. cut(2,3)
10. cut(3,3)
11. use_tool(center, t3)
12. cut(2,2)
13. unchuck

18 mm
abs_small_parts(left)
1 2

3

4

x

Figure 12: Example Case refinement abstract plan shown Figure
11 fails.

case generation procedure leads solutions optimal nearly optimal.
solutions require less 10 steps optimal solutions sense
known shortest solution problem solve. solutions longer
10 steps manually checked see whether contain steps
obviously redundant. redundant steps removed. Although solutions
necessarily shortest solutions, nevertheless acceptably short.

9.2 Evaluating Abstraction Dropping Sentences
first used recent version Alpine (Knoblock, 1993) together Prodigy4 (Blythe et al., 1992) check whether abstraction dropping sentences improve
problem solving domain represented described Section 8. Therefore, used
concrete problem solving domain domain theory Prodigy. Unfortunately,
representation, Alpine able generate ordered monotonic abstraction
hierarchy. reason Alpine distinguish different groups
literals different literal names (and argument types) used
problem space. example, Alpine cannot distinguish different sentences
described mat grid xpos predicate. important
abstraction. would like drop parts grid represent small rectangles
grooves. However, would require examination measures associated
grid area (as argument) also relation surrounding grid areas. Therefore, sentence drop (or criticalities assign) cannot decided statically
name predicate type arguments. hierarchical planners including
96

fiBuilding Refining Abstract Planning Cases

Prodigy Alpine highly dependent representation used, particular

strategy restricted dropping sentences (Holte et al., 1994, 1995). However, might
another representation domain hierarchical planners improve
performance think representation quite "natural" domain.
first trial conclude application domain representation
chosen following experiments Paris really require dropping
sentences achieve improvement abstraction.

9.3 Evaluating PARIS Approach

first experiment Paris designed evaluate hypotheses domain
need (I) changing representation language abstraction, (II)
reusing abstract cases instead generating abstract solutions scratch. test
hypotheses rely time solving randomly generated problems using different
modes Paris system.
9.3.1 Experimental Setting
experiment used Paris system solve 100 problems randomly

generated cases. Thereby goal abstraction improve concrete-level problem
solver, performs brute-force search depth-first iterative-deepening search
strategy (Korf, 1985a) introduced Section 7.3. improvement determined
terms problem solving time required solve single problem. Paris used solve
100 problems three different modes:

Pure search: problem solver used solve problem pure search without
use abstraction.

Hierarchical planning: mode Paris uses introduced abstract domain. How-

ever, abstract cases recalled case library computed automatically search standard hierarchical planning, using new abstraction language. So, problem solver first tries search solution original
problem abstract domain tries refine solution.
hierarchical problem solving, backtracking two levels abstraction
subproblem occur. Thereby, used hierarchical planning
new abstraction methodology instead dropping sentences.

Reasoning abstract cases: mode first used Paris learn abstract
cases come 100 concrete cases. problem, abstract cases
exists according abstraction methodology available one
problems solved. problem solving measured time required
solving problem using every applicable abstract cases. Then, problem,
three abstract cases determined: a) best abstract case, i.e., case leads
shortest solution time, b) worst abstract case (longest solution time)
abstraction aspired solution case, c) worst applicable abstract
case determined. difference b) c) relates difference
applicable refinable abstract cases introduced Section 7.1. abstract case
97

fiBergmann & Wilke

selected c) applicable current problem, might abstraction
case problem taken. b) abstract cases selected
indeed abstractions current problem, i.e., abstract cases
previously learned case problem taken. three
different cases selected figure impact case selection (which
addressed paper) proposed method.
Although every problem theoretically solved brute-force search procedure,
exponential nature search space avoids solution complex problems within
reasonable time. Therefore, time-bound 200 CPU seconds Sun Sparc-ELC
computer introduced three modes described above. limit-bound
exceeded problem remains unsolved. Increasing time-bound would increase
number solvable problems three modes.
9.3.2 Results

determined solution time 100 problems described
modes. average solution time well number problems could solved
within time limit shown Table 7. determined values reasoning
abstract cases separately three types abstract cases. significance
speedup results investigated using maximally conservative sign test
(Etzioni & Etzioni, 1994). Unfortunately turned speedup hierarchical
planning pure search significant. also couldn't find significant speedup
reasoning abstract cases using always worst applicable abstract case (c)
pure search. due large number doubly censored data (both problem
solvers cannot solve problem within time limit), counted
speedup hypothesis. However, improvements pure search reasoning refinable
abstract cases significant (p < 0:000001) using best refinable case (a)
using worst refinable case (b). Furthermore, turned speedup
reasoning refinable cases hierarchical planning also significant upper
bound p-value 0:001. mentioned p-value standard value used statistical
hypothesis tests. probability, assuming hypothesis hold,
encountering data favors hypothesis much observed data
experiment (Etzioni & Etzioni, 1994). Therefore result significant
p-value smaller. analysis, clearly see, two basic hypotheses
supported experimental data. Even significant see moderate
improvement problem solving time number solved problems using
hierarchical planning changing representation language. Please remember
hierarchical planning dropping conditions lead improvement (see
Section 9.2). Obviously, changing representation language abstraction required
improve problem solving domain stated first hypothesis (I).
strong support second hypothesis (II) also found presented
data. see significant speedups reasoning abstract cases pure search
even hierarchical planning. worst abstract case used problem
solved, speedup significant problem solving behavior slightly
worse hierarchical planning. Please note situations extremely unlikely
98

fiBuilding Refining Abstract Planning Cases

Problem solving mode
Average solution time (sec.) Solved problems
Pure search
156
29
Hierarchical planning
107
50
Reasoning abstract cases
(a) Best refinable case
35
94
(b) Worst refinable case
63
79
(c) Worst applicable case
117
45
Table 7: Comparison average solution time per problem number solved
problems within time-bound 200 seconds. table compares pure search
(depth-first iterative deepening), hierarchical planning using abstract problem solving domain, reasoning abstract cases differently selected
abstract cases.
happen all. sophisticated indexing retrieval abstract cases situation
avoided part.

9.4 Evaluating Impact Different Training Sets
one respect previous experiment based optimistic assumption. always
assume abstract cases required solving problem learned advance.
situation realistic scenario application. Usually, one set cases
available training system different set problems needs solved.
cannot assume good applicable abstract cases always available solve new
problem. Furthermore, presented example also shows problem solving time
vary lot different abstract cases selected problem solving. Therefore,
designed new experiment evaluate improvements caused Paris approach
realistic scenario.
9.4.1 Experimental Setting

randomly chosen 10 training sets 5 cases 10 training sets 10 cases
100 available cases. training sets selected independently other.
Then, 20 training sets used separate experiment. 20
experiments, 100 cases used particular training set
used evaluate performance resulting system. Training set test set
completely independent procedure. problem solving task,
determine problem solving behavior applicable abstract cases, used
simple automatic mechanism retrieve one (hopefully good) applicable abstract case
problem. Therefore, cases organized linearly cases base, sorted
length abstract plan contained case. case base sequentially searched
longer shorter plans applicable case found. heuristic based
assumption longer abstract plan specific shorter abstract plan
99

fiBergmann & Wilke

Size training sets
(cases)
5
10

Number abstract cases
minimum
maximum
average
7
15
9.1
8
25
14.2

Table 8: Comparison number learned abstract cases a) 10 training sets
consists 5 concrete cases b) 10 training sets
consists 10 concrete cases. table shows minimum, maximum,
average number abstract cases learned 10 training sets
respective size.
Size training sets
(cases)
5
10

Average problem solving time (sec.)
best set
worst set
average
43
89
59
35
76
56

Table 9: Comparison problem solving time required reasoning abstract cases
separate training a) 10 training sets consists 5
concrete cases b) 10 training sets consists 10 concrete
cases. table shows average problem solving time per problem best,
worst average training set 10 training sets size.
divides actual problem more, smaller subproblems. Consequently longest
applicable plan lead best improvement.
9.4.2 Results

statistically evaluated second experiment. Table 8 shows number abstract
cases could learned different training sets. minimum, maximum
average number abstract cases could learned 10 training sets
size indicated. Note altogether 42 abstract cases learned 100
cases would used training previous experiment. 10 training
sets contained 5 cases each, 7 15 abstract cases could learned.
expected, size training set increased abstract cases learned.
Table 9 shows average problem solving time learning different sets.
table also shows minimum, maximum average problem solving time
10 different training sets two sizes. see best training sets leads
problem solving time similar slightly worse optimum shown
Table 7. Even average case, considerable improvements pure search
hierarchical problem solving (compare Table 7 Table 9) discovered.
100

fiBuilding Refining Abstract Planning Cases

Size training sets
(cases)
5
10

Percentage Solved Problems
best set
worst set
average
91
68
83
94
74
86

Table 10: Comparison percentage solved problems separate training
a) 10 training sets consists 5 concrete cases b) 10
training sets consists 10 concrete cases. table shows
percentage solved problems best, worst average training
set 10 training sets size.
Size training sets
(cases)
5
10

Number training sets significant speedups
pure search
hierarchical planning
p < 0:0005
p < 0:0005
p < 0:05
9
4
8
10
5
7

Table 11: Comparison significance (p-value) speedup results pure search
hierarchical planning separate training a) 10 training sets
consists 5 concrete cases b) 10 training sets
consists 10 concrete cases. table shows number training sets
cause significant speedups different p-values.
positive results also identified looking percentage solved problems,
shown Table 10. also see best training sets number solved
problems close maximum achieved approach. Even worst
training set considerably problems could solved pure search hierarchical
planning.
Additionally mentioned speedup results analyzed maximally conservative sign test described (Etzioni & Etzioni, 1994). Table 11 summarizes
significance results speeding pure search hierarchical problem solver.
turned 19 20 training sets lead highly significant speedups (p < 0:0005)
pure search. hard upper bound p-values half training
sets lead significant differences reasoning abstract cases hierarchical
planning. slightly higher upper bound p < 0:05, 3=4 training sets
caused significantly better performance hierarchical planning.
Altogether, reported experiment showed even small number training cases
(i.e., 5% 10%) already lead strong improvements problem solving.
see abstract cases must present, first experiment, successful.
Furthermore, experiment shown even simple retrieval mechanism (sequential
101

fiBergmann & Wilke

Size training sets
(cases)
5
10

Average percentage solutions
shorter/equal/longer solution length
shorter
equal
longer
20
54
26
22
50
28

Table 12: Comparison length solutions created reasoning learned
abstract cases solutions available concrete cases. table shows
average percentage solutions shorter/equal/longer solution length
separate training a) 10 training sets consists 5
concrete cases b) 10 training sets consists 10 concrete
cases.
search) select beneficial abstract cases library. Neither training situations
second experiment lead results worse worst case shown Table
7.

9.5 Quality Produced Solutions

Although main purpose approach improve performance problem
solver, quality produced solutions also important practical system.
solution length used simple criterion determine quality
solution. However, general quality solution ect execution costs
plan, plans robustness, certain user preferences (Perez & Carbonell, 1993).
quality measures dicult assess, particular manufacturing
domain, rely simple criterion also used evaluating quality solutions
Prodigy/Analogy (Veloso, 1992).
9.5.1 Experimental Setting

analyzed solutions computed previous set experiments assess
quality solutions produced Paris. Therefore, length solutions derived
problem solving, learning 20 training sets, compared
length nearly optimal solutions contained concrete cases.
9.5.2 Results

training set length solution derived corresponding testing phase
compared length solution noted concrete case. percentage
solutions shorter, equal, longer solution length determined training set
separately, average 10 training sets equal size determined. Table
12 shows result evaluation.
turned big difference quality results 20
training sets. particular, size training sets strong uence
102

fiBuilding Refining Abstract Planning Cases

results. Table 12 see 72% (22% + 50%) 74% (20% + 54%)
solutions produced equal better quality solutions contained
concrete cases. Please note concrete cases used testing always different
cases used training. Additionally, solutions compare
results produced Paris already nearly optimal solutions due case generation
procedure.17 Taking account, results already fairly good.

9.6 Impact Abstract Problem Solving Domain
experiments reported conducted concrete abstract domain
representation presented Section 8 Online Appendix 1. final experiment
impact specific choice abstract problem solving domain investigated.
9.6.1 Experimental Setting

created new abstract problem solving domain less constrained one
used before. purpose one operator completely removed certain conditions
remaining operators removed also. particular, set fixation operator
removed conditions abs chuck pos, abs chuckable wp, chuck comp removed
preconditions three remaining operators. Hence, fact chucking
workpiece impact production plan neglected abstract level.
However, concrete problem solving domain generic abstraction theory
modified all. Consequently, chucking still plays important role concrete level.
set experiments described Section 9.4 repeated less constrained
abstract problem solving domain using training testing sets before.
9.6.2 Results

Table 13 14 summarize results experiments. Table 13 shows average
problem solving time occurs learning different training sets. turns
training sets, learning improves concrete level problem solver,
speedup much smaller using original abstract problem solving domain
(cf. Table 7 9). particular, none resulting speedups concrete level problem
solving significant. similar result observed comparing percentage
solved problems (see Figure 14). still slight improvement number
problems could solved learning improvement much smaller
using original abstract problem solving domain (cf. Table 7 10).

17. cases one, shorter solutions produced Paris one step shorter solution
contained concrete case.

103

fiBergmann & Wilke

Size training sets
(cases)
5
10

Average problem solving time (sec.)
best set
worst set
average
114
118
117
107
112
110

Table 13: Using less constrained abstract problem solving domain: Comparison
problem solving time required reasoning abstract cases separate
training a) 10 training sets consists 5 concrete cases
b) 10 training sets consists 10 concrete cases. table
shows average problem solving time per problem best, worst
average training set 10 training sets size.

Size training sets
(cases)
5
10

Percentage Solved Problems
best set
worst set
average
55
52
53
58
54
56

Table 14: Using less constrained abstract problem solving domain: Comparison
percentage solved problems separate training a) 10 training sets
consists 5 concrete cases b) 10 training sets
consists 10 concrete cases. table shows percentage solved problems
best, worst average training set 10 training sets
size.
experiment supported general intuition abstract problem solving domain significant impact improvement problem solving achieved
reasoning abstract cases. reason less constrained domain leads
worse results original abstract domain explained respect
criteria explained Section 7.5. Since important preconditions abstract operators
removed many situations new operators cannot refined.
holds particularly situations workpiece cannot chucked perform
required cutting operations. new abstract operators mostly independently
refinable. Moreover, since abstract operator set fixation removed concrete chuck
unchuck operator must introduced refinement remaining abstract
operators. Consequently, goal distance abstract operators increased.
two factors reason worse results using less constrained abstract domain
theory.
104

fiBuilding Refining Abstract Planning Cases

10. Discussion
paper shown detail hierarchical problem solving (Sacerdoti, 1974;
Tenenberg, 1988; Unruh & Rosenbloom, 1989; Yang & Tenenberg, 1990; Knoblock, 1990)
limited view abstraction dropping sentences well strategy
abstract solutions computed lead poor behavior various relevant situations.
observation supported comprehensive artificial examples (see Section 2.1 2.2)
real-world example domain mechanical engineering (see Section 8),
supported experiment (see Section 9.2). recent results reported (Holte et al.,
1995) support observations well.
general, abstraction task transforming problem solution concrete representation different abstract representation, reducing level
detail (Michalski & Kodratoff, 1990; Giunchiglia & Walsh, 1992; Michalski, 1994). However, hierarchical problem solvers, much limited view abstraction
dropping sentences shown reason ecient ways abstracting problem
solution impossible (e.g., see Section 2.1 Figure 4). second weakness
hierarchical problem solvers usually compute arbitrary abstract solutions solutions high chance refinable next concrete
level. Although upward solution property (Tenenberg, 1988) guarantees refinable abstract solution exists, guaranteed problem solver finds abstract
solution (e.g., see Section 2.2). Problem solvers even heuristically guided towards
refinable abstract solutions.
Paris approach present new formal abstraction methodology problem
solving (see Section 5) allows abstraction changing whole representation language concrete abstract. Together formal model, correct complete
learning algorithm abstracting concrete problem solving cases (see Section 6) given.
abstract solutions determined procedure useful solving new concrete
problems, high chance refinable.
detailed experimental evaluation fully implemented Paris system
domain mechanical engineering strongly demonstrates Paris significantly improve problem solving situations hierarchical problem solver using dropping
sentences fails show advantage (see Table 7 11).

10.1 Related Work
discuss Paris approach relation relevant work field.
10.1.1 Theory Abstraction

Within Giunchiglia Walsh's (1992) theory abstraction, Paris approach
classified follows: formal system ground space 1 given concrete
problem solving domain Dc using situation calculus (Green, 1969) representation.
language abstract formal system 2 given language abstract
problem solving domain Da . However, operators Da turned axioms
2 . Instead, abstract cases build axioms 2 . Moreover, generic abstraction
theory defines abstraction mapping f : 1 ) 2 . Within framework, view
105

fiBergmann & Wilke

Paris system learns useful axioms abstract system, composing several

smaller elementary axioms (the operators). However, prove formula (the existence
solution) abstract system, exactly one axiom (case) selected. deductive
machinery abstract system restricted respect ground space. Depending
learned abstract cases abstractions Paris either theory decreasing (TD)
theory increasing (TI). case-base abstract cases completely empty
domain axiom available resulting abstractions consequently TD. casebase contains maximally abstract case hhtrue; truei(nop)i18 (and generic abstraction
theory contains clause ! true), case applied every concrete problem
resulting abstraction consequently TI. Even maximally abstract case
improve ground level problem solving, always included case-base
ensure TI property, loosing completeness. case retrieval mechanism
must however guarantee, maximally abstract case chosen refinement
applicable case available. Note, fulfilled retrieval mechanism
(sequential search longer shorter plans) used experiments.
10.1.2 Skeletal Plans

already mentioned Section 3.4 Paris approach inspired idea skeletal
plans (Friedland & Iwasaki, 1985). abstract cases seen skeletal plan,
learning algorithm means learn skeletal plans automatically concrete
plans. Even idea skeletal plans intuitively appealing, knowledge,
paper contains first comprehensive experimental support usefulness planning
skeletal plans. Since shown skeletal plans acquired automatically,
planning method applied easily.
purpose, Anderson Farley (1988) Kramer Unger (1992) proposed approaches plan abstraction go direction Paris algorithm.
However, approach automatically forms abstract operators generalization, mostly
based dropping sentences. Moreover, abstracted plan, every concrete operator
abstracted, number operators reduced abstraction. Thereby
abstraction approach less powerful Paris style abstractions.
10.1.3 Alpine's Ordered Monotonic Abstraction Hierarchies
Alpine (Knoblock, 1989, 1990, 1993, 1994) automatically learns hierarchies abstraction

spaces given domain description domain description together planning problem. mentioned several times before, Alpine relies abstraction dropping
sentences. However, enables Alpine generate abstraction hierarchies automatically.
stronger abstraction framework one follow Paris, automatic
generation abstraction hierarchies (or abstract domain descriptions) seem
realistic due large (infinite) space possible abstract spaces. use powerful abstraction methodology, feel pay price losing ability
automatically construct abstraction hierarchy.
Another point specific property ordered monotonic abstraction hierarchies
generated Alpine, allows ecient plan refinement. refinement, ab18. nop 'no operation' operator always applicable change abstract state.

106

fiBuilding Refining Abstract Planning Cases

stract plan expanded successively lower levels inserting operators. Furthermore,
already established conditions plan guaranteed violated anymore refinement. Unfortunately, kind refinement cannot performed Paris-style
abstractions. Especially, direct correspondence abstract operators
concrete operators. Consequently, abstract plan cannot extended become
concrete plan. However, main function abstract plan maintained, namely
original problem decomposed several smaller subproblems causes main
reduction search.
10.1.4 Explanation-based Learning, Case-based Reasoning Analogy

presented Paris approach uses experience improve problem solving, similar several
approaches machine learning, mostly explanation-based learning (Mitchell et al.,
1986; DeJong & Mooney, 1986), case-based reasoning (Kolodner, 1980; Schank, 1982; Althoff & Wess, 1992; Kolodner, 1993) analogical problem solving (Carbonell, 1986; Veloso
& Carbonell, 1988). basic ideas behind explanation-based learning case-based
analogical reasoning much related. common goal approaches
avoid problem solving scratch situations already occurred past.
Explanations (i.e., proofs justifications) constructed successful solutions already
known system. explanation-based approaches, explanations mostly cover
whole problem solving process (Fikes, Hart, & Nilsson, 1972; Mooney, 1988; Kambhampati
& Kedar, 1994), also relate problem solving chunks (Rosenbloom & Laird,
1986; Laird, Rosenbloom, & Newell, 1986) smaller size even single decisions
within problem solving process (Minton, 1988; Minton et al., 1989). Explanation-based
approaches generalize constructed explanations learning extensive use
available domain knowledge store result control rule (Minton, 1988) schema
(Mooney & DeJong, 1985). case-based reasoning systems like Priar (Kambhampati
& Hendler, 1992) Prodigy/Analogy (Veloso & Carbonell, 1993; Veloso, 1994) cases
usually explicitly generalized advance. kept fully instantiated
case library, annotated created explanations. Unlike cases Paris
problem-solution-pairs, cases complete problem solving episodes containing detailed information decision taken problem solving. problem
solving, cases retrieved contain explanations applicable current problem (Kambhampati & Hendler, 1992; Veloso & Carbonell, 1993; Veloso, 1994). detailed
decisions recorded cases replayed modified become solution
current problem. approaches use kind generalization experience,
none approaches use idea abstraction speedup problem solving based
experience. already noted (Michalski & Kodratoff, 1990; Michalski, 1994), abstraction generalization must confused. generalization transforms description
along set-superset dimension, abstraction transforms description along level-of-detail
dimension.
exception given (Knoblock, Minton, & Etzioni, 1991a) Alpine's
abstractions combined EBL component Prodigy. Thereby, control rules
learned refer ground space problem solving also abstract
spaces. control rules speedup problem solving abstract level. However,
107

fiBergmann & Wilke

control rules guide problem solver abstract level finds solutions faster
manner finds refinable abstract solutions. Although
experience kind integration abstraction explanation-based learning,
assume control rules generated EBL component also guide problem
solver towards short abstract solutions cause much reduction search
several circumstances.

10.2 Requirements Limitations PARIS

following, summarize requirements limitations Paris
approach. main requirements availability good abstract domain description
availability concrete cases.
10.2.1 Abstract Domain

important prerequisite method availability required background knowledge, namely concrete world description, abstract world description,
generic abstraction theory. construction planning system, concrete
world descriptions must acquired anyway, since specify \language\ problem description (essential sentences) problem solution (operators). abstract
world generic abstraction theory must also acquired. feel indeed
price pay make planning tractable certain practical situations.
Nevertheless, formulation adequate abstract domain theory crucial
success approach. abstract operators missing required express
useful abstract plan, speedup achieved. need mostly independently
refinable abstract operators. operators exist, simply represented
abstract domain using whole representational power. hierarchical planning
dropping conditions, abstract domain must also implicitly contained concrete
domain way abstract domain remains, certain literals concrete domain
removed (see Section 2.1). feel kind modeling much harder
achieve modeling abstract view domain explicitly distinct planning space
Paris. Additionally, requirement abstract domain given user
also advantage learned abstract cases expressed terms user
familiar with. Thereby, user understand abstract case easily. open
additional opportunity involve user planning process, example
selection abstract cases she/he favors.
Research knowledge acquisition shown human experts employ lot
abstract knowledge cope complexity real-world planning problems. Specific knowledge acquisition tools developed comfortably acquire abstract
knowledge different sources. Especially, acquisition planning operators addressed much detail (Schmidt & Zickwolff, 1992; Schmidt, 1994).
10.2.2 Availability Cases
second prerequisite, Paris approach needs concrete planning cases (problem-

solution pairs). real-world scenario cases usually available company's
filing cabinet database. According requirement share general view
108

fiBuilding Refining Abstract Planning Cases

machine learning use kind experience promising way cope
highly intractable problems. Paris approach available cases must
somehow representative future problem solving tasks. known cases must similar
enough new problems abstract cases really reused. experiments
give strong indications even small set concrete cases training leads high
improvements problem solving (see Table 9 11).

10.3 Generality Achieved Results

reported experiments performed specific base-level problem solver
performs depth-first iterative-deepening search strategy (Korf, 1985a). However,
strongly believe Paris abstractions also beneficial problem solvers
using backward-chaining, means-end analysis nonlinear partial-order planning. shown
(Veloso & Blythe, 1994), one optimal planning strategy. Different planning
strategies usually rely different commitments search. strategy useful
one domain may worse others. However, search strategies, length
shortest possible solution usually determines amount search required.
Paris, whole search problem decomposed several subproblems allow
short solutions. Consequently, kind problem decomposition use
search strategies.
Moreover, think idea reasoning abstract cases, formulated
completely new terminology ground space also useful kinds
problem solving design model-based diagnosis. model-based diagnosis,
developed approach (Pews & Wess, 1993; Bergmann, Pews, & Wilke, 1994) similar
Paris. domain descriptions consist model technical system
diagnosis found. describes behavior elementary composed
component system different levels abstraction. model-based diagnosis,
behavior technical system simulated possible faulty component searched
cause observed symptoms. Using abstract cases, search reduced
focused onto components already defective (in similar machines)
consequently likely defective new situations.

10.4 Future Work

Future research investigate goal-directed procedures refinement backwarddirected search non-linear partial order planners (see Section 7.4). Additionally,
experience must gained additional domains different representations them.
Furthermore, address development highly ecient retrieval algorithms
abstract cases. Table 7 shows, retrieval mechanism strong uence
achieved speedup. Even linear retrieval presented turned pretty
good, expect utility problem (Minton, 1990) occur size casebase grows. Furthermore, good selection procedure abstract cases also use
feedback problem solver evaluate learned abstract cases based
speedup cause. would eliminate unbeneficial cases abstract operators
case-base abstract problem solving domain. Experiments different indexing
retrieval mechanisms recently indicated possible.
109

fiBergmann & Wilke

Furthermore, speedup caused combination different approaches
abstraction explanation-based learning addressed. Within Paris system
explanation-based component case generalization still present (see Figure 3),
used experiments plain abstraction evaluated.
experiments, abstraction, explanation-based learning integration
addressed comprehensively. hopefully lead better understanding
different strengths methods have.
long-term research goal, Paris-like approaches developed
evaluated kinds problem solving tasks configuration design or,
already started, model-based diagnosis.

Appendix A. Proofs

section contains proofs various lemma theorems.

Lemma 6 (Joining different abstractions) concrete domain Dc two disjoint abstract domains Da1 Da2 given, joint abstract domain Da = Da1 [ Da2
defined follows: Let Da1 = (La1; Ea1; Oa1; Ra1) let Da2 = (La2; Ea2; Oa2; Ra2).
Da = Da1 [ Da2 = (La1 [ La2 ; Ea1 [ Ea2 ; Oa1 [ Oa2 ; Ra1 [ Ra2). joint abstract domain
Da fulfills following property: Ca abstraction Cc respect (Dc, Da1)
respect (Dc , Da2), Ca also abstraction Cc respect (Dc ; Da).
Proof: proof lemma quite simple. Ca abstraction Cc respect
(Dc , Dai), exists sequence abstraction mapping ff sequence abstraction
mapping fi required Definition 5. easy see, abstraction mappings
also lead respective case abstraction (Dc ; Da). 2

Lemma 7 (Multi-Level Hierarchy) Let (D0; : : : ; Dl) arbitrary multi-level
hierarchy
domain descriptions. two-level description (Dc , Da ) Da = l =1
Dc = D0 holds that: Ca abstraction Cc respect (D0; : : : ; Dl) Ca
also abstraction Cc respect (Dc , Da ).
Proof: Let C = hhs0 ; smi; case domain (intermediate state denoted
sj ), let C0 = hhs00 ; s0n i; o0i case domain D0 (intermediate state denoted s0i ),
let C abstraction case C0 respect (D0; : : : ; ). sequence
cases (C1 ; : : : ; C ,1 ) exists Ci domain Di Ci+1 abstraction
case Ci respect (Di ; Di+1) 2 f0; : : : ; , 1g. proof induction
C also abstraction C0 respect (Dc , Da ) (see figure 13). basis
( = 1) obvious: C1 abstraction C0 respect (D0 ; D1) consequently also
abstraction respect (Dc , Da ). Now, assume lemma holds cases
domain ,1 . follows immediately C ,1 abstraction C0 respect
(Dc , Da ). Let C ,1 = hhs00; s0k i; o0i let intermediate states denoted s0r .

Definition 5 follows, state abstraction mapping ff sequence abstraction mapping
fi exists, ff(scfi(r)) = s0r r 2 f0; : : : ; kg. C abstraction C ,1
110

fiBuilding Refining Abstract Planning Cases












1










D0

Figure 13: Abstraction mappings hierarchies abstraction spaces
respect (D ,1 ; ), also exists state abstraction mapping ff0 sequence
abstraction mapping fi 0 ff0 (s0fi 0 (j ) ) = sj j 2 f0; : : : ; mg. Now,
define state abstraction mapping ff00(s) = ff0 (ff(s)) sequence abstraction mapping
fi 00(j ) = fi(fi0(j )). easy see, ff00 well defined state abstraction mapping
(s s0 ) ff(s) ff(s0) ) ff0 (ff(s)) ff0 (ff(s0 ))) fi 00 well defined sequence
abstraction mapping (fi (fi 0 (0)) = 0 ; fi (fi 0(m)) = fi (k) = n ; u < v , fi 0(u) < fi 0 (v ) ,
fi (fi 0 (u)) < fi(fi0(v))). Furthermore follows ff00(scfi 00 (j ) ) = ff0 (ff(scfi (fi 0(j )))) = ff0 (s0fi0(j ) ) = saj ,
leading conclusion C abstraction C0 respect (Dc , Da ). 2

Theorem 8 (Correctness completeness Pabs algorithm) complete SLDrefutation procedure used Pabs algorithm, Case Ca abstraction case Cc
respect (Dc ; Da) generic theory A, Ca 2 PABS(hDc ; Da; Ai; Cc).
Proof:

Correctness (\"): Ca returned Pabs, h(oa1 ; : : : ; oak); ff; fi 2 Paths holds 19
phase-IV. define state abstraction mapping ff(s) := fe 2 ff jRc [ [ ` eg,
which, together sequence abstraction mapping fi lead desired conclusion.
every operator oai, know construction phase-IV, hfi (i , 1); fi (i); oai; 2 G
holds. construction phase-III, conclude safi (i,1) [ Ra ` Preoai holds
consequently E [Ra ` Preoai also holds respective execution body
while-loop phase-IV. Since E ff0 ff holds ` monotonic derivation operator,
obvious ff(scfi (i)) [ Ra ` Preoai . Furthermore, `if all'-test, executed
oai
extension path, ensures (safi (i,1) \ ff ) ,!
(safi (i) \ ff ) holds. Together
oai
fulfillment precondition operator ff(scfi (i,1)) ,!
ff(scfi(i)).
Thus, shown, Ca correct abstraction respect Definition 5.
Completeness (\"): Assume, case Ca = hhsa0 ; sam i; (oa1; : : : ; oam)i abstraction Cc
based deductively justified state abstraction mapping. exists state ab19. Note ff refers set finally constructed termination while-loop. use ff
denote respective set construction loop.

111

fiBergmann & Wilke

oa


ff(scfi(i))
straction mapping ff sequence abstraction mapping fi ff(scfi (i,1)) ,!
holds 2 f1; : : : ; mg. Since ff deductively justified A, follows construction
phase-II, ff(sci,1 ) sai,1 . Since ` monotonic derivation operator, preconditon oai also fulfilled safi (i,1) . Furthermore, addlist operator fulfilled
ff(scfi (i)) consequently also fulfilled sai . construction phase-III,
guaranteed, hfi (i , 1); fi (i); oai; 2 G. Now, would like show, phase-IV:

exists sequence assignments variable Paths, h(); fi0; ff0i 2
Paths, h(oa1 ); fi1; ff1 2 Paths, : : : , h(oa1 ; : : : ; oam); fim; ffm 2 Paths ,
fik ( ) = fi( ) 2 f0; : : : ; kg
(ffk \ sal) ff(scl) l 2 f1; : : : ; ng
ffk Skl=1 Addoal .

proof induction i. induction basis obvious due initialization
Paths variable. Now, assume h(oa1 ; : : : ; oak); fik ; ffk 2 Paths (with k < m)
state execution phase-IV. Since, hfi (k); fi (k + 1); oak+1; 2 G holds
argued before, fi (k) = fik (k) induction hypothesis, selected operator sequence
tried extended oa = oak+1 body while-loop. Additionally,
know, E contains exactly sentences required proof precondition
oak+1 . Note, since SLD-resolution procedure assumed complete
oak+1 applicable ff(sck ), E required proof preconditition oa
E ff(scfi(k) ). Since ff deductively justified, 8e 2 E ; 8l 2 f1; : : : ; mg holds: e 2 ff(scfi (l))
scfi (l) [ Rc [ ` e. construction sal , 8e 2 E ; 8l 2 f1; : : : ; mg holds: e 2 ff(scfi (l))
e 2 sal . Consequently, E \ sal ff(scl ) l 2 f1; : : : ; mg. hand,
also know oak+1 leads ff(scfi (k+1) ). Consequently, Addoak+1 ff(scfi (k+1)). Following
argumentation above, conclude (Addoak+1 \ sal ) ff(scl )
l 2 f1; : : : ; mg. Consequently, ff0 = ffk [ E [ Addoak+1 holds ff0 \ sal ff(scl ). Now,
oa
conclude Paths extended oak+1 follows. Since ff(scfi ( ,1) ) ,!
ff(scfi ( ))
holds Addoa 2 ff0 (ff0 \ safi ( ) ) ff(scfi ( ) ), immediately follow
oa
(ff0 \ safi ( ,1) ) ,!
(ff0 \ safi ( ) ). Consequently, h(oa1 ; : : : ; oak; oak+1 ); ffk+1; fik+1 2 Paths
ffk+1 = ff0 fik+1 ( ) = fik ( ) = fi ( ) 2 f1; : : : ; kg fik+1(k + 1) = fi(k). So,
induction hypothesis fulfilled k + 1. Thereby, shown Ca returned
Pabs. 2

Acknowledgements
authors want thank Agnar Aamodt, Jaime Carbonell, Padraig Cunningham, Subbarao Kambhampati, Michael M. Richter, Manuela Veloso, well members
research group many helpful discussions remarks earlier versions paper. Particularly, want thank Padraig Cunningham carefully proof-reading
112

fiBuilding Refining Abstract Planning Cases

recent version paper. also greatly indebted anonymous JAIR reviewers helped significantly improve paper. research partially supported
German \Sonderforschungsbereich" SFB-314 Commission European
Communities (ESPRIT contract P6322, Inreca project). partners Inreca
AcknoSoft (prime contractor, France), tecInno (Germany), Irish Medical Systems (Ireland)
University Kaiserslautern (Germany).

References
Althoff, K. D., & Wess, S. (1992). Case-based reasoning expert system development.
Schmalhofer, F., Strube, G., & Wetter, T. (Eds.), Contemporary Knowledge Engineering amd Cognition. Springer, Heidelberg.
Anderson, J. S., & Farly, A. M. (1988). Plan abstraction based operator generalization.
Proceedings 7th International Conference Artifical Intelligence, pp. 100{104
San Mateo. Morgan Kaufmann.
Bacchus, F., & Yang, Q. (1994). Downward refinement eciency hierarchical problem
solving. Artificial Intelligence, 71, 43{100.
Bergmann, R. (1992a). Knowledge acquisition generating skeletal plans. Schmalhofer, F., Strube, G., & Wetter, T. (Eds.), Contemporary Knowledge Engineering
Cognition, pp. 125{133 Heidelberg. Springer.
Bergmann, R. (1992b). Learning abstract plans speed hierarchical planning.
Tadepalli, P. (Ed.), Proceedings ML92 Workshop Knowledge Compilation
Speedup Learning. University Aberdeen, Scotland.
Bergmann, R. (1992c). Learning plan abstractions. Ohlbach, H. (Ed.), GWAI-92 16th
German Workshop Artificial Intelligence, Vol. 671 Springer Lecture Notes
AI, pp. 187{198.
Bergmann, R. (1993). Integrating abstraction, explanation-based learning multiple
examples hierarchical clustering performance component planning.
Plaza, E. (Ed.), Proceedings ECML-93 Workshop Integrated Learning
Architectures (ILA-93) Vienna, Austria.
Bergmann, R., Pews, G., & Wilke, W. (1994). Explanation-based similarity: unifying
approach integrating domain knowledge case-based reasoning. Richter, M.,
Wess, S., Althoff, K., & Maurer, F. (Eds.), Topics Case-Based Reasoning, Vol. 837
Lecture Notes Artificial Intelligence, pp. 182{196. Springer.
Bergmann, R., & Wilke, W. (1994). Inkrementelles Lernen von Abstraktionshierarchien
aus maschinell abstrahierten Planen. Fensel, D., & Nakhaeizadeh, G. (Eds.),
Proceedings Workshop Maschinelles Lernen: Theoretische Ansatze und Anwendungsaspekte, No. 291. Institut fur angewandte Informatik und formale Beschreibungsverfahren, University Karlsruhe, Germany.
113

fiBergmann & Wilke

Blythe, J., Etzioni, O., & et al. (1992). Prodigy4.0: manual tutorial. Tech. rep.
CMU-CS-92-150, Carnegie Mellon University, Pittsburgh, PA.
Carbonell, J. G. (1986). Derivational analogy: theory reconstructive problem solving
expertise aquisition. Michalski, R. S., Carbonell, J. G., & Mitchell, T. M.
(Eds.), Machine learning: artificial intelligence approach, Vol. 2, chap. 14, pp.
371{392. Morgan Kaufmann, Los Altos, CA.
DeJong, G., & Mooney, R. (1986). Explanation-based learning: alternative view. Machine Learning, 1 (2), 145{176.
Etzioni, O. (1993). structural theory explanation-based learning. Artificial Intelligence,
60, 93{139.
Etzioni, O., & Etzioni, R. (1994). Statistical methods analyzing speedup learning.
Machine Learning, 14, 333{347.
Fikes, R. E., Hart, P. E., & Nilsson, N. J. (1972). Learning executing generalized robot
plans. Artificial Intelligence, 3, 251{288.
Fikes, R. E., & Nilsson, N. J. (1971). Strips: new approach application theorem
proving problem solving. Artificial Intelligence, 2, 189{208.
Friedland, P. E., & Iwasaki, Y. (1985). concept implementation skeletal plans.
Journal Automated Reasoning, 1 (2), 161{208.
Giordana, A., Roverso, D., & Saitta, L. (1991). Abstracting background knowledge
concept learning. Kodratoff, Y. (Ed.), Proceedings European Working Session
Learning (EWSL-91), Lecture Notes Artificial Intelligence, pp. 1{13 Berlin.
Springer.
Giunchiglia, F., & Walsh, T. (1992). theory abstraction. Artificial Intelligence, 57,
323{389.
Green, C. (1969). Application theorem proving problem solving. Proceedings
IJCAI-69, pp. 219{239 Washington, DC.
Holte, R., Drummond, C., Perez, M., Zimmer, R., & MacDonald, A. (1994). Searching
abstractions: unifying framework new high-performance algorithm.
Proceedings 10th Canadian Conference Artificial Intelligence, pp. 263{270.
Morgan Kaufmann Publishers.
Holte, R., Mkadmi, T., Zimmer, R., & MacDonald, A. (1995). Speeding problem solving
abstraction: graph-oriented approach. Tech. rep. TR-95-07, Computer Science
Dept., University Ottawa, Ontario, Canada.
Kambhampati, S., & Hendler, J. A. (1992). validation-structure-based theory plan
modification reuse. Artificial Intelligence, 55, 193{258.
114

fiBuilding Refining Abstract Planning Cases

Kambhampati, S., & Kedar, S. (1994). unified framework explanation-based generalization partially ordered partially instantiated plans. Artificial Intelligence, 67,
29{70.
Knoblock, C. A. (1989). theory abstraction hierachical planning. Proceedings
Workshop Change Representation Inductive Bias, pp. 81{104 Boston,
MA. Kluwer.
Knoblock, C. A. (1990). Learning abstraction hierarchies problem solving. Proceedings
Eighth National Conference Artificial Intelligence, Vol. 2, pp. 923{928 London.
MIT Press.
Knoblock, C. A. (1991). Search reduction hierarchical problem solving. Proceedings
9th National Conference Artificial Intelligence, Vol. 2, pp. 686{691 Anaheim,
CA.
Knoblock, C. A. (1993). Generating abstraction hierarchies: automated approach
reducing search planning. Kluwer Academic Publishers.
Knoblock, C. A. (1994). Automatically generating abstractions planning. Artificial
Intelligence, 68, 243{302.
Knoblock, C. A., Minton, S., & Etzioni, O. (1991a). Integrating abstraction
explanation-based learning PRODIGY. Proceedings 9th National Conference Artificial Intelligence, Vol. 2, pp. 541{546 Anaheim, CA.
Knoblock, C. A., Tenenberg, J. D., & Yang, Q. (1991b). Characterizing abstraction hierarchies planning. Proceedings 9th National Conference Artificial
Intelligence, Vol. 2, pp. 692{697 Anaheim, CA.
Kolodner, J. L. (1980). Retrieval Organizational Strategies Conceptual Memory.
Ph.D. thesis, Yale University.
Kolodner, J. L. (1993). Case-based reasoning. Morgan Kaufmann.
Korf, R. E. (1980). Toward model representation changes. Artifical Intelligence, 14,
41{78.
Korf, R. E. (1985a). Depth-first iterative-deepening: optimal admissible tree search.
Artifical Intelligence, 27, 97{109.
Korf, R. E. (1985b). Macro-operators: weak method learning. Artifical Intelligence,
26, 35{77.
Korf, R. E. (1987). Planning search: quantitative approach. Artifical Intelligence, 33,
65{88.
Korf, R. E. (1993). Linear-space best-first search. Artifical Intelligence, 62, 41{78.
115

fiBergmann & Wilke

Kramer, M., & Unger, C. (1992). Abstracting operators hierarchical planning.
Hendler, J. (Ed.), Proceedings International Conference AI Planning, pp.
287{288. Morgan Kaufmann.
Laird, J., Rosenbloom, P., & Newell, A. (1986). Universal Subgoaling Chunking:
Automatic Generation Learning Goal Hierarchies. Kluwer Academic Publishers, Norwell, MA.
Langley, P., & Allen, J. (1993). unified framework planning learning. Minton,
S. (Ed.), Machine Learning Methods Planning, chap. 10, pp. 317{350. Morgan
Kaufmann.
Lifschitz, V. (1987). semantics STRIPS. Reasoning Actions Plans:
Proceedings 1986 Workshop, pp. 1{9 Timberline, Oregon.
Lloyd, J. (1984). Foundations Logic Programming. Springer.
McAllester, D., & Rosenblitt, D. (1991). Systematic nonlinear planning. Proceedings
9th National Conference Artificial Intelligence, pp. 634{639.
Michalski, R. S. (1994). Inferential theory learning conceptual basis multistrategy
learning. Michalski, R., & Tecuci, G. (Eds.), Machine Learning: Multistrategy
Approach, No. 11, chap. 1, pp. 3{62. Morgan Kaufmann.
Michalski, R. S., & Kodratoff, Y. (1990). Research machine learning: Recent progress,
classification methods, future directions. Kodratoff, Y., & Michalski, R. S.
(Eds.), Machine learning: Artificial Intelligence Approach, Vol. 3, chap. 1, pp.
3{30. Morgan Kaufmann, San Mateo, CA.
Minton, S. (1988). Learning Search Control Knowledge: Explanation-Based Approach.
Kluwer, Boston, MA.
Minton, S. (1990). Quantitativ results concerning utility explanation-based learning.
Artifical Intelligence, 42, 363{391.
Minton, S., Carbonell, J. G., Knoblock, C., Kuokka, D. R., Etzioni, O., & Gil, Y. (1989).
Explanation-based learning: problem solving perspective. Artificial Intelligence,
40, 63{118.
Minton, S., & Zweben, M. (1993). Learning, planning scheduling: overview.
Minton, S. (Ed.), Machine Learning Methods Planning, chap. 1, pp. 1{30. Morgan
Kaufmann.
Mitchell, T. M., Keller, R. M., & Kedar-Cabelli, S. T. (1986). Explanation-based generalization: unifying view. Machine Learning, 1 (1), 47{80.
Mooney, R. J. (1988). Generalizing order operators macro-operators. Laird,
J. (Ed.), Proceedings 5th International Conference Machine Learning, pp.
270{283 San Mateo, CA. Morgan Kaufmann.
116

fiBuilding Refining Abstract Planning Cases

Mooney, R. J., & DeJong, G. F. (1985). Learning schemata natural language processing.
Proceedings IJCAI, pp. 681{687 Los Angeles, CA.
Mozetic, I. (1990). Abstraction model-based diagnosis. AAAI Workshop Automatic
Generation Approximations Abstractions, pp. 64{75 Boston, MA.
Newell, A., & Simon, H. (1972). Human Problem Solving. Prentice-Hall Englewood Cliffs,
NJ.
Paulokat, J., & Wess, S. (1994). Planning machining workpieces partial-order,
nonlinear planner. AAAI-Fall Symposium Planning Learning: Real
Applications.
Perez, M., & Carbonell, J. (1993). Automated acquisition control knowledge improve
quality plans. Tech. rep. CMU-CS-93-142, Carnegie Mellon University.
Pews, G., & Wess, S. (1993). Combining model-based approaches case-based reasoning
similarity assessment case adaptation diagnositc applications. Richter,
M. M., Wess, S., Althoff, K., & Maurer, F. (Eds.), Preprints First European
Workshop Case-Based Reasoning (EWCBR-93), Vol. II, pp. 325{328. University
Kaiserslautern, Germany.
Plaisted, D. (1981). Theorem proving abstraction. Artifical Intelligence, 16, 47{108.
Plaisted, D. (1986). Abstraction using generalization functions. Proceedings 8th
Conference Automated Deduction, Vol. 16, pp. 365{376.
Rosenbloom, P., & Laird, J. (1986). Mapping explanation-based learning onto SOAR.
Proceedings National Conference Artificial Intelligence, Vol. 2 Philadelphia, PA.
Sacerdoti, E. (1974). Planning hierarchy abstraction spaces. Artificial Intelligence,
5, 115{135.
Sacerdoti, E. (1977). Structure Plans Behavior, Vol. 5. American-Elsevier, New
York.
Schank, R. C. (1982). Dynamic Memory: Theory Learning Computers People.
Cambridge University Press, New York.
Schmidt, G. (1994). Modellbasierte, interaktive Wissensakquisition und Dokumentation von
Domaenenwissen. Ph.D. thesis, University Kaiserslautern, Germany.
Schmidt, G., & Zickwolff, M. (1992). Cases, models integrated knowledge acquisition
formalize operators manufacturing. Proceedings 7th Knowledge Acquisition
Knowledge-based Systems Workshop (Banff).
Shavlik, J., & O'Rorke, P. (1993). Empirically evluation EBL. Investigating ExplanationBased Learning, Vol. 5, chap. 7, pp. 222{294. Kluwer Academic Publishers.
Simon, H. (1975). functional equivalence problem solving skills. Cognitive Psychology,
7, 268{288.
117

fiBergmann & Wilke

Tenenberg, J. (1987). Preserving consistency across abstraction mappings. McDermott,
J. (Ed.), Proceedings 10th International Conference Artifical Intelligence,
pp. 1011{1014 Los Altos, CA. Morgan Kaufmann.
Tenenberg, J. (1988). Abstraction Planning. Ph.D. thesis, Computer Science Department,
University Rochester, New York.
Unruh, A., & Rosenbloom, P. (1989). Abstraction problem solving learning.
Proceedings International Joint Conference Artifical Intelligence-89, pp.
590{595 Detroit, MI. Morgan Kaufmann.
Veloso, M. M. (1992). Learning analogical reasoning general problem solving. Ph.D.
thesis, Carnegie Mellon University, Pittsburgh, PA.
Veloso, M. M. (1994). PRODIGY/ANALOGY: Analogical reasoning general problem
solving. Richer, M., Wess, S., Althoff, K., & Maurer, F. (Eds.), Topics CaseBased Reasoning, pp. 33{52. Lecture Notes AI, Vol. 837, Springer.
Veloso, M. M., & Blythe, J. (1994). Linkability: Examining causal link commitments
partial-order planning. Proceedings 2nd International Conference
Planning AI Systems AIPS-94.
Veloso, M. M., & Carbonell, J. G. (1988). Integrating derivational analogy general
problem solving architecture. Minton, S. (Ed.), Proceedings First Workshop
Case-Based Reasoning. Morgan Kaufmann.
Veloso, M. M., & Carbonell, J. G. (1993). Towards scaling machine learning: case
study derivational analogy PRODIGY. Minton, S. (Ed.), Machine Learning
Methods Planning, chap. 8, pp. 233{272. Morgan Kaufmann.
Wilke, W. (1993). Entwurf und Implementierung eines Algorithmus zum wissensintensiven
Lernen von Planabstraktionen nach der PABS-Methode. Projektarbeit, Universitat
Kaiserslautern.
Wilke, W. (1994). Entwurf, Implementierung und experimentelle Bewertung von
Auswahlverfahren fur abstrakte Plane im fallbasierten Planungssystem PARIS. Master's thesis, University Kaiserslautern, Germany.
Wilkins, D. (1988). Practical Planning: Extending classical AI planning paradigm.
Morgan Kaufmann.
Yang, Q., & Tenenberg, J. (1990). Abtweak: Abstracting nonlinear, least commitment
planner. Proceedings 8th National Conference Aritificial Intelligence, pp.
204{209 Boston, MA.

118

fiJournal Artificial Intelligence Research 3 (1995) 187-222

Submitted 5/95; published 10/95

Learning Membership Functions
Function-Based Object Recognition System
Kevin Woods

woods@bigpine.csee.usf.edu

Computer Science & Engineering
University South Florida
Tampa, FL 33620-5399

Diane Cook

cook@centauri.uta.edu

Computer Science & Engineering
University Texas Arlington
Arlington, TX 76019

Lawrence Hall
Kevin Bowyer

hall@waterfall.csee.usf.edu
kwb@bigpine.csee.usf.edu

Computer Science & Engineering
University South Florida
Tampa, FL 33620-5399

Louise Stark

stark@napa.eng.uop.edu

Electrical Computer Engineering
University Pacific
Stockton, CA 95211

Abstract

Functionality-based recognition systems recognize objects category level reasoning well objects support expected function. systems naturally
associate \measure goodness" \membership value" recognized object.
measure goodness result combining individual measures, membership values,
potentially many primitive evaluations different properties object's shape.
membership function used compute membership value evaluating primitive
particular physical property object. previous versions recognition system known Gruff, membership function primitive evaluations
hand-crafted system designer. paper, provide learning component
Gruff system, called Omlet, automatically learns membership functions given
set example objects labeled desired category measure. learning algorithm
generally applicable problem low-level membership values combined
and-or tree structure give final overall membership value.

1. Introduction
computer vision (CV) application involving recognition detection \objects", descriptions types objects recognized required. Object descriptions
explicitly supplied human \expert". Alternatively, machine learning techniques
used derive descriptions example objects.
advantages learning object descriptions examples rather
direct specification expert. Specifically, may dicult person

c 1995 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiWoods, Cook, Hall, Bowyer, & Stark

provide CV system accurate description object general enough
cover possible variations visual appearance different instances object.
example, two tumors medical images look exactly same. Similarly, would
cumbersome human provide CV system ranges possible values
different physical aspects chairs (i.e., possible surface areas
seating surface chair? seating surface supported?). Considerable
\tweaking" object description parameters may required human expert
order achieve satisfactory system performance. Machine learning techniques
used generate concepts consistent observed examples. examples
learning systems include C4.5 (Quinlan, 1992), AQ (Michalski, 1983). System
performance affected ratio number training examples number
features used describe examples, accuracy examples represent
\real-world" objects CV system may encounter.
function-based object recognition system example CV system
machine learning techniques useful development object descriptions.
function-based object recognition system recognizes object classifying one
generic object categories describe function object might serve
(Bogoni & Bajcsy, 1993; Brand, 1993; Di Manzo, Trucco, Giunchiglia, & Ricci, 1989; Kise,
Hattori, Kitahashi, & Fukunaga, 1993; Rivlin, Rosenfeld, & Perlis, 1993; Stark & Bowyer,
1991, 1994; Sutton, Stark, & Bowyer, 1993; Vaina & Jaulent, 1991). object category
defined terms functionality required object belongs category.
example, object category might defined as:
straight back chair ::= provides sittable surface & provides stability &
provides back support
indicating object classified straight back chair degree
satisfies conjunction three functional properties.
functional properties defined terms primitive evaluations
different aspects object's shape. example, candidate surfaces may checked
provides sittable surface evaluating whether appropriate width, depth
height support plane. many cases, unique ideal value
given aspect object's shape, instead range values considered
equivalent terms \goodness". example, anything 0.45 0.55 meters
might equally acceptable height seating surface. However, particular shape
measurement becomes small large, evaluation measure reduced.
Fuzzy set theory provides mathematical framework handling \goodness fit"
concept. case, fuzzy membership function transforms physical measurement (i.e.,
height object's surface ground) membership value interval [0,1].
membership value, evaluation measure, denotes degree object (or
portion object) fits primitive physical concept (i.e., well height
surface matches seating surface height typical chairs). Thus, separate measure
goodness produced primitive evaluation. measures combined
produce final aggregate measure goodness object.
Gruff system (Stark & Bowyer, 1991) function-based object recognition system
utilizes fuzzy logic, manner described, evaluate 3-D shapes. previous
188

fiLearning Membership Functions Object Recognition

versions Gruff, fuzzy membership functions embedded system
collectively hand-crafted refined produce best results large set example
shapes. membership functions ideal candidates learned examples using
machine learning approach.
paper, present method automatically learning collection fuzzy
membership functions set labeled example shapes. Due system constraints
imposed Gruff, general-purpose machine learning algorithms, neural networks,
genetic algorithms, decision trees, readily applicable. Thus, new special-purpose
learning component, called Omlet, developed. Omlet tested synthetic
data two different object categories (chairs cups), data collected
human evaluations physical chairs. Results presented show (a) learning
membership functions way provides level recognition performance equivalent
obtained \hand-tweaked" Gruff, (b) learning method compatible
human interpretation shapes. approach generally applicable
system set primitive evaluation measures combined produce
overall measure goodness final result.
paper organized follows. Section 2 discusses related work, justifies need develop special-purpose learning component. Section 3 introduces
Gruff object recognition system. Section 4 presents new learning component, called
Omlet. point, state material Section 3 previously
published, presented facilitate understanding new learning component. Although Omlet specifically \tailored" add-on learning component
Gruff system, applies data structure used systems.
general, Omlet described system learning context fuzzy
And/Or categorization tree. point reader questions concerning Gruff's
object recognition paradigm references provided. Section 5 describes experimental design data sets utilized. Section 6 documents experimental results
gives analysis them. Finally, Section 7 summary paper given
conclusions drawn.

2. Related Work
two ways learning might used ease construction systems
Gruff. first rules (or proof tree) make Gruff could built
inductive learning system. C4.5, decision tree learner (Quinlan, 1992), good example
class learning systems. However, types inductive classification systems
cannot adequately replace functionality Gruff/Omlet system. Omlet allows
examples less perfect membership class used training.
direct way accomplish system C4.5. decision-tree based system
would probably require different trees trained parent child categories.
functional concepts (provides sittable surface, example) would get lost training
process individual features chair directly used. could train series
trees learn functional concepts individually, train decision tree combine
results. approach parameters membership functions learned
paper would learned implicitly construction decision tree functional
189

fiWoods, Cook, Hall, Bowyer, & Stark

concept resulting rules. Replacing Gruff/Omlet decision tree
general-purpose rule learner possible, would require extensive work preserve
idea functional object recognition.
Omlet aimed second area Gruff-like system could benefit
learning, tuning membership functions. knowledge primitive might
sittable surface. Given measurements specific surface object specific orientation, necessary develop representation acceptable bounds measurements
determine whether surface area sittable.
Techniques areas machine learning used represent learn
probabilistic fuzzy membership functions. example, belief networks provide mechanism representing probabilistic relationships features domain. Individual
feature probabilities combined generate probability complex concept
propagating belief values constraints network. Adaptive probabilistic networks kind belief nets learn individual probability values distributions using gradient descent (Pearl, 1988; Cooper & Herskovits, 1992; Spiegelhalter, Dawid,
Lauritzen, & Cowell, 1993). structure belief nets update algorithms
similar approaches found Omlet. However, Omlet incorporates symbolic theorem proving, feature fundamental performing function-based object recognition,
well value propagation.
Similar research performed learn fuzzy membership functions using adaptive techniques genetic algorithms classifier systems (Parido & Bonelli, 1993;
Valenzuela-Rendon, 1991). Much work used learn individual membership functions cannot handle combinations input. again, little work
directed learning fuzzy memberships context rule-based system. Additional refinement techniques reinforcement learning (Mahadevan & Connell, 1991;
Watkins, 1989), neural networks, statistical learning techniques also used
refine confidence values.
project represents new direction computer vision machine learning research; namely, integration machine learning computer vision methods learn
fuzzy membership functions function-based object recognition system. Although learning functions rule-based context novel effort, similar research performed area refining certainty factors intelligent rule bases. example,
Mahoney Mooney (1993) Lacher et al. (1992) use backpropagation algorithms
adjust certainty factors existing rules order improve classification given set
training examples. contrast Omlet's approach, systems refine values
represent measure belief given result adjusted according combination
functions certainty factors. Omlet's measures represent degrees fuzzy membership
object class, refinement method propagates error And/Or tree.
work Wilkins (1994) focuses revising probabilistic rules classification expert system. Probabilistic weights applied rule, indicating strength
evidence supplied rule. However, refinements rule occur form
modifying applicability rule generalizing, specializing, deleting adding
rules, instead automatically refining weight rule. authors avoid automatic
refinement weights resulting rule base may interpretable experts.
190

fiLearning Membership Functions Object Recognition

Towell Shavlik (1993) convert set rules representation suitable
neural net, train network re-extract refined rules. initial network
set chain rules. extracted rules necessarily clear
functional meaning approach aims preserving.
several new approaches learning tuning fuzzy rules (Ishibuchi, Nozaki,
& Yamamoto, 1993; Berenji & Khedkar, 1992; Jang, 1993; Jang & Sun, 1995) use
genetic algorithms specialized kinds neural networks, making use reinforcement
learning. approaches might provide alternative way learn membership values
provided initial functional rules given fuzzy rules. However, modifications
learning approaches would needed normally work domains without rule
chaining hierarchies rules Gruff/Omlet.

3. Gruff Object Recognition System
Gruff acronym stands Generic Representation Using Form Function (Stark
& Bowyer, 1991). Gruff recognition system takes 3-D shape description input,
reasons whether shape could belong object categories known
Gruff, outputs interpretation category object could belong.
\interpretation" specified orientation labeling parts shape
identified satisfying functional properties. See Figure 1 example
interpretation.
GRUFF Input

GRUFF Output

Provides
Sittable
Surface

Provides
Stable
Support

Figure 1: Gruff interpretation 3-D shape category conventional chair. Elements shape labeled functional property provide.

191

fiWoods, Cook, Hall, Bowyer, & Stark

3.1 Knowledge Primitives

Gruff's reasoning shape performed using \low level" procedural knowledge
implemented set knowledge primitives . knowledge primitive represents
primitive physical property concerning shape, physics, causation. knowledge
primitive takes (specified portions a) 3-D shape description input, along
values parameters primitive, returns evaluation measure 0
1. evaluation measure represents well shape element satisfies particular
invocation primitive.
knowledge primitives used Gruff recognize chairs (Stark & Bowyer, 1991,
1994; Sutton et al., 1993):
1. relative orientation (normal one, normal two, range parameters)
primitive determines angle normals two surfaces (normal one normal two) falls within desired range.
2. dimensions ( shape element, dimension type, range parameters )
primitive used determine dimension (e.g. width depth)
surface lies within specified range.
3. proximity ( proximity type, shape element one, shape element two )
primitive used check qualitative relations shape elements,
, close .
4. clearance ( object description, clearance volume )
primitive used check specified volume unobstructed free space
location relative particular part shape.
5. stability ( shape, orientation, applied force )
primitive used check given shape stable placed
supporting plane given orientation (possibly zero) force applied.
first two knowledge primitives include four range parameters: z 1 (stands
1st zero point), n1 (1st normal point), n2 (2nd normal point), z 2 (2nd zero point).
parameters used define trapezoidal fuzzy membership function, Figure 2,
calculating evaluation measure invocation primitive. last three
knowledge primitives range parameters. return evaluation measure
1 0 depending whether primitive physical property satisfied.
Trapezoidal membership functions ect desire name (categorize) objects
manner compatible human naming. typically non-trivial range
\ideal" value many physical properties related functionality. example,
unique value mean sittable surface area population chairs, value
one would rate perfect \1.0" sittability. Reasonable deviations
result decrease sittability. sittable surface area falls outside ideal
range (i.e., z 1 n1, n2 z 2 Figure 2), evaluation measure
reduced, indicating surface provides less perfect (but still functional) sittable
192

fiLearning Membership Functions Object Recognition

1.0
Evaluation
Measure

0.0

z1 = least

z2 = greatest
n1 = low ideal n2 = high ideal

Physical Measurement Particular Property

Figure 2: Fuzzy membership function returns evaluation measure primitive physical
property.

area. Finally, area falls outside range values (less z 1, greater
z 2 Figure 2), surface longer function sittable portion chair,
evaluation measure 0 returned.

3.2 Category Definition Tree

Gruff's knowledge different object categories implemented category definition

tree , leaves represent invocations knowledge primitives. category
definition tree chair category illustrated Figure 3.
node category definition tree may two subtrees. One subtree gives
definition category terms list functional properties. chair example,
object must satisfy functional properties stability provides sittable surface order
considered member category conventional chair. functional property
may defined terms multiple primitives. evaluation measures individual
primitives combined (in manner discussed shortly) determine well
functional properties satisfied. functional property measures
combined arrive overall evaluation measure category node.
subtree defines subcategory. subcategory specialization parent
(or superordinate) category, thus provides detailed elaboration definition
parent. subcategory node subtree functional properties required
addition parent category. example, Figure 3, subcategory
straightback chair specialization conventional chair additional functional
requirement provides back support. overall evaluation measure subcategory node
combination parent category evaluation measure evaluation measure
associated additional functional properties. Figure 3, overall measure
subcategory straightback chair combination measures conventional
193

fiWoods, Cook, Hall, Bowyer, & Stark

Name: CHAIR
Node
(SUB)CATEGORY
Type:
Funtional Subcategory
Definition
Trees

Name: CONVENTIONAL
CHAIR
Node
Type:(SUB)CATEGORY

Name:

Node
Type:(SUB)CATEGORY

Funtional Subcategory
Definition
Trees

Name: PROVIDES
SITTABLE SURFACE
Node
FUNCTIONAL
Type:
PROPERTY

PROVIDES
Name:
STABLE SUPPORT
Node
FUNCTIONAL
Type:
PROPERTY

Name:
Node
Type:

Funtional Subcategory
Definition
Trees
Name: PROVIDES
STABLE SUPPORT
Node
FUNCTIONAL
Type:
PROPERTY

Name: STRAIGHTBACK
CHAIR
Node
Type:(SUB)CATEGORY
Funtional Subcategory
Definition
Trees

PROVIDES
BACK SUPPORT
FUNCTIONAL
PROPERTY

LOUNGE
CHAIR

PROVIDES
Name:
LOUNGING SITTABLE SURFACE
Node
Type:

RECLINER

Node
Type: (SUB)CATEGORY
Funtional
Definition

Subcategory
Trees

FUNCTIONAL
PROPERTY
Name: PROVIDES
LOUNGING BACK SUPPORT
Node
FUNCTIONAL
Type:
PROPERTY

Name: ARMCHAIR

Name:

Name: PROVIDES
LOUNGING ARM SUPPORT
Node
Type:

FUNCTIONAL
PROPERTY

Node
Type:(SUB)CATEGORY
Funtional Subcategory
Definition
Trees

Name: PROVIDES
ARM SUPPORT
Node
Type:

FUNCTIONAL
PROPERTY

Figure 3: Category definition tree basic level category chair.
chair node provides back support subtree. Note subcategory measurements
contribute cumulative measure parent category. may multiple levels
subcategories, conventional chair, straightback chair, armchair Figure 3.
Category nodes associated functional properties (such root node
chair Figure 3) associated evaluation measures. nodes used
set control structure function-based definition. However, provide
category definition since object member subcategory automatically
member predecessor categories. example, Figure 3, object belongs
subcategory straightback chair also belongs categories conventional chair
chair. superordinate category furniture could added chair category (Stark
& Bowyer, 1994).
194

fiLearning Membership Functions Object Recognition

3.3 Combination Evidence

evaluation measures returned primitive invocations functional property
node combined using T-norm:

(a; b) = b
b measures combined. T-norm commonly referred
probabilistic (Pand) function (Bonissone & Decker, 1986). immediate parent
category node directly receives associated measure combining measures
functional property nodes using T-norm.
example, functional property provides sittable surface defined six primitives. simplicity, we'll denote evaluation measures returned six primitives
p1 p6. functional property stability defined single primitive,
also returns evaluation measure (p7). determine overall evaluation measure
shape category conventional chair compute
conventional chair ::= provides sittable surface Pand stability


provides sittable surface ::= p1 Pand p2 Pand p3 Pand p4 Pand p5 Pand p6


stability := p7

Since definition (sub)category conjunction required functional properties, cumulative measure dominated \weakest link" individual
primitive evaluation measures, property Pand function. So, evaluation measure
0 one primitive physical property result cumulative evaluation measure
0. evaluation measure 1 indicates primitive physical property
ideally satisfied, shape may belong object category. final result depends
evaluation primitive physical properties.
would seem category could simply defined knowledge primitives without using notion functional properties. functional property level
introduced representation hierarchy two reasons. First, subgroupings
functional properties intuitively follow levels named categorization typical human
concepts function. Secondly, functional property evaluations result labeling
functional elements object (i.e., portions structure) fulfill
functional requirement.
Since subcategory definition represents increasingly specialized definition, evidence belonging subcategory result increased measure object
belonging subcategory opposed parent category. combination
functional property measurement subcategory node, a, parent node's
evaluation measure, b, computed using T-conorm:

(a; b) = + b , b
195

fiWoods, Cook, Hall, Bowyer, & Stark

T-conorm commonly referred probabilistic (Por) function (Bonissone
& Decker, 1986). T-conorm used combine measures subcategory node,
final subcategory evaluation measure actually computed as:

(

> T;
Esubcategory = 0S;(a; b); ifotherwise
:
user defined threshold. Thus, functional property measurement
subcategory node, a, must greater minimum order shape receive
non-zero evaluation measure subcategory. purposes work, value
= 0 assumed, indicating shape assigned subcategory long
non-zero evidence meets additional functional requirements associated
subcategory. practice, final classification decision might require much stronger
evidence, say = 0:7, shape assigned subcategory.
example, determine overall evaluation measure shape category
straightback chair, first compute overall evaluation measure category conventional chair, previously described. functional property provides back support defined 8 primitives. Denoting measurements returned 8 primitives p8
p15, overall evaluation measure (assuming measure provides back support > )
category straightback chair computed as:
straightback chair ::= conventional chair Por provides back support

provides back support ::= p8 Pand p9 Pand p10 Pand p11 Pand p12
Pand p13 Pand p14 Pand p15

object function straightback chair also definition function
conventional chair. T-conorm give object higher evaluation measure
subcategory straightback chair since evidence addition \minimal"
amount evidence required shape belong parent category conventional
chair. Thus, Gruff performs recognition shape selecting (sub)category
highest overall evaluation measure. correspond specific applicable
subcategory. One exception occurs parent category evaluation measure
1 non-zero evidence supporting subcategory functional requirements.
case, T-conorm assigns evaluation measure 1 category
subcategory.
particular T-norm/T-conorm pair utilized paper chosen among
representative T-norm/T-conorm possibilities (including non-probabilistic formulations) described Bonissone Decker (1986) analyzing performance conjunction
Gruff across set example shapes (Stark, Hall, & Bowyer, 1993a).

4. OMLET Learning System

section, describe Omlet learning (sub)system. Omlet learns fuzzy membership functions, located leaves And/Or categorization tree, sets
196

fiLearning Membership Functions Object Recognition

training examples. Omlet works together Gruff automatically learn object
category definitions use definitions recognize new objects.
training mode, Omlet uses examples learn fuzzy ranges primitive
measurements. training example consists object description coupled
desired overall evaluation measure. testing mode, Omlet uses previously learned
ranges act function-based object recognition system. Knowledge primitives form
building blocks Omlet system, rules make representation language.
rules, fixed, derived Gruff's category definition tree. indicate
1) knowledge primitives combined define functional properties, 2)
functional properties combined give function-based definition object
category.
Given training example, Omlet uses rules construct general proof tree
example's given object category. proof tree simply data structure mimics
way Gruff combines primitive evaluation measures. proof tree also maintains
primitive ranges modified learning algorithm. example proof tree
generated rules define object conventional chair category shown
Figure 4. proof trees contain knowledge primitives defined using
range parameters. knowledge primitives return 0/1 measures,
primitive membership function learn. training example must satisfy
\binary", necessary, functional properties return evaluation measures 1
order example member given category. example, Figure 4,
left branch top Pand node represents functional property provides stable support.
functional property defined single knowledge primitive range
parameters. Therefore, input Pand node fixed always return 1.
Omlet obtain overall evaluation measure example object, physical
measurements shape elements object input primitive fuzzy membership functions leaves proof tree. output leaf node represents
evaluation measure individual functional property. evaluation measures
combined internal nodes tree using probabilistic T-norm/T-conorm
combiners described Section 2.3. overall evaluation measure input example
output root node (see Figure 4).
Input Omlet consists set goals specific examples object (sub)categories.
goal includes example's (sub)category, elements 3-D shape fulfill
functional properties, overall desired evaluation measure greater 0
(otherwise object example object category). Figure 5 shows example
goal conventional chair object.
Using training examples, Omlet attempts learn ranges used trapezoidal
membership functions associated knowledge primitive definitions (see Figure 2).
training example presented, Omlet attempts prove via rule base
object member specified category. Here, check make sure physical
elements object listed goal satisfy binary, necessary, functional properties.
So, conventional chair training example, Omlet checks given orientation
stable, given seating surface accessible (clearance front above) meets
minimum width depth ratio. necessary functional properties satisfied,
proof tree constructed. actual overall evaluation measure calculated
197

fiWoods, Cook, Hall, Bowyer, & Stark

Rules Conventional Chair

Conventional Chair
Evaluation Measure
= 0.572
PAND

(conventional_chair ?a ?b ?c) ::=
(provides_sittable_surface ?a ?b ?c) PAND
(provides_stable_support ?a)
(provides_sittable_surface ?a ?b ?c) ::=
(dimensions AREA range_parameters ?b) PAND
(WIDTH/DEPTH 1.0 ?b) PAND
(dimensions CONTIGOUS SURFACE range_parameters ?b) PAND
(dimensions HEIGHT range_parameters ?b) PAND
(clearance ?a ?b) PAND
(clearance IN_FRONT ?a ?c)
(provides_stable_support ?a) ::=
(stability SELF ?a)

1.0
0.572

Binary functional property
"provides stable support"
fixed always return 1

?b
?c

PAND

?a

0.763

1.0

Height = 0.67

0.750
Contiguous
Surface = 1.0

Area = 0.116

Knowledge primitives ranges used
compute evaluation measures functional
property "provides sittable surface".

Figure 4: simplified proof tree constructed learning example category
conventional chair. ?a, ?b, ?c symbols rules represent physical
aspects shape used rules. orientation shape, face
sittable surface, front edge sittable surface substituted
?a, ?b, ?c, respectively. way Omlet knows elements
shape \measured" evaluated knowledge primitives.
198

fiLearning Membership Functions Object Recognition

( conventional_chair mchair.00.orientation2 mchair.00.face2 mchair.00.edge1-8 )

Object Category

Object Orientation

Sittable Surface

Front Edge
Sittable Surface

0.9808

Desired
Evaluation
Measure

Functional Properties

Figure 5: Training goal input Omlet conventional chair object.
manner described above. actual evaluation measure suciently different
desired evaluation measure, primitive fuzzy membership functions
included definition need adjusted.
Primitive membership functions adjusted propagating overall error
training sample nodes proof tree way attempts give
leaf node (i.e., range) portion error. range parameters (z 1, n1, n2,
z 2) define fuzzy membership trapezoids adjusted attempt
reduce total error examples training set. next subsections provide
details Omlet learning algorithm. First, discuss method calculating
error value propagating proof tree. Next, present method
making initial estimates parameters membership function. describe error
propagation first utilized initialization phase. describe
Omlet makes adjustments membership functions attempt reduce error
entire training set. last subsection describes general learning paradigm
provides theoretical justification implementation.

4.1 Error Propagation

error training example defined difference desired evaluation
measure actual evaluation measure computed current state Omlet
system. fraction error (defined \learning rate") propagated proof
tree Pand Por nodes. Error propagation Pand Por nodes
handled differently. error three element Pand node E , three
elements receive portion error equal cube root E (i.e., inverse
Pand function). Por node, full amount error, rather equal share,
propagated link. rationale treatment error become clear
Section 4.4.
noted desired evaluation measure fed root tree
propagated leaves, error directly computable since actual
projected desired values always known node. actual values node
computed physical measurements object shape fed leaf
199

fiWoods, Cook, Hall, Bowyer, & Stark

Desired = 0.6
PAND
Actual = 0.35

Desired = .795

Desired = .754

PAND

PAND

Actual = .612

Actual = .571

Actual = .85

Actual = .72

Desired = .959

Desired = .829

Actual = .81

Actual = .85

Actual = .83

Desired = .891 Desired = .911 Desired = .931

Figure 6: Example error propagation Pand tree. Actual values found
overall evaluation measure computed object. Desired values
propagated tree, error computed Desired , Actual.
nodes combined produce overall evaluation measure root. projected
desired values proof tree obtained propagating desired evaluation measure
root node leaves. example, given two input Pand node
actual inputs a1 a2, actual output a1 a2 (from T-norm section
2.3). desired output node D, compute desired inputs
node d1 d2 solving following set equations:

a1 a2 , d1 d2 = ,


a1 , d1 = a2 , d2

(1)

(2)
first equation computes error Pand node1, second equation assures
equal portions error assigned input. Figure 6 shows example
desired values computed via Equations 1 2 every node proof tree. figure,
known desired overall measure = 0:6 top Pand node, actual
measure = 0:35 computed Pand actual node inputs, a1 = 0:612
a2 = 0:571. Using Equations 1 2, easily compute two unknown desired
inputs d1 d2 top Pand node (which also desired outputs bottom
1. equivalent simpler equation d1 d2 = could substituted here.
200

fiLearning Membership Functions Object Recognition

two Pand nodes) 0:795 0:754, respectively. three inputs Pand node,
solve set three linear equations derive desired inputs.
three inputs Pand node, divide set inputs recursively groups
two three solve set two three linear equations, respectively.
Since Por nodes used combine single parent category measure single
aggregate measure subcategory's functional properties, never
2 inputs type node. Therefore, full amount error propagated
Por node simply solving independent equations:
a2 + d1 , a2 d1 =
(3)

a1 + d2 , a1 d2 =
(4)
Eventually, portion overall error propagated ranges defined
trapezoid membership functions. error reaches individual ranges
training example, input primitive membership function (i.e., x axis value)
desired primitive evaluation measure (the axis value) define point
lie somewhere trapezoid. also note leg trapezoid point belongs
to, based side normal portion range [n1,n2] x value lies.
set desired points leg used make adjustments trapezoid
attempt reduce error. Omlet collects desired points leg
membership function propagating error training examples
proof trees. trapezoid/range parameters (z 1,n1,n2,z 2) adjusted end
training epoch. Training continues fixed number epochs satisfactory
level performance, defined minimal classification error rate averaged training
set, achieved.

4.2 Initial Estimate Measurement Functions

Omlet's learning algorithm begins making reasonable initial estimates fuzzy trape-

zoid membership functions physical measurements. accomplished assigning actual values 0 membership functions training example propagating errors (which case would equal desired evaluation measures)
ranges leaf nodes proof trees. collections desired
points, make initial estimate trapezoidal membership function.
important stage place edges constructed normal range (the n1 n2
range parameters) somewhere within actual normal range. learning algorithm
make adjustments n1 n2 points subsequent training epochs. Additionally,
Omlet may set minimum maximum limits values range parameters
(more shortly).
training example desired evaluation measure 1 considered \perfect"
example object given category. Perfect training examples desirable
training set primitive measurements perfect examples known fall
range [n1,n2]. example, conventional chair training example desired
evaluation measure 1, know membership functions proof
tree (see Figure 4) must return values 1. result Pand function
greater minimum input.
201

fiWoods, Cook, Hall, Bowyer, & Stark

Omlet examines set desired points propagated range
definition tree determines \limit" points. defined follows.
two desired points values (memberships) 1, least segment normal
range [n1,n2] known. n1 range parameter set minimum x value desired
points values 1. Similarly, n2 parameter set maximum x value
desired points values 1. Note one desired point found
n1 n2 set value, membership function initially triangular.
Since portion normal range known correct, upper limit set
n1 value lower limit set n2 value assure known segment
normal range reduced subsequent training. Since training examples
desired membership values greater 0, know x input values must lie
z 1 z 2. Omlet uses minimum maximum x values set
desired points set limits z 1 z 2 range parameters. z 1 range parameter
never permitted increase minimum x value training. Similarly, z 2
value may never decrease maximum x value set desired points. Figure 7
shows range parameters (limit points) Omlet sets initialization phase given
set 10 examples.
p4

p5

p6

1.0
p3
p7

p8

p2
p9
0.0

p1
Maximum
z1 value
Allowed

Maximum
n1 value
Allowed

Minimum
n2 value
Allowed

p10
Minimum
z2 value
Allowed

Figure 7: Range parameter limits may set initializing range parameters.
limits range parameters serve several purposes. First, limits assure
perfect training examples assigned evaluation measures less 1,
training examples evaluation measures greater 0. importantly,
limiting changes made range parameters, better approximations
desired membership functions learned. subsequent learning, error
propagated proof tree assumption equal amounts error come
input node. assumption always valid, way
directly determine portion error belongs input. error propagated
membership function would cause change one range parameters
(z 1,n1,n2,z 2) moves parameter past set limit, portion overall error
assumed caused membership function correctly estimated.
202

fiLearning Membership Functions Object Recognition

occurs parameter set equal limit, effectively reducing degree
changes membership function would compensate overall error.
allow learning algorithm find good solution case different membership
functions contribute different amounts error.
segment normal range known membership function, initialization range parameters straight-forward. n1 n2 values already
set. z 1 value set simply making left leg trapezoid pass
point (n1,1.0) point set desired points minimum x value.
Similarly, z 2 value set making right leg trapezoid pass point
(n2,1.0) desired point maximum x value. points
left (right) n1 (n2) point, membership function assumed one-legged
(as CONTIGUOUS SURFACE Figure 4) parameters n1 z 1 (n2 z 2)
extended large negative (positive) value permitted change
training.
portion normal range membership function determined,
attempt fit trapezoid set desired points. First, two desired points
maximum values found. assume normal range lies somewhere
them. best-fit trapezoid determined varying n1 n2 range parameters
assumed normal range, selecting normal range [n1,n2] produces lowest
error set desired points. error sum absolute values
difference desired value actual value found point. z 1
(z 2) range parameter set manner before, left (right) trapezoid
leg forced pass desired point minimum (maximum) x value.
n1 value varied leftmost point assumed normal range rightmost
point small increments. different value n1, n2 value varied n1
rightmost point assumed normal range small increments. So, simply
testing range possible trapezoids (with degree accuracy, number trapezoids
tested, defined increments n1 n2 varied) normal range
[n1,n2] somewhere within assumed normal range. select set range
parameters minimize total error set training examples. use
best-fit trapezoid approach helpful, initial way accurately associate
error given trapezoid.

4.3 Adjusting Membership Functions

make adjustments membership trapezoid, leg trapezoid fit set
desired points using least squares line fit. Recall every training epoch
set desired points leg trapezoid. new z 1 (z 2) value
trapezoid set point left (right) leg intersects 0. new n1 (n2)
value set midway old n1 (n2) value value left (right)
leg fitted line intersects = 1. new n1 n2 values directly set
fitted trapezoid legs intersect 1 overestimating normal range [n1,n2]
eliminate desired points used least squares line fit
trapezoid leg. Desired points normal [n1,n2] range definition fall
leg trapezoid, used adjusting trapezoid legs. Therefore,
normal range overestimated, points truly belong trapezoid leg used
203

fiWoods, Cook, Hall, Bowyer, & Stark

adjust leg. gradually moving normal points n1 n2, Omlet better able
converge appropriate solution. new range parameter values (z 1,n1,n2,z 2)
determined, Omlet checks make sure none lie outside limits
may set initialization phase. Restrictions new range parameters
assure membership functions remain trapezoidal (or triangular n1 = n2). First,
z 1 must less equal n1. Similarly z 2 must greater equal n2.
z 1 (z 2) greater (less) n1 (n2) z 1 (z 2) set equal n1 (n2). Also, n1 must
less equal n2. case single point set desired
points trapezoid leg, leg defined normal point leg (n1 left
leg n2 right leg) single desired point.
training data may provide target points portion trapezoid
ranges. Omlet capable detecting situation observing slope
fitted line, adjusting membership function appropriately. slope left
trapezoid leg positive slope right leg negative.
slope fitted trapezoid leg nearly horizontal (close 0.0), sign slope
opposite expected, normal point leg moved (again, n1
left leg n2 right leg) outward. adjustment allows Omlet learn
one-legged membership functions, handle (as well possible) situations
enough training data available.
method escaping local minima empirically found useful. Normally Omlet
allow trapezoid leg change change causes increase total error
training set. So, possible zero, one trapezoid legs range
get adjusted epoch. learning slows suciently, Omlet temporarily
allow trapezoid leg changes cause increase overall error hopes escaping
possible local minima. precisely, total training set error one epoch decreases
less specified threshold, range changes cause increase overall error
permitted next training epoch.

4.4 Training Approach

order learn various subcategories defined category definition tree,
utilize machine learning approach based assumption human learning
known one disjunct per lesson (Lehn, 1990). Perhaps easiest understand
mechanics learning approach explain one-disjunct-per-lesson assumption
terminology cognitive science. Since many terms machine learning
derived cognitive sciences, dicult show similarities
algorithm characterization human learning. also examine
computational characteristics learning algorithm support choice
approach.
4.4.1 One Disjunct Per Lesson

Van Lehn (1990) tells us effective way teaching complicated concepts
build simple subconcepts, opposed \all-at-once" approach.
purposes, disjunct considered one simple subconcepts. lesson consists
uninterrupted sequence demonstrations, examples, exercises. length
lesson varies. Thus, might expect human better understand concept
204

fiLearning Membership Functions Object Recognition

armchair presenting series lessons, introduces single new subconcept
builds upon previous subconcepts. example, first lesson teaches concept
conventional chair requires stable sittable surface correct orientation.
learn constitutes straightback chair, build upon concept conventional
chair introducing subconcept back support second lesson. So, second
lesson broadens notion chairs, general. Finally, third lesson builds upon
understanding straightback chair introducing subconcept arm support.
contrast, all-at-once approach may try explain armchair provides stable
sittable surface correct orientation back arm support. Here,
trying teach three subconcepts one time, show three subconcepts
together form complex concept armchair. Indeed, Van Lehn (1990) cites
laboratory studies indicate learning task dicult
one disjunct (subconcept) taught per lesson.
chosen utilize machine learning algorithm underpinnings similar
Van Lehn's one-disjunct-per-lesson assumption. case, concepts subconcepts
represented categories subcategories. lesson algorithm consists
numerous epochs training examples one (sub)category. Thus, lesson
viewed uninterrupted sequence positive examples \teach" functional
requirements single (sub)category. length, number training epochs,
lessons may vary depending subcategory learned. learn ranges
category definition tree, begin learning simplest concepts first. learn
additional complex subconcepts building upon notion simple concept. example simplified proof tree Figure 8, parent category conventional
chair learned attempting learn subcategory (specialization) straightback
chair. Since subcategory straightback chair parent category, learned
attempting learn even complex subcategory armchair. remainder
subsection discusses implementation finer detail.
implementation standpoint, simplest concepts functional properties
associated categories directly linked root node category
definition tree provides sittable surface provides stable support category
conventional chair. first lesson, use positive examples \first level" (or
parent) categories learn membership functions associated categories.
first level categories learned, membership functions \frozen"
permitted change subsequent lessons.
second lesson, membership functions \second level" categories
(i.e., subcategories first level categories definition tree) learned.
Figure 8, membership functions belong node provides back support subcategory straightback chair. learned \simple" functional concept associated
parent category, values computed parent category node assumed
reasonably accurate. example, actual values proof tree computed
straightback chair training example, actual values emanating parent category
node conventional chair accurate since concepts associated node
already learned. is, evaluation measures functional properties
provides sittable surface provides stable support straightback chair example assumed correct. implies membership functions making functional
205

fiWoods, Cook, Hall, Bowyer, & Stark

arm_chair
POR
Example subcategory
learned
parent category

provides_arm_support
PAND

straight_back_chair
POR

...
Example
"parent category"

conventional_chair
PAND

provides_back_support
PAND

...

...

Figure 8: Simplified proof tree armchair object.

requirement subtree (i.e., provides back support) responsible entire error
subcategory training example. (This explains Equations 3 4 used propagate
error Por nodes.) Hence, error propagated modifiable leaves
functional requirement node Pand subtree learning continues before.
lessons continue parent category learned subcategories learned, subcategories learned. freezing parent category
membership functions learned, applying one-subconceptper-lesson strategy. Figure 8 learning straightback chair, membership functions branch frozen armchair subcategory learned modifying
membership functions provides arm support branch proof tree.
Omlet begins learning evaluating rule base order determine subcategory
dependencies assigns (sub)category definition tree level learning
hierarchy. example, Omlet determines category conventional chair parent category membership functions learned immediately (level 1). However,
evaluation measure subcategory straightback chair dependent parent
category conventional chair. straightback chair subcategory assigned learning
level 2. Subcategory armchair dependent parent category straightback chair,
therefore assigned learning level 3.
206

fiLearning Membership Functions Object Recognition

4.4.2 Practical Justification

order understand taken one-disjunct-per-lesson approach rather
all-at-once approach, let's make observations concerning accurately blame
assignment error determined typical training example.
Recall error propagation proof tree involves projecting desired node input
values known node output value. Consider Pand node known desired output
0.9, two unknown inputs. know inputs must least 0.9.
means inputs Pand node fall within relatively small range [0.9,1.0].
However, desired output two input Por node 0.9, sure
inputs fall range [0,0.9]. known output Pand Por node
low, say 0.1, opposite effect. is, unknown inputs
Por node would lie relatively small range [0.0,0.1], unknown inputs
Pand node would fall somewhere much larger range [0.1,1.0]. observations
suggest blame assignment error propagated Pand node
reasonable accuracy examples relatively good, say 0.7 above. However,
high evaluation measures, error value cannot reliably propagated Por
node.
Since subcategory evaluation measure computed Por parent category
evaluation measure combination additional functional requirements, Por
nodes proof tree two inputs. Por nodes (in proof trees) least 1
connecting node consists parent (or general) category whose membership
calculation involves Pand connectives. structure proof trees permits
membership functions contribute evaluation measure parent category
accurately learned prior learning defined additional functional requirements
subcategories. is, determine one inputs Por node
attempt propagate error node. one input desired output
Por node known, calculation unknown input trivial. Thus, learning
approach eliminates reliability problems associated propagating blame assignment
error Por nodes. verified Section 6 experimental results
subcategories straightback chair armchair.
mechanics learning algorithm suggests Omlet's performance depends
accurately blame assignment propagated Pand nodes proof tree.
Earlier, observed blame assignment less reliably propagated Pand nodes
\bad" training examples. surprisingly, suggests quality training
data effect system performance. mean \bad" examples
object (sub)category cannot, not, included training set. Since
use least squares line fit adjust fuzzy membership functions, use \bad"
training examples (for blame may inaccurately distributed among
fuzzy membership functions) dramatically affect overall reliability
learned system parameters. Rather, desirable train system examples
that, part, good examples labeled object category. However,
unreasonable might expect machine (or human matter) better
learn constitutes chair observing good examples chairs.
207

fiWoods, Cook, Hall, Bowyer, & Stark

5. Experimental Setup
Upon reading rule base, knowledge primitive measurements training examples, training example goals, Omlet begins learning membership functions
level 1 categories. first learning epoch used make initial estimates
membership functions, Omlet iterates 1000 additional training epochs.
learning rate 0.15 used 1000 training epochs, 15 percent actual error training example propagated adjustable ranges epoch.
1000 training epochs, best range parameters (those resulted lowest
overall error) level 1 categories restored frozen. 1000 training epochs
repeated level 2 categories, followed level 3 categories,
ranges category definition tree learned2.
performance task Omlet system evaluated well trained system
recognizes objects used training phase. One measurement system
performance error observed test examples. error test example
computed absolute value difference desired actual evaluation
measures. Training/Test sets configured two ways: random partitioning labeled
data training test sets, leave-one-out testing. first case, given
size training set, 10 train/test set pairs created randomly partitioning labeled
data. error single test set average error test examples. results
given size training set reported average error 10 partitions. leave-oneout testing, one example data set used test remaining samples form
training set. repeated using example data test set, results
reported average error test examples. average error per example versus
training set size plotted training sets 10, 20, 30, ... , N-1 samples. point
N-1 training examples represents leave-one-out test results.

5.1 Test Gruff Chair Database

evaluations Gruff (Stark & Bowyer, 1991), large database 3-D shapes
specified polyhedral boundary representations built up. Figure 9 shows 52 chair
shapes. number 52 shapes belong one category function
one stable orientation. results total 110 training examples.
78 labeled instances category conventional chair. 28 instances
additionally satisfy function straightback chair, 4 instances satisfy function
armchair. shape, evaluation measure shape's membership
different object categories, computed Gruff hand-crafted functions
primitive evaluation measures. set shapes evaluation measures make
first set training examples.
first set experiments help determine well Omlet learns set membership functions minimize overall error, also closely learned membership
functions approximate original functions hand-crafted expert Gruff.
question great practical importance vision researchers whether machine learning
2. preliminary experiments, Omlet converged low overall error level categories
anywhere 200 900 training epochs. Hence decision train 1000 epochs per category
level. learning rate also determined empirically.

208

fiLearning Membership Functions Object Recognition

Figure 9: 52 object chair database.
technique derive set system parameters equivalent hand-crafted results
system designer. so, manual effort system construction could greatly eased.
learning task formulated duplicating Gruff measures, training
data experiments effectively \noiseless". (Noiseless sense desired
evaluation measures used input Omlet derived manner
set hand-crafted fuzzy membership functions.)

5.2 Test Synthetic Cup Database

definition recognition cups task visited frequently machine
learning research (Mitchell, Keller, & Kedar-Cabelli, 1986; Winston, Binford, Katz, &
Lowry, 1983). Winston (1983) observes, hard tell vision systems cups
look like. much easier talk purpose function cup.
convey description cup providing functional definition. particular, cup
described object hold liquid, stable, liftable, used
drink liquids. physical identification made using functional definition.
particular, synthetic set objects created here, functional properties
broken 19 knowledge primitives, 17 range parameters.
generated database 200 synthetic cup examples, measurements
knowledge primitives randomly distributed. Hand-crafted range parameters
(z 1,n1,n2,z 2) supplied 17 ranges cup functional definition. generate
209

fiWoods, Cook, Hall, Bowyer, & Stark

cup example, primitive measurement randomly selected range. Approximately
80% time primitive measurement randomly chosen n1 n2.
20% time measurement randomly chosen outside n1 n2, inside
z 1 z 2. cup generator program provides us capability create large
number cup examples without time-consuming process creating actual 3-D CAD
models example.

5.3 Learning Human Evaluation Measures

object recognition important test system real objects, possible, number
reasons. First, see whether system approximate human judgment. Second,
important observe system performance presence noise, real-world data
inevitably contain. Finally, using real-world data alleviate need completely
hand-craft system synthetic data. actually useful guide scenario
\vision system engineer" gives system set human-labeled examples,
lets system learn parameters. test Omlet, used set 37 actual
objects human ratings well might serve chair. Figure 10 shows
objects used experiments.

Figure 10: examples chair objects used human evaluation tests.
order determine well Omlet learn recognize set real chair-like
objects, objects collected together single room object placed
orientation would likely recognized chair. actual chairs,
simply orientation chair would typically used. metal trash
210

fiLearning Membership Functions Object Recognition

would \upside down" orientation, etc. group 32 undergraduate
students Artificial Intelligence class given following instructions:
asked rate thirty-seven objects according degree
\chair-ness" ected 3-D shape. purposes, \chair-ness"
measures object could used chair. consider
3-D shape making rating. assume object made
appropriate materials, factor ratings.
consider suitability object shape orientation
see it, rather orientation. Examples factors
consider rating \chair-ness" shape height, width, depth, area,
relative orientation apparent stability.
asked rate shape requirements three different
aspects \chair-ness". first aspect solely ability provide stable
seating surface. second aspect solely ability provide back support
compatible seating surface. third aspect solely ability
provide arm support compatible seat back. aspect
judged independently scale 1 5, 1 means ability
provide required function 5 means seems ideal provide
desired function. may mark halfway two numbers wish.
ratings aspect \chair-ness" averaged, normalized rounded
nearest multiple 0.02 result values range [0,1]. overall evaluation
measures objects conventional chair category taken normalized
evaluation measures first aspect \chair-ness", object's ability provide
stable seating surface. Overall evaluation measures categories straightback chair
armchair computed using probabilistic T-conorm combine three aspects
\chair-ness" manner described Subsection 3.3. Hence, comfortable, sturdy
chair would value close 1 \chair-ness", upside-down trash
considerably lower value (approx. 0.5).
objects rated, measurements taken primitives
describing chair Gruff system. measurements required
Omlet rules, clearance ground, area sittable surface,
height sittable surface, etc. Complete Omlet examples describing objects
created, including aggregate evaluation measure objects categories
conventional chair, straightback chair, armchair. resulted 37 objects
conventional chair category, 22 objects straightback chair category (15 objects
back support all), 12 objects armchair category (10 objects
back support arm support). least two sources noise
experimental data: 1) human evaluations, 2) actual measurements
physical properties objects. example, standard deviations normalized
human evaluations 37 objects conventional chair category 0.12,
12%, average. results leave-one-out testing 37 real-world objects
presented next section.
211

fiWoods, Cook, Hall, Bowyer, & Stark

6. Experimental Results

least four factors may affect performance Omlet system: 1)
number training epochs, 2) number training samples category, 3)
number ranges learned category, 4) quality training data
category. Histograms desired evaluation measures training data used
convey concept training set \quality". shown Figure 11 Gruff
chair data. height histogram bin number training samples desired
evaluation measures fall within particular range. So, histogram \good" set
training data would skewed towards higher evaluation measures. Similarly,
histogram representing \bad" training data would skewed towards lower evaluation
measures.

Figure 11: Histograms desired evaluation measures Gruff chair training sets.
histogram parent category, conventional chair cup, represents
distribution overall desired evaluation measures (which goal measures
examples data set provided input Omlet). However, histograms subcategories, straightback chair armchair, represent distributions desired
evaluation measures associated additional functional requirements defined
212

fiLearning Membership Functions Object Recognition

subcategory. example, histogram straightback chair category represents
quality provides back support portion straightback chair examples data
set, overall desired evaluation measures. Recall ranges associated
parent category conventional chair frozen (and presumably accurate)
learning begins category straightback chair. So, Omlet uses straightback chair
examples learn ranges associated provides back support functional property.
Thus, learning ranges category straightback chair, want observe
quality back supports training examples. Similarly, want observe
quality arm supports armchair examples, overall desired evaluation
measures.
A) Effect Training Time GRUFF Objects

B) Effect Training Time Synthetic Cups

Training 77 GRUFF
Labeled Conventional Chairs

Training 200
Synthetic Cups

Training 27 GRUFF
Labeled Straightback Chairs

C) Effect Training Time Real Objects

Training 36 Human
Labeled Conventional Chairs

Training 21 Human
Labeled Straightback Chairs

Figure 12: Average training sample error versus number training epochs A) Gruff
chair objects, B) synthetic cups, C) real chair objects. plots
single leave-one-out test run.
Figure 12 shows examples average training sample error plotted function
number training epochs three data sets (Gruff objects, synthetic
cups, real objects). plots, see 1000 training epochs
sucient categories three data sets. Training could likely
213

fiWoods, Cook, Hall, Bowyer, & Stark

stopped 400 epochs categories without degradation system
performance. Since number training epochs categories,
shown sucient, eliminate factor possible cause different
levels performance among categories. experiments addition described
Section 5 run examine effect performance factors.

6.1 Gruff Chair Database

Figure 13: Omlet results test samples Gruff chair database.
Figure 13 shows plot average error per sample versus training set size examples conventional chair category, separate plot examples
straightback chair category. Since 28 straightback chair examples, 3 different training set sizes (6,12,18) evaluated addition leave-one-out testing.
78 conventional chair examples used train ranges associated conventional chair category ranges straightback chair category trained.
testing done subcategory armchair since four training samples
available. plot shows increasing number training samples generally leads
reduction average error. 20 training examples used,
actual evaluation measures test examples within approximately 1% desired
evaluation measures conventional chair straightback chair categories.
note errors overall evaluation measures found categories
different learning levels directly comparable. So, plot error rate
straightback chair category directly comparable plot conventional
chair category (Figure 13). example, consider object desired overall evaluation measure 0.85 category conventional chair. Omlet computes actual
214

fiLearning Membership Functions Object Recognition

evaluation measure 0.86, error example 0.01. Let's assume provides back support portion object desired evaluation measure 0.75.
overall desired evaluation measure example category straightback chair would
0.9625 (Por 0.85 0.75). Now, suppose Omlet finds actual evaluation measure back support object 0.76, error 0.01. case,
actual overall evaluation measure example category straightback chair would
0.9664 (Por 0.86 0.76). result, error 0.01 attributed provides back support portion object manifested much smaller error 0.0039
overall evaluation measure object.
original range parameters (z 1,n1,n2,z 2) hand-crafted expert three
ranges conventional chair definition (see Figure 4) are:
AREA (0.057599 0.135 0.22 0.546699)
CONTIGUOUS SURFACE (0.0 1.0 1.0 1.0)
HEIGHT (0.275 0.4 0.6 1.1)
range values used Gruff determine desired evaluation measures
goals provided Omlet. typical example range parameters learned
Omlet is:
AREA (0.057599 0.135002 0.219992 0.546706)
CONTIGUOUS SURFACE (7.45591e-06 0.999995 10000 10000)
HEIGHT (0.275 0.400002 0.6 1.10009)
Omlet able determine CONTIGUOUS SURFACE range one-legged

membership function, n2 z 2 values (i.e., leg exist) set
arbitrarily large values. results show Omlet system capable using
labeled examples automatically determine range parameters similar
would hand-crafted expert. facilitate construction
object category definitions.
Figure 13, see number training samples indeed affect
error rate test samples. 20 training samples, error rates
conventional chair straightback chair categories begin level off. So,
number training samples becomes less factor affecting system performance
sucient number used. constitutes sucient number training samples
category may depend number ranges learned quality training
data. 3 ranges must learned category conventional chair, 5
ranges must learned category straightback chair. histograms desired
evaluation measures Gruff conventional chairs back supports Gruff
straightback chairs Figure 11 B, respectively, ect quality training
data used leave-one-out tests.
isolate effect quality training data additional experiments utilizing two separate data sets Gruff conventional chair examples. number
215

fiWoods, Cook, Hall, Bowyer, & Stark

training epochs, number training samples, number ranges learned
identical data set. One data set 38 \bad" examples contains conventional chair examples desired evaluation measures less 0.6. second data set
\good" examples created selecting 38 remaining conventional chair examples.
histograms desired evaluation measures examples used \good"
\bad" data sets shown Figure 11 C D, respectively. Leave-one-out testing (37
training examples) resulted average error 0.0001 examples \good"
data set, 0.1869 examples \bad" data set. Thus, would seem
quality training data considerable effect performance learning
algorithm.
Using set 38 \good" conventional chair examples train Omlet, average
error found using 38 \bad" examples test drops 0.013 (compared average
error 0.1869 37 \bad" examples used train). closer examination
results reveals one \bad" example contributes relatively high error 0.5
average. single example excluded test results, average error
remaining 37 \bad" examples 0.00067. 38 \bad" examples used train
Omlet, average error found using 38 \good" examples test 0.242.
results indicate Omlet inherently biased produce accurate test results
\good" examples since able achieve low error rate \bad" examples
\good" training data used. Rather, results emphasize importance
controlling quality data used train Omlet.

6.2 Synthetic Cups Database

Figure 14: Omlet results test samples Gruff cup database.
216

fiLearning Membership Functions Object Recognition

Figure 14 shows plot average error per sample versus training set size examples
randomly generated cup category. before, Omlet's performance generally
improves number training samples increased. comparison error plots
conventional chair data cup data reveals average error
cups higher number training samples, error rate decreases
erratically. comparison error rates two categories valid since
level learning hierarchy. before, two performance
factors could cause different error rates. considerably
ranges need learned cup category Gruff conventional chair
category (17 versus 3). Also, Figure 15 A, see data set created
cup generator program poor quality. Thus, due random nature synthetic
cup generator program, system trained shapes that, average,
good examples cups. Regardless poor training data, 150 training
samples used, actual evaluation measures cup test examples within
approximately 4% desired evaluation measures. light \bad" set shapes
used training examples large number ranges must learned, higher
average error cups seems reasonable.

Figure 15: Histograms desired evaluation measures synthetic cup training sets.
additional test, generated set 78 synthetic cups manner
(see Section 5.2). However, required distribution desired evaluation
measures synthetic cups similar distribution Gruff conventional
chair examples (shown Figure 11 A). Figure 15 B shows histogram desired evaluation measures examples second synthetic cup data set. Since number
training epochs, number training examples, quality training data
first test using Gruff conventional chair examples, experiment
isolates effect number ranges must learned. Performing leave-one-out
test (77 training examples), average error per sample found approximately
0.08. Figure 13, leave-one-out results 78 Gruff conventional chair examples
217

fiWoods, Cook, Hall, Bowyer, & Stark

(Sub)Category
Conventional
Chair
Straightback
Chair
Armchair

Number
Average Desired Average Error
Training Samples Evaluation Measure per Sample
36
0.8447
0.0715373
21

0.9927

0.0066456

11

0.9973

0.0022430

Table 1: Leave-one-out test results real-object database evaluation measures derived human ratings objects.

show average error less 0.01 per sample. Thus, would seem number
ranges learned affects system performance considerably.
Finally, created set 200 synthetic cups similar distribution Gruff
conventional chair examples. histogram desired evaluation measures examples
third synthetic cup data set would look similar histograms Figure 11 A,
Figure 15 B. Performing leave-one-out test (199 training examples), average error per
sample found approximately 0.023. Compared error rate original 200
synthetic cups (approximately 0.04), note \better" training data improved
system performance considerably. Compared error rate 78 synthetic cup data
set (approximately 0.08), similar quality, see increased number training
samples significantly improved system performance. error rate third synthetic
cup data set 200 examples still higher error rate Gruff data set
78 conventional chair objects (less 0.01), similar quality distribution.
Consider Gruff data set used 77 training examples learn 3 ranges
conventional chair category, synthetic cup data set, used 199 training
examples learn 17 ranges cup category.

6.3 Chair Database Human Evaluation

Leave-one-out test results real-object database evaluation measures derived
human ratings objects listed Table 1. Recall error rates
directly comparable among three categories. actual evaluation measures
conventional chairs objects within approximately 7% human evaluation measures.
average error 6% greater average error Gruff data
similar number training samples. histogram Figure 16 shows data set
real conventional chair objects contains mostly \good" examples. Thus, higher average
error probably attributed \noise" associated real-object evaluation
measures. Considering average standard deviation 12% human evaluations
conventional chair objects, 7% average error per sample Omlet results
seem unreasonable. actual evaluation measures real-object straightback chairs
armchairs differ average less 1% desired measures. before,
conventional chair examples used train ranges associated conventional
218

fiLearning Membership Functions Object Recognition

chair category ranges straightback chair category trained.
histograms desired evaluation measures back support real straightback
chair objects arm support real armchair objects shown Figure 16 B
C, respectively.

Figure 16: Histograms desired evaluation measures real-object training sets.

7. Summary Discussion

presented system (Omlet) uses labeled training examples learn fuzzy
membership functions embedded function-based object recognition system. fuzzy
membership functions used provide evaluation measures determine well
shape fits functional description object category. Omlet system example
using machine learning techniques aid development computer vision system.
shown possible accurately automatically learn system parameters
would otherwise provided human expert. Omlet may used aid
construction object categories Gruff object recognition system.
expert need concentrate \hand-tweaking" range parameters improve
system performance, rather providing good set example objects \show"
Omlet. intuitively appealing deriving descriptions objects would
219

fiWoods, Cook, Hall, Bowyer, & Stark

like Gruff recognize providing examples object category. Additionally,
able demonstrate performance learning algorithm affected
number quality training examples.
possible learning approach described paper applied
systems measurements (or values) combined tree structure.
cases covered approach, except case 2 leaves leading directly Por
node. However, generalization method treating Por nodes may developed
handle situation. tree structure CV system composed entirely
probabilistic probabilistic nodes, used combine measurements.
possible similar approach applicable tree structures types
nodes (T-norms T-conorms) used.
Omlet system make easier adapt Gruff system new object
domains. Early versions Gruff performed object recognition starting complete
3-D shape descriptions (Stark & Bowyer, 1991, 1994; Sutton et al., 1993) rather
real sensory data. task reliably extracting accurate object shape descriptions
normal intensity images beyond current state art computer vision. Although
work in, example, binocular stereo, steadily progressing, accurate models object
shape readily extracted range imagery. Whereas normal imagery pixel
value represents intensity ected light, range imagery pixel value represents
distance point scene. version Gruff developed attempts
recognize object functionality shape model extracted single range
image (Stark, Hoover, Goldgof, & Bowyer, 1993b). major diculty is, course,
single range image yield complete model 3-D shape object.
\back half" object shape unseen (Hoover, Goldgof, & Bowyer, 1995).
accumulation complete 3-D shape model sequence range images topic
current research. problem solved, conceivable Omlet training
example might consist sequence range images along operator annotations
identify portions images correspond functionally important parts
object (seating surface, back support surface, etc.).

Acknowledgements
research supported Air Force Oce Scientific Research grant F49620-92-J0223 National Science Foundation grant IRI-91-20895.

References
Berenji, H., & Khedkar, P. (1992). \Learning Tuning Fuzzy Logic Controllers
Reinforcements". IEEE Transactions Neural Networks, 3, 724{740.
Bogoni, L., & Bajcsy (1993). \An Active Approach Characterization Recognition
Functionality Functional Properties". AAAI-93 Workshop Reasoning
Function, pp. 201{202 Washington, D.C.
220

fiLearning Membership Functions Object Recognition

Bonissone, P. P., & Decker, K. S. (1986). \Selecting Uncertainty Calculi Granularity:
Experiment Trading-off Precision Complexity". Kanal, L., & Lemmer, J.
(Eds.), Uncertainty Artificial Intelligence, pp. 217{247. North-Holland Publishing
Company.
Brand, M. (1993). \Vision Systems See Terms Function". AAAI-93 Workshop
Reasoning Function, pp. 17{22 Washington, D.C.
Cooper, G., & Herskovits, E. (1992). \A Bayesian Method Induction Probabalistic
Networks Data". Machine Learning, 9, 309{347.
Di Manzo, M., Trucco, E., Giunchiglia, F., & Ricci, F. (1989). \FUR: Understanding
FUnctional Reasoning". International Journal Intelligent Systems, 4, 431{457.
Hoover, A., Goldgof, D., & Bowyer, K. (1995). Extracting valid boundary representation
segmented range image. IEEE Transactions Pattern Analysis Machine
Intelligence. Accepted appear.
Ishibuchi, H., Nozaki, K., & Yamamoto, N. (1993). \Selecting Fuzzy Rules Genetic
Algorithm Classification Problems". 2nd IEEE International Conference
Fuzzy Systems, pp. 1119{1124.
Jang, J. S. R. (1993). \ANFIS: Adaptive-Network-based Fuzzy Inference Systems". IEEE
Transactions Systems, Man Cybernetics, 23 (3), 665{685.
Jang, J. S. R., & Sun, C. T. (1995). \Neuro-Fuzzy Modeling Control". Proceedings
IEEE, 378{406.
Kise, K., Hattori, H., Kitahashi, T., & Fukunaga, K. (1993). \Representing Recognizing
Simple Hand-tools Based Functions". Asian Conference Computer
Vision, pp. 656{659 Osaka, Japan.
Lehn, K. V. (1990). Mind Bugs: Origins Procedural Misconceptions. MIT Press,
Cambridge, Massachusetts.
Mahadevan, S., & Connell, J. (1991). \Automatic Programming Behavoir-Based Robots
Using Reinforcement Learning". AAAI, pp. 768{773.
Michalski, R. S. (1983). \A theory methodology inductive learning". Michalski,
R. S., Carbonell, J. G., & Mitchell, T. M. (Eds.), Machine Learning: Artificial
Intelligence Approach. Tioga Publishing Company, Palo Alto, CA.
Mitchell, T. M., Keller, R. M., & Kedar-Cabelli, S. T. (1986). \Explanation-Based Generalization: Unifying View". Machine Learning, 1, 47{80.
Parido, A., & Bonelli, P. (1993). \A New Approach Fuzzy Classifier Systems".
Proceedings Fifth International Conference Genetic Algorithms, pp. 223{
230.
Pearl, J. (1988). Probabilistic Reasoning Intelligent Systems: Networks Plausible
Inference. Morgan Kaufmann.
221

fiWoods, Cook, Hall, Bowyer, & Stark

Quinlan, J. R. (1992). C4.5: Programs Machine Learning. Morgan Kaufmann.
Rivlin, E., Rosenfeld, A., & Perlis, D. (1993). \Recognition Object Functionality
Goal-Directed Robotics". AAAI-93 Workshop Reasoning Function, pp.
126{130 Washington, D.C.
Spiegelhalter, D., Dawid, P., Lauritzen, S., & Cowell, R. (1993). \Bayesian Analysis
Expert Systems". Statistical Science, 8, 219{282.
Stark, L., & Bowyer, K. W. (1991). \Achieving generalized object recognition
reasoning association function structure". IEEE Transactions Pattern
Analysis Machine Intelligence, 3 (10), 1097{1104.
Stark, L., & Bowyer, K. W. (1994). \Function-based recognition multiple object categories". Image Understanding, 59 (10), 1{21.
Stark, L., Hall, L. O., & Bowyer, K. W. (1993a). \An investigation methods combining
functional evidence 3-D object recognition". Int. J. Pattern Recognition
Artificial Intelligence, 7 (3), 573{594.
Stark, L., Hoover, A. W., Goldgof, D. B., & Bowyer, K. W. (1993b). \Function-based
recognition incomplete knowledge shape". IEEE Workshop Qualitative
Vision, pp. 11{22 New York, New York.
Sutton, M., Stark, L., & Bowyer, K. W. (1993). \Function-based generic recognition
multiple object categories". Jain, A. K., & Flynn, P. J. (Eds.), Three-dimensional
Object Recognition Systems, pp. 447{470. Elsevier Science Publishers.
Vaina, L., & Jaulent, M. (1991). \Object structure action requirements: compatibility
model functional recognition". Int. J. Intelligent Systems, 6, 313{336.
Valenzuela-Rendon, M. (1991). \The Fuzzy Classifier System: Classifier System Continuously Varying Variables". Proceedings Fourth International Conference
Genetic Algorithms, pp. 346{353.
Watkins, C. J. (1989). Models Delayed Reinforcement Learning. Ph.D. thesis, Cambridge
University.
Winston, P. H., Binford, T. O., Katz, B., & Lowry, M. (1983). \Learning physical descriptions functional definitions, examples, precedents". National Conference
Artificial Intelligence, 433{439.

222

fiJournal Artificial Intelligence Research 3 (1995) 373-382

Submitted 7/95; published 12/95

Statistical Feature Combination
Evaluation Game Positions
Michael Buro

NEC Research Institute
4 Independence Way
Princeton NJ 08540 U.S.A.

mic@research.nj.nec.com

Abstract

article describes application three well{known statistical methods field
game{tree search: using large number classified Othello positions, feature weights
evaluation functions game{phase{independent meaning estimated means
logistic regression, Fisher's linear discriminant, quadratic discriminant function
normally distributed features. Thereafter, playing strengths compared means
tournaments resulting versions world{class Othello program.
application, logistic regression | used first time context game
playing | leads better results approaches.

1. Introduction

Programs playing games like chess, draughts, Othello use evaluation functions estimate
players' winning chances positions leaves game{trees. values
propagated root according NegaMax principle order choose move
root position leads highest score. Normally, evaluation functions combine
features measure properties position correlated winning chance,
material chess mobility Othello. popular quickly computable linear feature
combinations. early days game programming, feature weights chosen
intuitively improved manual hill{climbing process programmer's patience
gave out. technique laborious. Samuel (1959,1967) first describe method
automatic improvement evaluation function parameters. Since many approaches
investigated. Two main strategies distinguished:

Move adaptation: Evaluation function parameters tuned maximize frequency
searches yield moves occur lists moves belonging training
positions. idea get program mimic experts' moves.

Value adaptation: Given set labelled example positions, parameters determined

evaluation function fits specific model. instance, evaluation functions
constructed way predict final game result.

move adaptation, proposed instance Marsland (1985), v.d. Meulen (1989),
Mysliwietz (1994), linear feature combination two degrees freedom: multiplied positive constant constant added without changing move
decision. evaluation function depends game phase, positions different
phases compared (for example within framework selective extensions opening
book play), constants must chosen suitably. evaluation functions optimized
c 1995 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiBuro

move adaptation moment global interpretation, solution problem
obvious. Schaeffer et al. (1992) presented ad hoc game{specific approach.
respect, value adaptation promising. Here, evaluations different
phases comparable example position labels phase{independent meaning.
Mitchell (1984) labelled Othello positions occurring game final game result
form disc differential tried approximate values using linear
combination features. Since regression used determine weights, also
possible investigate features' statistical relevance. Another statistical approach
value adaptation used Lee & Mahajan (1988): example positions classified
win loss side move | assuming features multivariate normal |
quadratic discriminant function used predict winning probability. technique
ensures desired comparability applies also games without win degrees, i.e.
know wins, draws, losses.
Besides classical approaches heavily rely given feature sets, recent
years artificial neural networks (ANNs) trained evaluating game positions.
instance, Moriarty & Miikkulainen (1993) used genetic algorithms evolve topology
weights ANNs order learn Othello concepts means tournaments
fixed programs. discovering concept mobility, best 1{ply ANN{player
able win 70% games 3{ply brute{force program used evaluation
function without mobility features. important contribution field
Tesauro (1992,1994,1995). Using temporal difference learning (Sutton, 1988) updating
weights, ANNs learned evaluate backgammon positions master level means
self{play. Tesauro conjectured stochastic nature backgammon responsible
success approach. Though several researchers obtained encouraging preliminary
results applying Tesauro's learning procedure deterministic games, work yet
led strong tournament programs tactical games Awari, draughts, Othello,
chess, allow deep searches powerful quickly computable evaluation
functions known. might due tactics games knowledgeable
slower evaluation functions necessarily accurate relatively simple
faster evaluation functions conjunction deeper searches.
follows, three well{known statistical models | namely quadratic discrimination function normally distributed features, Fisher's linear discriminant, logistic
regression | described evaluation game positions context value
adaptation. Thereafter, shown example positions parameter estimation
generated. Finally, playing strengths three versions world{class Othello program1
| LOGISTELLO | equipped resulting evaluation functions compared order
determine strongest tournament player. turns quadratic feature combinations necessarily lead stronger programs linear combinations, logistic
regression gives best results application.

2. Statistical Feature Combination

formal basis statistical feature combination position evaluation stated
follows:
1. Since appearance October 1993 twelve 14 international tournaments played.

374

fiStatistical Feature Combination


set positions evaluate.
:
! fL; Wg classifies positions loss win player move,
assuming optimal play sides. Draws handled manner
outlined Section 4.
X1; : : :; X :
! IR features.
evaluation position ! 2
x = (X1; : : :; X )(!) conditional winning probability
n

n

V ( ! ) = P (Y

= W j (X1; : : :; X ) = x) =: P (W j x):
n

N classified example positions !1; : : :; ! 2
available
N

x = (X1; : : :; X )(! ) = (! ).


n







following subsections models express P (W j x) function linear quadratic feature combinations brie introduced way sucient practical
purposes. Good introductions theoretical details given instance Duda
& Hart (1973), Hand (1981), Agresti (1990), McCullagh & Nelder (1989). Fisher's
classical method logistic regression used model P (W j x) first time;
quadratic discriminant function used Lee & Mahajan (1988), however, without
considering Fisher's discriminant first.

2.1 Discriminant Functions Normally Distributed Features
Bayes' rule gives

j W )P (W )
= p(x j pW(x))P (W ) = p(x j W p)P(x(W
) + p(x j L)P (L)
,1

= 1 + pp((xxj jWL))PP ((LW)) ;
p(x j C ) features' conditional density function P (C ) priori probability
class C 2 fL; Wg. case priori probablities equal, features
multivariate normally distributed within class, i.e.
P (W j x )

p(x j C ) = (2 ), 2j j,1 2 exp
n=

C

=

n

, 21 (x , ),1(x , )0
C

C

C

mean vector covariance matrix C 2 fW ; Lg, follows
1
P (W j x) =
;
1 + exp(,f (x))
f following quadratic discriminant function:
C

f (x)



C

n



= , 21 x ,W1 , ,L 1 x0 + L ,L 1 , W ,W1 x0 +


1 ,1 0 , ,1 0 + log jW j , log jL j :
W
W
L
L
W
L
2

375

fiBuro

1.0

...........................................................
....................
............
..........
........
.
.
.
.
..
.......
.....
....
.....
....
....
.
.
...
....
.....
....
...
....
.
.
...
....
........................
...............................
......
.....
......
.
....
.... ....
....
....
.... ...... .....
....
...
.
.
.
.
.
......
...
..
....
.
.
.
.
.
.
....
.
.
.
........
....
.
.
.....
....
.
.
.
.
.
.
.
.
.
.....
.. ......
... ............
.
.
.
.
.
.
.
.....
.
......
.................
....
.....
.
.
.
.
.
.
.
.
.
.
.
.......
.......
................
....
.
.
.
.
......
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
........
....
...............
...........................................................................................................................................
........................................................................................................................................................................

0.5
0.0

L

x

W

Figure 1: Conditional densities winning probability
covariance matrices equal (=), expression simplified linear function:
f (x) = (W , L ),1 fx , (L + W )=2g0:
Interestingly, function also solution problem finding linear transformation
maximizes ratio squared sample mean distance sum within{class
sample variances transformation. Therefore, good separator properties even
features normally distributed. called Fisher's linear discriminant. Figure 1
illustrates relation conditional densities winning probability.
maximum likelihood (ML) parameter estimates
1 Xx
^ =
C

jI j
C

^ = jI1 j

2C



X

C

C





2C



(x , ^ )0(x , ^ )


C



C



= fi j = C g. covariance matrices equal,
X X
^ = jI j 1+ jI j
(x , ^ )0(x , ^ ):
W
L 2fL Wg 2 C
C





C

;



C



C



2.2 Logistic Regression

logistic regression conditional winning probability P (W j x) depends linear
combination x . Here, X1 1 assumed order able model constant offsets.
simple approach P (W j x) = xfi using parameter column vector fi unusable
xfi 2 [0;1] cannot guaranteed generally. requirement fulfilled means
link{function g : (0;1) ! IR according g (P (W j x)) = xfi . Figure 2 shows typical
nonlinear relation winning probability one feature. Since probability
usually monotone increasing function features, g satisfy lim !0+ g (x) = ,1
lim !1, g (x) = +1. link{function g (t) = logit(t) := log(t=(1 , t))
properties. Using g = logit, since g ,1(x) = f1 + exp(,x)g,1 , follows
1
P (W j x) =
1 + exp(,xfi ) :


x

x

376

fiStatistical Feature Combination

Hence, winning probability shape discriminant analysis. logistic
regression require features multivariate normal; even use
discrete features possible.
parameter vector fi estimated using ML approach. Unfortunately,
case necessary solve system nonlinear equations. follows, known
solving approach brie described (cf. Agresti, 1990; McCullagh & Nelder, 1989).
order ensure convergence iterative algorithm given below, necessary
slightly
variable
P generalize model: observed value random
,1
=

,



:


!
f
0
;
1
g

mean

=
f
1
+
exp(
,
x
fi
)
g
=1
stochastically independent. definition includes old model (n = 1 2 f0; 1g).
likelihood function L(fi), probability density, measures likely
see realization stochastically independent random variables , fi true
parameter vector. order maximize L, suces consider log(L):


n



j

i;j

i;j











log(L(fi)) = log


N

=1
XX


=

n

j

=1



(1 , )ni ,yi


N

=1

yx


ij


fi

,

j



X
N

=1

X
N

=
h

=1





log + (n , ) log(1 , )



log 1 + exp

n







X
n

j

=1



x fi
ij

j






:

function twice differentiable, strictly concave rare border cases,
unique maximum location 0 < < n (cf. Wedderburn, 1976)
iteratively found using Newton{Raphson method follows:
( +1)
fi^
= (X 0( )X ),1 X 0( ) z ( )
















(N n){matrix X built x ,



( ) = diag[n ^ ( )(1 , ^( ))]; ^( ) = 1 + exp ,















n







n



j

^ ( )
, n ^ ( )
(
)
z = log
+
:
1 , ^ ( ) n ^ ( )(1 , ^ ( ))

=1

x fi^( )


ij

o,1

j







X











1.0
P (W j x) 0.5

0.0















.....................................
.......................................
.............
..........
.........
.......
.
.
.
.
.
.
....
.....
.....
.....
....
....
.
.
.
.
..
....
...
....
....
...
.
.
.
...
....
....
....
....
....
.
.
.
.
....
.....
......
.....
.......
.........
.
.
.
.
.
.
.
.
....
...................
..................................................................

x

Figure 2: Typical shape winning probability
377

;



fiBuro

Starting ^ (0) = (y +1=2)=(n +1), ML estimate fi^ may usually computed high
accuracy within steps since method quadratically convergent relatively robust
respect choice starting vector. Unfortunately, = 0
= n estimates might converge. original model approximated,
instance, setting n = 100 = 1 99, depending whether position
question lost won.
















3. Generation Classification Example Positions
Value adaptation requires labelled example positions. Here, problems arise. First
all, nontrivial games endgame positions classified correctly won,
drawn, lost; opening midgame positions optimal play reach due
lack game knowledge time constraints. Furthermore, example positions
contain significant feature variance since otherwise discrimination possible. Hence,
problematic use high level games | might first idea | since good
players programs know relevant features try maximize game.
Therefore, features tend constant time statistical methods would
assign small weights them. final diculty, estimating parameters accurately
different game phases requires many positions.
pragmatic \solution" problems indicated Figure 3: period
two years, 60,000 Othello games2 played early versions LOGISTELLO
- urd-anovic's program REV.3 Feature variance ensured examining openings
Igor
length seven led mostly unbalanced starting positions. Since early program
versions used 5{10 minutes thinking time, games, though well
played time, error free. cases even big mistakes occurred
which, example, one side fell corner losing trap4 caused lack look{ahead.
without errors, reasonable weight estimation principal features (such corner
possession Othello) possible explained above. Following Lee & Mahajan (1988),
positions classified final game results. approach problematic
classification reliability decreases endgame opening phase due player
mistakes. reduce effect, early outcome searches performed solving Othello
positions 20 moves game end. Furthermore, time time game database
searched \obvious" errors using new program versions longer searches correct
games. Since process many lines play repeated, misclassification
rate reduced propagating game results leaves root
game{tree, built games according NegaMax principle.
way classification position depends examined successors
therefore reliable.
proposed classification method relatively fast allows us label many positions
reasonable time (on average 42 new positions 10{20 minutes). addition
2. game file obtained via anonymous ftp.
(ftp.uni-paderborn.de/unix/othello/misc/database.zip)
3. brief description programs given help pages Internet Othello Server.
(telnet faust.uni-paderborn.de 5000)
4. implications compared losing material nothing chess.

378

fiStatistical Feature Combination

....................................................
.....................
............
............
.......
......
........
...
......
..
...
...
..
...
......
....
....
.......
.
.
.
.
.
..........
..........
.
................
.
.
.
.
.
.
.
.
.
.
.
.
.....................................................

.............
..........

.......
......
......
......
.......
.......
......
.......
..........
.........
...................
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.........................

Database consisting
ca. 60,000 games

L
W
L
W

W x
W
x L xD x
W
x xW x

..........
..... ...........
....
.....
......
....
......
....
..... ....
...................
..... ........
.
..
.
..
.
..
... ...
..... ......
............
......
.... ......
...
...
.
.
.
....
..
...
...
....
....
.
...
.........
.... ...
.
... ...
............

.......
.... ......
.
..
................

........................................................
....................
............
..........
........
........
.....
.....
...
....
..
..
..
..
....
....
.......
.....
......
.
.
.
.
.
.
............
...
..................................................................................

.............
..........

.........
.... ...
.
... ...
..... ...
..
.... .... ......
...
...
.
.
...
...
...
...
...
....
....

Game tree

.......
.
......
......
......
......
.......
.....
.........
........
...............
..........
............................................

2.5 Million
classified positions

Figure 3: classification process
ensuring accurate parameter estimation even different game phases (which indicated
small parameter confidence intervals), method enabled us develop new pattern
features Othello based estimating winning probability conditioned upon occurrence
sub{configurations, like edge diagonal instances, board.5

4. Parameter Estimation Playing Strength Comparison

Although 5% example positions labelled drawn, decided
use parameter estimation since positions give exact information
feature balancing. natural way handle drawn positions within statistical evaluation
framework considered define winning probability 1=2 case.
extension logistic regression parameters easily determined setting = n =2
case draw. Alternatively, doubling lost positions incorporating drawn
positions lost leads estimate log likelihood
functions equal constant factor. latter technique used fitting
models.
Previous experiments showed parameters depend game phase,
disc count adequate measure Othello. example positions grouped according number discs board, adjacent groups used parameter
estimation order smooth data ensure almost equal numbers lost
positions.
success Othello program BILL described Lee & Mahajan (1990) shows
Othello table{based features quite effective. instance, important edge
structure quickly evaluated adding four pre{computed edge evaluations
stored table. 13 features used LOGISTELLO table{based. fall
two groups: first group pattern instances including horizontal, vertical,
diagonal lines board evaluated second group two mobility measures
computed.5
parameter estimation three described models, tournaments players QUAD (which uses quadratic discriminant function normally distributed features),




5. Details given Buro (1994). postscript file thesis obtained via anonymous ftp.

379

fiBuro

Pairing
LOG , QUAD
FISHER , QUAD
LOG , FISHER
LOG , FISHER
LOG , QUAD
FISHER , QUAD
LOG , QUAD

Time per game
Result
Winning
(Minutes)
(Win,Draw,Loss) Percentage
30 , 30
30 , 30
30 , 30
30 , 36
30 , 38
30 , 38
30 , 45

116 , 15 , 69
112 , 15 , 73
93 , 35 , 72
86 , 24 , 90
93 , 33 , 74
84 , 30 , 86
88 , 26 , 86

61.8%
59.8%
55.3%
49.0%
54.8%
49.5%
50.5%

Table 1: Tournament results
FISHER, LOG played order determine best tournament player. Starting
100 nearly even opening positions 14 discs (i.e. move 11) LOGISTELLO's opening book, game return game colours reversed played.6

opening midgame phase program versions performed usual iterative deepening NegaScout searches (Reinefeld, 1983) selective corner quiescence search extension.
Endgame positions 22 empty squares solved win{draw{loss searches.
pattern learning tournaments, facility think opponent's time turned order speed tournaments run parallel
seven SUN SPARC{10 workstations.
Applying conservative statistical test5 seen results listed Table 1
stating winning percentage greater 59% statistically significant 5% level.
first two results show clear advantage linear combinations normal tournament
conditions (30 minutes per player per game). Furthermore, since LOG outperforms FISHER
features would seem even approximately normally distributed. lies
advantage logistic regression: even discrete features like castling status chess
parity Othello used.
tournaments played time weaker players FISHER
QUAD order determine time factors lead equal playing strength.
shown Table 1 FISHER reaches LOG's strength given 20% time,
QUAD needs 50% time compete LOG. LOGISTELLO's optimized
implementation, search speed using quadratic combination still 20%
slower linear combination. Thus, giving QUAD 25% time (1=(1 ,
0:2) = 1:25) balances total number nodes searched game. even
timing, LOG stronger QUAD, FISHER still compete it. all,
quadratic combination slower linear combination, also
better discrimination properties. Indeed, look estimated covariance matrices
6. LOG's 11{ply evaluation positions lies range [,0:4; +0:4] corresponds winning
probabilities range [0:4; 0:6]. nearly even starting positions used compare
programs similar playing strength since clear positions colour determines winner
winning percentage would 50% even one player stronger. 100 starting positions six
always led game pairs balanced score.

380

fiStatistical Feature Combination

class revealed almost equal, therefore better evaluation quality
Fisher's linear discriminant could expected.

5. Discussion

paper three statistical approaches modelling evaluation functions game{
phase{independent meaning presented compared empirically using world{
class Othello program. Quadratic feature combinations necessarily lead stronger
programs linear combinations since evaluation speed drop significantly.
course, effect depends number features used evaluation speed:
features used takes long time evaluate them, playing strength
differences cannot explained different speeds case evaluation times
almost equal. case, using quadratic combinations covariance matrices
compared; (almost) equal, quadratic terms omitted
Fisher's linear discriminant used. Therefore, motivations Lee & Mahajan (1988)
need refinement, since existing feature correlation necessarily justify use
nonlinear combinations. Generally, possibly accurate nonlinear feature combinations
(such ANNs) compared simpler faster approaches practice, since
use always guarantee greater playing strength.
Besides linear regression discriminant analysis, logistic regression proven
suitable tool construction evaluation functions global interpretation.
drawback, parameter estimation system nonlinear equations solved,
compensated higher quality evaluation function comparison
approaches, since application parameters determined
once. current tournament version LOGISTELLO uses feature weights estimated
means logistic regression profits comparability evaluations different
game phases ensured use value adaptation. result possible
perform selective searches values different game phases compared;
moreover, values opening compared even late midgame values order
find promising move alternatives program's opening book (Buro 1994,1995).
sense, value comparability cornerstone LOGISTELLO's strength.

Acknowledgements
wish thank wife Karen competently answering many statistical questions.
- urd-anovic many fruitful discussions led
also thank colleague Igor
considerable improvements Othello programs. Furthermore, grateful Colin
Springer, Richard E. Korf, anonymous referees useful suggestions earlier
versions paper, helped improve presentation contents.

References

Agresti, A. (1990). Categorical Data Analysis. Wiley.
Buro, M. (1994). Techniken fur die Bewertung von Spielsituationen anhand von Beispielen.
Ph.D. thesis, University Paderborn, Germany.
(ftp.uni-paderborn.de/unix/othello/ps-files/mics_dis.ps.gz)

381

fiBuro

Buro, M. (1995). L'apprentissage des ouvertures chez Logistello. Magazine de la Federation
Francaise d'Othello FFORUM 37, 18{20.
Duda, R., Hart, P. (1973). Pattern Classification Scene Analysis. Wiley.
Hand, D.J. (1981). Discrimination Classification. Wiley.
Lee, K.F., Mahajan, S. (1988). Pattern Classification Approach Evaluation Function
Learning. Artificial Intelligence 36, 1{25.
Lee, K.F., Mahajan, S. (1990). Development World Class Othello Program. Artificial
Intelligence 43, 21{36.
Marsland, T.A. (1985). Evaluation Function Factors. ICCA Journal 8(2).
McCullagh, P., Nelder, J.A. (1989). Generalized Linear Models. Chapman & Hall.
van den Meulen, M. (1989). Weight Assesment Evaluation Functions. In: D.F. Beal
(Editor), Advances Computer Chess 5, Elsevier Science Publishers.
Mitchell, D.H. (1984). Using Features Evaluate Positions Experts' Novices' Othello
Games. Master Thesis, Northwestern University, Evanston Illinois U.S.A.
Moriarty, D., Miikkulainen, R. (1993). Evolving Complex Othello Strategies Using Marker{
Based Genetic Encoding Neural Networks. Tech. rep. AI93{206, Department
Computer Sciences, University Texas Austin.
Mysliwietz, P. (1994). Konstruktion und Optimierung von Bewertungsfunktionen beim
Schach. Ph.D. thesis, University Paderborn, Germany.
Reinefeld, A. (1983). Improvement Scout Tree Search Algorithm. ICCA Journal
6(4), 4{14.
Samuel, A.L. (1959). Studies Machine Learning Using Game Checkers. IBM
Journal Research Development 3, 210{229.
Samuel, A.L. (1967). Studies Machine Learning Using Game Checkers II.
IBM Journal Research Development 11, 601{617.
Schaeffer, J., Culberson, J., Treloar, N., Knight, B., Lu, P., Szafron, D. (1992). World
Championship Caliber Checkers Program. Artificial Intelligence 53, 273{289.
Sutton, R.S. (1988). Learning Predict Methods Temporal Differences. Machine
Learning 3, 9{44.
Tesauro, G. (1992). Practical Issues Temporal Difference Learning. Machine Learning 8,
257{277.
Tesauro, G. (1994). TD{Gammon, Self{Teaching Backgammon Program, Achieves
Master{Level Play. Neural Computation 6, 215{219.
Tesauro, G. (1995). Temporal Difference Learning TD{Gammon. Communications
ACM 38(3), 58{68.
Wedderburn, R.W.M. (1976). Existence Uniqueness Maximum Likelihood
Estimates Certain Generalized Linear Models. Biometrika 63, 27{32.
382

fi
ff fi


"!$#&%'(()*+,(.-+0/1

<>=?A@CBD=EGFHEJILKMEGFONQP&RSNUTJFCV
=Fa`

2345$68739()3:;4
!6&'19(3)

KMWQPXVY=N[Z\FCIEJW^]_TXN^=EGF

TbWQcJE&de=TJFf`

jSkmlonQprqtsguvrwmxk

EgVePihB

yz {|}~Qb}~8 X~{z

b&Xr 3.. b
r
$$Q Xr"
Jqkmk8qlokQvQx

~~\b~8 }{| {}} }

b Xr3Ori0Jbr 3..
^33
YGS3833O

r
$ 0Q " X "$be




g

$ e X0 $C 0 ^

J Xbb3 Q $ Q g
Dg X >0goC800 0
S0 b U03$e0 bC

QO Sff fi
0^8 [
8 Sm g0 8 0e$ X

"gC0S JS 0
0S ff$ ^ 8 JJ3O ^S
$ g33 $ $ $


!#"%$&'!
(*),+.-0/21ff3545+768/21ff9):0;<:0=>+.:@?1ff3AB+0)97/*CB+0397;<:04Dff9:E-B14;2=.:0;GFHDff9:I?/2JLK0;M:0CB1ff),1NCL-J>?OK01PAB) 1N4Q1ff:0DN1
+765/+0:0=7R'?1ff)3SCB1ffAT1ff:0CB1ff:0DN;1N4U;M:V?WK01X?W)9Y;M:0;<:0=ZCH97?W9B[]\^41N_B`01ff:0DN1>+76)9:0CB+.3Sa79) ;<9-0/21N4Lbc1[d=H[fe

9g41N_h`01ff:0DN15+76*+0-041ff) ai9Y?;2+.:045jffk
k
kn
kpo#q.erCB1ff:0+?1NCsk
;244W9Y;CX?+g1NuhK0;<-0;2?v/2+.:0=7R'?Q1ff)3
'Nl +7l
mffm

lffm
mffm
'Ht
CB1ffAB1ff:0CB1ff:0DN;21N4;G6w?WK01xai9) ;<9-0/21N4%k n 97?y9z=I;aI1ff:v?Q;M3{1}|~9) 1*4Q;=0:0;FHDff9I:?/2JCB1ffAT1ff:0CB1ff:?%+.:?WK01xai9),;M9I-0/1N4
k n<

97?35`0DNK>1ff9),/;21ff)5?Q;M3{1N4|
|W[X':U?WK01N41Dff9741N4ffe#94QJ.4?Q1ff3?O)97;<:01NC+0:X?WK0;24CH97?W9Ebc1[d=H[fe?+
1
35+0CB1N/x;?Q4CB;24?W) ;<-B`0?;2+.:wex+.)539I71DN/<974Q4;GFHDff97?;2+.:04+.)5AB) 1NCB;2DN?;2+.:04
KB974g?+>-B1s9-0/21?+X4?+0) 16+.)

9)-0;2?W)Q9) ;2/2J/2+.:0=vCH`B)9Y?;2+.:04}-0;2?4%+76;M:I6+.)3g97?;2+.:5;<:g;?Q4*4?W9Y?1xai9) ;<9-0/21e0Dff97/2/21NCs n K01ff),1[y:=I1ff:01ff)97/e

?WK01 CB;Dff`0/? JZ;4:0+?+0:0/J?Q+) 1ffAB) 1N41ff:I??WK01N41s/2+.:0=YR'?1ff)3^CB1ffAT1ff:0CB1ff:0DN;1
4ffe-B`0?P9Y/4Q+?+ZOO>9
) 1ffAB) 1N4Q1ff:?W9Y?;2+.:X+768AB974?OrNi8K0;2DKU?W971N4?OK01ff3;<:?Q+97DNDN+.`B:I?ff[}Off0W ffrH
. #rff#Qff
b`B3{1N/MKB9I) ?ffex;<:I?+.:wex;2/2/2;<9354ffeffIB%;2/2/2;<9354sw;<A041ff)NezffI

ep6+0)v1NuB93A0/21eKB9
a19:

;<:?Q1ff):B97/~4?W97?19:0CX9) ;2DNK1NuBAB) 1N44;2a15AB+7x1ff)?OKB97?AB) +7a.;2CB15?WK01ff3;2?WK?WK01:01NDN1N4Q4W9) J/2+.:0=7R'?Q1ff)3
351ff35+0) JDff9IAB9-0;2/;2?;21N4ff[
\z/2=+.) ;2?WKB3{4*?WKB97?#DN+0`0/C1ODN;21ff:I?/2J/21ff9):5?+v),1ffAB) 1N41ff:I?*/2+.:0=7R'?1ff)Q3]DN+.:I?1Nu0?#}+0`0/C-B1z`041O6`0/r;<:
39:IJ9) 1ff974x+76\) ?;GFHDN;<97/:?1N/2/2;2=1ff:0DN1[xH+0)#1NuB93A0/21eB?WK01NJ5DN+.`0/2Cs-B1v9IABA0/;21NC ?+39I:JAB) +.-0/21ff354
;<:L:B97?O`B)97/x/<9:0=.`B97=1sAB),+.DN1N44Q;M:0=re-B+?WK9Y??OK014Jh35-T+/2;D /21Na1N/{b1[d=H[<e~/21ff9):0;<:0=E=.)933g9) 49:0C
/<9:0=.`B97=I135+0CB1N/24
4JB:?OK01N4;24

[



ew9:0Cs4W`B-04QJh35-B+I/;2D/21Na1N/bc1[d=r[<eH35+0CB1N/2;M:0=sAB),+4+0CBJ6+.)4WAB1N1NDNKX) 1NDN+=.:0;2?;2+.:+.)


:+.) CB1ff)x?Q+?O)97;<:?WK01/21ff9):0;<:0=4J.4Q?1ff3eBK0+7}1NaI1ff)NeB9:1O1NDN?;2a1v351NDNKB9:0;24W3+Y6Dff) 1NCB;2?9Y44;2=.:IR

351ff:I?8?OKB) +.`0=.K?;<3515;4v:01N1NCB1NC[+DKB9I:0=1v?WK01AB9)Q9351N?1ff) 4+76*?WK0154J04?1ff3;M: +.),CB1ff)?+DNKB9:0=1
?WK01x;<:?Q1ff):B97/H4Q?W97?1%+76?WK01x4J04?1ff3]9Y?#?;<351|WeI4+v974#?+;<3AB) +7a1N?OK01};<:I?1ff):B97/r4?W97?Q1*+76w?WK01x4J.4Q?1ff3
'((3)QfifiB6 Q 6%X0 #r 3ff5$ #4
!'fi

!3c67
g

fi#HrUBHOBBB

<7ff<W0Nh0ff0Nw00vff NffB 2N2B,.B7.7Qff NB28.ff 0x<I.Q72. B7I B
<Z<5Lr.gNhg0xO0xB'>N2N72. 2WB.XXxB}~NW,000N
8
>N2ff%ffTwN.<00wy0<0ffN#0.0H0xffz0>O0{BYYB .B7072. WB .00X<5
72.,OB. NffB ffIv0ffB7x0N }0B5N<B Nv7<*ffI N2X.XW0N>I<07

ffB 2.wzB5ff 00v.YBffI 'BNNffIBYN72.,OB5vB
BNffEB .BINX.z20M0 W0
ff NB287Q2.B5ffIB,.02ff5xM,NffB ffI0N x.IdH<0B5N<B xN7<wffT22<5

<0ffN#
N#N
NQff N0ff B
0B0B7NQffYBff022N5<sO7<0<0s NffB ffI



0N x.I*5Bff.

W7WI*<802NW0zffT.7rN.I<0ff0N2N8B NffIxMO0<BB0
7.0WB0

NB0ff0NNOBE2.0<Iff 772@%ff02Hx0< xQ7N.0zfffiffH%X NffNzffT}x0xffN
ffff.N%ff02N*78 ffff.B
72 0B0W0N. NQffYH ff7.0~.~W02xBff02 {I0B 7N

X0N.72 NW025.B5NO 2BBB52ff7Q.Qff5v2WX0.I'2<0ffgW7Q>0N.,'W7
NffB,ff0NfiW

22vB M0ff,ff7<02Bff0 >WQ7<W0NL70ff

2W

.YBffIvBNQNff7W0HBQ72.X7W0BffBff0Bff0N2NTffI0WB NEM0ff,ff7Nffs N



"!#$
%&('*) + 21 g7WI
%,&('*-/.) 0
ff7QffY}B720257W0B .02ff^O0iWB7ffpBffBff0B<00XW00.43563 7W07.7N00MI
7O 28*.0Y8 }N00BQ00 2N<UW0NE.Qff5ff 0ff93:32;
IO0BhB{N57
W0vYW 27*B <7wBff 2iY2N7#W0W7Q0N0 'W7QzB0N2.w

W0v0N x.Y27

N2MI0 .,v0Q7#MI.g72.g.02WQ HBY2.0ffBNff2W

B0B0BNs<BB0v02H07xNffN0.YBffIO NWBNNzff,.x782ffQM{ffiII
2WNBB00ff<722'77x.0vB,.B7.7QN}O0ffB7N <<52<W0W0ffxB0Bz0ff

3:3"=

I.7B2ffI*ff?>H7LB7N 0B0*W0.Qff]2x2.ff722B0W020ffB0x N2<02

0 027}<I.7Q0.2.0<55%ff02sNv7 ffff.O0ixN>07

O05.B,W0

2ff0<0sY*007'ffBffBff0Bff0N2NIsB0<0NBB.0ffI<7225. xN0z.O0<@>0ff0N
78O0. 'ffQBffTff0Bff0N2N

c<EN.BI 2.UX007'ff^BffTff0Bff0N2NW7ffW0.7B2ffI

7}gNx'B0N2. 2WX NWTNN8QWQ7<B02{BI5Nff,ff6A0{IB70N072,NW02B022N

s0.I'2<0ff5BI5Nff B NNEBhB{ffY*0ff5O0>Yv5v NffBQ ff50N }0
B050
2<0ffvB,.B022Q2s5.BN2W0U7v02BBff>>Yi50BN2PXONCA0N5.BN25

WTNNMY*ff757x.BzB N.2.05 NW02v<Xz0NXW0DU0.QE3:63
IBNff0gW027O 2
GFHI(JK"LfiFMHNOJvYW 2pd<g7W 2QP

7xW0QQ0>B .B02222NRPS!#UTVXWY3:

80ff O0vWY87 <02[#ffO7]\020B5Bff7y77<0Nff

UZ'N

A0PYMEN0W,MB0Q0E7O0BTff52W0ff O. sI>N0ff02.E7zW0s0N.72s,NW02

.B0LE*ff0IUN{YL,fffiff. sO0ff7Q7C^QL@_a`fiIb(NOLcedfI(ghiF#z0NE<0N<0BsWI0H
XxB

j

N7<%ffTwN0<0.ENYf*ffI7vxN2}Yi <7Q00YXXW0U7

BB0k <0WB0XX j <XXWs%ff02YN.0fflIBN*0L#,<72m<0Qff i02

>77onNN22.V* 0NNN>p<zqnvW0.0B<HffTffTVrB 2Ww
NZ>\0
WB75<Eff0ffY%B0ff005ff0.E78Bs02.

7N.QN.0ff NB27Q0B5ff
#H0XW0

ff 0B2N2 7#W0vWQ022.sB,.B022 X7W 2NNffrBBff,TWO0 ffB NQffWY2.s0 W0
2ff0<07y2.0Y'ffN.IN0<W0v02BBff WYi,MI0

%Os0.5Iff0N.0v0>0.I0.{ff0N.0z>770MIs50BN2 N.02Bff NutvI@dIxw/h,y
czhkI{@F80ff 5ff0WBY8W05WQ022.XB .B02222N57*W05>775.BN*I vN.0QWI87ff
<5O
| ~}vI@c[yK"IdfIaw/hczhkI{@
F 5ff0WB7zW0NO022.>B,.B022QN 722ixN>QsBBGc
ff ffz.ff7NsQM{QffwwdH<w7gB0NQ0sY N0ffB7~<BB0vWB7
sBgB
ff ffIv7
ff7N5<5Qffw j gW080.5Iff0N.0*ffYcdr<7W0HI XXWN7W0N50BN2xff52ffgW0
B2W <B02.~
~7.0OB0#Nh0ff0NNY

I{Y0NMY<0v5.0WB0#B2O G


( (a
kzfiaY
2
:$Ofikx/(( afixOV(x(Y
OVUx:(fikx
' kYO6(OfiOkfi ''-". x( '*-/.[ 'O

((

fififizaO[qqR[[z"[*[ezfi

["aB/fO
: x$(fififi" fik"p[Ba(aSa
fiafi"B$ ]
"V"/@"/f@("/"
(fia
a"aBaB/G"/"
["[Ba
["aB/"C@/"[BaB/[fi/[["a["("BfiV"a
f"[fiaB/"k""C6([["v"G/"
["Vx"("
"C(afi SQ 2("B
afix/"6 /"
""CB(x"?qf"[6
fi$
"u/"[BaB/[fi[Ba
["aB/ fi
"B(G["aqaR("a
/"
["a"("f $"(q[["x"("
B$@@(
fi
a["("R/ aaB/q/Sfiaa z(fix"VB
o([a (C"/ff
@ qk"(afi
fi
"/"[
p( [( S[B
2( "a a/@
["aCVB
"[[(
a/"
V@aV"V/" ~aR["BBQk"MG?/[["$fiBaauaBv[ /[(x"("
SO[Ba(
fiaB/"q"[(Vx ! "?# "~[Ba/[@aok[ fi"k[V[
[fi[([("[]/G
"fik
aB/

fi(
"~/"a( 8""
["Ca["(" "
"~aafia [Ba
["aB/ $
"~a
fia
' af
[fik"x"("~fiaB/"(
fiC"ok"x"("~fi6[["a

a% $x/& (
o)
fi *
Vq v"+ fafB@] k"[(z[fik" v
f
/"a"Bf"
"
"/@"/?("B& fip
" ,
fifiR[fi $ k"CBBfiV"zz]
[fiB"xk"C
?Cff [f[ .
a~[("af
"]a"("u
[fi/kB$ka"aBaB/q[/[@"BBaB( [["a" Vq C"
fi
fiaB/"//
fi *
"p"/fiaB
"Ba[a(@aCk"[( [ ["BB("BVaB(a""CfiB/ k[f
2 ["( /k"(/afi[B(@[fiaG/"a

" fi
"
0 fiB/B
[ ("ax(
1YfiY 3
f "(fiaB/ fiB/B
[f$"BMo # q/G/xfiz[fiB @"QBa(xfiaB 8f"[4 "" /@a/"""fi"
[a@fa(O
"ofi
x"aBaB/q[/["BBBaB(/[@afa( $fiVu["x"q/["a"G
"a
[/[@"BBaB "[(a""af "fB(a""~(Ba(B/

5687:9<;=?><@A9<;BDC9FEHG8I>JEKBD@ABKL?9FIBK>JM
NOa/

( ff
fifi"@f/[[P"of[Ba(xCaVakfiaRQ/SUTUT+TVW"z[/[@"BB
[
aB~
a"aBaB/Q["aB/ OakfiafaQ"X"akfia "8 [ /["BBxaB/"
["["aB/Ox
fiafa
"C[Ba( afa
fia] @" (

fi]fi"ZQ/SUT+TUTV[W?$(fix?Caa( /\
/"
["
VBBp$ x^
]/_ `"V
"fB(f(@ SDa fi6fik ]]
]Yb ]]cT+TUT&] /Vk"^
V<dfeR[fi(fi
]]
"e ] b _ `V"
"B(f(@R SKa fi?
] b " 2 ""(( /@
"z"aB/x Vq (
"8 "("k[Y( /[aBk(("C"[aBaBffi

"(
g*hiffj!klUmfhnf"[([("[("fix
["aB/u"Bk[fip
"a
aV@"B
[u "

"[fiaffi$k"Ra["(" :
<
pUS+TUT+TffS
qF : qF
N"
"(?"[(("[("ofi


["x"/"(
"a
aV V"B[[(["Vf/"k["pYB6""a(Y"B
[fipk"V[Ba
["aB/
fipVaf(
r2[/"V[(("q/
"@
"($[aV@"B$$"(G B( "
fiaka"a
aB/"Vfi2afR
rp+ f[([(" "
"s

"S([a(@6[["/ SQ /2
"([a(@VfiaB/
fi "( CBBaG@at
/Y
fi *
Vq tVq
x"aBaB/fik u] [P "o

] _ ` f



fi$

?
, qFp

S, w v


$"(*v B o@a/ffi!$ "ak"B [@afa( 9
"Q"/?("/"~(fia
"q
x"aBaB/
fik BV/"a
@(@ ] ] "v[@afa( xvG
"("
[fiB[a~[(@a zqVB


"B(f(@afik"
a"aBaB/Gfi
#y]
"k["(fBaaB/"[([(" /Z "e
"[a(@akfiapfif
zo
"""
["
fiBau(fiBq(fBax" [Ba
["x"Q S, ffz "VB
[xfa(H
z /2X u" p
"
ff
fifiV[fiB"/f@("/""]
"/"
["Yfifi"p[B/"a$
"Bafi[[[( [[B&
k
{[
"(~k"[a@fa(H
z ([]BBaqG8
{
uVqfik u|u}
|s~ _

U

fi.J<ZJP

RwHffXUX( tUyRUU,!ffXt!XX&8ffwsffw&ff8f ? JR
UXyU!ffU84 *UX8U!ffUy&U&X,UffXAw^X%8/U
&fftff!,w!ff(R#sffXXXffX)!XXyff^#,w&ff*8Uxtff!-ffw!ffXw
!ff!?,XffX&X&AXw,ffXffU&U[(uJXcXX!ff
*#,%Rffw!ffUYUw,w!ff*RU*&XU&ffXA%XXff!(P&X
ffw!ffy .Zff))U+U&w[u%XX&*ffwtff!Hffw&ff
8w ffP})Y8U%cfft,ffUF cwUcwUtUUff%ffX!XX&cff*w
ffw&ff*8f X , ff
P!ffRwffffffUX,wff!X)&PUP&PJ8H<ff(X(&!ffffX!ffX
ffyw8ffP!ffXs!?w8)ff%yX!FK)&ffUX[w8&&8 3X A/Y#
Xffw,!Xff8XU&8 ?wU&RR8X&ff,
}
fiff ff[
YtUff)XX,#8!ffUZff)8!Xtwtw!X 84 t.wy&
Y!X)UwR 8f[ P? tXU&
X8&ffXs!w(ffXffU&H!.w
X YyU%XX8wXYw!
. %#&w Uw4ff !Rww
wffffff#&Xt&tff8*UFJwtU!ff!
"Y** #H
XY!F% $'&'(* )FXfftXY!F% $+',* -/UX% $'+$.H/ .0"Y**( #U2
1 ff!ffX4[% $'$'3
s#,Uff!ffXU<Y!XP(ws!X/wUxU&ffU&)fwX!sw&#
U&w!ff!ffcX&HXU)wywffXUXcwyXff&XX8X4
#H
X%4*% $+'5Xw!!ffXc*,8,!U&%ffX)ffU!,#!&wt.&X
wYX8w!ff^!wYff%#UH!}PUffU&ffU&Ywy&XwXX?ffwX},P
ffU&+K%#<!}PXffU%ffXUPYUff!#P UK4ff&JXffPw,ffff
&#&8!w#XX8 #U2
1 ff!,X% $'$'3J% $$'3XwXt!

:4 Uw A-P w.A84 P Aff, = <?>A@ > 7 f 6 > 8
6798 ;
&U
B 798 ;
:f A,ff . < > @ 7 > f. C ff8f C ;
D&,9 C E B > 8 C
U&RP(!Uff!Fw/#!X)sw!X&Ps}!ffffffU F
84 , .;
G 6 798
7

I8wtUffcU&ffU&B 798 JLK wUSB 78 R JTK KcffUff!
H ffyw!8
JNM'OQP R
JNM OQP U
8!P&XXUHRUy&ff
V
V
X
W @ZY [N[%[ W @ZY
]
\ ;
@Y WH [%[N[ @ W \
V
U& _
^ 6 8 U+ 6a` 8 9 b \ _
^cB 8 U+d B ` 8 9 b e
WH.(!!8!P&t!U^#,ff*&
ffX8f u ff,D) ywZg f9hcX#U^Uw:Y8!P&i
@/8Xw!tw)w,ffff
&#ffXR!Hff0
jw @/D 7lk ;
:s8P Offff.&wFX. URU!ffU JXw!
wRX!Xw%ff
@0m n 8 p q
@Yo nL@/o nrC [%[%[ @/ @Y
,
JXff-!}8%w&XX s.U(YffXff/XffU&YP tXX-!wH#,w&ff!JwHffw%ff?o n
n p
!,^u
jD.swffw&ff!P.ffw!ff?%ffu
jwvjK' F@ 7lm k 8 ;
:sXx nxOffff n PJP
yTz{|~}/co29|oL/9w%Nd/%d9}/909NN|'|99|%|u%d|%cc9Qo%
< ao/9o/z
%%

fior9o2xA'

w%*'wQgar2XQLwL''Q'Lw%'Q*wLgg%%?do
%%LxQ*d%r%A%%LgLLwQgqr%%%roeL*QrQ*
go %ALL*~eQQldL*Qro*L~*eLLQrLQ'% ALL*~L2*e' *
o%%%0 ?d%E%rL%4/eLLrQ*e='0Qr~Qr%rLg
'?
o%%rLN/gQworLLrQ*Erwo'*Lr*~r'%rQ%r'Q
*roLLrw*LrQ'QLL%
9
fiff
fi
ff!#"%$'&
)(*"%+,$'-,/.0213(4#"%+5$fi6
C2D > $ E G
FIHJC2DLKNM=OQPSR

$fi.).7#$98:"%<;= L*rQ'?>A@ +5$9"%"%B

U.V$'"%$9&B QLL'0L?ro~Qo'Q'
W27
X r%rQ*=0wQQQrQr C2Y % KNM=OQP ZFIHC2YZFIH

fi
ff [N"%B-7\]?.7"%$'-*(4#"%+5$'-,/.0*1^#_SQ]#"%$'&
`.7a
b!#+_*(4#"%+5$ 6 cedgfihf $ .j-,k9kl58
rrLrrQ Q#m
+ .7$9(ZnNklo r*Lrg $'p"'\]$ .qniVni
+0r$ Es H=f tu GFIHwvyx^KNMvzx|{
{B{}~{
fi
ff'1Jk'k @ ];7kl(4#"%+5$9-57.Q01S#SQ]"%$9&B(*"%+,$ 6A$fi..V$98A"%; L'ol
Q g $ EjB&
B+,og+_ @) -5#klb!(*/J.Vb!($ .n?.7$9"%$'&
R 1J QQw'Q (4#"%+5$fi6r$ .j;=#"'\+_ @ #S8-,#klb!(4
#k'kl @ ];7kl R

*LrQ'l X%e0rrLorLeroLLLrrQrQ*r'4L*rro
G'Lo4w $9-
$'8#
-,m(4#"%+,$ 6 L*rL*or'Q'%*L*rQ'0lX
Q4 x l X0*L'~%oLogA'rQrQ'w%QL '~ x uwoLQ%LEX
Q0LLLrQ*Q2l XLrLA*o0r'4
fi~LrALLLrL%E%L
*~Q'%Q2*A%rQL0 ~Lr%oLSo%r~04 "%5n#kl=!o
dQLL
l X L*rL*er
8#/.
;9wQQuQr2r
rrL ~Ll fi o2'
'= o'2*LoL


fi
ffL,+5+58#b!-
$%;7klq#"%+,$'-57.Q0w1S#!#"%$9&B }} (4#"%+,$ 6 fi$ .q.7#$'8*"%4;= orLLoQ
$ EEV#+`
&B
+5omni#$'+ M=OQP _Ej$98#$'-,/. > v M=OQP n?.V$'"%$'&
4$9"%!
+Z. R " R Z FIH2DSR
l X Q2orLLoQS*Q r*LorL!*r'SQ .V"%+_#]klo-,SS5-
"%58 9c'o
%7X*Qrr~eALL%''o0wrrL M=OQP L +_,8#b!-
$%;7kl lXQ*0Q~'
FlFGD 9c'o%~Qe?4Q%'Ad* * r2QrLLL
orLLoQ'2:
%c%
Q%gQL n
+5$9B8 uo7 X l Q0*%rLwL*~gQr*~9c' 'rj

FlF~2D 9c'o%E'g2w Q%'p
*QL
=# #Lr'oxowQ
v L /
'?orLLoQE XguogLLN'~'~%Eg Q g%QQL niB+,$'
8
l XZ A%Q*el X~gc' Q%'gLLQLo0rrLorL
rrQrQ**r'

e7 X'Q%EgQl Xe4%EgA
~QQQorrrL'e*r'
u
uQ*E
grro~d* *~u~rrL'LroerQ'E04Q%'
#**~
rQrQ'orL'%m



fi
ff: +5$9(4$'"%$9&Bg(4#"%+5$fi601#_SQ]#"%$'&
4(4#"%+5$fi6
`2DSR
76?$fi.7"'.J`ni?.7$9"%$'&
4$'S"%Q]B+ . R " R




$ .j.7#$98"%; o~QrQ' $ Eg"'\]B+_

fi#S9eS5

G!
_5%]_# fi]=#Z5A7]_7,!!!A_fi4l=l#g?5_lN ]!g
#AUGB!JN!?,
?l
!#,]
?=
q,=]*p7_7
#qr!!7
#!I,!
_j7!l==j?,?l
!#5
p7_7
!!7q#!S,!
*#_4?l=?,!m?l
!#5`#jL7=# fiG,!4#?l]
7l?j|qGlm7]!=l
,g?5_l77%#!7]_7,!!!),!]#!,`!lVL#_p_fi4l=l##
Z#=j5?fi=_7S!7fi!lpg?,lJ7l,!
J
_l]lg]m_fi4l=l##fiSU
_l!2
7#!,?
g_fi4l=l#`==!VU==l*gU,_lgl!777,#_ll?ll?G#!l#
Nfi^NAmB N=~
~S44!NBS
ql]7l#
#77=]`?`g?,#!g5!7 7]=_75]!fi!47l#
#??fi!7rB#q,!q%#llZ!
_]
_=l7g'=7
|7l# ff
fiS%]G4]]7l#
U!74#!7l#
#77=]_5
7=
=4fi#]
!
_l5!J
=l_pg?,S#!
% #fi



"! !#

Z#=m,?|!`==!VU==ljg?,)( $
( ,!m_#7=q7l#
?fi!g?G!]=#!!l7
#rJ,!?
?q%#ll?G
&
%7=fi!r'
:#_]gU
!qJ]!,U




( (( (
( (
+
** "! ** , -! ( ( , "! , ff
! *
!
**
*
*
*
.Z
!7p?l5!r7l#
?fi!7rB* #!]= l* 7=g]/i?q=)#0%7g!*5N!5!r#77]J?m]!7
1 32fiff4
547676684B:9<;fiGm!
_=5;G
!#=7,!,#!,=p?S?>!fi!7@ 1 1 25N!l=l]?
==!7?==ljg?5_l77
JlJ#7l#
#??fi!g#! 1 lm7]_7,!!!_l]G7l#
#77=]7
Z!%#ll?Gfi!j,!7]
GlS!=5!fi4V=?7=
_B7A fi!*!!4##
!7]!]S!7=|?S==!7?8C
=l*?,_l77*%UfiD."E0
E ,7
I~
H
=_]5C#J_]
!fi!gG!7]
g$KML NffNPO QSR$UTVQXWffYZ[=Z\YOffY]^Y_R#`aWffbT<c RdNMe:T<fgThbT<c R
fgWffbe:TjiffklnmoR YpbhmoR e8RqR irTVQSbhQW5YsR Tt`aR7Y_c7WffuBLaRwv$QLox mpbhmoWffb#y

4!NBSGF

z kv{TjQe8R|W5u}WffY~NO)QSThbT<c R
kv{x|W5YsRqW)Q|QO7x T<WffbR:~$T<bhm$QSbe:Thx7buBNO)QSThbT<c RguRISbWffY~$e:Tt`5mobR7T`oR7Y_c7R:x7bOffeQ:
( (
v5
kv SOffedWffYR7T`oR7Y_c7WffuBLaR0
kdbhmoRgR7T`oR7Y_c7R:x7bOffeQW Q|QO7x T<W5bR|~$T<bhmv{Wffe8RLaYTh7LaRgbO{x|O5YPQbWffYbfgLaubTNMuBRQ7k
( (
( (
kj ,\, W5Y~\TjQgWffYR Tt`aR7Yc WffuBLoRO8 g bhmoR , vPkg0Offe8R|O5c7R7e v0Thf-NMuBT<R Q
gk
kv{TjQW$QT<f-NMuBRge8O7OffbO8bhmoRx moWffe8Wffx7bR e|TVQbT<xgR:7LaWffbT<O5Yr7
=4fi#Uv ]k
7

fij hP0j0XPPaPVP@ff
taP8a j{|agPaoX5{a7a|P}75PffP"ao87ffjff
j8noaPa7a)|a&n78o5#MoP7ajan|ao87ooP & |8B}Bn|a78:o8
|affBBr-a_
7<V 5 qVgM:<gh< 7 <$gff:jff0no7<hBffho S7o ffBoVX
ff_sha78{jff_Bpff_X:ff:^ #Pff5<5s:t5o7o7_7:7ff j :
}a|ha7:q5^fiff5<
ffho ta7 ffBo 5^gB:hoff <Dg7ffaBff7
+ 5 Maa0 &aP B | |a wpff ffffM)n|agBff7 r ja
P ff&g ajaBno P 5ffn"oa a#8o|a&n78a5#M8o7aja&"ao87|P
Bw|ajff8ff"Bff7 jaff B"|aPaBag aj Bff7 ffo 5 B}ff|a7Bff7 r ja
ff
:apa ogBo$"BB B7aX|a$oaPa7a |aBo8ffBjff8 !s
|a w5a7a|#
"7ffP $ -|aoa )qaff-|P BoP Pa |h75< "B|$P78B
% o:a7 P % 57 ja ajagwaBSDff8|a % oaB p8aff- ff

&('*)+,.-(/103240657

d|aBa"ffP B98|a7 &) P8jgB:ff "|5aBBog |8: nB ':a57a7 a7
"B|D)#7 B |ff_ffh:ff 8:#a 78ja{ |aq)|8:{j ;" PB <$ =j5|8
7ha7ffh7hg| ?> 7h7_h j$o 7 g7 |Pw|a A@X7aB8Xj75ajaBoa #7 77 7a
G QJSRNoJ UTVK NRVWX E6GYELE[ZNJ
B DCFE?GI'H J4KL dKJNMPO F
: Bo58 a8"ff ffPaBB7 Bo w:an7o5#M8aP7ajag|ao87 ff |a{ aj o8ff
jff80Bw5\57{j{|affBB "jaX|aa87{

]^ JaMJG`_bacX jp M:<gh< 0S o)Sh0q5|Vffho )*d#e fgff hie kj Pl a78mj
VX|5<B:phoDo_ n o$ffhffff:p5j|?oahff pc$ho;q0ffsr ff{aff< o{8ff{pcX:5M87ff =j
o:ffg7:hr
taP8a j{|agPaoX5{a7a|P}75PffP"ao87ut wPv
-a5|aBBo0P7aj :aP8o) jaB08Ba$|aI)"|P "a7p)|8: Bw:ff 7
0{78|)P 7 x nBBga: B7ffp|ff)qBgBff7r jap|a:ffgXr7
Pff 77ff8BB7&)|a57 jaffBgoPP &poa$j=g aja70"a78:o8ffn|a
Bff7r ja{ waBSff8$X|P5 {ff8p)a) a7ffy8 78Bff7r ja$ x
z e{f &-aoaBXBff7r jawaBS affo5 78ffy8 78Xff8|affwwa5g aaBff
"a78dBoaBpoad|aSDBff7r jajD|ad7 )P8jgB:ff aP Bq |8:|" oj
|ad57ff $ {:a7 )P78B )|8Bw) 78B }% B7a Brd|a7ff8
oaB{
Bff7r jawa5g aaBdff waBpffff oa|a %~ 8aff" Pa8ff
= q87 Bn|P ":a ffP)X)|8: Bw|a jg7aBo0 &:aBja7ff|Pa|P g|P5Pa

5p|aBff7ff a8 ff o8|Pa $|aXaPgP7)Bja7ff8Bj 7P7 758 "#h"
ffjPa$ aa|aX :8: aa| ja 5p|aP8 9j 8ff o8P 5Pff
oa|):a{ffB "ja0#8o "ao87{v BXP \5 ff"|a7Bj h h 785
:8:
waff{Bff7r )ap58)p 7a odoa{Bff7r )a }h" "B|o8|Pa
Bff7ff $ ffjP|a5P$ :aP8 awaff 7ff"{ffPa0g7ffa":P "B8 ""ff8


fi(S F4444
4 pkkps:k4k!sk4s\;*p:4pkkps:k4::p|:9::s}p44::
[9? ?4[pA *6 XF 3:?:: <4<9y4:sp[49s:k! 9ysss[
I3 49k4::[9449494:s49\9#*? [ F9ss(.
[9ps19::(:\[9sss[(:k4<4<9:9(4pk9(<9Ps94k
4p[:s:yss94s:P*p:49;s9:;kp9s*p44::[4*? V [ 3
499(49mkp k. 93 4k[p(6914(k9<?kpp
[!s[1S? fi?[* <F9}9s4::!\syk9s49999p
:;9p?kp4\;:;I4w9\s|94:k93s{4949\gs49s[
9s[9}!9k999i `:m4p[:s:;9s:s:k*p:N; s499![p99
p94::;9#:s[;999s\994< \:(49:s4\9s<9kp9Ns
999k999k4:i93 !91(9:.k*k9
4.9s:k;(ks9[k*s:k[;9kp 94 ! 44s:k9?
ff
fi!#"%$ff&' ()+*
U#s94m4pk9<9k9ks:**p:<99:s(?kss:km4k9[9\(ss
[},4[9?4ps:9[p:[*9<9k9k9k9(sfi:\S4.-9<p*0/
p21903(([ps[pk994(4ps:4:s94pskp65#9798
: 05;2<.7=;w1 > [ 5?71
5fi@7
B s4(s91k(?p?((9<<9 : 05 ; 9<+7 ; DC : E5 ; <+7 ; 94SF(G4fi
?[949:k[9*9 \[9k4ssk(Xs9skH5 ; 9I7 ; 4p[99KJs:ML ?kp4[9
s*944p4\4\9
N OHff)ffQPSR [,99TVUks\99#:!W.X<?.Y iS#Zp[1k? \ (]:9#Z]2]:(^(`_a]:
?[ibY0c* !?yp dkfepMg? \?ih
:
W.X<?( > kml a4n k 0: 5 0; 95 ; <+<+77 ;;
j jipo q
k4s99U<9#:W%r?.Y4?dk?i?ibY[EcS*((] ]:(^h
W%r?<( * >t su wv u v u xA
k
R yW.XX9zW%r<:\{ep.e4y 1k 030/S?[S9 49i4pkps:4
-ps\ff|C}WF?<DC 9k94:F4~WF?(|w9m99\A4<:4s:p?9
9p?kp#! 99#:spk4::p;4sA?;9* 1k03**\N4?[N
<4ssP1.9P*p:*kps*s#;4p9skp#WF? r 6fCWF? r ,WF6!
9F(G*9p?kp4:s9s|[9#99s\9N.9s*9#:s:s
49::!s*44w?;9 64pk9 p:kps#s#m
ff
9"ff&9ff z#"T T#
b r> 2 49 +^(fepk9ss94ss:*p: r <!%<%? .Npk 94k4p\
HW.X9W%rAWF6 6(< |*9:[ ~ WF? r,> 2?|4S?[N:[ ~ r,> 214P#!
9\4s:pD}(p94\:pm#4p99*\:<9m4.-9![ss
4pkp94:9#:W}9;!W X k=W r kp[9*I|#8


fiDTT, #I###)#(T
Hff)fft%y+D `2%20z`fM%(`% M~0a`T02(0.2.!b. 26(M!D(y[
(# (I( (9(2{T=}ffE , 0
= MM H (# , +
, # ,
!
# . , fi ff ( , , ` , `
% ff%= , 2 ~( (MyM%(`% M! (0 "y( ( # {(0+ . $ `%

% , )& +TT `%( (I( ( # 2y+(( 02( ( y` fi '
)D) 2, + .
-6H[ $
( *
=@?8A? B + {T=}H0T M# ! . 2 0I0bM. +0 ( 0(
0
942 :3 6655 387 >
/ 1
0
;<243 : 387
C4D ff# ff F EG#H!E JI
K K K ML N
,
,` # J # ,` Q P `#,` ffS R DT U R 6,
x V , , E ,W= # 6 % XY ~. 2 # (D y,
, # R DD(9 (# [Z \ 6 H ]
= ^+ {, ff @0M(` `%(2

_U`ba&cffff dce=!
dT
gf h))ffg
c\ ikj6!
i% dmlnocf h
p ` ,U R 6
ff =M6 , ff ff # x .(!
+(m(+.(f @ 02 EoG#H!E # ` ff q ^r ? !s ? u twv
|o|| |o|| F
yz r


z
z

,U R # `

^
r
}

|

|
|


|

|

|

z


z

r r ~



ff q
z




z

x zzz ||| s^~< |o||
k
Q
## (



z

s^~<



ff q




|

|
|

|

|
|

]


{





[}

|o||

||o|



!M rV?H @s ? ff q(M ,M ff r]? ff ` #M ,UR { ? ff ` #
(M # #B ,M `#
H 9 9 ff VM ff
ff!= fi
! .T ( &r sff q #Q M, 0M(#
( w = ,` , } fi @ `
#M , vB fi * , r ? ? ]Z[y F 6 , = ( J
` ( J * (, R ` UI = x f ff
E % XY Q ^M# \ x Z[ u ` , Bff
Q
]M
\ B

[

]
r ? ,UR H ! = E ,I , !ff ( ,
9 , ,` ff#J y, ~ [ ,

_j6!

i% dmlnocf h
p #8
] D, 9
6 , TJ , #Q # # fi









9










B











, =, , 9 ` , `#w ff [I ? ff


fi,#%
!!!!







Primitive sets

u

&B#!&o

Periodic sets
&J&

Transient set
&

,UJ!F#*#fiUUJgfi#!J6!Jfi!fi6fiuqfiJfiU^!fi!#fi
#F#u!q
FUF!Fqu6!fiJFfi!fiw&6ufik!!6FUVB]F]#fik
@!UJQ
&]fi#Fq qF
]*J@6fi!!!FUJq&#FqfiFUU F!Fq
6#fififiFfi J]6, J 6,]
#fiV<,qfiUUJfi]#Jfi
6 !fiJFJ!u#!fi fiU!6fi#Fq&FU

2

2
0

1

0

3

1
3

5



4




,fi!Ffiff!
FUfi!U J!FU#nQFUJ ^fiu!!fiUJJ]U6u64


fi "!$#%#%&('$)$*!,+$-'$#.&/!1023

4$56879,:%9;
<>=,5?7@"A4156B79C:$7D(E,F9,DHGIJLKMN<ODPQRE15?S>=,9TUQWVYX,5Q,5Z<>P$[]\^_$\`<>=$Pa<<>PGb7Q,c(de4$6B9,:f,DZ<
9;4$56B79,:$7DRghP<>6B7DZ5ZSiT7<>=%<j=,5kS>Pgl5l7Q,DZ7:$5Q,DZ5RgkP<>687m%PQ,:n4156B79C:.deo,75ZF:$SkPeE,F9,DHGapL:$7Pc9CQ$PF
gkP<j6B7m(TU=,9bS 5fidqE,F9CDZGS?Pb6B5?4$6B7gl7< 7r5KUst=Cf,SiPk4$6B9,:f,DZ<UIhuv-w>x v"yz6B5Z<>Pa7{Q,St7{Qb;N9C6 ghP< 79CQRPbE$9Cf,<O<>=,5
7Q,7< 7PF|E,F9,DHG7{Q}TU=,7DZ=W~ v-w TPaSKUt9T|5Zrb56Z[$;N9C6t5Zr56BoeS>f,DZ=%E,F9CDZG}9;zS 7Z5e\[7Qb;9C6gkP< 79CQT7FF
E$5cC6 P:f$PaFFoeF9S <OPE$9Cf,<t<>=,5i5ZmPaDZ<7:$5Q< 7<Boe9;
<>=,5iS <>Pa< 5fi
""C"q<>=$P<E,F9CDZGK
st=,7Sl7S(E15ZS <k:$5gl9CQ,S<>6 P< 5Z:<>=$6B9Cf,cC=P}S 7gk4,F5R5Zm$Pgk4,F5KW9CQ,S7:$56<>=,5(7Q,DZ7:$5Q,DZ5WgkP<>687m
6B54$6B5ZS5Q< 5Z:.Ebo<j=,5kcC6 P4$=9;
7c,f$6B5/1K/MY<fi=$PSl4$56B79,:RPQ,:<>=,5(9,Q,FoQ,9CQbpL:$5Z< 56 gl7Q,7S < 7D
<>6 PbQ,S 7< 79CQi7S;L6B9CgS<>P< 5\[TU=,7DH=DPQOoC75ZF:l7Q< 9O5Z7<>=,569CQ,5
9;$<T9F9C9,4,SK]=,5QighPQoOS < 9,DZ=$PS < 7D
gkP<j6B7DZ5ZSiT7<>=}<>=,7SicC6 P4$=%P6B5lglf,F<7{4,F75Z:< 9c5Z<>=,56[7Qb;N9C6 gkP<79,QPbE$9Cf,<k"CqjR7Q}TU=,7DZ=%<>=,5
7Q,7< 7PFUS<>P< 5kTPSl7SkcC6P:f$PFFonF9S <RV"7NK5K-[
7;<>=,5q7Q,7< 7PFUS<>P< 5qTPSfi}9C6l$[
<j=,7Sh7{Qb;N9C6 ghP< 79CQ7S
cC6 Pa:f$PFFo%F9S <j`ZK?=$P<i7Sl6B5Z<>P7Q,5Z:W7S?<j=,5?CZ?7Qb;N9C6 gkP<79,Q[7NK5K[7Q%TU=,7DZ=nE,F9,DHG.V,C[C\C[
9C6$[`9;|PkDZo,DZF7DkDH=$Pa7{Q}TPS<j=,5?7Q,7< 7PFzS <jP< 5Ks=,7SiS>f,ccb5ZS < S<>=$Pa<U7<OT7FFzE15l5PS oe< 9kF5P6Q
PE19Cf,<l<>=,5k<Bo415(9a;U9Cf,<>4$f,< SlPS 9,DZ7P< 5Z:< 9R5PaDH=E,F9CDZGW9a;tP}DZo,DZF7DeDZ=$P7Q[zE$f,<l7<lT7FFOE$5e=$P6B:
< 9}F5Pb6 QnPbQo,<>=,7Q,cR5ZFS 5KRX$f$4$419S 5eQ,9T<>=$P<<>=,5kS 5Z$f,5Q,DZ5ZSk< 9RE15/g9C:$5ZF5Z:P6B5hS F7c,=< Fong9C6B5
DZ9Cgk4,F7DP< 5Z:[6B5Zf,76B7Q,cePQh5ZmC<>6PiF9C9,4%Bz$j?l7Q,S < 5Pa:(9;
$[$PSz7Qq
7cCf$6B5?$K
MQk<>=$Pa<|DPaS 5
7S4$687{g7<7rb5|PFF7Qb;N9C6 gkPa< 79CQePE$9,f,<<>=,5?7Q,7< 7PF]S <>P<5UT7FF
E$5?c,6 P:f$PFFoeF9S <K

k%LzOz
UZU

(a1


P 5Z:q9CQh<>=,5PbQ$PFoCS 7S9a;<>=,5i4$6B5ZrC79Cf,SS 5ZDZ<79,Q[$TU=,7DH=ePb4$4,FoqE$9<>=q<j=,5=,9Cg9c5Q,5Z9Cf,SPQ,:RQ,9CQbp
=,9Cgl9bc5Q,5Z9Cf,SlDPS 5ZS[]T5lQ,:.7Q<>=,7SfiS5ZDZ< 79CQ<>=$P<7{Q9C6B:$56< 9%PE,S 9Ff,< 5ZFo.Pr97:nPFF:$7f,S79,Q
9;
DZ9CQb< 5ZmC<OPQ,:eD6B5Z:$7<U7Qb;N9C6 gkPa< 79CQWVNE$9b<>=Wj>bPbQ,:nBBBHN"ODZ9CQ<5ZmC<>`[C<j=,5?<>6 PbQ,S 7< 79CQ,S
S>=,9Cf,F:%E$5i:$5Z< 56 g7{Q,7S <7DRVN9C6O\?4$689CE$PE,7F7<Bo$`ZK
9C6%%S[,<>=,7SUf$Qb;N9C6B<>f$Q$P<5ZFoeDZ9,6 6B5ZS>419CQ,:$S< 9
POS o,S < 5g<>=$P<]DPQl9CQ,Fokgl9,:$5ZFDZo,DZF5ZS?VNPbQ,:fi7S<>=,56B5j;N9C6B5UQ,9<
rb56Bofif,S 5j;Lf,F$;N9C6
gl9bS <zP4$4,F7DP< 79CQ,S>`ZK
9<>=OF5P6 Q,7Q,c?PQ,:l6B54$6B5ZS 5Qb< 7Q,cODZ9CQ<5ZmC<
P6B5z=,f$6B<Eboi<>=,5zSjPgl5
56Bc9,:$7DZ7<o?4$=,5Q,9,gl5Q,9CQlE$5ZDPf,S5
<>=,5OS <>P<5U< 9lQ,5ZmC<tS <>P< 5t<>6 PQ,SB;N9C6 ghP< 79CQl7SF7Q,5P6Z[$7NK5K-[,;9,6BTP6B:(PQ,:eE$PDZGTP68:/4$6B9,4$PcCP< 79CQhP6B5
o$gkgl5Z<>687DPaFK
5:$7S Df,SSR<>=,5n4$6PDZ< 7DPFi7gk4$PDZ<}9;fi<>=,7Se56Bcb9C:$7DZ7<Bo4$6B9CE,F5g;N9C6h7Q,D6B5gl5Qb<>PF?F5P6Q,7{Q,c
PFc9C687<j=$glSfiV"S>f,DZ=ePSUPQ,:ecC6 P:$75Qb<UPS DZ5Qb<7QeF7G5ZF7=,9C9,:`ZK
NCbN bq$]$ne",Z-
s9RE$5Z< < 56if$Q,:$568S <>PQ,:%<>=,5(4$689CE,F5ge[7<?7Si7Q< 5685ZS < 7Q,cR< 9qF9C9,GPa<Pe4$P68< 7Df,F{Pb6O7{Q,S<>PQ,DZ5k9;<>=,5

PFc9,6B7<>=$g;N9C6q%%S[gl9C6B5eSj4$5ZDZ7DPFFoC[?P<qP};9,6 g9a;<>=,5%f$4$:P<56f,F5;9,6k<>6PQ,S 7< 79CQ
4$6B9CE$PbE,7F7< 75ZS[
J/

V `
JO

J/

TU=,56B57S?<j=,5kF7{Ga5ZF7=,9,9C: 9;|<j=,5k<>6 P7Q,7Q,cRS5Zf,5Q,DZ5ZSKqW5qgl7cC=<T9CQ,:$56O7;8[]S <>Pb6B< 7Q,cq;Y689Cg P
4$9bS 7< 7r5S < 9,DH=$PS< 7D|gkP<j6B7m[<>=,5F5P6 Q,7Q,c?PFc9C6B7<>=$g DZ9Cf,F:lF5P6 Q<>=,5z<9C4$9F9cbo[7K 5K[6854,F{PaDZ5|S9Cgl5
<>6 PbQ,S 7< 79CQl4$6B9CE$PE,7F7< 75ZSEbo?Z5689C5ZSK
X,<>Pb6B< 7Q,cO;Y689Cg J OT5DZ9Cf,F:k9CE,<jP7QfiPiQ,5ZT J t9CQ,Fo
7; Z $[$7NK5K[$9,QRPlF9,DPF ghPmC7glf$g 9; <j=,5?F7G5ZF7{=,9,9,:tK|s=,f,SO<>=,5?
<j6 P7Q,7Q,c/PFc9,6B7<>=$g
Z
T7FFzQ,9<?
fi ffN 9CE,<>P7QeZ5689/4$6B9,E$PE,7F7< 75ZSKis]6 PQ,S 7< 79CQ%4$6B9,E$PE,7F7< 75ZSlgl7cC=<i=,9T5Zr56ijfi ffZ
$Klf$6B<>=,56 gl9,6B5[9CQ,DZ5( J =$PS<>PG5Q%PeQ,5P6pLZ5689RrPaF{f,5[]7<?Tt7FF< 5Q,:W< 9R6B5ghP7Q%S>gkPFFNK(st=,7S
S>f,ccb5ZS < S?<j=$P<fi4$6B79C6lG,Q,9TF5Z:$c5V9C6i7Q,7< 7PFrPFf,5ZSfi9a;U<>=,5e4$P6 Pgl5Z<56BS>`Z[]6 P<>=,56<>=$PQ%F5P6 Q,7Q,c[


fifi

"!$#%'&$$$

(*),+.-,/1032$45-,(6470"8:9<;>=$+?(@(@9A2,/14fi8B@+C0$47B@4D@EF9HG,4IB*),4J9AEJ=$+,DKB*LfiG?BM47/14EN4GfiB6(O+P;QB*),4JB6+.=$+fi/1+fiR?Sfi8:LfiG,0T;+.D
47(@B*L?2,/91(*),9AG,RCB*),4M/1+.G,RPUVB@4D@EWDK47/ALXB69+,G,(Y2Z47B\[]474G^47/4EF4GfiB@(_+X;:B'),4`+.2,(@4Dbafi470C(@47c$-,4G,d747(e
f B`91(OLP/(6+g9AGfiB64DK47(@B@9AG,RgB6+hLX(*i^9AGj[>),91d7)jd7+,G,0$9B69+,G,(O[]45L?DK4NR.-$LfiD@LfiG?B@47470jB')$LXBMB*),4DK4J[k9/1/]G,+fiB
2$4gL?GfiST0$9<l:-,(@91+.Gnmo+X;>9AG?pq-,4G,d74r9HGsB'),4J;+.DK[tLfiDK0j=$)$LX(64fi8uLfiG,0sdDK470$91BJ9AGsB*),4v2$LPdwi?[tLfiDK0x=$)$LX(645+X;
B*D@LP9HG,9AG,R.y
e f B]DK47cz-,9ADK47(]B*)$LPBuLX/1/+X;"B*),4t4791Rfi4G?a{LP/H-,47(_)$La?4>L`G,+.D6E|B*)$LXBu91(_}fie~t),91(QdL?GJ2$4MLXd7),947a?470
[t91B*)J=Z4DK91+.0$91d`EJLPB*DK91d747(um+X;=Z4DK91+.0C.y
8X[>),91dw))$Lafi4tM4791Rfi4G?a{LX/A-,47(tB*)$LPBuLfiDK4]B*),4>NDK+,+fiB@(+X;u}]+.G
B*),4d7+.EJ=,/147h-$G,91B_d79HDbd7/4fieM~+5Lafi+fi910hL?GfiS/1+fi(@(_+X;u9AG?;+.D6EJLXB@91+.GrLX/1(@+vDb47cz-,9ADK47(_B*)$LXBtN>|2$4NB*),4
910$4GfiB69BKSfi8?(@9AG,d74>LfiG?SM0$9HLPRfi+.G$LX/2,/1+,dwi+X;q



[t91B*)(@9174>EN+,DK4uB*)$L?G5}[t91/1/q2$DK9AG,R`L_/1+fi(@(+X;9HG?;+.D@EILXB@91+.G

m2Z47dLfi-,(@4M+X;"4DKRfi+,0$91d791B\S+X;=$Db9HEF9B69a?4`EJLXB*DK91d747(*y
e~k),9(kdLfiG52Z4>R?4G,4D@LX/1917470gB@+JDK470-,d79A2,/14OEJLPB*DK91d747(
[>),+fi(64MdLfiG,+.G,91dLX/;+.D6E

91(_d7+.EJ=Z+fi(@470C+X;u=$4DK91+,0$91dF2,/1+,dwi?(_t:[k9B')C



ne

~k),4Cd7+.G,0$91B@91+.G[Q4TLfiDK4C0$47(@dDb9H2,9AG,RLXd7B'-$LX/1/Sd7+.D@DK47('=$+.G,0$(JB6+xLxEILXB*DK91s[t91B*)3+.G,/1Sn}fi(5LfiG,0
k
(e+.DB*),91(>BKS$=$4`+P;EJLPB*DK91q8ZB*),4M9AG,d790$4G,d74CEJLXB'DK91
+X; 9(_47c$-$LX/"B@+JB'),4OEJLXB'DK91 k 91B@(@47/<;be


~t),4DK4';+.DK4fi8Z[>),4G
91(_,470"8B*),4jLfiD@iX+XaJd7)$LX9AGC91(`LX/1(@+5),+,EN+fiRfi4G,47+.-,(e f B>Lfi=$=Z4LfiDK(_B*)$LXB>EILfiGfiS
9AGfiB64DK47(@B@9AG,RMd7+.EJ=$-,B'LXB@91+.G,(dLfiG$G,+fiB2$4tLXd7),9147afi470N[t91B*)(*-,d7)`d7+,G,(@B*D@LX9AG?B@(tmo9e4fieA8+.G,/1SFLP//1+X[t9AG,RM+.G,4+.D
EN+.Db4Qd7S,d7/147(u+X;B*),4t(*L?EN4t=$4DK91+,0vLfiG,0JL=$-$DK47/1SO0$47B64D@EN9AG,91(@B@91dYL?G,05),+.EN+fiR?4G,47+.-,(jLfiD@iX+XaMd7)$LX9AG$y7e
q-$DbB*),4D@EN+.Db4fi8fi9<;:B*),4>=$L?D@LfiEN47B@4Db(u+X;"B*),4t(6S.(@B64EL?DK4tB*),4tB'D@LfiG,(@91B@91+.G=$DK+.2$Lfi2,91/191B@9147(>B'),4EN(@47/1afi47(`mLX(
9AGM+.Db0$9HG$L?DKS`tTT(*y78
(*-,dw)_(6+fi/A-,B@91+.G,(:d7+,D@DK47(*=Z+.G,0`B@+_L](*-$2,(@47B"+P;zB*),4d7+.D@G,4DK(+X;zB'),4

U*}u)?Sz=Z4DKd-$2$4

9AG5=$L?D@LfiEN47B@4D(*=$LXd74fie_[tLS`;VDK+.EB*),+fi(@4k(@+fi/A-,B@91+.G,(8,/14LfiD@G,9AG,RJ91(tEN+fi(@B6/SI9HG?pq-,4G,d7470T2fiS'.fi'u*
0$4=$4G,0$4G,d79147(8$2Z47dLfi-,(@4u+P;z0$9<l:-,(@91+.GM+P;zdDK470$91Be-$DKB*),4D@EN+,DK4fi8LX("(6474GM9AGM47c$-$LXB@91+.GJm?y78LX/1Rfi+.Db9B')$EN(
/19AiX45[t91//B64G,0hB6+5(@B'LSgG,4L?D>Ld7+.D6G,4Dt+.G,d74N91BM91(`Lfi=$=$DK+.LPdw),470"eM~t),91(`('-,RfiRfi47(@B@(_B*)$LXBNfiwK
'qoNA7fiofiTLX/1Rfi+.DK91B*)$EN(8D6LXB*),4DMd7+,GfiB@9AG,-,+.-,(`/1+,dLX/tLX/1Rfi+.DK91B*)$EF(8:EJLSj2$4CEN+.Db4FL?=$=$DK+.=$DK9ALXB@4B@+
47$=,/+,DK4`B*),45m/47R,LX/Aytd7+.D6G,4DK(t+X;:B'),9(M)?Sz=Z4DKd-$2$4fie
zL?EJ=,/147(O+P;B6+gB*),91(JLfi=$=$DK+.LPdw)jL?DK4N;+.-$G,0x9AGB*),4CLfiDK4LC+P;R,D@LfiEJEJL?D_9HG?;4DK4G,d74;+.D`G$LPB*-$D@LX/
/ALfiG,R.-$LXR?4OEN+,0$47/19HG,Rjmo4fieReA8,a{LfiDK9ALfi2,/14JEN4EN+,DKS5/14G,RfiB')CjLfiD@iX+XaJEN+,0$47/1(8q+.GC47B>LP/e8"}fiX8.+,D]d7+.G?U
(@B*D6-,d7B@91afi4gLX/1Rfi+.DK91B*)$EF(N;+,DN/14LfiD@G,9AG,Rxd7+,GfiB@47,BKU;VDK474CR.D@L?EJEJLfiDK(8u"LfiDK9_+.-$G,R8_}fi 8,B@+fi/1dwiP4h
EN+.),-$G,0DK+8}fi?fiy7et~t),4J=$DK+.2,/14E+X;0$9<l:-,(@91+.GT(@B*-,0$91470j),4DK4JLfi=$=,/19147(`+.G,/1SrB@+5LX/1Rfi+.Db9B')$EN(MB*)$LXB
-,(@4JR,D@LX0$914GfiB9AG?;+.D6EJLXB@91+.Gm(*-,dw)TLX(MB'),45]Lfi-$EUVj47/1d7)xLfiG,0R.D@LX0$914G?BKU\2$LX(@470xLP/R?+.DK91B*)$EN(*yML?G,0xL
R.D@LP0-$LX/tEN+.0$9<dLXB69+,Gs+X;>B*D@L?G,(@91B@91+.G3=$DK+.2$Lfi2,91/191B@9147(e

f BJ[]+.-,/102$4C9AGfiB64DK47(@B@9AG,RjB@+T47aXLX/A-$LXB@4g),+X[

(*-,d7)jd7+,G,(@B*D@-,d7B@91afi4CLfiG,0j0$91(@dDb47B@4C(@4LfiDKd7)jLX/1Rfi+,DK91B*)$EN(J=$4D;+.D@E[>),4Gs=$DK+.=$4Db/Ss(@+fi/1a,9AG,RhB'),45B*LP(*i
DK47c$-,9ADK47(MB@+J/14LfiD@GrB@+CDK4=$DK47(64GfiB_/1+.G,RXUVB@4D@Ed7+.G?B@47,Be GrB*),4O2$LX(69(_+X;uB*),4NDK47(*-,/1B@(M+X;B*),91(`=$Lfi=Z4D78
),+X[]47afi4D78[Q4J2Z47/9147afi4IB*)$LXBM9AGr+.DK0$4D_B@+(*-,d7d747(@(K;V-,/1/1Sj/14LfiD@Gr/1+.G,RXUVB@4D@E0$4=Z4G,0$4G,d79147(8(*-,d7)TLX/1Rfi+XU
DK91B*)$EN((*),+.-,/10J/1+,+.ik;+.D"a?4DKSM(*=$LfiDK(64uB@+.=Z+fi/1+fiRfi9147(tmo+.Dafi4DKSM0$47B@4D@EF9HG,91(@B69d_EN+.0$47/1(*y
ek+fiB@4B*)$LXB"(6+.EN4
+X;tB*),4CLX/ADK4LX0$Sx=$Db+.=$+fi(6470Lfi=$=$Db+.LXd7),47(^m]+.GT47BJLX/eA8]}fiP.yMLfiDK4/19HEF9B647039HGsB'),4JBKSz=Z45+X;_d7+.GfiB647.B
B*)$LXBdL?G52Z4>DK4=$DK47(@4G?B@470jmo4fieRe8fiG,+`/1+.+,=,(Q9AGIB*),4tR.D6Lfi=$)JLfiG,0JB'),4td7+.G,(@B*D6LX9AGfiBB*)$LXBuLX/1/9AG?B@4D@EN470$9ALXB64
+.2,(@4Dba{LXB@91+.G,(`2Z47BK[Q474GrB@9AEN47(MOLfiG,0T>EN-,(@BM2$4JDK4=$Db47(@4GfiB64702?SgB'),4`(@B*LPB@4`aXLfiDK9ALfi2,/14J9AGr+.DK0$4D_B@+
EN+,0$47/"B*),4M9AG?pq-,4G,d74J+X;

:o

+.G y7e

CHtAOzA

j4])$La?4QLX/ADK4LX0$S_;+.-$G,0JLfi2Z+{a?4uB*)$LXB47.d74=,B9AGMB'),4Q('=$47d79ALX/$dLX(@4+X;

+.D}B*D@LfiG,(@91B@91+.G=$DK+.2$Lfi2,91/191B@9147(8

B*),4t(6B*LXB@4]a{L?DK9ALfi2,/14`2$47d7+.EN47(]EN+.DK4_LfiG,05EN+.Db4t9AG,0$4=$4G,0$4G?Bt+X;:DK4EN+fiB64>=$LX(@B(@B'LXB@47(>mLfiG,0IB*),4DK4';+.DK4
+X;YDb4EN+fiB@45=$LP(@BN9HG$=$-,B6(5LfiG,03+.-,B*=$-,B6(*y7eT,9HG,d74rB*),91(5=$DK47afi4G?B@(JDK+.2$-,(6B@/1SxDK4=$DK47(@4G?B@9AG,Rj/1+.G,RXUVB64D@E
d7+.G?B@47,B8$/14LfiD@G,9AG,RC(*-,d7)TLN/1+.G,RXUVB@4D@Ed7+.G?B@47,Bt91(`LX/1(@+vEILX0$4OEN+,DK4`LfiG,0hEF+.DK4`0$9<5d-,/1B_;+.Dk/+,G,Rfi4D
B@4D@E0$4=$4G,0$4G,d79147(e



fi]AXX@o$TAT5$$,$$3vZfiX

kX]7fi7"1J1NAfi6K7@@A,j@r7.,@1$J,X*,Kfi,$71st*,5'fi,@1@1.$K
ff, fi1

X'K j$AK77fi 776`*,*,.KfiK
X??KT
X6,, ff!"o6#$K$
P$X@J7,fi@,NA%


. X6,&.b?K'?,(
X)?fiK*!+,@7rHfi1,fi@,A,(fi1fi.K1* t-,7.X0/213fi,o fi1174fi5
!
.P
$?]$7@7?,687V
fiK6, fi9fi

fi17,k7.,@1$]*,;:M$$,*,AIKfi,$177.=<7?t*,7@
X'K '$K,*,7@,6?>Hb@
fi170@BADCFEGAIHJA
KLK,KEMNH+M$*,



OLP @*AI!+Q

OLP IEGAI! OLP RH+AS!TK,KLK OLP EMD! OLP RH+MN!8C

U
V,W



OLP RH V ! OLP IE V !

IXff!

Yjg
fi(fiAK,P
3@73*
P

P EAI!(Z\[($ fi17@*,r*fi,@1@1.$b$
ff, fi167]fiK(fi fi0^..[ff6
L
_] Zt*
Pt*,` 6@1.]$K$
ff, fi11 X*K .H
1_$`Pfi.
fiI6+ab
fi5,A,C*,`$=cq,1@1.r
V










X

@

1

.



$


!
@

e

N

$

9

X

fi

.






fi

X
*

K



.

f
g
,

]



$


,


P
H


P

OLP If!2C

[




g
f
hRi jFk,l

h hNm

f

hnj

loFl

f

hnjJm

f

jpj

[
C

lq






f
hRi jrkl

h h

losl

f

jpj

lq

t1*&t+
uC v w

xt,K=.Kfi
P RH !2C

[





hyi j k-z

R{

l}|

CFt~4 !

>,17g1_*,fi4XfiMu*,KQfi9fiK?7@>

R{

oz

l|

Cv ~ !
q

t1*&t+
uC v ~

6@1.]$K$
ff, fi11@17X_*,1>6

`@@,N6xk,K=,Kfi

>,*,u*4fi,@1@1.$b$
ff, fi1678?KQ,fifi fi$^t,2[fiH*,u,P@$$6K7@]$,-
,@ P RH !GQF[fi
fi,s*,Kfi,$71 s7.=
<571?J
t*, X*b5 $K.*
,7e
@BAtAs


X@1.

IXff!M7,fifibfi7`@^X



A,K,P@7,68kfi@_*
X]*,1$K,*,7tfi1fi7]*,M.P$?] hRi Mhk'5K7=$77t@e ji AVK
J%
70gfiS6 [,%Xff^
*7,A,@.r70fiI6A[,ff%ff!+X



X@1.[L!fi,g1,@7rAg',/213fi1fi,K1*
]fi fi8X>Ar.P$?
X67gfi?.K1*
[,ff%

u,?.
>q4
X@7.,D
[,%ffff
!6

>.

"I]K1
fi1fi8[Lffff^
*,fi1N:M1T.KB>2fi9 e



Lff

Zfi

fi1fiAC',M,X@M8fi1,fi@,A,K1@K1.(k


>,K

9$D_

CF@BA




w,wLw#
6,A,7@ 1.,@73@$K$
P$X@K7$1'
P)?fiK$
L
Lff
,_*
Xfi1.,gV@
K
7$1M_.P*
fi fi5fi1fi@0X_1>1$K
X$X@7
,fi

1*,Cfi77@.;

1@_7.fi?Kfi,7`6v?
([


Xfifib$,"*,k.X$1?u*,fi1,fi@,A,NK1@K1.It1*JK7=$77u6fi fi*,0
P@@-X678$77 7
fi$I6 ffA6
7.?fiK?7t@e 1fi @9 fi N9[ff~L[ff~,wLww~,[ 6

L
x ,C7.fi6H ,
k
$,
1@@1.,C,X
6g1 .KC$n5
< , 1fi ($
7,ff,
6h',g$,@1
R{
AeCt4~2AI!
z
l|
,fi
]1fi ,,fi fi ZJ.K,X
6_*
fi
T.,ff6t
x ,"ffZ
Xfi5K7- 1fi ,fi
T@@ fi fiJZ
5 ,
-X
A,7jn>
]JK7@*K17$$


*,M-

X@6fi@1.@M',Q,P@7uAN>,17N*,0$b.*,7*,fi9fiK?7@ 1@@1.$K$
ff, fi11@17X,X7N@
fi JAe$
4X
7@17ff68V7 *,],X6t>,K]11Q,fi2$$$,$7",]
fi@fi 9X

@@,1JZ$$,$7"fi_,7N1u',
7.LK77-$KM*
Pt*,M-

YK7= fi_,fi.Z`$,-PH,7(%7.,@1$KA,C@,fi17g

6@1.($K
ff, fi1

X'K177,t1*"@,gfiA,pX7@,8A*
X1[t>,',> 1@6,.$K$
ff, fi111fi17@]*
fi[fi
fi,
CFt~4
R{
! fi*,Kk6ff6'
7@@A, CE H KLK,KE H 2fi1*,$,,T*,
h
z
l}|
Xfifi
fi .P
$?]t1*CK7-Z
77t@efi "
fi *,
P
@]@-X
@7],fi
I.KX fi&fi`?Kfi"IX+ A,K,X@7=!7


*
XM1.[,

*,Jfi
^A]@65fi fi7.fi?Kfi7_@[fiNfi,j*,Nfi77@,+
fifi9fiKfi,!



fi1@9 fi1N9[ff~,[%~,www~L[


6
,ff

C




fi1@C7.?fiKfi7M6'IZfi@@9 fi

fi2ff*ByD
*=




weak
influence
strong
influence
e

remote
past
event

near
past
event



et
current
event


time

2 $

; ,+
$ , -= $p,4
,
,
, .
` - e $ gp,
,
,
,%
,

(
g +-9(G]]0 -' , LG+ff,
-49 ` .G5 8$$
ff ]$$
,5,g5 5 np$
945 ;$ $
,b $ ff,G,
,,
, ,+$ 45
,
925
+%,ff0R$,
49 'G9b% ((R ,
9 'gJ4`. ),% 5,
-
ffDff -

ffe= ,effe 9%,9 ff.%,ffb ,
9 `
+,SS}ff9Nff,%
0 - $ "9% , - 04-ff9ff 9029$
,84
4,8
N$ -
9
8 29,0 +$
,+- bff,g5B9% , 4-++9+

$= 0 9 9 $
- $ -
b9-(,ff 4"- .
, $,
$,
,2ff
,ff 4
$g
5,%+ffb

"4ffff- ,= 09% , b9%,ff, 9 ff,%S-
9 .- ffG$,
`
- $ "
=I$b8G5 )&- ff,2-
%e- b9% ,

- ,$ff$= 5
5,
ff
fiff G+$+.9 ,,g,

!!"$#&%('*)+"-,fi#&./0'1%2"4365879#:.<;=#2>?34;-@BA'-5DC$'

+ ,ff ]e
ff4545%"e-ER$4-

` .4"p ffp$
4$ff

G
`545%ffG$ ;9
$
,G ,ff $ p,


,,
, ,2++$ ] `g4'
Lffeeff%GF,ff;9- ee-HE.

-% $"
$
ff 545"S0 ).* G-
$ ,
$N*+$%4(ff&- 0IE

,
9,%e
,9

9KJ $KL]ff 5 9 -4

92 $
ML%*N;%I$-

45ff?- eff, ,

-

ffPO= RQ:ST UPVIW8ffff


9;$
$ $ff
N8"
4 ,Dff
, $
G#],S$IE
ffe e-)ff$ $INffYXfiZ [ Z]\1^Gff 9 ,XfiZ [ Z%8
ff9$ *ff
-4 -
(
`
ff ``_

+
IaXfiZbZ Lff8
5 e$
ff ' ,L 5


- "
$ $ff
Ndc0 ` 4-

949

925
BeB9-)ff$ $$4,-

,ff 9 89
5 *
+-4b5 =
5$E$L
$2IE$, b - 9
$ ,e
,e
,
4,ff-g $ $ p4,$%IE J = ,=S % ,ff (%"- G]ff 4545 .
$%
ff 0
+,$
8D-g8,
,%9
$ ,;9eb,=9$%IE$+ff ,ff

p$

IE 0 ;`%
-
]*=
G+ff,B`-
;,&- ]-
5 ff.


ffbgfV V fiSffg.
I0 ,ff4 ` $ b9$
%9 .p ,
, e8%,ff;- ]

hfiifih

fijPkl&l&m$nokp-q?kq?rBs-t-u$pWv-k<s-qKrwp]x$y z&n

|

fixed priori
sentences

noun
verb
cat
{

{

words

dog



g



phonemes

subphonemic
Learning
meaning states
level
}~H-$R4fi oW~WG&fi-Iofib&o~Hd&I IR~M-III*II W~Ho~H???~H1W~Hfi&HH
H~~IGoa-0- --fiW~W~G9-WWfi
~HWfiHI I!fi-Ifi 0o~HW IW&
ofi-~HWW&HI- bWMW - ob
Iofi 9&ofiIoo~&IGo~WH
I&WIfi-ofiWIa&o~Hoo~HIfi

-WWfi
I9W-fiW
4WIHfi&Hfi W~W?Bfi-Iofib&o~Hg&PI IR~HWfi
~H-IMbGWW o~W~HRWa-&o~HR&-~HRWW:I-b


W Wfi-~IIo~H&IofibWWH]B~fiWaG~WIWo-&oo
B-~WaWW:I-b

~HHfi oW~W?I- WHIfi-fi WH~KG*-&o~WH~$IBWG-WHfi0Hfi W~W
WIRHW0ofio-fi]fiW-fiWI~HIfi*-fi-ofibIfi IM~W~Ha-~IIo~H~H-&oIW
H


~-fi&Wo~W
WHo~ofi0afi-Iofib&o~H4Wo&o& ~ WHa~HP-II] oIG~ fio&

-b&oI: ~bWI

W oIo~ g-W$WI~9I1-0oW

WHgo&a:b~ WHfiI!fi&I

]fio&o~WG&2-~!fifi Ro~

ofi&H RW-~W~0o-Wo~Hd~H-&RWW&ofioIboI~H
-afi-IofiboIM

oH&ao&oR: ~ WHIfi]W~HG
Wo-~WofiW~~bao
W-II~Hoo~
~W&

fibofiW~H0H&W--&0o~H9&!I

bWfiI-~ YHfi oW~W& fiYHWa$-o0o~HW

-WW?W W~HWfiIbIo&& ~ WHIfiMDG~-boBWIow
WHo~WHB~Bofi0IWWfi
~ $WI9IWo&~ oWobWo~Ho~HM-W- W~H~Ho~HIfi4Wd-&PW
- 0$-- W~HH~
&$I- W ~Wa& bo~
Poofi4



oH:& ~ WHIa&H

WbWfiWW$&-Wo~H9~H-&YW

obWo~Ho~H--bW~H~Ho~HIfi 2-P&IoI~
ofio
06WIW-~Ho~H-&T-bo&-- W~HH~Ho~HI&
fi&IGo~
9ofi&H ~H figWWHo&o aIII-9-&Wb1] WIo~Ha-fiW~WW~
WHo~
ofi&HgooWI-G~G --W-~&o


-&-&H*I1WfiWI?Hfi oW~W&b

W- W]fiWoI

fifi

WIK&W

fi $T!-$---

9T -D

ff
fi fffi fi
ff

fi

! "
# %$
& '

()
ff +
*
, -


&fi ff
$
! .fi
ff
&
fi/
0
21
fifi
ff fifi 3
WH
oIIoHP
-bbM



WI

WI

Ha

Ib

]

&W








]
fib

fiWI?

B





H



Ho



WIM
ooW

GRWIGW

YPB

&oH



& HII



]

?

Wfi8P

- -fi

H

-

-fiWIHI9





$I

H

46587:9<;>=?A@B; CDFEHGI?KJMLN ;POQ'RTSA;JU?ARVQW;VC3D3@
>

ff YX8
2[Z\ ^] `_ 3 '
&
Ba
ff
# %$ 3#
&fi !
H&
ff
b
fi3 c
)e Hfi



<fBa ff

#a $ 0g,
_
-.
h ^]
ff

ffi

$
# /jkZl mnfiofi
3p/qZl
Hfi r sa $ u fivX w
)
ff yxz
ff
$fi>
#Zp{Z|l fi r %a $ }. fi ra ff
ff_ u
# u
fiofi ~X 8 V xz }
.
$
fi ZpeZ zm

<e' fffi
) $
#16
# %$

% %$ % r
}



$

fi $*

3
&
ff
ff

$
#
B
Hfi
%$ %$ % r
fi

dfi
$ fi $ ra

- $ ! H r
fifio
# %$
nfifi
,&
ff
H b
fi % fio)e
% b
fi/ `
ff

.
. fi %
&
r z X:krqff{eZ

-i
Hfi)
) ^ ff . /

WH

HIIPI


- fi







&oaW

-

W






W -

fiWI





fiWI9o&

]

H



-

-





HH





-HH

W



PI

WWP &oP

Iofib



W

&PIW ofi



&



-H



&boWWa



H&P







&

0 HII

WoHoH

&



-



W

-adW

-

oW&KWP

H

oW

G

H

0


6W

-

0 HII

WW

-Ho





MI-WIIo

-W



H

b

- ]fi

fiWI9

&



0ooH

&oHW - 02H

-W9WI -fiWI

&o9W

?W9I

-

WIo 4ooW

ao

&o9

] H

-Y



-

HoW&

-IH MIW BIHfib $RWIGW






- ! fibIW

b

-HI gI BIHfib

]IIo

-P



W & b W

- H



b

&

WRH

ao
W Wo&

& HII

- ! fib

H

b

0

-P

WW




&

KH

W9



-fiWIHI

&K

&

H

WP WI WoHH

-W

-fi

W

H



0
H

gI-WIIo





W&

HRo

-




0





W H

WoH

465|NBQ';8D3;D6mKLN;JMLD'W@
*
fi

2]
&
ff
$'
r fifi
3
ff
$ b
}$
-.#
&fi $ mgIg
fi $

3 < $ H
* .
<$
fi
b
< <16 -
fi
H. fi8*

Hfi $

r fifi (.#
fi2 ff

- .
. fi ff
}q

I3&&X8 q' 8/ qZ&X ' 8/ Z
)
fi2anfi ^ dfi $AXs^Z\fi #$XtZ
8 \ r
y^#Z fifi $I $
fiwIX%keZ'
ff

d$
0
ff

fi $ i+
X k -k#Z

> B
$
ff
/q< 2] ffi
$ ff
fi <
ff

fi> k# r
$ b *
$

&
H
I&
#a
H H. (X8'q# Z
B <fi >_ fi
& o$ ^1
fi w
X8X%ZK,XkZZ'XtZBkB X%Z
&fi $
fi >_ fi ffi
$
`
&r ff
fi
ff sfiX s$ 'Z
` fi
mfi _ fi -
fi

$ .
dfi >_ fi d$
$<gIg
r
d'
ff

w mgg fifi
X &1
fi|
. i. $ ff
Zd

ms
$ H. ff
ff
fi M#oH H'Bff#'B U
,$ fi X%k :k 'Z

$ H. ff
|

Hfi $)
r

&
ff fi>
# %$ *
#16 &
r /}
fi $ $U r


ff fi
ff
#%&
BI fffi
$
fi


&fi H
3
&
B .


ff
.fi fi
#fio s$ .fi B&* &
Hfi
gIg
,{
B'/^n^ff^r^8|i'ni d8tr %%i%n%"^n %`\[ &' ff n8
ff Kd^0 ff^Tnr`\8d/ nni%diuB^Bff8B


&oW&

WHdW


- -fi

-

WoH

0W



-fiWIHI



WIWI

Wofi R W



&W

WfiWIIRP

- WHIo g

fiW

H

&

bfiW



&o?o


9oI YI

&o




H
W

]
fi P






WfiWIIG WI W

Ibo WHI

H



GW9o

2W







H







-





- -fi

R &I HI


W



H:

-fiWIHI


H

fi

H*I

- fi



&W

] -WIW

&

&Y -WI

b

G

`

]Ioo P

W

bM









W

fiWI

WIIIo
WH

bW

]

WHGI


HB

?W

WfiWII

H 0 WW

H

H

fiW

]

W

W HoHI9 &I

H GH

0o

H
W

H

IW

W
W

H





H

fiW





W



W


g





-

Wo

Wo


WK WW

fiW





fiWI



H




W

-

W

W



Wo



W

HI



-

HaP






` W




-







&W

& HWW

go &


bo

&



WoH

IP2W

HW

&WoMWI

W

Wa

=



G WW $ b

H 0 WW

YWfi9H

&o

RW

&W

- KIHW

- W






&






bIW

- ! fiba



H 0 WW

H

6 &oI

Ha?P

WoH?oGo




&G





&



0W

9W

IW-WIIo

] ao &I P

W &o



&

-HIWo - WIIIo

H



Ro

RW

oI

W



bWoHoH

g



fiWI

-







H G



&

WoHoH

WfiWI

-

& W

Go &oI

?I-WIIo

Wo9W

g

W

bo HI

MW

?a

]



fi| 'I I'VU'
#fiff ff$

5
0
-5

fi ! "

-10
-15



(

%'&

-20

ff

fi fi

-25

fiffff



-30
-35
-40

0

5

10

15


20

25

30

)+*-,".$/021$35476"89:0;/,:0;8<=0>6 ? @A6"B$/C.DE*F8GHDI<=6"0JK<=*L0;8MONPDQ0=0R@A0S8*-MC*-6"8UT:VW*X8UY$/6Z.<=M76 ? DCMC6<=E$[ DCMC*-<
\ [ M]/^*L<=0=D5[ DCDC6<=*X[ MC0=Z_MQ6`86"8a!E6 \ 6,:0;80=6".D5bc[/Cd 6 9e<=E$[ *X8DA<=6"8DCM]/C[f*F80=ZgB:hUZ$*jik0;/0;8M
M]/C[:8DQ*LMQ*L68l,"/C[Y$ED;monIE0Up[fMCMC0;8*X8,l6 ?AM]E0qB$6:MCMQ6 \ <;.$/9:0r*-DUZ.0_MC6sM]E0_t-* \ *-MCDU6 ?
8". \ 0;/*-<;[ Y$/0=<=*-DC*-6"8r*X8UM]E0A<=6 \ Y$.MC0;/70=u$Y$0;/* \ 0;8MCD;m

t=1

t=2

t=3

t=4

)+*-,".$/02T$35v+9:6tF.MQ*L68A6 ? \ [ M]/^*Lu2Y$/^6"Z.<=MCD+wyxzC{ |P}?~6"/k[ \ 6"Z$0=t$E$[9"*X8,A[7?.t-t-h2<=6"8$80=<=MC0=ZM]/Q[:8DC*-MC*-6"8
,"/C[:Y$Embq[ M]/^*LuK0=t-0 \ 0;8MCDNM]/C[:8DC*-MC*-6"8UY$/^6"B$[:B*-t-*LMQ*L0=DVA[:/0A9*LD.$[ t-*L=0=ZgI*-M]E,"/C[het-0=9:0=t-D;m
;;

fi+:k$$$$

0

1

2

3

1

2

3

0

0
4

2

5

4

5

6

7

+-"$2$5A;;CfCX`Igl$R$;RXrC]fCR=X=-=A$;:Q2C]fCRX$-==;"$$;^I"I
C] Q=X=-=$;:Q]$+C$O:-;+I->gI C=C5:;;C C7]7]Q XF
]y~"7]A=$$;X;C5]$ee-==_XU+-"$2
100

Correct topology given
Randomly connected,
24 states

% Converged

80
Fully connected,
40 states

60

40

Fully connected,
16 states

20

0
0.1

1

Fully connected,
24 states

10
Span

100

1000

+-"$2$5;=;] :efR=":;:;=KCr:CFQLoP :;2:]X -]y~"ff:-"C;^L=
=$$;^F;:Ce Ae]$:gf$;$;$;=-e-OX;;fC=:rF;^; CXg]eC=jP
]C:QLQL2$"$L--C-=fC C= 5:O= IW] ]>="C-CQ+F$=LXC=;==
:;;C Q=_:K]2>$;-=C=gXU+-"$2
;;

fi7X CP$gXg`$$$$l:

CX=e"^eC] Q=2]$:]K:;;C QFq>g:Q:$"=$==C-"e7;K;; C=sI-]
:: "$:---!:>+-"$O] II] ;C :A"$;I +=" :;:=r]X -
" ]=C2$ k;;
=I >gC L:-=;
UfL ; C=I]2$$;7
]===Cff ]X -RC -$-U >C
fi=;
$="eC"
XI :
-L=K]X - $ ff -;7 C C=
A:
5 ]7:;;Q CX
> :K]$ --=" C= ~': ]=CeCFQLO$ 'A] ]`$=F$Xq
eC $;=
X:Q ==$:eQ =C;K]_$-C]^F$QL
]rC$O:-;e]r; A]rC ;=:
~U-UXC;=CCX CC_]$f_Igg`>L :: "gC] Q=`]$ ===C] $U C
="$==C -! ; ~"C= =l$=CC; !
W -; -- Rr :^C;"C s="C= "$eCqgX:^:;
=# "`=-;: ;:$-=L%
$~ 5 &"; - '=sFc+L$
()R- g -- IA-" *C;C $ ;$;=-=
C`2 =C;C=g:U-;:C=q"5; C--:
+ :];>X:Q;=CCXK"C;ff C-"r-R]$fIX ::U;fC= ]2]Q XFK;$ff ::=R]$^""
"A"7,
:;
-f X Q;:;
.$= X C;I="-A & X X=q:K]A$ C-" ^"-;0
/
]_=X Q1 _"Cf$L;eI-] = ==`CgC :C:=C;-2
:;^] -3
$P]e]_ -:-]$
$ ;:5C`$C4 5)=6
I=C X Q;:A;:_=="
:;^`C;^L "-;5;_=F>C-
$ =5"$;^L;f ==-C-"r"7]=X>-;:]U$=== $$f== ]:-:
78:92;<>=@?BA>CED;<GF< HGIAKJ
A>LMONP;LQ

-"A7"R "_^=;$C; =7"R 3
$TSW;:-U=A ~ UVV
WX)77O$
$$ 5~">]=C
"-X;:5$$$:-; :Q:=C;fi==rC"QC; f" CXe;=$-5:;W]A-"`Q;C 7X*
=" fCXL5I-] CC"^FAX~"CefC-" ~"]>LOQ;CUS7 QL;fL-$>Le;"e"*-X;:-
$PX:;e7=-"CZ )CCC"r-"
*C;C ="C &`"$CQL >"C $-;CU$ 4
* f" C=l]$^""


CX
ff:-]rC -$-:[
UL ; $72$\ :2 -C]
"$_= C :O^=]-CR==;CX`] *
=C;] QL`: L;CXe -" *Q;C ="C & $$]=K $ -`Cq:R Fe$=L7]=K
>g ^AIggA",
_>^5a
`b_ ;">]=C`"$=-
~"$q]$f :]g]e ^=C;: C-"
:qe-;:CXg -" *Q;C="C &AX "Qe C-"qC-=C:=];=
g:;;C ]=q:
$]e$:]7;:$-=Le
]I]CC-C-" "$L--ee ] &0$P"]$$ef]-== -Z )= > 6
*
:; 5;2C:C-C-" ^"$:--LQL=I:^=-:CIQ3
UI: X ~"CefC-";:$7CC"^=b
~" ]
-"eC;QP
cdfeA;=$-I;U$ ^ " Q=` :;W]A-"eQ;CU
g A"$>
'$X:
~"7=;$C;
=7"R ]-]:=CC+]$f+] "-; -;:CX-" *C;Q $ ;$;=-=5-"X "7-h f
eikj4l\mon\pTn2 CX fi; C-" "-;Uq

~e $ ;:$ "`;-
~"A-; 7L;CX -:"-]$ ]=s
r ">"C $-;A$=C=;2CK-;:Cg QF C:C-C-" "$L--C-=`;:
U" ~':k C`-;:Q
]UC :-:: 75L-r] FsX:Q =="$e-" *C;Q$ ;$;=-;s
I-K]"- ;="$Q :
=C; "U -C;C$fC :t$P$-C;^=C )RfL"-]$
7$-C= :;X_IgC :-::u
$P= ==FfL-q
~"
=Q;:CXrL *C;C =":Q &"Z )v] A]:C :C=s:q
.C:-4 f2
wx^A"$%
$ffUVV)
:u
y7"r=2 ~2
$zUVVWX) {
^A$A=]-CA::=C5]$ 5]=fL"-]$A]LC] :CK$-C= :;
:^CIC :-::-= "W X:CW$=C;CX-CC-2$=-;
IR"$;C ^=C;:Q=;5:I=CQ; *
CX --:r $ --; C-"r =C]L-]=qef];e C-; =]-CA"Kq:R fE K=$ XRC ] L;
7L;CX_-"UC;C $ ;$;=-=eXq":;=" " *!":;="2>g;
I=C
:$;:Q+;^R -C2 $ "Q= & ;X;:QI"e:^C '=Ff ]| :C]$X] ;";
+$ QLU +;=$- U]A="C= "$XK$} "K;LrF]C XX`>g>CL;CU-" *Q;C
$ ;$;=-=;
^AIgg
$TSW;:-~
w Q C="T UVVWfUVV(:@ )>:u
_ ^5q
`b_+3
$."$ fUV@UV:@ fI$^Lz *
e: 6UVV )A:K" *!":;="
ff:X:C R>g ~': ] ]C:C-C-" "$L--C-=U:
$=C-"r
]X
$k~"[
^AIggZ )5">]Of=C-"%
$k{
_>^5a
`b_ Z )I 5; =rCX
],
Ie# *




fif@f#@@@

Z5R[
Z5{@@Z5R#@[Z505Xo5X 5X5[uR
E5: X@X5a|3@R
Z5R!0X ,RZ@155Z[2ff@ffRR5~51R550155BRR5R5>fXZ5~ 55
|Xzh5:ZR5RRXq@ffX@5RbR2|35]X,RR[Z5bR5RRRtX@X
ffRR5~@55X @05a@oXP5R#B5X@5#RX5Bq@RRZ5b 5Z@Z5
@5@ff5h5 @@@ RZR5RX R,@[ 5@2Z5551|[@RR 5RRX]51
0@R 5RR~B,qzX52Zff5,BffX0@R 51R0XR]Z5~R
X@ X5BRR@@5@5T>5RX5T[@qX [qqbZ555RZR
ffR#ffR[Z5b 5@R]R535{54ff,5[ff:ffRR5f
,@@5R535@ ff5|ff RZ5RZ@5R5, Xff 5@@ ZR
Z@5RZzf[Z Z@zRbX@515fffff5,#5b@5RXq@ffX506,5Z5ffR
RZ5:R~@:RRXR1 {5#5,R@55 [R@ @t@z15b55E1@2\ffRXR
fkRX5T@,Xz5uh5Tf55f@:@,@5R~b5X,X5:RX@15X
X 55bZ|fEo@ffXff55[@b[Z:5h5:BffX@5
635b#5@XR6@ffRR5ff6ff[R,5Xzh5 5Z5@@ffX,R,5h5
X5BRx@|5@51Z@[55RRRhq@5@5a5Rz45 ff@zR#RX:Z5bZR
5 u|~45%aZff5f55uRR
Z@BRZ2ff5 {5R2ffRRO@ff5f5
XRzZ@X5@>R,Z5[XRGRZ
R>4Z5[Z@BRZ
R6Eff5[b5@R{ ,@ff
R :RZ553
1[5uff@a@ffX@
XR ,X5qR]@XR
Z@5TX,X Z5R
Eff5
q |~B

Z5@b>5 [Rb[Z]Z5{
f5RRXR @@ffZ >5,T[h@
u 551qR:Z@@0 X RRXtX53~5R#B5XR,5Z5R155
50Z5 @>6,@65aBB~@@:B@5@5t
5[TX6Z@@|Xff
q5Zff @
65T@25X5@ qff, zv{u5 @a 5Z@
TXR15~R
RXY5@@quR0 X@@R Rff56Z@uffX5RX,B
@@
ff
5
6@05[#ff 5551\Xk uR fff\fffi5h1
RX R@55X@zh5
h Z50RZ
RRR{@
15R:@zX@51R~B@5RX5:, Ru@5 ff
ff k" !#\ $ fi|
>h]f,fffffi



%&('$)ff*+$'ff,'-.&/01ff243 4ff
52@RXaR\6o1T

Xf

>5f 5,6a5ffTE,kh @k765@,fzff
v,X@5X5R RX{5@
5o6Xo5@@] R3 5@@@ff98:8;8=<>&?."@ff$'ff"A'ff,BC$*+&(ff2B1C DE'ff&GF$H


ff

@
>5f R
RX5Tff\ 6[ff@bRX@ {Z@zX5X0hffI6{RR@
R,R0@4

@ffX@X
RXX6[ J5 Z@zfE] {Z|RX fT@ K)ffL ff%C@MNOB1C *P&(ff2
/ @Q@'ff&%RS.N'ffTM&?' /CU/@ffVW3 C RWSX@qXffXY6,B@

Z$[$\

fi]M^`_J_Jab9^c"de^`defYg"h"ic+j"^g"dkflcnmoffpJb

q:r$s+tffu4vwffx-y`wffz|{}G~J9@vPs+uwPy( ffffff~ffUyffu+9u4vPs-vJ>$}(r@"u4;u`s-~ff}9JvJ+u`~ffs-v+"r@4$y>sr@/~ff"}(vwffy`w
vP"}r@9$ffffwny>y`wzK4/"r@@9v+}@wy"$y@w"Kff ff%@NT$+(ff>/Uff%-ffffT($%@%ff
WO@yn=;}r@9$y
q:r$s+tffu4vw>x-y`wz{>}9~J9@vPs+uwyE($ffff."@yAsTus""+%JvP+/"+e~ff}(@+u49r@@/"}(rffyser@/~."}(vw>y`w
vP"}r@9$ffffwny>y`wzK4/"r@@9v+}@wy"$y@w"Kff ff%@NT$+(ff>/Uff%-ffffT($%@%ff
WO@yn=;}r@9$y
q:r$s+tffu4vwx-y`w+u`~ff}(wy`wz{>}9~J9@v+s+uwyS$ffJPUy>r$~ff}9s+u`s+t4vPs+tJ9r$}G"r$"r$s+"r$s+@u4r@Au4/
tP}9~J"u4r$s.A"r@9@r$s.Au4"uY$+4$y9;:>?."@ff$ff"KffT1 P(ff>$E.9 wffUw ff $."y
qM}(u4"4rffwffyP$ffffffUy$K`""~ffs+r@9$~A}(r@$"}9}(r$s.:s+r$"}9~J$s+r@(MvP}9K~ff}(@+u49r@@/"}(rEAu4/W~A+u4""r$s-~ff}9JvJ
-vP"r@us.9r$}9"}r@/~J9u4vPs>y . %/U;ff--+/ffffw($Uw. ff"y
"~ff++u`s>wx-y`wzqM~J4"uwy($.ffff@yAu4""r$sT~ff}9JvJY-v+"r@4v/+rWtJ?"}(vffGr@us.@v+"+r@}(r@@r$+GvP}
~ffOu4ffyM"ff+/ff(;ff +ffffffAN.G w> ff /ff%y
"}(u4/~ffs>wEy$ffffffUy=Mr@u`s.vP}@r$-r$sff4r$~ff}Gs+us+t|Au4/"r$}(@r$+%"~J~J4u`~J9u`s+tkA+r"r$}(@r$+%"~J
"uG9u`s+@9u4vPs+Y~ff""}(v+~J>yskM? /%%ffN.ff-(l+JffffffffK;.@@$($/./ N.
/ N4P$/ wff">y$ff $ff"y
r$+9Gr$}@w$-yJyw ~u}wffy@ky`wJz "+us>w+y$qKyP$ffffffUy$~J+u`S"Su`Jr@4u`+v+vP}vPu`s+@vP+4r@9r
~J/~WPu`~/+rE~J4tffv+}(u4/"yM"ff+/ff(M ff ff/. $ N Aw+Jw%."y
{}G~J9@vPs+uw"y`wPvP}(uwffky`w.~tfftffu`s+uwPky`wffz+v+~"w"y($.JP@y>s+ur@u`s.9r@tP}9~JGuv+s-vJr@"+4u@u4}G+r@
~ffs+ 4r$~ff}Gs+us+tk. r@"~ff+4ru`s }(r@$"}G}(r$sffs+r@(MvP}9.$y9:; >(ff"@ff Nffnff
ffM%@+
ff
1.,ff+N/ /ff+w>ff@w"J+ JPny
~ff}uw-y`w+z=xEv+"s+twP>y($.ffff@y+rr@9Gu~J9u4vPs-vJ9GvP@"~J99u4K@vPs.9r@P}(r@rtP}9~ff~ff}(;+9u`s+t-/+r
us+Gu"r%v++99u4"r~J4tffvP}(u4/"y;ff +$ . %/UYff
.ffP+@+$w "wff ff"y

>r@rffw
-y {Ay$ffffffUy+ff-ff . %/U%%9PNfffiffMP-ff$ $4 - ;P K9 @$-y
K.Mr$}MK$~J"r$-u4;"+y
>r@+u`s+9vPs>w>y>Ay`w>A~ff+u`s+r$}@wEyy`wz+vPs++uwky"kyE($ffff.@y;su`s./}(v++@9u4vPse9v/+rS~ff"+4u4$~
9u4vPs,vJE/+r/+r@vP}(,vJ"}vP"~ff+u44uG9u4-"s+@Guv+s+vJE~-~ff}9JvJY"}(v+@r@9AGvO~.+9vP~JGu%"r@r@@
}(r@@vfftPs+u49u4vPs>yMA N > >/UP%ff""ff+/ff4w +@w$ff. $ffy
evff@r$}@w ky y"($.ffff@yffA+rMu`s++@9u4vPs-vS+49u49$~r9r$"v+}9~J+9/}9+@/"}rffysWv+v+"ffwJy`wJ~ffs+GvPs>w
>y`wPz>u`"~.s"s>wyE" y@wPKff ff%@KN 1 P(ff/Uff%-ffffM? /U/@ff W "w"">y
ffff .ff"~ffs,~JGr@vw Synv+}(tP~ff
~ff.~ffs"s>y
A~ff+u`s+r$}@w:EyyM($ff.ff@y- /+GvP}(u`~JEvPs+u4""r$s~ff}9v OvP"r@4Y~ffs+ 9r@4r@@9r@ ~."+u4$~JGuv+s+u`s
/"r@r@@}(r@@v.tPs+u49u4vPs>yM( /%/.N.ff(-PW9;:wEff>ff@w"ff. ffffny

MvP.Mr$}@wyE($.JP@y;+r9u`-rW"uOr$s+9u4vPsTvJs+r$"}G~Js+r@(MvP}9-vP"r@4$yK- Pff%:+ N.Pw
.@w"ff Pffy
MvPs>w+y`w++u`s+tffr$}@w+xSywzMu4/+ffffw"Wy( ffJP@y>A+rnvJr$}:vJ~ffs+r@9u`~"ys vJA~ffs>wJy+y`w+r@%~ff"}(vw
y`wffzK4/"r@@GvP}@w+yE"$yUwff.$ff/U,1 P(ffn/@@ff%S.Nff,M($%@%ff > Jw+">y
$ff ff"~ffs,~JGr@vw Synv+}(tP~ff
~ff.~ffs"s>y



fi
"!$#&%('*)+
,.-#!
/0132547689;:<=?>7<A@B7CD:FEGCfi<H>7<JILKMBN4O4OB7813P<Q/R>QSUTVWXDY5>[Zfi28D9FC\B7C\]^B7C:F29_C8`49U2a9;25PF2C:.8`:FBOEGC\P?bc
29F9UEG9Ra9UE\a8`]G8`:FBOEGCfi>edfCg/01h254i68D9U:<=?>7<*ILjlkmQ4O254O4i8DC\n*<o
>QSqpnPr>sY5<tQuvUuwxwNyrwzR{7|5}qv.{~G}qy.
tvU.y5|.|{x\<`E4q>JTD<Gk568afi>
W<aafi>fiTWX>Dj^d9U25PFP<m813b9UBOn]2>
2C\25:8<"p>JSUTrVWTY5>D

yfGuD}q{$ryRuD}qv{xy|uD
uDvF`Gu{x|5> a9UB7C\]295<fi25E\9F
>
EGC\nB7"<Jp>S;TVY>6\2E\a\:FB71?8`4k5EGCD:9UE4AE`a89;:FB78`4O4NclEGb\P_29U8b\4O2j^89F`E`ea9UEGk525P_PF25PE`29:6\2
C\BN:_26\EG9UBO5EGCfi>AyvUu}q{x|Ry5|5y.uvU5G<fi`<ATT.fiTWW>
EGC\nB7"<Jp>S;TVWY>6\2E\a\:FB71?8`4k5EGCD:9UE4AE`a89;:FB78`4O4NclEGb\P_29U8b\4O2j^89F`E`ea9UEGk525P_PF25PE`29:6\2
BiC C\BO:F2?6\EG9;BN5E\CfinBOPFk5EG0CD:F25nk8`P_2>RAyrvuD}q{$|Ry|y.uvU5G<fiG<
Wr`
>
:FE4Ok5`2<3>7<IR13EG6\0C\n
9UE
< >ASUTVVDY5>J@BOnn2Cej^89F`E`?13E\n254*B7C\n
0\k5:FBOEGClbceQ8rc25PFB78Ce13E\n254
1329U]B7C\]
>RdCl@8C\PFEGCfi< >fio">7<mE8Cfi<"o
>fi=?>7<fiIHRBO4O25P<*mR>fiZ>SqpnP>sY5<fiu"y|{$yrGvUuw
55v.uD}q{$tQvry||5{xr|}qyr|`<
aafi>*TTTW 8Cj^8`:F25E
<mQ3>jlEG9U]\8C[R8D0D1?8DCCfi>
KMBO4N4OB7813Pr</R><IfiB7a\PF295<R=?>S;TVWVY>(4O289FC\B7C\]8`4O]EG9UBO:61qEG9k5EGC:_BiC\08`4O4Oc9F0CC\B7C\]0\4O4Oc
9U25k09F9U2CD:C\209F8`4AC\25:QEG9_P>yrGvUuw\}qu}q{$D
<`<
W>



fiJournal Artificial Intelligence Research 3 (1995) 119-145

Submitted 3/95; published 8/95

Using Qualitative Hypotheses Identify Inaccurate Data
qi-zhao@is.aist-nara.ac.jp
nishida@is.aist-nara.ac.jp

Qi Zhao
Toyoaki Nishida
Graduate School Information Science
Nara Institute Science Technology
8916-5, Takayama-cho, Ikoma-shi, Nara 630-01, Japan

Abstract

Identifying inaccurate data long regarded significant dicult problem AI. paper, present new method identifying inaccurate data
basis qualitative correlations among related data. First, introduce definitions
related data qualitative correlations among related data. put forward new
concept called support coecient function (SCF ). SCF used extract, represent,
calculate qualitative correlations among related data within dataset. propose
approach determining dynamic shift intervals inaccurate data, approach
calculating possibility identifying inaccurate data, respectively. approaches
based SCF . Finally present algorithm identifying inaccurate data
using qualitative correlations among related data confirmatory disconfirmatory evidence. developed practical system interpreting infrared spectra applying
method, fully tested system several hundred real spectra.
experimental results show method significantly better conventional
methods used many similar systems.
1. Introduction

many problems artificial intelligence, inferences drawn basis interpretation
analysis measured data. However, measured data inaccurate, interpreting
analyzing dicult. diagnosis signal analysis, example, general
reasoning method compare measured data reference values (Reiter, 1987; Shortliffe
& Buchanan, 1975). measured data accurate due noise unforeseen
reasons, comparison measured data reference values lead
useful conclusion. rule like \if strong peak 3000 cm01 - 3100 cm01

infrared spectrum unknown compound, unknown compound may contain
least one benzene-ring" may work ideal cases. However, rule work general
cases. example, spectral data inaccurate, e.g., measured peak 3000
cm01 - 3100 cm01 strong peak medium one, measured strong peak
exactly located 3000 cm01 - 3100 cm01 slightly shifted, rule may
applied.
practical problems, especially data rich problems diagnosis interpretation, measured data often inaccurate. One reason measuring methods
error-prone. example, patient's temperature blood-pressure may inaccurately
measured entered, witness may inaccurately describe features criminal.
reason real data noise-free. example, among received
c 1995 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiZhao & Nishida
signals, may noise mixed up, worse, infrared spectral data (peaks)
may noisy, i.e., peaks may affected noise factors.
Identifying inaccurate data long regarded significant dicult problem
AI. Many methods proposed deal problem. Fuzzy logic provides
mathematical framework representation calculation inaccurate data (Zadeh,
1978). fuzzy logic, reference value x0 associated fuzzy interval 4x.
measured data item falls [x0 0 4x; x0 + 4x], identified reference
value corresponding membership degree. Probability theory possibility theory
also widely used handling inaccuracy uncertainty (Dempster, 1968; Duda, Hart,
& Nilsson, 1976; Pearl, 1987; Shafer, 1976; Shortliffe & Buchanan, 1975).
methods commonly used AI systems. way applying them, however, depends
nature domain problems, yet standard generally accepted
method thus far.
present method identifying inaccurate data basis qualitative correlations among related data. method based essential consideration
data items within dataset qualitatively dependent: set data may describe
phenomenon, refer behavior. example, patient's temperature, blood
pressure symptomatic data ect patient's disease, couple peaks
infrared spectrum indicate presence partial component. call dependency
among data within dataset qualitative correlations among related data1 . considering
qualitative correlations among related data, obtain confirmatory disconfirmatory
evidence identify inaccurate data. general, related data simultaneously
present absent, related data completely identified, data
enhance identification rest. example, benzene-ring create many
peaks besides strong peak 3000 cm01 - 3100 cm01 . peaks created
benzene-ring related data qualitative correlations. peaks except
3000 cm01- 3100 cm01 completely identified, benzene-ring quite
likely contained unknown compound. Therefore, inaccurate peak around
3000 cm01 - 3100 cm01 may still identified. fact, spectroscopists frequently use
following knowledge addition rules given beginning section:

strong peak around 3000 cm01 - 3100 cm01 , spectrum may
partially created benzene-rings |{ check peaks around 1650 cm01 , 1550
cm01 700 cm01 - 900 cm01 make sure benzene-ring may
peaks time.
central idea method find evidence identifying inaccurate data
considering qualitative correlations among related data. idea common human
thinking. data except blood pressure patient show patient
certain disease, would naturally suspect blood pressure patient
inaccurately entered. Similarly, peaks except one indicate partial
component present, would naturally suspect unmatched peak inaccurately
measured peak affected noise something else. acceptable solutions
made assuming inaccurate data item reference value based qualitative
1. Detailed definitions given later.

120

fiUsing Qualitative Hypotheses Identify Inaccurate Data
correlations data item related data, inaccurate data item may
compensated hence identified.
contributions include: (1) method assumes inaccurate data item
certain reference value based qualitative correlations inaccurate data
item related data, (2) algorithm crystallizes method, (3)
practical system uses algorithm interpret infrared spectra.
key point new concept called support coecient function (SCF ) extracting,
representing, calculating qualitative correlations among related data. measured
data inaccurate, qualitative correlations among related data provide evidence
confirming disconfirming hypothesis measured data
reference values. approach determining dynamic shift intervals inaccurate data,
approach calculating possibility identifying inaccurate data, algorithm
identifying inaccurate data proposed basis SCF , respectively.
method requires assumptions advance, avoid inconsistency knowledge data bases. method identifies inaccurate data considering qualitative correlations among related data, quite effective ecient, especially case
problems dependencies among data apparently exist. general, qualitative correlations among data always, less, extracted. worst case
qualitative correlations known priori, method degenerates conventional
fuzzy method2 .
developed practical system interpreting infrared spectra using
method (Zhao & Nishida, 1994). primary task system identify unknown
compounds interpreting infrared spectra. fully tested system
several hundred real spectra. experimental results show method significantly
better traditional methods used many similar systems. rate correctness
(RC ) rate identification (RI ) two important standards evaluating
solutions infrared spectrum interpretation near 74% 90% respectively,
former highest among known systems.
following sections, first describe problem identifying inaccurate data
Section 2. Section 3 give definitions including concept support coecient
function (SCF ) concepts based SCF . Section 4 introduce method
identifying inaccurate data considering qualitative correlations among related data.
Section 5 demonstrates application method knowledge-based system
infrared spectrum identification, shows experimental results system. Related
work discussed Section 6. Conclusions addressed Section 7.

2. Problem Description

practical problems, measured data represented finite set:
2. refer fuzzy methods use empirical fuzzy interval inaccurate data item
conventional fuzzy methods.

121

fiZhao & Nishida

= fd1 ; d2 ; :::; dn g;

reference values also represented finite set:
RV = fr1 ; r2 ; :::; rN g:

Suppose interpreting analyzing measured data carried basis so-called
\if-then" rules premises comparisons RV like \if di = rj
...", \if (ri 2 MD) ^ (rj 2 D) ...". accurate, main
operation implied premises usually find corresponding reference value
RV data item D. However, inaccurate, operation becomes
complicated. case, dicult determine reference value inaccurate
data item corresponds to, e.g., measured data reference value may simply
identified, others one may available.
example, received signals known accurate, expected signal (reference value) found signal series (measured data), conclude
expected signal appear. However, received signals inaccurate,
expected signal identified signal series, hard decide whether
expected signal appear appears looks different due inaccuracy.
currently known approaches dealing inaccurate data fuzzy logic
probabilistic reasoning mainly based quantitative similarity closeness
measured data reference values. cases, however, identity qualitative
features effective reliable quantitative similarity closeness.
Consider signal analysis again. inaccurate signal qualitative features
expected one interval frequency, signal may still identified even
though quantitative features slightly different expected one
strength etc.; conversely, inaccurate signal may identified quantitatively
similar expected signal qualitative features expected
one.
discussed following points Section 1, (1) data items within dataset
qualitatively dependent (i.e., related data), (2) qualitative correlations
among related data, (3) qualitative correlations among related data enable us confirm
disconfirm identity qualitative features.
Therefore, RV be, explicitly implicitly, divided finite groups
basis qualitative dependencies among data, data group related
other. example, RV divided R1 , R2 , ... Rk :
RV = R1 [ R2 [ ::: [ Rk ;


Rj = frjl j rjl

2 RV; 1 l mg:

qualitative correlations among related data Rj include: (1) data Rj
simultaneously present absent means reference values Rj
122

fiUsing Qualitative Hypotheses Identify Inaccurate Data
corresponding data MD, (2) presence rjp may enhance presence rjq ,
absence rjp may depress presence rjq . Considering qualitative correlations
among related data lead evidence identification inaccurate data.
problem interpreting/analyzing inaccurate data make qualitative hypotheses
D, words, find subset RV MD, corresponding D:
(M D);

(IN (MD) RV ):

problem brie represented following predicate calculus:

8di8Rj ((di @Rj ) ^ (Rj @M D) ! Rj (M D))3 ;
\di@Rj " \Rj @MD" two essential qualitative predicates method
represent di possibly (qualitatively) belongs Rj (i.e., ? di 2 Rj ), Rj possibly
(qualitatively) belongs MD (i.e., ? Rj D), respectively. Determining \A@B "
based qualitative correlations among related data. work presented paper
mainly concentrated determining \di @Rj " \Rj @M D", realizing
predicate calculus.
3. Preliminaries

introducing method, first put forward explain several new concepts
section.

3.1 Qualitative Correlations among Related Data
Definition 3.1 Related data: data d1 , d2 , ..., dm describe common phenomenon,
refer behavior simultaneously, treated related data.
example, patient's temperature, blood pressure symptomatic data
related data, features describing criminal also related data. phenomenon data within dataset related data apparent engineering.
instance, two types related data infrared spectrum interpretation
shown Figure 1. First, far single peak concerned, frequency (position) fi ,
strength (height) si , width (shape) wi peak related data. Second, partial
component may create numerous peaks time. consider peaks
partial component may create, peaks related data.

Definition 3.2 Qualitative correlations among related data: di dj two related data
items, presence di enhances presence dj , absence di depresses
presence dj . kind effect called qualitative correlations among related data.
3. Con icts (overlaps) (MD ) eliminated. discuss con ict-resolving
paper, concentrate method identifying inaccurate data, i.e., ? di @Rj ? Rj @MD.
Interested readers may refer paper Zhao (1994) specific discussion concerning problem
con ict resolution.

123

fiZhao & Nishida

fi





wi

Figure 1: Example related data spectrum interpretation
Consider example spectrum interpretation again. spectral data inaccurate (i.e., measured peaks look like exactly reference
peaks), considering qualitative correlations among related data may lead qualitative evidence identification inaccurate data. example, suppose frequency
peak slightly different reference value, strength width
peak reference values. frequency peak may still
identified since related data support it. Similarly, peaks low frequency sections inaccurate, considering related peaks high frequency sections may help identify
peaks, vice versa.

3.2 Support Coecient Function
Definition 3.3 Support coecient function (SCF): 0 1 data related di,
support coecient function di calculates total effects related data
considering qualitative correlations di related data.
Suppose (di ; dj ) represents qualitative correlation di dj ,
support coecient function di defined as:
SCFi = fi (


X

j =1;j 6=i

(di; dj ); m):

SCFi directly depend many much related data support di .
SCFi greater certain value given domain experts, related data tend
support di ; otherwise, related data tend depress di .

3.3 Evidence Based SCF
Section 2, used \di @Rj " express di qualitatively identified Rj .
Realizing \di @Rj " requires definition shift interval 4 Rj as:
124

fiUsing Qualitative Hypotheses Identify Inaccurate Data

Rj 6 4 = f(rjl 6 4) j l = 1; 2; :::; mg;

definition possibility \di 2 Rj 6 4".
formula similar fuzzy logic, contains completely different
meanings. primary difference shift intervals dynamically determined
SCFi , fuzzy logic, fuzzy intervals usually provided domain experts
advance calculated quantitative criteria.

Definition 3.4 Shift interval: Shift interval dynamic region inaccurate data. Given
standard fuzzy interval inaccurate data, shift interval di varies around
standard fuzzy interval basis SCFi . SCFi shows related data
support di , shift interval di becomes wider standard fuzzy interval.
hand, SCFi shows related data support di , shift interval
di becomes narrower standard fuzzy interval.
Definition 3.5 Evidence based SCFi : SCFi determines shift interval di , is,
SCFi determines widely di allowed shift. wider shift interval,
easily di identified. Therefore, SCFi provides confirmatory disconfirmatory evidence
identifying di .
4. Making Qualitative Hypotheses Inaccurate Data

section, introduce analyze method identifying inaccurate data.
first discuss processes realizing two essential predicates method, \di @Rj "
\Rj @MD" respectively. Then, present algorithm making qualitative hypotheses
inaccurate data (i.e., realizing predicate calculus described Section 2).

4.1 Predicate \di @Rj "
di accurate, \di@Rj " equal \di 2 Rj ". reference value Rj
corresponds di (i.e., rjp 2 Rj rjp = di), di @Rj = . reference
value corresponding di , di@Rj = F . di inaccurate, however, sure
whether rjp corresponds di . case, \di@Rj " means di possibly (qualitatively)
belongs Rj , words, rjp possibly (qualitatively) corresponds di . value
\di @Rj " F , possibility \rjp = di " \di 2 Rj ".
discussed Section 2 cases identity qualitative features
robust reliable quantitative similarity closeness. also discussed
qualitative correlations among related data lead evidence identity qualitative features diagnosis interpretation. rjp (rjp 2 Rj ) assumed correspond
di, 0 1 reference values (rj1 , rj2 , ..., rjp01 , rjp+1 , ..., rjm ) related rjp ,
0 1 reference values correspond certain data item MD,
0 1 data items also related other. Therefore, qualitative correlations
di 0 1 related data items MD considered.
method first determines possibility \rjp = di " calculating similarity
closeness rjp di like conventional fuzzy methods, considers qualitative
125

fiZhao & Nishida
correlations among related data obtain evidence updating possibility.
qualitative correlations show related data support \rjp = di ", possibility
\rjp = di " increase. qualitative correlations show related data
support \rjp = di ", possibility decrease.
4.1.1 Defining Support Coefficient Function

Suppose rjq (rjq 2 Rj ) corresponds dt . rjq related rjp , dt related di .
discussed, qualitative correlation di dt means dt exists,
di enhanced; otherwise, di depressed.
first define qualitative correlation two related data items, di dt , as:
ci (dt ) =

(

1 dt found MD satisfies: rjq 0 dt rjq +
0 dt found satisfies: rjq 0 dt rjq +

standard fuzzy interval inaccurate data, ci(dt) expresses qualitative
correlation di dt . ci (dt )=1 means di enhanced since related data
item dt found measured dataset, ci (dt )=0 means di depressed
since related data item dt found measured dataset. definition
ci (dt ) simply based consideration data item identified, data
item support related data items (i.e., coexisting data items).
reference values Rj , define support coecient function
SCFi di based ci(dt) (t = 1; 2; :::; m; 6= i):
SCFi =

1+

Pm

t=1;t6=i ci (dt )



0 < SCFi 1, SCFi expresses total qualitative correlations di
related data. words, SCFi ects support coecient rjp
corresponding di .
= 1, SCFi = 1. > 1, SCFi direct ratio number
related data may identified D.
4.1.2 Determining Dynamic Shift Interval

Suppose standard fuzzy interval inaccurate data, define dynamic shift
interval di based SCFi as:

0 1)do 2 SCF
4di = (2m

0 < 4di < 2do , 4di direct ratio SCFi .
= 1, SCFi = 1, 4di = . words, qualitative correlations
among data known priori, SCFi = 1 4di = . case, method
degenerates conventional fuzzy method.
126

fiUsing Qualitative Hypotheses Identify Inaccurate Data
fixed, related data identified, greater SCFi is, therefore
greater 4di is. SCFi fixed, 4di depends number related data.
Table 1 shows relation among 4di , SCFi .

4di

1

/
/
/
/

1
0.8
SCFi 0.5
0.3
0.1

10
1.9000do
1.5200do
0.9500do
0.5700do
0.1900do

50
1.9800do
1.5840do
0.9900do
0.5940do
0.1980do



100
1.9900do
1.5920do
0.9950do
0.5970do
0.1990do

500
1.9980do
1.5984do
0.9990do
0.5994do
0.1998do

1000
1.9990do
1.5992do
0.9995do
0.5997do
0.1999do

Table 1: Relation among 4di , SCFi
draw following properties formulas.
Property 1: m, related data identified, greater SCFi
is; otherwise, smaller SCFi is.
Property 2: m, greater SCFi , greater 4di . words,
related data support di , widely di allowed shift.
Property 3: SCFi, greater m, less 4di varies along m.

words, greater number related data, less single related data item
affect di .
Property 2 Property 3 illustrated Figure 2.
2do
SCFi = 1

di

SCFi = 0.5

SCFi = 0.1
SCFi = 0.3

0


Figure 2:

4di versus different SCFi

Property 4: 4di linear relation SCFi . slope equal to, greater 1.5,
means 4di heavily depends SCFi .
127

fiZhao & Nishida
Property 5: Along increase m, slope increases slightly.
words, 4di depends number related data support di , rather
total number related data.
Property 4 Property 5 illustrated Figure 3.
2d

m=100

di
m=2


m=10

0
0

Figure 3:

1

SCFi

4di versus SCFi different

4.1.3 Calculating Value Predicate \di @Rj "

value \di @Rj " equal possibility \rjp = di " calculated
using following formula:
= 1 0

j di 0 rj j
4di
p

1.
glance, representation looks like membership degree \rjp 0 4di
di rjp + 4di" fuzzy logic. However, meaning completely different, 4di
neither provided domain experts determined quantitative similarity closeness.
4di determined basis qualitative correlations among related data.
qualitative correlations among related data considered, 4di , possibility
jd 0r j
1 0 jp . consideration qualitative correlations, possibility updated.
Two new properties drawn formula calculating .
Property 6: di, greater 4di , greater . words,
wider dynamic shift interval, greater value \di @Rj ". Formally, 4d00i
4d0i 4di , 00i 0i .
Property 7: SCFi provides qualitative evidence accepting rejecting di rjp since
direct ratio 4di, 4di direct ratio SCFi.
128

fiUsing Qualitative Hypotheses Identify Inaccurate Data
Property 6 Property 7 illustrated Figure 4.
1
ui
ui

ui

0
rjp

di
di
di

di

Figure 4: Value \di@Rj " versus various 4di
process realizing \di @Rj " calculating value \di @Rj "
expressed following procedure.
Procedure di@Rj
select rjp f rom Rj ;
SCFi = 0;
di = rjp f
SCFi = 1;
= 1;

g

elsef

rjl 2 Rj (l = 1; :::; m; l 6= p)f
calculate ci (dt )4 ;
SCFi = SCFi + ci (dt );

g

g

SCFi = (1 + SCFi )=m;
4di = 2 SCFi 2 (2m 0 1)=m;
= 10 j di 0 rjp j =4di;

4. dt stands data item MD corresponds rjl .

129

fiZhao & Nishida
> 0
return i;
else
return N IL

end procedure

di identified certain possibility (i.e., > 0), procedure returns
(i.e., value i); otherwise, procedure returns F .

4.2 Predicate \Rj @M D"

accurate, \Rj @M D" equal \Rj D". reference values
Rj identified MD, Rj @MD = ; otherwise Rj @M = F .
inaccurate, however, \Rj @M D" means Rj possibly (qualitatively) subset D.
value \Rj @MD" F , possibility reference values
Rj identified D.
l > 0 (l = 1; 2; :::; m), Rj regarded subset certain
possibility. Let s1 , s2 , ..., sm priorities reference values Rj ,
value \Rj @MD" calculated based 1 , 2 , ..., using following
formula:

Pm 2
l
=1 l
Rj @MD = lP
;
l=1 l

l > 0;

l > 0:

Suppose calculated using procedure di @Rj , process realizing
\Rj @MD" calculating value \Rj @M D" expressed simple procedure.
Procedure Rj @M
P = si 2 ;
= si ;
f l = 1 (l 6= p)f
l = dt @Rj ;
l > 0f
P = P + sl 2 l ;
= + sl ;

g

elsef

g

g

P = 0;
exit;

P > 0
return P=S ;
else
return N IL

end procedure

130

fiUsing Qualitative Hypotheses Identify Inaccurate Data
Rj identified subset certain possibility (i.e., P=S ),
procedure returns (i.e., value P=S ); otherwise, procedure returns F .

4.3 Algorithm Making Qualitative Hypotheses Inaccurate Data
give following algorithm interpreting/analyzing measured data based procedure di @Rj procedure Rj @MD. measured data accurate,
algorithm identify inaccurate data items considering qualitative correlations among
related data.

Algorithm aking -Qualitative-Hypotheses
(MD) = ;;

f = 1 n f
j = 1 k f
P (Rj ) = 0;
di @Rj (i:e:; Procedure di @Rj )
Rj @M (i:e:; Procedure Rj @M D) f
Rj ! (MD);
P (Rj ) = Rj @MD;

g

g
g

end
end

end

end f

end algorithm
algorithm, P (Rj ) represents value \Rj @MD". algorithm actually
realization predicate calculus: 8di8Rj ((di @Rj ) ^ (Rj @M D) ! Rj (MD)).
measured data item fd1 , d2 , ..., dn g, algorithm searches fR1 , R2 , ...,
Rk g once. Rj (Rj = frj1 ; rj2 ; :::; rjm g), algorithm checks n 0 1 measured
data items times, 0 1 reference values n times. Therefore, blind
search, number operations (at worst): n 2 k 2 [m 2 (n 0 1) + n 2 (m 0 1)] =
2 2 k 2 2 n2 0 k 2 n2 0 k 2 2 n. Since k two constants, complexity
algorithm O(n2 ).
5. Application Infrared Spectrum Interpretation

developed knowledge-based system interpreting infrared spectra applying
proposed method, fully tested system several hundred real spectra.
experimental results show proposed method significantly better
conventional methods used many similar systems.
131

fiZhao & Nishida
5.1 Infrared Spectrum Interpretation
primary task infrared spectrum interpretation identify unknown objects
interpreting infrared spectra. paper, limit problem interpretation
infrared spectra compounds determine composition unknown compounds without
loss generality.
Selecting infrared spectrum interpretation domain application
following reasons:
1. Interpreting infrared spectra significant problem academic research
industrial application. example, chemical science engineering, interpreting infrared spectra compounds effective way identify unknown
compounds, analyze composition purity compounds (Colthup, Daly,
& Wiberley, 1990).
2. Interpreting infrared spectra dicult problem. First, spectral data huge
quantity, complex representation. Second, symbolic reasoning
numerical analysis needed interpret infrared spectral data (Puskar, Levine, &
Lowry, 1986; Sadtler, 1988).
3. Interpreting infrared spectra typical problem dealing inaccurate data since
spectral data often inaccurate. often shift theoretical values due
various reasons. example, following assertion spectrum interpretation:

high frequency peak partial component P Cff located Fi .
practice, however, peak P Cff may irregularly shift around Fi due noise
unforeseen reasons. assertion used identify real spectra,
uncertainty arises.

5.2 Applying Proposed Method Infrared Spectrum Interpretation
Interpreting infrared spectra special problem diagnosis. Suppose infrared spectrum unknown compound thresholded represented finite set peaks
(i.e., measured dataset MD):
Sp = fp1 ; p2 ; :::; pn g;

every peak consists frequency (position) f , strength (height) s, width
(shape) w, respectively:
pi = (fi; si ; wi )

= 1; 2; :::; n:

fi , si wi refer peak pi , related data. first
kind related data infrared spectrum interpretation.
132

fiUsing Qualitative Hypotheses Identify Inaccurate Data
Suppose finite partial components (i.e., reference values RV ):
P C = fP C1 ; P C2 ; :::; P Ck g
= ffpj1 ; pj2 ; :::; pjm g j j = 1; 2; :::; kg
= ff(fjp ; sjp ; wjp ) j p = 1; 2; :::; mg j j = 1; 2; :::; kg.
fjp , sjp wjp also refer reference peak pjp , first kind
related data well.
spectroscopic knowledge interpreting infrared spectra usually expressed \if
pi equal pjp , pi may created partial component P Cj ". \pi equal
pjp " represents fi , si, wi equal fjp , sjp , wjp respectively.
first kind related data following qualitative correlations:
1. fi , si wi identified simultaneously, is,
fi fjp , si sjp wi wjp ,
si sjp , fi fjp wi wjp ,
wi wjp , fi fjp si sjp .
2. related data support other. example, fi si identified,
enhance identification wi . Conversely, fi si
identified, weaken identification wi .
method identifying fi , si wi based qualitative correlations among
formalized following predicate calculi, respectively:

8fi 8pj ((fi @pj ) ^ (pj @pi ) ! pi created P Cj ),
8si 8pj ((si@pj ) ^ (pj @pi ) ! pi created P Cj ),
8wi 8pj ((wi @pj ) ^ (pj @pi ) ! pi created P Cj ),
p

p

p

p

p

p

p

p

p

\pi created P Cj " means fi , si wi qualitatively identified
fjp , sjp wjp .
general, partial component may create finite peaks time. pi
created P Cj , Sp partially created P Cj ; Sp partially created P Cj ,
peaks P Cj may create contained Sp simultaneously. Therefore,
peaks created partial component also related data. second kind
related data infrared spectrum interpretation.
second kind related data following qualitative correlations:
1. peaks partial component identified simultaneously, is,
pi pjp , pjl

2 Sp

(l = 1; 2; :::; m; l 6= p).

2. peaks created partial component support other. example,
peaks partial component identified, peaks
enhance identification rest peaks. Conversely, peaks
partial component identified, identification rest peaks
depressed.
133

fiZhao & Nishida
method identifying related peaks based qualitative correlations
formalized following predicate calculus:

8pi 8P Cj ((pi @P Cj ) ^ (P Cj @Sp) ! P Cj (Sp)).
5.3 System Interpreting Infrared Spectra
system implemented C MS-WINDOWS. Figure 5 shows data ow
diagram system.
Knowledge
Base
spectroscopic
knowledge
input

H
C H
H

solution

INFERENCE ENGINE
reference
values
Sp: Unknown Infrared Spectrum

Data
Base

PCa

PCb

COC
PCc

IN(Sp): Interpretation Sp

Figure 5: Data ow diagram system
input data system infrared spectra unknown compounds,
solutions partial components input spectra may contain. inferences
based qualitative features spectral data qualitative correlations among related
data, system gain high correct interpretation performance noisy spectral data.
mentioned before, two types related data infrared spectrum interpretation: features single peak (i.e., fi , si wi pi), peaks
single partial component (i.e., p1 , p2 , ... pm ). inference engine system
employs proposed method types related data inaccuracy arises.

5.4 Example
discuss performance system following example. Figure 6 shows
infrared spectrum unknown compound. spectrum hard interpret
since peak arrow (named p1 ) shifts substantially. system correctly identifies
p1 created partial component benzene-ring.
contrast, many similar systems correctly identify peak (Clerc, Pretsch,
& Zurcher, 1986; Hasenoehrl, Perkins, & Griths, 1992; Wythoff, Buck, & Tomellini,
1989) since peak benzene-ring frequency position (named pb1 )
strong peak (i.e., sb1 > 1:000) according spectroscopic knowledge, medium one
(s1 = 0:510) case example. Systems based conventional fuzzy methods
usually assume fuzzy interval inaccurate peak, determine membership
degree inaccurate peak fuzzy interval. Suppose reference value
strong peak 1:000, fuzzy interval strong peak 0:300 (Colthup, Daly,
134

fiUsing Qualitative Hypotheses Identify Inaccurate Data
& Wiberley, 1990), peaks strength 1 6 0:300 regarded strong
peaks. Obviously, conventional fuzzy methods, possibility p1 strong peak
zero, i.e., benzene0ring (s1 ) = 0.
Inferring basis qualitative correlations among related data, system makes
correct interpretation spectrum. following two cases, introduce
inference process system, time demonstrate use method
identifying inaccurate data.

Strength (Absorbance)

0.000

1.200
4000

Frequency(cm1)

600

Figure 6: example infrared spectrum
5.4.1 Case I: Considering First Kind Related Data

frequency (position) width (shape) p1
benzene-ring, possibility f1 identified fb1 100% (i.e., benzene0ring (f1 ) = 1),
possibility w1 identified wb1 also 100% (i.e., benzene0ring (w1 ) = 15 .
discussed before, f1 , s1 w1 related data, obtain confirm
evidence identifying s1 considering qualitative correlations among s1 , f1 w1 :
benzene0ring (f1 ) = 1,
so, cs1 (f1 ) = 1 (cs1 (f1 ) represents qualitative correlation s1 f1 ),
benzene0ring (w1 ) = 1,

so, cs1 (w1 ) = 1 (cs1 (w1 ) represents qualitative correlation s1 w1 )
so, SCFs1 =

1+2
3

= 1,

4s1 = (601)23 0:300 2 1 = 0:500,
:510 = 0:02.
s1 @pb1 = 1 0 100:0500
5. 3 (d) means possibility identified conventional fuzzy methods, i.e., SCF
considered.

135

fiZhao & Nishida
considering SCFs1 , possibility p1 regarded strong peak benzenering increases 0 0:02. possibility, 0:02 may different 0:04 0:06,
0:02 significantly different 0. Many near-misses may handled negligible
possibility. example, systems based fuzzy methods (Clerc, Pretsch,
& Zurcher, 1986), impossible identify p1 \strong" (i.e., benzene0ring (s1 ) = 0),
considering qualitative correlations among related data makes possible although
possibility 0:02.
mentioned before, f1 w1 reference values, f1 @pb1 = 1,
w1 @pb1 = 1.
Suppose priorities f1 , s1 w1 2, 1 1 respectively, possibility
p1 identified pb1 is:
1 = pb1 @p1 =

2 2 1 + 0:02 + 1
= 0:755:
4

5.4.2 Case II: Considering Second Kind Related Data

process considering second kind related data quite similar.
got possibility p1 created benzene-ring 1 (1 = 0:755).
Suppose benzene-ring create peaks: fpb1 , pb2 , ..., pbm g, peaks
related other. p1 created benzene-ring, Sp partially created
benzene-ring, i.e., benzene-ring contained unknown spectrum; Sp
partially created benzene-ring, 0 1 peaks benzene-ring
also identified.
using procedure obtaining 1 , get 2 , 3 , ... well.
According method, qualitative correlation two related peaks, pi pj ,
defined as:
ci (pj ) =

(

j 0:5
j < 0:5:

1
0


SCFi =

1+

Pm

j =1;j 6=i ci (pj )



;

0 < SCFi 1:

Let = 1,

4di = 2mm0 1 2 SCFi ;

0 < 4di < 2;


pi @benzene 0 ring = 1 0

1 0
4di ;
136

pi @benzene 0 ring 1:

fiUsing Qualitative Hypotheses Identify Inaccurate Data
Roughly, SCFi > 0:5, related peaks tend support pi . related peaks
support pi , 4di > 1. 4di > 1, pi @benzene 0 ring > .
Table 2 shows relation among pi @benzene 0 ring, 4di .
pi @benzene 0 ring

4di

1.3
1.1
1
0.9
0.7

1
1
1
1
1
1

0.8
0.846
0.818
0.8
0.778
0.714


0.5
0.615
0.545
0.5
0.444
0.286

0.3
0.462
0.364
0.3
0.222
0

0
0.231
0.091
0
-0.111
-0.429

Table 2: Relation among pi @benzene 0 ring, 4di
example, SCF1 = 0:850, 4d1 = 1:658,
p1 @benzene 0 ring = 1 0

1 0 0:755
= 0:852:
1:658

Therefore, possibility p1 identified pb1 increases 0:755 0:852 due
qualitative correlations among related peaks. process similar probability
propagation probabilistic reasoning. identifying p1 hypothesis, qualitative
correlations among related data p1 pieces evidence.
peaks benzene-ring identified, possibility benzenering contained Sp finally calculated employing method described
Section 5.4.1.

5.5 Analysis Experimental Results
compare two methods experiments. first method (called \AF ") conventional fuzzy method used similar systems (Clerc, Pretsch, & Zurcher, 1986;
Wythoff, Buck, & Tomellini, 1989). use AF , reference value must associated
fuzzy interval dealing inaccuracy. reference values fuzzy intervals
empirically determined (Colthup, Daly, & Wiberley, 1990).
Table 3 lists reference values fuzzy intervals used AF .
137

fiZhao & Nishida

2960 6 15cm01
2870 6 15cm01
1450 6 10cm01
...
benzene 0 ring 3055 6 25cm01
1645 6 10cm01
1550 6 30cm01
1450 6 3cm01
...
0CH2 0 OH 3635 6 5cm01
3550 6 25cm01
...

CH3

strong 6 0:3
sharp 6 1
strong 6 0:3
sharp 6 1
medium 6 0:3 sharp 6 0:5
strong 6 0:3
medium 6 0:3
medium 6 0:3
medium 6 0:3

sharp 6 1:5
sharp 6 0:5
sharp 6 1
sharp 6 0

strong 6 0:3
strong 6 0:3

broad 6 1
sharp 6 1

Table 3: reference values fuzzy intervals
membership function AF is:

r (d) = maxf0; 1 0

j 0 r j g;
4d

measured data item, r reference value, 4d fuzzy interval r,
0 r (d) 1.
second method (called \AF 3 ") proposed method. AF 3 uses reference values fuzzy intervals AF , fuzzy intervals AF 3 used
standard fuzzy intervals based dynamic shift intervals determined considering qualitative correlations among related data.
AF AF 3 use reference values empirical fuzzy intervals. formula
calculating membership degrees AF (i.e., r (d) = maxf0; 1 0 jd40drj g) also similar
jd 0r j
formula calculating possibility AF 3 (i.e., = 1 0 i4dijp ). However, AF , 4d
simply empirical fuzzy interval, AF 3 , 4di dynamic shift interval based
qualitative correlations among related data.
tested system several hundred real infrared spectra organic
compounds. experimental results show AF 3 significantly better AF .
Table 4 lists part experimental results first column indicates
solutions obtained AF ; second column indicates solutions obtained AF 3 ;
third column shows correct solutions.
138

fiUsing Qualitative Hypotheses Identify Inaccurate Data

AF (Without SCF)

2/3

CH2

CH3

CH2

C

AF* (With SCF)

[CH2]n

CH2

CH3

[CH2]n

CH2

CH3 [CH2]n

CH2

CH3

C

CH2

CH3

CH3
CH2

CH3

CH3
CH2

CH

CH3

CH3
CH2

CH3

CH3

CH2

C

CH3

CH2

CH

CH3

CH2

1/3

>C=CH

4/5

C=CH

CH2

CH3

>C=CH

1/2

3/4

CH2

C

Cl
Cl

CH3

NH2

CH3

CH3

CH3
>C=CH

2/2

CH2

CH3

CH3

2/3

CH2

CH3

CH2

CH3

2/3

CH3

>C=CH

CH3

>C=CH

[CH2]n

C=CH

CH2

CH3

CH3

CH3

C=C

C

NH2

>C=CH

CH2

CH3

>C=CH

>C=CH

CH[CH3]2

CH2

CH3

C

CH

CH3

CH[CH3]2

CH[CH3]2
2/3

CH2

CH2

CH2

CH

CH3

[CH2]n C=CH
>C=CH

CH3

CH3

CH3

CH3

[CH2]n

C

CH

CH3

CH3
2/3

CH2

CH3

CH3
3/4

CH

C
CH3

CH3

CH3
2/3

Correct Solutions

Cl

CH2

CH3

C=C

C

Cl
C

CH3

Cl
Cl

C

NH2

: identified PC set PC set correct solution(in case, RI=1)
n

: identified PC set PC set correct solution(the number indicates RI)

Table 4: Experimental results AF AF 3
139

fiZhao & Nishida
two important standard metrics evaluating solutions infrared spectrum
interpretation:

Definition 5.1 Rate correctness (RC): rate identified partial component set
exactly partial component set correct solutions.
Definition 5.2 Rate identification (RI): rate partial components
correct solutions identified.
Table 5 shows comparison AF AF 3 two standard metrics.
RC (error-rate) RI (error-rate)
AF
0.455
(0.545)
0.812
(0.188)
AF 3
0.736
(0.264)
0.894
(0.106)
Table 5: Evaluation AF & AF 3 RC RI

Table 5 demonstrates RC RI increase integrating SCF ,
RC increases significantly. reason although AF identify partial
components unknown compounds, rate identify partial components
unknown compounds low always partial components whose
measured peaks seriously shift reference values.

5.6 Comparison Related Systems
Related systems mainly fall following four categories: (1) Systems based Y/N
classification, (2) Systems based fuzzy logic, (3) Systems based pattern recognition,
(4) Systems based neural networks.
5.6.1 Systems Based Yes/No Classification

method commonly used spectroscopists practice numerical analysis (Colthup,
Daly, & Wiberley, 1990). Numerical analysis primarily based comparison spectral data reference values. Reference values usually regions like f requency :
3615 6 5cm01 strength : 1:000 6 0:300. spectral data certain regions, answer
classification yes; otherwise, answer no.
systems interpreting infrared spectra use method (Hasenoehrl, Perkins, &
Griths, 1992; Puskar, Levine, & Lowry, 1986; Wythoff, Buck, & Tomellini, 1989).
example, Wythoff's system, rules comparing spectral data following forms.
PEAK(S)

FREQUENCY:1700-1707
WIDTH:SHARP BROAD

STRENGTH:0.7-1.0

ANSWER -YESACTION - ***

advantage systems easy develop
directly use spectroscopic knowledge, need computation. However,
problem systems applicable class compounds,
pure compounds case seriously inaccurate spectral data, reference
values (regions) ect inaccuracy. example, Hasenoehrl's system
140

fiUsing Qualitative Hypotheses Identify Inaccurate Data
distinguishing compounds containing least one carbonyl functionality
compounds, although RI system 98% (naturally, RC available),
Puskar's system identifying hazardous substances.
fact, spectroscopists also use qualitative analysis specific cases addition
formal spectroscopic knowledge, \if peaks 600 cm01 - 900 cm01 look like
peaks benzene-rings, peaks 3000 cm01 - 3100 cm01 quite likely
created benzene-ring". Unfortunately, qualitative analysis hardly applied
systems since used usual ways. contrast, system successfully
use qualitative analysis like spectroscopists. way using method proposed
paper. result, system applicable compounds exhibit high
performance respect correctness.
5.6.2 Systems Based Fuzzy Logic

Since spectral data always inaccurate, representation spectroscopic knowledge
quite like fuzzy logic, systems naturally use fuzzy logic techniques
similar fuzzy logic (Clerc, Pretsch, & Zurcher, 1986). systems, fuzzy intervals
similar regions described Section 5.6.1 given reference values,
memberships inaccurate data calculated basis degrees
inaccurate data fuzzy intervals. systems better described
Section 5.6.1 cases, degrees inaccurate data fuzzy intervals
necessarily ect possibility inaccurate data reference values.
example, Figure 7, dicult determine peak closer reference value
considering degrees peak peak b fuzzy interval.
peak

peak b

reference value
(fuzzy interval)

Figure 7: Two peaks fuzzy interval
However, applying method proposed paper, problem
easily solved. discussed Section 5.6.1, practice spectroscopists also frequently
use knowledge correlations among peaks addition formalizable spectroscopic
knowledge. kind knowledge essential method enables us use
qualitative correlations among related data evidence identification inaccurate
data.
compared fuzzy method used systems method Section
5.5. far know, RC system highest among similar systems,
RI system higher systems.
5.6.3 Systems Based Pattern Recognition

systems use pattern recognition techniques interpret infrared spectra (Jalsovszky &
Holly, 1988; Sadtler, 1988), Sadtler popular commercial system.
141

fiZhao & Nishida
system compares known patterns unknown ones, determines possibility
unknown pattern known one calculating quantitative similarity closeness
two patterns.
Unlike fuzzy techniques, pattern recognition considers group data (i.e., pattern)
time. However, pattern recognition primarily based quantitative analysis.
discussed many cases especially inaccuracy spectral data
slight, qualitative features spectral data much important quantitative ones.
example, Figure 8 shows two simple cases. difference two patterns
(a) smaller (b). viewpoint Sadtler, two patterns (a)
closer (b). However, two patterns (b) may
cases, two patterns (a) may case. reason
qualitative features (frequency positions peaks) two patterns (a) different.
pattern 2
difference

pattern 1

pattern 2
pattern 1

(a)

difference
(b)

Figure 8: Quantitative differences patterns
quantitative similarity closeness always sound, systems based
pattern recognition including Sadtler give concrete solutions. general,
solutions systems series candidates users finally
decide possible one themselves. dicult compare systems
solutions systems quite loose, neither RC RI
available. Sadtler, example, usually gives list known patterns associated
values quantitative differences unknown patterns known
ones.
5.6.4 Systems Based Neural Networks

Recently, neural networks applied infrared spectrum interpreting systems
(Anand, Mehrotra, Mohan, & Ranka, 1991; Robb & Munk, 1990). Anand's system,
neural network approach used analyze presence amino acids protein molecules.
specific classification, RI Anand's system 87%, RC
available. Robb's system, linear neural network model developed interpreting
infrared spectra. system general purpose like system. Without prior input
spectrum-structure correlations, RC Robb's system equal 53.3%.
Although RC RI system higher two systems,
still think using neural networks promising, especially model training
system learning must. research concerning applying neural networks
system left future.
142

fiUsing Qualitative Hypotheses Identify Inaccurate Data
6. Related Work Discussion

Identifying inaccurate data long regarded significant dicult problem
AI. Many methods techniques proposed.
Fuzzy logic provides mathematical fundamentals representation calculation
inaccurate data (Bowen, Lai, & Bahler, 1992; Negoita & Ralescu, 1987; Zadeh, 1978).
method primarily based fuzzy theory. compared conventional fuzzy
techniques, advantages method include: (1) fuzzy intervals inaccurate data
dynamically determined dynamic information used; (2) fuzzy intervals
based qualitative features data qualitative correlations among related data
solutions robust. limitation method qualitative
correlations among related data known advance, method degenerates
conventional fuzzy method. instance, SCF unavailable, two methods described
Section 5.5 become same.
Pattern recognition provides techniques interpreting measured data group
(Jalsovszky & Holly, 1988). pattern recognition methods, related data connections
among data considered. However, two preconditions must satisfied
complex data analysis pattern recognition successful. first precondition
obtain adequate data bases derive patterns
need recognize, second precondition demonstrate
suitable metrics similarity patterns. patterns explicitly exist,
measured patterns seriously noisy (e.g., fingerprint recognition), pattern recognition
methods effective. However, patterns explicit, patterns change irregularly
implies stable metrics determining similarity
patterns (e.g., spectrum interpretation), method practical robust.
identifying inaccurate data, roles \di @Rj " \Rj @M D" quite similar
role subjective statements prior probabilities systems (Duda, Hart,
& Nilsson, 1976; Shortliffe & Buchanan, 1975). However, essential difference
method dynamically calculates values \di @Rj " \Rj @MD" qualitative
correlations among related data need many assumptions beforehand,
avoid inconsistency knowledge data bases. method also handle
possibility propagation among inference networks. Readers may noticed
process considering second kind related data spectrum interpretation (see Section
5.4.2).
statistical samples sucient, subjective statements consistently obtained, probabilistic reasoning methods applied inaccurate data identification.
statistical samples inaccurate data enough consistent subjective statements available, method effective.
ongoing research related probabilistic reasoning consider interaction
among identified partial components. discussed before, spectroscopists frequently
use knowledge \if C6 H6 coexists CH3 , peaks CH3 around
2900 cm01 may shift", \if -C-O-C- identified, strength peaks
CH3 may change". Therefore, possible update possibilities identified partial
components considering interaction among them. Using probabilistic reasoning
analyze effects among identified partial components would help us identify
143

fiZhao & Nishida
inaccurate data, also provide us reason data inaccurate.
research experiments subject sequel paper.
7. Conclusions

paper, presented new method identifying inaccurate data
basis qualitative correlations among related data. first introduced new concept
called support coecient function (SCF ). Then, proposed approach determining
dynamic shift intervals inaccurate data based SCF , approach calculating
possibility identifying inaccurate data, respectively. also presented algorithm
using qualitative correlations among related data confirmatory disconfirmatory
evidence identification inaccurate data. developed practical system
interpreting infrared spectra applying proposed method, fully tested
system several hundred real spectra. experimental results show
proposed method significantly better conventional methods used many similar
systems. paper also described system experimental results.
Brie y, novel work includes:
1. method assumes inaccurate data item certain reference value
basis qualitative correlations inaccurate data item
related data.
2. algorithm crystallizes method.
3. practical system uses algorithm interpret infrared spectra.
Acknowledgments

Thanks editors anonymous reviewers JAIR helpful comments
suggestions, Chunling Sui Mitchell Bradt proofreading manuscript.
research partially supported Horiba Ltd., Kyoto, Japan, first author wishes
thank ASTEM Research Institute, Kyoto, Japan, worked researcher
1991 - 1994.
References

Anand, R., Mehrotra, K., Mohan, C. K., & Ranka, S. (1991). Analyzing Images Containing
Multiple Sparse Patterns Neural Networks. Proceedings IJCAI-91, pp. 838-

843.

Bowen, J., Lai, R., & Bahler, D. (1992). Lexical Imprecision Fuzzy Constraint Networks.
Proceedings AAAI-92, pp. 616-621.
Clerc, J. T., Pretsch, E., & Zurcher, M. (1986). Performance Analysis Infrared Library
Search Systems. Mikrochim. Acta [Wien], II, pp. 217-242.
Colthup, L., Daly, H., & Wiberley, S. E. (1990). Introduction Infrared Raman Spectroscopy. Academic Press.
144

fiUsing Qualitative Hypotheses Identify Inaccurate Data
Dempster, A. P. (1968). Generalization Bayesian Inference. Journal Royal Sta-

tistical Society, B-30, pp. 205-247.

Duda, R. O., Hart, P. E., & Nilsson, N. J. (1976). Subjective Bayesian Methods RuleBased Inference Systems. Proceedings National Computer Conference, pp. 1075-

1082.

Hasenoehrl, E. J., Perkins, J. H., & Griths, P. R. (1992). Expert System Based Principal Components Analysis Identification Molecular Structures VaporPhase Infrared Spectra. Journal Anal. Chem., 64, pp. 656-663.
Jalsovszky, G. & Holly, G. (1988). Pattern Recognition Applied Vapour-Phase Infrared
Spectra: Characteristics vOH Bands. Journal Molecular Structure, 175, pp.

263-270.

Negoita, C. V. & Ralescu, D. (1987). Simulation, Knowledge-Based Computing, Fuzzy
Statistics. Van Nostrand Reinhold Company.
Pearl, J. (1988). Probabilistic Reasoning Intelligent Systems: Networks Plausible Inference. Morgan Kaufmann Publishers.
Puskar, M. A., Levine, S. P., & Lowry, S. R. (1986). Computerized Infrared Spectral Identification Compounds Frequently Found Hazardous Waste Sites. Journal Anal.

Chem., 58, pp. 1156-1162.

Reiter, R. (1987). Theory Diagnosis First Principles. Artificial Intelligence, (87)

32, pp. 57-95.

Robb, E. W. & Munk, M. E. (1990). Neural Network Approach Infrared Spectrum
Interpretation. Mikrochim. Acta [Wien], I, pp. 131-155.
Sadtler Research Laboratories. (1988). Sadtler PC Spectral Search Libraries, Product Introduction & User's Manual.
Shafer, G. (1976). Mathematical Theory Evidence. Princeton Uni. Press.
Shortliffe, E. H. & Buchanan, B. G. (1975). Model Inexact Reasoning Medicine.

Mathematical Biosciences, 23, pp. 351-379.

Wythoff, B. J., Buck, C. F., & Tomellini, S. A. (1989). Descriptive Interactive ComputerAssisted Interpretation Infrared Spectra. Analytica Chimica Acta, 217, pp. 203-216.
Zadeh, L. A. (1978). Fuzzy Set Basis Theory Possibility. Fuzzy Sets Syst., 1,

pp. 3-28.

Zhao, Q. (1994). Ecient Method Solving Constraint Satisfaction Problems IR
Spectrum Interpretation. Proceedings 2nd International Conference Expert

Systems Development, pp. 165-170.

Zhao, Q. & Nishida, T. (1994). Knowledge Model Infrared Spectrum Processing.

Proceedings International Symposium Information Theory Applications, pp. 781-786.
145

fiJournal Artificial Intelligence Research 3 (1995) 25-52

Submitted 8/94; published 6/95

FLECS: Planning Flexible Commitment Strategy
Manuela Veloso
Peter Stone

Department Computer Science, Carnegie Mellon University
Pittsburgh, PA 15213-3891 USA

veloso@cs.cmu.edu
pstone@cs.cmu.edu

Abstract
evidence least-commitment planners eciently handle planning
problems involve dicult goal interactions. evidence led common belief
delayed-commitment \best" possible planning strategy. However, recently
found evidence eager-commitment planners handle variety planning problems
eciently, particular dicult operator choices. Resigned futility
trying find universally successful planning strategy, devised planner
used study domains problems best planning strategies.
article introduce new planning algorithm, flecs, uses FLExible
Commitment Strategy respect plan-step orderings. able use strategy
delayed-commitment eager-commitment. combination delayed eager
operator-ordering commitments allows flecs take advantage benefits explicitly
using simulated execution state reasoning planning constraints. flecs vary
commitment strategy across different problems domains, also course
single planning problem. flecs represents novel contribution planning
explicitly provides choice commitment strategy use planning. flecs
provides framework investigate mapping planning domains problems
ecient planning strategies.

1. Introduction
General-purpose planning long history research Artificial Intelligence. Several
different planning algorithms developed ranging pioneering GPS (Ernst
& Newell, 1969) variety recent algorithms SNLP (McAllester & Rosenblitt,
1991) family. basic level, purpose planning find sequence
actions change initial state state satisfies goal statement. Planners use
actions provided domain representations try achieve goal. However
different planners use different means end.
Faced variety different planning algorithms, planning researchers, including authors, increasingly curious compare different planning methodologies. Although general-purpose planning known undecidable (Chapman, 1987),
common belief least-commitment planning \best," i.e., efficient planning strategy planning problems. belief based evidence
least-commitment planners eciently handle planning problems involve dicult
plan step interactions (Barrett & Weld, 1994; Kambhampati, 1994; Minton, Bresina, &
Drummond, 1991). Delayed commitments, particular step orderings, allow plan

c 1995 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiVeloso & Stone

steps remain unordered interactions visible.1 similar situations, eagercommitment planners may encounter severe eciency problems early commitments
incorrect orderings.
Recently engaged investigation sorts planning problems would
handled eciently planning strategies. Since planning driven heuristics,
identified different sets heuristics correspond different planning methods.
designed sets planning domains problems test different planning strategies.
studying impact different strategies different kinds planning problems,
came across evidence eager-commitment planners eciently handle variety
planning problems, particular dicult operator choices (Stone, Veloso,
& Blythe, 1994). up-to-date state allows make informed planning choices,
particularly terms operator alternatives available. similar situations, delayedcommitment planners may need backtrack incorrect operator choices (Veloso &
Blythe, 1994). came believe planner consistently better others
across different domains problems.
Resigned futility trying find universally successful planning strategy,
felt need study domains problems best suited planning
methods.2 order so, devised implemented planner use
operator-ordering commitment strategy along continuum between, one extreme
delayed commitment, other, eager commitment. planner completely
exible along one dimension planning heuristics: operator-ordering commitments.
main contribution paper completely describe planning algorithm
put forth tool studying mapping heuristics domains problems.
Rather risking possibility planner might get overlooked
relegated \architecture" section future paper, present flecs underlying
philosophy contribution right.
continuum heuristics explored planning algorithm lies
operator-ordering commitment strategies delayed-commitment eager-commitment
backward-chaining planners, situate within broad range planning
problem solving methods. One possible planning strategy search possible states
reached initial state find one satisfies goal. method,
called progression forward-chaining, impractical. often many
accessible states world eciently search complete state space. alternative, several planners constrain search using regression, backward-chaining.
Rather considering possible actions could executed initial state
searching recursively forward state space, search backwards goal.
search driven set actions directly achieve goal.
two main ways performing backward-chaining. Several planners regression searching space possible plans. Planners, noah, tweak, snlp,
1. Least-commitment planners really delay commitments plan step orderings variable bindings.
Throughout article use term delayed commitment contrast eager commitment
context step orderings.
2. Similar concerns regarding different constraint satisfaction algorithms led recently design
Multi-Tac architecture (Minton, 1993). system investigates given problem find
combination heuristics collection available ones solve problem ecient way.

26

fiflecs: Planning Flexible Commitment Strategy

descendants (Chapman, 1987; McAllester & Rosenblitt, 1991; McDermott, 1978;
Sacerdoti, 1977; Tate, 1977; Wilkins, 1984) plan-space planners use delayedcommitment strategy. particular, delay decision ordering operators long
possible. Consequently, planner reasons initial state set
constraints regressed goal. hand, planners gps,
strips, prodigy family (Carbonell, Knoblock, & Minton, 1990; Fikes & Nilsson,
1971; Rosenbloom, Newell, & Laird, 1990) use eager-commitment strategy.3 use
backward-chaining select plan steps relevant goals. eager-commitment planners make explicit use internal representation state world (their internal
state) order operators possible reason updated version
state. trade risk eager commitment benefits using explicit
updated planning state.
article introduce planning algorithm, flecs, uses FLExible Commitment Strategy respect operator orderings. flecs designed provide us
planning researchers framework investigate mapping domains
problems ecient planning strategies. algorithm represents novel contribution
planning introduces explicitly choice commitment strategy.
ability change commitment strategy makes useful studying tradeoffs
delayed eager commitments. flecs descendant prodigy4.0 current
implementation directly top prodigy4.0. extends prodigy4.0 reasoning
explicitly ordering alternatives ability change commitment
strategy across different problems domains, also course single
planning problem.4
article gradually introduces flecs. Section 2 gives top-level view algorithm
describes different ways flecs makes use uniquely specified state
world. Section 3 introduces concepts used flecs algorithm. provide
annotated example illustrate details planning concepts defined. Section 4
presents flecs's planning algorithm full detail explains algorithm step step.
discuss different heuristics guide flecs's choices, particular exible choice
commitment strategy. analyze advantages disadvantages delayed eager
plan step ordering commitments. Section 5 shows specific examples planning domains
problems devised, support need use flecs's exible commitment
strategy. performed empirical analysis planning performance domains.
corresponding empirical results demonstrate tradeoffs discussed show evidence
exible commitment necessary. Finally Section 6 draws conclusions work.
3. Planners prodigy family include prodigy2.0 (Minton, Knoblock, Kuokka, Gil, Joseph, & Carbonell, 1989), NoLimit (Veloso, 1989), prodigy4.0 (Carbonell, Blythe, Etzioni, Gil, Joseph, Kahn,
Knoblock, Minton, Perez, Reilly, Veloso, & Wang, 1992). NoLimit prodigy4.0, opposed
prodigy2.0, require linearity assumption goal independence search spaces
complete (Fink & Veloso, 1994). also control commitment choices opposed
earlier total-order planners.
4. found needed new name algorithm flecs represents significant change
philosophy implementation prodigy4.0.

27

fiVeloso & Stone

2. Top-Level View flecs
prodigy4.0 flecs differ significantly state-of-the-art planning systems

search solution planning problem combining backward-chaining (or
regression) simulation plan execution (Fink & Veloso, 1994). back-chaining,
commit total-ordering plan steps make use uniquely specified
world state. planners maintain internal representation state update
simulating execution operators found relevant goal backward-chaining. Note
simulating execution planning differs interleaving planning execution,
since option \un-simulating," rolling back, must remain open. Interleaved planning
execution generally done separate modules planning, monitoring, executing,
replanning (Ambros-Ingerson & Steel, 1988). flecs either delay eagerly carry
plan simulation. way, planning algorithm exibility
able delay operator-ordering commitments able use effects previously
selected operators help determine goals plan next operators
use achieve goals. short, emulate delayed-commitment planners
eager-commitment planners.
Table 1 shows top-level view flecs algorithm.
1. Initialize.
2. Terminate goal statement satisfied.
3. Compute pending goals applicable operators.
Pending goals yet-to-be-achieved preconditions operators
selected plan.
Applicable operators preconditions satisfied
current state.
5. Choose subgoal apply: (backtrack point)
subgoal, go step 6.
apply, go step 7.
6. Select pending goal (no backtrack point) operator achieve (backtrack point); go step 3.
7. Change state specified applicable operator (backtrack point); go step 2.
Table 1: top-level view flecs. step numbers made correspond
step numbers detailed version algorithm presented Table 2
(Section 4), refines steps adds additional necessary step 4.
terms used table fully described along detailed version
algorithm Section 4. section focus two main characteristics algorithm,
namely use internal state exibility respect commitment strategies.
28

fiflecs: Planning Flexible Commitment Strategy

2.1 Use Simulated Planning State
flecs uses internal state least four purposes. First, terminates every goal

given problem satisfied current version state (the current state):
point, complete plan (the sequence operators transformed initial state
current state) created planning process stop. Second, every
cycle, algorithm uses internal state determine goals need planned
already achieved following means-ends analysis strategy. Unlike
planners analyze possible effects operators may
changed initial state, flecs simply checks particular goal true current
state.5 Third, planner uses state determine operators may applied:
i.e., whose preconditions true state. Fourth, flecs use state
choose operator bindings likely achieve particular goal
minimum planning effort (Blythe & Veloso, 1992). summary, reference
algorithm Table 1, flecs uses state determine:






goal statement satisfied (step 2);
goals still need achieved (step 3);
operators applicable (step 3);
operators try first planning (step 6).

planners keep internal state, four steps require considerable
planning effort even attempted all. contrast, flecs perform
steps sub-quadratic time. Furthermore, planners particular
methods choosing among possible operators achieve goal. particular use
state shown provide significant eciency gains prodigy4.0 (Veloso & Blythe,
1994).
Since flecs use state, makes big difference whether chooses
change state (apply operator) given time. advantage applying operator
informed planning results four steps. However,
choice apply operator involves commitment order operator operators yet applied. commitment temporary since plan
found operator position, operator \un-applied" simply
changing internal state back previous status. One may argue requirement operators applied explicit order opens possibility exponential
backtracking. However argument vacuous, planning undecidable (Chapman,
1987). Due use state, flecs reduce likelihood requiring backtracking
operator choice point. doing, may increase likelihood backtracking
operator-ordering choice point. However, exibility able come
either side tradeoff.
5. Note since goal state fully instantiated, matching accomplished
constant time goal using hash table literals.

29

fiVeloso & Stone

2.2 Choice Commitment Strategies

order control tradeoff eager delayed state changes, flecs
toggle determines whether algorithm prefers subgoaling applying operator
step 5. option flecs considers first may affect path search space
consequently planning eciency. ability accommodate different types
search novel part algorithm. significance lies difference
subgoaling applying.
difference subgoaling applying illustrated Figure 1. Subgoaling
best understood regressing one goal, backward chaining, using means-ends
analysis. includes choices goal plan operator achieve goal.
seen Section 2.1, choices affected flecs's internal state. Thus,
subgoaling without ever updating internal state (applying operator) lead
uninformed planning decisions. hand, subgoaling extensively, flecs
select large set operators appear plan deciding order
apply them. flecs takes account con icts, \threats," among operators
orders appropriately applying them.
x




C

z

G



x



x




z

C




G



C



z

G

Subgoaling

Applying

Operator achieves precondition
operator true state C.

preconditions operator x true state C.
Applying x changes state C.

Figure 1: diagram (Fink & Veloso, 1994) illustrates difference subgoaling applying. search node consisting \head-plan" \tailplan." head-plan contains operators already applied
changed initial state \I" current state \C." tail-plan consists
operators selected achieve goals goal statement \G"
operators selected achieve preconditions operators,
etc. figure shows planner could either subgoal apply given
search node.
Applying operator flecs's way changing current internal state
future subgoaling decisions informed. However, applying operator commitment (temporary since backtracking possible) operator executed
30

fiflecs: Planning Flexible Commitment Strategy

other. essential tradeoff eagerly subgoaling eagerly
applying: eagerly subgoaling delays ordering commitments (delayed commitment),
eagerly applying facilitates informed subgoaling (eager commitment).
flecs switch (toggle) change behavior eager subgoaling
eager applying vice versa time. feature significant improvement flecs prodigy4.0 predecessors. Since saw evidence neither delayed-commitment eager-commitment search strategies consistently effective (Stone et al., 1994), felt need provide flecs toggle. Thus, flecs
combine advantages delayed commitments eager commitments.6

3. Illustrative Example

section present example illustrates detail planning situations
arise general planning problem. Although planning may well understood
general, past descriptions planning algorithms directly addressed
situations full detail. flecs algorithm designed handle situations.
order describe flecs completely, need define several variables
maintained algorithm proceeds. Since much easier understand algorithm
one familiar concepts variables denote, present annotated
example Figures 2 9 formally presenting flecs. recommend
following variables functions C , G , P , O, A, a, c change throughout
annotated example, according definitions:
C represents current internal state planner. uses summarized
Section 2.1.
G set goals subgoals planner aiming achieve.
goals fringe subgoal tree. Goals G may goals
yet planned for, goals achieved (perhaps trivially) yet
used operator needs one preconditions (i.e., operator
applied yet).
P set pending goals: goals G may need planned current
state.
stands set instantiated operators selected achieve goals
subgoals.
set applicable operators: operators whose preconditions satisfied
current state needed current state achieve goal.
goal G, a(G) set ancestor goal sets { sequences goals
caused G become member G . Trivially, goal ancestor
preconditions operator selected achieve goal. a(G) set sets
G different sets ancestors. concept become clearer
example.
6. Section 5 discuss different heuristics guide choice discuss view toggle
perfect focus learning.

31

fiVeloso & Stone

operator O, c(O) set goals selected achieve { causes.
Applying establishes member c(O). illustrated below, functions
c needed determine goals pending operators
applicable. analogous causal links used determine threats
planners (Chapman, 1987; McAllester & Rosenblitt, 1991).

sequence planning decisions example (Figure 2 Figure 9) designed illustrate uses flecs's variables functions. recommend
becoming familiar spending time carefully tracing values returning definitions throughout example. Note figures show
tail-plan mention applied operators state changes text. Goals
circles: solid circles true dashed circles true current
state. Operators boxes arrows pointing goals \produce,"
i.e., goals operators selected achieve (their causes). turn,
preconditions operators goals arrows pointing operators
\consume" them. Operators applicable current state appear bold boxes.
Changes functions c underlined captions.
present example. Figure 2 shows initial planning situation,
consider planning problem three literals goal statement, G1 , G2, G3 , i.e.,
G = fG1; G2; G3g. one literal initial state, G7, i.e., C = fG7g. none
goals true initial state, P = G . operators selected, i.e., = ;,
therefore also operators applicable, i.e., = ;. point, since
top-level goals, none goals ancestors: a(G1) = a(G2) = a(G3) = ;.
applicable operators, next step must subgoal one pending goals.

C = fG7g
G = fG1; G2; G3g
O=;
P = fG1; G2; G3g
A=;

G

G

G

1

2

3

Figure 2: example: initial specification planning situation.
Figure 3 shows planning situation flecs subgoals G1 G2 . Suppose
operator O1 , preconditions G6 G7 , selected achieve G1, O2 chosen
achieve G2 indicated below. Note operators' preconditions replace
causes set fringe goals G ; since G7 true current state, included
set pending goals P . G1 cause O1, c(O1) = fG1g; similarly,
32

fiflecs: Planning Flexible Commitment Strategy

c(O2) = fG2g. new goals nonempty ancestor sets: a(G6) = a(G7) = ffG1gg,
a(G4) = ffG2gg. still applicable operators: O1 cannot applied
G6 62 C O2 cannot applied G4 62 C . Therefore, flecs subgoals again.

C = fG7g
G = fG3; G6; G7; G4g
= fO1; O2g
P = fG3; G6; G4g
A=;
G

G

G

7

6

4





1

2

G

G

G

1

2

3

Figure 3: Resulting planning situation subgoaling G1 G2 .
Figure 4 shows planning situation flecs subgoals G3 . Suppose
operator selected achieve G3 preconditions G4 G5 . c(O3) = fG3 g,
a(G5) = ffG3gg. causes operators O1 O2 change, c(O1) = fG1g
c(O2) = fG2g previous step. Similarly, a(G6 ) a(G7) remain unchanged.
However, G4 two sets ancestor goals: a(G4) = ffG2g; fG3gg. understand
need keep ancestor sets, consider possibility G2 could achieved
unexpectedly side-effect unrelated operator instead achieved O2
planned for. case, G4 would remain pending goal since would needed
achieve G3. Again, since applicable operators, flecs must subgoal one
pending goals, i.e., G6, G4, G5.

C = fG7g
G = fG6; G7; G4; G5g
= fO1; O2; O3g
P = fG6; G4; G5g
A=;
G

7

G

G

G

6

4

5







1

2

3

Figure 4: Resulting planning situation subgoaling G3 .
33

G

G

G

1

2

3

fiVeloso & Stone

Figure 5 shows planning situation flecs subgoals G4 . Suppose O4
| operator precondition G7 | selected achieve G4 . Since G7 true
current state, O4 first applicable operator. Note necessarily ordered
O2 O3 since cause precondition operators. usual, cause
new operator stored: c(O4) = fG4 g. addition, ancestors G7 must augmented
include two new ancestor sets: a(G7) = ffG1g; fG4; G2g; fG4; G3gg. Although
applicable operator, let us assume flecs chooses delay commitment
order O4 first step plan subgoals pending goal.

C = fG7g
G = fG6; G7; G5g
= fO1; O2; O3; O4g
P = fG6; G5g
= fO4g
G

7

G



4

G

G

6

4

5







G

1

G

2

G

3

1

2

3

Figure 5: Resulting planning situation subgoaling G4 .
Figure 6 shows planning situation flecs subgoals G5 . Suppose operator O4 also achieve G5 selected so. need update
causes operator ancestors precondition: c(O4) = fG4; G5g
a(G7) = ffG1g; fG4; G2g, fG4; G3g; fG5; G3gg. rather subgoaling last remaining pending goal (G6), let us apply O4 . Note decision corresponds early
commitment terms ordering operators O1 , O4, operators later selected
achieve G6 unordered current planning constraints. flecs changes
delayed-commitment strategy eager-commitment strategy.
C = fG7g
G = fG6; G7g
G
6
G

= fO1; O2; O3; O4g
1
1
P = fG6g
= fO4g
G

7



4

G

G

4

5





2

3

G

G

Figure 6: Resulting planning situation subgoaling G5 .
34

2

3

fiflecs: Planning Flexible Commitment Strategy

Figure 7 shows planning situation flecs applied O4 . Since operator O4
applied order achieve goals G4 G5, true current state
back fringe goal tree, i.e., C G . Notice stay G
eventually \consumed" O2 O3. However, since true
current state, pending goals. Since G7 precondition
one selected operator, a(G7) = ffG1gg before. O2 O3 applicable
preconditions true current state thanks O4. Let us assume
flecs maintains eager-commitment strategy continues applying applicable operators. flecs orders O2 O3, since O3 deletes precondition O2 (effects
shown).
C = fG7; G4; G5g
G = fG6; G7; G4; G5g
G
= fO1; O2; O3g

6
G
1
1
P = fG6g
= fO2; O3g
G

7

G

G

4

5





2

3

G

G

2

3

Figure 7: Resulting planning situation applying O4 Figure 6.
Figure 8 shows planning situation flecs applied O2. Suppose that, although
selected so, operator O2 achieves G1 side-effect. Perhaps O2
conditional effect visible planner, perhaps O1 simply looked
promising O2 operator achieve G1 time selected.

C = fG7; G4; G5; G1; G2g
G = fG6; G7; G4; G5; G2g
= fO1; O3g
P=;
= fO3g
G

7

G

G

G

6



1

G

4

5

G



3

G

1

2

3

Figure 8: Resulting planning situation applying O2 Figure 7.
35

fiVeloso & Stone

case, G1 C planning done longer needed: G6 longer
pending goal, since sole ancestor already C . fortuitous achievement goal
reason need use functions c adjust sets pending goals
P applicable operators A: would wasted effort flecs plan achieve G6.
Note G6 precondition O3 well O1, would pending goal since
would still relevant achieving G3 . point, ancestors G4 must
reset: a(G4) = ffG3gg. Since pending goals, flecs must apply
last remaining applicable operator, O3.
Figure 9 shows final planning situation flecs applied O3 . point
top level goals true current state. Despite fact planning
tree remains, flecs recognizes work done terminates.
final plan O4, O2, O3 , sequence operators applied head-plan (not
shown) corresponding steps Figures 7, 8, 9. posteriori algorithm (Veloso,
Perez, & Carbonell, 1990) convert sequence partially ordered plan capturing
dependencies: O4 ; fO2; O3g.

C = fG7; G4; G5; G1; G2; G3g
G = fG6; G7; G2; G3g
= fO1g
P=;
A=;
G

G

6



1

G

G

7

G

1

2

3

Figure 9: Final planning situation applying O3 Figure 8.

4. FLECS: Detailed Description
Aside variables functions introduced preceding section, need
define four things presenting complete algorithm. First, Initial State
Goal Statement corresponding ground literals problem definition. Second, given operator O, pre(O), add(O), del(O) instantiated preconditions,
add-list, delete-list respectively. flecs takes values straight domain representation, may include disjunctions, negations, existentially universally quantified preconditions effects, conditional effects (Carbonell et al., 1992).
conditional effects, add(O) del(O) determined dynamically, using state
time applied. Third, \relevant instantiated operators could achieve G"
(step 6) instantiated operators (operators fully-specified bindings)
36

fiflecs: Planning Flexible Commitment Strategy

G 2 add(O) G positive goal G 2 del(O) G negative goal. Fourth, toggle
variable determines avor search, described later.

4.1 Planning Algorithm
present flecs planning algorithm full detail Table 2.7 examining algorithm, notice fringe goals G , selected operators O, ancestor function a(G),
cause function c(O), current state C maintained incrementally.
hand, pending goals P , applicable operators A, toggle recomputed every
pass algorithm.
Step 1 initializes variables. beginning planning process,
goals G goal statement, current state C initial
state, since operators yet selected, empty. ancestor function
cause function c initialized constant function maps everything ;.
practice, domain set goals domain c set operators
appear problem. However, since goals operators
determined algorithm first called, must initialize functions
unrestricted domains.
Step 2 termination condition. called time new operator
applied. algorithm terminates successfully every goal G goal statement true,
satisfied, current state C , i.e., G 2 C .
step 3, sets pending goals applicable operators computed based
current state. Pending goals goals planner may need plan for. Initially,
pending goals fringe goals currently true true
initial state.8 applicable operators selected operators whose preconditions
true state.
Then, step 4 computes pending goals P applicable operators active
current state. pending goal active long fringe subgoal tree
still needs planned for. goal longer active every one ancestor sets
least one goal already achieved: purposes goal
selected longer exist (as case G6 Figure 8). applicable operator
active current state long would achieve goal still useful plan.
applicable operator longer active causes either true current
state longer active.
Step 5 novel part algorithm. allows exible search strategy
within single planning algorithm. Since step, flecs yet terminated,
must either active pending goals active applicable operators, i.e., P must
non-empty. However, one other, choice
made. If, hand, P non-empty, either proceed
step 6 step 7. sake completeness, must keep options open;
option flecs considers first may affect amount search required. changing
7. detail algorithm allows reader carefully study re-implement flecs.
8. Since planner cannot backtrack beyond initial state, must keep goals initial state
pending goals sake completeness.

37

fiVeloso & Stone

1. Initialize:
C : current state
a. G = Goal Statement.
G : fringe goals
b. C = Initial State.
P : pending goals
c. = ;.

: instantiated operators
d. 8G:a(G) = ;.

: applicable operators
e. 8O:c(O) = ;.
a: ancestor goal sets
c: causes
2. Terminate Goal Statement C .
3. Compute applicable operators pending goals P :
a. P = fG 2 G j G 62 C _ G 2 Initial Stateg.
b. = fA 2 j pre(A) Cg.
4. Adjust P contain active members:
a. P = P , fP 2 P j 8S 2 a(P ):9G 2 s.t. G 2 Cg.
b. = , fA 2 j 8G 2 c(A):[(G 2 C ) _ (8S 2 a(G):9G 2 s.t. G 2 C )]g.
5. Subgoal Apply:
a. Set reset toggle sub app, i.e. Set default delayed eager commitment.
b. = ;, go step 6.
c. P = ;, go step 7.
d. Choose apply subgoal (backtrack point):
toggle = sub ^ P 6 C , subgoal first: go step 6.
toggle = app, apply first: go step 7.
6. Choose goal P P (not backtrack point).
Choose goal true Current State using means-ends analysis.
a. Get set R relevant instantiated operators could achieve P .
b. R = ;
i. P = P , fP g.
ii. P = ; fail (i.e., backtrack).
iii. Go step 6.
c. Choose operator R (backtrack point).
Choose operator minimum conspiracy number, i.e. operator
appears achievable least amount planning.
d. = [ fOg.
e. G = (G , fP g) [ pre(O).
f. c(O) = c(O) [ fP g.
g. 8G 2 pre(O):a(G) = a(G) [ ffP g [ j 2 a(P )g.
h. Go step 3.
7. Choose operator (backtrack point interactions).
Use heuristic find operators fewer interactions { similar one used
SABA heuristic.
a. Apply A: C = (C [ add(A)) , del(A)
b. = , fAg.
c. 8G 2 pre(A):a(G) = a(G) , fS 2 a(G) j \ c(A) 6= ;g.
d. G = (G [ c(A)) , fG 2 pre(A) j a(G) = ;g.
e. c(A) = ;.
f. Go step 2.
0

Table 2: full description flecs.
38

0

fiflecs: Planning Flexible Commitment Strategy

value toggle, done pass loop, flecs change
type search works problem.
pass body algorithm visits either step 6 step 7.
subgoaling (step 6), active pending goal P chosen P . Note unlike
corresponding choice step 7, choice subgoals backtrack point. However,
operators could achieve goal, another goal chosen (step 6b).
Means-ends analysis used heuristic prefer subgoaling goals currently
true. Next, operator chosen could achieve chosen goal (step 6c).
either new operator existing one Figure 6 (O4, already
selected achieve G4, also selected achieve G5). choice operator backtrack
point. Unless heuristic provided, minimum conspiracy number heuristic
used determine operator tried first (Blythe & Veloso, 1992). short,
heuristic selects instantiated operator appears achievable least
amount planning.
returning top loop, affected variables updated. First,
added using set union operator never appears twice (step 6d).
Second, O's preconditions added G , P removed (step 6e): P
operator selected achieve it, longer fringe subgoal tree. Third,
cause augmented include P (step 6f). Fourth, ancestor sets O's preconditions
augmented include sets goals comprised P ancestors (step 6g).
explained Figure 4, ancestor sets must included. Finally, since state
changed all, termination condition cannot met. algorithm returns step 3.
applying operator (step 7), applicable operator chosen A.
heuristic analyzes applicable operators used choose best possible operator. One heuristic analyzes interactions operators identifying
negative threats, similarly saba heuristic (Stone et al., 1994). short,
heuristic prefers operators delete preconditions of, whose effects
deleted by, operators. choice applicable operator backtrack point
orderings interacting applicable operators considered. Different orderings
completely independent operators need considered. Completely independent operators interactions neither among ancestor
sets. Since application one operator make difference application
another, need consider one ordering operators.
chosen, promptly applied (step 7a). application involves changing
current state prescribed A. Note conditional effects, expanded
point. Next, relevant variables updated. First, updating involves removing
set selected operators (step 7b). Second, ancestors A's preconditions
ancestor sets include (step 7c): need
planning. Figure 7 shows example precondition (G7) still
ancestor remaining. Third, since applied, preconditions goals
reason longer fringe, causes (step 7d):
unachieved must re-achieved. Fourth, case ever selected operator
achieve goal, c(A) reset ; (step 7e). Finally, since current state
altered, algorithm returns step 2 termination condition checked.
39

fiVeloso & Stone

4.2 Discussion: Backtracking, Heuristics, Properties
One pay close attention placement backtrack points algorithm.
particular, three: subgoal/apply choice step 5, choice operator
achieve goal step 6, choice applicable operator step 7. However,
choice goal subgoal step 6, backtrack point prodigy
algorithm, backtrack point here. flecs need backtrack point
choice apply apply operator given time left open step 5
significantly different orders applying applicable operators considered step 7.
explained previous subsection, different orderings completely independent operators considered. Nevertheless, orderings could lead solution
considered. Therefore, backtracking choice subgoal would cause redundant
search. elimination backtrack point significant improvement flecs
previous implementations, namely NoLimit prodigy4.0. Note new backtrack
points added offset eliminated backtrack point.
flecs's explicit failure point step 6 occurs algorithm chosen
subgoal, none pending goals relevant operators. failures
implicit. is, backtrack point, choices unsuccessfully tried
algorithm backtracks. presented, algorithm terminates unsuccessfully
entire search space exhausted. causes failure, goal loops,
state loops, depth bounds, time limits, incorporated manner
prodigy4.0 (Carbonell et al., 1992).
choice point, heuristic determine branch try (first).
step 6, goal chosen using means-ends analysis, operator minimum
conspiracy number chosen achieve goal. step 7, choice mechanism
saba heuristic used determine applicable operator try first. step 5,
toggle, changed time, determines whether default commitment
strategy eager subgoaling eager applying. Note pending goals
true Current State (or pending goals), planner may apply
applicable operator regardless value toggle. Similarly, applicable
operators, planner must subgoal even toggle indicates prefer applying. toggle
new variable guide heuristic search existing choice point branching factor
two: represent addition new backtrack point. discussed throughout,
provides flecs ability change commitment strategy. suggested
name, toggle one two values: sub app indicating eager subgoaling eager
applying respectively.
describe domain-independent heuristic could used guide changes
value toggle. heuristic allow eager commitments reason
believe need backtrack resulting operator linearization.
case, setting toggle app increase planning eciency converting
partially-ordered set operators sequence leads single possible state,
used guide subsequent planning. process equivalent starting new
smaller planning problem previous choices embedded state.
situation described similar arises alpine system
constructs ecient abstraction hierarchies (Knoblock, 1994). alpine guarantee
40

fiflecs: Planning Flexible Commitment Strategy

planning hierarchically using generated abstraction hierarchies lead backtracking across refinement spaces. Figure 10 illustrates flecs use abstraction
planning information control value toggle. toggle changes app particular abstract planning step completely refined abstraction hierarchies preserve
alpine's ordered monotonicity property, need backtrack
resulting operator ordering. toggle change back sub, flecs continue
planning updated state information.
Abstraction level
1. Begin
toggle=sub.
S0

3. Continue planning:
toggle=sub.

Build partial
order plan
first step
abstract plan

S0

5. Continue
done...

S1
2. Set toggle=app.
Commit ordering
compute new state.

S1

S2
4. another
step abstract
plan, commit again:
toggle=app.

Figure 10: Using abstraction information guide changes toggle.
abstraction-driven heuristic one method exploiting choice point. Similarly,
minimum conspiracy number heuristic saba heuristic ways
guide choices instantiated operator applicable operator respectively.
heuristics used always changed, claim ones provide
defaults best possible: heuristic work time.
planning algorithm present sound complete searches entire
search space, using technique iterative deepening (Korf, 1985). flecs sound
terminates reached goal statement result applying
operators. is, application operator sequence returned final plan
entirely simulated time planner terminates. Thus preconditions
operator true time operator executed, operators
executed, goal statement satisfied. Consequently, flecs sound.
Since step algorithm prunes search space, flecs iteratively
increasing depth bound also complete: solution planning problem, flecs
find one. insure property, need show flecs consider possible
operators may achieve goal well orderings interacting applicable operators.
flecs maintaining backtracking points choice operator (step 6c)
points operator ordering could affected: choice applicable
operator (step 7) choice whether subgoal apply (step 5d). Selecting
41

fiVeloso & Stone

\apply" commits ordering operators currently applicable least
one currently applicable operators. Note completeness achieved even without
maintaining choice goals subgoal backtrack point (step 6), since regardless
order operators chosen, applied according possible
interactions (i.e., similarly resolving negative threats). Thus flecs's search space
significantly reduced prodigy4.0, still preserving completeness. (See
Appendix formal proofs flecs's soundness completeness.)

5. Empirical Analysis Heuristics Control Commitment Strategy

seen, flecs introduces notion exible choice point delayed
eager operator-ordering commitments. appreciate need exibility, consider
two extreme heuristics: always eagerly subgoaling (delaying commitment) always
eagerly applying (eager commitment). former heuristic chooses subgoal long
least one active pending goal (Subgoal Always Applying saba);
latter chooses apply long active applicable operators (Subgoal
eVery Try Apply savta). section show empirical results demonstrate
extremes lead highly sub-optimal search particular domains.
Indeed, believe single domain-independent search heuristic perform well
domains (Stone et al., 1994). reason equipped flecs
ability use either extreme domain-independent heuristic moderate
heuristic \in between" two: every iteration algorithm,
opportunity change eagerly subgoaling eagerly applying vice versa. One could
define different heuristics guide choice, one could leave choice user
interactively.
exibility search method provides algorithm ability search sensibly wide variety domains. algorithm exible susceptible
coming across domains cannot handle eciently (Barrett & Weld, 1994; Veloso &
Blythe, 1994; Kambhampati, 1994). flecs's exibility makes possible study
heuristics work best situations. addition, exible choice perfect learning
opportunity. Since single search method solve planning problems, use
learning techniques help us determine experience search strategies try.
illustrate need different search strategies, provide one real world situation
eagerly subgoaling leads directly optimal solution, one eagerly
applying so, one intermediate policy best. examples
intended exhaustive demonstration flecs's capabilities. Rather, examples
intended illustrate need consider problems traditional goal ordering
problems motivate potential impact flecs.

5.1 Eagerly Subgoaling Better

First, consider class tasks following true: operators initially
executable, must performed specific order operator deletes
preconditions operators supposed executed earlier. instance,
suppose single paint brush several objects need painted
different colors. paint brush washed fairly well, never comes completely
42

fiflecs: Planning Flexible Commitment Strategy

clean. reason, ever use lighter paint darker paint, darker
paint show painted object whole project ruined. Perhaps
shade red darker shade green. paint chair red seat
green legs, better paint legs first.
Consider range colors ordered light dark: white, yellow, green, : : : ,
black. Initially, could paint object color. However, start painting
something black, paint used. order represent situation
planner, created domain operators shown Table 3.
Operator:
preconds:
adds:
deletes:

paint-white <obj>

(usable white)
(white <obj>)

paint-yellow <obj>

(usable yellow)
(yellow <obj>)
(usable white)






..
.

paint-black <obj>

(usable black)
(black <obj>)
(usable white)
(usable yellow)
..
.
(usable brown)

Table 3: Example domain delayed step-ordering commitment results ecient
planning.
Assume colors usable initial state. Since painting object certain
color deletes precondition painting object lighter color, since precondition cannot re-achieved (no operator adds predicate \usable"), colors must
used specific order.
painting domain real-world interpretation artificial domain Dm 1 introduced (Barrett & Weld, 1994). operators Dm 1 look like:
Operator:
preconds: fI g
adds: fG g
deletes: fI jj < ig
Since operator deletes preconditions operators numerically it,
operators applied increasing numerical order. Thus, A1 corresponds
operator paint-white, A2 corresponds paint-yellow, etc. used domain
experiments, run SPARC station. generated random problems
one fifteen goals: ten problems number goals. used
150 problems test extreme heuristics. get data points, averaged
results ten problems number goals. raw data
contained online appendix. graph average time flecs took solve
problems versus number goals.
shown (Stone et al., 1994),9 eagerly applying leads exponential behavior (as
function number goals) domain, eagerly subgoaling, using






j

9. began study new planning algorithm | named flecs| prodigy4.0. consider
version prodigy used (Stone et al., 1994) preliminary implementation flecs.

43

fiVeloso & Stone

operator choice heuristic study, leads approximately linear behavior
backtracking. problem eagerly applying that, example, goal G7
solved G4, flecs immediately apply A7 backtrack
unsuccessfully tries apply A4 . Eagerly subgoaling allows flecs build set
operators need apply order appropriately selecting
application order avoids con icts threats. Figure 11 shows graphic comparison
two different behaviors.
Eager Subgoaling
Eager Applying

Time: msec

2500
2000
1500
1000
500
0
0

2

4

6
8
10 12
Number Goals

14

16

Figure 11: flecs's performance different heuristics domains Dm 1. Eager subgoaling applying correspond delayed commitments eager commitments
respectively.

5.2 Eagerly Applying Better

Next, consider class tasks following true: several operators could
used achieve goal, operator used once. use similar
example, suppose trying paint different parts single object different colors.
However, suppose using multiple brushes never come clean:
use brush one color, never safely use again. instance, painted
green parts using brush1, would need use brush2 (or brush besides brush1)
paint red parts. Table 4 represents operators new domain.
Operator:

paint-with-brush1

<parts> <color>
preconds: (unused brush1)
adds: (painted <parts> <color>)
deletes: (unused brush1)

: : : paint-with-brush8

<parts> <color>
(unused brush8)
(painted <parts> <color>)
(unused brush8)

Table 4: Example domain eager step-ordering commitment use state
results ecient planning.
Note operator used color, since deletes precondition,
used once. capture essential features domain artificial
domain called D1 -use-once. operators D1-use-once look like:
44

fiflecs: Planning Flexible Commitment Strategy


fI g
f< g >g
fI g

Operator:
preconds:
adds:
deletes:







operator achieve goal, since operator deletes precondition,
used once. operator corresponds painting different brush.
domain, better eagerly apply eagerly subgoal. Eagerly
subgoaling causes flecs select operator achieve goals.
deterministic method selecting operators (such minimum conspiracy number
order appearance domain specification tie-breaker), selects operator A1
achieve two different goals. However, since could apply A1 once, would need
backtrack select different operator one goals. shown Figure 12, eagerly
applying outperforms eagerly subgoaling case. generated results
way results previous subsection.
Eager Subgoaling
Eager Applying

Time: msec

5000
4000
3000
2000
1000
0
0

2

4

6
8
10 12
Number Goals

14

16

Figure 12: flecs's performance different heuristics domains D1-use-once.

5.3 Intermediate Heuristic

always possible find good solutions either always eagerly subgoaling,
first example, always eagerly applying, second, would need
include variable toggle flecs: could simply eager-subgoal mode
eager-apply mode. However, cases neither alternatives suces.
Instead, need eagerly subgoal portions search eagerly apply
others. One heuristic changing commitment strategy abstraction-driven
method described Section 4.2. present domain use form
heuristic.
time consider class tasks following true: top-level goals take
least three operators achieve, one irreversible, executed limited
number times, restricts bindings operators. One representative
class one-way rocket domain introduced (Veloso & Carbonell, 1993).
sake consistency, however, present representative class domains
painting context. Suppose painting walls rollers. paint wall
45

fiVeloso & Stone

need first \ready" wall, purpose example means decide
wall needs painted designate color roller paint wall. Next
must fill selected roller appropriately colored paint. paint
wall. Unfortunately, limited supply rollers never become clean
filled paint, must clean selected paint wall.
reason, must ready walls want paint roller
fill roller paint. reader familiar one-way rocket domain,
\fill-roller" operator analogous \move-rocket" operator domain:
executed due limited supply fuel, must executed
fully loaded. Table 5 shows possible set operators painting domain.
Operator:

designate-roller

fill-roller

paint-wall

<wall> <roller> <color> <roller> <color> <wall> <roller> <color>
preconds: (clean <roller>)
(clean <roller>)
(ready
(needs-painting <wall>)
(chosen
<wall> <roller> <color>)
<roller> <color>) (filled-with-paint
<roller> <color>)
adds: (ready
(filled-with-paint
(painted <wall> <color>)
<wall> <roller> <color>) <roller> <color>)
(chosen <roller> <color>)
deletes:
(clean <roller>)
(ready
<wall> <roller> <color>)
(needs-painting <wall>)

Table 5: Example domain exibility commitments results ecient planning.
given domain representation, flecs dicult time apparently simple problems uses search strategy throughout entire search.
example, consider problem five walls two rollers (equivalent problem
one-way rocket domain five objects two destinations):
Initial State
(needs-painting wallA)
(needs-painting wallB)
(needs-painting wallC)
(needs-painting wallD)
(needs-painting wallE)
(clean roller1)
(clean roller2)

Goal Statement
(painted wallA red)
(painted wallB red)
(painted wallC red)
(painted wallD green)
(painted wallE green)

46

Optimal Solution
<Designate-Roller wallA roller1 red>
<Designate-Roller wallB roller1 red>
<Designate-Roller wallC roller1 red>
<Fill-Roller roller1 red>
<Paint-Wall wallA roller1 red>
<Paint-Wall wallB roller1 red>
<Paint-Wall wallC roller1 red>
<Designate-Roller wallD roller2 green>
<Designate-Roller wallE roller2 green>
<Fill-Roller roller2 green>
<Paint-Wall wallD roller2 green>
<Paint-Wall wallE roller2 green>

fiflecs: Planning Flexible Commitment Strategy

flecs directly find solution always eagerly subgoaling always
eagerly applying. search eciently, must subgoal considered walls
need painted color; must apply applicable operators
continuing. explicit information domain telling use one roller red
one roller green.10 reason, flecs eagerly subgoals, initially selects
roller paint walls. extensively backtracks finding correct
bindings. flecs also realize \ready" walls going
painted color filling roller. Thus, flecs eagerly applies
operators, tries filling roller soon one wall \readied." Note planning
variables would solve problem since planner would still need make
binding selections subgoaling beyond \paint-wall," hence facing problems.
flecs tries solve problem using either strategy described,
succeed reasonable amount time. Since flecs complete, would certainly
succeed eventually, eventually long time away dealing NP-hard
problem: neither commitment strategies leads solution problem
500 seconds search time. lost. changing value toggle
appropriate times, flecs easily find solution problem. fact,
4 seconds toggle manually changed appropriate times.
time(sec) solution
eager applying
500

eager subgoaling
500

variable strategy
4
yes
flecs eagerly subgoals decided paint wallA, wallB, wallC
roller1, begin eagerly applying. three walls painted red, flecs
begin subgoaling without danger preparing walls wrong
roller: roller2 still clean. example change state allows
minimum conspiracy number heuristic select correct instantiated operator.
general heuristic toggle set sub walls need
painted color considered. toggle set app
applicable operators applied. toggle set back sub
process continues. way, flecs need little backtracking
quickly reach solution. heuristic corresponds using abstraction hierarchy
deal separately interactions different colors different walls.

6. Conclusion

presented planner intended studying correspondence planning problems search heuristics suited problems. flecs
ability eagerly subgoal, thus delaying operator-ordering commitments; eagerly apply,
thus maximizing advantages maintaining internal state; exibly interleave
two strategies. Thus operate point continuum operator-ordering
heuristics { one important dimension planning.
10. problem common planning often syntactically correct way restrict bindings
domain representation maintaining intended exibility generality domain.

47

fiVeloso & Stone

paper, explained advantages disadvantages delayed eager
commitments. presented flecs algorithm full detail, carefully motivating
concepts illustrating clear examples. discussed different heuristics
guide flecs choice points discussed properties. showed examples
specific planning tasks corresponding empirical results support position
general-purpose planner must able use exible commitment strategy. Although
planning problems solvable complete planners, flecs may solve
problems eciently planners ability change
commitment strategy may fall worst case unique commitment strategy.
flecs provides framework study characteristics different planning strategies
mapping planning domains problems. flecs represents view
domain-independent planning strategy uniformly ecient across different domains problems. flecs addresses particular operator-ordering choice
exible planning decision. allows combination delayed eager operator-ordering
commitments take advantage benefits explicitly using simulated execution
state reasoning planning constraints.
currently continuing work understanding tradeoffs among different
planning strategies along different dimensions. plan study effects eager versus
delayed commitments point operator instantiations. also investigating
effects combining real execution flecs. Finally, plan use machine learning
techniques flecs's choice points gain possibly automated understanding
mapping ecient planning methods planning domains problems.

Appendix A. Proofs
prove flecs sound iterative deepening complete. Consider
flecs algorithm presented Table 2. planning problem determined
initial state, goal statement, set operators available domain. plan
(totally-ordered) sequence instantiated operators. returned plan generated
flecs planning problem sequence applied operators upon termination.
solution planning problem plan whose operators applied problem's
initial state reach state satisfies Goal Statement. justified solution
solution subsequence operators solution also solution. flecs
terminates successfully termination condition met (step 2).

Theorem 1.

flecs sound.
show flecs algorithm sound; is, algorithm terminates suc-

cessfully, returned plan indeed solution given planning problem.
Assume flecs terminates successfully = O1 ; O2; :::On returned
plan. flecs applies operator preconditions operator satisfied
Current State C (step 7). Hence, construction, operators O1 ; O2; : : :Ok
k < n applied, preconditions operator Ok+1 satisfied C .
point termination, Current State C satisfies Goal Statement (step 2). C
reached initial state applying operators . Therefore solution.
QED.
48

fiflecs: Planning Flexible Commitment Strategy

Theorem 2.

flecs iterative deepening complete.

Recall completeness, informally, means solution particular
problem, algorithm find it. show flecs's search space complete
flecs's search algorithm complete long explores branches search
space, example using iterative deepening (Korf, 1985).11 Iterative deepening involves
searching bound number search steps may performed
particular search path suspended expansion; solution found
particular depth bound, search repeated larger depth bound.
planning problem, assume = O1; O2; :::On justified solution.
show flecs searches iterative deepening, find solution.
flecs algorithm four choice points. Three choice points backtrack
points: choice subgoaling applying (step 5d), choice operator
use achieve goal (step 6c), choice applicable operator apply
(step 7). One choice point backtrack point: choice goal subgoal
(step 6).
prove completeness, must show backtrack point, possible
choice lead flecs towards finding plan , matter choices flecs makes
non-backtrack choice point. flecs explores branches search space
searching iterative deepening, must eventually find unless finds
solution (of length n) first.
proof involves constructing oracles tell flecs choices make
backtrack points find . matter choices makes choice
point, finds solution plan .
Consider point search operators O1; O2; O3; : : :; Ok k (and
others) already applied. let oracles backtrack points
operate follows.
choice subgoaling applying (step 5d), first oracle makes flecs choose
apply Ok+1 applicable (i.e., A); otherwise makes flecs subgoal.
flecs chooses apply (Ok+1 2 A), reaches another choice point, namely choice
operator apply (step 7). Another oracle makes flecs select precisely step Ok+1 .
flecs chooses subgoal (Ok+1 62 A), let flecs choose goal P
set pending goals P (step 6). Since step 6 backtrack point, cannot
oracle determine choice point. Instead show that, independently
choice made point, flecs still find solution . find solution
consequence construction next oracle controls final choice point
(below). oracle guarantees P selected must either member goal
statement precondition operator .
final choice point selection operator achieve P (step 6c). third
oracle makes flecs choose operator achieve P . Since solution
planning problem since P either member Goal Statement precondition
operator , must operator achieves P .
one operator, one chosen. Since operators selected,
11. opposed breadth first search, iterative deepening harm eciency. combines eciency
searching depth first completeness searching breadth first.

49

fiVeloso & Stone

condition pending goals Goal Statement preconditions
operators maintained.
three oracles lead flecs justified solution . Since justified, every
operator necessary achieve either goal goal statement precondition another operator. Consequently, since third oracle chooses operators
, every operator eventually chosen applied prescribed
first two oracles. every operator applied, termination condition
met (since solution) flecs terminate successfully. QED.

Acknowledgements
would like recognize particular contributions Jim Blythe Eugene Fink
research. Jim Blythe highly responsible current implementation prodigy4.0
upon flecs based. Eugene Fink helped formalization algorithms
proofs. thank Eugene Fink, Karen Haigh, Gary Pelton, Alicia Perez, Xuemei Wang,
anonymous reviewers comments article.
research sponsored Wright Laboratory, Aeronautical Systems Center, Air
Force Materiel Command, USAF, Advanced Research Projects Agency (ARPA)
grant number F33615-93-1-1330. views conclusions contained document authors interpreted necessarily representing
ocial policies endorsements, either expressed implied, Wright Laboratory
U. S. Government.

References

Ambros-Ingerson, J., & Steel, S. (1988). Integrating planning, execution, monitoring.
Proceedings Seventh National Conference Artificial Intelligence, pp. 83{88
St. Paul, MN.
Barrett, A., & Weld, D. S. (1994). Partial-order planning: Evaluating possible eciency
gains. Artificial Intelligence, 67, 71{112.
Blythe, J., & Veloso, M. M. (1992). analysis search techniques totally-ordered
nonlinear planner. Proceedings First International Conference AI Planning Systems, pp. 13{19 College Park, MD.
Carbonell, J. G., Blythe, J., Etzioni, O., Gil, Y., Joseph, R., Kahn, D., Knoblock, C.,
Minton, S., Perez, A., Reilly, S., Veloso, M., & Wang, X. (1992). PRODIGY4.0:
manual tutorial. Tech. rep. CMU-CS-92-150, Department Computer Science,
Carnegie Mellon University.
Carbonell, J. G., Knoblock, C. A., & Minton, S. (1990). Prodigy: integrated architecture planning learning. VanLehn, K. (Ed.), Architectures Intelligence.
Erlbaum, Hillsdale, NJ. Also Technical Report CMU-CS-89-189.
Chapman, D. (1987). Planning conjunctive goals. Artificial Intelligence, 32, 333{378.
50

fiflecs: Planning Flexible Commitment Strategy

Ernst, G. W., & Newell, A. (1969). GPS: Case Study Generality Problem Solving.
ACM Monograph Series. Academic Press, New York, NY.
Fikes, R. E., & Nilsson, N. J. (1971). Strips: new approach application theorem
proving problem solving. Artificial Intelligence, 2, 189{208.
Fink, E., & Veloso, M. (1994). PRODIGY planning algorithm. Technical report CMU-CS94-123, School Computer Science, Carnegie Mellon University.
Kambhampati, S. (1994). Desing tradeoffs partial order (plan space) planning. Proceedings Second International Conference AI Planning Systems, AIPS-94,
pp. 92{97 Chicago, IL.
Knoblock, C. A. (1994). Automatically generating abstractions planning. Artificial
Intelligence, 68.
Korf, R. E. (1985). Depth-first iterative-deepening: optimal admissible tree search.
Artificial Intelligence, 27 (1), 97{109.
McAllester, D., & Rosenblitt, D. (1991). Systematic nonlinear planning. Proceedings
Ninth National Conference Artificial Intelligence, pp. 634{639.
McDermott, D. V. (1978). Planning acting. Cognitive Science, 2-2, 71{109.
Minton, S. (1993). Integrating heuristics constraint satisfaction problems: case study.
Proceedings Eleventh National Conference Artificial Intelligence, pp. 120{
126.
Minton, S., Bresina, J., & Drummond, M. (1991). Commitment strategies planning:
comparative analysis. Proceedings Twelfth International Joint Conference
Artificial Intelligence, pp. 259{265.
Minton, S., Knoblock, C. A., Kuokka, D. R., Gil, Y., Joseph, R. L., & Carbonell, J. G.
(1989). prodigy 2.0: manual tutorial. Technical report CMU-CS-89-146,
School Computer Science, Carnegie Mellon University.
Rosenbloom, P. S., Newell, A., & Laird, J. E. (1990). Towards knowledge level
SOAR: role architecture use knowledge. VanLehn, K. (Ed.),
Architectures Intelligence. Erlbaum, Hillsdale, NJ.
Sacerdoti, E. D. (1977). Structure Plans Behavior. American Elsevier, New York.
Stone, P., Veloso, M., & Blythe, J. (1994). need different domain-independent
heuristics. Proceedings Second International Conference AI Planning
Systems, pp. 164{169.
Tate, A. (1977). Generating project networks. Proceedings Fifth International
Joint Conference Artificial Intelligence, pp. 888{900.
51

fiVeloso & Stone

Veloso, M., & Blythe, J. (1994). Linkability: Examining causal link commitments partialorder planning. Proceedings Second International Conference AI Planning
Systems, pp. 170{175.
Veloso, M. M. (1989). Nonlinear problem solving using intelligent casual-commitment.
Technical report CMU-CS-89-210, School Computer Science, Carnegie Mellon University.
Veloso, M. M., & Carbonell, J. G. (1993). Derivational analogy prodigy: Automating
case acquisition, storage, utilization. Machine Learning, 10, 249{278.
Veloso, M. M., Perez, M. A., & Carbonell, J. G. (1990). Nonlinear planning parallel
resource allocation. Proceedings DARPA Workshop Innovative Approaches
Planning, Scheduling, Control, pp. 207{212 San Diego, CA. Morgan Kaufmann.
Wilkins, D. E. (1984). Domain-independent planning: Representation plan generation.
Artificial Intelligence, 22, 269{301.

52

fi
