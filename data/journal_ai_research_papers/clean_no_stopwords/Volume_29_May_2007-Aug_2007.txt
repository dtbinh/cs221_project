Journal Artificial Intelligence Research 29 (2007) 105-151Submitted 05/06; published 06/07Combination Strategies Semantic Role LabelingMihai SurdeanuLlus MarquezXavier CarrerasPere R. Comassurdeanu@lsi.upc.edulluism@lsi.upc.educarreras@lsi.upc.edupcomas@lsi.upc.eduTechnical University Catalonia,C/ Jordi Girona, 1-308034 Barcelona, SPAINAbstractpaper introduces analyzes battery inference models problem semantic role labeling: one based constraint satisfaction, several strategies modelinference meta-learning problem using discriminative classiers. classiersdeveloped rich set novel features encode proposition sentence-levelinformation. knowledge, rst work that: (a) performs thorough analysis learning-based inference models semantic role labeling, (b) compares severalinference strategies context. evaluate proposed inference strategiesframework CoNLL-2005 shared task using automatically-generated syntacticinformation. extensive experimental evaluation analysis indicatesproposed inference strategies successful outperform current best resultsreported CoNLL-2005 evaluation exercise proposed approachesadvantages disadvantages. Several important traits state-of-the-art SRL combination strategy emerge analysis: (i) individual models combinedgranularity candidate arguments rather granularity complete solutions;(ii) best combination strategy uses inference model based learning; (iii)learning-based inference benets max-margin classiers global feedback.1. IntroductionNatural Language Understanding (NLU) subeld Articial Intelligence (AI)deals extraction semantic information available natural language texts.knowledge used develop high-level applications requiring textual documentunderstanding, Question Answering Information Extraction. NLU complexAI-complete problem needs venture well beyond syntactic analysis naturallanguage texts. state art NLU still far reaching goals, recentresearch made important progress subtask NLU: Semantic Role Labeling.task Semantic Role Labeling (SRL) process detecting basic event structureswhom, where. See Figure 1 sample sentence annotatedevent frame.1.1 MotivationSRL received considerable interest past years (Gildea & Jurafsky, 2002;Surdeanu, Harabagiu, Williams, & Aarseth, 2003; Xue & Palmer, 2004; Pradhan, Hac2007AI Access Foundation. rights reserved.fiSurdeanu, Marquez, Carreras, & Comascioglu, Krugler, Ward, Martin, & Jurafsky, 2005a; Carreras & Marquez, 2005).shown identication event frames signicant contribution manyNLU applications Information Extraction (Surdeanu et al., 2003), Question Answering (Narayanan & Harabagiu, 2004), Machine Translation (Boas, 2002), Summarization (Melli, Wang, Liu, Kashani, Shi, Gu, Sarkar, & Popowich, 2005), CoreferenceResolution (Ponzetto & Strube, 2006b, 2006a).syntactic perspective, machine-learning SRL approaches classiedone two classes: approaches take advantage complete syntactic analysis text,pioneered Gildea Jurafsky (2002), approaches use partial syntactic analysis,championed previous evaluations performed within Conference ComputationalNatural Language Learning (CoNLL) (Carreras & Marquez, 2004, 2005). wisdomextracted rst representation indicates full syntactic analysis signicantcontribution SRL performance, using hand-corrected syntactic information (Gildea& Palmer, 2002). hand, automatically-generated syntax available,quality information provided full syntax decreases state-ofthe-art full parsing less robust performs worse tools used partialsyntactic analysis. real-world conditions, dierence two SRLapproaches (with full partial syntax) high. interestingly, two SRLstrategies perform better different semantic roles. example, models use fullsyntax recognize agent theme roles better, whereas models based partial syntaxbetter recognizing explicit patient roles, tend farther predicateaccumulate parsing errors (Marquez, Comas, Gimenez, & Catala, 2005).1.2 Approacharticle explore implications observations studying strategiescombining output several independent SRL systems, take advantagedierent syntactic views text. given sentence, combination models receivelabeled arguments individual systems, produce overall argument structurecorresponding sentence. proposed combination strategies exploit several levelsinformation: local global features (from individual models) constraintsargument structure. work, investigate three dierent approaches:rst combination model parameters estimate; makes useargument probabilities output individual models constraints argumentstructures build overall solution sentence. call model inferenceconstraint satisfaction.second approach implements cascaded inference model local learning: rst,type argument, classier trained oine decides whether candidatenal argument. Next, candidates passed previous stepcombined solution consistent constraints argument structures.refer model inference local learning.third inference model global: number online ranking functions, oneargument type, trained score argument candidates correctargument structure complete sentence globally ranked top. callmodel inference global learning.106fiCombination Strategies Semantic Role LabelingNPNPVPNPPPluxury auto maker last year sold 1,214 cars U.S.A0AgentAMTMPTemporalMarkerPA1Predicate ObjectAMLOCLocativeMarkerFigure 1: Sample sentence PropBank corpus.proposed combination strategies general depend waycandidate arguments collected. empirically prove experimentingindividual SRL systems developed house, also 10 best systemsCoNLL-2005 shared task evaluation.1.3 Contributionwork introduced paper several novel points. knowledge,rst work thoroughly explores inference model based meta-learning (thesecond third inference models introduced) context SRL. investigate metalearning combination strategies based rich, global representations form localglobal features, form structural constraints solutions. empiricalanalysis indicates combination strategies outperform current stateart. Note combination strategies proposed paper re-rankingapproaches (Haghighi, Toutanova, & Manning, 2005; Collins, 2000). Whereas re-rankingselects overall best solution pool complete solutions individual models,combination approaches combine candidate arguments, incomplete solutions,different individual models. show approach better potential, i.e., upperlimit F1 score higher performance better several corpora.second novelty paper performs comparative analysis several combination strategies SRL, using framework i.e., poolcandidates evaluation methodology. large number combinationapproaches previously analyzed context SRL larger contextpredicting structures natural language texts e.g., inference based constraint satisfaction (Koomen, Punyakanok, Roth, & Yih, 2005; Roth & Yih, 2005), inference basedlocal learning (Marquez et al., 2005), re-ranking (Collins, 2000; Haghighi et al., 2005) etc.still clear strategy performs best semantic role labeling. paper107fiSurdeanu, Marquez, Carreras, & Comasprovide empirical answers several important questions respect. example,combination strategy based constraint satisfaction better inference model basedlearning? Or, important global feedback learning-based inference model?analysis indicates following issues important traits state-of-the-artcombination SRL system: (i) individual models combined argument granularityrather granularity complete solutions (typical re-ranking); (ii) bestcombination strategy uses inference model based learning; (iii) learning-basedinference benets max-margin classiers global feedback.paper organized follows. Section 2 introduces semantic corpora usedtraining evaluation. Section 3 overviews proposed combination approaches.individual SRL models introduced Section 4 evaluated Section 5. Section 6lists features used three combination models introduced paper.combination models described Section 7. Section 8 introduces empirical analysis proposed combination methods. Section 9 reviews related workSection 10 concludes paper.2. Semantic Corporapaper used PropBank, approximately one-million-word corpus annotatedpredicate-argument structures (Palmer, Gildea, & Kingsbury, 2005). date, PropBank addresses predicates lexicalized verbs. Besides predicate-argument structures,PropBank contains full syntactic analysis sentences, extends Wall StreetJournal (WSJ) part Penn Treebank, corpus previously annotatedsyntactic information (Marcus, Santorini, & Marcinkiewicz, 1994).given predicate, survey carried determine predicate usage, and,required, usages divided major senses. However, senses dividedsyntactic grounds semantic, following assumption syntactic framesdirect reection underlying semantics. arguments predicate numbered sequentially A0 A5. Generally, A0 stands agent, A1 theme directobject, A2 indirect object, benefactive instrument, semantics tend verbspecic. Additionally, predicates might adjunctive arguments, referred AMs.example, AM-LOC indicates locative AM-TMP indicates temporal. Figure 1 showssample PropBank sentence one predicate (sold) 4 arguments. regularadjunctive arguments discontinuous, case trailing argument fragmentsprexed C-, e.g., [A1 funds] [predicate expected] [CA1 begin operationaround March 1]. Finally, PropBank contains argument references (typically pronominal),share label actual argument prexed R-.1paper use syntactic information Penn Treebank. Instead,develop models using automatically-generated syntax named-entity (NE) labels,made available CoNLL-2005 shared task evaluation (Carreras & Marquez, 2005).CoNLL data, use syntactic trees generated Charniak parser (Char1. original PropBank annotations, co-referenced arguments appear single item, differentiation referent reference. use version data used CoNLLshared tasks, reference arguments automatically separated corresponding referentssimple pattern-matching rules.108fiCombination Strategies Semantic Role Labelingniak, 2000) develop two individual models based full syntactic analysis, chunki.e., basic syntactic phrase labels clause boundaries construct partial-syntaxmodel. individual models use provided NE labels.Switching hand-corrected automatically-generated syntactic information meansPropBank assumption argument (or argument fragment discontinuous arguments) maps one syntactic phrase longer holds, due errors syntacticprocessors. analysis PropBank data indicates 91.36% semanticarguments matched exactly one phrase generated Charniak parser. Essentially, means SRL approaches make assumption semanticargument maps one syntactic construct recognize almost 9% arguments.statement made approaches based partial syntax caveatsetup arguments match sequence chunks. However, one expectsdegree compatibility syntactic chunks semantic arguments higherdue ner granularity syntactic elements chunking algorithms perform better full parsing algorithms. Indeed, analysis PropBank datasupports observation: 95.67% semantic arguments matched sequencechunks generated CoNLL syntactic chunker.Following CoNLL-2005 setting evaluated system PropBankalso fresh test set, derived Brown corpus. second evaluation allows usinvestigate robustness proposed combination models.3. Overview Combination Strategiespaper introduce analyze three combination strategies problemsemantic role labeling. three combination strategies implemented sharedframework detailed Figure 2 consists several stages: (a) generation candidate arguments, (b) candidate scoring, nally (c) inference. clarity, describerst proposed combination framework, i.e., vertical ow Figure 2. Then, moveoverview three combination methodologies, shown horizontally Figure 2.candidate generation step, merge solutions three individual SRL modelsunique pool candidate arguments. individual SRL models range completereliance full parsing using partial syntactic information. example, Model 1developed sequential tagger (using B-I-O tagging scheme) partialsyntactic information (basic phrases clause boundaries), whereas Model 3 uses fullsyntactic analysis text handles arguments map exactly one syntacticconstituent. detail individual SRL models Section 4 empirically evaluateSection 5.candidate scoring phrase, re-score candidate arguments using localinformation, e.g., syntactic structure candidate argument, global information,e.g., many individual models generated similar candidate arguments. describefeatures used candidate scoring Section 6.Finally, inference stage combination models search best solutionconsistent domain constraints, e.g., two arguments predicate cannotoverlap embed, predicate may one core argument (A0-5), etc.109fiSurdeanu, Marquez, Carreras, & ComasReliance full syntaxModel 1Model 2Model 3CandidateGenerationCandidate ArgumentPoolConstraintSatisfactionEngineSolutionInferenceConstraint SatisfactionLearning(batch)Learning(online)DynamicProgrammingEngineDynamicProgrammingEngineSolutionCandidateScoringInferenceSolutionInferenceLocal LearningInferenceGlobal LearningFigure 2: Overview proposed combination strategies.combination approaches proposed paper share candidate argument pool. guarantees results obtained dierent strategiescorpus comparable. hand, even though candidate generationstep shared, three combination methodologies dier signicantly scoringinference models.rst combination strategy analyzed, inference constraint satisfaction, skipscandidate scoring step completely uses instead probabilities output individual SRL models candidate argument. individual models raw activationsactual probabilities convert probabilities using softmax function (Bishop,1995), passing inference component. inference implemented usingConstraint Satisfaction model searches solution maximizes certaincompatibility function. compatibility function models probabilityglobal solution also consistency solution according domain constraints.combination strategy based technique presented Koomen et al. (2005).main dierence two systems candidate generation step: usethree independent individual SRL models, whereas Komen et al. used SRL model110fiCombination Strategies Semantic Role Labelingtrained dierent syntactic views data, i.e., top parse trees generatedCharniak Collins parsers (Charniak, 2000; Collins, 1999). Furthermore, takeargument candidates set complete solutions generated individual models, whereas Komen et al. take dierent syntactic trees, constructingcomplete solution. obvious advantage inference model Constraint Satisfaction unsupervised: learning necessary candidate scoring,scores individual models used. hand, Constraint Satisfactionmodel requires individual models provide raw activations, and, moreover,raw activations convertible true probabilities.second combination strategy proposed article, inference local learning,re-scores candidates pool using set binary discriminative classiers.classiers assign argument score measuring condence argumentpart correct, global solution. classiers trained batch modecompletely decoupled inference module. inference component implementedusing CKY-based dynamic programming algorithm (Younger, 1967). main advantagestrategy candidates re-scored using signicantly informationavailable individual model. example, incorporate features countnumber individual systems generated given candidate argument, severaltypes overlaps candidate arguments predicate also argumentspredicates, structural information based full partial syntax, etc.describe rich feature set used scoring candidate arguments Section 6. Also,combination approach depend argument probabilities individualSRL models (but incorporate features, available). combination approachcomplex previous strategy additional step requiressupervised learning: candidate scoring. Nevertheless, mean additionalcorpus necessary: using cross validation, candidate scoring classiers trainedcorpus used train individual SRL models. Moreover, show Section 8obtain excellent performance even candidate scoring classiers trainedsignicantly less data individual SRL models.Finally, inference strategy global learning investigates contribution globalinformation inference model based learning. strategy incorporates globalinformation previous inference model two ways. First importantly, candidate scoring trained online global feedback inference component.words, online learning algorithm corrects mistakes found comparingcorrect solution one generated inference. Second, integrate global information actual inference component: instead performing inference propositionindependently, whole sentence once. allows implementationadditional global domain constraints, e.g., arguments attached dierent predicatesoverlap.combination strategies proposed described detail Section 7 evaluatedSection 8.111fiSurdeanu, Marquez, Carreras, & Comas4. Individual SRL Modelssection introduces three individual SRL models used combination strategies discussed paper. rst two models variations algorithm:model SRL problem sequential tagging task, semantic argumentmatched sequence non-embedding phrases, Model 1 uses partial syntax(chunks clause boundaries), whereas Model 2 uses full syntax. third model takestraditional approach assuming exists one-to-one mappingsemantic arguments syntactic phrases.important note combination strategies introduced later paperindependent individual SRL models used. fact, Section 8 describeexperiments use individual models also best performing SRLsystems CoNLL-2005 evaluation (Carreras & Marquez, 2005). Nevertheless,choose focus mainly individual SRL approaches presented sectioncompleteness show state-of-the-art performance possible relatively simpleSRL models.4.1 Models 1 2models approach SRL sequential tagging task. pre-processing step,input syntactic structures traversed order select subset constituents organizedsequentially (i.e., non embedding). output process sequential tokenizationinput sentence verb predicates. Labeling tokens appropriatetags allows us codify complete argument structure predicate sentence.precisely, given verb predicate, sequential tokens selected follows:First, input sentence split disjoint sequential segments using markerssegment start/end verb position boundaries clauses includecorresponding predicate constituent. Second, segment, set top-mostnon-overlapping syntactic constituents completely falling inside segment selectedtokens. Finally, tokens labeled B-I-O tags, dependingbeginning, inside, outside predicate argument. Note strategy provides setsequential tokens covering complete sentence. Also, independent syntacticannotation explored, assuming provides clause boundaries.Consider example Figure 3, depicts PropBank annotation two verbpredicates sentence (release hope) corresponding partial full parsetrees. Since verbs main clause sentence, two segmentssentence considered predicates, i.e., dening left right contextsverbs ([w1 :Others, ..., w3 :just] [w5 :from, ..., w20 :big-time] predicate release,[w1 :Others, ..., w8 :,] [w10 :the, ..., w20 :big-time] predicate hope). Figure 4shows resulting tokenization predicates two alternative syntactic structures. case, correct argument annotation recovered cases, assumingperfect labeling tokens.worth noting resulting number tokens annotate much lowernumber words cases. Also, codications coming full parsingsubstantially fewer tokens coming partial parsing. example,predicate hope, dierence number tokens two syntactic views112fiCombination Strategies Semantic Role LabelingClauseNP6VPClauseVP1NP3ADVP4IINPPPVP,,52Others ,released majors , hope senior leaguebridge back bigtime.Clause81NP3ADVP2 , IIOthers ,A1AMTMPIIIVPIV 4PPV5NPVI7VPNP,6 VIIreleased majors , hope senior leaguePA0ClauseVPNPVIIIADVP PPNPbridge back bigtime.A2PA1Figure 3: Annotation example sentence two alternative syntactic structures.lower tree corresponds partial parsing annotation (PP) base chunksclause structure, upper represents full parse tree (FP). Semantic rolestwo predicates (release hope) also provided sentence.encircled nodes trees correspond selected nodes processsequential tokenization sentence. mark selected nodespredicate release Western numerals nodes selected hopeRoman numerals. See Figure 4 details.particularly large (8 vs. 2 tokens). Obviously, coarser token granularity, easierproblem assigning correct output labelings (i.e., less tokens labelalso long-distance relations among sentence constituents better captured).hand, coarser granularity tends introduce unrecoverable errorspre-processing stage. clear trade-o, dicult solve advance.using two models combination scheme take advantage diverse sentencetokenizations (see Sections 7 8).Compared common tree node labeling approaches (e.g., followingModel 3), B-I-O annotation tokens advantage permitting correctly annotate arguments match unique syntactic constituent. bad side,heuristic pre-selection candidate nodes predicate, i.e., nodessequentially cover sentence, makes number unrecoverable errors higher. Another source errors common strategies errors introduced real partial/fullparsers. calculated due syntactic errors introduced pre-processingstage, upper-bound recall gures 95.67% Model 1 90.32% Model 2 usingdatasets dened Section 8.113fiSurdeanu, Marquez, Carreras, & Comaswords1: Others2: ,3:4: released5:6:7: majors8: ,9: hope10:11: senior12: league13:14:15:16: bridge17: back18:19:20: big-timereleasePP1: B A12:3: B AM-TMP4: B A25: A26:7:tokensreleaseFPhopePP1: B A1I: B A02:II: A03: B AM-TMPIII: A0IV: A0V: A04: B A2VI: A05:hopeFPI: B A0VII: A0VIII: B A1II: B A16:8:Figure 4: Sequential tokenization sentence Figure 3 according two syntacticviews predicates (PP stands partial parsing FP full parsing).sentence semantic role annotations vertically displayed. tokennumbered indexes appear tree nodes Figure 3 containsB-I-O annotation needed codify proper semantic role structure.Approaching SRL sequential tagging task new. Hacioglu, Pradhan, Ward,Martin, Jurafsky (2004) presented system based sequential tagging base chunksB-I-O labels, best performing SRL system CoNLL-2004 sharedtask (Carreras & Marquez, 2004). novelty approach resides factsequence syntactic tokens label extracted hierarchical syntactic annotation(either partial full parse tree) restricted base chunks (i.e., tokenmay correspond complex syntactic phrase even clause).4.1.1 Featurestokens selected labeled B-I-O tags, converted trainingexamples considering rich set features, mainly borrowed state-of-the-art systems (Gildea & Jurafsky, 2002; Carreras, Marquez, & Chrupala, 2004; Xue & Palmer,2004). features codify properties from: (a) focus token, (b) target predicate,(c) sentence fragment token predicate, (d) dynamic context,i.e., B-I-O labels previously generated. describe four feature sets next.22. Features extracted partial parsing Named Entities common Model 1 2, featurescoming full parse trees apply Model 2.114fiCombination Strategies Semantic Role LabelingConstituent structure features:Constituent type head: extracted using head-word rules Collins (1999).rst element PP chunk, head rst NP extracted.example, type constituent U.S. Figure 1 PP, headU.S. instead in.First last words POS tags constituent, e.g., in/IN U.S./NNPconstituent U.S. Figure 1.POS sequence: less 5 tags long, e.g., INDTNNP sampleconstituent.2/3/4-grams POS sequence.Bag-of-words nouns, adjectives, adverbs. example, bag-of-nounsconstituent luxury auto maker {luxury, auto, maker}.TOP sequence: sequence types top-most syntactic elements constituent(if less 5 elements long). case full parsing correspondsright-hand side rule expanding constituent node. example, TOPsequence constituent U.S. INNP.2/3/4-grams TOP sequence.Governing category described Gildea Jurafsky (2002), indicates NParguments dominated sentence (typical subjects) verb phrase (typicalobjects). example, governing category constituent 1,214 carsFigure 1 VP, hints corresponding semantic role object.NamedEntity, indicating constituent embeds strictly matches named entityalong type. example, constituent U.S. embeds locativenamed entity: U.S..TMP, indicating constituent embeds strictly matches temporal keyword(automatically extracted AM-TMP arguments training set). Amongcommon temporal cue words extracted are: year, yesterday, week, month,etc. used total 109 cue words.Previous following words POS tag constituent. example,previous word constituent last year Figure 1 maker/NN, nextone sold/VBD.features characterizing focus constituents extracted two previousfollowing tokens, provided inside boundaries current segment.Predicate structure features:Predicate form, lemma, POS tag, e.g., sold, sell, VBD predicateFigure 1.Chunk type cardinality verb phrase verb included: single-wordmulti-word. example, predicate Figure 1 included single-word VPchunk.115fiSurdeanu, Marquez, Carreras, & Comaspredicate voice. distinguish voice types: active, passive, copulative,innitive, progressive.Binary ag indicating verb start/end clause.Sub-categorization rule, i.e., phrase structure rule expands predicatesimmediate parent, e.g., NP NP VP predicate Figure 1.Predicate-constituent features:Relative position, distance words chunks, level embedding (in numberclause-levels) respect constituent. example, constituentU.S. Figure 1 appears predicate, distance 2 words 1 chunk,level embedding 0.Constituent path described Gildea Jurafsky (2002) 3/4/5-gramspath constituents beginning verb predicate ending constituent.example, syntactic path constituent luxury auto makerpredicate sold Figure 1 NP VP VBD.Partial parsing path described Carreras et al. (2004) 3/4/5-grams pathelements beginning verb predicate ending constituent. example,path NP + PP + NP + VP VBD indicates current NP tokenpredicate PP, NP, constituents right (positive sign)level token path descends clause VPnd predicate. dierence previous constituent patharrows anymore introduce horizontal (left/right) movementssyntactic level.Syntactic frame described Xue Palmer (2004). syntactic frame capturesoverall sentence structure using predicate constituent pivots.example, syntactic frame predicate sold constituentU.S. NPNPVPNPPP, current predicate constituent emphasized.Knowing noun phrases predicate lowers probabilityconstituent serves agent (or A0).Dynamic features:BIOtag previous token. training, correct labels left contextused. testing, feature dynamically codied tag previouslyassigned SRL tagger.4.1.2 Learning Algorithm Sequence Taggingused generalized AdaBoost real-valued weak classiers (Schapire & Singer, 1999)base learning algorithm. version algorithm learns xed-depth small decisiontrees weak rules, combined ensemble constructed AdaBoost.implemented simple one-vs-all decomposition address multi-class classication.way, separate binary classier learned B-X I-X argument labelplus extra classier decision.116fiCombination Strategies Semantic Role LabelingAdaBoost binary classiers used labeling test sequences, left right,using recurrent sliding window approach information tags assignedpreceding tokens. explained previous list features, left tags already assigneddynamically codied features. Empirically, found optimal left contexttaken account reduces previous token.tested two dierent tagging procedures. First, greedy left-to-right assignmentbest scored label token. Second, Viterbi search label sequencemaximizes probability complete sequence. case, classiers predictionsconverted probabilities using softmax function described Section 7.1.signicant improvements obtained latter. selected former,faster, basic tagging algorithm experiments.Finally, tagging model enforces three basic constraints: (a) B-I-O output labeling must codify correct structure; (b) arguments cannot overlap clause chunkboundaries; (c) verb, A0-5 arguments present PropBank frames (takingunion rolesets dierent verb senses) considered.4.2 Model 3third individual SRL model makes strong assumption predicate argumentmaps one syntactic constituent. example, Figure 1 A0 maps noun phrase,AM-LOC maps prepositional phrase, etc. assumption holds well hand-correctedparse trees simplies signicantly SRL process one syntactic constituent correctly classied order recognize one semantic argument.hand, approach limited using automatically-generated syntactic trees.example, 91.36% arguments mapped one syntactic constituentsproduced Charniak parser.Using bottom-up approach, Model 3 maps argument rst syntactic constituent exact boundaries climbs high possibletree across unary production chains. currently ignore arguments mapsingle syntactic constituent. argument-constituent mapping performedtraining set preprocessing step. Figure 1 shows mapping example semanticarguments one verb corresponding sentence syntactic structure.mapping process completes, Model 3 extracts rich set lexical, syntactic,semantic features. features inspired previous work parsingSRL (Collins, 1999; Gildea & Jurafsky, 2002; Surdeanu et al., 2003; Pradhan et al.,2005a). describe complete feature set implemented Model 3 next.4.2.1 FeaturesSimilarly Models 1 2 group features three categories, based propertiescodify: (a) argument constituent, (b) target predicate, (c) relationconstituent predicate syntactic constituents.Constituent structure features:syntactic label candidate constituent.constituent head word, suffixes length 2, 3, 4, lemma, POS tag.117fiSurdeanu, Marquez, Carreras, & Comasconstituent content word, suffixes length 2, 3, 4, lemma, POS tag, NElabel. Content words, add informative lexicalized information dierenthead word, detected using heuristics Surdeanu et al. (2003). example,head word verb phrase placed auxiliary verb had, whereascontent word placed. Similarly, content word prepositional phrasespreposition (which selected head word), rather headword attached phrase, e.g., U.S. prepositional phrase U.S..first last constituent words POS tags.NE labels included candidate phrase.Binary features indicate presence temporal cue words, i.e., words appearoften AM-TMP phrases training. used list temporal cue wordsModels 1 2.Treebank syntactic label added feature indicate numberlabels included candidate phrase.TOP sequence constituent (constructed similarly Model 2).phrase label, head word POS tag constituent parent, left sibling,right sibling.Predicate structure features:predicate word lemma.predicate voice. denition Models 1 2.binary feature indicate predicate frequent (i.e., appearstwice training data) not.Sub-categorization rule. denition Models 1 2.Predicate-constituent features:path syntactic tree argument phrase predicatechain syntactic labels along traversal direction (up down).computed similarly Model 2.length syntactic path.number clauses (S* phrases) path. store overall clause countalso number clauses ascending descending part path.number verb phrases (VP) path. Similarly feature, storethree numbers: overall verb count, verb count ascending/descendingpart path.Generalized syntactic paths. generalize path syntactic tree,appears 3 elements, using two templates: (a) Arg Ancestor NiPred, Arg argument label, Pred predicate label, Ancestorlabel common ancestor, Ni instantiated labels118fiCombination Strategies Semantic Role LabelingPred Ancestor full path; (b) Arg Ni Ancestor Pred, Niinstantiated labels Arg Ancestor full path.example, path NP VP SBAR VP argument label rst NP,predicate label last VP, common ancestors label rst S. Hence,using last template, path generalized following three features: NPVP VP, NP SBAR VP, NP VP. generalization reducessparsity complete constituent-predicate path feature using dierent strategyModels 1 2, implement n-gram based approach.subsumption count, i.e., dierence depths syntactic treeargument predicate constituents. value 0 two phrases shareparent.governing category, similar Models 1 2.surface distance predicate argument phrases encoded as:number tokens, verb terminals (VB*), commas, coordinations (CC) argument predicate phrases, binary feature indicate twoconstituents adjacent. example, surface distance argumentcandidate Others predicate hope Figure 3 example: Others,released majors, hope senior league... 7 tokens, 1 verb, 2 commas,0 coordinations. features, originally proposed Collins (1999) dependency parsing model, capture robust, syntax-independent informationsentence structure. example, constituent unlikely argumentverb another verb appears two phrases.binary feature indicate argument starts predicate particle, i.e.,token seen RP* POS tag directly attached predicate training.motivation feature avoid inclusion predicate particlesargument constituent. example, without feature, SRL system tendincorrectly include predicate particle argument text: take [A1organization], marked text commonly incorrectly parsedprepositional phrase large number prepositional phrases directly attachedverb arguments corresponding predicate.4.2.2 ClassifierSimilarly Models 1 2, Model 3 trains one-vs-all classiers using AdaBoostcommon argument labels. reduce sample space, Model 3 selects training examples(both positive negative) from: (a) rst clause includes predicate,(b) phrases appear left predicate sentence. 98%argument constituents fall one classes.prediction time classiers combined using simple greedy techniqueiteratively assigns predicate argument classied highest condence.predicate consider candidates attributes, numbered attributesindicated corresponding PropBank frame. Additionally, greedy strategy enforceslimited number domain knowledge constraints generated solution: (a) argumentsoverlap form, (b) duplicate arguments allowed A0-5, (c)119fiSurdeanu, Marquez, Carreras, & Comaspredicate numbered arguments, i.e., A0-5, subset presentPropBank frame. constraints somewhat dierent constraints usedModels 1 2: (i) Model 3 use B-I-O representation hence constraintB-I-O labeling correct apply; (ii) Models 1 2 enforceconstraint numbered arguments duplicated implementationstraightforward architecture.5. Performance Individual Modelssection analyze performance three individual SRL models proposed.three SRL systems trained using complete CoNLL-2005 training set (PropBank/Treebank sections 2 21). avoid overtting syntactic processors i.e.,part-of-speech tagger, chunker, Charniaks full parser partitioned PropBanktraining set folds fold used output syntactic processorstrained four folds. models tuned separate development partition (Treebank section 24) evaluated two corpora: (a) Treebank section23, consists Wall Street Journal (WSJ) documents, (b) three sectionsBrown corpus, semantically annotated PropBank team CoNLL-2005 sharedtask evaluation.classiers individual models developed using AdaBoost decision trees depth 4 (i.e., branch may represent conjunction 4 basicfeatures). classication model trained 2,000 rounds. appliedsimplications keep training times memory requirements inside admissible bounds:(a) trained frequent argument labels: top 41 Model 1, top 35Model 2, top 24 Model 3; (b) discarded features occurring less 15times training set, (c) Model 3 classier, limited numbernegative training samples rst 500,000 negative samples extracted PropBanktraversal3 .Table 1 summarizes results three models WSJ Brown corpora.include percentage perfect propositions detected model (PProps),i.e., predicates recognized arguments, overall precision, recall, F1measure4 . results summarized Table 1 indicate individual systemssolid performance. Although none would rank top 3 CoNLL2005 evaluation (Carreras & Marquez, 2005), performance comparable bestindividual systems presented evaluation exercise5 . Consistently systemsevaluated Brown corpus, models experience severe performance dropcorpus, due lower performance linguistic processors.expected, models based full parsing (2 3) perform better modelbased partial syntax. But, interestingly, dierence large (e.g., less 2 points3. distribution samples Model 3 classifiers biased towards negative samples because,worst case, syntactic constituent sentence predicate potential argument.4. significance intervals F1 measure obtained using bootstrap resampling (Noreen,1989). F1 rates outside intervals assumed significantly different related F1rate (p < 0.05).5. best performing SRL systems CoNLL combination several subsystems. See section 9details.120fiCombination Strategies Semantic Role LabelingWSJModel 1Model 2Model 3BrownModel 1Model 2Model 3PProps48.45%52.04%45.28%Precision78.76%79.65%80.32%Recall72.44%74.92%72.95%F175.47 0.877.21 0.876.46 0.630.85%36.44%29.48%67.72%71.82%72.41%58.29%64.03%59.67%62.65 2.167.70 1.965.42 2.1Table 1: Overall results individual models WSJ Brown test sets.Model 1 F1Model 2 F1Model 3 F1A083.3786.6586.14A175.1377.0675.83A267.3365.0465.55A361.9262.7265.26A472.7372.4373.85Table 2: F1 scores individual systems A04 arguments WSJ test.F1 WSJ corpus), evincing base syntactic chunks clause boundariesenough obtain competitive performance. importantly, full-parsing modelsalways better partial-syntax model. Table 2 lists F1 measure threemodels rst numbered arguments. Table 2 shows Model 2, overallbest performing individual system, achieves best F-measure A0 A1 (typicallysubjects direct objects), Model 1, partial-syntax model, performs bestA2 (typically indirect objects, instruments, benefactives). explanationbehavior indirect objects tend farther predicates accumulateparsing errors. models based full syntax, Model 2 better recallwhereas Model 3 better precision, Model 3 lters candidate argumentsmatch single syntactic constituent. Generally, Table 2 shows modelsstrong weak points. justication focus combinationstrategies combine several independent models.6. Features Combination Modelsdetailed Section 3, paper analyze two classes combination strategiesproblem semantic role labeling: (a) inference model constraint satisfaction,nds set candidate arguments maximizes global cost function, (b)two inference strategies based learning, candidates scored ranked usingdiscriminative classiers. perspective feature space, main dierencetwo types combination models input rst combination strategy limited argument probabilities produced individual systems,whereas last class combination approaches incorporates much larger feature setranking classiers. robustness, paper use features extracted solutions provided individual systems, hence independent121fiSurdeanu, Marquez, Carreras, & Comas11110000000011110000111100001111000011110000111100001111000011110000111100001111000011110000111100001111000011110000111100001111A0A0VVA1A1VA1A2A4M1M2M3Figure 5: Sample solutions proposed predicate three individual SRL models:M1, M2 M3. Argument candidates displayed vertically system.individual models6 . describe features next. examples given sectionbased Figures 5 6.Voting features features quantify votes received argumentindividual systems. set includes following features:label candidate argument, e.g., A0 rst argument proposed systemM1 Figure 5.number systems generated argument label span.example shown Figure 5, feature value 1 argument A0 proposedM1 2 M1s A1, system M2 proposed argument.unique ids systems generated argument labelspan, e.g., M1 M2 argument A1 proposed M1 M2 Figure 5.argument sequence predicate systems generated argument label span. example, argument sequence generatedsystem M1 proposition illustrated Figure 5 is: A0 - V - A1 - A2. feature attempts capture information proposition level, e.g., combination modelmight learn trust model M1 argument sequence A0 - V - A1 - A2,M2 another sequence, etc.Same-predicate overlap features features measure overlap dierentarguments produced individual SRL models predicate:6. exception argument probabilities, required constraint satisfaction model.122fiCombination Strategies Semantic Role Labelingnumber unique ids systems generated argumentspan different label. example shown Figure 5, featuresvalues 1 M2 argument A2 proposed M1, model M2 proposedargument A4 span.number unique ids systems generated argument includedcurrent argument. candidate argument A0 proposed model M1Figure 5, features values 1 M3, M3 generated argument A0,included M1s A0.spirit, generate number unique ids systemsgenerated argument contains current argument, numberunique ids systems generated argument overlapsinclude contain current argument.Other-predicate overlap features features quantify overlap dierent arguments produced individual SRL models predicates. generatefeatures previous feature group, dierence compare arguments generated dierent predicates. motivation overlap features that,according PropBank annotations, form overlap allowed among argumentsattached predicate, inclusion containment permittedarguments assigned dierent predicates. overlap features meant detectdomain constraints satised candidate argument, indication,evidence strong, candidate incorrect.Partial-syntax features features codify structure argumentdistance argument predicate using partial syntactic information,i.e., chunks clause boundaries (see Figure 6 example). Note featuresinherently dierent features used Model 1, Model 1 evaluatesindividual chunk part candidate argument, whereas codify propertiescomplete argument constituent. describe partial-syntax features below.Length tokens chunks argument constituent, e.g., 4 1 argumentA0 Figure 6.sequence chunks included argument constituent, e.g., PP NPargument AM-LOC Figure 6. chunk sequence large, store n-gramslength 10 start end sequence.sequence clause boundaries, i.e., clause beginning ending, includedargument constituent.named entity types included argument constituent, e.g., LOCATIONAM-LOC argument Figure 6.Position argument: before/after predicate sentence, e.g., A1Figure 6.Boolean ag indicate argument constituent adjacent predicate,e.g., false A0 true A1 Figure 6.123fiSurdeanu, Marquez, Carreras, & ComasClauseNPNPVPNPPPNPluxury auto maker last year sold 1,214 cars U.S.A0AMTMPPA1AMLOCFigure 6: Sample proposition partial syntactic information.sequence chunks argument constituent predicate, e.g.,chunk sequence predicate argument AM-LOC Figure 6 is: NP.Similarly chunk sequence feature, sequence large, storestarting ending n-grams.number chunks predicate argument, e.g., 1 AM-LOCFigure 6.sequence clause boundaries argument constituent predicate.clause subsumption count, i.e., dierence depths clausetree argument predicate constituents. value 0 two phrasesincluded clause.Full-syntax features features codify structure argument constituent,predicate, distance two using full syntactic information.full-syntax features replicated Model 3 (see Section 4.2), assumesone-to-one mapping semantic constituents syntactic phrases exists. Unlike Model 3ignores arguments matched syntactic constituent,exact mapping exist due inclusion candidates Models 1 2,generate approximate mapping unmapped semantic constituent largestphrase included given span left boundary semantic constituent. heuristic guarantees capture least semanticconstituents syntactic structure.motivation partial full-syntax features learn preferencesindividual SRL models. example, features combination classier mightlearn trust model M1 arguments closer 3 chunks predicate, modelM2 predicate-argument syntactic path NP VP SBAR VP, etc.Individual systems argument probabilities individual model outputs condence score proposed arguments. scores converted probabilities using softmax function described detail Section 7.1. combinationstrategy based constraint satisfaction (Section 7.1) uses probabilities are,two strategies based meta-learning (Section 7.2) discretizeprobabilities include features. so, probability value matched124fiCombination Strategies Semantic Role Labelingone probability intervals corresponding interval used feature.probability intervals dynamically constructed argument label individual system corresponding system predictions argument labeluniformly distributed across intervals.Section 8.4 empirically analyze contribution proposed featuresets performance best combination model.7. Combination Strategiessection detail combination strategies proposed paper: (a) combinationmodel constraint satisfaction, aims nding set candidate argumentsmaximizes global cost function, (b) two combination models inference basedlearning, candidates scored ranked using discriminative classiers.previous section described complete feature set made available approaches.focus machine learning paradigm deployed combinationmodels.7.1 Inference Constraint SatisfactionConstraint Satisfaction model selects subset candidate arguments maximizescompatibility function subject fulllment set structural constraintsensure consistency solution. compatibility function based probabilitiesgiven individual SRL models candidate arguments. work use IntegerLinear Programming solve constraint satisfaction problem. approach rstproposed Roth Yih (2004) applied semantic role labeling Punyakanok,Roth, Yih, Zimak (2004), Koomen et al. (2005), among others. follow settingKomen et al., taken reference.rst step, scores model normalized probabilities. scoresyielded classiers signed unbounded real numbers, experimental evidenceshows condence predictions (taken absolute value raw scores)correlates well classication accuracy. Thus, softmax function (Bishop, 1995)used convert set unbounded scores probabilities. k possibleoutput labels given argument sco(li ) denotes score label li outputxed SRL model, estimated probability label is:esco(li )p(li ) = Pksco(lj )j=1 eparameter formula empirically adjusted avoid overly skewedprobability distributions normalize scores three individual modelssimilar range values. See details experimental setting Section 8.1.Candidate selection performed via Integer Linear Programming (ILP). programgoal maximize compatibility function modeling global condence selectedset candidates, subject set linear constraints. variables involvedtask take integer values may appear rst degree polynomials only.abstract ILP process described simple fashion as: given set variables V = {v1 , . . . , vn }, aims maximize global compatibility label assignment125fiSurdeanu, Marquez, Carreras, & Comas{l1 , . . . , ln } variables. local compatibility function cv (l) denes compatibilityassigning label l variable v. global compatibility function C(l1 , . . . , ln ) takensum local assignment compatibility, goal ILP processwritten as:argmax C(l1 , . . . , ln ) = argmaxl1 ,...,lnl1 ,...,lnnXcvi (li )i=1constraints described set accompanying integer linear equations involving variables problem.one wants codify soft constraints instead hard, possibility considering penalty component compatibility function. case, constraintr R seen function takes current label assignment outputsreal number, 0 constraint satised positive number not,indicating penalty imposed compatibility function. new expressioncompatibility function maximize is:C(l1 , . . . , ln ) =nXi=1cvi (li )Xr(l1 , . . . , ln )rRNote hard constraints also simulated setting making outputlarge positive number violated.particular problem, binary-valued variable vi N argument candidates generated SRL models, i.e., li labels {0, 1}. Given labelassignment, arguments li = 1 selected form solution, others(those li = 0) ltered out. variable vi , also probabilityvalues, pij , calculated score model j argument i, according softmaxformula described above7 . rst approach, compatibility function cv (li ) equalsP8(j=1 pij )li , number models, , 3 case .denition, maximizing compatibility function equivalent maximizingsum probabilities given models argument candidates consideredsolution. Since function always positive, global score increases directlynumber selected candidates. consequence, model biased towardsmaximization number candidates included solution (e.g., tending selectlot small non-overlapping arguments). Following Koomen et al. (2005), biascorrected adding new score oi , sums compatibility functioni-th candidate selected solution. global compatibility function needsrewritten encompass new information. Formalized ILP equation, looks like:argmax C(l1 , . . . , lN ) = argmaxL{0,1}NL{0,1}NN XX(i=1 j=1pij )li + oi (1 li )7. model j propose argument consider pij = 0.8. Instead accumulating probabilities models given candidate argument, one could considerdifferent variable model prediction introduce constraint forcing variablestake value end optimization problem. two alternatives equivalent.126fiCombination Strategies Semantic Role Labelingconstraints expressed separated integer linear equations. possibledene priori value oi . Komen et al. used validation corpus empiricallyestimate constant value oi (i.e., independent argument candidate)9 .use exactly solution working single constant value,refer O.Regarding consistency constraints, considered following six:1. Two candidate arguments verb overlap embed.2. verb may two core arguments type label A0-A5.3. argument R-X verb, also X argumentverb.4. argument C-X verb, also X argumentC-X verb.5. Arguments two dierent verbs overlap, embed.6. Two dierent verbs share AM-X, R-AM-X C-X arguments.Constraints 14 also included reference work (Punyakanok et al., 2004).constraints paper need checked since individual modeloutputs consistent solutions. Constraints 5 6, restrict set compatiblearguments among dierent predicates sentence, original work.Integer Linear Programming setting constraints written inequalities. example,Ai argument label i-th candidate Vi verb predicate, constraint numberP2 written as: (Ai =a Vi =v) li 1, given verb v argument label a.constraints similar translations inequalities.Constraint satisfaction optimization applied two dierent ways obtaincomplete output annotation sentence. rst one, proceed verb verbindependently nd best selection candidate arguments using constraints1 4. call approach local optimization. second scenariocandidate arguments sentence considered constraints 1 6enforced. refer second strategy global optimization. scenarioscompatibility function same, constraints need rewriting globalscenario include information concrete predicate.Section 8.3 extensively evaluate presented inference model based Constraint Satisfaction, describe experiments covering following topics: (a)contribution proposed constraints; (b) performance local vs. globaloptimization; (c) precisionrecall tradeo varying value bias-correctionparameter.7.2 Inference Based Learningcombination model consists two stages: candidate scoring phase, scorescandidate arguments pool using series discriminative classiers, inferencestage, selects best overall solution consistent domain constraints.9. Instead working constant, one could try set oi value candidate, takingaccount contextual features candidate. plan explore option near future.127fiSurdeanu, Marquez, Carreras, & Comasrst important component combination strategy candidatescoring module, assigns candidate argument score equal condenceargument part global solution. formed discriminative functions,one role label. Below, devise two dierent strategies train discriminativefunctions.scoring candidate arguments, nal global solution built inferencemodule, looks best scored argument structure satises domain specicconstraints. Here, global solution subset candidate arguments, scoredened sum condence values arguments form it. currently considerthree constraints determine solutions valid:(a) Candidate arguments predicate overlap embed.(b) predicate, duplicate arguments allowed numbered arguments A0-5.(c) Arguments predicate embedded within arguments predicatesoverlap.set constraints extended rules, particular case,know constraints, e.g., providing arguments indicated corresponding PropBank frame, already guaranteed individual models, others, e.g.,constraints 3 4 previous sub-section, positive impact overallperformance (see Section 8.3 empirical analysis). inference algorithm usebottom-up CKY-based dynamic programming strategy (Younger, 1967). buildssolution maximizes sum argument condences satisfying constraints,cubic time.Next, describe two dierent strategies train functions score candidatearguments. rst local strategy: function trained binary batch classier,independently combination process enforces domain constraints.second global strategy: functions trained online rankers, taking accountinteractions take place combination process decide one argumentanother.training strategies, discriminative functions employ representation arguments, using complete feature set described Section 6 (we analyzecontribution feature group Section 8). intuition rich featurespace introduced Section 6 allow gathering sucient statistics robustscoring candidate arguments. example, scoring classiers might learncandidate trusted if: (a) two individual systems proposed it, (b) labelA2 generated Model 1, (c) proposed Model 2 within certainargument sequence.7.2.1 Learning Local Classifierscombination process follows cascaded architecture, learning componentdecoupled inference module. particular, training strategy consiststraining binary classier role label. target label-based classierdetermine whether candidate argument actually belongs correct propositioncorresponding predicate, output condence value decision.128fiCombination Strategies Semantic Role Labelingspecic training strategy follows. training data consists poollabeled candidate arguments (proposed individual systems). candidate eitherpositive, actually correct argument sentence, negative,correct. strategy trains binary classier role label l, independentlylabels. so, concentrates candidate arguments datalabel l. forms dataset binary classication, specic label l. it,binary classier trained using existing techniques binary classication,requirement combination strategy needs condence valuesbinary prediction. Section 8 provide experiments using SVMs train localclassiers.all, classier trained independently classiers inference module. Looking globally combination process, classier seen argumentltering component decides candidates actual arguments using much richerrepresentation individual models. context, inference engine usedconict resolution engine, ensure combined solutions valid argument structures sentences.7.2.2 Learning Global Rankerscombination process couples learning inference, i.e., scoring functionstrained behave accurately within inference module. words, trainingstrategy global: target train global function maps set argumentcandidates sentence valid argument structure. setting, global functioncomposition scoring functions one label, previous strategy.Unlike previous strategy, completely decoupled inference engine,policy map set candidates solution determined inferenceengine.recent years, research active global learning methods tagging,parsing and, general, structure prediction problems (Collins, 2002; Taskar, Guestrin, &Koller, 2003; Taskar, Klein, Collins, Koller, & Manning, 2004; Tsochantaridis, Hofmann,Joachims, & Altun, 2004). article, make use simplest technique globallearning: online learning approach uses Perceptron (Collins, 2002). generalidea algorithm similar original Perceptron (Rosenblatt, 1958): correctingmistakes linear predictor made visiting training examples, additivemanner. key point learning global rankers relies criteria determinesmistake function trained, idea exploitedsimilar way multiclass ranking scenarios Crammer Singer (2003a, 2003b).Perceptron algorithm combination system works follows (pseudocodealgorithm given Figure 7). Let 1 . . . L possible role labels, letW = {w1 . . . wL } set parameter vectors scoring functions, onelabel. Perceptron initializes vectors W zero, proceeds cycletraining examples, visiting one time. case, training example pair (y, A),correct solution example set candidate argumentsit. Note sets labeled arguments, thus make useset dierence. note particular argument, l label a,129fiSurdeanu, Marquez, Carreras, & ComasInitialization: wl W wl = 0Training := 1 . . .training example (y, A)= Inference(A, W)\let l labelwl = wl + (a)\let l labelwl = wl (a)Output: WFigure 7: Perceptron Global Learning Algorithm(a) vector features described Section 6. example, Perceptron performstwo steps. First, predicts optimal solution according current settingW. Note prediction strategy employs complete combination model, includinginference component. Second, Perceptron corrects vectors W accordingmistakes seen y: arguments label l seen promoted vectorwl ; hand, arguments demoted wl . correction rulemoves scoring vectors towards missing arguments, away predicted argumentscorrect. guaranteed that, Perceptron visits examples,feedback rule improve accuracy global combination functionfeature space almost linearly separable (Freund & Schapire, 1999; Collins, 2002).all, training strategy global mistakes Perceptron correctsarise comparing predicted structure correct one. contrast,local strategy identies mistakes looking individually sign scoring predictions:candidate argument (is not) correct solution current scorers predictnegative (positive) condence value, corresponding scorer correctedcandidate argument. Note criteria used generate training dataclassiers trained locally. Section 8 compare approaches empirically.nal note, simplicity described Perceptron simple form.However, Perceptron version use experiments reported Section 8 incorporates two well-known extensions: kernels averaging (Freund & Schapire, 1999; Collins& Duy, 2002). Similar SVM, Perceptron kernel method. is, represented dual form, dot product example vectors generalizedkernel function exploits richer representations. hand, averagingtechnique increases robustness predictions testing. original form,test predictions computed parameters result training process.averaged version, test predictions computed average parametervectors generated training, every update. Details techniquefound original article Freund & Schapire.130fiCombination Strategies Semantic Role Labeling1DevelopmentBrownWSJ0.980.96Acuracy0.940.920.90.880.860.840.820102030405060708090100Reject Rate (%)Figure 8: Rejection curves estimated output probabilities individual models.8. Experimental Resultssection analyze performance three combination strategies previouslydescribed: (a) inference constraint satisfaction, (b) learning-based inference localrankers, (c) learning-based inference global rankers. bulk experiments use candidate arguments generated three individual SRL models describedSection 4 evaluated Section 5.8.1 Experimental Settingscombination strategies (with one exception, detailed below) trained usingcomplete CoNLL-2005 training set (PropBank/Treebank sections 2 21). minimizeovertting individual SRL models training data, partitioned trainingcorpus folds fold used output individual modelstrained remaining four folds. models tuned separate developmentpartition (Treebank section 24) evaluated two corpora: (a) Treebank section 23,(b) three annotated sections Brown corpus.constraint satisfaction model, converted scores output argumentsthree SRL models probabilities using softmax function explained Section 7.1.development set (section 24) used tune parameter softmax formulanal value 0.1 models. order assess quality procedure,plot Figure 8 rejection curves estimated output probabilities respectclassication accuracy development test sets (WSJ Brown). calculateplots, probability estimates three models put together set sorteddecreasing order. certain level rejection (n%), curve Figure 8 plotspercentage correct arguments lowest scoring n% subset rejected.131fiSurdeanu, Marquez, Carreras, & Comasexceptions, curves increasing smooth, indicating good correlationprobability estimates classication accuracy.last experiment, Section 8.6 analyze behavior proposed combinationstrategies candidate pool signicantly larger. experiment usedtop 10 best performing systems CoNLL-2005 shared task evaluation. setuptwo signicant dierences experiments used in-house individualsystems: (a) access systems outputs PropBank developmentsection two test sections, (b) argument probabilities individualmodels available. Thus, instead usual training set, traincombination models PropBank development section smaller feature set. Notealso development set 3.45% size regular training set.evaluated resulting combination models two testing sections: WSJBrown.8.2 Lower Upper Bounds Combination Strategiesventure evaluation combination strategies, explore lowerupper bounds combinations models given corpus individual models.analysis important order understand potential proposed approachsee close actually realizing it.performance upper bound calculated oracle combination systemperfect ltering classier selects correct candidate arguments discardsothers. comparison purposes, implemented second oracle system simulates re-ranking approach: predicate selects candidate frame i.e.,complete set arguments corresponding predicate proposed single modelhighest F1 score. Table 3 lists results obtained WSJ Brown corporatwo oracle systems using three individual models. combination systemoracle simulates combination strategies proposed paper, breakcandidate frames work individual candidate arguments. Note precisionoracle combination system 100% case discontinuous arguments,fragments pass oracle lter considered incorrect scorer corresponding argument complete, e.g., argument A1 appears without continuationC-A1. re-ranking columns list results second oracle system, selectsentire candidate frames.Table 3 indicates upper limit combination approaches proposedpaper relatively high: F1 combination oracle system 14 points higherbest individual system WSJ test set, 17 points higherBrown corpus (see Table 1). Furthermore, analysis indicates potentialcombination strategy higher re-ranking strategies, limitedperformance best complete frame candidate pool. allowing recombination arguments individual candidate solutions threshold raisedsignicantly: 6 F1 points WSJ 9 F1 points Brown.Table 4 lists distribution candidate arguments individual modelsselection performed combination oracle system. conciseness, listcore numbered arguments focus WSJ corpus. 3 indicates percent132fiCombination Strategies Semantic Role LabelingWSJBrownPProps70.76%51.87%CombinationPrecision Recall99.12%85.22%99.63%74.32%F191.6485.14PProps63.51%45.02%Re-RankingPrecision Recall88.08%82.84%80.80%71.70%F185.3875.98Table 3: Performance upper limits detected two oracle systems.A0A1A2A3A4380.45%69.82%56.04%56.03%65.85%212.10%17.83%22.32%21.55%20.73%Model 13.47%7.45%12.20%12.93%6.10%Model 22.14%2.77%4.95%5.17%2.44%Model 31.84%2.13%4.49%4.31%4.88%Table 4: Distribution individual systems arguments upper limit selection,A0A4 WSJ test set.age correct arguments 3 models agreed, 2 indicates percentagecorrect arguments 2 models agreed, columns indicate percentage correct arguments detected single model. Table 4 indicates that, expected,two individual models agreed large percentage correct arguments. Nevertheless, signicant number correct arguments, e.g., 22% A3, come singleindividual system. proves that, order achieve maximum performance, onelook beyond simple voting strategies favor arguments high agreementindividual systems.propose two lower bounds performance combination models using twobaseline systems:rst baseline recall-oriented: merges arguments generatedindividual systems. conict resolution, baseline uses approximate inferencealgorithm consisting two steps: (i) candidate arguments sorted using radixsort orders candidate arguments descending order of: (a) number modelsagreed argument, (b) argument length tokens, (c) performanceindividual system10 ; (ii) Candidates iteratively appended global solutionviolate domain constraints arguments alreadyselected.second baseline precision-oriented: considers arguments threeindividual systems agreed. conict resolution uses strategyprevious baseline system.Table 5 shows performance two baseline models. expected, precisionoriented baseline obtains precision signicantly higher best individual model(Table 1), recall suers individual models agree fairly largenumber candidate arguments. recall-oriented baseline balanced: expectedrecall higher individual model precision drop much10. combination produced highest-scoring baseline model.133fiSurdeanu, Marquez, Carreras, & ComasWSJbaselinebaselineBrownbaselinebaselinerecallprecisionPProps53.71%35.43%Prec.78.09%92.49%Recall78.77%60.48%F178.43 0.873.14 0.9recallprecision36.94%20.52%68.57%88.74%66.05%46.35%67.2960.892.02.1Table 5: Performance baseline models WSJ Brown test sets.inference strategy lters many unlikely candidates. Overall, recalloriented baseline performs best, F1 1.22 points higher best individualmodel WSJ corpus, 0.41 points lower Brown corpus.8.3 Performance Combination System Constraint SatisfactionConstraint Satisfaction setting arguments output individual Models 1, 2,3 recombined expected better solution satises set constraints.run inference model based Constraint Satisfaction described Section 7.1 usingXpress-MP ILP solver11 . main results summarized Table 6. variantspresented table following: Pred-by-pred stands local optimization,processes verb predicate independently others, Full sentence standsglobal optimization, i.e., resolving verb predicates sentencetime. column labeled Constraints shows particular constraints appliedconguration. column presents value parameter correcting biastowards candidate overgeneration. Concrete values empirically set maximize F1measure development set. = 0 corresponds setting bias correctionapplied.clear conclusions drawn Table 6. First, observe optimization variant obtains F1 results individual systems (Table 1)baseline combination schemes (Table 5). best combination model scores 2.61 F1 pointsWSJ 1.49 Brown higher best individual system. Taking accountlearning performed, clear Constraint Satisfaction simple yet formalsetting achieves good results.somewhat surprising result performance improvements come constraints 1 2 (i.e., overlapping embedding among arguments verb,repetition core arguments verb). Constraints 3 4 harmful,sentence-level constraints (5 6) impact overall performance12 .analysis proposed constraints yielded following explanations:Constraint number 3 prevents assignment R-X argument referredargument X present. makes inference miss easy R-X arguments11. Xpress-MP Dash Optimization product free academic usage.12. Section 8.5 see learning strategy incorporates global feedback, performingsentence-level inference slightly better proceeding predicate predicate.134fiCombination Strategies Semantic Role LabelingWSJPred-by-predFull sentenceBrownFull sentenceConstraints11+21+2+31+2+41+2+3+41+2+51+2+61+2+5+61+2+5+60.300.300.250.300.300.300.300.300PProps52.29%52.52%52.31%51.40%51.19%52.53%52.48%52.50%54.49%Precision84.20%84.61%84.34%84.13%83.86%84.63%84.64%84.65%78.74%Recall75.64%75.53%75.48%75.04%74.99%73.53%75.51%75.51%79.78%F179.69 0.879.81 0.679.67 0.779.32 0.879.18 0.779.82 0.779.81 0.879.82 0.679.26 0.71+2+5+61+2+5+60.30035.70%38.06%78.18%69.80%62.06%67.85%69.19 2.168.81 2.2Table 6: Results, WSJ Brown test sets, obtained multiple variants constraint satisfaction approachX argument correctly identied (e.g., constituents start{that, which, who} followed verb always R-A0). Furthermore, constraintpresents lot exceptions: 18.75% R-X arguments WSJ test setreferred argument X (e.g., law tells so),therefore hard application constraint 3 prevents selection correctR-X candidates. ocial evaluation script CoNLL-2005 (srl-eval)require constraint satised consider solution consistent.srl-eval script requires constraint number 4 (i.e., C-X tag acceptedwithout preceding X argument) fullled candidate solution consideredconsistent. nds solution violating constraint behaviorconvert rst C-X (without preceding X) X. turns simplepost-processing strategy better forcing coherent solution inference stepallows recover error argument completelyrecognized labeled C-X tags.Regarding sentence-level constraints, observed setting, inference usinglocal constraints (1+2) rarely produces solution inconsistencies sentencelevel.13 makes constraint 5 useless since almost never violated. Constraintnumber 6 (i.e., sharing AMs among dierent verbs) ad-hoc representsless universal principle SRL. number exceptions constraint,WSJ test set, 3.0% gold-standard data 4.8% outputinference uses local constraints (1+2). Forcing fulllmentconstraint makes inference process commit many errors corrections, makingeect negligible.13. fact partly explained small number overlapping arguments candidate poolproduced three individual models.135fiSurdeanu, Marquez, Carreras, & Comas959095PrecisionRecallF1908080%85%85PrecisionRecallF175757070656560-0.4-0.200.20.40.60.860-0.41Value-0.200.20.40.60.81ValueFigure 9: Precision-Recall plots, respect bias correcting parameter (O),WSJ development test sets (left right plots, respectively).Considering constraints universal, i.e., exceptions existgold standard, seems reasonable convert soft constraints. doneprecomputing compatibility corpora counts using, instance, point-wisemutual information, incorporating eect compatibility function explainedsection 7.1. softening could, principle, increase overall recall combination.Unfortunately, initial experiments showed dierences hard softvariants.Finally, dierences optimized values bias correcting parameter= 0 clearly explained observing precision recall values. defaultversion tends overgenerate argument assignments, implies higher recall costlower precision. contrary, F1 optimized variant conservativeneeds evidence select candidate. result, precision higher recalllower. side eect restrictive argument assignments, numbercorrectly annotated complete propositions also lower optimized setting.preference high-precision vs. high-recall system mostly task-dependant.interesting note constraint satisfaction setting, adjusting precisionrecall tradeo easily done varying value bias correcting score.Figure 9, plot precisionrecall curves respect dierent values parameter (the optimization done using constraints 1, 2, 5, 6). expected, high valuespromote precision demote recall, lower values contrary. Also,see wide range values combined F1 measure almostconstant (the approximate intervals marked using vertical lines), making possibleselect dierent recall precision values global performance (F1 ) near optimal. Parenthetically, note also optimal value estimated development set(O = 0.3) generalizes well WSJ test set.136fiCombination Strategies Semantic Role LabelingWSJModelsModelsModelsModelsBrownModelsModelsModelsModels1+21+32+31+2+3PProps49.28%48.26%49.36%51.66%Prec.87.39%86.80%86.63%87.47%Recall72.88%73.20%73.03%74.67%F179.48 0.679.42 0.679.25 0.780.56 0.6F1 improvement+2.27+2.96+2.04+3.351+21+32+31+2+334.33%31.22%32.84%34.33%81.14%80.43%80.90%81.75%60.86%59.07%60.31%61.32%69.55 2.068.11 1.969.11 2.170.08 2.1+1.85+2.69+1.41+2.38Table 7: Overall results learning-based inference local rankers WSJBrown test sets.8.4 Performance Combination System Local Rankersimplemented candidate-scoring classiers combination strategy using Support Vector Machines (SVM) polynomial kernels degree 2, performed slightlybetter types SVMs AdaBoost. implemented SVM classiersSVMlight software14 . Outside changing default kernel polynomialmodied default parameters. experiments reported section,trained models 4 possible combinations 3 individual systems, usingcomplete feature set introduced Section 6. dynamic programming engine usedactual inference processes predicate independently (similar Pred-by-predapproach previous sub-section).Table 7 summarizes performance combined systems WSJ Browncorpora. Table 7 indicates combination strategy always successful: resultscombination systems improve upon individual models (Table 1) F1scores always better baselines (Table 5). last column table showsF1 improvement combination model w.r.t. best individual model set.expected, highest scoring combined system includes three individual models.F1 measure 3.35 points higher best individual model (Model 2) WSJ testset 2.38 points higher Brown test set. Note combination twoindividual systems outperform current state art (see Section 9 details).empirical proof robust successful combination strategies SRL problempossible. Table 7 also indicates that, even though partial parsing model (Model 1)worst performing individual model, contribution ensemble important,indicating information provides indeed complementary models.instance, WSJ performance combination two best individual models(Models 2+3) worse combinations using model 1 (Models 1+2 1+3).14. http://svmlight.joachims.org/137fiSurdeanu, Marquez, Carreras, & ComasWSJFS1+ FS2+ FS3+ FS4+ FS5+ FS6BrownFS1+ FS2+ FS3+ FS4+ FS5+ FS6PProps50.24%50.39%51.22%50.66%51.38%51.66%Prec.86.47%86.41%86.13%86.67%87.21%87.47%Recall73.51%73.68%74.35%74.10%74.61%74.67%F179.47 0.779.54 0.679.80 0.779.89 0.780.42 0.680.56 0.632.21%32.84%33.33%33.33%34.08%34.33%80.12%80.80%80.29%81.10%81.76%81.75%59.44%59.94%60.82%60.50%61.14%61.32%68.25 2.068.83 2.269.21 2.069.30 2.169.96 2.270.08 1.9Table 8: Feature analysis learning-based inference local rankers.Due simple architecture i.e., feedback conict resolution componentcandidate ltering inference model good framework study contributionfeatures proposed Section 6. study group features 6 sets: FS1voting features, FS2 overlap features arguments predicate, FS3overlap features arguments predicates, FS4 partial-syntax features, FS5full-syntax features, FS6 probabilities generated individual systemscandidate arguments. Using sets constructed 6 combination modelsincreasing number features made available argument ltering classiers, e.g.,rst system uses FS1, second system adds FS2 rst systems features,FS3 added third system, etc. Table 8 lists performance 6 systemstwo test corpora. empirical analysis indicates feature setshighest contribution are:FS1, boosts F1 score combined system 2.26 points (WSJ) 0.55points (Brown) best individual system. yet another empirical proofvoting successful combination strategy.FS5, contribution 0.53 points (WSJ) 0.66 points (Brown) F1score. numbers indicate ltering classier capable learningpreferences individual models certain syntactic structures.FS3, contributes 0.26 points (WSJ) 0.38 points (Brown) F1 score.results promote idea information overall sentence structure,case inter-predicate relations, successfully used problem SRL.knowledge, novel.proposed features positive contribution performance combinedsystem. Overall, achieve F1 score 1.12 points (WSJ) 2.33 points (Brown)higher best performing combined system CoNLL-2005 shared task evaluation(see Section 9 details).138fiCombination Strategies Semantic Role Labeling8.5 Performance Combination System Global Rankerssection report experiments global Perceptron algorithm describedSection 7.2.2, globally trains scoring functions rankers. Similar localSVM models, use polynomial kernels degree 2. Furthermore, predictions testtime used averages parameter vectors, following technique Freund Schapire(1999).interested two main aspects. First, evaluate eect trainingscoring functions Perceptron using two dierent update rules, one globallocal. global feedback rule, detailed Section 7.2.2, corrects mistakes foundcomparing correct argument structure one results inference (thisnoted global feedback). contrast, local feedback rule corrects mistakesfound inference, candidate argument handled independently, ignoringglobal argument structure generated (this noted local feedback). Second,analyze eect using dierent constraints inference module. extent,congured inference module two ways. rst processes predicatessentence independently, thus might select overlapping arguments dierent predicates,incorrect according domain constraints (this one noted Pred-by-predinference). second processes predicates jointly, enforces hierarchical structurearguments, arguments never overlap, arguments predicate allowedembed arguments predicates (this noted Full sentence inference).perspective, model local update Pred-by-pred inference almost identicallocal combination strategy described Section 8.4, unique dierenceuse Perceptron instead SVM. apparently minute dierence turnssignicant empirical analysis allows us measure contributionSVM margin maximization global feedback classier-based combinationstrategy (see Section 8.7).trained four dierent models: local global feedback, predicate-bypredicate joint inference. model trained 5 epochs training data,evaluated development data training epoch. selected bestperforming point development, evaluated models test data. Table 9reports results test data.Looking results, rst impression dierence F1 measuresignicant among dierent congurations. However, observations pointed out.Global methods achieve much better recall gures, whereas local methods prioritizeprecision system. Overall, global methods achieve balanced tradeoprecision recall, contributes better F1 measure.Looking Pred-by-pred versus Full sentence inference, seenglobal methods sensitive dierence. Note local model trainedindependently inference module. Thus, adding constraints inferenceengine change parameters local model. testing time, dierentinference congurations aect results. contrast, global models traineddependently inference module. moving Pred-by-pred Full sentenceinference, consistency enforced argument structures dierent predicates,benets precision recall method. global learning algorithm139fiSurdeanu, Marquez, Carreras, & ComasWSJPred-by-pred, localFull sentence, localPred-by-pred, globalFull sentence, globalBrownPred-by-pred, localFull sentence, localPred-by-pred, globalFull sentence, globalPProps50.71%50.67%53.45%53.81%Prec.86.80%86.80%84.66%84.84%Recall74.31%74.29%76.19%76.30%F180.07 0.780.06 0.780.20 0.780.34 0.633.33%33.33%35.20%35.95%80.62%80.67%77.65%77.91%60.77%60.77%62.70%63.02%69.30 1.969.32 2.069.38 1.969.68 2.0Table 9: Test results combination system global rankers. Four congurationsevaluated, combine Pred-by-pred Full sentence inference localglobal feedback.improves precision recall coupled joint inference processconsiders constraints solution.Nevertheless, combination system local SVM classiers, presented previous section, achieves marginally better F1 score global learning method (80.56% vs.80.34% WSJ). explained dierent machine learning algorithms (we discussissue detail Section 8.7). better F1 score accomplished much betterprecision local approach (87.47% vs. 84.84% WSJ), whereas recall lowerlocal global approach (74.67% vs. 76.30% WSJ). hand,global strategy produces completely-correct annotations (see PProps column)local strategies investigated (see Tables 9 7). expected,considering global strategy optimizes sentence-level cost function. Somewhatsurprisingly, number perfect propositions generated global strategy lowernumber perfect propositions produced constraint-satisfaction approach.discuss result Section 8.7.8.6 Scalability Combination Strategiescombination experiments reported point used candidate argumentsgenerated three individual SRL models introduced Section 4. experiments provide empirical comparison three inference models proposed,answer obvious scalability question: proposed combination approachesscale number candidate arguments increases quality diminishes?mainly interested answering question last two combination models (whichuse inference based learning local global rankers) two reasons: (a)performed better constraint satisfaction model previous experiments,(b) requirements individual SRL systems outputs unlikeconstraint satisfaction model requires argument probabilities individual models coupled pools candidates generated individual SRLmodel.140fiCombination Strategies Semantic Role Labelingkoomenpradhan+haghighimarquezpradhansurdeanutsaichemoschittitjongkimsangyiozgencilWSJPrec.Recall82.28%76.78%82.95% 74.75%79.54% 77.39%79.55%76.45%50.14%81.97%73.27%77.3736.44%73.73%61.51%67.0745.28%45.43%47.81%47.66%45.85%80.32%82.77%80.48%76.55%79.03%72.95%70.90%72.79%75.24%72.03%76.4676.3876.4475.8975.3729.48%30.47%31.84%30.85%28.36%72.41%73.21%71.13%65.92%70.45%59.67%59.49%59.99%61.83%60.13%65.4265.6465.0963.8164.88F179.4478.6378.4577.97PProps32.34%38.93%37.06%36.44%BrownPrec.Recall73.38%62.93%74.49% 63.30%70.24% 65.37%70.79%64.35%PProps53.79%52.61%56.52%51.85%F167.7568.4467.7167.4247.50%77.51%72.97%75.1731.09%67.88%59.03%63.1446.19%74.66%74.21%74.4431.47%65.52%62.93%64.20Table 10: Performance best systems CoNLL-2005. pradhan+ contains postevaluation improvements. top 5 systems actually combination modelsthemselves. second column marks systems used evaluation: pradhan, replaced improved version pradhan+,yi, due format errors submitted data.scalability analysis, use individual SRL models top 10 systemsCoNLL-2005 shared task evaluation. Table 10 summarizes performance systemstwo test corpora used previous experiments. Table 10 indicates,performance systems varies widely: dierence 5 F1 points WSJcorpus 4 F1 points Brown corpus best worst systemset.combination experiments generated 5 candidate pools using top 2, 4, 6,8, 10 individual systems labeledTable 10. make two changesexperimental setup used rst part section: (a) trained combined models PropBank development section accessindividual systems outputs PropBank training partition; (b) featureset introduced Section 6 use individual systems argument probabilitiesraw activations individual models classiers available. Notesettings size training corpus 10 times smaller sizetraining set used previous experiments.Table 11 shows upper limits setups using combination reranking oracle systems introduced Section 8.2. Besides performance numbers, alsolist Table 11 average number candidates per sentence setup, i.e., numberunique candidate arguments (# Args./Sent.) combination oracle numberunique candidate frames (# Frames/Sent.) re-ranking oracle. Table 12 listsperformance combined models local feedback (Section 7.2.1) globalfeedback (Section 7.2.2). combination strategy global rankers uses joint inferenceglobal feedback (see description previous sub-section).141fiSurdeanu, Marquez, Carreras, & ComasWSJC2C4C6C8C10BrownC2C4C6C8C10# Args./Sent.8.539.7810.2310.7411.337.428.999.6210.2410.86CombinationPrec.Recall99.34%82.71%99.47%87.26%99.47%88.02%99.48%88.63%99.50% 89.02%99.62%99.65%99.65%99.66%99.66%71.34%77.58%79.38%80.52%81.72%F190.2792.9693.3993.7593.97Re-Ranking# Frames/Sent.Prec.3.1688.63%4.4491.08%7.2192.14%8.1192.88%8.9793.31%83.1487.2488.3789.0889.803.024.557.098.199.2182.45%86.01%88.19%88.95%89.65%Recall81.77%86.12%86.57%87.33%87.71%F185.0788.5389.2790.0290.4270.37%75.98%76.80%78.04%79.19%75.9480.6882.1083.1484.10Table 11: Performance upper limits determined oracle systems 10 best systems CoNLL-2005. Ck stands combination top k systemsTable 10. # Args./Sent. indicates average number candidate argumentsper sentence combination oracle; # Frames/Sent. indicates averagenumber candidate frames per sentence re-ranking oracle. latterlarger number systems combination averagemultiple predicates per sentence.WSJC2C4C6C8C10BrownC2C4C6C8C10PProps50.69%55.14%54.85%54.36%53.90%LocalPrec.86.60%86.67%87.45%87.49%87.48%rankerRecall73.90%76.63%76.34%76.12%75.81%F179.750.781.380.781.520.681.410.681.230.6PProps52.7454.9555.2155.0054.76Global rankerPrec.Recall84.07% 75.38%84.00% 77.19%84.24% 77.41%84.42% 77.10%84.02% 77.44%F179.490.780.450.780.680.780.590.780.600.732.71%35.95%35.32%35.95%36.32%79.56%80.27%80.94%81.98%82.61%60.45%63.16%62.24%61.87%61.97%68.701.870.692.070.371.870.522.270.812.035.3239.3037.4438.4337.4474.88%75.63%76.12%76.40%75.94%68.092.069.592.269.882.069.702.269.862.062.43%64.45%64.58%64.08%64.68%Table 12: Local versus global ranking combinations 10 best systems CoNLL2005. Ck stands combination top k systems Table 10.draw several conclusions experiments. First, performance upper limit re-ranking always lower argument-based combinationstrategy, even number candidates large. example, 10 individualmodels used, F1 upper limit approach Brown corpus 89.80 whereasF1 upper limit re-ranking 84.10. However, enhanced potential combination approach imply signicant increase computational cost: Table 11 shows142fiCombination Strategies Semantic Role Labelingnumber candidate arguments must handled combination approachesmuch higher number candidate frames input re-ranking system, especially number individual models high. example, 10individual models used, combination approaches must process around 11 argumentsper sentence, whereas re-ranking approaches must handle approximately 9 frames per sentence. intuition behind relatively small dierence computational cost that,even though number arguments signicantly larger number frames,dierence number unique candidates two approaches highprobability repeated arguments higher probability repeatedframes.second conclusion combination models boost performancecorresponding individual systems. example, best 4-system combination achievesF1 score approximately 2 points higher best individual model WSJBrown corpus. expected, combination models reach performance plateauaround 4-6 individual systems, quality individual models starts dropsignicantly. Nevertheless, considering top 4 individual systems use combinationstrategies amount training data experiment quite small,results show good potential combination models analyzed paper.third observation relation previously observed local globalrankers holds: combination model local rankers better precision, modelglobal rankers always better recall generally better PProps score. Overall,model local rankers obtains better F1 scores scales better numberindividual systems increases. discuss dierences detail nextsub-section.Finally, Table 11 indicates potential recall experiment (shownleft-most block table) higher potential recall combining threeindividual SRL systems (see Table 3): 3.8% higher WSJ test set, 7.4% higherBrown test set. expected, considering number qualitycandidate arguments last experiment higher. However, evenimprovement, potential recall combination strategies far 100%. Thus,combining solutions N best state-of-the-art SRL systems stillpotential properly solve SRL problem. Future work focus recallboosting strategies, e.g., using candidate arguments individual systemsindividual complete solutions generated, step many candidate argumentseliminated.8.7 Discussionexperimental results presented section indicate proposed combinationstrategies successful: three combination models provide statistically signicant improvements individual models baselines setups. immediate (butsomewhat shallow) comparison three combination strategies investigated indicatesthat: (a) best combination strategy SRL problem max-margin local metalearner; (b) global ranking approach meta-learner important143fiSurdeanu, Marquez, Carreras, & Comascontribution max-margin strategy; (c) constraint-satisfactionmodel performs worst strategies tried.However, experiments dierences combination approaches investigated small. reasonable observation combination strategyadvantages disadvantages dierent approaches suitable dierentapplications data. discuss dierences below.argument probabilities individual systems available, combination modelbased constraint satisfaction attractive choice: simple, unsupervised strategy obtains competitive performance. Furthermore, constraint satisfaction modelprovides elegant customizable framework tune balance precisionrecall (see Section 8.3). framework currently obtain highest recallcombination models: 3.48% higher best recall obtained meta-learning approaches WSJ corpus, 4.83% higher meta-learning models Browncorpus. higher recall implies also higher percentage predicates completelycorrectly annotated: best PProps numbers Table 6 best combinationstrategies. cause high dierence recall favor constraint satisfactionapproach candidate scoring learning-based inference acts implicitlylter: candidates whose score i.e., classier condence candidate partcorrect solution negative discarded, negatively aects overall recall.Hence, constraint satisfaction better solution SRL-based NLP applicationsrequire predicate-argument frames extracted high recall. example, Information Extraction, predicate-argument tuples ltered subsequent high-precision,domain-specic constraints (Surdeanu et al., 2003), hence paramount SRLmodel high recall.Nevertheless, many cases argument probabilities individual SRL modelsavailable, either models generate them, e.g., rule-based systems,individual models available black boxes, oer accessinternal information. conditions, showed combination strategies basedmeta-learning viable alternative. fact, approaches obtain highestF1 scores (see Section 8.4) obtain excellent performance even small amountstraining data (see Section 8.6). previously mentioned, candidate scoring actslter, learning-based inference tends favor precision recall: precision2.82% higher best precision constraint-satisfaction models WSJcorpus, 3.57% higher Brown corpus. preference precision recallpronounced learning-based inference local rankers (Section 8.4)inference model global rankers (Section 8.5). hypothesis causesglobal-ranking model less precision-biased conguration ratioerrors positive versus negative samples balanced. Thinking strategyPerceptron follows, local approach updates every candidate incorrect predictionsign, whereas global approach updates candidatescomplete solution, enforcing domain constraints. words, numbernegative updates drives precision bias reduced global approach,false positives generated ranking classiers eliminateddomain constraints. Thus, candidate scoring trained optimize accuracy,144fiCombination Strategies Semantic Role LabelingWSJglobal feedbackmax marginBrownglobal feedbackmax marginPProps+3.10%+0.95%Prec.-1.96%+0.67%Recall+1.99%+0.36%F1+0.27+0.49+2.62%+1.00%-2.71%+1.13%+2.25%+0.55%+0.38+0.78Table 13: Contribution global feedback max margin learning-based inference.baseline Pred-by-pred, local model Table 9.fewer candidate arguments eliminated meta-learner global rankers,translates better balance precision recall.Another important conclusion analysis global versus local rankinglearning-based inference max-margin approach candidate scoring classiersimportant global feedback inference. fact, consideringdierence model predicate-by-predicate inference local feedbackSection 8.5 (Pred-by-pred, local) versus best model Section 8.4 (+FS6)latter uses SVM classiers whereas former uses Perceptron, compute exactcontribution max margin global feedback15 . convenience, summarizeanalysis Table 13. table indicates max margin yields consistent improvementprecision recall, whereas contribution global feedback reducingdierence precision recall boosting recall decreasing precision.benet max-margin classiers even evident Table 12, showslocal-ranking model max-margin classiers generalizes better global-rankingmodel amount training data reduced signicantly.Even though paper analyzed several combination approaches threeindependent implementations, proposed models fact compatible other.Various combinations proposed strategies immediately possible. example,constraint satisfaction model applied output probabilities candidatescoring component introduced Section 7.2. model eliminates dependencyoutput scores individual SRL models retains advantagesconstraint satisfaction model, e.g., formal framework tune balance precision recall. Another possible combination approaches introduced paperuse max-margin classiers learning-based inference global feedback, e.g.,using global training method margin maximization SVMstruct (Tsochantaridis et al., 2004). model would indeed increased training time16 , couldleverage advantages max-margin classiers inference global feedback(summarized Table 13). Finally, another attractive approach stacking, i.e., N levels chained meta-learning. example, could cascade learning-based inferencemodel global rankers, boosts recall, learning-based inference localrankers, favors precision.15. contribution global feedback given model joint inference global feedback (Fullsentence, global) Section 8.5.16. main reason chose Perceptron proposed online strategies.145fiSurdeanu, Marquez, Carreras, & Comas9. Related Work4 best performing systems CoNLL-2005 shared task included combinationdierent base subsystems increase robustness gain coverage independenceparse errors. Therefore, closely related work paper. rstfour rows Table 10 summarize results exactly experimental settingone used paper.Koomen et al. (2005) used 2 layer architecture close ours. pool candidatesgenerated by: (a) running full syntax SRL system alternative input information (Collinsparsing, 5-best trees Charniaks parser), (b): taking candidates passlter set dierent parse trees. combination candidates performedelegant global inference procedure constraint satisfaction, which, formulatedInteger Linear Programming, solved eciently. dierent work,break complete solutions number SRL systems also investigatemeta-learning combination approach addition ILP inference. Koomen et al.ssystem best performing system CoNLL-2005 (see Table 10).Haghighi et al. (2005) implemented double re-ranking top several outputsbase SRL model. re-ranking performed, rst, set n-best solutions obtainedbase system run single parse tree, and, then, set best-candidatescoming n-best parse trees. second-best system CoNLL-2005(third row Table 10). Compared decomposition re-combination approach,re-ranking setting advantage allowing denition global featuresapply complete candidate solutions. According follow-up work authors(Toutanova, Haghighi, & Manning, 2005), global features source majorperformance improvements re-ranking system. contrast, focus featuresexploit redundancy individual models, e.g., overlap individualcandidate arguments, add global information frame level completesolutions provided individual models. main drawback re-ranking comparedapproach dierent individual solutions combined re-rankingforced select complete candidate solution. implies overall performancestrongly depends ability base model generate complete correct solutionset n-best candidates. drawback evident lower performance upperlimit re-ranking approach (see Tables 3 11) performance actualsystem best combination strategy achieves F1 score 2 points higherHaghighi et al. WSJ Brown17 .Finally, Pradhan, Hacioglu, Ward, Martin, Jurafsky (2005b) followed stackingapproach learning two individual systems based full syntax, whose outputs usedgenerate features feed training stage nal chunk-by-chunk SRL system. Althoughne granularity chunking-based system allows recover parsing errors,nd combination scheme quite ad-hoc forces break argument candidateschunks last stage.17. Recently, Yih Toutanova (2006) reported improved numbers system: 80.32 F1 WSJ68.81 Brown. However, numbers directly comparable systems presentedpaper fixed significant bug representation quotes input data, bugstill present data.146fiCombination Strategies Semantic Role LabelingOutside CoNLL shared task evaluation, Roth Yih (2005) reached conclusion quality local argument classiers important globalfeedback inference component. also one conclusions drawn paper. contribution shown hypothesis holds complexframework: combination several state-of-the-art individual models, whereas RothYih experimented single individual model, numbered arguments, slightlysimplied problem representation: B-I-O basic chunks. Additionally, detailedexperiments allowed us show clearly contribution max margin higherglobal learning several corpora several combinations individual systems.Punyakanok, Roth, Yih (2005) showed performance individual SRLmodels (particularly argument identication) signicantly improved full parsingused argument boundaries restricted match syntactic constituents (similarlyModel 3). believe approach used Models 1 2, candidatearguments match single syntactic constituent, increased robustnessbuilt-in mechanism handle syntax errors, argument constituent incorrectly fragmented multiple phrases. empirical results supportclaim: Model 2 performs better Model 3 models proposed Punyakanoket al. second advantage strategy proposed paper modeldeployed using full syntax (Model 2) partial syntax (Model 1).Pradhan, Ward, Hacioglu, Martin, Jurafsky (2005c) implement SRL combinationstrategy constituent level that, similarly approach, combines dierent syntacticviews data based full partial syntactic analysis. However, unlike approach,Pradhan et al.s work uses simple greedy inference strategy based probabilitiescandidate arguments, whereas paper introduce analyze three dierentcombination algorithms. analysis yielded combination system outperformscurrent state art.Previous work general eld predicting structures natural languagetexts indicated combination several individual models improves overall performance given task. Collins (2000) rst proposed learning layer based rankingimprove performance generative syntactic parser. approach, rerankertrained select best solution pool solutions produced generativeparser. so, reranker dealt complete parse trees, representedrich features exploited dependencies considered generative method.hand, computationally feasible train reranker, base methodreduced number possible parse trees sentence exponential number (w.r.t.sentence length) tens. recently, global discriminative learning methodspredicting structures proposed (Laerty, McCallum, & Pereira, 2001; Collins,2002, 2004; Taskar et al., 2003, 2004; Tsochantaridis et al., 2004). trainsingle discriminative ranking function detect structures sentence. major propertymethods model problem discriminatively, arbitraryrich representations structures used. Furthermore, training processmethods global, parameters set maximize measures relatedlocal accuracies (i.e., recognizing parts structure), also related globalaccuracy (i.e., recognizing complete structures). article, use globalrich representations also major motivation.147fiSurdeanu, Marquez, Carreras, & Comas10. Conclusionspaper introduces analyzes three combination strategies context semanticrole labeling: rst model implements inference strategy constraint satisfactionusing integer linear programming, second uses inference based learningcandidates scored using discriminative classiers using local information,third last inference model builds previous strategy adding global feedbackconict resolution component ranking classiers. meta-learners usedinference process developed rich set features includes votingstatistics i.e., many individual systems proposed candidate argument overlaparguments predicates sentence, structure distanceinformation coded using partial full syntax, probabilities individual SRLmodels (if available). knowledge, rst work that: (a) introduces thoroughinference model based learning semantic role labeling, (b) performs comparativeanalysis several inference strategies context SRL.results presented suggest strategy decomposing individual solutionsperforming learning-based re-combination constructing nal solution advantages approaches, e.g., re-ranking set complete candidate solutions.course, task-dependant conclusion. case semantic role labeling, approach relatively simple since re-combination argument candidates fulllset structural constraints generate consistent solution. target structure complex (e.g., full parse tree) re-combination step might complexlearning search perspectives.evaluation indicates proposed combination approaches successful:provide signicant improvements best individual model several baselinecombination algorithms setups. three combination strategies investigated,best F1 score obtained learning-based inference using max-margin classiers.proposed approaches advantages drawbacks (see Section 8.7detailed discussion dierences among proposed inference models) several important features state-of-the-art SRL combination strategy emerge analysis:(i) individual models combined granularity candidate arguments rathergranularity complete solutions frames; (ii) best combination strategyuses inference model based learning; (iii) learning-based inference benetsmax-margin classiers global feedback, (iv) inference sentence level (i.e.,considering predicates time) proves slightly useful learningperformed also globally, using feedback complete solution inference.Last least, results obtained best combination strategy developedwork outperform current state art. results empirical proofSRL system good performance built combining small number (threeexperiments) relatively simple SRL models.Acknowledgmentswould like thank JAIR reviewers valuable comments.research partially supported European Commission (CHIL project,148fiCombination Strategies Semantic Role LabelingIP-506909; PASCAL Network, IST-2002-506778) Spanish Ministry EducationScience (TRANGRAM, TIN2004-07925-C03-02). Mihai Surdeanu research fellowwithin Ramon Cajal program Spanish Ministry Education Science.also grateful Dash Optimization free academic use Xpress-MP.ReferencesBishop, C. (1995). Neural Networks Pattern Recognition. Oxford University Press.Boas, H. C. (2002). Bilingual framenet dictionaries machine translation. ProceedingsLREC 2002.Carreras, X., & Marquez, L. (2004). Introduction CoNLL-2004 shared task: Semanticrole labeling. Proceedings CoNLL 2004.Carreras, X., & Marquez, L. (2005). Introduction conll-2005 shared task: Semanticrole labeling. Proceedings CoNLL-2005.Carreras, X., Marquez, L., & Chrupala, G. (2004). Hierarchical recognition propositionalarguments perceptrons. Proceedings CoNLL 2004 Shared Task.Charniak, E. (2000). maximum-entropy-inspired parser. Proceedings NAACL.Collins, M. (1999). Head-Driven Statistical Models Natural Language Parsing. PhDDissertation, University Pennsylvania.Collins, M. (2000). Discriminative reranking natural language parsing. Proceedings17th International Conference Machine Learning, ICML-00, Stanford, CAUSA.Collins, M. (2002). Discriminative training methods hidden markov models: Theoryexperiments perceptron algorithms. Proceedings SIGDAT ConferenceEmpirical Methods Natural Language Processing, EMNLP-02.Collins, M. (2004). Parameter estimation statistical parsing models: Theory practice distribution-free methods. Bunt, H., Carroll, J., & Satta, G. (Eds.), NewDevelopments Parsing Technology, chap. 2. Kluwer.Collins, M., & Duy, N. (2002). New ranking algorithms parsing tagging: Kernelsdiscrete structures, voted perceptron. Proceedings 40th AnnualMeeting Association Computational Linguistics, ACL02.Crammer, K., & Singer, Y. (2003a). family additive online algorithms categoryranking. Journal Machine Learning Research, 3, 10251058.Crammer, K., & Singer, Y. (2003b). Ultraconservative online algorithms multiclassproblems. Journal Machine Learning Research, 3, 951991.Freund, Y., & Schapire, R. E. (1999). Large margin classication using perceptronalgorithm. Machine Learning, 37 (3), 277296.Gildea, D., & Jurafsky, D. (2002). Automatic labeling semantic roles. ComputationalLinguistics, 28 (3).149fiSurdeanu, Marquez, Carreras, & ComasGildea, D., & Palmer, M. (2002). necessity syntactic parsing predicate argumentrecognition. Proceedings 40th Annual Conference AssociationComputational Linguistics (ACL-02).Hacioglu, K., Pradhan, S., Ward, W., Martin, J. H., & Jurafsky, D. (2004). Semanticrole labeling tagging syntactic chunks. Proceedings 8th ConferenceComputational Natural Language Learning (CoNLL-2004).Haghighi, A., Toutanova, K., & Manning, C. (2005). joint model semantic role labeling.Proceedings CoNLL-2005 Shared Task.Koomen, P., Punyakanok, V., Roth, D., & Yih, W. (2005). Generalized inferencemultiple semantic role labeling systems. Proceedings CoNLL-2005 Shared Task.Laerty, J., McCallum, A., & Pereira, F. (2001). Conditonal random elds: Probabilistic models segmenting labeling sequence data. Proceedings 18thInternational Conference Machine Learning, ICML-01.Marcus, M., Santorini, B., & Marcinkiewicz, M. (1994). Building large annotated corpusEnglish: Penn Treebank. Computational Linguistics, 19 (2).Marquez, L., Comas, P., Gimenez, J., & Catala, N. (2005). Semantic role labelingsequential tagging. Proceedings CoNLL-2005 Shared Task.Melli, G., Wang, Y., Liu, Y., Kashani, M. M., Shi, Z., Gu, B., Sarkar, A., & Popowich,F. (2005). Description SQUASH, SFU question answering summary handlerDUC-2005 summarization task. Proceedings Document UnderstandingWorkshop, HLT/EMNLP Annual Meeting.Narayanan, S., & Harabagiu, S. (2004). Question answering based semantic structures.International Conference Computational Linguistics (COLING 2004).Noreen, E. W. (1989). Computer-Intensive Methods Testing Hypotheses. John Wiley &Sons.Palmer, M., Gildea, D., & Kingsbury, P. (2005). Proposition Bank: annotatedcorpus semantic roles. Computational Linguistics, 31 (1).Ponzetto, S. P., & Strube, M. (2006a). Exploiting semantic role labeling, wordnetwikipedia coreference resolution. Proceedings Human Language TechnolgyConference North American Chapter Association Computational Linguistics.Ponzetto, S. P., & Strube, M. (2006b). Semantic role labeling coreference resolution.Companion Volume Proceedings 11th Meeting European ChapterAssociation Computational Linguistics.Pradhan, S., Hacioglu, K., Krugler, V., Ward, W., Martin, J. H., & Jurafsky, D. (2005a).Support vector learning semantic argument classication. Machine Learning, 60,1139.Pradhan, S., Hacioglu, K., Ward, W., Martin, J. H., & Jurafsky, D. (2005b). Semantic rolechunking combining complementary syntactic views. Proceedings CoNLL-2005.150fiCombination Strategies Semantic Role LabelingPradhan, S., Ward, W., Hacioglu, K., Martin, J. H., & Jurafsky, D. (2005c). Semantic rolelabeling using dierent syntactic views. Proceedings 43rd Annual ConferenceAssociation Computational Linguistics.Punyakanok, V., Roth, D., & Yih, W. (2005). necessity syntactic parsing semantic role labeling. Proceedings International Joint Conference ArtificialIntelligence (IJCAI).Punyakanok, V., Roth, D., Yih, W., & Zimak, D. (2004). Semantic role labeling via integer linear programming inference. Proceedings International ConferenceComputational Linguistics (COLING04).Rosenblatt, F. (1958). perceptron: probabilistic model information storageorganization brain. Psychological Review, 65, 386407.Roth, D., & Yih, W. (2004). linear programming formulation global inferencenatural language tasks. Proceedings Annual Conference ComputationalNatural Language Learning (CoNLL-2004), pp. 18, Boston, MA.Roth, D., & Yih, W. (2005). Integer linear programming inference conditional randomelds. Proceedings International Conference Machine Learning (ICML).Schapire, R. E., & Singer, Y. (1999). Improved boosting algorithms using condence-ratedpredictions. Machine Learning, 37 (3).Surdeanu, M., Harabagiu, S., Williams, J., & Aarseth, P. (2003). Using predicate-argumentstructures information extraction. Proceedings 41st Annual MeetingAssociation Computational Linguistics (ACL 2003).Taskar, B., Guestrin, C., & Koller, D. (2003). Max-Margin Markov Networks. Proceedings17th Annual Conference Neural Information Processing Systems, NIPS-03,Vancouver, Canada.Taskar, B., Klein, D., Collins, M., Koller, D., & Manning, C. (2004). Max-margin parsing.Proceedings EMNLP-2004.Toutanova, K., Haghighi, A., & Manning, C. (2005). Joint learning improves semantic rolelabeling. Proceedings 43rd Annual Meeting Association Computational Linguistics (ACL05), pp. 589596, Ann Arbor, MI, USA. AssociationComputational Linguistics.Tsochantaridis, I., Hofmann, T., Joachims, T., & Altun, Y. (2004). Support vector machinelearning interdependent structured output spaces. Proceedings 21stInternational Conference Machine Learning, ICML-04.Xue, N., & Palmer, M. (2004). Calibrating features semantic role labeling. ProceedingsEMNLP-2004.Yih, S. W., & Toutanova, K. (2006). Automatic semantic role labeling. TutorialHuman Language Technolgy Conference North American ChapterAssociation Computational Linguistics.Younger, D. H. (1967). Recognition parsing context-free languages n3 time.Information Control, 10 (2), 189208.151fiJournal Artificial Intelligence Research 29 (2007) 353389Submitted 9/06; published 8/07Answer Sets Logic Programs Arbitrary AbstractConstraint AtomsTran Cao SonEnrico PontelliPhan Huy Tutson@cs.nmsu.eduepontell@cs.nmsu.edutphan@cs.nmsu.eduComputer Science DepartmentNew Mexico State UniversityLas Cruces, NM 88003, USAAbstractpaper, present two alternative approaches defining answer sets logicprograms arbitrary types abstract constraint atoms (c-atoms). approachesgeneralize fixpoint-based level mapping based answer set semantics normallogic programs case logic programs arbitrary types c-atoms. resultsfour different answer set definitions equivalent applied normal logicprograms.standard fixpoint-based semantics logic programs generalized two directions, called answer set reduct answer set complement. definitions,differ treatment negation-as-failure (naf ) atoms, make useimmediate consequence operator perform answer set checking, whose definition reliesnotion conditional satisfaction c-atoms w.r.t. pair interpretations.two definitions, called strongly weakly well-supported models, generalizations notion well-supported models normal logic programs caseprograms c-atoms. case fixpoint-based semantics, differencetwo definitions rooted treatment naf atoms.prove answer sets reduct (resp. complement) equivalent weakly(resp. strongly) well-supported models program, thus generalizing theoremcorrespondence stable models well-supported models normal logicprogram class programs c-atoms.show newly defined semantics coincide previously introduced semantics logic programs monotone c-atoms, extend original answer setsemantics normal logic programs. also study properties answer sets programs c-atoms, relate definitions several semantics logic programsaggregates presented literature.1. Introduction MotivationLogic programming answer set semantics introduced attractivesuitable knowledge representation language AI research (Baral, 2005), offersseveral desirable properties type applications. Among things, languagedeclarative simple syntax; naturally supports non-monotonic reasoning,sufficiently expressive representing several classes problems (e.g., normal logicprograms capture class NP-complete problems); solid theoretical foundationslarge body building block results (e.g., equivalence programs, systematicc2007AI Access Foundation. rights reserved.fiSon, Pontelli, & Tuprogram development, relationships non-monotonic formalisms), extremelyuseful development validation large knowledge bases; also large numberefficient computational tools. discussion issues, interested readerreferred book Baral (2003), overview paper Gelfond Leone (2002),paper Marek Truszczynski (1999), paper Niemela (1999).large number extensions logic programming, aimed improving usabilitycontext knowledge representation reasoning, proposed. Smodelssystem introduces weight cardinality constraint atoms facilitate encodingconstraints atom definitions (Simons, Niemela, & Soininen, 2002). constructsgeneralized aggregates; aggregates extensively studied generalcontext logic programming work (see, e.g., Kemp & Stuckey, 1991; Mumick,Pirahesh, & Ramakrishnan, 1990; Gelder, 1992), developed recent years (see,e.g., DellArmi, Faber, Ielpa, Leone, & Pfeifer, 2003; Denecker, Pelov, & Bruynooghe, 2001;Elkabani, Pontelli, & Son, 2004; Faber, Leone, & Pfeifer, 2004; Gelfond, 2002; Pelov, 2004;Son & Pontelli, 2007). dlv (Eiter, Leone, Mateis, Pfeifer, & Scarcello, 1998)Smodels extended deal various classes aggregates (DellArmi et al.,2003; Elkabani, Pontelli, & Son, 2005). semantics extensions definedeither indirectly, translating programs extensions normal logic programs,directly, providing new characterizations concept answer sets programsextensions.mentioned extensions logic programming introducedfacilitate representation desirable type knowledge logic programming.such, surprise focus definition semanticslittle done investigate basic building block results new classeslogic programs. context, study uniform framework covering various classesextensions provide us several benefits. example, prove (or disprove) whetherbasic building block result (e.g., splitting theorem) extended new classeslogic programs, need prove (or disprove) result once; new resultsstudy generic framework applicable study one aforementionedextensions; etc. Naturally, studies possible, uniform framework whosesemantical definition exhibits behavior various extensions logic programming, needsdeveloped. main goal paper address issue.concept logic programs abstract constraint atoms (or c-atoms)introduced Marek, Remmel, Truszczynski elegant theoretical frameworkinvestigating, uniform fashion, various extensions logic programming, including cardinality constraint atoms, weight constraint atoms, general forms aggregates(Marek & Remmel, 2004; Marek & Truszczynski, 2004). Intuitively, c-atom representsconstraint models program containing Aand description includesexplicit description conditions interpretation meet order satisfyA. view general, shown subsume description traditional classes aggregates (e.g., Sum, Count, Min, etc.).1 Thus, programs weightconstraint atoms aggregates represented logic programs c-atoms.1. One could also argue c-atoms general aggregates capture analogous notions.354fiLogic Programs Arbitrary Abstract Constraint Atomsfirst explicit definition answer sets positive programs arbitrary c-atoms(i.e., programs without negation-as-failure operator)called programs set constraints SC-programshas introduced work Marek Remmel (2004).work answer sets programs c-atoms defined extending notionanswer sets programs weight constraint atoms proposed work Niemela,Simons, Soininen (1999). Nevertheless, approach provides, certain cases, unintuitive answer sets (see, e.g., Examples 7 20). particular, approach MarekRemmel naturally capture well-agreed semantics aggregates.One main goals paper investigate alternative solutions problemcharacterizing answer sets programs arbitrary c-atoms. aim matchsemantics provided recent literature monotone c-atoms, avoidpitfalls approach developed work Marek Remmel (2004).concept answer sets programs c-atoms later revisited MarekTruszczynski (2004), focusing answer sets programs monotone constraintatoms, c-atom monotone if, pair interpretations 00 , satisfies implies 0 satisfies A. proposalextended case disjunctive logic programs monotone c-atoms (Pelov &Truszczynski, 2004). another paper (Liu & Truszczynski, 2005b), extended dealconvex c-atoms c-atom convex if, every pair interpretations JJ, J satisfy implies 0 satisfies every 0 J.paper also proves several properties programs monotone convex c-atoms.shown many well-known properties standard logic programming answerset semantics preserved case programs monotone c-atoms.main advantage focusing monotone c-atoms lies monotonicity providesrelatively simpler way defining answer sets logic programs c-atoms.hand, restriction allow several important classes problemsdirectly expressed. example2 , aggregate atom Min({X | p(X)}) > 2 cannotviewed monotone aggregate atomsince monotonic extensions definition pmight make aggregate false; e.g., aggregate true {p(3)} definition p,becomes false consider definition containing {p(3), p(1)}. Similarly, cardinalityconstraint atom 1 {a, b} 1 monotone constraint. Neither two examplesdirectly encoded using monotone c-atoms.studies Marek Remmel (2004), Marek Truszczynski (2004) LiuTruszczynski (2005b) lead following question: alternativesapproach defining answer sets programs arbitrary c-atoms developed MarekRemmel (2004)? Furthermore, alternativesif capture semanticsprograms monotone c-atoms proposed Marek Truszczynski (2004) avoidpitfalls notion answer sets arbitrary c-atoms Marek Remmel (2004)?present two equivalent approaches defining answer sets logic programsarbitrary c-atoms.first approach inspired notion conditional satisfactionoriginallydeveloped Son Pontelli (2007)to characterize semantics logic programs2. Although variables appear definition aggregates, locally quantified. such,aggregate literal nothing shorthand collection ground terms.355fiSon, Pontelli, & Tuaggregates. generalize notion case programs c-atoms.generalization turns significantly intuitive easier understandoriginal definition Son Pontelli (2007). Using notion, defineimmediate consequence operator TP answer set checking.second approach inspired notion well-supportedness, proposedFages (1994) normal logic programs.approaches intuitive, and, believe, improve semantics proposed logic programs arbitrary c-atoms Marek Remmel (2004).show newly defined semantics coincide previously introducedsemantics Marek Truszczynski (2004) case programs monotone c-atoms,extend original stable model semantics normal logic programs. discussdifferent approaches treating negation-as-failure c-atoms. also relate definitionsseveral semantics logic programs aggregates, since notion c-atomused encode arbitrary aggregates. results show proposed frameworknaturally subsumes many existing treatments aggregates logic programming.summary, main contributions paper are:new notion fixpoint answer set programs arbitrary c-atoms,inspired fixpoint construction proposed Son Pontelli (2007) (but simpler)differs significantly proposal programs arbitrary catoms Marek Remmel (2004); lead two different definitions answersets (answer set reduct answer set complement);generalization notion well-supported models Fages (1994) programsarbitrary c-atoms, whichto best knowledgehas investigated researchers, leads notions weakly stronglywell-supported models;result showing set answer sets reduct (resp. complement)equivalent set weakly (resp. strongly) well-supported models;number results showing newly defined notions answer sets captureanswer set semantics various extensions logic programming, casespreviously proposed semantics agree.rest paper organized follows. Section 2 presents preliminary definitions,including syntax language logic programming c-atoms, basic notionsatisfaction, notion answer set programs monotone c-atoms MarekTruszczynski (2004) positive programs arbitrary c-atoms Marek Remmel(2004). Section 3 presents first approach defining answer sets logic programsarbitrary c-atoms based fixpoint operator, Section 4 introduces alternativedefinition based well-supportedness. Section 5 extends semantics programsarbitrary c-atoms head rules. Section 6 relates semantics presented paperearly work abstract constraint atoms aggregates. Section 7 provides conclusionsfuture work. Proofs theorems propositions deferred appendix.356fiLogic Programs Arbitrary Abstract Constraint Atoms2. PreliminariesLogic Programs Abstract Constraint Atomsfollow syntax used Liu Truszczynski (2005b) define programs abstractconstraint atoms. Throughout paper, assume fixed propositional language Lcountable set propositional atoms.2.1 Syntaxabstract constraint atom (or c-atom) expression form (D, C),set atoms (the domain c-atom), C collection sets atoms belongingD, i.e., C 2D (the solutions c-atom). Intuitively, c-atom (D, C) constraintset atoms D, C represents admissible solutions. Given c-atom = (D, C),use Ad Ac denote C, respectively.c-atom form ({p}, {{p}}) called elementary c-atom simplywritten p. c-atom form (A, ), representing constraint admitsolutions, denoted . c-atom said monotone everyX Ad , X Ac implies Ac .rule formA1 , . . . , Ak , Ak+1 , . . . ,(1)A, Aj c-atoms. literals Aj (k < j n) called negation-as-failurec-atoms (or naf-atoms). rule r form (1), define:head(r) = A,pos(r) = {A1 , . . . , Ak },neg(r) = {Ak+1 , . . . , },body(r) = {A1 , . . . , Ak , Ak+1 , . . . , }.program P , hset(P ) denotes set rP head(r)d .recognize special types rules:1. rule r positive neg(r) = ;2. rule r basic head(r) elementary c-atom;3. rule r constraint rule head(r) = .logic program c-atoms (or logic program, simplicity)3 set rules. programP called basic program rule r P basic constraint rule. P saidpositive every rule P positive. P monotone (resp. naf-monotone) c-atomoccurring P (resp. naf-atom P ) monotone. Clearly, monotone programalso naf-monotone.3. Whenever want refer traditional logic programs (without c-atoms), explicitly talknormal logic programs.357fiSon, Pontelli, & Tu2.2 Models Satisfactionsubsection, introduce basic definitions study logic programsconstraints. begin definition satisfaction c-atoms.introduce notion model programs c-atoms.2.2.1 Satisfaction C-Atomsset atoms satisfies c-atom A, denoted |= A, Ad Ac . satisfiesA, denoted |= A, Ad 6 Ac .shown Marek Remmel (2004) Marek Truszczynski (2004)notion c-atom general extended atoms cardinality constraint atoms aggregate atoms; thus, c-atoms used conveniently representweight constraints, cardinality constraints (Simons et al., 2002), various classesaggregates, maximal cardinality constraints. example,Let us consider arbitrary choice atom form L{p1 , . . . , pk , notq1 , . . . , notqh }U ;represented c-atom (A, S) where:= {p1 , . . . , pk , q1 , . . . , qh }= { | L |(T {p1 , . . . , pk }) ({q1 , . . . , qh } \ )| U }Let us consider arbitrary aggregate form F {v | p(v)} V F setfunction (e.g., Sum, Avg), V number, comparison operation (e.g.,, >, 6=). represented c-atom (A, S), where:= {p(a) | p(a) A}= {T | A, F (T ) V }Example 1 Let us consider aggregate sum({X | p(X)}) 1, defined language= {p(1), p(2)}. considerations above, aggregaterepresented c-atom ({p1 ), p(2)}, S)= {T | {p(1), p(2)}, sum(T ) 1} = {, {p(1)}, {p(2), p(1)}}2Example 2 Let us consider cardinality constraint atom 1 {p(1), p(1)} 1.represented c-atom ({p(1), p(1)}, S)= { | {p(1), p(1)}, 1 |(T {p(1), p(1)}| 1 } = {{p(1)}, {p(1)}}2C-atoms allow us compactly represent properties would require complex propositional combinations traditional aggregates. E.g., condition like either elementselements set {a, b, c, d} true simply written single c-atom({a, b, c, d}, {, {a, b, c, d}}). motivations behind use c-atoms foundMarek Remmel (2004) Marek Truszczynski (2004).rest paper, often use examples notation cardinalityconstraint atoms, weight constraint atoms, general aggregate atoms instead c-atoms,whenever confusion possible.358fiLogic Programs Arbitrary Abstract Constraint Atoms2.2.2 Modelsset atoms satisfies body rule r form (1), denoted |= body(r),|= Ai = 1, . . . , k |= Aj j = k + 1, . . . , n. satisfies rule rsatisfies head(r) satisfy body(r).set atoms model program P satisfies every rule P . minimalmodel P model P proper subset also modelP . particular, programs may one minimal model (see, example,Example 5).Given program P , set atoms said support atom existsrule r P X head(r)c following conditions met:|= body(r),X S,X.Example 3 Let P1 4 programp(a)p(b)p(c)qqCount({X | p(X)}) > 2aggregate notation Count({X|p(X)}) > 2 represents c-atom (D, {D})= {p(a), p(b), p(c)}. P1 two models:M1 = {p(a), p(b), p(c), q}M2 = {p(a), p(b)}M2 minimal model P1 , M1 not.2Example 4 Let P2 programp(1)p(1) p(2)p(2)Sum({X | p(X)}) 1aggregate notation Sum({X|p(X)})1 represents c-atom (D, C)= {p(1), p(2), p(1)}C = {{p(1)}, {p(2)}, {p(1), p(2)}, {p(2), p(1)}, {p(1), p(2), p(1)}}first rule, model P2 need contain {p(1)}. easy see{p(1), p(1)} {p(1), p(2), p(1)} models P2 {p(1), p(2)} model P2 .2Example 5 Let P3 programp ({q}, {})q ({p}, {})P3 three models {p}, {q}, {p, q}, {p} {q} minimal.4. Remember notation p short form c-atom ({p}, {{p}}).3592fiSon, Pontelli, & Tu2.3 Previously Proposed Semanticssection, overview semantical characterizations programs c-atomsproposed existing literature. particular, review notion answer setsmonotone programs (i.e., program contain monotone c-atoms), definedMarek Truszczynski (2004). formal comparison semanticsnovel approach propose paper described Section 6.Given set atoms S, rule r applicable |= body(r). set applicablerules denoted P (S). set 0 nondeterministically one-step provablemeans P 0 hset(P (S)) 0 |= head(r) every r P (S). nondeterministicone-step provability operator TPnd function 2A 22 every A,TPnd (S) consists sets 0 nondeterministically one-step provablemeans P .P -computation sequence = (Xn )n=0,1,2,... X0 = every nonnegative integer n,(i) Xn Xn+1 ,(ii) Xn+1 TPnd (Xn )St =n=0 Xi called result computation t. set atoms derivable modelP exists P -computation = St . Gelfond-Lifschitz reductnormal logic programs generalized monotone programs follows.Definition 1 Let P monotone program. set atoms , reduct Prespect , denoted P , obtained P1. removing P every rule containing body literal |= A;2. removing literals form remaining rules.Answer sets monotone programs defined next.Definition 2 set atoms answer set monotone program Pderivable model reduct P .next example shows that, programs non-monotone c-atoms, Definition 2 is,general, applicable.Example 6 Consider program P3 Example 5. check programallow construction P3 -computation. fact, TPnd() = {{p, q}}3ndTP3 ({p, q}) = {}. Hence, {p} would answer set P3 (according Definition 2)since derivable model reduct P3 respect {p} (which P3 ).hand, easy see P3 intuitively equivalent normal logicprogram {p q, q p}. such, P3 accept {p} one answer sets.2main reason inapplicability Definition 2 lies nondeterministic onestep provability operator TPnd might become non-monotone presence non-monotonec-atoms.360fiLogic Programs Arbitrary Abstract Constraint Atoms2.4 Answer Sets Positive ProgramsPositive programs characterized lack negation-as-failure atoms. Positive programs arbitrary c-atoms investigated Marek Remmel (2004),name SC-programs. Let us briefly review notion answer sets SC-programswhich, turn, generalization notion answer sets logic programs weightconstraints, presented Niemela et al. (1999). detailed comparison approach Marek Remmel (2004) work given Section 6.b c-atomc-atom A, closure A, denoted A,( Ad , {Y | Ad , Z. (Z Ac , Z )} )Intuitively, closure constructed including supersets existing solutions.b rule form (1) Horn-rulec-atom said closed = A.(i) head elementary c-atom; (ii) c-atom body closed c-atom.SC-program P said Horn SC-program rule P Horn-rule.one-step provability operator, defined TP (X) = {a | r P, head(r) = a, X |= body(r)},associated Horn SC-program P monotone. Hence, every Horn SC-program Pleast fixpoint P minimal model P (w.r.t. set inclusion). Givenset atoms SC-program P , NSS-reduct P respect , denotedN SS(P, ), obtained P(i) removing rules whose body satisfied ;(ii) replacing rulee1 , . . . , en , A1 , . . . ,ei elementary c-atoms Aj non-elementary c-atoms setrulesc1 , . . . ,{a e1 , . . . , en ,| Ad }model program P answer set P least fixpoint one-stepprovability operator program N SS(P, S), i.e., = N SS(P,S) . sometimes yieldsanswer sets accepted extensions logic programming. nextexample illustrates point.Example 7 Consider program P4 :c({a, c}, {, {a, c}})M1 = {c} M2 = {a, c} models P4 . Furthermore, N SS(P4 , M1 )programcN SS(P4 , M2 ) consists rulesc({a, c}, {, {a}, {c}, {a, c})}361fiSon, Pontelli, & Tueasy see M1 = N SS(P,M1 ) M2 = N SS(P,M2 ) . Thus, observe P4non-minimal answer set {a, c} according Marek Remmel (2004). Noteprogram P4 viewed following program aggregatescCount({a, c}) 6= 1{a, c} answer set proposed semanticsaggregates (Denecker et al., 2001; Faber et al., 2004; Ferraris, 2005; Pelov, 2004; Son &Pontelli, 2007). Furthermore, approaches accept {c} answer setprogram.23. Answer Sets Basic Programs: Fixpoint Based Approachsection, define notion answer sets basic programs. approach,follow traditional way defining answer sets logic programs, i.e., by:1. first characterizing semantics positive programs (Definition 4),2. extending deal naf-atoms (Definitions 7 8).3.1 Answer Sets Basic Positive ProgramsExample 5 shows basic positive program might one minimal model.leads us define TP -like operator answer set checking, whose constructionbased following observation.Observation 1 Let P propositional normal logic program (i.e., withoutc-atoms)5 let R, two sets atoms. Given set atoms , defineoperator TP (R, S) monotone sequence interpretations hIiM ii=0follows.)(r P : head(r) = a,TP (R, S) =pos(r) R, neg(r) =I0M == (I , )Ii+1P(i 0)Let us denote IM limit sequence interpretations. possibleprove answer set P w.r.t. Gelfond Lifschitz (1988) iff= IM .see observation, (modified) consequence operator TP takestwo sets atoms, R S, arguments, generates one set atoms couldviewed consequences P given R true assumed answerset P . easy see TP monotone w.r.t. first argument, i.e., R V ,TP (R, S) TP (V, S). Thus, sequence hIjM ij=0 monotone converges IMgiven S. next show TP generalized programs c-atoms.5. rule r normal logic program P ,a1 , . . . , , b1 , . . . , bmhead(r), pos(r), neg(r) denote a, {a1 , . . . , }, {b1 , . . . , bm }, respectively.362fiLogic Programs Arbitrary Abstract Constraint AtomsObserve definition TP requires pos(r) R or, equivalently, R |= pos(r).normal logic programs, sufficient guarantee monotonicity TP (, S).definition naively generalized case programs c-atoms, monotonicityTP (., S) guaranteed certain circumstances, e.g., c-atoms pos(r)monotone. deal arbitrary c-atoms, need introduce notion conditionalsatisfaction c-atom.Definition 3 (Conditional Satisfaction) Let sets atoms. setconditionally satisfies c-atom w.r.t. , denoted |=M A,1. |= and,2. every Ad Ad Ad , Ac .Observe notion conditional satisfaction inspired conditionalsatisfaction used characterize aggregates Son Pontelli (2007), significantlysimpler.say conditionally satisfies set c-atoms V w.r.t. , denoted |=M V ,|=M every V . Intuitively, |=M V implies 0 |= V every 00 . Thus, conditional satisfaction ensures body rule satisfiedalso satisfied 0 , provided 0 . allows us generalizeoperator TP defined Observation 1 follows. set atoms positive basicprogram P , letnTP (S, ) =r P : |=M pos(r), head(r) = ({a}, {{a}})following proposition holds.Proposition 1 Let model P , let U .TP (U, ) M.TP (S, )Let TP0 (, ) = and, 0, letTPi+1 (, ) = TP (TPi (, ), )Then, following corollary natural consequence Proposition 1.Corollary 1 Let P positive, basic program model P . Then,TP0 (, ) TP1 (, ) . . .corollary implies sequence hTPi (, )ii=0 monotone limited (w.r.t.set inclusion) . Therefore, converges fixpoint. denote fixpointTP (, ).Definition 4 Let model basic positive program P . answer set Piff = TP (, ).363fiSon, Pontelli, & TuObserve constraint rules present P (i.e., rules whose head ) contributeconstruction performed TP ; nevertheless, requirementmodel P implies constraint rules satisfied answer set.illustrate Definition 4 next examples.Example 8 Consider program P1 Example 3.M1 = {p(a), p(b)} answer set P1 since:TP01 (, M1 ) =TP11 (, M1 ) = {p(a), p(b)} = M1TP21 (, M1 ) = TP1 ({p(a), p(b)}, M1 ) = M1M2 = {p(a), p(b), p(c), q} answer set P1 , since:TP01 (, M2 ) =TP11 (, M2 ) = {p(a), p(b)} = M1TP21 (, M2 ) = TP1 ({p(a), p(b)}, M2 ) = M12Example 9 Consider program P3 (Example 5). Let M1 = {p} M2 = {q}.TP03 (, M1 ) =TP03 (, M2 ) =TP13 (, M1 ) = {p} = M1TP13 (, M2 ) = {q} = M2Thus, {p} {q} answer sets P3 . hand, = {p, q},TP13 (, {p, q}) = 6|=M ({q}, {}) 6|=M ({p}, {}). Hence, {p, q}answer set P3 .2conclude section observing answer sets obtained construction minimal models.Corollary 2 Let P positive basic program answer set P . Then,minimal model P .next example shows every positive program answer set.Example 10 Consider P2 (Example 4). Since answer sets positive programs minimalmodels (Corollary 2) = {p(1), p(1)} minimal model P2 ,possible answer set P2 . SinceTP02 (, ) =TP12 (, ) = {p(1)}TP22 (, ) = TP2 ({p(1)}, ) = {p(1)}conclude answer set P2 . Thus, P2 answer sets. 2example highlights supportedness, approach, sufficient conditionanswer setM 0 = {p(1), p(1), p(2)} supported model, acceptedanswer set. reason rejecting 0 fact element p(2) essentiallyself-supporting (cyclically) 0 . Note 0 rejected, answer set,approaches aggregates logic programminge.g., approach Faber et al. (2004)rejects 0 minimal model FLP-reduct program.364fiLogic Programs Arbitrary Abstract Constraint Atoms3.2 Answer Sets Basic Programsdefine answer sets basic programs, i.e., programs elementary c-atomshead rules, rule bodies composed c-atoms naf-atoms.literature, two main approaches considered deal negation aggregates complex atoms. Various extensions logic programming (e.g., weightconstraints Simons et al. (2002) aggregates Faber et al. (2004)) support negationas-failure atoms replacing naf-atom c-atom A0 , A0 obtainedreplacing predicate relation negation. example, followingapproach, negated cardinality constraint atom 1 {a, b} 1 replaced({a, b}, {, {a, b}}). Similarly, negated aggregate atom Sum({X | p(X)}) 6= 5replaced Sum({X | p(X)}) = 5.hand, researchers (see, e.g., Marek & Truszczynski, 2004; Ferraris,2005) suggested handle naf-atoms using form program reductinspirit Gelfond Lifschitz (1988).Following perspectives, study two different approaches dealing nafatoms, described next two subsections. worth mentioning approachescoincide case monotone programs (Proposition 2).3.2.1 Negation-as-Failure Complementapproach, treat naf-atom replacing complement. definenotion complement c-atom follows.Definition 5 complement c-atom c-atom (Ad , 2Ad \ Ac ).next define complement program P .Definition 6 Given basic program P , define C(P ) (the complement P )program obtained P replacing occurrence P complementA.program C(P ) basic positive program, whose answer sets definedDefinition 4. allows us define notion answer sets basic programs follows.Definition 7 set atoms answer set complement basic program P iffanswer set C(P ).easy see answer set program P indeed minimal model P .Example 11 Let us consider program P5 , consists following rules:c({a, b}, {{a, b}})complement P5c ({a, b}, {, {a}, {b}}){a, c} answer set. Thus, {a, c} answer set complement P5 .2365fiSon, Pontelli, & TuExample 12 Let P6 programc 1{a, b}1cbC(P6 ) programc ({a, b}, {, {a, b}})cbprogram answer set (w.r.t. Definition 4); thus P6answer set complement.23.2.2 Negation-as-Failure ReductionAnother approach dealing naf-atoms adapt Gelfond-Lifschitz reductionnormal logic programs (Gelfond & Lifschitz, 1988) programs c-atomsthis approach considered Marek Truszczynski (2004) Ferraris (2005).generalize approach programs arbitrary c-atoms follows. basic programP set atoms , reduct P w.r.t. (P ) set rules obtained1. removing rules containing s.t. |= A;2. removing remaining rules.program P positive basic program. Thus, define answer sets Pfollows:Definition 8 set atoms answer set reduct P iff answer setP (w.r.t. Definition 4).Example 13 Let us reconsider program P5 Example 11 let us consider ={a, c}. perform reduct, left rulescwhose minimal model itself. Thus, answer set reduct program P5 .2next example shows approach lead different answer sets casenegation complement (for non-monotone programs).Example 14 Consider program P6 Example 12. Let = {a, b, c}. reductP6 w.r.t. programccbanswer set, i.e., answer set reduct P6 .3662fiLogic Programs Arbitrary Abstract Constraint AtomsOne consequence negation reduct approach fact might lead nonminimal answer setsin presence non-monotone atoms. instance, replaceatom Count({X | p(X)}) > 2 P1 Count({X | p(X)}) 2, newprogram (by replacing aggregate c-atom):p(a)p(b)p(c) qq({p(a), p(b), p(c)},, {p(a)}, {p(b)}, {p(c)},{p(a), p(b)}, {p(b), p(c)}, {p(a), p(c)})!program admits following two interpretations answer sets reduct: M1 ={p(a), p(b), p(c), q} M2 = {p(a), p(b)}. Since M2 M1 , non-minimalanswer set exists.result indicates that, certain programs c-atoms, might differentways treat naf-atoms, leading different semantical characterizations. problemmentioned Ferraris (2005). Investigating methodologies dealingnaf-atoms interesting topic research, plan pursue future.3.3 Properties Answer Sets Basic Programsshow notion answer sets basic programs c-atoms naturalgeneralization notions answer sets normal logic programs. proveanswer sets basic positive programs minimal supported models characterizesituations properties hold basic programs. begin result statingthat, class naf-monotone programs, two approaches dealing naf-atomscoincide.Proposition 2 Let P basic program. answer set complement Panswer set reduct P . Furthermore, P naf-monotone, answer setreduct P also answer set complement P .proposition implies that, general, negation-as-failure complement approach skeptical negation-as-failure reduct approach, mayaccept fewer answer sets.6 Furthermore, Examples 12 14 show minimal (w.r.t.set inclusion) answer set reduct necessarily answer set complementprogram.Let P normal logic program (without c-atoms) let c-atom(P ) program obtained replacing occurrence atom P ({a}, {{a}}). Since({a}, {{a}}) monotone c-atom, c-atom(P ) monotone program. Proposition 2 implies that, c-atom(P ), answer sets reduct answer sets complement coincide.next proposition, prove notion answer sets programs c-atomspreserves notion answer set normal logic programs, following sense.6. Note use term skeptical indicate acceptance fewer models, somewhat differentuse term model theory.367fiSon, Pontelli, & TuProposition 3 (Preserving Answer Sets) normal logic program P , answer set (by complement reduct) c-atom(P ) iff answer set P (w.r.t.definition Gelfond Lifschitz (1988)).proposition, together Proposition 2, implies normal logic programsrepresented positive basic programs. stated following corollary.Corollary 3 Every answer set normal logic program P answer setC(c-atom(P )) vice versa.next proposition, study minimality supportedness properties answersets basic programs.Proposition 4 (Minimality Answer Sets) following properties hold:1. Every answer set complement basic program P minimal model P .2. Every answer set reduct basic, naf-monotone program P minimal modelP .3. Every answer set (by complement/reduct) basic program P supportsmembers.4. Answer Sets Basic Programs: Level Mapping Based Approachdefinition answer sets provided previous section viewed generalization answer set semantics normal logic programsin sense reliesfixpoint operator, defined positive programs. section, discuss anotherapproach defining answer sets programs c-atoms, based notionwell-supported models.notion well-supported models normal logic programs introduced Fages(1994), provides interesting alternative characterization answer sets. Intuitively,model program P well-supported model iff exists level mapping,atoms set positive integers, atom supportedrule r, whose body satisfied level positive atom body(r) strictlysmaller level a.7 Fages proved answer sets well-supported modelsvice versa (Fages, 1994). notion well-supportedness extended dealdynamic logic programs Banti, Alferes, Brogi, Hitzler (2005). Level mappingalso used effective tool analyze different semantics logic programsuniform way (Hitzler & Wendt, 2005).follows, show notion well-supported models effectivelyapplied programs c-atoms. key formulation notion answerfollowing question:level c-atom given set atoms level mapping L ?one hand, one might argue level mapping defined independentlymapping atoms, atom itself. hand,7. implicitly means pos(r) neg(r) = , i.e., naf-atoms dealt reduct.368fiLogic Programs Arbitrary Abstract Constraint Atomsreasonable assume level depends levels atoms Ad , sincesatisfaction (w.r.t. given interpretation) depends satisfaction elementsAd . fact every existing semantics programs c-atoms evaluates truthvalue c-atom based truth value assigned elements Ad stipulates usadopt second view.worth mention view also allows us avoid undesirable circular justifications elements well-supported model: follow first view, program P7consisting following rulesbb({a, b}, {, {a, b}})would {a, b} well-supported model a, b, ({a, b}, {, {a, b}})supported ({a, b}, {, {a, b}}), a, {a, b} respectively. means trueb true, i.e., circular justification w.r.t. model{a, b}.Let set atoms, ` mapping positive integers, letc-atom. define H(X) = max({`(a) | X}),L(A, ) = min({H(X) | X Ac , X M, X |=M A}).Intuitively, level atom given smallest levels solutionsatom compatible level solution given maximum levelatoms solution. assume max() = 0, min() undefined.introduce two different notions well-supported models. first notion, called weaklywell-supported models, straightforward generalization definition given Fages(1994)in ignores naf-atoms. second notion,, called strongly well-supportedmodels, take consideration naf-atoms definition.Definition 9 (Weakly Well-Supported Model) Let P basic program. modelP said weakly well-supported iff exists level mapping ` that,b , P contains rule r head(r) = ({b}, {{b}}), |= body(r),pos(r), L(A, ) defined l(b) > L(A, ).illustrate definition next example.Example 15 Let us consider program P5 set atoms = {a, b}. Let= ({a, b}, {, {a, b}}). Obviously, model P5 . Assume weakly wellsupported model P5 . means exists mapping ` setpositive integers satisfying condition Definition 9. Since b onerule P5 b head, conclude `(b) > `(a). Observe 6|=M{a, b} |=M A. Thus, definition L(A, ),L(A, ) = max({`(a), `(b)}) = `(b).implies exists rule P5 , satisfies condition Definition 9head. words, weakly well-supported model P5 .2369fiSon, Pontelli, & Tunext proposition generalizes Fages result answer sets reduct programsc-atoms.Proposition 5 set atoms answer set reduct basic program P iffweakly well-supported model P .seen previous section, different ways deal naf-atoms leaddifferent semantics basic programs c-atoms. take consideration factnaf-atoms dealt complement, develop alternative generalizationFagess definition well-supported model programs abstract c-atoms follows.Definition 10 (Strongly Well-Supported Model) Let P basic program. modelP said strongly well-supported iff exists level mapping ` that,b , P contains rule r head(r) = ({b}, {{b}}), |= body(r),pos(r), L(A, ) defined `(b) > L(A, ), neg(r), L(A, )defined `(b) > L(A, ),Using Proposition 5 Proposition 2, easily show following result holds.Proposition 6 set atoms answer set complement basic program Piff strongly well-supported model C(P ).two propositions, together Proposition 2, lead following corollary.Corollary 4 every naf-monotone basic program P , weakly well-supported modelP also strongly well-supported model P vice versa.discussed previous section, normal logic program P easilytranslated monotone basic program c-atoms form ({a}, {{a}}), c-atom(P ).Thus, Corollary 4 indicates notion weakly/strongly well-supported modelindeed generalization Fagess definition well-supported model programs catoms.5. Answer Sets General ProgramsGeneral programs programs non-elementary c-atoms head. usefulnessrules non-elementary c-atoms head, form weight constraintaggregate, discussed Ferraris (2005), Simons et al. (2002) Son, Pontelli,Elkabani (2006). example, simple atom8Count({X | taken(X, ai)}) 10used represent constraint 10 students take AI class.next example shows 3-coloring problem graph G represented usingc-atoms.8. Recall aggregates special form c-atoms.370fiLogic Programs Arbitrary Abstract Constraint AtomsExample 16 Let three colors red (r), blue (b), green (g). program containsfollowing rules:set atoms edge(u, v) every edge (u, v) G,vertex u G, following rule:({color(u, b), color(u, r), color(u, g)}, {{color(u, b)}, {color(u, r)}, {color(u, g)}})states u must assigned one one colors red, blue,green.edge (u, v) G, three rules representing constraint u v mustdifferent color:color(u, r), color(v, r), edge(u, v)color(u, b), color(v, b), edge(u, v)color(u, g), color(v, g), edge(u, v)2note that, exception proposals Ferraris (2005), Son, Pontelli,Elkabani (2006), approaches defining answer sets logic programs aggregatesdeal programs aggregates head. hand, weight constraintchoice atoms allowed head (Simons et al., 2002). Similarly, c-atomsconsidered head rules framework logic programs c-atoms MarekRemmel (2004) Marek Truszczynski (2004).section, define answer sets general programsi.e., programsrule heads arbitrary c-atoms. approach convert program P c-atomshead collection basic programs, whose answer sets defined answer setsP . simplify presentation, talk answer set basic programrefer either answer set complement, answer set reduct, well-supportedmodel program. distinction stated clearly whenever needed.Let P program, r P , let model P . instance r w.r.t. ,denoted inst(r, ) defined follows(inst(r, ) ={b body(r) | b head(r)d }head(r)d head(r)cotherwiseinstance P w.r.t. , denoted inst(P, ), programinst(P, ) =[inst(r, )rPeasy see instance P w.r.t. basic program. allows us defineanswer sets general programs follows.Definition 11 Let P general program. answer set P iff modelP answer set inst(P, ).371fiSon, Pontelli, & Tudefinition illustrated next examples.Example 17 Let P8 program consisting single fact:({a, b}, {{a}, {b}})Intuitively, P8 choice atom 1 {a, b} 1 notation Smodels.program two models, {a} {b}. instance inst(P8 , {a}) containssingle factwhose answer set {a}. Similarly, instance inst(P8 , {b}) single factbwhose answer set {b}. Thus, P8 two answer sets {a} {b}.2next example shows presence non-elementary c-atoms head, answersets might minimal.Example 18 Let P9 program consisting following rules:({a, b}, {{a}, {b}, {a, b}})c bIntuitively, first rule P9 cardinality constraint 1 {a, b} 2 notationSmodels. program four models: M1 = {a}, M2 = {b, c}, M3 = {a, b, c},M4 = {a, c}. instance inst(P9 , M1 ) contains single factwhose answer set M1 . Thus, M1 answer set P9 .consider M3 , corresponding instance inst(P9 , M3 ) contains rulesbc bwhose answer set M3 . shows M3 another answer set P9 .Similarly, one show M2 also answer set P9 .instance inst(P9 , M4 ) programc b{a} answer set. Hence, M4 answer set P9 . Thus, P9three answer sets, M1 , M2 , M3 . particular, observe M1 M3 .2Observe P basic program P unique instance. such, notionanswer sets general programs generalization notion answer setsbasic programs. shown Proposition 2 also holds general programs.relationship notion answer set general programs definition givenMarek Remmel (2004) extensions logic programming discussednext section.372fiLogic Programs Arbitrary Abstract Constraint Atoms6. Related Work Discussionsection, relate work recently proposed extensions logic programming, discuss possible method computing answer sets programs c-atomsusing available answer set solvers.6.1 Related Workconcept logic programs c-atoms, used paper, originally introduced Marek Remmel (2004) Marek Truszczynski (2004)in particular,programs c-atoms named SC-programs Marek Remmel (2004).9Example 7 shows semantical characterization differs approach adoptedMarek Remmel (2004). particular, approach guarantees answer setsbasic programs minimal, case approach described MarekRemmel (2004). Consider another example:Example 19 Consider program P10c({a, c, d}, {{a}, {a, c, d}})According characterization, program one answer set, M1 = {a, c}.consider approach described Marek Remmel (2004), verifyM2 = {a, c, d} answer set since NSS-reduct P10 respect M2c({a, c, d}, {{a}, {a, c}, {a, d}, {a, c, d}})least fixpoint one-step provability operator {a, c, d}.2type examples, seems hard justify presence answer setoriginal program. suspect replacement c-atom closure, usedNSS-reduct, might reason acceptance unintuitive answer sets MarekRemmel (2004). following proposition states approach skepticalapproach Marek Remmel (2004).Proposition 7 Let P positive program. set atoms answer set Pw.r.t. Definition 11 answer set P w.r.t. Marek Remmel (2004).syntax logic programs c-atoms, used paper, also used LiuTruszczynski (2005b) Liu Truszczynski (2005a). One main differenceswork work Marek Truszczynski (2004) considerarbitrary c-atoms, proposal Marek Truszczynski (2004) focuses monotone9. Although naf-atoms allowed definition SC-programs, authors suggest naf-atomsreplaced complement.373fiSon, Pontelli, & Tu(and convex) c-atoms. framework introduced paper easily extendeddisjunctive logic programs considered Pelov Truszczynski (2004).immediate consequence operator TP proposed paper differentnondeterministic one-step provability operator, TPnd , adopted Marek Truszczynski(2004), TP deterministic applied basic positive programs. MarekTruszczynski (2004) Liu Truszczynski (2005b), researchers investigateseveral properties normal logic programs (e.g., strong equivalence) hold semantics programs monotone c-atoms Marek Truszczynski (2004).directly studied properties context semantical characterization; nevertheless, see later, Proposition 8 implies results proved LiuTruszczynski (2005b) immediately applicable semantic characterizationclass monotone programs. do, however, focus use well-supported modelslevel mapping studying answer sets programs c-atoms, approachused programs c-atoms.next present result shows approach define answer setsmonotone programs coincides Marek Truszczynski (2004).Proposition 8 Let P monotone program. set atoms answer set Pw.r.t. Definition 11 iff stable model P w.r.t. Marek Truszczynski (2004).discussed earlier, c-atoms used represent several extensions logic programs,among weight constraints aggregates. Intuitively, aggregate atom (see, e.g.,Elkabani et al., 2004; Faber et al., 2004) encoded c-atom (D, C),consists atoms occurring set expression C 2D everyX C satisfies (see Examples 3-4). indicated Marek Truszczynski (2004),many previous proposals dealing aggregates allow aggregates occurhead rules. Here, instead, consider programs c-atoms head.regards naf-atoms, proposals (see, e.g., Elkabani et al., 2004) allowaggregates occur naf-atoms. proposal Faber et al. (2004) treats naf-atomscomplement, although reduction used defining semantics, Ferraris (2005)argues that, different logics, naf-atoms might require different treatments.present propositions relate work recent worksaggregates. prove10 :Proposition 9 program monotone aggregates P , answer set P iffanswer set P w.r.t. Faber et al. (2004) Ferraris (2005).proposal presented Pelov (2004) Denecker et al. (2001) deals aggregatesusing approximation theory three-valued logic, building semantics threevalued immediate consequence operator aggr, maps three-valued interpretationsPthree-valued interpretations program. operator viewed operatormaps pairs set atoms (R, S) R pairs set atoms (R0 , 0 )R0 0 . authors show ultimate approximate aggregates provideprecise semantics logic programs aggregates. Let us denote 1 (R, S)2 (R, S)) two components aggr(R, S), i.e., aggr(R, ) = (1 (R, ), 2 (R, )).PPaggrnext proposition relates TP P .10. Abusing notation, use single symbol denote program different notations.374fiLogic Programs Arbitrary Abstract Constraint AtomsProposition 10 Let P positive program aggregates R two setatoms R . Then, TP (R, ) = 1 (R, ).proposition, together fact evaluation truth valueaggregate formulas Denecker et al. (2001) treats naf-atoms complement, allows usconclude that, program aggregates P , answer sets complement P (w.r.t.Definition 4) ultimate stable models P (Denecker et al., 2001) vice versa.result, together results Son Pontelli (2007), allows us conclude TPgeneralization immediate consequence operator aggregates programs SonPontelli (2007).conclude discussion related work, would like pointPropositions 7-10 show different approaches dealing aggregates differnon-monotone programs. main difference approach others liesskepticism TP operator, caused notion conditional satisfaction.illustrate issue next two examples.Example 20 Consider program P2 Example 4. programanswer set w.r.t. Definition 4 = {p(1), p(1), p(2)} answer set accordingMarek Remmel (2004). reason unacceptability answer setapproach lies truth value aggregate atom Sum({X | p(X)}) couldeither true false even p(1) known true. prevents third ruleapplicable hence second rule well. makes p(1) fixpoint TP2operator, given considered answer set. words, cannot regenerategiven programand skepticism TP2 main reason. observeapproaches (see, e.g., Faber et al., 2004; Ferraris, 2005) accept answer setP2 well.2following example shows difference approach Faber et al.(2004) well Ferraris (2005).Example 21 Consider program Pp(1)({p(1), p(1)}, {, {p(1), p(1)}})p(1)p(1)p(1) p(1)Intuitively, abstract atom = ({p(1), p(1)}, {, {p(1), p(1)}}) represents aggregate atom Sum({X | p(X)}) 0. program two models M1 = {p(1), p(1)}M2 = . approaches Marek Remmel (2004), Faber et al. (2004), Ferraris(2005) accept M1 answer set, approach Pelov (2004), Deneckeret al. (2001) admit answer sets. approach, TP (, M1 ) =conditionally satisfy w.r.t M1 since true every possible extensionleads M1 , namely true {p(1)}. words, skepticismapproach main reason difference approachapproaches Faber et al. (2004) Ferraris (2005).2375fiSon, Pontelli, & Tu6.2 Discussionsection, briefly discuss possible method computing answer sets programsc-atoms, using off-the-shelf answer set solvers. method makes use transformation similar unfolding transformation proposed Elkabani et al. (2004) dealingaggregates, studied implemented Elkabani et al. (2005).begin discussion basic positive programs. Given basic positive programP c-atom A, Ac 6= , unfolding expression formp1 , . . . , pn , q1 , . . . , qm{p1 , . . . , pn } Ac {q1 , . . . , qm } = Ad \ {p1 , . . . , pn }. Ac = , , denotingfalse, unique unfolding A. Observe = ({a}, {{a}}) unfoldinga. unfolding ruleA0 A1 , . . . , Akrule obtained replacing Ai one unfoldings. unf olding(r) denotesset unfoldings rule r. Let unf olding(P ) = rP unf olding(r). Clearly,unf olding(P ) normal logic program P basic positive program. showanswer set P iff answer set unf olding(P ). indicatescompute answer sets basic positive programs c-atoms (i) computing unfolding;(ii) using available answer set solvers compute answer sets unfoldedprogram. Following approach, main additional cost computing answer setsbasic positive program cost incurred unfolding process. Theoretically,costly rule r, |unf olding(r)| = Abody(r) |Ac |,|.| denotes cardinality set. means size program unf olding(P )might exponential size original program P . Thus, additional costmight significant. practice, expect number manageable,rule might contain c-atoms whose set solutions reasonably small.Furthermore, certain techniques employed reduce size unfolding program(Son, Pontelli, & Elkabani, 2006).method easily extended deal naf-atoms general programs.answer sets complement need computed, need (i) compute complementprogram; (ii) use procedure compute answer sets complement.hand, answer sets reduct need computed, handtentative answer set . reduction program respect computed,unfolding applied verify whether answer set reduct.Observe complement reduct program easily computed,increase size program. such, main cost computing answer setsgeneral programs following approach still cost unfolding. far,study programs aggregates (a special type c-atoms), encounterunmanageable situations (Son, Pontelli, & Elkabani, 2006).Observe specification c-atom requires enumeration domainsolutions, whose size exponential size set atoms program.mean explicit representation c-atoms needs used.cases, c-atoms replaced aggregate literals. this, several complexity376fiLogic Programs Arbitrary Abstract Constraint Atomsresults programs aggregates (see, e.g., Pelov, 2004; Son & Pontelli, 2007)extended logic programs c-atoms. example, easily show problemdetermining whether logic program answer set least NPco-NP .However, programs c-atoms representable standard aggregate functions, exceptform Sum(.) 6= value Avg(.) 6= value, problem determining whetherprogram answer set remains NP-complete.7. Conclusions Future Workpaper, explored general logic programming framework based use arbitrary constraint atoms. proposed approach provides characterizationline existing semantics logic programming aggregates characterization proposed Marek Remmel (2004). provided two alternative characterizationsanswer set semantics programs arbitrary constraint atoms, first basedfixpoint operator, generalizes immediate consequence operator traditionallogic programs, second built generalization notion well-supportedmodels Fages (1994).Within characterization answer set, investigated two methodologies treating naf-atoms identified class naf-monotone programs, twoapproaches dealing naf-atoms coincide. also proved newly proposedsemantics coincides semantics proposed Marek Truszczynski (2004)monotone programs. Finally, related work proposals logic programsaggregates discussed possible method computing answer sets programsabstract constraint atoms using available answer set solvers.proposal unexplored aspects. proposed approach rather skepticalidentification answer setswhile approach Marek Remmel (2004)overly credulous. believe two approaches represent two extremescontinuum needs explored. particular, believe possible identifyintermediate approaches simply modifying notion conditional satisfaction. Workprogress explore alternatives.Acknowledgmentauthors wish thank anonymous reviewers insightful comments.research partially supported NSF grants HRD-0420407, CNS-0454066,CNS-0220590. extended abstract paper appeared ProceedingsTwenty-First National Conference Artificial Intelligence, 2006.AppendixFirst, show lemmas used proofs propositions.Lemma 1 Let U 0 sets atoms abstract constraint atom.Then, |=M implies U |=M 0 A.377fiSon, Pontelli, & TuProof. |=M implies{I | Ad , Ad Ad } Ac .Together fact U 0 ,{I | Ad , U Ad 0 Ad } Ac .implies U |=M 0 A.2Lemma 2 two sets atoms 0 monotone c-atom A, 0 |= (resp.0 |= A) |= (resp. |= A) 0 |=M (resp. 0 |=M A). (Recalldenotes complement A.)Proof.1. Let us assume 0 |= |= A. monotonicity A,conclude that, every S, 0 , |= A. result,0 |=M A.2. Let us assume 0 |= |= A. Let us assume, contradiction,0 6|=M A. Since already know 0 |= A, implies existsAd , 0 Ad Ad , 6 2Ad \ Ac , i.e., Ac . Sincemonotone , |= A. contradiction, sinceinitially assumed |= A.2Proposition 1. Let model P , let U .TP (S, ) TP (U, ) M.Proof.1. Lemma 1, assumption U , definition TP ,TP (S, ) TP (U, ).2. Let us show TP (U, ) . Consider atom TP (U, ). needshow . definition TP operator, rule rhead(r) = ({a}, {{a}}) U |=M pos(r). observe that, pos(r),U |=M |= (Definition 3). Thus, conclude|= pos(r). Since program positive known model P ,must |= head(r), thus .2Corollary 2 Let P positive basic program answer set P . Then,minimal model P .Proof. model P since answer set P (Definition 4). Thus, needprove indeed minimal model P . Suppose exists 0378fiLogic Programs Arbitrary Abstract Constraint Atoms0 model P . Proposition 1 Lemma 1 imply k (, ) k (, 0 ) 0every k. Since answer set, 0 . contradicts assumption0 .2Proposition 2. Let P basic program. answer set complement Panswer set reduct P . Furthermore, P naf-monotone, answer setreduct P also answer set complement P .Proof. Let us start showing answer sets complement also answer setsreduct. Let model let us denote P1 = C(P ) let P2 = P . Usingfact |=M 6|= easily prove induction following resultholds:TP1 (, ) TP2 (, )(2)P naf-monotone programTPi 1 (, ) = TPi 2 (, )(3)answer set complement = TP1 (, ). Furthermore,TP2 (, ) (Proposition 1). implies answer set P reductwell.P naf-monotone, using Equation (3) fact answer set P2conclude answer set complement P .2Proposition 3. normal logic program P , answer set (by complementreduct) c-atom(P ) iff answer set P (w.r.t. Definition Gelfond Lifschitz(1988)).Proof. convenience, proof, refer answer sets defined GelfondLifschitz (1988) GL-answer sets. monotonicity c-atom(P )Proposition 2, suffices show answer set P iff answer setreduct c-atom(P ).Let us consider case P positive program. follows Observation 1fact |=M ({a}, {{a}}) iff operator TP (., .) P (definedObservation 1) coincides operator TP (., .) c-atom(P ). Hence, answerset c-atom(P ) iff GL-answer set P .suppose P arbitrary normal logic program. Let GL(P, )Gelfond-Lifschitzs reduct P w.r.t. . Since |= ({a}, {{a}}) iff ,c-atom(P )M = c-atom(GL(P, )). Using result positive program,GL-answer set P iff answer set reduct c-atom(P ).2Proposition 4.1. Every answer set complement basic program P minimal model P .2. Every answer set reduct basic, naf-monotone program P minimal modelP .3. Every answer set (by complement/reduct) basic program P supportsmembers.379fiSon, Pontelli, & TuProof.1. Notice set atoms abstract constraint atom A, |= iff|= A. implies model P iff model C(P ).Corollary 2, conclude answer set complementP , minimal model P .2. Let us assume P naf-monotone basic program, let answer setreduct P . Proposition 2, also answer set P complement.previous result implies minimal model P .3. follows Proposition 2 enough prove conclusion answer setsreduct P . Let answer set reduct P . definition,= TPM (, ). implies that, , existsTPi (, ). turn, allows us identify rule({a}, {{a}}) A1 , . . . , Ak , Ak+1 , . . . ,6|= Aj k + 1 j n TPi (, ) |=M Ai 1 k.particular, |= Ai 1 k. easily conclude given rulesupports a.2Proof Proposition 5Let us start proving following lemma:Lemma 3 Let P positive, basic program, let weakly well-supported modelP . Let l mapping satisfies desired properties weakly well-supportednessl(a)+1. every atom a, implies TP(, ).Proof. First, observe that, atom ,L(({a}, {{a}}), ) = l(a).Let us prove lemma induction l(a).1. Base Case: Consider l(a) = 0. Clearly, P must containrule({a}, {{a}})hence, TP1 (, ).2. Inductive Step: Assume result holds every atom b 0 l(b) < k.Consider atom l(a) = k. show TPk+1 (, ).Since weakly well-supported model P , exists rule({a}, {{a}}) A1 , . . . ,380fiLogic Programs Arbitrary Abstract Constraint AtomsP L(Ai , ) defined l(a) > L(Ai , ) every 1 n.Let = TPk (, ). {1, . . . , n}, since L(Ai , ) defined, X ,X (Ai )c X |=M Ai L(Ai , ) = H(X). Hence, k = l(a) >L(Ai , ) = H(X). inductive hypothesis, since X , concludeX S. hand, already proved (Corollary 1)TP0 (, ) . . . TPk (, ) = . . . M.result, X .Lemma 1, since X |=M Ai , implies |=M Ai . Accordingly,TPk+1 (, ).2proceed proof proposition.Proposition 5. set atoms answer set reduct basic program P iffweakly well-supported model P .Proof. prove proposition two steps. first prove result holdspositive programs extend case arbitrary basic programs.P positive program.1. : Suppose answer set P . Corollary 2 implies modelP . Thus, suffices find level mapping satisfies l condition Definition9. atom a, let(l(a) =min{k | TPk (, )}0otherwiseClearly, l well defined. show l indeed mapping satisfyingproperties Definition 9.Let us consider atom let k = l(a). Clearly, k > 0 since TP0 (, ) =. So, TPk (, ) 6 = TPk1 (, ) . twocases:(a) P contains rule({a}, {{a}})case, condition l atom trivially satisfied.(b) P contains rule r form({a}, {{a}}) A1 , . . . ,|=M Ai 1 n.Consider integer 1 n. Let X = (Ai )d . definitionconditional satisfaction, X (Ai )c . easy checkX |=M Ai . addition, X . result, L(Ai , ) defined.Furthermore, L(Ai , ) H(X) H(S) < k = l(a). showscondition l also satisfied case.381fiSon, Pontelli, & Tutwo cases allow us conclude l satisfies condition Definition 9, i.e., weakly well-supported model P .2. : Suppose weakly well-supported model P . Due Lemma 3,TP (, ). hand, Corollary 1,TP (, ) . Consequently, = TP (, ), impliesanswer set P .P arbitrary basic program. easy see set atomsweakly well-supported model P iff weakly well-supported model P .previous result, means answer set reduct P iffweakly well-supported model P .2Proposition 7. Let P positive program. set atoms answer set Pw.r.t. Definition 11 answer set P w.r.t. Marek Remmel (2004).Proof.Consider case P basic program. Since N SS(P, ) monotone positive programs, least fixpoint one-step provability operator TN SS(P,M ) (.)coincides least fixpoint extended immediate consequence operatorTN SS(P,M ) (., .) (see also Proposition 8). Furthermore, easily verifyTP (, ) = TNSS(P,M ) (, ) holds answer set w.r.t. Definition 11.two observations imply conclusion proposition.consider case P general positive program. Without loss generality, assume P contain constraints. Let Q = inst(P, ).rule r0 Q exists rule r P|= head(r), r0 = body(r), head(r)d . impliesN SS(P, ) = N SS(Q, ). Since answer set Q (w.r.t. Definition 11),conclude also answer set Q w.r.t. Marek Remmel (2004) (thebasic case) implies also answer set P w.r.t. Marek Remmel(2004)2Proposition 8. Let P monotone program. set atoms answer set Pw.r.t. Definition 11 iff stable model P w.r.t. Marek Truszczynski (2004).Proof. Let us start showing validity result positive programs. Let usassume P positive program. Without loss generality, assume Pcontain constraints.1. : Let answer set P . Definition 11, modelP answer set Q = inst(P, ).every non-negative integer i, letMi = TQi (, )382fiLogic Programs Arbitrary Abstract Constraint Atomsanswer set Q, definition,= TQ (, )show stable model P w.r.t. Marek Truszczynski (2004),need prove sequence hMii=0 P computation.proving (i) Mi Mi+1 (ii) every r P (Mi ) 11 , Mi+1 |= head(r),(iii) Mi+1 hset(P (Mi )).(i) Follows Corollary 1.(ii) Consider rule r P (Mi ). definition P (Mi ), Mi |=body(r). P monotone Mi , follows |= body(r)Mi |=M body(r).Let X = head(r)d . definition inst(r, ),inst(r, ) = {b body(r) | b X} QMi |=M body(r), every r0 inst(r, ), Mi |=M body(r0 ). definitionMi+1 , follows head(r0 ) Mi+1 . Hence, X Mi+1 . Since X head(r)d ,impliesX Mi+1 head(r)dhand, Mi+1 ,Mi+1 head(r)d XAccordingly,head(r)d = X = Mi+1 head(r)d(4)hand, model P |= body(r),|= head(r). Therefore,head(r)d head(r)c(5)(4) (5), Mi+1 head(r)d head(r)c , i.e., Mi+1 |= head(r).(iii) Let atom Mi+1 . definition Mi+1 easy see Qmust contain rule r0 whose head whose body satisfied Mi .implies P (Mi ) must contain rule r head(r)d . followshead(r)d hset(P (Mi )). Accordingly, Mi+1 hset(P (Mi )).2. : Let stable model P according Marek Truszczynski (2004)let hXii=0 canonical computation , i.e.,X0 =11. Recall P (Mi ) set rules P whose body satisfied Mi .383fiSon, Pontelli, & TuXi+1 =[head(r)drP (Xi )According Theorem 5 Marek Truszczynski (2004),M=[XiLet Q = inst(P, ). stable model P , also model P . So,prove answer set P , need show answer setQ.Let us construct sequence sets atoms hMifollowsM0 =Mi+1 = TQ (, Mi )Clearly, prove answer set Q, suffices showXi = Mi(6)Let us prove induction.(a) = 0: trivial X0 = M0 = .(b) Suppose (6) true = k, show true = k + 1.Consider atom Xk+1 . definition Xk+1 , exists rule r Phead(r)d Xk |= body(r). Since Xk P monotone,follows |= body(r). stable model P also model P ,|= head(r). result, Q contains following set rules:inst(r, ) = {b body(r) | b head(r)d }head(r)d Xk+1 , head(r)d .result, following rule belongs inst(r, )body(r)Mk = Xk (inductive hypothesis), Mk |= body(r) thusMk |=M body(r) (recall Mk = Xk body(r) consists monotoneabstract constraint atoms only). definition Mk+1 , Mk+1 .shown every atom Xk+1 , belongs Mk+1 . Hence,Xk+1 Mk+1(7)Now, show Mk+1 Xk+1 . Consider atom b Mk+1 .definition Mk+1 , exists rule r0 Q head(r)d = b Mk |=Mbody(r0 ). definition Q means exists rule r P|= head(r)d , body(r) = body(r0 ) b head(r)d . Xk = Mk384fiLogic Programs Arbitrary Abstract Constraint Atoms(inductive hypothesis), Mk |=M body(r0 ) = body(r), Xk |= body(r).implies r P (Xk ). Hence,b head(r)d Xk+1ThereforeMk+1 Xk+1(8)(7) (8), Xk+1 = Mk+1 .result easily extended programs negation-as-failure c-atoms.omit proof here.2Proof Proposition 9.prove proposition, brief review approach Faber et al. (2004) needed.notion answer set proposed Faber et al. (2004) based new notion reduct,defined follows. Given program P set atoms S, reduct P respectS, denoted P , obtained removing P rules whose body satisfiedS. words,F LP (P, ) = {r | r ground(P ), |= body(r)}.novelty reduct remove aggregate atoms negation-as-failureliterals satisfied S. program P , FLP-answer set P iff minimalmodel F LP (P, S). continue proof proposition. easysee enough consider programs without negation-as-failure c-atoms.Proposition 9. program monotone aggregates P , answer set P iffanswer set P w.r.t. Faber et al. (2004) Ferraris (2005).Proof. Due equivalent result Ferraris (2005), suffices prove equivalenceapproach Faber et al. (2004). Notice paperdealing ground programs therefore1. : Let FLP-answer set P . show answer set P(w.r.t. Definition 4).Let Q = F LP (P, ). definition FLP-answer set, minimal modelQ. Let 0 = TP (, ). model Q, also model P . Corollary1 implies 0 .Consider r Q 0 |= body(r) head(r) = ({a}, {{a}}).definition Q monotonicity P , |= body(r). followsLemma 2 0 |=M body(r). Hence, 0 (by definition operator TP ).implies 0 model Q.minimality 0 , 0 = . Hence,answer set P .385fiSon, Pontelli, & Tu2. : Let answer set P . prove FLP-answer set Pshowing minimal model Q = F LP (P, ).Let 0 model Q. First, demonstrate 0 model P .Suppose otherwise, i.e., 0 model P . implies P contains ruler head(r) = ({a}, {{a}}) atom a, 0 |= pos(r),6 0 . Due monotonicity P |= pos(r). Hence,Q contains rule r. result, 0 |= body(r). Thus, 0 0model Q. contradiction.shown 0 model P . hand, Corollary 2,minimal model P . Therefore, 0 . Accordingly, 0 = .Thus, minimal model Q, i.e., FLP-answer set P .2Proof Proposition 10. Let P positive program aggregates Rtwo set atoms R . Then, TP (R, ) = 1 (R, ) aggr (R, ) =(1 (R, ), 2 (R, )).Proof. order prove result, make use intermediate step. SonPontelli (2007), following concepts program aggregates introduced:Given aggregate A, solution pair hS + , i, satisfying followingproperties:+ A,+ = ,+ = , |= A.Given two interpretations I, , aggregate conditionally satisfied w.r.t. I,(denoted (I, ) |= A) hI Ad , Ad \ solution A. simplicity,define also conditional satisfaction atoms, saying conditionally satisfiedw.r.t. I, I.Given positive program aggregates P interpretation , aggreP : 2A 2A defined as:12 K P (I) = {head(r)|rgate consequence operator KMP, (I, ) |= body(r)}.wish show that, positive program aggregates P interpretationsP (I) = (I, ). allow us conclude result proposition 10, sinceI, , KMPP (I) = 1 (I, ) (Son & Pontelli, 2007).proved KMObserve that, condition :standard atom, |=M iff iff (I, ) |= a.Let aggregate.Let us assume |=M A. means |= and, J Ad s.t.Ad J Ad , J |= A.12. original definition Son Pontelli (2007) allows use negative atoms bodyrules, omit sake simplicity.386fiLogic Programs Arbitrary Abstract Constraint Atomsconsider J Ad s.t. Ad J J (Ad \ ) = ,Ad = Ad J, J Ad (otherwise, J 6 Ad ,Ad \ , would violate condition J (Ad \ ) = ).initial assumption |=M A, conclude J Ac . allowsus conclude |=M implies (I, ) |= A.Let us assume (I, ) |= A. means that, J Ad s.t. Ad JJ (Ad \ ) = , J Ac .First all, note Ad = Ad , thus Ad Ac i.e., |= A. Let ustake arbitrary J Ad , Ad J Ad . Since Ad J,particular Ad J. Furthermore, J (Ad \ ) = , since J Ad .Thus, initial assumption, J |= Ac . allows us conclude(I, ) |= implies |=M A.results allows us conclude element body rule P (eitheratom aggregate), (I, ) |= iff |=M . allows us immediately concludeP (I) = (I, ).KM2PReferencesBanti, F., Alferes, J. J., Brogi, A., & Hitzler, P. (2005). well supported semanticsmultidimensional dynamic logic programs.. Baral, C., Greco, G., Leone, N., &Terracina, G. (Eds.), Logic Programming Nonmonotonic Reasoning, 8th International Conference, LPNMR 2005, Diamante, Italy, September 5-8, 2005, Proceedings,Vol. 3662 Lecture Notes Computer Science, pp. 356368. Springer.Baral, C. (2003). Knowledge Representation, reasoning, declarative problem solvingAnswer sets. Cambridge University Press, Cambridge, MA.Baral, C. (2005). Knowledge Intelligence Building Blocks Applications..Invited Talk, AAAI, www.public.asu.edu/~cbaral/aaai05-invited-talk.ppt.DellArmi, T., Faber, W., Ielpa, G., Leone, N., & Pfeifer, G. (2003). Aggregate FunctionsDisjunctive Logic Programming: Semantics,Complexity,and Implementation DLV.Proceedings 18th International Joint Conference Artificial Intelligence(IJCAI) 2003, pp. 847852.Denecker, M., Pelov, N., & Bruynooghe, M. (2001). Ultimate well-founded stable semantics logic programs aggregates.. Codognet, P. (Ed.), Logic Programming,17th International Conference, ICLP 2001, Paphos, Cyprus, November 26 - December1, 2001, Proceedings, Vol. 2237 Lecture Notes Computer Science, pp. 212226.Springer.Eiter, T., Leone, N., Mateis, C., Pfeifer, G., & Scarcello, F. (1998). KR System dlv:Progress Report, Comparisons, Benchmarks. International ConferencePrinciples Knowledge Representation Reasoning, pp. 406417.Elkabani, I., Pontelli, E., & Son, T. C. (2004). Smodels CLP applications:simple effective approach aggregates asp.. Demoen, B., & Lifschitz, V.(Eds.), Logic Programming, 20th International Conference, ICLP 2004, Saint-Malo,387fiSon, Pontelli, & TuFrance, September 6-10, 2004, Proceedings, Vol. 3132 Lecture Notes ComputerScience, pp. 7389. Springer.Elkabani, I., Pontelli, E., & Son, T. C. (2005). SmodelsA - System Computing Answer Sets Logic Programs Aggregates.. Baral, C., Greco, G., Leone, N., &Terracina, G. (Eds.), Logic Programming Nonmonotonic Reasoning, 8th International Conference, LPNMR 2005, Diamante, Italy, September 5-8, 2005, Proceedings,Vol. 3662 Lecture Notes Computer Science, pp. 427431. Springer.Faber, W., Leone, N., & Pfeifer, G. (2004). Recursive aggregates disjunctive logic programs: Semantics complexity.. Alferes, J. J. , & Leite, J. A. (Eds.), LogicsArtificial Intelligence, 9th European Conference, JELIA 2004, Lisbon, Portugal,September 27-30, 2004, Proceedings, Vol. 3229 Lecture Notes Computer Science,pp. 200212. Springer.Fages, F. (1994). Consistency Clarks completion existence stable models. MethodsLogic Computer Science, pp. 5160.Ferraris, P. (2005). Answer sets propositional theories.. Baral, C., Greco, G., Leone,N., & Terracina, G. (Eds.), Logic Programming Nonmonotonic Reasoning, 8thInternational Conference, LPNMR 2005, Diamante, Italy, September 5-8, 2005, Proceedings, Vol. 3662 Lecture Notes Computer Science, pp. 119131. Springer.Gelder, A. V. (1992). well-founded semantics aggregation.. ProceedingsEleventh ACM SIGACT-SIGMOD-SIGART Symposium Principles DatabaseSystems, June 2-4, 1992, San Diego, California, pp. 127138. ACM Press.Gelfond, M., & Leone, N. (2002). Logic programming knowledge representationA-Prolog perspective. Artificial Intelligence, 138 (1-2), 338.Gelfond, M., & Lifschitz, V. (1988). stable model semantics logic programming.Kowalski, R., & Bowen, K. (Eds.), Logic Programming: Proceedings FifthInternational Conf. Symp., pp. 10701080.Gelfond, M. (2002). Representing Knowledge A-Prolog. Kakas, A., & Sadri, F. (Eds.),Computational Logic: Logic Programming Beyond, pp. 413451. Springer Verlag.Hitzler, P., & Wendt, M. (2005). uniform approach logic programming semantics.Theory Practice Logic Programming, 5 (1-2), 123159.Kemp, D. B., & Stuckey, P. J. (1991). Semantics logic programs aggregates..Saraswat, V. , & Ueda, K. (Eds.), Logic Programming, Proceedings 1991International Symposium, San Diego, California, USA, pp. 387-401. MIT Press.Liu, L., & Truszczynski, M. (2005a). Pbmodels - software compute stable modelspseudoboolean solvers.. Baral, C., Greco, G., Leone, N., & Terracina, G. (Eds.),Logic Programming Nonmonotonic Reasoning, 8th International Conference, LPNMR 2005, Diamante, Italy, September 5-8, 2005, Proceedings, Vol. 3662 LectureNotes Computer Science, pp. 410415.Liu, L., & Truszczynski, M. (2005b). Properties programs monotone convexconstraints.. Veloso, M. M., & Kambhampati, S. (Eds.), Proceedings, Twentieth National Conference Artificial Intelligence Seventeenth Innovative388fiLogic Programs Arbitrary Abstract Constraint AtomsApplications Artificial Intelligence Conference, July 9-13, 2005, Pittsburgh, Pennsylvania, USA, pp. 701706. AAAI Press AAAI Press / MIT Press.Marek, V. W., & Remmel, J. B. (2004). Set constraints logic programming. LogicProgramming Nonmonotonic Reasoning, 7th International Conference, LPNMR2004, Fort Lauderdale, FL, USA, January 6-8, 2004, Proceedings, Vol. 2923 LectureNotes Computer Science, pp. 167179. Springer Verlag.Marek, V. W., & Truszczynski, M. (1999). Stable Models Alternative Logic Programming Paradigm.. Logic Programming Paradigm, Springer Verlag.Marek, V. W., & Truszczynski, M. (2004). Logic programs abstract constraint atoms..Proceedings Nineteenth National Conference Artificial Intelligence, Sixteenth Conference Innovative Applications Artificial Intelligence, July 25-29,2004, San Jose, California, USA. AAAI Press / MIT Press.Mumick, I. S., Pirahesh, H., & Ramakrishnan, R. (1990). magic duplicatesaggregates.. McLeod, D., Sacks-Davis, R., & Schek, H.-J. (Eds.), 16th InternationalConference Large Data Bases, August 13-16, 1990, Brisbane, Queensland,Australia, Proceeding, pp. 264277. Morgan Kaufmann.Niemela, I., (1999). Logic Programs Stable Models Constraint ProgrammingParadigm.. Annals Math AI, 25 (34), 241273.Niemela, I., Simons, P., & Soininen, T. (1999). Stable model semantics weight constraintrules. Proceedings 5th International Conference Logic ProgrammingNonmonotonic Reasoning, pp. 315332.Pelov, N. (2004). Semantic Logic Programs Aggregates. Ph.D. thesis, KatholiekeUniversiteit Leuven. http://www.cs.kuleuven.ac.be/publicaties/doctoraten/cw/CW2004_02.abs.html.Pelov, N., & Truszczynski, M. (2004). Semantics disjunctive programs monotoneaggregates operator-based approach.. Delgrande, J. P., & Schaub, T. (Eds.),10th International Workshop Non-Monotonic Reasoning (NMR 2004), Whistler,Canada, June 6-8, 2004, Proceedings, pp. 327334.Simons, P., Niemela, N., & Soininen, T. (2002). Extending Implementing StableModel Semantics. Artificial Intelligence, 138 (12), 181234.Son, T. C., & Pontelli, E. (2007). Constructive Semantic Characterization AggregatesAnswer Set Programming. Theory Practice Logic Programming. 7 (03),355375.Son, T. C., Pontelli, E., & Elkabani, I. (2006). Unfolding-Based Semantics LogicProgramming Aggregates. Computing Research Repository. cs.SE/0605038.389fiJournal Artificial Intelligence Research 29 (2007) 309-352Submitted 6/06; published 7/07Learning Symbolic Models Stochastic DomainsHanna M. PasulaLuke S. ZettlemoyerLeslie Pack Kaelblingpasula@csail.mit.edulsz@csail.mit.edulpk@csail.mit.eduMIT CSAILCambridge, 02139Abstractarticle, work towards goal developing agents learn actcomplex worlds. develop probabilistic, relational planning rule representationcompactly models noisy, nondeterministic action effects, show ruleseffectively learned. experiments simple planning domains 3D simulatedblocks world realistic physics, demonstrate learning algorithm allowsagents effectively model world dynamics.1. IntroductionOne goals artificial intelligence build systems act complex environments effectively humans do: perform everyday human tasks, like making breakfastunpacking putting away contents office. Many tasks involve manipulating objects. pile things up, put objects boxes drawers, arrangeshelves. requires understanding world works: dependingobjects pile arranged made of, pile sometimes slips fallsover; pulling drawer usually opens it, sometimes drawer sticks; moving boxtypically break items inside it.Building agents perform common tasks challenging problem. work,approach problem developing rule-based representation agents usemodel, learn, effects acting environment. Learning allows agentsadapt new environments without requiring humans hand-craft models, somethinghumans notoriously bad at, especially numeric parametrization required.representation use probabilistic relational, includes additional logicalconcepts. present supervised learning algorithm uses representation languagebuild model action effects given set example action executions. optimizingtradeoff maximizing likelihood examples minimizing complexitycurrent hypothesis, algorithm effectively selects relational model structure,set model parameters, language new relational concepts together providecompact, yet highly accurate description action effects.agent hopes act real world must integrated system perceivesenvironment, understands, commands motors effect changes it. Unfortunately,current state art reasoning, planning, learning, perception, locomotion,manipulation far removed human-level abilities, cannot yet contemplatec2007AI Access Foundation. rights reserved.fiPasula, Zettlemoyer, & Pack KaelblingFigure 1: three-dimensional blocks world simulation. world consists table, several cubesroughly uniform density varying size, robotic gripper movedsimulated motors.working actual domain interest. Instead, choose work domainsalmost ridiculously simplified proxies.1One popular proxy, used since beginning work AI planning (Fikes &Nilsson, 1971) world stacking blocks. typically formalized versionlogic, using predicates on(a, b) clear (a) describe relationships blocksone another. Blocks always neatly stacked; dont fall jumbles.article, present work context slightly less ridiculous version blocksworld, one constructed using three-dimensional rigid-body dynamics simulator (ODE,2004). example world configuration shown Figure 1. simulated blocksworld, blocks vary size colour; piles always tidy, may sometimes fallover; gripper works medium-sized blocks, unreliable even there.approach capable enabling effective behavior domain must handle noisy,nondeterministic nature, nontrivial dynamics, able handledomains similar characteristics.One strategy formulating approach learn models worlds dynamicsuse planning different courses action based goals may changetime. Another strategy assume fixed goal reward function, learnpolicy optimizes reward function. worlds complexity imagining,would impossible establish, advance, appropriate reaction every possiblesituation; addition, expect agent overall control architecturehierarchical, individual level hierarchy changing goals.reasons, learn model world dynamics, use make plansachieve goals hand.begin paper describing assumptions underlie modeling decisions.describe syntax semantics modeling language give algorithm1. reasonable alternative approach, advocated Brooks (1991), working real world,natural complexity, solving problems almost ridiculously simplified proxiesproblems interest.310fiLearning Symbolic Models Stochastic World Dynamicslearning models language. validate models, introduce simple planningalgorithm provide empirical results demonstrating utility learned modelsshowing plan them. Finally, survey relevant previous work,draw conclusions.2. Structured Stochastic Worldsagent introduced novel world must find best possible explanationworlds dynamics within space possible models represent, definedagents representation language. ideal language would able compactly modelevery action effect agent might encounter, others. extra modeling capacitywasted complicate learning, since agent consider larger spacepossible models, likely overfit experience. Choosing good representationlanguage provides strong bias algorithm learn models language.languages used describe deterministic planning models are,least surface, first order; is, abstract particular identities objects, describing effects actions terms properties relations amongobjects. (They accomplish letting action take arguments, representingarguments variables.) representational capacity crucial reasons compactness generalization: usually grossly inefficient describe behaviorindividual objects.Much original work probabilistic planning uses formalism Markov decision processes, represents states world individually atomically (Puterman, 1999). recently, propositional (factored) representations dynamicsemployed (Boyen & Koller, 1998; Guestrin, Koller, Parr, & Venkataraman, 2003),first-order representations developed, including probabilistic rules (Blum & Langford, 1999), equivalence classes (Draper, Hanks, & Weld, 1994), situation calculusapproach Boutilier, Reiter, Price (2001). representations also make easyarticulate take direct advantage two useful assumptions world dynamics:frame assumption, states that, agent takes action world, anythingexplicitly changed stays same, outcome assumption, statesaction affects world small number distinct ways, possible effect causesset changes world happen together single outcome.take point departure probabilistic first-order representations worlddynamics. representations traditionally applied domains logisticsplanning traditional, abstract blocks world, idealized symbolic abstractionsunderlying domain. goal learn models realistic worlds, requiresus adapt modeling language accommodate additional uncertainty complexity.by:Allowing rules refer objects mentioned argument list action.Relaxing frame assumption: allowing unmodeled noise changes world.Extending language: allowing complex forms quantification construction new concepts.311fiPasula, Zettlemoyer, & Pack KaelblingAction parameterization traditional representations action dynamics, objectswhose properties may changed result action must named argumentlist action. Instead, define actions parameters describeobjects free parameters action: example, block picked up,object currently held block placed. However, actions changeproperties objects, ones parameter list, modelsway determining objects affected. paper,introduce use deictic references identify objects. Deictic references (Agre& Chapman, 1987) identify objects relative agent action performed.example, refer objects thing block picked up,currently held object, table block accidentally falls onto. use deicticreferences mechanism adding new logical variables models, muchway Benson (1996).Modeling noise complex domains, actions affect world variety ways.must learn model circumstances reasonable effects,also behavior unusual situations. complicates dynamics, makeslearning difficult. Also, actions executed physical world,guaranteed small number simple effects, result may violateoutcomes assumption. blocks world happen, example, stackknocked over. develop simple noise mechanism allows us partially modelaction effects, ignoring ones rare complicated model explicitly.Language extension traditional symbolic domains, rules constructed usingpredefined set observable predicates. However, sometimes useful define additionalpredicates whose truth values computed based predefined ones.found essential modeling certain advanced planning domains (Edelkamp &Hoffman, 2004).traditional blocks worlds, example, usual set predicates contains on, clearinhand. working realistic, noisy blocks world, foundpredicates would sufficient allow agent learn accurate model.example, would difficult state putting block tall stack likely causestack topple without concept stack height, state attemptingpick block clear usually picks block top stack withoutway describing block top stack.could simply add additional predicates seem useful perceptuallanguage, hand-engineering appropriate language every time tackle new problemdifficult, time consuming, error prone. State-of-the-art planning representationsPDDL (Edelkamp & Hoffman, 2004) use concept language define new predicatesconcepts terms previous, simpler ones. paper, show conceptslearned, much like predicates invented ILP (Khan, Muggleton, & Parson, 1998).see, traditional blocks world predicates, including inhand clear,well useful concepts height, easily defined terms given simpleconcept language (Yoon, Fern, & Givan, 2002).312fiLearning Symbolic Models Stochastic World Dynamics3. State Action Representationgoal learn model state transition dynamics world. so, needable represent set possible states world set possibleactions agent take. represent components using subsetrelatively standard first-order logic equality. representation states actionsground inference, learning, planning.begin defining primitive language includes set constants C, setpredicates , set functions . three types functions : traditionalfunctions, range objects; discrete-valued functions, range predefineddiscrete set values; integer-valued functions, range finite subsetintegers. primitives observed directly world. (In work,assume environment completely observable; is, agent ableperceive unambiguous correct description current state.2 ) constantsC assumed intrinsic meaning, viewed meaningless markersassigned perceptual system, described detail below.3.1 State RepresentationStates describe possible different configurations properties relationsobjects. state describes particular configuration valuesobjects world, individual objects denoted using constants.limit number objects world configuration, though currentformalism mechanism creation deletion objects resultworld dynamics.Formally, state descriptions conjunctive sentences form:^^tG(C,m())^()(t)^(t) = ,tG(C,m())m(x) arity predicate function x, C set c1 . . . cn constants, G(x, a)set length lists elements x, () indicates predicates mayoptionally negated, indicates functions assigned valuerange. manner, states list truth values possible groundingspredicates functions terms. sentence gives complete specification,vocabulary , properties interrelations |C| objects presentworld. (Note predicate function arguments always constants, neverterms made using function symbols, descriptions always finite given finitelanguage.)rest section, describe two approaches denoting objects usingconstants C, illustrate example conjunctive state sentences.3.1.1 Intrinsic Constantsfirst approach state descriptions refers objects using intrinsic constants.intrinsic constant associated particular object consistently used denote2. strong, ultimately indefensible assumption; one highest priorities futurework extend case environment partially observable.313fiPasula, Zettlemoyer, & Pack Kaelblingobject. constants useful perceptual system unique wayidentify perceived objects independent attributes relations one another.example, internet software agent might access universal identifiersdistinguish objects perceives.example, let us consider representing states simple blocks world, usinglanguage contains predicates on, clear, inhand, inhand-nil, block, table,integer-valued function height. objects world include blocks BLOCK-A BLOCK-B,table TABLE, gripper. Blocks blocks table. blocknothing clear. gripper hold one block empty. sentenceinhand-nil on(BLOCK-A, BLOCK-B) on(BLOCK-B, TABLE) on(BLOCK-B, BLOCK-A)on(BLOCK-A, TABLE) on(TABLE, BLOCK-A) on(TABLE, BLOCK-B) on(TABLE, TABLE)on(BLOCK-A, BLOCK-A) on(BLOCK-B, BLOCK-B) table(TABLE) table(BLOCK-A)(1)table(BLOCK-B) block(BLOCK-A) block(BLOCK-B) block(TABLE) clear(BLOCK-A)clear(BLOCK-B) clear(TABLE) inhand(BLOCK-A) inhand(BLOCK-B)inhand(TABLE) height(BLOCK-A) = 2 height(BLOCK-B) = 1 height(TABLE) = 0represents blocks world gripper holds nothing two blocks singlestack table. Block BLOCK-A top stack, BLOCK-B BLOCK-Atable TABLE.encoding, sentence contains meaningful information objectsidentities, used learning world dynamics.3.1.2 Skolem ConstantsAlternatively, states also denote objects using skolem constants. Skolem constantsarbitrary identifiers associated objects world inherentmeaning beyond used state description.3 constants usefulperceptual system way assigning meaningful identifiers objectsobserves. example, consider robot might build state description roomfinds in. assume robot observe objects present,properties, relationships other. However, naming objects,reason choose particular name specific object. Instead, createsarbitrary identifiers, skolem constants, uses build state.Using skolem constants, rewrite Sentence 1 as:inhand-nil on(c001, c002) on(c002, c004) on(c002, c001)on(c001, c004) on(c004, c001) on(c004, c002) on(c004, c004)on(c001, c001) on(c002, c002) table(c004) table(c001)table(c002) block(c001) block(c002) block(c004) clear(c001)clear(c002) clear(c004) inhand(c001) inhand(c002)inhand(c004) height(c001) = 2 height(c002) = 1 height(c004) = 0Here, perceptual system describes table two blocks using arbitraryconstants c004, c001, c002.3. Skolem constants interpreted skolemizations existential variables.314fiLearning Symbolic Models Stochastic World Dynamicsperspective, states world isomorphic interpretationslogical language, since might many interpretations satisfy particular statespecification sentence; interpretations permutationobjects constants refer to. occurs objects distinguishable basedproperties relations objects.techniques develop paper generally applicable representinglearning dynamics worlds intrinsic constants skolem constants.highlight cases true presented. also seeuse skolem constants perceptually plausible also forces uscreate new learning algorithms abstract object identity aggressively previouswork improve quality learned models.3.2 Action RepresentationActions represented positive literals whose predicates drawn special set, ,whose terms drawn set constants C associated worldaction executed.example, simulated blocks world, contains pickup/1, action pickingblocks, puton/1, action putting blocks. action literal pickup(BLOCK-A)could represent action gripper attempts pickup block BLOCK-Astate represented Sentence 1.4. World Dynamics Representationlearning probabilistic transition dynamics world, viewedconditional probability distribution Pr(s0 |s, a), s, s0 A. representdynamics rules constructed basic logic described Section 3, usinglogical variables abstract identities particular objects world.section, begin describing traditional representation deterministic worlddynamics. Next, present probabilistic case. Finally, extend waysmentioned Section 2: permitting rules refer objects mentionedaction description, adding noise, extending language allowconstruction new concepts.dynamic rule action z formx.(x) z(x) 0 (x) ,meaning that, vector terms x context holdscurrent time step, taking action z(x) cause formula 0 hold termsnext step. action z(x) must contain every xi x. constrain 0conjunctions literals constructed primitive predicates terms xi x,functions applied terms set equal value range. addition,allowed contain literals constructed integer-valued functions term relatedinteger range greater-than less-than predicates.say rule covers state action exists substitutionmapping variables x C (note may fewer variables x constants315fiPasula, Zettlemoyer, & Pack KaelblingC) |= ((x)) = z((x)). is, substitution constantsvariables that, applied context (x), grounds entailedstate and, applied rule action z(x), makes equal action a.Now, given rule covers a, say subsequent state s0 ?First, rule directly specifies 0 ((x)) holds next step. mayincomplete specification state; use frame assumption fill rest:s0 = 0 ((x))^^l(s, , (x)){{(t):tG(C,m())}pos(0 ((x)))}^^l(s, , (x)) ,{{(t):tG(C,m())}funct(0 ((x)))}l(s, y, t) stands literal predicate function argumentlist t, pos(0 ) set literals 0 negations ignored, funct(0 ) setground functions 0 extracted equality assignments. sayevery literal would needed make complete description stateincluded 0 ((x)) retrieved, associated truth value equality assignment,s.general set rules action, require contextsmutually exclusive, given state-action pair covered one rule;covered none, assume nothing changes. 4 example, considersmall set rules picking blocks,pickup(X, Y) : inhand-nil, on(X, Y), block(Y), height(Y) < 10inhand(X), on(X, Y), clear(Y),pickup(X, Y) : inhand-nil, on(X, Y), table(Y)inhand(X), on(X, Y).top line rule shows action followed context; next line describeseffects, outcome. According two rules, executing pickup(X, Y) changesworld hand empty X Y. exact set changes dependswhether table, block height nine less.4.1 Probabilistic Rulesdeterministic dynamics rules described allow generalization objectsexploitation frame assumption, well suited use highlystochastic domains. order apply domains extenddescribe probability distribution resulting states, Pr(s0 |s, a). Probabilistic STRIPSoperators (Blum & Langford, 1999) model agents actions affect world arounddescribing actions alter properties relationships objectsworld. rule specifies small number simple action outcomessets changesoccur tandem.4. Without restriction, would need define method choosing possibly conflicting predictions different covering rules. simplest way would involve picking onerules, perhaps specific one, one confident of. (Rule confidence scoreswould estimated.)316fiLearning Symbolic Models Stochastic World Dynamicssee probabilistic rules formp101 (x)x.(x) z(x) . . . . . .p0n n (x),p1 . . . pn positive numbers summing 1, representing probability distribution, 01 . . . 0n formulas describing subsequent state, s0 .Given state action a, compute coverage deterministiccase. Now, however, given covering substitution (x), probabilistic rules longer predictunique successor state. Instead, 01 . . . 0n used construct new state,single 0 deterministic case. n possible subsequentstates, s0i , occur associated probability pi .probability rule r assigns moving state state s0 actiontaken, Pr(s0 |s, a, r), calculated as:P (s0 |s, a, r) =XP (s0 , 0i |s, a, r)0i r=XP (s0 |0i , s, a, r)P (0i |s, a, r)(2)0i rP (0i |s, a, r) pi , outcome distribution P (s0 |0i , s, a, r) deterministicdistribution assigns mass relevant s0 . P (s0 |0i , s, a, r) = 1.0, is,s0 state would constructed given rule outcome, sayoutcome 0i covers s0 .general, possible, representation, subsequent state s0 coveredone rules outcomes. case, probability s0 occurringsum probabilities relevant outcomes. Consider rule painting blocks:paint(X) : inhand(X), block(X)(.8 : painted(X), wet.2 : change.rule used model transition caused action paint(a) initialstate contains wet painted(a), one possible successor state: onechange occurs, wet painted(a) remain true. outcomes describeone successor state, must sum probabilities recover states totalprobability.set rules specifies complete conditional probability distribution Pr(s0 |s, a)following way: current state action covered exactly one rule,distribution subsequent states prescribed rule. not, s0 predictedprobability 1.0.317fiPasula, Zettlemoyer, & Pack Kaelblingexample, probabilistic set rules picking blocks might look follows:pickup(X, Y) : inhand-nil, on(X, Y), block(Y), height(Y) < 10(.7 : inhand(X), on(X, Y), clear(Y).3 : changepickup(X, Y) : inhand-nil, on(X, Y), table(Y)(.8 : inhand(X), on(X, Y).2 : changetop line rule still shows action followed context; bracket surroundsoutcomes distribution. outcomes before,small chance occur.4.2 Deictic Referencestandard relational representations action dynamics, variable denoting objectwhose properties may changed result action must named argumentlist action. result awkwardness even deterministic situations. example, abstract action picking block must take two arguments. pickup(X, Y),X block picked block picked up.relationship encoded added condition on(X, Y) rules context. condition restrict applicability rule; exists guarantee boundappropriate object. restriction adopted means that, givengrounding action, variables rule bound, necessarysearch substitutions would allow rule cover state. However, complicate planning because, many cases, ground instances operator considered,even though eventually rejected due violations preconditions.example, would reject instances violating on(X, Y) relation context.complex domains, requirement even awkward: dependingcircumstances, taking action may affect different, varied sets objects. blocks worldsblock may several others, pickup action may affect propertiesblocks. model without additional mechanism referring objects,might increase, even vary, number arguments pickup takes.handle gracefully, extend rule formalism include deictic referencesobjects. rule may augmented list, D, deictic references. deicticreference consists variable Vi restriction set literals defineVi respect variables x action Vj j < i.restrictions supposed pick single, unique object: notif pickseveral, nonethe rule fails apply. So, handle pickup action described above,action would single argument, pickup(X), rule would contain deicticvariable V constraint on(X, V).use rules deictic references, must extend procedure computing rulecoverage ensure deictic references resolved. deictic variablesmay bound simply starting bindings x working sequentiallydeictic variables, using restrictions determine unique bindings. point318fiLearning Symbolic Models Stochastic World Dynamicsbinding deictic variable unique, fails refer, rule fails coverstateaction pair.formulation means extra variables need included action specification, reduces number operator instances, yet, requirementunique designation, substitution still quickly discovered testing coverage.So, example, denote red block table V2 (assumingone table one block) would use following deictic references:V1 : table(V1 )V2 : color (V2 ) = red block (V2 ) on(V2 , V1 ) .several, no, tables world, then, rule semantics, firstreference would fail: similarly, second reference would fail number red blocksunique table represented V1 one.give action-oriented example, denoting block top blocktouched, touch(Z) action, would use following deictic reference:V1 : on(V1 , Z) block (V1 ) .set deictic probabilistic rules picking blocks might look follows:pickup(X) :n: inhand(Y), Z : table(Z)empty context(.9 : inhand-nil, inhand(Y), on(Y, Z).1 : changepickup(X) :n: block(Y), on(X, Y)inhand-nil, height(Y) < 10(.7 : inhand(X), on(X, Y), clear(Y).3 : changepickup(X) :n: table(Y), on(X, Y)inhand-nil(.8 : inhand(X), on(X, Y).2 : changetop line rule shows action followed deictic variables,variable annotated restriction. next line context, outcomesdistribution follow. first rule applies situations somethinggripper, states probability 0.9 action cause grippedobject fall table, nothing change otherwise. second rule appliessituations object picked another block, statesprobability success 0.7. third rule applies situations objectpicked table describes slightly higher success probability, 0.8. Notedifferent objects affected, depending state world.319fiPasula, Zettlemoyer, & Pack Kaelbling4.3 Adding NoiseProbability models type seen thus far, ones small set possibleoutcomes, sufficiently flexible handle noise real world. maylarge number possible outcomes highly unlikely, reasonably hard model:example, configurations may result tall stack blocks topples.would inappropriate model outcomes impossible, dont spaceinclination model individual outcome.So, allow rule representation account results noise. definition, noise able represent outcomes whose probability havent quantified.Thus, allowing noise, lose precision true probability distributionnext states.handle noise, must change rules two ways. First, ruleadditional noise outcome 0noise , associated probability P (0noise |s, a, r); now,set outcome probabilities must sum 1.0 include P (0noise |s, a, r) wellP (01 |s, a, r) . . . P (0n |s, a, r). However, 0noise associated list literals,since declining model detail happens world cases.Second, create additional default rule, empty context two outcomes: empty outcome (which, combination frame assumption, modelssituations nothing changes), and, again, noise outcome (modeling situations). rule allows noise occur situations specific rule applies;probability assigned noise outcome default rule specifies kind backgroundnoise level.Since explicitly modeling effects noise, longer calculatetransition probability Pr(s0 |s, a, r) using Equation 2: lack required distributionP (s0 |0i , s, a, r) noise outcome. Instead, substitute worst case constant boundpmin P (s0 |0noise , s, a, r). allows us bound transition probabilityP (s0 |s, a, r) = pmin P (0noise |s, a, r) +XP (s0 |0i , s, a, r)P (0i |s, a, r)0i rP (s0 |s, a, r).(3)Intuitively, pmin assigns small amount probability mass every possible next stateNote take value higher true minimum: approximation.However, ensure probability model remains well-defined, pmin times numberpossible states exceed 1.0.way, create partial model allows us ignore unlikely overly complexstate transitions still learning acting effectively. 5Since rules include noise deictic references, call Noisy Deictic Rules(NDRs). rather stochastic world, set NDRs picking blocks mights0 .5. P (s0 |0noise , s, a, r) could modeled using well-defined probability distribution describing noiseworld, would give us full distribution next states. premisemight difficult specify distributionin domain, would ensuredistribution assign probability worlds impossible, worlds blocksfloating midair. long events unlikely enough would want considerplanning, reasonable model directly.320fiLearning Symbolic Models Stochastic World Dynamicslook follows:pickup(X) :n: inhand(Y), Z : table(Z)empty context.6 : inhand-nil, inhand(Y), on(Y, Z).1 : change.3 : noisepickup(X) :n: block(Y), on(X, Y)inhand-nil, height(Y) < 10.7 : inhand(X), on(X, Y), clear(Y).1 : change.2 : noisenpickup(X) :: table(Y), on(X, Y)inhand-nil.8 : inhand(X), on(X, Y).1 : change.1 : noisedefault (rule:.6 : change.4 : noiseformat rules before, Section 4.2, except ruleincludes explicit noise outcome. first three rules similar old versions,difference model noise. final rule default rule: statesthat, rule applies, probability observing change 0.4.Together rules provide complete example type rule set learnSection 5.1. However, written fixed modeling language functionspredicates. next section describes concepts used extend language.4.4 Concept Definitionsaddition observed primitive predicates, often useful backgroundknowledge defines additional predicates whose truth values computed basedobservations. found essential modeling certain planningdomains (Edelkamp & Hoffman, 2004).background knowledge consists definitions additional concept predicatesfunctions. work, express concept definitions using concept languageincludes conjunction, existential quantification, universal quantification, transitive closure, counting. Quantification used defining concepts inhand(X) :=block(X) Y.on(X, ). Transitive closure included language via Kleene staroperator defines concepts above(X, ) := (X, ). Finally, counting included using special quantifier # returns number objects formulatrue. useful defining integer-valued functions height(X) := #Y.above(X, ).321fiPasula, Zettlemoyer, & Pack Kaelblingdefined, concepts enable us simplify context deictic variable definitions, well restrict ways cannot described using simple conjunctions.Note, however, need track concept values outcomes, sincealways computed primitives. Therefore, rule contexts use languageenriched concepts; outcomes contain primitives.example, deictic noisy rule attempting pick block X, sideside background knowledge necessary primitive predicatestable.pickup(X) :: topstack(Y, X),Z : on(Y, Z),: table(T)inhand-nil, height(Y) < 9.80 : on(Y, Z).10 : on(Y, Z), on(Y, T).05 : change.05 : noiseclear(X):= Y.on(Y, X)inhand(X) := block(X) Y.on(X, Y)inhand-nil := Y.inhand(Y)above(X, Y):= (X, Y)(4)topstack(X, Y) := clear(X) above(X, Y)height(X) := #Y.above(X, Y)rule complicated example rules given thus far: dealssituation block picked up, X, middle stack. deictic variableidentifies (unique) block top stack, deictic variable Zthe object, deictic variable Tthe table. might expected, gripper succeedslifting high probability.concept definitions include clear(X), defined exists objectX; inhand(X), defined X block object; inhand-nil, definedexists object hand; above(X, Y), defined transitiveclosure on(X, Y); topstack(X, Y), defined X Y, clear; height(X),defined number objects X using chain ons. explainedabove, concepts used context deictic variable definitions,outcomes track primitive predicates; fact, appears outcomes, sincevalue table predicates never changes.4.5 Action Modelscombine set concept definitions set rules define action model.best action models represent rule set using NDRs, but, comparison purposes,experiments involve rule sets use simpler representations, withoutnoise deictic references. Moreover, rule sets differ whether allowedcontain constants. rules presented far contained none, neithercontext outcomes. reasonable setup states contain skolemconstants, constants inherent meaning names assignedgeneral repeated. However, states intrinsic constants, perfectlyacceptable include constants action models. all, constants useduniquely identify objects world.develop learning algorithm next section, assume generalconstants allowed action model, show simple restrictions within322fiLearning Symbolic Models Stochastic World Dynamicsalgorithm ensure learned models contain any. also show,Section 7, learning action models restricted free constants providesuseful bias improve generalization training small data sets.5. Learning Action Modelsdefined rule action models, describe may constructedusing learning algorithm attempts return action model best explains setexample actions results. formally, algorithm takes training set E,example (s, a, s0 ) triple, searches action model maximizeslikelihood action effects seen E, subject penalty complexity.Finding involves two distinct problems: defining set concept predicates,constructing rule set R using language contains predicates togetherdirectly observable primitive predicates. section, first discuss second problem,rule set learning, assuming fixed set predicates provided learner. Then,present simple algorithm discovers new, useful concept predicates.5.1 Learning Rule Setsproblem learning rule sets is, general, NP-hard (Zettlemoyer, Pasula, & Kaelbling,2003). Here, address problem using greedy search. structure searchhierarchically identifying two self-contained subproblems: outcome learning,subproblem general rule set search, parameter estimation, subproblemoutcome learning. Thus, overall algorithm involves three levels greedy search:outermost level, LearnRules, searches space rule sets, oftenconstructing new rules, altering existing ones; middle level, InduceOutcomes which,given incomplete rule consisting context, action, set deictic references, fillsrest rule; innermost level, LearnParameters, takes slightlycomplete rule, lacking distribution outcomes, finds distributionoptimizes likelihood examples covered rule. present threelevels starting inside out, subroutine described onedepends it. Since three subroutines attempt maximize scoring metric,begin introducing metric.5.1.1 Scoring Metricgreedy search algorithm must judge parts search space desirable.Here, done help scoring metric rule sets,S(R) =Xlog(P (s0 |s, a, r(s,a) ))(s,a,s0 )EXP EN (r)(5)rRr(s,a) rule governing transition occurring performed s,scaling parameter, P EN (r) complexity penalty applied rule r. Thus, S(R)favors rule sets maximize likelihood bound data penalizes rule setsoverly complex.Ideally, P would likelihood example. However, rules noise outcomescannot assign exact likelihood so, case, use lower bound defined Equa323fiPasula, Zettlemoyer, & Pack Kaelblingtion 3 instead. P EN (r) defined simply total number literals r. chosepenalty simplicity, also performed worse penaltyterm tested informal experiments. scaling parameter set 0.5 experiments, could also set using cross-validation hold-out datasetprincipled technique. metric puts pressure model explain examples usingnon-noise outcomes, increases P , also opposing pressure complexity, viaP EN (r).assume state-action pair (s, a) covered one rule (which,finite set examples, enforced simply ensuring examples stateaction pair covered one rule) rewrite metric terms rules ratherexamples, giveS(R) =XXrR(s,a,s0 )Erlog(P (s0 |s, a, r)) P EN (r)(6)Er set examples covered r. Thus, rules contribution S(R)calculated independently others.5.1.2 Learning Parametersfirst algorithms described section, LearnParameters, takes incompleterule r consisting action, set deictic references, context, set outcomes,learns distribution P maximizes rs score examples Er covered it.Since procedure allowed alter number literals rule, thereforecannot affect complexity penalty term, optimal distribution simply onemaximizes log likelihood Er . case rules noise outcomeslog(P (s0 |s, a, r))XL =(s,a,s0 )Er=log pmin P (0noise |s, a, r) +XXP (s0 |0i , s, a, r)P (0i |s, a, r) .(7)0i r(s,a,s0 )Ernon-noise outcome, P (s0 |0i , s, a, r) one 0i covers (s, a, s0 ) zero otherwise.(In case rules without noise outcomes, sum slightly simpler,pmin P (0noise |s, a, r) term missing.)every example covered unique outcome, Ls maximum expressedclosed form. Let set examples covered outcome 0 E0 . addLagrange multiplier enforce constraint P (0i |s, a, r) distributions must sum1.0, getL =X(s,a,s0 )Er=XE0logXP (s0 |0i , s, a, r)P (0i |s, a, r) + (X0i r0i|E0 | log P (0i |s, a, r) + (XP (0i |s, a, r) 1.0) .0i324P (0i |s, a, r) 1.0)fiLearning Symbolic Models Stochastic World DynamicsThen, partial derivative L respect P (0i |s, a, r) |E0 |/P (0i |s, a, r)= |E|, P (0i |s, a, r) = |E0i |/|E|. Thus, parameters estimatedcalculating percentage examples outcome covers.However, seen Section 4.1, possible example coveredone outcome; indeed, noise outcome, covers examples,always case. situation, sum examples cannot rewrittensimple sum terms representing different outcomes containing singlerelevant probability: probabilities overlapping outcomes remain tied together,general closed-form solution exists, estimating maximum-likelihood parametersnonlinear programming problem. Fortunately, instance well-studied problemmaximizing concave function (the log likelihood presented Equation 7) probability simplex. Several gradient ascent algorithms known problem (Bertsekas,1999); since function concave, guaranteed converge global maximum.LearnParameters uses conditional gradient method, works by, iteration,moving along parameter axis maximal partial derivative. step-sizeschosen using Armijo rule (with parameters = 1.0, = 0.1, = 0.01.)search converges improvement L small, less 106 . chosealgorithm easy implement converged quickly experimentstried. However, problems found method converges slowly, onemany nonlinear optimization methods, constrained Newtons method,could directly applied.5.1.3 Inducing OutcomesGiven LearnParameters, algorithm learning distribution outcomes,consider problem taking incomplete rule r consisting context, action,perhaps set deictic references, finding optimal way fill restrulethat is, set outcomes {01 . . . 0n } associated distribution Pmaximize scoreS(r) =Xlog(P (s0 |s, a, r)) P ENo (r),(s,a,s0 )ErEr set examples covered r, P ENo (r) total number literalsoutcomes r. (S(r) factor scoring metric Equation 6 duerule r, without aspects P EN (r) fixed purposes subroutine:number literals context.)general, outcome induction NP-hard (Zettlemoyer, Pasula, & Kaelbling, 2003). InduceOutcomes uses greedy search restricted subset possible outcome sets:proper training examples, outcome set proper every outcomecovers least one training example. Two operators, described below, movespace immediate moves improve rule score. setoutcomes considers, InduceOutcomes calls LearnParameters supply best P can.initial set outcomes created by, example, writing setatoms changed truth values result action, creating outcomedescribe every set changes observed way.325fiPasula, Zettlemoyer, & Pack KaelblingE1E2E3E401020304= t(c1), h(c2) h(c1), h(c2)= h(c1), t(c2) h(c1), h(c2)= h(c1), h(c2) t(c1), t(c2)= h(c1), h(c2) h(c1), h(c2)(a)= {h(c1)}= {h(c2)}= {t(c1), t(c2)}= {no change}(b)Figure 2: (a) Possible training data learning set outcomes. (b) initial setoutcomes would created data (a) picking smallestoutcome describes change.example, consider coins domain. coins world contains n coins,showing either heads tails. action flip-coupled, takes arguments,flips coins, half time heads, otherwise tails. set trainingdata learning outcomes two coins might look like part (a) Figure 2 h(C)stands heads(C), t(C) stands heads(C), s0 part (s, a, s0 ) example= flip-coupled. suppose suggested rule flip-coupledcontext deictic references. Given data, initial set outcomes fourentries part (b) Figure 2.rule contained variables, either abstract action arguments deicticreferences, InduceOutcomes would introduce variables appropriate placesoutcome set. variable introduction achieved applying inverse actionsubstitution examples set changes computing initial set outcomes. 6So, given deictic reference C : red(C) always found refer c1, redcoin, example set outcomes would contain C wherever currently contains c1.Finally, disallow use constants rules, variables become wayoutcomes refer objects whose properties changed. Then, changes containingconstant referred variable cannot expressed, correspondingexample covered noise outcome.Outcome Search OperatorsInduceOutcomes uses two search operators. first add operator, pickspair non-contradictory outcomes set creates new outcomeconjunction. example, might pick 01 02 combine them, adding newoutcome 05 = {h(c1), h(c2)} set. second remove operator dropsoutcome set. Outcomes dropped overlappingoutcomes every example cover, otherwise outcome set would remain proper.(Of course, outcome set contains noise outcome, every outcomedropped, since examples covered noise outcome.) Whenever operatoradds removes outcome, LearnParameters called find optimal distribution6. Thus, InduceOutcomes introduces variables aggressively wherever possible, based intuitioncorresponding objects would better described constant, become apparenttraining example.326fiLearning Symbolic Models Stochastic World Dynamicsnew outcome set, used calculate maximum log likelihooddata respect new outcome set.Sometimes, LearnParameters return zero probabilities outcomes.outcomes removed outcome set, since contribute nothinglikelihood, add complexity. optimization improves efficiencysearch.outcomes Figure 2, 04 dropped since covers E4 , alsocovered 01 02 . new outcome created conjoiningexisting ones 05 = {h(c1), h(c2)}, covers E1 , E2 , E3 . Thus, 05 added,01 02 dropped. Adding 05 dropping 01 , 02 , 04 creates outcomeset {03 , 05 }, optimal set outcomes training examples Figure 2.Notice outcome always equal union sets literals changetraining examples covers. fact ensures every proper outcome mademerging outcomes initial outcome set. InduceOutcomes can, theory, findset outcomes.5.1.4 Learning Rulesknow fill incomplete rules, describe LearnRules, outermostlevel learning algorithm, takes set examples E fixed languageprimitive derived predicates, performs greedy search space rulesets. precisely, searches space proper rule sets, rule set Rdefined proper respect data set E includes one ruleapplicable every example e E change occurs, includerules applicable examples.search proceeds described pseudocode Figure 3. starts rule setcontains default rule. every step, takes current rule set appliessearch operators obtain set new rule sets. selects rule set Rmaximizes scoring metric S(R) defined Equation 5. Ties S(R) brokenrandomly.begin explaining search initialized, go describeoperators used, finish working simple example shows LearnRulesaction.Rule Set Search InitializationLearnRules initialized proper rule set. paper, always initializeset noisy default rule. treats action effects training setnoise; search progresses, search operators introduce rules explain actioneffects explicitly. chose initial starting point simplicity, workedwell informal experiments. Another strategy would start specific ruleset, describing detail examples. bottom-up methods advantagedata-driven, help search reach good parts search spaceeasily. However, show, several search operators used algorithmpresented guided training examples, algorithm alreadydesirable property. Moreover, bottom-up method bad complexity properties327fiPasula, Zettlemoyer, & Pack KaelblingLearnRuleSet(E)Inputs:Training examples EComputation:Initialize rule set R contain default rulebetter rules sets foundsearch operatorCreate new rule sets O, RO = O(R, E)rule set R0 ROscore improves (S(R0 ) > S(R))Update new best rule set, R = R0Output:final rule set RFigure 3: LearnRuleSet pseudocode. algorithm performs greedy search spacerule sets. step set search operators propose set new rule sets.highest scoring rule set selected used next iteration.situations large data set described using relatively simple set rules,case interested in.Rule Set Search Operatorsrule set search, LearnRules repeatedly finds applies operatorincrease score current rule set most.search operators work creating new rule set rules (usuallyaltering existing rule) integrating new rules rule set wayensures rule set remains proper. Rule creation involves picking action z,set deictic references D, context , calling InduceOutcomeslearning algorithm complete rule filling 0i pi s. (If new rule coversexamples, attempt abandoned, since adding rule cannot help scoringmetric.) Integration rule set involves adding new rules, also removingold rules cover examples. increase number examplescovered default rule.5.1.5 Search Operatorssearch operator takes input rule set R set training examples E,creates set new rule sets RO evaluated greedy search loop. elevensearch operators. first describe complex operator, ExplainExamples, followedsimple one, DropRules. Then, present remaining nine operators,share common computational framework outlined Figure 4.Together, operators provide many different ways moving spacepossible rule sets. algorithm adapted learn different types rule sets (forexample, without constants) restricting set search operators used.328fiLearning Symbolic Models Stochastic World DynamicsOperatorTemplate(R, E)Inputs:Rule set RTraining examples EComputation:Repeatedly select rule r RCreate copy input rule set R0 = RCreate new set rules, N , making changes rnew rule r0 N covers examplesEstimate new outcomes r0 InduceOutcomesAdd r0 R0 remove rules R0 coverexamples r0 coversRecompute set examples default rule R0covers parameters default ruleAdd R0 return rule sets ROOutput:set rules sets, ROFigure 4: OperatorTemplate Pseudocode. algorithm basic framework usedsix different search operators. operator repeatedly selects rule, uses make nnew rules, integrates rules original rule set create new rule set.ExplainExamples takes input training set E rule set R creates new,alternative rule sets contain additional rules modeling training examplescovered default rule R. Figure 5 shows pseudocodealgorithm, considers training example E covered defaultrule R, executes three-step procedure. first step builds largespecific rule r0 describes example; second step attempts trim rule,generalize maximize score, still ensuring covers E;third step creates new rule set R0 copying R integrating newrule r0 new rule set.illustration, let us consider steps 1 2 ExplainExamples mightapplied training example (s, a, s0 ) = ({on(a, t), on(b, a)}, pickup(b), {on(a, t)}),background knowledge defined Rule 4 Section 4.4 constantsallowed.Step 1 builds rule r. creates new variable X represent object baction; then, action substitution becomes = {X b}, action rset pickup(X). context r set conjunction inhand-nil, inhand(X),clear(X), height(X) = 2, on(X, X), above(X, X), topstack(X, X). Then, Step1.2, ExplainExamples attempts create deictic references name constantswhose properties changed example, already action substitution. case, changed literal on(b, a), b substitution,C = {a}; new deictic variable created restricted, extended329fiPasula, Zettlemoyer, & Pack KaelblingExplainExamples(R, E)Inputs:rule set Rtraining set EComputation:example (s, a, s0 ) E covered default rule RStep 1: Create new rule rStep 1.1: Create action context rCreate new variables represent argumentsUse create new action substitutionSet rs action 1 (a)Set rs context conjunction boolean equality literalsformed using variables available functions predicates(primitive derived) entailedStep 1.2: Create deictic references rCollect set constants C whose properties changed s0 ,c CCreate new variable v extend map v cCreate , conjunction literals containing v formed usingavailable variables, functions, predicates, entailedCreate deictic reference variable v restriction 1 ()uniquely refers c s, add rStep 1.3: Complete ruleCall InduceOutcomes create rules outcomes.Step 2: Trim literals rCreate rule set R0 containing r default ruleGreedily trim literals r, ensuring r still covers (s, a, s0 ) fillingoutcomes using InduceOutcomes R0 score stops improvingStep 3: Create new rule set containing rCreate new rule set R0 = RAdd r R0 remove rules R0 cover examples r coversRecompute set examples default rule R0 covers parametersdefault ruleAdd R0 return rule sets ROOutput:set rule sets, ROFigure 5: ExplainExamples Pseudocode. algorithm attempts augment rule set newrules covering examples currently handled default rule.330fiLearning Symbolic Models Stochastic World Dynamics{X b, a}. Finally, Step 1.3, outcome set created. Assumingexamples context applies, nine ten end X lifted,rest falling onto table, resulting rule r0 looks follows:inhand(Y ), clear(Y), on(X, Y), table(Y)pickup(X) : : above(X, Y), topstack(X, Y), above(Y, Y)topstack(Y, Y), on(Y, Y), height(Y) = 1inhand-nil, inhand(X), clear(X), table(X), height(X) = 2, on(X, X),above(X,X), topstack(X, X)0.9 : on(X, Y)0.1 : noise(The falls table outcome modeled noise, since absence constantsrule way referring table.)Step 2, ExplainExamples trims rule remove literals always truetraining examples, like on(X, X), table()s, redundant ones,like inhand(), clear(Y), perhaps one heights, givepickup(X) : : on(X, Y)inhand-nil,clear(X), height(X) = 20.9 : on(X, Y)0.1 : noiserules context describes starting example concisely. Explain Examplesconsider dropping remaining literals, thereby generalizing ruleapplies examples different starting states. However, generalizationsnecessarily improve score. smaller contexts, might endcreating outcomes describe new examples, penalty termguaranteed improve. change likelihood term depend whethernew examples higher likelihood new rule default rule,whether old examples higher likelihood old distributionnew one. Quite frequently, need cover new examplesgive new rule distribution closer random before, usuallylead decrease likelihood large overcome improvementpenalty, given likelihood-penalty trade-off.Let us assume that, case, predicate dropped without worseninglikelihood. rule integrated rule set is.DropRules cycles rules current rule set, removes oneturn set. returns set rule sets, one missing different rule.remaining operators create new rule sets input rule set R repeatedlychoosing rule r R making changes create one new rules. newrules integrated R, ExplainExamples, create new rule set R0 .Figure 4 shows general pseudocode done. operators varyway select rules changes make them. variations described331fiPasula, Zettlemoyer, & Pack Kaelblingoperator below. (Note operators, deal deicticreferences constants, applicable action model representation allowsfeatures.)DropLits selects every rule r R n times, n number literalscontext r; words, selects r literal context.creates new rule r0 removing literal rs context; N Figure 4simply set containing r0 .So, example pickup rule created ExplainExamples would selected three times,inhand-nil, clear(X), one height(X) = 2, would createthree new rules (each different literal missing), three singleton N sets,three candidate new rule sets R0 . Since newly-created r0 generalizations r,certain cover rs examples, r removedR0 s.changes suggested DropLits therefore exactly suggested trimming search ExplainExamples, one crucial difference:DropLits attempts integrate new rule full rule set, instead making quick comparison default rule Step 2 ExplainExamples.ExplainExamples used trimming search relatively cheap, localheuristic allowing decide rule size, DropLits uses search globallyspace rule sets, comparing contributions various conflicting rules.DropRefs operator used deictic references permitted. selectsrule r R deictic reference r. creates new rule r0removing deictic reference r; N is, again, set containing r0 .applying operator, pickup rule would selected once, referencedescribing , one new rule set would returned: one containing rulewithout .GeneralizeEquality selects rule r R twice equality literal contextcreate two new rules: one equality replaced , onereplaced . rule integrated rule set R,resulting two R0 returned. Again, generalized rules certain coverrs examples, R0 contain r.context pickup rule contains one equality literal, height(X) = 1. GeneralizeEquality attempt replace literal height(X) 1 height(X) 1.domain containing two blocks, would likely yield interestinggeneralizations.ChangeRanges selects rule r R n times equality inequality literalcontext, n total number values range literal.time selects r creates new rule r0 replacing numeric value chosen(in)equality another possible value range. Note quite possiblenew rules cover examples, abandoned.remaining rules integrated new copies rule set usual.332fiLearning Symbolic Models Stochastic World DynamicsThus, f () ranges [1 . . . n], ChangeRange would, applied rule containing inequality f () < i, construct rule sets replacedintegers [1 . . . n].pickup rule contains one equality literal, height(X) = 1. two-block domain(s, a, s0 ) example drawn, height() take values 0, 1, 2,rule will, again, selected thrice, new rules created containingnew equalities. Since rule constrains X something, new rule containingheight(X) = 0 never cover examples certainly abandoned.SplitOnLits selects rule r R n times, n number literalsabsent rules context deictic references. (The set absent literalsobtained applying available functions predicatesboth primitivederivedto terms present rule, removing literals already presentrule resulting set.) constructs set new rules. casepredicate inequality literals, creates one rule positive versionliteral inserted context, one negative version.case equality literals, constructs rule every possible value equality couldtake. either case, rules cover examples dropped. remainingrules corresponding one literal placed N , integratedrule set simultaneously.Note newly created rules will, them, cover examplesstart covered original rule others, examplessplit them.list literals may added pickup rule consists inhand(X),inhand(Y), table(X), table(Y), clear(Y), on(Y, X), on(Y, Y), on(X, X), height(Y) =?,possible applications topstack. literals makeinteresting examples: adding context create rules eithercover examples all, abandoned, cover setexamples original rule, rejected likelihoodworse penalty. However, illustrate process, attempting addheight(Y) =? predicate result creation three new rules height(Y) = ncontext, one n [0, 1, 2]. rules would added rule setonce.AddLits selects rule r R 2n times, n number predicate-basedliterals absent rules context deictic references, 2 reflects fact literal may considered positive negative form.constructs new rule literal inserting literal earliest placerule variables well-defined: literal contains deicticvariables, context, otherwise restriction lastdeictic variable mentioned literal. (So, V1 V2 deictic variables V1appears first, on(V1 , V2 ) would inserted restriction V2 .) resultingrule integrated rule set.list literals may added pickup rule much SplitOnLits,without height(Y) =?. Again, process lead anything interesting333fiPasula, Zettlemoyer, & Pack Kaelblingexample, reason. illustration, inhand(Y) wouldchosen twice, inhand(Y), added context case. Sincecontext already contains inhand-nil, adding inhand(Y) redundant, addinginhand(Y) produce contradiction, neither rule seriously considered.AddRefs operator used deictic references permitted. selectsrule r R n times, n number literals constructedusing available predicates, variables r, new variable v. case,creates new deictic reference v, using current literal define restriction,adds deictic reference antecendent r construct new rule,integrated rule set.Supposing V new variable, list literals would constructedpickup rule consists inhand(V), clear(V), on(V, X), on(X, V), table(V), on(V, Y),on(Y, V), on(V, V), possible applications topstack (whichmirror on.) used create deictic references like V : table(V).(A useful reference here, allows rule describe falls table outcomesexplicitly; operator likely accepted point search.)RaiseConstants operator used constants permitted. selectsrule r R n times, n number constants among arguments rsaction. constant c, constructs new rule creating new variablereplacing every occurrence c it. integrates new rule ruleset.SplitVariables operator used constants permitted. selectsrule r R n times, n number variables among arguments rsaction. variable v, goes examples covered rule rcollects constants v binds to. Then, creates rule constantsreplacing every occurrence v constant. rules corresponding onevariable v combined set N integrated old rule set together.found operators consistently used learning.set operators heuristic, complete sense every rule setconstructed initial rule setalthough, course, guaranteescoring metric lead greedy search global maximum.LearnRuless search strategy one large drawback; set learned rulesguaranteed proper training set testing data. New test examplescould covered one rule. happens, employ alternativerule-selection semantics, return default rule model situation. way,essentially saying dont know happen. However,significant problem; problematic test examples always added future trainingset used learn better models. Given sufficiently large training set, failuresrare.334fiLearning Symbolic Models Stochastic World Dynamicse1:B2B2B0puton(B1)B2B0puton(B1)B0B1B1e3:r1 :r2 :puton(X):(): inhand(Y): table(T)emptycontext0.33 : on(Y, T)0.33 : on(Y, X)0.34 : noiser3 :puton(X):n: inhand(Y)clear(X)n1.0 : on(Y, X)B1B1e2:B0puton(X):(): inhand(Y)Z : on(Z, X)empty( context0.5 : on(Y, Z)0.5 : noiseB2B2puton(B1)B0 B1B2B0 B1Figure 6: Three training examples three blocks world. example paired initialrule ExplainExamples might create model it. example, agent tryingput block B2 onto block B1.Example Rule Set Learningexample, consider LearnRuleSet might learn set rules model threetraining examples Figure 6, given settings complexity penalty noise boundlater used experiments: = 0.5 pmin = 0.0000001. pmin lowthree-block domain, since 25 different states, use consistency.initialization, rule set contains default rule; changes occurexamples modeled noise. Since examples include change, default rulenoise probability 1.0. describe path greedy search takes.first round search ExplainExamples operator suggests adding newrules describe examples. general, ExplainExamples tries construct rulescompact, cover many examples, assign relatively high probabilitycovered example. (The latter means noise outcomes avoided wheneverpossible.) One reasonable set rules suggested shown right-hand sideFigure 6. Notice r3 deterministic, high-probability relatively compact:e3 unique initial state, ExplainExamples take advantage this. Meanwhile,335fiPasula, Zettlemoyer, & Pack Kaelblinge1 e2 starting state, rules explaining must coverothers examples. Thus, noise outcomes unavoidable rules, since lacknecessary deictic references. (Deictic variables created describe objectswhose state changes example explained.)Now, consider adding one rules. guaranteeconstitute improvement, since high complexity penalty would make rulelook bad, high pmin would make default rule look good. determinebest move is, algorithm compares scores rule sets containingproposed rules score initial rule set containing default rule. Let uscalculate scores example, starting rule set consisting rule r1 ,covers e1 e2 , default rule rd , covers remaining example,therefore noise probability 1.0. use Equation 5, let rulescomplexity number literals body: so, case r1 , three. get:S(r1 , rd ) =Xlog(P (s0 |s, a, r(s,a) ))(s,a,s0 )EXP EN (r)rR= log(0.5 + 0.5 pmin ) + log(0.5 pmin ) + log(pmin ) P EN (r1 ) P EN (rd )= log(0.50000005) + log(0.00000005) + log(0.0000001) 0.5 3 0.5 0= 0.301 7.301 7 1.5= 16.101So, rule set containing r1 score 16.101. Similar calculations showrule sets containing r2 r3 scores 10.443 15.5 respectively. Sinceinitial rule set score 21, new rule sets improvements, onecontaining r2 best, picked greedy search. new rule set now:puton(X) : : inhand(Y), : table(T)empty context0.33 : on(Y, T)0.33 : on(Y, X)0.34 : noisedefaultrule:1.0 : change0.0 : noiseNotice training examples covered non-default rule. situation,default rule cover examples probability assigned noiseoutcome.next step, search decide altering existing rule, introducing another rule describe example currently covered default rule. Sincedefault rule covers examples, altering single rule rule set option.operators likely score highly get rid noise outcome,rule means referring block X e1 .appropriate operator therefore AddRefs, introduce new deictic reference describing block. course, increases size rule, complexity,336fiLearning Symbolic Models Stochastic World Dynamicsaddition means rule longer applies e3 , leaving examplehandled default rule. However, new rule set raises probabilitiesexamples enough compensate increase complexity, endsscore 10.102, clear improvement 10.443. highest scoreobtainable step, algorithm alters rule set get:puton(X) :: inhand(Y), : table(T), Z : on(Z, X)empty context0.5 : on(Y, Z)0.5 : on(Y, T)defaultrule:0.0 : change1.0 : noisedefault rule covers e3 , ExplainExamples something work again.Adding r3 get rid noise, yield much improved score 4.602. Again,biggest improvement made, rule set becomes:puton(X) :: inhand(Y), : table(T), Z : on(Z, X)empty context0.5 : on(Y, Z)0.5 : on(Y, T)puton(X) : : inhand(Y)clear(X)1.0 : on(Y, X)defaultrule:1.0 : change0.0 : noiseNote rule could added earlier e3 also coveredfirst rule added, r2 , specialized. Thus, adding r3 rule set containing r2would knocked r2 out, caused examples e1 e2 explained noisedefault rule, would reduced overall score. (It is, however, possible ruleknock another yet improve score: requires complicated setexamples.)Learning continues search. Attempts apply rule-altering operatorscurrent rules either make bigger without changing likelihood, leadcreation noise outcomes. Dropping either rule add noise probabilitydefault rule lower score. Since extra examples explained,operator improve score, search stops rule set. seems likereasonable rule set domain: one rule covers happens try putonclear block, one describes try puton block another block it.Ideally, would like first rule generalize blocks something them,instead on, notice would need examples containing higher stacks.337fiPasula, Zettlemoyer, & Pack Kaelbling5.1.6 Different Versions Algorithmmaking small variations LearnRuleSet algorithm, learn different typesrule sets. important evaluating algorithm.explore effects constants rules, evaluate three different versionsrule learning: propositional, relational, deictic. propositional rule learning, ExplainExamples creates initial trimmed rules constants never introduces variables.None search operators introduce variables used. Thus, learned rulesguaranteed propositionalthey cannot generalize across identities specificobjects. relational rule learning, variables allowed rule action argumentssearch operators allowed introduce deictic references. ExplainExamples createsrules constants name objects, long constants alreadyvariable action argument list mapped them. Finally, deictic rule learning,constants allowed. see deictic learning provides strong biasimprove generalization.demonstrate addition noise deictic references result betterrules, learn action models enhancements. Again,done changing algorithm minor ways. disallow noise, set rule noiseprobability zero, means must constrain outcome sets containoutcome every example change observed; rules cannot expresschanges abandoned. disallow deictic references, disable operatorsintroduce them, ExplainExamples create empty deictic reference set.5.2 Learning Conceptscontexts deictic references NDRs make use concept predicates functions well primitive ones. concepts specified hand, learned usingrather simple algorithm, LearnConcepts, uses LearnRuleSet subproceduretesting concept usefulness. algorithm works constructing increasingly complex concepts, running LearnRuleSet checking concepts appear learnedrules. first set created applying operators Figure 7 literals builtoriginal language. Subsequent sets concepts constructed using literalsproved useful latest run; concepts tried before, alwaystrue always false across examples, discarded. search ends nonenew concepts prove useful.example, consider predicate topstack simple blocks world, coulddiscovered follows. first round learning, literal on(X1 , X2 ) used definenew predicate n(Y1 , Y2 ) := (Y1 , Y2 ), true Y1 stacked Y2 .Assuming new predicate appears learned rules, used secondround learning, define, among others, m(Z1 , Z2 ) := n(Z1 , Z2 ) clear(Z1 ). ensuringZ1 clear, predicate true Z1 highest block stackcontaining Z2 . notion topstack used determining happengripper tries pick Z2 . descends above, likely graspblock top stack instead.Since concept language quite rich, overfitting (e.g., learning conceptsused identify individual examples) serious problem. handle338fiLearning Symbolic Models Stochastic World Dynamicsp(X) n := QY.p(Y )p(X1 , X2 ) n(Y2 ) := QY1 .p(Y1 , Y2 )p(X1 , X2 ) n(Y1 ) := QY2 .p(Y1 , Y2 )p(X1 , X2 ) n(Y1 , Y2 ) := p (Y1 , Y2 )p(X1 , X2 ) n(Y1 , Y2 ) := p+ (Y1 , Y2 )p1 (X1 ), p2 (X2 ) n(Y1 ) := p1 (Y1 ) p2 (Y1 )p1 (X1 ), p2 (X2 , X3 ) n(Y1 , Y2 ) := p1 (Y1 ) p2 (Y1 , Y2 )p1 (X1 ), p2 (X2 , X3 ) n(Y1 , Y2 ) := p1 (Y1 ) p2 (Y2 , Y1 )p1 (X1 , X2 ), p2 (X3 , X4 ) n(Y1 , Y2 ) := p1 (Y1 , Y2 ) p2 (Y1 , Y2 )p1 (X1 , X2 ), p2 (X3 , X4 ) n(Y1 , Y2 ) := p1 (Y1 , Y2 ) p2 (Y2 , Y1 )p1 (X1 , X2 ), p2 (X3 , X4 ) n(Y1 , Y2 ) := p1 (Y1 , Y2 ) p2 (Y1 , Y1 )p1 (X1 , X2 ), p2 (X3 , X4 ) n(Y1 , Y2 ) := p1 (Y1 , Y2 ) p2 (Y2 , Y2 )f (X) = c n() := #Y.f (Y ) = cf (X) c n() := #Y.f (Y ) cf (X) c n() := #Y.f (Y ) cFigure 7: Operators used invent new predicate n. operator takes input oneliterals, listed left. ps represent old predicates; f represents old function;Q refer ; c numerical constant. operator takes literalreturns concept definition. operators applied literals usedrules rule set create new predicates.expected way: introducing penalty term, 0 c(R), create new scoring metric0 (R) = S(R) 0 c(R)c(R) number distinct concepts used rule set R 0 scalingparameter. new metric 0 used LearnRuleSet; avoids overfitting favoringrule sets use fewer derived predicates. (Note fact 0 cannot factoredrule, was, matter, since factoring used InduceOutcomesLearnParameters, neither change number concepts used relevantrule: outcomes contain primitive predicates.)5.3 Discussionrule set learning challenge addressed section complicated need learnstructure rules, numeric parameters associated outcome distributions,definitions derived predicates modeling language. LearnConcepts339fiPasula, Zettlemoyer, & Pack Kaelblingalgorithm conceptually simple, performs simultaneous learning effectively,see experiments Section 7.2.large number possible search operators might cause concern overallcomputational complexity LearnRuleSet algorithm. Although algorithm expensive, set search operators designed control complexity attemptingkeep number rules current set small possible.step search, number new rule sets considered dependscurrent set rules. ExplainExamples operator creates new rule sets,number examples covered default rule. Since search starts rule setcontaining default rule, initially equal number training examples.However, ExplainExamples designed introduce rules cover many examples,practice grows small quickly. operators create O(rm) new rule sets,r number rules current set depends specific operator.example, could number literals dropped contextrule DropLits operator. Although large, r stays small practicesearch starts default rule complexity penalty favors small rulesets.ensure score increases search step, algorithm guaranteed converge (usually local) optimum. not, however, guaranteequickly get there. practice, found algorithm converged quicklytest domains. LearnRuleSet algorithm never took 50 stepsLearnConcepts outer loop never cycled 5 times. entire algorithm never tooksix hours run single processor, although significant effort madecache intermediate computations final implementation.spite this, realize that, scale complex domains, approacheventually become prohibitively expensive. plan handle problem developing new algorithms learn concepts, rules, rule parameters online manner,directed search operators. However, leave complex approachfuture work.6. Planningexperiments Section 7.2 involve learning models complex actionstrue models dynamics, level relational rules, available evaluation.Instead, learned models evaluated planning executing actions.many possible ways plan. work, explore MDP planning.MDP (Puterman, 1999) 4-tuple (S, A, T, R). set possible states,set possible actions, distribution encodes transition dynamicsworld, (s0 |s, a). Finally, R reward signal maps every state real value.policy plan (possibly stochastic) mapping states actions. expectedamount reward achieved executing starting called valuePdefined V (s) = E[i=0 R(si )|], si states reachedtime i. discount factor 0 < 1 favors immediate rewards. goalMDP planning find policy achieve reward time.340fiLearning Symbolic Models Stochastic World Dynamicsoptimal policy found solving set Bellman equations,s, V (s) = R(s) +X(s0 |s, (a))V (s0 ).(8)s0application, action set state set defined worldmodeling. rule set R defines transition model reward function R definedhand.planning large domains, difficult solve Bellmanequations exactly. approximation, implemented simple planner basedsparse sampling algorithm (Kearns, Mansour, & Ng, 2002). Given state s, creates treestates (of predefined depth branching factor) sampling forward using transitionmodel, computes value node using Bellman equation, selects actionhighest value.adapt algorithm handle noisy outcomes, predict next state,estimating value unknown next state fraction value stayingstate: i.e., sample forward stayed state scalevalue obtain. scaling factor 0.75, depth branching factorfour.scaling method guess value unknown next state mightbe; noisy rules partial models, way compute value explicitly.future, would like explore methods learn associate values noiseoutcomes. example, value outcome tower blocks fallsdifferent goal build tall stack blocks goal putblocks table.algorithm solve hard combinatorial planning problems, allowus choose actions maximize relatively simple reward functions. seenext section, enough distinguish good models poor ones. Moreover,development first-order planning techniques active field research (AIPS, 2006).7. Evaluationsection, demonstrate rule learning algorithm robust variety lownoise domains, show works intrinsically noisy simulated blocks worlddomain. begin describing test domains, report series experiments.7.1 Domainsexperiments performed involve learning rules domains brieflydescribed following sections.7.1.1 Slippery Gripperslippery gripper domain, inspired work Draper et al. (1994), abstract,symbolic blocks world simulated robotic arm, used move blocksaround table, nozzle, used paint blocks. Painting blockmight cause gripper become wet, makes likely failmanipulate blocks successfully; fortunately, wet gripper dried.341fiPasula, Zettlemoyer, & Pack Kaelblingpickup(X, ) : on(X, ), clear(X),inhand-nil, block(X), block(Y ), wet,pickup(X, ) : on(X, ), clear(X),inhand-nil, block(X), block(Y ), wetinhand(X), clear(X), inhand-nil,.7 :on(X, ), clear(Y ).2 : on(X, TABLE), on(X, ).1 : changeinhand(X), clear(X), inhand-nil,.33 :on(X, ), clear(Y ).33 : on(X, TABLE), on(X, ).34 : changepickup(X, ) : on(X, ), clear(X),inhand-nil, block(X), table(Y ), wetpickup(X, ) : on(X, ), clear(X),inhand-nil, block(X), table(Y ), wet((inhand(X), clear(X), inhand-nil,on(X, ).5 : change.5 :inhand(X), clear(X), inhand-nil,on(X, ).2 : change.8 :inhand-nil, clear(Y), inhand(X),.7 :on(X, Y), clear(X)puton(X, Y) : clear(Y), inhand(X),on(X, TABLE), clear(X), inhand-nil,block(Y).2 : inhand(X).1 : change(puton(X, TABLE) : inhand(X)(.6 : painted(X).1 : painted(X), wet.3 : change.9 : wet.1 : changepaint(X) : block(X)dry : contexton(X, TABLE), clear(X), inhand-nil,inhand(X).2 : change.8 :Figure 8: Eight relational planning rules model slippery gripper domain.Figure 8 shows set rules model domain. Individual states representworld objects intrinsic constants experimental data generated samplingrules. Section 7.2.1, explore learning algorithms Section 5 comparenumber training examples scaled single complex world.7.1.2 Trucks DriversTrucks drivers logistics domain, adapted 2002 AIPS international planningcompetition (AIPS, 2002). four types constants: trucks, drivers, locations,objects. Trucks, drivers objects locations. locationsconnected paths links. Drivers board trucks, exit trucks, drive truckslocations linked. Drivers also walk, without truck, locationsconnected paths. Finally, objects loaded unloaded trucks.set rules shown Figure 9. actions simple rules succeedfail change world. However, walk action interesting twist. driverstry walk one location another, succeed time,342fiLearning Symbolic Models Stochastic World Dynamicsload(O, T, L) :at(T, L), at(O, L).9 : at(O, L), in(O, ).1 : changeunload(O, T, L) :in(O, ), at(T, L).9 : at(O, L), in(O, ).1 : changeboard(D, T, L) :at(T, L), at(D, L), empty(T ).9 : at(D, L), driving(D, ), empty(T ).1 : changedisembark(D, T, L) :at(T, L), driving(D, ).9 : driving(D, ), at(D, L), empty(T ).1 : changedrive(T, F L, L, D) :driving(D, ), at(T, F L), link(F L, L).9 : at(T, L), at(T, F L).1 : change.9 : at(D, L), at(D, F L)walk(D, F L, L) :at(D, F L), path(F L, L).1 : pick X s.t. path(F L, X)at(D, X), at(D, F L)Figure 9: Six rules encode world dynamics trucks drivers domain.time arrive randomly chosen location connected pathorigin location.representation presented cannot encode action efficiently. best ruleset rule origin location, outcomes every location originlinked to. Extending representation allow actions like walk representedsingle rule interesting area future work.Like slippery gripper domain, individual states represent world objects intrinsicconstants experimental data generated sampling rules. trucksdrivers dynamics difficult learn but, see Section 7.2.1, learnedenough training data.7.1.3 Simulated Blocks Worldvalidate rule extensions paper, Section 7.2 presents experiments rigidbody, simulated physics blocks world. section describes logical interfacesimulated world. description extra complexities inherent learning dynamicsworld presented Section 1.define interface symbolic representation use describeaction dynamics physical domain simulated blocks world. perceptualsystem produces states contain skolem constants. logical language includesbinary predicate on(X, Y), defined X exerts downward force obtainedquerying internal state simulator, unary typing predicates table block.actuation system translates actions sequences motor commands simulator.Actions always execute, regardless state world. define two actions;parameters allow agent specify objects intends manipulate.pickup(X) action centers gripper X, lowers hits something, grasps,raises gripper. Analogously, puton(X) action centers gripper X, lowersencounters pressure, opens it, raises it.343fiPasula, Zettlemoyer, & Pack Kaelblingusing simulator sidestepping difficult pixels-to-predicates problemoccurs whenever agent map domain observations internal representation.Primitive predicates defined terms internal state simulation simplercleaner observations real world would be. also make domain completelyobservable: prerequisite learning planning algorithms. Choosing setpredicates observe important. make rule learning problem easyhard, difficulty making choice magnified richer settings. limitedlanguage described balances extremes providing on, would difficultderive means, providing predicates inhand clear,learned.7.2 Experimentssection describes two sets experiments. First, compare learning deictic,relational, propositional rules slippery gripper trucks drivers data.domains modeled planning rules, contain intrinsic constants, noisy,thus allow us explore effect deictic references constants rules directly.Then, describe set experiments learns rules model data simulatedblocks world. data inherently noisy contains skolem constants. result,focus evaluating full algorithm performing ablation studies demonstratedeictic references, noise outcomes, concepts required effective learning.experiments use examples, (s, a, s0 ) E, generated randomly constructingstate s, randomly picking arguments action a, executing actionstate generate s0 . distribution used construct biased guarantee that,approximately half examples, chance change state. methoddata generation designed ensure learning algorithms always datarepresentative entire model learn. Thus, experimentsignore problems agent would face generate data exploring world.7.2.1 Learning Rule Sets Noiseknow model used generate data, evaluate model respectset similarly generated test examples E calculating average variational distancetrue model P estimate P ,V D(P, P ) =1 X|P (E) P (E)| .|E| EEVariational distance suitable measure clearly favors similar distributions,yet well-defined zero probability event observed. (As happennon-noisy rule learned sparse data many outcomesshould.)comparisons performed four actions. first two, paint pickup,slippery gripper domain, second two, drive walk,trucks drivers domain. action presents different challenges learning. Paintsimple action one outcome lead successor state (asdescribed Section 4.1). Pickup complex action must represented344fiLearning Symbolic Models Stochastic World DynamicsPaint Action0.30.25Pickup Action0.35PropositionalRelationalDeicticVariational DistanceVariational Distance0.350.20.150.10.0500.30.250.20.150.10.050100 200 300 400 500 600 700 800 9001000Training set size100 200 300 400 500 600 700 800 9001000Training set sizeWalk Action0.30.25Drive Action0.2PropositionalRelationalDeicticVariational DistanceVariational Distance0.35PropositionalRelationalDeictic0.20.150.10.0500.15PropositionalRelationalDeictic0.10.050100 200 300 400 500 600 700 800 900Training set size100 200 300 400 500 600 700 800 900Training set sizeFigure 10: Variational distance function number training examples propositional, relational, deictic rules. results averaged ten trialsexperiment. test set size 400 examples.one planning rule. Drive simple action four arguments. Finally, walkcomplicated action uses path connectivity world noise model lostpedestrians. slippery gripper actions performed world four blocks.trucks driver actions performed world two trucks, two drivers, twoobjects, four locations.compare three versions algorithm: deictic, includes full rules language allow constants; relational, allows variables constantsdeictic references; propositional, constants variables. Figure 10shows results. relational learning consistently outperforms propositional learning;implies variable abstractions useful. cases except walk action,deictic learner outperforms relational learner. result implies forcingrules contain variables preventing overfitting learning better models.results walk action interesting. Here, deictic learner cannot actuallyrepresent optimal rule; requires noise model complex. deictic learnerquickly learns best rule can, relational propositional learners eventually345fiPasula, Zettlemoyer, & Pack KaelblingLearning Simulated Blocksworld18learned conceptshand-engineered conceptswithout noise outcomesrestricted languageTotal Reward1614121086200300400500600700Training set size8009001000Figure 11: performance various action model variants function number trainingexamples. data points averaged five planning trials threerule sets learned different training data sets. comparison, average rewardperforming actions 9.2, reward obtained human directedgripper averaged 16.2.learn better rule sets use constants accurately model walkersmoving random locations.experiments, see variable abstraction helps learn less data,deictic rules, abstract aggressively, perform best, longrepresent model learned. next section, consider deicticrules, since working domain simulated perceptionaccess objects identities names using skolem constants.7.2.2 Learning Blocks World Simulatorfinal experiment demonstrates noise outcomes complicated conceptsnecessary learn good action models blocks world simulator.true model known, evaluate learned model using planestimating average reward gets. reward function used simulated blocksworld average height blocks world, breadth depthsearch sampling planner four. learning, set 0.5 pmin0.0000001.tested four action model variants, varying training set size; resultsshown Figure 11. curve labeled learned concepts represents full algorithmpresented paper. performance approaches obtained human expert,comparable algorithm labeled hand-engineered concepts346fiLearning Symbolic Models Stochastic World Dynamicsconcept learning, was, instead, provided hand-coded versions conceptsclear, inhand, inhand-nil, above, topstack, height. concept learner discoveredthese, well useful predicates, e.g., p(X, Y) := clear(Y) on(Y, X),call onclear. could action models outperformed hand-engineered onesslightly small training sets. domains less well-studied blocks world, mightless obvious useful concepts are; concept-discovery technique presentedprove helpful.remaining two model variants obtained rewards comparable rewardnothing all. (The planner attempt act experiments,poor job.) one variant, used full set predefined concepts rulescould noise outcomes. requirement explain every action effect ledsignificant overfitting decrease performance. rule set giventraditional blocks world language, include above, topstack, height,allowed learn rules noise outcomes. also tried full-language variant noiseoutcomes allowed, deictic references not: resulting rule sets containednoisy rules, planner attempt act all. poor performanceablated versions representation shows three extensionsessential modeling simulated blocks world domain.human agent commanding gripper solve problem received averagetotal reward 16.2, theoretical maximum due unexpected actionoutcomes. Thus, ND rules performing near-human levels, suggestingrepresentation reasonable one problem. also suggests planningapproximations learning bounds limiting performance. Traditional rules,face challenge modeling transitions seen data, much largerhypothesis space consider learning; surprising generalize poorlyconsistently out-performed NDRs.Informally, also report NDR algorithms execute significantly fastertraditional ones. one standard desktop PC, learning NDRs takes minutes learningtraditional rules take hours. noisy deictic action models generallycompact traditional ones (they contain fewer rules fewer outcomes) planningmuch faster well.get better feel types rules learned, two interesting rules producedfull algorithm.pickup(X) :: onclear(X, Y), Z : on(Y, Z),: table(T)inhand-nil, size(X) < 2.80 : on(Y, Z).10 : on(X, Y).10 : on(X, Y), on(Y, T), on(Y, Z)rule applies empty gripper asked pick small block X sitstop another block Y. gripper grabs high probability.347fiPasula, Zettlemoyer, & Pack Kaelblingputon(X) :: topstack(Y, X), Z : inhand(Z),: table(T)size(Y) < 2.62 :.12 :.04 :.22 :on(Z, Y)on(Z, T)on(Z, T), on(Y, T), on(Y, X)noiserule applies gripper asked put contents, Z, block Xinside stack topped small block Y. placing things small block chancy,reasonable probability Z fall table, small probabilityfollow.8. Discussionpaper, developed probabilistic action model representation rich enoughused learn models planning physically simulated blocks world.first step towards defining representations algorithms enable learningcomplex worlds.8.1 Related Workproblem learning deterministic action models well studied. workarea (Shen & Simon, 1989; Gil, 1993, 1994; Wang, 1995) focused incrementallylearning planning operators interacting simulated worlds. However, workassumes learned models completely deterministic.Oates Cohen (1996) earliest work learning probabilistic planning operators. rules factored apply parallel. However, representationstrictly propositional, allows rule contain single outcome.previous work, developed algorithms learning probabilistic relational planning operators (Pasula, Zettlemoyer, & Kaelbling, 2004). Unfortunately, neither probabilisticalgorithms robust enough learn complex, noisy environments like simulatedblocks world.One previous system comes close goal TRAIL learner (Benson, 1996).TRAIL learns extended version Horn clauses noisy environments applying inductive logic programming (ILP) learning techniques robust noise. TRAILintroduced deictic references name objects based functional relationshipsarguments actions. deictic references, exists-unique quantificationsemantics, generalization Bensons original work. Moreover, TRAIL models continuous actions real-valued fluents, allows represent complexmodels date, including knowledge required pilot realistic flight simulator. However, rules TRAIL learns limited probabilistic representationrepresent possible transition distributions. TRAIL also include mechanismslearning new predicates.348fiLearning Symbolic Models Stochastic World Dynamicswork action model learning used different versions greedy searchrule structure learning, closely related inspired learning versionspaces Mitchell (1982) later ILP work (Lavrac & Dzeroski, 1994). paper,also explore, first time, new way moving space rule setsusing noise rule initial rule set. found approach works wellpractice, avoiding need hand-selected initial rule set allowing algorithmlearn significantly complex environments.far know, work learning action models explored learning concepts.ILP literature, recent work (Assche, Vens, Blockeel, & Dzeroski, 2004) shownadding concept learning decision tree learning algorithms improves classificationperformance.Outside action learning, exists much related research learning probabilisticmodels relational logical structure. complete discussion beyond scopepaper, present highlights. work learns representationsrelational extension Bayesian networks. comprehensive example, see work Getoor(2001). work extends research ILP incorporating probabilistic dependencies.example, see wide range techniques presented Kersting (2006). Additionally,recent work learning Markov logic networks (Richardson & Domingos, 2006; Kok& Domingos, 2005), log-linear models features defined first-orderlogical formulae. action models action model learning algorithms paperdesigned represent action effects, special case general approaches listedabove. discussed Section 2, tailoring representation matchmodel learnt, simplify learning.Finally, let us consider work related NDR action model representation.relevant approach PPDDL, representation language probabilistic planning operatorsproblem domains (Younes & Littman, 2004). NDR representation partiallyinspired PPDDL operators includes restrictions make easier learn extensions, noise outcomes, required effectively model simulated blocksworld. future, algorithms paper could extended learn full PPDDLrules. Also, PPDDL planning algorithms (for examples, see papers recent planningcompetitions) could adapted improve simple planning presented Section 6.general sense, NDRs related probabilistic relational representationsdesigned model dependencies across time. examples, see work relationaldynamic Bayesian networks (Sanghai, Domingos, & Weld, 2005), specialization PRMs, logical hidden Markov models (Kersting, Raedt, & Raiko, 2006),come ILP research tradition. approaches make different set modelingassumptions closely tied planning representations NDR modelsextend.8.2 Future Ongoing Workremains much done context learning probabilistic planning rules.First all, likely work applied additional domains (suchrealistic robotic applications dialogue systems) representation needadapted, search operators adjusted accordingly. possible changes mentioned349fiPasula, Zettlemoyer, & Pack Kaelblingarticle include allowing rules apply parallel, different rules could applydifferent aspects state, extending outcomes include quantifiers, actionslike walk, trucks drivers domain Section 7.1.2, could described usingsingle rule. significant change intend pursue expanding approachhandle partial observability, possibly incorporating techniques workdeterministic learning (Amir, 2005). also hope make changes makeusing rules easier, associating values noise outcomes help plannerdecide whether avoided.second research direction involves development new algorithms learn probabilistic operators incremental, online manner, similar learning setupdeterministic case (Shen & Simon, 1989; Gil, 1994; Wang, 1995). potentialscale approach larger domains, make applicable even situationsdifficult obtain set training examples contains reasonable sampling worldslikely relevant agent. line work require developmenttechniques effectively exploring world learning model, much donereinforcement learning. longer term, would like online algorithms learnoperators concept predicates, also useful primitive predicates motoractions.Acknowledgmentsmaterial based upon work supported part Defense Advanced ResearchProjects Agency (DARPA), Department Interior, NBC, AcquisitionServices Division, Contract No. NBCHD030010; part DARPA Grant No.HR0011-04-1-0012 .ReferencesAgre, P., & Chapman, D. (1987). Pengi: implementation theory activity.Proceedings Sixth National Conference Artificial Intelligence (AAAI).AIPS (2002). International planning competition. http://www.dur.ac.uk/d.p.long/competition.html.AIPS (2006). International planning competition. http://www.ldc.usb.ve/bonet/ipc5/.Amir, E. (2005). Learning partially observable deterministic action models. ProceedingsNineteenth International Joint Conference Artificial Intelligence (IJCAI).Assche, A. V., Vens, C., Blockeel, H., & Dzeroski, S. (2004). random forest approachrelational learning. Proceedings ICML Workshop Statistical RelationalLearning Connections Fields.Benson, S. (1996). Learning Action Models Reactive Autonomous Agents. Ph.D. thesis,Stanford University.Bertsekas, D. P. (1999). Nonlinear Programming. Athena Scientific.Blum, A., & Langford, J. (1999). Probabilistic planning graphplan framework.Proceedings Fifth European Conference Planning (ECP).350fiLearning Symbolic Models Stochastic World DynamicsBoutilier, C., Reiter, R., & Price, B. (2001). Symbolic dynamic programming first-orderMDPs. Proceedings Seventeenth International Joint Conference ArtificialIntelligence (IJCAI).Boyen, X., & Koller, D. (1998). Tractable inference complex stochastic processes.Proceedings Fourteenth Annual Conference Uncertainty AI (UAI).Brooks, R. A. (1991). Intelligence without representation. Artificial Intelligence, 47.Draper, D., Hanks, S., & Weld, D. (1994). Probabilistic planning information gatheringcontingent execution. Proceedings Second International conferenceAI Planning Systems (AIPS).Edelkamp, S., & Hoffman, J. (2004). PDDL2.2: language classical part 4thinternational planning competition. Technical Report 195, Albert-Ludwigs-Universitat,Freiburg, Germany.Fikes, R. E., & Nilsson, N. J. (1971). STRIPS: new approach application theoremproving problem solving. Artificial Intelligence, 2(2).Getoor, L. (2001). Learning Statistical Models Relational Data. Ph.D. thesis, Stanford.Gil, Y. (1993). Efficient domain-independent experimentation. Proceedings TenthInternational Conference Machine Learning (ICML).Gil, Y. (1994). Learning experimentation: Incremental refinement incomplete planning domains. Proceedings Eleventh International Conference MachineLearning (ICML).Guestrin, C., Koller, D., Parr, R., & Venkataraman, S. (2003). Efficient solution algorithmsfactored MDPs. Journal Artificial Intelligence Research (JAIR), 19.Kearns, M., Mansour, Y., & Ng, A. (2002). sparse sampling algorithm near-optimalplanning large Markov decision processes. Machine Learning (ML), 49(2).Kersting, K. (2006). Inductive Logic Programming Approach Statistical RelationalLearning. IOS Press.Kersting, K., Raedt, L. D., & Raiko, T. (2006). Logical hidden markov models. JournalArtificial Intelligence Research (JAIR), 25.Khan, K., Muggleton, S., & Parson, R. (1998). Repeat learning using predicate invention.International Workshop Inductive Logic Programming (ILP).Kok, S., & Domingos, P. (2005). Learning structure markov logic networks. Proceedings Twenty Second International Conference Machine Learning (ICML).Lavrac, N., & Dzeroski, S. (1994). Inductive Logic Programming Techniques Applications. Ellis Horwood.Mitchell, T. M. (1982). Generalization search. Artificial Intelligence, 18(2).Oates, T., & Cohen, P. R. (1996). Searching planning operators context-dependentprobabilistic effects. Proceedings Thirteenth National ConferenceArtificial Intelligence (AAAI).ODE (2004). Open dynamics engine toolkit.. http://opende.sourceforge.net.351fiPasula, Zettlemoyer, & Pack KaelblingPasula, H., Zettlemoyer, L., & Kaelbling, L. (2004). Learning probabilistic relational planning rules. Proceedings Fourteenth International Conference AutomatedPlanning Scheduling (ICAPS).Puterman, M. L. (1999). Markov Decision Processes. John Wiley Sons, New York.Richardson, M., & Domingos, P. (2006). Markov logic networks. Machine Learning (ML),62.Sanghai, S., Domingos, P., & Weld, D. (2005). Relational dynamic bayesian networks.Journal Artificial Intelligence Research (JAIR), 24.Shen, W.-M., & Simon, H. A. (1989). Rule creation rule learning environmental exploration. Proceedings Eleventh International Joint ConferenceArtificial Intelligence (IJCAI).Wang, X. (1995). Learning observation practice: incremental approach planning operator acquisition. Proceedings Twelfth International ConferenceMachine Learning (ICML).Yoon, S., Fern, A., & Givan, R. (2002). Inductive policy selection first-order Markovdecision processes. Proceedings Eighteenth Conference UncertaintyArtificial Intelligence (UAI).Younes, H. L. S., & Littman, M. L. (2004). PPDDL1.0: extension PDDL expressingplanning domains probabilistic effects. School Computer Science, CarnegieMellon University, Technical Report CMU-CS-04-167.Zettlemoyer, L., Pasula, H., & Kaelbling, L. (2003). Learning probabilistic relational planning rules. MIT Tech Report.352fiJournal Artificial Intelligence Research 29 (2007) 191219Submitted 07/2006; published 06/2007Language SearchJinbo Huangjinbo.huang@nicta.com.auLogic Computation ProgramNational ICT AustraliaAdnan Darwichedarwiche@cs.ucla.eduComputer Science DepartmentUniversity California, Los AngelesAbstractpaper concerned class algorithms perform exhaustive searchpropositional knowledge bases. show algorithms defines generatespropositional language. Specifically, show trace search interpretedcombinational circuit, search algorithm defines propositional languageconsisting circuits generated across possible executions algorithm.particular, show several versions exhaustive DPLL search correspondwell-known languages FBDD, OBDD, precisely-defined subset d-DNNF.thus mapping search algorithms propositional languages, provide uniformpractical framework successful search techniques harnessed compilationknowledge various languages interest, new methodology whereby powerlimitations search algorithms understood looking tractabilitysuccinctness corresponding propositional languages.1. IntroductionSystematic search algorithms lie core wide range automated reasoning systems,many based procedure branches node search treegenerated splitting possible values chosen variable. One prototypical exampleDPLL algorithm (Davis, Logemann, & Loveland, 1962) propositional satisfiability(SAT). Given propositional formula, problem SAT determine whetherformula satisfying assignmentan assignment Boolean values (0 1)variables formula evaluates 1. example, (x1 = 0, x2 = 1, x3 = 0)satisfying assignment following formula: (x1 x2 )(x1 x2 x3 )(x1 x2 x3 ).determine satisfiability given formula , DPLL chooses variable xformula, recursively determines whether satisfiable case x set 0, case xset 1, declares satisfiable precisely least one two cases resultspositive answer. effect, algorithm performs systematic search spacevariable assignments terminates either finding satisfying assignment,realizing assignment exists.Despite simplicity, DPLL long remained basis SAT solversemploy systematic search (Berre & Simon, 2005), finds natural counterpartsgeneral constraint satisfaction problems, variables restrictedBoolean domain. Several decades sustained research greatly enhanced efficiencyscalability DPLL-based search algorithms, today routinely used solvec2007AI Access Foundation. rights reserved.fiHuang & Darwichepractical problems several million variables (Zhang & Malik, 2002). algorithmssuccessful, indeed, become recent trend areas formalverification modify produce solutions propositional formula (McMillan,2002; Chauhan, Clarke, & Kroening, 2003; Grumberg, Schuster, & Yadgar, 2004),alternative traditional practice (McMillan, 1993) converting formulaordered binary decision diagram (OBDD) (Bryant, 1986). modifications thus involvedform DPLL search terminate finding first solution,extended exhaust whole search space. formula shown earlier,example output exhaustive search could following set three solutions{(x1 = 0, x2 = 1, x3 = 0), (x1 = 1, x2 = 0, x3 = 0), (x1 = 1, x2 = 1)}. Note solutiondefined assignment Boolean values (possibly all) variablessatisfies formula regardless values variables. last solutionset, example, represents two satisfying assignments variable x3 freeassume either value.Producing solutions propositional formula is, course, one possiblecomputational tasks exhaustive search useful. tasks includecounting number satisfying assignments formula, also known model counting(Birnbaum & Lozinskii, 1999; Bayardo & Pehoushek, 2000; Bacchus, Dalmao, & Pitassi,2003b; Sang, Bacchus, Beame, Kautz, & Pitassi, 2004; Sang, Beame, & Kautz, 2005),processing certain types queries belief constraint networks (Dechter & Mateescu,2004b, 2004a).paper uncover fundamental connection class exhaustivesearch algorithms, group propositional languages extensively studied field knowledge compilation (Darwiche & Marquis, 2002). Specifically, showexhaustive search algorithm based variable splitting, run propositionalknowledge bases, defines generates propositional language precise sense:trace single search, recorded graph, interpreted combinationalcircuit logically equivalent propositional knowledge base searchrun; search algorithm defines propositional language consistingcircuits generated legal executions algorithm. show, particular,exhaustive DPLL corresponds language FBDD (free binary decision diagrams)(Blum, Chandra, & Wegman, 1980), exhaustive DPLL fixed variable ordering corresponds language OBDD (ordered binary decision diagrams) (Bryant, 1986),exhaustive DPLL decomposition corresponds well defined subset languaged-DNNF (deterministic decomposable negation normal form) (Darwiche, 2001).establishment correspondence supplies bridge field knowledge compilation, areas automated reasoning, including propositional satisfiability, search algorithms extensively studied. particular, leadsfollowing two sets theoretical practical benefits.First, show class search algorithms described immediatelyturned knowledge compilers respective propositional languages define,simply recording trace search. realization provides uniform practical framework successful techniques developed context searchdirectly used compilation knowledge various languages interest. particular,discuss recent advances DPLL search, including sophisticated conflict analysis,192fiThe Language Searchdependency-directed backtracking, clause learning, new variable ordering heuristics,data structures faster constraint propagation, harnessed building efficientpractical knowledge compilers.Second, show how, looking known properties propositional languages,able answer fundamental level, concrete terms, two important questionsregarding power limitations class search algorithms:algorithms do? not? Specifically, discuss tractabilitypropositional language defined search algorithm illustrates power algorithm,succinctness constraints language illustrate limitations.complement discussions relating results previous work knowledge compilation recent body work centering notion AND/OR search(Dechter & Mateescu, 2004b, 2004a; Marinescu & Dechter, 2005). particular, discusssimilarities well differences AND/OR search d-DNNF compilation.Finally, present experimental results implementations exhaustive search algorithms define distinct propositional languages. use programs compile setpropositional formulas respective languages, demonstrate practicality knowledge compilation framework, empirically illustrate variationlanguage succinctness response variation search strategy.remainder paper organized follows. Section 2 reviews numberpropositional languages concerned work theoretical roles relationsknowledge compilation. Section 3 discusses DPLL search algorithm propositionalsatisfiability exhaustive extension, introduces notion interpretingtrace search combinational circuit. Section 4 detailed exposition mappingvariants exhaustive DPLL FBDD, OBDD, subset d-DNNF, well techniques involved transforming algorithms practical knowledge compilersrespective languages. Section 5 formalizes two fundamental principles relating intrinsic power limitations class exhaustive search algorithms, using recently proposedmodel counting algorithms concrete examples. relate results previous workSection 6, present experimental results Section 7, conclude Section 8. Proofstheorems given appendix.2. Propositional Languages Propertiesstudy propositional languages (i.e., representations propositional theories)central subject knowledge compilation, concerned task converting given knowledge base one language another certain reasoningtasks become tractable compiled knowledge base (Selman & Kautz, 1991; del Val,1994, 1995; Marquis, 1995; Selman & Kautz, 1996; Cadoli & Donini, 1997; Darwiche &Marquis, 2002; Darwiche, 2002, 2004; Coste-Marquis, Berre, Letombe, & Marquis, 2005).propositional theories compiled language OBDD, example,equivalence tested time polynomial sizes OBDDs (Meinel &Theobald, 1998), constant time OBDDs use variable order (Bryant, 1986).recent applications compilation using language d-DNNF foundfields diagnosis (Barrett, 2004, 2005; Huang & Darwiche, 2005a; Elliott & Williams, 2006;Siddiqi & Huang, 2007), planning (Barrett, 2004; Palacios, Bonet, Darwiche, & Geffner,193fiHuang & Darwiche(a) NNF(b) Decision NodeXX(c) AlternativelyXBBCCFigure 1: NNF circuit decision node.2005; Huang, 2006; Bonet & Geffner, 2006), probabilistic reasoning (Chavira & Darwiche,2005; Chavira, Darwiche, & Jaeger, 2006), query rewrites databases (Arvelo, Bonet,& Vidal, 2006).section review set propositional languages discuss establishedbody results concerning tractability succinctness (Darwiche & Marquis, 2002)several languages resurface Section 4 exhaustive searchalgorithms mapped, properties prove vital formalization Section 5two fundamental principles relating power limitations exhaustive searchalgorithms.2.1 Propositional LanguagesFollowing conventions Darwiche Marquis (2002), consider graph representations propositional theories, allow sharing subformulas compactness. Specifically, consider directed acyclic graphs (DAGs) internal node labeledconjunction (and, ) disjunction (or, ), leaf labeled propositionalliteral constant (true/f alse, 1/0). clear DAG effectivelycombinational circuit and-gates, or-gates, inverters, inverters appearnext inputs (variables), property characteristic Negation Normal Form(NNF) (Barwise, 1977). hence refer DAGs NNF circuits setDAGs NNF language. Figure 1a depicts propositional theory representedNNF circuit. next define interesting subsets NNF language.popular language CNF (conjunctive normal form) definedsubset NNF satisfies (i) flatness: height DAG two; (ii)simple-disjunction: disjunction leaf nodes (i.e., clause). Similarly,DNF (disjunctive normal form) subset NNF satisfies flatness simpleconjunction: conjunction leaf nodes (i.e., term).consider next set nested representations, starting DNNF (decomposablenegation normal form) language, set NNF circuits satisfying decomposability: conjuncts conjunction share variables. next language, d-DNNF,satisfies decomposability determinism: disjuncts disjunction pairwiselogically inconsistent. NNF circuit shown Figure 1a, example, d-DNNF;194fiThe Language Searchx1x2X3X1x1X2(a) DNNFx2x3x3x3x201(b) FBDDx201(c) OBDDFigure 2: circuit DNNF, FBDD, OBDD.shown Figure 2a, contrast, DNNF d-DNNF neither twodisjunction nodes satisfies determinism.FBDD language subset d-DNNF root every circuitdecision node, defined recursively either constant (0 1) disjunctionform Figure 1b X propositional variable decision nodes.Note equivalent compact drawing decision node Figure 1c widelyused formal verification literature, FBDDs equivalently known BDDs(binary decision diagrams) satisfy test-once property: variable appearsroot-to-sink path (Gergov & Meinel, 1994).1 See Figure 2b FBDDexample using compact drawing.OBDD language subset FBDD circuits satisfy orderingproperty: variables appear order root-to-sink paths (Bryant, 1986). SeeFigure 2c OBDD example (using compact drawing). particularvariable order <, also write OBDD< denote corresponding OBDD subsetcircuits use order <.2.2 Succinctness Tractability Propositional LanguagesGiven choice languages knowledge base may represented, one needsstrike balance size representation support providesreasoning task hand, two properties representation often run counterother. CNF, example, often convenient compactly encoding knowledgebase since many applications behavior system naturally describedconjunction behaviors components. However, typical reasoning tasksefficiently carried CNF representations. efficient algorithm determine,example, whether arbitrary clause entailed CNF formula. story changespropositional theory represented language known PI (prime implicates,subset CNF): definition PI supports linear-time clausal entailment test.downside is, unfortunately, PI representations exponentially largerCNF equivalents worst case (Karnaugh, 1953; Forbus & de Kleer, 1993).therefore interested formally analyzing succinctness tractabilitylanguages, given required reasoning task, choose succinct language1. FBDDs also known read-once branching programs (Wegener, 2000).195fiHuang & Darwichesupports set necessary operations polynomial time. following classicaldefinition succinctness:Definition 1. (Succinctness) Let L1 L2 two subsets NNF. L1 least succinctL2 , denoted L1 L2 , iff exists polynomial p every circuit L2 ,exists logically equivalent circuit L1 || p(||). Here, || ||sizes , respectively.Intuitively, language L1 least succinct language L2 given circuit L2 ,exists logically equivalent circuit L1 whose size blow up. One alsodefine L1 strictly succinct L2 , denoted L1 < L2 , L1 L2 L2 6 L1 .languages described Section 2.1 satisfy following succinctness relations: NNF< DNNF < d-DNNF < FBDD < OBDD, NNF < CNF, DNNF < DNF (Darwiche &Marquis, 2002). Note, however, L1 L2 imply L1 < L2 general.words, imposing conditions representation necessarily reduce succinctness.One example smoothness, requires disjuncts disjunction mentionset variablesit known condition, imposed d-DNNF, reducesuccinctness (Darwiche & Marquis, 2002).turn tractability languages, refers set polynomial-timeoperations support. According Darwiche Marquis (2002), one traditionallydistinguishes two types operations circuits given language: queriestransformations. difference two queries return informationcircuits, normally change them, transformations modify circuits generatenew ones (in language).known results Darwiche Marquis (2002) regarding tractability languages summarized Table 1 (queries) Table 2 (transformations).abbreviations first row Table 1 stand following eight queries, respectively:Consistency (is formula satisfiable), Validity (does formula evaluate 1variable assignments), Clausal Entailment (does formula imply given clause),Implicant (is formula implied given term), Equivalence (are two formulas logically equivalent), Sentential Entailment (does one formula imply other),Model Counting (how many satisfying assignments formula have), Model Enumeration (what satisfying assignments formula). abbreviationsfirst row Table 2 stand following eight transformations, respectively: Conditioning (setting set variables constants), Forgetting (existentially quantifying setvariables), Single-Variable Forgetting (existentially quantifying single variable), Conjunction (conjoining set circuits), Bounded Conjunction (conjoining boundednumber circuits), Disjunction (disjoining set circuits), Bounded Disjunction(disjoining bounded number circuits), Negation (negating circuit).Interestingly, Table 1 offers one explanation popularity OBDDs formal verification efficient equivalence testing, among things, often critical. Althoughsuccinct, d-DNNF FBDD known admit polynomial-time equivalencetest (a polynomial-time probabilistic equivalence test possible; see Blum et al., 1980;Darwiche & Huang, 2002). Note also although difference d-DNNFFBDD extent table, question mark equivalence test (EQ) couldeventually resolved differently two languages.196fiThe Language SearchTable 1: Polynomial-time queries supported language ( means supported unlessP=NP ? means dont know).LanguageNNFDNNFd-DNNFBDDFBDDOBDDOBDD<DNFCNFCOVACEIMEQ??SECTTable 2: Polynomial-time transformations supported language ( means supported, means supported unless P=NP, ? means dont know).LanguageNNFDNNFd-DNNFBDDFBDDOBDDOBDD<DNFCNFCDFOSFOCBCCBCC?also worth pointing tractability respect queries generally improves language becomes restrictive (has conditions imposed),tractability respect transformations may not. DNNF, example, supportssubset queries supported OBDD according Table 1, thereforeless tractable OBDD point view. However, comes certaintransformations, operation Forgetting (existential quantification), DNNF becomes tractable OBDD according Table 2. key reason shiftadvantage transformations operate circuits given propositional language,require result languagethis requirement become burdenrestrictive language conditions need satisfied resulttransformation generated.197fiHuang & Darwiche2.3 Connection Establishedsummarized discussed section rich body known results concerningproperties various propositional languages. results previously presentedguide task selecting suitable target compilation language applicationsknowledge compilation. particular, suggest given reasoning task involvingknowledge compilation, one identify set operations required task,select succinct target compilation language supporting operations (Darwiche& Marquis, 2002).following sections paper, wish establish fundamental connectionpropositional languages distinct degrees succinctness tractability,exhaustive search algorithms running distinct sets constraints. Specifically,show trace exhaustive search interpreted circuit representingcompilation propositional knowledge base search run, searchalgorithm defines propositional language consisting possible traces.connection serve bridge field knowledge compilationareas automated reasoning search algorithms extensivelystudied, affording two related sets benefits follows.first direction, show connection provides set practical algorithmscompilation knowledge various languages. Specifically, exhaustive searchalgorithm directly turned knowledge compiler recording traceexecution graph, variations search algorithm nicely correspondcompilers different propositional languages. framework knowledge compilationprovides significant advantage many (past well future) advances searchautomatically carry knowledge compilation. particular, discussknowledge compilers capitalize several important recent advances DPLL searchpropositional satisfiability, including sophisticated conflict analysis, dependency-directedbacktracking, clause learning, new variable ordering heuristics, data structures fasterconstraint propagation.second direction, formulate two principles whereby intrinsic powerlimitations given exhaustive search algorithm understood identifyingpropositional language defined search algorithm. Specifically, tractabilitylanguage illustrates power (usefulness) search algorithm succinctnessconstraints language illustrates limitations. Using group recentlyproposed model counters concrete examples, show search algorithms usedmodel counters powerful enough support model counting query,queries known tractable language d-DNNF,probabilistic equivalence test (Darwiche & Huang, 2002). hand, two fundamental limitations identified algorithms, well exhaustivesearch algorithms based variable splitting, first traces restrictedsubset d-DNNF, potentially limiting efficiency search, secondinability produce traces without determinism, making overly constrainedcompilation knowledge general languages d-DNNF, DNNF.198fiThe Language Searchproceed uncover connection search algorithms propositionallanguages, starting systematic search algorithm propositional satisfiability,exhaustive extension, notion trace search.3. Systematic Search Satisfiability Exhaustive Extensionsection introduce notion trace systematic exhaustive search,show trace interpreted circuit, logically equivalent (and hencecompilation of) propositional knowledge base search run.context systematically searching satisfying assignments propositionalformula, major approach problem propositional satisfiability (SAT)come known DPLL (Davis et al., 1962).3.1 DPLL Search Exhaustive ExtensionAlgorithm 1 summary DPLL SAT, takes propositional formula CNF,return 1 (0) precisely formula satisfiable (unsatisfiable). works recursively case analysis assignment selected variable (Line 5): formulasatisfiable either case results satisfiable subformula (Line 6). twosubformulas denote |x=0 |x=1 , result replacing occurrencesx 0 1, respectively. keeping rules Boolean logic, assumeliteral becomes evaluates 0 result variable instantiation,removed every clause contains it; literal becomes evaluates 1,clauses contain removed. (To facilitate subsequent discussion variantsDPLL, omitted use unit resolution pseudocode. programsused Section 7, however, employ unit resolution.) effect, Algorithm 1 performssearch space variable assignments finds one satisfies given CNFformula realizes satisfying assignments exist.consider extending Algorithm 1 go space satisfying assignmentsby always exploring branches Line 6rather terminate finding first one. Figure 3a depicts search tree exhaustive version DPLL, particular variable ordering, following CNF formula:(x1 x2 ) (x1 x2 x3 ) (x1 x2 x3 ). Note drawing branchessearch use dotted (solid) line denote setting variable 0 (1)we also refercorresponding child search node low (high) child.Algorithm 1 DPLL(CNF: ): returns satisfiability1: empty clause2:return 03: variables4:return 15: select variable x6: return DPLL(|x=0 ) DPLL(|x=1 )199fiHuang & Darwichex1x1x2x2unsatsatx3unsat0 x2unsatx2x2x3satx1x2 10 x3 x3 1 0 x3 x3 1(b) Equivalent NNF circuitsat(a) Termination treeFigure 3: trace exhaustive DPLL search.tree depicted Figure 3a also known termination tree search,captures set paths search space exploredtermination search. particular, leaf tree labeled sat givespartial variable assignment satisfies propositional formula regardless valuesunassigned variables, whole tree characterizes precisely set satisfyingassignments, algorithm set find succeeded finding.3.2 Trace Search Issue Redundancyalluded earlier, would like view termination tree tracesearch, make two important observations: First, tracesearch depicted Figure 3a directly translated circuit NNF depictedFigure 3b. involved rename sat/unsat 1/0 invoke identityFigure 1b Figure 1c described Section 2.1. Second, NNF circuitlogically equivalent to, hence compilation of, CNF formulasearch run. (Note notion trace different used earlier workestablish power DPLL proof system unsatisfiable CNF formulas.example, earlier work shown unsatisfiable CNF formula, traceDPLL converted tree-like resolution refutation (Urquhart, 1995).)two observations imply exhaustive DPLL powerful knowledgecompiler, long one takes (small) trouble recording trace. viewpointknowledge compilation, however, search trace recorded present form mayimmediately useful, typically size proportional amount workdone produce it. Answering even linear-time query (which may require singletraversal compiled representation) compilation, example, wouldone running whole search again.problem remedied first realizing quite bit redundancysearch trace drawn. Figure 3a, example, two subgraphs whoseroots labeled x3 isomorphic could merged one.redundancy, course, present corresponding portions NNF circuitshown Figure 3b.200fiThe Language Searchdistinguish two levels dealing issue redundancy trace.first level, remove redundancy trace reducing treeDAG, repeated applications following two rules: (i) Isomorphic nodes (i.e.,nodes label, low child, high child) merged; (ii)node identical children deleted pointers redirected either onechildren (Bryant, 1986). apply reduction rules tree Figure 3a (againrenaming sat/unsat 1/0), get DAG shown Figure 2c (in particularexample second rule apply). Note instead performing reductionend search two reduction rules suggest, better integratingrules trace recording process redundant portions tracerecorded first place. brings us technique known unique nodes (Brace,Rudell, & Bryant, 1991; Somenzi, 2004), discuss detail next section.Removing redundancy level ensures smallest possible compilation obtained given particular execution search algorithm; however, improvetime complexity search itself. Figure 3a, example, reasontwo isomorphic subgraphs (rooted nodes labeled x3 ) first placesearch run equivalent subproblems different paths. general casenontrivial subproblems, solving one source great inefficiency. therefore refer second level dealing issue redundancy,would like able recognize equivalence subproblems avoid carryingcomputation again. done using techniqueformula caching (Majercik & Littman, 1998), also discuss following section.4. Language Searchestablished Section 3 notion interpreting trace exhaustive searchcircuit. section continue study search algorithms showingdefines propositional language consisting possible traces. lookthree algorithms particular: (i) original exhaustive DPLL, (ii) exhaustive DPLLfixed variable ordering, (iii) exhaustive DPLL decomposition. algorithmdiscuss propositional language defines, corresponding knowledge compilerprovides, well issues regarding efficiency knowledge compiler.4.1 Mapping Exhaustive DPLL FBDDseen Section 3 application reduction rules, trace exhaustiveDPLL example, depicted Figure 3a, stored compactly Figure 2c,none circuit language FBDD (which happens alsoOBDD case).formally show traces exhaustive DPLL across possible executionsalgorithm form propositional language precisely language (reduced)FBDD defined Section 2 (from assume circuits FBDDOBDD always given reduced form application two reduction rules).order first need formalism explicitly recording trace searchgraph. purpose introduce Algorithm 2, exactly exhaustiveextension original DPLL (Algorithm 1) except newly introduced function,201fiHuang & Darwicheget-node (given Algorithm 3), provides means recording trace searchform DAG. Specifically, get-node return decision node (in formFigure 1b) labeled first argument, second argument low child,third argument high child (Lines 2&4 also modifiedreturn terminal decision nodes, instead Boolean constants). Note that,briefly mentioned Section 3, algorithm trace recorded directlyreduced from, instead producing redundant nodes removed later.two reduction rules built means unique nodes table, well knownBDD community (Brace et al., 1991; Somenzi, 2004). Specifically, nodes createdget-node stored hash table get-node create new node (i) nodecreated already exists table (that existing node returned); (ii) secondthird arguments (either argument returned). formally stateresult follows:Theorem 1. DAGs returned Algorithm 2 form language (reduced) FBDD.Theorem 1 immediately provides us CNF-to-FBDD compiler, meanssoon search finishes, answer polynomial time querypropositional theory, long query known tractable FBDD. AccordingTable 1, queries include consistency, validity, clausal entailment, implicant, modelcounting, model enumeration. According Blum et al. (1980), one alsotest equivalence two propositional formulas probabilistically polynomial timerunning Algorithm 2 both. hand, propositional theory given Algorithm 2 known polynomial-size representation FBDD, also concludealgorithm able finish polynomial time matter variableordering uses.make Algorithm 2 practical FBDD compiler, need deal issueredundant computation briefly mentioned Section 3. reason that, despiteuse unique nodes controls space complexity, Algorithm 2 still timecomplexity proportional size tree version search trace: PortionsDAG end explored multiple times. See Figure 4 example,two different instantiations first three variables lead subformula,would compiled twice, unnecessarily, Algorithm 2. alleviate problem,one resorts technique formula caching (Majercik & Littman, 1998).Algorithm 4 describes exhaustive DPLL search, caching.result recursive call DPLLf () stored cache (Line 10) returned,indexed key (computed Line 5) identifying ; subsequent call 0Algorithm 2 dpllf (CNF: ): exhaustive DPLL1: empty clause2:return 0-sink3: variables4:return 1-sink5: select variable x6: return get-node(x, dpllf (|x=0 ), dpllf (|x=1 ))202fiThe Language Searchx5x6X10x4x5x1x3x2x3x1x21x6x4x5X210X3x3x5x4X2X311x6x5 x6x4x5x6x5 x6Figure 4: Reaching subformula via different paths search.immediately return existing compilation cache (Line 7) 0 foundequivalent (by key comparison Line 6). (Note introduction cachingchange identity proposition language defined algorithm.words, Theorem 1 applies Algorithm 4 well.)practice, one normally focuses efficiently recognizing formulas syntacticallyidentical (i.e., set clauses). Various methods proposedpurpose recent years, starting Majercik Littman (1998) used cachingprobabilistic planning problems, followed Darwiche (2002) proposed concreteformula caching method context knowledge compilation, Bacchus, Dalmao,Pitassi (2003a) Sang et al. (2004) context model counting,Darwiche (2004) Huang Darwiche (2005b) proposed refinementsmethod Darwiche (2002).4.2 Mapping Exhaustive DPLL Fixed Variable Ordering OBDDNote Algorithm 4, DPLL free choose variable branch (Line 8).corresponds use dynamic variable ordering heuristic typical SAT solver,keeping spirit free binary decision diagrams (FBDD).surprisingly, one switches dynamic static variable ordering, DAGsproduced algorithm restricted subset FBDD. Algorithm 5 implementschange, taking particular variable order second argument, making sureorder enforced choosing next branching point (see Line 8). Acrosspossible inputs variable orderings, algorithm indeed produce exactly setcircuits language (reduced) OBDD:Algorithm 3 get-node(int: i, BDD: low, BDD: high)1: low high2:return low3: node (i, low, high) exists unique-table4:return unique-table[(i, low, high)]5: result = create-bdd-node(i, low, high)6: unique-table[(i, low, high)] = result7: return result203fiHuang & DarwicheTheorem 2. DAGs returned Algorithm 5 form language (reduced) OBDD.therefore provided CNF-to-OBDD compiler Algorithm 5, meanssoon search finishes, answer polynomial time querypropositional theory, long query known tractable OBDD.notably, test equivalence two propositional formulas deterministicallypolynomial time running Algorithm 5 both, could Algorithm 2Algorithm 4. hand, propositional theory given Algorithm 5known polynomial-size representation OBDD, hidden weighted bitfunction (Bryant, 1991), also conclude algorithm able finishpolynomial time matter variable ordering uses.make Algorithm 5 practical OBDD compiler, need deal issueredundant computation. Naturally, general formula caching method, onesdescribed earlier, applicable Algorithm 5. constrained searchalgorithm, however, special method available shorter cache keys usedreduce cost manipulation. reader referred Huang Darwiche(2005b) details method, allows one bound number distinct cachekeys, therefore providing space time complexity bound. particular,specific caching scheme force, space time complexity Algorithm 5shown exponential cutwidth given CNF formula. variant cachingscheme allows one show parallel complexity terms pathwidth (cutwidthpathwidth comparable).emphasize Algorithm 5 represents distinct way OBDD construction,contrast standard method widely adopted formal verification one recursivelybuilds OBDDs components system (or propositional formula) compiledcombines using Apply operator (Bryant, 1986). well-known problemlatter method intermediate OBDDs arise process grow largemake manipulation impossible, even final result would tractablesize. Considering final OBDD really one after, Algorithm 5 affordssolution problem building exactly it, less (although maywork linear OBDD size, inconsistent subproblemscontribute OBDD size, caching complete). empiricalAlgorithm 4 DPLLf (CNF: ): exhaustive DPLL caching1: empty clause2:return 0-sink3: variables4:return 1-sink5: key = compute-key()6: exists cache entry (key, result)7:return result8: select variable x9: result = get-node(x, DPLLf (|x=0 ), DPLLf (|x=1 ))10: cache-insert(key, result)11: return result204fiThe Language SearchABCADEBCDEBCB CEDEBBCBE0C1(a) Mixture decision conjunction nodesBE(b) Equivalent NNF circuitFigure 5: Trace exhaustive DPLL decomposition.comparison compilation algorithm traditional OBDD construction methodfound Huang Darwiche (2005b).4.3 Mapping Exhaustive DPLL Decomposition Subset d-DNNFobserved, particular case model counting, efficiency exhaustive DPLL improved introducing decomposition, also known componentanalysis (Bayardo & Pehoushek, 2000; Bacchus et al., 2003b; Sang et al., 2004, 2005).idea propositional formula breaks conjunction disjoint subformulas (i.e., share variables), subformula processed separatelyresults combined.Algorithm 6 implements decomposition exhaustive DPLL relaxing constraintAlgorithm 4: Immediately Line 8 Algorithm 4, need insistcase analysis performed variable x formula; instead, examinecurrent formula, attempt decompose (Line 5) subsets shareAlgorithm 5 DPLLo (CNF: , order: ): exhaustive DPLL fixed variable ordering1: empty clause2:return 0-sink3: variables4:return 1-sink5: key = compute-key()6: exists cache entry (key, result)7:return result8: x = first variable order appears9: result = get-node(x, DPLLo (|x=0 , ), DPLLo (|x=1 , ))10: cache-insert(key, result)11: return result205fiHuang & Darwichevariable (we assume process nondeterministic; is, detectdecomposition points). search run subformulas separatelyrecursively (Lines 79), separate subtraces result connectedmeans and-node indicate results recursive call combined(Line 10). case decomposition performed (Line 6 fails), branch selectedvariable regular DPLL (Lines 14&15).Figure 5a shows result example execution algorithm, instantiation first variable breaks CNF formula two disjoint clauses,processed separately results combined and-node. Figure 5b showstrace drawn equivalently explicit NNF circuit (for ease viewing constantsremoved decision nodes bottom compacted corresponding literalsrepresent).witnessed, use decomposition exhaustive DPLL resultednew type node trace, returned get-and-node Line 10 Algorithm 6.old get-node function (Line 15) still returns decision nodes (in relaxed sense,children necessarily decision nodes) form Figure 1c. unique nodestechnique also extended straightforward way isomorphic and-nodes,well duplicate children and-node, created.ready discuss proposition language defined Algorithm 6,purpose first define following subset d-DNNF language, determinismfulfilled means decision nodes (again, relaxed sense):Definition 2. language decision-DNNF set d-DNNF circuitsdisjunction nodes form Figure 1b, (x ) (x ), x variable.22. Note that, unlike FBDD, either conjunction disjunction node.Algorithm 6 DPLLd (CNF: ): exhaustive DPLL decomposition1: empty clause2:return 0-sink3: variables4:return 1-sink5: components = exhaustive partitions disjoint variable sets6: |components| > 17:conjuncts = {}8:c components9:conjuncts = conjuncts {DPLLd (c )}10:return get-and-node(conjuncts)11: key = compute-key()12: exists cache entry (key, result)13:return result14: select variable x15: result = get-node(x, DPLLd (|x=0 ), DPLLd (|x=1 ))16: cache-insert(key, result)17: return result206fiThe Language Searchformally state result (again, assume circuits always givenreduced form application appropriate reduction rules described earlier,although allowed redundancy figures ease viewing):Theorem 3. DAGs returned Algorithm 6 form language (reduced) decision-DNNF.hence provided CNF-to-decision-DNNF compiler Algorithm 6,serve d-DNNF compiler practice since decision-DNNF d-DNNF. meanssearch finishes, answer polynomial time query inputpropositional formula, long query known tractable language dDNNF (see Table 1). hand, Algorithm 6 able finish polynomialtime propositional theory polynomial-size representation dDNNF (and decision-DNNF), matter variable ordering decomposition methoduses.Again, one needs implement form formula caching make Algorithm 6practical compiler. Several caching methods proposed d-DNNF compilation,latest effective appeared Darwiche (2004). However, referreader Darwiche (2001) caching scheme specific decomposition methodbased known dtrees (which discuss next). scheme effectiveone Darwiche (2004) former may miss equivalences wouldcaught latter, yet allows one show space time complexity Algorithm 6, caching scheme force, exponential treewidthCNF formula (as compared pathwidth cutwidth OBDD compilation discussedSection 4.2). Considering model counting linear-time query supportedd-DNNF language, results Darwiche (2001) also imply DPLL decomposition (such Algorithm 6) used count models time space complexityexponential treewidth CNF formula; see Bacchus et al. (2003a)alternative derivation complexity result. Interestingly, similar structure-basedmeasure complexity appears known FBDD compilation.Finally, would like briefly discuss distinction two possible methodsdecomposition. Algorithm 6 suggests dynamic notion decomposition, disjointcomponents recognized variable split. dynamic decompositioninitially proposed utilized Bayardo Pehoushek (2000) model countingadopted recent model counters (Sang et al., 2004, 2005). Darwiche (2002, 2004)proposed another method performing decomposition less dynamically preprocessing CNF formula generate dtree (decomposition tree), binary treewhose leaves correspond clauses CNF formula. node dtree definesset variables, called cutset, whose instantiation guaranteed decomposeCNF formula node disjoint components. rationale costdynamically computing partition (Line 5 Algorithm 6) many times searchreplaced lesser cost computing static recursive partitionall. method decomposition allows one provide structure-based computationalguarantees discussed above. Moreover, instantiation variables cutsetperformed dynamically, utilizing dynamic variable ordering heuristics typically doneSAT solvers. use dtrees, combined dynamic variable ordering, leadsalmost static behavior highly structured problems, cutsets small. Yet, one207fiHuang & Darwichesees dynamic behavior less structured problems, random 3-SAT,cutsets relatively large dynamic variable ordering tends dominate. Interestingly, static behavior dtrees (low overhead) orders magnitude efficientpurely dynamic behavior structured benchmarks, including ISCAS85 circuits.hand, dynamic behavior dtrees lead competitive resultsunstructured benchmarks, including random 3-SAT. One may obtain results effectrunning model counter Sang et al. (2004), Cachet Version 1.1, d-DNNFcompiler Darwiche (2004), c2d Version 2.2, relevant benchmarks. notedtwo programs differ aspects, decomposition method appearsone major differences.4.4 Harnessing Search Techniques Knowledge CompilationResearch recent years greatly improved efficiency scalability systematicsearch methods, particularly problem propositional satisfiability. Techniques contributing improvement include sophisticated conflict analysis, dependencydirected backtracking, clause learning, new variable ordering heuristics, data structuresfaster constraint propagation, among things (Marques-Silva & Sakallah, 1996;Marques-Silva, 1999; Aloul, Markov, & Sakallah, 2001; Moskewicz, Madigan, Zhao, Zhang,& Malik, 2001; Zhang, Madigan, Moskewicz, & Malik, 2001; Goldberg & Novikov, 2002;Zhang & Malik, 2002; Heule & van Maaren, 2004). hand, describedsection uniform framework systematic search algorithms convertedknowledge compilers exhausting search space recording trace search.framework affords opportunity many successful search techniquescarry knowledge compilation. refer reader Bayardo Pehoushek (2000),Darwiche (2002, 2004), Huang Darwiche (2005b), Sang et al. (2004, 2005) detailed discussions issues arise implementation techniquessearch extended exhaustion, trace search needs stored,decomposition introduced.Finally, note efficiency search addressed techniques (including caching particular) important practical issue, orthogonallanguage generated search, main focus present paper. simpleexample, one may two versions Algorithm 5 drastically different runningtimes input one much better caching method,end day, bound produce exactly OBDD due canonicityOBDDs. another example, learned clause provided conflict analysis reducenumber search nodes, affect final DAG (circuit) generated,nodes avoided correspond contradictions (the constant 0) wouldappear DAG anyway due reduction rules.5. Power Limitations Exhaustive Search AlgorithmsSections 3 4 established notion interpreting trace exhaustivesearch circuit, mapping search algorithm propositional languageconsisting possible traces. notion provides new perspective intrinsicpower limitations search algorithms, illustrated Section 4208fiThe Language SearchBCCB B(a) General determinismB(b) NondeterminismFigure 6: DPLL unable produce general determinism nondeterminism.discussing usefulness search algorithms knowledge compilers inherentinefficiency certain classes inputs. section formalizeconcepts illustrate using examples real implementations exhaustivesearch algorithms.Consider arbitrary exhaustive search algorithm based variable splitting, callDPLLx , suppose traces form propositional language Lx . intrinsic powerlimitations DPLLx identified following two principles, respectively:1. DPLLx runs polynomial time class formulas, DPLLx (with tracerecorded) answer polynomial time query formulas knowntractable language Lx .2. DPLLx run polynomial time formulas polynomial-sizerepresentations exist Lx .Take example model counters recently proposed Bayardo Pehoushek(2000) Sang et al. (2004, 2005), employ techniques decomposition(the latter also) formula caching. simple analysis model counters showstraces language decision-DNNF.3 consider query testingwhether minimization theory implies particular clause , min() |= ,min() defined theory whose models exactly minimum-cardinality models. query heart diagnostic nonmonotonic reasoning knowntractable d-DNNF. Applying first principle above, noting decisionDNNF d-DNNF, conclude query answered polynomial timeclass formulas model counters Bayardo Pehoushek (2000) Sanget al. (2004, 2005) polynomial time complexity. Similarly, probabilistic equivalencetest performed polynomial time formulas models counterspolynomial time complexity.example second principle above, first note neithermodel counters finish polynomial time formulas polynomial-sizerepresentations exist decision-DNNF. Furthermore, recall decision-DNNF definedDefinition 2 strict subset d-DNNF: Every disjunction decision-DNNF circuit3. See DDP algorithm Bayardo Pehoushek (2000) Table 1 Sang et al. (2004).example, variable splitting (Lines 59) Table 1 Sang et al. (2004) corresponds generationdecision node, ToComponents function (Line 6 Line 8) corresponds generationand-node satisfies decomposability.209fiHuang & Darwicheform (x ) (x ), d-DNNF allows disjunctions formlogically inconsistent, yet contradict particularvariable (Figure 6a gives one example). Recall also model counting query remainstractable one generalizes decision-DNNF d-DNNF. decision-DNNF turnssuccinct d-DNNF, therefore, one may find another generation modelcounters, well d-DNNF compilers exponentially efficientcurrent ones.Finally, note DPLL traces inherently bound NNF circuitsdeterministic decomposable. Decomposability alone, however, sufficienttractability important tasks clausal entailment testing, existential quantification variables, cardinality-based minimization (Darwiche & Marquis, 2002). DPLLcannot generate traces DNNF d-DNNF (Figure 6b example), sincevariable splitting (the heart DPLL) amounts enforcing determinism. property determinism provides power needed model counting (#SAT),essential applications probabilistic reasoning. one needpower, one go beyond DPLL-based procedures; otherwise one would solvingharder computational problem necessary.6. Relation Previous Workemployed notion trace search paper provide theoreticalpractical channel advances systematic search knowledge compilation. channel indeed active time, implicitly mostly onedirection: systematic search algorithms employed compile knowledge bases (see,example, Darwiche, 2002, 2004; Huang & Darwiche, 2005b; Darwiche, 2005). fact,techniques variable ordering, decomposition, caching extensivelyused bodies work, used (some recently) pure searchalgorithms.key contribution paper formally explicating notion searchtrace, proposing basis systematic framework compiling knowledgebases subsets NNF. contrasted earlier systematic studiesNNF (Darwiche & Marquis, 2002), concerned describing variousproperties compiled NNF representations without delving algorithmic naturegenerating them. Another key contribution paper activating seconddirection search/compilation channel: looking language membership searchtraces formally characterize power limitations various search algorithms.recent line work, centering notion AND/OR search,also concerned understanding power limitations various search techniques,decomposition caching, measuring size explored search spaces (Dechter& Mateescu, 2004b, 2004a; Marinescu & Dechter, 2005). premise worktraditional search algorithms (based branching) thought exploringORsearch space, recent search algorithms (employing decomposition) thoughtexploring AND/ORsearch space. Here, space AND/OR search characterized graph (or tree caching used) alternating layers AND-nodesOR-nodes, former representing decomposition latter branching. algorithms210fiThe Language Searchexploring AND/ORsearch space therefore exhibit behavior similar Algorithm 6, used compiling CNF d-DNNF (Darwiche, 2002, 2004, 2005)), exceptAlgorithm 6 records AND/ORsearch space explicitly circuit. Hence, AND/ORsearch Algorithm 6 share limitations discussed DPLL: cannot takeadvantage general notion determinism, rid determinism altogether.note proposed algorithms AND/OR search proceed instantiating variables performing decomposition according pseudo tree (Freuder & Quinn,1985), earlier work d-DNNF compilation uses decomposition tree twotasks (corresponding choices Lines 5 14 Algorithm 6). Pseudo trees decomposition trees similar provide scheme instantiationcertain set variables lead decomposition problem. frameworkproposed paper, however, make commitment either decompositionvariable ordering scheme, relevant discussion. One notethough commitment particular decomposition variable ordering schemesignificant practical implications. Specifically, search algorithm whose traced-DNNF may performing variable ordering decomposition wayprohibit possibility generating certain (space efficient) d-DNNF circuits.Finally, one identify major difference AND/OR search d-DNNFcompilation, terms handling queries: execution AND/OR searchalgorithm answers single query, executing d-DNNF compilation algorithmresults compact structure used repeatedly answer queries (forknowledge base) known tractable. discussed earlier, traversingcompiled structure potentially much efficient repeating searchproduced it. point view, separation search actual reasoningtask provides benefit amortizing search effort potentially large numberqueries. also provides, discussed, systematic methodologyindependent advances search harnessed improve performance automatedreasoning systems.7. Experimental Resultsway experimentation, ran implementations Algorithm 5 using MINCE variable ordering heuristic (Aloul et al., 2001), Algorithm 4 using VSIDS variable orderingheuristic (Moskewicz et al., 2001), Algorithm 6 using static decomposition hypergraph partitioning (Darwiche & Hopkins, 2001), compile set CNF formulasOBDD, FBDD, d-DNNF, respectively (implementation details first thirdprograms found Huang & Darwiche, 2005b Darwiche, 2004). goalexperiments show practicality search-based compilation frameworkillustrate improvement language succinctness response relaxationconstraints search process. benchmarks used include random 3-CNFgraph coloring problems Hoos Stutzle (2000), set ISCAS89 circuits.results experiments shown Table 3, running timesgiven seconds based 2.4GHz CPU. size compilation reflects numberedges NNF DAG. dash indicates compilation succeed givenavailable memory (4GB) 900-second time limit. seen211fiHuang & DarwicheTable 3: Compiling CNF OBDD, FBDD, d-DNNF.CNFNameuf75-01uf75-02uf75-03uf100-01uf100-02uf100-03uf200-01uf200-02uf200-03flat75-1flat75-2flat75-3flat100-1flat100-2flat100-3flat200-1flat200-2flat200-3s820s832s838.1s953s1196s1238s1423s1488s1494NumberModels22584622331419670641128961555776804085558249607741442592068428824537611197440537931483545613670940672152195604488388608838860873786976294838206464351843720888324294967296429496729624758800785707605497982484481638416384OBDDSizeTime103200.14224760.154500.0228862.2215540.91124620.788364651.04237840.16133740.28843300.29622980.78888241.57154860.151372536 72.991147272 76.55875520.242629464 38.814330656 78.263181302 158.846188427 50.353974256 31.67FBDDSizeTime36840.02147780.044500.0222680.0111640.0799240.12718235.931290033.72662238 56.61107580.0488440.04264720.07377040.10398820.30210720.09134184 7.07358092 4.13364698 0.69362520 0.701954752 4.014407768 12.494375122 12.14388026 1.14374760 1.07d-DNNFSizeTime8220.0215230.03790.014130.022100.0413630.022623.667442.6486696 10.6422730.0118380.0141840.0434750.0365540.0923850.02184781 56.869859 23.8192693.28233470.07213950.05121480.02852180.26206830 0.44293457 0.94738691 4.75518830.19556550.18instances, compilation smallest d-DNNF, FBDD, OBDD;similar relation observed among running times. Also, number instancessuccessfully compiled largest d-DNNF, FBDD, OBDD. trackswell theoretical succinctness relations three languages. (However, noteFBDD d-DNNF canonical representations therefore compilations smallerreported perfectly possible; smaller OBDD compilations are, course, alsopossible different variable orderings.)close section noting implementations knowledge compilersbear witness advantage search-based compilation framework describedSection 4. first compiler based existing SAT solver (Moskewicz et al.,2001), two implementation DPLL, three benefitingtechniques found success SAT, including conflict analysis, clause learning,data structures efficient detection unit clauses.212fiThe Language Search8. Conclusionwork concerned class exhaustive search algorithms run propositional knowledge bases. proposed novel methodology whereby trace searchidentified combinational circuit search algorithm mapped propositional language consisting possible traces. mapping leads uniformpractical framework compilation propositional knowledge bases various languagesinterest, time provides new perspective intrinsic power limitations exhaustive search algorithms. interesting examples, unveiled hiddenpower several recent model counters, discussed one potential limitations,pointed inability class algorithms produce traces without propertydeterminism, limits power knowledge compilation point view.discussed generality results relation recent work AND/ORsearch. Finally, presented experimental results demonstrate practicalitysearch-based knowledge compilation framework illustrate variation languagesuccinctness response variation search strategy.AcknowledgmentsParts work presented DPLL Trace: SAT KnowledgeCompilation, Proceedings 19th International Joint Conference Artificial Intelligence (IJCAI), 2005, pages 156162. thank Rina Dechter anonymous reviewersfeedback earlier drafts paper. work partially supportedNSF grant IIS-9988543, MURI grant N00014-00-1-0617, JPL/NASA contract 442511DA-57765. National ICT Australia funded Australian Governments BackingAustralias Ability initiative, part Australian Research Council.AppendixProof Theorem 1first point recursion guaranteed terminate recursive call(Line 6) accompanied disappearance one variable eventually either Line 2Line 4 execute. Assuming compact drawing decision nodes Figure 1c,show every DAG returned Algorithm 2 FBDD, every FBDDgenerated execution Algorithm 2.Part I: three return statements Algorithm 2: Lines 2, 4, 6. singlenodes returned Lines 2 4 trivial FBDDs. DAG returned get-nodeLine 6, call G, decision node induction level recursion. Hence remainsshow G satisfies test-once property (equivalent decomposability casediscussed Section 2.1), true Line 6, variable x replacedconstants two recursive calls, hence cannot appear two graphssupplied second third arguments get-node. Finally, FBDDs returnedalgorithm guaranteed reduced use unique nodes techniqueget-node function (Brace et al., 1991).213fiHuang & DarwichePart II: Let G denote arbitrary (reduced) FBDD, also root node. Definefollowing function (G) returns CNF formula (as set clauses) every G:{the empty clause},{},(G){x c | c (G.low)} {x c | c (G.high)},G 0-sink;G 1-sink;otherwise, node Glabeled variable x.last line definition above, assume literal x (and x) always appendedfront clause c. execute Algorithm 2 (G), Line 5 always choosefirst variable clause (the first variable every clause must same).DAG returned isomorphic G.Proof Theorem 2show every DAG returned Algorithm 5 OBDD, every OBDDgenerated execution Algorithm 5.Part I: First, DAG returned Algorithm 5 FBDD Algorithm 5restricted version Algorithm 2. Second, DAG OBDD nonterminalnode N DAG must constructed Line 9, therefore virtue Line 8 satisfiesfollowing property: variable x labels N appears variablestwo subgraphs N variable order . Finally, OBDDs returned algorithmguaranteed reduced use unique nodes technique get-nodefunction (Brace et al., 1991).Part II: Given arbitrary (reduced) OBDD G, let variable order G.using (G) defined previous proof, execute Algorithm 5 ((G), ). DAGreturned isomorphic G.Proof Theorem 3show every DAG returned Algorithm 6 decision-DNNF circuit,every decision-DNNF circuit generated execution Algorithm 6.Part I: Nodes returned get-and-node Line 10 conjunction nodes satisfydecomposability components identified Line 5 share variables. Nodesreturned get-node Line 15 disjunction nodes form Figure 1cdefinition get-node. Therefore whole DAG decision-DNNF. Finally, decisionDNNF circuits returned algorithm guaranteed reduced useunique nodes technique get-node get-and-node functions.Part II: Let G denote arbitrary (reduced) decision-DNNF circuit. assumingcompact drawing decision nodes Figure 1c, expand previous definition(G) follows:{the empty clause},{},[(G)(Gi ),{x c | c (G.low)} {x c | c (G.high)},214G 0-sink;G ^1-sink;GGi ;otherwise, node Glabeled variable x.fiThe Language Searchprevious definition (G), assume last line definition above,literal x (and x) always appended front clause c. Now, let literalclause associated (possibly empty) list colors follows: listsinitially empty literals x x introduced last line definition;third line definition, assign distinct color sets unioned,set, append assigned color head list colors first literalevery clause. execute Algorithm 6 (G) resolve nondeterministic choicesLine 5 (decomposition) Line 14 (variable selection) follows: first literalclause nonempty list colors, (the first literal every clause mustnonempty list colors) let Line 5 partition set clauses according first colorfirst literal remove color first literal every clause; otherwise,(the first literal every clause must mention variable) let Line 5 return singlepartition Line 14 choose first variable clause. DAG returnedisomorphic G.ReferencesAloul, F., Markov, I., & Sakallah, K. (2001). Faster SAT smaller BDDs via commonfunction structure. International Conference Computer Aided Design (ICCAD),pp. 443448.Arvelo, Y., Bonet, B., & Vidal, M.-E. (2006). Compilation query-rewriting problemstractable fragments propositional logic. Proceedings 21st NationalConference Artificial Intelligence (AAAI).Bacchus, F., Dalmao, S., & Pitassi, T. (2003a). Algorithms complexity results#SAT Bayesian inference. 44th Annual IEEE Symposium FoundationsComputer Science (FOCS), pp. 340351.Bacchus, F., Dalmao, S., & Pitassi, T. (2003b). DPLL caching: new algorithm#SAT Bayesian inference. Electronic Colloquium Computational Complexity(ECCC), 10 (003).Barrett, A. (2004). hybrid systems universal plans via domain compilation. Proceedings 14th International Conference Automated Planning Scheduling(ICAPS), pp. 4451.Barrett, A. (2005). Model compilation real-time planning diagnosis feedback.Proceedings 19th International Joint Conference Artificial Intelligence(IJCAI), pp. 11951200.Barwise, J. (Ed.). (1977). Handbook Mathematical Logic. North-Holland.Bayardo, R., & Pehoushek, J. (2000). Counting models using connected components.Proceedings 17th National Conference Artificial Intelligence (AAAI), pp.157162.Berre, D. L., & Simon, L. (2005).http://www.satcompetition.org/.AnnualSATCompetitions.Birnbaum, E., & Lozinskii, E. (1999). good old Davis-Putnam procedure helps countingmodels. Journal Artificial Intelligence Research, 10, 457477.215fiHuang & DarwicheBlum, M., Chandra, A. K., & Wegman, M. N. (1980). Equivalence free Boolean graphsdecided probabilistically polynomial time. Information Processing Letters,10 (2), 8082.Bonet, B., & Geffner, H. (2006). Heuristics planning penalties rewards using compiled knowledge. Proceedings Tenth International ConferencePrinciples Knowledge Representation Reasoning (KR), pp. 452462.Brace, K. S., Rudell, R. L., & Bryant, R. E. (1991). Efficient implementation BDDpackage. Proceedings 27th Design Automation Conference (DAC), pp. 4045.Bryant, R. E. (1986). Graph-based algorithms Boolean function manipulation. IEEETransactions Computers, C-35, 677691.Bryant, R. E. (1991). complexity VLSI implementations graph representationsBoolean functions application integer multiplication. IEEE transactionsComputers, 40, 205213.Cadoli, M., & Donini, F. M. (1997). survey knowledge compilation. AI Communications, 10, 137150.Chauhan, P., Clarke, E. M., & Kroening, D. (2003). Using SAT based image computationreachability analysis. Tech. rep. CMU-CS-03-151, School Computer Science,Carnegie Mellon University.Chavira, M., & Darwiche, A. (2005). Compiling Bayesian networks local structure.Proceedings 19th International Joint Conference Artificial Intelligence(IJCAI), pp. 13061312.Chavira, M., Darwiche, A., & Jaeger, M. (2006). Compiling relational Bayesian networksexact inference. International Journal Approximate Reasoning, 42 (1-2), 420.Coste-Marquis, S., Berre, D. L., Letombe, F., & Marquis, P. (2005). Propositional fragmentsknowledge compilation quantified Boolean formulae.. Proceedings20th National Conference Artificial Intelligence (AAAI), pp. 288293.Darwiche, A. (2001). tractability counting theory models applicationbelief revision truth maintenance. Journal Applied Non-Classical Logics,11 (1-2), 1134.Darwiche, A. (2002). compiler deterministic decomposable negation normal form.Proceedings 18th National Conference Artificial Intelligence (AAAI), pp.627634.Darwiche, A. (2004). New advances compiling CNF decomposable negation normal form. Proceedings 16th European Conference Artificial Intelligence(ECAI), pp. 328332.Darwiche, A. (2005). c2d compiler user manual. Tech. rep. D-147, Computer ScienceDepartment, UCLA. http://reasoning.cs.ucla.edu/c2d/.Darwiche, A., & Hopkins, M. (2001). Using recursive decomposition construct eliminationorders, jointrees dtrees. Trends Artificial Intelligence, Lecture notes AI,2143, pp. 180191. Springer-Verlag.216fiThe Language SearchDarwiche, A., & Huang, J. (2002). Testing equivalence probabilistically. Tech. rep. D-123,Computer Science Department, UCLA.Darwiche, A., & Marquis, P. (2002). knowledge compilation map. Journal ArtificialIntelligence Research, 17, 229264.Davis, M., Logemann, G., & Loveland, D. (1962). machine program theorem proving.Journal ACM, (5)7, 394397.Dechter, R., & Mateescu, R. (2004a). impact AND/OR search spaces constraintsatisfaction counting. Proceedings 10th International ConferencePrinciples Practice Constraint Programming (CP), pp. 731736.Dechter, R., & Mateescu, R. (2004b). Mixtures deterministic-probabilistic networksAND/OR search spaces. Proceedings 20th Conference UncertaintyArtificial Intelligence (UAI), pp. 120129.del Val, A. (1994). Tractable databases: make propositional unit resolution complete compilation. Proceedings Fourth International ConferencePrinciples Knowledge Representation Reasoning (KR), pp. 551561.del Val, A. (1995). analysis approximate knowledge compilation. Proceedings14th International Joint Conference Artificial Intelligence (IJCAI), pp. 830836.Elliott, P., & Williams, B. (2006). DNNF-based belief state estimation. Proceedings21st National Conference Artificial Intelligence (AAAI).Forbus, K. D., & de Kleer, J. (1993). Building Problem Solvers. MIT Press.Freuder, E. C., & Quinn, M. J. (1985). Taking advantage stable sets variablesconstraint satisfaction problems. Proceedings Ninth International Joint Conference Artificial Intelligence (IJCAI), pp. 10761078.Gergov, J., & Meinel, C. (1994). Efficient analysis manipulation OBDDsextended FBDDs. IEEE Transactions Computers, 43 (10), 11971209.Goldberg, E., & Novikov, Y. (2002). BerkMin: fast robust SAT-solver. DesignAutomation Test Europe (DATE), pp. 142149.Grumberg, O., Schuster, A., & Yadgar, A. (2004). Memory efficient all-solutions SAT solverapplication reachability analysis. Proceedings 5th InternationalConference Formal Methods Computer-Aided Design (FMCAD), pp. 275289.Heule, M., & van Maaren, H. (2004). Aligning CNF- equivalence reasoning. Proceedings Seventh International Conference Theory Applications Satisfiability Testing (SAT).Hoos, H. H., & Stutzle, T. (2000). SATLIB: online resource research SAT.I.P.Gent, H.v.Maaren, T.Walsh, editors, SAT 2000, pp. 283292. IOS Press. SATLIBavailable online www.satlib.org.Huang, J. (2006). Combining knowledge compilation search conformant probabilisticplanning. Proceedings 16th International Conference Automated PlanningScheduling (ICAPS), pp. 253262.217fiHuang & DarwicheHuang, J., & Darwiche, A. (2005a). compiling system models faster scalablediagnosis. Proceedings 20th National Conference Artificial Intelligence(AAAI), pp. 300306.Huang, J., & Darwiche, A. (2005b). Using DPLL efficient OBDD construction.Seventh International Conference Theory Applications Satisfiability Testing,SAT 2004, Revised Selected Papers, Vol. 3542 Lecture Notes Computer Science,pp. 157172.Karnaugh, M. (1953). map method synthesis combinational logic circuits. Transactions AIEE, 72 (9), 593599.Majercik, S. M., & Littman, M. L. (1998). Using caching solve larger probabilisticplanning problems. Proceedings 15th National Conference Artificial Intelligence (AAAI), pp. 954959.Marinescu, R., & Dechter, R. (2005). AND/OR branch-and-bound graphical models.Proceedings 19th International Joint Conference Artificial Intelligence(IJCAI), pp. 224229.Marques-Silva, J., & Sakallah, K. (1996). GRASPA new search algorithm satisfiability.Proceedings International Conference Computer Aided Design (ICCAD),pp. 220227.Marques-Silva, J. (1999). impact branching heuristics propositional satisfiabilityalgorithms. Proceedings 9th Portuguese Conference Artificial Intelligence,pp. 6274.Marquis, P. (1995). Knowledge compilation using theory prime implicates. Proceedings14th International Joint Conference Artificial Intelligence (IJCAI), pp. 837843.McMillan, K. (1993). Symbolic Model Checking. Kluwer Academic.McMillan, K. L. (2002). Applying SAT methods unbounded symbolic model checking.Proceedings 14th International Conference Computer Aided Verification(CAV), pp. 250264.Meinel, C., & Theobald, T. (1998). Algorithms Data Structures VLSI Design: OBDDFoundations Applications. Springer.Moskewicz, M., Madigan, C., Zhao, Y., Zhang, L., & Malik, S. (2001). Chaff: Engineeringefficient SAT solver. Proceedings 38th Design Automation Conference(DAC), pp. 530535.Palacios, H., Bonet, B., Darwiche, A., & Geffner, H. (2005). Pruning conformant planscounting models compiled d-DNNF representations. Proceedings 15thInternational Conference Automated Planning Scheduling (ICAPS), pp. 141150.Sang, T., Bacchus, F., Beame, P., Kautz, H., & Pitassi, T. (2004). Combining componentcaching clause learning effective model counting. Proceedings SeventhInternational Conference Theory Applications Satisfiability Testing (SAT),pp. 2028.218fiThe Language SearchSang, T., Beame, P., & Kautz, H. (2005). Heuristics fast exact model counting.Proceedings Eighth International Conference Theory ApplicationsSatisfiability Testing (SAT), Lecture Notes Computer Science, pp. 226240.Selman, B., & Kautz, H. (1991). Knowledge compilation using Horn approximation.Proceedings Ninth National Conference Artificial Intelligence (AAAI), pp.904909.Selman, B., & Kautz, H. (1996). Knowledge compilation theory approximation. JournalACM, 43 (2), 193224.Siddiqi, S., & Huang, J. (2007). Hierarchical diagnosis multiple faults. Proceedings20th International Joint Conference Artificial Intelligence (IJCAI), pp. 581586.Somenzi, F. (2004).CUDD: CU Decision Diagram Package, Release 2.4.0.http://vlsi.colorado.edu/fabio/CUDD/cuddIntro.html.Urquhart, A. (1995). complexity propositional proofs. Bulletin Symbolic Logic,1 (4), 425467.Wegener, I. (2000). Branching Programs Binary Decision Diagrams: Theory Applications. SIAM Monographs Discrete Mathematics Applications.Zhang, L., Madigan, C., Moskewicz, M., & Malik, S. (2001). Efficient conflict driven learningBoolean satisfiability solver. Proceedings International ConferenceComputer Aided Design (ICCAD), pp. 279285.Zhang, L., & Malik, S. (2002). quest efficient Boolean satisfiability solvers.Proceedings 18th International Conference Automated Deduction (CADE),Lecture Notes Computer Science, pp. 295313.219fiJournal Artificial Intelligence Research 29 (2007) 421-489Submitted 8/06; published 8/07Algebraic Graphical Model DecisionUncertainties, Feasibilities, UtilitiesCedric Praletcedric.pralet@onera.frONERA Toulouse, France2 av. Edouard Belin, 31400 ToulouseGerard Verfailliegerard.verfaillie@onera.frONERA Toulouse, France2 av. Edouard Belin, 31400 ToulouseThomas Schiexthomas.schiex@toulouse.inra.frINRA Toulouse, FranceChemin de Borde Rouge, 31320 Castanet-TolosanAbstractNumerous formalisms dedicated algorithms designed last decadesmodel solve decision making problems. formalisms, constraint networks, express simple decision problems, others designed take account uncertainties, unfeasible decisions, utilities. Even single formalism, severalvariants often proposed model different types uncertainty (probability, possibility...) utility (additive not). article, introduce algebraic graphical modelencompasses large number formalisms: (1) first adapt previous structuresFriedman, Chu Halpern representing uncertainty, utility, expected utilityorder deal generic forms sequential decision making; (2) structures,introduce composite graphical models express information via variables linkedlocal functions, thanks conditional independence; (3) graphical models,finally define simple class queries represent various scenarios termsobservabilities controllabilities. natural decision-tree semantics queriescompleted equivalent operational semantics, induces generic algorithms.proposed framework, called Plausibility-Feasibility-Utility (PFU) framework,provides better understanding links existing formalisms, alsocovers yet unpublished frameworks (such possibilistic influence diagrams) unifiesformalisms quantified boolean formulas influence diagrams. backtrackvariable elimination generic algorithms first step towards unified algorithms.1. Introductionlast decades, numerous formalisms developed express solve decisionmaking problems. problems, agent must make decisions consisting eitherchoosing actions ways fulfill (as action planning, task scheduling, resourceallocation), choosing explanations observed phenomena (as diagnosis situationassessment). choices may depend various parameters:1. uncertainty measures, call plausibilities, may describe beliefs stateenvironment;2. preconditions may satisfied decision feasible;c2007AI Access Foundation. rights reserved.fiPralet, Verfaillie, & Schiex3. possible states environment decisions generallyvalue decision makers point view. Utilities expressed model costs,gains, risks, satisfaction degrees, hard requirements, generally, preferences;4. time involved, decision processes may sequential environment maypartially observable. means may several decision steps,values variables may observed two steps, chessplayer plays turn observe move opponent playingagain;5. may adversarial collaborative decision makers, controllingset decisions. Hence, multi-agent aspect yield partial controllabilities.Given plausibilities defined states environment, feasibility constraints decisions, utilities defined decisions states environment, given possible multiple decision steps, objective provide decisionmaker optimal decision rules decision variables controls, dependingenvironment agents. concise, class problems denotedclass sequential decision problems plausibilities, feasibilities, utilities.Various formalisms designed cope problems class, sometimesdegenerated form (covering subset features general problem):formalisms developed boolean satisfiability framework: satisfiability problem (SAT), quantified boolean formulas, stochastic SAT (Littman, Majercik, & Pitassi,2001), extended stochastic SAT (Littman et al., 2001);formalisms developed close constraint satisfaction framework: constraintsatisfaction problems (CSPs, Mackworth, 1977), valued/semiring CSPs (Bistarelli,Montanari, Rossi, Schiex, Verfaillie, & Fargier, 1999) (covering classical, fuzzy, additive, lexicographic, probabilistic CSPs), mixed CSPs probabilistic mixed CSPs(Fargier, Lang, & Schiex, 1996), quantified CSPs (Bordeaux & Monfroy, 2002),stochastic CSPs (Walsh, 2002);formalisms developed represent uncertainty extended represent decisionproblems uncertainty: Bayesian networks (Pearl, 1988), Markov random fields(Chellappa & Jain, 1993) (also known Gibbs networks), chain graphs (Frydenberg, 1990), hybrid mixed networks (Dechter & Larkin, 2001; Dechter & Mateescu,2004), influence diagrams (Howard & Matheson, 1984), unconstrained (Jensen & Vomlelova, 2002), asymmetric (Smith, Holtzman, & Matheson, 1993; Nielsen & Jensen,2003), sequential (Jensen, Nielsen, & Shenoy, 2004) influence diagrams, valuationnetworks (Shenoy, 1992), asymmetric (Shenoy, 2000) sequential (Demirer &Shenoy, 2001) valuation networks;formalisms developed classical planning framework, STRIPS planning (Fikes & Nilsson, 1971; Ghallab, Nau, & Traverso, 2004), conformant planning (Goldman & Boddy, 1996), probabilistic planning (Kushmerick, Hanks, &Weld, 1995);422fiThe PFU Frameworkformalisms Markov decision processes (MDPs), probabilistic, possibilistic,using Spohns epistemic beliefs (Spohn, 1990; Wilson, 1995; Giang & Shenoy,2000), factored not, possibly partially observable (Puterman, 1994; Monahan, 1982;Sabbadin, 1999; Boutilier, Dean, & Hanks, 1999; Boutilier, Dearden, & Goldszmidt,2000).Many formalisms present interesting similarities:include variables modeling state environment (environment variables)decisions (decision variables);use sets functions which, depending formalism considered, modelplausibilities, feasibilities, utilities;use operators either combine local information (such aggregate probabilities independence hypothesis, + aggregate gains costs), projectglobal information (such + compute marginal probability, min maxcompute optimal decision).Even meaning variables, functions, combination projection operatorsmay specific formalism, seen graphical models senseexploit, implicitly explicitly, hypergraph local functions variables.article shows possible build generic algebraic framework subsuming manyformalisms reducing decision making problems sequence so-called variableeliminations aggregation local functions.generic framework able provide:better understanding existing formalisms: generic framework obvioustheoretical pedagogical interest, since bring light similarities differences formalisms covered help people different communitiescommunicate common basis;increased expressive power : generic framework may able capture problemscannot directly modeled existing formalism. increased expressiveness reachable capturing essential algebraic properties existingframeworks;generic algorithms: ultimately, besides generic framework, possibledefine generic algorithms capable solving problems defined framework.objective fits growing effort identify common algorithmic approachesdeveloped solving different AI problems. may also facilitate crossfertilization allowing subsumed framework reuse algorithmic ideas definedanother one.1.0.1 Article Outlineintroduction notations notions, article starts showing,catalog existing formalisms decision making, generic algebraic framework423fiPralet, Verfaillie, & Schiexinformally identified. generic framework, called Plausibility-Feasibility-Utility(PFU) framework, formally introduced three steps: (1) algebraic structures capturing plausibilities, feasibilities, utilities introduced (Section 4), (2) algebraic structures exploited build generic form graphical model (Section 5),(3) problems graphical models captured notion queries (Section 6).framework analyzed Section 7 generic algorithms defined Section 8.table recapitulating main notations used available Appendix proofspropositions theorems appear Appendix B. short version frameworkdescribed article already published (Pralet, Verfaillie, & Schiex, 2006c).2. Background Notations Definitionsessential objects used article variables, domains, local functions (calledscoped functions).Definition 1. domain values variable x denoted dom(x) everydom(x), (x, a) denotes assignment value x. extension, setvariables S, denoteQ dom(S) Cartesian product domains variablesS, i.e. dom(S) = xS dom(x). element dom(S) called assignment S.1A1 , A2 assignments disjoint subsets S1 , S2 , A1 .A2 , called concatenationA1 A2 , assignment S1 S2 variables S1 assigned A1variables S2 assigned A2 . assignment set variables S,projection onto 0 assignment 0 variables assignedvalue A.Definition 2. (Scoped function) scoped function pair (S, ) setvariables function mapping elements dom(S) given set E. following,often consider implicit denote scoped function (S, ) alone.set variables called scope denoted sc(). assignmentsuperset sc() A0 projection onto sc(), define (A) (A) = (A0 ).example, scoped function mapping assignments sc() elementsboolean lattice B = {t, f } analogous constraint describing subset dom(sc())authorized tuples constraint networks.this, general notion graphical model defined:Definition 3. (Graphical model) graphical model pair (V, ) V = {x1 , . . . , xn }finite set variables = {1 , . . . , } finite set scoped functions whosescopes included V .terminology graphical models used simply set scoped functionsrepresented hypergraph contains one hyperedge per function scope.see, hypergraph captures form independence (see Section 5) inducesparameters time space complexity algorithms (see Section 8).definition graphical models generalizes usual one used statistics, defining graphical1. assignment = {x1 , . . . , xk } actually set variable-value pairs {(x1 , a1 ), . . . , (xk , ak )};assume variables implicit using tuple values (a1 , . . . , ak ) dom(S).424fiThe PFU Frameworkmodel (directed not) graph nodes represent random variablesstructure captures probabilistic independence relations.Local scoped functions graphical model give space-tractable definitionglobal function defined aggregation. example, Bayesian network (Pearl,1988) global probability distribution Px,y,z x, y, z may defined product(using operator ) set scoped functions {Px , Py|x , Pz|y }. Local scoped functionsalso facilitate projection information expressed graphical model ontosmaller scope. example, order computeP marginalP probability distribution Py,zprevious network, computeP x Px,y,z = ( x Px Py|x ) Pz|y avoidtaking Pz|y account. operatorused project information onto smallerscope eliminating variable x. Operators used combine scoped functions calledcombination operators, operators used project information onto smaller scopescalled elimination operators.Definition 4. (Combination) Let 1 , 2 scoped functions E1 E2 respectively. Let: E1 E2 E binary operator. combination 1 2 , denoted 1 2 ,scoped function E scope sc(1 )sc(2 ) defined (1 2 )(A) = 1 (A)2 (A)assignments sc(1 ) sc(2 ). called combination operator 12 .rest article, combination operators denoted .Definition 5. (Elimination) Let scoped function E. Let op Eassociative, commutative, identity element . elimination variablex op scoped function whose scope sc() {x} whose valueassignment scope (opx )(A) = opadom(x) (A.(x, a)). context, op calledelimination operator x. elimination set variables = {x1 , . . . , xk }function scope sc() defined opS (A) = opA0 dom(S) (A.A0 ).PHence, computing x (Px Py|x Pz|x ), scoped functions aggregated usingcombination operator = information projected eliminating x usingelimination operator +. article, denotes elimination operators.cases, elimination set variables operator op scopedfunction performed subset dom(S) containing assignmentssatisfy property denoted boolean scoped function F . Then, must computeevery dom(sc() S) value opA0 dom(S),F (A0 )=t (A.A0 ). simplicityhomogeneity, order always use elimination dom(S), equivalentlytruncate elements dom(S) satisfy F mapped specialvalue (denoted ) defined new identity op.Definition 6. (Truncation operator) unfeasible value new special elementsupposed outside domain E every elimination operator op : E E E.explicitly extend every elimination operator op : E E E E {} takingconvention op(, e) = op(e, ) = e e E {}.Let {t, f } boolean lattice. boolean b e E, define b ? eequal e b = otherwise. ? called truncation operator.425fiPralet, Verfaillie, & SchiexGiven boolean scoped function F , ? make possible write quantities likeopA0 dom(S),F (A0 )=t elimination opS (F ? ).order solve decision problems, one usually wants compute functions mappingavailable information decision. notion decision rules used formalizethis:Definition 7. (Decision rule, policy) decision rule variable x given set variables0 function : dom(S 0 ) dom(x) mapping assignment 0 value dom(x).extension, decision rule set variables given set variables 0 function: dom(S 0 ) dom(S). set decision rules called policy.Definition 8. (Optimal decision rule) Consider totally -ordered set E, scoped functiondom(sc()) E, set variables sc(). decision rule : dom(sc()S) dom(S). said optimal iff, (A, A0 ) dom(sc() S) dom(S),(A.(A)) (A.A0 ) (resp. (A.(A)) (A.A0 )). decision rule always existsdom(sc()) finite.words, optimal decision rules examples decision rules given argminargmax (in article, consider optimality decision rules always givenmin max totally ordered set).Definition 9. (Directed Acyclic Graph (DAG)) directed graph G DAG containsdirected cycle. variables used vertices, paG (x) denotes set parentsvariable x G.Last, [1, n] denote set integers 1 n.3. Examples Graphical Models Generic Frameworkpresent different AI formalisms expressing solving decision problems.simple case, single decision maximizes utility sought. introductionplausibilities (uncertainties), unfeasible actions (feasibilities), sequential decision(several decision steps observations decision steps) appearssophisticated frameworks. goal section show formalismsviewed graphical models specific elimination combination operatorsused.3.1 Examples Graphical Modelsexamples used cover various AI formalisms, briefly described. wideraccurate review existing graphical models could provided (Pralet, 2006).3.1.1 Constraint NetworksConstraint networks (CNs, Mackworth, 1977), often called constraint satisfaction problems(CSPs), graphical models (V, ) scoped functions constraints mappingassignments onto {t, f }. usual query CN determine existence426fiThe PFU Frameworkassignment V satisfies constraints. setting f t, decision problemanswered computing:max .(1)Vquantity equals true, optimal decision rule V defines solution.query answered performing eliminations (using max) combination scopedfunctions (using ). Replacing hard constraints soft constraints (boolean scopedfunctions replaced cost functions) replacing abstract operator equal+, min, , . . . leads queries valued totally ordered semiring CN (Bistarelliet al., 1999).3.1.2 Bayesian NetworksBayesian networks (BNs, Pearl, 1988) model problems plausibilities expressedprobabilities. BN graphical model (V, ) set local conditionalprobability distributions: = {Px | paG (x) , x V }, G DAG vertices V .BN represents joint probability distribution PQV variables combinationlocal conditional probability distributions (PV = xV Px | paG (x) ), combinationlocal constraints CN defines global constraint variables. One possible queryBN compute marginal probability distribution variable V :!XXPy =PV =Px | paG (x) .(2)V {y}V {y}xVEquation 2 corresponds variable eliminations (with +) product scoped functions.queries BNs MAP (Maximum Posteriori hypothesis), eliminationsmax also performed.3.1.3 Quantified Boolean Formulas Quantified CNsQuantified boolean formulas (QBFs) quantified CNs (Bordeaux & Monfroy, 2002)model sequential decision problems. Let x1 , x2 , x3 boolean variables. QBF usingso-called prenex conjunctive normal form looks like (with f t):x1 x2 x3 ((x1 x3 ) (x2 x3 )) = max min max((x1 x3 ) (x2 x3 )).x1x2x3(3)Thus, query value x1 values x2 , exists valuex3 clauses x1 x3 x2 x3 satisfied? answeredEquation 3 using sequence eliminations (max x1 , min x2 , max x3 )conjunction clauses. quantified CN, clauses replaced constraints.3.1.4 Stochastic CNsstochastic CN (Walsh, 2002) model sequential decision problems probabilitiesplausibilities hard requirements utilities, provided decisions influenceenvironment (the so-called contingency assumption). stochastic CN, two types427fiPralet, Verfaillie, & Schiexvariables defined: decision variables di environment (stochastic) variables sj .global probability distribution environment variables expressed combinationlocal probability distributions. environment variables mutually independent,local probability distributions simply unary probability distributions Psj . Finally,stochastic CN defines set constraints {C1 , . . . , Cm } mapping tuples values onto{0, 1} (instead {t, f }). allows constraints multiplied probabilities.Consider situation first two decisions d1 d2 made, environmentvariable s1 observed, decisions d3 d4 made, environment variable s2remains unobserved. possible query stochastic CN compute decision rulesd1 , d2 , d3 , d4 maximize expected constraint satisfaction, Equation 4:QXXC(4)(Ps1 Ps2 )maxmaxi[1,m] .d1 ,d2s1d3 ,d4s2answer query defined Equation 4 determined sequence eliminations(max decision variables, + environment ones) combination scopedfunctions (probabilities combined using , constraints combined using , sinceexpressed onto {0, 1} instead {t, f }, probabilities combined constraintsusing ).3.1.5 Influence DiagramsInfluence diagrams (Howard & Matheson, 1984) model sequential decision problemsprobabilities plausibilities together gains costs utilities.seen extension BNs including notions decision utility. precisely,influence diagram composite graphical model defined three sets variablesorganized DAG G: (1) set chance variables; S, conditionalprobability distribution Ps | paG (s) given parents G specified; (2) setdecision variables; D, paG (d) set variables observed decisionmade; (3) set = {u1 , . . . , um } utility variables, associatedutility function Ui = UpaG (ui ) scope paG (ui ). Utility variables Pmust leavesDAG, utility functions define global additive utility UG = i[1,m] Ui .usual problem associated influence diagram compute decision rulesmaximizing global expected utility. modify example used stochastic CNsreplacing Ps1 Ps1 | d2 , Ps2 Ps2 | d1 ,d3 , constraints C1 , . . . , Cm additiveutility functions U1 , . . . , Um , optimal policy obtained computing optimaldecision rules d1 , d2 , d3 , d4 Equation 5:XXPmaxmaxPs1 | d2 Ps2 | d1 ,d3U.(5)i[1,m]d1 ,d2s1d3 ,d4s2Again, answer query defined Equation 5 computed sequenceeliminations (alternating max- sum-eliminations) combination scoped functions (plausibilities combined using , utilities combined using +, plausibilities utilitiescombined using ).428fiThe PFU Framework3.1.6 Valuation NetworksValuation networks (Shenoy, 1992) model sequential decision problems plausibilities, feasibilities, utilities, plausibilities combined using utilitiesadditive. valuation network composed several sets nodes valuations: (1)set decision nodes, (2) set chance nodes, (3) set F indicator valuations,specify unfeasible assignments decision chance variables, (4) set P probability valuations, multiplicative factors joint probability distributionchance variables, (5) setP U utility valuations, representing additive factorsjoint utility function UG =Ui U Ui . Arcs nodes also used defineorder decisions made chance variables observed. orderd1 d2 s1 d3 d4 s2 , shown optimal decision rules d1 , d2 , d3 , d4defined Equation 6:XXXFi ?maxmaxPiUi .(6)d1 ,d2s1d3 ,d4Fi Fs2Pi PUi ULocal feasibility constraints combined using , combined scoped functions using truncation operator ? (cf. Definition 6).3.1.7 Finite Horizon Markov Decision ProcessesFinite horizon Markov Decision Processes (MDPs, Puterman, 1994; Monahan, 1982; Sabbadin, 1999; Boutilier et al., 1999, 2000) model sequential decision problems plausibilities utilities horizon time-steps. every time-step t, variable strepresents state environment variable dt represents decision madeobserving st . factored MDPs, several state variables may used time-step.probabilistic finite horizon MDP, plausibilities environment describedlocal probability distributions Pst+1 | st ,dt state st+1 given st dt . utilitiesstates decisions local additive rewards Rst ,dt , boolean functions Fdt | stexpress whether decision dt feasible state st . optimal policy initial states1 computed following equation (which bit unusual defining optimalpolicies MDP, equivalent usual form):!!max u max . . . u maxd1s2d2sTdTt[1,T ]Fdt |st?p Pst+1 |st ,dtt[1,T [puu Rst ,dtt[1,T ].(7)Plausibilities combined using p = , utilities combined using u = +, plausibilitiesutilities combined using pu = , decision variables eliminated using max,environment variables eliminated using u = +. truncation operator ? enableselimination operators ignore unfeasible decisions.pessimistic possibilistic finite horizon MDP (Sabbadin, 1999), probability distributions Pst+1 | st ,dt replaced possibility distributions st+1 | st ,dt , rewards Rst ,dtreplaced preferences st ,dt , operators used u = p = u = minpu : (p, u) max(1 p, u).429fiPralet, Verfaillie, & Schiex3.2 Towards Generic Frameworkprevious section shows usual queries various existing formalisms reducedsequence variable eliminations combination scoped functions.observation led definition algebraic MDPs (Perny, Spanjaard, & Weng,2005) definition valuation algebras (Shenoy, 1991; Kolhas, 2003), genericalgebraic framework eliminations performed combination scopedfunctions. However, valuation algebras use one combination operator, whereas severalcombination operators may needed manipulate different types scoped functions (aspreviously shown). Moreover, valuation algebras deal one type elimination,whereas several elimination operators may required handling different typesvariables. valuation networks (Shenoy, 2000), plausibilities necessarily representedprobabilities, eliminations min cannot performed. Essentially, powerfulframework needed.order simple yet general enough cover queries defined Equations 17, generic form consider is:!!SovFiFi F?pPi PPipuuUi UUi.(8)(1) used combine local feasibilities, p used combine plausibilities, uused combine utilities, pu used combine plausibilities utilities,truncation operator ? used ignore unfeasible decisions without dealelimination operations restricted domains;2 (2) F , P , U (possibly empty) setslocal feasibility, plausibility, utility functions respectively; (3) Sov operatorvariable(s) sequence, indicating eliminate variables. Sov involves min maxeliminate decision variables operator u eliminate environment variables.Equation 8 still informal. define formally, provide clearsemantics, need define three key elements:1. must capture essential properties combination operators p , u , puused respectively combine plausibilities, utilities, plausibilities utilities.must also characterize elimination operators u p used project information coming utilities plausibilities. operators definealgebraic structure PFU (Plausibility-Feasibility-Utility) framework.2. algebraic structure, must define generic form graphical model, involving set variables sets scoped functions expressing plausibilities, feasibilities,utilities (sets P , F , U ). Together, define PFU network. factoredform offered graphical models must also analyzed order understandapplied concisely represent global functions (usingnotion conditional independence).2. Equation 8, plausibilities combined using operator p utilities combinedusing operator u ; denote models composite graphical models includedifferent types scoped functions (plausibilities, feasibilities, utilities). Beyond this, Equation 8also allows heterogeneous information among type scoped functions. example, ordermanipulate probabilities possibilities, use p defined probability-possibility pairs(p1 , 1 ) p (p2 , 2 ) = (p1 p2 , min(1 , 2 )).430fiThe PFU Framework3. Finally, must define queries PFU networks capturing interesting decision problems. Equation 8 shows, queries defined sequence Sov operatorvariable(s) pairs, applied combination scoped functions network.fact answer queries represents meaningful values decision theory point view proved relating approach.3.3 Summaryinformally shown several queries various formalisms dealing plausibilities and/or feasibilities and/or utilities reduce sequences variable eliminationsapplied combinations scoped functions, using various operators. intuitivelycovered Equation 8.three key elements (an algebraic structure, PFU network, sequence variable eliminations) needed formally define give sense equation introducedSections 4, 5, 6.4. PFU Algebraic Structuresfirst element PFU framework algebraic structure specifying information provided plausibilities, feasibilities, utilities combined synthesized.algebraic structure obtained adapting previous structures defined Friedman,Chu, Halpern (Friedman & Halpern, 1995; Halpern, 2001; Chu & Halpern, 2003a)representing uncertainties expected utilities.4.1 DefinitionsDefinition 10. (E, ~) commutative monoid iff E set ~ binary operatorE associative (x ~ (y ~ z) = (x ~ y) ~ z), commutative (x ~ = ~ x),identity 1E E (x ~ 1E = 1E ~ x = x).Definition 11. (E, , ) commutative semiring iff(E, ) commutative monoid, identity denoted 0E ,(E, ) commutative monoid, identity denoted 1E ,0E annihilator (x 0E = 0E ),distributes (x (y z) = (x y) (x z)).Definition 12. Let (Ea , , ) commutative semiring. Then, (Eb , b , ab ) semimodule (Ea , , ) iff(Eb , b ) commutative monoid, identity denoted 0Eb ,ab : Ea Eb Eb satisfiesab distributes b (a ab (b1 b b2 ) = (a ab b1 ) b (a ab b2 )),ab distributes ((a1 a2 ) ab b = (a1 ab b) b (a2 ab b)),431fiPralet, Verfaillie, & Schiexlinearity property: a1 ab (a2 ab b) = (a1 a2 ) ab b,b Eb , 0Ea ab b = 0Eb 1Ea ab b = b.Definition 13. Let E set partial order . operator ~ E monotoniciff (x y) (x ~ z ~ z) x, y, z E.4.2 Plausibility StructureVarious forms plausibilities exist (Halpern, 2003). usual one probabilities.shown previously, example Equation 2, probabilities aggregated using p =combination operator, projected using p = + elimination operator.plausibilities also expressed possibility degrees [0, 1]. Possibilitieseliminated using p = max usually combined using p = min. interesting caseappears possibility degrees booleans describing states environmentcompletely possible impossible. Plausibilities combined using p =eliminated using p = .Another example Spohns epistemic beliefs, also known -rankings (kappa rankings, Spohn, 1990; Wilson, 1995; Giang & Shenoy, 2000). case, plausibilitieselements N {+} called surprise degrees, 0 associated non-surprising situations,+ associated completely surprising (impossible) situations, generallysurprise degree k viewed probability k infinitesimal . Surprise degreescombined using p = + eliminated using p = min.capture various plausibility modeling frameworks, start FriedmanHalperns work plausibility measures (Friedman & Halpern, 1995; Halpern, 2001). Weydert (1994) Darwiche-Ginsberg (1992) developed similar approaches.Friedman-Halperns structure Assume want express plausibilities assignments set variables S. subset dom(S) called event. FriedmanHalpern (1995) define plausibilities elements set Ep called plausibility domain.Ep equipped partial order p two special elements 0p 1p satisfying0p p p p 1p p Ep . function P l : 2dom(S) Ep plausibility measureiff satisfies P l() = 0p , P l(dom(S)) = 1p , (W1 W2 ) (P l(W1 ) p P l(W2 )).means 0p associated impossibility, 1p associated highest plausibilitydegree, plausibility degree set least high plausibility degreesubsets.Among plausibility measures, focus so-called algebraic conditional plausibilitymeasures, use abstract functions p p analogous +probabilities. measures satisfy properties decomposability: disjointevents W1 , W2 , P l(W1 W2 ) = P l(W1 ) p P l(W2 ). associative commutative,follows p associative commutative representations disjoint events, i.e.(a p b) p c = p (b p c) p b = b p exist pairwise disjoint setsW1 , W2 , W3 P l(W1 ) = a, P l(W2 ) = b, P l(W3 ) = c. details availableFriedman-Halperns references (Friedman & Halpern, 1995; Halpern, 2001).Restriction Friedman-Halperns structure important aspect FriedmanHalperns work algebraic properties p p hold domains432fiThe PFU Frameworkdefinition p p . Although sufficient express manipulate plausibilities, algorithmically restrictive. Indeed, consider Bayesian network involving twoPx1 constantboolean variables {x1 , x2 } define Px1 ,x2 Px1 Px2 | x1 . AssumePPx2 | x1 ((x2 , t)) mustfactor 0 = 0.5. order evaluate Px2 ((x2 , t)), quantity x1 0 Pcomputed. so, simpler factor compute 0 x1 Px2 | x1 ((x2 , t)).Px2 | x1 ((x2 , t).(x1 , t)) = 0.6 Px2 | x1 ((x2 , t).(x1 , f )) = 0.8, answer 0.5(0.6+0.8) =0.7. Performing 0.6 + 0.8 requires applying addition outside range usual probabilities, p b defined + b 1, since two probabilities whose sum exceeds1 cannot associated disjoint events.take issues account, adapt Friedman-Halperns Ep , p , p pp become closed Ep Friedman-Halperns axioms hold closedstructure. closure performed, obtain plausibility structure.Definition 14. plausibility structure tuple (Ep , p , p )(Ep , p , p ) commutative semiring (identities p p denoted 0p1p respectively),Ep equipped partial order p 0p = min(Ep ) pp monotonic respect p .Elements Ep called plausibility degreesNote 1p necessarily maximal element Ep . probabilities, FriedmanHalperns structure would ([0, 1], +0 , ), +0 b = + b + b 1undefined otherwise. order get closed operators, take (Ep , p , p ) = (R+ , +, )therefore 1p = 1 maximal element Ep . cases, Friedman-Halpernsstructure already closed. case -rankings (where (Ep , p , p ) = (N{+}, min, +)) possibilities (where (Ep , p , p ) typically ([0, 1], max, min),although choices like ([0, 1], max, ) possible).Given two plausibility structures (Ep , p , p ) (Ep0 , 0p , 0p ), define E = Ep Ep0 ,(p1 , p01 ) (p2 , p02 ) = (p1 p p2 , p01 0p p02 ) (p1 , p01 ) (p2 , p02 ) = (p1 p p2 , p01 0p p02 ),(E, , ) plausibility structure too. allows us deal different kinds plausibilities (such probabilities possibilities) families probability distributions.4.2.1 Plausibility Measures Plausibility DistributionsLet us consider plausibility measure (Friedman & Halpern, 1995; Halpern, 2001) P l :2dom(S) Ep set variables S. Assume P l(W1 W2 ) = P l(W1 ) p P l(W2 )disjoint sets W1 , W2 2dom(S) , case Friedman-Halperns algebraicplausibility measures. assumption entails P l(W ) = p AW P l({A}) W2dom(S) . holds even W = since 0p identity p . Hence, definingP l({A}) complete assignments suffices describe P l. Moreover,case, three conditions defining plausibility measures (P l(dom(S)) = 1p , P l() = 0p ,(W1 W2 ) (P l(W1 ) p P l(W2 ))) equivalent p Adom(S) P l({A}) = 1p ,using monotonicity p third condition. means dealplausibility distributions instead plausibility measures:433fiPralet, Verfaillie, & SchiexDefinition 15. plausibility distribution function PS : dom(S) Epp Adom(S) PS (A) = 1p .normalization condition imposed plausibility distributions simply generalization convention probabilities sum 1. captures factdisjunction assignments 1p plausibility degree.Proposition 1. plausibility distribution PS extended give plausibility distribution PS 0 every 0 S, defined PS 0 = p SS 0 PS .4.3 Feasibility StructureFeasibilities define whether decision possible not, therefore expressedbooleans {t, f }. set equipped total order bool satisfying f bool t.Boolean scoped functions expressing feasibilities combined using operator ,since assignment decision variables feasible iff feasibility functions agreeassignment feasible.Given scoped function Fi expressing feasibilities, compute whether assignment set variables feasible according Fi computing sc(Fi )S Fi (A), sincefeasible according Fi iff one extensions sc(Fi ) feasible. meansprojection feasibility functions onto smaller scope uses elimination operator .result, feasibilities expressed using feasibility structure Sf = ({t, f }, , ).Sf commutative semiring, also plausibility structure. Therefore,plausibility notions properties apply feasibility. may therefore speak feasibility distributions, normalization condition FS = imposed feasibilitydistribution FS means least one decision must feasible.4.4 Utility StructureUtilities express preferences take various forms. Typically, utilities combined+. utilities also model priorities combined using min. Also, utilitiesrepresent hard requirements goals achieved properties satisfied,modeled booleans combined using . generally, utility degrees definedelements set Eu equipped partial order u . Smaller utility degrees associatedless preferred events. Utility degrees combined using operator uassumed associative commutative. guarantees combined utilitiesdepend way combination performed. also assume u admitsidentity 1u Eu , representing indifference. ensures existence default utilitydegree utility scoped functions. properties capturedfollowing notion utility structure.Definition 16. (Eu , u ) utility structure iff commutative monoid Euequipped partial order u . Elements Eu called utility degrees.Eu may minimum element u representing unacceptable eventsannihilator u (the combination event unacceptable one mustunacceptable too). u also usually monotonic. properties necessaryestablish forthcoming results.434fiThe PFU Frameworkdistinction plausibilities, feasibilities, utilities importantjustified using algebraic arguments. Since p u may different operators (forexample, p = u = + usual probabilities additive utilities), mustdistinguish plausibilities utilities. also necessary distinguish feasibilitiesutilities plausibilities. Indeed, imagine simple card game involving two players P1P2 , three cards: jack J, queen Q, king K. P1 must first play onecard x {J, Q, K}, P2 must play card {J, Q, K}, last P1 must play cardz {J, Q, K}. rule forbids play card consecutively (feasibility functions Fxy :x 6= Fyz : 6= z). goal P1 two cards x z value strictlybetter P2 card y. setting J < Q < K, requirement corresponds two utilityfunctions Uxy : x > Uyz : z > y. order compute optimal decisions presenceunfeasibilities, must restrict optimizations (eliminations decision variables maxmin) feasible values: instead maxx miny maxz (Uxy Uyz ), must compute:maxminmax(Uxy (a, b) Uyz (b, c)),adom(x)bdom(y),Fxy (a,b)=tcdom(z),Fyz (b,c)=twhich, setting f t, logically equivalentmax min Fxy max (Fyz (Uxy Uyz )) .xzlatter quantity, feasibility functions concerning P2 play (y) taken accountusing logical connective , P2 unfeasible decisions ignored setscenarios considered. Feasibility functions concerning P1 last move (z) taken account using , P1 consider scenarios achieves forbidden move.Therefore, feasibility functions cannot handled simply using combinationoperator utility functions: need dissociate unfeasible decisionmakers (unfeasibility absolute) unacceptable required one decisionmaker (utility relative), i.e. decision maker wants decision makerdo.general level, example Uxy Uyz soft requirementsknow exactly advance controls variable, logical connectivescannot used anymore. order ignore unfeasible values decision variables elimination, use truncation operator ? introduced Definition 6. order eliminatevariable x scoped function ignoring unfeasibilities indicated feasibilityfunction Fi , simply perform elimination x (Fi ? ) instead . mapsunfeasibilities value , ignored elimination operators (see Definition 6).example above, Uxy Uyz additive gains costs, would computemax min Fxy ? max (Fyz ? (Uxy + Uyz )) .xz4.5 Combining Plausibilities Utilities via Expected Utilitydefine expected utilities, plausibilities utilities must combined. Considersituation utility ui obtained plausibility pi [1, N ],435fiPralet, Verfaillie, & Schiexp1 p . . . p pN = 1p . L = ((p1 , u1 ), . . . , (pN , uN )) classically called lottery (von Neumann & Morgenstern, 1944). speak expected utility, implicitly speakexpected utility EU (L) lottery L.standard way combine plausibilities utilities useP probabilistic expected utility (von Neumann & Morgenstern, 1944) defining EU (L) i[1,N ] (pi ui ):aggregates plausibilities utilities using combination operator pu = projectsaggregated information using elimination operator u = +. However, alternativedefinitions exist:plausibilities possibilities, EU (L) = mini[1,N ] max(1 pi , ui )possibilistic pessimistic expected utility (Dubois & Prade, 1995) (i.e. u = minpu : (p, u) max(1p, u)) EU (L) = maxi[1,N ] min(pi , ui ) possibilisticoptimistic expected utility (Dubois & Prade, 1995) (i.e. u = max pu = min).plausibilities -rankings utilities positive integers (Giang & Shenoy,2000), EU (L) = mini[1,N ] (pi + ui ) (i.e. u = min pu = +).generalize definitions EU (L), start Chu-Halperns work generalized expected utility (Chu & Halpern, 2003a, 2003b).Chu-Halperns structure Generalized expected utility defined expectation domain, tuple (Ep , Eu , Eu0 , u , pu ) that: (1) Ep set plausibility degreesEu set utility degrees; (2) pu : Ep Eu Eu0 combines plausibilitiesutilities satisfies 1p pu u = u; (3) u : Eu0 Eu0 Eu0 commutative associativeoperator aggregate information combined using pu .decision problem additive, i.e. when, plausibility degrees p1 , p2 associated disjoint events, (p1 p p2 ) pu u = (p1 pu u) u (p2 pu u), generic definitionexpected utility lottery is:EU (L) = u (pi pu ui ).i[1,N ]Classical expectation domains also satisfy additional properties u monotonic 0p pu u = 0u , 0u identity u .Restriction Chu-Halperns structure sequential decision makinguse pu : Ep Eu Eu0 u : Eu0 Eu0 Eu0 compute expected utilitiesfirst decision step, need introduce operators 0pu : Ep Eu0 Eu000u : Eu00 Eu00 Eu00 compute expected utilities second decision step. end,decision steps, must define operators pu operators u . orderavoid definition algebraic structure would depend number decisionsteps, take Eu = Eu0 work one operator pu : Ep Eu Eu oneoperator u : Eu Eu Eu .plausibilities, sake future algorithms, restrict Chu-Halpernsexpectation domains (Ep , Eu , Eu , u , pu ) u pu become closed generalizeproperties initial u pu . However, closure sufficient dealsequential decision making, Chu-Halperns expected utility designed one-stepdecision processes only. introduce three additional axioms u pu :436fiThe PFU Frameworkfirst axiom similar standard axiom lotteries (von Neumann & Morgenstern, 1944) defining compound lotteries. states lottery L2 involvesutility u plausibility p2 , one utilities lottery L1 expectedutility L2 plausibility p1 , utility u obtainedplausibility p1 p p2 . gives axiom p1 pu (p2 pu u) = (p1 p p2 ) pu u.require pu distributes u . justify point, assumelottery L = ((p1 , u1 ), (p2 , u2 )) obtained plausibility p. Two different versionscontribution L global utility degree derived: first p pu((p1 pu u1 ) u (p2 pu u2 )), second, uses compound lotteries, ((p pp1 ) pu u1 ) u ((p p p2 ) pu u2 ). want two quantities equalp, p1 , p2 , u1 , u2 . shown equivalent simpler property p pu (u1 uu2 ) = (p pu u1 ) u (p pu u2 ), i.e. pu distributes u .Finally, assume pu right monotonic (i.e. (u1 u u2 ) (p pu u1 up pu u2 )). means agent prefers (strictly not) event ev2another event ev1 , events plausibility degree p,contribution ev2 global expected utility degree must lessercontribution ev1 .axioms define notion expected utility structure.Definition 17. Let (Ep , p , p ) plausibility structure let (Eu , u ) utilitystructure. (Ep , Eu , u , pu ) expected utility structure iff(Eu , u , pu ) semimodule (Ep , p , p ) (cf. Definition 12),u monotonic u pu right monotonic u ((u1 u u2 ) (ppu u1 up pu u2 )).Many structures considered literature instances expected utility structures,shown Proposition 2. results presented remaining article holdusual expected utility structures, generally structures satisfyingaxioms specified Definitions 14, 16, 17.Proposition 2. structures Table 1 expected utility structures.possible define complex expected utility structures existing ones.example, two expected utility structures (Ep , Eu , u , pu ) (Ep0 , Eu0 , 0u , 0pu ),possible build compound expected utility structure (Ep Ep0 , Eu Eu0 , 00u , 00pu ).used deal simultaneously probabilistic possibilistic expected utilitygenerally deal tuples expected utilities.business dinner example flesh definitions, consider followingtoy example, referred sequel. correspond concretereal-life problem, used simplicity. Peter invites John Mary (a divorcedcouple) business dinner order convince invest company. Peterknows John present end dinner, invest $10K. holdsMary $50K. Peter knows John Mary come together (one437fiPralet, Verfaillie, & Schiex123456789EpR+R+[0, 1][0, 1]N {}{t, f }{t, f }{t, f }{t, f }pboolboolboolboolp++maxmaxminpminmin+0p , 1p0, 10, 10, 10, 1, 0f,f,f,f,EuR {}R+[0, 1][0, 1]N {}{t, f }{t, f }{t, f }{t, f }uboolboolboolboolu+minmin+u++maxminminpu0u , 1u0, 00, 1min0, 1max(1p, u) 1, 1+, 0f,t,f, ft, fTable 1: Expected utility structures for: 1. probabilistic expected utility additiveutilities (allows probabilistic expected utility cost gain computed); 2. probabilistic expected utility multiplicative utilities, also calledprobabilistic expected satisfaction (allows probability satisfactionconstraints computed); 3. possibilistic optimistic expected utility; 4. possibilistic pessimistic expected utility; 5. qualitative utility -rankingspositive utilities; 6. boolean optimistic expected utility conjunctive utilities (allows one know whether exists possible worldgoals set goals G satisfied); bool denotes order booleansf bool t; 7. boolean pessimistic expected utility conjunctive utilities(allows one know whether possible worlds, goals set goals Gsatisfied); 8. boolean optimistic expected utility disjunctive utilities (allowsone know whether exists possible world least one goalset goals G satisfied); 9. boolean pessimistic expected utility disjunctiveutilities (allows one know whether possible worlds, least one goalset goals G satisfied).baby-sit child), least one come, case Johncomes Mary occurs probability 0.6. menu, Peter orderfish meat main course, white red wine. However, restaurantserve fish red wine together. John like white wine Marylike meat. menu suit them, leave dinner. John comes, Peterwant leave dinner best friend.Example. dinner problem uses expected utility structure representing probabilisticexpected additive utility (row 1 Table 1): plausibility structure (R+ , +, ), u = +,pu = , utilities additive gains ((Eu , u ) = (R {}, +), conventionu + () = ).4.6 Relation Existing Structurescompare algebraic structures defined existing ones (Friedman & Halpern,1995; Halpern, 2001; Chu & Halpern, 2003a), observe that:438fiThe PFU Frameworkstructures defined less general Friedman-Chu-Halperns, since additional axioms introduced. example, plausibility structures ablemodel belief functions (Shafer, 1976), decomposable, whereaspossible using Friedman-Halperns plausibility measures (however, authorsaware existing schemes decision theory using belief functions). Moreover, one-step decision processes, Chu-Halperns generalized expected utilitygeneral, since assumes pu : Ep Eu Eu0 whereas considerpu : Ep Eu Eu .Conversely, structures defined deal multi-step decision processeswhereas Chu-Halperns generalized expected utility designed one-shot decisionprocesses. Beyond this, axioms, use closed operators, essentially motivated operational reasons. use less expressive structuresake future algorithms (cf. Section 8).set Ep plausibility degrees set Eu utility degrees defined, plausibilities utilities must cardinal. Purely ordinal approaches CP-nets (Boutilier,Brafman, Domshlak, Hoos, & Poole, 2004), which, like Bayesian networks, exploit notion conditional independence express network purely ordinal preference relations,covered.pu takes values Eu , implicitly assumed plausibilities utilitiescommensurable: works Fargier Perny (1999), describing purely ordinal approach,qualitative preferences plausibilities necessarily commensurable,captured either. Also, works Giang Shenoy (2005), satisfy requiredassociativity, commutativity, identity, annihilator, distributivity properties,covered implicitly use pu : Ep Eu Eu0 Eu 6= Eu0 (evenexpected utility EU (L) = (p1 pu u1 ) u (p2 pu u2 ) lottery L = ((p1 , u1 ), (p2 , u2 )) staysEu ).Furthermore, axioms entail distributional plausibilities covered (theplausibility set variable assignments determined plausibilities coveredcomplete assignment): Dempster-Shafer belief functions (Shafer, 1976) Choquet expectedutility (Schmeidler, 1989) encompassed. Finally, one partial order u Eudefined, assumed decision makers share preferences utilities.4.7 Summarysection, introduced expected utility structures, first elementPFU framework. specify plausibilities combined projected (usingp p respectively), utilities combined (using u ), plausibilitiesutilities aggregated define generalized expected utility (using u pu ).structure chosen inspired Friedman-Chu-Halperns plausibility measures generalized expected utility. main differences lie addition axioms dealmulti-step decision processes use extended domains closed operators,motivated operational reasons.439fiPralet, Verfaillie, & Schiex5. Plausibility-Feasibility-Utility Networkssecond element PFU framework network scoped functions Pi , Fi ,Ui (cf. Equation 8) set variables V . network defines compact structured representation state environment, decisions, globalplausibilities, feasibilities, utilities hold them.rest article, plausibility function denotes scoped function Ep (theset plausibility degrees), feasibility function scoped function {t, f } (the setfeasibility degrees), utility function, scoped function Eu (the set utilitydegrees).5.1 Variablesstructured representations, decisions represented using decision variables,directly controlled agent, state environment represented environment variables, directly controlled agent. notion agent usedrestricted cooperative adversarial decision makers (if uncertaintyway decision maker behaves, decisions controls modeledenvironment variables). use VD denote set decision variables denoteset environment variables. VD form partition V .Example. dinner problem modeled using six variables: bpJ bpM (valuef ), representing Johns Marys presence beginning, epJ epM (valuef ), representing presence end, mc (value f ish meat), representing maincourse choice, w (value white red), representing wine choice. Thus,VD = {mc, w} = {bpJ , bpM , epJ , epM }.5.2 Decomposing Plausibilities Feasibilities Local FunctionsUsing combined local functions represent global one raises considerations:local functions obtained global one, conversely,local functions directly used, implicit assumptions global functionmade. show questions boil notion conditionalindependence. following definitions propositions, (Ep , p , p ) correspondsplausibility structure.5.2.1 Preliminaries: Generalization Bayesian Networks ResultsAssume want express global plausibility distribution PS (cf. Definition 15)combination local plausibility functions Pi . work Bayesian networks (Pearl,1988) shown, factorization joint distribution essentially related notion conditional independence. introduce conditional independence, first defineconditional plausibility distributions.Definition 18. plausibility distribution PS said conditionable iffexists set functions denoted PS1 | S2 (one function pair S1 , S2 disjoint subsetsS) S1 , S2 , S3 disjoint subsets S,440fiThe PFU Framework(a) assignments S2 PS2 (A) 6= 0p , PS1 | S2 (A) plausibility distribution S1 ,3(b) PS1 | = PS1 ,(c) p S1 PS1 ,S2 | S3 = PS2 | S3 ,(d) PS1 ,S2 | S3 = PS1 | S2 ,S3 p PS2 | S3 ,(e) (PS1 ,S2 ,S3 = PS1 | S3 p PS2 | S3 p PS3 ) (PS1 ,S2 | S3 = PS1 | S3 p PS2 | S3 ).PS1 | S2 called conditional plausibility distribution S1 given S2 .Condition (a) means conditional plausibility distributions must normalized.Condition (b) means information given empty set variableschange plausibilities states environment. Condition (c) meansconditional plausibility distributions consistent marginalization point view.Condition (d) analog so-called chain rule probabilities. Condition (e)kind weak division axiom.4Proposition 3 gives simple conditions plausibility structure, satisfied usualframeworks, suffice plausibility distributions conditionable.Definition 19. plausibility structure (Ep , p , p ) called conditionable plausibilitystructure iff satisfies axioms:p1 p p2 p2 6= 0p , max{p Ep | p1 = p p p2 } exists p 1p ,p1 p p2 , exists unique p Ep p1 = p p p2 ,p1 p p2 , exists unique p Ep p2 = p p p1 .Proposition 3. (Ep , p , p ) conditionable plausibility structure, plausibility distributions conditionable: suffices define PS1 | S2 PS1 | S2 (A) = max{pEp | PS1 ,S2 (A) = p p PS2 (A)} dom(S1 S2 ) satisfying PS2 (A) 6= 0p .systematic definition conditional plausibility distributions given Proposition 3fits usual definitions conditional distributions, are, probabilities,PS1 | S2 (A) = PS1 ,S2 (A)/PS2 (A), -rankings, PS1 | S2 (A) = PS1 ,S2 (A) PS2 (A),possibility degrees combined using min, PS1 | S2 (A) = PS1 ,S2 (A) PS1 ,S2 (A) <PS2 (A), 1 otherwise. following, every conditioning statement PS1 | S2 conditionable plausibility structures refer canonical notion conditioning givenProposition 3. Conditional independence defined.3. avoid specifying properties PS1 | S2 hold assignments S1 S2 satisfying PS2 (A) 6=0p , use expressions PS1 | S2 = denote dom(S1 S2 ), (PS2 (A) 6= 0p )(PS1 | S2 (A) = (A)).4. Compared Friedman Halperns conditional plausibility measures (Friedman & Halpern, 1995;Halpern, 2001), (c) analog axiom (Alg1), (d) analog axiom (Alg2), (e) analogaxiom (Alg4), axiom (Alg3) corresponds distributivity p p .441fiPralet, Verfaillie, & SchiexDefinition 20. Let (Ep , p , p ) conditionable plausibility structure. Let PSplausibility distribution S1 , S2 , S3 disjoint subsets S. S1 saidconditionally independent S2 given S3 , denoted I(S1 , S2 | S3 ), iff PS1 ,S2 | S3 = PS1 | S3 pPS2 | S3 .means S1 conditionally independent S2 given S3 , iff problemsplit one part depending S1 S3 , another part depending S2 S3 .5definition satisfies usual properties conditional independence, Proposition 4shows.Proposition 4. I(., . | .) satisfies semigraphoid axioms:1. symmetry: I(S1 , S2 | S3 ) I(S2 , S1 | S3 ),2. decomposition: I(S1 , S2 S3 | S4 ) I(S1 , S2 | S4 ),3. weak union: I(S1 , S2 S3 | S4 ) I(S1 , S2 | S3 S4 ),4. contraction: (I(S1 , S2 | S4 ) I(S1 , S3 | S2 S4 )) I(S1 , S2 S3 | S4 ).Proposition 4 makes possible use Bayesian network techniques express information compact way. Bayesian networks, DAG variables used representconditional independences variables (Pearl, 1988). cases, imageprocessing statistical physics, natural express conditional independencessets variables. probabilities used, situations modeled using chain graphs (Frydenberg, 1990). chain graph, DAG defined DAGvariables, DAG sets variables, called components. Conditional probability distributions Px | paG (x) variables replaced conditional probability distributions Pc | paG (c)components, Pc | paG (c) expressed factored form c1 c2 . . .ckc . Markovrandom fields (Chellappa & Jain, 1993) correspond case Quniquecomponent equal V , factored form PV looks like 1/Z jJ eHj(Gibbs distribution).formally introduce DAGs sets variables, called DAGs components,use factor plausibility distributions.Definition 21. DAG G said DAG components set variables iffvertices G form partition S. C(G) denotes set components G.c C(G), paG (c) denotes set variables included parents c G, ndG (c)denotes set variables included non-descendant components c G.Definition 22. Let (Ep , p , p ) conditionable plausibility structure. Let PSplausibility distribution let G DAG components S. G saidcompatible PS iff I(c, ndG (c) paG (c) | paG (c)) c C(G) (c conditionallyindependent non-descendants given parents).5. Definition 20 differs Halperns, S1 conditionally independent (CI) S2 given S3 iffPS1 | S2 ,S3 = PS1 | S3 PS2 | S1 ,S3 = PS2 | S3 . Halpern (2001) called definition adopt noninteractivity (NI) showed NI weaker CI. implies NI satisfied oftenmay lead factorizations. Halpern gave simple axiom (axiom (Alg4)) CINI equivalent. Though axiom holds many usual frameworks, hold possibilitydegrees combined using min, case covered PFU algebraic structure.442fiThe PFU FrameworkTheorem 1. (Conditional independence factorization) Let (Ep , p , p ) conditionable plausibility structure let G DAG components S.(a) G compatible plausibility distribution PS S, PS = p cC(G) Pc | paG (c) .(b) If, c C(G), function c,paG (c) c,paG (c) (A) plausibilitydistribution c assignments paG (c), = p cC(G) c,paG (c)plausibility distribution G compatible.Theorem 1 links conditional independence factorization. Theorem 1(a) generalization usual result Bayesian networks (Pearl, 1988) says DAGvariablescompatible probability distribution PS , PS factoredQPS = xS Px | paG (x) . Theorem 1(b) generalization standard result Bayesiannetworks (Pearl, 1988) says that, given DAG G variablesQ S, conditionalprobabilities Px | paG (x) defined variable x S, xS Px | paG (x) definesprobability distribution G compatible. results generalizationssince hold arbitrary plausibility distributions (and probability distributionsonly). Results similar spirit provided Halpern (2001), gives conditionsplausibility measure represented Bayesian network.Theorem 1(a) entails that, order factor global plausibility distribution PS ,suffices define DAG components compatible it, i.e. express conditionalindependences. define DAG, following systematic procedure used.initial DAG components empty DAG G. C(G) = {c1 , . . . , ck1 }partition S, do:1. Let Sk = c1 . . . ck1 ; choose subset ck set Sk variables alreadyconsidered.2. Add ck component G find minimal subset pak Sk I(ck , Skpak | pak ). Add edges directed components containing least one variablepak ck , paG (ck ) = (c{c1 ,...,ck1 })/(cpak 6=) c.resulting DAG components guaranteed compatible PS , implies, using Theorem 1(a), local functions Pi representing PS simply definedfunctions set {Pc | paG (c) , c C(G)}. practice, reasonable notioncauses effects, networks smaller somehow easier buildobtained using following two heuristics order choose ck stepprocedure above:(R1) Consider causes effects: dinner problem, suggests putting epJck causes bpJ w Sk .(R2) Gather component variables correlated even variables Skassigned : bpJ bpM correlated (R1) apply. Indeed, cannotsay bpJ causal influence bpM , bpM causal influence bpJ ,since Mary John chooses first (s)he baby-sits specified.even assume bpJ bpM correlated via unmodeled common cause,443fiPralet, Verfaillie, & Schiexcoin toss determines baby-sitter. Hence, bpJ bpM putcomponent c = {bpJ , bpM }.6say (R1) (R2) build DAG respecting causality. must seenpossible mechanisms help identifying conditional independences using notionscauses effects.previous results extending Bayesian networks results plausibility distributionsalso apply feasibilities. Indeed, feasibility structure Sf = ({t, f }, , ) particularcase conditionable plausibility structure, since satisfies axioms Definition 19.may therefore speak conditional feasibility distribution. set decisionvariables, construction DAG compatible feasibility distribution FS leadsfactorization FS = cC(G) Fc | paG (c) .5.2.2 Taking Differenty Types Variables Accountmaterial defined previous subsection enables us factor one plausibility distribution PVE defined set environment variables one feasibility distributionFVD defined set VD decision variables. However, dealing one plausibilitydistribution one feasibility distribution VD sufficient.Indeed, plausibilities, decision variables influence environment (for example,health state patient depends treatment chosen doctor). Ratherexpressing one plausibility distribution , want express family plausibility distributions , one assignment VD . make clear, definecontrolled plausibility distributions.Definition 23. plausibility distribution controlled VD (or controlledplausibility distribution), denoted PVE || VD , function dom(VE VD ) Ep ,assignments AD VD , PVE || VD (AD ) plausibility distribution .feasibilities, goes way around: values environment variablesconstrain possible decisions (for example, unmanned aerial vehicle flyingcannot take off). Thus, want express family feasibility distributions VD ,one assignment . words, want express controlled feasibilitydistribution FVD || .order directly reuse Theorem 1 controlled distributions, introduce notioncompletion controlled distribution. allows us extend distributionfull set variables V assigning plausibility (resp. feasibility) degreeevery assignment VD (resp. ), work one plausibility (resp. feasibility)distribution.6. Components {bpJ , bpM } could broken assuming example bpM causally influencesbpJ , i.e. Mary chooses baby-sits first. (and prefer to) keep component{bpJ , bpM } because, general, breaking components increase scopes functions involved.example, assume want model plausibilities variables representing colors pixelsN N image, color pixel probabilistically depends colors 4 neighborsonly. component approach, results Markov random fields (Chellappa & Jain, 1993) showlocal functions obtained scopes size 5 only, whereas component-breaking mechanism,size largest scope linear N .444fiThe PFU FrameworkProposition 5. Let (Ep , p , p ) conditionable plausibility structure. Then,n N , exists unique p0 p i{1,...,n} p0 = 1p .Definition 24. Let (Ep , p , p ) conditionable plausibility structure let PVE || VDcontrolled plausibility distribution. Then, completion PVE || VD function denotedPVE ,VD , defined PVE ,VD = PVE || VD p p0 , p0 unique element Epp i[1,|dom(VD )|] p0 = 1p (the cardinality set denoted ||).words, PVE ,VD defined PVE || VD assigning plausibility degreep0 assignments VD . case probability theory, corresponds sayingassignments VD equiprobable. definition completion controlledplausibility distribution could made flexible: instead defining uniform plausibility distribution VD , could define plausibility distribution assignmentVD 0p plausibility degree. arbitrarily choose uniform distribution,goal introduce prior plausibilities decision variables, sakefactorization.Proposition 6. Let PVE ,VD completion controlled plausibility distribution PVE || VD .Then, PVE ,VD plausibility distribution VD PVE | VD = PVE || VD .result, use PVE | VD denote PVE || VD (and equivalent). Similarly,possible complete controlled feasibility distribution FVD || .5.2.3 First FactorizationProposition 7 below, entailed Theorem 1(a), shows obtain first factorizationPVE | VD FVD | .Definition 25. DAG G typed DAG components VD iff verticesG form partition VD element partition subset eitherVD . vertex G called component. set components contained(environment components) denoted CE (G) set components contained VD(decision components) denoted CD (G).Proposition 7. Let G typed DAG components VD . Let Gp partialgraph G induced arcs G incident environment components. Let Gfpartial graph G induced arcs G incident decision components. Gpcompatible completion PVE || VD (cf. Definition 22) Gf compatiblecompletion FVD || ,PVE | VD =p Pc | paG (c)cCE (G)FVD | =cCD (G)Fc | paG (c) .allows us specify local Pi Fi functions: suffices express Pc | paG (c)Fc | paG (c) express PVE | VD FVD | compact way. fact, coulddefined two DAGs, one factorization PVE | VD factorizationFVD | , two DAGs actually always merged soon make(undemanding) assumption impossible, given x VD , xinfluences constrains possible decision values x. assumption ensuresunion two DAGs create cycles. use one DAG simplicity.445fiPralet, Verfaillie, & SchiexExample. Consider dinner problem illustrate first factorization step. One wayobtain G use causality-based reasoning described Theorem 1. startempty DAG. epJ epM effects bpJ , bpM , w, mc,considered first component c1 . bpJ chosen variable add c1 ,cannot say bpJ necessarily effect another variable. previously explained,bpJ cause bpM , effect bpM , bpJ may correlated bpM viaunmodeled cause. result, get c1 = {bpJ , bpM } first component. Obviously, c1parents DAG first added component.Then, epJ epM effects w mc, consider epJ epMsecond component c2 . Since w necessarily effect mc, add w c2 .dinner problem specifies ordering fish red wine simultaneously feasible,know whether wine chosen main course, i.e. wcause effect mc. result, take c2 = {mc, w}. menu choiceindependent present beginning, c2 parent temporary DAG.epJ direct effect bpJ w (John leaves dinner white winechosen), add epJ c3 . Moreover, epJ correlated epM c1 c2 ={bpJ , bpM , mc, w} assigned. Therefore, take c3 = {epJ }. Given epJ dependsbpJ w, c3 gets {bpJ , bpM } {mc, w} parents. Finally, c4 = {epM }, epMdepends bpM mc (Mary leaves meat chosen) independent epJ given bpMmc, I({epM }, {epJ , bpJ , w} | {bpM , mc}). entails {epM } addedDAG {bpJ , bpM } {mc, w} parents. Therefore, get CD (G) = {{mc, w}}set decision components CE (G) = {{bpJ , bpM }, {epJ }, {epM }} setenvironment components. DAG components shown Figure 1a.Using Proposition 7, know joint probability distribution factors PVE | VD =PbpJ ,bpM PepJ | bpJ ,bpM ,mc,w PepM | bpJ ,bpM ,mc,w joint feasibility distributionfactored FVD | = Fmc,w .5.2.4 Factorization StepsProposition 7 provides us decomposition PVE | VD FVD | based conditional independence relation I(., . | .) Definition 20. may possible performfactorization steps factoring Pc | paG (c) set local plausibility functions Pifactoring Fc | paG (c) set local feasibility functions Fi .cases, expressing factors Pc | paG (c) Fc | paG (c) quite natural. example, p = , variables environment component c = {xi,j | i, j [1, n]}without parents represent pixel colors, want model Pc twoadjacent pixels different colors, natural define set binary difference constraints xi,j ,xk,lfactorPP=ccx,xi[1,n1]j[1,n]i,ji+1,ji[1,n] j[1,n1] xi,j ,xi,j+1 . decomposition cannot obtained basedconditional independence relation I(., . | .) Definition 20.settings, Markov random fields (Chellappa & Jain, 1993), systematictechniques exist obtain factorizations. Bayesian network communityalso offers systematic techniques: hybrid networks (Dechter & Larkin, 2001),extract deterministic information contained conditional probabilitydistributions. precisely, conditional probability distribution Px | paG (x)446fiThe PFU Frameworkexpressed Px | paG (x) = Px | paG (x) , 0-1 function defined0 Px | paG (x) (A) = 0(A) =. factorization Px | paG (x) Px | paG (x)1 otherwisecomputationally relevant constraint propagation techniques 0-1 functionsused solve hybrid networks.may use another weaker definition conditional independence: valuation-basedsystems (Shenoy, 1994), S1 S2 said conditionally independent given S3regard function S1 ,S2 ,S3 function factors two scoped functionsscopes S1 S3 S2 S3 . definition used first factorizationstep destroys normalization conditions may usefulcomputational point view.additional factorization steps interest decreasing sizescopes functions involved adding redundant information problemcomputationally useful.every environment component c, Pi F act(c) stands Pi factorPc | paG (c) , second factorization gives usPc | paG (c) =pPi .Pi F act(c)p c Pc | paG (c) = 1p , Pi functions F act(c) satisfy normalization conditionp c (p Pi F act(c) Pi ) = 1p . scopes sc(Pi ) contained sc(Pc | paG (c) ) = c paG (c).every decision component c, Fi F act(c) stands Fi factor Fc | paG (c) ,second factorization gives usFc | paG (c) =Fi F act(c)Fi .Given c Fc | paG (c) = t, Fi functions F act(c) satisfy normalization conditionc Fi F act(c) Fi = t. Moreover, sc(Fi ) c paG (c).factorizations, decrease scopes functions involved, couldalso exploited. Indeed, scoped function Pi Fi internal localstructure, instance Pi noisy-OR gate (Pearl, 1988) Bayesian network,presence context-specific independence (Boutilier, Friedman, Goldszmidt, & Koller,1996). internal local structures made explicit representing functionstools Algebraic Decision Diagrams (Bahar, Frohm, Gaona, Hachtel, Macii, Pardo,& Somenzi, 1993). rest article, make assumption wayscoped function represented.Example. PbpJ ,bpM expressed terms first plausibility function P1 specifying probability John Mary present beginning. P1 definedP1 ((bpJ , t).(bpM , f )) = 0.6, P1 ((bpJ , f ).(bpM , t)) = 0.4, P1 ((bpJ , t).(bpM , t)) =P1 ((bpJ , f ).(bpM , f )) = 0. also add redundant deterministic information second plausibility function P2 defined constraint bpJ 6= bpM (P2 (A) = 1 constraintsatisfied, 0 otherwise). get PbpJ ,bpM = P1 p P2 F act({bpJ , bpM }) = {P1 , P2 }.447fiPralet, Verfaillie, & SchiexPepJ | bpJ ,bpM ,mc,w specified combination two plausibility functions P3P4 . P3 expresses John absent beginning, absent end: P3hard constraint (bpJ = f ) (epJ = f ) (P3 (A) = 1 constraint satisfied, 0 otherwise).Then, P4 : (bpJ = t) ((epJ = t) (w 6= white)) hard constraint specifyingJohn leaves iff white wine chosen. Hence, PepJ | bpJ ,bpM ,mc,w = P3 p P4F act({epJ }) = {P3 , P4 }. Similarly, PepM | bpJ ,bpM ,mc,w = P5 p P6 , P5 , P6 definedconstraints, F act({epM }) = {P5 , P6 }.feasibilities, Fmc,w specified feasibility function F1 expressing ordering fish red wine allowed: F1 : ((mc = f ish)(w = red)) F act({mc, w})= {F1 }. association local functions components appears Figure 1a.5.3 Local UtilitiesLocal utilities defined states environment (as utilityhealth state patient), decisions (as utility decision buyingcar not), states environment decisions (as utilityresult horse race bet race).7order specify local utilities, one standard approach, used CSPs influencediagrams, directly define set U local utility functions, modeling preferenceshard requirements, decision environment variables. set implicitly definesglobal utility UV = uUi U Ui variables. factored form obtainedglobal joint utility, one may rely, u = +, work Fishburn (1982)Bacchus-Grove (1995), introduced notion conditional independence utilities.normalization condition imposed local utilities.Example. dinner problem, three local utility functions defined. binaryutility function U1 expresses Peter want John leave dinner: U1hard constraint (bpJ = t) (epJ = t) (U1 (A) = 0 constraint satisfied,otherwise). Two unary utility functions U2 U3 epJ epM respectively expressgains expected presences end: U2 ((epJ , t)) = 10 U2 ((epJ , f )) = 0 (Johninvests $10K present end), U3 ((epM , t)) = 50 U3 ((epM , f )) = 0(Mary invests $50K present end). U2 U3 viewed soft constraints.local functions represented graphical model Figure 1b.5.4 Formal Definition PFU Networksformally define Plausibility-Feasibility-Utility networks. definition justified previous construction process, holds even plausibility structureconditionable.7. influence diagrams, special nodes called value nodes introduced represent outcomedecisions, one utility function associated value nodes (the utility outcome).PFU framework, directly represent utility functions scoped functions holdparents value nodes. explicitly express utility functions scoped functions,plausibility feasibility functions. words, utility functions directly utilities outcomedecision environment variables assignments.448fiThe PFU FrameworkP4mc, wbpJ , bpMP1 , P 2F1wF1epJepMP3 , P 4P5 , P 6(a)mcbpJP3environmentP2 U1P1bpMP5decisionepJU2plausibilityfunctionepMP6feasibilityfunctionU3utilityfunction(b)Figure 1: (a) DAG components (b) Network scoped functions.Definition 26. Plausibility-Feasibility-Utility network expected utility structuretuple N = (V, G, P, F, U ) following conditions hold:V = {x1 , x2 , . . .} finite set finite domain variables. V partitioned VD(decision variables) (environment variables);G typed DAG components VD (cf. Definition 25);P = {P1 , P2 , . . .} finite set plausibility functions. Pi P associated unique component c CE (G) sc(Pi ) c paG (c). setPi P associated component c CE (G) denoted F act(c) must satisfyp (p Pi F act(c) Pi ) = 1p ;cF = {F1 , F2 , . . .} finite set feasibility functions. function Fi associatedunique component c CD (G) sc(Fi ) c paG (c). setFi F associatedcomponent c CD (G) denoted F act(c) must satisfyFi F act(c) Fi = t;cU = {U1 , U2 , . . .} finite set utility functions.5.5 PFU Networks Global Functionsseen obtain PFU network expressing global controlled plausibilitydistribution PVE || VD , global controlled feasibility distribution FVD || , global utilityUV . Conversely, let N = (V, G, P, F, U ) PFU network, i.e. set variables, typedDAG components, sets scoped functions.global function = p Pi P Pi controlled plausibility distribution givenVD . Moreover, Theorem 1(b), plausibility structure conditionableGp partial DAG G induced arcs incident environment components,Gp compatible completion ;global function = Fi F Fi controlled feasibility distribution VD given. Moreover, Theorem 1(b), Gf partial DAG G induced arcsG incident decision components, Gf compatible completion ;449fiPralet, Verfaillie, & Schiex= uUi U Ui necessarily global utility.therefore denote PVE || VD , FVD || , UV .5.6 Back Existing FrameworksLet us consider formalisms described Section 3 again.CSP (hard soft) easily represented PFU network N = (V, G, , , U ):variables V decision variables, G reduced single decision componentcontaining variables, constraints represented utility functions. Usingfeasibility functions represent constraints, would impossible represent inconsistent networks normalization conditions feasibilities. SATmodeled similarly; difference constraints replaced clauses.PFU network used represent local functions quantifiedboolean formula quantified CSP. differences CSPs SAT appearconsider queries network (see Section 6).Bayesian network modeled N = (V, G, P, , ): variables Venvironment variables, G DAG BN, P = {Px | paG (x) , x V }.feasibility utility function. chain graph also modeled N = (V, G, P, , ),G DAG components chain graph P set factorsPc | paG (c) .stochastic CSP represented PFU network N = (V, G, P, , U ), Vpartitioned VD , set decision variables, , set stochasticvariables, G DAG depends relations stochastic variables,P set probability distributions stochastic variables, U setconstraints.influence diagram modeled N = (V, G, P, , U ) VD containsdecision variables, contains chance variables, G DAG influencediagram without utility nodes arcs random variables (i.e.keep so-called influence arcs), P = {Px | paG (x) , x }.feasibilities, one utility function Ui defined per utility variable u, scopeUi paG (u). represent valuation networks, set F feasibility functionsadded. Note business dinner example could modeled using standard influence diagram, since influence diagrams cannot model feasibilities(suitable extensions exist however, Shenoy, 2000).finite horizon probabilistic MDP modeled N = (V, G, P, F, U ).time-steps, VD = {dt , [1, ]}{s1 } = {st , [2, ]};8 G DAGcomponents (a) component contains one variable, (b) unique parentdecision component {dt } {st }, (c) parents environment component{st+1 } {st } {dt }; P = {Pst+1 |st ,dt , [1, 1]}, F = {Fdt | st , [1, ]},U = {Rst ,dt , [1, ]}. Modeling finite horizon possibilistic MDP similar.8. plausibility distribution initial state s1 , s1 viewed environmentvariable. corresponds special case decision variables model problem parameters.450fiThe PFU Framework5.7 Summarysection, introduced second element PFU framework: networkvariables linked local plausibility, feasibility, utility functions, DAG capturingnormalization conditions. factorization global plausibilities, feasibilities, utilitiesscoped functions linked conditional independence.6. Queries PFU Networkquery correspond reasoning task information expressed PFU network.decision variables involved PFU network considered, answering query mayprovide decision rules. Examples informal queries dinner problem1. best menu choice Peter know present beginning?2. best menu choice Peter knows present beginning?3. maximize expected investment restaurant chooses maincourse first Peter pessimistic choice, presentbeginning observed, last Peter chooses wine?Dissociating PFU networks queries consistent trend influence diagram community relax so-called information links, Unconstrained InfluenceDiagrams (Jensen & Vomlelova, 2002) Limited Memory Influence Diagrams (Lauritzen& Nilsson, 2001): explains intuition queries change local relationsvariables.section, define simple class queries PFU networks. assumesequence decisions must performed, order decisionsobservations made known. also make no-forgetting assumption, is,making decision, agent aware previous decisions observations.on, set utility degrees Eu assumed totally ordered. total orderassumption, holds standard frameworks, implies alwaysexists optimal decision rule. See Subsection 6.7 discussion extendresults partial order.Two definitions answer query given, first based decision trees,second operational. equivalence two definitionsestablished.6.1 Query Definitionorder formulate reasoning tasks PFU network, use sequence Sov operatorvariable(s) pairs. sequence captures different aspects query:Partial observabilities: Sov specifies order decisions made environment variables observed. x appears left VD (for exampleSov = . . . (u , {x}) . . . (max, {y}) . . .), means value x known (observed) value chosen. Conversely, Sov = . . . (max, {y}) . . . (u , {x}) . . .x observed choosing y.451fiPralet, Verfaillie, & SchiexOptimistic/pessimistic attitude concerning decision makers: (max, {y}) insertedelimination sequence decision maker optimistic behavioragent controlling decision variable (i.e. agent cooperative),(min, {y}) one pessimistic (i.e. agent controlling adversary).operator used environment variables always u , model expectedutilities sought.9Parameters decision making problem: set variables involvedSov kind parameters. absence indicates want obtain optimalexpected utilities and/or optimal policies assignment S. usefulorder evaluate several scenarios simultaneously.Example. sequence corresponding informal query: maximizeexpected investment restaurant chooses main course first Peter pessimisticchoice, present beginning dinner observed, lastPeter chooses wine knowing present end?Sov = (min, {mc}).(u , {bpJ , bpM }).(max, {w}).(u , {epJ , epM }).models fact that: (1) Peter pessimistic main course (min mc),chosen without observing variable (no variable left mc Sov); (2) Petermakes best choice wine (max w) main course chosenknowing present beginning (w appears right mc, bpJ , bpMSov), knowing present end (w appears left epJ , epM ).Specifically, bpJ bpM partially observable, whereas epJ epM unobservable.query becomes Peter observes present beginningdinner chooses wine knowing present end?,sequence use Sov = (u , {bpJ , bpM }).(max, {w}).(u , {epJ , epM }). case,variable mc appear sequence anymore, means mc parameteranswer value parameter sought.Definition 27. query PFU network pair Q = (N , Sov) N PFUnetwork Sov = (op1 , S1 )(op2 , S2 ) (opk , Sk ) sequence operator-set variablespairs(1) Si disjoint;(2) either Si VD opi = min max, Si opi = u ;(3) variables involved Si , called free variables, decision variables;(4) variables x, different types (one decision variable,environment variable), directed path component containsx component contains DAG PFU network N , xappear right Sov, i.e. either x appears left y, x freevariable.9. decision made nature plausibility distribution decision,decision viewed environment variable.452fiThe PFU FrameworkCondition (1) ensures variable eliminated once. Condition (2) meansoptimal decisions sought decision variables (either maximized decisionmaker controls decision variable cooperative, minimized adversarial),whereas expected utilities sought environment variables. Condition (3) meansvariables eliminated Sov act problem parameters vieweddecision variables. Condition (4) means x different types xancestor y, x assigned y. ensures causality respected variables different types: example, (N , (u , {bpJ , bpM , epJ , epM }).(max, {mc, w})),violates condition (4), violates causality since menu cannot chosen knowingpresent end.Variables appearing Sov called quantified variables, analogy quantifiedboolean formulas. set free variables denoted Vf r . Notice definitionqueries prevent environment variable quantified min max,may u = min u = max. Note also straightforwardevery PFU network N , exists least one query N without free variables.[1, k], defineset l(Si ) variables appearing Vf r left Si Sov l(Si ) =Vf r (j[1,i1] Sj );set r(Si ) variables appearing right Si Sov r(Si ) = j[i+1,k] Sj .6.2 Semantic Answer Querysubsection, assume plausibility structure conditionable (cf. Definition 19). controlled plausibility distribution PVE || VD = p Pi P Pi completed (cf. Definition 24) give plausibility distribution PVE ,VD VD . Similarly,controlled feasibility distribution FVD || = Fi F Fi completed give feasibility distribution FVE ,VD VD . also use global utility UV = uUi U Uidefined PFU network.Imagine want answer query Q = (N , Sov), N networkdinner problem Sov = (min, {mc}).(u , {bpJ , bpM }).(max, {w}).(u , {epJ , epM }).answer query, use decision tree. First, restaurant choosesworst possible main course, taking account feasibility distribution mc. Here,Fmc ((mc, meat)) = Fmc,w ((mc, meat).(w, white)) Fmc,w ((mc, meat).(w, red)) = =t. Similarly, Fmc ((mc, f ish)) = t. choices feasible. Then, A1 denotesassignment mc, uncertainty present beginning given maincourse choice described probability distribution PbpJ ,bpM | mc (A1 ). possibleassignment A2 {bpJ , bpM }, i.e. A2 PbpJ ,bpM | mc (A1 .A2 ) 6= 0p , Peterchooses best wine taking account feasibility Fw | mc,bpJ ,bpM (A1 .A2 ):restaurant chooses meat, Peter chooses optimal value red white,restaurant chooses fish, Peter choose white wine only. Then, feasibleassignment A3 w, uncertainty regarding presence John Mary enddinner given PepJ ,epM | bpJ ,bpM ,mc,w (A1 .A2 .A3 ).Note conditional probabilities used decision tree directlydefined network. must computed global distributions.computation challenge large problems.453fiPralet, Verfaillie, & Schiexutility UV (A1 .A2 .A3 .A4 ) associated possible complete assignmentA1 .A2 .A3 .A4 variables. possible assignment A1 .A2 .A3 {bpJ , bpM , mc, w},last stage, i.e. one epJ epM assigned,P seen lottery (vonNeumann & Morgenstern, 1944) whose expected utility A4 dom({epJ ,epM }) p(A4 )u(A4 ),p(A4 ) = PepJ ,epM | bpJ ,bpM ,mc,w (A1 .A2 .A3 .A4 ) u(A4 ) = UV (A1 .A2 .A3 .A4 ).expected utility becomes reward scenario {bpM , bpJ , mc, w} describedA1 .A2 .A3 . provides us criterion choosing optimal value w. stepbpJ bpM assigned seen lottery, provides uscriterion choosing worst value mc. computation associated previouslydescribed process is:minA1 dom(mc),Fmc (A1 )=tXPbpJ ,bpM | mc (A1 .A2 )(A2 dom({bpJ ,bpM }),PbpJ ,bpM(maxX| mc (A1 .A2 )6=0A3 dom(w),Fw | mc,bpJ ,bpM (A1 .A2 .A3 )=t(PepJ ,epM | bpJ ,bpM ,mc,w (A1 .A2 .A3 .A4 )A4 dom({epJ , epM })PepJ ,epM | bpJ ,bpM ,mc,w (A1 .A2 .A3 .A4 ) 6= 0UV (A1 .A2 .A3 .A4 )))).Decision rules decision variables (argmin argmax) recordedcomputation. formulation represents decision process decision treeinternal level corresponds variable assignments. Arcs associatedassignment set decision variables weighted feasibility decision givenprevious assignments. Arcs associated assignment environment variablesweighted plausibility degree assignment given previous assignments. Leafnodes correspond utilities complete assignments, node collects valueschildren compute value.6.2.1 Formalization Decision Tree Procedureorder formalize decision tree procedure, technical results first introducedProposition 8. results definitions preceding skipped firstreading.Definition 28. Let PS1 | S2 conditional plausibility distribution S1 given S2 letdom(S2 ). function PS1 | S2 (A) said well-defined iff PS2 (A) 6= 0p . Similarly,FS1 | S2 conditional feasibility distribution S1 given S2 , then, dom(S2 ),FS1 | S2 (A) said well-defined iff FS2 (A) = t.Next, conditioning defined directly controlled plausibility distributionsdom(VD ), PVE || VD (A) plausibility distribution :Definition 29. Assume plausibility structure used conditionable. Let PVE || VDcontrolled plausibility distribution S, 0 two disjoint subsets . defineconditional controlled plausibility distributions by: dom(S 0 VD )PS 0 || VD (A) 6= 0p , PS | 0 || VD (A) = max{p Ep | PS,S 0 || VD (A) = p p PS 0 || VD (A)},canonical definition conditioning given Proposition 3. Given controlled feasi454fiThe PFU Frameworkbility distribution FVD || , definition conditional controlled feasibility distributionsFS | 0 || S, 0 disjoint subsets VD similar.Proposition 8. Assume plausibility structure used conditionable. Let Q =(N , Sov) query Sov = (op1 , S1 ) (op2 , S2 ) (opk , Sk ). Let Vf r denote setfree variables Q.(1) Si PSi | l(Si ) (A) well-defined, exists least one A0 dom(Si )satisfying PSi | l(Si ) (A.A0 ) 6= 0p .(2) Si VD FSi | l(Si ) (A) well-defined, exists least one A0 dom(Si )satisfying FSi | l(Si ) (A.A0 ) = t.(3) 6= Si leftmost set environment variables appearing Sov, then,dom(l(Si )), PSi | l(Si ) (A) well-defined.(4) i, j [1, k], < j, Si , Sj , r(Si ) l(Sj ) VD (Sj first set environment variables appearing right Si Sov), (A, A0 ) dom(l(Si ))dom(Si ),PSi | l(Si ) (A) well-defined, PSi | l(Si ) (A.A0 ) 6= 0p , then, A00 extending A.A0l(Sj ), PSj | l(Sj ) (A00 ) well-defined.(5) i, j [1, k], < j, Si VD , Sj VD , r(Si ) l(Sj ) (Sj first setdecision variables appearing right Si Sov), (A, A0 ) dom(l(Si ))dom(Si ),FSi | l(Si ) (A) well-defined, FSi | l(Si ) (A.A0 ) = t, then, A00 extending A.A0l(Sj ), FSj | l(Sj ) (A00 ) well-defined.(6) [1, k] Si , PSi | l(Si ) = PSi | l(Si )VE ||VD .(7) [1, k] Si VD , FSi | l(Si ) = FSi | l(Si )VD ||VE .technical results Proposition 8 ensure that, following semantic answerquery (see Definition 30),quantities PS | l(S) (A.A0 ) FS | l(S) (A.A0 ) used defined (thanks items 35 Proposition 8);eliminations restricted domains defined restricted domainsused never empty (items 1 2 Proposition 8);conditional distributions used coincide conditioning defined directlycontrolled plausibility feasibility distributions PVE || VD FVD || (items 67 Proposition 8). useful guarantees PS | l(S) (A.A0 )FS | l(S) (A.A0 ), priori require notion completion written,actually independent notion completion, arbitrarily addedbasic information expressed PFU network. use PS | l(S) FS | l(S) insteadconditional controlled distributions PS | l(S)VE || VD FS | l(S)VD || notationconvenience explicitly represent PS | l(S)VE || VD FS | l(S)VD ||depend assignment VD l(S) l(S) respectively.455fiPralet, Verfaillie, & SchiexDefinition 30. semantic answer Sem-Ans(Q) query Q = (N , Sov) functionset Vf r free variables Q defined by10FVf r (A) = fSem-Ans(Q)(A) =Qs(N , Sov, A) otherwise,Qs inductively defined by:(1)Qs(N , , A) = UV (A)(2)Qs(N , (op, S) . Sov, A) =minQs (N , Sov, A.A0 )0dom(S)FS|l(S) (A.A0 ) =Qs (N , Sov, A.A0 )maxA0 dom(S)FS|l(S) (A.A0 ) =uA0 dom(S)PS|l(S) (A.A0 ) 6= 0p(S VD ) (op = min),(S VD ) (op = max),PS|l(S) (A.A0 ) pu Qs (N , Sov, A.A0 )(S ).words, step involving decision variables (first two cases) correspondsoptimization step among feasible choices, step involving environment variables(third case) corresponds lottery (von Neumann & Morgenstern, 1944)rewards Qs (N , Sov, A.A0 ), plausibility attributed rewardPS | l(S) (A.A0 ) (the formula looking like ui (pi pu ui ) expected utility lottery).set decision variables eliminated, decision rule recorded, usingargmax (resp. argmin) max (resp. min) performed.Example. maximum investment Peter expect, associated decision(s) make chooses menu without knowing attend? answerquestion, use query bpJ , bpM , epJ , epM eliminatedmc w represent fact values known menu chosen.query is:(N , (max, {mc, w}).(u , {bpJ , bpM , epJ , epM })).answer $6K, (mc, meat).(w, red) decision. Peter knows comes,query becomes(N , (u , {bpJ , bpM }).(max, {mc, w}).(u , {epJ , epM })).optimal values mc w depend bpJ bpM . answer $26K$20K gain observability present. decision rule {mc, w}(mc, meat).(w, red) John present Mary not, (mc, f ish).(w, white) otherwise.Consider query introduced beginning Section 6.1:(N , (min, {mc}).(u , {bpJ , bpM }).(max, {w}).(u , {epJ , epM })).answer : worst main course case, even Peter chooses wine, situation unacceptable. order compute expected utility menu choice,use query mc w free variables:10. unfeasible value, cf. Definition 6.456fiThe PFU Framework(N , (u , {bpJ , bpM , epJ , epM })).answer function {mc, w}. examples show queries capture varioussituations terms partial observabilities, optimistic/pessimistic attitude, parametersdecision process.6.3 Operational Answer Queryquantities PS | l(S) (A.A0 ) FS | l(S) (A.A0 ) involved definition semantic answer query directly available local functions expensivecompute. instance,probabilities, PS | l(S) (A.A0 ) equals PS,l(S) (A.A0 )/Pl(S) (A).P0 00Computing PS,l(S) (A.A0 ) =A00 dom(V (Sl(S))) PVE ,VD (A.A .A ) typically requires timeexponential |V (S l(S))|. Moreover, quantities must computed nodedecision tree. Fortunately, exists alternative definition answerquery, directly expressed using PFU instance, i.e. expressed localplausibility, feasibility, utility functions.Definition 31. operational answer Op-Ans(Q) query Q = (N , Sov) functionfree variables Q: assignment free variables, (Op-Ans(Q))(A)defined inductively follows:(Op-Ans(Q))(A) = Qo (N , Sov, A)Qo(N , (op, S) . Sov, A) = opA0 dom(S) Qo (N , Sov, A.A0 )!!Qo(N , , A) =Fi ? p Pi pu u Ui(A).Fi FPi P(9)(10)Ui UEquation 10, problem variables assigned, answer querycombination plausibility degree, feasibility degree, utility degreecorresponding complete assignment. Equation 9, variables assigned(op, S) leftmost operator-variable(s) pair Sov, answer query obtainedeliminating using op elimination operator. Again, optimal decision rulesdecision variables recorded needed, using argmin argmax. Equivalently,considering sequence operator-variable(s) pairs sequence variable eliminations,Op-Ans(Q) written:!!Op-Ans(Q) = SovFi ? p Pi pu u Ui.Fi FPi PUi Ushows Op-Ans(Q) actually corresponds generic form Equation 8.6.4 Equivalence TheoremTheorem 2 proves semantic definition Sem-Ans(Q) gives semantic foundationscomputed operational definition Op-Ans(Q).Theorem 2. plausibility structure conditionable, then, queries Q PFUnetwork, Sem-Ans(Q) = Op-Ans(Q) optimal policies decisionsSem-Ans(Q) Op-Ans(Q).457fiPralet, Verfaillie, & Schiexwords, Theorem 2 shows possible perform computationscompletely generic algebraic framework, providing result computationsdecision-theoretic foundations. Due equivalence theorem, Op-Ans(Q) denotedsimply Ans(Q) following. Note operational definition applies evennon-conditionable plausibility structure. Giving decision-theoretic-based semanticsOp-Ans plausibility structure conditionable open issue.6.5 Bounded Queriesmay interesting relax problem computing exact answer query.Assume leftmost operator-variable(s) pair sequence Sov (max, {x}),x decision variable. decision maker point view, computing decision rulesproviding expected utility greater given threshold may sufficient.case E-MAJSAT problem, defined Given boolean formula setvariables V = VD , exist assignment VD formulasatisfied least half assignments ? Extending generic PFU frameworkanswer queries done Definitions 32 33, introduce bounded queries.Definition 32. bounded query B-Q triple (N , Sov, ), (N , Sov) queryEu ( threshold).Definition 33. answer Ans(B-Q) bounded query B-Q = (N , Sov, ) booleanfunction free variables unbounded query Q = (N , Sov). every assignmentfree variables,Ans(Q)(A) u(Ans(B-Q))(A) =f otherwise.threshold may used prune search space resolution, computing answer bounded query easier computing answer unboundedone.6.6 Back Existing FrameworksLet us consider frameworks Section 3. Solving CSP (Equation 1) totallyordered soft CSP corresponds query Q = (N , (max, V )), N PFU networkcorresponding CSP V set variables CSP. Computing probabilitydistribution variable Bayesian network (Equation 2) modeled N correspondsQ = (N , (+, V {y}). examples mono-operator queries, involving onetype elimination operator.Consider multi-operator queries. search optimal policy stochasticCSP associated Equation 4 captured query Q = (N , (max, {d1 , d2 }).(+, {s1 }).(max, {d3 , d4 }).(+, {s2 })). query influence diagrams Equation 5query valuation networks Equation 6 captured way.finite horizon MDP time-steps (Equation 7), query looks like Q =(N , (max, {d1 }).(u , {s2 }).(max, {d2 }) . . . (u , {sT }).(max, {dT })), u = + probabilistic MDPs u = min pessimistic possibilistic MDPs. initial state s1458fiThe PFU Frameworkfree variable. quantified CSP quantified boolean formula, elimination operatorsmin max used represent .formally, show:Theorem 3. Queries bounded queries used express solve followinglist problems:1. SAT framework: SAT, MAJSAT, E-MAJSAT, quantified boolean formula, stochasticSAT (SSAT) extended-SSAT (Littman et al., 2001).2. CSP (or CN) framework:Check consistency CSP (Mackworth, 1977); find solution CSP; countnumber solutions CSP.Find solution valued CSP (Bistarelli et al., 1999).Solve quantified CSP (Bordeaux & Monfroy, 2002).Find conditional decision unconditional decision mixed CSPprobabilistic mixed CSP (Fargier et al., 1996).Find optimal policy stochastic CSP policy value greaterthreshold; solve stochastic COP (Constraint Optimization Problem) (Walsh,2002).3. Integer Linear Programming (Schrijver, 1998) finite domain variables.4. Search solution plan length k classical planning problem (STRIPSplanning, Fikes & Nilsson, 1971; Ghallab et al., 2004).5. Answer classical queries Bayesian networks (Pearl, 1988), Markov random fields(Chellappa & Jain, 1993), chain graphs (Frydenberg, 1990), plausibilitiesexpressed probabilities, possibilities, -rankings:Compute plausibility distributions.MAP (Maximum Posteriori hypothesis) MPE (Most Probable Explanation).Compute plausibility evidence.CPE task hybrid networks (Dechter & Larkin, 2001) (CPE means CNF Probability Evaluation, CNF formula Conjunctive Normal Form).6. Solve influence diagram (Howard & Matheson, 1984).7. finite horizon, solve probabilistic MDP, possibilistic MDP, MDP based-rankings, completely partially observable (POMDP), factored (Puterman,1994; Monahan, 1982; Sabbadin, 1999; Boutilier et al., 1999, 2000).459fiPralet, Verfaillie, & Schiex6.7 Towards Complex QueriesQueries made complex relaxing assumptions:definition queries, order u Eu assumed total. Extendingresults partial order possible (Eu , u ) defines lattice (partially orderedset closed least upper greatest lower bounds) pu distributesleast upper bound lub greatest lower bound glb (i.e. p pu lub(u1 , u2 ) =lub(p pu u1 , p pu u2 ) p pu glb(u1 , u2 ) = glb(p pu u1 , p pu u2 )). allowssemiring CSPs (Bistarelli et al., 1999) captured framework. believeextensions partial orders utilities allow algebraic MDPs (Pernyet al., 2005) captured.try relax no-forgetting assumption, limited memory influencediagrams (LIMIDs, Lauritzen & Nilsson, 2001), show relevantdecision processes involving multiple decision makers memory constraintspolicy recording. cases, optimal decisions become nondeterministic(decisions choose x = 0 probability p x = 1 probability 1p).order decisions made environment variables observedtotal completely determined query. One may wish computeoptimal policy decisions, also optimal order performdecisions, without exactly knowing steps agents make decisionssteps observations made. Work influence diagrams unordereddecisions (Jensen & Vomlelova, 2002) good starting point try extendwork direction.possible relax assumption variables finite domain,nontrivial, since transforming u = + integrals straightforward,performing min- max-eliminations continuous domains requires guaranteeexistence supremum.6.8 SummarySection 6, last element PFU framework, class queries PFU networks,introduced. decision-tree based definition answer query provided.first main result section Theorem 2, gives theoretical foundationsanother equivalent operational definition, reducing answer query sequenceeliminations combination scoped functions. latter best adapted futurealgorithms, directly handles local functions defined PFU network.second important result Theorem 3, shows many standard queries PFUqueries. Overall, PFU framework captured Definitions 14, 16, 17 algebraicstructures, Definition 26 PFU networks, Definitions 27 31 queries.7. Gains Costsbetter understanding Theorem 3 shows many existing frameworks instancesPFU framework. unification, similarities differences ex460fiThe PFU Frameworkisting formalisms analyzed. instance, comparing VCSPs optimisticversion finite horizon possibilistic MDPs operational definition answerquery, appears finite horizon optimistic possibilistic MDP (partially observablenot) fuzzy CSP: indeed represented query Q whose operationalanswer looks like maxV (min ), V set variables set scopedfunctions. Techniques available solving fuzzy CSPs used solve finitehorizon optimistic possibilistic MDPs.complexity theory point view, studying time space complexityanswering queries form Equation 8 lead upper bounds complexityseveral frameworks simultaneously. One may also try characterize propertieslead given theoretical complexity.Increased expressive power expressive power PFU networks resultnumber features: (1) flexibility plausibility/utility model; (2) flexibilitypossible networks; (3) flexibility queries terms situation modeling. enablesqueries PFU networks cover generic finite horizon sequential decision problemsplausibilities, feasibilities, utilities, cooperative adversarial decision makers, partial observabilities, possible parameters decision process modeled freevariables.none frameworks indicated Theorem 3 presents flexibility, everysubsumed formalism X indicated Theorem 3, possible find problemrepresented PFUs directly X. specifically, compared influencediagrams (Howard & Matheson, 1984; Jensen & Vomlelova, 2002; Smith et al., 1993; Nielsen& Jensen, 2003; Jensen et al., 2004) valuation networks (VNs, Shenoy, 1992, 2000;Demirer & Shenoy, 2001), PFUs deal probabilistic expected additiveutility allow us perform eliminations min model presence adversarialagents. Thus, quantified boolean formulas cannot represented influence diagramsVNs, covered PFU networks (see Theorem 3). Moreover, PFU networks useDAG captures normalization conditions plausibilities feasibilities, whereasVNs, information lost. Compared sequential influence diagrams (Jensenet al., 2004) sequential VNs (Demirer & Shenoy, 2001), PFUs express so-calledasymmetric decision problems (problems variables may even needconsidered decision process) adding dummy values variables.Actually, simple problems expressed PFUs cannot apparentlydirectly expressed frameworks. simple instance feasibilities normalizationconditions + hard requirements captured subsumed frameworks.example, using CSP model would result loss information providednormalization conditions feasibilities. occurs influence diagrams like sequential decision processes based possibilistic expected utility, couldcalled possibilistic influence diagrams. Similarly stochastic CSPs without contingencyassumption.cost greater flexibility increased expressive power PFU frameworkcannot described simply straightforwardly as, example, constraint networks.Generic algorithms Section 8 shows generic algorithms built answerqueries PFU networks. previously said, building generic algorithms facilitate461fiPralet, Verfaillie, & Schiexcross-fertilization sense subsumed formalisms directly benefittechniques developed another subsumed formalism. fits growingeffort generalize resolution methods used different AI problems. example, softconstraint propagation drastically improves resolution valued CSPs; integratingtool generic algorithm PFUs could improve resolution influence diagrams.Using abstract operators may enable us identify algorithmically interesting properties,infer necessary sufficient conditions particular algorithm usable.However, one could argue techniques highly specific one formalismone type problem, that, case, dedicated approaches certainly outperformgeneric algorithm. solution characterize actual properties useddedicated approach, order generalize much possible. Moreover, evenspecialized schemes usually improve generic ones, exist cases generaltools efficient specialized algorithms, shown use SAT solverssolving STRIPS planning problems (Sang, Beame, & Kautz, 2005).8. Algorithmsability design generic algorithms one motivations building PFUframework, choices justified algorithmic considerations. present genericalgorithms answer arbitrary PFU queries.8.1 Generic Tree Search Algorithmoperational definition answer query Q actually defines naive exponentialtime algorithm compute Ans(Q) using tree-exploration procedure, variableordering given Sov, collects elementary plausibilities, feasibilities, utilities.precisely, assignment free variables Q, tree explored.node tree corresponds partial assignment variables. value leafprovided combination scoped functions PFU network, appliedcomplete assignment defined path root leaf. Dependingoperator used, value internal node computed performing min, max,u operation values children. root node returns (Ans(Q))(A).corresponding pseudo-code given Figure 2. query (N , Sov), first callTreeSearchAnswerQ(N , Sov). returns function free variables.assume every operator returns result constant time, timecomplexity algorithm O(m n ln(d) dn ), stands maximum domainsize, n stands number variables PFU network, stands numberscoped functions.11space complexity polynomial (it shown linear entry datasize). Hence, computing answer bounded query PSPACE. Moreover, givensatisfiability QBF PSPACE-complete problem expressedbounded query (cf. Theorem 3), follows computing answer bounded queryPSPACE-hard. PSPACE PSPACE-hard, decision problem consists11. factor n ln(d) corresponds upper bound time needed get (A) scoped functionrepresented table (of size dn ).462fiThe PFU FrameworkTreeSearchAnswerQ((V, G, P, F, U ), Sov)beginforeach dom(Vf r ) (A) AnswerQ((V, G, P, F, U ), Sov, A)returnendAnswerQ((V, G, P, F, U ), Sov, A)beginSov = return ((Fi F Fi ) ? (p Pi P Pi ) pu (uUi U Ui ))(A)else(op, S).Sov 0 Sovchoose x= {x} Sov Sov 0 else Sov (op, {x}).Sov 0dom dom(x)resdom 6=choose domdom dom {a}res op (res, AnswerQ((V, G, P, F, U ), Sov, A.(x, a)))return resendFigure 2:generic tree search algorithm answering query Q((V, G, P, F, U ), Sov)=answering bounded query PSPACE-complete. result surprising, givesidea level expressiveness reached PFU framework.work needed identify subclasses queries lower complexity, although manyalready known.8.2 Generic Variable Elimination AlgorithmQuite naturally, generic variable elimination algorithm (Bertele & Brioschi, 1972; Shenoy,1991; Dechter, 1999; Kolhas, 2003) defined answer queries PFU network.8.2.1 First Naive Schemefirst naive variable elimination algorithm given Figure 3. eliminates variablesright left sequence Sov query, whereas tree searchprocedure, variables assigned left right. right-to-left processingentails algorithm naturally returns function free variables query.first call VarElimAnswerQ((V, G, P, F, U ), Sov).version presented Figure 3 actually naive variable elimination schemetime space complexities O(m n ln(d) dn ) O(m dn ) respectively: beginscombining scoped functions eliminating variables, whereas interestvariable elimination algorithm primarily use factorization local functions.463fiPralet, Verfaillie, & SchiexVarElimAnswerQ((V, G, P, F, U ), Sov)begin0 ((Fi F Fi ) ? (p Pi P Pi ) pu (uUi U Ui ))Sov 6=Sov 0 .(op, S) Sovchoose x= {x} Sov Sov 0 else Sov Sov 0 .(op, {x})0 opx 0return 0endFigure 3: first generic variable elimination algorithm answering query Q =((V, G, P, F, U ), Sov)8.2.2 Improving Basic Schemealgorithm Figure 3 works unique global function defined combinationplausibility, feasibility, utility functions (first line), whereas factorizationavailable. improve scheme, properties algebraic structure used.sequel, denote +x (resp. x ) scoped function (resp.have) x scope. Moreover, extend every combination operator E {}setting e = e = (combining anything something unfeasible unfeasibletoo).12First, order use factorization plausibilities feasibilities, useproperties below, come right monotonicity pu , distributivity puu , definitiontruncation operator ?:xmin(Ppu U ) = P x pu (minx U )xmaxx (P x pu U ) = P x pu (maxx U )ux (P x pu U ) = P x pu (ux U )minx (F x ? U ) = F x ? (minx U )maxx (F x ? U ) = F x ? (maxx U )ux (F x ? U ) = F x ? (ux U ) .express variable x eliminated, necessary consider plausibilityfunctions feasibility functions x scope.However, necessary add axioms expected utility structure, sincegeneral case, expression ux (P +x pu (U x u U +x )) cannot decomposed. give two axioms, Ax1 Ax2, sufficient additional conditionexploit factorization utility functions.(Ax1) (Ep , p ) = (Eu , u ), p = u , p = u = pu(Ax2) u = u Eu (but Eu {}).12. operator op used combination operator scoped functions elimination operator variables. case, extension op used combination operator createsoperator op0 op0 (e, ) = , whereas extension op used elimination operatorcreates operator op00 op00 (e, ) = e. op0 op00 coincide E differ E {}.464fiThe PFU FrameworkAmong cases Table 1, rows 2, 3, 5, 6 satisfy Ax1, whereas rows 1, 4, 7, 8 satisfyAx2. Ax1 andAx2 enable us write:minx (F +x ? (U x u U +x )) = U x u (minx F +x ? U +x )maxx (F +x ? (U x u U +x )) = U x u (maxx F +x ? U +x ) .xU u (ux P +x pu U +x ) Ax1+xx+xu P pu (U u U ) =((p x P +x ) pu U x ) u (ux P +x pu U +x ) Ax2.xHence, eliminating variable x, necessary consider utility functionsx scope.present algorithm Ax1 satisfied. Ax2 holds, working plausibility/utility pairs (p, u) allows Ax1 recovered: used, example, solveinfluence diagrams (Ndilikilikesha, 1994). Ax1 satisfied, actually oneset E = Ep = Eu , one order =p =u , one combination operator = p = u = pu ,one elimination operator = p = u . Rather express feasibilities {t, f },express {1E , } mapping onto 1E f onto : preserves valueanswer query, since f ? u = u ? u = 1E u.improved variable elimination algorithm shown Figure 4. answer queryQ = ((V, G, P, F, U ), Sov), first call Ax1-VarElimAnswerQ(P F U, Sov).returns set scoped functions whose -combination equals Ans(Q). time,factorization available PFU network exploited, since eliminating variable x,scoped functions involving x considered.Ax1-VarElimAnswerQ(, Sov)beginSov = returnelseSov 0 .(op, S) Sovchoose x= {x} Sov Sov 0 else Sov Sov 0 .(op, {x})+x { | x sc()}0 opx +x( +x ) {0 }return Ax1-VarElimAnswerQ(, Sov)endFigure 4: Variable elimination algorithm Ax1 holds (: set scoped functions)Ax1 holds, algorithm actually standard variable elimination algorithmcommutative semiring. classical variable elimination algorithms, time complexityalgorithm O(m n ln(d) dw+1 ), w tree-width (Bodlaender, 1997;Dechter & Fattah, 2001) network scoped functions, constrained eliminationorder imposed Sov. Yet, space complexity also exponential tree-width.8.3 ApproachesStarting generic tree-search algorithm Section 8.1, bound computations localconsistencies (Mackworth, 1977; Cooper & Schiex, 2004; Larrosa & Schiex., 2003)465fiPralet, Verfaillie, & Schiexintegrated order prune search space. Local consistencies improve qualitybounds thanks use smaller local functions. Techniques coming quantifiedboolean formulas game algorithms (such -algorithm) consideredefficiently manage bounds min max operators alternate. Caching strategiesexploiting problem structure (Darwiche, 2001; Jegou & Terrioux, 2003) also obviouscandidates improve basic tree search scheme. Additional axioms Ax1 Ax2useful direction. Heuristics choice variable assign pair(op, S) encountered, well heuristics value choices, may also speedsearch.another direction, approximate algorithms using sampling local search could alsoconsidered: sampling eliminations + (+, u ) performed, localsearch eliminations min max performed.9. Conclusionlast decades, AI witnessed design study numerous formalismsreasoning decision problems. article, built generic frameworkmodel sequential decision making plausibilities, feasibilities, utilities.framework covers many existing approaches, including hard, valued, quantified, mixed,stochastic CSPs, Bayesian networks, finite horizon probabilistic possibilistic MDPs,influence diagrams. result algebraic framework built upon decision-theoreticfoundations: PFU framework. two facets PFU framework explicitTheorem 2, states operational definition answer query equivalentdecision tree-based semantics. result design accountsexpressiveness computational aspects.Compared related works (Shenoy, 1991; Dechter, 1999; Kolhas, 2003), PFU framework framework directly deals different types variables (decisionenvironment variables), different types local functions (plausibilities, feasibilities,utilities), different types combination elimination operators.algorithmic point view, generic algorithms based tree search variableelimination described. prove PFU framework abstraction. next step explore ways improving algorithms, generalizetechniques used formalisms subsumed PFU framework. Along line,generic approach query optimization lead definition original architecturesanswering queries, called multi-operator cluster trees multi-operator cluster DAGs.applied QBFs structures compatible Ax1 (Pralet, Schiex, &Verfaillie, 2006a), well influence diagrams structures satisfying Ax2 (Pralet,Schiex, & Verfaillie, 2006b).Acknowledgmentswould like thank Jean-Loup Farges, Jerome Lang, Regis Sabbadin, threeanonymous reviewers useful comments previous versions article. work466fiThe PFU Frameworkdescribed article initiated first author LAAS-CNRS INRAToulouse. partially conducted within EU Integrated Project COGNIRON (TheCognitive Companion) funded European Commission Division FP6-IST FutureEmerging Technologies Contract FP6-002020.Appendix A. NotationsSee Table 2.Symbolpupupupu?VDdom(x)dom(S)GpaG (x)ndG (x)CE (G)CD (G)PiFiUiF act(c)sc()PSPS1 | S2FSFS1 | S2eaningElimination operatorElimination operator plausibilitiesElimination operator utilitiesCombination operatorCombination operator plausibilitiesCombination operator utilitiesCombination operator plausibilities utilitiesPartial order plausibilitiesPartial order utilitiesTruncation operatorUnfeasible valueEnvironment variablesDecision variablesDomainvalues variable xQdom(x)xSDirected Acyclic Graph (DAG)Parents x DAG GNon-descendant x DAG GSet environment components GSet decision components GPlausibility functionFeasibility functionUtility functionPi Fi factors associated component cScope local functionPlausibility distributionConditional plausibility distribution S1 given S2Feasibility distributionConditional feasibility distribution S1 given S2SovSequence operator-variable(s) pairsSem-Ans(Q) Semantic answer query Q (decision trees)Op-Ans(Q) Operational answer query QAns(Q)Answer query QTable 2: Notation.467fiPralet, Verfaillie, & SchiexAppendix B. ProofsProposition 1 plausibility distribution PS extended give plausibility distribution PS 0 every 0 S, defined PS 0 = p SS 0 PS .Proof. Given p associative commutative, p 0 PS 0 = p 0 (p SS 0 PS ) = p PS = 1p .Thus, PS 0 : dom(S 0 ) Ep plausibility distribution 0 .Proposition 2 structures presented Table 1 expected utility structures.Proof. sufficient verify required axioms successively.Proposition 3 (Ep , p , p ) conditionable plausibility structure, plausibility distributions conditionable: suffices define PS1 | S2 PS1 | S2 (A) = max{pEp | PS1 ,S2 (A) = p p PS2 (A)} dom(S1 S2 ) satisfying PS2 (A) 6= 0p .Proof. Let PS plausibility distribution S. S1 , S2 disjoint subsetsdom(S1 S2 ) satisfying PS2 (A) 6= 0p , let us define PS1 | S2 (A) = max{p Ep | PS1 ,S2 (A) =p p PS2 (A)}. must show PS1 | S2 functions satisfy axioms a, b, c, d, e Definition 18.(a) definition PS1 | S2 distributivity p p , writePS2 = p S1 PS1 ,S2 = p S1 (PS1 | S2 p PS2 ) = (p S1 PS1 | S2 ) p PS2 .PS2 p PS2 , infer p S1 PS1 | S2 p 1p . Let A2 assignment S2 satisfyingPS2 (A2 ) 6= 0p . Assume hypothesis (H): p S1 PS1 | S2 (A2 ) p 1p holds.Then, A1 dom(S1 ), PS1 ,S2 (A1 .A2 ) p PS2 (A2 ), since PS1 ,S2 (A1 .A2 ) = PS2 (A2 ),PS1 | S2 (A1 .A2 ) = 1p , implies p S1 PS1 | S2 (A2 ) p 1p monotonicityp . Moreover, (H) implies exists unique p Ep satisfying (p S1 PS1 | S2 (A2 )) pp = 1p . Combining equation PS2 (A2 ) gives PS2 (A2 ) p PS2 (A2 ) p p = PS2 (A2 ), i.e.PS2 (A2 ) p (1p p p) = PS2 (A2 ). implies 1p p p p 1p . Given 1p p p p 1p(by monotonicity p ), obtain 1p p p = 1p . analyze two cases.p p 1p , exists unique p0 satisfying p0 p p = 1p . (p S1 PS1 | S2 (A2 )) p p= 1p 1p p p = 1p , entails p S1 PS1 | S2 (A2 ) = 1p , contradicts (H).p = 1p , 1p p 1p = 1p . entails p idempotent. Let dom0 subsetdom(S1 ) p A1 dom0 PS1 ,S2 (A1 .A2 ) = PS2 (A2 ). Let A01 dom0 .write:(PS1 ,S2 (A01 .A2 ) p (p A1 dom0 {A0 } PS1 ,S2 (A1 .A2 )) = PS2 (A2 )1.PS1 ,S2 (A01 .A2 ) p (p A1 dom0 PS1 ,S2 (A1 .A2 )) = PS2 (A2 ) (as p idempotent)PS1 ,S2 (A01 .A2 ) p PS2 (A2 ), exists unique p00 Ep PS1 ,S2 (A01 .A2 )pp00 = PS2 (A2 ). Therefore, p A1 dom0 PS1 ,S2 (A1 .A2 ) = p A1 dom0 {A0 } PS1 ,S2 (A1 .A2 ),1gives p A1 dom0 {A0 } PS1 ,S2 (A1 .A2 ) = PS2 (A2 ).1assumption p A1 dom0 PS1 ,S2 (A1 .A2 ) = PS2 (A2 ) holds dom0 = dom(S1 ). Recursively applying previous mechanism removing one assignment dom0iteration leads p A1 dom0 PS1 ,S2 (A1 .A2 ) = PS2 (A2 ) |dom0 | = 1, i.e. leadsPS1 ,S2 (A001 .A2 ) = PS2 (A2 ) dom0 = {A001 }. result, obtain contradiction.cases, contradiction (H) obtained, p S1 PS1 | S2 (A2 ) = 1p .(b) PS1 = PS1 | p P = PS1 | p (p PS ) = PS1 | p 1p = PS1 | .468fiThe PFU Framework(d) Let dom(S1 S2 S3 ) satisfying PS2 ,S3 (A) 6= 0p . Then, PS1 ,S2 | S3 (A) = PS1 | S2 ,S3 (A) pPS2 | S3 (A) holds, because:PS1 ,S2 ,S3 (A) p PS3 (A), then, exists unique p Ep PS1 ,S2 ,S3 (A) =pp PS3 (A). PS1 ,S2 ,S3 (A) = PS1 ,S2 | S3 (A)p PS3 (A) (by definition PS1 ,S2 | S3 )PS1 ,S2 ,S3 (A) = PS1 | S2 ,S3 (A)p PS2 | S3 (A)p PS3 (A) (by definition PS1 | S2 ,S3PS2 | S3 ), implies PS1 ,S2 | S3 (A) = PS1 | S2 ,S3 (A) p PS2 | S3 (A).Otherwise, PS1 ,S2 ,S3 (A) = PS3 (A). implies 1p p PS1 ,S2 | S3 (A) and,PS1 ,S2 | S3 (A) p 1p , PS1 ,S2 | S3 (A) = 1p . Similarly, entails PS2 | S3 (A) = 1pPS1 | S2 ,S3 (A) = 1p (the monotonicity p implies PS1 ,S2 ,S3 (A) = PS2 ,S3 (A) =PS3 (A)). 1p = 1p p 1p , get PS1 ,S2 | S3 (A) = PS1 | S2 ,S3 (A) p PS2 | S3 (A).(c)p S1 PS1 ,S2 | S3= p S1 (PS1 | S2 ,S3 p PS2 | S3 ) (using (d))= (p S1 PS1 | S2 ,S3 ) p PS2 | S3 (because p distributes p )= PS2 | S3 (using (a))(e) Assume PS1 ,S2 ,S3 = PS1 | S3 p PS2 | S3 p PS3 . Let dom(S1 S2 S3 )PS3 (A) 6= 0p . Then, PS1 ,S2 | S3 (A) = PS1 | S3 (A) p PS2 | S3 (A) holds, because:PS1 ,S2 ,S3 (A) p PS3 (A), exists unique p Ep PS1 ,S2 ,S3 (A) =p p PS3 (A), therefore PS1 ,S2 | S3 (A) = PS1 | S3 (A) p PS2 | S3 (A).Otherwise, write PS1 | S3 (A) = PS2 | S3 (A) = PS1 ,S2 | S3 (A) = 1p using reasoning similar (d), therefore PS1 ,S2 | S3 (A) = PS1 | S3 (A) p PS2 | S3 (A).Proposition 4 I(., . | .) satisfies semigraphoid axioms:1. symmetry: I(S1 , S2 | S3 ) I(S2 , S1 | S3 ),2. decomposition: I(S1 , S2 S3 | S4 ) I(S1 , S2 | S4 ),3. weak union: I(S1 , S2 S3 | S4 ) I(S1 , S2 | S3 S4 ),4. contraction: (I(S1 , S2 | S4 ) I(S1 , S3 | S2 S4 )) I(S1 , S2 S3 | S4 ).Proof.1. Symmetry axiom: directly satisfied commutativity p .2. Decomposition axiom: assume I(S1 , S2 S3 | S4 ) holds.PS1 ,S2 | S4 = p S3 PS1 ,S2 ,S3 | S4= p S3 (PS1 | S4 p PS2 ,S3 | S4 ) (since I(S1 , S2 S3 | S4 ))= PS1 | S4 p (p S3 PS2 ,S3 | S4 ) (by distributivity p p )= PS1 | S4 p PS2 | S4 .Thus, I(S1 , S2 | S4 ) holds.3. Weak union axiom: assume I(S1 , S2 S3 | S4 ) holds. decomposition axiom entailsI(S1 , S3 | S4 ) also satisfied.PS1 ,S2 ,S3 ,S4 = PS1 ,S2 ,S3 | S4 p PS4 (chain rule)= PS1 | S4 p PS2 ,S3 | S4 p PS4 (since I(S1 , S2 S3 | S4 ))= PS1 | S4 p PS3 | S4 p PS4 p PS2 | S3 ,S4 (chain rule)= PS1 ,S3 | S4 p PS4 p PS2 | S3 ,S4 (since I(S1 , S3 | S4 ))= PS1 | S3 ,S4 p PS2 | S3 ,S4 p PS3 ,S4 (chain rule).axiom (e) Definition 18, infer PS1 ,S2 | S3 ,S4 = PS1 | S3 ,S4 p PS2 | S3 ,S4 , i.e.I(S1 , S2 | S3 S4 ) holds.469fiPralet, Verfaillie, & Schiex4. Contraction axiom: assume I(S1 , S2 | S4 ) I(S1 , S3 | S2 S4 ) hold.PS1 ,S2 ,S3 | S4 = PS1 ,S3 | S2 ,S4 p PS2 | S4 (chain rule)= PS1 | S2 ,S4 p PS3 | S2 ,S4 p PS2 | S4 (since I(S1 , S3 | S2 S4 ))= PS1 ,S2 | S4 p PS3 | S2 ,S4 (chain rule)= PS1 | S4 p PS2 | S4 p PS3 | S2 ,S4 (since I(S1 , S2 | S4 ))= PS1 | S4 p PS2 ,S3 | S4 (chain rule).Thus, I(S1 , S2 S3 | S4 ) holds.Theorem 1 (Conditional independence factorization) Let (Ep , p , p ) conditionable plausibility structure let G DAG components S.(a) G compatible plausibility distribution PS S, PS = p cC(G) Pc | paG (c) .(b) If, c C(G), function c,paG (c) c,paG (c) (A) plausibilitydistribution c assignments paG (c), = p cC(G) c,paG (c)plausibility distribution G compatible.Proof.(a) First, |C(G)| = 1, G contains unique component c1 . Then, p cC(G) Pc | paG (c) = Pc1 | =Pc1 : proposition holds |C(G)| = 1.Assume proposition holds DAGs n components. Let G DAGcomponents compatible plausibility distribution PS |C(G)| = n + 1.Let c0 component labeling leaf G. G compatible PS , writeI(c0 , ndG (c0 ) paG (c0 ) | paG (c0 )). c0 leaf, ndG (c0 ) = c0 , consequentlyI(c0 , (S c0 ) paG (c0 ) | paG (c0 )). means PSpaG (c0 ) | paG (c0 ) = Pc0 | paG (c0 ) pP(Sc0 )paG (c0 ) | paG (c0 ) . Combining side equation PpaG (c0 ) givesPS = Pc0 | paG (c0 ) p PSc0 .0Let G DAG obtained G deleting node labeled c0 . everycomponent c C(G0 ), paG0 (c) = paG (c) (since deleted component c0 leaf). MoreoverndG0 (c) equals either ndG (c) ndG (c)c0 (again, since deleted component c0 leaf).first case (ndG0 (c) = ndG (c)), property I(c, ndG (c) paG (c) | paG (c)) directly impliesI(c, ndG0 (c)paG0 (c) | paG0 (c)). second case (ndG0 (c) = ndG (c)c0 ), decompositionaxiom allows us write I(c, ndG0 (c) paG0 (c) | paG0 (c)) I(c, ndG (c) paG (c) | paG (c)).Consequently, G0 DAG compatible PSc0 . |C(G0 )| = n, induction hypothesisgives PSc0 = p cC(G0 ) Pc | paG (c) , implies PS = p cC(G) Pc | paG (c) , desired.(b) Assume every component c, c,paG (c) (A) plausibility distribution cassignments paG (c). |C(G)| = 1, C(G) = {c1 }. Then, = c1 plausibilitydistribution c1 . Moreover, | = 1p , write c1 | = c1 | p | , i.e.I(c1 , | ). Therefore, G compatible c1 : proposition holds |C(G)| = 1.Assume proposition holds DAGs n components. Consider DAG Gn + 1 components. first show plausibility distribution S, i.e.p (p cC(G) c,paG (c) ) = 1p . Let c0 leaf component G. c0 leaf, uniquescoped function whose scope contains variable c0 c0 ,paG (c0 ) . distributivityp p , impliesp c0 (p cC(G) c,paG (c) ) = (p c0 c0 ,paG (c0 ) ) p (p cC(G){c0 } c,paG (c) ).Given c0 ,paG (c0 ) (A) plausibility distribution c0 assignments paG (c0 ),470fiThe PFU Frameworkp c0 c0 ,paG (c0 ) = 1p . Consequently,p c0 (p cC(G) c,paG (c) ) = p cC(G){c0 } c,paG (c) .Applying induction hypothesis DAG n components obtained G deleting c0 , infer p Sc0 (p cC(G){c0 } c,paG (c) ) = 1p . allows us writep Sc0 (p c0 (p cC(G) c,paG (c) )) = 1p , i.e. p = 1p : plausibility distributionS. remains prove G DAG components compatible . Let c C(G).must show I(c, ndG (c) paG (c) | paG (c)) holds. two cases:1. c = c0 , must provec0 ,ndG (c0 )paG (c0 ) | paG (c0 ) = c0 | paG (c0 ) p ndG (c0 )paG (c0 ) | paG (c0 ) .First, notec0 ,paG (c0 ) = p S(c0 paG (c0 )) (p cC(G) c,paG (c) )= (p S(c0 paG (c0 )) (p cC(G){c0 } c,paG (c) )) p c0 ,paG (c0 )(because p distributes p sc(c0 ,paG (c0 ) ) c0 paG (c0 )= (p SpaG (c0 ) (p cC(G) c,paG (c) )) p c0 ,paG (c0 )(because p distributes p c0 c0 ,paG (c0 ) = 1p )= paG (c0 ) p c0 ,paG (c0 ) .this, possible write:ndG (c0 )paG (c0 ) | paG (c0 ) p c0 | paG (c0 ) p paG (c0 )= ndG (c0 )paG (c0 ) | paG (c0 ) p c0 ,paG (c0 )= ndG (c0 )paG (c0 ) | paG (c0 ) p paG (c0 ) p c0 ,paG (c0 )= ndG (c0 ) p c0 ,paG (c0 )= S{c0 } p c0 ,paG (c0 ) (because c0 leaf G)=(p cC(G){c0 } c,paG (c) ) p c0 ,paG (c0 )= p cC(G) c,paG (c)= .Using axiom (e) Definition 18, entails ndG (c0 )paG (c0 ) | paG (c0 ) p c0 | paG (c0 ) =SpaG (c0 ) | paG (c0 ) , i.e., = c0 ndG (c0 ), I(c0 , ndG (c0 ) paG (c0 ) | paG (c0 )).2. Otherwise, c 6= c0 . Let G0 DAG obtained G deleting c0 . G0 containsn components: induction hypothesis, I(c, ndG0 (c) paG0 (c) | paG0 (c)). c0leaf G, c0/ paG (c), implies paG0 (c) = paG (c). Thus,I(c, ndG0 (c) paG (c) | paG (c)).(i) ndG0 (c) = ndG (c), immediate I(c, ndG (c) paG (c) | paG (c)).(ii) Otherwise, ndG0 (c) 6= ndG (c). c0 leaf G, equivalent sayndG (c) = ndG0 (c) c0 . means c ancestor c0 , fortiori c/ paG (c0 ). following, four semigraphoid axioms usedprove required result. decomposition axiom, I(c0 , ndG (c0 )paG (c0 ) | paG (c0 )), (c ndG0 (c)) ndG (c0 ) (because ndG (c0 ) =c0 ), follows I(c0 , (c ndG0 (c)) paG (c0 ) | paG (c0 )), or, words,c paG (c0 ) = , I(c0 , c (ndG0 (c) paG (c0 )) | paG (c0 )). Using weakunion axiom leads I(c0 , c | (ndG0 (c) paG (c0 )) paG (c0 )) and, using symmetry axiom, I(c, c0 | (ndG0 (c) paG (c0 )) paG (c0 )). shown previously,I(c, ndG0 (c)paG (c) | paG (c)). Together I(c, c0 | (ndG0 (c)paG (c0 ))paG (c0 )),contraction axiom implies I(c, (ndG0 (c) paG (c)) c0 | paG (c)). c0/paG (c) ndG (c) = ndG0 (c) c0 , means I(c, ndG (c) paG (c)) | paG (c)).471fiPralet, Verfaillie, & Schiexproved G compatible . Consequently, proposition holdsn + 1 components G, ends proof induction.Proposition 5 Let (Ep , p , p ) conditionable plausibility structure. Then,n N , exists unique p0 p i[1,n] p0 = 1p .Proof. Let n N . p i[1,n] 1p = 1p , p0 = 1p satisfies required property. Moreover,case, distributivity p p implies p Ep , p i[1,n] p = p. Therefore,p i[1,n] p = 1p , p = 1p , shows p0 unique.Otherwise, p i[1,n] 1p 6= 1p . case, 1p p p i[1,n] 1p monotonicity p ,write 1p p p i[1,n] 1p . second item Definition 19 implies exists uniquep0 Ep 1p = p0 p (p i[1,n] 1p ), i.e. 1p = p i[1,n] p0 .Proposition 6Let PVE ,VD completion controlled plausibility distributionPVE || VD . Then, PVE ,VD plausibility distribution VD PVE | VD = PVE || VD .Proof. PVE ,VD = PVE || VD p p0 , p0 element Ep p i[1,|dom(VD )|] p0 = 1p .p VD PVE ,VD = p VD (PVE || VD p p0 ) = p VD ((p PVE || VD ) p p0 ) = p VD p0 =p i[1,|dom(VD )|] p0 = 1p . proves PVE ,VD plausibility distribution VD .PVE ,VD = PVE || VD p p0 PVE ,VD = PVE | VD p PVD , write PVE || VD p p0 =PVE | VD p PVD . Moreover, PVD = p PVE ,VD = p (PVE || VD p p0 ) = p0 . Thus, PVE || VD pp0 = PVE | VD p p0 . Summing equation |dom(VD )| times p gives PVE || VD = PVE | VD .Proposition 7 Let G typed DAG components VD . Let Gp partialgraph G induced arcs G incident environment components. Let Gfpartial graph G induced arcs G incident decision components. Gpcompatible completion PVE || VD (cf. Definition 22) Gf compatiblecompletion FVD || ,PVE | VD =p Pc | paG (c)cCE (G)FVD | =cCD (G)Fc | paG (c) .Proof. result proved PVE | VD (the proof FVD | similar). completionPVE || VD looks like PVE ,VD = PVE || VD p p0 . Gp compatible completion, Theorem 1aentails PVE ,VD = p cC(Gp ) Pc | paGp (c) . decision components roots Gp , infer,successively eliminating environment components, PVD = p PVE ,VD = p cCD (Gp ) Pc .hand, PVD = p PVE || VD p p0 = p0 . proves p cCD (Gp ) Pc =p0 . Therefore, PVE ,VD = PVE | VD p p0 = (p cCE (Gp ) Pc | paGp (c) ) p p0 . Summing equation|dom(VD )| times p gives PVE | VD = p cCE (Gp ) Pc | paGp (c) . CE (Gp ) = CE (G) paGp (c) =paG (c) every c CE (G), entails PVE | VD = p cCE (G) Pc | paG (c) .Proposition 8 Assume plausibility structure used conditionable. Let Q =(N , Sov) query Sov = (op1 , S1 ) (op2 , S2 ) (opk , Sk ). Let Vf r denote setfree variables Q.472fiThe PFU Framework(1) Si PSi | l(Si ) (A) well-defined, exists least one A0 dom(Si )satisfying PSi | l(Si ) (A.A0 ) 6= 0p .(2) Si VD FSi | l(Si ) (A) well-defined, exists least one A0 dom(Si )satisfying FSi | l(Si ) (A.A0 ) = t.(3) 6= Si leftmost set environment variables appearing Sov, then,dom(l(Si )), PSi | l(Si ) (A) well-defined.(4) i, j [1, k], < j, Si , Sj , r(Si )l(Sj ) VD (Sj first set environment variables appearing right Si Sov), (A, A0 ) dom(l(Si )) dom(Si ),PSi | l(Si ) (A) well-defined, PSi | l(Si ) (A.A0 ) 6= 0p , then, A00 extending A.A0l(Sj ), PSj | l(Sj ) (A00 ) well-defined.(5) i, j [1, k], < j, Si VD , Sj VD , r(Si ) l(Sj ) (Sj first setdecision variables appearing right Si Sov), (A, A0 ) dom(l(Si ))dom(Si ),FSi | l(Si ) (A) well-defined, FSi | l(Si ) (A.A0 ) = t, then, A00 extending A.A0l(Sj ), FSj | l(Sj ) (A00 ) well-defined.(6) [1, k] Si , PSi | l(Si ) = PSi | l(Si )VE ||VD .(7) [1, k] Si VD , FSi | l(Si ) = FSi | l(Si )VD ||VE .Proof. denote p0 element Ep completion PVE || VD equals PVE || VD p0 .Note p0 6= 0p , since must satisfy p i[1,|dom(VD )|] p0 = 1p .Lemma 1. Let (Ep , p , p ) conditionable plausibility structure. Then, (p1 p p2 = 0p )((p1 = 0p ) (p2 = 0p )).Proof. First, p1 = 0p p2 = 0p , p1 p p2 = 0p . Conversely, assume p1 p p2 = 0p . Then,p1 p 0p , conditionability plausibility structure together p1 p 0p = 0p entailsp2 = 0p . Similarly, p2 p 0p , p1 = 0p . Therefore (p1 p p2 = 0p ) ((p1 = 0p )(p2 = 0p )).Lemma 2. Assume plausibility structure conditionable. Let S1 , S2 disjoint subsets. Then, PS1 | S2 || VD = PS1 | S2 ,VD .Proof. Note PS1 ,S2 | VD = PS1 | S2 ,VD p PS2 | VD . Moreover, also write PS1 ,S2 | VD =PS1 ,S2 || VD = PS1 | S2 || VD p PS2 || VD = PS1 | S2 || VD p PS2 | VD . Let assignment V .PS1 ,S2 | VD (A) p PS2 | VD (A), conditionability plausibility structure entailsPS1 | S2 ,VD (A) = PS1 | S2 || VD (A). Otherwise, PS1 ,S2 | VD (A) = PS2 | VD (A), also entailsPS1 ,S2 || VD (A) = PS2 || VD (A). case, PS1 | S2 ,VD (A) = PS1 | S2 || VD (A) = 1p . Therefore,PS1 | S2 ,VD = PS1 | S2 || VD .(1) Assume Si PSi | l(Si ) (A) well-defined. Then, PSi | l(Si ) (A) plausibilitydistribution Si . Hence, p A0 dom(Si ) PSi | l(Si ) (A.A0 ) = 1p , implies existsleast one A0 dom(Si ) PSi | l(Si ) (A.A0 ) 6= 0p .(2) Proof similar point (2).(3) Assume 6= . Let Si leftmost set environment variables appearing Sovlet dom(l(Si )). Since l(Si ) = , write Pl(Si ) (A) = p V l(Si ) PVE ,VD (A) =p VD l(Si ) (p PVE ,VD (A)) = p VD l(Si ) p0 6= 0p . Therefore, PSi | l(Si ) (A) well-defined.473fiPralet, Verfaillie, & Schiex(6) Let lE (Si ) = l(Si ) lD (Si ) = l(Si ) VD . set variables S, denote dG (S)set variables V descendant DAG G least one variable S.First, PSi ,lE (Si ) || VD = p (Si lE (Si )) PVE || VD = p (Si lE (Si )) (p Pj P Pj ). definition query, variables dG (VD lD (Si )) belong Si lE (Si ) (the environmentvariables descendants as-yet-unassigned decision variables assigned yet).Thus, PSi ,lE (Si ) || VD = p (Si lE (Si )dG (VD lD (Si ))) (p Pj F act(c),c*VE dG (VD lD (Si )) Pj ).last equality obtained successively eliminating environment components includeddG (VD lD (Si )) (using normalization conditions). scope plausibility functionPj F act(c) included cpaG (c), equality entails PSi ,lE (Si ) || VD dependassignment VD lD (Si ). Morever, PlE (Si ) || VD = Si PSi ,lE (Si ) || VD dependassignment VD lD (Si ) too. PSi | lE (Si ) || VD = max{p Ep | PSi ,lE (Si ) || VD =p p PlE (Si ) || VD }, also entails PSi | lE (Si ) || VD depend assignmentVD lD (Si ). denoted PSi | lE (Si ) || lD (Si ) .show PSi | l(Si ) = PSi | lE (Si ) || lD (Si ) . First, notePSi ,l(Si ) = p VD lD (Si ) PSi ,lE (Si ),VD = p VD lD (Si ) (PSi | lE (Si ),VD p PlE (Si ),VD )= p VD lD (Si ) (PSi | lE (Si ) || VD p PlE (Si ),VD ) (using Lemma 2)= PSi | lE (Si ) || VD p (p VD lD (Si ) PlE (Si ),VD )(since PSi | lE (Si ) || VD depend assignment VD lD (Si ))= PSi | lE (Si ) || VD p Pl(Si ) .Let assignment V .PSi ,l(Si ) (A) p Pl(Si ) (A), conditionability plausibility structure directlyentails PSi | l(Si ) (A) = PSi | lE (Si ) || VD (A).Otherwise, PSi ,l(Si ) (A) = Pl(Si ) (A). case, PSi | l(Si ) (A) = 1p . Next, Vl(Si ) = (VD lD (Si )) (VE lE (Si )), observe Pl(Si ) = p V l(Si ) (PVE || VD p p0 ) =p VD lD (Si ) (PlE (Si ) || VD p p0 ). Similarly, PSi ,l(Si ) = p V (Si l(Si )) (PVE || VD pp0 ) = p VD lD (Si ) (PSi ,lE (Si ) || VD p p0 ). PSi ,l(Si ) (A) = Pl(Si ) (A), inferp VD lD (Si ) (PlE (Si ) || VD (A) p p0 ) = p VD lD (Si ) (PSi ,lE (Si ) || VD (A) p p0 ). neitherPlE (Si ) || VD PSi ,lE (Si ) || VD depends assignment VD lD (Si ), entailsPlE (Si ) || VD (A) p (p VD lD (Si ) p0 ) = PSi ,lE (Si ) || VD (A) p (p VD lD (Si ) p0 ). Summingequation |dom(lD (Si ))| times gives PSi ,lE (Si ) || VD (A) = PlE (Si ) || VD (A), thusPSi | lE (Si ) || VD (A) = 1p = PSi | l(Si ) (A).(7) Proof similar point (6).(4) Let i, j [1, k] < j, Si , Sj , r(Si ) l(Sj ) VD (Sj first setenvironment variables appearing right Si Sov). Let (A, A0 ) dom(l(Si ))dom(Si )PSi | l(Si ) (A) well-defined (i.e. Pl(Si ) (A) 6= 0p ) PSi | l(Si ) (A.A0 ) 6= 0p . Let A00extension A.A0 l(Sj ). must show PSj | l(Sj ) (A00 ) well-defined, i.e.Pl(Sj ) (A00 ) 6= 0p . PSi | l(Si ) (A.A0 ) 6= 0p Pl(Si ) (A) 6= 0p , Lemma 1 impliesPSi ,l(Si ) (A.A0 ) 6= 0p . Similarly proof point (6), possible show Pl(Sj )depend assignment l(Sj ) (Si l(Si )). Therefore, every A00 extending A.A0l(Sj ), p l(Sj )(Si l(Si )) Pl(Sj ) (A00 ) 6= 0p , implies Pl(Sj ) (A00 ) 6= 0p .(5) Proof similar point (4), except plausibilities replaced feasibilities decisionvariables replaced environment variables.474fiThe PFU FrameworkTheorem 2 plausibility structure conditionable, then, queries Q PFUnetwork, Sem-Ans(Q) = Op-Ans(Q) optimal policies decisionsSem-Ans(Q) Op-Ans(Q).Proof. Let Af r assignment set free variables Vf r FVf r (Af r ) = f .semantic definition gives (Sem-Ans(Q))(Af r ) = . Given FVf r (Af r ) = V Vf r FVE ,VD (Af r ) =V Vf r FVD || (Af r ) = V Vf r (Fi F Fi (Af r )) (since completion FVD || gives FVD || =FVD ,VE ), infer every complete assignment A00 extending Af r , Fi F Fi (A00 ) = f(Fi F Fi (A00 )) ? (p Pi P Pi (A00 )) pu (uUi U Ui (A00 )) = . min(, ) = max(, ) = u =, entails (Op-Ans(Q))(Af r ) = too.analyze case FVf r (Af r ) = t. use A00 denote complete assignmentmust considered semantic definition. Using properties:p pu min(u1 , u2 ) = min(p pu u1 , p pu u2 ) (right monotonicity pu ),p pu max(u1 , u2 ) = max(p pu u1 , p pu u2 ) (right monotonicity pu ),p pu (u1 u u2 ) = (p pu u1 ) u (p pu u2 ) (distributivity pu u ),p1 pu (p2 pu u) = (p1 p p2 ) pu u,move PSi | l(Si ) (A.A0 ) get, starting semantic definition,(p i[1,k],Si PSi | l(Si ) )(A00 ) pu UV (A00 )right elimination operators.prove quantity equals PVE | VD (A00 ) pu UV (A00 ). Let rightmost setquantified environment variables. chain rule enables us write PVE | VD = PS | lE (S),VD pPlE (S) | VD , lE (S) = l(S) . Moreover, using Lemma 2 Proposition 8(6),write PS | lE (S),VD = PS | lE (S) || VD = PS | l(S) . Therefore, PVE | VD = PS | l(S) p PlE (S) | VD . Recursively applying mechanism leads to: PVE | VD = p i[1,k],Si PSi | l(Si ) . Therefore, obtainPVE | VD (A00 ) pu UV (A00 ) right elimination operators.semantic definition query meaning simplified bit, thanks Lemma 1.lemma implies conditions like PS | l(S) (A.A0 ) 6= 0p , used Pl(S) (A) 6= 0p ,equivalent PS,l(S) (A.A0 ) 6= 0p , since PS,l(S) (A.A0 ) = PS | l(S) (A.A0 ) p Pl(S) (A). result,operators uA0 dom(S),PS | l(S) (A.A0 )6=0p replaced uA0 dom(S),PS,l(S) (A.A0 )6=0p . Similarly,eliminations minA0 dom(S),FS | l(S) (A.A0 )=t , conditions FS | l(S) (A.A0 ) = replacedFS,l(S) (A.A0 ) = t. holds eliminations maxadom(xi ),FS | l(S) (A.A0 )=t .start operational definition show reformulated above.operational definition applies sequence variable eliminations global function (Fi F Fi ) ?(p Pi P Pi ) pu (Ui U Ui ), also equals FVD | ? PVE | VD pu UV . Let leftmostset quantified decision variables. Let assignment l(S). Assume quantified min. Let A0 dom(S) FS,l(S) (A.A0 ) = f . inferredcomplete assignment A00 extending A.A0 , FVE ,VD (A00 ) = f , consequently FVD | (A00 ) =f . implies FVD | (A00 ) ? PVE | VD (A00 ) pu UV (A00 ) = . Given min(, ) =max(, ) = u = , obtain Qo(N , Sov, A.A0 ) = . min(d, ) = d, entailsminA0 dom(S) Qo(N , Sov, A.A0 ) = minA0 dom(S){A0 } Qo(N , Sov, A.A0 ). Thus, minA0 dom(S)replaced minA0 dom(S),FS,l(S) (A.A0 )=t (as FVf r (A) = t, exists least one assignmentA0 dom(S) FS,l(S) (A.A0 ) = t). result holds quantified max. Applying mechanism set quantified decision variables left right Sov,obtain minA0 dom(S) maxA0 dom(S) replaced minA0 dom(S),FS,l(S) (A.A0 )=tmaxA0 dom(S),FS,l(S) (A.A0 )=t respectively. Moreover, shown every complete assignment A00 considered corresponding transformed operational definition, FVD | (A00 ) = t.thus possible replace FVD | (A00 ) ? PVE | VD (A00 ) pu UV (A00 ) PVE | VD (A00 ) pu UV (A00 ).475fiPralet, Verfaillie, & Schiextransform uA0 dom(S) Qo(N , Sov, A.A0 ) looks like expressionsemantic definition. Let leftmost set quantified environment variables. Let assignment l(S). Let A0 dom(S) PS,l(S) (A.A0 ) = 0p . Then, complete assignmentsA00 extending A.A0 , PVE | VD (A00 ) = 0p , thus PVE | VD (A00 ) pu UV (A00 ) = 0u . min(0u , 0u ) =max(0u , 0u ) = 0u u 0u = 0u , obtain Qo(N , Sov, A.A0 ) = 0u . u 0u = d, computing uA0 dom(S) Qo(N , Sov, A.A0 ) equivalent computing uA0 dom(S){A0 } Qo(N , Sov, A.A0 ).Thus, uA0 dom(S) replaced uA0 dom(S),PS,l(S) (A.A0 )6=0p (as Pl(S) (A) 6= 0p , existsleast one assignment A0 dom(S) satisfying PS,l(S) (A.A0 ) 6= 0p ). Applying mechanism,considering set quantified environment variables left right Sov, getuA0 dom(S),PS,l(S) (A,A0 )6=0p instead uA0 dom(S) .Consequently, found function Sem-Ans(Q) = Op-Ans(Q) = .Moreover, optimal policies decisions Sem-Ans(Q) optimal policies decisions. Indeed, transformation rules used preserve set optimal policies. holdsOp-Ans(Q) . entails Sem-Ans(Q) = Op-Ans(Q), optimal policiesSem-Ans(Q) Op-Ans(Q).Theorem 3 Queries bounded queries used express solve followingnonexhaustive list problems:1. SAT framework: SAT, MAJSAT, E-MAJSAT, quantified boolean formula, stochasticSAT (SSAT) extended-SSAT (Littman et al., 2001).2. CSP (or CN) framework:Check consistency CSP (Mackworth, 1977); find solution CSP; countnumber solutions CSP.Find solution valued CSP (Bistarelli et al., 1999).Solve quantified CSP (Bordeaux & Monfroy, 2002).Find conditional decision unconditional decision mixed CSPprobabilistic mixed CSP (Fargier et al., 1996).Find optimal policy stochastic CSP policy value greaterthreshold; solve stochastic COP (Constraint Optimization Problem) (Walsh,2002).3. Integer Linear Programming (Schrijver, 1998) finite domain variables.4. Search solution plan length k classical planning problem (STRIPSplanning, Fikes & Nilsson, 1971; Ghallab et al., 2004).5. Answer classical queries Bayesian networks (Pearl, 1988), Markov random fields(Chellappa & Jain, 1993), chain graphs (Frydenberg, 1990), plausibilitiesexpressed probabilities, possibilities, -rankings:Compute plausibility distributions.MAP (Maximum Posteriori hypothesis) MPE (Most Probable Explanation).476fiThe PFU FrameworkCompute plausibility evidence.CPE task hybrid networks (Dechter & Larkin, 2001) (CPE means CNF Probability Evaluation, CNF formula Conjunctive Normal Form).6. Solve influence diagram (Howard & Matheson, 1984).7. finite horizon, solve probabilistic MDP, possibilistic MDP, MDP based-rankings, completely partially observable (POMDP), factored (Puterman,1994; Monahan, 1982; Sabbadin, 1999; Boutilier et al., 1999, 2000).Proof.Lemma 3. Let (Ep , Eu , u , pu ) expected utility structure Eu totally orderedu . Let S1 ,S2 local function Eu whose scope S1 S2 .maxuS1 ,S2 ((A).A):dom(S2 )dom(S1 ) Adom(S2 )= u max S1 ,S2 .S2S1Moreover, : dom(S2 ) dom(S1 ) satisfies (maxS1 S1 ,S2 )(A) = S1 ,S2 ((A).A)dom(S2 ) iff max:dom(S2 )dom(S1 ) uAdom(S2 ) S1 ,S2 ((A).A) = uAdom(S2 ) S1 ,S2 ((A).A).words, two sides equality set optimal policies S1 .Proof. Let 0 : dom(S2 ) dom(S1 ) functionmax:dom(S2 )dom(S1 ) uAdom(S2 ) S1 ,S2 ((A).A) = uAdom(S2 ) S1 ,S2 (0 (A).A).Given that, dom(S2 ), S1 ,S2 (0 (A).A) u maxA0 dom(S1 ) S1 ,S2 (A0 .A), monotonicityu entails uAdom(S2 ) S1 ,S2 (0 (A).A) u uAdom(S2 ) maxA0 dom(S1 ) S1 ,S2 (A0 .A). Thus,max:dom(S2 )dom(S1 ) uAdom(S2 ) S1 ,S2 ((A).A) u uS2 maxS1 S1 ,S2 .hand, let 0 : dom(S2 ) dom(S1 ) function dom(S2 ),(maxS1 S1 ,S2 )(A) = S1 ,S2 (0 (A).A). Then,uS2 maxS1 S1 ,S2 =uS1 ,S2 (0 (A).A) umaxuS1 ,S2 ((A).A).:dom(S2 )dom(S1 ) Adom(S2 )Adom(S2 )antisymmetry u implies required equality. equality set optimal policiesS1 directly implied equality.give proof theorem, uses cases previous lemma.1. (CSP based problems, Mackworth, 1977 )Let us consider CSP set variables V set constraints {C1 , . . . , Cm }.(a) (Consistency solution finding) Consistency checked using query Q =(N , (max, V )), N = (V, G, , , U ) (all variables V decision variables, Greduced unique decision component containing variables, U = {C1 , . . . , Cm }),expected utility structure boolean optimistic expected conjunctiveutility (row 6 Table 1). Computing Ans(Q) = maxV (C1 . . . Cm ) equivalentchecking consistency, Ans(Q) = iff exists assignment V satisfyingC1 . . .Cm , i.e. iff CSP consistent. order get solution Ans(Q) = t,suffices record optimal decision rule V . Integer Linear Programming (Schrijver,1998) finite domain variables formulated CSP.(b) (Counting number solutions) expected utility structure consideredtask probabilistic expected satisfaction (row 2 Table 1). PFU networkN = (V, G, P, , U ), variables V environment variables, G DAGunique component c0 = V , P = {1/0 }, 0 constant factor equal |dom(V )|477fiPralet, Verfaillie, & SchiexF act(c0 ) = {0 }, U = {C1 , . . . , Cm }. Implicitly, 1/0 specifiescomplete assignments equiprobable. enables normalizationconditionPc CE (G), p c p Pi F act(c) Pi = 1p satisfied, since V (1/|dom(V )|) = 1.query consider Q = (N , (+, V )). Phard check satisfiesconditions imposed queries Ans(Q) = V (1/0 (C1 . . . Cm )) givespercentage solutions CSP. 0 Ans(Q) gives number solutions.2. (Solving Valued CSP (VCSP), Bistarelli et al., 1999 )order model problem, difficulty lies definition expected utilitystructure. VCSP, triple (E, ~, ) called valuation structure introduced. satisfiesproperties (E, ~) commutative semigroup, total order E, Eminimum element denoted >. expected utility structure consider followingone: (Ep , p , p ) = ({t, f }, , ), (Eu , u ) = (E, ~), expected utility structure(Ep , Eu , u , pu ), u = min pu defined f alse pu u = > true pu u =u (it hard check structure expected utility structure). Next,PFU network N = (V, G, , , U ), V set variables VCSP, GDAG one decision component containing variables, U contains softconstraints. query Q = (min, V ) enables us find minimum violation degreesoft constraints. solution VCSP optimal (argmin) decision rule V .3. (Problems SAT framework, Littman et al., 2001 )SAT framework, queries conjunctive normal form boolean formula setvariables V = {x1 , . . . , xn } asked. Let us first prove extended SSAT formula evaluated PFU query. extended SSAT formula definedtriple (, , q) boolean formula conjunctive normal form, threshold[0, 1], q = (q1 x1 ) . . . (qn xn ) sequence quantifier/variable pairs (the quantifiers, , R; meaning R appears below). take f t, value quantification sequence q, val(, q), defined recursively by: (i) val(, ) = 1t, 0 otherwise; (ii) val(,(x) q 0 ) = maxx val(, q 0 ); (iii) val(, (x) q 0 ) = minx val(, q 0 );P(iv) val(, (Rx) q 0 ) =0.5val(, q 0 ). Intuitively, last case means R quantifiesxboolean variables taking equiprobable values. extended SSAT formula (, , q) iffval(, q) . denotes set variables quantified R, equivalent definitionval(, q) is: (i) val(, ) = 0.5|S| t, 0 otherwise; (ii) val(,(x) q 0 ) = maxx val(, q 0 );P000(iii) val(, (x) q ) = minx val(, q ); (iv) val(, (Rx) q ) = x val(, q 0 ). second definition proves val(, q) computed PFU query defined by: (a) expectedutility structure: probabilistic expected satisfaction (row 2 Table 1); (b) PFU network:N = (V, G, P, , U ), V set variables formula (the decision variablesvariables quantified ), G DAG without arcs, one decision component perdecision variable unique environment component containing variables quantifiedR, P = {0 }, 0 constant factor equal 0.5|VE | , U set clauses ; (c)query: Q = (N , Sov), Sov obtained q replacing , , R max, min,+ respectively. Then, Ans(Q) = val(, q), implies value extended SSATformula (, , q) value bounded query (N , Sov, ).SSAT particular case extended-SSAT therefore covered. SAT, MAJSAT, EMAJSAT, QBF also particular cases extended SSAT. result, instancesPFU bounded queries. precisely, SAT corresponds bounded query formQ = (N , (max, V ), 1); MAJSAT (given boolean formula set variables V ,satisfied least half assignments V ) corresponds bounded queryform (N , (+, V ), 0.5); E-MAJSAT (given boolean formula V = VD ,exist assignment VD formula satisfied least half assignments?) corresponds bounded query form (N , (max, VD ).(+, ), 0.5); QBF478fiThe PFU Frameworkcorresponds bounded query max existentially quantified variables minuniversally quantified variables alternate.4. (Solving Quantified CSP (QCSP), Bordeaux & Monfroy, 2002 )QCSP represents formula form Q1 x1 . . . Qn xn (C1 . . . Cm ), Qiquantifier ( ) Ci constraint. value QCSP defined recursivelyfollows: value QCSP without variables (i.e. containing t, f , connectives)given definition connectives. QCSP x qcsp iff either qcsp((x, t)) =qcsp((x, f )) = t. Assuming f t, gives x qcsp iff maxx qcsp = t. QCSP x qcspiff qcsp((x, t)) = qcsp((x, f )) = t. Equivalently, x qcsp iff minx qcsp = t.implies value QCSP actually given formula op(Q1 )x1 . . . op(Qn )xn (C1. . . Cm ), op() = max op() = min. corresponds answer query(N , (op(Q1 ), x1 ). . . . .(op(Qn ), xn )), N = (V, G, , , U ) (V set variablesQCSP, G DAG one decision component containing variables, Uset constraints), expected utility structure boolean optimistic expectedconjunctive utility (row 6 Table 1).5. (Solving mixed CSP probabilistic mixed CSP, Fargier et al., 1996 )probabilistic mixed CSP defined (i) set variables partitioned set Wcontingent variables set X decision variables; assignment AW W calledworld assignment AX X called decision; (ii) set C = {C1 , . . . , Cm }constraints involving least one decision variable; (iii) probability distribution PWworlds; possible world AW (i.e. PW (AW ) > 0) covered decision AX iffassignment AW .AX satisfies constraints C.one hand, decision must made without knowing world, task findoptimal non-conditional decision, i.e. find assignment AX decision variablescovered AX . probability equalP maximizes probability worldPP(A)=(PWW C1 . . . Cm ). result, optimalAW | (C1 ...Cm )(AX ,AW )=1 WWnon-conditionalPdecision found recording optimal decision rule Xformula maxX W (PW C1 . . . Cm ). previous formula actually specifiessolve problem PFUs. algebraic structure probabilistic expected additiveutility (row 2 Table 1), PFU network N = (V, G, P, , U ), VD = X, = W ,G DAG without arc, one decision component X set environment componentsdepends PW specified, P set multiplicative factors define PW ,finally U = {C1 , . . . , Cm }. query Q = (N , (max, X).(+, W )).hand, world known decision made, task lookoptimal conditional decision, i.e. look decision rule 0 : dom(W ) dom(X)maximizes probabilityP world covered. words, goal computemax:dom(W )dom(X) AW dom(W ) | (C1 ...Cm )(AW .(AW ))=1 PW (AW ) =Pmax:dom(W )dom(X) AW dom(W ) (PW C1 . . . Cm ) (AW .(AW )). Due Lemma 3,Palso equals W maxX (PW C1 . . . Cm ), 0 found recording optimaldecision rule X. proves query Q = (N , (+, W ).(max, X)) enables us computeoptimal conditional decision.Mixed CSPs, PW replaced set K constraints defining possible worlds.goal look decision, either conditional non-conditional, maximizesnumber covered worlds. task equivalent, ignoring normalizing constant, finddecision maximizes percentage covered worlds. solved using setplausibility functions P = K {N0 }, N0 normalizing constant ensuringnormalization condition plausibilities holds. N0 number possible worlds,actually need computed, since constant factor interestedoptimal decisions.479fiPralet, Verfaillie, & Schiex6. (Stochastic CSP (SCSP) stochastic COP (SCOP), Walsh, 2002 )Formally, SCSP tuple (V, S, P, C, ), V list variables (each variable xfinite domain dom(x)), set stochastic variables V , P = {Ps | S}set probability distributions (in advanced version SCSPs, probabilitiesmay defined Bayesian network; subsumption result still valid case),C = {C1 , . . . , Cm } set constraints, threshold [0, 1].SCSP-policy tree internal nodes labeled variables. root labeledfirst variable V , parents leaves labeled last variableV . Nodes labeled decision variable one child, whereas nodes labeledstochastic variable |dom(s)| children. Leaf nodes labeled 1 completeassignment define satisfies theQconstraints C, 0 otherwise. leafnode associated probability sS Ps (AS ), stands assignmentimplicitly defined path root leaf. satisfaction SCSP-policysum values leaves weighted probabilities. SCSP satisfiableiff exists SCSP-policy satisfaction least . optimal satisfactionSCSP maximum satisfaction SCSP-policies.subsumption proof, first consider problem looking optimal satisfaction SCSP. SCSP-policy, decision variable x take one value perassignment set preds (x) stochastic variables precede x list variables V . Instead described tree, SCSP-policy viewed setxfunctions=(x)) dom(x)), x V S}, value val() =PQ { : dom(predQ(PCx (AS ))). goal maximize previAS dom(S)sSCi C )(AS .(xVous quantity among sets . Let last decision variable V , let setlocal functions : dom(preds (y))definingrule y.X dom(y)XYa decision(val() = maxPsCi )(AS .( x (AS ))).maxdom(preds (y)) Spreds (y) sSCi CxValso equals:P Lemma 3,Pprevious quantityQQmaxPpreds (y))Spreds (y)sSCi C Ci . recursive application mechanism shows answer Ans(Q) query Q described equal optimalsatisfaction SCSP:expected utility structure: row 2 Table 1 (probabilistic expected satisfaction);PFU network: N = (V 0 , G, P, , U ), V 0 set variables SCSP; =VD = V 0 S; G DAG without arcs, one component per variable; P ={Ps | S}; F act({s}) = {Ps }; U set constraints SCSP;query: Q =(N , Sov), Sov=t(V ) (V thelist variables SCSP), t(V )(+, {x}).t(V 00 ) x.recursively defined t() = t(x.V 00 ) =(max, {x}).t(V 00 ) otherwiseoptimal SCSP-policy recorded evaluation Ans(Q). satisfiabilitySCSP answered bounded query (N , Sov, ). Again, correspondingSCSP-policy obtained recording optimal decision rules.Stochastic Constraint Optimization Problem (SCOP), constraints C additivesoft constraints. subsumption proof similar.7. (Classical planning problems (STRIPS planning), Fikes & Nilsson, 1971; Ghallab et al., 2004 )order search plan length lesser k, simply model classical planning problem CSP. transformation already available literature (Ghallabet al., 2004). However, also model classical planning problem directlyPFU framework. precisely, state one step described set boolean480fiThe PFU Frameworkenvironment variables. step, unique decision variable whose set values corresponds actions available. Plausibility functions deterministic linkvariables step variables step + 1 (these functions simply specify positivenegative effects actions). initial state also represented plausibility functionlinks variables first step. Feasibility functions define preconditions actionfeasible. link variables step decision variable step. Utilityfunctions boolean functions describe goal states. hold variablesstep k. order search plan length lesser k, sequence eliminationmax-elimination variables. expected utility structure used boolean optimisticexpected disjunctive utility.8. (Influence diagrams, Howard & Matheson, 1984 )start definition influence diagrams Section 3. decision variabled, associate decision rule : dom(paG (d)) dom(d). influence diagram policy(ID-policy) set = { | D} decision rules (one decision variable).value val() ID-policy XgivenYby probabilisticX expectation utility:((Ps | paG (s) ) (Ui ))(AS .( (AS ))).val() =dom(S)Ui UsSdDsolve influence diagram, must compute maximum value previous quantity find associated optimal ID-policy. Using Lemma 3 DAG structure,possible show, using ideas SCSP subsumption proof, optimalexpected utility given answer query Q (associated optimal decision rulesrecorded evaluation Ans(Q)):expected utility structure: row 1 Table 1 (probabilistic expected additive utility);PFU network: N = (V, G0 , P, , U ); V set variables influence diagram,G0 DAG obtained DAG influence diagram removing utilitynodes arcs decision nodes; G0 , one component per variable; P ={Ps | paG (s) , } F act({s}) = {Ps | paG (s) }; U set utility functionsassociated utility nodes.PFU query: Q = (N , Sov), Sov obtained DAG influence diagramfollows. Initially, Sov = . DAG influence diagram, decisions totallyordered. Let first decision variable DAG G influence diagram (i.e.decision variable parent decision variable). Then, repeatedly update SovSov Sov.(+, paG (d)).(max, {d}) delete variables paG (d) Gdecision variable remains. Then, perform Sov Sov.(+, S), setchance variables deleted G.9. (Finite horizon MDPs, Puterman, 1994; Monahan, 1982; Sabbadin, 1999; Boutilier et al.,1999, 2000 ) order prove encoding PFU framework given Sections 5.66.6 actually enables us solve time-steps probabilistic MDP, start remindingalgorithm used compute optimal MDP-policy. Usually, decision rule dTchosen computing VsT = maxdT RsT ,dT . VsT optimal reward obtainedstate sT . AtPtime-step [1, [, decision rule di chosen computing Vsi =maxdi (Rsi ,di + si+1 Psi+1 | si ,di Vsi+1 ). Last, optimal expected value reward,depends initial state s1 , Vs1 .Let us prove inductionforP[1,PQ 1],PVs1 = maxd1 s2 . . .maxdi si+1 (( k[1,i] Psk+1 | sk ,dk ) (( k[1,i] Rsk ,dk ) + Vsi+1 )).proposition holds = 1, since PVs1 = maxd1 (RP s1 ,d1 + s2 Ps2 | s1 ,d1 Vs2)P= maxd1 s2 (Ps2 | s1 ,d1 (Rs1 ,d1 + Vs2 )) (since s2 Ps2 | s1 ,d1 = 1).481fiPralet, Verfaillie, & SchiexMoreover, propositionholds PstepQi 1 (with > 1), PPVs1 = maxd1 s2 . . . maxdi1 si (( k[1,i1] Psk+1 | sk ,dk ) (( k[1,i1] Rsk ,dk ) + Vsi )).GivenPPP( k[1,i1] Rsk ,dk ) + Vsi = ( k[1,i1] Rsk ,dk ) + maxdi (Rsi ,di + si+1 Psi+1 | si ,di Vsi+1 )PP= maxdi (( k[1,i] Rsk ,dk ) + si+1 Psi+1 | si ,di Vsi+1 )PP= maxdi si+1 Psi+1 | si ,di (( k[1,i] Rsk ,dk ) + Vsi+1 )P(the last equality holds since si+1 Psi+1 | si ,di = 1), inferredQP( k[1,i1] Psk+1 | sk ,dk ) (( k[1,i1] Rsk ,dk ) + Vsi )PQP= maxdi si+1 (( k[1,i] Psk+1 | sk ,dk ) (( k[1,i] Rsk ,dk ) + Vsi+1 )),proves proposition holds step i. proves also holds step ,therefore Vs1 = Ans(Q). Furthermore, step proof preserves set optimaldecision rules, optimal MDP-policy recorded evaluation Ans(Q).study case partially observable finite horizon MDPs (finite horizon POMDPs).POMDP, add time step > 1 conditional probability distribution Pot | stmaking observation ot time step given state st . value st remains unobserved. also assume probability distribution Ps1 initial state available.subsumption proof case difficult. consider approach POMDPsconsists finding optimal policy tree. approach equivalent compute,decision variable dt , decision rule dt depending observations madefar, i.e. function dt : dom({o2 , . . . , ot }) dom(dt ). set functions denoteddt . set = {d1 , . . . , dT } called POMDP-policy. value POMDP-policyrecursively defined follows. First, value reward last decision step,depends assignment AsT sT observations O2T madebeginning, V ()sT ,o2 ,...,ot (AsT .O2T ) = RsT ,dT (AsT , dT (O2T )). time step i,obtained reward depends actual state Asi observations O2i made far.expression is:V ()si ,o2 ,...,oPPi (Asi .O2i )= (Rsi ,di + si+1 Psi+1 | si ,di oi+1 Poi+1 | si+1 V ()si+1 ,o1 ,...,oi+1 )(A)= Asi .di (O2i ).O2i equation recursive formula used definevalue policy tree POMDP (Kaelbling, Littman, & Cassandra,P1998) equivalent. Finally, expected reward POMDP-policy V () = s1 Ps1 V ()s1 .Solving finite horizon POMDP consists computing optimal expected reward amongPOMDP-policies (i.e. computing V = maxd1 ,...,dT V ({d1 , . . . , dT })), wellassociated optimal decision rules.Using proof induction observable MDP case, first possible proveproblem steps, PPV = maxd1 ,...,dT o2 ,...,oT s1 ,...,sT VQQPV = (Ps1 i[1,T [ Psi+1 | si ,di i[1,T [ Poi+1 | si+1 ) ( i[1,T ] Rsi ,di ).this, recursive use Lemma3 enablesPP us inferPthatPV = maxd1 o2 maxd2 o3 maxd3 . . . oT maxdT s1 ,...,sT V .proves query defined enables us compute V well optimal policy:algebraic structure: probabilistic expected additive utility (row 1 Table 1);PFU network: N = (V, G, P, , U ); V equals {si | [1, ]} {oi | [2, ]} {di |[1, ]}, VD = {di | [1, ]}; G DAG one variable per component;decision component parents, environment component {oi }{si } parent, component {si+1 } {si } {di } parents; P = {Ps1 }{Psi+1 | si ,di , [1, 1]} {Poi | si | [2, ]}; F act({s1 }) = {Ps1 }, F act({si+1 }) ={Psi+1 | si ,di }, F act({oi }) = {Poi | si }; last, U = {Rsi ,di | [1, ]};482fiThe PFU FrameworkPFU query: based DAG, necessary condition query defineddecision di must appear left variables {sk | k [i + 1, ]} {ok | k[i + 1, ]}; query considered Q = (N , Sov),Sov = (max, d1 ).(+, o2 ).(max, d2 ). . . . .(+, oT ).(max, dT ).(+, {s1 , . . . , sT }).proofs finite horizon (PO)MDPs based possibilities -rankings similar.subsumption factored MDPs, first argue every factored MDPrepresented usual MDP, therefore PFU query PFU network. Evensufficient argument, define better representation factored MDPsPFU framework: corresponds representation variables describing statesdirectly used together local plausibility functions rewards, modeledscoped functions (defined decision trees, binary decision diagrams. . . ).10. (Queries Bayesian networks, Pearl, 1988, Markov random fields, Chellappa & Jain, 1993,chain graphs, Frydenberg, 1990 )suffices consider chain graphs, since Bayesian networks Markov random fieldsparticular cases chain graphs. subsumption proofs provided general caseplausibility distributions defined totally ordered conditionable plausibility structure.(a) (MAP, MPE, probability evidence) MPE (Most Probable Explanation)computation probability evidence particular cases MAP (MaximumPosteriori hypothesis), suffices prove MAP subsumed. probabilisticMAP problem consists finding, given probability distribution PV , MaximumPosteriori explanation assignment subset V observed (alsocalled evidence). formally, let denote set variables explanationsought let e denote observed assignment O. MAP problem consistsfinding assignment maxAdom(D) PD | (A.e) = PD | (A .e).PD | = PD,O /PO , write:maxAdom(D) PD | (A.e) = (maxAdom(D) PPD,O (A.e))/PO (e)= (maxAdom(D) A0 dom(V (DO)) PV (A.e.A0 ))/PO (e)PThus, computing maxD V (DO) PV (e) sufficient (the difference lies normalizing constant). result generalized totally ordered conditionableplausibility structures.Indeed, p monotonic, maxAdom(D) PD,O (A.e) = (maxAdom(D) PD | (A.e)) pPO (e). maxAdom(D) PD,O (A.e) p PO (e), exists unique p EpmaxAdom(D) PD,O (A.e) = p p PO (e). gives us p = maxAdom(D) PD | (A.e).Otherwise, maxAdom(D) PD,O (A.e) = PO (e), infer existsdom(D) PD,O (A .e) = PO (e), therefore PD | (A .e) = 1p . Thus,maxAdom(D) PD | (A.e) = 1p too. shows determining maxAdom(D) PD,O (A.e)gives maxAdom(D) PD | (A.e).Moreover, argmax{PD,O (A0 .e), A0 dom(D)}, max{p Ep | PD,O (A .e) =p p PO (e)} p max{p Ep | PD,O (A.e) = p p PO (e)} dom(D). Therefore, optimal assignment maxD PD,O (e) also optimal assignmentmaxD PD | (e). result, MAP problem reduced computationmaxD PD,O (e) = maxD p V (DO) PV (e) = maxD p V (PV p )scoped function scope (e0 ) = 1p e0 = e, 0p otherwise. define PFU query whose answer Ans(Q) = maxD p V (PV p ):plausibility structure (Ep , p , p ), utility structure (Eu , u ) = (Ep , p ),expected utility structure (Ep , Eu , u , pu ) = (Ep , Ep , p , p );PFU network: difficulty definition PFU network lies factnormalization conditions components must satisfied. idea483fiPralet, Verfaillie, & Schiexcomponents variable involved modified. PFUnetwork N = (V, G, P, , U ); V set variables chain graph; VD == V D; G DAG components obtained DAG G0 chaingraph splitting every component c variable involved:component c transformed |c| components containing one variable;|c| components become parents child components c; component{x0 } included one |c| components, x0 D, {x0 } decisioncomponent; otherwise, {x0 } environment component, create plausibility function Pi , equal constant p0 (x0 ) p i[1,|dom(x0 )|] p0 (x0 ) = 1p ,F act({x0 }) = {p0 (x0 )}; P contains first constants defined above,second factors expressing Pc | paG0 (c) chain graph componentsc satisfying c (D O) = ; last, U contains factors expressing Pc | paG0 (c)chain graph components c c (D O) 6= , constant factorp1 (x0 ) satisfying p1 (x0 ) p p0 (x0 ) = 1p component {x0 } createdsplitting process described above, hard constraints representing ;PFU network, local normalization conditions satisfied, combinationlocal functions equals PV p ;PFU query: query simply Q = (N , (max, D).(u , V D)).optimal decision rule recorded computation Ans(Q).(b) (Plausibility distribution computation task ) Given plausibility distribution PV expressed combination plausibility functions chain graphs, goalcompute plausibility distribution PS set V . basic formula PS =p V PV proves query defined actually computes PS . query showsusefulness free variables.plausibility structure (Ep , p , p ), utility structure (Eu , u ) = (Ep , p ),expected utility structure (Ep , Eu , u , pu ) = (Ep , Ep , p , p );PFU network: N = (V, G, P, , U ), = V S, VD = S, DAGG sets P , U obtained similarly MAP case;PFU query: Q = (N , (u , V S))11. (Hybrid networks, Dechter & Larkin, 2001 )hybrid network triple (G, P, F ), G DAG set variables V partitionedR D, P set probability distributions expressing Pr | paG (r) r R,F set functions fpaG (d) (variables deterministic,sense value completely determined assignment parents).general task hybrid networks task belief assessment conditioned formula conjunctive normal form. consists computing probability distributionvariable x given complex evidence (complex may involve several variables).P Ignoring normalizing constant, requires compute, assignments (x, a)x, Adom(V {x}) | (A.(x,a))=t PV (A.(x, a)). C = {C1 , . . . , Cm } denotes set clausesPQQQ, also equals ( V {x} ( rR Pr | paG (r) ) ( dD fpaG (d) ) ( Ci C Ci ))((x, a)).query corresponding computation uses probabilistic expected satisfaction structure (row 2 Table 1), PFU network N = (V, G, P, , U ), = V , VD = {x},P = {Pr | paG (r) | r R {x}} {fpaG (d) | {x}}, either U = C {Px | paG (x) }x R U = C {fpaG (x) } x D. query Q = (N , (+, V {x})).484fiThe PFU FrameworkReferencesBacchus, F., & Grove, A. (1995). Graphical Models Preference Utility. Proc.11th International Conference Uncertainty Artificial Intelligence (UAI-95),pp. 310, Montreal, Canada.Bahar, R., Frohm, E., Gaona, C., Hachtel, G., Macii, E., Pardo, A., & Somenzi, F. (1993).Algebraic Decision Diagrams Applications. IEEE /ACM InternationalConference CAD, pp. 188191, Santa Clara, California, USA. IEEE ComputerSociety Press.Bertele, U., & Brioschi, F. (1972). Nonserial Dynamic Programming. Academic Press.Bistarelli, S., Montanari, U., Rossi, F., Schiex, T., Verfaillie, G., & Fargier, H. (1999).Semiring-Based CSPs Valued CSPs: Frameworks, Properties Comparison.Constraints, 4 (3), 199240.Bodlaender, H. (1997). Treewidth: Algorithmic techniques results. Proc.22nd International Symposium Mathematical Foundations Computer Science(MFCS-97).Bordeaux, L., & Monfroy, E. (2002). Beyond NP: Arc-consistency Quantified Constraints. Proc. 8th International Conference Principles PracticeConstraint Programming (CP-02), Ithaca, New York, USA.Boutilier, C., Brafman, R., Domshlak, C., Hoos, H., & Poole, D. (2004). CP-nets: ToolRepresenting Reasoning Conditional Ceteris Paribus Preference Statements.Journal Artificial Intelligence Research, 21, 135191.Boutilier, C., Dean, T., & Hanks, S. (1999). Decision-Theoretic Planning: Structural Assumptions Computational Leverage. Journal Artificial Intelligence Research,11, 194.Boutilier, C., Dearden, R., & Goldszmidt, M. (2000). Stochastic Dynamic ProgrammingFactored Representations. Artificial Intelligence, 121 (1-2), 49107.Boutilier, C., Friedman, N., Goldszmidt, M., & Koller, D. (1996). Context-Specific Independence Bayesian Networks. Proc. 12th International ConferenceUncertainty Artificial Intelligence (UAI-96), pp. 115123, Portland, Oregon, USA.Chellappa, R., & Jain, A. (1993). Markov Random Fields: Theory Applications. Academic Press.Chu, F., & Halpern, J. (2003a). Great Expectations. Part I: CustomizabilityGeneralized Expected Utility. Proc. 18th International Joint ConferenceArtificial Intelligence (IJCAI-03), Acapulco, Mexico.Chu, F., & Halpern, J. (2003b). Great Expectations. Part II: Generalized Expected UtilityUniversal Decision Rule. Proc. 18th International Joint ConferenceArtificial Intelligence (IJCAI-03), pp. 291296, Acapulco, Mexico.Cooper, M., & Schiex, T. (2004). Arc Consistency Soft Constraints. Artificial Intelligence, 154 (1-2), 199227.Darwiche, A. (2001). Recursive Conditioning. Artificial Intelligence, 126 (1-2), 541.485fiPralet, Verfaillie, & SchiexDarwiche, A., & Ginsberg, M. (1992). Symbolic Generalization Probability Theory.Proc. 10th National Conference Artificial Intelligence (AAAI-92), pp.622627, San Jose, CA, USA.Dechter, R. (1999). Bucket Elimination: Unifying Framework Reasoning. ArtificialIntelligence, 113 (1-2), 4185.Dechter, R., & Fattah, Y. E. (2001). Topological Parameters Time-Space Tradeoff.Artificial Intelligence, 125 (1-2), 93118.Dechter, R., & Larkin, D. (2001). Hybrid Processing Beliefs Constraints. Proc.17th International Conference Uncertainty Artificial Intelligence (UAI-01),pp. 112119, Seattle, WA, USA.Dechter, R., & Mateescu, R. (2004). Mixtures Deterministic-Probabilistic NetworksAND/OR Search Space. Proc. 20th International ConferenceUncertainty Artificial Intelligence (UAI-04), Banff, Canada.Demirer, R., & Shenoy, P. (2001). Sequential Valuation Networks: New Graphical Technique Asymmetric Decision Problems. Proc. 6th European ConferenceSymbolic Quantitavive Approaches Reasoning Uncertainty (ECSQARU01), pp. 252265, London, UK.Dubois, D., & Prade, H. (1995). Possibility Theory Basis Qualitative DecisionTheory. Proc. 14th International Joint Conference Artificial Intelligence(IJCAI-95), pp. 19251930, Montreal, Canada.Fargier, H., Lang, J., & Schiex, T. (1996). Mixed Constraint Satisfaction: FrameworkDecision Problems Incomplete Knowledge. Proc. 13th NationalConference Artificial Intelligence (AAAI-96), pp. 175180, Portland, OR, USA.Fargier, H., & Perny, P. (1999). Qualitative Models Decision Uncertainty withoutCommensurability Assumption. Proc. 15th International ConferenceUncertainty Artificial Intelligence (UAI-99), pp. 188195, Stockholm, Sweden.Fikes, R., & Nilsson, N. (1971). STRIPS: New Approach Application TheoremProving. Artificial Intelligence, 2 (3-4), 189208.Fishburn, P. (1982). Foundations Expected Utility. D. Reidel Publishing Company,Dordrecht.Friedman, N., & Halpern, J. (1995). Plausibility Measures: Users Guide. Proc.11th International Conference Uncertainty Artificial Intelligence (UAI-95), pp.175184, Montreal, Canada.Frydenberg, M. (1990). Chain Graph Markov Property. Scandinavian JournalStatistics, 17, 333353.Ghallab, M., Nau, D., & Traverso, P. (2004). Automated Planning: Theory Practice.Morgan Kaufmann.Giang, P., & Shenoy, P. (2000). Qualitative Linear Utility Theory Spohns TheoryEpistemic Beliefs. Proc. 16th International Conference UncertaintyArtificial Intelligence (UAI-00), pp. 220229, Stanford, California, USA.486fiThe PFU FrameworkGiang, P., & Shenoy, P. (2005). Two Axiomatic Approaches Decision Making UsingPossibility Theory. European Journal Operational Research, 162 (2), 450467.Goldman, R., & Boddy, M. (1996). Expressive Planning Explicit Knowledge. Proc.3rd International Conference Artificial Intelligence Planning Systems (AIPS96), pp. 110117, Edinburgh, Scotland.Halpern, J. (2001). Conditional Plausibility Measures Bayesian Networks. JournalArtificial Intelligence Research, 14, 359389.Halpern, J. (2003). Reasoning Uncertainty. MIT Press.Howard, R., & Matheson, J. (1984). Influence Diagrams. Readings PrinciplesApplications Decision Analysis, pp. 721762. Strategic Decisions Group, MenloPark, CA, USA.Jegou, P., & Terrioux, C. (2003). Hybrid Backtracking bounded Tree-decompositionConstraint Networks. Artificial Intelligence, 146 (1), 4375.Jensen, F., Nielsen, T., & Shenoy, P. (2004). Sequential Influence Diagrams: UnifiedAsymmetry Framework. Proceedings Second European Workshop Probabilistic Graphical Models (PGM-04), pp. 121128, Leiden, Netherlands.Jensen, F., & Vomlelova, M. (2002). Unconstrained Influence Diagrams. Proc.18th International Conference Uncertainty Artificial Intelligence (UAI-02), pp.234241, Seattle, WA, USA.Kaelbling, L., Littman, M., & Cassandra, A. (1998). Planning Acting PartiallyObservable Stochastic Domains. Artificial Intelligence, 101 (1-2), 99134.Kolhas, J. (2003). Information Algebras: Generic Structures Inference. Springer.Kushmerick, N., Hanks, S., & Weld, D. (1995). Algorithm Probabilistic Planning.Artificial Intelligence, 76 (1-2), 239286.Larrosa, J., & Schiex., T. (2003). quest best form local consistencyweighted csp. Proc. 18th International Joint Conference Artificial Intelligence (IJCAI-03), Acapulco, Mexico.Lauritzen, S., & Nilsson, D. (2001). Representing Solving Decision ProblemsLimited Information. Management Science, 47 (9), 12351251.Littman, M., Majercik, S., & Pitassi, T. (2001). Stochastic Boolean Satisfiability. JournalAutomated Reasoning, 27 (3), 251296.Mackworth, A. (1977). Consistency Networks Relations. Artificial Intelligence, 8 (1),99118.Monahan, G. (1982). Survey Partially Observable Markov Decision Processes: Theory,Models, Algorithms. Management Science, 28 (1), 116.Ndilikilikesha, P. (1994). Potential Influence Diagrams. International Journal Approximated Reasoning, 10, 251285.Nielsen, T., & Jensen, F. (2003). Representing solving asymmetric decision problems.International Journal Information Technology Decision Making, 2, 217263.487fiPralet, Verfaillie, & SchiexPearl, J. (1988). Probabilistic Reasoning Intelligent Systems: Networks Plausible Inference. Morgan Kaufmann.Perny, P., Spanjaard, O., & Weng, P. (2005). Algebraic Markov Decision Processes.Proc. 19th International Joint Conference Artificial Intelligence (IJCAI05), Edinburgh, Scotland.Pralet, C. (2006). Generic Algebraic Framework Representing Solving Sequential Decision Making Problems Uncertainties, Feasibilities, Utilities. Ph.D.thesis, Ecole Nationale Superieure de lAeronautique et de lEspace, Toulouse, France.Pralet, C., Schiex, T., & Verfaillie, G. (2006a). Decomposition Multi-Operator QueriesSemiring-based Graphical Models. Proc. 12th International ConferencePrinciples Practice Constraint Programming (CP-06), pp. 437452, Nantes,France.Pralet, C., Schiex, T., & Verfaillie, G. (2006b). Influence Diagrams MultioperatorCluster DAGs. Proc. 22nd International Conference UncertaintyArtificial Intelligence (UAI-06), Cambridge, MA, USA.Pralet, C., Verfaillie, G., & Schiex, T. (2006c). Decision Uncertainties, Feasibilities,Utilities: Towards Unified Algebraic Framework. Proc. 17th EuropeanConference Artificial Intelligence (ECAI-06), pp. 427431, Riva del Garda, Italy.Puterman, M. (1994). Markov Decision Processes, Discrete Stochastic Dynamic Programming. John Wiley & Sons.Sabbadin, R. (1999). Possibilistic Model Qualitative Sequential Decision ProblemsUncertainty Partially Observable Environments. Proc. 15th International Conference Uncertainty Artificial Intelligence (UAI-99), pp. 567574,Stockholm, Sweden.Sang, T., Beame, P., & Kautz, H. (2005). Solving Bayesian Networks Weighted ModelCounting. Proc. 20th National Conference Artificial Intelligence (AAAI05), pp. 475482, Pittsburgh, PA, USA.Schmeidler, D. (1989). Subjective Probability Expected Utility without Additivity.Econometrica, 57 (3), 571587.Schrijver, A. (1998). Theory Linear Integer Programming. John Wiley Sons.Shafer, G. (1976). Mathematical Theory Evidence. Princeton University Press.Shenoy, P. (1991). Valuation-based Systems Discrete Optimization. UncertaintyArtificial Intelligence, 6, 385400.Shenoy, P. (1992). Valuation-based Systems Bayesian Decision Analysis. OperationsResearch, 40 (3), 463484.Shenoy, P. (1994). Conditional Independence Valuation-Based Systems. InternationalJournal Approximated Reasoning, 10 (3), 203234.Shenoy, P. (2000). Valuation Network Representation Solution Asymmetric DecisionProblems. European Journal Operational Research, 121, 579608.488fiThe PFU FrameworkSmith, J., Holtzman, S., & Matheson, J. (1993). Structuring Conditional RelationshipsInfluence Diagrams. Operations Research, 41, 280297.Spohn, W. (1990). General Non-Probabilistic Theory Inductive Reasoning. Proc.6th International Conference Uncertainty Artificial Intelligence (UAI-90),pp. 149158, Cambridge, MA, USA.von Neumann, J., & Morgenstern, O. (1944). Theory Games Economic Behaviour.Princeton University Press.Walsh, T. (2002). Stochastic Constraint Programming. Proc. 15th EuropeanConference Artificial Intelligence (ECAI-02), pp. 111115, Lyon, France.Weydert, E. (1994). General Belief Measures. Proc. 10th International ConferenceUncertainty Artificial Intelligence (UAI-94), pp. 575582.Wilson, N. (1995). Order Magnitude Calculus. Proc. 11th InternationalConference Uncertainty Artificial Intelligence (UAI-95), pp. 548555, Montreal,Canada.489fiJournal Artificial Intelligence Research 29 (2007) 1-18Submitted 07/06; published 05/07Phase Transition Random Quantified XOR-FormulasNadia Creignoucreignou@lif.univ-mrs.frLIF, UMR CNRS 6166Universite de la Mediterranee163, avenue de Luminy13 288 Marseille, FranceHerve Daudedaude@gyptis.univ-mrs.frLATP, UMR CNRS 6632Universite de Provence39, rue Joliot-Curie13 453 Marseille, FranceUwe Eglyuwe@kr.tuwien.ac.atInstitut fur Informationssysteme 184/3Technische Universitat WienFavoritenstrae 911A1040 Wien, AustriaAbstractQXOR-SAT problem quantified version satisfiability problem XOR-SATconnective exclusive-or used instead usual or. study phasetransition associated random QXOR-SAT instances. give descriptionphase transition case one alternation quantifiers, thus performing advancedpractical theoretical study phase transition quantified problem.1. Introductionlast decade seen growth interest phase transition Boolean satisfiability(SAT). clausal version problem shows sharp transition sense that,density clauses increased, formulas abruptly change satisfiableunsatisfiable critical threshold point. Numerous experimental studiesperformed investigation phase transition different variants SAT problems,thus giving strong evidence location transition coincides instanceshard solve. meantime, theoretical studies conducted orderbetter understand transitions. Determining nature phase transition (sharpcoarse)1 , locating it, determining precise scaling window better understandingstructure space solutions turn challenging tasks,aroused lot interest different communities, namely mathematics, computer sciencestatistical physics (see e.g., Dubois, Monasson, Selman, & Zecchina, 2001).computer science point view, success SAT problem due two features.problem SAT provides framework problems within complexity class NP1. Definitions sharp coarse phase transitions found p. 21 (Janson, Luczak, & Rucinski,2000).c2007AI Access Foundation. rights reserved.fiCreignou, Daude, & Eglyadequately expressed, moreover practically efficient highly optimized solversavailable.order obtain even stronger systems, many researchers turned powerfulgeneralization Boolean satisfiability, QSAT, universal existential quantifiers Boolean variables permitted. QSAT problem permits adequaterepresentation modeling problems higher complexitywithin complexityclass PSPACEand coming various fields computer science knowledge representation, verification logic. Recently, random instances quantified problemsstarted attract attention (see Gent & Walsh, 1999; Chen & Interian, 2005).Models generating random instances developed, experimental studiesshown models QSAT property undergoes phase transitionqualitatively similar one appears ordinary SAT property. statedChen Interian (2005), hope research developing competitive solversquantified Boolean formulas could benefit better understanding typical behavior random instances. study follows pioneering work Chen Interian(2005) made precise promising model generating random instancesQSAT problem. use model apply satisfiability problem QXOR-SATpresent below.difficulty identifying transition factors performing theoretical explorationsSAT transition incited many researchers turn variant SAT problem:e-XOR-SAT problem. satisfiability problem deals Boolean formulas conjunctive normal form e variables per clause, usual replacedexclusive (we call clauses exclusive connective XOR-clauses).problem contributed develop validate techniques, thus revealing typical behaviorsrandom instances space solutions SAT-type problems (see, e.g.,Cocco, Dubois, Mandler, & Monasson, 2003; Creignou & Daude, 2003; Dubois, Boufkhad,& Mandler, 2000; Dubois & Mandler, 2002; Franz, Leone, Ricci-Tersenghi, & Zecchina,2001). Therefore, order understand phase transitions evolve satisfiabilityintroducing quantified variables, quite natural consider problem.Although phase transition random k-SAT yet well understood, generalization quantified version started years. hope generalizationproblem help understanding original one. Another way gaining insighthard problem look tractable variants. reasons paperembark theoretical study phase transition QXOR-SAT problem,quantified version XOR-SAT problem. Let us emphasize quantifiedproblem is, usual XOR-SAT problem, P, hence permit us provide experiments large scale, thus giving useful intuition asymptotical behavior randominstances. order efficiently solve instance XOR-SAT problem, clause setrewritten set equations coefficients finite field GF (2) Gaussianelimination performed resulting set equations. Gaussian elimination followedexamination quantifier structure provides algorithm quantified versionXOR-SAT problem (for details, see Creignou, Khanna, & Sudan, 2001, chap. 6.4).Following previous studies conducted Gent Walsh (1999) well ChenInterian (2005), focus formulas conjunctive normal form two quantifier2fiPhase Transition Random Quantified XOR-Formulasblocks, namely formulas type XY (X, ), X denote distinct setsvariables, (X, ) conjunction XOR-clauses. Moreover, variable occurring(X, ) occurs X , i.e., formula XY (X, ) closed. model severalparameters. First consider (a,e)-QXOR-formulas, clauseexactly (a + e) variables, X e . (a,e)-QXOR-SAT propertyproperty formula true. second parameter pair (m, n) specifyingnumber variables quantifier block, i.e., X . third parameter L,number clauses. sum up, generated formulas form XY (X, ),X variables, n variables, clause variables X etotal number L clauses . interested probabilityformula drawn random uniformly set formulas true n tendsinfinity (Section 2). prove nature phase transition (coarse sharp)(a,e)-QXOR-SAT governed number existential variables occurring clause.e = 2 1, prove Section 3 (a,2)-QXOR-SAT coarse phasetransition. Moreover give expression distribution function threshold(a,2)-QXOR-SAT show influenced different parameters model.e 3, prove Section 4 (a,e)-QXOR-SAT sharp phase transitionthusgetting first proof sharp threshold natural quantified satisfiability problem.2. QXOR, XOR Maximal rank Propertysection, relate QXOR XOR Maximal rank property. startdefinitions notations.2.1 Notatione-XOR-clause, C, linear equation finite field GF (2) using exactly e distinctvariables, C = ((x1 . . . xe ) = ) = 0 1.e-XOR-formula, , conjunction necessarily distinct e-XOR-clauses.truth assignment mapping assigns 0 1 variable domain, satisfieseXI(xi ) mod 2 =XOR-clause C = ((x1 . . . xe ) = ) I(C) :=i=1satisfies formula satisfies every clause .denote e-XOR-SAT property e-XOR-formula satisfiable.(a,e)-QXOR-formula closed quantified formula following typeXY (X, ),X denote distinct set variables, (X, ) (a + e)-XOR-formulaclause contains exactly variables X exactly e variables .formula true if, every assignment variables X, exists assignmentvariables , true. Observe that, closed formulas, notions truthsatisfiability coincide. reason, use two notions synonymouslyfollowing. denote (a,e)-QXOR-SAT property (a,e)-QXOR-formulatrue.Throughout paper, reserve number universal variables (resp. nnumber existential variables), {x1 , . . . , xm } (resp. {y1 , . . . , yn }) denotes set3fiCreignou, Daude, & Eglyvariables. NotenN=2e(1)(a,e)-XOR-clauses. consider random formulas XY (X, ) obtained choosing uniformly independently replacement L clauses possible N (a,e)-XORclauses. Using terminology Chen Interian (2005), formulas correspond(a,e)-QXOR((m,n),L)-formulas. interested estimating probabilityrandomly chosen (a,e)-QXOR((m,n),L)-formula true. denote probabilityPr(m,n,L) ((a,e)-QXOR-SAT), shortly Pr((a,e)-QXOR-SAT) confusion arise.restricted non-quantified case, e-XOR-SAT, i.e., a=0, omit firstcomponent subscript, thus discussing Prn,L (e-XOR-SAT), shortly Pr(e-XOR-SAT).show behavior (a,e)-QXOR-SAT property boundedtwo monotone properties, namely e-XOR-SAT propertyMaximal rank property. Experiments suggest right parameter order studyproperties c, ratio number clauses number existential variables. Moreover, according results obtained e-XOR-SAT Creignou, Daude,Dubois (2003), know transition occurs c < 1. Therefore, sequelalways suppose without loss generality L n.2.2 Upper Lower Bounds QXOR-SAT PropertyNote random (a,e)-QXOR((m,n),L)-formula also considered quantifiedlinear systemXY (AX + EY = C)(2)coefficient arithmetic GF (2), (respectively E) matrix chosen uniformlyset Boolean L (resp. L n) matrices exactly (respectively e) unitsrow, C Boolean column vector dimension L chosen uniformlyset vectors. Moreover, A, E C chosen independently.Observe quantified linear systemXY (AX + EY = C)consistentX (C AX) Im(E),Im(E) represents image linear application whose matrix representationE, Im(E) = {EY / {0, 1}n }. Hence quantified linear system consistentC Im(E) Im(A) Im(E). Therefore, get:Pr((a,e)-QXOR-SAT) = Pr(XY (AX + EY = C) consistent)= Pr(C Im(E) Im(A) Im(E)).Thus, one handPr((a,e)-QXOR-SAT) Pr(C Im(E)) = Pr(e-XOR-SAT)4fiPhase Transition Random Quantified XOR-Formulasholds, hand, inequalityPr((a,e)-QXOR-SAT) Pr(Im(E) = {0, 1}L )holds. Therefore, Prn,L (e-Max-rank) denotes probability random matrixset L n Boolean matrices e units per row maximal rank, everya, n L n, get following inequalities:Prn,L (e-Max-rank) Pr(m,n,L) ((a,e)-QXOR-SAT) Prn,L (e-XOR-SAT).(3)natural question stage estimate probability random matrixmaximal rank. following provide experiments theoretical resultscomparing behavior three properties, Maximal rank, QXOR-SAT XOR-SAT,thus making precise behavior (a,e)-QXOR-SAT property according valuee.3. Case e = 2section, restrict attention case problems two existentialvariables clause (and number variables allowed vary).3.1 Experimental Resultsorder illustrate inequalities (3) compare empirically three properties,discuss experiments performed. experiments, formulas closed.12-XOR-SAT n=10k(1,2)-QXOR-SAT m=n(2,2)-QXOR-SAT m=n(3,2)-QXOR-SAT m=n(4,2)-QXOR-SAT m=n2-Max-rank n=10k0.90.80.70.60.50.40.30.20.1000.10.20.30.40.50.6#clauses/#exvars0.70.80.91Figure 1: curves (a,2)-QXOR-SAT, = n = 10 000 varying.cases, experiments conducted according scheme. Letus describe detail Figure 1. One experiment consisted generating random (in5fiCreignou, Daude, & Eglydrawing uniformly independently) (1,2)-QXOR-formulas 10 000 existential variables 10 000 universal variables ratio number clauses/number existentialvariables varying 0.1 1 steps 0.05 0.1. chosen valuesratio, sample 1000 formulas studied using algorithm described workCreignou et al. (2001, chap. 6.4), thus deciding truth (or satisfiability) quantifiedformulas. proportion true instances considered value ratio plotted Figure 1. done (a,2)-QXOR-SAT properties. Hence,different curves independent other. 2-XOR-SAT experiment,used selection procedure 10 000 existential variables. Again, Gaussian elimination together examination quantifier structure used determinelogical status (true false) every formula. Additionally, computedwhether matrix E full rank not. curve 2-Max-rank shows proportionsystems full rank corresponds 2-XOR-SAT curve figure.close look Figure 1 reveals points (a,2)-QXOR-SAT curvesslightly (theoretical) lower bound given curve 2-Max-rank. reasonphenomenon independence satisfiability curvesnoise induced finite sampling problems. chosen correspondingproblems exactly existential part (and universal part varies),would got satisfiability curves curve 2-Max-rank.experimental results shown Figure 1 suggest first two bounding properties, namely 2-Max-rank 2-XOR-SAT distinguishable, second that, = n,(a,2)-QXOR-SAT property coincides asymptotically 2-Max-rank property independently 1, number universal variables per clause.1(1,2)-QXOR-SAT m=1, n=10k2-XOR-SAT n=10k2-Max-rank n=10k0.90.80.70.60.50.40.30.20.1000.10.20.30.40.50.6#clauses/#exvars0.70.80.91Figure 2: (1,2)-QXOR-SAT = 1 n = 10 000 compared 2-XOR-SAT2-Max-rank.6fiPhase Transition Random Quantified XOR-Formulasanother scale m, instance constant, experimental results reported Figure 2 suggest (a,2)-QXOR-SAT property two properties 2-Max-rank 2-XOR-SAT.following, validate conjectures suggested experimentsprove property (a,2)-QXOR-SAT coincides asymptotically 2-Max-rankproperty soon tending infinity n, 2-Max-rankproperty 2-XOR property fixed constant. particular, makeclear connection random (a,2)-QXOR-formulas random labelled graphs.3.2 Bad Cycles (a,2)-QXOR-SAT Propertyinterested satisfiability quantified systems form= (XY AX + EY = C),E (respectively A) matrix chosen uniformly set Boolean L n (respectively L m) matrices exactly 2 (respectively a) units row, C randomcolumn vector dimension L, 0 1 occur probability. satisfiability system strongly related existence cycles graphs. Indeed,construct graph Ga (s) n vertices L weighted edges. existential variableyi vertex Ga (s). equation yi yj = xi1 . . . xia , addedge {yi , yj } Ga (s) label xi1 . . . xia . cycle given sequencevertices (yi1 , . . . , yis ) 1 j 1, {yij , yij+1 } edge graph,{yis , yi1 }. cycle said elementary vertices sequencedistinct. weight cycle sum modulo 2 labels edges.Example 3.1 Let X = {x1 , x2 , x3 } let = {y1 , . . . , y7 }. formula XY (X, )(X, ) conjunction following equationsy1 y2y2 y3y3 y4y4 y5====x1x3x2 1x3 1y1 y7y2 y6y3 y5y6 y7====x2x2 1x3x1 1represented graph Figure 3.following, call cycle bad nonzero weight, good otherwise.Example 3.2 graph associated formula described previous example,good cycle, (y1 , y2 , y6 , y7 ), whose weight 0, bad one, (y3 , y4 , y5 ), whoseweight x2 . latter cycle, corresponding equations y3 y4 = x2 1, y3 y5 =x3 , y4 y5 = x3 1. Adding three equations yields equation 0 = x2cannot satisfied x2 X universally quantified.systems containing existential variables, i.e., = 0, observedCreignou Daude (2003) 2-XOR-formula satisfiable graphG0 (s) bad cycle, :Pr(2-XOR-SAT) = Pr(G0 (s) bad cycle).Using similar arguments, get following proposition.7(4)fiCreignou, Daude, & Eglyy1x1y2x3 x2+ 1y3y6x2 + 1y4x2x1 + 1x3y7x3 + 1y5Figure 3: graph Ga (s) Example 3.1 (addition performed mod2).Proposition 3.3 system satisfiable Ga (s) containelementary bad cycle, i.e.,Pr((a,2)-QXOR-SAT) = Pr(Ga (s) bad cycle).Proof: Suppose elementary cycle nonzero weight Ga (s). Clearly,cycle corresponds subsystem s, exists assignment Xassignment satisfy (see Example 3.2 illustration). Hence,unsatisfiable.Conversely, suppose (elementary) cycle nonzero weight Ga (s). Takearbitrary truth assignment (universal) variables X apply Ga (s).Since I(x) {0, 1} x X, weight edge reduced constant{0, 1} addition modulo 2. Moreover, since cycle Ga (s) zero weight,corresponding cycle reduced version, Ga (s), Ga (s) also zero weight.graph Ga (s) corresponds system existential quantifiers only.order obtain satisfying truth assignment existential variables, sufficesapply following procedure connected component Ga (s). Consider arbitraryroot vertex assign arbitrary truth value v it. obtain truth valuevertex Ga (s) performing depth-first search starting y. search,edge (y , ) labelled truth value yet, set valuevalue . assignment obtained way satisfies equationssince Ga (s) contain cycle nonzero weight.Remark: ObservePr(2-Max-rank) = Pr(Ga (s) cycle)holds.8(5)fiPhase Transition Random Quantified XOR-Formulas3.3 Distribution Functions 2-XOR-SAT 2-Max-ranksection, give exact asymptotical value bounds obtained (3)terms order parameter c, c n number clauses. usewell-known results random graph theory.Let us recall consider classical probabilistic model clause/edgechosen uniformly independently amongnN=2epossible ones. According Proposition 1.13 (Janson et al., 2000), choose L = c nclauses, model asymptotically equivalent one clause drawnindependently probability p,cnp = n1 + O(n1/2 )2 2holds. So, following, work random labelled graphs Ga (s) associatedquantified systems s, labelled edge probability:c.p=ncorresponding probability usually denoted p . However, simplicitykeep notation Pr.light Proposition 3.3 (5), appears studyPr(Ga (s) (bad) cycle).asymptotic behavior number cycles random graphs first investigated Erdos Renyi (1960), made precise Janson (1987) Takacs (1988).number converges distribution Poisson law parameter , limitaverage number cycles n, number vertices, tends infinity.result easily extended model labelled graphs. particular,Pr(Ga (s) (bad) cycle) exp(),limit average number (bad) cycles. challenging taskget simple expression lambda.Let random variable counts number cycles. Let C setpossible cycles. cycle c, introduce random variable XcXc (Ga (s)) = 1 holds, Ga (s) contains cycle c. average numbercyclesXXE(Y ) = E(Xc ) =E(Xc ).cCcCSince every cycle c length l expectation E(Xc ) = pl since number cyclesln(n 1) . . . (n l + 1)2l , getlength l2lX n(n 1) . . . (n l + 1) ml2l plE(Y ) =2ll29fiCreignou, Daude, & Eglyholds. Thus,lim E(Y ) =n+X (2c)ll22l1= ln(1 2c) c2also holds. (5), obtain every 0 < c <121lim Pr(n,cn) (2-Max-rank) = exp( ln(1 2c) + c)n+2holds, finallylim Pr(n,cn) (2-Max-rank) = H (c)(6)n+established,(exp(c) (1 2c)1/2H (c) =00 c 21 ,otherwise.experimental results shown Figure 4 illustrate asymptotical behavior.1H (x) = ex 1 2x2-Max-rank n=10k2-Max-rank n=20k2-Max-rank n=40k0.90.80.70.60.50.40.30.20.100.10.20.30.40.50.6#clauses/#exvars0.70.80.91Figure 4: curves 2-Max-rank property.According (4)lim Pr(n,cn) (2-XOR-SAT) = exp(0 )n+holds, 0 denotes limit average number bad cycles. particularcase, weight clause either 0 1, means half cycles bad.Thus,X n(n 1) . . . (n l + 1) ml1c0 = lim2l1 pl = ln(1 2c) .n+2l42l210fiPhase Transition Random Quantified XOR-FormulasTherefore, every c 0, get1clim Pr(n,cn) (2-XOR-SAT) = exp( ln(1 2c) + ),n+42finallylim Pr(n,cn) (2-XOR-SAT) = H0 (c)(7)n+established,(exp(c/2) (1 2c)1/4H0 (c) =00 c 12 ,otherwise.illustrated Figure 5.1H0 (x) = ex/2 (1 2x)0.252-XOR-SAT n=10k2-XOR-SAT n=20k2-XOR-SAT n=40k0.90.80.70.60.50.40.30.20.100.10.20.30.40.50.6#clauses/#exvars0.70.80.91Figure 5: curves 2-XOR-SAT property.3.4 Distribution Function (a,2)-QXOR-SATresults obtained previous section, (6) (7), together inequalities (3)sufficient conclude (a,2)-QXOR-SAT property coarse phase transitionscale L = c n distribution function functions H0H described above. precisely get following theorem.Theorem 3.4 integer 1 every c 0, let us consider (a,2)-QXOR((m,n),cn)formulas consisting conjunction c n XOR-clauses, clause containsvariables set universal variables, e variables set n existentialvariables. Then, n tends infinity, (a,2)-QXOR-SAT property coarse phase11fiCreignou, Daude, & Eglytransition whose asymptotical distribution function expressed function dependingm. precisely, c 0, every 1 =Pr(a,n,cn)((a,2)-QXOR-SAT) n+ H(c)holds,(exp(c)(1 2c)1/2 (1 4c2 )1/8H(c) =00 c 21 ,otherwise.function n tending infinity n, then, every 1,Pr(m,n,cn) ((a,2)-QXOR-SAT) n+ H (c)holds,(exp(c) (1 2c)1/2H (c) =00 c 12 ,otherwise.Moreover, every fixed 1, exists distribution function HmPr(m,n,cn) ((a,2)-QXOR-SAT) n+ Hm (c),Hm satisfyingH < Hm < H0 ,H0 (c) =(exp(c/2)(1 2c)1/400 c 21 ,otherwise.Proof: proof based Proposition 3.3 and, discussed previous section,estimation number bad cycles labelled graphs associated randomformulas.Let m,a limit average number bad cycles. give closedexpression m,a . Observe label edges graph associated(a,2)-QXOR((m,n),cn)-formula formed constant,0 1, variable-label madeuniversal variables. exactly variable-labels, numbered1. One decide whether cycle good bad according number1 (even odd) number occurrences variable-label. Thereforequite natural associate every cycle length l, sequence (N1 , . . . , N(m) )numbers occurrences variable-label, parity = 0 1 numberoccurrences constant 1. limit average number cycles whose parameter(l, (N1 , . . . , N(m) ), ) fixedcl 2l12llN1 ,...,N( )l.Moreover, parameter (l, (N1 , . . . , N(m) ), ), one decide whether cyclebad not.12fiPhase Transition Random Quantified XOR-Formulasbetter readability, let us focus case = 1. particular case, labeledge form xi , = 0 1 1 m. one hand, cyclesodd length bad (for weight cycle least one coefficientsxi nonzero). hand, two kinds cycles even lengthbad. ones constant 1 appears odd number times, onesone universal variables appears odd number times. Since, 1,XXllml =+N1 , N2 , . . . , NmN1 , N2 , . . . , NmNi 0(2)Ni 1(2)getm,1X (2c)2u+11 X (2c)2v1 X (2c)2v=++2(2u + 1) 2(2(2v)) 2(2(2v))u1v1v1lNi 1(2) N1 ,N2 ,...,Nm.mlP(8)Standard combinatorial computations show that, even l, equationPlm1X 1 (m 2k)lNi 1(2) N1 ,N2 ,...,Nm=1m1ml2mlkk=0holds. Therefore, rewrite (8) obtainm,1X (2c)2u+1X (2c)2vX (2c)2v=++2(2u + 1)2(2(2v))2(2(2v))u1v11v1m1Xk=0!m1(m 2k)l.m12mlkFirst, observe m,1 function c, thus deduce last part theorem:lim Pr(m,n,cn) ((1,2)-QXOR-SAT) = exp(m,1 ) = Hm (c).n+Second, expression m,1 using following inequality1m1Xk=0m1(m 2k)l4m11 ,k2mlgetlim (m,1 ) =m+X (2c)ll22l1= ln(1 2c) c2holds, proves second statement theorem.addition, = = 1, get equation1,1 =X (2c)2vX (2c)2u+111+= ln(1 2c) + ln(1 4c2 ) c.2(2u + 1)2(2(2v))28u1v1Thus, established13fiCreignou, Daude, & Eglylim Pr(1,n,cn) ((1,2)-QXOR-SAT) = exp(1,1 ) = H(c),n+(exp(c)(1 2c)1/2 (1 4c2 )1/8H(c) =00 c 12 ,otherwise.result illustrated Figure 6, Figure 7 shows comparative behaviorthree distribution functions H0 , H H .1H(x) = ex 1 2x (1 4x2 )1/8(1,2)-QXOR-SAT m=1, n=20k(1,2)-QXOR-SAT m=1, n=40k0.90.80.70.60.50.40.30.20.100.10.20.30.40.50.6#clauses/#exvars0.70.80.91Figure 6: curves (1,2)-QXOR-SAT property = 1.4. Case e 3observed experimental results shown Figure 8 that, contraryobserved previous section, three smooth lines connecting consecutive points corresponding transition three properties 3-Max-rank,(a,3)-QXOR-SAT 3-XOR-SAT difficult distinguish. Moreover, n increases(see Figure 9), curves straighten come closer one other, showing thus strongempirical evidence transitions three properties coincide asymptotically,sharp phase transition critical value c3 0.918 (which critical ratio3-XOR-SAT, see Dubois & Mandler, 2002). show that, e 3, introductionuniversal variables XOR-formulas influence sharp transition.Theorem 4.1 every e 3 integer a, (a,e)-QXOR-SAT propertysharp threshold coincides one e-XOR-SAT property.14fiPhase Transition Random Quantified XOR-Formulas1H(x) = ex 1 2x (1 4x2 )1/8H0 (x) = ex/2 (1 2x)0.25H (x) = ex 1 2x0.90.80.70.60.50.40.30.20.100.10.20.30.40.50.6#clauses/#exvars0.70.80.91Figure 7: distribution functions H0 , H H .10.90.80.70.60.50.40.3#clauses/#exvars = 0.9183-XOR-SAT n=1k3-Max-rank n=1k(1,3)-QXOR-SAT m=n0.20.100.80.850.9#clauses/#exvars0.951Figure 8: curves 3-XOR-SAT, 3-Max-rank (a,3)-QXOR-SAT n=1000.Proof: Let us recallPrn,L (e-XOR-SAT) = Pr(Y (EY = C) consistent)= Pr(C Im(E))X=Pr(C V Im(E) = V ),V {0,1}L15fiCreignou, Daude, & Egly10.90.80.70.60.50.40.30.20.100.8#clauses/#exvars = 0.9183-XOR-SAT n=2k3-Max-rank n=2k(1,3)-QXOR-SAT m=n0.850.9#clauses/#exvars0.951Figure 9: curves 3-XOR-SAT, 3-Max-rank (a,3)-QXOR-SAT n=2000.since E C chosen independently. Therefore, P(r) denotes probabilityrandom matrix set L n Boolean matrices e units per row rank r,LX12rL P(r) P(L) + (P(L1) + . . . P(0) ).Prn,L (e-XOR-SAT) =2r=0observe P(0) + . . . + P(L) = 1, thus (P(L1) + . . . P(0) ) = 1 P(L) , henceget1 + P(L).Prn,L (e-XOR-SAT)2Therefore, according (3),2 Prn,L (e-XOR-SAT) 1 Prn,L ((a,e)-QXOR-SAT) Prn,L (e-XOR-SAT).Since know property e-XOR-SAT exhibits sharp threshold L (n)(Creignou & Daude, 2003), shows (a,e)-QXOR-SAT also does. holdsproperty e-Max-rank (since Prn,L (e-Max-rank) = P(L) ). particular, e = 3,shown (a,e)-QXOR-SAT well 3-Max-rank sharp threshold criticalvalue c3 0.918, critical ratio 3-XOR-SAT (Dubois & Mandler, 2002).5. Conclusion(experimentally theoretically) analyzed phase transition quantifiedproblems (a,e)-QXOR-SAT. analysis conducted level sophistication one made e-XOR-SAT problem, thus showing model proposed16fiPhase Transition Random Quantified XOR-FormulasChen Interian (2005) mathematically tangible provides good parametersorder perform mathematical analysis phase transition quantified problems.one hand, observed QSAT (Gent & Walsh, 1999; Chen & Interian, 2005),proved nature transition influenced introductionuniversal variables. hand, contrast QSAT, provedlocation phase transitionthe critical ratiois two propertiesXOR-SAT QXOR-SAT, difference behavior two propertiesoccurs level distribution function.Acknowledgmentswork supported EGIDE 10632SE OAD Amadee 2/2006.ReferencesChen, H., & Interian, Y. (2005). model generating random quantified boolean formulas.Proceedings 19th International Joint Conference Artificial Intelligence(IJCAI2005), pp. 6671.Cocco, S., Dubois, O., Mandler, J., & Monasson, R. (2003). Rigorous decimation-basedconstruction ground pure states spin glass models random lattices. PhysicalReview Letters, 90, 472051472054.Creignou, N., & Daude, H. (2003). Coarse sharp thresholds random k-XOR-CNF. Informatique theorique et applications/Theoretical Informatics Applications, 37 (2),127147.Creignou, N., Daude, H., & Dubois, O. (2003). Approximating satisfiability thresholdrandom k-XOR-CNF formulas. Combinatorics, Probability Computing, 12 (2),113126.Creignou, N., Khanna, S., & Sudan, M. (2001). Complexity classifications Boolean constraint satisfaction problems. SIAM Monographs Discrete Mathematics Applications. SIAM, Philadelphia, PA, USA.Dubois, O., Boufkhad, Y., & Mandler, J. (2000). Typical random 3-SAT formulaesatisfiability threshold. Proceedings 11th ACM-SIAM Symposium DiscreteAlgorithms (SODA2000), pp. 124126.Dubois, O., & Mandler, J. (2002). 3-XOR-SAT threshold. Proceedings 43thAnnual IEEE Symposium Foundations Computer Science (FOCS 2002), pp.769778.Dubois, O., Monasson, R., Selman, B., & Zecchina, R. (2001). Editorial. Theoretical Computer Science, 265 (12).Erdos, P., & Renyi, A. (1960). evolution random graphs. Publ. Math. Inst.Hungar. Acad. Sci., Vol. 7, pp. 1761.Franz, S., Leone, M., Ricci-Tersenghi, F., & Zecchina, R. (2001). Exact solutions dilutedspin glasses optimization problems. Physical Review Letters, 87, 127209127212.17fiCreignou, Daude, & EglyGent, I., & Walsh, T. (1999). Beyond NP: QSAT phase transition. Proceedings16th National Conference Artificial Intelligence (AAAI99), pp. 648653.Janson, S. (1987). Poisson convergence Poisson processes applications randomgraphs. Stochastic Processes Applications, 26 (1), 130.Janson, S., Luczak, T., & Rucinski, A. (2000). Random graphs. John Wiley sons.Takacs, L. (1988). limit distribution number cycles random graph.Journal Applied Probability, 25, 359376.18fiJournal Artificial Intelligence Research 29 (2007) 269-307Submitted 8/06; published 7/07Semantic Matchmaking Non-Monotonic Reasoning:Description Logic ApproachTommaso Di NoiaEugenio Di Sciasciot.dinoia@poliba.itdisciascio@poliba.itSisInfLab - Politecnico di Bari, Bari, ItalyFrancesco M. Doninidonini@unitus.itUniversita della Tuscia, Viterbo, ItalyAbstractMatchmaking arises supply demand meet electronic marketplace,agents search web service perform task, even recruiting agenciesmatch curricula job proles. open environments, objective matchmaking process discover best available oers given request.address problem matchmaking knowledge representation perspective,formalization based Description Logics. devise Concept Abduction Concept Contraction non-monotonic inferences Description Logics suitable modelingmatchmaking logical framework, prove related complexity results. alsopresent reasonable algorithms semantic matchmaking based devised inferences,prove obey commonsense properties.Finally, report implementation proposed matchmaking framework,used mediator e-marketplaces semantic web servicesdiscovery.1. Introductionpromise Semantic Web initiative revolutionize way information coded,stored, searched Internet (Berners-Lee, Hendler, & Lassila, 2001). basicidea structure information aid markup languages, based XMLlanguage, RDF RDFS1 , OWL2 . languages conceivedrepresentation machine-understandable, unambiguous, description webcontent creation domain ontologies, aim increasing opennessinteroperability web environment.Widespread availability resources services enablesamong advantagesinteraction number potential counterparts. bottleneck dicultnding matches, possibly best ones, parties.need matchmaking process arises supply demand meetmarketplace, web services able perform task discovered, alsorecruiting agencies match curricula job proles dating agency proposepartners customer agency. Requests oers may hence generic demandssupplies, web services, information, tangible intangible goods, matchmakingprocess nd request appropriate response. paper concentrate1. http://www.w3.org/RDF/2. http://www.w3.org/TR/owl-features/c2007AI Access Foundation. rights reserved.fiDi Noia, Di Sciascio & Doniniautomated matchmaking, basically oriented electronic marketplaces service discovery, although principles algorithms denitely general enough cover alsoscenarios. assume, reasonable, requests oers endowedkind description. Based descriptions target matching processnding, given request, best matches available oers set, also, givenoer, determine best matching requests peer-to-peer fashion. may hence thinkelectronic mediator actor actively tries carry matchmaking process.Obviously descriptions might provided using unstructured text, caseautomated mediator revert adopting either basic string matching techniquessophisticated Information Retrieval techniques.Semantic Web paradigm calls descriptions provided structured form based ontologies, assume follows requests oersgiven reference common ontology. noticed even requestsoers described heterogeneous languages, using dierent ontologies modellingdomain, schema/data integration techniques may employed makecomparable, proposed e.g., Madhavan, Bernstein, Rahm (2001), ShvaikoEuzenat (2005); reformulated comparable way, one still leftbasic matchmaking problems: given request, compatible oers?several compatible oers, which, why, promising ones?Matchmaking widely studied several proposals made past;report Section 2. Recently, growing eort aimedformalization Description Logics (DLs) (Baader, Calvanese, Mc Guinness, Nardi, &Patel-Schneider, 2003) matchmaking process (e.g., Di Sciascio, Donini, Mongiello, &Piscitelli, 2001; Trastour, Bartolini, & Priest, 2002; Sycara, Wido, Klusch, & Lu, 2002; DiNoia, Di Sciascio, Donini, & Mongiello, 2003b; Li & Horrocks, 2003; Di Noia, Di Sciascio,Donini, & Mongiello, 2003c, 2003a, among others). DLs, fact, allow model structureddescriptions requests oers concepts, usually sharing common ontology. Furthermore DLs allow open-world assumption. Incomplete information admitted,absence information distinguished negative information. providelittle insight DLs Section 3.Usually, DL-based approaches exploit standard reasoning services DL systemsubsumption (un)satisabilityto match potential partners electronic transaction. brief, supply described concept Sup demand concept Dem,unsatisability conjunction Sup Dem (noted Sup Dem) identies incompatible proposals, satisability identies potential partnersthat still agreeunderspecied constraintsand subsumption Sup Dem (noted Sup Dem)means requirements Dem completely fullled Sup.Classication compatible incompatible matches useless presenceseveral compatible supplies; way rank promising ones identied; alsoexplanation motivation rank could appreciated. hand,lack compatible matches one may accept turn incompatible matchescould still interesting, revising original requirements presentedrequest, far one could easily identify them.words method needed provide logic-based score compatibleincompatible matches eventually provide partial/full ordering, allowing user270fiSemantic Matchmaking Non-Monotonic Reasoning: Description Logic Approachautomated agent choose promising counteroers. Furthermorepossible, given score, provide logical explanations resulting score, thus allowingunderstand rank result ease interaction rene/revise request.Although process quite simple human logic-based fullyautomated framework. believe need dene non-monotonic reasoning servicesDLs setting, deal approximation ranking, paper proposeuse Concept Abduction (Di Noia et al., 2003a) Concept Contraction (Colucci,Di Noia, Di Sciascio, Donini, & Mongiello, 2003), services amenable answerhighlighted issues satisfactory way. Contributions paper include:logical framework express requests oers terms concept descriptions,properties hold matchmaking facilitator;Concept Abduction logical basis ranking compatible counteroers givenoer provide logical explanations ranking result;Concept Contraction logical basis ranking incompatible matches, aimeddiscovering promising near misses, provide logical explanationsranking result;algorithms implementing formalized inferences matchmaking purposescomplexity results class matchmaking problems;description system implementing semantic matchmaking services, experimental evaluation.remaining paper structured follows: next Section reports backgroundwork subject. (Section 3) briey revise Description Logics basics. makepaper self-contained recall (Section 4) logic-based framework matchmaking,pointing properties matchmaking algorithms systems guarantee.Sections 5 6 present Concept Abduction Concept Contraction, two inferenceservices devised compute semantic matchmaking, present suitable denitionsproblem along complexity results. Section 7 describematchmaker, present (Section 7.1) evaluation results computed systemcompared human users behavior, standard full text retrieval approach.Conclusions close paper.2. Related Work MatchmakingMatchmaking investigated recent years number perspectivesdierent purposes, renovated interest information overload kept growingWeb widespreading use. try summarize relevant related work.Vague query answering, proposed Motro (1988), initial eort overcome limitations relational databases, using weights attributed several search variables.recent approaches along lines aim extending SQL preference clauses,order softly matchmake data structured databases (Kieling, 2002). Finin, Fritzson,McKay, McEntire (1994) proposed KQML agent communication language oriented matchmaking purposes. Kuokka Harada (1996) investigated matchmaking271fiDi Noia, Di Sciascio & Doniniprocess allowed potential producers/consumers provide descriptionsproducts/needs, either directly agents mediation, later unied engine identifying promising matches. Two engines developed, SHADE system,used KQML, description language KIF, matchmaking anywayrelying logical reasoning, COINS, adopted classical unstructured-text information retrieval techniques, namely SMART IR system. Similar methods laterre-considered GRAPPA system (Veit, Muller, Schneider, & Fiehn, 2001). Classiedads matchmaking, syntactic level, proposed Raman, Livny, Solomon (1998)matchmake semi-structured descriptions advertising computational resources fashionanticipating Grid resources brokering. Matchmaking used SIMS (Arens, Knoblock,& Shen, 1996) dynamically integrate queries; approach used KQML, LOOMdescription language. LOOM also used subsumption matching addressedGil Ramachandran (2001). InfoSleuth (Jacobs & Shea, 1995), system discoveryintegration information, included agent matchmaker, adopted KIFdeductive database language LDL++. Constraint-based approaches matchmakingproposed implemented several systems, e.g., PersonaLogic3 , Kasbah4systems Maes, Guttman, Moukas (1999), Karacapilidis Moraitis (2001), Wang,Liao, Liao (2002), Strobel Stolze (2002).Matchmaking satisability concept conjunction DLs rst proposedvenue Gonzales-Castillo, Trastour, Bartolini (2001) Di Sciascio et al.(2001), precisely dened Trastour et al. (2002). Sycara, Paolucci, Van Velsen,Giampapa (2003) introduced specic language agent advertisement frameworkRetsina Multiagent infrastructure. matchmaking engine developed (Sycaraet al., 2002; Paolucci, Kawamura, Payne, & Sycara, 2002), carries processpossible levels. levels exploit classical text-retrieval techniques semanticmatch using -subsumption. Nevertheless, standard features semantic-based system,satisability check unavailable. noteworthy approach, notionplug-in match introduced, overcome way limitations matching approach based exact matches. approach Paolucci et al. (2002) later extendedLi Horrocks (2003), two new levels matching classication introduced.similar classication proposedin venueby Di Noia et al. (2003c), alongproperties matchmaker DL-based framework, algorithmsclassify semantically rank matches within classes. Benatallah, Hacid, Rey, Toumani(2003) proposed Dierence Operator DLs semantic matchmaking. approachuses Concept Dierence, followed covering operation optimized using hypergraph techniques, framework web services discovery. briey comment relationshipConcept Dierence Concept Abduction end Section 5. initial DLbased approach, adopting penalty functions ranking, proposed Cal, Calvanese,Colucci, Di Noia, Donini (2004), framework dating systems. extendedmatchmaking approach, negotiable strict constraints DL frameworkproposed Colucci, Di Noia, Di Sciascio, Donini, Mongiello (2005), using Concept Contraction Concept Abduction. Matchmaking DLs locally-closed world3. http://www.PersonaLogic.com4. http://www.kasbah.com272fiSemantic Matchmaking Non-Monotonic Reasoning: Description Logic Approachassumption applying autoepistemic DLs proposed Grimm, Motik, Preist(2006).need work someway approximation ranking DL-based approachesmatchmaking also recently led adopting fuzzy-DLs, Smart (Agarwal &Lamparter, 2005) hybrid approaches, OWLS-MX matchmaker (Klusch, Fries,Khalid, & Sycara, 2005). approaches, anyway, relaxing logical constraints,allow explanation automated revision service.Finally, pointed matching DLs, widely treated Baader,Kusters, Borgida, Mc Guinness (1999) relation matchmaking. fact,work expressions denoting concepts considered, variables expressions.match substitution variables expressions makes concept expressionequivalent another. Also general setting concept rewriting DLsdirect relation matchmakingsee discussion Remark 1.3. Description Logics BasicsSection summarize basic notions denitions Description Logics(DLs), Classic, knowledge representation system application inspiredby. provide hereafter brief guided-tour DLs main characteristics, interestedreader refer comprehensive handbook Baader et al. (2003).3.1 Description LogicsDescription Logicsa.k.a. Terminological Logicsare family logic formalisms Knowledge Representation. DLs endowed syntax, semantics, usuallymodel-theoretic. basic syntax elements DLs are:concept names, e.g., Computer, CPU, Device, Software,role names, like hasSoftware, hasDeviceindividuals, used special named elements belonging concepts.Intuitively, concepts stand sets objects, roles link objects dierent concepts,role hasSoftware links computers software. using individualsformalization, hence skip parts regarding individuals.Formally, semantic interpretation pair = (, ), consists domaininterpretation function , maps every concept subset , everyrole subset .Basic elements combined using constructors form concept role expressions,DL distinguished set constructors. Every DL allows one formconjunction concepts, usually denoted ; DL include also disjunctioncomplement close concept expressions boolean operations.Roles combined concepts usingexistential role quantication:e.g., Computer hasSoftware.WordProcessordescribes set computers whose software include word processor,273fiDi Noia, Di Sciascio & Doniniuniversal role quanticatione.g., Server hasCPU.Inteldescribes servers Intel processors board.constructs may involve counting,number restrictions:e.g., Computer ( 1 hasCPU)expresses computers one CPU,e.g., Computer ( 4 hasCPU)describes computers equipped least four CPUs.Many constructs dened, increasing expressive power DL,n-ary relations (Calvanese, De Giacomo, & Lenzerini, 1998).follows, call atomic concepts union concept names, negated conceptnames, unqualied number restrictions. dene length concept C numberatomic concepts appearing C. denote length C |C|. Observeconsider zero length. dene Quantication Nesting (QN)concept following positive integer: QN atomic concept 0, QNuniversal role quantication R.F 1 plus QN F , QN conjunctionC1 C2 maximum QNs conjoined concepts C1 C2 .Expressions given semantics dening interpretation functionconstruct. example, concept conjunction interpreted set intersection: (C D)I =C DI , also boolean connectives , present, given usualset-theoretic interpretation union complement. interpretation constructsinvolving quantication roles needs make domain elements explicit: example,(R.C)I = {d1 | d2 : (d1 , d2 ) RI d2 C }3.2 TBoxesConcept expressions used axiomsthat either inclusions (symbol: ),denitions (symbol: )which impose restrictions possible interpretations accordingknowledge elicited given domain. example, could impose monitorsdivided CRT LCD using two inclusions: Monitor LCDMonitorCRTMonitor CRTMonitor LCDMonitor. Or, computers domestic useone operating system HomePC ( 1 hasOS). Denitions useful givemeaningful name particular combinations, Server Computer ( 2 hasCPU).Historically, sets axioms called TBox (Terminological Box).several possible types TBoxes. General TBoxes made General Concept Inclusions(GCI) form C D, C Dem concept DL.general TBoxes, distinction inclusions denitions disappears, sincedenition C expressed two GCIs C D, C. contrary,simple TBoxesalso called schemas Calvanese (1996), Buchheit, Donini, Nutt,Schaerf (1998)only concept name appear left-hand side (l.h.s.)axiom, concept name appear l.h.s. one axiom. Schemas274fiSemantic Matchmaking Non-Monotonic Reasoning: Description Logic Approachcyclic acyclic, cyclicity refers dependency graph GT concept names,dened follows: every concept name node GT , arc conceptname concept name B appears l.h.s. axiom, B appears (atlevel) concept right-hand side. acyclic GT is, cyclic otherwise.call acyclic schema simple TBox (Baader et al., 2003, Ch.2). depth simpleTBox length longest path GT . simple TBoxes, unfoldingdened following process (see Appendix denition): every denitionC, replace C every concept; every inclusion C, replace Cevery concept. Clearly, process trasforms every concept equivalent one,TBox forgotten. However, TBoxes, unfolding yield conceptsexponential size w.r.t. initial concepts. exponential blow-uphappen, call TBox bushy deep (Nebel, 1990).semantics axioms based set containment equality: interpretationsatises inclusion C C DI , satises denition C C = DI .model TBox interpretation satisfying axioms .Observe make distinction equivalence (used axioms) equality= symbols. use equality instantiate generic concept symbols conceptsstand for, e.g., write ... C = R.B... mean conceptsymbol C stands concept expression R.B text.3.3 Reasoning ServicesDL-based systems usually provide two basic reasoning services:1. Concept Satisability: given TBox concept C, exist least onemodel assigning non-empty extension C? abbreviate satisabilityconcept C w.r.t. TBox C .2. Subsumption: given TBox two concepts C D, C always containedevery model Iof ? abbreviate subsumption C w.r.t.C D.Since C satisable C subsumed , complexity lower bounds satisabilitycarry (for complement class) subsumption, upper bounds subsumptioncarry satisability. hand, since C subsumed Cunsatisable, subsumption reducible satisability DLs admitting general conceptnegation, DLs outside languageas DLsnext Section.3.4 System Classicsystem Classic (Borgida, Brachman, McGuinness, & A. Resnick, 1989; Borgida &Patel-Schneider, 1994) originally developed general Knowledge Representationsystem, successfully applied conguration (Wright, Weixelbaum, Vesonder,Brown, Palmer, Berman, & Moore, 1993) program repositories management (Devambu,Brachman, Selfridge, & Ballard, 1991).language designed expressive possible still admittingpolynomial-time inferences bushy deep TBoxes. provides intersection275fiDi Noia, Di Sciascio & Donininametopbottomintersectionuniversalquanticationnumberrestrictionsconcrete syntaxTOP(and C D)syntaxCsemanticsC DI(all R C)R.C{d1 | d2 : (d1 , d2 ) RI d2 C }(at-least n R)(at-most n R)( n R)( n R){d1 | {d2 | (d1 , d2 ) RI } n}{d1 | {d2 | (d1 , d2 ) RI } n}Table 1: Syntax semantics constructs Classicnamedenitioninclusiondisjointgroupsystem notation(createConcept C false)(createConcept C true)(createConcept A1 C symbol)...(createConcept Ak C symbol)syntaxACACdisj(A1 , . . . ,Ak )semanticsAI = CAI C= 1, . . . , k AIi Cj = + 1, . . . , kAIi AIj =Table 2: Syntax semantics TBox Classic assertions (symbol name denotinggroup disjoint concepts)concepts union, universal existential quantication roles, numberrestrictions roles intersection roles, since combinations knownmake reasoning np-hard (Donini, Lenzerini, Nardi, & Nutt, 1991; Donini, 2003).simplicity, consider subset constructs, namely, conjunction, numberrestrictions, universal role quantications, summarized Table 1. abbreviateconjunction ( n R) ( n R) (= n R). omit constructs ONE-OF(), FILLS(,)refer individuals, construct SAME-AS(,) equating llers functional roles.subset Classic refer known ALN (Attributive Language unqualiedNumber restrictions) (Donini, Lenzerini, Nardi, & Nutt, 1997b). number restrictionspresent, resulting DL known AL (Schmidt-Schau & Smolka, 1991). ALNprovides minimal set constructs allow one represent concept taxonomy, disjointgroups, role restrictions (AL), number restrictions (N ) represent restriction sonnumber llers role.Regarding axioms TBox, Classic allows one state simple TBox assertionsform summarized Table 2, A, A1 , . . . ,Ak concept names. AxiomsTBox subject constraints every concept name appearl.h.s. TBox, every concept name cannot appear l.h.s.denition disjointness assertion.Every Classic concept given normal form. consider normal formconstructs ALN used ontologies applications. Intuitively,normal form pre-computes implications concept, includingpossiblyits unsatisability. normal form reached, commutativity operator ,using well-known normalization rules, report Appendix make paper276fiSemantic Matchmaking Non-Monotonic Reasoning: Description Logic Approachself-contained. normal form unsatisable concept simply . Every satisableconcept C divided three components: Cnames C Call . component Cnamesconjunction concept names A1 , . . . ,Ah . component C conjunctionnumber restrictions, two every role (the maximum at-leastminimum at-most role), including every conjunct C form R.,number restriction ( 0 R) C . component Call conjoins concepts formR.D, one role R, normal form. call form Conjunctive Normal FormCNF, analogy Propositional Logicand observe CNFunique (also said canonical), commutativity conjunction.Moreover, TBox Classic embedded concepts, expandingdenitions, adding right-hand-side concepts inclusions, adding negationdisjoint concept namessee Appendix details. instance, supposeTBox contains:1. denition Server Computer ( 2 hasCPU),2. inclusion Computer ( 1 hasStorageDevice),3. disjointness assertion disj(AMD, Intel).Then, concept ServerhasCPU.Intel rewritten Computer( 2 hasCPU)( 1 hasStorageDevice)hasCPU.(IntelAMD), equivalent former w.r.t.models TBox. Observe concept name Computer kept rewriting,since inclusion gives necessary condition ( 1 hasStorageDevice). latterconcept safely conjoined Computermaking inclusion unnecessarybut cannot replace since ( 1 hasStorageDevice) sucient condition Computer.Instead, Computer ( 2 hasCPU) replaces Server since necessary sucientcondition it. disjoint assertion generates Intel AMD range hasCPU..rewriting carried concepts, TBox safely ignoredcomputing subsumption (and satisability). general, unfolding may lead exponential blow-up TBox, making entire computation (unfolding+subsumption) takeexponential time (and space) size initial concepts TBox. Yet exponentialtime computation subsumption likely unavoidable, since even without rewriting,taking TBox account makes subsumption np-hard (Nebel, 1990).normal form concepts take TBox embedding account (see Appendix A.2). case, component Cnames Classic concept C contains conceptnames Cnames+ negations concept names Cnames . following, denoteCNF concept C w.r.t. simple TBox CNF (C, ). Again, general, sizeCNF (C, ) may exponential w.r.t. size C . However, xed,CNF (C, ) polynomial-size w.r.t. size C i.e., exponential increase comesTBox unfolding. fact, k maximum size unfolded concept name(a constant xed), size CNF (C, ) k times size C.use argument later paper, decouple complexity analysis reasoningmethods matchmaking complexity raised TBox.ease presentation follows next Sections, adopt simple referenceontology, pictured Figure 1, used throughout paper. keep representation within ALN , modeled memory quantities number restriction, e.g., 20GB277fiDi Noia, Di Sciascio & DoniniCRTmonitorLCDmonitorMonitor=DVDRecorderFloppyDiskStorageDeviceHardDiskLinuxSolarisWindows2000WindowsXpOperatingSystemBrowserDeviceSoftwareWordProcessorPDAPCComputer=Computer ( 1 hasStorageDevice) hasStorageDevice.StorageDevicehasSoftware.Software ( 1 ram)HomePC PC ( 1 hasSoftware)(= 1 hasOS) ( 1 hasMonitor) hasMonitor.MonitorServer Computer ( 2 hasCPU)ram.( 512 mb) hasStorageDevice.( 20000 mb)Figure 1: Reference Ontology used examples( 20000 mb). reasoners specialized ALN , problem, since number nnever expanded n llers (Borgida & Patel-Schneider, 1994; Donini et al., 1997b).expressive DLs, Concrete Domains (Lutz, 1999) employed representquantities.4. Semantic Matchmaking Using Description LogicsMatchmaking widely used term variety frameworks, comprising severalquitedierentapproaches. begin Section trying provide generic sound denition matchmaking.Matchmaking information retrieval task whereby queries (a.k.a. demands) resources (a.k.a. supplies) expressed using semi-structured dataform advertisements, task results ordered (ranked) listsresources best fullling query.simple denition implies thatdierently classical unstructured-text InformationRetrieval systemssome structure advertisements expected matchmaking278fiSemantic Matchmaking Non-Monotonic Reasoning: Description Logic Approachsystem, matchmaking consider xed database-oriented relational structure.Furthermore, usually database systems provide answers queries includerelevance ranking, instead considered matchmaking process.Semantic matchmaking matchmaking task whereby queries resourcesadvertisements expressed reference shared specication conceptualization knowledge domain hand, i.e., ontology.on, concentrate semantic matchmaking marketplaces, adopting specicterminology, ease presentation approach. Nevertheless approach appliesgeneric matchmaking semantically annotated resources.note denitions Section apply every DL useddescribe marketplace (supplies, demands, background knowledge). denote Lgeneric DL. suppose common ontology supplies demands established,TBox L. match supply demand could evaluatedaccording .First all, remark logic-based representation supplies demands callsgenerally Open-world descriptions, is, absence characteristic description supply demand interpreted constraint absence. Instead,considered characteristic could either rened later, left openirrelevant user. Note generally open mean speciccharacteristic might declared closed. However, closure madepiecewise, using known declarative tool devised Knowledge Representation nonmonotonic reasoning, Defaults DLs (Baader & Hollunder, 1992), AutoepistemicDLs (Donini, Nardi, & Rosati, 1997a), Circumscription DLs (Bonatti, Lutz, & Wolter,2006) etc.analysis recent literature allows categorize semantic matchmaking processsupply Sup demand Dem w.r.t. TBox distinct classes:exact match: Sup Dem, i.e., Sup Dem Dem Sup, amountsperfect match, regardlessin semantic based environmentof syntactic dierences, i.e., Sup Dem equivalent concepts (Di Sciascio et al., 2001; GonzalesCastillo et al., 2001).full match: Sup Dem, amounts demand completely fullledavailable supply, i.e., Sup least features required Dem,necessarily vice versa, matchmaking process symmetric (Di Noia et al.,2003c); kind match also named subsume match Li Horrocks (2003).plug-in match: Dem Sup; corresponds demand Dem sub-conceptsupply Sup,i.e., Dem specic Sup (Sycara et al., 2002; Li & Horrocks,2003).potential match: DemSup , corresponds supply demandsomething common conicting characteristics (Di Noia et al., 2003c).relation also named intersection-satisable Li Horrocks (2003).279fiDi Noia, Di Sciascio & Doninipartial match: Dem Sup , amounts presence conictdemand available supply (Di Noia et al., 2003c). relation alsonamed disjoint Li Horrocks (2003)5 .stress demands could classied way w.r.t. given supply,suppliers turn look marketplace nd potential buyers. Hence,rest paper use term oer denoted symbol Dto mean either supplySup demand Dem, term counteroer denoted Cto mean, respectively,demand Dem supply Sup could match D.classication still coarse one, relying directly known logical relationsformulae. fact, result matchmaking rank counteroers,according criteriapossibly explicitso user trusting system wouldknow contact rst, case failure, next, on. rankingprocess satisfy criteria Knowledge Representation approach suggests.formulate ranking requirements referring properties penalty functions.Definition 1 Given DL L, two concepts C, L, TBox L, penaltyfunction three-arguments function p(C, D, ), returns null positive integer.use penalty functions rank counteroers C given demand (or supply) w.r.t.TBox . Intuitively, two given counteroers C1 , C2 marketplace, p(C1 , D, ) <p(C2 , D, ) issuer oer rank C1 better C2 decidingcontact rst. Clearly, 0-penalty ranked best, counteroerspenalties ranked breaking ties. rst property recall Non-symmetricevaluation proposals.Definition 2 penalty function p(, , ) non-symmetric exist concepts C,TBox p(C, D, ) = p(D, C, ).property evident constraints fullled C vice versa.Hence, C among top-ranked counteroers list potential partnersD, necessarily appear top list potential partners C.So, penalty function p(, , ) expected metric distance function.Secondly, logic used give meaning descriptions supplies demands,proposals meaning equally penalized, independentlysyntactic descriptions.Definition 3 penalty function p(, , ) syntax independent every triple concepts C1 , C2 , D, TBox , |= C1 C2 p(C1 , D, ) = p(C2 , D, ),holds also second argument , i.e., p(D, C1 , ) = p(D, C2 , )5. note preferring term partial match instead disjoint, stress match maystill recoverable, disjoint usually meant hopeless situation. Moreover, disjointintersection satisable refer set-theoretic semantics concepts Description Logics,quite hidden far original problems matchmaking. word, technologyoriented problem-oriented. instance, one used Propositional Logic, Three-valued Logicmodeling matchmaking, terms would make sense.280fiSemantic Matchmaking Non-Monotonic Reasoning: Description Logic ApproachClearly, logic admits normal form expressionsas CNF DNF propositional logic, normal form concepts DLs dened previous Sectionusingnormal form computation p(, , ) ensures syntax independence.Penalties enjoy desirable properties w.r.t. subsumption. reasons explained below, divide penalty functions ranking potential matchesranking partial (conicting) matches.Definition 4 penalty function potential matches monotonic subsumptionwhenever every issued oer D, every pair counteroers C1 C2 , TBox ,C1 C2 potential matches w.r.t. , (C1 C2 ), p(C1 , D, )p(C2 , D, )Intuitively, denition could read as: C1 C2 C1 penalized(and ranked) either same, better C2 . phrase, ranking potentialmatches monotonic subsumption specic means better. dual propertycould stated second argument: D1 D2 counteroer C less likelyfulll characteristics required D1 D2 . However, since scenario is: givenissuer proposal looking match marketplace, rank possible counteroersC1 , C2 , . . . , best one worst, deal dualityrst second argument p(, , ).turning partial matches, properties already conict supply demand, picture reverses. Now, adding another characteristicunsatisfactory proposal may worsen ranking (when another characteristic violated) keep (when new characteristic conict). Noteranking kept dierent ranking potential matches. all, acceptingdiscard one characteristics required much worse decidingproposal try rst among potential ones.Definition 5 penalty function partial matches antimonotonic subsumptionwhenever every issued oer D, every pair counteroers C1 C2 , TBox ,C1 C2 partial matches w.r.t. , (C1 C2 ), p(C1 , D, )p(C2 , D, )Intuitively, C1 C2 C1 penalized (and ranked) either same,worse C2 . words, ranking partial matches antimonotonicsubsumption specic means worse. property hold alsosecond argument, since concept conjunction commutative.need distinguish penalty function potential matches onepartial matches, put subscript former (as p ) subscriptlatter (as q ).Clearly, requirements general, leave ample room denitionpenalty functions. subtle requirement would penalties changeirrelevant details added, e.g., second-hand computer requested demandDem, specication brand CPU, supply Sup penalizedanother oer Sup hasCPU.Intel. However, instead delving irrelevancelogic-related issues directly penalties, borrow well-known logical281fiDi Noia, Di Sciascio & Doninireasoning frameworks propositional knowledge representation. detour give ussound declarative way dening penalties, dealing irrelevance byproduct,generally bring well-studied non-standard reasoning techniques matchmaking.5. Concept AbductionAbduction (Peirce, 1955) well known form commonsense reasoning, usually aimednding explanation given symptoms manifestations. introduce Concept Abduction DLs, showing model potential matchmaking DL setting.Following notation proposed Eiter Gottlob (1995), recall PropositionalAbduction Problem triple H, M, H (Hypotheses) (Manifestations)sets literals, (Theory) set formulae. solution H, M, Explanation E H E consistent, E |= . adapt frameworkDLs follows.Definition 6 Let L DL, C, D, two concepts L, set axiomsL, C satisable . Concept Abduction Problem (CAP)given L, C, D, , nding, possible, concept H L C H ,C H D.use P symbol generic CAP, denote SOL(P) setsolutions CAP P. Observe denition, limit inputs CAPsatisable concepts C D, since C unsatisable implies CAP solutionall, unsatisable leads counterintuitive results (e.g., C would solutioncase). Propositional Abduction extends implication, Concept Abduction extends concept subsumption. dierently propositional abduction, makedistinction manifestations hypotheses, usual abductionused diagnosis. fact, making hypotheses e.g., properties goodse-marketplaces, point making distinction. uniformity impliesalways trivial solution non-trivial CAP L, C, D, , statedformally follows.Proposition 1 Let L DL, let C, concepts L, L-TBox. CDSOL(L, C, D, ).Proof. C satisable , fullls requirements Def. 6, rstone hypothesis second one C tautology.hand, SOL(L, C, D, ) C denition.simple interpretation property application domain, i.e., matchmaking,hypothesize counteroer C exactly specications D,counteroer trivially meets given specicationsif compatible anyway. However,solutions CAP equivalent using Concept Abduction matchmaking.make simple example, suppose already C D. Then, H1 = H2 =(among others) solutions L, C, D, . Yet, solution H2 = tells issuerC already meets Ds specications, solution H1 = least282fiSemantic Matchmaking Non-Monotonic Reasoning: Description Logic Approachinformative solution point view. Hence, want use abduction highlightpromising counteroers, minimal hypotheses must dened.Definition 7 Let P =L, C, D, CAP. set SOL (P) subset SOL(P)whose concepts maximal . set SOL (P) subset SOL(P) whoseconcepts minimum length.Clearly, maximal w.r.t. still minimality criterion, since meansunnecessary hypothesis assumed. proved two measures incomparable.Proposition 2 exists CAP P two sets SOL (P) SOL (P)incomparable.Proof. sucient consider = A1 A2 A3 , C = A1 , = {B A2 A3 }.logic even propositional. A2 A3 SOL (L, C, D, ), B SOL (L, C, D, ),neither solution set.proof highlights that, although -minimality could preferable conciseness,heavily dependent . fact, every concept H SOL(P), sucient addaxiom H get -minimal solution A. hand, also -maximalitydrawbacks: concept disjunction present L, single -maximalsolution P, equivalent disjunction solutions SOL(P)notuseful solution. Making analogy Abduction-based Diagnosis (Console, Dupre, &Torasso, 1991), could say disjunction possible explanationsinformative explanation itselfalthough maximal w.r.t. implication. notending -minimal solution np-hard TBox depth 1, simple reductionSet Covering (Colucci, Di Noia, Di Sciascio, Donini, & Mongiello, 2004).Remark 1 interesting analyze whether concept minimal-rewriting techniquesasdened Baader, Kusters, Molitor (2000)could employed computingminimal concept abduction, trying rewrite C D. answer denitely negativeminimal length abduction: length-minimal solution B proof Proposition 2could obtained rewriting C = A1 A1 A2 A3 . fact, A1 Bequivalent rewriting former concept. Regarding -maximality answerindirect. fact, present rewriting techniques keep subconcept xedrewriting process. consider CAP = A1 , C = A2 , = {B A1 A2 }.equivalent minimal rewriting C B, solution cannotidentied since B cannot separated concept Cthe original oneand conceptH solution CAP. open whether future extensions rewriting mightkeep concept xed, cope problem.third minimality criterion possible DLs admit CNF, L = ALN .Definition 8 Let P =L, C, D, CAP L admits CNF, assumeconcepts SOL(P) CNF. set SOL (P) subset SOL(P) whose conceptsminimal conjunctions, i.e., C SOL (P) sub-conjunction C (at levelnesting) SOL(P). call solutions irreducible.283fiDi Noia, Di Sciascio & Doniniturns -minimality includes -maximality -minimality.Proposition 3 every CAP P L admits CNF, SOL (P) SOL (P)included SOL (P).Proof. contraposition, concept H -minimal another conceptH sub-conjunction Hwhich -minimal solution. |H | < |H|, hence Hlength-minimal. -maximality: since every sub-conjunction conceptH CNF subsumes H, H -minimal -maximal either.proof Proposition 2 modied show minimum-length abducedconcepts unique: sucient add another axiom B A2 A3 obtainanother minimum-length solution B . less obvious result also subsumptionmaximal solutions unique, least non-simple TBoxes: Let P = L, C, D,= {A2 A3 A1 }, C = A3 , = A1 . A1 A2 -maximalsolutions.5.1 Irreducible Solutions ALN -simple TBoxesassume TBox CAP P = L, C, D, always simple one. Findingirreducible solution easier nding -minimal -maximal solution, sincegreedy approach used minimize set conjuncts solution. example,starting C D, could delete one redundant conjunct time (at levelrole quantication nesting) D, using |D| calls subsumption-check procedure.However, algorithm would interesting theoretical purposes. Instead,adapt structural subsumption algorithm (Borgida & Patel-Schneider, 1994) collectsconcepts H conjoined C order C H subsumed D.algorithm operates concepts CNF. following algorithm, abbreviatefact concept appears conjunct concept C C (thus extendingmeaning conjunctions concepts).Algorithm ndIrred (P);input: CAP P = L, C, D, , L =ALN , simple , C CNF w.r.t.output: concept H SOL (P) (where H = means C D)variables: concept HbeginH := ;0. Creturn ;1. every concept name1.1CH := H A;2. every concept ( n R)2.1concept ( R) C nH := H ( n R);3. every concept ( n R)284fiSemantic Matchmaking Non-Monotonic Reasoning: Description Logic Approachconcept ( R) C nH := H ( n R);4. every concept R.E4.1exists R.F C4.1.1H := H R.ndIrred (ALN , F, E, );4.1.2else H := H R.E;/* H SOL(P), might reducible */5. every concept Hi HH without Hi SOL(P)delete Hi H;6. return H;end.3.1Theorem 1 Given CAP P, ndIrred (P) returns concept H, H , Hirreducible solution P.Proof. rst prove Step 5, computed concept H SOL(P), is,C H C H hold. fact, observe CNF (D, ) H, sinceconjuncts H come conjunct CNF (D, ). Hence, H since CNF (D, )equivalent models . Adding C sides subsumption yieldsC C H, since assume C , also C H . provesrst condition H SOL(P). Regarding condition C H D, supposehold: then, least one conjunct CNF (D, ) appear CNF (C H, ).possible construction, since H contains every conjunct CNF (D, )CNF (C, ). Therefore, conclude H SOL(P). provedH computed Step 5 solution P, note Step 5 deletes enoughconjuncts make H irreducible solution.rst part algorithm (before Step 5) easily follows well-known structural subsumption algorithms (Borgida & Patel-Schneider, 1994). Step 5 applies greedy approach, hencecomputed solution, although irreducible, might minimal.explain need reducibility check Step 5 help followingexample.Example 1 Let = {A1 A2 , A3 A4 }, let C = A3 , = A1 A4 . Lpropositional part AL. normal form C C = A3 A4 , = A1 A2 A4 .Step 5 algorithm computes H = A1 A2 , must still reducedA1 . worth noticing H already subsumption-maximal since H A1 . However,-minimality syntactic property, requires removal redundant conjuncts.complexity, aim proving nding irreducible solutioncomplex subsumption ALN . polynomial algorithm (w.r.t. sizes C,) cannot expected anyway, since subsumption AL (the sublanguage ALNwithout Number Restrictions) simple conp-hard (Nebel, 1990; Calvanese, 1996).However, Nebel (1990) argues unfolding TBox exponential depth285fiDi Noia, Di Sciascio & Doninihierarchy ; depth grows O(log |T |) size increasesa bushydeep TBoxthen unfolding polynomial, algorithm.generally, suppose xed: unrealistic hypothesismarketplace application, since represents ontology domain,expect vary supplies demands enter exit marketplace. case,analyze complexity ndIrred considering C size inputproblem.Theorem 2 Let P = L, C, D, CAP, L =ALN , simple TBox.nding irreducible solution P problem solvable time polynomial sizeC D.note problem exponential-size unfolding might mitigated LazyUnfolding (Horrocks & Tobies, 2000). Using technique, concept names TBoxunfolded needed.5.2 Abduction-Based Ranking Potential Matchesdene penalty function p potential matches based following intuition:ranking potential matches depend many hypotheses madecounteroers order transform full matches.Definition 9 Given simple TBox ALN , dene penalty function potential match counteroer C given oer D, C conceptsALN , follows:.p (C, D, ) = |ndIrred (ALN , CNF (C, ), CNF (D, ), )|(1)Note that, computing p , concept H actually computed ndIrredintermediate step. makes easy devise explanation facility, actualobtained ranking immediately enriched logical explanation; thus improvingusers trust interaction matchmaking system.prove p accordance properties higlighted previous Section.Since computation Formula (1) starts putting concepts C, normal form,recall normal form C summarized Cnames C Call , similarlyD. Without ambiguity, use three components also sets conjoined concepts.Theorem 3 penalty function p (i) non-symmetric, (ii) syntax independent,(iii) monotonic subsumption.Proof.(i) Non-symmetricity easily proved providing example: p (A, , ) =p ( , A, ). fact, ndIrred (ALN , A, , ) nds H1 = solution (A withouthypothesis) ndIrred (ALN , , A, ) nds H2 = A. Recalling | | = 0,|A| = 1, get rst claim.(ii) Syntax independence follows fact normal forms used Formula (1),already said normal forms unique commutativity conjunction.286fiSemantic Matchmaking Non-Monotonic Reasoning: Description Logic Approach(iii) Monotonicity subsumption proved analyzing conditions subsumption ALN . concept C subsumed concept C whenever conditionshold. condition, analyze changes behavior ndIrred , provingprovided solution H adds conjuncts. Recall monotonicity subsumption applied potential matches, hence assume C Cconsistent D. Since ndIrred recursive, proof also induction quantication nesting (QN) C . C QN equal 0, C conjunctionatomic conceptsnames, negated names, number restrictions. conditionssubsumption following:rst condition Cnames+ C names+ . Hence, Step 1.1 ndIrred ,number concept names added H respect names added Hdecrease, |H | |H| considering names. Regarding negated names,observe contribute solution ndIrred , since comedisjointness axiom positive name (that contributes).second condition every number restriction C , eithernumber restriction appears C , strengthened (an at-least increases, atmost decreases) C . Hence, number restrictions added Steps 2.1 3.1 Heither many added H, less. Again, also considering numberrestrictions |H | |H|.two cases prove basis induction (C QN equal 0). Supposeclaim holds concepts C QN n less, let C QN n + 1. Clearly,case C least one universal role quanticationcall R.F . conditionsubsumption C C following:Either every universal role quantication R.F C role R, musthold F F , universal role quantication R C. formercase, observe ndIrred recursively called6 Step 4.1.1 arguments F , E,F , E; call , respectively, solutions returned ndIrred . ObserveQN F n less, hence inductive hypothesis |I | |I|. Since Step 4.1.1adds R.I R.I H H, |H | |H|. instead universalrole quantication R C, Step 4.1.2 adds R.E H. also C containrole quantication R, Step 4.1.2 adds R.E also H , H cannotlonger H case. role quantication R.F C , Step 4.1.1makes recursive call arguments F , E. case, solution returnedlength less equal |E|, hence length H cannot longerlength H also case.summary, C C case length H increases respectlength H. proves monotonicity subsumption p .Intuitively, could say monotonicity subsumption potential matches meansspecic C is, lower penalty, better ranking w.r.t. D.6. findIrred called once, concepts CNF one universal role quanticationrole R.287fiDi Noia, Di Sciascio & Doninipreciselybut less intuitivelywe say rank C w.r.t. cannot worsenC made specic. Hence, given oer D, TBox , sequence increasingly specic counteroers C1 C2 C3 assigned sequencenon-increasing penalties p (C1 , D, ) p (C2 , D, ) p (C3 , D, ) . . . provesequences well-founded, bottom element zero, reached case subsumption.Proposition 4 p (C, D, ) = 0 C D.Proof.Recall Section 3.1 concepts length zero,ndIrred returns C potential match (Step 0 ndIrred ).Hence, p (C, D, ) = 0 concept whose length computed Formula (1). construction ndIrred , returned callndIrred (ALN , CNF (C, ), CNF (D, ), ) CNF (C, ) CNF (D, ),holds (see Borgida & Patel-Schneider, 1994) C D.Moreover, could also prove adding C details irrelevant leavespenalty unaected, adding C details relevant lowers Cs penalty.Note also Formula (1) take account normal form C, D,forget itwe use empty TBoxwhen calling ndIrred . explain choiceaid example.Example 2 Given = {A A1 A2 }, let = Demand two followingsupplies: C1 = A2 , C2 = . Observe CNF (D, ) = A1 A2 , CNF (C1 , ) =A2 , CNF (C2 , ) = . used following formula compute penalty.p (C, D, ) = |ndIrred (ALN , C, D, )|(2)ran algorithm ndIrred (ALN , C1 , D, ) ndIrred (ALN , C2 , D, ),Step 5 would get, respectively,H1 = A1H2 = A1 A2Step 5 ndIrred would return H1 = H2 = A, hence C1 C2 would receivepenalty. However, argue C1 closer C2 is, contains characteristic (A2 ) implicitly required D, C2 not. instead callndIrred (ALN , CNF (C1 , ), CNF (D, ), )ndIrred (ALN , CNF (C2 , ), CNF (D, ), ), get solutions H1 H2 aboveandStep 5 delete conjunct, since = . Therefore, C1 gets penalty 2, C2gets penalty 3, highlighting specied C1 w.r.t. C2 .generally, say reducibility step (Step 5 ndIrred ) attens solutionspecic conjuncts, leaving TBox implicit representationcharacteristics, ones already present supply present. Therefore,making empirical decision, consider TBox normal form C D,exclude reductions Step 5 ndIrred .288fiSemantic Matchmaking Non-Monotonic Reasoning: Description Logic ApproachRemark 2 Although denition Concept Abduction could appear similar ConceptDierence, so. note generically speaking, name Concept Abductionappeals logic, Concept Dierence appeals algebra (although Dierencemultiple solutions L includes universal role quantication). precisely, recall(Teege, 1994) dierence dened as: C = max {E L : (E D) C} providedC D. specialized denition dierence (Brandt, Kusters, & Turhan, 2002)refers DLs ALC ALE. dened as: C = min {E L : (E D)(C D)}where C, E ALC, ALE, minimality w.r.t. preorder specicnormal form extends CNF ALC. TBox taken account.Instead, solution CAP L, C, D, require C D,C . general, C let H = C CAP P = L, C, D,get solutions C H Dwhich obviously solutions P.Hence C SOL(P), vice versa (see proof Proposition 2 example).C comparison even possible, since C undened. However,generic setting, e.g., e-commerce scenario, subsumption demand supplyquite uncommon; oers neither subsumes other.greater generality, specic application matchmaking, Concept Abduction seemssuited Concept Dierence make basis penalty function.6. Concept ContractionC unsatisable , demander accepts retract Ds constraints,partially matching supplies may reconsidered. However, logic-based approachesmatchmaking Trastour et al. (2002), Sycara et al. (2002), Li Horrocks (2003)usually exclude case concept expressing demand inconsistentconcept expressing supply, assuming requirements strict ones. contrast,believe inconsistent matches still useful, especially e-marketplaces.fact, partial (a.k.a. disjoint) matches basis negotiation process, allowinguser specify negotiable requirementssome could bargained favorother. negotiation process carried various ways adopting approachesmatchmaking based logic (e.g., Strobel & Stolze, 2002), also, shownpractice Colucci et al. (2005), using Belief Revision. fact, logical formalizationconicting matches, aimed nding still interesting inconsistent matches withoutrevert text-based hybrid approaches, obtained exploiting denitionstypical Belief Revision. accordance Gardenfors (1988) formalization, revisionknowledge base K new piece knowledge contraction operation,KA|= A, followed additionresults new knowledge base KAKA usually modeled conjunction. call Concept Contraction adaptationBelief Revision DLs.Starting C unsatisable TBox , model Concept Contractionhow, retracting requirements C, may still obtain concept K (for Keep)K satisable . Clearly, user interested he/she must negotiatestart transactiona concept G (for Give up) C G K.289fiDi Noia, Di Sciascio & Doniniinstance, reference ontology Figure 1, user demands Demsupplier oers Sup, Dem Sup described follows:Dem = HomePC hasMonitor.LCDmonitorSup = HomePC hasMonitor.CRTmonitorpossible check Sup Dem unsatisable. partial match. Yet,case, demander gives concept G = hasMonitor.LCDmonitor keepsconcept K = HomePC, K Sup satisable, hence K potentially matches Sup.formally model Concept Contraction problem follows.Definition 10 (Concept Contraction) Let L DL, C, D, two concepts L,set axioms L, C satisable . Concept ContractionProblem (CCP), denoted L, C, D, , nding pair concepts G, K L L|= C GK, K satisable . call K contraction C according.use Q symbol CCP, denote SOLCCP (Q) setsolutions CCP Q. Observe concept abduction, rule caseseither C unsatisable, correspond counterintuitive situations. notealways trivial solution G, K = C, CCP. solution correspondsdrastic contraction, gives everything C. hand,C satisable , best possible solution , C, is, give nothing.Concept Abduction extends Subsumption, Concept Contraction extends satisabilityparticular, satisability conjunction C D. Hence, results complexitydeciding Satisability given concept carry Contraction.Proposition 5 Let L DL containing AL, let Concept Satisability w.r.t. TBoxL problem C-hard complexity class C. deciding whether given pairconcepts G, K solution CCP Q =L, C, D, C-hard.Proof. concept E L satisable w.r.t. TBox CCP L, C, D,solution , C, C = R.E = R. . Then, L contain leastuniversal role quantication (to express R.E), unqualied existential role quantication(to express R. ), conjunction (to express C G K) least unsatisableconcept (otherwise every concept satisable, problem trivializes). minimal, known DL containing constructs DL AL.gives lower bound complexity Concept Contraction, DLsinclude AL. DLs including AL, note proof showing C-hardnesssatisability involves concept topmost symbol, proof could adaptedConcept Contraction.Obviously, user marketplace likely willing give thingspossible, minimality contraction G must dened. skip concisenessdenitions minimal-length contraction subsumption-maximal contraction,dene straightforwardly conjunction-minimal contraction DLs admit normal formmade conjunctions.290fiSemantic Matchmaking Non-Monotonic Reasoning: Description Logic ApproachDefinition 11 Let Q =L, C, D, CCP L admits CNF. set SOLCCP (Q)subset SOLCCP (Q) following property: G, K SOLCCP (Q)sub-conjunction G G holds G , K SOLCCP (Q). call solutionsirreducible.6.1 Number-Restriction Minimal Contractionsfollows focus specic class irreducible solutions CCP ALN , C, D,exposing interesting characteristics user-oriented point view matchmakingscenario. dening class explain rationale behind investigation usingfollowing example.Example 3 Suppose following situation:demand Dem = HomePC hasMonitor.LCDmonitorsupply Sup = Server hasMonitor.CRTmonitor|= Dem Sup demander contract Dem order regain satisabilitySup. Two solutions CCP Q = ALN , Dem, Sup, are:G= HomePCK = PC ( 1 hasSoftware) (= 1 hasOS)hasMonitor.LCDmonitorG = hasMonitor.LCDmonitorK = HomePCG , K demander give specication HomePC; G , Kdemander give specications monitor type keepingrest.Observe solutions previously dened class SOLCCP (Q),user-oriented point view, G , K seems reasonable solution Q. GivingHomePC concept Demand ( 1 hasMonitor) axiomHomePCthe demander keeps specications requested components,vacuously true, since K Sup implies hasMonitor. i.e., component admitted.order make intuition precise, introduce number-restriction-minimalsolutions Q, whose set denote SOLCCPN (Q). Intuitively, solution G, K QSOLCCPN (Q) at-least restriction ( n R) G directly conictsat-most restriction ( R) (with < n) D. Solutions atleast restriction given conicting universal role quanticationse.g., R.AR.Aare SOLCCPN (Q). Since characteristic number-restrictionminimal solutions enforced level nesting, rst introduce rolepath concept ALN . need distinguish concept(dierent) occurrences another concept, e.g., B = R.A. theory, markoccurrence number, e.g., A1 R.A2 ; however, since need focus oneoccurrence time, mark A.291fiDi Noia, Di Sciascio & DoniniDefinition 12 Given concept B ALN , occurrence atomic (sub)conceptB, role path B, (B) string that:(A) = , denotes empty string(B1 B2 ) = (Bi ), Bi , {1, 2}, concept occurrenceappears(R.B) = R (B), denotes string concatenationrole path (B) represents role nesting concept occurrence conceptB. Note (B) commutation conjunctions B,rearrangement universal role quanticationsif atomic, wouldtrue7 . Using previous denition dene SOLCCPN (Q).Definition 13 Let Q = ALN , C, D, CCP. set SOLCCPN (Q) subsetsolutions G, K SOLCCP (Q) ( n R) occurs G exists( R), < n, occurring CNF (D, ) ( n R) (G) = ( R) (CNF (D, )).illustrate algorithm ndContract returns solution G, K SOLCCPN (Q)Q = ALN , CNF (C, ), CNF (D, ), , is, compares two ALN -concepts C,D, already CNF w.r.t. TBox , computes number-restriction minimal contraction G, K C w.r.t. without considering TBox.Algorithm ndContract (C, D);input ALN concepts C, D, already CNFoutput number-restriction minimal contraction G, K,G, K = , C means C satisablevariables concepts G, K, G , Kbegin1. C =return , ; /* see comment 1 */2. G := ; K := C; /* see comment 2 */3. concept name Knames+exists concept DnamesG := G A; delete K;4. concept ( x R) Kconcept ( R) < xG := G ( x R); delete ( x R) K;5. concept ( x R) Kconcept ( R) > xG := G ( x R); delete ( x R) K;6. concept R.F Kallexist R.E Dall (either ( x R) K x 17. readers familiar concept-centered normal form concepts (Baader et al., 2003),note (B) word UA concept-centered normal form B.292fiSemantic Matchmaking Non-Monotonic Reasoning: Description Logic Approach( x R) x 1 )let G , K result ndContract (F, E)G := G R.G ;replace R.F K R.K ;7. return G, K;end.Let us comment algorithm:1. case Step 1 cannot occur top level, since assumed C satisable denition CCP. However, may occur inside universal quanticatione.g., C = R.hence, case Step 1 may apply recursive call ndContract ,issued Step 6 outer call.2. Step 2, conjunction C assigned K order leave K everyconcept removed subsequent steps.denote G , K solutions CCP Q = ALN , CNF (C, ), CNF (D, ), .simplied CCP Q , completely unfold C forget it.Theorem 4 pair G, K computed ndContract (C, D) number-restrictionminimal contraction Q = ALN , CNF (C, ), CNF (D, ), .Proof.rst prove G, K solution Q , namely, (i) G K C,(ii) K satisable. prove (i) induction. base cases, observeclaim true Step 2 construction, Steps 35 conjunctdeleted K, also added G. Hence claim holds recursive callmade. inductive case, assume claim holds recursive call Step 6,is, G K F every concept R.F Kall . Let Gn , Kn values variables G, Kexecution Step 6, let Kn concept Kn without R.F . Then,Step 6 is:G K = (by assigment)Gn R.G Kn R.K (by denition )Gn Kn R.(G K ) (by inductive hypothesis)Gn Kn R.F (by denition Kn )Gn Kn (since base case holds Step 6)CRegarding (ii), proof induction, inductive hypothesisK E satisable. Basically, construct interpretation (, ) element xx (K D)I , show keep constructing without contradictions,since contradicting concepts deleted K. inductive case, assumeexistence interpretation ( , J ) K E (K E)J ,ffbuild joint interpretation ( , ) letting = , = J {x, RI }.prove G, K number-restriction-minimal solution Q . proofinduction Quantication Nesting (QN) C, dened Section 3.1. Observeat-least restriction deleted K Step 4 ndContract . basecaseQN (C) = 0, recursive callobserve role path retracted concept293fiDi Noia, Di Sciascio & Donini( n R) G , role path concept ( R) causing Step 4executed. Hence, claim holds base case. inductive case, assumeclaim holds concepts QNs smaller QN (C). Observe conceptF Step 6 concept, since QN smaller least 1. Hence, (occurrencean) at-least restriction ( x R), role path ( x R) (F ) deleted F , existsconicting at-most restriction E role path. Since F E occurinside scope concept R.F , R.E respectively, claim still holds role path( x R) (C) = R ( x R) (F ).6.2 Contraction-Based Ranking Partial Matchesdene penalty function p partial matches based following intuition:partial matches ranked based many characteristics retractedC make potential matches.Algorithm penaltyPartial (C, D);input ALN concepts C, D, already CNFoutput penalty partial match Czero means C satisablevariables integer nbegin1. C =return |D|; /* see Comment 1 */2. n = 0;3. concept name Cnames+exists concept Dnamesn := n + 1;4. concept ( x R) Cconcept ( R) < xn := n + 1;5. concept ( x R) Cconcept ( R) > xn := n + 1;6. concept R.F Callexist R.E Dall (either (( x R) C ( R) x y) /* see Comment 2 */( x R) x 1 )n := n + penaltyPartial (F, E);7. return n;end.algorithm structure similar ndContract : whenever ndContractremoves concepts K, penaltyPartial adds penalties n. two dierencesexplained following comments:294fiSemantic Matchmaking Non-Monotonic Reasoning: Description Logic Approach1. Step 1 adds whole length C = . addition ensures antimonotonicity presence , explained Example 4 below.2. Step 6 penaltyPartial additional condition ( R) x y.condition necessary penaltyPartial actually remove concepts,counts them. at-least restriction C contrast at-mostrestriction , ndContract removes K, penaltyPartial adds1 n. Yet, condition Step 6 evaluated, ndContract nds falseat-least restriction removed, penaltyPartial would ndtrue, additional condition.use outcome penaltyPartial dene penalty function partial matches.Definition 14 Given simple TBox ALN , let penalty function p partialmatch counteroer C given oer D, C concepts ALN ,follows..(3)p (C, D, ) = penaltyPartial (CNF (C, ), CNF (D, ))Note since penaltyPartial closely follows ndContract ndIrred , fact Formula (3)similar Formula (1) Denition 9 might appear. Implicitly, solveQ = ALN , CNF (C, ), CNF (D, ), , use result computationpenalty function, main dierence Step 1, though. explain dierencehelp example.Example 4 Let Dem 1 Dem 2 two demands, Dem 2 Dem 1 , let Supsupply, modeled using ontology Figure 1 following:Dem 1 = PC hasMonitor.CRTmonitorDem 2 = PC hasMonitor.Sup = HomePC hasMonitor.LCDmonitorComputing ndContract penaltyPartial CNF (Dem 1 , ) CNF (Dem 2 , )w.r.t. CNF (Sup, ) obtain:ndContract (CNF (Dem 1 , ), CNF (Sup, )) = hasMonitor.CRTmonitor,PC hasMonitor.MonitorpenaltyPartial (CNF (Dem 1 , ), CNF (Sup, )) = 1ndContract (CNF (Dem 2 , ), CNF (Sup, )) = hasMonitor., PCpenaltyPartial (CNF (Dem 2 , ), CNF (Sup, )) = 3summary, concept conicts every concept, yet conceptR. given up, length zero (or constant), hence length G cannotdirectly used antimonotonic penalty function. explains importanceStep 1 algorithm.show following formal correspondence p Concept Contractiondened previous Section.295fiDi Noia, Di Sciascio & DoniniTheorem 5 Let Q = ALN , C, D, CCP, let G , K solution Q returned ndContract (CNF (C, ), CNF (D, )). G contain occurrenceconcept ,p (C, D, ) = |G |Proof. function p based penaltyPartial , inspection, whenever penaltyPartialincrements n, ndContract adds atomic concept G . exception Step 1penaltyPartial , adds |D| ndContract adds G . However, caseexplicitly outside claim.prove p accordance properties highlighted previous Section.Theorem 6 penalty function p (i) non-symmetric, (ii) syntax independent,(iii) antimonotonic subsumption.Proof.(i) Non-symmetry proven example: let C = ( 1 R) R.A, =( 2 R) R.A. simplicity, = , observe C alreadyCNF. show p (C, D, ) = p (D, C, ). fact, former case, observeC must give everything: at-most restriction contrast at-leastrestriction, inside universal quantication contrast R.AD. Hence, penaltyPartial returns 2 = (1 Step 5) + (1 Step 1 recursivecall). Hence, p (C, D, ) = 2. latter case, instead, at-least restrictiongiven (and penaltyPartial adds 1 n Step 4), since role llers imposed,universal quantication compatible (the condition Step 6 false).Hence p (D, C, ) = 1.(ii) syntax independency immediate consequence fact Formula (3)uses normal forms concepts. Since normal forms unique commutativityconjunctionthat xed imposing order conjunctions, e.g., lexicographicclaim holds.(iii) antimonotonicity proved induction QN generic concept Csubsumed C; go conditions subsumption, analyzing changesbehavior algorithm C C . Recall goal provep (C , D, ) p (C, D, ). order make clear distinction two computations, let n (instance the) variable used call penaltyPartial (C , D),n used call penaltyPartial (C, D). ease notation, assume C, Calready CNF.First all, could case C = . case, n = |D| Step 1penaltyPartial . hand, observe penaltyPartial (C, D) |D|either C = too, every increase n corresponds atomic concept Dbyinspection Steps 35, recursively Step 6. Therefore, claim holdsbase case.Cnames C names . case, obvious Step 3 penaltyPartialmake increments n w.r.t. n, since C number iterationsincreases.296fiSemantic Matchmaking Non-Monotonic Reasoning: Description Logic Approachevery number restriction C , either number restriction appears C ,strengthened (an at-least increases, at-most decreases) C . Notestrengthening number restriction C turn false true conditionincrement n Steps 45. instance, passing ( x R) C( x R) C x x, ( R) < x implies < x .similar argument holds at-most. Moreover, number restrictions appearC increase number iterations Steps 45, hence nincrease w.r.t. n claim holds.three cases prove basis induction (C QN equal 0).prove case universal role quantication, assuming claim holds QNs lessQN (C ).every R.F C , either R universally quantied Call ,R.F Call F subsumed F (with F = F special case subsumption). Roles universally quantied Call quantied C ,increase number iterations Step 6, hence n increase duepresence. roles specic restriction F , inductive hypothesis assumed hold, since QN (F ) < QN (C ). Hence p (F , E, ) p (F, E, ).equivalent penaltyPartial (F , E) penaltyPartial (F, E). Moreover,condition Step 6 true call penaltyPartial (C, D), also true, ( x R) C , hence recursivepenaltyPartial (C , D), since R.F Callcall penaltyPartial (F, E) issued, also penaltyPartial (F , E) issued, increasingn least much n increased, inductive hypothesis. Hence claim holdsalso inductive case.7. Matchmaking SystemDLs-based approach semantic matchmaking illustrated previous Sectionsimplemented ALN reasoning engine MaMaS (MatchMaking Service). featuresclassical inference services DL reasoner, also implements algorithms nonstandard services matchmaking presented previous Sections.MaMaS multi-user, multi-ontology Java servlet based system; availableHTTP service at: http://dee227.poliba.it:8080/MAMAS-tng/DIG, exposes DIG1.18 compliant interface. basic DIG 1.1 extended cope non standardservices, briey describe additions.New elements:Match type detection: <matchType>E1 E2</matchType>- computes match typeaccording following classication: Exact (equivalence), Full, Plug-in, Potential,Partial.8. DIG 1.1 new standardized DL systems interface developed Description Logic ImplementationGroup (DIG) (Haarslev & Moller, 2003).297fiDi Noia, Di Sciascio & DoniniConcept Abduction: <abduce>E1 E2</abduce> - implements ndIrred .Concept Contraction: <contract>E1 E2</contract>- implements ndContract .Ranking Score: <rank type="potential">E1 E2</rank><rank type="partial">E1 E2</rank>- computes p (C, D, ) p (C, D, )presented previous Sections.New attributes <newKB/>shared: values used true false. MaMaS, newknowledge base created, KB uri associated IP address clienthost (owner) instantiating KB. shared attribute set false,owner authorized submit tells statements change KB well submitasks. case, requests IP addresses dierent owners oneasks. shared attribute set true, restriction settells asks statements. True default value.permanent: values used true false. MaMaS, KBused 300 seconds, KB automatically released. user wantsmaintain KB indenitely, permanent attribute must set true; falsedefault value.also pointed MaMaS supports simple-TBox, is, conceptaxioms concept name left side9 .using MaMaS matching engine various applications, including emarketplaces, (see e.g., Colucci, Di Noia, Di Sciascio, Donini, Ragone, & Rizzi, 2006;Colucci et al., 2005) semantic web services discovery (Ragone, Di Noia, Di Sciascio,Donini, Colucci, & Colasuonno, 2007). delve details applications here,refer interested reader cited references.7.1 Experimental Evaluationhypothesis seek conrm Section approach performs eectivelywide range matchmaking scenarios, i.e., able model commonsense humanbehavior analyzing ranking, given request, available oers. Hence experimentalframework relies comparison system behavior versus judgement human users.Furthermore, although system may allow use weights increase relevanceconcepts, following results refer basic unweighted version system,avoid biasing results due weights introduction.scenarios tested approach three: apartments rental, date/partnernding, skill management recruiting agencies. Several ontology design methodologiesproposed (Jones, Bench-Capon, & Visser, 1998); adopted one proposedN.F. Noy D.L. McGuinness (2001).9. Notice since MaMaS supports ALN , atomic negation expressed <disjoint/>groups must contain concepts specialized <impliesc> axiom (sub-concept axiom). Denedconcepts <equalc/> (same-class) admitted disjoint group.298fiSemantic Matchmaking Non-Monotonic Reasoning: Description Logic Approachthree scenarios carried thorough domain analysis, starting largeset advertisements taken newspapers descriptions on-line agencies,designed ontologies describing domain. particular:Apartments rental ontology made 146 concepts (primitive + dened) 33roles.Date/partner matching ontology made 131 concepts (primitive + dened)29 roles.Skill matching ontology made 308 concepts (primitive + dened) 38 roles.scenario selected several announcements. total number used experiments human users 180 (120 oers, 60 requests) apartments rental, 215(140 oers, 75 requests) skill matching. 100 advertisements Date matchingscenario also selected, yet actually distinguish among requestsoers announcements form proles, although included preferencesdating partner. announcements natural language manuallytranslated DL syntax. created, domain, 50 sets questionnaires.Questionnaires form one request (a demand supply) 10 oering advertisements. Three groups ten randomly selected volunteers, asked order,according judgement advertisements, respect given requests.obtained average users rankings, run sets advertisements system,gave us set system provided rankings. System rankings included partialmatching advertisements simply ordered worst potential matching advertisement. adopted, reference, standard Vector Space Model (VSM) (Salton & Gill,1983) system. used terms ontologies attening ontology descriptions, dimensions three separate vector spaces, determined weights using classical F IDFmeasure. Similarity results computed using well-known Cosine similarity measure(Salton & Gill, 1983).summarize results adopted Rnorm (Bollmann, Jochum, Reiner, Weissmann,& Zuse, 1985) quality measure system eectiveness. Rnorm dened follows.Given Sup, nite set descriptions user-dened preference relationcomplete transitive, let usr rank ordering Sup induced users preferencerelation, let sys system-provided ranking. Rnorm dened as:Rnorm (sys ) =S+1(1 +)+2Smax+ number descriptions pairs better description rankedsystem ahead worse one; number pairs worse description ranked+maximum possible number + . noticedahead better one Smax+calculation , , Smax based ranking descriptions pairssys relative ranking corresponding descriptions pairs usr . Rnorm valuesrange [0,1]; value 1 corresponds system-provided ordering availabledescriptions either identical one provided human users higherdegree resolution, lower values correspond proportional disagreementtwo. three scenarios considered, results presented table 3.299fiDi Noia, Di Sciascio & DoniniDomainApartments rentalDate/partner matchingSkill matchingMaMaS0.870.790.91VSM0.480.410.46Table 3: Rnorm values: MaMaS: Semantic matchmaking results, VSM: Vector Space ModelresultsAlthough present variability, believe partly due abilitycapture domain ontologies design, show approach provides rankingsclose human commonsense behavior far better obtainedunstructured text retrieval tools.8. Conclusionaddressed matchmaking problem descriptions DL perspective.analyzed semantic-based matchmaking process devised general commonsenseproperties matchmaker have. also pointed classical inferenceservices DLs, satisability subsumption, needed useful, maysucient cope challenges posed matchmaking open environment.Motivated studied Concept Abduction Contraction novel nonmonotonic inferences DLs suitable modeling semantic-based matchmaking scenarios.analyzed minimality criteria, proved simple complexity results. also presentedreasonable algorithms classifying ranking matches based devised inferencesterms penalty functions, proved obey properties individuated.Although several measures may determined compute scorepromising matches proposal logical foundations empyrically shownable well simulate commonsense human reasoning. Obviously, semanticbased approach, also rely well-designed ontologies able modelapplication domain considered.Based theoretical work implemented fully functional matchmakingfacilitator, oriented generic e-marketplace advertisements semantic-basedweb-service discovery, exploits state art technologies protocols, is,best knowledge, running system able cope Concept AbductionConcept Contraction problems.specic reference earlier work authors subject, Di Sciascio et al.(2001) dened matchmaking satisability concept conjunction. Denitions potentialmatch near-miss i.e., partial match, terms abduction belief-revision outlined, need ranking matches motivated, work Di Sciascio, Donini,Mongiello (2002). Di Noia et al. (2003b, 2003c) proposed semantic-based categorizationmatches, logic-based ranking matches within categories, properties ranking functionshave, framework E-marketplaces. extended revised versionworks (Di Noia, Di Sciascio, Donini, & Mongiello, 2004). Di Noia et al. (2003a) intro300fiSemantic Matchmaking Non-Monotonic Reasoning: Description Logic Approachduced Concept Abduction DLs presented algorithms solve Concept AbductionProblem ALN . Colucci et al. (2003) proposed Concept Abduction ConceptContraction inferences suitable semantic-matchmaking explanation services. Calet al. (2004) proposed basic approach adopting penalty functions ranking, framework dating systems. Colucci et al. (2004) proposed initial results algorithms basedtruth-prexed tableau solve Concept Abduction Contraction problems ALN .Colucci et al. (2005) showed services usefully adopted semanticmatchmaking nding negotiation spaces E-Commerce setting. useproposed inference services renement purposes semantic-matchmaking processoutlined work Colucci et al. (2006).current research oriented investigation algorithms expressiveDLs development tableaux-based system proposed inference services.Acknowledgmentsgrateful anonymous reviewers comments suggestions improvedquality paper. thank Andrea Cal Diego Calvanese useful discussions,particular suggesting term penalty function. Simona Colucci, Azzurra Ragone,Marina Mongiello people SisInfLab gave us invaluable help suggestions.research supported EU FP-6 IST STREP TOWL co. 026896.Appendix A. Rules Normal Formnormal form concept obtained repeatedly applying rules twofollowing Sections, rule applicable level nesting concepts inside R.C.A.1 Rules Involving Subconceptsfollowing rules, symbol l.h.s. considered associativecommutative operator; hence, instance, writing ( n R) ( R) secondrule, read concepts ( n R) ( R) appear order insideconjunction two concepts.C( n R) ( R) n >( n R) ( R) ( n R) n >( n R) ( R) ( n R) n <R.D1 R.D2 R.(D1 D2 )R. R. ( 0 R)301fiDi Noia, Di Sciascio & DoniniA.2 Rules Involving Concept TBoxC CC CB1 Bk disj (A, B1 , . . . , Bk )Usually concept resulting application rules referredexpansion, unfolding TBox.A.3 Properties Normal FormLet C concept Classic, let C concept obtained C repeatedlyappying rules. Let |C|, |C | denote size C, C respectively. proved(Borgida & Patel-Schneider, 1994) that:1. |C | polynomially bounded |C|, C computed time O(|C|2 );2. every concept resulting application rules equivalent C, w.r.t.models TBox.consequence latter property, C unsatisable normal form . Then,consequence former property, unsatisability decided polynomial time(Borgida & Patel-Schneider, 1994). fact |C | polynomially bounded |C|intuitively related Nebel (1990) form TBoxes, bushydeep. precise denition given Colucci et al. (2004).ReferencesAgarwal, S., & Lamparter, S. (2005). smart - semantic matchmaking portal electronicmarkets. Proceedings 7th International IEEE Conference E-CommerceTechnology 2005.Arens, Y., Knoblock, C. A., & Shen, W. (1996). Query Reformulation Dynamic Information Integration. Journal Intelligent Information Systems, 6, 99130.Baader, F., Calvanese, D., Mc Guinness, D., Nardi, D., & Patel-Schneider, P. (Eds.). (2003).Description Logic Handbook. Cambridge University Press.Baader, F., & Hollunder, B. (1992). Computing extensions terminological default theories.Proceedings ECAI Workshop Knowledge Representation Reasoning, pp.3052.Baader, F., Kusters, R., Borgida, A., & Mc Guinness, D. (1999). Matching DescriptionLogics. Journal Logic Computation, 9 (3), 411447.Baader, F., Kusters, R., & Molitor, R. (2000). Rewriting concepts using terminologies.Proceedings Seventh International Conference Principles KnowledgeRepresentation Reasoning (KR2000), pp. 297308.302fiSemantic Matchmaking Non-Monotonic Reasoning: Description Logic ApproachBenatallah, B., Hacid, M.-S., Rey, C., & Toumani, F. (2003). Request Rewriting-Based WebService Discovery. International Semantic Web Conference, Vol. 2870 LectureNotes Computer Science, pp. 242257. Springer.Berners-Lee, T., Hendler, J., & Lassila, O. (2001). semantic web. Scientic American,248 (4), 3443.Bollmann, P., Jochum, F., Reiner, U., Weissmann, V., & Zuse, H. (1985). LIVEProject-Retrieval experiments based evaluation viewpoints. Proceedings8th Annual International ACM/SIGIR Conference Research DevelopmentInformation Retrieval, pp. 213214. ACM, New York.Bonatti, P., Lutz, C., & Wolter, F. (2006). Description logics circumscription.Proceedings Tenth International Conference Principles Knowledge Representation Reasoning (KR2006), pp. 400410.Borgida, A., Brachman, R. J., McGuinness, D. L., & A. Resnick, L. (1989). CLASSIC:Structural Data Model Objects. Proceedings ACM SIGMOD InternationalConference Management Data, pp. 5967.Borgida, A., & Patel-Schneider, P. F. (1994). Semantics Complete AlgorithmSubsumption CLASSIC Description Logic. Journal Articial IntelligenceResearch, 1, 277308.Brandt, S., Kusters, R., & Turhan, A. (2002). Approximation dierence description logics. Proceedings Eight International Conference PrinciplesKnowledge Representation Reasoning (KR2002), pp. 203214. MK.Buchheit, M., Donini, F., Nutt, W., & Schaerf, A. (1998). rened architecture terminological systems: Terminology = schema + views. Articial Intelligence, 99 (2),209260.Cal, A., Calvanese, D., Colucci, S., Di Noia, T., & Donini, F. M. (2004). description logicbased approach matching user proles. Proceedings 17th InternationalWorkshop Description Logics (DL04), Vol. 104 CEUR Workshop Proceedings.Calvanese, D. (1996). Reasoning Inclusion Axioms Description Logics. ProceedingsTwelfth European Conference Articial Intelligence (ECAI96), pp. 303307.John Wiley & Sons.Calvanese, D., De Giacomo, G., & Lenzerini, M. (1998). Decidability QueryContainment Constraints. Proceedings Seventeenth ACM SIGACTSIGMOD SIGART Symposium Principles Database Systems (PODS98), pp.149158.Colucci, S., Di Noia, T., Di Sciascio, E., Donini, F., & Mongiello, M. (2003). Concept Abduction Contraction Description Logics. Proceedings 16th InternationalWorkshop Description Logics (DL03), Vol. 81 CEUR Workshop Proceedings.Colucci, S., Di Noia, T., Di Sciascio, E., Donini, F., & Mongiello, M. (2004). UniformTableaux-Based Approach Concept Abduction Contraction ALN. Proceedings 17th International Workshop Description Logics (DL04), Vol. 104CEUR Workshop Proceedings.303fiDi Noia, Di Sciascio & DoniniColucci, S., Di Noia, T., Di Sciascio, E., Donini, F., & Mongiello, M. (2005). ConceptAbduction Contraction Semantic-based Discovery Matches NegotiationSpaces E-Marketplace. Electronic Commerce Research Applications, 4 (4),345361.Colucci, S., Di Noia, T., Di Sciascio, E., Donini, F., Ragone, A., & Rizzi, R. (2006).semantic-based fully visual application matchmaking query renement B2Ce-marketplaces. 8th International conference Electronic Commerce, ICEC 06,pp. 174184. ACM Press.Console, L., Dupre, D., & Torasso, P. (1991). Relationship AbductionDeduction. Journal Logic Computation, 1 (5), 661690.Devambu, P., Brachman, R. J., Selfridge, P. J., & Ballard, B. W. (1991). LASSIE:Knowledge-Based Software Information System. Communications ACM, 34 (5),3649.Di Noia, T., Di Sciascio, E., Donini, F., & Mongiello, M. (2003a). Abductive matchmakingusing description logics. Proceedings Eighteenth International Joint Conference Articial Intelligence (IJCAI 2003), pp. 337342.Di Noia, T., Di Sciascio, E., Donini, F., & Mongiello, M. (2003b). Semantic matchmakingP-2-P electronic marketplace. Proc. Symposium Applied Computing (SAC03), pp. 582586. ACM.Di Noia, T., Di Sciascio, E., Donini, F., & Mongiello, M. (2003c). system principledMatchmaking electronic marketplace. Proc. International World Wide WebConference (WWW 03), pp. 321330. ACM, New York.Di Noia, T., Di Sciascio, E., Donini, F., & Mongiello, M. (2004). system principled Matchmaking electronic marketplace. International Journal ElectronicCommerce, 8 (4), 937.Di Sciascio, E., Donini, F., & Mongiello, M. (2002). Knowledge representation matchmaking P2P e-commerce. Atti dellVIII Convegno dellAssociazione Italiana diIntelligenza Articiale, Siena.Di Sciascio, E., Donini, F., Mongiello, M., & Piscitelli, G. (2001). Knowledge-Based System Person-to-Person E-Commerce. Proceedings KI-2001 WorkshopApplications Description Logics (ADL-2001), Vol. 44 CEUR Workshop Proceedings.Donini, F. M. (2003). Complexity reasoning. Description Logics Handbook, chap. 3.Cambridge University Press.Donini, F. M., Lenzerini, M., Nardi, D., & Nutt, W. (1991). Complexity Concept Languages. Allen, J., Fikes, R., & Sandewall, E. (Eds.), ProceedingsSecond International Conference Principles Knowledge RepresentationReasoning (KR91), pp. 151162. Morgan Kaufmann, Los Altos.Donini, F. M., Nardi, D., & Rosati, R. (1997a). Autoepistemic description logics. Proc.IJCAI 97, pp. 136141.304fiSemantic Matchmaking Non-Monotonic Reasoning: Description Logic ApproachDonini, F. M., Lenzerini, M., Nardi, D., & Nutt, W. (1997b). complexity conceptlanguages. Information Computation, 134, 158.Eiter, T., & Gottlob, G. (1995). Complexity Logic-Based Abduction. JournalACM, 42 (1), 342.Finin, T., Fritzson, R., McKay, D., & McEntire, R. (1994). KQML Agent Communication Language. Proceedings Third International Conference InformationKnowledge Management (CIKM94), pp. 456463. ACM.Gardenfors, P. (1988). Knowledge Flux: Modeling Dynamics Epistemic States.Bradford Books, MIT Press, Cambridge, MA.Gil, Y., & Ramachandran, S. (2001). PHOSPHORUS: Task based Agent Matchmaker.Proc. International Conference Autonomous Agents 01, pp. 110111. ACM.Gonzales-Castillo, J., Trastour, D., & Bartolini, C. (2001). Description Logics Matchmaking Services. Proceedings KI-2001 Workshop Applications Description Logics (ADL-2001), Vol. 44. CEUR Workshop Proceedings.Grimm, S., Motik, B., & Preist, C. (2006). Matching Semantic Service DescriptionsLocal Closed-World Reasoning. European Semantic Web Conference, pp. 575589.Haarslev, V., & Moller, R. (2003). dig description logic interface. ProceedingsInternational Workshop Description Logics (DL-2003), Vol. 81 CEUR WorkshopProceedings.Horrocks, I., & Tobies, S. (2000). Reasoning axioms: Theory practice.. Proceedings Seventh International Conference Principles Knowledge Representation Reasoning (KR2000), pp. 285296.Jacobs, N., & Shea, R. (1995). Carnot Infosleuth Database Technology Web.Proceedings ACM SIGMOD International Conference ManagementData, pp. 443444. ACM.Jones, D., Bench-Capon, T., & Visser, P. (1998). Methodologies ontology development.J. Cuena, editor, Proc. 15th IFIP World Computer Congress, pp. 6275, London,UK. Chapman Hall.Karacapilidis, N., & Moraitis, P. (2001). Building Agent-Mediated Electronic CommerceSystem Decision Analysis Features. Decision Support Systems, 32, 5369.Kieling, W. (2002). Foundations preferences database systems. ProceedingsTwentyeight International Conference Large Data Bases (VLDB 2002).Klusch, M., Fries, B., Khalid, M., & Sycara, K. (2005). Owls-mx: Hybrid owl-s servicematchmaking. Proceedings 1st Intl. AAAI Fall Symposium AgentsSemantic Web.Kuokka, D., & Harada, L. (1996). Integrating Information Via Matchmaking. JournalIntelligent Information Systems, 6, 261279.Li, L., & Horrocks, I. (2003). Software Framework Matchmaking Based SemanticWeb Technology. Proc. International World Wide Web Conference (WWW 03),pp. 331339. ACM, New York.305fiDi Noia, Di Sciascio & DoniniLutz, C. (1999). Reasoning concrete domains. Dean, T. (Ed.), ProceedingsSixteenth International Joint Conference Articial Intelligence (IJCAI99), pp.9095, Stockholm, Sweden. Morgan Kaufmann, Los Altos.Madhavan, J., Bernstein, P., & Rahm, E. (2001). Generic schema matching cupid.Proceedings Twentyseventh International Conference Large Data Bases(VLDB 2001), pp. 4958.Maes, P., Guttman, R., & Moukas, A. (1999). Agents Buy Sell. CommunicationsACM, 42 (3), 8191.Motro, A. (1988). VAGUE: User Interface Relational Databases Permits VagueQueries. ACM Transactions Oce Information Systems, 6 (3), 187214.Nebel, B. (1990). Terminological Reasoning Inherently Intractable. Articial Intelligence,43, 235249.N.F. Noy D.L. McGuinness (2001). Ontology Development 101: Guide CreatingFirst Ontology. Stanford Knowledge Systems Laboratory Technical Report KSL01-05.Paolucci, M., Kawamura, T., Payne, T., & Sycara, K. (2002). Semantic Matching WebServices Capabilities. Semantic Web - ISWC 2002, No. 2342 Lecture NotesComputer Science, pp. 333347. Springer-Verlag.Peirce, C. . (1955). Abduction induction. Philosophical Writings Peirce, chap. 11.J. Buchler.Ragone, A., Di Noia, T., Di Sciascio, E., Donini, F., Colucci, S., & Colasuonno, F. (2007).Fully Automated Web Services Discovery Composition Concept CoveringConcept Abduction. International Journal Web Services Research (JWSR),4 (3).Raman, R., Livny, M., & Solomon, M. (1998). Matchmaking: distributed resource management high throughput computing. Proceedings IEEE High PerformanceDistributed Computing Conf., pp. 140146.Salton, G., & Gill, M. M. (1983). Introduction Modern Information Retrieval. McGrawHill, New York.Schmidt-Schau, M., & Smolka, G. (1991). Attributive Concept Descriptions Complements. Articial Intelligence, 48 (1), 126.Shvaiko, P., & Euzenat, J. (2005). survey schema-based matching approaches. JournalData Semantics, 4, 146171.Strobel, M., & Stolze, M. (2002). Matchmaking Component Discovery Agreement Negotiation Spaces Electronic Markets. Group Decision Negotiation,11, 165181.Sycara, K., Paolucci, M., Van Velsen, M., & Giampapa, J. (2003). RETSINA MASinfrastructure. Autonomous agents multi-agent systems, 7, 2948.Sycara, K., Wido, S., Klusch, M., & Lu, J. (2002). LARKS: Dynamic Matchmaking AmongHeterogeneus Software Agents Cyberspace. Autonomous agents multi-agentsystems, 5, 173203.306fiSemantic Matchmaking Non-Monotonic Reasoning: Description Logic ApproachTeege, G. (1994). Making dierence: subtraction operation description logics.Proceedings Fourth International Conference Principles KnowledgeRepresentation Reasoning (KR94), pp. 540550. MK.Trastour, D., Bartolini, C., & Priest, C. (2002). Semantic Web Support Business-toBusiness E-Commerce Lifecycle. Proc. International World Wide Web Conference(WWW) 02, pp. 8998. ACM.Veit, D., Muller, J., Schneider, M., & Fiehn, B. (2001). Matchmaking AutonomousAgents Electronic Marketplaces. Proc. International Conference AutonomousAgents 01, pp. 6566. ACM.Wang, H., Liao, S., & Liao, L. (2002). Modeling Constraint-Based Negotiating Agents.Decision Support Systems, 33, 201217.Wright, J. R., Weixelbaum, E. S., Vesonder, G. T., Brown, K. E., Palmer, S. R., Berman,J. I., & Moore, H. H. (1993). Knowledge-Based Congurator Supports Sales,Engineering, Manufacturing AT&T Network Systems. AI Magazine, 14 (3),6980.307fiJournal Artificial Intelligence Research 29 (2007) 4977Submitted 09/06; published 05/07Solution-Guided Multi-Point Constructive Search JobShop SchedulingJ. Christopher Beckjcb@mie.utoronto.caDepartment Mechanical & Industrial EngineeringUniversity Toronto, CanadaAbstractSolution-Guided Multi-Point Constructive Search (SGMPCS) novel constructivesearch technique performs series resource-limited tree searches searchbegins either empty solution (as randomized restart) solutionencountered search. small number elite solutions maintainedsearch. introduce technique perform three sets experimentsjob shop scheduling problem. First, systematic, fully crossed study SGMPCScarried evaluate performance impact various parameter settings. Second,inquire diversity elite solution set, showing, contrary expectations,less diverse set leads stronger performance. Finally, compare best parametersetting SGMPCS first two experiments chronological backtracking, limiteddiscrepancy search, randomized restart, sophisticated tabu search algorithm setwell-known benchmark problems. Results demonstrate SGMPCS significantlybetter constructive techniques tested, though lags behind tabu search.1. Introductionnumber metaheuristic evolutionary approaches optimization describedsolution-guided, multi-point searches. example, genetic mimetic algorithms, population solutions maintained used basis search. newgeneration created combining aspects current generation: search thereforeguided existing solutions. population contains number individual solutions,search makes use multiple points search space. Traditional single-point metaheuristics, tabu search, augmented similar way. TSAB tabusearch (Nowicki & Smutnicki, 1996) maintains elite pool consisting small numberbest solutions found far search. Whenever basic search reachesthreshold number moves without finding new best solution, search restarted oneelite solutions. Again, higher-level search guided multiple existing solutions,though guidance somewhat different genetic algorithms.Solution-Guided Multi-Point Constructive Search (SGMPCS) 1 framework designedallow constructive search guided multiple existing (suboptimal) solutionsproblem instance. randomized restart techniques (Gomes, Selman, & Kautz,1998), framework consists series tree searches restricted resource limit,1. previous conference workshop publications, SGMPCS referred simply Multi-Point Constructive Search (Beck, 2006; Heckman & Beck, 2006; Beck, 2005a, 2005b). Empirical evidenceimportance solution guidance motivated change name reflective importantdifferences work existing tree search techniques.c2007AI Access Foundation. rights reserved.fiBecktypically maximum number fails. resource limit reached, search restarts.difference randomized restart SGMPCS keeps track small set elitesolutions: best solutions found. search restarted, startsempty solution, randomized restart, one elite solutions.paper, undertake first fully crossed systematic empirical study SGMPCS. particular, Section 3 investigate different parameter settings impact search performance makespan-minimization variant job shop scheduling problem. Results indicate guidance elite solutions contributes significantlyalgorithm performance but, somewhat unexpectedly, smaller elite set size resultsbetter performance. Indeed, elite set size one showed best performance.result motivates subsequent experimentation diversity elite set Section 4.show, contrary expectation consistent elite set size one,less diverse elite set, stronger performance. discussed in-depth Section6, two sets experiments call question extent exploitationmultiple points search space important performance SGMPCS.final experiment (Section 5) compares best parameter settings found first twoexperiments chronological backtracking, limited discrepancy search (Harvey, 1995),randomized restart, state-of-the-art tabu search (Watson, Howe, & Whitley, 2006)set well-known benchmarks. results show SGMPCS significantly outperforms constructive search methods perform well tabusearch.contributions paper follows:1. introduction systematic experimental evaluation Solution-Guided MultiPoint Constructive Search (SGMPCS).2. investigation importance diversity elite set performanceSGMPCS.3. demonstration SGMPCS significantly out-performs chronological backtracking, limited discrepancy search, randomized restart benchmark set jobshop scheduling problems.2. Solution-Guided Multi-Point Constructive SearchPseudocode basic Solution-Guided Multi-Point Constructive Search algorithmshown Algorithm 1. algorithm initializes set, e, elite solutions enterswhile-loop. iteration, probability p, search started empty solution(line 6) randomly selected elite solution (line 12). former case,best solution found search, s, better worst elite solution, replacesworst elite solution. latter case, replaces starting elite solution, r,better r. individual search limited maximum number failsincurred. optimal solution found proved overall boundcomputational resources (e.g., CPU time, number fails) reached, best elitesolution returned.elite solutions initialized search technique. paper, use 50independent runs randomized texture-based heuristic employed50fiSolution-Guided Multi-Point Constructive SearchSGMPCS():123456789101112131415initialize elite solution set etermination criteria unmetrand[0, 1) < pset upper bound cost functionset fail limit, l:= search(, l)6= better worst(e)replace worst(e)endelser := randomly chosen element eset upper bound cost functionset fail limit, l:= search(r, l)6= better rreplace rendendendreturn best(e)Algorithm 1: SGMPCS: Solution-Guided Multi-Point Constructive Searchmain search (see Section 3.2). backtracking done upper bound placedcost function. Without upper bound, run find solution, though probably onequite low quality. initial set 50 solutions, |e| best solutions insertedelite set. primary goal initialization quickly populate elite set.Previous work (Beck, 2006) shown spending effort run findgood starting solutions (e.g., via backtracking search) significantly improve overallperformance, number runs impact. variance quality amonginitial solutions high, best starting solution large elite set much bettersmall elite set. difference alone sufficient skew experimentsmeasured impact different elite set sizes overall performance. mitigateeffect generate fixed number elite solution candidates (i.e., 50) choose|e| best. interesting direction future work adaptively determine best timetransition elite pool generation main search.2.1 Searchlines 6 12 search(r, l) function standard tree search randomization,limited number fails, l, and, r 6= , guided solution r. search functionreturns best solution found, any, indication whether search spaceexhausted. Given large enough fail limit, individual search completely searchspace. Therefore, completeness approach depends policy settingincreasing fail limit. see Experiment 3 (Section 5), SGMPCS able51fiBeckfind optimal solutions prove optimality. place restrictionssearch, allowing tree traversal technique used. particular, experimentchronological backtracking limited discrepancy search (Harvey, 1995).r 6= , search guided reference solution, r. guiding solutionsimply used value ordering heuristic: search using (randomized) variableordering heuristic specifying value assigned variable onereference solution, provided still domain variable.search tree created asserting series choice points form: hV = xihVi 6=xi, Vi variable x value assigned V . Given importance variableordering heuristics constructive search, expect order choice pointsimpact search performance. SGMPCS can, therefore, use variable orderingheuristic choose next variable assign. choice point formed using valueassigned reference solution or, value reference solution inconsistent,heuristically chosen value. formally, let reference solution, r, set variableassignments, {hV1 = x1 i, hV2 = x2 i, . . . , hVm = xm i}, n, n numbervariables. variable ordering heuristic complete freedom choose variable, V ,assigned. xi dom(Vi ), hVi = xi r, choice point made x = x .Otherwise, xi/ dom(Vi ), value ordering heuristic used choose x dom(V ).need account possibility x/ dom(Vi ) reference solutionnecessarily valid solution later SGMPCS search process. take simpleexample, reference solution cost 100 constrain search findbetter solution, reach reference solution. Rather, via constraint propagation,reach dead-end different solution.technique starting constructive search reference solution quite general.Existing high-performance variable ordering heuristics exploited and, addressingcase xi/ dom(Vi ), make assumptions changes constraint modelmay made reference solution originally found. particular,means elite solution could solution relaxation full problem.2.2 Setting Bounds Cost Functionindividual search (lines 6 12), place upper bound cost function.bound impact set solutions and, therefore, solutions mayenter elite set. Intuitions constructive search metaheuristics differappropriate choice upper bound. standard tree search optimizationdiscrete cost function, usual approach use c 1 upper bound, cbest solution found far. Using higher bound would expand search spacewithout providing heuristic benefit. contrast, standard metaheuristic approach,search usually restricted enforcing upper bound cost acceptable states:search allowed travel worse states order (hopefully) find better ones.consequence, common replace elite solution better, necessarilybest-known, solution found. Since elite solutions used heuristically guide search,even solutions best-known provide heuristic guidance.two perspectives result two policies:1. Global Bound: Always set upper bound search cost c 1.52fiSolution-Guided Multi-Point Constructive Search2. Local Bound: starting empty solution, set upper boundequal one less cost worst elite solution. starting elitesolution, set upper bound one less cost starting solution.constraint programming, back-propagation extent placing boundcost function results domain reductions decision variables. Previous experimentsSGMPCS optimization problems strong back-propagation (such job shopscheduling objective minimizing makespan) show global bound policysuperior (Beck, 2006). problems weaker back-propagation satisfactionproblems (where back-propagation), local bound approach performs better(Beck, 2006; Heckman & Beck, 2006). Based results, use global boundpolicy here.2.3 Related WorkSGMPCS directly inspired TSAB tabu search algorithm (Nowicki & Smutnicki, 1996) noted above. TSAB, elite pool consisting small number bestsolutions found maintained search. Whenever basic tabu search stagnates,is, reaches threshold number moves without finding new best solution,search restarted one elite solutions. tabu list modifiedsearch restarted, follow different search path. basic mechanism,adapted constructive search, used SGMPCS. number years, TSABstate-of-the-art algorithm job shop scheduling problems. recentlyover-taken i-TSAB, algorithm based TSAB makes sophisticated useelite pool (Nowicki & Smutnicki, 2005). in-depth analysis i-TSAB seework Watson, Howe, Whitley (2006).SGMPCS performs series resource-limited tree searches. clear behaviour related extensive work randomized restart (Gomes et al., 1998; Horvitz,Ruan, Gomes, Kautz, Selman, & Chickering, 2001; Kautz, Horvitz, Ruan, Gomes, & Selman, 2002; Gomes, Fernandez, Selman, & Bessiere, 2005; Hulubei & OSullivan, 2006).Indeed, setting p, probability searching empty solution, 1 resultsrandomized restart technique. observed search effort chronologicalbacktracking given variable ordering forms heavy-tailed distribution. Intuitively,means randomly chosen variable ordering non-trivial chance resultingeither small large cost find solution problem instance. solutionfound threshold amount effort, beneficial restart search differentvariable ordering new ordering non-trivial probability quickly leadingsolution.number techniques make use randomized heuristic backtracking (Prestwich, 2002; Jussien & Lhomme, 2002; Dilkina, Duan, & Havens, 2005)form hybrid local search tree search allow exploration search spaceconstrained standard tree search. approaches differ SGMPCSfundamental level: use (multiple) existing solutions guide search.53fiBeck3. Experiment 1: Parameter Settingsprimary purpose experiment understand impact different parameter settings performance SGMPCS algorithms. present fully crossedexperiment evaluate impact varying parameters SGMPCS.3.1 SGMPCS ParametersElite Set Size number elite solutions maintained searchkey parameter controlling extent multiple points search spaceexploited SGMPCS. seem significant experimentationelite set size metaheuristic community, anecdotally, hybrid tabu searchelite set smaller six performs much worse larger elite sets job shopscheduling problems.2 paper, experiment elite set sizes {1, 4, 8, 12, 16, 20}.Proportion Searches Empty Solution p parameter controlsprobability searching empty solution versus searching one elitesolutions. high p value result algorithm behaviour similar randomized restartindeed, p = 1 randomized restart algorithm. One reason p parameterincluded SGMPCS intuition also impact diversityelite pool: higher p value diverse elite pool solutionsunrelated current elite solutions likely enter pool. seeExperiment 2, intuition contradicted empirical results. Here, studyp = {0, 0.25, 0.5, 0.75, 1}.Fail Limit Sequence resource limit sets number fails allowedtree search. Rather constant limit faced problem tuninglimit (Gomes et al., 1998), following work Kautz, Horvitz, Ruan, Gomes, Selman(2002), adopt dynamic restart policy limit number fails changesproblem solving. look two simple fail limit sequences (seq):Luby - fail limit sequence optimal sequence satisfaction problems condition knowledge solution distribution (Luby, Sinclair, &Zuckerman, 1993). sequence follows: 1, 1, 2, 1, 1, 2, 4, 1, 1, 2, 1, 1, 2, 4, 8,.... is, fail limit first second searches 1 fail, third search2 fails, on. sequence independent outcome searcheswhether search empty solution guided elite solution.Polynomial (Poly) - fail limit initialized 32 reset 32 whenever newbest solution found. Whenever search fails find new best solution, boundgrows polynomially adding 32 fail limit. value 32 chosen givereasonable increase fail limit iteration. tuning done determinevalue 32. Luby limit, Poly fail limit independent choicesearch empty solution elite solution.2. Jean-Paul Watson personal communication.54fiSolution-Guided Multi-Point Constructive SearchBacktrack Method Finally, noted above, style individual tree searchlimited chronological backtracking. Whether search begins empty solutionelite solution, choice search performed. particular,backtracking (bt) factor either standard chronological backtracking limited discrepancysearch (LDS) (Harvey, 1995). either case, search limited fail limitdescribed above.3.2 Experimental Detailsexperimental problems job shop scheduling problem (JSP) instances. n jobshop scheduling problem consists set n jobs, consisting complete orderingactivities. activity duration specified resource mustexecute. ordering activities job represents chain precedence constraints:activity cannot start preceding activity job completed. activitybegins execution, must execute complete duration (i.e., pre-emption allowed).unary capacity resources, meaning resource used oneactivity time. optimal solution JSP sequence activitiesresource union job sequences resource sequences acyclic,makespan (the time start earliest job end latest job)minimized. JSP NP-hard (Garey & Johnson, 1979) received extensive studyoperations research artificial intelligence literature (Jain & Meeran,1999).experimental instances twenty 20 20 problem instances generated usingexisting generator (Watson, Barbulescu, Whitley, & Howe, 2002). durationsactivities independently drawn uniform probability [1, 99]. machineroutings generated create work-flow problems job visits first 10 machines second 10 machines. Within two machine sets, routingsgenerated randomly uniform probability. Work-flow JSPs usedshown difficult JSPs random machine routings (Watson, 2003).algorithm run 20 CPU minute time-out, problem instance solved10 times independently given parameter configuration. algorithms implementedILOG Scheduler 6.2 run 2GHz Dual Core AMD Opteron 270 2Gb RAMrunning Red Hat Enterprise Linux 4.experiment, dependent variable mean relative error (MRE) relativebest solution known problem instance. MRE arithmetic meanrelative error run problem instance:MRE (a, K, R) =1 X X c(a, k, r) c (k)|R||K|c (k)(1)rR kKK set problem instances, R set independent runs different randomseeds, c(a, k, r) lowest cost found algorithm instance k run r, c (k)lowest cost known k. problem instances generated experiment,best-known solution found either algorithms tested variations usedpreliminary experiments.33. Problem instances best-known solutions available author.55fiBeckvariable ordering heuristic chooses pair activities resourcesequence. Texture-based heuristics (Beck & Fox, 2000) used identify resourcetime point maximum contention among activities choose pairunordered activities, branching two possible orders. heuristic randomizedspecifying hresource, time pointi pair chosen uniform probabilitytop 10% critical pairs. starting search elite solution, heuristicused choose pair activities sequenced, ordering found solutionasserted. standard constraint propagation techniques scheduling (Nuijten, 1994;Laborie, 2003; Le Pape, 1994) used algorithms.3.3 Resultsfully crossed experimental design implemented, consisting four factors (|e|, p, seq,bt) total 120 cells (6 5 2 2). cell result 10 runs20 problem instances, time limit run 20 minutes. resultsgenerated 333 CPU days.Analysis variance (ANOVA) MRE 1200 seconds shows factorsinteractions significant p 0.005. ANOVA shown Table 1.Factor(s)epbtseqe:pe:btp:bte:seqp:seqbt:seqe:p:bte:p:seqe:bt:seqp:bt:seqe:p:bt:seqResidualsDf541120545412020542023880Sum Sq0.999521.93760.86260.49240.37350.11440.30230.13590.22650.00360.03720.05030.00410.00780.01053.8821Mean Sq0.19995.48440.86260.49240.01870.02290.07560.02720.05660.00360.00190.00250.00080.00200.00050.0002F value1229.601533736.22775306.13503028.6761114.8711140.7780464.9442167.1942348.387222.146811.436115.48595.019112.02813.2147Pr(>F)< 2.2e-16< 2.2e-16< 2.2e-16< 2.2e-16< 2.2e-16< 2.2e-16< 2.2e-16< 2.2e-16< 2.2e-162.540e-06< 2.2e-16< 2.2e-160.00013429.144e-101.547e-06Table 1: Summary analysis variance found using R statistical package (RDevelopment Core Team, 2006). factors interactions significantp 0.005.attain detailed view results, Tukey HSD test (R Development CoreTeam, 2006) performed factors. Tukey HSD allows comparison multiple means controlling problems multiple testing. Table 2 showsthat, significance level p 0.005:Smaller |e| significantly better larger |e|.56fiSolution-Guided Multi-Point Constructive Searchp = 0 p = 0.25 significantly different. However, resultsignificantly lower MRE p = 0.50. p > 0.25, smaller value p better.Luby fail limit sequence significantly better Poly sequence.Chronological backtracking significantly better LDS.|e|pseqbt1 < 4 < 8 < 12 < 16 < 20{0, 0.25} < 0.50 < 0.75 < 1.00Luby < Polychron < ldsTable 2: results independent Tukey HSD tests factor. Significance leveltest parameter p 0.005. < b means incurs lower MREb, difference MRE values statistically significant. Parenthesis(i.e., {}) indicate statistically significant difference MRE.Finally, Table 3 presents five best five worst parameter settings determinedMRE 1200 CPU seconds. interesting note five worst settingsp = 1.00, corresponds pure randomized restart algorithm.|e|pBTSeq.MREFive Best Parameter Settings1 0.25 chron Luby 0.031584494 0.25 chron Luby 0.033084681 0.25 chron Poly 0.033284294 0.50 chron Luby 0.033908881 0.50 chron Poly 0.03421443Five Worst Parameter Setting4 1.00 chron Poly 0.1263789320 1.00 chron Poly 0.126455271 1.00 chron Poly 0.1265111712 1.00 chron Poly 0.126538768 1.00 chron Poly 0.12711269Table 3: best worst parameter combinations Experiment 1 based MRE.graphical representation results experiment impractical. However,statistical analysis based performance set parameter values 1200seconds, evolution performance time reflected results.Given arbitrariness 1200 second time limit, valid question wonderresults would change given different limit. address concern providegraphical sense results, present graphs experimental results oneparameter varied others held best values. parameterstwo values (i.e., seq bt) display results two different values |e| well.Elite Set Size: |e| Figure 1 shows results varying elite set sizeparameter settings follows: p = 0.25, seq = Luby, bt = chron. differences57fiBeckvarious levels |e| conclusion lower |e| results better performanceseen hold time limits less 1200 seconds. fact, superiorityalgorithms small |e| visible early search; 200 seconds,gaps among algorithms begin narrow.0.2SGMPCS |e|=20 (p=0.25, seq=luby, bt=chron)SGMPCS |e|=16 (p=0.25, seq=luby, bt=chron)SGMPCS |e|=12 (p=0.25, seq=luby, bt=chron)SGMPCS |e|=8 (p=0.25, seq=luby, bt=chron)SGMPCS |e|=4 (p=0.25, seq=luby, bt=chron)SGMPCS |e|=1 (p=0.25, seq=luby, bt=chron)Mean Relative Error0.150.10.0500200400600Time (secs)80010001200Figure 1: mean relative error SGMPCS set makespan JSPs sizeelite set varied.Given importance diversity elite solution sets within metaheuristic literature, performance algorithms elite size 1 somewhat surprisingseems contradict original intuitions motivations SGMPCS.return point Experiment 2.Probability Search Empty Solution: p Figure 2 displays resultsvarying p holding parameter values constant |e| = 1, seq = Luby,bt = chron. dramatic result performance p = 1.00, purerandomized restart technique. settings p result performanceorder magnitude4 better p = 1.00.Unlike experiments |e| values, observe change relativestrengths different parameter settings different time limits. p = 0.25results best performance time limits, low limits p = 0 appears out-performp = 0.50 p = 0.75. Later, latter two parameter values result better performancep = 0. Note apparent contradiction statistical significance findings4. MRE value achieved p = 1.00 1200 seconds achieved p values less 100seconds.58fiSolution-Guided Multi-Point Constructive Search0.2SGMPCS p=1.00 (|e|=1, seq=luby, bt=chron)SGMPCS p=0.00 (|e|=1, seq=luby, bt=chron)SGMPCS p=0.75 (|e|=1, seq=luby, bt=chron)SGMPCS p=0.50 (|e|=1, seq=luby, bt=chron)SGMPCS p=0.25 (|e|=1, seq=luby, bt=chron)Mean Relative Error0.150.10.0500200400600Time (secs)80010001200Figure 2: mean relative error varying p-values SGMPCS makespan JSPs.Table 2 explained fact interaction among parametersp = 0 performs better values rest parameters.Fail Sequence: seq Plots comparing two different fail sequences shown Figure3 p = 0.25, bt = chron, two different |e| values, |e| = 1 |e| = 4.run-times less 100 CPU seconds, Poly fail sequence performs betterLuby sequence conditions. threshold, Luby performs better.Backtracking Method: bt Finally, Figure 4 displays result varying backtracking method parameters p = 0.25, seq = luby, |e| = 1 |e| = 4. Usingchronological backtracking problems clearly results superior performancetime limits compared LDS.3.4 Summaryexperiment demonstrates job shop scheduling makespan minimization,best-performing parameter settings SGMPCS are: small elite set, relatively lowprobability starting search empty solution, Luby fail limit sequence,chronological backtracking. general, results robust changes time limitplaced runs.One careful interpreting results number reasons.1. shown ANOVA, parameters statistically significant interactions,directly seen performance p = 0, |e| = 1 Figure 2.59fiBeck0.2SGMPCS poly, |e|=4 (p=0.25, bt=chron)SGMPCS luby, |e|=4 (p=0.25, bt=chron)SGMPCS poly, |e|=1 (p=0.25, bt=chron)SGMPCS luby, |e|=1 (p=0.25, bt=chron)Mean Relative Error0.150.10.0500200400600Time (secs)80010001200Figure 3: mean relative error makespan JSPs two different fail sequences|e| = 1 |e| = 4.2. statistically significant effect factors, exceptionpoor performance p = 1.00, performance different parameter settingsdisplayed graphs wildly varying. differences amonglevels different factors may statistically significant, may practicallysignificant. advantage SGMPCS suggests fine tuningparameters really necessary: SGMPCS somewhat robust sensesmall changes parameters result small changes performance (again,exception p = 1.00).3. results presented based single problem, job shop schedulingmakespan minimization. comment applicability resultsproblems Section 6.2.4. Experiment 2: Impact Elite Set DiversitySGMPCS designed number intuitions impact diversity performance likely effect different parameter settings performance. particular,test following intuitions:higher |e| tend result higher diversity. strict relationshippossible solutions e identical.60fiSolution-Guided Multi-Point Constructive Search0.2SGMPCS lds, |e|=4 (p=0.25, seq=luby)SGMPCS lds, |e|=1 (p=0.25, seq=luby)SGMPCS chron, |e|=4 (p=0.25, seq=luby)SGMPCS chron, |e|=1 (p=0.25, seq=luby)Mean Relative Error0.150.10.0500200400600Time (secs)80010001200Figure 4: mean relative error using Luby fail limit either chronological backtracking LDS makespan JSPs.higher p value tend increase diversity. Since higher p increases proportion searches empty solution, lead wider explorationsearch space therefore diverse elite set.extent exploitation multiple points search space importantSGMPCS reflected performance sets different levelsdiversity. is, important simultaneously share search effort amongnumber regions search space, would expect higher levels diversitywould out-perform lower levels threshold diminishing returns.4.1 Measuring Diversitydisjunctive graph (Pinedo, 2005) standard representation job shop schedulingproblem activity node precedence constraints relating activitiesjob directed, conjunctive arcs. pair activities different jobsresource, disjunctive arc: arc directed eitherway. solution, disjunctive arc must oriented one direction graph(which contains conjunctive arcs) acyclic.Following work Watson, Beck, Howe, Whitley (2003), measure diversityelite pool mean pair-wise disjunctive graph distance. binary variableintroduced disjunctive constraint one value represents one orientationarc value, opposite orientation. solution problem therefore61fiBeckrepresented assignment disjunctive graph variables. distancepair solutions simply Hamming distance disjunctive graphvariable assignments. given elite set, take mean pair-wise distance measurediversity.Clearly, measure well-formed |e| = 1. assume diversityelite set size 1 0.4.2 Initial Evaluation Diversityinitial evaluation diversity simply measure diversity problem instances subset parameter values used Experiment 1. SGMPCS solverinstrumented calculated pair-wise Hamming distance whenever new solutioninserted elite set.Figure 5 displays diversity elite set time different elite set sizes.expected, higher elite set size results higher diversity. However, interestingnote stability diversity: first 100 seconds, diversity set changeslittle, quality solutions (see Figure 1) continues improve.1200Mean Pair-wise Hamming Distance1000800SGMPCS |e| = 20 (p=0.25, seq=luby, bt=chron)SGMPCS |e| = 16 (p=0.25, seq=luby, bt=chron)SGMPCS |e| = 12 (p=0.25, seq=luby, bt=chron)SGMPCS |e| = 8 (p=0.25, seq=luby, bt=chron)SGMPCS |e| = 4 (p=0.25, seq=luby, bt=chron)60040020000200400600Time (secs)80010001200Figure 5: diversity measured mean pair-wise Hamming distance among solutionselite set different elite set sizes.Figure 6 shows diversity changing p values. Contrary expectations,higher p values exhibit lower diversity. analysis shows primary causepattern way elite solutions replaced. search startselite solution, improved solution replaces starting solution. faillimit relatively low, starting solution is, high probability, also closest62fiSolution-Guided Multi-Point Constructive Searchelite solution improved solution. Therefore, replacing starting elite solutionrelatively small impact overall diversity. contrast, search startsempty solution, worst elite solution replaced improved solution.demonstrate below, difference replacement policy results significantly lower elitepool diversity searches start empty solution: diversity decreasesincreasing p.1200Mean Pair-wise Hamming Distance1000800600SGMPCS p = 0.00 (|e|=4, seq=luby, bt=chron)SGMPCS p = 0.25 (|e|=4, seq=luby, bt=chron)SGMPCS p = 0.50 (|e|=4, seq=luby, bt=chron)SGMPCS p = 0.75 (|e|=4, seq=luby, bt=chron)SGMPCS p = 1.00 (|e|=4, seq=luby, bt=chron)40020000200400600Time (secs)80010001200Figure 6: diversity measured mean pair-wise Hamming distance among solutionselite set values p.4.3 Manipulating DiversityMotivated interpretation results Figure 6, section experimentmanipulation diversity changing elite solution replacement rule. Threelevels diversity defined follows:Low Diversity: Regardless whether search starts elite solution emptysolution, improved solution replaces worst elite one. distance-based criteriaused. initialization phase, follow approach used above: 50elite solutions independently generated without constraining makespan,|e| best solutions inserted elite set.Medium Diversity: standard elite set replacement rules used Experiment 1defined Section 2 used.63fiBeckHigh Diversity: search starts empty solution, closest elite solutionreplaced improving solution found. search starts elite solution, starting solution replaced. noted above, latter rule resultsreplacement closest solution high probability. Therefore, two rulesalmost always equivalent replacing closest solution. initializationphase, |e| solutions generated inserted elite pool. Then, additional50 |e| solutions generated and, one solutions better worstelite solution, new solution inserted elite set, replacing closest elitesolution.verify manipulations indeed affect diversity elite set expected,conduct initial experiment subset parameter space. Using probleminstances Experiment 1 hardware software configurations, solvedproblem instance 10 times diversity condition varying |e| p.Rather fully crossed experiment, set |e| = 4 varied p 0 1,set p = 0.25 varied |e| 4 20.Figures 7 8 demonstrate manipulations affect diversityelite set expected. show different diversity levels two |e| valuestwo p values displaying data impractical. interesting notehigh low diversity conditions, effect diversity parameters disappears:little variation diversity |e| p varied two diversityconditions.1200Mean Pair-wise Hamming Distance1000800High: |e| = 8 (p=0.25, seq=luby, bt=chron)High: |e| = 4 (p=0.25, seq=luby, bt=chron)Medium: |e| = 8 (p=0.25, seq=luby, bt=chron)Medium: |e| = 4 (p=0.25, seq=luby, bt=chron)Low: |e| = 8 (p=0.25, seq=luby, bt=chron)Low: |e| = 4 (p=0.25, seq=luby, bt=chron)60040020000200400600Time (secs)80010001200Figure 7: diversity measured mean pair-wise Hamming distance among solutionselite set different diversity levels |e| = 4 |e| = 8.64fiSolution-Guided Multi-Point Constructive Search1200Mean Pair-wise Hamming Distance1000800High: p = 0.00 (|e|=4, seq=luby, bt=chron)High: p = 0.25 (|e|=4, seq=luby, bt=chron)Medium: p = 0.00 (|e|=4, seq=luby, bt=chron)Medium: p = 0.25 (|e|=4, seq=luby, bt=chron)Low: p = 0.00 (|e|=4, seq=luby, bt=chron)Low: p = 0.25 (|e|=4, seq=luby, bt=chron)60040020000200400600Time (secs)80010001200Figure 8: diversity measured mean pair-wise Hamming distance among solutionselite set different diversity levels p = 0 p = 0.25.4.4 Experimental Detailsverified indeed three different diversity settings, testimpact different diversity levels performance SGMPCS. perform fullycrossed experiment three independent variables: |e| which, above, takes values{1, 4, 8, 12, 16, 20}; p which, above, takes values {0, 0.25, 0.5, 0.75, 1}; diversity(div) taking values low, medium, high corresponding manipulations describedabove. conditions, use chronological backtracking Luby fail limit sequence.experimental details including problem instances, hardware software,1200 CPU second time limit, heuristics propagators, evaluation criteria(MRE) Experiment 1 (see Section 3.2).4.5 Resultsfully crossed experimental design results 90 cells (6 5 3). cell result10 runs 20 problem instances 20 minute time limit. resultsgenerated 250 CPU days.summary analysis variance shown Table 4. results demonstratefactors interactions significant p 0.005. Tukey HSD test (RDevelopment Core Team, 2006) significance level p 0.005 donefactors, results summarized Table 5. Tukey HSD results indicate that:65fiBeckExperiment 1, lower |e| better, though case significantdifference |e| = 1 |e| = 4.p = 0 significantly worse p = 0.50 turn significantly worsep = 0.25. Recall Experiment 1, p = 0 significantly differentp = 0.25.Lower diversity better medium turn better high diversity.Factor(s)epdive:pe:divp:dive:p:divResidualsDf542201084017910Sum Sq0.070921.46900.07060.05840.02340.05630.01863.1008Mean Sq0.01425.36730.03530.00290.00230.00700.00050.0002F value81.913031000.5636204.023216.867913.493840.61662.6925Pr(>F)< 2.2e-16< 2.2e-16< 2.2e-16< 2.2e-16< 2.2e-16< 2.2e-164.298e-08Table 4: Summary analysis variance found using R statistical package (RDevelopment Core Team, 2006). factors interactions significantp 0.005.|e|pdiv{1, 4} < 8 < {12, 16} < 200.25 < 0.50 < 0 < 0.75 < 1.00low < medium < highTable 5: results independent Tukey tests factor diversity experiment.Significance level test parameter p 0.005.Finally, Table 6 presents parameter values result five lowest fivehighest MRE results. Note previous best set parameter values (|e| = 1, p = 0.25,div = med) incurs slightly worse MRE |e| = 4, p = 0.25, div = low.4.6 Summaryexperiment diversity addressed number intuitions:expected, larger elite set results higher elite set diversity.Contrary expectations, higher probability searching empty solutiondecreases diversity. able show impact directly duep value rather different elite set replacement rules.Finally, importantly, appears diversity elite set negativelycorrelated performance: lower diversity, higher performance.66fiSolution-Guided Multi-Point Constructive Search|e|pDivMREFive Best Parameter Settings4 0.25 low0.030857391 0.25 med 0.031584498 0.25 low0.0322480316 0.25 low0.0323116812 0.25 low0.03233298Five Worst Parameter Setting20 1.00 med 0.124828888 1.00 low0.124845711 1.00 low0.1248708512 1.00 med 0.1248833516 1.00 low0.12489075Table 6: Best worst parameters diversity experiments.result calls question extent SGMPCS performance basedexploiting multiple points search space. exploitation importantperformance, would expect higher diversity out-perform lower diversity.return question Section 6.5. Experiment 3: Benchmark Comparison Techniquesfirst two experiments concentrated providing basic data performancedifferent parameter settings SGMPCS initial inquiry reasons underlyingSGMPCS performance. experiment, turn comparisons SGMPCSexisting heuristic search techniques.5.1 Experimental Detailsuse three sets well-known JSP benchmark problem instances (Taillard, 1993).set contains 10 instances, different sets problems different size: 20 15,20 20, 30 15. problems numbered 11 though 40. 5 instancesused development SGMPCS.Five algorithms tested:Standard chronological backtracking (Chron): non-randomized versiontexture-based heuristic employed used together global constraint propagators. heuristic randomized, one run doneproblem instance.Limited Discrepancy Search (LDS): identical algorithm Chron exceptbacktracking LDS.5. See http://ina2.eivd.ch/collaborateurs/etd/problemes.dir/ordonnancement.dir/ordonnancement.htmlbenchmark instances. best-known upper lower bounds latest summaryfile website, dated 23/11/05.67fiBeckRandomized Restart (Restart): randomized restart algorithm usingrandomized texture-based heuristic global constraint propagators usedExperiment 1 2. backtracking restarts chronological faillimit used Luby limit. problem instance solved 10 times.Solution-Guided Multi-Point Constructive Search (SGMPCS): take best parameters Experiments 1 2: |e| = 4, p = 0.25, seq = Luby, bt = chron,div = low. parameter settings, sole difference SGMPCSRestart use elite set fact searches guided elitesolution. particular, use heuristics, propagators, fail limit sequence,type backtracking. problem instance solved 10 times.Iterated Simple Tabu Search (i-STS): i-STS algorithm sophisticated multiphase tabu search built model state-of-the-art i-TSAB (Nowicki & Smutnicki,2005) goal simplifying order study various componentscontribute overall performance (Watson et al., 2006). Taillard benchmarks, i-STS slightly under-performs i-TSAB terms solution quality givenequal number iterations.6 use parameters recommended7 Taillardinstances: |E| = 8, Xa = 40000, Xb = 7000, pi = pd = 0.5. full definitionparameters, see work Watson et al. (2006).time limit run 3600 CPU seconds. experimental details,including hardware software first four algorithms, evaluation criteriaExperiment 1 (see Section 3.2). i-STS algorithm Watson et al.sC++ implementation run hardware algorithms, meaningdirect run-time comparison meaningful.constructive search-based approaches (i.e., algorithms tested excepti-STS), Global Bound policy followed (see Section 2.2): whenever new best solutionfound, global upper bound cost function modified one lessnew best cost. particular, means Restart benefits back-propagationcost constraint exactly way SGMPCS does.5.2 Resultsmean best makespan found problem set shown Tables 7 9.Table 10 shows performance terms finding proving optimal makespanproblems optimal solution known.5.2.1 Comparing Constructive Search Algorithms20 15 problems (Table 7), SGMPCS dominates constructive algorithms,finding lowest makespan (as judged mean makespan), one instance(instance 14). particular, problem instances mean SGMPCS solution betterbest solution found Restart. terms mean relative error, SGMPCS outperforms constructive algorithms factor 3 8.6. previous experiments, use CPU time limit. estimated i-STS 57 times slower i-TSAB.7. Jean-Paul Watson, personal communication.68fiSolution-Guided Multi-Point Constructive SearchProb.11121314151617181920MRELB/UB1323/13591351/13671282/134213451304/13391302/136014621369/13961297/13351318/1348(vs. UB)Chron14441587140114961436149615971663145713870.0956LDS14101411140113451403142414851464138813900.0343Restartmeanbest1412.414081404.714021388.613851378.513701432.214271416.214081509.015071459.914561393.513861388.113780.0389 0.0348SGMPCSmeanbest1387.813651377.213671352.913431345.2 13451375.913641373.313651472.714621423.214001349.913351361.513560.0122 0.0036i-STSmeanbest1366.613651376.313751349.71347134513451350.213421362.313621467.814641407.114041339.213351355.313500.0049 0.0026Table 7: Results Taillards 20 15 instances. Bold entries indicate best performanceacross five algorithms instance. Restart, SGMPCS, i-STS,use mean makespan performance measure. also include bestmakespan found algorithms solve instance multiple times.indicates optimal makespan found proved probleminstance. final row shows mean relative error (relative best-knownupper bound) algorithm.interesting note similar performance LDS Restart. observeusing dynamic variable ordering, LDS performs partial restarts jumpingtop tree introduce discrepancy. suggests performanceLDS dynamic variable orderings may due exploitation heavy-tailsphenomenon. similar results JSP instances section supportidea. knowledge relationship commented before.Prob.21222324252627282930MRELB/UB1539/16441511/16001472/15571602/16461504/15951539/16451616/16801591/16031514/16251473/1584(vs. UB)Chron18091689165718101685182718271778171816660.0793LDS16991659162016761669172317551645167816590.0373Restartmeanbest1694.516861654.016491614.216021697.516941673.116641706.917011754.617501663.716561665.516601646.516410.0366 0.0324SGMPCSmeanbest1665.716491632.116211571.415611663.916521619.616081669.416561715.617061628.116191642.216261606.915980.0146 0.0072i-STSmeanbest1648.016471614.116001560.215571653.216471599.315951653.316511690.016871617.416141628.016271587.215840.0044 0.0019Table 8: Results Taillards 20 20 instances. See caption Table 7.Table 8 displays results 20 20 problems. Again, SGMPCS dominatesconstructive algorithms, finding mean makespan better bestmakespan found constructive techniques. SGMPCS unable find69fiBecksolutions good best-known upper bound instances. termsMRE, SGMPCS out-performs algorithms factor 3 5.Prob.31323334353637383940MRELB/UB17641774/17951778/17911828/1829200718191771167317951631/1674(vs. UB)Chron21182163213820962110241120182005211821060.190LDS19121975198719892007196419471853190418700.0832Restartmeanbest1896.818881983.119782021.620151968.419622007.0 20071957.119491940.319351822.018171896.118811859.418550.0813 0.0776SGMPCSmeanbest1774.017661828.318041840.918141863.918332007.0 20071832.7 18191810.617871701.716911803.5 17951714.716900.0147 0.0051i-STSmeanbest1764.017641813.418041804.217991831.918312007.020071819.718191791.117781675.716731799.317971689.416860.0044 0.0022Table 9: Results Taillards 30 15 instances. See caption Table 7.Table 9 displays results largest problem instances (30 15). instancesone, mean solution found SGMPCS better best solutionconstructive algorithms. instance 35, SGMPCS equals performanceLDS Restart finding (and, cases, proving) optimal solution. Overall,SGMPCS factor 5 13 better terms MRE.Prob.1417313536373839Opt.13451462176420071819177116731795Chron0(0)0(0)0(0)0(0)0(0)0(0)0(0)0(0)LDS10(10)0(0)0(0)10(0)0(0)0(0)0(0)0(0)Restart0(0)0(0)0(0)10(2)0(0)0(0)0(0)0(0)SGMPCS9(9)1(0)0(0)10(4)1(1)0(0)0(0)3(3)i-STS10(0)0(0)10(10)10(0)8(0)0(0)1(1)0(0)Table 10: Results Taillard instances optimal solution known.first two columns problem index optimal makespan respectively.rest columns number runs algorithm foundoptimal solution and, parenthesis, number times proved optimality. Recall Chron LDS run per instancestochastic. However, provide fair basis comparison, presentresults assuming produced identical results ten runs per instance.i-STS complete algorithm, structural characteristics solution imply optimality (Nowicki & Smutnicki, 1996).solution characteristic found, i-STS able prove optimalityshown two instances: tai31 tai38.70fiSolution-Guided Multi-Point Constructive SearchFinally, Table 10 presents number runs algorithm able findprove optimal solutions problem instances known optimal. SGMPCSfinds optimal solution least five instances proves optimality leastfour instances. Chron unable find prove optimality instances,Restart one instance, LDS able find optimal solutiontwo instances prove one.5.2.2 SGMPCS vs. i-STSalmost instances Tables 8 9 i-STS performs substantially better SGMPCS. many cases, mean solution found i-STS better best foundSGMPCS. However, seven ten smallest instances (Table 7), best solutionfound SGMPCS good better found i-STS, SGMPCS strictlybetter five instances. larger problems, however, mean makespan foundi-STS better found SGMPCS instances.Recall algorithm run 3600 CPU seconds. includegraphs run-time distributions, observed performance gap termsMRE SGMPCS i-STS 3600 seconds present time points 60seconds. words, i-STS substantially out-performs SGMPCS first 60 secondsthereafter algorithms find better solutions rate.Table 10 shows one area SGMPCS clearly superior i-STSproving optimality solutions. i-STS complete algorithm, identifysolutions particular structure optimal (Nowicki & Smutnicki, 1996). SGMPCSable find prove optimality within time limit four instances least one runi-STS two instances.5.3 Summary30 problem instances used experiment, mean solution found SGMPCSbetter best solution found constructive techniques 28instances. remaining instances, SGMPCS performs well LDS Restartinstance 35 slightly worse LDS instance 14. Overall, terms meanrelative error, SGMPCS 3 13 times better constructive searchalgorithms different problem sets.SGMPCS perform well i-STS terms mean makespan; however,smaller problems best solution able find better i-STS fiveinstances.6. Discussion Future Workpaper demonstrates Solution-Guided Multi-Point Constructive Search significantly out-perform existing constructive search techniques solving hard combinatorialsearch problems trails behind state-of-the-art metaheuristic search. section, present preliminary ideas regarding reasons observed performance,discussion generality SGMPCS, directions extensions SGMPCS.71fiBeck6.1 SGMPCS Work?extent SGMPCS out-performs existing constructive search approaches solving hard combinatorial search problems, interesting question arisingexperiments understanding reasons strong performance. speculatethree, non-mutually exclusive, candidates: exploitation heavy-tails,impact revisiting previous high-quality solutions, use multiple elite solutions.6.1.1 Exploiting Heavy-TailsSGMPCS restart-based algorithm. Even p = 0, search periodically restarts, albeitvalue ordering based elite solution. believe likely, therefore,SGMPCS exploits heavy-tailed distributions much way randomized restart(Gomes et al., 2005; Gomes & Shmoys, 2002).One way test idea reproduce Gomes et al.s original experiment SGMPCSfollows: random variable ordering, solve problem instance optimality startinggiven sub-optimal solution, s, record search effort involved; repeat k different random variable orderings large k; finally observe frequency distributionsearch effort. whole experiment repeated different starting solutions.resulting distributions exhibit heavy-tailed behaviour, reasons randomizedrestart able take advantage heavy-tailed distributions may shared SGMPCS.currently pursuing experiment.6.1.2 Revisiting Solutionsbelieve likely experiment suggested Section 6.1.1 demonstrateSGMPCS takes advantage heavy-tailed distributions, significant performanceadvantage SGMPCS Restart Experiment 3 well poor performancep = 1 parameter setting Experiments 1 2, lead us expectadditional factors needed account performance SGMPCS.believe leading candidate one additional factors impactrevisiting high-quality solutions using different variable ordering. time elitesolution revisited different variable ordering, different search tree created.resource-limited chronological search visit nodes deep tree resourcelimit reached. However, different variable ordering results different set nodesdeep tree are, therefore, within reach search. 8 strong resultsSGMPCS |e| = 1 may indication mechanism responsible strongperformance sampling solutions close elite solution different search trees.primary direction future research formalize meaning close withinsearch tree provide firm empirical foundation investigate impactrevisiting solutions. hope adapt significant work fitness-distance correlation(Hoos & Stuzle, 2005) local search literature constructive search.8. Similar reasoning applies use LDS.72fiSolution-Guided Multi-Point Constructive Search6.1.3 Exploiting Multiple Points Search Spaceuse multiple solutions and, specifically, balance intensificationdiversification viewed important metaheuristic literature (Rochat& Taillard, 1995). Intensification suggests searching region good solutionsdiversification suggests searching areas searched before. Furthermore,one important aspects metaheuristics based elite solutionsdiversity elite set maintained (Watson, 2005).However, experiments presented suggest increased diversityimportant factor performance SGMPCS. best performance achievedsmall elite set sizes even, Experiment 1, elite set size 1. Basedresults, original motivations SGMPCS are, say least, suspect.results may due idiosyncrasies makespan JSP problem. experiments problems (see below) directly manipulated diversity,results indicated better relative performance larger elite set sizes observedhere. may indication problems see positive contributionmaintaining multiple viewpoints.speculative note, closer look Figure 1 may show diversity playrole search performance. figure shows greatest differences performancedifferent elite set sizes comes early search, relatively easy findimproving solution. Later search, performance difference narrows, thoughclose completely within time limit. One interpretation pattern that, earlysearch, relatively easy improve upon existing elite solutions, large elitepool distracts search guiding elite solution significantly worsebest elite solution. narrowing performance gap may simply duefact that, better solutions, harder improve upon regardlesssize elite set, rate improvement decrease. Since algorithmslower |e| better solutions, rate slows earlier. alternative explanationmaintaining multiple elite solutions positive influence initialeasy phase search. better solutions harder find, diverse elite setmay help search probability least one elite solutions bettersolution vicinity rises elite set size. 9 experimentation requiredinvestigate intuitions.6.2 GeneralitySGMPCS general technique conducting constructive search: nothing SGMPCSframework specific scheduling constraint programming. However, paperone type problem used evaluate SGMPCS therefore question practicalutility generality addressed.Existing work shows SGMPCS effectively applied optimizationsatisfaction problems quasigroup-with-holes completion (Beck, 2005b; Heckman &Beck, 2006), job shop scheduling objective minimize weighted tardiness (Beck,2006), multi-dimensional knapsack optimization (Heckman & Beck, 2007). addi9. explanation accurate, adaptive strategy |e| growing search might worthinvestigating.73fiBecktion, recent work Sellmann Ansotegui (2006) demonstrates good performanceclosely related technique diagonally ordered magic squares SAT instances.However, SGMPCS performs worse randomized restart (though better chronological backtracking) magic square instances, randomized restart SGMPCSperform much worse chronological backtracking satisfaction version multidimensional knapsack problem (Heckman & Beck, 2006).application SGMPCS variety problems demonstrates indeedgeneral technique whose impact applied beyond job shop scheduling.time, negative results problems point lack understandingmechanisms behind SGMPCS performance motivates future work.6.3 Extending SGMPCSimmediate focus future work understanding reasons performance, number ways framework extended.First, implied speculations regarding impact diversity Section 6.1.3,dynamic parameter learning (Horvitz et al., 2001) would appear useful SGMPCSframework. example, one could imagine adapting p search dependingrelative success searching empty solution versus searching elite solution.Second, given metaheuristics community working elite solutionsnumber years, number techniques may fruitfully extend SGMPCS. example, path relinking (Glover, Laguna, & Marti, 2004) pair elite solutionstaken end-points local search trajectory. Path relinking elegant counterpartSGMPCS: two elite solutions chosen, variable assignments commonfixed, defining sub-space variable assignments two solutions differ.Unlike path relinking local search, constructive search one perform complete search sub-space post no-good removing sub-space futureconsideration. preliminary experiments approach appear promising.Third, clause learning techniques, originated conflict learning constraintprogramming (Prosser, 1993), widely used restart state-of-the-art satisfiabilitysolvers (Huang, 2007). seems natural investigate combining conflict learningsolution-guidance. techniques may interesting relationship former trieslearn mistakes led dead-end latter attempts heuristicallyidentify correct decisions made.Finally, work loosely coupled hybrid search techniques share single solutions(Carchrae & Beck, 2005) easily generalizable share set solutions. date, ratherable exploit full solution shared technique, constructive searchable use bound cost function. Therefore, revisiting solutionsprovides way exploit much richer information (i.e., full solutions) availablehybrid search technique.7. Conclusionpaper presents first fully crossed study Solution-Guided Multi-Point Constructive Search. Using set job shop scheduling problems, varied SGMPCS parametersettings control size elite set, probability searching empty so74fiSolution-Guided Multi-Point Constructive Searchlution, fail sequence, form backtracking, diversity level elite set.Experiments indicated low elite set sizes, low probability searching emptysolution, Luby fail sequence, chronological backtracking, low diversity leadbest performance. compared best SGMPCS parameters found existing constructive search techniques state-of-the-art tabu search algorithm well-knownset benchmark problems. results demonstrated SGMPCS significantly outperforms chronological backtracking, limited discrepancy search, randomized restartout-performed tabu search algorithm.primary contribution paper introduction new search frameworkdemonstration significantly out-perform existing constructive searchtechniques. Secondary contributions include demonstration impact elite setdiversity performance opposite expected (i.e., low diversity leadshigher performance) identification research directions reasons underlyingperformance SGMPCS focusing quantification effects heavy-tails,impact revisiting solutions different variable orderings, exploitationmultiple points search space.Acknowledgmentsresearch supported part Natural Sciences Engineering ResearchCouncil ILOG, S.A. Thanks Jean-Paul Watson, Daria Terekhov, Tom Carchrae,Ivan Heckman, Lei Duan comments early versions paper. preliminaryversion parts work previously published (Beck, 2006).ReferencesBeck, J. C. (2005a). Multi-point constructive search. Proceedings Eleventh International Conference Principles Practice Constraint Programming (CP05),pp. 737741.Beck, J. C. (2005b). Multi-point constructive search: Extended remix. ProceedingsCP2005 Workshop Local Search Techniques Constraint Satisfaction, pp. 1731.Beck, J. C. (2006). empirical study multi-point constructive search constraintbased scheduling. Proceedings Sixteenth International Automated PlanningScheduling (ICAPS06), pp. 274283.Beck, J. C., & Fox, M. S. (2000). Dynamic problem structure analysis basisconstraint-directed scheduling heuristics. Artificial Intelligence, 117 (1), 3181.Carchrae, T., & Beck, J. C. (2005). Applying machine learning low knowledge controloptimization algorithms. Computational Intelligence, 21 (4), 372387.Dilkina, B., Duan, L., & Havens, W. (2005). Extending systematic local search jobshop scheduling problems. Proceedings Eleventh International ConferencePrinciples Practice Constraint Programming (CP05), pp. 762766.Garey, M. R., & Johnson, D. S. (1979). Computers Intractability: Guide TheoryNP-Completeness. W.H. Freeman Company, New York.75fiBeckGlover, F., Laguna, M., & Marti, R. (2004). Scatter search path relinking: advancesapplications. Onwubolu, G., & Babu, B. (Eds.), New Optimization TechniquesEngineering. Springer.Gomes, C. P., Selman, B., & Kautz, H. (1998). Boosting combinatorial searchrandomization. Proceedings Fifteenth National Conference Artificial Intelligence (AAAI-98), pp. 431437.Gomes, C. P., Fernandez, C., Selman, B., & Bessiere, C. (2005). Statistical regimes acrossconstrainedness regions. Constraints, 10 (4), 317337.Gomes, C., & Shmoys, D. (2002). Completing quasigroups latin squares: structuredgraph coloring problem. Proceedings Computational Symposium GraphColoring Generalizations.Harvey, W. D. (1995). Nonsystematic backtracking search. Ph.D. thesis, DepartmentComputer Science, Stanford University.Heckman, I., & Beck, J. C. (2006). empirical study multi-point constructive searchconstraint satisfaction. Proceedings Third International WorkshopLocal Search Techniques Constraint Satisfaction.Heckman, I., & Beck, J. C. (2007). empirical study multi-point constructive searchconstraint satisfaction. Submitted Constraints.Hoos, H., & Stuzle, T. (2005). Stochastic Local Search: Foundations Applications.Morgan Kaufmann.Horvitz, E., Ruan, Y., Gomes, C., Kautz, H., Selman, B., & Chickering, M. (2001).bayesian approach tacking hard computational problems. ProceedingsSeventeenth Conference Uncertainty Artificial Intelligence (UAI-2001), pp.235244.Huang, J. (2007). effect restarts efficiency clause learning. ProceedingsTwentieth International Joint Conference Artificial Intelligence (IJCAI07),pp. 23182323.Hulubei, T., & OSullivan, B. (2006). impact search heuristics heavy-tailedbehaviour. Constraints, 11 (23), 159178.Jain, A. S., & Meeran, S. (1999). Deterministic job-shop scheduling: Past, presentfuture. European Journal Operational Research, 113 (2), 390434.Jussien, N., & Lhomme, O. (2002). Local search constraint propagation conflictbased heuristics. Artificial Intelligence, 139, 2145.Kautz, H., Horvitz, E., Ruan, Y., Gomes, C., & Selman, B. (2002). Dynamic restart policies.Proceedings Eighteenth National Conference Artifiical Intelligence (AAAI02), pp. 674681.Laborie, P. (2003). Algorithms propagating resource constraints AI planningscheduling: Existing approaches new results. Artificial Intelligence, 143, 151188.Le Pape, C. (1994). Implementation resource constraints ILOG Schedule: librarydevelopment constraint-based scheduling systems. Intelligent Systems Engineering, 3 (2), 5566.76fiSolution-Guided Multi-Point Constructive SearchLuby, M., Sinclair, A., & Zuckerman, D. (1993). Optimal speedup Las Vegas algorithms.Information Processing Letters, 47, 173180.Nowicki, E., & Smutnicki, C. (1996). fast taboo search algorithm job shop problem.Management Science, 42 (6), 797813.Nowicki, E., & Smutnicki, C. (2005). advanced tabu algorithm job shop problem.Journal Scheduling, 8, 145159.Nuijten, W. P. M. (1994). Time resource constrained scheduling: constraint satisfaction approach. Ph.D. thesis, Department Mathematics Computing Science,Eindhoven University Technology.Pinedo, M. (2005). Planning Scheduling Manufacturing Services. Springer.Prestwich, S. (2002). Combining scalability local search pruning techniquessystematic search. Annals Operations Research, 115, 5172.Prosser, P. (1993). Hybrid algorithms constraint satisfaction problem. ComputationalIntelligence, 9 (3), 268299.R Development Core Team (2006). R: Language Environment Statistical Computing. R Foundation Statistical Computing, Vienna, Austria. ISBN 3-900051-07-0.Rochat, Y., & Taillard, E. D. (1995). Probabilistic diversification intensification localsearch vehicle routing. Journal Heuristics, 1, 147167.Sellmann, M., & Ansotegui, C. (2006). Disco-novo-gogo: Integrating local search complete saerch restarts. Proceedings Twenty-First National ConferenceArtificial Intelligence (AAAI06), pp. 10511056.Taillard, E. D. (1993). Benchmarks basic scheduling problems. European JournalOperational Research, 64, 278285.Watson, J.-P. (2003). Empirical Modeling Analysis Local Search AlgorithmsJob-Shop Scheduling Problem. Ph.D. thesis, Dept. Computer Science, ColoradoState University.Watson, J.-P. (2005). metaheuristics failure modes: case study tabu search jobshop scheduling. Proceedings Fifth Metaheuristics International Conference.Watson, J.-P., Barbulescu, L., Whitley, L. D., & Howe, A. E. (2002). Contrasting structuredrandom permutation flow-shop scheduling problems: search-space topologyalgorithm performance. INFORMS Journal Computing, 14 (2), 98123.Watson, J.-P., Beck, J. C., Howe, A. E., & Whitley, L. D. (2003). Problem difficultytabu search job-shop scheduling. Artificial Intelligence, 143 (2), 189217.Watson, J.-P., Howe, A. E., & Whitley, L. D. (2006). Deconstructing Nowicki Smutnickis i-TSAB tabu search algorithm job-shop scheduling problem. ComputersOperations Research, 33 (9), 26232644.77fiJournal Artificial Intelligence Research 29 (2007) 153-190Submitted 10/06; published 06/07Generalized A* ArchitecturePedro F. Felzenszwalbpff@cs.uchicago.eduDepartment Computer ScienceUniversity ChicagoChicago, IL 60637David McAllestermcallester@tti-c.orgToyota Technological Institute ChicagoChicago, IL 60637Abstractconsider problem computing lightest derivation global structure usingset weighted rules. large variety inference problems AI formulatedframework. generalize A* search heuristics derived abstractionsbroad class lightest derivation problems. also describe new algorithm searcheslightest derivations using hierarchy abstractions. generalization A* givesnew algorithm searching AND/OR graphs bottom-up fashion.discuss algorithms described provide general architecture addressing pipeline problem problem passing information back forthvarious stages processing perceptual system. consider examples computer vision natural language processing. apply hierarchical search algorithmproblem estimating boundaries convex objects grayscale images comparesearch methods. second set experiments demonstrate use newcompositional model finding salient curves images.1. Introductionconsider class problems defined set weighted rules composing structureslarger structures. goal problems find lightest (least cost) derivationglobal structure derivable given rules. large variety classical inferenceproblems AI expressed within framework. example global structuremight parse tree, match deformable object model image, assignmentvalues variables Markov random field.define lightest derivation problem terms set statements, set weightedrules deriving statements using statements special goal statement.case looking lightest derivation goal statement. usually expresslightest derivation problem using rule schemas implicitly represent large setrules terms small number rules variables. Lightest derivation problemsformally equivalent search AND/OR graphs (Nilsson, 1980), findformulation natural applications interested in.One goals research construction algorithms global optimizationacross many levels processing perceptual system. described algorithmsused integrate multiple stages processing pipeline single global optimization problem solved efficiently.c2007AI Access Foundation. rights reserved.fiFelzenszwalb & McAllesterDynamic programming fundamental technique designing efficient inference algorithms. Good examples Viterbi algorithm hidden Markov models (Rabiner,1989) chart parsing methods stochastic context free grammars (Charniak, 1996).algorithms described used speed solution problems normallysolved using dynamic programming. demonstrate specific problem,goal estimate boundary convex object cluttered image. second setexperiments show algorithms used find salient curves images.describe new model salient curves based compositional rule enforceslong range shape constraints. leads problem large solved usingclassical dynamic programming methods.algorithms consider related Dijkstras shortest paths algorithm (DSP)(Dijkstra, 1959) A* search (Hart, Nilsson, & Raphael, 1968). DSP A*used find shortest path cyclic graph. use priority queue define ordernodes expanded worst case running time O(M log N ) Nnumber nodes graph number edges. DSP A*expansion node v involves generating nodes u edge v u.difference two methods A* uses heuristic function avoidexpanding non-promising nodes.Knuth gave generalization DSP used solve lightest derivationproblem cyclic rules (Knuth, 1977). call Knuths lightest derivation algorithm(KLD). analogy Dijkstras algorithm, KLD uses priority queue define orderstatements expanded. expansion statement v involves generatingconclusions derived single step using v statements alreadyexpanded. long rule bounded number antecedents KLD also worstcase running time O(M log N ) N number statements problemnumber rules. Nilssons AO* algorithm (1980) also used solvelightest derivation problems. Although AO* use heuristic function, truegeneralization A* use priority queue, handles acyclic rules,require O(M N ) time even applied shortest path problem.1 particular, AO*variants use backward chaining technique starts goal repeatedlyrefines subgoals, A* forward chaining algorithm.2Klein Manning (2003) described A* parsing algorithm similar KLDuse heuristic function. One contributions generalization algorithmarbitrary lightest derivation problems. call algorithm A* lightest derivation(A*LD). method forward chaining, uses priority queue control orderstatements expanded, handles cyclic rules worst case running timeO(M log N ) problems rule small number antecedents. A*LDseen true generalization A* lightest derivation problems. lightest derivationproblem comes shortest path problem A*LD identical A*.course running times seen practice often well predicted worst caseanalysis. specially true problems large defined implicitly.example, use dynamic programming solve shortest path problem acyclicgraph O(M ) time. better O(M log N ) bound DSP, implicit1. extensions handle cyclic rules (Jimenez & Torras, 2000).2. AO* backward chaining terms inference rules defining lightest derivation problem.154fiThe Generalized A* Architecturegraphs DSP much efficient since expands nodes best-first order.searching shortest path source goal, DSP expand nodes vd(v) w . d(v) length shortest path source v, wlength shortest path source goal. case A* monotoneadmissible heuristic function, h(v), possible obtain similar bound searchingimplicit graphs. A* expand nodes v d(v) + h(v) w .running time KLD A*LD expressed similar way. solvinglightest derivation problem, KLD expand statements v d(v) w . d(v)weight lightest derivation v, w weight lightest derivationgoal statement. Furthermore, A*LD expand statements v d(v) + h(v) w .heuristic function, h(v), gives estimate additional weight necessaryderiving goal statement using derivation v. heuristic values used A*LDanalogous distance node goal graph search problem (the notionused A*). note heuristic values significantly different onesused AO*. case AO* heuristic function, h(v), would estimate weightlightest derivation v.important difference A*LD AO* A*LD computes derivationsbottom-up fashion, AO* uses top-down approach. method advantages, depending type problem solved. example, classical problemcomputer vision involves grouping pixels long smooth curves. formulateproblem terms finding smooth curves pairs pixels far apart.image n pixels (n2 ) pairs. straight forward implementationtop-down algorithm would start considering (n2 ) possibilities. bottomup algorithm would start O(n) pairs nearby pixels. case expectbottom-up grouping method would efficient top-down method.classical AO* algorithm requires set rules acyclic. Jimenez Torras(2000) extended method handle cyclic rules. Another top-down algorithmhandle cyclic rules described Bonet Geffner (2005). Hansen Zilberstein (2001)described search algorithm problems optimal solutionscyclic. algorithms described paper handle problems cyclic rulesrequire optimal solutions acyclic. also note AO* handle rulesnon-superior weight functions (as defined Section 3) KLD requires superior weightfunctions. A*LD replaces requirement requirement heuristic function.well known method defining heuristics A* consider abstract relaxedsearch problem. example, consider problem solving Rubiks cube smallnumber moves. Suppose ignore edge center pieces solve corners.example problem abstraction. number moves necessary putcorners good configuration lower bound number moves necessary solveoriginal problem. fewer corner configurations full configurationsmakes easier solve abstract problem. general, shortest pathsgoal abstract problem used define admissible monotone heuristicfunction solving original problem A*.show abstractions also used define heuristic functions A*LD.lightest derivation problem notion shortest path goal replacednotion lightest context, context statement v derivation155fiFelzenszwalb & McAllestergoal hole filled derivation v. computation lightestabstract contexts lightest derivation problem.Abstractions related problem relaxations defined Pearl (1984). abstractions often lead small problems solved search, relaxations leadproblems still large state space may simple enough solved closedform. definition abstractions use lightest derivation problems includesrelaxations special case.Another contribution work hierarchical search method call HA*LD.algorithm effectively use hierarchy abstractions solve lightest derivationproblem. algorithm novel even case classical search (shortest paths) problem. HA*LD searches lightest derivations contexts every level abstractionsimultaneously. specifically, level abstraction set statementsrules. search lightest derivations contexts level controlledsingle priority queue. understand running time HA*LD, let w weightlightest derivation goal original (not abstracted) problem. statement vabstraction hierarchy let d(v) weight lightest derivation v levelabstraction. Let h(v) weight lightest context abstraction v (definedone level v hierarchy). Let K total number statementshierarchy d(v) + h(v) w . HAL*D expands 2K statements solvingoriginal problem. factor two comes fact algorithm computesderivations contexts level abstraction.Previous algorithms use abstractions solving search problems include methods based pattern databases (Culberson & Schaeffer, 1998; Korf, 1997; Korf & Felner,2002), Hierarchical A* (HA*, HIDA*) (Holte, Perez, Zimmer, & MacDonald, 1996; Holte,Grajkowski, & Tanner, 2005) coarse-to-fine dynamic programming (CFDP) (Raphael,2001). Pattern databases made possible compute solutions impressively largesearch problems. methods construct lookup table shortest paths nodegoal abstract states. practice approach limited tables remainfixed different problem instances, relatively small tables heuristic mustrecomputed instance. example, Rubiks cube precomputenumber moves necessary solve every corner configuration. table useddefine heuristic function solving full configuration Rubiks cube.HA* HIDA* use hierarchy abstractions avoid searching nodeslevel hierarchy. hand, directed graphs methods may stillexpand abstract nodes arbitrarily large heuristic values. also cleargeneralize HA* HIDA* lightest derivation problems rulesone antecedent. Finally, CFDP related AO* repeatedly solves everrefined problems using dynamic programming. leads worst case running timeO(N ). discuss relationships HA*LD hierarchicalmethods detail Section 8.note A* search related algorithms previously used solvenumber problems classical state space search problems. includestraveling salesman problem (Zhang & Korf, 1996), planning (Edelkamp, 2002), multiplesequence alignment (Korf, Zhang, Thayer, & Hohwald, 2005), combinatorial problemsgraphs (Felner, 2005) parsing using context-free-grammars (Klein & Manning, 2003).156fiThe Generalized A* Architecturework Bulitko, Sturtevant, Lu, Yau (2006) uses hierarchy state-space abstractions real-time search.1.1 Pipeline Problemmajor problem artificial intelligence integration multiple processing stagesform complete perceptual system. call pipeline problem. generalconcatenation systems stage feeds information next. vision,example, might edge detector feeding information boundary finding system,turn feeds information object recognition system.computational constraints need build modules clean interfacespipelines often make hard decisions module boundaries. example, edge detectortypically constructs Boolean array indicates weather edge detectedimage location. general recognition presence edgecertain location depend context around it. People often see edges placesimage gradient small if, higher cognitive level, clear actuallyobject boundary location. Speech recognition systems try address problemreturning n-best lists, may may contain actual utterance. wouldlike speech recognition system able take high-level information accountavoid hard decision exactly strings output n-best list.processing pipeline specified describing stages terms rulesconstructing structures using structures produced previous stage. vision systemone stage could rules grouping edges smooth curves next stage couldrules grouping smooth curves objects. case construct singlelightest derivation problem representing entire system. Moreover, hierarchical setabstractions applied entire pipeline. using HA*LD compute lightestderivations complete scene interpretation derived one level abstraction guidesprocessing stages concrete level. provides mechanism enables coarsehigh-level processing guide low-level computation. believe importantproperty implementing efficient perceptual pipelines avoid making hard decisionsprocessing stages.note formulation complete computer vision system lightest derivation problem related work Geman, Potter, Chi (2002), Tu, Chen, Yuille,Zhu (2005) Jin Geman (2006). papers image understanding posedparsing problem, goal explain image terms set objectsformed (possibly recursive) composition generic parts. Tu et al. (2005) usedata driven MCMC compute optimal parses Geman et al. (2002) JinGeman (2006) use bottom-up algorithm building compositions greedy fashion.Neither methods guaranteed compute optimal scene interpretation.hope HA*LD provide principled computational technique solving largeparsing problems defined compositional models.1.2 Overviewbegin formally defining lightest derivation problems Section 2. section alsodiscusses dynamic programming relationship lightest derivation problems157fiFelzenszwalb & McAllesterAND/OR graphs. Section 3 describe Knuths lightest derivation algorithm.Section 4 describe A*LD prove correctness. Section 5 shows abstractionsused define mechanically constructed heuristic functions A*LD. describeHA*LD Section 6 discuss use solving pipeline problem Section 7. Section 8 discusses relationship HA*LD hierarchical search methods.Sections 9 10 present experimental results. conclude Section 11.2. Lightest Derivation ProblemsLet set statements R set inference rules following form,A1 = w1...= wnC = g(w1 , . . . , wn )antecedents Ai conclusion C statements , weights winon-negative real valued variables g non-negative real valued weight function.rule antecedents function g simply non-negative real value. Throughoutpaper also use A1 , . . . , g C denote inference rule type.derivation C finite tree rooted rule A1 , . . . , g C n children,i-th child derivation Ai . leaves tree rules antecedents.Every derivation weight value obtained recursive applicationfunctions g along derivation tree. Figure 1 illustrates derivation tree.Intuitively rule A1 , . . . , g C says derive antecedents Aiweights wi derive conclusion C weight g(w1 , . . . , wn ). probleminterested compute lightest derivation special goal statement.algorithms discussed paper assume weight functions g associated lightest derivation problem non-decreasing variable.fundamental property ensuring lightest derivations optimal substructure property. case lightest derivations constructed lightest derivations.facilitate runtime analysis algorithms assume every rule smallnumber antecedents. use N denote number statements lightest derivationproblem, denotes number rules. problems interestedN large problem implicitly defined compact way,using small number rules variables examples below. also assumeN since statements conclusion rule clearlyderivable ignored.2.1 Dynamic Programmingsay set rules acyclic ordering statementsrule conclusion C antecedents statements come Cordering. Dynamic programming used solve lightest derivation problem158fiThe Generalized A* ArchitectureA1A2A3CDerivationA1DerivationA2DerivationA3Figure 1: derivation C tree rules rooted rule r conclusion C.children root derivations antecedents r. leafs treerules antecedents.functions g rule non-decreasing set rules acyclic. caselightest derivations computed sequentially terms acyclic ordering O.i-th step lightest derivation i-th statement obtained minimizing rulesused derive statement. method takes O(M ) time computelightest derivation statement .note cyclic rules sometimes possible compute lightest derivationstaking multiple passes statements. also note authors would referDijkstras algorithm (and KLD) dynamic programming method. paperuse term referring algorithms compute lightest derivations fixedorder independent solutions computed along way (this includes recursiveimplementations use memoization).2.2 ExamplesRules computing shortest paths single source weighted graph shownFigure 2. assume given weighted graph G = (V, E), wxynon-negative weight edge (x, y) E distinguished start node. firstrule states path weight zero start node s. second set rulesstate path node x extend path edge xobtain appropriately weighted path node y. rule typeedge graph. lightest derivation path(x) corresponds shortest pathx. Note general graphs rules cyclic. Figure 3 illustrates graph159fiFelzenszwalb & McAllester(1)path(s) = 0(2) (x, y) E,path(x) = wpath(y) = w + wxyFigure 2: Rules computing shortest paths graph.bcpath(d) = wpath(c) = wpath(b) = w + wdbpath(b) = w + wcbpath(s) = wpath(e) = wpath(d) = w + wsdpath(c) = w + wecepath(s) = wpath(s) = 0path(e) = w + wsepath(s) = 0Figure 3: graph two highlighted paths b corresponding derivationsusing rules Figure 2.two different derivations path(b) using rules described. correspondstwo different paths b.Rules chart parsing shown Figure 4. assume given weightedcontext free grammar Chomsky normal form (Charniak, 1996), i.e., weighted setproductions form X X Z X, Z nonterminal symbolsterminal symbol. input string given sequence terminals (s1 , . . . , sn ).160fiThe Generalized A* Architecture(1) production X si ,phrase(X, i, + 1) = w(X si )(2) production X Z 1 < j < k n + 1,phrase(Y, i, j) = w1phrase(Z, j, k) = w2phrase(X, i, k) = w1 + w2 + w(X Z)Figure 4: Rules parsing context free grammar.first set rules state grammar contains production X siphrase type X generating i-th entry input weight w(X si ). secondset rules state grammar contains production X Z phrasetype j phrase type Z j k an, appropriatelyweighted, phrase type X k. Let start symbol grammar.goal parsing find lightest derivation phrase(S, 1, n + 1). rules acyclicphrases composed together form longer phrases.2.3 AND/OR GraphsLightest derivation problems closely related AND/OR graphs. Let R setstatements rules defining lightest derivation problem. convert problemAND/OR graph representation build graph disjunction nodestatement conjunction node rule R. edge statement rule deriving statement, edge rule antecedents.leaves AND/OR graph rules antecedents. derivationsstatement using rules R represented solutions rooted statementcorresponding AND/OR graph. Conversely, also possible represent AND/ORgraph search problem lightest derivation problem. case view nodegraph statement build appropriate set rules R.3. Knuths Lightest DerivationKnuth (1977) described generalization Dijkstras shortest paths algorithm callKnuths lightest derivation (KLD). Knuths algorithm used solve large classlightest derivation problems. algorithm allows rules cyclic requiresweight functions associated rule non-decreasing superior. Specificallyrequire following two properties weight function g rule,non-decreasing:superior:wi0 wi g(w1 , . . . , wi0 , . . . , wn ) g(w1 , . . . , wi , . . . , wn )g(w1 , . . . , wn ) wi161fiFelzenszwalb & McAllesterexample,g(x1 , . . . , xn ) = x1 + + xng(x1 , . . . , xn ) = max(x1 , . . . , xn )non-decreasing superior functions.Knuths algorithm computes lightest derivations non-decreasing weight order. Sinceinterested lightest derivation special goal statement often stopalgorithm computing lightest derivation every statement.weight assignment expression form (B = w) B statementw non-negative real value. say weight assignment (B = w) derivablederivation B weight w. set rules R, statement B, weightw write R ` (B = w) rules R used derive (B = w). Let `(B, R)infimum set weights derivable B,`(B, R) = inf{w : R ` (B = w)}.Given set rules R statement goal interested computing derivationgoal weight `(goal , R).define bottom-up logic programming language easily expressalgorithms wish discuss throughout rest paper. algorithm definedset rules priorities. encode priority rule writing alongline separating antecedents conclusion follows,A1 = w1...= wnp(w1 , . . . , wn )C = g(w1 , . . . , wn )call rule form prioritized rule. execution set prioritized rulesP defined procedure Figure 5. procedure keeps track setpriority queue Q weight assignments form (B = w). Initially empty Qcontains weight assignments defined rules antecedents priorities givenrules. iteratively remove lowest priority assignment (B = w) Q. Balready assigned weight new assignment ignored. Otherwise addnew assignment expand every assignment derivable (B = w)assignments already using rule P added Q priority specifiedrule. procedure stops queue empty.result executing set prioritized rules set weight assignments. Moreover,procedure implicitly keep track derivations remembering assignmentsused derive item inserted queue.Lemma 1. execution finite set prioritized rules P derives every statementderivable rules P .Proof. rule causes one item inserted queue. Thus eventually Qempty algorithm terminates. Q empty every statement derivable162fiThe Generalized A* ArchitectureProcedure Run(P )1.2. Initialize Q assignments defined rules antecedents priorities3. Q empty4.Remove lowest priority element (B = w) Q5.B assigned weight6.{(B = w)}7.Insert assignments derivable (B = w) assignments usingrule P Q priority specified rule8. returnFigure 5: Running set prioritized rules.single rule using antecedents weight already weight S. impliesevery derivable statement weight S.ready define Knuths lightest derivation algorithm. algorithmeasily described terms prioritized rules.Definition 1 (Knuths lightest derivation). Let R finite set non-decreasingsuperior rules. Define set prioritized rules K(R) setting priority ruleR weight conclusion. KLD given execution K(R).show running K(R), (B = w) added w = `(B, R).means assignments represent lightest derivations. also showassignments inserted non-decreasing weight order. stop algorithmsoon insert weight assignment goal expand statements B`(B, R) < `(goal , R) statements B `(B, R) = `(goal , R).properties follow general result described next section.3.1 Implementationalgorithm Figure 5 implemented run O(M log N ) time, Nrefer size problem defined prioritized rules P .practice set prioritized rules P often specified implicitly, terms smallnumber rules variables. case problem executing P closely relatedwork logical algorithms described McAllester (2002).main difficulty devising efficient implementation procedure Figure 5step 7. step need find weight assignments combined(B = w) derive new weight assignments. logical algorithms work showsset inference rules variables transformed new set rules,every rule two antecedents particularly simple form. Moreover,transformation increase number rules much. rulestransformed execution implemented efficiently using hashtable representS, heap represent Q indexing tables allow us perform step 7 quickly.163fiFelzenszwalb & McAllesterConsider second set rules parsing Figure 4. representedsingle rule variables. Moreover rule two antecedents. executingparsing rules keep track table mapping value j statements phrase(Y, i, j)weight S. Using table quickly find statements weightcombined statement form phrase(Z, j, k). Similarly keeptrack table mapping value j statements phrase(Z, j, k) weightS. second table lets us quickly find statements combined statementform phrase(Y, i, j). refer reader (McAllester, 2002) details.4. A* Lightest DerivationA* lightest derivation algorithm (A*LD) generalization A* search lightestderivation problems subsumes A* parsing. algorithm similar KLDuse heuristic function speed computation. Consider lightest derivation problemrules R goal statement goal . Knuths algorithm expand statement B`(B, R) < `(goal , R). using heuristic function A*LD avoid expandingstatements light derivations part light derivation goal .Let R set rules statements , h heuristic function assigningweight statement. h(B) estimate additional weight requiredderive goal using derivation B. note case shortest path problemweight exactly distance node goal. value `(B, R) + h(B) providesfigure merit statement B. A* lightest derivation algorithm expandsstatements order figure merit.say heuristic function monotone every rule A1 , . . . , g C Rderivable weight assignments (Ai = wi ) have,wi + h(Ai ) g(w1 , . . . , wn ) + h(C).(1)definition agrees standard notion monotone heuristic function rulescome shortest path problem. show h monotone h(goal ) = 0h admissible appropriate notion admissibility. correctnessA*LD, however, required h monotone h(goal ) finite.case monotonicity implies heuristic value every statement C appearsderivation goal finite. assume h(C) finite every statement. h(C)finite ignore C every rule derives C.Definition 2 (A* lightest derivation). Let R finite set non-decreasing rules hmonotone heuristic function R. Define set prioritized rules A(R) settingpriority rule R weight conclusion plus heuristic value,g(w1 , . . . , wn ) + h(C). A*LD given execution A(R).show execution A(R) correctly computes lightest derivationsexpands statements order figure merit values.Theorem 2. execution A(R), (B = w) w = `(B, R).Proof. proof induction size S. statement trivial = .Suppose statement true right algorithm removed (B = wb ) Q164fiThe Generalized A* Architectureadded S. fact (B = wb ) Q implies weight assignment derivablethus wb `(B, R).Suppose derivation B weight wb0 < wb . Consider moment rightalgorithm removed (B = wb ) Q added S. Let A1 , . . . , g Crule antecedents Ai weight conclusion C not.Let wc = g(`(A1 , R), . . . , `(An , R)). induction hypothesis weight Ai`(Ai , R). Thus (C = wc ) Q priority wc + h(C). Let wc0 weight assignsC. Since g non-decreasing know wc wc0 . Since h monotone wc0 +h(C) wb0 +h(B).follows using monotonicity condition along path C B .note wc + h(C) < wb + h(B) turn implies (B = wb ) weightassignment Q minimum priority.Theorem 3. execution A(R) statements expanded order figuremerit value `(B, R) + h(B).Proof. First show minimum priority Q decrease throughoutexecution algorithm. Suppose (B = w) element Q minimum priority.Removing (B = w) Q decrease minimum priority. suppose add(B = w) insert assignments derivable (B = w) Q. Since h monotonepriority every assignment derivable (B = w) least priority (B = w).weight assignment (B = w) expanded removed Q added S.last theorem w = `(B, R) definition A(R) weight assignmentqueued priority `(B, R) + h(B). Since removed (B = w) Q mustminimum priority queue. minimum priority decrease timemust expand statements order figure merit value.accurate heuristic functions A*LD much efficient KLD.Consider situation perfect heuristic function. is, suppose h(B)exactly additional weight required derive goal using derivation B.figure merit `(B, R) + h(B) equals weight lightest derivation goal usesB. case A*LD derive goal expanding statements partlightest derivation goal .correctness KLD follows correctness A*LD. set non-decreasingsuperior rules consider trivial heuristic function h(B) = 0. factrules superior imply heuristic monotone. theorems implyKnuths algorithm correctly computes lightest derivations expands statementsorder lightest derivable weights.5. Heuristics Derived Abstractionsconsider case additive rules rules weight conclusionsum weights antecedents plus non-negative value v called weightrule. denote rule A1 , . . . , v C. weight derivation usingadditive rules sum weights rules appear derivation tree.context statement B finite tree rules add derivationB tree get derivation goal . Intuitively context B derivation goalhole filled derivation B (see Figure 6).165fiFelzenszwalb & McAllester......goalA1A2A3context CCcontext A3DerivationA1DerivationA2DerivationA3Figure 6: derivation goal defines contexts statements appear derivation tree. Note context C together rule A1 , A2 , A3 Cderivations A1 A2 define context A3 .additive rules, context weight sum weights rules it.Let R set additive rules statements . B define `(context(B), R)weight lightest context B. value `(B, R) + `(context(B), R)weight lightest derivation goal uses B.Contexts derived using rules R together context rules c(R) definedfollows. First, goal empty context weight zero. captured ruleantecedents 0 context(goal ). rule A1 , . . . , v C R put n rulesc(R). rules capture notion context C derivations Aj j 6=define context Ai ,context(C), A1 , . . . , Ai1 , Ai+1 , . . . , v context(Ai ).Figure 6 illustrates context C together derivations A1 A2 ruleA1 , A2 , A3 C define context A3 .166fiThe Generalized A* Architecturesay heuristic function h admissible h(B) `(context(B), R). Admissibleheuristic functions never over-estimate weight deriving goal using derivationparticular statement. heuristic function perfect h(B) = `(context(B), R).show obtain admissible monotone heuristic functions abstractions.5.1 AbstractionsLet (, R) lightest derivation problem statements rules R. abstraction(, R) given problem (0 , R0 ) map abs : 0 , every ruleA1 , . . . , v C R rule abs(A1 ), . . . , abs(An ) v0 abs(C) R0 v 0 v.show abstraction used define monotone admissible heuristicfunction original problem.usually think abs defining coarsening mapping several statementsabstract statement. example, parser abs might map lexicalizednonterminal N Phouse nonlexicalized nonterminal N P . case abstractiondefines smaller problem abstract statements. Abstractions often definedmechanical way starting map abs set abstract statements0 . project rules R 0 using abs get set abstractrules. Typically several rules R map abstract rule. needkeep one copy abstract rule, weight lower bound weightconcrete rules mapping it.Every derivation (, R) maps abstract derivation `(abs(C), R0 )`(C, R). let goal abstract problem abs(goal ) every context (, R)maps abstract context see `(context(abs(C)), R0 ) `(context(C), R).means lightest abstract context weights form admissible heuristic function,h(C) = `(context(abs(C)), R0 ).show heuristic function also monotone.Consider rule A1 , . . . , v C R let (Ai = wi ) weight assignments derivableusing R. case rule abs(A1 ), . . . , abs(An ) v0 abs(C) R0 v 0 v(abs(Ai ) = wi0 ) derivable using R0 wi0 wi . definition contexts (inabstract problem) have,X`(context(abs(Ai )), R0 ) v 0 +wj0 + `(context(abs(C)), R0 ).j6=iSince v 0 v wj0 wj have,`(context(abs(Ai )), R0 ) v +Xwj + `(context(abs(C)), R0 ).j6=iPlugging heuristic function h adding wi sides,Xwi + h(Ai ) v +wj + h(C),jexactly monotonicity condition equation (1) additive rule.167fiFelzenszwalb & McAllesterabstract problem defined (0 , R0 ) relatively small efficiently computelightest context weights every statement 0 using dynamic programming KLD.store weights pattern database (a lookup table) serve heuristicfunction solving concrete problem using A*LD. heuristic may able stopA*LD exploring lot non-promising structures. exactly approachused Culberson Schaeffer (1998) Korf (1997) solving large searchproblems. results section show pattern databases usedgeneral setting lightest derivations problems. experiments Section 10 demonstratetechnique specific application.6. Hierarchical A* Lightest Derivationmain disadvantage using pattern databases precompute contextweights every abstract statement. often take lot time space.define hierarchical algorithm, HA*LD, searches lightest derivations contextsentire abstraction hierarchy simultaneously. algorithm often solveconcrete problem without fully computing context weights level abstraction.level abstraction behavior HA*LD similar behavior A*LDusing abstraction-derived heuristic function. hierarchical algorithm queuesderivations statement C priority depends lightest abstract contextC. abstract contexts computed advance. Instead, abstract contextscomputed time computing derivations. abstract contextC, derivations C stalled. captured addition context(abs(C))antecedent rule derives C.define abstraction hierarchy levels sequence lightest derivation problems additive rules (k , Rk ) 0 k 1 single abstractionfunction abs. 0 k < 1 abstraction function maps k onto k+1 . require (k+1 , Rk+1 ) abstraction (k , Rk ) defined previous section:A1 , . . . , v C Rk exists rule abs(A1 ), . . . , abs(An ) v0 abs(C)Rk+1 v 0 v. hierarchical algorithm computes lightest derivations statementsk using contexts k+1 define heuristic values. extend abs mapsm1 abstract set statements containing single element . Since absonto |k | |k+1 |. is, number statements decrease goabstraction hierarchy. denote abs k abstraction function 0 k obtainedcomposing abs k times.interested computing lightest derivation goal statement goal 0 . Letgoal k = abs k (goal ) goal level abstraction. hierarchical algorithmdefined set prioritized rules H Figure 7. Rules labeled compute derivationsstatements one level abstraction using context weights level definepriorities. Rules labeled BASE compute contexts one level abstractionusing derivation weights level define priorities. rules labeled START1START2 start inference handling abstract level.execution H starts computing derivation context START1START2. continues deriving statements m1 using rules.lightest derivation goal m1 found algorithm derives context goal m1168fiThe Generalized A* Architecture0START1:=0START2:0context() = 0BASE:goal k = wwcontext(goal k ) = 0UP:context(abs(C)) = wcA1 = w1...= wnv + w1 + + wn + wcC = v + w1 + + wnDOWN:context(C) = wcA1 = w1...= wnv + wc + w1 + + wncontext(Ai ) = v + wc + w1 + + wn wiFigure 7: Prioritized rules H defining HA*LD. BASE rules defined 0 k 1.rules defined rule A1 , . . . , v C Rk0 k 1.BASE rule starts computing contexts statements m1 using rules.general HA*LD interleaves computation derivations contexts levelabstraction since execution H uses single priority queue.Note computation happens given level abstraction lightest derivation goal found level above. means structureabstraction hierarchy defined dynamically. example, CFDP algorithm,could define set statements level abstraction refining statementsappear lightest derivation goal level above. assume staticabstraction hierarchy.statement C k 0 k 1 use `(C) denote weightlightest derivation C using Rk `(context(C)) denotes weight lightestcontext C using Rk . abstract level define `() = `(context()) = 0.169fiFelzenszwalb & McAllestershow HA*LD correctly computes lightest derivations lightest contextsevery level abstraction. Moreover, order derivations contextsexpanded controlled heuristic function defined follows. C k 0 k1 define heuristic value C using contexts level heuristic valuecontext(C) using derivations level,h(C) = `(context(abs(C))),h(context(C)) = `(C).abstract level define h() = h(context()) = 0. Let generalized statementeither element k 0 k expression form context(C)C k . define intrinsic priority follows,p() = `() + h().C k , p(context(C)) weight lightest derivation goal kuses C, p(C) lower bound weight.results Sections 4 5 cannot used directly show correctnessHA*LD. rules Figure 7 generate heuristic values timegenerate derivations depend heuristic values. Intuitively must showexecution prioritized rules H, heuristic value availableappropriate point time. next lemma shows rules H satisfy monotonicityproperty respect intrinsic priority generalized statements. Theorem 5 provescorrectness hierarchical algorithm.Lemma 4 (Monotonicity). rule 1 , . . . , hierarchical algorithm,weight antecedent `(i ) weight conclusion(a) priority rule + h().(b) + h() p(i ).Proof. rules START1 START2 result follows fact rulesantecedents h() = h(context()) = 0.Consider rule labeled BASE w = `(goal k ). see (a) note always zeropriority rule w = h(context(goal k )). (b) note p(goal k ) =`(goal k ) equals priority rule.consider rule labeled wc = `(context(abs(C))) wi = `(Ai ) i.part (a) note priority rule + wc h(C) = wc . part (b) considerfirst antecedent rule. h(context(abs(C))) = `(abs(C)) `(C) ,p(context(abs(C))) = wc + h(context(abs(C))) + wc . consider antecedentAi . abs(Ai ) = p(Ai ) = wi + wc . abs(Ai ) 6= showh(Ai ) = `(context(abs(Ai ))) wc + wi . implies p(Ai ) = wi + h(Ai ) + wc .Finally consider rule labeled wc = `(context(C)) wj = `(Aj )j. part (a) note priority rule + wi h(context(Ai )) = wi .Ppart(b) consider first antecedent rule. h(context(C)) = `(C) v + j wjsee p(context(C)) = wc + h(C) + wi . consider antecedent Aj .abs(Aj ) = h(Aj ) = 0 p(Aj ) = wj + wi . abs(Aj ) 6= showh(Aj ) + wi wj . Hence p(Aj ) = wj + h(Aj ) + wi .170fiThe Generalized A* ArchitectureTheorem 5. execution H maintains following invariants.1. ( = w) w = `().2. ( = w) Q priority w + h().3. p() < p(Q) ( = `())p(Q) denotes smallest priority Q.Proof. initial state algorithm empty Q contains ( = 0)(context() = 0) priority 0. initial state invariant 1 true since empty;invariant 2 follows definition h() h(context()); invariant 3 followsfact p(Q) = 0 p() 0 . Let Q denote statealgorithm immediately prior iteration loop Figure 5 supposeinvariants true. Let 0 Q0 denote state algorithm iteration.first prove invariant 1 0 . Let ( = w) element removed Qiteration. soundness rules w `(). w = `() clearlyinvariant 1 holds 0 . w > `() invariant 2 implies p(Q) = w +h() > `()+h()invariant 3 know contains ( = `()). case 0 = S.Invariant 2 Q0 follows invariant 2 Q, invariant 1 0 , part (a)monotonicity lemma.Finally, consider invariant 3 0 Q0 . proof reverse inductionabstraction level . say level k k form context(C)C k . reverse induction, base case considers level m. Initiallyalgorithm inserts ( = 0) (context() = 0) queue priority 0. p(Q0 ) > 00 must contain ( = 0) (context() = 0). Hence invariant 3 holds 0 Q0level m.assume invariant 3 holds 0 Q0 levels greater kconsider level k. first consider statements C k . Since rules Rk additive,every statement C derivable Rk lightest derivation (a derivation weight`(C)). follows correctness Knuths algorithm. Moreover, additiverules, subtrees lightest derivations also lightest derivations. show structuralinduction lightest derivation conclusion C p(C) < p(Q0 )(C = `(C)) 0 . Consider lightest derivation Rk conclusion Cp(C) < p(Q0 ). final rule derivation A1 , . . . , v C corresponds ruleadd antecedent context(abs(C)). part (b) monotonicity lemmaantecedents rule intrinsic priority less p(Q0 ). inductionhypothesis lightest derivations (Ai = `(Ai )) 0 . Since invariant 3 holdsstatements levels greater k (context(abs(C)) = `(context(abs(C)))) 0 .implies point rule used derive (C = `(C)) priority p(C).p(C) < p(Q0 ) hence item must removed queue. Therefore0 must contain (C = w) w and, invariant 1, w = `(C).consider form context(C) C k . see c(Rk )additive thus every statement derivable c(Rk ) lightest derivation subtreeslightest derivations lightest derivations themselves. prove structural induction171fiFelzenszwalb & McAllesterlightest derivation conclusion context(C) p(context(C)) <p(Q0 ) (context(C) = `(context(C))) 0 . Suppose last rule form,context(C), A1 , . . . , Ai1 , Ai+1 , . . . , v context(Ai ).rule corresponds rule add antecedent Ai . part (b)monotonicity lemma antecedents rule intrinsic priority lessp(Q0 ). invariant 3 statements k induction hypothesis lightestderivations using c(Rk ), antecedents rule lightest weight0 . point (context(Ai ) = `(context(Ai ))) derived priority p(Ai ).p(Ai ) < p(Q0 ) implies item removed queue and, invariant 1,(context(Ai ) = `(context(Ai ))) 0 .suppose last (and only) rule 0 context(goal k ). rule corresponds BASE rule add goal k antecedent. Note p(goal k ) =`(goal k ) = p(context(goal k )) hence p(goal k ) < p(Q0 ). invariant 3 statementsk (goal k = `(goal k )) 0 point BASE rule used queue(context(goal k ) = `(context(goal k ))) priority p(context(goal k )). previous casesp(context(goal k )) < p(Q0 ) implies (context(goal k ) = `(context(goal k ))) 0 .last theorem implies generalized statements expanded orderintrinsic priority. Let K number statements C entire abstraction hierarchyp(C) p(goal ) = `(goal ). every statement C p(C) p(context(C)).conclude HA*LD expands 2K generalized statements computinglightest derivation goal .6.1 Exampleconsider execution HA*LD specific example. example illustratesHA*LD interleaves computation structures different levels abstraction.Consider following abstraction hierarchy 2 levels.0 = {X1 , . . . , Xn , Y1 , . . . , Yn , Z1 , . . . , Zn , goal 0 }, 1 = {X, Y, Z, goal 1 },1 X,Xi ,Y,,1Xi , Yj ij goal 0 ,X, 1 goal 1 ,, R1 =,R0 =Z,,Z,X,X55Z 1 goal 1 ,Zi goal 0 ,abs(Xi ) = X, abs(Yi ) = , abs(Zi ) = Z abs(goal0 ) = goal1 .1. Initially = Q = {( = 0) (context() = 0) priority 0}.2. ( = 0) comes queue gets put nothing else happens.3. (context() = 0) comes queue gets put S. statements 1abstract context S. causes rules come rules R1antecedents fire, putting (X = 1) (Y = 1) Q priority 1.172fiThe Generalized A* Architecture4. (X = 1) (Y = 1) come queue get put S, causing tworules fire, putting (goal 1 = 3) priority 3 (Z = 7) priority 7 queue.5. have,= {( = 0), (context() = 0), (X = 1), (Y = 1)}Q = {(goal 1 = 3) priority 3, (Z = 7) priority 7}6. point (goal 1 = 3) comes queue goes S. BASE rule firesputting (context(goal 1 ) = 0) queue priority 3.7. (context(goal 1 ) = 0) comes queue. base case contexts 1 . Tworules use (context(goal 1 ) = 0), (X = 1) (Y = 1) put (context(X) = 2)(context(Y ) = 2) Q priority 3.8. (context(X) = 2) comes queue gets put S. abstractcontext Xi 0 , rules put (Xi = i) Q priority + 2.9. (context(Y ) = 2) comes queue goes S. previous steprules put (Yi = i) Q priority + 2.10. have,= {( = 0), (context() = 0), (X = 1), (Y = 1), (goal 1 = 3),(context(goal 1 ) = 0), (context(X) = 2), (context(Y ) = 2)}Q = {(Xi = i) (Yi = i) priority + 2 1 n, (Z = 7) priority 7}11. Next (X1 = 1) (Y1 = 1) come queue go S. causesrule put (goal 0 = 3) queue priority 3.12. (goal 0 = 3) comes queue goes S. algorithm stop sincederivation concrete goal.Note HA*LD terminates fully computing abstract derivations contexts.particular (Z = 7) Q Z never expanded. Moreover context(Z) evenqueue. keep running algorithm would eventually derive context(Z),would allow Zi derived.7. Perception PipelineFigure 8 shows hypothetical run hierarchical algorithm processing pipelinevision system. system weighted statements edges used deriveweighted statements contours provide input later stages ultimately resultingstatements recognized objects.well known subjective presence edges particular image locationdepend context given image patch appears. interpretedperception pipeline stating higher level processes later pipelineinfluence low-level interpretations. kind influence happens naturally lightest173fiFelzenszwalb & McAllesterm1EdgesContoursRecognition1EdgesContoursRecognition0EdgesContoursRecognitionFigure 8: vision system several levels processing. Forward arrows representnormal flow information one stage processing next. Backwardarrows represent computation contexts. Downward arrows representinfluence contexts.derivation problem. example, lightest derivation complete scene analysis mightrequire presence edge locally apparent. implementing wholesystem single lightest derivation problem avoid need make hard decisionsstages pipeline.influence late pipeline stages guiding earlier stages pronounced useHA*LD compute lightest derivations. case influence apparentstructure optimal solution also flow information across differentstages processing. HA*LD complete interpretation derived one level abstractionguides processing stages concrete level. Structures derived late stagespipeline guide earlier stages abstract context weights. allows earlyprocessing stages concentrate computational efforts constructing structureslikely part globally optimal solution.emphasized use admissible heuristics, note A* architecture, including HA*LD, also used inadmissible heuristic functions (of coursewould break optimality guarantees). Inadmissible heuristics importantadmissible heuristics tend force first stages processing pipeline generatemany derivations. derivations composed weights increase causeslarge number derivations generated first stages processingfirst derivation reaches end pipeline. Inadmissible heuristics produce behaviorsimilar beam search derivations generated first stage pipeline flowwhole pipeline quickly. natural way construct inadmissible heuristicssimply scale-up admissible heuristic ones obtained abstractions.possible construct hierarchical algorithm inadmissible heuristics obtainedone level abstraction used guide search level below.8. Hierarchical Methodssection compare HA*LD hierarchical search methods.174fiThe Generalized A* Architecture8.1 Coarse-to-Fine Dynamic ProgrammingHA*LD related coarse-to-fine dynamic programming (CFDP) method describedRaphael (2001). understand relationship consider problem finding shortestpath trellis graph like one shown Figure 9(a). k columnsn nodes every node one column connected constant number nodesnext column. Standard dynamic programming used find shortest pathO(kn) time. CFDP HA*LD often find shortest path much faster.hand worst case behavior algorithms different describebelow, CFDP taking significantly time HA*LD.CFDP algorithm works coarsening graph, grouping nodes columnsmall number supernodes illustrated Figure 9(b). weight edgetwo supernodes B minimum weight nodes b B.algorithm starts using dynamic programming find shortest path Pcoarse graph, shown bold Figure 9(b). supernodes along Ppartitioned define finer graph shown Figure 9(c) procedure repeated.Eventually shortest path P go supernodes size one, correspondingpath original graph. point know P must shortest pathoriginal graph. best case optimal path iterationrefinement optimal path previous iteration. would result O(log n)shortest paths computations, fairly coarse graphs. hand, worstcase CFDP take (n) iterations refine whole graph, many iterationsinvolve finding shortest paths large graphs. case CFDP takes (kn2 ) timemuch worst standard dynamic programming approach.suppose use HA*LD find shortest path graph likeone Figure 9(a). build abstraction hierarchy O(log n) levelssupernode level contains 2i nodes one column original graph. coarsegraph Figure 9(b) represents highest level abstraction hierarchy. NoteHA*LD consider small number, O(log n), predefined graphs CFDP endconsidering much larger number, (n), graphs. best case scenario HA*LDexpand nodes shortest path levelhierarchy. worst case HA*LD compute lightest path context everynode hierarchy (here context node v path v t). i-thabstraction level graph O(kn/2i ) nodes edges. HA*LD spendO(kn log(kn)/2i ) time computing paths contexts level i. Summing levelsget O(kn log(kn)) time total, much worst O(kn) timetaken standard dynamic programming approach.8.2 Hierarchical Heuristic Searchhierarchical method also related HA* HIDA* algorithms describedHolte et al. (1996) Holte et al. (2005). methods restricted shortest pathsproblems also use hierarchy abstractions. heuristic function definedlevel abstraction using shortest paths goal level above. mainidea run A* IDA* compute shortest path computing heuristic values ondemand. Let abs map node abstraction let g goal node concrete175fiFelzenszwalb & McAllester(a)(b)(c)Figure 9: (a) Original dynamic programming graph. (b) Coarse graph shortest pathshown bold. (c) Refinement coarse graph along shortest path.graph. Whenever heuristic value concrete node v needed call algorithmrecursively find shortest path abs(v) abs(g). recursive call uses heuristicvalues defined abstraction, computed deeper recursive calls.clear generalize HA* HIDA* lightest derivation problemsrules multiple antecedents. Another disadvantage methodspotentially stall case directed graphs. example, suppose usingHA* HIDA* expand node two successors x y, x close goalfar. point need heuristic value x y, mightspend long time computing shortest path abs(y) abs(g). hand,HA*LD would wait shortest path fully computed. Intuitively HA*LDwould compute shortest paths abs(x) abs(y) abs(g) simultaneously. soonshortest path abs(x) abs(g) found start exploring path xg, independent long would take compute path abs(y) abs(g).176fiThe Generalized A* Architecturer2r1r3r0r4r7r5r6Figure 10: convex set specified hypothesis (r0 , . . . , r7 ).9. Convex Object Detectionconsider application HA*LD problem detecting convex objectsimages. pose problem using formulation similar one described Raphael(2001), optimal convex object around point found solving shortestpath problem. compare HA*LD search methods, including CFDP A*pattern databases. results indicate HA*LD performs bettermethods wide range inputs.Let x reference point inside convex object. represent object boundaryusing polar coordinates respect coordinate system centered x. caseobject described periodic function r() specifying distance x objectboundary function angle . specify r() finite number angles(0 , . . . , N 1 ) assume boundary straight line segment sample points.also assume object contained ball radius R around x r()integer. Thus object parametrized (r0 , . . . , rN 1 ) ri [0, R 1]. exampleN = 8 angles shown Figure 10.every hypothesis (r0 , . . . , rN 1 ) specifies convex object. hypothesis describesconvex set exactly object boundary turns left sample point (i , ri )increases. Let C(ri1 , ri , ri+1 ) Boolean function indicating three sequentialvalues r() define boundary locally convex i. hypothesis (r0 , . . . , rN 1 )convex locally convex i.3Throughout section assume reference point x fixed advance.goal find optimal convex object around given reference point. practicereference locations found using variety methods Hough transform.3. parametrization convex objects similar identical one used Raphael (2001).177fiFelzenszwalb & McAllesterLet D(i, ri , ri+1 ) image data cost measuring evidence boundary segment(i , ri ) (i+1 , ri+1 ). consider problem finding convex objectsum data costs along whole boundary minimal. is, lookconvex hypothesis minimizing following energy function,E(r0 , . . . , rN 1 ) =N1XD(i, ri , ri+1 ).i=0data costs precomputed specified lookup table O(N R2 ) entries.experiments use data cost based integral image gradient alongboundary segment. Another approach would use data term describedRaphael (2001) cost depends contrast inside outsideobject measured within pie-slice defined i+1 .optimal convex object found using standard dynamic programming techniques. Let B(i, r0 , r1 , ri1 , ri ) cost optimal partial convex object startingr0 r1 ending ri1 ri . keep track last two boundary pointsenforce convexity constraint extend partial objects. also keep trackfirst two boundary points enforce rN = r0 convexity constraint r0 .compute B using recursive formula,B(1, r0 , r1 , r0 , r1 ) = D(0, r0 , r1 ),B(i + 1, r0 , r1 , ri , ri+1 ) = min B(i, r0 , r1 , ri1 , ri ) + D(i, ri , ri+1 ),ri1minimization choices ri1 C(ri1 , ri , ri+1 ) = true.cost optimal object given minimum value B(N, r0 , r1 , rN 1 , r0 )C(rN 1 , r0 , r1 ) = true. optimal object found tracing-back typical dynamic programming algorithms. main problem approach dynamicprogramming table O(N R4 ) entries takes O(R) time compute entry.overall algorithm runs O(N R5 ) time quite slow.show optimal convex objects defined terms lightest derivationproblem. Let convex (i, r0 , r1 , ri1 , ri ) denote partial convex object starting r0 r1ending ri1 ri . corresponds entry dynamic programming tabledescribed above. Define set statements,= {convex (i, a, b, c, d) | [1, N ], a, b, c, [0, R 1]} {goal }.optimal convex object corresponds lightest derivations goal using rulesFigure 11. first set rules specify cost partial object r0 r1 .second set rules specify object ending ri1 ri extendedchoice ri+1 boundary locally convex ri . last set rules specifycomplete convex object partial object r0 rN rN = r0boundary locally convex r0 .construct abstraction hierarchy define L nested partitions radius space[0, R 1] ranges integers. abstract statement instead specifying integervalue r() specify range r() contained. simplify notation178fiThe Generalized A* Architecture(1) r0 , r1 [0, R 1],convex (1, r0 , r1 , r0 , r1 ) = D(0, r0 , r1 )(2) r0 , r1 , ri1 , ri , ri+1 [0, R 1] C(ri1 , ri , ri+1 ) = true,convex (i, r0 , r1 , ri1 , ri ) = wconvex (i + 1, r0 , r1 , ri , ri+1 ) = w + D(i, ri , ri+1 )(3) r0 , r1 , rN 1 [0, R 1] C(rN 1 , r0 , r1 ) = true,convex (N, r0 , r1 , rN 1 , r0 ) = wgoal = wFigure 11: Rules finding optimal convex object.assume R power two. k-th partition P k contains R/2k ranges,2k consecutive integers. j-th range P k given [j 2k , (j + 1) 2k 1].statements abstraction hierarchy are,k = {convex (i, a, b, c, d) | [1, N ], a, b, c, P k } {goal k },k [0, L 1]. range P 0 contains single integer 0 = . Let f map rangeP k range P k+1 containing it. statements level k < L 1 defineabstraction function,abs(convex (i, a, b, c, d)) = convex (i, f (a), f (b), f (c), f (d)),abs(goal k ) = goal k+1 .abstract rules use bounds data costs boundary segments (i , si )(i+1 , si+1 ) si si+1 ranges P k ,Dk (i, si , si+1 ) =minD(i, ri , ri+1 ).ri siri+1 si+1Since range P k union two ranges P k1 one entry Dk computedquickly (in constant time) Dk1 computed. bounds levels computed O(N R2 ) time total. also need abstract versions convexity constraints.si1 , si , si+1 P k , let C k (si1 , si , si+1 ) = true exist integers ri1 , ri ri+1si1 , si si+1 respectively C(ri1 , ri , ri+1 ) = true. value C kdefined closed form evaluated quickly using simple geometry.rules abstraction hierarchy almost identical rules Figure 11.rules level k obtained original rules simply replacing instance[0, R 1] P k , C C k Dk .179fiFelzenszwalb & McAllesterStandard DPCFDPHA*LDA* pattern database 2A* pattern database 36718.6 seconds13.5 seconds8.6 seconds14.3 seconds29.7 secondsTable 1: Running time comparison example Figure 12.9.1 Experimental ResultsFigure 12 shows example image set reference locations selected manuallyoptimal convex object found around reference point. 14 referencelocations used N = 30 R = 60 parametrize object. Table 1 comparesrunning time different optimization algorithms implemented problem.line shows time took solve 14 problems contained example image usingparticular search algorithm. standard DP algorithm uses dynamic programmingsolution outlined above. CFDP method based algorithm Raphael (2001)modified representation convex objects. hierarchical A* algorithm usesabstraction hierarchy described here. A* pattern databases used dynamicprogramming compute pattern database particular level abstraction,used database provide heuristic values A*. Note problem describedpattern database depends input. running times listed include timetook compute pattern database case.see CFDP, HA*LD A* pattern databases much efficientstandard dynamic programming algorithm use abstractions. HA*LDslightly faster methods example. Note running timevaries algorithm algorithm output every method findglobally optimum objects.quantitative evaluation different search algorithms created large setproblems varying difficulty size follows. given value R generated squareimages width height 2 R + 1. image circle radius less R nearcenter pixels image corrupted independent Gaussian noise.difficulty problem controlled standard deviation, , noise. Figure 13shows example images optimal convex object found around centers.graph Figure 14 shows running time (in seconds) different searchalgorithms function noise level problem size fixed R = 100.sample point indicates average running time 200 random inputs. graphshows running times point circles reliably detected.compared HA*LD CFDP A* using pattern databases (PD2 PD3). PD2PD3 refer A* pattern database defined 2 3 respectively. Sincepattern database needs recomputed input trade-off amounttime spent computing database accuracy heuristic provides.see easy problems better use smaller database (defined higher levelabstraction) harder problems worth spending time computing biggerdatabase. HA*LD outperforms methods every situation captured here.180fiThe Generalized A* Architecture(a)(b)Figure 12: (a) Reference locations. (b) Optimal convex objects.181fiFelzenszwalb & McAllesterFigure 13: Random images circles optimal convex object around centerone (with N = 20 R = 100). noise level images = 50.Figure 15 shows running time different methods function problemsize R, problems fixed noise level = 100. sample pointindicates average running time taken 200 random inputs. see runningtime pattern database approach grows quickly problem size increases.computing database fixed level abstraction takes O(N R5 ) time.hand running time CFDP HA*LD grows much slower.CFDP performed essentially well HA*LD experiment, graph Figure 14shows HA*LD performs better difficulty problem increases.10. Finding Salient Curves Imagesclassical problem computer vision involves finding salient curves images. Intuitivelygoal find long smooth curves go along paths high image gradient.standard way pose problem define saliency score search curvesoptimizing score. methods use score defined simple combination localterms. example, score usually depends curvature image gradientpoint curve. type score often optimized efficiently using dynamicprogramming shortest paths algorithms (Montanari, 1971; Shashua & Ullman, 1988;Basri & Alter, 1996; Williams & Jacobs, 1996).consider new compositional model finding salient curves. importantaspect model capture global shape constraints. particular, lookscurves almost straight, something done using local constraintsalone. Local constraints enforce small curvature point curve,182fiThe Generalized A* ArchitectureFigure 14: Running time different search algorithms function noise levelinput. sample point indicates average running time taken 200random inputs. case N = 20 R = 100. See text discussion.enough prevent curves turning twisting around long distances.problem finding salient curve image compositional model definedsolved using dynamic programming, approach slow practicaluse. Shortest paths algorithms applicable compositional naturemodel. Instead use A*LD heuristic function derived abstraction(a pattern database).Let C1 curve endpoints b C2 curve endpoints b c.two curves composed form curve C c. define weightcomposition sum weights C1 C2 plus shape cost dependsgeometric arrangement points (a, b, c). Figure 16 illustrates idea shapecosts use. Note C1 C2 long, arrangement endpoints reflectnon-local geometric properties. general consider composing C1 C2 angleformed ab bc least /2 lengths C1 C2 approximately equal.constraints reduce total number compositions play important roleabstract problem defined below.Besides compositional rule say b nearby locations,short curve endpoints b. forms base case creating longer curves.183fiFelzenszwalb & McAllesterFigure 15: Running time different search algorithms function problem size R.sample point indicates average running time taken 200 randominputs. case N = 20 = 100. See text discussion.bcFigure 16: curve endpoints (a, c) formed composing curves endpoints(a, b) (b, c). assume /2. cost compositionproportional sin2 (t). cost scale invariant encourages curvesrelatively straight.assume short curves straight, weight depends imagedata along line segment b. use data term, seg(a, b), zeroimage gradient along pixels ab perpendicular ab, higher otherwise.Figure 17 gives formal definition two rules model. constants k1k2 specify minimum maximum length base case curves, L constant184fiThe Generalized A* Architecture(1) pixels a, b, c angle ab bc least /2 0 L,curve(a, b, i) = w1curve(b, c, i) = w2curve(a, c, + 1) = w1 + w2 + shape(a, b, c)(2) pixels a, b k1 ||a b|| k2 ,curve(a, b, 0) = seg(a, b)Figure 17: Rules finding almost straight curves pair endpoints. L,k1 k2 constants, shape(a, b, c) function measuring costcomposition.controlling maximum depth derivations. derivation curve(a, b, i) encodes curveb. value seen approximate measure arclength. derivationcurve(a, b, i) full binary tree depth encodes curve length2i k1 2i k2 . let k2 = 2k1 allow curves length.rules Figure 17 define good measure saliencyalways prefer short curves long ones. define saliency curveterms weight minus arclength, salient curves light long. Letpositive constant. consider finding lightest derivation goal using,curve(a, b, i) = wgoal = w 2in n image (n4 ) statements form curve(a, c, i). Moreover,c far apart (n) choices midpoint b defining two curvescomposed lightest derivation curve(a, c, i). makes dynamic programmingsolution lightest derivation problem impractical. tried using KLD evensmall images algorithm runs memory minutes. describeabstraction used define heuristic function A*LD.Consider hierarchical set partitions image boxes. i-th partitiondefined tiling image boxes 2i 2i pixels. partitions form pyramidboxes different sizes level. box level union 4 boxes levelit, boxes level 0 pixels themselves. Let fi (a) box containingi-th level pyramid. defineabs(curve(a, b, i)) = curve(fi (a), fi (b), i).185fiFelzenszwalb & McAllesterBbcCFigure 18: abstraction maps curve statement statement curvesboxes. > j curve(a, b, i) gets coarsened curve(c, d, j). Sincelight curves almost straight, > j usually implies ||a b|| > ||c d||.Figure 18 illustrates map selects pyramid level abstract statement. Intuitively abs defines adaptive coarsening criteria. b far other,curve b must long, turn implies map b boxescoarse partition image. creates abstract problem small numberstatements without losing much information.define abstract problem also need define set abstract rules. Recallevery concrete rule r need corresponding abstract rule r0 weightr0 weight r. small number rules antecedentsFigure 17. concrete rule seg(a,b) curve(a, b, 0) define corresponding abstractrule, seg(a,b) abs(curve(a, b, 0)). compositional rules Figure 17 lead abstractrules composing curves boxes,curve(A, B, i), curve(B, C, i) v curve(A0 , C 0 , + 1),A, B C boxes i-th pyramid level A0 C 0 boxeslevel + 1 containing C respectively. weight v shape(a, b, c)a, b c arbitrary pixels A, B C respectively. compute valuev bounding orientations line segments ab bc boxes.186fiThe Generalized A* Architecture146 137 pixels. Running time: 50 seconds (38 + 12).122 179 pixels. Running time: 65 seconds (43 + 22).226 150 pixels. Running time: 73 seconds (61 + 12).Figure 19: salient curve different images. running time sumtime spent computing pattern database time spent solvingconcrete problem.187fiFelzenszwalb & McAllesterFigure 20: example salient curve goes locations essentiallylocal evidence curve locations.abstract problem defined relatively small even large images,use pattern database approach outlined Section 5.1. input image useKLD compute lightest context weights every abstract statement. useweights heuristic values solving concrete problem A*LD. Figure 19 illustratesresults obtained using method. seems like abstract problemable capture short curves extended salient curve. tookone minute find salient curve images. Figure 19 listsdimensions image running time case.Note algorithm rely initial binary edge detection stage. Insteadbase case rules allow salient curves go pixel, even localevidence boundary particular location. Figure 20 shows examplehappens. case small part horse back blends backgroundconsider local properties alone.curve finding algorithm described section would difficult formulatewithout A*LD general notion heuristics derived abstractions lightestderivation problems. However, using framework introduced paper becomesrelatively easy specify algorithm.future plan compose rules computing salient curves rulescomputing complex structures. basic idea using pyramid boxes definingabstract problem applicable variety problems computer vision.188fiThe Generalized A* Architecture11. ConclusionAlthough presented preliminary results last two sections, viewmain contribution paper providing general architecture perceptual inference.Dijkstras shortest paths algorithm A* search fundamental algorithmsmany applications. Knuth noted generalization Dijkstras algorithm generalproblems defined set recursive rules. paper given similar generalizations A* search heuristics derived abstractions. also describednew method solving lightest derivation problems using hierarchy abstractions.Finally, outlined approach using generalizations constructionprocessing pipelines perceptual inference.Acknowledgmentsmaterial based upon work supported National Science FoundationGrant No. 0535174 0534820.ReferencesBasri, R., & Alter, T. (1996). Extracting salient curves images: analysissaliency network. IEEE Conference Computer Vision Pattern Recognition.Bonet, B., & Geffner, H. (2005). algorithm better AO*. ProceedingsNational Conference Artificial Intelligence.Bulitko, V., Sturtevant, N., Lu, J., & Yau, T. (2006). State abstraction real-time heuristicsearch. Technical Report, University Alberta, Department Computer Science.Charniak, E. (1996). Statistical Language Learning. MIT Press.Culberson, J., & Schaeffer, J. (1998). Pattern databases. Computational Intelligence, 14 (3),318334.Dijkstra, E. (1959). note two problems connection graphs. Numerical Mathematics, 1, 269271.Edelkamp, S. (2002). Symbolic pattern databases heuristic search panning. International Conference AI Planning Scheduling.Felner, A. (2005). Finding optimal solutions graph partitioning problem heuristicsearch. Annals Mathematics Artificial Intelligence, 45 (3-4), 293322.Geman, S., Potter, D., & Chi, Z. (2002). Composition systems. Quarterly AppliedMathematics, 707736.Hansen, E., & Zilberstein, S. (2001). LAO*: heuristic search algorithm finds solutionsloops. Artificial Intelligence, 129, 3562.Hart, P., Nilsson, N., & Raphael, B. (1968). formal basis heuristic determinationminimal cost paths. IEEE Transactions Systems Science Cybernetics, 4 (2),100107.Holte, R., Grajkowski, J., & Tanner, B. (2005). Hierarchical heuristic search revisited.Symposium Abstraction, Reformulation Approximation.189fiFelzenszwalb & McAllesterHolte, R., Perez, M., Zimmer, R., & MacDonald, A. (1996). Hierarchical A*: Searching abstraction hierarchies efficiently. Proceedings National Conference ArtificialIntelligence.Jimenez, P., & Torras, C. (2000). efficient algorithm searching implicit AND/ORgraphs cycles. Artificial Intelligence, 124, 130.Jin, Y., & Geman, S. (2006). Context hierarchy probabilistic image model.IEEE Conference Computer Vision Pattern Recognition.Klein, D., & Manning, C. (2003). A* parsing: Fast exact viterbi parse selection. Proceedings HLT-NAACL.Knuth, D. (1977). generalization Dijkstras algorithm. Information Processing Letters,6 (1), 15.Korf, R. (1997). Finding optimal solutions Rubiks cube using pattern databases.Proceedings National Conference Artificial Intelligence.Korf, R., & Felner, A. (2002). Disjoint pattern database heuristics. Artificial Intelligence,134, 922.Korf, R., Zhang, W., Thayer, I., & Hohwald, H. (2005). Frontier search. JournalACM, 52 (5), 715748.McAllester, D. (2002). complexity analysis static analyses. Journal ACM,49 (4), 512537.Montanari, U. (1971). optimal detection curves noisy pictures. CommunicationsACM, 14 (5).Nilsson, N. (1980). Principles Artificial Intelligence. Morgan Kaufmann.Pearl, J. (1984). Heuristics: intelligent search strategies computer problem solving.Addison-Wesley.Rabiner, L. (1989). tutorial hidden Markov models selected applications speechrecognition. Proceedings IEEE, 77 (2), 257286.Raphael, C. (2001). Coarse-to-fine dynamic programming. IEEE Transactions PatternAnalysis Machine Intelligence, 23 (12), 13791390.Shashua, A., & Ullman, S. (1988). Structural saliency: detection globally salientstructures using locally connected network. IEEE International ConferenceComputer Vision.Tu, Z., Chen, X., Yuille, A., & Zhu, S. (2005). Image parsing: Unifying segmentation,detection, recognition. International Journal Computer Vision, 63 (2), 113140.Williams, L., & Jacobs, D. (1996). Local parallel computation stochastic completionfields. IEEE Conference Computer Vision Pattern Recognition.Zhang, W., & Korf, R. (1996). study complexity transitions asymmetric travelingsalesman problem. Artificial Intelligence, 81, 12.190fiJournal Artificial Intelligence Research 29 (2007) 391-419Submitted 1/2007; published 8/2007Obtaining Reliable Feedback Sanctioning ReputationMechanismsRadu JurcaBoi Faltingsradu.jurca@epfl.chboi.faltings@epfl.chEcole Polytechnique Federale de Lausanne (EPFL)Artificial Intelligence Laboratory (LIA)CH-1015 Lausanne, Switzerlandhttp: // liawww. epfl. chAbstractReputation mechanisms offer effective alternative verification authorities building trust electronic markets moral hazard. Future clients guide business decisions considering feedback past transactions; truthfully exposed, cheatingbehavior sanctioned thus becomes irrational.therefore becomes important ensure rational clients right incentivesreport honestly. alternative side-payment schemes explicitly reward truthful reports, show honesty emerge rational behavior clientsrepeated presence market. end describe mechanism supportsequilibrium truthful feedback obtained. characterize set paretooptimal equilibria mechanism, derive upper bound percentage falsereports recorded mechanism. important role existencebound played fact rational clients establish reputation reportinghonestly.1. Introductionavailability ubiquitous communication Internet driving migration business transactions direct contact people electronically mediatedinteractions. People interact electronically either human-computer interfacesprograms representing humans, so-called agents. either case, physical interactions among entities occur, systems much susceptible frauddeception.Traditional methods avoid cheating involve cryptographic schemes trusted thirdparties (TTPs) overlook every transaction. systems costly, introducepotential bottlenecks, may difficult deploy due complexity heterogeneity environment: e.g., agents different geographical locations may subjectdifferent legislation, different interaction protocols.Reputation mechanisms offer novel effective way ensuring necessary leveltrust essential functioning market. based observation agent strategies change consider interactions repeated:party remembers past cheating, changes terms business accordingly future.Therefore, expected gains due future transactions agent higherreputation offset loss incurred cheating present. effect amc2007AI Access Foundation. rights reserved.fiJurca & Faltingsplified considerably reputation information shared among large population,thus multiplies expected future gains made accessible honest behavior.Existing reputation mechanisms enjoy huge success. Systems eBay1 Amazon2implement reputation mechanisms partly credited businesses success.Studies show human users seriously take account reputation sellerplacing bids online auctions (Houser & Wooders, 2006), despite incentivefree ride, feedback provided half transactions eBay (Resnick &Zeckhauser, 2002).One important challenge associated designing reputation mechanisms ensuretruthful feedback obtained actual interactions, property called incentivecompatibility. Rational users regard private information observedvaluable asset, freely shared. Worse even, agents external incentivesmisreport thus manipulate reputation information available agents(Harmon, 2004). Without proper measures, reputation mechanism obtain unreliableinformation, biased strategic interests reporters.Honest reporting incentives addressed differently depending predominant role reputation mechanisms. signaling role useful environmentsservice offered different providers may different quality, clients interacting provider treated equally (markets adverse selection).case, example, market web-services. Different providers possess differenthardware resources employ different algorithms; makes certain web-services betterothers. Nevertheless, requests issued web-service treatedprogram. clients might experience worse service others, differences random, determined provider. feedback previous clientsstatistically estimates quality delivered provider future, hence signalsfuture clients provider selected.sanctioning role, hand, present settings service requestsissued clients must individually addressed provider. Think barber,must skillfully shave every client walks shop. problem providersmust exert care (and costly effort) satisfying every service request. Good qualityresult enough effort exerted, provider better exerting lesseffort: e.g., clients anyway pay shave, barber better sloppyjob fast possible order time customers. moral hazard situationeliminated reputation mechanism punishes providers exerting effort.Low effort results negative feedback decreases reputation, hence futurebusiness opportunities provider. future loss due bad reputation offsetsmomentary gain obtained cheating, makes cooperative behavior profitable.well known solutions providing honest reporting incentives signalingreputation mechanisms. Since clients interacting service receive quality(in statistical sense), clients private observation influences belief regardingexperience clients. web-services market mentioned before, fact oneclient bad experience certain web-service makes likely believeclients also encounter problems web-service. correlation1. www.ebay.com2. www.amazon.com392fiObtaining Reliable Feedback Sanctioning Reputation Mechanismsclients private belief feedback reported clients useddesign feedback payments make honesty Nash equilibrium. submittingfeedback, clients get paid amount depends value reportedreports submitted clients. long others report truthfully,expected payment every client maximized honest report thus equilibrium.Miller, Resnick, Zeckhauser (2005) Jurca Faltings (2006) show incentivecompatible payments designed offset reporting costs lying incentives.sanctioning reputation mechanisms payment schemes guaranteedincentive-compatible. Different clients may experience different service qualityprovider decided exert different effort levels. private beliefs reportermay longer correlated feedback clients, therefore, statisticalproperties exploited Miller et al. (2005) longer present.alternative, propose different incentives motivate honest reporting basedrepeated presence client market. Game theoretic results (i.e., folktheorems) show repeated interactions support new equilibria present deviationsmade unattractive future penalties. Even without reputation mechanism, clientguide future play depending experience previous interactions. firstresult paper, describe mechanism indeed supports cooperative equilibriumproviders exert effort time. reputation mechanism correctly recordsclient received low quality.certainly applications clients repeatedly interactseller potential moral hazard problem. barber shop mentioned oneexample, people prefer going barber (or hairdresser). Another examplemarket delivery services. Every package must scheduled timely delivery,involves cost provider. cost may saved occasionallydropping package, hence moral hazard. Moreover, business clients typically relycarrier dispatch documents merchandise. businessdepends quality timeliness delivery, incentive formlasting relationship get good service. Yet another example business personrepeatedly travels offshore client. business person direct interestrepeatedly obtain good service hotel closest clients offices.assume quality observed clients also influenced environmentalfactors outside control of, however observable by, provider. Despite barbersbest effort, sudden movement client always generate accidental cutmake client unhappy. Likewise, delivery company may occasionally lose damagepackages due transportation accidents. Nevertheless, delivery company (likebarber) eventually learns certainty delays, damages losses entitleclients complain unsatisfactory service.mechanism propose quite simple. asking feedback client,mechanism gives provider opportunity acknowledge failure, reimburseclient. provider claims good service reputation mechanism recordfeedback client. Contradictory reports (the provider claims good service,client submits negative feedback) may appear one parties lying,therefore, client provider sanctioned: provider suffers lossconsequence negative report, client given small fine.393fiJurca & FaltingsOne equilibrium mechanism providers always best deliverpromised quality, truthfully acknowledge failures caused environmentalfactors. honest behavior motivated threat mistake driveunsatisfied client away market. future transactions generate sufficientrevenue, provider afford risk losing client, hence equilibrium.Unfortunately, socially desired equilibrium unique. Clients occasionallyaccept bad service keep returning provider dont betteralternatives. Moreover, since complaining bad service sanctioned reputationmechanism, clients might reluctant report negative feedback. Penalties negativereports clients lack choice drives provider occasionally cheat orderincrease revenue.second result, characterize set pareto-optimal equilibria mechanismprove amount unreported cheating occur limited two factors.first factor limits amount cheating general, given qualityalternatives available clients. Better alternatives increase expectationsclients, therefore provider must cheat less order keep customers.second factor limits amount unreported cheating, represents costincurred clients establish reputation reporting truth. stubbornly exposingbad service happens, despite fine imposed reputation mechanism,client signals provider committed always report truth. signalseventually change strategy provider full cooperation, avoidpunishment negative feedback. reputation reporting truthfully course,valuable client; therefore, rational client accepts lie (and give reputation)cost building reputation reporting honestly greateroccasional loss created tolerated cheating. cost given easeprovider switches cooperative play, magnitude fine imposednegative feedback.Concretely, paper proceeds follows. Section 2 describe related work, followed detailed description setting Section 3. Section 4 presents gametheoretic model mechanism analysis reporting incentives equilibria.establish existence cooperative equilibrium, derive un upper boundamount cheating occur pareto-optimal equilibrium.Section 5 establish cost building reputation reporting honestly,hence compute upper bound percentage false reports recorded reputationmechanism equilibrium.continue Section 6 analyzing impact malicious buyers explicitlytry destroy reputation provider. give initial approximationsworst case damage buyers cause providers. discussions, open issuesdirections future work discussed Section 7. Finally, Section 8 concludes work.2. Related Worknotion reputation often used Game Theory signal commitment playertowards fixed strategy. mean saying clients establish reputationreporting truth: commit always report truth. Building reputation394fiObtaining Reliable Feedback Sanctioning Reputation Mechanismsusually requires incomplete information repeated game, significantly impactset equilibrium points game. commonly referred reputationeffect, first characterized seminal papers Kreps, Milgrom, Roberts, Wilson(1982), Kreps Wilson (1982) Milgrom Roberts (1982).reputation effect extended games player (A) could benefitcommitting certain strategy credible complete informationgame: e.g., monopolist seller would like commit fight potential entrantschain-store game (Selten, 1978), however, commitment credible due costfighting. incomplete information game commitment type positiveprobability, opponent (B) point become convinced playingcommitment type. point, B play best response ,gives desired payoff. Establishing reputation commitment strategy requirestime cost. higher future payoffs offset cost building reputation,reputation effect prescribes minimum payoffs equilibrium strategy give player(otherwise, profitably deviate playing commitment type).Fudenberg Levine (1989) study class repeated games long-runplayer faces sequence single-shot opponents observe previous games.long-run player sufficiently patient single-shot players positive prior belieflong-run player might commitment type, authors derive lower boundpayoff received long-run player Nash equilibrium repeated game.result holds finitely infinitely repeated games, robustperturbations information structure (i.e., independent typespositive probability).Schmidt (1993) provides generalization result two long-run playercase special class games called conflicting interests, one playerssufficiently patient opponent. game conflicting interestscommitment strategy one player (A) holds opponent (B) minimax payoff.author derives upper limit number rounds B play best responsecommitment type, turn generates lower bound equilibrium payoff.detailed treatment reputation effect, reader directed work MailathSamuelson (2006).computer science information systems research, reputation information definesaggregate feedback reports past transactions. semanticsusing referring reputation provider. Reputation information encompassesunitary appreciation personal attributes provider, influences trustingdecisions clients. Depending environment, reputation two main roles: signalcapabilities provider, sanction cheating behavior (Kuwabara, 2003).Signaling reputation mechanisms allow clients learn providerscapable providing good service. systems widely used computationaltrust mechanisms. Birk (2001) Biswas, Sen, Debnath (2000) describe systemsagents use direct past experience recognize trustworthy partners. globalefficiency market clearly increased, however, time needed build reputationinformation prohibits use kind mechanisms large scale online market.number signaling reputation mechanisms also take consideration indirect reputation information, i.e., information reported peers. Schillo, Funk, Rovatsos (2000)395fiJurca & FaltingsYu Singh (2002, 2003) use social networks order obtain reputationunknown agent. Agents ask acquaintances several hops away trustworthinessunknown agent. Recommendations afterwards aggregated single measureagents reputation. class mechanisms, however intuitive, providerational participation incentives agents. Moreover, little protectionuntruthful reporting, guarantee mechanism cannot manipulatedmalicious provider order obtain higher payoffs.Truthful reporting incentives signaling reputation mechanisms describedMiller et al. (2005). Honest reports explicitly rewarded payments takeaccount value submitted report, value report submitted anotherclient (called reference reporter ). payment schemes designed based properscoring rules, mathematical functions make possible revelation private beliefs(Cooke, 1991). essence behind honest reporting incentives observationprivate information client obtains interacting provider changes belief regarding reports clients. change beliefs exploited make honestyex-ante Nash equilibrium strategy.Jurca Faltings (2006) extend result taking computational approachdesigning incentive compatible payment schemes. Instead using closed form scoringrules, compute payments using optimization problem minimizes totalbudget required reward reporters. also using several reference reports filteringmechanisms, render payment mechanisms cheaper practical.Dellarocas (2005) presents comprehensive investigation binary sanctioning reputation mechanisms. setting, providers equally capable providing high quality,however, requires costly effort. role reputation mechanism encourage cooperative behavior punishing cheating: negative feedback reduces future revenueseither excluding provider market, decreasing price providercharge future transactions. Dellarocas shows simple information structuresdecision rules lead efficient equilibria, given clients report honestly.paper builds upon mechanisms addressing reporting incentives. abstract away details underlying reputation mechanism explicit penaltyassociated negative feedback. Given high enough penalties exist, reputation mechanism (i.e., feedback aggregation trusting decision rules) pluggedscheme.group work addresses reporting incentives, mention workBraynov Sandholm (2002), Dellarocas (2002) Papaioannou Stamoulis (2005).Braynov Sandholm consider exchanges goods money prove marketagents trusted degree deserve trusted equally efficientmarket complete trustworthiness. scaling amount traded product,authors prove possible make rational sellers truthfully declaretrustworthiness. Truthful declaration ones trustworthiness eliminates needreputation mechanisms significantly reduces cost trust management. However,assumptions made trading environment (i.e. form cost functionselling price supposed smaller marginal cost) commonelectronic markets.396fiObtaining Reliable Feedback Sanctioning Reputation Mechanismse-Bay-like auctions, Goodwill Hunting mechanism (Dellarocas, 2002) providesway make sellers indifferent lying truthfully declaring quality goodoffered sale. Momentary gains losses obtained misrepresenting goods qualitylater compensated mechanism power modify announcementseller.Papaioannou Stamoulis (2005) describe incentive-compatible reputation mechanism particularly suited peer-to-peer applications. mechanism similarours, sense provider client punished submitting conflicting reports. authors experimentally show class common lying strategiessuccessfully deterred scheme. Unlike results, paper considers possibleequilibrium strategies sets bounds amount untruthful information recordedreputation mechanism.3. Settingassume online market, rational clients (she) repeatedly request service one provider (he). Every client repeatedly interacts service provider,however, successive requests client always interleaved enough requests generated clients. Transactions assumed sequential, providercapacity constraints, accepts requests.price service p monetary units, service either high (q1 )low (q0 ) quality. high quality valuable clients, utility u(q1 ) = u.Low quality utility 0, precisely distinguished high quality.round, client decide request service provider, quit marketresort outside provider completely trustworthy. outside provider alwaysdelivers high quality service, higher price p(1 + ).client decides interact online provider, issues requestprovider, pays service. provider decide exert low (e0 ) high(e1 ) effort treating request. Low effort normalized cost 0, generateslow quality. High effort expensive (normalized cost equals c(e1 ) = c) generateshigh quality probability < 1. fixed, depends environmental factorsoutside control provider. p > c, individually rational providersexert effort.exerting effort, provider observe quality resulting service.decide deliver service is, acknowledge failure roll backtransaction fully reimbursing3 client. assume perfect delivery channels,client perceives exactly quality provider. delivery, clientinspects quality service, accuse low quality submitting negative reportreputation mechanism.reputation mechanism (RM) unique market, trusted participants.oversee monetary transactions (i.e., payments made clients provider)impose fines parties. However, RM observe effort levelexerted provider, know quality delivered service.3. reality, provider might also pay penalty rolling back transaction. long penaltysmall, qualitative results present paper remain valid.397fiJurca & FaltingsRM asks feedback client chose transact providercurrent round (i.e., paid price service provider) provider deliveredservice (i.e., provider reimburse client). client submits negativefeedback, RM punishes client provider: client must pay fine ,provider accumulates negative reputation report.3.1 ExamplesAlthough simplistic, model retains main characteristics several interesting applications. delivery service perishable goods (goods lose value past certaindeadline) one them. Pizza, example, must delivered within 30 minutes, otherwise gets cold loses taste. Hungry clients order home, driveexpensive local restaurant, theyre sure get hot pizza. price homedelivered pizza p = 1, restaurant, pizza would cost p(1 + ) = 1.2.cases, utility warm meal u = 2.pizza delivery provider must exert costly effort deliver orders within deadline.courier must dispatched immediately (high effort), estimated cost c = 0.8.action usually results good service (the probability timely delivery= 99%), traffic conditions unexpected accidents (e.g., address easily found)may still delay deliveries past deadline.destination, delivery person, well client, know deliverylate not. common practice, provider acknowledge late,reimburse client. Clients may provide feedback reputation mechanism,feedback counts reimbursed. clients fine submitting negativereport set example = 0.01. future loss provider causednegative report (and quantified ) depends reputation mechanism.simplified market car garagists plumbers could fit model. providercommissioned repair car (respectively plumbing) quality workdepends exerted effort. High effort costly ensures lasting resulthigh probability. Low effort cheap, resulting fix temporary.cases, however, warranty convention may specify right client askreimbursement problems reoccur within warranty period. Reputation feedback maysubmitted end warranty period, accepted reimbursementsdidnt occur.interesting emerging application comes new generation web servicesoptimally decide treat every request. service types, high qualityresponse requires exclusive use costly resources. example, computation jobsrequire CPU time, storage requests need disk space, information requests need queriesdatabases. Sufficient resources, prerequisite, guarantee good service.Software hardware failures may occur, however, failures properly signaledprovider. monetary incentives become sufficiently important markets,intelligent providers identify moral hazard problem, may act strategicallyidentified model.398fiObtaining Reliable Feedback Sanctioning Reputation Mechanisms4. Behavior Reporting Incentivesgame theoretic point view, one interaction client providermodeled extensive-form game (G) imperfect public information, shownFigure 1. client moves first decides (at node 1) whether play interactprovider, play resort trusted outside option.client plays in, provider chose node 2 whether exert highlow effort (i.e., plays e1 e0 respectively). provider plays e0 generatedquality low. provider plays e1 , nature chooses high quality (q1 )probability , low quality (q0 ) probability 1 . constant assumedcommon knowledge market. seen resulting quality, provider delivers(i.e., plays d) service, acknowledges low quality rolls back transaction (i.e.,plays l) fully reimbursing client. service delivered, client reportpositive (1) negative (0) feedback.pure strategy deterministic mapping describing action playersinformation sets. client three information sets game G. first informationset singleton contains node 1 beginning game client mustdecide playing out. second information set contains nodes 7 8(the dotted oval Figure 1) client must decide reporting 0 1, givenreceived low quality, q0 . third information set singleton containsnode 9 client must decide reporting 0 1, given received highquality, q1 . strategy in0q0 1q1 , example, honest reporting strategy, specifyingclient enters game, reports 0 receives low quality, reports 1receives high quality. set pure strategies client is:AC = {out1q0 1q1 , out1q0 0q1 , out0q0 1q1 , out0q0 0q1 , in1q0 1q1 , in1q0 0q1 , in0q0 1q1 , in1q0 1q1 };Similarly, set pure strategies provider is:AP = {e0 l, e0 d, e1 lq0 lq1 , e1 lq0 dq1 , e1 dq0 lq1 , e1 dq0 dq1 };e1 lq0 dq1 , example, socially desired strategy: provider exerts effortnode 2, acknowledges low quality node 5, delivers high quality node 6. purestrategy profile pair (sC , sP ) sC AC sP AP . (A) denotes setprobability distributions elements A, C (AC ) P (AP ) mixedstrategies client, respectively provider, = (C , P ) mixed strategyprofile.payoffs playersdepend chosen strategy profile, movenature. Let g() = gC (), gP () denote pair expected payoffs receivedclient, respectively provider playing strategy profile . function g :(AC ) (AP ) R2 characterized Table 1 also describs normal formtransformation G. Besides corresponding payments made clientprovider, Table 1 also reflects influence reputation mechanism,explained Section 4.1. four strategies client involve playing node 1generate outcomes, therefore, collapsed simplicity singlerow Table 1.399fiJurca & FaltingsClient1Provider2e0u-p(1+r)0e1Nature3q04ProviderProviderlq156ProviderllClient7000-p-ep-eClient1890-pp0-c1-p-ep-c-e-pp-c0u-p-ep-c-e0-c1u-pp-cFigure 1: game representing one interaction. Empty circles represent decision nodes,edge labels represent actions, full circles represent terminal nodes dottedoval represents information set. Payoffs represented rectangles, toprow describes payoff client, second row describes payoffprovider.4.1 Reputation Mechanismevery interaction, reputation mechanism records one three different signalsmay receive: positive feedback client reports 1, negative feedback clientreports 0, neutral feedback provider rolls back transaction reimbursesclient. Figure 1 (and Table 1) positive neutral feedback influencepayoff provider, negative feedback imposes punishment equivalent .Two considerations made us choose representation. First, associate neutralpositive feedback reward (0 case) intuitively, acknowledgement failure may also regarded honest behavior behalf provider.Failures occur despite best effort, acknowledging them, provider shouldnt suffer.However, neutral feedback may also result provider exert effort.lack punishment instances contradicts goal reputation mechanism400fiObtaining Reliable Feedback Sanctioning Reputation Mechanismsin1q0 1q1Providere0 le0e1 lq0 lq1e1 lq0 dq1e1 dq0 lq1e1 dq0 dq1Clientin0q0 1q1in1q0 0q100000pppp0pp0c0pp0cin0q0 0q100cu p(1 + )0u p(1 + )00cu p(1 + )0(u p)(u p )(u p)(u p )p c(1 )p(p ) c(1 )pp c(1 )(p + )(p ) c(1 )(p + )0(1 )p cu p(1 )p c(u ) p(1)(p )cu(1)p(1)(p )cu p0pcp cp (1 ) cp c0u p(1 + )u p(1 + )u p(1 + )Table 1: Normal transformation extensive form game, Gencourage exertion effort. Fortunately, action e0 l result rational behaviortwo circumstances, excusable: one, provider defendsmalicious client expected falsely report negative feedback (details Section6), two, environmental noise big ( small) justify exertioneffort. Neutral feedback used estimate parameter , detect coalitionsmalicious clients, indirectly, may influence revenue provider. However,simplified model presented above, positive neutral feedback consideredterms generated payoffs.second argument relates role RM constrain revenueprovider depending feedback client. several ways that.Dellarocas (2005) describes two principles, two mechanisms punish providerclients submit negative reports. first, works exclusion. negativereport reputation mechanism bans provider market probability .probability tuned provider incentive cooperate almosttime, market stays efficient. second works changing conditionsfuture trade. Every negative report triggers decrease price next N clientspay service. lower values N price decrease higher, nonetheless, Ntake value efficient market.mechanisms work future losses offset momentary gain providerwould intentionally cheating client. Note penalties givenendogenously lost future opportunities, require minimum premiums trustedproviders. margins high enough, providers care enough futuretransactions, use present opportunity cheating.Another option use exogenous penalties cheating. example, providermay required buy licence operating market4 . licence partiallydestroyed every negative feedback. Totaly destroyed licences must restorednew payment, remaining parts sold provider quits market.price licence amount destroyed negative feedback scaled4. reputation mechanism buy sell market licences401fiJurca & Faltingsrational providers incentive cooperate. Unlike previous solutions,mechanism require minimum transaction margins punishments negativefeedback directly subtracted upfront deposit.One way another, reputation mechanisms foster cooperation providerassociates value client feedback. Let V (R+ ) V (R ) value positive, respectively negative report. game Figure 1, V (R+ ) normalized 0, V (R ). using notation, abstract away details reputation mechanism,retain essential punishment associated negative feedback. reputation mechanism plugged scheme, long particular constraints (e.g.,minimum margins transactions) satisfied.One last aspect considered influence reputation mechanismfuture transactions client. negative reports attract lower prices, rational long-runclients might tempted falsely report order purchase cheaper services future.Fortunately, mechanisms designed single-run clients, influencereporting strategy long-run clients. reputation mechanism keeps lastN reports (Dellarocas, 2005) one them. false negative report influencesnext N transactions provider; given N requests interleavedtwo successive requests client, dishonest reporter cannot decreaseprice future transactions.licence-based mechanism described another example. priceservice remains unchanged, therefore reporting incentives unaffected.hand, negative feedback punished exclusion, clients may reluctantreport negatively, since also lose trading partner.4.2 Analysis Equilibriaone-time game presented Figure 1 one subgame equilibrium clientopts out. asked report feedback, client always prefers report 1 (reporting0 attracts penalty ). Knowing this, best strategy provider exert loweffort deliver service. Knowing provider play e0 d, strictly betterclient play out.repeated game client provider may, however,equilibria. analyzing repeated game, let us note every interactionprovider particular client strategically isolated considered independently.provider accepts clients views identically, maximize expectedrevenue isolated repeated games.on, consider repeated interaction providerone client. modeled -fold repetition stage game G, denoted GT ,finite infinite. paper deal infinite horizon case, however,results obtained also applied minor modifications finitely repeated gameslarge enough.per period discount factor reflecting probability market ceasesexist round, (or present value future revenues), let us denoteexpected discount factor game GT . client interacts provideraverage every N rounds, = N .402fiObtaining Reliable Feedback Sanctioning Reputation Mechanismslife-time expected payoff players computed as:Xgi ;=0{C, P } client, respectively provider, gi expected payoff obtainedplayer th interaction, discount applied compute present dayvalue gi .consider normalized life-time expected payoffs, payoffs G GTexpressed using measure:XVi = (1 )gi ;(1)=0define average continuation payoff player period onward (and including period t) as:Vit = (1 )Xgi ;(2)=tset outcomes publicly perceived players round is:= {out, l, q0 1, q0 0, q1 1, q1 0}where:observed client opts out,l observed provider acknowledges low quality rolls back transaction,qi j observed provider delivers quality qi {q0 , q1 } client reportsj {0, 1}.denote ht specific public history repeated game set H = (Y )tpossible histories including period t. repeated game, public strategyplayer sequence maps (it ), : H t1 (Ai ) prescribes (mixed)strategy played round t, public history ht1 H t1 . perfect publicequilibrium (PPE) profile public strategies = (C , P ) that, beginning timegiven public history ht1 , form Nash equilibrium point (Fudenberg,Levine, & Maskin, 1994). Vit () continuation payoff player given strategyprofile .G game product structure since public outcome expressed vectortwo components (yC , yP ) distribution yi depends actionsplayer {C, P }, client, respectively provider. games, Fudenberg et al.(1994) establish Folk Theorem proving feasible, individually rational payoffprofile achievable PPE G discount factor close enough 1. setfeasible, individually rational payoff profiles characterized by:minimax payoff client, obtained option out: VC = u p(1 + );403fiJurca & FaltingsVC(in1q01q1 ; e 1lq0d q1 )(u -p)(in1q01q1; e 1dq0d q1 )u-ppareto optimalfrontieru -p(1+)0p-cp-cVPpVP-p(in1q01q1; e 0d)Figure 2: pareto-optimal frontier set feasible, individually rational payoffprofiles G.minimax payoff provider, obtained provider plays e0 l: VP = 0;pareto optimal frontier (graphically presented Figure 2) delimitedpayoffs given (linear combination of) strategy profiles (in1q0 1q1 , e1 lq0 dq1 ),(in1q0 1q1 , e1 dq0 dq1 ) (in1q0 1q1 , e0 d).contains one point (i.e., payoff client plays out) (up) >u p(1 + ) p c > 0. conditions impose restrictions minimum margingenerated transaction interaction profitable. PPE payoff profilegives provider maximum payoff (VC , VP ) where:(VP =u c u + p(1 + )p + c(pu)>uu(1)pu(1)pVC defined above.completely characterizing set PPE payoffs discount factors strictlysmaller 1 outside scope paper, let us note following results:First, discount factor high enough (but strictly less 1) respectprofit margin obtained provider one interaction, least one PPEreputation mechanism records honest reports. Moreover, equilibriumpareto-optimal.Proposition 1 >pp(1+)c ,strategy profile:provider always exerts high effort, delivers high quality; clientdeviates equilibrium , provider switches e0 rest rounds;404fiObtaining Reliable Feedback Sanctioning Reputation Mechanismsclient always reports 1 asked submit feedback; provider deviates,(i.e., receives low quality), client switches rest rounds.pareto-optimal PPE.Proof. profitable client deviate equilibrium path. Reporting0 attracts penalty present round, termination interactionprovider (the provider stops exerting effort round onwards).provider, hand, momentarily gain deviating e1 dq0 dq1 e0 d.deviation e1 dq0 dq1 gives expected momentary gain p(1 ) expectedcontinuation loss (1 )(p c). deviation e0 brings expected momentarygain equal (1 )p + c expected continuation loss p c. discountfactor satisfying hypothesis, deviations profitable. discount factorlow enough respect profit margins, future revenues givenequilibrium strategy offset momentary gains obtained deviating.equilibrium payoff profile (VC , VP ) = ((u p), p c), pareto-optimalsocially efficient.Second, prove client never reports negative feedback paretooptimal PPE, regardless value discount factor. restriction pareto-optimaljustifiable practical reasons: assuming client provider somehownegotiate equilibrium going play, makes sense choose onepareto-optimal equilibria.Proposition 2 probability client reports negative feedback equilibriumpath pareto-optimal PPE strategy zero.Sketch Proof. full proof presented Appendix follows following steps.Step 1, equilibrium payoffs expressed adding present round payoffdiscounted continuation payoff next round onward. Step 2, take PPE payoffprofile V = (VC , VP ), PPE payoff profile V 0 = (VC0 , VP )VC < VC0 . client never reports negative feedback first round equilibriumgives V . Step 3, equilibrium continuation payoff first round also satisfiesconditions set V . Hence, probability client reports negative feedbackequilibrium path gives V 0. Pareto-optimal PPE payoff profiles clearly satisfydefinition V , hence result proposition.third result want mention here, upper boundpercentage false reports recorded reputation mechanism paretooptimal equilibria.Proposition 3 upper bound percentage false reports recorded reputation mechanism PPE equilibrium is:((1)(pu)+pppu405p u(1 );p > u(1 )(3)fiJurca & FaltingsSketch Proof. full proof presented Appendix B builds directly resultProposition 2. Since clients never report negative feedback along pareto-optimal equilibria,false reports recorded reputation mechanism appear providerdelivers low quality, client reports positive feedback. However, PPE profilemust give client least VC = u p(1 + ), otherwise client better resortingoutside option. Every round provider deliberatively delivers low qualitygives client payoff strictly smaller u p(1 + ). equilibrium payoff greaterVC therefore possible percentage rounds provider deliverslow quality bounded. bound limits percentage false reports recordedreputation mechanism.intuitive understanding results presented section, let us referpizza delivery example detailed Section 3.1. price home delivered pizzap = 1, local restaurant pizza would cost p(1 + ) = 1.2. utilitywarm pizza client u = 2, cost delivery c = 0.8 probabilityunexpected traffic conditions delay delivery beyond 30 minutes deadline (despitebest effort provider) 1 = 0.01.client secure minimax payoff VC = u p(1 + ) = 0.8 always goingrestaurant. However, socially desired equilibrium happens clientorders pizza home, pizza service exerts effort deliver pizza time:case payoff client VC = (u p) = 0.99, payoff providerVP = p c = 0.19.Proposition 1 gives lower bound discount factor pizza delivery servicerepeated clients expect socially desired equilibrium. bound =pp(1+)c = 0.84; assuming daily discount factor pizza service = 0.996,client must order pizza home least every 6 weeks. valuesdiscount factors also interpreted terms minimum number roundsclient (and provider) likely play game. example, discount factorviewed probability client (respectively provider) live anotherinteraction market. follows average lifetime provider least1/(1 ) = 250 interactions (with clients), average lifetime clientleast 1/(1 ) = 7 interactions (with pizza delivery service). clearlyrealistic numbers.Proposition 3 gives upper bound percentage false reports mechanism may record equilibrium clients. u(1 ) = 0.02 < 0.2 = p, limitis:=p= 0.1;ufollows least 90% reports recorded mechanism (in equilibrium)correct. false reports (false positive reports) result rare cases pizzadelivery intentionally delayed save cost clients complain. falsereport justified, example, providers threat refuse future ordersclients complain. Given late deliveries still rare enough, clients betterhome delivery restaurant, hence accept threat.options become available clients (e.g., competing delivery services) bounddecrease.406fiObtaining Reliable Feedback Sanctioning Reputation MechanismsPlease note upper bound defined Proposition 3 depends outsidealternative available provider, influenced punishment introducedreputation mechanism. happens revenue client independentinteractions clients, therefore, reputation information reportedclients. Equilibrium strategies exclusively based direct experienceclient. following section, however, refine bound consideringclients build reputation reporting honestly. There, punishment playsimportant role.5. Building Reputation Truthful Reportingimmediate consequence Propositions 2 3 provider extractsurplus created transactions occasionally delivering low quality, convincingclients report negative feedback (providers promising sufficiently highcontinuation payoffs prevent client resort outside provider). Assumingprovider power market, could influence choiceequilibrium strategy one gives revenue, holds clients closeminimax payoff VC = u p(1 + ) given outside option.5However, client could commit report honestly, (i.e., commit play strategysC = in0q0 1q1 ) would benefit cooperative trade. providers best responsesC play e1 lq0 dq1 repeatedly, leads game socially efficient outcome.Unfortunately commitment sC credible complete information game,reasons explained Section 4.2.Following results Kreps et al. (1982), Fudenberg Levine (1989) Schmidt(1993) know honest reporting commitments may become credible gameincomplete information. Suppose provider incomplete information G ,believes non-negative probability facing committed client alwaysreports truth. rational client fake committed client, buildreputation reporting honestly. reputation becomes credible, providerplay e1 lq0 dq1 (the best response sC ), better clientpayoff would obtain provider knew rational type.effect reputation building, set equilibrium points reduced setpayoff client higher payoff obtained client committedreport honestly. anticipated Proposition 3, smaller set equilibrium points alsoreduces bound false reports recorded reputation mechanism. certain cases,bound reduced almost zero.Formally, incomplete information modeled perturbation completeinformation repeated game G period 0 (before first round gameplayed) type client drawn nature countable set accordingprobability measure . clients payoff additionally depends type.5. pareto-optimal PPE payoff profiles also renegotiation-proof (Bernheim & Ray, 1989; Farrell &Maskin, 1989). follows proof Proposition 3: continuation payoffs enforcing paretooptimal PPE payoff profile also pareto-optimal. Therefore, clients falsely report positive feedbackeven restrictive notion negotiation-proof equilibrium.407fiJurca & Faltingssay perturbed game G () provider incomplete informationsure true type client.Two types particular importance:normal type client, denoted 0 , rational clientpayoffs presented Figure 1.commitment type client, denoted , always prefers play commitment strategy sC . rational perspective, commitment type client obtainsarbitrarily high supplementary reward reporting truth. external reward makes strategy sC dominant strategy, therefore, commitmenttype client play anything else sC .Theorem 1 give upper bound kP number times provider deliverslow quality G (), given always observes client reporting honestly.intuition behind result following. providers best responsehonest reporter e1 lq0 dq1 : always exert high effort, deliver qualityhigh. gives commitment type client maximum attainable payoff G (),corresponding socially efficient outcome. provider, however, would betterplaying normal type client, obtain expected payoffgreater p c.normal type client may distinguished commitment type clientrounds provider delivers low quality: commitment type always reportsnegative feedback, normal type might decide report positive feedback orderavoid penalty . provider therefore decide deliver low quality clientorder test real type. question is, many times provider testtrue type client.Every failed test (i.e., provider delivers low quality client reports negativefeedback) generates loss provider, slightly enforces beliefclient reports honestly. Since provider cannot wait infinitely future payoffs,must time provider stop testing type provider, acceptsplay socially efficient strategy, e1 lq0 dq1 .switch socially efficient strategy triggered revelation clientstype. provider believes client behaves commitment type,client commitment type. client may well normal typechooses mimic commitment type, hope obtain better serviceprovider. However, trying determine true type client costlyprovider. Therefore, provider chooses play e1 lq0 dq1 , best responsecommitment strategy sC .Theorem 1 provider incomplete information G , assigns positive probability normal commitment type client ((0 ) > 0, 0 = ( ) > 0),finite upper bound, kP , number times provider delivers low qualityequilibrium G (). upper bound is:kP =ln(0 )P p+c)+(1)pln (V(VP p+c)+(1)408(4)fiObtaining Reliable Feedback Sanctioning Reputation MechanismsProof. First, use important result obtained Fudenberg Levine (1989)statistical inference (Lemma 1): every previously delivered low quality service sanctioned negative report, provider must expect increasing probabilitynext low quality delivery also sanctioned negative feedback. Technically,< 1, provider deliver n() low quality services (sanctioned negativefeedback) expecting n() + 1 low quality delivery also sanctionednegative feedback probability greater . number equals to:lnn() =;lnstated earlier, lemma prove provider become convincedfacing commitment type client. simply proves finite numberrounds provider becomes convinced client playing commitmenttype.VPSecond, > V +(1)strictly smaller 1, rational providerPdeliver low quality (it easy verify maximum discounted future gaincompensate risk getting negative feedback present round).previously mentioned lemma, must equilibrium, provider delivers lowquality finite number times.Third, let us analyze round, t, provider deliver low qualityservice (play dq0 ) last time. belief provider client reportshonestly round t, expected payoff (just deciding deliver low qualityservice) computed follows:probability client reports 0. reputation reporting honestly becomescredible, provider plays e1 lq0 dq1 subsequent rounds. provider gainsp current round, expects p c subsequent rounds;probability 1, client reports 1 deviates commitment strategy,provider knows facing rational client, choose continuation PPEstrategy complete information game. gains p current round,expects VP subsequent rounds;VP (1 )(p ) + ((p c) + (1 )VP )hand, provider acknowledged low quality rolled backtransaction (i.e., play lq0 ), expected payoff would least:VP0 (1 )0 + (p c)Since provider chooses nonetheless play dq0 must VP VP0equivalent to:=(VP p + c) + (1 )p(VP p + c) + (1 )409(5)fiJurca & FaltingsFinally, replacing Equation (5) definition n() obtain upper boundnumber times provider delivers low quality service client committedreport honestly.existence kP reduces possible equilibrium payoffs client getG (). Consider rational client receives first time low quality.following options:report negative feedback attempt build reputation reporting honestly.payoff current round p . Moreover, worst case expectationfuture next kP 1 rounds also give p , followedcommitment payoff equal (u p):VC |0 = (1 )(p ) + (1 kP 1 )(p ) + kP (u p);(6)hand, reporting positive feedback reveals normal type,loses p current round, expects continuation payoff equal VC givenPPE strategy profile complete information game G :VC |1 = (1 )(p) + VC ;(7)reputation mechanism records false reports clients incentive build reputation reporting honestly, VC |1 > VC |0; true for:VC > kP 1 (u p) (1 kP 1 )(p + )1;Following argument Proposition 3 obtain bound percentagefalse reports recorded reputation mechanism pareto-optimal PPE givesclient least VC :(=(up)VCpupVCuVC u p;VC < u p(8)particular importance case kP = 1. VC become:VC = (u p)1;=(1 );p(9)probability recording false report (after first one) arbitrarily close0 0.pizza delivery example introduced Section 3.1, Figure 3 plots bound, kP ,defined Theorem 1, function prior belief (0 ) provider clienthonest reporter. used value discount factor equal = 0.95,average, every client interacts 1/(1 ) = 20 times provider.penalty negative feedback taken = 2.5. provider believes 20%410fiObtaining Reliable Feedback Sanctioning Reputation Mechanisms10987kP65432100.10.20.30.40.50.60.70Figure 3: upper bound kP function prior belief 0 .clients always report honestly, deliver 3 times low quality.belief goes 0 = 40% rational provider deliver low quality once.Figure 4 plot values bounds (Equation (3)) (Equation (8))function prior belief 0 . bounds simultaneously hold, therefore maximumpercentage false reports recorded reputation mechanism minimumtwo. 0 less 0.25, kP 2, , reputation effect significantlyreduce worst case percentage false reports recorded mechanism. However,0 (0.25, 0.4) reputation mechanism records (in worst case) half many falsereports, 0 > 0.4, percentage false reports drops 0.005. probabilitydecreased decreasing penalty . limit, approaches 0,reputation mechanism register false report vanishing probability.result Theorem 1 interpreted worst case scenario. real markets,providers already small predisposition cooperate defect fewer times.Moreover, mechanism self enforcing, sense clients act commitment types, higher prior beliefs providers new, unknown clientsreport truthfully, therefore easier new clients act truthfulreporters.mentioned end Section 4.2, bound strongly depends punishmentimposed reputation mechanism negative feedback. higher , easierclients build reputation, therefore, lower amount false informationrecorded reputation mechanism.6. Threat Malicious Clientsmechanism described far encourages service providers best delivergood service. clients assumed rational, committed report honestly,411fiJurca & Faltings0.4min(, )0.350.3,0.250.20.150.10.05000.10.20.30.40.50.60.70Figure 4: maximum probability recording false report function priorbelief 0 .either case, never report negative feedback unfairly. section, investigatehappens clients explicitly try hurt providers submitting fake negativeratings reputation mechanism.immediate consequence fake negative reports clients lose money. However,costs negative report would probably small deter clients separate agendas hurting provider. Fortunately, mechanism propose naturallyprotects service providers consistent attacks initiated malicious clients.Formally, malicious type client, , obtains supplementary (external) payoffreporting negative feedback. Obviously, greater penalty , otherwiseresults Proposition 2 would apply. incomplete information game G (),provider assigns non-zero initial probability belief client malicious.normal type, 0 , honest reporter type malicious typenon-zero initial probability, mechanism describe robust unfairnegative reports. first false negative report exposes client malicious, sinceneither normal, commitment type report 0 receiving high quality.Bayes Law, providers updated belief following false negative report must assignprobability 1 malicious type. Although providers allowed refuse servicerequests, protect malicious clients playing e0 l: i.e., exertlow effort reimburse client afterwards. RM records neutral feedbackcase, sanction provider. e0 l, malicious clients betterquitting market (opt out), thus stopping attack. RM records one falsenegative report every malicious client, assuming identity changes difficult,providers vulnerable unfair punishments.412fiObtaining Reliable Feedback Sanctioning Reputation Mechanismstypes (besides 0 , ) non-zero initial probability, maliciousclients harder detect. could masquerade client types normal,accidentally misreport. rational provider immediately exclude (by playinge0 l) normal clients rarely misreport: majority cooperative transactionsrewarded positive feedback still generate positive payoffs. Let us considerclient type 0 () behaves exactly like normal type, misreports 0 instead1 independently probability . interacting client type 0 (),provider receives maximum number unfair negative reports playing efficientequilibrium: i.e., e1 lq0 dq1 . case, providers expected payoff is:VP = p c ;Since VP positive (the minimax payoff provider 0, given e0 l), mustpc.maximum value also good approximation maximum percentagefalse negative reports malicious type submit reputation mechanism.significantly higher number harmful reports exposes malicious type allowsprovider defend himself.Note, however, malicious type submit fraction false reportstype 0 () positive prior probability. provider believenormal client make many mistakes (even percentage false reports stilllow enough generate positive revenues) attributes false reports malicious type,disengages cooperative behavior. Therefore, one method reduce impactmalicious clients make sure normal clients make mistakes. Technicalmeans (for example providing automated tools formatting submitting feedback),improved user interfaces (that make easier human users spot reporting mistakes)greatly limit percentage mistakes made normal clients, therefore, alsoreduce amount harm done malicious clients.One concrete method reducing mistakes solicit negative feedbackclients (the principle news good news, also applied Dellarocas (2005)).reporting involves conscious decision, mistakes less frequent.hand, reporting effort add penalty negative report, makes hardernormal clients establish reputation honest reporters. Alternative methodsreducing harm done malicious clients (like filtering mechanisms, etc., ) welltighter bounds percentage false reports introduced clientsaddressed future work.7. Discussion Future Workbenefits obtained clients reputation reporting honestly sharedwithin market. reports submitted client interacting providerschange initial beliefs new provider. seen Section 5, providerscheat less priory expect higher probability encounter honest reportingclients. client built reputation truthfully reporting providersbehavior benefit cooperative trade entire lifetime, withoutconvince provider separately. Therefore upper bound loss clientwithstand order convince provider commitment type, becomes upper413fiJurca & Faltingsbound total loss client withstand entire lifetime market.effectively share reputation clients within market remains open issue.Correlated idea observation clients use mechanismmotivated keep identity. generalized markets agents encouragedplay roles (e.g. peer-2-peer file sharing market fact agent actsprovider interpreted strong indication double identityintention cheating) mechanism also solves problem signaled FriedmanResnick (2001) related cheap online pseudonyms. price pay new identityloss due building reputation truthful reporter acting client.Unlike incentive-compatible mechanism pay reporters depending feedbackprovided peers, mechanism described less vulnerable collusion.reason individual clients would collude badmouth (i.e., artificially decrease reputation of) provider. However, long punishment negative feedbacksuper-linear number reports (this usually case), coordinating within coalition brings benefits colluders: individual actions effective actionspart coalition. collusion provider client accelerate synchronization strategies one PPE profiles (collusion non-PPEstrategy profile stable), rather desirable. profitable collusionhappen competitor providers incentivize normal clients unfairly downratecurrent provider. Colluding clients become malicious case, limitsharm presented Section 6.mechanism describe general solution online markets.general retail e-commerce, clients dont usually interact service provideronce. showed along paper, assumption repeated interactioncrucial results. Nevertheless, believe several scenarios practicalimportance meet requirements (e.g., interactions part supply chain).these, mechanism used conjunction reputation mechanismsguarantee reliable feedback improve overall efficiency market.mechanism criticized centralized. reputation mechanism acts central authority supervising monetary transactions, collecting feedbackimposing penalties participants. However, see problem implementingreputation mechanism distributed system. Different providers use differentreputation mechanisms, or, even switch mechanisms given safeguarding measures place. Concrete implementations remain addressed future work.Although present setting service always costs amount,results easily extended scenarios provider may deliver different kindsservices, different prices. long provider believes requestsrandomly drawn distribution, bounds presented computedusing average values u, p c. constraint providers belief necessaryorder exclude unlikely situations provider cheats one time highvalue transaction, knowing following interactions carry little revenue, therefore,cannot impose effective punishments.paper, systematically overestimate bounds worst case percentagefalse reports recorded mechanism. computation tight bounds requiresprecise quantitative description actual set PPE payoffs client provider414fiObtaining Reliable Feedback Sanctioning Reputation MechanismsG . Fudenberg et al. (1994) Abreu, Pearce, Stacchetti (1990) posetheoretical grounds computing set PPE payoffs infinitely repeated gamediscount factors strictly smaller 1. However, efficient algorithms allow usfind set still open question. research domain progresses, expectable significantly lower upper bounds described Sections 4 5.One direction future research study behavior mechanismtwo-sided incomplete information: i.e. client also uncertain typeprovider. provider type particular importance greedy type alwayslikes keep client continuation payoff arbitrarily close minimal one.situation expect able find upper bound kC number roundsrational client would willing test true type provider. condition kP < kCdescribes constraints parameters system reputation effectwork favor client: i.e. provider give first psychologicalwar revert cooperative equilibrium.problem involuntary reporting mistakes briefly mentioned Section 6 needsaddressing. Besides false negative mistakes (reporting 0 instead 1), normal clientsalso make false positive mistakes (report 1 instead intended 0). presentframework, one mistake enough ro ruin reputation normal type clientreport honestly. one reasons chose sequential modelfeedback client required provider acknowledges low quality.reputation client becomes credible, provider always rolls back transactionsgenerate (accidentally not) low quality, client required continuously defendreputation. Nevertheless, consequences reporting mistakes reputationbuilding phase must considered detail. Similarly, mistakes made provider,monitoring communication errors also influence results presented here.Last, least, practical implementations mechanism propose mustaddress problem persistent online identities. One possible attack created easyidentity changes mentioned Section 6: malicious buyers continuously changeidentity order discredit provider. another attack, provider use fakeidentities increase revenue. punishments negative feedback generatedendogenously decreased prices fixed number future transactions (e.g., Dellarocas,2005), provider adopt following strategy: cheats real customers,generates sufficient number fake transactions two real transactions,effect created real negative report disappears. easy fix latterattack charge transaction entrance fees. However, measures also affectoverall efficiency market, therefore, different applications likely needindividual solutions.8. ConclusionsEffective reputation mechanisms must provide appropriate incentives order obtainhonest feedback self-interested clients. environments characterized adverseselection, direct payments explicitly reward honest information conditioningamount paid information reported peers. technique unfortunately work service providers moral hazard, individually415fiJurca & Faltingsdecide requests satisfy. Sanctioning reputation mechanisms must therefore usemechanisms obtain reliable feedback.paper describe incentive-compatible reputation mechanism clientsalso repeated presence market. asking feedback clients,allow provider acknowledge failures reimburse price paid service.future transactions generate sufficient profit, prove equilibriumprovider behaves socially desired: always exerts effort, reimburses clientsoccasionally receive bad service due uncontrollable factors. Moreover, analyzeset pareto-optimal equilibria mechanism, establish limit maximumamount false information recorded mechanism. bound dependsexternal alternatives available clients ease commitreporting truth.Appendix A. Proof Proposition 2probability client reports negative feedback equilibrium pathpareto-optimal PPE strategy zero.Proof.Step 1. Following principle dynamic programming (Abreu et al., 1990), payoffprofile V = (VC , VP ) PPE G , strategy profile G,continuation PPE payoffs profiles {W (y)|y } G , that:V obtained playing current round, PPE strategy gives W (y)continuation payoff, public outcome current round,P r[y|] probability observing playing :VC = (1 )gC () +XyYVP = (1 )gP () +XP r[y|] WC (y) ;P r[y|] WP (y) ;yYplayer finds profitable deviate :X00VC (1 )gC (C, P ) +P r y|(C, P ) WC (y) ;0C6= CyYXVP (1 )gP (C , P0 ) +P r y|(C , P0 ) WP (y) ;P0 6= PyYstrategy payoff profiles {W (y)|y } said enforce V .Step 2. Take PPE payoff profile V = (VC , VP ), PPEpayoff profile V 0 = (VC0 , VP ) VC < VC0 . Let {W (y)|y } enforce V , assumeassigns positive probability 0 = P r[q0 0|] > 0 outcome q0 0. 1 = P r[q0 1|](possibly equal 0), let us consider:0 , ) 0 obtained asking clientstrategy profile 0 = (CPCCreport 1 instead 0 receives low quality (i.e., q0 );416fiObtaining Reliable Feedback Sanctioning Reputation Mechanismscontinuation payoffs {W 0 (y)|y } Wi0 (q0 1) = 0 Wi (q0 0) + 1 Wi (q0 1)Wi0 (y 6= q0 1) = Wi (y) {C, P }. Since, set correlated PPE payoffprofiles G convex, W (y) PPE payoff profiles, W 0 (y).payoff profile (VC0 , VP ), VC0 = VC + (1 )0 PPE equilibrium profileenforced 0 {W 0 (y)|y }. However, contradicts assumptionVC0 < VC , P r[q0 0|] must 0. Following exactly argument, proveP r[q1 0|] = 0.Step 3. Taking V , {W (y)|y } step 2, have:VC = (1 )gC () +XP r[y|] WC (y) ;(10)yYPPE payoff profile V 0 = (VC0 , VP ) VC0 > VC , mustcontinuation payoffs W (y) satisfy property. (Assume otherwisePPE (WC0 (y), WP (y)) WC0 (y) > WC (y). Replacing WC0 (y) (10) obtain V 0contradicts hypothesis).continuing recursion, obtain client never reports 0 equilibriumpath enforces payoff profile defined Step 2. Pareto-optimal payoff profiles clearlyenter category, hence result proposition.Appendix B. Proof Proposition 3upper bound percentage false reports recorded reputation mechanismPPE equilibrium is:((1)(pu)+pppup u(1 );p > u(1 )Proof. Since clients never report negative feedback along pareto-optimal equilibria,false reports recorded reputation mechanism appear providerdelivers low quality, client reports positive feedback. Let = (C , P ) paretooptimal PPE strategy profile. induces probability distribution public historiesand, therefore, expected outcomes following transactions. Letprobability distribution induced outcomes round t. (q0 0) = (q1 0) = 0proven Proposition 2. payoff received client playing therefore:VC () (1 )X(q0 1)(p) + (q1 1)(u p) + (l)0 + (out)(u p p) ;t=0(q0 1)+t (q1 1)+t (l)+t (out) = 1 (q0 1)+t (l) (1)t (q1 1)/,probability q0 least (1 )/ times probability q1 .discount factor, , probability repeated interaction stoptransaction, expected probability outcome q0 1 is:= (1 )Xt=0417(q0 1);fiJurca & FaltingsSince PPE profile must give client least VC = up(1+), (otherwise clientbetter resorting outside option), VC () VC . replacing expressionVC (), taking account constraints probability q1 obtain:(p) + (u p) min 1 , VC ;((1)(pu)+pppup u(1 );p > u(1 )ReferencesAbreu, P., Pearce, D., & Stacchetti, E. (1990). Toward Theory Discounted RepeatedGames Imperfect Monitoring. Econometrica, 58 (5), 1041 1063.Bernheim, B. D., & Ray, D. (1989). Collective Dynamic Consistency Repeated Games.Games Economic Behavior, 1, 295326.Birk, A. (2001). Learning Trust. Falcone, R., Singh, M., & Tan, Y.-H. (Eds.), TrustCyber-societies, Vol. LNAI 2246, pp. 133144. Springer-Verlag, Berlin Heidelberg.Biswas, A., Sen, S., & Debnath, S. (2000). Limiting Deception Group Social Agents.Applied Artificial Intelligence, 14, 785797.Braynov, S., & Sandholm, T. (2002). Incentive Compatible Mechanism Trust Revelation.Proceedings AAMAS, Bologna, Italy.Cooke, R. (1991). Experts Uncertainity: Opinion Subjective Probability Science.Oxford University Press: New York.Dellarocas, C. (2002). Goodwill Hunting: Economically Efficient Online Feedback.Padget, J., & et al. (Eds.), Agent-Mediated Electronic Commerce IV. Designing Mechanisms Systems, Vol. LNCS 2531, pp. 238252. Springer Verlag.Dellarocas, C. (2005). Reputation Mechanism Design Online Trading EnvironmentsPure Moral Hazard. Information Systems Research, 16 (2), 209230.Farrell, J., & Maskin, E. (1989). Renegotiation Repeated Games. Games EconomicBehavior, 1, 327360.Friedman, E., & Resnick, P. (2001). Social Cost Cheap Pseudonyms. JournalEconomics Management Strategy, 10(2), 173199.Fudenberg, D., & Levine, D. (1989). Reputation Equilibrium Selection GamesPatient Player. Econometrica, 57, 759778.Fudenberg, D., Levine, D., & Maskin, E. (1994). Folk Theorem Imperfect PublicInformation. Econometica, 62 (5), 9971039.Harmon, A. (2004). Amazon Glitch Unmasks War Reviewers. New York Times.Houser, D., & Wooders, J. (2006). Reputation Auctions: Theory EvidenceeBay. Journal Economics Management Strategy, 15, 353369.418fiObtaining Reliable Feedback Sanctioning Reputation MechanismsJurca, R., & Faltings, B. (2006). Minimum Payments Reward Honest ReputationFeedback. Proceedings ACM Conference Electronic Commerce (EC06),pp. 190199, Ann Arbor, Michigan, USA.Kreps, D. M., Milgrom, P., Roberts, J., & Wilson, R. (1982). Rational CooperationFinitely Repeated Pisoners Dilemma. Journal Economic Theory, 27, 245252.Kreps, D. M., & Wilson, R. (1982). Reputation Imperfect Information. JournalEconomic Theory, 27, 253279.Kuwabara, K. (2003). Decomposing Reputation Effects: Sanctioning Signaling?. Workingpaper.Mailath, G., & Samuelson, L. (2006). Repeated Games Reputations: Long-Run Relationships. Oxford University Press.Milgrom, P., & Roberts, J. (1982). Predation, Reputation Entry Deterrence. JournalEconomic Theory, 27, 280312.Miller, N., Resnick, P., & Zeckhauser, R. (2005). Eliciting Informative Feedback: PeerPrediction Method. Management Science, 51, 1359 1373.Papaioannou, T. G., & Stamoulis, G. D. (2005). Incentives Mechanism PromotingTruthful Feedback Peer-to-Peer Systems. Proceedings IEEE/ACM CCGRID2005.Resnick, P., & Zeckhauser, R. (2002). Trust Among Strangers Electronic Transactions:Empirical Analysis eBays Reputation System. Baye, M. (Ed.), EconomicsInternet E-Commerce, Vol. 11 Advances Applied Microeconomics.Elsevier Science, Amsterdam.Schillo, M., Funk, P., & Rovatsos, M. (2000). Using Trust Detecting Deceitful AgentsArtificial Societies. Applied Artificial Intelligence, 14, 825848.Schmidt, K. M. (1993). Reputation Equilibrium Characterization Repeated GamesConflicting Interests. Econometrica, 61, 325351.Selten, R. (1978). Chain-Store Paradox. Theory Decision, 9, 127159.Yu, B., & Singh, M. (2002). Evidential Model Distributed Reputation Management.Proceedings AAMAS, Bologna, Italy.Yu, B., & Singh, M. (2003). Detecting Deception Reputation Management. ProceedingsAAMAS, Melbourne, Australia.419fiJournal Artificial Intelligence Research 29 (2007) 221267Submitted 12/06; published 06/07Formal SemanticsSpeech-Act Based CommunicationAgent-Oriented Programming LanguageRenata Vieirarenatav@unisinos.brUniversidade Vale Rio dos SinosSao Leopoldo, RS, 93022-000, BrazilAlvaro MoreiraAlvaro.Moreira@inf.ufrgs.brUniversidade Federal Rio Grande SulPorto Alegre, RS, 91501-970, BrazilMichael Wooldridgemjw@csc.liv.ac.ukUniversity LiverpoolLiverpool L69 3BX, United KingdomRafael H. BordiniR.Bordini@durham.ac.ukUniversity DurhamDurham DH1 3LE, United KingdomAbstractResearch agent communication languages typically taken speech acts paradigmstarting point. Despite manifest attractions, speech-act models communication several serious disadvantages foundation communication artificialagent systems. particular, proved extremely difficult give satisfactorysemantics speech-act based agent communication languages. part, problemspeech-act semantics typically make reference mental states agents (theirbeliefs, desires, intentions), general way attribute attitudesarbitrary computational agents. addition, agent programming languagessemantics formalised abstract, stand-alone versions, neglecting aspectscommunication primitives. respect communication, implemented agent programming languages tended rather ad hoc. paper addressesproblems, giving semantics speech-act based messages received AgentSpeakagent. AgentSpeak logic-based agent programming language incorporatesmain features PRS model reactive planning systems. paper builds uponstructural operational semantics AgentSpeak developed previous work.main contributions paper follows: extension earlier worktheoretical foundations AgentSpeak interpreters; computationally grounded semantics(the core) performatives used speech-act based agent communication languages;well-defined extension AgentSpeak supports agent communication.1. IntroductionFirst introduced 1987, reactive planning model Georgeff Lanskys PRS system subsequently proved one influential long-lived approachesprogramming multi-agent systems (Georgeff & Lansky, 1987). AgentSpeak programming language, introduced Rao (1996), represents attempt distill key featuresc2007AI Access Foundation. rights reserved.fiVieira, Moreira, Wooldridge, & BordiniPRS approach simple, abstract, logic-based language. AgentSpeak particularly interesting, comparison agent-oriented languages, retainsimportant aspects BDI-based reactive planning systems based,time robust working interpreters (Bordini, Hubner, & Vieira, 2005;Bordini & Hubner, 2007; Bordini, Bazzan, Jannone, Basso, Vicari, & Lesser, 2002), formal semantics relation BDI logics (Rao & Georgeff, 1998; Wooldridge, 2000b)thoroughly studied (Bordini & Moreira, 2004; Moreira, Vieira, & Bordini, 2004; Moreira & Bordini, 2002), ongoing work use model-checking techniquesverification AgentSpeak multi-agent systems (Bordini, Fisher, Visser, & Wooldridge,2004; Bordini, Visser, Fisher, Pardavila, & Wooldridge, 2003; Bordini, Fisher, Pardavila, &Wooldridge, 2003).original formulation AgentSpeak (Rao, 1996), main emphasis internal control structures decision-making cycle agent: issue communicationagents addressed. Accordingly, attempts give formal semanticslanguage focused internal aspects (Moreira & Bordini, 2002). Althoughseveral extensions AgentSpeak proposed attempt make practically useful language (Bordini et al., 2005, 2002), comparatively little researchaddressed issue principled mechanism support communication AgentSpeak,clearly essential engineering multi -agent systems.agent communication languages taken speech-act theory (Austin, 1962; Searle,1969) starting point. suggested name, speech-act theory predicatedview utterances actions, performed rational agents furtherancepersonal desires intentions. Thus, according speech-act theory, utterances mayconsidered actions performed agent, typically intention changingmental state hearer(s) utterance. Speech-act theory thus seems particularly appropriate foundation communication among intentional agents.communication, agent share internal state (beliefs, desires, intentions)agents, attempt influence mental states agents.Although initial speech-act based communication model AgentSpeak agentspreviously introduced (Bordini et al., 2003), formal semantics model givenpaper. preliminary formal account communication AgentSpeak agentsfirst given Moreira et al. (2004). main contribution present paperthoroughly extend operational semantics AgentSpeak accounting speech-actstyle communication. semantics precisely defines implement processingmessages received AgentSpeak agent; is, computational representationsmental states changed message received. Note implementationsBDI architecture, concepts plan plan library used simplify aspectsdeliberation means-ends reasoning. Therefore, AgentSpeak agent sends messagewhenever communicative action body intended planexecuted; plans typically written agent programmer.pointed Singh (1998), well-known approaches agent communication focuslargely senders perspective, ignoring message processed understood. main aspect agent communication consider paper.extending operational semantics AgentSpeak account inter-agent communication, also touch upon another long-standing problem area multi-agent systems:222fiSpeech-Act Based Communication Agent Programmingsemantics communication languages based speech acts. difficulty that,taking inspiration attempts develop semantics human speech acts,semantics agent communication languages defined meaning messages agents respect mental states communication participants.arguably advantage remaining neutral actual internal structure agents,number authors observed makes impossible general determinewhether program claims implementing semantics really implementing (Wooldridge, 1998; Singh, 1998). problem semantics makesreference agent believing (or intending state satisfying) certain proposition,way ensure software using communication language compliesunderlying semantics belief (or intention, mental attitudes general).related fact previous approaches attempt give programminglanguage independent semantics agent communication. semantics, developedone specific language, advantage relying mechanismsabstractly defined mental states cannot verified real programs. note that,best knowledge, work represents first semantics given speech-actstyle, knowledge level communication language used real system.Since precise notion Belief-Desire-Intention given previouslyAgentSpeak agents (Bordini & Moreira, 2004), provide computationallygrounded (Wooldridge, 2000a) semantics speech-act based communication language, making possible determine AgentSpeak agent interprets particularmessage received. Note, however, whether agent acts uponreceived communication depends plan library circumstances timemessage processed. Also, although approach tied particular language,usefully employed reference model developing communication semanticsimplementing communication agent programming languages.remainder paper organised follows. Section 2 provides generalbackground PRS-style BDI architectures speech-act based agent communication.Section 3 presents AgentSpeak syntax semantics much revised version syntaxsemantics AgentSpeak presented Moreira Bordini (2002, 2004). Section 4presents speech-act based communication model AgentSpeak agents, extensionpreliminary formal account given Moreira et al. (2004). Section 5 illustratessemantics example semantic rules applied typical reasoning cycle.Section 6, show programmers use basic communication constructsdevelop elaborate forms communication required multi-agentapplications (for example, ensuring belief shared two agents keepingtrack progress achievement delegated goal), Section 7 givesimple example use framework proving properties communicating agents.Section 8 presents discussion applications developments languagepresented paper. Conclusions planned future work given final section.2. Backgroundability plan seems one key components rational action humans.Planning ability take goal, goal generate recipe (i.e., plan)223fiVieira, Moreira, Wooldridge, & Bordiniaction that, recipe followed (under favourable conditions), goalachieved. Accordingly, great deal research artificial intelligence addressedissue automatic planning: synthesis plans agents first principles (Allen,Hendler, & Tate, 1990). Unfortunately, planning is, like many problems artificialintelligence, prohibitively expensive computational terms. great stridesmade developing efficient automatic planning systems (Ghallab, Nau, & Traverso, 2004),inherent complexity process inevitably casts doubt whetherpossible use plan-synthesis algorithms develop plans run-time systemsmust operate tight real-time constraints. Many researchers instead consideredapproaches make use pre-compiled plans, i.e., plans developed off-line, design time.Procedural Reasoning System (PRS) Georgeff Lansky common ancestormany approaches (Georgeff & Lansky, 1987).2.1 PRS AgentSpeakone level, PRS understood simply architecture executing precompiled plans. However, control structures architecture incorporate numberfeatures together provide sophisticated environment run-time practical reasoning. First, plans may invoked effect, rather simply name (ascase conventional programming languages). Second, plans associated context,must match agents current situation order plan consideredviable option. two features mean agent may multiple potential plansend, dynamically select run-time, depending currentcircumstances. addition, plans associated triggering events, ideaplan made active occurrence event, may external internal agent. External events changes environment perceived agent;example internal event might creation new sub-goal, failureplan achieve desired effect. Thus, overall, plans may invoked goal-drivenmanner (to satisfy sub-goal created) event-driven manner.PRS architecture illustrated Figure 1. AgentSpeak language, introduced Rao(1996), represents attempt distill essential features PRS simple,unified programming language1 ; provide detailed introduction AgentSpeak below,discuss speech-act theory agent communication.2.2 Speech ActsPRS model, AgentSpeak language turn, primarily concernedinternal structure decision making, particular interplay creation(sub-)goals execution plans achieve (sub-)goals. twin issuescommunication multi-agent interaction addressed within basic architecture.raises question issues might dealt within architecture.BDI theory based philosophical literature practical reasoning (Bratman,1. name language originally introduced Rao (1996) AgentSpeak(L). paper,adopt simpler form AgentSpeak instead, use refer original languagevariants appeared literature.224fiSpeech-Act Based Communication Agent ProgrammingPlanLibraryBeliefsSensor InputAction OutputInterpreterGoalsIntentionsFigure 1: PRS architecture.1987), agent communication multi-agent systems typically based speech-acttheory, particular work Austin (1962) Searle (1969).Speech-act theory starts principle language action: rational agentmakes utterance attempt change state world, wayagent performs physical actions change state world. distinguishesspeech acts (non-speech) actions domain speech actpart world agent wishes modify performance actmostly mental state(s) hearer(s) utterance.Speech acts generally classified according illocutionary force typeutterance. natural language, illocutionary forces associated utterances (orlocutionary acts). utterance door open, example, generally informtell type action. perlocutionary force represents speaker utteranceattempting achieve performing act. making statement opendoor, perlocutionary force generally state affairs speakerhopes bring making utterance; course, actual effect utterancebeyond control speaker. Whether choose believeinform door open depends upon disposed towards you. naturallanguage, illocutionary force perlocutionary force implicit within speechact context. theory adapted agent communication, however,225fiVieira, Moreira, Wooldridge, & Bordiniillocutionary forces made explicit facilitate processing communication act.various types speech acts generally referred performatives contextagent communication.pragmatic factors related communication social roles conventions discussed literature (Levinson, 1981; Ballmer & Brennenstuhl, 1981;Singh, 1994). Illocutionary forces may require existence certain relationships speaker hearer felicitous. command, instance, requiressubordination relation individuals involved communication, whereassubordination required request.Apart illocutionary forces social roles, classifications relationsamong speech acts proposed (Levinson, 1981); example, reply followsquestion, threatening stronger warning. categories place messageslarger context multi-agent dialogue. multi-agent systems, communicative interactions seen communication protocols, turn normally relatedspecific coordination/cooperation mechanism. Contract Net (Smith, 1980), example, protocol task allocation, defined terms number constituentperformatives (such announcing bidding).2.3 Agent Communication Languages: KQML & FIPAKnowledge Query Manipulation Language (KQML), developed contextKnowledge Sharing Effort project (Genesereth & Ketchpel, 1994), first attemptdefine practical agent communication language included high level (speech-act based)communication considered distributed artificial intelligence literature. KQMLessentially knowledge-level messaging language (Labrou & Finin, 1994; Mayfield, Labrou,& Finin, 1996). KQML defines number performatives, make explicit agentsintentions sending message. example, KQML performative tell usedintention changing receivers beliefs, whereas achieve used intentionchanging receivers goals. Thus performative label KQML message explicitlyidentifies intent message sender.FIPA standard agent communication2 released 2002. standardclosely based KQML, almost identical conceptually syntactically, differing performative set certain details semantic framework (Labrou, Finin, &Peng, 1999). differences important purposes paper;refer traditional approaches semantics speech-act based inter-agent communication,reference applies equally. However, historical reasons, refer mainlyKQML richer literature found semantics.2.4 Semantics Agent Communication LanguagesPerhaps first serious attempt define semantics KQML made LabrouFinin (1994). work built pioneering work Cohen Perrault actiontheoretic semantics natural language speech acts (Cohen & Perrault, 1979). keyinsight Cohen Perraults work that, take seriously idea utterances2. http://www.fipa.org/specs/fipa00037/SC00037J.html226fiSpeech-Act Based Communication Agent Programmingaction, able apply formalism reasoning action reasoningutterances. used STRIPS-style pre- post-condition formalism definesemantics inform request speech acts (perhaps canonical examplesspeech acts), pre- post-conditions framed terms beliefs,desires, abilities conversation participants. applied Labrou FininKQML language (1994), pre- post-conditions defined mental statessender receiver KQML message sending message.description mental states, work area based Cohen Levesquestheory intention (1990a, 1990b). Agent states described mental attitudesbelief (bel), knowledge (know), desire (want), intention (intend). mentalattitudes normally propositions (i.e., symbolic representations states world)arguments. Figures 2 3 give semantics KQML performatives tell(S, R, X) (Stells R believes X true), ask (S, R, X) (S asks R R believes Xtrue), style introduced Labrou Finin (1994).Pre-conditions states R:P re(S):bel(S, X) know(S, want(R, know(R, bel(S, X))))P re(R):intend(R, know(R, bel(S, X)))Post-conditions R:P os(S):know(S, know(R, bel(S, X)))P os(R):know(R, bel(S, X))Action completion:know(R, bel(S, X))Figure 2: Semantics tell (Labrou & Finin, 1994).Pre-conditions states R:P re(S): want(S, know(S, )) know(S, intend(R, process(R, )))either bel(R, X) bel(R, X) ask-if (S, R, X)P re(R):intend(R, process(R, ))Post-conditions R S:P os(S):intend(S, know(S, ))P os(R) : know(R, want(S, know(S, )))Action completion:know(S, )Figure 3: Semantics ask-if (Labrou & Finin, 1994).227fiVieira, Moreira, Wooldridge, & Bordininoted above, one key problems (widely used) approach givingsemantics agent communication languages way determine whethersoftware component uses communication language compliessemantics. semantics makes reference mental states,general principled way attribute mental states arbitrary pieces software.true semantic approaches KQML FIPA, discussedWooldridge (1998) Singh (1998). example, consider legacy software componentwrapped agent uses KQML FIPA interoperate agents. Onecannot prove communication properties system, precise definitionlegacy system believes (or intends achieve state world where)proposition true. approach builds work Bordini Moreira (2004),presented precise definition means AgentSpeak agent believe,desire, intend certain formula; approach also adopted work modelchecking AgentSpeak (Bordini et al., 2004). consequence, able successfullymeaningfully apply speech act-style semantics communication AgentSpeak.drawback, course, approach is, formally, limited AgentSpeak agents, eventhough ideas used work semantics agent languages.3. Syntax Semantics AgentSpeakAgentSpeak programming language introduced Rao (1996). understood natural extension logic programming BDI agent architecture,provides elegant abstract framework programming BDI agents. BDI architecture is, turn, perhaps one major approaches implementation rationalpractical reasoning agents (Wooldridge, 2000b).AgentSpeak agent created specification set beliefs forming initialbelief base set plans forming plan library. agents belief base setground first-order predicates, change time represent current stateenvironment perceived agent.AgentSpeak distinguishes two types goals: achievement goals test goals. Achievement test goals predicates (as beliefs), prefixed one operators !?, respectively. Achievement goals state agent wants achieve stateworld associated predicate true; practice, see, doneexecution plan. test goal returns unification associated predicateone agents beliefs; fails unification possible. triggering eventdefines events may initiate execution plan. event internal (whensubgoal needs achieved), external (when generated belief updates resultperceiving environment). Additionally, respect model communicationpaper, external events related messages received agents.two types triggering events: related addition (+) deletion (-)mental attitudes (beliefs goals).Plans refer basic actions agent able perform environment.plan formed triggering event, denoting events plan relevant.triggering event followed conjunction belief literals representing contextplan. context must logical consequence agents current beliefs228fiSpeech-Act Based Communication Agent Programming+concert(A,V) : likes(A)!book tickets(A,V).+!book tickets(A,V) : busy(phone)?phone number(V,N);call(N);. . .;!choose seats(A,V).Figure 4: Examples AgentSpeak plans.plan applicable one plans relevant applicable chosenexecution handle particular event. remainder plan sequencebasic actions (sub-)goals agent achieve (or test) plan executed.Figure 4 shows examples AgentSpeak plans. first plan tells us that,concert announced artist venue V (so that, perceiving environment,belief concert(A,V) added belief base), provided agent happens likeartist A, new achievement goal booking tickets concert.second plan tells us whenever agent adopts goal booking ticketsperformance V, provided case telephone busy, executeplan consisting retrieving belief base telephone number venue V (withtest goal ?phone number(V,N)), performing basic action call(N) (assumingmaking phone call one actions agent able perform), followedcertain protocol booking tickets (indicated . . .), case endsexecution plan choosing seats performance particular venue.Next, formally present syntax semantics AgentSpeak. Noteyet consider communication; extend semantics deal communicationSection 4.3.1 Abstract Syntaxsyntax AgentSpeak agent program ag defined grammar below.AgentSpeak, agent program simply given set bs beliefs set ps plans.beliefs bs define initial state agents belief base (i.e., state belief baseagent starts running), plans ps form agents plan library. atomicformul language predicates, P predicate symbol t1 , . . . , tnstandard terms first order logic. belief atomic formula variables;use b meta-variable beliefs.229fiVieira, Moreira, Wooldridge, & Bordiniagbspsptectct 1hh1gu::=::=::=::=::=::=::=::=::=::=|::=::=::=::=bs psb1 . . . b np1 . . . p nte : ct h+at| | +gct 1||| ct 1 ct 1h1 ;T|| g| uP(t1 , . . . , tn )P(t1 , . . . , tn )[s1 , . . . , sm ]percept | self | idA(t1 , . . . , tn )!at| ?at+b|(n 0)(n 1)|g|| h1 ;h1(n 0)(n 0, > 0)(n 0)grammar gives alternative definition at, extending conventionalsyntactic form predicates. extension allows annotations associatedpredicate; extension AgentSpeaks original syntax motivated workcommunication, discussed Section 3.2. time being, suffice sayidea annotate atomic formula source: either term id identifyingagent previously communicated information, self denote beliefs createdagent (through belief update operations within plan, described below),percept indicate belief acquired perception environment.So, example, agent belief concert(a, v)[j] belief base, would meanagent j previously informed agent concert(a, v) words, jwanted believe concert v. Similarly, concert(a, v)[percept, j]would mean concert v believed j informed agentthis, also perceived fact (e.g., seeing poster walking pasttheatre).plan AgentSpeak given p above, te triggering event, ct planscontext, h sequence actions, goals, belief updates (which thoughtmental notes created agent itself). refer te : ct head plan,h body. set plans agent given ps. plan parthead formula ct specifies conditions plan chosenexecution.triggering event te addition deletion belief agentsbelief base (denoted +at at, respectively), addition deletion goal(+g g, respectively3 ). plan bodies, assume agent disposal setactions use meta-variable ranging them. largely unconcernedrespect exactly actions are. Actions written using notation3. Triggering events form g, approach, used practice handling plan failure. Althoughleft construct grammar, omitted discussion formalisation planfailure clarity, focus paper semantics communication.230fiSpeech-Act Based Communication Agent Programmingpredicates, except action symbol used instead predicate symbol. Goalsg either achievement goals (!at) test goals (?at). Finally, +b (in bodyplan) represent operations updating (u) belief base by, respectively, addingremoving beliefs; recall atomic formula must ground addedbelief base.3.2 Semanticsdefine semantics AgentSpeak using operational semantics, widely used methodgiving semantics programming languages (Plotkin, 1981). operational semantics given set rules define transition relation configurationshag, C, M, T, si where:agent program ag is, defined above, set beliefs bs set plans ps.agents circumstance C tuple hI, E, Ai where:set intentions {i, i0 , . . .}. intention stack partially instantiated plans.E set events {(te, i), (te 0 , i0 ), . . .}. event pair (te, i), tetriggering event intention stack plans case internalevent, empty intention case external event. beliefrevision function (which part AgentSpeak interpreter ratheragents overall architecture), updates belief base, associated eventsi.e., additions deletions beliefs included set.called external events; internal events generated additions deletionsgoals plans currently executing.set actions performed environment.tuple hIn, Out, SIi whose components characterise following aspectscommunicating agents (note communication asynchronous):mail inbox: system includes messages addressed agentset. Elements set form hmid , id , ilf , cnti, midmessage identifier, id identifies sender message, ilf illocutionaryforce message, cnt content: (possibly singleton) set AgentSpeakpredicates plans, depending illocutionary force message.agent posts messages wishes send; assumedunderlying communication infrastructure handles delivery messages.(We concerned infrastructure here.) Messages setexactly format above, except id refers agentmessage sent.SI used keep track intentions suspended due processingcommunication messages; explained detail next section,intuition follows: intentions associated illocutionary forces231fiVieira, Moreira, Wooldridge, & Bordinirequire reply interlocutor suspended, resumedreply received.useful structure keeps track temporary information maysubsequently required within reasoning cycle. tuple hR, Ap, , ,temporary information; components follows:R set relevant plans (for event handled).Ap set applicable plans (the relevant plans whose contexts true)., , record particular intention, event, applicable plan (respectively)considered along execution one reasoning cycle.current step within agents reasoning cycle symbolically annotated{ProcMsg, SelEv, RelPl, ApplPl, SelAppl, AddIM, SelInt, ExecInt, ClrInt}. labels stand for, respectively: processing message agents mail inbox, selecting event set events, retrieving relevant plans, checkingapplicable, selecting one particular applicable plan (the intended means),adding new intended means set intentions, selecting intention, executing selected intention, clearing intention intended means mayfinished previous step.interests readability, adopt following notational conventionssemantic rules:C AgentSpeak agent circumstance, write CE make reference Ecomponent C, similarly components configuration.write = (the underscore symbol) indicate intention presentlyconsidered reasoning cycle. Similarly .write i[p] denote intention plan p top intention i.AgentSpeak interpreter makes use three selection functions definedagent programmer. selection function SE selects event set events CE ;selection function SAp selects one applicable plan given set applicable plans;SI selects intention set intentions CI (the chosen intention executed).Formally, selection functions agent uses also part configuration (associal acceptance function mention later formalise agent communication).However, defined agent programmer design time (inprinciple) change run time, avoid including configuration sakereadability.define functions help simplify semantics. p plan formte : ct h, define TrEv(p) = te Ctxt(p) = ct. is, projection functionsreturn triggering event context plan, respectively. TrEv functionalso applied head plan rather whole plan, works similarlycase.232fiSpeech-Act Based Communication Agent ProgrammingNext, need define specific (limited) notion logical consequence used here.assume procedure computes general unifier two literals (as usuallogic programming), this, define logical consequence relation |= useddefinitions functions checking relevant applicable plans, wellexecuting test goals. Given extended syntax atomic formulinclude annotations sources information symbolically represented it,also need define |= particular context, follows.Definition 1 say atomic formula at1 annotations s11 , . . . , s1n logicalconsequence set ground atomic formul bs, written bs |= at1 [s11 , . . . , s1n ] if,if, exists at2 [s21 , . . . , s2m ] bs (i) at1 = at2 , generalunifier , (ii) {s11 , . . . , s1n } {s21 , . . . , s2m }.intuition that, predicate unify belief bs (i),also specified sources information corroborated bs (ii). Thus,example, p(X)[ag1 ] follows {p(t)[ag1 ,ag2 ]}, p(X)[ag1 ,ag2 ] follow{p(t)[ag1 ]}. concretely, if, order applicable, plan requiresdrowning person explicitly perceived rather communicated another agent(which represented drowning(Person)[percept]), follows beliefdrowning(man)[percept,passerby] (i.e., perceived communicatedpasserby). hand, required context two independent sourcesprovided information, say cheating(Person)[witness1,witness2], cannotinferred belief cheating(husband)[witness1].order make semantic rules readable, use two operations beliefbase (i.e., set annotated ground atomic formul). use bs 0 = bs + b say bs 0bs except bs 0 |= b. Similarly bs 0 = bs b means bs 0 bs except bs 0 6|= b.plan considered relevant relation triggering event writtendeal event. practice, checked trying unify triggering event partplan triggering event within event selected treatmentreasoning cycle. definition below, use logical consequence relationdefined check plans triggering event unifies event occurred.this, need extend |= relation also applies triggering eventsinstead predicates. fact, purposes here, consider operatorstriggering event (such + !) part predicate symbol or, precisely, letat1 predicate (with annotation) within triggering event te 1 at2 one withinte 2 , {te 2 } |= te 1 if, if, {at2 } |= at1 and, course, operators prefixing te 1te 2 exactly same. requirement inclusion annotations,converse might true.Definition 2 Given plans ps agent triggering event te, set RelPlans(ps, te)relevant plans te defined follows:RelPlans(ps, te) = {(p, ) | p ps s.t. {te} |= TrEv(p)}.intuition regarding annotations follows. programmer includeannotations plans triggering event sources must generated233fiVieira, Moreira, Wooldridge, & Bordinievent plan relevant (or include annotation source informationimportant plan considered relevant). plan relevant,therefore suffices annotations plans triggering event subsetevent occurred. plan triggering event +!p(X)[s] relevant eventh+!p(t)[s, t], Ti since RelPlans requires {p(t)[s, t]} |= p(X)[s] (for generalunifier ), turn requires {s} {s, t}. consequence, plantriggering event annotations (e.g., +!p(X)) relevant particular event(say, h+!p(t)[ag1 ], ii) requires predicates unify usual sense since{} S, set S.plan applicable relevant context logical consequence agentsbeliefs. need extend slightly definition |= given above. plans contextconjunction literals (l either at). say bs |= l1 . . . ln if,if, bs |= li li form at, bs 6|= li li form at, 1 n.function determining applicable plans set relevant plans formalisedfollows.Definition 3 Given set relevant plans R beliefs bs agent, setapplicable plans AppPlans(bs, R) defined follows:AppPlans(bs, R) = {(p, 0 ) | (p, ) R 0 s.t. bs |= Ctxt(p)0 }.need another function used semantic rule agentexecute test goal. evaluation test goal ?at consists testing formulalogical consequence agents beliefs. function returns set generalunifiers make formula logical consequence set formul bs,follows.Definition 4 Given set formul bs formula at, set substitutionsTest(bs, at) produced testing bs defined follows:Test(bs, at) = { | bs |= at}.Next, present reasoning cycle AgentSpeak agents rules defineoperational semantics.3.3 Reasoning CycleFigure 5 shows possible transitions various steps agents reasoningcycle determined AgentSpeak interpreter. labels nodes identify stepcycle, are: processing received messages (ProcMsg); selecting eventset events (SelEv); retrieving relevant plans (RelPl); checkingapplicable (ApplPl); selecting one particular applicable plan (the intended means) (SelAppl);adding new intended means set intentions (AddIM); selecting intention(SelInt); executing selected intention (ExecInt), clearing intention intendedmeans may finished previous step (ClrInt).general case, agents initial configuration hag, C, M, T, ProcMsgi, aggiven agent program, components C, , empty. Note234fiSpeech-Act Based Communication Agent ProgrammingProcMsgSelEvClrIntRelPlExecIntApplPlSelIntSelApplAddIMFigure 5: AgentSpeak agent reasoning cycle.reasoning cycle starts processing received messages (ProcMsg) semanticspart reasoning cycle given main section paper. that,original AgentSpeak reasoning cycle takes place. event selection (SelEv) made,followed determining relevant applicable plans (RelPl ApplPl, respectively).One relevant plans selected (SelAppl); note eventstreated applicable plans deal event agent turnsattention selection intended means (SelInt) executed next. onerelevant plans selected (SelAppl) instance plan becomes intendedmeans therefore included set intentions (AddIM).one intention (which normally case except extremely simple agents), oneintentions selected (SelInt) executed (ExecInt).important transitions; others made clearersemantics presented. rules define transition systems giving operationalsemantics AgentSpeak (without communication) presented next.3.4 Semantic Rulessection, present operational semantics AgentSpeak formalisestransitions possible steps interpretation AgentSpeak agents shownFigure 5. general case, agents initial configuration hag, C, M, T, ProcMsgi,ag given agent program, components C, , empty.Note reasoning cycle starts processing received messages (ProcMsg), accordingrecent extension semantics presented Section 4. eventselection (SelEv) made, starting reasoning cycle originally definedlanguage, part semantics presented below.Event Selection: rule assumes existence selection function SEselects events set events E. selected event removed Eassigned component temporary information. Rule SelEv2 skipsintention execution part cycle, case events handle.235fiVieira, Moreira, Wooldridge, & BordiniSE (CE ) = hte, iihag, C, M, T, SelEvi hag, C 0 , M, 0 , RelPliwhere:(SelEv1 )CE0 = CE \ {hte, ii}T0 = hte, iiCE = {}hag, C, M, T, SelEvi hag, C, M, T, SelInti(SelEv2 )Relevant Plans: Rule Rel1 assigns set relevant plans component TR . Rule Rel2deals possibility relevant plans event, caseevent simply discarded. fact, intention associated event might alsodiscarded: relevant plans handle event generated intention,cannot executed. practice, instead simply discarding event (andpossibly intention it), leads activation plan failure mechanism,discuss clarity presentation, discussed earlier.= hte, iiRelPlans(agps , te) 6= {}hag, C, M, T, RelPli hag, C, M, 0 , ApplPliwhere:(Rel1 )TR0 = RelPlans(agps , te)RelPlans(agps , te) = {}hag, C, M, T, RelPli hag, C, M, T, SelEvi(Rel2 )alternative approach situations relevant plans eventintroduced Ancona, Mascardi, Hubner, Bordini (2004). assumescases, explicitly specified programmer, agent want ask agentsrecipes use handling events. mechanism plan exchangeAgentSpeak agents proposed allows programmer specify triggering eventsgenerate attempts retrieve external plans, plans agent agrees shareothers, plan used handling particular eventinstance, forth.Applicable Plans: rule Appl1 assigns set applicable plans TAp component; rule Appl2 applies applicable plans event, caseevent simply discarded. Again, practice, normally leads plan failure mechanism activated, rather simply discarding event (and whole intentionit).AppPlans(agbs , TR ) 6= {}hag, C, M, T, ApplPli hag, C, M, 0 , SelAppliwhere:(Appl1 )0TAp= AppPlans(agbs , TR )AppPlans(agbs , TR ) = {}hag, C, M, T, ApplPli hag, C, M, T, SelInti236(Appl2 )fiSpeech-Act Based Communication Agent ProgrammingSelection Applicable Plan: rule assumes existence selection functionSAp selects one plan set applicable plans TAp . selected planassigned component configuration.SAp (TAp ) = (p, )hag, C, M, T, SelAppli hag, C, M, 0 , AddIMiwhere:(SelAppl)T0 = (p, )Adding Intended Means Set Intentions: Events classifiedexternal internal (depending whether generated agents perception,whether generated previous execution plans, respectively). RuleExtEv determines that, event external (which indicated intentionassociated ), new intention created intended means newintention plan p assigned component. event internal, rule IntEvdetermines plan put top intention associatedevent.= hte, Ti= (p, )hag, C, M, T, AddIMi hag, C 0 , M, T, SelIntiwhere:CI0= CI { [p] }= hte, ii = (p, )hag, C, M, T, AddIMi hag, C 0 , M, T, SelIntiwhere:CI0(ExtEv)(IntEv)= CI { i[(p)] }Note that, rule IntEv, whole intention generated internal event needsinserted back CI , p pushed onto top intention. relatedresuming suspended intentions; suspending intentions appears rule AchvGlbelow.Intention Selection: Rule SelInt1 assumes existence function SI selectsintention processing next, rule SelInt2 takes care situation setintentions empty (in case reasoning cycle simply starts again).CI 6= {}SI (CI ) =hag, C, M, T, SelInti hag, C, M, 0 , ExecIntiwhere:(SelInt1 )T0 =CI = {}hag, C, M, T, SelInti hag, C, M, T, ProcMsgi(SelInt2 )Executing Intention: group rules express effects executingformula body plan. rule deals one type formula appear237fiVieira, Moreira, Wooldridge, & Bordiniplan body. Recall Section 3.2 intention stack (partially instantiated)plan instances; plan instance copy plan agents plan library). planinstance executed always one top intention selectedprevious step (rule SelInt1 ); specific formula executed one beginningbody plan.Actions: formula executed action, action body planadded set actions (which, recall, denotes action executed usingagents effectors). action removed body plan intentionupdated reflect removal.= i[head a;h]hag, C, M, T, ExecInti hag, C 0 , M, T, ClrIntiwhere:(Action)0CA= CA {a}CI0 = (CI \ {T }) {i[head h]}Achievement Goals: rule registers new internal event set events E.event selected handling future reasoning cycle (see rule SelEv1 ).formula executed goal, formula removed body plan,cases. happens plan used achieving goal finishessuccessfully; see rule ClrInt2 . reasons related instantiationplan variables well handling plan failure.= i[head !at;h]hag, C, M, T, ExecInti hag, C 0 , M, T, ProcMsgiwhere:(AchvGl)CE0 = CE {h+!at, i}CI0 = CI \ {T }Note intention generated internal event removed setintentions CI , capturing idea suspended intentions. plan body, !g; f(where f formula appear plan bodies), means that, fexecuted, state affairs represented goal g needs achieved (throughexecution relevant, applicable plan). goal included new event createdrule AchvGl treated event, means go set eventseventually selected later reasoning cycle, according agents specificpriorities selecting events (rule SelEv1 ). Meanwhile, plan (with formula fexecuted next) longer executed, hence whole intention suspendedplaced, within newly created event, set events removed setintentions. event created rule selected applicable planachieving g chosen, intended means pushed top suspendedintention, resumed (i.e., moved back set intentions), accordingrule IntEv. next time intention selected, execution proceedplan achieving g top, plan finished f executed (asplan, without achieved goal, top intention again);details suspended intentions found AgentSpeak literature (e.g., see Bordini& Moreira, 2004).238fiSpeech-Act Based Communication Agent ProgrammingTest Goals: rules used test goal formula ?at executed. RuleTestGl1 used set substitutions make logical consequenceagents beliefs, means test goal succeeded. test goal succeeds,substitution applied whole intended means, reasoning cyclecontinued. case, might turn test goal used triggeringevent plan, used programmers formulate sophisticated queries.Rule TestGl2 used case: generates internal event, may triggerexecution plan, achievement goals. carry plan agent requiredobtain information (at time actual execution plan) directlyavailable belief base, plan test goal written which, example, sendsmessages agents, processes available data, particular test goalconcluded (producing appropriate instantiation logical variables). internal eventgenerated test goal executed, process similar achievement goals,intention suspended plan selected achieve goal, explainedabove.= i[head ?at;h]Test(agbs , at) 6= {}hag, C, M, T, ExecInti hag, C 0 , M, T, ClrIntiwhere:CI0= (CI \ {T }) {i[(head h)]}Test(agbs , at)= i[head ?at;h]Test(agbs , at) = {}hag, C, M, T, ExecInti hag, C 0 , M, T, ClrIntiwhere:(TestGl1 )(TestGl2 )CE0 = CE {h+?at, i}CI0 = CI \ {T }Updating Beliefs: rules below, set beliefs agent modified wayeither atomic formula (with annotation self) included new set beliefs(rule AddBel) removed (rule DelBel). rules add new eventset events E, update intention removing +b formulaexecuted. Note belief deletions variables (at), whilst ground atoms(b) added belief base.= i[head +b;h]hag, C, M, T, ExecInti hag 0 , C 0 , M, T, ClrIntiwhere:ag 0bsCE0CI0= ag bs + b[self]= CE {h+b[self], Ti}= (CI \ {T }) {i[head h]}= i[head at;h]hag, C, M, T, ExecInti hag 0 , C 0 , M, T, ClrIntiwhere:ag 0bsCE0CI0(AddBel)= ag bs at[self]= CE {hat[self], Ti}= (CI \ {T }) {i[head h]}239(DelBel)fiVieira, Moreira, Wooldridge, & BordiniClearing Intentions: Finally, following rules remove empty intended means intentions set intentions. Rule ClrInt1 simply removes whole intentionnothing else executed intention. Rule ClrInt2 clears remainderplan empty body currently top (non empty) intention. case,necessary instantiate plan finished plan (currently topintention), remove goal left beginning body plan(see rules AchvGl TestGl). Note that, case, clearing mightnecessary, hence next step still ClrInt. Rule ClrInt3 takes care situation(further) clearing required, new reasoning cycle start (at step ProcMsg).j = [head T], j CIhag, C, M, T, ClrInti hag, C 0 , M, T, ProcMsgiwhere:CI0(ClrInt1 )= CI \ {j}j = i[head T], j CIhag, C, M, T, ClrInti hag, C 0 , M, T, ClrInti(ClrInt2 )where: CI0 = (CI \ {j}) {k[(head0 h)]}= k[head0 g;h] s.t. g = TrEv(head)j=6 [head T] j 6= i[head T], j CIhag, C, M, T, ClrInti hag, C, M, T, ProcMsgi(ClrInt3 )4. Semantics Communicating AgentSpeak Agentsrules previous section give semantics key internal decision makingcontrol aspects AgentSpeak. Furthermore, overall agent architecture sensors(with associated belief revision function) effectors, addition AgentSpeakinterpreter. relation components AgentSpeak interpreter essentialgiving semantics language itself. suffices note belief revisionperception environment adds (external) events set CE (which usedAgentSpeak interpretation cycle), effectors simply execute every actionincluded reasoner set CA .Similarly, mechanism allows messages exchanged part overallagent architecture part practical reasoning component, specifically program AgentSpeak. notion internal actions AgentSpeak(Bordini et al., 2002) appropriate here: sending message corresponds executing(predefined) internal action .send appears plan body. underlying agent architecture ensures necessary technical means used message reachagent message addressed. However, referring special typecommunication action involves suspending intentions, need includedetails semantics.44. aspects whole framework still included formalisation given paper.extend semantics point required accounting semantics speech-act basedmessages received agent.240fiSpeech-Act Based Communication Agent Programmingformat messages hmid , id , ilf , cnti, mid uniquely identifies message,id identifies agent message addressed (when message sent)agent sent message (when message received), ilfillocutionary force (i.e., performative) associated message, cntmessage content. Depending illocutionary force message, content be:atomic formula (at); set formul (AT s); ground atomic formula (b); setground atomic formul (Bs); set plans (P Ls).mechanism receiving sending messages asynchronously defined. Messages stored mail box one processed agent beginningreasoning cycle. Recall that, configuration transition system, MIn setmessages agent received processed yet, MOut set messagessent agents, MSI set suspended intentions awaiting replies(information request) messages previously sent. specifically, MSI set pairsform (mid , i), mid message identifier uniquely identifies previouslysent message caused intention suspended.sending messages illocutionary forces related information requests,chosen semantics intention suspended reply receivedinterlocutor, much way intentions get suspended waitinginternal event handled. particular semantics ask messages,programmer knows certainty subsequent action body planexecuted requested information already received. However, noteinformation received reply stored directly agents belief base, test goalrequired information used remainder plan.give two rules executing (internal) action sending message anotheragent: first ask messages require suspending intentions secondtypes messages. rules priority Action; although Actioncould also applied configurations, assume rules usedformula executed specifically .send action. (We include provisorule Action improve readability.)= i[head .send(id , ilf , cnt);h]ilf {AskIf , AskAll , AskHow }hag, C, M, T, ExecInti hag, C 0 , 0 , T, ProcMsgiwhere:0MOut0MSICI0(ExecActSndAsk)= MOut {hmid , id , ilf , cnti}= MSI {(mid , i[head h])},mid new message identifier;= (CI \ {T })semantics sending types illocutionary forces simply addwell-formed message agents mail outbox (rule ExecActSnd). Note ruleabove, intention suspended, next step reasoning cycle ProcMsg(i.e.,new cycle started), whereas rule ClrInt, updated intentionsending action removed plan body might require clearing,intention execution rules seen previous section.241fiVieira, Moreira, Wooldridge, & Bordini= i[head .send(id , ilf , cnt);h]ilf 6 {AskIf , AskAll , AskHow }hag, C, M, T, ExecInti hag, C 0 , 0 , T, ClrIntiwhere:0MOutCI0(ExecActSnd)= MOut {hmid , id , ilf , cnti},mid new message identifier;= (CI \ {T }) {i[head h]}Whenever new messages sent, assume system creates unique message identifiers (mid ). Later, shall see that, replying message, messageidentifier kept message, similar way reply-with used KQML.Thus, receiving agent aware particular message reply previous onechecking message identifiers set intentions suspended waitingreply. feature used give semantics receiving Tell messages,sent agent spontaneously wants receiver believe something (orleast believe something senders beliefs), also usedagent receives ask type message chooses reply it.mentioned earlier, aim formalise every aspect system multiple AgentSpeak agents. extend previous semantics extent requiredformalise speech-act based communication agents. relevant, therefore,consider rule defines message exchange accomplished underlying messageexchange mechanism available overall agent architecture. abstracted awaysemantics means following rule, AGid k , k = 1 . . . n, agentconfiguration hag id k , Cid k , Mid k , Tid k , sid k i:hmid , id j , ilf , cnti Mid{AGid 1 , . . . AGid , AGid j , . . . AGid n , env}{AGid 1 , . . . AG0id , AG0id j , . . . AGid n , env}where:(MsgExchg)0Mid= Mid \ {hmid , id j , ilf , cnti}0Mid j= Mid j {hmid , id , ilf , cnti}rule above, n agents, env denotes environmentagents situated; typically, AgentSpeak agent, simply representedset properties currently true environment changed agentsactions. Note how, message sent, second component identifiesaddressee (the agent message sent), whereas received messagecomponent identifies sender message.4.1 Speech-act Based Communication AgentSpeaksection discuss performatives relevant communicationAgentSpeak. largely inspired corresponding KQML performatives.also consider new performatives, related plan exchange rather communicationpropositions usual. performatives consider briefly described below,denotes agent sends message, r denotes agent receives242fiSpeech-Act Based Communication Agent Programmingmessage. Note tell untell used either agent pro-activelysend information another agent, replies previous ask messages.tell: intends r believe (that believes) sentence messages contenttrue;untell: intends r believe (that believes) sentence messages contenttrue;achieve: requests r intend achieve state world messagecontent true;unachieve: requests r drop intention achieving state worldmessage content true;tell-how: informs r plan (i.e., know-how s);untell-how: requests r disregard certain plan (i.e., delete plan planlibrary);ask-if: wants know content message true r;ask-all: wants rs answers question (i.e., beliefs unifymessage content);ask-how: wants rs plans particular triggering event (in message content).processing messages, new selection function necessary, operates muchway selection functions described previous section. newselection function called SM , selects message MIn ; intuitively, representspriority assigned type message programmer. also need anothergiven function, purpose different selection functions. Boolean functionSocAcc(id , ilf , at), ilf illocutionary force message agent id ,propositional content at, determines message socially acceptable given context.example, message form hmid , id , Tell , ati, receiving agent may wantconsider whether id relevant source information, even remembering id believesmight appropriate. message illocutionary force Achieve, agent wouldnormally check, example, whether id sufficient social power itself, whetherwishes act altruistically towards id , actually committing whateverasked.mention role SocAcc() framework analogous,receivers side, cause want cause believe predicates CohenPerraults plan-based theory speech acts (1979). is, provides bridgeillocutionary force message perlocutionary force. idea userdefined functions determining relations trust power already usedpractice Bordini et al. (2003). Similar interpretations use SocAccapplied types messages (e.g., AskIf ) easily derived.considerable work elaborate conceptions trust context multi-agentsystems, example work Castelfranchi Falcone (1998). framework,243fiVieira, Moreira, Wooldridge, & Bordinisophisticated notions trust power implemented consideringannotation sources information agents practical reasoning rathersimple use SocAcc. annotation construct facilitates determining, plancontext, source belief plan becomes intended means.start presentation semantic rules communication, worthnoting that, paper particular, consider nested annotations. Nestedannotations allow representation beliefs agents beliefs, generallysituations agent told j, turn told k, forth.4.2 Semantic Rules Interpreting Received MessagesReceiving Tell Message: Tell message might sent agent either replyinform action. receiving Tell message inform (as opposed replyprevious request), AgentSpeak agent include content received messageknowledge base annotate sender source belief. Notecorresponds, way, specified action completion condition LabrouFinin (1994): receiver know senders attitude regarding belief.account social aspects multi-agent systems, consider social relationsregulate messages receiver process discard; referredsemantics SocAcc function, assumed given agent designer.rule shows annotated belief added belief base, appropriate eventgenerated.SM (MIn ) = hmid , id , Tell , Bsi(mid , i) 6 MSI (for intention i)SocAcc(id , Tell , Bs)hag, C, M, T, ProcMsgi hag 0 , C 0 , 0 , T, SelEviwhere:0MIn(Tell)= MIn \ {hmid , id , Tell , Bsi}b Bs :ag 0bs = ag bs + b[id ]CE0= CE {h+b[id ], Ti}Receiving Tell Message Reply: rule similar one above, exceptsuspended intention associated particular message givenreply previous ask message sent agent needs resumed. Recallresume intention need place back set intentions (CI0 ).244fiSpeech-Act Based Communication Agent ProgrammingSM (MIn ) = hmid , id , Tell , Bsi(mid , i) MSI (for intention i)SocAcc(id , Tell , Bs)hag, C, M, T, ProcMsgi hag 0 , C 0 , 0 , T, SelEviwhere:0MIn0MSI0CI(TellRepl)= MIn \ {hmid , id , Tell , Bsi}= MSI \ {(mid , i)}= CI {i}b Bs :ag 0bs = ag bs + b[id ]CE0= CE {h+b[id ], Ti}Receiving Untell Message: receiving Untell message, sendermessage removed set sources giving accreditation atomic formulacontent message. case sender source information,belief removed receivers belief base. Note that, atomic formulacontent Untell message uninstantiated variables, beliefagents belief base unified formula needs considered turn,appropriate events generated.SM (MIn ) = hmid , id , Untell , si(mid , i) 6 MSI (for intention i)SocAcc(id , Untell , s)hag, C, M, T, ProcMsgi hag 0 , C 0 , 0 , T, SelEviwhere:0MIn(Untell)= MIn \ {hmid , id , Untell , si}b {at |Test(agbs , at) s}ag 0bs = ag bs b[id ]CE0= CE {hb[id ], Ti}Receiving Untell Message Reply: above, sender sourcebelief, belief itself, excluded belief base receiver, exceptsuspended intention needs resumed (similarly Tell reply).245fiVieira, Moreira, Wooldridge, & BordiniSM (MIn ) = hmid , id , Untell , si(mid , i) MSI (for intention i)SocAcc(id , Untell , s)hag, C, M, T, ProcMsgi hag 0 , C 0 , 0 , T, SelEviwhere:0MIn0MSI0CI(UntellRepl)= MIn \ {hmid , id , Untell , si}= MSI \ {(mid , i)}= CI {i}b {at |Test(agbs , at) s}0ag bs = ag bs b[id ]CE0= CE {hb[id ], Ti}Receiving Achieve Message: appropriate social context (e.g., senderpower receiver), receiver try execute plan whose triggering event+!at; is, try achieve goal associated propositional contentmessage. external event thus included set events (recall external eventstriggering event associated empty intention T).Note possible new focus attention (a stack plans setintentions I) initiated addition (or deletion, see below) achievementgoal. Originally, belief change arising perception environment initiatednew focus attention; plan chosen event could, turn, achievementgoals body, thus pushing new plans onto stack.SM (MIn ) = hmid , id , Achieve, atiSocAcc(id , Achieve, at)hag, C, M, T, ProcMsgi hag, C 0 , 0 , T, SelEviwhere:0MIn0CE(Achieve)= MIn \ {hmid , id , Achieve, ati}= CE {h+!at, Ti}shall later discuss detail issue autonomy. gives impression simply accepting orders removes agents autonomy (and similarlyregards acquired beliefs), way agent behave aware another agentattempting delegate goal completely depends particular plans happenagents plan library. suitable plan exists, agent could simply dropgoal, could tell interlocutor goal delegation noted goal couldadopted expected, etc.Receiving Unachieve Message: rule similar preceding one, exceptdeletion (rather addition) achievement goal included setevents. assumption that, agent plan triggeringevent, plan handle aspects dropping intention. However,practice may require alteration set intentions, thus requiring specialmechanisms included formalisation AgentSpeak yet, eventhough already available practice, example Jason interpreter (Bordini &Hubner, 2007).246fiSpeech-Act Based Communication Agent ProgrammingSM (MIn ) = hmid , id , Unachieve, atiSocAcc(id , Unachieve, at)hag, C, M, T, ProcMsgi hag, C 0 , 0 , T, SelEviwhere:0MIn0CE(Unachieve)= MIn \ {hmid , id , Unachieve, ati}= CE {h!at, Ti}Receiving Tell-How Message: AgentSpeak notion plan related Singhsconcept know-how (1994). Accordingly, use TellHow performative agentswish exchange know-how rather communicate beliefs delegate goals. is,TellHow message used sender (an agent external source generally)inform AgentSpeak agent plan used handling certain types events(as expressed plans triggering event). source trusted, plansmessage content simply added receivers plan library.SM (MIn ) = hmid , id , TellHow , P Lsi(mid , i) 6 MSI (for intention i)SocAcc(id , TellHow , P Ls)hag, C, M, T, ProcMsgi hag 0 , C, 0 , T, SelEviwhere:(TellHow)0MIn= MIn \ {hmid , id , TellHow , P Lsi}0ag ps = ag ps P LsNote include annotation identify source plan, so,semantics, possible take account identity agentprovided plan deciding whether use it. practice, feature implementedJason interpreter, language extended use annotated predicatesplan labels. also allows programmers annotate plans informationused meta-level reasoning (e.g., choosing plan use case various applicableplans available, intention execute next); examples information wouldexpected payoff specific plan expected chance success, thus allowinguse decision-theoretic techniques making choices.Receiving Tell-How Message Reply: TellHow performative replyalso cause suspended intention one associated respective AskHowmessage previously sent resumed.SM (MIn ) = hmid , id , TellHow , P Lsi(mid , i) MSI (for intention i)SocAcc(id , TellHow , P Ls)hag, C, M, T, ProcMsgi hag 0 , C 0 , 0 , T, SelEviwhere:0MIn0MSI0CIag 0ps====MIn \ {hmid , id , TellHow , P Lsi}MSI \ {(mid , i)}CI {i}ag ps P Ls247(TellHowRepl)fiVieira, Moreira, Wooldridge, & BordiniReceiving Untell-How Message: similar rule above, except plansremoved receivers plan library. external source may find planlonger appropriate handling events supposed handle; may wantinform another agent that. Thus, receiving socially acceptable UntellHowmessage, agent removes associated plans (i.e., message content)plan library.SM (MIn ) = hmid , id , UntellHow , P LsiSocAcc(id , UntellHow , P Ls)hag, C, M, T, ProcMsgi hag 0 , C, 0 , T, SelEviwhere:(UntellHow)0MIn= MIn \ {hmid , id , UntellHow , P Lsi}0ag ps = ag ps \ P LsReceiving Ask-If Message: receiver respond request informationcertain conditions imposed social settings (the SocAcc function) holdsender receiver.Note ask-if ask-all differ kind request made receiver.former, receiver confirm whether predicate message contentbelief base not; latter, agent replies predicatesbelief base unify formula message content. receiver processingAskIf message responds action sending either Tell (to reply positively)Untell message (to reply negatively); reply message content AskIfmessage. Note reply sent social context receiver wishesconsider senders request.SM (MIn ) = hmid , id , AskIf , {b}iSocAcc(id , AskIf , b)hag, C, M, T, ProcMsgi hag, C, 0 , T, SelEviwhere:0MIn0MOut=( \ {hmid , id , AskIf , {b}i}MOut {hmid , id , Tell , {b}i}=MOut {hmid , id , Untell , {b}i}(AskIf )ag bs |= bag bs 6|= brole SM plays agents reasoning cycle slightly importantoriginally conceived (Moreira et al., 2004). agent considers whether acceptmessage not, reply message automatically assembled agent selects(and accepts) ask messages. However, providing reply may requireconsiderable computational resources (e.g., whole plan library may need scannedconsiderable number plans retrieved order produce reply message).Therefore, SM normally defined agent selects AskIf , AskAll ,AskHow message determines agent currently busy provide reply.Receiving AskAll: AskIf , receiver processing AskAll respondeither Tell Untell , provided social context receiver choose248fiSpeech-Act Based Communication Agent Programmingrespond. noted above, agent replies predicates belief baseunify formula message content.SM (MIn ) = hmid , id , AskAll , {at}iSocAcc(id , AskAll , at)hag, C, M, T, ProcMsgi hag, C, 0 , T, SelEviwhere:0MIn0MOut=MIn \ {hmid , id , AskAll , {at}i}MOut {hmid , id , Tell , si},= {at | Test(agbs , at)}={hmid , id , Untell , {at}i}(AskAll)Test(agbs , at) 6= {}otherwiseReceiving AskHow: receiver AskHow respond actionsending TellHow message, provided social configuration receiverconsider senders request. contrast use Untell AskAll , responsereceiver knows relevant plan (for triggering event message content)reply empty set plans.SM (MIn ) = hmid , id , AskHow , teiSocAcc(id , AskHow , te)hag, C, M, T, ProcMsgi hag, C, 0 , T, SelEviwhere:0MIn0MOut(AskHow)= MIn \ {hmid , id , AskHow , tei}= MOut {hmid , id , TellHow , P Lsi}P Ls = {p | (p, ) RelPlans(agps , te)}SocAcc Fails: rules consider social relations senderreceiver favourable particular communicative act (i.e, require SocAcctrue). required social relation hold, message simply discardedremoved set messages ignored. rule used receivingmessage untrusted source, regardless performative.SM (MIn ) = hmid , id , ilf , BsiSocAcc(id , ilf , Bs)(with ilf {Tell , Untell , TellHow , UntellHow ,Achieve, Unachieve, AskIf , AskAll , AskHow })hag, C, M, T, ProcMsgi hag, C, 0 , T, SelEviwhere:0MIn(NotSocAcc)= MIn \ {hmid , id , ilf , Bsi}MIn empty: last semantic rule states that, mail inbox empty,agent simply goes next step reasoning cycle (SelEv).MIn = {}hag, C, M, T, ProcMsgi hag, C, M, T, SelEvi249(NoMsg)fiVieira, Moreira, Wooldridge, & Bordini4.3 Comments Fault Detection Recoverydistributed system, multi-agent systems (and do) fail real world.Possibly even typical distributed systems, given multi-agent systemsnormally used dynamic, unpredictable environments. contexts, failuresexpected happen quite often, agents need recover best possibleway. specific case systems composed AgentSpeak agents, failures occurwhen, instance, agent message sent left multi-agentsystem, cannot contacted, ceased exist (e.g., machine networkcrash). Equally, intention suspended waiting reply may never resumeddue failure agent supposed provide reply. (However, noteAgentSpeak agents typically various concurrent foci attention i.e., multipleintentions currently set intentions even one particular intention neverprogress another agent never replies, agent simply carry workingfoci attention.)context AgentSpeak agents, fault detection recovery startlevel infrastructure supports agent execution. infrastructure adopttechniques available traditional distributed systems fundamental difference:responsible adding appropriate events signaling failures set CE externalevents, possibly resuming suspended intentions immediately making failexample message reply timed out. events, treated agentnormal reasoning cycle, using plan failure mechanism formalised availablepractical interpreters, trigger plan specifically written agent programmerdefines strategy failure recovery. Therefore, point view formalsemantics AgentSpeak, failure recovery reduces event handling plan execution,partly responsibility underlying execution infrastructure partlyresponsibility programmers. note various approaches failure detection recovery within multi-agent systems particular appear literature (e.g.,Jennings, 1995; Kumar & Cohen, 2000). typically involve use special agentsplans defined deal failure.natural concern set agents executing concurrently sharedresources always left consistent state. is, course, classical problemconcurrency, typically solved atomically executing parts code accessshared resources. Many programming language constructs enable programmer guarantee atomic execution critical sections. multi-agent system writtenAgentSpeak, atomicity immediately issue since critical sections,given different AgentSpeak agents directly share memory. However, AgentSpeakagents exchange information form messages, responsibility management exchanges lies underlying message passing infrastructure.hand, agents multi-agent systems typically share environment, particular application requires environment resources shared agents, clearly programmersneed ensure suitable agent interaction protocols used avoid dead-/live-locksstarvation.Another possible source concern regarding atomicity concurrent executionagents intentions. Agents several intentions ready executed one250fiSpeech-Act Based Communication Agent Programmingread/write data shared intentions (as accessbelief base). scope paper formalise mechanisms controlconcurrency, worth mentioning Jason interpreter provides programmerspossibility annotating plans atomic, oneselected execution (see SelInt semantic rule), guaranteed runtime agentplatform plan execution suspended/interrupted (i.e.,intention selected execution following reasoning cycles) wholeplan finishes executing.Next, give example intended illustrate semantic rules appliedreasoning cycle. example includes agents exchanging messages using semanticframework agent communication formalised earlier section.5. Example Reasoning Cycles Communicating AgentsConsider following scenario. Firefighting robots action trying control rapidlyspreading fire building, supervision commander robot. Another robotpiloting helicopter observe direction fire spreading rapidly. Letrobot helicopter r1, let r2 ground commander, let r3 onefirefighting robots.One plans r1s plan library, shall refer ps1, shownFigure 6. plan says soon r1 perceives fire spreading direction D, tells Rfire spreading towards D, R agent believes ground commander.Plan ps2 one plans robot r2 (the commander) plan library,also shown Figure 6. Plan ps2 says that, r2 gets believe5 fire spreadingdirection D, request robot believed closest part buildingachieve state world fighting post robot (in words,robot relocate part building direction D).proceed show rules operational semantics apply, usingone reasoning cycle AgentSpeak agent controls r1 example; rulescommunication exemplified afterwards. simplicity, assume r1 currentlydefined configuration hag 1 , C1 , M1 , T1 , s1 i, s1 = ProcMsg ag 1 componenthaving:ag 1bs = {commander(r2)},ag 1ps = {ps1}.Suppose r1 perceived fire spreading towards south. belief revision function (see Section 3.2) operated, r1s beliefs updated ag 1bs ={commander(r2), spreading(south)} C1E component r1s configuration (i.e.,set events) follows:C1E = {h+spreading(south), Ti}.5. Note that, plans triggering event require particular source information (as in, e.g., +spreading(D)[percept]), plan used belief acquiredcommunication well perception environment.251fiVieira, Moreira, Wooldridge, & Bordinir1s plan ps1+spreading(D): commander(R);<- .send(R,tell,spreading(D)).r2s plan ps2+spreading(D): closest(D,A);<-.send(A,achieve,fight post(A,D)).Figure 6: Plans used firefighting robots example.point, show sequence rules applied complete onereasoning cycle: see Table 1, left column shows rule appliedright column shows components configuration changedconsequence rule applied. Note next step component s1changes obvious way (given rules applied), show changefirst step, messages processed cycle goes straightselecting event handled reasoning cycle.Table 1: Example sequence rules applied one reasoning cycle.RuleChanged Configuration ComponentsNoMsgs1 = SelEvSelEv1C1E = {}T1 = h+spreading(south), TiRel1T1R = {(ps1, R )}, R = {D 7 south}Appl1T1Ap = {(ps1, )}, = {D 7 south, R 7 r2}SelAppT1 = (ps1, )ExtEvC1I = {[ps1A ]}SelInt1T1 = [ps1A ]ExecActSnd M1Out = {hmid 1 , r2, Tell , {spreading(south)i}}C1I = {[+spreading(south) : commander(r2) <- T]}ClrInt1C1I = {}r1s reasoning cycle shown table, rule MsgExchg applies and, assuminghag 2 , C2 , M2 , T2 , s2 r2s configuration, simplicity assume initial (i.e.,empty) configuration hence s2 = ProcMsg, shall that:252fiSpeech-Act Based Communication Agent ProgrammingM2In = {hmid 1 , r1, Tell , {spreading(south)}i},leads rule Tell applied, thus starting reasoning cycle (similarone Table 1) r2 configuration following componentschanged (see Rule Tell):M2In = {}ag 2bs = {spreading(south)[r1]}C2E = {h+spreading(south)[r1], Ti}.reasoning cycle r2, would r3 that:M3In = {hmid 2 , r2, Achieve, fight post(r3,south)i},M3In r3s mail inbox (and assuming M3In previously empty). Note r3sSocAcc function used rule Achieve (leading mid 2 included M3In statedabove) would probably consider hierarchy determined firefighters ranks. Robotr3 would consider events generated received message subsequentreasoning cycles, would act accordance plans plan library,show here, simplicity.6. Developing Elaborate Communication Structuressometimes require elaborate communication structures performativesdiscussed Section 4. hand, course important keepcommunication scheme semantic basis simple possible. emphasise that,approach, sophisticated communication structures programmed, topbasic communication features formalised here, use plans implementinteraction protocols. practical AgentSpeak interpreters, communication features(built composing atomic performatives) provided programmers eitherextra pre-defined performatives plan templates plan libraries made publicly availableJason (Bordini & Hubner, 2007), former approach used, latteralso possible. section, give, examples advanced communicationfeatures, plans allow agents reach shared beliefs ensure agents keptinformed adoption goals agents. Note however examplesmake use simple practical feature (available, e.g., Jason) appearabstract syntax used earlier formal presentation: variable instantiatedfirst order term used, within certain constructs (such belief goal additions),place atomic formula, usual also Prolog implementations.Example 1 (Shared Beliefs) network infrastructure reliable, easy ensureagents reach shared beliefs. reaching shared belief, mean two agents believingb well believing agent also believes b. explicitly, say agentsag1 ag2 share belief b ag1 believes b[self] b[ag2], time ag2253fiVieira, Moreira, Wooldridge, & Bordinibelieves b[self] b[ag1]. order allow agents ag1 ag2 reach sharedbeliefs, suffices6 provide agents copies following plans:rsb1+!reachSharedBel(P,A) : P[self]<- +P;!reachSharedBel(P,A).rsb2+!reachSharedBel(P,A) : P[self] & P[A]<- .send(A,tell,P);.send(A,achieve,reachSharedBel(P,me)).rsb3+!reachSharedBel(P,A) : P[self] & P[A]<- true.plans above, stands agents name. (Recall that, Prolog,uppercase initial denotes logical variable.) Assume agent ag1 plansplan, instance currently set intentions, requiresag2 share belief p(X). plan would following goal body:!reachSharedBel(p(X),ag2). would eventually lead execution plansexample above, explained. plan labelled rsb1 says ag1(new) goal reaching shared belief P agent A, case ag1 yet believeP itself, first make sure believes P note +P; bodyplan add ground predicate bound P source self new belief agentag1 goal reaching shared belief (noterecursive plan). time, plan rsb1 longer applicable, rsb2 chosenexecution. Plan rsb2 says that, provided ag1 believes P yet believeagent believes P, tell agent (ag1) believes P, finally askalso achieve shared belief ag1.Agent ag2, also copies plans example above, would then, givenappropriate SocAcc function, instance plan rsb1 set intentions,eventually execute rsb2 well, directly rsb2 case may be. Notelast line plan rsb2, executed agent asked reach shared believe,rather one took initiative, redundant lead agentusing rsb3, says action required, given sharedbelief already obtained. Clearly, efficient ways implementingprotocol reaching shared belief, present plansused regardless whether agent takes initiative reach shared belief not.version give therefore arguably elegant, symmetry facilitatesreasoning protocol.6. Even agents plans advance, willing told reach sharedbeliefs (by accepting TellHow messages agents know-how), become capablereaching shared beliefs too.254fiSpeech-Act Based Communication Agent Programminggive another example, shows agents informationrequests goal adoption (i.e., ask another agent achieve stateaffairs behalf).Example 2 (Feedback Goal Adoption) often case that, one agent asksanother agent something, may want least reassuranceagent agreed whatever asked. Furthermore, may wantknow agent believes accomplished task. following plansused ag1 delegate tasks ag2 way.ag1 plans:nsd1+needDoneBy(G,A) : delegatedTo(G,A)<- +delegatedTo(G,A);.send(A,achieve,doAndFeedbackTo(G,me)).nsd2+needDoneBy(G,A): agreedToDo(G)[A] & finishedDoing(G)[A]<- .send(A,tell,shouldHaveFinished(G));...nsd3+needDoneBy(G,A) : finishedDoing(G)[A]<- ......fd+finishedDoing(G)[A] : true<- -delegatedTo(G,A);-agreedToDo(G)[A].ag2 plans:dft1+!doAndFeedbackTo(G,A) : cntxt1<- .send(A,tell,agreedToDo(G));+!G;.send(A,tell,finishedDoing(G)).dft2+!doAndFeedbackTo(G,A) : cntxt2<- .send(A,tell,cannotDo(G)).255fiVieira, Moreira, Wooldridge, & Bordiniexample above, assume something perceived environment leadsagent believe needs goal G achieved agent A,perception recurs certain intervals, need motivated request still existsresult achieving G observed. Plan nsd1 used needoccurs request yet sent A. plan ensures ag1 rememberalready asked (say, ag2) G agent achieve goal associatedspecial plan: see plan dft1 ag2. plan makes sure requesting agentinformed ag2 adopted goal requested (before attempts achieveit) well agent believes achieved G. programmer defineSocAcc function ag2 accepts requests ag1, programmer stilldetermine autonomous ag2 using appropriate plan contexts. plan dft1,context cntxt1 would determine circumstances agent ag2 believesable adopt goal, context cntxt2 , plan dft2, used circumstancesag2 simply inform adopt goal requested ag1 (aelaborate plan could explain agent cannot adopt goal, example caseone situation goal cannot adopted).Going back plans nsd2 nsd3 agent ag1, former used put pressureagent adopted ag1s goal G, need perceivedalready agreed that, presumably fast enough. Clearly,shouldHaveFinished belief trigger plan ag2 desiredeffect. Plan nsd3 template one various alternative courses actionstaken ag1 need motivated request ag2 adopt goal still existsag2 believes goal already achieved: might old belief needsrevised new request made, ag1 could try asking another agent, inform ag2belief achieving G might wrong, etc. Plan fd used simply removeunnecessary beliefs used previous stages interaction aimed goal adoption.difficult see plans important multi-agent issues, ensuringagents jointly committed course action, developed elaboratingcombinations communication performatives along lines examples above.hand, many complications related agent interaction might needaccounted could addressed simple examples provided here,shared beliefs becoming inaccurate passage time. plans goones shown would required coping complications, necessaryparticular applications.7. Proving Communication Properties AgentSpeak AgentsBordini Moreira (2004) introduced framework proving BDI propertiesAgentSpeak agents based operational semantics. framework included precisedefinitions BDI modalities interpreted terms configurations transition system gives semantics AgentSpeak. definitions usedwork model checking AgentSpeak (Bordini et al., 2004), allows useautomated techniques verification AgentSpeak programs. Below, give exampleproof using operational semantics simple property involves beliefmodality. belief modality clear respect AgentSpeak agent, given256fiSpeech-Act Based Communication Agent Programmingarchitecture includes belief base explicitly, avoid need discusspaper previous work interpretation modalities (Bordini & Moreira, 2004).Proposition 1 (Reachability Shared Beliefs) two AgentSpeak agents ag1ag2 plan libraries rsb1, rsb2, rsb3 plans shown Example 1, also appropriate SocAcc function well usual implementation selection functions (or others fairness also guaranteed, senseevents intentions eventually selected), moment time ag1reachSharedBel(b,ag2 ) goal set events (i.e., eventh+!reachSharedBel(b,ag2 ), ii, intention), eventually agents believe b believe agent also believes b note formulatedusing BDI-like logic top LTL3((Bel ag1 b[self ]) (Bel ag2 b[ag1 ]) (Bel ag2 b[self ]) (Bel ag1 b[ag2 ])).Proof.assumed ag1 h+!reachSharedBel(b, ag2 ), ii set events.Assume precisely event selected rule SelEv1 applied.rule Rel1 would select plans rsb1, rsb2, rsb3 relevant chosen event. RuleAppl1 would narrow rsb1 as, presumably, ag1 yet believe bitself. Rule SelAppl would necessarily select rsb1 intended means, givenapplicable plan, rule IntEv would include i[rsb1] set intentions (i.e.,chosen intended means would pushed top intention generatedevent above). Consider reasoning cycle (for simplicity), rule SelInt1would choose precisely intention execution within reasoning cycle. ruleAddBel would add b[self ] ag1 belief base, hence (Bel ag1 b[self ]).subsequent reasoning cycles, ag1 intention selection function selectsintention execution, rule AchvGl would generate internal eventh+!reachSharedBel(b, ag2 ), ii. process expect plan rsb1longer applicable, rsb2 is, therefore chosen intended means.plan executed (similarly described above), rule ExecActSnd would add messagehmid1 , ag2 , Tell , bi ag1 MOut component. Rule MsgExchg ensures message hmid, ag1 , Tell , bi added ag2 MIn component, beginningnext reasoning cycle would lead rule Tell adding b[ag1 ] ag2 belief base, hence(Bel ag2 b[ag1 ]). intention selected execution third reasoning cycle, final formula body plan rsb1 would executed. use similar rules sending receiving messages, would ag2 receiving messagehmid2 , ag1 , Achieve, reachSharedBel(b, ag1 )i, rule Achieve used interpretingillocutionary force message, thus adding event h+!reachSharedBel(b, ag1 ), iiag2 set events. Note precisely process started ag1sequence rules apply ag2 , will, symmetrically, lead(Bel ag2 b[self ]) (Bel ag1 b[ag2 ]) true, eventually. point time((Bel ag1 b[self ]) (Bel ag2 b[ag1 ]) (Bel ag2 b[self ]) (Bel ag1 b[ag2 ])).discussed earlier, ag2 using exact copies plans used ag1 , ag2also ask ag1 reach b shared belief, even though ag1 already executed part257fiVieira, Moreira, Wooldridge, & Bordinijoint plan. plan rsb3 important. ensures agent actpart joint plan reaching shared belief alreadyachieved.Note, however, possible guarantee shared belief reachedpossible runs neither agent plans interfere negatively executionplans given Example 1, example forcing deletion instancebelief b shared belief reached. verification exercise differentproposition wanted prove, showing shared beliefs reached (undergiven assumptions).8. Applications AgentSpeak Ongoing Workmention applications written AgentSpeak. AgentSpeak programming language also used academia student projects various courses.noted, however, language clearly suited large range applications known BDI systems appropriate; various applications PRS(Georgeff & Lansky, 1987) dMARS (Kinny, 1993), example, appearedliterature (Wooldridge, 2002, Chapter 11).One particular area application great interest Social Simulation(Doran & Gilbert, 1994). fact, AgentSpeak used part project produceplatform tailored particularly social simulation. platform called MAS-SOC developed Bordini, da Rocha Costa, Hubner, Moreira, Okuyama, Vieira (2005);includes high-level language called ELMS (Okuyama, Bordini, & da Rocha Costa,2005) describing environments shared multiple agents. approachused develop, example, social simulation social aspects urban growth (Krafta,de Oliveira, & Bordini, 2003). Another area application initially exploreduse AgentSpeak defining behaviour animated characters computeranimation virtual reality environments (Torres, Nedel, & Bordini, 2004).recently, AgentSpeak used implementation team goldminers entry agent programming competition (Bordini, Hubner, & Tralamazza,2006). scenario7 , teams agents must coordinate actions order collectmuch gold deliver gold trading agent located depotgold safely stored. AgentSpeak team, composed four mining agents oneleader helped coordinate team miners, competition 2006. worthnoting language support high-level communication (formalised paper)proved important feature designing implementing system.AgentSpeak interpreter multi-agent platform Jason constantly improved, long term goal supporting various multi-agent systems technologies.important aspect Jason precisely formal semanticsessential features. Various projects currently looking extending Jason variousways, example combine organisational model one proposeHubner, Sichman, Boissier (2004). particularly important given socialstructure fundamental notion developing complex multi-agent systems. Anotherarea development incorporate ontologies AgentSpeak belief base (Moreira,7. See http://cig.in.tu-clausthal.de/CLIMAContest/ details.258fiSpeech-Act Based Communication Agent ProgrammingVieira, Bordini, & Hubner, 2006; Vieira, Moreira, Bordini, & Hubner, 2006), facilitatinguse Jason Semantic Web applications. Recent work also considered automatedbelief revision (Alechina, Bordini, Hubner, Jago, & Logan, 2006) plan exchange mechanisms (Ancona et al., 2004). detailed description language comparisonagent-oriented programming languages given Bordini et al. (2005).9. Conclusionspointed Singh (1998), various perspectives semantics agentcommunication. Whereas senders perspective common one literature,approach uses primarily receiver. given formal semanticsprocessing speech-act based messages AgentSpeak agent. Previous attemptsdefine semantics agent communication languages (e.g., Labrou & Finin, 1994)based pre-condition action post-condition approach, referring agent mental states modal languages typically based Cohen Levesques work intention(1990a). semantics communication, besides closely linked implementation (as serves specification interpreter agent programminglanguage), also used proof communication properties (Wooldridge, 2000c).work somewhat related de Boer, van Eijk, Van Der Hoek, Meyer(2000) van Eijk, de Boer, Van Der Hoek, Meyer (2003), also provideoperational semantics agent communication language. However, workconsider effects communication terms BDI-like agents (such writtenAgentSpeak). idea giving semantics speech-act based communication withinBDI programming language first introduced Moreira et al. (2004). Subsequently,Dastani, van der Ham, Dignum (2003) also published initial work semantics communication 3APL agents, although emphasis formalisingmessage exchange mechanisms synchronous asynchronous communication.contrast, largely abstract away specific message exchange mechanism (thisformalised high level semantics), interested asynchronouscommunication (which usual communication model cognitive agents). orderillustrate message exchange mechanism, Dastani et al. gave semantics effectsreceiving treating request inform messages is, considerinformation exchange. work uses much comprehensive selection illocutionaryforces, main contribution precisely giving detailed semantics waysvarious illocutionary forces affect mental states agents implementedprogramming language actually precise definitions notions BDIarchitecture. denotational semantics agent communication languages proposedGuerin Pitt (2001), semantics given abstract version ACLaddress issues interaction ACL componentsagent architecture.paper provided new semantic rules illocutionary forces usedcommunication language AgentSpeak agents. giving semantics communicatingAgentSpeak agents, provided means implementation AgentSpeakinterpreters functionality, well given computationally groundedsemantics speech-act based agent communication. fact, operational semantics259fiVieira, Moreira, Wooldridge, & Bordinipresented paper proved useful implementation AgentSpeak interpretersJason (Bordini & Hubner, 2007). Singhs proposal social-agency basedsemantics (1998) may appropriate general purpose agent communication languagesFIPA KQML, within context BDI agent programming language,approach used without drawbacks pointed Singh.fact deal intentional states agents giving semantics communication leads us number related pragmatic questions. First, manytreatments speech-act style communication make use mutual mental states mutualbelief, common knowledge, similar. make use mutual mental statesformalisation. good reasons this. First, although mutual mental statesuseful elegant tool analysis, known represent theoretical idealisationsonly, cannot achieved systems admit possibility message deliveryfailure (Halpern, 1990). Thus, although mutual mental states useful abstractionunderstanding communication works, cannot, realistically, implemented,always mismatch implementation (which excludes possibility mutual mental states faithfully implemented) theory. primarilymutual mental states form part language semantics, built topfundamental communication primitives formalised paper, shownSection 6. Note also known mutual mental states simulated,desired degree nesting, appropriate message acknowledgement scheme (Halpern &Zuck, 1992), therefore approach problem solved mechanismsprocessed messages triggering action sending message acknowledges receipt.also worth adding belief annotation scheme used language permits agentssimple mechanism nested beliefs: annotation source beliefindication agent sent message believed propositional contenttime message sent (but note indication only, unless agent veracityguaranteed). Annotation information source time message received doneautomatically according semantics given. However, programmers alsouse belief base register sent messages, possibly using annotations mannerreceived messages. would function indication agents statesmind, point view sender. plan deal questionslie gray area semantics pragmatics detail future work.discussing models mutual mental states, also mention passingjoint intentions form part semantics, although widely usedimplementation coordination schemes multi-agent systems, following seminalwork Levesque, Cohen, Nunes (1990). fact constructs builtlanguage (or language semantics) primitives precludeimplemented using language constructs, provided usual practical considerationsassumptions, limiting number required acknowledgement messagesachievement shared beliefs, place. Indeed, exactly approach takenTambe, STEAM system (1997), Jennings, GRATE* system (1995).examples Section 6 help indicate achieved elaborationplans, making use communication primitives gave semanticspaper.260fiSpeech-Act Based Communication Agent Programminganticipate readers ponder whether semantics limits autonomyagents use approach communication. provide SocAcc() functionworks initial filter, may give impression beliefsacquired/trusted goals adopted simple filter. important emphasise actual behaviour agent ensuing communication receivedagents completely depends particular plans agent happensplan library; current semantics, ask variants, TellHow , UntellHowperformatives dependent solely SocAcc filter. Example 2, mentionedplan contexts used determine whether agent would actually act towards achieving goal requested another agent, choose commit achievinggoal. general rule: agent autonomy depends plans givenagent programmer obtained communication agents (the plans currentlyagents plan library). would typically programmers responsibility writeplans ensure agent sufficiently autonomous purpose givenapplication or, use interesting notion, program agents adjustable autonomy. Similarly, benevolent self-interested agent be, extentbeliefs acquired agents trusted, issues programmerscareful about: semantics communication ensure one caseother. Needless say, much difficult task program agents takepart open systems agents self-interested cannot trusted.agent programming language combined suitable agent communication languagegives much support task, surely automatically solve problems;still remains complex programming task.also worth commenting semantics used researchers,particularly using agent programming languages AgentSpeak. mainpoint semantics provides reference semantics communicationlanguage used context agent-oriented programming. is, using semantics, possible predict exactly particular AgentSpeak agent would interpretparticular message given situation. Using reference model,principle possible implement communication agent programming languages.course, semantics language independent: developed specificallyAgentSpeak, language specifics ought considered. However, attempts givingsemantics agent communication language independent problems,notably computational grounding problem referred above. semantics,developed specifically practical agent programming language, advantagerelying mechanisms (such abstractly defined mental states) cannot checkedreal programs. note that, best knowledge, work represents firstsemantics given speech-act style, knowledge level communication languageused real system.current work consider commissive declarative speech acts.surely relevant topics future work, since commissive acts declarations relevantvarious forms agent interaction, negotiation. Nevertheless, proposedframework possible programmer multi-agent system designer incorporateelaborate forms interactions writing appropriate plans.261fiVieira, Moreira, Wooldridge, & Bordiniwork, assume communication occurs among agents writtenprogramming language, cannot adopted directly heterogeneous multi-agent systems. (Consider, example, issues arising processing AskHow performative,involves sending plan another agent.) However, variety agentlanguages, difficult write wrappers translating message contents.relevant areas future investigation regarding role definitionssocial structures agent organisations. consider would interesting developments proposed SocAcc() function libraries plans plan patterns. Deonticrelationships social norms also closely related extensions. casee-business, instance, contract usually creates number obligations contractors.Future work also consider giving better formal treatment information sources,particular case plans exchanged agents. communication aspects ontological agreement among AgentSpeak agents, reasoninginformation sources (e.g., executing test goals choosing plans based annotations)also considered future work. expect sophisticated multi-agent systemapplications developed AgentSpeak interpreters implemented accordingsemantics.AcknowledgementsMany thanks Jomi F. Hubner comments suggestions earlier versionpaper, Berndt Farwer Louise Dennis carefully proofread it. firstsecond authors acknowledge support CNPq.ReferencesAlechina, N., Bordini, R. H., Hubner, J. F., Jago, M., & Logan, B. (2006). Automatingbelief revision agentspeak. Baldoni, M., & Endriss, U. (Eds.), ProceedingsFourth International Workshop Declarative Agent Languages Technologies(DALT 2006), held AAMAS 2006, 8th May, Hakodate, Japan, pp. 116.Allen, J. F., Hendler, J., & Tate, A. (Eds.). (1990). Readings Planning. Morgan Kaufmann.Ancona, D., Mascardi, V., Hubner, J. F., & Bordini, R. H. (2004). Coo-AgentSpeak:Cooperation AgentSpeak plan exchange. Jennings, N. R., Sierra, C.,Sonenberg, L., & Tambe, M. (Eds.), Proceedings Third International JointConference Autonomous Agents Multi-Agent Systems (AAMAS-2004), NewYork, NY, 1923 July, pp. 698705 New York, NY. ACM Press.Austin, J. L. (1962). Things Words. Oxford University Press, London.Ballmer, T. T., & Brennenstuhl, W. (1981). Speech Act Classification: StudyLexical Analysis English Speech Activity Verbs. Springer-Verlag, Berlin.262fiSpeech-Act Based Communication Agent ProgrammingBordini, R. H., Bazzan, A. L. C., Jannone, R. O., Basso, D. M., Vicari, R. M., & Lesser,V. R. (2002). AgentSpeak(XL): Efficient intention selection BDI agents via decisiontheoretic task scheduling. Castelfranchi, C., & Johnson, W. L. (Eds.), ProceedingsFirst International Joint Conference Autonomous Agents Multi-AgentSystems (AAMAS-2002), 1519 July, Bologna, Italy, pp. 12941302 New York, NY.ACM Press.Bordini, R. H., da Rocha Costa, A. C., Hubner, J. F., Moreira, A. F., Okuyama, F. Y., &Vieira, R. (2005). MAS-SOC: social simulation platform based agent-orientedprogramming. Journal Artificial Societies Social Simulation, 8 (3). JASSSForum, <http://jasss.soc.surrey.ac.uk/8/3/7.html>.Bordini, R. H., Fisher, M., Pardavila, C., & Wooldridge, M. (2003). Model checkingAgentSpeak. Rosenschein, J. S., Sandholm, T., Wooldridge, M., & Yokoo, M.(Eds.), Proceedings Second International Joint Conference AutonomousAgents Multi-Agent Systems (AAMAS-2003), Melbourne, Australia, 1418 July,pp. 409416 New York, NY. ACM Press.Bordini, R. H., Fisher, M., Visser, W., & Wooldridge, M. (2004). Model checking rationalagents. IEEE Intelligent Systems, 19 (5), 4652.Bordini, R. H., & Hubner, J. F. (2007).Jason:Java-based Interpreter Extended version AgentSpeak (Manual, version 0.9 edition).http://jason.sourceforge.net/.Bordini, R. H., Hubner, J. F., & Tralamazza, D. M. (2006). Using Jason implementteam gold miners (a preliminary design). Inoue, K., Satoh, K., & Toni, F.(Eds.), Proceedings Seventh Workshop Computational Logic Multi-AgentSystems (CLIMA VII), held AAMAS 2006, 89th May, Hakodate, Japan, pp.233237. (Clima Contest paper).Bordini, R. H., Hubner, J. F., & Vieira, R. (2005). Jason Golden Fleeceagent-oriented programming. Bordini, R. H., Dastani, M., Dix, J., & El Fallah Seghrouchni, A. (Eds.), Multi-Agent Programming: Languages, Platforms,Applications, chap. 1. Springer-Verlag.Bordini, R. H., & Moreira, A. F. (2004). Proving BDI properties agent-oriented programming languages: asymmetry thesis principles AgentSpeak(L). AnnalsMathematics Artificial Intelligence, 42 (13), 197226. Special Issue Computational Logic Multi-Agent Systems.Bordini, R. H., Visser, W., Fisher, M., Pardavila, C., & Wooldridge, M. (2003). Modelchecking multi-agent programs CASP. Hunt Jr., W. A., & Somenzi, F. (Eds.),Proceedgins Fifteenth Conference Computer-Aided Verification (CAV-2003),Boulder, CO, 812 July, No. 2725 LNCS, pp. 110113 Berlin. Springer-Verlag. Tooldescription.Bratman, M. E. (1987). Intentions, Plans Practical Reason. Harvard University Press,Cambridge, MA.263fiVieira, Moreira, Wooldridge, & BordiniCastelfranchi, C., & Falcone, R. (1998). Principles trust MAS: Cognitive anatomy,social importance, quantification. Demazeau, Y. (Ed.), Proceedings ThirdInternational Conference Multi-Agent Systems (ICMAS98), 47 July, Paris, pp.7279 Washington. IEEE Computer Society Press.Cohen, P., & Perrault, R. (1979). Elements plan based theory speech acts. CognitiveScience, 3, 177212.Cohen, P. R., & Levesque, H. J. (1990a). Intention choice commitment. ArtificialIntelligence, 42 (3), 213261.Cohen, P. R., & Levesque, H. J. (1990b). Rational interaction basis communication. Cohen, P. R., Morgan, J., & Pollack, M. E. (Eds.), Intentions Communication, chap. 12, pp. 221255. MIT Press, Cambridge, MA.Dastani, M., van der Ham, J., & Dignum, F. (2003). Communication goal directedagents. Huget, M.-P. (Ed.), Communication Multiagent Systems, Vol. 2650LNCS, pp. 239252. Springer-Verlag.de Boer, F. S., van Eijk, R. M., Van Der Hoek, W., & Meyer, J.-J. C. (2000). Failuresemantics exchange information multi-agent systems. Palamidessi, C.(Ed.), Eleventh International Conference Concurrency Theory (CONCUR 2000),University Park, PA, 2225 August, No. 1877 LNCS, pp. 214228. Springer-Verlag.Doran, J., & Gilbert, N. (1994). Simulating societies: introduction. Gilbert, N., &Doran, J. (Eds.), Simulating Society: Computer Simulation ofSocial Phenomena,chap. 1, pp. 118. UCL Press, London.Genesereth, M. R., & Ketchpel, S. P. (1994). Software agents. CommunicationsACM, 37 (7), 4853.Georgeff, M. P., & Lansky, A. L. (1987). Reactive reasoning planning. ProceedingsSixth National Conference Artificial Intelligence (AAAI87), 1317 July,1987,Seattle, WA, pp. 677682 Manlo Park, CA. AAAI Press / MIT Press.Ghallab, M., Nau, D., & Traverso, P. (2004). Automated Planning: Theory Practice.Morgan Kaufmann.Guerin, F., & Pitt, J. (2001). Denotational semantics agent communication language.Proceedings fifth international conference Autonomous Agents (Agents2001), 28th May 1st June, Montreal Canada, pp. 497504. ACM Press.Halpern, J. Y. (1990). Knowledge common knowledge distributed environment.Journal ACM, 37 (3).Halpern, J. Y., & Zuck, L. D. (1992). little knowledge goes long way: knowledge-basedderivations correctness proofs family protocols. Journal ACM,39 (3), 449478.264fiSpeech-Act Based Communication Agent ProgrammingHubner, J. F., Sichman, J. S., & Boissier, O. (2004). Using Moise+ cooperativeframework MAS reorganisation.. Bazzan, A. L. C., & Labidi, S. (Eds.), AdvancesArtificial Intelligence - SBIA 2004, 17th Brazilian Symposium Artificial Intelligence, Sao Luis, Maranhao, Brazil, September 29 - October 1, 2004, Proceedings, Vol.3171 LNCS, pp. 506515. Springer-Verlag.Jennings, N. R. (1995). Controlling cooperative problem solving industrial multi-agentsystems using joint intentions. Artificial Intelligence, 75 (2), 195240.Kinny, D. (1993). distributed multi-agent reasoning system architecture languagespecification. Tech. rep., Australian Artificial Intelligence Institute, Melbourne, Australia.Krafta, R., de Oliveira, D., & Bordini, R. H. (2003). city object human agency.Fourth International Space Syntax Symposium (SSS4), London, 1719 June, pp.33.133.18.Kumar, S., & Cohen, P. R. (2000). Towards fault-tolerant multi-agent system architecture.Proceedings Fourth International Conference Autonomous Agents (Agents2000), 37 June, Barcelona, Spain, pp. 459466. ACM Press.Labrou, Y., & Finin, T. (1994). semantics approach KQMLa general purposecommunication language software agents. Proceedings Third InternationalConference Information Knowledge Management (CIKM94), 29th November2nd December, Gaithersburg, MD. ACM Press.Labrou, Y., Finin, T., & Peng, Y. (1999). current landscape agent communicationlanguages. Intelligent Systems, 14 (2), 4552.Levesque, H. J., Cohen, P. R., & Nunes, J. H. T. (1990). acting together. ProceedingsEighth National Conference Artificial Intelligence (AAAI-1990), 29th July3rd August, Boston, MA, pp. 9499. AAAI Press.Levinson, S. C. (1981). essential inadequacies speech act models dialogue. Parret, H., Sbisa, M., & Verschuren, J. (Eds.), Possibilities limitations pragmatics:Proceedings Conference Pragmatics Urbino, July, 1979, pp. 473492. Benjamins, Amsterdam.Mayfield, J., Labrou, Y., & Finin, T. (1996). Evaluation KQML agent communication language. Wooldridge, M., Muller, J. P., & Tambe, M. (Eds.), IntelligentAgents IIProceedings Second International Workshop Agent Theories, Architectures, Languages (ATAL95), held part IJCAI95, Montreal, Canada,August1995, No. 1037 LNAI, pp. 347360 Berlin. Springer-Verlag.Moreira, A. F., & Bordini, R. H. (2002). operational semantics BDI agent-orientedprogramming language. Meyer, J.-J. C., & Wooldridge, M. J. (Eds.), ProceedingsWorkshop Logics Agent-Based Systems (LABS-02), held conjunctionEighth International Conference Principles Knowledge RepresentationReasoning (KR2002), April 2225, Toulouse, France, pp. 4559.265fiVieira, Moreira, Wooldridge, & BordiniMoreira, A. F., Vieira, R., & Bordini, R. H. (2004). Extending operational semanticsBDI agent-oriented programming language introducing speech-act based communication. Leite, J., Omicini, A., Sterling, L., & Torroni, P. (Eds.), DeclarativeAgent Languages Technologies, Proceedings First International Workshop(DALT-03), held AAMAS-03, 15 July, 2003, Melbourne, Australia (Revised Selected Invited Papers), No. 2990 LNAI, pp. 135154 Berlin. Springer-Verlag.Moreira, A. F., Vieira, R., Bordini, R. H., & Hubner, J. F. (2006). Agent-oriented programming underlying ontological reasoning. Baldoni, M., Endriss, U., Omicini, A.,& Torroni, P. (Eds.), Proceedings Third International Workshop DeclarativeAgent Languages Technologies (DALT-05), held AAMAS-05, 25th July,Utrecht, Netherlands, No. 3904 LNCS, pp. 155170. Springer-Verlag.Okuyama, F. Y., Bordini, R. H., & da Rocha Costa, A. C. (2005). ELMS: environmentdescription language multi-agent simulations. Weyns, D., van Dyke Parunak,H., Michel, F., Holvoet, T., & Ferber, J. (Eds.), Environments Multiagent Systems, State-of-the-art Research Challenges. Proceedings First InternationalWorkshop Environments Multiagent Systems (E4MAS), held AAMAS-04,19th July, No. 3374 LNAI, pp. 91108 Berlin. Springer-Verlag.Plotkin, G. (1981). structural approach operational semantics.. Technical Report,Department Computer Science, Aarhus University.Rao, A. S. (1996). AgentSpeak(L): BDI agents speak logical computable language.van de Velde, W., & Perram, J. (Eds.), Proceedings 7th Workshop Modelling Autonomous Agents Multi-Agent World (MAAMAW96), 2225 January,Eindhoven, Netherlands, No. 1038 LNAI, pp. 4255 London. Springer-Verlag.Rao, A. S., & Georgeff, M. P. (1998). Decision procedures BDI logics. Journal LogicComputation, 8 (3), 293343.Searle, J. R. (1969). Speech Acts: Essay Philosophy Language. CambridgeUniversity Press, Cambridge.Singh, M. P. (1994). Multiagent SystemsA Theoretic Framework Intentions, KnowHow, Communications. No. 799 LNAI. Springer-Verlag, Berlin.Singh, M. P. (1998). Agent communication languages: Rethinking principles. IEEEComputer, 31 (12), 4047.Smith, R. G. (1980). contract net protocol: High-level communication controldistributed problem solver. IEEE Transactions Computers, c-29 (12), 11041113.Tambe, M. (1997). Towards flexible teamwork. Journal Artificial Intelligence Research,7, 83124.Torres, J. A., Nedel, L. P., & Bordini, R. H. (2004). Autonomous agents multiple fociattention virtual environments. Proceedings 17th International ConferenceComputer Animation Social Agents (CASA 2004), Geneva, Switzerland, 79July, pp. 189196.266fiSpeech-Act Based Communication Agent Programmingvan Eijk, R. M., de Boer, F. S., Van Der Hoek, W., & Meyer, J.-J. C. (2003). verificationframework agent communication. Autonomous Agents Multi-Agent Systems,6 (2), 185219.Vieira, R., Moreira, A. F., Bordini, R. H., & Hubner, J. (2006). agent-oriented programming language computing context. Debenham, J. (Ed.), ProceedingsSecond IFIP Symposium Professional Practice Artificial Intelligence, held19th IFIP World Computer Congress, TC-12 Professional Practice Stream, 2124August, Santiago, Chile, No. 218 IFIP, pp. 6170 Berlin. Springer-Verlag.Wooldridge, M. (1998). Verifiable semantics agent communication languages. Proceedings Third International Conference Multi-Agent Systems (ICMAS98),47 July, Paris, pp. 349365. IEEE Computer Society Press.Wooldridge, M. (2000a). Computationally grounded theories agency. Durfee, E. (Ed.),Proceedings Fourth International Conference Multi-Agent Systems (ICMAS2000),1012 July, Boston, pp. 1320 Los Alamitos, CA. IEEE Computer Society.Paper Invited Talk.Wooldridge, M. (2000b). Reasoning Rational Agents. MIT Press, Cambridge,MA.Wooldridge, M. (2000c). Semantic issues verification agent communication languages. Autonomous Agents Multi-Agent Systems, 3 (1), 931.Wooldridge, M. (2002). Introduction MultiAgent Systems. John Wiley & Sons.267fiJournal Artificial Intelligence Research 29 (2007) 79-103Submitted 09/06; published 06/07NP Animacy Identification Anaphora ResolutionConstantin OrasanRichard EvansC.Orasan@wlv.ac.ukR.J.Evans@wlv.ac.ukResearch Group Computational LinguisticsSchool Humanities, Languages Social SciencesUniversity WolverhamptonStafford St., Wolverhampton, WV1 1SBUnited KingdomAbstractanaphora resolution English, animacy identification play integral roleapplication agreement restrictions pronouns candidates, result,improve accuracy anaphora resolution systems. paper, two methodsanimacy identification proposed evaluated using intrinsic extrinsic measures.first method rule-based one uses information unique beginnersWordNet classify NPs basis animacy. second method reliesmachine learning algorithm exploits WordNet enriched animacy informationsense. effect word sense disambiguation two methods also assessed.intrinsic evaluation reveals machine learning method reaches human levelsperformance. extrinsic evaluation demonstrates animacy identificationbeneficial anaphora resolution, especially cases animate entitiesidentified high precision.1. IntroductionAnaphora resolution process attempts determine meaning expressionspronouns definite descriptions whose interpretation depends previouslymentioned entities discourse segments. Anaphora resolution importantmany fields computational linguistics machine translation, natural languageunderstanding, information extraction text generation (Mitkov, 2002).Previous work anaphora resolution (AR) shown levels performancerelated type text processed average number nounphrases (NPs) consideration pronouns antecedent (Evans & Orasan, 2000).Acknowledging this, researchers proposed incorporated various methods intendedreduce number candidate NPs considered anaphora resolution systems.approaches pronominal anaphora resolution rely compatibility agreementfeatures pronouns antecedents, means minimising number NPcandidates. Although, noted Barlow (1998) Barbu, Evans, Mitkov (2002),assumption always hold, reliable enough cases great practicalvalue anaphora coreference resolution systems. systems rely knowledgenumber gender NP candidates order check compatibilitypronouns candidates (Hobbs, 1976; Lappin & Leass, 1994; Kennedy & Boguraev, 1996;Mitkov, 1998; Cardie & Wagstaff, 1999; Ng & Cardie, 2002). addition numberc2007AI Access Foundation. rights reserved.fiOrasan & Evansgender compatibility, researchers reduced number competing candidates consideredsystems means syntactic filters (Hobbs, 1976; Lappin & Leass, 1994), semanticfilters (Hobbs, 1978) discourse structure (Brennan, Friedman, & Pollard, 1987; Cristea,Ide, Marcu, & Tablan, 2000).English, automatic identification specific gender NPs difficult taskarguably limited utility. Despite this, numerous researchers (Hale & Charniak, 1998;Denber, 1998; Cardie & Wagstaff, 1999) proposed automatic methods identifyingpotential gender NPs referents. paper, problem animacy identificationtackled. concern animacy opposed gender arises observationanimacy serves reliable basis agreement pronouns candidates (seeexamples Section 2). Animacy identification useful tasks like anaphoraresolution coreference resolution level ambiguity reduced filteringcandidates value animacy anaphor, wellquestion answering, used improve system responses questionsallowing ensure generated answers consist animate references.research, NP considered animate referent also referredusing one pronouns he, she, him, her, his, hers, himself, herself, combinationpronouns (e.g. his/her ). Section 2 provides clarity definition, consideringrange exceptions problematic cases, well examining consequencestreatment animacy. corpus used research described Section 3.paper several methods animacy identification proposed evaluated. First,simple statistical method based WordNet (Fellbaum, 1998) described Section4.1. Following description simple statistical method, machine learningmethod overcomes problems simple method, offering improvedperformance, described Section 4.2. latest stages development, word sensedisambiguation (WSD) added improve accuracy classification.presented Section 4.3. Section 5, systems evaluated using intrinsicextrinsic evaluation methods, noted machine learning methods reachhuman performance levels. Finally, Section 6 dedicated related work followedconclusions.2. Constitutes Animate Noun Phrase?argued English nouns classified grammatically, semanticallyaccording coreferential relations personal, reflexive wh-pronouns (Quirk,Greenbaum, Leech, & Svartvik, 1985, p. 314). According classification, animatenoun phrases contain personal (e.g. male, female, dual, common collective nouns)non-personal noun phrases (e.g. common, collective animal nouns). paper,goal design method improves performance anaphora resolutionmethods filtering candidates agree terms animacy givenreferential pronoun. reason, specific definition animacy givenintroduction used. means paper, noun phrases normallyreferred pronouns possessive reflexive forms,considered animate, distinction made pronouns determinegender. view adopted because, linguistic processing English documents,80fiNP Animacy Identification Anaphora ResolutionFigure 1: Quirk el. al. (1985) vs classification animacy. (Adapted Quirk el. al.(1985, p. 314, Fig. 5.104))vital distinguish neuter animate references problematic, oftenlimited utility, distinguish masculine feminine ones.illustrate, sentence primary user machine selectsettings, considering noun phrase primary user machine eithermasculine feminine, applying strict agreement constraints referencesubsequent pronominal ones, adversely affect performance referenceresolution systems constraints eliminate antecedent listcandidates one pronouns depending gender attached NP. Ideally,reference considered animate - compatible, terms agreement, subsequentanimate pronouns, incompatible neuter pronouns.Figure 1 presents differences Quirk et. al.s (1985) classification animacyone used paper. seen figure, definition animatenouns much wider used paper. consider classes presentedQuirk et al.s (1985), animate entities male, female, dual 1 commongender 2 nouns.Common gender nouns defined Quirk et al. (1985) intermediatepersonal non-personal nouns. us, animacy either animate inanimate,depending pronoun used refer them. However, animacycommon nouns cat depends upon perception entity speaker/writer.noun used refer pet, speaker/writer also likely use animate1. Dual nouns nouns refer people whose gender underspecified artist, cook, etc.2. Figure 1 nouns labeled common.81fiOrasan & Evanspronouns rather inanimate ones refer it. circumstances detectedmethod: may focus methods try identify sentimentsspeakers/writers towards entities.Collective nouns team, refer sets animate entities, may intuitivelyconsidered animate. However, suitable pronominal references denotationphrases singular neuter pronouns plural pronouns unspecified gender.referents never referred using animate pronouns. Given raison detreresearch animacy identification facilitation real-world anaphora resolution,NPs considered inanimate current work, animateQuirk et al. (1985).Collective nouns people pose problems annotation processing.contexts word people used plural form person, caseconsidered animate definition presented earlier. However casesused generically refer national populations (e.g. peoples Asia)case considered inanimate. light this, seems class worddepends context. However, practical terms, morpho-syntactic parsing softwareuse (Tapanainen & Jarvinen, 1997) returns people person rootnoun, reason, noun people considered inanimate purposes.reasoning applied similar nouns. drawback approachannotators find intuitive result errors introducedannotation (as discussed next section).rest categories introduced Quirk et al. (1985): non-personal higher, nonpersonal lower inanimate correspond definition inanimate nouns.common gender nouns, possible non-personal higher lower nounshorse rabbit pets therefore referred speakers usingshe. cannot detect usages, considered inanimate.3present work, animacy noun phrase (NP) considered deriveanimacy head. illustrate, man dead man referred usinganimate pronoun. Moreover, considering animacy plural NPsmileage claimants, singular form mileage claimant derived used basisclassification plural form shares animacy singular form.way, treatment NP animacy mirrors treatment grammatical numberGovernment Binding Theory (Chomsky, 1981). approach, projectionprinciple implies agreement information NP derived head.paper, animacy common nouns determined propernouns named entities (NE). reason separate task namedentity recognition normally used classify NEs different categories person,organization, location. Given label entities similar semantic types,categories used determine animacy entities belongthem. acknowledged named entity recognition important componentidentification animate references, one lies beyond scope presentwork. Methods based semantics, ones described Section 4 especiallyvulnerable errors caused failure recognise difference words3. Actually basis explanation provided Quirk et al. (1985) distinction commonnouns higher lower non-personal nouns latter personified seems fuzzy.82fiNP Animacy Identification Anaphora Resolutionwordsanimate entitiesinanimate entitiesPercentage animate entitiesTotal entitiesSEMCOR104,6122,32117,38012%19,701AI15,7675382,58621%3,124Table 1: characteristics two corpora usedCat Bob used common nouns inanimate references proper nounsanimate references.3. Corpus-Based Investigationidentification NP animacy, described previous section, amenablecorpus-based solution. research two corpora used: first collectiontexts Amnesty International (AI) selected contain relativelylarge proportion references animate entities. second selection textsSEMCOR corpus (Landes, Leacock, & Tengi, 1998), chosen nounsannotated senses WordNet. annotation made suitable exploitationdevelopment automatic method animacy identification described Section4.2. SEMCOR corpus built basis Brown Corpus (Frances & Kucera,1982) experiments use texts newswire, science, fiction humor.order make data suitable evaluation purposes, NPs two corporamanually annotated information animacy. characteristicscorpora summarized Table 1. seen table, even though textscontain many references animate entities selected, number inanimateentities still much larger number animate ones.assess difficulty annotation task, implicitly, estimate upperperformance limit automatic methods, second annotator asked annotate partcorpus inter-annotator agreement calculated. end, whole AIcorpus, nine texts 3,500 references SEMCOR corpusrandomly selected annotated. Comparison two annotations revealedlevel agreement 97.5% two annotators value 0.91 kappastatistic indicates high agreement annotators. agreementSEMCOR data slightly higher AI corpus, differencestatistically significant.Investigation annotation performed two annotators discussionrevealed main source disagreement monotony task.two annotators use simple interface displayed sentence one NPtime, required indicate whether NP animate inanimate choosingone two key strokes. Due large number inanimate entities corpus,annotators often marked animate entities inanimate accidentally. casesnoticed mistake corrected it, likely many mistakes wentunobserved.83fiOrasan & EvansAnother source disagreement collective nouns people, government, juryfolk according discussion Section 2 normally marked inanimate.cases, context NP tiredness part annotator lederroneously marked animate. Similarly, noticed annotatorswrongly considered plural noun phrases observers, delegates, communists,assistants collective ones marked inanimate. However, likelyerrors introduced due monotony task. Unfamiliar nounsthuggee, words used specialized domains baseball also causeddifficulties. Finally, another source error arose use Connexors FDG Parser(Tapanainen & Jarvinen, 1997) identify noun phrases annotation. result,noun phrases recognized system ambiguous (e.g. specialistsbusy people presented one NP according definition animacy adoptedpresent work, specialists animate, whereas busy people inanimate4 .).4. Methods Animacy Identificationcontrast situation proper name recognition classification,exploit surface textual clues capitalization explicit occurrence wordssmall gazetteer titles, knowledge animacy common NPs appears purelyimplicit. Recognition references animate entities must, point, groundedworld-knowledge computed explicit features text. section presentstwo methods developed animacy identification rely information extractedWordNet, electronic lexical resource organized hierarchically relations setssynonyms near-synonyms called synsets (Fellbaum, 1998). first method rulebased one employs limited number resources presented Section 4.1.shortcomings addressed machine learning method presented Section 4.2.methods consider senses word taking decision animacy.reason, word sense disambiguation (WSD) module briefly discussed Section 4.3integrated them.4.1 Rule-Based MethodWordNet, four primary classes content-words (nouns, verbs, adjectivesadverbs) arranged small set top-level hypernyms called unique beginners(Fellbaum, 1998). Investigation unique beginners revealed severalinterest respect aim identifying animate entities text. casenouns 25 unique beginners, three expected hypernyms sensesnouns usually refer animate entities. animal, reference number (05),person (18), relation (24).5 also four verb sense hierarchies fourteen,allow inference made subject NPs animate. uniquebeginners cases cognition (31), communication (32), emotion (37) social4. argued singular form people person, therefore markedanimate. However, discussed Section 2 due way processed preprocessing toolsemployed here, annotators asked consider inanimate5. unique beginner animal corresponds animate inanimate entities relation subsumesmainly human relationships brother, sister, parent, etc.84fiNP Animacy Identification Anaphora Resolution(41).6 noted inanimate entities organizations animals alsoagents types verb, expected general case instancesrare enough ignore. light way WordNet organized, clearcould exploited order associate heads noun phrases measureconfidence associated NP either animate inanimate referent.common noun one meaning, many casescorresponding sense hierarchies start different unique beginners.reason, decision whether noun phrase animate inanimate takenpossible senses head noun consulted. Givensenses animate whilst others inanimate, algorithm countsnumber animate senses listed noun (hyponyms unique beginners 05, 18,24) number inanimate senses (hyponyms remaining unique beginners)proposed. Two ratios computed noun:N oun animacy (N A) =N oun inanimacy (N I) =N umber animate sensesotal number sensesN umber inanimate sensesotal number sensescompared pre-defined thresholds order classify animate inanimate.Similarly, case nouns heads subject NPs, counts madeanimate inanimate senses verbs subjects used calculate Verbanimacy (VA) Verb inanimacy (VI) way NA NI. ratiosalso used determine animacy subject NP. Finally, contextual rules (e.g.presence NP-internal complementizers reflexives )applied order improve classification. algorithm presented Algorithm 1evaluated Section 5. three thresholds used algorithm determinedexperimentation best values found t1 = 0.71, t2 = 0.92t3 = 0.90.4.2 Machine Learning Animacy Identificationmethod presented previous section two main weaknesses. first oneunique beginners used determine number animate/inanimate sensesgeneral, cases reliably indicate animacy senseclass. second weakness due nave nature rules decide whether NPanimate not. application simple involves comparison values obtainedNP threshold values determined basis relatively smallnumber experiments. light problems, two step approach, addressingone aforementioned weaknesses, proposed. first step, annotated corpusused determine animacy WordNet synsets. process presented Section4.2.1. information propagated whole WordNet, usedmachine learning algorithm determine animacy NPs. method presentedSection 4.2.2.6. social unique beginner subsumes relations abdicate, educate socialize.85fiOrasan & Evans123456789101112131415161718Data: NP noun phrase animacy determined, t1 , t2 , t3Result: animacy NPCompute NA, NI, VA, VI NP;N > t1NP animate;Stop;endN > t2NP inanimate;Stop;end(N > N I) (V > V I)NP animate;Stop;end(NP contains complementizer who) (V > t3 )NP animate;Stop;endNP inanimate;1: rule-based algorithm used determine animacy noun phrase4.2.1 Classification Sensespreviously mentioned, unique beginners general satisfactorily classifiedwholly animate inanimate. However, mean possibleuniquely classify specific senses animate inanimate. section, corpusbased method classifies synsets WordNet according animacy presented.starting point classifying synsets information presentannotated version SEMCOR corpus. reason addinganimacy annotation nouns annotated corresponding senseWordNet, information could used determine animacy synset. However,due linguistic ambiguities tagging errors senses classified adequatelyway. Moreover, many senses WordNet appear SEMCOR, meansdirect animacy information determined them. order addressproblem, decision made use bottom procedure begins classifyingunambiguous terminal nodes propagates information general nodes.terminal node unambiguously classified using information annotated filesoccurrences corpus annotated class. way,general node unambiguously classified hyponyms assignedclass.Due annotation errors rare uses sense, condition rarely metstatistical measure must employed order test animacy general node.simple approach classifies synset using simple voting procedure behalf86fiNP Animacy Identification Anaphora ResolutionFigure 2: Example showing propagation animacy corpus generalsenseshyponyms unsatisfactory necessary know node generalable assign one classes. reason statistical measure useddetermine animacy node ambiguous cases.statistical measure used process chi-squared, non-parametric testused estimate whether significant difference twodifferent populations. order test whether node animate, two populationscompared are:1. observed population consists senses nodes hyponymsannotated animate,2. hypothetical population nodes hyponyms animate.chi-square indicates difference two populationsnode classified animate. process repeated order classify inanimatenode. neither test passed, means node general,hypernyms equally refer animate inanimate entities. unambiguous cases(i.e. hyponyms observed corpus7 annotated either animateinanimate, both), general node classified hyponyms are. wayinformation propagated corpus WordNet presented Figure 2.illustrate, general node n hyponyms contingency table(Table 2) built used determine animacy. hyponym considered7. Either directly indirectly via hyponymy relations.87fiOrasan & EvansObservedExpectedSense1ani1ani1 + inani1Sense2ani2ani2 + inani2Sense3ani3ani3 + inani3.........Sensenaninanin + inaninTable 2: Contingency table testing animacy hypernymtwo attributes: number times annotated animate (anii )number times annotated inanimate (inanii ). figures aniiinanii include number times sense directly appears corpusnumber times appears indirectly via hyponyms. Given system testingsee whether general node animate not, hyponyms, totalnumber occurrences sense annotated corpus expected value (meaninginstances animate marked animatemarked way annotation error rare usage sense) numbertimes hyponym annotated referring animate entity observed value.Chi-square calculated, result compared critical level obtained n 1degrees freedom significance level .05. test passed, generalnode classified animate.order valid test significance, chi-square usually requires expected frequencies5 more. contingency table larger two-by-two, exceptionsallowed long expected frequency less one 20%expected frequencies less 5 (Sirkin, 1995). present case possibleexpected frequencies less one would entail presence corpus.If, test applied, 20% senses expected frequency less5, two similar senses lowest frequency merged test repeated.8senses merged still 20% expected frequencies less5, test rejected.approach used classify nodes WordNet animate, inanimateundecided. approach also employed classify animacy verbsbasis animacy subjects. assessment coverage providedmethod revealed almost 94% nodes WordNet classified animateinanimate. mainly due fact general nodes person,plant abstraction classified without ambiguity result hyponymsclassified way. enriched version WordNet used classifynouns described next section.4.2.2 Classification Nounclassification described previous section useful determining animacysense, even previously found annotated corpus,hyponyms node classified. However, nouns whose sense unknowncannot classified directly therefore additional level processing necessary.8. context, two senses considered similar attribute (i.e. animacyinanimacy) equal zero.88fiNP Animacy Identification Anaphora Resolutionsection, use timbl (Daelemans, Zavrel, van der Sloot, & van den Bosch, 2000)determine animacy nouns described.Timbl program implements several machine learning techniques.Experimenting algorithms available timbl different configurations, bestresults obtained using instance-based learning gain ratio weighting measure(Quinlan, 1993; Mitchell, 1997). type learning, instances stored withouttrying infer anything them. classification stage, algorithm comparespreviously unseen instance data stored training stage. frequentclass k nearest neighbors assigned class instance belongs.experimentation, noticed best results obtained three nearestneighbors used (k=3), distance two instances calculated using overlapmetric importance feature weighted using gain ratio (Daelemans et al.,2000).present case, instances used training classification consistfollowing information:1. lemma noun classified.2. number animate inanimate senses word. mentioned before,cases animacy sense known, inferred hypernyms.information cannot found words hypernyms, informationunique beginners words sense used, manner similar usedrule-based system described Section 4.1.3. heads subject NPs, number animate/inanimate senses verb.senses classification known, algorithm similarone described nouns employed. values 0 heads non-subjects.4. ratio number animate singular pronouns (e.g she) inanimatesingular pronouns (e.g. it) whole text. justification featuretext containing large number gender marked pronouns likelymention many animate entitiesfeatures encoded vectors classified timbl using algorithmsettings described earlier. algorithm described section evaluated Section 5.4.3 Word Sense Disambiguationdifficult disambiguate possible senses words unrestricted texts,difficult identify senses likely used text others.information considered methods presented Sections 4.1 4.2.Instead, methods, senses considered equal weight. orderaddress shortcoming, word sense disambiguation (WSD) method describedResnik (1995) implemented used classification algorithm. WSD methodcomputes weight possible sense noun considering nounstext. weights used compute number animate/inanimate senses.underlying hypothesis animacy/inanimacy senses likely89fiOrasan & Evansused particular text count improbable senses. impactapproach animacy identifiers presented previous section also evaluated.5. Evaluation Systemssection, systems presented Section 4 evaluated using intrinsicextrinsic evaluation methods (Sparck Jones & Galliers, 1996). evaluation methodsnecessary aim find methods classifyreferences animate entities accurately, also assess appropriateinclusion anaphora resolution method. addition, complexity systemsconsidered.order increase reliability evaluation, systems assessedcorpora described Section 3. thresholds used simple method presentedSection 4.1 determined direct observation performance resultssystem applied AI corpus. Evaluating method SEMCOR corpusallows performance measured completely unseen data. addition, textsSEMCOR completely different genre AI, allowing assessmentmade degree system described Section 4.1 genre independent.Evaluation raises serious problems machine learning methodconsidered. well known, whenever machine learning method evaluated, cleardistinction made training data testing data. casesystem described Section 4.2, approach evaluated using 10-fold cross-validationSEMCOR corpus. Given AI corpus available, systems alsoevaluated data domain used setting parametersmachine learning method. addition, evaluation machine learning methodsAI corpus useful proving classification synsets WordNetbasis animacy annotation added SEMCOR used develop systemwhose performance text-dependent.5.1 Intrinsic EvaluationIntrinsic evaluation methods measure accuracy system performing taskdesigned carry out. present case, accuracy entityclassified animate inanimate. order assess performance systems,four measures considered:Correctly classif ied itemsotal number items(1)rue positivesrue positives + F alse positives(2)Accuracy =P recision =Recall =rue positivesrue positives + F alse negativesF measure =2 P recision RecallP recision + Recall90(3)(4)fiNP Animacy Identification Anaphora ResolutionFigure 3: Evaluation methods AI corpusaccuracy (1) measures well system correctly classify referenceentity animate inanimate, misleading large numberinanimate entities mentioned texts. clear Table 1, even though textschosen contain large number references animate entities, rationumber references animate entities inanimate entities approximatively 17.5 SEMCOR, 1 4.8 AI. means method classifiesreferences entities inanimate would accuracy 88.21% SEMCOR82.77% AI. seen Figures 3 4, well Table 4, resultsfar accuracy obtained system described Section 4.1. However,mentioned earlier, intention use filtering references animate entitiesanaphora resolution therefore, use filter classifies referencesinanimate would highly detrimental.clearly important know well system able identify references animateinanimate entities. order measure this, precision (2) recall (3) usedclass. precision system identify animate references definedratio number references correctly classified system animatetotal number references classifies animate (including wrongly classifiedones). methods recall classifying references animate entities defined rationumber references correctly classified animate total numberanimate references classified. precision recall inanimate classificationdefined similar manner. f-measure (4) combines precision recall one value.Several formulae f-measure proposed, one used gives equal importanceprecision recall.Figures 3 4, well Table 4 end paper, present accuracyclassification, f-measures classifying animate inanimate references.addition methods presented Section 4, three baseline methods introduced.first one classifies reference entity animate inanimate random basisreferred figures baseline. second random baseline introduced91fiOrasan & EvansFigure 4: Evaluation methods SEMCOR corpusassumed number gender marked pronouns text indicatelikely particular noun appearing text animate inanimate.case, probability reference animate proportional numberanimate pronouns text classification made weighted random basis.similar rule applies inanimate references. second baseline referredfigures W-baseline. purposes comparison, method included classifiesreferences inanimate. method referred dummy method.Figures 3 4 show methods significantly outperform baselinesused. Close investigation figures, well Table 4, shows that, corpora,best method one uses machine learning (presented Section 4.2). obtainshigh accuracy classifying references animate inanimate entities. termsaccuracy, simple method performs unexpectedly well, fails accurately classifyreferences animate entities. Moreover, comparison dummy method filesshows results simple method much better, suggestssimple method bias towards recognition references inanimate entities.integration word sense disambiguation yields mixed results: increases accuracysimple method, slightly decreases performance machine learningmethod.relatively poor accuracy Simple system expected explainedfact unique beginners, used basis classificationmethod, cover range senses wide classified belonging singleanimate inanimate class. general used basis accurateclassification. Additionally, rules used assist classification provide limited recallidentifying animate references.Comparison accuracy machine learning method level interannotator agreement reveals automatic method agrees first annotatorsecond annotator does. result this, concluded accuracyautomatic method matches human performance levels.92fiNP Animacy Identification Anaphora ResolutionFigure 5: accuracy mars different animacy filters applied5.2 Extrinsic evaluationprevious section, performance classification methods evaluateddemonstrated even simple methods achieve high accuracy expense lowprecision recall classification references animate entities. computationallinguistics, output one method often used input another one, thereforeimportant know results first method influence resultssecond. kind evaluation called extrinsic evaluation. Given identificationreferences animate entities useful right, vital taskslike anaphora resolution, necessary perform extrinsic evaluation too. caseevaluation, assumption performance anaphora resolutionimproved filtering candidates agree animacy referentialpronoun.influence animacy identification anaphora resolution thus evaluated usingmars (Mitkov, Evans, & Orasan, 2002), robust anaphora resolver relies setboosting impeding indicators select antecedent set competing candidates.Due fact evaluation mars requires manual annotation pronounsantecedents, time consuming task, evaluation carried partcorpus. end, entire Amnesty International corpus well 22 filesSEMCOR corpus used. Given animacy identifier influenceaccuracy anaphora resolvers respect third person singular pronouns, accuracyresolver reported pronouns. Accuracy anaphora resolutioncalculated ratio number pronouns correctly resolved totalnumber third person singular pronouns appearing test data. Figure 5 Table5 display accuracy alternate versions mars exploit different methodsanimacy identification.Mars designed process texts technical domain, thereforeperformance rather poor test corpus. Moreover, performance vary greatlyone domain another. light fact results different anaphoraresolver may different set data, addition performance93fiOrasan & EvansFigure 6: average number candidates percentage pronouns without correctcandidates different animacy filters appliedmars respect third person singular pronouns, Figure 6 Table 5 also presentreduction number candidates results animacy filtering,increase number pronouns whose sets competing candidates contain validantecedents result filtering. former number presented averagenumber candidates per pronoun, latter percentage pronouns withoutvalid antecedents list candidates. justification reporting two measuresgood animacy filter eliminate many candidates possible,eliminate antecedents leave pronouns without correct candidates resolved to.9seen Figure 5 Table 5, regardless animacy identificationmethod used, accuracy anaphora resolver improves. degree improvementvaries one corpus another, pattern regarding reduction numbercandidates increase number pronouns whose sets competing candidatescontain valid antecedent across corpora. AI corpus, bestperformance obtained simple method enhanced word sense disambiguationused, followed simple method. improvements statically significant10 ,well difference them. versions machine learning method improvesuccess rate mars small margin statistically significant,increase number pronouns valid antecedent select one, increasestatistically significant. simple methods, increase numbertype pronoun much larger statistically significant. Thereforecase AI corpus, concluded that, mars, aggressive methodfiltering candidates, simple method word sense disambiguation,appropriate. However, possible anaphora resolution methods resultvalid may strongly influenced increase numberpronouns valid antecedent select.9. noted that, even without filtering, pronouns candidatesdue errors introduced preprocessing tools NP extractor fails identifyNPs.10. cases checked whether differences two results statistically significantused t-test 0.05 confidence level.94fiNP Animacy Identification Anaphora ResolutionProcessing SEMCOR corpus, best results mars obtained machinelearning method without WSD module followed one performs WSD.cases increase performance unfiltered version statisticallysignificant, differences two machine learning methods smallsignificant. addition, two methods ensure large reduction numbercandidates smallest increase number pronouns whose sets competingcandidates contain valid antecedent, increase significant.expected, three baselines perform rather poorly. three reducenumber candidates expense high increase number pronounsvalid antecedent available selection. reduction number candidatesincrease number pronouns valid antecedent statistically significantcompared system use filtering.results marss performance rather mixed baselines used.AI corpus, random baseline leads better result mars machinelearning methods, differences statistically significant. However,achieved large increase number pronouns cannot correctly resolvedvalid antecedents also filtered method. AI corpus,application two baselines led results worse equal marsfiltering applied result large drop number candidates.SEMCOR corpus, three baselines give rise statistically significantimprovements performance levels obtained filtering applied,achieved dramatically reducing number candidates considered. Integrationdummy method mars leads results better simple methodsbut, argued before, method appropriate anaphora resolversprevents correctly resolving animate pronoun.Investigation results revealed 31% candidatespossible apply animacy filtering. three reasons this. First,majority cases, candidates named entities which, mentioned Section 2,tackled method, though constitute relatively high proportion nounphrases occurring chosen texts. second reason cases factwords present WordNet result, ignored method.Finally, limited number cases noun phrases identified mars matchidentified animacy identifiers reason possible classifythem.115.3 Extrinsic Evaluation Simulated Dataresults presented previous section makes difficult clear ideaaccurate animacy identifier needs order significant positive influenceperformance mars. light this, performed experiment animacyidentifiers perform predefined accuracy simulated. systemsdesigned way precision animacy identification varies 1% increments11. animacy identifiers proposed paper use NP context (i.e. verbdepends number pronouns text) therefore run independentlymodule uses results.95fiOrasan & EvansFigure 7: evolution success rate changes precision recall10% 100%, whilst recall varies 50% 100%.12 order achieve this,introduced controlled number errors annotated data randomly changinganimacy predetermined number noun phrases. order ensure fair results,experiment run 50 times precision-recall pair, different set entitieswrongly classified run. list classified entities (in case deriveddirectly annotated data processed methods describedpaper) used MARS resolution process. Figure 7 presents evolutionsuccess rate recall precision changed. order see success rateinfluenced increase recall, calculated success rates correspondingchosen recall value values precision 10% 100% averagedthem. way calculated evolution success rate changes precision.seen figures, precision greater influence success ratemars recall increasing precision, notice almost continuous increasesuccess rate. Overall, increasing recall also leads increase success rate,increase smooth. basis this, conclude high precisionanimacy identification important recall. results also supportedTable 5 Simple method leads good performance mars despite lowrecall (but higher precision) identification animate entities.experiments also reveal values higher 80% precision recall,success rate vary considerably. reason decided focus region. Figure8 presents success rate corresponding different precision-recall pairs using contourchart. darker areas correspond higher values success rate. noticed before,areas correspond high precision high recall also feature high success rates,difficult identify clear thresholds precision recall lead improvedperformance especially differences first four intervalsstatistically significant.12. decided control precision recall animacy identification way,indirectly, also control recall precision identification inanimate entities.96fiNP Animacy Identification Anaphora ResolutionFigure 8: Contour chart showing success rate different values precision recall5.4 Complexity SystemsOne aspect needs considered whenever system developed complexity.becomes important issue whenever system integrated largersystem, needs react promptly input (e.g. systems availableWeb). present case, method presented Section 4 complexprevious one, therefore requires time run. Table 3 shows time necessaryrun system two corpora. seen, fastest method simplemethod complexity proportional n*m n number entitiesentire corpus, average number senses word WordNet.method uses machine learning slower prepare datamachine learning algorithm, process similar complexity simple method,addition run memory-based learning algorithm, comparesnew instance instances already seen. Even though timbl, machine learningalgorithm used, employs sophisticated indexing techniques speed process,large training sets, algorithm slow. noted k-NN extremelyslow classifier use alternate ML algorithms, maximum entropy, may leadquicker classification times loss accuracy. word sense disambiguation97fiOrasan & EvansMethodSimple methodMLSimple+WSDML+WSDAISEMCOR3 sec.25 sec.51 sec.286 sec.Several hoursSeveral hoursTable 3: run time necessary different methodsused, processing time increases dramatically, complexity algorithmused nm n number distinct nouns text disambiguated,average number senses WordNet noun. performancerun time methods considered, best performing method ML, ensureshigh accuracy together relatively low execution time. use alternate WSDmethod exploits N-best lists, rather considering possible assignments wordsenses, would likely improve speed disambiguation. approach typeyet tested current work.6. Related Workregard work concerned recognition NP animacy, sole concernsection methods tackle problem English texts, problemconcerned semantics cannot addressed using morphological information,languages.Identification specific gender proper names attempted HaleCharniak (1998). method works processing 93931-word portion PennTreebank corpus pronoun resolution system noting frequenciesparticular proper nouns identified antecedents feminine masculinepronouns. paper reports accuracy 68.15% assigning correct genderproper names.approach taken Cardie Wagstaff (1999) similar simple statistical onedescribed Section 4.1, though one described paper exploits larger numberunique beginners ontology, considers semantic information verbsNPs arguments, also considers possible senses noun. approachpresented Cardie Wagstaff (1999), nouns sense subsumed particular nodesWordNet ontology (namely nodes human animal) considered animate.terms gender agreement, gazetteers also used assign NP valuegender set masculine, feminine, either (which assumed correspondanimate), neuter. method employed Cardie Wagstaff fairly simpleincorporated one feature vector used classify coreferenceNPs. employed machine learning method blindly exploits value assignedanimacy feature, without interpreting semantically. WordNet used identifyNP animacy work Denber (1998). Unfortunately, evaluation task animacyidentification reported papers.98fiNP Animacy Identification Anaphora Resolution7. ConclusionsAnimacy identification preprocessing step improve performanceanaphora resolution English filtering candidates compatible,terms agreement features, referential expression. paper,specific definition animacy used one proposed Quirk et al. (1985).adopted definition appropriate conveys usefulness feature anaphoraresolution. present study, animacy noun phrase determined factreferred means masculine feminine pronoun wellpossessive, relative reflexive forms.paper, two different animacy identifiers presented evaluated.first one relies unique beginners WordNet combination simple rulesdetermine animacy noun phrase. Given unique beginners generalused way rules designed nave observations, secondmethod proposed. second approach relies machine learning methodenhanced WordNet determine animacy noun phrase. addition normalsemantic information, enhanced WordNet contains information animacysynset. animacy information automatically calculated basis manualannotation SEMCOR corpus animacy information.two animacy identifiers evaluated using intrinsic extrinsic methods.intrinsic evaluation employed several measures determine appropriate identifier.Comparison results methods revealed easy obtain relativelyhigh overall accuracy expense low accuracy classification animatereferences. reason, concluded extra resources requiredmachine learning method, best performing method, fully justified. Inter-annotatoragreement measured order ascertain difficulty task result this,noted machine learning method reaches level performance comparablehumans.extrinsic evaluation focused performance mars, robust anaphoraresolver, influenced animacy identifier. light fact mars designedresolve anaphors texts different genre, results reported extrinsicevaluation focus accuracy system, also manycandidates removed animacy identifier many pronouns leftvalid antecedent select sets candidates result process.Evaluation mars revealed methods proposed paper improveaccuracy, degree improvement varies one corpus another. termsreduction number candidates anaphora resolution system consider,machine learning method eliminates fewest candidates, result evokessmall increases number pronouns whose sets competing candidates containvalid antecedents. reason, argue extrinsic evaluation also showsmachine learning approach appropriate method determine animacynoun phrases.Experiments WSD produced mixed results. one corpora usedresearch lead small improvements performance. thus concludeextra computation required order disambiguate words unnecessary.99fi28.24%29.23%67.73%70.83%94.20%93.65%82.11%79.27%82.77%88.93%91.60%98.33%98.34%50.32%20.60%100%99.24%96.66%99.26%99.07%62.39%32.70%90.57%93.80%94.06%98.79%98.70%22.05%15.09%68.90%76.50%90.93%90.05%86.19%88.41%88.21%91.81%93.94%98.75%98.59%50.14%31.64%100%98.51%98.38%98.57%98.56%63.39%46.60%93.73%95.04%96.11%98.65%98.57%Table 4: results classificationOrasan & EvansPrecAcknowledgments100Random baselineWeighted baselineDummy methodSimple systemSimple system + WSDMachine learning systemMachine learning WSDInanimacyRecall F-measF-measwould like thank Laura Hasler helping us annotation processthree referees useful comments enabled us improve paper.Random baselineWeighted baselineDummy methodSimple systemSimple system + WSDMachine learning systemMachine learning WSDAnimacyPrecRecallAI corpus50.60% 19.37% 52.13%31.01% 18.07% 76.48%82.77%0%89.61% 94.79% 52.69%90.14% 81.60% 62.57%98.04% 96.31% 92.19%97.85% 95.37% 92.00%SEMCOR corpus50.19% 14.11% 50.49%37.62% 8.40% 74.44%88.21%0%91.42% 88.48% 56.42%93.33% 88.88% 67.14%97.72% 91.91% 89.99%97.51% 89.97% 90.14%AccAppendix A. TablesExperimentfiNo filteringSimpleSimple + WSDMachine learningMachine learning + WSDRandom baselineWeighted baselineDummy method101filteringSimpleSimple + WSDMachine learningMachine learning + WSDRandom baselineWeighted baselineDummy methodAverage candidates per pronouns Percentage pronouns without antecedentResults AI Corpus: 215 animate pronouns17.2020.4612.3726.0412.4724.1813.7120.9313.7020.939.9533.0210.5740.469.1742.32Results part SEMCOR: 1250 animate pronouns10.2024.808.4426.968.6626.888.3326.328.3326.327.5533.127.2836.167.8338.16Table 5: results extrinsic evaluationMARS accuracy40.00%43.26%45.58%40.93%40.93%41.40%38.60%40.00%29.60%37.60%37.50%39.60%39.52%36.96%34.08%38.16%NP Animacy Identification Anaphora ResolutionSystemfiOrasan & EvansReferencesBarbu, C., Evans, R., & Mitkov, R. (2002). corpus based analysis morphologicaldisagreement anaphora resolution. Proceedings Third International ConferenceLanguage Resources Evaluation (LREC2002), pp. 1995 1999 Las Palmas deGran Canaria, Spain.Barlow, M. (1998). Feature mismatches anaphora resolution.DAARC2, pp. 34 41 Lancaster, UK.ProceedingsBrennan, S. E., Friedman, M. W., & Pollard, C. J. (1987). centering approachpronouns. Proceedings 25th Annual Metting ACL, pp. 155 162Stanford, California.Cardie, C., & Wagstaff, K. (1999). Noun phrase coreference clustering. Proceedings1999 Joint SIGDAT conference Emphirical Methods NLP LargeCorpora (ACL99), pp. 82 89 University Maryland, USA.Chomsky, N. (1981). Lectures Government Binding. Dordrecht: Foris.Cristea, D., Ide, N., Marcu, D., & Tablan, V. (2000). empirical investigationrelation discourse structure co-reference. Proceedings 18thInternational Conference Computational Linguistics (COLING2000), pp. 208214 Saarbrucken, Germany.Daelemans, W., Zavrel, J., van der Sloot, K., & van den Bosch, A. (2000). TiMBL: Tilburgmemory based learner, version 3.0, reference guide, ilk technical report 00-01. Ilk00-01, Tilburg University.Denber, M. (1998). Automatic resolution anaphora English. Tech. rep., EastmanKodak Co, Imaging Science Division.Evans, R., & Orasan, C. (2000). Improving anaphora resolution identifying animateentities texts. Proceedings Discourse Anaphora Reference ResolutionConference (DAARC2000), pp. 154 162 Lancaster, UK.Fellbaum, C. (Ed.). (1998). WordNet: Electronic Lexical Database. MIT Press.Frances, W., & Kucera, H. (1982). Frequency Analysis English Usage. Houghton Mifflin,Boston.Hale, J., & Charniak, E. (1998). Getting useful gender statistics English text. Tech.rep. CS-98-06, Brown University.Hobbs, J. (1976). Pronoun resolution. Research report 76-1, City College, City UniversityNew York.Hobbs, J. (1978). Pronoun resolution. Lingua, 44, 339352.102fiNP Animacy Identification Anaphora ResolutionKennedy, C., & Boguraev, B. (1996). Anaphora everyone: pronominal anaphoraresolution without parser. Proceedings 16th International ConferenceComputational Linguistics (COLING96), pp. 113 118 Copenhagen, Denmark.Landes, S., Leacock, C., & Tengi, R. I. (1998). Building semantic concordances. Fellbaum(Fellbaum, 1998), pp. 199 216.Lappin, S., & Leass, H. J. (1994). algorithm pronominal anaphora resolution.Computational Linguistics, 20 (4), 535 562.Mitchell, T. M. (1997).McGraw-Hill.Machine learning.McGraw-Hill Series Computer Science.Mitkov, R. (1998). Robust pronoun resolution limited knowledge. Proceedings18th International Conference Computational Linguistics (COLING98/ACL98),pp. 867 875 Montreal, Quebec, Canada.Mitkov, R. (2002). Anaphora resolution. Longman.Mitkov, R., Evans, R., & Orasan, C. (2002). new, fully automatic version Mitkovsknowledge-poor pronoun resolution method. Proceedings CICLing-2002, pp. 168186 Mexico City, Mexico.Ng, V., & Cardie, C. (2002). Improving machine learning approaches coreferenceresolution. Proceedings 40th Annual Meeting AssociationComputational Linguistics (ACL2002), pp. 104 111 Philadelphia, Pennsylvania.Quinlan, J. R. (1993). C4.5: Programs Machine Learning. Morgan Kaufmann.Quirk, R., Greenbaum, S., Leech, G., & Svartvik, J. (1985). Comprehensive GrammarEnglish Language. Longman.Resnik, P. (1995). Disambiguating noun groupings respect Wordnet senses.Yarovsky, D., & Church, K. (Eds.), Proceedings Third Workshop LargeCorpora, pp. 5468 Somerset, New Jersey. Association Computational Linguistics.Sirkin, R. M. (1995). Statistics social sciences. SAGE Publications.Sparck Jones, K., & Galliers, J. R. (1996). Evaluating natural language processing systems:analysis review. No. 1083 Lecture Notes Artificial Intelligence. Springer.Tapanainen, P., & Jarvinen, T. (1997). non-projective dependency parser. Proceedings5th Conference Applied Natural Language Processing, pp. 64 71 WashingtonD.C., USA.103fiJournal Artificial Intelligence Research 29 (2007) 1947Submitted 03/06; published 05/07Computationally Feasible VCG MechanismsNoam Nisannoam@cs.huji.ac.ilSchool Computer Science Engineering,Hebrew University Jerusalem, IsraelAmir Ronenamirr@ie.technion.ac.ilFaculty Industrial Engineering & Management,Technion - Israel Institute Technology,Haifa 32000, IsraelAbstractmajor achievement mechanism design theory general method construction truthful mechanisms called VCG (Vickrey, Clarke, Groves). applyingmethod complex problems combinatorial auctions, diculty arises: VCGmechanisms required compute optimal outcomes are, therefore, computationally infeasible. However, optimal outcome replaced results sub-optimalalgorithm, resulting mechanism (termed VCG-based) longer necessarily truthful.rst part paper studies phenomenon depth shows nearuniversal. Specically, prove essentially reasonable approximations heuristics combinatorial auctions well wide class cost minimization problems yieldnon-truthful VCG-based mechanisms. generalize results ane maximizers.second part paper proposes general method circumventingproblem. introduce modication VCG-based mechanisms agentsgiven chance improve output underlying algorithm. agents behavetruthfully, welfare obtained mechanism least good one obtainedalgorithms output. provide strong rationale truth-telling behavior.method satises individual rationality well.1. IntroductionMechanism design sub-eld game theory microeconomics studies design protocols non-cooperative environments. environments participatingagents follow goals necessarily act instructed mechanism.theory traditionally applied economic applications auctions various kinds. introduction mechanism design found several books (Osborne& Rubinstein, 1994; Mas-Collel, Whinston, & Green, 1995). recent years, problemsborder mechanism design computer science attracted attentionmany researchers, within outside AI community. particular, mechanismdesign models applied multi-agent systems (Rosenschein & Zlotkin, 1994; Wellman,Wurman, Walsh, & MacKie-Mason, 2001; Shoham & Tanaka, 1997; Shoham & Tennenholtz, 2001), decentralized resource task allocations (Nisan & Ronen, 2001; Wellmanet al., 2001; Elkind, Sahai, & Steiglitz, 2004; Porter, Ronen, Shoham, & Tennenholtz, 2002),economic electronic commerce applications (Parkes, 1999; Cramton, 1997), communication networks (Feigenbaum, Papadimitriou, & Shenker, 2000; Anderson, Kelly, &Steinberg, 2002).c2007AI Access Foundation. rights reserved.fiNisan & Ronencanonical mechanism design problem described follows: set rationalagents needs collaboratively choose outcome nite set possibilities.agent privately known valuation function v : R quantifying agentsbenet possible outcome. agents supposed report valuationfunctions v () centralized mechanism. goal mechanism chooseoutcome maximizes total welfare v (o). main diculty agents maychoose misreport valuations attempt aect outcome liking.manipulations likely severely damage resulting welfare (simulationsdemonstrate welfare loss found Carroll & Grosu, 2005). toolmechanism uses motivate agents reveal truth monetary payments.payments need designed way ensures rational agents always revealtrue valuations. Mechanisms property called incentive compatible truthful(in dominant strategies). date, one general method, called VCG (Vickrey, 1961;Clarke, 1971; Groves, 1973) (or slightly generally, ane maximization), knowndesigning payment structure1 . settings, known methodsole available one (Roberts, 1979; Lavi, Nisan, & Mualem, 2003).Many novel applications mechanism design complex require implementationcomputer systems. Cases point include combinatorial auctions multiple itemsconcurrently sold auction (Cramton, Shoham, & Steinberg, 2006), decentralizedtask resource allocation problems (Nisan & Ronen, 2001; Wellman et al., 2001),networking applications (Feigenbaum et al., 2000; Anderson et al., 2002). manyapplications, range possible outcomes huge even nding outcomemaximizes total welfare known NP-complete. Since cases computingoptimal outcome intractable, VCG method cannot applied.natural general approach development mechanisms cases woulduse sub-optimal polynomial time algorithm computing outcome, calculatepayments applying VCG payment rule underlying algorithm. termmechanisms VCG-based.starting point paper observation, noted already researchers(Lehmann, OCallaghan, & Shoham, 2002; Nisan & Ronen, 2001), VCG-based mechanisms necessarily truthful. Thus, rational agents may lie, taking advantage quirksoutcome determination algorithm.1.1 VCG-based Mechanisms Generally Truthfulrst part paper examines last phenomenon depth showsnear universal: essentially reasonable VCG-based mechanisms truthful.rst turn attention combinatorial auctions characterize class truthful VCG-based mechanisms problem2 . say allocation algorithm1. Recently, truthful mechanisms, ane maximizers, obtained combinatorialauctions (Bartal, Gonen, & Nisan, 2003).2. importance combinatorial auctions twofold. First, direct applications FCCauctions. Second, abstract many problems resource allocation among self-interested agents.comprehensive survey research combinatorial auctions found recent book (Cramtonet al., 2006).20fiComputationally Feasible VCG Mechanismscombinatorial auctions reasonable if, whenever item desired single agent only,agent receives item. characterization leads following corollary:Theorem: truthful VCG-based mechanism combinatorial auctions reasonable (unless uses exponential optimal allocation algorithm).particular, unless P = N P , every polynomial time, truthful VCG-based mechanismreasonable.Loosely speaking, show essentially degree freedom available truthful VCG-based mechanisms choice range optimize. Within rangeperfect optimization needed. theorem seems intuitive VCG payments identifyagents utility society, thus social welfare optimizedmechanism, agents motivated lie order so. Yet, argumentshows outcome must locally optimal locality dened deviationsingle agent. heart argument delicate hybrid argument showinggeneral context local optimization essentially implies global optimization.Next study family problems termed cost minimization allocation problems.family contains many natural decentralized task allocation problems mechanismdesign versions shortest path problem (Elkind et al., 2004; Nisan & Ronen, 2001;Rosenschein & Zlotkin, 1994). call mechanism problem degenerateexist inputs cause produce results arbitrarily far optimal.Theorem: cost minimization allocation problem, sub-optimal truthful VCGbased mechanism degenerate.word order signicance results. VCG-based mechanismsspecial case truthful mechanisms essentially generalmethod known truthful mechanisms non-single dimensional settings. Moreover,certain settings known indeed truthful mechanisms (Roberts, 1979;Lavi et al., 2003). precisely, weighted versions VCG-based mechanisms calledane maximizers truthful, results extend (as show) cases well.Consequently, results imply designing truthful mechanisms computationallyintractable problems requires either restricting range outcomes (getting unreasonable degenerate mechanisms) developing entirely new techniques truthfulmechanisms may even exist. similar implication results intractabilitystems computational considerations, rather communication considerations (Cramton et al., 2006, Chapter 11).1.2 Second Chance Mechanismsecond part paper proposes general method circumventing dicultyconstructing truthful mechanisms. VCG-based mechanisms lose incentivecompatibility, still pose special property. Loosely speaking, mechanism,reason agent misreport valuation help algorithm computebetter outcome. would like exploit property obtain mechanismsalmost truthful.21fiNisan & RonenGiven algorithm corresponding optimization problem dene second chance mechanism based it. mechanism modication VCG-basedmechanism where, addition valuations, agents allowed submit appealfunctions. appeal function allows agent give algorithm input (a vectordeclared valuations), dierent original input, without misreportingtype. agents behave truthfully, welfare obtained mechanismleast good one obtained algorithms output.formulate rationale truthful behavior mechanism. Informally,argument follows: reasonable assumptions, situation agentbelieves benecial lie mechanism, better agent reportactual type mechanism ask appeal check whether lie really helps it.Thus, agent construct truthful strategy premised fact awaresituation another strategy would better. believe strongargument truth-telling.construct version mechanism satises individual rationality well.generalization results ane maximization compensation bonusmechanisms (Nisan & Ronen, 2001) straightforward.Several alternative approaches aimed handling diculty developing truthfulmechanisms suggested past. One approach construction mechanismscomputationally hard manipulate (e.g., Bartholdi et al., 1992). bestknowledge manipulations hard worst case (e.g., may NPhard always compute manipulation). Nevertheless, hardness rulepossibility manipulations may easy compute typical cases. Anotherpossible approach consider equilibria VCG (Holzman, Kr-Dahav, Monderer, &Tennenholtz, 2004; Holzman & Monderer, 2004). However, apparent wayagents coordinate equilibria. Several recent works construct ascending mechanismscombinatorial auctions (e.g. Parkes, 1999). mechanisms rely assumptionsagents dierent (e.g., myopic behavior). may interestingcompare virtues mechanisms ours.multi-round mechanisms combinatorial auctions let agents improveprovisional allocation proposed tested past (Banks, Ledyard, & Porter,1989). argument truthfulness second chance mechanisms may provide partialexplanation relative success reported experiments.2. Preliminariessection formally present model. attempt much possible usestandard notions mechanism design computational complexity theories.2.1 Mechanism Design Problemssection formulates class mechanism design problems study.Denition 1 (utilitarian mechanism design problem) (utilitarian) mechanism design problem described by:1. nite set allowed outputs.22fiComputationally Feasible VCG Mechanisms2. agent = (1, . . . , n) real function v (o O) called valuation type.quantication benet possible output termscommon currency. v (.) privately known agent i.3. mechanisms output addition mechanism hands agent pi unitscurrency, utility ui equals3 v (o) + pi . utility agent aimsoptimize.4. goal mechanism select output maximizes totalwelfare g(v, o) = v (o).example problem found Section 2.4.Note goal problems maximize total welfare necessarilyrevenue. goal, also known economic eciency, justied many settingsextensively studied economics.direct revelation mechanism, participants simply asked reveal typesmechanism. Based declarations mechanism computes outputpayment pi agents.Denition 2 (mechanism) (direct revelation) mechanism pair = (k, p)that:output function k accepts input vector w = (w1 , . . . , wn ) declared valuationfunctions4 returns output k(w) O.payment function p(w) = (p1 (w), . . . , pn (w)) returns real vector quantifyingpayment handed mechanism agents (e.g. pi = 2, mechanismpays two units currency agent i).agents try maximize utility thus may lie mechanism.lies might severely reduce total welfare, mechanism carefullydesigned benet agents report types truthfully.Notation: denote tuple (a1 , ...ai1 , ai+1 , ..., ) ai . let (ai , ai ) denotetuple (a1 , . . . , ).Denition 3 (truthful mechanism) mechanism called truthful truth-tellingdominant strategy, i.e., every agent type v every type declaration wiagents, agents utility maximized declares real valuation functionvi.example consider famous Vickrey auction (Vickrey, 1961): seller wishessell one item auction. n buyers, privately knowing valuation vitem. (The value winning assumed zero.) Vickrey auctionbuyers simply asked valuation; item allocated buyer3. assumption called quasi-linearity common mechanism design.4. consider issue represent valuations.23fiNisan & Ronenhighest bid price second highest. reader may verify mechanismtruthful. Another example truthful mechanism found Section 2.4.general, communication protocol mechanism complicated. simpleobservation known revelation principle dominant strategies (e.g., Mas-Collel et al.,1995, pp. 871) states every mechanism agents dominant strategies,exists equivalent truthful mechanism. Thus, w.l.o.g. possible focustruthful mechanisms.2.2 VCG-based Mechanismssubsection presents celebrated VCG mechanisms. Intuitively, mechanismssolve utilitarian problems identifying utility truthful agents declaredtotal welfare. generalize mechanisms.Denition 4 (VCG mechanism, (via Groves, 1973)) mechanism = (k, p) belongsVCG family if:k(w) maximizes total welfare according w. is, w, k(w) arg maxo g(w, o).payment calculated according VCG formula: pi (w) =hi (wi ) (hi (.) arbitrary function wi ).j=i wj (k(w))+reader may verify Vickrey auction VCG mechanism. well knownVCG mechanisms truthful (Groves, 1973).Unfortunately, many applications, task nding output k(w) maximizes total welfare computationally infeasible (e.g., NP-hard). paperconsider VCG mechanisms optimal algorithm replaced sub-optimalcomputationally feasible one.Denition 5 (VCG-based mechanism) Let k(w) algorithm maps type declarations allowable outputs. call = (k(w), p(w)) VCG mechanism basedk(.) p(.) calculated according VCG formula: pi (w) = j=i wj (k(w)) + hi (wi )(where hi (.) arbitrary function wi ).Obviously, VCG-based mechanism based optimal algorithm VCG mechanism. Note payment function VCG-based mechanism identicalVCG payment algorithm k(.) plugged payment formula.characterize utility agent VCG-based mechanisms. utility equivalenttotal welfare according declared types agents actual typeagent consideration.Lemma 2.1 (VCG-based utility) Consider VCG-based mechanism dened allocation algorithm k(.), functions (h1 (.), . . . , hn (.)). Suppose actual valuationagent v , declarations w = (w1 (.), . . . , wn (.)). utility agentequals g((v , wi ), k(w)) + hi (wi ).24fiComputationally Feasible VCG MechanismsProof: proof immediate denitions. agents utility equals v (k(w)) +pi (w) = v (k(w)) + j=i v j (k(w)) + hi (wi ) = g((v , wi ), k(w)) + hi (wi ).words, VCG-based mechanism identies utility truthful agentstotal welfare. particular, k(.) optimal, g((v , wi ), k(w)) maximizedagent truthful. implies VCG mechanisms truthful truthfulnessnecessarily preserved VCG-based mechanisms.2.2.1 Example: Non Optimal Vickrey Auctionsection demonstrates problems might occur optimal algorithmVCG mechanism replaced sub-optimal one. Consider sale single item.already commented, Vickrey auction VCG mechanism. algorithm allocatesitem agent highest declared value. function hi (wi ) = j=i wj (o)equals negation second highest value case winning.Consider mechanism optimal algorithm replaced algorithmchooses second highest agent. mechanism give objectagent second highest declaration price third highest agent.Suppose three agents. Alice value $2 million, Bobvalue $1.7 million, Carol value $1 million. agents truthful,Bob wins pays $1 million. case Alices benet reduce declarationBobs. Similarly, Alice wins, Bob would like lower declaration further,on. Note natural situations Carol win well.dicult see dominant strategies game. outcomemechanism highly unpredictable, depending heavily agents beliefsothers, risk attitude, level sophistication. mechanismyield inecient outcomes. eciency loss may get much worse underlyingoptimization problem complex combinatorial structure (simulations demonstratecontext scheduling done Carroll & Grosu, 2005).2.2.2 Affine-based mechanismspossible slightly generalize class VCG mechanisms obtain mechanismscalled ane maximizers. mechanisms maximize ane transformations valuations. domain valuations unrestricted, ane maximizers soletruthful mechanisms (Roberts, 1979; Lavi et al., 2003). Similarly VCG, generalizemechanisms incorporate sub-optimal algorithms.Notation: Let = (a0 , . . . , ) n + 1-tuple a0 (.) valuation function,a1 , . . . , strictly positive. dene weighted welfare ga (w, o) outputa0 (o) + i>0 ai wi (o) w vector types output.Denition 6 (ane-based mechanism) Let k(w) algorithm maps type declarations allowable outputs, = (a0 , . . . , ) n + 1-tuple a0 (.)valuation function, a1 , . . . , strictly positive. call = (k(w), p(w)) anemechanism based k p calculated according formula: pi (w) = a1i ( j=i,0 ajwj (k(w)) + hi (wi )) (where hi () arbitrary function wi ).25fiNisan & Ronenfunction a0 (.) interpreted preferences mechanism setalternatives a1 , . . . , weights agents. VCG mechanisms,agents utility convenient characterization.Lemma 2.2 (ane-based utility) Consider ane-based mechanism denedallocation algorithm k(.), tuple functions h1 (.), . . . , hn (.). Supposeactual valuation agent v , declarations w = (w1 (.), . . . , wn (.)).utility agent equals a1i (ga ((v , wi ), k(w)) + hi (wi )).Proof: proof immediate denitions. agents utility equals v (k(w) +pi (w)) = a1i (ai v (k(w)) + pi (w) = a1i (ga ((v , wi ), k(w)) + hi (wi )).words, ane-based mechanism identies agents utility anetransformation valuations aims optimize. particular, k(.) maximizesga (w, .), mechanism truthful.2.3 Computational Considerations Mechanism Designsection adopts standard notions computational complexity revelation mechanisms.Denition 7 (polynomial mechanism) mechanism (k, p) called polynomial timecomputable k(w) p(w) run polynomial time (in size w).Note VCG-based mechanism polynomial output algorithm functions hi (.) polynomial. sometimes call polynomial algorithms mechanismscomputationally feasible.Denition 8 (NP-complete problem) mechanism design problem called NP-Completeproblem nding output maximizes total welfare NP-Complete.use term feasible denote acceptable computational time infeasibleunacceptable computational time. particular, NP-hard problems exponential algorithms considers infeasible, polynomial algorithms considered feasible. usenon-standard terms results limited specic complexityclasses.2.4 Example: Combinatorial Auctionsproblem combinatorial auctions extensively studied recent years (a recentbook found Cramton et al., 2006). importance problem twofold.Firstly, several important applications rely (e.g., FCC auction Cramton, 1997).Secondly, generalization many problems interest, particular eldelectronic commerce.problem: seller wishes sell set items (radio spectra licenses, electronicdevices, etc.) group agents desire them. agent has, every subsetitems, non-negative number v (s) represents much worthit. v (.) privately known agent i. make two standard additional assumptionsagents type space:26fiComputationally Feasible VCG Mechanismsexternalities valuation agent depends items allocatedit. words, every two allocations x = (x1 , . . . , xn ) = (y1 , . . . , yn ),xi = yi , v (x) = v (y). Thus, denote valuation agentv : 2S R.Free disposal Items non-negative values, i.e., t, v (s) v (t). Also,v () = 0.Items either complementary, i.e., v (S ) v (S) + v (T ), substitutes, i.e.,v (S ) v (S) + v (T ) (for disjoint ). example, buyer may willingpay $200 T.V. set, $150 VCR, $450 $200 two VCRs.agent gets set si items, payment pi , utility v (si ) + pi . (Thepayments combinatorial auctions non-positive.) utility agent triesoptimize. example, agent prefers buy $1000 valued VCR $600, gaining$400, rather buy $1500 valued VCR $1250.VCG mechanism combinatorial auction, participants rst requiredreveal valuation functions mechanism. mechanism computes,according agents declarations, allocation maximizes total welfare.payment agents calculated according VCG formula. Lemma2.1, utility ui = v (si ) + pi agents maximized reveals truevaluation mechanism. agents truthful, mechanism maximizestotal welfare.Consider, however, computational task faced mechanism. typesdeclared, mechanism needs select, among possible allocations, one maximizes total welfare. problem known NP-Complete. Therefore, unlessnumber agents items small, mechanism computationally infeasible.Even problem ndingallocation approximates optimal allocation withinreasonable factor |S| N P -Complete (Zuckerman, 2006). Nevertheless, variousheuristics tractable sub-cases analyzed literature (Cramton et al.,2006, Chapter 13). would like nd way turn sub-optimal algorithmsmechanisms.note that, general, revealing valuation function requires exponential communication. ignore communication issues paper, subsequent work (Ronen,2001) extends second chance method address communication limitations well.3. Limitations Truthful VCG-based Mechanismssection studies limitations truthful VCG-based mechanisms. Section 3.1 characterizes mechanisms important problem combinatorial auctions (see Section2.4). characterization precludes possibility obtaining truthfulness applyingVCG rules many proposed heuristics combinatorial auctions (e.g., greedyalgorithms Lehmann et al., 2002 Nisan, 2000). Moreover, show truthfulnon-optimal VCG-based mechanism combinatorial auctions suers abnormal behavior. Section 3.2 shows many natural cost minimization problems, truthfulVCG-based mechanism either optimal produces results arbitrarily far27fiNisan & Ronenoptimal. result, problem computationally intractable, truthful computationally feasible VCG-based mechanism inputs cause produce degenerateresults. Furthermore, since standard algorithmic techniques yield anomalies,might dicult develop algorithms plugged truthful mechanisms.generalize results ane-based mechanisms well.3.1 Truthful VCG-based Mechanisms Combinatorial Auctionssection characterizes class truthful VCG-based mechanisms combinatorialauctions.Denition 9 (maximal range) Let k(w) algorithm maps type decladfrations allowable outputs. Let V = ni=1 V space possible types letV V subspace V . Let denote range k V , i.e. = {k(w)|w V }.say k maximal range V every type w V , k(w) maximizes gO. say k maximal range maximal range V .Consider, example, algorithm combinatorial auctions allocatesitems (the set S) agent highest valuation v (S). Clearly, polynomialtime algorithm maximal range . welfare obtained allocationalgorithm achieves least factor max(1/n, 1/|S|) optimal welfare (where ndenotes number agents).Proposition 3.1 VCG-based mechanism output algorithm maximalrange truthful.Proof: mechanism VCG mechanism set allowable outputsrange output algorithm. Lemma 2.1 mechanism truthful.show proposition almost characterizes class truthfulVCG-based mechanisms combinatorial auction problem.Notation: let V denote space types v = (v 1 , . . . , v n ) twodierent allocations x y, g(v, x) = g(v, y). (Recall g(.) denotes total welfare.)dicult see V contains almost types, i.e. V V measure zeroV .Theorem 3.2 VCG-based mechanism combinatorial auction problem truthful,output algorithm maximal range V .Proof: Assume contradiction = (k, p) truthful k(.) maximalrange V . Since functions hi (.) aect truthfulness mechanism,assume zero, i.e., assume i, pi (w) = j=i wj (k(w)).According Lemma 2.1, utility agent equals v (k(w)) + j=i wj (k(w)) =g((v , wi ), k(w)).Let denote range k(.) V let v V type k(v)optimal O. Let = arg maxoO g(v, o) optimal allocation among O. Note28fiComputationally Feasible VCG Mechanismsdenition V , unique. Finally, let w V type = k(w).type exists since range algorithm.Dene type vector zz (s) =v (s).stands suciently large number. words, agent strongly desiresset . Apart this, v z identical. assume z V . Otherwisecould add suciently small noise (s) z claims remain true.show z forces algorithm output y. showalgorithm outputs type z, must also output type vcontradiction.Lemma 3.3 = k(z).Proof: Dene sequence type vectors by:w0 = (w1 , . . . , wn )w1 = (z 1 , w2 , . . . , wn )w2 = (z 1 , z 2 , w3 , . . . , wn )...wn = (z 1 , . . . , z n ).words, every agent turn moves wi z . assume wj Vj. dicult see z modied adding small noise it, wayguarantees above.Claim 3.4 k(w1 ) = y.Proof: Assume contradiction false. denition V obtaing(w1 , k(w1 )) = g(w1 , y).Consider case agent 1s type z 1 types others w2 , . . . , wn .declaring w1 , agent 1 force algorithm decide y. Since mechanismtruthful, must g(w1 , k(w1 )) > g(w1 , y).Since large, must k 1 (w1 ) 1 (i.e., agent 1 gets items getstype w1 ). Thus, denition z 1 , obtain + nj=2 wj (k(w1 )) >+ nj=2 wj (y). Because, due free disposal assumption, w1 (k(w1 )) w1 (y),obtain w1 (k(w1 )) + nj=2 wj (k(w1 )) > w1 (y) + nj=2 wj (y) (even z perturbed).Thus, g(w0 , k(w1 )) > g(w0 , y).Therefore, type agent 1 w1 , better declaring z 1 , forcingmechanism output k(w1 ). contradicts truthfulness mechanism.Similarly, induction j, obtain k(wj ) = j, particular wn = z.completes proof Lemma 3.3.show k(z) = implies k(v) = contradiction. Considerfollowing sequence type vectors:29fiNisan & Ronenv0 = (v 1 , . . . , v n )v1 = (z 1 , v 2 , . . . , v n )...vn = (z 1 , . . . , z n ).words, every agent turn, moves v z . choose zvj V .Claim 3.5 vj , maximizes g O.Proof: show v1 . proof j > 1 follows similar argument.Assume contradiction x = maximizes welfare v1 . Since arbitrarilylarge must x1 . Consequently, cases agent 1s valuation equals .Recall uniquely maximizes g v0 . Thus, every allocation x = y,v 1 (y) + nj=2 v j (y) > v 1 (x) + nj=2 v j (x). Therefore, + nj=2 v j (y) > + nj=2 v j (x).left hand side equals g(v1 , y) right hand side equals g(v1 , x). Thus, g(v1 , y) >g(v1 , x) contradiction.Claim 3.6 k(vn1 ) = y.Proof: showed k(vn ) = y. (Recall vn = z.) also showed uniquelymaximizes g(vn1 , .). Let xn1 = k(vn1 ). Assume contradiction xn1 = y. According Lemma 2.1, utility agent n truthful g(vn1 , xn1 ). Thus,agent ns type v n , better declaring z n obtaining utility g(vn1 , y).contradicts truthfulness mechanism.Similarly, downward induction j, obtain k(v0 ) = y. v0 = vassumed k(v) = contradiction. completes proof Theorem 3.2.Remarks theorem characterizes output algorithms could incorporated truthful VCG-based mechanisms zero-measured subset types.characterization holds even set possible types discrete (under mildcondition type vector z dened agents indierentallocations). theorem gives rise several interesting algorithmic combinatorial questions. example, given approximation factor c 1, minimalsize sub-family every v, maxyO g(v, y) c gopt (v)? limitedversion question analyzed Holzman et al., 2004 Holzman & Monderer,2004.Corollary 3.7 Consider VCG-based mechanism combinatorial auction output algorithm k. mechanism truthful, exists output algorithm k, maximalrange, every v, g(v, k(v)) = g(v, k(v)).Proof: Let denote range k V , dene another algorithm optimalrange v, k(v) arg maxoO . According Proposition 3.1, VCG mechanism30fiComputationally Feasible VCG Mechanismsbased k truthful. Consider case agents truthful. Recallutility agents determined resulting total welfare. Thus, dicultsee welfares g(v, k(v)) g(v, k(v)) must continuous v. Two continuous realfunctions, identical dense subspace, identical whole spacethus corollary follows.show non-optimal truthful VCG-based mechanisms suer followingdisturbing abnormal behavior:Denition 10 (reasonable mechanism) mechanism combinatorial auctionscalled reasonable whenever exists item j agent that:1. S, j/ S, v (S {j}) > v (S), and,2. every agent l = i, S, v (S {j}) = v (S),j allocated agent i.Simply put, situations one agent desires item, agent gets it.Theorem 3.8 non-optimal truthful VCG-based mechanism combinatorial auctionsreasonable.Proof: Consider mechanism m. According Corollary 3.7 exists equivalentmechanism = (k, p), optimal range. Since must also sub-optimal,exists least one partition = (s1 , . . . , sn ) range mechanism.Dene vector types by:1 x siv (x) =0 otherwise.words, agent wants single set si , two agents want item(as sets disjoined). Since range must k(v) = s. Sincestrictly optimal, k(v) must also suboptimal. Hence, exists least one agentget si . particular, exists least one item j si agentget. Since agent desires j, theorem follows.Corollary 3.9 Unless P = N P , polynomial time truthful VCG-based mechanismcombinatorial auctions reasonable.believe natural allocation algorithms (e.g., linear programming relaxations, algorithms greedily allocate items agents, local search algorithms)yield anomaly. particular, presume agent wants singlesubset items subsets disjoined, algorithm nd optimalallocation. Thus, corollary suggests might dicult develop allocationalgorithms yield truthful VCG-based mechanisms.show generalize results ane-based mechanism. Given tuple= (a0 , . . . , ), dene V space types v two dierentallocations x y, ga (v, x) = ga (v, y). Similarly unweighted case, sayalgorithm optimal range respect ga (.) always produces allocationsmaximize ga (.).31fiNisan & RonenTheorem 3.10 Consider ane-based mechanism combinatorial auction problemdened allocation algorithm k(.), tuple = (a0 , . . . , ). mechanismtruthful, k(.) maximal range respect ga (.) V .Proof: (sketch) proof similar proof Theorem 3.2 thus sketch it.Dene V similarly w.r.t. ane transformation ga (.). Assume contradictionexists type vector v k(v) optimal O. Let optimalallocation range O, w V k(w) = y. According Lemma 2.2,utility agent maximized weighted welfare ga ((v , wi ), .). Thus,possible proceed along lines proof Theorem 3.2: Dene type vector zsimilarly; then, start w gradually transform agents z concludek(z) = y; gradually transform agents z v show k(v) = y, i.e.,contradiction.Open Questions currently know whether theorems similar Theorem 3.2hold valuations bounded. Moreover, know get ridusage V . Thus, preclude possibility Corollary 3.7 holdspace possible types discrete. also know whether holdallocation algorithm randomized whether Bayesian versions theorems applyexpected externality mechanism (dAspremont & Gerard-Varet, 1979) (an analogVCG Bayesian model). leave future research. conjecture similartheorems apply many mechanism design problems.3.2 Truthful VCG-based Mechanisms Cost Minimization Problemsshow many natural cost minimization problems, truthful VCG-basedmechanism either optimal produces results arbitrarily far optimal.start sample problem.Multicast transmissions: communication network modeled directed graphG = (V, E). edge e privately owned link. cost te sending message alongedge privately known owner. Given source V set Vterminals, mechanism must select subtree rooted covers terminals.message broadcasted along tree. assume agent owns cutnetwork.Naturally, goal mechanism select, among possible trees, tree Rminimizes total cost:eR te . goal agent maximize prot:pi (eR owned i) te . dicult see utilitarian mechanism designproblem.example introduced Feigenbaum et al., 2000 (using dierent model).motivated need broadcast long messages (e.g., movies) Internet.generalize example.Denition 11 (cost minimization allocation problem)cost minimization allocation problem (CMAP) mechanism design problem described by:32fiComputationally Feasible VCG Mechanisms). let =Type space type agent described vector (v1i , . . . , vmmi . (In multicast example corresponds negation cost te .)Allowable outputs output denoted bit vector x = (x11 , . . . , x1m1 , . . . , xn1 , . . . , xnmn ){0, 1}m . denote (xi1 , . . . , ximi ) xi . may additional constraintsset allowable outputs. (In example x corresponds tree networksgraph xij equals 1 corresponding edge chosen tree.)following conditions satised:) describes type agent w v (asUnbounded costs v = (v1i , . . . , vmvectors), w also describes type.Independence monotonicity valuation v depends bits xi . (Inexample, agent valuation given tree depends edges it.)j, wji vji , every output x, wi (xi ) v (xi ).Forcing condition every type v, allowable output x real number ,dene type v[]v[]ij=vjixij = 1otherwise.forcing condition satised every allowable output = x, lim g(t(), y) =.Many natural decentralized task allocation problems goal minimizetotal cost given constraints belong class. particular reader mayverify multicast example falls category. Another example shortestpath problem studied extensively recent years (e.g., Rosenschein & Zlotkin, 1994; Archer& Tardos, 2002; Elkind et al., 2004).Notation: type v let gopt (v) denote optimal value g. denote g(v, k(v))gk (v).Denition 12 (degenerate algorithm) output algorithm k called degenerateg (v)gopt (v)unbounded, i.e., exist vs rk (v) arbitrarilyratio rk (v) = k|gopt (v)|+1large.degenerate algorithm arbitrarily far optimal, additively multiplicatively. Note confused standard notion approximationratio, denition corresponds single problem. particular, number agentsxed. note rule possibility algorithmgood non worst case metric.Theorem 3.11 VCG-based mechanism CMAP truthful, output algorithm either optimal degenerate.33fiNisan & Ronenstating proof let us illustrate using multicast transmission example.Suppose start type vector leads sub-optimal solution. raisecost edge, utility owner cannot increase (due truthfulnessLemma 2.1). gradually raise cost edges except ones optimaltree. Still, algorithm choose sub-optimal tree. However, costsuboptimal tree arbitrarily high optimal cost remains same.Proof: Let = (k, p) non-optimal truthful VCG-based mechanism CMAP.Theorem 3.2, assume pi (w) = j=i wj (k(w)). Let v type vector k(v)optimal let = opt(v) optimal output.dene type z by:zji =vjiyji = 1otherwise.arbitrarily large.Consider type sequence:v0 = (v 1 , . . . , v n )v1 = (z 1 , v 2 , . . . , v n )...vn = (z 1 , . . . , z n ).Claim 3.12 j, = opt(vj ).Proof: denition optimal v0 . Let x = allocation. independencecondition, j, g(vj , y) = g(v0 , y). monotonicity, g(vj , x) g(v0 , x). Together,g(vj , x) g(v0 , x) g(v0 , y) = g(vj , y).Claim 3.13 g(v1 , k(v1 )) < g(v1 , y)Proof: Assume contradiction claim false. Since optimal v1 ,means g(v1 , k(v1 )) = g(v1 , y). independence, g(v1 , y) = g(v0 , y). Recallk(v0 ) suboptimal g(v0 , y) > g(v0 , k(v0 )). monotonicity (we worsentype agent 1), g(v0 , k(v1 )) g(v1 , k(v1 )). Thus, together g(v0 , k(v1 )) g(v1 , k(v1 )) =g(v1 , y) = g(v0 , y) > g(v0 , k(v0 )). particular, g(v0 , k(v1 )) > g(v0 , k(v0 )).Consider case agent 1s type v 1 declarations agents(v 2 , . . . , v n ). According Lemma 2.1, utility truthful, equals g(v0 , k(v0 )).hand, falsely declares z 1 , utility equals g(v0 , k(v1 )). Since showedg(v1 , k(v1 )) > g(v0 , k(v0 )), contradicts truthfulness mechanism.Similarly, obtain g(vn , k(vn )) < g(vn , y) = g(v0 , y). forcing condition,g(vn , k(vn )) . Thus, algorithm degenerate.Corollary 3.14 Unless P = N P , polynomial time truthful VCG-based mechanismNP-hard CAMP degenerate.34fiComputationally Feasible VCG MechanismsNote due revelation principle, theorems section hold mechanism agents dominant strategies. Similarly Theorem 3.11, mechanismuses VCG payments non-optimal ex-post Nash equilibrium also equilibriaarbitrarily far optimal.show generalize theorems section ane-based mechanisms.Theorem 3.15 ane-based mechanism (k, p) CMAP truthful, outputalgorithm either optimal degenerate.Proof:(sketch) proof almost identical proof Theorem 3.11. Let vtype k(w) optimal w.r.t. corresponding ane transformation ga .dene type vector z similarly Theorem 3.11 consider sequence type vectorsagent turn changes type wi z . Due incentive compatibilityLemma 2.2 , utility agent cannot increase, meaning weighted welfarega remains sub-optimal. Due forcing condition, outputs except optimal,arbitrarily high cost. means algorithm degenerate.compensation bonus mechanism (Nisan & Ronen, 2001) identies utilityagents total welfare similarly VCG, i.e., utility agent described similarly Lemma 2.1. Thus, theorems section appliedcompensation bonus mechanisms well.4. Second Chance Mechanismsdate, ane maximization known general method developmenttruthful mechanisms. Therefore, results previous section leave much hopedevelopment truthful mechanisms many complex problems.section proposes method circumventing problem. Consider VCG-basedmechanism. immediate consequence Lemma 2.1 reason agentmisreport type help algorithm improve overall result. leadsintuition agents cannot improve upon underlying algorithm,better truthful. would like exploit special property VCG-basedmechanisms construct mechanisms almost truthful.Given algorithm corresponding optimization problem dene second chance mechanism based it. mechanism modication VCG-basedmechanism addition valuations, agents allowed submit appealfunctions. appeal function allows agent give algorithm input (vectordeclared valuations) dierent original input without misreportingtype. agents behave truthfully, welfare obtained mechanism leastgood one obtained algorithms output.formulate rationale truthfulness second chance mechanisms. Informally, argument follows: reasonable assumptions, situationagent believes benecial lie mechanism, better reportactual type mechanism ask appeal check whether lie indeed helpful.Thus, agent construct truthful strategy premised fact aware35fiNisan & Ronensituation another strategy better it. believe strongargument truth-telling.generalization results ane maximization compensation bonusmechanisms straightforward.4.1 Mechanismsection formulate second chance mechanism basic properties.Denition 13 (appeal function) Let V =appeal partial function5 l : V V .Videnote type space agents.semantics appeal l(.) is: agents type vector v = (v1 , . . . , vn ),believe output algorithm k(.) produces better result (w.r.t. v) giveninput l(v) instead actual input v. appeal function gives agent opportunityimprove algorithms output. v domain l(.), semanticsagent know cause algorithm compute better result k(v).second chance mechanism dened Figure 4.1. modication VCGallows agents submit appeal functions well.execution manager mechanism publishes outcome determination algorithm time limit computation time appeal.Declaration agent submits type declaration wi appeal function li (.)mechanism. appeals must adhere specied time limit.Allocation Let w = (w1 , . . . , wn ). mechanism computes k(w), k(l1 (w)), . . . , k(ln (w))chooses among outputs one maximizes total welfare (accordingw).Payment Let denote chosen output. mechanism calculates payments according VCG formula: pi = j=i wj (o) + hi (wi , li ) (where hi (.) realfunction).Figure 1: Second Chance MechanismRemarks agents send programs represent appeal functions mechanism. programs executed mechanism. mechanism terminatecomputation appeal units computation time (and refer vectordeclarations w appeals domain). Thus, assume w.l.o.g.appeals adhere given time limit. discussion choice time limitalternative representations appeal functions appears Section 4.3. believepossible construct software tools APIs make formulationappeals easy task.5. function f : R called partial domain subset D, i.e. Dom(f ) D.36fiComputationally Feasible VCG Mechanismsfunctions hi (.) play role agents considerations every hi (.)independent actions. Section 4.4 possible simply assume hi (.) 0i. Section 4.4 use functions order satisfy individual rationality.Denition 14 (truthful action) action second chance mechanism pair(wi , li ) wi type declaration li (.) appeal function. action calledtruthful wi = v .following observation key property mechanism.Proposition 4.1 Consider second chance mechanism output algorithm k.every type vector v = (v 1 , . . . , v n ), agents truth-telling, g(v, o) g(w, k(v)).words, agents truth-telling, result mechanism leastgood k(v). proof immediate denition mechanism.formulate analog Lemma 2.1. proof similar lemmas proofhenceforth omitted.Lemma 4.2 (second chance utility) Consider second chance mechanism. Letchosen output. utility agent equals g((v , wi ), o) + hi (wi , li ).Therefore, informally, benecial agent declare wi = v either helpsoutput algorithm k(.) compute better result (w.r.t. (v , wi )) helps oneappeals agents.Note lying second chance mechanism may harm agent two ways. First,damage output algorithm k(.). Second, cause mechanism measurewelfare according wrong type vector thus cause choose inferior output.Notation: say second chance mechanism T-limited time limit species. Similarly, algorithm called T-limited computational time never exceedsunits computation.following proposition obvious.Proposition 4.3 Consider -limited second chance mechanism. output algorithmmechanism also -limited, overall computational time mechanismO(nT ).4.1.1 toy exampleConsider combinatorial auction two items. type agent 3-tuple representingvalue every non empty subset items. Suppose agent values pairitems $3 million values every single item $1 million. type is, therefore, v =37fiNisan & Ronen{3, 1, 1}. Suppose agent notices allocation algorithm often produces betterallocations declares wi = {3, 0, 0} (i.e., hides willingness accept one item).VCG-based mechanism agent may prefer declare wi instead actual type.might cause two problems:1. Even others truthful, may many type vectors v belonging agents, declaring wi damages chosen allocation, i.e.,g((v , wi ), k((wi , wi ))) < g((v , wi ), k((v , wi ))).2. Even case every agent chooses declaration wig((v , wi ), k((wi , v ))) g((v , wi ), k(w)), may according actualtype vector v output k(w) may inferior k(v) (i.e., g(v, k(w)) < g(v, k(v))).second chance mechanism enables agent check whether declaring falsied typewould yield better result. Instead declaring wi = {3, 0, 0}, agent declareactual type dene appeal li (w ) = (wi , wi ). way agent enjoysworlds. cases falsied type better, mechanism prefer k((wi , wi ))k((v , wi )). cases truthful declaration better, mechanism preferk((v , wi )). Note mechanism allows appeal modify declarationagent submitted also whole vector declarations. allow usprovide strong argument truth-telling.Possible Variants Second Chance Mechanism One alternative denitionmechanism let agents submit outcome determination algorithms insteadappeals. possible apply reasoning similar variant. However,formulating output algorithms might demanding task many applications.also delicate dierences.Another possibility dene multi-round variant mechanism. rstround agents submit type declarations w. Then, round, agent getschance improve allocation found algorithm k(w). mechanism terminatesagent improves current allocation. strategy space multi-round mechanisms complex. Yet, myopic behavior (Parkes, 1999), arguments similarused justify truthful behavior. arguments may explain relativesuccess ad hoc mechanisms iterative VCG (IVG) AUSM6 reported Bankset al., 1989.Standard Equilibria Second Chance Mechanisms second chance mechanismuses VCG payments and, therefore, theorems rst part paper apply it.Lemma 4.2, vector truthful actions ex post equilibriumresulting allocation optimal range algorithm. Moreover, consider agentlet (wi , li ) set actions agents. (wi , li ) best responseagent resulting allocation optimal range underlyingalgorithm respect (v , wi ). least intuitively, nding response least6. mechanisms spirit second chance mechanism, let agents improveallocation. actual rules mechanisms complicated described Banks et al.,1989.38fiComputationally Feasible VCG Mechanismshard nding allocation optimal range algorithm. Thus, oneexpect agents follow equilibrium strategies traditional sense. arguesimilar arguments made every game computing best responsecomputationally dicult. Hence, argument takes account agentslimitations required. note succeed nding natural complexitylimitations truth-telling equilibria agents. leaveintriguing open problem.4.2 Rationale Truth-tellingnoted, standard equilibria expected second chance mechanisms.section formulates rationale truth-telling mechanisms. rst introducenotion feasibly dominant actions7 takes account fact agentscapabilities limited. demonstrate reasonable assumptionsagents, truthful, polynomial time, feasibly dominant actions exist.4.2.1 Feasible Truthfulnessbasic models equilibria game theory justied implicit assumptionagents capable computing best response functions. many games,however, action space huge function complex computed, evenapproximately within reasonable amount time. situations assumptionseems longer valid.section re-formulate concept dominant actions assumptionagents limited capability computing best response. concept meantused context one stage games, i.e. games agents chooseactions without knowing anything others choices. second chance mechanismone stage-game. nutshell, action feasibly dominant agent awaresituation (a vector agents actions) another action better it.Notation: denote action space agent Ai . Given tuple = (a1 , . . . , )actions chosen agents, denote utility agent ui (a).Denition 15 (revision function) revision function agent partial functionform bi : Ai Ai .semantics bi (ai ) knew actions others ai , would choosebi (ai ) (instead ai ). revision function captures cases agent knowswould like act knew others actions. Note optimal revision functionsstandard best-response functions. vector actions ai belongdomain bi (.), semantics agent prefers stick action.Denition 16 (feasible non-regret) Let agent, bi (.) revision function,ai vector actions agents. action ai satises feasible non-regret7. make standard distinction action strategy mapping agents typeaction.39fiNisan & Ronencondition (w.r.t. ai bi ), either ai domain bi ui ((bi (ai ), ai ))ui (a).words, actions may better ai , agent unawarecannot compute choosing action.revision function agent optimal, feasible non-regret equivalentstandard non-regret (best response) condition.Denition 17 (feasibly dominant action) Let agent, bi (.) revision function.action ai called feasibly dominant (w.r.t. bi (.)) every vector ai actionsagents, ai satises feasible non-regret condition (w.r.t. ai bi ).Put dierently, action ai feasibly dominant (when choosing action) agentaware action ai vector ai actions agents,better choosing ai others choose ai . dominant action always feasiblydominant. revision function optimal, feasibly dominant action dominant.Example order demonstrate concept feasibly dominant actions considerchess match Alice Bob submit computer programs play behalf.Currently, course known compute equilibrium chess thereforestandard equilibria relevant analysis game. program aA feasiblydominant Alice aware possible program Bobbetter submitting another program.Denition 18 (feasibly truthful action) action ai second chance mechanismcalled feasibly truthful both, truthful feasibly dominant.4.2.2 Natural revision functions give rise feasibly truthful actionsBeforehand showed agents truthful, total welfare leastg(v, k(v)). also argued feasibly truthful action available, agent strongincentive choose it. subsection demonstrates reasonable assumptionsagents, polynomial time feasibly truthful actions exist.Notation: let denote empty appeal. (w, ) denote action vectordeclaration agent wi appeals empty.Denition 19 (appeal-independent revision function) revision function bi (.)called appeal independent every vector domain includes empty appeals, i.e.ai dom(bi ), exists vector wi ai = (wi , ).say appeal independent function -limited computational timebounded every appeal function range.class appeal-independent revision functions represents agents exploreoutput algorithm (or alternatively, base choice action solely outputalgorithm). approach seems reasonable space appeals agents40fiComputationally Feasible VCG Mechanismshuge, apparent structure. least intuitively, seems unreasonable agentable lie way improve result appeals agentssignicant probability. Moreover, commented, agent obvious potentialloss misreporting type.Theorem 4.4 Consider second chance mechanism -limited output algorithm.Suppose agent -limited appeal-independent revision function. every= (T ), mechanism -limited, agent feasibly truthful action.Proof: Let bi (.) agents revision function. Dene appeal li (.) follows.every vector wi , let (wi , ) = bi ((wi , )). Let w = (wi , wi ). Consider outputso1 = k(w) o2 = k( (w)). dene li (w) better two outputs, i.e.,li (w) = arg maxj=1,2 g((v , wi ), oj ). Intuitively, li (.) checks whether declaring wi helpfulagent.Claim 4.5 ai = (v , li ) feasibly truthful.Proof: not, exists vector ai = (wi , ) domain bi (.)u(ai , ai ) < u(bi (ai ), ai ). Let bi (ai ) = (wi , ). Recall according Lemma 4.2,agents utility equivalent total welfare g((v , wi ), o) chosen output(up adding hi (.), independent agents actions).Consider case agents action bi (ai ). Let denote chosen outputcase. According denition mechanism, taken set {o1 , o2 }welfare measured according declaration w.agent chooses truthful action ai , output (denoted o) chosenoutputs o0 = k((v , wi )) (from denition mechanism), both, o1 , o2 (fromdenition li ). superset set outputs rst case. Moreover,output chosen according right type vector (v , wi ). Thus, g((v , wi ), o)g((v , wi ), o), implying agent higher utility second case contradiction.remains show li (.) (T )-limited. obvious both, k(.) (.)-limited. completes proof theorem.Given agents revision function, easy construct appeal li (.) dened (i.e.,construct program computes it). Thus, agent appeal independentfunction, guarantee feasibly dominant action.general class revision functions found Appendix. Interestingly,tradeo generality class time limit, sucesfeasible truthfulness.4.3 Remarks Choice Time LimitSections 4.2.2 A.1 demonstrate two natural classes revision functionsagents polynomial time feasibly truthful actions. claim everyrevision function practice fall categories. Yet, plausiblecase many applications. general, exists tradeo generality41fiNisan & Ronenclass revision functions time limit required feasible truthfulness.particular, without time limit, submitting optimal appeal dominant.hand, plausible small time limits suce practice. leavecomprehensive study tradeo future research.interesting future direction develop representations appeal functionsrelate time limit imposed agent actual revision function. One possibilityrepresent appeals decision trees agents required supplyleaf , type vector v , algorithms result strictly improved givenl(t ) instead actual input v . v proves mechanism computational timerequired compute leaf indeed needed order represent agents revisionfunction. related possibility allow agent purchase additional computationaltime.Currently, know whether every polynomial class revision functions guarantees existence polynomial feasibly truthful actions. agent substantialknowledge appeal space agents, may able nd falsied declaration causes typical appeals produce better results. case, maybenecial agent lie. know whether knowledge exist practice.yes, may possible overcome allowing agents submit meta-appeals,i.e., functions let agents modify input appeals agents.leave future research.4.4 Obtaining Individual Rationalitybasic desirable property mechanisms utility truthful agent guaranteednon-negative (individual rationality). section construct variant secondchance mechanisms satises property.Let gopt (v) denote optimal welfare obtained type vector v . shallassume agent i, exists type v every v = (v 1 , . . . , v n ),gopt ((v , v )) gopt (v). call type lowest. combinatorial auctionexample, lowest type dened zero valuation v (s) = 0 every combinationitems.Clarke mechanism (Clarke, 1971) VCG mechanism hi (wi ) = gopt (v , wi ),i.e., pi (w) = j=i wj (opt(w)) gopt (v , (wi )). words, agent pays welfareloss causes society. Thus, natural dene payment VCG-basedmechanism j=i wj (opt(w)) g((v , wi ), k((v , wi ))).Like truthfulness, individual rationality may preserved optimal algorithm Clarke mechanism replaced sub-optimal one. order xneed ensure result algorithm improve declaration wireplaced lowest type v .Denition 20 (lowest type closure) Given allocation algorithm k(w) denelowest type closure k best allocation (according w) among outputs (k(w), k((v 1 , w1 )), . . . , k((v n , wSince k(.) calls k(.) n times, k -limited, k O(nT )-limited.Claim 4.6 every w, g(w, k(w)) g((v , wi ), k((v , wi ))).42fiComputationally Feasible VCG MechanismsProof: Since k((v , wi )) candidate output k tests, g(w, k(w)) g(w, k((v , wi ))).Given denition v , g(w, k((v , wi ))) g((v , wi ), k(v , wi )), claim follows.Denition 21 (second chance-IR) Given allocation algorithm k(w) time limitdene corresponding second chance-IR mechanism second chance mechanismoutput algorithm k(.), time limit , every agent i, hi (wi ) = g((v , wi ), k((v , wi ))).utility truthful agent mechanism equals ui = g(w, o)g((v , wi ), k((v , wi )))g(w, k(w)) g((v , wi ), k((v , wi ))) 0. Therefore, mechanism satises individual rationality.5. Conclusion Future Researchpaper studies VCG mechanisms optimal outcome determination algorithmreplaced sub-optimal computationally tractable algorithm. rst partpaper shows wide range problems, mechanisms lose game theoreticvirtues optimal counterparts. Similar results hold ane maximization.results leave much hope development polynomial time truthful mechanismsmany problems high complexity.second part paper proposes general method overcoming dicultyconstructing truthful mechanisms. Given algorithm underlying optimizationproblem dene second chance mechanism based it. demonstratereasonable assumptions agents, truth-telling still rational strategyagents. agents truthful, welfare obtained mechanism leastgood one obtained underlying algorithm.Successful implementation second chance mechanisms relies several toolsdeveloped particular, tools description valuations appeal functions.engineering issues require exploration.important stress second chance method yet tested.particular, truthfulness agents validated experimentally.hand, believe practice, small time limits agents appeals likelyguarantee truthfulness agents. Several questions regarding payment propertiessecond chance mechanisms open. leave future research.Several open questions, directly stem work, raised within bodypaper.Acknowledgmentsthank Abraham Newman Motty Perry helpful discussions various stageswork. thank Ron Lavi, Ahuva Mualem, Elan Pavlov, Inbal Ronen, anonymousreviewers comments earlier drafts paper. Noam Nisan supportedgrants Israel Science Foundation USA-Israel Binational ScienceFoundation. Amir Ronen supported part grant number 969/06 IsraelScience Foundation. preliminary version paper appeared proceedings3rd ACM Conference Electronic Commerce (EC 01).43fiNisan & RonenAppendix A. d-bounded Revision Functionsclass d-bounded revision functions represents agents that, addition outputalgorithm, explore polynomial family potential appeals agents. classgeneralization d-limited appeal-independent functions.Denition 22 (d-bounded revision function) say revision function bi (.)d-bounded following hold:1. revision function bi (.) O(nd )-limited.2. LetL = {lj | li,j , wi s.t. (wi , (li , li,j )) Dom(bi )}{li | (wi , li ), wi s.t. (wi , li ) = bi ((wi , li ))}family appeals appear either domain range bi (.).|L| = O(nd ).3. exists constant c every appeal l L cnd -limited.Theorem A.1 Consider second chance mechanism O(nd )-limited output algorithm. Suppose agent d-bounded revision function. every = (n2d ),mechanism -limited, agent feasibly truthful action.Proof: Let agent let bi revision function. use simulationargument order dene appeal li (.). every vector wi compute followingoutputs:1. o0 = k(w).2. Similarly proof Theorem 4.4, let L = {1 . . . |L| } familyappeal functions domain range bi . j = 1, . . . |L| deneoj = k(j (w))).3. Dene l(w) = arg max0j|L| g((v , wi ), oj ) output maximum welfareaccording (v , wi ) among outputs dened above.Claim A.2 li (.) n2d -limited.Proof: W.l.o.g. running time k(.) bounded cnd . Otherwise, raiseconstant. According denitions, appeal li performs nd + 1 computations,requiring cnd time units. Thus, overall computation takes O(n2d ).Claim A.3 ai = (v , li ) feasibly truthful.Proof: Assume contradiction exists action vector ai dom(bi )u((ai , ai ) < u((bi (ai ), ai ).Consider case agent chooses bi (ai ) = (wi , ). mechanism takesoutput maximizes welfare (according w) following set outputs:44fiComputationally Feasible VCG Mechanisms1. o0 = k(w).2. oj = k(lj (w)) every j = i, i.e. result appeals agents.3. oi = k( (w)).agent chooses ai , outputs measured according right typevector (vi , wi ). Moreover, taken following superset outputs S:1. o0 = k((vi , wi )) (from denition mechanism).2. oj = k(lj ((vi , wi ))) every j = i, i.e., result appeals agents(also, denition mechanism).3. oj = k( (w)) every L. Since ai domain bi , set includesoutputs form k(lj (w)) case chooses bi (ai ). also containsresult appeal (w).4. k(w) (from denition li (.)).Let chosen output case. Since set outputs second casesuperset rst, g((vi , wi ), o) g((vi , wi ), o). According Lemma 4.2 utilityagent choosing ai thus higher choosing bi (ai ) contradiction.completes proof Theorem A.1.case appeal-independent functions, theorem gives prescription constructing appeal guarantees agent feasibly dominant action.ReferencesAnderson, E., Kelly, F., & Steinberg, R. (2002). contract balancing mechanismsharing capacity communication network.. appear.Archer, A., & Tardos, E. (2002). Frugal path mechanisms. Proceedings 13thAnnual ACM-SIAM Symposium Discrete Algorithms, 991999.Banks, J., Ledyard, J., & Porter, D. (1989). Allocating uncertain unresponsive resources: experimental approach. RAND Journal Economics, 20, 125.Bartal, Y., Gonen, R., & Nisan, N. (2003). Incentive compatible multi unit combinatorialauctions. Proceedings Ninth Conference Theoretical Aspects RationalityKnowledge, pp. 7287.Bartholdi, J. J., Tovey, C. A., & Trick., M. A. (1992). hard control election?.Mathematical Computer Modelling (Special Issue Formal Theories Politics),16, 2740.Carroll, T. E., & Grosu, D. (2005). Distributed algorithmic mechanism design schedulingunrelated machines. Proceedings 8th International Symposium ParallelArchitectures, Algorithms, Networks, pp. 194199.45fiNisan & RonenClarke, E. H. (1971). Multipart pricing public goods. Public Choice, 1733.Cramton, P. (1997). fcc spectrum auction: early assessment. Journal EconomicsManagement Strategy, 431495.Cramton, P., Shoham, Y., & Steinberg, R. (2006). Combinatorial Auctions. MIT Press.dAspremont, C., & Gerard-Varet, L. (1979). Incentives incomplete information. Journal Public Economics, 11 (1), 2545.Elkind, E., Sahai, A., & Steiglitz, K. (2004). Frugality path auctions. Proceedings15th Annual ACM-SIAM Symposium Discrete Algorithms, pp. 701709.Feigenbaum, J., Papadimitriou, C., & Shenker, S. (2000). Sharing cost multicasttransmissions. Proceeding Thirty-Second Annual ACM Symposium TheoryComputing.Groves, T. (1973). Incentives teams. Econometrica, 41, 617631.Holzman, R., Kr-Dahav, N., Monderer, D., & Tennenholtz, M. (2004). Bundling equilibrium combinatorial auctions. Games Economic Behavior, 47, 104123.Holzman, R., & Monderer, D. (2004). Characterization ex post equilibrium vcgcombinatorial auctions. Games Economic Behavior, 47, 87103.Lavi, R., Nisan, N., & Mualem, A. (2003). Towards characterization truthful combinatorial auctions. Proceedings 44th Annual IEEE Symposium FoundationsComputer Science.Lehmann, D., OCallaghan, L., & Shoham, Y. (2002). Truth revelation rapid, approximately ecient combinatorial auctions. Journal ACM, 49 (5), 577602.preliminay version appeared Proc. rst ACM Conference Electronic Commerce.Mas-Collel, A., Whinston, W., & Green, J. (1995). Microeconomic Theory. Oxford universitypress.Nisan, N. (2000). Bidding allocation combinatorial auctions. ProceedingsSecond ACM Conference Electronic Commerce, pp. 112.Nisan, N., & Ronen, A. (2001). Algorithmic mechanism design. Games EconomicBehaviour, 35, 166196. Extended abstract appeared Proceedings ThirtyFirst Annual ACM symposium Theory Computing.Osborne, M. J., & Rubinstein, A. (1994). Course Game Theory. MIT press.Parkes, D. (1999). ibundle: ecient ascending price bundle auction.. ProceedingsACM Conference Electronic Commerce (EC-99), pp. 148157.Porter, R., Ronen, A., Shoham, Y., & Tennenholtz, M. (2002). Mechanism designexecution uncertainty. Proceedings 18th Conference UncertaintyArticial Intelligence, pp. 414421.Roberts, K. (1979). characterization implementable choise rules. Laont, J.-J.(Ed.), Aggregation Revelation Preferences, pp. 321349. North-Holland. Paperspresented rst European Summer Workshop Econometric Society.46fiComputationally Feasible VCG MechanismsRonen, A. (2001). Mechanism design incomplete languages. ProceedingsThird ACM Conference Electronic Commerce, 105114.Rosenschein, J. S., & Zlotkin, G. (1994). Rules Encounter: Designing ConventionsAutomated Negotiation Among Computers. MIT Press.Shoham, Y., & Tanaka, K. (1997). dynamic theory incentives multi-agent systems(preliminary report). Proceedings Fifteenth International Joint ConferencesArticial Intelligence, pp. 626631.Shoham, Y., & Tennenholtz, M. (2001). fair imposition tasks multi-agent systems.Proceedings International Conference Articial Intelligence, pp. 10831088.Vickrey, W. (1961). Counterspeculation, auctions competitive sealed tenders. JournalFinance, 837.Wellman, M., Wurman, P., Walsh, W., & MacKie-Mason, J. (2001). Auction protocolsdecentralized scheduling. Games Economic Behavior, 35, 271303.Zuckerman, D. (2006). Linear degree extractors inapproximability max cliquechromatic number. Proceedings 38th ACM Symposium TheoryComputing, Seattle, Washington, USA.47fi