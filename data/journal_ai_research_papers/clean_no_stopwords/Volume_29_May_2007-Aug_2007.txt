Journal Artificial Intelligence Research 29 (2007) 105-151

Submitted 05/06; published 06/07

Combination Strategies Semantic Role Labeling
Mihai Surdeanu
Llus Marquez
Xavier Carreras
Pere R. Comas

surdeanu@lsi.upc.edu
lluism@lsi.upc.edu
carreras@lsi.upc.edu
pcomas@lsi.upc.edu

Technical University Catalonia,
C/ Jordi Girona, 1-3
08034 Barcelona, SPAIN

Abstract
paper introduces analyzes battery inference models problem semantic role labeling: one based constraint satisfaction, several strategies model
inference meta-learning problem using discriminative classiers. classiers
developed rich set novel features encode proposition sentence-level
information. knowledge, rst work that: (a) performs thorough analysis learning-based inference models semantic role labeling, (b) compares several
inference strategies context. evaluate proposed inference strategies
framework CoNLL-2005 shared task using automatically-generated syntactic
information. extensive experimental evaluation analysis indicates
proposed inference strategies successful outperform current best results
reported CoNLL-2005 evaluation exercise proposed approaches
advantages disadvantages. Several important traits state-of-the-art SRL combination strategy emerge analysis: (i) individual models combined
granularity candidate arguments rather granularity complete solutions;
(ii) best combination strategy uses inference model based learning; (iii)
learning-based inference benets max-margin classiers global feedback.

1. Introduction
Natural Language Understanding (NLU) subeld Articial Intelligence (AI)
deals extraction semantic information available natural language texts.
knowledge used develop high-level applications requiring textual document
understanding, Question Answering Information Extraction. NLU complex
AI-complete problem needs venture well beyond syntactic analysis natural
language texts. state art NLU still far reaching goals, recent
research made important progress subtask NLU: Semantic Role Labeling.
task Semantic Role Labeling (SRL) process detecting basic event structures
whom, where. See Figure 1 sample sentence annotated
event frame.
1.1 Motivation
SRL received considerable interest past years (Gildea & Jurafsky, 2002;
Surdeanu, Harabagiu, Williams, & Aarseth, 2003; Xue & Palmer, 2004; Pradhan, Hac
2007
AI Access Foundation. rights reserved.

fiSurdeanu, Marquez, Carreras, & Comas

cioglu, Krugler, Ward, Martin, & Jurafsky, 2005a; Carreras & Marquez, 2005).
shown identication event frames signicant contribution many
NLU applications Information Extraction (Surdeanu et al., 2003), Question Answering (Narayanan & Harabagiu, 2004), Machine Translation (Boas, 2002), Summarization (Melli, Wang, Liu, Kashani, Shi, Gu, Sarkar, & Popowich, 2005), Coreference
Resolution (Ponzetto & Strube, 2006b, 2006a).
syntactic perspective, machine-learning SRL approaches classied
one two classes: approaches take advantage complete syntactic analysis text,
pioneered Gildea Jurafsky (2002), approaches use partial syntactic analysis,
championed previous evaluations performed within Conference Computational
Natural Language Learning (CoNLL) (Carreras & Marquez, 2004, 2005). wisdom
extracted rst representation indicates full syntactic analysis signicant
contribution SRL performance, using hand-corrected syntactic information (Gildea
& Palmer, 2002). hand, automatically-generated syntax available,
quality information provided full syntax decreases state-ofthe-art full parsing less robust performs worse tools used partial
syntactic analysis. real-world conditions, dierence two SRL
approaches (with full partial syntax) high. interestingly, two SRL
strategies perform better different semantic roles. example, models use full
syntax recognize agent theme roles better, whereas models based partial syntax
better recognizing explicit patient roles, tend farther predicate
accumulate parsing errors (Marquez, Comas, Gimenez, & Catala, 2005).
1.2 Approach
article explore implications observations studying strategies
combining output several independent SRL systems, take advantage
dierent syntactic views text. given sentence, combination models receive
labeled arguments individual systems, produce overall argument structure
corresponding sentence. proposed combination strategies exploit several levels
information: local global features (from individual models) constraints
argument structure. work, investigate three dierent approaches:
rst combination model parameters estimate; makes use
argument probabilities output individual models constraints argument
structures build overall solution sentence. call model inference
constraint satisfaction.
second approach implements cascaded inference model local learning: rst,
type argument, classier trained oine decides whether candidate
nal argument. Next, candidates passed previous step
combined solution consistent constraints argument structures.
refer model inference local learning.
third inference model global: number online ranking functions, one
argument type, trained score argument candidates correct
argument structure complete sentence globally ranked top. call
model inference global learning.
106

fiCombination Strategies Semantic Role Labeling



NP

NP

VP
NP

PP

luxury auto maker last year sold 1,214 cars U.S.
A0
Agent

AMTMP
Temporal
Marker

P

A1
Predicate Object

AMLOC
Locative
Marker

Figure 1: Sample sentence PropBank corpus.
proposed combination strategies general depend way
candidate arguments collected. empirically prove experimenting
individual SRL systems developed house, also 10 best systems
CoNLL-2005 shared task evaluation.
1.3 Contribution
work introduced paper several novel points. knowledge,
rst work thoroughly explores inference model based meta-learning (the
second third inference models introduced) context SRL. investigate metalearning combination strategies based rich, global representations form local
global features, form structural constraints solutions. empirical
analysis indicates combination strategies outperform current state
art. Note combination strategies proposed paper re-ranking
approaches (Haghighi, Toutanova, & Manning, 2005; Collins, 2000). Whereas re-ranking
selects overall best solution pool complete solutions individual models,
combination approaches combine candidate arguments, incomplete solutions,
different individual models. show approach better potential, i.e., upper
limit F1 score higher performance better several corpora.
second novelty paper performs comparative analysis several combination strategies SRL, using framework i.e., pool
candidates evaluation methodology. large number combination
approaches previously analyzed context SRL larger context
predicting structures natural language texts e.g., inference based constraint satisfaction (Koomen, Punyakanok, Roth, & Yih, 2005; Roth & Yih, 2005), inference based
local learning (Marquez et al., 2005), re-ranking (Collins, 2000; Haghighi et al., 2005) etc.
still clear strategy performs best semantic role labeling. paper
107

fiSurdeanu, Marquez, Carreras, & Comas

provide empirical answers several important questions respect. example,
combination strategy based constraint satisfaction better inference model based
learning? Or, important global feedback learning-based inference model?
analysis indicates following issues important traits state-of-the-art
combination SRL system: (i) individual models combined argument granularity
rather granularity complete solutions (typical re-ranking); (ii) best
combination strategy uses inference model based learning; (iii) learning-based
inference benets max-margin classiers global feedback.
paper organized follows. Section 2 introduces semantic corpora used
training evaluation. Section 3 overviews proposed combination approaches.
individual SRL models introduced Section 4 evaluated Section 5. Section 6
lists features used three combination models introduced paper.
combination models described Section 7. Section 8 introduces empirical analysis proposed combination methods. Section 9 reviews related work
Section 10 concludes paper.

2. Semantic Corpora
paper used PropBank, approximately one-million-word corpus annotated
predicate-argument structures (Palmer, Gildea, & Kingsbury, 2005). date, PropBank addresses predicates lexicalized verbs. Besides predicate-argument structures,
PropBank contains full syntactic analysis sentences, extends Wall Street
Journal (WSJ) part Penn Treebank, corpus previously annotated
syntactic information (Marcus, Santorini, & Marcinkiewicz, 1994).
given predicate, survey carried determine predicate usage, and,
required, usages divided major senses. However, senses divided
syntactic grounds semantic, following assumption syntactic frames
direct reection underlying semantics. arguments predicate numbered sequentially A0 A5. Generally, A0 stands agent, A1 theme direct
object, A2 indirect object, benefactive instrument, semantics tend verb
specic. Additionally, predicates might adjunctive arguments, referred AMs.
example, AM-LOC indicates locative AM-TMP indicates temporal. Figure 1 shows
sample PropBank sentence one predicate (sold) 4 arguments. regular
adjunctive arguments discontinuous, case trailing argument fragments
prexed C-, e.g., [A1 funds] [predicate expected] [CA1 begin operation
around March 1]. Finally, PropBank contains argument references (typically pronominal),
share label actual argument prexed R-.1
paper use syntactic information Penn Treebank. Instead,
develop models using automatically-generated syntax named-entity (NE) labels,
made available CoNLL-2005 shared task evaluation (Carreras & Marquez, 2005).
CoNLL data, use syntactic trees generated Charniak parser (Char1. original PropBank annotations, co-referenced arguments appear single item, differentiation referent reference. use version data used CoNLL
shared tasks, reference arguments automatically separated corresponding referents
simple pattern-matching rules.

108

fiCombination Strategies Semantic Role Labeling

niak, 2000) develop two individual models based full syntactic analysis, chunk
i.e., basic syntactic phrase labels clause boundaries construct partial-syntax
model. individual models use provided NE labels.
Switching hand-corrected automatically-generated syntactic information means
PropBank assumption argument (or argument fragment discontinuous arguments) maps one syntactic phrase longer holds, due errors syntactic
processors. analysis PropBank data indicates 91.36% semantic
arguments matched exactly one phrase generated Charniak parser. Essentially, means SRL approaches make assumption semantic
argument maps one syntactic construct recognize almost 9% arguments.
statement made approaches based partial syntax caveat
setup arguments match sequence chunks. However, one expects
degree compatibility syntactic chunks semantic arguments higher
due ner granularity syntactic elements chunking algorithms perform better full parsing algorithms. Indeed, analysis PropBank data
supports observation: 95.67% semantic arguments matched sequence
chunks generated CoNLL syntactic chunker.
Following CoNLL-2005 setting evaluated system PropBank
also fresh test set, derived Brown corpus. second evaluation allows us
investigate robustness proposed combination models.

3. Overview Combination Strategies
paper introduce analyze three combination strategies problem
semantic role labeling. three combination strategies implemented shared
framework detailed Figure 2 consists several stages: (a) generation candidate arguments, (b) candidate scoring, nally (c) inference. clarity, describe
rst proposed combination framework, i.e., vertical ow Figure 2. Then, move
overview three combination methodologies, shown horizontally Figure 2.
candidate generation step, merge solutions three individual SRL models
unique pool candidate arguments. individual SRL models range complete
reliance full parsing using partial syntactic information. example, Model 1
developed sequential tagger (using B-I-O tagging scheme) partial
syntactic information (basic phrases clause boundaries), whereas Model 3 uses full
syntactic analysis text handles arguments map exactly one syntactic
constituent. detail individual SRL models Section 4 empirically evaluate
Section 5.
candidate scoring phrase, re-score candidate arguments using local
information, e.g., syntactic structure candidate argument, global information,
e.g., many individual models generated similar candidate arguments. describe
features used candidate scoring Section 6.
Finally, inference stage combination models search best solution
consistent domain constraints, e.g., two arguments predicate cannot
overlap embed, predicate may one core argument (A0-5), etc.
109

fiSurdeanu, Marquez, Carreras, & Comas

Reliance full syntax

Model 1

Model 2

Model 3

Candidate
Generation
Candidate Argument
Pool

Constraint
Satisfaction
Engine

Solution

Inference
Constraint Satisfaction

Learning
(batch)

Learning
(online)

Dynamic
Programming
Engine

Dynamic
Programming
Engine

Solution

Candidate
Scoring

Inference

Solution

Inference
Local Learning

Inference
Global Learning

Figure 2: Overview proposed combination strategies.

combination approaches proposed paper share candidate argument pool. guarantees results obtained dierent strategies
corpus comparable. hand, even though candidate generation
step shared, three combination methodologies dier signicantly scoring
inference models.
rst combination strategy analyzed, inference constraint satisfaction, skips
candidate scoring step completely uses instead probabilities output individual SRL models candidate argument. individual models raw activations
actual probabilities convert probabilities using softmax function (Bishop,
1995), passing inference component. inference implemented using
Constraint Satisfaction model searches solution maximizes certain
compatibility function. compatibility function models probability
global solution also consistency solution according domain constraints.
combination strategy based technique presented Koomen et al. (2005).
main dierence two systems candidate generation step: use
three independent individual SRL models, whereas Komen et al. used SRL model
110

fiCombination Strategies Semantic Role Labeling

trained dierent syntactic views data, i.e., top parse trees generated
Charniak Collins parsers (Charniak, 2000; Collins, 1999). Furthermore, take
argument candidates set complete solutions generated individual models, whereas Komen et al. take dierent syntactic trees, constructing
complete solution. obvious advantage inference model Constraint Satisfaction unsupervised: learning necessary candidate scoring,
scores individual models used. hand, Constraint Satisfaction
model requires individual models provide raw activations, and, moreover,
raw activations convertible true probabilities.
second combination strategy proposed article, inference local learning,
re-scores candidates pool using set binary discriminative classiers.
classiers assign argument score measuring condence argument
part correct, global solution. classiers trained batch mode
completely decoupled inference module. inference component implemented
using CKY-based dynamic programming algorithm (Younger, 1967). main advantage
strategy candidates re-scored using signicantly information
available individual model. example, incorporate features count
number individual systems generated given candidate argument, several
types overlaps candidate arguments predicate also arguments
predicates, structural information based full partial syntax, etc.
describe rich feature set used scoring candidate arguments Section 6. Also,
combination approach depend argument probabilities individual
SRL models (but incorporate features, available). combination approach
complex previous strategy additional step requires
supervised learning: candidate scoring. Nevertheless, mean additional
corpus necessary: using cross validation, candidate scoring classiers trained
corpus used train individual SRL models. Moreover, show Section 8
obtain excellent performance even candidate scoring classiers trained
signicantly less data individual SRL models.
Finally, inference strategy global learning investigates contribution global
information inference model based learning. strategy incorporates global
information previous inference model two ways. First importantly, candidate scoring trained online global feedback inference component.
words, online learning algorithm corrects mistakes found comparing
correct solution one generated inference. Second, integrate global information actual inference component: instead performing inference proposition
independently, whole sentence once. allows implementation
additional global domain constraints, e.g., arguments attached dierent predicates
overlap.
combination strategies proposed described detail Section 7 evaluated
Section 8.
111

fiSurdeanu, Marquez, Carreras, & Comas

4. Individual SRL Models
section introduces three individual SRL models used combination strategies discussed paper. rst two models variations algorithm:
model SRL problem sequential tagging task, semantic argument
matched sequence non-embedding phrases, Model 1 uses partial syntax
(chunks clause boundaries), whereas Model 2 uses full syntax. third model takes
traditional approach assuming exists one-to-one mapping
semantic arguments syntactic phrases.
important note combination strategies introduced later paper
independent individual SRL models used. fact, Section 8 describe
experiments use individual models also best performing SRL
systems CoNLL-2005 evaluation (Carreras & Marquez, 2005). Nevertheless,
choose focus mainly individual SRL approaches presented section
completeness show state-of-the-art performance possible relatively simple
SRL models.
4.1 Models 1 2
models approach SRL sequential tagging task. pre-processing step,
input syntactic structures traversed order select subset constituents organized
sequentially (i.e., non embedding). output process sequential tokenization
input sentence verb predicates. Labeling tokens appropriate
tags allows us codify complete argument structure predicate sentence.
precisely, given verb predicate, sequential tokens selected follows:
First, input sentence split disjoint sequential segments using markers
segment start/end verb position boundaries clauses include
corresponding predicate constituent. Second, segment, set top-most
non-overlapping syntactic constituents completely falling inside segment selected
tokens. Finally, tokens labeled B-I-O tags, depending
beginning, inside, outside predicate argument. Note strategy provides set
sequential tokens covering complete sentence. Also, independent syntactic
annotation explored, assuming provides clause boundaries.
Consider example Figure 3, depicts PropBank annotation two verb
predicates sentence (release hope) corresponding partial full parse
trees. Since verbs main clause sentence, two segments
sentence considered predicates, i.e., dening left right contexts
verbs ([w1 :Others, ..., w3 :just] [w5 :from, ..., w20 :big-time] predicate release,
[w1 :Others, ..., w8 :,] [w10 :the, ..., w20 :big-time] predicate hope). Figure 4
shows resulting tokenization predicates two alternative syntactic structures. case, correct argument annotation recovered cases, assuming
perfect labeling tokens.
worth noting resulting number tokens annotate much lower
number words cases. Also, codications coming full parsing
substantially fewer tokens coming partial parsing. example,
predicate hope, dierence number tokens two syntactic views
112

fiCombination Strategies Semantic Role Labeling

Clause
NP



6

VP
Clause

VP
1

NP

3

ADVP

4

II

NP

PP

VP

,

,

5

2

Others ,

released majors , hope senior league

bridge back bigtime.

Clause
8

1

NP



3

ADVP

2 , II
Others ,

A1

AMTMP

III

VP

IV 4

PP

V

5

NP

VI

7

VP

NP

,
6 VII
released majors , hope senior league
P
A0

Clause

VP

NP

VIII

ADVP PP

NP

bridge back bigtime.

A2
P

A1

Figure 3: Annotation example sentence two alternative syntactic structures.
lower tree corresponds partial parsing annotation (PP) base chunks
clause structure, upper represents full parse tree (FP). Semantic roles
two predicates (release hope) also provided sentence.
encircled nodes trees correspond selected nodes process
sequential tokenization sentence. mark selected nodes
predicate release Western numerals nodes selected hope
Roman numerals. See Figure 4 details.

particularly large (8 vs. 2 tokens). Obviously, coarser token granularity, easier
problem assigning correct output labelings (i.e., less tokens label
also long-distance relations among sentence constituents better captured).
hand, coarser granularity tends introduce unrecoverable errors
pre-processing stage. clear trade-o, dicult solve advance.
using two models combination scheme take advantage diverse sentence
tokenizations (see Sections 7 8).
Compared common tree node labeling approaches (e.g., following
Model 3), B-I-O annotation tokens advantage permitting correctly annotate arguments match unique syntactic constituent. bad side,
heuristic pre-selection candidate nodes predicate, i.e., nodes
sequentially cover sentence, makes number unrecoverable errors higher. Another source errors common strategies errors introduced real partial/full
parsers. calculated due syntactic errors introduced pre-processing
stage, upper-bound recall gures 95.67% Model 1 90.32% Model 2 using
datasets dened Section 8.
113

fiSurdeanu, Marquez, Carreras, & Comas

words
1: Others
2: ,
3:
4: released
5:
6:
7: majors
8: ,
9: hope
10:
11: senior
12: league
13:
14:
15:
16: bridge
17: back
18:
19:
20: big-time

releasePP
1: B A1
2:
3: B AM-TMP

4: B A2
5: A2
6:
7:

tokens
releaseFP
hopePP
1: B A1
I: B A0
2:
II: A0
3: B AM-TMP
III: A0

IV: A0
V: A0
4: B A2
VI: A0
5:

hopeFP

I: B A0

VII: A0




VIII: B A1

II: B A1

6:
8:

Figure 4: Sequential tokenization sentence Figure 3 according two syntactic
views predicates (PP stands partial parsing FP full parsing).
sentence semantic role annotations vertically displayed. token
numbered indexes appear tree nodes Figure 3 contains
B-I-O annotation needed codify proper semantic role structure.

Approaching SRL sequential tagging task new. Hacioglu, Pradhan, Ward,
Martin, Jurafsky (2004) presented system based sequential tagging base chunks
B-I-O labels, best performing SRL system CoNLL-2004 shared
task (Carreras & Marquez, 2004). novelty approach resides fact
sequence syntactic tokens label extracted hierarchical syntactic annotation
(either partial full parse tree) restricted base chunks (i.e., token
may correspond complex syntactic phrase even clause).
4.1.1 Features
tokens selected labeled B-I-O tags, converted training
examples considering rich set features, mainly borrowed state-of-the-art systems (Gildea & Jurafsky, 2002; Carreras, Marquez, & Chrupala, 2004; Xue & Palmer,
2004). features codify properties from: (a) focus token, (b) target predicate,
(c) sentence fragment token predicate, (d) dynamic context,
i.e., B-I-O labels previously generated. describe four feature sets next.2
2. Features extracted partial parsing Named Entities common Model 1 2, features
coming full parse trees apply Model 2.

114

fiCombination Strategies Semantic Role Labeling

Constituent structure features:
Constituent type head: extracted using head-word rules Collins (1999).
rst element PP chunk, head rst NP extracted.
example, type constituent U.S. Figure 1 PP, head
U.S. instead in.
First last words POS tags constituent, e.g., in/IN U.S./NNP
constituent U.S. Figure 1.
POS sequence: less 5 tags long, e.g., INDTNNP sample
constituent.
2/3/4-grams POS sequence.
Bag-of-words nouns, adjectives, adverbs. example, bag-of-nouns
constituent luxury auto maker {luxury, auto, maker}.
TOP sequence: sequence types top-most syntactic elements constituent
(if less 5 elements long). case full parsing corresponds
right-hand side rule expanding constituent node. example, TOP
sequence constituent U.S. INNP.
2/3/4-grams TOP sequence.
Governing category described Gildea Jurafsky (2002), indicates NP
arguments dominated sentence (typical subjects) verb phrase (typical
objects). example, governing category constituent 1,214 cars
Figure 1 VP, hints corresponding semantic role object.
NamedEntity, indicating constituent embeds strictly matches named entity
along type. example, constituent U.S. embeds locative
named entity: U.S..
TMP, indicating constituent embeds strictly matches temporal keyword
(automatically extracted AM-TMP arguments training set). Among
common temporal cue words extracted are: year, yesterday, week, month,
etc. used total 109 cue words.
Previous following words POS tag constituent. example,
previous word constituent last year Figure 1 maker/NN, next
one sold/VBD.
features characterizing focus constituents extracted two previous
following tokens, provided inside boundaries current segment.
Predicate structure features:
Predicate form, lemma, POS tag, e.g., sold, sell, VBD predicate
Figure 1.
Chunk type cardinality verb phrase verb included: single-word
multi-word. example, predicate Figure 1 included single-word VP
chunk.
115

fiSurdeanu, Marquez, Carreras, & Comas

predicate voice. distinguish voice types: active, passive, copulative,
innitive, progressive.
Binary ag indicating verb start/end clause.
Sub-categorization rule, i.e., phrase structure rule expands predicates
immediate parent, e.g., NP NP VP predicate Figure 1.
Predicate-constituent features:
Relative position, distance words chunks, level embedding (in number
clause-levels) respect constituent. example, constituent
U.S. Figure 1 appears predicate, distance 2 words 1 chunk,
level embedding 0.
Constituent path described Gildea Jurafsky (2002) 3/4/5-grams
path constituents beginning verb predicate ending constituent.
example, syntactic path constituent luxury auto maker
predicate sold Figure 1 NP VP VBD.
Partial parsing path described Carreras et al. (2004) 3/4/5-grams path
elements beginning verb predicate ending constituent. example,
path NP + PP + NP + VP VBD indicates current NP token
predicate PP, NP, constituents right (positive sign)
level token path descends clause VP
nd predicate. dierence previous constituent path
arrows anymore introduce horizontal (left/right) movements
syntactic level.
Syntactic frame described Xue Palmer (2004). syntactic frame captures
overall sentence structure using predicate constituent pivots.
example, syntactic frame predicate sold constituent
U.S. NPNPVPNPPP, current predicate constituent emphasized.
Knowing noun phrases predicate lowers probability
constituent serves agent (or A0).
Dynamic features:
BIOtag previous token. training, correct labels left context
used. testing, feature dynamically codied tag previously
assigned SRL tagger.
4.1.2 Learning Algorithm Sequence Tagging
used generalized AdaBoost real-valued weak classiers (Schapire & Singer, 1999)
base learning algorithm. version algorithm learns xed-depth small decision
trees weak rules, combined ensemble constructed AdaBoost.
implemented simple one-vs-all decomposition address multi-class classication.
way, separate binary classier learned B-X I-X argument label
plus extra classier decision.
116

fiCombination Strategies Semantic Role Labeling

AdaBoost binary classiers used labeling test sequences, left right,
using recurrent sliding window approach information tags assigned
preceding tokens. explained previous list features, left tags already assigned
dynamically codied features. Empirically, found optimal left context
taken account reduces previous token.
tested two dierent tagging procedures. First, greedy left-to-right assignment
best scored label token. Second, Viterbi search label sequence
maximizes probability complete sequence. case, classiers predictions
converted probabilities using softmax function described Section 7.1.
signicant improvements obtained latter. selected former,
faster, basic tagging algorithm experiments.
Finally, tagging model enforces three basic constraints: (a) B-I-O output labeling must codify correct structure; (b) arguments cannot overlap clause chunk
boundaries; (c) verb, A0-5 arguments present PropBank frames (taking
union rolesets dierent verb senses) considered.
4.2 Model 3
third individual SRL model makes strong assumption predicate argument
maps one syntactic constituent. example, Figure 1 A0 maps noun phrase,
AM-LOC maps prepositional phrase, etc. assumption holds well hand-corrected
parse trees simplies signicantly SRL process one syntactic constituent correctly classied order recognize one semantic argument.
hand, approach limited using automatically-generated syntactic trees.
example, 91.36% arguments mapped one syntactic constituents
produced Charniak parser.
Using bottom-up approach, Model 3 maps argument rst syntactic constituent exact boundaries climbs high possible
tree across unary production chains. currently ignore arguments map
single syntactic constituent. argument-constituent mapping performed
training set preprocessing step. Figure 1 shows mapping example semantic
arguments one verb corresponding sentence syntactic structure.
mapping process completes, Model 3 extracts rich set lexical, syntactic,
semantic features. features inspired previous work parsing
SRL (Collins, 1999; Gildea & Jurafsky, 2002; Surdeanu et al., 2003; Pradhan et al.,
2005a). describe complete feature set implemented Model 3 next.
4.2.1 Features
Similarly Models 1 2 group features three categories, based properties
codify: (a) argument constituent, (b) target predicate, (c) relation
constituent predicate syntactic constituents.
Constituent structure features:
syntactic label candidate constituent.

constituent head word, suffixes length 2, 3, 4, lemma, POS tag.
117

fiSurdeanu, Marquez, Carreras, & Comas

constituent content word, suffixes length 2, 3, 4, lemma, POS tag, NE
label. Content words, add informative lexicalized information dierent
head word, detected using heuristics Surdeanu et al. (2003). example,
head word verb phrase placed auxiliary verb had, whereas
content word placed. Similarly, content word prepositional phrases
preposition (which selected head word), rather head
word attached phrase, e.g., U.S. prepositional phrase U.S..
first last constituent words POS tags.
NE labels included candidate phrase.
Binary features indicate presence temporal cue words, i.e., words appear
often AM-TMP phrases training. used list temporal cue words
Models 1 2.
Treebank syntactic label added feature indicate number
labels included candidate phrase.
TOP sequence constituent (constructed similarly Model 2).
phrase label, head word POS tag constituent parent, left sibling,
right sibling.
Predicate structure features:
predicate word lemma.
predicate voice. denition Models 1 2.
binary feature indicate predicate frequent (i.e., appears
twice training data) not.
Sub-categorization rule. denition Models 1 2.
Predicate-constituent features:
path syntactic tree argument phrase predicate
chain syntactic labels along traversal direction (up down).
computed similarly Model 2.
length syntactic path.
number clauses (S* phrases) path. store overall clause count
also number clauses ascending descending part path.
number verb phrases (VP) path. Similarly feature, store
three numbers: overall verb count, verb count ascending/descending
part path.
Generalized syntactic paths. generalize path syntactic tree,
appears 3 elements, using two templates: (a) Arg Ancestor Ni
Pred, Arg argument label, Pred predicate label, Ancestor
label common ancestor, Ni instantiated labels
118

fiCombination Strategies Semantic Role Labeling

Pred Ancestor full path; (b) Arg Ni Ancestor Pred, Ni
instantiated labels Arg Ancestor full path.
example, path NP VP SBAR VP argument label rst NP,
predicate label last VP, common ancestors label rst S. Hence,
using last template, path generalized following three features: NP
VP VP, NP SBAR VP, NP VP. generalization reduces
sparsity complete constituent-predicate path feature using dierent strategy
Models 1 2, implement n-gram based approach.
subsumption count, i.e., dierence depths syntactic tree
argument predicate constituents. value 0 two phrases share
parent.
governing category, similar Models 1 2.

surface distance predicate argument phrases encoded as:
number tokens, verb terminals (VB*), commas, coordinations (CC) argument predicate phrases, binary feature indicate two
constituents adjacent. example, surface distance argument
candidate Others predicate hope Figure 3 example: Others,
released majors, hope senior league... 7 tokens, 1 verb, 2 commas,
0 coordinations. features, originally proposed Collins (1999) dependency parsing model, capture robust, syntax-independent information
sentence structure. example, constituent unlikely argument
verb another verb appears two phrases.

binary feature indicate argument starts predicate particle, i.e.,
token seen RP* POS tag directly attached predicate training.
motivation feature avoid inclusion predicate particles
argument constituent. example, without feature, SRL system tend
incorrectly include predicate particle argument text: take [A1
organization], marked text commonly incorrectly parsed
prepositional phrase large number prepositional phrases directly attached
verb arguments corresponding predicate.
4.2.2 Classifier
Similarly Models 1 2, Model 3 trains one-vs-all classiers using AdaBoost
common argument labels. reduce sample space, Model 3 selects training examples
(both positive negative) from: (a) rst clause includes predicate,
(b) phrases appear left predicate sentence. 98%
argument constituents fall one classes.
prediction time classiers combined using simple greedy technique
iteratively assigns predicate argument classied highest condence.
predicate consider candidates attributes, numbered attributes
indicated corresponding PropBank frame. Additionally, greedy strategy enforces
limited number domain knowledge constraints generated solution: (a) arguments
overlap form, (b) duplicate arguments allowed A0-5, (c)
119

fiSurdeanu, Marquez, Carreras, & Comas

predicate numbered arguments, i.e., A0-5, subset present
PropBank frame. constraints somewhat dierent constraints used
Models 1 2: (i) Model 3 use B-I-O representation hence constraint
B-I-O labeling correct apply; (ii) Models 1 2 enforce
constraint numbered arguments duplicated implementation
straightforward architecture.

5. Performance Individual Models
section analyze performance three individual SRL models proposed.
three SRL systems trained using complete CoNLL-2005 training set (PropBank/Treebank sections 2 21). avoid overtting syntactic processors i.e.,
part-of-speech tagger, chunker, Charniaks full parser partitioned PropBank
training set folds fold used output syntactic processors
trained four folds. models tuned separate development partition (Treebank section 24) evaluated two corpora: (a) Treebank section
23, consists Wall Street Journal (WSJ) documents, (b) three sections
Brown corpus, semantically annotated PropBank team CoNLL-2005 shared
task evaluation.
classiers individual models developed using AdaBoost decision trees depth 4 (i.e., branch may represent conjunction 4 basic
features). classication model trained 2,000 rounds. applied
simplications keep training times memory requirements inside admissible bounds:
(a) trained frequent argument labels: top 41 Model 1, top 35
Model 2, top 24 Model 3; (b) discarded features occurring less 15
times training set, (c) Model 3 classier, limited number
negative training samples rst 500,000 negative samples extracted PropBank
traversal3 .
Table 1 summarizes results three models WSJ Brown corpora.
include percentage perfect propositions detected model (PProps),
i.e., predicates recognized arguments, overall precision, recall, F1
measure4 . results summarized Table 1 indicate individual systems
solid performance. Although none would rank top 3 CoNLL2005 evaluation (Carreras & Marquez, 2005), performance comparable best
individual systems presented evaluation exercise5 . Consistently systems
evaluated Brown corpus, models experience severe performance drop
corpus, due lower performance linguistic processors.
expected, models based full parsing (2 3) perform better model
based partial syntax. But, interestingly, dierence large (e.g., less 2 points
3. distribution samples Model 3 classifiers biased towards negative samples because,
worst case, syntactic constituent sentence predicate potential argument.
4. significance intervals F1 measure obtained using bootstrap resampling (Noreen,
1989). F1 rates outside intervals assumed significantly different related F1
rate (p < 0.05).
5. best performing SRL systems CoNLL combination several subsystems. See section 9
details.

120

fiCombination Strategies Semantic Role Labeling

WSJ
Model 1
Model 2
Model 3
Brown
Model 1
Model 2
Model 3

PProps
48.45%
52.04%
45.28%

Precision
78.76%
79.65%
80.32%

Recall
72.44%
74.92%
72.95%

F1
75.47 0.8
77.21 0.8
76.46 0.6

30.85%
36.44%
29.48%

67.72%
71.82%
72.41%

58.29%
64.03%
59.67%

62.65 2.1
67.70 1.9
65.42 2.1

Table 1: Overall results individual models WSJ Brown test sets.
Model 1 F1
Model 2 F1
Model 3 F1

A0
83.37
86.65
86.14

A1
75.13
77.06
75.83

A2
67.33
65.04
65.55

A3
61.92
62.72
65.26

A4
72.73
72.43
73.85

Table 2: F1 scores individual systems A04 arguments WSJ test.
F1 WSJ corpus), evincing base syntactic chunks clause boundaries
enough obtain competitive performance. importantly, full-parsing models
always better partial-syntax model. Table 2 lists F1 measure three
models rst numbered arguments. Table 2 shows Model 2, overall
best performing individual system, achieves best F-measure A0 A1 (typically
subjects direct objects), Model 1, partial-syntax model, performs best
A2 (typically indirect objects, instruments, benefactives). explanation
behavior indirect objects tend farther predicates accumulate
parsing errors. models based full syntax, Model 2 better recall
whereas Model 3 better precision, Model 3 lters candidate arguments
match single syntactic constituent. Generally, Table 2 shows models
strong weak points. justication focus combination
strategies combine several independent models.

6. Features Combination Models
detailed Section 3, paper analyze two classes combination strategies
problem semantic role labeling: (a) inference model constraint satisfaction,
nds set candidate arguments maximizes global cost function, (b)
two inference strategies based learning, candidates scored ranked using
discriminative classiers. perspective feature space, main dierence
two types combination models input rst combination strategy limited argument probabilities produced individual systems,
whereas last class combination approaches incorporates much larger feature set
ranking classiers. robustness, paper use features extracted solutions provided individual systems, hence independent
121

fiSurdeanu, Marquez, Carreras, & Comas

1111
0000
0000
1111
0000
1111
0000
1111
0000
1111
0000
1111
0000
1111
0000
1111
0000
1111
0000
1111
0000
1111
0000
1111
0000
1111
0000
1111
0000
1111
0000
1111
A0

A0

V

V

A1

A1

V

A1

A2

A4

M1

M2

M3

Figure 5: Sample solutions proposed predicate three individual SRL models:
M1, M2 M3. Argument candidates displayed vertically system.

individual models6 . describe features next. examples given section
based Figures 5 6.
Voting features features quantify votes received argument
individual systems. set includes following features:
label candidate argument, e.g., A0 rst argument proposed system
M1 Figure 5.
number systems generated argument label span.
example shown Figure 5, feature value 1 argument A0 proposed
M1 2 M1s A1, system M2 proposed argument.
unique ids systems generated argument label
span, e.g., M1 M2 argument A1 proposed M1 M2 Figure 5.
argument sequence predicate systems generated argument label span. example, argument sequence generated
system M1 proposition illustrated Figure 5 is: A0 - V - A1 - A2. feature attempts capture information proposition level, e.g., combination model
might learn trust model M1 argument sequence A0 - V - A1 - A2,
M2 another sequence, etc.
Same-predicate overlap features features measure overlap dierent
arguments produced individual SRL models predicate:
6. exception argument probabilities, required constraint satisfaction model.

122

fiCombination Strategies Semantic Role Labeling

number unique ids systems generated argument
span different label. example shown Figure 5, features
values 1 M2 argument A2 proposed M1, model M2 proposed
argument A4 span.
number unique ids systems generated argument included
current argument. candidate argument A0 proposed model M1
Figure 5, features values 1 M3, M3 generated argument A0,
included M1s A0.
spirit, generate number unique ids systems
generated argument contains current argument, number
unique ids systems generated argument overlaps
include contain current argument.
Other-predicate overlap features features quantify overlap dierent arguments produced individual SRL models predicates. generate
features previous feature group, dierence compare arguments generated dierent predicates. motivation overlap features that,
according PropBank annotations, form overlap allowed among arguments
attached predicate, inclusion containment permitted
arguments assigned dierent predicates. overlap features meant detect
domain constraints satised candidate argument, indication,
evidence strong, candidate incorrect.
Partial-syntax features features codify structure argument
distance argument predicate using partial syntactic information,
i.e., chunks clause boundaries (see Figure 6 example). Note features
inherently dierent features used Model 1, Model 1 evaluates
individual chunk part candidate argument, whereas codify properties
complete argument constituent. describe partial-syntax features below.
Length tokens chunks argument constituent, e.g., 4 1 argument
A0 Figure 6.
sequence chunks included argument constituent, e.g., PP NP
argument AM-LOC Figure 6. chunk sequence large, store n-grams
length 10 start end sequence.
sequence clause boundaries, i.e., clause beginning ending, included
argument constituent.
named entity types included argument constituent, e.g., LOCATION
AM-LOC argument Figure 6.
Position argument: before/after predicate sentence, e.g., A1
Figure 6.
Boolean ag indicate argument constituent adjacent predicate,
e.g., false A0 true A1 Figure 6.
123

fiSurdeanu, Marquez, Carreras, & Comas

Clause

NP

NP

VP

NP

PP

NP

luxury auto maker last year sold 1,214 cars U.S.
A0

AMTMP

P

A1

AMLOC

Figure 6: Sample proposition partial syntactic information.
sequence chunks argument constituent predicate, e.g.,
chunk sequence predicate argument AM-LOC Figure 6 is: NP.
Similarly chunk sequence feature, sequence large, store
starting ending n-grams.
number chunks predicate argument, e.g., 1 AM-LOC
Figure 6.
sequence clause boundaries argument constituent predicate.
clause subsumption count, i.e., dierence depths clause
tree argument predicate constituents. value 0 two phrases
included clause.
Full-syntax features features codify structure argument constituent,
predicate, distance two using full syntactic information.
full-syntax features replicated Model 3 (see Section 4.2), assumes
one-to-one mapping semantic constituents syntactic phrases exists. Unlike Model 3
ignores arguments matched syntactic constituent,
exact mapping exist due inclusion candidates Models 1 2,
generate approximate mapping unmapped semantic constituent largest
phrase included given span left boundary semantic constituent. heuristic guarantees capture least semantic
constituents syntactic structure.
motivation partial full-syntax features learn preferences
individual SRL models. example, features combination classier might
learn trust model M1 arguments closer 3 chunks predicate, model
M2 predicate-argument syntactic path NP VP SBAR VP, etc.
Individual systems argument probabilities individual model outputs condence score proposed arguments. scores converted probabilities using softmax function described detail Section 7.1. combination
strategy based constraint satisfaction (Section 7.1) uses probabilities are,
two strategies based meta-learning (Section 7.2) discretize
probabilities include features. so, probability value matched
124

fiCombination Strategies Semantic Role Labeling

one probability intervals corresponding interval used feature.
probability intervals dynamically constructed argument label individual system corresponding system predictions argument label
uniformly distributed across intervals.
Section 8.4 empirically analyze contribution proposed feature
sets performance best combination model.

7. Combination Strategies
section detail combination strategies proposed paper: (a) combination
model constraint satisfaction, aims nding set candidate arguments
maximizes global cost function, (b) two combination models inference based
learning, candidates scored ranked using discriminative classiers.
previous section described complete feature set made available approaches.
focus machine learning paradigm deployed combination
models.
7.1 Inference Constraint Satisfaction
Constraint Satisfaction model selects subset candidate arguments maximizes
compatibility function subject fulllment set structural constraints
ensure consistency solution. compatibility function based probabilities
given individual SRL models candidate arguments. work use Integer
Linear Programming solve constraint satisfaction problem. approach rst
proposed Roth Yih (2004) applied semantic role labeling Punyakanok,
Roth, Yih, Zimak (2004), Koomen et al. (2005), among others. follow setting
Komen et al., taken reference.
rst step, scores model normalized probabilities. scores
yielded classiers signed unbounded real numbers, experimental evidence
shows condence predictions (taken absolute value raw scores)
correlates well classication accuracy. Thus, softmax function (Bishop, 1995)
used convert set unbounded scores probabilities. k possible
output labels given argument sco(li ) denotes score label li output
xed SRL model, estimated probability label is:
esco(li )
p(li ) = Pk
sco(lj )
j=1 e
parameter formula empirically adjusted avoid overly skewed
probability distributions normalize scores three individual models
similar range values. See details experimental setting Section 8.1.
Candidate selection performed via Integer Linear Programming (ILP). program
goal maximize compatibility function modeling global condence selected
set candidates, subject set linear constraints. variables involved
task take integer values may appear rst degree polynomials only.
abstract ILP process described simple fashion as: given set variables V = {v1 , . . . , vn }, aims maximize global compatibility label assignment
125

fiSurdeanu, Marquez, Carreras, & Comas

{l1 , . . . , ln } variables. local compatibility function cv (l) denes compatibility
assigning label l variable v. global compatibility function C(l1 , . . . , ln ) taken
sum local assignment compatibility, goal ILP process
written as:
argmax C(l1 , . . . , ln ) = argmax
l1 ,...,ln

l1 ,...,ln

n
X

cvi (li )

i=1

constraints described set accompanying integer linear equations involving variables problem.
one wants codify soft constraints instead hard, possibility considering penalty component compatibility function. case, constraint
r R seen function takes current label assignment outputs
real number, 0 constraint satised positive number not,
indicating penalty imposed compatibility function. new expression
compatibility function maximize is:
C(l1 , . . . , ln ) =

n
X
i=1

cvi (li )

X

r(l1 , . . . , ln )

rR

Note hard constraints also simulated setting making output
large positive number violated.
particular problem, binary-valued variable vi N argument candidates generated SRL models, i.e., li labels {0, 1}. Given label
assignment, arguments li = 1 selected form solution, others
(those li = 0) ltered out. variable vi , also probability
values, pij , calculated score model j argument i, according softmax
formula described above7 . rst approach, compatibility function cv (li ) equals
P
8
(
j=1 pij )li , number models, , 3 case .
denition, maximizing compatibility function equivalent maximizing
sum probabilities given models argument candidates considered
solution. Since function always positive, global score increases directly
number selected candidates. consequence, model biased towards
maximization number candidates included solution (e.g., tending select
lot small non-overlapping arguments). Following Koomen et al. (2005), bias
corrected adding new score oi , sums compatibility function
i-th candidate selected solution. global compatibility function needs
rewritten encompass new information. Formalized ILP equation, looks like:
argmax C(l1 , . . . , lN ) = argmax

L{0,1}N

L{0,1}N


N X
X

(

i=1 j=1

pij )li + oi (1 li )

7. model j propose argument consider pij = 0.
8. Instead accumulating probabilities models given candidate argument, one could consider
different variable model prediction introduce constraint forcing variables
take value end optimization problem. two alternatives equivalent.

126

fiCombination Strategies Semantic Role Labeling

constraints expressed separated integer linear equations. possible
dene priori value oi . Komen et al. used validation corpus empirically
estimate constant value oi (i.e., independent argument candidate)9 .
use exactly solution working single constant value,
refer O.
Regarding consistency constraints, considered following six:
1. Two candidate arguments verb overlap embed.
2. verb may two core arguments type label A0-A5.
3. argument R-X verb, also X argument
verb.
4. argument C-X verb, also X argument
C-X verb.
5. Arguments two dierent verbs overlap, embed.
6. Two dierent verbs share AM-X, R-AM-X C-X arguments.
Constraints 14 also included reference work (Punyakanok et al., 2004).
constraints paper need checked since individual model
outputs consistent solutions. Constraints 5 6, restrict set compatible
arguments among dierent predicates sentence, original work.
Integer Linear Programming setting constraints written inequalities. example,
Ai argument label i-th candidate Vi verb predicate, constraint number
P
2 written as: (Ai =a Vi =v) li 1, given verb v argument label a.
constraints similar translations inequalities.
Constraint satisfaction optimization applied two dierent ways obtain
complete output annotation sentence. rst one, proceed verb verb
independently nd best selection candidate arguments using constraints
1 4. call approach local optimization. second scenario
candidate arguments sentence considered constraints 1 6
enforced. refer second strategy global optimization. scenarios
compatibility function same, constraints need rewriting global
scenario include information concrete predicate.
Section 8.3 extensively evaluate presented inference model based Constraint Satisfaction, describe experiments covering following topics: (a)
contribution proposed constraints; (b) performance local vs. global
optimization; (c) precisionrecall tradeo varying value bias-correction
parameter.
7.2 Inference Based Learning
combination model consists two stages: candidate scoring phase, scores
candidate arguments pool using series discriminative classiers, inference
stage, selects best overall solution consistent domain constraints.
9. Instead working constant, one could try set oi value candidate, taking
account contextual features candidate. plan explore option near future.

127

fiSurdeanu, Marquez, Carreras, & Comas

rst important component combination strategy candidate
scoring module, assigns candidate argument score equal condence
argument part global solution. formed discriminative functions,
one role label. Below, devise two dierent strategies train discriminative
functions.
scoring candidate arguments, nal global solution built inference
module, looks best scored argument structure satises domain specic
constraints. Here, global solution subset candidate arguments, score
dened sum condence values arguments form it. currently consider
three constraints determine solutions valid:
(a) Candidate arguments predicate overlap embed.
(b) predicate, duplicate arguments allowed numbered arguments A0-5.
(c) Arguments predicate embedded within arguments predicates
overlap.
set constraints extended rules, particular case,
know constraints, e.g., providing arguments indicated corresponding PropBank frame, already guaranteed individual models, others, e.g.,
constraints 3 4 previous sub-section, positive impact overall
performance (see Section 8.3 empirical analysis). inference algorithm use
bottom-up CKY-based dynamic programming strategy (Younger, 1967). builds
solution maximizes sum argument condences satisfying constraints,
cubic time.
Next, describe two dierent strategies train functions score candidate
arguments. rst local strategy: function trained binary batch classier,
independently combination process enforces domain constraints.
second global strategy: functions trained online rankers, taking account
interactions take place combination process decide one argument
another.
training strategies, discriminative functions employ representation arguments, using complete feature set described Section 6 (we analyze
contribution feature group Section 8). intuition rich feature
space introduced Section 6 allow gathering sucient statistics robust
scoring candidate arguments. example, scoring classiers might learn
candidate trusted if: (a) two individual systems proposed it, (b) label
A2 generated Model 1, (c) proposed Model 2 within certain
argument sequence.
7.2.1 Learning Local Classifiers
combination process follows cascaded architecture, learning component
decoupled inference module. particular, training strategy consists
training binary classier role label. target label-based classier
determine whether candidate argument actually belongs correct proposition
corresponding predicate, output condence value decision.
128

fiCombination Strategies Semantic Role Labeling

specic training strategy follows. training data consists pool
labeled candidate arguments (proposed individual systems). candidate either
positive, actually correct argument sentence, negative,
correct. strategy trains binary classier role label l, independently
labels. so, concentrates candidate arguments data
label l. forms dataset binary classication, specic label l. it,
binary classier trained using existing techniques binary classication,
requirement combination strategy needs condence values
binary prediction. Section 8 provide experiments using SVMs train local
classiers.
all, classier trained independently classiers inference module. Looking globally combination process, classier seen argument
ltering component decides candidates actual arguments using much richer
representation individual models. context, inference engine used
conict resolution engine, ensure combined solutions valid argument structures sentences.
7.2.2 Learning Global Rankers
combination process couples learning inference, i.e., scoring functions
trained behave accurately within inference module. words, training
strategy global: target train global function maps set argument
candidates sentence valid argument structure. setting, global function
composition scoring functions one label, previous strategy.
Unlike previous strategy, completely decoupled inference engine,
policy map set candidates solution determined inference
engine.
recent years, research active global learning methods tagging,
parsing and, general, structure prediction problems (Collins, 2002; Taskar, Guestrin, &
Koller, 2003; Taskar, Klein, Collins, Koller, & Manning, 2004; Tsochantaridis, Hofmann,
Joachims, & Altun, 2004). article, make use simplest technique global
learning: online learning approach uses Perceptron (Collins, 2002). general
idea algorithm similar original Perceptron (Rosenblatt, 1958): correcting
mistakes linear predictor made visiting training examples, additive
manner. key point learning global rankers relies criteria determines
mistake function trained, idea exploited
similar way multiclass ranking scenarios Crammer Singer (2003a, 2003b).
Perceptron algorithm combination system works follows (pseudocode
algorithm given Figure 7). Let 1 . . . L possible role labels, let
W = {w1 . . . wL } set parameter vectors scoring functions, one
label. Perceptron initializes vectors W zero, proceeds cycle
training examples, visiting one time. case, training example pair (y, A),
correct solution example set candidate arguments
it. Note sets labeled arguments, thus make use
set dierence. note particular argument, l label a,
129

fiSurdeanu, Marquez, Carreras, & Comas

Initialization: wl W wl = 0
Training :
= 1 . . .
training example (y, A)
= Inference(A, W)
\
let l label
wl = wl + (a)
\
let l label
wl = wl (a)
Output: W
Figure 7: Perceptron Global Learning Algorithm

(a) vector features described Section 6. example, Perceptron performs
two steps. First, predicts optimal solution according current setting
W. Note prediction strategy employs complete combination model, including
inference component. Second, Perceptron corrects vectors W according
mistakes seen y: arguments label l seen promoted vector
wl ; hand, arguments demoted wl . correction rule
moves scoring vectors towards missing arguments, away predicted arguments
correct. guaranteed that, Perceptron visits examples,
feedback rule improve accuracy global combination function
feature space almost linearly separable (Freund & Schapire, 1999; Collins, 2002).
all, training strategy global mistakes Perceptron corrects
arise comparing predicted structure correct one. contrast,
local strategy identies mistakes looking individually sign scoring predictions:
candidate argument (is not) correct solution current scorers predict
negative (positive) condence value, corresponding scorer corrected
candidate argument. Note criteria used generate training data
classiers trained locally. Section 8 compare approaches empirically.
nal note, simplicity described Perceptron simple form.
However, Perceptron version use experiments reported Section 8 incorporates two well-known extensions: kernels averaging (Freund & Schapire, 1999; Collins
& Duy, 2002). Similar SVM, Perceptron kernel method. is, represented dual form, dot product example vectors generalized
kernel function exploits richer representations. hand, averaging
technique increases robustness predictions testing. original form,
test predictions computed parameters result training process.
averaged version, test predictions computed average parameter
vectors generated training, every update. Details technique
found original article Freund & Schapire.
130

fiCombination Strategies Semantic Role Labeling

1

Development
Brown
WSJ

0.98
0.96

Acuracy

0.94
0.92
0.9
0.88
0.86
0.84
0.82
0

10

20

30

40

50

60

70

80

90

100

Reject Rate (%)

Figure 8: Rejection curves estimated output probabilities individual models.

8. Experimental Results
section analyze performance three combination strategies previously
described: (a) inference constraint satisfaction, (b) learning-based inference local
rankers, (c) learning-based inference global rankers. bulk experiments use candidate arguments generated three individual SRL models described
Section 4 evaluated Section 5.
8.1 Experimental Settings
combination strategies (with one exception, detailed below) trained using
complete CoNLL-2005 training set (PropBank/Treebank sections 2 21). minimize
overtting individual SRL models training data, partitioned training
corpus folds fold used output individual models
trained remaining four folds. models tuned separate development
partition (Treebank section 24) evaluated two corpora: (a) Treebank section 23,
(b) three annotated sections Brown corpus.
constraint satisfaction model, converted scores output arguments
three SRL models probabilities using softmax function explained Section 7.1.
development set (section 24) used tune parameter softmax formula
nal value 0.1 models. order assess quality procedure,
plot Figure 8 rejection curves estimated output probabilities respect
classication accuracy development test sets (WSJ Brown). calculate
plots, probability estimates three models put together set sorted
decreasing order. certain level rejection (n%), curve Figure 8 plots
percentage correct arguments lowest scoring n% subset rejected.
131

fiSurdeanu, Marquez, Carreras, & Comas

exceptions, curves increasing smooth, indicating good correlation
probability estimates classication accuracy.
last experiment, Section 8.6 analyze behavior proposed combination
strategies candidate pool signicantly larger. experiment used
top 10 best performing systems CoNLL-2005 shared task evaluation. setup
two signicant dierences experiments used in-house individual
systems: (a) access systems outputs PropBank development
section two test sections, (b) argument probabilities individual
models available. Thus, instead usual training set, train
combination models PropBank development section smaller feature set. Note
also development set 3.45% size regular training set.
evaluated resulting combination models two testing sections: WSJ
Brown.
8.2 Lower Upper Bounds Combination Strategies
venture evaluation combination strategies, explore lower
upper bounds combinations models given corpus individual models.
analysis important order understand potential proposed approach
see close actually realizing it.
performance upper bound calculated oracle combination system
perfect ltering classier selects correct candidate arguments discards
others. comparison purposes, implemented second oracle system simulates re-ranking approach: predicate selects candidate frame i.e.,
complete set arguments corresponding predicate proposed single model
highest F1 score. Table 3 lists results obtained WSJ Brown corpora
two oracle systems using three individual models. combination system
oracle simulates combination strategies proposed paper, break
candidate frames work individual candidate arguments. Note precision
oracle combination system 100% case discontinuous arguments,
fragments pass oracle lter considered incorrect scorer corresponding argument complete, e.g., argument A1 appears without continuation
C-A1. re-ranking columns list results second oracle system, selects
entire candidate frames.
Table 3 indicates upper limit combination approaches proposed
paper relatively high: F1 combination oracle system 14 points higher
best individual system WSJ test set, 17 points higher
Brown corpus (see Table 1). Furthermore, analysis indicates potential
combination strategy higher re-ranking strategies, limited
performance best complete frame candidate pool. allowing recombination arguments individual candidate solutions threshold raised
signicantly: 6 F1 points WSJ 9 F1 points Brown.
Table 4 lists distribution candidate arguments individual models
selection performed combination oracle system. conciseness, list
core numbered arguments focus WSJ corpus. 3 indicates percent132

fiCombination Strategies Semantic Role Labeling

WSJ
Brown

PProps
70.76%
51.87%

Combination
Precision Recall
99.12%
85.22%
99.63%
74.32%

F1
91.64
85.14

PProps
63.51%
45.02%

Re-Ranking
Precision Recall
88.08%
82.84%
80.80%
71.70%

F1
85.38
75.98

Table 3: Performance upper limits detected two oracle systems.
A0
A1
A2
A3
A4

3
80.45%
69.82%
56.04%
56.03%
65.85%

2
12.10%
17.83%
22.32%
21.55%
20.73%

Model 1
3.47%
7.45%
12.20%
12.93%
6.10%

Model 2
2.14%
2.77%
4.95%
5.17%
2.44%

Model 3
1.84%
2.13%
4.49%
4.31%
4.88%

Table 4: Distribution individual systems arguments upper limit selection,
A0A4 WSJ test set.

age correct arguments 3 models agreed, 2 indicates percentage
correct arguments 2 models agreed, columns indicate percentage correct arguments detected single model. Table 4 indicates that, expected,
two individual models agreed large percentage correct arguments. Nevertheless, signicant number correct arguments, e.g., 22% A3, come single
individual system. proves that, order achieve maximum performance, one
look beyond simple voting strategies favor arguments high agreement
individual systems.
propose two lower bounds performance combination models using two
baseline systems:
rst baseline recall-oriented: merges arguments generated
individual systems. conict resolution, baseline uses approximate inference
algorithm consisting two steps: (i) candidate arguments sorted using radix
sort orders candidate arguments descending order of: (a) number models
agreed argument, (b) argument length tokens, (c) performance
individual system10 ; (ii) Candidates iteratively appended global solution
violate domain constraints arguments already
selected.
second baseline precision-oriented: considers arguments three
individual systems agreed. conict resolution uses strategy
previous baseline system.
Table 5 shows performance two baseline models. expected, precisionoriented baseline obtains precision signicantly higher best individual model
(Table 1), recall suers individual models agree fairly large
number candidate arguments. recall-oriented baseline balanced: expected
recall higher individual model precision drop much
10. combination produced highest-scoring baseline model.

133

fiSurdeanu, Marquez, Carreras, & Comas

WSJ
baseline
baseline
Brown
baseline
baseline

recall
precision

PProps
53.71%
35.43%

Prec.
78.09%
92.49%

Recall
78.77%
60.48%

F1
78.43 0.8
73.14 0.9

recall
precision

36.94%
20.52%

68.57%
88.74%

66.05%
46.35%

67.29
60.89

2.0
2.1

Table 5: Performance baseline models WSJ Brown test sets.
inference strategy lters many unlikely candidates. Overall, recalloriented baseline performs best, F1 1.22 points higher best individual
model WSJ corpus, 0.41 points lower Brown corpus.
8.3 Performance Combination System Constraint Satisfaction
Constraint Satisfaction setting arguments output individual Models 1, 2,
3 recombined expected better solution satises set constraints.
run inference model based Constraint Satisfaction described Section 7.1 using
Xpress-MP ILP solver11 . main results summarized Table 6. variants
presented table following: Pred-by-pred stands local optimization,
processes verb predicate independently others, Full sentence stands
global optimization, i.e., resolving verb predicates sentence
time. column labeled Constraints shows particular constraints applied
conguration. column presents value parameter correcting bias
towards candidate overgeneration. Concrete values empirically set maximize F1
measure development set. = 0 corresponds setting bias correction
applied.
clear conclusions drawn Table 6. First, observe optimization variant obtains F1 results individual systems (Table 1)
baseline combination schemes (Table 5). best combination model scores 2.61 F1 points
WSJ 1.49 Brown higher best individual system. Taking account
learning performed, clear Constraint Satisfaction simple yet formal
setting achieves good results.
somewhat surprising result performance improvements come constraints 1 2 (i.e., overlapping embedding among arguments verb,
repetition core arguments verb). Constraints 3 4 harmful,
sentence-level constraints (5 6) impact overall performance12 .
analysis proposed constraints yielded following explanations:
Constraint number 3 prevents assignment R-X argument referred
argument X present. makes inference miss easy R-X arguments
11. Xpress-MP Dash Optimization product free academic usage.
12. Section 8.5 see learning strategy incorporates global feedback, performing
sentence-level inference slightly better proceeding predicate predicate.

134

fiCombination Strategies Semantic Role Labeling

WSJ
Pred-by-pred

Full sentence

Brown
Full sentence

Constraints
1
1+2
1+2+3
1+2+4
1+2+3+4
1+2+5
1+2+6
1+2+5+6
1+2+5+6


0.30
0.30
0.25
0.30
0.30
0.30
0.30
0.30
0

PProps
52.29%
52.52%
52.31%
51.40%
51.19%
52.53%
52.48%
52.50%
54.49%

Precision
84.20%
84.61%
84.34%
84.13%
83.86%
84.63%
84.64%
84.65%
78.74%

Recall
75.64%
75.53%
75.48%
75.04%
74.99%
73.53%
75.51%
75.51%
79.78%

F1
79.69 0.8
79.81 0.6
79.67 0.7
79.32 0.8
79.18 0.7
79.82 0.7
79.81 0.8
79.82 0.6
79.26 0.7

1+2+5+6
1+2+5+6

0.30
0

35.70%
38.06%

78.18%
69.80%

62.06%
67.85%

69.19 2.1
68.81 2.2

Table 6: Results, WSJ Brown test sets, obtained multiple variants constraint satisfaction approach

X argument correctly identied (e.g., constituents start
{that, which, who} followed verb always R-A0). Furthermore, constraint
presents lot exceptions: 18.75% R-X arguments WSJ test set
referred argument X (e.g., law tells so),
therefore hard application constraint 3 prevents selection correct
R-X candidates. ocial evaluation script CoNLL-2005 (srl-eval)
require constraint satised consider solution consistent.
srl-eval script requires constraint number 4 (i.e., C-X tag accepted
without preceding X argument) fullled candidate solution considered
consistent. nds solution violating constraint behavior
convert rst C-X (without preceding X) X. turns simple
post-processing strategy better forcing coherent solution inference step
allows recover error argument completely
recognized labeled C-X tags.
Regarding sentence-level constraints, observed setting, inference using
local constraints (1+2) rarely produces solution inconsistencies sentence
level.13 makes constraint 5 useless since almost never violated. Constraint
number 6 (i.e., sharing AMs among dierent verbs) ad-hoc represents
less universal principle SRL. number exceptions constraint,
WSJ test set, 3.0% gold-standard data 4.8% output
inference uses local constraints (1+2). Forcing fulllment
constraint makes inference process commit many errors corrections, making
eect negligible.
13. fact partly explained small number overlapping arguments candidate pool
produced three individual models.

135

fiSurdeanu, Marquez, Carreras, & Comas

95
90

95

Precision
Recall
F1

90

80

80
%

85

%

85

Precision
Recall
F1

75

75

70

70

65

65

60
-0.4

-0.2

0

0.2

0.4

0.6

0.8

60
-0.4

1

Value

-0.2

0

0.2

0.4

0.6

0.8

1

Value

Figure 9: Precision-Recall plots, respect bias correcting parameter (O),
WSJ development test sets (left right plots, respectively).

Considering constraints universal, i.e., exceptions exist
gold standard, seems reasonable convert soft constraints. done
precomputing compatibility corpora counts using, instance, point-wise
mutual information, incorporating eect compatibility function explained
section 7.1. softening could, principle, increase overall recall combination.
Unfortunately, initial experiments showed dierences hard soft
variants.
Finally, dierences optimized values bias correcting parameter
= 0 clearly explained observing precision recall values. default
version tends overgenerate argument assignments, implies higher recall cost
lower precision. contrary, F1 optimized variant conservative
needs evidence select candidate. result, precision higher recall
lower. side eect restrictive argument assignments, number
correctly annotated complete propositions also lower optimized setting.
preference high-precision vs. high-recall system mostly task-dependant.
interesting note constraint satisfaction setting, adjusting precision
recall tradeo easily done varying value bias correcting score.
Figure 9, plot precisionrecall curves respect dierent values parameter (the optimization done using constraints 1, 2, 5, 6). expected, high values
promote precision demote recall, lower values contrary. Also,
see wide range values combined F1 measure almost
constant (the approximate intervals marked using vertical lines), making possible
select dierent recall precision values global performance (F1 ) near optimal. Parenthetically, note also optimal value estimated development set
(O = 0.3) generalizes well WSJ test set.
136

fiCombination Strategies Semantic Role Labeling

WSJ
Models
Models
Models
Models
Brown
Models
Models
Models
Models

1+2
1+3
2+3
1+2+3

PProps
49.28%
48.26%
49.36%
51.66%

Prec.
87.39%
86.80%
86.63%
87.47%

Recall
72.88%
73.20%
73.03%
74.67%

F1
79.48 0.6
79.42 0.6
79.25 0.7
80.56 0.6

F1 improvement
+2.27
+2.96
+2.04
+3.35

1+2
1+3
2+3
1+2+3

34.33%
31.22%
32.84%
34.33%

81.14%
80.43%
80.90%
81.75%

60.86%
59.07%
60.31%
61.32%

69.55 2.0
68.11 1.9
69.11 2.1
70.08 2.1

+1.85
+2.69
+1.41
+2.38

Table 7: Overall results learning-based inference local rankers WSJ
Brown test sets.

8.4 Performance Combination System Local Rankers
implemented candidate-scoring classiers combination strategy using Support Vector Machines (SVM) polynomial kernels degree 2, performed slightly
better types SVMs AdaBoost. implemented SVM classiers
SVMlight software14 . Outside changing default kernel polynomial
modied default parameters. experiments reported section,
trained models 4 possible combinations 3 individual systems, using
complete feature set introduced Section 6. dynamic programming engine used
actual inference processes predicate independently (similar Pred-by-pred
approach previous sub-section).
Table 7 summarizes performance combined systems WSJ Brown
corpora. Table 7 indicates combination strategy always successful: results
combination systems improve upon individual models (Table 1) F1
scores always better baselines (Table 5). last column table shows
F1 improvement combination model w.r.t. best individual model set.
expected, highest scoring combined system includes three individual models.
F1 measure 3.35 points higher best individual model (Model 2) WSJ test
set 2.38 points higher Brown test set. Note combination two
individual systems outperform current state art (see Section 9 details).
empirical proof robust successful combination strategies SRL problem
possible. Table 7 also indicates that, even though partial parsing model (Model 1)
worst performing individual model, contribution ensemble important,
indicating information provides indeed complementary models.
instance, WSJ performance combination two best individual models
(Models 2+3) worse combinations using model 1 (Models 1+2 1+3).
14. http://svmlight.joachims.org/

137

fiSurdeanu, Marquez, Carreras, & Comas

WSJ
FS1
+ FS2
+ FS3
+ FS4
+ FS5
+ FS6
Brown
FS1
+ FS2
+ FS3
+ FS4
+ FS5
+ FS6

PProps
50.24%
50.39%
51.22%
50.66%
51.38%
51.66%

Prec.
86.47%
86.41%
86.13%
86.67%
87.21%
87.47%

Recall
73.51%
73.68%
74.35%
74.10%
74.61%
74.67%

F1
79.47 0.7
79.54 0.6
79.80 0.7
79.89 0.7
80.42 0.6
80.56 0.6

32.21%
32.84%
33.33%
33.33%
34.08%
34.33%

80.12%
80.80%
80.29%
81.10%
81.76%
81.75%

59.44%
59.94%
60.82%
60.50%
61.14%
61.32%

68.25 2.0
68.83 2.2
69.21 2.0
69.30 2.1
69.96 2.2
70.08 1.9

Table 8: Feature analysis learning-based inference local rankers.
Due simple architecture i.e., feedback conict resolution component
candidate ltering inference model good framework study contribution
features proposed Section 6. study group features 6 sets: FS1
voting features, FS2 overlap features arguments predicate, FS3
overlap features arguments predicates, FS4 partial-syntax features, FS5
full-syntax features, FS6 probabilities generated individual systems
candidate arguments. Using sets constructed 6 combination models
increasing number features made available argument ltering classiers, e.g.,
rst system uses FS1, second system adds FS2 rst systems features,
FS3 added third system, etc. Table 8 lists performance 6 systems
two test corpora. empirical analysis indicates feature sets
highest contribution are:
FS1, boosts F1 score combined system 2.26 points (WSJ) 0.55
points (Brown) best individual system. yet another empirical proof
voting successful combination strategy.
FS5, contribution 0.53 points (WSJ) 0.66 points (Brown) F1
score. numbers indicate ltering classier capable learning
preferences individual models certain syntactic structures.
FS3, contributes 0.26 points (WSJ) 0.38 points (Brown) F1 score.
results promote idea information overall sentence structure,
case inter-predicate relations, successfully used problem SRL.
knowledge, novel.
proposed features positive contribution performance combined
system. Overall, achieve F1 score 1.12 points (WSJ) 2.33 points (Brown)
higher best performing combined system CoNLL-2005 shared task evaluation
(see Section 9 details).
138

fiCombination Strategies Semantic Role Labeling

8.5 Performance Combination System Global Rankers
section report experiments global Perceptron algorithm described
Section 7.2.2, globally trains scoring functions rankers. Similar local
SVM models, use polynomial kernels degree 2. Furthermore, predictions test
time used averages parameter vectors, following technique Freund Schapire
(1999).
interested two main aspects. First, evaluate eect training
scoring functions Perceptron using two dierent update rules, one global
local. global feedback rule, detailed Section 7.2.2, corrects mistakes found
comparing correct argument structure one results inference (this
noted global feedback). contrast, local feedback rule corrects mistakes
found inference, candidate argument handled independently, ignoring
global argument structure generated (this noted local feedback). Second,
analyze eect using dierent constraints inference module. extent,
congured inference module two ways. rst processes predicates
sentence independently, thus might select overlapping arguments dierent predicates,
incorrect according domain constraints (this one noted Pred-by-pred
inference). second processes predicates jointly, enforces hierarchical structure
arguments, arguments never overlap, arguments predicate allowed
embed arguments predicates (this noted Full sentence inference).
perspective, model local update Pred-by-pred inference almost identical
local combination strategy described Section 8.4, unique dierence
use Perceptron instead SVM. apparently minute dierence turns
signicant empirical analysis allows us measure contribution
SVM margin maximization global feedback classier-based combination
strategy (see Section 8.7).
trained four dierent models: local global feedback, predicate-bypredicate joint inference. model trained 5 epochs training data,
evaluated development data training epoch. selected best
performing point development, evaluated models test data. Table 9
reports results test data.
Looking results, rst impression dierence F1 measure
signicant among dierent congurations. However, observations pointed out.
Global methods achieve much better recall gures, whereas local methods prioritize
precision system. Overall, global methods achieve balanced tradeo
precision recall, contributes better F1 measure.
Looking Pred-by-pred versus Full sentence inference, seen
global methods sensitive dierence. Note local model trained
independently inference module. Thus, adding constraints inference
engine change parameters local model. testing time, dierent
inference congurations aect results. contrast, global models trained
dependently inference module. moving Pred-by-pred Full sentence
inference, consistency enforced argument structures dierent predicates,
benets precision recall method. global learning algorithm
139

fiSurdeanu, Marquez, Carreras, & Comas

WSJ
Pred-by-pred, local
Full sentence, local
Pred-by-pred, global
Full sentence, global
Brown
Pred-by-pred, local
Full sentence, local
Pred-by-pred, global
Full sentence, global

PProps
50.71%
50.67%
53.45%
53.81%

Prec.
86.80%
86.80%
84.66%
84.84%

Recall
74.31%
74.29%
76.19%
76.30%

F1
80.07 0.7
80.06 0.7
80.20 0.7
80.34 0.6

33.33%
33.33%
35.20%
35.95%

80.62%
80.67%
77.65%
77.91%

60.77%
60.77%
62.70%
63.02%

69.30 1.9
69.32 2.0
69.38 1.9
69.68 2.0

Table 9: Test results combination system global rankers. Four congurations
evaluated, combine Pred-by-pred Full sentence inference local
global feedback.

improves precision recall coupled joint inference process
considers constraints solution.
Nevertheless, combination system local SVM classiers, presented previous section, achieves marginally better F1 score global learning method (80.56% vs.
80.34% WSJ). explained dierent machine learning algorithms (we discuss
issue detail Section 8.7). better F1 score accomplished much better
precision local approach (87.47% vs. 84.84% WSJ), whereas recall lower
local global approach (74.67% vs. 76.30% WSJ). hand,
global strategy produces completely-correct annotations (see PProps column)
local strategies investigated (see Tables 9 7). expected,
considering global strategy optimizes sentence-level cost function. Somewhat
surprisingly, number perfect propositions generated global strategy lower
number perfect propositions produced constraint-satisfaction approach.
discuss result Section 8.7.
8.6 Scalability Combination Strategies
combination experiments reported point used candidate arguments
generated three individual SRL models introduced Section 4. experiments provide empirical comparison three inference models proposed,
answer obvious scalability question: proposed combination approaches
scale number candidate arguments increases quality diminishes?
mainly interested answering question last two combination models (which
use inference based learning local global rankers) two reasons: (a)
performed better constraint satisfaction model previous experiments,
(b) requirements individual SRL systems outputs unlike
constraint satisfaction model requires argument probabilities individual models coupled pools candidates generated individual SRL
model.
140

fiCombination Strategies Semantic Role Labeling

koomen
pradhan+
haghighi
marquez
pradhan

surdeanu
tsai
che
moschitti
tjongkimsang
yi

ozgencil

WSJ
Prec.
Recall
82.28%
76.78%
82.95% 74.75%
79.54% 77.39%
79.55%
76.45%






50.14%

81.97%

73.27%

77.37

36.44%

73.73%

61.51%

67.07






45.28%
45.43%
47.81%
47.66%
45.85%

80.32%
82.77%
80.48%
76.55%
79.03%

72.95%
70.90%
72.79%
75.24%
72.03%

76.46
76.38
76.44
75.89
75.37

29.48%
30.47%
31.84%
30.85%
28.36%

72.41%
73.21%
71.13%
65.92%
70.45%

59.67%
59.49%
59.99%
61.83%
60.13%

65.42
65.64
65.09
63.81
64.88







F1
79.44
78.63
78.45
77.97

PProps
32.34%
38.93%
37.06%
36.44%

Brown
Prec.
Recall
73.38%
62.93%
74.49% 63.30%
70.24% 65.37%
70.79%
64.35%

PProps
53.79%
52.61%
56.52%
51.85%

F1
67.75
68.44
67.71
67.42

47.50%

77.51%

72.97%

75.17

31.09%

67.88%

59.03%

63.14

46.19%

74.66%

74.21%

74.44

31.47%

65.52%

62.93%

64.20

Table 10: Performance best systems CoNLL-2005. pradhan+ contains postevaluation improvements. top 5 systems actually combination models
themselves. second column marks systems used evaluation: pradhan, replaced improved version pradhan+,
yi, due format errors submitted data.

scalability analysis, use individual SRL models top 10 systems
CoNLL-2005 shared task evaluation. Table 10 summarizes performance systems
two test corpora used previous experiments. Table 10 indicates,
performance systems varies widely: dierence 5 F1 points WSJ
corpus 4 F1 points Brown corpus best worst system
set.
combination experiments generated 5 candidate pools using top 2, 4, 6,

8, 10 individual systems labeled
Table 10. make two changes
experimental setup used rst part section: (a) trained combined models PropBank development section access
individual systems outputs PropBank training partition; (b) feature
set introduced Section 6 use individual systems argument probabilities
raw activations individual models classiers available. Note
settings size training corpus 10 times smaller size
training set used previous experiments.
Table 11 shows upper limits setups using combination reranking oracle systems introduced Section 8.2. Besides performance numbers, also
list Table 11 average number candidates per sentence setup, i.e., number
unique candidate arguments (# Args./Sent.) combination oracle number
unique candidate frames (# Frames/Sent.) re-ranking oracle. Table 12 lists
performance combined models local feedback (Section 7.2.1) global
feedback (Section 7.2.2). combination strategy global rankers uses joint inference
global feedback (see description previous sub-section).
141

fiSurdeanu, Marquez, Carreras, & Comas

WSJ
C2
C4
C6
C8
C10
Brown
C2
C4
C6
C8
C10

# Args./Sent.
8.53
9.78
10.23
10.74
11.33
7.42
8.99
9.62
10.24
10.86

Combination
Prec.
Recall
99.34%
82.71%
99.47%
87.26%
99.47%
88.02%
99.48%
88.63%
99.50% 89.02%
99.62%
99.65%
99.65%
99.66%
99.66%

71.34%
77.58%
79.38%
80.52%
81.72%

F1
90.27
92.96
93.39
93.75
93.97

Re-Ranking
# Frames/Sent.
Prec.
3.16
88.63%
4.44
91.08%
7.21
92.14%
8.11
92.88%
8.97
93.31%

83.14
87.24
88.37
89.08
89.80

3.02
4.55
7.09
8.19
9.21

82.45%
86.01%
88.19%
88.95%
89.65%

Recall
81.77%
86.12%
86.57%
87.33%
87.71%

F1
85.07
88.53
89.27
90.02
90.42

70.37%
75.98%
76.80%
78.04%
79.19%

75.94
80.68
82.10
83.14
84.10

Table 11: Performance upper limits determined oracle systems 10 best systems CoNLL-2005. Ck stands combination top k systems
Table 10. # Args./Sent. indicates average number candidate arguments
per sentence combination oracle; # Frames/Sent. indicates average
number candidate frames per sentence re-ranking oracle. latter
larger number systems combination average
multiple predicates per sentence.

WSJ
C2
C4
C6
C8
C10
Brown
C2
C4
C6
C8
C10

PProps
50.69%
55.14%
54.85%
54.36%
53.90%

Local
Prec.
86.60%
86.67%
87.45%
87.49%
87.48%

ranker
Recall
73.90%
76.63%
76.34%
76.12%
75.81%

F1
79.750.7
81.380.7
81.520.6
81.410.6
81.230.6

PProps
52.74
54.95
55.21
55.00
54.76

Global ranker
Prec.
Recall
84.07% 75.38%
84.00% 77.19%
84.24% 77.41%
84.42% 77.10%
84.02% 77.44%

F1
79.490.7
80.450.7
80.680.7
80.590.7
80.600.7

32.71%
35.95%
35.32%
35.95%
36.32%

79.56%
80.27%
80.94%
81.98%
82.61%

60.45%
63.16%
62.24%
61.87%
61.97%

68.701.8
70.692.0
70.371.8
70.522.2
70.812.0

35.32
39.30
37.44
38.43
37.44

74.88%
75.63%
76.12%
76.40%
75.94%

68.092.0
69.592.2
69.882.0
69.702.2
69.862.0

62.43%
64.45%
64.58%
64.08%
64.68%

Table 12: Local versus global ranking combinations 10 best systems CoNLL2005. Ck stands combination top k systems Table 10.

draw several conclusions experiments. First, performance upper limit re-ranking always lower argument-based combination
strategy, even number candidates large. example, 10 individual
models used, F1 upper limit approach Brown corpus 89.80 whereas
F1 upper limit re-ranking 84.10. However, enhanced potential combination approach imply signicant increase computational cost: Table 11 shows
142

fiCombination Strategies Semantic Role Labeling

number candidate arguments must handled combination approaches
much higher number candidate frames input re-ranking system, especially number individual models high. example, 10
individual models used, combination approaches must process around 11 arguments
per sentence, whereas re-ranking approaches must handle approximately 9 frames per sentence. intuition behind relatively small dierence computational cost that,
even though number arguments signicantly larger number frames,
dierence number unique candidates two approaches high
probability repeated arguments higher probability repeated
frames.
second conclusion combination models boost performance
corresponding individual systems. example, best 4-system combination achieves
F1 score approximately 2 points higher best individual model WSJ
Brown corpus. expected, combination models reach performance plateau
around 4-6 individual systems, quality individual models starts drop
signicantly. Nevertheless, considering top 4 individual systems use combination
strategies amount training data experiment quite small,
results show good potential combination models analyzed paper.
third observation relation previously observed local global
rankers holds: combination model local rankers better precision, model
global rankers always better recall generally better PProps score. Overall,
model local rankers obtains better F1 scores scales better number
individual systems increases. discuss dierences detail next
sub-section.
Finally, Table 11 indicates potential recall experiment (shown
left-most block table) higher potential recall combining three
individual SRL systems (see Table 3): 3.8% higher WSJ test set, 7.4% higher
Brown test set. expected, considering number quality
candidate arguments last experiment higher. However, even
improvement, potential recall combination strategies far 100%. Thus,
combining solutions N best state-of-the-art SRL systems still
potential properly solve SRL problem. Future work focus recallboosting strategies, e.g., using candidate arguments individual systems
individual complete solutions generated, step many candidate arguments
eliminated.
8.7 Discussion
experimental results presented section indicate proposed combination
strategies successful: three combination models provide statistically signicant improvements individual models baselines setups. immediate (but
somewhat shallow) comparison three combination strategies investigated indicates
that: (a) best combination strategy SRL problem max-margin local metalearner; (b) global ranking approach meta-learner important
143

fiSurdeanu, Marquez, Carreras, & Comas

contribution max-margin strategy; (c) constraint-satisfaction
model performs worst strategies tried.
However, experiments dierences combination approaches investigated small. reasonable observation combination strategy
advantages disadvantages dierent approaches suitable dierent
applications data. discuss dierences below.
argument probabilities individual systems available, combination model
based constraint satisfaction attractive choice: simple, unsupervised strategy obtains competitive performance. Furthermore, constraint satisfaction model
provides elegant customizable framework tune balance precision
recall (see Section 8.3). framework currently obtain highest recall
combination models: 3.48% higher best recall obtained meta-learning approaches WSJ corpus, 4.83% higher meta-learning models Brown
corpus. higher recall implies also higher percentage predicates completely
correctly annotated: best PProps numbers Table 6 best combination
strategies. cause high dierence recall favor constraint satisfaction
approach candidate scoring learning-based inference acts implicitly
lter: candidates whose score i.e., classier condence candidate part
correct solution negative discarded, negatively aects overall recall.
Hence, constraint satisfaction better solution SRL-based NLP applications
require predicate-argument frames extracted high recall. example, Information Extraction, predicate-argument tuples ltered subsequent high-precision,
domain-specic constraints (Surdeanu et al., 2003), hence paramount SRL
model high recall.
Nevertheless, many cases argument probabilities individual SRL models
available, either models generate them, e.g., rule-based systems,
individual models available black boxes, oer access
internal information. conditions, showed combination strategies based
meta-learning viable alternative. fact, approaches obtain highest
F1 scores (see Section 8.4) obtain excellent performance even small amounts
training data (see Section 8.6). previously mentioned, candidate scoring acts
lter, learning-based inference tends favor precision recall: precision
2.82% higher best precision constraint-satisfaction models WSJ
corpus, 3.57% higher Brown corpus. preference precision recall
pronounced learning-based inference local rankers (Section 8.4)
inference model global rankers (Section 8.5). hypothesis causes
global-ranking model less precision-biased conguration ratio
errors positive versus negative samples balanced. Thinking strategy
Perceptron follows, local approach updates every candidate incorrect prediction
sign, whereas global approach updates candidates
complete solution, enforcing domain constraints. words, number
negative updates drives precision bias reduced global approach,
false positives generated ranking classiers eliminated
domain constraints. Thus, candidate scoring trained optimize accuracy,
144

fiCombination Strategies Semantic Role Labeling

WSJ
global feedback
max margin
Brown
global feedback
max margin

PProps
+3.10%
+0.95%

Prec.
-1.96%
+0.67%

Recall
+1.99%
+0.36%

F1
+0.27
+0.49

+2.62%
+1.00%

-2.71%
+1.13%

+2.25%
+0.55%

+0.38
+0.78

Table 13: Contribution global feedback max margin learning-based inference.
baseline Pred-by-pred, local model Table 9.

fewer candidate arguments eliminated meta-learner global rankers,
translates better balance precision recall.
Another important conclusion analysis global versus local ranking
learning-based inference max-margin approach candidate scoring classiers
important global feedback inference. fact, considering
dierence model predicate-by-predicate inference local feedback
Section 8.5 (Pred-by-pred, local) versus best model Section 8.4 (+FS6)
latter uses SVM classiers whereas former uses Perceptron, compute exact
contribution max margin global feedback15 . convenience, summarize
analysis Table 13. table indicates max margin yields consistent improvement
precision recall, whereas contribution global feedback reducing
dierence precision recall boosting recall decreasing precision.
benet max-margin classiers even evident Table 12, shows
local-ranking model max-margin classiers generalizes better global-ranking
model amount training data reduced signicantly.
Even though paper analyzed several combination approaches three
independent implementations, proposed models fact compatible other.
Various combinations proposed strategies immediately possible. example,
constraint satisfaction model applied output probabilities candidate
scoring component introduced Section 7.2. model eliminates dependency
output scores individual SRL models retains advantages
constraint satisfaction model, e.g., formal framework tune balance precision recall. Another possible combination approaches introduced paper
use max-margin classiers learning-based inference global feedback, e.g.,
using global training method margin maximization SVMstruct (Tsochantaridis et al., 2004). model would indeed increased training time16 , could
leverage advantages max-margin classiers inference global feedback
(summarized Table 13). Finally, another attractive approach stacking, i.e., N levels chained meta-learning. example, could cascade learning-based inference
model global rankers, boosts recall, learning-based inference local
rankers, favors precision.
15. contribution global feedback given model joint inference global feedback (Full
sentence, global) Section 8.5.
16. main reason chose Perceptron proposed online strategies.

145

fiSurdeanu, Marquez, Carreras, & Comas

9. Related Work
4 best performing systems CoNLL-2005 shared task included combination
dierent base subsystems increase robustness gain coverage independence
parse errors. Therefore, closely related work paper. rst
four rows Table 10 summarize results exactly experimental setting
one used paper.
Koomen et al. (2005) used 2 layer architecture close ours. pool candidates
generated by: (a) running full syntax SRL system alternative input information (Collins
parsing, 5-best trees Charniaks parser), (b): taking candidates pass
lter set dierent parse trees. combination candidates performed
elegant global inference procedure constraint satisfaction, which, formulated
Integer Linear Programming, solved eciently. dierent work,
break complete solutions number SRL systems also investigate
meta-learning combination approach addition ILP inference. Koomen et al.s
system best performing system CoNLL-2005 (see Table 10).
Haghighi et al. (2005) implemented double re-ranking top several outputs
base SRL model. re-ranking performed, rst, set n-best solutions obtained
base system run single parse tree, and, then, set best-candidates
coming n-best parse trees. second-best system CoNLL-2005
(third row Table 10). Compared decomposition re-combination approach,
re-ranking setting advantage allowing denition global features
apply complete candidate solutions. According follow-up work authors
(Toutanova, Haghighi, & Manning, 2005), global features source major
performance improvements re-ranking system. contrast, focus features
exploit redundancy individual models, e.g., overlap individual
candidate arguments, add global information frame level complete
solutions provided individual models. main drawback re-ranking compared
approach dierent individual solutions combined re-ranking
forced select complete candidate solution. implies overall performance
strongly depends ability base model generate complete correct solution
set n-best candidates. drawback evident lower performance upper
limit re-ranking approach (see Tables 3 11) performance actual
system best combination strategy achieves F1 score 2 points higher
Haghighi et al. WSJ Brown17 .
Finally, Pradhan, Hacioglu, Ward, Martin, Jurafsky (2005b) followed stacking
approach learning two individual systems based full syntax, whose outputs used
generate features feed training stage nal chunk-by-chunk SRL system. Although
ne granularity chunking-based system allows recover parsing errors,
nd combination scheme quite ad-hoc forces break argument candidates
chunks last stage.
17. Recently, Yih Toutanova (2006) reported improved numbers system: 80.32 F1 WSJ
68.81 Brown. However, numbers directly comparable systems presented
paper fixed significant bug representation quotes input data, bug
still present data.

146

fiCombination Strategies Semantic Role Labeling

Outside CoNLL shared task evaluation, Roth Yih (2005) reached conclusion quality local argument classiers important global
feedback inference component. also one conclusions drawn paper. contribution shown hypothesis holds complex
framework: combination several state-of-the-art individual models, whereas Roth
Yih experimented single individual model, numbered arguments, slightly
simplied problem representation: B-I-O basic chunks. Additionally, detailed
experiments allowed us show clearly contribution max margin higher
global learning several corpora several combinations individual systems.
Punyakanok, Roth, Yih (2005) showed performance individual SRL
models (particularly argument identication) signicantly improved full parsing
used argument boundaries restricted match syntactic constituents (similarly
Model 3). believe approach used Models 1 2, candidate
arguments match single syntactic constituent, increased robustness
built-in mechanism handle syntax errors, argument constituent incorrectly fragmented multiple phrases. empirical results support
claim: Model 2 performs better Model 3 models proposed Punyakanok
et al. second advantage strategy proposed paper model
deployed using full syntax (Model 2) partial syntax (Model 1).
Pradhan, Ward, Hacioglu, Martin, Jurafsky (2005c) implement SRL combination
strategy constituent level that, similarly approach, combines dierent syntactic
views data based full partial syntactic analysis. However, unlike approach,
Pradhan et al.s work uses simple greedy inference strategy based probabilities
candidate arguments, whereas paper introduce analyze three dierent
combination algorithms. analysis yielded combination system outperforms
current state art.
Previous work general eld predicting structures natural language
texts indicated combination several individual models improves overall performance given task. Collins (2000) rst proposed learning layer based ranking
improve performance generative syntactic parser. approach, reranker
trained select best solution pool solutions produced generative
parser. so, reranker dealt complete parse trees, represented
rich features exploited dependencies considered generative method.
hand, computationally feasible train reranker, base method
reduced number possible parse trees sentence exponential number (w.r.t.
sentence length) tens. recently, global discriminative learning methods
predicting structures proposed (Laerty, McCallum, & Pereira, 2001; Collins,
2002, 2004; Taskar et al., 2003, 2004; Tsochantaridis et al., 2004). train
single discriminative ranking function detect structures sentence. major property
methods model problem discriminatively, arbitrary
rich representations structures used. Furthermore, training process
methods global, parameters set maximize measures related
local accuracies (i.e., recognizing parts structure), also related global
accuracy (i.e., recognizing complete structures). article, use global
rich representations also major motivation.
147

fiSurdeanu, Marquez, Carreras, & Comas

10. Conclusions
paper introduces analyzes three combination strategies context semantic
role labeling: rst model implements inference strategy constraint satisfaction
using integer linear programming, second uses inference based learning
candidates scored using discriminative classiers using local information,
third last inference model builds previous strategy adding global feedback
conict resolution component ranking classiers. meta-learners used
inference process developed rich set features includes voting
statistics i.e., many individual systems proposed candidate argument overlap
arguments predicates sentence, structure distance
information coded using partial full syntax, probabilities individual SRL
models (if available). knowledge, rst work that: (a) introduces thorough
inference model based learning semantic role labeling, (b) performs comparative
analysis several inference strategies context SRL.
results presented suggest strategy decomposing individual solutions
performing learning-based re-combination constructing nal solution advantages approaches, e.g., re-ranking set complete candidate solutions.
course, task-dependant conclusion. case semantic role labeling, approach relatively simple since re-combination argument candidates fulll
set structural constraints generate consistent solution. target structure complex (e.g., full parse tree) re-combination step might complex
learning search perspectives.
evaluation indicates proposed combination approaches successful:
provide signicant improvements best individual model several baseline
combination algorithms setups. three combination strategies investigated,
best F1 score obtained learning-based inference using max-margin classiers.
proposed approaches advantages drawbacks (see Section 8.7
detailed discussion dierences among proposed inference models) several important features state-of-the-art SRL combination strategy emerge analysis:
(i) individual models combined granularity candidate arguments rather
granularity complete solutions frames; (ii) best combination strategy
uses inference model based learning; (iii) learning-based inference benets
max-margin classiers global feedback, (iv) inference sentence level (i.e.,
considering predicates time) proves slightly useful learning
performed also globally, using feedback complete solution inference.
Last least, results obtained best combination strategy developed
work outperform current state art. results empirical proof
SRL system good performance built combining small number (three
experiments) relatively simple SRL models.

Acknowledgments
would like thank JAIR reviewers valuable comments.
research partially supported European Commission (CHIL project,
148

fiCombination Strategies Semantic Role Labeling

IP-506909; PASCAL Network, IST-2002-506778) Spanish Ministry Education
Science (TRANGRAM, TIN2004-07925-C03-02). Mihai Surdeanu research fellow
within Ramon Cajal program Spanish Ministry Education Science.
also grateful Dash Optimization free academic use Xpress-MP.

References
Bishop, C. (1995). Neural Networks Pattern Recognition. Oxford University Press.
Boas, H. C. (2002). Bilingual framenet dictionaries machine translation. Proceedings
LREC 2002.
Carreras, X., & Marquez, L. (2004). Introduction CoNLL-2004 shared task: Semantic
role labeling. Proceedings CoNLL 2004.
Carreras, X., & Marquez, L. (2005). Introduction conll-2005 shared task: Semantic
role labeling. Proceedings CoNLL-2005.
Carreras, X., Marquez, L., & Chrupala, G. (2004). Hierarchical recognition propositional
arguments perceptrons. Proceedings CoNLL 2004 Shared Task.
Charniak, E. (2000). maximum-entropy-inspired parser. Proceedings NAACL.
Collins, M. (1999). Head-Driven Statistical Models Natural Language Parsing. PhD
Dissertation, University Pennsylvania.
Collins, M. (2000). Discriminative reranking natural language parsing. Proceedings
17th International Conference Machine Learning, ICML-00, Stanford, CA
USA.
Collins, M. (2002). Discriminative training methods hidden markov models: Theory
experiments perceptron algorithms. Proceedings SIGDAT Conference
Empirical Methods Natural Language Processing, EMNLP-02.
Collins, M. (2004). Parameter estimation statistical parsing models: Theory practice distribution-free methods. Bunt, H., Carroll, J., & Satta, G. (Eds.), New
Developments Parsing Technology, chap. 2. Kluwer.
Collins, M., & Duy, N. (2002). New ranking algorithms parsing tagging: Kernels
discrete structures, voted perceptron. Proceedings 40th Annual
Meeting Association Computational Linguistics, ACL02.
Crammer, K., & Singer, Y. (2003a). family additive online algorithms category
ranking. Journal Machine Learning Research, 3, 10251058.
Crammer, K., & Singer, Y. (2003b). Ultraconservative online algorithms multiclass
problems. Journal Machine Learning Research, 3, 951991.
Freund, Y., & Schapire, R. E. (1999). Large margin classication using perceptron
algorithm. Machine Learning, 37 (3), 277296.
Gildea, D., & Jurafsky, D. (2002). Automatic labeling semantic roles. Computational
Linguistics, 28 (3).
149

fiSurdeanu, Marquez, Carreras, & Comas

Gildea, D., & Palmer, M. (2002). necessity syntactic parsing predicate argument
recognition. Proceedings 40th Annual Conference Association
Computational Linguistics (ACL-02).
Hacioglu, K., Pradhan, S., Ward, W., Martin, J. H., & Jurafsky, D. (2004). Semantic
role labeling tagging syntactic chunks. Proceedings 8th Conference
Computational Natural Language Learning (CoNLL-2004).
Haghighi, A., Toutanova, K., & Manning, C. (2005). joint model semantic role labeling.
Proceedings CoNLL-2005 Shared Task.
Koomen, P., Punyakanok, V., Roth, D., & Yih, W. (2005). Generalized inference
multiple semantic role labeling systems. Proceedings CoNLL-2005 Shared Task.
Laerty, J., McCallum, A., & Pereira, F. (2001). Conditonal random elds: Probabilistic models segmenting labeling sequence data. Proceedings 18th
International Conference Machine Learning, ICML-01.
Marcus, M., Santorini, B., & Marcinkiewicz, M. (1994). Building large annotated corpus
English: Penn Treebank. Computational Linguistics, 19 (2).
Marquez, L., Comas, P., Gimenez, J., & Catala, N. (2005). Semantic role labeling
sequential tagging. Proceedings CoNLL-2005 Shared Task.
Melli, G., Wang, Y., Liu, Y., Kashani, M. M., Shi, Z., Gu, B., Sarkar, A., & Popowich,
F. (2005). Description SQUASH, SFU question answering summary handler
DUC-2005 summarization task. Proceedings Document Understanding
Workshop, HLT/EMNLP Annual Meeting.
Narayanan, S., & Harabagiu, S. (2004). Question answering based semantic structures.
International Conference Computational Linguistics (COLING 2004).
Noreen, E. W. (1989). Computer-Intensive Methods Testing Hypotheses. John Wiley &
Sons.
Palmer, M., Gildea, D., & Kingsbury, P. (2005). Proposition Bank: annotated
corpus semantic roles. Computational Linguistics, 31 (1).
Ponzetto, S. P., & Strube, M. (2006a). Exploiting semantic role labeling, wordnet
wikipedia coreference resolution. Proceedings Human Language Technolgy
Conference North American Chapter Association Computational Linguistics.
Ponzetto, S. P., & Strube, M. (2006b). Semantic role labeling coreference resolution.
Companion Volume Proceedings 11th Meeting European Chapter
Association Computational Linguistics.
Pradhan, S., Hacioglu, K., Krugler, V., Ward, W., Martin, J. H., & Jurafsky, D. (2005a).
Support vector learning semantic argument classication. Machine Learning, 60,
1139.
Pradhan, S., Hacioglu, K., Ward, W., Martin, J. H., & Jurafsky, D. (2005b). Semantic role
chunking combining complementary syntactic views. Proceedings CoNLL-2005.
150

fiCombination Strategies Semantic Role Labeling

Pradhan, S., Ward, W., Hacioglu, K., Martin, J. H., & Jurafsky, D. (2005c). Semantic role
labeling using dierent syntactic views. Proceedings 43rd Annual Conference
Association Computational Linguistics.
Punyakanok, V., Roth, D., & Yih, W. (2005). necessity syntactic parsing semantic role labeling. Proceedings International Joint Conference Artificial
Intelligence (IJCAI).
Punyakanok, V., Roth, D., Yih, W., & Zimak, D. (2004). Semantic role labeling via integer linear programming inference. Proceedings International Conference
Computational Linguistics (COLING04).
Rosenblatt, F. (1958). perceptron: probabilistic model information storage
organization brain. Psychological Review, 65, 386407.
Roth, D., & Yih, W. (2004). linear programming formulation global inference
natural language tasks. Proceedings Annual Conference Computational
Natural Language Learning (CoNLL-2004), pp. 18, Boston, MA.
Roth, D., & Yih, W. (2005). Integer linear programming inference conditional random
elds. Proceedings International Conference Machine Learning (ICML).
Schapire, R. E., & Singer, Y. (1999). Improved boosting algorithms using condence-rated
predictions. Machine Learning, 37 (3).
Surdeanu, M., Harabagiu, S., Williams, J., & Aarseth, P. (2003). Using predicate-argument
structures information extraction. Proceedings 41st Annual Meeting
Association Computational Linguistics (ACL 2003).
Taskar, B., Guestrin, C., & Koller, D. (2003). Max-Margin Markov Networks. Proceedings
17th Annual Conference Neural Information Processing Systems, NIPS-03,
Vancouver, Canada.
Taskar, B., Klein, D., Collins, M., Koller, D., & Manning, C. (2004). Max-margin parsing.
Proceedings EMNLP-2004.
Toutanova, K., Haghighi, A., & Manning, C. (2005). Joint learning improves semantic role
labeling. Proceedings 43rd Annual Meeting Association Computational Linguistics (ACL05), pp. 589596, Ann Arbor, MI, USA. Association
Computational Linguistics.
Tsochantaridis, I., Hofmann, T., Joachims, T., & Altun, Y. (2004). Support vector machine
learning interdependent structured output spaces. Proceedings 21st
International Conference Machine Learning, ICML-04.
Xue, N., & Palmer, M. (2004). Calibrating features semantic role labeling. Proceedings
EMNLP-2004.
Yih, S. W., & Toutanova, K. (2006). Automatic semantic role labeling. Tutorial
Human Language Technolgy Conference North American Chapter
Association Computational Linguistics.
Younger, D. H. (1967). Recognition parsing context-free languages n3 time.
Information Control, 10 (2), 189208.

151

fiJournal Artificial Intelligence Research 29 (2007) 353389

Submitted 9/06; published 8/07

Answer Sets Logic Programs Arbitrary Abstract
Constraint Atoms
Tran Cao Son
Enrico Pontelli
Phan Huy Tu

tson@cs.nmsu.edu
epontell@cs.nmsu.edu
tphan@cs.nmsu.edu

Computer Science Department
New Mexico State University
Las Cruces, NM 88003, USA

Abstract
paper, present two alternative approaches defining answer sets logic
programs arbitrary types abstract constraint atoms (c-atoms). approaches
generalize fixpoint-based level mapping based answer set semantics normal
logic programs case logic programs arbitrary types c-atoms. results
four different answer set definitions equivalent applied normal logic
programs.
standard fixpoint-based semantics logic programs generalized two directions, called answer set reduct answer set complement. definitions,
differ treatment negation-as-failure (naf ) atoms, make use
immediate consequence operator perform answer set checking, whose definition relies
notion conditional satisfaction c-atoms w.r.t. pair interpretations.
two definitions, called strongly weakly well-supported models, generalizations notion well-supported models normal logic programs case
programs c-atoms. case fixpoint-based semantics, difference
two definitions rooted treatment naf atoms.
prove answer sets reduct (resp. complement) equivalent weakly
(resp. strongly) well-supported models program, thus generalizing theorem
correspondence stable models well-supported models normal logic
program class programs c-atoms.
show newly defined semantics coincide previously introduced semantics logic programs monotone c-atoms, extend original answer set
semantics normal logic programs. also study properties answer sets programs c-atoms, relate definitions several semantics logic programs
aggregates presented literature.

1. Introduction Motivation
Logic programming answer set semantics introduced attractive
suitable knowledge representation language AI research (Baral, 2005), offers
several desirable properties type applications. Among things, language
declarative simple syntax; naturally supports non-monotonic reasoning,
sufficiently expressive representing several classes problems (e.g., normal logic
programs capture class NP-complete problems); solid theoretical foundations
large body building block results (e.g., equivalence programs, systematic
c
2007
AI Access Foundation. rights reserved.

fiSon, Pontelli, & Tu

program development, relationships non-monotonic formalisms), extremely
useful development validation large knowledge bases; also large number
efficient computational tools. discussion issues, interested reader
referred book Baral (2003), overview paper Gelfond Leone (2002),
paper Marek Truszczynski (1999), paper Niemela (1999).
large number extensions logic programming, aimed improving usability
context knowledge representation reasoning, proposed. Smodels
system introduces weight cardinality constraint atoms facilitate encoding
constraints atom definitions (Simons, Niemela, & Soininen, 2002). constructs
generalized aggregates; aggregates extensively studied general
context logic programming work (see, e.g., Kemp & Stuckey, 1991; Mumick,
Pirahesh, & Ramakrishnan, 1990; Gelder, 1992), developed recent years (see,
e.g., DellArmi, Faber, Ielpa, Leone, & Pfeifer, 2003; Denecker, Pelov, & Bruynooghe, 2001;
Elkabani, Pontelli, & Son, 2004; Faber, Leone, & Pfeifer, 2004; Gelfond, 2002; Pelov, 2004;
Son & Pontelli, 2007). dlv (Eiter, Leone, Mateis, Pfeifer, & Scarcello, 1998)
Smodels extended deal various classes aggregates (DellArmi et al.,
2003; Elkabani, Pontelli, & Son, 2005). semantics extensions defined
either indirectly, translating programs extensions normal logic programs,
directly, providing new characterizations concept answer sets programs
extensions.
mentioned extensions logic programming introduced
facilitate representation desirable type knowledge logic programming.
such, surprise focus definition semantics
little done investigate basic building block results new classes
logic programs. context, study uniform framework covering various classes
extensions provide us several benefits. example, prove (or disprove) whether
basic building block result (e.g., splitting theorem) extended new classes
logic programs, need prove (or disprove) result once; new results
study generic framework applicable study one aforementioned
extensions; etc. Naturally, studies possible, uniform framework whose
semantical definition exhibits behavior various extensions logic programming, needs
developed. main goal paper address issue.
concept logic programs abstract constraint atoms (or c-atoms)
introduced Marek, Remmel, Truszczynski elegant theoretical framework
investigating, uniform fashion, various extensions logic programming, including cardinality constraint atoms, weight constraint atoms, general forms aggregates
(Marek & Remmel, 2004; Marek & Truszczynski, 2004). Intuitively, c-atom represents
constraint models program containing Aand description includes
explicit description conditions interpretation meet order satisfy
A. view general, shown subsume description traditional classes aggregates (e.g., Sum, Count, Min, etc.).1 Thus, programs weight
constraint atoms aggregates represented logic programs c-atoms.
1. One could also argue c-atoms general aggregates capture analogous notions.

354

fiLogic Programs Arbitrary Abstract Constraint Atoms

first explicit definition answer sets positive programs arbitrary c-atoms
(i.e., programs without negation-as-failure operator)called programs set constraints SC-programshas introduced work Marek Remmel (2004).
work answer sets programs c-atoms defined extending notion
answer sets programs weight constraint atoms proposed work Niemela,
Simons, Soininen (1999). Nevertheless, approach provides, certain cases, unintuitive answer sets (see, e.g., Examples 7 20). particular, approach Marek
Remmel naturally capture well-agreed semantics aggregates.
One main goals paper investigate alternative solutions problem
characterizing answer sets programs arbitrary c-atoms. aim match
semantics provided recent literature monotone c-atoms, avoid
pitfalls approach developed work Marek Remmel (2004).
concept answer sets programs c-atoms later revisited Marek
Truszczynski (2004), focusing answer sets programs monotone constraint
atoms, c-atom monotone if, pair interpretations 0
0 , satisfies implies 0 satisfies A. proposal
extended case disjunctive logic programs monotone c-atoms (Pelov &
Truszczynski, 2004). another paper (Liu & Truszczynski, 2005b), extended deal
convex c-atoms c-atom convex if, every pair interpretations J
J, J satisfy implies 0 satisfies every 0 J.
paper also proves several properties programs monotone convex c-atoms.
shown many well-known properties standard logic programming answer
set semantics preserved case programs monotone c-atoms.
main advantage focusing monotone c-atoms lies monotonicity provides
relatively simpler way defining answer sets logic programs c-atoms.
hand, restriction allow several important classes problems
directly expressed. example2 , aggregate atom Min({X | p(X)}) > 2 cannot
viewed monotone aggregate atomsince monotonic extensions definition p
might make aggregate false; e.g., aggregate true {p(3)} definition p,
becomes false consider definition containing {p(3), p(1)}. Similarly, cardinality
constraint atom 1 {a, b} 1 monotone constraint. Neither two examples
directly encoded using monotone c-atoms.
studies Marek Remmel (2004), Marek Truszczynski (2004) Liu
Truszczynski (2005b) lead following question: alternatives
approach defining answer sets programs arbitrary c-atoms developed Marek
Remmel (2004)? Furthermore, alternativesif capture semantics
programs monotone c-atoms proposed Marek Truszczynski (2004) avoid
pitfalls notion answer sets arbitrary c-atoms Marek Remmel (2004)?
present two equivalent approaches defining answer sets logic programs
arbitrary c-atoms.
first approach inspired notion conditional satisfactionoriginally
developed Son Pontelli (2007)to characterize semantics logic programs
2. Although variables appear definition aggregates, locally quantified. such,
aggregate literal nothing shorthand collection ground terms.

355

fiSon, Pontelli, & Tu

aggregates. generalize notion case programs c-atoms.
generalization turns significantly intuitive easier understand
original definition Son Pontelli (2007). Using notion, define
immediate consequence operator TP answer set checking.
second approach inspired notion well-supportedness, proposed
Fages (1994) normal logic programs.
approaches intuitive, and, believe, improve semantics proposed logic programs arbitrary c-atoms Marek Remmel (2004).
show newly defined semantics coincide previously introduced
semantics Marek Truszczynski (2004) case programs monotone c-atoms,
extend original stable model semantics normal logic programs. discuss
different approaches treating negation-as-failure c-atoms. also relate definitions
several semantics logic programs aggregates, since notion c-atom
used encode arbitrary aggregates. results show proposed framework
naturally subsumes many existing treatments aggregates logic programming.
summary, main contributions paper are:
new notion fixpoint answer set programs arbitrary c-atoms,
inspired fixpoint construction proposed Son Pontelli (2007) (but simpler)
differs significantly proposal programs arbitrary catoms Marek Remmel (2004); lead two different definitions answer
sets (answer set reduct answer set complement);
generalization notion well-supported models Fages (1994) programs
arbitrary c-atoms, whichto best knowledgehas investigated researchers, leads notions weakly strongly
well-supported models;
result showing set answer sets reduct (resp. complement)
equivalent set weakly (resp. strongly) well-supported models;
number results showing newly defined notions answer sets capture
answer set semantics various extensions logic programming, cases
previously proposed semantics agree.
rest paper organized follows. Section 2 presents preliminary definitions,
including syntax language logic programming c-atoms, basic notion
satisfaction, notion answer set programs monotone c-atoms Marek
Truszczynski (2004) positive programs arbitrary c-atoms Marek Remmel
(2004). Section 3 presents first approach defining answer sets logic programs
arbitrary c-atoms based fixpoint operator, Section 4 introduces alternative
definition based well-supportedness. Section 5 extends semantics programs
arbitrary c-atoms head rules. Section 6 relates semantics presented paper
early work abstract constraint atoms aggregates. Section 7 provides conclusions
future work. Proofs theorems propositions deferred appendix.
356

fiLogic Programs Arbitrary Abstract Constraint Atoms

2. PreliminariesLogic Programs Abstract Constraint Atoms
follow syntax used Liu Truszczynski (2005b) define programs abstract
constraint atoms. Throughout paper, assume fixed propositional language L
countable set propositional atoms.
2.1 Syntax
abstract constraint atom (or c-atom) expression form (D, C),
set atoms (the domain c-atom), C collection sets atoms belonging
D, i.e., C 2D (the solutions c-atom). Intuitively, c-atom (D, C) constraint
set atoms D, C represents admissible solutions. Given c-atom = (D, C),
use Ad Ac denote C, respectively.
c-atom form ({p}, {{p}}) called elementary c-atom simply
written p. c-atom form (A, ), representing constraint admit
solutions, denoted . c-atom said monotone every
X Ad , X Ac implies Ac .
rule form
A1 , . . . , Ak , Ak+1 , . . . ,

(1)

A, Aj c-atoms. literals Aj (k < j n) called negation-as-failure
c-atoms (or naf-atoms). rule r form (1), define:
head(r) = A,
pos(r) = {A1 , . . . , Ak },
neg(r) = {Ak+1 , . . . , },
body(r) = {A1 , . . . , Ak , Ak+1 , . . . , }.
program P , hset(P ) denotes set rP head(r)d .
recognize special types rules:
1. rule r positive neg(r) = ;
2. rule r basic head(r) elementary c-atom;
3. rule r constraint rule head(r) = .
logic program c-atoms (or logic program, simplicity)3 set rules. program
P called basic program rule r P basic constraint rule. P said
positive every rule P positive. P monotone (resp. naf-monotone) c-atom
occurring P (resp. naf-atom P ) monotone. Clearly, monotone program
also naf-monotone.
3. Whenever want refer traditional logic programs (without c-atoms), explicitly talk
normal logic programs.

357

fiSon, Pontelli, & Tu

2.2 Models Satisfaction
subsection, introduce basic definitions study logic programs
constraints. begin definition satisfaction c-atoms.
introduce notion model programs c-atoms.
2.2.1 Satisfaction C-Atoms
set atoms satisfies c-atom A, denoted |= A, Ad Ac . satisfies
A, denoted |= A, Ad 6 Ac .
shown Marek Remmel (2004) Marek Truszczynski (2004)
notion c-atom general extended atoms cardinality constraint atoms aggregate atoms; thus, c-atoms used conveniently represent
weight constraints, cardinality constraints (Simons et al., 2002), various classes
aggregates, maximal cardinality constraints. example,
Let us consider arbitrary choice atom form L{p1 , . . . , pk , notq1 , . . . , notqh }U ;
represented c-atom (A, S) where:
= {p1 , . . . , pk , q1 , . . . , qh }
= { | L |(T {p1 , . . . , pk }) ({q1 , . . . , qh } \ )| U }
Let us consider arbitrary aggregate form F {v | p(v)} V F set
function (e.g., Sum, Avg), V number, comparison operation (e.g.,
, >, 6=). represented c-atom (A, S), where:
= {p(a) | p(a) A}
= {T | A, F (T ) V }
Example 1 Let us consider aggregate sum({X | p(X)}) 1, defined language
= {p(1), p(2)}. considerations above, aggregate
represented c-atom ({p1 ), p(2)}, S)
= {T | {p(1), p(2)}, sum(T ) 1} = {, {p(1)}, {p(2), p(1)}}
2
Example 2 Let us consider cardinality constraint atom 1 {p(1), p(1)} 1.
represented c-atom ({p(1), p(1)}, S)
= { | {p(1), p(1)}, 1 |(T {p(1), p(1)}| 1 } = {{p(1)}, {p(1)}}
2
C-atoms allow us compactly represent properties would require complex propositional combinations traditional aggregates. E.g., condition like either elements
elements set {a, b, c, d} true simply written single c-atom
({a, b, c, d}, {, {a, b, c, d}}). motivations behind use c-atoms found
Marek Remmel (2004) Marek Truszczynski (2004).
rest paper, often use examples notation cardinality
constraint atoms, weight constraint atoms, general aggregate atoms instead c-atoms,
whenever confusion possible.
358

fiLogic Programs Arbitrary Abstract Constraint Atoms

2.2.2 Models
set atoms satisfies body rule r form (1), denoted |= body(r),
|= Ai = 1, . . . , k |= Aj j = k + 1, . . . , n. satisfies rule r
satisfies head(r) satisfy body(r).
set atoms model program P satisfies every rule P . minimal
model P model P proper subset also model
P . particular, programs may one minimal model (see, example,
Example 5).
Given program P , set atoms said support atom exists
rule r P X head(r)c following conditions met:
|= body(r),
X S,
X.
Example 3 Let P1 4 program
p(a)
p(b)
p(c)
q



q
Count({X | p(X)}) > 2

aggregate notation Count({X|p(X)}) > 2 represents c-atom (D, {D})
= {p(a), p(b), p(c)}. P1 two models:
M1 = {p(a), p(b), p(c), q}

M2 = {p(a), p(b)}

M2 minimal model P1 , M1 not.

2

Example 4 Let P2 program
p(1)

p(1) p(2)
p(2)
Sum({X | p(X)}) 1
aggregate notation Sum({X|p(X)})1 represents c-atom (D, C)
= {p(1), p(2), p(1)}

C = {{p(1)}, {p(2)}, {p(1), p(2)}, {p(2), p(1)}, {p(1), p(2), p(1)}}
first rule, model P2 need contain {p(1)}. easy see
{p(1), p(1)} {p(1), p(2), p(1)} models P2 {p(1), p(2)} model P2 .
2
Example 5 Let P3 program
p ({q}, {})
q ({p}, {})
P3 three models {p}, {q}, {p, q}, {p} {q} minimal.
4. Remember notation p short form c-atom ({p}, {{p}}).

359

2

fiSon, Pontelli, & Tu

2.3 Previously Proposed Semantics
section, overview semantical characterizations programs c-atoms
proposed existing literature. particular, review notion answer sets
monotone programs (i.e., program contain monotone c-atoms), defined
Marek Truszczynski (2004). formal comparison semantics
novel approach propose paper described Section 6.
Given set atoms S, rule r applicable |= body(r). set applicable
rules denoted P (S). set 0 nondeterministically one-step provable
means P 0 hset(P (S)) 0 |= head(r) every r P (S). nondeterministic

one-step provability operator TPnd function 2A 22 every A,
TPnd (S) consists sets 0 nondeterministically one-step provable
means P .
P -computation sequence = (Xn )n=0,1,2,... X0 = every nonnegative integer n,
(i) Xn Xn+1 ,
(ii) Xn+1 TPnd (Xn )
St =
n=0 Xi called result computation t. set atoms derivable model
P exists P -computation = St . Gelfond-Lifschitz reduct
normal logic programs generalized monotone programs follows.
Definition 1 Let P monotone program. set atoms , reduct P
respect , denoted P , obtained P
1. removing P every rule containing body literal |= A;

2. removing literals form remaining rules.
Answer sets monotone programs defined next.
Definition 2 set atoms answer set monotone program P
derivable model reduct P .
next example shows that, programs non-monotone c-atoms, Definition 2 is,
general, applicable.
Example 6 Consider program P3 Example 5. check program
allow construction P3 -computation. fact, TPnd
() = {{p, q}}
3
nd
TP3 ({p, q}) = {}. Hence, {p} would answer set P3 (according Definition 2)
since derivable model reduct P3 respect {p} (which P3 ).
hand, easy see P3 intuitively equivalent normal logic
program {p q, q p}. such, P3 accept {p} one answer sets.
2
main reason inapplicability Definition 2 lies nondeterministic onestep provability operator TPnd might become non-monotone presence non-monotone
c-atoms.
360

fiLogic Programs Arbitrary Abstract Constraint Atoms

2.4 Answer Sets Positive Programs
Positive programs characterized lack negation-as-failure atoms. Positive programs arbitrary c-atoms investigated Marek Remmel (2004),
name SC-programs. Let us briefly review notion answer sets SC-programs
which, turn, generalization notion answer sets logic programs weight
constraints, presented Niemela et al. (1999). detailed comparison approach Marek Remmel (2004) work given Section 6.
b c-atom
c-atom A, closure A, denoted A,
( Ad , {Y | Ad , Z. (Z Ac , Z )} )
Intuitively, closure constructed including supersets existing solutions.
b rule form (1) Horn-rule
c-atom said closed = A.
(i) head elementary c-atom; (ii) c-atom body closed c-atom.
SC-program P said Horn SC-program rule P Horn-rule.
one-step provability operator, defined TP (X) = {a | r P, head(r) = a, X |= body(r)},
associated Horn SC-program P monotone. Hence, every Horn SC-program P
least fixpoint P minimal model P (w.r.t. set inclusion). Given
set atoms SC-program P , NSS-reduct P respect , denoted
N SS(P, ), obtained P
(i) removing rules whose body satisfied ;
(ii) replacing rule
e1 , . . . , en , A1 , . . . ,
ei elementary c-atoms Aj non-elementary c-atoms set
rules
c1 , . . . ,

{a e1 , . . . , en ,
| Ad }
model program P answer set P least fixpoint one-step
provability operator program N SS(P, S), i.e., = N SS(P,S) . sometimes yields
answer sets accepted extensions logic programming. next
example illustrates point.
Example 7 Consider program P4 :
c
({a, c}, {, {a, c}})
M1 = {c} M2 = {a, c} models P4 . Furthermore, N SS(P4 , M1 )
program
c
N SS(P4 , M2 ) consists rules
c
({a, c}, {, {a}, {c}, {a, c})}
361

fiSon, Pontelli, & Tu

easy see M1 = N SS(P,M1 ) M2 = N SS(P,M2 ) . Thus, observe P4
non-minimal answer set {a, c} according Marek Remmel (2004). Note
program P4 viewed following program aggregates
c
Count({a, c}) 6= 1
{a, c} answer set proposed semantics
aggregates (Denecker et al., 2001; Faber et al., 2004; Ferraris, 2005; Pelov, 2004; Son &
Pontelli, 2007). Furthermore, approaches accept {c} answer set
program.
2

3. Answer Sets Basic Programs: Fixpoint Based Approach
section, define notion answer sets basic programs. approach,
follow traditional way defining answer sets logic programs, i.e., by:
1. first characterizing semantics positive programs (Definition 4),
2. extending deal naf-atoms (Definitions 7 8).
3.1 Answer Sets Basic Positive Programs
Example 5 shows basic positive program might one minimal model.
leads us define TP -like operator answer set checking, whose construction
based following observation.
Observation 1 Let P propositional normal logic program (i.e., without
c-atoms)5 let R, two sets atoms. Given set atoms , define
operator TP (R, S) monotone sequence interpretations hIiM ii=0
follows.
)
(
r P : head(r) = a,
TP (R, S) =
pos(r) R, neg(r) =
I0M =

= (I , )
Ii+1
P

(i 0)

Let us denote IM limit sequence interpretations. possible
prove answer set P w.r.t. Gelfond Lifschitz (1988) iff
= IM .
see observation, (modified) consequence operator TP takes
two sets atoms, R S, arguments, generates one set atoms could
viewed consequences P given R true assumed answer
set P . easy see TP monotone w.r.t. first argument, i.e., R V ,
TP (R, S) TP (V, S). Thus, sequence hIjM ij=0 monotone converges IM
given S. next show TP generalized programs c-atoms.
5. rule r normal logic program P ,
a1 , . . . , , b1 , . . . , bm
head(r), pos(r), neg(r) denote a, {a1 , . . . , }, {b1 , . . . , bm }, respectively.

362

fiLogic Programs Arbitrary Abstract Constraint Atoms

Observe definition TP requires pos(r) R or, equivalently, R |= pos(r).
normal logic programs, sufficient guarantee monotonicity TP (, S).
definition naively generalized case programs c-atoms, monotonicity
TP (., S) guaranteed certain circumstances, e.g., c-atoms pos(r)
monotone. deal arbitrary c-atoms, need introduce notion conditional
satisfaction c-atom.
Definition 3 (Conditional Satisfaction) Let sets atoms. set
conditionally satisfies c-atom w.r.t. , denoted |=M A,
1. |= and,
2. every Ad Ad Ad , Ac .
Observe notion conditional satisfaction inspired conditional
satisfaction used characterize aggregates Son Pontelli (2007), significantly
simpler.
say conditionally satisfies set c-atoms V w.r.t. , denoted |=M V ,
|=M every V . Intuitively, |=M V implies 0 |= V every 0
0 . Thus, conditional satisfaction ensures body rule satisfied
also satisfied 0 , provided 0 . allows us generalize
operator TP defined Observation 1 follows. set atoms positive basic
program P , let


n

TP (S, ) =

r P : |=M pos(r), head(r) = ({a}, {{a}})

following proposition holds.
Proposition 1 Let model P , let U .
TP (U, ) M.

TP (S, )

Let TP0 (, ) = and, 0, let
TPi+1 (, ) = TP (TPi (, ), )
Then, following corollary natural consequence Proposition 1.
Corollary 1 Let P positive, basic program model P . Then,
TP0 (, ) TP1 (, ) . . .
corollary implies sequence hTPi (, )i
i=0 monotone limited (w.r.t.
set inclusion) . Therefore, converges fixpoint. denote fixpoint
TP (, ).
Definition 4 Let model basic positive program P . answer set P
iff = TP (, ).
363

fiSon, Pontelli, & Tu

Observe constraint rules present P (i.e., rules whose head ) contribute
construction performed TP ; nevertheless, requirement
model P implies constraint rules satisfied answer set.
illustrate Definition 4 next examples.
Example 8 Consider program P1 Example 3.
M1 = {p(a), p(b)} answer set P1 since:
TP01 (, M1 ) =
TP11 (, M1 ) = {p(a), p(b)} = M1
TP21 (, M1 ) = TP1 ({p(a), p(b)}, M1 ) = M1
M2 = {p(a), p(b), p(c), q} answer set P1 , since:
TP01 (, M2 ) =
TP11 (, M2 ) = {p(a), p(b)} = M1
TP21 (, M2 ) = TP1 ({p(a), p(b)}, M2 ) = M1
2
Example 9 Consider program P3 (Example 5). Let M1 = {p} M2 = {q}.

TP03 (, M1 ) =
TP03 (, M2 ) =
TP13 (, M1 ) = {p} = M1
TP13 (, M2 ) = {q} = M2
Thus, {p} {q} answer sets P3 . hand, = {p, q},
TP13 (, {p, q}) = 6|=M ({q}, {}) 6|=M ({p}, {}). Hence, {p, q}
answer set P3 .
2
conclude section observing answer sets obtained construction minimal models.
Corollary 2 Let P positive basic program answer set P . Then,
minimal model P .
next example shows every positive program answer set.
Example 10 Consider P2 (Example 4). Since answer sets positive programs minimal
models (Corollary 2) = {p(1), p(1)} minimal model P2 ,
possible answer set P2 . Since
TP02 (, ) =
TP12 (, ) = {p(1)}
TP22 (, ) = TP2 ({p(1)}, ) = {p(1)}
conclude answer set P2 . Thus, P2 answer sets. 2
example highlights supportedness, approach, sufficient condition
answer setM 0 = {p(1), p(1), p(2)} supported model, accepted
answer set. reason rejecting 0 fact element p(2) essentially
self-supporting (cyclically) 0 . Note 0 rejected, answer set,
approaches aggregates logic programminge.g., approach Faber et al. (2004)
rejects 0 minimal model FLP-reduct program.
364

fiLogic Programs Arbitrary Abstract Constraint Atoms

3.2 Answer Sets Basic Programs
define answer sets basic programs, i.e., programs elementary c-atoms
head rules, rule bodies composed c-atoms naf-atoms.
literature, two main approaches considered deal negation aggregates complex atoms. Various extensions logic programming (e.g., weight
constraints Simons et al. (2002) aggregates Faber et al. (2004)) support negationas-failure atoms replacing naf-atom c-atom A0 , A0 obtained
replacing predicate relation negation. example, following
approach, negated cardinality constraint atom 1 {a, b} 1 replaced
({a, b}, {, {a, b}}). Similarly, negated aggregate atom Sum({X | p(X)}) 6= 5
replaced Sum({X | p(X)}) = 5.
hand, researchers (see, e.g., Marek & Truszczynski, 2004; Ferraris,
2005) suggested handle naf-atoms using form program reductin
spirit Gelfond Lifschitz (1988).
Following perspectives, study two different approaches dealing nafatoms, described next two subsections. worth mentioning approaches
coincide case monotone programs (Proposition 2).
3.2.1 Negation-as-Failure Complement
approach, treat naf-atom replacing complement. define
notion complement c-atom follows.
Definition 5 complement c-atom c-atom (Ad , 2Ad \ Ac ).
next define complement program P .
Definition 6 Given basic program P , define C(P ) (the complement P )
program obtained P replacing occurrence P complement
A.
program C(P ) basic positive program, whose answer sets defined
Definition 4. allows us define notion answer sets basic programs follows.
Definition 7 set atoms answer set complement basic program P iff
answer set C(P ).
easy see answer set program P indeed minimal model P .
Example 11 Let us consider program P5 , consists following rules:

c

({a, b}, {{a, b}})

complement P5

c ({a, b}, {, {a}, {b}})
{a, c} answer set. Thus, {a, c} answer set complement P5 .
2
365

fiSon, Pontelli, & Tu

Example 12 Let P6 program
c 1{a, b}1
c
b
C(P6 ) program
c ({a, b}, {, {a, b}})
c
b
program answer set (w.r.t. Definition 4); thus P6
answer set complement.
2
3.2.2 Negation-as-Failure Reduction
Another approach dealing naf-atoms adapt Gelfond-Lifschitz reduction
normal logic programs (Gelfond & Lifschitz, 1988) programs c-atomsthis approach considered Marek Truszczynski (2004) Ferraris (2005).
generalize approach programs arbitrary c-atoms follows. basic program
P set atoms , reduct P w.r.t. (P ) set rules obtained
1. removing rules containing s.t. |= A;
2. removing remaining rules.
program P positive basic program. Thus, define answer sets P
follows:
Definition 8 set atoms answer set reduct P iff answer set
P (w.r.t. Definition 4).
Example 13 Let us reconsider program P5 Example 11 let us consider =
{a, c}. perform reduct, left rules

c
whose minimal model itself. Thus, answer set reduct program P5 .
2
next example shows approach lead different answer sets case
negation complement (for non-monotone programs).
Example 14 Consider program P6 Example 12. Let = {a, b, c}. reduct
P6 w.r.t. program
c
c
b
answer set, i.e., answer set reduct P6 .
366

2

fiLogic Programs Arbitrary Abstract Constraint Atoms

One consequence negation reduct approach fact might lead nonminimal answer setsin presence non-monotone atoms. instance, replace
atom Count({X | p(X)}) > 2 P1 Count({X | p(X)}) 2, new
program (by replacing aggregate c-atom):
p(a)
p(b)
p(c) q
q





(

{p(a), p(b), p(c)},

, {p(a)}, {p(b)}, {p(c)},
{p(a), p(b)}, {p(b), p(c)}, {p(a), p(c)}

)!

program admits following two interpretations answer sets reduct: M1 =
{p(a), p(b), p(c), q} M2 = {p(a), p(b)}. Since M2 M1 , non-minimal
answer set exists.
result indicates that, certain programs c-atoms, might different
ways treat naf-atoms, leading different semantical characterizations. problem
mentioned Ferraris (2005). Investigating methodologies dealing
naf-atoms interesting topic research, plan pursue future.
3.3 Properties Answer Sets Basic Programs
show notion answer sets basic programs c-atoms natural
generalization notions answer sets normal logic programs. prove
answer sets basic positive programs minimal supported models characterize
situations properties hold basic programs. begin result stating
that, class naf-monotone programs, two approaches dealing naf-atoms
coincide.
Proposition 2 Let P basic program. answer set complement P
answer set reduct P . Furthermore, P naf-monotone, answer set
reduct P also answer set complement P .
proposition implies that, general, negation-as-failure complement approach skeptical negation-as-failure reduct approach, may
accept fewer answer sets.6 Furthermore, Examples 12 14 show minimal (w.r.t.
set inclusion) answer set reduct necessarily answer set complement
program.
Let P normal logic program (without c-atoms) let c-atom(P ) program obtained replacing occurrence atom P ({a}, {{a}}). Since
({a}, {{a}}) monotone c-atom, c-atom(P ) monotone program. Proposition 2 implies that, c-atom(P ), answer sets reduct answer sets complement coincide.
next proposition, prove notion answer sets programs c-atoms
preserves notion answer set normal logic programs, following sense.
6. Note use term skeptical indicate acceptance fewer models, somewhat different
use term model theory.

367

fiSon, Pontelli, & Tu

Proposition 3 (Preserving Answer Sets) normal logic program P , answer set (by complement reduct) c-atom(P ) iff answer set P (w.r.t.
definition Gelfond Lifschitz (1988)).
proposition, together Proposition 2, implies normal logic programs
represented positive basic programs. stated following corollary.
Corollary 3 Every answer set normal logic program P answer set
C(c-atom(P )) vice versa.
next proposition, study minimality supportedness properties answer
sets basic programs.
Proposition 4 (Minimality Answer Sets) following properties hold:
1. Every answer set complement basic program P minimal model P .
2. Every answer set reduct basic, naf-monotone program P minimal model
P .
3. Every answer set (by complement/reduct) basic program P supports
members.

4. Answer Sets Basic Programs: Level Mapping Based Approach
definition answer sets provided previous section viewed generalization answer set semantics normal logic programsin sense relies
fixpoint operator, defined positive programs. section, discuss another
approach defining answer sets programs c-atoms, based notion
well-supported models.
notion well-supported models normal logic programs introduced Fages
(1994), provides interesting alternative characterization answer sets. Intuitively,
model program P well-supported model iff exists level mapping,
atoms set positive integers, atom supported
rule r, whose body satisfied level positive atom body(r) strictly
smaller level a.7 Fages proved answer sets well-supported models
vice versa (Fages, 1994). notion well-supportedness extended deal
dynamic logic programs Banti, Alferes, Brogi, Hitzler (2005). Level mapping
also used effective tool analyze different semantics logic programs
uniform way (Hitzler & Wendt, 2005).
follows, show notion well-supported models effectively
applied programs c-atoms. key formulation notion answer
following question:
level c-atom given set atoms level mapping L ?
one hand, one might argue level mapping defined independently
mapping atoms, atom itself. hand,
7. implicitly means pos(r) neg(r) = , i.e., naf-atoms dealt reduct.

368

fiLogic Programs Arbitrary Abstract Constraint Atoms

reasonable assume level depends levels atoms Ad , since
satisfaction (w.r.t. given interpretation) depends satisfaction elements
Ad . fact every existing semantics programs c-atoms evaluates truth
value c-atom based truth value assigned elements Ad stipulates us
adopt second view.
worth mention view also allows us avoid undesirable circular justifications elements well-supported model: follow first view, program P7
consisting following rules
b
b
({a, b}, {, {a, b}})
would {a, b} well-supported model a, b, ({a, b}, {, {a, b}})
supported ({a, b}, {, {a, b}}), a, {a, b} respectively. means true
b true, i.e., circular justification w.r.t. model
{a, b}.
Let set atoms, ` mapping positive integers, let
c-atom. define H(X) = max({`(a) | X}),
L(A, ) = min({H(X) | X Ac , X M, X |=M A}).
Intuitively, level atom given smallest levels solutions
atom compatible level solution given maximum level
atoms solution. assume max() = 0, min() undefined.
introduce two different notions well-supported models. first notion, called weakly
well-supported models, straightforward generalization definition given Fages
(1994)in ignores naf-atoms. second notion,, called strongly well-supported
models, take consideration naf-atoms definition.
Definition 9 (Weakly Well-Supported Model) Let P basic program. model
P said weakly well-supported iff exists level mapping ` that,
b , P contains rule r head(r) = ({b}, {{b}}), |= body(r),
pos(r), L(A, ) defined l(b) > L(A, ).
illustrate definition next example.
Example 15 Let us consider program P5 set atoms = {a, b}. Let
= ({a, b}, {, {a, b}}). Obviously, model P5 . Assume weakly wellsupported model P5 . means exists mapping ` set
positive integers satisfying condition Definition 9. Since b one
rule P5 b head, conclude `(b) > `(a). Observe 6|=M
{a, b} |=M A. Thus, definition L(A, ),
L(A, ) = max({`(a), `(b)}) = `(b).
implies exists rule P5 , satisfies condition Definition 9
head. words, weakly well-supported model P5 .
2
369

fiSon, Pontelli, & Tu

next proposition generalizes Fages result answer sets reduct programs
c-atoms.
Proposition 5 set atoms answer set reduct basic program P iff
weakly well-supported model P .
seen previous section, different ways deal naf-atoms lead
different semantics basic programs c-atoms. take consideration fact
naf-atoms dealt complement, develop alternative generalization
Fagess definition well-supported model programs abstract c-atoms follows.
Definition 10 (Strongly Well-Supported Model) Let P basic program. model
P said strongly well-supported iff exists level mapping ` that,
b , P contains rule r head(r) = ({b}, {{b}}), |= body(r),
pos(r), L(A, ) defined `(b) > L(A, ), neg(r), L(A, )
defined `(b) > L(A, ),
Using Proposition 5 Proposition 2, easily show following result holds.
Proposition 6 set atoms answer set complement basic program P
iff strongly well-supported model C(P ).
two propositions, together Proposition 2, lead following corollary.
Corollary 4 every naf-monotone basic program P , weakly well-supported model
P also strongly well-supported model P vice versa.
discussed previous section, normal logic program P easily
translated monotone basic program c-atoms form ({a}, {{a}}), c-atom(P ).
Thus, Corollary 4 indicates notion weakly/strongly well-supported model
indeed generalization Fagess definition well-supported model programs catoms.

5. Answer Sets General Programs
General programs programs non-elementary c-atoms head. usefulness
rules non-elementary c-atoms head, form weight constraint
aggregate, discussed Ferraris (2005), Simons et al. (2002) Son, Pontelli,
Elkabani (2006). example, simple atom8
Count({X | taken(X, ai)}) 10
used represent constraint 10 students take AI class.
next example shows 3-coloring problem graph G represented using
c-atoms.
8. Recall aggregates special form c-atoms.

370

fiLogic Programs Arbitrary Abstract Constraint Atoms

Example 16 Let three colors red (r), blue (b), green (g). program contains
following rules:
set atoms edge(u, v) every edge (u, v) G,
vertex u G, following rule:
({color(u, b), color(u, r), color(u, g)}, {{color(u, b)}, {color(u, r)}, {color(u, g)}})
states u must assigned one one colors red, blue,
green.
edge (u, v) G, three rules representing constraint u v must
different color:
color(u, r), color(v, r), edge(u, v)
color(u, b), color(v, b), edge(u, v)
color(u, g), color(v, g), edge(u, v)
2
note that, exception proposals Ferraris (2005), Son, Pontelli,
Elkabani (2006), approaches defining answer sets logic programs aggregates
deal programs aggregates head. hand, weight constraint
choice atoms allowed head (Simons et al., 2002). Similarly, c-atoms
considered head rules framework logic programs c-atoms Marek
Remmel (2004) Marek Truszczynski (2004).
section, define answer sets general programsi.e., programs
rule heads arbitrary c-atoms. approach convert program P c-atoms
head collection basic programs, whose answer sets defined answer sets
P . simplify presentation, talk answer set basic program
refer either answer set complement, answer set reduct, well-supported
model program. distinction stated clearly whenever needed.
Let P program, r P , let model P . instance r w.r.t. ,
denoted inst(r, ) defined follows
(

inst(r, ) =

{b body(r) | b head(r)d }


head(r)d head(r)c
otherwise

instance P w.r.t. , denoted inst(P, ), program
inst(P, ) =

[

inst(r, )

rP

easy see instance P w.r.t. basic program. allows us define
answer sets general programs follows.
Definition 11 Let P general program. answer set P iff model
P answer set inst(P, ).
371

fiSon, Pontelli, & Tu

definition illustrated next examples.
Example 17 Let P8 program consisting single fact:
({a, b}, {{a}, {b}})
Intuitively, P8 choice atom 1 {a, b} 1 notation Smodels.
program two models, {a} {b}. instance inst(P8 , {a}) contains
single fact

whose answer set {a}. Similarly, instance inst(P8 , {b}) single fact
b
whose answer set {b}. Thus, P8 two answer sets {a} {b}.

2

next example shows presence non-elementary c-atoms head, answer
sets might minimal.
Example 18 Let P9 program consisting following rules:
({a, b}, {{a}, {b}, {a, b}})
c b
Intuitively, first rule P9 cardinality constraint 1 {a, b} 2 notation
Smodels. program four models: M1 = {a}, M2 = {b, c}, M3 = {a, b, c},
M4 = {a, c}. instance inst(P9 , M1 ) contains single fact

whose answer set M1 . Thus, M1 answer set P9 .
consider M3 , corresponding instance inst(P9 , M3 ) contains rules

b
c b
whose answer set M3 . shows M3 another answer set P9 .
Similarly, one show M2 also answer set P9 .
instance inst(P9 , M4 ) program

c b
{a} answer set. Hence, M4 answer set P9 . Thus, P9
three answer sets, M1 , M2 , M3 . particular, observe M1 M3 .
2
Observe P basic program P unique instance. such, notion
answer sets general programs generalization notion answer sets
basic programs. shown Proposition 2 also holds general programs.
relationship notion answer set general programs definition given
Marek Remmel (2004) extensions logic programming discussed
next section.
372

fiLogic Programs Arbitrary Abstract Constraint Atoms

6. Related Work Discussion
section, relate work recently proposed extensions logic programming, discuss possible method computing answer sets programs c-atoms
using available answer set solvers.
6.1 Related Work
concept logic programs c-atoms, used paper, originally introduced Marek Remmel (2004) Marek Truszczynski (2004)in particular,
programs c-atoms named SC-programs Marek Remmel (2004).9
Example 7 shows semantical characterization differs approach adopted
Marek Remmel (2004). particular, approach guarantees answer sets
basic programs minimal, case approach described Marek
Remmel (2004). Consider another example:
Example 19 Consider program P10

c
({a, c, d}, {{a}, {a, c, d}})
According characterization, program one answer set, M1 = {a, c}.
consider approach described Marek Remmel (2004), verify
M2 = {a, c, d} answer set since NSS-reduct P10 respect M2

c
({a, c, d}, {{a}, {a, c}, {a, d}, {a, c, d}})
least fixpoint one-step provability operator {a, c, d}.

2

type examples, seems hard justify presence answer set
original program. suspect replacement c-atom closure, used
NSS-reduct, might reason acceptance unintuitive answer sets Marek
Remmel (2004). following proposition states approach skeptical
approach Marek Remmel (2004).
Proposition 7 Let P positive program. set atoms answer set P
w.r.t. Definition 11 answer set P w.r.t. Marek Remmel (2004).
syntax logic programs c-atoms, used paper, also used Liu
Truszczynski (2005b) Liu Truszczynski (2005a). One main differences
work work Marek Truszczynski (2004) consider
arbitrary c-atoms, proposal Marek Truszczynski (2004) focuses monotone
9. Although naf-atoms allowed definition SC-programs, authors suggest naf-atoms
replaced complement.

373

fiSon, Pontelli, & Tu

(and convex) c-atoms. framework introduced paper easily extended
disjunctive logic programs considered Pelov Truszczynski (2004).
immediate consequence operator TP proposed paper different
nondeterministic one-step provability operator, TPnd , adopted Marek Truszczynski
(2004), TP deterministic applied basic positive programs. Marek
Truszczynski (2004) Liu Truszczynski (2005b), researchers investigate
several properties normal logic programs (e.g., strong equivalence) hold semantics programs monotone c-atoms Marek Truszczynski (2004).
directly studied properties context semantical characterization; nevertheless, see later, Proposition 8 implies results proved Liu
Truszczynski (2005b) immediately applicable semantic characterization
class monotone programs. do, however, focus use well-supported models
level mapping studying answer sets programs c-atoms, approach
used programs c-atoms.
next present result shows approach define answer sets
monotone programs coincides Marek Truszczynski (2004).
Proposition 8 Let P monotone program. set atoms answer set P
w.r.t. Definition 11 iff stable model P w.r.t. Marek Truszczynski (2004).
discussed earlier, c-atoms used represent several extensions logic programs,
among weight constraints aggregates. Intuitively, aggregate atom (see, e.g.,
Elkabani et al., 2004; Faber et al., 2004) encoded c-atom (D, C),
consists atoms occurring set expression C 2D every
X C satisfies (see Examples 3-4). indicated Marek Truszczynski (2004),
many previous proposals dealing aggregates allow aggregates occur
head rules. Here, instead, consider programs c-atoms head.
regards naf-atoms, proposals (see, e.g., Elkabani et al., 2004) allow
aggregates occur naf-atoms. proposal Faber et al. (2004) treats naf-atoms
complement, although reduction used defining semantics, Ferraris (2005)
argues that, different logics, naf-atoms might require different treatments.
present propositions relate work recent works
aggregates. prove10 :
Proposition 9 program monotone aggregates P , answer set P iff
answer set P w.r.t. Faber et al. (2004) Ferraris (2005).
proposal presented Pelov (2004) Denecker et al. (2001) deals aggregates
using approximation theory three-valued logic, building semantics threevalued immediate consequence operator aggr
, maps three-valued interpretations
P
three-valued interpretations program. operator viewed operator
maps pairs set atoms (R, S) R pairs set atoms (R0 , 0 )
R0 0 . authors show ultimate approximate aggregates provide
precise semantics logic programs aggregates. Let us denote 1 (R, S)
2 (R, S)) two components aggr
(R, S), i.e., aggr
(R, ) = (1 (R, ), 2 (R, )).
P
P
aggr
next proposition relates TP P .
10. Abusing notation, use single symbol denote program different notations.

374

fiLogic Programs Arbitrary Abstract Constraint Atoms

Proposition 10 Let P positive program aggregates R two set
atoms R . Then, TP (R, ) = 1 (R, ).
proposition, together fact evaluation truth value
aggregate formulas Denecker et al. (2001) treats naf-atoms complement, allows us
conclude that, program aggregates P , answer sets complement P (w.r.t.
Definition 4) ultimate stable models P (Denecker et al., 2001) vice versa.
result, together results Son Pontelli (2007), allows us conclude TP
generalization immediate consequence operator aggregates programs Son
Pontelli (2007).
conclude discussion related work, would like point
Propositions 7-10 show different approaches dealing aggregates differ
non-monotone programs. main difference approach others lies
skepticism TP operator, caused notion conditional satisfaction.
illustrate issue next two examples.
Example 20 Consider program P2 Example 4. program
answer set w.r.t. Definition 4 = {p(1), p(1), p(2)} answer set according
Marek Remmel (2004). reason unacceptability answer set
approach lies truth value aggregate atom Sum({X | p(X)}) could
either true false even p(1) known true. prevents third rule
applicable hence second rule well. makes p(1) fixpoint TP2
operator, given considered answer set. words, cannot regenerate
given programand skepticism TP2 main reason. observe
approaches (see, e.g., Faber et al., 2004; Ferraris, 2005) accept answer set
P2 well.
2
following example shows difference approach Faber et al.
(2004) well Ferraris (2005).
Example 21 Consider program P
p(1)
({p(1), p(1)}, {, {p(1), p(1)}})
p(1)
p(1)
p(1) p(1)
Intuitively, abstract atom = ({p(1), p(1)}, {, {p(1), p(1)}}) represents aggregate atom Sum({X | p(X)}) 0. program two models M1 = {p(1), p(1)}
M2 = . approaches Marek Remmel (2004), Faber et al. (2004), Ferraris
(2005) accept M1 answer set, approach Pelov (2004), Denecker
et al. (2001) admit answer sets. approach, TP (, M1 ) =
conditionally satisfy w.r.t M1 since true every possible extension
leads M1 , namely true {p(1)}. words, skepticism
approach main reason difference approach
approaches Faber et al. (2004) Ferraris (2005).
2
375

fiSon, Pontelli, & Tu

6.2 Discussion
section, briefly discuss possible method computing answer sets programs
c-atoms, using off-the-shelf answer set solvers. method makes use transformation similar unfolding transformation proposed Elkabani et al. (2004) dealing
aggregates, studied implemented Elkabani et al. (2005).
begin discussion basic positive programs. Given basic positive program
P c-atom A, Ac 6= , unfolding expression form
p1 , . . . , pn , q1 , . . . , qm
{p1 , . . . , pn } Ac {q1 , . . . , qm } = Ad \ {p1 , . . . , pn }. Ac = , , denoting
false, unique unfolding A. Observe = ({a}, {{a}}) unfolding
a. unfolding rule
A0 A1 , . . . , Ak
rule obtained replacing Ai one unfoldings. unf olding(r) denotes

set unfoldings rule r. Let unf olding(P ) = rP unf olding(r). Clearly,
unf olding(P ) normal logic program P basic positive program. show
answer set P iff answer set unf olding(P ). indicates
compute answer sets basic positive programs c-atoms (i) computing unfolding;
(ii) using available answer set solvers compute answer sets unfolded
program. Following approach, main additional cost computing answer sets
basic positive program cost incurred unfolding process. Theoretically,
costly rule r, |unf olding(r)| = Abody(r) |Ac |,
|.| denotes cardinality set. means size program unf olding(P )
might exponential size original program P . Thus, additional cost
might significant. practice, expect number manageable,
rule might contain c-atoms whose set solutions reasonably small.
Furthermore, certain techniques employed reduce size unfolding program
(Son, Pontelli, & Elkabani, 2006).
method easily extended deal naf-atoms general programs.
answer sets complement need computed, need (i) compute complement
program; (ii) use procedure compute answer sets complement.
hand, answer sets reduct need computed, hand
tentative answer set . reduction program respect computed,
unfolding applied verify whether answer set reduct.
Observe complement reduct program easily computed,
increase size program. such, main cost computing answer sets
general programs following approach still cost unfolding. far,
study programs aggregates (a special type c-atoms), encounter
unmanageable situations (Son, Pontelli, & Elkabani, 2006).
Observe specification c-atom requires enumeration domain
solutions, whose size exponential size set atoms program.
mean explicit representation c-atoms needs used.
cases, c-atoms replaced aggregate literals. this, several complexity
376

fiLogic Programs Arbitrary Abstract Constraint Atoms

results programs aggregates (see, e.g., Pelov, 2004; Son & Pontelli, 2007)
extended logic programs c-atoms. example, easily show problem
determining whether logic program answer set least NPco-NP .
However, programs c-atoms representable standard aggregate functions, except
form Sum(.) 6= value Avg(.) 6= value, problem determining whether
program answer set remains NP-complete.

7. Conclusions Future Work
paper, explored general logic programming framework based use arbitrary constraint atoms. proposed approach provides characterization
line existing semantics logic programming aggregates characterization proposed Marek Remmel (2004). provided two alternative characterizations
answer set semantics programs arbitrary constraint atoms, first based
fixpoint operator, generalizes immediate consequence operator traditional
logic programs, second built generalization notion well-supported
models Fages (1994).
Within characterization answer set, investigated two methodologies treating naf-atoms identified class naf-monotone programs, two
approaches dealing naf-atoms coincide. also proved newly proposed
semantics coincides semantics proposed Marek Truszczynski (2004)
monotone programs. Finally, related work proposals logic programs
aggregates discussed possible method computing answer sets programs
abstract constraint atoms using available answer set solvers.
proposal unexplored aspects. proposed approach rather skeptical
identification answer setswhile approach Marek Remmel (2004)
overly credulous. believe two approaches represent two extremes
continuum needs explored. particular, believe possible identify
intermediate approaches simply modifying notion conditional satisfaction. Work
progress explore alternatives.
Acknowledgment
authors wish thank anonymous reviewers insightful comments.
research partially supported NSF grants HRD-0420407, CNS-0454066,
CNS-0220590. extended abstract paper appeared Proceedings
Twenty-First National Conference Artificial Intelligence, 2006.

Appendix
First, show lemmas used proofs propositions.
Lemma 1 Let U 0 sets atoms abstract constraint atom.
Then, |=M implies U |=M 0 A.
377

fiSon, Pontelli, & Tu

Proof. |=M implies
{I | Ad , Ad Ad } Ac .
Together fact U 0 ,
{I | Ad , U Ad 0 Ad } Ac .
implies U |=M 0 A.

2

Lemma 2 two sets atoms 0 monotone c-atom A, 0 |= (resp.
0 |= A) |= (resp. |= A) 0 |=M (resp. 0 |=M A). (Recall
denotes complement A.)
Proof.
1. Let us assume 0 |= |= A. monotonicity A,
conclude that, every S, 0 , |= A. result,
0 |=M A.
2. Let us assume 0 |= |= A. Let us assume, contradiction,
0 6|=M A. Since already know 0 |= A, implies exists
Ad , 0 Ad Ad , 6 2Ad \ Ac , i.e., Ac . Since
monotone , |= A. contradiction, since
initially assumed |= A.
2
Proposition 1. Let model P , let U .
TP (S, ) TP (U, ) M.
Proof.
1. Lemma 1, assumption U , definition TP ,
TP (S, ) TP (U, ).
2. Let us show TP (U, ) . Consider atom TP (U, ). need
show . definition TP operator, rule r
head(r) = ({a}, {{a}}) U |=M pos(r). observe that, pos(r),
U |=M |= (Definition 3). Thus, conclude
|= pos(r). Since program positive known model P ,
must |= head(r), thus .
2
Corollary 2 Let P positive basic program answer set P . Then,
minimal model P .
Proof. model P since answer set P (Definition 4). Thus, need
prove indeed minimal model P . Suppose exists 0
378

fiLogic Programs Arbitrary Abstract Constraint Atoms

0 model P . Proposition 1 Lemma 1 imply k (, ) k (, 0 ) 0
every k. Since answer set, 0 . contradicts assumption
0 .
2
Proposition 2. Let P basic program. answer set complement P
answer set reduct P . Furthermore, P naf-monotone, answer set
reduct P also answer set complement P .
Proof. Let us start showing answer sets complement also answer sets
reduct. Let model let us denote P1 = C(P ) let P2 = P . Using
fact |=M 6|= easily prove induction following result
holds:
TP1 (, ) TP2 (, )
(2)
P naf-monotone program
TPi 1 (, ) = TPi 2 (, )

(3)

answer set complement = TP1 (, ). Furthermore,
TP2 (, ) (Proposition 1). implies answer set P reduct
well.
P naf-monotone, using Equation (3) fact answer set P2
conclude answer set complement P .
2
Proposition 3. normal logic program P , answer set (by complement
reduct) c-atom(P ) iff answer set P (w.r.t. Definition Gelfond Lifschitz
(1988)).
Proof. convenience, proof, refer answer sets defined Gelfond
Lifschitz (1988) GL-answer sets. monotonicity c-atom(P )
Proposition 2, suffices show answer set P iff answer set
reduct c-atom(P ).
Let us consider case P positive program. follows Observation 1
fact |=M ({a}, {{a}}) iff operator TP (., .) P (defined
Observation 1) coincides operator TP (., .) c-atom(P ). Hence, answer
set c-atom(P ) iff GL-answer set P .
suppose P arbitrary normal logic program. Let GL(P, )
Gelfond-Lifschitzs reduct P w.r.t. . Since |= ({a}, {{a}}) iff ,
c-atom(P )M = c-atom(GL(P, )). Using result positive program,
GL-answer set P iff answer set reduct c-atom(P ).
2
Proposition 4.
1. Every answer set complement basic program P minimal model P .
2. Every answer set reduct basic, naf-monotone program P minimal model
P .
3. Every answer set (by complement/reduct) basic program P supports
members.
379

fiSon, Pontelli, & Tu

Proof.
1. Notice set atoms abstract constraint atom A, |= iff
|= A. implies model P iff model C(P ).
Corollary 2, conclude answer set complement
P , minimal model P .
2. Let us assume P naf-monotone basic program, let answer set
reduct P . Proposition 2, also answer set P complement.
previous result implies minimal model P .
3. follows Proposition 2 enough prove conclusion answer sets
reduct P . Let answer set reduct P . definition,
= TPM (, ). implies that, , exists
TPi (, ). turn, allows us identify rule
({a}, {{a}}) A1 , . . . , Ak , Ak+1 , . . . ,
6|= Aj k + 1 j n TPi (, ) |=M Ai 1 k.
particular, |= Ai 1 k. easily conclude given rule
supports a.
2
Proof Proposition 5
Let us start proving following lemma:
Lemma 3 Let P positive, basic program, let weakly well-supported model
P . Let l mapping satisfies desired properties weakly well-supportedness
l(a)+1
. every atom a, implies TP
(, ).
Proof. First, observe that, atom ,
L(({a}, {{a}}), ) = l(a).
Let us prove lemma induction l(a).
1. Base Case: Consider l(a) = 0. Clearly, P must contain
rule
({a}, {{a}})
hence, TP1 (, ).
2. Inductive Step: Assume result holds every atom b 0 l(b) < k.
Consider atom l(a) = k. show TPk+1 (, ).
Since weakly well-supported model P , exists rule
({a}, {{a}}) A1 , . . . ,
380

fiLogic Programs Arbitrary Abstract Constraint Atoms

P L(Ai , ) defined l(a) > L(Ai , ) every 1 n.
Let = TPk (, ). {1, . . . , n}, since L(Ai , ) defined, X ,
X (Ai )c X |=M Ai L(Ai , ) = H(X). Hence, k = l(a) >
L(Ai , ) = H(X). inductive hypothesis, since X , conclude
X S. hand, already proved (Corollary 1)
TP0 (, ) . . . TPk (, ) = . . . M.
result, X .
Lemma 1, since X |=M Ai , implies |=M Ai . Accordingly,
TPk+1 (, ).
2
proceed proof proposition.
Proposition 5. set atoms answer set reduct basic program P iff
weakly well-supported model P .
Proof. prove proposition two steps. first prove result holds
positive programs extend case arbitrary basic programs.
P positive program.
1. : Suppose answer set P . Corollary 2 implies model
P . Thus, suffices find level mapping satisfies l condition Definition
9. atom a, let
(

l(a) =

min{k | TPk (, )}
0
otherwise

Clearly, l well defined. show l indeed mapping satisfying
properties Definition 9.
Let us consider atom let k = l(a). Clearly, k > 0 since TP0 (, ) =
. So, TPk (, ) 6 = TPk1 (, ) . two
cases:
(a) P contains rule
({a}, {{a}})
case, condition l atom trivially satisfied.
(b) P contains rule r form
({a}, {{a}}) A1 , . . . ,
|=M Ai 1 n.
Consider integer 1 n. Let X = (Ai )d . definition
conditional satisfaction, X (Ai )c . easy check
X |=M Ai . addition, X . result, L(Ai , ) defined.
Furthermore, L(Ai , ) H(X) H(S) < k = l(a). shows
condition l also satisfied case.
381

fiSon, Pontelli, & Tu

two cases allow us conclude l satisfies condition Definition 9, i.e., weakly well-supported model P .
2. : Suppose weakly well-supported model P . Due Lemma 3,
TP (, ). hand, Corollary 1,
TP (, ) . Consequently, = TP (, ), implies
answer set P .
P arbitrary basic program. easy see set atoms
weakly well-supported model P iff weakly well-supported model P .
previous result, means answer set reduct P iff
weakly well-supported model P .
2
Proposition 7. Let P positive program. set atoms answer set P
w.r.t. Definition 11 answer set P w.r.t. Marek Remmel (2004).
Proof.
Consider case P basic program. Since N SS(P, ) monotone positive programs, least fixpoint one-step provability operator TN SS(P,M ) (.)
coincides least fixpoint extended immediate consequence operator
TN SS(P,M ) (., .) (see also Proposition 8). Furthermore, easily verify
TP (, ) = TNSS(P,M ) (, ) holds answer set w.r.t. Definition 11.
two observations imply conclusion proposition.
consider case P general positive program. Without loss generality, assume P contain constraints. Let Q = inst(P, ).
rule r0 Q exists rule r P
|= head(r), r0 = body(r), head(r)d . implies
N SS(P, ) = N SS(Q, ). Since answer set Q (w.r.t. Definition 11),
conclude also answer set Q w.r.t. Marek Remmel (2004) (the
basic case) implies also answer set P w.r.t. Marek Remmel
(2004)
2
Proposition 8. Let P monotone program. set atoms answer set P
w.r.t. Definition 11 iff stable model P w.r.t. Marek Truszczynski (2004).
Proof. Let us start showing validity result positive programs. Let us
assume P positive program. Without loss generality, assume P
contain constraints.
1. : Let answer set P . Definition 11, model
P answer set Q = inst(P, ).
every non-negative integer i, let
Mi = TQi (, )
382

fiLogic Programs Arbitrary Abstract Constraint Atoms

answer set Q, definition,
= TQ (, )
show stable model P w.r.t. Marek Truszczynski (2004),
need prove sequence hMi
i=0 P computation.
proving (i) Mi Mi+1 (ii) every r P (Mi ) 11 , Mi+1 |= head(r),
(iii) Mi+1 hset(P (Mi )).
(i) Follows Corollary 1.
(ii) Consider rule r P (Mi ). definition P (Mi ), Mi |=
body(r). P monotone Mi , follows |= body(r)
Mi |=M body(r).
Let X = head(r)d . definition inst(r, ),
inst(r, ) = {b body(r) | b X} Q
Mi |=M body(r), every r0 inst(r, ), Mi |=M body(r0 ). definition
Mi+1 , follows head(r0 ) Mi+1 . Hence, X Mi+1 . Since X head(r)d ,
implies
X Mi+1 head(r)d
hand, Mi+1 ,
Mi+1 head(r)d X
Accordingly,
head(r)d = X = Mi+1 head(r)d

(4)

hand, model P |= body(r),
|= head(r). Therefore,
head(r)d head(r)c

(5)

(4) (5), Mi+1 head(r)d head(r)c , i.e., Mi+1 |= head(r).
(iii) Let atom Mi+1 . definition Mi+1 easy see Q
must contain rule r0 whose head whose body satisfied Mi .
implies P (Mi ) must contain rule r head(r)d . follows
head(r)d hset(P (Mi )). Accordingly, Mi+1 hset(P (Mi )).
2. : Let stable model P according Marek Truszczynski (2004)
let hXi
i=0 canonical computation , i.e.,
X0 =
11. Recall P (Mi ) set rules P whose body satisfied Mi .

383

fiSon, Pontelli, & Tu

Xi+1 =

[

head(r)d

rP (Xi )

According Theorem 5 Marek Truszczynski (2004),
M=

[

Xi



Let Q = inst(P, ). stable model P , also model P . So,
prove answer set P , need show answer set
Q.
Let us construct sequence sets atoms hMi
follows
M0 =
Mi+1 = TQ (, Mi )
Clearly, prove answer set Q, suffices show
Xi = Mi

(6)

Let us prove induction.
(a) = 0: trivial X0 = M0 = .
(b) Suppose (6) true = k, show true = k + 1.
Consider atom Xk+1 . definition Xk+1 , exists rule r P
head(r)d Xk |= body(r). Since Xk P monotone,
follows |= body(r). stable model P also model P ,
|= head(r). result, Q contains following set rules:
inst(r, ) = {b body(r) | b head(r)d }
head(r)d Xk+1 , head(r)d .
result, following rule belongs inst(r, )
body(r)
Mk = Xk (inductive hypothesis), Mk |= body(r) thus
Mk |=M body(r) (recall Mk = Xk body(r) consists monotone
abstract constraint atoms only). definition Mk+1 , Mk+1 .
shown every atom Xk+1 , belongs Mk+1 . Hence,
Xk+1 Mk+1

(7)

Now, show Mk+1 Xk+1 . Consider atom b Mk+1 .
definition Mk+1 , exists rule r0 Q head(r)d = b Mk |=M
body(r0 ). definition Q means exists rule r P
|= head(r)d , body(r) = body(r0 ) b head(r)d . Xk = Mk
384

fiLogic Programs Arbitrary Abstract Constraint Atoms

(inductive hypothesis), Mk |=M body(r0 ) = body(r), Xk |= body(r).
implies r P (Xk ). Hence,
b head(r)d Xk+1
Therefore
Mk+1 Xk+1

(8)

(7) (8), Xk+1 = Mk+1 .
result easily extended programs negation-as-failure c-atoms.
omit proof here.
2
Proof Proposition 9.
prove proposition, brief review approach Faber et al. (2004) needed.
notion answer set proposed Faber et al. (2004) based new notion reduct,
defined follows. Given program P set atoms S, reduct P respect
S, denoted P , obtained removing P rules whose body satisfied
S. words,
F LP (P, ) = {r | r ground(P ), |= body(r)}.
novelty reduct remove aggregate atoms negation-as-failure
literals satisfied S. program P , FLP-answer set P iff minimal
model F LP (P, S). continue proof proposition. easy
see enough consider programs without negation-as-failure c-atoms.
Proposition 9. program monotone aggregates P , answer set P iff
answer set P w.r.t. Faber et al. (2004) Ferraris (2005).
Proof. Due equivalent result Ferraris (2005), suffices prove equivalence
approach Faber et al. (2004). Notice paper
dealing ground programs therefore
1. : Let FLP-answer set P . show answer set P
(w.r.t. Definition 4).
Let Q = F LP (P, ). definition FLP-answer set, minimal model
Q. Let 0 = TP (, ). model Q, also model P . Corollary
1 implies 0 .
Consider r Q 0 |= body(r) head(r) = ({a}, {{a}}).
definition Q monotonicity P , |= body(r). follows
Lemma 2 0 |=M body(r). Hence, 0 (by definition operator TP ).
implies 0 model Q.
minimality 0 , 0 = . Hence,
answer set P .
385

fiSon, Pontelli, & Tu

2. : Let answer set P . prove FLP-answer set P
showing minimal model Q = F LP (P, ).
Let 0 model Q. First, demonstrate 0 model P .
Suppose otherwise, i.e., 0 model P . implies P contains rule
r head(r) = ({a}, {{a}}) atom a, 0 |= pos(r),
6 0 . Due monotonicity P |= pos(r). Hence,
Q contains rule r. result, 0 |= body(r). Thus, 0 0
model Q. contradiction.
shown 0 model P . hand, Corollary 2,
minimal model P . Therefore, 0 . Accordingly, 0 = .
Thus, minimal model Q, i.e., FLP-answer set P .
2
Proof Proposition 10. Let P positive program aggregates R
two set atoms R . Then, TP (R, ) = 1 (R, ) aggr (R, ) =
(1 (R, ), 2 (R, )).
Proof. order prove result, make use intermediate step. Son
Pontelli (2007), following concepts program aggregates introduced:
Given aggregate A, solution pair hS + , i, satisfying following
properties:
+ A,
+ = ,
+ = , |= A.
Given two interpretations I, , aggregate conditionally satisfied w.r.t. I,
(denoted (I, ) |= A) hI Ad , Ad \ solution A. simplicity,
define also conditional satisfaction atoms, saying conditionally satisfied
w.r.t. I, I.
Given positive program aggregates P interpretation , aggreP : 2A 2A defined as:12 K P (I) = {head(r)|r
gate consequence operator KM

P, (I, ) |= body(r)}.
wish show that, positive program aggregates P interpretations
P (I) = (I, ). allow us conclude result proposition 10, since
I, , KM
P
P (I) = 1 (I, ) (Son & Pontelli, 2007).
proved KM
Observe that, condition :
standard atom, |=M iff iff (I, ) |= a.
Let aggregate.
Let us assume |=M A. means |= and, J Ad s.t.
Ad J Ad , J |= A.
12. original definition Son Pontelli (2007) allows use negative atoms body
rules, omit sake simplicity.

386

fiLogic Programs Arbitrary Abstract Constraint Atoms

consider J Ad s.t. Ad J J (Ad \ ) = ,
Ad = Ad J, J Ad (otherwise, J 6 Ad ,
Ad \ , would violate condition J (Ad \ ) = ).
initial assumption |=M A, conclude J Ac . allows
us conclude |=M implies (I, ) |= A.
Let us assume (I, ) |= A. means that, J Ad s.t. Ad J
J (Ad \ ) = , J Ac .
First all, note Ad = Ad , thus Ad Ac i.e., |= A. Let us
take arbitrary J Ad , Ad J Ad . Since Ad J,
particular Ad J. Furthermore, J (Ad \ ) = , since J Ad .
Thus, initial assumption, J |= Ac . allows us conclude
(I, ) |= implies |=M A.
results allows us conclude element body rule P (either
atom aggregate), (I, ) |= iff |=M . allows us immediately conclude
P (I) = (I, ).
KM
2
P

References
Banti, F., Alferes, J. J., Brogi, A., & Hitzler, P. (2005). well supported semantics
multidimensional dynamic logic programs.. Baral, C., Greco, G., Leone, N., &
Terracina, G. (Eds.), Logic Programming Nonmonotonic Reasoning, 8th International Conference, LPNMR 2005, Diamante, Italy, September 5-8, 2005, Proceedings,
Vol. 3662 Lecture Notes Computer Science, pp. 356368. Springer.
Baral, C. (2003). Knowledge Representation, reasoning, declarative problem solving
Answer sets. Cambridge University Press, Cambridge, MA.
Baral, C. (2005). Knowledge Intelligence Building Blocks Applications..
Invited Talk, AAAI, www.public.asu.edu/~cbaral/aaai05-invited-talk.ppt.
DellArmi, T., Faber, W., Ielpa, G., Leone, N., & Pfeifer, G. (2003). Aggregate Functions
Disjunctive Logic Programming: Semantics,Complexity,and Implementation DLV.
Proceedings 18th International Joint Conference Artificial Intelligence
(IJCAI) 2003, pp. 847852.
Denecker, M., Pelov, N., & Bruynooghe, M. (2001). Ultimate well-founded stable semantics logic programs aggregates.. Codognet, P. (Ed.), Logic Programming,
17th International Conference, ICLP 2001, Paphos, Cyprus, November 26 - December
1, 2001, Proceedings, Vol. 2237 Lecture Notes Computer Science, pp. 212226.
Springer.
Eiter, T., Leone, N., Mateis, C., Pfeifer, G., & Scarcello, F. (1998). KR System dlv:
Progress Report, Comparisons, Benchmarks. International Conference
Principles Knowledge Representation Reasoning, pp. 406417.
Elkabani, I., Pontelli, E., & Son, T. C. (2004). Smodels CLP applications:
simple effective approach aggregates asp.. Demoen, B., & Lifschitz, V.
(Eds.), Logic Programming, 20th International Conference, ICLP 2004, Saint-Malo,
387

fiSon, Pontelli, & Tu

France, September 6-10, 2004, Proceedings, Vol. 3132 Lecture Notes Computer
Science, pp. 7389. Springer.
Elkabani, I., Pontelli, E., & Son, T. C. (2005). SmodelsA - System Computing Answer Sets Logic Programs Aggregates.. Baral, C., Greco, G., Leone, N., &
Terracina, G. (Eds.), Logic Programming Nonmonotonic Reasoning, 8th International Conference, LPNMR 2005, Diamante, Italy, September 5-8, 2005, Proceedings,
Vol. 3662 Lecture Notes Computer Science, pp. 427431. Springer.
Faber, W., Leone, N., & Pfeifer, G. (2004). Recursive aggregates disjunctive logic programs: Semantics complexity.. Alferes, J. J. , & Leite, J. A. (Eds.), Logics
Artificial Intelligence, 9th European Conference, JELIA 2004, Lisbon, Portugal,
September 27-30, 2004, Proceedings, Vol. 3229 Lecture Notes Computer Science,
pp. 200212. Springer.
Fages, F. (1994). Consistency Clarks completion existence stable models. Methods
Logic Computer Science, pp. 5160.
Ferraris, P. (2005). Answer sets propositional theories.. Baral, C., Greco, G., Leone,
N., & Terracina, G. (Eds.), Logic Programming Nonmonotonic Reasoning, 8th
International Conference, LPNMR 2005, Diamante, Italy, September 5-8, 2005, Proceedings, Vol. 3662 Lecture Notes Computer Science, pp. 119131. Springer.
Gelder, A. V. (1992). well-founded semantics aggregation.. Proceedings
Eleventh ACM SIGACT-SIGMOD-SIGART Symposium Principles Database
Systems, June 2-4, 1992, San Diego, California, pp. 127138. ACM Press.
Gelfond, M., & Leone, N. (2002). Logic programming knowledge representation
A-Prolog perspective. Artificial Intelligence, 138 (1-2), 338.
Gelfond, M., & Lifschitz, V. (1988). stable model semantics logic programming.
Kowalski, R., & Bowen, K. (Eds.), Logic Programming: Proceedings Fifth
International Conf. Symp., pp. 10701080.
Gelfond, M. (2002). Representing Knowledge A-Prolog. Kakas, A., & Sadri, F. (Eds.),
Computational Logic: Logic Programming Beyond, pp. 413451. Springer Verlag.
Hitzler, P., & Wendt, M. (2005). uniform approach logic programming semantics.
Theory Practice Logic Programming, 5 (1-2), 123159.
Kemp, D. B., & Stuckey, P. J. (1991). Semantics logic programs aggregates..
Saraswat, V. , & Ueda, K. (Eds.), Logic Programming, Proceedings 1991
International Symposium, San Diego, California, USA, pp. 387-401. MIT Press.
Liu, L., & Truszczynski, M. (2005a). Pbmodels - software compute stable models
pseudoboolean solvers.. Baral, C., Greco, G., Leone, N., & Terracina, G. (Eds.),
Logic Programming Nonmonotonic Reasoning, 8th International Conference, LPNMR 2005, Diamante, Italy, September 5-8, 2005, Proceedings, Vol. 3662 Lecture
Notes Computer Science, pp. 410415.
Liu, L., & Truszczynski, M. (2005b). Properties programs monotone convex
constraints.. Veloso, M. M., & Kambhampati, S. (Eds.), Proceedings, Twentieth National Conference Artificial Intelligence Seventeenth Innovative
388

fiLogic Programs Arbitrary Abstract Constraint Atoms

Applications Artificial Intelligence Conference, July 9-13, 2005, Pittsburgh, Pennsylvania, USA, pp. 701706. AAAI Press AAAI Press / MIT Press.
Marek, V. W., & Remmel, J. B. (2004). Set constraints logic programming. Logic
Programming Nonmonotonic Reasoning, 7th International Conference, LPNMR
2004, Fort Lauderdale, FL, USA, January 6-8, 2004, Proceedings, Vol. 2923 Lecture
Notes Computer Science, pp. 167179. Springer Verlag.
Marek, V. W., & Truszczynski, M. (1999). Stable Models Alternative Logic Programming Paradigm.. Logic Programming Paradigm, Springer Verlag.
Marek, V. W., & Truszczynski, M. (2004). Logic programs abstract constraint atoms..
Proceedings Nineteenth National Conference Artificial Intelligence, Sixteenth Conference Innovative Applications Artificial Intelligence, July 25-29,
2004, San Jose, California, USA. AAAI Press / MIT Press.
Mumick, I. S., Pirahesh, H., & Ramakrishnan, R. (1990). magic duplicates
aggregates.. McLeod, D., Sacks-Davis, R., & Schek, H.-J. (Eds.), 16th International
Conference Large Data Bases, August 13-16, 1990, Brisbane, Queensland,
Australia, Proceeding, pp. 264277. Morgan Kaufmann.
Niemela, I., (1999). Logic Programs Stable Models Constraint Programming
Paradigm.. Annals Math AI, 25 (34), 241273.
Niemela, I., Simons, P., & Soininen, T. (1999). Stable model semantics weight constraint
rules. Proceedings 5th International Conference Logic Programming
Nonmonotonic Reasoning, pp. 315332.
Pelov, N. (2004). Semantic Logic Programs Aggregates. Ph.D. thesis, Katholieke
Universiteit Leuven. http://www.cs.kuleuven.ac.be/publicaties/doctoraten/
cw/CW2004_02.abs.html.
Pelov, N., & Truszczynski, M. (2004). Semantics disjunctive programs monotone
aggregates operator-based approach.. Delgrande, J. P., & Schaub, T. (Eds.),
10th International Workshop Non-Monotonic Reasoning (NMR 2004), Whistler,
Canada, June 6-8, 2004, Proceedings, pp. 327334.
Simons, P., Niemela, N., & Soininen, T. (2002). Extending Implementing Stable
Model Semantics. Artificial Intelligence, 138 (12), 181234.
Son, T. C., & Pontelli, E. (2007). Constructive Semantic Characterization Aggregates
Answer Set Programming. Theory Practice Logic Programming. 7 (03),
355375.
Son, T. C., Pontelli, E., & Elkabani, I. (2006). Unfolding-Based Semantics Logic
Programming Aggregates. Computing Research Repository. cs.SE/0605038.

389

fiJournal Artificial Intelligence Research 29 (2007) 309-352

Submitted 6/06; published 7/07

Learning Symbolic Models Stochastic Domains
Hanna M. Pasula
Luke S. Zettlemoyer
Leslie Pack Kaelbling

pasula@csail.mit.edu
lsz@csail.mit.edu
lpk@csail.mit.edu

MIT CSAIL
Cambridge, 02139

Abstract
article, work towards goal developing agents learn act
complex worlds. develop probabilistic, relational planning rule representation
compactly models noisy, nondeterministic action effects, show rules
effectively learned. experiments simple planning domains 3D simulated
blocks world realistic physics, demonstrate learning algorithm allows
agents effectively model world dynamics.

1. Introduction
One goals artificial intelligence build systems act complex environments effectively humans do: perform everyday human tasks, like making breakfast
unpacking putting away contents office. Many tasks involve manipulating objects. pile things up, put objects boxes drawers, arrange
shelves. requires understanding world works: depending
objects pile arranged made of, pile sometimes slips falls
over; pulling drawer usually opens it, sometimes drawer sticks; moving box
typically break items inside it.
Building agents perform common tasks challenging problem. work,
approach problem developing rule-based representation agents use
model, learn, effects acting environment. Learning allows agents
adapt new environments without requiring humans hand-craft models, something
humans notoriously bad at, especially numeric parametrization required.
representation use probabilistic relational, includes additional logical
concepts. present supervised learning algorithm uses representation language
build model action effects given set example action executions. optimizing
tradeoff maximizing likelihood examples minimizing complexity
current hypothesis, algorithm effectively selects relational model structure,
set model parameters, language new relational concepts together provide
compact, yet highly accurate description action effects.
agent hopes act real world must integrated system perceives
environment, understands, commands motors effect changes it. Unfortunately,
current state art reasoning, planning, learning, perception, locomotion,
manipulation far removed human-level abilities, cannot yet contemplate
c
2007
AI Access Foundation. rights reserved.

fiPasula, Zettlemoyer, & Pack Kaelbling

Figure 1: three-dimensional blocks world simulation. world consists table, several cubes
roughly uniform density varying size, robotic gripper moved
simulated motors.

working actual domain interest. Instead, choose work domains
almost ridiculously simplified proxies.1
One popular proxy, used since beginning work AI planning (Fikes &
Nilsson, 1971) world stacking blocks. typically formalized version
logic, using predicates on(a, b) clear (a) describe relationships blocks
one another. Blocks always neatly stacked; dont fall jumbles.
article, present work context slightly less ridiculous version blocks
world, one constructed using three-dimensional rigid-body dynamics simulator (ODE,
2004). example world configuration shown Figure 1. simulated blocks
world, blocks vary size colour; piles always tidy, may sometimes fall
over; gripper works medium-sized blocks, unreliable even there.
approach capable enabling effective behavior domain must handle noisy,
nondeterministic nature, nontrivial dynamics, able handle
domains similar characteristics.
One strategy formulating approach learn models worlds dynamics
use planning different courses action based goals may change
time. Another strategy assume fixed goal reward function, learn
policy optimizes reward function. worlds complexity imagining,
would impossible establish, advance, appropriate reaction every possible
situation; addition, expect agent overall control architecture
hierarchical, individual level hierarchy changing goals.
reasons, learn model world dynamics, use make plans
achieve goals hand.
begin paper describing assumptions underlie modeling decisions.
describe syntax semantics modeling language give algorithm
1. reasonable alternative approach, advocated Brooks (1991), working real world,
natural complexity, solving problems almost ridiculously simplified proxies
problems interest.

310

fiLearning Symbolic Models Stochastic World Dynamics

learning models language. validate models, introduce simple planning
algorithm provide empirical results demonstrating utility learned models
showing plan them. Finally, survey relevant previous work,
draw conclusions.

2. Structured Stochastic Worlds
agent introduced novel world must find best possible explanation
worlds dynamics within space possible models represent, defined
agents representation language. ideal language would able compactly model
every action effect agent might encounter, others. extra modeling capacity
wasted complicate learning, since agent consider larger space
possible models, likely overfit experience. Choosing good representation
language provides strong bias algorithm learn models language.
languages used describe deterministic planning models are,
least surface, first order; is, abstract particular identities objects, describing effects actions terms properties relations among
objects. (They accomplish letting action take arguments, representing
arguments variables.) representational capacity crucial reasons compactness generalization: usually grossly inefficient describe behavior
individual objects.
Much original work probabilistic planning uses formalism Markov decision processes, represents states world individually atomically (Puterman, 1999). recently, propositional (factored) representations dynamics
employed (Boyen & Koller, 1998; Guestrin, Koller, Parr, & Venkataraman, 2003),
first-order representations developed, including probabilistic rules (Blum & Langford, 1999), equivalence classes (Draper, Hanks, & Weld, 1994), situation calculus
approach Boutilier, Reiter, Price (2001). representations also make easy
articulate take direct advantage two useful assumptions world dynamics:
frame assumption, states that, agent takes action world, anything
explicitly changed stays same, outcome assumption, states
action affects world small number distinct ways, possible effect causes
set changes world happen together single outcome.
take point departure probabilistic first-order representations world
dynamics. representations traditionally applied domains logistics
planning traditional, abstract blocks world, idealized symbolic abstractions
underlying domain. goal learn models realistic worlds, requires
us adapt modeling language accommodate additional uncertainty complexity.
by:
Allowing rules refer objects mentioned argument list action.
Relaxing frame assumption: allowing unmodeled noise changes world.
Extending language: allowing complex forms quantification construction new concepts.
311

fiPasula, Zettlemoyer, & Pack Kaelbling

Action parameterization traditional representations action dynamics, objects
whose properties may changed result action must named argument
list action. Instead, define actions parameters describe
objects free parameters action: example, block picked up,
object currently held block placed. However, actions change
properties objects, ones parameter list, models
way determining objects affected. paper,
introduce use deictic references identify objects. Deictic references (Agre
& Chapman, 1987) identify objects relative agent action performed.
example, refer objects thing block picked up,
currently held object, table block accidentally falls onto. use deictic
references mechanism adding new logical variables models, much
way Benson (1996).
Modeling noise complex domains, actions affect world variety ways.
must learn model circumstances reasonable effects,
also behavior unusual situations. complicates dynamics, makes
learning difficult. Also, actions executed physical world,
guaranteed small number simple effects, result may violate
outcomes assumption. blocks world happen, example, stack
knocked over. develop simple noise mechanism allows us partially model
action effects, ignoring ones rare complicated model explicitly.
Language extension traditional symbolic domains, rules constructed using
predefined set observable predicates. However, sometimes useful define additional
predicates whose truth values computed based predefined ones.
found essential modeling certain advanced planning domains (Edelkamp &
Hoffman, 2004).
traditional blocks worlds, example, usual set predicates contains on, clear
inhand. working realistic, noisy blocks world, found
predicates would sufficient allow agent learn accurate model.
example, would difficult state putting block tall stack likely cause
stack topple without concept stack height, state attempting
pick block clear usually picks block top stack without
way describing block top stack.
could simply add additional predicates seem useful perceptual
language, hand-engineering appropriate language every time tackle new problem
difficult, time consuming, error prone. State-of-the-art planning representations
PDDL (Edelkamp & Hoffman, 2004) use concept language define new predicates
concepts terms previous, simpler ones. paper, show concepts
learned, much like predicates invented ILP (Khan, Muggleton, & Parson, 1998).
see, traditional blocks world predicates, including inhand clear,
well useful concepts height, easily defined terms given simple
concept language (Yoon, Fern, & Givan, 2002).
312

fiLearning Symbolic Models Stochastic World Dynamics

3. State Action Representation
goal learn model state transition dynamics world. so, need
able represent set possible states world set possible
actions agent take. represent components using subset
relatively standard first-order logic equality. representation states actions
ground inference, learning, planning.
begin defining primitive language includes set constants C, set
predicates , set functions . three types functions : traditional
functions, range objects; discrete-valued functions, range predefined
discrete set values; integer-valued functions, range finite subset
integers. primitives observed directly world. (In work,
assume environment completely observable; is, agent able
perceive unambiguous correct description current state.2 ) constants
C assumed intrinsic meaning, viewed meaningless markers
assigned perceptual system, described detail below.
3.1 State Representation
States describe possible different configurations properties relations
objects. state describes particular configuration values
objects world, individual objects denoted using constants.
limit number objects world configuration, though current
formalism mechanism creation deletion objects result
world dynamics.
Formally, state descriptions conjunctive sentences form:
^

^

tG(C,m())

^

()(t)

^

(t) = ,

tG(C,m())

m(x) arity predicate function x, C set c1 . . . cn constants, G(x, a)
set length lists elements x, () indicates predicates may
optionally negated, indicates functions assigned value
range. manner, states list truth values possible groundings
predicates functions terms. sentence gives complete specification,
vocabulary , properties interrelations |C| objects present
world. (Note predicate function arguments always constants, never
terms made using function symbols, descriptions always finite given finite
language.)
rest section, describe two approaches denoting objects using
constants C, illustrate example conjunctive state sentences.
3.1.1 Intrinsic Constants
first approach state descriptions refers objects using intrinsic constants.
intrinsic constant associated particular object consistently used denote
2. strong, ultimately indefensible assumption; one highest priorities future
work extend case environment partially observable.

313

fiPasula, Zettlemoyer, & Pack Kaelbling

object. constants useful perceptual system unique way
identify perceived objects independent attributes relations one another.
example, internet software agent might access universal identifiers
distinguish objects perceives.
example, let us consider representing states simple blocks world, using
language contains predicates on, clear, inhand, inhand-nil, block, table,
integer-valued function height. objects world include blocks BLOCK-A BLOCK-B,
table TABLE, gripper. Blocks blocks table. block
nothing clear. gripper hold one block empty. sentence
inhand-nil on(BLOCK-A, BLOCK-B) on(BLOCK-B, TABLE) on(BLOCK-B, BLOCK-A)
on(BLOCK-A, TABLE) on(TABLE, BLOCK-A) on(TABLE, BLOCK-B) on(TABLE, TABLE)
on(BLOCK-A, BLOCK-A) on(BLOCK-B, BLOCK-B) table(TABLE) table(BLOCK-A)
(1)
table(BLOCK-B) block(BLOCK-A) block(BLOCK-B) block(TABLE) clear(BLOCK-A)
clear(BLOCK-B) clear(TABLE) inhand(BLOCK-A) inhand(BLOCK-B)
inhand(TABLE) height(BLOCK-A) = 2 height(BLOCK-B) = 1 height(TABLE) = 0
represents blocks world gripper holds nothing two blocks single
stack table. Block BLOCK-A top stack, BLOCK-B BLOCK-A
table TABLE.
encoding, sentence contains meaningful information objects
identities, used learning world dynamics.
3.1.2 Skolem Constants
Alternatively, states also denote objects using skolem constants. Skolem constants
arbitrary identifiers associated objects world inherent
meaning beyond used state description.3 constants useful
perceptual system way assigning meaningful identifiers objects
observes. example, consider robot might build state description room
finds in. assume robot observe objects present,
properties, relationships other. However, naming objects,
reason choose particular name specific object. Instead, creates
arbitrary identifiers, skolem constants, uses build state.
Using skolem constants, rewrite Sentence 1 as:
inhand-nil on(c001, c002) on(c002, c004) on(c002, c001)
on(c001, c004) on(c004, c001) on(c004, c002) on(c004, c004)
on(c001, c001) on(c002, c002) table(c004) table(c001)
table(c002) block(c001) block(c002) block(c004) clear(c001)
clear(c002) clear(c004) inhand(c001) inhand(c002)
inhand(c004) height(c001) = 2 height(c002) = 1 height(c004) = 0
Here, perceptual system describes table two blocks using arbitrary
constants c004, c001, c002.
3. Skolem constants interpreted skolemizations existential variables.

314

fiLearning Symbolic Models Stochastic World Dynamics

perspective, states world isomorphic interpretations
logical language, since might many interpretations satisfy particular statespecification sentence; interpretations permutation
objects constants refer to. occurs objects distinguishable based
properties relations objects.
techniques develop paper generally applicable representing
learning dynamics worlds intrinsic constants skolem constants.
highlight cases true presented. also see
use skolem constants perceptually plausible also forces us
create new learning algorithms abstract object identity aggressively previous
work improve quality learned models.
3.2 Action Representation
Actions represented positive literals whose predicates drawn special set, ,
whose terms drawn set constants C associated world
action executed.
example, simulated blocks world, contains pickup/1, action picking
blocks, puton/1, action putting blocks. action literal pickup(BLOCK-A)
could represent action gripper attempts pickup block BLOCK-A
state represented Sentence 1.

4. World Dynamics Representation
learning probabilistic transition dynamics world, viewed
conditional probability distribution Pr(s0 |s, a), s, s0 A. represent
dynamics rules constructed basic logic described Section 3, using
logical variables abstract identities particular objects world.
section, begin describing traditional representation deterministic world
dynamics. Next, present probabilistic case. Finally, extend ways
mentioned Section 2: permitting rules refer objects mentioned
action description, adding noise, extending language allow
construction new concepts.
dynamic rule action z form
x.(x) z(x) 0 (x) ,
meaning that, vector terms x context holds
current time step, taking action z(x) cause formula 0 hold terms
next step. action z(x) must contain every xi x. constrain 0
conjunctions literals constructed primitive predicates terms xi x,
functions applied terms set equal value range. addition,
allowed contain literals constructed integer-valued functions term related
integer range greater-than less-than predicates.
say rule covers state action exists substitution
mapping variables x C (note may fewer variables x constants
315

fiPasula, Zettlemoyer, & Pack Kaelbling

C) |= ((x)) = z((x)). is, substitution constants
variables that, applied context (x), grounds entailed
state and, applied rule action z(x), makes equal action a.
Now, given rule covers a, say subsequent state s0 ?
First, rule directly specifies 0 ((x)) holds next step. may
incomplete specification state; use frame assumption fill rest:
s0 = 0 ((x))

^

^

l(s, , (x))

{{(t):tG(C,m())}pos(0 ((x)))}



^

^

l(s, , (x)) ,

{{(t):tG(C,m())}funct(0 ((x)))}

l(s, y, t) stands literal predicate function argument
list t, pos(0 ) set literals 0 negations ignored, funct(0 ) set
ground functions 0 extracted equality assignments. say
every literal would needed make complete description state
included 0 ((x)) retrieved, associated truth value equality assignment,
s.
general set rules action, require contexts
mutually exclusive, given state-action pair covered one rule;
covered none, assume nothing changes. 4 example, consider
small set rules picking blocks,
pickup(X, Y) : inhand-nil, on(X, Y), block(Y), height(Y) < 10
inhand(X), on(X, Y), clear(Y),
pickup(X, Y) : inhand-nil, on(X, Y), table(Y)
inhand(X), on(X, Y).
top line rule shows action followed context; next line describes
effects, outcome. According two rules, executing pickup(X, Y) changes
world hand empty X Y. exact set changes depends
whether table, block height nine less.
4.1 Probabilistic Rules
deterministic dynamics rules described allow generalization objects
exploitation frame assumption, well suited use highly
stochastic domains. order apply domains extend
describe probability distribution resulting states, Pr(s0 |s, a). Probabilistic STRIPS
operators (Blum & Langford, 1999) model agents actions affect world around
describing actions alter properties relationships objects
world. rule specifies small number simple action outcomessets changes
occur tandem.
4. Without restriction, would need define method choosing possibly conflicting predictions different covering rules. simplest way would involve picking one
rules, perhaps specific one, one confident of. (Rule confidence scores
would estimated.)

316

fiLearning Symbolic Models Stochastic World Dynamics

see probabilistic rules form


p1

01 (x)
x.(x) z(x) . . . . . .

p
0
n n (x)

,

p1 . . . pn positive numbers summing 1, representing probability distribution, 01 . . . 0n formulas describing subsequent state, s0 .
Given state action a, compute coverage deterministic
case. Now, however, given covering substitution (x), probabilistic rules longer predict
unique successor state. Instead, 01 . . . 0n used construct new state,
single 0 deterministic case. n possible subsequent
states, s0i , occur associated probability pi .
probability rule r assigns moving state state s0 action
taken, Pr(s0 |s, a, r), calculated as:

P (s0 |s, a, r) =

X

P (s0 , 0i |s, a, r)

0i r

=

X

P (s0 |0i , s, a, r)P (0i |s, a, r)

(2)

0i r

P (0i |s, a, r) pi , outcome distribution P (s0 |0i , s, a, r) deterministic
distribution assigns mass relevant s0 . P (s0 |0i , s, a, r) = 1.0, is,
s0 state would constructed given rule outcome, say
outcome 0i covers s0 .
general, possible, representation, subsequent state s0 covered
one rules outcomes. case, probability s0 occurring
sum probabilities relevant outcomes. Consider rule painting blocks:

paint(X) : inhand(X), block(X)
(



.8 : painted(X), wet
.2 : change.

rule used model transition caused action paint(a) initial
state contains wet painted(a), one possible successor state: one
change occurs, wet painted(a) remain true. outcomes describe
one successor state, must sum probabilities recover states total
probability.
set rules specifies complete conditional probability distribution Pr(s0 |s, a)
following way: current state action covered exactly one rule,
distribution subsequent states prescribed rule. not, s0 predicted
probability 1.0.
317

fiPasula, Zettlemoyer, & Pack Kaelbling

example, probabilistic set rules picking blocks might look follows:
pickup(X, Y) : inhand-nil, on(X, Y), block(Y), height(Y) < 10
(



.7 : inhand(X), on(X, Y), clear(Y)
.3 : change

pickup(X, Y) : inhand-nil, on(X, Y), table(Y)
(



.8 : inhand(X), on(X, Y)
.2 : change

top line rule still shows action followed context; bracket surrounds
outcomes distribution. outcomes before,
small chance occur.
4.2 Deictic Reference
standard relational representations action dynamics, variable denoting object
whose properties may changed result action must named argument
list action. result awkwardness even deterministic situations. example, abstract action picking block must take two arguments. pickup(X, Y),
X block picked block picked up.
relationship encoded added condition on(X, Y) rules context. condition restrict applicability rule; exists guarantee bound
appropriate object. restriction adopted means that, given
grounding action, variables rule bound, necessary
search substitutions would allow rule cover state. However, complicate planning because, many cases, ground instances operator considered,
even though eventually rejected due violations preconditions.
example, would reject instances violating on(X, Y) relation context.
complex domains, requirement even awkward: depending
circumstances, taking action may affect different, varied sets objects. blocks worlds
block may several others, pickup action may affect properties
blocks. model without additional mechanism referring objects,
might increase, even vary, number arguments pickup takes.
handle gracefully, extend rule formalism include deictic references
objects. rule may augmented list, D, deictic references. deictic
reference consists variable Vi restriction set literals define
Vi respect variables x action Vj j < i.
restrictions supposed pick single, unique object: notif pick
several, nonethe rule fails apply. So, handle pickup action described above,
action would single argument, pickup(X), rule would contain deictic
variable V constraint on(X, V).
use rules deictic references, must extend procedure computing rule
coverage ensure deictic references resolved. deictic variables
may bound simply starting bindings x working sequentially
deictic variables, using restrictions determine unique bindings. point
318

fiLearning Symbolic Models Stochastic World Dynamics

binding deictic variable unique, fails refer, rule fails cover
stateaction pair.
formulation means extra variables need included action specification, reduces number operator instances, yet, requirement
unique designation, substitution still quickly discovered testing coverage.
So, example, denote red block table V2 (assuming
one table one block) would use following deictic references:
V1 : table(V1 )
V2 : color (V2 ) = red block (V2 ) on(V2 , V1 ) .
several, no, tables world, then, rule semantics, first
reference would fail: similarly, second reference would fail number red blocks
unique table represented V1 one.
give action-oriented example, denoting block top block
touched, touch(Z) action, would use following deictic reference:
V1 : on(V1 , Z) block (V1 ) .
set deictic probabilistic rules picking blocks might look follows:
pickup(X) :

n

: inhand(Y), Z : table(Z)



empty context
(



.9 : inhand-nil, inhand(Y), on(Y, Z)
.1 : change

pickup(X) :

n

: block(Y), on(X, Y)



inhand-nil, height(Y) < 10
(



.7 : inhand(X), on(X, Y), clear(Y)
.3 : change

pickup(X) :

n

: table(Y), on(X, Y)



inhand-nil
(
.8 : inhand(X), on(X, Y)

.2 : change
top line rule shows action followed deictic variables,
variable annotated restriction. next line context, outcomes
distribution follow. first rule applies situations something
gripper, states probability 0.9 action cause gripped
object fall table, nothing change otherwise. second rule applies
situations object picked another block, states
probability success 0.7. third rule applies situations object
picked table describes slightly higher success probability, 0.8. Note
different objects affected, depending state world.
319

fiPasula, Zettlemoyer, & Pack Kaelbling

4.3 Adding Noise
Probability models type seen thus far, ones small set possible
outcomes, sufficiently flexible handle noise real world. may
large number possible outcomes highly unlikely, reasonably hard model:
example, configurations may result tall stack blocks topples.
would inappropriate model outcomes impossible, dont space
inclination model individual outcome.
So, allow rule representation account results noise. definition, noise able represent outcomes whose probability havent quantified.
Thus, allowing noise, lose precision true probability distribution
next states.
handle noise, must change rules two ways. First, rule
additional noise outcome 0noise , associated probability P (0noise |s, a, r); now,
set outcome probabilities must sum 1.0 include P (0noise |s, a, r) well
P (01 |s, a, r) . . . P (0n |s, a, r). However, 0noise associated list literals,
since declining model detail happens world cases.
Second, create additional default rule, empty context two outcomes: empty outcome (which, combination frame assumption, models
situations nothing changes), and, again, noise outcome (modeling situations). rule allows noise occur situations specific rule applies;
probability assigned noise outcome default rule specifies kind background
noise level.
Since explicitly modeling effects noise, longer calculate
transition probability Pr(s0 |s, a, r) using Equation 2: lack required distribution
P (s0 |0i , s, a, r) noise outcome. Instead, substitute worst case constant bound
pmin P (s0 |0noise , s, a, r). allows us bound transition probability
P (s0 |s, a, r) = pmin P (0noise |s, a, r) +

X

P (s0 |0i , s, a, r)P (0i |s, a, r)

0i r

P (s0 |s, a, r).

(3)

Intuitively, pmin assigns small amount probability mass every possible next state
Note take value higher true minimum: approximation.
However, ensure probability model remains well-defined, pmin times number
possible states exceed 1.0.
way, create partial model allows us ignore unlikely overly complex
state transitions still learning acting effectively. 5
Since rules include noise deictic references, call Noisy Deictic Rules
(NDRs). rather stochastic world, set NDRs picking blocks might
s0 .

5. P (s0 |0noise , s, a, r) could modeled using well-defined probability distribution describing noise
world, would give us full distribution next states. premise
might difficult specify distributionin domain, would ensure
distribution assign probability worlds impossible, worlds blocks
floating midair. long events unlikely enough would want consider
planning, reasonable model directly.

320

fiLearning Symbolic Models Stochastic World Dynamics

look follows:
pickup(X) :

n

: inhand(Y), Z : table(Z)



empty context


.6 : inhand-nil, inhand(Y), on(Y, Z)
.1 : change


.3 : noise
pickup(X) :

n

: block(Y), on(X, Y)



inhand-nil, height(Y) < 10




.7 : inhand(X), on(X, Y), clear(Y)

.1 : change


.2 : noise
n

pickup(X) :

: table(Y), on(X, Y)



inhand-nil


.8 : inhand(X), on(X, Y)
.1 : change


.1 : noise
default (rule:
.6 : change

.4 : noise
format rules before, Section 4.2, except rule
includes explicit noise outcome. first three rules similar old versions,
difference model noise. final rule default rule: states
that, rule applies, probability observing change 0.4.
Together rules provide complete example type rule set learn
Section 5.1. However, written fixed modeling language functions
predicates. next section describes concepts used extend language.
4.4 Concept Definitions
addition observed primitive predicates, often useful background
knowledge defines additional predicates whose truth values computed based
observations. found essential modeling certain planning
domains (Edelkamp & Hoffman, 2004).
background knowledge consists definitions additional concept predicates
functions. work, express concept definitions using concept language
includes conjunction, existential quantification, universal quantification, transitive closure, counting. Quantification used defining concepts inhand(X) :=
block(X) Y.on(X, ). Transitive closure included language via Kleene star
operator defines concepts above(X, ) := (X, ). Finally, counting included using special quantifier # returns number objects formula
true. useful defining integer-valued functions height(X) := #Y.above(X, ).
321

fiPasula, Zettlemoyer, & Pack Kaelbling

defined, concepts enable us simplify context deictic variable definitions, well restrict ways cannot described using simple conjunctions.
Note, however, need track concept values outcomes, since
always computed primitives. Therefore, rule contexts use language
enriched concepts; outcomes contain primitives.
example, deictic noisy rule attempting pick block X, side
side background knowledge necessary primitive predicates
table.

pickup(X) :




: topstack(Y, X),


Z : on(Y, Z),

: table(T)




inhand-nil, height(Y) < 9


.80 : on(Y, Z)


.10 : on(Y, Z), on(Y, T)


.05 : change



.05 : noise

clear(X)

:= Y.on(Y, X)

inhand(X) := block(X) Y.on(X, Y)
inhand-nil := Y.inhand(Y)
above(X, Y)

:= (X, Y)

(4)

topstack(X, Y) := clear(X) above(X, Y)
height(X) := #Y.above(X, Y)

rule complicated example rules given thus far: deals
situation block picked up, X, middle stack. deictic variable
identifies (unique) block top stack, deictic variable Zthe object
, deictic variable Tthe table. might expected, gripper succeeds
lifting high probability.
concept definitions include clear(X), defined exists object
X; inhand(X), defined X block object; inhand-nil, defined
exists object hand; above(X, Y), defined transitive
closure on(X, Y); topstack(X, Y), defined X Y, clear; height(X),
defined number objects X using chain ons. explained
above, concepts used context deictic variable definitions,
outcomes track primitive predicates; fact, appears outcomes, since
value table predicates never changes.
4.5 Action Models
combine set concept definitions set rules define action model.
best action models represent rule set using NDRs, but, comparison purposes,
experiments involve rule sets use simpler representations, without
noise deictic references. Moreover, rule sets differ whether allowed
contain constants. rules presented far contained none, neither
context outcomes. reasonable setup states contain skolem
constants, constants inherent meaning names assigned
general repeated. However, states intrinsic constants, perfectly
acceptable include constants action models. all, constants used
uniquely identify objects world.
develop learning algorithm next section, assume general
constants allowed action model, show simple restrictions within
322

fiLearning Symbolic Models Stochastic World Dynamics

algorithm ensure learned models contain any. also show,
Section 7, learning action models restricted free constants provides
useful bias improve generalization training small data sets.

5. Learning Action Models
defined rule action models, describe may constructed
using learning algorithm attempts return action model best explains set
example actions results. formally, algorithm takes training set E,
example (s, a, s0 ) triple, searches action model maximizes
likelihood action effects seen E, subject penalty complexity.
Finding involves two distinct problems: defining set concept predicates,
constructing rule set R using language contains predicates together
directly observable primitive predicates. section, first discuss second problem,
rule set learning, assuming fixed set predicates provided learner. Then,
present simple algorithm discovers new, useful concept predicates.
5.1 Learning Rule Sets
problem learning rule sets is, general, NP-hard (Zettlemoyer, Pasula, & Kaelbling,
2003). Here, address problem using greedy search. structure search
hierarchically identifying two self-contained subproblems: outcome learning,
subproblem general rule set search, parameter estimation, subproblem
outcome learning. Thus, overall algorithm involves three levels greedy search:
outermost level, LearnRules, searches space rule sets, often
constructing new rules, altering existing ones; middle level, InduceOutcomes which,
given incomplete rule consisting context, action, set deictic references, fills
rest rule; innermost level, LearnParameters, takes slightly
complete rule, lacking distribution outcomes, finds distribution
optimizes likelihood examples covered rule. present three
levels starting inside out, subroutine described one
depends it. Since three subroutines attempt maximize scoring metric,
begin introducing metric.
5.1.1 Scoring Metric
greedy search algorithm must judge parts search space desirable.
Here, done help scoring metric rule sets,
S(R) =

X

log(P (s0 |s, a, r(s,a) ))

(s,a,s0 )E

X

P EN (r)

(5)

rR

r(s,a) rule governing transition occurring performed s,
scaling parameter, P EN (r) complexity penalty applied rule r. Thus, S(R)
favors rule sets maximize likelihood bound data penalizes rule sets
overly complex.
Ideally, P would likelihood example. However, rules noise outcomes
cannot assign exact likelihood so, case, use lower bound defined Equa323

fiPasula, Zettlemoyer, & Pack Kaelbling

tion 3 instead. P EN (r) defined simply total number literals r. chose
penalty simplicity, also performed worse penalty
term tested informal experiments. scaling parameter set 0.5 experiments, could also set using cross-validation hold-out dataset
principled technique. metric puts pressure model explain examples using
non-noise outcomes, increases P , also opposing pressure complexity, via
P EN (r).
assume state-action pair (s, a) covered one rule (which,
finite set examples, enforced simply ensuring examples stateaction pair covered one rule) rewrite metric terms rules rather
examples, give
S(R) =

X

X

rR

(s,a,s0 )Er

log(P (s0 |s, a, r)) P EN (r)

(6)

Er set examples covered r. Thus, rules contribution S(R)
calculated independently others.
5.1.2 Learning Parameters
first algorithms described section, LearnParameters, takes incomplete
rule r consisting action, set deictic references, context, set outcomes,
learns distribution P maximizes rs score examples Er covered it.
Since procedure allowed alter number literals rule, therefore
cannot affect complexity penalty term, optimal distribution simply one
maximizes log likelihood Er . case rules noise outcomes
log(P (s0 |s, a, r))

X

L =

(s,a,s0 )Er



=



log pmin P (0noise |s, a, r) +

X

X

P (s0 |0i , s, a, r)P (0i |s, a, r) .

(7)

0i r

(s,a,s0 )Er

non-noise outcome, P (s0 |0i , s, a, r) one 0i covers (s, a, s0 ) zero otherwise.
(In case rules without noise outcomes, sum slightly simpler,
pmin P (0noise |s, a, r) term missing.)
every example covered unique outcome, Ls maximum expressed
closed form. Let set examples covered outcome 0 E0 . add
Lagrange multiplier enforce constraint P (0i |s, a, r) distributions must sum
1.0, get


L =

X
(s,a,s0 )Er

=

X
E0

log


X

P (s0 |0i , s, a, r)P (0i |s, a, r) + (

X

0i r

0i

|E0 | log P (0i |s, a, r) + (


X

P (0i |s, a, r) 1.0) .

0i

324

P (0i |s, a, r) 1.0)

fiLearning Symbolic Models Stochastic World Dynamics

Then, partial derivative L respect P (0i |s, a, r) |E0 |/P (0i |s, a, r)
= |E|, P (0i |s, a, r) = |E0i |/|E|. Thus, parameters estimated
calculating percentage examples outcome covers.
However, seen Section 4.1, possible example covered
one outcome; indeed, noise outcome, covers examples,
always case. situation, sum examples cannot rewritten
simple sum terms representing different outcomes containing single
relevant probability: probabilities overlapping outcomes remain tied together,
general closed-form solution exists, estimating maximum-likelihood parameters
nonlinear programming problem. Fortunately, instance well-studied problem
maximizing concave function (the log likelihood presented Equation 7) probability simplex. Several gradient ascent algorithms known problem (Bertsekas,
1999); since function concave, guaranteed converge global maximum.
LearnParameters uses conditional gradient method, works by, iteration,
moving along parameter axis maximal partial derivative. step-sizes
chosen using Armijo rule (with parameters = 1.0, = 0.1, = 0.01.)
search converges improvement L small, less 106 . chose
algorithm easy implement converged quickly experiments
tried. However, problems found method converges slowly, one
many nonlinear optimization methods, constrained Newtons method,
could directly applied.
5.1.3 Inducing Outcomes
Given LearnParameters, algorithm learning distribution outcomes,
consider problem taking incomplete rule r consisting context, action,
perhaps set deictic references, finding optimal way fill rest
rulethat is, set outcomes {01 . . . 0n } associated distribution P
maximize score
S(r) =

X

log(P (s0 |s, a, r)) P ENo (r),

(s,a,s0 )Er

Er set examples covered r, P ENo (r) total number literals
outcomes r. (S(r) factor scoring metric Equation 6 due
rule r, without aspects P EN (r) fixed purposes subroutine:
number literals context.)
general, outcome induction NP-hard (Zettlemoyer, Pasula, & Kaelbling, 2003). InduceOutcomes uses greedy search restricted subset possible outcome sets:
proper training examples, outcome set proper every outcome
covers least one training example. Two operators, described below, move
space immediate moves improve rule score. set
outcomes considers, InduceOutcomes calls LearnParameters supply best P can.
initial set outcomes created by, example, writing set
atoms changed truth values result action, creating outcome
describe every set changes observed way.
325

fiPasula, Zettlemoyer, & Pack Kaelbling

E1
E2
E3
E4

01
02
03
04

= t(c1), h(c2) h(c1), h(c2)
= h(c1), t(c2) h(c1), h(c2)
= h(c1), h(c2) t(c1), t(c2)
= h(c1), h(c2) h(c1), h(c2)
(a)

= {h(c1)}
= {h(c2)}
= {t(c1), t(c2)}
= {no change}
(b)

Figure 2: (a) Possible training data learning set outcomes. (b) initial set
outcomes would created data (a) picking smallest
outcome describes change.

example, consider coins domain. coins world contains n coins,
showing either heads tails. action flip-coupled, takes arguments,
flips coins, half time heads, otherwise tails. set training
data learning outcomes two coins might look like part (a) Figure 2 h(C)
stands heads(C), t(C) stands heads(C), s0 part (s, a, s0 ) example
= flip-coupled. suppose suggested rule flip-coupled
context deictic references. Given data, initial set outcomes four
entries part (b) Figure 2.
rule contained variables, either abstract action arguments deictic
references, InduceOutcomes would introduce variables appropriate places
outcome set. variable introduction achieved applying inverse action
substitution examples set changes computing initial set outcomes. 6
So, given deictic reference C : red(C) always found refer c1, red
coin, example set outcomes would contain C wherever currently contains c1.
Finally, disallow use constants rules, variables become way
outcomes refer objects whose properties changed. Then, changes containing
constant referred variable cannot expressed, corresponding
example covered noise outcome.
Outcome Search Operators

InduceOutcomes uses two search operators. first add operator, picks
pair non-contradictory outcomes set creates new outcome
conjunction. example, might pick 01 02 combine them, adding new
outcome 05 = {h(c1), h(c2)} set. second remove operator drops
outcome set. Outcomes dropped overlapping
outcomes every example cover, otherwise outcome set would remain proper.
(Of course, outcome set contains noise outcome, every outcome
dropped, since examples covered noise outcome.) Whenever operator
adds removes outcome, LearnParameters called find optimal distribution
6. Thus, InduceOutcomes introduces variables aggressively wherever possible, based intuition
corresponding objects would better described constant, become apparent
training example.

326

fiLearning Symbolic Models Stochastic World Dynamics

new outcome set, used calculate maximum log likelihood
data respect new outcome set.
Sometimes, LearnParameters return zero probabilities outcomes.
outcomes removed outcome set, since contribute nothing
likelihood, add complexity. optimization improves efficiency
search.
outcomes Figure 2, 04 dropped since covers E4 , also
covered 01 02 . new outcome created conjoining
existing ones 05 = {h(c1), h(c2)}, covers E1 , E2 , E3 . Thus, 05 added,
01 02 dropped. Adding 05 dropping 01 , 02 , 04 creates outcome
set {03 , 05 }, optimal set outcomes training examples Figure 2.
Notice outcome always equal union sets literals change
training examples covers. fact ensures every proper outcome made
merging outcomes initial outcome set. InduceOutcomes can, theory, find
set outcomes.
5.1.4 Learning Rules
know fill incomplete rules, describe LearnRules, outermost
level learning algorithm, takes set examples E fixed language
primitive derived predicates, performs greedy search space rule
sets. precisely, searches space proper rule sets, rule set R
defined proper respect data set E includes one rule
applicable every example e E change occurs, include
rules applicable examples.
search proceeds described pseudocode Figure 3. starts rule set
contains default rule. every step, takes current rule set applies
search operators obtain set new rule sets. selects rule set R
maximizes scoring metric S(R) defined Equation 5. Ties S(R) broken
randomly.
begin explaining search initialized, go describe
operators used, finish working simple example shows LearnRules
action.
Rule Set Search Initialization

LearnRules initialized proper rule set. paper, always initialize
set noisy default rule. treats action effects training set
noise; search progresses, search operators introduce rules explain action
effects explicitly. chose initial starting point simplicity, worked
well informal experiments. Another strategy would start specific rule
set, describing detail examples. bottom-up methods advantage
data-driven, help search reach good parts search space
easily. However, show, several search operators used algorithm
presented guided training examples, algorithm already
desirable property. Moreover, bottom-up method bad complexity properties
327

fiPasula, Zettlemoyer, & Pack Kaelbling

LearnRuleSet(E)
Inputs:
Training examples E
Computation:
Initialize rule set R contain default rule
better rules sets found
search operator
Create new rule sets O, RO = O(R, E)
rule set R0 RO
score improves (S(R0 ) > S(R))
Update new best rule set, R = R0
Output:
final rule set R

Figure 3: LearnRuleSet pseudocode. algorithm performs greedy search space
rule sets. step set search operators propose set new rule sets.
highest scoring rule set selected used next iteration.

situations large data set described using relatively simple set rules,
case interested in.
Rule Set Search Operators

rule set search, LearnRules repeatedly finds applies operator
increase score current rule set most.
search operators work creating new rule set rules (usually
altering existing rule) integrating new rules rule set way
ensures rule set remains proper. Rule creation involves picking action z,
set deictic references D, context , calling InduceOutcomes
learning algorithm complete rule filling 0i pi s. (If new rule covers
examples, attempt abandoned, since adding rule cannot help scoring
metric.) Integration rule set involves adding new rules, also removing
old rules cover examples. increase number examples
covered default rule.
5.1.5 Search Operators
search operator takes input rule set R set training examples E,
creates set new rule sets RO evaluated greedy search loop. eleven
search operators. first describe complex operator, ExplainExamples, followed
simple one, DropRules. Then, present remaining nine operators,
share common computational framework outlined Figure 4.
Together, operators provide many different ways moving space
possible rule sets. algorithm adapted learn different types rule sets (for
example, without constants) restricting set search operators used.
328

fiLearning Symbolic Models Stochastic World Dynamics

OperatorTemplate(R, E)
Inputs:
Rule set R
Training examples E
Computation:
Repeatedly select rule r R
Create copy input rule set R0 = R
Create new set rules, N , making changes r
new rule r0 N covers examples
Estimate new outcomes r0 InduceOutcomes
Add r0 R0 remove rules R0 cover
examples r0 covers
Recompute set examples default rule R0
covers parameters default rule
Add R0 return rule sets RO
Output:
set rules sets, RO

Figure 4: OperatorTemplate Pseudocode. algorithm basic framework used
six different search operators. operator repeatedly selects rule, uses make n
new rules, integrates rules original rule set create new rule set.

ExplainExamples takes input training set E rule set R creates new,
alternative rule sets contain additional rules modeling training examples
covered default rule R. Figure 5 shows pseudocode
algorithm, considers training example E covered default
rule R, executes three-step procedure. first step builds large
specific rule r0 describes example; second step attempts trim rule,
generalize maximize score, still ensuring covers E;
third step creates new rule set R0 copying R integrating new
rule r0 new rule set.
illustration, let us consider steps 1 2 ExplainExamples might
applied training example (s, a, s0 ) = ({on(a, t), on(b, a)}, pickup(b), {on(a, t)}),
background knowledge defined Rule 4 Section 4.4 constants
allowed.
Step 1 builds rule r. creates new variable X represent object b
action; then, action substitution becomes = {X b}, action r
set pickup(X). context r set conjunction inhand-nil, inhand(X),
clear(X), height(X) = 2, on(X, X), above(X, X), topstack(X, X). Then, Step
1.2, ExplainExamples attempts create deictic references name constants
whose properties changed example, already action substitution. case, changed literal on(b, a), b substitution,
C = {a}; new deictic variable created restricted, extended
329

fiPasula, Zettlemoyer, & Pack Kaelbling

ExplainExamples(R, E)
Inputs:
rule set R
training set E
Computation:
example (s, a, s0 ) E covered default rule R
Step 1: Create new rule r
Step 1.1: Create action context r
Create new variables represent arguments
Use create new action substitution
Set rs action 1 (a)
Set rs context conjunction boolean equality literals
formed using variables available functions predicates
(primitive derived) entailed
Step 1.2: Create deictic references r
Collect set constants C whose properties changed s0 ,

c C
Create new variable v extend map v c
Create , conjunction literals containing v formed using
available variables, functions, predicates, entailed
Create deictic reference variable v restriction 1 ()
uniquely refers c s, add r
Step 1.3: Complete rule
Call InduceOutcomes create rules outcomes.
Step 2: Trim literals r
Create rule set R0 containing r default rule
Greedily trim literals r, ensuring r still covers (s, a, s0 ) filling
outcomes using InduceOutcomes R0 score stops improving
Step 3: Create new rule set containing r
Create new rule set R0 = R
Add r R0 remove rules R0 cover examples r covers
Recompute set examples default rule R0 covers parameters
default rule
Add R0 return rule sets RO
Output:
set rule sets, RO

Figure 5: ExplainExamples Pseudocode. algorithm attempts augment rule set new
rules covering examples currently handled default rule.

330

fiLearning Symbolic Models Stochastic World Dynamics

{X b, a}. Finally, Step 1.3, outcome set created. Assuming
examples context applies, nine ten end X lifted,
rest falling onto table, resulting rule r0 looks follows:


inhand(Y ), clear(Y), on(X, Y), table(Y)

pickup(X) : : above(X, Y), topstack(X, Y), above(Y, Y)


topstack(Y, Y), on(Y, Y), height(Y) = 1
inhand-nil, inhand(X), clear(X), table(X), height(X) = 2, on(X, X),
above(X,
X), topstack(X, X)

0.9 : on(X, Y)

0.1 : noise

(The falls table outcome modeled noise, since absence constants
rule way referring table.)
Step 2, ExplainExamples trims rule remove literals always true
training examples, like on(X, X), table()s, redundant ones,
like inhand(), clear(Y), perhaps one heights, give


pickup(X) : : on(X, Y)
inhand-nil,
clear(X), height(X) = 2

0.9 : on(X, Y)

0.1 : noise

rules context describes starting example concisely. Explain Examples
consider dropping remaining literals, thereby generalizing rule
applies examples different starting states. However, generalizations
necessarily improve score. smaller contexts, might end
creating outcomes describe new examples, penalty term
guaranteed improve. change likelihood term depend whether
new examples higher likelihood new rule default rule,
whether old examples higher likelihood old distribution
new one. Quite frequently, need cover new examples
give new rule distribution closer random before, usually
lead decrease likelihood large overcome improvement
penalty, given likelihood-penalty trade-off.
Let us assume that, case, predicate dropped without worsening
likelihood. rule integrated rule set is.
DropRules cycles rules current rule set, removes one
turn set. returns set rule sets, one missing different rule.
remaining operators create new rule sets input rule set R repeatedly
choosing rule r R making changes create one new rules. new
rules integrated R, ExplainExamples, create new rule set R0 .
Figure 4 shows general pseudocode done. operators vary
way select rules changes make them. variations described
331

fiPasula, Zettlemoyer, & Pack Kaelbling

operator below. (Note operators, deal deictic
references constants, applicable action model representation allows
features.)
DropLits selects every rule r R n times, n number literals
context r; words, selects r literal context.
creates new rule r0 removing literal rs context; N Figure 4
simply set containing r0 .
So, example pickup rule created ExplainExamples would selected three times,
inhand-nil, clear(X), one height(X) = 2, would create
three new rules (each different literal missing), three singleton N sets,
three candidate new rule sets R0 . Since newly-created r0 generalizations r,
certain cover rs examples, r removed
R0 s.
changes suggested DropLits therefore exactly suggested trimming search ExplainExamples, one crucial difference:
DropLits attempts integrate new rule full rule set, instead making quick comparison default rule Step 2 ExplainExamples.
ExplainExamples used trimming search relatively cheap, local
heuristic allowing decide rule size, DropLits uses search globally
space rule sets, comparing contributions various conflicting rules.
DropRefs operator used deictic references permitted. selects
rule r R deictic reference r. creates new rule r0
removing deictic reference r; N is, again, set containing r0 .
applying operator, pickup rule would selected once, reference
describing , one new rule set would returned: one containing rule
without .
GeneralizeEquality selects rule r R twice equality literal context
create two new rules: one equality replaced , one
replaced . rule integrated rule set R,
resulting two R0 returned. Again, generalized rules certain cover
rs examples, R0 contain r.
context pickup rule contains one equality literal, height(X) = 1. GeneralizeEquality attempt replace literal height(X) 1 height(X) 1.
domain containing two blocks, would likely yield interesting
generalizations.
ChangeRanges selects rule r R n times equality inequality literal
context, n total number values range literal.
time selects r creates new rule r0 replacing numeric value chosen
(in)equality another possible value range. Note quite possible
new rules cover examples, abandoned.
remaining rules integrated new copies rule set usual.
332

fiLearning Symbolic Models Stochastic World Dynamics

Thus, f () ranges [1 . . . n], ChangeRange would, applied rule containing inequality f () < i, construct rule sets replaced
integers [1 . . . n].
pickup rule contains one equality literal, height(X) = 1. two-block domain
(s, a, s0 ) example drawn, height() take values 0, 1, 2,
rule will, again, selected thrice, new rules created containing
new equalities. Since rule constrains X something, new rule containing
height(X) = 0 never cover examples certainly abandoned.
SplitOnLits selects rule r R n times, n number literals
absent rules context deictic references. (The set absent literals
obtained applying available functions predicatesboth primitive
derivedto terms present rule, removing literals already present
rule resulting set.) constructs set new rules. case
predicate inequality literals, creates one rule positive version
literal inserted context, one negative version.
case equality literals, constructs rule every possible value equality could
take. either case, rules cover examples dropped. remaining
rules corresponding one literal placed N , integrated
rule set simultaneously.
Note newly created rules will, them, cover examples
start covered original rule others, examples
split them.
list literals may added pickup rule consists inhand(X),
inhand(Y), table(X), table(Y), clear(Y), on(Y, X), on(Y, Y), on(X, X), height(Y) =?,
possible applications topstack. literals make
interesting examples: adding context create rules either
cover examples all, abandoned, cover set
examples original rule, rejected likelihood
worse penalty. However, illustrate process, attempting add
height(Y) =? predicate result creation three new rules height(Y) = n
context, one n [0, 1, 2]. rules would added rule set
once.
AddLits selects rule r R 2n times, n number predicate-based
literals absent rules context deictic references, 2 reflects fact literal may considered positive negative form.
constructs new rule literal inserting literal earliest place
rule variables well-defined: literal contains deictic
variables, context, otherwise restriction last
deictic variable mentioned literal. (So, V1 V2 deictic variables V1
appears first, on(V1 , V2 ) would inserted restriction V2 .) resulting
rule integrated rule set.
list literals may added pickup rule much SplitOnLits,
without height(Y) =?. Again, process lead anything interesting
333

fiPasula, Zettlemoyer, & Pack Kaelbling

example, reason. illustration, inhand(Y) would
chosen twice, inhand(Y), added context case. Since
context already contains inhand-nil, adding inhand(Y) redundant, adding
inhand(Y) produce contradiction, neither rule seriously considered.
AddRefs operator used deictic references permitted. selects
rule r R n times, n number literals constructed
using available predicates, variables r, new variable v. case,
creates new deictic reference v, using current literal define restriction,
adds deictic reference antecendent r construct new rule,
integrated rule set.
Supposing V new variable, list literals would constructed
pickup rule consists inhand(V), clear(V), on(V, X), on(X, V), table(V), on(V, Y),
on(Y, V), on(V, V), possible applications topstack (which
mirror on.) used create deictic references like V : table(V).
(A useful reference here, allows rule describe falls table outcomes
explicitly; operator likely accepted point search.)
RaiseConstants operator used constants permitted. selects
rule r R n times, n number constants among arguments rs
action. constant c, constructs new rule creating new variable
replacing every occurrence c it. integrates new rule rule
set.
SplitVariables operator used constants permitted. selects
rule r R n times, n number variables among arguments rs
action. variable v, goes examples covered rule r
collects constants v binds to. Then, creates rule constants
replacing every occurrence v constant. rules corresponding one
variable v combined set N integrated old rule set together.
found operators consistently used learning.
set operators heuristic, complete sense every rule set
constructed initial rule setalthough, course, guarantee
scoring metric lead greedy search global maximum.
LearnRuless search strategy one large drawback; set learned rules
guaranteed proper training set testing data. New test examples
could covered one rule. happens, employ alternative
rule-selection semantics, return default rule model situation. way,
essentially saying dont know happen. However,
significant problem; problematic test examples always added future training
set used learn better models. Given sufficiently large training set, failures
rare.

334

fiLearning Symbolic Models Stochastic World Dynamics

e1:

B2

B2
B0

puton(B1)

B2
B0

puton(B1)

B0
B1

B1

e3:

r1 :

r2 :

puton(X)
:
(
)
: inhand(Y)
: table(T)
empty
context

0.33 : on(Y, T)
0.33 : on(Y, X)


0.34 : noise

r3 :

puton(X)
:
n

: inhand(Y)
clear(X)
n
1.0 : on(Y, X)

B1

B1

e2:

B0

puton(X)
:
(
)
: inhand(Y)
Z : on(Z, X)
empty
( context
0.5 : on(Y, Z)

0.5 : noise

B2

B2
puton(B1)

B0 B1

B2
B0 B1

Figure 6: Three training examples three blocks world. example paired initial
rule ExplainExamples might create model it. example, agent trying
put block B2 onto block B1.

Example Rule Set Learning

example, consider LearnRuleSet might learn set rules model three
training examples Figure 6, given settings complexity penalty noise bound
later used experiments: = 0.5 pmin = 0.0000001. pmin low
three-block domain, since 25 different states, use consistency.
initialization, rule set contains default rule; changes occur
examples modeled noise. Since examples include change, default rule
noise probability 1.0. describe path greedy search takes.
first round search ExplainExamples operator suggests adding new
rules describe examples. general, ExplainExamples tries construct rules
compact, cover many examples, assign relatively high probability
covered example. (The latter means noise outcomes avoided whenever
possible.) One reasonable set rules suggested shown right-hand side
Figure 6. Notice r3 deterministic, high-probability relatively compact:
e3 unique initial state, ExplainExamples take advantage this. Meanwhile,
335

fiPasula, Zettlemoyer, & Pack Kaelbling

e1 e2 starting state, rules explaining must cover
others examples. Thus, noise outcomes unavoidable rules, since lack
necessary deictic references. (Deictic variables created describe objects
whose state changes example explained.)
Now, consider adding one rules. guarantee
constitute improvement, since high complexity penalty would make rule
look bad, high pmin would make default rule look good. determine
best move is, algorithm compares scores rule sets containing
proposed rules score initial rule set containing default rule. Let us
calculate scores example, starting rule set consisting rule r1 ,
covers e1 e2 , default rule rd , covers remaining example,
therefore noise probability 1.0. use Equation 5, let rules
complexity number literals body: so, case r1 , three. get:
S(r1 , rd ) =

X

log(P (s0 |s, a, r(s,a) ))

(s,a,s0 )E

X

P EN (r)

rR

= log(0.5 + 0.5 pmin ) + log(0.5 pmin ) + log(pmin ) P EN (r1 ) P EN (rd )
= log(0.50000005) + log(0.00000005) + log(0.0000001) 0.5 3 0.5 0
= 0.301 7.301 7 1.5
= 16.101
So, rule set containing r1 score 16.101. Similar calculations show
rule sets containing r2 r3 scores 10.443 15.5 respectively. Since
initial rule set score 21, new rule sets improvements, one
containing r2 best, picked greedy search. new rule set now:


puton(X) : : inhand(Y), : table(T)
empty context

0.33 : on(Y, T)
0.33 : on(Y, X)


0.34 : noise
default
rule:
1.0 : change

0.0 : noise

Notice training examples covered non-default rule. situation,
default rule cover examples probability assigned noise
outcome.
next step, search decide altering existing rule, introducing another rule describe example currently covered default rule. Since
default rule covers examples, altering single rule rule set option.
operators likely score highly get rid noise outcome,
rule means referring block X e1 .
appropriate operator therefore AddRefs, introduce new deictic reference describing block. course, increases size rule, complexity,
336

fiLearning Symbolic Models Stochastic World Dynamics

addition means rule longer applies e3 , leaving example
handled default rule. However, new rule set raises probabilities
examples enough compensate increase complexity, ends
score 10.102, clear improvement 10.443. highest score
obtainable step, algorithm alters rule set get:
puton(X) :



: inhand(Y), : table(T), Z : on(Z, X)



empty context

0.5 : on(Y, Z)

0.5 : on(Y, T)
default
rule:
0.0 : change

1.0 : noise

default rule covers e3 , ExplainExamples something work again.
Adding r3 get rid noise, yield much improved score 4.602. Again,
biggest improvement made, rule set becomes:
puton(X) :



: inhand(Y), : table(T), Z : on(Z, X)



empty context

0.5 : on(Y, Z)

0.5 : on(Y, T)


puton(X) : : inhand(Y)
clear(X)

1.0 : on(Y, X)
default
rule:
1.0 : change

0.0 : noise

Note rule could added earlier e3 also covered
first rule added, r2 , specialized. Thus, adding r3 rule set containing r2
would knocked r2 out, caused examples e1 e2 explained noise
default rule, would reduced overall score. (It is, however, possible rule
knock another yet improve score: requires complicated set
examples.)
Learning continues search. Attempts apply rule-altering operators
current rules either make bigger without changing likelihood, lead
creation noise outcomes. Dropping either rule add noise probability
default rule lower score. Since extra examples explained,
operator improve score, search stops rule set. seems like
reasonable rule set domain: one rule covers happens try puton
clear block, one describes try puton block another block it.
Ideally, would like first rule generalize blocks something them,
instead on, notice would need examples containing higher stacks.
337

fiPasula, Zettlemoyer, & Pack Kaelbling

5.1.6 Different Versions Algorithm
making small variations LearnRuleSet algorithm, learn different types
rule sets. important evaluating algorithm.
explore effects constants rules, evaluate three different versions
rule learning: propositional, relational, deictic. propositional rule learning, ExplainExamples creates initial trimmed rules constants never introduces variables.
None search operators introduce variables used. Thus, learned rules
guaranteed propositionalthey cannot generalize across identities specific
objects. relational rule learning, variables allowed rule action arguments
search operators allowed introduce deictic references. ExplainExamples creates
rules constants name objects, long constants already
variable action argument list mapped them. Finally, deictic rule learning,
constants allowed. see deictic learning provides strong bias
improve generalization.
demonstrate addition noise deictic references result better
rules, learn action models enhancements. Again,
done changing algorithm minor ways. disallow noise, set rule noise
probability zero, means must constrain outcome sets contain
outcome every example change observed; rules cannot express
changes abandoned. disallow deictic references, disable operators
introduce them, ExplainExamples create empty deictic reference set.
5.2 Learning Concepts
contexts deictic references NDRs make use concept predicates functions well primitive ones. concepts specified hand, learned using
rather simple algorithm, LearnConcepts, uses LearnRuleSet subprocedure
testing concept usefulness. algorithm works constructing increasingly complex concepts, running LearnRuleSet checking concepts appear learned
rules. first set created applying operators Figure 7 literals built
original language. Subsequent sets concepts constructed using literals
proved useful latest run; concepts tried before, always
true always false across examples, discarded. search ends none
new concepts prove useful.
example, consider predicate topstack simple blocks world, could
discovered follows. first round learning, literal on(X1 , X2 ) used define
new predicate n(Y1 , Y2 ) := (Y1 , Y2 ), true Y1 stacked Y2 .
Assuming new predicate appears learned rules, used second
round learning, define, among others, m(Z1 , Z2 ) := n(Z1 , Z2 ) clear(Z1 ). ensuring
Z1 clear, predicate true Z1 highest block stack
containing Z2 . notion topstack used determining happen
gripper tries pick Z2 . descends above, likely grasp
block top stack instead.
Since concept language quite rich, overfitting (e.g., learning concepts
used identify individual examples) serious problem. handle
338

fiLearning Symbolic Models Stochastic World Dynamics

p(X) n := QY.p(Y )
p(X1 , X2 ) n(Y2 ) := QY1 .p(Y1 , Y2 )
p(X1 , X2 ) n(Y1 ) := QY2 .p(Y1 , Y2 )
p(X1 , X2 ) n(Y1 , Y2 ) := p (Y1 , Y2 )
p(X1 , X2 ) n(Y1 , Y2 ) := p+ (Y1 , Y2 )
p1 (X1 ), p2 (X2 ) n(Y1 ) := p1 (Y1 ) p2 (Y1 )
p1 (X1 ), p2 (X2 , X3 ) n(Y1 , Y2 ) := p1 (Y1 ) p2 (Y1 , Y2 )
p1 (X1 ), p2 (X2 , X3 ) n(Y1 , Y2 ) := p1 (Y1 ) p2 (Y2 , Y1 )
p1 (X1 , X2 ), p2 (X3 , X4 ) n(Y1 , Y2 ) := p1 (Y1 , Y2 ) p2 (Y1 , Y2 )
p1 (X1 , X2 ), p2 (X3 , X4 ) n(Y1 , Y2 ) := p1 (Y1 , Y2 ) p2 (Y2 , Y1 )
p1 (X1 , X2 ), p2 (X3 , X4 ) n(Y1 , Y2 ) := p1 (Y1 , Y2 ) p2 (Y1 , Y1 )
p1 (X1 , X2 ), p2 (X3 , X4 ) n(Y1 , Y2 ) := p1 (Y1 , Y2 ) p2 (Y2 , Y2 )
f (X) = c n() := #Y.f (Y ) = c
f (X) c n() := #Y.f (Y ) c
f (X) c n() := #Y.f (Y ) c
Figure 7: Operators used invent new predicate n. operator takes input one
literals, listed left. ps represent old predicates; f represents old function;
Q refer ; c numerical constant. operator takes literal
returns concept definition. operators applied literals used
rules rule set create new predicates.

expected way: introducing penalty term, 0 c(R), create new scoring metric
0 (R) = S(R) 0 c(R)
c(R) number distinct concepts used rule set R 0 scaling
parameter. new metric 0 used LearnRuleSet; avoids overfitting favoring
rule sets use fewer derived predicates. (Note fact 0 cannot factored
rule, was, matter, since factoring used InduceOutcomes
LearnParameters, neither change number concepts used relevant
rule: outcomes contain primitive predicates.)
5.3 Discussion
rule set learning challenge addressed section complicated need learn
structure rules, numeric parameters associated outcome distributions,
definitions derived predicates modeling language. LearnConcepts
339

fiPasula, Zettlemoyer, & Pack Kaelbling

algorithm conceptually simple, performs simultaneous learning effectively,
see experiments Section 7.2.
large number possible search operators might cause concern overall
computational complexity LearnRuleSet algorithm. Although algorithm expensive, set search operators designed control complexity attempting
keep number rules current set small possible.
step search, number new rule sets considered depends
current set rules. ExplainExamples operator creates new rule sets,
number examples covered default rule. Since search starts rule set
containing default rule, initially equal number training examples.
However, ExplainExamples designed introduce rules cover many examples,
practice grows small quickly. operators create O(rm) new rule sets,
r number rules current set depends specific operator.
example, could number literals dropped context
rule DropLits operator. Although large, r stays small practice
search starts default rule complexity penalty favors small rule
sets.
ensure score increases search step, algorithm guaranteed converge (usually local) optimum. not, however, guarantee
quickly get there. practice, found algorithm converged quickly
test domains. LearnRuleSet algorithm never took 50 steps
LearnConcepts outer loop never cycled 5 times. entire algorithm never took
six hours run single processor, although significant effort made
cache intermediate computations final implementation.
spite this, realize that, scale complex domains, approach
eventually become prohibitively expensive. plan handle problem developing new algorithms learn concepts, rules, rule parameters online manner,
directed search operators. However, leave complex approach
future work.

6. Planning
experiments Section 7.2 involve learning models complex actions
true models dynamics, level relational rules, available evaluation.
Instead, learned models evaluated planning executing actions.
many possible ways plan. work, explore MDP planning.
MDP (Puterman, 1999) 4-tuple (S, A, T, R). set possible states,
set possible actions, distribution encodes transition dynamics
world, (s0 |s, a). Finally, R reward signal maps every state real value.
policy plan (possibly stochastic) mapping states actions. expected
amount reward achieved executing starting called value
P

defined V (s) = E[
i=0 R(si )|], si states reached
time i. discount factor 0 < 1 favors immediate rewards. goal
MDP planning find policy achieve reward time.
340

fiLearning Symbolic Models Stochastic World Dynamics

optimal policy found solving set Bellman equations,
s, V (s) = R(s) +

X

(s0 |s, (a))V (s0 ).

(8)

s0

application, action set state set defined world
modeling. rule set R defines transition model reward function R defined
hand.
planning large domains, difficult solve Bellman
equations exactly. approximation, implemented simple planner based
sparse sampling algorithm (Kearns, Mansour, & Ng, 2002). Given state s, creates tree
states (of predefined depth branching factor) sampling forward using transition
model, computes value node using Bellman equation, selects action
highest value.
adapt algorithm handle noisy outcomes, predict next state,
estimating value unknown next state fraction value staying
state: i.e., sample forward stayed state scale
value obtain. scaling factor 0.75, depth branching factor
four.
scaling method guess value unknown next state might
be; noisy rules partial models, way compute value explicitly.
future, would like explore methods learn associate values noise
outcomes. example, value outcome tower blocks falls
different goal build tall stack blocks goal put
blocks table.
algorithm solve hard combinatorial planning problems, allow
us choose actions maximize relatively simple reward functions. see
next section, enough distinguish good models poor ones. Moreover,
development first-order planning techniques active field research (AIPS, 2006).

7. Evaluation
section, demonstrate rule learning algorithm robust variety lownoise domains, show works intrinsically noisy simulated blocks world
domain. begin describing test domains, report series experiments.
7.1 Domains
experiments performed involve learning rules domains briefly
described following sections.
7.1.1 Slippery Gripper
slippery gripper domain, inspired work Draper et al. (1994), abstract,
symbolic blocks world simulated robotic arm, used move blocks
around table, nozzle, used paint blocks. Painting block
might cause gripper become wet, makes likely fail
manipulate blocks successfully; fortunately, wet gripper dried.
341

fiPasula, Zettlemoyer, & Pack Kaelbling

pickup(X, ) : on(X, ), clear(X),
inhand-nil, block(X), block(Y ), wet,



pickup(X, ) : on(X, ), clear(X),
inhand-nil, block(X), block(Y ), wet




inhand(X), clear(X), inhand-nil,

.7 :
on(X, ), clear(Y )


.2 : on(X, TABLE), on(X, )
.1 : change

inhand(X), clear(X), inhand-nil,

.33 :
on(X, ), clear(Y )


.33 : on(X, TABLE), on(X, )
.34 : change

pickup(X, ) : on(X, ), clear(X),
inhand-nil, block(X), table(Y ), wet
pickup(X, ) : on(X, ), clear(X),
inhand-nil, block(X), table(Y ), wet

(


(


inhand(X), clear(X), inhand-nil,
on(X, )
.5 : change

.5 :

inhand(X), clear(X), inhand-nil,
on(X, )
.2 : change

.8 :


inhand-nil, clear(Y), inhand(X),


.7 :


on(X, Y), clear(X)

puton(X, Y) : clear(Y), inhand(X),
on(X, TABLE), clear(X), inhand-nil,

block(Y)

.2 : inhand(X)


.1 : change

(
puton(X, TABLE) : inhand(X)

(

.6 : painted(X)
.1 : painted(X), wet
.3 : change



.9 : wet
.1 : change

paint(X) : block(X)

dry : context

on(X, TABLE), clear(X), inhand-nil,
inhand(X)
.2 : change
.8 :

Figure 8: Eight relational planning rules model slippery gripper domain.

Figure 8 shows set rules model domain. Individual states represent
world objects intrinsic constants experimental data generated sampling
rules. Section 7.2.1, explore learning algorithms Section 5 compare
number training examples scaled single complex world.
7.1.2 Trucks Drivers
Trucks drivers logistics domain, adapted 2002 AIPS international planning
competition (AIPS, 2002). four types constants: trucks, drivers, locations,
objects. Trucks, drivers objects locations. locations
connected paths links. Drivers board trucks, exit trucks, drive trucks
locations linked. Drivers also walk, without truck, locations
connected paths. Finally, objects loaded unloaded trucks.
set rules shown Figure 9. actions simple rules succeed
fail change world. However, walk action interesting twist. drivers
try walk one location another, succeed time,
342

fiLearning Symbolic Models Stochastic World Dynamics

load(O, T, L) :

at(T, L), at(O, L)



.9 : at(O, L), in(O, )
.1 : change

unload(O, T, L) :

in(O, ), at(T, L)



.9 : at(O, L), in(O, )
.1 : change

board(D, T, L) :

at(T, L), at(D, L), empty(T )



.9 : at(D, L), driving(D, ), empty(T )
.1 : change

disembark(D, T, L) :

at(T, L), driving(D, )



.9 : driving(D, ), at(D, L), empty(T )
.1 : change

drive(T, F L, L, D) :

driving(D, ), at(T, F L), link(F L, L)



.9 : at(T, L), at(T, F L)
.1 : change


.9 : at(D, L), at(D, F L)

walk(D, F L, L) :

at(D, F L), path(F L, L)
.1 : pick X s.t. path(F L, X)
at(D, X), at(D, F L)

Figure 9: Six rules encode world dynamics trucks drivers domain.
time arrive randomly chosen location connected path
origin location.
representation presented cannot encode action efficiently. best rule
set rule origin location, outcomes every location origin
linked to. Extending representation allow actions like walk represented
single rule interesting area future work.
Like slippery gripper domain, individual states represent world objects intrinsic
constants experimental data generated sampling rules. trucks
drivers dynamics difficult learn but, see Section 7.2.1, learned
enough training data.
7.1.3 Simulated Blocks World
validate rule extensions paper, Section 7.2 presents experiments rigid
body, simulated physics blocks world. section describes logical interface
simulated world. description extra complexities inherent learning dynamics
world presented Section 1.
define interface symbolic representation use describe
action dynamics physical domain simulated blocks world. perceptual
system produces states contain skolem constants. logical language includes
binary predicate on(X, Y), defined X exerts downward force obtained
querying internal state simulator, unary typing predicates table block.
actuation system translates actions sequences motor commands simulator.
Actions always execute, regardless state world. define two actions;
parameters allow agent specify objects intends manipulate.
pickup(X) action centers gripper X, lowers hits something, grasps,
raises gripper. Analogously, puton(X) action centers gripper X, lowers
encounters pressure, opens it, raises it.
343

fiPasula, Zettlemoyer, & Pack Kaelbling

using simulator sidestepping difficult pixels-to-predicates problem
occurs whenever agent map domain observations internal representation.
Primitive predicates defined terms internal state simulation simpler
cleaner observations real world would be. also make domain completely
observable: prerequisite learning planning algorithms. Choosing set
predicates observe important. make rule learning problem easy
hard, difficulty making choice magnified richer settings. limited
language described balances extremes providing on, would difficult
derive means, providing predicates inhand clear,
learned.
7.2 Experiments
section describes two sets experiments. First, compare learning deictic,
relational, propositional rules slippery gripper trucks drivers data.
domains modeled planning rules, contain intrinsic constants, noisy,
thus allow us explore effect deictic references constants rules directly.
Then, describe set experiments learns rules model data simulated
blocks world. data inherently noisy contains skolem constants. result,
focus evaluating full algorithm performing ablation studies demonstrate
deictic references, noise outcomes, concepts required effective learning.
experiments use examples, (s, a, s0 ) E, generated randomly constructing
state s, randomly picking arguments action a, executing action
state generate s0 . distribution used construct biased guarantee that,
approximately half examples, chance change state. method
data generation designed ensure learning algorithms always data
representative entire model learn. Thus, experiments
ignore problems agent would face generate data exploring world.
7.2.1 Learning Rule Sets Noise
know model used generate data, evaluate model respect
set similarly generated test examples E calculating average variational distance
true model P estimate P ,
V D(P, P ) =

1 X
|P (E) P (E)| .
|E| EE

Variational distance suitable measure clearly favors similar distributions,
yet well-defined zero probability event observed. (As happen
non-noisy rule learned sparse data many outcomes
should.)
comparisons performed four actions. first two, paint pickup,
slippery gripper domain, second two, drive walk,
trucks drivers domain. action presents different challenges learning. Paint
simple action one outcome lead successor state (as
described Section 4.1). Pickup complex action must represented
344

fiLearning Symbolic Models Stochastic World Dynamics

Paint Action
0.3
0.25

Pickup Action
0.35

Propositional
Relational
Deictic

Variational Distance

Variational Distance

0.35

0.2
0.15
0.1
0.05
0

0.3
0.25
0.2
0.15
0.1
0.05
0

100 200 300 400 500 600 700 800 9001000
Training set size

100 200 300 400 500 600 700 800 9001000
Training set size

Walk Action
0.3
0.25

Drive Action
0.2

Propositional
Relational
Deictic

Variational Distance

Variational Distance

0.35

Propositional
Relational
Deictic

0.2
0.15
0.1
0.05
0

0.15

Propositional
Relational
Deictic

0.1
0.05
0

100 200 300 400 500 600 700 800 900
Training set size

100 200 300 400 500 600 700 800 900
Training set size

Figure 10: Variational distance function number training examples propositional, relational, deictic rules. results averaged ten trials
experiment. test set size 400 examples.

one planning rule. Drive simple action four arguments. Finally, walk
complicated action uses path connectivity world noise model lost
pedestrians. slippery gripper actions performed world four blocks.
trucks driver actions performed world two trucks, two drivers, two
objects, four locations.
compare three versions algorithm: deictic, includes full rules language allow constants; relational, allows variables constants
deictic references; propositional, constants variables. Figure 10
shows results. relational learning consistently outperforms propositional learning;
implies variable abstractions useful. cases except walk action,
deictic learner outperforms relational learner. result implies forcing
rules contain variables preventing overfitting learning better models.
results walk action interesting. Here, deictic learner cannot actually
represent optimal rule; requires noise model complex. deictic learner
quickly learns best rule can, relational propositional learners eventually
345

fiPasula, Zettlemoyer, & Pack Kaelbling

Learning Simulated Blocksworld
18

learned concepts
hand-engineered concepts
without noise outcomes
restricted language

Total Reward

16
14
12
10
8
6
200

300

400

500
600
700
Training set size

800

900

1000

Figure 11: performance various action model variants function number training
examples. data points averaged five planning trials three
rule sets learned different training data sets. comparison, average reward
performing actions 9.2, reward obtained human directed
gripper averaged 16.2.

learn better rule sets use constants accurately model walkers
moving random locations.
experiments, see variable abstraction helps learn less data,
deictic rules, abstract aggressively, perform best, long
represent model learned. next section, consider deictic
rules, since working domain simulated perception
access objects identities names using skolem constants.
7.2.2 Learning Blocks World Simulator
final experiment demonstrates noise outcomes complicated concepts
necessary learn good action models blocks world simulator.
true model known, evaluate learned model using plan
estimating average reward gets. reward function used simulated blocks
world average height blocks world, breadth depth
search sampling planner four. learning, set 0.5 pmin
0.0000001.
tested four action model variants, varying training set size; results
shown Figure 11. curve labeled learned concepts represents full algorithm
presented paper. performance approaches obtained human expert,
comparable algorithm labeled hand-engineered concepts
346

fiLearning Symbolic Models Stochastic World Dynamics

concept learning, was, instead, provided hand-coded versions concepts
clear, inhand, inhand-nil, above, topstack, height. concept learner discovered
these, well useful predicates, e.g., p(X, Y) := clear(Y) on(Y, X),
call onclear. could action models outperformed hand-engineered ones
slightly small training sets. domains less well-studied blocks world, might
less obvious useful concepts are; concept-discovery technique presented
prove helpful.
remaining two model variants obtained rewards comparable reward
nothing all. (The planner attempt act experiments,
poor job.) one variant, used full set predefined concepts rules
could noise outcomes. requirement explain every action effect led
significant overfitting decrease performance. rule set given
traditional blocks world language, include above, topstack, height,
allowed learn rules noise outcomes. also tried full-language variant noise
outcomes allowed, deictic references not: resulting rule sets contained
noisy rules, planner attempt act all. poor performance
ablated versions representation shows three extensions
essential modeling simulated blocks world domain.
human agent commanding gripper solve problem received average
total reward 16.2, theoretical maximum due unexpected action
outcomes. Thus, ND rules performing near-human levels, suggesting
representation reasonable one problem. also suggests planning
approximations learning bounds limiting performance. Traditional rules,
face challenge modeling transitions seen data, much larger
hypothesis space consider learning; surprising generalize poorly
consistently out-performed NDRs.
Informally, also report NDR algorithms execute significantly faster
traditional ones. one standard desktop PC, learning NDRs takes minutes learning
traditional rules take hours. noisy deictic action models generally
compact traditional ones (they contain fewer rules fewer outcomes) planning
much faster well.
get better feel types rules learned, two interesting rules produced
full algorithm.

pickup(X) :

: onclear(X, Y), Z : on(Y, Z),
: table(T)



inhand-nil, size(X) < 2

.80 : on(Y, Z)
.10 : on(X, Y)


.10 : on(X, Y), on(Y, T), on(Y, Z)

rule applies empty gripper asked pick small block X sits
top another block Y. gripper grabs high probability.

347

fiPasula, Zettlemoyer, & Pack Kaelbling


puton(X) :

: topstack(Y, X), Z : inhand(Z),
: table(T)

size(Y) < 2


.62 :

.12 :

.04 :



.22 :



on(Z, Y)
on(Z, T)
on(Z, T), on(Y, T), on(Y, X)
noise

rule applies gripper asked put contents, Z, block X
inside stack topped small block Y. placing things small block chancy,
reasonable probability Z fall table, small probability
follow.

8. Discussion
paper, developed probabilistic action model representation rich enough
used learn models planning physically simulated blocks world.
first step towards defining representations algorithms enable learning
complex worlds.
8.1 Related Work
problem learning deterministic action models well studied. work
area (Shen & Simon, 1989; Gil, 1993, 1994; Wang, 1995) focused incrementally
learning planning operators interacting simulated worlds. However, work
assumes learned models completely deterministic.
Oates Cohen (1996) earliest work learning probabilistic planning operators. rules factored apply parallel. However, representation
strictly propositional, allows rule contain single outcome.
previous work, developed algorithms learning probabilistic relational planning operators (Pasula, Zettlemoyer, & Kaelbling, 2004). Unfortunately, neither probabilistic
algorithms robust enough learn complex, noisy environments like simulated
blocks world.
One previous system comes close goal TRAIL learner (Benson, 1996).
TRAIL learns extended version Horn clauses noisy environments applying inductive logic programming (ILP) learning techniques robust noise. TRAIL
introduced deictic references name objects based functional relationships
arguments actions. deictic references, exists-unique quantification
semantics, generalization Bensons original work. Moreover, TRAIL models continuous actions real-valued fluents, allows represent complex
models date, including knowledge required pilot realistic flight simulator. However, rules TRAIL learns limited probabilistic representation
represent possible transition distributions. TRAIL also include mechanisms
learning new predicates.
348

fiLearning Symbolic Models Stochastic World Dynamics

work action model learning used different versions greedy search
rule structure learning, closely related inspired learning version
spaces Mitchell (1982) later ILP work (Lavrac & Dzeroski, 1994). paper,
also explore, first time, new way moving space rule sets
using noise rule initial rule set. found approach works well
practice, avoiding need hand-selected initial rule set allowing algorithm
learn significantly complex environments.
far know, work learning action models explored learning concepts.
ILP literature, recent work (Assche, Vens, Blockeel, & Dzeroski, 2004) shown
adding concept learning decision tree learning algorithms improves classification
performance.
Outside action learning, exists much related research learning probabilistic
models relational logical structure. complete discussion beyond scope
paper, present highlights. work learns representations
relational extension Bayesian networks. comprehensive example, see work Getoor
(2001). work extends research ILP incorporating probabilistic dependencies.
example, see wide range techniques presented Kersting (2006). Additionally,
recent work learning Markov logic networks (Richardson & Domingos, 2006; Kok
& Domingos, 2005), log-linear models features defined first-order
logical formulae. action models action model learning algorithms paper
designed represent action effects, special case general approaches listed
above. discussed Section 2, tailoring representation match
model learnt, simplify learning.
Finally, let us consider work related NDR action model representation.
relevant approach PPDDL, representation language probabilistic planning operators
problem domains (Younes & Littman, 2004). NDR representation partially
inspired PPDDL operators includes restrictions make easier learn extensions, noise outcomes, required effectively model simulated blocks
world. future, algorithms paper could extended learn full PPDDL
rules. Also, PPDDL planning algorithms (for examples, see papers recent planning
competitions) could adapted improve simple planning presented Section 6.
general sense, NDRs related probabilistic relational representations
designed model dependencies across time. examples, see work relational
dynamic Bayesian networks (Sanghai, Domingos, & Weld, 2005), specialization PRMs, logical hidden Markov models (Kersting, Raedt, & Raiko, 2006),
come ILP research tradition. approaches make different set modeling
assumptions closely tied planning representations NDR models
extend.
8.2 Future Ongoing Work
remains much done context learning probabilistic planning rules.
First all, likely work applied additional domains (such
realistic robotic applications dialogue systems) representation need
adapted, search operators adjusted accordingly. possible changes mentioned
349

fiPasula, Zettlemoyer, & Pack Kaelbling

article include allowing rules apply parallel, different rules could apply
different aspects state, extending outcomes include quantifiers, actions
like walk, trucks drivers domain Section 7.1.2, could described using
single rule. significant change intend pursue expanding approach
handle partial observability, possibly incorporating techniques work
deterministic learning (Amir, 2005). also hope make changes make
using rules easier, associating values noise outcomes help planner
decide whether avoided.
second research direction involves development new algorithms learn probabilistic operators incremental, online manner, similar learning setup
deterministic case (Shen & Simon, 1989; Gil, 1994; Wang, 1995). potential
scale approach larger domains, make applicable even situations
difficult obtain set training examples contains reasonable sampling worlds
likely relevant agent. line work require development
techniques effectively exploring world learning model, much done
reinforcement learning. longer term, would like online algorithms learn
operators concept predicates, also useful primitive predicates motor
actions.

Acknowledgments
material based upon work supported part Defense Advanced Research
Projects Agency (DARPA), Department Interior, NBC, Acquisition
Services Division, Contract No. NBCHD030010; part DARPA Grant No.
HR0011-04-1-0012 .

References
Agre, P., & Chapman, D. (1987). Pengi: implementation theory activity.
Proceedings Sixth National Conference Artificial Intelligence (AAAI).
AIPS (2002). International planning competition. http://www.dur.ac.uk/d.p.long/competition.html.
AIPS (2006). International planning competition. http://www.ldc.usb.ve/bonet/ipc5/.
Amir, E. (2005). Learning partially observable deterministic action models. Proceedings
Nineteenth International Joint Conference Artificial Intelligence (IJCAI).
Assche, A. V., Vens, C., Blockeel, H., & Dzeroski, S. (2004). random forest approach
relational learning. Proceedings ICML Workshop Statistical Relational
Learning Connections Fields.
Benson, S. (1996). Learning Action Models Reactive Autonomous Agents. Ph.D. thesis,
Stanford University.
Bertsekas, D. P. (1999). Nonlinear Programming. Athena Scientific.
Blum, A., & Langford, J. (1999). Probabilistic planning graphplan framework.
Proceedings Fifth European Conference Planning (ECP).
350

fiLearning Symbolic Models Stochastic World Dynamics

Boutilier, C., Reiter, R., & Price, B. (2001). Symbolic dynamic programming first-order
MDPs. Proceedings Seventeenth International Joint Conference Artificial
Intelligence (IJCAI).
Boyen, X., & Koller, D. (1998). Tractable inference complex stochastic processes.
Proceedings Fourteenth Annual Conference Uncertainty AI (UAI).
Brooks, R. A. (1991). Intelligence without representation. Artificial Intelligence, 47.
Draper, D., Hanks, S., & Weld, D. (1994). Probabilistic planning information gathering
contingent execution. Proceedings Second International conference
AI Planning Systems (AIPS).
Edelkamp, S., & Hoffman, J. (2004). PDDL2.2: language classical part 4th
international planning competition. Technical Report 195, Albert-Ludwigs-Universitat,
Freiburg, Germany.
Fikes, R. E., & Nilsson, N. J. (1971). STRIPS: new approach application theorem
proving problem solving. Artificial Intelligence, 2(2).
Getoor, L. (2001). Learning Statistical Models Relational Data. Ph.D. thesis, Stanford.
Gil, Y. (1993). Efficient domain-independent experimentation. Proceedings Tenth
International Conference Machine Learning (ICML).
Gil, Y. (1994). Learning experimentation: Incremental refinement incomplete planning domains. Proceedings Eleventh International Conference Machine
Learning (ICML).
Guestrin, C., Koller, D., Parr, R., & Venkataraman, S. (2003). Efficient solution algorithms
factored MDPs. Journal Artificial Intelligence Research (JAIR), 19.
Kearns, M., Mansour, Y., & Ng, A. (2002). sparse sampling algorithm near-optimal
planning large Markov decision processes. Machine Learning (ML), 49(2).
Kersting, K. (2006). Inductive Logic Programming Approach Statistical Relational
Learning. IOS Press.
Kersting, K., Raedt, L. D., & Raiko, T. (2006). Logical hidden markov models. Journal
Artificial Intelligence Research (JAIR), 25.
Khan, K., Muggleton, S., & Parson, R. (1998). Repeat learning using predicate invention.
International Workshop Inductive Logic Programming (ILP).
Kok, S., & Domingos, P. (2005). Learning structure markov logic networks. Proceedings Twenty Second International Conference Machine Learning (ICML).
Lavrac, N., & Dzeroski, S. (1994). Inductive Logic Programming Techniques Applications. Ellis Horwood.
Mitchell, T. M. (1982). Generalization search. Artificial Intelligence, 18(2).
Oates, T., & Cohen, P. R. (1996). Searching planning operators context-dependent
probabilistic effects. Proceedings Thirteenth National Conference
Artificial Intelligence (AAAI).
ODE (2004). Open dynamics engine toolkit.. http://opende.sourceforge.net.
351

fiPasula, Zettlemoyer, & Pack Kaelbling

Pasula, H., Zettlemoyer, L., & Kaelbling, L. (2004). Learning probabilistic relational planning rules. Proceedings Fourteenth International Conference Automated
Planning Scheduling (ICAPS).
Puterman, M. L. (1999). Markov Decision Processes. John Wiley Sons, New York.
Richardson, M., & Domingos, P. (2006). Markov logic networks. Machine Learning (ML),
62.
Sanghai, S., Domingos, P., & Weld, D. (2005). Relational dynamic bayesian networks.
Journal Artificial Intelligence Research (JAIR), 24.
Shen, W.-M., & Simon, H. A. (1989). Rule creation rule learning environmental exploration. Proceedings Eleventh International Joint Conference
Artificial Intelligence (IJCAI).
Wang, X. (1995). Learning observation practice: incremental approach planning operator acquisition. Proceedings Twelfth International Conference
Machine Learning (ICML).
Yoon, S., Fern, A., & Givan, R. (2002). Inductive policy selection first-order Markov
decision processes. Proceedings Eighteenth Conference Uncertainty
Artificial Intelligence (UAI).
Younes, H. L. S., & Littman, M. L. (2004). PPDDL1.0: extension PDDL expressing
planning domains probabilistic effects. School Computer Science, Carnegie
Mellon University, Technical Report CMU-CS-04-167.
Zettlemoyer, L., Pasula, H., & Kaelbling, L. (2003). Learning probabilistic relational planning rules. MIT Tech Report.

352

fiJournal Artificial Intelligence Research 29 (2007) 191219

Submitted 07/2006; published 06/2007

Language Search
Jinbo Huang

jinbo.huang@nicta.com.au

Logic Computation Program
National ICT Australia

Adnan Darwiche

darwiche@cs.ucla.edu

Computer Science Department
University California, Los Angeles

Abstract
paper concerned class algorithms perform exhaustive search
propositional knowledge bases. show algorithms defines generates
propositional language. Specifically, show trace search interpreted
combinational circuit, search algorithm defines propositional language
consisting circuits generated across possible executions algorithm.
particular, show several versions exhaustive DPLL search correspond
well-known languages FBDD, OBDD, precisely-defined subset d-DNNF.
thus mapping search algorithms propositional languages, provide uniform
practical framework successful search techniques harnessed compilation
knowledge various languages interest, new methodology whereby power
limitations search algorithms understood looking tractability
succinctness corresponding propositional languages.

1. Introduction
Systematic search algorithms lie core wide range automated reasoning systems,
many based procedure branches node search tree
generated splitting possible values chosen variable. One prototypical example
DPLL algorithm (Davis, Logemann, & Loveland, 1962) propositional satisfiability
(SAT). Given propositional formula, problem SAT determine whether
formula satisfying assignmentan assignment Boolean values (0 1)
variables formula evaluates 1. example, (x1 = 0, x2 = 1, x3 = 0)
satisfying assignment following formula: (x1 x2 )(x1 x2 x3 )(x1 x2 x3 ).
determine satisfiability given formula , DPLL chooses variable x
formula, recursively determines whether satisfiable case x set 0, case x
set 1, declares satisfiable precisely least one two cases results
positive answer. effect, algorithm performs systematic search space
variable assignments terminates either finding satisfying assignment,
realizing assignment exists.
Despite simplicity, DPLL long remained basis SAT solvers
employ systematic search (Berre & Simon, 2005), finds natural counterparts
general constraint satisfaction problems, variables restricted
Boolean domain. Several decades sustained research greatly enhanced efficiency
scalability DPLL-based search algorithms, today routinely used solve

c
2007
AI Access Foundation. rights reserved.

fiHuang & Darwiche

practical problems several million variables (Zhang & Malik, 2002). algorithms
successful, indeed, become recent trend areas formal
verification modify produce solutions propositional formula (McMillan,
2002; Chauhan, Clarke, & Kroening, 2003; Grumberg, Schuster, & Yadgar, 2004),
alternative traditional practice (McMillan, 1993) converting formula
ordered binary decision diagram (OBDD) (Bryant, 1986). modifications thus involved
form DPLL search terminate finding first solution,
extended exhaust whole search space. formula shown earlier,
example output exhaustive search could following set three solutions
{(x1 = 0, x2 = 1, x3 = 0), (x1 = 1, x2 = 0, x3 = 0), (x1 = 1, x2 = 1)}. Note solution
defined assignment Boolean values (possibly all) variables
satisfies formula regardless values variables. last solution
set, example, represents two satisfying assignments variable x3 free
assume either value.
Producing solutions propositional formula is, course, one possible
computational tasks exhaustive search useful. tasks include
counting number satisfying assignments formula, also known model counting
(Birnbaum & Lozinskii, 1999; Bayardo & Pehoushek, 2000; Bacchus, Dalmao, & Pitassi,
2003b; Sang, Bacchus, Beame, Kautz, & Pitassi, 2004; Sang, Beame, & Kautz, 2005),
processing certain types queries belief constraint networks (Dechter & Mateescu,
2004b, 2004a).
paper uncover fundamental connection class exhaustive
search algorithms, group propositional languages extensively studied field knowledge compilation (Darwiche & Marquis, 2002). Specifically, show
exhaustive search algorithm based variable splitting, run propositional
knowledge bases, defines generates propositional language precise sense:
trace single search, recorded graph, interpreted combinational
circuit logically equivalent propositional knowledge base search
run; search algorithm defines propositional language consisting
circuits generated legal executions algorithm. show, particular,
exhaustive DPLL corresponds language FBDD (free binary decision diagrams)
(Blum, Chandra, & Wegman, 1980), exhaustive DPLL fixed variable ordering corresponds language OBDD (ordered binary decision diagrams) (Bryant, 1986),
exhaustive DPLL decomposition corresponds well defined subset language
d-DNNF (deterministic decomposable negation normal form) (Darwiche, 2001).
establishment correspondence supplies bridge field knowledge compilation, areas automated reasoning, including propositional satisfiability, search algorithms extensively studied. particular, leads
following two sets theoretical practical benefits.
First, show class search algorithms described immediately
turned knowledge compilers respective propositional languages define,
simply recording trace search. realization provides uniform practical framework successful techniques developed context search
directly used compilation knowledge various languages interest. particular,
discuss recent advances DPLL search, including sophisticated conflict analysis,
192

fiThe Language Search

dependency-directed backtracking, clause learning, new variable ordering heuristics,
data structures faster constraint propagation, harnessed building efficient
practical knowledge compilers.
Second, show how, looking known properties propositional languages,
able answer fundamental level, concrete terms, two important questions
regarding power limitations class search algorithms:
algorithms do? not? Specifically, discuss tractability
propositional language defined search algorithm illustrates power algorithm,
succinctness constraints language illustrate limitations.
complement discussions relating results previous work knowledge compilation recent body work centering notion AND/OR search
(Dechter & Mateescu, 2004b, 2004a; Marinescu & Dechter, 2005). particular, discuss
similarities well differences AND/OR search d-DNNF compilation.
Finally, present experimental results implementations exhaustive search algorithms define distinct propositional languages. use programs compile set
propositional formulas respective languages, demonstrate practicality knowledge compilation framework, empirically illustrate variation
language succinctness response variation search strategy.
remainder paper organized follows. Section 2 reviews number
propositional languages concerned work theoretical roles relations
knowledge compilation. Section 3 discusses DPLL search algorithm propositional
satisfiability exhaustive extension, introduces notion interpreting
trace search combinational circuit. Section 4 detailed exposition mapping
variants exhaustive DPLL FBDD, OBDD, subset d-DNNF, well techniques involved transforming algorithms practical knowledge compilers
respective languages. Section 5 formalizes two fundamental principles relating intrinsic power limitations class exhaustive search algorithms, using recently proposed
model counting algorithms concrete examples. relate results previous work
Section 6, present experimental results Section 7, conclude Section 8. Proofs
theorems given appendix.

2. Propositional Languages Properties
study propositional languages (i.e., representations propositional theories)
central subject knowledge compilation, concerned task converting given knowledge base one language another certain reasoning
tasks become tractable compiled knowledge base (Selman & Kautz, 1991; del Val,
1994, 1995; Marquis, 1995; Selman & Kautz, 1996; Cadoli & Donini, 1997; Darwiche &
Marquis, 2002; Darwiche, 2002, 2004; Coste-Marquis, Berre, Letombe, & Marquis, 2005).
propositional theories compiled language OBDD, example,
equivalence tested time polynomial sizes OBDDs (Meinel &
Theobald, 1998), constant time OBDDs use variable order (Bryant, 1986).
recent applications compilation using language d-DNNF found
fields diagnosis (Barrett, 2004, 2005; Huang & Darwiche, 2005a; Elliott & Williams, 2006;
Siddiqi & Huang, 2007), planning (Barrett, 2004; Palacios, Bonet, Darwiche, & Geffner,
193

fiHuang & Darwiche

(a) NNF

(b) Decision Node



















X







X



(c) Alternatively
X



B

B



C





C





Figure 1: NNF circuit decision node.
2005; Huang, 2006; Bonet & Geffner, 2006), probabilistic reasoning (Chavira & Darwiche,
2005; Chavira, Darwiche, & Jaeger, 2006), query rewrites databases (Arvelo, Bonet,
& Vidal, 2006).
section review set propositional languages discuss established
body results concerning tractability succinctness (Darwiche & Marquis, 2002)
several languages resurface Section 4 exhaustive search
algorithms mapped, properties prove vital formalization Section 5
two fundamental principles relating power limitations exhaustive search
algorithms.
2.1 Propositional Languages
Following conventions Darwiche Marquis (2002), consider graph representations propositional theories, allow sharing subformulas compactness. Specifically, consider directed acyclic graphs (DAGs) internal node labeled
conjunction (and, ) disjunction (or, ), leaf labeled propositional
literal constant (true/f alse, 1/0). clear DAG effectively
combinational circuit and-gates, or-gates, inverters, inverters appear
next inputs (variables), property characteristic Negation Normal Form
(NNF) (Barwise, 1977). hence refer DAGs NNF circuits set
DAGs NNF language. Figure 1a depicts propositional theory represented
NNF circuit. next define interesting subsets NNF language.
popular language CNF (conjunctive normal form) defined
subset NNF satisfies (i) flatness: height DAG two; (ii)
simple-disjunction: disjunction leaf nodes (i.e., clause). Similarly,
DNF (disjunctive normal form) subset NNF satisfies flatness simpleconjunction: conjunction leaf nodes (i.e., term).
consider next set nested representations, starting DNNF (decomposable
negation normal form) language, set NNF circuits satisfying decomposability: conjuncts conjunction share variables. next language, d-DNNF,
satisfies decomposability determinism: disjuncts disjunction pairwise
logically inconsistent. NNF circuit shown Figure 1a, example, d-DNNF;
194

fiThe Language Search

x1





x2


X3

X1

x1

X2

(a) DNNF

x2

x3
x3

x3

x2

0

1

(b) FBDD

x2

0

1

(c) OBDD

Figure 2: circuit DNNF, FBDD, OBDD.
shown Figure 2a, contrast, DNNF d-DNNF neither two
disjunction nodes satisfies determinism.
FBDD language subset d-DNNF root every circuit
decision node, defined recursively either constant (0 1) disjunction
form Figure 1b X propositional variable decision nodes.
Note equivalent compact drawing decision node Figure 1c widely
used formal verification literature, FBDDs equivalently known BDDs
(binary decision diagrams) satisfy test-once property: variable appears
root-to-sink path (Gergov & Meinel, 1994).1 See Figure 2b FBDD
example using compact drawing.
OBDD language subset FBDD circuits satisfy ordering
property: variables appear order root-to-sink paths (Bryant, 1986). See
Figure 2c OBDD example (using compact drawing). particular
variable order <, also write OBDD< denote corresponding OBDD subset
circuits use order <.
2.2 Succinctness Tractability Propositional Languages
Given choice languages knowledge base may represented, one needs
strike balance size representation support provides
reasoning task hand, two properties representation often run counter
other. CNF, example, often convenient compactly encoding knowledge
base since many applications behavior system naturally described
conjunction behaviors components. However, typical reasoning tasks
efficiently carried CNF representations. efficient algorithm determine,
example, whether arbitrary clause entailed CNF formula. story changes
propositional theory represented language known PI (prime implicates,
subset CNF): definition PI supports linear-time clausal entailment test.
downside is, unfortunately, PI representations exponentially larger
CNF equivalents worst case (Karnaugh, 1953; Forbus & de Kleer, 1993).
therefore interested formally analyzing succinctness tractability
languages, given required reasoning task, choose succinct language
1. FBDDs also known read-once branching programs (Wegener, 2000).

195

fiHuang & Darwiche

supports set necessary operations polynomial time. following classical
definition succinctness:
Definition 1. (Succinctness) Let L1 L2 two subsets NNF. L1 least succinct
L2 , denoted L1 L2 , iff exists polynomial p every circuit L2 ,
exists logically equivalent circuit L1 || p(||). Here, || ||
sizes , respectively.
Intuitively, language L1 least succinct language L2 given circuit L2 ,
exists logically equivalent circuit L1 whose size blow up. One also
define L1 strictly succinct L2 , denoted L1 < L2 , L1 L2 L2 6 L1 .
languages described Section 2.1 satisfy following succinctness relations: NNF
< DNNF < d-DNNF < FBDD < OBDD, NNF < CNF, DNNF < DNF (Darwiche &
Marquis, 2002). Note, however, L1 L2 imply L1 < L2 general.
words, imposing conditions representation necessarily reduce succinctness.
One example smoothness, requires disjuncts disjunction mention
set variablesit known condition, imposed d-DNNF, reduce
succinctness (Darwiche & Marquis, 2002).
turn tractability languages, refers set polynomial-time
operations support. According Darwiche Marquis (2002), one traditionally
distinguishes two types operations circuits given language: queries
transformations. difference two queries return information
circuits, normally change them, transformations modify circuits generate
new ones (in language).
known results Darwiche Marquis (2002) regarding tractability languages summarized Table 1 (queries) Table 2 (transformations).
abbreviations first row Table 1 stand following eight queries, respectively:
Consistency (is formula satisfiable), Validity (does formula evaluate 1
variable assignments), Clausal Entailment (does formula imply given clause),
Implicant (is formula implied given term), Equivalence (are two formulas logically equivalent), Sentential Entailment (does one formula imply other),
Model Counting (how many satisfying assignments formula have), Model Enumeration (what satisfying assignments formula). abbreviations
first row Table 2 stand following eight transformations, respectively: Conditioning (setting set variables constants), Forgetting (existentially quantifying set
variables), Single-Variable Forgetting (existentially quantifying single variable), Conjunction (conjoining set circuits), Bounded Conjunction (conjoining bounded
number circuits), Disjunction (disjoining set circuits), Bounded Disjunction
(disjoining bounded number circuits), Negation (negating circuit).
Interestingly, Table 1 offers one explanation popularity OBDDs formal verification efficient equivalence testing, among things, often critical. Although
succinct, d-DNNF FBDD known admit polynomial-time equivalence
test (a polynomial-time probabilistic equivalence test possible; see Blum et al., 1980;
Darwiche & Huang, 2002). Note also although difference d-DNNF
FBDD extent table, question mark equivalence test (EQ) could
eventually resolved differently two languages.
196

fiThe Language Search

Table 1: Polynomial-time queries supported language ( means supported unless
P=NP ? means dont know).
Language
NNF
DNNF
d-DNNF
BDD
FBDD
OBDD
OBDD<
DNF
CNF

CO




VA




CE




IM




































EQ


?

?



SE








CT






























Table 2: Polynomial-time transformations supported language ( means supported, means supported unless P=NP, ? means dont know).
Language
NNF
DNNF
d-DNNF
BDD
FBDD
OBDD
OBDD<
DNF
CNF

CD










FO



SFO











C


BC































C



BC






















C


?







also worth pointing tractability respect queries generally improves language becomes restrictive (has conditions imposed),
tractability respect transformations may not. DNNF, example, supports
subset queries supported OBDD according Table 1, therefore
less tractable OBDD point view. However, comes certain
transformations, operation Forgetting (existential quantification), DNNF becomes tractable OBDD according Table 2. key reason shift
advantage transformations operate circuits given propositional language,
require result languagethis requirement become burden
restrictive language conditions need satisfied result
transformation generated.

197

fiHuang & Darwiche

2.3 Connection Established
summarized discussed section rich body known results concerning
properties various propositional languages. results previously presented
guide task selecting suitable target compilation language applications
knowledge compilation. particular, suggest given reasoning task involving
knowledge compilation, one identify set operations required task,
select succinct target compilation language supporting operations (Darwiche
& Marquis, 2002).
following sections paper, wish establish fundamental connection
propositional languages distinct degrees succinctness tractability,
exhaustive search algorithms running distinct sets constraints. Specifically,
show trace exhaustive search interpreted circuit representing
compilation propositional knowledge base search run, search
algorithm defines propositional language consisting possible traces.
connection serve bridge field knowledge compilation
areas automated reasoning search algorithms extensively
studied, affording two related sets benefits follows.
first direction, show connection provides set practical algorithms
compilation knowledge various languages. Specifically, exhaustive search
algorithm directly turned knowledge compiler recording trace
execution graph, variations search algorithm nicely correspond
compilers different propositional languages. framework knowledge compilation
provides significant advantage many (past well future) advances search
automatically carry knowledge compilation. particular, discuss
knowledge compilers capitalize several important recent advances DPLL search
propositional satisfiability, including sophisticated conflict analysis, dependency-directed
backtracking, clause learning, new variable ordering heuristics, data structures faster
constraint propagation.
second direction, formulate two principles whereby intrinsic power
limitations given exhaustive search algorithm understood identifying
propositional language defined search algorithm. Specifically, tractability
language illustrates power (usefulness) search algorithm succinctness
constraints language illustrates limitations. Using group recently
proposed model counters concrete examples, show search algorithms used
model counters powerful enough support model counting query,
queries known tractable language d-DNNF,
probabilistic equivalence test (Darwiche & Huang, 2002). hand, two fundamental limitations identified algorithms, well exhaustive
search algorithms based variable splitting, first traces restricted
subset d-DNNF, potentially limiting efficiency search, second
inability produce traces without determinism, making overly constrained
compilation knowledge general languages d-DNNF, DNNF.

198

fiThe Language Search

proceed uncover connection search algorithms propositional
languages, starting systematic search algorithm propositional satisfiability,
exhaustive extension, notion trace search.

3. Systematic Search Satisfiability Exhaustive Extension
section introduce notion trace systematic exhaustive search,
show trace interpreted circuit, logically equivalent (and hence
compilation of) propositional knowledge base search run.
context systematically searching satisfying assignments propositional
formula, major approach problem propositional satisfiability (SAT)
come known DPLL (Davis et al., 1962).
3.1 DPLL Search Exhaustive Extension
Algorithm 1 summary DPLL SAT, takes propositional formula CNF,
return 1 (0) precisely formula satisfiable (unsatisfiable). works recursively case analysis assignment selected variable (Line 5): formula
satisfiable either case results satisfiable subformula (Line 6). two
subformulas denote |x=0 |x=1 , result replacing occurrences
x 0 1, respectively. keeping rules Boolean logic, assume
literal becomes evaluates 0 result variable instantiation,
removed every clause contains it; literal becomes evaluates 1,
clauses contain removed. (To facilitate subsequent discussion variants
DPLL, omitted use unit resolution pseudocode. programs
used Section 7, however, employ unit resolution.) effect, Algorithm 1 performs
search space variable assignments finds one satisfies given CNF
formula realizes satisfying assignments exist.
consider extending Algorithm 1 go space satisfying assignmentsby always exploring branches Line 6rather terminate finding first one. Figure 3a depicts search tree exhaustive version DPLL, particular variable ordering, following CNF formula:
(x1 x2 ) (x1 x2 x3 ) (x1 x2 x3 ). Note drawing branches
search use dotted (solid) line denote setting variable 0 (1)we also refer
corresponding child search node low (high) child.
Algorithm 1 DPLL(CNF: ): returns satisfiability
1: empty clause
2:
return 0
3: variables
4:
return 1
5: select variable x
6: return DPLL(|x=0 ) DPLL(|x=1 )

199

fiHuang & Darwiche



x1


x1
x2



x2

unsat


sat

x3
unsat

0 x2

unsat




x2


x2


x3
sat


x1

x2 1





0 x3 x3 1 0 x3 x3 1
(b) Equivalent NNF circuit

sat

(a) Termination tree

Figure 3: trace exhaustive DPLL search.
tree depicted Figure 3a also known termination tree search,
captures set paths search space explored
termination search. particular, leaf tree labeled sat gives
partial variable assignment satisfies propositional formula regardless values
unassigned variables, whole tree characterizes precisely set satisfying
assignments, algorithm set find succeeded finding.
3.2 Trace Search Issue Redundancy
alluded earlier, would like view termination tree trace
search, make two important observations: First, trace
search depicted Figure 3a directly translated circuit NNF depicted
Figure 3b. involved rename sat/unsat 1/0 invoke identity
Figure 1b Figure 1c described Section 2.1. Second, NNF circuit
logically equivalent to, hence compilation of, CNF formula
search run. (Note notion trace different used earlier work
establish power DPLL proof system unsatisfiable CNF formulas.
example, earlier work shown unsatisfiable CNF formula, trace
DPLL converted tree-like resolution refutation (Urquhart, 1995).)
two observations imply exhaustive DPLL powerful knowledge
compiler, long one takes (small) trouble recording trace. viewpoint
knowledge compilation, however, search trace recorded present form may
immediately useful, typically size proportional amount work
done produce it. Answering even linear-time query (which may require single
traversal compiled representation) compilation, example, would
one running whole search again.
problem remedied first realizing quite bit redundancy
search trace drawn. Figure 3a, example, two subgraphs whose
roots labeled x3 isomorphic could merged one.
redundancy, course, present corresponding portions NNF circuit
shown Figure 3b.
200

fiThe Language Search

distinguish two levels dealing issue redundancy trace.
first level, remove redundancy trace reducing tree
DAG, repeated applications following two rules: (i) Isomorphic nodes (i.e.,
nodes label, low child, high child) merged; (ii)
node identical children deleted pointers redirected either one
children (Bryant, 1986). apply reduction rules tree Figure 3a (again
renaming sat/unsat 1/0), get DAG shown Figure 2c (in particular
example second rule apply). Note instead performing reduction
end search two reduction rules suggest, better integrating
rules trace recording process redundant portions trace
recorded first place. brings us technique known unique nodes (Brace,
Rudell, & Bryant, 1991; Somenzi, 2004), discuss detail next section.
Removing redundancy level ensures smallest possible compilation obtained given particular execution search algorithm; however, improve
time complexity search itself. Figure 3a, example, reason
two isomorphic subgraphs (rooted nodes labeled x3 ) first place
search run equivalent subproblems different paths. general case
nontrivial subproblems, solving one source great inefficiency. therefore refer second level dealing issue redundancy,
would like able recognize equivalence subproblems avoid carrying
computation again. done using technique
formula caching (Majercik & Littman, 1998), also discuss following section.

4. Language Search
established Section 3 notion interpreting trace exhaustive search
circuit. section continue study search algorithms showing
defines propositional language consisting possible traces. look
three algorithms particular: (i) original exhaustive DPLL, (ii) exhaustive DPLL
fixed variable ordering, (iii) exhaustive DPLL decomposition. algorithm
discuss propositional language defines, corresponding knowledge compiler
provides, well issues regarding efficiency knowledge compiler.
4.1 Mapping Exhaustive DPLL FBDD
seen Section 3 application reduction rules, trace exhaustive
DPLL example, depicted Figure 3a, stored compactly Figure 2c,
none circuit language FBDD (which happens also
OBDD case).
formally show traces exhaustive DPLL across possible executions
algorithm form propositional language precisely language (reduced)
FBDD defined Section 2 (from assume circuits FBDD
OBDD always given reduced form application two reduction rules).
order first need formalism explicitly recording trace search
graph. purpose introduce Algorithm 2, exactly exhaustive
extension original DPLL (Algorithm 1) except newly introduced function,
201

fiHuang & Darwiche

get-node (given Algorithm 3), provides means recording trace search
form DAG. Specifically, get-node return decision node (in form
Figure 1b) labeled first argument, second argument low child,
third argument high child (Lines 2&4 also modified
return terminal decision nodes, instead Boolean constants). Note that,
briefly mentioned Section 3, algorithm trace recorded directly
reduced from, instead producing redundant nodes removed later.
two reduction rules built means unique nodes table, well known
BDD community (Brace et al., 1991; Somenzi, 2004). Specifically, nodes created
get-node stored hash table get-node create new node (i) node
created already exists table (that existing node returned); (ii) second
third arguments (either argument returned). formally state
result follows:
Theorem 1. DAGs returned Algorithm 2 form language (reduced) FBDD.
Theorem 1 immediately provides us CNF-to-FBDD compiler, means
soon search finishes, answer polynomial time query
propositional theory, long query known tractable FBDD. According
Table 1, queries include consistency, validity, clausal entailment, implicant, model
counting, model enumeration. According Blum et al. (1980), one also
test equivalence two propositional formulas probabilistically polynomial time
running Algorithm 2 both. hand, propositional theory given Algorithm 2 known polynomial-size representation FBDD, also conclude
algorithm able finish polynomial time matter variable
ordering uses.
make Algorithm 2 practical FBDD compiler, need deal issue
redundant computation briefly mentioned Section 3. reason that, despite
use unique nodes controls space complexity, Algorithm 2 still time
complexity proportional size tree version search trace: Portions
DAG end explored multiple times. See Figure 4 example,
two different instantiations first three variables lead subformula,
would compiled twice, unnecessarily, Algorithm 2. alleviate problem,
one resorts technique formula caching (Majercik & Littman, 1998).
Algorithm 4 describes exhaustive DPLL search, caching.
result recursive call DPLLf () stored cache (Line 10) returned,
indexed key (computed Line 5) identifying ; subsequent call 0
Algorithm 2 dpllf (CNF: ): exhaustive DPLL
1: empty clause
2:
return 0-sink
3: variables
4:
return 1-sink
5: select variable x
6: return get-node(x, dpllf (|x=0 ), dpllf (|x=1 ))
202

fiThe Language Search

x5

x6

X1

0
x4

x5

x1

x3

x2

x3

x1

x2

1

x6
x4

x5

X2

1

0

X3
x3
x5
x4

X2

X3
1

1

x6
x5 x6

x4

x5

x6
x5 x6

Figure 4: Reaching subformula via different paths search.
immediately return existing compilation cache (Line 7) 0 found
equivalent (by key comparison Line 6). (Note introduction caching
change identity proposition language defined algorithm.
words, Theorem 1 applies Algorithm 4 well.)
practice, one normally focuses efficiently recognizing formulas syntactically
identical (i.e., set clauses). Various methods proposed
purpose recent years, starting Majercik Littman (1998) used caching
probabilistic planning problems, followed Darwiche (2002) proposed concrete
formula caching method context knowledge compilation, Bacchus, Dalmao,
Pitassi (2003a) Sang et al. (2004) context model counting,
Darwiche (2004) Huang Darwiche (2005b) proposed refinements
method Darwiche (2002).
4.2 Mapping Exhaustive DPLL Fixed Variable Ordering OBDD
Note Algorithm 4, DPLL free choose variable branch (Line 8).
corresponds use dynamic variable ordering heuristic typical SAT solver,
keeping spirit free binary decision diagrams (FBDD).
surprisingly, one switches dynamic static variable ordering, DAGs
produced algorithm restricted subset FBDD. Algorithm 5 implements
change, taking particular variable order second argument, making sure
order enforced choosing next branching point (see Line 8). Across
possible inputs variable orderings, algorithm indeed produce exactly set
circuits language (reduced) OBDD:
Algorithm 3 get-node(int: i, BDD: low, BDD: high)
1: low high
2:
return low
3: node (i, low, high) exists unique-table
4:
return unique-table[(i, low, high)]
5: result = create-bdd-node(i, low, high)
6: unique-table[(i, low, high)] = result
7: return result
203

fiHuang & Darwiche

Theorem 2. DAGs returned Algorithm 5 form language (reduced) OBDD.
therefore provided CNF-to-OBDD compiler Algorithm 5, means
soon search finishes, answer polynomial time query
propositional theory, long query known tractable OBDD.
notably, test equivalence two propositional formulas deterministically
polynomial time running Algorithm 5 both, could Algorithm 2
Algorithm 4. hand, propositional theory given Algorithm 5
known polynomial-size representation OBDD, hidden weighted bit
function (Bryant, 1991), also conclude algorithm able finish
polynomial time matter variable ordering uses.
make Algorithm 5 practical OBDD compiler, need deal issue
redundant computation. Naturally, general formula caching method, ones
described earlier, applicable Algorithm 5. constrained search
algorithm, however, special method available shorter cache keys used
reduce cost manipulation. reader referred Huang Darwiche
(2005b) details method, allows one bound number distinct cache
keys, therefore providing space time complexity bound. particular,
specific caching scheme force, space time complexity Algorithm 5
shown exponential cutwidth given CNF formula. variant caching
scheme allows one show parallel complexity terms pathwidth (cutwidth
pathwidth comparable).
emphasize Algorithm 5 represents distinct way OBDD construction,
contrast standard method widely adopted formal verification one recursively
builds OBDDs components system (or propositional formula) compiled
combines using Apply operator (Bryant, 1986). well-known problem
latter method intermediate OBDDs arise process grow large
make manipulation impossible, even final result would tractable
size. Considering final OBDD really one after, Algorithm 5 affords
solution problem building exactly it, less (although may
work linear OBDD size, inconsistent subproblems
contribute OBDD size, caching complete). empirical
Algorithm 4 DPLLf (CNF: ): exhaustive DPLL caching
1: empty clause
2:
return 0-sink
3: variables
4:
return 1-sink
5: key = compute-key()
6: exists cache entry (key, result)
7:
return result
8: select variable x
9: result = get-node(x, DPLLf (|x=0 ), DPLLf (|x=1 ))
10: cache-insert(key, result)
11: return result
204

fiThe Language Search

ABC
ADE
BC
DE






BC



B C
E






DE

B



B





C




B

E
0






C

1

(a) Mixture decision conjunction nodes






B
E

(b) Equivalent NNF circuit

Figure 5: Trace exhaustive DPLL decomposition.
comparison compilation algorithm traditional OBDD construction method
found Huang Darwiche (2005b).
4.3 Mapping Exhaustive DPLL Decomposition Subset d-DNNF
observed, particular case model counting, efficiency exhaustive DPLL improved introducing decomposition, also known component
analysis (Bayardo & Pehoushek, 2000; Bacchus et al., 2003b; Sang et al., 2004, 2005).
idea propositional formula breaks conjunction disjoint subformulas (i.e., share variables), subformula processed separately
results combined.
Algorithm 6 implements decomposition exhaustive DPLL relaxing constraint
Algorithm 4: Immediately Line 8 Algorithm 4, need insist
case analysis performed variable x formula; instead, examine
current formula, attempt decompose (Line 5) subsets share
Algorithm 5 DPLLo (CNF: , order: ): exhaustive DPLL fixed variable ordering
1: empty clause
2:
return 0-sink
3: variables
4:
return 1-sink
5: key = compute-key()
6: exists cache entry (key, result)
7:
return result
8: x = first variable order appears
9: result = get-node(x, DPLLo (|x=0 , ), DPLLo (|x=1 , ))
10: cache-insert(key, result)
11: return result
205

fiHuang & Darwiche

variable (we assume process nondeterministic; is, detect
decomposition points). search run subformulas separately
recursively (Lines 79), separate subtraces result connected
means and-node indicate results recursive call combined
(Line 10). case decomposition performed (Line 6 fails), branch selected
variable regular DPLL (Lines 14&15).
Figure 5a shows result example execution algorithm, instantiation first variable breaks CNF formula two disjoint clauses,
processed separately results combined and-node. Figure 5b shows
trace drawn equivalently explicit NNF circuit (for ease viewing constants
removed decision nodes bottom compacted corresponding literals
represent).
witnessed, use decomposition exhaustive DPLL resulted
new type node trace, returned get-and-node Line 10 Algorithm 6.
old get-node function (Line 15) still returns decision nodes (in relaxed sense,
children necessarily decision nodes) form Figure 1c. unique nodes
technique also extended straightforward way isomorphic and-nodes,
well duplicate children and-node, created.
ready discuss proposition language defined Algorithm 6,
purpose first define following subset d-DNNF language, determinism
fulfilled means decision nodes (again, relaxed sense):
Definition 2. language decision-DNNF set d-DNNF circuits
disjunction nodes form Figure 1b, (x ) (x ), x variable.2
2. Note that, unlike FBDD, either conjunction disjunction node.

Algorithm 6 DPLLd (CNF: ): exhaustive DPLL decomposition
1: empty clause
2:
return 0-sink
3: variables
4:
return 1-sink
5: components = exhaustive partitions disjoint variable sets
6: |components| > 1
7:
conjuncts = {}
8:
c components
9:
conjuncts = conjuncts {DPLLd (c )}
10:
return get-and-node(conjuncts)
11: key = compute-key()
12: exists cache entry (key, result)
13:
return result
14: select variable x
15: result = get-node(x, DPLLd (|x=0 ), DPLLd (|x=1 ))
16: cache-insert(key, result)
17: return result
206

fiThe Language Search

formally state result (again, assume circuits always given
reduced form application appropriate reduction rules described earlier,
although allowed redundancy figures ease viewing):
Theorem 3. DAGs returned Algorithm 6 form language (reduced) decision-DNNF.
hence provided CNF-to-decision-DNNF compiler Algorithm 6,
serve d-DNNF compiler practice since decision-DNNF d-DNNF. means
search finishes, answer polynomial time query input
propositional formula, long query known tractable language dDNNF (see Table 1). hand, Algorithm 6 able finish polynomial
time propositional theory polynomial-size representation dDNNF (and decision-DNNF), matter variable ordering decomposition method
uses.
Again, one needs implement form formula caching make Algorithm 6
practical compiler. Several caching methods proposed d-DNNF compilation,
latest effective appeared Darwiche (2004). However, refer
reader Darwiche (2001) caching scheme specific decomposition method
based known dtrees (which discuss next). scheme effective
one Darwiche (2004) former may miss equivalences would
caught latter, yet allows one show space time complexity Algorithm 6, caching scheme force, exponential treewidth
CNF formula (as compared pathwidth cutwidth OBDD compilation discussed
Section 4.2). Considering model counting linear-time query supported
d-DNNF language, results Darwiche (2001) also imply DPLL decomposition (such Algorithm 6) used count models time space complexity
exponential treewidth CNF formula; see Bacchus et al. (2003a)
alternative derivation complexity result. Interestingly, similar structure-based
measure complexity appears known FBDD compilation.
Finally, would like briefly discuss distinction two possible methods
decomposition. Algorithm 6 suggests dynamic notion decomposition, disjoint
components recognized variable split. dynamic decomposition
initially proposed utilized Bayardo Pehoushek (2000) model counting
adopted recent model counters (Sang et al., 2004, 2005). Darwiche (2002, 2004)
proposed another method performing decomposition less dynamically preprocessing CNF formula generate dtree (decomposition tree), binary tree
whose leaves correspond clauses CNF formula. node dtree defines
set variables, called cutset, whose instantiation guaranteed decompose
CNF formula node disjoint components. rationale cost
dynamically computing partition (Line 5 Algorithm 6) many times search
replaced lesser cost computing static recursive partition
all. method decomposition allows one provide structure-based computational
guarantees discussed above. Moreover, instantiation variables cutset
performed dynamically, utilizing dynamic variable ordering heuristics typically done
SAT solvers. use dtrees, combined dynamic variable ordering, leads
almost static behavior highly structured problems, cutsets small. Yet, one
207

fiHuang & Darwiche

sees dynamic behavior less structured problems, random 3-SAT,
cutsets relatively large dynamic variable ordering tends dominate. Interestingly, static behavior dtrees (low overhead) orders magnitude efficient
purely dynamic behavior structured benchmarks, including ISCAS85 circuits.
hand, dynamic behavior dtrees lead competitive results
unstructured benchmarks, including random 3-SAT. One may obtain results effect
running model counter Sang et al. (2004), Cachet Version 1.1, d-DNNF
compiler Darwiche (2004), c2d Version 2.2, relevant benchmarks. noted
two programs differ aspects, decomposition method appears
one major differences.
4.4 Harnessing Search Techniques Knowledge Compilation
Research recent years greatly improved efficiency scalability systematic
search methods, particularly problem propositional satisfiability. Techniques contributing improvement include sophisticated conflict analysis, dependencydirected backtracking, clause learning, new variable ordering heuristics, data structures
faster constraint propagation, among things (Marques-Silva & Sakallah, 1996;
Marques-Silva, 1999; Aloul, Markov, & Sakallah, 2001; Moskewicz, Madigan, Zhao, Zhang,
& Malik, 2001; Zhang, Madigan, Moskewicz, & Malik, 2001; Goldberg & Novikov, 2002;
Zhang & Malik, 2002; Heule & van Maaren, 2004). hand, described
section uniform framework systematic search algorithms converted
knowledge compilers exhausting search space recording trace search.
framework affords opportunity many successful search techniques
carry knowledge compilation. refer reader Bayardo Pehoushek (2000),
Darwiche (2002, 2004), Huang Darwiche (2005b), Sang et al. (2004, 2005) detailed discussions issues arise implementation techniques
search extended exhaustion, trace search needs stored,
decomposition introduced.
Finally, note efficiency search addressed techniques (including caching particular) important practical issue, orthogonal
language generated search, main focus present paper. simple
example, one may two versions Algorithm 5 drastically different running
times input one much better caching method,
end day, bound produce exactly OBDD due canonicity
OBDDs. another example, learned clause provided conflict analysis reduce
number search nodes, affect final DAG (circuit) generated,
nodes avoided correspond contradictions (the constant 0) would
appear DAG anyway due reduction rules.

5. Power Limitations Exhaustive Search Algorithms
Sections 3 4 established notion interpreting trace exhaustive
search circuit, mapping search algorithm propositional language
consisting possible traces. notion provides new perspective intrinsic
power limitations search algorithms, illustrated Section 4
208

fiThe Language Search











B

C




C



B B
(a) General determinism




B

(b) Nondeterminism

Figure 6: DPLL unable produce general determinism nondeterminism.
discussing usefulness search algorithms knowledge compilers inherent
inefficiency certain classes inputs. section formalize
concepts illustrate using examples real implementations exhaustive
search algorithms.
Consider arbitrary exhaustive search algorithm based variable splitting, call
DPLLx , suppose traces form propositional language Lx . intrinsic power
limitations DPLLx identified following two principles, respectively:
1. DPLLx runs polynomial time class formulas, DPLLx (with trace
recorded) answer polynomial time query formulas known
tractable language Lx .
2. DPLLx run polynomial time formulas polynomial-size
representations exist Lx .
Take example model counters recently proposed Bayardo Pehoushek
(2000) Sang et al. (2004, 2005), employ techniques decomposition
(the latter also) formula caching. simple analysis model counters shows
traces language decision-DNNF.3 consider query testing
whether minimization theory implies particular clause , min() |= ,
min() defined theory whose models exactly minimum-cardinality models
. query heart diagnostic nonmonotonic reasoning known
tractable d-DNNF. Applying first principle above, noting decisionDNNF d-DNNF, conclude query answered polynomial time
class formulas model counters Bayardo Pehoushek (2000) Sang
et al. (2004, 2005) polynomial time complexity. Similarly, probabilistic equivalence
test performed polynomial time formulas models counters
polynomial time complexity.
example second principle above, first note neither
model counters finish polynomial time formulas polynomial-size
representations exist decision-DNNF. Furthermore, recall decision-DNNF defined
Definition 2 strict subset d-DNNF: Every disjunction decision-DNNF circuit
3. See DDP algorithm Bayardo Pehoushek (2000) Table 1 Sang et al. (2004).
example, variable splitting (Lines 59) Table 1 Sang et al. (2004) corresponds generation
decision node, ToComponents function (Line 6 Line 8) corresponds generation
and-node satisfies decomposability.

209

fiHuang & Darwiche

form (x ) (x ), d-DNNF allows disjunctions form
logically inconsistent, yet contradict particular
variable (Figure 6a gives one example). Recall also model counting query remains
tractable one generalizes decision-DNNF d-DNNF. decision-DNNF turns
succinct d-DNNF, therefore, one may find another generation model
counters, well d-DNNF compilers exponentially efficient
current ones.
Finally, note DPLL traces inherently bound NNF circuits
deterministic decomposable. Decomposability alone, however, sufficient
tractability important tasks clausal entailment testing, existential quantification variables, cardinality-based minimization (Darwiche & Marquis, 2002). DPLL
cannot generate traces DNNF d-DNNF (Figure 6b example), since
variable splitting (the heart DPLL) amounts enforcing determinism. property determinism provides power needed model counting (#SAT),
essential applications probabilistic reasoning. one need
power, one go beyond DPLL-based procedures; otherwise one would solving
harder computational problem necessary.

6. Relation Previous Work
employed notion trace search paper provide theoretical
practical channel advances systematic search knowledge compilation. channel indeed active time, implicitly mostly one
direction: systematic search algorithms employed compile knowledge bases (see,
example, Darwiche, 2002, 2004; Huang & Darwiche, 2005b; Darwiche, 2005). fact,
techniques variable ordering, decomposition, caching extensively
used bodies work, used (some recently) pure search
algorithms.
key contribution paper formally explicating notion search
trace, proposing basis systematic framework compiling knowledge
bases subsets NNF. contrasted earlier systematic studies
NNF (Darwiche & Marquis, 2002), concerned describing various
properties compiled NNF representations without delving algorithmic nature
generating them. Another key contribution paper activating second
direction search/compilation channel: looking language membership search
traces formally characterize power limitations various search algorithms.
recent line work, centering notion AND/OR search,
also concerned understanding power limitations various search techniques,
decomposition caching, measuring size explored search spaces (Dechter
& Mateescu, 2004b, 2004a; Marinescu & Dechter, 2005). premise work
traditional search algorithms (based branching) thought exploring
ORsearch space, recent search algorithms (employing decomposition) thought
exploring AND/ORsearch space. Here, space AND/OR search characterized graph (or tree caching used) alternating layers AND-nodes
OR-nodes, former representing decomposition latter branching. algorithms
210

fiThe Language Search

exploring AND/ORsearch space therefore exhibit behavior similar Algorithm 6, used compiling CNF d-DNNF (Darwiche, 2002, 2004, 2005)), except
Algorithm 6 records AND/ORsearch space explicitly circuit. Hence, AND/OR
search Algorithm 6 share limitations discussed DPLL: cannot take
advantage general notion determinism, rid determinism altogether.
note proposed algorithms AND/OR search proceed instantiating variables performing decomposition according pseudo tree (Freuder & Quinn,
1985), earlier work d-DNNF compilation uses decomposition tree two
tasks (corresponding choices Lines 5 14 Algorithm 6). Pseudo trees decomposition trees similar provide scheme instantiation
certain set variables lead decomposition problem. framework
proposed paper, however, make commitment either decomposition
variable ordering scheme, relevant discussion. One note
though commitment particular decomposition variable ordering scheme
significant practical implications. Specifically, search algorithm whose trace
d-DNNF may performing variable ordering decomposition way
prohibit possibility generating certain (space efficient) d-DNNF circuits.
Finally, one identify major difference AND/OR search d-DNNF
compilation, terms handling queries: execution AND/OR search
algorithm answers single query, executing d-DNNF compilation algorithm
results compact structure used repeatedly answer queries (for
knowledge base) known tractable. discussed earlier, traversing
compiled structure potentially much efficient repeating search
produced it. point view, separation search actual reasoning
task provides benefit amortizing search effort potentially large number
queries. also provides, discussed, systematic methodology
independent advances search harnessed improve performance automated
reasoning systems.

7. Experimental Results
way experimentation, ran implementations Algorithm 5 using MINCE variable ordering heuristic (Aloul et al., 2001), Algorithm 4 using VSIDS variable ordering
heuristic (Moskewicz et al., 2001), Algorithm 6 using static decomposition hypergraph partitioning (Darwiche & Hopkins, 2001), compile set CNF formulas
OBDD, FBDD, d-DNNF, respectively (implementation details first third
programs found Huang & Darwiche, 2005b Darwiche, 2004). goal
experiments show practicality search-based compilation framework
illustrate improvement language succinctness response relaxation
constraints search process. benchmarks used include random 3-CNF
graph coloring problems Hoos Stutzle (2000), set ISCAS89 circuits.
results experiments shown Table 3, running times
given seconds based 2.4GHz CPU. size compilation reflects number
edges NNF DAG. dash indicates compilation succeed given
available memory (4GB) 900-second time limit. seen
211

fiHuang & Darwiche

Table 3: Compiling CNF OBDD, FBDD, d-DNNF.
CNF
Name
uf75-01
uf75-02
uf75-03
uf100-01
uf100-02
uf100-03
uf200-01
uf200-02
uf200-03
flat75-1
flat75-2
flat75-3
flat100-1
flat100-2
flat100-3
flat200-1
flat200-2
flat200-3
s820
s832
s838.1
s953
s1196
s1238
s1423
s1488
s1494

Number
Models
2258
4622
3
314
196
7064
112896
1555776
804085558
24960
774144
25920
684288
245376
11197440
5379314835456
13670940672
15219560448
8388608
8388608
73786976294838206464
35184372088832
4294967296
4294967296
2475880078570760549798248448
16384
16384

OBDD
Size
Time
10320
0.14
22476
0.15
450
0.02
2886
2.22
1554
0.91
12462
0.78
8364
651.04




23784
0.16
13374
0.28
84330
0.29
62298
0.78
88824
1.57
15486
0.15






1372536 72.99
1147272 76.55
87552
0.24
2629464 38.81
4330656 78.26
3181302 158.84


6188427 50.35
3974256 31.67

FBDD
Size
Time
3684
0.02
14778
0.04
450
0.02
2268
0.01
1164
0.07
9924
0.12
7182
35.93
12900
33.72
662238 56.61
10758
0.04
8844
0.04
26472
0.07
37704
0.10
39882
0.30
21072
0.09


134184 7.07
358092 4.13
364698 0.69
362520 0.70


1954752 4.01
4407768 12.49
4375122 12.14


388026 1.14
374760 1.07

d-DNNF
Size
Time
822
0.02
1523
0.03
79
0.01
413
0.02
210
0.04
1363
0.02
262
3.66
744
2.64
86696 10.64
2273
0.01
1838
0.01
4184
0.04
3475
0.03
6554
0.09
2385
0.02
184781 56.86
9859 23.81
9269
3.28
23347
0.07
21395
0.05
12148
0.02
85218
0.26
206830 0.44
293457 0.94
738691 4.75
51883
0.19
55655
0.18

instances, compilation smallest d-DNNF, FBDD, OBDD;
similar relation observed among running times. Also, number instances
successfully compiled largest d-DNNF, FBDD, OBDD. tracks
well theoretical succinctness relations three languages. (However, note
FBDD d-DNNF canonical representations therefore compilations smaller
reported perfectly possible; smaller OBDD compilations are, course, also
possible different variable orderings.)
close section noting implementations knowledge compilers
bear witness advantage search-based compilation framework described
Section 4. first compiler based existing SAT solver (Moskewicz et al.,
2001), two implementation DPLL, three benefiting
techniques found success SAT, including conflict analysis, clause learning,
data structures efficient detection unit clauses.

212

fiThe Language Search

8. Conclusion
work concerned class exhaustive search algorithms run propositional knowledge bases. proposed novel methodology whereby trace search
identified combinational circuit search algorithm mapped propositional language consisting possible traces. mapping leads uniform
practical framework compilation propositional knowledge bases various languages
interest, time provides new perspective intrinsic power limitations exhaustive search algorithms. interesting examples, unveiled hidden
power several recent model counters, discussed one potential limitations,
pointed inability class algorithms produce traces without property
determinism, limits power knowledge compilation point view.
discussed generality results relation recent work AND/OR
search. Finally, presented experimental results demonstrate practicality
search-based knowledge compilation framework illustrate variation language
succinctness response variation search strategy.

Acknowledgments
Parts work presented DPLL Trace: SAT Knowledge
Compilation, Proceedings 19th International Joint Conference Artificial Intelligence (IJCAI), 2005, pages 156162. thank Rina Dechter anonymous reviewers
feedback earlier drafts paper. work partially supported
NSF grant IIS-9988543, MURI grant N00014-00-1-0617, JPL/NASA contract 442511DA-57765. National ICT Australia funded Australian Governments Backing
Australias Ability initiative, part Australian Research Council.

Appendix
Proof Theorem 1
first point recursion guaranteed terminate recursive call
(Line 6) accompanied disappearance one variable eventually either Line 2
Line 4 execute. Assuming compact drawing decision nodes Figure 1c,
show every DAG returned Algorithm 2 FBDD, every FBDD
generated execution Algorithm 2.
Part I: three return statements Algorithm 2: Lines 2, 4, 6. single
nodes returned Lines 2 4 trivial FBDDs. DAG returned get-node
Line 6, call G, decision node induction level recursion. Hence remains
show G satisfies test-once property (equivalent decomposability case
discussed Section 2.1), true Line 6, variable x replaced
constants two recursive calls, hence cannot appear two graphs
supplied second third arguments get-node. Finally, FBDDs returned
algorithm guaranteed reduced use unique nodes technique
get-node function (Brace et al., 1991).

213

fiHuang & Darwiche

Part II: Let G denote arbitrary (reduced) FBDD, also root node. Define
following function (G) returns CNF formula (as set clauses) every G:


{the empty clause},




{},
(G)

{x c | c (G.low)} {x c | c (G.high)},



G 0-sink;
G 1-sink;
otherwise, node G
labeled variable x.

last line definition above, assume literal x (and x) always appended
front clause c. execute Algorithm 2 (G), Line 5 always choose
first variable clause (the first variable every clause must same).
DAG returned isomorphic G.
Proof Theorem 2
show every DAG returned Algorithm 5 OBDD, every OBDD
generated execution Algorithm 5.
Part I: First, DAG returned Algorithm 5 FBDD Algorithm 5
restricted version Algorithm 2. Second, DAG OBDD nonterminal
node N DAG must constructed Line 9, therefore virtue Line 8 satisfies
following property: variable x labels N appears variables
two subgraphs N variable order . Finally, OBDDs returned algorithm
guaranteed reduced use unique nodes technique get-node
function (Brace et al., 1991).
Part II: Given arbitrary (reduced) OBDD G, let variable order G.
using (G) defined previous proof, execute Algorithm 5 ((G), ). DAG
returned isomorphic G.
Proof Theorem 3
show every DAG returned Algorithm 6 decision-DNNF circuit,
every decision-DNNF circuit generated execution Algorithm 6.
Part I: Nodes returned get-and-node Line 10 conjunction nodes satisfy
decomposability components identified Line 5 share variables. Nodes
returned get-node Line 15 disjunction nodes form Figure 1c
definition get-node. Therefore whole DAG decision-DNNF. Finally, decisionDNNF circuits returned algorithm guaranteed reduced use
unique nodes technique get-node get-and-node functions.
Part II: Let G denote arbitrary (reduced) decision-DNNF circuit. assuming
compact drawing decision nodes Figure 1c, expand previous definition
(G) follows:


{the empty clause},




{},


[

(G)

(Gi ),







{x c | c (G.low)} {x c | c (G.high)},



214

G 0-sink;
G ^
1-sink;
G
Gi ;


otherwise, node G
labeled variable x.

fiThe Language Search

previous definition (G), assume last line definition above,
literal x (and x) always appended front clause c. Now, let literal
clause associated (possibly empty) list colors follows: lists
initially empty literals x x introduced last line definition;
third line definition, assign distinct color sets unioned,
set, append assigned color head list colors first literal
every clause. execute Algorithm 6 (G) resolve nondeterministic choices
Line 5 (decomposition) Line 14 (variable selection) follows: first literal
clause nonempty list colors, (the first literal every clause must
nonempty list colors) let Line 5 partition set clauses according first color
first literal remove color first literal every clause; otherwise,
(the first literal every clause must mention variable) let Line 5 return single
partition Line 14 choose first variable clause. DAG returned
isomorphic G.

References
Aloul, F., Markov, I., & Sakallah, K. (2001). Faster SAT smaller BDDs via common
function structure. International Conference Computer Aided Design (ICCAD),
pp. 443448.
Arvelo, Y., Bonet, B., & Vidal, M.-E. (2006). Compilation query-rewriting problems
tractable fragments propositional logic. Proceedings 21st National
Conference Artificial Intelligence (AAAI).
Bacchus, F., Dalmao, S., & Pitassi, T. (2003a). Algorithms complexity results
#SAT Bayesian inference. 44th Annual IEEE Symposium Foundations
Computer Science (FOCS), pp. 340351.
Bacchus, F., Dalmao, S., & Pitassi, T. (2003b). DPLL caching: new algorithm
#SAT Bayesian inference. Electronic Colloquium Computational Complexity
(ECCC), 10 (003).
Barrett, A. (2004). hybrid systems universal plans via domain compilation. Proceedings 14th International Conference Automated Planning Scheduling
(ICAPS), pp. 4451.
Barrett, A. (2005). Model compilation real-time planning diagnosis feedback.
Proceedings 19th International Joint Conference Artificial Intelligence
(IJCAI), pp. 11951200.
Barwise, J. (Ed.). (1977). Handbook Mathematical Logic. North-Holland.
Bayardo, R., & Pehoushek, J. (2000). Counting models using connected components.
Proceedings 17th National Conference Artificial Intelligence (AAAI), pp.
157162.
Berre, D. L., & Simon, L. (2005).
http://www.satcompetition.org/.



Annual

SAT

Competitions.

Birnbaum, E., & Lozinskii, E. (1999). good old Davis-Putnam procedure helps counting
models. Journal Artificial Intelligence Research, 10, 457477.
215

fiHuang & Darwiche

Blum, M., Chandra, A. K., & Wegman, M. N. (1980). Equivalence free Boolean graphs
decided probabilistically polynomial time. Information Processing Letters,
10 (2), 8082.
Bonet, B., & Geffner, H. (2006). Heuristics planning penalties rewards using compiled knowledge. Proceedings Tenth International Conference
Principles Knowledge Representation Reasoning (KR), pp. 452462.
Brace, K. S., Rudell, R. L., & Bryant, R. E. (1991). Efficient implementation BDD
package. Proceedings 27th Design Automation Conference (DAC), pp. 4045.
Bryant, R. E. (1986). Graph-based algorithms Boolean function manipulation. IEEE
Transactions Computers, C-35, 677691.
Bryant, R. E. (1991). complexity VLSI implementations graph representations
Boolean functions application integer multiplication. IEEE transactions
Computers, 40, 205213.
Cadoli, M., & Donini, F. M. (1997). survey knowledge compilation. AI Communications, 10, 137150.
Chauhan, P., Clarke, E. M., & Kroening, D. (2003). Using SAT based image computation
reachability analysis. Tech. rep. CMU-CS-03-151, School Computer Science,
Carnegie Mellon University.
Chavira, M., & Darwiche, A. (2005). Compiling Bayesian networks local structure.
Proceedings 19th International Joint Conference Artificial Intelligence
(IJCAI), pp. 13061312.
Chavira, M., Darwiche, A., & Jaeger, M. (2006). Compiling relational Bayesian networks
exact inference. International Journal Approximate Reasoning, 42 (1-2), 420.
Coste-Marquis, S., Berre, D. L., Letombe, F., & Marquis, P. (2005). Propositional fragments
knowledge compilation quantified Boolean formulae.. Proceedings
20th National Conference Artificial Intelligence (AAAI), pp. 288293.
Darwiche, A. (2001). tractability counting theory models application
belief revision truth maintenance. Journal Applied Non-Classical Logics,
11 (1-2), 1134.
Darwiche, A. (2002). compiler deterministic decomposable negation normal form.
Proceedings 18th National Conference Artificial Intelligence (AAAI), pp.
627634.
Darwiche, A. (2004). New advances compiling CNF decomposable negation normal form. Proceedings 16th European Conference Artificial Intelligence
(ECAI), pp. 328332.
Darwiche, A. (2005). c2d compiler user manual. Tech. rep. D-147, Computer Science
Department, UCLA. http://reasoning.cs.ucla.edu/c2d/.
Darwiche, A., & Hopkins, M. (2001). Using recursive decomposition construct elimination
orders, jointrees dtrees. Trends Artificial Intelligence, Lecture notes AI,
2143, pp. 180191. Springer-Verlag.

216

fiThe Language Search

Darwiche, A., & Huang, J. (2002). Testing equivalence probabilistically. Tech. rep. D-123,
Computer Science Department, UCLA.
Darwiche, A., & Marquis, P. (2002). knowledge compilation map. Journal Artificial
Intelligence Research, 17, 229264.
Davis, M., Logemann, G., & Loveland, D. (1962). machine program theorem proving.
Journal ACM, (5)7, 394397.
Dechter, R., & Mateescu, R. (2004a). impact AND/OR search spaces constraint
satisfaction counting. Proceedings 10th International Conference
Principles Practice Constraint Programming (CP), pp. 731736.
Dechter, R., & Mateescu, R. (2004b). Mixtures deterministic-probabilistic networks
AND/OR search spaces. Proceedings 20th Conference Uncertainty
Artificial Intelligence (UAI), pp. 120129.
del Val, A. (1994). Tractable databases: make propositional unit resolution complete compilation. Proceedings Fourth International Conference
Principles Knowledge Representation Reasoning (KR), pp. 551561.
del Val, A. (1995). analysis approximate knowledge compilation. Proceedings
14th International Joint Conference Artificial Intelligence (IJCAI), pp. 830836.
Elliott, P., & Williams, B. (2006). DNNF-based belief state estimation. Proceedings
21st National Conference Artificial Intelligence (AAAI).
Forbus, K. D., & de Kleer, J. (1993). Building Problem Solvers. MIT Press.
Freuder, E. C., & Quinn, M. J. (1985). Taking advantage stable sets variables
constraint satisfaction problems. Proceedings Ninth International Joint Conference Artificial Intelligence (IJCAI), pp. 10761078.
Gergov, J., & Meinel, C. (1994). Efficient analysis manipulation OBDDs
extended FBDDs. IEEE Transactions Computers, 43 (10), 11971209.
Goldberg, E., & Novikov, Y. (2002). BerkMin: fast robust SAT-solver. Design
Automation Test Europe (DATE), pp. 142149.
Grumberg, O., Schuster, A., & Yadgar, A. (2004). Memory efficient all-solutions SAT solver
application reachability analysis. Proceedings 5th International
Conference Formal Methods Computer-Aided Design (FMCAD), pp. 275289.
Heule, M., & van Maaren, H. (2004). Aligning CNF- equivalence reasoning. Proceedings Seventh International Conference Theory Applications Satisfiability Testing (SAT).
Hoos, H. H., & Stutzle, T. (2000). SATLIB: online resource research SAT.
I.P.Gent, H.v.Maaren, T.Walsh, editors, SAT 2000, pp. 283292. IOS Press. SATLIB
available online www.satlib.org.
Huang, J. (2006). Combining knowledge compilation search conformant probabilistic
planning. Proceedings 16th International Conference Automated Planning
Scheduling (ICAPS), pp. 253262.

217

fiHuang & Darwiche

Huang, J., & Darwiche, A. (2005a). compiling system models faster scalable
diagnosis. Proceedings 20th National Conference Artificial Intelligence
(AAAI), pp. 300306.
Huang, J., & Darwiche, A. (2005b). Using DPLL efficient OBDD construction.
Seventh International Conference Theory Applications Satisfiability Testing,
SAT 2004, Revised Selected Papers, Vol. 3542 Lecture Notes Computer Science,
pp. 157172.
Karnaugh, M. (1953). map method synthesis combinational logic circuits. Transactions AIEE, 72 (9), 593599.
Majercik, S. M., & Littman, M. L. (1998). Using caching solve larger probabilistic
planning problems. Proceedings 15th National Conference Artificial Intelligence (AAAI), pp. 954959.
Marinescu, R., & Dechter, R. (2005). AND/OR branch-and-bound graphical models.
Proceedings 19th International Joint Conference Artificial Intelligence
(IJCAI), pp. 224229.
Marques-Silva, J., & Sakallah, K. (1996). GRASPA new search algorithm satisfiability.
Proceedings International Conference Computer Aided Design (ICCAD),
pp. 220227.
Marques-Silva, J. (1999). impact branching heuristics propositional satisfiability
algorithms. Proceedings 9th Portuguese Conference Artificial Intelligence,
pp. 6274.
Marquis, P. (1995). Knowledge compilation using theory prime implicates. Proceedings
14th International Joint Conference Artificial Intelligence (IJCAI), pp. 837
843.
McMillan, K. (1993). Symbolic Model Checking. Kluwer Academic.
McMillan, K. L. (2002). Applying SAT methods unbounded symbolic model checking.
Proceedings 14th International Conference Computer Aided Verification
(CAV), pp. 250264.
Meinel, C., & Theobald, T. (1998). Algorithms Data Structures VLSI Design: OBDD
Foundations Applications. Springer.
Moskewicz, M., Madigan, C., Zhao, Y., Zhang, L., & Malik, S. (2001). Chaff: Engineering
efficient SAT solver. Proceedings 38th Design Automation Conference
(DAC), pp. 530535.
Palacios, H., Bonet, B., Darwiche, A., & Geffner, H. (2005). Pruning conformant plans
counting models compiled d-DNNF representations. Proceedings 15th
International Conference Automated Planning Scheduling (ICAPS), pp. 141
150.
Sang, T., Bacchus, F., Beame, P., Kautz, H., & Pitassi, T. (2004). Combining component
caching clause learning effective model counting. Proceedings Seventh
International Conference Theory Applications Satisfiability Testing (SAT),
pp. 2028.
218

fiThe Language Search

Sang, T., Beame, P., & Kautz, H. (2005). Heuristics fast exact model counting.
Proceedings Eighth International Conference Theory Applications
Satisfiability Testing (SAT), Lecture Notes Computer Science, pp. 226240.
Selman, B., & Kautz, H. (1991). Knowledge compilation using Horn approximation.
Proceedings Ninth National Conference Artificial Intelligence (AAAI), pp.
904909.
Selman, B., & Kautz, H. (1996). Knowledge compilation theory approximation. Journal
ACM, 43 (2), 193224.
Siddiqi, S., & Huang, J. (2007). Hierarchical diagnosis multiple faults. Proceedings
20th International Joint Conference Artificial Intelligence (IJCAI), pp. 581
586.
Somenzi, F. (2004).
CUDD: CU Decision Diagram Package, Release 2.4.0.
http://vlsi.colorado.edu/fabio/CUDD/cuddIntro.html.
Urquhart, A. (1995). complexity propositional proofs. Bulletin Symbolic Logic,
1 (4), 425467.
Wegener, I. (2000). Branching Programs Binary Decision Diagrams: Theory Applications. SIAM Monographs Discrete Mathematics Applications.
Zhang, L., Madigan, C., Moskewicz, M., & Malik, S. (2001). Efficient conflict driven learning
Boolean satisfiability solver. Proceedings International Conference
Computer Aided Design (ICCAD), pp. 279285.
Zhang, L., & Malik, S. (2002). quest efficient Boolean satisfiability solvers.
Proceedings 18th International Conference Automated Deduction (CADE),
Lecture Notes Computer Science, pp. 295313.

219

fiJournal Artificial Intelligence Research 29 (2007) 421-489

Submitted 8/06; published 8/07

Algebraic Graphical Model Decision
Uncertainties, Feasibilities, Utilities
Cedric Pralet

cedric.pralet@onera.fr

ONERA Toulouse, France
2 av. Edouard Belin, 31400 Toulouse

Gerard Verfaillie

gerard.verfaillie@onera.fr

ONERA Toulouse, France
2 av. Edouard Belin, 31400 Toulouse

Thomas Schiex

thomas.schiex@toulouse.inra.fr

INRA Toulouse, France
Chemin de Borde Rouge, 31320 Castanet-Tolosan

Abstract
Numerous formalisms dedicated algorithms designed last decades
model solve decision making problems. formalisms, constraint networks, express simple decision problems, others designed take account uncertainties, unfeasible decisions, utilities. Even single formalism, several
variants often proposed model different types uncertainty (probability, possibility...) utility (additive not). article, introduce algebraic graphical model
encompasses large number formalisms: (1) first adapt previous structures
Friedman, Chu Halpern representing uncertainty, utility, expected utility
order deal generic forms sequential decision making; (2) structures,
introduce composite graphical models express information via variables linked
local functions, thanks conditional independence; (3) graphical models,
finally define simple class queries represent various scenarios terms
observabilities controllabilities. natural decision-tree semantics queries
completed equivalent operational semantics, induces generic algorithms.
proposed framework, called Plausibility-Feasibility-Utility (PFU) framework,
provides better understanding links existing formalisms, also
covers yet unpublished frameworks (such possibilistic influence diagrams) unifies
formalisms quantified boolean formulas influence diagrams. backtrack
variable elimination generic algorithms first step towards unified algorithms.

1. Introduction
last decades, numerous formalisms developed express solve decision
making problems. problems, agent must make decisions consisting either
choosing actions ways fulfill (as action planning, task scheduling, resource
allocation), choosing explanations observed phenomena (as diagnosis situation
assessment). choices may depend various parameters:
1. uncertainty measures, call plausibilities, may describe beliefs state
environment;
2. preconditions may satisfied decision feasible;
c
2007
AI Access Foundation. rights reserved.

fiPralet, Verfaillie, & Schiex

3. possible states environment decisions generally
value decision makers point view. Utilities expressed model costs,
gains, risks, satisfaction degrees, hard requirements, generally, preferences;
4. time involved, decision processes may sequential environment may
partially observable. means may several decision steps,
values variables may observed two steps, chess
player plays turn observe move opponent playing
again;
5. may adversarial collaborative decision makers, controlling
set decisions. Hence, multi-agent aspect yield partial controllabilities.
Given plausibilities defined states environment, feasibility constraints decisions, utilities defined decisions states environment, given possible multiple decision steps, objective provide decision
maker optimal decision rules decision variables controls, depending
environment agents. concise, class problems denoted
class sequential decision problems plausibilities, feasibilities, utilities.
Various formalisms designed cope problems class, sometimes
degenerated form (covering subset features general problem):
formalisms developed boolean satisfiability framework: satisfiability problem (SAT), quantified boolean formulas, stochastic SAT (Littman, Majercik, & Pitassi,
2001), extended stochastic SAT (Littman et al., 2001);
formalisms developed close constraint satisfaction framework: constraint
satisfaction problems (CSPs, Mackworth, 1977), valued/semiring CSPs (Bistarelli,
Montanari, Rossi, Schiex, Verfaillie, & Fargier, 1999) (covering classical, fuzzy, additive, lexicographic, probabilistic CSPs), mixed CSPs probabilistic mixed CSPs
(Fargier, Lang, & Schiex, 1996), quantified CSPs (Bordeaux & Monfroy, 2002),
stochastic CSPs (Walsh, 2002);
formalisms developed represent uncertainty extended represent decision
problems uncertainty: Bayesian networks (Pearl, 1988), Markov random fields
(Chellappa & Jain, 1993) (also known Gibbs networks), chain graphs (Frydenberg, 1990), hybrid mixed networks (Dechter & Larkin, 2001; Dechter & Mateescu,
2004), influence diagrams (Howard & Matheson, 1984), unconstrained (Jensen & Vomlelova, 2002), asymmetric (Smith, Holtzman, & Matheson, 1993; Nielsen & Jensen,
2003), sequential (Jensen, Nielsen, & Shenoy, 2004) influence diagrams, valuation
networks (Shenoy, 1992), asymmetric (Shenoy, 2000) sequential (Demirer &
Shenoy, 2001) valuation networks;
formalisms developed classical planning framework, STRIPS planning (Fikes & Nilsson, 1971; Ghallab, Nau, & Traverso, 2004), conformant planning (Goldman & Boddy, 1996), probabilistic planning (Kushmerick, Hanks, &
Weld, 1995);

422

fiThe PFU Framework

formalisms Markov decision processes (MDPs), probabilistic, possibilistic,
using Spohns epistemic beliefs (Spohn, 1990; Wilson, 1995; Giang & Shenoy,
2000), factored not, possibly partially observable (Puterman, 1994; Monahan, 1982;
Sabbadin, 1999; Boutilier, Dean, & Hanks, 1999; Boutilier, Dearden, & Goldszmidt,
2000).
Many formalisms present interesting similarities:
include variables modeling state environment (environment variables)
decisions (decision variables);
use sets functions which, depending formalism considered, model
plausibilities, feasibilities, utilities;
use operators either combine local information (such aggregate probabilities independence hypothesis, + aggregate gains costs), project
global information (such + compute marginal probability, min max
compute optimal decision).
Even meaning variables, functions, combination projection operators
may specific formalism, seen graphical models sense
exploit, implicitly explicitly, hypergraph local functions variables.
article shows possible build generic algebraic framework subsuming many
formalisms reducing decision making problems sequence so-called variable
eliminations aggregation local functions.
generic framework able provide:
better understanding existing formalisms: generic framework obvious
theoretical pedagogical interest, since bring light similarities differences formalisms covered help people different communities
communicate common basis;
increased expressive power : generic framework may able capture problems
cannot directly modeled existing formalism. increased expressiveness reachable capturing essential algebraic properties existing
frameworks;
generic algorithms: ultimately, besides generic framework, possible
define generic algorithms capable solving problems defined framework.
objective fits growing effort identify common algorithmic approaches
developed solving different AI problems. may also facilitate crossfertilization allowing subsumed framework reuse algorithmic ideas defined
another one.
1.0.1 Article Outline
introduction notations notions, article starts showing,
catalog existing formalisms decision making, generic algebraic framework
423

fiPralet, Verfaillie, & Schiex

informally identified. generic framework, called Plausibility-Feasibility-Utility
(PFU) framework, formally introduced three steps: (1) algebraic structures capturing plausibilities, feasibilities, utilities introduced (Section 4), (2) algebraic structures exploited build generic form graphical model (Section 5),
(3) problems graphical models captured notion queries (Section 6).
framework analyzed Section 7 generic algorithms defined Section 8.
table recapitulating main notations used available Appendix proofs
propositions theorems appear Appendix B. short version framework
described article already published (Pralet, Verfaillie, & Schiex, 2006c).

2. Background Notations Definitions
essential objects used article variables, domains, local functions (called
scoped functions).
Definition 1. domain values variable x denoted dom(x) every
dom(x), (x, a) denotes assignment value x. extension, set
variables S, denote
Q dom(S) Cartesian product domains variables
S, i.e. dom(S) = xS dom(x). element dom(S) called assignment S.1
A1 , A2 assignments disjoint subsets S1 , S2 , A1 .A2 , called concatenation
A1 A2 , assignment S1 S2 variables S1 assigned A1
variables S2 assigned A2 . assignment set variables S,
projection onto 0 assignment 0 variables assigned
value A.
Definition 2. (Scoped function) scoped function pair (S, ) set
variables function mapping elements dom(S) given set E. following,
often consider implicit denote scoped function (S, ) alone.
set variables called scope denoted sc(). assignment
superset sc() A0 projection onto sc(), define (A) (A) = (A0 ).
example, scoped function mapping assignments sc() elements
boolean lattice B = {t, f } analogous constraint describing subset dom(sc())
authorized tuples constraint networks.
this, general notion graphical model defined:
Definition 3. (Graphical model) graphical model pair (V, ) V = {x1 , . . . , xn }
finite set variables = {1 , . . . , } finite set scoped functions whose
scopes included V .
terminology graphical models used simply set scoped functions
represented hypergraph contains one hyperedge per function scope.
see, hypergraph captures form independence (see Section 5) induces
parameters time space complexity algorithms (see Section 8).
definition graphical models generalizes usual one used statistics, defining graphical
1. assignment = {x1 , . . . , xk } actually set variable-value pairs {(x1 , a1 ), . . . , (xk , ak )};
assume variables implicit using tuple values (a1 , . . . , ak ) dom(S).

424

fiThe PFU Framework

model (directed not) graph nodes represent random variables
structure captures probabilistic independence relations.
Local scoped functions graphical model give space-tractable definition
global function defined aggregation. example, Bayesian network (Pearl,
1988) global probability distribution Px,y,z x, y, z may defined product
(using operator ) set scoped functions {Px , Py|x , Pz|y }. Local scoped functions
also facilitate projection information expressed graphical model onto
smaller scope. example, order compute
P marginal
P probability distribution Py,z
previous network, computeP x Px,y,z = ( x Px Py|x ) Pz|y avoid
taking Pz|y account. operator
used project information onto smaller
scope eliminating variable x. Operators used combine scoped functions called
combination operators, operators used project information onto smaller scopes
called elimination operators.
Definition 4. (Combination) Let 1 , 2 scoped functions E1 E2 respectively. Let
: E1 E2 E binary operator. combination 1 2 , denoted 1 2 ,
scoped function E scope sc(1 )sc(2 ) defined (1 2 )(A) = 1 (A)2 (A)
assignments sc(1 ) sc(2 ). called combination operator 1
2 .
rest article, combination operators denoted .
Definition 5. (Elimination) Let scoped function E. Let op E
associative, commutative, identity element . elimination variable
x op scoped function whose scope sc() {x} whose value
assignment scope (opx )(A) = opadom(x) (A.(x, a)). context, op called
elimination operator x. elimination set variables = {x1 , . . . , xk }
function scope sc() defined opS (A) = opA0 dom(S) (A.A0 ).
P
Hence, computing x (Px Py|x Pz|x ), scoped functions aggregated using
combination operator = information projected eliminating x using
elimination operator +. article, denotes elimination operators.
cases, elimination set variables operator op scoped
function performed subset dom(S) containing assignments
satisfy property denoted boolean scoped function F . Then, must compute
every dom(sc() S) value opA0 dom(S),F (A0 )=t (A.A0 ). simplicity
homogeneity, order always use elimination dom(S), equivalently
truncate elements dom(S) satisfy F mapped special
value (denoted ) defined new identity op.
Definition 6. (Truncation operator) unfeasible value new special element
supposed outside domain E every elimination operator op : E E E.
explicitly extend every elimination operator op : E E E E {} taking
convention op(, e) = op(e, ) = e e E {}.
Let {t, f } boolean lattice. boolean b e E, define b ? e
equal e b = otherwise. ? called truncation operator.

425

fiPralet, Verfaillie, & Schiex

Given boolean scoped function F , ? make possible write quantities like
opA0 dom(S),F (A0 )=t elimination opS (F ? ).
order solve decision problems, one usually wants compute functions mapping
available information decision. notion decision rules used formalize
this:
Definition 7. (Decision rule, policy) decision rule variable x given set variables
0 function : dom(S 0 ) dom(x) mapping assignment 0 value dom(x).
extension, decision rule set variables given set variables 0 function
: dom(S 0 ) dom(S). set decision rules called policy.
Definition 8. (Optimal decision rule) Consider totally -ordered set E, scoped function
dom(sc()) E, set variables sc(). decision rule : dom(sc()
S) dom(S). said optimal iff, (A, A0 ) dom(sc() S) dom(S),
(A.(A)) (A.A0 ) (resp. (A.(A)) (A.A0 )). decision rule always exists
dom(sc()) finite.
words, optimal decision rules examples decision rules given argmin
argmax (in article, consider optimality decision rules always given
min max totally ordered set).
Definition 9. (Directed Acyclic Graph (DAG)) directed graph G DAG contains
directed cycle. variables used vertices, paG (x) denotes set parents
variable x G.
Last, [1, n] denote set integers 1 n.

3. Examples Graphical Models Generic Framework
present different AI formalisms expressing solving decision problems.
simple case, single decision maximizes utility sought. introduction
plausibilities (uncertainties), unfeasible actions (feasibilities), sequential decision
(several decision steps observations decision steps) appears
sophisticated frameworks. goal section show formalisms
viewed graphical models specific elimination combination operators
used.
3.1 Examples Graphical Models
examples used cover various AI formalisms, briefly described. wider
accurate review existing graphical models could provided (Pralet, 2006).
3.1.1 Constraint Networks
Constraint networks (CNs, Mackworth, 1977), often called constraint satisfaction problems
(CSPs), graphical models (V, ) scoped functions constraints mapping
assignments onto {t, f }. usual query CN determine existence

426

fiThe PFU Framework

assignment V satisfies constraints. setting f t, decision problem
answered computing:


max .
(1)
V



quantity equals true, optimal decision rule V defines solution.
query answered performing eliminations (using max) combination scoped
functions (using ). Replacing hard constraints soft constraints (boolean scoped
functions replaced cost functions) replacing abstract operator equal
+, min, , . . . leads queries valued totally ordered semiring CN (Bistarelli
et al., 1999).
3.1.2 Bayesian Networks
Bayesian networks (BNs, Pearl, 1988) model problems plausibilities expressed
probabilities. BN graphical model (V, ) set local conditional
probability distributions: = {Px | paG (x) , x V }, G DAG vertices V .
BN represents joint probability distribution P
QV variables combination
local conditional probability distributions (PV = xV Px | paG (x) ), combination
local constraints CN defines global constraint variables. One possible query
BN compute marginal probability distribution variable V :
!
X
X

Py =
PV =
Px | paG (x) .
(2)
V {y}

V {y}

xV

Equation 2 corresponds variable eliminations (with +) product scoped functions.
queries BNs MAP (Maximum Posteriori hypothesis), eliminations
max also performed.
3.1.3 Quantified Boolean Formulas Quantified CNs
Quantified boolean formulas (QBFs) quantified CNs (Bordeaux & Monfroy, 2002)
model sequential decision problems. Let x1 , x2 , x3 boolean variables. QBF using
so-called prenex conjunctive normal form looks like (with f t):
x1 x2 x3 ((x1 x3 ) (x2 x3 )) = max min max((x1 x3 ) (x2 x3 )).
x1

x2

x3

(3)

Thus, query value x1 values x2 , exists value
x3 clauses x1 x3 x2 x3 satisfied? answered
Equation 3 using sequence eliminations (max x1 , min x2 , max x3 )
conjunction clauses. quantified CN, clauses replaced constraints.
3.1.4 Stochastic CNs
stochastic CN (Walsh, 2002) model sequential decision problems probabilities
plausibilities hard requirements utilities, provided decisions influence
environment (the so-called contingency assumption). stochastic CN, two types
427

fiPralet, Verfaillie, & Schiex

variables defined: decision variables di environment (stochastic) variables sj .
global probability distribution environment variables expressed combination
local probability distributions. environment variables mutually independent,
local probability distributions simply unary probability distributions Psj . Finally,
stochastic CN defines set constraints {C1 , . . . , Cm } mapping tuples values onto
{0, 1} (instead {t, f }). allows constraints multiplied probabilities.
Consider situation first two decisions d1 d2 made, environment
variable s1 observed, decisions d3 d4 made, environment variable s2
remains unobserved. possible query stochastic CN compute decision rules
d1 , d2 , d3 , d4 maximize expected constraint satisfaction, Equation 4:
Q

X
X
C
(4)
(Ps1 Ps2 )
max
max
i[1,m] .
d1 ,d2

s1

d3 ,d4

s2

answer query defined Equation 4 determined sequence eliminations
(max decision variables, + environment ones) combination scoped
functions (probabilities combined using , constraints combined using , since
expressed onto {0, 1} instead {t, f }, probabilities combined constraints
using ).
3.1.5 Influence Diagrams
Influence diagrams (Howard & Matheson, 1984) model sequential decision problems
probabilities plausibilities together gains costs utilities.
seen extension BNs including notions decision utility. precisely,
influence diagram composite graphical model defined three sets variables
organized DAG G: (1) set chance variables; S, conditional
probability distribution Ps | paG (s) given parents G specified; (2) set
decision variables; D, paG (d) set variables observed decision
made; (3) set = {u1 , . . . , um } utility variables, associated
utility function Ui = UpaG (ui ) scope paG (ui ). Utility variables P
must leaves
DAG, utility functions define global additive utility UG = i[1,m] Ui .
usual problem associated influence diagram compute decision rules
maximizing global expected utility. modify example used stochastic CNs
replacing Ps1 Ps1 | d2 , Ps2 Ps2 | d1 ,d3 , constraints C1 , . . . , Cm additive
utility functions U1 , . . . , Um , optimal policy obtained computing optimal
decision rules d1 , d2 , d3 , d4 Equation 5:

X
X
P
max
max
Ps1 | d2 Ps2 | d1 ,d3
U
.
(5)

i[1,m]
d1 ,d2

s1

d3 ,d4

s2

Again, answer query defined Equation 5 computed sequence
eliminations (alternating max- sum-eliminations) combination scoped functions (plausibilities combined using , utilities combined using +, plausibilities utilities
combined using ).

428

fiThe PFU Framework

3.1.6 Valuation Networks
Valuation networks (Shenoy, 1992) model sequential decision problems plausibilities, feasibilities, utilities, plausibilities combined using utilities
additive. valuation network composed several sets nodes valuations: (1)
set decision nodes, (2) set chance nodes, (3) set F indicator valuations,
specify unfeasible assignments decision chance variables, (4) set P probability valuations, multiplicative factors joint probability distribution
chance variables, (5) set
P U utility valuations, representing additive factors
joint utility function UG =
Ui U Ui . Arcs nodes also used define
order decisions made chance variables observed. order
d1 d2 s1 d3 d4 s2 , shown optimal decision rules d1 , d2 , d3 , d4
defined Equation 6:





X
X

X
Fi ?
max
max
Pi
Ui .
(6)
d1 ,d2

s1

d3 ,d4

Fi F

s2

Pi P

Ui U

Local feasibility constraints combined using , combined scoped functions using truncation operator ? (cf. Definition 6).
3.1.7 Finite Horizon Markov Decision Processes
Finite horizon Markov Decision Processes (MDPs, Puterman, 1994; Monahan, 1982; Sabbadin, 1999; Boutilier et al., 1999, 2000) model sequential decision problems plausibilities utilities horizon time-steps. every time-step t, variable st
represents state environment variable dt represents decision made
observing st . factored MDPs, several state variables may used time-step.
probabilistic finite horizon MDP, plausibilities environment described
local probability distributions Pst+1 | st ,dt state st+1 given st dt . utilities
states decisions local additive rewards Rst ,dt , boolean functions Fdt | st
express whether decision dt feasible state st . optimal policy initial state
s1 computed following equation (which bit unusual defining optimal
policies MDP, equivalent usual form):
!
!


max u max . . . u max
d1

s2

d2

sT

dT


t[1,T ]

Fdt |st

?

p Pst+1 |st ,dt
t[1,T [

pu

u Rst ,dt
t[1,T ]

.

(7)

Plausibilities combined using p = , utilities combined using u = +, plausibilities
utilities combined using pu = , decision variables eliminated using max,
environment variables eliminated using u = +. truncation operator ? enables
elimination operators ignore unfeasible decisions.
pessimistic possibilistic finite horizon MDP (Sabbadin, 1999), probability distributions Pst+1 | st ,dt replaced possibility distributions st+1 | st ,dt , rewards Rst ,dt
replaced preferences st ,dt , operators used u = p = u = min
pu : (p, u) max(1 p, u).

429

fiPralet, Verfaillie, & Schiex

3.2 Towards Generic Framework
previous section shows usual queries various existing formalisms reduced
sequence variable eliminations combination scoped functions.
observation led definition algebraic MDPs (Perny, Spanjaard, & Weng,
2005) definition valuation algebras (Shenoy, 1991; Kolhas, 2003), generic
algebraic framework eliminations performed combination scoped
functions. However, valuation algebras use one combination operator, whereas several
combination operators may needed manipulate different types scoped functions (as
previously shown). Moreover, valuation algebras deal one type elimination,
whereas several elimination operators may required handling different types
variables. valuation networks (Shenoy, 2000), plausibilities necessarily represented
probabilities, eliminations min cannot performed. Essentially, powerful
framework needed.
order simple yet general enough cover queries defined Equations 1
7, generic form consider is:
!



!
Sov

Fi

Fi F

?

p
Pi P

Pi

pu

u
Ui U

Ui

.

(8)

(1) used combine local feasibilities, p used combine plausibilities, u
used combine utilities, pu used combine plausibilities utilities,
truncation operator ? used ignore unfeasible decisions without deal
elimination operations restricted domains;2 (2) F , P , U (possibly empty) sets
local feasibility, plausibility, utility functions respectively; (3) Sov operatorvariable(s) sequence, indicating eliminate variables. Sov involves min max
eliminate decision variables operator u eliminate environment variables.
Equation 8 still informal. define formally, provide clear
semantics, need define three key elements:
1. must capture essential properties combination operators p , u , pu
used respectively combine plausibilities, utilities, plausibilities utilities.
must also characterize elimination operators u p used project information coming utilities plausibilities. operators define
algebraic structure PFU (Plausibility-Feasibility-Utility) framework.
2. algebraic structure, must define generic form graphical model, involving set variables sets scoped functions expressing plausibilities, feasibilities,
utilities (sets P , F , U ). Together, define PFU network. factored
form offered graphical models must also analyzed order understand
applied concisely represent global functions (using
notion conditional independence).
2. Equation 8, plausibilities combined using operator p utilities combined
using operator u ; denote models composite graphical models include
different types scoped functions (plausibilities, feasibilities, utilities). Beyond this, Equation 8
also allows heterogeneous information among type scoped functions. example, order
manipulate probabilities possibilities, use p defined probability-possibility pairs
(p1 , 1 ) p (p2 , 2 ) = (p1 p2 , min(1 , 2 )).

430

fiThe PFU Framework

3. Finally, must define queries PFU networks capturing interesting decision problems. Equation 8 shows, queries defined sequence Sov operatorvariable(s) pairs, applied combination scoped functions network.
fact answer queries represents meaningful values decision theory point view proved relating approach.
3.3 Summary
informally shown several queries various formalisms dealing plausibilities and/or feasibilities and/or utilities reduce sequences variable eliminations
applied combinations scoped functions, using various operators. intuitively
covered Equation 8.
three key elements (an algebraic structure, PFU network, sequence variable eliminations) needed formally define give sense equation introduced
Sections 4, 5, 6.

4. PFU Algebraic Structures
first element PFU framework algebraic structure specifying information provided plausibilities, feasibilities, utilities combined synthesized.
algebraic structure obtained adapting previous structures defined Friedman,
Chu, Halpern (Friedman & Halpern, 1995; Halpern, 2001; Chu & Halpern, 2003a)
representing uncertainties expected utilities.
4.1 Definitions
Definition 10. (E, ~) commutative monoid iff E set ~ binary operator
E associative (x ~ (y ~ z) = (x ~ y) ~ z), commutative (x ~ = ~ x),
identity 1E E (x ~ 1E = 1E ~ x = x).
Definition 11. (E, , ) commutative semiring iff
(E, ) commutative monoid, identity denoted 0E ,
(E, ) commutative monoid, identity denoted 1E ,
0E annihilator (x 0E = 0E ),
distributes (x (y z) = (x y) (x z)).
Definition 12. Let (Ea , , ) commutative semiring. Then, (Eb , b , ab ) semimodule (Ea , , ) iff
(Eb , b ) commutative monoid, identity denoted 0Eb ,
ab : Ea Eb Eb satisfies
ab distributes b (a ab (b1 b b2 ) = (a ab b1 ) b (a ab b2 )),
ab distributes ((a1 a2 ) ab b = (a1 ab b) b (a2 ab b)),
431

fiPralet, Verfaillie, & Schiex

linearity property: a1 ab (a2 ab b) = (a1 a2 ) ab b,
b Eb , 0Ea ab b = 0Eb 1Ea ab b = b.
Definition 13. Let E set partial order . operator ~ E monotonic
iff (x y) (x ~ z ~ z) x, y, z E.
4.2 Plausibility Structure
Various forms plausibilities exist (Halpern, 2003). usual one probabilities.
shown previously, example Equation 2, probabilities aggregated using p =
combination operator, projected using p = + elimination operator.
plausibilities also expressed possibility degrees [0, 1]. Possibilities
eliminated using p = max usually combined using p = min. interesting case
appears possibility degrees booleans describing states environment
completely possible impossible. Plausibilities combined using p =
eliminated using p = .
Another example Spohns epistemic beliefs, also known -rankings (kappa rankings, Spohn, 1990; Wilson, 1995; Giang & Shenoy, 2000). case, plausibilities
elements N {+} called surprise degrees, 0 associated non-surprising situations,
+ associated completely surprising (impossible) situations, generally
surprise degree k viewed probability k infinitesimal . Surprise degrees
combined using p = + eliminated using p = min.
capture various plausibility modeling frameworks, start FriedmanHalperns work plausibility measures (Friedman & Halpern, 1995; Halpern, 2001). Weydert (1994) Darwiche-Ginsberg (1992) developed similar approaches.
Friedman-Halperns structure Assume want express plausibilities assignments set variables S. subset dom(S) called event. Friedman
Halpern (1995) define plausibilities elements set Ep called plausibility domain.
Ep equipped partial order p two special elements 0p 1p satisfying
0p p p p 1p p Ep . function P l : 2dom(S) Ep plausibility measure
iff satisfies P l() = 0p , P l(dom(S)) = 1p , (W1 W2 ) (P l(W1 ) p P l(W2 )).
means 0p associated impossibility, 1p associated highest plausibility
degree, plausibility degree set least high plausibility degree
subsets.
Among plausibility measures, focus so-called algebraic conditional plausibility
measures, use abstract functions p p analogous +
probabilities. measures satisfy properties decomposability: disjoint
events W1 , W2 , P l(W1 W2 ) = P l(W1 ) p P l(W2 ). associative commutative,
follows p associative commutative representations disjoint events, i.e.
(a p b) p c = p (b p c) p b = b p exist pairwise disjoint sets
W1 , W2 , W3 P l(W1 ) = a, P l(W2 ) = b, P l(W3 ) = c. details available
Friedman-Halperns references (Friedman & Halpern, 1995; Halpern, 2001).
Restriction Friedman-Halperns structure important aspect FriedmanHalperns work algebraic properties p p hold domains

432

fiThe PFU Framework

definition p p . Although sufficient express manipulate plausibilities, algorithmically restrictive. Indeed, consider Bayesian network involving two
Px1 constant
boolean variables {x1 , x2 } define Px1 ,x2 Px1 Px2 | x1 . Assume
P
Px2 | x1 ((x2 , t)) must
factor 0 = 0.5. order evaluate Px2 ((x2 , t)), quantity x1 0 P
computed. so, simpler factor compute 0 x1 Px2 | x1 ((x2 , t)).
Px2 | x1 ((x2 , t).(x1 , t)) = 0.6 Px2 | x1 ((x2 , t).(x1 , f )) = 0.8, answer 0.5(0.6+0.8) =
0.7. Performing 0.6 + 0.8 requires applying addition outside range usual probabilities, p b defined + b 1, since two probabilities whose sum exceeds
1 cannot associated disjoint events.
take issues account, adapt Friedman-Halperns Ep , p , p p
p become closed Ep Friedman-Halperns axioms hold closed
structure. closure performed, obtain plausibility structure.
Definition 14. plausibility structure tuple (Ep , p , p )
(Ep , p , p ) commutative semiring (identities p p denoted 0p
1p respectively),
Ep equipped partial order p 0p = min(Ep ) p
p monotonic respect p .
Elements Ep called plausibility degrees
Note 1p necessarily maximal element Ep . probabilities, FriedmanHalperns structure would ([0, 1], +0 , ), +0 b = + b + b 1
undefined otherwise. order get closed operators, take (Ep , p , p ) = (R+ , +, )
therefore 1p = 1 maximal element Ep . cases, Friedman-Halperns
structure already closed. case -rankings (where (Ep , p , p ) = (N
{+}, min, +)) possibilities (where (Ep , p , p ) typically ([0, 1], max, min),
although choices like ([0, 1], max, ) possible).
Given two plausibility structures (Ep , p , p ) (Ep0 , 0p , 0p ), define E = Ep Ep0 ,
(p1 , p01 ) (p2 , p02 ) = (p1 p p2 , p01 0p p02 ) (p1 , p01 ) (p2 , p02 ) = (p1 p p2 , p01 0p p02 ),
(E, , ) plausibility structure too. allows us deal different kinds plausibilities (such probabilities possibilities) families probability distributions.
4.2.1 Plausibility Measures Plausibility Distributions
Let us consider plausibility measure (Friedman & Halpern, 1995; Halpern, 2001) P l :
2dom(S) Ep set variables S. Assume P l(W1 W2 ) = P l(W1 ) p P l(W2 )
disjoint sets W1 , W2 2dom(S) , case Friedman-Halperns algebraic
plausibility measures. assumption entails P l(W ) = p AW P l({A}) W
2dom(S) . holds even W = since 0p identity p . Hence, defining
P l({A}) complete assignments suffices describe P l. Moreover,
case, three conditions defining plausibility measures (P l(dom(S)) = 1p , P l() = 0p ,
(W1 W2 ) (P l(W1 ) p P l(W2 ))) equivalent p Adom(S) P l({A}) = 1p ,
using monotonicity p third condition. means deal
plausibility distributions instead plausibility measures:

433

fiPralet, Verfaillie, & Schiex

Definition 15. plausibility distribution function PS : dom(S) Ep
p Adom(S) PS (A) = 1p .
normalization condition imposed plausibility distributions simply generalization convention probabilities sum 1. captures fact
disjunction assignments 1p plausibility degree.
Proposition 1. plausibility distribution PS extended give plausibility distribution PS 0 every 0 S, defined PS 0 = p SS 0 PS .
4.3 Feasibility Structure
Feasibilities define whether decision possible not, therefore expressed
booleans {t, f }. set equipped total order bool satisfying f bool t.
Boolean scoped functions expressing feasibilities combined using operator ,
since assignment decision variables feasible iff feasibility functions agree
assignment feasible.
Given scoped function Fi expressing feasibilities, compute whether assignment set variables feasible according Fi computing sc(Fi )S Fi (A), since
feasible according Fi iff one extensions sc(Fi ) feasible. means
projection feasibility functions onto smaller scope uses elimination operator .
result, feasibilities expressed using feasibility structure Sf = ({t, f }, , ).
Sf commutative semiring, also plausibility structure. Therefore,
plausibility notions properties apply feasibility. may therefore speak feasibility distributions, normalization condition FS = imposed feasibility
distribution FS means least one decision must feasible.
4.4 Utility Structure
Utilities express preferences take various forms. Typically, utilities combined
+. utilities also model priorities combined using min. Also, utilities
represent hard requirements goals achieved properties satisfied,
modeled booleans combined using . generally, utility degrees defined
elements set Eu equipped partial order u . Smaller utility degrees associated
less preferred events. Utility degrees combined using operator u
assumed associative commutative. guarantees combined utilities
depend way combination performed. also assume u admits
identity 1u Eu , representing indifference. ensures existence default utility
degree utility scoped functions. properties captured
following notion utility structure.
Definition 16. (Eu , u ) utility structure iff commutative monoid Eu
equipped partial order u . Elements Eu called utility degrees.
Eu may minimum element u representing unacceptable events
annihilator u (the combination event unacceptable one must
unacceptable too). u also usually monotonic. properties necessary
establish forthcoming results.
434

fiThe PFU Framework

distinction plausibilities, feasibilities, utilities important
justified using algebraic arguments. Since p u may different operators (for
example, p = u = + usual probabilities additive utilities), must
distinguish plausibilities utilities. also necessary distinguish feasibilities
utilities plausibilities. Indeed, imagine simple card game involving two players P1
P2 , three cards: jack J, queen Q, king K. P1 must first play one
card x {J, Q, K}, P2 must play card {J, Q, K}, last P1 must play card
z {J, Q, K}. rule forbids play card consecutively (feasibility functions Fxy :
x 6= Fyz : 6= z). goal P1 two cards x z value strictly
better P2 card y. setting J < Q < K, requirement corresponds two utility
functions Uxy : x > Uyz : z > y. order compute optimal decisions presence
unfeasibilities, must restrict optimizations (eliminations decision variables max
min) feasible values: instead maxx miny maxz (Uxy Uyz ), must compute:



max
min
max
(Uxy (a, b) Uyz (b, c))
,
adom(x)

bdom(y),Fxy (a,b)=t

cdom(z),Fyz (b,c)=t

which, setting f t, logically equivalent


max min Fxy max (Fyz (Uxy Uyz )) .
x



z

latter quantity, feasibility functions concerning P2 play (y) taken account
using logical connective , P2 unfeasible decisions ignored set
scenarios considered. Feasibility functions concerning P1 last move (z) taken account using , P1 consider scenarios achieves forbidden move.
Therefore, feasibility functions cannot handled simply using combination
operator utility functions: need dissociate unfeasible decision
makers (unfeasibility absolute) unacceptable required one decision
maker (utility relative), i.e. decision maker wants decision maker
do.
general level, example Uxy Uyz soft requirements
know exactly advance controls variable, logical connectives
cannot used anymore. order ignore unfeasible values decision variables elimination, use truncation operator ? introduced Definition 6. order eliminate
variable x scoped function ignoring unfeasibilities indicated feasibility
function Fi , simply perform elimination x (Fi ? ) instead . maps
unfeasibilities value , ignored elimination operators (see Definition 6).
example above, Uxy Uyz additive gains costs, would compute


max min Fxy ? max (Fyz ? (Uxy + Uyz )) .
x



z

4.5 Combining Plausibilities Utilities via Expected Utility
define expected utilities, plausibilities utilities must combined. Consider
situation utility ui obtained plausibility pi [1, N ],

435

fiPralet, Verfaillie, & Schiex

p1 p . . . p pN = 1p . L = ((p1 , u1 ), . . . , (pN , uN )) classically called lottery (von Neumann & Morgenstern, 1944). speak expected utility, implicitly speak
expected utility EU (L) lottery L.
standard way combine plausibilities utilities use
P probabilistic expected utility (von Neumann & Morgenstern, 1944) defining EU (L) i[1,N ] (pi ui ):
aggregates plausibilities utilities using combination operator pu = projects
aggregated information using elimination operator u = +. However, alternative
definitions exist:
plausibilities possibilities, EU (L) = mini[1,N ] max(1 pi , ui )
possibilistic pessimistic expected utility (Dubois & Prade, 1995) (i.e. u = min
pu : (p, u) max(1p, u)) EU (L) = maxi[1,N ] min(pi , ui ) possibilistic
optimistic expected utility (Dubois & Prade, 1995) (i.e. u = max pu = min).
plausibilities -rankings utilities positive integers (Giang & Shenoy,
2000), EU (L) = mini[1,N ] (pi + ui ) (i.e. u = min pu = +).
generalize definitions EU (L), start Chu-Halperns work generalized expected utility (Chu & Halpern, 2003a, 2003b).
Chu-Halperns structure Generalized expected utility defined expectation domain, tuple (Ep , Eu , Eu0 , u , pu ) that: (1) Ep set plausibility degrees
Eu set utility degrees; (2) pu : Ep Eu Eu0 combines plausibilities
utilities satisfies 1p pu u = u; (3) u : Eu0 Eu0 Eu0 commutative associative
operator aggregate information combined using pu .
decision problem additive, i.e. when, plausibility degrees p1 , p2 associated disjoint events, (p1 p p2 ) pu u = (p1 pu u) u (p2 pu u), generic definition
expected utility lottery is:
EU (L) = u (pi pu ui ).
i[1,N ]

Classical expectation domains also satisfy additional properties u monotonic 0p pu u = 0u , 0u identity u .
Restriction Chu-Halperns structure sequential decision making
use pu : Ep Eu Eu0 u : Eu0 Eu0 Eu0 compute expected utilities
first decision step, need introduce operators 0pu : Ep Eu0 Eu00
0u : Eu00 Eu00 Eu00 compute expected utilities second decision step. end,
decision steps, must define operators pu operators u . order
avoid definition algebraic structure would depend number decision
steps, take Eu = Eu0 work one operator pu : Ep Eu Eu one
operator u : Eu Eu Eu .
plausibilities, sake future algorithms, restrict Chu-Halperns
expectation domains (Ep , Eu , Eu , u , pu ) u pu become closed generalize
properties initial u pu . However, closure sufficient deal
sequential decision making, Chu-Halperns expected utility designed one-step
decision processes only. introduce three additional axioms u pu :
436

fiThe PFU Framework

first axiom similar standard axiom lotteries (von Neumann & Morgenstern, 1944) defining compound lotteries. states lottery L2 involves
utility u plausibility p2 , one utilities lottery L1 expected
utility L2 plausibility p1 , utility u obtained
plausibility p1 p p2 . gives axiom p1 pu (p2 pu u) = (p1 p p2 ) pu u.
require pu distributes u . justify point, assume
lottery L = ((p1 , u1 ), (p2 , u2 )) obtained plausibility p. Two different versions
contribution L global utility degree derived: first p pu
((p1 pu u1 ) u (p2 pu u2 )), second, uses compound lotteries, ((p p
p1 ) pu u1 ) u ((p p p2 ) pu u2 ). want two quantities equal
p, p1 , p2 , u1 , u2 . shown equivalent simpler property p pu (u1 u
u2 ) = (p pu u1 ) u (p pu u2 ), i.e. pu distributes u .
Finally, assume pu right monotonic (i.e. (u1 u u2 ) (p pu u1 u
p pu u2 )). means agent prefers (strictly not) event ev2
another event ev1 , events plausibility degree p,
contribution ev2 global expected utility degree must lesser
contribution ev1 .
axioms define notion expected utility structure.
Definition 17. Let (Ep , p , p ) plausibility structure let (Eu , u ) utility
structure. (Ep , Eu , u , pu ) expected utility structure iff
(Eu , u , pu ) semimodule (Ep , p , p ) (cf. Definition 12),
u monotonic u pu right monotonic u ((u1 u u2 ) (ppu u1 u
p pu u2 )).
Many structures considered literature instances expected utility structures,
shown Proposition 2. results presented remaining article hold
usual expected utility structures, generally structures satisfying
axioms specified Definitions 14, 16, 17.
Proposition 2. structures Table 1 expected utility structures.
possible define complex expected utility structures existing ones.
example, two expected utility structures (Ep , Eu , u , pu ) (Ep0 , Eu0 , 0u , 0pu ),
possible build compound expected utility structure (Ep Ep0 , Eu Eu0 , 00u , 00pu ).
used deal simultaneously probabilistic possibilistic expected utility
generally deal tuples expected utilities.
business dinner example flesh definitions, consider following
toy example, referred sequel. correspond concrete
real-life problem, used simplicity. Peter invites John Mary (a divorced
couple) business dinner order convince invest company. Peter
knows John present end dinner, invest $10K. holds
Mary $50K. Peter knows John Mary come together (one
437

fiPralet, Verfaillie, & Schiex

1
2
3
4
5
6
7
8
9

Ep
R+
R+
[0, 1]
[0, 1]
N {}
{t, f }
{t, f }
{t, f }
{t, f }

p





bool
bool
bool
bool

p
+
+
max
max
min





p


min
min
+





0p , 1p
0, 1
0, 1
0, 1
0, 1
, 0
f,
f,
f,
f,

Eu
R {}
R+
[0, 1]
[0, 1]
N {}
{t, f }
{t, f }
{t, f }
{t, f }

u





bool
bool
bool
bool

u
+

min
min
+





u
+
+
max
min
min





pu
0u , 1u

0, 0

0, 1
min
0, 1
max(1p, u) 1, 1
+
, 0

f,

t,

f, f

t, f

Table 1: Expected utility structures for: 1. probabilistic expected utility additive
utilities (allows probabilistic expected utility cost gain computed); 2. probabilistic expected utility multiplicative utilities, also called
probabilistic expected satisfaction (allows probability satisfaction
constraints computed); 3. possibilistic optimistic expected utility; 4. possibilistic pessimistic expected utility; 5. qualitative utility -rankings
positive utilities; 6. boolean optimistic expected utility conjunctive utilities (allows one know whether exists possible world
goals set goals G satisfied); bool denotes order booleans
f bool t; 7. boolean pessimistic expected utility conjunctive utilities
(allows one know whether possible worlds, goals set goals G
satisfied); 8. boolean optimistic expected utility disjunctive utilities (allows
one know whether exists possible world least one goal
set goals G satisfied); 9. boolean pessimistic expected utility disjunctive
utilities (allows one know whether possible worlds, least one goal
set goals G satisfied).

baby-sit child), least one come, case John
comes Mary occurs probability 0.6. menu, Peter order
fish meat main course, white red wine. However, restaurant
serve fish red wine together. John like white wine Mary
like meat. menu suit them, leave dinner. John comes, Peter
want leave dinner best friend.
Example. dinner problem uses expected utility structure representing probabilistic
expected additive utility (row 1 Table 1): plausibility structure (R+ , +, ), u = +,
pu = , utilities additive gains ((Eu , u ) = (R {}, +), convention
u + () = ).
4.6 Relation Existing Structures
compare algebraic structures defined existing ones (Friedman & Halpern,
1995; Halpern, 2001; Chu & Halpern, 2003a), observe that:

438

fiThe PFU Framework

structures defined less general Friedman-Chu-Halperns, since additional axioms introduced. example, plausibility structures able
model belief functions (Shafer, 1976), decomposable, whereas
possible using Friedman-Halperns plausibility measures (however, authors
aware existing schemes decision theory using belief functions). Moreover, one-step decision processes, Chu-Halperns generalized expected utility
general, since assumes pu : Ep Eu Eu0 whereas consider
pu : Ep Eu Eu .
Conversely, structures defined deal multi-step decision processes
whereas Chu-Halperns generalized expected utility designed one-shot decision
processes. Beyond this, axioms, use closed operators, essentially motivated operational reasons. use less expressive structure
sake future algorithms (cf. Section 8).
set Ep plausibility degrees set Eu utility degrees defined, plausibilities utilities must cardinal. Purely ordinal approaches CP-nets (Boutilier,
Brafman, Domshlak, Hoos, & Poole, 2004), which, like Bayesian networks, exploit notion conditional independence express network purely ordinal preference relations,
covered.
pu takes values Eu , implicitly assumed plausibilities utilities
commensurable: works Fargier Perny (1999), describing purely ordinal approach,
qualitative preferences plausibilities necessarily commensurable,
captured either. Also, works Giang Shenoy (2005), satisfy required
associativity, commutativity, identity, annihilator, distributivity properties,
covered implicitly use pu : Ep Eu Eu0 Eu 6= Eu0 (even
expected utility EU (L) = (p1 pu u1 ) u (p2 pu u2 ) lottery L = ((p1 , u1 ), (p2 , u2 )) stays
Eu ).
Furthermore, axioms entail distributional plausibilities covered (the
plausibility set variable assignments determined plausibilities covered
complete assignment): Dempster-Shafer belief functions (Shafer, 1976) Choquet expected
utility (Schmeidler, 1989) encompassed. Finally, one partial order u Eu
defined, assumed decision makers share preferences utilities.
4.7 Summary
section, introduced expected utility structures, first element
PFU framework. specify plausibilities combined projected (using
p p respectively), utilities combined (using u ), plausibilities
utilities aggregated define generalized expected utility (using u pu ).
structure chosen inspired Friedman-Chu-Halperns plausibility measures generalized expected utility. main differences lie addition axioms deal
multi-step decision processes use extended domains closed operators,
motivated operational reasons.

439

fiPralet, Verfaillie, & Schiex

5. Plausibility-Feasibility-Utility Networks
second element PFU framework network scoped functions Pi , Fi ,
Ui (cf. Equation 8) set variables V . network defines compact structured representation state environment, decisions, global
plausibilities, feasibilities, utilities hold them.
rest article, plausibility function denotes scoped function Ep (the
set plausibility degrees), feasibility function scoped function {t, f } (the set
feasibility degrees), utility function, scoped function Eu (the set utility
degrees).
5.1 Variables
structured representations, decisions represented using decision variables,
directly controlled agent, state environment represented environment variables, directly controlled agent. notion agent used
restricted cooperative adversarial decision makers (if uncertainty
way decision maker behaves, decisions controls modeled
environment variables). use VD denote set decision variables denote
set environment variables. VD form partition V .
Example. dinner problem modeled using six variables: bpJ bpM (value
f ), representing Johns Marys presence beginning, epJ epM (value
f ), representing presence end, mc (value f ish meat), representing main
course choice, w (value white red), representing wine choice. Thus,
VD = {mc, w} = {bpJ , bpM , epJ , epM }.
5.2 Decomposing Plausibilities Feasibilities Local Functions
Using combined local functions represent global one raises considerations:
local functions obtained global one, conversely,
local functions directly used, implicit assumptions global function
made. show questions boil notion conditional
independence. following definitions propositions, (Ep , p , p ) corresponds
plausibility structure.
5.2.1 Preliminaries: Generalization Bayesian Networks Results
Assume want express global plausibility distribution PS (cf. Definition 15)
combination local plausibility functions Pi . work Bayesian networks (Pearl,
1988) shown, factorization joint distribution essentially related notion conditional independence. introduce conditional independence, first define
conditional plausibility distributions.
Definition 18. plausibility distribution PS said conditionable iff
exists set functions denoted PS1 | S2 (one function pair S1 , S2 disjoint subsets
S) S1 , S2 , S3 disjoint subsets S,

440

fiThe PFU Framework

(a) assignments S2 PS2 (A) 6= 0p , PS1 | S2 (A) plausibility distribution S1 ,3
(b) PS1 | = PS1 ,
(c) p S1 PS1 ,S2 | S3 = PS2 | S3 ,
(d) PS1 ,S2 | S3 = PS1 | S2 ,S3 p PS2 | S3 ,
(e) (PS1 ,S2 ,S3 = PS1 | S3 p PS2 | S3 p PS3 ) (PS1 ,S2 | S3 = PS1 | S3 p PS2 | S3 ).
PS1 | S2 called conditional plausibility distribution S1 given S2 .
Condition (a) means conditional plausibility distributions must normalized.
Condition (b) means information given empty set variables
change plausibilities states environment. Condition (c) means
conditional plausibility distributions consistent marginalization point view.
Condition (d) analog so-called chain rule probabilities. Condition (e)
kind weak division axiom.4
Proposition 3 gives simple conditions plausibility structure, satisfied usual
frameworks, suffice plausibility distributions conditionable.
Definition 19. plausibility structure (Ep , p , p ) called conditionable plausibility
structure iff satisfies axioms:
p1 p p2 p2 6= 0p , max{p Ep | p1 = p p p2 } exists p 1p ,
p1 p p2 , exists unique p Ep p1 = p p p2 ,
p1 p p2 , exists unique p Ep p2 = p p p1 .
Proposition 3. (Ep , p , p ) conditionable plausibility structure, plausibility distributions conditionable: suffices define PS1 | S2 PS1 | S2 (A) = max{p
Ep | PS1 ,S2 (A) = p p PS2 (A)} dom(S1 S2 ) satisfying PS2 (A) 6= 0p .
systematic definition conditional plausibility distributions given Proposition 3
fits usual definitions conditional distributions, are, probabilities,
PS1 | S2 (A) = PS1 ,S2 (A)/PS2 (A), -rankings, PS1 | S2 (A) = PS1 ,S2 (A) PS2 (A),
possibility degrees combined using min, PS1 | S2 (A) = PS1 ,S2 (A) PS1 ,S2 (A) <
PS2 (A), 1 otherwise. following, every conditioning statement PS1 | S2 conditionable plausibility structures refer canonical notion conditioning given
Proposition 3. Conditional independence defined.
3. avoid specifying properties PS1 | S2 hold assignments S1 S2 satisfying PS2 (A) 6=
0p , use expressions PS1 | S2 = denote dom(S1 S2 ), (PS2 (A) 6= 0p )
(PS1 | S2 (A) = (A)).
4. Compared Friedman Halperns conditional plausibility measures (Friedman & Halpern, 1995;
Halpern, 2001), (c) analog axiom (Alg1), (d) analog axiom (Alg2), (e) analog
axiom (Alg4), axiom (Alg3) corresponds distributivity p p .

441

fiPralet, Verfaillie, & Schiex

Definition 20. Let (Ep , p , p ) conditionable plausibility structure. Let PS
plausibility distribution S1 , S2 , S3 disjoint subsets S. S1 said
conditionally independent S2 given S3 , denoted I(S1 , S2 | S3 ), iff PS1 ,S2 | S3 = PS1 | S3 p
PS2 | S3 .
means S1 conditionally independent S2 given S3 , iff problem
split one part depending S1 S3 , another part depending S2 S3 .5
definition satisfies usual properties conditional independence, Proposition 4
shows.
Proposition 4. I(., . | .) satisfies semigraphoid axioms:
1. symmetry: I(S1 , S2 | S3 ) I(S2 , S1 | S3 ),
2. decomposition: I(S1 , S2 S3 | S4 ) I(S1 , S2 | S4 ),
3. weak union: I(S1 , S2 S3 | S4 ) I(S1 , S2 | S3 S4 ),
4. contraction: (I(S1 , S2 | S4 ) I(S1 , S3 | S2 S4 )) I(S1 , S2 S3 | S4 ).
Proposition 4 makes possible use Bayesian network techniques express information compact way. Bayesian networks, DAG variables used represent
conditional independences variables (Pearl, 1988). cases, image
processing statistical physics, natural express conditional independences
sets variables. probabilities used, situations modeled using chain graphs (Frydenberg, 1990). chain graph, DAG defined DAG
variables, DAG sets variables, called components. Conditional probability distributions Px | paG (x) variables replaced conditional probability distributions Pc | paG (c)
components, Pc | paG (c) expressed factored form c1 c2 . . .ckc . Markov
random fields (Chellappa & Jain, 1993) correspond case Q
unique
component equal V , factored form PV looks like 1/Z jJ eHj
(Gibbs distribution).
formally introduce DAGs sets variables, called DAGs components,
use factor plausibility distributions.
Definition 21. DAG G said DAG components set variables iff
vertices G form partition S. C(G) denotes set components G.
c C(G), paG (c) denotes set variables included parents c G, ndG (c)
denotes set variables included non-descendant components c G.
Definition 22. Let (Ep , p , p ) conditionable plausibility structure. Let PS
plausibility distribution let G DAG components S. G said
compatible PS iff I(c, ndG (c) paG (c) | paG (c)) c C(G) (c conditionally
independent non-descendants given parents).
5. Definition 20 differs Halperns, S1 conditionally independent (CI) S2 given S3 iff
PS1 | S2 ,S3 = PS1 | S3 PS2 | S1 ,S3 = PS2 | S3 . Halpern (2001) called definition adopt noninteractivity (NI) showed NI weaker CI. implies NI satisfied often
may lead factorizations. Halpern gave simple axiom (axiom (Alg4)) CI
NI equivalent. Though axiom holds many usual frameworks, hold possibility
degrees combined using min, case covered PFU algebraic structure.

442

fiThe PFU Framework

Theorem 1. (Conditional independence factorization) Let (Ep , p , p ) conditionable plausibility structure let G DAG components S.
(a) G compatible plausibility distribution PS S, PS = p cC(G) Pc | paG (c) .
(b) If, c C(G), function c,paG (c) c,paG (c) (A) plausibility
distribution c assignments paG (c), = p cC(G) c,paG (c)
plausibility distribution G compatible.
Theorem 1 links conditional independence factorization. Theorem 1(a) generalization usual result Bayesian networks (Pearl, 1988) says DAG
variables
compatible probability distribution PS , PS factored
Q
PS = xS Px | paG (x) . Theorem 1(b) generalization standard result Bayesian
networks (Pearl, 1988) says that, given DAG G variables
Q S, conditional
probabilities Px | paG (x) defined variable x S, xS Px | paG (x) defines
probability distribution G compatible. results generalizations
since hold arbitrary plausibility distributions (and probability distributions
only). Results similar spirit provided Halpern (2001), gives conditions
plausibility measure represented Bayesian network.
Theorem 1(a) entails that, order factor global plausibility distribution PS ,
suffices define DAG components compatible it, i.e. express conditional
independences. define DAG, following systematic procedure used.
initial DAG components empty DAG G. C(G) = {c1 , . . . , ck1 }
partition S, do:
1. Let Sk = c1 . . . ck1 ; choose subset ck set Sk variables already
considered.
2. Add ck component G find minimal subset pak Sk I(ck , Sk
pak | pak ). Add edges directed components containing least one variable
pak ck , paG (ck ) = (c{c1 ,...,ck1 })/(cpak 6=) c.
resulting DAG components guaranteed compatible PS , implies, using Theorem 1(a), local functions Pi representing PS simply defined
functions set {Pc | paG (c) , c C(G)}. practice, reasonable notion
causes effects, networks smaller somehow easier build
obtained using following two heuristics order choose ck step
procedure above:
(R1) Consider causes effects: dinner problem, suggests putting epJ
ck causes bpJ w Sk .
(R2) Gather component variables correlated even variables Sk
assigned : bpJ bpM correlated (R1) apply. Indeed, cannot
say bpJ causal influence bpM , bpM causal influence bpJ ,
since Mary John chooses first (s)he baby-sits specified.
even assume bpJ bpM correlated via unmodeled common cause,

443

fiPralet, Verfaillie, & Schiex

coin toss determines baby-sitter. Hence, bpJ bpM put
component c = {bpJ , bpM }.6
say (R1) (R2) build DAG respecting causality. must seen
possible mechanisms help identifying conditional independences using notions
causes effects.
previous results extending Bayesian networks results plausibility distributions
also apply feasibilities. Indeed, feasibility structure Sf = ({t, f }, , ) particular
case conditionable plausibility structure, since satisfies axioms Definition 19.
may therefore speak conditional feasibility distribution. set decision
variables, construction DAG compatible feasibility distribution FS leads
factorization FS = cC(G) Fc | paG (c) .
5.2.2 Taking Differenty Types Variables Account
material defined previous subsection enables us factor one plausibility distribution PVE defined set environment variables one feasibility distribution
FVD defined set VD decision variables. However, dealing one plausibility
distribution one feasibility distribution VD sufficient.
Indeed, plausibilities, decision variables influence environment (for example,
health state patient depends treatment chosen doctor). Rather
expressing one plausibility distribution , want express family plausibility distributions , one assignment VD . make clear, define
controlled plausibility distributions.
Definition 23. plausibility distribution controlled VD (or controlled
plausibility distribution), denoted PVE || VD , function dom(VE VD ) Ep ,
assignments AD VD , PVE || VD (AD ) plausibility distribution .
feasibilities, goes way around: values environment variables
constrain possible decisions (for example, unmanned aerial vehicle flying
cannot take off). Thus, want express family feasibility distributions VD ,
one assignment . words, want express controlled feasibility
distribution FVD || .
order directly reuse Theorem 1 controlled distributions, introduce notion
completion controlled distribution. allows us extend distribution
full set variables V assigning plausibility (resp. feasibility) degree
every assignment VD (resp. ), work one plausibility (resp. feasibility)
distribution.
6. Components {bpJ , bpM } could broken assuming example bpM causally influences
bpJ , i.e. Mary chooses baby-sits first. (and prefer to) keep component
{bpJ , bpM } because, general, breaking components increase scopes functions involved.
example, assume want model plausibilities variables representing colors pixels
N N image, color pixel probabilistically depends colors 4 neighbors
only. component approach, results Markov random fields (Chellappa & Jain, 1993) show
local functions obtained scopes size 5 only, whereas component-breaking mechanism,
size largest scope linear N .

444

fiThe PFU Framework

Proposition 5. Let (Ep , p , p ) conditionable plausibility structure. Then,
n N , exists unique p0 p i{1,...,n} p0 = 1p .
Definition 24. Let (Ep , p , p ) conditionable plausibility structure let PVE || VD
controlled plausibility distribution. Then, completion PVE || VD function denoted
PVE ,VD , defined PVE ,VD = PVE || VD p p0 , p0 unique element Ep
p i[1,|dom(VD )|] p0 = 1p (the cardinality set denoted ||).
words, PVE ,VD defined PVE || VD assigning plausibility degree
p0 assignments VD . case probability theory, corresponds saying
assignments VD equiprobable. definition completion controlled
plausibility distribution could made flexible: instead defining uniform plausibility distribution VD , could define plausibility distribution assignment
VD 0p plausibility degree. arbitrarily choose uniform distribution,
goal introduce prior plausibilities decision variables, sake
factorization.
Proposition 6. Let PVE ,VD completion controlled plausibility distribution PVE || VD .
Then, PVE ,VD plausibility distribution VD PVE | VD = PVE || VD .
result, use PVE | VD denote PVE || VD (and equivalent). Similarly,
possible complete controlled feasibility distribution FVD || .
5.2.3 First Factorization
Proposition 7 below, entailed Theorem 1(a), shows obtain first factorization
PVE | VD FVD | .
Definition 25. DAG G typed DAG components VD iff vertices
G form partition VD element partition subset either
VD . vertex G called component. set components contained
(environment components) denoted CE (G) set components contained VD
(decision components) denoted CD (G).
Proposition 7. Let G typed DAG components VD . Let Gp partial
graph G induced arcs G incident environment components. Let Gf
partial graph G induced arcs G incident decision components. Gp
compatible completion PVE || VD (cf. Definition 22) Gf compatible
completion FVD || ,
PVE | VD =

p Pc | paG (c)
cCE (G)

FVD | =


cCD (G)

Fc | paG (c) .

allows us specify local Pi Fi functions: suffices express Pc | paG (c)
Fc | paG (c) express PVE | VD FVD | compact way. fact, could
defined two DAGs, one factorization PVE | VD factorization
FVD | , two DAGs actually always merged soon make
(undemanding) assumption impossible, given x VD , x
influences constrains possible decision values x. assumption ensures
union two DAGs create cycles. use one DAG simplicity.
445

fiPralet, Verfaillie, & Schiex

Example. Consider dinner problem illustrate first factorization step. One way
obtain G use causality-based reasoning described Theorem 1. start
empty DAG. epJ epM effects bpJ , bpM , w, mc,
considered first component c1 . bpJ chosen variable add c1 ,
cannot say bpJ necessarily effect another variable. previously explained,
bpJ cause bpM , effect bpM , bpJ may correlated bpM via
unmodeled cause. result, get c1 = {bpJ , bpM } first component. Obviously, c1
parents DAG first added component.
Then, epJ epM effects w mc, consider epJ epM
second component c2 . Since w necessarily effect mc, add w c2 .
dinner problem specifies ordering fish red wine simultaneously feasible,
know whether wine chosen main course, i.e. w
cause effect mc. result, take c2 = {mc, w}. menu choice
independent present beginning, c2 parent temporary DAG.
epJ direct effect bpJ w (John leaves dinner white wine
chosen), add epJ c3 . Moreover, epJ correlated epM c1 c2 =
{bpJ , bpM , mc, w} assigned. Therefore, take c3 = {epJ }. Given epJ depends
bpJ w, c3 gets {bpJ , bpM } {mc, w} parents. Finally, c4 = {epM }, epM
depends bpM mc (Mary leaves meat chosen) independent epJ given bpM
mc, I({epM }, {epJ , bpJ , w} | {bpM , mc}). entails {epM } added
DAG {bpJ , bpM } {mc, w} parents. Therefore, get CD (G) = {{mc, w}}
set decision components CE (G) = {{bpJ , bpM }, {epJ }, {epM }} set
environment components. DAG components shown Figure 1a.
Using Proposition 7, know joint probability distribution factors PVE | VD =
PbpJ ,bpM PepJ | bpJ ,bpM ,mc,w PepM | bpJ ,bpM ,mc,w joint feasibility distribution
factored FVD | = Fmc,w .
5.2.4 Factorization Steps
Proposition 7 provides us decomposition PVE | VD FVD | based conditional independence relation I(., . | .) Definition 20. may possible perform
factorization steps factoring Pc | paG (c) set local plausibility functions Pi
factoring Fc | paG (c) set local feasibility functions Fi .
cases, expressing factors Pc | paG (c) Fc | paG (c) quite natural. example, p = , variables environment component c = {xi,j | i, j [1, n]}
without parents represent pixel colors, want model Pc two
adjacent pixels different colors, natural define set binary differ
ence constraints xi,j ,xk,l

factor
P

P
=




c
c
x
,x
i[1,n1]
j[1,n]
i,j
i+1,j

i[1,n] j[1,n1] xi,j ,xi,j+1 . decomposition cannot obtained based
conditional independence relation I(., . | .) Definition 20.
settings, Markov random fields (Chellappa & Jain, 1993), systematic
techniques exist obtain factorizations. Bayesian network community
also offers systematic techniques: hybrid networks (Dechter & Larkin, 2001),
extract deterministic information contained conditional probability
distributions. precisely, conditional probability distribution Px | paG (x)
446

fiThe PFU Framework

expressed Px | paG (x) = Px | paG (x) , 0-1 function defined

0 Px | paG (x) (A) = 0
(A) =
. factorization Px | paG (x) Px | paG (x)
1 otherwise
computationally relevant constraint propagation techniques 0-1 functions
used solve hybrid networks.
may use another weaker definition conditional independence: valuation-based
systems (Shenoy, 1994), S1 S2 said conditionally independent given S3
regard function S1 ,S2 ,S3 function factors two scoped functions
scopes S1 S3 S2 S3 . definition used first factorization
step destroys normalization conditions may useful
computational point view.
additional factorization steps interest decreasing size
scopes functions involved adding redundant information problem
computationally useful.
every environment component c, Pi F act(c) stands Pi factor
Pc | paG (c) , second factorization gives us
Pc | paG (c) =

p
Pi .
Pi F act(c)

p c Pc | paG (c) = 1p , Pi functions F act(c) satisfy normalization condition
p c (p Pi F act(c) Pi ) = 1p . scopes sc(Pi ) contained sc(Pc | paG (c) ) = c paG (c).
every decision component c, Fi F act(c) stands Fi factor Fc | paG (c) ,
second factorization gives us
Fc | paG (c) =



Fi F act(c)

Fi .

Given c Fc | paG (c) = t, Fi functions F act(c) satisfy normalization condition
c Fi F act(c) Fi = t. Moreover, sc(Fi ) c paG (c).
factorizations, decrease scopes functions involved, could
also exploited. Indeed, scoped function Pi Fi internal local
structure, instance Pi noisy-OR gate (Pearl, 1988) Bayesian network,
presence context-specific independence (Boutilier, Friedman, Goldszmidt, & Koller,
1996). internal local structures made explicit representing functions
tools Algebraic Decision Diagrams (Bahar, Frohm, Gaona, Hachtel, Macii, Pardo,
& Somenzi, 1993). rest article, make assumption way
scoped function represented.
Example. PbpJ ,bpM expressed terms first plausibility function P1 specifying probability John Mary present beginning. P1 defined
P1 ((bpJ , t).(bpM , f )) = 0.6, P1 ((bpJ , f ).(bpM , t)) = 0.4, P1 ((bpJ , t).(bpM , t)) =
P1 ((bpJ , f ).(bpM , f )) = 0. also add redundant deterministic information second plausibility function P2 defined constraint bpJ 6= bpM (P2 (A) = 1 constraint
satisfied, 0 otherwise). get PbpJ ,bpM = P1 p P2 F act({bpJ , bpM }) = {P1 , P2 }.

447

fiPralet, Verfaillie, & Schiex

PepJ | bpJ ,bpM ,mc,w specified combination two plausibility functions P3
P4 . P3 expresses John absent beginning, absent end: P3
hard constraint (bpJ = f ) (epJ = f ) (P3 (A) = 1 constraint satisfied, 0 otherwise).
Then, P4 : (bpJ = t) ((epJ = t) (w 6= white)) hard constraint specifying
John leaves iff white wine chosen. Hence, PepJ | bpJ ,bpM ,mc,w = P3 p P4
F act({epJ }) = {P3 , P4 }. Similarly, PepM | bpJ ,bpM ,mc,w = P5 p P6 , P5 , P6 defined
constraints, F act({epM }) = {P5 , P6 }.
feasibilities, Fmc,w specified feasibility function F1 expressing ordering fish red wine allowed: F1 : ((mc = f ish)(w = red)) F act({mc, w})
= {F1 }. association local functions components appears Figure 1a.
5.3 Local Utilities
Local utilities defined states environment (as utility
health state patient), decisions (as utility decision buying
car not), states environment decisions (as utility
result horse race bet race).7
order specify local utilities, one standard approach, used CSPs influence
diagrams, directly define set U local utility functions, modeling preferences
hard requirements, decision environment variables. set implicitly defines
global utility UV = uUi U Ui variables. factored form obtained
global joint utility, one may rely, u = +, work Fishburn (1982)
Bacchus-Grove (1995), introduced notion conditional independence utilities.
normalization condition imposed local utilities.
Example. dinner problem, three local utility functions defined. binary
utility function U1 expresses Peter want John leave dinner: U1
hard constraint (bpJ = t) (epJ = t) (U1 (A) = 0 constraint satisfied,
otherwise). Two unary utility functions U2 U3 epJ epM respectively express
gains expected presences end: U2 ((epJ , t)) = 10 U2 ((epJ , f )) = 0 (John
invests $10K present end), U3 ((epM , t)) = 50 U3 ((epM , f )) = 0
(Mary invests $50K present end). U2 U3 viewed soft constraints.
local functions represented graphical model Figure 1b.
5.4 Formal Definition PFU Networks
formally define Plausibility-Feasibility-Utility networks. definition justified previous construction process, holds even plausibility structure
conditionable.
7. influence diagrams, special nodes called value nodes introduced represent outcome
decisions, one utility function associated value nodes (the utility outcome).
PFU framework, directly represent utility functions scoped functions hold
parents value nodes. explicitly express utility functions scoped functions,
plausibility feasibility functions. words, utility functions directly utilities outcome
decision environment variables assignments.

448

fiThe PFU Framework

P4
mc, w

bpJ , bpM
P1 , P 2

F1

w
F1

epJ

epM

P3 , P 4

P5 , P 6

(a)

mc

bpJ

P3

environment

P2 U1

P1

bpM

P5

decision

epJ
U2

plausibility
function

epM

P6

feasibility
function

U3

utility
function

(b)

Figure 1: (a) DAG components (b) Network scoped functions.
Definition 26. Plausibility-Feasibility-Utility network expected utility structure
tuple N = (V, G, P, F, U ) following conditions hold:
V = {x1 , x2 , . . .} finite set finite domain variables. V partitioned VD
(decision variables) (environment variables);
G typed DAG components VD (cf. Definition 25);
P = {P1 , P2 , . . .} finite set plausibility functions. Pi P associated unique component c CE (G) sc(Pi ) c paG (c). set
Pi P associated component c CE (G) denoted F act(c) must satisfy
p (p Pi F act(c) Pi ) = 1p ;
c

F = {F1 , F2 , . . .} finite set feasibility functions. function Fi associated
unique component c CD (G) sc(Fi ) c paG (c). set
Fi F associated
component c CD (G) denoted F act(c) must satisfy
Fi F act(c) Fi = t;
c

U = {U1 , U2 , . . .} finite set utility functions.
5.5 PFU Networks Global Functions
seen obtain PFU network expressing global controlled plausibility
distribution PVE || VD , global controlled feasibility distribution FVD || , global utility
UV . Conversely, let N = (V, G, P, F, U ) PFU network, i.e. set variables, typed
DAG components, sets scoped functions.
global function = p Pi P Pi controlled plausibility distribution given
VD . Moreover, Theorem 1(b), plausibility structure conditionable
Gp partial DAG G induced arcs incident environment components,
Gp compatible completion ;
global function = Fi F Fi controlled feasibility distribution VD given
. Moreover, Theorem 1(b), Gf partial DAG G induced arcs
G incident decision components, Gf compatible completion ;
449

fiPralet, Verfaillie, & Schiex

= uUi U Ui necessarily global utility.
therefore denote PVE || VD , FVD || , UV .
5.6 Back Existing Frameworks
Let us consider formalisms described Section 3 again.
CSP (hard soft) easily represented PFU network N = (V, G, , , U ):
variables V decision variables, G reduced single decision component
containing variables, constraints represented utility functions. Using
feasibility functions represent constraints, would impossible represent inconsistent networks normalization conditions feasibilities. SAT
modeled similarly; difference constraints replaced clauses.
PFU network used represent local functions quantified
boolean formula quantified CSP. differences CSPs SAT appear
consider queries network (see Section 6).
Bayesian network modeled N = (V, G, P, , ): variables V
environment variables, G DAG BN, P = {Px | paG (x) , x V }.
feasibility utility function. chain graph also modeled N = (V, G, P, , ),
G DAG components chain graph P set factors
Pc | paG (c) .
stochastic CSP represented PFU network N = (V, G, P, , U ), V
partitioned VD , set decision variables, , set stochastic
variables, G DAG depends relations stochastic variables,
P set probability distributions stochastic variables, U set
constraints.
influence diagram modeled N = (V, G, P, , U ) VD contains
decision variables, contains chance variables, G DAG influence
diagram without utility nodes arcs random variables (i.e.
keep so-called influence arcs), P = {Px | paG (x) , x }.
feasibilities, one utility function Ui defined per utility variable u, scope
Ui paG (u). represent valuation networks, set F feasibility functions
added. Note business dinner example could modeled using standard influence diagram, since influence diagrams cannot model feasibilities
(suitable extensions exist however, Shenoy, 2000).
finite horizon probabilistic MDP modeled N = (V, G, P, F, U ).
time-steps, VD = {dt , [1, ]}{s1 } = {st , [2, ]};8 G DAG
components (a) component contains one variable, (b) unique parent
decision component {dt } {st }, (c) parents environment component
{st+1 } {st } {dt }; P = {Pst+1 |st ,dt , [1, 1]}, F = {Fdt | st , [1, ]},
U = {Rst ,dt , [1, ]}. Modeling finite horizon possibilistic MDP similar.
8. plausibility distribution initial state s1 , s1 viewed environment
variable. corresponds special case decision variables model problem parameters.

450

fiThe PFU Framework

5.7 Summary
section, introduced second element PFU framework: network
variables linked local plausibility, feasibility, utility functions, DAG capturing
normalization conditions. factorization global plausibilities, feasibilities, utilities
scoped functions linked conditional independence.

6. Queries PFU Network
query correspond reasoning task information expressed PFU network.
decision variables involved PFU network considered, answering query may
provide decision rules. Examples informal queries dinner problem
1. best menu choice Peter know present beginning?
2. best menu choice Peter knows present beginning?
3. maximize expected investment restaurant chooses main
course first Peter pessimistic choice, present
beginning observed, last Peter chooses wine?
Dissociating PFU networks queries consistent trend influence diagram community relax so-called information links, Unconstrained Influence
Diagrams (Jensen & Vomlelova, 2002) Limited Memory Influence Diagrams (Lauritzen
& Nilsson, 2001): explains intuition queries change local relations
variables.
section, define simple class queries PFU networks. assume
sequence decisions must performed, order decisions
observations made known. also make no-forgetting assumption, is,
making decision, agent aware previous decisions observations.
on, set utility degrees Eu assumed totally ordered. total order
assumption, holds standard frameworks, implies always
exists optimal decision rule. See Subsection 6.7 discussion extend
results partial order.
Two definitions answer query given, first based decision trees,
second operational. equivalence two definitions
established.
6.1 Query Definition
order formulate reasoning tasks PFU network, use sequence Sov operatorvariable(s) pairs. sequence captures different aspects query:
Partial observabilities: Sov specifies order decisions made environment variables observed. x appears left VD (for example
Sov = . . . (u , {x}) . . . (max, {y}) . . .), means value x known (observed) value chosen. Conversely, Sov = . . . (max, {y}) . . . (u , {x}) . . .
x observed choosing y.
451

fiPralet, Verfaillie, & Schiex

Optimistic/pessimistic attitude concerning decision makers: (max, {y}) inserted
elimination sequence decision maker optimistic behavior
agent controlling decision variable (i.e. agent cooperative),
(min, {y}) one pessimistic (i.e. agent controlling adversary).
operator used environment variables always u , model expected
utilities sought.9
Parameters decision making problem: set variables involved
Sov kind parameters. absence indicates want obtain optimal
expected utilities and/or optimal policies assignment S. useful
order evaluate several scenarios simultaneously.
Example. sequence corresponding informal query: maximize
expected investment restaurant chooses main course first Peter pessimistic
choice, present beginning dinner observed, last
Peter chooses wine knowing present end?
Sov = (min, {mc}).(u , {bpJ , bpM }).(max, {w}).(u , {epJ , epM }).
models fact that: (1) Peter pessimistic main course (min mc),
chosen without observing variable (no variable left mc Sov); (2) Peter
makes best choice wine (max w) main course chosen
knowing present beginning (w appears right mc, bpJ , bpM
Sov), knowing present end (w appears left epJ , epM ).
Specifically, bpJ bpM partially observable, whereas epJ epM unobservable.
query becomes Peter observes present beginning
dinner chooses wine knowing present end?,
sequence use Sov = (u , {bpJ , bpM }).(max, {w}).(u , {epJ , epM }). case,
variable mc appear sequence anymore, means mc parameter
answer value parameter sought.
Definition 27. query PFU network pair Q = (N , Sov) N PFU
network Sov = (op1 , S1 )(op2 , S2 ) (opk , Sk ) sequence operator-set variables
pairs
(1) Si disjoint;
(2) either Si VD opi = min max, Si opi = u ;
(3) variables involved Si , called free variables, decision variables;
(4) variables x, different types (one decision variable,
environment variable), directed path component contains
x component contains DAG PFU network N , x
appear right Sov, i.e. either x appears left y, x free
variable.
9. decision made nature plausibility distribution decision,
decision viewed environment variable.

452

fiThe PFU Framework

Condition (1) ensures variable eliminated once. Condition (2) means
optimal decisions sought decision variables (either maximized decision
maker controls decision variable cooperative, minimized adversarial),
whereas expected utilities sought environment variables. Condition (3) means
variables eliminated Sov act problem parameters viewed
decision variables. Condition (4) means x different types x
ancestor y, x assigned y. ensures causality respected variables different types: example, (N , (u , {bpJ , bpM , epJ , epM }).(max, {mc, w})),
violates condition (4), violates causality since menu cannot chosen knowing
present end.
Variables appearing Sov called quantified variables, analogy quantified
boolean formulas. set free variables denoted Vf r . Notice definition
queries prevent environment variable quantified min max,
may u = min u = max. Note also straightforward
every PFU network N , exists least one query N without free variables.
[1, k], define
set l(Si ) variables appearing Vf r left Si Sov l(Si ) =
Vf r (j[1,i1] Sj );
set r(Si ) variables appearing right Si Sov r(Si ) = j[i+1,k] Sj .
6.2 Semantic Answer Query
subsection, assume plausibility structure conditionable (cf. Definition 19). controlled plausibility distribution PVE || VD = p Pi P Pi completed (cf. Definition 24) give plausibility distribution PVE ,VD VD . Similarly,
controlled feasibility distribution FVD || = Fi F Fi completed give feasibility distribution FVE ,VD VD . also use global utility UV = uUi U Ui
defined PFU network.
Imagine want answer query Q = (N , Sov), N network
dinner problem Sov = (min, {mc}).(u , {bpJ , bpM }).(max, {w}).(u , {epJ , epM }).
answer query, use decision tree. First, restaurant chooses
worst possible main course, taking account feasibility distribution mc. Here,
Fmc ((mc, meat)) = Fmc,w ((mc, meat).(w, white)) Fmc,w ((mc, meat).(w, red)) = =
t. Similarly, Fmc ((mc, f ish)) = t. choices feasible. Then, A1 denotes
assignment mc, uncertainty present beginning given main
course choice described probability distribution PbpJ ,bpM | mc (A1 ). possible
assignment A2 {bpJ , bpM }, i.e. A2 PbpJ ,bpM | mc (A1 .A2 ) 6= 0p , Peter
chooses best wine taking account feasibility Fw | mc,bpJ ,bpM (A1 .A2 ):
restaurant chooses meat, Peter chooses optimal value red white,
restaurant chooses fish, Peter choose white wine only. Then, feasible
assignment A3 w, uncertainty regarding presence John Mary end
dinner given PepJ ,epM | bpJ ,bpM ,mc,w (A1 .A2 .A3 ).
Note conditional probabilities used decision tree directly
defined network. must computed global distributions.
computation challenge large problems.
453

fiPralet, Verfaillie, & Schiex

utility UV (A1 .A2 .A3 .A4 ) associated possible complete assignment
A1 .A2 .A3 .A4 variables. possible assignment A1 .A2 .A3 {bpJ , bpM , mc, w},
last stage, i.e. one epJ epM assigned,
P seen lottery (von
Neumann & Morgenstern, 1944) whose expected utility A4 dom({epJ ,epM }) p(A4 )u(A4 ),
p(A4 ) = PepJ ,epM | bpJ ,bpM ,mc,w (A1 .A2 .A3 .A4 ) u(A4 ) = UV (A1 .A2 .A3 .A4 ).
expected utility becomes reward scenario {bpM , bpJ , mc, w} described
A1 .A2 .A3 . provides us criterion choosing optimal value w. step
bpJ bpM assigned seen lottery, provides us
criterion choosing worst value mc. computation associated previously
described process is:
min
A1 dom(mc),Fmc (A1 )=t
X
PbpJ ,bpM | mc (A1 .A2 )
(
A2 dom({bpJ ,bpM }),PbpJ ,bpM

(

max
X

| mc (A1 .A2 )6=0

A3 dom(w),Fw | mc,bpJ ,bpM (A1 .A2 .A3 )=t

(

PepJ ,epM | bpJ ,bpM ,mc,w (A1 .A2 .A3 .A4 )

A4 dom({epJ , epM })
PepJ ,epM | bpJ ,bpM ,mc,w (A1 .A2 .A3 .A4 ) 6= 0

UV (A1 .A2 .A3 .A4 )))).

Decision rules decision variables (argmin argmax) recorded
computation. formulation represents decision process decision tree
internal level corresponds variable assignments. Arcs associated
assignment set decision variables weighted feasibility decision given
previous assignments. Arcs associated assignment environment variables
weighted plausibility degree assignment given previous assignments. Leaf
nodes correspond utilities complete assignments, node collects values
children compute value.
6.2.1 Formalization Decision Tree Procedure
order formalize decision tree procedure, technical results first introduced
Proposition 8. results definitions preceding skipped first
reading.
Definition 28. Let PS1 | S2 conditional plausibility distribution S1 given S2 let
dom(S2 ). function PS1 | S2 (A) said well-defined iff PS2 (A) 6= 0p . Similarly,
FS1 | S2 conditional feasibility distribution S1 given S2 , then, dom(S2 ),
FS1 | S2 (A) said well-defined iff FS2 (A) = t.
Next, conditioning defined directly controlled plausibility distributions
dom(VD ), PVE || VD (A) plausibility distribution :
Definition 29. Assume plausibility structure used conditionable. Let PVE || VD
controlled plausibility distribution S, 0 two disjoint subsets . define
conditional controlled plausibility distributions by: dom(S 0 VD )
PS 0 || VD (A) 6= 0p , PS | 0 || VD (A) = max{p Ep | PS,S 0 || VD (A) = p p PS 0 || VD (A)},
canonical definition conditioning given Proposition 3. Given controlled feasi454

fiThe PFU Framework

bility distribution FVD || , definition conditional controlled feasibility distributions
FS | 0 || S, 0 disjoint subsets VD similar.
Proposition 8. Assume plausibility structure used conditionable. Let Q =
(N , Sov) query Sov = (op1 , S1 ) (op2 , S2 ) (opk , Sk ). Let Vf r denote set
free variables Q.
(1) Si PSi | l(Si ) (A) well-defined, exists least one A0 dom(Si )
satisfying PSi | l(Si ) (A.A0 ) 6= 0p .
(2) Si VD FSi | l(Si ) (A) well-defined, exists least one A0 dom(Si )
satisfying FSi | l(Si ) (A.A0 ) = t.
(3) 6= Si leftmost set environment variables appearing Sov, then,
dom(l(Si )), PSi | l(Si ) (A) well-defined.
(4) i, j [1, k], < j, Si , Sj , r(Si ) l(Sj ) VD (Sj first set environment variables appearing right Si Sov), (A, A0 ) dom(l(Si ))dom(Si ),
PSi | l(Si ) (A) well-defined, PSi | l(Si ) (A.A0 ) 6= 0p , then, A00 extending A.A0
l(Sj ), PSj | l(Sj ) (A00 ) well-defined.
(5) i, j [1, k], < j, Si VD , Sj VD , r(Si ) l(Sj ) (Sj first set
decision variables appearing right Si Sov), (A, A0 ) dom(l(Si ))dom(Si ),
FSi | l(Si ) (A) well-defined, FSi | l(Si ) (A.A0 ) = t, then, A00 extending A.A0
l(Sj ), FSj | l(Sj ) (A00 ) well-defined.
(6) [1, k] Si , PSi | l(Si ) = PSi | l(Si )VE ||VD .
(7) [1, k] Si VD , FSi | l(Si ) = FSi | l(Si )VD ||VE .
technical results Proposition 8 ensure that, following semantic answer
query (see Definition 30),
quantities PS | l(S) (A.A0 ) FS | l(S) (A.A0 ) used defined (thanks items 3
5 Proposition 8);
eliminations restricted domains defined restricted domains
used never empty (items 1 2 Proposition 8);
conditional distributions used coincide conditioning defined directly
controlled plausibility feasibility distributions PVE || VD FVD || (items 6
7 Proposition 8). useful guarantees PS | l(S) (A.A0 )
FS | l(S) (A.A0 ), priori require notion completion written,
actually independent notion completion, arbitrarily added
basic information expressed PFU network. use PS | l(S) FS | l(S) instead
conditional controlled distributions PS | l(S)VE || VD FS | l(S)VD || notation
convenience explicitly represent PS | l(S)VE || VD FS | l(S)VD ||
depend assignment VD l(S) l(S) respectively.

455

fiPralet, Verfaillie, & Schiex

Definition 30. semantic answer Sem-Ans(Q) query Q = (N , Sov) function
set Vf r free variables Q defined by10

FVf r (A) = f
Sem-Ans(Q)(A) =
Qs(N , Sov, A) otherwise,
Qs inductively defined by:
(1)

Qs(N , , A) = UV (A)

(2)

Qs(N , (op, S) . Sov, A) =


min
Qs (N , Sov, A.A0 )

0

dom(S)



FS|l(S) (A.A0 ) =




Qs (N , Sov, A.A0 )
max











A0 dom(S)
FS|l(S) (A.A0 ) =

u

A0 dom(S)
PS|l(S) (A.A0 ) 6= 0p

(S VD ) (op = min),
(S VD ) (op = max),


PS|l(S) (A.A0 ) pu Qs (N , Sov, A.A0 )

(S ).

words, step involving decision variables (first two cases) corresponds
optimization step among feasible choices, step involving environment variables
(third case) corresponds lottery (von Neumann & Morgenstern, 1944)
rewards Qs (N , Sov, A.A0 ), plausibility attributed reward
PS | l(S) (A.A0 ) (the formula looking like ui (pi pu ui ) expected utility lottery).
set decision variables eliminated, decision rule recorded, using
argmax (resp. argmin) max (resp. min) performed.
Example. maximum investment Peter expect, associated decision(s) make chooses menu without knowing attend? answer
question, use query bpJ , bpM , epJ , epM eliminated
mc w represent fact values known menu chosen.
query is:
(N , (max, {mc, w}).(u , {bpJ , bpM , epJ , epM })).
answer $6K, (mc, meat).(w, red) decision. Peter knows comes,
query becomes
(N , (u , {bpJ , bpM }).(max, {mc, w}).(u , {epJ , epM })).
optimal values mc w depend bpJ bpM . answer $26K
$20K gain observability present. decision rule {mc, w}
(mc, meat).(w, red) John present Mary not, (mc, f ish).(w, white) otherwise.
Consider query introduced beginning Section 6.1:
(N , (min, {mc}).(u , {bpJ , bpM }).(max, {w}).(u , {epJ , epM })).
answer : worst main course case, even Peter chooses wine, situation unacceptable. order compute expected utility menu choice,
use query mc w free variables:
10. unfeasible value, cf. Definition 6.

456

fiThe PFU Framework

(N , (u , {bpJ , bpM , epJ , epM })).
answer function {mc, w}. examples show queries capture various
situations terms partial observabilities, optimistic/pessimistic attitude, parameters
decision process.
6.3 Operational Answer Query
quantities PS | l(S) (A.A0 ) FS | l(S) (A.A0 ) involved definition semantic answer query directly available local functions expensive
compute. instance,
probabilities, PS | l(S) (A.A0 ) equals PS,l(S) (A.A0 )/Pl(S) (A).
P
0 00
Computing PS,l(S) (A.A0 ) =
A00 dom(V (Sl(S))) PVE ,VD (A.A .A ) typically requires time
exponential |V (S l(S))|. Moreover, quantities must computed node
decision tree. Fortunately, exists alternative definition answer
query, directly expressed using PFU instance, i.e. expressed local
plausibility, feasibility, utility functions.
Definition 31. operational answer Op-Ans(Q) query Q = (N , Sov) function
free variables Q: assignment free variables, (Op-Ans(Q))(A)
defined inductively follows:
(Op-Ans(Q))(A) = Qo (N , Sov, A)
Qo(N , (op, S) . Sov, A) = opA0 dom(S) Qo (N , Sov, A.A0 )
!



!
Qo(N , , A) =
Fi ? p Pi pu u Ui
(A).
Fi F

Pi P

(9)
(10)

Ui U

Equation 10, problem variables assigned, answer query
combination plausibility degree, feasibility degree, utility degree
corresponding complete assignment. Equation 9, variables assigned
(op, S) leftmost operator-variable(s) pair Sov, answer query obtained
eliminating using op elimination operator. Again, optimal decision rules
decision variables recorded needed, using argmin argmax. Equivalently,
considering sequence operator-variable(s) pairs sequence variable eliminations,
Op-Ans(Q) written:
!
!



Op-Ans(Q) = Sov
Fi ? p Pi pu u Ui
.
Fi F

Pi P

Ui U

shows Op-Ans(Q) actually corresponds generic form Equation 8.
6.4 Equivalence Theorem
Theorem 2 proves semantic definition Sem-Ans(Q) gives semantic foundations
computed operational definition Op-Ans(Q).
Theorem 2. plausibility structure conditionable, then, queries Q PFU
network, Sem-Ans(Q) = Op-Ans(Q) optimal policies decisions
Sem-Ans(Q) Op-Ans(Q).
457

fiPralet, Verfaillie, & Schiex

words, Theorem 2 shows possible perform computations
completely generic algebraic framework, providing result computations
decision-theoretic foundations. Due equivalence theorem, Op-Ans(Q) denoted
simply Ans(Q) following. Note operational definition applies even
non-conditionable plausibility structure. Giving decision-theoretic-based semantics
Op-Ans plausibility structure conditionable open issue.
6.5 Bounded Queries
may interesting relax problem computing exact answer query.
Assume leftmost operator-variable(s) pair sequence Sov (max, {x}),
x decision variable. decision maker point view, computing decision rules
providing expected utility greater given threshold may sufficient.
case E-MAJSAT problem, defined Given boolean formula set
variables V = VD , exist assignment VD formula
satisfied least half assignments ? Extending generic PFU framework
answer queries done Definitions 32 33, introduce bounded queries.
Definition 32. bounded query B-Q triple (N , Sov, ), (N , Sov) query
Eu ( threshold).
Definition 33. answer Ans(B-Q) bounded query B-Q = (N , Sov, ) boolean
function free variables unbounded query Q = (N , Sov). every assignment
free variables,

Ans(Q)(A) u
(Ans(B-Q))(A) =
f otherwise.
threshold may used prune search space resolution, computing answer bounded query easier computing answer unbounded
one.
6.6 Back Existing Frameworks
Let us consider frameworks Section 3. Solving CSP (Equation 1) totally
ordered soft CSP corresponds query Q = (N , (max, V )), N PFU network
corresponding CSP V set variables CSP. Computing probability
distribution variable Bayesian network (Equation 2) modeled N corresponds
Q = (N , (+, V {y}). examples mono-operator queries, involving one
type elimination operator.
Consider multi-operator queries. search optimal policy stochastic
CSP associated Equation 4 captured query Q = (N , (max, {d1 , d2 })
.(+, {s1 }).(max, {d3 , d4 }).(+, {s2 })). query influence diagrams Equation 5
query valuation networks Equation 6 captured way.
finite horizon MDP time-steps (Equation 7), query looks like Q =
(N , (max, {d1 }).(u , {s2 }).(max, {d2 }) . . . (u , {sT }).(max, {dT })), u = + probabilistic MDPs u = min pessimistic possibilistic MDPs. initial state s1

458

fiThe PFU Framework

free variable. quantified CSP quantified boolean formula, elimination operators
min max used represent .
formally, show:
Theorem 3. Queries bounded queries used express solve following
list problems:
1. SAT framework: SAT, MAJSAT, E-MAJSAT, quantified boolean formula, stochastic
SAT (SSAT) extended-SSAT (Littman et al., 2001).
2. CSP (or CN) framework:
Check consistency CSP (Mackworth, 1977); find solution CSP; count
number solutions CSP.
Find solution valued CSP (Bistarelli et al., 1999).
Solve quantified CSP (Bordeaux & Monfroy, 2002).
Find conditional decision unconditional decision mixed CSP
probabilistic mixed CSP (Fargier et al., 1996).
Find optimal policy stochastic CSP policy value greater
threshold; solve stochastic COP (Constraint Optimization Problem) (Walsh,
2002).
3. Integer Linear Programming (Schrijver, 1998) finite domain variables.
4. Search solution plan length k classical planning problem (STRIPS
planning, Fikes & Nilsson, 1971; Ghallab et al., 2004).
5. Answer classical queries Bayesian networks (Pearl, 1988), Markov random fields
(Chellappa & Jain, 1993), chain graphs (Frydenberg, 1990), plausibilities
expressed probabilities, possibilities, -rankings:
Compute plausibility distributions.
MAP (Maximum Posteriori hypothesis) MPE (Most Probable Explanation).
Compute plausibility evidence.
CPE task hybrid networks (Dechter & Larkin, 2001) (CPE means CNF Probability Evaluation, CNF formula Conjunctive Normal Form).
6. Solve influence diagram (Howard & Matheson, 1984).
7. finite horizon, solve probabilistic MDP, possibilistic MDP, MDP based
-rankings, completely partially observable (POMDP), factored (Puterman,
1994; Monahan, 1982; Sabbadin, 1999; Boutilier et al., 1999, 2000).

459

fiPralet, Verfaillie, & Schiex

6.7 Towards Complex Queries
Queries made complex relaxing assumptions:
definition queries, order u Eu assumed total. Extending
results partial order possible (Eu , u ) defines lattice (partially ordered
set closed least upper greatest lower bounds) pu distributes
least upper bound lub greatest lower bound glb (i.e. p pu lub(u1 , u2 ) =
lub(p pu u1 , p pu u2 ) p pu glb(u1 , u2 ) = glb(p pu u1 , p pu u2 )). allows
semiring CSPs (Bistarelli et al., 1999) captured framework. believe
extensions partial orders utilities allow algebraic MDPs (Perny
et al., 2005) captured.
try relax no-forgetting assumption, limited memory influence
diagrams (LIMIDs, Lauritzen & Nilsson, 2001), show relevant
decision processes involving multiple decision makers memory constraints
policy recording. cases, optimal decisions become nondeterministic
(decisions choose x = 0 probability p x = 1 probability 1p).
order decisions made environment variables observed
total completely determined query. One may wish compute
optimal policy decisions, also optimal order perform
decisions, without exactly knowing steps agents make decisions
steps observations made. Work influence diagrams unordered
decisions (Jensen & Vomlelova, 2002) good starting point try extend
work direction.
possible relax assumption variables finite domain,
nontrivial, since transforming u = + integrals straightforward,
performing min- max-eliminations continuous domains requires guarantee
existence supremum.
6.8 Summary
Section 6, last element PFU framework, class queries PFU networks,
introduced. decision-tree based definition answer query provided.
first main result section Theorem 2, gives theoretical foundations
another equivalent operational definition, reducing answer query sequence
eliminations combination scoped functions. latter best adapted future
algorithms, directly handles local functions defined PFU network.
second important result Theorem 3, shows many standard queries PFU
queries. Overall, PFU framework captured Definitions 14, 16, 17 algebraic
structures, Definition 26 PFU networks, Definitions 27 31 queries.

7. Gains Costs
better understanding Theorem 3 shows many existing frameworks instances
PFU framework. unification, similarities differences ex460

fiThe PFU Framework

isting formalisms analyzed. instance, comparing VCSPs optimistic
version finite horizon possibilistic MDPs operational definition answer
query, appears finite horizon optimistic possibilistic MDP (partially observable
not) fuzzy CSP: indeed represented query Q whose operational
answer looks like maxV (min ), V set variables set scoped
functions. Techniques available solving fuzzy CSPs used solve finite
horizon optimistic possibilistic MDPs.
complexity theory point view, studying time space complexity
answering queries form Equation 8 lead upper bounds complexity
several frameworks simultaneously. One may also try characterize properties
lead given theoretical complexity.
Increased expressive power expressive power PFU networks result
number features: (1) flexibility plausibility/utility model; (2) flexibility
possible networks; (3) flexibility queries terms situation modeling. enables
queries PFU networks cover generic finite horizon sequential decision problems
plausibilities, feasibilities, utilities, cooperative adversarial decision makers, partial observabilities, possible parameters decision process modeled free
variables.
none frameworks indicated Theorem 3 presents flexibility, every
subsumed formalism X indicated Theorem 3, possible find problem
represented PFUs directly X. specifically, compared influence
diagrams (Howard & Matheson, 1984; Jensen & Vomlelova, 2002; Smith et al., 1993; Nielsen
& Jensen, 2003; Jensen et al., 2004) valuation networks (VNs, Shenoy, 1992, 2000;
Demirer & Shenoy, 2001), PFUs deal probabilistic expected additive
utility allow us perform eliminations min model presence adversarial
agents. Thus, quantified boolean formulas cannot represented influence diagrams
VNs, covered PFU networks (see Theorem 3). Moreover, PFU networks use
DAG captures normalization conditions plausibilities feasibilities, whereas
VNs, information lost. Compared sequential influence diagrams (Jensen
et al., 2004) sequential VNs (Demirer & Shenoy, 2001), PFUs express so-called
asymmetric decision problems (problems variables may even need
considered decision process) adding dummy values variables.
Actually, simple problems expressed PFUs cannot apparently
directly expressed frameworks. simple instance feasibilities normalization
conditions + hard requirements captured subsumed frameworks.
example, using CSP model would result loss information provided
normalization conditions feasibilities. occurs influence diagrams like sequential decision processes based possibilistic expected utility, could
called possibilistic influence diagrams. Similarly stochastic CSPs without contingency
assumption.
cost greater flexibility increased expressive power PFU framework
cannot described simply straightforwardly as, example, constraint networks.
Generic algorithms Section 8 shows generic algorithms built answer
queries PFU networks. previously said, building generic algorithms facilitate
461

fiPralet, Verfaillie, & Schiex

cross-fertilization sense subsumed formalisms directly benefit
techniques developed another subsumed formalism. fits growing
effort generalize resolution methods used different AI problems. example, soft
constraint propagation drastically improves resolution valued CSPs; integrating
tool generic algorithm PFUs could improve resolution influence diagrams.
Using abstract operators may enable us identify algorithmically interesting properties,
infer necessary sufficient conditions particular algorithm usable.
However, one could argue techniques highly specific one formalism
one type problem, that, case, dedicated approaches certainly outperform
generic algorithm. solution characterize actual properties used
dedicated approach, order generalize much possible. Moreover, even
specialized schemes usually improve generic ones, exist cases general
tools efficient specialized algorithms, shown use SAT solvers
solving STRIPS planning problems (Sang, Beame, & Kautz, 2005).

8. Algorithms
ability design generic algorithms one motivations building PFU
framework, choices justified algorithmic considerations. present generic
algorithms answer arbitrary PFU queries.
8.1 Generic Tree Search Algorithm
operational definition answer query Q actually defines naive exponential
time algorithm compute Ans(Q) using tree-exploration procedure, variable
ordering given Sov, collects elementary plausibilities, feasibilities, utilities.
precisely, assignment free variables Q, tree explored.
node tree corresponds partial assignment variables. value leaf
provided combination scoped functions PFU network, applied
complete assignment defined path root leaf. Depending
operator used, value internal node computed performing min, max,
u operation values children. root node returns (Ans(Q))(A).
corresponding pseudo-code given Figure 2. query (N , Sov), first call
TreeSearchAnswerQ(N , Sov). returns function free variables.
assume every operator returns result constant time, time
complexity algorithm O(m n ln(d) dn ), stands maximum domain
size, n stands number variables PFU network, stands number
scoped functions.11
space complexity polynomial (it shown linear entry data
size). Hence, computing answer bounded query PSPACE. Moreover, given
satisfiability QBF PSPACE-complete problem expressed
bounded query (cf. Theorem 3), follows computing answer bounded query
PSPACE-hard. PSPACE PSPACE-hard, decision problem consists
11. factor n ln(d) corresponds upper bound time needed get (A) scoped function
represented table (of size dn ).

462

fiThe PFU Framework

TreeSearchAnswerQ((V, G, P, F, U ), Sov)
begin
foreach dom(Vf r ) (A) AnswerQ((V, G, P, F, U ), Sov, A)
return
end
AnswerQ((V, G, P, F, U ), Sov, A)
begin
Sov = return ((Fi F Fi ) ? (p Pi P Pi ) pu (uUi U Ui ))(A)
else
(op, S).Sov 0 Sov
choose x
= {x} Sov Sov 0 else Sov (op, {x}).Sov 0
dom dom(x)
res
dom 6=
choose dom
dom dom {a}
res op (res, AnswerQ((V, G, P, F, U ), Sov, A.(x, a)))
return res
end

Figure 2:
generic tree search algorithm answering query Q
((V, G, P, F, U ), Sov)

=

answering bounded query PSPACE-complete. result surprising, gives
idea level expressiveness reached PFU framework.
work needed identify subclasses queries lower complexity, although many
already known.
8.2 Generic Variable Elimination Algorithm
Quite naturally, generic variable elimination algorithm (Bertele & Brioschi, 1972; Shenoy,
1991; Dechter, 1999; Kolhas, 2003) defined answer queries PFU network.
8.2.1 First Naive Scheme
first naive variable elimination algorithm given Figure 3. eliminates variables
right left sequence Sov query, whereas tree search
procedure, variables assigned left right. right-to-left processing
entails algorithm naturally returns function free variables query.
first call VarElimAnswerQ((V, G, P, F, U ), Sov).
version presented Figure 3 actually naive variable elimination scheme
time space complexities O(m n ln(d) dn ) O(m dn ) respectively: begins
combining scoped functions eliminating variables, whereas interest
variable elimination algorithm primarily use factorization local functions.

463

fiPralet, Verfaillie, & Schiex

VarElimAnswerQ((V, G, P, F, U ), Sov)
begin
0 ((Fi F Fi ) ? (p Pi P Pi ) pu (uUi U Ui ))
Sov 6=
Sov 0 .(op, S) Sov
choose x
= {x} Sov Sov 0 else Sov Sov 0 .(op, {x})
0 opx 0
return 0
end

Figure 3: first generic variable elimination algorithm answering query Q =
((V, G, P, F, U ), Sov)
8.2.2 Improving Basic Scheme
algorithm Figure 3 works unique global function defined combination
plausibility, feasibility, utility functions (first line), whereas factorization
available. improve scheme, properties algebraic structure used.
sequel, denote +x (resp. x ) scoped function (resp.
have) x scope. Moreover, extend every combination operator E {}
setting e = e = (combining anything something unfeasible unfeasible
too).12
First, order use factorization plausibilities feasibilities, use
properties below, come right monotonicity pu , distributivity pu
u , definition
truncation operator ?:
x
min
(P
pu U ) = P x pu (minx U )
x




maxx (P x pu U ) = P x pu (maxx U )



ux (P x pu U ) = P x pu (ux U )
minx (F x ? U ) = F x ? (minx U )





maxx (F x ? U ) = F x ? (maxx U )


ux (F x ? U ) = F x ? (ux U ) .
express variable x eliminated, necessary consider plausibility
functions feasibility functions x scope.
However, necessary add axioms expected utility structure, since
general case, expression ux (P +x pu (U x u U +x )) cannot decomposed. give two axioms, Ax1 Ax2, sufficient additional condition
exploit factorization utility functions.
(Ax1) (Ep , p ) = (Eu , u ), p = u , p = u = pu
(Ax2) u = u Eu (but Eu {}).
12. operator op used combination operator scoped functions elimination operator variables. case, extension op used combination operator creates
operator op0 op0 (e, ) = , whereas extension op used elimination operator
creates operator op00 op00 (e, ) = e. op0 op00 coincide E differ E {}.

464

fiThe PFU Framework

Among cases Table 1, rows 2, 3, 5, 6 satisfy Ax1, whereas rows 1, 4, 7, 8 satisfy
Ax2. Ax1 andAx2 enable us write:
minx (F +x ? (U x u U +x )) = U x u (minx F +x ? U +x )
maxx (F +x ? (U x u U +x )) = U x u (maxx F +x ? U +x ) .

x

U u (ux P +x pu U +x ) Ax1
+x
x
+x
u P pu (U u U ) =
((p x P +x ) pu U x ) u (ux P +x pu U +x ) Ax2.
x
Hence, eliminating variable x, necessary consider utility functions
x scope.
present algorithm Ax1 satisfied. Ax2 holds, working plausibility/utility pairs (p, u) allows Ax1 recovered: used, example, solve
influence diagrams (Ndilikilikesha, 1994). Ax1 satisfied, actually one
set E = Ep = Eu , one order =p =u , one combination operator = p = u = pu ,
one elimination operator = p = u . Rather express feasibilities {t, f },
express {1E , } mapping onto 1E f onto : preserves value
answer query, since f ? u = u ? u = 1E u.
improved variable elimination algorithm shown Figure 4. answer query
Q = ((V, G, P, F, U ), Sov), first call Ax1-VarElimAnswerQ(P F U, Sov).
returns set scoped functions whose -combination equals Ans(Q). time,
factorization available PFU network exploited, since eliminating variable x,
scoped functions involving x considered.
Ax1-VarElimAnswerQ(, Sov)
begin
Sov = return
else
Sov 0 .(op, S) Sov
choose x
= {x} Sov Sov 0 else Sov Sov 0 .(op, {x})
+x { | x sc()}
0 opx +x
( +x ) {0 }
return Ax1-VarElimAnswerQ(, Sov)
end

Figure 4: Variable elimination algorithm Ax1 holds (: set scoped functions)
Ax1 holds, algorithm actually standard variable elimination algorithm
commutative semiring. classical variable elimination algorithms, time complexity
algorithm O(m n ln(d) dw+1 ), w tree-width (Bodlaender, 1997;
Dechter & Fattah, 2001) network scoped functions, constrained elimination
order imposed Sov. Yet, space complexity also exponential tree-width.
8.3 Approaches
Starting generic tree-search algorithm Section 8.1, bound computations local
consistencies (Mackworth, 1977; Cooper & Schiex, 2004; Larrosa & Schiex., 2003)

465

fiPralet, Verfaillie, & Schiex

integrated order prune search space. Local consistencies improve quality
bounds thanks use smaller local functions. Techniques coming quantified
boolean formulas game algorithms (such -algorithm) considered
efficiently manage bounds min max operators alternate. Caching strategies
exploiting problem structure (Darwiche, 2001; Jegou & Terrioux, 2003) also obvious
candidates improve basic tree search scheme. Additional axioms Ax1 Ax2
useful direction. Heuristics choice variable assign pair
(op, S) encountered, well heuristics value choices, may also speed
search.
another direction, approximate algorithms using sampling local search could also
considered: sampling eliminations + (+, u ) performed, local
search eliminations min max performed.

9. Conclusion
last decades, AI witnessed design study numerous formalisms
reasoning decision problems. article, built generic framework
model sequential decision making plausibilities, feasibilities, utilities.
framework covers many existing approaches, including hard, valued, quantified, mixed,
stochastic CSPs, Bayesian networks, finite horizon probabilistic possibilistic MDPs,
influence diagrams. result algebraic framework built upon decision-theoretic
foundations: PFU framework. two facets PFU framework explicit
Theorem 2, states operational definition answer query equivalent
decision tree-based semantics. result design accounts
expressiveness computational aspects.
Compared related works (Shenoy, 1991; Dechter, 1999; Kolhas, 2003), PFU framework framework directly deals different types variables (decision
environment variables), different types local functions (plausibilities, feasibilities,
utilities), different types combination elimination operators.
algorithmic point view, generic algorithms based tree search variable
elimination described. prove PFU framework abstraction. next step explore ways improving algorithms, generalize
techniques used formalisms subsumed PFU framework. Along line,
generic approach query optimization lead definition original architectures
answering queries, called multi-operator cluster trees multi-operator cluster DAGs.
applied QBFs structures compatible Ax1 (Pralet, Schiex, &
Verfaillie, 2006a), well influence diagrams structures satisfying Ax2 (Pralet,
Schiex, & Verfaillie, 2006b).

Acknowledgments
would like thank Jean-Loup Farges, Jerome Lang, Regis Sabbadin, three
anonymous reviewers useful comments previous versions article. work

466

fiThe PFU Framework

described article initiated first author LAAS-CNRS INRA
Toulouse. partially conducted within EU Integrated Project COGNIRON (The
Cognitive Companion) funded European Commission Division FP6-IST Future
Emerging Technologies Contract FP6-002020.

Appendix A. Notations
See Table 2.
Symbol

p
u

p
u
pu
p
u
?



VD
dom(x)
dom(S)
G
paG (x)
ndG (x)
CE (G)
CD (G)
Pi
Fi
Ui
F act(c)
sc()
PS
PS1 | S2
FS
FS1 | S2

eaning
Elimination operator
Elimination operator plausibilities
Elimination operator utilities
Combination operator
Combination operator plausibilities
Combination operator utilities
Combination operator plausibilities utilities
Partial order plausibilities
Partial order utilities
Truncation operator
Unfeasible value

Environment variables
Decision variables
Domain
values variable x
Q
dom(x)
xS
Directed Acyclic Graph (DAG)
Parents x DAG G
Non-descendant x DAG G
Set environment components G
Set decision components G
Plausibility function
Feasibility function
Utility function
Pi Fi factors associated component c
Scope local function
Plausibility distribution
Conditional plausibility distribution S1 given S2
Feasibility distribution
Conditional feasibility distribution S1 given S2

Sov
Sequence operator-variable(s) pairs
Sem-Ans(Q) Semantic answer query Q (decision trees)
Op-Ans(Q) Operational answer query Q
Ans(Q)
Answer query Q

Table 2: Notation.
467

fiPralet, Verfaillie, & Schiex

Appendix B. Proofs
Proposition 1 plausibility distribution PS extended give plausibility distribution PS 0 every 0 S, defined PS 0 = p SS 0 PS .
Proof. Given p associative commutative, p 0 PS 0 = p 0 (p SS 0 PS ) = p PS = 1p .
Thus, PS 0 : dom(S 0 ) Ep plausibility distribution 0 .

Proposition 2 structures presented Table 1 expected utility structures.
Proof. sufficient verify required axioms successively.

Proposition 3 (Ep , p , p ) conditionable plausibility structure, plausibility distributions conditionable: suffices define PS1 | S2 PS1 | S2 (A) = max{p
Ep | PS1 ,S2 (A) = p p PS2 (A)} dom(S1 S2 ) satisfying PS2 (A) 6= 0p .
Proof. Let PS plausibility distribution S. S1 , S2 disjoint subsets
dom(S1 S2 ) satisfying PS2 (A) 6= 0p , let us define PS1 | S2 (A) = max{p Ep | PS1 ,S2 (A) =
p p PS2 (A)}. must show PS1 | S2 functions satisfy axioms a, b, c, d, e Definition 18.
(a) definition PS1 | S2 distributivity p p , write
PS2 = p S1 PS1 ,S2 = p S1 (PS1 | S2 p PS2 ) = (p S1 PS1 | S2 ) p PS2 .
PS2 p PS2 , infer p S1 PS1 | S2 p 1p . Let A2 assignment S2 satisfying
PS2 (A2 ) 6= 0p . Assume hypothesis (H): p S1 PS1 | S2 (A2 ) p 1p holds.
Then, A1 dom(S1 ), PS1 ,S2 (A1 .A2 ) p PS2 (A2 ), since PS1 ,S2 (A1 .A2 ) = PS2 (A2 ),
PS1 | S2 (A1 .A2 ) = 1p , implies p S1 PS1 | S2 (A2 ) p 1p monotonicity
p . Moreover, (H) implies exists unique p Ep satisfying (p S1 PS1 | S2 (A2 )) p
p = 1p . Combining equation PS2 (A2 ) gives PS2 (A2 ) p PS2 (A2 ) p p = PS2 (A2 ), i.e.
PS2 (A2 ) p (1p p p) = PS2 (A2 ). implies 1p p p p 1p . Given 1p p p p 1p
(by monotonicity p ), obtain 1p p p = 1p . analyze two cases.
p p 1p , exists unique p0 satisfying p0 p p = 1p . (p S1 PS1 | S2 (A2 )) p p
= 1p 1p p p = 1p , entails p S1 PS1 | S2 (A2 ) = 1p , contradicts (H).
p = 1p , 1p p 1p = 1p . entails p idempotent. Let dom0 subset
dom(S1 ) p A1 dom0 PS1 ,S2 (A1 .A2 ) = PS2 (A2 ). Let A01 dom0 .
write:
(
PS1 ,S2 (A01 .A2 ) p (p A1 dom0 {A0 } PS1 ,S2 (A1 .A2 )) = PS2 (A2 )
1
.
PS1 ,S2 (A01 .A2 ) p (p A1 dom0 PS1 ,S2 (A1 .A2 )) = PS2 (A2 ) (as p idempotent)
PS1 ,S2 (A01 .A2 ) p PS2 (A2 ), exists unique p00 Ep PS1 ,S2 (A01 .A2 )p
p00 = PS2 (A2 ). Therefore, p A1 dom0 PS1 ,S2 (A1 .A2 ) = p A1 dom0 {A0 } PS1 ,S2 (A1 .A2 ),
1
gives p A1 dom0 {A0 } PS1 ,S2 (A1 .A2 ) = PS2 (A2 ).
1

assumption p A1 dom0 PS1 ,S2 (A1 .A2 ) = PS2 (A2 ) holds dom0 = dom(S1 ). Recursively applying previous mechanism removing one assignment dom0
iteration leads p A1 dom0 PS1 ,S2 (A1 .A2 ) = PS2 (A2 ) |dom0 | = 1, i.e. leads
PS1 ,S2 (A001 .A2 ) = PS2 (A2 ) dom0 = {A001 }. result, obtain contradiction.
cases, contradiction (H) obtained, p S1 PS1 | S2 (A2 ) = 1p .
(b) PS1 = PS1 | p P = PS1 | p (p PS ) = PS1 | p 1p = PS1 | .
468

fiThe PFU Framework

(d) Let dom(S1 S2 S3 ) satisfying PS2 ,S3 (A) 6= 0p . Then, PS1 ,S2 | S3 (A) = PS1 | S2 ,S3 (A) p
PS2 | S3 (A) holds, because:
PS1 ,S2 ,S3 (A) p PS3 (A), then, exists unique p Ep PS1 ,S2 ,S3 (A) =
pp PS3 (A). PS1 ,S2 ,S3 (A) = PS1 ,S2 | S3 (A)p PS3 (A) (by definition PS1 ,S2 | S3 )
PS1 ,S2 ,S3 (A) = PS1 | S2 ,S3 (A)p PS2 | S3 (A)p PS3 (A) (by definition PS1 | S2 ,S3
PS2 | S3 ), implies PS1 ,S2 | S3 (A) = PS1 | S2 ,S3 (A) p PS2 | S3 (A).
Otherwise, PS1 ,S2 ,S3 (A) = PS3 (A). implies 1p p PS1 ,S2 | S3 (A) and,
PS1 ,S2 | S3 (A) p 1p , PS1 ,S2 | S3 (A) = 1p . Similarly, entails PS2 | S3 (A) = 1p
PS1 | S2 ,S3 (A) = 1p (the monotonicity p implies PS1 ,S2 ,S3 (A) = PS2 ,S3 (A) =
PS3 (A)). 1p = 1p p 1p , get PS1 ,S2 | S3 (A) = PS1 | S2 ,S3 (A) p PS2 | S3 (A).
(c)

p S1 PS1 ,S2 | S3

= p S1 (PS1 | S2 ,S3 p PS2 | S3 ) (using (d))
= (p S1 PS1 | S2 ,S3 ) p PS2 | S3 (because p distributes p )
= PS2 | S3 (using (a))

(e) Assume PS1 ,S2 ,S3 = PS1 | S3 p PS2 | S3 p PS3 . Let dom(S1 S2 S3 )
PS3 (A) 6= 0p . Then, PS1 ,S2 | S3 (A) = PS1 | S3 (A) p PS2 | S3 (A) holds, because:
PS1 ,S2 ,S3 (A) p PS3 (A), exists unique p Ep PS1 ,S2 ,S3 (A) =
p p PS3 (A), therefore PS1 ,S2 | S3 (A) = PS1 | S3 (A) p PS2 | S3 (A).
Otherwise, write PS1 | S3 (A) = PS2 | S3 (A) = PS1 ,S2 | S3 (A) = 1p using reasoning similar (d), therefore PS1 ,S2 | S3 (A) = PS1 | S3 (A) p PS2 | S3 (A).

Proposition 4 I(., . | .) satisfies semigraphoid axioms:
1. symmetry: I(S1 , S2 | S3 ) I(S2 , S1 | S3 ),
2. decomposition: I(S1 , S2 S3 | S4 ) I(S1 , S2 | S4 ),
3. weak union: I(S1 , S2 S3 | S4 ) I(S1 , S2 | S3 S4 ),
4. contraction: (I(S1 , S2 | S4 ) I(S1 , S3 | S2 S4 )) I(S1 , S2 S3 | S4 ).
Proof.
1. Symmetry axiom: directly satisfied commutativity p .
2. Decomposition axiom: assume I(S1 , S2 S3 | S4 ) holds.
PS1 ,S2 | S4 = p S3 PS1 ,S2 ,S3 | S4
= p S3 (PS1 | S4 p PS2 ,S3 | S4 ) (since I(S1 , S2 S3 | S4 ))
= PS1 | S4 p (p S3 PS2 ,S3 | S4 ) (by distributivity p p )
= PS1 | S4 p PS2 | S4 .
Thus, I(S1 , S2 | S4 ) holds.
3. Weak union axiom: assume I(S1 , S2 S3 | S4 ) holds. decomposition axiom entails
I(S1 , S3 | S4 ) also satisfied.
PS1 ,S2 ,S3 ,S4 = PS1 ,S2 ,S3 | S4 p PS4 (chain rule)
= PS1 | S4 p PS2 ,S3 | S4 p PS4 (since I(S1 , S2 S3 | S4 ))
= PS1 | S4 p PS3 | S4 p PS4 p PS2 | S3 ,S4 (chain rule)
= PS1 ,S3 | S4 p PS4 p PS2 | S3 ,S4 (since I(S1 , S3 | S4 ))
= PS1 | S3 ,S4 p PS2 | S3 ,S4 p PS3 ,S4 (chain rule).
axiom (e) Definition 18, infer PS1 ,S2 | S3 ,S4 = PS1 | S3 ,S4 p PS2 | S3 ,S4 , i.e.
I(S1 , S2 | S3 S4 ) holds.
469

fiPralet, Verfaillie, & Schiex

4. Contraction axiom: assume I(S1 , S2 | S4 ) I(S1 , S3 | S2 S4 ) hold.
PS1 ,S2 ,S3 | S4 = PS1 ,S3 | S2 ,S4 p PS2 | S4 (chain rule)
= PS1 | S2 ,S4 p PS3 | S2 ,S4 p PS2 | S4 (since I(S1 , S3 | S2 S4 ))
= PS1 ,S2 | S4 p PS3 | S2 ,S4 (chain rule)
= PS1 | S4 p PS2 | S4 p PS3 | S2 ,S4 (since I(S1 , S2 | S4 ))
= PS1 | S4 p PS2 ,S3 | S4 (chain rule).
Thus, I(S1 , S2 S3 | S4 ) holds.

Theorem 1 (Conditional independence factorization) Let (Ep , p , p ) conditionable plausibility structure let G DAG components S.
(a) G compatible plausibility distribution PS S, PS = p cC(G) Pc | paG (c) .
(b) If, c C(G), function c,paG (c) c,paG (c) (A) plausibility
distribution c assignments paG (c), = p cC(G) c,paG (c)
plausibility distribution G compatible.
Proof.
(a) First, |C(G)| = 1, G contains unique component c1 . Then, p cC(G) Pc | paG (c) = Pc1 | =
Pc1 : proposition holds |C(G)| = 1.
Assume proposition holds DAGs n components. Let G DAG
components compatible plausibility distribution PS |C(G)| = n + 1.
Let c0 component labeling leaf G. G compatible PS , write
I(c0 , ndG (c0 ) paG (c0 ) | paG (c0 )). c0 leaf, ndG (c0 ) = c0 , consequently
I(c0 , (S c0 ) paG (c0 ) | paG (c0 )). means PSpaG (c0 ) | paG (c0 ) = Pc0 | paG (c0 ) p
P(Sc0 )paG (c0 ) | paG (c0 ) . Combining side equation PpaG (c0 ) gives
PS = Pc0 | paG (c0 ) p PSc0 .
0
Let G DAG obtained G deleting node labeled c0 . every
component c C(G0 ), paG0 (c) = paG (c) (since deleted component c0 leaf). Moreover
ndG0 (c) equals either ndG (c) ndG (c)c0 (again, since deleted component c0 leaf).
first case (ndG0 (c) = ndG (c)), property I(c, ndG (c) paG (c) | paG (c)) directly implies
I(c, ndG0 (c)paG0 (c) | paG0 (c)). second case (ndG0 (c) = ndG (c)c0 ), decomposition
axiom allows us write I(c, ndG0 (c) paG0 (c) | paG0 (c)) I(c, ndG (c) paG (c) | paG (c)).
Consequently, G0 DAG compatible PSc0 . |C(G0 )| = n, induction hypothesis
gives PSc0 = p cC(G0 ) Pc | paG (c) , implies PS = p cC(G) Pc | paG (c) , desired.
(b) Assume every component c, c,paG (c) (A) plausibility distribution c
assignments paG (c). |C(G)| = 1, C(G) = {c1 }. Then, = c1 plausibility
distribution c1 . Moreover, | = 1p , write c1 | = c1 | p | , i.e.
I(c1 , | ). Therefore, G compatible c1 : proposition holds |C(G)| = 1.
Assume proposition holds DAGs n components. Consider DAG G
n + 1 components. first show plausibility distribution S, i.e.
p (p cC(G) c,paG (c) ) = 1p . Let c0 leaf component G. c0 leaf, unique
scoped function whose scope contains variable c0 c0 ,paG (c0 ) . distributivity
p p , implies
p c0 (p cC(G) c,paG (c) ) = (p c0 c0 ,paG (c0 ) ) p (p cC(G){c0 } c,paG (c) ).
Given c0 ,paG (c0 ) (A) plausibility distribution c0 assignments paG (c0 ),
470

fiThe PFU Framework

p c0 c0 ,paG (c0 ) = 1p . Consequently,
p c0 (p cC(G) c,paG (c) ) = p cC(G){c0 } c,paG (c) .
Applying induction hypothesis DAG n components obtained G deleting c0 , infer p Sc0 (p cC(G){c0 } c,paG (c) ) = 1p . allows us write
p Sc0 (p c0 (p cC(G) c,paG (c) )) = 1p , i.e. p = 1p : plausibility distribution
S. remains prove G DAG components compatible . Let c C(G).
must show I(c, ndG (c) paG (c) | paG (c)) holds. two cases:
1. c = c0 , must prove
c0 ,ndG (c0 )paG (c0 ) | paG (c0 ) = c0 | paG (c0 ) p ndG (c0 )paG (c0 ) | paG (c0 ) .
First, note
c0 ,paG (c0 ) = p S(c0 paG (c0 )) (p cC(G) c,paG (c) )
= (p S(c0 paG (c0 )) (p cC(G){c0 } c,paG (c) )) p c0 ,paG (c0 )
(because p distributes p sc(c0 ,paG (c0 ) ) c0 paG (c0 )
= (p SpaG (c0 ) (p cC(G) c,paG (c) )) p c0 ,paG (c0 )
(because p distributes p c0 c0 ,paG (c0 ) = 1p )
= paG (c0 ) p c0 ,paG (c0 ) .
this, possible write:
ndG (c0 )paG (c0 ) | paG (c0 ) p c0 | paG (c0 ) p paG (c0 )
= ndG (c0 )paG (c0 ) | paG (c0 ) p c0 ,paG (c0 )
= ndG (c0 )paG (c0 ) | paG (c0 ) p paG (c0 ) p c0 ,paG (c0 )
= ndG (c0 ) p c0 ,paG (c0 )
= S{c0 } p c0 ,paG (c0 ) (because c0 leaf G)
=

(p cC(G){c0 } c,paG (c) ) p c0 ,paG (c0 )

= p cC(G) c,paG (c)
= .
Using axiom (e) Definition 18, entails ndG (c0 )paG (c0 ) | paG (c0 ) p c0 | paG (c0 ) =
SpaG (c0 ) | paG (c0 ) , i.e., = c0 ndG (c0 ), I(c0 , ndG (c0 ) paG (c0 ) | paG (c0 )).
2. Otherwise, c 6= c0 . Let G0 DAG obtained G deleting c0 . G0 contains
n components: induction hypothesis, I(c, ndG0 (c) paG0 (c) | paG0 (c)). c0
leaf G, c0
/ paG (c), implies paG0 (c) = paG (c). Thus,
I(c, ndG0 (c) paG (c) | paG (c)).
(i) ndG0 (c) = ndG (c), immediate I(c, ndG (c) paG (c) | paG (c)).
(ii) Otherwise, ndG0 (c) 6= ndG (c). c0 leaf G, equivalent say
ndG (c) = ndG0 (c) c0 . means c ancestor c0 , fortiori c
/ paG (c0 ). following, four semigraphoid axioms used
prove required result. decomposition axiom, I(c0 , ndG (c0 )
paG (c0 ) | paG (c0 )), (c ndG0 (c)) ndG (c0 ) (because ndG (c0 ) =
c0 ), follows I(c0 , (c ndG0 (c)) paG (c0 ) | paG (c0 )), or, words,
c paG (c0 ) = , I(c0 , c (ndG0 (c) paG (c0 )) | paG (c0 )). Using weak
union axiom leads I(c0 , c | (ndG0 (c) paG (c0 )) paG (c0 )) and, using symmetry axiom, I(c, c0 | (ndG0 (c) paG (c0 )) paG (c0 )). shown previously,
I(c, ndG0 (c)paG (c) | paG (c)). Together I(c, c0 | (ndG0 (c)paG (c0 ))paG (c0 )),
contraction axiom implies I(c, (ndG0 (c) paG (c)) c0 | paG (c)). c0
/
paG (c) ndG (c) = ndG0 (c) c0 , means I(c, ndG (c) paG (c)) | paG (c)).
471

fiPralet, Verfaillie, & Schiex

proved G compatible . Consequently, proposition holds
n + 1 components G, ends proof induction.

Proposition 5 Let (Ep , p , p ) conditionable plausibility structure. Then,
n N , exists unique p0 p i[1,n] p0 = 1p .
Proof. Let n N . p i[1,n] 1p = 1p , p0 = 1p satisfies required property. Moreover,
case, distributivity p p implies p Ep , p i[1,n] p = p. Therefore,
p i[1,n] p = 1p , p = 1p , shows p0 unique.
Otherwise, p i[1,n] 1p 6= 1p . case, 1p p p i[1,n] 1p monotonicity p ,
write 1p p p i[1,n] 1p . second item Definition 19 implies exists unique
p0 Ep 1p = p0 p (p i[1,n] 1p ), i.e. 1p = p i[1,n] p0 .

Proposition 6
Let PVE ,VD completion controlled plausibility distribution
PVE || VD . Then, PVE ,VD plausibility distribution VD PVE | VD = PVE || VD .
Proof. PVE ,VD = PVE || VD p p0 , p0 element Ep p i[1,|dom(VD )|] p0 = 1p .
p VD PVE ,VD = p VD (PVE || VD p p0 ) = p VD ((p PVE || VD ) p p0 ) = p VD p0 =
p i[1,|dom(VD )|] p0 = 1p . proves PVE ,VD plausibility distribution VD .
PVE ,VD = PVE || VD p p0 PVE ,VD = PVE | VD p PVD , write PVE || VD p p0 =
PVE | VD p PVD . Moreover, PVD = p PVE ,VD = p (PVE || VD p p0 ) = p0 . Thus, PVE || VD p
p0 = PVE | VD p p0 . Summing equation |dom(VD )| times p gives PVE || VD = PVE | VD .

Proposition 7 Let G typed DAG components VD . Let Gp partial
graph G induced arcs G incident environment components. Let Gf
partial graph G induced arcs G incident decision components. Gp
compatible completion PVE || VD (cf. Definition 22) Gf compatible
completion FVD || ,
PVE | VD =

p Pc | paG (c)
cCE (G)

FVD | =


cCD (G)

Fc | paG (c) .

Proof. result proved PVE | VD (the proof FVD | similar). completion
PVE || VD looks like PVE ,VD = PVE || VD p p0 . Gp compatible completion, Theorem 1a
entails PVE ,VD = p cC(Gp ) Pc | paGp (c) . decision components roots Gp , infer,
successively eliminating environment components, PVD = p PVE ,VD = p cCD (Gp ) Pc .

hand, PVD = p PVE || VD p p0 = p0 . proves p cCD (Gp ) Pc =
p0 . Therefore, PVE ,VD = PVE | VD p p0 = (p cCE (Gp ) Pc | paGp (c) ) p p0 . Summing equation
|dom(VD )| times p gives PVE | VD = p cCE (Gp ) Pc | paGp (c) . CE (Gp ) = CE (G) paGp (c) =
paG (c) every c CE (G), entails PVE | VD = p cCE (G) Pc | paG (c) .

Proposition 8 Assume plausibility structure used conditionable. Let Q =
(N , Sov) query Sov = (op1 , S1 ) (op2 , S2 ) (opk , Sk ). Let Vf r denote set
free variables Q.
472

fiThe PFU Framework

(1) Si PSi | l(Si ) (A) well-defined, exists least one A0 dom(Si )
satisfying PSi | l(Si ) (A.A0 ) 6= 0p .
(2) Si VD FSi | l(Si ) (A) well-defined, exists least one A0 dom(Si )
satisfying FSi | l(Si ) (A.A0 ) = t.
(3) 6= Si leftmost set environment variables appearing Sov, then,
dom(l(Si )), PSi | l(Si ) (A) well-defined.
(4) i, j [1, k], < j, Si , Sj , r(Si )l(Sj ) VD (Sj first set environment variables appearing right Si Sov), (A, A0 ) dom(l(Si )) dom(Si ),
PSi | l(Si ) (A) well-defined, PSi | l(Si ) (A.A0 ) 6= 0p , then, A00 extending A.A0
l(Sj ), PSj | l(Sj ) (A00 ) well-defined.
(5) i, j [1, k], < j, Si VD , Sj VD , r(Si ) l(Sj ) (Sj first set
decision variables appearing right Si Sov), (A, A0 ) dom(l(Si ))dom(Si ),
FSi | l(Si ) (A) well-defined, FSi | l(Si ) (A.A0 ) = t, then, A00 extending A.A0
l(Sj ), FSj | l(Sj ) (A00 ) well-defined.
(6) [1, k] Si , PSi | l(Si ) = PSi | l(Si )VE ||VD .
(7) [1, k] Si VD , FSi | l(Si ) = FSi | l(Si )VD ||VE .
Proof. denote p0 element Ep completion PVE || VD equals PVE || VD p0 .
Note p0 6= 0p , since must satisfy p i[1,|dom(VD )|] p0 = 1p .
Lemma 1. Let (Ep , p , p ) conditionable plausibility structure. Then, (p1 p p2 = 0p )
((p1 = 0p ) (p2 = 0p )).
Proof. First, p1 = 0p p2 = 0p , p1 p p2 = 0p . Conversely, assume p1 p p2 = 0p . Then,
p1 p 0p , conditionability plausibility structure together p1 p 0p = 0p entails
p2 = 0p . Similarly, p2 p 0p , p1 = 0p . Therefore (p1 p p2 = 0p ) ((p1 = 0p )(p2 = 0p )).
Lemma 2. Assume plausibility structure conditionable. Let S1 , S2 disjoint subsets
. Then, PS1 | S2 || VD = PS1 | S2 ,VD .
Proof. Note PS1 ,S2 | VD = PS1 | S2 ,VD p PS2 | VD . Moreover, also write PS1 ,S2 | VD =
PS1 ,S2 || VD = PS1 | S2 || VD p PS2 || VD = PS1 | S2 || VD p PS2 | VD . Let assignment V .
PS1 ,S2 | VD (A) p PS2 | VD (A), conditionability plausibility structure entails
PS1 | S2 ,VD (A) = PS1 | S2 || VD (A). Otherwise, PS1 ,S2 | VD (A) = PS2 | VD (A), also entails
PS1 ,S2 || VD (A) = PS2 || VD (A). case, PS1 | S2 ,VD (A) = PS1 | S2 || VD (A) = 1p . Therefore,
PS1 | S2 ,VD = PS1 | S2 || VD .
(1) Assume Si PSi | l(Si ) (A) well-defined. Then, PSi | l(Si ) (A) plausibility
distribution Si . Hence, p A0 dom(Si ) PSi | l(Si ) (A.A0 ) = 1p , implies exists
least one A0 dom(Si ) PSi | l(Si ) (A.A0 ) 6= 0p .
(2) Proof similar point (2).
(3) Assume 6= . Let Si leftmost set environment variables appearing Sov
let dom(l(Si )). Since l(Si ) = , write Pl(Si ) (A) = p V l(Si ) PVE ,VD (A) =
p VD l(Si ) (p PVE ,VD (A)) = p VD l(Si ) p0 6= 0p . Therefore, PSi | l(Si ) (A) well-defined.

473

fiPralet, Verfaillie, & Schiex

(6) Let lE (Si ) = l(Si ) lD (Si ) = l(Si ) VD . set variables S, denote dG (S)
set variables V descendant DAG G least one variable S.
First, PSi ,lE (Si ) || VD = p (Si lE (Si )) PVE || VD = p (Si lE (Si )) (p Pj P Pj ). definition query, variables dG (VD lD (Si )) belong Si lE (Si ) (the environment
variables descendants as-yet-unassigned decision variables assigned yet).
Thus, PSi ,lE (Si ) || VD = p (Si lE (Si )dG (VD lD (Si ))) (p Pj F act(c),c*VE dG (VD lD (Si )) Pj ).
last equality obtained successively eliminating environment components included
dG (VD lD (Si )) (using normalization conditions). scope plausibility function
Pj F act(c) included cpaG (c), equality entails PSi ,lE (Si ) || VD depend
assignment VD lD (Si ). Morever, PlE (Si ) || VD = Si PSi ,lE (Si ) || VD depend
assignment VD lD (Si ) too. PSi | lE (Si ) || VD = max{p Ep | PSi ,lE (Si ) || VD =
p p PlE (Si ) || VD }, also entails PSi | lE (Si ) || VD depend assignment
VD lD (Si ). denoted PSi | lE (Si ) || lD (Si ) .
show PSi | l(Si ) = PSi | lE (Si ) || lD (Si ) . First, note
PSi ,l(Si ) = p VD lD (Si ) PSi ,lE (Si ),VD = p VD lD (Si ) (PSi | lE (Si ),VD p PlE (Si ),VD )
= p VD lD (Si ) (PSi | lE (Si ) || VD p PlE (Si ),VD ) (using Lemma 2)
= PSi | lE (Si ) || VD p (p VD lD (Si ) PlE (Si ),VD )
(since PSi | lE (Si ) || VD depend assignment VD lD (Si ))
= PSi | lE (Si ) || VD p Pl(Si ) .
Let assignment V .
PSi ,l(Si ) (A) p Pl(Si ) (A), conditionability plausibility structure directly
entails PSi | l(Si ) (A) = PSi | lE (Si ) || VD (A).
Otherwise, PSi ,l(Si ) (A) = Pl(Si ) (A). case, PSi | l(Si ) (A) = 1p . Next, V
l(Si ) = (VD lD (Si )) (VE lE (Si )), observe Pl(Si ) = p V l(Si ) (PVE || VD p p0 ) =
p VD lD (Si ) (PlE (Si ) || VD p p0 ). Similarly, PSi ,l(Si ) = p V (Si l(Si )) (PVE || VD p
p0 ) = p VD lD (Si ) (PSi ,lE (Si ) || VD p p0 ). PSi ,l(Si ) (A) = Pl(Si ) (A), infer
p VD lD (Si ) (PlE (Si ) || VD (A) p p0 ) = p VD lD (Si ) (PSi ,lE (Si ) || VD (A) p p0 ). neither
PlE (Si ) || VD PSi ,lE (Si ) || VD depends assignment VD lD (Si ), entails
PlE (Si ) || VD (A) p (p VD lD (Si ) p0 ) = PSi ,lE (Si ) || VD (A) p (p VD lD (Si ) p0 ). Summing
equation |dom(lD (Si ))| times gives PSi ,lE (Si ) || VD (A) = PlE (Si ) || VD (A), thus
PSi | lE (Si ) || VD (A) = 1p = PSi | l(Si ) (A).
(7) Proof similar point (6).
(4) Let i, j [1, k] < j, Si , Sj , r(Si ) l(Sj ) VD (Sj first set
environment variables appearing right Si Sov). Let (A, A0 ) dom(l(Si ))dom(Si )
PSi | l(Si ) (A) well-defined (i.e. Pl(Si ) (A) 6= 0p ) PSi | l(Si ) (A.A0 ) 6= 0p . Let A00
extension A.A0 l(Sj ). must show PSj | l(Sj ) (A00 ) well-defined, i.e.
Pl(Sj ) (A00 ) 6= 0p . PSi | l(Si ) (A.A0 ) 6= 0p Pl(Si ) (A) 6= 0p , Lemma 1 implies
PSi ,l(Si ) (A.A0 ) 6= 0p . Similarly proof point (6), possible show Pl(Sj )
depend assignment l(Sj ) (Si l(Si )). Therefore, every A00 extending A.A0
l(Sj ), p l(Sj )(Si l(Si )) Pl(Sj ) (A00 ) 6= 0p , implies Pl(Sj ) (A00 ) 6= 0p .
(5) Proof similar point (4), except plausibilities replaced feasibilities decision
variables replaced environment variables.

474

fiThe PFU Framework

Theorem 2 plausibility structure conditionable, then, queries Q PFU
network, Sem-Ans(Q) = Op-Ans(Q) optimal policies decisions
Sem-Ans(Q) Op-Ans(Q).
Proof. Let Af r assignment set free variables Vf r FVf r (Af r ) = f .
semantic definition gives (Sem-Ans(Q))(Af r ) = . Given FVf r (Af r ) = V Vf r FVE ,VD (Af r ) =
V Vf r FVD || (Af r ) = V Vf r (Fi F Fi (Af r )) (since completion FVD || gives FVD || =
FVD ,VE ), infer every complete assignment A00 extending Af r , Fi F Fi (A00 ) = f
(Fi F Fi (A00 )) ? (p Pi P Pi (A00 )) pu (uUi U Ui (A00 )) = . min(, ) = max(, ) = u =
, entails (Op-Ans(Q))(Af r ) = too.
analyze case FVf r (Af r ) = t. use A00 denote complete assignment
must considered semantic definition. Using properties:
p pu min(u1 , u2 ) = min(p pu u1 , p pu u2 ) (right monotonicity pu ),
p pu max(u1 , u2 ) = max(p pu u1 , p pu u2 ) (right monotonicity pu ),
p pu (u1 u u2 ) = (p pu u1 ) u (p pu u2 ) (distributivity pu u ),
p1 pu (p2 pu u) = (p1 p p2 ) pu u,
move PSi | l(Si ) (A.A0 ) get, starting semantic definition,
(p i[1,k],Si PSi | l(Si ) )(A00 ) pu UV (A00 )
right elimination operators.
prove quantity equals PVE | VD (A00 ) pu UV (A00 ). Let rightmost set
quantified environment variables. chain rule enables us write PVE | VD = PS | lE (S),VD p
PlE (S) | VD , lE (S) = l(S) . Moreover, using Lemma 2 Proposition 8(6),
write PS | lE (S),VD = PS | lE (S) || VD = PS | l(S) . Therefore, PVE | VD = PS | l(S) p PlE (S) | VD . Recursively applying mechanism leads to: PVE | VD = p i[1,k],Si PSi | l(Si ) . Therefore, obtain
PVE | VD (A00 ) pu UV (A00 ) right elimination operators.
semantic definition query meaning simplified bit, thanks Lemma 1.
lemma implies conditions like PS | l(S) (A.A0 ) 6= 0p , used Pl(S) (A) 6= 0p ,
equivalent PS,l(S) (A.A0 ) 6= 0p , since PS,l(S) (A.A0 ) = PS | l(S) (A.A0 ) p Pl(S) (A). result,
operators uA0 dom(S),PS | l(S) (A.A0 )6=0p replaced uA0 dom(S),PS,l(S) (A.A0 )6=0p . Similarly,
eliminations minA0 dom(S),FS | l(S) (A.A0 )=t , conditions FS | l(S) (A.A0 ) = replaced
FS,l(S) (A.A0 ) = t. holds eliminations maxadom(xi ),FS | l(S) (A.A0 )=t .
start operational definition show reformulated above.
operational definition applies sequence variable eliminations global function (Fi F Fi ) ?
(p Pi P Pi ) pu (Ui U Ui ), also equals FVD | ? PVE | VD pu UV . Let leftmost
set quantified decision variables. Let assignment l(S). Assume quantified min. Let A0 dom(S) FS,l(S) (A.A0 ) = f . inferred
complete assignment A00 extending A.A0 , FVE ,VD (A00 ) = f , consequently FVD | (A00 ) =
f . implies FVD | (A00 ) ? PVE | VD (A00 ) pu UV (A00 ) = . Given min(, ) =
max(, ) = u = , obtain Qo(N , Sov, A.A0 ) = . min(d, ) = d, entails
minA0 dom(S) Qo(N , Sov, A.A0 ) = minA0 dom(S){A0 } Qo(N , Sov, A.A0 ). Thus, minA0 dom(S)
replaced minA0 dom(S),FS,l(S) (A.A0 )=t (as FVf r (A) = t, exists least one assignment
A0 dom(S) FS,l(S) (A.A0 ) = t). result holds quantified max. Applying mechanism set quantified decision variables left right Sov,
obtain minA0 dom(S) maxA0 dom(S) replaced minA0 dom(S),FS,l(S) (A.A0 )=t
maxA0 dom(S),FS,l(S) (A.A0 )=t respectively. Moreover, shown every complete assignment A00 considered corresponding transformed operational definition, FVD | (A00 ) = t.
thus possible replace FVD | (A00 ) ? PVE | VD (A00 ) pu UV (A00 ) PVE | VD (A00 ) pu UV (A00 ).

475

fiPralet, Verfaillie, & Schiex

transform uA0 dom(S) Qo(N , Sov, A.A0 ) looks like expression
semantic definition. Let leftmost set quantified environment variables. Let assignment l(S). Let A0 dom(S) PS,l(S) (A.A0 ) = 0p . Then, complete assignments
A00 extending A.A0 , PVE | VD (A00 ) = 0p , thus PVE | VD (A00 ) pu UV (A00 ) = 0u . min(0u , 0u ) =
max(0u , 0u ) = 0u u 0u = 0u , obtain Qo(N , Sov, A.A0 ) = 0u . u 0u = d, computing uA0 dom(S) Qo(N , Sov, A.A0 ) equivalent computing uA0 dom(S){A0 } Qo(N , Sov, A.A0 ).
Thus, uA0 dom(S) replaced uA0 dom(S),PS,l(S) (A.A0 )6=0p (as Pl(S) (A) 6= 0p , exists
least one assignment A0 dom(S) satisfying PS,l(S) (A.A0 ) 6= 0p ). Applying mechanism,
considering set quantified environment variables left right Sov, get
uA0 dom(S),PS,l(S) (A,A0 )6=0p instead uA0 dom(S) .
Consequently, found function Sem-Ans(Q) = Op-Ans(Q) = .
Moreover, optimal policies decisions Sem-Ans(Q) optimal policies decisions
. Indeed, transformation rules used preserve set optimal policies. holds
Op-Ans(Q) . entails Sem-Ans(Q) = Op-Ans(Q), optimal policies
Sem-Ans(Q) Op-Ans(Q).

Theorem 3 Queries bounded queries used express solve following
nonexhaustive list problems:
1. SAT framework: SAT, MAJSAT, E-MAJSAT, quantified boolean formula, stochastic
SAT (SSAT) extended-SSAT (Littman et al., 2001).
2. CSP (or CN) framework:
Check consistency CSP (Mackworth, 1977); find solution CSP; count
number solutions CSP.
Find solution valued CSP (Bistarelli et al., 1999).
Solve quantified CSP (Bordeaux & Monfroy, 2002).
Find conditional decision unconditional decision mixed CSP
probabilistic mixed CSP (Fargier et al., 1996).
Find optimal policy stochastic CSP policy value greater
threshold; solve stochastic COP (Constraint Optimization Problem) (Walsh,
2002).
3. Integer Linear Programming (Schrijver, 1998) finite domain variables.
4. Search solution plan length k classical planning problem (STRIPS
planning, Fikes & Nilsson, 1971; Ghallab et al., 2004).
5. Answer classical queries Bayesian networks (Pearl, 1988), Markov random fields
(Chellappa & Jain, 1993), chain graphs (Frydenberg, 1990), plausibilities
expressed probabilities, possibilities, -rankings:
Compute plausibility distributions.
MAP (Maximum Posteriori hypothesis) MPE (Most Probable Explanation).
476

fiThe PFU Framework

Compute plausibility evidence.
CPE task hybrid networks (Dechter & Larkin, 2001) (CPE means CNF Probability Evaluation, CNF formula Conjunctive Normal Form).
6. Solve influence diagram (Howard & Matheson, 1984).
7. finite horizon, solve probabilistic MDP, possibilistic MDP, MDP based
-rankings, completely partially observable (POMDP), factored (Puterman,
1994; Monahan, 1982; Sabbadin, 1999; Boutilier et al., 1999, 2000).
Proof.
Lemma 3. Let (Ep , Eu , u , pu ) expected utility structure Eu totally ordered
u . Let S1 ,S2 local function Eu whose scope S1 S2 .
max
u
S1 ,S2 ((A).A)
:dom(S2 )dom(S1 ) Adom(S2 )

= u max S1 ,S2 .
S2

S1

Moreover, : dom(S2 ) dom(S1 ) satisfies (maxS1 S1 ,S2 )(A) = S1 ,S2 ((A).A)
dom(S2 ) iff max:dom(S2 )dom(S1 ) uAdom(S2 ) S1 ,S2 ((A).A) = uAdom(S2 ) S1 ,S2 ((A).A).
words, two sides equality set optimal policies S1 .
Proof. Let 0 : dom(S2 ) dom(S1 ) function
max:dom(S2 )dom(S1 ) uAdom(S2 ) S1 ,S2 ((A).A) = uAdom(S2 ) S1 ,S2 (0 (A).A).
Given that, dom(S2 ), S1 ,S2 (0 (A).A) u maxA0 dom(S1 ) S1 ,S2 (A0 .A), monotonicity
u entails uAdom(S2 ) S1 ,S2 (0 (A).A) u uAdom(S2 ) maxA0 dom(S1 ) S1 ,S2 (A0 .A). Thus,
max:dom(S2 )dom(S1 ) uAdom(S2 ) S1 ,S2 ((A).A) u uS2 maxS1 S1 ,S2 .
hand, let 0 : dom(S2 ) dom(S1 ) function dom(S2 ),
(maxS1 S1 ,S2 )(A) = S1 ,S2 (0 (A).A). Then,
uS2 maxS1 S1 ,S2 =
u
S1 ,S2 (0 (A).A) u
max
u
S1 ,S2 ((A).A).
:dom(S2 )dom(S1 ) Adom(S2 )

Adom(S2 )

antisymmetry u implies required equality. equality set optimal policies
S1 directly implied equality.
give proof theorem, uses cases previous lemma.
1. (CSP based problems, Mackworth, 1977 )
Let us consider CSP set variables V set constraints {C1 , . . . , Cm }.
(a) (Consistency solution finding) Consistency checked using query Q =
(N , (max, V )), N = (V, G, , , U ) (all variables V decision variables, G
reduced unique decision component containing variables, U = {C1 , . . . , Cm }),
expected utility structure boolean optimistic expected conjunctive
utility (row 6 Table 1). Computing Ans(Q) = maxV (C1 . . . Cm ) equivalent
checking consistency, Ans(Q) = iff exists assignment V satisfying
C1 . . .Cm , i.e. iff CSP consistent. order get solution Ans(Q) = t,
suffices record optimal decision rule V . Integer Linear Programming (Schrijver,
1998) finite domain variables formulated CSP.
(b) (Counting number solutions) expected utility structure considered
task probabilistic expected satisfaction (row 2 Table 1). PFU network
N = (V, G, P, , U ), variables V environment variables, G DAG
unique component c0 = V , P = {1/0 }, 0 constant factor equal |dom(V )|

477

fiPralet, Verfaillie, & Schiex

F act(c0 ) = {0 }, U = {C1 , . . . , Cm }. Implicitly, 1/0 specifies
complete assignments equiprobable. enables normalization
condition
P
c CE (G), p c p Pi F act(c) Pi = 1p satisfied, since V (1/|dom(V )|) = 1.
query consider Q = (N , (+, V )). P
hard check satisfies
conditions imposed queries Ans(Q) = V (1/0 (C1 . . . Cm )) gives
percentage solutions CSP. 0 Ans(Q) gives number solutions.
2. (Solving Valued CSP (VCSP), Bistarelli et al., 1999 )
order model problem, difficulty lies definition expected utility
structure. VCSP, triple (E, ~, ) called valuation structure introduced. satisfies
properties (E, ~) commutative semigroup, total order E, E
minimum element denoted >. expected utility structure consider following
one: (Ep , p , p ) = ({t, f }, , ), (Eu , u ) = (E, ~), expected utility structure
(Ep , Eu , u , pu ), u = min pu defined f alse pu u = > true pu u =
u (it hard check structure expected utility structure). Next,
PFU network N = (V, G, , , U ), V set variables VCSP, G
DAG one decision component containing variables, U contains soft
constraints. query Q = (min, V ) enables us find minimum violation degree
soft constraints. solution VCSP optimal (argmin) decision rule V .
3. (Problems SAT framework, Littman et al., 2001 )
SAT framework, queries conjunctive normal form boolean formula set
variables V = {x1 , . . . , xn } asked. Let us first prove extended SSAT formula evaluated PFU query. extended SSAT formula defined
triple (, , q) boolean formula conjunctive normal form, threshold
[0, 1], q = (q1 x1 ) . . . (qn xn ) sequence quantifier/variable pairs (the quantifiers
, , R; meaning R appears below). take f t, value quantification sequence q, val(, q), defined recursively by: (i) val(, ) = 1
t, 0 otherwise; (ii) val(,
(x) q 0 ) = maxx val(, q 0 ); (iii) val(, (x) q 0 ) = minx val(, q 0 );
P
(iv) val(, (Rx) q 0 ) =
0.5
val(, q 0 ). Intuitively, last case means R quantifies
x
boolean variables taking equiprobable values. extended SSAT formula (, , q) iff
val(, q) . denotes set variables quantified R, equivalent definition
val(, q) is: (i) val(, ) = 0.5|S| t, 0 otherwise; (ii) val(,
(x) q 0 ) = maxx val(, q 0 );
P
0
0
0
(iii) val(, (x) q ) = minx val(, q ); (iv) val(, (Rx) q ) = x val(, q 0 ). second definition proves val(, q) computed PFU query defined by: (a) expected
utility structure: probabilistic expected satisfaction (row 2 Table 1); (b) PFU network:
N = (V, G, P, , U ), V set variables formula (the decision variables
variables quantified ), G DAG without arcs, one decision component per
decision variable unique environment component containing variables quantified
R, P = {0 }, 0 constant factor equal 0.5|VE | , U set clauses ; (c)
query: Q = (N , Sov), Sov obtained q replacing , , R max, min,
+ respectively. Then, Ans(Q) = val(, q), implies value extended SSAT
formula (, , q) value bounded query (N , Sov, ).
SSAT particular case extended-SSAT therefore covered. SAT, MAJSAT, EMAJSAT, QBF also particular cases extended SSAT. result, instances
PFU bounded queries. precisely, SAT corresponds bounded query form
Q = (N , (max, V ), 1); MAJSAT (given boolean formula set variables V ,
satisfied least half assignments V ) corresponds bounded query
form (N , (+, V ), 0.5); E-MAJSAT (given boolean formula V = VD ,
exist assignment VD formula satisfied least half assignments
?) corresponds bounded query form (N , (max, VD ).(+, ), 0.5); QBF

478

fiThe PFU Framework

corresponds bounded query max existentially quantified variables min
universally quantified variables alternate.
4. (Solving Quantified CSP (QCSP), Bordeaux & Monfroy, 2002 )
QCSP represents formula form Q1 x1 . . . Qn xn (C1 . . . Cm ), Qi
quantifier ( ) Ci constraint. value QCSP defined recursively
follows: value QCSP without variables (i.e. containing t, f , connectives)
given definition connectives. QCSP x qcsp iff either qcsp((x, t)) =
qcsp((x, f )) = t. Assuming f t, gives x qcsp iff maxx qcsp = t. QCSP x qcsp
iff qcsp((x, t)) = qcsp((x, f )) = t. Equivalently, x qcsp iff minx qcsp = t.
implies value QCSP actually given formula op(Q1 )x1 . . . op(Qn )xn (C1
. . . Cm ), op() = max op() = min. corresponds answer query
(N , (op(Q1 ), x1 ). . . . .(op(Qn ), xn )), N = (V, G, , , U ) (V set variables
QCSP, G DAG one decision component containing variables, U
set constraints), expected utility structure boolean optimistic expected
conjunctive utility (row 6 Table 1).
5. (Solving mixed CSP probabilistic mixed CSP, Fargier et al., 1996 )
probabilistic mixed CSP defined (i) set variables partitioned set W
contingent variables set X decision variables; assignment AW W called
world assignment AX X called decision; (ii) set C = {C1 , . . . , Cm }
constraints involving least one decision variable; (iii) probability distribution PW
worlds; possible world AW (i.e. PW (AW ) > 0) covered decision AX iff
assignment AW .AX satisfies constraints C.
one hand, decision must made without knowing world, task find
optimal non-conditional decision, i.e. find assignment AX decision variables

covered AX . probability equal
P maximizes probability world
P
P
(A
)
=
(P
W
W C1 . . . Cm ). result, optimal
AW | (C1 ...Cm )(AX ,AW )=1 W
W
non-conditionalPdecision found recording optimal decision rule X
formula maxX W (PW C1 . . . Cm ). previous formula actually specifies
solve problem PFUs. algebraic structure probabilistic expected additive
utility (row 2 Table 1), PFU network N = (V, G, P, , U ), VD = X, = W ,
G DAG without arc, one decision component X set environment components
depends PW specified, P set multiplicative factors define PW ,
finally U = {C1 , . . . , Cm }. query Q = (N , (max, X).(+, W )).
hand, world known decision made, task look
optimal conditional decision, i.e. look decision rule 0 : dom(W ) dom(X)
maximizes probability
P world covered. words, goal compute
max:dom(W )dom(X) AW dom(W ) | (C1 ...Cm )(AW .(AW ))=1 PW (AW ) =
P
max:dom(W )dom(X) AW dom(W ) (PW C1 . . . Cm ) (AW .(AW )). Due Lemma 3,
P
also equals W maxX (PW C1 . . . Cm ), 0 found recording optimal
decision rule X. proves query Q = (N , (+, W ).(max, X)) enables us compute
optimal conditional decision.
Mixed CSPs, PW replaced set K constraints defining possible worlds.
goal look decision, either conditional non-conditional, maximizes
number covered worlds. task equivalent, ignoring normalizing constant, find
decision maximizes percentage covered worlds. solved using set
plausibility functions P = K {N0 }, N0 normalizing constant ensuring
normalization condition plausibilities holds. N0 number possible worlds,
actually need computed, since constant factor interested
optimal decisions.
479

fiPralet, Verfaillie, & Schiex

6. (Stochastic CSP (SCSP) stochastic COP (SCOP), Walsh, 2002 )
Formally, SCSP tuple (V, S, P, C, ), V list variables (each variable x
finite domain dom(x)), set stochastic variables V , P = {Ps | S}
set probability distributions (in advanced version SCSPs, probabilities
may defined Bayesian network; subsumption result still valid case),
C = {C1 , . . . , Cm } set constraints, threshold [0, 1].
SCSP-policy tree internal nodes labeled variables. root labeled
first variable V , parents leaves labeled last variable
V . Nodes labeled decision variable one child, whereas nodes labeled
stochastic variable |dom(s)| children. Leaf nodes labeled 1 complete
assignment define satisfies theQconstraints C, 0 otherwise. leaf
node associated probability sS Ps (AS ), stands assignment
implicitly defined path root leaf. satisfaction SCSP-policy
sum values leaves weighted probabilities. SCSP satisfiable
iff exists SCSP-policy satisfaction least . optimal satisfaction
SCSP maximum satisfaction SCSP-policies.
subsumption proof, first consider problem looking optimal satisfaction SCSP. SCSP-policy, decision variable x take one value per
assignment set preds (x) stochastic variables precede x list variables V . Instead described tree, SCSP-policy viewed set
x
functions
=
(x)) dom(x)), x V S}, value val() =
P
Q { : dom(pred
Q
(
P

C
x (AS ))). goal maximize previAS dom(S)
sS
Ci C )(AS .(
xV

ous quantity among sets . Let last decision variable V , let set
local functions : dom(preds (y))
defining
rule y.
X dom(y)X
Ya decision
(
val() = max
Ps
Ci )(AS .( x (AS ))).
max








dom(preds (y)) Spreds (y) sS

Ci C

xV


also equals:

P Lemma 3,
Pprevious quantity
Q
Q
max
P

preds (y))
Spreds (y)
sS
Ci C Ci . recursive application mechanism shows answer Ans(Q) query Q described equal optimal
satisfaction SCSP:
expected utility structure: row 2 Table 1 (probabilistic expected satisfaction);
PFU network: N = (V 0 , G, P, , U ), V 0 set variables SCSP; =
VD = V 0 S; G DAG without arcs, one component per variable; P =
{Ps | S}; F act({s}) = {Ps }; U set constraints SCSP;
query: Q =(N , Sov), Sov=t(V ) (V thelist variables SCSP), t(V )
(+, {x}).t(V 00 ) x
.
recursively defined t() = t(x.V 00 ) =
(max, {x}).t(V 00 ) otherwise
optimal SCSP-policy recorded evaluation Ans(Q). satisfiability
SCSP answered bounded query (N , Sov, ). Again, corresponding
SCSP-policy obtained recording optimal decision rules.
Stochastic Constraint Optimization Problem (SCOP), constraints C additive
soft constraints. subsumption proof similar.
7. (Classical planning problems (STRIPS planning), Fikes & Nilsson, 1971; Ghallab et al., 2004 )
order search plan length lesser k, simply model classical planning problem CSP. transformation already available literature (Ghallab
et al., 2004). However, also model classical planning problem directly
PFU framework. precisely, state one step described set boolean

480

fiThe PFU Framework

environment variables. step, unique decision variable whose set values corresponds actions available. Plausibility functions deterministic link
variables step variables step + 1 (these functions simply specify positive
negative effects actions). initial state also represented plausibility function
links variables first step. Feasibility functions define preconditions action
feasible. link variables step decision variable step. Utility
functions boolean functions describe goal states. hold variables
step k. order search plan length lesser k, sequence elimination
max-elimination variables. expected utility structure used boolean optimistic
expected disjunctive utility.
8. (Influence diagrams, Howard & Matheson, 1984 )
start definition influence diagrams Section 3. decision variable
d, associate decision rule : dom(paG (d)) dom(d). influence diagram policy
(ID-policy) set = { | D} decision rules (one decision variable).
value val() ID-policy X
given
Yby probabilistic
X expectation utility:
((
Ps | paG (s) ) (
Ui ))(AS .( (AS ))).
val() =
dom(S)

Ui U

sS

dD

solve influence diagram, must compute maximum value previous quantity find associated optimal ID-policy. Using Lemma 3 DAG structure,
possible show, using ideas SCSP subsumption proof, optimal
expected utility given answer query Q (associated optimal decision rules
recorded evaluation Ans(Q)):
expected utility structure: row 1 Table 1 (probabilistic expected additive utility);
PFU network: N = (V, G0 , P, , U ); V set variables influence diagram,
G0 DAG obtained DAG influence diagram removing utility
nodes arcs decision nodes; G0 , one component per variable; P =
{Ps | paG (s) , } F act({s}) = {Ps | paG (s) }; U set utility functions
associated utility nodes.
PFU query: Q = (N , Sov), Sov obtained DAG influence diagram
follows. Initially, Sov = . DAG influence diagram, decisions totally
ordered. Let first decision variable DAG G influence diagram (i.e.
decision variable parent decision variable). Then, repeatedly update Sov
Sov Sov.(+, paG (d)).(max, {d}) delete variables paG (d) G
decision variable remains. Then, perform Sov Sov.(+, S), set
chance variables deleted G.
9. (Finite horizon MDPs, Puterman, 1994; Monahan, 1982; Sabbadin, 1999; Boutilier et al.,
1999, 2000 ) order prove encoding PFU framework given Sections 5.6
6.6 actually enables us solve time-steps probabilistic MDP, start reminding
algorithm used compute optimal MDP-policy. Usually, decision rule dT
chosen computing VsT = maxdT RsT ,dT . VsT optimal reward obtained
state sT . AtP
time-step [1, [, decision rule di chosen computing Vsi =
maxdi (Rsi ,di + si+1 Psi+1 | si ,di Vsi+1 ). Last, optimal expected value reward,
depends initial state s1 , Vs1 .
Let us prove induction
forP
[1,
P
Q 1],
P
Vs1 = maxd1 s2 . . .maxdi si+1 (( k[1,i] Psk+1 | sk ,dk ) (( k[1,i] Rsk ,dk ) + Vsi+1 )).
proposition holds = 1, since P

Vs1 = maxd1 (R
P s1 ,d1 + s2 Ps2 | s1 ,d1 Vs2)
P
= maxd1 s2 (Ps2 | s1 ,d1 (Rs1 ,d1 + Vs2 )) (since s2 Ps2 | s1 ,d1 = 1).
481

fiPralet, Verfaillie, & Schiex

Moreover, proposition
holds P
stepQi 1 (with > 1), P
P
Vs1 = maxd1 s2 . . . maxdi1 si (( k[1,i1] Psk+1 | sk ,dk ) (( k[1,i1] Rsk ,dk ) + Vsi )).
Given
P
P
P
( k[1,i1] Rsk ,dk ) + Vsi = ( k[1,i1] Rsk ,dk ) + maxdi (Rsi ,di + si+1 Psi+1 | si ,di Vsi+1 )
P
P
= maxdi (( k[1,i] Rsk ,dk ) + si+1 Psi+1 | si ,di Vsi+1 )
P
P
= maxdi si+1 Psi+1 | si ,di (( k[1,i] Rsk ,dk ) + Vsi+1 )
P
(the last equality holds since si+1 Psi+1 | si ,di = 1), inferred
Q
P
( k[1,i1] Psk+1 | sk ,dk ) (( k[1,i1] Rsk ,dk ) + Vsi )
P
Q
P
= maxdi si+1 (( k[1,i] Psk+1 | sk ,dk ) (( k[1,i] Rsk ,dk ) + Vsi+1 )),
proves proposition holds step i. proves also holds step ,
therefore Vs1 = Ans(Q). Furthermore, step proof preserves set optimal
decision rules, optimal MDP-policy recorded evaluation Ans(Q).
study case partially observable finite horizon MDPs (finite horizon POMDPs).
POMDP, add time step > 1 conditional probability distribution Pot | st
making observation ot time step given state st . value st remains unobserved. also assume probability distribution Ps1 initial state available.
subsumption proof case difficult. consider approach POMDPs
consists finding optimal policy tree. approach equivalent compute,
decision variable dt , decision rule dt depending observations made
far, i.e. function dt : dom({o2 , . . . , ot }) dom(dt ). set functions denoted
dt . set = {d1 , . . . , dT } called POMDP-policy. value POMDP-policy
recursively defined follows. First, value reward last decision step,
depends assignment AsT sT observations O2T made
beginning, V ()sT ,o2 ,...,ot (AsT .O2T ) = RsT ,dT (AsT , dT (O2T )). time step i,
obtained reward depends actual state Asi observations O2i made far.
expression is:
V ()si ,o2 ,...,o
P
Pi (Asi .O2i )
= (Rsi ,di + si+1 Psi+1 | si ,di oi+1 Poi+1 | si+1 V ()si+1 ,o1 ,...,oi+1 )(A)
= Asi .di (O2i ).O2i equation recursive formula used define
value policy tree POMDP (Kaelbling, Littman, & Cassandra,P
1998) equivalent. Finally, expected reward POMDP-policy V () = s1 Ps1 V ()s1 .
Solving finite horizon POMDP consists computing optimal expected reward among
POMDP-policies (i.e. computing V = maxd1 ,...,dT V ({d1 , . . . , dT })), well
associated optimal decision rules.
Using proof induction observable MDP case, first possible prove
problem steps, P
P
V = maxd1 ,...,dT o2 ,...,oT s1 ,...,sT V
Q
Q
P
V = (Ps1 i[1,T [ Psi+1 | si ,di i[1,T [ Poi+1 | si+1 ) ( i[1,T ] Rsi ,di ).
this, recursive use Lemma
3 enables
P
P us infer
Pthat
P
V = maxd1 o2 maxd2 o3 maxd3 . . . oT maxdT s1 ,...,sT V .
proves query defined enables us compute V well optimal policy:
algebraic structure: probabilistic expected additive utility (row 1 Table 1);
PFU network: N = (V, G, P, , U ); V equals {si | [1, ]} {oi | [2, ]} {di |
[1, ]}, VD = {di | [1, ]}; G DAG one variable per component;
decision component parents, environment component {oi }
{si } parent, component {si+1 } {si } {di } parents; P = {Ps1 }
{Psi+1 | si ,di , [1, 1]} {Poi | si | [2, ]}; F act({s1 }) = {Ps1 }, F act({si+1 }) =
{Psi+1 | si ,di }, F act({oi }) = {Poi | si }; last, U = {Rsi ,di | [1, ]};
482

fiThe PFU Framework

PFU query: based DAG, necessary condition query defined
decision di must appear left variables {sk | k [i + 1, ]} {ok | k
[i + 1, ]}; query considered Q = (N , Sov),
Sov = (max, d1 ).(+, o2 ).(max, d2 ). . . . .(+, oT ).(max, dT ).(+, {s1 , . . . , sT }).
proofs finite horizon (PO)MDPs based possibilities -rankings similar.
subsumption factored MDPs, first argue every factored MDP
represented usual MDP, therefore PFU query PFU network. Even
sufficient argument, define better representation factored MDPs
PFU framework: corresponds representation variables describing states
directly used together local plausibility functions rewards, modeled
scoped functions (defined decision trees, binary decision diagrams. . . ).
10. (Queries Bayesian networks, Pearl, 1988, Markov random fields, Chellappa & Jain, 1993,
chain graphs, Frydenberg, 1990 )
suffices consider chain graphs, since Bayesian networks Markov random fields
particular cases chain graphs. subsumption proofs provided general case
plausibility distributions defined totally ordered conditionable plausibility structure.
(a) (MAP, MPE, probability evidence) MPE (Most Probable Explanation)
computation probability evidence particular cases MAP (Maximum
Posteriori hypothesis), suffices prove MAP subsumed. probabilistic
MAP problem consists finding, given probability distribution PV , Maximum
Posteriori explanation assignment subset V observed (also
called evidence). formally, let denote set variables explanation
sought let e denote observed assignment O. MAP problem consists
finding assignment maxAdom(D) PD | (A.e) = PD | (A .e).
PD | = PD,O /PO , write:
maxAdom(D) PD | (A.e) = (maxAdom(D) P
PD,O (A.e))/PO (e)
= (maxAdom(D) A0 dom(V (DO)) PV (A.e.A0 ))/PO (e)
P
Thus, computing maxD V (DO) PV (e) sufficient (the difference lies normalizing constant). result generalized totally ordered conditionable
plausibility structures.
Indeed, p monotonic, maxAdom(D) PD,O (A.e) = (maxAdom(D) PD | (A.e)) p
PO (e). maxAdom(D) PD,O (A.e) p PO (e), exists unique p Ep
maxAdom(D) PD,O (A.e) = p p PO (e). gives us p = maxAdom(D) PD | (A.e).
Otherwise, maxAdom(D) PD,O (A.e) = PO (e), infer exists
dom(D) PD,O (A .e) = PO (e), therefore PD | (A .e) = 1p . Thus,
maxAdom(D) PD | (A.e) = 1p too. shows determining maxAdom(D) PD,O (A.e)
gives maxAdom(D) PD | (A.e).
Moreover, argmax{PD,O (A0 .e), A0 dom(D)}, max{p Ep | PD,O (A .e) =
p p PO (e)} p max{p Ep | PD,O (A.e) = p p PO (e)} dom(D). Therefore, optimal assignment maxD PD,O (e) also optimal assignment
maxD PD | (e). result, MAP problem reduced computation
maxD PD,O (e) = maxD p V (DO) PV (e) = maxD p V (PV p )
scoped function scope (e0 ) = 1p e0 = e, 0p otherwise. define PFU query whose answer Ans(Q) = maxD p V (PV p ):
plausibility structure (Ep , p , p ), utility structure (Eu , u ) = (Ep , p ),
expected utility structure (Ep , Eu , u , pu ) = (Ep , Ep , p , p );
PFU network: difficulty definition PFU network lies fact
normalization conditions components must satisfied. idea
483

fiPralet, Verfaillie, & Schiex

components variable involved modified. PFU
network N = (V, G, P, , U ); V set variables chain graph; VD =
= V D; G DAG components obtained DAG G0 chain
graph splitting every component c variable involved:
component c transformed |c| components containing one variable;
|c| components become parents child components c; component
{x0 } included one |c| components, x0 D, {x0 } decision
component; otherwise, {x0 } environment component, create plausibility function Pi , equal constant p0 (x0 ) p i[1,|dom(x0 )|] p0 (x0 ) = 1p ,
F act({x0 }) = {p0 (x0 )}; P contains first constants defined above,
second factors expressing Pc | paG0 (c) chain graph components
c satisfying c (D O) = ; last, U contains factors expressing Pc | paG0 (c)
chain graph components c c (D O) 6= , constant factor
p1 (x0 ) satisfying p1 (x0 ) p p0 (x0 ) = 1p component {x0 } created
splitting process described above, hard constraints representing ;
PFU network, local normalization conditions satisfied, combination
local functions equals PV p ;
PFU query: query simply Q = (N , (max, D).(u , V D)).
optimal decision rule recorded computation Ans(Q).
(b) (Plausibility distribution computation task ) Given plausibility distribution PV expressed combination plausibility functions chain graphs, goal
compute plausibility distribution PS set V . basic formula PS =
p V PV proves query defined actually computes PS . query shows
usefulness free variables.
plausibility structure (Ep , p , p ), utility structure (Eu , u ) = (Ep , p ),
expected utility structure (Ep , Eu , u , pu ) = (Ep , Ep , p , p );
PFU network: N = (V, G, P, , U ), = V S, VD = S, DAG
G sets P , U obtained similarly MAP case;
PFU query: Q = (N , (u , V S))
11. (Hybrid networks, Dechter & Larkin, 2001 )
hybrid network triple (G, P, F ), G DAG set variables V partitioned
R D, P set probability distributions expressing Pr | paG (r) r R,
F set functions fpaG (d) (variables deterministic,
sense value completely determined assignment parents).
general task hybrid networks task belief assessment conditioned formula conjunctive normal form. consists computing probability distribution
variable x given complex evidence (complex may involve several variables).
P Ignoring normalizing constant, requires compute, assignments (x, a)
x, Adom(V {x}) | (A.(x,a))=t PV (A.(x, a)). C = {C1 , . . . , Cm } denotes set clauses
P
Q
Q
Q
, also equals ( V {x} ( rR Pr | paG (r) ) ( dD fpaG (d) ) ( Ci C Ci ))((x, a)).
query corresponding computation uses probabilistic expected satisfaction structure (row 2 Table 1), PFU network N = (V, G, P, , U ), = V , VD = {x},
P = {Pr | paG (r) | r R {x}} {fpaG (d) | {x}}, either U = C {Px | paG (x) }
x R U = C {fpaG (x) } x D. query Q = (N , (+, V {x})).

484

fiThe PFU Framework

References
Bacchus, F., & Grove, A. (1995). Graphical Models Preference Utility. Proc.
11th International Conference Uncertainty Artificial Intelligence (UAI-95),
pp. 310, Montreal, Canada.
Bahar, R., Frohm, E., Gaona, C., Hachtel, G., Macii, E., Pardo, A., & Somenzi, F. (1993).
Algebraic Decision Diagrams Applications. IEEE /ACM International
Conference CAD, pp. 188191, Santa Clara, California, USA. IEEE Computer
Society Press.
Bertele, U., & Brioschi, F. (1972). Nonserial Dynamic Programming. Academic Press.
Bistarelli, S., Montanari, U., Rossi, F., Schiex, T., Verfaillie, G., & Fargier, H. (1999).
Semiring-Based CSPs Valued CSPs: Frameworks, Properties Comparison.
Constraints, 4 (3), 199240.
Bodlaender, H. (1997). Treewidth: Algorithmic techniques results. Proc.
22nd International Symposium Mathematical Foundations Computer Science
(MFCS-97).
Bordeaux, L., & Monfroy, E. (2002). Beyond NP: Arc-consistency Quantified Constraints. Proc. 8th International Conference Principles Practice
Constraint Programming (CP-02), Ithaca, New York, USA.
Boutilier, C., Brafman, R., Domshlak, C., Hoos, H., & Poole, D. (2004). CP-nets: Tool
Representing Reasoning Conditional Ceteris Paribus Preference Statements.
Journal Artificial Intelligence Research, 21, 135191.
Boutilier, C., Dean, T., & Hanks, S. (1999). Decision-Theoretic Planning: Structural Assumptions Computational Leverage. Journal Artificial Intelligence Research,
11, 194.
Boutilier, C., Dearden, R., & Goldszmidt, M. (2000). Stochastic Dynamic Programming
Factored Representations. Artificial Intelligence, 121 (1-2), 49107.
Boutilier, C., Friedman, N., Goldszmidt, M., & Koller, D. (1996). Context-Specific Independence Bayesian Networks. Proc. 12th International Conference
Uncertainty Artificial Intelligence (UAI-96), pp. 115123, Portland, Oregon, USA.
Chellappa, R., & Jain, A. (1993). Markov Random Fields: Theory Applications. Academic Press.
Chu, F., & Halpern, J. (2003a). Great Expectations. Part I: Customizability
Generalized Expected Utility. Proc. 18th International Joint Conference
Artificial Intelligence (IJCAI-03), Acapulco, Mexico.
Chu, F., & Halpern, J. (2003b). Great Expectations. Part II: Generalized Expected Utility
Universal Decision Rule. Proc. 18th International Joint Conference
Artificial Intelligence (IJCAI-03), pp. 291296, Acapulco, Mexico.
Cooper, M., & Schiex, T. (2004). Arc Consistency Soft Constraints. Artificial Intelligence, 154 (1-2), 199227.
Darwiche, A. (2001). Recursive Conditioning. Artificial Intelligence, 126 (1-2), 541.
485

fiPralet, Verfaillie, & Schiex

Darwiche, A., & Ginsberg, M. (1992). Symbolic Generalization Probability Theory.
Proc. 10th National Conference Artificial Intelligence (AAAI-92), pp.
622627, San Jose, CA, USA.
Dechter, R. (1999). Bucket Elimination: Unifying Framework Reasoning. Artificial
Intelligence, 113 (1-2), 4185.
Dechter, R., & Fattah, Y. E. (2001). Topological Parameters Time-Space Tradeoff.
Artificial Intelligence, 125 (1-2), 93118.
Dechter, R., & Larkin, D. (2001). Hybrid Processing Beliefs Constraints. Proc.
17th International Conference Uncertainty Artificial Intelligence (UAI-01),
pp. 112119, Seattle, WA, USA.
Dechter, R., & Mateescu, R. (2004). Mixtures Deterministic-Probabilistic Networks
AND/OR Search Space. Proc. 20th International Conference
Uncertainty Artificial Intelligence (UAI-04), Banff, Canada.
Demirer, R., & Shenoy, P. (2001). Sequential Valuation Networks: New Graphical Technique Asymmetric Decision Problems. Proc. 6th European Conference
Symbolic Quantitavive Approaches Reasoning Uncertainty (ECSQARU01), pp. 252265, London, UK.
Dubois, D., & Prade, H. (1995). Possibility Theory Basis Qualitative Decision
Theory. Proc. 14th International Joint Conference Artificial Intelligence
(IJCAI-95), pp. 19251930, Montreal, Canada.
Fargier, H., Lang, J., & Schiex, T. (1996). Mixed Constraint Satisfaction: Framework
Decision Problems Incomplete Knowledge. Proc. 13th National
Conference Artificial Intelligence (AAAI-96), pp. 175180, Portland, OR, USA.
Fargier, H., & Perny, P. (1999). Qualitative Models Decision Uncertainty without
Commensurability Assumption. Proc. 15th International Conference
Uncertainty Artificial Intelligence (UAI-99), pp. 188195, Stockholm, Sweden.
Fikes, R., & Nilsson, N. (1971). STRIPS: New Approach Application Theorem
Proving. Artificial Intelligence, 2 (3-4), 189208.
Fishburn, P. (1982). Foundations Expected Utility. D. Reidel Publishing Company,
Dordrecht.
Friedman, N., & Halpern, J. (1995). Plausibility Measures: Users Guide. Proc.
11th International Conference Uncertainty Artificial Intelligence (UAI-95), pp.
175184, Montreal, Canada.
Frydenberg, M. (1990). Chain Graph Markov Property. Scandinavian Journal
Statistics, 17, 333353.
Ghallab, M., Nau, D., & Traverso, P. (2004). Automated Planning: Theory Practice.
Morgan Kaufmann.
Giang, P., & Shenoy, P. (2000). Qualitative Linear Utility Theory Spohns Theory
Epistemic Beliefs. Proc. 16th International Conference Uncertainty
Artificial Intelligence (UAI-00), pp. 220229, Stanford, California, USA.

486

fiThe PFU Framework

Giang, P., & Shenoy, P. (2005). Two Axiomatic Approaches Decision Making Using
Possibility Theory. European Journal Operational Research, 162 (2), 450467.
Goldman, R., & Boddy, M. (1996). Expressive Planning Explicit Knowledge. Proc.
3rd International Conference Artificial Intelligence Planning Systems (AIPS96), pp. 110117, Edinburgh, Scotland.
Halpern, J. (2001). Conditional Plausibility Measures Bayesian Networks. Journal
Artificial Intelligence Research, 14, 359389.
Halpern, J. (2003). Reasoning Uncertainty. MIT Press.
Howard, R., & Matheson, J. (1984). Influence Diagrams. Readings Principles
Applications Decision Analysis, pp. 721762. Strategic Decisions Group, Menlo
Park, CA, USA.
Jegou, P., & Terrioux, C. (2003). Hybrid Backtracking bounded Tree-decomposition
Constraint Networks. Artificial Intelligence, 146 (1), 4375.
Jensen, F., Nielsen, T., & Shenoy, P. (2004). Sequential Influence Diagrams: Unified
Asymmetry Framework. Proceedings Second European Workshop Probabilistic Graphical Models (PGM-04), pp. 121128, Leiden, Netherlands.
Jensen, F., & Vomlelova, M. (2002). Unconstrained Influence Diagrams. Proc.
18th International Conference Uncertainty Artificial Intelligence (UAI-02), pp.
234241, Seattle, WA, USA.
Kaelbling, L., Littman, M., & Cassandra, A. (1998). Planning Acting Partially
Observable Stochastic Domains. Artificial Intelligence, 101 (1-2), 99134.
Kolhas, J. (2003). Information Algebras: Generic Structures Inference. Springer.
Kushmerick, N., Hanks, S., & Weld, D. (1995). Algorithm Probabilistic Planning.
Artificial Intelligence, 76 (1-2), 239286.
Larrosa, J., & Schiex., T. (2003). quest best form local consistency
weighted csp. Proc. 18th International Joint Conference Artificial Intelligence (IJCAI-03), Acapulco, Mexico.
Lauritzen, S., & Nilsson, D. (2001). Representing Solving Decision Problems
Limited Information. Management Science, 47 (9), 12351251.
Littman, M., Majercik, S., & Pitassi, T. (2001). Stochastic Boolean Satisfiability. Journal
Automated Reasoning, 27 (3), 251296.
Mackworth, A. (1977). Consistency Networks Relations. Artificial Intelligence, 8 (1),
99118.
Monahan, G. (1982). Survey Partially Observable Markov Decision Processes: Theory,
Models, Algorithms. Management Science, 28 (1), 116.
Ndilikilikesha, P. (1994). Potential Influence Diagrams. International Journal Approximated Reasoning, 10, 251285.
Nielsen, T., & Jensen, F. (2003). Representing solving asymmetric decision problems.
International Journal Information Technology Decision Making, 2, 217263.

487

fiPralet, Verfaillie, & Schiex

Pearl, J. (1988). Probabilistic Reasoning Intelligent Systems: Networks Plausible Inference. Morgan Kaufmann.
Perny, P., Spanjaard, O., & Weng, P. (2005). Algebraic Markov Decision Processes.
Proc. 19th International Joint Conference Artificial Intelligence (IJCAI05), Edinburgh, Scotland.
Pralet, C. (2006). Generic Algebraic Framework Representing Solving Sequential Decision Making Problems Uncertainties, Feasibilities, Utilities. Ph.D.
thesis, Ecole Nationale Superieure de lAeronautique et de lEspace, Toulouse, France.
Pralet, C., Schiex, T., & Verfaillie, G. (2006a). Decomposition Multi-Operator Queries
Semiring-based Graphical Models. Proc. 12th International Conference
Principles Practice Constraint Programming (CP-06), pp. 437452, Nantes,
France.
Pralet, C., Schiex, T., & Verfaillie, G. (2006b). Influence Diagrams Multioperator
Cluster DAGs. Proc. 22nd International Conference Uncertainty
Artificial Intelligence (UAI-06), Cambridge, MA, USA.
Pralet, C., Verfaillie, G., & Schiex, T. (2006c). Decision Uncertainties, Feasibilities,
Utilities: Towards Unified Algebraic Framework. Proc. 17th European
Conference Artificial Intelligence (ECAI-06), pp. 427431, Riva del Garda, Italy.
Puterman, M. (1994). Markov Decision Processes, Discrete Stochastic Dynamic Programming. John Wiley & Sons.
Sabbadin, R. (1999). Possibilistic Model Qualitative Sequential Decision Problems
Uncertainty Partially Observable Environments. Proc. 15th International Conference Uncertainty Artificial Intelligence (UAI-99), pp. 567574,
Stockholm, Sweden.
Sang, T., Beame, P., & Kautz, H. (2005). Solving Bayesian Networks Weighted Model
Counting. Proc. 20th National Conference Artificial Intelligence (AAAI05), pp. 475482, Pittsburgh, PA, USA.
Schmeidler, D. (1989). Subjective Probability Expected Utility without Additivity.
Econometrica, 57 (3), 571587.
Schrijver, A. (1998). Theory Linear Integer Programming. John Wiley Sons.
Shafer, G. (1976). Mathematical Theory Evidence. Princeton University Press.
Shenoy, P. (1991). Valuation-based Systems Discrete Optimization. Uncertainty
Artificial Intelligence, 6, 385400.
Shenoy, P. (1992). Valuation-based Systems Bayesian Decision Analysis. Operations
Research, 40 (3), 463484.
Shenoy, P. (1994). Conditional Independence Valuation-Based Systems. International
Journal Approximated Reasoning, 10 (3), 203234.
Shenoy, P. (2000). Valuation Network Representation Solution Asymmetric Decision
Problems. European Journal Operational Research, 121, 579608.

488

fiThe PFU Framework

Smith, J., Holtzman, S., & Matheson, J. (1993). Structuring Conditional Relationships
Influence Diagrams. Operations Research, 41, 280297.
Spohn, W. (1990). General Non-Probabilistic Theory Inductive Reasoning. Proc.
6th International Conference Uncertainty Artificial Intelligence (UAI-90),
pp. 149158, Cambridge, MA, USA.
von Neumann, J., & Morgenstern, O. (1944). Theory Games Economic Behaviour.
Princeton University Press.
Walsh, T. (2002). Stochastic Constraint Programming. Proc. 15th European
Conference Artificial Intelligence (ECAI-02), pp. 111115, Lyon, France.
Weydert, E. (1994). General Belief Measures. Proc. 10th International Conference
Uncertainty Artificial Intelligence (UAI-94), pp. 575582.
Wilson, N. (1995). Order Magnitude Calculus. Proc. 11th International
Conference Uncertainty Artificial Intelligence (UAI-95), pp. 548555, Montreal,
Canada.

489

fiJournal Artificial Intelligence Research 29 (2007) 1-18

Submitted 07/06; published 05/07

Phase Transition Random Quantified XOR-Formulas
Nadia Creignou

creignou@lif.univ-mrs.fr

LIF, UMR CNRS 6166
Universite de la Mediterranee
163, avenue de Luminy
13 288 Marseille, France

Herve Daude

daude@gyptis.univ-mrs.fr

LATP, UMR CNRS 6632
Universite de Provence
39, rue Joliot-Curie
13 453 Marseille, France

Uwe Egly

uwe@kr.tuwien.ac.at

Institut fur Informationssysteme 184/3
Technische Universitat Wien
Favoritenstrae 911
A1040 Wien, Austria

Abstract
QXOR-SAT problem quantified version satisfiability problem XOR-SAT
connective exclusive-or used instead usual or. study phase
transition associated random QXOR-SAT instances. give description
phase transition case one alternation quantifiers, thus performing advanced
practical theoretical study phase transition quantified problem.

1. Introduction
last decade seen growth interest phase transition Boolean satisfiability
(SAT). clausal version problem shows sharp transition sense that,
density clauses increased, formulas abruptly change satisfiable
unsatisfiable critical threshold point. Numerous experimental studies
performed investigation phase transition different variants SAT problems,
thus giving strong evidence location transition coincides instances
hard solve. meantime, theoretical studies conducted order
better understand transitions. Determining nature phase transition (sharp
coarse)1 , locating it, determining precise scaling window better understanding
structure space solutions turn challenging tasks,
aroused lot interest different communities, namely mathematics, computer science
statistical physics (see e.g., Dubois, Monasson, Selman, & Zecchina, 2001).
computer science point view, success SAT problem due two features.
problem SAT provides framework problems within complexity class NP
1. Definitions sharp coarse phase transitions found p. 21 (Janson, Luczak, & Rucinski,
2000).

c
2007
AI Access Foundation. rights reserved.

fiCreignou, Daude, & Egly

adequately expressed, moreover practically efficient highly optimized solvers
available.
order obtain even stronger systems, many researchers turned powerful
generalization Boolean satisfiability, QSAT, universal existential quantifiers Boolean variables permitted. QSAT problem permits adequate
representation modeling problems higher complexitywithin complexity
class PSPACEand coming various fields computer science knowledge representation, verification logic. Recently, random instances quantified problems
started attract attention (see Gent & Walsh, 1999; Chen & Interian, 2005).
Models generating random instances developed, experimental studies
shown models QSAT property undergoes phase transition
qualitatively similar one appears ordinary SAT property. stated
Chen Interian (2005), hope research developing competitive solvers
quantified Boolean formulas could benefit better understanding typical behavior random instances. study follows pioneering work Chen Interian
(2005) made precise promising model generating random instances
QSAT problem. use model apply satisfiability problem QXOR-SAT
present below.
difficulty identifying transition factors performing theoretical explorations
SAT transition incited many researchers turn variant SAT problem:
e-XOR-SAT problem. satisfiability problem deals Boolean formulas conjunctive normal form e variables per clause, usual replaced
exclusive (we call clauses exclusive connective XOR-clauses).
problem contributed develop validate techniques, thus revealing typical behaviors
random instances space solutions SAT-type problems (see, e.g.,
Cocco, Dubois, Mandler, & Monasson, 2003; Creignou & Daude, 2003; Dubois, Boufkhad,
& Mandler, 2000; Dubois & Mandler, 2002; Franz, Leone, Ricci-Tersenghi, & Zecchina,
2001). Therefore, order understand phase transitions evolve satisfiability
introducing quantified variables, quite natural consider problem.
Although phase transition random k-SAT yet well understood, generalization quantified version started years. hope generalization
problem help understanding original one. Another way gaining insight
hard problem look tractable variants. reasons paper
embark theoretical study phase transition QXOR-SAT problem,
quantified version XOR-SAT problem. Let us emphasize quantified
problem is, usual XOR-SAT problem, P, hence permit us provide experiments large scale, thus giving useful intuition asymptotical behavior random
instances. order efficiently solve instance XOR-SAT problem, clause set
rewritten set equations coefficients finite field GF (2) Gaussian
elimination performed resulting set equations. Gaussian elimination followed
examination quantifier structure provides algorithm quantified version
XOR-SAT problem (for details, see Creignou, Khanna, & Sudan, 2001, chap. 6.4).
Following previous studies conducted Gent Walsh (1999) well Chen
Interian (2005), focus formulas conjunctive normal form two quantifier
2

fiPhase Transition Random Quantified XOR-Formulas

blocks, namely formulas type XY (X, ), X denote distinct sets
variables, (X, ) conjunction XOR-clauses. Moreover, variable occurring
(X, ) occurs X , i.e., formula XY (X, ) closed. model several
parameters. First consider (a,e)-QXOR-formulas, clause
exactly (a + e) variables, X e . (a,e)-QXOR-SAT property
property formula true. second parameter pair (m, n) specifying
number variables quantifier block, i.e., X . third parameter L,
number clauses. sum up, generated formulas form XY (X, ),
X variables, n variables, clause variables X e
total number L clauses . interested probability
formula drawn random uniformly set formulas true n tends
infinity (Section 2). prove nature phase transition (coarse sharp)
(a,e)-QXOR-SAT governed number existential variables occurring clause.
e = 2 1, prove Section 3 (a,2)-QXOR-SAT coarse phase
transition. Moreover give expression distribution function threshold
(a,2)-QXOR-SAT show influenced different parameters model.
e 3, prove Section 4 (a,e)-QXOR-SAT sharp phase transitionthus
getting first proof sharp threshold natural quantified satisfiability problem.

2. QXOR, XOR Maximal rank Property
section, relate QXOR XOR Maximal rank property. start
definitions notations.
2.1 Notation
e-XOR-clause, C, linear equation finite field GF (2) using exactly e distinct
variables, C = ((x1 . . . xe ) = ) = 0 1.
e-XOR-formula, , conjunction necessarily distinct e-XOR-clauses.
truth assignment mapping assigns 0 1 variable domain, satisfies
e
X
I(xi ) mod 2 =
XOR-clause C = ((x1 . . . xe ) = ) I(C) :=
i=1

satisfies formula satisfies every clause .
denote e-XOR-SAT property e-XOR-formula satisfiable.
(a,e)-QXOR-formula closed quantified formula following type
XY (X, ),

X denote distinct set variables, (X, ) (a + e)-XOR-formula
clause contains exactly variables X exactly e variables .
formula true if, every assignment variables X, exists assignment
variables , true. Observe that, closed formulas, notions truth
satisfiability coincide. reason, use two notions synonymously
following. denote (a,e)-QXOR-SAT property (a,e)-QXOR-formula
true.
Throughout paper, reserve number universal variables (resp. n
number existential variables), {x1 , . . . , xm } (resp. {y1 , . . . , yn }) denotes set
3

fiCreignou, Daude, & Egly

variables. Note


n
N=

2

e

(1)

(a,e)-XOR-clauses. consider random formulas XY (X, ) obtained choosing uniformly independently replacement L clauses possible N (a,e)-XORclauses. Using terminology Chen Interian (2005), formulas correspond
(a,e)-QXOR((m,n),L)-formulas. interested estimating probability
randomly chosen (a,e)-QXOR((m,n),L)-formula true. denote probability
Pr(m,n,L) ((a,e)-QXOR-SAT), shortly Pr((a,e)-QXOR-SAT) confusion arise.
restricted non-quantified case, e-XOR-SAT, i.e., a=0, omit first
component subscript, thus discussing Prn,L (e-XOR-SAT), shortly Pr(e-XOR-SAT).
show behavior (a,e)-QXOR-SAT property bounded
two monotone properties, namely e-XOR-SAT property
Maximal rank property. Experiments suggest right parameter order study
properties c, ratio number clauses number existential variables. Moreover, according results obtained e-XOR-SAT Creignou, Daude,
Dubois (2003), know transition occurs c < 1. Therefore, sequel
always suppose without loss generality L n.
2.2 Upper Lower Bounds QXOR-SAT Property
Note random (a,e)-QXOR((m,n),L)-formula also considered quantified
linear system
XY (AX + EY = C)
(2)
coefficient arithmetic GF (2), (respectively E) matrix chosen uniformly
set Boolean L (resp. L n) matrices exactly (respectively e) units
row, C Boolean column vector dimension L chosen uniformly
set vectors. Moreover, A, E C chosen independently.
Observe quantified linear system
XY (AX + EY = C)
consistent
X (C AX) Im(E),
Im(E) represents image linear application whose matrix representation
E, Im(E) = {EY / {0, 1}n }. Hence quantified linear system consistent
C Im(E) Im(A) Im(E). Therefore, get:
Pr((a,e)-QXOR-SAT) = Pr(XY (AX + EY = C) consistent)
= Pr(C Im(E) Im(A) Im(E)).
Thus, one hand
Pr((a,e)-QXOR-SAT) Pr(C Im(E)) = Pr(e-XOR-SAT)
4

fiPhase Transition Random Quantified XOR-Formulas

holds, hand, inequality
Pr((a,e)-QXOR-SAT) Pr(Im(E) = {0, 1}L )
holds. Therefore, Prn,L (e-Max-rank) denotes probability random matrix
set L n Boolean matrices e units per row maximal rank, every
a, n L n, get following inequalities:
Prn,L (e-Max-rank) Pr(m,n,L) ((a,e)-QXOR-SAT) Prn,L (e-XOR-SAT).

(3)

natural question stage estimate probability random matrix
maximal rank. following provide experiments theoretical results
comparing behavior three properties, Maximal rank, QXOR-SAT XOR-SAT,
thus making precise behavior (a,e)-QXOR-SAT property according value
e.

3. Case e = 2
section, restrict attention case problems two existential
variables clause (and number variables allowed vary).
3.1 Experimental Results
order illustrate inequalities (3) compare empirically three properties,
discuss experiments performed. experiments, formulas closed.
1
2-XOR-SAT n=10k
(1,2)-QXOR-SAT m=n
(2,2)-QXOR-SAT m=n
(3,2)-QXOR-SAT m=n
(4,2)-QXOR-SAT m=n
2-Max-rank n=10k

0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

0

0.1

0.2

0.3

0.4
0.5
0.6
#clauses/#exvars

0.7

0.8

0.9

1

Figure 1: curves (a,2)-QXOR-SAT, = n = 10 000 varying.
cases, experiments conducted according scheme. Let
us describe detail Figure 1. One experiment consisted generating random (in
5

fiCreignou, Daude, & Egly

drawing uniformly independently) (1,2)-QXOR-formulas 10 000 existential variables 10 000 universal variables ratio number clauses/number existential
variables varying 0.1 1 steps 0.05 0.1. chosen values
ratio, sample 1000 formulas studied using algorithm described work
Creignou et al. (2001, chap. 6.4), thus deciding truth (or satisfiability) quantified
formulas. proportion true instances considered value ratio plotted Figure 1. done (a,2)-QXOR-SAT properties. Hence,
different curves independent other. 2-XOR-SAT experiment,
used selection procedure 10 000 existential variables. Again, Gaussian elimination together examination quantifier structure used determine
logical status (true false) every formula. Additionally, computed
whether matrix E full rank not. curve 2-Max-rank shows proportion
systems full rank corresponds 2-XOR-SAT curve figure.
close look Figure 1 reveals points (a,2)-QXOR-SAT curves
slightly (theoretical) lower bound given curve 2-Max-rank. reason
phenomenon independence satisfiability curves
noise induced finite sampling problems. chosen corresponding
problems exactly existential part (and universal part varies),
would got satisfiability curves curve 2-Max-rank.
experimental results shown Figure 1 suggest first two bounding properties, namely 2-Max-rank 2-XOR-SAT distinguishable, second that, = n,
(a,2)-QXOR-SAT property coincides asymptotically 2-Max-rank property independently 1, number universal variables per clause.
1
(1,2)-QXOR-SAT m=1, n=10k
2-XOR-SAT n=10k
2-Max-rank n=10k

0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

0

0.1

0.2

0.3

0.4
0.5
0.6
#clauses/#exvars

0.7

0.8

0.9

1

Figure 2: (1,2)-QXOR-SAT = 1 n = 10 000 compared 2-XOR-SAT
2-Max-rank.

6

fiPhase Transition Random Quantified XOR-Formulas

another scale m, instance constant, experimental results reported Figure 2 suggest (a,2)-QXOR-SAT property two properties 2-Max-rank 2-XOR-SAT.
following, validate conjectures suggested experiments
prove property (a,2)-QXOR-SAT coincides asymptotically 2-Max-rank
property soon tending infinity n, 2-Max-rank
property 2-XOR property fixed constant. particular, make
clear connection random (a,2)-QXOR-formulas random labelled graphs.
3.2 Bad Cycles (a,2)-QXOR-SAT Property
interested satisfiability quantified systems form
= (XY AX + EY = C),
E (respectively A) matrix chosen uniformly set Boolean L n (respectively L m) matrices exactly 2 (respectively a) units row, C random
column vector dimension L, 0 1 occur probability. satisfiability system strongly related existence cycles graphs. Indeed,
construct graph Ga (s) n vertices L weighted edges. existential variable
yi vertex Ga (s). equation yi yj = xi1 . . . xia , add
edge {yi , yj } Ga (s) label xi1 . . . xia . cycle given sequence
vertices (yi1 , . . . , yis ) 1 j 1, {yij , yij+1 } edge graph,
{yis , yi1 }. cycle said elementary vertices sequence
distinct. weight cycle sum modulo 2 labels edges.
Example 3.1 Let X = {x1 , x2 , x3 } let = {y1 , . . . , y7 }. formula XY (X, )
(X, ) conjunction following equations
y1 y2
y2 y3
y3 y4
y4 y5

=
=
=
=

x1
x3
x2 1
x3 1

y1 y7
y2 y6
y3 y5
y6 y7

=
=
=
=

x2
x2 1
x3
x1 1

represented graph Figure 3.
following, call cycle bad nonzero weight, good otherwise.
Example 3.2 graph associated formula described previous example,
good cycle, (y1 , y2 , y6 , y7 ), whose weight 0, bad one, (y3 , y4 , y5 ), whose
weight x2 . latter cycle, corresponding equations y3 y4 = x2 1, y3 y5 =
x3 , y4 y5 = x3 1. Adding three equations yields equation 0 = x2
cannot satisfied x2 X universally quantified.
systems containing existential variables, i.e., = 0, observed
Creignou Daude (2003) 2-XOR-formula satisfiable graph
G0 (s) bad cycle, :
Pr(2-XOR-SAT) = Pr(G0 (s) bad cycle).
Using similar arguments, get following proposition.
7

(4)

fiCreignou, Daude, & Egly

y1
x1
y2
x3 x2+ 1
y3

y6

x2 + 1
y4

x2

x1 + 1
x3

y7

x3 + 1
y5

Figure 3: graph Ga (s) Example 3.1 (addition performed mod2).
Proposition 3.3 system satisfiable Ga (s) contain
elementary bad cycle, i.e.,
Pr((a,2)-QXOR-SAT) = Pr(Ga (s) bad cycle).
Proof: Suppose elementary cycle nonzero weight Ga (s). Clearly,
cycle corresponds subsystem s, exists assignment X
assignment satisfy (see Example 3.2 illustration). Hence,
unsatisfiable.
Conversely, suppose (elementary) cycle nonzero weight Ga (s). Take
arbitrary truth assignment (universal) variables X apply Ga (s).
Since I(x) {0, 1} x X, weight edge reduced constant
{0, 1} addition modulo 2. Moreover, since cycle Ga (s) zero weight,
corresponding cycle reduced version, Ga (s), Ga (s) also zero weight.
graph Ga (s) corresponds system existential quantifiers only.
order obtain satisfying truth assignment existential variables, suffices
apply following procedure connected component Ga (s). Consider arbitrary
root vertex assign arbitrary truth value v it. obtain truth value
vertex Ga (s) performing depth-first search starting y. search,
edge (y , ) labelled truth value yet, set value
value . assignment obtained way satisfies equations
since Ga (s) contain cycle nonzero weight.
Remark: Observe
Pr(2-Max-rank) = Pr(Ga (s) cycle)
holds.
8

(5)

fiPhase Transition Random Quantified XOR-Formulas

3.3 Distribution Functions 2-XOR-SAT 2-Max-rank
section, give exact asymptotical value bounds obtained (3)
terms order parameter c, c n number clauses. use
well-known results random graph theory.
Let us recall consider classical probabilistic model clause/edge
chosen uniformly independently among


n
N=

2

e
possible ones. According Proposition 1.13 (Janson et al., 2000), choose L = c n
clauses, model asymptotically equivalent one clause drawn
independently probability p,


cn
p = n
1 + O(n1/2 )
2 2
holds. So, following, work random labelled graphs Ga (s) associated
quantified systems s, labelled edge probability:
c
.
p=
n


corresponding probability usually denoted p . However, simplicity
keep notation Pr.
light Proposition 3.3 (5), appears study
Pr(Ga (s) (bad) cycle).
asymptotic behavior number cycles random graphs first investigated Erdos Renyi (1960), made precise Janson (1987) Takacs (1988).
number converges distribution Poisson law parameter , limit
average number cycles n, number vertices, tends infinity.
result easily extended model labelled graphs. particular,
Pr(Ga (s) (bad) cycle) exp(),
limit average number (bad) cycles. challenging task
get simple expression lambda.
Let random variable counts number cycles. Let C set
possible cycles. cycle c, introduce random variable Xc
Xc (Ga (s)) = 1 holds, Ga (s) contains cycle c. average number
cycles
X
X
E(Y ) = E(
Xc ) =
E(Xc ).
cC

cC

Since every cycle c length l expectation E(Xc ) = pl since number cycles
l

n(n 1) . . . (n l + 1)

2l , get
length l

2l
X n(n 1) . . . (n l + 1) ml

2l pl
E(Y ) =

2l
l2

9

fiCreignou, Daude, & Egly

holds. Thus,
lim E(Y ) =

n+

X (2c)l
l2

2l

1
= ln(1 2c) c
2

also holds. (5), obtain every 0 < c <

1
2



1
lim Pr(n,cn) (2-Max-rank) = exp( ln(1 2c) + c)
n+
2
holds, finally
lim Pr(n,cn) (2-Max-rank) = H (c)

(6)

n+

established,
(
exp(c) (1 2c)1/2
H (c) =
0

0 c 21 ,
otherwise.

experimental results shown Figure 4 illustrate asymptotical behavior.
1


H (x) = ex 1 2x
2-Max-rank n=10k
2-Max-rank n=20k
2-Max-rank n=40k

0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

0.1

0.2

0.3

0.4
0.5
0.6
#clauses/#exvars

0.7

0.8

0.9

1

Figure 4: curves 2-Max-rank property.
According (4)
lim Pr(n,cn) (2-XOR-SAT) = exp(0 )

n+

holds, 0 denotes limit average number bad cycles. particular
case, weight clause either 0 1, means half cycles bad.
Thus,
X n(n 1) . . . (n l + 1) ml
1
c
0 = lim

2l1 pl = ln(1 2c) .
n+

2l
4
2
l2

10

fiPhase Transition Random Quantified XOR-Formulas

Therefore, every c 0, get
1
c
lim Pr(n,cn) (2-XOR-SAT) = exp( ln(1 2c) + ),
n+
4
2
finally
lim Pr(n,cn) (2-XOR-SAT) = H0 (c)

(7)

n+

established,
(
exp(c/2) (1 2c)1/4
H0 (c) =
0

0 c 12 ,
otherwise.

illustrated Figure 5.
1

H0 (x) = ex/2 (1 2x)0.25
2-XOR-SAT n=10k
2-XOR-SAT n=20k
2-XOR-SAT n=40k

0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

0.1

0.2

0.3

0.4
0.5
0.6
#clauses/#exvars

0.7

0.8

0.9

1

Figure 5: curves 2-XOR-SAT property.

3.4 Distribution Function (a,2)-QXOR-SAT
results obtained previous section, (6) (7), together inequalities (3)
sufficient conclude (a,2)-QXOR-SAT property coarse phase transition
scale L = c n distribution function functions H0
H described above. precisely get following theorem.
Theorem 3.4 integer 1 every c 0, let us consider (a,2)-QXOR((m,n),cn)formulas consisting conjunction c n XOR-clauses, clause contains
variables set universal variables, e variables set n existential
variables. Then, n tends infinity, (a,2)-QXOR-SAT property coarse phase
11

fiCreignou, Daude, & Egly

transition whose asymptotical distribution function expressed function depending
m. precisely, c 0, every 1 =
Pr(a,n,cn)((a,2)-QXOR-SAT) n+ H(c)
holds,
(
exp(c)(1 2c)1/2 (1 4c2 )1/8
H(c) =
0

0 c 21 ,
otherwise.

function n tending infinity n, then, every 1,
Pr(m,n,cn) ((a,2)-QXOR-SAT) n+ H (c)
holds,
(
exp(c) (1 2c)1/2
H (c) =
0

0 c 12 ,
otherwise.

Moreover, every fixed 1, exists distribution function Hm
Pr(m,n,cn) ((a,2)-QXOR-SAT) n+ Hm (c),
Hm satisfying
H < Hm < H0 ,

H0 (c) =

(

exp(c/2)(1 2c)1/4
0

0 c 21 ,
otherwise.

Proof: proof based Proposition 3.3 and, discussed previous section,
estimation number bad cycles labelled graphs associated random
formulas.
Let m,a limit average number bad cycles. give closed
expression m,a . Observe label edges graph associated
(a,2)-QXOR((m,n),cn)-formula formed constant,
0 1, variable-label made

universal variables. exactly variable-labels, numbered
1
. One decide whether cycle good bad according number
1 (even odd) number occurrences variable-label. Therefore
quite natural associate every cycle length l, sequence (N1 , . . . , N(m) )

numbers occurrences variable-label, parity = 0 1 number
occurrences constant 1. limit average number cycles whose parameter
(l, (N1 , . . . , N(m) ), ) fixed


cl 2l1
2l

l
N1 ,...,N






( )

l




.

Moreover, parameter (l, (N1 , . . . , N(m) ), ), one decide whether cycle

bad not.
12

fiPhase Transition Random Quantified XOR-Formulas

better readability, let us focus case = 1. particular case, label
edge form xi , = 0 1 1 m. one hand, cycles
odd length bad (for weight cycle least one coefficients
xi nonzero). hand, two kinds cycles even length
bad. ones constant 1 appears odd number times, ones
one universal variables appears odd number times. Since, 1,



X
X
l
l
ml =
+
N1 , N2 , . . . , Nm
N1 , N2 , . . . , Nm
Ni 0(2)

Ni 1(2)

get
m,1

X (2c)2u+1
1 X (2c)2v
1 X (2c)2v
=
+
+

2(2u + 1) 2
(2(2v)) 2
(2(2v))
u1

v1

v1


l
Ni 1(2) N1 ,N2 ,...,Nm
.
ml

P

(8)

Standard combinatorial computations show that, even l, equation

P
l
m1
X 1 (m 2k)l
Ni 1(2) N1 ,N2 ,...,Nm
=1
m1
ml
2
ml
k
k=0

holds. Therefore, rewrite (8) obtain
m,1

X (2c)2u+1
X (2c)2v
X (2c)2v
=
+
+

2(2u + 1)
2(2(2v))
2(2(2v))
u1

v1

1

v1

m1
X
k=0

!

m1
(m 2k)l
.
m1
2
ml
k

First, observe m,1 function c, thus deduce last part theorem:
lim Pr(m,n,cn) ((1,2)-QXOR-SAT) = exp(m,1 ) = Hm (c).

n+

Second, expression m,1 using following inequality
1

m1
X
k=0


m1
(m 2k)l
4
m1
1 ,
k
2
ml


get
lim (m,1 ) =

m+

X (2c)l
l2

2l

1
= ln(1 2c) c
2

holds, proves second statement theorem.
addition, = = 1, get equation
1,1 =

X (2c)2v
X (2c)2u+1
1
1
+
= ln(1 2c) + ln(1 4c2 ) c.
2(2u + 1)
2(2(2v))
2
8
u1

v1

Thus, established

13

fiCreignou, Daude, & Egly

lim Pr(1,n,cn) ((1,2)-QXOR-SAT) = exp(1,1 ) = H(c),

n+



(
exp(c)(1 2c)1/2 (1 4c2 )1/8
H(c) =
0

0 c 12 ,
otherwise.

result illustrated Figure 6, Figure 7 shows comparative behavior
three distribution functions H0 , H H .
1


H(x) = ex 1 2x (1 4x2 )1/8
(1,2)-QXOR-SAT m=1, n=20k
(1,2)-QXOR-SAT m=1, n=40k

0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

0.1

0.2

0.3

0.4
0.5
0.6
#clauses/#exvars

0.7

0.8

0.9

1

Figure 6: curves (1,2)-QXOR-SAT property = 1.

4. Case e 3
observed experimental results shown Figure 8 that, contrary
observed previous section, three smooth lines connecting consecutive points corresponding transition three properties 3-Max-rank,
(a,3)-QXOR-SAT 3-XOR-SAT difficult distinguish. Moreover, n increases
(see Figure 9), curves straighten come closer one other, showing thus strong
empirical evidence transitions three properties coincide asymptotically,
sharp phase transition critical value c3 0.918 (which critical ratio
3-XOR-SAT, see Dubois & Mandler, 2002). show that, e 3, introduction
universal variables XOR-formulas influence sharp transition.
Theorem 4.1 every e 3 integer a, (a,e)-QXOR-SAT property
sharp threshold coincides one e-XOR-SAT property.
14

fiPhase Transition Random Quantified XOR-Formulas

1


H(x) = ex 1 2x (1 4x2 )1/8
H0 (x) = ex/2 (1 2x)0.25
H (x) = ex 1 2x

0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

0.1

0.2

0.3

0.4
0.5
0.6
#clauses/#exvars

0.7

0.8

0.9

1

Figure 7: distribution functions H0 , H H .
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3

#clauses/#exvars = 0.918
3-XOR-SAT n=1k
3-Max-rank n=1k
(1,3)-QXOR-SAT m=n

0.2
0.1
0
0.8

0.85

0.9
#clauses/#exvars

0.95

1

Figure 8: curves 3-XOR-SAT, 3-Max-rank (a,3)-QXOR-SAT n=1000.
Proof: Let us recall
Prn,L (e-XOR-SAT) = Pr(Y (EY = C) consistent)
= Pr(C Im(E))
X
=
Pr(C V Im(E) = V ),
V {0,1}L

15

fiCreignou, Daude, & Egly

1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
0.8

#clauses/#exvars = 0.918
3-XOR-SAT n=2k
3-Max-rank n=2k
(1,3)-QXOR-SAT m=n

0.85

0.9
#clauses/#exvars

0.95

1

Figure 9: curves 3-XOR-SAT, 3-Max-rank (a,3)-QXOR-SAT n=2000.
since E C chosen independently. Therefore, P(r) denotes probability
random matrix set L n Boolean matrices e units per row rank r,

L
X
1
2rL P(r) P(L) + (P(L1) + . . . P(0) ).
Prn,L (e-XOR-SAT) =
2
r=0

observe P(0) + . . . + P(L) = 1, thus (P(L1) + . . . P(0) ) = 1 P(L) , hence
get
1 + P(L)
.
Prn,L (e-XOR-SAT)
2
Therefore, according (3),
2 Prn,L (e-XOR-SAT) 1 Prn,L ((a,e)-QXOR-SAT) Prn,L (e-XOR-SAT).
Since know property e-XOR-SAT exhibits sharp threshold L (n)
(Creignou & Daude, 2003), shows (a,e)-QXOR-SAT also does. holds
property e-Max-rank (since Prn,L (e-Max-rank) = P(L) ). particular, e = 3,
shown (a,e)-QXOR-SAT well 3-Max-rank sharp threshold critical
value c3 0.918, critical ratio 3-XOR-SAT (Dubois & Mandler, 2002).

5. Conclusion
(experimentally theoretically) analyzed phase transition quantified
problems (a,e)-QXOR-SAT. analysis conducted level sophistication one made e-XOR-SAT problem, thus showing model proposed

16

fiPhase Transition Random Quantified XOR-Formulas

Chen Interian (2005) mathematically tangible provides good parameters
order perform mathematical analysis phase transition quantified problems.
one hand, observed QSAT (Gent & Walsh, 1999; Chen & Interian, 2005),
proved nature transition influenced introduction
universal variables. hand, contrast QSAT, proved
location phase transitionthe critical ratiois two properties
XOR-SAT QXOR-SAT, difference behavior two properties
occurs level distribution function.

Acknowledgments
work supported EGIDE 10632SE OAD Amadee 2/2006.

References
Chen, H., & Interian, Y. (2005). model generating random quantified boolean formulas.
Proceedings 19th International Joint Conference Artificial Intelligence
(IJCAI2005), pp. 6671.
Cocco, S., Dubois, O., Mandler, J., & Monasson, R. (2003). Rigorous decimation-based
construction ground pure states spin glass models random lattices. Physical
Review Letters, 90, 472051472054.
Creignou, N., & Daude, H. (2003). Coarse sharp thresholds random k-XOR-CNF. Informatique theorique et applications/Theoretical Informatics Applications, 37 (2),
127147.
Creignou, N., Daude, H., & Dubois, O. (2003). Approximating satisfiability threshold
random k-XOR-CNF formulas. Combinatorics, Probability Computing, 12 (2),
113126.
Creignou, N., Khanna, S., & Sudan, M. (2001). Complexity classifications Boolean constraint satisfaction problems. SIAM Monographs Discrete Mathematics Applications. SIAM, Philadelphia, PA, USA.
Dubois, O., Boufkhad, Y., & Mandler, J. (2000). Typical random 3-SAT formulae
satisfiability threshold. Proceedings 11th ACM-SIAM Symposium Discrete
Algorithms (SODA2000), pp. 124126.
Dubois, O., & Mandler, J. (2002). 3-XOR-SAT threshold. Proceedings 43th
Annual IEEE Symposium Foundations Computer Science (FOCS 2002), pp.
769778.
Dubois, O., Monasson, R., Selman, B., & Zecchina, R. (2001). Editorial. Theoretical Computer Science, 265 (12).
Erdos, P., & Renyi, A. (1960). evolution random graphs. Publ. Math. Inst.
Hungar. Acad. Sci., Vol. 7, pp. 1761.
Franz, S., Leone, M., Ricci-Tersenghi, F., & Zecchina, R. (2001). Exact solutions diluted
spin glasses optimization problems. Physical Review Letters, 87, 127209127212.

17

fiCreignou, Daude, & Egly

Gent, I., & Walsh, T. (1999). Beyond NP: QSAT phase transition. Proceedings
16th National Conference Artificial Intelligence (AAAI99), pp. 648653.
Janson, S. (1987). Poisson convergence Poisson processes applications random
graphs. Stochastic Processes Applications, 26 (1), 130.
Janson, S., Luczak, T., & Rucinski, A. (2000). Random graphs. John Wiley sons.
Takacs, L. (1988). limit distribution number cycles random graph.
Journal Applied Probability, 25, 359376.

18

fiJournal Artificial Intelligence Research 29 (2007) 269-307

Submitted 8/06; published 7/07

Semantic Matchmaking Non-Monotonic Reasoning:
Description Logic Approach
Tommaso Di Noia
Eugenio Di Sciascio

t.dinoia@poliba.it
disciascio@poliba.it

SisInfLab - Politecnico di Bari, Bari, Italy

Francesco M. Donini

donini@unitus.it

Universita della Tuscia, Viterbo, Italy

Abstract
Matchmaking arises supply demand meet electronic marketplace,
agents search web service perform task, even recruiting agencies
match curricula job proles. open environments, objective matchmaking process discover best available oers given request.
address problem matchmaking knowledge representation perspective,
formalization based Description Logics. devise Concept Abduction Concept Contraction non-monotonic inferences Description Logics suitable modeling
matchmaking logical framework, prove related complexity results. also
present reasonable algorithms semantic matchmaking based devised inferences,
prove obey commonsense properties.
Finally, report implementation proposed matchmaking framework,
used mediator e-marketplaces semantic web services
discovery.

1. Introduction
promise Semantic Web initiative revolutionize way information coded,
stored, searched Internet (Berners-Lee, Hendler, & Lassila, 2001). basic
idea structure information aid markup languages, based XML
language, RDF RDFS1 , OWL2 . languages conceived
representation machine-understandable, unambiguous, description web
content creation domain ontologies, aim increasing openness
interoperability web environment.
Widespread availability resources services enablesamong advantages
interaction number potential counterparts. bottleneck dicult
nding matches, possibly best ones, parties.
need matchmaking process arises supply demand meet
marketplace, web services able perform task discovered, also
recruiting agencies match curricula job proles dating agency propose
partners customer agency. Requests oers may hence generic demands
supplies, web services, information, tangible intangible goods, matchmaking
process nd request appropriate response. paper concentrate
1. http://www.w3.org/RDF/
2. http://www.w3.org/TR/owl-features/
c
2007
AI Access Foundation. rights reserved.

fiDi Noia, Di Sciascio & Donini

automated matchmaking, basically oriented electronic marketplaces service discovery, although principles algorithms denitely general enough cover also
scenarios. assume, reasonable, requests oers endowed
kind description. Based descriptions target matching process
nding, given request, best matches available oers set, also, given
oer, determine best matching requests peer-to-peer fashion. may hence think
electronic mediator actor actively tries carry matchmaking process.
Obviously descriptions might provided using unstructured text, case
automated mediator revert adopting either basic string matching techniques
sophisticated Information Retrieval techniques.
Semantic Web paradigm calls descriptions provided structured form based ontologies, assume follows requests oers
given reference common ontology. noticed even requests
oers described heterogeneous languages, using dierent ontologies modelling
domain, schema/data integration techniques may employed make
comparable, proposed e.g., Madhavan, Bernstein, Rahm (2001), Shvaiko
Euzenat (2005); reformulated comparable way, one still left
basic matchmaking problems: given request, compatible oers?
several compatible oers, which, why, promising ones?
Matchmaking widely studied several proposals made past;
report Section 2. Recently, growing eort aimed
formalization Description Logics (DLs) (Baader, Calvanese, Mc Guinness, Nardi, &
Patel-Schneider, 2003) matchmaking process (e.g., Di Sciascio, Donini, Mongiello, &
Piscitelli, 2001; Trastour, Bartolini, & Priest, 2002; Sycara, Wido, Klusch, & Lu, 2002; Di
Noia, Di Sciascio, Donini, & Mongiello, 2003b; Li & Horrocks, 2003; Di Noia, Di Sciascio,
Donini, & Mongiello, 2003c, 2003a, among others). DLs, fact, allow model structured
descriptions requests oers concepts, usually sharing common ontology. Furthermore DLs allow open-world assumption. Incomplete information admitted,
absence information distinguished negative information. provide
little insight DLs Section 3.
Usually, DL-based approaches exploit standard reasoning services DL system
subsumption (un)satisabilityto match potential partners electronic transaction. brief, supply described concept Sup demand concept Dem,
unsatisability conjunction Sup Dem (noted Sup Dem) identies incompatible proposals, satisability identies potential partnersthat still agree
underspecied constraintsand subsumption Sup Dem (noted Sup Dem)
means requirements Dem completely fullled Sup.
Classication compatible incompatible matches useless presence
several compatible supplies; way rank promising ones identied; also
explanation motivation rank could appreciated. hand,
lack compatible matches one may accept turn incompatible matches
could still interesting, revising original requirements presented
request, far one could easily identify them.
words method needed provide logic-based score compatible
incompatible matches eventually provide partial/full ordering, allowing user
270

fiSemantic Matchmaking Non-Monotonic Reasoning: Description Logic Approach

automated agent choose promising counteroers. Furthermore
possible, given score, provide logical explanations resulting score, thus allowing
understand rank result ease interaction rene/revise request.
Although process quite simple human logic-based fully
automated framework. believe need dene non-monotonic reasoning services
DLs setting, deal approximation ranking, paper propose
use Concept Abduction (Di Noia et al., 2003a) Concept Contraction (Colucci,
Di Noia, Di Sciascio, Donini, & Mongiello, 2003), services amenable answer
highlighted issues satisfactory way. Contributions paper include:
logical framework express requests oers terms concept descriptions,
properties hold matchmaking facilitator;
Concept Abduction logical basis ranking compatible counteroers given
oer provide logical explanations ranking result;
Concept Contraction logical basis ranking incompatible matches, aimed
discovering promising near misses, provide logical explanations
ranking result;
algorithms implementing formalized inferences matchmaking purposes
complexity results class matchmaking problems;
description system implementing semantic matchmaking services, experimental evaluation.
remaining paper structured follows: next Section reports background
work subject. (Section 3) briey revise Description Logics basics. make
paper self-contained recall (Section 4) logic-based framework matchmaking,
pointing properties matchmaking algorithms systems guarantee.
Sections 5 6 present Concept Abduction Concept Contraction, two inference
services devised compute semantic matchmaking, present suitable denitions
problem along complexity results. Section 7 describe
matchmaker, present (Section 7.1) evaluation results computed system
compared human users behavior, standard full text retrieval approach.
Conclusions close paper.

2. Related Work Matchmaking
Matchmaking investigated recent years number perspectives
dierent purposes, renovated interest information overload kept growing
Web widespreading use. try summarize relevant related work.
Vague query answering, proposed Motro (1988), initial eort overcome limitations relational databases, using weights attributed several search variables.
recent approaches along lines aim extending SQL preference clauses,
order softly matchmake data structured databases (Kieling, 2002). Finin, Fritzson,
McKay, McEntire (1994) proposed KQML agent communication language oriented matchmaking purposes. Kuokka Harada (1996) investigated matchmaking
271

fiDi Noia, Di Sciascio & Donini

process allowed potential producers/consumers provide descriptions
products/needs, either directly agents mediation, later unied engine identifying promising matches. Two engines developed, SHADE system,
used KQML, description language KIF, matchmaking anyway
relying logical reasoning, COINS, adopted classical unstructured-text information retrieval techniques, namely SMART IR system. Similar methods later
re-considered GRAPPA system (Veit, Muller, Schneider, & Fiehn, 2001). Classiedads matchmaking, syntactic level, proposed Raman, Livny, Solomon (1998)
matchmake semi-structured descriptions advertising computational resources fashion
anticipating Grid resources brokering. Matchmaking used SIMS (Arens, Knoblock,
& Shen, 1996) dynamically integrate queries; approach used KQML, LOOM
description language. LOOM also used subsumption matching addressed
Gil Ramachandran (2001). InfoSleuth (Jacobs & Shea, 1995), system discovery
integration information, included agent matchmaker, adopted KIF
deductive database language LDL++. Constraint-based approaches matchmaking
proposed implemented several systems, e.g., PersonaLogic3 , Kasbah4
systems Maes, Guttman, Moukas (1999), Karacapilidis Moraitis (2001), Wang,
Liao, Liao (2002), Strobel Stolze (2002).
Matchmaking satisability concept conjunction DLs rst proposed
venue Gonzales-Castillo, Trastour, Bartolini (2001) Di Sciascio et al.
(2001), precisely dened Trastour et al. (2002). Sycara, Paolucci, Van Velsen,
Giampapa (2003) introduced specic language agent advertisement framework
Retsina Multiagent infrastructure. matchmaking engine developed (Sycara
et al., 2002; Paolucci, Kawamura, Payne, & Sycara, 2002), carries process
possible levels. levels exploit classical text-retrieval techniques semantic
match using -subsumption. Nevertheless, standard features semantic-based system,
satisability check unavailable. noteworthy approach, notion
plug-in match introduced, overcome way limitations matching approach based exact matches. approach Paolucci et al. (2002) later extended
Li Horrocks (2003), two new levels matching classication introduced.
similar classication proposedin venueby Di Noia et al. (2003c), along
properties matchmaker DL-based framework, algorithms
classify semantically rank matches within classes. Benatallah, Hacid, Rey, Toumani
(2003) proposed Dierence Operator DLs semantic matchmaking. approach
uses Concept Dierence, followed covering operation optimized using hypergraph techniques, framework web services discovery. briey comment relationship
Concept Dierence Concept Abduction end Section 5. initial DLbased approach, adopting penalty functions ranking, proposed Cal, Calvanese,
Colucci, Di Noia, Donini (2004), framework dating systems. extended
matchmaking approach, negotiable strict constraints DL framework
proposed Colucci, Di Noia, Di Sciascio, Donini, Mongiello (2005), using Concept Contraction Concept Abduction. Matchmaking DLs locally-closed world
3. http://www.PersonaLogic.com
4. http://www.kasbah.com

272

fiSemantic Matchmaking Non-Monotonic Reasoning: Description Logic Approach

assumption applying autoepistemic DLs proposed Grimm, Motik, Preist
(2006).
need work someway approximation ranking DL-based approaches
matchmaking also recently led adopting fuzzy-DLs, Smart (Agarwal &
Lamparter, 2005) hybrid approaches, OWLS-MX matchmaker (Klusch, Fries,
Khalid, & Sycara, 2005). approaches, anyway, relaxing logical constraints,
allow explanation automated revision service.
Finally, pointed matching DLs, widely treated Baader,
Kusters, Borgida, Mc Guinness (1999) relation matchmaking. fact,
work expressions denoting concepts considered, variables expressions.
match substitution variables expressions makes concept expression
equivalent another. Also general setting concept rewriting DLs
direct relation matchmakingsee discussion Remark 1.

3. Description Logics Basics
Section summarize basic notions denitions Description Logics
(DLs), Classic, knowledge representation system application inspired
by. provide hereafter brief guided-tour DLs main characteristics, interested
reader refer comprehensive handbook Baader et al. (2003).
3.1 Description Logics
Description Logicsa.k.a. Terminological Logicsare family logic formalisms Knowledge Representation. DLs endowed syntax, semantics, usually
model-theoretic. basic syntax elements DLs are:
concept names, e.g., Computer, CPU, Device, Software,
role names, like hasSoftware, hasDevice
individuals, used special named elements belonging concepts.
Intuitively, concepts stand sets objects, roles link objects dierent concepts,
role hasSoftware links computers software. using individuals
formalization, hence skip parts regarding individuals.
Formally, semantic interpretation pair = (, ), consists domain
interpretation function , maps every concept subset , every
role subset .
Basic elements combined using constructors form concept role expressions,
DL distinguished set constructors. Every DL allows one form
conjunction concepts, usually denoted ; DL include also disjunction
complement close concept expressions boolean operations.
Roles combined concepts using
existential role quantication:
e.g., Computer hasSoftware.WordProcessor
describes set computers whose software include word processor,
273

fiDi Noia, Di Sciascio & Donini

universal role quantication
e.g., Server hasCPU.Intel
describes servers Intel processors board.
constructs may involve counting,
number restrictions:
e.g., Computer ( 1 hasCPU)
expresses computers one CPU,
e.g., Computer ( 4 hasCPU)
describes computers equipped least four CPUs.
Many constructs dened, increasing expressive power DL,
n-ary relations (Calvanese, De Giacomo, & Lenzerini, 1998).
follows, call atomic concepts union concept names, negated concept
names, unqualied number restrictions. dene length concept C number
atomic concepts appearing C. denote length C |C|. Observe
consider zero length. dene Quantication Nesting (QN)
concept following positive integer: QN atomic concept 0, QN
universal role quantication R.F 1 plus QN F , QN conjunction
C1 C2 maximum QNs conjoined concepts C1 C2 .
Expressions given semantics dening interpretation function
construct. example, concept conjunction interpreted set intersection: (C D)I =
C DI , also boolean connectives , present, given usual
set-theoretic interpretation union complement. interpretation constructs
involving quantication roles needs make domain elements explicit: example,
(R.C)I = {d1 | d2 : (d1 , d2 ) RI d2 C }
3.2 TBoxes
Concept expressions used axiomsthat either inclusions (symbol: ),
denitions (symbol: )which impose restrictions possible interpretations according
knowledge elicited given domain. example, could impose monitors
divided CRT LCD using two inclusions: Monitor LCDMonitor
CRTMonitor CRTMonitor LCDMonitor. Or, computers domestic use
one operating system HomePC ( 1 hasOS). Denitions useful give
meaningful name particular combinations, Server Computer ( 2 hasCPU).
Historically, sets axioms called TBox (Terminological Box).
several possible types TBoxes. General TBoxes made General Concept Inclusions
(GCI) form C D, C Dem concept DL.
general TBoxes, distinction inclusions denitions disappears, since
denition C expressed two GCIs C D, C. contrary,
simple TBoxesalso called schemas Calvanese (1996), Buchheit, Donini, Nutt,
Schaerf (1998)only concept name appear left-hand side (l.h.s.)
axiom, concept name appear l.h.s. one axiom. Schemas
274

fiSemantic Matchmaking Non-Monotonic Reasoning: Description Logic Approach

cyclic acyclic, cyclicity refers dependency graph GT concept names,
dened follows: every concept name node GT , arc concept
name concept name B appears l.h.s. axiom, B appears (at
level) concept right-hand side. acyclic GT is, cyclic otherwise.
call acyclic schema simple TBox (Baader et al., 2003, Ch.2). depth simple
TBox length longest path GT . simple TBoxes, unfolding
dened following process (see Appendix denition): every denition
C, replace C every concept; every inclusion C, replace C
every concept. Clearly, process trasforms every concept equivalent one,
TBox forgotten. However, TBoxes, unfolding yield concepts
exponential size w.r.t. initial concepts. exponential blow-up
happen, call TBox bushy deep (Nebel, 1990).
semantics axioms based set containment equality: interpretation
satises inclusion C C DI , satises denition C C = DI .
model TBox interpretation satisfying axioms .
Observe make distinction equivalence (used axioms) equality
= symbols. use equality instantiate generic concept symbols concepts
stand for, e.g., write ... C = R.B... mean concept
symbol C stands concept expression R.B text.
3.3 Reasoning Services
DL-based systems usually provide two basic reasoning services:
1. Concept Satisability: given TBox concept C, exist least one
model assigning non-empty extension C? abbreviate satisability
concept C w.r.t. TBox C .
2. Subsumption: given TBox two concepts C D, C always contained
every model Iof ? abbreviate subsumption C w.r.t.
C D.
Since C satisable C subsumed , complexity lower bounds satisability
carry (for complement class) subsumption, upper bounds subsumption
carry satisability. hand, since C subsumed C
unsatisable, subsumption reducible satisability DLs admitting general concept
negation, DLs outside languageas DLs
next Section.
3.4 System Classic
system Classic (Borgida, Brachman, McGuinness, & A. Resnick, 1989; Borgida &
Patel-Schneider, 1994) originally developed general Knowledge Representation
system, successfully applied conguration (Wright, Weixelbaum, Vesonder,
Brown, Palmer, Berman, & Moore, 1993) program repositories management (Devambu,
Brachman, Selfridge, & Ballard, 1991).
language designed expressive possible still admitting
polynomial-time inferences bushy deep TBoxes. provides intersection
275

fiDi Noia, Di Sciascio & Donini

name
top
bottom
intersection
universal
quantication
number
restrictions

concrete syntax
TOP
(and C D)

syntax


C

semantics



C DI

(all R C)

R.C

{d1 | d2 : (d1 , d2 ) RI d2 C }

(at-least n R)
(at-most n R)

( n R)
( n R)

{d1 | {d2 | (d1 , d2 ) RI } n}
{d1 | {d2 | (d1 , d2 ) RI } n}

Table 1: Syntax semantics constructs Classic
name
denition
inclusion
disjoint
group

system notation
(createConcept C false)
(createConcept C true)
(createConcept A1 C symbol)
...
(createConcept Ak C symbol)

syntax
AC
AC
disj(A1 , . . . ,Ak )

semantics
AI = C
AI C
= 1, . . . , k AIi C
j = + 1, . . . , k
AIi AIj =

Table 2: Syntax semantics TBox Classic assertions (symbol name denoting
group disjoint concepts)

concepts union, universal existential quantication roles, number
restrictions roles intersection roles, since combinations known
make reasoning np-hard (Donini, Lenzerini, Nardi, & Nutt, 1991; Donini, 2003).
simplicity, consider subset constructs, namely, conjunction, number
restrictions, universal role quantications, summarized Table 1. abbreviate
conjunction ( n R) ( n R) (= n R). omit constructs ONE-OF(), FILLS(,)
refer individuals, construct SAME-AS(,) equating llers functional roles.
subset Classic refer known ALN (Attributive Language unqualied
Number restrictions) (Donini, Lenzerini, Nardi, & Nutt, 1997b). number restrictions
present, resulting DL known AL (Schmidt-Schau & Smolka, 1991). ALN
provides minimal set constructs allow one represent concept taxonomy, disjoint
groups, role restrictions (AL), number restrictions (N ) represent restriction son
number llers role.
Regarding axioms TBox, Classic allows one state simple TBox assertions
form summarized Table 2, A, A1 , . . . ,Ak concept names. Axioms
TBox subject constraints every concept name appear
l.h.s. TBox, every concept name cannot appear l.h.s.
denition disjointness assertion.
Every Classic concept given normal form. consider normal form
constructs ALN used ontologies applications. Intuitively,
normal form pre-computes implications concept, includingpossiblyits unsatisability. normal form reached, commutativity operator ,
using well-known normalization rules, report Appendix make paper
276

fiSemantic Matchmaking Non-Monotonic Reasoning: Description Logic Approach

self-contained. normal form unsatisable concept simply . Every satisable
concept C divided three components: Cnames C Call . component Cnames
conjunction concept names A1 , . . . ,Ah . component C conjunction
number restrictions, two every role (the maximum at-least
minimum at-most role), including every conjunct C form R.,
number restriction ( 0 R) C . component Call conjoins concepts form
R.D, one role R, normal form. call form Conjunctive Normal FormCNF, analogy Propositional Logicand observe CNF
unique (also said canonical), commutativity conjunction.
Moreover, TBox Classic embedded concepts, expanding
denitions, adding right-hand-side concepts inclusions, adding negation
disjoint concept namessee Appendix details. instance, suppose
TBox contains:
1. denition Server Computer ( 2 hasCPU),
2. inclusion Computer ( 1 hasStorageDevice),
3. disjointness assertion disj(AMD, Intel).
Then, concept ServerhasCPU.Intel rewritten Computer( 2 hasCPU)
( 1 hasStorageDevice)hasCPU.(IntelAMD), equivalent former w.r.t.
models TBox. Observe concept name Computer kept rewriting,
since inclusion gives necessary condition ( 1 hasStorageDevice). latter
concept safely conjoined Computermaking inclusion unnecessarybut cannot replace since ( 1 hasStorageDevice) sucient condition Computer.
Instead, Computer ( 2 hasCPU) replaces Server since necessary sucient
condition it. disjoint assertion generates Intel AMD range hasCPU..
rewriting carried concepts, TBox safely ignored
computing subsumption (and satisability). general, unfolding may lead exponential blow-up TBox, making entire computation (unfolding+subsumption) take
exponential time (and space) size initial concepts TBox. Yet exponentialtime computation subsumption likely unavoidable, since even without rewriting,
taking TBox account makes subsumption np-hard (Nebel, 1990).
normal form concepts take TBox embedding account (see Appendix A.2). case, component Cnames Classic concept C contains concept
names Cnames+ negations concept names Cnames . following, denote
CNF concept C w.r.t. simple TBox CNF (C, ). Again, general, size
CNF (C, ) may exponential w.r.t. size C . However, xed,
CNF (C, ) polynomial-size w.r.t. size C i.e., exponential increase comes
TBox unfolding. fact, k maximum size unfolded concept name
(a constant xed), size CNF (C, ) k times size C.
use argument later paper, decouple complexity analysis reasoning
methods matchmaking complexity raised TBox.
ease presentation follows next Sections, adopt simple reference
ontology, pictured Figure 1, used throughout paper. keep representation within ALN , modeled memory quantities number restriction, e.g., 20GB
277

fiDi Noia, Di Sciascio & Donini



CRTmonitor
LCDmonitor




Monitor








=




DVDRecorder





FloppyDisk
StorageDevice





HardDisk

Linux
Solaris
Windows2000
WindowsXp




















OperatingSystem





Browser




Device

Software

WordProcessor


PDA
PC

Computer
=

Computer ( 1 hasStorageDevice) hasStorageDevice.StorageDevice
hasSoftware.Software ( 1 ram)
HomePC PC ( 1 hasSoftware)
(= 1 hasOS) ( 1 hasMonitor) hasMonitor.Monitor
Server Computer ( 2 hasCPU)
ram.( 512 mb) hasStorageDevice.( 20000 mb)
Figure 1: Reference Ontology used examples
( 20000 mb). reasoners specialized ALN , problem, since number n
never expanded n llers (Borgida & Patel-Schneider, 1994; Donini et al., 1997b).
expressive DLs, Concrete Domains (Lutz, 1999) employed represent
quantities.

4. Semantic Matchmaking Using Description Logics
Matchmaking widely used term variety frameworks, comprising severalquite
dierentapproaches. begin Section trying provide generic sound denition matchmaking.
Matchmaking information retrieval task whereby queries (a.k.a. demands) resources (a.k.a. supplies) expressed using semi-structured data
form advertisements, task results ordered (ranked) lists
resources best fullling query.
simple denition implies thatdierently classical unstructured-text Information
Retrieval systemssome structure advertisements expected matchmaking
278

fiSemantic Matchmaking Non-Monotonic Reasoning: Description Logic Approach

system, matchmaking consider xed database-oriented relational structure.
Furthermore, usually database systems provide answers queries include
relevance ranking, instead considered matchmaking process.
Semantic matchmaking matchmaking task whereby queries resources
advertisements expressed reference shared specication conceptualization knowledge domain hand, i.e., ontology.
on, concentrate semantic matchmaking marketplaces, adopting specic
terminology, ease presentation approach. Nevertheless approach applies
generic matchmaking semantically annotated resources.
note denitions Section apply every DL used
describe marketplace (supplies, demands, background knowledge). denote L
generic DL. suppose common ontology supplies demands established,
TBox L. match supply demand could evaluated
according .
First all, remark logic-based representation supplies demands calls
generally Open-world descriptions, is, absence characteristic description supply demand interpreted constraint absence. Instead,
considered characteristic could either rened later, left open
irrelevant user. Note generally open mean specic
characteristic might declared closed. However, closure made
piecewise, using known declarative tool devised Knowledge Representation nonmonotonic reasoning, Defaults DLs (Baader & Hollunder, 1992), Autoepistemic
DLs (Donini, Nardi, & Rosati, 1997a), Circumscription DLs (Bonatti, Lutz, & Wolter,
2006) etc.
analysis recent literature allows categorize semantic matchmaking process
supply Sup demand Dem w.r.t. TBox distinct classes:
exact match: Sup Dem, i.e., Sup Dem Dem Sup, amounts
perfect match, regardlessin semantic based environmentof syntactic dierences, i.e., Sup Dem equivalent concepts (Di Sciascio et al., 2001; GonzalesCastillo et al., 2001).
full match: Sup Dem, amounts demand completely fullled
available supply, i.e., Sup least features required Dem,
necessarily vice versa, matchmaking process symmetric (Di Noia et al.,
2003c); kind match also named subsume match Li Horrocks (2003).
plug-in match: Dem Sup; corresponds demand Dem sub-concept
supply Sup,i.e., Dem specic Sup (Sycara et al., 2002; Li & Horrocks,
2003).
potential match: DemSup , corresponds supply demand
something common conicting characteristics (Di Noia et al., 2003c).
relation also named intersection-satisable Li Horrocks (2003).
279

fiDi Noia, Di Sciascio & Donini

partial match: Dem Sup , amounts presence conict
demand available supply (Di Noia et al., 2003c). relation also
named disjoint Li Horrocks (2003)5 .
stress demands could classied way w.r.t. given supply,
suppliers turn look marketplace nd potential buyers. Hence,
rest paper use term oer denoted symbol Dto mean either supply
Sup demand Dem, term counteroer denoted Cto mean, respectively,
demand Dem supply Sup could match D.
classication still coarse one, relying directly known logical relations
formulae. fact, result matchmaking rank counteroers,
according criteriapossibly explicitso user trusting system would
know contact rst, case failure, next, on. ranking
process satisfy criteria Knowledge Representation approach suggests.
formulate ranking requirements referring properties penalty functions.
Definition 1 Given DL L, two concepts C, L, TBox L, penalty
function three-arguments function p(C, D, ), returns null positive integer.
use penalty functions rank counteroers C given demand (or supply) w.r.t.
TBox . Intuitively, two given counteroers C1 , C2 marketplace, p(C1 , D, ) <
p(C2 , D, ) issuer oer rank C1 better C2 deciding
contact rst. Clearly, 0-penalty ranked best, counteroers
penalties ranked breaking ties. rst property recall Non-symmetric
evaluation proposals.
Definition 2 penalty function p(, , ) non-symmetric exist concepts C,
TBox p(C, D, ) = p(D, C, ).
property evident constraints fullled C vice versa.
Hence, C among top-ranked counteroers list potential partners
D, necessarily appear top list potential partners C.
So, penalty function p(, , ) expected metric distance function.
Secondly, logic used give meaning descriptions supplies demands,
proposals meaning equally penalized, independently
syntactic descriptions.
Definition 3 penalty function p(, , ) syntax independent every triple concepts C1 , C2 , D, TBox , |= C1 C2 p(C1 , D, ) = p(C2 , D, ),
holds also second argument , i.e., p(D, C1 , ) = p(D, C2 , )
5. note preferring term partial match instead disjoint, stress match may
still recoverable, disjoint usually meant hopeless situation. Moreover, disjoint
intersection satisable refer set-theoretic semantics concepts Description Logics,
quite hidden far original problems matchmaking. word, technologyoriented problem-oriented. instance, one used Propositional Logic, Three-valued Logic
modeling matchmaking, terms would make sense.

280

fiSemantic Matchmaking Non-Monotonic Reasoning: Description Logic Approach

Clearly, logic admits normal form expressionsas CNF DNF propositional logic, normal form concepts DLs dened previous Sectionusing
normal form computation p(, , ) ensures syntax independence.
Penalties enjoy desirable properties w.r.t. subsumption. reasons explained below, divide penalty functions ranking potential matches
ranking partial (conicting) matches.
Definition 4 penalty function potential matches monotonic subsumption
whenever every issued oer D, every pair counteroers C1 C2 , TBox ,
C1 C2 potential matches w.r.t. , (C1 C2 ), p(C1 , D, )
p(C2 , D, )
Intuitively, denition could read as: C1 C2 C1 penalized
(and ranked) either same, better C2 . phrase, ranking potential
matches monotonic subsumption specic means better. dual property
could stated second argument: D1 D2 counteroer C less likely
fulll characteristics required D1 D2 . However, since scenario is: given
issuer proposal looking match marketplace, rank possible counteroers
C1 , C2 , . . . , best one worst, deal duality
rst second argument p(, , ).
turning partial matches, properties already conict supply demand, picture reverses. Now, adding another characteristic
unsatisfactory proposal may worsen ranking (when another characteristic violated) keep (when new characteristic conict). Note
ranking kept dierent ranking potential matches. all, accepting
discard one characteristics required much worse deciding
proposal try rst among potential ones.
Definition 5 penalty function partial matches antimonotonic subsumption
whenever every issued oer D, every pair counteroers C1 C2 , TBox ,
C1 C2 partial matches w.r.t. , (C1 C2 ), p(C1 , D, )
p(C2 , D, )
Intuitively, C1 C2 C1 penalized (and ranked) either same,
worse C2 . words, ranking partial matches antimonotonic
subsumption specic means worse. property hold also
second argument, since concept conjunction commutative.
need distinguish penalty function potential matches one
partial matches, put subscript former (as p ) subscript
latter (as q ).
Clearly, requirements general, leave ample room denition
penalty functions. subtle requirement would penalties change
irrelevant details added, e.g., second-hand computer requested demand
Dem, specication brand CPU, supply Sup penalized
another oer Sup hasCPU.Intel. However, instead delving irrelevance
logic-related issues directly penalties, borrow well-known logical
281

fiDi Noia, Di Sciascio & Donini

reasoning frameworks propositional knowledge representation. detour give us
sound declarative way dening penalties, dealing irrelevance byproduct,
generally bring well-studied non-standard reasoning techniques matchmaking.

5. Concept Abduction
Abduction (Peirce, 1955) well known form commonsense reasoning, usually aimed
nding explanation given symptoms manifestations. introduce Concept Abduction DLs, showing model potential matchmaking DL setting.
Following notation proposed Eiter Gottlob (1995), recall Propositional
Abduction Problem triple H, M, H (Hypotheses) (Manifestations)
sets literals, (Theory) set formulae. solution H, M, Explanation E H E consistent, E |= . adapt framework
DLs follows.
Definition 6 Let L DL, C, D, two concepts L, set axioms
L, C satisable . Concept Abduction Problem (CAP)
given L, C, D, , nding, possible, concept H L C H ,
C H D.
use P symbol generic CAP, denote SOL(P) set
solutions CAP P. Observe denition, limit inputs CAP
satisable concepts C D, since C unsatisable implies CAP solution
all, unsatisable leads counterintuitive results (e.g., C would solution
case). Propositional Abduction extends implication, Concept Abduction extends concept subsumption. dierently propositional abduction, make
distinction manifestations hypotheses, usual abduction
used diagnosis. fact, making hypotheses e.g., properties goods
e-marketplaces, point making distinction. uniformity implies
always trivial solution non-trivial CAP L, C, D, , stated
formally follows.
Proposition 1 Let L DL, let C, concepts L, L-TBox. CD
SOL(L, C, D, ).
Proof. C satisable , fullls requirements Def. 6, rst
one hypothesis second one C tautology.
hand, SOL(L, C, D, ) C denition.
simple interpretation property application domain, i.e., matchmaking,
hypothesize counteroer C exactly specications D,
counteroer trivially meets given specicationsif compatible anyway. However,
solutions CAP equivalent using Concept Abduction matchmaking.
make simple example, suppose already C D. Then, H1 = H2 =
(among others) solutions L, C, D, . Yet, solution H2 = tells issuer
C already meets Ds specications, solution H1 = least
282

fiSemantic Matchmaking Non-Monotonic Reasoning: Description Logic Approach

informative solution point view. Hence, want use abduction highlight
promising counteroers, minimal hypotheses must dened.
Definition 7 Let P =L, C, D, CAP. set SOL (P) subset SOL(P)
whose concepts maximal . set SOL (P) subset SOL(P) whose
concepts minimum length.
Clearly, maximal w.r.t. still minimality criterion, since means
unnecessary hypothesis assumed. proved two measures incomparable.
Proposition 2 exists CAP P two sets SOL (P) SOL (P)
incomparable.
Proof. sucient consider = A1 A2 A3 , C = A1 , = {B A2 A3 }.
logic even propositional. A2 A3 SOL (L, C, D, ), B SOL (L, C, D, ),
neither solution set.
proof highlights that, although -minimality could preferable conciseness,
heavily dependent . fact, every concept H SOL(P), sucient add
axiom H get -minimal solution A. hand, also -maximality
drawbacks: concept disjunction present L, single -maximal
solution P, equivalent disjunction solutions SOL(P)not
useful solution. Making analogy Abduction-based Diagnosis (Console, Dupre, &
Torasso, 1991), could say disjunction possible explanations
informative explanation itselfalthough maximal w.r.t. implication. note
nding -minimal solution np-hard TBox depth 1, simple reduction
Set Covering (Colucci, Di Noia, Di Sciascio, Donini, & Mongiello, 2004).
Remark 1 interesting analyze whether concept minimal-rewriting techniquesas
dened Baader, Kusters, Molitor (2000)could employed computing
minimal concept abduction, trying rewrite C D. answer denitely negative
minimal length abduction: length-minimal solution B proof Proposition 2
could obtained rewriting C = A1 A1 A2 A3 . fact, A1 B
equivalent rewriting former concept. Regarding -maximality answer
indirect. fact, present rewriting techniques keep subconcept xed
rewriting process. consider CAP = A1 , C = A2 , = {B A1 A2 }.
equivalent minimal rewriting C B, solution cannot
identied since B cannot separated concept Cthe original oneand concept
H solution CAP. open whether future extensions rewriting might
keep concept xed, cope problem.
third minimality criterion possible DLs admit CNF, L = ALN .
Definition 8 Let P =L, C, D, CAP L admits CNF, assume
concepts SOL(P) CNF. set SOL (P) subset SOL(P) whose concepts
minimal conjunctions, i.e., C SOL (P) sub-conjunction C (at level
nesting) SOL(P). call solutions irreducible.
283

fiDi Noia, Di Sciascio & Donini

turns -minimality includes -maximality -minimality.
Proposition 3 every CAP P L admits CNF, SOL (P) SOL (P)
included SOL (P).
Proof. contraposition, concept H -minimal another concept
H sub-conjunction Hwhich -minimal solution. |H | < |H|, hence H
length-minimal. -maximality: since every sub-conjunction concept
H CNF subsumes H, H -minimal -maximal either.
proof Proposition 2 modied show minimum-length abduced
concepts unique: sucient add another axiom B A2 A3 obtain
another minimum-length solution B . less obvious result also subsumptionmaximal solutions unique, least non-simple TBoxes: Let P = L, C, D,
= {A2 A3 A1 }, C = A3 , = A1 . A1 A2 -maximal
solutions.
5.1 Irreducible Solutions ALN -simple TBoxes
assume TBox CAP P = L, C, D, always simple one. Finding
irreducible solution easier nding -minimal -maximal solution, since
greedy approach used minimize set conjuncts solution. example,
starting C D, could delete one redundant conjunct time (at level
role quantication nesting) D, using |D| calls subsumption-check procedure.
However, algorithm would interesting theoretical purposes. Instead,
adapt structural subsumption algorithm (Borgida & Patel-Schneider, 1994) collects
concepts H conjoined C order C H subsumed D.
algorithm operates concepts CNF. following algorithm, abbreviate
fact concept appears conjunct concept C C (thus extending
meaning conjunctions concepts).
Algorithm ndIrred (P);
input: CAP P = L, C, D, , L =ALN , simple , C CNF w.r.t.
output: concept H SOL (P) (where H = means C D)
variables: concept H
begin
H := ;
0. C
return ;
1. every concept name
1.1
C
H := H A;
2. every concept ( n R)
2.1
concept ( R) C n
H := H ( n R);
3. every concept ( n R)
284

fiSemantic Matchmaking Non-Monotonic Reasoning: Description Logic Approach

concept ( R) C n
H := H ( n R);
4. every concept R.E
4.1
exists R.F C
4.1.1
H := H R.ndIrred (ALN , F, E, );
4.1.2
else H := H R.E;
/* H SOL(P), might reducible */
5. every concept Hi H
H without Hi SOL(P)
delete Hi H;
6. return H;
end.
3.1

Theorem 1 Given CAP P, ndIrred (P) returns concept H, H , H
irreducible solution P.
Proof. rst prove Step 5, computed concept H SOL(P), is,
C H C H hold. fact, observe CNF (D, ) H, since
conjuncts H come conjunct CNF (D, ). Hence, H since CNF (D, )
equivalent models . Adding C sides subsumption yields
C C H, since assume C , also C H . proves
rst condition H SOL(P). Regarding condition C H D, suppose
hold: then, least one conjunct CNF (D, ) appear CNF (C H, ).
possible construction, since H contains every conjunct CNF (D, )
CNF (C, ). Therefore, conclude H SOL(P). proved
H computed Step 5 solution P, note Step 5 deletes enough
conjuncts make H irreducible solution.
rst part algorithm (before Step 5) easily follows well-known structural subsumption algorithms (Borgida & Patel-Schneider, 1994). Step 5 applies greedy approach, hence
computed solution, although irreducible, might minimal.
explain need reducibility check Step 5 help following
example.
Example 1 Let = {A1 A2 , A3 A4 }, let C = A3 , = A1 A4 . L
propositional part AL. normal form C C = A3 A4 , = A1 A2 A4 .
Step 5 algorithm computes H = A1 A2 , must still reduced
A1 . worth noticing H already subsumption-maximal since H A1 . However,
-minimality syntactic property, requires removal redundant conjuncts.
complexity, aim proving nding irreducible solution
complex subsumption ALN . polynomial algorithm (w.r.t. sizes C,
) cannot expected anyway, since subsumption AL (the sublanguage ALN
without Number Restrictions) simple conp-hard (Nebel, 1990; Calvanese, 1996).
However, Nebel (1990) argues unfolding TBox exponential depth
285

fiDi Noia, Di Sciascio & Donini

hierarchy ; depth grows O(log |T |) size increasesa bushy
deep TBoxthen unfolding polynomial, algorithm.
generally, suppose xed: unrealistic hypothesis
marketplace application, since represents ontology domain,
expect vary supplies demands enter exit marketplace. case,
analyze complexity ndIrred considering C size input
problem.
Theorem 2 Let P = L, C, D, CAP, L =ALN , simple TBox.
nding irreducible solution P problem solvable time polynomial size
C D.
note problem exponential-size unfolding might mitigated Lazy
Unfolding (Horrocks & Tobies, 2000). Using technique, concept names TBox
unfolded needed.
5.2 Abduction-Based Ranking Potential Matches
dene penalty function p potential matches based following intuition:
ranking potential matches depend many hypotheses made
counteroers order transform full matches.
Definition 9 Given simple TBox ALN , dene penalty function potential match counteroer C given oer D, C concepts
ALN , follows:
.
p (C, D, ) = |ndIrred (ALN , CNF (C, ), CNF (D, ), )|

(1)

Note that, computing p , concept H actually computed ndIrred
intermediate step. makes easy devise explanation facility, actual
obtained ranking immediately enriched logical explanation; thus improving
users trust interaction matchmaking system.
prove p accordance properties higlighted previous Section.
Since computation Formula (1) starts putting concepts C, normal form,
recall normal form C summarized Cnames C Call , similarly
D. Without ambiguity, use three components also sets conjoined concepts.
Theorem 3 penalty function p (i) non-symmetric, (ii) syntax independent,
(iii) monotonic subsumption.
Proof.
(i) Non-symmetricity easily proved providing example: p (A, , ) =
p ( , A, ). fact, ndIrred (ALN , A, , ) nds H1 = solution (A without
hypothesis) ndIrred (ALN , , A, ) nds H2 = A. Recalling | | = 0,
|A| = 1, get rst claim.
(ii) Syntax independence follows fact normal forms used Formula (1),
already said normal forms unique commutativity conjunction.
286

fiSemantic Matchmaking Non-Monotonic Reasoning: Description Logic Approach

(iii) Monotonicity subsumption proved analyzing conditions subsumption ALN . concept C subsumed concept C whenever conditions
hold. condition, analyze changes behavior ndIrred , proving
provided solution H adds conjuncts. Recall monotonicity subsumption applied potential matches, hence assume C C
consistent D. Since ndIrred recursive, proof also induction quantication nesting (QN) C . C QN equal 0, C conjunction
atomic conceptsnames, negated names, number restrictions. conditions
subsumption following:
rst condition Cnames+ C names+ . Hence, Step 1.1 ndIrred ,
number concept names added H respect names added H
decrease, |H | |H| considering names. Regarding negated names,
observe contribute solution ndIrred , since come
disjointness axiom positive name (that contributes).
second condition every number restriction C , either
number restriction appears C , strengthened (an at-least increases, atmost decreases) C . Hence, number restrictions added Steps 2.1 3.1 H
either many added H, less. Again, also considering number
restrictions |H | |H|.
two cases prove basis induction (C QN equal 0). Suppose
claim holds concepts C QN n less, let C QN n + 1. Clearly,
case C least one universal role quanticationcall R.F . condition
subsumption C C following:
Either every universal role quantication R.F C role R, must
hold F F , universal role quantication R C. former
case, observe ndIrred recursively called6 Step 4.1.1 arguments F , E,
F , E; call , respectively, solutions returned ndIrred . Observe
QN F n less, hence inductive hypothesis |I | |I|. Since Step 4.1.1
adds R.I R.I H H, |H | |H|. instead universal
role quantication R C, Step 4.1.2 adds R.E H. also C contain
role quantication R, Step 4.1.2 adds R.E also H , H cannot
longer H case. role quantication R.F C , Step 4.1.1
makes recursive call arguments F , E. case, solution returned
length less equal |E|, hence length H cannot longer
length H also case.
summary, C C case length H increases respect
length H. proves monotonicity subsumption p .
Intuitively, could say monotonicity subsumption potential matches means
specic C is, lower penalty, better ranking w.r.t. D.
6. findIrred called once, concepts CNF one universal role quantication
role R.

287

fiDi Noia, Di Sciascio & Donini

preciselybut less intuitivelywe say rank C w.r.t. cannot worsen
C made specic. Hence, given oer D, TBox , sequence increasingly specic counteroers C1 C2 C3 assigned sequence
non-increasing penalties p (C1 , D, ) p (C2 , D, ) p (C3 , D, ) . . . prove
sequences well-founded, bottom element zero, reached case subsumption.
Proposition 4 p (C, D, ) = 0 C D.
Proof.
Recall Section 3.1 concepts length zero,
ndIrred returns C potential match (Step 0 ndIrred ).
Hence, p (C, D, ) = 0 concept whose length computed Formula (1)
. construction ndIrred , returned call
ndIrred (ALN , CNF (C, ), CNF (D, ), ) CNF (C, ) CNF (D, ),
holds (see Borgida & Patel-Schneider, 1994) C D.
Moreover, could also prove adding C details irrelevant leaves
penalty unaected, adding C details relevant lowers Cs penalty.
Note also Formula (1) take account normal form C, D,
forget itwe use empty TBoxwhen calling ndIrred . explain choice
aid example.
Example 2 Given = {A A1 A2 }, let = Demand two following
supplies: C1 = A2 , C2 = . Observe CNF (D, ) = A1 A2 , CNF (C1 , ) =
A2 , CNF (C2 , ) = . used following formula compute penalty
.
p (C, D, ) = |ndIrred (ALN , C, D, )|

(2)

ran algorithm ndIrred (ALN , C1 , D, ) ndIrred (ALN , C2 , D, ),
Step 5 would get, respectively,
H1 = A1
H2 = A1 A2
Step 5 ndIrred would return H1 = H2 = A, hence C1 C2 would receive
penalty. However, argue C1 closer C2 is, contains characteristic (A2 ) implicitly required D, C2 not. instead call
ndIrred (ALN , CNF (C1 , ), CNF (D, ), )
ndIrred (ALN , CNF (C2 , ), CNF (D, ), ), get solutions H1 H2 aboveand
Step 5 delete conjunct, since = . Therefore, C1 gets penalty 2, C2
gets penalty 3, highlighting specied C1 w.r.t. C2 .
generally, say reducibility step (Step 5 ndIrred ) attens solution
specic conjuncts, leaving TBox implicit representation
characteristics, ones already present supply present. Therefore,
making empirical decision, consider TBox normal form C D,
exclude reductions Step 5 ndIrred .
288

fiSemantic Matchmaking Non-Monotonic Reasoning: Description Logic Approach

Remark 2 Although denition Concept Abduction could appear similar Concept
Dierence, so. note generically speaking, name Concept Abduction
appeals logic, Concept Dierence appeals algebra (although Dierence
multiple solutions L includes universal role quantication). precisely, recall
(Teege, 1994) dierence dened as: C = max {E L : (E D) C} provided
C D. specialized denition dierence (Brandt, Kusters, & Turhan, 2002)
refers DLs ALC ALE. dened as: C = min {E L : (E D)
(C D)}where C, E ALC, ALE, minimality w.r.t. preorder specic
normal form extends CNF ALC. TBox taken account.
Instead, solution CAP L, C, D, require C D,
C . general, C let H = C CAP P = L, C, D,
get solutions C H Dwhich obviously solutions P.
Hence C SOL(P), vice versa (see proof Proposition 2 example).
C comparison even possible, since C undened. However,
generic setting, e.g., e-commerce scenario, subsumption demand supply
quite uncommon; oers neither subsumes other.
greater generality, specic application matchmaking, Concept Abduction seems
suited Concept Dierence make basis penalty function.

6. Concept Contraction
C unsatisable , demander accepts retract Ds constraints,
partially matching supplies may reconsidered. However, logic-based approaches
matchmaking Trastour et al. (2002), Sycara et al. (2002), Li Horrocks (2003)
usually exclude case concept expressing demand inconsistent
concept expressing supply, assuming requirements strict ones. contrast,
believe inconsistent matches still useful, especially e-marketplaces.
fact, partial (a.k.a. disjoint) matches basis negotiation process, allowing
user specify negotiable requirementssome could bargained favor
other. negotiation process carried various ways adopting approaches
matchmaking based logic (e.g., Strobel & Stolze, 2002), also, shown
practice Colucci et al. (2005), using Belief Revision. fact, logical formalization
conicting matches, aimed nding still interesting inconsistent matches without
revert text-based hybrid approaches, obtained exploiting denitions
typical Belief Revision. accordance Gardenfors (1988) formalization, revision
knowledge base K new piece knowledge contraction operation,


KA
|= A, followed addition
results new knowledge base KA

KA usually modeled conjunction. call Concept Contraction adaptation
Belief Revision DLs.
Starting C unsatisable TBox , model Concept Contraction
how, retracting requirements C, may still obtain concept K (for Keep)
K satisable . Clearly, user interested he/she must negotiate
start transactiona concept G (for Give up) C G K.
289

fiDi Noia, Di Sciascio & Donini

instance, reference ontology Figure 1, user demands Dem
supplier oers Sup, Dem Sup described follows:
Dem = HomePC hasMonitor.LCDmonitor
Sup = HomePC hasMonitor.CRTmonitor
possible check Sup Dem unsatisable. partial match. Yet,
case, demander gives concept G = hasMonitor.LCDmonitor keeps
concept K = HomePC, K Sup satisable, hence K potentially matches Sup.
formally model Concept Contraction problem follows.
Definition 10 (Concept Contraction) Let L DL, C, D, two concepts L,
set axioms L, C satisable . Concept Contraction
Problem (CCP), denoted L, C, D, , nding pair concepts G, K L L
|= C GK, K satisable . call K contraction C according
.
use Q symbol CCP, denote SOLCCP (Q) set
solutions CCP Q. Observe concept abduction, rule cases
either C unsatisable, correspond counterintuitive situations. note
always trivial solution G, K = C, CCP. solution corresponds
drastic contraction, gives everything C. hand,
C satisable , best possible solution , C, is, give nothing.
Concept Abduction extends Subsumption, Concept Contraction extends satisability
particular, satisability conjunction C D. Hence, results complexity
deciding Satisability given concept carry Contraction.
Proposition 5 Let L DL containing AL, let Concept Satisability w.r.t. TBox
L problem C-hard complexity class C. deciding whether given pair
concepts G, K solution CCP Q =L, C, D, C-hard.
Proof. concept E L satisable w.r.t. TBox CCP L, C, D,
solution , C, C = R.E = R. . Then, L contain least
universal role quantication (to express R.E), unqualied existential role quantication
(to express R. ), conjunction (to express C G K) least unsatisable
concept (otherwise every concept satisable, problem trivializes). minimal, known DL containing constructs DL AL.
gives lower bound complexity Concept Contraction, DLs
include AL. DLs including AL, note proof showing C-hardness
satisability involves concept topmost symbol, proof could adapted
Concept Contraction.
Obviously, user marketplace likely willing give things
possible, minimality contraction G must dened. skip conciseness
denitions minimal-length contraction subsumption-maximal contraction,
dene straightforwardly conjunction-minimal contraction DLs admit normal form
made conjunctions.
290

fiSemantic Matchmaking Non-Monotonic Reasoning: Description Logic Approach

Definition 11 Let Q =L, C, D, CCP L admits CNF. set SOLCCP (Q)
subset SOLCCP (Q) following property: G, K SOLCCP (Q)
sub-conjunction G G holds G , K SOLCCP (Q). call solutions
irreducible.
6.1 Number-Restriction Minimal Contractions
follows focus specic class irreducible solutions CCP ALN , C, D,
exposing interesting characteristics user-oriented point view matchmaking
scenario. dening class explain rationale behind investigation using
following example.
Example 3 Suppose following situation:
demand Dem = HomePC hasMonitor.LCDmonitor
supply Sup = Server hasMonitor.CRTmonitor
|= Dem Sup demander contract Dem order regain satisability
Sup. Two solutions CCP Q = ALN , Dem, Sup, are:


G

= HomePC
K = PC ( 1 hasSoftware) (= 1 hasOS)


hasMonitor.LCDmonitor



G = hasMonitor.LCDmonitor
K = HomePC

G , K demander give specication HomePC; G , K
demander give specications monitor type keeping
rest.
Observe solutions previously dened class SOLCCP (Q),
user-oriented point view, G , K seems reasonable solution Q. Giving
HomePC concept Demand ( 1 hasMonitor) axiom
HomePCthe demander keeps specications requested components,
vacuously true, since K Sup implies hasMonitor. i.e., component admitted.
order make intuition precise, introduce number-restriction-minimal
solutions Q, whose set denote SOLCCPN (Q). Intuitively, solution G, K Q
SOLCCPN (Q) at-least restriction ( n R) G directly conicts
at-most restriction ( R) (with < n) D. Solutions atleast restriction given conicting universal role quanticationse.g., R.A
R.Aare SOLCCPN (Q). Since characteristic number-restrictionminimal solutions enforced level nesting, rst introduce role
path concept ALN . need distinguish concept
(dierent) occurrences another concept, e.g., B = R.A. theory, mark
occurrence number, e.g., A1 R.A2 ; however, since need focus one
occurrence time, mark A.
291

fiDi Noia, Di Sciascio & Donini

Definition 12 Given concept B ALN , occurrence atomic (sub)concept
B, role path B, (B) string that:
(A) = , denotes empty string
(B1 B2 ) = (Bi ), Bi , {1, 2}, concept occurrence
appears
(R.B) = R (B), denotes string concatenation
role path (B) represents role nesting concept occurrence concept
B. Note (B) commutation conjunctions B,
rearrangement universal role quanticationsif atomic, would
true7 . Using previous denition dene SOLCCPN (Q).
Definition 13 Let Q = ALN , C, D, CCP. set SOLCCPN (Q) subset
solutions G, K SOLCCP (Q) ( n R) occurs G exists
( R), < n, occurring CNF (D, ) ( n R) (G) = ( R) (CNF (D, )).
illustrate algorithm ndContract returns solution G, K SOLCCPN (Q)
Q = ALN , CNF (C, ), CNF (D, ), , is, compares two ALN -concepts C,
D, already CNF w.r.t. TBox , computes number-restriction minimal contraction G, K C w.r.t. without considering TBox.
Algorithm ndContract (C, D);
input ALN concepts C, D, already CNF
output number-restriction minimal contraction G, K,
G, K = , C means C satisable
variables concepts G, K, G , K
begin
1. C =
return , ; /* see comment 1 */
2. G := ; K := C; /* see comment 2 */
3. concept name Knames+
exists concept Dnames
G := G A; delete K;
4. concept ( x R) K
concept ( R) < x
G := G ( x R); delete ( x R) K;
5. concept ( x R) K
concept ( R) > x
G := G ( x R); delete ( x R) K;
6. concept R.F Kall
exist R.E Dall (
either ( x R) K x 1
7. readers familiar concept-centered normal form concepts (Baader et al., 2003),
note (B) word UA concept-centered normal form B.

292

fiSemantic Matchmaking Non-Monotonic Reasoning: Description Logic Approach

( x R) x 1 )
let G , K result ndContract (F, E)
G := G R.G ;
replace R.F K R.K ;
7. return G, K;
end.
Let us comment algorithm:
1. case Step 1 cannot occur top level, since assumed C satisable denition CCP. However, may occur inside universal quantication
e.g., C = R.hence, case Step 1 may apply recursive call ndContract ,
issued Step 6 outer call.
2. Step 2, conjunction C assigned K order leave K every
concept removed subsequent steps.
denote G , K solutions CCP Q = ALN , CNF (C, ), CNF (D, ), .
simplied CCP Q , completely unfold C forget it.
Theorem 4 pair G, K computed ndContract (C, D) number-restrictionminimal contraction Q = ALN , CNF (C, ), CNF (D, ), .
Proof.
rst prove G, K solution Q , namely, (i) G K C,
(ii) K satisable. prove (i) induction. base cases, observe
claim true Step 2 construction, Steps 35 conjunct
deleted K, also added G. Hence claim holds recursive call
made. inductive case, assume claim holds recursive call Step 6,
is, G K F every concept R.F Kall . Let Gn , Kn values variables G, K
execution Step 6, let Kn concept Kn without R.F . Then,
Step 6 is:
G K = (by assigment)


Gn R.G Kn R.K (by denition )
Gn Kn R.(G K ) (by inductive hypothesis)
Gn Kn R.F (by denition Kn )
Gn Kn (since base case holds Step 6)
C
Regarding (ii), proof induction, inductive hypothesis
K E satisable. Basically, construct interpretation (, ) element x
x (K D)I , show keep constructing without contradictions,
since contradicting concepts deleted K. inductive case, assume
existence interpretation ( , J ) K E (K E)J ,
ff


build joint interpretation ( , ) letting = , = J {x, RI }.
prove G, K number-restriction-minimal solution Q . proof
induction Quantication Nesting (QN) C, dened Section 3.1. Observe
at-least restriction deleted K Step 4 ndContract . base
caseQN (C) = 0, recursive callobserve role path retracted concept
293

fiDi Noia, Di Sciascio & Donini

( n R) G , role path concept ( R) causing Step 4
executed. Hence, claim holds base case. inductive case, assume
claim holds concepts QNs smaller QN (C). Observe concept
F Step 6 concept, since QN smaller least 1. Hence, (occurrence
an) at-least restriction ( x R), role path ( x R) (F ) deleted F , exists
conicting at-most restriction E role path. Since F E occur
inside scope concept R.F , R.E respectively, claim still holds role path
( x R) (C) = R ( x R) (F ).

6.2 Contraction-Based Ranking Partial Matches
dene penalty function p partial matches based following intuition:
partial matches ranked based many characteristics retracted
C make potential matches.
Algorithm penaltyPartial (C, D);
input ALN concepts C, D, already CNF
output penalty partial match C
zero means C satisable
variables integer n
begin
1. C =
return |D|; /* see Comment 1 */
2. n = 0;
3. concept name Cnames+
exists concept Dnames
n := n + 1;
4. concept ( x R) C
concept ( R) < x
n := n + 1;
5. concept ( x R) C
concept ( R) > x
n := n + 1;
6. concept R.F Call
exist R.E Dall (
either (( x R) C ( R) x y) /* see Comment 2 */
( x R) x 1 )
n := n + penaltyPartial (F, E);
7. return n;
end.
algorithm structure similar ndContract : whenever ndContract
removes concepts K, penaltyPartial adds penalties n. two dierences
explained following comments:
294

fiSemantic Matchmaking Non-Monotonic Reasoning: Description Logic Approach

1. Step 1 adds whole length C = . addition ensures antimonotonicity presence , explained Example 4 below.
2. Step 6 penaltyPartial additional condition ( R) x y.
condition necessary penaltyPartial actually remove concepts,
counts them. at-least restriction C contrast at-most
restriction , ndContract removes K, penaltyPartial adds
1 n. Yet, condition Step 6 evaluated, ndContract nds false
at-least restriction removed, penaltyPartial would nd
true, additional condition.
use outcome penaltyPartial dene penalty function partial matches.
Definition 14 Given simple TBox ALN , let penalty function p partial
match counteroer C given oer D, C concepts ALN ,
follows.
.
(3)
p (C, D, ) = penaltyPartial (CNF (C, ), CNF (D, ))
Note since penaltyPartial closely follows ndContract ndIrred , fact Formula (3)
similar Formula (1) Denition 9 might appear. Implicitly, solve
Q = ALN , CNF (C, ), CNF (D, ), , use result computation
penalty function, main dierence Step 1, though. explain dierence
help example.
Example 4 Let Dem 1 Dem 2 two demands, Dem 2 Dem 1 , let Sup
supply, modeled using ontology Figure 1 following:
Dem 1 = PC hasMonitor.CRTmonitor
Dem 2 = PC hasMonitor.
Sup = HomePC hasMonitor.LCDmonitor
Computing ndContract penaltyPartial CNF (Dem 1 , ) CNF (Dem 2 , )
w.r.t. CNF (Sup, ) obtain:
ndContract (CNF (Dem 1 , ), CNF (Sup, )) = hasMonitor.CRTmonitor,
PC hasMonitor.Monitor
penaltyPartial (CNF (Dem 1 , ), CNF (Sup, )) = 1
ndContract (CNF (Dem 2 , ), CNF (Sup, )) = hasMonitor., PC
penaltyPartial (CNF (Dem 2 , ), CNF (Sup, )) = 3
summary, concept conicts every concept, yet concept
R. given up, length zero (or constant), hence length G cannot
directly used antimonotonic penalty function. explains importance
Step 1 algorithm.
show following formal correspondence p Concept Contraction
dened previous Section.
295

fiDi Noia, Di Sciascio & Donini

Theorem 5 Let Q = ALN , C, D, CCP, let G , K solution Q returned ndContract (CNF (C, ), CNF (D, )). G contain occurrence
concept ,
p (C, D, ) = |G |
Proof. function p based penaltyPartial , inspection, whenever penaltyPartial
increments n, ndContract adds atomic concept G . exception Step 1
penaltyPartial , adds |D| ndContract adds G . However, case
explicitly outside claim.
prove p accordance properties highlighted previous Section.
Theorem 6 penalty function p (i) non-symmetric, (ii) syntax independent,
(iii) antimonotonic subsumption.
Proof.
(i) Non-symmetry proven example: let C = ( 1 R) R.A, =
( 2 R) R.A. simplicity, = , observe C already
CNF. show p (C, D, ) = p (D, C, ). fact, former case, observe
C must give everything: at-most restriction contrast at-least
restriction, inside universal quantication contrast R.A
D. Hence, penaltyPartial returns 2 = (1 Step 5) + (1 Step 1 recursive
call). Hence, p (C, D, ) = 2. latter case, instead, at-least restriction
given (and penaltyPartial adds 1 n Step 4), since role llers imposed,
universal quantication compatible (the condition Step 6 false).
Hence p (D, C, ) = 1.
(ii) syntax independency immediate consequence fact Formula (3)
uses normal forms concepts. Since normal forms unique commutativity
conjunctionthat xed imposing order conjunctions, e.g., lexicographic
claim holds.
(iii) antimonotonicity proved induction QN generic concept C
subsumed C; go conditions subsumption, analyzing changes
behavior algorithm C C . Recall goal prove
p (C , D, ) p (C, D, ). order make clear distinction two computations, let n (instance the) variable used call penaltyPartial (C , D),
n used call penaltyPartial (C, D). ease notation, assume C, C
already CNF.
First all, could case C = . case, n = |D| Step 1
penaltyPartial . hand, observe penaltyPartial (C, D) |D|
either C = too, every increase n corresponds atomic concept Dby
inspection Steps 35, recursively Step 6. Therefore, claim holds
base case.
Cnames C names . case, obvious Step 3 penaltyPartial
make increments n w.r.t. n, since C number iterations
increases.
296

fiSemantic Matchmaking Non-Monotonic Reasoning: Description Logic Approach

every number restriction C , either number restriction appears C ,
strengthened (an at-least increases, at-most decreases) C . Note
strengthening number restriction C turn false true condition
increment n Steps 45. instance, passing ( x R) C
( x R) C x x, ( R) < x implies < x .
similar argument holds at-most. Moreover, number restrictions appear
C increase number iterations Steps 45, hence n
increase w.r.t. n claim holds.
three cases prove basis induction (C QN equal 0).
prove case universal role quantication, assuming claim holds QNs less
QN (C ).
every R.F C , either R universally quantied Call ,
R.F Call F subsumed F (with F = F special case subsumption). Roles universally quantied Call quantied C ,
increase number iterations Step 6, hence n increase due
presence. roles specic restriction F , inductive hypothesis assumed hold, since QN (F ) < QN (C ). Hence p (F , E, ) p (F, E, ).
equivalent penaltyPartial (F , E) penaltyPartial (F, E). Moreover,
condition Step 6 true call penaltyPartial (C, D), also true
, ( x R) C , hence recursive
penaltyPartial (C , D), since R.F Call

call penaltyPartial (F, E) issued, also penaltyPartial (F , E) issued, increasing
n least much n increased, inductive hypothesis. Hence claim holds
also inductive case.

7. Matchmaking System
DLs-based approach semantic matchmaking illustrated previous Sections
implemented ALN reasoning engine MaMaS (MatchMaking Service). features
classical inference services DL reasoner, also implements algorithms nonstandard services matchmaking presented previous Sections.
MaMaS multi-user, multi-ontology Java servlet based system; available
HTTP service at: http://dee227.poliba.it:8080/MAMAS-tng/DIG, exposes DIG
1.18 compliant interface. basic DIG 1.1 extended cope non standard
services, briey describe additions.
New elements:
Match type detection: <matchType>E1 E2</matchType>- computes match type
according following classication: Exact (equivalence), Full, Plug-in, Potential,
Partial.
8. DIG 1.1 new standardized DL systems interface developed Description Logic Implementation
Group (DIG) (Haarslev & Moller, 2003).

297

fiDi Noia, Di Sciascio & Donini

Concept Abduction: <abduce>E1 E2</abduce> - implements ndIrred .
Concept Contraction: <contract>E1 E2</contract>- implements ndContract .
Ranking Score: <rank type="potential">E1 E2</rank>
<rank type="partial">E1 E2</rank>- computes p (C, D, ) p (C, D, )
presented previous Sections.
New attributes <newKB/>
shared: values used true false. MaMaS, new
knowledge base created, KB uri associated IP address client
host (owner) instantiating KB. shared attribute set false,
owner authorized submit tells statements change KB well submit
asks. case, requests IP addresses dierent owners one
asks. shared attribute set true, restriction set
tells asks statements. True default value.
permanent: values used true false. MaMaS, KB
used 300 seconds, KB automatically released. user wants
maintain KB indenitely, permanent attribute must set true; false
default value.
also pointed MaMaS supports simple-TBox, is, concept
axioms concept name left side9 .
using MaMaS matching engine various applications, including emarketplaces, (see e.g., Colucci, Di Noia, Di Sciascio, Donini, Ragone, & Rizzi, 2006;
Colucci et al., 2005) semantic web services discovery (Ragone, Di Noia, Di Sciascio,
Donini, Colucci, & Colasuonno, 2007). delve details applications here,
refer interested reader cited references.
7.1 Experimental Evaluation
hypothesis seek conrm Section approach performs eectively
wide range matchmaking scenarios, i.e., able model commonsense human
behavior analyzing ranking, given request, available oers. Hence experimental
framework relies comparison system behavior versus judgement human users.
Furthermore, although system may allow use weights increase relevance
concepts, following results refer basic unweighted version system,
avoid biasing results due weights introduction.
scenarios tested approach three: apartments rental, date/partner
nding, skill management recruiting agencies. Several ontology design methodologies
proposed (Jones, Bench-Capon, & Visser, 1998); adopted one proposed
N.F. Noy D.L. McGuinness (2001).
9. Notice since MaMaS supports ALN , atomic negation expressed <disjoint/>
groups must contain concepts specialized <impliesc> axiom (sub-concept axiom). Dened
concepts <equalc/> (same-class) admitted disjoint group.

298

fiSemantic Matchmaking Non-Monotonic Reasoning: Description Logic Approach

three scenarios carried thorough domain analysis, starting large
set advertisements taken newspapers descriptions on-line agencies,
designed ontologies describing domain. particular:
Apartments rental ontology made 146 concepts (primitive + dened) 33
roles.
Date/partner matching ontology made 131 concepts (primitive + dened)
29 roles.
Skill matching ontology made 308 concepts (primitive + dened) 38 roles.
scenario selected several announcements. total number used experiments human users 180 (120 oers, 60 requests) apartments rental, 215
(140 oers, 75 requests) skill matching. 100 advertisements Date matching
scenario also selected, yet actually distinguish among requests
oers announcements form proles, although included preferences
dating partner. announcements natural language manually
translated DL syntax. created, domain, 50 sets questionnaires.
Questionnaires form one request (a demand supply) 10 oering advertisements. Three groups ten randomly selected volunteers, asked order,
according judgement advertisements, respect given requests.
obtained average users rankings, run sets advertisements system,
gave us set system provided rankings. System rankings included partial
matching advertisements simply ordered worst potential matching advertisement. adopted, reference, standard Vector Space Model (VSM) (Salton & Gill,
1983) system. used terms ontologies attening ontology descriptions, dimensions three separate vector spaces, determined weights using classical F IDF
measure. Similarity results computed using well-known Cosine similarity measure
(Salton & Gill, 1983).
summarize results adopted Rnorm (Bollmann, Jochum, Reiner, Weissmann,
& Zuse, 1985) quality measure system eectiveness. Rnorm dened follows.
Given Sup, nite set descriptions user-dened preference relation
complete transitive, let usr rank ordering Sup induced users preference
relation, let sys system-provided ranking. Rnorm dened as:
Rnorm (sys ) =

S+
1
(1 +
)
+
2
Smax

+ number descriptions pairs better description ranked
system ahead worse one; number pairs worse description ranked
+
maximum possible number + . noticed
ahead better one Smax
+

calculation , , Smax based ranking descriptions pairs
sys relative ranking corresponding descriptions pairs usr . Rnorm values
range [0,1]; value 1 corresponds system-provided ordering available
descriptions either identical one provided human users higher
degree resolution, lower values correspond proportional disagreement
two. three scenarios considered, results presented table 3.
299

fiDi Noia, Di Sciascio & Donini

Domain
Apartments rental
Date/partner matching
Skill matching

MaMaS
0.87
0.79
0.91

VSM
0.48
0.41
0.46

Table 3: Rnorm values: MaMaS: Semantic matchmaking results, VSM: Vector Space Model
results

Although present variability, believe partly due ability
capture domain ontologies design, show approach provides rankings
close human commonsense behavior far better obtained
unstructured text retrieval tools.

8. Conclusion
addressed matchmaking problem descriptions DL perspective.
analyzed semantic-based matchmaking process devised general commonsense
properties matchmaker have. also pointed classical inference
services DLs, satisability subsumption, needed useful, may
sucient cope challenges posed matchmaking open environment.
Motivated studied Concept Abduction Contraction novel nonmonotonic inferences DLs suitable modeling semantic-based matchmaking scenarios.
analyzed minimality criteria, proved simple complexity results. also presented
reasonable algorithms classifying ranking matches based devised inferences
terms penalty functions, proved obey properties individuated.
Although several measures may determined compute score
promising matches proposal logical foundations empyrically shown
able well simulate commonsense human reasoning. Obviously, semanticbased approach, also rely well-designed ontologies able model
application domain considered.
Based theoretical work implemented fully functional matchmaking
facilitator, oriented generic e-marketplace advertisements semantic-based
web-service discovery, exploits state art technologies protocols, is,
best knowledge, running system able cope Concept Abduction
Concept Contraction problems.
specic reference earlier work authors subject, Di Sciascio et al.
(2001) dened matchmaking satisability concept conjunction. Denitions potential
match near-miss i.e., partial match, terms abduction belief-revision outlined, need ranking matches motivated, work Di Sciascio, Donini,
Mongiello (2002). Di Noia et al. (2003b, 2003c) proposed semantic-based categorization
matches, logic-based ranking matches within categories, properties ranking functions
have, framework E-marketplaces. extended revised version
works (Di Noia, Di Sciascio, Donini, & Mongiello, 2004). Di Noia et al. (2003a) intro300

fiSemantic Matchmaking Non-Monotonic Reasoning: Description Logic Approach

duced Concept Abduction DLs presented algorithms solve Concept Abduction
Problem ALN . Colucci et al. (2003) proposed Concept Abduction Concept
Contraction inferences suitable semantic-matchmaking explanation services. Cal
et al. (2004) proposed basic approach adopting penalty functions ranking, framework dating systems. Colucci et al. (2004) proposed initial results algorithms based
truth-prexed tableau solve Concept Abduction Contraction problems ALN .
Colucci et al. (2005) showed services usefully adopted semanticmatchmaking nding negotiation spaces E-Commerce setting. use
proposed inference services renement purposes semantic-matchmaking process
outlined work Colucci et al. (2006).
current research oriented investigation algorithms expressive
DLs development tableaux-based system proposed inference services.

Acknowledgments
grateful anonymous reviewers comments suggestions improved
quality paper. thank Andrea Cal Diego Calvanese useful discussions,
particular suggesting term penalty function. Simona Colucci, Azzurra Ragone,
Marina Mongiello people SisInfLab gave us invaluable help suggestions.
research supported EU FP-6 IST STREP TOWL co. 026896.

Appendix A. Rules Normal Form
normal form concept obtained repeatedly applying rules two
following Sections, rule applicable level nesting concepts inside R.C.
A.1 Rules Involving Subconcepts
following rules, symbol l.h.s. considered associative
commutative operator; hence, instance, writing ( n R) ( R) second
rule, read concepts ( n R) ( R) appear order inside
conjunction two concepts.

C
( n R) ( R) n >

( n R) ( R) ( n R) n >
( n R) ( R) ( n R) n <
R.D1 R.D2 R.(D1 D2 )
R. R. ( 0 R)
301

fiDi Noia, Di Sciascio & Donini

A.2 Rules Involving Concept TBox

C C
C C
B1 Bk disj (A, B1 , . . . , Bk )
Usually concept resulting application rules referred
expansion, unfolding TBox.
A.3 Properties Normal Form
Let C concept Classic, let C concept obtained C repeatedly
appying rules. Let |C|, |C | denote size C, C respectively. proved
(Borgida & Patel-Schneider, 1994) that:
1. |C | polynomially bounded |C|, C computed time O(|C|2 );
2. every concept resulting application rules equivalent C, w.r.t.
models TBox.
consequence latter property, C unsatisable normal form . Then,
consequence former property, unsatisability decided polynomial time
(Borgida & Patel-Schneider, 1994). fact |C | polynomially bounded |C|
intuitively related Nebel (1990) form TBoxes, bushy
deep. precise denition given Colucci et al. (2004).

References
Agarwal, S., & Lamparter, S. (2005). smart - semantic matchmaking portal electronic
markets. Proceedings 7th International IEEE Conference E-Commerce
Technology 2005.
Arens, Y., Knoblock, C. A., & Shen, W. (1996). Query Reformulation Dynamic Information Integration. Journal Intelligent Information Systems, 6, 99130.
Baader, F., Calvanese, D., Mc Guinness, D., Nardi, D., & Patel-Schneider, P. (Eds.). (2003).
Description Logic Handbook. Cambridge University Press.
Baader, F., & Hollunder, B. (1992). Computing extensions terminological default theories.
Proceedings ECAI Workshop Knowledge Representation Reasoning, pp.
3052.
Baader, F., Kusters, R., Borgida, A., & Mc Guinness, D. (1999). Matching Description
Logics. Journal Logic Computation, 9 (3), 411447.
Baader, F., Kusters, R., & Molitor, R. (2000). Rewriting concepts using terminologies.
Proceedings Seventh International Conference Principles Knowledge
Representation Reasoning (KR2000), pp. 297308.
302

fiSemantic Matchmaking Non-Monotonic Reasoning: Description Logic Approach

Benatallah, B., Hacid, M.-S., Rey, C., & Toumani, F. (2003). Request Rewriting-Based Web
Service Discovery. International Semantic Web Conference, Vol. 2870 Lecture
Notes Computer Science, pp. 242257. Springer.
Berners-Lee, T., Hendler, J., & Lassila, O. (2001). semantic web. Scientic American,
248 (4), 3443.
Bollmann, P., Jochum, F., Reiner, U., Weissmann, V., & Zuse, H. (1985). LIVEProject-Retrieval experiments based evaluation viewpoints. Proceedings
8th Annual International ACM/SIGIR Conference Research Development
Information Retrieval, pp. 213214. ACM, New York.
Bonatti, P., Lutz, C., & Wolter, F. (2006). Description logics circumscription.
Proceedings Tenth International Conference Principles Knowledge Representation Reasoning (KR2006), pp. 400410.
Borgida, A., Brachman, R. J., McGuinness, D. L., & A. Resnick, L. (1989). CLASSIC:
Structural Data Model Objects. Proceedings ACM SIGMOD International
Conference Management Data, pp. 5967.
Borgida, A., & Patel-Schneider, P. F. (1994). Semantics Complete Algorithm
Subsumption CLASSIC Description Logic. Journal Articial Intelligence
Research, 1, 277308.
Brandt, S., Kusters, R., & Turhan, A. (2002). Approximation dierence description logics. Proceedings Eight International Conference Principles
Knowledge Representation Reasoning (KR2002), pp. 203214. MK.
Buchheit, M., Donini, F., Nutt, W., & Schaerf, A. (1998). rened architecture terminological systems: Terminology = schema + views. Articial Intelligence, 99 (2),
209260.
Cal, A., Calvanese, D., Colucci, S., Di Noia, T., & Donini, F. M. (2004). description logic
based approach matching user proles. Proceedings 17th International
Workshop Description Logics (DL04), Vol. 104 CEUR Workshop Proceedings.
Calvanese, D. (1996). Reasoning Inclusion Axioms Description Logics. Proceedings
Twelfth European Conference Articial Intelligence (ECAI96), pp. 303307.
John Wiley & Sons.
Calvanese, D., De Giacomo, G., & Lenzerini, M. (1998). Decidability Query
Containment Constraints. Proceedings Seventeenth ACM SIGACT
SIGMOD SIGART Symposium Principles Database Systems (PODS98), pp.
149158.
Colucci, S., Di Noia, T., Di Sciascio, E., Donini, F., & Mongiello, M. (2003). Concept Abduction Contraction Description Logics. Proceedings 16th International
Workshop Description Logics (DL03), Vol. 81 CEUR Workshop Proceedings.
Colucci, S., Di Noia, T., Di Sciascio, E., Donini, F., & Mongiello, M. (2004). Uniform
Tableaux-Based Approach Concept Abduction Contraction ALN. Proceedings 17th International Workshop Description Logics (DL04), Vol. 104
CEUR Workshop Proceedings.
303

fiDi Noia, Di Sciascio & Donini

Colucci, S., Di Noia, T., Di Sciascio, E., Donini, F., & Mongiello, M. (2005). Concept
Abduction Contraction Semantic-based Discovery Matches Negotiation
Spaces E-Marketplace. Electronic Commerce Research Applications, 4 (4),
345361.
Colucci, S., Di Noia, T., Di Sciascio, E., Donini, F., Ragone, A., & Rizzi, R. (2006).
semantic-based fully visual application matchmaking query renement B2C
e-marketplaces. 8th International conference Electronic Commerce, ICEC 06,
pp. 174184. ACM Press.
Console, L., Dupre, D., & Torasso, P. (1991). Relationship Abduction
Deduction. Journal Logic Computation, 1 (5), 661690.
Devambu, P., Brachman, R. J., Selfridge, P. J., & Ballard, B. W. (1991). LASSIE:
Knowledge-Based Software Information System. Communications ACM, 34 (5),
3649.
Di Noia, T., Di Sciascio, E., Donini, F., & Mongiello, M. (2003a). Abductive matchmaking
using description logics. Proceedings Eighteenth International Joint Conference Articial Intelligence (IJCAI 2003), pp. 337342.
Di Noia, T., Di Sciascio, E., Donini, F., & Mongiello, M. (2003b). Semantic matchmaking
P-2-P electronic marketplace. Proc. Symposium Applied Computing (SAC
03), pp. 582586. ACM.
Di Noia, T., Di Sciascio, E., Donini, F., & Mongiello, M. (2003c). system principled
Matchmaking electronic marketplace. Proc. International World Wide Web
Conference (WWW 03), pp. 321330. ACM, New York.
Di Noia, T., Di Sciascio, E., Donini, F., & Mongiello, M. (2004). system principled Matchmaking electronic marketplace. International Journal Electronic
Commerce, 8 (4), 937.
Di Sciascio, E., Donini, F., & Mongiello, M. (2002). Knowledge representation matchmaking P2P e-commerce. Atti dellVIII Convegno dellAssociazione Italiana di
Intelligenza Articiale, Siena.
Di Sciascio, E., Donini, F., Mongiello, M., & Piscitelli, G. (2001). Knowledge-Based System Person-to-Person E-Commerce. Proceedings KI-2001 Workshop
Applications Description Logics (ADL-2001), Vol. 44 CEUR Workshop Proceedings.
Donini, F. M. (2003). Complexity reasoning. Description Logics Handbook, chap. 3.
Cambridge University Press.
Donini, F. M., Lenzerini, M., Nardi, D., & Nutt, W. (1991). Complexity Concept Languages. Allen, J., Fikes, R., & Sandewall, E. (Eds.), Proceedings
Second International Conference Principles Knowledge Representation
Reasoning (KR91), pp. 151162. Morgan Kaufmann, Los Altos.
Donini, F. M., Nardi, D., & Rosati, R. (1997a). Autoepistemic description logics. Proc.
IJCAI 97, pp. 136141.
304

fiSemantic Matchmaking Non-Monotonic Reasoning: Description Logic Approach

Donini, F. M., Lenzerini, M., Nardi, D., & Nutt, W. (1997b). complexity concept
languages. Information Computation, 134, 158.
Eiter, T., & Gottlob, G. (1995). Complexity Logic-Based Abduction. Journal
ACM, 42 (1), 342.
Finin, T., Fritzson, R., McKay, D., & McEntire, R. (1994). KQML Agent Communication Language. Proceedings Third International Conference Information
Knowledge Management (CIKM94), pp. 456463. ACM.
Gardenfors, P. (1988). Knowledge Flux: Modeling Dynamics Epistemic States.
Bradford Books, MIT Press, Cambridge, MA.
Gil, Y., & Ramachandran, S. (2001). PHOSPHORUS: Task based Agent Matchmaker.
Proc. International Conference Autonomous Agents 01, pp. 110111. ACM.
Gonzales-Castillo, J., Trastour, D., & Bartolini, C. (2001). Description Logics Matchmaking Services. Proceedings KI-2001 Workshop Applications Description Logics (ADL-2001), Vol. 44. CEUR Workshop Proceedings.
Grimm, S., Motik, B., & Preist, C. (2006). Matching Semantic Service Descriptions
Local Closed-World Reasoning. European Semantic Web Conference, pp. 575589.
Haarslev, V., & Moller, R. (2003). dig description logic interface. Proceedings
International Workshop Description Logics (DL-2003), Vol. 81 CEUR Workshop
Proceedings.
Horrocks, I., & Tobies, S. (2000). Reasoning axioms: Theory practice.. Proceedings Seventh International Conference Principles Knowledge Representation Reasoning (KR2000), pp. 285296.
Jacobs, N., & Shea, R. (1995). Carnot Infosleuth Database Technology Web.
Proceedings ACM SIGMOD International Conference Management
Data, pp. 443444. ACM.
Jones, D., Bench-Capon, T., & Visser, P. (1998). Methodologies ontology development.
J. Cuena, editor, Proc. 15th IFIP World Computer Congress, pp. 6275, London,
UK. Chapman Hall.
Karacapilidis, N., & Moraitis, P. (2001). Building Agent-Mediated Electronic Commerce
System Decision Analysis Features. Decision Support Systems, 32, 5369.
Kieling, W. (2002). Foundations preferences database systems. Proceedings
Twentyeight International Conference Large Data Bases (VLDB 2002).
Klusch, M., Fries, B., Khalid, M., & Sycara, K. (2005). Owls-mx: Hybrid owl-s service
matchmaking. Proceedings 1st Intl. AAAI Fall Symposium Agents
Semantic Web.
Kuokka, D., & Harada, L. (1996). Integrating Information Via Matchmaking. Journal
Intelligent Information Systems, 6, 261279.
Li, L., & Horrocks, I. (2003). Software Framework Matchmaking Based Semantic
Web Technology. Proc. International World Wide Web Conference (WWW 03),
pp. 331339. ACM, New York.
305

fiDi Noia, Di Sciascio & Donini

Lutz, C. (1999). Reasoning concrete domains. Dean, T. (Ed.), Proceedings
Sixteenth International Joint Conference Articial Intelligence (IJCAI99), pp.
9095, Stockholm, Sweden. Morgan Kaufmann, Los Altos.
Madhavan, J., Bernstein, P., & Rahm, E. (2001). Generic schema matching cupid.
Proceedings Twentyseventh International Conference Large Data Bases
(VLDB 2001), pp. 4958.
Maes, P., Guttman, R., & Moukas, A. (1999). Agents Buy Sell. Communications
ACM, 42 (3), 8191.
Motro, A. (1988). VAGUE: User Interface Relational Databases Permits Vague
Queries. ACM Transactions Oce Information Systems, 6 (3), 187214.
Nebel, B. (1990). Terminological Reasoning Inherently Intractable. Articial Intelligence,
43, 235249.
N.F. Noy D.L. McGuinness (2001). Ontology Development 101: Guide Creating
First Ontology. Stanford Knowledge Systems Laboratory Technical Report KSL01-05.
Paolucci, M., Kawamura, T., Payne, T., & Sycara, K. (2002). Semantic Matching Web
Services Capabilities. Semantic Web - ISWC 2002, No. 2342 Lecture Notes
Computer Science, pp. 333347. Springer-Verlag.
Peirce, C. . (1955). Abduction induction. Philosophical Writings Peirce, chap. 11.
J. Buchler.
Ragone, A., Di Noia, T., Di Sciascio, E., Donini, F., Colucci, S., & Colasuonno, F. (2007).
Fully Automated Web Services Discovery Composition Concept Covering
Concept Abduction. International Journal Web Services Research (JWSR),
4 (3).
Raman, R., Livny, M., & Solomon, M. (1998). Matchmaking: distributed resource management high throughput computing. Proceedings IEEE High Performance
Distributed Computing Conf., pp. 140146.
Salton, G., & Gill, M. M. (1983). Introduction Modern Information Retrieval. McGrawHill, New York.
Schmidt-Schau, M., & Smolka, G. (1991). Attributive Concept Descriptions Complements. Articial Intelligence, 48 (1), 126.
Shvaiko, P., & Euzenat, J. (2005). survey schema-based matching approaches. Journal
Data Semantics, 4, 146171.
Strobel, M., & Stolze, M. (2002). Matchmaking Component Discovery Agreement Negotiation Spaces Electronic Markets. Group Decision Negotiation,
11, 165181.
Sycara, K., Paolucci, M., Van Velsen, M., & Giampapa, J. (2003). RETSINA MAS
infrastructure. Autonomous agents multi-agent systems, 7, 2948.
Sycara, K., Wido, S., Klusch, M., & Lu, J. (2002). LARKS: Dynamic Matchmaking Among
Heterogeneus Software Agents Cyberspace. Autonomous agents multi-agent
systems, 5, 173203.
306

fiSemantic Matchmaking Non-Monotonic Reasoning: Description Logic Approach

Teege, G. (1994). Making dierence: subtraction operation description logics.
Proceedings Fourth International Conference Principles Knowledge
Representation Reasoning (KR94), pp. 540550. MK.
Trastour, D., Bartolini, C., & Priest, C. (2002). Semantic Web Support Business-toBusiness E-Commerce Lifecycle. Proc. International World Wide Web Conference
(WWW) 02, pp. 8998. ACM.
Veit, D., Muller, J., Schneider, M., & Fiehn, B. (2001). Matchmaking Autonomous
Agents Electronic Marketplaces. Proc. International Conference Autonomous
Agents 01, pp. 6566. ACM.
Wang, H., Liao, S., & Liao, L. (2002). Modeling Constraint-Based Negotiating Agents.
Decision Support Systems, 33, 201217.
Wright, J. R., Weixelbaum, E. S., Vesonder, G. T., Brown, K. E., Palmer, S. R., Berman,
J. I., & Moore, H. H. (1993). Knowledge-Based Congurator Supports Sales,
Engineering, Manufacturing AT&T Network Systems. AI Magazine, 14 (3),
6980.

307

fiJournal Artificial Intelligence Research 29 (2007) 4977

Submitted 09/06; published 05/07

Solution-Guided Multi-Point Constructive Search Job
Shop Scheduling
J. Christopher Beck

jcb@mie.utoronto.ca

Department Mechanical & Industrial Engineering
University Toronto, Canada

Abstract
Solution-Guided Multi-Point Constructive Search (SGMPCS) novel constructive
search technique performs series resource-limited tree searches search
begins either empty solution (as randomized restart) solution
encountered search. small number elite solutions maintained
search. introduce technique perform three sets experiments
job shop scheduling problem. First, systematic, fully crossed study SGMPCS
carried evaluate performance impact various parameter settings. Second,
inquire diversity elite solution set, showing, contrary expectations,
less diverse set leads stronger performance. Finally, compare best parameter
setting SGMPCS first two experiments chronological backtracking, limited
discrepancy search, randomized restart, sophisticated tabu search algorithm set
well-known benchmark problems. Results demonstrate SGMPCS significantly
better constructive techniques tested, though lags behind tabu search.

1. Introduction
number metaheuristic evolutionary approaches optimization described
solution-guided, multi-point searches. example, genetic mimetic algorithms, population solutions maintained used basis search. new
generation created combining aspects current generation: search therefore
guided existing solutions. population contains number individual solutions,
search makes use multiple points search space. Traditional single-point metaheuristics, tabu search, augmented similar way. TSAB tabu
search (Nowicki & Smutnicki, 1996) maintains elite pool consisting small number
best solutions found far search. Whenever basic search reaches
threshold number moves without finding new best solution, search restarted one
elite solutions. Again, higher-level search guided multiple existing solutions,
though guidance somewhat different genetic algorithms.
Solution-Guided Multi-Point Constructive Search (SGMPCS) 1 framework designed
allow constructive search guided multiple existing (suboptimal) solutions
problem instance. randomized restart techniques (Gomes, Selman, & Kautz,
1998), framework consists series tree searches restricted resource limit,
1. previous conference workshop publications, SGMPCS referred simply Multi-Point Constructive Search (Beck, 2006; Heckman & Beck, 2006; Beck, 2005a, 2005b). Empirical evidence
importance solution guidance motivated change name reflective important
differences work existing tree search techniques.
c
2007
AI Access Foundation. rights reserved.

fiBeck

typically maximum number fails. resource limit reached, search restarts.
difference randomized restart SGMPCS keeps track small set elite
solutions: best solutions found. search restarted, starts
empty solution, randomized restart, one elite solutions.
paper, undertake first fully crossed systematic empirical study SGMPCS. particular, Section 3 investigate different parameter settings impact search performance makespan-minimization variant job shop scheduling problem. Results indicate guidance elite solutions contributes significantly
algorithm performance but, somewhat unexpectedly, smaller elite set size results
better performance. Indeed, elite set size one showed best performance.
result motivates subsequent experimentation diversity elite set Section 4.
show, contrary expectation consistent elite set size one,
less diverse elite set, stronger performance. discussed in-depth Section
6, two sets experiments call question extent exploitation
multiple points search space important performance SGMPCS.
final experiment (Section 5) compares best parameter settings found first two
experiments chronological backtracking, limited discrepancy search (Harvey, 1995),
randomized restart, state-of-the-art tabu search (Watson, Howe, & Whitley, 2006)
set well-known benchmarks. results show SGMPCS significantly outperforms constructive search methods perform well tabu
search.
contributions paper follows:
1. introduction systematic experimental evaluation Solution-Guided MultiPoint Constructive Search (SGMPCS).
2. investigation importance diversity elite set performance
SGMPCS.
3. demonstration SGMPCS significantly out-performs chronological backtracking, limited discrepancy search, randomized restart benchmark set job
shop scheduling problems.

2. Solution-Guided Multi-Point Constructive Search
Pseudocode basic Solution-Guided Multi-Point Constructive Search algorithm
shown Algorithm 1. algorithm initializes set, e, elite solutions enters
while-loop. iteration, probability p, search started empty solution
(line 6) randomly selected elite solution (line 12). former case,
best solution found search, s, better worst elite solution, replaces
worst elite solution. latter case, replaces starting elite solution, r,
better r. individual search limited maximum number fails
incurred. optimal solution found proved overall bound
computational resources (e.g., CPU time, number fails) reached, best elite
solution returned.
elite solutions initialized search technique. paper, use 50
independent runs randomized texture-based heuristic employed
50

fiSolution-Guided Multi-Point Constructive Search

SGMPCS():
1
2
3
4
5
6
7
8

9
10
11
12
13
14

15

initialize elite solution set e
termination criteria unmet
rand[0, 1) < p
set upper bound cost function
set fail limit, l
:= search(, l)
6= better worst(e)
replace worst(e)
end
else
r := randomly chosen element e
set upper bound cost function
set fail limit, l
:= search(r, l)
6= better r
replace r
end
end
end
return best(e)
Algorithm 1: SGMPCS: Solution-Guided Multi-Point Constructive Search

main search (see Section 3.2). backtracking done upper bound placed
cost function. Without upper bound, run find solution, though probably one
quite low quality. initial set 50 solutions, |e| best solutions inserted
elite set. primary goal initialization quickly populate elite set.
Previous work (Beck, 2006) shown spending effort run find
good starting solutions (e.g., via backtracking search) significantly improve overall
performance, number runs impact. variance quality among
initial solutions high, best starting solution large elite set much better
small elite set. difference alone sufficient skew experiments
measured impact different elite set sizes overall performance. mitigate
effect generate fixed number elite solution candidates (i.e., 50) choose
|e| best. interesting direction future work adaptively determine best time
transition elite pool generation main search.
2.1 Search
lines 6 12 search(r, l) function standard tree search randomization,
limited number fails, l, and, r 6= , guided solution r. search function
returns best solution found, any, indication whether search space
exhausted. Given large enough fail limit, individual search completely search
space. Therefore, completeness approach depends policy setting
increasing fail limit. see Experiment 3 (Section 5), SGMPCS able
51

fiBeck

find optimal solutions prove optimality. place restrictions
search, allowing tree traversal technique used. particular, experiment
chronological backtracking limited discrepancy search (Harvey, 1995).
r 6= , search guided reference solution, r. guiding solution
simply used value ordering heuristic: search using (randomized) variable
ordering heuristic specifying value assigned variable one
reference solution, provided still domain variable.
search tree created asserting series choice points form: hV = xihVi 6=
xi, Vi variable x value assigned V . Given importance variable
ordering heuristics constructive search, expect order choice points
impact search performance. SGMPCS can, therefore, use variable ordering
heuristic choose next variable assign. choice point formed using value
assigned reference solution or, value reference solution inconsistent,
heuristically chosen value. formally, let reference solution, r, set variable
assignments, {hV1 = x1 i, hV2 = x2 i, . . . , hVm = xm i}, n, n number
variables. variable ordering heuristic complete freedom choose variable, V ,
assigned. xi dom(Vi ), hVi = xi r, choice point made x = x .
Otherwise, xi
/ dom(Vi ), value ordering heuristic used choose x dom(V ).
need account possibility x
/ dom(Vi ) reference solution
necessarily valid solution later SGMPCS search process. take simple
example, reference solution cost 100 constrain search find
better solution, reach reference solution. Rather, via constraint propagation,
reach dead-end different solution.
technique starting constructive search reference solution quite general.
Existing high-performance variable ordering heuristics exploited and, addressing
case xi
/ dom(Vi ), make assumptions changes constraint model
may made reference solution originally found. particular,
means elite solution could solution relaxation full problem.
2.2 Setting Bounds Cost Function
individual search (lines 6 12), place upper bound cost function.
bound impact set solutions and, therefore, solutions may
enter elite set. Intuitions constructive search metaheuristics differ
appropriate choice upper bound. standard tree search optimization
discrete cost function, usual approach use c 1 upper bound, c
best solution found far. Using higher bound would expand search space
without providing heuristic benefit. contrast, standard metaheuristic approach,
search usually restricted enforcing upper bound cost acceptable states:
search allowed travel worse states order (hopefully) find better ones.
consequence, common replace elite solution better, necessarily
best-known, solution found. Since elite solutions used heuristically guide search,
even solutions best-known provide heuristic guidance.
two perspectives result two policies:
1. Global Bound: Always set upper bound search cost c 1.
52

fiSolution-Guided Multi-Point Constructive Search

2. Local Bound: starting empty solution, set upper bound
equal one less cost worst elite solution. starting elite
solution, set upper bound one less cost starting solution.

constraint programming, back-propagation extent placing bound
cost function results domain reductions decision variables. Previous experiments
SGMPCS optimization problems strong back-propagation (such job shop
scheduling objective minimizing makespan) show global bound policy
superior (Beck, 2006). problems weaker back-propagation satisfaction
problems (where back-propagation), local bound approach performs better
(Beck, 2006; Heckman & Beck, 2006). Based results, use global bound
policy here.
2.3 Related Work
SGMPCS directly inspired TSAB tabu search algorithm (Nowicki & Smutnicki, 1996) noted above. TSAB, elite pool consisting small number best
solutions found maintained search. Whenever basic tabu search stagnates,
is, reaches threshold number moves without finding new best solution,
search restarted one elite solutions. tabu list modified
search restarted, follow different search path. basic mechanism,
adapted constructive search, used SGMPCS. number years, TSAB
state-of-the-art algorithm job shop scheduling problems. recently
over-taken i-TSAB, algorithm based TSAB makes sophisticated use
elite pool (Nowicki & Smutnicki, 2005). in-depth analysis i-TSAB see
work Watson, Howe, Whitley (2006).
SGMPCS performs series resource-limited tree searches. clear behaviour related extensive work randomized restart (Gomes et al., 1998; Horvitz,
Ruan, Gomes, Kautz, Selman, & Chickering, 2001; Kautz, Horvitz, Ruan, Gomes, & Selman, 2002; Gomes, Fernandez, Selman, & Bessiere, 2005; Hulubei & OSullivan, 2006).
Indeed, setting p, probability searching empty solution, 1 results
randomized restart technique. observed search effort chronological
backtracking given variable ordering forms heavy-tailed distribution. Intuitively,
means randomly chosen variable ordering non-trivial chance resulting
either small large cost find solution problem instance. solution
found threshold amount effort, beneficial restart search different
variable ordering new ordering non-trivial probability quickly leading
solution.
number techniques make use randomized heuristic backtracking (Prestwich, 2002; Jussien & Lhomme, 2002; Dilkina, Duan, & Havens, 2005)
form hybrid local search tree search allow exploration search space
constrained standard tree search. approaches differ SGMPCS
fundamental level: use (multiple) existing solutions guide search.
53

fiBeck

3. Experiment 1: Parameter Settings
primary purpose experiment understand impact different parameter settings performance SGMPCS algorithms. present fully crossed
experiment evaluate impact varying parameters SGMPCS.
3.1 SGMPCS Parameters
Elite Set Size number elite solutions maintained search
key parameter controlling extent multiple points search space
exploited SGMPCS. seem significant experimentation
elite set size metaheuristic community, anecdotally, hybrid tabu search
elite set smaller six performs much worse larger elite sets job shop
scheduling problems.2 paper, experiment elite set sizes {1, 4, 8, 12, 16, 20}.
Proportion Searches Empty Solution p parameter controls
probability searching empty solution versus searching one elite
solutions. high p value result algorithm behaviour similar randomized restart
indeed, p = 1 randomized restart algorithm. One reason p parameter
included SGMPCS intuition also impact diversity
elite pool: higher p value diverse elite pool solutions
unrelated current elite solutions likely enter pool. see
Experiment 2, intuition contradicted empirical results. Here, study
p = {0, 0.25, 0.5, 0.75, 1}.
Fail Limit Sequence resource limit sets number fails allowed
tree search. Rather constant limit faced problem tuning
limit (Gomes et al., 1998), following work Kautz, Horvitz, Ruan, Gomes, Selman
(2002), adopt dynamic restart policy limit number fails changes
problem solving. look two simple fail limit sequences (seq):
Luby - fail limit sequence optimal sequence satisfaction problems condition knowledge solution distribution (Luby, Sinclair, &
Zuckerman, 1993). sequence follows: 1, 1, 2, 1, 1, 2, 4, 1, 1, 2, 1, 1, 2, 4, 8,
.... is, fail limit first second searches 1 fail, third search
2 fails, on. sequence independent outcome searches
whether search empty solution guided elite solution.
Polynomial (Poly) - fail limit initialized 32 reset 32 whenever new
best solution found. Whenever search fails find new best solution, bound
grows polynomially adding 32 fail limit. value 32 chosen give
reasonable increase fail limit iteration. tuning done determine
value 32. Luby limit, Poly fail limit independent choice
search empty solution elite solution.
2. Jean-Paul Watson personal communication.

54

fiSolution-Guided Multi-Point Constructive Search

Backtrack Method Finally, noted above, style individual tree search
limited chronological backtracking. Whether search begins empty solution
elite solution, choice search performed. particular,
backtracking (bt) factor either standard chronological backtracking limited discrepancy
search (LDS) (Harvey, 1995). either case, search limited fail limit
described above.
3.2 Experimental Details
experimental problems job shop scheduling problem (JSP) instances. n job
shop scheduling problem consists set n jobs, consisting complete ordering
activities. activity duration specified resource must
execute. ordering activities job represents chain precedence constraints:
activity cannot start preceding activity job completed. activity
begins execution, must execute complete duration (i.e., pre-emption allowed).
unary capacity resources, meaning resource used one
activity time. optimal solution JSP sequence activities
resource union job sequences resource sequences acyclic,
makespan (the time start earliest job end latest job)
minimized. JSP NP-hard (Garey & Johnson, 1979) received extensive study
operations research artificial intelligence literature (Jain & Meeran,
1999).
experimental instances twenty 20 20 problem instances generated using
existing generator (Watson, Barbulescu, Whitley, & Howe, 2002). durations
activities independently drawn uniform probability [1, 99]. machine
routings generated create work-flow problems job visits first 10 machines second 10 machines. Within two machine sets, routings
generated randomly uniform probability. Work-flow JSPs used
shown difficult JSPs random machine routings (Watson, 2003).
algorithm run 20 CPU minute time-out, problem instance solved
10 times independently given parameter configuration. algorithms implemented
ILOG Scheduler 6.2 run 2GHz Dual Core AMD Opteron 270 2Gb RAM
running Red Hat Enterprise Linux 4.
experiment, dependent variable mean relative error (MRE) relative
best solution known problem instance. MRE arithmetic mean
relative error run problem instance:
MRE (a, K, R) =

1 X X c(a, k, r) c (k)
|R||K|
c (k)

(1)

rR kK

K set problem instances, R set independent runs different random
seeds, c(a, k, r) lowest cost found algorithm instance k run r, c (k)
lowest cost known k. problem instances generated experiment,
best-known solution found either algorithms tested variations used
preliminary experiments.3
3. Problem instances best-known solutions available author.

55

fiBeck

variable ordering heuristic chooses pair activities resource
sequence. Texture-based heuristics (Beck & Fox, 2000) used identify resource
time point maximum contention among activities choose pair
unordered activities, branching two possible orders. heuristic randomized
specifying hresource, time pointi pair chosen uniform probability
top 10% critical pairs. starting search elite solution, heuristic
used choose pair activities sequenced, ordering found solution
asserted. standard constraint propagation techniques scheduling (Nuijten, 1994;
Laborie, 2003; Le Pape, 1994) used algorithms.
3.3 Results
fully crossed experimental design implemented, consisting four factors (|e|, p, seq,
bt) total 120 cells (6 5 2 2). cell result 10 runs
20 problem instances, time limit run 20 minutes. results
generated 333 CPU days.
Analysis variance (ANOVA) MRE 1200 seconds shows factors
interactions significant p 0.005. ANOVA shown Table 1.
Factor(s)
e
p
bt
seq
e:p
e:bt
p:bt
e:seq
p:seq
bt:seq
e:p:bt
e:p:seq
e:bt:seq
p:bt:seq
e:p:bt:seq
Residuals

Df
5
4
1
1
20
5
4
5
4
1
20
20
5
4
20
23880

Sum Sq
0.9995
21.9376
0.8626
0.4924
0.3735
0.1144
0.3023
0.1359
0.2265
0.0036
0.0372
0.0503
0.0041
0.0078
0.0105
3.8821

Mean Sq
0.1999
5.4844
0.8626
0.4924
0.0187
0.0229
0.0756
0.0272
0.0566
0.0036
0.0019
0.0025
0.0008
0.0020
0.0005
0.0002

F value
1229.6015
33736.2277
5306.1350
3028.6761
114.8711
140.7780
464.9442
167.1942
348.3872
22.1468
11.4361
15.4859
5.0191
12.0281
3.2147

Pr(>F)
< 2.2e-16
< 2.2e-16
< 2.2e-16
< 2.2e-16
< 2.2e-16
< 2.2e-16
< 2.2e-16
< 2.2e-16
< 2.2e-16
2.540e-06
< 2.2e-16
< 2.2e-16
0.0001342
9.144e-10
1.547e-06

Table 1: Summary analysis variance found using R statistical package (R
Development Core Team, 2006). factors interactions significant
p 0.005.

attain detailed view results, Tukey HSD test (R Development Core
Team, 2006) performed factors. Tukey HSD allows comparison multiple means controlling problems multiple testing. Table 2 shows
that, significance level p 0.005:
Smaller |e| significantly better larger |e|.
56

fiSolution-Guided Multi-Point Constructive Search

p = 0 p = 0.25 significantly different. However, result
significantly lower MRE p = 0.50. p > 0.25, smaller value p better.
Luby fail limit sequence significantly better Poly sequence.
Chronological backtracking significantly better LDS.
|e|
p
seq
bt

1 < 4 < 8 < 12 < 16 < 20
{0, 0.25} < 0.50 < 0.75 < 1.00
Luby < Poly
chron < lds

Table 2: results independent Tukey HSD tests factor. Significance level
test parameter p 0.005. < b means incurs lower MRE
b, difference MRE values statistically significant. Parenthesis
(i.e., {}) indicate statistically significant difference MRE.
Finally, Table 3 presents five best five worst parameter settings determined
MRE 1200 CPU seconds. interesting note five worst settings
p = 1.00, corresponds pure randomized restart algorithm.
|e|

p
BT
Seq.
MRE
Five Best Parameter Settings
1 0.25 chron Luby 0.03158449
4 0.25 chron Luby 0.03308468
1 0.25 chron Poly 0.03328429
4 0.50 chron Luby 0.03390888
1 0.50 chron Poly 0.03421443
Five Worst Parameter Setting
4 1.00 chron Poly 0.12637893
20 1.00 chron Poly 0.12645527
1 1.00 chron Poly 0.12651117
12 1.00 chron Poly 0.12653876
8 1.00 chron Poly 0.12711269

Table 3: best worst parameter combinations Experiment 1 based MRE.
graphical representation results experiment impractical. However,
statistical analysis based performance set parameter values 1200
seconds, evolution performance time reflected results.
Given arbitrariness 1200 second time limit, valid question wonder
results would change given different limit. address concern provide
graphical sense results, present graphs experimental results one
parameter varied others held best values. parameters
two values (i.e., seq bt) display results two different values |e| well.
Elite Set Size: |e| Figure 1 shows results varying elite set size
parameter settings follows: p = 0.25, seq = Luby, bt = chron. differences
57

fiBeck

various levels |e| conclusion lower |e| results better performance
seen hold time limits less 1200 seconds. fact, superiority
algorithms small |e| visible early search; 200 seconds,
gaps among algorithms begin narrow.
0.2

SGMPCS |e|=20 (p=0.25, seq=luby, bt=chron)
SGMPCS |e|=16 (p=0.25, seq=luby, bt=chron)
SGMPCS |e|=12 (p=0.25, seq=luby, bt=chron)
SGMPCS |e|=8 (p=0.25, seq=luby, bt=chron)
SGMPCS |e|=4 (p=0.25, seq=luby, bt=chron)
SGMPCS |e|=1 (p=0.25, seq=luby, bt=chron)

Mean Relative Error

0.15

0.1

0.05

0

0

200

400

600
Time (secs)

800

1000

1200

Figure 1: mean relative error SGMPCS set makespan JSPs size
elite set varied.
Given importance diversity elite solution sets within metaheuristic literature, performance algorithms elite size 1 somewhat surprising
seems contradict original intuitions motivations SGMPCS.
return point Experiment 2.
Probability Search Empty Solution: p Figure 2 displays results
varying p holding parameter values constant |e| = 1, seq = Luby,
bt = chron. dramatic result performance p = 1.00, pure
randomized restart technique. settings p result performance
order magnitude4 better p = 1.00.
Unlike experiments |e| values, observe change relative
strengths different parameter settings different time limits. p = 0.25
results best performance time limits, low limits p = 0 appears out-perform
p = 0.50 p = 0.75. Later, latter two parameter values result better performance
p = 0. Note apparent contradiction statistical significance findings
4. MRE value achieved p = 1.00 1200 seconds achieved p values less 100
seconds.

58

fiSolution-Guided Multi-Point Constructive Search

0.2

SGMPCS p=1.00 (|e|=1, seq=luby, bt=chron)
SGMPCS p=0.00 (|e|=1, seq=luby, bt=chron)
SGMPCS p=0.75 (|e|=1, seq=luby, bt=chron)
SGMPCS p=0.50 (|e|=1, seq=luby, bt=chron)
SGMPCS p=0.25 (|e|=1, seq=luby, bt=chron)

Mean Relative Error

0.15

0.1

0.05

0

0

200

400

600
Time (secs)

800

1000

1200

Figure 2: mean relative error varying p-values SGMPCS makespan JSPs.
Table 2 explained fact interaction among parameters
p = 0 performs better values rest parameters.
Fail Sequence: seq Plots comparing two different fail sequences shown Figure
3 p = 0.25, bt = chron, two different |e| values, |e| = 1 |e| = 4.
run-times less 100 CPU seconds, Poly fail sequence performs better
Luby sequence conditions. threshold, Luby performs better.
Backtracking Method: bt Finally, Figure 4 displays result varying backtracking method parameters p = 0.25, seq = luby, |e| = 1 |e| = 4. Using
chronological backtracking problems clearly results superior performance
time limits compared LDS.
3.4 Summary
experiment demonstrates job shop scheduling makespan minimization,
best-performing parameter settings SGMPCS are: small elite set, relatively low
probability starting search empty solution, Luby fail limit sequence,
chronological backtracking. general, results robust changes time limit
placed runs.
One careful interpreting results number reasons.
1. shown ANOVA, parameters statistically significant interactions,
directly seen performance p = 0, |e| = 1 Figure 2.
59

fiBeck

0.2

SGMPCS poly, |e|=4 (p=0.25, bt=chron)
SGMPCS luby, |e|=4 (p=0.25, bt=chron)
SGMPCS poly, |e|=1 (p=0.25, bt=chron)
SGMPCS luby, |e|=1 (p=0.25, bt=chron)

Mean Relative Error

0.15

0.1

0.05

0

0

200

400

600
Time (secs)

800

1000

1200

Figure 3: mean relative error makespan JSPs two different fail sequences
|e| = 1 |e| = 4.

2. statistically significant effect factors, exception
poor performance p = 1.00, performance different parameter settings
displayed graphs wildly varying. differences among
levels different factors may statistically significant, may practically
significant. advantage SGMPCS suggests fine tuning
parameters really necessary: SGMPCS somewhat robust sense
small changes parameters result small changes performance (again,
exception p = 1.00).
3. results presented based single problem, job shop scheduling
makespan minimization. comment applicability results
problems Section 6.2.

4. Experiment 2: Impact Elite Set Diversity
SGMPCS designed number intuitions impact diversity performance likely effect different parameter settings performance. particular,
test following intuitions:
higher |e| tend result higher diversity. strict relationship
possible solutions e identical.
60

fiSolution-Guided Multi-Point Constructive Search

0.2

SGMPCS lds, |e|=4 (p=0.25, seq=luby)
SGMPCS lds, |e|=1 (p=0.25, seq=luby)
SGMPCS chron, |e|=4 (p=0.25, seq=luby)
SGMPCS chron, |e|=1 (p=0.25, seq=luby)

Mean Relative Error

0.15

0.1

0.05

0

0

200

400

600
Time (secs)

800

1000

1200

Figure 4: mean relative error using Luby fail limit either chronological backtracking LDS makespan JSPs.

higher p value tend increase diversity. Since higher p increases proportion searches empty solution, lead wider exploration
search space therefore diverse elite set.
extent exploitation multiple points search space important
SGMPCS reflected performance sets different levels
diversity. is, important simultaneously share search effort among
number regions search space, would expect higher levels diversity
would out-perform lower levels threshold diminishing returns.
4.1 Measuring Diversity
disjunctive graph (Pinedo, 2005) standard representation job shop scheduling
problem activity node precedence constraints relating activities
job directed, conjunctive arcs. pair activities different jobs
resource, disjunctive arc: arc directed either
way. solution, disjunctive arc must oriented one direction graph
(which contains conjunctive arcs) acyclic.
Following work Watson, Beck, Howe, Whitley (2003), measure diversity
elite pool mean pair-wise disjunctive graph distance. binary variable
introduced disjunctive constraint one value represents one orientation
arc value, opposite orientation. solution problem therefore
61

fiBeck

represented assignment disjunctive graph variables. distance
pair solutions simply Hamming distance disjunctive graph
variable assignments. given elite set, take mean pair-wise distance measure
diversity.
Clearly, measure well-formed |e| = 1. assume diversity
elite set size 1 0.
4.2 Initial Evaluation Diversity
initial evaluation diversity simply measure diversity problem instances subset parameter values used Experiment 1. SGMPCS solver
instrumented calculated pair-wise Hamming distance whenever new solution
inserted elite set.
Figure 5 displays diversity elite set time different elite set sizes.
expected, higher elite set size results higher diversity. However, interesting
note stability diversity: first 100 seconds, diversity set changes
little, quality solutions (see Figure 1) continues improve.
1200

Mean Pair-wise Hamming Distance

1000

800

SGMPCS |e| = 20 (p=0.25, seq=luby, bt=chron)
SGMPCS |e| = 16 (p=0.25, seq=luby, bt=chron)
SGMPCS |e| = 12 (p=0.25, seq=luby, bt=chron)
SGMPCS |e| = 8 (p=0.25, seq=luby, bt=chron)
SGMPCS |e| = 4 (p=0.25, seq=luby, bt=chron)

600

400

200

0

0

200

400

600
Time (secs)

800

1000

1200

Figure 5: diversity measured mean pair-wise Hamming distance among solutions
elite set different elite set sizes.
Figure 6 shows diversity changing p values. Contrary expectations,
higher p values exhibit lower diversity. analysis shows primary cause
pattern way elite solutions replaced. search starts
elite solution, improved solution replaces starting solution. fail
limit relatively low, starting solution is, high probability, also closest
62

fiSolution-Guided Multi-Point Constructive Search

elite solution improved solution. Therefore, replacing starting elite solution
relatively small impact overall diversity. contrast, search starts
empty solution, worst elite solution replaced improved solution.
demonstrate below, difference replacement policy results significantly lower elite
pool diversity searches start empty solution: diversity decreases
increasing p.
1200

Mean Pair-wise Hamming Distance

1000

800

600
SGMPCS p = 0.00 (|e|=4, seq=luby, bt=chron)
SGMPCS p = 0.25 (|e|=4, seq=luby, bt=chron)
SGMPCS p = 0.50 (|e|=4, seq=luby, bt=chron)
SGMPCS p = 0.75 (|e|=4, seq=luby, bt=chron)
SGMPCS p = 1.00 (|e|=4, seq=luby, bt=chron)

400

200

0

0

200

400

600
Time (secs)

800

1000

1200

Figure 6: diversity measured mean pair-wise Hamming distance among solutions
elite set values p.

4.3 Manipulating Diversity
Motivated interpretation results Figure 6, section experiment
manipulation diversity changing elite solution replacement rule. Three
levels diversity defined follows:
Low Diversity: Regardless whether search starts elite solution empty
solution, improved solution replaces worst elite one. distance-based criteria
used. initialization phase, follow approach used above: 50
elite solutions independently generated without constraining makespan,
|e| best solutions inserted elite set.
Medium Diversity: standard elite set replacement rules used Experiment 1
defined Section 2 used.
63

fiBeck

High Diversity: search starts empty solution, closest elite solution
replaced improving solution found. search starts elite solution, starting solution replaced. noted above, latter rule results
replacement closest solution high probability. Therefore, two rules
almost always equivalent replacing closest solution. initialization
phase, |e| solutions generated inserted elite pool. Then, additional
50 |e| solutions generated and, one solutions better worst
elite solution, new solution inserted elite set, replacing closest elite
solution.
verify manipulations indeed affect diversity elite set expected,
conduct initial experiment subset parameter space. Using problem
instances Experiment 1 hardware software configurations, solved
problem instance 10 times diversity condition varying |e| p.
Rather fully crossed experiment, set |e| = 4 varied p 0 1,
set p = 0.25 varied |e| 4 20.
Figures 7 8 demonstrate manipulations affect diversity
elite set expected. show different diversity levels two |e| values
two p values displaying data impractical. interesting note
high low diversity conditions, effect diversity parameters disappears:
little variation diversity |e| p varied two diversity
conditions.
1200

Mean Pair-wise Hamming Distance

1000

800

High: |e| = 8 (p=0.25, seq=luby, bt=chron)
High: |e| = 4 (p=0.25, seq=luby, bt=chron)
Medium: |e| = 8 (p=0.25, seq=luby, bt=chron)
Medium: |e| = 4 (p=0.25, seq=luby, bt=chron)
Low: |e| = 8 (p=0.25, seq=luby, bt=chron)
Low: |e| = 4 (p=0.25, seq=luby, bt=chron)

600

400

200

0

0

200

400

600
Time (secs)

800

1000

1200

Figure 7: diversity measured mean pair-wise Hamming distance among solutions
elite set different diversity levels |e| = 4 |e| = 8.

64

fiSolution-Guided Multi-Point Constructive Search

1200

Mean Pair-wise Hamming Distance

1000

800
High: p = 0.00 (|e|=4, seq=luby, bt=chron)
High: p = 0.25 (|e|=4, seq=luby, bt=chron)
Medium: p = 0.00 (|e|=4, seq=luby, bt=chron)
Medium: p = 0.25 (|e|=4, seq=luby, bt=chron)
Low: p = 0.00 (|e|=4, seq=luby, bt=chron)
Low: p = 0.25 (|e|=4, seq=luby, bt=chron)

600

400

200

0

0

200

400

600
Time (secs)

800

1000

1200

Figure 8: diversity measured mean pair-wise Hamming distance among solutions
elite set different diversity levels p = 0 p = 0.25.

4.4 Experimental Details
verified indeed three different diversity settings, test
impact different diversity levels performance SGMPCS. perform fully
crossed experiment three independent variables: |e| which, above, takes values
{1, 4, 8, 12, 16, 20}; p which, above, takes values {0, 0.25, 0.5, 0.75, 1}; diversity
(div) taking values low, medium, high corresponding manipulations described
above. conditions, use chronological backtracking Luby fail limit sequence.
experimental details including problem instances, hardware software,
1200 CPU second time limit, heuristics propagators, evaluation criteria
(MRE) Experiment 1 (see Section 3.2).
4.5 Results
fully crossed experimental design results 90 cells (6 5 3). cell result
10 runs 20 problem instances 20 minute time limit. results
generated 250 CPU days.
summary analysis variance shown Table 4. results demonstrate
factors interactions significant p 0.005. Tukey HSD test (R
Development Core Team, 2006) significance level p 0.005 done
factors, results summarized Table 5. Tukey HSD results indicate that:
65

fiBeck

Experiment 1, lower |e| better, though case significant
difference |e| = 1 |e| = 4.
p = 0 significantly worse p = 0.50 turn significantly worse
p = 0.25. Recall Experiment 1, p = 0 significantly different
p = 0.25.
Lower diversity better medium turn better high diversity.
Factor(s)
e
p
div
e:p
e:div
p:div
e:p:div
Residuals

Df
5
4
2
20
10
8
40
17910

Sum Sq
0.0709
21.4690
0.0706
0.0584
0.0234
0.0563
0.0186
3.1008

Mean Sq
0.0142
5.3673
0.0353
0.0029
0.0023
0.0070
0.0005
0.0002

F value
81.9130
31000.5636
204.0232
16.8679
13.4938
40.6166
2.6925

Pr(>F)
< 2.2e-16
< 2.2e-16
< 2.2e-16
< 2.2e-16
< 2.2e-16
< 2.2e-16
4.298e-08

Table 4: Summary analysis variance found using R statistical package (R
Development Core Team, 2006). factors interactions significant
p 0.005.

|e|
p
div

{1, 4} < 8 < {12, 16} < 20
0.25 < 0.50 < 0 < 0.75 < 1.00
low < medium < high

Table 5: results independent Tukey tests factor diversity experiment.
Significance level test parameter p 0.005.
Finally, Table 6 presents parameter values result five lowest five
highest MRE results. Note previous best set parameter values (|e| = 1, p = 0.25,
div = med) incurs slightly worse MRE |e| = 4, p = 0.25, div = low.
4.6 Summary
experiment diversity addressed number intuitions:
expected, larger elite set results higher elite set diversity.
Contrary expectations, higher probability searching empty solution
decreases diversity. able show impact directly due
p value rather different elite set replacement rules.
Finally, importantly, appears diversity elite set negatively
correlated performance: lower diversity, higher performance.
66

fiSolution-Guided Multi-Point Constructive Search

|e|
p
Div
MRE
Five Best Parameter Settings
4 0.25 low
0.03085739
1 0.25 med 0.03158449
8 0.25 low
0.03224803
16 0.25 low
0.03231168
12 0.25 low
0.03233298
Five Worst Parameter Setting
20 1.00 med 0.12482888
8 1.00 low
0.12484571
1 1.00 low
0.12487085
12 1.00 med 0.12488335
16 1.00 low
0.12489075

Table 6: Best worst parameters diversity experiments.
result calls question extent SGMPCS performance based
exploiting multiple points search space. exploitation important
performance, would expect higher diversity out-perform lower diversity.
return question Section 6.

5. Experiment 3: Benchmark Comparison Techniques
first two experiments concentrated providing basic data performance
different parameter settings SGMPCS initial inquiry reasons underlying
SGMPCS performance. experiment, turn comparisons SGMPCS
existing heuristic search techniques.
5.1 Experimental Details
use three sets well-known JSP benchmark problem instances (Taillard, 1993).
set contains 10 instances, different sets problems different size: 20 15,
20 20, 30 15. problems numbered 11 though 40. 5 instances
used development SGMPCS.
Five algorithms tested:
Standard chronological backtracking (Chron): non-randomized version
texture-based heuristic employed used together global constraint propagators. heuristic randomized, one run done
problem instance.
Limited Discrepancy Search (LDS): identical algorithm Chron except
backtracking LDS.
5. See http://ina2.eivd.ch/collaborateurs/etd/problemes.dir/ordonnancement.dir/ordonnancement.html
benchmark instances. best-known upper lower bounds latest summary
file website, dated 23/11/05.

67

fiBeck

Randomized Restart (Restart): randomized restart algorithm using
randomized texture-based heuristic global constraint propagators used
Experiment 1 2. backtracking restarts chronological fail
limit used Luby limit. problem instance solved 10 times.
Solution-Guided Multi-Point Constructive Search (SGMPCS): take best parameters Experiments 1 2: |e| = 4, p = 0.25, seq = Luby, bt = chron,
div = low. parameter settings, sole difference SGMPCS
Restart use elite set fact searches guided elite
solution. particular, use heuristics, propagators, fail limit sequence,
type backtracking. problem instance solved 10 times.
Iterated Simple Tabu Search (i-STS): i-STS algorithm sophisticated multiphase tabu search built model state-of-the-art i-TSAB (Nowicki & Smutnicki,
2005) goal simplifying order study various components
contribute overall performance (Watson et al., 2006). Taillard benchmarks, i-STS slightly under-performs i-TSAB terms solution quality given
equal number iterations.6 use parameters recommended7 Taillard
instances: |E| = 8, Xa = 40000, Xb = 7000, pi = pd = 0.5. full definition
parameters, see work Watson et al. (2006).
time limit run 3600 CPU seconds. experimental details,
including hardware software first four algorithms, evaluation criteria
Experiment 1 (see Section 3.2). i-STS algorithm Watson et al.s
C++ implementation run hardware algorithms, meaning
direct run-time comparison meaningful.
constructive search-based approaches (i.e., algorithms tested except
i-STS), Global Bound policy followed (see Section 2.2): whenever new best solution
found, global upper bound cost function modified one less
new best cost. particular, means Restart benefits back-propagation
cost constraint exactly way SGMPCS does.
5.2 Results
mean best makespan found problem set shown Tables 7 9.
Table 10 shows performance terms finding proving optimal makespan
problems optimal solution known.
5.2.1 Comparing Constructive Search Algorithms
20 15 problems (Table 7), SGMPCS dominates constructive algorithms,
finding lowest makespan (as judged mean makespan), one instance
(instance 14). particular, problem instances mean SGMPCS solution better
best solution found Restart. terms mean relative error, SGMPCS outperforms constructive algorithms factor 3 8.
6. previous experiments, use CPU time limit. estimated i-STS 5
7 times slower i-TSAB.
7. Jean-Paul Watson, personal communication.

68

fiSolution-Guided Multi-Point Constructive Search

Prob.
11
12
13
14
15
16
17
18
19
20
MRE

LB/UB
1323/1359
1351/1367
1282/1342
1345
1304/1339
1302/1360
1462
1369/1396
1297/1335
1318/1348
(vs. UB)

Chron
1444
1587
1401
1496
1436
1496
1597
1663
1457
1387
0.0956

LDS
1410
1411
1401
1345
1403
1424
1485
1464
1388
1390
0.0343

Restart
mean
best
1412.4
1408
1404.7
1402
1388.6
1385
1378.5
1370
1432.2
1427
1416.2
1408
1509.0
1507
1459.9
1456
1393.5
1386
1388.1
1378
0.0389 0.0348

SGMPCS
mean
best
1387.8
1365
1377.2
1367
1352.9
1343
1345.2 1345
1375.9
1364
1373.3
1365
1472.7
1462
1423.2
1400
1349.9
1335
1361.5
1356
0.0122 0.0036

i-STS
mean
best
1366.6
1365
1376.3
1375
1349.7
1347
1345
1345
1350.2
1342
1362.3
1362
1467.8
1464
1407.1
1404
1339.2
1335
1355.3
1350
0.0049 0.0026

Table 7: Results Taillards 20 15 instances. Bold entries indicate best performance
across five algorithms instance. Restart, SGMPCS, i-STS,
use mean makespan performance measure. also include best
makespan found algorithms solve instance multiple times.
indicates optimal makespan found proved problem
instance. final row shows mean relative error (relative best-known
upper bound) algorithm.

interesting note similar performance LDS Restart. observe
using dynamic variable ordering, LDS performs partial restarts jumping
top tree introduce discrepancy. suggests performance
LDS dynamic variable orderings may due exploitation heavy-tails
phenomenon. similar results JSP instances section support
idea. knowledge relationship commented before.

Prob.
21
22
23
24
25
26
27
28
29
30
MRE

LB/UB
1539/1644
1511/1600
1472/1557
1602/1646
1504/1595
1539/1645
1616/1680
1591/1603
1514/1625
1473/1584
(vs. UB)

Chron
1809
1689
1657
1810
1685
1827
1827
1778
1718
1666
0.0793

LDS
1699
1659
1620
1676
1669
1723
1755
1645
1678
1659
0.0373

Restart
mean
best
1694.5
1686
1654.0
1649
1614.2
1602
1697.5
1694
1673.1
1664
1706.9
1701
1754.6
1750
1663.7
1656
1665.5
1660
1646.5
1641
0.0366 0.0324

SGMPCS
mean
best
1665.7
1649
1632.1
1621
1571.4
1561
1663.9
1652
1619.6
1608
1669.4
1656
1715.6
1706
1628.1
1619
1642.2
1626
1606.9
1598
0.0146 0.0072

i-STS
mean
best
1648.0
1647
1614.1
1600
1560.2
1557
1653.2
1647
1599.3
1595
1653.3
1651
1690.0
1687
1617.4
1614
1628.0
1627
1587.2
1584
0.0044 0.0019

Table 8: Results Taillards 20 20 instances. See caption Table 7.
Table 8 displays results 20 20 problems. Again, SGMPCS dominates
constructive algorithms, finding mean makespan better best
makespan found constructive techniques. SGMPCS unable find
69

fiBeck

solutions good best-known upper bound instances. terms
MRE, SGMPCS out-performs algorithms factor 3 5.

Prob.
31
32
33
34
35
36
37
38
39
40
MRE

LB/UB
1764
1774/1795
1778/1791
1828/1829
2007
1819
1771
1673
1795
1631/1674
(vs. UB)

Chron
2118
2163
2138
2096
2110
2411
2018
2005
2118
2106
0.190

LDS
1912
1975
1987
1989
2007
1964
1947
1853
1904
1870
0.0832

Restart
mean
best
1896.8
1888
1983.1
1978
2021.6
2015
1968.4
1962
2007.0 2007
1957.1
1949
1940.3
1935
1822.0
1817
1896.1
1881
1859.4
1855
0.0813 0.0776

SGMPCS
mean
best
1774.0
1766
1828.3
1804
1840.9
1814
1863.9
1833
2007.0 2007
1832.7 1819
1810.6
1787
1701.7
1691
1803.5 1795
1714.7
1690
0.0147 0.0051

i-STS
mean
best
1764.0
1764
1813.4
1804
1804.2
1799
1831.9
1831
2007.0
2007
1819.7
1819
1791.1
1778
1675.7
1673
1799.3
1797
1689.4
1686
0.0044 0.0022

Table 9: Results Taillards 30 15 instances. See caption Table 7.
Table 9 displays results largest problem instances (30 15). instances
one, mean solution found SGMPCS better best solution
constructive algorithms. instance 35, SGMPCS equals performance
LDS Restart finding (and, cases, proving) optimal solution. Overall,
SGMPCS factor 5 13 better terms MRE.
Prob.
14
17
31
35
36
37
38
39

Opt.
1345
1462
1764
2007
1819
1771
1673
1795

Chron
0(0)
0(0)
0(0)
0(0)
0(0)
0(0)
0(0)
0(0)

LDS
10(10)
0(0)
0(0)
10(0)
0(0)
0(0)
0(0)
0(0)

Restart
0(0)
0(0)
0(0)
10(2)
0(0)
0(0)
0(0)
0(0)

SGMPCS
9(9)
1(0)
0(0)
10(4)
1(1)
0(0)
0(0)
3(3)

i-STS
10(0)
0(0)
10(10)
10(0)
8(0)
0(0)
1(1)
0(0)

Table 10: Results Taillard instances optimal solution known.
first two columns problem index optimal makespan respectively.
rest columns number runs algorithm found
optimal solution and, parenthesis, number times proved optimality. Recall Chron LDS run per instance
stochastic. However, provide fair basis comparison, present
results assuming produced identical results ten runs per instance.
i-STS complete algorithm, structural characteristics solution imply optimality (Nowicki & Smutnicki, 1996).
solution characteristic found, i-STS able prove optimality
shown two instances: tai31 tai38.

70

fiSolution-Guided Multi-Point Constructive Search

Finally, Table 10 presents number runs algorithm able find
prove optimal solutions problem instances known optimal. SGMPCS
finds optimal solution least five instances proves optimality least
four instances. Chron unable find prove optimality instances,
Restart one instance, LDS able find optimal solution
two instances prove one.
5.2.2 SGMPCS vs. i-STS
almost instances Tables 8 9 i-STS performs substantially better SGMPCS. many cases, mean solution found i-STS better best found
SGMPCS. However, seven ten smallest instances (Table 7), best solution
found SGMPCS good better found i-STS, SGMPCS strictly
better five instances. larger problems, however, mean makespan found
i-STS better found SGMPCS instances.
Recall algorithm run 3600 CPU seconds. include
graphs run-time distributions, observed performance gap terms
MRE SGMPCS i-STS 3600 seconds present time points 60
seconds. words, i-STS substantially out-performs SGMPCS first 60 seconds
thereafter algorithms find better solutions rate.
Table 10 shows one area SGMPCS clearly superior i-STS
proving optimality solutions. i-STS complete algorithm, identify
solutions particular structure optimal (Nowicki & Smutnicki, 1996). SGMPCS
able find prove optimality within time limit four instances least one run
i-STS two instances.
5.3 Summary
30 problem instances used experiment, mean solution found SGMPCS
better best solution found constructive techniques 28
instances. remaining instances, SGMPCS performs well LDS Restart
instance 35 slightly worse LDS instance 14. Overall, terms mean
relative error, SGMPCS 3 13 times better constructive search
algorithms different problem sets.
SGMPCS perform well i-STS terms mean makespan; however,
smaller problems best solution able find better i-STS five
instances.

6. Discussion Future Work
paper demonstrates Solution-Guided Multi-Point Constructive Search significantly out-perform existing constructive search techniques solving hard combinatorial
search problems trails behind state-of-the-art metaheuristic search. section, present preliminary ideas regarding reasons observed performance,
discussion generality SGMPCS, directions extensions SGMPCS.
71

fiBeck

6.1 SGMPCS Work?
extent SGMPCS out-performs existing constructive search approaches solving hard combinatorial search problems, interesting question arising
experiments understanding reasons strong performance. speculate
three, non-mutually exclusive, candidates: exploitation heavy-tails,
impact revisiting previous high-quality solutions, use multiple elite solutions.
6.1.1 Exploiting Heavy-Tails
SGMPCS restart-based algorithm. Even p = 0, search periodically restarts, albeit
value ordering based elite solution. believe likely, therefore,
SGMPCS exploits heavy-tailed distributions much way randomized restart
(Gomes et al., 2005; Gomes & Shmoys, 2002).
One way test idea reproduce Gomes et al.s original experiment SGMPCS
follows: random variable ordering, solve problem instance optimality starting
given sub-optimal solution, s, record search effort involved; repeat k different random variable orderings large k; finally observe frequency distribution
search effort. whole experiment repeated different starting solutions.
resulting distributions exhibit heavy-tailed behaviour, reasons randomized
restart able take advantage heavy-tailed distributions may shared SGMPCS.
currently pursuing experiment.
6.1.2 Revisiting Solutions
believe likely experiment suggested Section 6.1.1 demonstrate
SGMPCS takes advantage heavy-tailed distributions, significant performance
advantage SGMPCS Restart Experiment 3 well poor performance
p = 1 parameter setting Experiments 1 2, lead us expect
additional factors needed account performance SGMPCS.
believe leading candidate one additional factors impact
revisiting high-quality solutions using different variable ordering. time elite
solution revisited different variable ordering, different search tree created.
resource-limited chronological search visit nodes deep tree resource
limit reached. However, different variable ordering results different set nodes
deep tree are, therefore, within reach search. 8 strong results
SGMPCS |e| = 1 may indication mechanism responsible strong
performance sampling solutions close elite solution different search trees.
primary direction future research formalize meaning close within
search tree provide firm empirical foundation investigate impact
revisiting solutions. hope adapt significant work fitness-distance correlation
(Hoos & Stuzle, 2005) local search literature constructive search.

8. Similar reasoning applies use LDS.

72

fiSolution-Guided Multi-Point Constructive Search

6.1.3 Exploiting Multiple Points Search Space
use multiple solutions and, specifically, balance intensification
diversification viewed important metaheuristic literature (Rochat
& Taillard, 1995). Intensification suggests searching region good solutions
diversification suggests searching areas searched before. Furthermore,
one important aspects metaheuristics based elite solutions
diversity elite set maintained (Watson, 2005).
However, experiments presented suggest increased diversity
important factor performance SGMPCS. best performance achieved
small elite set sizes even, Experiment 1, elite set size 1. Based
results, original motivations SGMPCS are, say least, suspect.
results may due idiosyncrasies makespan JSP problem. experiments problems (see below) directly manipulated diversity,
results indicated better relative performance larger elite set sizes observed
here. may indication problems see positive contribution
maintaining multiple viewpoints.
speculative note, closer look Figure 1 may show diversity play
role search performance. figure shows greatest differences performance
different elite set sizes comes early search, relatively easy find
improving solution. Later search, performance difference narrows, though
close completely within time limit. One interpretation pattern that, early
search, relatively easy improve upon existing elite solutions, large elite
pool distracts search guiding elite solution significantly worse
best elite solution. narrowing performance gap may simply due
fact that, better solutions, harder improve upon regardless
size elite set, rate improvement decrease. Since algorithms
lower |e| better solutions, rate slows earlier. alternative explanation
maintaining multiple elite solutions positive influence initial
easy phase search. better solutions harder find, diverse elite set
may help search probability least one elite solutions better
solution vicinity rises elite set size. 9 experimentation required
investigate intuitions.
6.2 Generality
SGMPCS general technique conducting constructive search: nothing SGMPCS
framework specific scheduling constraint programming. However, paper
one type problem used evaluate SGMPCS therefore question practical
utility generality addressed.
Existing work shows SGMPCS effectively applied optimization
satisfaction problems quasigroup-with-holes completion (Beck, 2005b; Heckman &
Beck, 2006), job shop scheduling objective minimize weighted tardiness (Beck,
2006), multi-dimensional knapsack optimization (Heckman & Beck, 2007). addi9. explanation accurate, adaptive strategy |e| growing search might worth
investigating.

73

fiBeck

tion, recent work Sellmann Ansotegui (2006) demonstrates good performance
closely related technique diagonally ordered magic squares SAT instances.
However, SGMPCS performs worse randomized restart (though better chronological backtracking) magic square instances, randomized restart SGMPCS
perform much worse chronological backtracking satisfaction version multidimensional knapsack problem (Heckman & Beck, 2006).
application SGMPCS variety problems demonstrates indeed
general technique whose impact applied beyond job shop scheduling.
time, negative results problems point lack understanding
mechanisms behind SGMPCS performance motivates future work.
6.3 Extending SGMPCS
immediate focus future work understanding reasons performance, number ways framework extended.
First, implied speculations regarding impact diversity Section 6.1.3,
dynamic parameter learning (Horvitz et al., 2001) would appear useful SGMPCS
framework. example, one could imagine adapting p search depending
relative success searching empty solution versus searching elite solution.
Second, given metaheuristics community working elite solutions
number years, number techniques may fruitfully extend SGMPCS. example, path relinking (Glover, Laguna, & Marti, 2004) pair elite solutions
taken end-points local search trajectory. Path relinking elegant counterpart
SGMPCS: two elite solutions chosen, variable assignments common
fixed, defining sub-space variable assignments two solutions differ.
Unlike path relinking local search, constructive search one perform complete search sub-space post no-good removing sub-space future
consideration. preliminary experiments approach appear promising.
Third, clause learning techniques, originated conflict learning constraint
programming (Prosser, 1993), widely used restart state-of-the-art satisfiability
solvers (Huang, 2007). seems natural investigate combining conflict learning
solution-guidance. techniques may interesting relationship former tries
learn mistakes led dead-end latter attempts heuristically
identify correct decisions made.
Finally, work loosely coupled hybrid search techniques share single solutions
(Carchrae & Beck, 2005) easily generalizable share set solutions. date, rather
able exploit full solution shared technique, constructive search
able use bound cost function. Therefore, revisiting solutions
provides way exploit much richer information (i.e., full solutions) available
hybrid search technique.

7. Conclusion
paper presents first fully crossed study Solution-Guided Multi-Point Constructive Search. Using set job shop scheduling problems, varied SGMPCS parameter
settings control size elite set, probability searching empty so74

fiSolution-Guided Multi-Point Constructive Search

lution, fail sequence, form backtracking, diversity level elite set.
Experiments indicated low elite set sizes, low probability searching empty
solution, Luby fail sequence, chronological backtracking, low diversity lead
best performance. compared best SGMPCS parameters found existing constructive search techniques state-of-the-art tabu search algorithm well-known
set benchmark problems. results demonstrated SGMPCS significantly outperforms chronological backtracking, limited discrepancy search, randomized restart
out-performed tabu search algorithm.
primary contribution paper introduction new search framework
demonstration significantly out-perform existing constructive search
techniques. Secondary contributions include demonstration impact elite set
diversity performance opposite expected (i.e., low diversity leads
higher performance) identification research directions reasons underlying
performance SGMPCS focusing quantification effects heavy-tails,
impact revisiting solutions different variable orderings, exploitation
multiple points search space.

Acknowledgments
research supported part Natural Sciences Engineering Research
Council ILOG, S.A. Thanks Jean-Paul Watson, Daria Terekhov, Tom Carchrae,
Ivan Heckman, Lei Duan comments early versions paper. preliminary
version parts work previously published (Beck, 2006).

References
Beck, J. C. (2005a). Multi-point constructive search. Proceedings Eleventh International Conference Principles Practice Constraint Programming (CP05),
pp. 737741.
Beck, J. C. (2005b). Multi-point constructive search: Extended remix. Proceedings
CP2005 Workshop Local Search Techniques Constraint Satisfaction, pp. 1731.
Beck, J. C. (2006). empirical study multi-point constructive search constraintbased scheduling. Proceedings Sixteenth International Automated Planning
Scheduling (ICAPS06), pp. 274283.
Beck, J. C., & Fox, M. S. (2000). Dynamic problem structure analysis basis
constraint-directed scheduling heuristics. Artificial Intelligence, 117 (1), 3181.
Carchrae, T., & Beck, J. C. (2005). Applying machine learning low knowledge control
optimization algorithms. Computational Intelligence, 21 (4), 372387.
Dilkina, B., Duan, L., & Havens, W. (2005). Extending systematic local search job
shop scheduling problems. Proceedings Eleventh International Conference
Principles Practice Constraint Programming (CP05), pp. 762766.
Garey, M. R., & Johnson, D. S. (1979). Computers Intractability: Guide Theory
NP-Completeness. W.H. Freeman Company, New York.
75

fiBeck

Glover, F., Laguna, M., & Marti, R. (2004). Scatter search path relinking: advances
applications. Onwubolu, G., & Babu, B. (Eds.), New Optimization Techniques
Engineering. Springer.
Gomes, C. P., Selman, B., & Kautz, H. (1998). Boosting combinatorial search
randomization. Proceedings Fifteenth National Conference Artificial Intelligence (AAAI-98), pp. 431437.
Gomes, C. P., Fernandez, C., Selman, B., & Bessiere, C. (2005). Statistical regimes across
constrainedness regions. Constraints, 10 (4), 317337.
Gomes, C., & Shmoys, D. (2002). Completing quasigroups latin squares: structured
graph coloring problem. Proceedings Computational Symposium Graph
Coloring Generalizations.
Harvey, W. D. (1995). Nonsystematic backtracking search. Ph.D. thesis, Department
Computer Science, Stanford University.
Heckman, I., & Beck, J. C. (2006). empirical study multi-point constructive search
constraint satisfaction. Proceedings Third International Workshop
Local Search Techniques Constraint Satisfaction.
Heckman, I., & Beck, J. C. (2007). empirical study multi-point constructive search
constraint satisfaction. Submitted Constraints.
Hoos, H., & Stuzle, T. (2005). Stochastic Local Search: Foundations Applications.
Morgan Kaufmann.
Horvitz, E., Ruan, Y., Gomes, C., Kautz, H., Selman, B., & Chickering, M. (2001).
bayesian approach tacking hard computational problems. Proceedings
Seventeenth Conference Uncertainty Artificial Intelligence (UAI-2001), pp.
235244.
Huang, J. (2007). effect restarts efficiency clause learning. Proceedings
Twentieth International Joint Conference Artificial Intelligence (IJCAI07),
pp. 23182323.
Hulubei, T., & OSullivan, B. (2006). impact search heuristics heavy-tailed
behaviour. Constraints, 11 (23), 159178.
Jain, A. S., & Meeran, S. (1999). Deterministic job-shop scheduling: Past, present
future. European Journal Operational Research, 113 (2), 390434.
Jussien, N., & Lhomme, O. (2002). Local search constraint propagation conflictbased heuristics. Artificial Intelligence, 139, 2145.
Kautz, H., Horvitz, E., Ruan, Y., Gomes, C., & Selman, B. (2002). Dynamic restart policies.
Proceedings Eighteenth National Conference Artifiical Intelligence (AAAI02), pp. 674681.
Laborie, P. (2003). Algorithms propagating resource constraints AI planning
scheduling: Existing approaches new results. Artificial Intelligence, 143, 151188.
Le Pape, C. (1994). Implementation resource constraints ILOG Schedule: library
development constraint-based scheduling systems. Intelligent Systems Engineering, 3 (2), 5566.
76

fiSolution-Guided Multi-Point Constructive Search

Luby, M., Sinclair, A., & Zuckerman, D. (1993). Optimal speedup Las Vegas algorithms.
Information Processing Letters, 47, 173180.
Nowicki, E., & Smutnicki, C. (1996). fast taboo search algorithm job shop problem.
Management Science, 42 (6), 797813.
Nowicki, E., & Smutnicki, C. (2005). advanced tabu algorithm job shop problem.
Journal Scheduling, 8, 145159.
Nuijten, W. P. M. (1994). Time resource constrained scheduling: constraint satisfaction approach. Ph.D. thesis, Department Mathematics Computing Science,
Eindhoven University Technology.
Pinedo, M. (2005). Planning Scheduling Manufacturing Services. Springer.
Prestwich, S. (2002). Combining scalability local search pruning techniques
systematic search. Annals Operations Research, 115, 5172.
Prosser, P. (1993). Hybrid algorithms constraint satisfaction problem. Computational
Intelligence, 9 (3), 268299.
R Development Core Team (2006). R: Language Environment Statistical Computing. R Foundation Statistical Computing, Vienna, Austria. ISBN 3-900051-07-0.
Rochat, Y., & Taillard, E. D. (1995). Probabilistic diversification intensification local
search vehicle routing. Journal Heuristics, 1, 147167.
Sellmann, M., & Ansotegui, C. (2006). Disco-novo-gogo: Integrating local search complete saerch restarts. Proceedings Twenty-First National Conference
Artificial Intelligence (AAAI06), pp. 10511056.
Taillard, E. D. (1993). Benchmarks basic scheduling problems. European Journal
Operational Research, 64, 278285.
Watson, J.-P. (2003). Empirical Modeling Analysis Local Search Algorithms
Job-Shop Scheduling Problem. Ph.D. thesis, Dept. Computer Science, Colorado
State University.
Watson, J.-P. (2005). metaheuristics failure modes: case study tabu search jobshop scheduling. Proceedings Fifth Metaheuristics International Conference.
Watson, J.-P., Barbulescu, L., Whitley, L. D., & Howe, A. E. (2002). Contrasting structured
random permutation flow-shop scheduling problems: search-space topology
algorithm performance. INFORMS Journal Computing, 14 (2), 98123.
Watson, J.-P., Beck, J. C., Howe, A. E., & Whitley, L. D. (2003). Problem difficulty
tabu search job-shop scheduling. Artificial Intelligence, 143 (2), 189217.
Watson, J.-P., Howe, A. E., & Whitley, L. D. (2006). Deconstructing Nowicki Smutnickis i-TSAB tabu search algorithm job-shop scheduling problem. Computers
Operations Research, 33 (9), 26232644.

77

fiJournal Artificial Intelligence Research 29 (2007) 153-190

Submitted 10/06; published 06/07

Generalized A* Architecture
Pedro F. Felzenszwalb

pff@cs.uchicago.edu

Department Computer Science
University Chicago
Chicago, IL 60637

David McAllester

mcallester@tti-c.org

Toyota Technological Institute Chicago
Chicago, IL 60637

Abstract
consider problem computing lightest derivation global structure using
set weighted rules. large variety inference problems AI formulated
framework. generalize A* search heuristics derived abstractions
broad class lightest derivation problems. also describe new algorithm searches
lightest derivations using hierarchy abstractions. generalization A* gives
new algorithm searching AND/OR graphs bottom-up fashion.
discuss algorithms described provide general architecture addressing pipeline problem problem passing information back forth
various stages processing perceptual system. consider examples computer vision natural language processing. apply hierarchical search algorithm
problem estimating boundaries convex objects grayscale images compare
search methods. second set experiments demonstrate use new
compositional model finding salient curves images.

1. Introduction
consider class problems defined set weighted rules composing structures
larger structures. goal problems find lightest (least cost) derivation
global structure derivable given rules. large variety classical inference
problems AI expressed within framework. example global structure
might parse tree, match deformable object model image, assignment
values variables Markov random field.
define lightest derivation problem terms set statements, set weighted
rules deriving statements using statements special goal statement.
case looking lightest derivation goal statement. usually express
lightest derivation problem using rule schemas implicitly represent large set
rules terms small number rules variables. Lightest derivation problems
formally equivalent search AND/OR graphs (Nilsson, 1980), find
formulation natural applications interested in.
One goals research construction algorithms global optimization
across many levels processing perceptual system. described algorithms
used integrate multiple stages processing pipeline single global optimization problem solved efficiently.
c
2007
AI Access Foundation. rights reserved.

fiFelzenszwalb & McAllester

Dynamic programming fundamental technique designing efficient inference algorithms. Good examples Viterbi algorithm hidden Markov models (Rabiner,
1989) chart parsing methods stochastic context free grammars (Charniak, 1996).
algorithms described used speed solution problems normally
solved using dynamic programming. demonstrate specific problem,
goal estimate boundary convex object cluttered image. second set
experiments show algorithms used find salient curves images.
describe new model salient curves based compositional rule enforces
long range shape constraints. leads problem large solved using
classical dynamic programming methods.
algorithms consider related Dijkstras shortest paths algorithm (DSP)
(Dijkstra, 1959) A* search (Hart, Nilsson, & Raphael, 1968). DSP A*
used find shortest path cyclic graph. use priority queue define order
nodes expanded worst case running time O(M log N ) N
number nodes graph number edges. DSP A*
expansion node v involves generating nodes u edge v u.
difference two methods A* uses heuristic function avoid
expanding non-promising nodes.
Knuth gave generalization DSP used solve lightest derivation
problem cyclic rules (Knuth, 1977). call Knuths lightest derivation algorithm
(KLD). analogy Dijkstras algorithm, KLD uses priority queue define order
statements expanded. expansion statement v involves generating
conclusions derived single step using v statements already
expanded. long rule bounded number antecedents KLD also worst
case running time O(M log N ) N number statements problem
number rules. Nilssons AO* algorithm (1980) also used solve
lightest derivation problems. Although AO* use heuristic function, true
generalization A* use priority queue, handles acyclic rules,
require O(M N ) time even applied shortest path problem.1 particular, AO*
variants use backward chaining technique starts goal repeatedly
refines subgoals, A* forward chaining algorithm.2
Klein Manning (2003) described A* parsing algorithm similar KLD
use heuristic function. One contributions generalization algorithm
arbitrary lightest derivation problems. call algorithm A* lightest derivation
(A*LD). method forward chaining, uses priority queue control order
statements expanded, handles cyclic rules worst case running time
O(M log N ) problems rule small number antecedents. A*LD
seen true generalization A* lightest derivation problems. lightest derivation
problem comes shortest path problem A*LD identical A*.
course running times seen practice often well predicted worst case
analysis. specially true problems large defined implicitly.
example, use dynamic programming solve shortest path problem acyclic
graph O(M ) time. better O(M log N ) bound DSP, implicit
1. extensions handle cyclic rules (Jimenez & Torras, 2000).
2. AO* backward chaining terms inference rules defining lightest derivation problem.

154

fiThe Generalized A* Architecture

graphs DSP much efficient since expands nodes best-first order.
searching shortest path source goal, DSP expand nodes v
d(v) w . d(v) length shortest path source v, w
length shortest path source goal. case A* monotone
admissible heuristic function, h(v), possible obtain similar bound searching
implicit graphs. A* expand nodes v d(v) + h(v) w .
running time KLD A*LD expressed similar way. solving
lightest derivation problem, KLD expand statements v d(v) w . d(v)
weight lightest derivation v, w weight lightest derivation
goal statement. Furthermore, A*LD expand statements v d(v) + h(v) w .
heuristic function, h(v), gives estimate additional weight necessary
deriving goal statement using derivation v. heuristic values used A*LD
analogous distance node goal graph search problem (the notion
used A*). note heuristic values significantly different ones
used AO*. case AO* heuristic function, h(v), would estimate weight
lightest derivation v.
important difference A*LD AO* A*LD computes derivations
bottom-up fashion, AO* uses top-down approach. method advantages, depending type problem solved. example, classical problem
computer vision involves grouping pixels long smooth curves. formulate
problem terms finding smooth curves pairs pixels far apart.
image n pixels (n2 ) pairs. straight forward implementation
top-down algorithm would start considering (n2 ) possibilities. bottomup algorithm would start O(n) pairs nearby pixels. case expect
bottom-up grouping method would efficient top-down method.
classical AO* algorithm requires set rules acyclic. Jimenez Torras
(2000) extended method handle cyclic rules. Another top-down algorithm
handle cyclic rules described Bonet Geffner (2005). Hansen Zilberstein (2001)
described search algorithm problems optimal solutions
cyclic. algorithms described paper handle problems cyclic rules
require optimal solutions acyclic. also note AO* handle rules
non-superior weight functions (as defined Section 3) KLD requires superior weight
functions. A*LD replaces requirement requirement heuristic function.
well known method defining heuristics A* consider abstract relaxed
search problem. example, consider problem solving Rubiks cube small
number moves. Suppose ignore edge center pieces solve corners.
example problem abstraction. number moves necessary put
corners good configuration lower bound number moves necessary solve
original problem. fewer corner configurations full configurations
makes easier solve abstract problem. general, shortest paths
goal abstract problem used define admissible monotone heuristic
function solving original problem A*.
show abstractions also used define heuristic functions A*LD.
lightest derivation problem notion shortest path goal replaced
notion lightest context, context statement v derivation
155

fiFelzenszwalb & McAllester

goal hole filled derivation v. computation lightest
abstract contexts lightest derivation problem.
Abstractions related problem relaxations defined Pearl (1984). abstractions often lead small problems solved search, relaxations lead
problems still large state space may simple enough solved closed
form. definition abstractions use lightest derivation problems includes
relaxations special case.
Another contribution work hierarchical search method call HA*LD.
algorithm effectively use hierarchy abstractions solve lightest derivation
problem. algorithm novel even case classical search (shortest paths) problem. HA*LD searches lightest derivations contexts every level abstraction
simultaneously. specifically, level abstraction set statements
rules. search lightest derivations contexts level controlled
single priority queue. understand running time HA*LD, let w weight
lightest derivation goal original (not abstracted) problem. statement v
abstraction hierarchy let d(v) weight lightest derivation v level
abstraction. Let h(v) weight lightest context abstraction v (defined
one level v hierarchy). Let K total number statements
hierarchy d(v) + h(v) w . HAL*D expands 2K statements solving
original problem. factor two comes fact algorithm computes
derivations contexts level abstraction.
Previous algorithms use abstractions solving search problems include methods based pattern databases (Culberson & Schaeffer, 1998; Korf, 1997; Korf & Felner,
2002), Hierarchical A* (HA*, HIDA*) (Holte, Perez, Zimmer, & MacDonald, 1996; Holte,
Grajkowski, & Tanner, 2005) coarse-to-fine dynamic programming (CFDP) (Raphael,
2001). Pattern databases made possible compute solutions impressively large
search problems. methods construct lookup table shortest paths node
goal abstract states. practice approach limited tables remain
fixed different problem instances, relatively small tables heuristic must
recomputed instance. example, Rubiks cube precompute
number moves necessary solve every corner configuration. table used
define heuristic function solving full configuration Rubiks cube.
HA* HIDA* use hierarchy abstractions avoid searching nodes
level hierarchy. hand, directed graphs methods may still
expand abstract nodes arbitrarily large heuristic values. also clear
generalize HA* HIDA* lightest derivation problems rules
one antecedent. Finally, CFDP related AO* repeatedly solves ever
refined problems using dynamic programming. leads worst case running time
O(N ). discuss relationships HA*LD hierarchical
methods detail Section 8.
note A* search related algorithms previously used solve
number problems classical state space search problems. includes
traveling salesman problem (Zhang & Korf, 1996), planning (Edelkamp, 2002), multiple
sequence alignment (Korf, Zhang, Thayer, & Hohwald, 2005), combinatorial problems
graphs (Felner, 2005) parsing using context-free-grammars (Klein & Manning, 2003).
156

fiThe Generalized A* Architecture

work Bulitko, Sturtevant, Lu, Yau (2006) uses hierarchy state-space abstractions real-time search.
1.1 Pipeline Problem
major problem artificial intelligence integration multiple processing stages
form complete perceptual system. call pipeline problem. general
concatenation systems stage feeds information next. vision,
example, might edge detector feeding information boundary finding system,
turn feeds information object recognition system.
computational constraints need build modules clean interfaces
pipelines often make hard decisions module boundaries. example, edge detector
typically constructs Boolean array indicates weather edge detected
image location. general recognition presence edge
certain location depend context around it. People often see edges places
image gradient small if, higher cognitive level, clear actually
object boundary location. Speech recognition systems try address problem
returning n-best lists, may may contain actual utterance. would
like speech recognition system able take high-level information account
avoid hard decision exactly strings output n-best list.
processing pipeline specified describing stages terms rules
constructing structures using structures produced previous stage. vision system
one stage could rules grouping edges smooth curves next stage could
rules grouping smooth curves objects. case construct single
lightest derivation problem representing entire system. Moreover, hierarchical set
abstractions applied entire pipeline. using HA*LD compute lightest
derivations complete scene interpretation derived one level abstraction guides
processing stages concrete level. provides mechanism enables coarse
high-level processing guide low-level computation. believe important
property implementing efficient perceptual pipelines avoid making hard decisions
processing stages.
note formulation complete computer vision system lightest derivation problem related work Geman, Potter, Chi (2002), Tu, Chen, Yuille,
Zhu (2005) Jin Geman (2006). papers image understanding posed
parsing problem, goal explain image terms set objects
formed (possibly recursive) composition generic parts. Tu et al. (2005) use
data driven MCMC compute optimal parses Geman et al. (2002) Jin
Geman (2006) use bottom-up algorithm building compositions greedy fashion.
Neither methods guaranteed compute optimal scene interpretation.
hope HA*LD provide principled computational technique solving large
parsing problems defined compositional models.
1.2 Overview
begin formally defining lightest derivation problems Section 2. section also
discusses dynamic programming relationship lightest derivation problems
157

fiFelzenszwalb & McAllester

AND/OR graphs. Section 3 describe Knuths lightest derivation algorithm.
Section 4 describe A*LD prove correctness. Section 5 shows abstractions
used define mechanically constructed heuristic functions A*LD. describe
HA*LD Section 6 discuss use solving pipeline problem Section 7. Section 8 discusses relationship HA*LD hierarchical search methods.
Sections 9 10 present experimental results. conclude Section 11.

2. Lightest Derivation Problems
Let set statements R set inference rules following form,
A1 = w1
..
.
= wn
C = g(w1 , . . . , wn )
antecedents Ai conclusion C statements , weights wi
non-negative real valued variables g non-negative real valued weight function.
rule antecedents function g simply non-negative real value. Throughout
paper also use A1 , . . . , g C denote inference rule type.
derivation C finite tree rooted rule A1 , . . . , g C n children,
i-th child derivation Ai . leaves tree rules antecedents.
Every derivation weight value obtained recursive application
functions g along derivation tree. Figure 1 illustrates derivation tree.
Intuitively rule A1 , . . . , g C says derive antecedents Ai
weights wi derive conclusion C weight g(w1 , . . . , wn ). problem
interested compute lightest derivation special goal statement.
algorithms discussed paper assume weight functions g associated lightest derivation problem non-decreasing variable.
fundamental property ensuring lightest derivations optimal substructure property. case lightest derivations constructed lightest derivations.
facilitate runtime analysis algorithms assume every rule small
number antecedents. use N denote number statements lightest derivation
problem, denotes number rules. problems interested
N large problem implicitly defined compact way,
using small number rules variables examples below. also assume
N since statements conclusion rule clearly
derivable ignored.
2.1 Dynamic Programming
say set rules acyclic ordering statements
rule conclusion C antecedents statements come C
ordering. Dynamic programming used solve lightest derivation problem
158

fiThe Generalized A* Architecture

A1
A2
A3
C

Derivation
A1

Derivation
A2

Derivation
A3

Figure 1: derivation C tree rules rooted rule r conclusion C.
children root derivations antecedents r. leafs tree
rules antecedents.

functions g rule non-decreasing set rules acyclic. case
lightest derivations computed sequentially terms acyclic ordering O.
i-th step lightest derivation i-th statement obtained minimizing rules
used derive statement. method takes O(M ) time compute
lightest derivation statement .
note cyclic rules sometimes possible compute lightest derivations
taking multiple passes statements. also note authors would refer
Dijkstras algorithm (and KLD) dynamic programming method. paper
use term referring algorithms compute lightest derivations fixed
order independent solutions computed along way (this includes recursive
implementations use memoization).
2.2 Examples
Rules computing shortest paths single source weighted graph shown
Figure 2. assume given weighted graph G = (V, E), wxy
non-negative weight edge (x, y) E distinguished start node. first
rule states path weight zero start node s. second set rules
state path node x extend path edge x
obtain appropriately weighted path node y. rule type
edge graph. lightest derivation path(x) corresponds shortest path
x. Note general graphs rules cyclic. Figure 3 illustrates graph
159

fiFelzenszwalb & McAllester

(1)

path(s) = 0
(2) (x, y) E,
path(x) = w
path(y) = w + wxy
Figure 2: Rules computing shortest paths graph.

b

c

path(d) = w

path(c) = w

path(b) = w + wdb

path(b) = w + wcb

path(s) = w

path(e) = w

path(d) = w + wsd

path(c) = w + wec



e

path(s) = w
path(s) = 0
path(e) = w + wse

path(s) = 0

Figure 3: graph two highlighted paths b corresponding derivations
using rules Figure 2.

two different derivations path(b) using rules described. corresponds
two different paths b.
Rules chart parsing shown Figure 4. assume given weighted
context free grammar Chomsky normal form (Charniak, 1996), i.e., weighted set
productions form X X Z X, Z nonterminal symbols
terminal symbol. input string given sequence terminals (s1 , . . . , sn ).
160

fiThe Generalized A* Architecture

(1) production X si ,

phrase(X, i, + 1) = w(X si )
(2) production X Z 1 < j < k n + 1,
phrase(Y, i, j) = w1
phrase(Z, j, k) = w2
phrase(X, i, k) = w1 + w2 + w(X Z)
Figure 4: Rules parsing context free grammar.
first set rules state grammar contains production X si
phrase type X generating i-th entry input weight w(X si ). second
set rules state grammar contains production X Z phrase
type j phrase type Z j k an, appropriately
weighted, phrase type X k. Let start symbol grammar.
goal parsing find lightest derivation phrase(S, 1, n + 1). rules acyclic
phrases composed together form longer phrases.
2.3 AND/OR Graphs
Lightest derivation problems closely related AND/OR graphs. Let R set
statements rules defining lightest derivation problem. convert problem
AND/OR graph representation build graph disjunction node
statement conjunction node rule R. edge statement rule deriving statement, edge rule antecedents.
leaves AND/OR graph rules antecedents. derivations
statement using rules R represented solutions rooted statement
corresponding AND/OR graph. Conversely, also possible represent AND/OR
graph search problem lightest derivation problem. case view node
graph statement build appropriate set rules R.

3. Knuths Lightest Derivation
Knuth (1977) described generalization Dijkstras shortest paths algorithm call
Knuths lightest derivation (KLD). Knuths algorithm used solve large class
lightest derivation problems. algorithm allows rules cyclic requires
weight functions associated rule non-decreasing superior. Specifically
require following two properties weight function g rule,
non-decreasing:
superior:

wi0 wi g(w1 , . . . , wi0 , . . . , wn ) g(w1 , . . . , wi , . . . , wn )
g(w1 , . . . , wn ) wi
161

fiFelzenszwalb & McAllester

example,
g(x1 , . . . , xn ) = x1 + + xn
g(x1 , . . . , xn ) = max(x1 , . . . , xn )
non-decreasing superior functions.
Knuths algorithm computes lightest derivations non-decreasing weight order. Since
interested lightest derivation special goal statement often stop
algorithm computing lightest derivation every statement.
weight assignment expression form (B = w) B statement
w non-negative real value. say weight assignment (B = w) derivable
derivation B weight w. set rules R, statement B, weight
w write R ` (B = w) rules R used derive (B = w). Let `(B, R)
infimum set weights derivable B,
`(B, R) = inf{w : R ` (B = w)}.
Given set rules R statement goal interested computing derivation
goal weight `(goal , R).
define bottom-up logic programming language easily express
algorithms wish discuss throughout rest paper. algorithm defined
set rules priorities. encode priority rule writing along
line separating antecedents conclusion follows,
A1 = w1
..
.
= wn
p(w1 , . . . , wn )
C = g(w1 , . . . , wn )
call rule form prioritized rule. execution set prioritized rules
P defined procedure Figure 5. procedure keeps track set
priority queue Q weight assignments form (B = w). Initially empty Q
contains weight assignments defined rules antecedents priorities given
rules. iteratively remove lowest priority assignment (B = w) Q. B
already assigned weight new assignment ignored. Otherwise add
new assignment expand every assignment derivable (B = w)
assignments already using rule P added Q priority specified
rule. procedure stops queue empty.
result executing set prioritized rules set weight assignments. Moreover,
procedure implicitly keep track derivations remembering assignments
used derive item inserted queue.
Lemma 1. execution finite set prioritized rules P derives every statement
derivable rules P .
Proof. rule causes one item inserted queue. Thus eventually Q
empty algorithm terminates. Q empty every statement derivable
162

fiThe Generalized A* Architecture

Procedure Run(P )
1.
2. Initialize Q assignments defined rules antecedents priorities
3. Q empty
4.
Remove lowest priority element (B = w) Q
5.
B assigned weight
6.
{(B = w)}
7.
Insert assignments derivable (B = w) assignments using
rule P Q priority specified rule
8. return
Figure 5: Running set prioritized rules.
single rule using antecedents weight already weight S. implies
every derivable statement weight S.
ready define Knuths lightest derivation algorithm. algorithm
easily described terms prioritized rules.
Definition 1 (Knuths lightest derivation). Let R finite set non-decreasing
superior rules. Define set prioritized rules K(R) setting priority rule
R weight conclusion. KLD given execution K(R).
show running K(R), (B = w) added w = `(B, R).
means assignments represent lightest derivations. also show
assignments inserted non-decreasing weight order. stop algorithm
soon insert weight assignment goal expand statements B
`(B, R) < `(goal , R) statements B `(B, R) = `(goal , R).
properties follow general result described next section.
3.1 Implementation
algorithm Figure 5 implemented run O(M log N ) time, N
refer size problem defined prioritized rules P .
practice set prioritized rules P often specified implicitly, terms small
number rules variables. case problem executing P closely related
work logical algorithms described McAllester (2002).
main difficulty devising efficient implementation procedure Figure 5
step 7. step need find weight assignments combined
(B = w) derive new weight assignments. logical algorithms work shows
set inference rules variables transformed new set rules,
every rule two antecedents particularly simple form. Moreover,
transformation increase number rules much. rules
transformed execution implemented efficiently using hashtable represent
S, heap represent Q indexing tables allow us perform step 7 quickly.
163

fiFelzenszwalb & McAllester

Consider second set rules parsing Figure 4. represented
single rule variables. Moreover rule two antecedents. executing
parsing rules keep track table mapping value j statements phrase(Y, i, j)
weight S. Using table quickly find statements weight
combined statement form phrase(Z, j, k). Similarly keep
track table mapping value j statements phrase(Z, j, k) weight
S. second table lets us quickly find statements combined statement
form phrase(Y, i, j). refer reader (McAllester, 2002) details.

4. A* Lightest Derivation
A* lightest derivation algorithm (A*LD) generalization A* search lightest
derivation problems subsumes A* parsing. algorithm similar KLD
use heuristic function speed computation. Consider lightest derivation problem
rules R goal statement goal . Knuths algorithm expand statement B
`(B, R) < `(goal , R). using heuristic function A*LD avoid expanding
statements light derivations part light derivation goal .
Let R set rules statements , h heuristic function assigning
weight statement. h(B) estimate additional weight required
derive goal using derivation B. note case shortest path problem
weight exactly distance node goal. value `(B, R) + h(B) provides
figure merit statement B. A* lightest derivation algorithm expands
statements order figure merit.
say heuristic function monotone every rule A1 , . . . , g C R
derivable weight assignments (Ai = wi ) have,
wi + h(Ai ) g(w1 , . . . , wn ) + h(C).

(1)

definition agrees standard notion monotone heuristic function rules
come shortest path problem. show h monotone h(goal ) = 0
h admissible appropriate notion admissibility. correctness
A*LD, however, required h monotone h(goal ) finite.
case monotonicity implies heuristic value every statement C appears
derivation goal finite. assume h(C) finite every statement. h(C)
finite ignore C every rule derives C.
Definition 2 (A* lightest derivation). Let R finite set non-decreasing rules h
monotone heuristic function R. Define set prioritized rules A(R) setting
priority rule R weight conclusion plus heuristic value,
g(w1 , . . . , wn ) + h(C). A*LD given execution A(R).
show execution A(R) correctly computes lightest derivations
expands statements order figure merit values.
Theorem 2. execution A(R), (B = w) w = `(B, R).
Proof. proof induction size S. statement trivial = .
Suppose statement true right algorithm removed (B = wb ) Q
164

fiThe Generalized A* Architecture

added S. fact (B = wb ) Q implies weight assignment derivable
thus wb `(B, R).
Suppose derivation B weight wb0 < wb . Consider moment right
algorithm removed (B = wb ) Q added S. Let A1 , . . . , g C
rule antecedents Ai weight conclusion C not.
Let wc = g(`(A1 , R), . . . , `(An , R)). induction hypothesis weight Ai
`(Ai , R). Thus (C = wc ) Q priority wc + h(C). Let wc0 weight assigns
C. Since g non-decreasing know wc wc0 . Since h monotone wc0 +h(C) wb0 +h(B).
follows using monotonicity condition along path C B .
note wc + h(C) < wb + h(B) turn implies (B = wb ) weight
assignment Q minimum priority.
Theorem 3. execution A(R) statements expanded order figure
merit value `(B, R) + h(B).
Proof. First show minimum priority Q decrease throughout
execution algorithm. Suppose (B = w) element Q minimum priority.
Removing (B = w) Q decrease minimum priority. suppose add
(B = w) insert assignments derivable (B = w) Q. Since h monotone
priority every assignment derivable (B = w) least priority (B = w).
weight assignment (B = w) expanded removed Q added S.
last theorem w = `(B, R) definition A(R) weight assignment
queued priority `(B, R) + h(B). Since removed (B = w) Q must
minimum priority queue. minimum priority decrease time
must expand statements order figure merit value.
accurate heuristic functions A*LD much efficient KLD.
Consider situation perfect heuristic function. is, suppose h(B)
exactly additional weight required derive goal using derivation B.
figure merit `(B, R) + h(B) equals weight lightest derivation goal uses
B. case A*LD derive goal expanding statements part
lightest derivation goal .
correctness KLD follows correctness A*LD. set non-decreasing
superior rules consider trivial heuristic function h(B) = 0. fact
rules superior imply heuristic monotone. theorems imply
Knuths algorithm correctly computes lightest derivations expands statements
order lightest derivable weights.

5. Heuristics Derived Abstractions
consider case additive rules rules weight conclusion
sum weights antecedents plus non-negative value v called weight
rule. denote rule A1 , . . . , v C. weight derivation using
additive rules sum weights rules appear derivation tree.
context statement B finite tree rules add derivation
B tree get derivation goal . Intuitively context B derivation goal
hole filled derivation B (see Figure 6).
165

fiFelzenszwalb & McAllester

...
...
goal

A1
A2
A3
context C

C

context A3

Derivation
A1

Derivation
A2

Derivation
A3

Figure 6: derivation goal defines contexts statements appear derivation tree. Note context C together rule A1 , A2 , A3 C
derivations A1 A2 define context A3 .

additive rules, context weight sum weights rules it.
Let R set additive rules statements . B define `(context(B), R)
weight lightest context B. value `(B, R) + `(context(B), R)
weight lightest derivation goal uses B.
Contexts derived using rules R together context rules c(R) defined
follows. First, goal empty context weight zero. captured rule
antecedents 0 context(goal ). rule A1 , . . . , v C R put n rules
c(R). rules capture notion context C derivations Aj j 6=
define context Ai ,
context(C), A1 , . . . , Ai1 , Ai+1 , . . . , v context(Ai ).
Figure 6 illustrates context C together derivations A1 A2 rule
A1 , A2 , A3 C define context A3 .
166

fiThe Generalized A* Architecture

say heuristic function h admissible h(B) `(context(B), R). Admissible
heuristic functions never over-estimate weight deriving goal using derivation
particular statement. heuristic function perfect h(B) = `(context(B), R).
show obtain admissible monotone heuristic functions abstractions.
5.1 Abstractions
Let (, R) lightest derivation problem statements rules R. abstraction
(, R) given problem (0 , R0 ) map abs : 0 , every rule
A1 , . . . , v C R rule abs(A1 ), . . . , abs(An ) v0 abs(C) R0 v 0 v.
show abstraction used define monotone admissible heuristic
function original problem.
usually think abs defining coarsening mapping several statements
abstract statement. example, parser abs might map lexicalized
nonterminal N Phouse nonlexicalized nonterminal N P . case abstraction
defines smaller problem abstract statements. Abstractions often defined
mechanical way starting map abs set abstract statements
0 . project rules R 0 using abs get set abstract
rules. Typically several rules R map abstract rule. need
keep one copy abstract rule, weight lower bound weight
concrete rules mapping it.
Every derivation (, R) maps abstract derivation `(abs(C), R0 )
`(C, R). let goal abstract problem abs(goal ) every context (, R)
maps abstract context see `(context(abs(C)), R0 ) `(context(C), R).
means lightest abstract context weights form admissible heuristic function,
h(C) = `(context(abs(C)), R0 ).
show heuristic function also monotone.
Consider rule A1 , . . . , v C R let (Ai = wi ) weight assignments derivable
using R. case rule abs(A1 ), . . . , abs(An ) v0 abs(C) R0 v 0 v
(abs(Ai ) = wi0 ) derivable using R0 wi0 wi . definition contexts (in
abstract problem) have,
X
`(context(abs(Ai )), R0 ) v 0 +
wj0 + `(context(abs(C)), R0 ).
j6=i

Since v 0 v wj0 wj have,
`(context(abs(Ai )), R0 ) v +

X

wj + `(context(abs(C)), R0 ).

j6=i

Plugging heuristic function h adding wi sides,
X
wi + h(Ai ) v +
wj + h(C),
j

exactly monotonicity condition equation (1) additive rule.
167

fiFelzenszwalb & McAllester

abstract problem defined (0 , R0 ) relatively small efficiently compute
lightest context weights every statement 0 using dynamic programming KLD.
store weights pattern database (a lookup table) serve heuristic
function solving concrete problem using A*LD. heuristic may able stop
A*LD exploring lot non-promising structures. exactly approach
used Culberson Schaeffer (1998) Korf (1997) solving large search
problems. results section show pattern databases used
general setting lightest derivations problems. experiments Section 10 demonstrate
technique specific application.

6. Hierarchical A* Lightest Derivation
main disadvantage using pattern databases precompute context
weights every abstract statement. often take lot time space.
define hierarchical algorithm, HA*LD, searches lightest derivations contexts
entire abstraction hierarchy simultaneously. algorithm often solve
concrete problem without fully computing context weights level abstraction.
level abstraction behavior HA*LD similar behavior A*LD
using abstraction-derived heuristic function. hierarchical algorithm queues
derivations statement C priority depends lightest abstract context
C. abstract contexts computed advance. Instead, abstract contexts
computed time computing derivations. abstract context
C, derivations C stalled. captured addition context(abs(C))
antecedent rule derives C.
define abstraction hierarchy levels sequence lightest derivation problems additive rules (k , Rk ) 0 k 1 single abstraction
function abs. 0 k < 1 abstraction function maps k onto k+1 . require (k+1 , Rk+1 ) abstraction (k , Rk ) defined previous section:
A1 , . . . , v C Rk exists rule abs(A1 ), . . . , abs(An ) v0 abs(C)
Rk+1 v 0 v. hierarchical algorithm computes lightest derivations statements
k using contexts k+1 define heuristic values. extend abs maps
m1 abstract set statements containing single element . Since abs
onto |k | |k+1 |. is, number statements decrease go
abstraction hierarchy. denote abs k abstraction function 0 k obtained
composing abs k times.
interested computing lightest derivation goal statement goal 0 . Let
goal k = abs k (goal ) goal level abstraction. hierarchical algorithm
defined set prioritized rules H Figure 7. Rules labeled compute derivations
statements one level abstraction using context weights level define
priorities. Rules labeled BASE compute contexts one level abstraction
using derivation weights level define priorities. rules labeled START1
START2 start inference handling abstract level.
execution H starts computing derivation context START1
START2. continues deriving statements m1 using rules.
lightest derivation goal m1 found algorithm derives context goal m1
168

fiThe Generalized A* Architecture

0

START1:
=0

START2:

0
context() = 0

BASE:

goal k = w
w
context(goal k ) = 0

UP:

context(abs(C)) = wc
A1 = w1
..
.
= wn
v + w1 + + wn + wc
C = v + w1 + + wn

DOWN:

context(C) = wc
A1 = w1
..
.
= wn
v + wc + w1 + + wn
context(Ai ) = v + wc + w1 + + wn wi

Figure 7: Prioritized rules H defining HA*LD. BASE rules defined 0 k 1.
rules defined rule A1 , . . . , v C Rk
0 k 1.

BASE rule starts computing contexts statements m1 using rules.
general HA*LD interleaves computation derivations contexts level
abstraction since execution H uses single priority queue.
Note computation happens given level abstraction lightest derivation goal found level above. means structure
abstraction hierarchy defined dynamically. example, CFDP algorithm,
could define set statements level abstraction refining statements
appear lightest derivation goal level above. assume static
abstraction hierarchy.
statement C k 0 k 1 use `(C) denote weight
lightest derivation C using Rk `(context(C)) denotes weight lightest
context C using Rk . abstract level define `() = `(context()) = 0.
169

fiFelzenszwalb & McAllester

show HA*LD correctly computes lightest derivations lightest contexts
every level abstraction. Moreover, order derivations contexts
expanded controlled heuristic function defined follows. C k 0 k
1 define heuristic value C using contexts level heuristic value
context(C) using derivations level,
h(C) = `(context(abs(C))),
h(context(C)) = `(C).
abstract level define h() = h(context()) = 0. Let generalized statement
either element k 0 k expression form context(C)
C k . define intrinsic priority follows,
p() = `() + h().
C k , p(context(C)) weight lightest derivation goal k
uses C, p(C) lower bound weight.
results Sections 4 5 cannot used directly show correctness
HA*LD. rules Figure 7 generate heuristic values time
generate derivations depend heuristic values. Intuitively must show
execution prioritized rules H, heuristic value available
appropriate point time. next lemma shows rules H satisfy monotonicity
property respect intrinsic priority generalized statements. Theorem 5 proves
correctness hierarchical algorithm.
Lemma 4 (Monotonicity). rule 1 , . . . , hierarchical algorithm,
weight antecedent `(i ) weight conclusion
(a) priority rule + h().
(b) + h() p(i ).
Proof. rules START1 START2 result follows fact rules
antecedents h() = h(context()) = 0.
Consider rule labeled BASE w = `(goal k ). see (a) note always zero
priority rule w = h(context(goal k )). (b) note p(goal k ) =
`(goal k ) equals priority rule.
consider rule labeled wc = `(context(abs(C))) wi = `(Ai ) i.
part (a) note priority rule + wc h(C) = wc . part (b) consider
first antecedent rule. h(context(abs(C))) = `(abs(C)) `(C) ,
p(context(abs(C))) = wc + h(context(abs(C))) + wc . consider antecedent
Ai . abs(Ai ) = p(Ai ) = wi + wc . abs(Ai ) 6= show
h(Ai ) = `(context(abs(Ai ))) wc + wi . implies p(Ai ) = wi + h(Ai ) + wc .
Finally consider rule labeled wc = `(context(C)) wj = `(Aj )
j. part (a) note priority rule + wi h(context(Ai )) = wi .
Ppart
(b) consider first antecedent rule. h(context(C)) = `(C) v + j wj
see p(context(C)) = wc + h(C) + wi . consider antecedent Aj .
abs(Aj ) = h(Aj ) = 0 p(Aj ) = wj + wi . abs(Aj ) 6= show
h(Aj ) + wi wj . Hence p(Aj ) = wj + h(Aj ) + wi .
170

fiThe Generalized A* Architecture

Theorem 5. execution H maintains following invariants.
1. ( = w) w = `().
2. ( = w) Q priority w + h().
3. p() < p(Q) ( = `())
p(Q) denotes smallest priority Q.
Proof. initial state algorithm empty Q contains ( = 0)
(context() = 0) priority 0. initial state invariant 1 true since empty;
invariant 2 follows definition h() h(context()); invariant 3 follows
fact p(Q) = 0 p() 0 . Let Q denote state
algorithm immediately prior iteration loop Figure 5 suppose
invariants true. Let 0 Q0 denote state algorithm iteration.
first prove invariant 1 0 . Let ( = w) element removed Q
iteration. soundness rules w `(). w = `() clearly
invariant 1 holds 0 . w > `() invariant 2 implies p(Q) = w +h() > `()+h()
invariant 3 know contains ( = `()). case 0 = S.
Invariant 2 Q0 follows invariant 2 Q, invariant 1 0 , part (a)
monotonicity lemma.
Finally, consider invariant 3 0 Q0 . proof reverse induction
abstraction level . say level k k form context(C)
C k . reverse induction, base case considers level m. Initially
algorithm inserts ( = 0) (context() = 0) queue priority 0. p(Q0 ) > 0
0 must contain ( = 0) (context() = 0). Hence invariant 3 holds 0 Q0
level m.
assume invariant 3 holds 0 Q0 levels greater k
consider level k. first consider statements C k . Since rules Rk additive,
every statement C derivable Rk lightest derivation (a derivation weight
`(C)). follows correctness Knuths algorithm. Moreover, additive
rules, subtrees lightest derivations also lightest derivations. show structural
induction lightest derivation conclusion C p(C) < p(Q0 )
(C = `(C)) 0 . Consider lightest derivation Rk conclusion C
p(C) < p(Q0 ). final rule derivation A1 , . . . , v C corresponds rule
add antecedent context(abs(C)). part (b) monotonicity lemma
antecedents rule intrinsic priority less p(Q0 ). induction
hypothesis lightest derivations (Ai = `(Ai )) 0 . Since invariant 3 holds
statements levels greater k (context(abs(C)) = `(context(abs(C)))) 0 .
implies point rule used derive (C = `(C)) priority p(C).
p(C) < p(Q0 ) hence item must removed queue. Therefore
0 must contain (C = w) w and, invariant 1, w = `(C).
consider form context(C) C k . see c(Rk )
additive thus every statement derivable c(Rk ) lightest derivation subtrees
lightest derivations lightest derivations themselves. prove structural induction
171

fiFelzenszwalb & McAllester

lightest derivation conclusion context(C) p(context(C)) <
p(Q0 ) (context(C) = `(context(C))) 0 . Suppose last rule form,
context(C), A1 , . . . , Ai1 , Ai+1 , . . . , v context(Ai ).
rule corresponds rule add antecedent Ai . part (b)
monotonicity lemma antecedents rule intrinsic priority less
p(Q0 ). invariant 3 statements k induction hypothesis lightest
derivations using c(Rk ), antecedents rule lightest weight
0 . point (context(Ai ) = `(context(Ai ))) derived priority p(Ai ).
p(Ai ) < p(Q0 ) implies item removed queue and, invariant 1,
(context(Ai ) = `(context(Ai ))) 0 .
suppose last (and only) rule 0 context(goal k ). rule corresponds BASE rule add goal k antecedent. Note p(goal k ) =
`(goal k ) = p(context(goal k )) hence p(goal k ) < p(Q0 ). invariant 3 statements
k (goal k = `(goal k )) 0 point BASE rule used queue
(context(goal k ) = `(context(goal k ))) priority p(context(goal k )). previous cases
p(context(goal k )) < p(Q0 ) implies (context(goal k ) = `(context(goal k ))) 0 .
last theorem implies generalized statements expanded order
intrinsic priority. Let K number statements C entire abstraction hierarchy
p(C) p(goal ) = `(goal ). every statement C p(C) p(context(C)).
conclude HA*LD expands 2K generalized statements computing
lightest derivation goal .
6.1 Example
consider execution HA*LD specific example. example illustrates
HA*LD interleaves computation structures different levels abstraction.
Consider following abstraction hierarchy 2 levels.
0 = {X1 , . . . , Xn , Y1 , . . . , Yn , Z1 , . . . , Zn , goal 0 }, 1 = {X, Y, Z, goal 1 },




1 X,
Xi ,

















Y,


,


1

Xi , Yj ij goal 0 ,
X, 1 goal 1 ,
, R1 =
,
R0 =








Z,
,


Z
,
X,


X




5







5
Z 1 goal 1 ,
Zi goal 0 ,
abs(Xi ) = X, abs(Yi ) = , abs(Zi ) = Z abs(goal0 ) = goal1 .
1. Initially = Q = {( = 0) (context() = 0) priority 0}.
2. ( = 0) comes queue gets put nothing else happens.
3. (context() = 0) comes queue gets put S. statements 1
abstract context S. causes rules come rules R1
antecedents fire, putting (X = 1) (Y = 1) Q priority 1.
172

fiThe Generalized A* Architecture

4. (X = 1) (Y = 1) come queue get put S, causing two
rules fire, putting (goal 1 = 3) priority 3 (Z = 7) priority 7 queue.
5. have,
= {( = 0), (context() = 0), (X = 1), (Y = 1)}
Q = {(goal 1 = 3) priority 3, (Z = 7) priority 7}
6. point (goal 1 = 3) comes queue goes S. BASE rule fires
putting (context(goal 1 ) = 0) queue priority 3.
7. (context(goal 1 ) = 0) comes queue. base case contexts 1 . Two
rules use (context(goal 1 ) = 0), (X = 1) (Y = 1) put (context(X) = 2)
(context(Y ) = 2) Q priority 3.
8. (context(X) = 2) comes queue gets put S. abstract
context Xi 0 , rules put (Xi = i) Q priority + 2.
9. (context(Y ) = 2) comes queue goes S. previous step
rules put (Yi = i) Q priority + 2.
10. have,
= {( = 0), (context() = 0), (X = 1), (Y = 1), (goal 1 = 3),
(context(goal 1 ) = 0), (context(X) = 2), (context(Y ) = 2)}
Q = {(Xi = i) (Yi = i) priority + 2 1 n, (Z = 7) priority 7}
11. Next (X1 = 1) (Y1 = 1) come queue go S. causes
rule put (goal 0 = 3) queue priority 3.
12. (goal 0 = 3) comes queue goes S. algorithm stop since
derivation concrete goal.
Note HA*LD terminates fully computing abstract derivations contexts.
particular (Z = 7) Q Z never expanded. Moreover context(Z) even
queue. keep running algorithm would eventually derive context(Z),
would allow Zi derived.

7. Perception Pipeline
Figure 8 shows hypothetical run hierarchical algorithm processing pipeline
vision system. system weighted statements edges used derive
weighted statements contours provide input later stages ultimately resulting
statements recognized objects.
well known subjective presence edges particular image location
depend context given image patch appears. interpreted
perception pipeline stating higher level processes later pipeline
influence low-level interpretations. kind influence happens naturally lightest
173

fiFelzenszwalb & McAllester

m1

Edges

Contours

Recognition

1

Edges

Contours

Recognition

0

Edges

Contours

Recognition

Figure 8: vision system several levels processing. Forward arrows represent
normal flow information one stage processing next. Backward
arrows represent computation contexts. Downward arrows represent
influence contexts.

derivation problem. example, lightest derivation complete scene analysis might
require presence edge locally apparent. implementing whole
system single lightest derivation problem avoid need make hard decisions
stages pipeline.
influence late pipeline stages guiding earlier stages pronounced use
HA*LD compute lightest derivations. case influence apparent
structure optimal solution also flow information across different
stages processing. HA*LD complete interpretation derived one level abstraction
guides processing stages concrete level. Structures derived late stages
pipeline guide earlier stages abstract context weights. allows early
processing stages concentrate computational efforts constructing structures
likely part globally optimal solution.
emphasized use admissible heuristics, note A* architecture, including HA*LD, also used inadmissible heuristic functions (of course
would break optimality guarantees). Inadmissible heuristics important
admissible heuristics tend force first stages processing pipeline generate
many derivations. derivations composed weights increase causes
large number derivations generated first stages processing
first derivation reaches end pipeline. Inadmissible heuristics produce behavior
similar beam search derivations generated first stage pipeline flow
whole pipeline quickly. natural way construct inadmissible heuristics
simply scale-up admissible heuristic ones obtained abstractions.
possible construct hierarchical algorithm inadmissible heuristics obtained
one level abstraction used guide search level below.

8. Hierarchical Methods
section compare HA*LD hierarchical search methods.
174

fiThe Generalized A* Architecture

8.1 Coarse-to-Fine Dynamic Programming
HA*LD related coarse-to-fine dynamic programming (CFDP) method described
Raphael (2001). understand relationship consider problem finding shortest
path trellis graph like one shown Figure 9(a). k columns
n nodes every node one column connected constant number nodes
next column. Standard dynamic programming used find shortest path
O(kn) time. CFDP HA*LD often find shortest path much faster.
hand worst case behavior algorithms different describe
below, CFDP taking significantly time HA*LD.
CFDP algorithm works coarsening graph, grouping nodes column
small number supernodes illustrated Figure 9(b). weight edge
two supernodes B minimum weight nodes b B.
algorithm starts using dynamic programming find shortest path P
coarse graph, shown bold Figure 9(b). supernodes along P
partitioned define finer graph shown Figure 9(c) procedure repeated.
Eventually shortest path P go supernodes size one, corresponding
path original graph. point know P must shortest path
original graph. best case optimal path iteration
refinement optimal path previous iteration. would result O(log n)
shortest paths computations, fairly coarse graphs. hand, worst
case CFDP take (n) iterations refine whole graph, many iterations
involve finding shortest paths large graphs. case CFDP takes (kn2 ) time
much worst standard dynamic programming approach.
suppose use HA*LD find shortest path graph like
one Figure 9(a). build abstraction hierarchy O(log n) levels
supernode level contains 2i nodes one column original graph. coarse
graph Figure 9(b) represents highest level abstraction hierarchy. Note
HA*LD consider small number, O(log n), predefined graphs CFDP end
considering much larger number, (n), graphs. best case scenario HA*LD
expand nodes shortest path level
hierarchy. worst case HA*LD compute lightest path context every
node hierarchy (here context node v path v t). i-th
abstraction level graph O(kn/2i ) nodes edges. HA*LD spend
O(kn log(kn)/2i ) time computing paths contexts level i. Summing levels
get O(kn log(kn)) time total, much worst O(kn) time
taken standard dynamic programming approach.
8.2 Hierarchical Heuristic Search
hierarchical method also related HA* HIDA* algorithms described
Holte et al. (1996) Holte et al. (2005). methods restricted shortest paths
problems also use hierarchy abstractions. heuristic function defined
level abstraction using shortest paths goal level above. main
idea run A* IDA* compute shortest path computing heuristic values ondemand. Let abs map node abstraction let g goal node concrete
175

fiFelzenszwalb & McAllester





(a)







(b)



(c)

Figure 9: (a) Original dynamic programming graph. (b) Coarse graph shortest path
shown bold. (c) Refinement coarse graph along shortest path.

graph. Whenever heuristic value concrete node v needed call algorithm
recursively find shortest path abs(v) abs(g). recursive call uses heuristic
values defined abstraction, computed deeper recursive calls.
clear generalize HA* HIDA* lightest derivation problems
rules multiple antecedents. Another disadvantage methods
potentially stall case directed graphs. example, suppose using
HA* HIDA* expand node two successors x y, x close goal
far. point need heuristic value x y, might
spend long time computing shortest path abs(y) abs(g). hand,
HA*LD would wait shortest path fully computed. Intuitively HA*LD
would compute shortest paths abs(x) abs(y) abs(g) simultaneously. soon
shortest path abs(x) abs(g) found start exploring path x
g, independent long would take compute path abs(y) abs(g).
176

fiThe Generalized A* Architecture

r2
r1

r3

r0
r4
r7
r5

r6

Figure 10: convex set specified hypothesis (r0 , . . . , r7 ).

9. Convex Object Detection
consider application HA*LD problem detecting convex objects
images. pose problem using formulation similar one described Raphael
(2001), optimal convex object around point found solving shortest
path problem. compare HA*LD search methods, including CFDP A*
pattern databases. results indicate HA*LD performs better
methods wide range inputs.
Let x reference point inside convex object. represent object boundary
using polar coordinates respect coordinate system centered x. case
object described periodic function r() specifying distance x object
boundary function angle . specify r() finite number angles
(0 , . . . , N 1 ) assume boundary straight line segment sample points.
also assume object contained ball radius R around x r()
integer. Thus object parametrized (r0 , . . . , rN 1 ) ri [0, R 1]. example
N = 8 angles shown Figure 10.
every hypothesis (r0 , . . . , rN 1 ) specifies convex object. hypothesis describes
convex set exactly object boundary turns left sample point (i , ri )
increases. Let C(ri1 , ri , ri+1 ) Boolean function indicating three sequential
values r() define boundary locally convex i. hypothesis (r0 , . . . , rN 1 )
convex locally convex i.3
Throughout section assume reference point x fixed advance.
goal find optimal convex object around given reference point. practice
reference locations found using variety methods Hough transform.
3. parametrization convex objects similar identical one used Raphael (2001).

177

fiFelzenszwalb & McAllester

Let D(i, ri , ri+1 ) image data cost measuring evidence boundary segment
(i , ri ) (i+1 , ri+1 ). consider problem finding convex object
sum data costs along whole boundary minimal. is, look
convex hypothesis minimizing following energy function,
E(r0 , . . . , rN 1 ) =

N
1
X

D(i, ri , ri+1 ).

i=0

data costs precomputed specified lookup table O(N R2 ) entries.
experiments use data cost based integral image gradient along
boundary segment. Another approach would use data term described
Raphael (2001) cost depends contrast inside outside
object measured within pie-slice defined i+1 .
optimal convex object found using standard dynamic programming techniques. Let B(i, r0 , r1 , ri1 , ri ) cost optimal partial convex object starting
r0 r1 ending ri1 ri . keep track last two boundary points
enforce convexity constraint extend partial objects. also keep track
first two boundary points enforce rN = r0 convexity constraint r0 .
compute B using recursive formula,
B(1, r0 , r1 , r0 , r1 ) = D(0, r0 , r1 ),
B(i + 1, r0 , r1 , ri , ri+1 ) = min B(i, r0 , r1 , ri1 , ri ) + D(i, ri , ri+1 ),
ri1

minimization choices ri1 C(ri1 , ri , ri+1 ) = true.
cost optimal object given minimum value B(N, r0 , r1 , rN 1 , r0 )
C(rN 1 , r0 , r1 ) = true. optimal object found tracing-back typical dynamic programming algorithms. main problem approach dynamic
programming table O(N R4 ) entries takes O(R) time compute entry.
overall algorithm runs O(N R5 ) time quite slow.
show optimal convex objects defined terms lightest derivation
problem. Let convex (i, r0 , r1 , ri1 , ri ) denote partial convex object starting r0 r1
ending ri1 ri . corresponds entry dynamic programming table
described above. Define set statements,
= {convex (i, a, b, c, d) | [1, N ], a, b, c, [0, R 1]} {goal }.
optimal convex object corresponds lightest derivations goal using rules
Figure 11. first set rules specify cost partial object r0 r1 .
second set rules specify object ending ri1 ri extended
choice ri+1 boundary locally convex ri . last set rules specify
complete convex object partial object r0 rN rN = r0
boundary locally convex r0 .
construct abstraction hierarchy define L nested partitions radius space
[0, R 1] ranges integers. abstract statement instead specifying integer
value r() specify range r() contained. simplify notation
178

fiThe Generalized A* Architecture

(1) r0 , r1 [0, R 1],

convex (1, r0 , r1 , r0 , r1 ) = D(0, r0 , r1 )
(2) r0 , r1 , ri1 , ri , ri+1 [0, R 1] C(ri1 , ri , ri+1 ) = true,
convex (i, r0 , r1 , ri1 , ri ) = w
convex (i + 1, r0 , r1 , ri , ri+1 ) = w + D(i, ri , ri+1 )
(3) r0 , r1 , rN 1 [0, R 1] C(rN 1 , r0 , r1 ) = true,
convex (N, r0 , r1 , rN 1 , r0 ) = w
goal = w
Figure 11: Rules finding optimal convex object.
assume R power two. k-th partition P k contains R/2k ranges,
2k consecutive integers. j-th range P k given [j 2k , (j + 1) 2k 1].
statements abstraction hierarchy are,
k = {convex (i, a, b, c, d) | [1, N ], a, b, c, P k } {goal k },
k [0, L 1]. range P 0 contains single integer 0 = . Let f map range
P k range P k+1 containing it. statements level k < L 1 define
abstraction function,
abs(convex (i, a, b, c, d)) = convex (i, f (a), f (b), f (c), f (d)),
abs(goal k ) = goal k+1 .
abstract rules use bounds data costs boundary segments (i , si )
(i+1 , si+1 ) si si+1 ranges P k ,
Dk (i, si , si+1 ) =

min
D(i, ri , ri+1 ).
ri si
ri+1 si+1

Since range P k union two ranges P k1 one entry Dk computed
quickly (in constant time) Dk1 computed. bounds levels computed O(N R2 ) time total. also need abstract versions convexity constraints.
si1 , si , si+1 P k , let C k (si1 , si , si+1 ) = true exist integers ri1 , ri ri+1
si1 , si si+1 respectively C(ri1 , ri , ri+1 ) = true. value C k
defined closed form evaluated quickly using simple geometry.
rules abstraction hierarchy almost identical rules Figure 11.
rules level k obtained original rules simply replacing instance
[0, R 1] P k , C C k Dk .
179

fiFelzenszwalb & McAllester

Standard DP
CFDP
HA*LD
A* pattern database 2
A* pattern database 3

6718.6 seconds
13.5 seconds
8.6 seconds
14.3 seconds
29.7 seconds

Table 1: Running time comparison example Figure 12.
9.1 Experimental Results
Figure 12 shows example image set reference locations selected manually
optimal convex object found around reference point. 14 reference
locations used N = 30 R = 60 parametrize object. Table 1 compares
running time different optimization algorithms implemented problem.
line shows time took solve 14 problems contained example image using
particular search algorithm. standard DP algorithm uses dynamic programming
solution outlined above. CFDP method based algorithm Raphael (2001)
modified representation convex objects. hierarchical A* algorithm uses
abstraction hierarchy described here. A* pattern databases used dynamic
programming compute pattern database particular level abstraction,
used database provide heuristic values A*. Note problem described
pattern database depends input. running times listed include time
took compute pattern database case.
see CFDP, HA*LD A* pattern databases much efficient
standard dynamic programming algorithm use abstractions. HA*LD
slightly faster methods example. Note running time
varies algorithm algorithm output every method find
globally optimum objects.
quantitative evaluation different search algorithms created large set
problems varying difficulty size follows. given value R generated square
images width height 2 R + 1. image circle radius less R near
center pixels image corrupted independent Gaussian noise.
difficulty problem controlled standard deviation, , noise. Figure 13
shows example images optimal convex object found around centers.
graph Figure 14 shows running time (in seconds) different search
algorithms function noise level problem size fixed R = 100.
sample point indicates average running time 200 random inputs. graph
shows running times point circles reliably detected.
compared HA*LD CFDP A* using pattern databases (PD2 PD3). PD2
PD3 refer A* pattern database defined 2 3 respectively. Since
pattern database needs recomputed input trade-off amount
time spent computing database accuracy heuristic provides.
see easy problems better use smaller database (defined higher level
abstraction) harder problems worth spending time computing bigger
database. HA*LD outperforms methods every situation captured here.
180

fiThe Generalized A* Architecture

(a)

(b)
Figure 12: (a) Reference locations. (b) Optimal convex objects.

181

fiFelzenszwalb & McAllester

Figure 13: Random images circles optimal convex object around center
one (with N = 20 R = 100). noise level images = 50.

Figure 15 shows running time different methods function problem
size R, problems fixed noise level = 100. sample point
indicates average running time taken 200 random inputs. see running
time pattern database approach grows quickly problem size increases.
computing database fixed level abstraction takes O(N R5 ) time.
hand running time CFDP HA*LD grows much slower.
CFDP performed essentially well HA*LD experiment, graph Figure 14
shows HA*LD performs better difficulty problem increases.

10. Finding Salient Curves Images
classical problem computer vision involves finding salient curves images. Intuitively
goal find long smooth curves go along paths high image gradient.
standard way pose problem define saliency score search curves
optimizing score. methods use score defined simple combination local
terms. example, score usually depends curvature image gradient
point curve. type score often optimized efficiently using dynamic
programming shortest paths algorithms (Montanari, 1971; Shashua & Ullman, 1988;
Basri & Alter, 1996; Williams & Jacobs, 1996).
consider new compositional model finding salient curves. important
aspect model capture global shape constraints. particular, looks
curves almost straight, something done using local constraints
alone. Local constraints enforce small curvature point curve,
182

fiThe Generalized A* Architecture

Figure 14: Running time different search algorithms function noise level
input. sample point indicates average running time taken 200
random inputs. case N = 20 R = 100. See text discussion.

enough prevent curves turning twisting around long distances.
problem finding salient curve image compositional model defined
solved using dynamic programming, approach slow practical
use. Shortest paths algorithms applicable compositional nature
model. Instead use A*LD heuristic function derived abstraction
(a pattern database).
Let C1 curve endpoints b C2 curve endpoints b c.
two curves composed form curve C c. define weight
composition sum weights C1 C2 plus shape cost depends
geometric arrangement points (a, b, c). Figure 16 illustrates idea shape
costs use. Note C1 C2 long, arrangement endpoints reflect
non-local geometric properties. general consider composing C1 C2 angle
formed ab bc least /2 lengths C1 C2 approximately equal.
constraints reduce total number compositions play important role
abstract problem defined below.
Besides compositional rule say b nearby locations,
short curve endpoints b. forms base case creating longer curves.
183

fiFelzenszwalb & McAllester

Figure 15: Running time different search algorithms function problem size R.
sample point indicates average running time taken 200 random
inputs. case N = 20 = 100. See text discussion.

b




c

Figure 16: curve endpoints (a, c) formed composing curves endpoints
(a, b) (b, c). assume /2. cost composition
proportional sin2 (t). cost scale invariant encourages curves
relatively straight.

assume short curves straight, weight depends image
data along line segment b. use data term, seg(a, b), zero
image gradient along pixels ab perpendicular ab, higher otherwise.
Figure 17 gives formal definition two rules model. constants k1
k2 specify minimum maximum length base case curves, L constant
184

fiThe Generalized A* Architecture

(1) pixels a, b, c angle ab bc least /2 0 L,
curve(a, b, i) = w1
curve(b, c, i) = w2
curve(a, c, + 1) = w1 + w2 + shape(a, b, c)
(2) pixels a, b k1 ||a b|| k2 ,

curve(a, b, 0) = seg(a, b)
Figure 17: Rules finding almost straight curves pair endpoints. L,
k1 k2 constants, shape(a, b, c) function measuring cost
composition.

controlling maximum depth derivations. derivation curve(a, b, i) encodes curve
b. value seen approximate measure arclength. derivation
curve(a, b, i) full binary tree depth encodes curve length
2i k1 2i k2 . let k2 = 2k1 allow curves length.
rules Figure 17 define good measure saliency
always prefer short curves long ones. define saliency curve
terms weight minus arclength, salient curves light long. Let
positive constant. consider finding lightest derivation goal using,
curve(a, b, i) = w
goal = w 2i
n n image (n4 ) statements form curve(a, c, i). Moreover,
c far apart (n) choices midpoint b defining two curves
composed lightest derivation curve(a, c, i). makes dynamic programming
solution lightest derivation problem impractical. tried using KLD even
small images algorithm runs memory minutes. describe
abstraction used define heuristic function A*LD.
Consider hierarchical set partitions image boxes. i-th partition
defined tiling image boxes 2i 2i pixels. partitions form pyramid
boxes different sizes level. box level union 4 boxes level
it, boxes level 0 pixels themselves. Let fi (a) box containing
i-th level pyramid. define
abs(curve(a, b, i)) = curve(fi (a), fi (b), i).
185

fiFelzenszwalb & McAllester


B


b

c


C

Figure 18: abstraction maps curve statement statement curves
boxes. > j curve(a, b, i) gets coarsened curve(c, d, j). Since
light curves almost straight, > j usually implies ||a b|| > ||c d||.

Figure 18 illustrates map selects pyramid level abstract statement. Intuitively abs defines adaptive coarsening criteria. b far other,
curve b must long, turn implies map b boxes
coarse partition image. creates abstract problem small number
statements without losing much information.
define abstract problem also need define set abstract rules. Recall
every concrete rule r need corresponding abstract rule r0 weight
r0 weight r. small number rules antecedents
Figure 17. concrete rule seg(a,b) curve(a, b, 0) define corresponding abstract
rule, seg(a,b) abs(curve(a, b, 0)). compositional rules Figure 17 lead abstract
rules composing curves boxes,
curve(A, B, i), curve(B, C, i) v curve(A0 , C 0 , + 1),
A, B C boxes i-th pyramid level A0 C 0 boxes
level + 1 containing C respectively. weight v shape(a, b, c)
a, b c arbitrary pixels A, B C respectively. compute value
v bounding orientations line segments ab bc boxes.
186

fiThe Generalized A* Architecture

146 137 pixels. Running time: 50 seconds (38 + 12).

122 179 pixels. Running time: 65 seconds (43 + 22).

226 150 pixels. Running time: 73 seconds (61 + 12).
Figure 19: salient curve different images. running time sum
time spent computing pattern database time spent solving
concrete problem.

187

fiFelzenszwalb & McAllester

Figure 20: example salient curve goes locations essentially
local evidence curve locations.

abstract problem defined relatively small even large images,
use pattern database approach outlined Section 5.1. input image use
KLD compute lightest context weights every abstract statement. use
weights heuristic values solving concrete problem A*LD. Figure 19 illustrates
results obtained using method. seems like abstract problem
able capture short curves extended salient curve. took
one minute find salient curve images. Figure 19 lists
dimensions image running time case.
Note algorithm rely initial binary edge detection stage. Instead
base case rules allow salient curves go pixel, even local
evidence boundary particular location. Figure 20 shows example
happens. case small part horse back blends background
consider local properties alone.
curve finding algorithm described section would difficult formulate
without A*LD general notion heuristics derived abstractions lightest
derivation problems. However, using framework introduced paper becomes
relatively easy specify algorithm.
future plan compose rules computing salient curves rules
computing complex structures. basic idea using pyramid boxes defining
abstract problem applicable variety problems computer vision.
188

fiThe Generalized A* Architecture

11. Conclusion
Although presented preliminary results last two sections, view
main contribution paper providing general architecture perceptual inference.
Dijkstras shortest paths algorithm A* search fundamental algorithms
many applications. Knuth noted generalization Dijkstras algorithm general
problems defined set recursive rules. paper given similar generalizations A* search heuristics derived abstractions. also described
new method solving lightest derivation problems using hierarchy abstractions.
Finally, outlined approach using generalizations construction
processing pipelines perceptual inference.

Acknowledgments
material based upon work supported National Science Foundation
Grant No. 0535174 0534820.

References
Basri, R., & Alter, T. (1996). Extracting salient curves images: analysis
saliency network. IEEE Conference Computer Vision Pattern Recognition.
Bonet, B., & Geffner, H. (2005). algorithm better AO*. Proceedings
National Conference Artificial Intelligence.
Bulitko, V., Sturtevant, N., Lu, J., & Yau, T. (2006). State abstraction real-time heuristic
search. Technical Report, University Alberta, Department Computer Science.
Charniak, E. (1996). Statistical Language Learning. MIT Press.
Culberson, J., & Schaeffer, J. (1998). Pattern databases. Computational Intelligence, 14 (3),
318334.
Dijkstra, E. (1959). note two problems connection graphs. Numerical Mathematics, 1, 269271.
Edelkamp, S. (2002). Symbolic pattern databases heuristic search panning. International Conference AI Planning Scheduling.
Felner, A. (2005). Finding optimal solutions graph partitioning problem heuristic
search. Annals Mathematics Artificial Intelligence, 45 (3-4), 293322.
Geman, S., Potter, D., & Chi, Z. (2002). Composition systems. Quarterly Applied
Mathematics, 707736.
Hansen, E., & Zilberstein, S. (2001). LAO*: heuristic search algorithm finds solutions
loops. Artificial Intelligence, 129, 3562.
Hart, P., Nilsson, N., & Raphael, B. (1968). formal basis heuristic determination
minimal cost paths. IEEE Transactions Systems Science Cybernetics, 4 (2),
100107.
Holte, R., Grajkowski, J., & Tanner, B. (2005). Hierarchical heuristic search revisited.
Symposium Abstraction, Reformulation Approximation.
189

fiFelzenszwalb & McAllester

Holte, R., Perez, M., Zimmer, R., & MacDonald, A. (1996). Hierarchical A*: Searching abstraction hierarchies efficiently. Proceedings National Conference Artificial
Intelligence.
Jimenez, P., & Torras, C. (2000). efficient algorithm searching implicit AND/OR
graphs cycles. Artificial Intelligence, 124, 130.
Jin, Y., & Geman, S. (2006). Context hierarchy probabilistic image model.
IEEE Conference Computer Vision Pattern Recognition.
Klein, D., & Manning, C. (2003). A* parsing: Fast exact viterbi parse selection. Proceedings HLT-NAACL.
Knuth, D. (1977). generalization Dijkstras algorithm. Information Processing Letters,
6 (1), 15.
Korf, R. (1997). Finding optimal solutions Rubiks cube using pattern databases.
Proceedings National Conference Artificial Intelligence.
Korf, R., & Felner, A. (2002). Disjoint pattern database heuristics. Artificial Intelligence,
134, 922.
Korf, R., Zhang, W., Thayer, I., & Hohwald, H. (2005). Frontier search. Journal
ACM, 52 (5), 715748.
McAllester, D. (2002). complexity analysis static analyses. Journal ACM,
49 (4), 512537.
Montanari, U. (1971). optimal detection curves noisy pictures. Communications
ACM, 14 (5).
Nilsson, N. (1980). Principles Artificial Intelligence. Morgan Kaufmann.
Pearl, J. (1984). Heuristics: intelligent search strategies computer problem solving.
Addison-Wesley.
Rabiner, L. (1989). tutorial hidden Markov models selected applications speech
recognition. Proceedings IEEE, 77 (2), 257286.
Raphael, C. (2001). Coarse-to-fine dynamic programming. IEEE Transactions Pattern
Analysis Machine Intelligence, 23 (12), 13791390.
Shashua, A., & Ullman, S. (1988). Structural saliency: detection globally salient
structures using locally connected network. IEEE International Conference
Computer Vision.
Tu, Z., Chen, X., Yuille, A., & Zhu, S. (2005). Image parsing: Unifying segmentation,
detection, recognition. International Journal Computer Vision, 63 (2), 113
140.
Williams, L., & Jacobs, D. (1996). Local parallel computation stochastic completion
fields. IEEE Conference Computer Vision Pattern Recognition.
Zhang, W., & Korf, R. (1996). study complexity transitions asymmetric traveling
salesman problem. Artificial Intelligence, 81, 12.

190

fiJournal Artificial Intelligence Research 29 (2007) 391-419

Submitted 1/2007; published 8/2007

Obtaining Reliable Feedback Sanctioning Reputation
Mechanisms
Radu Jurca
Boi Faltings

radu.jurca@epfl.ch
boi.faltings@epfl.ch

Ecole Polytechnique Federale de Lausanne (EPFL)
Artificial Intelligence Laboratory (LIA)
CH-1015 Lausanne, Switzerland
http: // liawww. epfl. ch

Abstract
Reputation mechanisms offer effective alternative verification authorities building trust electronic markets moral hazard. Future clients guide business decisions considering feedback past transactions; truthfully exposed, cheating
behavior sanctioned thus becomes irrational.
therefore becomes important ensure rational clients right incentives
report honestly. alternative side-payment schemes explicitly reward truthful reports, show honesty emerge rational behavior clients
repeated presence market. end describe mechanism supports
equilibrium truthful feedback obtained. characterize set paretooptimal equilibria mechanism, derive upper bound percentage false
reports recorded mechanism. important role existence
bound played fact rational clients establish reputation reporting
honestly.

1. Introduction
availability ubiquitous communication Internet driving migration business transactions direct contact people electronically mediated
interactions. People interact electronically either human-computer interfaces
programs representing humans, so-called agents. either case, physical interactions among entities occur, systems much susceptible fraud
deception.
Traditional methods avoid cheating involve cryptographic schemes trusted third
parties (TTPs) overlook every transaction. systems costly, introduce
potential bottlenecks, may difficult deploy due complexity heterogeneity environment: e.g., agents different geographical locations may subject
different legislation, different interaction protocols.
Reputation mechanisms offer novel effective way ensuring necessary level
trust essential functioning market. based observation agent strategies change consider interactions repeated:
party remembers past cheating, changes terms business accordingly future.
Therefore, expected gains due future transactions agent higher
reputation offset loss incurred cheating present. effect amc
2007
AI Access Foundation. rights reserved.

fiJurca & Faltings

plified considerably reputation information shared among large population,
thus multiplies expected future gains made accessible honest behavior.
Existing reputation mechanisms enjoy huge success. Systems eBay1 Amazon2
implement reputation mechanisms partly credited businesses success.
Studies show human users seriously take account reputation seller
placing bids online auctions (Houser & Wooders, 2006), despite incentive
free ride, feedback provided half transactions eBay (Resnick &
Zeckhauser, 2002).
One important challenge associated designing reputation mechanisms ensure
truthful feedback obtained actual interactions, property called incentivecompatibility. Rational users regard private information observed
valuable asset, freely shared. Worse even, agents external incentives
misreport thus manipulate reputation information available agents
(Harmon, 2004). Without proper measures, reputation mechanism obtain unreliable
information, biased strategic interests reporters.
Honest reporting incentives addressed differently depending predominant role reputation mechanisms. signaling role useful environments
service offered different providers may different quality, clients interacting provider treated equally (markets adverse selection).
case, example, market web-services. Different providers possess different
hardware resources employ different algorithms; makes certain web-services better
others. Nevertheless, requests issued web-service treated
program. clients might experience worse service others, differences random, determined provider. feedback previous clients
statistically estimates quality delivered provider future, hence signals
future clients provider selected.
sanctioning role, hand, present settings service requests
issued clients must individually addressed provider. Think barber,
must skillfully shave every client walks shop. problem providers
must exert care (and costly effort) satisfying every service request. Good quality
result enough effort exerted, provider better exerting less
effort: e.g., clients anyway pay shave, barber better sloppy
job fast possible order time customers. moral hazard situation
eliminated reputation mechanism punishes providers exerting effort.
Low effort results negative feedback decreases reputation, hence future
business opportunities provider. future loss due bad reputation offsets
momentary gain obtained cheating, makes cooperative behavior profitable.
well known solutions providing honest reporting incentives signaling
reputation mechanisms. Since clients interacting service receive quality
(in statistical sense), clients private observation influences belief regarding
experience clients. web-services market mentioned before, fact one
client bad experience certain web-service makes likely believe
clients also encounter problems web-service. correlation
1. www.ebay.com
2. www.amazon.com

392

fiObtaining Reliable Feedback Sanctioning Reputation Mechanisms

clients private belief feedback reported clients used
design feedback payments make honesty Nash equilibrium. submitting
feedback, clients get paid amount depends value reported
reports submitted clients. long others report truthfully,
expected payment every client maximized honest report thus equilibrium.
Miller, Resnick, Zeckhauser (2005) Jurca Faltings (2006) show incentivecompatible payments designed offset reporting costs lying incentives.
sanctioning reputation mechanisms payment schemes guaranteed
incentive-compatible. Different clients may experience different service quality
provider decided exert different effort levels. private beliefs reporter
may longer correlated feedback clients, therefore, statistical
properties exploited Miller et al. (2005) longer present.
alternative, propose different incentives motivate honest reporting based
repeated presence client market. Game theoretic results (i.e., folk
theorems) show repeated interactions support new equilibria present deviations
made unattractive future penalties. Even without reputation mechanism, client
guide future play depending experience previous interactions. first
result paper, describe mechanism indeed supports cooperative equilibrium
providers exert effort time. reputation mechanism correctly records
client received low quality.
certainly applications clients repeatedly interact
seller potential moral hazard problem. barber shop mentioned one
example, people prefer going barber (or hairdresser). Another example
market delivery services. Every package must scheduled timely delivery,
involves cost provider. cost may saved occasionally
dropping package, hence moral hazard. Moreover, business clients typically rely
carrier dispatch documents merchandise. business
depends quality timeliness delivery, incentive form
lasting relationship get good service. Yet another example business person
repeatedly travels offshore client. business person direct interest
repeatedly obtain good service hotel closest clients offices.
assume quality observed clients also influenced environmental
factors outside control of, however observable by, provider. Despite barbers
best effort, sudden movement client always generate accidental cut
make client unhappy. Likewise, delivery company may occasionally lose damage
packages due transportation accidents. Nevertheless, delivery company (like
barber) eventually learns certainty delays, damages losses entitle
clients complain unsatisfactory service.
mechanism propose quite simple. asking feedback client,
mechanism gives provider opportunity acknowledge failure, reimburse
client. provider claims good service reputation mechanism record
feedback client. Contradictory reports (the provider claims good service,
client submits negative feedback) may appear one parties lying,
therefore, client provider sanctioned: provider suffers loss
consequence negative report, client given small fine.
393

fiJurca & Faltings

One equilibrium mechanism providers always best deliver
promised quality, truthfully acknowledge failures caused environmental
factors. honest behavior motivated threat mistake drive
unsatisfied client away market. future transactions generate sufficient
revenue, provider afford risk losing client, hence equilibrium.
Unfortunately, socially desired equilibrium unique. Clients occasionally
accept bad service keep returning provider dont better
alternatives. Moreover, since complaining bad service sanctioned reputation
mechanism, clients might reluctant report negative feedback. Penalties negative
reports clients lack choice drives provider occasionally cheat order
increase revenue.
second result, characterize set pareto-optimal equilibria mechanism
prove amount unreported cheating occur limited two factors.
first factor limits amount cheating general, given quality
alternatives available clients. Better alternatives increase expectations
clients, therefore provider must cheat less order keep customers.
second factor limits amount unreported cheating, represents cost
incurred clients establish reputation reporting truth. stubbornly exposing
bad service happens, despite fine imposed reputation mechanism,
client signals provider committed always report truth. signals
eventually change strategy provider full cooperation, avoid
punishment negative feedback. reputation reporting truthfully course,
valuable client; therefore, rational client accepts lie (and give reputation)
cost building reputation reporting honestly greater
occasional loss created tolerated cheating. cost given ease
provider switches cooperative play, magnitude fine imposed
negative feedback.
Concretely, paper proceeds follows. Section 2 describe related work, followed detailed description setting Section 3. Section 4 presents game
theoretic model mechanism analysis reporting incentives equilibria.
establish existence cooperative equilibrium, derive un upper bound
amount cheating occur pareto-optimal equilibrium.
Section 5 establish cost building reputation reporting honestly,
hence compute upper bound percentage false reports recorded reputation
mechanism equilibrium.
continue Section 6 analyzing impact malicious buyers explicitly
try destroy reputation provider. give initial approximations
worst case damage buyers cause providers. discussions, open issues
directions future work discussed Section 7. Finally, Section 8 concludes work.

2. Related Work
notion reputation often used Game Theory signal commitment player
towards fixed strategy. mean saying clients establish reputation
reporting truth: commit always report truth. Building reputation
394

fiObtaining Reliable Feedback Sanctioning Reputation Mechanisms

usually requires incomplete information repeated game, significantly impact
set equilibrium points game. commonly referred reputation
effect, first characterized seminal papers Kreps, Milgrom, Roberts, Wilson
(1982), Kreps Wilson (1982) Milgrom Roberts (1982).
reputation effect extended games player (A) could benefit
committing certain strategy credible complete information
game: e.g., monopolist seller would like commit fight potential entrants
chain-store game (Selten, 1978), however, commitment credible due cost
fighting. incomplete information game commitment type positive
probability, opponent (B) point become convinced playing
commitment type. point, B play best response ,
gives desired payoff. Establishing reputation commitment strategy requires
time cost. higher future payoffs offset cost building reputation,
reputation effect prescribes minimum payoffs equilibrium strategy give player
(otherwise, profitably deviate playing commitment type).
Fudenberg Levine (1989) study class repeated games long-run
player faces sequence single-shot opponents observe previous games.
long-run player sufficiently patient single-shot players positive prior belief
long-run player might commitment type, authors derive lower bound
payoff received long-run player Nash equilibrium repeated game.
result holds finitely infinitely repeated games, robust
perturbations information structure (i.e., independent types
positive probability).
Schmidt (1993) provides generalization result two long-run player
case special class games called conflicting interests, one players
sufficiently patient opponent. game conflicting interests
commitment strategy one player (A) holds opponent (B) minimax payoff.
author derives upper limit number rounds B play best response
commitment type, turn generates lower bound equilibrium payoff.
detailed treatment reputation effect, reader directed work Mailath
Samuelson (2006).
computer science information systems research, reputation information defines
aggregate feedback reports past transactions. semantics
using referring reputation provider. Reputation information encompasses
unitary appreciation personal attributes provider, influences trusting
decisions clients. Depending environment, reputation two main roles: signal
capabilities provider, sanction cheating behavior (Kuwabara, 2003).
Signaling reputation mechanisms allow clients learn providers
capable providing good service. systems widely used computational
trust mechanisms. Birk (2001) Biswas, Sen, Debnath (2000) describe systems
agents use direct past experience recognize trustworthy partners. global
efficiency market clearly increased, however, time needed build reputation
information prohibits use kind mechanisms large scale online market.
number signaling reputation mechanisms also take consideration indirect reputation information, i.e., information reported peers. Schillo, Funk, Rovatsos (2000)
395

fiJurca & Faltings

Yu Singh (2002, 2003) use social networks order obtain reputation
unknown agent. Agents ask acquaintances several hops away trustworthiness
unknown agent. Recommendations afterwards aggregated single measure
agents reputation. class mechanisms, however intuitive, provide
rational participation incentives agents. Moreover, little protection
untruthful reporting, guarantee mechanism cannot manipulated
malicious provider order obtain higher payoffs.
Truthful reporting incentives signaling reputation mechanisms described
Miller et al. (2005). Honest reports explicitly rewarded payments take
account value submitted report, value report submitted another
client (called reference reporter ). payment schemes designed based proper
scoring rules, mathematical functions make possible revelation private beliefs
(Cooke, 1991). essence behind honest reporting incentives observation
private information client obtains interacting provider changes belief regarding reports clients. change beliefs exploited make honesty
ex-ante Nash equilibrium strategy.
Jurca Faltings (2006) extend result taking computational approach
designing incentive compatible payment schemes. Instead using closed form scoring
rules, compute payments using optimization problem minimizes total
budget required reward reporters. also using several reference reports filtering
mechanisms, render payment mechanisms cheaper practical.
Dellarocas (2005) presents comprehensive investigation binary sanctioning reputation mechanisms. setting, providers equally capable providing high quality,
however, requires costly effort. role reputation mechanism encourage cooperative behavior punishing cheating: negative feedback reduces future revenues
either excluding provider market, decreasing price provider
charge future transactions. Dellarocas shows simple information structures
decision rules lead efficient equilibria, given clients report honestly.
paper builds upon mechanisms addressing reporting incentives. abstract away details underlying reputation mechanism explicit penalty
associated negative feedback. Given high enough penalties exist, reputation mechanism (i.e., feedback aggregation trusting decision rules) plugged
scheme.
group work addresses reporting incentives, mention work
Braynov Sandholm (2002), Dellarocas (2002) Papaioannou Stamoulis (2005).
Braynov Sandholm consider exchanges goods money prove market
agents trusted degree deserve trusted equally efficient
market complete trustworthiness. scaling amount traded product,
authors prove possible make rational sellers truthfully declare
trustworthiness. Truthful declaration ones trustworthiness eliminates need
reputation mechanisms significantly reduces cost trust management. However,
assumptions made trading environment (i.e. form cost function
selling price supposed smaller marginal cost) common
electronic markets.
396

fiObtaining Reliable Feedback Sanctioning Reputation Mechanisms

e-Bay-like auctions, Goodwill Hunting mechanism (Dellarocas, 2002) provides
way make sellers indifferent lying truthfully declaring quality good
offered sale. Momentary gains losses obtained misrepresenting goods quality
later compensated mechanism power modify announcement
seller.
Papaioannou Stamoulis (2005) describe incentive-compatible reputation mechanism particularly suited peer-to-peer applications. mechanism similar
ours, sense provider client punished submitting conflicting reports. authors experimentally show class common lying strategies
successfully deterred scheme. Unlike results, paper considers possible
equilibrium strategies sets bounds amount untruthful information recorded
reputation mechanism.

3. Setting
assume online market, rational clients (she) repeatedly request service one provider (he). Every client repeatedly interacts service provider,
however, successive requests client always interleaved enough requests generated clients. Transactions assumed sequential, provider
capacity constraints, accepts requests.
price service p monetary units, service either high (q1 )
low (q0 ) quality. high quality valuable clients, utility u(q1 ) = u.
Low quality utility 0, precisely distinguished high quality.
round, client decide request service provider, quit market
resort outside provider completely trustworthy. outside provider always
delivers high quality service, higher price p(1 + ).
client decides interact online provider, issues request
provider, pays service. provider decide exert low (e0 ) high
(e1 ) effort treating request. Low effort normalized cost 0, generates
low quality. High effort expensive (normalized cost equals c(e1 ) = c) generates
high quality probability < 1. fixed, depends environmental factors
outside control provider. p > c, individually rational providers
exert effort.
exerting effort, provider observe quality resulting service.
decide deliver service is, acknowledge failure roll back
transaction fully reimbursing3 client. assume perfect delivery channels,
client perceives exactly quality provider. delivery, client
inspects quality service, accuse low quality submitting negative report
reputation mechanism.
reputation mechanism (RM) unique market, trusted participants.
oversee monetary transactions (i.e., payments made clients provider)
impose fines parties. However, RM observe effort level
exerted provider, know quality delivered service.
3. reality, provider might also pay penalty rolling back transaction. long penalty
small, qualitative results present paper remain valid.

397

fiJurca & Faltings

RM asks feedback client chose transact provider
current round (i.e., paid price service provider) provider delivered
service (i.e., provider reimburse client). client submits negative
feedback, RM punishes client provider: client must pay fine ,
provider accumulates negative reputation report.
3.1 Examples
Although simplistic, model retains main characteristics several interesting applications. delivery service perishable goods (goods lose value past certain
deadline) one them. Pizza, example, must delivered within 30 minutes, otherwise gets cold loses taste. Hungry clients order home, drive
expensive local restaurant, theyre sure get hot pizza. price home
delivered pizza p = 1, restaurant, pizza would cost p(1 + ) = 1.2.
cases, utility warm meal u = 2.
pizza delivery provider must exert costly effort deliver orders within deadline.
courier must dispatched immediately (high effort), estimated cost c = 0.8.
action usually results good service (the probability timely delivery
= 99%), traffic conditions unexpected accidents (e.g., address easily found)
may still delay deliveries past deadline.
destination, delivery person, well client, know delivery
late not. common practice, provider acknowledge late,
reimburse client. Clients may provide feedback reputation mechanism,
feedback counts reimbursed. clients fine submitting negative
report set example = 0.01. future loss provider caused
negative report (and quantified ) depends reputation mechanism.
simplified market car garagists plumbers could fit model. provider
commissioned repair car (respectively plumbing) quality work
depends exerted effort. High effort costly ensures lasting result
high probability. Low effort cheap, resulting fix temporary.
cases, however, warranty convention may specify right client ask
reimbursement problems reoccur within warranty period. Reputation feedback may
submitted end warranty period, accepted reimbursements
didnt occur.
interesting emerging application comes new generation web services
optimally decide treat every request. service types, high quality
response requires exclusive use costly resources. example, computation jobs
require CPU time, storage requests need disk space, information requests need queries
databases. Sufficient resources, prerequisite, guarantee good service.
Software hardware failures may occur, however, failures properly signaled
provider. monetary incentives become sufficiently important markets,
intelligent providers identify moral hazard problem, may act strategically
identified model.
398

fiObtaining Reliable Feedback Sanctioning Reputation Mechanisms

4. Behavior Reporting Incentives
game theoretic point view, one interaction client provider
modeled extensive-form game (G) imperfect public information, shown
Figure 1. client moves first decides (at node 1) whether play interact
provider, play resort trusted outside option.
client plays in, provider chose node 2 whether exert high
low effort (i.e., plays e1 e0 respectively). provider plays e0 generated
quality low. provider plays e1 , nature chooses high quality (q1 )
probability , low quality (q0 ) probability 1 . constant assumed
common knowledge market. seen resulting quality, provider delivers
(i.e., plays d) service, acknowledges low quality rolls back transaction (i.e.,
plays l) fully reimbursing client. service delivered, client report
positive (1) negative (0) feedback.
pure strategy deterministic mapping describing action players
information sets. client three information sets game G. first information
set singleton contains node 1 beginning game client must
decide playing out. second information set contains nodes 7 8
(the dotted oval Figure 1) client must decide reporting 0 1, given
received low quality, q0 . third information set singleton contains
node 9 client must decide reporting 0 1, given received high
quality, q1 . strategy in0q0 1q1 , example, honest reporting strategy, specifying
client enters game, reports 0 receives low quality, reports 1
receives high quality. set pure strategies client is:
AC = {out1q0 1q1 , out1q0 0q1 , out0q0 1q1 , out0q0 0q1 , in1q0 1q1 , in1q0 0q1 , in0q0 1q1 , in1q0 1q1 };
Similarly, set pure strategies provider is:
AP = {e0 l, e0 d, e1 lq0 lq1 , e1 lq0 dq1 , e1 dq0 lq1 , e1 dq0 dq1 };
e1 lq0 dq1 , example, socially desired strategy: provider exerts effort
node 2, acknowledges low quality node 5, delivers high quality node 6. pure
strategy profile pair (sC , sP ) sC AC sP AP . (A) denotes set
probability distributions elements A, C (AC ) P (AP ) mixed
strategies client, respectively provider, = (C , P ) mixed strategy
profile.
payoffs players
depend chosen strategy profile, move

nature. Let g() = gC (), gP () denote pair expected payoffs received
client, respectively provider playing strategy profile . function g :
(AC ) (AP ) R2 characterized Table 1 also describs normal form
transformation G. Besides corresponding payments made client
provider, Table 1 also reflects influence reputation mechanism,
explained Section 4.1. four strategies client involve playing node 1
generate outcomes, therefore, collapsed simplicity single
row Table 1.
399

fiJurca & Faltings

Client
1





Provider
2

e0

u-p(1+r)
0

e1
Nature
3

q0

4

Provider

Provider



l



q1

5

6

Provider



l

l

Client
7

0
0

0

-p-e
p-e

Client
1

8

9

0

-p
p

0
-c

1

-p-e
p-c-e

-p
p-c

0

u-p-e
p-c-e

0
-c

1

u-p
p-c

Figure 1: game representing one interaction. Empty circles represent decision nodes,
edge labels represent actions, full circles represent terminal nodes dotted
oval represents information set. Payoffs represented rectangles, top
row describes payoff client, second row describes payoff
provider.

4.1 Reputation Mechanism
every interaction, reputation mechanism records one three different signals
may receive: positive feedback client reports 1, negative feedback client
reports 0, neutral feedback provider rolls back transaction reimburses
client. Figure 1 (and Table 1) positive neutral feedback influence
payoff provider, negative feedback imposes punishment equivalent .
Two considerations made us choose representation. First, associate neutral
positive feedback reward (0 case) intuitively, acknowledgement failure may also regarded honest behavior behalf provider.
Failures occur despite best effort, acknowledging them, provider shouldnt suffer.
However, neutral feedback may also result provider exert effort.
lack punishment instances contradicts goal reputation mechanism
400

fiObtaining Reliable Feedback Sanctioning Reputation Mechanisms

in1q0 1q1

Provider

e0 l
e0
e1 lq0 lq1
e1 lq0 dq1
e1 dq0 lq1
e1 dq0 dq1

Client
in0q0 1q1

in1q0 0q1
0

0

0
0

0

p
p

p
p

0
p
p

0
c


0

p
p

0
c

in0q0 0q1
0

0
c

u p(1 + )
0
u p(1 + )
0

0
c

u p(1 + )
0

(u p)

(u p )

(u p)

(u p )

p c
(1 )p

(p ) c
(1 )p

p c
(1 )(p + )

(p ) c
(1 )(p + )

0

(1 )p c
u p

(1 )p c
(u ) p

(1)(p )c
u(1)p

(1)(p )c
u p

0

pc

p c

p (1 ) c

p c

0

u p(1 + )
u p(1 + )
u p(1 + )

Table 1: Normal transformation extensive form game, G
encourage exertion effort. Fortunately, action e0 l result rational behavior
two circumstances, excusable: one, provider defends
malicious client expected falsely report negative feedback (details Section
6), two, environmental noise big ( small) justify exertion
effort. Neutral feedback used estimate parameter , detect coalitions
malicious clients, indirectly, may influence revenue provider. However,
simplified model presented above, positive neutral feedback considered
terms generated payoffs.
second argument relates role RM constrain revenue
provider depending feedback client. several ways that.
Dellarocas (2005) describes two principles, two mechanisms punish provider
clients submit negative reports. first, works exclusion. negative
report reputation mechanism bans provider market probability .
probability tuned provider incentive cooperate almost
time, market stays efficient. second works changing conditions
future trade. Every negative report triggers decrease price next N clients
pay service. lower values N price decrease higher, nonetheless, N
take value efficient market.
mechanisms work future losses offset momentary gain provider
would intentionally cheating client. Note penalties given
endogenously lost future opportunities, require minimum premiums trusted
providers. margins high enough, providers care enough future
transactions, use present opportunity cheating.
Another option use exogenous penalties cheating. example, provider
may required buy licence operating market4 . licence partially
destroyed every negative feedback. Totaly destroyed licences must restored
new payment, remaining parts sold provider quits market.
price licence amount destroyed negative feedback scaled
4. reputation mechanism buy sell market licences

401

fiJurca & Faltings

rational providers incentive cooperate. Unlike previous solutions,
mechanism require minimum transaction margins punishments negative
feedback directly subtracted upfront deposit.
One way another, reputation mechanisms foster cooperation provider
associates value client feedback. Let V (R+ ) V (R ) value positive, respectively negative report. game Figure 1, V (R+ ) normalized 0, V (R )
. using notation, abstract away details reputation mechanism,
retain essential punishment associated negative feedback. reputation mechanism plugged scheme, long particular constraints (e.g.,
minimum margins transactions) satisfied.
One last aspect considered influence reputation mechanism
future transactions client. negative reports attract lower prices, rational long-run
clients might tempted falsely report order purchase cheaper services future.
Fortunately, mechanisms designed single-run clients, influence
reporting strategy long-run clients. reputation mechanism keeps last
N reports (Dellarocas, 2005) one them. false negative report influences
next N transactions provider; given N requests interleaved
two successive requests client, dishonest reporter cannot decrease
price future transactions.
licence-based mechanism described another example. price
service remains unchanged, therefore reporting incentives unaffected.
hand, negative feedback punished exclusion, clients may reluctant
report negatively, since also lose trading partner.
4.2 Analysis Equilibria
one-time game presented Figure 1 one subgame equilibrium client
opts out. asked report feedback, client always prefers report 1 (reporting
0 attracts penalty ). Knowing this, best strategy provider exert low
effort deliver service. Knowing provider play e0 d, strictly better
client play out.
repeated game client provider may, however,
equilibria. analyzing repeated game, let us note every interaction
provider particular client strategically isolated considered independently.
provider accepts clients views identically, maximize expected
revenue isolated repeated games.
on, consider repeated interaction provider
one client. modeled -fold repetition stage game G, denoted GT ,
finite infinite. paper deal infinite horizon case, however,
results obtained also applied minor modifications finitely repeated games
large enough.
per period discount factor reflecting probability market ceases
exist round, (or present value future revenues), let us denote
expected discount factor game GT . client interacts provider
average every N rounds, = N .
402

fiObtaining Reliable Feedback Sanctioning Reputation Mechanisms

life-time expected payoff players computed as:

X

gi ;

=0

{C, P } client, respectively provider, gi expected payoff obtained
player th interaction, discount applied compute present day
value gi .
consider normalized life-time expected payoffs, payoffs G GT
expressed using measure:

X

Vi = (1 )

gi ;

(1)

=0

define average continuation payoff player period onward (and including period t) as:
Vit = (1 )


X

gi ;

(2)

=t

set outcomes publicly perceived players round is:
= {out, l, q0 1, q0 0, q1 1, q1 0}

where:
observed client opts out,
l observed provider acknowledges low quality rolls back transaction,
qi j observed provider delivers quality qi {q0 , q1 } client reports
j {0, 1}.
denote ht specific public history repeated game set H = (Y )t
possible histories including period t. repeated game, public strategy
player sequence maps (it ), : H t1 (Ai ) prescribes (mixed)
strategy played round t, public history ht1 H t1 . perfect public
equilibrium (PPE) profile public strategies = (C , P ) that, beginning time
given public history ht1 , form Nash equilibrium point (Fudenberg,
Levine, & Maskin, 1994). Vit () continuation payoff player given strategy
profile .
G game product structure since public outcome expressed vector
two components (yC , yP ) distribution yi depends actions
player {C, P }, client, respectively provider. games, Fudenberg et al.
(1994) establish Folk Theorem proving feasible, individually rational payoff
profile achievable PPE G discount factor close enough 1. set
feasible, individually rational payoff profiles characterized by:
minimax payoff client, obtained option out: VC = u p(1 + );
403

fiJurca & Faltings

VC
(in1q01q1 ; e 1lq0d q1 )

(u -p)

(in1q01q1; e 1dq0d q1 )

u-p
pareto optimal
frontier

u -p(1+)

0

p-c


p-c


VP
p

VP

-p
(in1q01q1; e 0d)

Figure 2: pareto-optimal frontier set feasible, individually rational payoff
profiles G.

minimax payoff provider, obtained provider plays e0 l: VP = 0;
pareto optimal frontier (graphically presented Figure 2) delimited
payoffs given (linear combination of) strategy profiles (in1q0 1q1 , e1 lq0 dq1 ),
(in1q0 1q1 , e1 dq0 dq1 ) (in1q0 1q1 , e0 d).
contains one point (i.e., payoff client plays out) (up) >
u p(1 + ) p c > 0. conditions impose restrictions minimum margin
generated transaction interaction profitable. PPE payoff profile
gives provider maximum payoff (VC , VP ) where:
(
VP =

u c u + p(1 + )
p + c(pu)
>
u

u(1)
p
u(1)
p

VC defined above.
completely characterizing set PPE payoffs discount factors strictly
smaller 1 outside scope paper, let us note following results:
First, discount factor high enough (but strictly less 1) respect
profit margin obtained provider one interaction, least one PPE
reputation mechanism records honest reports. Moreover, equilibrium
pareto-optimal.
Proposition 1 >

p
p(1+)c ,

strategy profile:

provider always exerts high effort, delivers high quality; client
deviates equilibrium , provider switches e0 rest rounds;
404

fiObtaining Reliable Feedback Sanctioning Reputation Mechanisms

client always reports 1 asked submit feedback; provider deviates,
(i.e., receives low quality), client switches rest rounds.
pareto-optimal PPE.
Proof. profitable client deviate equilibrium path. Reporting
0 attracts penalty present round, termination interaction
provider (the provider stops exerting effort round onwards).
provider, hand, momentarily gain deviating e1 dq0 dq1 e0 d.
deviation e1 dq0 dq1 gives expected momentary gain p(1 ) expected
continuation loss (1 )(p c). deviation e0 brings expected momentary
gain equal (1 )p + c expected continuation loss p c. discount
factor satisfying hypothesis, deviations profitable. discount factor
low enough respect profit margins, future revenues given
equilibrium strategy offset momentary gains obtained deviating.
equilibrium payoff profile (VC , VP ) = ((u p), p c), pareto-optimal
socially efficient.

Second, prove client never reports negative feedback paretooptimal PPE, regardless value discount factor. restriction pareto-optimal
justifiable practical reasons: assuming client provider somehow
negotiate equilibrium going play, makes sense choose one
pareto-optimal equilibria.
Proposition 2 probability client reports negative feedback equilibrium
path pareto-optimal PPE strategy zero.
Sketch Proof. full proof presented Appendix follows following steps.
Step 1, equilibrium payoffs expressed adding present round payoff
discounted continuation payoff next round onward. Step 2, take PPE payoff
profile V = (VC , VP ), PPE payoff profile V 0 = (VC0 , VP )
VC < VC0 . client never reports negative feedback first round equilibrium
gives V . Step 3, equilibrium continuation payoff first round also satisfies
conditions set V . Hence, probability client reports negative feedback
equilibrium path gives V 0. Pareto-optimal PPE payoff profiles clearly satisfy
definition V , hence result proposition.

third result want mention here, upper bound
percentage false reports recorded reputation mechanism paretooptimal equilibria.
Proposition 3 upper bound percentage false reports recorded reputation mechanism PPE equilibrium is:
(


(1)(pu)+p
p

p
u

405

p u(1 );
p > u(1 )

(3)

fiJurca & Faltings

Sketch Proof. full proof presented Appendix B builds directly result
Proposition 2. Since clients never report negative feedback along pareto-optimal equilibria,
false reports recorded reputation mechanism appear provider
delivers low quality, client reports positive feedback. However, PPE profile
must give client least VC = u p(1 + ), otherwise client better resorting
outside option. Every round provider deliberatively delivers low quality
gives client payoff strictly smaller u p(1 + ). equilibrium payoff greater
VC therefore possible percentage rounds provider delivers
low quality bounded. bound limits percentage false reports recorded
reputation mechanism.

intuitive understanding results presented section, let us refer
pizza delivery example detailed Section 3.1. price home delivered pizza
p = 1, local restaurant pizza would cost p(1 + ) = 1.2. utility
warm pizza client u = 2, cost delivery c = 0.8 probability
unexpected traffic conditions delay delivery beyond 30 minutes deadline (despite
best effort provider) 1 = 0.01.
client secure minimax payoff VC = u p(1 + ) = 0.8 always going
restaurant. However, socially desired equilibrium happens client
orders pizza home, pizza service exerts effort deliver pizza time:
case payoff client VC = (u p) = 0.99, payoff provider
VP = p c = 0.19.
Proposition 1 gives lower bound discount factor pizza delivery service
repeated clients expect socially desired equilibrium. bound =
p
p(1+)c = 0.84; assuming daily discount factor pizza service = 0.996,
client must order pizza home least every 6 weeks. values
discount factors also interpreted terms minimum number rounds
client (and provider) likely play game. example, discount factor
viewed probability client (respectively provider) live another
interaction market. follows average lifetime provider least
1/(1 ) = 250 interactions (with clients), average lifetime client
least 1/(1 ) = 7 interactions (with pizza delivery service). clearly
realistic numbers.
Proposition 3 gives upper bound percentage false reports mechanism may record equilibrium clients. u(1 ) = 0.02 < 0.2 = p, limit
is:
=

p
= 0.1;
u

follows least 90% reports recorded mechanism (in equilibrium)
correct. false reports (false positive reports) result rare cases pizza
delivery intentionally delayed save cost clients complain. false
report justified, example, providers threat refuse future orders
clients complain. Given late deliveries still rare enough, clients better
home delivery restaurant, hence accept threat.
options become available clients (e.g., competing delivery services) bound
decrease.
406

fiObtaining Reliable Feedback Sanctioning Reputation Mechanisms

Please note upper bound defined Proposition 3 depends outside
alternative available provider, influenced punishment introduced
reputation mechanism. happens revenue client independent
interactions clients, therefore, reputation information reported
clients. Equilibrium strategies exclusively based direct experience
client. following section, however, refine bound considering
clients build reputation reporting honestly. There, punishment plays
important role.

5. Building Reputation Truthful Reporting
immediate consequence Propositions 2 3 provider extract
surplus created transactions occasionally delivering low quality, convincing
clients report negative feedback (providers promising sufficiently high
continuation payoffs prevent client resort outside provider). Assuming
provider power market, could influence choice
equilibrium strategy one gives revenue, holds clients close
minimax payoff VC = u p(1 + ) given outside option.5
However, client could commit report honestly, (i.e., commit play strategy
sC = in0q0 1q1 ) would benefit cooperative trade. providers best response
sC play e1 lq0 dq1 repeatedly, leads game socially efficient outcome.
Unfortunately commitment sC credible complete information game,
reasons explained Section 4.2.
Following results Kreps et al. (1982), Fudenberg Levine (1989) Schmidt
(1993) know honest reporting commitments may become credible game
incomplete information. Suppose provider incomplete information G ,
believes non-negative probability facing committed client always
reports truth. rational client fake committed client, build
reputation reporting honestly. reputation becomes credible, provider
play e1 lq0 dq1 (the best response sC ), better client
payoff would obtain provider knew rational type.
effect reputation building, set equilibrium points reduced set
payoff client higher payoff obtained client committed
report honestly. anticipated Proposition 3, smaller set equilibrium points also
reduces bound false reports recorded reputation mechanism. certain cases,
bound reduced almost zero.
Formally, incomplete information modeled perturbation complete
information repeated game G period 0 (before first round game
played) type client drawn nature countable set according
probability measure . clients payoff additionally depends type.
5. pareto-optimal PPE payoff profiles also renegotiation-proof (Bernheim & Ray, 1989; Farrell &
Maskin, 1989). follows proof Proposition 3: continuation payoffs enforcing paretooptimal PPE payoff profile also pareto-optimal. Therefore, clients falsely report positive feedback
even restrictive notion negotiation-proof equilibrium.

407

fiJurca & Faltings

say perturbed game G () provider incomplete information
sure true type client.
Two types particular importance:
normal type client, denoted 0 , rational client
payoffs presented Figure 1.
commitment type client, denoted , always prefers play commitment strategy sC . rational perspective, commitment type client obtains
arbitrarily high supplementary reward reporting truth. external reward makes strategy sC dominant strategy, therefore, commitment
type client play anything else sC .
Theorem 1 give upper bound kP number times provider delivers
low quality G (), given always observes client reporting honestly.
intuition behind result following. providers best response
honest reporter e1 lq0 dq1 : always exert high effort, deliver quality
high. gives commitment type client maximum attainable payoff G (),
corresponding socially efficient outcome. provider, however, would better
playing normal type client, obtain expected payoff
greater p c.
normal type client may distinguished commitment type client
rounds provider delivers low quality: commitment type always reports
negative feedback, normal type might decide report positive feedback order
avoid penalty . provider therefore decide deliver low quality client
order test real type. question is, many times provider test
true type client.
Every failed test (i.e., provider delivers low quality client reports negative
feedback) generates loss provider, slightly enforces belief
client reports honestly. Since provider cannot wait infinitely future payoffs,
must time provider stop testing type provider, accepts
play socially efficient strategy, e1 lq0 dq1 .
switch socially efficient strategy triggered revelation clients
type. provider believes client behaves commitment type,
client commitment type. client may well normal type
chooses mimic commitment type, hope obtain better service
provider. However, trying determine true type client costly
provider. Therefore, provider chooses play e1 lq0 dq1 , best response
commitment strategy sC .
Theorem 1 provider incomplete information G , assigns positive probability normal commitment type client ((0 ) > 0, 0 = ( ) > 0),
finite upper bound, kP , number times provider delivers low quality
equilibrium G (). upper bound is:



kP =





ln(0 )


P p+c)+(1)p
ln (V
(VP p+c)+(1)

408

(4)

fiObtaining Reliable Feedback Sanctioning Reputation Mechanisms

Proof. First, use important result obtained Fudenberg Levine (1989)
statistical inference (Lemma 1): every previously delivered low quality service sanctioned negative report, provider must expect increasing probability
next low quality delivery also sanctioned negative feedback. Technically,
< 1, provider deliver n() low quality services (sanctioned negative
feedback) expecting n() + 1 low quality delivery also sanctioned
negative feedback probability greater . number equals to:



ln
n() =
;
ln

stated earlier, lemma prove provider become convinced
facing commitment type client. simply proves finite number
rounds provider becomes convinced client playing commitment
type.
VP
Second, > V +(1)
strictly smaller 1, rational provider
P
deliver low quality (it easy verify maximum discounted future gain
compensate risk getting negative feedback present round).
previously mentioned lemma, must equilibrium, provider delivers low
quality finite number times.
Third, let us analyze round, t, provider deliver low quality
service (play dq0 ) last time. belief provider client reports
honestly round t, expected payoff (just deciding deliver low quality
service) computed follows:
probability client reports 0. reputation reporting honestly becomes
credible, provider plays e1 lq0 dq1 subsequent rounds. provider gains
p current round, expects p c subsequent rounds;
probability 1, client reports 1 deviates commitment strategy,
provider knows facing rational client, choose continuation PPE
strategy complete information game. gains p current round,
expects VP subsequent rounds;
VP (1 )(p ) + ((p c) + (1 )VP )

hand, provider acknowledged low quality rolled back
transaction (i.e., play lq0 ), expected payoff would least:
VP0 (1 )0 + (p c)

Since provider chooses nonetheless play dq0 must VP VP0
equivalent to:
=

(VP p + c) + (1 )p
(VP p + c) + (1 )

409

(5)

fiJurca & Faltings

Finally, replacing Equation (5) definition n() obtain upper bound
number times provider delivers low quality service client committed
report honestly.

existence kP reduces possible equilibrium payoffs client get
G (). Consider rational client receives first time low quality.
following options:
report negative feedback attempt build reputation reporting honestly.
payoff current round p . Moreover, worst case expectation
future next kP 1 rounds also give p , followed
commitment payoff equal (u p):
VC |0 = (1 )(p ) + (1 kP 1 )(p ) + kP (u p);

(6)

hand, reporting positive feedback reveals normal type,
loses p current round, expects continuation payoff equal VC given
PPE strategy profile complete information game G :
VC |1 = (1 )(p) + VC ;

(7)

reputation mechanism records false reports clients incentive build reputation reporting honestly, VC |1 > VC |0; true for:
VC > kP 1 (u p) (1 kP 1 )(p + )

1
;


Following argument Proposition 3 obtain bound percentage
false reports recorded reputation mechanism pareto-optimal PPE gives
client least VC :
(
=

(up)VC
p
upVC
u

VC u p;
VC < u p

(8)

particular importance case kP = 1. VC become:
VC = (u p)

1
;


=

(1 )
;
p

(9)

probability recording false report (after first one) arbitrarily close
0 0.
pizza delivery example introduced Section 3.1, Figure 3 plots bound, kP ,
defined Theorem 1, function prior belief (0 ) provider client
honest reporter. used value discount factor equal = 0.95,
average, every client interacts 1/(1 ) = 20 times provider.
penalty negative feedback taken = 2.5. provider believes 20%
410

fiObtaining Reliable Feedback Sanctioning Reputation Mechanisms

10

9

8

7

kP

6

5

4

3

2

1

0

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0

Figure 3: upper bound kP function prior belief 0 .
clients always report honestly, deliver 3 times low quality.
belief goes 0 = 40% rational provider deliver low quality once.
Figure 4 plot values bounds (Equation (3)) (Equation (8))
function prior belief 0 . bounds simultaneously hold, therefore maximum
percentage false reports recorded reputation mechanism minimum
two. 0 less 0.25, kP 2, , reputation effect significantly
reduce worst case percentage false reports recorded mechanism. However,
0 (0.25, 0.4) reputation mechanism records (in worst case) half many false
reports, 0 > 0.4, percentage false reports drops 0.005. probability
decreased decreasing penalty . limit, approaches 0,
reputation mechanism register false report vanishing probability.
result Theorem 1 interpreted worst case scenario. real markets,
providers already small predisposition cooperate defect fewer times.
Moreover, mechanism self enforcing, sense clients act commitment types, higher prior beliefs providers new, unknown clients
report truthfully, therefore easier new clients act truthful
reporters.
mentioned end Section 4.2, bound strongly depends punishment
imposed reputation mechanism negative feedback. higher , easier
clients build reputation, therefore, lower amount false information
recorded reputation mechanism.

6. Threat Malicious Clients
mechanism described far encourages service providers best deliver
good service. clients assumed rational, committed report honestly,
411

fiJurca & Faltings

0.4



min(, )

0.35

0.3

,

0.25

0.2

0.15

0.1

0.05

0

0

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0

Figure 4: maximum probability recording false report function prior
belief 0 .

either case, never report negative feedback unfairly. section, investigate
happens clients explicitly try hurt providers submitting fake negative
ratings reputation mechanism.
immediate consequence fake negative reports clients lose money. However,
costs negative report would probably small deter clients separate agendas hurting provider. Fortunately, mechanism propose naturally
protects service providers consistent attacks initiated malicious clients.
Formally, malicious type client, , obtains supplementary (external) payoff
reporting negative feedback. Obviously, greater penalty , otherwise
results Proposition 2 would apply. incomplete information game G (),
provider assigns non-zero initial probability belief client malicious.
normal type, 0 , honest reporter type malicious type
non-zero initial probability, mechanism describe robust unfair
negative reports. first false negative report exposes client malicious, since
neither normal, commitment type report 0 receiving high quality.
Bayes Law, providers updated belief following false negative report must assign
probability 1 malicious type. Although providers allowed refuse service
requests, protect malicious clients playing e0 l: i.e., exert
low effort reimburse client afterwards. RM records neutral feedback
case, sanction provider. e0 l, malicious clients better
quitting market (opt out), thus stopping attack. RM records one false
negative report every malicious client, assuming identity changes difficult,
providers vulnerable unfair punishments.
412

fiObtaining Reliable Feedback Sanctioning Reputation Mechanisms

types (besides 0 , ) non-zero initial probability, malicious
clients harder detect. could masquerade client types normal,
accidentally misreport. rational provider immediately exclude (by playing
e0 l) normal clients rarely misreport: majority cooperative transactions
rewarded positive feedback still generate positive payoffs. Let us consider
client type 0 () behaves exactly like normal type, misreports 0 instead
1 independently probability . interacting client type 0 (),
provider receives maximum number unfair negative reports playing efficient
equilibrium: i.e., e1 lq0 dq1 . case, providers expected payoff is:
VP = p c ;

Since VP positive (the minimax payoff provider 0, given e0 l), must
pc
.
maximum value also good approximation maximum percentage
false negative reports malicious type submit reputation mechanism.
significantly higher number harmful reports exposes malicious type allows
provider defend himself.
Note, however, malicious type submit fraction false reports
type 0 () positive prior probability. provider believe
normal client make many mistakes (even percentage false reports still
low enough generate positive revenues) attributes false reports malicious type,
disengages cooperative behavior. Therefore, one method reduce impact
malicious clients make sure normal clients make mistakes. Technical
means (for example providing automated tools formatting submitting feedback),
improved user interfaces (that make easier human users spot reporting mistakes)
greatly limit percentage mistakes made normal clients, therefore, also
reduce amount harm done malicious clients.
One concrete method reducing mistakes solicit negative feedback
clients (the principle news good news, also applied Dellarocas (2005)).
reporting involves conscious decision, mistakes less frequent.
hand, reporting effort add penalty negative report, makes harder
normal clients establish reputation honest reporters. Alternative methods
reducing harm done malicious clients (like filtering mechanisms, etc., ) well
tighter bounds percentage false reports introduced clients
addressed future work.

7. Discussion Future Work
benefits obtained clients reputation reporting honestly shared
within market. reports submitted client interacting providers
change initial beliefs new provider. seen Section 5, providers
cheat less priory expect higher probability encounter honest reporting
clients. client built reputation truthfully reporting providers
behavior benefit cooperative trade entire lifetime, without
convince provider separately. Therefore upper bound loss client
withstand order convince provider commitment type, becomes upper
413

fiJurca & Faltings

bound total loss client withstand entire lifetime market.
effectively share reputation clients within market remains open issue.
Correlated idea observation clients use mechanism
motivated keep identity. generalized markets agents encouraged
play roles (e.g. peer-2-peer file sharing market fact agent acts
provider interpreted strong indication double identity
intention cheating) mechanism also solves problem signaled Friedman
Resnick (2001) related cheap online pseudonyms. price pay new identity
loss due building reputation truthful reporter acting client.
Unlike incentive-compatible mechanism pay reporters depending feedback
provided peers, mechanism described less vulnerable collusion.
reason individual clients would collude badmouth (i.e., artificially decrease reputation of) provider. However, long punishment negative feedback
super-linear number reports (this usually case), coordinating within coalition brings benefits colluders: individual actions effective actions
part coalition. collusion provider client accelerate synchronization strategies one PPE profiles (collusion non-PPE
strategy profile stable), rather desirable. profitable collusion
happen competitor providers incentivize normal clients unfairly downrate
current provider. Colluding clients become malicious case, limits
harm presented Section 6.
mechanism describe general solution online markets.
general retail e-commerce, clients dont usually interact service provider
once. showed along paper, assumption repeated interaction
crucial results. Nevertheless, believe several scenarios practical
importance meet requirements (e.g., interactions part supply chain).
these, mechanism used conjunction reputation mechanisms
guarantee reliable feedback improve overall efficiency market.
mechanism criticized centralized. reputation mechanism acts central authority supervising monetary transactions, collecting feedback
imposing penalties participants. However, see problem implementing
reputation mechanism distributed system. Different providers use different
reputation mechanisms, or, even switch mechanisms given safeguarding measures place. Concrete implementations remain addressed future work.
Although present setting service always costs amount,
results easily extended scenarios provider may deliver different kinds
services, different prices. long provider believes requests
randomly drawn distribution, bounds presented computed
using average values u, p c. constraint providers belief necessary
order exclude unlikely situations provider cheats one time high
value transaction, knowing following interactions carry little revenue, therefore,
cannot impose effective punishments.
paper, systematically overestimate bounds worst case percentage
false reports recorded mechanism. computation tight bounds requires
precise quantitative description actual set PPE payoffs client provider
414

fiObtaining Reliable Feedback Sanctioning Reputation Mechanisms

G . Fudenberg et al. (1994) Abreu, Pearce, Stacchetti (1990) pose
theoretical grounds computing set PPE payoffs infinitely repeated game
discount factors strictly smaller 1. However, efficient algorithms allow us
find set still open question. research domain progresses, expect
able significantly lower upper bounds described Sections 4 5.
One direction future research study behavior mechanism
two-sided incomplete information: i.e. client also uncertain type
provider. provider type particular importance greedy type always
likes keep client continuation payoff arbitrarily close minimal one.
situation expect able find upper bound kC number rounds
rational client would willing test true type provider. condition kP < kC
describes constraints parameters system reputation effect
work favor client: i.e. provider give first psychological
war revert cooperative equilibrium.
problem involuntary reporting mistakes briefly mentioned Section 6 needs
addressing. Besides false negative mistakes (reporting 0 instead 1), normal clients
also make false positive mistakes (report 1 instead intended 0). present
framework, one mistake enough ro ruin reputation normal type client
report honestly. one reasons chose sequential model
feedback client required provider acknowledges low quality.
reputation client becomes credible, provider always rolls back transactions
generate (accidentally not) low quality, client required continuously defend
reputation. Nevertheless, consequences reporting mistakes reputation
building phase must considered detail. Similarly, mistakes made provider,
monitoring communication errors also influence results presented here.
Last, least, practical implementations mechanism propose must
address problem persistent online identities. One possible attack created easy
identity changes mentioned Section 6: malicious buyers continuously change
identity order discredit provider. another attack, provider use fake
identities increase revenue. punishments negative feedback generated
endogenously decreased prices fixed number future transactions (e.g., Dellarocas,
2005), provider adopt following strategy: cheats real customers,
generates sufficient number fake transactions two real transactions,
effect created real negative report disappears. easy fix latter
attack charge transaction entrance fees. However, measures also affect
overall efficiency market, therefore, different applications likely need
individual solutions.

8. Conclusions
Effective reputation mechanisms must provide appropriate incentives order obtain
honest feedback self-interested clients. environments characterized adverse
selection, direct payments explicitly reward honest information conditioning
amount paid information reported peers. technique unfortunately work service providers moral hazard, individually
415

fiJurca & Faltings

decide requests satisfy. Sanctioning reputation mechanisms must therefore use
mechanisms obtain reliable feedback.
paper describe incentive-compatible reputation mechanism clients
also repeated presence market. asking feedback clients,
allow provider acknowledge failures reimburse price paid service.
future transactions generate sufficient profit, prove equilibrium
provider behaves socially desired: always exerts effort, reimburses clients
occasionally receive bad service due uncontrollable factors. Moreover, analyze
set pareto-optimal equilibria mechanism, establish limit maximum
amount false information recorded mechanism. bound depends
external alternatives available clients ease commit
reporting truth.

Appendix A. Proof Proposition 2
probability client reports negative feedback equilibrium path
pareto-optimal PPE strategy zero.
Proof.
Step 1. Following principle dynamic programming (Abreu et al., 1990), payoff
profile V = (VC , VP ) PPE G , strategy profile G,
continuation PPE payoffs profiles {W (y)|y } G , that:
V obtained playing current round, PPE strategy gives W (y)
continuation payoff, public outcome current round,
P r[y|] probability observing playing :
VC = (1 )gC () +

X
yY

VP = (1 )gP () +

X


P r[y|] WC (y) ;

P r[y|] WP (y) ;

yY

player finds profitable deviate :
X

0



0
VC (1 )gC (C
, P ) +
P r y|(C
, P ) WC (y) ;

0
C
6= C

yY

X





VP (1 )gP (C , P0 ) +
P r y|(C , P0 ) WP (y) ;

P0 6= P

yY

strategy payoff profiles {W (y)|y } said enforce V .
Step 2. Take PPE payoff profile V = (VC , VP ), PPE
payoff profile V 0 = (VC0 , VP ) VC < VC0 . Let {W (y)|y } enforce V , assume
assigns positive probability 0 = P r[q0 0|] > 0 outcome q0 0. 1 = P r[q0 1|]
(possibly equal 0), let us consider:
0 , ) 0 obtained asking client
strategy profile 0 = (C
P
C
C
report 1 instead 0 receives low quality (i.e., q0 );

416

fiObtaining Reliable Feedback Sanctioning Reputation Mechanisms

continuation payoffs {W 0 (y)|y } Wi0 (q0 1) = 0 Wi (q0 0) + 1 Wi (q0 1)
Wi0 (y 6= q0 1) = Wi (y) {C, P }. Since, set correlated PPE payoff
profiles G convex, W (y) PPE payoff profiles, W 0 (y).
payoff profile (VC0 , VP ), VC0 = VC + (1 )0 PPE equilibrium profile
enforced 0 {W 0 (y)|y }. However, contradicts assumption
VC0 < VC , P r[q0 0|] must 0. Following exactly argument, prove
P r[q1 0|] = 0.
Step 3. Taking V , {W (y)|y } step 2, have:
VC = (1 )gC () +

X


P r[y|] WC (y) ;

(10)

yY

PPE payoff profile V 0 = (VC0 , VP ) VC0 > VC , must
continuation payoffs W (y) satisfy property. (Assume otherwise
PPE (WC0 (y), WP (y)) WC0 (y) > WC (y). Replacing WC0 (y) (10) obtain V 0
contradicts hypothesis).
continuing recursion, obtain client never reports 0 equilibrium
path enforces payoff profile defined Step 2. Pareto-optimal payoff profiles clearly
enter category, hence result proposition.


Appendix B. Proof Proposition 3
upper bound percentage false reports recorded reputation mechanism
PPE equilibrium is:
(


(1)(pu)+p
p
p
u

p u(1 );
p > u(1 )

Proof. Since clients never report negative feedback along pareto-optimal equilibria,
false reports recorded reputation mechanism appear provider
delivers low quality, client reports positive feedback. Let = (C , P ) paretooptimal PPE strategy profile. induces probability distribution public histories
and, therefore, expected outcomes following transactions. Let
probability distribution induced outcomes round t. (q0 0) = (q1 0) = 0
proven Proposition 2. payoff received client playing therefore:
VC () (1 )


X



(q0 1)(p) + (q1 1)(u p) + (l)0 + (out)(u p p) ;

t=0

(q0 1)+t (q1 1)+t (l)+t (out) = 1 (q0 1)+t (l) (1)t (q1 1)/,
probability q0 least (1 )/ times probability q1 .
discount factor, , probability repeated interaction stop
transaction, expected probability outcome q0 1 is:
= (1 )


X
t=0

417

(q0 1);

fiJurca & Faltings

Since PPE profile must give client least VC = up(1+), (otherwise client
better resorting outside option), VC () VC . replacing expression
VC (), taking account constraints probability q1 obtain:


(p) + (u p) min 1 , VC ;
(


(1)(pu)+p
p

p
u

p u(1 );
p > u(1 )


References
Abreu, P., Pearce, D., & Stacchetti, E. (1990). Toward Theory Discounted Repeated
Games Imperfect Monitoring. Econometrica, 58 (5), 1041 1063.
Bernheim, B. D., & Ray, D. (1989). Collective Dynamic Consistency Repeated Games.
Games Economic Behavior, 1, 295326.
Birk, A. (2001). Learning Trust. Falcone, R., Singh, M., & Tan, Y.-H. (Eds.), Trust
Cyber-societies, Vol. LNAI 2246, pp. 133144. Springer-Verlag, Berlin Heidelberg.
Biswas, A., Sen, S., & Debnath, S. (2000). Limiting Deception Group Social Agents.
Applied Artificial Intelligence, 14, 785797.
Braynov, S., & Sandholm, T. (2002). Incentive Compatible Mechanism Trust Revelation.
Proceedings AAMAS, Bologna, Italy.
Cooke, R. (1991). Experts Uncertainity: Opinion Subjective Probability Science.
Oxford University Press: New York.
Dellarocas, C. (2002). Goodwill Hunting: Economically Efficient Online Feedback.
Padget, J., & et al. (Eds.), Agent-Mediated Electronic Commerce IV. Designing Mechanisms Systems, Vol. LNCS 2531, pp. 238252. Springer Verlag.
Dellarocas, C. (2005). Reputation Mechanism Design Online Trading Environments
Pure Moral Hazard. Information Systems Research, 16 (2), 209230.
Farrell, J., & Maskin, E. (1989). Renegotiation Repeated Games. Games Economic
Behavior, 1, 327360.
Friedman, E., & Resnick, P. (2001). Social Cost Cheap Pseudonyms. Journal
Economics Management Strategy, 10(2), 173199.
Fudenberg, D., & Levine, D. (1989). Reputation Equilibrium Selection Games
Patient Player. Econometrica, 57, 759778.
Fudenberg, D., Levine, D., & Maskin, E. (1994). Folk Theorem Imperfect Public
Information. Econometica, 62 (5), 9971039.
Harmon, A. (2004). Amazon Glitch Unmasks War Reviewers. New York Times.
Houser, D., & Wooders, J. (2006). Reputation Auctions: Theory Evidence
eBay. Journal Economics Management Strategy, 15, 353369.
418

fiObtaining Reliable Feedback Sanctioning Reputation Mechanisms

Jurca, R., & Faltings, B. (2006). Minimum Payments Reward Honest Reputation
Feedback. Proceedings ACM Conference Electronic Commerce (EC06),
pp. 190199, Ann Arbor, Michigan, USA.
Kreps, D. M., Milgrom, P., Roberts, J., & Wilson, R. (1982). Rational Cooperation
Finitely Repeated Pisoners Dilemma. Journal Economic Theory, 27, 245252.
Kreps, D. M., & Wilson, R. (1982). Reputation Imperfect Information. Journal
Economic Theory, 27, 253279.
Kuwabara, K. (2003). Decomposing Reputation Effects: Sanctioning Signaling?. Working
paper.
Mailath, G., & Samuelson, L. (2006). Repeated Games Reputations: Long-Run Relationships. Oxford University Press.
Milgrom, P., & Roberts, J. (1982). Predation, Reputation Entry Deterrence. Journal
Economic Theory, 27, 280312.
Miller, N., Resnick, P., & Zeckhauser, R. (2005). Eliciting Informative Feedback: PeerPrediction Method. Management Science, 51, 1359 1373.
Papaioannou, T. G., & Stamoulis, G. D. (2005). Incentives Mechanism Promoting
Truthful Feedback Peer-to-Peer Systems. Proceedings IEEE/ACM CCGRID
2005.
Resnick, P., & Zeckhauser, R. (2002). Trust Among Strangers Electronic Transactions:
Empirical Analysis eBays Reputation System. Baye, M. (Ed.), Economics
Internet E-Commerce, Vol. 11 Advances Applied Microeconomics.
Elsevier Science, Amsterdam.
Schillo, M., Funk, P., & Rovatsos, M. (2000). Using Trust Detecting Deceitful Agents
Artificial Societies. Applied Artificial Intelligence, 14, 825848.
Schmidt, K. M. (1993). Reputation Equilibrium Characterization Repeated Games
Conflicting Interests. Econometrica, 61, 325351.
Selten, R. (1978). Chain-Store Paradox. Theory Decision, 9, 127159.
Yu, B., & Singh, M. (2002). Evidential Model Distributed Reputation Management.
Proceedings AAMAS, Bologna, Italy.
Yu, B., & Singh, M. (2003). Detecting Deception Reputation Management. Proceedings
AAMAS, Melbourne, Australia.

419

fiJournal Artificial Intelligence Research 29 (2007) 221267

Submitted 12/06; published 06/07

Formal Semantics
Speech-Act Based Communication
Agent-Oriented Programming Language
Renata Vieira

renatav@unisinos.br

Universidade Vale Rio dos Sinos
Sao Leopoldo, RS, 93022-000, Brazil

Alvaro Moreira

Alvaro.Moreira@inf.ufrgs.br

Universidade Federal Rio Grande Sul
Porto Alegre, RS, 91501-970, Brazil

Michael Wooldridge

mjw@csc.liv.ac.uk

University Liverpool
Liverpool L69 3BX, United Kingdom

Rafael H. Bordini

R.Bordini@durham.ac.uk

University Durham
Durham DH1 3LE, United Kingdom

Abstract
Research agent communication languages typically taken speech acts paradigm
starting point. Despite manifest attractions, speech-act models communication several serious disadvantages foundation communication artificial
agent systems. particular, proved extremely difficult give satisfactory
semantics speech-act based agent communication languages. part, problem
speech-act semantics typically make reference mental states agents (their
beliefs, desires, intentions), general way attribute attitudes
arbitrary computational agents. addition, agent programming languages
semantics formalised abstract, stand-alone versions, neglecting aspects
communication primitives. respect communication, implemented agent programming languages tended rather ad hoc. paper addresses
problems, giving semantics speech-act based messages received AgentSpeak
agent. AgentSpeak logic-based agent programming language incorporates
main features PRS model reactive planning systems. paper builds upon
structural operational semantics AgentSpeak developed previous work.
main contributions paper follows: extension earlier work
theoretical foundations AgentSpeak interpreters; computationally grounded semantics
(the core) performatives used speech-act based agent communication languages;
well-defined extension AgentSpeak supports agent communication.

1. Introduction
First introduced 1987, reactive planning model Georgeff Lanskys PRS system subsequently proved one influential long-lived approaches
programming multi-agent systems (Georgeff & Lansky, 1987). AgentSpeak programming language, introduced Rao (1996), represents attempt distill key features
c
2007
AI Access Foundation. rights reserved.

fiVieira, Moreira, Wooldridge, & Bordini

PRS approach simple, abstract, logic-based language. AgentSpeak particularly interesting, comparison agent-oriented languages, retains
important aspects BDI-based reactive planning systems based,
time robust working interpreters (Bordini, Hubner, & Vieira, 2005;
Bordini & Hubner, 2007; Bordini, Bazzan, Jannone, Basso, Vicari, & Lesser, 2002), formal semantics relation BDI logics (Rao & Georgeff, 1998; Wooldridge, 2000b)
thoroughly studied (Bordini & Moreira, 2004; Moreira, Vieira, & Bordini, 2004; Moreira & Bordini, 2002), ongoing work use model-checking techniques
verification AgentSpeak multi-agent systems (Bordini, Fisher, Visser, & Wooldridge,
2004; Bordini, Visser, Fisher, Pardavila, & Wooldridge, 2003; Bordini, Fisher, Pardavila, &
Wooldridge, 2003).
original formulation AgentSpeak (Rao, 1996), main emphasis internal control structures decision-making cycle agent: issue communication
agents addressed. Accordingly, attempts give formal semantics
language focused internal aspects (Moreira & Bordini, 2002). Although
several extensions AgentSpeak proposed attempt make practically useful language (Bordini et al., 2005, 2002), comparatively little research
addressed issue principled mechanism support communication AgentSpeak,
clearly essential engineering multi -agent systems.
agent communication languages taken speech-act theory (Austin, 1962; Searle,
1969) starting point. suggested name, speech-act theory predicated
view utterances actions, performed rational agents furtherance
personal desires intentions. Thus, according speech-act theory, utterances may
considered actions performed agent, typically intention changing
mental state hearer(s) utterance. Speech-act theory thus seems particularly appropriate foundation communication among intentional agents.
communication, agent share internal state (beliefs, desires, intentions)
agents, attempt influence mental states agents.
Although initial speech-act based communication model AgentSpeak agents
previously introduced (Bordini et al., 2003), formal semantics model given
paper. preliminary formal account communication AgentSpeak agents
first given Moreira et al. (2004). main contribution present paper
thoroughly extend operational semantics AgentSpeak accounting speech-act
style communication. semantics precisely defines implement processing
messages received AgentSpeak agent; is, computational representations
mental states changed message received. Note implementations
BDI architecture, concepts plan plan library used simplify aspects
deliberation means-ends reasoning. Therefore, AgentSpeak agent sends message
whenever communicative action body intended plan
executed; plans typically written agent programmer.
pointed Singh (1998), well-known approaches agent communication focus
largely senders perspective, ignoring message processed understood. main aspect agent communication consider paper.
extending operational semantics AgentSpeak account inter-agent communication, also touch upon another long-standing problem area multi-agent systems:
222

fiSpeech-Act Based Communication Agent Programming

semantics communication languages based speech acts. difficulty that,
taking inspiration attempts develop semantics human speech acts,
semantics agent communication languages defined meaning messages agents respect mental states communication participants.
arguably advantage remaining neutral actual internal structure agents,
number authors observed makes impossible general determine
whether program claims implementing semantics really implementing (Wooldridge, 1998; Singh, 1998). problem semantics makes
reference agent believing (or intending state satisfying) certain proposition,
way ensure software using communication language complies
underlying semantics belief (or intention, mental attitudes general).
related fact previous approaches attempt give programming
language independent semantics agent communication. semantics, developed
one specific language, advantage relying mechanisms
abstractly defined mental states cannot verified real programs. note that,
best knowledge, work represents first semantics given speech-act
style, knowledge level communication language used real system.
Since precise notion Belief-Desire-Intention given previously
AgentSpeak agents (Bordini & Moreira, 2004), provide computationally
grounded (Wooldridge, 2000a) semantics speech-act based communication language, making possible determine AgentSpeak agent interprets particular
message received. Note, however, whether agent acts upon
received communication depends plan library circumstances time
message processed. Also, although approach tied particular language,
usefully employed reference model developing communication semantics
implementing communication agent programming languages.
remainder paper organised follows. Section 2 provides general
background PRS-style BDI architectures speech-act based agent communication.
Section 3 presents AgentSpeak syntax semantics much revised version syntax
semantics AgentSpeak presented Moreira Bordini (2002, 2004). Section 4
presents speech-act based communication model AgentSpeak agents, extension
preliminary formal account given Moreira et al. (2004). Section 5 illustrates
semantics example semantic rules applied typical reasoning cycle.
Section 6, show programmers use basic communication constructs
develop elaborate forms communication required multi-agent
applications (for example, ensuring belief shared two agents keeping
track progress achievement delegated goal), Section 7 give
simple example use framework proving properties communicating agents.
Section 8 presents discussion applications developments language
presented paper. Conclusions planned future work given final section.

2. Background
ability plan seems one key components rational action humans.
Planning ability take goal, goal generate recipe (i.e., plan)
223

fiVieira, Moreira, Wooldridge, & Bordini

action that, recipe followed (under favourable conditions), goal
achieved. Accordingly, great deal research artificial intelligence addressed
issue automatic planning: synthesis plans agents first principles (Allen,
Hendler, & Tate, 1990). Unfortunately, planning is, like many problems artificial
intelligence, prohibitively expensive computational terms. great strides
made developing efficient automatic planning systems (Ghallab, Nau, & Traverso, 2004),
inherent complexity process inevitably casts doubt whether
possible use plan-synthesis algorithms develop plans run-time systems
must operate tight real-time constraints. Many researchers instead considered
approaches make use pre-compiled plans, i.e., plans developed off-line, design time.
Procedural Reasoning System (PRS) Georgeff Lansky common ancestor
many approaches (Georgeff & Lansky, 1987).
2.1 PRS AgentSpeak
one level, PRS understood simply architecture executing precompiled plans. However, control structures architecture incorporate number
features together provide sophisticated environment run-time practical reasoning. First, plans may invoked effect, rather simply name (as
case conventional programming languages). Second, plans associated context,
must match agents current situation order plan considered
viable option. two features mean agent may multiple potential plans
end, dynamically select run-time, depending current
circumstances. addition, plans associated triggering events, idea
plan made active occurrence event, may external internal agent. External events changes environment perceived agent;
example internal event might creation new sub-goal, failure
plan achieve desired effect. Thus, overall, plans may invoked goal-driven
manner (to satisfy sub-goal created) event-driven manner.
PRS architecture illustrated Figure 1. AgentSpeak language, introduced Rao
(1996), represents attempt distill essential features PRS simple,
unified programming language1 ; provide detailed introduction AgentSpeak below,
discuss speech-act theory agent communication.
2.2 Speech Acts
PRS model, AgentSpeak language turn, primarily concerned
internal structure decision making, particular interplay creation
(sub-)goals execution plans achieve (sub-)goals. twin issues
communication multi-agent interaction addressed within basic architecture.
raises question issues might dealt within architecture.
BDI theory based philosophical literature practical reasoning (Bratman,
1. name language originally introduced Rao (1996) AgentSpeak(L). paper,
adopt simpler form AgentSpeak instead, use refer original language
variants appeared literature.

224

fiSpeech-Act Based Communication Agent Programming

Plan
Library

Beliefs

Sensor Input

Action Output

Interpreter

Goals

Intentions

Figure 1: PRS architecture.

1987), agent communication multi-agent systems typically based speech-act
theory, particular work Austin (1962) Searle (1969).
Speech-act theory starts principle language action: rational agent
makes utterance attempt change state world, way
agent performs physical actions change state world. distinguishes
speech acts (non-speech) actions domain speech act
part world agent wishes modify performance act
mostly mental state(s) hearer(s) utterance.
Speech acts generally classified according illocutionary force type
utterance. natural language, illocutionary forces associated utterances (or
locutionary acts). utterance door open, example, generally inform
tell type action. perlocutionary force represents speaker utterance
attempting achieve performing act. making statement open
door, perlocutionary force generally state affairs speaker
hopes bring making utterance; course, actual effect utterance
beyond control speaker. Whether choose believe
inform door open depends upon disposed towards you. natural
language, illocutionary force perlocutionary force implicit within speech
act context. theory adapted agent communication, however,
225

fiVieira, Moreira, Wooldridge, & Bordini

illocutionary forces made explicit facilitate processing communication act.
various types speech acts generally referred performatives context
agent communication.
pragmatic factors related communication social roles conventions discussed literature (Levinson, 1981; Ballmer & Brennenstuhl, 1981;
Singh, 1994). Illocutionary forces may require existence certain relationships speaker hearer felicitous. command, instance, requires
subordination relation individuals involved communication, whereas
subordination required request.
Apart illocutionary forces social roles, classifications relations
among speech acts proposed (Levinson, 1981); example, reply follows
question, threatening stronger warning. categories place messages
larger context multi-agent dialogue. multi-agent systems, communicative interactions seen communication protocols, turn normally related
specific coordination/cooperation mechanism. Contract Net (Smith, 1980), example, protocol task allocation, defined terms number constituent
performatives (such announcing bidding).
2.3 Agent Communication Languages: KQML & FIPA
Knowledge Query Manipulation Language (KQML), developed context
Knowledge Sharing Effort project (Genesereth & Ketchpel, 1994), first attempt
define practical agent communication language included high level (speech-act based)
communication considered distributed artificial intelligence literature. KQML
essentially knowledge-level messaging language (Labrou & Finin, 1994; Mayfield, Labrou,
& Finin, 1996). KQML defines number performatives, make explicit agents
intentions sending message. example, KQML performative tell used
intention changing receivers beliefs, whereas achieve used intention
changing receivers goals. Thus performative label KQML message explicitly
identifies intent message sender.
FIPA standard agent communication2 released 2002. standard
closely based KQML, almost identical conceptually syntactically, differing performative set certain details semantic framework (Labrou, Finin, &
Peng, 1999). differences important purposes paper;
refer traditional approaches semantics speech-act based inter-agent communication,
reference applies equally. However, historical reasons, refer mainly
KQML richer literature found semantics.
2.4 Semantics Agent Communication Languages
Perhaps first serious attempt define semantics KQML made Labrou
Finin (1994). work built pioneering work Cohen Perrault actiontheoretic semantics natural language speech acts (Cohen & Perrault, 1979). key
insight Cohen Perraults work that, take seriously idea utterances
2. http://www.fipa.org/specs/fipa00037/SC00037J.html

226

fiSpeech-Act Based Communication Agent Programming

action, able apply formalism reasoning action reasoning
utterances. used STRIPS-style pre- post-condition formalism define
semantics inform request speech acts (perhaps canonical examples
speech acts), pre- post-conditions framed terms beliefs,
desires, abilities conversation participants. applied Labrou Finin
KQML language (1994), pre- post-conditions defined mental states
sender receiver KQML message sending message.
description mental states, work area based Cohen Levesques
theory intention (1990a, 1990b). Agent states described mental attitudes
belief (bel), knowledge (know), desire (want), intention (intend). mental
attitudes normally propositions (i.e., symbolic representations states world)
arguments. Figures 2 3 give semantics KQML performatives tell(S, R, X) (S
tells R believes X true), ask (S, R, X) (S asks R R believes X
true), style introduced Labrou Finin (1994).
Pre-conditions states R:
P re(S):

bel(S, X) know(S, want(R, know(R, bel(S, X))))

P re(R):

intend(R, know(R, bel(S, X)))

Post-conditions R:
P os(S):

know(S, know(R, bel(S, X)))

P os(R):

know(R, bel(S, X))

Action completion:
know(R, bel(S, X))

Figure 2: Semantics tell (Labrou & Finin, 1994).

Pre-conditions states R:
P re(S): want(S, know(S, )) know(S, intend(R, process(R, )))
either bel(R, X) bel(R, X) ask-if (S, R, X)
P re(R):

intend(R, process(R, ))

Post-conditions R S:
P os(S):

intend(S, know(S, ))

P os(R) : know(R, want(S, know(S, )))
Action completion:
know(S, )

Figure 3: Semantics ask-if (Labrou & Finin, 1994).
227

fiVieira, Moreira, Wooldridge, & Bordini

noted above, one key problems (widely used) approach giving
semantics agent communication languages way determine whether
software component uses communication language complies
semantics. semantics makes reference mental states,
general principled way attribute mental states arbitrary pieces software.
true semantic approaches KQML FIPA, discussed
Wooldridge (1998) Singh (1998). example, consider legacy software component
wrapped agent uses KQML FIPA interoperate agents. One
cannot prove communication properties system, precise definition
legacy system believes (or intends achieve state world where)
proposition true. approach builds work Bordini Moreira (2004),
presented precise definition means AgentSpeak agent believe,
desire, intend certain formula; approach also adopted work modelchecking AgentSpeak (Bordini et al., 2004). consequence, able successfully
meaningfully apply speech act-style semantics communication AgentSpeak.
drawback, course, approach is, formally, limited AgentSpeak agents, even
though ideas used work semantics agent languages.

3. Syntax Semantics AgentSpeak
AgentSpeak programming language introduced Rao (1996). understood natural extension logic programming BDI agent architecture,
provides elegant abstract framework programming BDI agents. BDI architecture is, turn, perhaps one major approaches implementation rational
practical reasoning agents (Wooldridge, 2000b).
AgentSpeak agent created specification set beliefs forming initial
belief base set plans forming plan library. agents belief base set
ground first-order predicates, change time represent current state
environment perceived agent.
AgentSpeak distinguishes two types goals: achievement goals test goals. Achievement test goals predicates (as beliefs), prefixed one operators !
?, respectively. Achievement goals state agent wants achieve state
world associated predicate true; practice, see, done
execution plan. test goal returns unification associated predicate
one agents beliefs; fails unification possible. triggering event
defines events may initiate execution plan. event internal (when
subgoal needs achieved), external (when generated belief updates result
perceiving environment). Additionally, respect model communication
paper, external events related messages received agents.
two types triggering events: related addition (+) deletion (-)
mental attitudes (beliefs goals).
Plans refer basic actions agent able perform environment.
plan formed triggering event, denoting events plan relevant.
triggering event followed conjunction belief literals representing context
plan. context must logical consequence agents current beliefs
228

fiSpeech-Act Based Communication Agent Programming

+concert(A,V) : likes(A)
!book tickets(A,V).
+!book tickets(A,V) : busy(phone)
?phone number(V,N);
call(N);
. . .;
!choose seats(A,V).

Figure 4: Examples AgentSpeak plans.

plan applicable one plans relevant applicable chosen
execution handle particular event. remainder plan sequence
basic actions (sub-)goals agent achieve (or test) plan executed.
Figure 4 shows examples AgentSpeak plans. first plan tells us that,
concert announced artist venue V (so that, perceiving environment,
belief concert(A,V) added belief base), provided agent happens like
artist A, new achievement goal booking tickets concert.
second plan tells us whenever agent adopts goal booking tickets
performance V, provided case telephone busy, execute
plan consisting retrieving belief base telephone number venue V (with
test goal ?phone number(V,N)), performing basic action call(N) (assuming
making phone call one actions agent able perform), followed
certain protocol booking tickets (indicated . . .), case ends
execution plan choosing seats performance particular venue.
Next, formally present syntax semantics AgentSpeak. Note
yet consider communication; extend semantics deal communication
Section 4.

3.1 Abstract Syntax
syntax AgentSpeak agent program ag defined grammar below.
AgentSpeak, agent program simply given set bs beliefs set ps plans.
beliefs bs define initial state agents belief base (i.e., state belief base
agent starts running), plans ps form agents plan library. atomic
formul language predicates, P predicate symbol t1 , . . . , tn
standard terms first order logic. belief atomic formula variables;
use b meta-variable beliefs.
229

fiVieira, Moreira, Wooldridge, & Bordini

ag
bs
ps
p
te
ct
ct 1
h
h1



g
u

::=
::=
::=
::=
::=
::=
::=
::=
::=
::=
|
::=
::=
::=
::=

bs ps
b1 . . . b n
p1 . . . p n
te : ct h
+at
| | +g
ct 1
|

|
| ct 1 ct 1
h1 ;T
|

| g
| u
P(t1 , . . . , tn )
P(t1 , . . . , tn )[s1 , . . . , sm ]
percept | self | id
A(t1 , . . . , tn )
!at
| ?at
+b
|

(n 0)
(n 1)
|

g

|
| h1 ;h1
(n 0)
(n 0, > 0)
(n 0)

grammar gives alternative definition at, extending conventional
syntactic form predicates. extension allows annotations associated
predicate; extension AgentSpeaks original syntax motivated work
communication, discussed Section 3.2. time being, suffice say
idea annotate atomic formula source: either term id identifying
agent previously communicated information, self denote beliefs created
agent (through belief update operations within plan, described below),
percept indicate belief acquired perception environment.
So, example, agent belief concert(a, v)[j] belief base, would mean
agent j previously informed agent concert(a, v) words, j
wanted believe concert v. Similarly, concert(a, v)[percept, j]
would mean concert v believed j informed agent
this, also perceived fact (e.g., seeing poster walking past
theatre).
plan AgentSpeak given p above, te triggering event, ct plans
context, h sequence actions, goals, belief updates (which thought
mental notes created agent itself). refer te : ct head plan,
h body. set plans agent given ps. plan part
head formula ct specifies conditions plan chosen
execution.
triggering event te addition deletion belief agents
belief base (denoted +at at, respectively), addition deletion goal
(+g g, respectively3 ). plan bodies, assume agent disposal set
actions use meta-variable ranging them. largely unconcerned
respect exactly actions are. Actions written using notation
3. Triggering events form g, approach, used practice handling plan failure. Although
left construct grammar, omitted discussion formalisation plan
failure clarity, focus paper semantics communication.

230

fiSpeech-Act Based Communication Agent Programming

predicates, except action symbol used instead predicate symbol. Goals
g either achievement goals (!at) test goals (?at). Finally, +b (in body
plan) represent operations updating (u) belief base by, respectively, adding
removing beliefs; recall atomic formula must ground added
belief base.
3.2 Semantics
define semantics AgentSpeak using operational semantics, widely used method
giving semantics programming languages (Plotkin, 1981). operational semantics given set rules define transition relation configurations
hag, C, M, T, si where:
agent program ag is, defined above, set beliefs bs set plans ps.
agents circumstance C tuple hI, E, Ai where:
set intentions {i, i0 , . . .}. intention stack partially instantiated plans.
E set events {(te, i), (te 0 , i0 ), . . .}. event pair (te, i), te
triggering event intention stack plans case internal
event, empty intention case external event. belief
revision function (which part AgentSpeak interpreter rather
agents overall architecture), updates belief base, associated events
i.e., additions deletions beliefs included set.
called external events; internal events generated additions deletions
goals plans currently executing.
set actions performed environment.
tuple hIn, Out, SIi whose components characterise following aspects
communicating agents (note communication asynchronous):
mail inbox: system includes messages addressed agent
set. Elements set form hmid , id , ilf , cnti, mid
message identifier, id identifies sender message, ilf illocutionary
force message, cnt content: (possibly singleton) set AgentSpeak
predicates plans, depending illocutionary force message.
agent posts messages wishes send; assumed
underlying communication infrastructure handles delivery messages.
(We concerned infrastructure here.) Messages set
exactly format above, except id refers agent
message sent.
SI used keep track intentions suspended due processing
communication messages; explained detail next section,
intuition follows: intentions associated illocutionary forces
231

fiVieira, Moreira, Wooldridge, & Bordini

require reply interlocutor suspended, resumed
reply received.
useful structure keeps track temporary information may
subsequently required within reasoning cycle. tuple hR, Ap, , ,
temporary information; components follows:
R set relevant plans (for event handled).
Ap set applicable plans (the relevant plans whose contexts true).
, , record particular intention, event, applicable plan (respectively)
considered along execution one reasoning cycle.
current step within agents reasoning cycle symbolically annotated
{ProcMsg, SelEv, RelPl, ApplPl, SelAppl, AddIM, SelInt, ExecInt, ClrInt}. labels stand for, respectively: processing message agents mail inbox, selecting event set events, retrieving relevant plans, checking
applicable, selecting one particular applicable plan (the intended means),
adding new intended means set intentions, selecting intention, executing selected intention, clearing intention intended means may
finished previous step.
interests readability, adopt following notational conventions
semantic rules:
C AgentSpeak agent circumstance, write CE make reference E
component C, similarly components configuration.
write = (the underscore symbol) indicate intention presently
considered reasoning cycle. Similarly .
write i[p] denote intention plan p top intention i.
AgentSpeak interpreter makes use three selection functions defined
agent programmer. selection function SE selects event set events CE ;
selection function SAp selects one applicable plan given set applicable plans;
SI selects intention set intentions CI (the chosen intention executed).
Formally, selection functions agent uses also part configuration (as
social acceptance function mention later formalise agent communication).
However, defined agent programmer design time (in
principle) change run time, avoid including configuration sake
readability.
define functions help simplify semantics. p plan form
te : ct h, define TrEv(p) = te Ctxt(p) = ct. is, projection functions
return triggering event context plan, respectively. TrEv function
also applied head plan rather whole plan, works similarly
case.
232

fiSpeech-Act Based Communication Agent Programming

Next, need define specific (limited) notion logical consequence used here.
assume procedure computes general unifier two literals (as usual
logic programming), this, define logical consequence relation |= used
definitions functions checking relevant applicable plans, well
executing test goals. Given extended syntax atomic formul
include annotations sources information symbolically represented it,
also need define |= particular context, follows.
Definition 1 say atomic formula at1 annotations s11 , . . . , s1n logical
consequence set ground atomic formul bs, written bs |= at1 [s11 , . . . , s1n ] if,
if, exists at2 [s21 , . . . , s2m ] bs (i) at1 = at2 , general
unifier , (ii) {s11 , . . . , s1n } {s21 , . . . , s2m }.
intuition that, predicate unify belief bs (i),
also specified sources information corroborated bs (ii). Thus,
example, p(X)[ag1 ] follows {p(t)[ag1 ,ag2 ]}, p(X)[ag1 ,ag2 ] follow
{p(t)[ag1 ]}. concretely, if, order applicable, plan requires
drowning person explicitly perceived rather communicated another agent
(which represented drowning(Person)[percept]), follows belief
drowning(man)[percept,passerby] (i.e., perceived communicated
passerby). hand, required context two independent sources
provided information, say cheating(Person)[witness1,witness2], cannot
inferred belief cheating(husband)[witness1].
order make semantic rules readable, use two operations belief
base (i.e., set annotated ground atomic formul). use bs 0 = bs + b say bs 0
bs except bs 0 |= b. Similarly bs 0 = bs b means bs 0 bs except bs 0 6|= b.
plan considered relevant relation triggering event written
deal event. practice, checked trying unify triggering event part
plan triggering event within event selected treatment
reasoning cycle. definition below, use logical consequence relation
defined check plans triggering event unifies event occurred.
this, need extend |= relation also applies triggering events
instead predicates. fact, purposes here, consider operators
triggering event (such + !) part predicate symbol or, precisely, let
at1 predicate (with annotation) within triggering event te 1 at2 one within
te 2 , {te 2 } |= te 1 if, if, {at2 } |= at1 and, course, operators prefixing te 1
te 2 exactly same. requirement inclusion annotations,
converse might true.
Definition 2 Given plans ps agent triggering event te, set RelPlans(ps, te)
relevant plans te defined follows:
RelPlans(ps, te) = {(p, ) | p ps s.t. {te} |= TrEv(p)}.
intuition regarding annotations follows. programmer include
annotations plans triggering event sources must generated
233

fiVieira, Moreira, Wooldridge, & Bordini

event plan relevant (or include annotation source information
important plan considered relevant). plan relevant,
therefore suffices annotations plans triggering event subset
event occurred. plan triggering event +!p(X)[s] relevant event
h+!p(t)[s, t], Ti since RelPlans requires {p(t)[s, t]} |= p(X)[s] (for general
unifier ), turn requires {s} {s, t}. consequence, plan
triggering event annotations (e.g., +!p(X)) relevant particular event
(say, h+!p(t)[ag1 ], ii) requires predicates unify usual sense since
{} S, set S.
plan applicable relevant context logical consequence agents
beliefs. need extend slightly definition |= given above. plans context
conjunction literals (l either at). say bs |= l1 . . . ln if,
if, bs |= li li form at, bs 6|= li li form at, 1 n.
function determining applicable plans set relevant plans formalised
follows.
Definition 3 Given set relevant plans R beliefs bs agent, set
applicable plans AppPlans(bs, R) defined follows:
AppPlans(bs, R) = {(p, 0 ) | (p, ) R 0 s.t. bs |= Ctxt(p)0 }.
need another function used semantic rule agent
execute test goal. evaluation test goal ?at consists testing formula
logical consequence agents beliefs. function returns set general
unifiers make formula logical consequence set formul bs,
follows.
Definition 4 Given set formul bs formula at, set substitutions
Test(bs, at) produced testing bs defined follows:
Test(bs, at) = { | bs |= at}.
Next, present reasoning cycle AgentSpeak agents rules define
operational semantics.
3.3 Reasoning Cycle
Figure 5 shows possible transitions various steps agents reasoning
cycle determined AgentSpeak interpreter. labels nodes identify step
cycle, are: processing received messages (ProcMsg); selecting event
set events (SelEv); retrieving relevant plans (RelPl); checking
applicable (ApplPl); selecting one particular applicable plan (the intended means) (SelAppl);
adding new intended means set intentions (AddIM); selecting intention
(SelInt); executing selected intention (ExecInt), clearing intention intended
means may finished previous step (ClrInt).
general case, agents initial configuration hag, C, M, T, ProcMsgi, ag
given agent program, components C, , empty. Note
234

fiSpeech-Act Based Communication Agent Programming

ProcMsg

SelEv

ClrInt

RelPl

ExecInt

ApplPl

SelInt

SelAppl

AddIM

Figure 5: AgentSpeak agent reasoning cycle.

reasoning cycle starts processing received messages (ProcMsg) semantics
part reasoning cycle given main section paper. that,
original AgentSpeak reasoning cycle takes place. event selection (SelEv) made,
followed determining relevant applicable plans (RelPl ApplPl, respectively).
One relevant plans selected (SelAppl); note events
treated applicable plans deal event agent turns
attention selection intended means (SelInt) executed next. one
relevant plans selected (SelAppl) instance plan becomes intended
means therefore included set intentions (AddIM).
one intention (which normally case except extremely simple agents), one
intentions selected (SelInt) executed (ExecInt).
important transitions; others made clearer
semantics presented. rules define transition systems giving operational
semantics AgentSpeak (without communication) presented next.

3.4 Semantic Rules
section, present operational semantics AgentSpeak formalises
transitions possible steps interpretation AgentSpeak agents shown
Figure 5. general case, agents initial configuration hag, C, M, T, ProcMsgi,
ag given agent program, components C, , empty.
Note reasoning cycle starts processing received messages (ProcMsg), according
recent extension semantics presented Section 4. event
selection (SelEv) made, starting reasoning cycle originally defined
language, part semantics presented below.
Event Selection: rule assumes existence selection function SE
selects events set events E. selected event removed E
assigned component temporary information. Rule SelEv2 skips
intention execution part cycle, case events handle.
235

fiVieira, Moreira, Wooldridge, & Bordini

SE (CE ) = hte, ii
hag, C, M, T, SelEvi hag, C 0 , M, 0 , RelPli
where:

(SelEv1 )

CE0 = CE \ {hte, ii}
T0 = hte, ii

CE = {}
hag, C, M, T, SelEvi hag, C, M, T, SelInti

(SelEv2 )

Relevant Plans: Rule Rel1 assigns set relevant plans component TR . Rule Rel2
deals possibility relevant plans event, case
event simply discarded. fact, intention associated event might also
discarded: relevant plans handle event generated intention,
cannot executed. practice, instead simply discarding event (and
possibly intention it), leads activation plan failure mechanism,
discuss clarity presentation, discussed earlier.
= hte, ii
RelPlans(agps , te) 6= {}
hag, C, M, T, RelPli hag, C, M, 0 , ApplPli
where:

(Rel1 )

TR0 = RelPlans(agps , te)

RelPlans(agps , te) = {}
hag, C, M, T, RelPli hag, C, M, T, SelEvi

(Rel2 )

alternative approach situations relevant plans event
introduced Ancona, Mascardi, Hubner, Bordini (2004). assumes
cases, explicitly specified programmer, agent want ask agents
recipes use handling events. mechanism plan exchange
AgentSpeak agents proposed allows programmer specify triggering events
generate attempts retrieve external plans, plans agent agrees share
others, plan used handling particular event
instance, forth.
Applicable Plans: rule Appl1 assigns set applicable plans TAp component; rule Appl2 applies applicable plans event, case
event simply discarded. Again, practice, normally leads plan failure mechanism activated, rather simply discarding event (and whole intention
it).
AppPlans(agbs , TR ) 6= {}
hag, C, M, T, ApplPli hag, C, M, 0 , SelAppli
where:

(Appl1 )

0
TAp
= AppPlans(agbs , TR )

AppPlans(agbs , TR ) = {}
hag, C, M, T, ApplPli hag, C, M, T, SelInti
236

(Appl2 )

fiSpeech-Act Based Communication Agent Programming

Selection Applicable Plan: rule assumes existence selection function
SAp selects one plan set applicable plans TAp . selected plan
assigned component configuration.
SAp (TAp ) = (p, )
hag, C, M, T, SelAppli hag, C, M, 0 , AddIMi
where:

(SelAppl)

T0 = (p, )

Adding Intended Means Set Intentions: Events classified
external internal (depending whether generated agents perception,
whether generated previous execution plans, respectively). Rule
ExtEv determines that, event external (which indicated intention
associated ), new intention created intended means new
intention plan p assigned component. event internal, rule IntEv
determines plan put top intention associated
event.
= hte, Ti
= (p, )
hag, C, M, T, AddIMi hag, C 0 , M, T, SelInti
where:

CI0

= CI { [p] }

= hte, ii = (p, )
hag, C, M, T, AddIMi hag, C 0 , M, T, SelInti
where:

CI0

(ExtEv)

(IntEv)

= CI { i[(p)] }

Note that, rule IntEv, whole intention generated internal event needs
inserted back CI , p pushed onto top intention. related
resuming suspended intentions; suspending intentions appears rule AchvGl
below.
Intention Selection: Rule SelInt1 assumes existence function SI selects
intention processing next, rule SelInt2 takes care situation set
intentions empty (in case reasoning cycle simply starts again).
CI 6= {}
SI (CI ) =
hag, C, M, T, SelInti hag, C, M, 0 , ExecInti
where:

(SelInt1 )

T0 =

CI = {}
hag, C, M, T, SelInti hag, C, M, T, ProcMsgi

(SelInt2 )

Executing Intention: group rules express effects executing
formula body plan. rule deals one type formula appear
237

fiVieira, Moreira, Wooldridge, & Bordini

plan body. Recall Section 3.2 intention stack (partially instantiated)
plan instances; plan instance copy plan agents plan library). plan
instance executed always one top intention selected
previous step (rule SelInt1 ); specific formula executed one beginning
body plan.
Actions: formula executed action, action body plan
added set actions (which, recall, denotes action executed using
agents effectors). action removed body plan intention
updated reflect removal.
= i[head a;h]
hag, C, M, T, ExecInti hag, C 0 , M, T, ClrInti
where:

(Action)

0
CA
= CA {a}
CI0 = (CI \ {T }) {i[head h]}

Achievement Goals: rule registers new internal event set events E.
event selected handling future reasoning cycle (see rule SelEv1 ).
formula executed goal, formula removed body plan,
cases. happens plan used achieving goal finishes
successfully; see rule ClrInt2 . reasons related instantiation
plan variables well handling plan failure.
= i[head !at;h]
hag, C, M, T, ExecInti hag, C 0 , M, T, ProcMsgi
where:

(AchvGl)

CE0 = CE {h+!at, i}
CI0 = CI \ {T }

Note intention generated internal event removed set
intentions CI , capturing idea suspended intentions. plan body, !g; f
(where f formula appear plan bodies), means that, f
executed, state affairs represented goal g needs achieved (through
execution relevant, applicable plan). goal included new event created
rule AchvGl treated event, means go set events
eventually selected later reasoning cycle, according agents specific
priorities selecting events (rule SelEv1 ). Meanwhile, plan (with formula f
executed next) longer executed, hence whole intention suspended
placed, within newly created event, set events removed set
intentions. event created rule selected applicable plan
achieving g chosen, intended means pushed top suspended
intention, resumed (i.e., moved back set intentions), according
rule IntEv. next time intention selected, execution proceed
plan achieving g top, plan finished f executed (as
plan, without achieved goal, top intention again);
details suspended intentions found AgentSpeak literature (e.g., see Bordini
& Moreira, 2004).
238

fiSpeech-Act Based Communication Agent Programming

Test Goals: rules used test goal formula ?at executed. Rule
TestGl1 used set substitutions make logical consequence
agents beliefs, means test goal succeeded. test goal succeeds,
substitution applied whole intended means, reasoning cycle
continued. case, might turn test goal used triggering
event plan, used programmers formulate sophisticated queries.
Rule TestGl2 used case: generates internal event, may trigger
execution plan, achievement goals. carry plan agent required
obtain information (at time actual execution plan) directly
available belief base, plan test goal written which, example, sends
messages agents, processes available data, particular test goal
concluded (producing appropriate instantiation logical variables). internal event
generated test goal executed, process similar achievement goals,
intention suspended plan selected achieve goal, explained
above.
= i[head ?at;h]
Test(agbs , at) 6= {}
hag, C, M, T, ExecInti hag, C 0 , M, T, ClrInti
where:

CI0

= (CI \ {T }) {i[(head h)]}
Test(agbs , at)

= i[head ?at;h]
Test(agbs , at) = {}
hag, C, M, T, ExecInti hag, C 0 , M, T, ClrInti
where:

(TestGl1 )

(TestGl2 )

CE0 = CE {h+?at, i}
CI0 = CI \ {T }

Updating Beliefs: rules below, set beliefs agent modified way
either atomic formula (with annotation self) included new set beliefs
(rule AddBel) removed (rule DelBel). rules add new event
set events E, update intention removing +b formula
executed. Note belief deletions variables (at), whilst ground atoms
(b) added belief base.
= i[head +b;h]
hag, C, M, T, ExecInti hag 0 , C 0 , M, T, ClrInti
where:

ag 0bs
CE0
CI0

= ag bs + b[self]
= CE {h+b[self], Ti}
= (CI \ {T }) {i[head h]}

= i[head at;h]
hag, C, M, T, ExecInti hag 0 , C 0 , M, T, ClrInti
where:

ag 0bs
CE0
CI0

(AddBel)

= ag bs at[self]
= CE {hat[self], Ti}
= (CI \ {T }) {i[head h]}
239

(DelBel)

fiVieira, Moreira, Wooldridge, & Bordini

Clearing Intentions: Finally, following rules remove empty intended means intentions set intentions. Rule ClrInt1 simply removes whole intention
nothing else executed intention. Rule ClrInt2 clears remainder
plan empty body currently top (non empty) intention. case,
necessary instantiate plan finished plan (currently top
intention), remove goal left beginning body plan
(see rules AchvGl TestGl). Note that, case, clearing might
necessary, hence next step still ClrInt. Rule ClrInt3 takes care situation
(further) clearing required, new reasoning cycle start (at step ProcMsg).
j = [head T], j CI
hag, C, M, T, ClrInti hag, C 0 , M, T, ProcMsgi
where:

CI0

(ClrInt1 )

= CI \ {j}

j = i[head T], j CI
hag, C, M, T, ClrInti hag, C 0 , M, T, ClrInti

(ClrInt2 )

where: CI0 = (CI \ {j}) {k[(head0 h)]}
= k[head0 g;h] s.t. g = TrEv(head)
j=
6 [head T] j 6= i[head T], j CI
hag, C, M, T, ClrInti hag, C, M, T, ProcMsgi

(ClrInt3 )

4. Semantics Communicating AgentSpeak Agents
rules previous section give semantics key internal decision making
control aspects AgentSpeak. Furthermore, overall agent architecture sensors
(with associated belief revision function) effectors, addition AgentSpeak
interpreter. relation components AgentSpeak interpreter essential
giving semantics language itself. suffices note belief revision
perception environment adds (external) events set CE (which used
AgentSpeak interpretation cycle), effectors simply execute every action
included reasoner set CA .
Similarly, mechanism allows messages exchanged part overall
agent architecture part practical reasoning component, specifically program AgentSpeak. notion internal actions AgentSpeak
(Bordini et al., 2002) appropriate here: sending message corresponds executing
(predefined) internal action .send appears plan body. underlying agent architecture ensures necessary technical means used message reach
agent message addressed. However, referring special type
communication action involves suspending intentions, need include
details semantics.4
4. aspects whole framework still included formalisation given paper.
extend semantics point required accounting semantics speech-act based
messages received agent.

240

fiSpeech-Act Based Communication Agent Programming

format messages hmid , id , ilf , cnti, mid uniquely identifies message,
id identifies agent message addressed (when message sent)
agent sent message (when message received), ilf
illocutionary force (i.e., performative) associated message, cnt
message content. Depending illocutionary force message, content be:
atomic formula (at); set formul (AT s); ground atomic formula (b); set
ground atomic formul (Bs); set plans (P Ls).
mechanism receiving sending messages asynchronously defined. Messages stored mail box one processed agent beginning
reasoning cycle. Recall that, configuration transition system, MIn set
messages agent received processed yet, MOut set messages
sent agents, MSI set suspended intentions awaiting replies
(information request) messages previously sent. specifically, MSI set pairs
form (mid , i), mid message identifier uniquely identifies previously
sent message caused intention suspended.
sending messages illocutionary forces related information requests,
chosen semantics intention suspended reply received
interlocutor, much way intentions get suspended waiting
internal event handled. particular semantics ask messages,
programmer knows certainty subsequent action body plan
executed requested information already received. However, note
information received reply stored directly agents belief base, test goal
required information used remainder plan.
give two rules executing (internal) action sending message another
agent: first ask messages require suspending intentions second
types messages. rules priority Action; although Action
could also applied configurations, assume rules used
formula executed specifically .send action. (We include proviso
rule Action improve readability.)
= i[head .send(id , ilf , cnt);h]
ilf {AskIf , AskAll , AskHow }
hag, C, M, T, ExecInti hag, C 0 , 0 , T, ProcMsgi
where:

0
MOut
0
MSI

CI0

(ExecActSndAsk)

= MOut {hmid , id , ilf , cnti}
= MSI {(mid , i[head h])},
mid new message identifier;
= (CI \ {T })

semantics sending types illocutionary forces simply add
well-formed message agents mail outbox (rule ExecActSnd). Note rule
above, intention suspended, next step reasoning cycle ProcMsg(i.e.,
new cycle started), whereas rule ClrInt, updated intention
sending action removed plan body might require clearing,
intention execution rules seen previous section.
241

fiVieira, Moreira, Wooldridge, & Bordini

= i[head .send(id , ilf , cnt);h]
ilf 6 {AskIf , AskAll , AskHow }
hag, C, M, T, ExecInti hag, C 0 , 0 , T, ClrInti
where:

0
MOut

CI0

(ExecActSnd)

= MOut {hmid , id , ilf , cnti},
mid new message identifier;
= (CI \ {T }) {i[head h]}

Whenever new messages sent, assume system creates unique message identifiers (mid ). Later, shall see that, replying message, message
identifier kept message, similar way reply-with used KQML.
Thus, receiving agent aware particular message reply previous one
checking message identifiers set intentions suspended waiting
reply. feature used give semantics receiving Tell messages,
sent agent spontaneously wants receiver believe something (or
least believe something senders beliefs), also used
agent receives ask type message chooses reply it.
mentioned earlier, aim formalise every aspect system multiple AgentSpeak agents. extend previous semantics extent required
formalise speech-act based communication agents. relevant, therefore,
consider rule defines message exchange accomplished underlying message
exchange mechanism available overall agent architecture. abstracted away
semantics means following rule, AGid k , k = 1 . . . n, agent
configuration hag id k , Cid k , Mid k , Tid k , sid k i:
hmid , id j , ilf , cnti Mid
{AGid 1 , . . . AGid , AGid j , . . . AGid n , env}
{AGid 1 , . . . AG0id , AG0id j , . . . AGid n , env}
where:

(MsgExchg)

0
Mid
= Mid \ {hmid , id j , ilf , cnti}

0
Mid j
= Mid j {hmid , id , ilf , cnti}


rule above, n agents, env denotes environment
agents situated; typically, AgentSpeak agent, simply represented
set properties currently true environment changed agents
actions. Note how, message sent, second component identifies
addressee (the agent message sent), whereas received message
component identifies sender message.
4.1 Speech-act Based Communication AgentSpeak
section discuss performatives relevant communication
AgentSpeak. largely inspired corresponding KQML performatives.
also consider new performatives, related plan exchange rather communication
propositions usual. performatives consider briefly described below,
denotes agent sends message, r denotes agent receives
242

fiSpeech-Act Based Communication Agent Programming

message. Note tell untell used either agent pro-actively
send information another agent, replies previous ask messages.
tell: intends r believe (that believes) sentence messages content
true;
untell: intends r believe (that believes) sentence messages content
true;
achieve: requests r intend achieve state world message
content true;
unachieve: requests r drop intention achieving state world
message content true;
tell-how: informs r plan (i.e., know-how s);
untell-how: requests r disregard certain plan (i.e., delete plan plan
library);
ask-if: wants know content message true r;
ask-all: wants rs answers question (i.e., beliefs unify
message content);
ask-how: wants rs plans particular triggering event (in message content).
processing messages, new selection function necessary, operates much
way selection functions described previous section. new
selection function called SM , selects message MIn ; intuitively, represents
priority assigned type message programmer. also need another
given function, purpose different selection functions. Boolean function
SocAcc(id , ilf , at), ilf illocutionary force message agent id ,
propositional content at, determines message socially acceptable given context.
example, message form hmid , id , Tell , ati, receiving agent may want
consider whether id relevant source information, even remembering id believes
might appropriate. message illocutionary force Achieve, agent would
normally check, example, whether id sufficient social power itself, whether
wishes act altruistically towards id , actually committing whatever
asked.
mention role SocAcc() framework analogous,
receivers side, cause want cause believe predicates Cohen
Perraults plan-based theory speech acts (1979). is, provides bridge
illocutionary force message perlocutionary force. idea userdefined functions determining relations trust power already used
practice Bordini et al. (2003). Similar interpretations use SocAcc
applied types messages (e.g., AskIf ) easily derived.
considerable work elaborate conceptions trust context multi-agent
systems, example work Castelfranchi Falcone (1998). framework,
243

fiVieira, Moreira, Wooldridge, & Bordini

sophisticated notions trust power implemented considering
annotation sources information agents practical reasoning rather
simple use SocAcc. annotation construct facilitates determining, plan
context, source belief plan becomes intended means.
start presentation semantic rules communication, worth
noting that, paper particular, consider nested annotations. Nested
annotations allow representation beliefs agents beliefs, generally
situations agent told j, turn told k, forth.

4.2 Semantic Rules Interpreting Received Messages
Receiving Tell Message: Tell message might sent agent either reply
inform action. receiving Tell message inform (as opposed reply
previous request), AgentSpeak agent include content received message
knowledge base annotate sender source belief. Note
corresponds, way, specified action completion condition Labrou
Finin (1994): receiver know senders attitude regarding belief.
account social aspects multi-agent systems, consider social relations
regulate messages receiver process discard; referred
semantics SocAcc function, assumed given agent designer.
rule shows annotated belief added belief base, appropriate event
generated.

SM (MIn ) = hmid , id , Tell , Bsi
(mid , i) 6 MSI (for intention i)
SocAcc(id , Tell , Bs)
hag, C, M, T, ProcMsgi hag 0 , C 0 , 0 , T, SelEvi
where:

0
MIn

(Tell)

= MIn \ {hmid , id , Tell , Bsi}

b Bs :
ag 0bs = ag bs + b[id ]
CE0
= CE {h+b[id ], Ti}

Receiving Tell Message Reply: rule similar one above, except
suspended intention associated particular message given
reply previous ask message sent agent needs resumed. Recall
resume intention need place back set intentions (CI0 ).
244

fiSpeech-Act Based Communication Agent Programming

SM (MIn ) = hmid , id , Tell , Bsi
(mid , i) MSI (for intention i)
SocAcc(id , Tell , Bs)
hag, C, M, T, ProcMsgi hag 0 , C 0 , 0 , T, SelEvi
where:

0
MIn
0
MSI
0
CI

(TellRepl)

= MIn \ {hmid , id , Tell , Bsi}
= MSI \ {(mid , i)}
= CI {i}

b Bs :
ag 0bs = ag bs + b[id ]
CE0
= CE {h+b[id ], Ti}

Receiving Untell Message: receiving Untell message, sender
message removed set sources giving accreditation atomic formula
content message. case sender source information,
belief removed receivers belief base. Note that, atomic formula
content Untell message uninstantiated variables, belief
agents belief base unified formula needs considered turn,
appropriate events generated.

SM (MIn ) = hmid , id , Untell , si
(mid , i) 6 MSI (for intention i)
SocAcc(id , Untell , s)
hag, C, M, T, ProcMsgi hag 0 , C 0 , 0 , T, SelEvi
where:

0
MIn

(Untell)

= MIn \ {hmid , id , Untell , si}

b {at |
Test(agbs , at) s}
ag 0bs = ag bs b[id ]
CE0
= CE {hb[id ], Ti}

Receiving Untell Message Reply: above, sender source
belief, belief itself, excluded belief base receiver, except
suspended intention needs resumed (similarly Tell reply).
245

fiVieira, Moreira, Wooldridge, & Bordini

SM (MIn ) = hmid , id , Untell , si
(mid , i) MSI (for intention i)
SocAcc(id , Untell , s)
hag, C, M, T, ProcMsgi hag 0 , C 0 , 0 , T, SelEvi
where:

0
MIn
0
MSI
0
CI

(UntellRepl)

= MIn \ {hmid , id , Untell , si}
= MSI \ {(mid , i)}
= CI {i}

b {at |
Test(agbs , at) s}
0
ag bs = ag bs b[id ]
CE0
= CE {hb[id ], Ti}
Receiving Achieve Message: appropriate social context (e.g., sender
power receiver), receiver try execute plan whose triggering event
+!at; is, try achieve goal associated propositional content
message. external event thus included set events (recall external events
triggering event associated empty intention T).
Note possible new focus attention (a stack plans set
intentions I) initiated addition (or deletion, see below) achievement
goal. Originally, belief change arising perception environment initiated
new focus attention; plan chosen event could, turn, achievement
goals body, thus pushing new plans onto stack.
SM (MIn ) = hmid , id , Achieve, ati
SocAcc(id , Achieve, at)
hag, C, M, T, ProcMsgi hag, C 0 , 0 , T, SelEvi
where:

0
MIn
0
CE

(Achieve)

= MIn \ {hmid , id , Achieve, ati}
= CE {h+!at, Ti}

shall later discuss detail issue autonomy. gives impression simply accepting orders removes agents autonomy (and similarly
regards acquired beliefs), way agent behave aware another agent
attempting delegate goal completely depends particular plans happen
agents plan library. suitable plan exists, agent could simply drop
goal, could tell interlocutor goal delegation noted goal could
adopted expected, etc.
Receiving Unachieve Message: rule similar preceding one, except
deletion (rather addition) achievement goal included set
events. assumption that, agent plan triggering
event, plan handle aspects dropping intention. However,
practice may require alteration set intentions, thus requiring special
mechanisms included formalisation AgentSpeak yet, even
though already available practice, example Jason interpreter (Bordini &
Hubner, 2007).
246

fiSpeech-Act Based Communication Agent Programming

SM (MIn ) = hmid , id , Unachieve, ati
SocAcc(id , Unachieve, at)
hag, C, M, T, ProcMsgi hag, C 0 , 0 , T, SelEvi
where:

0
MIn
0
CE

(Unachieve)

= MIn \ {hmid , id , Unachieve, ati}
= CE {h!at, Ti}

Receiving Tell-How Message: AgentSpeak notion plan related Singhs
concept know-how (1994). Accordingly, use TellHow performative agents
wish exchange know-how rather communicate beliefs delegate goals. is,
TellHow message used sender (an agent external source generally)
inform AgentSpeak agent plan used handling certain types events
(as expressed plans triggering event). source trusted, plans
message content simply added receivers plan library.
SM (MIn ) = hmid , id , TellHow , P Lsi
(mid , i) 6 MSI (for intention i)
SocAcc(id , TellHow , P Ls)
hag, C, M, T, ProcMsgi hag 0 , C, 0 , T, SelEvi
where:

(TellHow)

0
MIn
= MIn \ {hmid , id , TellHow , P Lsi}
0
ag ps = ag ps P Ls

Note include annotation identify source plan, so,
semantics, possible take account identity agent
provided plan deciding whether use it. practice, feature implemented
Jason interpreter, language extended use annotated predicates
plan labels. also allows programmers annotate plans information
used meta-level reasoning (e.g., choosing plan use case various applicable
plans available, intention execute next); examples information would
expected payoff specific plan expected chance success, thus allowing
use decision-theoretic techniques making choices.
Receiving Tell-How Message Reply: TellHow performative reply
also cause suspended intention one associated respective AskHow
message previously sent resumed.
SM (MIn ) = hmid , id , TellHow , P Lsi
(mid , i) MSI (for intention i)
SocAcc(id , TellHow , P Ls)
hag, C, M, T, ProcMsgi hag 0 , C 0 , 0 , T, SelEvi
where:

0
MIn
0
MSI
0
CI
ag 0ps

=
=
=
=

MIn \ {hmid , id , TellHow , P Lsi}
MSI \ {(mid , i)}
CI {i}
ag ps P Ls
247

(TellHowRepl)

fiVieira, Moreira, Wooldridge, & Bordini

Receiving Untell-How Message: similar rule above, except plans
removed receivers plan library. external source may find plan
longer appropriate handling events supposed handle; may want
inform another agent that. Thus, receiving socially acceptable UntellHow
message, agent removes associated plans (i.e., message content)
plan library.
SM (MIn ) = hmid , id , UntellHow , P Lsi
SocAcc(id , UntellHow , P Ls)
hag, C, M, T, ProcMsgi hag 0 , C, 0 , T, SelEvi
where:

(UntellHow)

0
MIn
= MIn \ {hmid , id , UntellHow , P Lsi}
0
ag ps = ag ps \ P Ls

Receiving Ask-If Message: receiver respond request information
certain conditions imposed social settings (the SocAcc function) hold
sender receiver.
Note ask-if ask-all differ kind request made receiver.
former, receiver confirm whether predicate message content
belief base not; latter, agent replies predicates
belief base unify formula message content. receiver processing
AskIf message responds action sending either Tell (to reply positively)
Untell message (to reply negatively); reply message content AskIf
message. Note reply sent social context receiver wishes
consider senders request.
SM (MIn ) = hmid , id , AskIf , {b}i
SocAcc(id , AskIf , b)
hag, C, M, T, ProcMsgi hag, C, 0 , T, SelEvi
where:
0
MIn
0
MOut

=
( \ {hmid , id , AskIf , {b}i}
MOut {hmid , id , Tell , {b}i}
=
MOut {hmid , id , Untell , {b}i}

(AskIf )

ag bs |= b
ag bs 6|= b

role SM plays agents reasoning cycle slightly important
originally conceived (Moreira et al., 2004). agent considers whether accept
message not, reply message automatically assembled agent selects
(and accepts) ask messages. However, providing reply may require
considerable computational resources (e.g., whole plan library may need scanned
considerable number plans retrieved order produce reply message).
Therefore, SM normally defined agent selects AskIf , AskAll ,
AskHow message determines agent currently busy provide reply.
Receiving AskAll: AskIf , receiver processing AskAll respond
either Tell Untell , provided social context receiver choose
248

fiSpeech-Act Based Communication Agent Programming

respond. noted above, agent replies predicates belief base
unify formula message content.
SM (MIn ) = hmid , id , AskAll , {at}i
SocAcc(id , AskAll , at)
hag, C, M, T, ProcMsgi hag, C, 0 , T, SelEvi
where:
0
MIn
0
MOut

=
MIn \ {hmid , id , AskAll , {at}i}

MOut {hmid , id , Tell , si},
= {at | Test(agbs , at)}
=


{hmid , id , Untell , {at}i}

(AskAll)

Test(agbs , at) 6= {}
otherwise

Receiving AskHow: receiver AskHow respond action
sending TellHow message, provided social configuration receiver
consider senders request. contrast use Untell AskAll , response
receiver knows relevant plan (for triggering event message content)
reply empty set plans.
SM (MIn ) = hmid , id , AskHow , tei
SocAcc(id , AskHow , te)
hag, C, M, T, ProcMsgi hag, C, 0 , T, SelEvi
where:
0
MIn
0
MOut

(AskHow)

= MIn \ {hmid , id , AskHow , tei}
= MOut {hmid , id , TellHow , P Lsi}
P Ls = {p | (p, ) RelPlans(agps , te)}

SocAcc Fails: rules consider social relations sender
receiver favourable particular communicative act (i.e, require SocAcc
true). required social relation hold, message simply discarded
removed set messages ignored. rule used receiving
message untrusted source, regardless performative.
SM (MIn ) = hmid , id , ilf , Bsi
SocAcc(id , ilf , Bs)
(with ilf {Tell , Untell , TellHow , UntellHow ,
Achieve, Unachieve, AskIf , AskAll , AskHow })
hag, C, M, T, ProcMsgi hag, C, 0 , T, SelEvi
where:

0
MIn

(NotSocAcc)

= MIn \ {hmid , id , ilf , Bsi}

MIn empty: last semantic rule states that, mail inbox empty,
agent simply goes next step reasoning cycle (SelEv).
MIn = {}
hag, C, M, T, ProcMsgi hag, C, M, T, SelEvi

249

(NoMsg)

fiVieira, Moreira, Wooldridge, & Bordini

4.3 Comments Fault Detection Recovery
distributed system, multi-agent systems (and do) fail real world.
Possibly even typical distributed systems, given multi-agent systems
normally used dynamic, unpredictable environments. contexts, failures
expected happen quite often, agents need recover best possible
way. specific case systems composed AgentSpeak agents, failures occur
when, instance, agent message sent left multi-agent
system, cannot contacted, ceased exist (e.g., machine network
crash). Equally, intention suspended waiting reply may never resumed
due failure agent supposed provide reply. (However, note
AgentSpeak agents typically various concurrent foci attention i.e., multiple
intentions currently set intentions even one particular intention never
progress another agent never replies, agent simply carry working
foci attention.)
context AgentSpeak agents, fault detection recovery start
level infrastructure supports agent execution. infrastructure adopt
techniques available traditional distributed systems fundamental difference:
responsible adding appropriate events signaling failures set CE external
events, possibly resuming suspended intentions immediately making fail
example message reply timed out. events, treated agent
normal reasoning cycle, using plan failure mechanism formalised available
practical interpreters, trigger plan specifically written agent programmer
defines strategy failure recovery. Therefore, point view formal
semantics AgentSpeak, failure recovery reduces event handling plan execution,
partly responsibility underlying execution infrastructure partly
responsibility programmers. note various approaches failure detection recovery within multi-agent systems particular appear literature (e.g.,
Jennings, 1995; Kumar & Cohen, 2000). typically involve use special agents
plans defined deal failure.
natural concern set agents executing concurrently shared
resources always left consistent state. is, course, classical problem
concurrency, typically solved atomically executing parts code access
shared resources. Many programming language constructs enable programmer guarantee atomic execution critical sections. multi-agent system written
AgentSpeak, atomicity immediately issue since critical sections,
given different AgentSpeak agents directly share memory. However, AgentSpeak
agents exchange information form messages, responsibility management exchanges lies underlying message passing infrastructure.
hand, agents multi-agent systems typically share environment, particular application requires environment resources shared agents, clearly programmers
need ensure suitable agent interaction protocols used avoid dead-/live-locks
starvation.
Another possible source concern regarding atomicity concurrent execution
agents intentions. Agents several intentions ready executed one
250

fiSpeech-Act Based Communication Agent Programming

read/write data shared intentions (as access
belief base). scope paper formalise mechanisms control
concurrency, worth mentioning Jason interpreter provides programmers
possibility annotating plans atomic, one
selected execution (see SelInt semantic rule), guaranteed runtime agent
platform plan execution suspended/interrupted (i.e.,
intention selected execution following reasoning cycles) whole
plan finishes executing.
Next, give example intended illustrate semantic rules applied
reasoning cycle. example includes agents exchanging messages using semantic
framework agent communication formalised earlier section.

5. Example Reasoning Cycles Communicating Agents
Consider following scenario. Firefighting robots action trying control rapidly
spreading fire building, supervision commander robot. Another robot
piloting helicopter observe direction fire spreading rapidly. Let
robot helicopter r1, let r2 ground commander, let r3 one
firefighting robots.
One plans r1s plan library, shall refer ps1, shown
Figure 6. plan says soon r1 perceives fire spreading direction D, tells R
fire spreading towards D, R agent believes ground commander.
Plan ps2 one plans robot r2 (the commander) plan library,
also shown Figure 6. Plan ps2 says that, r2 gets believe5 fire spreading
direction D, request robot believed closest part building
achieve state world fighting post robot (in words,
robot relocate part building direction D).
proceed show rules operational semantics apply, using
one reasoning cycle AgentSpeak agent controls r1 example; rules
communication exemplified afterwards. simplicity, assume r1 currently
defined configuration hag 1 , C1 , M1 , T1 , s1 i, s1 = ProcMsg ag 1 component
having:
ag 1bs = {commander(r2)},
ag 1ps = {ps1}.
Suppose r1 perceived fire spreading towards south. belief revision function (see Section 3.2) operated, r1s beliefs updated ag 1bs =
{commander(r2), spreading(south)} C1E component r1s configuration (i.e.,
set events) follows:
C1E = {h+spreading(south), Ti}.
5. Note that, plans triggering event require particular source information (as in, e.g., +spreading(D)[percept]), plan used belief acquired
communication well perception environment.

251

fiVieira, Moreira, Wooldridge, & Bordini

r1s plan ps1
+spreading(D)
: commander(R);
<- .send(R,tell,spreading(D)).
r2s plan ps2
+spreading(D)
: closest(D,A);
<-.send(A,achieve,fight post(A,D)).

Figure 6: Plans used firefighting robots example.
point, show sequence rules applied complete one
reasoning cycle: see Table 1, left column shows rule applied
right column shows components configuration changed
consequence rule applied. Note next step component s1
changes obvious way (given rules applied), show change
first step, messages processed cycle goes straight
selecting event handled reasoning cycle.
Table 1: Example sequence rules applied one reasoning cycle.
Rule
Changed Configuration Components
NoMsg
s1 = SelEv
SelEv1
C1E = {}
T1 = h+spreading(south), Ti
Rel1
T1R = {(ps1, R )}, R = {D 7 south}
Appl1
T1Ap = {(ps1, )}, = {D 7 south, R 7 r2}
SelApp
T1 = (ps1, )
ExtEv
C1I = {[ps1A ]}
SelInt1
T1 = [ps1A ]
ExecActSnd M1Out = {hmid 1 , r2, Tell , {spreading(south)i}}
C1I = {[+spreading(south) : commander(r2) <- T]}
ClrInt1
C1I = {}

r1s reasoning cycle shown table, rule MsgExchg applies and, assuming
hag 2 , C2 , M2 , T2 , s2 r2s configuration, simplicity assume initial (i.e.,
empty) configuration hence s2 = ProcMsg, shall that:
252

fiSpeech-Act Based Communication Agent Programming

M2In = {hmid 1 , r1, Tell , {spreading(south)}i},
leads rule Tell applied, thus starting reasoning cycle (similar
one Table 1) r2 configuration following components
changed (see Rule Tell):
M2In = {}
ag 2bs = {spreading(south)[r1]}
C2E = {h+spreading(south)[r1], Ti}.
reasoning cycle r2, would r3 that:
M3In = {hmid 2 , r2, Achieve, fight post(r3,south)i},
M3In r3s mail inbox (and assuming M3In previously empty). Note r3s
SocAcc function used rule Achieve (leading mid 2 included M3In stated
above) would probably consider hierarchy determined firefighters ranks. Robot
r3 would consider events generated received message subsequent
reasoning cycles, would act accordance plans plan library,
show here, simplicity.

6. Developing Elaborate Communication Structures
sometimes require elaborate communication structures performatives
discussed Section 4. hand, course important keep
communication scheme semantic basis simple possible. emphasise that,
approach, sophisticated communication structures programmed, top
basic communication features formalised here, use plans implement
interaction protocols. practical AgentSpeak interpreters, communication features
(built composing atomic performatives) provided programmers either
extra pre-defined performatives plan templates plan libraries made publicly available
Jason (Bordini & Hubner, 2007), former approach used, latter
also possible. section, give, examples advanced communication
features, plans allow agents reach shared beliefs ensure agents kept
informed adoption goals agents. Note however examples
make use simple practical feature (available, e.g., Jason) appear
abstract syntax used earlier formal presentation: variable instantiated
first order term used, within certain constructs (such belief goal additions),
place atomic formula, usual also Prolog implementations.
Example 1 (Shared Beliefs) network infrastructure reliable, easy ensure
agents reach shared beliefs. reaching shared belief, mean two agents believing
b well believing agent also believes b. explicitly, say agents
ag1 ag2 share belief b ag1 believes b[self] b[ag2], time ag2
253

fiVieira, Moreira, Wooldridge, & Bordini

believes b[self] b[ag1]. order allow agents ag1 ag2 reach shared
beliefs, suffices6 provide agents copies following plans:
rsb1
+!reachSharedBel(P,A) : P[self]
<- +P;
!reachSharedBel(P,A).
rsb2
+!reachSharedBel(P,A) : P[self] & P[A]
<- .send(A,tell,P);
.send(A,achieve,reachSharedBel(P,me)).
rsb3
+!reachSharedBel(P,A) : P[self] & P[A]
<- true.
plans above, stands agents name. (Recall that, Prolog,
uppercase initial denotes logical variable.) Assume agent ag1 plans
plan, instance currently set intentions, requires
ag2 share belief p(X). plan would following goal body:
!reachSharedBel(p(X),ag2). would eventually lead execution plans
example above, explained. plan labelled rsb1 says ag1
(new) goal reaching shared belief P agent A, case ag1 yet believe
P itself, first make sure believes P note +P; body
plan add ground predicate bound P source self new belief agent
ag1 goal reaching shared belief (note
recursive plan). time, plan rsb1 longer applicable, rsb2 chosen
execution. Plan rsb2 says that, provided ag1 believes P yet believe
agent believes P, tell agent (ag1) believes P, finally ask
also achieve shared belief ag1.
Agent ag2, also copies plans example above, would then, given
appropriate SocAcc function, instance plan rsb1 set intentions,
eventually execute rsb2 well, directly rsb2 case may be. Note
last line plan rsb2, executed agent asked reach shared believe,
rather one took initiative, redundant lead agent
using rsb3, says action required, given shared
belief already obtained. Clearly, efficient ways implementing
protocol reaching shared belief, present plans
used regardless whether agent takes initiative reach shared belief not.
version give therefore arguably elegant, symmetry facilitates
reasoning protocol.
6. Even agents plans advance, willing told reach shared
beliefs (by accepting TellHow messages agents know-how), become capable
reaching shared beliefs too.

254

fiSpeech-Act Based Communication Agent Programming

give another example, shows agents information
requests goal adoption (i.e., ask another agent achieve state
affairs behalf).
Example 2 (Feedback Goal Adoption) often case that, one agent asks
another agent something, may want least reassurance
agent agreed whatever asked. Furthermore, may want
know agent believes accomplished task. following plans
used ag1 delegate tasks ag2 way.
ag1 plans:
nsd1
+needDoneBy(G,A) : delegatedTo(G,A)
<- +delegatedTo(G,A);
.send(A,achieve,doAndFeedbackTo(G,me)).
nsd2
+needDoneBy(G,A)
: agreedToDo(G)[A] & finishedDoing(G)[A]
<- .send(A,tell,shouldHaveFinished(G));
...
nsd3
+needDoneBy(G,A) : finishedDoing(G)[A]
<- ...
...
fd
+finishedDoing(G)[A] : true
<- -delegatedTo(G,A);
-agreedToDo(G)[A].

ag2 plans:
dft1
+!doAndFeedbackTo(G,A) : cntxt1
<- .send(A,tell,agreedToDo(G));
+!G;
.send(A,tell,finishedDoing(G)).
dft2
+!doAndFeedbackTo(G,A) : cntxt2
<- .send(A,tell,cannotDo(G)).
255

fiVieira, Moreira, Wooldridge, & Bordini

example above, assume something perceived environment leads
agent believe needs goal G achieved agent A,
perception recurs certain intervals, need motivated request still exists
result achieving G observed. Plan nsd1 used need
occurs request yet sent A. plan ensures ag1 remember
already asked (say, ag2) G agent achieve goal associated
special plan: see plan dft1 ag2. plan makes sure requesting agent
informed ag2 adopted goal requested (before attempts achieve
it) well agent believes achieved G. programmer define
SocAcc function ag2 accepts requests ag1, programmer still
determine autonomous ag2 using appropriate plan contexts. plan dft1,
context cntxt1 would determine circumstances agent ag2 believes
able adopt goal, context cntxt2 , plan dft2, used circumstances
ag2 simply inform adopt goal requested ag1 (a
elaborate plan could explain agent cannot adopt goal, example case
one situation goal cannot adopted).
Going back plans nsd2 nsd3 agent ag1, former used put pressure
agent adopted ag1s goal G, need perceived
already agreed that, presumably fast enough. Clearly,
shouldHaveFinished belief trigger plan ag2 desired
effect. Plan nsd3 template one various alternative courses actions
taken ag1 need motivated request ag2 adopt goal still exists
ag2 believes goal already achieved: might old belief needs
revised new request made, ag1 could try asking another agent, inform ag2
belief achieving G might wrong, etc. Plan fd used simply remove
unnecessary beliefs used previous stages interaction aimed goal adoption.
difficult see plans important multi-agent issues, ensuring
agents jointly committed course action, developed elaborating
combinations communication performatives along lines examples above.
hand, many complications related agent interaction might need
accounted could addressed simple examples provided here,
shared beliefs becoming inaccurate passage time. plans go
ones shown would required coping complications, necessary
particular applications.

7. Proving Communication Properties AgentSpeak Agents
Bordini Moreira (2004) introduced framework proving BDI properties
AgentSpeak agents based operational semantics. framework included precise
definitions BDI modalities interpreted terms configurations transition system gives semantics AgentSpeak. definitions used
work model checking AgentSpeak (Bordini et al., 2004), allows use
automated techniques verification AgentSpeak programs. Below, give example
proof using operational semantics simple property involves belief
modality. belief modality clear respect AgentSpeak agent, given
256

fiSpeech-Act Based Communication Agent Programming

architecture includes belief base explicitly, avoid need discuss
paper previous work interpretation modalities (Bordini & Moreira, 2004).
Proposition 1 (Reachability Shared Beliefs) two AgentSpeak agents ag1
ag2 plan libraries rsb1, rsb2, rsb3 plans shown Example 1, also appropriate SocAcc function well usual implementation selection functions (or others fairness also guaranteed, sense
events intentions eventually selected), moment time ag1
reachSharedBel(b,ag2 ) goal set events (i.e., event
h+!reachSharedBel(b,ag2 ), ii, intention), eventually agents believe b believe agent also believes b note formulated
using BDI-like logic top LTL
3((Bel ag1 b[self ]) (Bel ag2 b[ag1 ]) (Bel ag2 b[self ]) (Bel ag1 b[ag2 ])).
Proof.
assumed ag1 h+!reachSharedBel(b, ag2 ), ii set events.
Assume precisely event selected rule SelEv1 applied.
rule Rel1 would select plans rsb1, rsb2, rsb3 relevant chosen event. Rule
Appl1 would narrow rsb1 as, presumably, ag1 yet believe b
itself. Rule SelAppl would necessarily select rsb1 intended means, given
applicable plan, rule IntEv would include i[rsb1] set intentions (i.e.,
chosen intended means would pushed top intention generated
event above). Consider reasoning cycle (for simplicity), rule SelInt1
would choose precisely intention execution within reasoning cycle. rule
AddBel would add b[self ] ag1 belief base, hence (Bel ag1 b[self ]).
subsequent reasoning cycles, ag1 intention selection function selects
intention execution, rule AchvGl would generate internal event
h+!reachSharedBel(b, ag2 ), ii. process expect plan rsb1
longer applicable, rsb2 is, therefore chosen intended means.
plan executed (similarly described above), rule ExecActSnd would add message
hmid1 , ag2 , Tell , bi ag1 MOut component. Rule MsgExchg ensures message hmid, ag1 , Tell , bi added ag2 MIn component, beginning
next reasoning cycle would lead rule Tell adding b[ag1 ] ag2 belief base, hence
(Bel ag2 b[ag1 ]). intention selected execution third reasoning cycle, final formula body plan rsb1 would executed. use similar rules sending receiving messages, would ag2 receiving message
hmid2 , ag1 , Achieve, reachSharedBel(b, ag1 )i, rule Achieve used interpreting
illocutionary force message, thus adding event h+!reachSharedBel(b, ag1 ), ii
ag2 set events. Note precisely process started ag1
sequence rules apply ag2 , will, symmetrically, lead
(Bel ag2 b[self ]) (Bel ag1 b[ag2 ]) true, eventually. point time
((Bel ag1 b[self ]) (Bel ag2 b[ag1 ]) (Bel ag2 b[self ]) (Bel ag1 b[ag2 ])).
discussed earlier, ag2 using exact copies plans used ag1 , ag2
also ask ag1 reach b shared belief, even though ag1 already executed part
257

fiVieira, Moreira, Wooldridge, & Bordini

joint plan. plan rsb3 important. ensures agent act
part joint plan reaching shared belief already
achieved.
Note, however, possible guarantee shared belief reached
possible runs neither agent plans interfere negatively execution
plans given Example 1, example forcing deletion instance
belief b shared belief reached. verification exercise different
proposition wanted prove, showing shared beliefs reached (under
given assumptions).

8. Applications AgentSpeak Ongoing Work
mention applications written AgentSpeak. AgentSpeak programming language also used academia student projects various courses.
noted, however, language clearly suited large range applications known BDI systems appropriate; various applications PRS
(Georgeff & Lansky, 1987) dMARS (Kinny, 1993), example, appeared
literature (Wooldridge, 2002, Chapter 11).
One particular area application great interest Social Simulation
(Doran & Gilbert, 1994). fact, AgentSpeak used part project produce
platform tailored particularly social simulation. platform called MAS-SOC developed Bordini, da Rocha Costa, Hubner, Moreira, Okuyama, Vieira (2005);
includes high-level language called ELMS (Okuyama, Bordini, & da Rocha Costa,
2005) describing environments shared multiple agents. approach
used develop, example, social simulation social aspects urban growth (Krafta,
de Oliveira, & Bordini, 2003). Another area application initially explored
use AgentSpeak defining behaviour animated characters computer
animation virtual reality environments (Torres, Nedel, & Bordini, 2004).
recently, AgentSpeak used implementation team gold
miners entry agent programming competition (Bordini, Hubner, & Tralamazza,
2006). scenario7 , teams agents must coordinate actions order collect
much gold deliver gold trading agent located depot
gold safely stored. AgentSpeak team, composed four mining agents one
leader helped coordinate team miners, competition 2006. worth
noting language support high-level communication (formalised paper)
proved important feature designing implementing system.
AgentSpeak interpreter multi-agent platform Jason constantly improved, long term goal supporting various multi-agent systems technologies.
important aspect Jason precisely formal semantics
essential features. Various projects currently looking extending Jason various
ways, example combine organisational model one propose
Hubner, Sichman, Boissier (2004). particularly important given social
structure fundamental notion developing complex multi-agent systems. Another
area development incorporate ontologies AgentSpeak belief base (Moreira,
7. See http://cig.in.tu-clausthal.de/CLIMAContest/ details.

258

fiSpeech-Act Based Communication Agent Programming

Vieira, Bordini, & Hubner, 2006; Vieira, Moreira, Bordini, & Hubner, 2006), facilitating
use Jason Semantic Web applications. Recent work also considered automated
belief revision (Alechina, Bordini, Hubner, Jago, & Logan, 2006) plan exchange mechanisms (Ancona et al., 2004). detailed description language comparison
agent-oriented programming languages given Bordini et al. (2005).

9. Conclusions
pointed Singh (1998), various perspectives semantics agent
communication. Whereas senders perspective common one literature,
approach uses primarily receiver. given formal semantics
processing speech-act based messages AgentSpeak agent. Previous attempts
define semantics agent communication languages (e.g., Labrou & Finin, 1994)
based pre-condition action post-condition approach, referring agent mental states modal languages typically based Cohen Levesques work intention
(1990a). semantics communication, besides closely linked implementation (as serves specification interpreter agent programming
language), also used proof communication properties (Wooldridge, 2000c).
work somewhat related de Boer, van Eijk, Van Der Hoek, Meyer
(2000) van Eijk, de Boer, Van Der Hoek, Meyer (2003), also provide
operational semantics agent communication language. However, work
consider effects communication terms BDI-like agents (such written
AgentSpeak). idea giving semantics speech-act based communication within
BDI programming language first introduced Moreira et al. (2004). Subsequently,
Dastani, van der Ham, Dignum (2003) also published initial work semantics communication 3APL agents, although emphasis formalising
message exchange mechanisms synchronous asynchronous communication.
contrast, largely abstract away specific message exchange mechanism (this
formalised high level semantics), interested asynchronous
communication (which usual communication model cognitive agents). order
illustrate message exchange mechanism, Dastani et al. gave semantics effects
receiving treating request inform messages is, consider
information exchange. work uses much comprehensive selection illocutionary
forces, main contribution precisely giving detailed semantics ways
various illocutionary forces affect mental states agents implemented
programming language actually precise definitions notions BDI
architecture. denotational semantics agent communication languages proposed
Guerin Pitt (2001), semantics given abstract version ACL
address issues interaction ACL components
agent architecture.
paper provided new semantic rules illocutionary forces used
communication language AgentSpeak agents. giving semantics communicating
AgentSpeak agents, provided means implementation AgentSpeak
interpreters functionality, well given computationally grounded
semantics speech-act based agent communication. fact, operational semantics
259

fiVieira, Moreira, Wooldridge, & Bordini

presented paper proved useful implementation AgentSpeak interpreters
Jason (Bordini & Hubner, 2007). Singhs proposal social-agency based
semantics (1998) may appropriate general purpose agent communication languages
FIPA KQML, within context BDI agent programming language,
approach used without drawbacks pointed Singh.
fact deal intentional states agents giving semantics communication leads us number related pragmatic questions. First, many
treatments speech-act style communication make use mutual mental states mutual
belief, common knowledge, similar. make use mutual mental states
formalisation. good reasons this. First, although mutual mental states
useful elegant tool analysis, known represent theoretical idealisations
only, cannot achieved systems admit possibility message delivery
failure (Halpern, 1990). Thus, although mutual mental states useful abstraction
understanding communication works, cannot, realistically, implemented,
always mismatch implementation (which excludes possibility mutual mental states faithfully implemented) theory. primarily
mutual mental states form part language semantics, built top
fundamental communication primitives formalised paper, shown
Section 6. Note also known mutual mental states simulated,
desired degree nesting, appropriate message acknowledgement scheme (Halpern &
Zuck, 1992), therefore approach problem solved mechanisms
processed messages triggering action sending message acknowledges receipt.
also worth adding belief annotation scheme used language permits agents
simple mechanism nested beliefs: annotation source belief
indication agent sent message believed propositional content
time message sent (but note indication only, unless agent veracity
guaranteed). Annotation information source time message received done
automatically according semantics given. However, programmers also
use belief base register sent messages, possibly using annotations manner
received messages. would function indication agents states
mind, point view sender. plan deal questions
lie gray area semantics pragmatics detail future work.
discussing models mutual mental states, also mention passing
joint intentions form part semantics, although widely used
implementation coordination schemes multi-agent systems, following seminal
work Levesque, Cohen, Nunes (1990). fact constructs built
language (or language semantics) primitives preclude
implemented using language constructs, provided usual practical considerations
assumptions, limiting number required acknowledgement messages
achievement shared beliefs, place. Indeed, exactly approach taken
Tambe, STEAM system (1997), Jennings, GRATE* system (1995).
examples Section 6 help indicate achieved elaboration
plans, making use communication primitives gave semantics
paper.
260

fiSpeech-Act Based Communication Agent Programming

anticipate readers ponder whether semantics limits autonomy
agents use approach communication. provide SocAcc() function
works initial filter, may give impression beliefs
acquired/trusted goals adopted simple filter. important emphasise actual behaviour agent ensuing communication received
agents completely depends particular plans agent happens
plan library; current semantics, ask variants, TellHow , UntellHow
performatives dependent solely SocAcc filter. Example 2, mentioned
plan contexts used determine whether agent would actually act towards achieving goal requested another agent, choose commit achieving
goal. general rule: agent autonomy depends plans given
agent programmer obtained communication agents (the plans currently
agents plan library). would typically programmers responsibility write
plans ensure agent sufficiently autonomous purpose given
application or, use interesting notion, program agents adjustable autonomy. Similarly, benevolent self-interested agent be, extent
beliefs acquired agents trusted, issues programmers
careful about: semantics communication ensure one case
other. Needless say, much difficult task program agents take
part open systems agents self-interested cannot trusted.
agent programming language combined suitable agent communication language
gives much support task, surely automatically solve problems;
still remains complex programming task.
also worth commenting semantics used researchers,
particularly using agent programming languages AgentSpeak. main
point semantics provides reference semantics communication
language used context agent-oriented programming. is, using semantics, possible predict exactly particular AgentSpeak agent would interpret
particular message given situation. Using reference model,
principle possible implement communication agent programming languages.
course, semantics language independent: developed specifically
AgentSpeak, language specifics ought considered. However, attempts giving
semantics agent communication language independent problems,
notably computational grounding problem referred above. semantics,
developed specifically practical agent programming language, advantage
relying mechanisms (such abstractly defined mental states) cannot checked
real programs. note that, best knowledge, work represents first
semantics given speech-act style, knowledge level communication language
used real system.
current work consider commissive declarative speech acts.
surely relevant topics future work, since commissive acts declarations relevant
various forms agent interaction, negotiation. Nevertheless, proposed
framework possible programmer multi-agent system designer incorporate
elaborate forms interactions writing appropriate plans.
261

fiVieira, Moreira, Wooldridge, & Bordini

work, assume communication occurs among agents written
programming language, cannot adopted directly heterogeneous multi-agent systems. (Consider, example, issues arising processing AskHow performative,
involves sending plan another agent.) However, variety agent
languages, difficult write wrappers translating message contents.
relevant areas future investigation regarding role definitions
social structures agent organisations. consider would interesting developments proposed SocAcc() function libraries plans plan patterns. Deontic
relationships social norms also closely related extensions. case
e-business, instance, contract usually creates number obligations contractors.
Future work also consider giving better formal treatment information sources,
particular case plans exchanged agents. communication aspects ontological agreement among AgentSpeak agents, reasoning
information sources (e.g., executing test goals choosing plans based annotations)
also considered future work. expect sophisticated multi-agent system
applications developed AgentSpeak interpreters implemented according
semantics.

Acknowledgements
Many thanks Jomi F. Hubner comments suggestions earlier version
paper, Berndt Farwer Louise Dennis carefully proofread it. first
second authors acknowledge support CNPq.

References
Alechina, N., Bordini, R. H., Hubner, J. F., Jago, M., & Logan, B. (2006). Automating
belief revision agentspeak. Baldoni, M., & Endriss, U. (Eds.), Proceedings
Fourth International Workshop Declarative Agent Languages Technologies
(DALT 2006), held AAMAS 2006, 8th May, Hakodate, Japan, pp. 116.
Allen, J. F., Hendler, J., & Tate, A. (Eds.). (1990). Readings Planning. Morgan Kaufmann.
Ancona, D., Mascardi, V., Hubner, J. F., & Bordini, R. H. (2004). Coo-AgentSpeak:
Cooperation AgentSpeak plan exchange. Jennings, N. R., Sierra, C.,
Sonenberg, L., & Tambe, M. (Eds.), Proceedings Third International Joint
Conference Autonomous Agents Multi-Agent Systems (AAMAS-2004), New
York, NY, 1923 July, pp. 698705 New York, NY. ACM Press.
Austin, J. L. (1962). Things Words. Oxford University Press, London.
Ballmer, T. T., & Brennenstuhl, W. (1981). Speech Act Classification: Study
Lexical Analysis English Speech Activity Verbs. Springer-Verlag, Berlin.
262

fiSpeech-Act Based Communication Agent Programming

Bordini, R. H., Bazzan, A. L. C., Jannone, R. O., Basso, D. M., Vicari, R. M., & Lesser,
V. R. (2002). AgentSpeak(XL): Efficient intention selection BDI agents via decisiontheoretic task scheduling. Castelfranchi, C., & Johnson, W. L. (Eds.), Proceedings
First International Joint Conference Autonomous Agents Multi-Agent
Systems (AAMAS-2002), 1519 July, Bologna, Italy, pp. 12941302 New York, NY.
ACM Press.
Bordini, R. H., da Rocha Costa, A. C., Hubner, J. F., Moreira, A. F., Okuyama, F. Y., &
Vieira, R. (2005). MAS-SOC: social simulation platform based agent-oriented
programming. Journal Artificial Societies Social Simulation, 8 (3). JASSS
Forum, <http://jasss.soc.surrey.ac.uk/8/3/7.html>.
Bordini, R. H., Fisher, M., Pardavila, C., & Wooldridge, M. (2003). Model checking
AgentSpeak. Rosenschein, J. S., Sandholm, T., Wooldridge, M., & Yokoo, M.
(Eds.), Proceedings Second International Joint Conference Autonomous
Agents Multi-Agent Systems (AAMAS-2003), Melbourne, Australia, 1418 July,
pp. 409416 New York, NY. ACM Press.
Bordini, R. H., Fisher, M., Visser, W., & Wooldridge, M. (2004). Model checking rational
agents. IEEE Intelligent Systems, 19 (5), 4652.
Bordini, R. H., & Hubner, J. F. (2007).
Jason:
Java-based Interpreter Extended version AgentSpeak (Manual, version 0.9 edition).
http://jason.sourceforge.net/.
Bordini, R. H., Hubner, J. F., & Tralamazza, D. M. (2006). Using Jason implement
team gold miners (a preliminary design). Inoue, K., Satoh, K., & Toni, F.
(Eds.), Proceedings Seventh Workshop Computational Logic Multi-Agent
Systems (CLIMA VII), held AAMAS 2006, 89th May, Hakodate, Japan, pp.
233237. (Clima Contest paper).
Bordini, R. H., Hubner, J. F., & Vieira, R. (2005). Jason Golden Fleece
agent-oriented programming. Bordini, R. H., Dastani, M., Dix, J., & El Fallah Seghrouchni, A. (Eds.), Multi-Agent Programming: Languages, Platforms,
Applications, chap. 1. Springer-Verlag.
Bordini, R. H., & Moreira, A. F. (2004). Proving BDI properties agent-oriented programming languages: asymmetry thesis principles AgentSpeak(L). Annals
Mathematics Artificial Intelligence, 42 (13), 197226. Special Issue Computational Logic Multi-Agent Systems.
Bordini, R. H., Visser, W., Fisher, M., Pardavila, C., & Wooldridge, M. (2003). Model
checking multi-agent programs CASP. Hunt Jr., W. A., & Somenzi, F. (Eds.),
Proceedgins Fifteenth Conference Computer-Aided Verification (CAV-2003),
Boulder, CO, 812 July, No. 2725 LNCS, pp. 110113 Berlin. Springer-Verlag. Tool
description.
Bratman, M. E. (1987). Intentions, Plans Practical Reason. Harvard University Press,
Cambridge, MA.
263

fiVieira, Moreira, Wooldridge, & Bordini

Castelfranchi, C., & Falcone, R. (1998). Principles trust MAS: Cognitive anatomy,
social importance, quantification. Demazeau, Y. (Ed.), Proceedings Third
International Conference Multi-Agent Systems (ICMAS98), 47 July, Paris, pp.
7279 Washington. IEEE Computer Society Press.
Cohen, P., & Perrault, R. (1979). Elements plan based theory speech acts. Cognitive
Science, 3, 177212.
Cohen, P. R., & Levesque, H. J. (1990a). Intention choice commitment. Artificial
Intelligence, 42 (3), 213261.
Cohen, P. R., & Levesque, H. J. (1990b). Rational interaction basis communication. Cohen, P. R., Morgan, J., & Pollack, M. E. (Eds.), Intentions Communication, chap. 12, pp. 221255. MIT Press, Cambridge, MA.
Dastani, M., van der Ham, J., & Dignum, F. (2003). Communication goal directed
agents. Huget, M.-P. (Ed.), Communication Multiagent Systems, Vol. 2650
LNCS, pp. 239252. Springer-Verlag.
de Boer, F. S., van Eijk, R. M., Van Der Hoek, W., & Meyer, J.-J. C. (2000). Failure
semantics exchange information multi-agent systems. Palamidessi, C.
(Ed.), Eleventh International Conference Concurrency Theory (CONCUR 2000),
University Park, PA, 2225 August, No. 1877 LNCS, pp. 214228. Springer-Verlag.
Doran, J., & Gilbert, N. (1994). Simulating societies: introduction. Gilbert, N., &
Doran, J. (Eds.), Simulating Society: Computer Simulation ofSocial Phenomena,
chap. 1, pp. 118. UCL Press, London.
Genesereth, M. R., & Ketchpel, S. P. (1994). Software agents. Communications
ACM, 37 (7), 4853.
Georgeff, M. P., & Lansky, A. L. (1987). Reactive reasoning planning. Proceedings
Sixth National Conference Artificial Intelligence (AAAI87), 1317 July,1987,
Seattle, WA, pp. 677682 Manlo Park, CA. AAAI Press / MIT Press.
Ghallab, M., Nau, D., & Traverso, P. (2004). Automated Planning: Theory Practice.
Morgan Kaufmann.
Guerin, F., & Pitt, J. (2001). Denotational semantics agent communication language.
Proceedings fifth international conference Autonomous Agents (Agents
2001), 28th May 1st June, Montreal Canada, pp. 497504. ACM Press.
Halpern, J. Y. (1990). Knowledge common knowledge distributed environment.
Journal ACM, 37 (3).
Halpern, J. Y., & Zuck, L. D. (1992). little knowledge goes long way: knowledge-based
derivations correctness proofs family protocols. Journal ACM,
39 (3), 449478.
264

fiSpeech-Act Based Communication Agent Programming

Hubner, J. F., Sichman, J. S., & Boissier, O. (2004). Using Moise+ cooperative
framework MAS reorganisation.. Bazzan, A. L. C., & Labidi, S. (Eds.), Advances
Artificial Intelligence - SBIA 2004, 17th Brazilian Symposium Artificial Intelligence, Sao Luis, Maranhao, Brazil, September 29 - October 1, 2004, Proceedings, Vol.
3171 LNCS, pp. 506515. Springer-Verlag.
Jennings, N. R. (1995). Controlling cooperative problem solving industrial multi-agent
systems using joint intentions. Artificial Intelligence, 75 (2), 195240.
Kinny, D. (1993). distributed multi-agent reasoning system architecture language
specification. Tech. rep., Australian Artificial Intelligence Institute, Melbourne, Australia.
Krafta, R., de Oliveira, D., & Bordini, R. H. (2003). city object human agency.
Fourth International Space Syntax Symposium (SSS4), London, 1719 June, pp.
33.133.18.
Kumar, S., & Cohen, P. R. (2000). Towards fault-tolerant multi-agent system architecture.
Proceedings Fourth International Conference Autonomous Agents (Agents
2000), 37 June, Barcelona, Spain, pp. 459466. ACM Press.
Labrou, Y., & Finin, T. (1994). semantics approach KQMLa general purpose
communication language software agents. Proceedings Third International
Conference Information Knowledge Management (CIKM94), 29th November
2nd December, Gaithersburg, MD. ACM Press.
Labrou, Y., Finin, T., & Peng, Y. (1999). current landscape agent communication
languages. Intelligent Systems, 14 (2), 4552.
Levesque, H. J., Cohen, P. R., & Nunes, J. H. T. (1990). acting together. Proceedings
Eighth National Conference Artificial Intelligence (AAAI-1990), 29th July
3rd August, Boston, MA, pp. 9499. AAAI Press.
Levinson, S. C. (1981). essential inadequacies speech act models dialogue. Parret, H., Sbisa, M., & Verschuren, J. (Eds.), Possibilities limitations pragmatics:
Proceedings Conference Pragmatics Urbino, July, 1979, pp. 473492. Benjamins, Amsterdam.
Mayfield, J., Labrou, Y., & Finin, T. (1996). Evaluation KQML agent communication language. Wooldridge, M., Muller, J. P., & Tambe, M. (Eds.), Intelligent
Agents IIProceedings Second International Workshop Agent Theories, Architectures, Languages (ATAL95), held part IJCAI95, Montreal, Canada,
August1995, No. 1037 LNAI, pp. 347360 Berlin. Springer-Verlag.
Moreira, A. F., & Bordini, R. H. (2002). operational semantics BDI agent-oriented
programming language. Meyer, J.-J. C., & Wooldridge, M. J. (Eds.), Proceedings
Workshop Logics Agent-Based Systems (LABS-02), held conjunction
Eighth International Conference Principles Knowledge Representation
Reasoning (KR2002), April 2225, Toulouse, France, pp. 4559.
265

fiVieira, Moreira, Wooldridge, & Bordini

Moreira, A. F., Vieira, R., & Bordini, R. H. (2004). Extending operational semantics
BDI agent-oriented programming language introducing speech-act based communication. Leite, J., Omicini, A., Sterling, L., & Torroni, P. (Eds.), Declarative
Agent Languages Technologies, Proceedings First International Workshop
(DALT-03), held AAMAS-03, 15 July, 2003, Melbourne, Australia (Revised Selected Invited Papers), No. 2990 LNAI, pp. 135154 Berlin. Springer-Verlag.
Moreira, A. F., Vieira, R., Bordini, R. H., & Hubner, J. F. (2006). Agent-oriented programming underlying ontological reasoning. Baldoni, M., Endriss, U., Omicini, A.,
& Torroni, P. (Eds.), Proceedings Third International Workshop Declarative
Agent Languages Technologies (DALT-05), held AAMAS-05, 25th July,
Utrecht, Netherlands, No. 3904 LNCS, pp. 155170. Springer-Verlag.
Okuyama, F. Y., Bordini, R. H., & da Rocha Costa, A. C. (2005). ELMS: environment
description language multi-agent simulations. Weyns, D., van Dyke Parunak,
H., Michel, F., Holvoet, T., & Ferber, J. (Eds.), Environments Multiagent Systems, State-of-the-art Research Challenges. Proceedings First International
Workshop Environments Multiagent Systems (E4MAS), held AAMAS-04,
19th July, No. 3374 LNAI, pp. 91108 Berlin. Springer-Verlag.
Plotkin, G. (1981). structural approach operational semantics.. Technical Report,
Department Computer Science, Aarhus University.
Rao, A. S. (1996). AgentSpeak(L): BDI agents speak logical computable language.
van de Velde, W., & Perram, J. (Eds.), Proceedings 7th Workshop Modelling Autonomous Agents Multi-Agent World (MAAMAW96), 2225 January,
Eindhoven, Netherlands, No. 1038 LNAI, pp. 4255 London. Springer-Verlag.
Rao, A. S., & Georgeff, M. P. (1998). Decision procedures BDI logics. Journal Logic
Computation, 8 (3), 293343.
Searle, J. R. (1969). Speech Acts: Essay Philosophy Language. Cambridge
University Press, Cambridge.
Singh, M. P. (1994). Multiagent SystemsA Theoretic Framework Intentions, KnowHow, Communications. No. 799 LNAI. Springer-Verlag, Berlin.
Singh, M. P. (1998). Agent communication languages: Rethinking principles. IEEE
Computer, 31 (12), 4047.
Smith, R. G. (1980). contract net protocol: High-level communication control
distributed problem solver. IEEE Transactions Computers, c-29 (12), 11041113.
Tambe, M. (1997). Towards flexible teamwork. Journal Artificial Intelligence Research,
7, 83124.
Torres, J. A., Nedel, L. P., & Bordini, R. H. (2004). Autonomous agents multiple foci
attention virtual environments. Proceedings 17th International Conference
Computer Animation Social Agents (CASA 2004), Geneva, Switzerland, 79
July, pp. 189196.
266

fiSpeech-Act Based Communication Agent Programming

van Eijk, R. M., de Boer, F. S., Van Der Hoek, W., & Meyer, J.-J. C. (2003). verification
framework agent communication. Autonomous Agents Multi-Agent Systems,
6 (2), 185219.
Vieira, R., Moreira, A. F., Bordini, R. H., & Hubner, J. (2006). agent-oriented programming language computing context. Debenham, J. (Ed.), Proceedings
Second IFIP Symposium Professional Practice Artificial Intelligence, held
19th IFIP World Computer Congress, TC-12 Professional Practice Stream, 2124
August, Santiago, Chile, No. 218 IFIP, pp. 6170 Berlin. Springer-Verlag.
Wooldridge, M. (1998). Verifiable semantics agent communication languages. Proceedings Third International Conference Multi-Agent Systems (ICMAS98),
47 July, Paris, pp. 349365. IEEE Computer Society Press.
Wooldridge, M. (2000a). Computationally grounded theories agency. Durfee, E. (Ed.),
Proceedings Fourth International Conference Multi-Agent Systems (ICMAS2000),1012 July, Boston, pp. 1320 Los Alamitos, CA. IEEE Computer Society.
Paper Invited Talk.
Wooldridge, M. (2000b). Reasoning Rational Agents. MIT Press, Cambridge,
MA.
Wooldridge, M. (2000c). Semantic issues verification agent communication languages. Autonomous Agents Multi-Agent Systems, 3 (1), 931.
Wooldridge, M. (2002). Introduction MultiAgent Systems. John Wiley & Sons.

267

fiJournal Artificial Intelligence Research 29 (2007) 79-103

Submitted 09/06; published 06/07

NP Animacy Identification Anaphora Resolution
Constantin Orasan
Richard Evans

C.Orasan@wlv.ac.uk
R.J.Evans@wlv.ac.uk

Research Group Computational Linguistics
School Humanities, Languages Social Sciences
University Wolverhampton
Stafford St., Wolverhampton, WV1 1SB
United Kingdom

Abstract
anaphora resolution English, animacy identification play integral role
application agreement restrictions pronouns candidates, result,
improve accuracy anaphora resolution systems. paper, two methods
animacy identification proposed evaluated using intrinsic extrinsic measures.
first method rule-based one uses information unique beginners
WordNet classify NPs basis animacy. second method relies
machine learning algorithm exploits WordNet enriched animacy information
sense. effect word sense disambiguation two methods also assessed.
intrinsic evaluation reveals machine learning method reaches human levels
performance. extrinsic evaluation demonstrates animacy identification
beneficial anaphora resolution, especially cases animate entities
identified high precision.

1. Introduction
Anaphora resolution process attempts determine meaning expressions
pronouns definite descriptions whose interpretation depends previously
mentioned entities discourse segments. Anaphora resolution important
many fields computational linguistics machine translation, natural language
understanding, information extraction text generation (Mitkov, 2002).
Previous work anaphora resolution (AR) shown levels performance
related type text processed average number noun
phrases (NPs) consideration pronouns antecedent (Evans & Orasan, 2000).
Acknowledging this, researchers proposed incorporated various methods intended
reduce number candidate NPs considered anaphora resolution systems.
approaches pronominal anaphora resolution rely compatibility agreement
features pronouns antecedents, means minimising number NP
candidates. Although, noted Barlow (1998) Barbu, Evans, Mitkov (2002),
assumption always hold, reliable enough cases great practical
value anaphora coreference resolution systems. systems rely knowledge
number gender NP candidates order check compatibility
pronouns candidates (Hobbs, 1976; Lappin & Leass, 1994; Kennedy & Boguraev, 1996;
Mitkov, 1998; Cardie & Wagstaff, 1999; Ng & Cardie, 2002). addition number

c
2007
AI Access Foundation. rights reserved.

fiOrasan & Evans

gender compatibility, researchers reduced number competing candidates considered
systems means syntactic filters (Hobbs, 1976; Lappin & Leass, 1994), semantic
filters (Hobbs, 1978) discourse structure (Brennan, Friedman, & Pollard, 1987; Cristea,
Ide, Marcu, & Tablan, 2000).
English, automatic identification specific gender NPs difficult task
arguably limited utility. Despite this, numerous researchers (Hale & Charniak, 1998;
Denber, 1998; Cardie & Wagstaff, 1999) proposed automatic methods identifying
potential gender NPs referents. paper, problem animacy identification
tackled. concern animacy opposed gender arises observation
animacy serves reliable basis agreement pronouns candidates (see
examples Section 2). Animacy identification useful tasks like anaphora
resolution coreference resolution level ambiguity reduced filtering
candidates value animacy anaphor, well
question answering, used improve system responses questions
allowing ensure generated answers consist animate references.
research, NP considered animate referent also referred
using one pronouns he, she, him, her, his, hers, himself, herself, combination
pronouns (e.g. his/her ). Section 2 provides clarity definition, considering
range exceptions problematic cases, well examining consequences
treatment animacy. corpus used research described Section 3.
paper several methods animacy identification proposed evaluated. First,
simple statistical method based WordNet (Fellbaum, 1998) described Section
4.1. Following description simple statistical method, machine learning
method overcomes problems simple method, offering improved
performance, described Section 4.2. latest stages development, word sense
disambiguation (WSD) added improve accuracy classification.
presented Section 4.3. Section 5, systems evaluated using intrinsic
extrinsic evaluation methods, noted machine learning methods reach
human performance levels. Finally, Section 6 dedicated related work followed
conclusions.

2. Constitutes Animate Noun Phrase?
argued English nouns classified grammatically, semantically
according coreferential relations personal, reflexive wh-pronouns (Quirk,
Greenbaum, Leech, & Svartvik, 1985, p. 314). According classification, animate
noun phrases contain personal (e.g. male, female, dual, common collective nouns)
non-personal noun phrases (e.g. common, collective animal nouns). paper,
goal design method improves performance anaphora resolution
methods filtering candidates agree terms animacy given
referential pronoun. reason, specific definition animacy given
introduction used. means paper, noun phrases normally
referred pronouns possessive reflexive forms,
considered animate, distinction made pronouns determine
gender. view adopted because, linguistic processing English documents,
80

fiNP Animacy Identification Anaphora Resolution

Figure 1: Quirk el. al. (1985) vs classification animacy. (Adapted Quirk el. al.
(1985, p. 314, Fig. 5.104))
vital distinguish neuter animate references problematic, often
limited utility, distinguish masculine feminine ones.
illustrate, sentence primary user machine select
settings, considering noun phrase primary user machine either
masculine feminine, applying strict agreement constraints reference
subsequent pronominal ones, adversely affect performance reference
resolution systems constraints eliminate antecedent list
candidates one pronouns depending gender attached NP. Ideally,
reference considered animate - compatible, terms agreement, subsequent
animate pronouns, incompatible neuter pronouns.
Figure 1 presents differences Quirk et. al.s (1985) classification animacy
one used paper. seen figure, definition animate
nouns much wider used paper. consider classes presented
Quirk et al.s (1985), animate entities male, female, dual 1 common
gender 2 nouns.
Common gender nouns defined Quirk et al. (1985) intermediate
personal non-personal nouns. us, animacy either animate inanimate,
depending pronoun used refer them. However, animacy
common nouns cat depends upon perception entity speaker/writer.
noun used refer pet, speaker/writer also likely use animate
1. Dual nouns nouns refer people whose gender underspecified artist, cook, etc.
2. Figure 1 nouns labeled common.

81

fiOrasan & Evans

pronouns rather inanimate ones refer it. circumstances detected
method: may focus methods try identify sentiments
speakers/writers towards entities.
Collective nouns team, refer sets animate entities, may intuitively
considered animate. However, suitable pronominal references denotation
phrases singular neuter pronouns plural pronouns unspecified gender.
referents never referred using animate pronouns. Given raison detre
research animacy identification facilitation real-world anaphora resolution,
NPs considered inanimate current work, animate
Quirk et al. (1985).
Collective nouns people pose problems annotation processing.
contexts word people used plural form person, case
considered animate definition presented earlier. However cases
used generically refer national populations (e.g. peoples Asia)
case considered inanimate. light this, seems class word
depends context. However, practical terms, morpho-syntactic parsing software
use (Tapanainen & Jarvinen, 1997) returns people person root
noun, reason, noun people considered inanimate purposes.
reasoning applied similar nouns. drawback approach
annotators find intuitive result errors introduced
annotation (as discussed next section).
rest categories introduced Quirk et al. (1985): non-personal higher, nonpersonal lower inanimate correspond definition inanimate nouns.
common gender nouns, possible non-personal higher lower nouns
horse rabbit pets therefore referred speakers using
she. cannot detect usages, considered inanimate.3
present work, animacy noun phrase (NP) considered derive
animacy head. illustrate, man dead man referred using
animate pronoun. Moreover, considering animacy plural NPs
mileage claimants, singular form mileage claimant derived used basis
classification plural form shares animacy singular form.
way, treatment NP animacy mirrors treatment grammatical number
Government Binding Theory (Chomsky, 1981). approach, projection
principle implies agreement information NP derived head.
paper, animacy common nouns determined proper
nouns named entities (NE). reason separate task named
entity recognition normally used classify NEs different categories person,
organization, location. Given label entities similar semantic types,
categories used determine animacy entities belong
them. acknowledged named entity recognition important component
identification animate references, one lies beyond scope present
work. Methods based semantics, ones described Section 4 especially
vulnerable errors caused failure recognise difference words
3. Actually basis explanation provided Quirk et al. (1985) distinction common
nouns higher lower non-personal nouns latter personified seems fuzzy.

82

fiNP Animacy Identification Anaphora Resolution

words
animate entities
inanimate entities
Percentage animate entities
Total entities

SEMCOR
104,612
2,321
17,380
12%
19,701

AI
15,767
538
2,586
21%
3,124

Table 1: characteristics two corpora used
Cat Bob used common nouns inanimate references proper nouns
animate references.

3. Corpus-Based Investigation
identification NP animacy, described previous section, amenable
corpus-based solution. research two corpora used: first collection
texts Amnesty International (AI) selected contain relatively
large proportion references animate entities. second selection texts
SEMCOR corpus (Landes, Leacock, & Tengi, 1998), chosen nouns
annotated senses WordNet. annotation made suitable exploitation
development automatic method animacy identification described Section
4.2. SEMCOR corpus built basis Brown Corpus (Frances & Kucera,
1982) experiments use texts newswire, science, fiction humor.
order make data suitable evaluation purposes, NPs two corpora
manually annotated information animacy. characteristics
corpora summarized Table 1. seen table, even though texts
contain many references animate entities selected, number inanimate
entities still much larger number animate ones.
assess difficulty annotation task, implicitly, estimate upper
performance limit automatic methods, second annotator asked annotate part
corpus inter-annotator agreement calculated. end, whole AI
corpus, nine texts 3,500 references SEMCOR corpus
randomly selected annotated. Comparison two annotations revealed
level agreement 97.5% two annotators value 0.91 kappa
statistic indicates high agreement annotators. agreement
SEMCOR data slightly higher AI corpus, difference
statistically significant.
Investigation annotation performed two annotators discussion
revealed main source disagreement monotony task.
two annotators use simple interface displayed sentence one NP
time, required indicate whether NP animate inanimate choosing
one two key strokes. Due large number inanimate entities corpus,
annotators often marked animate entities inanimate accidentally. cases
noticed mistake corrected it, likely many mistakes went
unobserved.

83

fiOrasan & Evans

Another source disagreement collective nouns people, government, jury
folk according discussion Section 2 normally marked inanimate.
cases, context NP tiredness part annotator led
erroneously marked animate. Similarly, noticed annotators
wrongly considered plural noun phrases observers, delegates, communists,
assistants collective ones marked inanimate. However, likely
errors introduced due monotony task. Unfamiliar nouns
thuggee, words used specialized domains baseball also caused
difficulties. Finally, another source error arose use Connexors FDG Parser
(Tapanainen & Jarvinen, 1997) identify noun phrases annotation. result,
noun phrases recognized system ambiguous (e.g. specialists
busy people presented one NP according definition animacy adopted
present work, specialists animate, whereas busy people inanimate4 .).

4. Methods Animacy Identification
contrast situation proper name recognition classification,
exploit surface textual clues capitalization explicit occurrence words
small gazetteer titles, knowledge animacy common NPs appears purely
implicit. Recognition references animate entities must, point, grounded
world-knowledge computed explicit features text. section presents
two methods developed animacy identification rely information extracted
WordNet, electronic lexical resource organized hierarchically relations sets
synonyms near-synonyms called synsets (Fellbaum, 1998). first method rulebased one employs limited number resources presented Section 4.1.
shortcomings addressed machine learning method presented Section 4.2.
methods consider senses word taking decision animacy.
reason, word sense disambiguation (WSD) module briefly discussed Section 4.3
integrated them.
4.1 Rule-Based Method
WordNet, four primary classes content-words (nouns, verbs, adjectives
adverbs) arranged small set top-level hypernyms called unique beginners
(Fellbaum, 1998). Investigation unique beginners revealed several
interest respect aim identifying animate entities text. case
nouns 25 unique beginners, three expected hypernyms senses
nouns usually refer animate entities. animal, reference number (05),
person (18), relation (24).5 also four verb sense hierarchies fourteen,
allow inference made subject NPs animate. unique
beginners cases cognition (31), communication (32), emotion (37) social
4. argued singular form people person, therefore marked
animate. However, discussed Section 2 due way processed preprocessing tools
employed here, annotators asked consider inanimate
5. unique beginner animal corresponds animate inanimate entities relation subsumes
mainly human relationships brother, sister, parent, etc.

84

fiNP Animacy Identification Anaphora Resolution

(41).6 noted inanimate entities organizations animals also
agents types verb, expected general case instances
rare enough ignore. light way WordNet organized, clear
could exploited order associate heads noun phrases measure
confidence associated NP either animate inanimate referent.
common noun one meaning, many cases
corresponding sense hierarchies start different unique beginners.
reason, decision whether noun phrase animate inanimate taken
possible senses head noun consulted. Given
senses animate whilst others inanimate, algorithm counts
number animate senses listed noun (hyponyms unique beginners 05, 18,
24) number inanimate senses (hyponyms remaining unique beginners)
proposed. Two ratios computed noun:
N oun animacy (N A) =
N oun inanimacy (N I) =

N umber animate senses
otal number senses
N umber inanimate senses
otal number senses

compared pre-defined thresholds order classify animate inanimate.
Similarly, case nouns heads subject NPs, counts made
animate inanimate senses verbs subjects used calculate Verb
animacy (VA) Verb inanimacy (VI) way NA NI. ratios
also used determine animacy subject NP. Finally, contextual rules (e.g.
presence NP-internal complementizers reflexives )
applied order improve classification. algorithm presented Algorithm 1
evaluated Section 5. three thresholds used algorithm determined
experimentation best values found t1 = 0.71, t2 = 0.92
t3 = 0.90.
4.2 Machine Learning Animacy Identification
method presented previous section two main weaknesses. first one
unique beginners used determine number animate/inanimate senses
general, cases reliably indicate animacy sense
class. second weakness due nave nature rules decide whether NP
animate not. application simple involves comparison values obtained
NP threshold values determined basis relatively small
number experiments. light problems, two step approach, addressing
one aforementioned weaknesses, proposed. first step, annotated corpus
used determine animacy WordNet synsets. process presented Section
4.2.1. information propagated whole WordNet, used
machine learning algorithm determine animacy NPs. method presented
Section 4.2.2.
6. social unique beginner subsumes relations abdicate, educate socialize.

85

fiOrasan & Evans

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18

Data: NP noun phrase animacy determined, t1 , t2 , t3
Result: animacy NP
Compute NA, NI, VA, VI NP;
N > t1
NP animate;
Stop;
end
N > t2
NP inanimate;
Stop;
end
(N > N I) (V > V I)
NP animate;
Stop;
end
(NP contains complementizer who) (V > t3 )
NP animate;
Stop;
end
NP inanimate;
1: rule-based algorithm used determine animacy noun phrase

4.2.1 Classification Senses
previously mentioned, unique beginners general satisfactorily classified
wholly animate inanimate. However, mean possible
uniquely classify specific senses animate inanimate. section, corpusbased method classifies synsets WordNet according animacy presented.
starting point classifying synsets information present
annotated version SEMCOR corpus. reason adding
animacy annotation nouns annotated corresponding sense
WordNet, information could used determine animacy synset. However,
due linguistic ambiguities tagging errors senses classified adequately
way. Moreover, many senses WordNet appear SEMCOR, means
direct animacy information determined them. order address
problem, decision made use bottom procedure begins classifying
unambiguous terminal nodes propagates information general nodes.
terminal node unambiguously classified using information annotated files
occurrences corpus annotated class. way,
general node unambiguously classified hyponyms assigned
class.
Due annotation errors rare uses sense, condition rarely met
statistical measure must employed order test animacy general node.
simple approach classifies synset using simple voting procedure behalf

86

fiNP Animacy Identification Anaphora Resolution

Figure 2: Example showing propagation animacy corpus general
senses
hyponyms unsatisfactory necessary know node general
able assign one classes. reason statistical measure used
determine animacy node ambiguous cases.
statistical measure used process chi-squared, non-parametric test
used estimate whether significant difference two
different populations. order test whether node animate, two populations
compared are:
1. observed population consists senses nodes hyponyms
annotated animate,
2. hypothetical population nodes hyponyms animate.
chi-square indicates difference two populations
node classified animate. process repeated order classify inanimate
node. neither test passed, means node general,
hypernyms equally refer animate inanimate entities. unambiguous cases
(i.e. hyponyms observed corpus7 annotated either animate
inanimate, both), general node classified hyponyms are. way
information propagated corpus WordNet presented Figure 2.
illustrate, general node n hyponyms contingency table
(Table 2) built used determine animacy. hyponym considered
7. Either directly indirectly via hyponymy relations.

87

fiOrasan & Evans

Observed
Expected

Sense1
ani1
ani1 + inani1

Sense2
ani2
ani2 + inani2

Sense3
ani3
ani3 + inani3

...
...
...

Sensen
anin
anin + inanin

Table 2: Contingency table testing animacy hypernym

two attributes: number times annotated animate (anii )
number times annotated inanimate (inanii ). figures anii
inanii include number times sense directly appears corpus
number times appears indirectly via hyponyms. Given system testing
see whether general node animate not, hyponyms, total
number occurrences sense annotated corpus expected value (meaning
instances animate marked animate
marked way annotation error rare usage sense) number
times hyponym annotated referring animate entity observed value.
Chi-square calculated, result compared critical level obtained n 1
degrees freedom significance level .05. test passed, general
node classified animate.
order valid test significance, chi-square usually requires expected frequencies
5 more. contingency table larger two-by-two, exceptions
allowed long expected frequency less one 20%
expected frequencies less 5 (Sirkin, 1995). present case possible
expected frequencies less one would entail presence corpus.
If, test applied, 20% senses expected frequency less
5, two similar senses lowest frequency merged test repeated.8
senses merged still 20% expected frequencies less
5, test rejected.
approach used classify nodes WordNet animate, inanimate
undecided. approach also employed classify animacy verbs
basis animacy subjects. assessment coverage provided
method revealed almost 94% nodes WordNet classified animate
inanimate. mainly due fact general nodes person,
plant abstraction classified without ambiguity result hyponyms
classified way. enriched version WordNet used classify
nouns described next section.
4.2.2 Classification Noun
classification described previous section useful determining animacy
sense, even previously found annotated corpus,
hyponyms node classified. However, nouns whose sense unknown
cannot classified directly therefore additional level processing necessary.
8. context, two senses considered similar attribute (i.e. animacy
inanimacy) equal zero.

88

fiNP Animacy Identification Anaphora Resolution

section, use timbl (Daelemans, Zavrel, van der Sloot, & van den Bosch, 2000)
determine animacy nouns described.
Timbl program implements several machine learning techniques.
Experimenting algorithms available timbl different configurations, best
results obtained using instance-based learning gain ratio weighting measure
(Quinlan, 1993; Mitchell, 1997). type learning, instances stored without
trying infer anything them. classification stage, algorithm compares
previously unseen instance data stored training stage. frequent
class k nearest neighbors assigned class instance belongs.
experimentation, noticed best results obtained three nearest
neighbors used (k=3), distance two instances calculated using overlap
metric importance feature weighted using gain ratio (Daelemans et al.,
2000).
present case, instances used training classification consist
following information:
1. lemma noun classified.
2. number animate inanimate senses word. mentioned before,
cases animacy sense known, inferred hypernyms.
information cannot found words hypernyms, information
unique beginners words sense used, manner similar used
rule-based system described Section 4.1.
3. heads subject NPs, number animate/inanimate senses verb.
senses classification known, algorithm similar
one described nouns employed. values 0 heads non-subjects.
4. ratio number animate singular pronouns (e.g she) inanimate
singular pronouns (e.g. it) whole text. justification feature
text containing large number gender marked pronouns likely
mention many animate entities
features encoded vectors classified timbl using algorithm
settings described earlier. algorithm described section evaluated Section 5.
4.3 Word Sense Disambiguation
difficult disambiguate possible senses words unrestricted texts,
difficult identify senses likely used text others.
information considered methods presented Sections 4.1 4.2.
Instead, methods, senses considered equal weight. order
address shortcoming, word sense disambiguation (WSD) method described
Resnik (1995) implemented used classification algorithm. WSD method
computes weight possible sense noun considering nouns
text. weights used compute number animate/inanimate senses.
underlying hypothesis animacy/inanimacy senses likely
89

fiOrasan & Evans

used particular text count improbable senses. impact
approach animacy identifiers presented previous section also evaluated.

5. Evaluation Systems
section, systems presented Section 4 evaluated using intrinsic
extrinsic evaluation methods (Sparck Jones & Galliers, 1996). evaluation methods
necessary aim find methods classify
references animate entities accurately, also assess appropriate
inclusion anaphora resolution method. addition, complexity systems
considered.
order increase reliability evaluation, systems assessed
corpora described Section 3. thresholds used simple method presented
Section 4.1 determined direct observation performance results
system applied AI corpus. Evaluating method SEMCOR corpus
allows performance measured completely unseen data. addition, texts
SEMCOR completely different genre AI, allowing assessment
made degree system described Section 4.1 genre independent.
Evaluation raises serious problems machine learning method
considered. well known, whenever machine learning method evaluated, clear
distinction made training data testing data. case
system described Section 4.2, approach evaluated using 10-fold cross-validation
SEMCOR corpus. Given AI corpus available, systems also
evaluated data domain used setting parameters
machine learning method. addition, evaluation machine learning methods
AI corpus useful proving classification synsets WordNet
basis animacy annotation added SEMCOR used develop system
whose performance text-dependent.
5.1 Intrinsic Evaluation
Intrinsic evaluation methods measure accuracy system performing task
designed carry out. present case, accuracy entity
classified animate inanimate. order assess performance systems,
four measures considered:
Correctly classif ied items
otal number items

(1)

rue positives
rue positives + F alse positives

(2)

Accuracy =
P recision =
Recall =

rue positives
rue positives + F alse negatives

F measure =

2 P recision Recall
P recision + Recall

90

(3)
(4)

fiNP Animacy Identification Anaphora Resolution

Figure 3: Evaluation methods AI corpus
accuracy (1) measures well system correctly classify reference
entity animate inanimate, misleading large number
inanimate entities mentioned texts. clear Table 1, even though texts
chosen contain large number references animate entities, ratio
number references animate entities inanimate entities approximatively 1
7.5 SEMCOR, 1 4.8 AI. means method classifies
references entities inanimate would accuracy 88.21% SEMCOR
82.77% AI. seen Figures 3 4, well Table 4, results
far accuracy obtained system described Section 4.1. However,
mentioned earlier, intention use filtering references animate entities
anaphora resolution therefore, use filter classifies references
inanimate would highly detrimental.
clearly important know well system able identify references animate
inanimate entities. order measure this, precision (2) recall (3) used
class. precision system identify animate references defined
ratio number references correctly classified system animate
total number references classifies animate (including wrongly classified
ones). methods recall classifying references animate entities defined ratio
number references correctly classified animate total number
animate references classified. precision recall inanimate classification
defined similar manner. f-measure (4) combines precision recall one value.
Several formulae f-measure proposed, one used gives equal importance
precision recall.
Figures 3 4, well Table 4 end paper, present accuracy
classification, f-measures classifying animate inanimate references.
addition methods presented Section 4, three baseline methods introduced.
first one classifies reference entity animate inanimate random basis
referred figures baseline. second random baseline introduced

91

fiOrasan & Evans

Figure 4: Evaluation methods SEMCOR corpus
assumed number gender marked pronouns text indicate
likely particular noun appearing text animate inanimate.
case, probability reference animate proportional number
animate pronouns text classification made weighted random basis.
similar rule applies inanimate references. second baseline referred
figures W-baseline. purposes comparison, method included classifies
references inanimate. method referred dummy method.
Figures 3 4 show methods significantly outperform baselines
used. Close investigation figures, well Table 4, shows that, corpora,
best method one uses machine learning (presented Section 4.2). obtains
high accuracy classifying references animate inanimate entities. terms
accuracy, simple method performs unexpectedly well, fails accurately classify
references animate entities. Moreover, comparison dummy method files
shows results simple method much better, suggests
simple method bias towards recognition references inanimate entities.
integration word sense disambiguation yields mixed results: increases accuracy
simple method, slightly decreases performance machine learning
method.
relatively poor accuracy Simple system expected explained
fact unique beginners, used basis classification
method, cover range senses wide classified belonging single
animate inanimate class. general used basis accurate
classification. Additionally, rules used assist classification provide limited recall
identifying animate references.
Comparison accuracy machine learning method level interannotator agreement reveals automatic method agrees first annotator
second annotator does. result this, concluded accuracy
automatic method matches human performance levels.

92

fiNP Animacy Identification Anaphora Resolution

Figure 5: accuracy mars different animacy filters applied
5.2 Extrinsic evaluation
previous section, performance classification methods evaluated
demonstrated even simple methods achieve high accuracy expense low
precision recall classification references animate entities. computational
linguistics, output one method often used input another one, therefore
important know results first method influence results
second. kind evaluation called extrinsic evaluation. Given identification
references animate entities useful right, vital tasks
like anaphora resolution, necessary perform extrinsic evaluation too. case
evaluation, assumption performance anaphora resolution
improved filtering candidates agree animacy referential
pronoun.
influence animacy identification anaphora resolution thus evaluated using
mars (Mitkov, Evans, & Orasan, 2002), robust anaphora resolver relies set
boosting impeding indicators select antecedent set competing candidates.
Due fact evaluation mars requires manual annotation pronouns
antecedents, time consuming task, evaluation carried part
corpus. end, entire Amnesty International corpus well 22 files
SEMCOR corpus used. Given animacy identifier influence
accuracy anaphora resolvers respect third person singular pronouns, accuracy
resolver reported pronouns. Accuracy anaphora resolution
calculated ratio number pronouns correctly resolved total
number third person singular pronouns appearing test data. Figure 5 Table
5 display accuracy alternate versions mars exploit different methods
animacy identification.
Mars designed process texts technical domain, therefore
performance rather poor test corpus. Moreover, performance vary greatly
one domain another. light fact results different anaphora
resolver may different set data, addition performance
93

fiOrasan & Evans

Figure 6: average number candidates percentage pronouns without correct
candidates different animacy filters applied
mars respect third person singular pronouns, Figure 6 Table 5 also present
reduction number candidates results animacy filtering,
increase number pronouns whose sets competing candidates contain valid
antecedents result filtering. former number presented average
number candidates per pronoun, latter percentage pronouns without
valid antecedents list candidates. justification reporting two measures
good animacy filter eliminate many candidates possible,
eliminate antecedents leave pronouns without correct candidates resolved to.9
seen Figure 5 Table 5, regardless animacy identification
method used, accuracy anaphora resolver improves. degree improvement
varies one corpus another, pattern regarding reduction number
candidates increase number pronouns whose sets competing candidates
contain valid antecedent across corpora. AI corpus, best
performance obtained simple method enhanced word sense disambiguation
used, followed simple method. improvements statically significant10 ,
well difference them. versions machine learning method improve
success rate mars small margin statistically significant,
increase number pronouns valid antecedent select one, increase
statistically significant. simple methods, increase number
type pronoun much larger statistically significant. Therefore
case AI corpus, concluded that, mars, aggressive method
filtering candidates, simple method word sense disambiguation,
appropriate. However, possible anaphora resolution methods result
valid may strongly influenced increase number
pronouns valid antecedent select.
9. noted that, even without filtering, pronouns candidates
due errors introduced preprocessing tools NP extractor fails identify
NPs.
10. cases checked whether differences two results statistically significant
used t-test 0.05 confidence level.

94

fiNP Animacy Identification Anaphora Resolution

Processing SEMCOR corpus, best results mars obtained machine
learning method without WSD module followed one performs WSD.
cases increase performance unfiltered version statistically
significant, differences two machine learning methods small
significant. addition, two methods ensure large reduction number
candidates smallest increase number pronouns whose sets competing
candidates contain valid antecedent, increase significant.
expected, three baselines perform rather poorly. three reduce
number candidates expense high increase number pronouns
valid antecedent available selection. reduction number candidates
increase number pronouns valid antecedent statistically significant
compared system use filtering.
results marss performance rather mixed baselines used.
AI corpus, random baseline leads better result mars machine
learning methods, differences statistically significant. However,
achieved large increase number pronouns cannot correctly resolved
valid antecedents also filtered method. AI corpus,
application two baselines led results worse equal mars
filtering applied result large drop number candidates.
SEMCOR corpus, three baselines give rise statistically significant
improvements performance levels obtained filtering applied,
achieved dramatically reducing number candidates considered. Integration
dummy method mars leads results better simple methods
but, argued before, method appropriate anaphora resolvers
prevents correctly resolving animate pronoun.
Investigation results revealed 31% candidates
possible apply animacy filtering. three reasons this. First,
majority cases, candidates named entities which, mentioned Section 2,
tackled method, though constitute relatively high proportion noun
phrases occurring chosen texts. second reason cases fact
words present WordNet result, ignored method.
Finally, limited number cases noun phrases identified mars match
identified animacy identifiers reason possible classify
them.11
5.3 Extrinsic Evaluation Simulated Data
results presented previous section makes difficult clear idea
accurate animacy identifier needs order significant positive influence
performance mars. light this, performed experiment animacy
identifiers perform predefined accuracy simulated. systems
designed way precision animacy identification varies 1% increments
11. animacy identifiers proposed paper use NP context (i.e. verb
depends number pronouns text) therefore run independently
module uses results.

95

fiOrasan & Evans

Figure 7: evolution success rate changes precision recall
10% 100%, whilst recall varies 50% 100%.12 order achieve this,
introduced controlled number errors annotated data randomly changing
animacy predetermined number noun phrases. order ensure fair results,
experiment run 50 times precision-recall pair, different set entities
wrongly classified run. list classified entities (in case derived
directly annotated data processed methods described
paper) used MARS resolution process. Figure 7 presents evolution
success rate recall precision changed. order see success rate
influenced increase recall, calculated success rates corresponding
chosen recall value values precision 10% 100% averaged
them. way calculated evolution success rate changes precision.
seen figures, precision greater influence success rate
mars recall increasing precision, notice almost continuous increase
success rate. Overall, increasing recall also leads increase success rate,
increase smooth. basis this, conclude high precision
animacy identification important recall. results also supported
Table 5 Simple method leads good performance mars despite low
recall (but higher precision) identification animate entities.
experiments also reveal values higher 80% precision recall,
success rate vary considerably. reason decided focus region. Figure
8 presents success rate corresponding different precision-recall pairs using contour
chart. darker areas correspond higher values success rate. noticed before,
areas correspond high precision high recall also feature high success rates,
difficult identify clear thresholds precision recall lead improved
performance especially differences first four intervals
statistically significant.
12. decided control precision recall animacy identification way,
indirectly, also control recall precision identification inanimate entities.

96

fiNP Animacy Identification Anaphora Resolution

Figure 8: Contour chart showing success rate different values precision recall
5.4 Complexity Systems
One aspect needs considered whenever system developed complexity.
becomes important issue whenever system integrated larger
system, needs react promptly input (e.g. systems available
Web). present case, method presented Section 4 complex
previous one, therefore requires time run. Table 3 shows time necessary
run system two corpora. seen, fastest method simple
method complexity proportional n*m n number entities
entire corpus, average number senses word WordNet.
method uses machine learning slower prepare data
machine learning algorithm, process similar complexity simple method,
addition run memory-based learning algorithm, compares
new instance instances already seen. Even though timbl, machine learning
algorithm used, employs sophisticated indexing techniques speed process,
large training sets, algorithm slow. noted k-NN extremely
slow classifier use alternate ML algorithms, maximum entropy, may lead
quicker classification times loss accuracy. word sense disambiguation
97

fiOrasan & Evans

Method
Simple method
ML
Simple+WSD
ML+WSD

AI
SEMCOR
3 sec.
25 sec.
51 sec.
286 sec.
Several hours
Several hours

Table 3: run time necessary different methods

used, processing time increases dramatically, complexity algorithm
used nm n number distinct nouns text disambiguated,
average number senses WordNet noun. performance
run time methods considered, best performing method ML, ensures
high accuracy together relatively low execution time. use alternate WSD
method exploits N-best lists, rather considering possible assignments word
senses, would likely improve speed disambiguation. approach type
yet tested current work.

6. Related Work
regard work concerned recognition NP animacy, sole concern
section methods tackle problem English texts, problem
concerned semantics cannot addressed using morphological information,
languages.
Identification specific gender proper names attempted Hale
Charniak (1998). method works processing 93931-word portion PennTreebank corpus pronoun resolution system noting frequencies
particular proper nouns identified antecedents feminine masculine
pronouns. paper reports accuracy 68.15% assigning correct gender
proper names.
approach taken Cardie Wagstaff (1999) similar simple statistical one
described Section 4.1, though one described paper exploits larger number
unique beginners ontology, considers semantic information verbs
NPs arguments, also considers possible senses noun. approach
presented Cardie Wagstaff (1999), nouns sense subsumed particular nodes
WordNet ontology (namely nodes human animal) considered animate.
terms gender agreement, gazetteers also used assign NP value
gender set masculine, feminine, either (which assumed correspond
animate), neuter. method employed Cardie Wagstaff fairly simple
incorporated one feature vector used classify coreference
NPs. employed machine learning method blindly exploits value assigned
animacy feature, without interpreting semantically. WordNet used identify
NP animacy work Denber (1998). Unfortunately, evaluation task animacy
identification reported papers.

98

fiNP Animacy Identification Anaphora Resolution

7. Conclusions
Animacy identification preprocessing step improve performance
anaphora resolution English filtering candidates compatible,
terms agreement features, referential expression. paper,
specific definition animacy used one proposed Quirk et al. (1985).
adopted definition appropriate conveys usefulness feature anaphora
resolution. present study, animacy noun phrase determined fact
referred means masculine feminine pronoun well
possessive, relative reflexive forms.
paper, two different animacy identifiers presented evaluated.
first one relies unique beginners WordNet combination simple rules
determine animacy noun phrase. Given unique beginners general
used way rules designed nave observations, second
method proposed. second approach relies machine learning method
enhanced WordNet determine animacy noun phrase. addition normal
semantic information, enhanced WordNet contains information animacy
synset. animacy information automatically calculated basis manual
annotation SEMCOR corpus animacy information.
two animacy identifiers evaluated using intrinsic extrinsic methods.
intrinsic evaluation employed several measures determine appropriate identifier.
Comparison results methods revealed easy obtain relatively
high overall accuracy expense low accuracy classification animate
references. reason, concluded extra resources required
machine learning method, best performing method, fully justified. Inter-annotator
agreement measured order ascertain difficulty task result this,
noted machine learning method reaches level performance comparable
humans.
extrinsic evaluation focused performance mars, robust anaphora
resolver, influenced animacy identifier. light fact mars designed
resolve anaphors texts different genre, results reported extrinsic
evaluation focus accuracy system, also many
candidates removed animacy identifier many pronouns left
valid antecedent select sets candidates result process.
Evaluation mars revealed methods proposed paper improve
accuracy, degree improvement varies one corpus another. terms
reduction number candidates anaphora resolution system consider,
machine learning method eliminates fewest candidates, result evokes
small increases number pronouns whose sets competing candidates contain
valid antecedents. reason, argue extrinsic evaluation also shows
machine learning approach appropriate method determine animacy
noun phrases.
Experiments WSD produced mixed results. one corpora used
research lead small improvements performance. thus conclude
extra computation required order disambiguate words unnecessary.

99

fi28.24%
29.23%
67.73%
70.83%
94.20%
93.65%

82.11%
79.27%
82.77%
88.93%
91.60%
98.33%
98.34%

50.32%
20.60%
100%
99.24%
96.66%
99.26%
99.07%

62.39%
32.70%
90.57%
93.80%
94.06%
98.79%
98.70%

22.05%
15.09%
68.90%
76.50%
90.93%
90.05%

86.19%
88.41%
88.21%
91.81%
93.94%
98.75%
98.59%

50.14%
31.64%
100%
98.51%
98.38%
98.57%
98.56%

63.39%
46.60%
93.73%
95.04%
96.11%
98.65%
98.57%

Table 4: results classification

Orasan & Evans

Prec

Acknowledgments

100

Random baseline
Weighted baseline
Dummy method
Simple system
Simple system + WSD
Machine learning system
Machine learning WSD

Inanimacy
Recall F-meas

F-meas

would like thank Laura Hasler helping us annotation process
three referees useful comments enabled us improve paper.

Random baseline
Weighted baseline
Dummy method
Simple system
Simple system + WSD
Machine learning system
Machine learning WSD

Animacy
Prec
Recall
AI corpus
50.60% 19.37% 52.13%
31.01% 18.07% 76.48%
82.77%
0%
89.61% 94.79% 52.69%
90.14% 81.60% 62.57%
98.04% 96.31% 92.19%
97.85% 95.37% 92.00%
SEMCOR corpus
50.19% 14.11% 50.49%
37.62% 8.40% 74.44%
88.21%
0%
91.42% 88.48% 56.42%
93.33% 88.88% 67.14%
97.72% 91.91% 89.99%
97.51% 89.97% 90.14%
Acc

Appendix A. Tables

Experiment

fiNo filtering
Simple
Simple + WSD
Machine learning
Machine learning + WSD
Random baseline
Weighted baseline
Dummy method

101

filtering
Simple
Simple + WSD
Machine learning
Machine learning + WSD
Random baseline
Weighted baseline
Dummy method

Average candidates per pronouns Percentage pronouns without antecedent
Results AI Corpus: 215 animate pronouns
17.20
20.46
12.37
26.04
12.47
24.18
13.71
20.93
13.70
20.93
9.95
33.02
10.57
40.46
9.17
42.32
Results part SEMCOR: 1250 animate pronouns
10.20
24.80
8.44
26.96
8.66
26.88
8.33
26.32
8.33
26.32
7.55
33.12
7.28
36.16
7.83
38.16

Table 5: results extrinsic evaluation

MARS accuracy
40.00%
43.26%
45.58%
40.93%
40.93%
41.40%
38.60%
40.00%
29.60%
37.60%
37.50%
39.60%
39.52%
36.96%
34.08%
38.16%

NP Animacy Identification Anaphora Resolution

System

fiOrasan & Evans

References
Barbu, C., Evans, R., & Mitkov, R. (2002). corpus based analysis morphological
disagreement anaphora resolution. Proceedings Third International Conference
Language Resources Evaluation (LREC2002), pp. 1995 1999 Las Palmas de
Gran Canaria, Spain.
Barlow, M. (1998). Feature mismatches anaphora resolution.
DAARC2, pp. 34 41 Lancaster, UK.

Proceedings

Brennan, S. E., Friedman, M. W., & Pollard, C. J. (1987). centering approach
pronouns. Proceedings 25th Annual Metting ACL, pp. 155 162
Stanford, California.
Cardie, C., & Wagstaff, K. (1999). Noun phrase coreference clustering. Proceedings
1999 Joint SIGDAT conference Emphirical Methods NLP Large
Corpora (ACL99), pp. 82 89 University Maryland, USA.
Chomsky, N. (1981). Lectures Government Binding. Dordrecht: Foris.
Cristea, D., Ide, N., Marcu, D., & Tablan, V. (2000). empirical investigation
relation discourse structure co-reference. Proceedings 18th
International Conference Computational Linguistics (COLING2000), pp. 208
214 Saarbrucken, Germany.
Daelemans, W., Zavrel, J., van der Sloot, K., & van den Bosch, A. (2000). TiMBL: Tilburg
memory based learner, version 3.0, reference guide, ilk technical report 00-01. Ilk
00-01, Tilburg University.
Denber, M. (1998). Automatic resolution anaphora English. Tech. rep., Eastman
Kodak Co, Imaging Science Division.
Evans, R., & Orasan, C. (2000). Improving anaphora resolution identifying animate
entities texts. Proceedings Discourse Anaphora Reference Resolution
Conference (DAARC2000), pp. 154 162 Lancaster, UK.
Fellbaum, C. (Ed.). (1998). WordNet: Electronic Lexical Database. MIT Press.
Frances, W., & Kucera, H. (1982). Frequency Analysis English Usage. Houghton Mifflin,
Boston.
Hale, J., & Charniak, E. (1998). Getting useful gender statistics English text. Tech.
rep. CS-98-06, Brown University.
Hobbs, J. (1976). Pronoun resolution. Research report 76-1, City College, City University
New York.
Hobbs, J. (1978). Pronoun resolution. Lingua, 44, 339352.

102

fiNP Animacy Identification Anaphora Resolution

Kennedy, C., & Boguraev, B. (1996). Anaphora everyone: pronominal anaphora
resolution without parser. Proceedings 16th International Conference
Computational Linguistics (COLING96), pp. 113 118 Copenhagen, Denmark.
Landes, S., Leacock, C., & Tengi, R. I. (1998). Building semantic concordances. Fellbaum
(Fellbaum, 1998), pp. 199 216.
Lappin, S., & Leass, H. J. (1994). algorithm pronominal anaphora resolution.
Computational Linguistics, 20 (4), 535 562.
Mitchell, T. M. (1997).
McGraw-Hill.

Machine learning.

McGraw-Hill Series Computer Science.

Mitkov, R. (1998). Robust pronoun resolution limited knowledge. Proceedings
18th International Conference Computational Linguistics (COLING98/ACL98),
pp. 867 875 Montreal, Quebec, Canada.
Mitkov, R. (2002). Anaphora resolution. Longman.
Mitkov, R., Evans, R., & Orasan, C. (2002). new, fully automatic version Mitkovs
knowledge-poor pronoun resolution method. Proceedings CICLing-2002, pp. 168
186 Mexico City, Mexico.
Ng, V., & Cardie, C. (2002). Improving machine learning approaches coreference
resolution. Proceedings 40th Annual Meeting Association
Computational Linguistics (ACL2002), pp. 104 111 Philadelphia, Pennsylvania.
Quinlan, J. R. (1993). C4.5: Programs Machine Learning. Morgan Kaufmann.
Quirk, R., Greenbaum, S., Leech, G., & Svartvik, J. (1985). Comprehensive Grammar
English Language. Longman.
Resnik, P. (1995). Disambiguating noun groupings respect Wordnet senses.
Yarovsky, D., & Church, K. (Eds.), Proceedings Third Workshop Large
Corpora, pp. 5468 Somerset, New Jersey. Association Computational Linguistics.
Sirkin, R. M. (1995). Statistics social sciences. SAGE Publications.
Sparck Jones, K., & Galliers, J. R. (1996). Evaluating natural language processing systems:
analysis review. No. 1083 Lecture Notes Artificial Intelligence. Springer.
Tapanainen, P., & Jarvinen, T. (1997). non-projective dependency parser. Proceedings
5th Conference Applied Natural Language Processing, pp. 64 71 Washington
D.C., USA.

103

fiJournal Artificial Intelligence Research 29 (2007) 1947

Submitted 03/06; published 05/07

Computationally Feasible VCG Mechanisms
Noam Nisan

noam@cs.huji.ac.il

School Computer Science Engineering,
Hebrew University Jerusalem, Israel

Amir Ronen

amirr@ie.technion.ac.il

Faculty Industrial Engineering & Management,
Technion - Israel Institute Technology,
Haifa 32000, Israel

Abstract
major achievement mechanism design theory general method construction truthful mechanisms called VCG (Vickrey, Clarke, Groves). applying
method complex problems combinatorial auctions, diculty arises: VCG
mechanisms required compute optimal outcomes are, therefore, computationally infeasible. However, optimal outcome replaced results sub-optimal
algorithm, resulting mechanism (termed VCG-based) longer necessarily truthful.
rst part paper studies phenomenon depth shows near
universal. Specically, prove essentially reasonable approximations heuristics combinatorial auctions well wide class cost minimization problems yield
non-truthful VCG-based mechanisms. generalize results ane maximizers.
second part paper proposes general method circumventing
problem. introduce modication VCG-based mechanisms agents
given chance improve output underlying algorithm. agents behave
truthfully, welfare obtained mechanism least good one obtained
algorithms output. provide strong rationale truth-telling behavior.
method satises individual rationality well.

1. Introduction
Mechanism design sub-eld game theory microeconomics studies design protocols non-cooperative environments. environments participating
agents follow goals necessarily act instructed mechanism.
theory traditionally applied economic applications auctions various kinds. introduction mechanism design found several books (Osborne
& Rubinstein, 1994; Mas-Collel, Whinston, & Green, 1995). recent years, problems
border mechanism design computer science attracted attention
many researchers, within outside AI community. particular, mechanism
design models applied multi-agent systems (Rosenschein & Zlotkin, 1994; Wellman,
Wurman, Walsh, & MacKie-Mason, 2001; Shoham & Tanaka, 1997; Shoham & Tennenholtz, 2001), decentralized resource task allocations (Nisan & Ronen, 2001; Wellman
et al., 2001; Elkind, Sahai, & Steiglitz, 2004; Porter, Ronen, Shoham, & Tennenholtz, 2002),
economic electronic commerce applications (Parkes, 1999; Cramton, 1997), communication networks (Feigenbaum, Papadimitriou, & Shenker, 2000; Anderson, Kelly, &
Steinberg, 2002).
c
2007
AI Access Foundation. rights reserved.

fiNisan & Ronen

canonical mechanism design problem described follows: set rational
agents needs collaboratively choose outcome nite set possibilities.
agent privately known valuation function v : R quantifying agents
benet possible outcome. agents supposed report valuation
functions v () centralized mechanism. goal mechanism choose

outcome maximizes total welfare v (o). main diculty agents may
choose misreport valuations attempt aect outcome liking.
manipulations likely severely damage resulting welfare (simulations
demonstrate welfare loss found Carroll & Grosu, 2005). tool
mechanism uses motivate agents reveal truth monetary payments.
payments need designed way ensures rational agents always reveal
true valuations. Mechanisms property called incentive compatible truthful
(in dominant strategies). date, one general method, called VCG (Vickrey, 1961;
Clarke, 1971; Groves, 1973) (or slightly generally, ane maximization), known
designing payment structure1 . settings, known method
sole available one (Roberts, 1979; Lavi, Nisan, & Mualem, 2003).
Many novel applications mechanism design complex require implementation
computer systems. Cases point include combinatorial auctions multiple items
concurrently sold auction (Cramton, Shoham, & Steinberg, 2006), decentralized
task resource allocation problems (Nisan & Ronen, 2001; Wellman et al., 2001),
networking applications (Feigenbaum et al., 2000; Anderson et al., 2002). many
applications, range possible outcomes huge even nding outcome
maximizes total welfare known NP-complete. Since cases computing
optimal outcome intractable, VCG method cannot applied.
natural general approach development mechanisms cases would
use sub-optimal polynomial time algorithm computing outcome, calculate
payments applying VCG payment rule underlying algorithm. term
mechanisms VCG-based.
starting point paper observation, noted already researchers
(Lehmann, OCallaghan, & Shoham, 2002; Nisan & Ronen, 2001), VCG-based mechanisms necessarily truthful. Thus, rational agents may lie, taking advantage quirks
outcome determination algorithm.
1.1 VCG-based Mechanisms Generally Truthful
rst part paper examines last phenomenon depth shows
near universal: essentially reasonable VCG-based mechanisms truthful.
rst turn attention combinatorial auctions characterize class truthful VCG-based mechanisms problem2 . say allocation algorithm
1. Recently, truthful mechanisms, ane maximizers, obtained combinatorial
auctions (Bartal, Gonen, & Nisan, 2003).
2. importance combinatorial auctions twofold. First, direct applications FCC
auctions. Second, abstract many problems resource allocation among self-interested agents.
comprehensive survey research combinatorial auctions found recent book (Cramton
et al., 2006).

20

fiComputationally Feasible VCG Mechanisms

combinatorial auctions reasonable if, whenever item desired single agent only,
agent receives item. characterization leads following corollary:
Theorem: truthful VCG-based mechanism combinatorial auctions reasonable (unless uses exponential optimal allocation algorithm).
particular, unless P = N P , every polynomial time, truthful VCG-based mechanism
reasonable.
Loosely speaking, show essentially degree freedom available truthful VCG-based mechanisms choice range optimize. Within range
perfect optimization needed. theorem seems intuitive VCG payments identify
agents utility society, thus social welfare optimized
mechanism, agents motivated lie order so. Yet, argument
shows outcome must locally optimal locality dened deviation
single agent. heart argument delicate hybrid argument showing
general context local optimization essentially implies global optimization.
Next study family problems termed cost minimization allocation problems.
family contains many natural decentralized task allocation problems mechanism
design versions shortest path problem (Elkind et al., 2004; Nisan & Ronen, 2001;
Rosenschein & Zlotkin, 1994). call mechanism problem degenerate
exist inputs cause produce results arbitrarily far optimal.
Theorem: cost minimization allocation problem, sub-optimal truthful VCGbased mechanism degenerate.
word order signicance results. VCG-based mechanisms
special case truthful mechanisms essentially general
method known truthful mechanisms non-single dimensional settings. Moreover,
certain settings known indeed truthful mechanisms (Roberts, 1979;
Lavi et al., 2003). precisely, weighted versions VCG-based mechanisms called
ane maximizers truthful, results extend (as show) cases well.
Consequently, results imply designing truthful mechanisms computationally
intractable problems requires either restricting range outcomes (getting unreasonable degenerate mechanisms) developing entirely new techniques truthful
mechanisms may even exist. similar implication results intractability
stems computational considerations, rather communication considerations (Cramton et al., 2006, Chapter 11).
1.2 Second Chance Mechanism
second part paper proposes general method circumventing diculty
constructing truthful mechanisms. VCG-based mechanisms lose incentive
compatibility, still pose special property. Loosely speaking, mechanism,
reason agent misreport valuation help algorithm compute
better outcome. would like exploit property obtain mechanisms
almost truthful.
21

fiNisan & Ronen

Given algorithm corresponding optimization problem dene second chance mechanism based it. mechanism modication VCG-based
mechanism where, addition valuations, agents allowed submit appeal
functions. appeal function allows agent give algorithm input (a vector
declared valuations), dierent original input, without misreporting
type. agents behave truthfully, welfare obtained mechanism
least good one obtained algorithms output.
formulate rationale truthful behavior mechanism. Informally,
argument follows: reasonable assumptions, situation agent
believes benecial lie mechanism, better agent report
actual type mechanism ask appeal check whether lie really helps it.
Thus, agent construct truthful strategy premised fact aware
situation another strategy would better. believe strong
argument truth-telling.
construct version mechanism satises individual rationality well.
generalization results ane maximization compensation bonus
mechanisms (Nisan & Ronen, 2001) straightforward.
Several alternative approaches aimed handling diculty developing truthful
mechanisms suggested past. One approach construction mechanisms
computationally hard manipulate (e.g., Bartholdi et al., 1992). best
knowledge manipulations hard worst case (e.g., may NPhard always compute manipulation). Nevertheless, hardness rule
possibility manipulations may easy compute typical cases. Another
possible approach consider equilibria VCG (Holzman, Kr-Dahav, Monderer, &
Tennenholtz, 2004; Holzman & Monderer, 2004). However, apparent way
agents coordinate equilibria. Several recent works construct ascending mechanisms
combinatorial auctions (e.g. Parkes, 1999). mechanisms rely assumptions
agents dierent (e.g., myopic behavior). may interesting
compare virtues mechanisms ours.
multi-round mechanisms combinatorial auctions let agents improve
provisional allocation proposed tested past (Banks, Ledyard, & Porter,
1989). argument truthfulness second chance mechanisms may provide partial
explanation relative success reported experiments.

2. Preliminaries
section formally present model. attempt much possible use
standard notions mechanism design computational complexity theories.
2.1 Mechanism Design Problems
section formulates class mechanism design problems study.
Denition 1 (utilitarian mechanism design problem) (utilitarian) mechanism design problem described by:
1. nite set allowed outputs.
22

fiComputationally Feasible VCG Mechanisms

2. agent = (1, . . . , n) real function v (o O) called valuation type.
quantication benet possible output terms
common currency. v (.) privately known agent i.
3. mechanisms output addition mechanism hands agent pi units
currency, utility ui equals3 v (o) + pi . utility agent aims
optimize.
4. goal mechanism select output maximizes total

welfare g(v, o) = v (o).
example problem found Section 2.4.
Note goal problems maximize total welfare necessarily
revenue. goal, also known economic eciency, justied many settings
extensively studied economics.
direct revelation mechanism, participants simply asked reveal types
mechanism. Based declarations mechanism computes output
payment pi agents.
Denition 2 (mechanism) (direct revelation) mechanism pair = (k, p)
that:
output function k accepts input vector w = (w1 , . . . , wn ) declared valuation
functions4 returns output k(w) O.
payment function p(w) = (p1 (w), . . . , pn (w)) returns real vector quantifying
payment handed mechanism agents (e.g. pi = 2, mechanism
pays two units currency agent i).
agents try maximize utility thus may lie mechanism.
lies might severely reduce total welfare, mechanism carefully
designed benet agents report types truthfully.
Notation: denote tuple (a1 , ...ai1 , ai+1 , ..., ) ai . let (ai , ai ) denote
tuple (a1 , . . . , ).
Denition 3 (truthful mechanism) mechanism called truthful truth-telling
dominant strategy, i.e., every agent type v every type declaration wi
agents, agents utility maximized declares real valuation function
vi.
example consider famous Vickrey auction (Vickrey, 1961): seller wishes
sell one item auction. n buyers, privately knowing valuation v
item. (The value winning assumed zero.) Vickrey auction
buyers simply asked valuation; item allocated buyer
3. assumption called quasi-linearity common mechanism design.
4. consider issue represent valuations.

23

fiNisan & Ronen

highest bid price second highest. reader may verify mechanism
truthful. Another example truthful mechanism found Section 2.4.
general, communication protocol mechanism complicated. simple
observation known revelation principle dominant strategies (e.g., Mas-Collel et al.,
1995, pp. 871) states every mechanism agents dominant strategies,
exists equivalent truthful mechanism. Thus, w.l.o.g. possible focus
truthful mechanisms.
2.2 VCG-based Mechanisms
subsection presents celebrated VCG mechanisms. Intuitively, mechanisms
solve utilitarian problems identifying utility truthful agents declared
total welfare. generalize mechanisms.
Denition 4 (VCG mechanism, (via Groves, 1973)) mechanism = (k, p) belongs
VCG family if:
k(w) maximizes total welfare according w. is, w, k(w) arg maxo g(w, o).
payment calculated according VCG formula: pi (w) =
hi (wi ) (hi (.) arbitrary function wi ).



j=i w

j (k(w))

+

reader may verify Vickrey auction VCG mechanism. well known
VCG mechanisms truthful (Groves, 1973).
Unfortunately, many applications, task nding output k(w) maximizes total welfare computationally infeasible (e.g., NP-hard). paper
consider VCG mechanisms optimal algorithm replaced sub-optimal
computationally feasible one.
Denition 5 (VCG-based mechanism) Let k(w) algorithm maps type declarations allowable outputs. call = (k(w), p(w)) VCG mechanism based

k(.) p(.) calculated according VCG formula: pi (w) = j=i wj (k(w)) + hi (wi )
(where hi (.) arbitrary function wi ).
Obviously, VCG-based mechanism based optimal algorithm VCG mechanism. Note payment function VCG-based mechanism identical
VCG payment algorithm k(.) plugged payment formula.
characterize utility agent VCG-based mechanisms. utility equivalent
total welfare according declared types agents actual type
agent consideration.
Lemma 2.1 (VCG-based utility) Consider VCG-based mechanism dened allocation algorithm k(.), functions (h1 (.), . . . , hn (.)). Suppose actual valuation
agent v , declarations w = (w1 (.), . . . , wn (.)). utility agent
equals g((v , wi ), k(w)) + hi (wi ).
24

fiComputationally Feasible VCG Mechanisms

Proof: proof immediate denitions. agents utility equals v (k(w)) +

pi (w) = v (k(w)) + j=i v j (k(w)) + hi (wi ) = g((v , wi ), k(w)) + hi (wi ).
words, VCG-based mechanism identies utility truthful agents
total welfare. particular, k(.) optimal, g((v , wi ), k(w)) maximized
agent truthful. implies VCG mechanisms truthful truthfulness
necessarily preserved VCG-based mechanisms.
2.2.1 Example: Non Optimal Vickrey Auction
section demonstrates problems might occur optimal algorithm
VCG mechanism replaced sub-optimal one. Consider sale single item.
already commented, Vickrey auction VCG mechanism. algorithm allocates

item agent highest declared value. function hi (wi ) = j=i wj (o)
equals negation second highest value case winning.
Consider mechanism optimal algorithm replaced algorithm
chooses second highest agent. mechanism give object
agent second highest declaration price third highest agent.
Suppose three agents. Alice value $2 million, Bob
value $1.7 million, Carol value $1 million. agents truthful,
Bob wins pays $1 million. case Alices benet reduce declaration
Bobs. Similarly, Alice wins, Bob would like lower declaration further,
on. Note natural situations Carol win well.
dicult see dominant strategies game. outcome
mechanism highly unpredictable, depending heavily agents beliefs
others, risk attitude, level sophistication. mechanism
yield inecient outcomes. eciency loss may get much worse underlying
optimization problem complex combinatorial structure (simulations demonstrate
context scheduling done Carroll & Grosu, 2005).
2.2.2 Affine-based mechanisms
possible slightly generalize class VCG mechanisms obtain mechanisms
called ane maximizers. mechanisms maximize ane transformations valuations. domain valuations unrestricted, ane maximizers sole
truthful mechanisms (Roberts, 1979; Lavi et al., 2003). Similarly VCG, generalize
mechanisms incorporate sub-optimal algorithms.
Notation: Let = (a0 , . . . , ) n + 1-tuple a0 (.) valuation function,
a1 , . . . , strictly positive. dene weighted welfare ga (w, o) output

a0 (o) + i>0 ai wi (o) w vector types output.
Denition 6 (ane-based mechanism) Let k(w) algorithm maps type declarations allowable outputs, = (a0 , . . . , ) n + 1-tuple a0 (.)
valuation function, a1 , . . . , strictly positive. call = (k(w), p(w)) ane

mechanism based k p calculated according formula: pi (w) = a1i ( j=i,0 aj
wj (k(w)) + hi (wi )) (where hi () arbitrary function wi ).
25

fiNisan & Ronen

function a0 (.) interpreted preferences mechanism set
alternatives a1 , . . . , weights agents. VCG mechanisms,
agents utility convenient characterization.
Lemma 2.2 (ane-based utility) Consider ane-based mechanism dened
allocation algorithm k(.), tuple functions h1 (.), . . . , hn (.). Suppose
actual valuation agent v , declarations w = (w1 (.), . . . , wn (.)).
utility agent equals a1i (ga ((v , wi ), k(w)) + hi (wi )).
Proof: proof immediate denitions. agents utility equals v (k(w) +
pi (w)) = a1i (ai v (k(w)) + pi (w) = a1i (ga ((v , wi ), k(w)) + hi (wi )).
words, ane-based mechanism identies agents utility ane
transformation valuations aims optimize. particular, k(.) maximizes
ga (w, .), mechanism truthful.
2.3 Computational Considerations Mechanism Design
section adopts standard notions computational complexity revelation mechanisms.
Denition 7 (polynomial mechanism) mechanism (k, p) called polynomial time
computable k(w) p(w) run polynomial time (in size w).
Note VCG-based mechanism polynomial output algorithm functions hi (.) polynomial. sometimes call polynomial algorithms mechanisms
computationally feasible.
Denition 8 (NP-complete problem) mechanism design problem called NP-Complete
problem nding output maximizes total welfare NP-Complete.
use term feasible denote acceptable computational time infeasible
unacceptable computational time. particular, NP-hard problems exponential algorithms considers infeasible, polynomial algorithms considered feasible. use
non-standard terms results limited specic complexity
classes.
2.4 Example: Combinatorial Auctions
problem combinatorial auctions extensively studied recent years (a recent
book found Cramton et al., 2006). importance problem twofold.
Firstly, several important applications rely (e.g., FCC auction Cramton, 1997).
Secondly, generalization many problems interest, particular eld
electronic commerce.
problem: seller wishes sell set items (radio spectra licenses, electronic
devices, etc.) group agents desire them. agent has, every subset
items, non-negative number v (s) represents much worth
it. v (.) privately known agent i. make two standard additional assumptions
agents type space:
26

fiComputationally Feasible VCG Mechanisms

externalities valuation agent depends items allocated
it. words, every two allocations x = (x1 , . . . , xn ) = (y1 , . . . , yn ),
xi = yi , v (x) = v (y). Thus, denote valuation agent
v : 2S R.
Free disposal Items non-negative values, i.e., t, v (s) v (t). Also,
v () = 0.


Items either complementary, i.e., v (S ) v (S) + v (T ), substitutes, i.e.,

v (S ) v (S) + v (T ) (for disjoint ). example, buyer may willing
pay $200 T.V. set, $150 VCR, $450 $200 two VCRs.
agent gets set si items, payment pi , utility v (si ) + pi . (The
payments combinatorial auctions non-positive.) utility agent tries
optimize. example, agent prefers buy $1000 valued VCR $600, gaining
$400, rather buy $1500 valued VCR $1250.
VCG mechanism combinatorial auction, participants rst required
reveal valuation functions mechanism. mechanism computes,
according agents declarations, allocation maximizes total welfare.
payment agents calculated according VCG formula. Lemma
2.1, utility ui = v (si ) + pi agents maximized reveals true
valuation mechanism. agents truthful, mechanism maximizes
total welfare.
Consider, however, computational task faced mechanism. types
declared, mechanism needs select, among possible allocations, one maximizes total welfare. problem known NP-Complete. Therefore, unless
number agents items small, mechanism computationally infeasible.
Even problem nding
allocation approximates optimal allocation within

reasonable factor |S| N P -Complete (Zuckerman, 2006). Nevertheless, various
heuristics tractable sub-cases analyzed literature (Cramton et al.,
2006, Chapter 13). would like nd way turn sub-optimal algorithms
mechanisms.
note that, general, revealing valuation function requires exponential communication. ignore communication issues paper, subsequent work (Ronen,
2001) extends second chance method address communication limitations well.

3. Limitations Truthful VCG-based Mechanisms
section studies limitations truthful VCG-based mechanisms. Section 3.1 characterizes mechanisms important problem combinatorial auctions (see Section
2.4). characterization precludes possibility obtaining truthfulness applying
VCG rules many proposed heuristics combinatorial auctions (e.g., greedy
algorithms Lehmann et al., 2002 Nisan, 2000). Moreover, show truthful
non-optimal VCG-based mechanism combinatorial auctions suers abnormal behavior. Section 3.2 shows many natural cost minimization problems, truthful
VCG-based mechanism either optimal produces results arbitrarily far
27

fiNisan & Ronen

optimal. result, problem computationally intractable, truthful computationally feasible VCG-based mechanism inputs cause produce degenerate
results. Furthermore, since standard algorithmic techniques yield anomalies,
might dicult develop algorithms plugged truthful mechanisms.
generalize results ane-based mechanisms well.
3.1 Truthful VCG-based Mechanisms Combinatorial Auctions
section characterizes class truthful VCG-based mechanisms combinatorial
auctions.
Denition 9 (maximal range) Let k(w) algorithm maps type decladf



rations allowable outputs. Let V = ni=1 V space possible types let
V V subspace V . Let denote range k V , i.e. = {k(w)|w V }.
say k maximal range V every type w V , k(w) maximizes g
O. say k maximal range maximal range V .
Consider, example, algorithm combinatorial auctions allocates
items (the set S) agent highest valuation v (S). Clearly, polynomial
time algorithm maximal range . welfare obtained allocation
algorithm achieves least factor max(1/n, 1/|S|) optimal welfare (where n
denotes number agents).
Proposition 3.1 VCG-based mechanism output algorithm maximal
range truthful.
Proof: mechanism VCG mechanism set allowable outputs
range output algorithm. Lemma 2.1 mechanism truthful.
show proposition almost characterizes class truthful
VCG-based mechanisms combinatorial auction problem.
Notation: let V denote space types v = (v 1 , . . . , v n ) two
dierent allocations x y, g(v, x) = g(v, y). (Recall g(.) denotes total welfare.)
dicult see V contains almost types, i.e. V V measure zero
V .
Theorem 3.2 VCG-based mechanism combinatorial auction problem truthful,
output algorithm maximal range V .
Proof: Assume contradiction = (k, p) truthful k(.) maximal
range V . Since functions hi (.) aect truthfulness mechanism,

assume zero, i.e., assume i, pi (w) = j=i wj (k(w)).

According Lemma 2.1, utility agent equals v (k(w)) + j=i wj (k(w)) =
g((v , wi ), k(w)).
Let denote range k(.) V let v V type k(v)
optimal O. Let = arg maxoO g(v, o) optimal allocation among O. Note
28

fiComputationally Feasible VCG Mechanisms

denition V , unique. Finally, let w V type = k(w).
type exists since range algorithm.
Dene type vector z



z (s) =

v (s)

.

stands suciently large number. words, agent strongly desires
set . Apart this, v z identical. assume z V . Otherwise
could add suciently small noise (s) z claims remain true.
show z forces algorithm output y. show
algorithm outputs type z, must also output type v
contradiction.
Lemma 3.3 = k(z).
Proof: Dene sequence type vectors by:
w0 = (w1 , . . . , wn )
w1 = (z 1 , w2 , . . . , wn )
w2 = (z 1 , z 2 , w3 , . . . , wn )
..
.
wn = (z 1 , . . . , z n ).
words, every agent turn moves wi z . assume wj V
j. dicult see z modied adding small noise it, way
guarantees above.
Claim 3.4 k(w1 ) = y.
Proof: Assume contradiction false. denition V obtain
g(w1 , k(w1 )) = g(w1 , y).
Consider case agent 1s type z 1 types others w2 , . . . , wn .
declaring w1 , agent 1 force algorithm decide y. Since mechanism
truthful, must g(w1 , k(w1 )) > g(w1 , y).
Since large, must k 1 (w1 ) 1 (i.e., agent 1 gets items gets

type w1 ). Thus, denition z 1 , obtain + nj=2 wj (k(w1 )) >

+ nj=2 wj (y). Because, due free disposal assumption, w1 (k(w1 )) w1 (y),


obtain w1 (k(w1 )) + nj=2 wj (k(w1 )) > w1 (y) + nj=2 wj (y) (even z perturbed).
Thus, g(w0 , k(w1 )) > g(w0 , y).
Therefore, type agent 1 w1 , better declaring z 1 , forcing
mechanism output k(w1 ). contradicts truthfulness mechanism.
Similarly, induction j, obtain k(wj ) = j, particular wn = z.
completes proof Lemma 3.3.
show k(z) = implies k(v) = contradiction. Consider
following sequence type vectors:
29

fiNisan & Ronen

v0 = (v 1 , . . . , v n )
v1 = (z 1 , v 2 , . . . , v n )
..
.
vn = (z 1 , . . . , z n ).
words, every agent turn, moves v z . choose z
vj V .
Claim 3.5 vj , maximizes g O.
Proof: show v1 . proof j > 1 follows similar argument.
Assume contradiction x = maximizes welfare v1 . Since arbitrarily
large must x1 . Consequently, cases agent 1s valuation equals .
Recall uniquely maximizes g v0 . Thus, every allocation x = y,




v 1 (y) + nj=2 v j (y) > v 1 (x) + nj=2 v j (x). Therefore, + nj=2 v j (y) > + nj=2 v j (x).
left hand side equals g(v1 , y) right hand side equals g(v1 , x). Thus, g(v1 , y) >
g(v1 , x) contradiction.
Claim 3.6 k(vn1 ) = y.
Proof: showed k(vn ) = y. (Recall vn = z.) also showed uniquely
maximizes g(vn1 , .). Let xn1 = k(vn1 ). Assume contradiction xn1 = y. According Lemma 2.1, utility agent n truthful g(vn1 , xn1 ). Thus,
agent ns type v n , better declaring z n obtaining utility g(vn1 , y).
contradicts truthfulness mechanism.
Similarly, downward induction j, obtain k(v0 ) = y. v0 = v
assumed k(v) = contradiction. completes proof Theorem 3.2.
Remarks theorem characterizes output algorithms could incorporated truthful VCG-based mechanisms zero-measured subset types.
characterization holds even set possible types discrete (under mild
condition type vector z dened agents indierent
allocations). theorem gives rise several interesting algorithmic combinatorial questions. example, given approximation factor c 1, minimal
size sub-family every v, maxyO g(v, y) c gopt (v)? limited
version question analyzed Holzman et al., 2004 Holzman & Monderer,
2004.
Corollary 3.7 Consider VCG-based mechanism combinatorial auction output algorithm k. mechanism truthful, exists output algorithm k, maximal
range, every v, g(v, k(v)) = g(v, k(v)).
Proof: Let denote range k V , dene another algorithm optimal
range v, k(v) arg maxoO . According Proposition 3.1, VCG mechanism
30

fiComputationally Feasible VCG Mechanisms

based k truthful. Consider case agents truthful. Recall
utility agents determined resulting total welfare. Thus, dicult
see welfares g(v, k(v)) g(v, k(v)) must continuous v. Two continuous real
functions, identical dense subspace, identical whole space
thus corollary follows.
show non-optimal truthful VCG-based mechanisms suer following
disturbing abnormal behavior:
Denition 10 (reasonable mechanism) mechanism combinatorial auctions
called reasonable whenever exists item j agent that:
1. S, j
/ S, v (S {j}) > v (S), and,
2. every agent l = i, S, v (S {j}) = v (S),
j allocated agent i.
Simply put, situations one agent desires item, agent gets it.
Theorem 3.8 non-optimal truthful VCG-based mechanism combinatorial auctions
reasonable.
Proof: Consider mechanism m. According Corollary 3.7 exists equivalent
mechanism = (k, p), optimal range. Since must also sub-optimal,
exists least one partition = (s1 , . . . , sn ) range mechanism.
Dene vector types by:

1 x si

v (x) =
0 otherwise.
words, agent wants single set si , two agents want item
(as sets disjoined). Since range must k(v) = s. Since
strictly optimal, k(v) must also suboptimal. Hence, exists least one agent
get si . particular, exists least one item j si agent
get. Since agent desires j, theorem follows.
Corollary 3.9 Unless P = N P , polynomial time truthful VCG-based mechanism
combinatorial auctions reasonable.
believe natural allocation algorithms (e.g., linear programming relaxations, algorithms greedily allocate items agents, local search algorithms)
yield anomaly. particular, presume agent wants single
subset items subsets disjoined, algorithm nd optimal
allocation. Thus, corollary suggests might dicult develop allocation
algorithms yield truthful VCG-based mechanisms.
show generalize results ane-based mechanism. Given tuple
= (a0 , . . . , ), dene V space types v two dierent
allocations x y, ga (v, x) = ga (v, y). Similarly unweighted case, say
algorithm optimal range respect ga (.) always produces allocations
maximize ga (.).
31

fiNisan & Ronen

Theorem 3.10 Consider ane-based mechanism combinatorial auction problem
dened allocation algorithm k(.), tuple = (a0 , . . . , ). mechanism
truthful, k(.) maximal range respect ga (.) V .
Proof: (sketch) proof similar proof Theorem 3.2 thus sketch it.
Dene V similarly w.r.t. ane transformation ga (.). Assume contradiction
exists type vector v k(v) optimal O. Let optimal
allocation range O, w V k(w) = y. According Lemma 2.2,
utility agent maximized weighted welfare ga ((v , wi ), .). Thus,
possible proceed along lines proof Theorem 3.2: Dene type vector z
similarly; then, start w gradually transform agents z conclude
k(z) = y; gradually transform agents z v show k(v) = y, i.e.,
contradiction.
Open Questions currently know whether theorems similar Theorem 3.2
hold valuations bounded. Moreover, know get rid
usage V . Thus, preclude possibility Corollary 3.7 hold
space possible types discrete. also know whether hold
allocation algorithm randomized whether Bayesian versions theorems apply
expected externality mechanism (dAspremont & Gerard-Varet, 1979) (an analog
VCG Bayesian model). leave future research. conjecture similar
theorems apply many mechanism design problems.
3.2 Truthful VCG-based Mechanisms Cost Minimization Problems
show many natural cost minimization problems, truthful VCG-based
mechanism either optimal produces results arbitrarily far optimal.
start sample problem.
Multicast transmissions: communication network modeled directed graph
G = (V, E). edge e privately owned link. cost te sending message along
edge privately known owner. Given source V set V
terminals, mechanism must select subtree rooted covers terminals.
message broadcasted along tree. assume agent owns cut
network.
Naturally, goal mechanism select, among possible trees, tree R

minimizes total cost:
eR te . goal agent maximize prot:

pi (eR owned i) te . dicult see utilitarian mechanism design
problem.
example introduced Feigenbaum et al., 2000 (using dierent model).
motivated need broadcast long messages (e.g., movies) Internet.
generalize example.
Denition 11 (cost minimization allocation problem)
cost minimization allocation problem (CMAP) mechanism design problem described by:
32

fiComputationally Feasible VCG Mechanisms

). let =
Type space type agent described vector (v1i , . . . , vm



mi . (In multicast example corresponds negation cost te .)

Allowable outputs output denoted bit vector x = (x11 , . . . , x1m1 , . . . , xn1 , . . . , xnmn )
{0, 1}m . denote (xi1 , . . . , ximi ) xi . may additional constraints
set allowable outputs. (In example x corresponds tree networks
graph xij equals 1 corresponding edge chosen tree.)
following conditions satised:
) describes type agent w v (as
Unbounded costs v = (v1i , . . . , vm


vectors), w also describes type.

Independence monotonicity valuation v depends bits xi . (In
example, agent valuation given tree depends edges it.)
j, wji vji , every output x, wi (xi ) v (xi ).
Forcing condition every type v, allowable output x real number ,
dene type v[]


v[]ij

=

vji


xij = 1
otherwise.

forcing condition satised every allowable output = x, lim g(t(), y) =
.
Many natural decentralized task allocation problems goal minimize
total cost given constraints belong class. particular reader may
verify multicast example falls category. Another example shortest
path problem studied extensively recent years (e.g., Rosenschein & Zlotkin, 1994; Archer
& Tardos, 2002; Elkind et al., 2004).
Notation: type v let gopt (v) denote optimal value g. denote g(v, k(v))
gk (v).
Denition 12 (degenerate algorithm) output algorithm k called degenerate
g (v)gopt (v)
unbounded, i.e., exist vs rk (v) arbitrarily
ratio rk (v) = k|gopt (v)|+1
large.
degenerate algorithm arbitrarily far optimal, additively multiplicatively. Note confused standard notion approximation
ratio, denition corresponds single problem. particular, number agents
xed. note rule possibility algorithm
good non worst case metric.
Theorem 3.11 VCG-based mechanism CMAP truthful, output algorithm either optimal degenerate.
33

fiNisan & Ronen

stating proof let us illustrate using multicast transmission example.
Suppose start type vector leads sub-optimal solution. raise
cost edge, utility owner cannot increase (due truthfulness
Lemma 2.1). gradually raise cost edges except ones optimal
tree. Still, algorithm choose sub-optimal tree. However, cost
suboptimal tree arbitrarily high optimal cost remains same.
Proof: Let = (k, p) non-optimal truthful VCG-based mechanism CMAP.

Theorem 3.2, assume pi (w) = j=i wj (k(w)). Let v type vector k(v)
optimal let = opt(v) optimal output.
dene type z by:


zji =

vji
yji = 1
otherwise.

arbitrarily large.
Consider type sequence:
v0 = (v 1 , . . . , v n )
v1 = (z 1 , v 2 , . . . , v n )
..
.
vn = (z 1 , . . . , z n ).
Claim 3.12 j, = opt(vj ).
Proof: denition optimal v0 . Let x = allocation. independence
condition, j, g(vj , y) = g(v0 , y). monotonicity, g(vj , x) g(v0 , x). Together,
g(vj , x) g(v0 , x) g(v0 , y) = g(vj , y).
Claim 3.13 g(v1 , k(v1 )) < g(v1 , y)
Proof: Assume contradiction claim false. Since optimal v1 ,
means g(v1 , k(v1 )) = g(v1 , y). independence, g(v1 , y) = g(v0 , y). Recall
k(v0 ) suboptimal g(v0 , y) > g(v0 , k(v0 )). monotonicity (we worsen
type agent 1), g(v0 , k(v1 )) g(v1 , k(v1 )). Thus, together g(v0 , k(v1 )) g(v1 , k(v1 )) =
g(v1 , y) = g(v0 , y) > g(v0 , k(v0 )). particular, g(v0 , k(v1 )) > g(v0 , k(v0 )).
Consider case agent 1s type v 1 declarations agents
(v 2 , . . . , v n ). According Lemma 2.1, utility truthful, equals g(v0 , k(v0 )).
hand, falsely declares z 1 , utility equals g(v0 , k(v1 )). Since showed
g(v1 , k(v1 )) > g(v0 , k(v0 )), contradicts truthfulness mechanism.
Similarly, obtain g(vn , k(vn )) < g(vn , y) = g(v0 , y). forcing condition,
g(vn , k(vn )) . Thus, algorithm degenerate.
Corollary 3.14 Unless P = N P , polynomial time truthful VCG-based mechanism
NP-hard CAMP degenerate.
34

fiComputationally Feasible VCG Mechanisms

Note due revelation principle, theorems section hold mechanism agents dominant strategies. Similarly Theorem 3.11, mechanism
uses VCG payments non-optimal ex-post Nash equilibrium also equilibria
arbitrarily far optimal.
show generalize theorems section ane-based mechanisms.
Theorem 3.15 ane-based mechanism (k, p) CMAP truthful, output
algorithm either optimal degenerate.
Proof:(sketch) proof almost identical proof Theorem 3.11. Let v
type k(w) optimal w.r.t. corresponding ane transformation ga .
dene type vector z similarly Theorem 3.11 consider sequence type vectors
agent turn changes type wi z . Due incentive compatibility
Lemma 2.2 , utility agent cannot increase, meaning weighted welfare
ga remains sub-optimal. Due forcing condition, outputs except optimal,
arbitrarily high cost. means algorithm degenerate.
compensation bonus mechanism (Nisan & Ronen, 2001) identies utility
agents total welfare similarly VCG, i.e., utility agent described similarly Lemma 2.1. Thus, theorems section applied
compensation bonus mechanisms well.

4. Second Chance Mechanisms
date, ane maximization known general method development
truthful mechanisms. Therefore, results previous section leave much hope
development truthful mechanisms many complex problems.
section proposes method circumventing problem. Consider VCG-based
mechanism. immediate consequence Lemma 2.1 reason agent
misreport type help algorithm improve overall result. leads
intuition agents cannot improve upon underlying algorithm,
better truthful. would like exploit special property VCG-based
mechanisms construct mechanisms almost truthful.
Given algorithm corresponding optimization problem dene second chance mechanism based it. mechanism modication VCG-based
mechanism addition valuations, agents allowed submit appeal
functions. appeal function allows agent give algorithm input (vector
declared valuations) dierent original input without misreporting
type. agents behave truthfully, welfare obtained mechanism least
good one obtained algorithms output.
formulate rationale truthfulness second chance mechanisms. Informally, argument follows: reasonable assumptions, situation
agent believes benecial lie mechanism, better report
actual type mechanism ask appeal check whether lie indeed helpful.
Thus, agent construct truthful strategy premised fact aware
35

fiNisan & Ronen

situation another strategy better it. believe strong
argument truth-telling.
generalization results ane maximization compensation bonus
mechanisms straightforward.
4.1 Mechanism
section formulate second chance mechanism basic properties.
Denition 13 (appeal function) Let V =
appeal partial function5 l : V V .



Vi

denote type space agents.

semantics appeal l(.) is: agents type vector v = (v1 , . . . , vn ),
believe output algorithm k(.) produces better result (w.r.t. v) given
input l(v) instead actual input v. appeal function gives agent opportunity
improve algorithms output. v domain l(.), semantics
agent know cause algorithm compute better result k(v).
second chance mechanism dened Figure 4.1. modication VCG
allows agents submit appeal functions well.

execution manager mechanism publishes outcome determination algorithm time limit computation time appeal.
Declaration agent submits type declaration wi appeal function li (.)
mechanism. appeals must adhere specied time limit.
Allocation Let w = (w1 , . . . , wn ). mechanism computes k(w), k(l1 (w)), . . . , k(ln (w))
chooses among outputs one maximizes total welfare (according
w).
Payment Let denote chosen output. mechanism calculates payments ac
cording VCG formula: pi = j=i wj (o) + hi (wi , li ) (where hi (.) real
function).
Figure 1: Second Chance Mechanism
Remarks agents send programs represent appeal functions mechanism. programs executed mechanism. mechanism terminate
computation appeal units computation time (and refer vector
declarations w appeals domain). Thus, assume w.l.o.g.
appeals adhere given time limit. discussion choice time limit
alternative representations appeal functions appears Section 4.3. believe
possible construct software tools APIs make formulation
appeals easy task.
5. function f : R called partial domain subset D, i.e. Dom(f ) D.

36

fiComputationally Feasible VCG Mechanisms

functions hi (.) play role agents considerations every hi (.)
independent actions. Section 4.4 possible simply assume hi (.) 0
i. Section 4.4 use functions order satisfy individual rationality.
Denition 14 (truthful action) action second chance mechanism pair
(wi , li ) wi type declaration li (.) appeal function. action called
truthful wi = v .
following observation key property mechanism.
Proposition 4.1 Consider second chance mechanism output algorithm k.
every type vector v = (v 1 , . . . , v n ), agents truth-telling, g(v, o) g(w, k(v)).

words, agents truth-telling, result mechanism least
good k(v). proof immediate denition mechanism.
formulate analog Lemma 2.1. proof similar lemmas proof
henceforth omitted.
Lemma 4.2 (second chance utility) Consider second chance mechanism. Let
chosen output. utility agent equals g((v , wi ), o) + hi (wi , li ).

Therefore, informally, benecial agent declare wi = v either helps
output algorithm k(.) compute better result (w.r.t. (v , wi )) helps one
appeals agents.
Note lying second chance mechanism may harm agent two ways. First,
damage output algorithm k(.). Second, cause mechanism measure
welfare according wrong type vector thus cause choose inferior output.
Notation: say second chance mechanism T-limited time limit species
. Similarly, algorithm called T-limited computational time never exceeds
units computation.
following proposition obvious.
Proposition 4.3 Consider -limited second chance mechanism. output algorithm
mechanism also -limited, overall computational time mechanism
O(nT ).

4.1.1 toy example
Consider combinatorial auction two items. type agent 3-tuple representing
value every non empty subset items. Suppose agent values pair
items $3 million values every single item $1 million. type is, therefore, v =
37

fiNisan & Ronen

{3, 1, 1}. Suppose agent notices allocation algorithm often produces better
allocations declares wi = {3, 0, 0} (i.e., hides willingness accept one item).
VCG-based mechanism agent may prefer declare wi instead actual type.
might cause two problems:
1. Even others truthful, may many type vectors v belonging agents, declaring wi damages chosen allocation, i.e.,
g((v , wi ), k((wi , wi ))) < g((v , wi ), k((v , wi ))).
2. Even case every agent chooses declaration wi
g((v , wi ), k((wi , v ))) g((v , wi ), k(w)), may according actual
type vector v output k(w) may inferior k(v) (i.e., g(v, k(w)) < g(v, k(v))).
second chance mechanism enables agent check whether declaring falsied type
would yield better result. Instead declaring wi = {3, 0, 0}, agent declare
actual type dene appeal li (w ) = (wi , wi ). way agent enjoys
worlds. cases falsied type better, mechanism prefer k((wi , wi ))
k((v , wi )). cases truthful declaration better, mechanism prefer
k((v , wi )). Note mechanism allows appeal modify declaration
agent submitted also whole vector declarations. allow us
provide strong argument truth-telling.
Possible Variants Second Chance Mechanism One alternative denition
mechanism let agents submit outcome determination algorithms instead
appeals. possible apply reasoning similar variant. However,
formulating output algorithms might demanding task many applications.
also delicate dierences.
Another possibility dene multi-round variant mechanism. rst
round agents submit type declarations w. Then, round, agent gets
chance improve allocation found algorithm k(w). mechanism terminates
agent improves current allocation. strategy space multi-round mechanisms complex. Yet, myopic behavior (Parkes, 1999), arguments similar
used justify truthful behavior. arguments may explain relative
success ad hoc mechanisms iterative VCG (IVG) AUSM6 reported Banks
et al., 1989.
Standard Equilibria Second Chance Mechanisms second chance mechanism
uses VCG payments and, therefore, theorems rst part paper apply it.
Lemma 4.2, vector truthful actions ex post equilibrium
resulting allocation optimal range algorithm. Moreover, consider agent
let (wi , li ) set actions agents. (wi , li ) best response
agent resulting allocation optimal range underlying
algorithm respect (v , wi ). least intuitively, nding response least
6. mechanisms spirit second chance mechanism, let agents improve
allocation. actual rules mechanisms complicated described Banks et al.,
1989.

38

fiComputationally Feasible VCG Mechanisms

hard nding allocation optimal range algorithm. Thus, one
expect agents follow equilibrium strategies traditional sense. argue
similar arguments made every game computing best response
computationally dicult. Hence, argument takes account agents
limitations required. note succeed nding natural complexity
limitations truth-telling equilibria agents. leave
intriguing open problem.
4.2 Rationale Truth-telling
noted, standard equilibria expected second chance mechanisms.
section formulates rationale truth-telling mechanisms. rst introduce
notion feasibly dominant actions7 takes account fact agents
capabilities limited. demonstrate reasonable assumptions
agents, truthful, polynomial time, feasibly dominant actions exist.
4.2.1 Feasible Truthfulness
basic models equilibria game theory justied implicit assumption
agents capable computing best response functions. many games,
however, action space huge function complex computed, even
approximately within reasonable amount time. situations assumption
seems longer valid.
section re-formulate concept dominant actions assumption
agents limited capability computing best response. concept meant
used context one stage games, i.e. games agents choose
actions without knowing anything others choices. second chance mechanism
one stage-game. nutshell, action feasibly dominant agent aware
situation (a vector agents actions) another action better it.
Notation: denote action space agent Ai . Given tuple = (a1 , . . . , )
actions chosen agents, denote utility agent ui (a).
Denition 15 (revision function) revision function agent partial function
form bi : Ai Ai .
semantics bi (ai ) knew actions others ai , would choose
bi (ai ) (instead ai ). revision function captures cases agent knows
would like act knew others actions. Note optimal revision functions
standard best-response functions. vector actions ai belong
domain bi (.), semantics agent prefers stick action.
Denition 16 (feasible non-regret) Let agent, bi (.) revision function,
ai vector actions agents. action ai satises feasible non-regret
7. make standard distinction action strategy mapping agents type
action.

39

fiNisan & Ronen

condition (w.r.t. ai bi ), either ai domain bi ui ((bi (ai ), ai ))
ui (a).
words, actions may better ai , agent unaware
cannot compute choosing action.
revision function agent optimal, feasible non-regret equivalent
standard non-regret (best response) condition.
Denition 17 (feasibly dominant action) Let agent, bi (.) revision function.
action ai called feasibly dominant (w.r.t. bi (.)) every vector ai actions
agents, ai satises feasible non-regret condition (w.r.t. ai bi ).
Put dierently, action ai feasibly dominant (when choosing action) agent
aware action ai vector ai actions agents,
better choosing ai others choose ai . dominant action always feasibly
dominant. revision function optimal, feasibly dominant action dominant.
Example order demonstrate concept feasibly dominant actions consider
chess match Alice Bob submit computer programs play behalf.
Currently, course known compute equilibrium chess therefore
standard equilibria relevant analysis game. program aA feasibly
dominant Alice aware possible program Bob
better submitting another program.
Denition 18 (feasibly truthful action) action ai second chance mechanism
called feasibly truthful both, truthful feasibly dominant.
4.2.2 Natural revision functions give rise feasibly truthful actions
Beforehand showed agents truthful, total welfare least
g(v, k(v)). also argued feasibly truthful action available, agent strong
incentive choose it. subsection demonstrates reasonable assumptions
agents, polynomial time feasibly truthful actions exist.
Notation: let denote empty appeal. (w, ) denote action vector
declaration agent wi appeals empty.
Denition 19 (appeal-independent revision function) revision function bi (.)
called appeal independent every vector domain includes empty appeals, i.e.
ai dom(bi ), exists vector wi ai = (wi , ).
say appeal independent function -limited computational time
bounded every appeal function range.
class appeal-independent revision functions represents agents explore
output algorithm (or alternatively, base choice action solely output
algorithm). approach seems reasonable space appeals agents
40

fiComputationally Feasible VCG Mechanisms

huge, apparent structure. least intuitively, seems unreasonable agent
able lie way improve result appeals agents
signicant probability. Moreover, commented, agent obvious potential
loss misreporting type.
Theorem 4.4 Consider second chance mechanism -limited output algorithm.
Suppose agent -limited appeal-independent revision function. every
= (T ), mechanism -limited, agent feasibly truthful action.
Proof: Let bi (.) agents revision function. Dene appeal li (.) follows.
every vector wi , let (wi , ) = bi ((wi , )). Let w = (wi , wi ). Consider outputs
o1 = k(w) o2 = k( (w)). dene li (w) better two outputs, i.e.,
li (w) = arg maxj=1,2 g((v , wi ), oj ). Intuitively, li (.) checks whether declaring wi helpful
agent.
Claim 4.5 ai = (v , li ) feasibly truthful.
Proof: not, exists vector ai = (wi , ) domain bi (.)
u(ai , ai ) < u(bi (ai ), ai ). Let bi (ai ) = (wi , ). Recall according Lemma 4.2,
agents utility equivalent total welfare g((v , wi ), o) chosen output
(up adding hi (.), independent agents actions).
Consider case agents action bi (ai ). Let denote chosen output
case. According denition mechanism, taken set {o1 , o2 }
welfare measured according declaration w.
agent chooses truthful action ai , output (denoted o) chosen
outputs o0 = k((v , wi )) (from denition mechanism), both, o1 , o2 (from
denition li ). superset set outputs rst case. Moreover,
output chosen according right type vector (v , wi ). Thus, g((v , wi ), o)
g((v , wi ), o), implying agent higher utility second case contradiction.
remains show li (.) (T )-limited. obvious both, k(.) (.)
-limited. completes proof theorem.
Given agents revision function, easy construct appeal li (.) dened (i.e.,
construct program computes it). Thus, agent appeal independent
function, guarantee feasibly dominant action.
general class revision functions found Appendix. Interestingly,
tradeo generality class time limit, suces
feasible truthfulness.
4.3 Remarks Choice Time Limit
Sections 4.2.2 A.1 demonstrate two natural classes revision functions
agents polynomial time feasibly truthful actions. claim every
revision function practice fall categories. Yet, plausible
case many applications. general, exists tradeo generality
41

fiNisan & Ronen

class revision functions time limit required feasible truthfulness.
particular, without time limit, submitting optimal appeal dominant.
hand, plausible small time limits suce practice. leave
comprehensive study tradeo future research.
interesting future direction develop representations appeal functions
relate time limit imposed agent actual revision function. One possibility
represent appeals decision trees agents required supply
leaf , type vector v , algorithms result strictly improved given
l(t ) instead actual input v . v proves mechanism computational time
required compute leaf indeed needed order represent agents revision
function. related possibility allow agent purchase additional computational
time.
Currently, know whether every polynomial class revision functions guarantees existence polynomial feasibly truthful actions. agent substantial
knowledge appeal space agents, may able nd falsied declaration causes typical appeals produce better results. case, may
benecial agent lie. know whether knowledge exist practice.
yes, may possible overcome allowing agents submit meta-appeals,
i.e., functions let agents modify input appeals agents.
leave future research.
4.4 Obtaining Individual Rationality
basic desirable property mechanisms utility truthful agent guaranteed
non-negative (individual rationality). section construct variant second
chance mechanisms satises property.
Let gopt (v) denote optimal welfare obtained type vector v . shall
assume agent i, exists type v every v = (v 1 , . . . , v n ),
gopt ((v , v )) gopt (v). call type lowest. combinatorial auction
example, lowest type dened zero valuation v (s) = 0 every combination
items.
Clarke mechanism (Clarke, 1971) VCG mechanism hi (wi ) = gopt (v , wi ),

i.e., pi (w) = j=i wj (opt(w)) gopt (v , (wi )). words, agent pays welfare
loss causes society. Thus, natural dene payment VCG-based

mechanism j=i wj (opt(w)) g((v , wi ), k((v , wi ))).
Like truthfulness, individual rationality may preserved optimal algorithm Clarke mechanism replaced sub-optimal one. order x
need ensure result algorithm improve declaration wi
replaced lowest type v .

Denition 20 (lowest type closure) Given allocation algorithm k(w) dene
lowest type closure k best allocation (according w) among outputs (k(w), k((v 1 , w1 )), . . . , k((v n , w
Since k(.) calls k(.) n times, k -limited, k O(nT )-limited.
Claim 4.6 every w, g(w, k(w)) g((v , wi ), k((v , wi ))).
42

fiComputationally Feasible VCG Mechanisms

Proof: Since k((v , wi )) candidate output k tests, g(w, k(w)) g(w, k((v , wi ))).
Given denition v , g(w, k((v , wi ))) g((v , wi ), k(v , wi )), claim follows.
Denition 21 (second chance-IR) Given allocation algorithm k(w) time limit
dene corresponding second chance-IR mechanism second chance mechanism
output algorithm k(.), time limit , every agent i, hi (wi ) = g((v , wi ), k((v , wi ))).
utility truthful agent mechanism equals ui = g(w, o)g((v , wi ), k((v , wi )))
g(w, k(w)) g((v , wi ), k((v , wi ))) 0. Therefore, mechanism satises individual rationality.

5. Conclusion Future Research
paper studies VCG mechanisms optimal outcome determination algorithm
replaced sub-optimal computationally tractable algorithm. rst part
paper shows wide range problems, mechanisms lose game theoretic
virtues optimal counterparts. Similar results hold ane maximization.
results leave much hope development polynomial time truthful mechanisms
many problems high complexity.
second part paper proposes general method overcoming diculty
constructing truthful mechanisms. Given algorithm underlying optimization
problem dene second chance mechanism based it. demonstrate
reasonable assumptions agents, truth-telling still rational strategy
agents. agents truthful, welfare obtained mechanism least
good one obtained underlying algorithm.
Successful implementation second chance mechanisms relies several tools
developed particular, tools description valuations appeal functions.
engineering issues require exploration.
important stress second chance method yet tested.
particular, truthfulness agents validated experimentally.
hand, believe practice, small time limits agents appeals likely
guarantee truthfulness agents. Several questions regarding payment properties
second chance mechanisms open. leave future research.
Several open questions, directly stem work, raised within body
paper.

Acknowledgments
thank Abraham Newman Motty Perry helpful discussions various stages
work. thank Ron Lavi, Ahuva Mualem, Elan Pavlov, Inbal Ronen, anonymous
reviewers comments earlier drafts paper. Noam Nisan supported
grants Israel Science Foundation USA-Israel Binational Science
Foundation. Amir Ronen supported part grant number 969/06 Israel
Science Foundation. preliminary version paper appeared proceedings
3rd ACM Conference Electronic Commerce (EC 01).
43

fiNisan & Ronen

Appendix A. d-bounded Revision Functions
class d-bounded revision functions represents agents that, addition output
algorithm, explore polynomial family potential appeals agents. class
generalization d-limited appeal-independent functions.
Denition 22 (d-bounded revision function) say revision function bi (.)
d-bounded following hold:
1. revision function bi (.) O(nd )-limited.
2. Let
L = {lj | li,j , wi s.t. (wi , (li , li,j )) Dom(bi )}



{li | (wi , li ), wi s.t. (wi , li ) = bi ((wi , li ))}

family appeals appear either domain range bi (.).
|L| = O(nd ).
3. exists constant c every appeal l L cnd -limited.
Theorem A.1 Consider second chance mechanism O(nd )-limited output algorithm. Suppose agent d-bounded revision function. every = (n2d ),
mechanism -limited, agent feasibly truthful action.
Proof: Let agent let bi revision function. use simulation
argument order dene appeal li (.). every vector wi compute following
outputs:
1. o0 = k(w).
2. Similarly proof Theorem 4.4, let L = {1 . . . |L| } family
appeal functions domain range bi . j = 1, . . . |L| dene
oj = k(j (w))).
3. Dene l(w) = arg max0j|L| g((v , wi ), oj ) output maximum welfare
according (v , wi ) among outputs dened above.
Claim A.2 li (.) n2d -limited.
Proof: W.l.o.g. running time k(.) bounded cnd . Otherwise, raise
constant. According denitions, appeal li performs nd + 1 computations,
requiring cnd time units. Thus, overall computation takes O(n2d ).
Claim A.3 ai = (v , li ) feasibly truthful.
Proof: Assume contradiction exists action vector ai dom(bi )
u((ai , ai ) < u((bi (ai ), ai ).
Consider case agent chooses bi (ai ) = (wi , ). mechanism takes
output maximizes welfare (according w) following set outputs:
44

fiComputationally Feasible VCG Mechanisms

1. o0 = k(w).
2. oj = k(lj (w)) every j = i, i.e. result appeals agents.
3. oi = k( (w)).
agent chooses ai , outputs measured according right type
vector (vi , wi ). Moreover, taken following superset outputs S:
1. o0 = k((vi , wi )) (from denition mechanism).
2. oj = k(lj ((vi , wi ))) every j = i, i.e., result appeals agents
(also, denition mechanism).
3. oj = k( (w)) every L. Since ai domain bi , set includes
outputs form k(lj (w)) case chooses bi (ai ). also contains
result appeal (w).
4. k(w) (from denition li (.)).
Let chosen output case. Since set outputs second case
superset rst, g((vi , wi ), o) g((vi , wi ), o). According Lemma 4.2 utility
agent choosing ai thus higher choosing bi (ai ) contradiction.
completes proof Theorem A.1.
case appeal-independent functions, theorem gives prescription constructing appeal guarantees agent feasibly dominant action.

References
Anderson, E., Kelly, F., & Steinberg, R. (2002). contract balancing mechanism
sharing capacity communication network.. appear.
Archer, A., & Tardos, E. (2002). Frugal path mechanisms. Proceedings 13th
Annual ACM-SIAM Symposium Discrete Algorithms, 991999.
Banks, J., Ledyard, J., & Porter, D. (1989). Allocating uncertain unresponsive resources: experimental approach. RAND Journal Economics, 20, 125.
Bartal, Y., Gonen, R., & Nisan, N. (2003). Incentive compatible multi unit combinatorial
auctions. Proceedings Ninth Conference Theoretical Aspects Rationality
Knowledge, pp. 7287.
Bartholdi, J. J., Tovey, C. A., & Trick., M. A. (1992). hard control election?.
Mathematical Computer Modelling (Special Issue Formal Theories Politics),
16, 2740.
Carroll, T. E., & Grosu, D. (2005). Distributed algorithmic mechanism design scheduling
unrelated machines. Proceedings 8th International Symposium Parallel
Architectures, Algorithms, Networks, pp. 194199.
45

fiNisan & Ronen

Clarke, E. H. (1971). Multipart pricing public goods. Public Choice, 1733.
Cramton, P. (1997). fcc spectrum auction: early assessment. Journal Economics
Management Strategy, 431495.
Cramton, P., Shoham, Y., & Steinberg, R. (2006). Combinatorial Auctions. MIT Press.
dAspremont, C., & Gerard-Varet, L. (1979). Incentives incomplete information. Journal Public Economics, 11 (1), 2545.
Elkind, E., Sahai, A., & Steiglitz, K. (2004). Frugality path auctions. Proceedings
15th Annual ACM-SIAM Symposium Discrete Algorithms, pp. 701709.
Feigenbaum, J., Papadimitriou, C., & Shenker, S. (2000). Sharing cost multicast
transmissions. Proceeding Thirty-Second Annual ACM Symposium Theory
Computing.
Groves, T. (1973). Incentives teams. Econometrica, 41, 617631.
Holzman, R., Kr-Dahav, N., Monderer, D., & Tennenholtz, M. (2004). Bundling equilibrium combinatorial auctions. Games Economic Behavior, 47, 104123.
Holzman, R., & Monderer, D. (2004). Characterization ex post equilibrium vcg
combinatorial auctions. Games Economic Behavior, 47, 87103.
Lavi, R., Nisan, N., & Mualem, A. (2003). Towards characterization truthful combinatorial auctions. Proceedings 44th Annual IEEE Symposium Foundations
Computer Science.
Lehmann, D., OCallaghan, L., & Shoham, Y. (2002). Truth revelation rapid, approximately ecient combinatorial auctions. Journal ACM, 49 (5), 577602.
preliminay version appeared Proc. rst ACM Conference Electronic Commerce.
Mas-Collel, A., Whinston, W., & Green, J. (1995). Microeconomic Theory. Oxford university
press.
Nisan, N. (2000). Bidding allocation combinatorial auctions. Proceedings
Second ACM Conference Electronic Commerce, pp. 112.
Nisan, N., & Ronen, A. (2001). Algorithmic mechanism design. Games Economic
Behaviour, 35, 166196. Extended abstract appeared Proceedings Thirty
First Annual ACM symposium Theory Computing.
Osborne, M. J., & Rubinstein, A. (1994). Course Game Theory. MIT press.
Parkes, D. (1999). ibundle: ecient ascending price bundle auction.. Proceedings
ACM Conference Electronic Commerce (EC-99), pp. 148157.
Porter, R., Ronen, A., Shoham, Y., & Tennenholtz, M. (2002). Mechanism design
execution uncertainty. Proceedings 18th Conference Uncertainty
Articial Intelligence, pp. 414421.
Roberts, K. (1979). characterization implementable choise rules. Laont, J.-J.
(Ed.), Aggregation Revelation Preferences, pp. 321349. North-Holland. Papers
presented rst European Summer Workshop Econometric Society.
46

fiComputationally Feasible VCG Mechanisms

Ronen, A. (2001). Mechanism design incomplete languages. Proceedings
Third ACM Conference Electronic Commerce, 105114.
Rosenschein, J. S., & Zlotkin, G. (1994). Rules Encounter: Designing Conventions
Automated Negotiation Among Computers. MIT Press.
Shoham, Y., & Tanaka, K. (1997). dynamic theory incentives multi-agent systems
(preliminary report). Proceedings Fifteenth International Joint Conferences
Articial Intelligence, pp. 626631.
Shoham, Y., & Tennenholtz, M. (2001). fair imposition tasks multi-agent systems.
Proceedings International Conference Articial Intelligence, pp. 1083
1088.
Vickrey, W. (1961). Counterspeculation, auctions competitive sealed tenders. Journal
Finance, 837.
Wellman, M., Wurman, P., Walsh, W., & MacKie-Mason, J. (2001). Auction protocols
decentralized scheduling. Games Economic Behavior, 35, 271303.
Zuckerman, D. (2006). Linear degree extractors inapproximability max clique
chromatic number. Proceedings 38th ACM Symposium Theory
Computing, Seattle, Washington, USA.

47

fi
